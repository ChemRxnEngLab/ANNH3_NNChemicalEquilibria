{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.Linear(input_size, hidden1_size), #Lineare Transformation mit gespeicherten weights und biases\n",
    "            #nn.LayerNorm(hidden1_size),\n",
    "            nn.Tanh(), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            #nn.LayerNorm(hidden2_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden2_size, hidden3_size),\n",
    "            #nn.LayerNorm(hidden3_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden3_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (6): Tanh()\n",
      "    (7): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#T = log10(T)\n",
    "# T = T / 850\n",
    "# p = p / 1000\n",
    "\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 70, 100], gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "            #print(pred.size())\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 1/25, Loss: 0.0720\n",
      "Epoch 1/200, Iteration 2/25, Loss: 2.2745\n",
      "Epoch 1/200, Iteration 3/25, Loss: 3.2900\n",
      "Epoch 1/200, Iteration 4/25, Loss: 2.2322\n",
      "Epoch 1/200, Iteration 5/25, Loss: 0.5461\n",
      "Epoch 1/200, Iteration 6/25, Loss: 0.6639\n",
      "Epoch 1/200, Iteration 7/25, Loss: 0.8029\n",
      "Epoch 1/200, Iteration 8/25, Loss: 0.4876\n",
      "Epoch 1/200, Iteration 9/25, Loss: 0.4861\n",
      "Epoch 1/200, Iteration 10/25, Loss: 0.6788\n",
      "Epoch 1/200, Iteration 11/25, Loss: 0.5318\n",
      "Epoch 1/200, Iteration 12/25, Loss: 0.4889\n",
      "Epoch 1/200, Iteration 13/25, Loss: 0.3534\n",
      "Epoch 1/200, Iteration 14/25, Loss: 0.3383\n",
      "Epoch 1/200, Iteration 15/25, Loss: 0.1776\n",
      "Epoch 1/200, Iteration 16/25, Loss: 0.1575\n",
      "Epoch 1/200, Iteration 17/25, Loss: 0.2582\n",
      "Epoch 1/200, Iteration 18/25, Loss: 0.2231\n",
      "Epoch 1/200, Iteration 19/25, Loss: 0.2280\n",
      "Epoch 1/200, Iteration 20/25, Loss: 0.1500\n",
      "Epoch 1/200, Iteration 21/25, Loss: 0.1208\n",
      "Epoch 1/200, Iteration 22/25, Loss: 0.1396\n",
      "Epoch 1/200, Iteration 23/25, Loss: 0.1277\n",
      "Epoch 1/200, Iteration 24/25, Loss: 0.1644\n",
      "Epoch 1/200, Iteration 25/25, Loss: 0.1776\n",
      "Train Error: \n",
      " Accuracy: 33.0%, Avg loss: 0.119601, MRE: 5.785507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.126673, MRE: 12.843977 \n",
      "\n",
      "Epoch 2/200, Iteration 1/25, Loss: 0.0962\n",
      "Epoch 2/200, Iteration 2/25, Loss: 0.1620\n",
      "Epoch 2/200, Iteration 3/25, Loss: 0.1212\n",
      "Epoch 2/200, Iteration 4/25, Loss: 0.0834\n",
      "Epoch 2/200, Iteration 5/25, Loss: 0.0726\n",
      "Epoch 2/200, Iteration 6/25, Loss: 0.0728\n",
      "Epoch 2/200, Iteration 7/25, Loss: 0.0504\n",
      "Epoch 2/200, Iteration 8/25, Loss: 0.0705\n",
      "Epoch 2/200, Iteration 9/25, Loss: 0.1751\n",
      "Epoch 2/200, Iteration 10/25, Loss: 0.1083\n",
      "Epoch 2/200, Iteration 11/25, Loss: 0.0627\n",
      "Epoch 2/200, Iteration 12/25, Loss: 0.1480\n",
      "Epoch 2/200, Iteration 13/25, Loss: 0.0793\n",
      "Epoch 2/200, Iteration 14/25, Loss: 0.0853\n",
      "Epoch 2/200, Iteration 15/25, Loss: 0.0914\n",
      "Epoch 2/200, Iteration 16/25, Loss: 0.0466\n",
      "Epoch 2/200, Iteration 17/25, Loss: 0.0806\n",
      "Epoch 2/200, Iteration 18/25, Loss: 0.1613\n",
      "Epoch 2/200, Iteration 19/25, Loss: 0.0579\n",
      "Epoch 2/200, Iteration 20/25, Loss: 0.1974\n",
      "Epoch 2/200, Iteration 21/25, Loss: 0.0999\n",
      "Epoch 2/200, Iteration 22/25, Loss: 0.3207\n",
      "Epoch 2/200, Iteration 23/25, Loss: 0.3921\n",
      "Epoch 2/200, Iteration 24/25, Loss: 0.1032\n",
      "Epoch 2/200, Iteration 25/25, Loss: 0.3353\n",
      "Train Error: \n",
      " Accuracy: 39.0%, Avg loss: 0.522586, MRE: 33.748339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.538023, MRE: 70.369705 \n",
      "\n",
      "Epoch 3/200, Iteration 1/25, Loss: 0.5389\n",
      "Epoch 3/200, Iteration 2/25, Loss: 0.3651\n",
      "Epoch 3/200, Iteration 3/25, Loss: 0.0544\n",
      "Epoch 3/200, Iteration 4/25, Loss: 0.2547\n",
      "Epoch 3/200, Iteration 5/25, Loss: 0.2213\n",
      "Epoch 3/200, Iteration 6/25, Loss: 0.1148\n",
      "Epoch 3/200, Iteration 7/25, Loss: 0.1993\n",
      "Epoch 3/200, Iteration 8/25, Loss: 0.0513\n",
      "Epoch 3/200, Iteration 9/25, Loss: 0.1875\n",
      "Epoch 3/200, Iteration 10/25, Loss: 0.1394\n",
      "Epoch 3/200, Iteration 11/25, Loss: 0.1445\n",
      "Epoch 3/200, Iteration 12/25, Loss: 0.1417\n",
      "Epoch 3/200, Iteration 13/25, Loss: 0.0957\n",
      "Epoch 3/200, Iteration 14/25, Loss: 0.0419\n",
      "Epoch 3/200, Iteration 15/25, Loss: 0.0907\n",
      "Epoch 3/200, Iteration 16/25, Loss: 0.0384\n",
      "Epoch 3/200, Iteration 17/25, Loss: 0.0766\n",
      "Epoch 3/200, Iteration 18/25, Loss: 0.0867\n",
      "Epoch 3/200, Iteration 19/25, Loss: 0.0442\n",
      "Epoch 3/200, Iteration 20/25, Loss: 0.0455\n",
      "Epoch 3/200, Iteration 21/25, Loss: 0.0422\n",
      "Epoch 3/200, Iteration 22/25, Loss: 0.0878\n",
      "Epoch 3/200, Iteration 23/25, Loss: 0.0614\n",
      "Epoch 3/200, Iteration 24/25, Loss: 0.0438\n",
      "Epoch 3/200, Iteration 25/25, Loss: 0.0384\n",
      "Train Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.040802, MRE: 2.015968 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.042711, MRE: 4.067754 \n",
      "\n",
      "Epoch 4/200, Iteration 1/25, Loss: 0.0442\n",
      "Epoch 4/200, Iteration 2/25, Loss: 0.0820\n",
      "Epoch 4/200, Iteration 3/25, Loss: 0.0798\n",
      "Epoch 4/200, Iteration 4/25, Loss: 0.0444\n",
      "Epoch 4/200, Iteration 5/25, Loss: 0.0536\n",
      "Epoch 4/200, Iteration 6/25, Loss: 0.0314\n",
      "Epoch 4/200, Iteration 7/25, Loss: 0.0376\n",
      "Epoch 4/200, Iteration 8/25, Loss: 0.0320\n",
      "Epoch 4/200, Iteration 9/25, Loss: 0.0980\n",
      "Epoch 4/200, Iteration 10/25, Loss: 0.0534\n",
      "Epoch 4/200, Iteration 11/25, Loss: 0.0330\n",
      "Epoch 4/200, Iteration 12/25, Loss: 0.0897\n",
      "Epoch 4/200, Iteration 13/25, Loss: 0.0261\n",
      "Epoch 4/200, Iteration 14/25, Loss: 0.0325\n",
      "Epoch 4/200, Iteration 15/25, Loss: 0.0853\n",
      "Epoch 4/200, Iteration 16/25, Loss: 0.1104\n",
      "Epoch 4/200, Iteration 17/25, Loss: 0.0356\n",
      "Epoch 4/200, Iteration 18/25, Loss: 0.1076\n",
      "Epoch 4/200, Iteration 19/25, Loss: 0.0348\n",
      "Epoch 4/200, Iteration 20/25, Loss: 0.1071\n",
      "Epoch 4/200, Iteration 21/25, Loss: 0.0437\n",
      "Epoch 4/200, Iteration 22/25, Loss: 0.0381\n",
      "Epoch 4/200, Iteration 23/25, Loss: 0.0345\n",
      "Epoch 4/200, Iteration 24/25, Loss: 0.0604\n",
      "Epoch 4/200, Iteration 25/25, Loss: 0.0731\n",
      "Train Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.042989, MRE: 2.343026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.039931, MRE: 4.195480 \n",
      "\n",
      "Epoch 5/200, Iteration 1/25, Loss: 0.0532\n",
      "Epoch 5/200, Iteration 2/25, Loss: 0.1270\n",
      "Epoch 5/200, Iteration 3/25, Loss: 0.0525\n",
      "Epoch 5/200, Iteration 4/25, Loss: 0.1595\n",
      "Epoch 5/200, Iteration 5/25, Loss: 0.0937\n",
      "Epoch 5/200, Iteration 6/25, Loss: 0.1911\n",
      "Epoch 5/200, Iteration 7/25, Loss: 0.1887\n",
      "Epoch 5/200, Iteration 8/25, Loss: 0.0485\n",
      "Epoch 5/200, Iteration 9/25, Loss: 0.1908\n",
      "Epoch 5/200, Iteration 10/25, Loss: 0.1929\n",
      "Epoch 5/200, Iteration 11/25, Loss: 0.0640\n",
      "Epoch 5/200, Iteration 12/25, Loss: 0.1128\n",
      "Epoch 5/200, Iteration 13/25, Loss: 0.0533\n",
      "Epoch 5/200, Iteration 14/25, Loss: 0.0853\n",
      "Epoch 5/200, Iteration 15/25, Loss: 0.0963\n",
      "Epoch 5/200, Iteration 16/25, Loss: 0.0547\n",
      "Epoch 5/200, Iteration 17/25, Loss: 0.0765\n",
      "Epoch 5/200, Iteration 18/25, Loss: 0.0747\n",
      "Epoch 5/200, Iteration 19/25, Loss: 0.0433\n",
      "Epoch 5/200, Iteration 20/25, Loss: 0.0652\n",
      "Epoch 5/200, Iteration 21/25, Loss: 0.0771\n",
      "Epoch 5/200, Iteration 22/25, Loss: 0.0334\n",
      "Epoch 5/200, Iteration 23/25, Loss: 0.0691\n",
      "Epoch 5/200, Iteration 24/25, Loss: 0.0848\n",
      "Epoch 5/200, Iteration 25/25, Loss: 0.0382\n",
      "Train Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.087696, MRE: 6.350962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.083178, MRE: 13.404122 \n",
      "\n",
      "Epoch 6/200, Iteration 1/25, Loss: 0.0946\n",
      "Epoch 6/200, Iteration 2/25, Loss: 0.0480\n",
      "Epoch 6/200, Iteration 3/25, Loss: 0.0254\n",
      "Epoch 6/200, Iteration 4/25, Loss: 0.0790\n",
      "Epoch 6/200, Iteration 5/25, Loss: 0.0431\n",
      "Epoch 6/200, Iteration 6/25, Loss: 0.1454\n",
      "Epoch 6/200, Iteration 7/25, Loss: 0.0755\n",
      "Epoch 6/200, Iteration 8/25, Loss: 0.1971\n",
      "Epoch 6/200, Iteration 9/25, Loss: 0.2333\n",
      "Epoch 6/200, Iteration 10/25, Loss: 0.0731\n",
      "Epoch 6/200, Iteration 11/25, Loss: 0.1726\n",
      "Epoch 6/200, Iteration 12/25, Loss: 0.2521\n",
      "Epoch 6/200, Iteration 13/25, Loss: 0.0758\n",
      "Epoch 6/200, Iteration 14/25, Loss: 0.2347\n",
      "Epoch 6/200, Iteration 15/25, Loss: 0.2971\n",
      "Epoch 6/200, Iteration 16/25, Loss: 0.1826\n",
      "Epoch 6/200, Iteration 17/25, Loss: 0.1344\n",
      "Epoch 6/200, Iteration 18/25, Loss: 0.1853\n",
      "Epoch 6/200, Iteration 19/25, Loss: 0.0913\n",
      "Epoch 6/200, Iteration 20/25, Loss: 0.1644\n",
      "Epoch 6/200, Iteration 21/25, Loss: 0.2168\n",
      "Epoch 6/200, Iteration 22/25, Loss: 0.0886\n",
      "Epoch 6/200, Iteration 23/25, Loss: 0.1841\n",
      "Epoch 6/200, Iteration 24/25, Loss: 0.2382\n",
      "Epoch 6/200, Iteration 25/25, Loss: 0.0966\n",
      "Train Error: \n",
      " Accuracy: 66.12%, Avg loss: 0.164608, MRE: 10.719097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.150728, MRE: 12.582561 \n",
      "\n",
      "Epoch 7/200, Iteration 1/25, Loss: 0.1821\n",
      "Epoch 7/200, Iteration 2/25, Loss: 0.2285\n",
      "Epoch 7/200, Iteration 3/25, Loss: 0.1895\n",
      "Epoch 7/200, Iteration 4/25, Loss: 0.0699\n",
      "Epoch 7/200, Iteration 5/25, Loss: 0.1375\n",
      "Epoch 7/200, Iteration 6/25, Loss: 0.0862\n",
      "Epoch 7/200, Iteration 7/25, Loss: 0.1262\n",
      "Epoch 7/200, Iteration 8/25, Loss: 0.1535\n",
      "Epoch 7/200, Iteration 9/25, Loss: 0.0665\n",
      "Epoch 7/200, Iteration 10/25, Loss: 0.1350\n",
      "Epoch 7/200, Iteration 11/25, Loss: 0.1801\n",
      "Epoch 7/200, Iteration 12/25, Loss: 0.1541\n",
      "Epoch 7/200, Iteration 13/25, Loss: 0.0904\n",
      "Epoch 7/200, Iteration 14/25, Loss: 0.1004\n",
      "Epoch 7/200, Iteration 15/25, Loss: 0.0587\n",
      "Epoch 7/200, Iteration 16/25, Loss: 0.1011\n",
      "Epoch 7/200, Iteration 17/25, Loss: 0.0947\n",
      "Epoch 7/200, Iteration 18/25, Loss: 0.0719\n",
      "Epoch 7/200, Iteration 19/25, Loss: 0.1046\n",
      "Epoch 7/200, Iteration 20/25, Loss: 0.0423\n",
      "Epoch 7/200, Iteration 21/25, Loss: 0.1211\n",
      "Epoch 7/200, Iteration 22/25, Loss: 0.0765\n",
      "Epoch 7/200, Iteration 23/25, Loss: 0.0770\n",
      "Epoch 7/200, Iteration 24/25, Loss: 0.0937\n",
      "Epoch 7/200, Iteration 25/25, Loss: 0.0355\n",
      "Train Error: \n",
      " Accuracy: 33.38%, Avg loss: 0.070617, MRE: 5.349829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 0.073058, MRE: 8.933757 \n",
      "\n",
      "Epoch 8/200, Iteration 1/25, Loss: 0.0606\n",
      "Epoch 8/200, Iteration 2/25, Loss: 0.0647\n",
      "Epoch 8/200, Iteration 3/25, Loss: 0.0655\n",
      "Epoch 8/200, Iteration 4/25, Loss: 0.0415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 5/25, Loss: 0.0409\n",
      "Epoch 8/200, Iteration 6/25, Loss: 0.0268\n",
      "Epoch 8/200, Iteration 7/25, Loss: 0.0517\n",
      "Epoch 8/200, Iteration 8/25, Loss: 0.0526\n",
      "Epoch 8/200, Iteration 9/25, Loss: 0.0377\n",
      "Epoch 8/200, Iteration 10/25, Loss: 0.0666\n",
      "Epoch 8/200, Iteration 11/25, Loss: 0.0609\n",
      "Epoch 8/200, Iteration 12/25, Loss: 0.0590\n",
      "Epoch 8/200, Iteration 13/25, Loss: 0.0488\n",
      "Epoch 8/200, Iteration 14/25, Loss: 0.0376\n",
      "Epoch 8/200, Iteration 15/25, Loss: 0.0439\n",
      "Epoch 8/200, Iteration 16/25, Loss: 0.0517\n",
      "Epoch 8/200, Iteration 17/25, Loss: 0.0609\n",
      "Epoch 8/200, Iteration 18/25, Loss: 0.0679\n",
      "Epoch 8/200, Iteration 19/25, Loss: 0.0554\n",
      "Epoch 8/200, Iteration 20/25, Loss: 0.0368\n",
      "Epoch 8/200, Iteration 21/25, Loss: 0.0347\n",
      "Epoch 8/200, Iteration 22/25, Loss: 0.0363\n",
      "Epoch 8/200, Iteration 23/25, Loss: 0.0522\n",
      "Epoch 8/200, Iteration 24/25, Loss: 0.0445\n",
      "Epoch 8/200, Iteration 25/25, Loss: 0.0684\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.054527, MRE: 2.507047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.055428, MRE: 8.804789 \n",
      "\n",
      "Epoch 9/200, Iteration 1/25, Loss: 0.0549\n",
      "Epoch 9/200, Iteration 2/25, Loss: 0.0565\n",
      "Epoch 9/200, Iteration 3/25, Loss: 0.0976\n",
      "Epoch 9/200, Iteration 4/25, Loss: 0.0879\n",
      "Epoch 9/200, Iteration 5/25, Loss: 0.1037\n",
      "Epoch 9/200, Iteration 6/25, Loss: 0.1046\n",
      "Epoch 9/200, Iteration 7/25, Loss: 0.0357\n",
      "Epoch 9/200, Iteration 8/25, Loss: 0.1067\n",
      "Epoch 9/200, Iteration 9/25, Loss: 0.0456\n",
      "Epoch 9/200, Iteration 10/25, Loss: 0.0967\n",
      "Epoch 9/200, Iteration 11/25, Loss: 0.0678\n",
      "Epoch 9/200, Iteration 12/25, Loss: 0.0817\n",
      "Epoch 9/200, Iteration 13/25, Loss: 0.0701\n",
      "Epoch 9/200, Iteration 14/25, Loss: 0.0945\n",
      "Epoch 9/200, Iteration 15/25, Loss: 0.1080\n",
      "Epoch 9/200, Iteration 16/25, Loss: 0.0331\n",
      "Epoch 9/200, Iteration 17/25, Loss: 0.0916\n",
      "Epoch 9/200, Iteration 18/25, Loss: 0.0784\n",
      "Epoch 9/200, Iteration 19/25, Loss: 0.0693\n",
      "Epoch 9/200, Iteration 20/25, Loss: 0.0877\n",
      "Epoch 9/200, Iteration 21/25, Loss: 0.1008\n",
      "Epoch 9/200, Iteration 22/25, Loss: 0.1172\n",
      "Epoch 9/200, Iteration 23/25, Loss: 0.0785\n",
      "Epoch 9/200, Iteration 24/25, Loss: 0.0643\n",
      "Epoch 9/200, Iteration 25/25, Loss: 0.0645\n",
      "Train Error: \n",
      " Accuracy: 52.88%, Avg loss: 0.077744, MRE: 6.008245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.072176, MRE: 14.955546 \n",
      "\n",
      "Epoch 10/200, Iteration 1/25, Loss: 0.0805\n",
      "Epoch 10/200, Iteration 2/25, Loss: 0.0917\n",
      "Epoch 10/200, Iteration 3/25, Loss: 0.0831\n",
      "Epoch 10/200, Iteration 4/25, Loss: 0.0608\n",
      "Epoch 10/200, Iteration 5/25, Loss: 0.0716\n",
      "Epoch 10/200, Iteration 6/25, Loss: 0.0356\n",
      "Epoch 10/200, Iteration 7/25, Loss: 0.0693\n",
      "Epoch 10/200, Iteration 8/25, Loss: 0.0668\n",
      "Epoch 10/200, Iteration 9/25, Loss: 0.0659\n",
      "Epoch 10/200, Iteration 10/25, Loss: 0.0389\n",
      "Epoch 10/200, Iteration 11/25, Loss: 0.0347\n",
      "Epoch 10/200, Iteration 12/25, Loss: 0.0688\n",
      "Epoch 10/200, Iteration 13/25, Loss: 0.0464\n",
      "Epoch 10/200, Iteration 14/25, Loss: 0.0417\n",
      "Epoch 10/200, Iteration 15/25, Loss: 0.0502\n",
      "Epoch 10/200, Iteration 16/25, Loss: 0.0620\n",
      "Epoch 10/200, Iteration 17/25, Loss: 0.0480\n",
      "Epoch 10/200, Iteration 18/25, Loss: 0.0718\n",
      "Epoch 10/200, Iteration 19/25, Loss: 0.0410\n",
      "Epoch 10/200, Iteration 20/25, Loss: 0.0790\n",
      "Epoch 10/200, Iteration 21/25, Loss: 0.0473\n",
      "Epoch 10/200, Iteration 22/25, Loss: 0.0509\n",
      "Epoch 10/200, Iteration 23/25, Loss: 0.0515\n",
      "Epoch 10/200, Iteration 24/25, Loss: 0.0395\n",
      "Epoch 10/200, Iteration 25/25, Loss: 0.0858\n",
      "Train Error: \n",
      " Accuracy: 44.62%, Avg loss: 0.039179, MRE: 2.503137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.041416, MRE: 4.697396 \n",
      "\n",
      "Epoch 11/200, Iteration 1/25, Loss: 0.0568\n",
      "Epoch 11/200, Iteration 2/25, Loss: 0.1724\n",
      "Epoch 11/200, Iteration 3/25, Loss: 0.1942\n",
      "Epoch 11/200, Iteration 4/25, Loss: 0.1053\n",
      "Epoch 11/200, Iteration 5/25, Loss: 0.1479\n",
      "Epoch 11/200, Iteration 6/25, Loss: 0.1697\n",
      "Epoch 11/200, Iteration 7/25, Loss: 0.0642\n",
      "Epoch 11/200, Iteration 8/25, Loss: 0.1669\n",
      "Epoch 11/200, Iteration 9/25, Loss: 0.2012\n",
      "Epoch 11/200, Iteration 10/25, Loss: 0.0585\n",
      "Epoch 11/200, Iteration 11/25, Loss: 0.1516\n",
      "Epoch 11/200, Iteration 12/25, Loss: 0.1959\n",
      "Epoch 11/200, Iteration 13/25, Loss: 0.0958\n",
      "Epoch 11/200, Iteration 14/25, Loss: 0.1412\n",
      "Epoch 11/200, Iteration 15/25, Loss: 0.1450\n",
      "Epoch 11/200, Iteration 16/25, Loss: 0.0550\n",
      "Epoch 11/200, Iteration 17/25, Loss: 0.1270\n",
      "Epoch 11/200, Iteration 18/25, Loss: 0.1014\n",
      "Epoch 11/200, Iteration 19/25, Loss: 0.0771\n",
      "Epoch 11/200, Iteration 20/25, Loss: 0.1171\n",
      "Epoch 11/200, Iteration 21/25, Loss: 0.0495\n",
      "Epoch 11/200, Iteration 22/25, Loss: 0.1669\n",
      "Epoch 11/200, Iteration 23/25, Loss: 0.1712\n",
      "Epoch 11/200, Iteration 24/25, Loss: 0.0941\n",
      "Epoch 11/200, Iteration 25/25, Loss: 0.1445\n",
      "Train Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.166582, MRE: 11.099117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.162409, MRE: 28.113969 \n",
      "\n",
      "Epoch 12/200, Iteration 1/25, Loss: 0.1751\n",
      "Epoch 12/200, Iteration 2/25, Loss: 0.1010\n",
      "Epoch 12/200, Iteration 3/25, Loss: 0.1479\n",
      "Epoch 12/200, Iteration 4/25, Loss: 0.1216\n",
      "Epoch 12/200, Iteration 5/25, Loss: 0.0556\n",
      "Epoch 12/200, Iteration 6/25, Loss: 0.1569\n",
      "Epoch 12/200, Iteration 7/25, Loss: 0.1472\n",
      "Epoch 12/200, Iteration 8/25, Loss: 0.0839\n",
      "Epoch 12/200, Iteration 9/25, Loss: 0.0921\n",
      "Epoch 12/200, Iteration 10/25, Loss: 0.0854\n",
      "Epoch 12/200, Iteration 11/25, Loss: 0.0479\n",
      "Epoch 12/200, Iteration 12/25, Loss: 0.0795\n",
      "Epoch 12/200, Iteration 13/25, Loss: 0.0308\n",
      "Epoch 12/200, Iteration 14/25, Loss: 0.0563\n",
      "Epoch 12/200, Iteration 15/25, Loss: 0.0419\n",
      "Epoch 12/200, Iteration 16/25, Loss: 0.0776\n",
      "Epoch 12/200, Iteration 17/25, Loss: 0.0457\n",
      "Epoch 12/200, Iteration 18/25, Loss: 0.0520\n",
      "Epoch 12/200, Iteration 19/25, Loss: 0.0594\n",
      "Epoch 12/200, Iteration 20/25, Loss: 0.0317\n",
      "Epoch 12/200, Iteration 21/25, Loss: 0.0565\n",
      "Epoch 12/200, Iteration 22/25, Loss: 0.0376\n",
      "Epoch 12/200, Iteration 23/25, Loss: 0.0419\n",
      "Epoch 12/200, Iteration 24/25, Loss: 0.0383\n",
      "Epoch 12/200, Iteration 25/25, Loss: 0.0595\n",
      "Train Error: \n",
      " Accuracy: 57.25%, Avg loss: 0.033937, MRE: 2.051393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.036661, MRE: 3.821081 \n",
      "\n",
      "Epoch 13/200, Iteration 1/25, Loss: 0.0276\n",
      "Epoch 13/200, Iteration 2/25, Loss: 0.0474\n",
      "Epoch 13/200, Iteration 3/25, Loss: 0.0512\n",
      "Epoch 13/200, Iteration 4/25, Loss: 0.0375\n",
      "Epoch 13/200, Iteration 5/25, Loss: 0.0476\n",
      "Epoch 13/200, Iteration 6/25, Loss: 0.0433\n",
      "Epoch 13/200, Iteration 7/25, Loss: 0.0434\n",
      "Epoch 13/200, Iteration 8/25, Loss: 0.0721\n",
      "Epoch 13/200, Iteration 9/25, Loss: 0.0506\n",
      "Epoch 13/200, Iteration 10/25, Loss: 0.0832\n",
      "Epoch 13/200, Iteration 11/25, Loss: 0.0926\n",
      "Epoch 13/200, Iteration 12/25, Loss: 0.0516\n",
      "Epoch 13/200, Iteration 13/25, Loss: 0.0916\n",
      "Epoch 13/200, Iteration 14/25, Loss: 0.1304\n",
      "Epoch 13/200, Iteration 15/25, Loss: 0.0825\n",
      "Epoch 13/200, Iteration 16/25, Loss: 0.0390\n",
      "Epoch 13/200, Iteration 17/25, Loss: 0.0767\n",
      "Epoch 13/200, Iteration 18/25, Loss: 0.0584\n",
      "Epoch 13/200, Iteration 19/25, Loss: 0.0882\n",
      "Epoch 13/200, Iteration 20/25, Loss: 0.0762\n",
      "Epoch 13/200, Iteration 21/25, Loss: 0.0555\n",
      "Epoch 13/200, Iteration 22/25, Loss: 0.0592\n",
      "Epoch 13/200, Iteration 23/25, Loss: 0.0751\n",
      "Epoch 13/200, Iteration 24/25, Loss: 0.0596\n",
      "Epoch 13/200, Iteration 25/25, Loss: 0.0773\n",
      "Train Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.052629, MRE: 3.025385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.058899, MRE: 2.073112 \n",
      "\n",
      "Epoch 14/200, Iteration 1/25, Loss: 0.0477\n",
      "Epoch 14/200, Iteration 2/25, Loss: 0.0686\n",
      "Epoch 14/200, Iteration 3/25, Loss: 0.0424\n",
      "Epoch 14/200, Iteration 4/25, Loss: 0.0859\n",
      "Epoch 14/200, Iteration 5/25, Loss: 0.0474\n",
      "Epoch 14/200, Iteration 6/25, Loss: 0.0516\n",
      "Epoch 14/200, Iteration 7/25, Loss: 0.0567\n",
      "Epoch 14/200, Iteration 8/25, Loss: 0.0390\n",
      "Epoch 14/200, Iteration 9/25, Loss: 0.0467\n",
      "Epoch 14/200, Iteration 10/25, Loss: 0.0444\n",
      "Epoch 14/200, Iteration 11/25, Loss: 0.0375\n",
      "Epoch 14/200, Iteration 12/25, Loss: 0.0482\n",
      "Epoch 14/200, Iteration 13/25, Loss: 0.0412\n",
      "Epoch 14/200, Iteration 14/25, Loss: 0.0543\n",
      "Epoch 14/200, Iteration 15/25, Loss: 0.0299\n",
      "Epoch 14/200, Iteration 16/25, Loss: 0.0338\n",
      "Epoch 14/200, Iteration 17/25, Loss: 0.0431\n",
      "Epoch 14/200, Iteration 18/25, Loss: 0.0474\n",
      "Epoch 14/200, Iteration 19/25, Loss: 0.0283\n",
      "Epoch 14/200, Iteration 20/25, Loss: 0.0317\n",
      "Epoch 14/200, Iteration 21/25, Loss: 0.0501\n",
      "Epoch 14/200, Iteration 22/25, Loss: 0.0376\n",
      "Epoch 14/200, Iteration 23/25, Loss: 0.0334\n",
      "Epoch 14/200, Iteration 24/25, Loss: 0.0485\n",
      "Epoch 14/200, Iteration 25/25, Loss: 0.0327\n",
      "Train Error: \n",
      " Accuracy: 48.25%, Avg loss: 0.046801, MRE: 2.766243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 0.052617, MRE: 2.923858 \n",
      "\n",
      "Epoch 15/200, Iteration 1/25, Loss: 0.0475\n",
      "Epoch 15/200, Iteration 2/25, Loss: 0.0487\n",
      "Epoch 15/200, Iteration 3/25, Loss: 0.0416\n",
      "Epoch 15/200, Iteration 4/25, Loss: 0.0520\n",
      "Epoch 15/200, Iteration 5/25, Loss: 0.0630\n",
      "Epoch 15/200, Iteration 6/25, Loss: 0.0444\n",
      "Epoch 15/200, Iteration 7/25, Loss: 0.0872\n",
      "Epoch 15/200, Iteration 8/25, Loss: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Iteration 9/25, Loss: 0.0395\n",
      "Epoch 15/200, Iteration 10/25, Loss: 0.0398\n",
      "Epoch 15/200, Iteration 11/25, Loss: 0.0357\n",
      "Epoch 15/200, Iteration 12/25, Loss: 0.0350\n",
      "Epoch 15/200, Iteration 13/25, Loss: 0.0357\n",
      "Epoch 15/200, Iteration 14/25, Loss: 0.0255\n",
      "Epoch 15/200, Iteration 15/25, Loss: 0.0367\n",
      "Epoch 15/200, Iteration 16/25, Loss: 0.0469\n",
      "Epoch 15/200, Iteration 17/25, Loss: 0.0489\n",
      "Epoch 15/200, Iteration 18/25, Loss: 0.0528\n",
      "Epoch 15/200, Iteration 19/25, Loss: 0.0419\n",
      "Epoch 15/200, Iteration 20/25, Loss: 0.0411\n",
      "Epoch 15/200, Iteration 21/25, Loss: 0.0387\n",
      "Epoch 15/200, Iteration 22/25, Loss: 0.0478\n",
      "Epoch 15/200, Iteration 23/25, Loss: 0.0288\n",
      "Epoch 15/200, Iteration 24/25, Loss: 0.0392\n",
      "Epoch 15/200, Iteration 25/25, Loss: 0.0431\n",
      "Train Error: \n",
      " Accuracy: 62.12%, Avg loss: 0.036256, MRE: 2.253538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.040451, MRE: 6.503457 \n",
      "\n",
      "Epoch 16/200, Iteration 1/25, Loss: 0.0378\n",
      "Epoch 16/200, Iteration 2/25, Loss: 0.0480\n",
      "Epoch 16/200, Iteration 3/25, Loss: 0.0391\n",
      "Epoch 16/200, Iteration 4/25, Loss: 0.0390\n",
      "Epoch 16/200, Iteration 5/25, Loss: 0.0375\n",
      "Epoch 16/200, Iteration 6/25, Loss: 0.0268\n",
      "Epoch 16/200, Iteration 7/25, Loss: 0.0322\n",
      "Epoch 16/200, Iteration 8/25, Loss: 0.0305\n",
      "Epoch 16/200, Iteration 9/25, Loss: 0.0431\n",
      "Epoch 16/200, Iteration 10/25, Loss: 0.0548\n",
      "Epoch 16/200, Iteration 11/25, Loss: 0.0349\n",
      "Epoch 16/200, Iteration 12/25, Loss: 0.0512\n",
      "Epoch 16/200, Iteration 13/25, Loss: 0.0716\n",
      "Epoch 16/200, Iteration 14/25, Loss: 0.0637\n",
      "Epoch 16/200, Iteration 15/25, Loss: 0.0404\n",
      "Epoch 16/200, Iteration 16/25, Loss: 0.0678\n",
      "Epoch 16/200, Iteration 17/25, Loss: 0.0628\n",
      "Epoch 16/200, Iteration 18/25, Loss: 0.0357\n",
      "Epoch 16/200, Iteration 19/25, Loss: 0.0357\n",
      "Epoch 16/200, Iteration 20/25, Loss: 0.0688\n",
      "Epoch 16/200, Iteration 21/25, Loss: 0.0417\n",
      "Epoch 16/200, Iteration 22/25, Loss: 0.0876\n",
      "Epoch 16/200, Iteration 23/25, Loss: 0.0594\n",
      "Epoch 16/200, Iteration 24/25, Loss: 0.0576\n",
      "Epoch 16/200, Iteration 25/25, Loss: 0.0584\n",
      "Train Error: \n",
      " Accuracy: 66.88%, Avg loss: 0.039470, MRE: 1.763381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.041284, MRE: 6.289622 \n",
      "\n",
      "Epoch 17/200, Iteration 1/25, Loss: 0.0469\n",
      "Epoch 17/200, Iteration 2/25, Loss: 0.0500\n",
      "Epoch 17/200, Iteration 3/25, Loss: 0.0495\n",
      "Epoch 17/200, Iteration 4/25, Loss: 0.0606\n",
      "Epoch 17/200, Iteration 5/25, Loss: 0.0471\n",
      "Epoch 17/200, Iteration 6/25, Loss: 0.1038\n",
      "Epoch 17/200, Iteration 7/25, Loss: 0.0440\n",
      "Epoch 17/200, Iteration 8/25, Loss: 0.0929\n",
      "Epoch 17/200, Iteration 9/25, Loss: 0.0279\n",
      "Epoch 17/200, Iteration 10/25, Loss: 0.1409\n",
      "Epoch 17/200, Iteration 11/25, Loss: 0.0952\n",
      "Epoch 17/200, Iteration 12/25, Loss: 0.0726\n",
      "Epoch 17/200, Iteration 13/25, Loss: 0.0686\n",
      "Epoch 17/200, Iteration 14/25, Loss: 0.0788\n",
      "Epoch 17/200, Iteration 15/25, Loss: 0.0711\n",
      "Epoch 17/200, Iteration 16/25, Loss: 0.0509\n",
      "Epoch 17/200, Iteration 17/25, Loss: 0.0671\n",
      "Epoch 17/200, Iteration 18/25, Loss: 0.0411\n",
      "Epoch 17/200, Iteration 19/25, Loss: 0.0488\n",
      "Epoch 17/200, Iteration 20/25, Loss: 0.0338\n",
      "Epoch 17/200, Iteration 21/25, Loss: 0.0534\n",
      "Epoch 17/200, Iteration 22/25, Loss: 0.0678\n",
      "Epoch 17/200, Iteration 23/25, Loss: 0.0507\n",
      "Epoch 17/200, Iteration 24/25, Loss: 0.0511\n",
      "Epoch 17/200, Iteration 25/25, Loss: 0.0507\n",
      "Train Error: \n",
      " Accuracy: 40.25%, Avg loss: 0.074431, MRE: 4.402348 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.074049, MRE: 7.312350 \n",
      "\n",
      "Epoch 18/200, Iteration 1/25, Loss: 0.0865\n",
      "Epoch 18/200, Iteration 2/25, Loss: 0.0393\n",
      "Epoch 18/200, Iteration 3/25, Loss: 0.0564\n",
      "Epoch 18/200, Iteration 4/25, Loss: 0.0423\n",
      "Epoch 18/200, Iteration 5/25, Loss: 0.0375\n",
      "Epoch 18/200, Iteration 6/25, Loss: 0.0495\n",
      "Epoch 18/200, Iteration 7/25, Loss: 0.0452\n",
      "Epoch 18/200, Iteration 8/25, Loss: 0.0447\n",
      "Epoch 18/200, Iteration 9/25, Loss: 0.0551\n",
      "Epoch 18/200, Iteration 10/25, Loss: 0.0247\n",
      "Epoch 18/200, Iteration 11/25, Loss: 0.0416\n",
      "Epoch 18/200, Iteration 12/25, Loss: 0.0590\n",
      "Epoch 18/200, Iteration 13/25, Loss: 0.0408\n",
      "Epoch 18/200, Iteration 14/25, Loss: 0.0868\n",
      "Epoch 18/200, Iteration 15/25, Loss: 0.0515\n",
      "Epoch 18/200, Iteration 16/25, Loss: 0.0474\n",
      "Epoch 18/200, Iteration 17/25, Loss: 0.0560\n",
      "Epoch 18/200, Iteration 18/25, Loss: 0.0455\n",
      "Epoch 18/200, Iteration 19/25, Loss: 0.0395\n",
      "Epoch 18/200, Iteration 20/25, Loss: 0.0329\n",
      "Epoch 18/200, Iteration 21/25, Loss: 0.0589\n",
      "Epoch 18/200, Iteration 22/25, Loss: 0.0389\n",
      "Epoch 18/200, Iteration 23/25, Loss: 0.0888\n",
      "Epoch 18/200, Iteration 24/25, Loss: 0.0544\n",
      "Epoch 18/200, Iteration 25/25, Loss: 0.0779\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.042059, MRE: 2.678640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.045367, MRE: 9.779955 \n",
      "\n",
      "Epoch 19/200, Iteration 1/25, Loss: 0.0529\n",
      "Epoch 19/200, Iteration 2/25, Loss: 0.0907\n",
      "Epoch 19/200, Iteration 3/25, Loss: 0.0662\n",
      "Epoch 19/200, Iteration 4/25, Loss: 0.1058\n",
      "Epoch 19/200, Iteration 5/25, Loss: 0.0683\n",
      "Epoch 19/200, Iteration 6/25, Loss: 0.0789\n",
      "Epoch 19/200, Iteration 7/25, Loss: 0.0417\n",
      "Epoch 19/200, Iteration 8/25, Loss: 0.0440\n",
      "Epoch 19/200, Iteration 9/25, Loss: 0.0806\n",
      "Epoch 19/200, Iteration 10/25, Loss: 0.0363\n",
      "Epoch 19/200, Iteration 11/25, Loss: 0.0999\n",
      "Epoch 19/200, Iteration 12/25, Loss: 0.0769\n",
      "Epoch 19/200, Iteration 13/25, Loss: 0.0367\n",
      "Epoch 19/200, Iteration 14/25, Loss: 0.0516\n",
      "Epoch 19/200, Iteration 15/25, Loss: 0.0543\n",
      "Epoch 19/200, Iteration 16/25, Loss: 0.0726\n",
      "Epoch 19/200, Iteration 17/25, Loss: 0.0420\n",
      "Epoch 19/200, Iteration 18/25, Loss: 0.0667\n",
      "Epoch 19/200, Iteration 19/25, Loss: 0.0361\n",
      "Epoch 19/200, Iteration 20/25, Loss: 0.0786\n",
      "Epoch 19/200, Iteration 21/25, Loss: 0.0538\n",
      "Epoch 19/200, Iteration 22/25, Loss: 0.0484\n",
      "Epoch 19/200, Iteration 23/25, Loss: 0.0510\n",
      "Epoch 19/200, Iteration 24/25, Loss: 0.0361\n",
      "Epoch 19/200, Iteration 25/25, Loss: 0.0584\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.047612, MRE: 2.675123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.047221, MRE: 5.478727 \n",
      "\n",
      "Epoch 20/200, Iteration 1/25, Loss: 0.0438\n",
      "Epoch 20/200, Iteration 2/25, Loss: 0.0843\n",
      "Epoch 20/200, Iteration 3/25, Loss: 0.0737\n",
      "Epoch 20/200, Iteration 4/25, Loss: 0.0455\n",
      "Epoch 20/200, Iteration 5/25, Loss: 0.0639\n",
      "Epoch 20/200, Iteration 6/25, Loss: 0.0377\n",
      "Epoch 20/200, Iteration 7/25, Loss: 0.0576\n",
      "Epoch 20/200, Iteration 8/25, Loss: 0.0585\n",
      "Epoch 20/200, Iteration 9/25, Loss: 0.0484\n",
      "Epoch 20/200, Iteration 10/25, Loss: 0.0565\n",
      "Epoch 20/200, Iteration 11/25, Loss: 0.0295\n",
      "Epoch 20/200, Iteration 12/25, Loss: 0.0347\n",
      "Epoch 20/200, Iteration 13/25, Loss: 0.0512\n",
      "Epoch 20/200, Iteration 14/25, Loss: 0.0402\n",
      "Epoch 20/200, Iteration 15/25, Loss: 0.0293\n",
      "Epoch 20/200, Iteration 16/25, Loss: 0.0345\n",
      "Epoch 20/200, Iteration 17/25, Loss: 0.0226\n",
      "Epoch 20/200, Iteration 18/25, Loss: 0.0592\n",
      "Epoch 20/200, Iteration 19/25, Loss: 0.0331\n",
      "Epoch 20/200, Iteration 20/25, Loss: 0.0478\n",
      "Epoch 20/200, Iteration 21/25, Loss: 0.0308\n",
      "Epoch 20/200, Iteration 22/25, Loss: 0.0430\n",
      "Epoch 20/200, Iteration 23/25, Loss: 0.0513\n",
      "Epoch 20/200, Iteration 24/25, Loss: 0.0435\n",
      "Epoch 20/200, Iteration 25/25, Loss: 0.0584\n",
      "Train Error: \n",
      " Accuracy: 50.38%, Avg loss: 0.043673, MRE: 3.090798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.045789, MRE: 9.643832 \n",
      "\n",
      "Epoch 21/200, Iteration 1/25, Loss: 0.0386\n",
      "Epoch 21/200, Iteration 2/25, Loss: 0.0551\n",
      "Epoch 21/200, Iteration 3/25, Loss: 0.0502\n",
      "Epoch 21/200, Iteration 4/25, Loss: 0.0402\n",
      "Epoch 21/200, Iteration 5/25, Loss: 0.0327\n",
      "Epoch 21/200, Iteration 6/25, Loss: 0.0395\n",
      "Epoch 21/200, Iteration 7/25, Loss: 0.0248\n",
      "Epoch 21/200, Iteration 8/25, Loss: 0.0357\n",
      "Epoch 21/200, Iteration 9/25, Loss: 0.0264\n",
      "Epoch 21/200, Iteration 10/25, Loss: 0.0308\n",
      "Epoch 21/200, Iteration 11/25, Loss: 0.0449\n",
      "Epoch 21/200, Iteration 12/25, Loss: 0.0273\n",
      "Epoch 21/200, Iteration 13/25, Loss: 0.0585\n",
      "Epoch 21/200, Iteration 14/25, Loss: 0.0448\n",
      "Epoch 21/200, Iteration 15/25, Loss: 0.0634\n",
      "Epoch 21/200, Iteration 16/25, Loss: 0.0558\n",
      "Epoch 21/200, Iteration 17/25, Loss: 0.0429\n",
      "Epoch 21/200, Iteration 18/25, Loss: 0.0776\n",
      "Epoch 21/200, Iteration 19/25, Loss: 0.0443\n",
      "Epoch 21/200, Iteration 20/25, Loss: 0.0457\n",
      "Epoch 21/200, Iteration 21/25, Loss: 0.0542\n",
      "Epoch 21/200, Iteration 22/25, Loss: 0.0446\n",
      "Epoch 21/200, Iteration 23/25, Loss: 0.0396\n",
      "Epoch 21/200, Iteration 24/25, Loss: 0.0467\n",
      "Epoch 21/200, Iteration 25/25, Loss: 0.0634\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.067329, MRE: 3.543976 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.071344, MRE: 14.799473 \n",
      "\n",
      "Epoch 22/200, Iteration 1/25, Loss: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Iteration 2/25, Loss: 0.0546\n",
      "Epoch 22/200, Iteration 3/25, Loss: 0.0602\n",
      "Epoch 22/200, Iteration 4/25, Loss: 0.0386\n",
      "Epoch 22/200, Iteration 5/25, Loss: 0.0590\n",
      "Epoch 22/200, Iteration 6/25, Loss: 0.0553\n",
      "Epoch 22/200, Iteration 7/25, Loss: 0.0585\n",
      "Epoch 22/200, Iteration 8/25, Loss: 0.0698\n",
      "Epoch 22/200, Iteration 9/25, Loss: 0.0313\n",
      "Epoch 22/200, Iteration 10/25, Loss: 0.0680\n",
      "Epoch 22/200, Iteration 11/25, Loss: 0.0439\n",
      "Epoch 22/200, Iteration 12/25, Loss: 0.0332\n",
      "Epoch 22/200, Iteration 13/25, Loss: 0.0420\n",
      "Epoch 22/200, Iteration 14/25, Loss: 0.0498\n",
      "Epoch 22/200, Iteration 15/25, Loss: 0.0506\n",
      "Epoch 22/200, Iteration 16/25, Loss: 0.0422\n",
      "Epoch 22/200, Iteration 17/25, Loss: 0.0385\n",
      "Epoch 22/200, Iteration 18/25, Loss: 0.0286\n",
      "Epoch 22/200, Iteration 19/25, Loss: 0.0313\n",
      "Epoch 22/200, Iteration 20/25, Loss: 0.0281\n",
      "Epoch 22/200, Iteration 21/25, Loss: 0.0477\n",
      "Epoch 22/200, Iteration 22/25, Loss: 0.0420\n",
      "Epoch 22/200, Iteration 23/25, Loss: 0.0571\n",
      "Epoch 22/200, Iteration 24/25, Loss: 0.0517\n",
      "Epoch 22/200, Iteration 25/25, Loss: 0.0413\n",
      "Train Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.037809, MRE: 1.692597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.040673, MRE: 5.477399 \n",
      "\n",
      "Epoch 23/200, Iteration 1/25, Loss: 0.0316\n",
      "Epoch 23/200, Iteration 2/25, Loss: 0.0290\n",
      "Epoch 23/200, Iteration 3/25, Loss: 0.0395\n",
      "Epoch 23/200, Iteration 4/25, Loss: 0.0389\n",
      "Epoch 23/200, Iteration 5/25, Loss: 0.0395\n",
      "Epoch 23/200, Iteration 6/25, Loss: 0.0328\n",
      "Epoch 23/200, Iteration 7/25, Loss: 0.0584\n",
      "Epoch 23/200, Iteration 8/25, Loss: 0.0465\n",
      "Epoch 23/200, Iteration 9/25, Loss: 0.0707\n",
      "Epoch 23/200, Iteration 10/25, Loss: 0.0509\n",
      "Epoch 23/200, Iteration 11/25, Loss: 0.0372\n",
      "Epoch 23/200, Iteration 12/25, Loss: 0.0264\n",
      "Epoch 23/200, Iteration 13/25, Loss: 0.0561\n",
      "Epoch 23/200, Iteration 14/25, Loss: 0.0623\n",
      "Epoch 23/200, Iteration 15/25, Loss: 0.0512\n",
      "Epoch 23/200, Iteration 16/25, Loss: 0.0474\n",
      "Epoch 23/200, Iteration 17/25, Loss: 0.0650\n",
      "Epoch 23/200, Iteration 18/25, Loss: 0.0746\n",
      "Epoch 23/200, Iteration 19/25, Loss: 0.0387\n",
      "Epoch 23/200, Iteration 20/25, Loss: 0.0741\n",
      "Epoch 23/200, Iteration 21/25, Loss: 0.0663\n",
      "Epoch 23/200, Iteration 22/25, Loss: 0.0792\n",
      "Epoch 23/200, Iteration 23/25, Loss: 0.0762\n",
      "Epoch 23/200, Iteration 24/25, Loss: 0.0758\n",
      "Epoch 23/200, Iteration 25/25, Loss: 0.0569\n",
      "Train Error: \n",
      " Accuracy: 63.75%, Avg loss: 0.041644, MRE: 2.528119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.040990, MRE: 5.075034 \n",
      "\n",
      "Epoch 24/200, Iteration 1/25, Loss: 0.0516\n",
      "Epoch 24/200, Iteration 2/25, Loss: 0.0686\n",
      "Epoch 24/200, Iteration 3/25, Loss: 0.0763\n",
      "Epoch 24/200, Iteration 4/25, Loss: 0.0732\n",
      "Epoch 24/200, Iteration 5/25, Loss: 0.0609\n",
      "Epoch 24/200, Iteration 6/25, Loss: 0.0570\n",
      "Epoch 24/200, Iteration 7/25, Loss: 0.0517\n",
      "Epoch 24/200, Iteration 8/25, Loss: 0.0578\n",
      "Epoch 24/200, Iteration 9/25, Loss: 0.0665\n",
      "Epoch 24/200, Iteration 10/25, Loss: 0.0300\n",
      "Epoch 24/200, Iteration 11/25, Loss: 0.0466\n",
      "Epoch 24/200, Iteration 12/25, Loss: 0.0396\n",
      "Epoch 24/200, Iteration 13/25, Loss: 0.0429\n",
      "Epoch 24/200, Iteration 14/25, Loss: 0.0533\n",
      "Epoch 24/200, Iteration 15/25, Loss: 0.0783\n",
      "Epoch 24/200, Iteration 16/25, Loss: 0.0917\n",
      "Epoch 24/200, Iteration 17/25, Loss: 0.0462\n",
      "Epoch 24/200, Iteration 18/25, Loss: 0.0600\n",
      "Epoch 24/200, Iteration 19/25, Loss: 0.0582\n",
      "Epoch 24/200, Iteration 20/25, Loss: 0.0870\n",
      "Epoch 24/200, Iteration 21/25, Loss: 0.0616\n",
      "Epoch 24/200, Iteration 22/25, Loss: 0.0843\n",
      "Epoch 24/200, Iteration 23/25, Loss: 0.0829\n",
      "Epoch 24/200, Iteration 24/25, Loss: 0.0513\n",
      "Epoch 24/200, Iteration 25/25, Loss: 0.0669\n",
      "Train Error: \n",
      " Accuracy: 40.38%, Avg loss: 0.091170, MRE: 5.811425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.090025, MRE: 10.676485 \n",
      "\n",
      "Epoch 25/200, Iteration 1/25, Loss: 0.0872\n",
      "Epoch 25/200, Iteration 2/25, Loss: 0.0525\n",
      "Epoch 25/200, Iteration 3/25, Loss: 0.0469\n",
      "Epoch 25/200, Iteration 4/25, Loss: 0.0303\n",
      "Epoch 25/200, Iteration 5/25, Loss: 0.0415\n",
      "Epoch 25/200, Iteration 6/25, Loss: 0.0657\n",
      "Epoch 25/200, Iteration 7/25, Loss: 0.0500\n",
      "Epoch 25/200, Iteration 8/25, Loss: 0.0490\n",
      "Epoch 25/200, Iteration 9/25, Loss: 0.0596\n",
      "Epoch 25/200, Iteration 10/25, Loss: 0.0467\n",
      "Epoch 25/200, Iteration 11/25, Loss: 0.0282\n",
      "Epoch 25/200, Iteration 12/25, Loss: 0.0372\n",
      "Epoch 25/200, Iteration 13/25, Loss: 0.0463\n",
      "Epoch 25/200, Iteration 14/25, Loss: 0.0275\n",
      "Epoch 25/200, Iteration 15/25, Loss: 0.0585\n",
      "Epoch 25/200, Iteration 16/25, Loss: 0.0291\n",
      "Epoch 25/200, Iteration 17/25, Loss: 0.0391\n",
      "Epoch 25/200, Iteration 18/25, Loss: 0.0362\n",
      "Epoch 25/200, Iteration 19/25, Loss: 0.0494\n",
      "Epoch 25/200, Iteration 20/25, Loss: 0.0359\n",
      "Epoch 25/200, Iteration 21/25, Loss: 0.0347\n",
      "Epoch 25/200, Iteration 22/25, Loss: 0.0523\n",
      "Epoch 25/200, Iteration 23/25, Loss: 0.0528\n",
      "Epoch 25/200, Iteration 24/25, Loss: 0.0574\n",
      "Epoch 25/200, Iteration 25/25, Loss: 0.0514\n",
      "Train Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.046667, MRE: 3.071271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.050821, MRE: 11.107131 \n",
      "\n",
      "Epoch 26/200, Iteration 1/25, Loss: 0.0408\n",
      "Epoch 26/200, Iteration 2/25, Loss: 0.0435\n",
      "Epoch 26/200, Iteration 3/25, Loss: 0.0366\n",
      "Epoch 26/200, Iteration 4/25, Loss: 0.0319\n",
      "Epoch 26/200, Iteration 5/25, Loss: 0.0499\n",
      "Epoch 26/200, Iteration 6/25, Loss: 0.0284\n",
      "Epoch 26/200, Iteration 7/25, Loss: 0.0389\n",
      "Epoch 26/200, Iteration 8/25, Loss: 0.0287\n",
      "Epoch 26/200, Iteration 9/25, Loss: 0.0486\n",
      "Epoch 26/200, Iteration 10/25, Loss: 0.0320\n",
      "Epoch 26/200, Iteration 11/25, Loss: 0.0501\n",
      "Epoch 26/200, Iteration 12/25, Loss: 0.0506\n",
      "Epoch 26/200, Iteration 13/25, Loss: 0.0514\n",
      "Epoch 26/200, Iteration 14/25, Loss: 0.0456\n",
      "Epoch 26/200, Iteration 15/25, Loss: 0.0310\n",
      "Epoch 26/200, Iteration 16/25, Loss: 0.0371\n",
      "Epoch 26/200, Iteration 17/25, Loss: 0.0495\n",
      "Epoch 26/200, Iteration 18/25, Loss: 0.0409\n",
      "Epoch 26/200, Iteration 19/25, Loss: 0.0371\n",
      "Epoch 26/200, Iteration 20/25, Loss: 0.0484\n",
      "Epoch 26/200, Iteration 21/25, Loss: 0.0404\n",
      "Epoch 26/200, Iteration 22/25, Loss: 0.0542\n",
      "Epoch 26/200, Iteration 23/25, Loss: 0.0757\n",
      "Epoch 26/200, Iteration 24/25, Loss: 0.0749\n",
      "Epoch 26/200, Iteration 25/25, Loss: 0.0870\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.044016, MRE: 2.409455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.045811, MRE: 6.697483 \n",
      "\n",
      "Epoch 27/200, Iteration 1/25, Loss: 0.0492\n",
      "Epoch 27/200, Iteration 2/25, Loss: 0.0512\n",
      "Epoch 27/200, Iteration 3/25, Loss: 0.0314\n",
      "Epoch 27/200, Iteration 4/25, Loss: 0.0657\n",
      "Epoch 27/200, Iteration 5/25, Loss: 0.0539\n",
      "Epoch 27/200, Iteration 6/25, Loss: 0.0664\n",
      "Epoch 27/200, Iteration 7/25, Loss: 0.0687\n",
      "Epoch 27/200, Iteration 8/25, Loss: 0.0557\n",
      "Epoch 27/200, Iteration 9/25, Loss: 0.0852\n",
      "Epoch 27/200, Iteration 10/25, Loss: 0.0618\n",
      "Epoch 27/200, Iteration 11/25, Loss: 0.0547\n",
      "Epoch 27/200, Iteration 12/25, Loss: 0.0933\n",
      "Epoch 27/200, Iteration 13/25, Loss: 0.0633\n",
      "Epoch 27/200, Iteration 14/25, Loss: 0.0316\n",
      "Epoch 27/200, Iteration 15/25, Loss: 0.0460\n",
      "Epoch 27/200, Iteration 16/25, Loss: 0.0467\n",
      "Epoch 27/200, Iteration 17/25, Loss: 0.0516\n",
      "Epoch 27/200, Iteration 18/25, Loss: 0.0503\n",
      "Epoch 27/200, Iteration 19/25, Loss: 0.0547\n",
      "Epoch 27/200, Iteration 20/25, Loss: 0.0747\n",
      "Epoch 27/200, Iteration 21/25, Loss: 0.0571\n",
      "Epoch 27/200, Iteration 22/25, Loss: 0.0522\n",
      "Epoch 27/200, Iteration 23/25, Loss: 0.0494\n",
      "Epoch 27/200, Iteration 24/25, Loss: 0.0584\n",
      "Epoch 27/200, Iteration 25/25, Loss: 0.0654\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.062535, MRE: 3.327973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.062688, MRE: 8.775794 \n",
      "\n",
      "Epoch 28/200, Iteration 1/25, Loss: 0.0718\n",
      "Epoch 28/200, Iteration 2/25, Loss: 0.0349\n",
      "Epoch 28/200, Iteration 3/25, Loss: 0.0605\n",
      "Epoch 28/200, Iteration 4/25, Loss: 0.0528\n",
      "Epoch 28/200, Iteration 5/25, Loss: 0.0334\n",
      "Epoch 28/200, Iteration 6/25, Loss: 0.0380\n",
      "Epoch 28/200, Iteration 7/25, Loss: 0.0651\n",
      "Epoch 28/200, Iteration 8/25, Loss: 0.0659\n",
      "Epoch 28/200, Iteration 9/25, Loss: 0.0673\n",
      "Epoch 28/200, Iteration 10/25, Loss: 0.0543\n",
      "Epoch 28/200, Iteration 11/25, Loss: 0.0978\n",
      "Epoch 28/200, Iteration 12/25, Loss: 0.0734\n",
      "Epoch 28/200, Iteration 13/25, Loss: 0.0614\n",
      "Epoch 28/200, Iteration 14/25, Loss: 0.0558\n",
      "Epoch 28/200, Iteration 15/25, Loss: 0.0627\n",
      "Epoch 28/200, Iteration 16/25, Loss: 0.0665\n",
      "Epoch 28/200, Iteration 17/25, Loss: 0.0254\n",
      "Epoch 28/200, Iteration 18/25, Loss: 0.0478\n",
      "Epoch 28/200, Iteration 19/25, Loss: 0.0331\n",
      "Epoch 28/200, Iteration 20/25, Loss: 0.0497\n",
      "Epoch 28/200, Iteration 21/25, Loss: 0.0446\n",
      "Epoch 28/200, Iteration 22/25, Loss: 0.0405\n",
      "Epoch 28/200, Iteration 23/25, Loss: 0.0542\n",
      "Epoch 28/200, Iteration 24/25, Loss: 0.0588\n",
      "Epoch 28/200, Iteration 25/25, Loss: 0.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.105057, MRE: 7.096058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.100471, MRE: 25.006212 \n",
      "\n",
      "Epoch 29/200, Iteration 1/25, Loss: 0.0916\n",
      "Epoch 29/200, Iteration 2/25, Loss: 0.0781\n",
      "Epoch 29/200, Iteration 3/25, Loss: 0.1209\n",
      "Epoch 29/200, Iteration 4/25, Loss: 0.1006\n",
      "Epoch 29/200, Iteration 5/25, Loss: 0.0569\n",
      "Epoch 29/200, Iteration 6/25, Loss: 0.1286\n",
      "Epoch 29/200, Iteration 7/25, Loss: 0.0738\n",
      "Epoch 29/200, Iteration 8/25, Loss: 0.0830\n",
      "Epoch 29/200, Iteration 9/25, Loss: 0.0873\n",
      "Epoch 29/200, Iteration 10/25, Loss: 0.0681\n",
      "Epoch 29/200, Iteration 11/25, Loss: 0.0410\n",
      "Epoch 29/200, Iteration 12/25, Loss: 0.0757\n",
      "Epoch 29/200, Iteration 13/25, Loss: 0.0904\n",
      "Epoch 29/200, Iteration 14/25, Loss: 0.0517\n",
      "Epoch 29/200, Iteration 15/25, Loss: 0.0324\n",
      "Epoch 29/200, Iteration 16/25, Loss: 0.0543\n",
      "Epoch 29/200, Iteration 17/25, Loss: 0.0473\n",
      "Epoch 29/200, Iteration 18/25, Loss: 0.0281\n",
      "Epoch 29/200, Iteration 19/25, Loss: 0.0644\n",
      "Epoch 29/200, Iteration 20/25, Loss: 0.0642\n",
      "Epoch 29/200, Iteration 21/25, Loss: 0.0629\n",
      "Epoch 29/200, Iteration 22/25, Loss: 0.0894\n",
      "Epoch 29/200, Iteration 23/25, Loss: 0.0507\n",
      "Epoch 29/200, Iteration 24/25, Loss: 0.0557\n",
      "Epoch 29/200, Iteration 25/25, Loss: 0.1085\n",
      "Train Error: \n",
      " Accuracy: 54.25%, Avg loss: 0.060081, MRE: 3.673473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.063123, MRE: 8.695742 \n",
      "\n",
      "Epoch 30/200, Iteration 1/25, Loss: 0.0628\n",
      "Epoch 30/200, Iteration 2/25, Loss: 0.0436\n",
      "Epoch 30/200, Iteration 3/25, Loss: 0.0542\n",
      "Epoch 30/200, Iteration 4/25, Loss: 0.0380\n",
      "Epoch 30/200, Iteration 5/25, Loss: 0.0542\n",
      "Epoch 30/200, Iteration 6/25, Loss: 0.0511\n",
      "Epoch 30/200, Iteration 7/25, Loss: 0.0586\n",
      "Epoch 30/200, Iteration 8/25, Loss: 0.0496\n",
      "Epoch 30/200, Iteration 9/25, Loss: 0.0841\n",
      "Epoch 30/200, Iteration 10/25, Loss: 0.0562\n",
      "Epoch 30/200, Iteration 11/25, Loss: 0.0523\n",
      "Epoch 30/200, Iteration 12/25, Loss: 0.0670\n",
      "Epoch 30/200, Iteration 13/25, Loss: 0.0690\n",
      "Epoch 30/200, Iteration 14/25, Loss: 0.0894\n",
      "Epoch 30/200, Iteration 15/25, Loss: 0.1042\n",
      "Epoch 30/200, Iteration 16/25, Loss: 0.0848\n",
      "Epoch 30/200, Iteration 17/25, Loss: 0.0883\n",
      "Epoch 30/200, Iteration 18/25, Loss: 0.0785\n",
      "Epoch 30/200, Iteration 19/25, Loss: 0.0618\n",
      "Epoch 30/200, Iteration 20/25, Loss: 0.0500\n",
      "Epoch 30/200, Iteration 21/25, Loss: 0.0573\n",
      "Epoch 30/200, Iteration 22/25, Loss: 0.0527\n",
      "Epoch 30/200, Iteration 23/25, Loss: 0.0414\n",
      "Epoch 30/200, Iteration 24/25, Loss: 0.0612\n",
      "Epoch 30/200, Iteration 25/25, Loss: 0.0557\n",
      "Train Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.044463, MRE: 3.187849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.044791, MRE: 13.763817 \n",
      "\n",
      "Epoch 31/200, Iteration 1/25, Loss: 0.0376\n",
      "Epoch 31/200, Iteration 2/25, Loss: 0.0408\n",
      "Epoch 31/200, Iteration 3/25, Loss: 0.0275\n",
      "Epoch 31/200, Iteration 4/25, Loss: 0.0288\n",
      "Epoch 31/200, Iteration 5/25, Loss: 0.0307\n",
      "Epoch 31/200, Iteration 6/25, Loss: 0.0303\n",
      "Epoch 31/200, Iteration 7/25, Loss: 0.0337\n",
      "Epoch 31/200, Iteration 8/25, Loss: 0.0347\n",
      "Epoch 31/200, Iteration 9/25, Loss: 0.0227\n",
      "Epoch 31/200, Iteration 10/25, Loss: 0.0405\n",
      "Epoch 31/200, Iteration 11/25, Loss: 0.0316\n",
      "Epoch 31/200, Iteration 12/25, Loss: 0.0380\n",
      "Epoch 31/200, Iteration 13/25, Loss: 0.0294\n",
      "Epoch 31/200, Iteration 14/25, Loss: 0.0277\n",
      "Epoch 31/200, Iteration 15/25, Loss: 0.0232\n",
      "Epoch 31/200, Iteration 16/25, Loss: 0.0222\n",
      "Epoch 31/200, Iteration 17/25, Loss: 0.0235\n",
      "Epoch 31/200, Iteration 18/25, Loss: 0.0288\n",
      "Epoch 31/200, Iteration 19/25, Loss: 0.0513\n",
      "Epoch 31/200, Iteration 20/25, Loss: 0.0325\n",
      "Epoch 31/200, Iteration 21/25, Loss: 0.0272\n",
      "Epoch 31/200, Iteration 22/25, Loss: 0.0376\n",
      "Epoch 31/200, Iteration 23/25, Loss: 0.0254\n",
      "Epoch 31/200, Iteration 24/25, Loss: 0.0214\n",
      "Epoch 31/200, Iteration 25/25, Loss: 0.0212\n",
      "Train Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.020661, MRE: 1.499317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.023440, MRE: 3.652174 \n",
      "\n",
      "Epoch 32/200, Iteration 1/25, Loss: 0.0222\n",
      "Epoch 32/200, Iteration 2/25, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 3/25, Loss: 0.0286\n",
      "Epoch 32/200, Iteration 4/25, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 5/25, Loss: 0.0346\n",
      "Epoch 32/200, Iteration 6/25, Loss: 0.0197\n",
      "Epoch 32/200, Iteration 7/25, Loss: 0.0279\n",
      "Epoch 32/200, Iteration 8/25, Loss: 0.0359\n",
      "Epoch 32/200, Iteration 9/25, Loss: 0.0171\n",
      "Epoch 32/200, Iteration 10/25, Loss: 0.0166\n",
      "Epoch 32/200, Iteration 11/25, Loss: 0.0213\n",
      "Epoch 32/200, Iteration 12/25, Loss: 0.0412\n",
      "Epoch 32/200, Iteration 13/25, Loss: 0.0362\n",
      "Epoch 32/200, Iteration 14/25, Loss: 0.0318\n",
      "Epoch 32/200, Iteration 15/25, Loss: 0.0124\n",
      "Epoch 32/200, Iteration 16/25, Loss: 0.0250\n",
      "Epoch 32/200, Iteration 17/25, Loss: 0.0173\n",
      "Epoch 32/200, Iteration 18/25, Loss: 0.0280\n",
      "Epoch 32/200, Iteration 19/25, Loss: 0.0257\n",
      "Epoch 32/200, Iteration 20/25, Loss: 0.0262\n",
      "Epoch 32/200, Iteration 21/25, Loss: 0.0265\n",
      "Epoch 32/200, Iteration 22/25, Loss: 0.0398\n",
      "Epoch 32/200, Iteration 23/25, Loss: 0.0250\n",
      "Epoch 32/200, Iteration 24/25, Loss: 0.0158\n",
      "Epoch 32/200, Iteration 25/25, Loss: 0.0379\n",
      "Train Error: \n",
      " Accuracy: 70.75%, Avg loss: 0.016971, MRE: 1.055898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.019412, MRE: 3.481724 \n",
      "\n",
      "Epoch 33/200, Iteration 1/25, Loss: 0.0311\n",
      "Epoch 33/200, Iteration 2/25, Loss: 0.0276\n",
      "Epoch 33/200, Iteration 3/25, Loss: 0.0247\n",
      "Epoch 33/200, Iteration 4/25, Loss: 0.0377\n",
      "Epoch 33/200, Iteration 5/25, Loss: 0.0191\n",
      "Epoch 33/200, Iteration 6/25, Loss: 0.0228\n",
      "Epoch 33/200, Iteration 7/25, Loss: 0.0229\n",
      "Epoch 33/200, Iteration 8/25, Loss: 0.0203\n",
      "Epoch 33/200, Iteration 9/25, Loss: 0.0166\n",
      "Epoch 33/200, Iteration 10/25, Loss: 0.0250\n",
      "Epoch 33/200, Iteration 11/25, Loss: 0.0233\n",
      "Epoch 33/200, Iteration 12/25, Loss: 0.0237\n",
      "Epoch 33/200, Iteration 13/25, Loss: 0.0201\n",
      "Epoch 33/200, Iteration 14/25, Loss: 0.0239\n",
      "Epoch 33/200, Iteration 15/25, Loss: 0.0212\n",
      "Epoch 33/200, Iteration 16/25, Loss: 0.0305\n",
      "Epoch 33/200, Iteration 17/25, Loss: 0.0190\n",
      "Epoch 33/200, Iteration 18/25, Loss: 0.0218\n",
      "Epoch 33/200, Iteration 19/25, Loss: 0.0261\n",
      "Epoch 33/200, Iteration 20/25, Loss: 0.0229\n",
      "Epoch 33/200, Iteration 21/25, Loss: 0.0186\n",
      "Epoch 33/200, Iteration 22/25, Loss: 0.0466\n",
      "Epoch 33/200, Iteration 23/25, Loss: 0.0232\n",
      "Epoch 33/200, Iteration 24/25, Loss: 0.0193\n",
      "Epoch 33/200, Iteration 25/25, Loss: 0.0231\n",
      "Train Error: \n",
      " Accuracy: 75.38%, Avg loss: 0.017342, MRE: 1.205088 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.021512, MRE: 3.659666 \n",
      "\n",
      "Epoch 34/200, Iteration 1/25, Loss: 0.0185\n",
      "Epoch 34/200, Iteration 2/25, Loss: 0.0197\n",
      "Epoch 34/200, Iteration 3/25, Loss: 0.0326\n",
      "Epoch 34/200, Iteration 4/25, Loss: 0.0202\n",
      "Epoch 34/200, Iteration 5/25, Loss: 0.0235\n",
      "Epoch 34/200, Iteration 6/25, Loss: 0.0170\n",
      "Epoch 34/200, Iteration 7/25, Loss: 0.0248\n",
      "Epoch 34/200, Iteration 8/25, Loss: 0.0238\n",
      "Epoch 34/200, Iteration 9/25, Loss: 0.0243\n",
      "Epoch 34/200, Iteration 10/25, Loss: 0.0153\n",
      "Epoch 34/200, Iteration 11/25, Loss: 0.0575\n",
      "Epoch 34/200, Iteration 12/25, Loss: 0.0418\n",
      "Epoch 34/200, Iteration 13/25, Loss: 0.0286\n",
      "Epoch 34/200, Iteration 14/25, Loss: 0.0388\n",
      "Epoch 34/200, Iteration 15/25, Loss: 0.0378\n",
      "Epoch 34/200, Iteration 16/25, Loss: 0.0275\n",
      "Epoch 34/200, Iteration 17/25, Loss: 0.0340\n",
      "Epoch 34/200, Iteration 18/25, Loss: 0.0248\n",
      "Epoch 34/200, Iteration 19/25, Loss: 0.0379\n",
      "Epoch 34/200, Iteration 20/25, Loss: 0.0319\n",
      "Epoch 34/200, Iteration 21/25, Loss: 0.0190\n",
      "Epoch 34/200, Iteration 22/25, Loss: 0.0180\n",
      "Epoch 34/200, Iteration 23/25, Loss: 0.0193\n",
      "Epoch 34/200, Iteration 24/25, Loss: 0.0388\n",
      "Epoch 34/200, Iteration 25/25, Loss: 0.0234\n",
      "Train Error: \n",
      " Accuracy: 68.38%, Avg loss: 0.022984, MRE: 1.041482 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.027902, MRE: 1.911752 \n",
      "\n",
      "Epoch 35/200, Iteration 1/25, Loss: 0.0298\n",
      "Epoch 35/200, Iteration 2/25, Loss: 0.0264\n",
      "Epoch 35/200, Iteration 3/25, Loss: 0.0223\n",
      "Epoch 35/200, Iteration 4/25, Loss: 0.0300\n",
      "Epoch 35/200, Iteration 5/25, Loss: 0.0213\n",
      "Epoch 35/200, Iteration 6/25, Loss: 0.0237\n",
      "Epoch 35/200, Iteration 7/25, Loss: 0.0311\n",
      "Epoch 35/200, Iteration 8/25, Loss: 0.0356\n",
      "Epoch 35/200, Iteration 9/25, Loss: 0.0263\n",
      "Epoch 35/200, Iteration 10/25, Loss: 0.0299\n",
      "Epoch 35/200, Iteration 11/25, Loss: 0.0199\n",
      "Epoch 35/200, Iteration 12/25, Loss: 0.0282\n",
      "Epoch 35/200, Iteration 13/25, Loss: 0.0316\n",
      "Epoch 35/200, Iteration 14/25, Loss: 0.0438\n",
      "Epoch 35/200, Iteration 15/25, Loss: 0.0465\n",
      "Epoch 35/200, Iteration 16/25, Loss: 0.0240\n",
      "Epoch 35/200, Iteration 17/25, Loss: 0.0155\n",
      "Epoch 35/200, Iteration 18/25, Loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Iteration 19/25, Loss: 0.0273\n",
      "Epoch 35/200, Iteration 20/25, Loss: 0.0208\n",
      "Epoch 35/200, Iteration 21/25, Loss: 0.0184\n",
      "Epoch 35/200, Iteration 22/25, Loss: 0.0158\n",
      "Epoch 35/200, Iteration 23/25, Loss: 0.0174\n",
      "Epoch 35/200, Iteration 24/25, Loss: 0.0218\n",
      "Epoch 35/200, Iteration 25/25, Loss: 0.0254\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.015499, MRE: 1.013561 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.017688, MRE: 3.070484 \n",
      "\n",
      "Epoch 36/200, Iteration 1/25, Loss: 0.0184\n",
      "Epoch 36/200, Iteration 2/25, Loss: 0.0154\n",
      "Epoch 36/200, Iteration 3/25, Loss: 0.0260\n",
      "Epoch 36/200, Iteration 4/25, Loss: 0.0198\n",
      "Epoch 36/200, Iteration 5/25, Loss: 0.0226\n",
      "Epoch 36/200, Iteration 6/25, Loss: 0.0484\n",
      "Epoch 36/200, Iteration 7/25, Loss: 0.0199\n",
      "Epoch 36/200, Iteration 8/25, Loss: 0.0199\n",
      "Epoch 36/200, Iteration 9/25, Loss: 0.0170\n",
      "Epoch 36/200, Iteration 10/25, Loss: 0.0288\n",
      "Epoch 36/200, Iteration 11/25, Loss: 0.0187\n",
      "Epoch 36/200, Iteration 12/25, Loss: 0.0219\n",
      "Epoch 36/200, Iteration 13/25, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 14/25, Loss: 0.0252\n",
      "Epoch 36/200, Iteration 15/25, Loss: 0.0199\n",
      "Epoch 36/200, Iteration 16/25, Loss: 0.0177\n",
      "Epoch 36/200, Iteration 17/25, Loss: 0.0182\n",
      "Epoch 36/200, Iteration 18/25, Loss: 0.0233\n",
      "Epoch 36/200, Iteration 19/25, Loss: 0.0355\n",
      "Epoch 36/200, Iteration 20/25, Loss: 0.0211\n",
      "Epoch 36/200, Iteration 21/25, Loss: 0.0285\n",
      "Epoch 36/200, Iteration 22/25, Loss: 0.0249\n",
      "Epoch 36/200, Iteration 23/25, Loss: 0.0199\n",
      "Epoch 36/200, Iteration 24/25, Loss: 0.0197\n",
      "Epoch 36/200, Iteration 25/25, Loss: 0.0274\n",
      "Train Error: \n",
      " Accuracy: 71.12%, Avg loss: 0.016047, MRE: 0.986230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.019763, MRE: 2.794908 \n",
      "\n",
      "Epoch 37/200, Iteration 1/25, Loss: 0.0170\n",
      "Epoch 37/200, Iteration 2/25, Loss: 0.0181\n",
      "Epoch 37/200, Iteration 3/25, Loss: 0.0227\n",
      "Epoch 37/200, Iteration 4/25, Loss: 0.0183\n",
      "Epoch 37/200, Iteration 5/25, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 6/25, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 7/25, Loss: 0.0147\n",
      "Epoch 37/200, Iteration 8/25, Loss: 0.0209\n",
      "Epoch 37/200, Iteration 9/25, Loss: 0.0412\n",
      "Epoch 37/200, Iteration 10/25, Loss: 0.0192\n",
      "Epoch 37/200, Iteration 11/25, Loss: 0.0128\n",
      "Epoch 37/200, Iteration 12/25, Loss: 0.0302\n",
      "Epoch 37/200, Iteration 13/25, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 14/25, Loss: 0.0181\n",
      "Epoch 37/200, Iteration 15/25, Loss: 0.0238\n",
      "Epoch 37/200, Iteration 16/25, Loss: 0.0173\n",
      "Epoch 37/200, Iteration 17/25, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 18/25, Loss: 0.0310\n",
      "Epoch 37/200, Iteration 19/25, Loss: 0.0258\n",
      "Epoch 37/200, Iteration 20/25, Loss: 0.0426\n",
      "Epoch 37/200, Iteration 21/25, Loss: 0.0208\n",
      "Epoch 37/200, Iteration 22/25, Loss: 0.0407\n",
      "Epoch 37/200, Iteration 23/25, Loss: 0.0223\n",
      "Epoch 37/200, Iteration 24/25, Loss: 0.0253\n",
      "Epoch 37/200, Iteration 25/25, Loss: 0.0280\n",
      "Train Error: \n",
      " Accuracy: 68.38%, Avg loss: 0.021077, MRE: 1.020116 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.024916, MRE: 2.009891 \n",
      "\n",
      "Epoch 38/200, Iteration 1/25, Loss: 0.0193\n",
      "Epoch 38/200, Iteration 2/25, Loss: 0.0248\n",
      "Epoch 38/200, Iteration 3/25, Loss: 0.0256\n",
      "Epoch 38/200, Iteration 4/25, Loss: 0.0217\n",
      "Epoch 38/200, Iteration 5/25, Loss: 0.0259\n",
      "Epoch 38/200, Iteration 6/25, Loss: 0.0190\n",
      "Epoch 38/200, Iteration 7/25, Loss: 0.0296\n",
      "Epoch 38/200, Iteration 8/25, Loss: 0.0263\n",
      "Epoch 38/200, Iteration 9/25, Loss: 0.0220\n",
      "Epoch 38/200, Iteration 10/25, Loss: 0.0180\n",
      "Epoch 38/200, Iteration 11/25, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 12/25, Loss: 0.0240\n",
      "Epoch 38/200, Iteration 13/25, Loss: 0.0263\n",
      "Epoch 38/200, Iteration 14/25, Loss: 0.0282\n",
      "Epoch 38/200, Iteration 15/25, Loss: 0.0207\n",
      "Epoch 38/200, Iteration 16/25, Loss: 0.0238\n",
      "Epoch 38/200, Iteration 17/25, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 18/25, Loss: 0.0241\n",
      "Epoch 38/200, Iteration 19/25, Loss: 0.0330\n",
      "Epoch 38/200, Iteration 20/25, Loss: 0.0266\n",
      "Epoch 38/200, Iteration 21/25, Loss: 0.0268\n",
      "Epoch 38/200, Iteration 22/25, Loss: 0.0190\n",
      "Epoch 38/200, Iteration 23/25, Loss: 0.0165\n",
      "Epoch 38/200, Iteration 24/25, Loss: 0.0275\n",
      "Epoch 38/200, Iteration 25/25, Loss: 0.0198\n",
      "Train Error: \n",
      " Accuracy: 61.25%, Avg loss: 0.017941, MRE: 1.074407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.022231, MRE: 2.046906 \n",
      "\n",
      "Epoch 39/200, Iteration 1/25, Loss: 0.0191\n",
      "Epoch 39/200, Iteration 2/25, Loss: 0.0166\n",
      "Epoch 39/200, Iteration 3/25, Loss: 0.0146\n",
      "Epoch 39/200, Iteration 4/25, Loss: 0.0170\n",
      "Epoch 39/200, Iteration 5/25, Loss: 0.0345\n",
      "Epoch 39/200, Iteration 6/25, Loss: 0.0183\n",
      "Epoch 39/200, Iteration 7/25, Loss: 0.0206\n",
      "Epoch 39/200, Iteration 8/25, Loss: 0.0131\n",
      "Epoch 39/200, Iteration 9/25, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 10/25, Loss: 0.0169\n",
      "Epoch 39/200, Iteration 11/25, Loss: 0.0188\n",
      "Epoch 39/200, Iteration 12/25, Loss: 0.0198\n",
      "Epoch 39/200, Iteration 13/25, Loss: 0.0224\n",
      "Epoch 39/200, Iteration 14/25, Loss: 0.0188\n",
      "Epoch 39/200, Iteration 15/25, Loss: 0.0191\n",
      "Epoch 39/200, Iteration 16/25, Loss: 0.0281\n",
      "Epoch 39/200, Iteration 17/25, Loss: 0.0150\n",
      "Epoch 39/200, Iteration 18/25, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 19/25, Loss: 0.0261\n",
      "Epoch 39/200, Iteration 20/25, Loss: 0.0313\n",
      "Epoch 39/200, Iteration 21/25, Loss: 0.0141\n",
      "Epoch 39/200, Iteration 22/25, Loss: 0.0260\n",
      "Epoch 39/200, Iteration 23/25, Loss: 0.0275\n",
      "Epoch 39/200, Iteration 24/25, Loss: 0.0301\n",
      "Epoch 39/200, Iteration 25/25, Loss: 0.0164\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.016944, MRE: 0.720288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.019532, MRE: 2.318088 \n",
      "\n",
      "Epoch 40/200, Iteration 1/25, Loss: 0.0192\n",
      "Epoch 40/200, Iteration 2/25, Loss: 0.0139\n",
      "Epoch 40/200, Iteration 3/25, Loss: 0.0226\n",
      "Epoch 40/200, Iteration 4/25, Loss: 0.0262\n",
      "Epoch 40/200, Iteration 5/25, Loss: 0.0204\n",
      "Epoch 40/200, Iteration 6/25, Loss: 0.0312\n",
      "Epoch 40/200, Iteration 7/25, Loss: 0.0208\n",
      "Epoch 40/200, Iteration 8/25, Loss: 0.0182\n",
      "Epoch 40/200, Iteration 9/25, Loss: 0.0191\n",
      "Epoch 40/200, Iteration 10/25, Loss: 0.0218\n",
      "Epoch 40/200, Iteration 11/25, Loss: 0.0415\n",
      "Epoch 40/200, Iteration 12/25, Loss: 0.0318\n",
      "Epoch 40/200, Iteration 13/25, Loss: 0.0337\n",
      "Epoch 40/200, Iteration 14/25, Loss: 0.0303\n",
      "Epoch 40/200, Iteration 15/25, Loss: 0.0244\n",
      "Epoch 40/200, Iteration 16/25, Loss: 0.0273\n",
      "Epoch 40/200, Iteration 17/25, Loss: 0.0303\n",
      "Epoch 40/200, Iteration 18/25, Loss: 0.0382\n",
      "Epoch 40/200, Iteration 19/25, Loss: 0.0249\n",
      "Epoch 40/200, Iteration 20/25, Loss: 0.0342\n",
      "Epoch 40/200, Iteration 21/25, Loss: 0.0214\n",
      "Epoch 40/200, Iteration 22/25, Loss: 0.0417\n",
      "Epoch 40/200, Iteration 23/25, Loss: 0.0261\n",
      "Epoch 40/200, Iteration 24/25, Loss: 0.0212\n",
      "Epoch 40/200, Iteration 25/25, Loss: 0.0197\n",
      "Train Error: \n",
      " Accuracy: 68.75%, Avg loss: 0.015304, MRE: 0.919962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.017894, MRE: 2.441388 \n",
      "\n",
      "Epoch 41/200, Iteration 1/25, Loss: 0.0219\n",
      "Epoch 41/200, Iteration 2/25, Loss: 0.0143\n",
      "Epoch 41/200, Iteration 3/25, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 4/25, Loss: 0.0113\n",
      "Epoch 41/200, Iteration 5/25, Loss: 0.0181\n",
      "Epoch 41/200, Iteration 6/25, Loss: 0.0151\n",
      "Epoch 41/200, Iteration 7/25, Loss: 0.0187\n",
      "Epoch 41/200, Iteration 8/25, Loss: 0.0136\n",
      "Epoch 41/200, Iteration 9/25, Loss: 0.0179\n",
      "Epoch 41/200, Iteration 10/25, Loss: 0.0191\n",
      "Epoch 41/200, Iteration 11/25, Loss: 0.0206\n",
      "Epoch 41/200, Iteration 12/25, Loss: 0.0218\n",
      "Epoch 41/200, Iteration 13/25, Loss: 0.0203\n",
      "Epoch 41/200, Iteration 14/25, Loss: 0.0228\n",
      "Epoch 41/200, Iteration 15/25, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 16/25, Loss: 0.0176\n",
      "Epoch 41/200, Iteration 17/25, Loss: 0.0267\n",
      "Epoch 41/200, Iteration 18/25, Loss: 0.0218\n",
      "Epoch 41/200, Iteration 19/25, Loss: 0.0187\n",
      "Epoch 41/200, Iteration 20/25, Loss: 0.0186\n",
      "Epoch 41/200, Iteration 21/25, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 22/25, Loss: 0.0332\n",
      "Epoch 41/200, Iteration 23/25, Loss: 0.0166\n",
      "Epoch 41/200, Iteration 24/25, Loss: 0.0258\n",
      "Epoch 41/200, Iteration 25/25, Loss: 0.0204\n",
      "Train Error: \n",
      " Accuracy: 77.62%, Avg loss: 0.016671, MRE: 0.718564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.020158, MRE: 2.067874 \n",
      "\n",
      "Epoch 42/200, Iteration 1/25, Loss: 0.0206\n",
      "Epoch 42/200, Iteration 2/25, Loss: 0.0200\n",
      "Epoch 42/200, Iteration 3/25, Loss: 0.0207\n",
      "Epoch 42/200, Iteration 4/25, Loss: 0.0265\n",
      "Epoch 42/200, Iteration 5/25, Loss: 0.0154\n",
      "Epoch 42/200, Iteration 6/25, Loss: 0.0206\n",
      "Epoch 42/200, Iteration 7/25, Loss: 0.0276\n",
      "Epoch 42/200, Iteration 8/25, Loss: 0.0249\n",
      "Epoch 42/200, Iteration 9/25, Loss: 0.0126\n",
      "Epoch 42/200, Iteration 10/25, Loss: 0.0171\n",
      "Epoch 42/200, Iteration 11/25, Loss: 0.0382\n",
      "Epoch 42/200, Iteration 12/25, Loss: 0.0263\n",
      "Epoch 42/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 42/200, Iteration 14/25, Loss: 0.0255\n",
      "Epoch 42/200, Iteration 15/25, Loss: 0.0132\n",
      "Epoch 42/200, Iteration 16/25, Loss: 0.0152\n",
      "Epoch 42/200, Iteration 17/25, Loss: 0.0138\n",
      "Epoch 42/200, Iteration 18/25, Loss: 0.0271\n",
      "Epoch 42/200, Iteration 19/25, Loss: 0.0252\n",
      "Epoch 42/200, Iteration 20/25, Loss: 0.0328\n",
      "Epoch 42/200, Iteration 21/25, Loss: 0.0371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Iteration 22/25, Loss: 0.0290\n",
      "Epoch 42/200, Iteration 23/25, Loss: 0.0224\n",
      "Epoch 42/200, Iteration 24/25, Loss: 0.0282\n",
      "Epoch 42/200, Iteration 25/25, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 73.38%, Avg loss: 0.013036, MRE: 0.777681 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.016525, MRE: 1.731903 \n",
      "\n",
      "Epoch 43/200, Iteration 1/25, Loss: 0.0312\n",
      "Epoch 43/200, Iteration 2/25, Loss: 0.0182\n",
      "Epoch 43/200, Iteration 3/25, Loss: 0.0281\n",
      "Epoch 43/200, Iteration 4/25, Loss: 0.0268\n",
      "Epoch 43/200, Iteration 5/25, Loss: 0.0215\n",
      "Epoch 43/200, Iteration 6/25, Loss: 0.0112\n",
      "Epoch 43/200, Iteration 7/25, Loss: 0.0232\n",
      "Epoch 43/200, Iteration 8/25, Loss: 0.0194\n",
      "Epoch 43/200, Iteration 9/25, Loss: 0.0217\n",
      "Epoch 43/200, Iteration 10/25, Loss: 0.0287\n",
      "Epoch 43/200, Iteration 11/25, Loss: 0.0285\n",
      "Epoch 43/200, Iteration 12/25, Loss: 0.0140\n",
      "Epoch 43/200, Iteration 13/25, Loss: 0.0333\n",
      "Epoch 43/200, Iteration 14/25, Loss: 0.0397\n",
      "Epoch 43/200, Iteration 15/25, Loss: 0.0286\n",
      "Epoch 43/200, Iteration 16/25, Loss: 0.0292\n",
      "Epoch 43/200, Iteration 17/25, Loss: 0.0151\n",
      "Epoch 43/200, Iteration 18/25, Loss: 0.0144\n",
      "Epoch 43/200, Iteration 19/25, Loss: 0.0248\n",
      "Epoch 43/200, Iteration 20/25, Loss: 0.0234\n",
      "Epoch 43/200, Iteration 21/25, Loss: 0.0282\n",
      "Epoch 43/200, Iteration 22/25, Loss: 0.0197\n",
      "Epoch 43/200, Iteration 23/25, Loss: 0.0176\n",
      "Epoch 43/200, Iteration 24/25, Loss: 0.0280\n",
      "Epoch 43/200, Iteration 25/25, Loss: 0.0308\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.022595, MRE: 1.547793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.025591, MRE: 2.630866 \n",
      "\n",
      "Epoch 44/200, Iteration 1/25, Loss: 0.0253\n",
      "Epoch 44/200, Iteration 2/25, Loss: 0.0211\n",
      "Epoch 44/200, Iteration 3/25, Loss: 0.0175\n",
      "Epoch 44/200, Iteration 4/25, Loss: 0.0291\n",
      "Epoch 44/200, Iteration 5/25, Loss: 0.0212\n",
      "Epoch 44/200, Iteration 6/25, Loss: 0.0275\n",
      "Epoch 44/200, Iteration 7/25, Loss: 0.0351\n",
      "Epoch 44/200, Iteration 8/25, Loss: 0.0205\n",
      "Epoch 44/200, Iteration 9/25, Loss: 0.0161\n",
      "Epoch 44/200, Iteration 10/25, Loss: 0.0225\n",
      "Epoch 44/200, Iteration 11/25, Loss: 0.0148\n",
      "Epoch 44/200, Iteration 12/25, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 13/25, Loss: 0.0505\n",
      "Epoch 44/200, Iteration 14/25, Loss: 0.0244\n",
      "Epoch 44/200, Iteration 15/25, Loss: 0.0318\n",
      "Epoch 44/200, Iteration 16/25, Loss: 0.0346\n",
      "Epoch 44/200, Iteration 17/25, Loss: 0.0225\n",
      "Epoch 44/200, Iteration 18/25, Loss: 0.0184\n",
      "Epoch 44/200, Iteration 19/25, Loss: 0.0235\n",
      "Epoch 44/200, Iteration 20/25, Loss: 0.0168\n",
      "Epoch 44/200, Iteration 21/25, Loss: 0.0219\n",
      "Epoch 44/200, Iteration 22/25, Loss: 0.0237\n",
      "Epoch 44/200, Iteration 23/25, Loss: 0.0253\n",
      "Epoch 44/200, Iteration 24/25, Loss: 0.0266\n",
      "Epoch 44/200, Iteration 25/25, Loss: 0.0210\n",
      "Train Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.015091, MRE: 0.578066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.017854, MRE: 2.137284 \n",
      "\n",
      "Epoch 45/200, Iteration 1/25, Loss: 0.0198\n",
      "Epoch 45/200, Iteration 2/25, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 3/25, Loss: 0.0240\n",
      "Epoch 45/200, Iteration 4/25, Loss: 0.0292\n",
      "Epoch 45/200, Iteration 5/25, Loss: 0.0227\n",
      "Epoch 45/200, Iteration 6/25, Loss: 0.0277\n",
      "Epoch 45/200, Iteration 7/25, Loss: 0.0167\n",
      "Epoch 45/200, Iteration 8/25, Loss: 0.0182\n",
      "Epoch 45/200, Iteration 9/25, Loss: 0.0216\n",
      "Epoch 45/200, Iteration 10/25, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 11/25, Loss: 0.0378\n",
      "Epoch 45/200, Iteration 12/25, Loss: 0.0278\n",
      "Epoch 45/200, Iteration 13/25, Loss: 0.0245\n",
      "Epoch 45/200, Iteration 14/25, Loss: 0.0370\n",
      "Epoch 45/200, Iteration 15/25, Loss: 0.0286\n",
      "Epoch 45/200, Iteration 16/25, Loss: 0.0180\n",
      "Epoch 45/200, Iteration 17/25, Loss: 0.0217\n",
      "Epoch 45/200, Iteration 18/25, Loss: 0.0176\n",
      "Epoch 45/200, Iteration 19/25, Loss: 0.0212\n",
      "Epoch 45/200, Iteration 20/25, Loss: 0.0252\n",
      "Epoch 45/200, Iteration 21/25, Loss: 0.0222\n",
      "Epoch 45/200, Iteration 22/25, Loss: 0.0194\n",
      "Epoch 45/200, Iteration 23/25, Loss: 0.0230\n",
      "Epoch 45/200, Iteration 24/25, Loss: 0.0214\n",
      "Epoch 45/200, Iteration 25/25, Loss: 0.0334\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.018784, MRE: 1.166749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.023561, MRE: 1.804637 \n",
      "\n",
      "Epoch 46/200, Iteration 1/25, Loss: 0.0149\n",
      "Epoch 46/200, Iteration 2/25, Loss: 0.0211\n",
      "Epoch 46/200, Iteration 3/25, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 4/25, Loss: 0.0205\n",
      "Epoch 46/200, Iteration 5/25, Loss: 0.0208\n",
      "Epoch 46/200, Iteration 6/25, Loss: 0.0189\n",
      "Epoch 46/200, Iteration 7/25, Loss: 0.0278\n",
      "Epoch 46/200, Iteration 8/25, Loss: 0.0151\n",
      "Epoch 46/200, Iteration 9/25, Loss: 0.0251\n",
      "Epoch 46/200, Iteration 10/25, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 11/25, Loss: 0.0163\n",
      "Epoch 46/200, Iteration 12/25, Loss: 0.0197\n",
      "Epoch 46/200, Iteration 13/25, Loss: 0.0140\n",
      "Epoch 46/200, Iteration 14/25, Loss: 0.0169\n",
      "Epoch 46/200, Iteration 15/25, Loss: 0.0312\n",
      "Epoch 46/200, Iteration 16/25, Loss: 0.0173\n",
      "Epoch 46/200, Iteration 17/25, Loss: 0.0313\n",
      "Epoch 46/200, Iteration 18/25, Loss: 0.0174\n",
      "Epoch 46/200, Iteration 19/25, Loss: 0.0188\n",
      "Epoch 46/200, Iteration 20/25, Loss: 0.0249\n",
      "Epoch 46/200, Iteration 21/25, Loss: 0.0227\n",
      "Epoch 46/200, Iteration 22/25, Loss: 0.0185\n",
      "Epoch 46/200, Iteration 23/25, Loss: 0.0178\n",
      "Epoch 46/200, Iteration 24/25, Loss: 0.0173\n",
      "Epoch 46/200, Iteration 25/25, Loss: 0.0220\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.020698, MRE: 1.124064 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.024406, MRE: 2.433879 \n",
      "\n",
      "Epoch 47/200, Iteration 1/25, Loss: 0.0231\n",
      "Epoch 47/200, Iteration 2/25, Loss: 0.0220\n",
      "Epoch 47/200, Iteration 3/25, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 4/25, Loss: 0.0169\n",
      "Epoch 47/200, Iteration 5/25, Loss: 0.0165\n",
      "Epoch 47/200, Iteration 6/25, Loss: 0.0237\n",
      "Epoch 47/200, Iteration 7/25, Loss: 0.0243\n",
      "Epoch 47/200, Iteration 8/25, Loss: 0.0289\n",
      "Epoch 47/200, Iteration 9/25, Loss: 0.0234\n",
      "Epoch 47/200, Iteration 10/25, Loss: 0.0221\n",
      "Epoch 47/200, Iteration 11/25, Loss: 0.0212\n",
      "Epoch 47/200, Iteration 12/25, Loss: 0.0157\n",
      "Epoch 47/200, Iteration 13/25, Loss: 0.0188\n",
      "Epoch 47/200, Iteration 14/25, Loss: 0.0213\n",
      "Epoch 47/200, Iteration 15/25, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 16/25, Loss: 0.0311\n",
      "Epoch 47/200, Iteration 17/25, Loss: 0.0212\n",
      "Epoch 47/200, Iteration 18/25, Loss: 0.0187\n",
      "Epoch 47/200, Iteration 19/25, Loss: 0.0193\n",
      "Epoch 47/200, Iteration 20/25, Loss: 0.0296\n",
      "Epoch 47/200, Iteration 21/25, Loss: 0.0141\n",
      "Epoch 47/200, Iteration 22/25, Loss: 0.0211\n",
      "Epoch 47/200, Iteration 23/25, Loss: 0.0189\n",
      "Epoch 47/200, Iteration 24/25, Loss: 0.0261\n",
      "Epoch 47/200, Iteration 25/25, Loss: 0.0205\n",
      "Train Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.020122, MRE: 0.971017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.021351, MRE: 1.679272 \n",
      "\n",
      "Epoch 48/200, Iteration 1/25, Loss: 0.0229\n",
      "Epoch 48/200, Iteration 2/25, Loss: 0.0188\n",
      "Epoch 48/200, Iteration 3/25, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 4/25, Loss: 0.0190\n",
      "Epoch 48/200, Iteration 5/25, Loss: 0.0225\n",
      "Epoch 48/200, Iteration 6/25, Loss: 0.0255\n",
      "Epoch 48/200, Iteration 7/25, Loss: 0.0141\n",
      "Epoch 48/200, Iteration 8/25, Loss: 0.0161\n",
      "Epoch 48/200, Iteration 9/25, Loss: 0.0294\n",
      "Epoch 48/200, Iteration 10/25, Loss: 0.0235\n",
      "Epoch 48/200, Iteration 11/25, Loss: 0.0216\n",
      "Epoch 48/200, Iteration 12/25, Loss: 0.0262\n",
      "Epoch 48/200, Iteration 13/25, Loss: 0.0278\n",
      "Epoch 48/200, Iteration 14/25, Loss: 0.0196\n",
      "Epoch 48/200, Iteration 15/25, Loss: 0.0384\n",
      "Epoch 48/200, Iteration 16/25, Loss: 0.0272\n",
      "Epoch 48/200, Iteration 17/25, Loss: 0.0301\n",
      "Epoch 48/200, Iteration 18/25, Loss: 0.0270\n",
      "Epoch 48/200, Iteration 19/25, Loss: 0.0242\n",
      "Epoch 48/200, Iteration 20/25, Loss: 0.0415\n",
      "Epoch 48/200, Iteration 21/25, Loss: 0.0299\n",
      "Epoch 48/200, Iteration 22/25, Loss: 0.0227\n",
      "Epoch 48/200, Iteration 23/25, Loss: 0.0445\n",
      "Epoch 48/200, Iteration 24/25, Loss: 0.0370\n",
      "Epoch 48/200, Iteration 25/25, Loss: 0.0290\n",
      "Train Error: \n",
      " Accuracy: 52.75%, Avg loss: 0.027822, MRE: 1.988438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.029822, MRE: 2.491009 \n",
      "\n",
      "Epoch 49/200, Iteration 1/25, Loss: 0.0316\n",
      "Epoch 49/200, Iteration 2/25, Loss: 0.0223\n",
      "Epoch 49/200, Iteration 3/25, Loss: 0.0197\n",
      "Epoch 49/200, Iteration 4/25, Loss: 0.0243\n",
      "Epoch 49/200, Iteration 5/25, Loss: 0.0303\n",
      "Epoch 49/200, Iteration 6/25, Loss: 0.0238\n",
      "Epoch 49/200, Iteration 7/25, Loss: 0.0129\n",
      "Epoch 49/200, Iteration 8/25, Loss: 0.0173\n",
      "Epoch 49/200, Iteration 9/25, Loss: 0.0331\n",
      "Epoch 49/200, Iteration 10/25, Loss: 0.0245\n",
      "Epoch 49/200, Iteration 11/25, Loss: 0.0361\n",
      "Epoch 49/200, Iteration 12/25, Loss: 0.0187\n",
      "Epoch 49/200, Iteration 13/25, Loss: 0.0096\n",
      "Epoch 49/200, Iteration 14/25, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 15/25, Loss: 0.0250\n",
      "Epoch 49/200, Iteration 16/25, Loss: 0.0189\n",
      "Epoch 49/200, Iteration 17/25, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 18/25, Loss: 0.0147\n",
      "Epoch 49/200, Iteration 19/25, Loss: 0.0196\n",
      "Epoch 49/200, Iteration 20/25, Loss: 0.0250\n",
      "Epoch 49/200, Iteration 21/25, Loss: 0.0199\n",
      "Epoch 49/200, Iteration 22/25, Loss: 0.0227\n",
      "Epoch 49/200, Iteration 23/25, Loss: 0.0396\n",
      "Epoch 49/200, Iteration 24/25, Loss: 0.0327\n",
      "Epoch 49/200, Iteration 25/25, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 74.12%, Avg loss: 0.018267, MRE: 0.841260 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.019524, MRE: 1.969332 \n",
      "\n",
      "Epoch 50/200, Iteration 1/25, Loss: 0.0270\n",
      "Epoch 50/200, Iteration 2/25, Loss: 0.0270\n",
      "Epoch 50/200, Iteration 3/25, Loss: 0.0190\n",
      "Epoch 50/200, Iteration 4/25, Loss: 0.0311\n",
      "Epoch 50/200, Iteration 5/25, Loss: 0.0164\n",
      "Epoch 50/200, Iteration 6/25, Loss: 0.0329\n",
      "Epoch 50/200, Iteration 7/25, Loss: 0.0188\n",
      "Epoch 50/200, Iteration 8/25, Loss: 0.0350\n",
      "Epoch 50/200, Iteration 9/25, Loss: 0.0174\n",
      "Epoch 50/200, Iteration 10/25, Loss: 0.0178\n",
      "Epoch 50/200, Iteration 11/25, Loss: 0.0227\n",
      "Epoch 50/200, Iteration 12/25, Loss: 0.0213\n",
      "Epoch 50/200, Iteration 13/25, Loss: 0.0309\n",
      "Epoch 50/200, Iteration 14/25, Loss: 0.0169\n",
      "Epoch 50/200, Iteration 15/25, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 16/25, Loss: 0.0258\n",
      "Epoch 50/200, Iteration 17/25, Loss: 0.0255\n",
      "Epoch 50/200, Iteration 18/25, Loss: 0.0140\n",
      "Epoch 50/200, Iteration 19/25, Loss: 0.0234\n",
      "Epoch 50/200, Iteration 20/25, Loss: 0.0155\n",
      "Epoch 50/200, Iteration 21/25, Loss: 0.0275\n",
      "Epoch 50/200, Iteration 22/25, Loss: 0.0224\n",
      "Epoch 50/200, Iteration 23/25, Loss: 0.0198\n",
      "Epoch 50/200, Iteration 24/25, Loss: 0.0146\n",
      "Epoch 50/200, Iteration 25/25, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 63.12%, Avg loss: 0.013610, MRE: 0.817610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.014868, MRE: 2.851929 \n",
      "\n",
      "Epoch 51/200, Iteration 1/25, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 2/25, Loss: 0.0178\n",
      "Epoch 51/200, Iteration 3/25, Loss: 0.0130\n",
      "Epoch 51/200, Iteration 4/25, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 5/25, Loss: 0.0120\n",
      "Epoch 51/200, Iteration 6/25, Loss: 0.0191\n",
      "Epoch 51/200, Iteration 7/25, Loss: 0.0367\n",
      "Epoch 51/200, Iteration 8/25, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 9/25, Loss: 0.0139\n",
      "Epoch 51/200, Iteration 10/25, Loss: 0.0225\n",
      "Epoch 51/200, Iteration 11/25, Loss: 0.0361\n",
      "Epoch 51/200, Iteration 12/25, Loss: 0.0216\n",
      "Epoch 51/200, Iteration 13/25, Loss: 0.0268\n",
      "Epoch 51/200, Iteration 14/25, Loss: 0.0194\n",
      "Epoch 51/200, Iteration 15/25, Loss: 0.0200\n",
      "Epoch 51/200, Iteration 16/25, Loss: 0.0155\n",
      "Epoch 51/200, Iteration 17/25, Loss: 0.0193\n",
      "Epoch 51/200, Iteration 18/25, Loss: 0.0280\n",
      "Epoch 51/200, Iteration 19/25, Loss: 0.0235\n",
      "Epoch 51/200, Iteration 20/25, Loss: 0.0254\n",
      "Epoch 51/200, Iteration 21/25, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 22/25, Loss: 0.0274\n",
      "Epoch 51/200, Iteration 23/25, Loss: 0.0306\n",
      "Epoch 51/200, Iteration 24/25, Loss: 0.0170\n",
      "Epoch 51/200, Iteration 25/25, Loss: 0.0176\n",
      "Train Error: \n",
      " Accuracy: 75.12%, Avg loss: 0.012124, MRE: 0.773047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.014052, MRE: 2.842114 \n",
      "\n",
      "Epoch 52/200, Iteration 1/25, Loss: 0.0117\n",
      "Epoch 52/200, Iteration 2/25, Loss: 0.0200\n",
      "Epoch 52/200, Iteration 3/25, Loss: 0.0187\n",
      "Epoch 52/200, Iteration 4/25, Loss: 0.0185\n",
      "Epoch 52/200, Iteration 5/25, Loss: 0.0195\n",
      "Epoch 52/200, Iteration 6/25, Loss: 0.0157\n",
      "Epoch 52/200, Iteration 7/25, Loss: 0.0161\n",
      "Epoch 52/200, Iteration 8/25, Loss: 0.0116\n",
      "Epoch 52/200, Iteration 9/25, Loss: 0.0222\n",
      "Epoch 52/200, Iteration 10/25, Loss: 0.0358\n",
      "Epoch 52/200, Iteration 11/25, Loss: 0.0305\n",
      "Epoch 52/200, Iteration 12/25, Loss: 0.0311\n",
      "Epoch 52/200, Iteration 13/25, Loss: 0.0246\n",
      "Epoch 52/200, Iteration 14/25, Loss: 0.0315\n",
      "Epoch 52/200, Iteration 15/25, Loss: 0.0268\n",
      "Epoch 52/200, Iteration 16/25, Loss: 0.0406\n",
      "Epoch 52/200, Iteration 17/25, Loss: 0.0150\n",
      "Epoch 52/200, Iteration 18/25, Loss: 0.0151\n",
      "Epoch 52/200, Iteration 19/25, Loss: 0.0197\n",
      "Epoch 52/200, Iteration 20/25, Loss: 0.0157\n",
      "Epoch 52/200, Iteration 21/25, Loss: 0.0309\n",
      "Epoch 52/200, Iteration 22/25, Loss: 0.0252\n",
      "Epoch 52/200, Iteration 23/25, Loss: 0.0171\n",
      "Epoch 52/200, Iteration 24/25, Loss: 0.0240\n",
      "Epoch 52/200, Iteration 25/25, Loss: 0.0372\n",
      "Train Error: \n",
      " Accuracy: 48.75%, Avg loss: 0.020267, MRE: 1.424594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.021112, MRE: 1.573802 \n",
      "\n",
      "Epoch 53/200, Iteration 1/25, Loss: 0.0343\n",
      "Epoch 53/200, Iteration 2/25, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 3/25, Loss: 0.0162\n",
      "Epoch 53/200, Iteration 4/25, Loss: 0.0169\n",
      "Epoch 53/200, Iteration 5/25, Loss: 0.0223\n",
      "Epoch 53/200, Iteration 6/25, Loss: 0.0236\n",
      "Epoch 53/200, Iteration 7/25, Loss: 0.0233\n",
      "Epoch 53/200, Iteration 8/25, Loss: 0.0250\n",
      "Epoch 53/200, Iteration 9/25, Loss: 0.0375\n",
      "Epoch 53/200, Iteration 10/25, Loss: 0.0333\n",
      "Epoch 53/200, Iteration 11/25, Loss: 0.0342\n",
      "Epoch 53/200, Iteration 12/25, Loss: 0.0196\n",
      "Epoch 53/200, Iteration 13/25, Loss: 0.0251\n",
      "Epoch 53/200, Iteration 14/25, Loss: 0.0210\n",
      "Epoch 53/200, Iteration 15/25, Loss: 0.0262\n",
      "Epoch 53/200, Iteration 16/25, Loss: 0.0206\n",
      "Epoch 53/200, Iteration 17/25, Loss: 0.0166\n",
      "Epoch 53/200, Iteration 18/25, Loss: 0.0194\n",
      "Epoch 53/200, Iteration 19/25, Loss: 0.0292\n",
      "Epoch 53/200, Iteration 20/25, Loss: 0.0241\n",
      "Epoch 53/200, Iteration 21/25, Loss: 0.0298\n",
      "Epoch 53/200, Iteration 22/25, Loss: 0.0257\n",
      "Epoch 53/200, Iteration 23/25, Loss: 0.0192\n",
      "Epoch 53/200, Iteration 24/25, Loss: 0.0205\n",
      "Epoch 53/200, Iteration 25/25, Loss: 0.0252\n",
      "Train Error: \n",
      " Accuracy: 62.38%, Avg loss: 0.024445, MRE: 1.053219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.027484, MRE: 1.647608 \n",
      "\n",
      "Epoch 54/200, Iteration 1/25, Loss: 0.0228\n",
      "Epoch 54/200, Iteration 2/25, Loss: 0.0216\n",
      "Epoch 54/200, Iteration 3/25, Loss: 0.0206\n",
      "Epoch 54/200, Iteration 4/25, Loss: 0.0385\n",
      "Epoch 54/200, Iteration 5/25, Loss: 0.0247\n",
      "Epoch 54/200, Iteration 6/25, Loss: 0.0281\n",
      "Epoch 54/200, Iteration 7/25, Loss: 0.0258\n",
      "Epoch 54/200, Iteration 8/25, Loss: 0.0191\n",
      "Epoch 54/200, Iteration 9/25, Loss: 0.0142\n",
      "Epoch 54/200, Iteration 10/25, Loss: 0.0265\n",
      "Epoch 54/200, Iteration 11/25, Loss: 0.0361\n",
      "Epoch 54/200, Iteration 12/25, Loss: 0.0305\n",
      "Epoch 54/200, Iteration 13/25, Loss: 0.0292\n",
      "Epoch 54/200, Iteration 14/25, Loss: 0.0289\n",
      "Epoch 54/200, Iteration 15/25, Loss: 0.0339\n",
      "Epoch 54/200, Iteration 16/25, Loss: 0.0381\n",
      "Epoch 54/200, Iteration 17/25, Loss: 0.0214\n",
      "Epoch 54/200, Iteration 18/25, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 19/25, Loss: 0.0240\n",
      "Epoch 54/200, Iteration 20/25, Loss: 0.0246\n",
      "Epoch 54/200, Iteration 21/25, Loss: 0.0320\n",
      "Epoch 54/200, Iteration 22/25, Loss: 0.0355\n",
      "Epoch 54/200, Iteration 23/25, Loss: 0.0187\n",
      "Epoch 54/200, Iteration 24/25, Loss: 0.0167\n",
      "Epoch 54/200, Iteration 25/25, Loss: 0.0259\n",
      "Train Error: \n",
      " Accuracy: 40.12%, Avg loss: 0.020976, MRE: 1.619091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.021389, MRE: 1.317933 \n",
      "\n",
      "Epoch 55/200, Iteration 1/25, Loss: 0.0235\n",
      "Epoch 55/200, Iteration 2/25, Loss: 0.0285\n",
      "Epoch 55/200, Iteration 3/25, Loss: 0.0188\n",
      "Epoch 55/200, Iteration 4/25, Loss: 0.0199\n",
      "Epoch 55/200, Iteration 5/25, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 6/25, Loss: 0.0205\n",
      "Epoch 55/200, Iteration 7/25, Loss: 0.0176\n",
      "Epoch 55/200, Iteration 8/25, Loss: 0.0245\n",
      "Epoch 55/200, Iteration 9/25, Loss: 0.0272\n",
      "Epoch 55/200, Iteration 10/25, Loss: 0.0278\n",
      "Epoch 55/200, Iteration 11/25, Loss: 0.0193\n",
      "Epoch 55/200, Iteration 12/25, Loss: 0.0169\n",
      "Epoch 55/200, Iteration 13/25, Loss: 0.0365\n",
      "Epoch 55/200, Iteration 14/25, Loss: 0.0178\n",
      "Epoch 55/200, Iteration 15/25, Loss: 0.0249\n",
      "Epoch 55/200, Iteration 16/25, Loss: 0.0212\n",
      "Epoch 55/200, Iteration 17/25, Loss: 0.0193\n",
      "Epoch 55/200, Iteration 18/25, Loss: 0.0155\n",
      "Epoch 55/200, Iteration 19/25, Loss: 0.0190\n",
      "Epoch 55/200, Iteration 20/25, Loss: 0.0212\n",
      "Epoch 55/200, Iteration 21/25, Loss: 0.0205\n",
      "Epoch 55/200, Iteration 22/25, Loss: 0.0208\n",
      "Epoch 55/200, Iteration 23/25, Loss: 0.0251\n",
      "Epoch 55/200, Iteration 24/25, Loss: 0.0249\n",
      "Epoch 55/200, Iteration 25/25, Loss: 0.0193\n",
      "Train Error: \n",
      " Accuracy: 67.88%, Avg loss: 0.013923, MRE: 0.777806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.016384, MRE: 3.176236 \n",
      "\n",
      "Epoch 56/200, Iteration 1/25, Loss: 0.0369\n",
      "Epoch 56/200, Iteration 2/25, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 3/25, Loss: 0.0291\n",
      "Epoch 56/200, Iteration 4/25, Loss: 0.0239\n",
      "Epoch 56/200, Iteration 5/25, Loss: 0.0224\n",
      "Epoch 56/200, Iteration 6/25, Loss: 0.0475\n",
      "Epoch 56/200, Iteration 7/25, Loss: 0.0105\n",
      "Epoch 56/200, Iteration 8/25, Loss: 0.0164\n",
      "Epoch 56/200, Iteration 9/25, Loss: 0.0200\n",
      "Epoch 56/200, Iteration 10/25, Loss: 0.0125\n",
      "Epoch 56/200, Iteration 11/25, Loss: 0.0135\n",
      "Epoch 56/200, Iteration 12/25, Loss: 0.0345\n",
      "Epoch 56/200, Iteration 13/25, Loss: 0.0180\n",
      "Epoch 56/200, Iteration 14/25, Loss: 0.0165\n",
      "Epoch 56/200, Iteration 15/25, Loss: 0.0185\n",
      "Epoch 56/200, Iteration 16/25, Loss: 0.0184\n",
      "Epoch 56/200, Iteration 17/25, Loss: 0.0124\n",
      "Epoch 56/200, Iteration 18/25, Loss: 0.0134\n",
      "Epoch 56/200, Iteration 19/25, Loss: 0.0340\n",
      "Epoch 56/200, Iteration 20/25, Loss: 0.0145\n",
      "Epoch 56/200, Iteration 21/25, Loss: 0.0127\n",
      "Epoch 56/200, Iteration 22/25, Loss: 0.0164\n",
      "Epoch 56/200, Iteration 23/25, Loss: 0.0304\n",
      "Epoch 56/200, Iteration 24/25, Loss: 0.0166\n",
      "Epoch 56/200, Iteration 25/25, Loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 66.75%, Avg loss: 0.012583, MRE: 0.895931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.014830, MRE: 1.061024 \n",
      "\n",
      "Epoch 57/200, Iteration 1/25, Loss: 0.0141\n",
      "Epoch 57/200, Iteration 2/25, Loss: 0.0218\n",
      "Epoch 57/200, Iteration 3/25, Loss: 0.0136\n",
      "Epoch 57/200, Iteration 4/25, Loss: 0.0175\n",
      "Epoch 57/200, Iteration 5/25, Loss: 0.0169\n",
      "Epoch 57/200, Iteration 6/25, Loss: 0.0184\n",
      "Epoch 57/200, Iteration 7/25, Loss: 0.0153\n",
      "Epoch 57/200, Iteration 8/25, Loss: 0.0129\n",
      "Epoch 57/200, Iteration 9/25, Loss: 0.0568\n",
      "Epoch 57/200, Iteration 10/25, Loss: 0.0161\n",
      "Epoch 57/200, Iteration 11/25, Loss: 0.0179\n",
      "Epoch 57/200, Iteration 12/25, Loss: 0.0135\n",
      "Epoch 57/200, Iteration 13/25, Loss: 0.0218\n",
      "Epoch 57/200, Iteration 14/25, Loss: 0.0169\n",
      "Epoch 57/200, Iteration 15/25, Loss: 0.0222\n",
      "Epoch 57/200, Iteration 16/25, Loss: 0.0181\n",
      "Epoch 57/200, Iteration 17/25, Loss: 0.0164\n",
      "Epoch 57/200, Iteration 18/25, Loss: 0.0217\n",
      "Epoch 57/200, Iteration 19/25, Loss: 0.0228\n",
      "Epoch 57/200, Iteration 20/25, Loss: 0.0170\n",
      "Epoch 57/200, Iteration 21/25, Loss: 0.0300\n",
      "Epoch 57/200, Iteration 22/25, Loss: 0.0158\n",
      "Epoch 57/200, Iteration 23/25, Loss: 0.0146\n",
      "Epoch 57/200, Iteration 24/25, Loss: 0.0187\n",
      "Epoch 57/200, Iteration 25/25, Loss: 0.0200\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.019703, MRE: 1.211123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.019125, MRE: 2.459133 \n",
      "\n",
      "Epoch 58/200, Iteration 1/25, Loss: 0.0222\n",
      "Epoch 58/200, Iteration 2/25, Loss: 0.0220\n",
      "Epoch 58/200, Iteration 3/25, Loss: 0.0122\n",
      "Epoch 58/200, Iteration 4/25, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 5/25, Loss: 0.0215\n",
      "Epoch 58/200, Iteration 6/25, Loss: 0.0202\n",
      "Epoch 58/200, Iteration 7/25, Loss: 0.0191\n",
      "Epoch 58/200, Iteration 8/25, Loss: 0.0213\n",
      "Epoch 58/200, Iteration 9/25, Loss: 0.0189\n",
      "Epoch 58/200, Iteration 10/25, Loss: 0.0437\n",
      "Epoch 58/200, Iteration 11/25, Loss: 0.0252\n",
      "Epoch 58/200, Iteration 12/25, Loss: 0.0264\n",
      "Epoch 58/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 58/200, Iteration 14/25, Loss: 0.0175\n",
      "Epoch 58/200, Iteration 15/25, Loss: 0.0207\n",
      "Epoch 58/200, Iteration 16/25, Loss: 0.0316\n",
      "Epoch 58/200, Iteration 17/25, Loss: 0.0241\n",
      "Epoch 58/200, Iteration 18/25, Loss: 0.0216\n",
      "Epoch 58/200, Iteration 19/25, Loss: 0.0404\n",
      "Epoch 58/200, Iteration 20/25, Loss: 0.0236\n",
      "Epoch 58/200, Iteration 21/25, Loss: 0.0206\n",
      "Epoch 58/200, Iteration 22/25, Loss: 0.0234\n",
      "Epoch 58/200, Iteration 23/25, Loss: 0.0160\n",
      "Epoch 58/200, Iteration 24/25, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 25/25, Loss: 0.0229\n",
      "Train Error: \n",
      " Accuracy: 85.75%, Avg loss: 0.013210, MRE: 0.753794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.014033, MRE: 1.354503 \n",
      "\n",
      "Epoch 59/200, Iteration 1/25, Loss: 0.0188\n",
      "Epoch 59/200, Iteration 2/25, Loss: 0.0258\n",
      "Epoch 59/200, Iteration 3/25, Loss: 0.0329\n",
      "Epoch 59/200, Iteration 4/25, Loss: 0.0211\n",
      "Epoch 59/200, Iteration 5/25, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 6/25, Loss: 0.0188\n",
      "Epoch 59/200, Iteration 7/25, Loss: 0.0155\n",
      "Epoch 59/200, Iteration 8/25, Loss: 0.0265\n",
      "Epoch 59/200, Iteration 9/25, Loss: 0.0194\n",
      "Epoch 59/200, Iteration 10/25, Loss: 0.0231\n",
      "Epoch 59/200, Iteration 11/25, Loss: 0.0138\n",
      "Epoch 59/200, Iteration 12/25, Loss: 0.0280\n",
      "Epoch 59/200, Iteration 13/25, Loss: 0.0160\n",
      "Epoch 59/200, Iteration 14/25, Loss: 0.0244\n",
      "Epoch 59/200, Iteration 15/25, Loss: 0.0146\n",
      "Epoch 59/200, Iteration 16/25, Loss: 0.0270\n",
      "Epoch 59/200, Iteration 17/25, Loss: 0.0207\n",
      "Epoch 59/200, Iteration 18/25, Loss: 0.0197\n",
      "Epoch 59/200, Iteration 19/25, Loss: 0.0161\n",
      "Epoch 59/200, Iteration 20/25, Loss: 0.0254\n",
      "Epoch 59/200, Iteration 21/25, Loss: 0.0153\n",
      "Epoch 59/200, Iteration 22/25, Loss: 0.0165\n",
      "Epoch 59/200, Iteration 23/25, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 24/25, Loss: 0.0191\n",
      "Epoch 59/200, Iteration 25/25, Loss: 0.0135\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.011491, MRE: 0.711001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.012291, MRE: 1.154862 \n",
      "\n",
      "Epoch 60/200, Iteration 1/25, Loss: 0.0136\n",
      "Epoch 60/200, Iteration 2/25, Loss: 0.0176\n",
      "Epoch 60/200, Iteration 3/25, Loss: 0.0230\n",
      "Epoch 60/200, Iteration 4/25, Loss: 0.0261\n",
      "Epoch 60/200, Iteration 5/25, Loss: 0.0171\n",
      "Epoch 60/200, Iteration 6/25, Loss: 0.0223\n",
      "Epoch 60/200, Iteration 7/25, Loss: 0.0125\n",
      "Epoch 60/200, Iteration 8/25, Loss: 0.0206\n",
      "Epoch 60/200, Iteration 9/25, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 10/25, Loss: 0.0157\n",
      "Epoch 60/200, Iteration 11/25, Loss: 0.0208\n",
      "Epoch 60/200, Iteration 12/25, Loss: 0.0140\n",
      "Epoch 60/200, Iteration 13/25, Loss: 0.0202\n",
      "Epoch 60/200, Iteration 14/25, Loss: 0.0149\n",
      "Epoch 60/200, Iteration 15/25, Loss: 0.0196\n",
      "Epoch 60/200, Iteration 16/25, Loss: 0.0166\n",
      "Epoch 60/200, Iteration 17/25, Loss: 0.0168\n",
      "Epoch 60/200, Iteration 18/25, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 19/25, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 20/25, Loss: 0.0110\n",
      "Epoch 60/200, Iteration 21/25, Loss: 0.0291\n",
      "Epoch 60/200, Iteration 22/25, Loss: 0.0528\n",
      "Epoch 60/200, Iteration 23/25, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 24/25, Loss: 0.0218\n",
      "Epoch 60/200, Iteration 25/25, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.015017, MRE: 1.038483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.016622, MRE: 2.273523 \n",
      "\n",
      "Epoch 61/200, Iteration 1/25, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 2/25, Loss: 0.0225\n",
      "Epoch 61/200, Iteration 3/25, Loss: 0.0099\n",
      "Epoch 61/200, Iteration 4/25, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 5/25, Loss: 0.0171\n",
      "Epoch 61/200, Iteration 6/25, Loss: 0.0202\n",
      "Epoch 61/200, Iteration 7/25, Loss: 0.0222\n",
      "Epoch 61/200, Iteration 8/25, Loss: 0.0145\n",
      "Epoch 61/200, Iteration 9/25, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 10/25, Loss: 0.0190\n",
      "Epoch 61/200, Iteration 11/25, Loss: 0.0540\n",
      "Epoch 61/200, Iteration 12/25, Loss: 0.0210\n",
      "Epoch 61/200, Iteration 13/25, Loss: 0.0141\n",
      "Epoch 61/200, Iteration 14/25, Loss: 0.0341\n",
      "Epoch 61/200, Iteration 15/25, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 16/25, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 17/25, Loss: 0.0195\n",
      "Epoch 61/200, Iteration 18/25, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 19/25, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 20/25, Loss: 0.0186\n",
      "Epoch 61/200, Iteration 21/25, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 22/25, Loss: 0.0231\n",
      "Epoch 61/200, Iteration 23/25, Loss: 0.0150\n",
      "Epoch 61/200, Iteration 24/25, Loss: 0.0225\n",
      "Epoch 61/200, Iteration 25/25, Loss: 0.0116\n",
      "Train Error: \n",
      " Accuracy: 49.12%, Avg loss: 0.017719, MRE: 1.170865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.019666, MRE: 2.013058 \n",
      "\n",
      "Epoch 62/200, Iteration 1/25, Loss: 0.0264\n",
      "Epoch 62/200, Iteration 2/25, Loss: 0.0124\n",
      "Epoch 62/200, Iteration 3/25, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 4/25, Loss: 0.0165\n",
      "Epoch 62/200, Iteration 5/25, Loss: 0.0144\n",
      "Epoch 62/200, Iteration 6/25, Loss: 0.0116\n",
      "Epoch 62/200, Iteration 7/25, Loss: 0.0298\n",
      "Epoch 62/200, Iteration 8/25, Loss: 0.0143\n",
      "Epoch 62/200, Iteration 9/25, Loss: 0.0359\n",
      "Epoch 62/200, Iteration 10/25, Loss: 0.0268\n",
      "Epoch 62/200, Iteration 11/25, Loss: 0.0341\n",
      "Epoch 62/200, Iteration 12/25, Loss: 0.0097\n",
      "Epoch 62/200, Iteration 13/25, Loss: 0.0086\n",
      "Epoch 62/200, Iteration 14/25, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 15/25, Loss: 0.0288\n",
      "Epoch 62/200, Iteration 16/25, Loss: 0.0164\n",
      "Epoch 62/200, Iteration 17/25, Loss: 0.0302\n",
      "Epoch 62/200, Iteration 18/25, Loss: 0.0270\n",
      "Epoch 62/200, Iteration 19/25, Loss: 0.0227\n",
      "Epoch 62/200, Iteration 20/25, Loss: 0.0155\n",
      "Epoch 62/200, Iteration 21/25, Loss: 0.0146\n",
      "Epoch 62/200, Iteration 22/25, Loss: 0.0287\n",
      "Epoch 62/200, Iteration 23/25, Loss: 0.0159\n",
      "Epoch 62/200, Iteration 24/25, Loss: 0.0295\n",
      "Epoch 62/200, Iteration 25/25, Loss: 0.0236\n",
      "Train Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.020594, MRE: 1.194532 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.019268, MRE: 1.758286 \n",
      "\n",
      "Epoch 63/200, Iteration 1/25, Loss: 0.0189\n",
      "Epoch 63/200, Iteration 2/25, Loss: 0.0351\n",
      "Epoch 63/200, Iteration 3/25, Loss: 0.0137\n",
      "Epoch 63/200, Iteration 4/25, Loss: 0.0207\n",
      "Epoch 63/200, Iteration 5/25, Loss: 0.0289\n",
      "Epoch 63/200, Iteration 6/25, Loss: 0.0328\n",
      "Epoch 63/200, Iteration 7/25, Loss: 0.0275\n",
      "Epoch 63/200, Iteration 8/25, Loss: 0.0254\n",
      "Epoch 63/200, Iteration 9/25, Loss: 0.0292\n",
      "Epoch 63/200, Iteration 10/25, Loss: 0.0211\n",
      "Epoch 63/200, Iteration 11/25, Loss: 0.0217\n",
      "Epoch 63/200, Iteration 12/25, Loss: 0.0309\n",
      "Epoch 63/200, Iteration 13/25, Loss: 0.0273\n",
      "Epoch 63/200, Iteration 14/25, Loss: 0.0153\n",
      "Epoch 63/200, Iteration 15/25, Loss: 0.0227\n",
      "Epoch 63/200, Iteration 16/25, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 17/25, Loss: 0.0130\n",
      "Epoch 63/200, Iteration 18/25, Loss: 0.0297\n",
      "Epoch 63/200, Iteration 19/25, Loss: 0.0219\n",
      "Epoch 63/200, Iteration 20/25, Loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Iteration 21/25, Loss: 0.0166\n",
      "Epoch 63/200, Iteration 22/25, Loss: 0.0290\n",
      "Epoch 63/200, Iteration 23/25, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 24/25, Loss: 0.0181\n",
      "Epoch 63/200, Iteration 25/25, Loss: 0.0154\n",
      "Train Error: \n",
      " Accuracy: 76.38%, Avg loss: 0.011140, MRE: 0.600014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.013822, MRE: 1.134323 \n",
      "\n",
      "Epoch 64/200, Iteration 1/25, Loss: 0.0182\n",
      "Epoch 64/200, Iteration 2/25, Loss: 0.0178\n",
      "Epoch 64/200, Iteration 3/25, Loss: 0.0339\n",
      "Epoch 64/200, Iteration 4/25, Loss: 0.0328\n",
      "Epoch 64/200, Iteration 5/25, Loss: 0.0148\n",
      "Epoch 64/200, Iteration 6/25, Loss: 0.0242\n",
      "Epoch 64/200, Iteration 7/25, Loss: 0.0137\n",
      "Epoch 64/200, Iteration 8/25, Loss: 0.0141\n",
      "Epoch 64/200, Iteration 9/25, Loss: 0.0171\n",
      "Epoch 64/200, Iteration 10/25, Loss: 0.0223\n",
      "Epoch 64/200, Iteration 11/25, Loss: 0.0159\n",
      "Epoch 64/200, Iteration 12/25, Loss: 0.0272\n",
      "Epoch 64/200, Iteration 13/25, Loss: 0.0221\n",
      "Epoch 64/200, Iteration 14/25, Loss: 0.0329\n",
      "Epoch 64/200, Iteration 15/25, Loss: 0.0219\n",
      "Epoch 64/200, Iteration 16/25, Loss: 0.0225\n",
      "Epoch 64/200, Iteration 17/25, Loss: 0.0145\n",
      "Epoch 64/200, Iteration 18/25, Loss: 0.0123\n",
      "Epoch 64/200, Iteration 19/25, Loss: 0.0141\n",
      "Epoch 64/200, Iteration 20/25, Loss: 0.0238\n",
      "Epoch 64/200, Iteration 21/25, Loss: 0.0277\n",
      "Epoch 64/200, Iteration 22/25, Loss: 0.0171\n",
      "Epoch 64/200, Iteration 23/25, Loss: 0.0183\n",
      "Epoch 64/200, Iteration 24/25, Loss: 0.0161\n",
      "Epoch 64/200, Iteration 25/25, Loss: 0.0214\n",
      "Train Error: \n",
      " Accuracy: 86.25%, Avg loss: 0.012463, MRE: 0.875308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.012732, MRE: 2.348639 \n",
      "\n",
      "Epoch 65/200, Iteration 1/25, Loss: 0.0162\n",
      "Epoch 65/200, Iteration 2/25, Loss: 0.0193\n",
      "Epoch 65/200, Iteration 3/25, Loss: 0.0138\n",
      "Epoch 65/200, Iteration 4/25, Loss: 0.0309\n",
      "Epoch 65/200, Iteration 5/25, Loss: 0.0218\n",
      "Epoch 65/200, Iteration 6/25, Loss: 0.0180\n",
      "Epoch 65/200, Iteration 7/25, Loss: 0.0222\n",
      "Epoch 65/200, Iteration 8/25, Loss: 0.0144\n",
      "Epoch 65/200, Iteration 9/25, Loss: 0.0171\n",
      "Epoch 65/200, Iteration 10/25, Loss: 0.0264\n",
      "Epoch 65/200, Iteration 11/25, Loss: 0.0146\n",
      "Epoch 65/200, Iteration 12/25, Loss: 0.0189\n",
      "Epoch 65/200, Iteration 13/25, Loss: 0.0141\n",
      "Epoch 65/200, Iteration 14/25, Loss: 0.0166\n",
      "Epoch 65/200, Iteration 15/25, Loss: 0.0184\n",
      "Epoch 65/200, Iteration 16/25, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 17/25, Loss: 0.0298\n",
      "Epoch 65/200, Iteration 18/25, Loss: 0.0172\n",
      "Epoch 65/200, Iteration 19/25, Loss: 0.0218\n",
      "Epoch 65/200, Iteration 20/25, Loss: 0.0203\n",
      "Epoch 65/200, Iteration 21/25, Loss: 0.0184\n",
      "Epoch 65/200, Iteration 22/25, Loss: 0.0398\n",
      "Epoch 65/200, Iteration 23/25, Loss: 0.0241\n",
      "Epoch 65/200, Iteration 24/25, Loss: 0.0197\n",
      "Epoch 65/200, Iteration 25/25, Loss: 0.0169\n",
      "Train Error: \n",
      " Accuracy: 66.75%, Avg loss: 0.012940, MRE: 1.028790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.015415, MRE: 1.941931 \n",
      "\n",
      "Epoch 66/200, Iteration 1/25, Loss: 0.0200\n",
      "Epoch 66/200, Iteration 2/25, Loss: 0.0137\n",
      "Epoch 66/200, Iteration 3/25, Loss: 0.0265\n",
      "Epoch 66/200, Iteration 4/25, Loss: 0.0185\n",
      "Epoch 66/200, Iteration 5/25, Loss: 0.0171\n",
      "Epoch 66/200, Iteration 6/25, Loss: 0.0234\n",
      "Epoch 66/200, Iteration 7/25, Loss: 0.0286\n",
      "Epoch 66/200, Iteration 8/25, Loss: 0.0347\n",
      "Epoch 66/200, Iteration 9/25, Loss: 0.0245\n",
      "Epoch 66/200, Iteration 10/25, Loss: 0.0215\n",
      "Epoch 66/200, Iteration 11/25, Loss: 0.0237\n",
      "Epoch 66/200, Iteration 12/25, Loss: 0.0348\n",
      "Epoch 66/200, Iteration 13/25, Loss: 0.0244\n",
      "Epoch 66/200, Iteration 14/25, Loss: 0.0214\n",
      "Epoch 66/200, Iteration 15/25, Loss: 0.0198\n",
      "Epoch 66/200, Iteration 16/25, Loss: 0.0246\n",
      "Epoch 66/200, Iteration 17/25, Loss: 0.0167\n",
      "Epoch 66/200, Iteration 18/25, Loss: 0.0165\n",
      "Epoch 66/200, Iteration 19/25, Loss: 0.0221\n",
      "Epoch 66/200, Iteration 20/25, Loss: 0.0199\n",
      "Epoch 66/200, Iteration 21/25, Loss: 0.0236\n",
      "Epoch 66/200, Iteration 22/25, Loss: 0.0187\n",
      "Epoch 66/200, Iteration 23/25, Loss: 0.0224\n",
      "Epoch 66/200, Iteration 24/25, Loss: 0.0323\n",
      "Epoch 66/200, Iteration 25/25, Loss: 0.0369\n",
      "Train Error: \n",
      " Accuracy: 62.88%, Avg loss: 0.021246, MRE: 1.186356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.021073, MRE: 3.390867 \n",
      "\n",
      "Epoch 67/200, Iteration 1/25, Loss: 0.0144\n",
      "Epoch 67/200, Iteration 2/25, Loss: 0.0269\n",
      "Epoch 67/200, Iteration 3/25, Loss: 0.0154\n",
      "Epoch 67/200, Iteration 4/25, Loss: 0.0200\n",
      "Epoch 67/200, Iteration 5/25, Loss: 0.0207\n",
      "Epoch 67/200, Iteration 6/25, Loss: 0.0201\n",
      "Epoch 67/200, Iteration 7/25, Loss: 0.0271\n",
      "Epoch 67/200, Iteration 8/25, Loss: 0.0363\n",
      "Epoch 67/200, Iteration 9/25, Loss: 0.0192\n",
      "Epoch 67/200, Iteration 10/25, Loss: 0.0210\n",
      "Epoch 67/200, Iteration 11/25, Loss: 0.0293\n",
      "Epoch 67/200, Iteration 12/25, Loss: 0.0237\n",
      "Epoch 67/200, Iteration 13/25, Loss: 0.0173\n",
      "Epoch 67/200, Iteration 14/25, Loss: 0.0196\n",
      "Epoch 67/200, Iteration 15/25, Loss: 0.0206\n",
      "Epoch 67/200, Iteration 16/25, Loss: 0.0273\n",
      "Epoch 67/200, Iteration 17/25, Loss: 0.0187\n",
      "Epoch 67/200, Iteration 18/25, Loss: 0.0197\n",
      "Epoch 67/200, Iteration 19/25, Loss: 0.0324\n",
      "Epoch 67/200, Iteration 20/25, Loss: 0.0183\n",
      "Epoch 67/200, Iteration 21/25, Loss: 0.0216\n",
      "Epoch 67/200, Iteration 22/25, Loss: 0.0225\n",
      "Epoch 67/200, Iteration 23/25, Loss: 0.0153\n",
      "Epoch 67/200, Iteration 24/25, Loss: 0.0377\n",
      "Epoch 67/200, Iteration 25/25, Loss: 0.0485\n",
      "Train Error: \n",
      " Accuracy: 78.38%, Avg loss: 0.020232, MRE: 1.251016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.020349, MRE: 3.325223 \n",
      "\n",
      "Epoch 68/200, Iteration 1/25, Loss: 0.0205\n",
      "Epoch 68/200, Iteration 2/25, Loss: 0.0213\n",
      "Epoch 68/200, Iteration 3/25, Loss: 0.0184\n",
      "Epoch 68/200, Iteration 4/25, Loss: 0.0123\n",
      "Epoch 68/200, Iteration 5/25, Loss: 0.0304\n",
      "Epoch 68/200, Iteration 6/25, Loss: 0.0244\n",
      "Epoch 68/200, Iteration 7/25, Loss: 0.0167\n",
      "Epoch 68/200, Iteration 8/25, Loss: 0.0170\n",
      "Epoch 68/200, Iteration 9/25, Loss: 0.0110\n",
      "Epoch 68/200, Iteration 10/25, Loss: 0.0182\n",
      "Epoch 68/200, Iteration 11/25, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 12/25, Loss: 0.0220\n",
      "Epoch 68/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 68/200, Iteration 14/25, Loss: 0.0128\n",
      "Epoch 68/200, Iteration 15/25, Loss: 0.0167\n",
      "Epoch 68/200, Iteration 16/25, Loss: 0.0257\n",
      "Epoch 68/200, Iteration 17/25, Loss: 0.0181\n",
      "Epoch 68/200, Iteration 18/25, Loss: 0.0149\n",
      "Epoch 68/200, Iteration 19/25, Loss: 0.0264\n",
      "Epoch 68/200, Iteration 20/25, Loss: 0.0143\n",
      "Epoch 68/200, Iteration 21/25, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 22/25, Loss: 0.0154\n",
      "Epoch 68/200, Iteration 23/25, Loss: 0.0300\n",
      "Epoch 68/200, Iteration 24/25, Loss: 0.0132\n",
      "Epoch 68/200, Iteration 25/25, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.014187, MRE: 0.947804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.014878, MRE: 2.906134 \n",
      "\n",
      "Epoch 69/200, Iteration 1/25, Loss: 0.0167\n",
      "Epoch 69/200, Iteration 2/25, Loss: 0.0308\n",
      "Epoch 69/200, Iteration 3/25, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 4/25, Loss: 0.0277\n",
      "Epoch 69/200, Iteration 5/25, Loss: 0.0201\n",
      "Epoch 69/200, Iteration 6/25, Loss: 0.0179\n",
      "Epoch 69/200, Iteration 7/25, Loss: 0.0188\n",
      "Epoch 69/200, Iteration 8/25, Loss: 0.0225\n",
      "Epoch 69/200, Iteration 9/25, Loss: 0.0195\n",
      "Epoch 69/200, Iteration 10/25, Loss: 0.0198\n",
      "Epoch 69/200, Iteration 11/25, Loss: 0.0265\n",
      "Epoch 69/200, Iteration 12/25, Loss: 0.0194\n",
      "Epoch 69/200, Iteration 13/25, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 14/25, Loss: 0.0166\n",
      "Epoch 69/200, Iteration 15/25, Loss: 0.0171\n",
      "Epoch 69/200, Iteration 16/25, Loss: 0.0218\n",
      "Epoch 69/200, Iteration 17/25, Loss: 0.0210\n",
      "Epoch 69/200, Iteration 18/25, Loss: 0.0221\n",
      "Epoch 69/200, Iteration 19/25, Loss: 0.0185\n",
      "Epoch 69/200, Iteration 20/25, Loss: 0.0194\n",
      "Epoch 69/200, Iteration 21/25, Loss: 0.0207\n",
      "Epoch 69/200, Iteration 22/25, Loss: 0.0180\n",
      "Epoch 69/200, Iteration 23/25, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 24/25, Loss: 0.0170\n",
      "Epoch 69/200, Iteration 25/25, Loss: 0.0176\n",
      "Train Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.015443, MRE: 0.620923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.015317, MRE: 1.120394 \n",
      "\n",
      "Epoch 70/200, Iteration 1/25, Loss: 0.0197\n",
      "Epoch 70/200, Iteration 2/25, Loss: 0.0177\n",
      "Epoch 70/200, Iteration 3/25, Loss: 0.0183\n",
      "Epoch 70/200, Iteration 4/25, Loss: 0.0152\n",
      "Epoch 70/200, Iteration 5/25, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 6/25, Loss: 0.0187\n",
      "Epoch 70/200, Iteration 7/25, Loss: 0.0200\n",
      "Epoch 70/200, Iteration 8/25, Loss: 0.0258\n",
      "Epoch 70/200, Iteration 9/25, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 10/25, Loss: 0.0155\n",
      "Epoch 70/200, Iteration 11/25, Loss: 0.0276\n",
      "Epoch 70/200, Iteration 12/25, Loss: 0.0418\n",
      "Epoch 70/200, Iteration 13/25, Loss: 0.0092\n",
      "Epoch 70/200, Iteration 14/25, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 15/25, Loss: 0.0192\n",
      "Epoch 70/200, Iteration 16/25, Loss: 0.0125\n",
      "Epoch 70/200, Iteration 17/25, Loss: 0.0110\n",
      "Epoch 70/200, Iteration 18/25, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 19/25, Loss: 0.0305\n",
      "Epoch 70/200, Iteration 20/25, Loss: 0.0247\n",
      "Epoch 70/200, Iteration 21/25, Loss: 0.0213\n",
      "Epoch 70/200, Iteration 22/25, Loss: 0.0156\n",
      "Epoch 70/200, Iteration 23/25, Loss: 0.0184\n",
      "Epoch 70/200, Iteration 24/25, Loss: 0.0155\n",
      "Epoch 70/200, Iteration 25/25, Loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 75.12%, Avg loss: 0.013454, MRE: 0.814842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.014029, MRE: 2.613865 \n",
      "\n",
      "Epoch 71/200, Iteration 1/25, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 2/25, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 3/25, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 4/25, Loss: 0.0163\n",
      "Epoch 71/200, Iteration 5/25, Loss: 0.0156\n",
      "Epoch 71/200, Iteration 6/25, Loss: 0.0129\n",
      "Epoch 71/200, Iteration 7/25, Loss: 0.0181\n",
      "Epoch 71/200, Iteration 8/25, Loss: 0.0122\n",
      "Epoch 71/200, Iteration 9/25, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 10/25, Loss: 0.0148\n",
      "Epoch 71/200, Iteration 11/25, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 12/25, Loss: 0.0180\n",
      "Epoch 71/200, Iteration 13/25, Loss: 0.0099\n",
      "Epoch 71/200, Iteration 14/25, Loss: 0.0248\n",
      "Epoch 71/200, Iteration 15/25, Loss: 0.0246\n",
      "Epoch 71/200, Iteration 16/25, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 17/25, Loss: 0.0237\n",
      "Epoch 71/200, Iteration 18/25, Loss: 0.0115\n",
      "Epoch 71/200, Iteration 19/25, Loss: 0.0155\n",
      "Epoch 71/200, Iteration 20/25, Loss: 0.0075\n",
      "Epoch 71/200, Iteration 21/25, Loss: 0.0095\n",
      "Epoch 71/200, Iteration 22/25, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 23/25, Loss: 0.0142\n",
      "Epoch 71/200, Iteration 24/25, Loss: 0.0367\n",
      "Epoch 71/200, Iteration 25/25, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 90.25%, Avg loss: 0.008948, MRE: 0.491420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.010002, MRE: 1.439849 \n",
      "\n",
      "Epoch 72/200, Iteration 1/25, Loss: 0.0187\n",
      "Epoch 72/200, Iteration 2/25, Loss: 0.0137\n",
      "Epoch 72/200, Iteration 3/25, Loss: 0.0097\n",
      "Epoch 72/200, Iteration 4/25, Loss: 0.0193\n",
      "Epoch 72/200, Iteration 5/25, Loss: 0.0177\n",
      "Epoch 72/200, Iteration 6/25, Loss: 0.0158\n",
      "Epoch 72/200, Iteration 7/25, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 8/25, Loss: 0.0072\n",
      "Epoch 72/200, Iteration 9/25, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 10/25, Loss: 0.0104\n",
      "Epoch 72/200, Iteration 11/25, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 12/25, Loss: 0.0214\n",
      "Epoch 72/200, Iteration 13/25, Loss: 0.0150\n",
      "Epoch 72/200, Iteration 14/25, Loss: 0.0110\n",
      "Epoch 72/200, Iteration 15/25, Loss: 0.0103\n",
      "Epoch 72/200, Iteration 16/25, Loss: 0.0184\n",
      "Epoch 72/200, Iteration 17/25, Loss: 0.0259\n",
      "Epoch 72/200, Iteration 18/25, Loss: 0.0161\n",
      "Epoch 72/200, Iteration 19/25, Loss: 0.0163\n",
      "Epoch 72/200, Iteration 20/25, Loss: 0.0124\n",
      "Epoch 72/200, Iteration 21/25, Loss: 0.0271\n",
      "Epoch 72/200, Iteration 22/25, Loss: 0.0117\n",
      "Epoch 72/200, Iteration 23/25, Loss: 0.0103\n",
      "Epoch 72/200, Iteration 24/25, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 25/25, Loss: 0.0245\n",
      "Train Error: \n",
      " Accuracy: 86.75%, Avg loss: 0.008142, MRE: 0.446456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.009966, MRE: 0.750560 \n",
      "\n",
      "Epoch 73/200, Iteration 1/25, Loss: 0.0140\n",
      "Epoch 73/200, Iteration 2/25, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 3/25, Loss: 0.0216\n",
      "Epoch 73/200, Iteration 4/25, Loss: 0.0115\n",
      "Epoch 73/200, Iteration 5/25, Loss: 0.0123\n",
      "Epoch 73/200, Iteration 6/25, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 7/25, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 8/25, Loss: 0.0254\n",
      "Epoch 73/200, Iteration 9/25, Loss: 0.0152\n",
      "Epoch 73/200, Iteration 10/25, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 11/25, Loss: 0.0199\n",
      "Epoch 73/200, Iteration 12/25, Loss: 0.0165\n",
      "Epoch 73/200, Iteration 13/25, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 14/25, Loss: 0.0091\n",
      "Epoch 73/200, Iteration 15/25, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 16/25, Loss: 0.0106\n",
      "Epoch 73/200, Iteration 17/25, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 18/25, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 19/25, Loss: 0.0106\n",
      "Epoch 73/200, Iteration 20/25, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 21/25, Loss: 0.0158\n",
      "Epoch 73/200, Iteration 22/25, Loss: 0.0154\n",
      "Epoch 73/200, Iteration 23/25, Loss: 0.0139\n",
      "Epoch 73/200, Iteration 24/25, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 25/25, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007872, MRE: 0.389704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.009287, MRE: 1.208344 \n",
      "\n",
      "Epoch 74/200, Iteration 1/25, Loss: 0.0255\n",
      "Epoch 74/200, Iteration 2/25, Loss: 0.0095\n",
      "Epoch 74/200, Iteration 3/25, Loss: 0.0139\n",
      "Epoch 74/200, Iteration 4/25, Loss: 0.0071\n",
      "Epoch 74/200, Iteration 5/25, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 6/25, Loss: 0.0301\n",
      "Epoch 74/200, Iteration 7/25, Loss: 0.0101\n",
      "Epoch 74/200, Iteration 8/25, Loss: 0.0129\n",
      "Epoch 74/200, Iteration 9/25, Loss: 0.0168\n",
      "Epoch 74/200, Iteration 10/25, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 11/25, Loss: 0.0072\n",
      "Epoch 74/200, Iteration 12/25, Loss: 0.0142\n",
      "Epoch 74/200, Iteration 13/25, Loss: 0.0277\n",
      "Epoch 74/200, Iteration 14/25, Loss: 0.0155\n",
      "Epoch 74/200, Iteration 15/25, Loss: 0.0116\n",
      "Epoch 74/200, Iteration 16/25, Loss: 0.0306\n",
      "Epoch 74/200, Iteration 17/25, Loss: 0.0443\n",
      "Epoch 74/200, Iteration 18/25, Loss: 0.0177\n",
      "Epoch 74/200, Iteration 19/25, Loss: 0.0119\n",
      "Epoch 74/200, Iteration 20/25, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 21/25, Loss: 0.0212\n",
      "Epoch 74/200, Iteration 22/25, Loss: 0.0087\n",
      "Epoch 74/200, Iteration 23/25, Loss: 0.0113\n",
      "Epoch 74/200, Iteration 24/25, Loss: 0.0164\n",
      "Epoch 74/200, Iteration 25/25, Loss: 0.0173\n",
      "Train Error: \n",
      " Accuracy: 91.38%, Avg loss: 0.007162, MRE: 0.402461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.009085, MRE: 1.029047 \n",
      "\n",
      "Epoch 75/200, Iteration 1/25, Loss: 0.0218\n",
      "Epoch 75/200, Iteration 2/25, Loss: 0.0167\n",
      "Epoch 75/200, Iteration 3/25, Loss: 0.0108\n",
      "Epoch 75/200, Iteration 4/25, Loss: 0.0185\n",
      "Epoch 75/200, Iteration 5/25, Loss: 0.0191\n",
      "Epoch 75/200, Iteration 6/25, Loss: 0.0141\n",
      "Epoch 75/200, Iteration 7/25, Loss: 0.0290\n",
      "Epoch 75/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 75/200, Iteration 9/25, Loss: 0.0117\n",
      "Epoch 75/200, Iteration 10/25, Loss: 0.0127\n",
      "Epoch 75/200, Iteration 11/25, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 12/25, Loss: 0.0091\n",
      "Epoch 75/200, Iteration 13/25, Loss: 0.0141\n",
      "Epoch 75/200, Iteration 14/25, Loss: 0.0080\n",
      "Epoch 75/200, Iteration 15/25, Loss: 0.0179\n",
      "Epoch 75/200, Iteration 16/25, Loss: 0.0142\n",
      "Epoch 75/200, Iteration 17/25, Loss: 0.0096\n",
      "Epoch 75/200, Iteration 18/25, Loss: 0.0135\n",
      "Epoch 75/200, Iteration 19/25, Loss: 0.0306\n",
      "Epoch 75/200, Iteration 20/25, Loss: 0.0232\n",
      "Epoch 75/200, Iteration 21/25, Loss: 0.0099\n",
      "Epoch 75/200, Iteration 22/25, Loss: 0.0371\n",
      "Epoch 75/200, Iteration 23/25, Loss: 0.0077\n",
      "Epoch 75/200, Iteration 24/25, Loss: 0.0259\n",
      "Epoch 75/200, Iteration 25/25, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 90.12%, Avg loss: 0.008157, MRE: 0.459849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.009486, MRE: 1.603300 \n",
      "\n",
      "Epoch 76/200, Iteration 1/25, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 2/25, Loss: 0.0243\n",
      "Epoch 76/200, Iteration 3/25, Loss: 0.0284\n",
      "Epoch 76/200, Iteration 4/25, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 5/25, Loss: 0.0136\n",
      "Epoch 76/200, Iteration 6/25, Loss: 0.0258\n",
      "Epoch 76/200, Iteration 7/25, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 8/25, Loss: 0.0154\n",
      "Epoch 76/200, Iteration 9/25, Loss: 0.0081\n",
      "Epoch 76/200, Iteration 10/25, Loss: 0.0092\n",
      "Epoch 76/200, Iteration 11/25, Loss: 0.0105\n",
      "Epoch 76/200, Iteration 12/25, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 13/25, Loss: 0.0207\n",
      "Epoch 76/200, Iteration 14/25, Loss: 0.0170\n",
      "Epoch 76/200, Iteration 15/25, Loss: 0.0294\n",
      "Epoch 76/200, Iteration 16/25, Loss: 0.0091\n",
      "Epoch 76/200, Iteration 17/25, Loss: 0.0189\n",
      "Epoch 76/200, Iteration 18/25, Loss: 0.0350\n",
      "Epoch 76/200, Iteration 19/25, Loss: 0.0243\n",
      "Epoch 76/200, Iteration 20/25, Loss: 0.0231\n",
      "Epoch 76/200, Iteration 21/25, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 22/25, Loss: 0.0138\n",
      "Epoch 76/200, Iteration 23/25, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 24/25, Loss: 0.0161\n",
      "Epoch 76/200, Iteration 25/25, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007657, MRE: 0.390452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.009269, MRE: 0.720209 \n",
      "\n",
      "Epoch 77/200, Iteration 1/25, Loss: 0.0118\n",
      "Epoch 77/200, Iteration 2/25, Loss: 0.0259\n",
      "Epoch 77/200, Iteration 3/25, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 4/25, Loss: 0.0243\n",
      "Epoch 77/200, Iteration 5/25, Loss: 0.0087\n",
      "Epoch 77/200, Iteration 6/25, Loss: 0.0140\n",
      "Epoch 77/200, Iteration 7/25, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 9/25, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 10/25, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 11/25, Loss: 0.0050\n",
      "Epoch 77/200, Iteration 12/25, Loss: 0.0096\n",
      "Epoch 77/200, Iteration 13/25, Loss: 0.0079\n",
      "Epoch 77/200, Iteration 14/25, Loss: 0.0136\n",
      "Epoch 77/200, Iteration 15/25, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 16/25, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 17/25, Loss: 0.0195\n",
      "Epoch 77/200, Iteration 18/25, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 19/25, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 20/25, Loss: 0.0102\n",
      "Epoch 77/200, Iteration 21/25, Loss: 0.0154\n",
      "Epoch 77/200, Iteration 22/25, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 23/25, Loss: 0.0186\n",
      "Epoch 77/200, Iteration 24/25, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 25/25, Loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.88%, Avg loss: 0.006718, MRE: 0.354620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.008523, MRE: 0.801095 \n",
      "\n",
      "Epoch 78/200, Iteration 1/25, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 2/25, Loss: 0.0166\n",
      "Epoch 78/200, Iteration 3/25, Loss: 0.0100\n",
      "Epoch 78/200, Iteration 4/25, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 5/25, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 6/25, Loss: 0.0180\n",
      "Epoch 78/200, Iteration 7/25, Loss: 0.0103\n",
      "Epoch 78/200, Iteration 8/25, Loss: 0.0329\n",
      "Epoch 78/200, Iteration 9/25, Loss: 0.0203\n",
      "Epoch 78/200, Iteration 10/25, Loss: 0.0243\n",
      "Epoch 78/200, Iteration 11/25, Loss: 0.0096\n",
      "Epoch 78/200, Iteration 12/25, Loss: 0.0144\n",
      "Epoch 78/200, Iteration 13/25, Loss: 0.0207\n",
      "Epoch 78/200, Iteration 14/25, Loss: 0.0288\n",
      "Epoch 78/200, Iteration 15/25, Loss: 0.0261\n",
      "Epoch 78/200, Iteration 16/25, Loss: 0.0151\n",
      "Epoch 78/200, Iteration 17/25, Loss: 0.0129\n",
      "Epoch 78/200, Iteration 18/25, Loss: 0.0113\n",
      "Epoch 78/200, Iteration 19/25, Loss: 0.0158\n",
      "Epoch 78/200, Iteration 20/25, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 21/25, Loss: 0.0098\n",
      "Epoch 78/200, Iteration 22/25, Loss: 0.0118\n",
      "Epoch 78/200, Iteration 23/25, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 24/25, Loss: 0.0206\n",
      "Epoch 78/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 87.25%, Avg loss: 0.007414, MRE: 0.419598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.009007, MRE: 0.829009 \n",
      "\n",
      "Epoch 79/200, Iteration 1/25, Loss: 0.0080\n",
      "Epoch 79/200, Iteration 2/25, Loss: 0.0129\n",
      "Epoch 79/200, Iteration 3/25, Loss: 0.0090\n",
      "Epoch 79/200, Iteration 4/25, Loss: 0.0118\n",
      "Epoch 79/200, Iteration 5/25, Loss: 0.0116\n",
      "Epoch 79/200, Iteration 6/25, Loss: 0.0203\n",
      "Epoch 79/200, Iteration 7/25, Loss: 0.0161\n",
      "Epoch 79/200, Iteration 8/25, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 9/25, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 10/25, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 11/25, Loss: 0.0150\n",
      "Epoch 79/200, Iteration 12/25, Loss: 0.0121\n",
      "Epoch 79/200, Iteration 13/25, Loss: 0.0289\n",
      "Epoch 79/200, Iteration 14/25, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 15/25, Loss: 0.0138\n",
      "Epoch 79/200, Iteration 16/25, Loss: 0.0088\n",
      "Epoch 79/200, Iteration 17/25, Loss: 0.0105\n",
      "Epoch 79/200, Iteration 18/25, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 19/25, Loss: 0.0267\n",
      "Epoch 79/200, Iteration 20/25, Loss: 0.0073\n",
      "Epoch 79/200, Iteration 21/25, Loss: 0.0310\n",
      "Epoch 79/200, Iteration 22/25, Loss: 0.0221\n",
      "Epoch 79/200, Iteration 23/25, Loss: 0.0181\n",
      "Epoch 79/200, Iteration 24/25, Loss: 0.0132\n",
      "Epoch 79/200, Iteration 25/25, Loss: 0.0138\n",
      "Train Error: \n",
      " Accuracy: 92.25%, Avg loss: 0.008442, MRE: 0.403353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.010825, MRE: 1.244495 \n",
      "\n",
      "Epoch 80/200, Iteration 1/25, Loss: 0.0111\n",
      "Epoch 80/200, Iteration 2/25, Loss: 0.0125\n",
      "Epoch 80/200, Iteration 3/25, Loss: 0.0124\n",
      "Epoch 80/200, Iteration 4/25, Loss: 0.0098\n",
      "Epoch 80/200, Iteration 5/25, Loss: 0.0349\n",
      "Epoch 80/200, Iteration 6/25, Loss: 0.0145\n",
      "Epoch 80/200, Iteration 7/25, Loss: 0.0119\n",
      "Epoch 80/200, Iteration 8/25, Loss: 0.0132\n",
      "Epoch 80/200, Iteration 9/25, Loss: 0.0159\n",
      "Epoch 80/200, Iteration 10/25, Loss: 0.0108\n",
      "Epoch 80/200, Iteration 11/25, Loss: 0.0139\n",
      "Epoch 80/200, Iteration 12/25, Loss: 0.0119\n",
      "Epoch 80/200, Iteration 13/25, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 14/25, Loss: 0.0083\n",
      "Epoch 80/200, Iteration 15/25, Loss: 0.0083\n",
      "Epoch 80/200, Iteration 16/25, Loss: 0.0105\n",
      "Epoch 80/200, Iteration 17/25, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 18/25, Loss: 0.0217\n",
      "Epoch 80/200, Iteration 19/25, Loss: 0.0218\n",
      "Epoch 80/200, Iteration 20/25, Loss: 0.0312\n",
      "Epoch 80/200, Iteration 21/25, Loss: 0.0140\n",
      "Epoch 80/200, Iteration 22/25, Loss: 0.0179\n",
      "Epoch 80/200, Iteration 23/25, Loss: 0.0267\n",
      "Epoch 80/200, Iteration 24/25, Loss: 0.0253\n",
      "Epoch 80/200, Iteration 25/25, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 91.75%, Avg loss: 0.007693, MRE: 0.374427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.009528, MRE: 1.276610 \n",
      "\n",
      "Epoch 81/200, Iteration 1/25, Loss: 0.0070\n",
      "Epoch 81/200, Iteration 2/25, Loss: 0.0124\n",
      "Epoch 81/200, Iteration 3/25, Loss: 0.0168\n",
      "Epoch 81/200, Iteration 4/25, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 5/25, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 6/25, Loss: 0.0113\n",
      "Epoch 81/200, Iteration 7/25, Loss: 0.0276\n",
      "Epoch 81/200, Iteration 8/25, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 9/25, Loss: 0.0220\n",
      "Epoch 81/200, Iteration 10/25, Loss: 0.0119\n",
      "Epoch 81/200, Iteration 11/25, Loss: 0.0133\n",
      "Epoch 81/200, Iteration 12/25, Loss: 0.0117\n",
      "Epoch 81/200, Iteration 13/25, Loss: 0.0097\n",
      "Epoch 81/200, Iteration 14/25, Loss: 0.0154\n",
      "Epoch 81/200, Iteration 15/25, Loss: 0.0121\n",
      "Epoch 81/200, Iteration 16/25, Loss: 0.0083\n",
      "Epoch 81/200, Iteration 17/25, Loss: 0.0257\n",
      "Epoch 81/200, Iteration 18/25, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 19/25, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 20/25, Loss: 0.0189\n",
      "Epoch 81/200, Iteration 21/25, Loss: 0.0153\n",
      "Epoch 81/200, Iteration 22/25, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 23/25, Loss: 0.0248\n",
      "Epoch 81/200, Iteration 24/25, Loss: 0.0093\n",
      "Epoch 81/200, Iteration 25/25, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.007712, MRE: 0.380211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.009357, MRE: 1.640244 \n",
      "\n",
      "Epoch 82/200, Iteration 1/25, Loss: 0.0248\n",
      "Epoch 82/200, Iteration 2/25, Loss: 0.0210\n",
      "Epoch 82/200, Iteration 3/25, Loss: 0.0111\n",
      "Epoch 82/200, Iteration 4/25, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 5/25, Loss: 0.0068\n",
      "Epoch 82/200, Iteration 6/25, Loss: 0.0165\n",
      "Epoch 82/200, Iteration 7/25, Loss: 0.0060\n",
      "Epoch 82/200, Iteration 8/25, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 9/25, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 10/25, Loss: 0.0072\n",
      "Epoch 82/200, Iteration 11/25, Loss: 0.0160\n",
      "Epoch 82/200, Iteration 12/25, Loss: 0.0085\n",
      "Epoch 82/200, Iteration 13/25, Loss: 0.0105\n",
      "Epoch 82/200, Iteration 14/25, Loss: 0.0074\n",
      "Epoch 82/200, Iteration 15/25, Loss: 0.0386\n",
      "Epoch 82/200, Iteration 16/25, Loss: 0.0270\n",
      "Epoch 82/200, Iteration 17/25, Loss: 0.0133\n",
      "Epoch 82/200, Iteration 18/25, Loss: 0.0131\n",
      "Epoch 82/200, Iteration 19/25, Loss: 0.0122\n",
      "Epoch 82/200, Iteration 20/25, Loss: 0.0135\n",
      "Epoch 82/200, Iteration 21/25, Loss: 0.0103\n",
      "Epoch 82/200, Iteration 22/25, Loss: 0.0093\n",
      "Epoch 82/200, Iteration 23/25, Loss: 0.0120\n",
      "Epoch 82/200, Iteration 24/25, Loss: 0.0090\n",
      "Epoch 82/200, Iteration 25/25, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.008884, MRE: 0.405913 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.010070, MRE: 1.566494 \n",
      "\n",
      "Epoch 83/200, Iteration 1/25, Loss: 0.0237\n",
      "Epoch 83/200, Iteration 2/25, Loss: 0.0168\n",
      "Epoch 83/200, Iteration 3/25, Loss: 0.0181\n",
      "Epoch 83/200, Iteration 4/25, Loss: 0.0300\n",
      "Epoch 83/200, Iteration 5/25, Loss: 0.0112\n",
      "Epoch 83/200, Iteration 6/25, Loss: 0.0179\n",
      "Epoch 83/200, Iteration 7/25, Loss: 0.0192\n",
      "Epoch 83/200, Iteration 8/25, Loss: 0.0302\n",
      "Epoch 83/200, Iteration 9/25, Loss: 0.0073\n",
      "Epoch 83/200, Iteration 10/25, Loss: 0.0190\n",
      "Epoch 83/200, Iteration 11/25, Loss: 0.0173\n",
      "Epoch 83/200, Iteration 12/25, Loss: 0.0160\n",
      "Epoch 83/200, Iteration 13/25, Loss: 0.0070\n",
      "Epoch 83/200, Iteration 14/25, Loss: 0.0216\n",
      "Epoch 83/200, Iteration 15/25, Loss: 0.0206\n",
      "Epoch 83/200, Iteration 16/25, Loss: 0.0284\n",
      "Epoch 83/200, Iteration 17/25, Loss: 0.0071\n",
      "Epoch 83/200, Iteration 18/25, Loss: 0.0098\n",
      "Epoch 83/200, Iteration 19/25, Loss: 0.0202\n",
      "Epoch 83/200, Iteration 20/25, Loss: 0.0192\n",
      "Epoch 83/200, Iteration 21/25, Loss: 0.0191\n",
      "Epoch 83/200, Iteration 22/25, Loss: 0.0136\n",
      "Epoch 83/200, Iteration 23/25, Loss: 0.0116\n",
      "Epoch 83/200, Iteration 24/25, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 25/25, Loss: 0.0235\n",
      "Train Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.007949, MRE: 0.452808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.009920, MRE: 0.733428 \n",
      "\n",
      "Epoch 84/200, Iteration 1/25, Loss: 0.0172\n",
      "Epoch 84/200, Iteration 2/25, Loss: 0.0184\n",
      "Epoch 84/200, Iteration 3/25, Loss: 0.0272\n",
      "Epoch 84/200, Iteration 4/25, Loss: 0.0303\n",
      "Epoch 84/200, Iteration 5/25, Loss: 0.0196\n",
      "Epoch 84/200, Iteration 6/25, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 7/25, Loss: 0.0126\n",
      "Epoch 84/200, Iteration 8/25, Loss: 0.0108\n",
      "Epoch 84/200, Iteration 9/25, Loss: 0.0206\n",
      "Epoch 84/200, Iteration 10/25, Loss: 0.0171\n",
      "Epoch 84/200, Iteration 11/25, Loss: 0.0100\n",
      "Epoch 84/200, Iteration 12/25, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 13/25, Loss: 0.0145\n",
      "Epoch 84/200, Iteration 14/25, Loss: 0.0149\n",
      "Epoch 84/200, Iteration 15/25, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 16/25, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 17/25, Loss: 0.0081\n",
      "Epoch 84/200, Iteration 18/25, Loss: 0.0132\n",
      "Epoch 84/200, Iteration 19/25, Loss: 0.0104\n",
      "Epoch 84/200, Iteration 20/25, Loss: 0.0154\n",
      "Epoch 84/200, Iteration 21/25, Loss: 0.0183\n",
      "Epoch 84/200, Iteration 22/25, Loss: 0.0146\n",
      "Epoch 84/200, Iteration 23/25, Loss: 0.0072\n",
      "Epoch 84/200, Iteration 24/25, Loss: 0.0155\n",
      "Epoch 84/200, Iteration 25/25, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 82.38%, Avg loss: 0.007728, MRE: 0.415353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.009332, MRE: 0.464862 \n",
      "\n",
      "Epoch 85/200, Iteration 1/25, Loss: 0.0178\n",
      "Epoch 85/200, Iteration 2/25, Loss: 0.0252\n",
      "Epoch 85/200, Iteration 3/25, Loss: 0.0176\n",
      "Epoch 85/200, Iteration 4/25, Loss: 0.0201\n",
      "Epoch 85/200, Iteration 5/25, Loss: 0.0148\n",
      "Epoch 85/200, Iteration 6/25, Loss: 0.0206\n",
      "Epoch 85/200, Iteration 7/25, Loss: 0.0152\n",
      "Epoch 85/200, Iteration 8/25, Loss: 0.0141\n",
      "Epoch 85/200, Iteration 9/25, Loss: 0.0138\n",
      "Epoch 85/200, Iteration 10/25, Loss: 0.0112\n",
      "Epoch 85/200, Iteration 11/25, Loss: 0.0145\n",
      "Epoch 85/200, Iteration 12/25, Loss: 0.0170\n",
      "Epoch 85/200, Iteration 13/25, Loss: 0.0128\n",
      "Epoch 85/200, Iteration 14/25, Loss: 0.0088\n",
      "Epoch 85/200, Iteration 15/25, Loss: 0.0097\n",
      "Epoch 85/200, Iteration 16/25, Loss: 0.0158\n",
      "Epoch 85/200, Iteration 17/25, Loss: 0.0191\n",
      "Epoch 85/200, Iteration 18/25, Loss: 0.0146\n",
      "Epoch 85/200, Iteration 19/25, Loss: 0.0215\n",
      "Epoch 85/200, Iteration 20/25, Loss: 0.0088\n",
      "Epoch 85/200, Iteration 21/25, Loss: 0.0132\n",
      "Epoch 85/200, Iteration 22/25, Loss: 0.0115\n",
      "Epoch 85/200, Iteration 23/25, Loss: 0.0142\n",
      "Epoch 85/200, Iteration 24/25, Loss: 0.0132\n",
      "Epoch 85/200, Iteration 25/25, Loss: 0.0102\n",
      "Train Error: \n",
      " Accuracy: 93.25%, Avg loss: 0.006956, MRE: 0.387045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.008959, MRE: 0.607899 \n",
      "\n",
      "Epoch 86/200, Iteration 1/25, Loss: 0.0198\n",
      "Epoch 86/200, Iteration 2/25, Loss: 0.0316\n",
      "Epoch 86/200, Iteration 3/25, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 4/25, Loss: 0.0099\n",
      "Epoch 86/200, Iteration 5/25, Loss: 0.0075\n",
      "Epoch 86/200, Iteration 6/25, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 7/25, Loss: 0.0094\n",
      "Epoch 86/200, Iteration 8/25, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 9/25, Loss: 0.0164\n",
      "Epoch 86/200, Iteration 10/25, Loss: 0.0197\n",
      "Epoch 86/200, Iteration 11/25, Loss: 0.0320\n",
      "Epoch 86/200, Iteration 12/25, Loss: 0.0066\n",
      "Epoch 86/200, Iteration 13/25, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 14/25, Loss: 0.0282\n",
      "Epoch 86/200, Iteration 15/25, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 16/25, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 17/25, Loss: 0.0207\n",
      "Epoch 86/200, Iteration 18/25, Loss: 0.0131\n",
      "Epoch 86/200, Iteration 19/25, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 20/25, Loss: 0.0210\n",
      "Epoch 86/200, Iteration 21/25, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 22/25, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 23/25, Loss: 0.0123\n",
      "Epoch 86/200, Iteration 24/25, Loss: 0.0186\n",
      "Epoch 86/200, Iteration 25/25, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 90.25%, Avg loss: 0.006736, MRE: 0.379853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.008653, MRE: 0.436828 \n",
      "\n",
      "Epoch 87/200, Iteration 1/25, Loss: 0.0139\n",
      "Epoch 87/200, Iteration 2/25, Loss: 0.0108\n",
      "Epoch 87/200, Iteration 3/25, Loss: 0.0255\n",
      "Epoch 87/200, Iteration 4/25, Loss: 0.0089\n",
      "Epoch 87/200, Iteration 5/25, Loss: 0.0086\n",
      "Epoch 87/200, Iteration 6/25, Loss: 0.0115\n",
      "Epoch 87/200, Iteration 7/25, Loss: 0.0362\n",
      "Epoch 87/200, Iteration 8/25, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 9/25, Loss: 0.0264\n",
      "Epoch 87/200, Iteration 10/25, Loss: 0.0114\n",
      "Epoch 87/200, Iteration 11/25, Loss: 0.0155\n",
      "Epoch 87/200, Iteration 12/25, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 13/25, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 14/25, Loss: 0.0091\n",
      "Epoch 87/200, Iteration 15/25, Loss: 0.0240\n",
      "Epoch 87/200, Iteration 16/25, Loss: 0.0116\n",
      "Epoch 87/200, Iteration 17/25, Loss: 0.0377\n",
      "Epoch 87/200, Iteration 18/25, Loss: 0.0204\n",
      "Epoch 87/200, Iteration 19/25, Loss: 0.0120\n",
      "Epoch 87/200, Iteration 20/25, Loss: 0.0102\n",
      "Epoch 87/200, Iteration 21/25, Loss: 0.0241\n",
      "Epoch 87/200, Iteration 22/25, Loss: 0.0359\n",
      "Epoch 87/200, Iteration 23/25, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 24/25, Loss: 0.0180\n",
      "Epoch 87/200, Iteration 25/25, Loss: 0.0211\n",
      "Train Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.008233, MRE: 0.490655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.009241, MRE: 1.090586 \n",
      "\n",
      "Epoch 88/200, Iteration 1/25, Loss: 0.0519\n",
      "Epoch 88/200, Iteration 2/25, Loss: 0.0171\n",
      "Epoch 88/200, Iteration 3/25, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 4/25, Loss: 0.0093\n",
      "Epoch 88/200, Iteration 5/25, Loss: 0.0077\n",
      "Epoch 88/200, Iteration 6/25, Loss: 0.0080\n",
      "Epoch 88/200, Iteration 7/25, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 8/25, Loss: 0.0197\n",
      "Epoch 88/200, Iteration 9/25, Loss: 0.0264\n",
      "Epoch 88/200, Iteration 10/25, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 11/25, Loss: 0.0168\n",
      "Epoch 88/200, Iteration 12/25, Loss: 0.0124\n",
      "Epoch 88/200, Iteration 13/25, Loss: 0.0106\n",
      "Epoch 88/200, Iteration 14/25, Loss: 0.0066\n",
      "Epoch 88/200, Iteration 15/25, Loss: 0.0278\n",
      "Epoch 88/200, Iteration 16/25, Loss: 0.0179\n",
      "Epoch 88/200, Iteration 17/25, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 18/25, Loss: 0.0128\n",
      "Epoch 88/200, Iteration 19/25, Loss: 0.0143\n",
      "Epoch 88/200, Iteration 20/25, Loss: 0.0098\n",
      "Epoch 88/200, Iteration 21/25, Loss: 0.0175\n",
      "Epoch 88/200, Iteration 22/25, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 23/25, Loss: 0.0235\n",
      "Epoch 88/200, Iteration 24/25, Loss: 0.0115\n",
      "Epoch 88/200, Iteration 25/25, Loss: 0.0120\n",
      "Train Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.006617, MRE: 0.386722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.008579, MRE: 0.752805 \n",
      "\n",
      "Epoch 89/200, Iteration 1/25, Loss: 0.0149\n",
      "Epoch 89/200, Iteration 2/25, Loss: 0.0192\n",
      "Epoch 89/200, Iteration 3/25, Loss: 0.0139\n",
      "Epoch 89/200, Iteration 4/25, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 5/25, Loss: 0.0166\n",
      "Epoch 89/200, Iteration 6/25, Loss: 0.0175\n",
      "Epoch 89/200, Iteration 7/25, Loss: 0.0214\n",
      "Epoch 89/200, Iteration 8/25, Loss: 0.0075\n",
      "Epoch 89/200, Iteration 9/25, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 10/25, Loss: 0.0125\n",
      "Epoch 89/200, Iteration 11/25, Loss: 0.0102\n",
      "Epoch 89/200, Iteration 12/25, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 13/25, Loss: 0.0153\n",
      "Epoch 89/200, Iteration 14/25, Loss: 0.0102\n",
      "Epoch 89/200, Iteration 15/25, Loss: 0.0105\n",
      "Epoch 89/200, Iteration 16/25, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 17/25, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 18/25, Loss: 0.0184\n",
      "Epoch 89/200, Iteration 19/25, Loss: 0.0204\n",
      "Epoch 89/200, Iteration 20/25, Loss: 0.0180\n",
      "Epoch 89/200, Iteration 21/25, Loss: 0.0105\n",
      "Epoch 89/200, Iteration 22/25, Loss: 0.0070\n",
      "Epoch 89/200, Iteration 23/25, Loss: 0.0157\n",
      "Epoch 89/200, Iteration 24/25, Loss: 0.0450\n",
      "Epoch 89/200, Iteration 25/25, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 71.88%, Avg loss: 0.008671, MRE: 0.513406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.010081, MRE: 1.169319 \n",
      "\n",
      "Epoch 90/200, Iteration 1/25, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 2/25, Loss: 0.0238\n",
      "Epoch 90/200, Iteration 3/25, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 4/25, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 5/25, Loss: 0.0126\n",
      "Epoch 90/200, Iteration 6/25, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 7/25, Loss: 0.0070\n",
      "Epoch 90/200, Iteration 8/25, Loss: 0.0152\n",
      "Epoch 90/200, Iteration 9/25, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 10/25, Loss: 0.0296\n",
      "Epoch 90/200, Iteration 11/25, Loss: 0.0289\n",
      "Epoch 90/200, Iteration 12/25, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 13/25, Loss: 0.0121\n",
      "Epoch 90/200, Iteration 14/25, Loss: 0.0227\n",
      "Epoch 90/200, Iteration 15/25, Loss: 0.0164\n",
      "Epoch 90/200, Iteration 16/25, Loss: 0.0116\n",
      "Epoch 90/200, Iteration 17/25, Loss: 0.0111\n",
      "Epoch 90/200, Iteration 18/25, Loss: 0.0093\n",
      "Epoch 90/200, Iteration 19/25, Loss: 0.0109\n",
      "Epoch 90/200, Iteration 20/25, Loss: 0.0178\n",
      "Epoch 90/200, Iteration 21/25, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 22/25, Loss: 0.0123\n",
      "Epoch 90/200, Iteration 23/25, Loss: 0.0122\n",
      "Epoch 90/200, Iteration 24/25, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 25/25, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 89.12%, Avg loss: 0.006492, MRE: 0.335926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.007962, MRE: 0.630236 \n",
      "\n",
      "Epoch 91/200, Iteration 1/25, Loss: 0.0179\n",
      "Epoch 91/200, Iteration 2/25, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 3/25, Loss: 0.0183\n",
      "Epoch 91/200, Iteration 4/25, Loss: 0.0112\n",
      "Epoch 91/200, Iteration 5/25, Loss: 0.0200\n",
      "Epoch 91/200, Iteration 6/25, Loss: 0.0355\n",
      "Epoch 91/200, Iteration 7/25, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 8/25, Loss: 0.0093\n",
      "Epoch 91/200, Iteration 9/25, Loss: 0.0341\n",
      "Epoch 91/200, Iteration 10/25, Loss: 0.0209\n",
      "Epoch 91/200, Iteration 11/25, Loss: 0.0072\n",
      "Epoch 91/200, Iteration 12/25, Loss: 0.0108\n",
      "Epoch 91/200, Iteration 13/25, Loss: 0.0220\n",
      "Epoch 91/200, Iteration 14/25, Loss: 0.0102\n",
      "Epoch 91/200, Iteration 15/25, Loss: 0.0076\n",
      "Epoch 91/200, Iteration 16/25, Loss: 0.0273\n",
      "Epoch 91/200, Iteration 17/25, Loss: 0.0215\n",
      "Epoch 91/200, Iteration 18/25, Loss: 0.0138\n",
      "Epoch 91/200, Iteration 19/25, Loss: 0.0326\n",
      "Epoch 91/200, Iteration 20/25, Loss: 0.0155\n",
      "Epoch 91/200, Iteration 21/25, Loss: 0.0167\n",
      "Epoch 91/200, Iteration 22/25, Loss: 0.0135\n",
      "Epoch 91/200, Iteration 23/25, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Iteration 24/25, Loss: 0.0124\n",
      "Epoch 91/200, Iteration 25/25, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.008537, MRE: 0.353076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.011039, MRE: 1.217740 \n",
      "\n",
      "Epoch 92/200, Iteration 1/25, Loss: 0.0176\n",
      "Epoch 92/200, Iteration 2/25, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 3/25, Loss: 0.0118\n",
      "Epoch 92/200, Iteration 4/25, Loss: 0.0141\n",
      "Epoch 92/200, Iteration 5/25, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 6/25, Loss: 0.0229\n",
      "Epoch 92/200, Iteration 7/25, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 8/25, Loss: 0.0169\n",
      "Epoch 92/200, Iteration 9/25, Loss: 0.0331\n",
      "Epoch 92/200, Iteration 10/25, Loss: 0.0259\n",
      "Epoch 92/200, Iteration 11/25, Loss: 0.0276\n",
      "Epoch 92/200, Iteration 12/25, Loss: 0.0154\n",
      "Epoch 92/200, Iteration 13/25, Loss: 0.0143\n",
      "Epoch 92/200, Iteration 14/25, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 15/25, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 16/25, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 17/25, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 18/25, Loss: 0.0134\n",
      "Epoch 92/200, Iteration 19/25, Loss: 0.0337\n",
      "Epoch 92/200, Iteration 20/25, Loss: 0.0165\n",
      "Epoch 92/200, Iteration 21/25, Loss: 0.0140\n",
      "Epoch 92/200, Iteration 22/25, Loss: 0.0235\n",
      "Epoch 92/200, Iteration 23/25, Loss: 0.0134\n",
      "Epoch 92/200, Iteration 24/25, Loss: 0.0349\n",
      "Epoch 92/200, Iteration 25/25, Loss: 0.0364\n",
      "Train Error: \n",
      " Accuracy: 57.12%, Avg loss: 0.010180, MRE: 0.577046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.011573, MRE: 0.737994 \n",
      "\n",
      "Epoch 93/200, Iteration 1/25, Loss: 0.0316\n",
      "Epoch 93/200, Iteration 2/25, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 3/25, Loss: 0.0085\n",
      "Epoch 93/200, Iteration 4/25, Loss: 0.0145\n",
      "Epoch 93/200, Iteration 5/25, Loss: 0.0105\n",
      "Epoch 93/200, Iteration 6/25, Loss: 0.0115\n",
      "Epoch 93/200, Iteration 7/25, Loss: 0.0153\n",
      "Epoch 93/200, Iteration 8/25, Loss: 0.0168\n",
      "Epoch 93/200, Iteration 9/25, Loss: 0.0132\n",
      "Epoch 93/200, Iteration 10/25, Loss: 0.0278\n",
      "Epoch 93/200, Iteration 11/25, Loss: 0.0187\n",
      "Epoch 93/200, Iteration 12/25, Loss: 0.0218\n",
      "Epoch 93/200, Iteration 13/25, Loss: 0.0156\n",
      "Epoch 93/200, Iteration 14/25, Loss: 0.0289\n",
      "Epoch 93/200, Iteration 15/25, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 16/25, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 17/25, Loss: 0.0089\n",
      "Epoch 93/200, Iteration 18/25, Loss: 0.0283\n",
      "Epoch 93/200, Iteration 19/25, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 20/25, Loss: 0.0079\n",
      "Epoch 93/200, Iteration 21/25, Loss: 0.0218\n",
      "Epoch 93/200, Iteration 22/25, Loss: 0.0307\n",
      "Epoch 93/200, Iteration 23/25, Loss: 0.0168\n",
      "Epoch 93/200, Iteration 24/25, Loss: 0.0172\n",
      "Epoch 93/200, Iteration 25/25, Loss: 0.0121\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.006822, MRE: 0.408835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.008817, MRE: 0.720908 \n",
      "\n",
      "Epoch 94/200, Iteration 1/25, Loss: 0.0122\n",
      "Epoch 94/200, Iteration 2/25, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 3/25, Loss: 0.0155\n",
      "Epoch 94/200, Iteration 4/25, Loss: 0.0127\n",
      "Epoch 94/200, Iteration 5/25, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 6/25, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 7/25, Loss: 0.0345\n",
      "Epoch 94/200, Iteration 8/25, Loss: 0.0134\n",
      "Epoch 94/200, Iteration 9/25, Loss: 0.0139\n",
      "Epoch 94/200, Iteration 10/25, Loss: 0.0062\n",
      "Epoch 94/200, Iteration 11/25, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 12/25, Loss: 0.0161\n",
      "Epoch 94/200, Iteration 13/25, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 14/25, Loss: 0.0094\n",
      "Epoch 94/200, Iteration 15/25, Loss: 0.0181\n",
      "Epoch 94/200, Iteration 16/25, Loss: 0.0200\n",
      "Epoch 94/200, Iteration 17/25, Loss: 0.0143\n",
      "Epoch 94/200, Iteration 18/25, Loss: 0.0329\n",
      "Epoch 94/200, Iteration 19/25, Loss: 0.0180\n",
      "Epoch 94/200, Iteration 20/25, Loss: 0.0097\n",
      "Epoch 94/200, Iteration 21/25, Loss: 0.0132\n",
      "Epoch 94/200, Iteration 22/25, Loss: 0.0129\n",
      "Epoch 94/200, Iteration 23/25, Loss: 0.0201\n",
      "Epoch 94/200, Iteration 24/25, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 25/25, Loss: 0.0169\n",
      "Train Error: \n",
      " Accuracy: 81.38%, Avg loss: 0.008298, MRE: 0.573853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.009796, MRE: 0.658622 \n",
      "\n",
      "Epoch 95/200, Iteration 1/25, Loss: 0.0100\n",
      "Epoch 95/200, Iteration 2/25, Loss: 0.0102\n",
      "Epoch 95/200, Iteration 3/25, Loss: 0.0150\n",
      "Epoch 95/200, Iteration 4/25, Loss: 0.0100\n",
      "Epoch 95/200, Iteration 5/25, Loss: 0.0132\n",
      "Epoch 95/200, Iteration 6/25, Loss: 0.0317\n",
      "Epoch 95/200, Iteration 7/25, Loss: 0.0089\n",
      "Epoch 95/200, Iteration 8/25, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 9/25, Loss: 0.0115\n",
      "Epoch 95/200, Iteration 10/25, Loss: 0.0132\n",
      "Epoch 95/200, Iteration 11/25, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 12/25, Loss: 0.0302\n",
      "Epoch 95/200, Iteration 13/25, Loss: 0.0167\n",
      "Epoch 95/200, Iteration 14/25, Loss: 0.0119\n",
      "Epoch 95/200, Iteration 15/25, Loss: 0.0174\n",
      "Epoch 95/200, Iteration 16/25, Loss: 0.0349\n",
      "Epoch 95/200, Iteration 17/25, Loss: 0.0067\n",
      "Epoch 95/200, Iteration 18/25, Loss: 0.0083\n",
      "Epoch 95/200, Iteration 19/25, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 20/25, Loss: 0.0166\n",
      "Epoch 95/200, Iteration 21/25, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 22/25, Loss: 0.0191\n",
      "Epoch 95/200, Iteration 23/25, Loss: 0.0239\n",
      "Epoch 95/200, Iteration 24/25, Loss: 0.0204\n",
      "Epoch 95/200, Iteration 25/25, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 78.88%, Avg loss: 0.009736, MRE: 0.509228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.010755, MRE: 2.019212 \n",
      "\n",
      "Epoch 96/200, Iteration 1/25, Loss: 0.0136\n",
      "Epoch 96/200, Iteration 2/25, Loss: 0.0130\n",
      "Epoch 96/200, Iteration 3/25, Loss: 0.0306\n",
      "Epoch 96/200, Iteration 4/25, Loss: 0.0128\n",
      "Epoch 96/200, Iteration 5/25, Loss: 0.0213\n",
      "Epoch 96/200, Iteration 6/25, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 7/25, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 8/25, Loss: 0.0148\n",
      "Epoch 96/200, Iteration 9/25, Loss: 0.0169\n",
      "Epoch 96/200, Iteration 10/25, Loss: 0.0098\n",
      "Epoch 96/200, Iteration 11/25, Loss: 0.0326\n",
      "Epoch 96/200, Iteration 12/25, Loss: 0.0167\n",
      "Epoch 96/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 96/200, Iteration 14/25, Loss: 0.0079\n",
      "Epoch 96/200, Iteration 15/25, Loss: 0.0362\n",
      "Epoch 96/200, Iteration 16/25, Loss: 0.0162\n",
      "Epoch 96/200, Iteration 17/25, Loss: 0.0190\n",
      "Epoch 96/200, Iteration 18/25, Loss: 0.0092\n",
      "Epoch 96/200, Iteration 19/25, Loss: 0.0081\n",
      "Epoch 96/200, Iteration 20/25, Loss: 0.0367\n",
      "Epoch 96/200, Iteration 21/25, Loss: 0.0205\n",
      "Epoch 96/200, Iteration 22/25, Loss: 0.0124\n",
      "Epoch 96/200, Iteration 23/25, Loss: 0.0069\n",
      "Epoch 96/200, Iteration 24/25, Loss: 0.0348\n",
      "Epoch 96/200, Iteration 25/25, Loss: 0.0204\n",
      "Train Error: \n",
      " Accuracy: 90.62%, Avg loss: 0.007177, MRE: 0.380352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.009574, MRE: 0.530127 \n",
      "\n",
      "Epoch 97/200, Iteration 1/25, Loss: 0.0129\n",
      "Epoch 97/200, Iteration 2/25, Loss: 0.0126\n",
      "Epoch 97/200, Iteration 3/25, Loss: 0.0196\n",
      "Epoch 97/200, Iteration 4/25, Loss: 0.0220\n",
      "Epoch 97/200, Iteration 5/25, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 6/25, Loss: 0.0207\n",
      "Epoch 97/200, Iteration 7/25, Loss: 0.0192\n",
      "Epoch 97/200, Iteration 8/25, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 9/25, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 97/200, Iteration 11/25, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 12/25, Loss: 0.0088\n",
      "Epoch 97/200, Iteration 13/25, Loss: 0.0113\n",
      "Epoch 97/200, Iteration 14/25, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 15/25, Loss: 0.0224\n",
      "Epoch 97/200, Iteration 16/25, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 17/25, Loss: 0.0136\n",
      "Epoch 97/200, Iteration 18/25, Loss: 0.0243\n",
      "Epoch 97/200, Iteration 19/25, Loss: 0.0130\n",
      "Epoch 97/200, Iteration 20/25, Loss: 0.0081\n",
      "Epoch 97/200, Iteration 21/25, Loss: 0.0127\n",
      "Epoch 97/200, Iteration 22/25, Loss: 0.0171\n",
      "Epoch 97/200, Iteration 23/25, Loss: 0.0211\n",
      "Epoch 97/200, Iteration 24/25, Loss: 0.0142\n",
      "Epoch 97/200, Iteration 25/25, Loss: 0.0160\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.007987, MRE: 0.466069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.009470, MRE: 1.361392 \n",
      "\n",
      "Epoch 98/200, Iteration 1/25, Loss: 0.0131\n",
      "Epoch 98/200, Iteration 2/25, Loss: 0.0205\n",
      "Epoch 98/200, Iteration 3/25, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 4/25, Loss: 0.0081\n",
      "Epoch 98/200, Iteration 5/25, Loss: 0.0191\n",
      "Epoch 98/200, Iteration 6/25, Loss: 0.0063\n",
      "Epoch 98/200, Iteration 7/25, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 8/25, Loss: 0.0097\n",
      "Epoch 98/200, Iteration 9/25, Loss: 0.0153\n",
      "Epoch 98/200, Iteration 10/25, Loss: 0.0275\n",
      "Epoch 98/200, Iteration 11/25, Loss: 0.0179\n",
      "Epoch 98/200, Iteration 12/25, Loss: 0.0228\n",
      "Epoch 98/200, Iteration 13/25, Loss: 0.0231\n",
      "Epoch 98/200, Iteration 14/25, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 15/25, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 16/25, Loss: 0.0155\n",
      "Epoch 98/200, Iteration 17/25, Loss: 0.0104\n",
      "Epoch 98/200, Iteration 18/25, Loss: 0.0170\n",
      "Epoch 98/200, Iteration 19/25, Loss: 0.0275\n",
      "Epoch 98/200, Iteration 20/25, Loss: 0.0194\n",
      "Epoch 98/200, Iteration 21/25, Loss: 0.0205\n",
      "Epoch 98/200, Iteration 22/25, Loss: 0.0102\n",
      "Epoch 98/200, Iteration 23/25, Loss: 0.0094\n",
      "Epoch 98/200, Iteration 24/25, Loss: 0.0118\n",
      "Epoch 98/200, Iteration 25/25, Loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007050, MRE: 0.343281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.009079, MRE: 1.260239 \n",
      "\n",
      "Epoch 99/200, Iteration 1/25, Loss: 0.0172\n",
      "Epoch 99/200, Iteration 2/25, Loss: 0.0332\n",
      "Epoch 99/200, Iteration 3/25, Loss: 0.0094\n",
      "Epoch 99/200, Iteration 4/25, Loss: 0.0302\n",
      "Epoch 99/200, Iteration 5/25, Loss: 0.0097\n",
      "Epoch 99/200, Iteration 6/25, Loss: 0.0356\n",
      "Epoch 99/200, Iteration 7/25, Loss: 0.0118\n",
      "Epoch 99/200, Iteration 8/25, Loss: 0.0070\n",
      "Epoch 99/200, Iteration 9/25, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 10/25, Loss: 0.0080\n",
      "Epoch 99/200, Iteration 11/25, Loss: 0.0212\n",
      "Epoch 99/200, Iteration 12/25, Loss: 0.0174\n",
      "Epoch 99/200, Iteration 13/25, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 14/25, Loss: 0.0108\n",
      "Epoch 99/200, Iteration 15/25, Loss: 0.0094\n",
      "Epoch 99/200, Iteration 16/25, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 17/25, Loss: 0.0072\n",
      "Epoch 99/200, Iteration 18/25, Loss: 0.0302\n",
      "Epoch 99/200, Iteration 19/25, Loss: 0.0081\n",
      "Epoch 99/200, Iteration 20/25, Loss: 0.0157\n",
      "Epoch 99/200, Iteration 21/25, Loss: 0.0084\n",
      "Epoch 99/200, Iteration 22/25, Loss: 0.0096\n",
      "Epoch 99/200, Iteration 23/25, Loss: 0.0200\n",
      "Epoch 99/200, Iteration 24/25, Loss: 0.0089\n",
      "Epoch 99/200, Iteration 25/25, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 87.25%, Avg loss: 0.006889, MRE: 0.301547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.008034, MRE: 1.109245 \n",
      "\n",
      "Epoch 100/200, Iteration 1/25, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 2/25, Loss: 0.0198\n",
      "Epoch 100/200, Iteration 3/25, Loss: 0.0303\n",
      "Epoch 100/200, Iteration 4/25, Loss: 0.0161\n",
      "Epoch 100/200, Iteration 5/25, Loss: 0.0083\n",
      "Epoch 100/200, Iteration 6/25, Loss: 0.0191\n",
      "Epoch 100/200, Iteration 7/25, Loss: 0.0200\n",
      "Epoch 100/200, Iteration 8/25, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 9/25, Loss: 0.0185\n",
      "Epoch 100/200, Iteration 10/25, Loss: 0.0285\n",
      "Epoch 100/200, Iteration 11/25, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 12/25, Loss: 0.0178\n",
      "Epoch 100/200, Iteration 13/25, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 14/25, Loss: 0.0238\n",
      "Epoch 100/200, Iteration 15/25, Loss: 0.0142\n",
      "Epoch 100/200, Iteration 16/25, Loss: 0.0107\n",
      "Epoch 100/200, Iteration 17/25, Loss: 0.0177\n",
      "Epoch 100/200, Iteration 18/25, Loss: 0.0182\n",
      "Epoch 100/200, Iteration 19/25, Loss: 0.0135\n",
      "Epoch 100/200, Iteration 20/25, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 21/25, Loss: 0.0126\n",
      "Epoch 100/200, Iteration 22/25, Loss: 0.0450\n",
      "Epoch 100/200, Iteration 23/25, Loss: 0.0194\n",
      "Epoch 100/200, Iteration 24/25, Loss: 0.0127\n",
      "Epoch 100/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006491, MRE: 0.358676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.007827, MRE: 0.851566 \n",
      "\n",
      "Epoch 101/200, Iteration 1/25, Loss: 0.0296\n",
      "Epoch 101/200, Iteration 2/25, Loss: 0.0091\n",
      "Epoch 101/200, Iteration 3/25, Loss: 0.0053\n",
      "Epoch 101/200, Iteration 4/25, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 5/25, Loss: 0.0110\n",
      "Epoch 101/200, Iteration 6/25, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 7/25, Loss: 0.0058\n",
      "Epoch 101/200, Iteration 8/25, Loss: 0.0074\n",
      "Epoch 101/200, Iteration 9/25, Loss: 0.0202\n",
      "Epoch 101/200, Iteration 10/25, Loss: 0.0183\n",
      "Epoch 101/200, Iteration 11/25, Loss: 0.0125\n",
      "Epoch 101/200, Iteration 12/25, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 13/25, Loss: 0.0134\n",
      "Epoch 101/200, Iteration 14/25, Loss: 0.0245\n",
      "Epoch 101/200, Iteration 15/25, Loss: 0.0260\n",
      "Epoch 101/200, Iteration 16/25, Loss: 0.0270\n",
      "Epoch 101/200, Iteration 17/25, Loss: 0.0159\n",
      "Epoch 101/200, Iteration 18/25, Loss: 0.0145\n",
      "Epoch 101/200, Iteration 19/25, Loss: 0.0147\n",
      "Epoch 101/200, Iteration 20/25, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 21/25, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 22/25, Loss: 0.0365\n",
      "Epoch 101/200, Iteration 23/25, Loss: 0.0130\n",
      "Epoch 101/200, Iteration 24/25, Loss: 0.0199\n",
      "Epoch 101/200, Iteration 25/25, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 90.62%, Avg loss: 0.006038, MRE: 0.344352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.007742, MRE: 0.861539 \n",
      "\n",
      "Epoch 102/200, Iteration 1/25, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 2/25, Loss: 0.0163\n",
      "Epoch 102/200, Iteration 3/25, Loss: 0.0231\n",
      "Epoch 102/200, Iteration 4/25, Loss: 0.0241\n",
      "Epoch 102/200, Iteration 5/25, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 6/25, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 7/25, Loss: 0.0260\n",
      "Epoch 102/200, Iteration 8/25, Loss: 0.0282\n",
      "Epoch 102/200, Iteration 9/25, Loss: 0.0172\n",
      "Epoch 102/200, Iteration 10/25, Loss: 0.0087\n",
      "Epoch 102/200, Iteration 11/25, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 12/25, Loss: 0.0239\n",
      "Epoch 102/200, Iteration 13/25, Loss: 0.0080\n",
      "Epoch 102/200, Iteration 14/25, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 15/25, Loss: 0.0082\n",
      "Epoch 102/200, Iteration 16/25, Loss: 0.0148\n",
      "Epoch 102/200, Iteration 17/25, Loss: 0.0076\n",
      "Epoch 102/200, Iteration 18/25, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 19/25, Loss: 0.0182\n",
      "Epoch 102/200, Iteration 20/25, Loss: 0.0240\n",
      "Epoch 102/200, Iteration 21/25, Loss: 0.0126\n",
      "Epoch 102/200, Iteration 22/25, Loss: 0.0173\n",
      "Epoch 102/200, Iteration 23/25, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 24/25, Loss: 0.0094\n",
      "Epoch 102/200, Iteration 25/25, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 90.12%, Avg loss: 0.006027, MRE: 0.317276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.007621, MRE: 0.829608 \n",
      "\n",
      "Epoch 103/200, Iteration 1/25, Loss: 0.0076\n",
      "Epoch 103/200, Iteration 2/25, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 3/25, Loss: 0.0204\n",
      "Epoch 103/200, Iteration 4/25, Loss: 0.0112\n",
      "Epoch 103/200, Iteration 5/25, Loss: 0.0102\n",
      "Epoch 103/200, Iteration 6/25, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 7/25, Loss: 0.0205\n",
      "Epoch 103/200, Iteration 8/25, Loss: 0.0122\n",
      "Epoch 103/200, Iteration 9/25, Loss: 0.0309\n",
      "Epoch 103/200, Iteration 10/25, Loss: 0.0194\n",
      "Epoch 103/200, Iteration 11/25, Loss: 0.0142\n",
      "Epoch 103/200, Iteration 12/25, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 13/25, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 14/25, Loss: 0.0090\n",
      "Epoch 103/200, Iteration 15/25, Loss: 0.0132\n",
      "Epoch 103/200, Iteration 16/25, Loss: 0.0165\n",
      "Epoch 103/200, Iteration 17/25, Loss: 0.0156\n",
      "Epoch 103/200, Iteration 18/25, Loss: 0.0106\n",
      "Epoch 103/200, Iteration 19/25, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 20/25, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 21/25, Loss: 0.0200\n",
      "Epoch 103/200, Iteration 22/25, Loss: 0.0127\n",
      "Epoch 103/200, Iteration 23/25, Loss: 0.0136\n",
      "Epoch 103/200, Iteration 24/25, Loss: 0.0281\n",
      "Epoch 103/200, Iteration 25/25, Loss: 0.0117\n",
      "Train Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.005909, MRE: 0.306878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.007448, MRE: 1.024935 \n",
      "\n",
      "Epoch 104/200, Iteration 1/25, Loss: 0.0166\n",
      "Epoch 104/200, Iteration 2/25, Loss: 0.0091\n",
      "Epoch 104/200, Iteration 3/25, Loss: 0.0145\n",
      "Epoch 104/200, Iteration 4/25, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 5/25, Loss: 0.0150\n",
      "Epoch 104/200, Iteration 6/25, Loss: 0.0191\n",
      "Epoch 104/200, Iteration 7/25, Loss: 0.0151\n",
      "Epoch 104/200, Iteration 8/25, Loss: 0.0206\n",
      "Epoch 104/200, Iteration 9/25, Loss: 0.0320\n",
      "Epoch 104/200, Iteration 10/25, Loss: 0.0230\n",
      "Epoch 104/200, Iteration 11/25, Loss: 0.0342\n",
      "Epoch 104/200, Iteration 12/25, Loss: 0.0152\n",
      "Epoch 104/200, Iteration 13/25, Loss: 0.0094\n",
      "Epoch 104/200, Iteration 14/25, Loss: 0.0327\n",
      "Epoch 104/200, Iteration 15/25, Loss: 0.0152\n",
      "Epoch 104/200, Iteration 16/25, Loss: 0.0263\n",
      "Epoch 104/200, Iteration 17/25, Loss: 0.0185\n",
      "Epoch 104/200, Iteration 18/25, Loss: 0.0231\n",
      "Epoch 104/200, Iteration 19/25, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 20/25, Loss: 0.0128\n",
      "Epoch 104/200, Iteration 21/25, Loss: 0.0069\n",
      "Epoch 104/200, Iteration 22/25, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 23/25, Loss: 0.0131\n",
      "Epoch 104/200, Iteration 24/25, Loss: 0.0126\n",
      "Epoch 104/200, Iteration 25/25, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.005872, MRE: 0.303043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.007730, MRE: 0.795018 \n",
      "\n",
      "Epoch 105/200, Iteration 1/25, Loss: 0.0273\n",
      "Epoch 105/200, Iteration 2/25, Loss: 0.0221\n",
      "Epoch 105/200, Iteration 3/25, Loss: 0.0237\n",
      "Epoch 105/200, Iteration 4/25, Loss: 0.0198\n",
      "Epoch 105/200, Iteration 5/25, Loss: 0.0236\n",
      "Epoch 105/200, Iteration 6/25, Loss: 0.0164\n",
      "Epoch 105/200, Iteration 7/25, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 8/25, Loss: 0.0169\n",
      "Epoch 105/200, Iteration 9/25, Loss: 0.0112\n",
      "Epoch 105/200, Iteration 10/25, Loss: 0.0141\n",
      "Epoch 105/200, Iteration 11/25, Loss: 0.0100\n",
      "Epoch 105/200, Iteration 12/25, Loss: 0.0122\n",
      "Epoch 105/200, Iteration 13/25, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 14/25, Loss: 0.0127\n",
      "Epoch 105/200, Iteration 15/25, Loss: 0.0093\n",
      "Epoch 105/200, Iteration 16/25, Loss: 0.0141\n",
      "Epoch 105/200, Iteration 17/25, Loss: 0.0149\n",
      "Epoch 105/200, Iteration 18/25, Loss: 0.0172\n",
      "Epoch 105/200, Iteration 19/25, Loss: 0.0198\n",
      "Epoch 105/200, Iteration 20/25, Loss: 0.0144\n",
      "Epoch 105/200, Iteration 21/25, Loss: 0.0123\n",
      "Epoch 105/200, Iteration 22/25, Loss: 0.0072\n",
      "Epoch 105/200, Iteration 23/25, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 24/25, Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200, Iteration 25/25, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.006032, MRE: 0.320939 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.007658, MRE: 0.869600 \n",
      "\n",
      "Epoch 106/200, Iteration 1/25, Loss: 0.0131\n",
      "Epoch 106/200, Iteration 2/25, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 3/25, Loss: 0.0272\n",
      "Epoch 106/200, Iteration 4/25, Loss: 0.0138\n",
      "Epoch 106/200, Iteration 5/25, Loss: 0.0233\n",
      "Epoch 106/200, Iteration 6/25, Loss: 0.0147\n",
      "Epoch 106/200, Iteration 7/25, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 8/25, Loss: 0.0057\n",
      "Epoch 106/200, Iteration 9/25, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 10/25, Loss: 0.0237\n",
      "Epoch 106/200, Iteration 11/25, Loss: 0.0140\n",
      "Epoch 106/200, Iteration 12/25, Loss: 0.0119\n",
      "Epoch 106/200, Iteration 13/25, Loss: 0.0079\n",
      "Epoch 106/200, Iteration 14/25, Loss: 0.0071\n",
      "Epoch 106/200, Iteration 15/25, Loss: 0.0134\n",
      "Epoch 106/200, Iteration 16/25, Loss: 0.0115\n",
      "Epoch 106/200, Iteration 17/25, Loss: 0.0100\n",
      "Epoch 106/200, Iteration 18/25, Loss: 0.0202\n",
      "Epoch 106/200, Iteration 19/25, Loss: 0.0104\n",
      "Epoch 106/200, Iteration 20/25, Loss: 0.0092\n",
      "Epoch 106/200, Iteration 21/25, Loss: 0.0307\n",
      "Epoch 106/200, Iteration 22/25, Loss: 0.0184\n",
      "Epoch 106/200, Iteration 23/25, Loss: 0.0171\n",
      "Epoch 106/200, Iteration 24/25, Loss: 0.0227\n",
      "Epoch 106/200, Iteration 25/25, Loss: 0.0174\n",
      "Train Error: \n",
      " Accuracy: 78.88%, Avg loss: 0.007253, MRE: 0.457898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.008384, MRE: 0.785035 \n",
      "\n",
      "Epoch 107/200, Iteration 1/25, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 2/25, Loss: 0.0084\n",
      "Epoch 107/200, Iteration 3/25, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 4/25, Loss: 0.0051\n",
      "Epoch 107/200, Iteration 5/25, Loss: 0.0113\n",
      "Epoch 107/200, Iteration 6/25, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 7/25, Loss: 0.0079\n",
      "Epoch 107/200, Iteration 8/25, Loss: 0.0145\n",
      "Epoch 107/200, Iteration 9/25, Loss: 0.0090\n",
      "Epoch 107/200, Iteration 10/25, Loss: 0.0092\n",
      "Epoch 107/200, Iteration 11/25, Loss: 0.0113\n",
      "Epoch 107/200, Iteration 12/25, Loss: 0.0143\n",
      "Epoch 107/200, Iteration 13/25, Loss: 0.0136\n",
      "Epoch 107/200, Iteration 14/25, Loss: 0.0330\n",
      "Epoch 107/200, Iteration 15/25, Loss: 0.0353\n",
      "Epoch 107/200, Iteration 16/25, Loss: 0.0197\n",
      "Epoch 107/200, Iteration 17/25, Loss: 0.0211\n",
      "Epoch 107/200, Iteration 18/25, Loss: 0.0190\n",
      "Epoch 107/200, Iteration 19/25, Loss: 0.0270\n",
      "Epoch 107/200, Iteration 20/25, Loss: 0.0258\n",
      "Epoch 107/200, Iteration 21/25, Loss: 0.0185\n",
      "Epoch 107/200, Iteration 22/25, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 23/25, Loss: 0.0243\n",
      "Epoch 107/200, Iteration 24/25, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 25/25, Loss: 0.0163\n",
      "Train Error: \n",
      " Accuracy: 87.38%, Avg loss: 0.006188, MRE: 0.333783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.007560, MRE: 0.874146 \n",
      "\n",
      "Epoch 108/200, Iteration 1/25, Loss: 0.0108\n",
      "Epoch 108/200, Iteration 2/25, Loss: 0.0298\n",
      "Epoch 108/200, Iteration 3/25, Loss: 0.0113\n",
      "Epoch 108/200, Iteration 4/25, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 5/25, Loss: 0.0361\n",
      "Epoch 108/200, Iteration 6/25, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 7/25, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 8/25, Loss: 0.0135\n",
      "Epoch 108/200, Iteration 9/25, Loss: 0.0117\n",
      "Epoch 108/200, Iteration 10/25, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 11/25, Loss: 0.0207\n",
      "Epoch 108/200, Iteration 12/25, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 13/25, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 14/25, Loss: 0.0118\n",
      "Epoch 108/200, Iteration 15/25, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 16/25, Loss: 0.0171\n",
      "Epoch 108/200, Iteration 17/25, Loss: 0.0178\n",
      "Epoch 108/200, Iteration 18/25, Loss: 0.0199\n",
      "Epoch 108/200, Iteration 19/25, Loss: 0.0232\n",
      "Epoch 108/200, Iteration 20/25, Loss: 0.0246\n",
      "Epoch 108/200, Iteration 21/25, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 22/25, Loss: 0.0153\n",
      "Epoch 108/200, Iteration 23/25, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 24/25, Loss: 0.0171\n",
      "Epoch 108/200, Iteration 25/25, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 94.62%, Avg loss: 0.006321, MRE: 0.340599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.008023, MRE: 1.155763 \n",
      "\n",
      "Epoch 109/200, Iteration 1/25, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 2/25, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 3/25, Loss: 0.0309\n",
      "Epoch 109/200, Iteration 4/25, Loss: 0.0436\n",
      "Epoch 109/200, Iteration 5/25, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 6/25, Loss: 0.0123\n",
      "Epoch 109/200, Iteration 7/25, Loss: 0.0075\n",
      "Epoch 109/200, Iteration 8/25, Loss: 0.0154\n",
      "Epoch 109/200, Iteration 9/25, Loss: 0.0126\n",
      "Epoch 109/200, Iteration 10/25, Loss: 0.0108\n",
      "Epoch 109/200, Iteration 11/25, Loss: 0.0122\n",
      "Epoch 109/200, Iteration 12/25, Loss: 0.0165\n",
      "Epoch 109/200, Iteration 13/25, Loss: 0.0134\n",
      "Epoch 109/200, Iteration 14/25, Loss: 0.0120\n",
      "Epoch 109/200, Iteration 15/25, Loss: 0.0138\n",
      "Epoch 109/200, Iteration 16/25, Loss: 0.0092\n",
      "Epoch 109/200, Iteration 17/25, Loss: 0.0418\n",
      "Epoch 109/200, Iteration 18/25, Loss: 0.0122\n",
      "Epoch 109/200, Iteration 19/25, Loss: 0.0080\n",
      "Epoch 109/200, Iteration 20/25, Loss: 0.0077\n",
      "Epoch 109/200, Iteration 21/25, Loss: 0.0240\n",
      "Epoch 109/200, Iteration 22/25, Loss: 0.0093\n",
      "Epoch 109/200, Iteration 23/25, Loss: 0.0091\n",
      "Epoch 109/200, Iteration 24/25, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 25/25, Loss: 0.0246\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.005927, MRE: 0.333460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007639, MRE: 0.962061 \n",
      "\n",
      "Epoch 110/200, Iteration 1/25, Loss: 0.0140\n",
      "Epoch 110/200, Iteration 2/25, Loss: 0.0142\n",
      "Epoch 110/200, Iteration 3/25, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 4/25, Loss: 0.0115\n",
      "Epoch 110/200, Iteration 5/25, Loss: 0.0093\n",
      "Epoch 110/200, Iteration 6/25, Loss: 0.0119\n",
      "Epoch 110/200, Iteration 7/25, Loss: 0.0269\n",
      "Epoch 110/200, Iteration 8/25, Loss: 0.0203\n",
      "Epoch 110/200, Iteration 9/25, Loss: 0.0085\n",
      "Epoch 110/200, Iteration 10/25, Loss: 0.0392\n",
      "Epoch 110/200, Iteration 11/25, Loss: 0.0205\n",
      "Epoch 110/200, Iteration 12/25, Loss: 0.0093\n",
      "Epoch 110/200, Iteration 13/25, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 14/25, Loss: 0.0079\n",
      "Epoch 110/200, Iteration 15/25, Loss: 0.0121\n",
      "Epoch 110/200, Iteration 16/25, Loss: 0.0113\n",
      "Epoch 110/200, Iteration 17/25, Loss: 0.0224\n",
      "Epoch 110/200, Iteration 18/25, Loss: 0.0162\n",
      "Epoch 110/200, Iteration 19/25, Loss: 0.0076\n",
      "Epoch 110/200, Iteration 20/25, Loss: 0.0205\n",
      "Epoch 110/200, Iteration 21/25, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 22/25, Loss: 0.0271\n",
      "Epoch 110/200, Iteration 23/25, Loss: 0.0117\n",
      "Epoch 110/200, Iteration 24/25, Loss: 0.0349\n",
      "Epoch 110/200, Iteration 25/25, Loss: 0.0143\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.006234, MRE: 0.341359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007996, MRE: 0.739633 \n",
      "\n",
      "Epoch 111/200, Iteration 1/25, Loss: 0.0170\n",
      "Epoch 111/200, Iteration 2/25, Loss: 0.0219\n",
      "Epoch 111/200, Iteration 3/25, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 4/25, Loss: 0.0080\n",
      "Epoch 111/200, Iteration 5/25, Loss: 0.0149\n",
      "Epoch 111/200, Iteration 6/25, Loss: 0.0110\n",
      "Epoch 111/200, Iteration 7/25, Loss: 0.0146\n",
      "Epoch 111/200, Iteration 8/25, Loss: 0.0063\n",
      "Epoch 111/200, Iteration 9/25, Loss: 0.0163\n",
      "Epoch 111/200, Iteration 10/25, Loss: 0.0398\n",
      "Epoch 111/200, Iteration 11/25, Loss: 0.0300\n",
      "Epoch 111/200, Iteration 12/25, Loss: 0.0142\n",
      "Epoch 111/200, Iteration 13/25, Loss: 0.0305\n",
      "Epoch 111/200, Iteration 14/25, Loss: 0.0073\n",
      "Epoch 111/200, Iteration 15/25, Loss: 0.0225\n",
      "Epoch 111/200, Iteration 16/25, Loss: 0.0089\n",
      "Epoch 111/200, Iteration 17/25, Loss: 0.0077\n",
      "Epoch 111/200, Iteration 18/25, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 19/25, Loss: 0.0068\n",
      "Epoch 111/200, Iteration 20/25, Loss: 0.0092\n",
      "Epoch 111/200, Iteration 21/25, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 22/25, Loss: 0.0051\n",
      "Epoch 111/200, Iteration 23/25, Loss: 0.0149\n",
      "Epoch 111/200, Iteration 24/25, Loss: 0.0178\n",
      "Epoch 111/200, Iteration 25/25, Loss: 0.0136\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.006334, MRE: 0.384556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.008134, MRE: 1.060673 \n",
      "\n",
      "Epoch 112/200, Iteration 1/25, Loss: 0.0127\n",
      "Epoch 112/200, Iteration 2/25, Loss: 0.0065\n",
      "Epoch 112/200, Iteration 3/25, Loss: 0.0059\n",
      "Epoch 112/200, Iteration 4/25, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 5/25, Loss: 0.0141\n",
      "Epoch 112/200, Iteration 6/25, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 7/25, Loss: 0.0257\n",
      "Epoch 112/200, Iteration 8/25, Loss: 0.0157\n",
      "Epoch 112/200, Iteration 9/25, Loss: 0.0080\n",
      "Epoch 112/200, Iteration 10/25, Loss: 0.0084\n",
      "Epoch 112/200, Iteration 11/25, Loss: 0.0207\n",
      "Epoch 112/200, Iteration 12/25, Loss: 0.0118\n",
      "Epoch 112/200, Iteration 13/25, Loss: 0.0209\n",
      "Epoch 112/200, Iteration 14/25, Loss: 0.0096\n",
      "Epoch 112/200, Iteration 15/25, Loss: 0.0125\n",
      "Epoch 112/200, Iteration 16/25, Loss: 0.0164\n",
      "Epoch 112/200, Iteration 17/25, Loss: 0.0138\n",
      "Epoch 112/200, Iteration 18/25, Loss: 0.0070\n",
      "Epoch 112/200, Iteration 19/25, Loss: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200, Iteration 20/25, Loss: 0.0142\n",
      "Epoch 112/200, Iteration 21/25, Loss: 0.0166\n",
      "Epoch 112/200, Iteration 22/25, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 23/25, Loss: 0.0085\n",
      "Epoch 112/200, Iteration 24/25, Loss: 0.0144\n",
      "Epoch 112/200, Iteration 25/25, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 89.25%, Avg loss: 0.005829, MRE: 0.320462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.007492, MRE: 0.970958 \n",
      "\n",
      "Epoch 113/200, Iteration 1/25, Loss: 0.0216\n",
      "Epoch 113/200, Iteration 2/25, Loss: 0.0228\n",
      "Epoch 113/200, Iteration 3/25, Loss: 0.0136\n",
      "Epoch 113/200, Iteration 4/25, Loss: 0.0066\n",
      "Epoch 113/200, Iteration 5/25, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 6/25, Loss: 0.0230\n",
      "Epoch 113/200, Iteration 7/25, Loss: 0.0134\n",
      "Epoch 113/200, Iteration 8/25, Loss: 0.0267\n",
      "Epoch 113/200, Iteration 9/25, Loss: 0.0163\n",
      "Epoch 113/200, Iteration 10/25, Loss: 0.0083\n",
      "Epoch 113/200, Iteration 11/25, Loss: 0.0153\n",
      "Epoch 113/200, Iteration 12/25, Loss: 0.0098\n",
      "Epoch 113/200, Iteration 13/25, Loss: 0.0083\n",
      "Epoch 113/200, Iteration 14/25, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 15/25, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 16/25, Loss: 0.0076\n",
      "Epoch 113/200, Iteration 17/25, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 18/25, Loss: 0.0067\n",
      "Epoch 113/200, Iteration 19/25, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 20/25, Loss: 0.0210\n",
      "Epoch 113/200, Iteration 21/25, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 22/25, Loss: 0.0312\n",
      "Epoch 113/200, Iteration 23/25, Loss: 0.0098\n",
      "Epoch 113/200, Iteration 24/25, Loss: 0.0292\n",
      "Epoch 113/200, Iteration 25/25, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.006098, MRE: 0.328790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007868, MRE: 1.148636 \n",
      "\n",
      "Epoch 114/200, Iteration 1/25, Loss: 0.0164\n",
      "Epoch 114/200, Iteration 2/25, Loss: 0.0334\n",
      "Epoch 114/200, Iteration 3/25, Loss: 0.0133\n",
      "Epoch 114/200, Iteration 4/25, Loss: 0.0168\n",
      "Epoch 114/200, Iteration 5/25, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 6/25, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 7/25, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 8/25, Loss: 0.0054\n",
      "Epoch 114/200, Iteration 9/25, Loss: 0.0078\n",
      "Epoch 114/200, Iteration 10/25, Loss: 0.0158\n",
      "Epoch 114/200, Iteration 11/25, Loss: 0.0190\n",
      "Epoch 114/200, Iteration 12/25, Loss: 0.0115\n",
      "Epoch 114/200, Iteration 13/25, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 14/25, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 15/25, Loss: 0.0168\n",
      "Epoch 114/200, Iteration 16/25, Loss: 0.0074\n",
      "Epoch 114/200, Iteration 17/25, Loss: 0.0220\n",
      "Epoch 114/200, Iteration 18/25, Loss: 0.0085\n",
      "Epoch 114/200, Iteration 19/25, Loss: 0.0074\n",
      "Epoch 114/200, Iteration 20/25, Loss: 0.0124\n",
      "Epoch 114/200, Iteration 21/25, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 22/25, Loss: 0.0086\n",
      "Epoch 114/200, Iteration 23/25, Loss: 0.0241\n",
      "Epoch 114/200, Iteration 24/25, Loss: 0.0197\n",
      "Epoch 114/200, Iteration 25/25, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.006123, MRE: 0.334665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.008034, MRE: 1.130208 \n",
      "\n",
      "Epoch 115/200, Iteration 1/25, Loss: 0.0171\n",
      "Epoch 115/200, Iteration 2/25, Loss: 0.0105\n",
      "Epoch 115/200, Iteration 3/25, Loss: 0.0107\n",
      "Epoch 115/200, Iteration 4/25, Loss: 0.0098\n",
      "Epoch 115/200, Iteration 5/25, Loss: 0.0186\n",
      "Epoch 115/200, Iteration 6/25, Loss: 0.0191\n",
      "Epoch 115/200, Iteration 7/25, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 8/25, Loss: 0.0134\n",
      "Epoch 115/200, Iteration 9/25, Loss: 0.0171\n",
      "Epoch 115/200, Iteration 10/25, Loss: 0.0124\n",
      "Epoch 115/200, Iteration 11/25, Loss: 0.0074\n",
      "Epoch 115/200, Iteration 12/25, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 13/25, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 14/25, Loss: 0.0168\n",
      "Epoch 115/200, Iteration 15/25, Loss: 0.0147\n",
      "Epoch 115/200, Iteration 16/25, Loss: 0.0110\n",
      "Epoch 115/200, Iteration 17/25, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 18/25, Loss: 0.0053\n",
      "Epoch 115/200, Iteration 19/25, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 20/25, Loss: 0.0113\n",
      "Epoch 115/200, Iteration 21/25, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 22/25, Loss: 0.0121\n",
      "Epoch 115/200, Iteration 23/25, Loss: 0.0102\n",
      "Epoch 115/200, Iteration 24/25, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 25/25, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.006187, MRE: 0.402662 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.007675, MRE: 1.038023 \n",
      "\n",
      "Epoch 116/200, Iteration 1/25, Loss: 0.0146\n",
      "Epoch 116/200, Iteration 2/25, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 3/25, Loss: 0.0273\n",
      "Epoch 116/200, Iteration 4/25, Loss: 0.0152\n",
      "Epoch 116/200, Iteration 5/25, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 6/25, Loss: 0.0151\n",
      "Epoch 116/200, Iteration 7/25, Loss: 0.0281\n",
      "Epoch 116/200, Iteration 8/25, Loss: 0.0252\n",
      "Epoch 116/200, Iteration 9/25, Loss: 0.0494\n",
      "Epoch 116/200, Iteration 10/25, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 11/25, Loss: 0.0167\n",
      "Epoch 116/200, Iteration 12/25, Loss: 0.0134\n",
      "Epoch 116/200, Iteration 13/25, Loss: 0.0156\n",
      "Epoch 116/200, Iteration 14/25, Loss: 0.0065\n",
      "Epoch 116/200, Iteration 15/25, Loss: 0.0271\n",
      "Epoch 116/200, Iteration 16/25, Loss: 0.0105\n",
      "Epoch 116/200, Iteration 17/25, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 18/25, Loss: 0.0150\n",
      "Epoch 116/200, Iteration 19/25, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 20/25, Loss: 0.0189\n",
      "Epoch 116/200, Iteration 21/25, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 22/25, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 23/25, Loss: 0.0105\n",
      "Epoch 116/200, Iteration 24/25, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 25/25, Loss: 0.0121\n",
      "Train Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.005691, MRE: 0.310765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007397, MRE: 0.896793 \n",
      "\n",
      "Epoch 117/200, Iteration 1/25, Loss: 0.0106\n",
      "Epoch 117/200, Iteration 2/25, Loss: 0.0150\n",
      "Epoch 117/200, Iteration 3/25, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 4/25, Loss: 0.0132\n",
      "Epoch 117/200, Iteration 5/25, Loss: 0.0059\n",
      "Epoch 117/200, Iteration 6/25, Loss: 0.0125\n",
      "Epoch 117/200, Iteration 7/25, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 8/25, Loss: 0.0093\n",
      "Epoch 117/200, Iteration 9/25, Loss: 0.0119\n",
      "Epoch 117/200, Iteration 10/25, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 11/25, Loss: 0.0070\n",
      "Epoch 117/200, Iteration 12/25, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 13/25, Loss: 0.0182\n",
      "Epoch 117/200, Iteration 14/25, Loss: 0.0350\n",
      "Epoch 117/200, Iteration 15/25, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 16/25, Loss: 0.0300\n",
      "Epoch 117/200, Iteration 17/25, Loss: 0.0144\n",
      "Epoch 117/200, Iteration 18/25, Loss: 0.0122\n",
      "Epoch 117/200, Iteration 19/25, Loss: 0.0097\n",
      "Epoch 117/200, Iteration 20/25, Loss: 0.0106\n",
      "Epoch 117/200, Iteration 21/25, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 22/25, Loss: 0.0143\n",
      "Epoch 117/200, Iteration 23/25, Loss: 0.0142\n",
      "Epoch 117/200, Iteration 24/25, Loss: 0.0262\n",
      "Epoch 117/200, Iteration 25/25, Loss: 0.0078\n",
      "Train Error: \n",
      " Accuracy: 82.62%, Avg loss: 0.006663, MRE: 0.341984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.007759, MRE: 0.721377 \n",
      "\n",
      "Epoch 118/200, Iteration 1/25, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 2/25, Loss: 0.0207\n",
      "Epoch 118/200, Iteration 3/25, Loss: 0.0244\n",
      "Epoch 118/200, Iteration 4/25, Loss: 0.0261\n",
      "Epoch 118/200, Iteration 5/25, Loss: 0.0289\n",
      "Epoch 118/200, Iteration 6/25, Loss: 0.0419\n",
      "Epoch 118/200, Iteration 7/25, Loss: 0.0350\n",
      "Epoch 118/200, Iteration 8/25, Loss: 0.0071\n",
      "Epoch 118/200, Iteration 9/25, Loss: 0.0065\n",
      "Epoch 118/200, Iteration 10/25, Loss: 0.0280\n",
      "Epoch 118/200, Iteration 11/25, Loss: 0.0209\n",
      "Epoch 118/200, Iteration 12/25, Loss: 0.0264\n",
      "Epoch 118/200, Iteration 13/25, Loss: 0.0181\n",
      "Epoch 118/200, Iteration 14/25, Loss: 0.0113\n",
      "Epoch 118/200, Iteration 15/25, Loss: 0.0196\n",
      "Epoch 118/200, Iteration 16/25, Loss: 0.0101\n",
      "Epoch 118/200, Iteration 17/25, Loss: 0.0177\n",
      "Epoch 118/200, Iteration 18/25, Loss: 0.0169\n",
      "Epoch 118/200, Iteration 19/25, Loss: 0.0106\n",
      "Epoch 118/200, Iteration 20/25, Loss: 0.0115\n",
      "Epoch 118/200, Iteration 21/25, Loss: 0.0463\n",
      "Epoch 118/200, Iteration 22/25, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 23/25, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 24/25, Loss: 0.0067\n",
      "Epoch 118/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.006067, MRE: 0.357076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007981, MRE: 0.868223 \n",
      "\n",
      "Epoch 119/200, Iteration 1/25, Loss: 0.0264\n",
      "Epoch 119/200, Iteration 2/25, Loss: 0.0227\n",
      "Epoch 119/200, Iteration 3/25, Loss: 0.0111\n",
      "Epoch 119/200, Iteration 4/25, Loss: 0.0107\n",
      "Epoch 119/200, Iteration 5/25, Loss: 0.0345\n",
      "Epoch 119/200, Iteration 6/25, Loss: 0.0143\n",
      "Epoch 119/200, Iteration 7/25, Loss: 0.0172\n",
      "Epoch 119/200, Iteration 8/25, Loss: 0.0078\n",
      "Epoch 119/200, Iteration 9/25, Loss: 0.0061\n",
      "Epoch 119/200, Iteration 10/25, Loss: 0.0080\n",
      "Epoch 119/200, Iteration 11/25, Loss: 0.0215\n",
      "Epoch 119/200, Iteration 12/25, Loss: 0.0340\n",
      "Epoch 119/200, Iteration 13/25, Loss: 0.0165\n",
      "Epoch 119/200, Iteration 14/25, Loss: 0.0252\n",
      "Epoch 119/200, Iteration 15/25, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 16/25, Loss: 0.0315\n",
      "Epoch 119/200, Iteration 17/25, Loss: 0.0140\n",
      "Epoch 119/200, Iteration 18/25, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 19/25, Loss: 0.0131\n",
      "Epoch 119/200, Iteration 20/25, Loss: 0.0192\n",
      "Epoch 119/200, Iteration 21/25, Loss: 0.0085\n",
      "Epoch 119/200, Iteration 22/25, Loss: 0.0120\n",
      "Epoch 119/200, Iteration 23/25, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 24/25, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 25/25, Loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.005747, MRE: 0.317475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.007318, MRE: 0.870984 \n",
      "\n",
      "Epoch 120/200, Iteration 1/25, Loss: 0.0273\n",
      "Epoch 120/200, Iteration 2/25, Loss: 0.0230\n",
      "Epoch 120/200, Iteration 3/25, Loss: 0.0199\n",
      "Epoch 120/200, Iteration 4/25, Loss: 0.0153\n",
      "Epoch 120/200, Iteration 5/25, Loss: 0.0256\n",
      "Epoch 120/200, Iteration 6/25, Loss: 0.0086\n",
      "Epoch 120/200, Iteration 7/25, Loss: 0.0169\n",
      "Epoch 120/200, Iteration 8/25, Loss: 0.0220\n",
      "Epoch 120/200, Iteration 9/25, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 10/25, Loss: 0.0095\n",
      "Epoch 120/200, Iteration 11/25, Loss: 0.0134\n",
      "Epoch 120/200, Iteration 12/25, Loss: 0.0211\n",
      "Epoch 120/200, Iteration 13/25, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 14/25, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 15/25, Loss: 0.0192\n",
      "Epoch 120/200, Iteration 16/25, Loss: 0.0069\n",
      "Epoch 120/200, Iteration 17/25, Loss: 0.0294\n",
      "Epoch 120/200, Iteration 18/25, Loss: 0.0156\n",
      "Epoch 120/200, Iteration 19/25, Loss: 0.0084\n",
      "Epoch 120/200, Iteration 20/25, Loss: 0.0090\n",
      "Epoch 120/200, Iteration 21/25, Loss: 0.0067\n",
      "Epoch 120/200, Iteration 22/25, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 23/25, Loss: 0.0110\n",
      "Epoch 120/200, Iteration 24/25, Loss: 0.0102\n",
      "Epoch 120/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 91.12%, Avg loss: 0.005827, MRE: 0.293290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.007413, MRE: 1.086785 \n",
      "\n",
      "Epoch 121/200, Iteration 1/25, Loss: 0.0234\n",
      "Epoch 121/200, Iteration 2/25, Loss: 0.0069\n",
      "Epoch 121/200, Iteration 3/25, Loss: 0.0182\n",
      "Epoch 121/200, Iteration 4/25, Loss: 0.0086\n",
      "Epoch 121/200, Iteration 5/25, Loss: 0.0105\n",
      "Epoch 121/200, Iteration 6/25, Loss: 0.0116\n",
      "Epoch 121/200, Iteration 7/25, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 8/25, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 9/25, Loss: 0.0132\n",
      "Epoch 121/200, Iteration 10/25, Loss: 0.0104\n",
      "Epoch 121/200, Iteration 11/25, Loss: 0.0257\n",
      "Epoch 121/200, Iteration 12/25, Loss: 0.0223\n",
      "Epoch 121/200, Iteration 13/25, Loss: 0.0141\n",
      "Epoch 121/200, Iteration 14/25, Loss: 0.0184\n",
      "Epoch 121/200, Iteration 15/25, Loss: 0.0182\n",
      "Epoch 121/200, Iteration 16/25, Loss: 0.0208\n",
      "Epoch 121/200, Iteration 17/25, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 18/25, Loss: 0.0274\n",
      "Epoch 121/200, Iteration 19/25, Loss: 0.0080\n",
      "Epoch 121/200, Iteration 20/25, Loss: 0.0096\n",
      "Epoch 121/200, Iteration 21/25, Loss: 0.0280\n",
      "Epoch 121/200, Iteration 22/25, Loss: 0.0166\n",
      "Epoch 121/200, Iteration 23/25, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 24/25, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 25/25, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.006102, MRE: 0.307369 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.007800, MRE: 0.789561 \n",
      "\n",
      "Epoch 122/200, Iteration 1/25, Loss: 0.0150\n",
      "Epoch 122/200, Iteration 2/25, Loss: 0.0073\n",
      "Epoch 122/200, Iteration 3/25, Loss: 0.0278\n",
      "Epoch 122/200, Iteration 4/25, Loss: 0.0214\n",
      "Epoch 122/200, Iteration 5/25, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 6/25, Loss: 0.0243\n",
      "Epoch 122/200, Iteration 7/25, Loss: 0.0112\n",
      "Epoch 122/200, Iteration 8/25, Loss: 0.0331\n",
      "Epoch 122/200, Iteration 9/25, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 10/25, Loss: 0.0123\n",
      "Epoch 122/200, Iteration 11/25, Loss: 0.0147\n",
      "Epoch 122/200, Iteration 12/25, Loss: 0.0175\n",
      "Epoch 122/200, Iteration 13/25, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 14/25, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 15/25, Loss: 0.0070\n",
      "Epoch 122/200, Iteration 16/25, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 17/25, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 18/25, Loss: 0.0233\n",
      "Epoch 122/200, Iteration 19/25, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 20/25, Loss: 0.0095\n",
      "Epoch 122/200, Iteration 21/25, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 22/25, Loss: 0.0195\n",
      "Epoch 122/200, Iteration 23/25, Loss: 0.0092\n",
      "Epoch 122/200, Iteration 24/25, Loss: 0.0085\n",
      "Epoch 122/200, Iteration 25/25, Loss: 0.0122\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005848, MRE: 0.319657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007614, MRE: 0.989887 \n",
      "\n",
      "Epoch 123/200, Iteration 1/25, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 2/25, Loss: 0.0194\n",
      "Epoch 123/200, Iteration 3/25, Loss: 0.0195\n",
      "Epoch 123/200, Iteration 4/25, Loss: 0.0050\n",
      "Epoch 123/200, Iteration 5/25, Loss: 0.0136\n",
      "Epoch 123/200, Iteration 6/25, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 7/25, Loss: 0.0063\n",
      "Epoch 123/200, Iteration 8/25, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 9/25, Loss: 0.0231\n",
      "Epoch 123/200, Iteration 10/25, Loss: 0.0055\n",
      "Epoch 123/200, Iteration 11/25, Loss: 0.0253\n",
      "Epoch 123/200, Iteration 12/25, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 13/25, Loss: 0.0161\n",
      "Epoch 123/200, Iteration 14/25, Loss: 0.0283\n",
      "Epoch 123/200, Iteration 15/25, Loss: 0.0218\n",
      "Epoch 123/200, Iteration 16/25, Loss: 0.0068\n",
      "Epoch 123/200, Iteration 17/25, Loss: 0.0069\n",
      "Epoch 123/200, Iteration 18/25, Loss: 0.0214\n",
      "Epoch 123/200, Iteration 19/25, Loss: 0.0099\n",
      "Epoch 123/200, Iteration 20/25, Loss: 0.0071\n",
      "Epoch 123/200, Iteration 21/25, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 22/25, Loss: 0.0177\n",
      "Epoch 123/200, Iteration 23/25, Loss: 0.0116\n",
      "Epoch 123/200, Iteration 24/25, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 25/25, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 90.75%, Avg loss: 0.005884, MRE: 0.325410 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.007336, MRE: 0.835670 \n",
      "\n",
      "Epoch 124/200, Iteration 1/25, Loss: 0.0210\n",
      "Epoch 124/200, Iteration 2/25, Loss: 0.0230\n",
      "Epoch 124/200, Iteration 3/25, Loss: 0.0407\n",
      "Epoch 124/200, Iteration 4/25, Loss: 0.0236\n",
      "Epoch 124/200, Iteration 5/25, Loss: 0.0122\n",
      "Epoch 124/200, Iteration 6/25, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 7/25, Loss: 0.0221\n",
      "Epoch 124/200, Iteration 8/25, Loss: 0.0156\n",
      "Epoch 124/200, Iteration 9/25, Loss: 0.0168\n",
      "Epoch 124/200, Iteration 10/25, Loss: 0.0281\n",
      "Epoch 124/200, Iteration 11/25, Loss: 0.0269\n",
      "Epoch 124/200, Iteration 12/25, Loss: 0.0121\n",
      "Epoch 124/200, Iteration 13/25, Loss: 0.0101\n",
      "Epoch 124/200, Iteration 14/25, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 15/25, Loss: 0.0129\n",
      "Epoch 124/200, Iteration 16/25, Loss: 0.0228\n",
      "Epoch 124/200, Iteration 17/25, Loss: 0.0101\n",
      "Epoch 124/200, Iteration 18/25, Loss: 0.0088\n",
      "Epoch 124/200, Iteration 19/25, Loss: 0.0083\n",
      "Epoch 124/200, Iteration 20/25, Loss: 0.0060\n",
      "Epoch 124/200, Iteration 21/25, Loss: 0.0089\n",
      "Epoch 124/200, Iteration 22/25, Loss: 0.0136\n",
      "Epoch 124/200, Iteration 23/25, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 24/25, Loss: 0.0160\n",
      "Epoch 124/200, Iteration 25/25, Loss: 0.0170\n",
      "Train Error: \n",
      " Accuracy: 89.38%, Avg loss: 0.006287, MRE: 0.367824 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007353, MRE: 0.748237 \n",
      "\n",
      "Epoch 125/200, Iteration 1/25, Loss: 0.0175\n",
      "Epoch 125/200, Iteration 2/25, Loss: 0.0295\n",
      "Epoch 125/200, Iteration 3/25, Loss: 0.0249\n",
      "Epoch 125/200, Iteration 4/25, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 5/25, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 6/25, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 7/25, Loss: 0.0159\n",
      "Epoch 125/200, Iteration 8/25, Loss: 0.0158\n",
      "Epoch 125/200, Iteration 9/25, Loss: 0.0073\n",
      "Epoch 125/200, Iteration 10/25, Loss: 0.0125\n",
      "Epoch 125/200, Iteration 11/25, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 12/25, Loss: 0.0056\n",
      "Epoch 125/200, Iteration 13/25, Loss: 0.0193\n",
      "Epoch 125/200, Iteration 14/25, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 15/25, Loss: 0.0103\n",
      "Epoch 125/200, Iteration 16/25, Loss: 0.0235\n",
      "Epoch 125/200, Iteration 17/25, Loss: 0.0179\n",
      "Epoch 125/200, Iteration 18/25, Loss: 0.0173\n",
      "Epoch 125/200, Iteration 19/25, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 20/25, Loss: 0.0103\n",
      "Epoch 125/200, Iteration 21/25, Loss: 0.0089\n",
      "Epoch 125/200, Iteration 22/25, Loss: 0.0121\n",
      "Epoch 125/200, Iteration 23/25, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 24/25, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 89.38%, Avg loss: 0.006206, MRE: 0.345772 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.007570, MRE: 0.655925 \n",
      "\n",
      "Epoch 126/200, Iteration 1/25, Loss: 0.0181\n",
      "Epoch 126/200, Iteration 2/25, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 3/25, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 4/25, Loss: 0.0078\n",
      "Epoch 126/200, Iteration 5/25, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 6/25, Loss: 0.0159\n",
      "Epoch 126/200, Iteration 7/25, Loss: 0.0111\n",
      "Epoch 126/200, Iteration 8/25, Loss: 0.0066\n",
      "Epoch 126/200, Iteration 9/25, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 10/25, Loss: 0.0223\n",
      "Epoch 126/200, Iteration 11/25, Loss: 0.0168\n",
      "Epoch 126/200, Iteration 12/25, Loss: 0.0110\n",
      "Epoch 126/200, Iteration 13/25, Loss: 0.0256\n",
      "Epoch 126/200, Iteration 14/25, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 15/25, Loss: 0.0243\n",
      "Epoch 126/200, Iteration 16/25, Loss: 0.0078\n",
      "Epoch 126/200, Iteration 17/25, Loss: 0.0355\n",
      "Epoch 126/200, Iteration 18/25, Loss: 0.0069\n",
      "Epoch 126/200, Iteration 19/25, Loss: 0.0074\n",
      "Epoch 126/200, Iteration 20/25, Loss: 0.0074\n",
      "Epoch 126/200, Iteration 21/25, Loss: 0.0094\n",
      "Epoch 126/200, Iteration 22/25, Loss: 0.0075\n",
      "Epoch 126/200, Iteration 23/25, Loss: 0.0297\n",
      "Epoch 126/200, Iteration 24/25, Loss: 0.0119\n",
      "Epoch 126/200, Iteration 25/25, Loss: 0.0314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.006090, MRE: 0.325427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007996, MRE: 1.058451 \n",
      "\n",
      "Epoch 127/200, Iteration 1/25, Loss: 0.0103\n",
      "Epoch 127/200, Iteration 2/25, Loss: 0.0113\n",
      "Epoch 127/200, Iteration 3/25, Loss: 0.0166\n",
      "Epoch 127/200, Iteration 4/25, Loss: 0.0143\n",
      "Epoch 127/200, Iteration 5/25, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 6/25, Loss: 0.0220\n",
      "Epoch 127/200, Iteration 7/25, Loss: 0.0077\n",
      "Epoch 127/200, Iteration 8/25, Loss: 0.0126\n",
      "Epoch 127/200, Iteration 9/25, Loss: 0.0149\n",
      "Epoch 127/200, Iteration 10/25, Loss: 0.0221\n",
      "Epoch 127/200, Iteration 11/25, Loss: 0.0390\n",
      "Epoch 127/200, Iteration 12/25, Loss: 0.0140\n",
      "Epoch 127/200, Iteration 13/25, Loss: 0.0217\n",
      "Epoch 127/200, Iteration 14/25, Loss: 0.0069\n",
      "Epoch 127/200, Iteration 15/25, Loss: 0.0244\n",
      "Epoch 127/200, Iteration 16/25, Loss: 0.0160\n",
      "Epoch 127/200, Iteration 17/25, Loss: 0.0086\n",
      "Epoch 127/200, Iteration 18/25, Loss: 0.0085\n",
      "Epoch 127/200, Iteration 19/25, Loss: 0.0100\n",
      "Epoch 127/200, Iteration 20/25, Loss: 0.0087\n",
      "Epoch 127/200, Iteration 21/25, Loss: 0.0291\n",
      "Epoch 127/200, Iteration 22/25, Loss: 0.0141\n",
      "Epoch 127/200, Iteration 23/25, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 24/25, Loss: 0.0062\n",
      "Epoch 127/200, Iteration 25/25, Loss: 0.0175\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005977, MRE: 0.315113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.008003, MRE: 1.095823 \n",
      "\n",
      "Epoch 128/200, Iteration 1/25, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 2/25, Loss: 0.0061\n",
      "Epoch 128/200, Iteration 3/25, Loss: 0.0067\n",
      "Epoch 128/200, Iteration 4/25, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 5/25, Loss: 0.0133\n",
      "Epoch 128/200, Iteration 6/25, Loss: 0.0105\n",
      "Epoch 128/200, Iteration 7/25, Loss: 0.0253\n",
      "Epoch 128/200, Iteration 8/25, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 9/25, Loss: 0.0115\n",
      "Epoch 128/200, Iteration 10/25, Loss: 0.0083\n",
      "Epoch 128/200, Iteration 11/25, Loss: 0.0334\n",
      "Epoch 128/200, Iteration 12/25, Loss: 0.0141\n",
      "Epoch 128/200, Iteration 13/25, Loss: 0.0130\n",
      "Epoch 128/200, Iteration 14/25, Loss: 0.0096\n",
      "Epoch 128/200, Iteration 15/25, Loss: 0.0124\n",
      "Epoch 128/200, Iteration 16/25, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 17/25, Loss: 0.0068\n",
      "Epoch 128/200, Iteration 18/25, Loss: 0.0157\n",
      "Epoch 128/200, Iteration 19/25, Loss: 0.0088\n",
      "Epoch 128/200, Iteration 20/25, Loss: 0.0195\n",
      "Epoch 128/200, Iteration 21/25, Loss: 0.0090\n",
      "Epoch 128/200, Iteration 22/25, Loss: 0.0141\n",
      "Epoch 128/200, Iteration 23/25, Loss: 0.0202\n",
      "Epoch 128/200, Iteration 24/25, Loss: 0.0299\n",
      "Epoch 128/200, Iteration 25/25, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 85.75%, Avg loss: 0.006295, MRE: 0.388444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.007737, MRE: 0.796822 \n",
      "\n",
      "Epoch 129/200, Iteration 1/25, Loss: 0.0256\n",
      "Epoch 129/200, Iteration 2/25, Loss: 0.0498\n",
      "Epoch 129/200, Iteration 3/25, Loss: 0.0216\n",
      "Epoch 129/200, Iteration 4/25, Loss: 0.0180\n",
      "Epoch 129/200, Iteration 5/25, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 6/25, Loss: 0.0077\n",
      "Epoch 129/200, Iteration 7/25, Loss: 0.0138\n",
      "Epoch 129/200, Iteration 8/25, Loss: 0.0179\n",
      "Epoch 129/200, Iteration 9/25, Loss: 0.0158\n",
      "Epoch 129/200, Iteration 10/25, Loss: 0.0147\n",
      "Epoch 129/200, Iteration 11/25, Loss: 0.0060\n",
      "Epoch 129/200, Iteration 12/25, Loss: 0.0209\n",
      "Epoch 129/200, Iteration 13/25, Loss: 0.0066\n",
      "Epoch 129/200, Iteration 14/25, Loss: 0.0100\n",
      "Epoch 129/200, Iteration 15/25, Loss: 0.0078\n",
      "Epoch 129/200, Iteration 16/25, Loss: 0.0080\n",
      "Epoch 129/200, Iteration 17/25, Loss: 0.0174\n",
      "Epoch 129/200, Iteration 18/25, Loss: 0.0158\n",
      "Epoch 129/200, Iteration 19/25, Loss: 0.0151\n",
      "Epoch 129/200, Iteration 20/25, Loss: 0.0187\n",
      "Epoch 129/200, Iteration 21/25, Loss: 0.0131\n",
      "Epoch 129/200, Iteration 22/25, Loss: 0.0156\n",
      "Epoch 129/200, Iteration 23/25, Loss: 0.0125\n",
      "Epoch 129/200, Iteration 24/25, Loss: 0.0330\n",
      "Epoch 129/200, Iteration 25/25, Loss: 0.0107\n",
      "Train Error: \n",
      " Accuracy: 93.12%, Avg loss: 0.005932, MRE: 0.339081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.007778, MRE: 0.684008 \n",
      "\n",
      "Epoch 130/200, Iteration 1/25, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 2/25, Loss: 0.0295\n",
      "Epoch 130/200, Iteration 3/25, Loss: 0.0108\n",
      "Epoch 130/200, Iteration 4/25, Loss: 0.0082\n",
      "Epoch 130/200, Iteration 5/25, Loss: 0.0104\n",
      "Epoch 130/200, Iteration 6/25, Loss: 0.0260\n",
      "Epoch 130/200, Iteration 7/25, Loss: 0.0208\n",
      "Epoch 130/200, Iteration 8/25, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 9/25, Loss: 0.0082\n",
      "Epoch 130/200, Iteration 10/25, Loss: 0.0270\n",
      "Epoch 130/200, Iteration 11/25, Loss: 0.0261\n",
      "Epoch 130/200, Iteration 12/25, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 13/25, Loss: 0.0151\n",
      "Epoch 130/200, Iteration 14/25, Loss: 0.0061\n",
      "Epoch 130/200, Iteration 15/25, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 16/25, Loss: 0.0113\n",
      "Epoch 130/200, Iteration 17/25, Loss: 0.0051\n",
      "Epoch 130/200, Iteration 18/25, Loss: 0.0195\n",
      "Epoch 130/200, Iteration 19/25, Loss: 0.0080\n",
      "Epoch 130/200, Iteration 20/25, Loss: 0.0130\n",
      "Epoch 130/200, Iteration 21/25, Loss: 0.0136\n",
      "Epoch 130/200, Iteration 22/25, Loss: 0.0064\n",
      "Epoch 130/200, Iteration 23/25, Loss: 0.0076\n",
      "Epoch 130/200, Iteration 24/25, Loss: 0.0072\n",
      "Epoch 130/200, Iteration 25/25, Loss: 0.0176\n",
      "Train Error: \n",
      " Accuracy: 89.38%, Avg loss: 0.006009, MRE: 0.326241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.007467, MRE: 0.775717 \n",
      "\n",
      "Epoch 131/200, Iteration 1/25, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 2/25, Loss: 0.0187\n",
      "Epoch 131/200, Iteration 3/25, Loss: 0.0167\n",
      "Epoch 131/200, Iteration 4/25, Loss: 0.0186\n",
      "Epoch 131/200, Iteration 5/25, Loss: 0.0162\n",
      "Epoch 131/200, Iteration 6/25, Loss: 0.0196\n",
      "Epoch 131/200, Iteration 7/25, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 8/25, Loss: 0.0231\n",
      "Epoch 131/200, Iteration 9/25, Loss: 0.0262\n",
      "Epoch 131/200, Iteration 10/25, Loss: 0.0111\n",
      "Epoch 131/200, Iteration 11/25, Loss: 0.0234\n",
      "Epoch 131/200, Iteration 12/25, Loss: 0.0089\n",
      "Epoch 131/200, Iteration 13/25, Loss: 0.0101\n",
      "Epoch 131/200, Iteration 14/25, Loss: 0.0274\n",
      "Epoch 131/200, Iteration 15/25, Loss: 0.0117\n",
      "Epoch 131/200, Iteration 16/25, Loss: 0.0100\n",
      "Epoch 131/200, Iteration 17/25, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 18/25, Loss: 0.0124\n",
      "Epoch 131/200, Iteration 19/25, Loss: 0.0131\n",
      "Epoch 131/200, Iteration 20/25, Loss: 0.0195\n",
      "Epoch 131/200, Iteration 21/25, Loss: 0.0134\n",
      "Epoch 131/200, Iteration 22/25, Loss: 0.0082\n",
      "Epoch 131/200, Iteration 23/25, Loss: 0.0099\n",
      "Epoch 131/200, Iteration 24/25, Loss: 0.0134\n",
      "Epoch 131/200, Iteration 25/25, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 86.62%, Avg loss: 0.006064, MRE: 0.362372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.007522, MRE: 0.839339 \n",
      "\n",
      "Epoch 132/200, Iteration 1/25, Loss: 0.0310\n",
      "Epoch 132/200, Iteration 2/25, Loss: 0.0069\n",
      "Epoch 132/200, Iteration 3/25, Loss: 0.0118\n",
      "Epoch 132/200, Iteration 4/25, Loss: 0.0136\n",
      "Epoch 132/200, Iteration 5/25, Loss: 0.0201\n",
      "Epoch 132/200, Iteration 6/25, Loss: 0.0100\n",
      "Epoch 132/200, Iteration 7/25, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 8/25, Loss: 0.0146\n",
      "Epoch 132/200, Iteration 9/25, Loss: 0.0079\n",
      "Epoch 132/200, Iteration 10/25, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 11/25, Loss: 0.0252\n",
      "Epoch 132/200, Iteration 12/25, Loss: 0.0208\n",
      "Epoch 132/200, Iteration 13/25, Loss: 0.0202\n",
      "Epoch 132/200, Iteration 14/25, Loss: 0.0236\n",
      "Epoch 132/200, Iteration 15/25, Loss: 0.0227\n",
      "Epoch 132/200, Iteration 16/25, Loss: 0.0285\n",
      "Epoch 132/200, Iteration 17/25, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 18/25, Loss: 0.0110\n",
      "Epoch 132/200, Iteration 19/25, Loss: 0.0062\n",
      "Epoch 132/200, Iteration 20/25, Loss: 0.0144\n",
      "Epoch 132/200, Iteration 21/25, Loss: 0.0072\n",
      "Epoch 132/200, Iteration 22/25, Loss: 0.0200\n",
      "Epoch 132/200, Iteration 23/25, Loss: 0.0094\n",
      "Epoch 132/200, Iteration 24/25, Loss: 0.0095\n",
      "Epoch 132/200, Iteration 25/25, Loss: 0.0134\n",
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.006089, MRE: 0.344204 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007894, MRE: 1.061877 \n",
      "\n",
      "Epoch 133/200, Iteration 1/25, Loss: 0.0121\n",
      "Epoch 133/200, Iteration 2/25, Loss: 0.0064\n",
      "Epoch 133/200, Iteration 3/25, Loss: 0.0257\n",
      "Epoch 133/200, Iteration 4/25, Loss: 0.0104\n",
      "Epoch 133/200, Iteration 5/25, Loss: 0.0143\n",
      "Epoch 133/200, Iteration 6/25, Loss: 0.0187\n",
      "Epoch 133/200, Iteration 7/25, Loss: 0.0131\n",
      "Epoch 133/200, Iteration 8/25, Loss: 0.0158\n",
      "Epoch 133/200, Iteration 9/25, Loss: 0.0141\n",
      "Epoch 133/200, Iteration 10/25, Loss: 0.0118\n",
      "Epoch 133/200, Iteration 11/25, Loss: 0.0121\n",
      "Epoch 133/200, Iteration 12/25, Loss: 0.0085\n",
      "Epoch 133/200, Iteration 13/25, Loss: 0.0109\n",
      "Epoch 133/200, Iteration 14/25, Loss: 0.0191\n",
      "Epoch 133/200, Iteration 15/25, Loss: 0.0453\n",
      "Epoch 133/200, Iteration 16/25, Loss: 0.0088\n",
      "Epoch 133/200, Iteration 17/25, Loss: 0.0205\n",
      "Epoch 133/200, Iteration 18/25, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200, Iteration 19/25, Loss: 0.0114\n",
      "Epoch 133/200, Iteration 20/25, Loss: 0.0134\n",
      "Epoch 133/200, Iteration 21/25, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 22/25, Loss: 0.0305\n",
      "Epoch 133/200, Iteration 23/25, Loss: 0.0094\n",
      "Epoch 133/200, Iteration 24/25, Loss: 0.0141\n",
      "Epoch 133/200, Iteration 25/25, Loss: 0.0110\n",
      "Train Error: \n",
      " Accuracy: 90.75%, Avg loss: 0.005766, MRE: 0.331642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.007389, MRE: 0.766914 \n",
      "\n",
      "Epoch 134/200, Iteration 1/25, Loss: 0.0391\n",
      "Epoch 134/200, Iteration 2/25, Loss: 0.0062\n",
      "Epoch 134/200, Iteration 3/25, Loss: 0.0263\n",
      "Epoch 134/200, Iteration 4/25, Loss: 0.0098\n",
      "Epoch 134/200, Iteration 5/25, Loss: 0.0403\n",
      "Epoch 134/200, Iteration 6/25, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 7/25, Loss: 0.0195\n",
      "Epoch 134/200, Iteration 8/25, Loss: 0.0155\n",
      "Epoch 134/200, Iteration 9/25, Loss: 0.0155\n",
      "Epoch 134/200, Iteration 10/25, Loss: 0.0102\n",
      "Epoch 134/200, Iteration 11/25, Loss: 0.0092\n",
      "Epoch 134/200, Iteration 12/25, Loss: 0.0094\n",
      "Epoch 134/200, Iteration 13/25, Loss: 0.0159\n",
      "Epoch 134/200, Iteration 14/25, Loss: 0.0147\n",
      "Epoch 134/200, Iteration 15/25, Loss: 0.0231\n",
      "Epoch 134/200, Iteration 16/25, Loss: 0.0218\n",
      "Epoch 134/200, Iteration 17/25, Loss: 0.0104\n",
      "Epoch 134/200, Iteration 18/25, Loss: 0.0232\n",
      "Epoch 134/200, Iteration 19/25, Loss: 0.0174\n",
      "Epoch 134/200, Iteration 20/25, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 21/25, Loss: 0.0151\n",
      "Epoch 134/200, Iteration 22/25, Loss: 0.0069\n",
      "Epoch 134/200, Iteration 23/25, Loss: 0.0115\n",
      "Epoch 134/200, Iteration 24/25, Loss: 0.0253\n",
      "Epoch 134/200, Iteration 25/25, Loss: 0.0261\n",
      "Train Error: \n",
      " Accuracy: 91.38%, Avg loss: 0.006045, MRE: 0.345123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007581, MRE: 0.688043 \n",
      "\n",
      "Epoch 135/200, Iteration 1/25, Loss: 0.0107\n",
      "Epoch 135/200, Iteration 2/25, Loss: 0.0460\n",
      "Epoch 135/200, Iteration 3/25, Loss: 0.0136\n",
      "Epoch 135/200, Iteration 4/25, Loss: 0.0158\n",
      "Epoch 135/200, Iteration 5/25, Loss: 0.0192\n",
      "Epoch 135/200, Iteration 6/25, Loss: 0.0121\n",
      "Epoch 135/200, Iteration 7/25, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 8/25, Loss: 0.0179\n",
      "Epoch 135/200, Iteration 9/25, Loss: 0.0108\n",
      "Epoch 135/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 135/200, Iteration 11/25, Loss: 0.0189\n",
      "Epoch 135/200, Iteration 12/25, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 135/200, Iteration 14/25, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 15/25, Loss: 0.0114\n",
      "Epoch 135/200, Iteration 16/25, Loss: 0.0265\n",
      "Epoch 135/200, Iteration 17/25, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 18/25, Loss: 0.0067\n",
      "Epoch 135/200, Iteration 19/25, Loss: 0.0055\n",
      "Epoch 135/200, Iteration 20/25, Loss: 0.0335\n",
      "Epoch 135/200, Iteration 21/25, Loss: 0.0115\n",
      "Epoch 135/200, Iteration 22/25, Loss: 0.0185\n",
      "Epoch 135/200, Iteration 23/25, Loss: 0.0038\n",
      "Epoch 135/200, Iteration 24/25, Loss: 0.0141\n",
      "Epoch 135/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.007050, MRE: 0.432163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.008879, MRE: 1.224069 \n",
      "\n",
      "Epoch 136/200, Iteration 1/25, Loss: 0.0070\n",
      "Epoch 136/200, Iteration 2/25, Loss: 0.0130\n",
      "Epoch 136/200, Iteration 3/25, Loss: 0.0078\n",
      "Epoch 136/200, Iteration 4/25, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 5/25, Loss: 0.0130\n",
      "Epoch 136/200, Iteration 6/25, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 7/25, Loss: 0.0311\n",
      "Epoch 136/200, Iteration 8/25, Loss: 0.0100\n",
      "Epoch 136/200, Iteration 9/25, Loss: 0.0092\n",
      "Epoch 136/200, Iteration 10/25, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 11/25, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 12/25, Loss: 0.0153\n",
      "Epoch 136/200, Iteration 13/25, Loss: 0.0128\n",
      "Epoch 136/200, Iteration 14/25, Loss: 0.0075\n",
      "Epoch 136/200, Iteration 15/25, Loss: 0.0096\n",
      "Epoch 136/200, Iteration 16/25, Loss: 0.0159\n",
      "Epoch 136/200, Iteration 17/25, Loss: 0.0266\n",
      "Epoch 136/200, Iteration 18/25, Loss: 0.0301\n",
      "Epoch 136/200, Iteration 19/25, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 20/25, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 21/25, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 22/25, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 23/25, Loss: 0.0132\n",
      "Epoch 136/200, Iteration 24/25, Loss: 0.0112\n",
      "Epoch 136/200, Iteration 25/25, Loss: 0.0261\n",
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.006257, MRE: 0.374563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.008002, MRE: 1.219846 \n",
      "\n",
      "Epoch 137/200, Iteration 1/25, Loss: 0.0194\n",
      "Epoch 137/200, Iteration 2/25, Loss: 0.0098\n",
      "Epoch 137/200, Iteration 3/25, Loss: 0.0270\n",
      "Epoch 137/200, Iteration 4/25, Loss: 0.0069\n",
      "Epoch 137/200, Iteration 5/25, Loss: 0.0185\n",
      "Epoch 137/200, Iteration 6/25, Loss: 0.0133\n",
      "Epoch 137/200, Iteration 7/25, Loss: 0.0061\n",
      "Epoch 137/200, Iteration 8/25, Loss: 0.0120\n",
      "Epoch 137/200, Iteration 9/25, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 10/25, Loss: 0.0296\n",
      "Epoch 137/200, Iteration 11/25, Loss: 0.0109\n",
      "Epoch 137/200, Iteration 12/25, Loss: 0.0062\n",
      "Epoch 137/200, Iteration 13/25, Loss: 0.0222\n",
      "Epoch 137/200, Iteration 14/25, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 15/25, Loss: 0.0140\n",
      "Epoch 137/200, Iteration 16/25, Loss: 0.0165\n",
      "Epoch 137/200, Iteration 17/25, Loss: 0.0141\n",
      "Epoch 137/200, Iteration 18/25, Loss: 0.0094\n",
      "Epoch 137/200, Iteration 19/25, Loss: 0.0187\n",
      "Epoch 137/200, Iteration 20/25, Loss: 0.0186\n",
      "Epoch 137/200, Iteration 21/25, Loss: 0.0161\n",
      "Epoch 137/200, Iteration 22/25, Loss: 0.0291\n",
      "Epoch 137/200, Iteration 23/25, Loss: 0.0182\n",
      "Epoch 137/200, Iteration 24/25, Loss: 0.0110\n",
      "Epoch 137/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 91.38%, Avg loss: 0.005769, MRE: 0.293213 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.007496, MRE: 0.949011 \n",
      "\n",
      "Epoch 138/200, Iteration 1/25, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 2/25, Loss: 0.0065\n",
      "Epoch 138/200, Iteration 3/25, Loss: 0.0080\n",
      "Epoch 138/200, Iteration 4/25, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 5/25, Loss: 0.0314\n",
      "Epoch 138/200, Iteration 6/25, Loss: 0.0092\n",
      "Epoch 138/200, Iteration 7/25, Loss: 0.0082\n",
      "Epoch 138/200, Iteration 8/25, Loss: 0.0127\n",
      "Epoch 138/200, Iteration 9/25, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 10/25, Loss: 0.0098\n",
      "Epoch 138/200, Iteration 11/25, Loss: 0.0178\n",
      "Epoch 138/200, Iteration 12/25, Loss: 0.0110\n",
      "Epoch 138/200, Iteration 13/25, Loss: 0.0121\n",
      "Epoch 138/200, Iteration 14/25, Loss: 0.0164\n",
      "Epoch 138/200, Iteration 15/25, Loss: 0.0105\n",
      "Epoch 138/200, Iteration 16/25, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 17/25, Loss: 0.0115\n",
      "Epoch 138/200, Iteration 18/25, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 19/25, Loss: 0.0291\n",
      "Epoch 138/200, Iteration 20/25, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 21/25, Loss: 0.0254\n",
      "Epoch 138/200, Iteration 22/25, Loss: 0.0147\n",
      "Epoch 138/200, Iteration 23/25, Loss: 0.0407\n",
      "Epoch 138/200, Iteration 24/25, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 25/25, Loss: 0.0149\n",
      "Train Error: \n",
      " Accuracy: 80.25%, Avg loss: 0.007214, MRE: 0.457103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.008466, MRE: 0.732000 \n",
      "\n",
      "Epoch 139/200, Iteration 1/25, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 2/25, Loss: 0.0254\n",
      "Epoch 139/200, Iteration 3/25, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 4/25, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 5/25, Loss: 0.0082\n",
      "Epoch 139/200, Iteration 6/25, Loss: 0.0184\n",
      "Epoch 139/200, Iteration 7/25, Loss: 0.0096\n",
      "Epoch 139/200, Iteration 8/25, Loss: 0.0123\n",
      "Epoch 139/200, Iteration 9/25, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 10/25, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 11/25, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 12/25, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 13/25, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 14/25, Loss: 0.0109\n",
      "Epoch 139/200, Iteration 15/25, Loss: 0.0146\n",
      "Epoch 139/200, Iteration 16/25, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 17/25, Loss: 0.0292\n",
      "Epoch 139/200, Iteration 18/25, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 19/25, Loss: 0.0135\n",
      "Epoch 139/200, Iteration 20/25, Loss: 0.0078\n",
      "Epoch 139/200, Iteration 21/25, Loss: 0.0123\n",
      "Epoch 139/200, Iteration 22/25, Loss: 0.0081\n",
      "Epoch 139/200, Iteration 23/25, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 24/25, Loss: 0.0215\n",
      "Epoch 139/200, Iteration 25/25, Loss: 0.0089\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.005747, MRE: 0.331862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.007424, MRE: 0.761114 \n",
      "\n",
      "Epoch 140/200, Iteration 1/25, Loss: 0.0136\n",
      "Epoch 140/200, Iteration 2/25, Loss: 0.0313\n",
      "Epoch 140/200, Iteration 3/25, Loss: 0.0118\n",
      "Epoch 140/200, Iteration 4/25, Loss: 0.0563\n",
      "Epoch 140/200, Iteration 5/25, Loss: 0.0093\n",
      "Epoch 140/200, Iteration 6/25, Loss: 0.0160\n",
      "Epoch 140/200, Iteration 7/25, Loss: 0.0078\n",
      "Epoch 140/200, Iteration 8/25, Loss: 0.0123\n",
      "Epoch 140/200, Iteration 9/25, Loss: 0.0225\n",
      "Epoch 140/200, Iteration 10/25, Loss: 0.0175\n",
      "Epoch 140/200, Iteration 11/25, Loss: 0.0101\n",
      "Epoch 140/200, Iteration 12/25, Loss: 0.0109\n",
      "Epoch 140/200, Iteration 13/25, Loss: 0.0098\n",
      "Epoch 140/200, Iteration 14/25, Loss: 0.0322\n",
      "Epoch 140/200, Iteration 15/25, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 16/25, Loss: 0.0252\n",
      "Epoch 140/200, Iteration 17/25, Loss: 0.0137\n",
      "Epoch 140/200, Iteration 18/25, Loss: 0.0129\n",
      "Epoch 140/200, Iteration 19/25, Loss: 0.0209\n",
      "Epoch 140/200, Iteration 20/25, Loss: 0.0079\n",
      "Epoch 140/200, Iteration 21/25, Loss: 0.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Iteration 22/25, Loss: 0.0152\n",
      "Epoch 140/200, Iteration 23/25, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 24/25, Loss: 0.0145\n",
      "Epoch 140/200, Iteration 25/25, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.005654, MRE: 0.312435 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.007471, MRE: 0.812015 \n",
      "\n",
      "Epoch 141/200, Iteration 1/25, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 2/25, Loss: 0.0075\n",
      "Epoch 141/200, Iteration 3/25, Loss: 0.0138\n",
      "Epoch 141/200, Iteration 4/25, Loss: 0.0216\n",
      "Epoch 141/200, Iteration 5/25, Loss: 0.0165\n",
      "Epoch 141/200, Iteration 6/25, Loss: 0.0104\n",
      "Epoch 141/200, Iteration 7/25, Loss: 0.0121\n",
      "Epoch 141/200, Iteration 8/25, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 9/25, Loss: 0.0481\n",
      "Epoch 141/200, Iteration 10/25, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 11/25, Loss: 0.0207\n",
      "Epoch 141/200, Iteration 12/25, Loss: 0.0231\n",
      "Epoch 141/200, Iteration 13/25, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 14/25, Loss: 0.0118\n",
      "Epoch 141/200, Iteration 15/25, Loss: 0.0110\n",
      "Epoch 141/200, Iteration 16/25, Loss: 0.0192\n",
      "Epoch 141/200, Iteration 17/25, Loss: 0.0141\n",
      "Epoch 141/200, Iteration 18/25, Loss: 0.0108\n",
      "Epoch 141/200, Iteration 19/25, Loss: 0.0068\n",
      "Epoch 141/200, Iteration 20/25, Loss: 0.0092\n",
      "Epoch 141/200, Iteration 21/25, Loss: 0.0109\n",
      "Epoch 141/200, Iteration 22/25, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 23/25, Loss: 0.0240\n",
      "Epoch 141/200, Iteration 24/25, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 25/25, Loss: 0.0143\n",
      "Train Error: \n",
      " Accuracy: 88.62%, Avg loss: 0.005913, MRE: 0.340936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.007344, MRE: 0.707298 \n",
      "\n",
      "Epoch 142/200, Iteration 1/25, Loss: 0.0294\n",
      "Epoch 142/200, Iteration 2/25, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 3/25, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 4/25, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 5/25, Loss: 0.0117\n",
      "Epoch 142/200, Iteration 6/25, Loss: 0.0100\n",
      "Epoch 142/200, Iteration 7/25, Loss: 0.0292\n",
      "Epoch 142/200, Iteration 8/25, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 9/25, Loss: 0.0275\n",
      "Epoch 142/200, Iteration 10/25, Loss: 0.0191\n",
      "Epoch 142/200, Iteration 11/25, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 12/25, Loss: 0.0235\n",
      "Epoch 142/200, Iteration 13/25, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 14/25, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 15/25, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 16/25, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 17/25, Loss: 0.0118\n",
      "Epoch 142/200, Iteration 18/25, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 19/25, Loss: 0.0113\n",
      "Epoch 142/200, Iteration 20/25, Loss: 0.0121\n",
      "Epoch 142/200, Iteration 21/25, Loss: 0.0267\n",
      "Epoch 142/200, Iteration 22/25, Loss: 0.0055\n",
      "Epoch 142/200, Iteration 23/25, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 24/25, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 25/25, Loss: 0.0226\n",
      "Train Error: \n",
      " Accuracy: 82.25%, Avg loss: 0.006752, MRE: 0.334740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.007997, MRE: 0.646871 \n",
      "\n",
      "Epoch 143/200, Iteration 1/25, Loss: 0.0169\n",
      "Epoch 143/200, Iteration 2/25, Loss: 0.0158\n",
      "Epoch 143/200, Iteration 3/25, Loss: 0.0239\n",
      "Epoch 143/200, Iteration 4/25, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 5/25, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 6/25, Loss: 0.0473\n",
      "Epoch 143/200, Iteration 7/25, Loss: 0.0078\n",
      "Epoch 143/200, Iteration 8/25, Loss: 0.0133\n",
      "Epoch 143/200, Iteration 9/25, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 10/25, Loss: 0.0299\n",
      "Epoch 143/200, Iteration 11/25, Loss: 0.0087\n",
      "Epoch 143/200, Iteration 12/25, Loss: 0.0221\n",
      "Epoch 143/200, Iteration 13/25, Loss: 0.0121\n",
      "Epoch 143/200, Iteration 14/25, Loss: 0.0232\n",
      "Epoch 143/200, Iteration 15/25, Loss: 0.0171\n",
      "Epoch 143/200, Iteration 16/25, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 17/25, Loss: 0.0242\n",
      "Epoch 143/200, Iteration 18/25, Loss: 0.0145\n",
      "Epoch 143/200, Iteration 19/25, Loss: 0.0075\n",
      "Epoch 143/200, Iteration 20/25, Loss: 0.0215\n",
      "Epoch 143/200, Iteration 21/25, Loss: 0.0120\n",
      "Epoch 143/200, Iteration 22/25, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 23/25, Loss: 0.0412\n",
      "Epoch 143/200, Iteration 24/25, Loss: 0.0247\n",
      "Epoch 143/200, Iteration 25/25, Loss: 0.0140\n",
      "Train Error: \n",
      " Accuracy: 90.88%, Avg loss: 0.005859, MRE: 0.302508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007543, MRE: 0.761475 \n",
      "\n",
      "Epoch 144/200, Iteration 1/25, Loss: 0.0133\n",
      "Epoch 144/200, Iteration 2/25, Loss: 0.0271\n",
      "Epoch 144/200, Iteration 3/25, Loss: 0.0105\n",
      "Epoch 144/200, Iteration 4/25, Loss: 0.0079\n",
      "Epoch 144/200, Iteration 5/25, Loss: 0.0248\n",
      "Epoch 144/200, Iteration 6/25, Loss: 0.0230\n",
      "Epoch 144/200, Iteration 7/25, Loss: 0.0160\n",
      "Epoch 144/200, Iteration 8/25, Loss: 0.0263\n",
      "Epoch 144/200, Iteration 9/25, Loss: 0.0092\n",
      "Epoch 144/200, Iteration 10/25, Loss: 0.0086\n",
      "Epoch 144/200, Iteration 11/25, Loss: 0.0146\n",
      "Epoch 144/200, Iteration 12/25, Loss: 0.0258\n",
      "Epoch 144/200, Iteration 13/25, Loss: 0.0174\n",
      "Epoch 144/200, Iteration 14/25, Loss: 0.0173\n",
      "Epoch 144/200, Iteration 15/25, Loss: 0.0214\n",
      "Epoch 144/200, Iteration 16/25, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 17/25, Loss: 0.0180\n",
      "Epoch 144/200, Iteration 18/25, Loss: 0.0281\n",
      "Epoch 144/200, Iteration 19/25, Loss: 0.0152\n",
      "Epoch 144/200, Iteration 20/25, Loss: 0.0145\n",
      "Epoch 144/200, Iteration 21/25, Loss: 0.0207\n",
      "Epoch 144/200, Iteration 22/25, Loss: 0.0200\n",
      "Epoch 144/200, Iteration 23/25, Loss: 0.0221\n",
      "Epoch 144/200, Iteration 24/25, Loss: 0.0087\n",
      "Epoch 144/200, Iteration 25/25, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 88.38%, Avg loss: 0.006024, MRE: 0.319407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.007454, MRE: 0.842949 \n",
      "\n",
      "Epoch 145/200, Iteration 1/25, Loss: 0.0247\n",
      "Epoch 145/200, Iteration 2/25, Loss: 0.0145\n",
      "Epoch 145/200, Iteration 3/25, Loss: 0.0124\n",
      "Epoch 145/200, Iteration 4/25, Loss: 0.0129\n",
      "Epoch 145/200, Iteration 5/25, Loss: 0.0100\n",
      "Epoch 145/200, Iteration 6/25, Loss: 0.0178\n",
      "Epoch 145/200, Iteration 7/25, Loss: 0.0204\n",
      "Epoch 145/200, Iteration 8/25, Loss: 0.0097\n",
      "Epoch 145/200, Iteration 9/25, Loss: 0.0133\n",
      "Epoch 145/200, Iteration 10/25, Loss: 0.0163\n",
      "Epoch 145/200, Iteration 11/25, Loss: 0.0077\n",
      "Epoch 145/200, Iteration 12/25, Loss: 0.0092\n",
      "Epoch 145/200, Iteration 13/25, Loss: 0.0100\n",
      "Epoch 145/200, Iteration 14/25, Loss: 0.0333\n",
      "Epoch 145/200, Iteration 15/25, Loss: 0.0110\n",
      "Epoch 145/200, Iteration 16/25, Loss: 0.0247\n",
      "Epoch 145/200, Iteration 17/25, Loss: 0.0103\n",
      "Epoch 145/200, Iteration 18/25, Loss: 0.0081\n",
      "Epoch 145/200, Iteration 19/25, Loss: 0.0205\n",
      "Epoch 145/200, Iteration 20/25, Loss: 0.0220\n",
      "Epoch 145/200, Iteration 21/25, Loss: 0.0138\n",
      "Epoch 145/200, Iteration 22/25, Loss: 0.0107\n",
      "Epoch 145/200, Iteration 23/25, Loss: 0.0112\n",
      "Epoch 145/200, Iteration 24/25, Loss: 0.0135\n",
      "Epoch 145/200, Iteration 25/25, Loss: 0.0134\n",
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006449, MRE: 0.325388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.007691, MRE: 0.775950 \n",
      "\n",
      "Epoch 146/200, Iteration 1/25, Loss: 0.0137\n",
      "Epoch 146/200, Iteration 2/25, Loss: 0.0060\n",
      "Epoch 146/200, Iteration 3/25, Loss: 0.0283\n",
      "Epoch 146/200, Iteration 4/25, Loss: 0.0125\n",
      "Epoch 146/200, Iteration 5/25, Loss: 0.0116\n",
      "Epoch 146/200, Iteration 6/25, Loss: 0.0092\n",
      "Epoch 146/200, Iteration 7/25, Loss: 0.0168\n",
      "Epoch 146/200, Iteration 8/25, Loss: 0.0057\n",
      "Epoch 146/200, Iteration 9/25, Loss: 0.0191\n",
      "Epoch 146/200, Iteration 10/25, Loss: 0.0131\n",
      "Epoch 146/200, Iteration 11/25, Loss: 0.0106\n",
      "Epoch 146/200, Iteration 12/25, Loss: 0.0085\n",
      "Epoch 146/200, Iteration 13/25, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 14/25, Loss: 0.0074\n",
      "Epoch 146/200, Iteration 15/25, Loss: 0.0074\n",
      "Epoch 146/200, Iteration 16/25, Loss: 0.0069\n",
      "Epoch 146/200, Iteration 17/25, Loss: 0.0119\n",
      "Epoch 146/200, Iteration 18/25, Loss: 0.0245\n",
      "Epoch 146/200, Iteration 19/25, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 20/25, Loss: 0.0313\n",
      "Epoch 146/200, Iteration 21/25, Loss: 0.0045\n",
      "Epoch 146/200, Iteration 22/25, Loss: 0.0097\n",
      "Epoch 146/200, Iteration 23/25, Loss: 0.0248\n",
      "Epoch 146/200, Iteration 24/25, Loss: 0.0163\n",
      "Epoch 146/200, Iteration 25/25, Loss: 0.0223\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.005590, MRE: 0.305094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.007227, MRE: 0.851148 \n",
      "\n",
      "Epoch 147/200, Iteration 1/25, Loss: 0.0062\n",
      "Epoch 147/200, Iteration 2/25, Loss: 0.0074\n",
      "Epoch 147/200, Iteration 3/25, Loss: 0.0075\n",
      "Epoch 147/200, Iteration 4/25, Loss: 0.0232\n",
      "Epoch 147/200, Iteration 5/25, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 6/25, Loss: 0.0134\n",
      "Epoch 147/200, Iteration 7/25, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 8/25, Loss: 0.0099\n",
      "Epoch 147/200, Iteration 9/25, Loss: 0.0118\n",
      "Epoch 147/200, Iteration 10/25, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 11/25, Loss: 0.0169\n",
      "Epoch 147/200, Iteration 12/25, Loss: 0.0250\n",
      "Epoch 147/200, Iteration 13/25, Loss: 0.0080\n",
      "Epoch 147/200, Iteration 14/25, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 15/25, Loss: 0.0112\n",
      "Epoch 147/200, Iteration 16/25, Loss: 0.0112\n",
      "Epoch 147/200, Iteration 17/25, Loss: 0.0234\n",
      "Epoch 147/200, Iteration 18/25, Loss: 0.0125\n",
      "Epoch 147/200, Iteration 19/25, Loss: 0.0225\n",
      "Epoch 147/200, Iteration 20/25, Loss: 0.0199\n",
      "Epoch 147/200, Iteration 21/25, Loss: 0.0192\n",
      "Epoch 147/200, Iteration 22/25, Loss: 0.0279\n",
      "Epoch 147/200, Iteration 23/25, Loss: 0.0158\n",
      "Epoch 147/200, Iteration 24/25, Loss: 0.0089\n",
      "Epoch 147/200, Iteration 25/25, Loss: 0.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005905, MRE: 0.334462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007725, MRE: 0.865080 \n",
      "\n",
      "Epoch 148/200, Iteration 1/25, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 2/25, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 3/25, Loss: 0.0093\n",
      "Epoch 148/200, Iteration 4/25, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 5/25, Loss: 0.0124\n",
      "Epoch 148/200, Iteration 6/25, Loss: 0.0253\n",
      "Epoch 148/200, Iteration 7/25, Loss: 0.0056\n",
      "Epoch 148/200, Iteration 8/25, Loss: 0.0072\n",
      "Epoch 148/200, Iteration 9/25, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 10/25, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 11/25, Loss: 0.0092\n",
      "Epoch 148/200, Iteration 12/25, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 13/25, Loss: 0.0199\n",
      "Epoch 148/200, Iteration 14/25, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 15/25, Loss: 0.0208\n",
      "Epoch 148/200, Iteration 16/25, Loss: 0.0159\n",
      "Epoch 148/200, Iteration 17/25, Loss: 0.0076\n",
      "Epoch 148/200, Iteration 18/25, Loss: 0.0132\n",
      "Epoch 148/200, Iteration 19/25, Loss: 0.0119\n",
      "Epoch 148/200, Iteration 20/25, Loss: 0.0079\n",
      "Epoch 148/200, Iteration 21/25, Loss: 0.0120\n",
      "Epoch 148/200, Iteration 22/25, Loss: 0.0060\n",
      "Epoch 148/200, Iteration 23/25, Loss: 0.0081\n",
      "Epoch 148/200, Iteration 24/25, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 25/25, Loss: 0.0228\n",
      "Train Error: \n",
      " Accuracy: 88.12%, Avg loss: 0.005962, MRE: 0.356855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007452, MRE: 0.894114 \n",
      "\n",
      "Epoch 149/200, Iteration 1/25, Loss: 0.0284\n",
      "Epoch 149/200, Iteration 2/25, Loss: 0.0169\n",
      "Epoch 149/200, Iteration 3/25, Loss: 0.0208\n",
      "Epoch 149/200, Iteration 4/25, Loss: 0.0162\n",
      "Epoch 149/200, Iteration 5/25, Loss: 0.0337\n",
      "Epoch 149/200, Iteration 6/25, Loss: 0.0165\n",
      "Epoch 149/200, Iteration 7/25, Loss: 0.0174\n",
      "Epoch 149/200, Iteration 8/25, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 9/25, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 10/25, Loss: 0.0049\n",
      "Epoch 149/200, Iteration 11/25, Loss: 0.0141\n",
      "Epoch 149/200, Iteration 12/25, Loss: 0.0071\n",
      "Epoch 149/200, Iteration 13/25, Loss: 0.0140\n",
      "Epoch 149/200, Iteration 14/25, Loss: 0.0139\n",
      "Epoch 149/200, Iteration 15/25, Loss: 0.0189\n",
      "Epoch 149/200, Iteration 16/25, Loss: 0.0137\n",
      "Epoch 149/200, Iteration 17/25, Loss: 0.0125\n",
      "Epoch 149/200, Iteration 18/25, Loss: 0.0194\n",
      "Epoch 149/200, Iteration 19/25, Loss: 0.0068\n",
      "Epoch 149/200, Iteration 20/25, Loss: 0.0131\n",
      "Epoch 149/200, Iteration 21/25, Loss: 0.0277\n",
      "Epoch 149/200, Iteration 22/25, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 23/25, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 24/25, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.005783, MRE: 0.335229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007719, MRE: 0.899474 \n",
      "\n",
      "Epoch 150/200, Iteration 1/25, Loss: 0.0062\n",
      "Epoch 150/200, Iteration 2/25, Loss: 0.0136\n",
      "Epoch 150/200, Iteration 3/25, Loss: 0.0072\n",
      "Epoch 150/200, Iteration 4/25, Loss: 0.0176\n",
      "Epoch 150/200, Iteration 5/25, Loss: 0.0159\n",
      "Epoch 150/200, Iteration 6/25, Loss: 0.0093\n",
      "Epoch 150/200, Iteration 7/25, Loss: 0.0170\n",
      "Epoch 150/200, Iteration 8/25, Loss: 0.0159\n",
      "Epoch 150/200, Iteration 9/25, Loss: 0.0163\n",
      "Epoch 150/200, Iteration 10/25, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 11/25, Loss: 0.0147\n",
      "Epoch 150/200, Iteration 12/25, Loss: 0.0203\n",
      "Epoch 150/200, Iteration 13/25, Loss: 0.0120\n",
      "Epoch 150/200, Iteration 14/25, Loss: 0.0076\n",
      "Epoch 150/200, Iteration 15/25, Loss: 0.0244\n",
      "Epoch 150/200, Iteration 16/25, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 17/25, Loss: 0.0076\n",
      "Epoch 150/200, Iteration 18/25, Loss: 0.0135\n",
      "Epoch 150/200, Iteration 19/25, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 20/25, Loss: 0.0064\n",
      "Epoch 150/200, Iteration 21/25, Loss: 0.0097\n",
      "Epoch 150/200, Iteration 22/25, Loss: 0.0177\n",
      "Epoch 150/200, Iteration 23/25, Loss: 0.0270\n",
      "Epoch 150/200, Iteration 24/25, Loss: 0.0175\n",
      "Epoch 150/200, Iteration 25/25, Loss: 0.0137\n",
      "Train Error: \n",
      " Accuracy: 91.12%, Avg loss: 0.005715, MRE: 0.341505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.007473, MRE: 0.696339 \n",
      "\n",
      "Epoch 151/200, Iteration 1/25, Loss: 0.0142\n",
      "Epoch 151/200, Iteration 2/25, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 3/25, Loss: 0.0220\n",
      "Epoch 151/200, Iteration 4/25, Loss: 0.0150\n",
      "Epoch 151/200, Iteration 5/25, Loss: 0.0183\n",
      "Epoch 151/200, Iteration 6/25, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 7/25, Loss: 0.0077\n",
      "Epoch 151/200, Iteration 8/25, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 9/25, Loss: 0.0251\n",
      "Epoch 151/200, Iteration 10/25, Loss: 0.0127\n",
      "Epoch 151/200, Iteration 11/25, Loss: 0.0075\n",
      "Epoch 151/200, Iteration 12/25, Loss: 0.0127\n",
      "Epoch 151/200, Iteration 13/25, Loss: 0.0167\n",
      "Epoch 151/200, Iteration 14/25, Loss: 0.0193\n",
      "Epoch 151/200, Iteration 15/25, Loss: 0.0087\n",
      "Epoch 151/200, Iteration 16/25, Loss: 0.0105\n",
      "Epoch 151/200, Iteration 17/25, Loss: 0.0268\n",
      "Epoch 151/200, Iteration 18/25, Loss: 0.0093\n",
      "Epoch 151/200, Iteration 19/25, Loss: 0.0280\n",
      "Epoch 151/200, Iteration 20/25, Loss: 0.0175\n",
      "Epoch 151/200, Iteration 21/25, Loss: 0.0269\n",
      "Epoch 151/200, Iteration 22/25, Loss: 0.0077\n",
      "Epoch 151/200, Iteration 23/25, Loss: 0.0102\n",
      "Epoch 151/200, Iteration 24/25, Loss: 0.0197\n",
      "Epoch 151/200, Iteration 25/25, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 83.62%, Avg loss: 0.006540, MRE: 0.391864 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.007787, MRE: 0.531904 \n",
      "\n",
      "Epoch 152/200, Iteration 1/25, Loss: 0.0277\n",
      "Epoch 152/200, Iteration 2/25, Loss: 0.0099\n",
      "Epoch 152/200, Iteration 3/25, Loss: 0.0365\n",
      "Epoch 152/200, Iteration 4/25, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 5/25, Loss: 0.0211\n",
      "Epoch 152/200, Iteration 6/25, Loss: 0.0406\n",
      "Epoch 152/200, Iteration 7/25, Loss: 0.0184\n",
      "Epoch 152/200, Iteration 8/25, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 9/25, Loss: 0.0234\n",
      "Epoch 152/200, Iteration 10/25, Loss: 0.0120\n",
      "Epoch 152/200, Iteration 11/25, Loss: 0.0129\n",
      "Epoch 152/200, Iteration 12/25, Loss: 0.0128\n",
      "Epoch 152/200, Iteration 13/25, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 14/25, Loss: 0.0145\n",
      "Epoch 152/200, Iteration 15/25, Loss: 0.0095\n",
      "Epoch 152/200, Iteration 16/25, Loss: 0.0068\n",
      "Epoch 152/200, Iteration 17/25, Loss: 0.0190\n",
      "Epoch 152/200, Iteration 18/25, Loss: 0.0067\n",
      "Epoch 152/200, Iteration 19/25, Loss: 0.0349\n",
      "Epoch 152/200, Iteration 20/25, Loss: 0.0233\n",
      "Epoch 152/200, Iteration 21/25, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 22/25, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 23/25, Loss: 0.0531\n",
      "Epoch 152/200, Iteration 24/25, Loss: 0.0112\n",
      "Epoch 152/200, Iteration 25/25, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006350, MRE: 0.382699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.008178, MRE: 0.916632 \n",
      "\n",
      "Epoch 153/200, Iteration 1/25, Loss: 0.0185\n",
      "Epoch 153/200, Iteration 2/25, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 3/25, Loss: 0.0080\n",
      "Epoch 153/200, Iteration 4/25, Loss: 0.0124\n",
      "Epoch 153/200, Iteration 5/25, Loss: 0.0080\n",
      "Epoch 153/200, Iteration 6/25, Loss: 0.0104\n",
      "Epoch 153/200, Iteration 7/25, Loss: 0.0107\n",
      "Epoch 153/200, Iteration 8/25, Loss: 0.0146\n",
      "Epoch 153/200, Iteration 9/25, Loss: 0.0245\n",
      "Epoch 153/200, Iteration 10/25, Loss: 0.0206\n",
      "Epoch 153/200, Iteration 11/25, Loss: 0.0168\n",
      "Epoch 153/200, Iteration 12/25, Loss: 0.0198\n",
      "Epoch 153/200, Iteration 13/25, Loss: 0.0110\n",
      "Epoch 153/200, Iteration 14/25, Loss: 0.0202\n",
      "Epoch 153/200, Iteration 15/25, Loss: 0.0142\n",
      "Epoch 153/200, Iteration 16/25, Loss: 0.0159\n",
      "Epoch 153/200, Iteration 17/25, Loss: 0.0099\n",
      "Epoch 153/200, Iteration 18/25, Loss: 0.0072\n",
      "Epoch 153/200, Iteration 19/25, Loss: 0.0435\n",
      "Epoch 153/200, Iteration 20/25, Loss: 0.0102\n",
      "Epoch 153/200, Iteration 21/25, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 22/25, Loss: 0.0069\n",
      "Epoch 153/200, Iteration 23/25, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 24/25, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 25/25, Loss: 0.0116\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.005744, MRE: 0.289675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.007442, MRE: 0.959426 \n",
      "\n",
      "Epoch 154/200, Iteration 1/25, Loss: 0.0129\n",
      "Epoch 154/200, Iteration 2/25, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 3/25, Loss: 0.0191\n",
      "Epoch 154/200, Iteration 4/25, Loss: 0.0195\n",
      "Epoch 154/200, Iteration 5/25, Loss: 0.0102\n",
      "Epoch 154/200, Iteration 6/25, Loss: 0.0301\n",
      "Epoch 154/200, Iteration 7/25, Loss: 0.0120\n",
      "Epoch 154/200, Iteration 8/25, Loss: 0.0134\n",
      "Epoch 154/200, Iteration 9/25, Loss: 0.0263\n",
      "Epoch 154/200, Iteration 10/25, Loss: 0.0247\n",
      "Epoch 154/200, Iteration 11/25, Loss: 0.0103\n",
      "Epoch 154/200, Iteration 12/25, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 13/25, Loss: 0.0169\n",
      "Epoch 154/200, Iteration 14/25, Loss: 0.0128\n",
      "Epoch 154/200, Iteration 15/25, Loss: 0.0119\n",
      "Epoch 154/200, Iteration 16/25, Loss: 0.0206\n",
      "Epoch 154/200, Iteration 17/25, Loss: 0.0130\n",
      "Epoch 154/200, Iteration 18/25, Loss: 0.0147\n",
      "Epoch 154/200, Iteration 19/25, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 20/25, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200, Iteration 21/25, Loss: 0.0111\n",
      "Epoch 154/200, Iteration 22/25, Loss: 0.0140\n",
      "Epoch 154/200, Iteration 23/25, Loss: 0.0149\n",
      "Epoch 154/200, Iteration 24/25, Loss: 0.0498\n",
      "Epoch 154/200, Iteration 25/25, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 70.88%, Avg loss: 0.008132, MRE: 0.525213 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.009048, MRE: 0.595853 \n",
      "\n",
      "Epoch 155/200, Iteration 1/25, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 2/25, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 3/25, Loss: 0.0155\n",
      "Epoch 155/200, Iteration 4/25, Loss: 0.0132\n",
      "Epoch 155/200, Iteration 5/25, Loss: 0.0064\n",
      "Epoch 155/200, Iteration 6/25, Loss: 0.0129\n",
      "Epoch 155/200, Iteration 7/25, Loss: 0.0101\n",
      "Epoch 155/200, Iteration 8/25, Loss: 0.0121\n",
      "Epoch 155/200, Iteration 9/25, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 10/25, Loss: 0.0157\n",
      "Epoch 155/200, Iteration 11/25, Loss: 0.0161\n",
      "Epoch 155/200, Iteration 12/25, Loss: 0.0142\n",
      "Epoch 155/200, Iteration 13/25, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 14/25, Loss: 0.0121\n",
      "Epoch 155/200, Iteration 15/25, Loss: 0.0080\n",
      "Epoch 155/200, Iteration 16/25, Loss: 0.0178\n",
      "Epoch 155/200, Iteration 17/25, Loss: 0.0166\n",
      "Epoch 155/200, Iteration 18/25, Loss: 0.0161\n",
      "Epoch 155/200, Iteration 19/25, Loss: 0.0139\n",
      "Epoch 155/200, Iteration 20/25, Loss: 0.0077\n",
      "Epoch 155/200, Iteration 21/25, Loss: 0.0085\n",
      "Epoch 155/200, Iteration 22/25, Loss: 0.0107\n",
      "Epoch 155/200, Iteration 23/25, Loss: 0.0060\n",
      "Epoch 155/200, Iteration 24/25, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.005642, MRE: 0.316930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.007446, MRE: 0.710919 \n",
      "\n",
      "Epoch 156/200, Iteration 1/25, Loss: 0.0115\n",
      "Epoch 156/200, Iteration 2/25, Loss: 0.0252\n",
      "Epoch 156/200, Iteration 3/25, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 4/25, Loss: 0.0121\n",
      "Epoch 156/200, Iteration 5/25, Loss: 0.0138\n",
      "Epoch 156/200, Iteration 6/25, Loss: 0.0109\n",
      "Epoch 156/200, Iteration 7/25, Loss: 0.0109\n",
      "Epoch 156/200, Iteration 8/25, Loss: 0.0144\n",
      "Epoch 156/200, Iteration 9/25, Loss: 0.0075\n",
      "Epoch 156/200, Iteration 10/25, Loss: 0.0265\n",
      "Epoch 156/200, Iteration 11/25, Loss: 0.0158\n",
      "Epoch 156/200, Iteration 12/25, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 13/25, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 14/25, Loss: 0.0169\n",
      "Epoch 156/200, Iteration 15/25, Loss: 0.0074\n",
      "Epoch 156/200, Iteration 16/25, Loss: 0.0268\n",
      "Epoch 156/200, Iteration 17/25, Loss: 0.0187\n",
      "Epoch 156/200, Iteration 18/25, Loss: 0.0126\n",
      "Epoch 156/200, Iteration 19/25, Loss: 0.0090\n",
      "Epoch 156/200, Iteration 20/25, Loss: 0.0157\n",
      "Epoch 156/200, Iteration 21/25, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 22/25, Loss: 0.0213\n",
      "Epoch 156/200, Iteration 23/25, Loss: 0.0235\n",
      "Epoch 156/200, Iteration 24/25, Loss: 0.0208\n",
      "Epoch 156/200, Iteration 25/25, Loss: 0.0204\n",
      "Train Error: \n",
      " Accuracy: 87.25%, Avg loss: 0.006117, MRE: 0.361932 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.007541, MRE: 0.737717 \n",
      "\n",
      "Epoch 157/200, Iteration 1/25, Loss: 0.0111\n",
      "Epoch 157/200, Iteration 2/25, Loss: 0.0163\n",
      "Epoch 157/200, Iteration 3/25, Loss: 0.0170\n",
      "Epoch 157/200, Iteration 4/25, Loss: 0.0168\n",
      "Epoch 157/200, Iteration 5/25, Loss: 0.0124\n",
      "Epoch 157/200, Iteration 6/25, Loss: 0.0059\n",
      "Epoch 157/200, Iteration 7/25, Loss: 0.0123\n",
      "Epoch 157/200, Iteration 8/25, Loss: 0.0137\n",
      "Epoch 157/200, Iteration 9/25, Loss: 0.0115\n",
      "Epoch 157/200, Iteration 10/25, Loss: 0.0311\n",
      "Epoch 157/200, Iteration 11/25, Loss: 0.0196\n",
      "Epoch 157/200, Iteration 12/25, Loss: 0.0171\n",
      "Epoch 157/200, Iteration 13/25, Loss: 0.0147\n",
      "Epoch 157/200, Iteration 14/25, Loss: 0.0078\n",
      "Epoch 157/200, Iteration 15/25, Loss: 0.0266\n",
      "Epoch 157/200, Iteration 16/25, Loss: 0.0149\n",
      "Epoch 157/200, Iteration 17/25, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 18/25, Loss: 0.0265\n",
      "Epoch 157/200, Iteration 19/25, Loss: 0.0059\n",
      "Epoch 157/200, Iteration 20/25, Loss: 0.0201\n",
      "Epoch 157/200, Iteration 21/25, Loss: 0.0175\n",
      "Epoch 157/200, Iteration 22/25, Loss: 0.0174\n",
      "Epoch 157/200, Iteration 23/25, Loss: 0.0050\n",
      "Epoch 157/200, Iteration 24/25, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.005789, MRE: 0.319115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.007195, MRE: 0.868813 \n",
      "\n",
      "Epoch 158/200, Iteration 1/25, Loss: 0.0138\n",
      "Epoch 158/200, Iteration 2/25, Loss: 0.0087\n",
      "Epoch 158/200, Iteration 3/25, Loss: 0.0156\n",
      "Epoch 158/200, Iteration 4/25, Loss: 0.0252\n",
      "Epoch 158/200, Iteration 5/25, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 6/25, Loss: 0.0325\n",
      "Epoch 158/200, Iteration 7/25, Loss: 0.0155\n",
      "Epoch 158/200, Iteration 8/25, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 9/25, Loss: 0.0102\n",
      "Epoch 158/200, Iteration 10/25, Loss: 0.0074\n",
      "Epoch 158/200, Iteration 11/25, Loss: 0.0195\n",
      "Epoch 158/200, Iteration 12/25, Loss: 0.0388\n",
      "Epoch 158/200, Iteration 13/25, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 14/25, Loss: 0.0121\n",
      "Epoch 158/200, Iteration 15/25, Loss: 0.0128\n",
      "Epoch 158/200, Iteration 16/25, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 17/25, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 18/25, Loss: 0.0105\n",
      "Epoch 158/200, Iteration 19/25, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 20/25, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 21/25, Loss: 0.0217\n",
      "Epoch 158/200, Iteration 22/25, Loss: 0.0237\n",
      "Epoch 158/200, Iteration 23/25, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 24/25, Loss: 0.0119\n",
      "Epoch 158/200, Iteration 25/25, Loss: 0.0250\n",
      "Train Error: \n",
      " Accuracy: 90.38%, Avg loss: 0.005903, MRE: 0.345333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007566, MRE: 0.607297 \n",
      "\n",
      "Epoch 159/200, Iteration 1/25, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 2/25, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 3/25, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 4/25, Loss: 0.0140\n",
      "Epoch 159/200, Iteration 5/25, Loss: 0.0334\n",
      "Epoch 159/200, Iteration 6/25, Loss: 0.0083\n",
      "Epoch 159/200, Iteration 7/25, Loss: 0.0071\n",
      "Epoch 159/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 159/200, Iteration 9/25, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 10/25, Loss: 0.0096\n",
      "Epoch 159/200, Iteration 11/25, Loss: 0.0171\n",
      "Epoch 159/200, Iteration 12/25, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 13/25, Loss: 0.0234\n",
      "Epoch 159/200, Iteration 14/25, Loss: 0.0224\n",
      "Epoch 159/200, Iteration 15/25, Loss: 0.0194\n",
      "Epoch 159/200, Iteration 16/25, Loss: 0.0190\n",
      "Epoch 159/200, Iteration 17/25, Loss: 0.0179\n",
      "Epoch 159/200, Iteration 18/25, Loss: 0.0100\n",
      "Epoch 159/200, Iteration 19/25, Loss: 0.0164\n",
      "Epoch 159/200, Iteration 20/25, Loss: 0.0131\n",
      "Epoch 159/200, Iteration 21/25, Loss: 0.0159\n",
      "Epoch 159/200, Iteration 22/25, Loss: 0.0166\n",
      "Epoch 159/200, Iteration 23/25, Loss: 0.0312\n",
      "Epoch 159/200, Iteration 24/25, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 25/25, Loss: 0.0102\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.006031, MRE: 0.335989 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.008025, MRE: 0.774044 \n",
      "\n",
      "Epoch 160/200, Iteration 1/25, Loss: 0.0069\n",
      "Epoch 160/200, Iteration 2/25, Loss: 0.0055\n",
      "Epoch 160/200, Iteration 3/25, Loss: 0.0179\n",
      "Epoch 160/200, Iteration 4/25, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 5/25, Loss: 0.0150\n",
      "Epoch 160/200, Iteration 6/25, Loss: 0.0169\n",
      "Epoch 160/200, Iteration 7/25, Loss: 0.0315\n",
      "Epoch 160/200, Iteration 8/25, Loss: 0.0150\n",
      "Epoch 160/200, Iteration 9/25, Loss: 0.0226\n",
      "Epoch 160/200, Iteration 10/25, Loss: 0.0079\n",
      "Epoch 160/200, Iteration 11/25, Loss: 0.0077\n",
      "Epoch 160/200, Iteration 12/25, Loss: 0.0096\n",
      "Epoch 160/200, Iteration 13/25, Loss: 0.0224\n",
      "Epoch 160/200, Iteration 14/25, Loss: 0.0114\n",
      "Epoch 160/200, Iteration 15/25, Loss: 0.0089\n",
      "Epoch 160/200, Iteration 16/25, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 17/25, Loss: 0.0093\n",
      "Epoch 160/200, Iteration 18/25, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 19/25, Loss: 0.0123\n",
      "Epoch 160/200, Iteration 20/25, Loss: 0.0202\n",
      "Epoch 160/200, Iteration 21/25, Loss: 0.0248\n",
      "Epoch 160/200, Iteration 22/25, Loss: 0.0065\n",
      "Epoch 160/200, Iteration 23/25, Loss: 0.0125\n",
      "Epoch 160/200, Iteration 24/25, Loss: 0.0177\n",
      "Epoch 160/200, Iteration 25/25, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.005766, MRE: 0.314915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007871, MRE: 0.699222 \n",
      "\n",
      "Epoch 161/200, Iteration 1/25, Loss: 0.0288\n",
      "Epoch 161/200, Iteration 2/25, Loss: 0.0080\n",
      "Epoch 161/200, Iteration 3/25, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 4/25, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 5/25, Loss: 0.0063\n",
      "Epoch 161/200, Iteration 6/25, Loss: 0.0117\n",
      "Epoch 161/200, Iteration 7/25, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 8/25, Loss: 0.0139\n",
      "Epoch 161/200, Iteration 9/25, Loss: 0.0165\n",
      "Epoch 161/200, Iteration 10/25, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 11/25, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 12/25, Loss: 0.0281\n",
      "Epoch 161/200, Iteration 13/25, Loss: 0.0079\n",
      "Epoch 161/200, Iteration 14/25, Loss: 0.0393\n",
      "Epoch 161/200, Iteration 15/25, Loss: 0.0146\n",
      "Epoch 161/200, Iteration 16/25, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 17/25, Loss: 0.0153\n",
      "Epoch 161/200, Iteration 18/25, Loss: 0.0207\n",
      "Epoch 161/200, Iteration 19/25, Loss: 0.0101\n",
      "Epoch 161/200, Iteration 20/25, Loss: 0.0105\n",
      "Epoch 161/200, Iteration 21/25, Loss: 0.0129\n",
      "Epoch 161/200, Iteration 22/25, Loss: 0.0134\n",
      "Epoch 161/200, Iteration 23/25, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 24/25, Loss: 0.0101\n",
      "Epoch 161/200, Iteration 25/25, Loss: 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.005605, MRE: 0.339872 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007623, MRE: 0.631177 \n",
      "\n",
      "Epoch 162/200, Iteration 1/25, Loss: 0.0132\n",
      "Epoch 162/200, Iteration 2/25, Loss: 0.0305\n",
      "Epoch 162/200, Iteration 3/25, Loss: 0.0109\n",
      "Epoch 162/200, Iteration 4/25, Loss: 0.0224\n",
      "Epoch 162/200, Iteration 5/25, Loss: 0.0228\n",
      "Epoch 162/200, Iteration 6/25, Loss: 0.0206\n",
      "Epoch 162/200, Iteration 7/25, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 8/25, Loss: 0.0176\n",
      "Epoch 162/200, Iteration 9/25, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 10/25, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 11/25, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 12/25, Loss: 0.0059\n",
      "Epoch 162/200, Iteration 13/25, Loss: 0.0213\n",
      "Epoch 162/200, Iteration 14/25, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 15/25, Loss: 0.0151\n",
      "Epoch 162/200, Iteration 16/25, Loss: 0.0116\n",
      "Epoch 162/200, Iteration 17/25, Loss: 0.0068\n",
      "Epoch 162/200, Iteration 18/25, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 19/25, Loss: 0.0109\n",
      "Epoch 162/200, Iteration 20/25, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 21/25, Loss: 0.0163\n",
      "Epoch 162/200, Iteration 22/25, Loss: 0.0060\n",
      "Epoch 162/200, Iteration 23/25, Loss: 0.0089\n",
      "Epoch 162/200, Iteration 24/25, Loss: 0.0199\n",
      "Epoch 162/200, Iteration 25/25, Loss: 0.0078\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.005636, MRE: 0.324332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.007146, MRE: 0.976498 \n",
      "\n",
      "Epoch 163/200, Iteration 1/25, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 2/25, Loss: 0.0122\n",
      "Epoch 163/200, Iteration 3/25, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 4/25, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 5/25, Loss: 0.0255\n",
      "Epoch 163/200, Iteration 6/25, Loss: 0.0180\n",
      "Epoch 163/200, Iteration 7/25, Loss: 0.0219\n",
      "Epoch 163/200, Iteration 8/25, Loss: 0.0248\n",
      "Epoch 163/200, Iteration 9/25, Loss: 0.0313\n",
      "Epoch 163/200, Iteration 10/25, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 11/25, Loss: 0.0114\n",
      "Epoch 163/200, Iteration 12/25, Loss: 0.0079\n",
      "Epoch 163/200, Iteration 13/25, Loss: 0.0398\n",
      "Epoch 163/200, Iteration 14/25, Loss: 0.0217\n",
      "Epoch 163/200, Iteration 15/25, Loss: 0.0072\n",
      "Epoch 163/200, Iteration 16/25, Loss: 0.0127\n",
      "Epoch 163/200, Iteration 17/25, Loss: 0.0093\n",
      "Epoch 163/200, Iteration 18/25, Loss: 0.0165\n",
      "Epoch 163/200, Iteration 19/25, Loss: 0.0194\n",
      "Epoch 163/200, Iteration 20/25, Loss: 0.0146\n",
      "Epoch 163/200, Iteration 21/25, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 22/25, Loss: 0.0181\n",
      "Epoch 163/200, Iteration 23/25, Loss: 0.0063\n",
      "Epoch 163/200, Iteration 24/25, Loss: 0.0119\n",
      "Epoch 163/200, Iteration 25/25, Loss: 0.0127\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.005626, MRE: 0.312237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.007348, MRE: 0.687423 \n",
      "\n",
      "Epoch 164/200, Iteration 1/25, Loss: 0.0161\n",
      "Epoch 164/200, Iteration 2/25, Loss: 0.0136\n",
      "Epoch 164/200, Iteration 3/25, Loss: 0.0276\n",
      "Epoch 164/200, Iteration 4/25, Loss: 0.0070\n",
      "Epoch 164/200, Iteration 5/25, Loss: 0.0137\n",
      "Epoch 164/200, Iteration 6/25, Loss: 0.0178\n",
      "Epoch 164/200, Iteration 7/25, Loss: 0.0120\n",
      "Epoch 164/200, Iteration 8/25, Loss: 0.0073\n",
      "Epoch 164/200, Iteration 9/25, Loss: 0.0145\n",
      "Epoch 164/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 164/200, Iteration 11/25, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 12/25, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 13/25, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 14/25, Loss: 0.0138\n",
      "Epoch 164/200, Iteration 15/25, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 16/25, Loss: 0.0063\n",
      "Epoch 164/200, Iteration 17/25, Loss: 0.0148\n",
      "Epoch 164/200, Iteration 18/25, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 19/25, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 20/25, Loss: 0.0123\n",
      "Epoch 164/200, Iteration 21/25, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 22/25, Loss: 0.0100\n",
      "Epoch 164/200, Iteration 23/25, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 24/25, Loss: 0.0085\n",
      "Epoch 164/200, Iteration 25/25, Loss: 0.0152\n",
      "Train Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.005501, MRE: 0.300501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007159, MRE: 0.904600 \n",
      "\n",
      "Epoch 165/200, Iteration 1/25, Loss: 0.0469\n",
      "Epoch 165/200, Iteration 2/25, Loss: 0.0387\n",
      "Epoch 165/200, Iteration 3/25, Loss: 0.0172\n",
      "Epoch 165/200, Iteration 4/25, Loss: 0.0295\n",
      "Epoch 165/200, Iteration 5/25, Loss: 0.0096\n",
      "Epoch 165/200, Iteration 6/25, Loss: 0.0127\n",
      "Epoch 165/200, Iteration 7/25, Loss: 0.0048\n",
      "Epoch 165/200, Iteration 8/25, Loss: 0.0159\n",
      "Epoch 165/200, Iteration 9/25, Loss: 0.0147\n",
      "Epoch 165/200, Iteration 10/25, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 11/25, Loss: 0.0380\n",
      "Epoch 165/200, Iteration 12/25, Loss: 0.0062\n",
      "Epoch 165/200, Iteration 13/25, Loss: 0.0194\n",
      "Epoch 165/200, Iteration 14/25, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 15/25, Loss: 0.0460\n",
      "Epoch 165/200, Iteration 16/25, Loss: 0.0052\n",
      "Epoch 165/200, Iteration 17/25, Loss: 0.0189\n",
      "Epoch 165/200, Iteration 18/25, Loss: 0.0220\n",
      "Epoch 165/200, Iteration 19/25, Loss: 0.0228\n",
      "Epoch 165/200, Iteration 20/25, Loss: 0.0189\n",
      "Epoch 165/200, Iteration 21/25, Loss: 0.0233\n",
      "Epoch 165/200, Iteration 22/25, Loss: 0.0194\n",
      "Epoch 165/200, Iteration 23/25, Loss: 0.0131\n",
      "Epoch 165/200, Iteration 24/25, Loss: 0.0233\n",
      "Epoch 165/200, Iteration 25/25, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.006203, MRE: 0.300160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008506, MRE: 0.795399 \n",
      "\n",
      "Epoch 166/200, Iteration 1/25, Loss: 0.0315\n",
      "Epoch 166/200, Iteration 2/25, Loss: 0.0198\n",
      "Epoch 166/200, Iteration 3/25, Loss: 0.0082\n",
      "Epoch 166/200, Iteration 4/25, Loss: 0.0052\n",
      "Epoch 166/200, Iteration 5/25, Loss: 0.0120\n",
      "Epoch 166/200, Iteration 6/25, Loss: 0.0117\n",
      "Epoch 166/200, Iteration 7/25, Loss: 0.0106\n",
      "Epoch 166/200, Iteration 8/25, Loss: 0.0138\n",
      "Epoch 166/200, Iteration 9/25, Loss: 0.0107\n",
      "Epoch 166/200, Iteration 10/25, Loss: 0.0164\n",
      "Epoch 166/200, Iteration 11/25, Loss: 0.0277\n",
      "Epoch 166/200, Iteration 12/25, Loss: 0.0141\n",
      "Epoch 166/200, Iteration 13/25, Loss: 0.0244\n",
      "Epoch 166/200, Iteration 14/25, Loss: 0.0137\n",
      "Epoch 166/200, Iteration 15/25, Loss: 0.0104\n",
      "Epoch 166/200, Iteration 16/25, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 17/25, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 18/25, Loss: 0.0172\n",
      "Epoch 166/200, Iteration 19/25, Loss: 0.0077\n",
      "Epoch 166/200, Iteration 20/25, Loss: 0.0090\n",
      "Epoch 166/200, Iteration 21/25, Loss: 0.0069\n",
      "Epoch 166/200, Iteration 22/25, Loss: 0.0081\n",
      "Epoch 166/200, Iteration 23/25, Loss: 0.0145\n",
      "Epoch 166/200, Iteration 24/25, Loss: 0.0181\n",
      "Epoch 166/200, Iteration 25/25, Loss: 0.0094\n",
      "Train Error: \n",
      " Accuracy: 88.88%, Avg loss: 0.005898, MRE: 0.351935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.007378, MRE: 0.786234 \n",
      "\n",
      "Epoch 167/200, Iteration 1/25, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 2/25, Loss: 0.0080\n",
      "Epoch 167/200, Iteration 3/25, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 4/25, Loss: 0.0130\n",
      "Epoch 167/200, Iteration 5/25, Loss: 0.0081\n",
      "Epoch 167/200, Iteration 6/25, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 7/25, Loss: 0.0111\n",
      "Epoch 167/200, Iteration 8/25, Loss: 0.0262\n",
      "Epoch 167/200, Iteration 9/25, Loss: 0.0197\n",
      "Epoch 167/200, Iteration 10/25, Loss: 0.0317\n",
      "Epoch 167/200, Iteration 11/25, Loss: 0.0108\n",
      "Epoch 167/200, Iteration 12/25, Loss: 0.0149\n",
      "Epoch 167/200, Iteration 13/25, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 14/25, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 15/25, Loss: 0.0133\n",
      "Epoch 167/200, Iteration 16/25, Loss: 0.0174\n",
      "Epoch 167/200, Iteration 17/25, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 18/25, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 19/25, Loss: 0.0058\n",
      "Epoch 167/200, Iteration 20/25, Loss: 0.0107\n",
      "Epoch 167/200, Iteration 21/25, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 22/25, Loss: 0.0084\n",
      "Epoch 167/200, Iteration 23/25, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 24/25, Loss: 0.0071\n",
      "Epoch 167/200, Iteration 25/25, Loss: 0.0128\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005664, MRE: 0.330697 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007527, MRE: 0.809225 \n",
      "\n",
      "Epoch 168/200, Iteration 1/25, Loss: 0.0180\n",
      "Epoch 168/200, Iteration 2/25, Loss: 0.0214\n",
      "Epoch 168/200, Iteration 3/25, Loss: 0.0266\n",
      "Epoch 168/200, Iteration 4/25, Loss: 0.0191\n",
      "Epoch 168/200, Iteration 5/25, Loss: 0.0079\n",
      "Epoch 168/200, Iteration 6/25, Loss: 0.0228\n",
      "Epoch 168/200, Iteration 7/25, Loss: 0.0128\n",
      "Epoch 168/200, Iteration 8/25, Loss: 0.0106\n",
      "Epoch 168/200, Iteration 9/25, Loss: 0.0248\n",
      "Epoch 168/200, Iteration 10/25, Loss: 0.0125\n",
      "Epoch 168/200, Iteration 11/25, Loss: 0.0127\n",
      "Epoch 168/200, Iteration 12/25, Loss: 0.0081\n",
      "Epoch 168/200, Iteration 13/25, Loss: 0.0173\n",
      "Epoch 168/200, Iteration 14/25, Loss: 0.0122\n",
      "Epoch 168/200, Iteration 15/25, Loss: 0.0128\n",
      "Epoch 168/200, Iteration 16/25, Loss: 0.0253\n",
      "Epoch 168/200, Iteration 17/25, Loss: 0.0163\n",
      "Epoch 168/200, Iteration 18/25, Loss: 0.0284\n",
      "Epoch 168/200, Iteration 19/25, Loss: 0.0197\n",
      "Epoch 168/200, Iteration 20/25, Loss: 0.0246\n",
      "Epoch 168/200, Iteration 21/25, Loss: 0.0111\n",
      "Epoch 168/200, Iteration 22/25, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200, Iteration 23/25, Loss: 0.0059\n",
      "Epoch 168/200, Iteration 24/25, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 25/25, Loss: 0.0116\n",
      "Train Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.005635, MRE: 0.283582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.007035, MRE: 0.894667 \n",
      "\n",
      "Epoch 169/200, Iteration 1/25, Loss: 0.0117\n",
      "Epoch 169/200, Iteration 2/25, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 3/25, Loss: 0.0282\n",
      "Epoch 169/200, Iteration 4/25, Loss: 0.0182\n",
      "Epoch 169/200, Iteration 5/25, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 6/25, Loss: 0.0141\n",
      "Epoch 169/200, Iteration 7/25, Loss: 0.0113\n",
      "Epoch 169/200, Iteration 8/25, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 9/25, Loss: 0.0143\n",
      "Epoch 169/200, Iteration 10/25, Loss: 0.0147\n",
      "Epoch 169/200, Iteration 11/25, Loss: 0.0133\n",
      "Epoch 169/200, Iteration 12/25, Loss: 0.0108\n",
      "Epoch 169/200, Iteration 13/25, Loss: 0.0132\n",
      "Epoch 169/200, Iteration 14/25, Loss: 0.0110\n",
      "Epoch 169/200, Iteration 15/25, Loss: 0.0069\n",
      "Epoch 169/200, Iteration 16/25, Loss: 0.0062\n",
      "Epoch 169/200, Iteration 17/25, Loss: 0.0137\n",
      "Epoch 169/200, Iteration 18/25, Loss: 0.0573\n",
      "Epoch 169/200, Iteration 19/25, Loss: 0.0174\n",
      "Epoch 169/200, Iteration 20/25, Loss: 0.0144\n",
      "Epoch 169/200, Iteration 21/25, Loss: 0.0111\n",
      "Epoch 169/200, Iteration 22/25, Loss: 0.0056\n",
      "Epoch 169/200, Iteration 23/25, Loss: 0.0116\n",
      "Epoch 169/200, Iteration 24/25, Loss: 0.0108\n",
      "Epoch 169/200, Iteration 25/25, Loss: 0.0134\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.005531, MRE: 0.321830 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.007457, MRE: 0.754983 \n",
      "\n",
      "Epoch 170/200, Iteration 1/25, Loss: 0.0279\n",
      "Epoch 170/200, Iteration 2/25, Loss: 0.0155\n",
      "Epoch 170/200, Iteration 3/25, Loss: 0.0084\n",
      "Epoch 170/200, Iteration 4/25, Loss: 0.0411\n",
      "Epoch 170/200, Iteration 5/25, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 6/25, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 7/25, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 8/25, Loss: 0.0156\n",
      "Epoch 170/200, Iteration 9/25, Loss: 0.0160\n",
      "Epoch 170/200, Iteration 10/25, Loss: 0.0077\n",
      "Epoch 170/200, Iteration 11/25, Loss: 0.0400\n",
      "Epoch 170/200, Iteration 12/25, Loss: 0.0123\n",
      "Epoch 170/200, Iteration 13/25, Loss: 0.0088\n",
      "Epoch 170/200, Iteration 14/25, Loss: 0.0263\n",
      "Epoch 170/200, Iteration 15/25, Loss: 0.0070\n",
      "Epoch 170/200, Iteration 16/25, Loss: 0.0235\n",
      "Epoch 170/200, Iteration 17/25, Loss: 0.0123\n",
      "Epoch 170/200, Iteration 18/25, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 19/25, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 20/25, Loss: 0.0184\n",
      "Epoch 170/200, Iteration 21/25, Loss: 0.0093\n",
      "Epoch 170/200, Iteration 22/25, Loss: 0.0092\n",
      "Epoch 170/200, Iteration 23/25, Loss: 0.0202\n",
      "Epoch 170/200, Iteration 24/25, Loss: 0.0088\n",
      "Epoch 170/200, Iteration 25/25, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005697, MRE: 0.330829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007790, MRE: 0.705054 \n",
      "\n",
      "Epoch 171/200, Iteration 1/25, Loss: 0.0277\n",
      "Epoch 171/200, Iteration 2/25, Loss: 0.0291\n",
      "Epoch 171/200, Iteration 3/25, Loss: 0.0117\n",
      "Epoch 171/200, Iteration 4/25, Loss: 0.0191\n",
      "Epoch 171/200, Iteration 5/25, Loss: 0.0169\n",
      "Epoch 171/200, Iteration 6/25, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 7/25, Loss: 0.0120\n",
      "Epoch 171/200, Iteration 8/25, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 9/25, Loss: 0.0082\n",
      "Epoch 171/200, Iteration 10/25, Loss: 0.0068\n",
      "Epoch 171/200, Iteration 11/25, Loss: 0.0078\n",
      "Epoch 171/200, Iteration 12/25, Loss: 0.0181\n",
      "Epoch 171/200, Iteration 13/25, Loss: 0.0104\n",
      "Epoch 171/200, Iteration 14/25, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 15/25, Loss: 0.0122\n",
      "Epoch 171/200, Iteration 16/25, Loss: 0.0100\n",
      "Epoch 171/200, Iteration 17/25, Loss: 0.0160\n",
      "Epoch 171/200, Iteration 18/25, Loss: 0.0078\n",
      "Epoch 171/200, Iteration 19/25, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 20/25, Loss: 0.0170\n",
      "Epoch 171/200, Iteration 21/25, Loss: 0.0070\n",
      "Epoch 171/200, Iteration 22/25, Loss: 0.0201\n",
      "Epoch 171/200, Iteration 23/25, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 24/25, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 25/25, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.005653, MRE: 0.359568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007467, MRE: 0.770480 \n",
      "\n",
      "Epoch 172/200, Iteration 1/25, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 2/25, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 3/25, Loss: 0.0073\n",
      "Epoch 172/200, Iteration 4/25, Loss: 0.0167\n",
      "Epoch 172/200, Iteration 5/25, Loss: 0.0093\n",
      "Epoch 172/200, Iteration 6/25, Loss: 0.0064\n",
      "Epoch 172/200, Iteration 7/25, Loss: 0.0126\n",
      "Epoch 172/200, Iteration 8/25, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 9/25, Loss: 0.0050\n",
      "Epoch 172/200, Iteration 10/25, Loss: 0.0223\n",
      "Epoch 172/200, Iteration 11/25, Loss: 0.0164\n",
      "Epoch 172/200, Iteration 12/25, Loss: 0.0196\n",
      "Epoch 172/200, Iteration 13/25, Loss: 0.0113\n",
      "Epoch 172/200, Iteration 14/25, Loss: 0.0135\n",
      "Epoch 172/200, Iteration 15/25, Loss: 0.0103\n",
      "Epoch 172/200, Iteration 16/25, Loss: 0.0286\n",
      "Epoch 172/200, Iteration 17/25, Loss: 0.0082\n",
      "Epoch 172/200, Iteration 18/25, Loss: 0.0078\n",
      "Epoch 172/200, Iteration 19/25, Loss: 0.0092\n",
      "Epoch 172/200, Iteration 20/25, Loss: 0.0118\n",
      "Epoch 172/200, Iteration 21/25, Loss: 0.0091\n",
      "Epoch 172/200, Iteration 22/25, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 23/25, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 24/25, Loss: 0.0125\n",
      "Epoch 172/200, Iteration 25/25, Loss: 0.0102\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005606, MRE: 0.296816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007684, MRE: 0.811347 \n",
      "\n",
      "Epoch 173/200, Iteration 1/25, Loss: 0.0123\n",
      "Epoch 173/200, Iteration 2/25, Loss: 0.0087\n",
      "Epoch 173/200, Iteration 3/25, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 4/25, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 5/25, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 6/25, Loss: 0.0149\n",
      "Epoch 173/200, Iteration 7/25, Loss: 0.0342\n",
      "Epoch 173/200, Iteration 8/25, Loss: 0.0119\n",
      "Epoch 173/200, Iteration 9/25, Loss: 0.0167\n",
      "Epoch 173/200, Iteration 10/25, Loss: 0.0076\n",
      "Epoch 173/200, Iteration 11/25, Loss: 0.0238\n",
      "Epoch 173/200, Iteration 12/25, Loss: 0.0315\n",
      "Epoch 173/200, Iteration 13/25, Loss: 0.0105\n",
      "Epoch 173/200, Iteration 14/25, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 15/25, Loss: 0.0175\n",
      "Epoch 173/200, Iteration 16/25, Loss: 0.0262\n",
      "Epoch 173/200, Iteration 17/25, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 18/25, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 19/25, Loss: 0.0114\n",
      "Epoch 173/200, Iteration 20/25, Loss: 0.0083\n",
      "Epoch 173/200, Iteration 21/25, Loss: 0.0138\n",
      "Epoch 173/200, Iteration 22/25, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 23/25, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 24/25, Loss: 0.0089\n",
      "Epoch 173/200, Iteration 25/25, Loss: 0.0190\n",
      "Train Error: \n",
      " Accuracy: 89.88%, Avg loss: 0.005721, MRE: 0.318179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.007158, MRE: 0.795238 \n",
      "\n",
      "Epoch 174/200, Iteration 1/25, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 2/25, Loss: 0.0117\n",
      "Epoch 174/200, Iteration 3/25, Loss: 0.0140\n",
      "Epoch 174/200, Iteration 4/25, Loss: 0.0351\n",
      "Epoch 174/200, Iteration 5/25, Loss: 0.0098\n",
      "Epoch 174/200, Iteration 6/25, Loss: 0.0092\n",
      "Epoch 174/200, Iteration 7/25, Loss: 0.0146\n",
      "Epoch 174/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 174/200, Iteration 9/25, Loss: 0.0197\n",
      "Epoch 174/200, Iteration 10/25, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 11/25, Loss: 0.0123\n",
      "Epoch 174/200, Iteration 12/25, Loss: 0.0063\n",
      "Epoch 174/200, Iteration 13/25, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 14/25, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 15/25, Loss: 0.0104\n",
      "Epoch 174/200, Iteration 16/25, Loss: 0.0081\n",
      "Epoch 174/200, Iteration 17/25, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 18/25, Loss: 0.0162\n",
      "Epoch 174/200, Iteration 19/25, Loss: 0.0153\n",
      "Epoch 174/200, Iteration 20/25, Loss: 0.0248\n",
      "Epoch 174/200, Iteration 21/25, Loss: 0.0363\n",
      "Epoch 174/200, Iteration 22/25, Loss: 0.0075\n",
      "Epoch 174/200, Iteration 23/25, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 24/25, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 25/25, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 87.88%, Avg loss: 0.006000, MRE: 0.340203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007350, MRE: 0.679656 \n",
      "\n",
      "Epoch 175/200, Iteration 1/25, Loss: 0.0085\n",
      "Epoch 175/200, Iteration 2/25, Loss: 0.0087\n",
      "Epoch 175/200, Iteration 3/25, Loss: 0.0208\n",
      "Epoch 175/200, Iteration 4/25, Loss: 0.0081\n",
      "Epoch 175/200, Iteration 5/25, Loss: 0.0211\n",
      "Epoch 175/200, Iteration 6/25, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 7/25, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 8/25, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 9/25, Loss: 0.0101\n",
      "Epoch 175/200, Iteration 10/25, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 11/25, Loss: 0.0094\n",
      "Epoch 175/200, Iteration 12/25, Loss: 0.0078\n",
      "Epoch 175/200, Iteration 13/25, Loss: 0.0114\n",
      "Epoch 175/200, Iteration 14/25, Loss: 0.0104\n",
      "Epoch 175/200, Iteration 15/25, Loss: 0.0087\n",
      "Epoch 175/200, Iteration 16/25, Loss: 0.0060\n",
      "Epoch 175/200, Iteration 17/25, Loss: 0.0134\n",
      "Epoch 175/200, Iteration 18/25, Loss: 0.0068\n",
      "Epoch 175/200, Iteration 19/25, Loss: 0.0064\n",
      "Epoch 175/200, Iteration 20/25, Loss: 0.0165\n",
      "Epoch 175/200, Iteration 21/25, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 22/25, Loss: 0.0075\n",
      "Epoch 175/200, Iteration 23/25, Loss: 0.0165\n",
      "Epoch 175/200, Iteration 24/25, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 25/25, Loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 85.38%, Avg loss: 0.006260, MRE: 0.361394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.007563, MRE: 0.603726 \n",
      "\n",
      "Epoch 176/200, Iteration 1/25, Loss: 0.0099\n",
      "Epoch 176/200, Iteration 2/25, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 3/25, Loss: 0.0105\n",
      "Epoch 176/200, Iteration 4/25, Loss: 0.0105\n",
      "Epoch 176/200, Iteration 5/25, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 6/25, Loss: 0.0262\n",
      "Epoch 176/200, Iteration 7/25, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 8/25, Loss: 0.0094\n",
      "Epoch 176/200, Iteration 9/25, Loss: 0.0226\n",
      "Epoch 176/200, Iteration 10/25, Loss: 0.0139\n",
      "Epoch 176/200, Iteration 11/25, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 12/25, Loss: 0.0105\n",
      "Epoch 176/200, Iteration 13/25, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 14/25, Loss: 0.0112\n",
      "Epoch 176/200, Iteration 15/25, Loss: 0.0152\n",
      "Epoch 176/200, Iteration 16/25, Loss: 0.0076\n",
      "Epoch 176/200, Iteration 17/25, Loss: 0.0084\n",
      "Epoch 176/200, Iteration 18/25, Loss: 0.0128\n",
      "Epoch 176/200, Iteration 19/25, Loss: 0.0158\n",
      "Epoch 176/200, Iteration 20/25, Loss: 0.0056\n",
      "Epoch 176/200, Iteration 21/25, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 22/25, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 23/25, Loss: 0.0126\n",
      "Epoch 176/200, Iteration 24/25, Loss: 0.0084\n",
      "Epoch 176/200, Iteration 25/25, Loss: 0.0089\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.005522, MRE: 0.334960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.007179, MRE: 0.650081 \n",
      "\n",
      "Epoch 177/200, Iteration 1/25, Loss: 0.0121\n",
      "Epoch 177/200, Iteration 2/25, Loss: 0.0133\n",
      "Epoch 177/200, Iteration 3/25, Loss: 0.0116\n",
      "Epoch 177/200, Iteration 4/25, Loss: 0.0151\n",
      "Epoch 177/200, Iteration 5/25, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 6/25, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 7/25, Loss: 0.0061\n",
      "Epoch 177/200, Iteration 8/25, Loss: 0.0103\n",
      "Epoch 177/200, Iteration 9/25, Loss: 0.0129\n",
      "Epoch 177/200, Iteration 10/25, Loss: 0.0083\n",
      "Epoch 177/200, Iteration 11/25, Loss: 0.0424\n",
      "Epoch 177/200, Iteration 12/25, Loss: 0.0172\n",
      "Epoch 177/200, Iteration 13/25, Loss: 0.0121\n",
      "Epoch 177/200, Iteration 14/25, Loss: 0.0103\n",
      "Epoch 177/200, Iteration 15/25, Loss: 0.0101\n",
      "Epoch 177/200, Iteration 16/25, Loss: 0.0080\n",
      "Epoch 177/200, Iteration 17/25, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 18/25, Loss: 0.0146\n",
      "Epoch 177/200, Iteration 19/25, Loss: 0.0088\n",
      "Epoch 177/200, Iteration 20/25, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 21/25, Loss: 0.0273\n",
      "Epoch 177/200, Iteration 22/25, Loss: 0.0082\n",
      "Epoch 177/200, Iteration 23/25, Loss: 0.0294\n",
      "Epoch 177/200, Iteration 24/25, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 25/25, Loss: 0.0174\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.005905, MRE: 0.359096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007669, MRE: 0.975667 \n",
      "\n",
      "Epoch 178/200, Iteration 1/25, Loss: 0.0149\n",
      "Epoch 178/200, Iteration 2/25, Loss: 0.0267\n",
      "Epoch 178/200, Iteration 3/25, Loss: 0.0089\n",
      "Epoch 178/200, Iteration 4/25, Loss: 0.0117\n",
      "Epoch 178/200, Iteration 5/25, Loss: 0.0239\n",
      "Epoch 178/200, Iteration 6/25, Loss: 0.0089\n",
      "Epoch 178/200, Iteration 7/25, Loss: 0.0124\n",
      "Epoch 178/200, Iteration 8/25, Loss: 0.0183\n",
      "Epoch 178/200, Iteration 9/25, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 10/25, Loss: 0.0073\n",
      "Epoch 178/200, Iteration 11/25, Loss: 0.0238\n",
      "Epoch 178/200, Iteration 12/25, Loss: 0.0152\n",
      "Epoch 178/200, Iteration 13/25, Loss: 0.0063\n",
      "Epoch 178/200, Iteration 14/25, Loss: 0.0089\n",
      "Epoch 178/200, Iteration 15/25, Loss: 0.0068\n",
      "Epoch 178/200, Iteration 16/25, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 17/25, Loss: 0.0195\n",
      "Epoch 178/200, Iteration 18/25, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 19/25, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 20/25, Loss: 0.0074\n",
      "Epoch 178/200, Iteration 21/25, Loss: 0.0303\n",
      "Epoch 178/200, Iteration 22/25, Loss: 0.0228\n",
      "Epoch 178/200, Iteration 23/25, Loss: 0.0185\n",
      "Epoch 178/200, Iteration 24/25, Loss: 0.0121\n",
      "Epoch 178/200, Iteration 25/25, Loss: 0.0369\n",
      "Train Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.005967, MRE: 0.374414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.007794, MRE: 0.472110 \n",
      "\n",
      "Epoch 179/200, Iteration 1/25, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 2/25, Loss: 0.0092\n",
      "Epoch 179/200, Iteration 3/25, Loss: 0.0103\n",
      "Epoch 179/200, Iteration 4/25, Loss: 0.0142\n",
      "Epoch 179/200, Iteration 5/25, Loss: 0.0077\n",
      "Epoch 179/200, Iteration 6/25, Loss: 0.0252\n",
      "Epoch 179/200, Iteration 7/25, Loss: 0.0148\n",
      "Epoch 179/200, Iteration 8/25, Loss: 0.0079\n",
      "Epoch 179/200, Iteration 9/25, Loss: 0.0094\n",
      "Epoch 179/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 179/200, Iteration 11/25, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 12/25, Loss: 0.0064\n",
      "Epoch 179/200, Iteration 13/25, Loss: 0.0095\n",
      "Epoch 179/200, Iteration 14/25, Loss: 0.0221\n",
      "Epoch 179/200, Iteration 15/25, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 16/25, Loss: 0.0098\n",
      "Epoch 179/200, Iteration 17/25, Loss: 0.0117\n",
      "Epoch 179/200, Iteration 18/25, Loss: 0.0195\n",
      "Epoch 179/200, Iteration 19/25, Loss: 0.0186\n",
      "Epoch 179/200, Iteration 20/25, Loss: 0.0225\n",
      "Epoch 179/200, Iteration 21/25, Loss: 0.0132\n",
      "Epoch 179/200, Iteration 22/25, Loss: 0.0190\n",
      "Epoch 179/200, Iteration 23/25, Loss: 0.0100\n",
      "Epoch 179/200, Iteration 24/25, Loss: 0.0268\n",
      "Epoch 179/200, Iteration 25/25, Loss: 0.0174\n",
      "Train Error: \n",
      " Accuracy: 91.25%, Avg loss: 0.005812, MRE: 0.345637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.007659, MRE: 0.529210 \n",
      "\n",
      "Epoch 180/200, Iteration 1/25, Loss: 0.0173\n",
      "Epoch 180/200, Iteration 2/25, Loss: 0.0160\n",
      "Epoch 180/200, Iteration 3/25, Loss: 0.0187\n",
      "Epoch 180/200, Iteration 4/25, Loss: 0.0212\n",
      "Epoch 180/200, Iteration 5/25, Loss: 0.0084\n",
      "Epoch 180/200, Iteration 6/25, Loss: 0.0101\n",
      "Epoch 180/200, Iteration 7/25, Loss: 0.0232\n",
      "Epoch 180/200, Iteration 8/25, Loss: 0.0185\n",
      "Epoch 180/200, Iteration 9/25, Loss: 0.0176\n",
      "Epoch 180/200, Iteration 10/25, Loss: 0.0189\n",
      "Epoch 180/200, Iteration 11/25, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 12/25, Loss: 0.0097\n",
      "Epoch 180/200, Iteration 13/25, Loss: 0.0147\n",
      "Epoch 180/200, Iteration 14/25, Loss: 0.0144\n",
      "Epoch 180/200, Iteration 15/25, Loss: 0.0199\n",
      "Epoch 180/200, Iteration 16/25, Loss: 0.0063\n",
      "Epoch 180/200, Iteration 17/25, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 18/25, Loss: 0.0088\n",
      "Epoch 180/200, Iteration 19/25, Loss: 0.0372\n",
      "Epoch 180/200, Iteration 20/25, Loss: 0.0073\n",
      "Epoch 180/200, Iteration 21/25, Loss: 0.0085\n",
      "Epoch 180/200, Iteration 22/25, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 23/25, Loss: 0.0117\n",
      "Epoch 180/200, Iteration 24/25, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 25/25, Loss: 0.0104\n",
      "Train Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.006579, MRE: 0.399194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.007727, MRE: 0.690652 \n",
      "\n",
      "Epoch 181/200, Iteration 1/25, Loss: 0.0233\n",
      "Epoch 181/200, Iteration 2/25, Loss: 0.0133\n",
      "Epoch 181/200, Iteration 3/25, Loss: 0.0170\n",
      "Epoch 181/200, Iteration 4/25, Loss: 0.0081\n",
      "Epoch 181/200, Iteration 5/25, Loss: 0.0104\n",
      "Epoch 181/200, Iteration 6/25, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 7/25, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 9/25, Loss: 0.0125\n",
      "Epoch 181/200, Iteration 10/25, Loss: 0.0269\n",
      "Epoch 181/200, Iteration 11/25, Loss: 0.0096\n",
      "Epoch 181/200, Iteration 12/25, Loss: 0.0123\n",
      "Epoch 181/200, Iteration 13/25, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 14/25, Loss: 0.0090\n",
      "Epoch 181/200, Iteration 15/25, Loss: 0.0175\n",
      "Epoch 181/200, Iteration 16/25, Loss: 0.0185\n",
      "Epoch 181/200, Iteration 17/25, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 18/25, Loss: 0.0070\n",
      "Epoch 181/200, Iteration 19/25, Loss: 0.0147\n",
      "Epoch 181/200, Iteration 20/25, Loss: 0.0097\n",
      "Epoch 181/200, Iteration 21/25, Loss: 0.0272\n",
      "Epoch 181/200, Iteration 22/25, Loss: 0.0183\n",
      "Epoch 181/200, Iteration 23/25, Loss: 0.0270\n",
      "Epoch 181/200, Iteration 24/25, Loss: 0.0267\n",
      "Epoch 181/200, Iteration 25/25, Loss: 0.0177\n",
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.006328, MRE: 0.396039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.007924, MRE: 1.197609 \n",
      "\n",
      "Epoch 182/200, Iteration 1/25, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 2/25, Loss: 0.0212\n",
      "Epoch 182/200, Iteration 3/25, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 4/25, Loss: 0.0249\n",
      "Epoch 182/200, Iteration 5/25, Loss: 0.0135\n",
      "Epoch 182/200, Iteration 6/25, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 7/25, Loss: 0.0157\n",
      "Epoch 182/200, Iteration 8/25, Loss: 0.0140\n",
      "Epoch 182/200, Iteration 9/25, Loss: 0.0205\n",
      "Epoch 182/200, Iteration 10/25, Loss: 0.0180\n",
      "Epoch 182/200, Iteration 11/25, Loss: 0.0148\n",
      "Epoch 182/200, Iteration 12/25, Loss: 0.0340\n",
      "Epoch 182/200, Iteration 13/25, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 14/25, Loss: 0.0125\n",
      "Epoch 182/200, Iteration 15/25, Loss: 0.0340\n",
      "Epoch 182/200, Iteration 16/25, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 17/25, Loss: 0.0188\n",
      "Epoch 182/200, Iteration 18/25, Loss: 0.0094\n",
      "Epoch 182/200, Iteration 19/25, Loss: 0.0249\n",
      "Epoch 182/200, Iteration 20/25, Loss: 0.0117\n",
      "Epoch 182/200, Iteration 21/25, Loss: 0.0277\n",
      "Epoch 182/200, Iteration 22/25, Loss: 0.0147\n",
      "Epoch 182/200, Iteration 23/25, Loss: 0.0290\n",
      "Epoch 182/200, Iteration 24/25, Loss: 0.0165\n",
      "Epoch 182/200, Iteration 25/25, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.005514, MRE: 0.325574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007223, MRE: 0.682269 \n",
      "\n",
      "Epoch 183/200, Iteration 1/25, Loss: 0.0120\n",
      "Epoch 183/200, Iteration 2/25, Loss: 0.0104\n",
      "Epoch 183/200, Iteration 3/25, Loss: 0.0144\n",
      "Epoch 183/200, Iteration 4/25, Loss: 0.0085\n",
      "Epoch 183/200, Iteration 5/25, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 6/25, Loss: 0.0100\n",
      "Epoch 183/200, Iteration 7/25, Loss: 0.0160\n",
      "Epoch 183/200, Iteration 8/25, Loss: 0.0265\n",
      "Epoch 183/200, Iteration 9/25, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 10/25, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 11/25, Loss: 0.0057\n",
      "Epoch 183/200, Iteration 12/25, Loss: 0.0128\n",
      "Epoch 183/200, Iteration 13/25, Loss: 0.0160\n",
      "Epoch 183/200, Iteration 14/25, Loss: 0.0091\n",
      "Epoch 183/200, Iteration 15/25, Loss: 0.0330\n",
      "Epoch 183/200, Iteration 16/25, Loss: 0.0328\n",
      "Epoch 183/200, Iteration 17/25, Loss: 0.0155\n",
      "Epoch 183/200, Iteration 18/25, Loss: 0.0203\n",
      "Epoch 183/200, Iteration 19/25, Loss: 0.0204\n",
      "Epoch 183/200, Iteration 20/25, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 21/25, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 22/25, Loss: 0.0217\n",
      "Epoch 183/200, Iteration 23/25, Loss: 0.0195\n",
      "Epoch 183/200, Iteration 24/25, Loss: 0.0078\n",
      "Epoch 183/200, Iteration 25/25, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 90.25%, Avg loss: 0.005876, MRE: 0.328350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.007286, MRE: 0.532545 \n",
      "\n",
      "Epoch 184/200, Iteration 1/25, Loss: 0.0161\n",
      "Epoch 184/200, Iteration 2/25, Loss: 0.0090\n",
      "Epoch 184/200, Iteration 3/25, Loss: 0.0232\n",
      "Epoch 184/200, Iteration 4/25, Loss: 0.0338\n",
      "Epoch 184/200, Iteration 5/25, Loss: 0.0121\n",
      "Epoch 184/200, Iteration 6/25, Loss: 0.0180\n",
      "Epoch 184/200, Iteration 7/25, Loss: 0.0078\n",
      "Epoch 184/200, Iteration 8/25, Loss: 0.0112\n",
      "Epoch 184/200, Iteration 9/25, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 184/200, Iteration 11/25, Loss: 0.0185\n",
      "Epoch 184/200, Iteration 12/25, Loss: 0.0100\n",
      "Epoch 184/200, Iteration 13/25, Loss: 0.0239\n",
      "Epoch 184/200, Iteration 14/25, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 15/25, Loss: 0.0224\n",
      "Epoch 184/200, Iteration 16/25, Loss: 0.0202\n",
      "Epoch 184/200, Iteration 17/25, Loss: 0.0356\n",
      "Epoch 184/200, Iteration 18/25, Loss: 0.0117\n",
      "Epoch 184/200, Iteration 19/25, Loss: 0.0063\n",
      "Epoch 184/200, Iteration 20/25, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 21/25, Loss: 0.0197\n",
      "Epoch 184/200, Iteration 22/25, Loss: 0.0068\n",
      "Epoch 184/200, Iteration 23/25, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 24/25, Loss: 0.0152\n",
      "Epoch 184/200, Iteration 25/25, Loss: 0.0089\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.005574, MRE: 0.313268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007231, MRE: 0.669293 \n",
      "\n",
      "Epoch 185/200, Iteration 1/25, Loss: 0.0102\n",
      "Epoch 185/200, Iteration 2/25, Loss: 0.0091\n",
      "Epoch 185/200, Iteration 3/25, Loss: 0.0096\n",
      "Epoch 185/200, Iteration 4/25, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 5/25, Loss: 0.0436\n",
      "Epoch 185/200, Iteration 6/25, Loss: 0.0237\n",
      "Epoch 185/200, Iteration 7/25, Loss: 0.0118\n",
      "Epoch 185/200, Iteration 8/25, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 9/25, Loss: 0.0062\n",
      "Epoch 185/200, Iteration 10/25, Loss: 0.0090\n",
      "Epoch 185/200, Iteration 11/25, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 12/25, Loss: 0.0132\n",
      "Epoch 185/200, Iteration 13/25, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 14/25, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 15/25, Loss: 0.0080\n",
      "Epoch 185/200, Iteration 16/25, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 17/25, Loss: 0.0227\n",
      "Epoch 185/200, Iteration 18/25, Loss: 0.0127\n",
      "Epoch 185/200, Iteration 19/25, Loss: 0.0091\n",
      "Epoch 185/200, Iteration 20/25, Loss: 0.0070\n",
      "Epoch 185/200, Iteration 21/25, Loss: 0.0217\n",
      "Epoch 185/200, Iteration 22/25, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 23/25, Loss: 0.0186\n",
      "Epoch 185/200, Iteration 24/25, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 25/25, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005731, MRE: 0.289942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007935, MRE: 0.797563 \n",
      "\n",
      "Epoch 186/200, Iteration 1/25, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 2/25, Loss: 0.0122\n",
      "Epoch 186/200, Iteration 3/25, Loss: 0.0231\n",
      "Epoch 186/200, Iteration 4/25, Loss: 0.0109\n",
      "Epoch 186/200, Iteration 5/25, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 6/25, Loss: 0.0077\n",
      "Epoch 186/200, Iteration 7/25, Loss: 0.0207\n",
      "Epoch 186/200, Iteration 8/25, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 9/25, Loss: 0.0169\n",
      "Epoch 186/200, Iteration 10/25, Loss: 0.0279\n",
      "Epoch 186/200, Iteration 11/25, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 12/25, Loss: 0.0112\n",
      "Epoch 186/200, Iteration 13/25, Loss: 0.0072\n",
      "Epoch 186/200, Iteration 14/25, Loss: 0.0063\n",
      "Epoch 186/200, Iteration 15/25, Loss: 0.0452\n",
      "Epoch 186/200, Iteration 16/25, Loss: 0.0342\n",
      "Epoch 186/200, Iteration 17/25, Loss: 0.0080\n",
      "Epoch 186/200, Iteration 18/25, Loss: 0.0106\n",
      "Epoch 186/200, Iteration 19/25, Loss: 0.0081\n",
      "Epoch 186/200, Iteration 20/25, Loss: 0.0104\n",
      "Epoch 186/200, Iteration 21/25, Loss: 0.0077\n",
      "Epoch 186/200, Iteration 22/25, Loss: 0.0207\n",
      "Epoch 186/200, Iteration 23/25, Loss: 0.0154\n",
      "Epoch 186/200, Iteration 24/25, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 25/25, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.005682, MRE: 0.318394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007732, MRE: 0.673576 \n",
      "\n",
      "Epoch 187/200, Iteration 1/25, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 2/25, Loss: 0.0369\n",
      "Epoch 187/200, Iteration 3/25, Loss: 0.0201\n",
      "Epoch 187/200, Iteration 4/25, Loss: 0.0162\n",
      "Epoch 187/200, Iteration 5/25, Loss: 0.0072\n",
      "Epoch 187/200, Iteration 6/25, Loss: 0.0158\n",
      "Epoch 187/200, Iteration 7/25, Loss: 0.0179\n",
      "Epoch 187/200, Iteration 8/25, Loss: 0.0098\n",
      "Epoch 187/200, Iteration 9/25, Loss: 0.0148\n",
      "Epoch 187/200, Iteration 10/25, Loss: 0.0130\n",
      "Epoch 187/200, Iteration 11/25, Loss: 0.0232\n",
      "Epoch 187/200, Iteration 12/25, Loss: 0.0141\n",
      "Epoch 187/200, Iteration 13/25, Loss: 0.0122\n",
      "Epoch 187/200, Iteration 14/25, Loss: 0.0074\n",
      "Epoch 187/200, Iteration 15/25, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 16/25, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 17/25, Loss: 0.0151\n",
      "Epoch 187/200, Iteration 18/25, Loss: 0.0084\n",
      "Epoch 187/200, Iteration 19/25, Loss: 0.0178\n",
      "Epoch 187/200, Iteration 20/25, Loss: 0.0220\n",
      "Epoch 187/200, Iteration 21/25, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 22/25, Loss: 0.0122\n",
      "Epoch 187/200, Iteration 23/25, Loss: 0.0525\n",
      "Epoch 187/200, Iteration 24/25, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 25/25, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 77.12%, Avg loss: 0.007330, MRE: 0.454729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.008393, MRE: 0.635830 \n",
      "\n",
      "Epoch 188/200, Iteration 1/25, Loss: 0.0146\n",
      "Epoch 188/200, Iteration 2/25, Loss: 0.0257\n",
      "Epoch 188/200, Iteration 3/25, Loss: 0.0102\n",
      "Epoch 188/200, Iteration 4/25, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 5/25, Loss: 0.0128\n",
      "Epoch 188/200, Iteration 6/25, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 7/25, Loss: 0.0229\n",
      "Epoch 188/200, Iteration 8/25, Loss: 0.0157\n",
      "Epoch 188/200, Iteration 9/25, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 10/25, Loss: 0.0205\n",
      "Epoch 188/200, Iteration 11/25, Loss: 0.0154\n",
      "Epoch 188/200, Iteration 12/25, Loss: 0.0222\n",
      "Epoch 188/200, Iteration 13/25, Loss: 0.0138\n",
      "Epoch 188/200, Iteration 14/25, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 15/25, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 16/25, Loss: 0.0123\n",
      "Epoch 188/200, Iteration 17/25, Loss: 0.0177\n",
      "Epoch 188/200, Iteration 18/25, Loss: 0.0236\n",
      "Epoch 188/200, Iteration 19/25, Loss: 0.0106\n",
      "Epoch 188/200, Iteration 20/25, Loss: 0.0072\n",
      "Epoch 188/200, Iteration 21/25, Loss: 0.0357\n",
      "Epoch 188/200, Iteration 22/25, Loss: 0.0068\n",
      "Epoch 188/200, Iteration 23/25, Loss: 0.0140\n",
      "Epoch 188/200, Iteration 24/25, Loss: 0.0273\n",
      "Epoch 188/200, Iteration 25/25, Loss: 0.0151\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.005682, MRE: 0.294171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.006974, MRE: 0.912422 \n",
      "\n",
      "Epoch 189/200, Iteration 1/25, Loss: 0.0136\n",
      "Epoch 189/200, Iteration 2/25, Loss: 0.0328\n",
      "Epoch 189/200, Iteration 3/25, Loss: 0.0078\n",
      "Epoch 189/200, Iteration 4/25, Loss: 0.0187\n",
      "Epoch 189/200, Iteration 5/25, Loss: 0.0085\n",
      "Epoch 189/200, Iteration 6/25, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 7/25, Loss: 0.0319\n",
      "Epoch 189/200, Iteration 8/25, Loss: 0.0107\n",
      "Epoch 189/200, Iteration 9/25, Loss: 0.0395\n",
      "Epoch 189/200, Iteration 10/25, Loss: 0.0097\n",
      "Epoch 189/200, Iteration 11/25, Loss: 0.0103\n",
      "Epoch 189/200, Iteration 12/25, Loss: 0.0256\n",
      "Epoch 189/200, Iteration 13/25, Loss: 0.0123\n",
      "Epoch 189/200, Iteration 14/25, Loss: 0.0196\n",
      "Epoch 189/200, Iteration 15/25, Loss: 0.0086\n",
      "Epoch 189/200, Iteration 16/25, Loss: 0.0118\n",
      "Epoch 189/200, Iteration 17/25, Loss: 0.0104\n",
      "Epoch 189/200, Iteration 18/25, Loss: 0.0112\n",
      "Epoch 189/200, Iteration 19/25, Loss: 0.0224\n",
      "Epoch 189/200, Iteration 20/25, Loss: 0.0120\n",
      "Epoch 189/200, Iteration 21/25, Loss: 0.0127\n",
      "Epoch 189/200, Iteration 22/25, Loss: 0.0093\n",
      "Epoch 189/200, Iteration 23/25, Loss: 0.0242\n",
      "Epoch 189/200, Iteration 24/25, Loss: 0.0139\n",
      "Epoch 189/200, Iteration 25/25, Loss: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005939, MRE: 0.341978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.007710, MRE: 1.095861 \n",
      "\n",
      "Epoch 190/200, Iteration 1/25, Loss: 0.0083\n",
      "Epoch 190/200, Iteration 2/25, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 3/25, Loss: 0.0164\n",
      "Epoch 190/200, Iteration 4/25, Loss: 0.0129\n",
      "Epoch 190/200, Iteration 5/25, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 6/25, Loss: 0.0127\n",
      "Epoch 190/200, Iteration 7/25, Loss: 0.0219\n",
      "Epoch 190/200, Iteration 8/25, Loss: 0.0232\n",
      "Epoch 190/200, Iteration 9/25, Loss: 0.0216\n",
      "Epoch 190/200, Iteration 10/25, Loss: 0.0181\n",
      "Epoch 190/200, Iteration 11/25, Loss: 0.0152\n",
      "Epoch 190/200, Iteration 12/25, Loss: 0.0078\n",
      "Epoch 190/200, Iteration 13/25, Loss: 0.0101\n",
      "Epoch 190/200, Iteration 14/25, Loss: 0.0085\n",
      "Epoch 190/200, Iteration 15/25, Loss: 0.0154\n",
      "Epoch 190/200, Iteration 16/25, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 17/25, Loss: 0.0081\n",
      "Epoch 190/200, Iteration 18/25, Loss: 0.0090\n",
      "Epoch 190/200, Iteration 19/25, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 20/25, Loss: 0.0101\n",
      "Epoch 190/200, Iteration 21/25, Loss: 0.0207\n",
      "Epoch 190/200, Iteration 22/25, Loss: 0.0073\n",
      "Epoch 190/200, Iteration 23/25, Loss: 0.0157\n",
      "Epoch 190/200, Iteration 24/25, Loss: 0.0103\n",
      "Epoch 190/200, Iteration 25/25, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005599, MRE: 0.342386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007235, MRE: 0.900143 \n",
      "\n",
      "Epoch 191/200, Iteration 1/25, Loss: 0.0242\n",
      "Epoch 191/200, Iteration 2/25, Loss: 0.0166\n",
      "Epoch 191/200, Iteration 3/25, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 4/25, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 5/25, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 6/25, Loss: 0.0096\n",
      "Epoch 191/200, Iteration 7/25, Loss: 0.0109\n",
      "Epoch 191/200, Iteration 8/25, Loss: 0.0116\n",
      "Epoch 191/200, Iteration 9/25, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 10/25, Loss: 0.0066\n",
      "Epoch 191/200, Iteration 11/25, Loss: 0.0071\n",
      "Epoch 191/200, Iteration 12/25, Loss: 0.0085\n",
      "Epoch 191/200, Iteration 13/25, Loss: 0.0199\n",
      "Epoch 191/200, Iteration 14/25, Loss: 0.0059\n",
      "Epoch 191/200, Iteration 15/25, Loss: 0.0106\n",
      "Epoch 191/200, Iteration 16/25, Loss: 0.0208\n",
      "Epoch 191/200, Iteration 17/25, Loss: 0.0195\n",
      "Epoch 191/200, Iteration 18/25, Loss: 0.0085\n",
      "Epoch 191/200, Iteration 19/25, Loss: 0.0204\n",
      "Epoch 191/200, Iteration 20/25, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 21/25, Loss: 0.0183\n",
      "Epoch 191/200, Iteration 22/25, Loss: 0.0143\n",
      "Epoch 191/200, Iteration 23/25, Loss: 0.0188\n",
      "Epoch 191/200, Iteration 24/25, Loss: 0.0385\n",
      "Epoch 191/200, Iteration 25/25, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.006477, MRE: 0.376618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008599, MRE: 1.074239 \n",
      "\n",
      "Epoch 192/200, Iteration 1/25, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 2/25, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 3/25, Loss: 0.0059\n",
      "Epoch 192/200, Iteration 4/25, Loss: 0.0080\n",
      "Epoch 192/200, Iteration 5/25, Loss: 0.0143\n",
      "Epoch 192/200, Iteration 6/25, Loss: 0.0123\n",
      "Epoch 192/200, Iteration 7/25, Loss: 0.0132\n",
      "Epoch 192/200, Iteration 8/25, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 9/25, Loss: 0.0235\n",
      "Epoch 192/200, Iteration 10/25, Loss: 0.0086\n",
      "Epoch 192/200, Iteration 11/25, Loss: 0.0281\n",
      "Epoch 192/200, Iteration 12/25, Loss: 0.0248\n",
      "Epoch 192/200, Iteration 13/25, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 14/25, Loss: 0.0087\n",
      "Epoch 192/200, Iteration 15/25, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 16/25, Loss: 0.0302\n",
      "Epoch 192/200, Iteration 17/25, Loss: 0.0097\n",
      "Epoch 192/200, Iteration 18/25, Loss: 0.0269\n",
      "Epoch 192/200, Iteration 19/25, Loss: 0.0399\n",
      "Epoch 192/200, Iteration 20/25, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 21/25, Loss: 0.0266\n",
      "Epoch 192/200, Iteration 22/25, Loss: 0.0182\n",
      "Epoch 192/200, Iteration 23/25, Loss: 0.0060\n",
      "Epoch 192/200, Iteration 24/25, Loss: 0.0203\n",
      "Epoch 192/200, Iteration 25/25, Loss: 0.0160\n",
      "Train Error: \n",
      " Accuracy: 93.25%, Avg loss: 0.005523, MRE: 0.309716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.007081, MRE: 0.865683 \n",
      "\n",
      "Epoch 193/200, Iteration 1/25, Loss: 0.0157\n",
      "Epoch 193/200, Iteration 2/25, Loss: 0.0237\n",
      "Epoch 193/200, Iteration 3/25, Loss: 0.0400\n",
      "Epoch 193/200, Iteration 4/25, Loss: 0.0086\n",
      "Epoch 193/200, Iteration 5/25, Loss: 0.0127\n",
      "Epoch 193/200, Iteration 6/25, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 7/25, Loss: 0.0158\n",
      "Epoch 193/200, Iteration 8/25, Loss: 0.0219\n",
      "Epoch 193/200, Iteration 9/25, Loss: 0.0119\n",
      "Epoch 193/200, Iteration 10/25, Loss: 0.0138\n",
      "Epoch 193/200, Iteration 11/25, Loss: 0.0275\n",
      "Epoch 193/200, Iteration 12/25, Loss: 0.0175\n",
      "Epoch 193/200, Iteration 13/25, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 14/25, Loss: 0.0090\n",
      "Epoch 193/200, Iteration 15/25, Loss: 0.0078\n",
      "Epoch 193/200, Iteration 16/25, Loss: 0.0182\n",
      "Epoch 193/200, Iteration 17/25, Loss: 0.0109\n",
      "Epoch 193/200, Iteration 18/25, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 19/25, Loss: 0.0079\n",
      "Epoch 193/200, Iteration 20/25, Loss: 0.0075\n",
      "Epoch 193/200, Iteration 21/25, Loss: 0.0112\n",
      "Epoch 193/200, Iteration 22/25, Loss: 0.0186\n",
      "Epoch 193/200, Iteration 23/25, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 24/25, Loss: 0.0070\n",
      "Epoch 193/200, Iteration 25/25, Loss: 0.0112\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.005532, MRE: 0.311142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007234, MRE: 0.932357 \n",
      "\n",
      "Epoch 194/200, Iteration 1/25, Loss: 0.0157\n",
      "Epoch 194/200, Iteration 2/25, Loss: 0.0282\n",
      "Epoch 194/200, Iteration 3/25, Loss: 0.0101\n",
      "Epoch 194/200, Iteration 4/25, Loss: 0.0100\n",
      "Epoch 194/200, Iteration 5/25, Loss: 0.0218\n",
      "Epoch 194/200, Iteration 6/25, Loss: 0.0114\n",
      "Epoch 194/200, Iteration 7/25, Loss: 0.0074\n",
      "Epoch 194/200, Iteration 8/25, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 9/25, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 10/25, Loss: 0.0181\n",
      "Epoch 194/200, Iteration 11/25, Loss: 0.0244\n",
      "Epoch 194/200, Iteration 12/25, Loss: 0.0078\n",
      "Epoch 194/200, Iteration 13/25, Loss: 0.0282\n",
      "Epoch 194/200, Iteration 14/25, Loss: 0.0067\n",
      "Epoch 194/200, Iteration 15/25, Loss: 0.0107\n",
      "Epoch 194/200, Iteration 16/25, Loss: 0.0096\n",
      "Epoch 194/200, Iteration 17/25, Loss: 0.0069\n",
      "Epoch 194/200, Iteration 18/25, Loss: 0.0160\n",
      "Epoch 194/200, Iteration 19/25, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 20/25, Loss: 0.0097\n",
      "Epoch 194/200, Iteration 21/25, Loss: 0.0225\n",
      "Epoch 194/200, Iteration 22/25, Loss: 0.0082\n",
      "Epoch 194/200, Iteration 23/25, Loss: 0.0243\n",
      "Epoch 194/200, Iteration 24/25, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 25/25, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 88.25%, Avg loss: 0.005869, MRE: 0.323500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.007104, MRE: 0.887702 \n",
      "\n",
      "Epoch 195/200, Iteration 1/25, Loss: 0.0069\n",
      "Epoch 195/200, Iteration 2/25, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 3/25, Loss: 0.0117\n",
      "Epoch 195/200, Iteration 4/25, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 5/25, Loss: 0.0240\n",
      "Epoch 195/200, Iteration 6/25, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 7/25, Loss: 0.0089\n",
      "Epoch 195/200, Iteration 8/25, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 9/25, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 10/25, Loss: 0.0099\n",
      "Epoch 195/200, Iteration 11/25, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 12/25, Loss: 0.0138\n",
      "Epoch 195/200, Iteration 13/25, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 14/25, Loss: 0.0073\n",
      "Epoch 195/200, Iteration 15/25, Loss: 0.0187\n",
      "Epoch 195/200, Iteration 16/25, Loss: 0.0112\n",
      "Epoch 195/200, Iteration 17/25, Loss: 0.0136\n",
      "Epoch 195/200, Iteration 18/25, Loss: 0.0132\n",
      "Epoch 195/200, Iteration 19/25, Loss: 0.0112\n",
      "Epoch 195/200, Iteration 20/25, Loss: 0.0128\n",
      "Epoch 195/200, Iteration 21/25, Loss: 0.0119\n",
      "Epoch 195/200, Iteration 22/25, Loss: 0.0153\n",
      "Epoch 195/200, Iteration 23/25, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 24/25, Loss: 0.0104\n",
      "Epoch 195/200, Iteration 25/25, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.005441, MRE: 0.305083 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.007073, MRE: 0.894209 \n",
      "\n",
      "Epoch 196/200, Iteration 1/25, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 2/25, Loss: 0.0115\n",
      "Epoch 196/200, Iteration 3/25, Loss: 0.0068\n",
      "Epoch 196/200, Iteration 4/25, Loss: 0.0077\n",
      "Epoch 196/200, Iteration 5/25, Loss: 0.0071\n",
      "Epoch 196/200, Iteration 6/25, Loss: 0.0161\n",
      "Epoch 196/200, Iteration 7/25, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 8/25, Loss: 0.0215\n",
      "Epoch 196/200, Iteration 9/25, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 10/25, Loss: 0.0069\n",
      "Epoch 196/200, Iteration 11/25, Loss: 0.0276\n",
      "Epoch 196/200, Iteration 12/25, Loss: 0.0269\n",
      "Epoch 196/200, Iteration 13/25, Loss: 0.0360\n",
      "Epoch 196/200, Iteration 14/25, Loss: 0.0299\n",
      "Epoch 196/200, Iteration 15/25, Loss: 0.0152\n",
      "Epoch 196/200, Iteration 16/25, Loss: 0.0094\n",
      "Epoch 196/200, Iteration 17/25, Loss: 0.0113\n",
      "Epoch 196/200, Iteration 18/25, Loss: 0.0297\n",
      "Epoch 196/200, Iteration 19/25, Loss: 0.0258\n",
      "Epoch 196/200, Iteration 20/25, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 21/25, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 22/25, Loss: 0.0128\n",
      "Epoch 196/200, Iteration 23/25, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 24/25, Loss: 0.0081\n",
      "Epoch 196/200, Iteration 25/25, Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.005517, MRE: 0.322954 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.006874, MRE: 0.980945 \n",
      "\n",
      "Epoch 197/200, Iteration 1/25, Loss: 0.0064\n",
      "Epoch 197/200, Iteration 2/25, Loss: 0.0071\n",
      "Epoch 197/200, Iteration 3/25, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 4/25, Loss: 0.0217\n",
      "Epoch 197/200, Iteration 5/25, Loss: 0.0386\n",
      "Epoch 197/200, Iteration 6/25, Loss: 0.0168\n",
      "Epoch 197/200, Iteration 7/25, Loss: 0.0072\n",
      "Epoch 197/200, Iteration 8/25, Loss: 0.0419\n",
      "Epoch 197/200, Iteration 9/25, Loss: 0.0065\n",
      "Epoch 197/200, Iteration 10/25, Loss: 0.0231\n",
      "Epoch 197/200, Iteration 11/25, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 12/25, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 13/25, Loss: 0.0184\n",
      "Epoch 197/200, Iteration 14/25, Loss: 0.0129\n",
      "Epoch 197/200, Iteration 15/25, Loss: 0.0175\n",
      "Epoch 197/200, Iteration 16/25, Loss: 0.0141\n",
      "Epoch 197/200, Iteration 17/25, Loss: 0.0171\n",
      "Epoch 197/200, Iteration 18/25, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 19/25, Loss: 0.0077\n",
      "Epoch 197/200, Iteration 20/25, Loss: 0.0570\n",
      "Epoch 197/200, Iteration 21/25, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 22/25, Loss: 0.0201\n",
      "Epoch 197/200, Iteration 23/25, Loss: 0.0075\n",
      "Epoch 197/200, Iteration 24/25, Loss: 0.0104\n",
      "Epoch 197/200, Iteration 25/25, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.006036, MRE: 0.368520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007869, MRE: 1.111723 \n",
      "\n",
      "Epoch 198/200, Iteration 1/25, Loss: 0.0296\n",
      "Epoch 198/200, Iteration 2/25, Loss: 0.0141\n",
      "Epoch 198/200, Iteration 3/25, Loss: 0.0146\n",
      "Epoch 198/200, Iteration 4/25, Loss: 0.0238\n",
      "Epoch 198/200, Iteration 5/25, Loss: 0.0176\n",
      "Epoch 198/200, Iteration 6/25, Loss: 0.0129\n",
      "Epoch 198/200, Iteration 7/25, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 8/25, Loss: 0.0136\n",
      "Epoch 198/200, Iteration 9/25, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 10/25, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 11/25, Loss: 0.0077\n",
      "Epoch 198/200, Iteration 12/25, Loss: 0.0136\n",
      "Epoch 198/200, Iteration 13/25, Loss: 0.0103\n",
      "Epoch 198/200, Iteration 14/25, Loss: 0.0110\n",
      "Epoch 198/200, Iteration 15/25, Loss: 0.0180\n",
      "Epoch 198/200, Iteration 16/25, Loss: 0.0411\n",
      "Epoch 198/200, Iteration 17/25, Loss: 0.0179\n",
      "Epoch 198/200, Iteration 18/25, Loss: 0.0252\n",
      "Epoch 198/200, Iteration 19/25, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 20/25, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 21/25, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 22/25, Loss: 0.0340\n",
      "Epoch 198/200, Iteration 23/25, Loss: 0.0204\n",
      "Epoch 198/200, Iteration 24/25, Loss: 0.0233\n",
      "Epoch 198/200, Iteration 25/25, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.005583, MRE: 0.326857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.007283, MRE: 0.690551 \n",
      "\n",
      "Epoch 199/200, Iteration 1/25, Loss: 0.0151\n",
      "Epoch 199/200, Iteration 2/25, Loss: 0.0137\n",
      "Epoch 199/200, Iteration 3/25, Loss: 0.0240\n",
      "Epoch 199/200, Iteration 4/25, Loss: 0.0255\n",
      "Epoch 199/200, Iteration 5/25, Loss: 0.0242\n",
      "Epoch 199/200, Iteration 6/25, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 7/25, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 8/25, Loss: 0.0144\n",
      "Epoch 199/200, Iteration 9/25, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 10/25, Loss: 0.0257\n",
      "Epoch 199/200, Iteration 11/25, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 12/25, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 13/25, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 14/25, Loss: 0.0070\n",
      "Epoch 199/200, Iteration 15/25, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 16/25, Loss: 0.0070\n",
      "Epoch 199/200, Iteration 17/25, Loss: 0.0206\n",
      "Epoch 199/200, Iteration 18/25, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 19/25, Loss: 0.0305\n",
      "Epoch 199/200, Iteration 20/25, Loss: 0.0072\n",
      "Epoch 199/200, Iteration 21/25, Loss: 0.0096\n",
      "Epoch 199/200, Iteration 22/25, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 23/25, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 24/25, Loss: 0.0287\n",
      "Epoch 199/200, Iteration 25/25, Loss: 0.0163\n",
      "Train Error: \n",
      " Accuracy: 91.88%, Avg loss: 0.005396, MRE: 0.309445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.006859, MRE: 0.736074 \n",
      "\n",
      "Epoch 200/200, Iteration 1/25, Loss: 0.0245\n",
      "Epoch 200/200, Iteration 2/25, Loss: 0.0115\n",
      "Epoch 200/200, Iteration 3/25, Loss: 0.0108\n",
      "Epoch 200/200, Iteration 4/25, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 5/25, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 6/25, Loss: 0.0169\n",
      "Epoch 200/200, Iteration 7/25, Loss: 0.0078\n",
      "Epoch 200/200, Iteration 8/25, Loss: 0.0166\n",
      "Epoch 200/200, Iteration 9/25, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 10/25, Loss: 0.0082\n",
      "Epoch 200/200, Iteration 11/25, Loss: 0.0072\n",
      "Epoch 200/200, Iteration 12/25, Loss: 0.0078\n",
      "Epoch 200/200, Iteration 13/25, Loss: 0.0216\n",
      "Epoch 200/200, Iteration 14/25, Loss: 0.0127\n",
      "Epoch 200/200, Iteration 15/25, Loss: 0.0072\n",
      "Epoch 200/200, Iteration 16/25, Loss: 0.0126\n",
      "Epoch 200/200, Iteration 17/25, Loss: 0.0074\n",
      "Epoch 200/200, Iteration 18/25, Loss: 0.0151\n",
      "Epoch 200/200, Iteration 19/25, Loss: 0.0068\n",
      "Epoch 200/200, Iteration 20/25, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 21/25, Loss: 0.0194\n",
      "Epoch 200/200, Iteration 22/25, Loss: 0.0192\n",
      "Epoch 200/200, Iteration 23/25, Loss: 0.0087\n",
      "Epoch 200/200, Iteration 24/25, Loss: 0.0122\n",
      "Epoch 200/200, Iteration 25/25, Loss: 0.0087\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005514, MRE: 0.334501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.007361, MRE: 0.932497 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predictions = torch.max(pred.data, 1)\n",
    "#         train_correct += (predictions == y.data).sum()                \n",
    "#         train_total += predictions.size(0)    \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping\n",
    "    #train_loss.append(loss.item())\n",
    "    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "\n",
    "#     loss = criterion(outputs, Variable(test_classes))\n",
    "#     test_loss.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "#plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "428c9744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418caa55",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.6064e+02, 2.0704e+02, 4.0792e-02, 4.7369e-01, 4.8552e-01],\n",
      "        [7.8662e+02, 1.4209e+02, 1.3679e-01, 8.1887e-01, 4.4340e-02],\n",
      "        [8.0918e+02, 1.6963e+02, 7.0844e-01, 5.1524e-02, 2.4004e-01],\n",
      "        [6.8684e+02, 2.3671e+02, 5.1572e-01, 2.7098e-01, 2.1330e-01],\n",
      "        [8.1671e+02, 2.4731e+02, 1.7561e-01, 3.0300e-01, 5.2139e-01],\n",
      "        [7.4844e+02, 2.0990e+02, 2.1584e-01, 7.7154e-01, 1.2628e-02],\n",
      "        [7.0683e+02, 2.1601e+02, 1.7549e-01, 7.7199e-01, 5.2514e-02],\n",
      "        [8.0684e+02, 1.8546e+02, 6.7824e-01, 7.0748e-02, 2.5101e-01],\n",
      "        [7.6657e+02, 1.8731e+02, 3.2162e-01, 1.4388e-01, 5.3449e-01],\n",
      "        [8.1156e+02, 2.0908e+02, 8.2041e-02, 8.2321e-01, 9.4751e-02],\n",
      "        [8.4591e+02, 1.7150e+02, 4.7691e-02, 4.9042e-01, 4.6189e-01],\n",
      "        [7.9338e+02, 2.4362e+02, 1.9469e-01, 7.7407e-02, 7.2790e-01],\n",
      "        [7.8136e+02, 1.2807e+02, 3.2330e-01, 6.2757e-01, 4.9133e-02],\n",
      "        [6.9826e+02, 2.2055e+02, 7.6220e-01, 1.1302e-01, 1.2478e-01],\n",
      "        [7.8222e+02, 1.0961e+02, 1.3416e-02, 2.9572e-01, 6.9086e-01],\n",
      "        [7.6535e+02, 1.0744e+02, 3.2285e-01, 2.9224e-01, 3.8491e-01],\n",
      "        [7.6903e+02, 2.4830e+02, 3.7813e-01, 4.7029e-01, 1.5158e-01],\n",
      "        [6.5761e+02, 2.1144e+02, 4.6053e-02, 4.4350e-01, 5.1045e-01],\n",
      "        [7.2657e+02, 1.8313e+02, 3.7772e-01, 4.9798e-01, 1.2430e-01],\n",
      "        [8.4229e+02, 2.3966e+02, 6.0574e-01, 2.2130e-01, 1.7296e-01],\n",
      "        [8.4625e+02, 1.0797e+02, 6.0035e-01, 1.4486e-01, 2.5479e-01],\n",
      "        [6.9194e+02, 1.6590e+02, 6.2578e-01, 1.6624e-01, 2.0797e-01],\n",
      "        [6.8600e+02, 1.2603e+02, 2.5453e-01, 1.0076e-01, 6.4471e-01],\n",
      "        [7.4369e+02, 1.5252e+02, 5.2191e-01, 1.7475e-01, 3.0334e-01],\n",
      "        [8.4507e+02, 1.9805e+02, 1.8039e-01, 4.6553e-02, 7.7306e-01],\n",
      "        [7.7970e+02, 1.1318e+02, 8.7421e-02, 7.7572e-01, 1.3686e-01],\n",
      "        [7.2611e+02, 1.8617e+02, 5.2054e-01, 3.7025e-01, 1.0922e-01],\n",
      "        [8.3936e+02, 2.2321e+02, 5.7842e-01, 3.3966e-01, 8.1922e-02],\n",
      "        [7.5694e+02, 2.3340e+02, 2.9184e-01, 5.5437e-01, 1.5378e-01],\n",
      "        [7.8080e+02, 2.1490e+02, 7.1687e-03, 4.8634e-01, 5.0649e-01],\n",
      "        [7.9817e+02, 1.7209e+02, 1.7247e-01, 2.1098e-01, 6.1655e-01],\n",
      "        [6.8621e+02, 1.1211e+02, 3.9594e-04, 8.1582e-01, 1.8378e-01]])\n",
      "tensor([[-0.1471],\n",
      "        [-0.0081],\n",
      "        [-0.0615],\n",
      "        [ 0.0484],\n",
      "        [-0.1696],\n",
      "        [ 0.0222],\n",
      "        [ 0.0141],\n",
      "        [-0.0593],\n",
      "        [-0.1529],\n",
      "        [-0.0300],\n",
      "        [-0.1847],\n",
      "        [-0.2365],\n",
      "        [ 0.0065],\n",
      "        [ 0.0601],\n",
      "        [-0.2726],\n",
      "        [-0.1235],\n",
      "        [ 0.0032],\n",
      "        [-0.0819],\n",
      "        [ 0.0186],\n",
      "        [-0.0237],\n",
      "        [-0.0923],\n",
      "        [ 0.0295],\n",
      "        [-0.1551],\n",
      "        [-0.0513],\n",
      "        [-0.3052],\n",
      "        [-0.0489],\n",
      "        [ 0.0424],\n",
      "        [ 0.0124],\n",
      "        [-0.0063],\n",
      "        [-0.1672],\n",
      "        [-0.2183],\n",
      "        [-0.0557]])\n",
      "tensor([[-0.1380],\n",
      "        [-0.0093],\n",
      "        [-0.0619],\n",
      "        [ 0.0533],\n",
      "        [-0.1749],\n",
      "        [ 0.0230],\n",
      "        [ 0.0224],\n",
      "        [-0.0593],\n",
      "        [-0.1504],\n",
      "        [-0.0290],\n",
      "        [-0.1967],\n",
      "        [-0.2345],\n",
      "        [ 0.0055],\n",
      "        [ 0.0438],\n",
      "        [-0.2605],\n",
      "        [-0.1279],\n",
      "        [ 0.0114],\n",
      "        [-0.0742],\n",
      "        [ 0.0235],\n",
      "        [-0.0175],\n",
      "        [-0.0930],\n",
      "        [ 0.0343],\n",
      "        [-0.1579],\n",
      "        [-0.0521],\n",
      "        [-0.3025],\n",
      "        [-0.0474],\n",
      "        [ 0.0603],\n",
      "        [ 0.0191],\n",
      "        [ 0.0008],\n",
      "        [-0.1661],\n",
      "        [-0.2726],\n",
      "        [-0.0508]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241eab8",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.1043, 0.9870, 1.0391, 1.0371, 1.0062], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0535, -0.0087, -0.0583,  0.1264, -0.2733], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.1075e-01,  1.4678e-01, -1.6221e-01, -3.5890e-01,  1.9407e-01],\n",
       "         [-2.3683e-01,  4.5399e-01, -3.5903e-01, -4.2926e-01,  5.3468e-01],\n",
       "         [ 3.7104e-01, -7.5742e-02,  2.3967e-01,  3.7836e-03,  4.1633e-01],\n",
       "         [-7.4484e-02, -1.9336e-01,  3.3664e-01, -1.3770e-02, -3.0381e-01],\n",
       "         [ 4.9701e-01,  4.2192e-01,  3.3892e-01, -2.4827e-01,  3.7383e-01],\n",
       "         [ 1.8401e-01,  2.0049e-01,  4.1676e-02,  5.8047e-02, -4.6527e-01],\n",
       "         [ 1.0521e-01,  4.2141e-01,  3.3485e-02, -1.7852e-01, -4.5616e-04],\n",
       "         [ 4.5306e-01, -2.9761e-02,  6.2915e-02,  3.0283e-01, -2.6821e-01],\n",
       "         [ 8.0099e-02, -3.1124e-01, -2.6838e-01,  4.7901e-01,  1.2388e-01],\n",
       "         [ 1.2127e-01,  3.4419e-01,  1.0725e-01,  1.2400e-01, -5.2750e-01],\n",
       "         [-1.2217e-01,  3.3923e-02,  8.6900e-02,  5.6280e-01, -5.4637e-02],\n",
       "         [-5.4399e-01,  4.3057e-01, -6.5981e-03,  8.2047e-02,  2.6320e-01],\n",
       "         [ 3.5445e-01, -1.9013e-01,  3.0337e-01, -4.6137e-01,  5.2822e-01],\n",
       "         [ 5.6897e-01, -2.2892e-01, -3.4095e-01,  1.8975e-02, -3.3980e-01],\n",
       "         [ 1.1213e-01, -3.9688e-01,  3.8988e-01,  5.9033e-02, -4.1677e-01],\n",
       "         [-3.1504e-01, -2.4410e-02,  4.0702e-01, -1.7951e-01,  4.7635e-02],\n",
       "         [-1.9778e-01,  4.9510e-01, -3.3751e-01,  2.4167e-01,  5.4786e-01],\n",
       "         [ 6.0238e-01,  1.7666e-01,  2.3415e-01, -3.3057e-01,  3.6700e-01],\n",
       "         [-6.5259e-02,  1.3226e-01,  1.8896e-01,  2.5330e-01,  5.4625e-01],\n",
       "         [-5.8743e-01,  4.0295e-02, -4.8241e-01,  1.8989e-01,  1.2204e-01],\n",
       "         [-2.3038e-01,  1.2140e-01,  3.2464e-01, -6.5698e-02, -1.8950e-01],\n",
       "         [ 3.3241e-01,  3.1390e-01, -4.1584e-01,  3.9061e-01, -4.2245e-01],\n",
       "         [-1.2215e-01,  1.8128e-01,  3.3416e-01,  1.8067e-01, -2.3505e-01],\n",
       "         [-4.5644e-02, -8.0211e-02, -7.5510e-02, -2.0678e-01, -4.4502e-01],\n",
       "         [ 5.4407e-01, -1.7979e-02, -3.3790e-01,  1.7729e-01,  3.0338e-01],\n",
       "         [-6.4275e-02,  4.9450e-01, -4.5322e-01,  2.0768e-01,  3.4712e-02],\n",
       "         [-7.6378e-02, -4.5834e-02,  3.4994e-01,  4.0769e-01, -7.0272e-02],\n",
       "         [-4.8543e-01,  4.8343e-01,  6.2164e-02, -3.9912e-01, -4.3926e-02],\n",
       "         [ 3.9554e-01, -1.1586e-01,  4.4565e-01,  6.9497e-02, -3.1716e-01],\n",
       "         [ 2.2528e-01,  2.8287e-01, -1.4128e-01,  2.4807e-01, -7.5852e-02],\n",
       "         [-4.4831e-01,  2.0104e-01, -4.4664e-01,  1.2924e-01, -3.3494e-01],\n",
       "         [-1.4998e-01,  3.2314e-01, -2.2986e-01,  2.7903e-01,  5.2033e-01],\n",
       "         [ 4.8004e-01,  5.2909e-02,  2.8302e-01, -3.8663e-01, -2.5781e-01],\n",
       "         [ 2.7008e-01, -2.6417e-02, -3.4703e-02, -1.5030e-01,  3.1913e-01],\n",
       "         [-3.8567e-01, -2.7298e-01, -3.0676e-01, -1.3781e-01,  4.8980e-01],\n",
       "         [-3.1618e-01,  5.3367e-01, -5.1327e-02,  3.8004e-01,  2.6589e-01],\n",
       "         [-2.6309e-01, -1.8973e-01,  2.6308e-01,  2.4137e-01, -1.9976e-01],\n",
       "         [-3.0529e-01,  3.8609e-01, -1.8187e-01,  1.2951e-01, -1.6889e-01],\n",
       "         [ 4.0818e-01,  1.6516e-02, -9.0622e-02,  3.4326e-01,  3.5238e-01],\n",
       "         [-4.7512e-01,  1.9575e-01, -4.0853e-01,  1.6525e-01,  2.6627e-01],\n",
       "         [ 3.5473e-01, -3.9013e-01, -3.9211e-01, -6.1442e-02,  1.1576e-01],\n",
       "         [ 3.8549e-01,  2.3655e-01, -4.1933e-01, -3.2382e-02, -5.8608e-02],\n",
       "         [ 3.3238e-01, -2.4701e-01, -3.2974e-02,  2.8428e-01, -5.6176e-01],\n",
       "         [ 4.7329e-01,  1.6150e-01, -6.7610e-02,  4.4549e-01, -2.4842e-01],\n",
       "         [-3.8194e-01, -1.7729e-01,  3.4128e-01,  3.2157e-01, -1.5759e-01],\n",
       "         [ 6.3152e-01,  4.7749e-01,  3.4794e-01, -4.5737e-01, -1.7964e-01],\n",
       "         [ 2.2335e-01, -1.4102e-01,  5.4560e-01, -2.1430e-01, -3.3579e-02],\n",
       "         [-1.8623e-01, -3.0421e-01, -1.5506e-01,  2.7293e-01,  3.5247e-01],\n",
       "         [ 2.3354e-01, -4.6037e-01, -3.8493e-01,  4.0272e-01,  9.9065e-02],\n",
       "         [-2.0406e-01,  3.8177e-01,  2.2116e-02, -4.7678e-01,  3.7316e-01],\n",
       "         [ 5.4689e-01, -1.5526e-01, -7.4174e-02, -1.5411e-01, -1.2762e-01],\n",
       "         [-2.5999e-01,  4.2079e-01, -5.8687e-02, -3.0297e-01, -4.2665e-01],\n",
       "         [ 2.7686e-01,  1.9515e-01,  2.5892e-01, -3.5356e-01, -2.4013e-01],\n",
       "         [ 1.9412e-01, -2.4850e-01,  3.4185e-01,  5.1062e-01, -3.1845e-01],\n",
       "         [ 1.8655e-03, -3.5881e-01,  3.7485e-01, -1.7667e-01,  4.5508e-01],\n",
       "         [ 1.7809e-01,  2.6791e-01,  4.5732e-01, -2.1576e-02,  3.7045e-01],\n",
       "         [-1.2162e-01,  7.3647e-02, -4.1089e-01,  1.6276e-01,  1.2724e-01],\n",
       "         [-2.2786e-01,  2.9419e-01, -5.1026e-01, -4.6475e-01, -1.9552e-01],\n",
       "         [-3.1863e-01,  2.6450e-01, -2.5155e-01, -2.2285e-01,  2.3418e-01],\n",
       "         [ 1.1658e-01, -3.0941e-01, -4.1310e-01, -5.4620e-03,  1.0241e-01],\n",
       "         [ 6.1155e-01, -3.6640e-01, -4.6915e-01, -7.4699e-03, -4.2462e-01],\n",
       "         [ 1.6296e-01, -1.2709e-01, -1.2893e-01, -3.4602e-01,  3.4869e-01],\n",
       "         [ 4.6799e-01, -2.1701e-01, -5.9577e-01,  1.7886e-01, -3.1692e-01],\n",
       "         [-1.2233e-01,  2.1097e-01,  4.2382e-01, -2.6624e-01, -2.5004e-02],\n",
       "         [-1.8064e-01, -3.5030e-01,  3.9788e-02, -3.3402e-01,  2.2676e-01],\n",
       "         [ 7.0785e-01,  3.3076e-01, -6.1407e-01, -1.7588e-01, -3.7183e-01],\n",
       "         [ 2.7118e-01,  2.7859e-01,  2.1133e-01,  2.8433e-01, -3.4149e-01],\n",
       "         [-4.9084e-02, -6.2606e-02, -2.1693e-02, -3.8803e-01,  4.5341e-02],\n",
       "         [-2.1651e-01, -3.6576e-01,  4.7682e-01, -1.3575e-01,  3.7264e-01],\n",
       "         [ 1.4921e-01,  4.5744e-01,  9.1229e-02,  1.8648e-02, -5.0528e-01],\n",
       "         [-1.3588e-01,  3.1216e-01, -1.7406e-01, -2.9955e-01, -4.7966e-02],\n",
       "         [-3.0371e-01,  5.6401e-02, -1.1602e-01, -3.6633e-01, -4.1123e-01],\n",
       "         [ 5.8595e-01, -3.4633e-01, -5.0994e-01,  2.1447e-01, -3.2861e-01],\n",
       "         [-3.0742e-01,  4.8780e-01,  1.2520e-01, -5.1762e-02,  1.3385e-01],\n",
       "         [-4.1843e-01, -2.8181e-01,  3.1888e-01,  2.3012e-01,  1.6240e-01],\n",
       "         [ 4.8189e-01, -3.5349e-01, -3.6054e-01,  2.2777e-01,  3.0571e-01],\n",
       "         [-8.3239e-02, -9.7397e-02,  8.5543e-02, -2.6632e-02, -3.2353e-01],\n",
       "         [ 4.6164e-01, -1.6555e-01,  4.5086e-01,  2.3414e-01, -4.1060e-01],\n",
       "         [ 4.4172e-01, -5.4940e-01,  2.0261e-01,  5.7416e-02, -8.2279e-02],\n",
       "         [-2.4919e-01, -2.0845e-01, -3.1036e-02,  1.1600e-01,  2.4725e-02],\n",
       "         [-1.2308e-01, -7.0237e-02,  2.3926e-01,  2.7539e-01, -6.2690e-02],\n",
       "         [-4.8064e-01,  3.0910e-01,  1.5117e-01,  6.1229e-04,  2.7393e-01],\n",
       "         [-9.2720e-02, -4.9934e-01,  9.3548e-02, -3.0395e-01, -2.3226e-01],\n",
       "         [-3.3068e-01,  3.6534e-01, -4.4239e-01,  9.8395e-02,  4.8753e-01],\n",
       "         [-6.4959e-01, -3.3547e-01,  1.1508e-02,  3.0415e-01, -6.6944e-02],\n",
       "         [-1.1944e-01, -1.4104e-01, -5.7596e-02,  3.0829e-01, -4.8931e-01],\n",
       "         [ 7.4412e-02, -2.3454e-01, -2.7959e-01, -4.0913e-01, -1.2551e-01],\n",
       "         [-2.1147e-01,  7.5422e-02, -4.3313e-01,  4.4033e-01,  3.6913e-01],\n",
       "         [ 3.5380e-01,  1.2482e-02,  5.3169e-01, -1.5983e-01, -4.6519e-01],\n",
       "         [ 3.3030e-01,  5.0233e-03, -1.0498e-01, -2.4026e-01, -1.2952e-02],\n",
       "         [-1.3140e-01, -9.7415e-02, -9.1938e-02,  1.8307e-01,  5.2921e-01],\n",
       "         [-1.6935e-02, -4.8607e-02, -1.8432e-01, -1.6737e-01,  3.0569e-01],\n",
       "         [ 1.2768e-01, -4.9919e-01,  4.3286e-01, -2.1581e-01, -4.9262e-01],\n",
       "         [ 3.2557e-01,  2.1740e-01, -4.2795e-01, -3.1998e-01,  1.7309e-01],\n",
       "         [-2.8834e-01,  2.9699e-01, -8.5357e-03, -3.5327e-01,  2.0225e-01],\n",
       "         [-4.5697e-03, -2.8315e-01, -2.2508e-01, -3.3388e-01,  3.1285e-01],\n",
       "         [ 3.7315e-01,  2.1654e-01, -8.7518e-03, -2.3336e-01,  9.3304e-02],\n",
       "         [-3.6002e-01,  2.6026e-01, -4.8935e-01, -8.3567e-02,  2.2197e-01],\n",
       "         [-2.2240e-01, -3.7265e-01, -5.5342e-01, -2.5974e-01, -3.3205e-02],\n",
       "         [-3.6351e-01,  3.1269e-01,  4.4232e-01, -2.9804e-01, -2.4459e-01],\n",
       "         [ 4.6118e-01, -6.1110e-03, -3.0199e-01,  3.3942e-01, -7.3546e-02],\n",
       "         [-1.0540e-01, -2.0930e-02, -4.4826e-01, -2.4654e-01, -2.8805e-02],\n",
       "         [-5.2864e-01,  3.4063e-01,  9.3764e-02,  3.6301e-01,  1.2168e-01],\n",
       "         [ 5.0015e-02,  3.6529e-01,  4.7522e-02,  4.7464e-01, -1.0886e-01],\n",
       "         [-2.0199e-01, -1.0449e-02,  2.0881e-01,  1.1764e-01,  3.0559e-01],\n",
       "         [ 2.1109e-01, -2.2743e-02, -1.0444e-01,  4.5062e-01, -5.7802e-01],\n",
       "         [-5.5994e-02,  4.7798e-01,  2.8887e-01,  4.3367e-01, -1.9563e-01],\n",
       "         [ 9.9786e-02,  7.2902e-02,  3.5326e-01,  2.1481e-01, -2.5204e-01],\n",
       "         [-1.5758e-01, -1.4015e-01, -1.1944e-01, -1.8534e-01,  1.0730e-01],\n",
       "         [-9.1944e-02, -1.8240e-02,  1.9059e-01,  2.0052e-01, -2.3217e-01],\n",
       "         [-1.6421e-01, -1.8522e-01,  2.6808e-01,  5.3458e-01, -2.3092e-01],\n",
       "         [ 3.4958e-01, -3.0478e-01, -8.7848e-02,  5.6650e-02,  3.7283e-01],\n",
       "         [ 2.4824e-01, -3.2950e-01, -5.2828e-01,  1.9843e-01,  1.7154e-01],\n",
       "         [ 1.8587e-01,  2.4122e-01, -1.4392e-01,  5.1874e-01,  6.1373e-02],\n",
       "         [-4.4835e-01,  4.7065e-01, -8.1303e-03,  4.3483e-01, -3.2689e-01],\n",
       "         [ 1.4935e-01,  4.3192e-01,  5.0577e-01, -1.1557e-01, -1.4389e-01],\n",
       "         [-3.3843e-01,  4.1662e-02,  3.7381e-01,  3.1937e-01,  1.2800e-01],\n",
       "         [-3.0489e-01,  9.7651e-02, -4.6348e-01,  4.4534e-01, -6.2952e-02],\n",
       "         [ 3.3500e-01, -3.3322e-01,  3.5446e-01, -2.0725e-02,  4.3009e-01],\n",
       "         [ 5.5128e-01, -2.5298e-01, -6.2806e-01,  1.1061e-01, -4.0000e-01],\n",
       "         [-1.5494e-01,  8.6354e-02, -2.3502e-01,  4.1857e-01, -6.6340e-01],\n",
       "         [ 7.6806e-02, -3.2343e-02, -3.3383e-01,  3.6445e-01, -4.3380e-01],\n",
       "         [-1.8849e-01, -2.3165e-01, -1.5665e-01, -5.0991e-01, -3.3843e-03],\n",
       "         [-2.1716e-01, -2.1819e-01,  6.0675e-02,  1.8424e-01,  5.3862e-01],\n",
       "         [-5.4292e-01,  1.0085e-01,  4.3808e-01, -5.9422e-01, -1.8460e-01],\n",
       "         [ 4.1750e-01,  3.6418e-01,  3.2922e-01, -2.7415e-01, -1.6393e-01],\n",
       "         [-5.6936e-01, -3.6855e-01,  4.6254e-01, -1.1310e-01, -9.3208e-02],\n",
       "         [ 3.7135e-01,  7.3540e-02, -1.8040e-01, -1.0819e-01,  4.3175e-01],\n",
       "         [-2.8222e-01, -1.5952e-01, -3.9672e-01, -2.6599e-01,  1.5897e-01],\n",
       "         [ 3.9247e-02,  2.9360e-01, -6.7965e-02, -2.8585e-01,  5.6577e-01],\n",
       "         [ 2.7620e-01, -9.6629e-02,  7.6135e-02, -7.5355e-03,  7.0709e-02],\n",
       "         [-2.8911e-02,  1.8032e-01,  1.7927e-01,  3.8121e-01, -4.8309e-02],\n",
       "         [-2.8058e-01,  1.1942e-02,  2.2743e-01,  2.9500e-01, -2.5731e-01],\n",
       "         [-4.2599e-01, -2.3127e-01,  2.3652e-02, -3.7383e-01, -1.1643e-02],\n",
       "         [ 3.5446e-01,  3.3548e-01,  5.3215e-01, -1.0993e-01, -3.9221e-01],\n",
       "         [-2.7058e-01, -3.9382e-01,  2.0035e-02,  3.7401e-01, -1.7471e-01],\n",
       "         [ 3.6408e-01,  2.6908e-01,  2.9006e-01,  1.2964e-01,  4.5993e-01],\n",
       "         [-6.4845e-02, -2.3968e-01,  1.6434e-01, -5.2209e-01,  3.3839e-01],\n",
       "         [ 4.3559e-02, -3.0482e-01, -1.7070e-01, -3.4148e-01,  3.0673e-01],\n",
       "         [-1.8603e-01,  6.1729e-02, -2.3449e-01, -2.5779e-01,  2.1327e-01],\n",
       "         [-3.9738e-01,  2.5731e-01,  5.1435e-01, -2.9969e-01, -1.3813e-01],\n",
       "         [-2.5959e-01,  8.8049e-02,  1.7436e-01,  6.1937e-02, -2.5196e-01],\n",
       "         [ 8.6465e-02,  7.5004e-02, -1.3768e-01,  1.9622e-01, -3.1349e-01],\n",
       "         [ 5.5750e-01, -4.2530e-01,  3.6029e-01,  2.1068e-01,  1.4420e-01],\n",
       "         [ 2.4810e-01, -3.5026e-01, -3.9203e-02, -1.0429e-01, -1.8568e-01],\n",
       "         [ 5.1303e-02, -1.8046e-01,  3.5789e-01,  2.8109e-01, -1.1404e-02],\n",
       "         [-3.5269e-01,  1.1563e-01,  4.2934e-01,  2.7114e-02, -1.6966e-01],\n",
       "         [ 1.4348e-01,  5.6825e-02, -8.4801e-02, -3.8395e-01,  1.0996e-01],\n",
       "         [ 3.9821e-01, -3.2623e-01,  4.6173e-01,  4.9882e-01,  3.4879e-02],\n",
       "         [-2.0675e-01,  3.2287e-01, -4.1186e-01,  3.7063e-01, -2.7010e-01],\n",
       "         [-4.4235e-01, -1.5587e-01,  2.8361e-01,  7.9710e-03, -3.0717e-01],\n",
       "         [ 3.8958e-01,  3.3117e-01,  3.9268e-01,  3.6432e-01, -4.2184e-01],\n",
       "         [ 4.1808e-01,  1.6290e-01,  3.6562e-01, -5.3154e-02, -1.3538e-01],\n",
       "         [ 1.9933e-01, -3.1220e-01, -3.1529e-01, -1.1521e-01,  2.9846e-01],\n",
       "         [ 5.7319e-01, -2.1163e-01, -1.8346e-02,  3.5228e-02,  3.7498e-01],\n",
       "         [-2.3897e-02, -6.6133e-02,  2.7209e-01,  2.4991e-01,  5.0995e-01],\n",
       "         [ 4.0413e-01, -4.7339e-01, -2.9635e-01, -1.1897e-01, -1.2894e-01],\n",
       "         [-5.7731e-01,  1.3584e-01, -3.4619e-01,  2.5524e-01, -5.2781e-01],\n",
       "         [ 2.8686e-01, -4.9083e-01, -2.2736e-01, -5.6663e-01, -2.2028e-02],\n",
       "         [-1.8528e-01,  1.7458e-01, -1.5796e-01,  3.2709e-01,  5.9761e-01],\n",
       "         [ 3.2556e-01,  3.5721e-01,  2.6311e-01,  5.0209e-01, -3.1693e-01],\n",
       "         [ 4.5857e-01,  4.4834e-01, -3.1608e-01,  1.5137e-01, -4.2941e-01],\n",
       "         [-4.8977e-02,  4.3690e-02, -1.7666e-01,  1.2560e-01,  4.2697e-01],\n",
       "         [ 7.1175e-02,  1.7627e-01,  4.3712e-02, -2.1826e-01,  1.9021e-02],\n",
       "         [-5.6736e-01, -2.0922e-01,  2.1907e-01,  2.0458e-02,  1.3803e-01],\n",
       "         [ 1.5146e-01, -2.8339e-01,  4.8262e-01, -3.4306e-01, -1.6614e-01],\n",
       "         [-3.5577e-02,  2.1160e-01, -4.9621e-01,  2.0822e-01,  2.5379e-01],\n",
       "         [ 2.4370e-02,  1.7433e-03, -4.8423e-01,  3.7310e-01, -5.0758e-01],\n",
       "         [ 5.3051e-01,  5.5031e-01, -2.1931e-01,  4.6826e-01, -5.4864e-01],\n",
       "         [-5.1403e-01,  5.4311e-02,  6.2722e-02,  4.1877e-01,  4.4320e-01],\n",
       "         [-1.6313e-01, -5.1112e-01, -3.8448e-01,  5.4661e-01, -1.5719e-01],\n",
       "         [ 6.2480e-01,  2.2646e-01, -4.0655e-01,  4.7204e-01,  2.5992e-01],\n",
       "         [ 2.1368e-01,  2.3360e-01,  1.2273e-01, -5.7750e-01,  4.8834e-01],\n",
       "         [-4.0907e-01,  3.6784e-01,  6.0407e-01, -8.1438e-02,  3.8956e-01],\n",
       "         [ 4.4395e-01,  3.1881e-01, -2.6215e-01, -3.2942e-01,  3.1431e-01],\n",
       "         [ 7.4016e-02, -3.5199e-01, -2.3112e-01, -2.4371e-02, -4.6316e-01],\n",
       "         [-3.6544e-01, -3.9902e-01, -1.1656e-01, -3.8189e-01,  1.3753e-01],\n",
       "         [ 4.0099e-01,  3.9195e-01,  5.7603e-01, -1.5288e-01, -8.6893e-02],\n",
       "         [ 5.0561e-01, -1.2165e-01, -2.2885e-01, -2.5442e-01, -2.7927e-01],\n",
       "         [ 4.6975e-01, -4.0406e-02, -2.6655e-01, -3.8429e-01,  2.1525e-01],\n",
       "         [ 4.9437e-01,  9.8192e-02, -1.9854e-01, -2.3994e-01,  2.3185e-01],\n",
       "         [-3.2701e-01,  1.0021e-01, -1.1946e-01,  4.3191e-01, -8.6163e-02],\n",
       "         [-7.4494e-02, -2.8663e-01,  3.1128e-01,  5.4119e-01, -2.9488e-01],\n",
       "         [ 3.4685e-02, -1.4912e-01,  3.2839e-01,  4.0630e-01, -3.8068e-01],\n",
       "         [ 2.2006e-01,  7.8989e-02, -1.7215e-01,  2.1416e-01,  6.3737e-02],\n",
       "         [-3.4077e-01, -3.5874e-01, -5.3836e-01,  3.1549e-01,  6.4927e-01],\n",
       "         [-3.6581e-01, -1.1253e-01, -1.2252e-01,  2.5791e-01,  6.2140e-01],\n",
       "         [ 3.1706e-01, -2.0397e-01, -1.5674e-02, -1.9581e-01,  2.4333e-01],\n",
       "         [-2.2258e-01,  2.0668e-01,  5.1170e-01, -3.2994e-01, -9.8523e-02],\n",
       "         [-2.3936e-01, -6.7533e-02,  9.9190e-02,  1.6472e-01, -3.4208e-02],\n",
       "         [ 3.8131e-02, -1.3985e-01,  8.7136e-02,  6.1447e-03,  4.5880e-01],\n",
       "         [-2.0097e-01, -4.0603e-01,  1.6500e-01, -4.5138e-01, -7.7243e-02],\n",
       "         [ 5.3461e-01, -1.3594e-01,  9.3488e-02, -3.7663e-01,  1.3816e-01],\n",
       "         [ 3.7509e-01, -3.3118e-01,  6.7768e-02,  4.1751e-01, -3.5616e-01],\n",
       "         [ 3.9647e-01,  3.3511e-01,  4.1049e-01,  5.6564e-02, -1.7330e-01],\n",
       "         [-4.1534e-02, -2.1137e-01, -4.9141e-01, -1.6500e-01,  3.4890e-02],\n",
       "         [-3.9720e-01, -2.5407e-01, -4.4631e-02,  2.3645e-01,  1.5678e-01],\n",
       "         [-3.2000e-01,  3.3998e-01,  1.9978e-01, -1.6496e-02, -2.5785e-01],\n",
       "         [ 1.7016e-01,  2.2063e-01, -3.7485e-02, -1.2806e-01, -6.0548e-01],\n",
       "         [-5.7855e-01,  3.6362e-01,  3.4215e-01, -2.6309e-01, -2.0130e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.1986e-02, -1.9224e-01, -1.0887e-01,  1.7672e-01, -3.5145e-01,\n",
       "         -5.4129e-02, -1.5578e-01, -2.0186e-01, -1.7137e-01, -1.2084e-01,\n",
       "          5.3659e-02, -8.6790e-02, -3.2415e-01, -6.9568e-02,  1.1991e-01,\n",
       "         -1.4477e-01,  3.2305e-01, -3.6583e-04,  2.3650e-01, -2.5059e-01,\n",
       "          1.0402e-01,  2.1577e-01,  1.8929e-02, -1.2903e-01, -2.8307e-01,\n",
       "          3.4080e-01,  1.2345e-02, -5.4963e-03,  3.3702e-01,  1.1668e-01,\n",
       "         -2.9730e-01, -8.1715e-02,  3.4224e-01, -1.6034e-01, -3.4921e-01,\n",
       "         -2.2176e-01,  6.9998e-02,  6.3528e-02, -8.7845e-02, -1.6763e-01,\n",
       "         -1.3558e-01, -3.4157e-02, -1.1395e-01, -1.4856e-01,  1.0579e-01,\n",
       "          2.2996e-01,  1.3682e-01, -3.7023e-01, -2.8833e-01, -2.4479e-02,\n",
       "         -1.3023e-01,  4.3294e-02,  2.2239e-01, -1.5515e-01, -1.6251e-01,\n",
       "          3.2286e-01, -1.8342e-01, -3.4344e-01,  9.8909e-02, -5.9825e-02,\n",
       "          5.0525e-02, -9.1284e-04, -1.9272e-01, -1.9795e-01, -3.2950e-01,\n",
       "         -1.1660e-01, -2.9486e-01, -3.8471e-02, -1.8226e-01,  2.1998e-01,\n",
       "          1.6005e-01, -2.2652e-02,  1.1137e-01,  1.3891e-01, -3.3685e-01,\n",
       "         -2.0847e-01,  2.1570e-01, -3.5986e-01,  9.0785e-02,  1.0909e-02,\n",
       "          3.5146e-01, -3.1814e-01,  2.3651e-01,  2.0413e-01, -2.2958e-02,\n",
       "         -4.4065e-02, -1.2355e-02, -3.3939e-01,  3.2298e-01,  6.0341e-02,\n",
       "          5.5925e-02,  5.3951e-02,  3.5858e-01, -2.3749e-01,  2.0703e-01,\n",
       "         -2.9034e-02,  2.7292e-01, -1.9900e-02, -1.8796e-01,  1.5710e-01,\n",
       "          2.0132e-01, -2.6934e-02, -1.7561e-01, -2.2056e-01,  9.3906e-02,\n",
       "          3.5303e-02,  1.3719e-01,  1.0540e-01,  1.2950e-01,  4.0452e-03,\n",
       "         -4.8355e-02, -5.8740e-02,  3.0847e-01,  2.4703e-01,  2.4138e-01,\n",
       "          2.6693e-01, -1.3384e-02,  9.3646e-02, -3.1080e-02, -2.7087e-01,\n",
       "          7.2238e-02,  3.2823e-01, -2.5118e-01, -6.0561e-02, -6.5492e-02,\n",
       "          3.4160e-01,  3.0747e-03,  3.4851e-01,  1.9343e-01,  1.3880e-01,\n",
       "          1.4305e-01,  3.5736e-01,  1.3639e-01, -3.6041e-01,  6.5841e-02,\n",
       "         -2.8407e-01, -3.2627e-01, -2.8777e-01, -1.1863e-01,  8.5350e-02,\n",
       "         -3.6269e-02,  1.1174e-01, -2.0259e-01, -3.2286e-02,  6.7449e-03,\n",
       "         -1.4936e-01, -6.3839e-02, -2.6068e-01,  3.3557e-01,  3.1262e-01,\n",
       "          1.5874e-01, -3.4075e-01,  2.6846e-01, -1.1716e-01, -1.2127e-01,\n",
       "         -8.0016e-02, -3.2333e-01,  2.0972e-01, -2.9239e-01, -1.8001e-01,\n",
       "         -9.6438e-02, -2.4944e-01, -5.0698e-03,  3.6624e-01, -8.9413e-02,\n",
       "          2.9190e-01, -1.8910e-01,  1.8895e-01, -1.4097e-01, -2.4487e-01,\n",
       "          2.8068e-01,  7.7448e-03, -2.6850e-01,  3.3840e-02,  5.5079e-02,\n",
       "         -1.5927e-01, -3.2889e-01, -2.8275e-01,  2.3508e-01, -1.5796e-01,\n",
       "         -1.2886e-01,  5.3973e-02,  2.5757e-01,  2.9680e-01, -1.6215e-01,\n",
       "         -2.4374e-01, -1.6271e-01, -1.5078e-01, -2.0623e-01, -4.0047e-02,\n",
       "          9.4778e-03, -5.4178e-02,  1.3336e-02, -1.5901e-01,  3.7389e-01,\n",
       "         -1.5098e-01,  2.6963e-01, -3.7442e-01, -7.1890e-02, -8.1423e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0216, -0.0317,  0.0803,  ...,  0.0327, -0.0290, -0.0082],\n",
       "         [ 0.1217,  0.0939,  0.1618,  ..., -0.0364, -0.0389,  0.0709],\n",
       "         [ 0.1279, -0.0268,  0.1688,  ..., -0.0413, -0.0637,  0.0330],\n",
       "         ...,\n",
       "         [-0.0162, -0.0313,  0.1078,  ..., -0.0557,  0.0434,  0.0039],\n",
       "         [ 0.0799, -0.0096,  0.0500,  ..., -0.0405,  0.0100, -0.0302],\n",
       "         [-0.0737, -0.0454,  0.0395,  ..., -0.0988, -0.1071, -0.0927]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0575, -0.0512,  0.0166,  0.0155, -0.0118, -0.0127,  0.0476,  0.0025,\n",
       "         -0.0129,  0.0657,  0.0059,  0.0828,  0.0599, -0.0240,  0.0410,  0.0429,\n",
       "          0.0326, -0.0569,  0.0121, -0.0356,  0.0325, -0.0091,  0.0401,  0.0458,\n",
       "         -0.0010,  0.0701, -0.0146,  0.0351, -0.0131,  0.0124, -0.0897, -0.0600,\n",
       "          0.0037, -0.0318,  0.0771, -0.0184, -0.0455,  0.0780,  0.0304, -0.0139,\n",
       "          0.0452, -0.0882,  0.0107, -0.0030, -0.0522, -0.0819, -0.0194, -0.0472,\n",
       "         -0.0780,  0.1320,  0.0193,  0.0577, -0.0033, -0.0391, -0.0671, -0.0265,\n",
       "         -0.0161, -0.0430, -0.0299,  0.0214, -0.0495, -0.0511,  0.0755,  0.0258,\n",
       "         -0.0539, -0.0243,  0.0100, -0.0521,  0.0089, -0.0049,  0.0014, -0.0335,\n",
       "         -0.0606, -0.1493, -0.0777,  0.0012,  0.0665,  0.0719,  0.0196, -0.0600,\n",
       "         -0.0328, -0.1043, -0.0103, -0.0211,  0.0488,  0.0200, -0.0111,  0.0342,\n",
       "         -0.0073,  0.0097, -0.0315,  0.0564, -0.0450, -0.0589,  0.1131, -0.0384,\n",
       "         -0.1141,  0.0159,  0.0017,  0.0868, -0.0153, -0.0591,  0.0328, -0.0886,\n",
       "         -0.0739, -0.0845, -0.0755, -0.0326,  0.0285,  0.0085,  0.0282, -0.0273,\n",
       "          0.0576, -0.0251, -0.0602, -0.0022, -0.0766, -0.0882, -0.0052, -0.0134,\n",
       "          0.0490, -0.0074, -0.0030,  0.0987, -0.1219, -0.0365,  0.0372,  0.0885,\n",
       "         -0.0929,  0.0559,  0.0180,  0.0153,  0.0356, -0.0140,  0.0079,  0.0892,\n",
       "          0.0178, -0.0112,  0.0930,  0.0326,  0.0255,  0.0239, -0.0753, -0.1089,\n",
       "         -0.0228,  0.0148,  0.0434,  0.0231,  0.0244,  0.0075, -0.0444, -0.0494,\n",
       "         -0.0372,  0.0122,  0.0624, -0.0291, -0.0522,  0.0099, -0.0203, -0.0003,\n",
       "          0.0211, -0.0408, -0.0069, -0.0802, -0.0207, -0.0066, -0.0233, -0.0347,\n",
       "         -0.0243,  0.0471, -0.0238, -0.0008, -0.0118,  0.0411, -0.0288,  0.0225,\n",
       "         -0.0788, -0.0241, -0.0208,  0.0007, -0.0409,  0.0130,  0.0216,  0.0018,\n",
       "          0.1101,  0.0114,  0.0965, -0.0224, -0.0064,  0.0591, -0.0265,  0.0441,\n",
       "         -0.0203, -0.1026, -0.0217,  0.0039,  0.0009, -0.0017, -0.0347,  0.0075],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0567, -0.0412, -0.0519,  ..., -0.0300, -0.1086,  0.0188],\n",
       "         [-0.1463,  0.2001,  0.1260,  ..., -0.0459, -0.1064, -0.0261],\n",
       "         [ 0.0271,  0.0032,  0.0328,  ...,  0.0707,  0.0777,  0.0590],\n",
       "         ...,\n",
       "         [-0.0590, -0.0348, -0.0472,  ...,  0.0136,  0.0027,  0.0643],\n",
       "         [-0.0969, -0.1345, -0.1788,  ..., -0.0096,  0.1927, -0.0227],\n",
       "         [-0.0403,  0.0148, -0.0229,  ..., -0.0478, -0.0107,  0.0498]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0172, -0.0740,  0.0379,  0.1056,  0.0351,  0.0093,  0.0090, -0.0679,\n",
       "         -0.0023, -0.0223, -0.0024, -0.1084, -0.1009, -0.0003,  0.0664, -0.1046,\n",
       "          0.0374,  0.0318, -0.0157, -0.0197,  0.0263, -0.0632,  0.0499,  0.0752,\n",
       "          0.0087,  0.0855, -0.0262,  0.0940,  0.0446, -0.0741, -0.0342,  0.0153,\n",
       "         -0.0688,  0.0044, -0.1493,  0.0605,  0.0478,  0.1827,  0.0697,  0.0484,\n",
       "         -0.0423,  0.0862,  0.0326,  0.0500, -0.0685, -0.0489, -0.1235, -0.0379,\n",
       "          0.0492, -0.0157, -0.0284,  0.0379, -0.0954,  0.1517, -0.0059, -0.0003,\n",
       "          0.0763,  0.1072, -0.1127, -0.0258,  0.0289,  0.0279, -0.1379, -0.0065,\n",
       "          0.0024,  0.0016,  0.0435, -0.0122,  0.0840, -0.0610, -0.0306, -0.0905,\n",
       "         -0.0078, -0.0095,  0.0341, -0.0323, -0.1015,  0.1526,  0.0031,  0.0985,\n",
       "          0.0517,  0.0470,  0.0911, -0.0863, -0.0242,  0.0168,  0.0222, -0.1266,\n",
       "         -0.0889,  0.0276, -0.0235, -0.0752,  0.0382,  0.0116,  0.0223, -0.0902,\n",
       "          0.0162,  0.0586, -0.1169, -0.0025, -0.2345,  0.0440,  0.0702,  0.1342,\n",
       "          0.0321,  0.1320,  0.0113, -0.0435,  0.0392, -0.0262, -0.0400, -0.0912,\n",
       "          0.0489, -0.0236, -0.0173, -0.0877, -0.0636, -0.0400, -0.0433,  0.0758,\n",
       "          0.1103,  0.0437,  0.0119, -0.0372,  0.0515,  0.0519, -0.0506,  0.0657,\n",
       "         -0.0411,  0.0472,  0.0121, -0.0256, -0.0093,  0.0806, -0.0027,  0.0196,\n",
       "         -0.0101, -0.0053, -0.0248, -0.0123, -0.0462,  0.0402, -0.0335, -0.0647,\n",
       "         -0.0159, -0.0176,  0.0324, -0.0648,  0.0842,  0.0211,  0.0661,  0.0626,\n",
       "         -0.0052,  0.0168,  0.0912,  0.0689,  0.0016, -0.1114,  0.0304,  0.0694,\n",
       "         -0.0772,  0.0937,  0.0499,  0.1747,  0.0710,  0.1377,  0.0359,  0.0497,\n",
       "         -0.0917, -0.1343,  0.0119, -0.0615, -0.0735, -0.0599, -0.0271, -0.0712,\n",
       "          0.0010,  0.0172, -0.0073, -0.0118,  0.0125, -0.0483,  0.0457,  0.0902,\n",
       "          0.0964,  0.0571, -0.0429,  0.0358,  0.0112, -0.0196,  0.0311, -0.0490,\n",
       "         -0.0037, -0.0158, -0.0227, -0.0255, -0.0602,  0.1180,  0.0951,  0.0864],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.7624e-03, -6.8783e-04, -7.1886e-04,  6.9181e-04,  3.3821e-03,\n",
       "           2.3844e-03,  1.7530e-03,  1.6413e-03, -2.1129e-03, -1.5173e-04,\n",
       "           3.2573e-04,  2.8668e-03,  1.2089e-03,  4.2476e-03,  3.7991e-03,\n",
       "           2.1775e-03, -1.5177e-03,  3.1805e-04,  1.8985e-03, -3.6013e-03,\n",
       "          -2.3960e-03, -1.7826e-03, -1.7193e-03, -4.8422e-04,  1.4020e-03,\n",
       "          -1.2210e-03,  3.4300e-04,  1.0956e-03,  6.0862e-04, -9.9733e-04,\n",
       "           8.5628e-04,  1.9857e-03,  4.2974e-05, -1.5171e-03, -1.5637e-03,\n",
       "           3.5785e-04, -1.1670e-03, -4.1428e-04,  1.4171e-03,  1.6296e-03,\n",
       "           2.0969e-03, -6.1225e-04,  1.3116e-03, -3.9983e-03,  1.1404e-03,\n",
       "           1.3051e-03, -1.0695e-03, -6.6520e-04, -1.6106e-03, -1.4107e-04,\n",
       "          -1.4850e-04,  1.2465e-03,  2.5510e-04, -1.0975e-04,  1.3230e-02,\n",
       "          -1.5216e-03,  3.9533e-04, -3.5700e-04, -1.4825e-03,  3.1096e-04,\n",
       "           6.9480e-04, -4.0630e-04,  3.9970e-03, -1.5858e-03, -8.3905e-04,\n",
       "          -1.7410e-03, -2.9910e-04, -3.1044e-04, -1.9252e-04, -9.6289e-03,\n",
       "           1.5814e-03, -4.6378e-03,  5.1599e-04, -1.2865e-03,  3.9905e-04,\n",
       "           4.5243e-04,  5.3876e-03, -1.5805e-03, -3.5370e-03, -4.3780e-04,\n",
       "           8.8022e-04, -8.7065e-04,  1.5540e-04, -2.6297e-04,  1.7890e-03,\n",
       "          -4.8666e-03, -9.0886e-04,  1.6482e-03,  5.1706e-04, -3.2374e-04,\n",
       "           2.9837e-03,  1.6972e-03,  2.4914e-03, -1.0874e-03,  1.8501e-03,\n",
       "           2.8040e-03, -1.1192e-03, -6.5237e-03, -3.4918e-03,  1.7641e-03,\n",
       "          -5.9248e-03, -1.0493e-03, -1.3634e-03,  4.8494e-03, -3.4526e-03,\n",
       "           7.5091e-04, -8.7489e-04, -1.7804e-03, -1.9595e-03,  4.2704e-04,\n",
       "           4.2097e-04, -7.4525e-04, -4.3090e-03,  6.6171e-04, -4.3628e-03,\n",
       "           6.0346e-04, -8.8200e-04, -1.5645e-03, -3.2757e-04, -1.1098e-03,\n",
       "           1.1471e-03, -4.1949e-04, -5.0861e-04,  1.8215e-03, -3.8697e-03,\n",
       "          -3.6862e-04,  1.5861e-03, -1.4332e-03, -3.9890e-03,  2.1357e-03,\n",
       "           1.3001e-04, -7.8296e-04, -2.8477e-03, -3.0600e-03,  2.1198e-03,\n",
       "           3.1051e-03, -9.5536e-04, -1.7113e-04, -1.2278e-02,  1.0612e-03,\n",
       "           1.1308e-02, -1.4645e-03,  1.5620e-03, -1.8809e-04,  2.6548e-03,\n",
       "           1.4127e-03, -2.8681e-04,  1.8404e-03, -1.5347e-03, -1.3168e-03,\n",
       "           3.0245e-03,  1.1023e-03,  1.0311e-02, -7.9995e-05,  2.3814e-03,\n",
       "           1.9347e-03,  1.7538e-03, -2.2241e-05,  8.0232e-04,  1.8443e-04,\n",
       "          -3.5020e-05, -1.1874e-03, -2.0711e-03,  3.8919e-03,  5.7682e-03,\n",
       "           1.4510e-04,  1.5918e-03, -4.8459e-05,  1.1895e-03,  1.4041e-03,\n",
       "          -4.4387e-04,  7.7663e-04, -2.0270e-03, -9.6603e-04, -7.8073e-03,\n",
       "           8.8731e-04,  9.7867e-04, -4.1492e-03,  2.3311e-04,  1.0939e-02,\n",
       "          -3.3813e-03, -2.5497e-03, -2.3070e-03,  1.1906e-03,  3.5406e-03,\n",
       "          -2.4054e-03, -6.4181e-04,  1.2390e-03,  8.9137e-04, -6.4309e-04,\n",
       "          -7.5016e-04, -6.2349e-04, -1.6892e-03,  7.0005e-04,  1.8675e-03,\n",
       "           9.9331e-04, -9.5828e-04, -3.5947e-03,  2.2485e-03,  8.2028e-04]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0947], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3266, 0.6750, 0.1421, 0.7355, 0.0283],\n",
      "        [0.2792, 0.1409, 0.3279, 0.2373, 0.6770]])\n",
      "tensor([[-0.0426],\n",
      "        [-0.0822]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lnorm = nn.LayerNorm(5)\n",
    "Bnorm = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f854e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.2969e+02, 1.6121e+02, 7.0821e-01, 1.4969e-01, 1.4210e-01],\n",
      "        [7.4403e+02, 1.4598e+02, 2.5051e-01, 6.5827e-01, 9.1223e-02],\n",
      "        [7.9695e+02, 1.7629e+02, 3.1200e-01, 5.8035e-02, 6.2996e-01],\n",
      "        [8.1668e+02, 2.3041e+02, 1.9560e-01, 5.0106e-01, 3.0334e-01],\n",
      "        [6.9961e+02, 2.0997e+02, 2.6385e-02, 6.2347e-01, 3.5015e-01],\n",
      "        [6.6285e+02, 2.2195e+02, 3.1569e-01, 2.9775e-01, 3.8656e-01],\n",
      "        [8.2498e+02, 1.2240e+02, 7.1009e-01, 1.7525e-01, 1.1466e-01],\n",
      "        [7.3734e+02, 2.4739e+02, 4.3876e-01, 4.4509e-01, 1.1615e-01],\n",
      "        [8.1358e+02, 1.1043e+02, 3.9437e-01, 1.6179e-01, 4.4385e-01],\n",
      "        [6.6310e+02, 1.7660e+02, 4.5854e-01, 4.0436e-01, 1.3710e-01],\n",
      "        [6.6752e+02, 1.3568e+02, 1.7925e-01, 5.6229e-01, 2.5846e-01],\n",
      "        [6.9686e+02, 2.1160e+02, 8.1950e-01, 4.1973e-02, 1.3852e-01],\n",
      "        [6.9723e+02, 1.5600e+02, 2.8456e-01, 7.5954e-02, 6.3948e-01],\n",
      "        [7.6081e+02, 1.2611e+02, 3.6153e-01, 4.4044e-01, 1.9802e-01],\n",
      "        [7.4514e+02, 2.4420e+02, 3.5671e-01, 6.1264e-01, 3.0655e-02],\n",
      "        [7.8402e+02, 1.7302e+02, 6.3905e-01, 4.3015e-02, 3.1794e-01],\n",
      "        [7.9552e+02, 1.9802e+02, 1.4898e-02, 6.7249e-01, 3.1261e-01],\n",
      "        [7.7435e+02, 1.3430e+02, 3.1828e-01, 4.0196e-01, 2.7976e-01],\n",
      "        [7.1818e+02, 2.2299e+02, 3.9508e-01, 4.0070e-01, 2.0421e-01],\n",
      "        [7.8725e+02, 1.7083e+02, 3.1717e-01, 4.8014e-01, 2.0269e-01],\n",
      "        [6.6682e+02, 2.3497e+02, 4.2973e-01, 2.8795e-01, 2.8232e-01],\n",
      "        [6.8642e+02, 2.2142e+02, 2.4280e-01, 2.6893e-01, 4.8827e-01],\n",
      "        [8.1642e+02, 1.0947e+02, 7.9612e-01, 5.0667e-02, 1.5322e-01],\n",
      "        [7.5892e+02, 1.2882e+02, 4.2741e-01, 1.6498e-01, 4.0761e-01],\n",
      "        [7.6421e+02, 1.0920e+02, 9.3405e-02, 7.0932e-01, 1.9728e-01],\n",
      "        [7.3377e+02, 1.1054e+02, 2.8884e-01, 1.8286e-01, 5.2830e-01],\n",
      "        [6.9014e+02, 1.4565e+02, 5.9374e-01, 1.3129e-01, 2.7497e-01],\n",
      "        [8.2337e+02, 2.1232e+02, 5.6458e-01, 4.2516e-02, 3.9290e-01],\n",
      "        [8.0004e+02, 1.5199e+02, 2.5276e-01, 2.8439e-01, 4.6285e-01],\n",
      "        [6.5761e+02, 2.1144e+02, 4.6053e-02, 4.4350e-01, 5.1045e-01],\n",
      "        [6.9651e+02, 1.7961e+02, 1.1593e-01, 4.1290e-02, 8.4278e-01],\n",
      "        [6.8215e+02, 1.2313e+02, 2.4367e-01, 1.9255e-01, 5.6378e-01]])\n",
      "tensor([ 0.0000e+00, -3.1919e-16, -1.5266e-16, -9.7145e-17,  1.5959e-16],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.1973, -0.2525,  1.6332, -0.7701, -0.9849],\n",
      "        [ 0.0674, -0.5986, -0.5274,  1.6324, -1.2588],\n",
      "        [ 1.0449,  0.0905, -0.2371, -1.2030,  1.6412],\n",
      "        [ 1.4093,  1.3209, -0.7865,  0.8898, -0.1170],\n",
      "        [-0.7529,  0.8563, -1.5853,  1.4680,  0.1350],\n",
      "        [-1.4319,  1.1287, -0.2197, -0.0706,  0.3310],\n",
      "        [ 1.5626, -1.1347,  1.6421, -0.6493, -1.1326],\n",
      "        [-0.0560,  1.7070,  0.3613,  0.6254, -1.1246],\n",
      "        [ 1.3520, -1.4069,  0.1517, -0.7129,  0.6394],\n",
      "        [-1.4272,  0.0974,  0.4546,  0.4330, -1.0118],\n",
      "        [-1.3456, -0.8329, -0.8637,  1.1790, -0.3586],\n",
      "        [-0.8037,  0.8932,  2.1586, -1.2789, -1.0042],\n",
      "        [-0.7969, -0.3709, -0.3666, -1.1184,  1.6925],\n",
      "        [ 0.3774, -1.0505, -0.0033,  0.6034, -0.6839],\n",
      "        [ 0.0880,  1.6346, -0.0261,  1.4169, -1.5848],\n",
      "        [ 0.8060,  0.0162,  1.3067, -1.2740, -0.0384],\n",
      "        [ 1.0185,  0.5845, -1.6396,  1.6996, -0.0670],\n",
      "        [ 0.6274, -0.8642, -0.2074,  0.4216, -0.2439],\n",
      "        [-0.4099,  1.1524,  0.1551,  0.4157, -0.6505],\n",
      "        [ 0.8657, -0.0337, -0.2127,  0.7909, -0.6588],\n",
      "        [-1.3586,  1.4247,  0.3187, -0.1169, -0.2301],\n",
      "        [-0.9965,  1.1167, -0.5638, -0.2068,  0.8785],\n",
      "        [ 1.4044, -1.4289,  2.0482, -1.2379, -0.9251],\n",
      "        [ 0.3424, -0.9887,  0.3077, -0.6979,  0.4443],\n",
      "        [ 0.4401, -1.4348, -1.2690,  1.8736, -0.6879],\n",
      "        [-0.1221, -1.4044, -0.3464, -0.6134,  1.0940],\n",
      "        [-0.9279, -0.6062,  1.0928, -0.8570, -0.2696],\n",
      "        [ 1.5328,  0.9096,  0.9552, -1.2764,  0.3651],\n",
      "        [ 1.1020, -0.4621, -0.5167, -0.1338,  0.7417],\n",
      "        [-1.5286,  0.8897, -1.4925,  0.6179,  0.9979],\n",
      "        [-0.8103,  0.1659, -1.1626, -1.2822,  2.7868],\n",
      "        [-1.0754, -1.1183, -0.5596, -0.5676,  1.2850]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    #print(y.reshape((-1,1)))\n",
    "    print(Bnorm(X).mean(dim=0))\n",
    "    print(Bnorm(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
