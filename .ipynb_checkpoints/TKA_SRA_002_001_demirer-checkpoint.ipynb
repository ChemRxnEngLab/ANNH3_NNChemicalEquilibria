{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz Demirer et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            #nn.LayerNorm(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size, hidden1_size), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.01),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.01, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#Bnorm = nn.BatchNorm1d(5)\n",
    "T = log10(T)\n",
    "p = p / 1000\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "#x_input = Bnorm(x_input)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 0.02\n",
    "#learnin_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 200], gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "            #print(pred.size())\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 1/800, Iteration 2/12, Loss: 0.0076\n",
      "Epoch 1/800, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 1/800, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 1/800, Iteration 5/12, Loss: 0.0055\n",
      "Epoch 1/800, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 1/800, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 1/800, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 1/800, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 1/800, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 1/800, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 1/800, Iteration 12/12, Loss: 0.0065\n",
      "Epoch 1/800, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 66.25%, Avg loss: 0.004436, MRE: 3.010362 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.004541, MRE: 4.029286 \n",
      "\n",
      "Epoch 2/800, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 2/800, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 2/800, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 2/800, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 2/800, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 2/800, Iteration 6/12, Loss: 0.0054\n",
      "Epoch 2/800, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 2/800, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 2/800, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 2/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 2/800, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 2/800, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 2/800, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.003681, MRE: 2.132477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.003912, MRE: 2.008032 \n",
      "\n",
      "Epoch 3/800, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 3/800, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 3/800, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 3/800, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 3/800, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 3/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 3/800, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 3/800, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 3/800, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 3/800, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 3/800, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 3/800, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 3/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 56.62%, Avg loss: 0.003281, MRE: 1.758179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.003582, MRE: 1.956427 \n",
      "\n",
      "Epoch 4/800, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 4/800, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 4/800, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 4/800, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 4/800, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 4/800, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 4/800, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 4/800, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 4/800, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 4/800, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 4/800, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 4/800, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 4/800, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 68.75%, Avg loss: 0.002957, MRE: 2.781160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.002978, MRE: 2.288475 \n",
      "\n",
      "Epoch 5/800, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 5/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 5/800, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 5/800, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 5/800, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 5/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 5/800, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 5/800, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 5/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 5/800, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 5/800, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 5/800, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 5/800, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 63.12%, Avg loss: 0.002540, MRE: 1.942006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.002724, MRE: 2.013451 \n",
      "\n",
      "Epoch 6/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 6/800, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 6/800, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 6/800, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 6/800, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 6/800, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 6/800, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 6/800, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 6/800, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 6/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 6/800, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 6/800, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 6/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 57.12%, Avg loss: 0.002389, MRE: 1.667931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.002648, MRE: 2.382447 \n",
      "\n",
      "Epoch 7/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 7/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 7/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 7/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 7/800, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 7/800, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 7/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 7/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 7/800, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 7/800, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 7/800, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 7/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 7/800, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 69.62%, Avg loss: 0.002369, MRE: 2.231722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.002387, MRE: 1.961405 \n",
      "\n",
      "Epoch 8/800, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 8/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 8/800, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 8/800, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 8/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 8/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 8/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 8/800, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 8/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 8/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 8/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 8/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 8/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.002066, MRE: 1.689148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.002286, MRE: 2.624567 \n",
      "\n",
      "Epoch 9/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 9/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 9/800, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 9/800, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 9/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 9/800, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 9/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 9/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 9/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 9/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 9/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 9/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 9/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.002018, MRE: 1.681710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.002178, MRE: 2.765875 \n",
      "\n",
      "Epoch 10/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 10/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 10/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 10/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 10/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 10/800, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 10/800, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 10/800, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 10/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 10/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 10/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 10/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 10/800, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.001962, MRE: 1.915050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.002022, MRE: 2.548834 \n",
      "\n",
      "Epoch 11/800, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 11/800, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 11/800, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 11/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 11/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 11/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 11/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 11/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 11/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 11/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 11/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 11/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 11/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 56.12%, Avg loss: 0.001881, MRE: 1.980324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.002060, MRE: 3.208399 \n",
      "\n",
      "Epoch 12/800, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 12/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 12/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 12/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 12/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 12/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 12/800, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 12/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 12/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 12/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 12/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 12/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 12/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001798, MRE: 1.647668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001949, MRE: 3.192714 \n",
      "\n",
      "Epoch 13/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 13/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 13/800, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 13/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 13/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 13/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 13/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 13/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 13/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 13/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 13/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 13/800, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 13/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 70.25%, Avg loss: 0.001873, MRE: 1.967692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.001867, MRE: 2.705612 \n",
      "\n",
      "Epoch 14/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 14/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 14/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 14/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 14/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 14/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 14/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 14/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 14/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 14/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 14/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 14/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 14/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001724, MRE: 1.672199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001839, MRE: 3.386073 \n",
      "\n",
      "Epoch 15/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 15/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 15/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 15/800, Iteration 4/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 15/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 15/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 15/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 15/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 15/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 15/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 15/800, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 15/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.001653, MRE: 1.697852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001768, MRE: 3.296027 \n",
      "\n",
      "Epoch 16/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 16/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 16/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 16/800, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 16/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 16/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 16/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 16/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 16/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 16/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 16/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 16/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 16/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001649, MRE: 1.728974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001753, MRE: 3.494136 \n",
      "\n",
      "Epoch 17/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 17/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 17/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 17/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 17/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 17/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 17/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 17/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 17/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 17/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 17/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 17/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 17/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.001654, MRE: 2.042808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.001691, MRE: 3.332663 \n",
      "\n",
      "Epoch 18/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 18/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 18/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 18/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 18/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 18/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 18/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 18/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 18/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 18/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 18/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 18/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 18/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.001674, MRE: 1.783451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.001664, MRE: 3.255488 \n",
      "\n",
      "Epoch 19/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 19/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 19/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 19/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 19/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 19/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 19/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 19/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 19/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 19/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 19/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 19/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 19/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001625, MRE: 1.711726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001687, MRE: 3.856160 \n",
      "\n",
      "Epoch 20/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 20/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 20/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 20/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 20/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 20/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 20/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 20/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 20/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 20/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 20/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 20/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 20/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 62.12%, Avg loss: 0.001568, MRE: 1.741759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001625, MRE: 3.599928 \n",
      "\n",
      "Epoch 21/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 21/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 21/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 21/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 21/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 21/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 21/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 21/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 21/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 21/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 21/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 21/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 21/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 72.38%, Avg loss: 0.001732, MRE: 1.984119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.001703, MRE: 2.984979 \n",
      "\n",
      "Epoch 22/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 22/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 22/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 22/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 22/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 22/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 22/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 22/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 22/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 22/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 22/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 22/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 22/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 53.62%, Avg loss: 0.001591, MRE: 1.740327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.001673, MRE: 4.293846 \n",
      "\n",
      "Epoch 23/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 23/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 23/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 23/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 23/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 23/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 23/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 23/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 23/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 23/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 23/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 23/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 23/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.001547, MRE: 1.717861 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001574, MRE: 3.735375 \n",
      "\n",
      "Epoch 24/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 24/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 24/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 24/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 24/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 24/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 24/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 24/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 24/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 24/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 24/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 24/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 24/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001554, MRE: 1.717459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001574, MRE: 3.938232 \n",
      "\n",
      "Epoch 25/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 25/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 25/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 25/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 25/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 25/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 25/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 25/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 25/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001546, MRE: 1.768123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001567, MRE: 4.018525 \n",
      "\n",
      "Epoch 26/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 26/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 26/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 26/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 26/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 26/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 26/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 26/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 26/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 26/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 26/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 26/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 26/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001551, MRE: 1.747976 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001601, MRE: 4.326041 \n",
      "\n",
      "Epoch 27/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 27/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 27/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 27/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 27/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 27/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 27/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 27/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 27/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 27/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 27/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 27/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 27/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001515, MRE: 1.720578 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001567, MRE: 4.175003 \n",
      "\n",
      "Epoch 28/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 28/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 28/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 28/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 28/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 28/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 28/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 28/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001496, MRE: 1.847720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001537, MRE: 3.991077 \n",
      "\n",
      "Epoch 29/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 29/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 29/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 29/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 29/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 29/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 29/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 29/800, Iteration 12/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 65.12%, Avg loss: 0.001534, MRE: 1.768145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.001518, MRE: 3.525121 \n",
      "\n",
      "Epoch 30/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 30/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 30/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 30/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 30/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 30/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 30/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 30/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 30/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 30/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 30/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 30/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 30/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 56.12%, Avg loss: 0.001492, MRE: 1.771840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001543, MRE: 4.198262 \n",
      "\n",
      "Epoch 31/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 31/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 31/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 31/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 31/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 31/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 31/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 31/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 31/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 31/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 31/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 31/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 31/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001520, MRE: 1.735203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001520, MRE: 4.007806 \n",
      "\n",
      "Epoch 32/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 32/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 32/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 32/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 32/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 32/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 32/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 32/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 32/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 32/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 32/800, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 32/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 32/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001544, MRE: 1.743158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001514, MRE: 3.933271 \n",
      "\n",
      "Epoch 33/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 33/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 33/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 33/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 33/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 33/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 33/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 33/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 33/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 33/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 33/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 33/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 33/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 60.88%, Avg loss: 0.001521, MRE: 1.763228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001510, MRE: 3.890326 \n",
      "\n",
      "Epoch 34/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 34/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 34/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 34/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 34/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 34/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 34/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 34/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 34/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 34/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 34/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 34/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 34/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001493, MRE: 1.710881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001513, MRE: 3.947047 \n",
      "\n",
      "Epoch 35/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 35/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 35/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 35/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 35/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 35/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 35/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 35/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 35/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 35/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 35/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 35/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 35/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001503, MRE: 1.864888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001513, MRE: 3.953826 \n",
      "\n",
      "Epoch 36/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 36/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 36/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 36/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 36/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 36/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 36/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 36/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 36/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 36/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 36/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 36/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 36/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001508, MRE: 2.070144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001514, MRE: 3.979780 \n",
      "\n",
      "Epoch 37/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 37/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 37/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 37/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 37/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 37/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 37/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 37/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 37/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 37/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 37/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 37/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 37/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001520, MRE: 1.744682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001520, MRE: 4.052164 \n",
      "\n",
      "Epoch 38/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 38/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 38/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 38/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 38/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 38/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 38/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 38/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 38/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 38/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 38/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 38/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 38/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001500, MRE: 1.792180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001514, MRE: 3.997463 \n",
      "\n",
      "Epoch 39/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 39/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 39/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 39/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 39/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 39/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 39/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 39/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 39/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 39/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001541, MRE: 2.077359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001509, MRE: 3.940368 \n",
      "\n",
      "Epoch 40/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 40/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 40/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 40/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 40/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 40/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 40/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 40/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 40/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 40/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 40/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 40/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 40/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.001510, MRE: 1.712584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001507, MRE: 3.915617 \n",
      "\n",
      "Epoch 41/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 41/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 41/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 41/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 41/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 41/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 41/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 41/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 41/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 41/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 41/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 41/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 41/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001478, MRE: 1.714677 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001505, MRE: 3.895220 \n",
      "\n",
      "Epoch 42/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 42/800, Iteration 2/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 42/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 42/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 42/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 42/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 42/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 42/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 42/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 42/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 42/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 42/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001483, MRE: 1.724895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001506, MRE: 3.923207 \n",
      "\n",
      "Epoch 43/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 43/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 43/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 43/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 43/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 43/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 43/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 43/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 43/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001499, MRE: 1.710945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001508, MRE: 3.957454 \n",
      "\n",
      "Epoch 44/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 44/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 44/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 44/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 44/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 44/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 44/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 44/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 44/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 44/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 44/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 44/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 44/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001508, MRE: 1.725124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001510, MRE: 3.991518 \n",
      "\n",
      "Epoch 45/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 45/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 45/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 45/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 45/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 45/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 45/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 45/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001516, MRE: 1.710089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001506, MRE: 3.951084 \n",
      "\n",
      "Epoch 46/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 46/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 46/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 46/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 46/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 46/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 46/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 46/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 46/800, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 46/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001491, MRE: 2.091546 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001507, MRE: 3.974134 \n",
      "\n",
      "Epoch 47/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 47/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 47/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 47/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 47/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 47/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 47/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 47/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 47/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 47/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 47/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 47/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 47/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001482, MRE: 1.725317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001505, MRE: 3.957674 \n",
      "\n",
      "Epoch 48/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 48/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 48/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 48/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 48/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 48/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 48/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 48/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 48/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 48/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 48/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 48/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 48/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 61.12%, Avg loss: 0.001492, MRE: 1.720390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001498, MRE: 3.840090 \n",
      "\n",
      "Epoch 49/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 49/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 49/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 49/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 49/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 49/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 49/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 49/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 49/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 49/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 49/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 49/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 49/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001497, MRE: 1.734220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001501, MRE: 3.900911 \n",
      "\n",
      "Epoch 50/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 50/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 50/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 50/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 50/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 50/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 50/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 50/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 50/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 50/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 50/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 50/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 50/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001520, MRE: 1.739300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001502, MRE: 3.929372 \n",
      "\n",
      "Epoch 51/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 51/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 51/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 51/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 51/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 51/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 51/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 51/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 51/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 51/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 51/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 51/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 51/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001482, MRE: 1.711249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001502, MRE: 3.943750 \n",
      "\n",
      "Epoch 52/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 52/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 52/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 52/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 52/800, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 52/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 52/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 52/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 52/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 52/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 52/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 52/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 52/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001484, MRE: 1.882434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001505, MRE: 3.992059 \n",
      "\n",
      "Epoch 53/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 53/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 53/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 53/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 53/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 53/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 53/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 53/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 53/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 53/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 53/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 53/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 53/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001491, MRE: 2.043447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001496, MRE: 3.865442 \n",
      "\n",
      "Epoch 54/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 54/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 54/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 54/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 54/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 54/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 54/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 54/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 54/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 54/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 54/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 54/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 54/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001500, MRE: 1.766466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001499, MRE: 3.933572 \n",
      "\n",
      "Epoch 55/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 55/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 55/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 55/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 55/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 55/800, Iteration 6/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 55/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 55/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 55/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 55/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 55/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 55/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001493, MRE: 1.730148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001503, MRE: 3.985367 \n",
      "\n",
      "Epoch 56/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 56/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 56/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 56/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 56/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 56/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 56/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 56/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 56/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 56/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 56/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 56/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 56/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 60.12%, Avg loss: 0.001507, MRE: 1.748212 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001498, MRE: 3.923364 \n",
      "\n",
      "Epoch 57/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 57/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 57/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 57/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 57/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 57/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 57/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 57/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 57/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 57/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001495, MRE: 1.725746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001500, MRE: 3.973346 \n",
      "\n",
      "Epoch 58/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 58/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 58/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 58/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 58/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 58/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 58/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 58/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 58/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001483, MRE: 1.726860 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001500, MRE: 3.972597 \n",
      "\n",
      "Epoch 59/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 59/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 59/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 59/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 59/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 59/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 59/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 59/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 59/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 59/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 59/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 59/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 59/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001494, MRE: 1.822633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001500, MRE: 3.980665 \n",
      "\n",
      "Epoch 60/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 60/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 60/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 60/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 60/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 60/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 60/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 60/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 60/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 60/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 60/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001502, MRE: 1.740002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001497, MRE: 3.953919 \n",
      "\n",
      "Epoch 61/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 61/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 61/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 61/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 61/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 61/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 61/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 61/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001489, MRE: 1.704844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001493, MRE: 3.905575 \n",
      "\n",
      "Epoch 62/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 62/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 62/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 62/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 62/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 62/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 62/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 62/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001500, MRE: 1.725169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001493, MRE: 3.913390 \n",
      "\n",
      "Epoch 63/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 63/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 63/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 63/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 63/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 63/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 63/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 63/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 63/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 63/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 63/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 63/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 63/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001482, MRE: 1.731653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001490, MRE: 3.865596 \n",
      "\n",
      "Epoch 64/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 64/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 64/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 64/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 64/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 64/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 64/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 64/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 64/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 64/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 64/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 64/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 64/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.001493, MRE: 1.713569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001487, MRE: 3.797163 \n",
      "\n",
      "Epoch 65/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 65/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 65/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 65/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 65/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 65/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 65/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 65/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 65/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 65/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 65/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 65/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 65/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001506, MRE: 1.728051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001488, MRE: 3.841360 \n",
      "\n",
      "Epoch 66/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 66/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 66/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 66/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 66/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 66/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 66/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 66/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 66/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 66/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 66/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 66/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 66/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 61.25%, Avg loss: 0.001504, MRE: 1.710442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001487, MRE: 3.828564 \n",
      "\n",
      "Epoch 67/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 67/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 67/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 67/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 67/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 67/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 67/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 67/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 67/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 67/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 67/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 67/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 67/800, Iteration 13/12, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001498, MRE: 1.713237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001493, MRE: 3.951362 \n",
      "\n",
      "Epoch 68/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 68/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 68/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 68/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 68/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 68/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 68/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 68/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 68/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 68/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 68/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 68/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 68/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 61.12%, Avg loss: 0.001508, MRE: 1.727452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001486, MRE: 3.836266 \n",
      "\n",
      "Epoch 69/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 69/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 69/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 69/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 69/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 69/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 69/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 69/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 69/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 69/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 69/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 69/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 69/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001489, MRE: 1.707625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001490, MRE: 3.917635 \n",
      "\n",
      "Epoch 70/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 70/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 70/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 70/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 70/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 70/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 70/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 70/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 70/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 70/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 70/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 70/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 70/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001477, MRE: 1.704922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001487, MRE: 3.871628 \n",
      "\n",
      "Epoch 71/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 71/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 71/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 71/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 71/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 71/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 71/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001519, MRE: 1.853151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001494, MRE: 3.991827 \n",
      "\n",
      "Epoch 72/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 72/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 72/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 72/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 72/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 72/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 72/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 72/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 72/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 72/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 72/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 72/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 72/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001473, MRE: 1.722968 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001491, MRE: 3.962654 \n",
      "\n",
      "Epoch 73/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 73/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 73/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 73/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 73/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 73/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 73/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 73/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 73/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 73/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 73/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 73/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 73/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001478, MRE: 1.707735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001487, MRE: 3.914839 \n",
      "\n",
      "Epoch 74/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 74/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 74/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 74/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 74/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 74/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 74/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 74/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 74/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 74/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 74/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 74/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 74/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001491, MRE: 1.725763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001484, MRE: 3.860933 \n",
      "\n",
      "Epoch 75/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 75/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 75/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 75/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 75/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 75/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 75/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 75/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 75/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 75/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 75/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 75/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 75/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.001498, MRE: 1.724548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001487, MRE: 3.932037 \n",
      "\n",
      "Epoch 76/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 76/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 76/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 76/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 76/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 76/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 76/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 76/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 76/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 76/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001486, MRE: 1.713080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001485, MRE: 3.899087 \n",
      "\n",
      "Epoch 77/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 77/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 77/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 77/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 77/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 77/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 77/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 77/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 77/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 77/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 77/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 77/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 77/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001482, MRE: 1.850032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001490, MRE: 3.982144 \n",
      "\n",
      "Epoch 78/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 78/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 78/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 78/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 78/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 78/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 78/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 78/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 78/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 78/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 78/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 78/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 78/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001484, MRE: 1.730701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001484, MRE: 3.910377 \n",
      "\n",
      "Epoch 79/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 79/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 79/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 79/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 79/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 79/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 79/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 79/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 79/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 60.38%, Avg loss: 0.001478, MRE: 1.709707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001483, MRE: 3.892727 \n",
      "\n",
      "Epoch 80/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 80/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 80/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 80/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 80/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 80/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 80/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 80/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 80/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 80/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 80/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 80/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 80/800, Iteration 13/12, Loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 61.25%, Avg loss: 0.001491, MRE: 1.747637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001479, MRE: 3.826431 \n",
      "\n",
      "Epoch 81/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 81/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 81/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 81/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 81/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 81/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 81/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 81/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 81/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 81/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 81/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 81/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 81/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.88%, Avg loss: 0.001491, MRE: 1.742579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001481, MRE: 3.868586 \n",
      "\n",
      "Epoch 82/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 82/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 82/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 82/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 82/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 82/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 82/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 82/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 82/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 82/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 82/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 82/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 82/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001492, MRE: 1.711790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001486, MRE: 3.967016 \n",
      "\n",
      "Epoch 83/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 83/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 83/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 83/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 83/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 83/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 83/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 83/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 83/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 83/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 83/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 83/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 83/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001484, MRE: 1.704536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001480, MRE: 3.880207 \n",
      "\n",
      "Epoch 84/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 84/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 84/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 84/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 84/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 84/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 84/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 84/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 84/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 84/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 84/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 84/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 84/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001475, MRE: 1.706652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001480, MRE: 3.881811 \n",
      "\n",
      "Epoch 85/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 85/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 85/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 85/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 85/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 85/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 85/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001475, MRE: 1.700000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001480, MRE: 3.903791 \n",
      "\n",
      "Epoch 86/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 86/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 86/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 86/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 86/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 86/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 86/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 86/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 86/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 86/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001475, MRE: 1.708222 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001484, MRE: 3.969664 \n",
      "\n",
      "Epoch 87/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 87/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 87/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 87/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 87/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 87/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 87/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 87/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 87/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 87/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 87/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 87/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 87/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001473, MRE: 1.712852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001482, MRE: 3.957242 \n",
      "\n",
      "Epoch 88/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 88/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 88/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 88/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 88/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 88/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 88/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 88/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 88/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 88/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 88/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 88/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 88/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.001516, MRE: 1.720044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001480, MRE: 3.933685 \n",
      "\n",
      "Epoch 89/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 89/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 89/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 89/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 89/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 89/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 89/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 89/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 89/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 89/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 89/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001479, MRE: 1.721737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001480, MRE: 3.940120 \n",
      "\n",
      "Epoch 90/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 90/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 90/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 90/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 90/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 90/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 90/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 90/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 90/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 90/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 90/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 90/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 90/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001469, MRE: 1.882486 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001482, MRE: 3.969956 \n",
      "\n",
      "Epoch 91/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 91/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 91/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 91/800, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 91/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 91/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 91/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 91/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 91/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 91/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 91/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 91/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 91/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001487, MRE: 1.708744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001478, MRE: 3.910081 \n",
      "\n",
      "Epoch 92/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 92/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 92/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 92/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 92/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 92/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 92/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 92/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 92/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 92/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 92/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 92/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 92/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001481, MRE: 1.720338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001479, MRE: 3.939392 \n",
      "\n",
      "Epoch 93/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 93/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 93/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 93/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 93/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 93/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 93/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 93/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 93/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 93/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 93/800, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 93/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 93/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001501, MRE: 1.732814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001479, MRE: 3.946447 \n",
      "\n",
      "Epoch 94/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 94/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 94/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 94/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 94/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 94/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 94/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 94/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 94/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 94/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 94/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 94/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 94/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.001484, MRE: 1.716918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001477, MRE: 3.937916 \n",
      "\n",
      "Epoch 95/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 95/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 95/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 95/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 95/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 95/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 95/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 95/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 95/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 95/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 95/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 95/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 95/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001497, MRE: 1.753921 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001477, MRE: 3.940369 \n",
      "\n",
      "Epoch 96/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 96/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 96/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 96/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 96/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 96/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.12%, Avg loss: 0.001465, MRE: 1.750394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001476, MRE: 3.931696 \n",
      "\n",
      "Epoch 97/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 97/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 97/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 97/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 97/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 97/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 97/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001489, MRE: 1.715074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001480, MRE: 3.999099 \n",
      "\n",
      "Epoch 98/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 98/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 98/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 98/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 98/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 98/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 98/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 98/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001478, MRE: 2.030934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001475, MRE: 3.922741 \n",
      "\n",
      "Epoch 99/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 99/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 99/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 99/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 99/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 99/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 99/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 99/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001477, MRE: 1.708055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001477, MRE: 3.969946 \n",
      "\n",
      "Epoch 100/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 100/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 100/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 100/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 100/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 100/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 100/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 100/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 100/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 100/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 100/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 100/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001459, MRE: 1.742949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001474, MRE: 3.925619 \n",
      "\n",
      "Epoch 101/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 101/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 101/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 101/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 101/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 101/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 101/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 101/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 101/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 101/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 101/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 101/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 101/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001493, MRE: 1.747806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001473, MRE: 3.924715 \n",
      "\n",
      "Epoch 102/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 102/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 102/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 102/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 102/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 102/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 102/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 102/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 102/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 102/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 102/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 102/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 102/800, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001486, MRE: 1.703074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001471, MRE: 3.898057 \n",
      "\n",
      "Epoch 103/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 103/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 103/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 103/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 103/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 103/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 103/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 103/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 103/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 103/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001493, MRE: 1.718547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001470, MRE: 3.875141 \n",
      "\n",
      "Epoch 104/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 104/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 104/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 104/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 104/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 104/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 104/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 104/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 104/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 104/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 104/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 104/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 104/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001467, MRE: 1.711745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001473, MRE: 3.936111 \n",
      "\n",
      "Epoch 105/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 105/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 105/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 105/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 105/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 105/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 105/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 105/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 105/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 105/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 105/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 105/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 105/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001475, MRE: 1.764744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001474, MRE: 3.963314 \n",
      "\n",
      "Epoch 106/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 106/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 106/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 106/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 106/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 106/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 106/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 106/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 106/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001482, MRE: 1.771952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001478, MRE: 4.013562 \n",
      "\n",
      "Epoch 107/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 107/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 107/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 107/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 107/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 107/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 107/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 107/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 107/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 107/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 107/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 107/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 107/800, Iteration 13/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001482, MRE: 1.718358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001479, MRE: 4.034472 \n",
      "\n",
      "Epoch 108/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 108/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 108/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 108/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 108/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 108/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 108/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 108/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 108/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 108/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 108/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 108/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 108/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001481, MRE: 1.710947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001472, MRE: 3.946038 \n",
      "\n",
      "Epoch 109/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 109/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 109/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 109/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 109/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 109/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 109/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 109/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 109/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 109/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 109/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 109/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 109/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001477, MRE: 1.709011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001472, MRE: 3.956201 \n",
      "\n",
      "Epoch 110/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 110/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 110/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 110/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 110/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 110/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 110/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 110/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 110/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 110/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 110/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 110/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 110/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001483, MRE: 1.717696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001466, MRE: 3.843208 \n",
      "\n",
      "Epoch 111/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 111/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 111/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 111/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 111/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 111/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 111/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 111/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 111/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 111/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 111/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001453, MRE: 2.031459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001469, MRE: 3.923840 \n",
      "\n",
      "Epoch 112/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 112/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 112/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 112/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 112/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 112/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 112/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 112/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 112/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 112/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 112/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 112/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 112/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001478, MRE: 1.711208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001470, MRE: 3.952845 \n",
      "\n",
      "Epoch 113/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 113/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 113/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 113/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 113/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 113/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 113/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 113/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 113/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 113/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 113/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 113/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 113/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001486, MRE: 1.723282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001471, MRE: 3.961059 \n",
      "\n",
      "Epoch 114/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 114/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 114/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 114/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 114/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 114/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 114/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 114/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001491, MRE: 1.725801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001472, MRE: 3.980346 \n",
      "\n",
      "Epoch 115/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 115/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 115/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 115/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 115/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 115/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 115/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 115/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 115/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 115/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 115/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 115/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 115/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001485, MRE: 2.074743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001472, MRE: 3.991507 \n",
      "\n",
      "Epoch 116/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 116/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 116/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 116/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 116/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 116/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 116/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 116/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 116/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 116/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 116/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 116/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 116/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001473, MRE: 1.735298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001475, MRE: 4.035549 \n",
      "\n",
      "Epoch 117/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 117/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 117/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 117/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 117/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 117/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 117/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 117/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 117/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001480, MRE: 2.036085 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001469, MRE: 3.947765 \n",
      "\n",
      "Epoch 118/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 118/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 118/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 118/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 118/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 118/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 118/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 118/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001485, MRE: 1.741352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001469, MRE: 3.966762 \n",
      "\n",
      "Epoch 119/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 119/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 119/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 119/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 119/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 119/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 119/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 119/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 119/800, Iteration 9/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 119/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 119/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 119/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001471, MRE: 1.729997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001473, MRE: 4.012609 \n",
      "\n",
      "Epoch 120/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 120/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 120/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 120/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 120/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 120/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 120/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 120/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 120/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 120/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 120/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 120/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 120/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001472, MRE: 1.712108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001473, MRE: 4.019849 \n",
      "\n",
      "Epoch 121/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 121/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 121/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 121/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 121/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 121/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 121/800, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 121/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 121/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 121/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001474, MRE: 1.709715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001469, MRE: 3.980463 \n",
      "\n",
      "Epoch 122/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 122/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 122/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 122/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 122/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 122/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 122/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 122/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 122/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 122/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 122/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 122/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 122/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001478, MRE: 1.741520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001468, MRE: 3.961505 \n",
      "\n",
      "Epoch 123/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 123/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 123/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 123/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 123/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 123/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 123/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 123/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 123/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 123/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 123/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 123/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 123/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001457, MRE: 1.697273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001470, MRE: 4.005396 \n",
      "\n",
      "Epoch 124/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 124/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 124/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 124/800, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 124/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 124/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 124/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 124/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 124/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 124/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001474, MRE: 1.702414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001467, MRE: 3.961557 \n",
      "\n",
      "Epoch 125/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 125/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 125/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 125/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 125/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 125/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 125/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 125/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 125/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 125/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 125/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 125/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 125/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001458, MRE: 1.716015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001465, MRE: 3.942879 \n",
      "\n",
      "Epoch 126/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 126/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 126/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 126/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 126/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 126/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 126/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 126/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 126/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 126/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 126/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 126/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 126/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001467, MRE: 1.731390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001466, MRE: 3.961470 \n",
      "\n",
      "Epoch 127/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 127/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 127/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 127/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 127/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 127/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 127/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 127/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 127/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 127/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 127/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 127/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 127/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001470, MRE: 1.708161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001467, MRE: 3.979849 \n",
      "\n",
      "Epoch 128/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 128/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 128/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 128/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 128/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 128/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 128/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 128/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 128/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001479, MRE: 1.745475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001469, MRE: 4.013978 \n",
      "\n",
      "Epoch 129/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 129/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 129/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 129/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 129/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 129/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 129/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 129/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 129/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 129/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 129/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 129/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 129/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 56.25%, Avg loss: 0.001474, MRE: 1.793639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001481, MRE: 4.137493 \n",
      "\n",
      "Epoch 130/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 130/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 130/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 130/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 130/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 130/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 130/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 130/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 130/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 130/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 130/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 130/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 130/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001472, MRE: 1.729847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001467, MRE: 3.998386 \n",
      "\n",
      "Epoch 131/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 131/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 131/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 131/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 131/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 131/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 131/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 131/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 131/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001454, MRE: 1.709292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001464, MRE: 3.948919 \n",
      "\n",
      "Epoch 132/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 132/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 132/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 132/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 132/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 132/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 132/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 132/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 132/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 132/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 132/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 132/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 132/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001500, MRE: 2.025483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001461, MRE: 3.910936 \n",
      "\n",
      "Epoch 133/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 133/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 133/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 133/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 133/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 133/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 133/800, Iteration 8/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 133/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 133/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 133/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001477, MRE: 1.708518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001461, MRE: 3.910963 \n",
      "\n",
      "Epoch 134/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 134/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 134/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 134/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 134/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 134/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 134/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 134/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 134/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 134/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 134/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 134/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 134/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001473, MRE: 1.731929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001459, MRE: 3.888949 \n",
      "\n",
      "Epoch 135/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 135/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 135/800, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 135/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 135/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 135/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 135/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 135/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 135/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 135/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 135/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 135/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 135/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001460, MRE: 1.866027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001463, MRE: 3.961096 \n",
      "\n",
      "Epoch 136/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 136/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 136/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 136/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 136/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 136/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 136/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 136/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 136/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 136/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 136/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 136/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 136/800, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 56.88%, Avg loss: 0.001471, MRE: 1.703598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001471, MRE: 4.065979 \n",
      "\n",
      "Epoch 137/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 137/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 137/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 137/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 137/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 137/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 137/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 137/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 137/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 137/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 137/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 137/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 137/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001464, MRE: 1.701231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001464, MRE: 3.975967 \n",
      "\n",
      "Epoch 138/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 138/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 138/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 138/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 138/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 138/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 138/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 138/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001448, MRE: 1.722297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001463, MRE: 3.962042 \n",
      "\n",
      "Epoch 139/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 139/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 139/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 139/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 139/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 139/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 139/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 139/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 139/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 139/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 139/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 139/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 139/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001453, MRE: 1.701580 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001462, MRE: 3.957146 \n",
      "\n",
      "Epoch 140/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 140/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 140/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 140/800, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 140/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 140/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 140/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 140/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 140/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 140/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 140/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 140/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001448, MRE: 1.703242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001460, MRE: 3.930652 \n",
      "\n",
      "Epoch 141/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 141/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 141/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 141/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 141/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 141/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 141/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 141/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 141/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 141/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 141/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001458, MRE: 1.765838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001461, MRE: 3.951731 \n",
      "\n",
      "Epoch 142/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 142/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 142/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 142/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 142/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 142/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 142/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 142/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 142/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 142/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 142/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 142/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 142/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 60.38%, Avg loss: 0.001457, MRE: 1.702931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001457, MRE: 3.901094 \n",
      "\n",
      "Epoch 143/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 143/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 143/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 143/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 143/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 143/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 143/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 143/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 143/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 143/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 143/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001472, MRE: 1.719677 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001461, MRE: 3.968529 \n",
      "\n",
      "Epoch 144/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 144/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 144/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 144/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 144/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 144/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 144/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 144/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 144/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 144/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 144/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 144/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 144/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001478, MRE: 1.721699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001459, MRE: 3.935591 \n",
      "\n",
      "Epoch 145/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 145/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 145/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 145/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 145/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 145/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 145/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 145/800, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 145/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 145/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 145/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 145/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 145/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.38%, Avg loss: 0.001453, MRE: 1.837233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001456, MRE: 3.898791 \n",
      "\n",
      "Epoch 146/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 146/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 146/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 146/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 146/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 146/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 146/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 146/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 146/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 146/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 146/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 146/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 146/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001474, MRE: 1.701246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001465, MRE: 4.026662 \n",
      "\n",
      "Epoch 147/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 147/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 147/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 147/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 147/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 147/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 147/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 147/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 147/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 12/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001467, MRE: 1.699385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001463, MRE: 4.011133 \n",
      "\n",
      "Epoch 148/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 148/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 148/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 148/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 148/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 148/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 148/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 148/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 148/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 148/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 148/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 148/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 148/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001471, MRE: 1.710938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001460, MRE: 3.971838 \n",
      "\n",
      "Epoch 149/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 149/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 149/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 149/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 149/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 149/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 149/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 149/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 149/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 149/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 149/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 149/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 149/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001471, MRE: 1.835028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001460, MRE: 3.971697 \n",
      "\n",
      "Epoch 150/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 150/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 150/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 150/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 150/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 150/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 150/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 150/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 150/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 150/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 150/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 150/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 150/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001462, MRE: 1.750659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001456, MRE: 3.905624 \n",
      "\n",
      "Epoch 151/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 151/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 151/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 151/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 151/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 151/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 151/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 151/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 151/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 151/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 151/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 151/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 151/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001469, MRE: 1.700344 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001458, MRE: 3.954844 \n",
      "\n",
      "Epoch 152/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 152/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 152/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 152/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 152/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 152/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 152/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 152/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 152/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 152/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 152/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 152/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 152/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 56.62%, Avg loss: 0.001467, MRE: 1.702905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001469, MRE: 4.089662 \n",
      "\n",
      "Epoch 153/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 153/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 153/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 153/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 153/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 153/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 153/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 153/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 153/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 153/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 153/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 153/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 153/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001480, MRE: 1.721618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001462, MRE: 4.020781 \n",
      "\n",
      "Epoch 154/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 154/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 154/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 154/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 154/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 154/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 154/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 154/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 154/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001460, MRE: 1.726395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001461, MRE: 4.006738 \n",
      "\n",
      "Epoch 155/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 155/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 155/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 155/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 155/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 155/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 155/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 155/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001452, MRE: 1.687915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001457, MRE: 3.956225 \n",
      "\n",
      "Epoch 156/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 156/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 156/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 156/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 156/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 156/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 156/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 156/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 156/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 156/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 156/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 156/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 156/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001452, MRE: 1.834891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001462, MRE: 4.021410 \n",
      "\n",
      "Epoch 157/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 157/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 157/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 157/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 157/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 157/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 157/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001461, MRE: 1.765578 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001457, MRE: 3.956305 \n",
      "\n",
      "Epoch 158/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 158/800, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 158/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 158/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 158/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 158/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 158/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 158/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 158/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 158/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 158/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001454, MRE: 1.726292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001456, MRE: 3.957242 \n",
      "\n",
      "Epoch 159/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 159/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 159/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 159/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 159/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 159/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 159/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 159/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 159/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 159/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 159/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001457, MRE: 1.723807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001453, MRE: 3.895412 \n",
      "\n",
      "Epoch 160/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 160/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 160/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 160/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 160/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 160/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 160/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 160/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 160/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001486, MRE: 1.711361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001459, MRE: 3.994059 \n",
      "\n",
      "Epoch 161/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 161/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 161/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 161/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 161/800, Iteration 5/12, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 161/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 161/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 161/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 161/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001488, MRE: 1.744247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001455, MRE: 3.948190 \n",
      "\n",
      "Epoch 162/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 162/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 162/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 162/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 162/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 162/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 162/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 162/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 162/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 162/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 162/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 162/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 162/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001462, MRE: 1.697522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001453, MRE: 3.925855 \n",
      "\n",
      "Epoch 163/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 163/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 163/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 163/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 163/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 163/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 163/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 163/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 163/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 163/800, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001463, MRE: 1.696041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001455, MRE: 3.947020 \n",
      "\n",
      "Epoch 164/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 164/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 164/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 164/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 164/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 164/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 164/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 164/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 164/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 164/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 164/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 164/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 164/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 60.88%, Avg loss: 0.001444, MRE: 1.688778 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001450, MRE: 3.866709 \n",
      "\n",
      "Epoch 165/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 165/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 165/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 165/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 165/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 165/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 165/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 165/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 165/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 165/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 165/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 165/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 165/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001444, MRE: 1.716788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001452, MRE: 3.911579 \n",
      "\n",
      "Epoch 166/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 166/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 166/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 166/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 166/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 166/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 166/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 166/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 166/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 166/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 166/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 166/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 166/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001476, MRE: 1.730391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001456, MRE: 3.977083 \n",
      "\n",
      "Epoch 167/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 167/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 167/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 167/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 167/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 167/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 167/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 167/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 60.88%, Avg loss: 0.001466, MRE: 1.721388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001449, MRE: 3.865318 \n",
      "\n",
      "Epoch 168/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 168/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 168/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 168/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 168/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 168/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 168/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 168/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 168/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 168/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 168/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 168/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 168/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001457, MRE: 1.886810 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001453, MRE: 3.938962 \n",
      "\n",
      "Epoch 169/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 169/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 169/800, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 169/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 169/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 169/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 169/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 169/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 169/800, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001472, MRE: 1.695900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001459, MRE: 4.025873 \n",
      "\n",
      "Epoch 170/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 170/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 170/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 170/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 170/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 170/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 170/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 170/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 170/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 170/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 170/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 170/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 170/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001445, MRE: 1.720646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001453, MRE: 3.954940 \n",
      "\n",
      "Epoch 171/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 171/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 171/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 171/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 171/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 171/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 171/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 171/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 171/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 171/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 171/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 171/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 171/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 57.25%, Avg loss: 0.001460, MRE: 1.716394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001460, MRE: 4.039191 \n",
      "\n",
      "Epoch 172/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 172/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 172/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 172/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 172/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 172/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 172/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 172/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 172/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 172/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 172/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 172/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 172/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001441, MRE: 1.688103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001451, MRE: 3.915275 \n",
      "\n",
      "Epoch 173/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 173/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 173/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 173/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 173/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 173/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 173/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 173/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 173/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 173/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 173/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 173/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 173/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001466, MRE: 1.886516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001454, MRE: 3.971517 \n",
      "\n",
      "Epoch 174/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 174/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 174/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 174/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 174/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 174/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 174/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 174/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 174/800, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001437, MRE: 1.687002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001453, MRE: 3.960020 \n",
      "\n",
      "Epoch 175/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 175/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 175/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 175/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 175/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 56.38%, Avg loss: 0.001458, MRE: 1.712218 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001466, MRE: 4.112427 \n",
      "\n",
      "Epoch 176/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 176/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 176/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 176/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 176/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 176/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 176/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 176/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 176/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 176/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 176/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 176/800, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 176/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001460, MRE: 1.688457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001455, MRE: 4.002346 \n",
      "\n",
      "Epoch 177/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 177/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 177/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 177/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 177/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 177/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 177/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 177/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 177/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 177/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 177/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 177/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 177/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001454, MRE: 1.695014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001456, MRE: 4.019125 \n",
      "\n",
      "Epoch 178/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 178/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 178/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 178/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 178/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 178/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 178/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 178/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 56.75%, Avg loss: 0.001462, MRE: 1.704049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001460, MRE: 4.067459 \n",
      "\n",
      "Epoch 179/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 179/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 179/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 179/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 179/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 179/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 179/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 179/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 179/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 179/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 179/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 179/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 179/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001458, MRE: 1.713982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001452, MRE: 3.971352 \n",
      "\n",
      "Epoch 180/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 180/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 180/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 180/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 180/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 180/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 180/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 180/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 180/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 180/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 180/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 180/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 180/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001446, MRE: 1.718711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001454, MRE: 3.999482 \n",
      "\n",
      "Epoch 181/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 181/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 181/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 181/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 181/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 181/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 181/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 181/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 181/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 181/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 181/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 181/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 181/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001445, MRE: 1.688806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001450, MRE: 3.944244 \n",
      "\n",
      "Epoch 182/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 182/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 182/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 182/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 182/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 182/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 182/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 182/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 182/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 182/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 182/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 182/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 182/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001457, MRE: 1.741476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001454, MRE: 4.010025 \n",
      "\n",
      "Epoch 183/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 183/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 183/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 183/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 183/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 183/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 183/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 183/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 183/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 183/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 183/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 183/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 183/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001470, MRE: 1.700612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001455, MRE: 4.027697 \n",
      "\n",
      "Epoch 184/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 184/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 184/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 184/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 184/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 184/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 184/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 184/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 184/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 184/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 184/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 184/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 184/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001457, MRE: 1.704451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001450, MRE: 3.958668 \n",
      "\n",
      "Epoch 185/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 185/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 185/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 185/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 185/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 185/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 185/800, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 185/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 185/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 185/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001463, MRE: 1.700807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001447, MRE: 3.916964 \n",
      "\n",
      "Epoch 186/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 186/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 186/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 186/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 186/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 186/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 186/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 186/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 186/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 186/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 186/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 186/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 186/800, Iteration 13/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001456, MRE: 1.721229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001452, MRE: 3.989858 \n",
      "\n",
      "Epoch 187/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 187/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 187/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 187/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 187/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 187/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 187/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 187/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 187/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 187/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 187/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 187/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 187/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001466, MRE: 1.699303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001447, MRE: 3.926228 \n",
      "\n",
      "Epoch 188/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 188/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 188/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 188/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 188/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 188/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 188/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 188/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 188/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 188/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001457, MRE: 1.722195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001447, MRE: 3.930228 \n",
      "\n",
      "Epoch 189/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 189/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 189/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 189/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 189/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 189/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 189/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 189/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 189/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 189/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 189/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001437, MRE: 1.723310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001447, MRE: 3.937689 \n",
      "\n",
      "Epoch 190/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 190/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 190/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 190/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 190/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 190/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 190/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 190/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 190/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 190/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 190/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 190/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 190/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001441, MRE: 1.691244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001446, MRE: 3.927994 \n",
      "\n",
      "Epoch 191/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 191/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 191/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 191/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 191/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 191/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 191/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 191/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 191/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 191/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 191/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.75%, Avg loss: 0.001459, MRE: 1.696552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 3.867253 \n",
      "\n",
      "Epoch 192/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 192/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 192/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 192/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 192/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 192/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 192/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 192/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 192/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 192/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 192/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 192/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 192/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 60.75%, Avg loss: 0.001453, MRE: 1.693739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 3.884842 \n",
      "\n",
      "Epoch 193/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 193/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 193/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 193/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 193/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 193/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 193/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 193/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 193/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 193/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 193/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 193/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 193/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001479, MRE: 1.694925 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001447, MRE: 3.953053 \n",
      "\n",
      "Epoch 194/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 194/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 194/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 194/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 194/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 194/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 194/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 194/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 194/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 194/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 194/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 194/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 194/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001478, MRE: 1.711246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001449, MRE: 3.986861 \n",
      "\n",
      "Epoch 195/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 195/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 195/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 195/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 195/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 195/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 195/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 195/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 195/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 195/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 195/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 195/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 195/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001445, MRE: 1.688886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001450, MRE: 4.006580 \n",
      "\n",
      "Epoch 196/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 196/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 196/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 196/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 196/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 196/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 196/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 196/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 196/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 196/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 196/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 196/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 196/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001481, MRE: 1.686149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001446, MRE: 3.951099 \n",
      "\n",
      "Epoch 197/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 197/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 197/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 197/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 197/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 197/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 197/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 197/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 197/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 197/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 197/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 197/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 197/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001466, MRE: 1.683018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.933451 \n",
      "\n",
      "Epoch 198/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 198/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 198/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 198/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 198/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 198/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 198/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 198/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 198/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 198/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 198/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 198/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 198/800, Iteration 13/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001446, MRE: 1.723665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001442, MRE: 3.887716 \n",
      "\n",
      "Epoch 199/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 199/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 199/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 199/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 199/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 199/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 199/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 199/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 199/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 199/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 199/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 199/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 199/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.38%, Avg loss: 0.001460, MRE: 1.684932 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001451, MRE: 4.030007 \n",
      "\n",
      "Epoch 200/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 200/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 200/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 200/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 200/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 200/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 200/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 200/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 200/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 200/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 200/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 200/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 200/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001462, MRE: 1.694418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.951849 \n",
      "\n",
      "Epoch 201/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 201/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 201/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 201/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 201/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 201/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 201/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 201/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 201/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 201/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001452, MRE: 1.681122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.947009 \n",
      "\n",
      "Epoch 202/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 202/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 202/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 202/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 202/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 202/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 202/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 202/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 202/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 202/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 202/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 202/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 202/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001433, MRE: 1.692867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.944296 \n",
      "\n",
      "Epoch 203/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 203/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 203/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 203/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 203/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 203/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 203/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 203/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 203/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 203/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 203/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 203/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 203/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.692574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.945805 \n",
      "\n",
      "Epoch 204/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 204/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 204/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 204/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 204/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 204/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 204/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 204/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 204/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 204/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 204/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 204/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 204/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001454, MRE: 1.767247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.954897 \n",
      "\n",
      "Epoch 205/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 205/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 205/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 205/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 205/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 205/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 205/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 205/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 205/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 205/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 205/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001448, MRE: 1.699248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001446, MRE: 3.961608 \n",
      "\n",
      "Epoch 206/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 206/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 206/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 206/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 206/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 206/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 206/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 206/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 206/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 206/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 206/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 206/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 206/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.684133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.961409 \n",
      "\n",
      "Epoch 207/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 207/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 207/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 207/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 207/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 207/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 207/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 207/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 207/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 207/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 207/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 207/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 207/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001451, MRE: 1.687718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.957443 \n",
      "\n",
      "Epoch 208/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 208/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 208/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 208/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 208/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 208/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 208/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 208/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 208/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001449, MRE: 1.676679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.955970 \n",
      "\n",
      "Epoch 209/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 209/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 209/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 209/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 209/800, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 209/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 209/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 209/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 209/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 209/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 209/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 209/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 209/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001441, MRE: 1.680093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.949539 \n",
      "\n",
      "Epoch 210/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 210/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 210/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 210/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 210/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 210/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 210/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 210/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 210/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 210/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 210/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 210/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 210/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001438, MRE: 1.831355 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.947428 \n",
      "\n",
      "Epoch 211/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 211/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 211/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 211/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 211/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 211/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 211/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 211/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 211/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 211/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 211/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 211/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 211/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001446, MRE: 1.687514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.948951 \n",
      "\n",
      "Epoch 212/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 212/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 212/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 212/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 212/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 212/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 212/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 212/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 212/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001462, MRE: 1.700662 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.948530 \n",
      "\n",
      "Epoch 213/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 213/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 213/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 213/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 213/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 213/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 213/800, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 213/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 213/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 213/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001468, MRE: 1.685534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.945873 \n",
      "\n",
      "Epoch 214/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 214/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 214/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 214/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 214/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 214/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 214/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 214/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 214/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 214/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 214/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 214/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001446, MRE: 1.723828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.944255 \n",
      "\n",
      "Epoch 215/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 215/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 215/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 215/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 215/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 215/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 215/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 215/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 215/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 215/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 215/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 215/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 215/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001459, MRE: 1.684491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.946232 \n",
      "\n",
      "Epoch 216/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 216/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 216/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 216/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 216/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 216/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 216/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 216/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 216/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 216/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 216/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 216/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 216/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001447, MRE: 2.010206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.944922 \n",
      "\n",
      "Epoch 217/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 217/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 217/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 217/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 217/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 217/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 217/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 217/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 217/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 217/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 217/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 217/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 217/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001452, MRE: 1.764889 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.946297 \n",
      "\n",
      "Epoch 218/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 218/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 218/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 218/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 218/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 218/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 218/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001443, MRE: 1.714049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.945919 \n",
      "\n",
      "Epoch 219/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 219/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 219/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 219/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 219/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 219/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 219/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 219/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 219/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 219/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 219/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 219/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001430, MRE: 1.697667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.944262 \n",
      "\n",
      "Epoch 220/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 220/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 220/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 220/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 220/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 220/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 220/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 220/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 220/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 220/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 220/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 220/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 220/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.821120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.943093 \n",
      "\n",
      "Epoch 221/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 221/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 221/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 221/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 221/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 221/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 221/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001468, MRE: 1.711773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.935377 \n",
      "\n",
      "Epoch 222/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 222/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 222/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 222/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 222/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 222/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 222/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 222/800, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 222/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 222/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 222/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 222/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 222/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001435, MRE: 1.677735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.928984 \n",
      "\n",
      "Epoch 223/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 223/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 223/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 223/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 223/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 223/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 223/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 223/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 223/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 223/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 223/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 223/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 223/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001445, MRE: 1.742885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.934103 \n",
      "\n",
      "Epoch 224/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 224/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 224/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 224/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 224/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 224/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 224/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 224/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 224/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 224/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001443, MRE: 1.679059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.940547 \n",
      "\n",
      "Epoch 225/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 225/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 225/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 225/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 225/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 225/800, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 225/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 225/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 225/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001450, MRE: 1.682773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.940554 \n",
      "\n",
      "Epoch 226/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 226/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 226/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 226/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 226/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 226/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 226/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 226/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 226/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 226/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 226/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 226/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 226/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001438, MRE: 1.744068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.937962 \n",
      "\n",
      "Epoch 227/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 227/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 227/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 227/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 227/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 227/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 227/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 227/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 227/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 227/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 227/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 227/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 227/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001454, MRE: 1.678867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.941015 \n",
      "\n",
      "Epoch 228/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 228/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 228/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 228/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 228/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 228/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 228/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 228/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 228/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 228/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 228/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001437, MRE: 1.735555 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.942464 \n",
      "\n",
      "Epoch 229/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 229/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 229/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 229/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 229/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 229/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 229/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 229/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 229/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 229/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 229/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 229/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 229/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001465, MRE: 1.687238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.947796 \n",
      "\n",
      "Epoch 230/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 230/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 230/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 230/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 230/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 230/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 230/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 230/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 230/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 230/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 230/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 230/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 230/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001460, MRE: 1.688018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.945284 \n",
      "\n",
      "Epoch 231/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 231/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 231/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 231/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 231/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 231/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 231/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 231/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 231/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 231/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001443, MRE: 1.717590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.941812 \n",
      "\n",
      "Epoch 232/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 232/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 232/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 232/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 232/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 232/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 232/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 232/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001455, MRE: 1.693956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.951731 \n",
      "\n",
      "Epoch 233/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 233/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 233/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 233/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 233/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 233/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 233/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 233/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 233/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 233/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 233/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 233/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 233/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001460, MRE: 1.708053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.962946 \n",
      "\n",
      "Epoch 234/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 234/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 234/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 234/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 234/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 234/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 234/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 234/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 234/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 234/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 234/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001463, MRE: 1.725285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.964154 \n",
      "\n",
      "Epoch 235/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 235/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 235/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 235/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 235/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 235/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 235/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 235/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 235/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 235/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 235/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001431, MRE: 1.672483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.957698 \n",
      "\n",
      "Epoch 236/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 236/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 236/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 236/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 236/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 236/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 236/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 236/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 236/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 236/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 236/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 236/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 236/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001448, MRE: 1.728939 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.957484 \n",
      "\n",
      "Epoch 237/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 237/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 237/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 237/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 237/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 237/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 237/800, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 237/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 237/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001447, MRE: 1.685614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.952008 \n",
      "\n",
      "Epoch 238/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 238/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 238/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 238/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 238/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 238/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 238/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 238/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 238/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 238/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 238/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 238/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 238/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.692473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.947425 \n",
      "\n",
      "Epoch 239/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 239/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 239/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 239/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 239/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 239/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 239/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 239/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 239/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 239/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001467, MRE: 1.701518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.938792 \n",
      "\n",
      "Epoch 240/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 240/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 240/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 240/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 240/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 240/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 240/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 240/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 240/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 240/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 240/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 240/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 240/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001442, MRE: 1.692113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.940604 \n",
      "\n",
      "Epoch 241/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 241/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 241/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 241/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 241/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 241/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 241/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 241/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 241/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 241/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001475, MRE: 1.765196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.945559 \n",
      "\n",
      "Epoch 242/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 242/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 242/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 242/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 242/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 242/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 242/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 242/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 242/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 242/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.890749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.940049 \n",
      "\n",
      "Epoch 243/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 243/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 243/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 243/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 243/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 243/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 243/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 243/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 243/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 243/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 243/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001461, MRE: 1.679075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.940296 \n",
      "\n",
      "Epoch 244/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 244/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 244/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 244/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 244/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 244/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 244/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 244/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 244/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 244/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 244/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 244/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 244/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001462, MRE: 1.702783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.937035 \n",
      "\n",
      "Epoch 245/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 245/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 245/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 245/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 245/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 245/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 245/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 245/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 245/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 245/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 245/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 245/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 245/800, Iteration 13/12, Loss: 0.0006\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001450, MRE: 1.696671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.930107 \n",
      "\n",
      "Epoch 246/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 246/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 246/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 246/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 246/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 246/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 246/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 246/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 246/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 246/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 246/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001462, MRE: 1.888001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.947808 \n",
      "\n",
      "Epoch 247/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 247/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 247/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 247/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 247/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 247/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 247/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 247/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 247/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 247/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 247/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 247/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001443, MRE: 1.679066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.953426 \n",
      "\n",
      "Epoch 248/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 248/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 248/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 248/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 248/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 248/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 248/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 248/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 248/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 248/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 248/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 248/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 248/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001454, MRE: 2.026531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.956844 \n",
      "\n",
      "Epoch 249/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 249/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 249/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 249/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 249/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 249/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 249/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 249/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 249/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 249/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 249/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 249/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 249/800, Iteration 13/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001475, MRE: 2.051241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.968575 \n",
      "\n",
      "Epoch 250/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 250/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 250/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 250/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 250/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 250/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 250/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001462, MRE: 1.683862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001445, MRE: 3.969157 \n",
      "\n",
      "Epoch 251/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 251/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 251/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 251/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 251/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 251/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 251/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 251/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 251/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 251/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 251/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 251/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 251/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001447, MRE: 1.700922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.962974 \n",
      "\n",
      "Epoch 252/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 252/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 252/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 252/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 252/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 252/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 252/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 252/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001461, MRE: 1.707828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.951831 \n",
      "\n",
      "Epoch 253/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 253/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 253/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 253/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 253/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 253/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 253/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 253/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001443, MRE: 1.749680 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.950940 \n",
      "\n",
      "Epoch 254/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 254/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 254/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 254/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 254/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 254/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 254/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 254/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 254/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 254/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 254/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 254/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 254/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001448, MRE: 2.023630 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.939534 \n",
      "\n",
      "Epoch 255/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 255/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 255/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 255/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 255/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 255/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 255/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 255/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 255/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001466, MRE: 2.021000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.936702 \n",
      "\n",
      "Epoch 256/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 256/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 256/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 256/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 256/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 256/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 256/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 256/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 256/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 256/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 256/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 256/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 256/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001449, MRE: 1.752973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.939191 \n",
      "\n",
      "Epoch 257/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 257/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 257/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 257/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 257/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 257/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 257/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 257/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 257/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 257/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001436, MRE: 1.694878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.942400 \n",
      "\n",
      "Epoch 258/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 258/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 258/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 258/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 258/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 258/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 258/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 258/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 258/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 258/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 258/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 258/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001434, MRE: 1.722650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.939236 \n",
      "\n",
      "Epoch 259/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 259/800, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 259/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 259/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 259/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 259/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 259/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 259/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 259/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 259/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 259/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 259/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 259/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001472, MRE: 1.692767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.936578 \n",
      "\n",
      "Epoch 260/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 260/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 260/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 260/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 260/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 260/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 260/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 260/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 260/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 260/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 260/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 260/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 260/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001449, MRE: 1.739570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.937719 \n",
      "\n",
      "Epoch 261/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 261/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 261/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 261/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 261/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 261/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 261/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 261/800, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 261/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 261/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001465, MRE: 1.708005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.936884 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 262/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 262/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 262/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 262/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 262/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 262/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 262/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 262/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 262/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 262/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 262/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 262/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001442, MRE: 1.681801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.945294 \n",
      "\n",
      "Epoch 263/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 263/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 263/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 263/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 263/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 263/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 263/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 263/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 263/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 263/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 263/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 263/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 263/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001452, MRE: 1.687327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.951204 \n",
      "\n",
      "Epoch 264/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 264/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 264/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 264/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 264/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 264/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 264/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 264/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 264/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 264/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 264/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 264/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 264/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001427, MRE: 1.710393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.955943 \n",
      "\n",
      "Epoch 265/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 265/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 265/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 265/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 265/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 265/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 265/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 265/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 265/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001452, MRE: 1.823118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.954879 \n",
      "\n",
      "Epoch 266/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 266/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 266/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 266/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 266/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 266/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 266/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 266/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 266/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 266/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 266/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 266/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 266/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001441, MRE: 1.849570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.955435 \n",
      "\n",
      "Epoch 267/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 267/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 267/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 267/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 267/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 267/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 267/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 267/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 267/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 267/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 267/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 267/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 267/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001453, MRE: 1.690153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.945785 \n",
      "\n",
      "Epoch 268/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 268/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 268/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 268/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 268/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 268/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 268/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 268/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 268/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 268/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 268/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 268/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 268/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.691922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.955691 \n",
      "\n",
      "Epoch 269/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 269/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 269/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 269/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 269/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 269/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 269/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 269/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 269/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 269/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 269/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 269/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 269/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001451, MRE: 1.685414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.957340 \n",
      "\n",
      "Epoch 270/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 270/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 270/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 270/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 270/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 270/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 270/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 270/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 270/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 270/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 270/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 270/800, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 270/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001461, MRE: 1.710551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.952877 \n",
      "\n",
      "Epoch 271/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 271/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 271/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 271/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 271/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 271/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 271/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 271/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 271/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 271/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 271/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 271/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 271/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001451, MRE: 1.689487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.942713 \n",
      "\n",
      "Epoch 272/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 272/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 272/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 272/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 272/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 272/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 272/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 272/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 272/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 272/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 272/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 272/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 272/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001446, MRE: 1.687423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.947798 \n",
      "\n",
      "Epoch 273/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 273/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 273/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 273/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 273/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 273/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 273/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 273/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 273/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 273/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001445, MRE: 1.682704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.950105 \n",
      "\n",
      "Epoch 274/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 274/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 274/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 274/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 274/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 274/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 274/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 274/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 274/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 274/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 274/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001443, MRE: 1.673550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.951811 \n",
      "\n",
      "Epoch 275/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 275/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 275/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 275/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 275/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 275/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 275/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 275/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 275/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 275/800, Iteration 10/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/800, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 275/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 275/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001461, MRE: 1.710043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.946996 \n",
      "\n",
      "Epoch 276/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 276/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 276/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 276/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 276/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 276/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 276/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 276/800, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001458, MRE: 1.750663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.954810 \n",
      "\n",
      "Epoch 277/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 277/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 277/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 277/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 277/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 277/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 277/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 277/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 277/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 277/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 277/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 277/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 277/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001454, MRE: 1.692769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.956556 \n",
      "\n",
      "Epoch 278/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 278/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 278/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 278/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 278/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 278/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 278/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 278/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 278/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001432, MRE: 1.688242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.949064 \n",
      "\n",
      "Epoch 279/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 279/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 279/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 279/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 279/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 279/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 279/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 279/800, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 279/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 279/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 279/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 279/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 279/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001452, MRE: 1.683388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.949292 \n",
      "\n",
      "Epoch 280/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 280/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 280/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 280/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 280/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 280/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 280/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 280/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 280/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 280/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 280/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 280/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 280/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001475, MRE: 1.677322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.964579 \n",
      "\n",
      "Epoch 281/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 281/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 281/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 281/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 281/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 281/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 281/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 281/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.707383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001444, MRE: 3.963861 \n",
      "\n",
      "Epoch 282/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 282/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 282/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 282/800, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 282/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 282/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 282/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 282/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 282/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 282/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001454, MRE: 1.857607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.960428 \n",
      "\n",
      "Epoch 283/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 283/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 283/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 283/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 283/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 283/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 283/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 283/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 283/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 283/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 283/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 283/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 283/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001457, MRE: 1.855149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.951736 \n",
      "\n",
      "Epoch 284/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 284/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 284/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 284/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 284/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 284/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 284/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 284/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 284/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 284/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 284/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 284/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 284/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.680449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.952241 \n",
      "\n",
      "Epoch 285/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 285/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 285/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 285/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 285/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 285/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 285/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 285/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 285/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 285/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 285/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 285/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 285/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001449, MRE: 1.723879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.953391 \n",
      "\n",
      "Epoch 286/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 286/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 286/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 286/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 286/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 286/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 286/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 286/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 286/800, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 286/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 286/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 286/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 286/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.689581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.941067 \n",
      "\n",
      "Epoch 287/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 287/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 287/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 287/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 287/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 287/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 287/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001443, MRE: 1.703160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.943969 \n",
      "\n",
      "Epoch 288/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 288/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 288/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 288/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 288/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 288/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 288/800, Iteration 11/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 288/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001446, MRE: 1.699593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.939363 \n",
      "\n",
      "Epoch 289/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 289/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 289/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 289/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 289/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 289/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 289/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 289/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 289/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 289/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 289/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 289/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 289/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001437, MRE: 1.689188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.936464 \n",
      "\n",
      "Epoch 290/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 290/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 290/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 290/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 290/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 290/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 290/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 290/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 290/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 290/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 290/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 290/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 290/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001437, MRE: 1.678209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.937242 \n",
      "\n",
      "Epoch 291/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 291/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 291/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 291/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 291/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 291/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 291/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 291/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 291/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 291/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 291/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 291/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 291/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001455, MRE: 1.692664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.942436 \n",
      "\n",
      "Epoch 292/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 292/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 292/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 292/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 292/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 292/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 292/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 292/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 292/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001452, MRE: 1.841493 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.943011 \n",
      "\n",
      "Epoch 293/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 293/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 293/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 293/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 293/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 293/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 293/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 293/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 293/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 293/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 293/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 293/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 293/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001454, MRE: 1.690461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.931522 \n",
      "\n",
      "Epoch 294/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 294/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 294/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 294/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 294/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 294/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 294/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 294/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 294/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 294/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 294/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 294/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 294/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001441, MRE: 1.675749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.936842 \n",
      "\n",
      "Epoch 295/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 295/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 295/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 295/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 295/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 295/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 295/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 295/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 295/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 295/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001447, MRE: 1.682505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.926147 \n",
      "\n",
      "Epoch 296/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 296/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 296/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 296/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 296/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 296/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 296/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 296/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 296/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 296/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001464, MRE: 1.681531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.931838 \n",
      "\n",
      "Epoch 297/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 297/800, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 297/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 297/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 297/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 297/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 297/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 297/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 297/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 297/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001437, MRE: 1.679643 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.929526 \n",
      "\n",
      "Epoch 298/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 298/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 298/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 298/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 298/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 298/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 298/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 298/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 298/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 298/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001449, MRE: 1.682667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.930179 \n",
      "\n",
      "Epoch 299/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 299/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 299/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 299/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 299/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 299/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 299/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 299/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 299/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 299/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 299/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 299/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 299/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001434, MRE: 1.687560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.935224 \n",
      "\n",
      "Epoch 300/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 300/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 300/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 300/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 300/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 300/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 300/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 300/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 300/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 300/800, Iteration 10/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 300/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 300/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001449, MRE: 2.005301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.936390 \n",
      "\n",
      "Epoch 301/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 301/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 301/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 301/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 301/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 301/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 301/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 301/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 301/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 301/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 301/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 301/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 301/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001435, MRE: 1.692053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.940373 \n",
      "\n",
      "Epoch 302/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 302/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 302/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 302/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 302/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 302/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 302/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 302/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 302/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 302/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 302/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 302/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 302/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001441, MRE: 1.834144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.947246 \n",
      "\n",
      "Epoch 303/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 303/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 303/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 303/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 303/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 303/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 303/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 303/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 303/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 303/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 303/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001412, MRE: 1.683270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.954297 \n",
      "\n",
      "Epoch 304/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 304/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 304/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 304/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 304/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 304/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 304/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 304/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 304/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 304/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 304/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 304/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 304/800, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001447, MRE: 1.690143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.951193 \n",
      "\n",
      "Epoch 305/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 305/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 305/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 305/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 305/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 305/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 305/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 305/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 305/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 305/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 305/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 305/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 305/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001480, MRE: 1.688009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.944607 \n",
      "\n",
      "Epoch 306/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 306/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 306/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 306/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 306/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 306/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 306/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 306/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 306/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 306/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 306/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 306/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 306/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001466, MRE: 1.684744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.947479 \n",
      "\n",
      "Epoch 307/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 307/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 307/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 307/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 307/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 307/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 307/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 307/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 307/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 307/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.694164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.948563 \n",
      "\n",
      "Epoch 308/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 308/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 308/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 308/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 308/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 308/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 308/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 308/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 308/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 308/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 308/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 308/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.734281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.944175 \n",
      "\n",
      "Epoch 309/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 309/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 309/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 309/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 309/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 309/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 309/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 309/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 309/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 309/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 309/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 309/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 309/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001444, MRE: 1.727389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.933387 \n",
      "\n",
      "Epoch 310/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 310/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 310/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 310/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 310/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 310/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 310/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 310/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 310/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 310/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 310/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 310/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 310/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001442, MRE: 1.676576 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.936610 \n",
      "\n",
      "Epoch 311/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 311/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 311/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 311/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 311/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 311/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 311/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 311/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 311/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 311/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 311/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 311/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 311/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001454, MRE: 1.690723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.935320 \n",
      "\n",
      "Epoch 312/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 312/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 312/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 312/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 312/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 312/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 312/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 312/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 312/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 312/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 312/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 312/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 312/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001446, MRE: 1.683189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.926757 \n",
      "\n",
      "Epoch 313/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 313/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 313/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 313/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 313/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 313/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 313/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 313/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 313/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 313/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 313/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 313/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 313/800, Iteration 13/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001484, MRE: 1.706429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.931695 \n",
      "\n",
      "Epoch 314/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 314/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 314/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 314/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 314/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 314/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 314/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 314/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 314/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 314/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 314/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001443, MRE: 1.697917 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.930429 \n",
      "\n",
      "Epoch 315/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 315/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 315/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 315/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 315/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 315/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 315/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 315/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 315/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 315/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 315/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 315/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 315/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001446, MRE: 1.678463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.937081 \n",
      "\n",
      "Epoch 316/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 316/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 316/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 316/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 316/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 316/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 316/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 316/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 316/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 316/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 316/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 316/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 316/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001436, MRE: 1.696373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.938942 \n",
      "\n",
      "Epoch 317/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 317/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 317/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 317/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 317/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 317/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 317/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 317/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 317/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001434, MRE: 1.673580 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.945033 \n",
      "\n",
      "Epoch 318/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 318/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 318/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 318/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 318/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 318/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 318/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 318/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 318/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 318/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 318/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 318/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 318/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001454, MRE: 1.709309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.946407 \n",
      "\n",
      "Epoch 319/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 319/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 319/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 319/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 319/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 319/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 319/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 319/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 319/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 319/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 319/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 319/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 319/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001445, MRE: 1.709305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.947483 \n",
      "\n",
      "Epoch 320/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 320/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 320/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 320/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 320/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 320/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 320/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 320/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 320/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 320/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 320/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 320/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 320/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001451, MRE: 1.686321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.951897 \n",
      "\n",
      "Epoch 321/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 321/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 321/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 321/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 321/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 321/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 321/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 321/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 321/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 321/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 321/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 321/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 321/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001428, MRE: 1.671945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.954428 \n",
      "\n",
      "Epoch 322/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 322/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 322/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 322/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 322/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 322/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 322/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 322/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 322/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 322/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 322/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.725788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.956448 \n",
      "\n",
      "Epoch 323/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 323/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 323/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 323/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 323/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 323/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 323/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 323/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 323/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 323/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001464, MRE: 1.696713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.958452 \n",
      "\n",
      "Epoch 324/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 324/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 324/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 324/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 324/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 324/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 324/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 324/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 324/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.677052 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.962487 \n",
      "\n",
      "Epoch 325/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 325/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 325/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 325/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 325/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 325/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 325/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 325/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 325/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 325/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 325/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 325/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 325/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.722186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.963269 \n",
      "\n",
      "Epoch 326/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 326/800, Iteration 2/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 326/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 326/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 326/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 326/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 326/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 326/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 326/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 326/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 326/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 326/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001455, MRE: 1.692353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.954337 \n",
      "\n",
      "Epoch 327/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 327/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 327/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 327/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 327/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 327/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 327/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 327/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 327/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 327/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 327/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 327/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 327/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001481, MRE: 1.690804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.960117 \n",
      "\n",
      "Epoch 328/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 328/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 328/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 328/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 328/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 328/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 328/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 328/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 328/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 328/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 328/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 328/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 328/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001454, MRE: 2.013688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.964435 \n",
      "\n",
      "Epoch 329/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 329/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 329/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 329/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 329/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 329/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 329/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 329/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 329/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 329/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 329/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 329/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 329/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001437, MRE: 2.145936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001443, MRE: 3.965917 \n",
      "\n",
      "Epoch 330/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 330/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 330/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 330/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 330/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 330/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001425, MRE: 1.681087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.955429 \n",
      "\n",
      "Epoch 331/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 331/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 331/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 331/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 331/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 331/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 331/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 331/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 331/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 331/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 331/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 331/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 331/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001442, MRE: 1.677203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.947617 \n",
      "\n",
      "Epoch 332/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 332/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 332/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 332/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 332/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 332/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 332/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 332/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 332/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 332/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 332/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 332/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001441, MRE: 1.687799 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.939318 \n",
      "\n",
      "Epoch 333/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 333/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 333/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 333/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 333/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 333/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 333/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 333/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 333/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 333/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 333/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 333/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001440, MRE: 1.693724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.937171 \n",
      "\n",
      "Epoch 334/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 334/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 334/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 334/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 334/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 334/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 334/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 334/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 334/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 334/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 334/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 334/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 334/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001447, MRE: 1.691435 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.930580 \n",
      "\n",
      "Epoch 335/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 335/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 335/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 335/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 335/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 335/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 335/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 335/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 335/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 335/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 335/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 335/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 335/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001425, MRE: 1.680095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.941000 \n",
      "\n",
      "Epoch 336/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 336/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 336/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 336/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 336/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 336/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 336/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 336/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 336/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 336/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 336/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 336/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 336/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001455, MRE: 1.691132 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.947706 \n",
      "\n",
      "Epoch 337/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 337/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 337/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 337/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 337/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 337/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 337/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 337/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 337/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 337/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 337/800, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 337/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 337/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001463, MRE: 1.682687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.945994 \n",
      "\n",
      "Epoch 338/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 338/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 338/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 338/800, Iteration 4/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 338/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 338/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 338/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 338/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 338/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 338/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 338/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 338/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001459, MRE: 1.718475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.949156 \n",
      "\n",
      "Epoch 339/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 339/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 339/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 339/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 339/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 339/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 339/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 339/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 339/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 339/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.704678 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.950633 \n",
      "\n",
      "Epoch 340/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 340/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 340/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 340/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 340/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 340/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 340/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 340/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 340/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.714599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.938619 \n",
      "\n",
      "Epoch 341/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 341/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 341/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 341/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 341/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 341/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 341/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 341/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 341/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001470, MRE: 1.680073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.933546 \n",
      "\n",
      "Epoch 342/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 342/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 342/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 342/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 342/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 342/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 342/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 342/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 342/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 342/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 342/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 342/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 342/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001443, MRE: 1.688450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.933414 \n",
      "\n",
      "Epoch 343/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 343/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 343/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 343/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 343/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 343/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 343/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 343/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 343/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 343/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001430, MRE: 1.731624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.932864 \n",
      "\n",
      "Epoch 344/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 344/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 344/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 344/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 344/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 344/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 344/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 344/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 344/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 344/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 344/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 344/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 344/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001428, MRE: 1.712142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.926662 \n",
      "\n",
      "Epoch 345/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 345/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 345/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 345/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 345/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 345/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 345/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 345/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 345/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 345/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 345/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 345/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 345/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001449, MRE: 1.746329 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.931364 \n",
      "\n",
      "Epoch 346/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 346/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 346/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 346/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 346/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 346/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 346/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 346/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 346/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 346/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 346/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 346/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 346/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001462, MRE: 1.742081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.931756 \n",
      "\n",
      "Epoch 347/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 347/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 347/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 347/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 347/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 347/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001424, MRE: 1.697240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.931579 \n",
      "\n",
      "Epoch 348/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 348/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 348/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 348/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 348/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 348/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 348/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 348/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 348/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 348/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 348/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 348/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 348/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001452, MRE: 1.737490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.932240 \n",
      "\n",
      "Epoch 349/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 349/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 349/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 349/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 349/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 349/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 349/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 349/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 349/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 349/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 349/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 349/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 349/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001452, MRE: 1.689562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.933334 \n",
      "\n",
      "Epoch 350/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 350/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 350/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 350/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 350/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 350/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 350/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 350/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 350/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 350/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 350/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 350/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 350/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001439, MRE: 1.680863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.924433 \n",
      "\n",
      "Epoch 351/800, Iteration 1/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 351/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 351/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 351/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 351/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 351/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 351/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 351/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 351/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 351/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 351/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 351/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.719352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.936156 \n",
      "\n",
      "Epoch 352/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 352/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 352/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 352/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 352/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 352/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 352/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 352/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 352/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 352/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 352/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 352/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 352/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001470, MRE: 2.003591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.939242 \n",
      "\n",
      "Epoch 353/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 353/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 353/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 353/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 353/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 353/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 353/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 353/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 353/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 353/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 353/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 353/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001450, MRE: 1.688979 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.950121 \n",
      "\n",
      "Epoch 354/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 354/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 354/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 354/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 354/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 354/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 354/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 354/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 354/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 354/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 354/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001442, MRE: 2.013750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.958633 \n",
      "\n",
      "Epoch 355/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 355/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 355/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 355/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 355/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 355/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 355/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 355/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 355/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 355/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 355/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 355/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 355/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001426, MRE: 1.720805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.952055 \n",
      "\n",
      "Epoch 356/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 356/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 356/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 356/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 356/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 356/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 356/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 356/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 356/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 356/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 356/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 356/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 356/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001442, MRE: 1.670468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.951664 \n",
      "\n",
      "Epoch 357/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 357/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 357/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 357/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 357/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 357/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 357/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 357/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 357/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001438, MRE: 1.684936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.950933 \n",
      "\n",
      "Epoch 358/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 358/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 358/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 358/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 358/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 358/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 358/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 358/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001464, MRE: 1.689476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.945438 \n",
      "\n",
      "Epoch 359/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 359/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 359/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 359/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 359/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 359/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 359/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 359/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 359/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 359/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 359/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 359/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 359/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 1.718940 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.948352 \n",
      "\n",
      "Epoch 360/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 360/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 360/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 360/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 360/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 360/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 360/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 360/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 360/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 360/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 360/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 360/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 360/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001444, MRE: 1.724965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.958796 \n",
      "\n",
      "Epoch 361/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 361/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 361/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 361/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 361/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 361/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 361/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 361/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 361/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 361/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 361/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 361/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 361/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001428, MRE: 1.676143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.962576 \n",
      "\n",
      "Epoch 362/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 362/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 362/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 362/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 362/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 362/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 362/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 362/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 362/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 362/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 362/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 362/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 362/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001441, MRE: 1.841195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001442, MRE: 3.966816 \n",
      "\n",
      "Epoch 363/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 363/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 363/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 363/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 363/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 363/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 363/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 363/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 363/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 363/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 363/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 363/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 363/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001457, MRE: 1.745244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.959149 \n",
      "\n",
      "Epoch 364/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 364/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 364/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 364/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 364/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 364/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 364/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 364/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 364/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 364/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 364/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 364/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 364/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001431, MRE: 1.689396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.952848 \n",
      "\n",
      "Epoch 365/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 365/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 365/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 365/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 365/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 365/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 365/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 365/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 365/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 365/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 365/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 365/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 365/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.683527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.954401 \n",
      "\n",
      "Epoch 366/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 366/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 366/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 366/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 366/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 366/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 366/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 366/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 366/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 366/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001451, MRE: 1.707105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.951408 \n",
      "\n",
      "Epoch 367/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 367/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 367/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 367/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 367/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 367/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 367/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 367/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 367/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 367/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 367/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 367/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 367/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001455, MRE: 1.681573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.951652 \n",
      "\n",
      "Epoch 368/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 368/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 368/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 368/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 368/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 368/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001430, MRE: 1.679593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.947870 \n",
      "\n",
      "Epoch 369/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 369/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 369/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 369/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 369/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 369/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 369/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 369/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 369/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 369/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 369/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 369/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 369/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.700472 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.947951 \n",
      "\n",
      "Epoch 370/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 370/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 370/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 370/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 370/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 370/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 370/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 370/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 370/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 370/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 370/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 370/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 370/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001457, MRE: 1.704931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.942224 \n",
      "\n",
      "Epoch 371/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 371/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 371/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 371/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 371/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 371/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 371/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 371/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 371/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 371/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 371/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 371/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 371/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001442, MRE: 1.706263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001441, MRE: 3.951630 \n",
      "\n",
      "Epoch 372/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 372/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 372/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 372/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 372/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 372/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 372/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 372/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 372/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 372/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 372/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 372/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 372/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001450, MRE: 1.683384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.946894 \n",
      "\n",
      "Epoch 373/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 373/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 373/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 373/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 373/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 373/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 373/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 373/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 373/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 373/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 373/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 373/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 373/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001458, MRE: 1.724488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.943307 \n",
      "\n",
      "Epoch 374/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 374/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 374/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 374/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 374/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 374/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 374/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 374/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 374/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 374/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 374/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 374/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 374/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001447, MRE: 1.687644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.943228 \n",
      "\n",
      "Epoch 375/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 375/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 375/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 375/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 375/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 375/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 375/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 375/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 375/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 375/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 375/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 375/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 375/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001449, MRE: 1.696265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.943942 \n",
      "\n",
      "Epoch 376/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 376/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 376/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 376/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 376/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 376/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 376/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 376/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 376/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 376/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 376/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 376/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 376/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001437, MRE: 1.677549 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.940456 \n",
      "\n",
      "Epoch 377/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 377/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 377/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 377/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 377/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 377/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 377/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 377/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 377/800, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 377/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 377/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 377/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001443, MRE: 1.679926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.942335 \n",
      "\n",
      "Epoch 378/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 378/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 378/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 378/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 378/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 378/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 378/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 378/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 378/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 378/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 378/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 378/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 378/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001420, MRE: 1.692701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.936392 \n",
      "\n",
      "Epoch 379/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 379/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 379/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 379/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 379/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 379/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 379/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 379/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 379/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.724045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001440, MRE: 3.943730 \n",
      "\n",
      "Epoch 380/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 380/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 380/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 380/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 380/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 380/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 380/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 380/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 380/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 380/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 380/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 380/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 380/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001420, MRE: 1.717950 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.936120 \n",
      "\n",
      "Epoch 381/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 381/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 381/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 381/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 381/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 381/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 381/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 381/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 381/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 381/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 381/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 381/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 381/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001469, MRE: 1.678521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.930005 \n",
      "\n",
      "Epoch 382/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 382/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 382/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 382/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 382/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 382/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 382/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 382/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 382/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 382/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 382/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 382/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 382/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001449, MRE: 1.679079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.934146 \n",
      "\n",
      "Epoch 383/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 383/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 383/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 383/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 383/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 383/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 383/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 383/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 383/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 383/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 383/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001460, MRE: 1.727171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.932440 \n",
      "\n",
      "Epoch 384/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 384/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 384/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 384/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 384/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 384/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 384/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 384/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 384/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001464, MRE: 1.747991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.932976 \n",
      "\n",
      "Epoch 385/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 385/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 385/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 385/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 385/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 385/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 385/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 385/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 385/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 385/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 385/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 385/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 385/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001426, MRE: 1.997189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.924884 \n",
      "\n",
      "Epoch 386/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 386/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 386/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 386/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 386/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 386/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 386/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 386/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 386/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 386/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 386/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 386/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 386/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001430, MRE: 1.672091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.922339 \n",
      "\n",
      "Epoch 387/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 387/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 387/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 387/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 387/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 387/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 387/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 387/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 387/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 387/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 387/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 387/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 387/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001443, MRE: 1.687280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.929094 \n",
      "\n",
      "Epoch 388/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 388/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 388/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 388/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 388/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 388/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 388/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 388/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 388/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 388/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 388/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 388/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 388/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001442, MRE: 1.684798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.925234 \n",
      "\n",
      "Epoch 389/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 389/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 389/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 389/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 389/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 389/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 389/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 389/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 389/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 389/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 389/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 389/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 389/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001448, MRE: 1.676765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.928067 \n",
      "\n",
      "Epoch 390/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 390/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 390/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 390/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 390/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 390/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 390/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 390/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 390/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 390/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 390/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 390/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001453, MRE: 1.685470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.924893 \n",
      "\n",
      "Epoch 391/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 391/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 391/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 391/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 391/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 391/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 391/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 391/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 391/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 391/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001436, MRE: 1.762541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.927267 \n",
      "\n",
      "Epoch 392/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 392/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 392/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 392/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 392/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 392/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 392/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 392/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 392/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 392/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001439, MRE: 1.684317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.927468 \n",
      "\n",
      "Epoch 393/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 393/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 393/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 393/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 393/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 393/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 393/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 393/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 393/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 393/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 393/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 393/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 393/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001462, MRE: 1.857305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.921407 \n",
      "\n",
      "Epoch 394/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 394/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 394/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 394/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 394/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 394/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 394/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 394/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 394/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 394/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 394/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 394/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001439, MRE: 1.685175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.922442 \n",
      "\n",
      "Epoch 395/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 395/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 395/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 395/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 395/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 395/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 395/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 395/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 395/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 395/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 395/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 395/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 395/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001436, MRE: 1.709970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.916990 \n",
      "\n",
      "Epoch 396/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 396/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 396/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 396/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 396/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 396/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 396/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 396/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 396/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001473, MRE: 1.674534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.921863 \n",
      "\n",
      "Epoch 397/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 397/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 397/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 397/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 397/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 397/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 397/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 397/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 397/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 397/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 397/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 397/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 397/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001443, MRE: 1.713129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.920039 \n",
      "\n",
      "Epoch 398/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 398/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 398/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 398/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 398/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 398/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 398/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 398/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 398/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 398/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 398/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 398/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 398/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001463, MRE: 1.750451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.916453 \n",
      "\n",
      "Epoch 399/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 399/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 399/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 399/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 399/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 399/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 399/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 399/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 399/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 399/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 399/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 399/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 399/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001445, MRE: 1.684082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.921557 \n",
      "\n",
      "Epoch 400/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 400/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 400/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 400/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 400/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 400/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 400/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 400/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 400/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001454, MRE: 1.886289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.913044 \n",
      "\n",
      "Epoch 401/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 401/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 401/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 401/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 401/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 401/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 401/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 401/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 401/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 401/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 401/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 401/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 401/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001459, MRE: 1.687709 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.910775 \n",
      "\n",
      "Epoch 402/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 402/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 402/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 402/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 402/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 402/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 402/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 402/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 402/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 402/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 402/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 402/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 402/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001445, MRE: 1.678711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.907627 \n",
      "\n",
      "Epoch 403/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 403/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 403/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 403/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 403/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 403/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 403/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 403/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 403/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001443, MRE: 1.725150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.914275 \n",
      "\n",
      "Epoch 404/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 404/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 404/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 404/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 404/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 404/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 404/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 404/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 404/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 404/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 404/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 404/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 404/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001423, MRE: 1.727219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.914394 \n",
      "\n",
      "Epoch 405/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 405/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 405/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 405/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 405/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 405/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 405/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 405/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 405/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 405/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 405/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 405/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 405/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001471, MRE: 1.681321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.923008 \n",
      "\n",
      "Epoch 406/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 406/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 406/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 406/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 406/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 406/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 406/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 406/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 406/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 406/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001451, MRE: 1.678351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.928999 \n",
      "\n",
      "Epoch 407/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 407/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 407/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 407/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 407/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 407/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 407/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 407/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001453, MRE: 1.683341 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.931994 \n",
      "\n",
      "Epoch 408/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 408/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 408/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 408/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 408/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 408/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 408/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 408/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 408/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 408/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 408/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001425, MRE: 1.743148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.931917 \n",
      "\n",
      "Epoch 409/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 409/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 409/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 409/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 409/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 409/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 409/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 409/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 409/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 409/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 409/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 409/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 409/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001427, MRE: 1.679978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.939733 \n",
      "\n",
      "Epoch 410/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 410/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 410/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 410/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 410/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 410/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 410/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 410/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 410/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 410/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 410/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 410/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001446, MRE: 1.693314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.937281 \n",
      "\n",
      "Epoch 411/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 411/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 411/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 411/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 411/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 411/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 411/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 411/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 411/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 411/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 411/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 411/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 411/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001434, MRE: 1.676648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.948611 \n",
      "\n",
      "Epoch 412/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 412/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 412/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 412/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 412/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 412/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 412/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 412/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 412/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 412/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 412/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 412/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 412/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001434, MRE: 1.710672 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.949436 \n",
      "\n",
      "Epoch 413/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 413/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 413/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 413/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 413/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 413/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 413/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 413/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 413/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 413/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001442, MRE: 1.671151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.939236 \n",
      "\n",
      "Epoch 414/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 414/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 414/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 414/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 414/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 414/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 414/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 414/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001449, MRE: 1.759768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.939724 \n",
      "\n",
      "Epoch 415/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 415/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 415/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 415/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 415/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 415/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 415/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 415/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 415/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 415/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 415/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 415/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 415/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001451, MRE: 1.681466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.934098 \n",
      "\n",
      "Epoch 416/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 416/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 416/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 416/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 416/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 416/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 416/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 416/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001448, MRE: 1.704996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.930348 \n",
      "\n",
      "Epoch 417/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 417/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 417/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 417/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 417/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 417/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 417/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 417/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 417/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 417/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 417/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 417/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 417/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001455, MRE: 1.704200 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.927549 \n",
      "\n",
      "Epoch 418/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 418/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 418/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 418/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 418/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 418/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 418/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 418/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 418/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 418/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001487, MRE: 1.674521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.923489 \n",
      "\n",
      "Epoch 419/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 419/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 419/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 419/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 419/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 419/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 419/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 419/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 419/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 419/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 419/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 419/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 419/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001453, MRE: 1.680812 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.924310 \n",
      "\n",
      "Epoch 420/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 420/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 420/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 420/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 420/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 420/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 420/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 420/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 420/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 420/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 420/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 420/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 420/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001436, MRE: 1.671371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.924014 \n",
      "\n",
      "Epoch 421/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 421/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 421/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 421/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 421/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 421/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 421/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 421/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 421/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 421/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 421/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 421/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001452, MRE: 1.673750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.923236 \n",
      "\n",
      "Epoch 422/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 422/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 422/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 422/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 422/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 422/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 422/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 422/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 422/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 422/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001466, MRE: 1.898611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.926748 \n",
      "\n",
      "Epoch 423/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 423/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 423/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 423/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 423/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 423/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 423/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 423/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 423/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001455, MRE: 1.691046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.920275 \n",
      "\n",
      "Epoch 424/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 424/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 424/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 424/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 424/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 424/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 424/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 424/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 424/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 424/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 424/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 424/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 424/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001430, MRE: 1.728275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.927680 \n",
      "\n",
      "Epoch 425/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 425/800, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 425/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 425/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 425/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 425/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 425/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001454, MRE: 1.679235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.921845 \n",
      "\n",
      "Epoch 426/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 426/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 426/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 426/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 426/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 426/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 426/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 426/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 426/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 426/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001443, MRE: 1.727069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.934494 \n",
      "\n",
      "Epoch 427/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 427/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 427/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 427/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 427/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 427/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 427/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 427/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 427/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 427/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 427/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 427/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 427/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001455, MRE: 1.683327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.939587 \n",
      "\n",
      "Epoch 428/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 428/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 428/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 428/800, Iteration 6/12, Loss: 0.0007\n",
      "Epoch 428/800, Iteration 7/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 428/800, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 428/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 428/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 428/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001425, MRE: 1.673869 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.938672 \n",
      "\n",
      "Epoch 429/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 429/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 429/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 429/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 429/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 429/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 429/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 429/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 429/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 429/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 429/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 429/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001435, MRE: 1.680982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.940688 \n",
      "\n",
      "Epoch 430/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 430/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 430/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 430/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 430/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 430/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 430/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 430/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 430/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 430/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 430/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 430/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 430/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001419, MRE: 1.718507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.931536 \n",
      "\n",
      "Epoch 431/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 431/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 431/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 431/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 431/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 431/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 431/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 431/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 431/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 431/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 431/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 431/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 431/800, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001444, MRE: 1.705481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.938258 \n",
      "\n",
      "Epoch 432/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 432/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 432/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 432/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 432/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 432/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 432/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 432/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 432/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 432/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 432/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 432/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 432/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.685007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.934315 \n",
      "\n",
      "Epoch 433/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 433/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 433/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 433/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 433/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 433/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 433/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 433/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 433/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 433/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 433/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001426, MRE: 1.834999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.930148 \n",
      "\n",
      "Epoch 434/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 434/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 434/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 434/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 434/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 434/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 434/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 434/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 434/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001452, MRE: 1.687002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.935327 \n",
      "\n",
      "Epoch 435/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 435/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 435/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 435/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 435/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 435/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 435/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 435/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 435/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 435/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 435/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 435/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 435/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001463, MRE: 1.732740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.936180 \n",
      "\n",
      "Epoch 436/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 436/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 436/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 436/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 436/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 436/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 436/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 436/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 436/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 436/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001470, MRE: 1.675070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.944925 \n",
      "\n",
      "Epoch 437/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 437/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 437/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 437/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 437/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 437/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 437/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 437/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 437/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 437/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 437/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 437/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 437/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001455, MRE: 1.701197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.938194 \n",
      "\n",
      "Epoch 438/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 438/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 438/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 438/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 438/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 438/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 438/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 438/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 438/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 438/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 438/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 438/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 438/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.683037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.929687 \n",
      "\n",
      "Epoch 439/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 439/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 439/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 439/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 439/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 439/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 439/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 439/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 439/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 439/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 439/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 439/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 439/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001466, MRE: 2.005002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.931035 \n",
      "\n",
      "Epoch 440/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 440/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 440/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 440/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 440/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 440/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 440/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 440/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 440/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 440/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 440/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 440/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 440/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001437, MRE: 1.688700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.935768 \n",
      "\n",
      "Epoch 441/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 441/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 441/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 441/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 441/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 441/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 441/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 441/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 441/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 441/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001448, MRE: 1.680513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.934721 \n",
      "\n",
      "Epoch 442/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 442/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 442/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 442/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 442/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 442/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 442/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 442/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 442/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 442/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 442/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 442/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 442/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001432, MRE: 1.715338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.925794 \n",
      "\n",
      "Epoch 443/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 443/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 443/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 443/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 443/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 443/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 443/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 443/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 443/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 443/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 443/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 443/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 443/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001467, MRE: 1.710221 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.921083 \n",
      "\n",
      "Epoch 444/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 444/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 444/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 444/800, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 444/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 444/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 444/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 444/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 444/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 444/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 444/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 444/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 444/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001474, MRE: 1.695937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.926242 \n",
      "\n",
      "Epoch 445/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 445/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 445/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 445/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 445/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 445/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 445/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 445/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 445/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 445/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 445/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 445/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 445/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001435, MRE: 1.680913 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.928611 \n",
      "\n",
      "Epoch 446/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 446/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 446/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 446/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 446/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 446/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 446/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 446/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 446/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 446/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 446/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 446/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 446/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001458, MRE: 1.748146 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.925608 \n",
      "\n",
      "Epoch 447/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 447/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 447/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 447/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 447/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 447/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 447/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 447/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001426, MRE: 1.666568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.933623 \n",
      "\n",
      "Epoch 448/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 448/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 448/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 448/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 448/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 448/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 448/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 448/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 448/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 448/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 448/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 448/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001452, MRE: 1.684104 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.931185 \n",
      "\n",
      "Epoch 449/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 449/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 449/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 449/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 449/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 449/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 449/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 449/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 449/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 449/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 449/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 449/800, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 449/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001450, MRE: 1.991439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.935027 \n",
      "\n",
      "Epoch 450/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 450/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 450/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 450/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 450/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 450/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 450/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 450/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 450/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 450/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 450/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 450/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 450/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001441, MRE: 1.814588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.946809 \n",
      "\n",
      "Epoch 451/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 451/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 451/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 451/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 451/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 451/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 451/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 451/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 451/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 451/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 451/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 451/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 451/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001450, MRE: 1.680438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.955817 \n",
      "\n",
      "Epoch 452/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 452/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 452/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 452/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 452/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 452/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 452/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 452/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 452/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 452/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 452/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 452/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 452/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001470, MRE: 1.683518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.953906 \n",
      "\n",
      "Epoch 453/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 453/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 453/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 453/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 453/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 453/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 453/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 453/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 453/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 453/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 453/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 453/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 453/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001449, MRE: 1.685383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.951632 \n",
      "\n",
      "Epoch 454/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 454/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 454/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 454/800, Iteration 4/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 454/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 454/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 454/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001451, MRE: 1.686316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.951150 \n",
      "\n",
      "Epoch 455/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 455/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 455/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 455/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 455/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 455/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 455/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 455/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 455/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 455/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 455/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 455/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 455/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001427, MRE: 1.715548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001439, MRE: 3.956085 \n",
      "\n",
      "Epoch 456/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 456/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 456/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 456/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 456/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 456/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 456/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 456/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 456/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 456/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 456/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 456/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 456/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001446, MRE: 1.739970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.949611 \n",
      "\n",
      "Epoch 457/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 457/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 457/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 457/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 457/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 457/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 457/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 457/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 457/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 457/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001434, MRE: 1.872686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.954532 \n",
      "\n",
      "Epoch 458/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 458/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 458/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 458/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 458/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 458/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 458/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 458/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 458/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 458/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 458/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 458/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 458/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001438, MRE: 1.673313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.953112 \n",
      "\n",
      "Epoch 459/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 459/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 459/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 459/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 459/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 459/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 459/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 459/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 459/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 459/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 459/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 459/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 459/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001444, MRE: 1.688408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.947738 \n",
      "\n",
      "Epoch 460/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 460/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 460/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 460/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 460/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 460/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 460/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 460/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 460/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 460/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001441, MRE: 1.885544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.943158 \n",
      "\n",
      "Epoch 461/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 461/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 461/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 461/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 461/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 461/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 461/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 461/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 461/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 461/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 461/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 461/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 461/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001436, MRE: 1.720984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.944951 \n",
      "\n",
      "Epoch 462/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 462/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 462/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 462/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 462/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 462/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 462/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 462/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 462/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 462/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 462/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 462/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 462/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001456, MRE: 1.682970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.947223 \n",
      "\n",
      "Epoch 463/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 463/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 463/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 463/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 463/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 463/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 463/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 463/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 463/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001438, MRE: 1.682056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.949338 \n",
      "\n",
      "Epoch 464/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 464/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 464/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 464/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 464/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 464/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 464/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 464/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 464/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 464/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 464/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 464/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 464/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001428, MRE: 1.672619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.950314 \n",
      "\n",
      "Epoch 465/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 465/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 465/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 465/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 465/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 465/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 465/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 465/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 465/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 465/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 465/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 465/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 465/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001457, MRE: 1.666237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.950888 \n",
      "\n",
      "Epoch 466/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 466/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 466/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 466/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 466/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 466/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 466/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 466/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 466/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 466/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 466/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 466/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 466/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001433, MRE: 1.674316 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.948048 \n",
      "\n",
      "Epoch 467/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 467/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 467/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 467/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 467/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 467/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 467/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 467/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 467/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 467/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 467/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 467/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 467/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001434, MRE: 1.687287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.948805 \n",
      "\n",
      "Epoch 468/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 468/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 468/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 468/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 468/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 468/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 468/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 468/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 468/800, Iteration 13/12, Loss: 0.0005\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001436, MRE: 1.678600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.949070 \n",
      "\n",
      "Epoch 469/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 469/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 469/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 469/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 469/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 469/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 469/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 469/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 469/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 469/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 1.677137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.949013 \n",
      "\n",
      "Epoch 470/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 470/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 470/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 470/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 470/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 470/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 470/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 470/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 470/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 470/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 470/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001458, MRE: 1.689732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001438, MRE: 3.946802 \n",
      "\n",
      "Epoch 471/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 471/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 471/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 471/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 471/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 471/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 471/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 471/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 471/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 471/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 471/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 471/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 471/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.692060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.943527 \n",
      "\n",
      "Epoch 472/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 472/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 472/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 472/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 472/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 472/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 472/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 472/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 472/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 472/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 472/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 472/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 472/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001444, MRE: 2.009467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.942700 \n",
      "\n",
      "Epoch 473/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 473/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 473/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 473/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 473/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 473/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 473/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 473/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 473/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 473/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 473/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 473/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 473/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001433, MRE: 1.679866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.936765 \n",
      "\n",
      "Epoch 474/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 474/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 474/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 474/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 474/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 474/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 474/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 474/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 474/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001440, MRE: 1.685984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.933562 \n",
      "\n",
      "Epoch 475/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 475/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 475/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 475/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 475/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 475/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 475/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 475/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 475/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 475/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 475/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 475/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 475/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001438, MRE: 1.743171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.935476 \n",
      "\n",
      "Epoch 476/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 476/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 476/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 476/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 476/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 476/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 476/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 476/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 476/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 476/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 476/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 476/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 476/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001467, MRE: 2.002129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.940496 \n",
      "\n",
      "Epoch 477/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 477/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 477/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 477/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 477/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 477/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 477/800, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 477/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 477/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 477/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 477/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 477/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 477/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.740457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.939840 \n",
      "\n",
      "Epoch 478/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 478/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 478/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 478/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 478/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 478/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 478/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 478/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 478/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 478/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 478/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 478/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 478/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001434, MRE: 1.819462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.940141 \n",
      "\n",
      "Epoch 479/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 479/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 479/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 479/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 479/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 479/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 479/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 479/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 479/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 479/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 479/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001428, MRE: 1.684828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.941900 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 480/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 480/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 480/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 480/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 480/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 480/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 480/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 480/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 480/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001435, MRE: 1.682710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.944431 \n",
      "\n",
      "Epoch 481/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 481/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 481/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 481/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 481/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 481/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 481/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 481/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 481/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 481/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 481/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 481/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001450, MRE: 1.666522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.947378 \n",
      "\n",
      "Epoch 482/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 482/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 482/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 482/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 482/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 482/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 482/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 482/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 482/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 482/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 482/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 482/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 482/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001439, MRE: 1.698029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.944555 \n",
      "\n",
      "Epoch 483/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 483/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 483/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 483/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 483/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 483/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 483/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 483/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 483/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 483/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 483/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001446, MRE: 1.852734 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.941149 \n",
      "\n",
      "Epoch 484/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 484/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 484/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 484/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 484/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 484/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 484/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 484/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 484/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 484/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 484/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 484/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 484/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001463, MRE: 1.721786 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.937970 \n",
      "\n",
      "Epoch 485/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 485/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 485/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 485/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 485/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 485/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 485/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 485/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 485/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 485/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 485/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 485/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 485/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001470, MRE: 1.681502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.934329 \n",
      "\n",
      "Epoch 486/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 486/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 486/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 486/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 486/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 486/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 486/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 486/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 486/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 486/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001454, MRE: 1.677111 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.934534 \n",
      "\n",
      "Epoch 487/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 487/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 487/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 487/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 487/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 487/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 487/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 487/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 487/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 487/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 487/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 487/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 487/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001433, MRE: 1.675157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.921693 \n",
      "\n",
      "Epoch 488/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 488/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 488/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 488/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 488/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 488/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 488/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 488/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 488/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 488/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 488/800, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001457, MRE: 1.895118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.931540 \n",
      "\n",
      "Epoch 489/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 489/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 489/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 489/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 489/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 489/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 489/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 489/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 489/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001440, MRE: 1.721874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.926838 \n",
      "\n",
      "Epoch 490/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 490/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 490/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 490/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 490/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 490/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 490/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 490/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 490/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 490/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 490/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 490/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 490/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001474, MRE: 1.721521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.926457 \n",
      "\n",
      "Epoch 491/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 491/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 491/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 491/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 491/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 491/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 491/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 491/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 491/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 491/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 491/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 491/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001451, MRE: 1.704919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.929837 \n",
      "\n",
      "Epoch 492/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 492/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 492/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 492/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 492/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 492/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 492/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 492/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 492/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 492/800, Iteration 13/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001451, MRE: 1.677425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.935397 \n",
      "\n",
      "Epoch 493/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 493/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 493/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 493/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 493/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 493/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 493/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 493/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 493/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 493/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 493/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 493/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 493/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001447, MRE: 1.714926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.944127 \n",
      "\n",
      "Epoch 494/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 494/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 494/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 494/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 494/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 494/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 494/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 494/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 494/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001440, MRE: 1.724714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.936728 \n",
      "\n",
      "Epoch 495/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 495/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 495/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 495/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 495/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 495/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 495/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 495/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 495/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 495/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 495/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 495/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 495/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001452, MRE: 1.714426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.943229 \n",
      "\n",
      "Epoch 496/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 496/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 496/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 496/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 496/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 496/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 496/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 496/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 496/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001469, MRE: 1.690324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.939573 \n",
      "\n",
      "Epoch 497/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 497/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 497/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 497/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 497/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 497/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 497/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 497/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 497/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 497/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 497/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 497/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 497/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001442, MRE: 1.780509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.929885 \n",
      "\n",
      "Epoch 498/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 498/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 498/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 498/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 498/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 498/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 498/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 498/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 498/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 498/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001433, MRE: 1.691817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.942703 \n",
      "\n",
      "Epoch 499/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 499/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 499/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 499/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 499/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 499/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 499/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 499/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 499/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 499/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 499/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 499/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 499/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001474, MRE: 1.685526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.949633 \n",
      "\n",
      "Epoch 500/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 500/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 500/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 500/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 500/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 500/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 500/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 500/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 500/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 500/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 500/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 500/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 500/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001442, MRE: 1.718927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.937670 \n",
      "\n",
      "Epoch 501/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 501/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 501/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 501/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 501/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 501/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 501/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 501/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 501/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 501/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 501/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 501/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 501/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001438, MRE: 1.664955 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.936917 \n",
      "\n",
      "Epoch 502/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 502/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 502/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 502/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 502/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 502/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 502/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 502/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 502/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 502/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 502/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 502/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 502/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001454, MRE: 1.671278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.942313 \n",
      "\n",
      "Epoch 503/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 503/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 503/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 503/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 503/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 503/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 503/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 503/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 503/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 503/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 503/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 503/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 503/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001452, MRE: 1.709324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.935511 \n",
      "\n",
      "Epoch 504/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 504/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 504/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 504/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 504/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 504/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 504/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 504/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 504/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 504/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 504/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 504/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 504/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001466, MRE: 1.693840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.927700 \n",
      "\n",
      "Epoch 505/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 505/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 505/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 505/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 505/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 505/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 505/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 505/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 505/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 505/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 505/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001436, MRE: 1.676889 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.931236 \n",
      "\n",
      "Epoch 506/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 506/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 506/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 506/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 506/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 506/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 506/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 506/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 506/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 506/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 506/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 506/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 506/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001425, MRE: 1.685653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.932855 \n",
      "\n",
      "Epoch 507/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 507/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 507/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 507/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 507/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 507/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 507/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 507/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 507/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 507/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 507/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 507/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 507/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001436, MRE: 1.691480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.932514 \n",
      "\n",
      "Epoch 508/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 508/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 508/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 508/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 508/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 508/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 508/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 508/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 508/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 508/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 508/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 508/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 508/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001459, MRE: 1.684170 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.936776 \n",
      "\n",
      "Epoch 509/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 509/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 509/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 509/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 509/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 509/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 509/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 509/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 509/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 509/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 509/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 509/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 509/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001434, MRE: 1.676518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.937318 \n",
      "\n",
      "Epoch 510/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 510/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 510/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 510/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 510/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 510/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 510/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 510/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 510/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 510/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001445, MRE: 1.676314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.938395 \n",
      "\n",
      "Epoch 511/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 511/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 511/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 511/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 511/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 511/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 511/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 511/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 511/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 511/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 511/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001443, MRE: 1.667808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.929555 \n",
      "\n",
      "Epoch 512/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 512/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 512/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 512/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 512/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 512/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 512/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001421, MRE: 1.843394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.934756 \n",
      "\n",
      "Epoch 513/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 513/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 513/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 513/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 513/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 513/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 513/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 513/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 513/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 513/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 513/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 513/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 513/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001457, MRE: 1.683880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.927839 \n",
      "\n",
      "Epoch 514/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 514/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 514/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 514/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 514/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 514/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 514/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 514/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 514/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 514/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 514/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 514/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001425, MRE: 1.807722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.928129 \n",
      "\n",
      "Epoch 515/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 515/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 515/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 515/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 515/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 515/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 515/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 515/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 515/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 515/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 515/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001440, MRE: 1.697135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.927114 \n",
      "\n",
      "Epoch 516/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 516/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 516/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 516/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 516/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 516/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 516/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 516/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 516/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 516/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 516/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 516/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 516/800, Iteration 13/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001448, MRE: 1.678346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.932836 \n",
      "\n",
      "Epoch 517/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 517/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 517/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 517/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 517/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 517/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 517/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 517/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 517/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 517/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 517/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 517/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 517/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001463, MRE: 1.690003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.928784 \n",
      "\n",
      "Epoch 518/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 518/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 518/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 518/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 518/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 518/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 518/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 518/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 518/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 518/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 518/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 518/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 518/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001445, MRE: 1.685302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.935350 \n",
      "\n",
      "Epoch 519/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 519/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 519/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 519/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 519/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 519/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 519/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 519/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 519/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001437, MRE: 1.682115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.926764 \n",
      "\n",
      "Epoch 520/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 520/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 520/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 520/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 520/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 520/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 520/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 520/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001439, MRE: 1.682414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.931074 \n",
      "\n",
      "Epoch 521/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 521/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 521/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 521/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 521/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 521/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 521/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 521/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 521/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 521/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 521/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 521/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 521/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001461, MRE: 1.727833 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.928578 \n",
      "\n",
      "Epoch 522/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 522/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 522/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 522/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 522/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 522/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 522/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 522/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 522/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 522/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 522/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 522/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 522/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001439, MRE: 1.720653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.930571 \n",
      "\n",
      "Epoch 523/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 523/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 523/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 523/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 523/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 523/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 523/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 523/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 523/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 523/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 523/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 523/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 523/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001441, MRE: 1.670942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.935906 \n",
      "\n",
      "Epoch 524/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 524/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 524/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 524/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 524/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 524/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 524/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 524/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 524/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 524/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 524/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 524/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 524/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001454, MRE: 1.910891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.938566 \n",
      "\n",
      "Epoch 525/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 525/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 525/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 525/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 525/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 525/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 525/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 525/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 525/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 525/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 525/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 525/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 525/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001431, MRE: 1.684619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.937525 \n",
      "\n",
      "Epoch 526/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 526/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 526/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 526/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 526/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 526/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 526/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 526/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 526/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 526/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 526/800, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 526/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 526/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001430, MRE: 1.676243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.934752 \n",
      "\n",
      "Epoch 527/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 527/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 527/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 527/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 527/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 527/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 527/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 527/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 527/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 527/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 527/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 527/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 527/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001440, MRE: 1.678758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.930801 \n",
      "\n",
      "Epoch 528/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 528/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 528/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 528/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 528/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 528/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 528/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 528/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 528/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 528/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 528/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 528/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 528/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001468, MRE: 1.678197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.925674 \n",
      "\n",
      "Epoch 529/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 529/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 529/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 529/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 529/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 529/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 529/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 529/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 529/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 529/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 529/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 529/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 529/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001466, MRE: 1.695484 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.926850 \n",
      "\n",
      "Epoch 530/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 530/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 530/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 530/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 530/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 530/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 530/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 530/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 530/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 530/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 530/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 530/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 530/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001425, MRE: 1.691330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.920744 \n",
      "\n",
      "Epoch 531/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 531/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 531/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 531/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 531/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 531/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 531/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 531/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 531/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 531/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 531/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 531/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 531/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001427, MRE: 1.669102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.922698 \n",
      "\n",
      "Epoch 532/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 532/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 532/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 532/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 532/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 532/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 532/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 532/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 532/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 532/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001446, MRE: 1.994752 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.929607 \n",
      "\n",
      "Epoch 533/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 533/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 533/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 533/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 533/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 533/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 533/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 533/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 533/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 533/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 533/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 533/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 533/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.674640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.928648 \n",
      "\n",
      "Epoch 534/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 534/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 534/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 534/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 534/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 534/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 534/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 534/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 534/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 534/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 534/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001445, MRE: 1.697376 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.932061 \n",
      "\n",
      "Epoch 535/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 535/800, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 535/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 535/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 535/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 535/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 535/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 535/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 535/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 535/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 535/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 535/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 535/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001458, MRE: 1.700767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.930480 \n",
      "\n",
      "Epoch 536/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 536/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 536/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 536/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 536/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 536/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 536/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 536/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 536/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 536/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 536/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 536/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 536/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001453, MRE: 1.676190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.933410 \n",
      "\n",
      "Epoch 537/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 537/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 537/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 537/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 537/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 537/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 537/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 537/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 537/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 537/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001473, MRE: 2.026312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.934479 \n",
      "\n",
      "Epoch 538/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 538/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 538/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 538/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 538/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 538/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 538/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 538/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 538/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 538/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 538/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 538/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 538/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001454, MRE: 1.668847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.938977 \n",
      "\n",
      "Epoch 539/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 539/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 539/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 539/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 539/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 539/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 539/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 539/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 539/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 539/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 539/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001435, MRE: 1.678697 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.934266 \n",
      "\n",
      "Epoch 540/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 540/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 540/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 540/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 540/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 540/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 540/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 540/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001434, MRE: 1.672143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.940042 \n",
      "\n",
      "Epoch 541/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 541/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 541/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 541/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 541/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 541/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 541/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 541/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 541/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 541/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 541/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 541/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 541/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001463, MRE: 1.900203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.931934 \n",
      "\n",
      "Epoch 542/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 542/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 542/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 542/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 542/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 542/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 542/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 542/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 542/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 542/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 542/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 542/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 542/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001443, MRE: 1.686027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.940853 \n",
      "\n",
      "Epoch 543/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 543/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 543/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 543/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 543/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 543/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 543/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 543/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 543/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 543/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 543/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 543/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 543/800, Iteration 13/12, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001432, MRE: 1.672532 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.946978 \n",
      "\n",
      "Epoch 544/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 544/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 544/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 544/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 544/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 544/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 544/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 544/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 544/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 544/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 544/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 544/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 544/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001454, MRE: 1.717365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.941422 \n",
      "\n",
      "Epoch 545/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 545/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 545/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 545/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 545/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 545/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 545/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001459, MRE: 1.672509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.945481 \n",
      "\n",
      "Epoch 546/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 546/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 546/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 546/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 546/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 546/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 546/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 546/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 546/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 546/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 546/800, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 546/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 546/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.667935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.942053 \n",
      "\n",
      "Epoch 547/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 547/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 547/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 547/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 547/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 547/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 547/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 547/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 547/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 547/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 547/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 547/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 547/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001458, MRE: 1.677164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.939338 \n",
      "\n",
      "Epoch 548/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 548/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 548/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 548/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 548/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 548/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 548/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 548/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 548/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 548/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 548/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 548/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 548/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001448, MRE: 1.675231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.929874 \n",
      "\n",
      "Epoch 549/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 549/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 549/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 549/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 549/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 549/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 549/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 549/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 549/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 549/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 549/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 549/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 549/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001447, MRE: 1.683926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.927385 \n",
      "\n",
      "Epoch 550/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 550/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 550/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 550/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 550/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 550/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 550/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 550/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 550/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 550/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 550/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 550/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 550/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001430, MRE: 1.679958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.928264 \n",
      "\n",
      "Epoch 551/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 551/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 551/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 551/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 551/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 551/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 551/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 551/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 551/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 551/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 551/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 551/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 551/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001453, MRE: 1.684877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.938129 \n",
      "\n",
      "Epoch 552/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 552/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 552/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 552/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 552/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 552/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 552/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 552/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 552/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 552/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 552/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 552/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 552/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001431, MRE: 1.676468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.935698 \n",
      "\n",
      "Epoch 553/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 553/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 553/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 553/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 553/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 553/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 553/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 553/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 553/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 553/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 553/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 553/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 553/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001419, MRE: 1.674263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.939577 \n",
      "\n",
      "Epoch 554/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 554/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 554/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 554/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 554/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 554/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 554/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 554/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 554/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 554/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001445, MRE: 1.706651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.948879 \n",
      "\n",
      "Epoch 555/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 555/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 555/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 555/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 555/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 555/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 555/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 555/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 555/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 555/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 555/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 555/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 555/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001443, MRE: 1.725030 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.955160 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 556/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 556/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 556/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 556/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 556/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 556/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 556/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 556/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 556/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 556/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 556/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 556/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001442, MRE: 1.673600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.956220 \n",
      "\n",
      "Epoch 557/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 557/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 557/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 557/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 557/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 557/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 557/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 557/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 557/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 557/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 557/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 557/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 557/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.685525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.948062 \n",
      "\n",
      "Epoch 558/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 558/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 558/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 558/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 558/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 558/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 558/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 558/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 558/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 558/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001440, MRE: 1.720624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.949769 \n",
      "\n",
      "Epoch 559/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 559/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 559/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 559/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 559/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 559/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 559/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 559/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 559/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001427, MRE: 1.667858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.953434 \n",
      "\n",
      "Epoch 560/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 560/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 560/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 560/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 560/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 560/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 560/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 560/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 560/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 560/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 560/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 560/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 560/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001423, MRE: 1.677792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.957723 \n",
      "\n",
      "Epoch 561/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 561/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 561/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 561/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 561/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 561/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 561/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 561/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 561/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 561/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 561/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 561/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 561/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001470, MRE: 1.669110 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.955509 \n",
      "\n",
      "Epoch 562/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 562/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 562/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 562/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 562/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 562/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 562/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 562/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 562/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001435, MRE: 1.841370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.956382 \n",
      "\n",
      "Epoch 563/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 563/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 563/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 563/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 563/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 563/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 563/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 563/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 563/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 563/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 563/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 563/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 563/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001457, MRE: 1.722414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.954378 \n",
      "\n",
      "Epoch 564/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 564/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 564/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 564/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 564/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 564/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 564/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 564/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 564/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 564/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 564/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 564/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 564/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001446, MRE: 1.682798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001437, MRE: 3.958521 \n",
      "\n",
      "Epoch 565/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 565/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 565/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 565/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 565/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 565/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 565/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 565/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 565/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 565/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 565/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 565/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 565/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001439, MRE: 1.669965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.950966 \n",
      "\n",
      "Epoch 566/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 566/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 566/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 566/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 566/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 566/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 566/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 566/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 566/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 566/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 566/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 566/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 566/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001457, MRE: 1.699165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.946995 \n",
      "\n",
      "Epoch 567/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 567/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 567/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 567/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 567/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 567/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 567/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 567/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 567/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 567/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 567/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 567/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 567/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001439, MRE: 1.703588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.951669 \n",
      "\n",
      "Epoch 568/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 568/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 568/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 568/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 568/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 568/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 568/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 568/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 568/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001432, MRE: 1.670618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.953771 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 569/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 569/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 569/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 569/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 569/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 569/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 569/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 569/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 569/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 569/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 569/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 569/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001432, MRE: 1.688909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.952839 \n",
      "\n",
      "Epoch 570/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 570/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 570/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 570/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 570/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 570/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 570/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 570/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 570/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 570/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001456, MRE: 1.699689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.953772 \n",
      "\n",
      "Epoch 571/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 571/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 571/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 571/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 571/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 571/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 571/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 571/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 571/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 571/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 571/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 571/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 571/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001433, MRE: 1.669608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001436, MRE: 3.946570 \n",
      "\n",
      "Epoch 572/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 572/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 572/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 572/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 572/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 572/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 572/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 572/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 572/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 572/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 572/800, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 572/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 572/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001429, MRE: 1.719184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.938659 \n",
      "\n",
      "Epoch 573/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 573/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 573/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 573/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 573/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 573/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 573/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 573/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 573/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 573/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 573/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 573/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 573/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001453, MRE: 1.693364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.939857 \n",
      "\n",
      "Epoch 574/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 574/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 574/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 574/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 574/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 574/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 574/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 574/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 574/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 574/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 574/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 574/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 574/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001435, MRE: 1.991483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.933368 \n",
      "\n",
      "Epoch 575/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 575/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 575/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 575/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 575/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 575/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 575/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 575/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 575/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 575/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 575/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 575/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 575/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.709787 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.932519 \n",
      "\n",
      "Epoch 576/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 576/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 576/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 576/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 576/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 576/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 576/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 576/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 576/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 576/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 576/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 576/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 576/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001467, MRE: 1.714498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.927397 \n",
      "\n",
      "Epoch 577/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 577/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 577/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 577/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 577/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 577/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 577/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 577/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 577/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 577/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 577/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 577/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001445, MRE: 1.733030 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.927581 \n",
      "\n",
      "Epoch 578/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 578/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 578/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 578/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 578/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 578/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 578/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 578/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 578/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 578/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 578/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 578/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 578/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001456, MRE: 1.718151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.930209 \n",
      "\n",
      "Epoch 579/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 579/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 579/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 579/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 579/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 579/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 579/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 579/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 579/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 579/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 579/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 579/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 579/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001434, MRE: 1.686821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.926004 \n",
      "\n",
      "Epoch 580/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 580/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 580/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 580/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 580/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 580/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 580/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001441, MRE: 1.680302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.922289 \n",
      "\n",
      "Epoch 581/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 581/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 581/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 581/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 581/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 581/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 581/800, Iteration 7/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 581/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 581/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 581/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 581/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 581/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001453, MRE: 1.820120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.919153 \n",
      "\n",
      "Epoch 582/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 582/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 582/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 582/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 582/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 582/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 582/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 582/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 582/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 582/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 582/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 582/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 582/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001459, MRE: 1.678926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.928963 \n",
      "\n",
      "Epoch 583/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 583/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 583/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 583/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 583/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 583/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 583/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 583/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 583/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 583/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 583/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 583/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 583/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001431, MRE: 2.012312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.929230 \n",
      "\n",
      "Epoch 584/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 584/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 584/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 584/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 584/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 584/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 584/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 584/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001444, MRE: 1.836184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.925909 \n",
      "\n",
      "Epoch 585/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 585/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 585/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 585/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 585/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 585/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 585/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 585/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 585/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001443, MRE: 2.037737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.918441 \n",
      "\n",
      "Epoch 586/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 586/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 586/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 586/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 586/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 586/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 586/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 586/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 586/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 586/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 586/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 586/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 586/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001432, MRE: 1.710102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.921780 \n",
      "\n",
      "Epoch 587/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 587/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 587/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 587/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 587/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 587/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 587/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 587/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 587/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 587/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 587/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 587/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 587/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001452, MRE: 1.671013 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.916311 \n",
      "\n",
      "Epoch 588/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 588/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 588/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 588/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 588/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 588/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 588/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 588/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 588/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001431, MRE: 1.679764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.923485 \n",
      "\n",
      "Epoch 589/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 589/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 589/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 589/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 589/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 589/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 589/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 589/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 589/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 589/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001424, MRE: 1.696624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.920442 \n",
      "\n",
      "Epoch 590/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 590/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 590/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 590/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 590/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 590/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 590/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 590/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 590/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 590/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 590/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 590/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 590/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001432, MRE: 2.004778 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.918807 \n",
      "\n",
      "Epoch 591/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 591/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 591/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 591/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 591/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 591/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 591/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 591/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 591/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 591/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 591/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001433, MRE: 1.665380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.923222 \n",
      "\n",
      "Epoch 592/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 592/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 592/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 592/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 592/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 592/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 592/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 592/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 592/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 592/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 592/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 592/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 592/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001437, MRE: 1.681773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.928865 \n",
      "\n",
      "Epoch 593/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 593/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 593/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 593/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 593/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 593/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 593/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 593/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 593/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 593/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 593/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 593/800, Iteration 12/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001464, MRE: 1.703250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.930865 \n",
      "\n",
      "Epoch 594/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 594/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 594/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 594/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 594/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 594/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 594/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 594/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 594/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 594/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 594/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 594/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 594/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001455, MRE: 1.673156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.937121 \n",
      "\n",
      "Epoch 595/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 595/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 595/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 595/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 595/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 595/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 595/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 595/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 595/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 595/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 595/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 595/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 595/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001445, MRE: 1.685316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.934257 \n",
      "\n",
      "Epoch 596/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 596/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 596/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 596/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 596/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 596/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 596/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 596/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 596/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 596/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 596/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001434, MRE: 1.711288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001435, MRE: 3.940965 \n",
      "\n",
      "Epoch 597/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 597/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 597/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 597/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 597/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 597/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 597/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 597/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 597/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 597/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 597/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 597/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 597/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001446, MRE: 1.690521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.926543 \n",
      "\n",
      "Epoch 598/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 598/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 598/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 598/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 598/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 598/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 598/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 598/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 598/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 598/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 598/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 598/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 598/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001428, MRE: 1.705189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.917339 \n",
      "\n",
      "Epoch 599/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 599/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 599/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 599/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 599/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 599/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 599/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 599/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 599/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 599/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 599/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 599/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001425, MRE: 1.671776 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.916673 \n",
      "\n",
      "Epoch 600/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 600/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 600/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 600/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 600/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 600/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 600/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 600/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001441, MRE: 1.747550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.917856 \n",
      "\n",
      "Epoch 601/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 601/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 601/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 601/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 601/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 601/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 601/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 601/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 601/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 601/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.668590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.933295 \n",
      "\n",
      "Epoch 602/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 602/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 602/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 602/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 602/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 602/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 602/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 602/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 602/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 602/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 602/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 602/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 602/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.693224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.925328 \n",
      "\n",
      "Epoch 603/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 603/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 603/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 603/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 603/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 603/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 603/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 603/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 603/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 603/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 603/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 603/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 603/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001431, MRE: 1.678225 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.930506 \n",
      "\n",
      "Epoch 604/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 604/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 604/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 604/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 604/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001436, MRE: 1.845160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.932964 \n",
      "\n",
      "Epoch 605/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 605/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 605/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 605/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 605/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 605/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 605/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 605/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 605/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 605/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 605/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 605/800, Iteration 12/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001458, MRE: 1.682367 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.930007 \n",
      "\n",
      "Epoch 606/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 606/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 606/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 606/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 606/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 606/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 606/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 606/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 606/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 606/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 606/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001429, MRE: 1.713958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.934437 \n",
      "\n",
      "Epoch 607/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 607/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 607/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 607/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 607/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 607/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 607/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.669875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.940438 \n",
      "\n",
      "Epoch 608/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 608/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 608/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 608/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 608/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 608/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 608/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 608/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 608/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 608/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 608/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 608/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 608/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001434, MRE: 1.666951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.936588 \n",
      "\n",
      "Epoch 609/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 609/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 609/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 609/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 609/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 609/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 609/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 609/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 609/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 609/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 609/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 609/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 609/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001429, MRE: 1.684010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.940258 \n",
      "\n",
      "Epoch 610/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 610/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 610/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 610/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 610/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 610/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 610/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 610/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 610/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 610/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 610/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001461, MRE: 1.671745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.939063 \n",
      "\n",
      "Epoch 611/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 611/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 611/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 611/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 611/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 611/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 611/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 611/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001461, MRE: 1.669161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.939066 \n",
      "\n",
      "Epoch 612/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 612/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 612/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 612/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 612/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 612/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 612/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 612/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001422, MRE: 1.672404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.938750 \n",
      "\n",
      "Epoch 613/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 613/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 613/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 613/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 613/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 613/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 613/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 613/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 613/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 613/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001433, MRE: 1.688075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.935589 \n",
      "\n",
      "Epoch 614/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 614/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 614/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 614/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 614/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 614/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 614/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 614/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 614/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 614/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 614/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 614/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 614/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001444, MRE: 1.673066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.934664 \n",
      "\n",
      "Epoch 615/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 615/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 615/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 615/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 615/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 615/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 615/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 615/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 615/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 615/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 615/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 615/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 615/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001423, MRE: 2.140368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.934389 \n",
      "\n",
      "Epoch 616/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 616/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 616/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 616/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 616/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 616/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 616/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 616/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 616/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 616/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 616/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 616/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001447, MRE: 1.670481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.931006 \n",
      "\n",
      "Epoch 617/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 617/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 617/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 617/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 617/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 617/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 617/800, Iteration 7/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 617/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 617/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 617/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 617/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 617/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001421, MRE: 1.701227 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.929415 \n",
      "\n",
      "Epoch 618/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 618/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 618/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 618/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 618/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 618/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 618/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 618/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 618/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001444, MRE: 1.671157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.928783 \n",
      "\n",
      "Epoch 619/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 619/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 619/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 619/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 619/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 619/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 619/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 619/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 619/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 619/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 619/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 619/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 619/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001424, MRE: 1.704717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.929289 \n",
      "\n",
      "Epoch 620/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 620/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 620/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 620/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 620/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 620/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 620/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 620/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 620/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 620/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 620/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 620/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 620/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001439, MRE: 1.680835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.931931 \n",
      "\n",
      "Epoch 621/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 621/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 621/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 621/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 621/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 621/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 621/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 621/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 621/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 621/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 621/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 621/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 621/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001446, MRE: 1.672755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.933878 \n",
      "\n",
      "Epoch 622/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 622/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 622/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 622/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 622/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 622/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 622/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 622/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 622/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 622/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 622/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001437, MRE: 1.712867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.937933 \n",
      "\n",
      "Epoch 623/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 623/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 623/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 623/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 623/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 623/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 623/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 623/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 623/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 623/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 623/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 623/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 623/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001449, MRE: 1.683927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.937866 \n",
      "\n",
      "Epoch 624/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 624/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 624/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 624/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 624/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 624/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 624/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 624/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 624/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 624/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 624/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 624/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 624/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001440, MRE: 1.695507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.940339 \n",
      "\n",
      "Epoch 625/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 625/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 625/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 625/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 625/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 625/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 625/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 625/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 625/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 625/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 625/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 625/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 625/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001453, MRE: 1.679901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.931064 \n",
      "\n",
      "Epoch 626/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 626/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 626/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 626/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 626/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 626/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 626/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 626/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 626/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 626/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 626/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 626/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 626/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001423, MRE: 1.660689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.927978 \n",
      "\n",
      "Epoch 627/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 627/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 627/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 627/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 627/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 627/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 627/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 627/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 627/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001408, MRE: 1.663107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.922587 \n",
      "\n",
      "Epoch 628/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 628/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 628/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 628/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 628/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 628/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 628/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 628/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 628/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 628/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 628/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 628/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 628/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001443, MRE: 1.712666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.918866 \n",
      "\n",
      "Epoch 629/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 629/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 629/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 629/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 629/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 629/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 629/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 629/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 629/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 629/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 629/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 629/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 629/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001433, MRE: 1.990447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.914942 \n",
      "\n",
      "Epoch 630/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 630/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 630/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 630/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 630/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 630/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 630/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 630/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 630/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 630/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 630/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 630/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 630/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001427, MRE: 1.821187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.926428 \n",
      "\n",
      "Epoch 631/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 631/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 631/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 631/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 631/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 631/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 631/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 631/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 631/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 631/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 631/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 631/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 631/800, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001429, MRE: 1.710349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.930454 \n",
      "\n",
      "Epoch 632/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 632/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 632/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 632/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 632/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 632/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 632/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 632/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 632/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 632/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 632/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 632/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 632/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001436, MRE: 1.674454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001434, MRE: 3.937701 \n",
      "\n",
      "Epoch 633/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 633/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 633/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 633/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 633/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 633/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 633/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 633/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 633/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 633/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 633/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 633/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 633/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001461, MRE: 1.680923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.932166 \n",
      "\n",
      "Epoch 634/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 634/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 634/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 634/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 634/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 634/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 634/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 634/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 634/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 634/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 634/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 634/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 634/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001444, MRE: 1.671023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.932064 \n",
      "\n",
      "Epoch 635/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 635/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 635/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 635/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 635/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 635/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 635/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 635/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001433, MRE: 1.662974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.931818 \n",
      "\n",
      "Epoch 636/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 636/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 636/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 636/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 636/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 636/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 636/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 636/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 636/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 636/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 636/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 636/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 636/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001425, MRE: 1.679530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.923612 \n",
      "\n",
      "Epoch 637/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 637/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 637/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 637/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 637/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 637/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 637/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 637/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 637/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 637/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 637/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 637/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 637/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.700811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.930540 \n",
      "\n",
      "Epoch 638/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 638/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 638/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 638/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 638/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 638/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 638/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 638/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 638/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 638/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 638/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 638/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 638/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001429, MRE: 1.670091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.924754 \n",
      "\n",
      "Epoch 639/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 639/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 639/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 639/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 639/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 639/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 639/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 639/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 639/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 639/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001438, MRE: 1.716867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.928706 \n",
      "\n",
      "Epoch 640/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 640/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 640/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 640/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 640/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 640/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 640/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 640/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 640/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 640/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 640/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 640/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 640/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001455, MRE: 1.764426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.928246 \n",
      "\n",
      "Epoch 641/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 641/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 641/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 641/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 641/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 641/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 641/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 641/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 641/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 641/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 641/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 641/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 641/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001439, MRE: 1.680716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.930270 \n",
      "\n",
      "Epoch 642/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 642/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 642/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 642/800, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 642/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 642/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 642/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 642/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 642/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 642/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 642/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 642/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 642/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001454, MRE: 1.687875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.926066 \n",
      "\n",
      "Epoch 643/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 643/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 643/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 643/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 643/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 643/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 643/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 643/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 643/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 643/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 643/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 643/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 643/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001430, MRE: 1.668068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.927189 \n",
      "\n",
      "Epoch 644/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 644/800, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 644/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 644/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 644/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 644/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 644/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 644/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 644/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 644/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 13/12, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001428, MRE: 1.986663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.926567 \n",
      "\n",
      "Epoch 645/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 645/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 645/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 645/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 645/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 645/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 645/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 645/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 645/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 645/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 645/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 645/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 645/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001468, MRE: 2.019776 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.917195 \n",
      "\n",
      "Epoch 646/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 646/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 646/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 646/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 646/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 646/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 646/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 646/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 646/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 646/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 646/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 646/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 646/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001433, MRE: 2.033641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.924094 \n",
      "\n",
      "Epoch 647/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 647/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 647/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 647/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 647/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 647/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 647/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 647/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 647/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001449, MRE: 1.848011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.920257 \n",
      "\n",
      "Epoch 648/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 648/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 648/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 648/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 648/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 648/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 648/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 648/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 648/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 648/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 648/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 648/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 648/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001440, MRE: 1.693980 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.921422 \n",
      "\n",
      "Epoch 649/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 649/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 649/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 649/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 649/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 649/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 649/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 649/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 649/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 649/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 649/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 649/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 649/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001444, MRE: 1.739305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.920669 \n",
      "\n",
      "Epoch 650/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 650/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 650/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 650/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 650/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 650/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 650/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 650/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 650/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 650/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 650/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 650/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 650/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001437, MRE: 1.989719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.920192 \n",
      "\n",
      "Epoch 651/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 651/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 651/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 651/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 651/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 651/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 651/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 651/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 651/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 651/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 651/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 651/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 651/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001443, MRE: 1.709773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.927185 \n",
      "\n",
      "Epoch 652/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 652/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 652/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 652/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 652/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 652/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 652/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 652/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 652/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 652/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001432, MRE: 1.732430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.915981 \n",
      "\n",
      "Epoch 653/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 653/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 653/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 653/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 653/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 653/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 653/800, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 653/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 653/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 653/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001429, MRE: 1.668628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.917102 \n",
      "\n",
      "Epoch 654/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 654/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 654/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 654/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 654/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 654/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 654/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 654/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 654/800, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 654/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 654/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 654/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 654/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001427, MRE: 1.723347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.913647 \n",
      "\n",
      "Epoch 655/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 655/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 655/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 655/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 655/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 655/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 655/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 655/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 655/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 655/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 655/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 655/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 655/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001444, MRE: 1.875867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.915649 \n",
      "\n",
      "Epoch 656/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 656/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 656/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 656/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 656/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 656/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 656/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 656/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 656/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 656/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 656/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 656/800, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 656/800, Iteration 13/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001434, MRE: 1.695206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.919227 \n",
      "\n",
      "Epoch 657/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 657/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 657/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 657/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 657/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 657/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 657/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 657/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 657/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 657/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 657/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 657/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 657/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001433, MRE: 1.667423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.917593 \n",
      "\n",
      "Epoch 658/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 658/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 658/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 658/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 658/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 658/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 658/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 658/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 658/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001445, MRE: 1.806757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.913116 \n",
      "\n",
      "Epoch 659/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 659/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 659/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 659/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 659/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 659/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 659/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 659/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 659/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 659/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 659/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 659/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 659/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001435, MRE: 1.836020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.925942 \n",
      "\n",
      "Epoch 660/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 660/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 660/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 660/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 660/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 660/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 660/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 660/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 660/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 660/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 660/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 660/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 660/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001439, MRE: 1.833500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.923497 \n",
      "\n",
      "Epoch 661/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 661/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 661/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 661/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 661/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 661/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 661/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 661/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 661/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 661/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 661/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 661/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 661/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001435, MRE: 1.669276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.930489 \n",
      "\n",
      "Epoch 662/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 662/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 662/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 662/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 662/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 662/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 662/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 662/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 662/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 662/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 662/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 662/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 662/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001439, MRE: 1.666767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.926600 \n",
      "\n",
      "Epoch 663/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 663/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 663/800, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 663/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 663/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 663/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 663/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 663/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 663/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 663/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 663/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 663/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 663/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 1.686730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.934773 \n",
      "\n",
      "Epoch 664/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 664/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 664/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 664/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 664/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 664/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 664/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 664/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 664/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 664/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001433, MRE: 1.681668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.939053 \n",
      "\n",
      "Epoch 665/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 665/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 665/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 665/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 665/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 665/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 665/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 665/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 665/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 665/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 665/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 665/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 665/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001430, MRE: 1.679495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.937598 \n",
      "\n",
      "Epoch 666/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 666/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 666/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 666/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 666/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 666/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 666/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 666/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 666/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 666/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 666/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001433, MRE: 1.726246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.939959 \n",
      "\n",
      "Epoch 667/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 667/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 667/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 667/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 667/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 667/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 667/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 667/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001457, MRE: 1.672683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.941736 \n",
      "\n",
      "Epoch 668/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 668/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 668/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 668/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 668/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 668/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 668/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 668/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 668/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001431, MRE: 1.711497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.946154 \n",
      "\n",
      "Epoch 669/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 669/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 669/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 669/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 669/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 669/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 669/800, Iteration 8/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 669/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 669/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 669/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 669/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001441, MRE: 1.684359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.940623 \n",
      "\n",
      "Epoch 670/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 670/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 670/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 670/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 670/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 670/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 670/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 670/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 670/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 670/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001431, MRE: 1.680479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.939252 \n",
      "\n",
      "Epoch 671/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 671/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 671/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 671/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 671/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 671/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 671/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 671/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 671/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 671/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 671/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 671/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 671/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001449, MRE: 1.671322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.940161 \n",
      "\n",
      "Epoch 672/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 672/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 672/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 672/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 672/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 672/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 672/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 672/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 672/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 672/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 672/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 672/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 672/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001463, MRE: 1.669148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.939082 \n",
      "\n",
      "Epoch 673/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 673/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 673/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 673/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 673/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 673/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 673/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 673/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 673/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 673/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 673/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001447, MRE: 1.675187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.938006 \n",
      "\n",
      "Epoch 674/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 674/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 674/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 674/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 674/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 674/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 674/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 674/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 674/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 674/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 674/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 674/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 674/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001438, MRE: 1.672660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.933223 \n",
      "\n",
      "Epoch 675/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 675/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 675/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 675/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 675/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 675/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 675/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 675/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 675/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 675/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 675/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 675/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 675/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001431, MRE: 1.695696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.934254 \n",
      "\n",
      "Epoch 676/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 676/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 676/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 676/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 676/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 676/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 676/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 676/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 676/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 676/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 676/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 676/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 676/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001431, MRE: 1.707516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.930107 \n",
      "\n",
      "Epoch 677/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 677/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 677/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 677/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 677/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 677/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 677/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 677/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 677/800, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 677/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001419, MRE: 1.672837 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001433, MRE: 3.938336 \n",
      "\n",
      "Epoch 678/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 678/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 678/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 678/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 678/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 678/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 678/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 678/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 678/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 678/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001448, MRE: 1.663798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.929657 \n",
      "\n",
      "Epoch 679/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 679/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 679/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 679/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 679/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 679/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 679/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 679/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 679/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 679/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001438, MRE: 1.717548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.919117 \n",
      "\n",
      "Epoch 680/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 680/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 680/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 680/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 680/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 680/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 680/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 680/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 680/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 680/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 680/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 680/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 680/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001432, MRE: 1.659596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001432, MRE: 3.924299 \n",
      "\n",
      "Epoch 681/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 681/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 681/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 681/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 681/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 681/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 681/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 681/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 681/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 681/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 681/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 681/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.712125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.911968 \n",
      "\n",
      "Epoch 682/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 682/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 682/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 682/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 682/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 682/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 682/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 682/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 682/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 682/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 682/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 682/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 682/800, Iteration 13/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001430, MRE: 1.673586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.918633 \n",
      "\n",
      "Epoch 683/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 683/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 683/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 683/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 683/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 683/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 683/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 683/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 683/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001432, MRE: 1.666135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.916804 \n",
      "\n",
      "Epoch 684/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 684/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 684/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 684/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 684/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 684/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 684/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 684/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 684/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 684/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 684/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 684/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 684/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001419, MRE: 1.685678 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.915963 \n",
      "\n",
      "Epoch 685/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 685/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 685/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 685/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 685/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 685/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 685/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 685/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 685/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 685/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 685/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 685/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 685/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001445, MRE: 1.710810 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.913110 \n",
      "\n",
      "Epoch 686/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 686/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 686/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 686/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 686/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 686/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 686/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 686/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001431, MRE: 1.667424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.907849 \n",
      "\n",
      "Epoch 687/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 687/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 687/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 687/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 687/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 687/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 687/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 687/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 687/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 687/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 687/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001450, MRE: 1.850556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.907270 \n",
      "\n",
      "Epoch 688/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 688/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 688/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 688/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 688/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 688/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 688/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 688/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 688/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 688/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 688/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 688/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 688/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001431, MRE: 2.138350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.906409 \n",
      "\n",
      "Epoch 689/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 689/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 689/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 689/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 689/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 689/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 689/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 689/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 689/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 689/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 689/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 689/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 689/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001451, MRE: 1.669977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.904745 \n",
      "\n",
      "Epoch 690/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 690/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 690/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 690/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 690/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 690/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 690/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 690/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 690/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 690/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 690/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 690/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 690/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001433, MRE: 1.672626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.906695 \n",
      "\n",
      "Epoch 691/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 691/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 691/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 691/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 691/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 691/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 691/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 691/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 691/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 691/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 691/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 691/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 691/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001440, MRE: 1.718498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.900930 \n",
      "\n",
      "Epoch 692/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 692/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 692/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 692/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 692/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 692/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 692/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 692/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 692/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 692/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001444, MRE: 1.705337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.907751 \n",
      "\n",
      "Epoch 693/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 693/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 693/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 693/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 693/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 693/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 693/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 693/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 693/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 693/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 693/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 693/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 693/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001455, MRE: 1.688478 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.912272 \n",
      "\n",
      "Epoch 694/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 694/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 694/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 694/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 694/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 694/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 694/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 694/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 694/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001455, MRE: 1.673708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.917218 \n",
      "\n",
      "Epoch 695/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 695/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 695/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 695/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 695/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 695/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 695/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 695/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 695/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 695/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 695/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 695/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 695/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001454, MRE: 2.015908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.912823 \n",
      "\n",
      "Epoch 696/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 696/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 696/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 696/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 696/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 696/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 696/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 696/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 696/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001431, MRE: 1.812849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909048 \n",
      "\n",
      "Epoch 697/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 697/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 697/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 697/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 697/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 697/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 697/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 697/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 697/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 697/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 697/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 697/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 697/800, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001425, MRE: 1.683251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.910105 \n",
      "\n",
      "Epoch 698/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 698/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 698/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 698/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 698/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 698/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 698/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 698/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 698/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001425, MRE: 1.698447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909014 \n",
      "\n",
      "Epoch 699/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 699/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 699/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 699/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 699/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 699/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 699/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 699/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 699/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 699/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 699/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 699/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 699/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001435, MRE: 1.701914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.911205 \n",
      "\n",
      "Epoch 700/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 700/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 700/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 700/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 700/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 700/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 700/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 700/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 700/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 700/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 700/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 700/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 700/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001444, MRE: 1.675914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.908617 \n",
      "\n",
      "Epoch 701/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 701/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 701/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 701/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 701/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 701/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 701/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 701/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 701/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 701/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 701/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 701/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 701/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001427, MRE: 1.666333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.911828 \n",
      "\n",
      "Epoch 702/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 702/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 702/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 702/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 702/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 702/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 702/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 702/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 702/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 702/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 702/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 702/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 702/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001435, MRE: 1.671210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.910055 \n",
      "\n",
      "Epoch 703/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 703/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 703/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 703/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 703/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 703/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 703/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 703/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 703/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 703/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 703/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 703/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 703/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001448, MRE: 1.720967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909547 \n",
      "\n",
      "Epoch 704/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 704/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 704/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 704/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 704/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 704/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 704/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 704/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 704/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 704/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 704/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 704/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 704/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001438, MRE: 1.665882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.912109 \n",
      "\n",
      "Epoch 705/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 705/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 705/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 705/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 705/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 705/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 705/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 705/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 705/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 705/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 705/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 705/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 705/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001430, MRE: 1.704552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.919521 \n",
      "\n",
      "Epoch 706/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 706/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 706/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 706/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 706/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 706/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 706/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 706/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 706/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 706/800, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 706/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 706/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 706/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001441, MRE: 1.680549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.913593 \n",
      "\n",
      "Epoch 707/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 707/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 707/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 707/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 707/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 707/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 707/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 707/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 707/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 707/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 707/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001440, MRE: 1.663906 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.922499 \n",
      "\n",
      "Epoch 708/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 708/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 708/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 708/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 708/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 708/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 708/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 708/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 708/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 708/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 708/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 708/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 708/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001421, MRE: 1.683175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.908801 \n",
      "\n",
      "Epoch 709/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 709/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 709/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 709/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 709/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 709/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 709/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 709/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 709/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 709/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 709/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 709/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 709/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001456, MRE: 1.677964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.908626 \n",
      "\n",
      "Epoch 710/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 710/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 710/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 710/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 710/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 710/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 710/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 710/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 710/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 710/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 710/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 710/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 710/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001430, MRE: 1.667515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.906603 \n",
      "\n",
      "Epoch 711/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 711/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 711/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 711/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 711/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 711/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 711/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 711/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 711/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 711/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 711/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 711/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 711/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001449, MRE: 1.672336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909055 \n",
      "\n",
      "Epoch 712/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 712/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 712/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 712/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 712/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 712/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 712/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 712/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 712/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 712/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 712/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 712/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 712/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001428, MRE: 1.687115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909875 \n",
      "\n",
      "Epoch 713/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 713/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 713/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 713/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 713/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 713/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 713/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 713/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 713/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 713/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 713/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 713/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 713/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001429, MRE: 1.674942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909565 \n",
      "\n",
      "Epoch 714/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 714/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 714/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 714/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 714/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 714/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 714/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 714/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 714/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 714/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 714/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 714/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 714/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001443, MRE: 1.665499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.916882 \n",
      "\n",
      "Epoch 715/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 715/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 715/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 715/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 715/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 715/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 715/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 715/800, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 715/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001423, MRE: 1.726868 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.916296 \n",
      "\n",
      "Epoch 716/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 716/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 716/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 716/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 716/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 716/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 716/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 716/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 716/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 716/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001435, MRE: 1.821879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.919274 \n",
      "\n",
      "Epoch 717/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 717/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 717/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 717/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 717/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 717/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 717/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 717/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 717/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 717/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 717/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 717/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 717/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001417, MRE: 1.689964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.917928 \n",
      "\n",
      "Epoch 718/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 718/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 718/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 718/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 718/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 718/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 718/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 718/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 718/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 718/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 718/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 718/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 718/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001427, MRE: 1.827551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.919937 \n",
      "\n",
      "Epoch 719/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 719/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 719/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 719/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 719/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 719/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 719/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 719/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 719/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 719/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 719/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 719/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 719/800, Iteration 13/12, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001453, MRE: 1.681400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.924018 \n",
      "\n",
      "Epoch 720/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 720/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 720/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 720/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 720/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 720/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 720/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 720/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 720/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 720/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 720/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 720/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 720/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.708547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.921995 \n",
      "\n",
      "Epoch 721/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 721/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 721/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 721/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 721/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 721/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 721/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 721/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 721/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 721/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 721/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 721/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 721/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.671589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909749 \n",
      "\n",
      "Epoch 722/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 722/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 722/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 722/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 722/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 722/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 722/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 722/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 722/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 722/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 722/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 722/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 722/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001441, MRE: 1.734162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909214 \n",
      "\n",
      "Epoch 723/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 723/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 723/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 723/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 723/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 723/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 723/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 723/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 723/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 723/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001451, MRE: 1.693865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.909915 \n",
      "\n",
      "Epoch 724/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 724/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 724/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 724/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 724/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 724/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 724/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 724/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 724/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001445, MRE: 1.679323 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.914836 \n",
      "\n",
      "Epoch 725/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 725/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 725/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 725/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 725/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 725/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 725/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 725/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 725/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 725/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001433, MRE: 1.737379 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.917204 \n",
      "\n",
      "Epoch 726/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 726/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 726/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 726/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 726/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 726/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 726/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 726/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001432, MRE: 1.711015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.921475 \n",
      "\n",
      "Epoch 727/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 727/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 727/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 727/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 727/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 727/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 727/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 727/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 727/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 727/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 727/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 727/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 727/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001443, MRE: 1.813510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001431, MRE: 3.925541 \n",
      "\n",
      "Epoch 728/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 728/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 728/800, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 728/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 728/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 728/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 728/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 728/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 728/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 728/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 728/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 728/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001453, MRE: 2.011573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.918689 \n",
      "\n",
      "Epoch 729/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 729/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 729/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 729/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 729/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 729/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 729/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 729/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 729/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 729/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 729/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 729/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 729/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001427, MRE: 1.667505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.919960 \n",
      "\n",
      "Epoch 730/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 730/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 730/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 730/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 730/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 730/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 730/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 730/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 730/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 730/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 730/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001447, MRE: 1.669884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.911708 \n",
      "\n",
      "Epoch 731/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 731/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 731/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 731/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 731/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 731/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 731/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 731/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 731/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 731/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 731/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 731/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 731/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001444, MRE: 1.784695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.906850 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 732/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 732/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 732/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 732/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 732/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 732/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 732/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 732/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 732/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 732/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 732/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 732/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 732/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001461, MRE: 1.737161 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.915070 \n",
      "\n",
      "Epoch 733/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 733/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 733/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 733/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 733/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 733/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 733/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 733/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 733/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 733/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 733/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001443, MRE: 1.667303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.915305 \n",
      "\n",
      "Epoch 734/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 734/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 734/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 734/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 734/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 734/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 734/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 734/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 734/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 734/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001429, MRE: 1.663499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.916593 \n",
      "\n",
      "Epoch 735/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 735/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 735/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 735/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 735/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 735/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 735/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 735/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 735/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 735/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001433, MRE: 1.668320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.914629 \n",
      "\n",
      "Epoch 736/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 736/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 736/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 736/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 736/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 736/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 736/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 736/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 736/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 736/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 736/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 736/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 736/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001442, MRE: 1.669322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.921822 \n",
      "\n",
      "Epoch 737/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 737/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 737/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 737/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 737/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 737/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 737/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 737/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 737/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 737/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 737/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 737/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 737/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.673372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.920157 \n",
      "\n",
      "Epoch 738/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 738/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 738/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 738/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 738/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 738/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 738/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 738/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 738/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 738/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001431, MRE: 1.827109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.924377 \n",
      "\n",
      "Epoch 739/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 739/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 739/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 739/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 739/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 739/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 739/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 739/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 739/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 739/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 739/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 739/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 739/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001425, MRE: 1.806228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.920373 \n",
      "\n",
      "Epoch 740/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 740/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 740/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 740/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 740/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 740/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 740/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 740/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 740/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 740/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 740/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 740/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 740/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001447, MRE: 1.664023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.913192 \n",
      "\n",
      "Epoch 741/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 741/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 741/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 741/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 741/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 741/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 741/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 741/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 741/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 741/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 741/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 741/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 741/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001432, MRE: 1.734240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.901792 \n",
      "\n",
      "Epoch 742/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 742/800, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 742/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 742/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 742/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 742/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 742/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 742/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 742/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 742/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 742/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001429, MRE: 1.667535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.899781 \n",
      "\n",
      "Epoch 743/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 743/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 743/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 743/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 743/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 743/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 743/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 743/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 743/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001449, MRE: 1.668550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.898434 \n",
      "\n",
      "Epoch 744/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 744/800, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 744/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 744/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 744/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 744/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 744/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 744/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 744/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 744/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 744/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 744/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 744/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001452, MRE: 1.705207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.895545 \n",
      "\n",
      "Epoch 745/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 745/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 745/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 745/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 745/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 745/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 745/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 745/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 745/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 745/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 745/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 745/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 745/800, Iteration 13/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001449, MRE: 1.663687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.900298 \n",
      "\n",
      "Epoch 746/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 746/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 746/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 746/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 746/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 746/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 746/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 746/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 746/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 746/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 746/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 746/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 746/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001440, MRE: 1.669289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.897049 \n",
      "\n",
      "Epoch 747/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 747/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 747/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 747/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 747/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 747/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 747/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 747/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 747/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 747/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001425, MRE: 1.693572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.901017 \n",
      "\n",
      "Epoch 748/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 748/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 748/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 748/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 748/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 748/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 748/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 748/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 748/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 748/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 748/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 748/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 748/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001464, MRE: 1.665074 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.906412 \n",
      "\n",
      "Epoch 749/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 749/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 749/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 749/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 749/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 749/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 749/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 749/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 749/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 749/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001453, MRE: 1.691868 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.905617 \n",
      "\n",
      "Epoch 750/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 750/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 750/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 750/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 750/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 750/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 750/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 750/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 750/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 750/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 750/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 750/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 750/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001422, MRE: 1.676526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.901509 \n",
      "\n",
      "Epoch 751/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 751/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 751/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 751/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 751/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 751/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 751/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 751/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 751/800, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 751/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 751/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 751/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 751/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001433, MRE: 1.732761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.908594 \n",
      "\n",
      "Epoch 752/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 752/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 752/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 752/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 752/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 752/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 752/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 752/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 752/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001462, MRE: 1.672793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.912436 \n",
      "\n",
      "Epoch 753/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 753/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 753/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 753/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 753/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 753/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 753/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 753/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 753/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 753/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 753/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 753/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 753/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001444, MRE: 1.703187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.922770 \n",
      "\n",
      "Epoch 754/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 754/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 754/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 754/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 754/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 754/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 754/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 754/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 754/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001431, MRE: 1.671065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.915399 \n",
      "\n",
      "Epoch 755/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 755/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 755/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 755/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 755/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 755/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 755/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 755/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 755/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 755/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 755/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001445, MRE: 1.826726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.918934 \n",
      "\n",
      "Epoch 756/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 756/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 756/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 756/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 756/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 756/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 756/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 756/800, Iteration 8/12, Loss: 0.0007\n",
      "Epoch 756/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 756/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 756/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 756/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 756/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001421, MRE: 1.673288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001430, MRE: 3.918375 \n",
      "\n",
      "Epoch 757/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 757/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 757/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 757/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 757/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 757/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 757/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 757/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 757/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 757/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 757/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 757/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 757/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001430, MRE: 1.690743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.910281 \n",
      "\n",
      "Epoch 758/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 758/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 758/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 758/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 758/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 758/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 758/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 758/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 758/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 758/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 758/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 758/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 758/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001436, MRE: 1.664182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.903479 \n",
      "\n",
      "Epoch 759/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 759/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 759/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 759/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 759/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 759/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 759/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 759/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 759/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 759/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 759/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 759/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 759/800, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001431, MRE: 1.676824 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.909556 \n",
      "\n",
      "Epoch 760/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 760/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 760/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 760/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 760/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 760/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 760/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 760/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 760/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 760/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 760/800, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 760/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 760/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001442, MRE: 2.056814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.909504 \n",
      "\n",
      "Epoch 761/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 761/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 761/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 761/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 761/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 761/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 761/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 761/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 761/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 761/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001457, MRE: 1.680946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.909555 \n",
      "\n",
      "Epoch 762/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 762/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 762/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 762/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 762/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 762/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 762/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 762/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 762/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001451, MRE: 1.682528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.913635 \n",
      "\n",
      "Epoch 763/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 763/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 763/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 763/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 763/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 763/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 763/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 763/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 763/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 763/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 763/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 763/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 763/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001446, MRE: 1.706584 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.916012 \n",
      "\n",
      "Epoch 764/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 764/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 764/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 764/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 764/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 764/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 764/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 764/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 764/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 764/800, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001427, MRE: 1.660729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.908267 \n",
      "\n",
      "Epoch 765/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 765/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 765/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 765/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 765/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 765/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 765/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 765/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 765/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 765/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001457, MRE: 1.676332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.903904 \n",
      "\n",
      "Epoch 766/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 766/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 766/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 766/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 766/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 766/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 766/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 766/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 766/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 766/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001441, MRE: 1.676889 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.918719 \n",
      "\n",
      "Epoch 767/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 767/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 767/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 767/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 767/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 767/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 767/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 767/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 767/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 767/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 767/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 767/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 767/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001410, MRE: 1.662809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.905957 \n",
      "\n",
      "Epoch 768/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 768/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 768/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 768/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 768/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 768/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 768/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 768/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 768/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001432, MRE: 1.762564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.903611 \n",
      "\n",
      "Epoch 769/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 769/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 769/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 769/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 769/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 769/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 769/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 769/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 769/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 769/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 769/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 769/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 769/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001440, MRE: 1.724378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.909489 \n",
      "\n",
      "Epoch 770/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 770/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 770/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 770/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 770/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 770/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 770/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 770/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 770/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 770/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 770/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 770/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 770/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001434, MRE: 1.668077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.918201 \n",
      "\n",
      "Epoch 771/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 771/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 771/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 771/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 771/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 771/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 771/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 771/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 771/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 771/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 771/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 771/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 771/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001415, MRE: 1.657297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.914448 \n",
      "\n",
      "Epoch 772/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 772/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 772/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 772/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 772/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 772/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 772/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 772/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 772/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 772/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 772/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 772/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 772/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001428, MRE: 1.681579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.916837 \n",
      "\n",
      "Epoch 773/800, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 773/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 773/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 773/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 773/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 773/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 773/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 773/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 773/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 773/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 773/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 773/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 773/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001452, MRE: 1.725850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.915965 \n",
      "\n",
      "Epoch 774/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 774/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 774/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 774/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 774/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 774/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 774/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 774/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 774/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 774/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 774/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001419, MRE: 1.673192 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.922611 \n",
      "\n",
      "Epoch 775/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 775/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 775/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 775/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 775/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 775/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 775/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 775/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 775/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 775/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 775/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 775/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 775/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001457, MRE: 1.679460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.922144 \n",
      "\n",
      "Epoch 776/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 776/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 776/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 776/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 776/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 776/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 776/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 776/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 776/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 776/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 776/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 776/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 776/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001437, MRE: 1.668099 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.923552 \n",
      "\n",
      "Epoch 777/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 777/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 777/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 777/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 777/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 777/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 777/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 777/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 777/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 777/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 777/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 777/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 777/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001424, MRE: 1.819906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.918789 \n",
      "\n",
      "Epoch 778/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 778/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 778/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 778/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 778/800, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 778/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 778/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 778/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 778/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 778/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 778/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 778/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 778/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001435, MRE: 1.998429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.909898 \n",
      "\n",
      "Epoch 779/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 779/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 779/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 779/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 779/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 779/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 779/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 779/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 779/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 779/800, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 779/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 779/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 779/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001425, MRE: 1.660692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.911003 \n",
      "\n",
      "Epoch 780/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 780/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 780/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 780/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 780/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 780/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 780/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 780/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 780/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 780/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 780/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 780/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 780/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001448, MRE: 1.672959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.914157 \n",
      "\n",
      "Epoch 781/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 781/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 781/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 781/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 781/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 781/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 781/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 781/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 781/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 781/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 781/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 781/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 781/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001442, MRE: 1.678396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.912859 \n",
      "\n",
      "Epoch 782/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 782/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 782/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 782/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 782/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 782/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 782/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 782/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 782/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 782/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 782/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 782/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 782/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001434, MRE: 1.670365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.917503 \n",
      "\n",
      "Epoch 783/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 783/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 783/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 783/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 783/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 783/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 783/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 783/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 783/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001444, MRE: 1.680908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.923195 \n",
      "\n",
      "Epoch 784/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 784/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 784/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 784/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 784/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 784/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 784/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 784/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 784/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 784/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 784/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001455, MRE: 1.670393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.925807 \n",
      "\n",
      "Epoch 785/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 785/800, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 785/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 785/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 785/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 785/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 785/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 785/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 785/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 785/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 785/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 785/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 785/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001425, MRE: 1.671986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.912274 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 786/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 786/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 786/800, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 786/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 786/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 786/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 786/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 786/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 786/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 786/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 786/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 786/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001440, MRE: 1.728305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.917588 \n",
      "\n",
      "Epoch 787/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 787/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 787/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 787/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 787/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 787/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 787/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 787/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 787/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 787/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 787/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 787/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 787/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001441, MRE: 1.679360 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.925207 \n",
      "\n",
      "Epoch 788/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 788/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 788/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 788/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 788/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 788/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 788/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 788/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 788/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 788/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 788/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 788/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 788/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001433, MRE: 1.668041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.916069 \n",
      "\n",
      "Epoch 789/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 789/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 789/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 789/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 789/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 789/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 789/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 789/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001426, MRE: 1.659232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.909596 \n",
      "\n",
      "Epoch 790/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 790/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 790/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 790/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 790/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 790/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 790/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 790/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 790/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 790/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 790/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 790/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 790/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001421, MRE: 1.663557 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.907209 \n",
      "\n",
      "Epoch 791/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 791/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 791/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 791/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 791/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 791/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 791/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 791/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 791/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 791/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 791/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 791/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 791/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.001421, MRE: 1.817226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.903516 \n",
      "\n",
      "Epoch 792/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 792/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 792/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 792/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 792/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 792/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 792/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 792/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 792/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 792/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 792/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001431, MRE: 1.657970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.909042 \n",
      "\n",
      "Epoch 793/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 793/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 793/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 793/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 793/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 793/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 793/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 793/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 793/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 793/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 793/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 793/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 793/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001423, MRE: 1.659628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.913108 \n",
      "\n",
      "Epoch 794/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 794/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 794/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 794/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 794/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 794/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 794/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 794/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 794/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 794/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 794/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 794/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 794/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001446, MRE: 1.660732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001429, MRE: 3.916777 \n",
      "\n",
      "Epoch 795/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 795/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 795/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 795/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 795/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 795/800, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 795/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001428, MRE: 1.681214 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.906604 \n",
      "\n",
      "Epoch 796/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 796/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 796/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 796/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 796/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 796/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 796/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 796/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 796/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 796/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 796/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 796/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 796/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001410, MRE: 1.831725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.911099 \n",
      "\n",
      "Epoch 797/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 797/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 797/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 797/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 797/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 797/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 797/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 797/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 797/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 797/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 797/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 797/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 797/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001441, MRE: 1.813498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.912286 \n",
      "\n",
      "Epoch 798/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 798/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 798/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 798/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 798/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 798/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 798/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 798/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 798/800, Iteration 12/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001417, MRE: 2.009907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.906312 \n",
      "\n",
      "Epoch 799/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 799/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 799/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 799/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 799/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 799/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 799/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 799/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 799/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 799/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 799/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 799/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 799/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001428, MRE: 1.678231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.914794 \n",
      "\n",
      "Epoch 800/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 800/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 800/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 800/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 800/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 800/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 800/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 800/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 800/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 800/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001408, MRE: 1.675008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001428, MRE: 3.908442 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 800 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predictions = torch.max(pred.data, 1)\n",
    "#         train_correct += (predictions == y.data).sum()                \n",
    "#         train_total += predictions.size(0)    \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping\n",
    "    #train_loss.append(loss.item())\n",
    "    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "\n",
    "#     loss = criterion(outputs, Variable(test_classes))\n",
    "#     test_loss.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Loss$ / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9654f4",
   "metadata": {},
   "source": [
    "#### Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2330a798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAGoCAYAAADLiKg7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACIDklEQVR4nO3de1xUdf4/8NcZBARSREAFRUFNsfKCd/BerfdMs02jrEztYlbWlqJtm102sNt+t9Iuam5bav52JTMvtJaaEt4BtRItA0VAAYVREUXh/P4YzjiXc2bO3JgLr+fj4W7MnDnzGWrevj+390cQRVEEEREREXk9jbsbQERERETOwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IHPavf/0LgiDo/zRp0gTt2rXD9OnTUVRU5NT3io2NxSOPPKL/ubi4GIsWLUJubq5T30ftZ9qxYwcEQcCOHTtsfo+srCwsWrQIlZWVzms4ETVqTdzdACLyHStXrkR8fDyqq6uxc+dOpKam4scff8SRI0cQEhLilPf4+uuv0bx5c/3PxcXFePXVVxEbG4tevXo55T0MufIzZWVl4dVXX8UjjzyCFi1aOKfBRNSoMbEjIqe57bbb0LdvXwDAiBEjUFtbi9dffx3r16/HAw884NC9q6urERQUhISEBGc0VTVXfiYiImfjVCwRuczAgQMBACdPngQAvPrqqxgwYABatmyJ5s2bo3fv3lixYgVEUTR6XWxsLMaPH4/09HQkJCSgadOmePXVV/XPSVOxO3bsQL9+/QAA06dP10+bLlq0CF988QUEQcDu3bvN2vXaa6/B398fxcXFDn8mJRs2bEBiYiKCg4PRrFkz/OlPfzJqy6JFi/Diiy8CAOLi4vRtt2dKl4hIwhE7InKZ33//HQAQGRkJACgoKMDjjz+O9u3bAwD27NmDp59+GkVFRfjb3/5m9Nrs7GwcPXoUf/3rXxEXFyc77dm7d2+sXLkS06dPx1//+leMGzcOANCuXTu0atUK8+bNw5IlS5CYmKh/zfXr1/HJJ59g0qRJiI6OdvgzyVm9ejUeeOABjBw5EmvWrMHVq1fx1ltvYfjw4fjhhx8wePBgzJw5E+fPn8cHH3yA9PR0REVFAQBuueUWm9tERCRhYkdETlNbW4vr16/jypUr+PHHH/HGG2+gWbNmmDBhAgDdejVJXV0dhg8fDlEU8c9//hMvv/wyBEHQP19aWopff/0VXbp0UXy/5s2b47bbbgMAdOrUST+aJnn88ceRmpqK9957D61atQIApKeno7i4GHPmzHHKZzJVV1eHF198Ed27d8eWLVug0egmRsaOHYtOnTph/vz5+Omnn9CuXTt9gpuQkIDY2FhV7SEisoRTsUTkNAMHDoS/vz+aNWuG8ePHo02bNtiyZQtat24NANi2bRvuvPNOhIaGws/PD/7+/vjb3/6Gc+fOobS01OhePXr0sJjUqfHkk08CAJYtW6Z/7MMPP0T37t0xdOhQp3wmU8eOHUNxcTGmTZumT+oA4KabbsLkyZOxZ88eXL582YFPRUSkjCN2ROQ0//73v9GtWzc0adIErVu31k8vAsC+ffswcuRIDB8+HMuWLUO7du0QEBCA9evX4+9//zuqq6uN7mX4Wnu1bt0aU6ZMwSeffIKUlBT88ssv2LVrFz755BOnfCY5586dAyDf/ujoaNTV1aGiogLBwcG2fRgiIhWY2BGR03Tr1k2/g9TUV199BX9/f2zcuBFNmzbVP75+/XrZ6w2nZR3x7LPP4osvvsA333yDjIwMtGjRwqbdrJY+k5zw8HAAQElJidlzxcXF0Gg0CAsLU30/IiJbcCqWiBqEVOTXz89P/1h1dTW++OILh+4bGBiov5ecPn36ICkpCYsXL8aqVavwyCOPOK2mnpyuXbuibdu2WL16tdFu36qqKqxbt06/U1ZN24mIbMXEjogaxLhx43Dp0iUkJydj69at+OqrrzBkyBB9cmOvTp06ISgoCKtWrcKOHTtw4MABszImzz77LPbt24fq6mrMnj3bofezRqPR4K233kJubi7Gjx+PDRs24D//+Q9GjBiByspKpKWl6a/t3r07AOCf//wndu/ejQMHDuDixYsubR8R+TYmdkTUIG6//XZ89tlnOHLkCO666y689NJLuPfee5GSkuLQfYODg/HZZ5/h3LlzGDlyJPr164dPP/3U6JqJEyciMDAQo0aNws033+zQ+6mRnJyM9evX49y5c5gyZQqmT5+O5s2bY/v27Rg8eLD+uuHDh2PBggX49ttvMXjwYPTr1w8HDx50efuIyHcJomllUCIiH/Ptt99iwoQJ2LRpE8aOHevu5hARuQwTOyLyWb/++itOnjyJZ599FiEhIcjOznbapgwiIk/EqVgi8lmzZ8/GhAkTEBYWhjVr1jCpIyKfxxE7IiIiIh/BETsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEcwsSMiIiLyEUzsiIiIiHwEEzsiIiIiH8HEjpxKEARVf3bs2OHQ+yxatAiCIDin0fUM2+fn54ewsDD07NkTjz/+OPbs2ePQvd98802sX7/eOQ0lIo/QUPEOAC5fvoxFixapvldBQYFRG/z9/REeHo5+/frhueeewy+//NJgbaGGJYiiKLq7EeQ7TBOg119/Hdu3b8e2bduMHr/lllvQvHlzu9/n9OnTOH36NAYOHGj3PUwJgoB7770Xf/nLXyCKIi5cuICff/4Z//73v3H48GE888wz+Oc//2nXvW+66Sbce++9+Ne//uW09hKRezVUvAOA8vJyREZG4pVXXsGiRYusXl9QUIC4uDg8/fTTSE5ORl1dHSorK5GTk4PPPvsMJ0+eRGpqKl588UWXt4UaVhN3N4B8i2miFRkZCY1GYzUBu3z5MoKDg1W/T7t27dCuXTu72mhJ69atjdo6atQozJ07F4899hjef/99xMfH48knn3T6+xKR97E33jWk9u3bG7Vn7NixeP7553HPPfdg3rx5uO222zBmzBg3tpCcjVOx1OCGDx+O2267DTt37kRSUhKCg4Px6KOPAgDWrl2LkSNHIioqCkFBQejWrRtSUlJQVVVldA+5qdjY2FiMHz8eGRkZ6N27N4KCghAfH4/PPvvMofb6+fnhww8/REREBN5++23941euXMFf/vIX9OrVC6GhoWjZsiUSExPxzTffGL1eEARUVVXh888/10+LDB8+HABQVlaG2bNn45ZbbsFNN92EVq1a4fbbb8euXbscajMReYaamhq88cYbiI+PR2BgICIjIzF9+nSUlZUZXbdt2zYMHz4c4eHhCAoKQvv27TF58mRcvnwZBQUFiIyMBAC8+uqr+jjyyCOP2NWmoKAgrFixAv7+/kYxTU08staW33//HdOnT8fNN9+M4OBgtG3bFnfddReOHDliV1vJdhyxI7coKSnBgw8+iHnz5uHNN9+ERqPrY/z2228YO3Ys5s6di5CQEOTl5WHx4sXYt2+f2fSGnEOHDuEvf/kLUlJS0Lp1ayxfvhwzZsxA586dMXToULvbGxQUhDvvvBNfffUVTp8+jXbt2uHq1as4f/48XnjhBbRt2xY1NTX4/vvvcc8992DlypV46KGHAAC7d+/G7bffjhEjRuDll18GAP20zPnz5wEAr7zyCtq0aYNLly7h66+/xvDhw/HDDz/oE0Ai8j51dXW4++67sWvXLsybNw9JSUk4efIkXnnlFQwfPhwHDhxAUFAQCgoKMG7cOAwZMgSfffYZWrRogaKiImRkZKCmpgZRUVHIyMjA6NGjMWPGDMycORMA9AmWPaKjo9GnTx9kZWXh+vXraNKkiap4ZK0txcXFCA8PR1paGiIjI3H+/Hl8/vnnGDBgAHJyctC1a1cHf6tklUjkQg8//LAYEhJi9NiwYcNEAOIPP/xg8bV1dXXitWvXxB9//FEEIB46dEj/3CuvvCKa/ufboUMHsWnTpuLJkyf1j1VXV4stW7YUH3/8cattBSA+9dRTis/Pnz9fBCDu3btX9vnr16+L165dE2fMmCEmJCQYPRcSEiI+/PDDVtsg3eOOO+4QJ02aZPV6IvIcpvFuzZo1IgBx3bp1Rtft379fBCAuXbpUFEVR/O9//ysCEHNzcxXvXVZWJgIQX3nlFVVtyc/PFwGIb7/9tuI1U6ZMEQGIZ8+elX1eKR7Z0pbr16+LNTU14s033yw+99xzqtpOjuFULLlFWFgYbr/9drPH//jjDyQnJ6NNmzbw8/ODv78/hg0bBgA4evSo1fv26tUL7du31//ctGlTdOnSBSdPnnS4zaLMPqP//Oc/GDRoEG666SY0adIE/v7+WLFihaq2Sj7++GP07t0bTZs21d/jhx9+sOkeROR5Nm7ciBYtWuCuu+7C9evX9X969eqFNm3a6HeV9urVCwEBAXjsscfw+eef448//miQ9snFNEfj0fXr1/Hmm2/illtuQUBAAJo0aYKAgAD89ttvjGkNhIkduUVUVJTZY5cuXcKQIUOwd+9evPHGG9ixYwf279+P9PR0AEB1dbXV+4aHh5s9FhgYqOq11kjJYXR0NAAgPT0d9913H9q2bYsvv/wSu3fvxv79+/Hoo4/iypUrqu753nvv4cknn8SAAQOwbt067NmzB/v378fo0aOd0mYicp+zZ8+isrISAQEB8Pf3N/pz5swZlJeXAwA6deqE77//Hq1atcJTTz2FTp06oVOnTnbvwlfr5MmTCAwMRMuWLQE4Jx49//zzePnllzFx4kR8++232Lt3L/bv34+ePXsypjUQrrEjt5CrQbdt2zYUFxdjx44d+lE6AKisrGzAlsmrrq7G999/j06dOul343755ZeIi4vD2rVrjT7P1atXVd/3yy+/xPDhw/HRRx8ZPX7x4kXnNJyI3CYiIgLh4eHIyMiQfb5Zs2b6fx4yZAiGDBmC2tpaHDhwAB988AHmzp2L1q1bY+rUqU5vW1FREQ4ePIhhw4ahSRNdKuCMePTll1/ioYcewptvvmn0eHl5OVq0aOFwu8k6jtiRx5CSo8DAQKPHP/nkE3c0R6+2thZz5szBuXPnMH/+fP3jgiAgICDAKKk7c+aM2a5YQHnUUBAEs897+PBh7N6924mfgIjcYfz48Th37hxqa2vRt29fsz9yGwn8/PwwYMAALFmyBACQnZ0N4EZcdMaoV3V1NWbOnInr169j3rx5+sfVxiNLbZG7x6ZNm1BUVORwu0kdjtiRx0hKSkJYWBieeOIJvPLKK/D398eqVatw6NChBmvD2bNnsWfPHoiiiIsXL+oLFB86dAjPPfccZs2apb92/PjxSE9Px+zZs3HvvfeisLAQr7/+OqKiovDbb78Z3bd79+7YsWMHvv32W0RFRaFZs2bo2rUrxo8fj9dffx2vvPIKhg0bhmPHjuG1115DXFwcrl+/3mCfm4icb+rUqVi1ahXGjh2LZ599Fv3794e/vz9Onz6N7du34+6778akSZPw8ccfY9u2bRg3bhzat2+PK1eu6Ms03XnnnQB0o3sdOnTAN998gzvuuAMtW7ZEREQEYmNjLbbh1KlT2LNnD+rq6qDVao0KFL/77rsYOXKk/lq18chSW8aPH49//etfiI+PR48ePXDw4EG8/fbbLqk7SgrcvHmDfJzSrthbb71V9vqsrCwxMTFRDA4OFiMjI8WZM2eK2dnZIgBx5cqV+uuUdsWOGzfO7J7Dhg0Thw0bZrWtAPR/NBqN2Lx5c7F79+7iY489Ju7evVv2NWlpaWJsbKwYGBgoduvWTVy2bJls23Jzc8VBgwaJwcHBIgB9e65evSq+8MILYtu2bcWmTZuKvXv3FtevXy8+/PDDYocOHay2mYg8h1y8u3btmvjOO++IPXv2FJs2bSredNNNYnx8vPj444+Lv/32myiKorh7925x0qRJYocOHcTAwEAxPDxcHDZsmLhhwwaje33//fdiQkKCGBgYKAKwuNNe2hUr/fHz8xPDwsLEPn36iHPnzhV/+eUXs9fYEo+U2lJRUSHOmDFDbNWqlRgcHCwOHjxY3LVrl+o4TI7jkWJEREREPoJr7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfATr2Nmhrq4OxcXFaNasmewJCkTkWmJ9ncHo6GhoNOyfOhtjHJH7OBrfmNjZobi4GDExMe5uBlGjV1hYyMKnLsAYR+R+9sY3JnZ2kM73KywsRPPmzd3cGqJG4tNPgRdfBABcABAD47M2yXkY44gaWFkZMG4ccOyYw/GNiZ0dpKmJ5s2bM+gRNYQlS/RJHQDghReAd97hNKGLMMYRNaDSUmDCBODYMd3PbdsCRUV2xzefWJyydOlSxMXFoWnTpujTpw927dqleG1JSQmSk5PRtWtXaDQazJ07t+EaSkS2W7IEmDPnxs8vvQT89a/ua48bMMYR+ajSUmDECODXX3U/x8QAGzc6dEuvT+zWrl2LuXPn4qWXXkJOTg6GDBmCMWPG4NSpU7LXX716FZGRkXjppZfQs2fPBm4tEdlELql7/XWgEY3UMcYR+Si5pG77dqBjR4du6/VnxQ4YMAC9e/fGRx99pH+sW7dumDhxIlJTUy2+dvjw4ejVqxf+7//+z6b3vHDhAkJDQ6HVajlNQV6vRFuN/PIqxEWEICo0yN3NucFCUteYvoOMcUQ+SCmp69TJ4e+fV6+xq6mpwcGDB5GSkmL0+MiRI5GVleW097l69SquXr2q//nChQtOuzeRO63dfwoL0o+gTgQ0ApB6T3dM6dfe3c3iSF09xjgiH2QhqXMGr56KLS8vR21tLVq3bm30eOvWrXHmzBmnvU9qaipCQ0P1f1gGgHxBibZan9QBQJ0ILEz/GSXaavc2jEmdHmMckY9xcVIHeHliJzHdOSKKolN3yy1YsABarVb/p7Cw0Gn3JnKX/PIqfVInqRVFFJRfdk+DACZ1ChjjiHxAAyR1gJdPxUZERMDPz8+s51paWmrWw3VEYGAgAgMDnXY/Ik8QFxECjQCj5M5PEBAbEeyeBjGpM8MYR+QjGiipA7x8xC4gIAB9+vTB1q1bjR7funUrkpKS3NQqIu8QFRqE1Hu6w68+cfITBLx5z23u2UDBpE4WYxyRD2jApA7w8hE7AHj++ecxbdo09O3bF4mJifj0009x6tQpPPHEEwB0UwxFRUX497//rX9Nbm4uAODSpUsoKytDbm4uAgICcMstt7jjIxC5zZR+7TG0SyQKyi8jNiKYSZ0HYowj8mINnNQBPpDYTZkyBefOncNrr72GkpIS3Hbbbdi8eTM6dOgAQFes07TeU0JCgv6fDx48iNWrV6NDhw4oKChoyKYTeYSo0CD3lTlhUmcVYxyRl3JDUgf4QB07d2CNJyIncCCp43fQtfj7JXKQA0mdo98/r15jR0ReiiN1ROSr3DRSJ2FiR0QNi0kdEfkqNyd1ABM7ImpITOqIyFd5QFIHMLEjIgtKtNXIOlHunNMomNQRka/ykKQO8IFdsUTkGk49R5ZJHRH5Kg9K6gCO2BE1GiXaamw8XIxvDxVZHYFz6jmyTOqIyFd5WFIHcMSOqFFYu/8UUtYdgVTbSACQNll5BM7SObI21bxjUkdEvsoDkzqAI3ZEPk8afTPM00QAC9YdURyBk86RNSR3jqzFNXhM6ojIV3loUgcwsSPySYYJ14GC82ajbwBQB6Cg/LLs69WcI7t2/ykMStuG5GV7MShtG9buNzj9gEkdEfkqD07qAE7FEvkcw00PltIoDWA2AmfI0jmySmvwhnaJRNSXnxkldR8mTUHkhFmYwqSOiOxQoq1GfnkV4iJC3Hf8ocTDkzqAiR2RTynRVmP+uiP6n5XOCxQApE7urg+SSoFT6RxZpTV41f/4AHh1vv6xDxKn4N3BD8Lv618wtGsr9wdlIvIqTt2d7ygvSOoAJnZEPmXefw9bveaZ2zvj/gHt9UmWPYEzJMDP7LFp2RvRcevH+p8/SJyCd4c8CAiC2cYLpUTS8HEAntNLJ6IGZ2lmAGjg+OAlSR3AxI7IZxwqrMCu38otXuMnCEZJncUpVZNgKSVdR4q0WLwlz+i5adkb8bpBUvdhkm6kDgZr9KRpX6VEUm4KWYQH9NKJyC2UZgZW/pSP5bvyjWLI0C6Rrkv0vCipA5jYEfmMfQXnLT6vEWC2AUJtWRPDpMuUXFL3jklSJ72vXCK5YN0RRNwUYPS44dvI9dIjAmqt/DaIyNtJu/MN445GAJbtzNfHiDoRSFl3BEL9dc7sCJZoq3H6WAF6PTwZ/nlHdQ96eFIHcFcskc+orLpm8fn3pyaYBTs1ZU1MkzFDpkndB4nGSZ0GwKcP9UZMy2AcKqzAmn2nzO5TB2Dm5wdl7y+pFUWszCzQ78Id+Y+dFj8rEXk/ud35MwbHma0dFgHnFFM3sHb/KUx4OR2hY0d7VVIHcMSOyCeUaKvx0Y8nFJ/3EwT0iQ3TT6eGBPihqqYWcREhmJTQFuuyi/TXTkyIBgBknShHSIAf9imUS5FL6qQ1dZI6ADM+P2i1/RZyOgC6qdnlmX8YBW8i8n2mu/MBYEVmvtWOoM3F1A2UaKvxzhe7sGr1QnQ5pyvjVNw8Ek02bEErD0/qACZ2RD5BbkpVIk2F7jxeZjbyphEA0eR16TlFSM8usphsqUnqnGlcjzbYePiMS+5NRJ7NdHd+6j3dsTD9Z9SKIjTQdQwN45VcMXVbnD5WYJTUFTWLxP1T38TiZm3Qyu67ynNFKRcmdkQ+QGktyvtTE9AnNgwAMChtm/k0qEz2ZpromXJVUmfafokAYNaQjth85AxH6ojIbBRv5/EyfaInV0zdJqWlujV1hknd/W+iqGW0Q8miHLmNZEO7ROLn/HMO3ZeJHZEPkNaiGAa3eWO6ouVNAQAsj+jZwtlJnZTMSe1dvCXPrJ0pY+LRMybM7PMRUeMgN6plOIpnqZi6Lc7+fhLNxoxC8O/HAOimX++fqkvqHEoWZchtJEtJPwKIQO1V+ROB1GJiR+QjDIPb4dOV+iRJIwDzR8crj4gJAETr69ycndQ9NqQjpg+ONQrGLYL8b0yxCMD8MfF4fGgns88XHnAdXf9h19sSkRdRW2dTqZi6NVLS+NuRP5A4689oXa4bqatqHY0mGf/D4mZtHEoWlch1tq3NlqjFxI7Iy1gr7hsS4IfFGXlGPcG3Mo5h9G1tsPmI8To1QQDS7umOQ6crsXpvoeJ7qk3qDOvPWaIBMH1wrFkwttbzlq4/XnjWyjsQkbezpc6m3GutrV2TksawS5VYs8Z4Td2DE1/D6riOSHRR8WO55TPOwsSOyIuoKu4rsyGiVhSx5YjM5gMRiG/TDCkGx5CZUpvUJfdvj6fv6IzPMvOxbFe+4v00sHycmbWe99r9pzB/zV7F54nIN6ipsymXwKkZ5ZOSRrmk7v7738SpFm0c2llrjenyGWkjmzPyPCZ2RF5Cqfca36aZcXFfmcigga70iCkRwP6CCsVgojapm9grCk/f0RlRoUF4dHAclu/KN7unRgBmDu6oH6kDbD/OzFJNPSLyLXKjWtZOsRnaJVLVKF9+eZVyUhcW5fDOWjWUNoHIxWpbsEAxkZdQ6r3uL6iQTXSkL7efIGD+mHizQsTSNXEKwcuWNXXrc0swKG0b1u4/hajQIKRNvlFUVAPgsaFx+CnldkwfHIv88iqUaKsVE1VLhUWdtQmEiDyfXIFiS6fYLEz/GQdPmsdDaZTPUCexCmu+Uk7qHN0sUaKtRtaJcquFkqNCg5DYKRxRoUGY0q89MlNG4LOH+9n9vgBH7Ii8hlLvtV9smOzjnz7UG/nll9EvNgw9Y8LQItgf8w2mXAXoNifkFlaavZc9GyUMe8Zya+VMe9czBsdZnGaRm2LR/w5s+s0RkbdSWner1NGFaF46SSMA5ZeuoERbrXt9aSla3z1Wv1HCMKkTBGDemK5mMweHCiuwr+A8+se2RM+YMItttnUmwlBUaBBCOrZUda0SJnZEXkKppElVTS3mj4nHW1uO6R+fmBCNWf8+aBRYAOOA17VNM6RtyTObMnVk96thYma4Vk6ud708Mx/1G3L1pOkPpcAo/Q5S1uyz87dIRN5Gbt2tUke3T6xxaSRpzfHTa3KhEYCnb2uOOW88rj8mzDCpA3TXvrXlGCb0jNa/51/+X67R6TyTe7fFu/f1km2rIxs+nIWJHZGHULOLy1pJkx7tWuByzTWjY7zqRGD+uiNmQTDvzEWz+zta0kQDIDYiGCXaanx/9CxKL1zBnd1ao6qmVnFrvxR4pekPAIqBEQBiWgbjy5n9MJjlTogaLbmOrjR9KsXJ7JMVmLM6R995DLtUiXHPztYXH5bq1ElJncSwg3qosMIoqQOAddlFeCixg+zI3UqZ484cPeLMVkzsiDyALUP3UaFBKL1wxWi0TSppMm9MV6RtzpN9nbW1aaZJ3YcqkrrHhsZh2c4bGyVEAO98d8woEH6w7QS6tblJdrcuAAgi8GFyAnp3CENUaBCyTpTLBsaVmQU3zoutcayAJxF5P0vlkaJCgxAWUqWPTeFVMhslZJI6wHiDxr6C87LvfaCgwiyxK9FW41OZigAaAS7fiGH0fg32TkQky9ZNBGv3n8LEpVlmU6i1oig7taqG3EjdO1aSOj9BwIA447UgImDWuwWAo2cuKRbfrAPQMiTQbB2dIQ1wI6mDa2o/EZFzqN044AyGmw9M31uKJbJJ3f3ySZ1GgNHGif6x8uvd+sbeSOqk93z/h99kr505uGODjdYBHLEjcjtLtZqk5+MiQgAABwrOIyX9iGKSZE/lcnunX7tFNcPMfx90uO6SNH0rkavvNLV/jMUCykTkGRzZOOCK935veBRueXC2YlInLVHRAJg5NA7jukehqqZWv9GiZ0wYJvdua9RhHXJzBFo1b2r2nnIE6IqxNyQmdkRuprQI+HBRJR5YvkdXdLj+cXuTKNNNChJH1tT9XHzBztYYEwHsPF5mFPyn9GuPysvXkFa/hnDN3kLFz0BEnsFZGwesrTcu0VbjQMF5CIKAPvVLOOTe+90vMvHT1jfgL7P7FdDF2fTZibhcU6evIzdpaZZZUvrufb3wUGIHLNv1BzYePoNdv5VjUNo2zB8db3TKj5xZQ+MadLQOYGJH5HZRoUG6ALElD3XQBZt5o7vqN0YA9iU0homQs5M6ZxJxo9ByVU2tfnRycUaeUfsF3Ohd+zVwG4nIOjUnRSiRkrkjp7X6ZEluxG/t/lNIWXdEHxsEAGmTuyOmZbDRe4dXVeLLNQv1GyUQE4Odi/+F04erAYPNWtI6OWtJaavmTY2OZKwToY/ZSjQCMH1QnMXP7QpM7IjcbO3+U7pABl1O9cTwjtBoHF9HZunlnpLUSWpFUbdu0EKNOxHAB1MTEH5TIMIDrqMrd8USeRRrJ0UoUZrONE2uSrTVRkkdoIsLC9KP4OvZSfr3Nl1Th5gYYPt23N+pE4aPrZbdbGEtKZV7XorZcktgnFHk2F5M7IjcyLSXKIrAku0nXPqerkjqnHGYtWjQU16hUOOuT6xu2uXCBedMAxOR81gqQaLE2jGBpsmV3GV1InC5pg6p93THu19k4kuZpA6dOunbKNcea0mp0vPzxnQ1qiH65PCOaBEcoC8M7w5M7IjcqKGPyHJVUrfsoT76gsjWSAWU1+cU6zZHwPwkiTpRV0plxa4C1X9BEJH7TenXHvFtmmF/QYWq5MZaDDRNruRI5UQSm9Xinq1vGE2/GiZ1llhLSpWen9KvPSb0jL5RW9TCNHJDYWJH5EZyvUBXcdX0a50I7M0/bxT05GgAfGBQr+6FUV1RUH4ZwQEa/YJliZ8gYPqgOEwfFCc7bUJEnsnWXbGWYqC03ji/vAqAbpOV6Ui+AN3SDU1ZKXD3WP2JEmqSOtNNGpbq4gHKdfOk/5c2uwHqN46oKUxvKyZ2RA3I9Ets2gt0FVevqVu2Mx/rn0pCZsoIfdDbcKhYvwFE6t2O6xGtf43hlIi1njIReT57dsUqHZXYo20LHC66cbqOXGUAKclLz8jBnx9ZqD/7VU1SZ+nYQksxR+l5ezaOuKo0DBM7ogai9CWWeoEHCyqQ9cc5fLXvlP4aZ4zkNcRGCRHAxKVZSLunO4Z2iUR+eRUm9IzWT1FYG3Gz1lMmIs9n765Yue9/ibbaaARMLhSKMN8oUduuHfysJHWHCiuMNmE44zxXWzeOWEqCQxwMzT5x8sTSpUsRFxeHpk2bok+fPti1a5fF63/88Uf06dMHTZs2RceOHfHxxx9bvJ7IUdZOl9h5vAzPfJWD1XtPQRSB5AExWDThFrMTGGxla1I3pW87LBgTD3veVhSBlPQjSErdhuRlezEobRt2Hi8zqgpviWkFebqBMY68gdypMWp2xQLm338164/lTpT45JXlFpO6T3aewMQl8if3SEXh7SGNPEqlmKytC7ZWmN4RXp/YrV27FnPnzsVLL72EnJwcDBkyBGPGjMGpU6dkr8/Pz8fYsWMxZMgQ5OTkYOHChXjmmWewbt26Bm45NSaWvsRmO2MBrN5biL9986tDI3b2jNQN7RKJFsH+UMrsrA3yiSLMesGmxwo15HFDvoAxjtxN7XfW1uTG0vudu3TVYgdT6Ziwd05cl22nLs4eRupm+WMXTRNQe+LUlH7tkZkyAmtmDURmyghVawsttcFegii6cGFPAxgwYAB69+6Njz76SP9Yt27dMHHiRKSmpppdP3/+fGzYsAFHjx7VP/bEE0/g0KFD2L17t6r3vHDhAkJDQ6HVatG8eXPHPwT5vBJtNQalbTMbps9MGYH88iokL9vr1Pezd/p1eNdI7DxepphQ3hHfCj/kldrUljWzBiKxUzgA560paUzfQcY4cid7vrMlWvlacba+nyHDNXbWzn41jDnSPU3r3xnSAEidfONzNdSxaGv3n5LdZevo98+rR+xqampw8OBBjBw50ujxkSNHIisrS/Y1u3fvNrt+1KhROHDgAK5duyb7mqtXr+LChQtGf4hsYaknGxLgZ9NyN2tfWkfW1O04ppzUAbCY1GkE84E+wx6oteloMscYR+5k73fW3mUVlmraCQKQMiYeEVaSOgAIDrgRJaV7KoU1QQC+fipJn7g1ZJyyZYTPFl6d2JWXl6O2thatW7c2erx169Y4c+aM7GvOnDkje/3169dRXl4u+5rU1FSEhobq/8TExDjnA1CjYvglTp+diJiWwXjlm59x95Is2crlcoZ3jUCfWOW6UO46UUIA8PXsJKRNvpG8agDMG93V4poZZ60p8VWMceRODf2dtbSurk4Eegddw+7v/24xqQOAwvM3kjBra/VSxsQb1dpr6M/sirXFXp3YSQSTv7REUTR7zNr1co9LFixYAK1Wq/9TWFjoYIupsYoKDcKp81WYtDQLycv24vPdJ216/Y5j5dhfUCH7nDuPCZs1NA49Y8IwpV97zBvTFYKgKzq8OCMPa/frgrAr15T4OsY4coeG/s7KvZ+k1WUtej18j75OXW27dnhn/hKzpA4AKqtrjO6p9E1J7h+Dx4cab7TwhTjl1YldREQE/Pz8zHqupaWlZj1WSZs2bWSvb9KkCcLDw2VfExgYiObNmxv9IbKHteNz7OXOpM7woOsSbTUWb8kzOh5MmsZw1sLqxoQxjtzJ3u+s4cYD6Z8PFVbIbkYwfD6/vArzR8ebha2Iy5XYunGRPqm7GtUWx1d/g68vyidbLYICjD5Dyph4s2s0AvD0HTc77TN7Eq+uYxcQEIA+ffpg69atmDRpkv7xrVu34u6775Z9TWJiIr799lujx/73v/+hb9++8Pf3d2l7yfs5WiXcFUeIWUrqRsRHYntemVPfz3ARs7SwWM10q5rK7mSMMY7czdbvrOHGA7miwoabEeQ2SpieLBFeVYnVaxYitH76tbh5JKbetQiFm0pk318AzJarPD6sEyAAaQY7YkVRV2ZKbl2bt8cprx6xA4Dnn38ey5cvx2effYajR4/iueeew6lTp/DEE08A0E0xPPTQQ/rrn3jiCZw8eRLPP/88jh49is8++wwrVqzACy+84K6PQF5i7f5TGJR2o0abNMVoytI2eUtTDfawNlLn7KQO0AVdw+BoSM00BuvV2YYxjtxN7XdWrnSTaT9WGsU/VFghO3thmtSZbpSYOlW3pk6pf5wyJl62nRN6Rhv9LMLypghvjlNePWIHAFOmTMG5c+fw2muvoaSkBLfddhs2b96MDh06AABKSkqM6j3FxcVh8+bNeO6557BkyRJER0fj/fffx+TJk931EcgLyO2UWrDuiFmlcmvb5HceL1O9UcIad06/SqTgKP0eTI8HMt1AQbZjjCNvoXZGolYUsb+gwuK11kqaSKTTHjQCMH9MvNmaOcO2KRUl9rX45PV17NyBNZ4an6wT5bK15h4b0hELx3VDibYaB09W4OnVOUbBQ6pVJx2RY1rLTo4gmI+EmfKEpM6Qad2oT3aeQFr9WjtX1IHid9C1+Psle6iNcRroSoxMWpole63apM5PEJA+OxGXa+qsTplaqiXqaYldo65jR9RQlHZWLc/8A5/8eAKD0rZhjklSB+h6hGv2nsIXewqwpv4MWGvG3RalX7grxxVJnQbAU8OVj+GxRK5iu+kGigXpR1ivjsjHSSP21hILEUDemYtGmxQkapM6AcCb99yGnjFhiI0IRn55lcUY4wubItTy+qlYIleTNkzc3z8Gq/cZl4GoE6EbmbLw+ve3/W7T+03qHY1JvaMx4/ODZs+5aqRu2cN9cEe3Njhz4QrWZRfpHzddyGxKLjjKTcfUicDKn/KxcOwtDrWTiLyASeAwjSPSEo7MlBHITBmBgvLLyPy9DP9v40GsMknqHlBI6tY/lYSeMWE2nRIhtynC0Q1xnoiJHZEFpkHDNEBJ6zucSS6hAxxP6iwlacEBut2S797XCw8ldsC2o6WIaBaIHu1Ccbqi2mw0UiMA709NQJ/YMLNgKG2gMP29LN+Zj+mD4nwmeBKRMaVyTnJxR1rfJm1QSGxWi7lz/w7/+qSutl07nP38a6zpcyt2Hi8zS956xoQpnhJhuvbZkLQWGGi4o8MaGqdiiRTIBQ0IN740foKA+WPizXaBCjA/WstRjiZ1foKAe3q3VXzOcCo178xFfLD9d7z8zS+YtDQLl65eNzpRwk8QkHpPd4zvGa3v8RruAo4KDcKMwXFm71MH8JQJIg9lz6H3pmwp52QUd0pLgREj9HXqEBMDvx070Pv2vvoyST+l3I41swbip5Tb9cmXI6dE+PIRhxyxI1IgFzREEfgwOQEtQwL1Q/ktgvyNDnKeMTgWn+7Kd1o7rCV11jZbfHh/AmJaBmHSUvOzRTUCjKZSlYKd4ZSJ4SJl05pVs4bEYfrgODw6OA7Ld+WbbSTxpurtRI2Fs0aulEbrTRkt4ahP6vDrr7onY2KA7duBTsZrfg1H2iy9n9o4Y63mpjfjiB2RAqWabL07hBnVN5rSrz3SZyfir+O6IX12IgKaOO9rpWakztoO2u+PnkVVTa1ssH1/agKGdonEt4eKsPFwMQ6eNC9BUCuKyD5ZYVbXSa5m1ae78jEobRt2Hi8zG+Xz1YXKRN7MmSNXphsU5GgAfPpQb8S0DMbZ309aTOqsjSI6siHCF44OU8IROyIFpjXZlILG2v2nkLLuiH50ylnTsM7aKLE+txhtw4Jke7ZF2mo8nWq8fk5uLd6c1Tm4dPW6US9eadrF2igfEXmGEm01Nh4udurIlbRBYWVmAZbt+sO8QDGAmf8+iJaXKrHmq4VoXV5fg9EkqVM7imjtlAilzRFq47s3YmJHVE8uABgGjeAADapqavW9x/zyKoQE+BkldYDlXaRKNABem3grWgQFYHnmH+j+zSqn7n79aPsJzB8Tj7cyjukKBwvAE8M7Gh2xY9QekyTQtBAxYHnaxXRhNBF5FrnjvCTOGLlanmme1ElaXjIvaZLzz1UYX5/UHSqsQEr6EbMzp5U2RchN0wLWk0NvPzpMCRM7IlgOAFGhQUa7spxNAyB1su79XvnmZ6cndYCul9yjXQvMG90VaVvyUCcCS7efkA28IoCnR3Q2K9NSK4o4WFCBljfdSH5T7+mOBeuOoM70MwnwiSkNIl+ktHsVsH/ZhGHHWGk0XwDQUqFOXdG+i+hzezV2Hi8z6ywDto8iWtsxa9hew+LqvoCJHTV6agKAq5I6AJg6IAZT+rXH2xl5qFuyxKakzk8QMG90V4QE+uGv639RfA8/QUBwgAaLMwwOwbbQppiW8sHz6a9yzE6TkJt2sXTANhG5l1Li9fK4bhjbI8rmpM60Yzx/dLzZaL5GAP41rgPaTJwtX3y4fi3vgnTzpE5yuKhSdRJmaXOEXPkUX4pV3DxBjZ61LfO2bOG3x+q9hXjnuzxceO+fNiV1L4/rhsyUEXh8WCd0jLxJ8f4aAZjSPwbfHz2r+nNoq6/LPm46NVKirUZUaBCmD441vg6+UzqAyNcobRyQS+qsbWCQ6xi/lXEM88fEG21qeG94FBJn3ad4ooSfIKBOFC3GqLe2HFMdU+Q+owZAcIDGZ8ucSDhiR42etS3z1rbwWzudQQ3tu7YldRropjo3Hi5G/9iW+iPPTNshQNfu1XtPmd+k/j6iyev8BAGVl2usttlwaqQxHbBN5O1s2RhmbWRLqWPco20L/eapjuIltL57LFBfp840qdNAV3apb2xLi7HWlpgifUbDaV0RwKbDJT5b5kTCxI4aBUvHxpgGOY0APGowAmVpLRkAPDSwAz7fc9Luttmz+7VNaFOjEyrG3tYG47q3wcYjZ4yus5Zwzh8TDwBYvCUPdbgxtbs4I8/sWtPE0Vry6yulA4h8kZrdpGpOdVDq+ErTplFXLwIjxupLmhQ3j8T9Uw2SOgH4erbueDAARrHYlK0xZWiXSKM6nyKA5bvyfT5WcSqWfN7a/acwKG0bkpftxaC0bVi733z0akq/9shMGYHHhsZBFIFl9fXYpGun9GuPnxbcjseGdNQP72sEYM6ITrguyqV76thb0qRYe8Xo580/nzFL6tQ4d6kGizN0SZ0gAPPGdEX3dqGyPeZZQzrqp1aUkl/WrSPyHqa1KQ2pPdUhKjQI80fHm73+rS3HZOvUZf9rHYpaRgO4cYqNlNQBN2LxmlkDsWBsvEMxRfbcagAzB3f06VgliKK18qZk6sKFCwgNDYVWq0Xz5s3d3RyyoERbjUFp28x6Z5kpI8y+yIcKKzBxSZbZqJTptSXaamSfrEDm7+VYu7/Q7vV3zqpTp0RT31NVap4GAGR6rumzEzFpaZbs7wwAVv6Uj2U7dadKmE7PlGirG6R0AL+DrsXfL9kSO7NOlCN52V6jx8KrKrEr43UE/35M94BBnTpb4oQjMaVEW42k1G1mdTqzFtwOAB5b5sTR7x9H7Minqe11rt1/ChOXZimuEzNcQLzzeBmeWp2DNfs8N6l7eVw3/JRyO9Imd5e9pZ8gYOaQONnfzeWaOqTe010fHKT1L1LwMzwqzHThsaURACLybIZxzpZReNONCuFVuuLDckkdYFuccHpMEVx0Xw/CNXbktSytm5OoWfslrSWRG7v2EwQcLqrEA8v36BcQW0rmpg1sD40g4PPdymvuHE3q/AQBPWNCkX2qUvGa63Wi/vDsoV0ikX2yAqKoK2NyuaZO//mXZ+bL/m5Ona+6sajOoFm+fL4iUWOmtFFCTQFfw3XKLS5VGNWpUzr7tSHIbeoSRfh8vFKd2D3//POqb/ree+/Z1RgitdQeN6Nm95dSORMNoNtIUF/QF7Cc1GkE4N4+7dAzJgzRLYKQusV8A4KjSZ0GQPrsRPSMCcPb3+VhyfYTste9lXEME3pF6yuy9+6g+5ytmjfVf+a4iBDZ3w0AxUXTvrxJgjGOGitrGyXUJEFT+rXH8DARmjvuQGR9UlfcPBLZ9SdKqOmIO5svxytLVCd2OTk5qq4TnDSVRKRE7W4tidKxYJaOxpJ2alXV1Kqebq0TgUlLs5B6T3e0CPY3e94Z0691AC7X1KFEW42PdsgndYDxKJphEiy9k+H6ONPzXLNOlCuOyiV2CvfZ8xUZ46ixcspIfGkpWt41Bv6ndHGpqJlu92vRvosoCj+h7yA3ZEFgXz4P1hLVid327dtd2Q4i1ewJQlGhQdhwqBhpW/LMTk6ICg3CpIS2WJddpL9+UkJb9IwJw6HCCqPt8tbUiZA9DsdZa+qk3qaaosmHiyoRGxFslAQbvkRKiDNTRhhVc7fWy/XV8xUZ46ixcnhkq7QUGDEC/nJ16kRRH3cB6x1xZ/PVeGUJ19iR17EnCH3y4wmjqVHD4AIAX+cUGV3/dU4RApposHZ/oeqkTuKqpA4AJiZE6wOTtfV+b205hujQphavkUuI1fRy1U7PEJF7mU6Byk2JOjSyVZ/USSVNTIsPCzDvGDf0utzGFq/sTuwqKyuxYsUKHD16FIIgoFu3bpgxYwZCQ0Od2T4iM7YGoRJtNdJk1rvViiI2HS5BG5nkp04E1uwrdLitzt79uj6nGC+M6mpeVBkwK56sK7YsWEwANQJQfumK0dQ0IN/LNfwLAUCDr5dpaIxx5O1M1yJPSmiLr3OKZKdEpe/8wYIKQAD6dAizcnfIJnXJ97+JwvqkDpAvt9QY1rm5k1117A4cOIBRo0YhKCgI/fv3hyiKOHDgAKqrq/G///0PvXv3dkVbPQZrPHkGpfpGpj3SjYeLMWe18vopw3VnzuSqkiZrZg3UT50eKqzA/oIKxEUEY9a/D8rWnNp5vEyfAAoAUD+1LNTvepWrR2fK2jq9hj5A29XfQcY4xjhvJ1eHzpRpXTq1m9IAWByps9SZlDrirogZhworsK/gPPrHtjQqeuxtHP3+2ZXYDRkyBJ07d8ayZcvQpIlu0O/69euYOXMm/vjjD+zcudPmhngTBj3PJddDTc8uspq0OeO814m9ovHNoWKIouuSOqm4pummCOmzrs8pNhrFlCscDADZJyswZ3WO1WLM0mst/QWh9DpXcvV3kDGOMc7byRUNliN1FOW+54IAvHb3rbizW2vj77eV6VclL4/rhrE9olwSK/7y/3KN1klP7t0W797Xy+nv0xAc/f7ZNRV74MABo4AHAE2aNMG8efPQt29fe25J5DC53bKGX3RLnDFa901uMe7vHwO/jz9yWfFhEcCG3GJM6BVttEmjTgTSc4qwfnaSvk6dpTVxYSHm9Z2U1r1Y26jhi3XsGOPI2ymd4WrIcEpU7nsuisDL63/B39b/grTJ9aN3Jkldbbt2eGDcKzjV4kZSJ3fqjZ8guCypO1RYYRbr12UX4aHEDl49cmcvu06eaN68OU6dMj9vs7CwEM2aNXO4UUT2ULNTFABev/tWoyrpgC4QOZp2iQBG/bjOpSdKAMDiLXlYd/C0bOHN0xXVqqqpm1aKB5TXvchdq+Z13owxjrxdVGgQZgyOU3zedG2ype+5CF1tS7mzX/127MCTM0YanVCRek93pE02P7UCgP5kC2faV3Be9vEDBRVOfR9vYdeI3ZQpUzBjxgy88847SEpKgiAIyMzMxIsvvoj777/f2W0kUkVtD/XOW1ojoInGbPPFqXOXscRCbThrpmVvxDAnJXWWpobrALzzv+Oyz6ldWGHLBhTTaw3X6flqXSjGOPIFjw6OMzoCENB1Yt+fmoA+sWGyu+FTFE7hCbtUiWZjRgH1x4TVtmsHv/oTJaZ0gmxJEcPHdh4v00/1Onttbv/YlrKP941tfKN1gJ2J3TvvvANBEPDQQw/h+vXrEEURAQEBePLJJ5GWlubsNhKpNrM+kNVBl3RMTIg2W3dmeNTWD0fP4uyFKzh13vGkztaROrnpCokIYOjNEdj5W7ltDRFgtsNViS31nUyvBTz3AG1nYIwjb2a4iSBtsnkHbnzPaNnXTenXHjW1dXh5/S9Gj4dXVWLNmoUIrj9RoqhZJB4Y9wqePO+PKfUnhcmVFJEes7WovK16xoRhcu+2ZmvsGuM0LGDn5gnJ5cuXceLECYiiiM6dOyM42LemY5RwYbHnMd1IMHNwR0wfHKsPKnJJiOliWyUCgHHdozCpd7TZzlNAPql7b8iDEFWM1D02NA7Ld+ablSqRNiSUXriC93/4HdvySvW7UJVGJKVRPnftVG1IDfUdZIxjjPM2cpsIXhjVVXVHrERbjaTUbfoOp5TUdTFI6qSNEmo3Tilt5DDc4e8MhworcKCgAn1jw7w6qXPL5gkAuHLlCn7++WeUlpairq4OBQUF+ucmTJhg722JbCbXG1yRmY9xPdroy55IpzWUXriCqppaVNdcV5XUdWtzE46dvYSNR0qw+ecSo52ngHxS939Dp2HMbW2w+eczFu+tEYDpg+IwfVAcHlqxD7+VXtI/1zMmVN/bfWPSbThQcB4aQUC7sCBMWpplvHOt/n/cVdndVzHGkbextIlAbQIVFRqElLHxWLwlD2GXlJM6QP3GqYY6s7VnjHcndM5iV2KXkZGBadOm4dy5c2bPCYKA2tpahxtGpJbSEWMTl2RBhGN16vLOXDLaebo+pxhpk2/DvP8ewYMKSd28MfFYnGFeENmUKAI7j5chvk0zo6QOALJPVeJQYQXyzlw0qys1f7Qu6ErTzTMGx+LTXflmn9/Xdqo2JMY48kaWNhGoTXjW7j8lm9RdbBWFBya9ZrT7VW1y1ljPbHUXu3bFzpkzB/fddx9KSkpQV1dn9IcBjxpSibYa3x4qln1ONPh/e9cbyJUEeVEhqQtO+zsyF9yO6BaWj/EyvPeCdUewPke+/dvySs1GIlPWHcHiDF1SJwjAvDFdMX1wnPkuX8Dndqo2JMY48hQl2mrVO0mVNhGojQXS7IfcSN1dE1/DuImDzXa6qk3OpvRrj8yUEVgzayAyU0b49FIRd7MrsSstLcXzzz+P1q1bO7s9RKqt3X8KSanbnHL0ly2Upl/H9ozGzuNleParXNX3qgOwMqtA9rnwmwLM60rhxnSGKOrOgwV0I3mCyXU7j5epbgcZY4wjT7B2/ykMStuG5GV7MShtG9buNy/BY0jaRGBq1r8PWn0toJv9UJp+LQiLwpIdJzAtsT3WzBqI9NmJiGkZbFPpkqjQIFXlmMgxdiV29957L3bs2OHkphCpJ/UslQbGnFc17gaNoLz7dWJ9MDUcYXNUz3YtLNaPA25MuQ7tEmm0AVeEbp2ds+tFNRaMceRuSjtJrX2n372vF1Y83McoBqp9bSexCmu+Ul5TBwD/yjqJv2/6FZOWZikmnLaMMpLz2bXG7sMPP8Sf//xn7Nq1C927d4e/v7/R888884xTGkckMT3/1VIxYkFQX8/N1IqH+8jufAWABw4qlzRZn1OMEfGtVCV1ao8vu1xTh0kJbS1u8pDWuCitM+Q6O/swxpG7OfKdDgpoovpkGb3SUrS+eyxalysndZKfiy/o/9l0s5ZN582SS9iV2K1evRrfffcdgoKCsGPHDggGQwWCIDDokVPJBYqhXSJlS39oHEjqACD7ZKXRIl+JtTp1taKIiqoaszbJbdxQk3gKAC7XXEO6SVIn1L++TqY4cEPsOmssGOPI3RzZSWrza2XOfk2+/02MGDMQn+85afX9pKQRgEvr1ZE6dk3F/vWvf8Vrr70GrVaLgoIC5Ofn6//88ccfzm4jNWJK0xGALsGTFvJqoKsJ98+pvRw693XpjhMY2iUS6bMT9UmZ2uLDr2z4BZMS2t5okwDcPyDGrD11oq6tfhbq3IkAZnx+0PzYMOiqxpsuQJZ2ndm7sJmMMcaRuznynbbptTJJ3f33v4mTYVH4cu8pPJLUwer7qZk5oIZj14hdTU0NpkyZAo3GrryQSDWlQLHpcAnG9YhCZsoIo8KbJdpqq8eKWSICOFhQgZIL1RChnNRJIziGbyOVQ3liWEcs3XECdSKwZm+h2dSrnyDo69dtOlyCNzYdVd0+P0EwOwpIYstJEmQZYxw1FNNlJoYc+U5be22JthqnjxWg18OT4Z+ni0FydepG3RqFsxeuYotBXc7e7VvgUKFWtnSJ2pFCS5+bHGNX1Hr44Yexdu1aZ7fFZhUVFZg2bRpCQ0MRGhqKadOmobKy0uJr0tPTMWrUKEREREAQBOTm5jZIW8k+IQF+so+/sekoElO3YcOhYn1PUTpKy7CnaisBwDNf5eDvm/IsjtSJAJ6+vbPZ62tFEUt3nDAqtQJAvwnCMAhGhQZhXI8o1Rs9NIDVg7S568w5GOOoIajZ9erId1rptWv3n8KEl9MROna0PqmrbdcODyQbr6mTkrKPHuyDb55KwsvjuuGbp5KQPnuQbOkStSOFtu72JdvYNWJXW1uLt956C9999x169OhhtrD4vffec0rjrElOTsbp06eRkZEBAHjssccwbdo0fPvtt4qvqaqqwqBBg/DnP/8Zs2bNapB2kv2qaizXDEvdnIe0zXlmR2lVVl9D2pY8m9bbaXCjnIi16VcNgFPn5acX5KZPP5iagPCbAo16zlKPNWVsvP4zAPLr8jQC8PXsJOSduag/SFsAkDImHo8P66T+Q5IqjHHkaq48P9XSaFiJthrvfLELq1bf2P1a3DwSTb7NwJPXmikWETY91UHubFhA3Ugh1+G5ll2J3ZEjR5CQkAAA+Pnnn42eE+wcKbHV0aNHkZGRgT179mDAgAEAgGXLliExMRHHjh1D165dZV83bdo0ADA6Hog8V1xEiNVdpIYnQyxM/xnxbZphscqkzk8QkD47EZdr6nCu6irmrM4xS+pyp81GwKPPwe+746gVRQjQ1Z9bnytfWFhOUWW10cHbphtCUsbEo22LIAgC0LtDGHYeLzMLsK2aNzU6TkwEkLolDxCAx4daT+449aEeYxy5mqt2slvblXo4+7hRUlfULBL3T30Ti5u1wZRO4U5ZzqGU9AGu+9x0g12J3fbt253dDpvt3r0boaGh+oAHAAMHDkRoaCiysrIUg549rl69iqtXr+p/vnDhgoWryV7OSDxqRRE/HC2VXWMnt9btzXtu0/dCDxVW4KHsjXjNIKlbkjQF97z/Nh5vEYwJCW1xsKACz3yVY/PO28UZeZjQK1q/DtC0x/pWxjGjw7Tler1ZJ8plP9fiLXmY0DPa4u+MJQhswxjHGOdqSjtXgwM0yDpRblcctDYatv67bNzy4CSzOnVFLaP16+AsJWXO0FDnxjZmXrsy+MyZM2jVqpXZ461atcKZM5YPX7dVamqqfo1LaGgoYmJinHp/kl9zUaKtxsbDxTbvcv1g+++y69akc2OfGtHJbG3I2v2nkD5joVlS1+TNN5B/7rJ+/V5LmdMg1KgTgZU/6c5zVbtzzHR9jDR6KXfvgwUViu9tb6FTci/GON9muh5NAyCpczgmLlEu/GuNpdhy9veTuqTOpE7d6bAoxR2zrig0bG0dHosbO86uETtXWrRoEV599VWL1+zfvx+A/JSIKIpOnypZsGABnn/+ef3PFy5cYOBzIrnEIyX9CCDad8arKOqWwgkyrxcBfLzjDzw4sIN+9OxAwXn8+lIqXjVI6j5MnILqv76CjzKOqaqfp8bynfmYPijO5h6r4Uhmyph43fSriWe+ykFVzXXZUThOfXgWxjiSSCPzKzMLsCzzD+z6rVz/nD1rz5RiS0fxEpqNGSVbfHhJcgLG9Yg2u5crR/mV1uFxZsE5PC6xmzNnDqZOnWrxmtjYWBw+fBhnz541e66srMzp5zsGBgYiMDDQqfekG+QSD0eKDFt7vZTU7DxehpR1R/Cg0kaJH2/UK5OCbGbKCNkCxmrUASgov4zETuFG97BUY0ou0D01ohOWbD9hfG8Lfwlw6sOzMMaRqeWZf8jGLFs7YDuPlxndRxCAd4e3Qeu7xwK/686VNkzq/AQBvTuEmS2DccYGB2tLa0ynfLmpwnk8LrGLiIhARESE1esSExOh1Wqxb98+9O/fHwCwd+9eaLVaJCUlubqZ5ERqNkg4k58g4HLNNcxfd0R18WHgRpA17G1KGy7Uvq+0fmZol0hkpozQTaEKQJ8OYWbXy45krjsi1zSj9pkGQWnqQ00iSa7HGEeGLB2PaEsHTO787IhLlRg390WgvqRJVetoPDjxNZxq0UYfB3YeLzPrPMa0DHZolN+ekTfOLDiPTYndwoULMXHiRH2Qcadu3bph9OjRmDVrFj755BMAulIA48ePN1pUHB8fj9TUVEyaNAkAcP78eZw6dQrFxbodjceO6Xoxbdq0QZs2bRr4U5ArWDqyy08QMDEhGjM+P2hTUgfoAlT5pSv69Xa2FETWCMDEhGj9rlaNAIy+tQ22/HIGokLwkx3JhOXPpvSXAIsXq8MYRw1NbkQduFG30rQ8ktIImGm8CK+qxKo1C+Ffv1ECMTEI2b4dqyOi9XEAgL58EnBjlCx9dqJZmzQCVCWZ9o68cWbBeWzaPFFSUoLx48cjKioKjz32GDZt2mS0k6qhrVq1Ct27d8fIkSMxcuRI9OjRA1988YXRNceOHYNWq9X/vGHDBiQkJGDcuHEAgKlTpyIhIQEff/wxyD3yy6ssjtbJpVkCgNfvvhULxsabHSu2fnaSviCw4fUf3p+A9NmJ+DqnyOakDtAlVE+vyTVa1Ky2IPKEnlH4OqfIKNht/vmMPkmT29AgBTo11IzCsXixdYxx1NDMNlEIwGNDOuKnBbcbbe6yVtDXMF6EV1VizZobJU1qotsC27cDnTrp4wAAbDxcLDtK9kNeKeaPiTcKh6Kom+q1xt5jxXgsovMIomjbQiFRFJGZmYlvv/0WGzZsQFFREf70pz9hwoQJGD9+vKopBm934cIFhIaGQqvVonnz5u5ujtcr0VYb9RoNCQD+MqoLqmtq8dH2E6gzeM5wQ4PcItyUdUeMiv7OHtEJlZdroPnoI5tH6kzb5icIRuVJDhVWYOKSLMUEVe1U85pZA/VBV/oc0hSqVEDZqHAxgA+SE9C7g/wxY77Kld9BxjjGOHco0VbLjqjLxUfT+CP55McT+PS/e4ySOmlNXb87+uLd+3oBMJ4qVSIXs5Te1/RzqG2v0usb+8yCo98/m8udCIKAIUOG4K233kJeXh727duHgQMHYtmyZWjbti2GDh2Kd955B0VFRTY3hryfPVvVo0KD0CumhexzIoB3vjuOpdtP4MnhnYxyL2mUq/TCFYgmIWhol0jj3iaAJdtP2JzUAcCEnuY7xqTzaqXPWVVTa7WIsrWNjHJTHVP6tdcf3fPTgtuRNtm4R5s6uTvG9bBcw45swxhH7qA0om7LCFjvoBrZpO5UWBTWZRfhUGGF2VSpErmnG2LkjTMLjrN5xM6SsrIybNiwARs2bMCQIUPwwgsvOOvWHoW9WXm2LpiV1owUVVzGi/89YvX+SqNe0uMaAZg/Jh7d24bi3KWreHpNrtF1StOv43tEYeMR5bpglkbbpM8Z36YZ7l6SpXgPP0HAvDFd8daWY4q7aReMjVd9ggR7tO75DjLGkTNYWy9n+DwAdSNgpaW4Nmy4/uxXw6RO8vK4bugW3RzJy/ba1W6OvDUMR79/Tk3sGgsGPXNqh9+lgHXktBaLM/JsrgdnaWOEIU39ddKlSkmdRhDw9VNJFqdRrfETBPzz/l6Ku2OlHuuUfu31we5wUaU+ydNAl5DyzFf1+B10Lf5+XcdaB1jueQBmu9qNOs2lpcCIEcCvvwLQnf06dapxUgcA3zyVhFbNmyoufTEl1P+pA+Tfl1zC0e+fx5U7Ie+kZqu6mnUd1jw1vBM+2vGHLiGysBu1rr5IMUTlpA6CgDoAheflp43VrourFUUcP3NRdhfZ+1MT0CdWV8pEOiYosVM4EjuFY0LPaPZoiRoRaztGlZ7PTBmBzJQR8vHCJKlDTAyabNiC2IOXcMqg4PHk3m31xyeqqcUpCECawhpm8mxM7MgprG1VV7uuw5pBnSPxwMAOKCi/jOAAjb58iBxRBJZW7sZYC2vqNACOl16UTeBeu/tWvLLhF7NkzXAkUPL+tt8B3EgGpd7t+J7Rij10V5/JSESexVoH2NLzsuvOTJK62nbt4Ld9O1p16oR/99Jt6jpQUIG+sWH6pA4wLn9kNHsgAFP7tcegzuFGG7IYp7wLEztyCmtFcC0V4VRLShQNEyJLPc+HszdaTOqkJOz9H36Xfa87b2mNgCYas88EwGjHrSERQHL/GDx9x82qK7hbW29DRL5BrgOsARAcoFF8XqmW29nfT6LZmFEINjhR4oFxr+DJ8/6YUr+qo2eMcUJnSIqjnD3wPUzsyGksFcFVKsJpibSJ1HAETEqWpETIqOd5uhJvZeh6ntOyNxqf/Zo0Be8OfhAajYD5Y+LRNjQIz3yVI9sewwQuJLAJFt19C8KCAhDTMghVNbUICfCzuNbvq32FePqOmwFY76HzbEQiz+bMjpdpBxjQrV+btDRL/91Xc0rM+u+yccuDk8zPfm0RZdcxXHKzB+xwei+HErvNmzdbfH7s2LGO3J68TIm2GgcKzkOQ6WHKjejNG9MVPdq2QHCABpdr6nC4qBKLt+QZJTmmiaKlac3ETuEY2LEl1s1YiNdMkroha5aizzVRf5+sE+WySd3L47phbI8o7DxehqTUbUajctIIn7W1d9KZsFGhQRZ74Dwb0fMxxjVuzup4mXZG49s0w8SlWWYFyod2ibR6SszZ30/ilgcnoYtpUle/UcIZx3Cxw+ndHErs/vOf/wAASktLkZWVhTvuuAOiKGL79u0YNmwYg14jIlcQOG2ycTCwFrBOna8yCnSVl68Z9SQPFVYgJf2I0TUL1h1BfJtm+ukGzUcfGSV1HyTqRuriKq9gXA9dPboSbTXOV9WYJWh+goCxPXTB0fTMRRhca23QUcCNenSWpqjlkkuejehZGOMaL2d1vOSSpJiWwWYj/obffcX1t6WlaDZmlPlIncHuV0eP4WKH0/s5lNitXLkSAHDXXXfh6NGj+nMIz5w5gyeffNLx1pFXKNFWm605E6FLjkyDgVLAkjvAOnVLHk6ev4wpfdth4+ESLN+Vb5ZU1QGYuDQLafd0x5R936J76kv65wzX1ElB1DDISlv5Tad6lUbzTClOLQtA6YUrstPFUkJrKbnk2YiegzGu8XLGofRKSZLcWaym332zqdD6jRKGa+rkkjpHj+Fyxucm93LKGrsTJ04gMjJS/3N4eLj+4GnyfUpnvdaJUB0MlDZXrN57Cqv3mp+LaEgUgV9fSgO2fqR/zDCpEwD0iQ0zC7JSUeMP6kuSSO1Usx7QTxCQPjsR+wsq8Mamo2btkerimU4XA+qSS/IsjHGNjzMOpVdKki7X1FlcS2c6yvfe8ChMfH6afvdrVetoPDjxNZxq0Ua3rGV0V/Ro18Ipmx+c8bnJvZyS2E2ePBlJSUmYNGkSBEHA119/jXvvvdcZtyYvEBcRIrvuTO6ILKUFuUr3UMN0o0TmlMfwXoe7AEGABkDq5O6KI3F1IhB+U6DZqGLqPd2Npn0B4wRs3uiuqKqpRb/YMNkkUPrRWp0qpeSSPAtjXONjbae/IUtxTSlJSuwULrs0xTRGhF2qxC0Pzgbqp18RE4OQ7duxOsJ1O1lnDo7D8l35RoWJGZu8h1MSu9dffx0TJkxAVlYWRFHEBx98gH79+jnj1uQFokKDkDa5u/Eau/qRKsNgYGlBblRoEFLGxCN1S55N721afPjDpCl4p8NdEAQBjw2Nw/RBcRZH4pR6otL0afbJCogi9EWGpbpPhps8JiW0xfqcYsWiydbqVMkll+RZGOMaJ2vrggHluCYle/NHx+t365smSYbloKSfDWNEeFWl0dmviIkBtm8HOnVCFJxfX870szw2uCOmD45lbPIyTit3UldXh8jISCQnJ+P8+fM4ffo02rVr56zbk4eTdnr9cLQUrZoH4o5urc2OErO2IHdCr2ikbclTPWonm9QNrl9TB2D5znyM6x5lFETV9sCl68f1MC6vEhsRjAeW7zH6HOtzipE+OxGXa+pkiyYbJo+c5vBejHGNk6VC4kpxrbL6mlHnb/6YePRoaz5VKpcUxrdpBsA8qauJbouA+qTOFeQ+y4rMfEwfHOuS9yPXcUpit2jRImRnZyMvLw/Jycmorq7G1KlTkZmZ6YzbkxcwDVD+fhqjHbFqFuQqrdWTY5rUHZ/5DN5p+Sd98WHAZGNFfVvU9MANffLjCX2yqRF0UxRKa2YSO4UDgMXk0dbkkjwDYxzJUYpraVvyjHbvv7XlmOy52XJJ4T/v72WW1BU1i8TZL9ajd6dOLqkvV6KtxsbDxdw04SOcktitX78eOTk56N27NwCgbdu2uHjxojNuTR5EKaDIBagF6cZlSNSMVMlWZReAxZO7Y966G+vdTJO67GmzEfV2KjSLt5uvdTNoS6vmTfXtl5IwSz7ZecJoarhOBJbvyrf6Oawlj7Yml+R+jHEkR+kkCTUJklJSGHCuHGu+Mk7qHkxOxeo+t7qkvpylM7w5m+CdNM64SWBgIABAqB8tqays1P8z+Ya1+09hUNo2JC/bi0Fp27B2/42dqkrrxiYuydJfJ41U+dX/dyE3UrUh17jHKEAXuP7ctz3S6l9rmtR9kDgF90aPwc7fypF6T3fZ/6DrRODuJVlISr3R/k92nkDWiXKUaKtlP2+JthppMuv96gDMHNzR4ueQPq/s2Y4qnyfPwhhHcuTi2vwx8dCY/KdhWJRcijtSUmio1WUtRsyealR8+MHkVDwx408AIDvCpxTD1LB0hjdnE7yXU0bsnnzySUyZMgXl5eV44403sHbtWsyfP98ZtyYPYG19nNKOVhHG10nr8PYXVKCfyaHUpqNj0usrq68B0I1yjf5xHULlzn6FgIXpPyMzZQS+firJqKK76f2k9qdu1r2XUq83v7xK9h4aANMHx2L64FiOuDUijHGkRBqBP1hQAQhAnw5haBHsb7bcYufxMrPRNsNlGa0ua7F14yL45/8GAKhuE41jy/6D1UMSXFbQXKnMlHQCD2Obd3JKYvfAAw9gwIAB+OGHHyCKIr766ivceuutzrh1o+VJ5/Q5UrCyVhRxsKACLW+qwpHTWv16NcOTKZRGxwBg8ZY8TOgZjagvP0Poi8/rHzesU2fYnsRO4Ui7p7tZwWQlSlXVlWrZzR8Tb7ajjXwfYxwpKdFW47PMfKzIzDdK2jJTRug7fwAwKG2bWec4M2UEMlNG4PSxk+j18D36pK64eSSmTngVp3+qQGrrMkzp194lG6+U7smkzrs5nNjV1dWhX79+yM3NRbdu3ZzRpkbP087psxZQrG16ePqrHLPRLxFAyjrdyRRKo2OA7j2r//EB8OqN0ZGLL8zDP/yGQJcemrdnaJdI09tYJJekmm5ykHa2PT7UNTvSyHMxxjUutnSqTY9SBIyTNmktr6XRtsRmtYiaPhnI0xU6L24eialT60+UMOl4OnvjFTdz+SaHEzuNRoP+/fvjl19+YQ/WCdx9Tp9cULP25bd2UoNS0iYCOFhQgT4KRX4B4OHsTehocKIEXnoJzV5/HakHChXbo5RoKhVAtlbLjlOujRtjXONhugveUqda7hhEiWlnUalz3FG8BIwYqz9R4mpUW0y9a5HRMWGG93JFTLJ0T0+aOSL1nDIVu2/fPiQkJKBLly4IDg6GKIoQBAH79u1zxu0bFXee02dppNDSlz8qNAjzR9teXBjQzaSaJo6Sh7M34VWTpA6vv46SC1cQ0zJYXzvOtD1KiaYI4LGhcQgPCVQsGGrKUg0rajwY43yf3C54S51qpfVpgHlnUa5z/O7wNmh9942kDjEx0G7YgtNrC4x6oHL3cnZMkrunp80ckXpOSey++eYbZ9yG4NoCtpZ6X2pGCuWqpEu6twu1q02nK3U7ugwTx+AADZqtWGY2UofXX8faA4Vmwca0dIkUROV2ey3fmY+fFtyOCb2Mj+Nhz5QsYYzzHvZ8l5XW+VrqVCt1IDUCzDqLJdpqo85oR/GSWVKH7dvRqlMnpF5rZvPUqLPjl7tnjsgxTknsOnTo4IzbEFy35sFa70vNSKGle1ibjlWyeEseBsa1RM+YsBu9xiVLjNbUGY7UqQ02U/q1R3CAH55ek2v0eB2AlZkFWDium6rPRQQwxnkLe7/Lltb5Hi6qlK17abYOF8BMk2MM5dr03vAoJD4/zSypk06UsHW61RXxy50zR+Q4pyR2oihi3bp1yMrKgiAISEpKwj333MM6T3aydx2FLQWETRMiayOF1u4hBbmU9COKAVJujZtUY27BmHg8PqyTLqmbM+fGBfVJHQTB5mDTvqX8KOfyzD/05x+yZ0pqMMZ5Pke+y5Y6pm9tOabbmS9zD2ux2rRNYZcqccsDswGZs18NqZ1udVX84tGH3s0pBYoff/xxfPnll+jXrx/69u2LVatW4fHHH3fGrRstWwvY2lpAWEqIDN/PUgHhgycrrN5jaJdIs8xNIwDfPJWENbMGYv1TSVD6azB1Sx4yn1ukmNQBkC3oqRRs1u4/hUlLs2Tfq04EVv6UD0Dd74aIMc7zOfJdluKf3F+I1u5hKVYbtsn0mLDi5pHY+M9VDp396qr4paagPHkup4zY7d69G0eOHNH/PHXqVPTo0cMZtyYV1BQQVtP7Uup9Slv6TZneQ243ap0I/TmqJdpqxbIo07I3YrBB8eGLL8zDkUeeRdyFK0Zr/J4c1glLd5yACOVgY6maumT5znxMHxTXoD1TruPzXoxxns/R77JUQN20wLkj8SAkwA+CALS8ZH726/1T30TRvovoc3u13fHAlfGLVQG8l1NG7Hr06IHc3Fz9z4cOHcKAAQOccWtSwVqvzbT3pRGAeWO6yn5RDXuf0sHQcsV+5RYIWxtRkzZdmDI9JuyX6XPQ028IkpfvMxp9/Mv/y8WS+qQOAEbd1lp2LYml3WqSOkA/hdsQPVNLI6rk+RjjPJ8zvss9Y8L0xxfaew+JNGsgm9Tdr6tT5+jomqvjF48+9E5OGbH7+eef0bdvX3Tu3BkA8Ntvv6FHjx7o168fSwI0ADW9tin92qPy8jWkbclDnajbtNAiyF9xka2lg6EB+bUoaurdmTJN6s4+/RfcFTwcdfWTttLoY8RNAViXXWT02s1HzuBQYYXR0WRKvw9Thr8fV/dMuY7P+zHGeQc1a96sjZo7Ix5I3/kw06SuuW6kTqpT54zRNY6skSnVid348eOxatUqhIaal7XYsGGDUxtFtlGzk7ZEW43FGXlG56XKJRcl2mocKDhvdSoTkH+9tSCT3D8Gq/cVApAfqdM+Mx91y43/kqwVRWzPK5Ntw4EC88QuKjQIkxLaGiWCvdu3wKFCreLvx5X16rjDzDswxvkGpe+yLbtH7Y0HUuJ47tJV86SuWSS+efcLFJ2oBZxcyoT1NsmQ6sRu8+bNKCwsNAp6v//+Ozp37mxWCkAq3kkNx1pCpZRcHCyowPie5mU/1FBKTkyDTIm2Gisz87FsV74+sTRN6rZPnoURK95HyYUrsqOPI+Ij8eVe8+lLud5uibYaX+cYj+4dKtQqFjR2Ne4w8w6Mcb6rIUbNDeNn5GXzpO7B5FSs/vNQTALcWsqEfJ9Na+xOnDih/2dRFBEfH4+ff/7Z6JpHHnkETZo0Qf/+/XH8+HHntJJUsbQeQm79GwA881UOPvnxhH4tnVJSp/RX2O9lF1GirVZsk7S27FMLSd0HiVMwo/MElNRvlJBbM3JLdChubnWT2f1n/fug2Xo1pSRW2sTR0D1b7jDzHoxxvsnVu98NE8fwqkqsWm2e1D0x40/6Tq+aOKSUjFqKt0SAjYldenq6/p+LiopQV1eH0tJS/WNarRZffPEF1q9fj+HDh+PRRx91XktJtRJtNbJOlBsFAKXt/HWirtTInNU5ijtW/QQBs4bEyT738vpfFDcDyO1OlUvq3h3yIOog6IPslH7tkZkyAmtmDURmyggAQFLqNvxWesnsPeSCXVxEiGwierioUuETup7pZ2Kv2zMxxvkmW0ol2UNKHE1LmlS3icbZ9ZuxenEypvRrLxubrd3TEEsxkRo2JXY//vgjPv74Y1y/fh0rVqxAYGAgfvzxR/3zxcXFCAwMxF133YVFixbh4YcfdnqDSVmJthp/3/Sr4u7LKf3a4/3kBNX30wBYkpyAzJQRuHqtTvE6w+TKMHCZBialpA6CIHseolTtXemgbYlpsNt5vEz2+re2HLO5t2tLILaGO8w8H2Ocb3L1qHlcRIjZ9Gtx80hc3PI/9L69L6JCg2zeGe/qZJR8l+o1dg888AAeffRRPPTQQ3j22Wdx/fp1LFmyBIsWLcKDDz6Im2++GZs2bULHjh0BAMHBwZg1a5bLGk7GpFpzhgmNlHDFt2mGqppaxEWEoE+HMFVHf0mBb1yPaBwqrMDne05avL5WFLHyp3ws35WvXw8yf3S8/r2sJXVKQVZN6RIACA7Q9VGkUUKlNtqyYYHrWxoXxjjvYG89SFfuHo26ehHfb3wVoQZJXfa/1mF8r1v1bbZ1jZ+rjpck36c6sfviiy8AAH/88Qdyc3PRokUL3Hzzzbh48SJuu+029OjRA4cOHcKrr77qssaSPCloyOU/taKIiUuyIOJGcmIYLORM7BWNPh3CEBzgh09+PCF7OLYpjQAs25lvtOv2rYxjmD8mHsVvvItXTZK6/xs6DQvGxKNHuxYWg6zaM2gv1+hGFC0lgrb0dlmipPFhjPN8jna2XLJ7tLQUGDECofm/AQCuRrVFk83f6ZM6wP6d8SxlQvYQRFHpZE/1fvrpJ3z33Xdo3749ZsyY4fO7xS5cuIDQ0FBotVo0b97c3c1B1olyJC/bq+paP0HQr1vLPlmBrb+ewfrcEofbMK57FDYdMb/Ptqa/oOOr8/U/X3xhHn5+/EXERqrvba/df0qfiEr/ZZn+RyudNVuircagtG1mQdTWvwSUfqdrZg2UPRCcGlZDfwcZ49xP7rstxTO3JTz1SR1+/VX3s8LZrx7Z9no8EcfzOPr9c0qB4kGDBmHQoEHOuBXZISTAT/W1Ui/x1Pkqm0qbWKIB8NjQOGz5ucTofg9nb0RHg5E6vPQSmr3+OmIvXNGfQqEmkJj2WjccKkbqZuNRxLcyjmFCr2iz6QsNgJlD4zB9UJxNQYslSsgQY5z7KY16ZZ+sQFhIlb4AeoMlKSqTOsBzp1W53MQ3OSWxc5eKigo888wz+uKhEyZMwAcffIAWLVrIXn/t2jX89a9/xebNm/HHH38gNDQUd955J9LS0hAdHd2ALXeuqppa1df6CQKCAzROS+qkANUzJswocD2UvdFo+vWX6XPQ8oWF+GzzUazIzLc5kBhOoXRva15A1nBawxnTF54aiKlx8eUYZ+tIkVxnSxCg39FvOJpvb5Kiuk0KSV1JRDTyT5TLvt7TplW53MR3eXVil5ycjNOnTyMjIwMA8Nhjj2HatGn49ttvZa+/fPkysrOz8fLLL6Nnz56oqKjA3LlzMWHCBBw4cKAhm+5U0kHT1ibVpeSkqqbWrqTOTxAwb3RX9GjXAsEBGrNiv1LgKk/7B7qbrKl7r9UoiGnbje4nF0jUBFY1o2lSIijtag0J8NNvIFEbtDwtEFPj46sxzp6RIrPR+PqYJ4UBuY1jtiQpqtukkNStPe+PBcu3mb3eNKZ5ShzhiTi+yylr7Nzh6NGjuOWWW7Bnzx79Ydx79uxBYmIi8vLy0LVrV1X32b9/P/r374+TJ0+ifXt1vTtPWn8id1qEIACoD3iGyZiUnCitQxMAjL6tDTJ+OaNPEgUAKWPj0TY0CBCAPh10x3cpJl9LlgBz5uh/NNz9quTD+xMwvme0TcHecN2dlLCaXiv3u+F0g2/wpO+gq3h6jLN3bZaj681KtNUoKL+M8ktX8PSaXIvXql0Tq7pNFkbq5F4/b3RXLM7I88ipTk9e99fYecQaO3fYvXs3QkND9QEPAAYOHIjQ0FBkZWWpDnparRaCIChObQDA1atXcfXqVf3PFy5csLvdziRXAFgD4OvZSWjVvKniSJPU812w7ggMq9OJAP73y1msn52E0xXVEEWgT2wYdh4vwzNf5aBOtDLdYUdSB+hOvyiqrNYHQMB6j1tuNM3wLxoAstPNnG4gb+HJMc6RtVmOjhQZjsZb2jFvy5pYVW2ysKYu/0S57OvTtpifz21YfsqdMYjLTXyX1yZ2Z86cQatWrcweb9WqFc6cOaPqHleuXEFKSgqSk5MtZsWpqakeWeJALhjVQVf6Q2nIX0p+hnaJxPvJCZizOsfoeenorXE9ovXXGyZIitMdX35mV1In3WfxljyYlkC2FuwNP6PpXzQzB8cpBnxON5A38NQY5+jaLHs2JsmNDpomJgIA1E/P2pqkWG2TlY0Scq+XSzrlyk+5cwSPy018k00nTzSERYsWQRAEi3+ktSJyJQfUHs597do1TJ06FXV1dVi6dKnFaxcsWACtVqv/U1hYaN+HczJbK5ObVj4vqqi2+nprBYJrRRHV//jAalIn4MZon9y/nTqY54Bqe9xyf9Es35UvezauLfclcgVvj3GOHnVl6ykQlk5sMDyqL2vB7chKud3mY/ukpPHJ4Z30McOoTSp2v0aFBmFSQluj+46+tY1sDDIdwXP32a88Ecf3eNyI3Zw5czB16lSL18TGxuLw4cM4e/as2XNlZWVo3bq1xddfu3YN9913H/Lz87Ft2zarc9iBgYEIDAy03ngH2LNeRc1QunTfkAA/s+RHKiD81pZjiq+3ViD44exN6Lj1I/3PZ5/+C94LGm6WpUk91A+mJiCmZRAmLc0yX48ypqvFtihRGrl8bHBHrMjMNyrEzOkGcjdvj3HOKAWkdqRIrtO2YN0Ro9FB09kJW77bsmuUAcwb3VWXGNpQp+7rnCKjx7775axRfFUawePsATmbxyV2ERERiIiIsHpdYmIitFot9u3bh/79+wMA9u7dC61Wi6SkJMXXSQHvt99+w/bt2xEe7v5is46sV7EUIA3vK7drtlYU0aNtC2SmjLC6Hk9uuuPh7E141SCp+2X6HNwVPByi7JicLqiF3xRoVhrFcPPDhJ7RyD5ZgTpRRN/Ylqp+B0p/0UwfHIvpg2NRUH5ZdhcvkTt4e4xz1tosNTtElTptKzMLsHBcNxtbbkxujTKg64S+lXEME9s2Qeu7x6qqU6c0imkYX4MDNLIdWs4ekLN5XGKnVrdu3TB69GjMmjULn3zyCQBdKYDx48cbLSqOj49HamoqJk2ahOvXr+Pee+9FdnY2Nm7ciNraWv1alZYtWyIgIKDBP4czagnJBUiztXEyI25SULEWYE2TRwCo/scHRiN1x2c+g7vC/4Q6haTO8P3k7im9/87jZQ6XQTD9i8Z0BDNLoc4UkSfx5BjXUGuz4iJCUL/J38jyzD8wfXCs6l20crMhlpaZtLhUgWZjRgG/H9M9YCGpk9qpNIppGF+5WYEagtcmdgCwatUqPPPMMxg5ciQAXfHODz/80OiaY8eOQavVAgBOnz6tL/TZq1cvo+u2b9+O4cOHu7zNppxZS8gwgCkFLQ10PV5bg4pR8rdkCWBwTNiHSVPwTss/QX71nI7c+5kmlI4kuWr+olEaGeWROuSpPDnGNURNtqjQIAy5OQI7fys3erxOhKoYaWk2RGmZSXhVJdZ8tRDB5fVr+awkdVI71SRt3KxADcGrE7uWLVviyy+/tHiNYZm+2NhYeFrZPrXrVawlH0bTrgBmj+gke9/02YmOTUmalDT5MGkK3hlseffry+O6YWyPKLumXewpgyBHKWmsrL6m25HrgXWmiHwhxjmiRFuNzN/LzR7XAFanMK11FE2TMeBGUtfFhqROojZp86QixeSbvDqx8wVqenrW1uDJlSRZsv0Ext7WBt/9ctbovj1jwuxvrElSVzj7Obxz0+0Wkzo/QVCV1AG2Lcq2dZRNKWlM25Knn6ZmjTsiz6I08zBzqPWzn9V0FA2TseYXziHuvgk2jdSZauikjbMNJIeJXQOx9AW01NNT2hUWEtgEfTqEISo0SDH4ZfxyBl/PTnLOpgGTpA4vvYQmLyyEZvF2xXUqGgFWp3tNfy9ySS4Ao3VxajabmN5Xts4UuEuNqCHYm4Ao1YebPijOrtfKdRSjQoMQdfUiMGGS6jV17mD6O3Rk0x35NiZ2DUDNF1Cpp6e0K2zO6hz9vYZ2iZRdYFwnAvsLKtAvNgz55VUovXBFseK5xcArk9Th9dex80ChxfNp35+qOypMidLvxTDJ3Xm8TH/sjUYA5o+Ot3pChdJ9TZNGw+N+JNylRuRcct/HoV0iVSV6juzAVf1alSVN3Mn0d6gmDlLj5bVnxbqTLee4HSqs0Fcal9h6LqLcua6m99qQW4zULXmq2m+aXFpMPBWSupILVyy2SyMAP6XcbnHNm7VzCuWukTZ/mJLOhLR2X+mcSWkEU82Zs+R5GsNZse7krN+v3PdRgG71hi0jTabfW1vboPjaBk7qTDvQakYy7YmD5N0a7Vmx3mDt/lNIST9iNpJm64YA0wW+cvea0CsaJ89XYc3eQrP3M2XYuwOgvMDY5Jgww6Ru4+FiiydSiKKudIlSwFaz/kVptNK0Jp/hKJu1+5qOjHKXGpHryH0fRcDmda2OrF1TfK2LkjqlZM20Az0poS2+zimymuDaEwepcfO4I8V8hbQ2zlL9OGuvzzpRjhJttf7YnA/vT5A9Auzw6UoMStuG1XsLIQjAHd3Mz5c0JSU7SomQ6TFhUlK39kAhklK34e+bLI8OirB8XI6a49CUrkkZE694HJGtx6wBPFKHyFkM4xYg/300ZctxZE7joqRO6fgzubXS67KLzDrUcvHSnjhIjRtH7FxEaUODdFyNpS+g0tTo+J5BqKq5brxObExXfbkOQBcgtuWVWm2fYbJjusDY9Jgww5G6lHXmI5CA/NSApZFJNetfpGsWrDuCuvr3MDyhQm6UzVlV8YnINmrWtmpQP2Jn8LoGH2ly4Uid0uyHtTO3AeV4qRTTLMVBatyY2LmIUvFLEcDijDy0CPaXHXa3VnvJdOpQdqrDSgAxTXYMg4bpMWFSUgdBwIGC87JJ3bO3d8bt3VrZfFyO6mlQaWeIQa/V0tQMp1eJGpaluCW3IcptHS8XrqmztAzE2pnbgOV4qRTTWBOP5DCxcxFLa+MsrSuxtkZMbv2GXMAYc1sbfPfzGd1aDACzhsZhXPco2dInUtAwPSbMMKkDAEGhXl2XNs0Uz3+1FnQsBaZDhRVGI4S27PxiwCNqOGrXtpZoqxHTMtjxQun2cPFGCWvHipnGx4kJ0VifU6w6XjKmkVpM7FxISpg2HS7BG5uOGj2nlKxZCg5KUx3zx8QjdbPxmrf//XIWXz+lvoZd1JefGR0TZprUAUCfDmFmZVUEAejdIczo8zpjpMwZG0+IqGGoqRknF78abAdnA+x+tbYMRC4+vjCqK2cWyOmY2LlYVGgQxvWIwpubj6pO1pSK9CpNdXRvG2r2vrWiiMs1deoCp0xJk5IXFuLA4WIIgoA+9YlbfnkVUsbGmx3BZbrGzZEAVaKtxoGC8w5tPCGihmUtqXHkHGiHNWBJE2udW9P4yFE4cgUmdg3A0okKcsEuM2UEMlNGGAWHrBPlNq3fUJ0AySR1ayfMQkraduOROehG6qTimD3atXB6L3Pt/lOKmzOAG5snGAiJPI+lpMbRc6DVkC0z4obiw0zWyN2Y2DUApXUllpI10/IbR4q0Zve1tH5DVQKkMFJnmtQBMFrn9lbGMdUFltUo0Vbj4MkKzF93RPEajQB8PTvJsbNuicillJIahzqfKsguU+nQ1ONPlCByBSZ2LmZpXYnaYFeircZimVMlDMumDO0Sif+b2hMaQUDv+jNkLVI4USL/j3NWCxw7s6dt+PtRIiWqTOqIvJMryxDJTfO++0Um7tn6Bvzz6tc2e3BSZ+85ukRKmNi5kLV1JWqDnVINpB7tWgBQdxatEZOk7uIL83DkkWcRd+EK4iJCZM+dNeQnCAgO0CDrRLlDwcj09yPn2Ts6Y2r/9gx4RF7OVWWITONjeFUlvlyzEP7ndMWBPTmpszl2E6nAxM6F1KwrMQx2wQEaVNXUokRbbRT0LI3s2bwo2SSp+2X6HNzlNwR1y/fpA0va5O5Ga92kfbFi/ftOTIjW16xzJBhZK9opCDBL6ti7JfJerlh/Zhgfw6sqsWbNQnTxgqTOrRtKyKcxsXMhtVOtUaFB2Hm8TLHnZmlkz9I6PbPgIDNSd5ffENTVp26GmzeyFtyOgwUVEASgXVgQTp2/DI0goF1YkFEhYjXBSErGQgL8UFVTq0/KLBXtlNtxy94tEZmS4uO7X2TiSy9J6oCG2VBCjRMTOxcyTcg0AGYMjjW7Tk3PTWkaQ03yWKKtRvU/3kfHV1NuXPTSSzjyyLOoW77PqC2GmzfG9wzC2v2njEbnZg6OsykYya2hM0zKJiW0xbrsIv1zY7u3wdjbogAB+jIran9HRNQ4TenQVLemzkuSOsD1G0qo8dK4uwG+bkq/9shMGYHHhnQEBODTXflGh0MDlntuhuQOq5eSR6XDoNfuP4WP//y8WVKH119HXORNsodLS+vnfjh6BinrjJOp5bvyZV8jF4yU1tBJSdmhwgp8nVNk9NyWn8/g6TU5mLM6x+j3pPZ3RESNTH1JE2/YKGHIWuwmshdH7BrI8sw/FEebHO25KY3mlWir8etLqXh168f6a5ckTcE9LyxElCAoHnNjeuaroToAjw3uiBWZ+VZ3t1laQ1crithfUGHxnFvD3xN7t0Rkxg116pyJ51qTKzCxcyLThf3Sz+eraqyeo+hoKQC5RcnV/3jfKKn7IHEK3h38IHqfq0ZUC11CZLp5w1JSB+iGeMf1aIPpg2OtBiNLa+j8BAH9YsOsHoxtODXsqnIJROSFvDypk7CgMTkbEzsnMV3YPymhLb7OKUKdqNtValpCxHS0yek9tyVLjKZfP0icgneHPAg/jUZ284bSRgxTdQAmLc1StXHBNGGVGNalM1qDKOhG7JR+T+zdEhEAn0nqiFyBiZ0TyC3sN9wQIEKX2EmjU0qjTU7ruZnsfl2SpBup89NoLI5yWRphM2TLxgXTEUHDkzdMn4+NCMbO42UWR+XYuyVq5JjUEVnExM4BZ7TVaN68udV6bIAuuftgagLCbwp07WiTzIkS97ywEL3PVVt9X6URNjm2bMu3lowZPs9ROSJSxKSOyComdg4Y+Y+dWDCxN9q2CLJ6WgMAFFVWY3zPaNc1SOGYsChB0K+ps8Ywsfrp9zIs3XFCcY2cqzYucFSOiMwwqSNShYmdA+pEIHWz7gxXw3V0foKAUbe1xuYjZ4yufyvjGCb0inZN0qKQ1EEQZC+3dIKDlFgldgrHAwM7oKD8Mg6frsRbGce4cYGIGh6TOiLVmNg5iQjdGroPpiagT2wY8surzBK7WlHEpsMlGNcjyrlJkY1JnS0nOBgmeRN6RTfoFCmPDyMiJnVEtmGBYieqE4EzF64AuLERwdQbm46aFSh2iB0jdXInOJRoq62+lVyBZOmeWSfKVd1DrbX7T2FQ2jYkL9vr3N8XEdnFFd9zq5jUEdmMiZ2TSYnbzuNlRlXFDdmSTFlkY1IHOP8EB1ckYI4kn0TkfG7paDGpI7ILEzsHPP+nmy0mbkO7RCIzZQT+Oq6b2TUOH4dlR1IHyI8k2rsRwlUJGI8PI/IcbuloMakjshsTOwc8Orij1cQtKjQI43pEOS2ZAmBXUidNowBw2vmErkrAnJl8EpFjGryjxaSOyCFM7BykJnFz6mHPdiR1ptMoAJCZMgJrZg1EZsoIqydIKHFVAsbDsYk8R4N2tJjUETlMEEUrlWjJzIULFxAaGgqtVovmzZsD0CVPpicmmCZMJdpqx3aV2jlSNyhtm1GP208QkJkywimJkprPbS+Hf1/ks+S+g+Q8pr9fV37P9ZjUEQFwPL6x3IkTlGirEdMyGOmzE82OzDLkUOFdO9fUWZpGcUay5MqTIliomMgzuPxEGCZ1RE7DxM5BcjXhEjuFO/dN7EzqAPnzX509jcIEjMj3uex7zqSOyKm4xs4BZ2R2iy1IP4JvDxU5b8eYnUmdKzZLEBE5FZM6IqfjiJ0DTp67bDbNWScCT6/JtXqigyp2JnVyo4iZKSNkp1F4ugMRuQWTOiKX4IidAzqEB8ueLgE4odaTAyN1cjWnAJidGsHTHYjILZjUEbmMVyd2FRUVmDZtGkJDQxEaGopp06ahsrLS4msWLVqE+Ph4hISEICwsDHfeeSf27t1r1/u3MSnLYcruWk8OrKlTW3OKpzsQeT53xziXYFJH5FJendglJycjNzcXGRkZyMjIQG5uLqZNm2bxNV26dMGHH36II0eOIDMzE7GxsRg5ciTKysrsasOUfu2RmTICS5ITYJp22bVJwYGkDlBfc4qnOxB5Pk+IcU7FpI7I5by2jt3Ro0dxyy23YM+ePRgwYAAAYM+ePUhMTEReXh66du2q6j5SvZjvv/8ed9xxh02vMa0x43CtJweTOlva4er6dkSu1Bjq2HlijHMIkzoiVRptHbvdu3cjNDRUH/AAYODAgQgNDUVWVpaqoFdTU4NPP/0UoaGh6Nmzp+J1V69exdWrV/U/X7hwQfY6h2o9OSmpU9sO6XQH0wSQSR2RZ/DEGGc3JnVEDcZrE7szZ86gVatWZo+3atUKZ86csfjajRs3YurUqbh8+TKioqKwdetWREREKF6fmpqKV199VVW77Kr15MSkzpZ2uLzoKBHZzVNjnM2Y1BE1KI9bY7do0SIIgmDxz4EDBwAAgkziI4qi7OOGRowYgdzcXGRlZWH06NG47777UFpaqnj9ggULoNVq9X8KCwtt+kxSTTnZjQkuSOpsJcIrZ+OJvJIvxjhFTOqIGpzHjdjNmTMHU6dOtXhNbGwsDh8+jLNnz5o9V1ZWhtatW1t8fUhICDp37ozOnTtj4MCBuPnmm7FixQosWLBA9vrAwEAEBgaq/xAG5GrK6de7uTmps9g2InIJX4txipjUEbmFxyV2ERERFqcMJImJidBqtdi3bx/69+8PANi7dy+0Wi2SkpJsek9RFI3Wl9hDrtCvUkmRoV0iEfXlZ25N6iy2jVOyRC7jrTHOJkzqiNzG46Zi1erWrRtGjx6NWbNmYc+ePdizZw9mzZqF8ePHGy0qjo+Px9dffw0AqKqqwsKFC7Fnzx6cPHkS2dnZmDlzJk6fPo0///nPdrdFqdCvUkmR6n984PbpV5Y7IfJsnhTjbMKkjsitvDaxA4BVq1ahe/fuGDlyJEaOHIkePXrgiy++MLrm2LFj0Gq1AAA/Pz/k5eVh8uTJ6NKlC8aPH4+ysjLs2rULt956q11tsFToV66m3MPZm9Dx1fk3HnBDUgeor3dHRO7jCTHOJkzqiNzOa+vYuZNhjZmfy2qQvMy8qvuaWQOR2CncqKbcw9mb8OrWj25c5KakTuJw3T0iN2kMdezcya7fL5M6IqdotHXsPIU08mVa6Fca+ZJKilT/4wN09KCkzrBtLHdCRA5hUkfkMbx6KtYTRJmcFytX6Dfqy888YvpVTlRoEBI7hTOpIyL7MKkj8igcsXMCiyNfHlCnjojIJZjUEXkcJnZOInvSA5M6IvJVTOqIPBKnYl2FSR0R+SomdUQei4mdKzCpIyJfxaSOyKMxsXM2JnVE5KuY1BF5PCZ2zsSkjoh8FZM6Iq/AxM5ZmNQRka9iUkfkNZjYOQOTOiLyVUzqiLwKEztHMakjIl9VVsakjsjLMLFzxKefMqkjIt81bhyTOiIvw8TOES++eOOfmdQRka85dkz3/0zqiLwGEztnYFJHRL6KSR2RV+GRYnYQRREAcAEAXnhBN3J38aJb20TUmFy4cAHAje8iOZc+xkVFARs2AJGRQP3vnIhcy9H4JoiMjDY7ffo0YmJi3N0MokavsLAQ7dq1c3czfA5jHJH72RvfmNjZoa6uDsXFxWjWrBkEJ06/XrhwATExMSgsLETz5s2ddt+GxM/gGXz9M4iiiIsXLyI6OhoaDVeUOBtjnDJ+Bs/gy5/B0fjGqVg7aDQal44SNG/e3Gv/Q5XwM3gGX/4MoaGhbmhN48AYZx0/g2fw1c/gSHxjV5eIiIjIRzCxIyIiIvIRTOw8SGBgIF555RUEBga6uyl242fwDPwM5Il84d8pP4Nn4GdQxs0TRERERD6CI3ZEREREPoKJHREREZGPYGJHRERE5COY2BERERH5CCZ2blZRUYFp06YhNDQUoaGhmDZtGiorKy2+ZtGiRYiPj0dISAjCwsJw5513Yu/evQ3TYBm2foZr165h/vz56N69O0JCQhAdHY2HHnoIxcXFDddoE/b8e0hPT8eoUaMQEREBQRCQm5vbIG2VLF26FHFxcWjatCn69OmDXbt2Wbz+xx9/RJ8+fdC0aVN07NgRH3/8cQO1VJktn6GkpATJycno2rUrNBoN5s6d23ANJbswvjG+OYIxbq5d78nEzs2Sk5ORm5uLjIwMZGRkIDc3F9OmTbP4mi5duuDDDz/EkSNHkJmZidjYWIwcORJlZWUN1Gpjtn6Gy5cvIzs7Gy+//DKys7ORnp6O48ePY8KECQ3YamP2/HuoqqrCoEGDkJaW1kCtvGHt2rWYO3cuXnrpJeTk5GDIkCEYM2YMTp06JXt9fn4+xo4diyFDhiAnJwcLFy7EM888g3Xr1jVwy2+w9TNcvXoVkZGReOmll9CzZ88Gbi3Zg/GN8c1ejHEOxDiR3ObXX38VAYh79uzRP7Z7924RgJiXl6f6PlqtVgQgfv/9965opkXO+gz79u0TAYgnT550RTMtcvQz5OfniwDEnJwcF7bSWP/+/cUnnnjC6LH4+HgxJSVF9vp58+aJ8fHxRo89/vjj4sCBA13WRmts/QyGhg0bJj777LMuahk5A+PbDYxvtmOMsz/GccTOjXbv3o3Q0FAMGDBA/9jAgQMRGhqKrKwsVfeoqanBp59+itDQULeMYjjjMwCAVquFIAho0aKFC1ppmbM+Q0OpqanBwYMHMXLkSKPHR44cqdje3bt3m10/atQoHDhwANeuXXNZW5XY8xnIuzC+3cD4ZhvGOMcwsXOjM2fOoFWrVmaPt2rVCmfOnLH42o0bN+Kmm25C06ZN8Y9//ANbt25FRESEq5qqyJHPILly5QpSUlKQnJzslsOcnfEZGlJ5eTlqa2vRunVro8dbt26t2N4zZ87IXn/9+nWUl5e7rK1K7PkM5F0Y33QY32zHGOcYJnYusGjRIgiCYPHPgQMHAACCIJi9XhRF2ccNjRgxArm5ucjKysLo0aNx3333obS01Ks+A6BbaDx16lTU1dVh6dKlTmt/Q34GdzFtm7X2yl0v93hDsvUzkPsxvjG+NRTGOPs0cendG6k5c+Zg6tSpFq+JjY3F4cOHcfbsWbPnysrKzLJ8UyEhIejcuTM6d+6MgQMH4uabb8aKFSuwYMECh9ouaYjPcO3aNdx3333Iz8/Htm3bnN6bbYjP4A4RERHw8/Mz6/WVlpYqtrdNmzay1zdp0gTh4eEua6sSez4DeQbGN8Y3V2OMcwwTOxeIiIhQNW2QmJgIrVaLffv2oX///gCAvXv3QqvVIikpyab3FEURV69etau9clz9GaSg99tvv2H79u0u+eK5499DQwgICECfPn2wdetWTJo0Sf/41q1bcffdd8u+JjExEd9++63RY//73//Qt29f+Pv7u7S9cuz5DOQZGN8Y31yNMc5Bdm25IKcZPXq02KNHD3H37t3i7t27xe7du4vjx483uqZr165ienq6KIqieOnSJXHBggXi7t27xYKCAvHgwYPijBkzxMDAQPHnn392x0ew+TNcu3ZNnDBhgtiuXTsxNzdXLCkp0f+5evWqOz6CzZ9BFEXx3LlzYk5Ojrhp0yYRgPjVV1+JOTk5YklJicvb+9VXX4n+/v7iihUrxF9//VWcO3euGBISIhYUFIiiKIopKSnitGnT9Nf/8ccfYnBwsPjcc8+Jv/76q7hixQrR399f/O9//+vytiqx9TOIoijm5OSIOTk5Yp8+fcTk5GQxJydH/OWXX9zRfFKB8Y3xzV6McfbHOCZ2bnbu3DnxgQceEJs1ayY2a9ZMfOCBB8SKigqjawCIK1euFEVRFKurq8VJkyaJ0dHRYkBAgBgVFSVOmDBB3LdvX8M3vp6tn0HaPi/3Z/v27Q3eflG0/TOIoiiuXLlS9jO88sorDdLmJUuWiB06dBADAgLE3r17iz/++KP+uYcfflgcNmyY0fU7duwQExISxICAADE2Nlb86KOPGqSdltj6GeR+3x06dGjYRpNqjG+Mb45gjLMvxgn1NyIiIiIiL8ddsUREREQ+gokdERERkY9gYkdERETkI5jYEREREfkIJnZEREREPoKJHREREZGPYGJHRERE5COY2BERERH5CCZ2RERERD6CiR0RERGRj2BiR17hwQcfhCAIRn/Gjh3r7maZGT58OObOnevuZhCRF2F8I2dq4u4GEKnx6KOPYufOnRg6dCgmT56MTp06ISYmxuJrHnnkEbRp0wZpaWkN1EoiItsxvpEzMbEjj1dTU4OHHnoICxYswFNPPaXqNXV1ddi0aRM2bNjg4tYREdmP8Y2cjVOx5PFyc3Nx9uxZzJo1S/VrfvrpJ2g0GgwYMED2+eHDh+Ppp5/G3LlzERYWhtatW+PTTz9FVVUVpk+fjmbNmqFTp07YsmWL/jVXr17FM888g1atWqFp06YYPHgw9u/f7/DnI6LGi/GNnI2JHXm8Fi1a4Pr163jzzTdRWFiIuro6q6/ZsGED7rrrLmg0yv+Jf/7554iIiMC+ffvw9NNP48knn8Sf//xnJCUlITs7G6NGjcK0adNw+fJlAMC8efOwbt06fP7558jOzkbnzp0xatQonD9/3mmflYgaF8Y3cjqRyAssXbpUDAwMFAGIgiCIx44ds3h9ly5dxA0bNig+P2zYMHHw4MH6n69fvy6GhISI06ZN0z9WUlIiAhB3794tXrp0SfT39xdXrVqlf76mpkaMjo4W33rrLaP7Pvvss3Z8QiJqrBjfyJm4xo483ttvv423334bL7zwAoYPH45WrVrh5ptvVrz+6NGjOH36NO68806L9+3Ro4f+n/38/BAeHo7u3bvrH2vdujUAoLS0FCdOnMC1a9cwaNAg/fP+/v7o378/jh49au9HI6JGjvGNnI2JHXm0n376CS+99BIOHz6M+Ph4Va/ZsGED/vSnPyEoKMjidf7+/kY/C4Jg9JggCAB0C5VFUTR6TCKKotljRERqML6RK3CNHXm0jIwMdO/eXXXQA4BvvvkGEyZMcGo7OnfujICAAGRmZuofu3btGg4cOIBu3bo59b2IqHFgfCNXYGJHHq19+/Y4dOgQ3n77bfz666+orKy0eH1paSn279+P8ePHO7UdISEhePLJJ/Hiiy8iIyMDv/76K2bNmoXLly9jxowZTn0vImocGN/IFTgVSx5txowZKC0txcqVK/Hyyy/j6tWreOihh/D555/LXv/tt99iwIABaNWqldPbkpaWhrq6OkybNg0XL15E37598d133yEsLMzp70VEvo/xjVxBEKXJdSIvsGHDBtx99924fv06/Pz8zJ6fMGECBg8ejHnz5rmhdURE9mN8I2fgVCx5jaqqKmRmZqJPnz6yQQ8ABg8ejPvvv7+BW0ZE5BjGN3IWjtiR1/j000/xr3/9C5999plNi42JiDwd4xs5CxM7IiIiIh/BqVgiIiIiH8HEjoiIiMhHMLEjIiIi8hFM7IiIiIh8BBM7IiIiIh/BxI6IiIjIRzCxIyIiIvIRTOyIiIiIfAQTOyIiIiIfwcSOiIiIyEf8f01zSloRU1WwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xi_real = []\n",
    "xi_pred = []\n",
    "for (X,y) in train_dataloader:\n",
    "    xi_real = np.append(xi_real, y.numpy())\n",
    "    xi_pred = np.append(xi_pred, net(X).detach().numpy())\n",
    "\n",
    "xi_real_test = []\n",
    "xi_pred_test = []\n",
    "for (X,y) in test_dataloader:\n",
    "    xi_real_test = np.append(xi_real_test, y.numpy())\n",
    "    xi_pred_test = np.append(xi_pred_test, net(X).detach().numpy())\n",
    "\n",
    "# find the boundaries of X and Y values\n",
    "bounds = (min(xi_real.min(), xi_pred.min()) - int(0.1 * xi_pred.min()), max(xi_real.max(), xi_pred.max())+ int(0.1 * xi_pred.max()))\n",
    "\n",
    "fig,ax = plt.subplots(1,2)\n",
    "\n",
    "# # Reset the limits\n",
    "# ax[0] = plt.gca()\n",
    "ax[0].set_xlim(bounds)\n",
    "ax[0].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[0].plot(xi_real, xi_pred, '.')\n",
    "ax[0].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[0].transAxes)\n",
    "ax[0].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[0].set_title('Train Data')\n",
    "\n",
    "# Reset the limits\n",
    "#ax[1] = plt.gca()\n",
    "ax[1].set_xlim(bounds)\n",
    "ax[1].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[1].plot(xi_real_test, xi_pred_test, '.')\n",
    "ax[1].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[1].transAxes)\n",
    "ax[1].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[1].set_title('Test Data')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "fig.suptitle(\"Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5e5454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545dcb8",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8844, 0.1137, 0.1411, 0.2610, 0.5978],\n",
      "        [2.8770, 0.2230, 0.0898, 0.1979, 0.7123],\n",
      "        [2.8564, 0.1106, 0.3901, 0.0598, 0.5501],\n",
      "        [2.8746, 0.1486, 0.3976, 0.3092, 0.2932],\n",
      "        [2.8981, 0.1326, 0.0060, 0.9518, 0.0422],\n",
      "        [2.9053, 0.1314, 0.7077, 0.1869, 0.1054],\n",
      "        [2.8786, 0.2375, 0.8015, 0.1726, 0.0259],\n",
      "        [2.8962, 0.1581, 0.3084, 0.6852, 0.0064],\n",
      "        [2.8483, 0.1358, 0.0333, 0.3123, 0.6544],\n",
      "        [2.8638, 0.2302, 0.1246, 0.5652, 0.3101],\n",
      "        [2.8606, 0.1684, 0.8049, 0.0562, 0.1389],\n",
      "        [2.9166, 0.2458, 0.2051, 0.7422, 0.0527],\n",
      "        [2.8948, 0.1261, 0.0653, 0.7310, 0.2036],\n",
      "        [2.8658, 0.1043, 0.0398, 0.9394, 0.0208],\n",
      "        [2.8404, 0.2008, 0.1002, 0.1346, 0.7652],\n",
      "        [2.8896, 0.1693, 0.1919, 0.7536, 0.0545],\n",
      "        [2.8886, 0.2013, 0.0124, 0.8054, 0.1821],\n",
      "        [2.8272, 0.1356, 0.1571, 0.0265, 0.8164],\n",
      "        [2.9095, 0.1995, 0.2371, 0.0900, 0.6728],\n",
      "        [2.8786, 0.1780, 0.0097, 0.2260, 0.7643],\n",
      "        [2.8365, 0.2155, 0.3710, 0.4073, 0.2217],\n",
      "        [2.8891, 0.1755, 0.2076, 0.3062, 0.4861],\n",
      "        [2.8386, 0.1309, 0.0439, 0.0903, 0.8658],\n",
      "        [2.8516, 0.2499, 0.6584, 0.2449, 0.0968],\n",
      "        [2.8500, 0.1960, 0.6003, 0.0981, 0.3016],\n",
      "        [2.9194, 0.1429, 0.1949, 0.4748, 0.3303],\n",
      "        [2.8542, 0.1475, 0.3062, 0.6460, 0.0478],\n",
      "        [2.8289, 0.1628, 0.6176, 0.2110, 0.1714],\n",
      "        [2.9101, 0.1036, 0.5117, 0.4779, 0.0104],\n",
      "        [2.9296, 0.1400, 0.7756, 0.0485, 0.1759],\n",
      "        [2.9224, 0.2424, 0.8106, 0.0494, 0.1400],\n",
      "        [2.8619, 0.2358, 0.0171, 0.5974, 0.3855],\n",
      "        [2.9052, 0.2358, 0.2924, 0.3514, 0.3562],\n",
      "        [2.9059, 0.1664, 0.1907, 0.6829, 0.1264],\n",
      "        [2.8441, 0.2241, 0.4340, 0.5515, 0.0144],\n",
      "        [2.8421, 0.1741, 0.8018, 0.1138, 0.0844],\n",
      "        [2.9021, 0.1280, 0.1778, 0.6071, 0.2151],\n",
      "        [2.8354, 0.1729, 0.0151, 0.2037, 0.7812],\n",
      "        [2.8354, 0.1420, 0.5158, 0.1387, 0.3455],\n",
      "        [2.8722, 0.2442, 0.3567, 0.6126, 0.0307],\n",
      "        [2.8193, 0.1969, 0.7094, 0.0876, 0.2030],\n",
      "        [2.8912, 0.1985, 0.7645, 0.2004, 0.0351],\n",
      "        [2.9187, 0.1324, 0.2564, 0.3670, 0.3766],\n",
      "        [2.9068, 0.1855, 0.6782, 0.0707, 0.2510],\n",
      "        [2.8187, 0.2454, 0.3841, 0.4009, 0.2150],\n",
      "        [2.9074, 0.1104, 0.1262, 0.4546, 0.4192],\n",
      "        [2.8500, 0.1828, 0.4613, 0.4029, 0.1358],\n",
      "        [2.8961, 0.1933, 0.0184, 0.2188, 0.7628],\n",
      "        [2.8859, 0.2483, 0.3781, 0.4703, 0.1516],\n",
      "        [2.8245, 0.1357, 0.1793, 0.5623, 0.2585],\n",
      "        [2.8236, 0.1233, 0.3381, 0.2010, 0.4609],\n",
      "        [2.9241, 0.1635, 0.2355, 0.7152, 0.0492],\n",
      "        [2.8495, 0.1668, 0.1079, 0.0753, 0.8168],\n",
      "        [2.8229, 0.2212, 0.0531, 0.8979, 0.0490],\n",
      "        [2.9153, 0.1573, 0.0965, 0.5869, 0.3166],\n",
      "        [2.9199, 0.2111, 0.0073, 0.7218, 0.2709],\n",
      "        [2.9174, 0.1487, 0.6747, 0.0922, 0.2331],\n",
      "        [2.8274, 0.1799, 0.4086, 0.1237, 0.4678],\n",
      "        [2.8436, 0.2266, 0.4904, 0.3171, 0.1926],\n",
      "        [2.8919, 0.1132, 0.0874, 0.7757, 0.1369],\n",
      "        [2.8334, 0.2308, 0.4973, 0.3515, 0.1512],\n",
      "        [2.8526, 0.2425, 0.2556, 0.1680, 0.5764],\n",
      "        [2.8350, 0.1559, 0.9720, 0.0125, 0.0154],\n",
      "        [2.8356, 0.1515, 0.2485, 0.7480, 0.0035]])\n",
      "tensor([[-0.2167],\n",
      "        [-0.2076],\n",
      "        [-0.1581],\n",
      "        [-0.0573],\n",
      "        [-0.0181],\n",
      "        [-0.0031],\n",
      "        [ 0.0766],\n",
      "        [ 0.0234],\n",
      "        [-0.1870],\n",
      "        [-0.0635],\n",
      "        [ 0.0128],\n",
      "        [-0.0023],\n",
      "        [-0.0750],\n",
      "        [-0.0061],\n",
      "        [-0.1736],\n",
      "        [-0.0022],\n",
      "        [-0.0621],\n",
      "        [-0.2002],\n",
      "        [-0.2401],\n",
      "        [-0.2517],\n",
      "        [ 0.0217],\n",
      "        [-0.1490],\n",
      "        [-0.2451],\n",
      "        [ 0.0821],\n",
      "        [-0.0131],\n",
      "        [-0.1233],\n",
      "        [ 0.0270],\n",
      "        [ 0.0567],\n",
      "        [ 0.0231],\n",
      "        [-0.0539],\n",
      "        [-0.0184],\n",
      "        [-0.0981],\n",
      "        [-0.0947],\n",
      "        [-0.0337],\n",
      "        [ 0.0753],\n",
      "        [ 0.0638],\n",
      "        [-0.0726],\n",
      "        [-0.1894],\n",
      "        [-0.0273],\n",
      "        [ 0.0434],\n",
      "        [ 0.0480],\n",
      "        [ 0.0558],\n",
      "        [-0.1417],\n",
      "        [-0.0593],\n",
      "        [ 0.0482],\n",
      "        [-0.1654],\n",
      "        [ 0.0369],\n",
      "        [-0.2692],\n",
      "        [ 0.0032],\n",
      "        [-0.0298],\n",
      "        [-0.0664],\n",
      "        [-0.0066],\n",
      "        [-0.2235],\n",
      "        [-0.0020],\n",
      "        [-0.1192],\n",
      "        [-0.1039],\n",
      "        [-0.0672],\n",
      "        [-0.0464],\n",
      "        [ 0.0418],\n",
      "        [-0.0489],\n",
      "        [ 0.0652],\n",
      "        [-0.1060],\n",
      "        [ 0.0120],\n",
      "        [ 0.0377]])\n",
      "tensor([[-1.7427e-01],\n",
      "        [-2.2203e-01],\n",
      "        [-1.3956e-01],\n",
      "        [-5.4601e-02],\n",
      "        [-5.3807e-03],\n",
      "        [ 1.3677e-02],\n",
      "        [ 3.1413e-02],\n",
      "        [ 2.9110e-02],\n",
      "        [-1.9050e-01],\n",
      "        [-9.9297e-02],\n",
      "        [ 1.9802e-02],\n",
      "        [-6.6852e-03],\n",
      "        [-3.5431e-02],\n",
      "        [ 7.3344e-03],\n",
      "        [-2.3682e-01],\n",
      "        [ 7.0217e-03],\n",
      "        [-4.5785e-02],\n",
      "        [-2.4686e-01],\n",
      "        [-2.0787e-01],\n",
      "        [-2.4261e-01],\n",
      "        [-8.0622e-02],\n",
      "        [-1.3369e-01],\n",
      "        [-2.6542e-01],\n",
      "        [ 1.9492e-02],\n",
      "        [-1.0281e-01],\n",
      "        [-8.0662e-02],\n",
      "        [ 1.9783e-02],\n",
      "        [ 3.1942e-03],\n",
      "        [ 4.7053e-02],\n",
      "        [ 4.5782e-03],\n",
      "        [ 4.2094e-02],\n",
      "        [-1.1136e-01],\n",
      "        [-6.1195e-02],\n",
      "        [-1.5819e-02],\n",
      "        [ 3.4880e-02],\n",
      "        [ 4.5710e-02],\n",
      "        [-8.0010e-02],\n",
      "        [-2.4920e-01],\n",
      "        [-7.5851e-02],\n",
      "        [ 1.6012e-02],\n",
      "        [-1.8962e-02],\n",
      "        [ 4.7606e-02],\n",
      "        [-6.1238e-02],\n",
      "        [-1.3667e-02],\n",
      "        [-1.5155e-02],\n",
      "        [-1.1271e-01],\n",
      "        [ 1.6881e-04],\n",
      "        [-2.4339e-01],\n",
      "        [-1.5489e-02],\n",
      "        [-4.8648e-02],\n",
      "        [-1.0831e-01],\n",
      "        [ 9.7251e-03],\n",
      "        [-2.5326e-01],\n",
      "        [ 7.4383e-03],\n",
      "        [-7.5761e-02],\n",
      "        [-1.1200e-01],\n",
      "        [-2.0493e-02],\n",
      "        [-1.1528e-01],\n",
      "        [-7.8186e-03],\n",
      "        [-2.3021e-02],\n",
      "        [-9.1402e-03],\n",
      "        [-1.6423e-01],\n",
      "        [ 6.4069e-02],\n",
      "        [ 2.4036e-02]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fa554",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.5218e-01,  2.0328e-02, -1.2856e-01, -2.2727e-01, -3.4185e-01],\n",
       "         [ 3.2245e-01, -4.2546e-02, -4.3903e-01, -3.5057e-01, -4.0133e-02],\n",
       "         [ 2.4342e-01,  1.0523e-01,  2.0466e-01,  2.0433e-02, -4.3570e-01],\n",
       "         [-1.1225e-01,  3.6787e-01, -1.6835e-01, -2.1828e-01,  1.3345e-01],\n",
       "         [ 1.7182e-01,  1.5793e-01, -3.3831e-01,  6.7314e-02, -1.0308e-01],\n",
       "         [ 1.7874e-01,  2.8195e-01, -1.4830e-01,  2.2074e-01, -8.4795e-02],\n",
       "         [ 2.4910e-01, -6.3608e-02, -3.6720e-02, -2.4913e-01,  1.1801e-01],\n",
       "         [-3.6438e-01, -3.6556e-01, -2.4893e-01,  5.8167e-02,  9.9194e-02],\n",
       "         [-3.6678e-01,  7.4277e-02, -2.6346e-01,  2.2830e-01,  6.3421e-02],\n",
       "         [-3.3905e-01,  2.6863e-01, -4.3291e-01,  8.3837e-02, -3.0016e-01],\n",
       "         [-2.5347e-01, -8.9617e-02, -3.2540e-01, -4.3177e-01,  2.0168e-01],\n",
       "         [ 1.0326e-01, -3.4124e-01, -9.5799e-02,  3.2070e-01, -3.0468e-01],\n",
       "         [-2.6177e-01,  1.9794e-01,  1.2585e-01, -9.9574e-02,  1.1501e-01],\n",
       "         [ 2.8529e-01,  9.1299e-02, -3.1528e-01, -3.8902e-01, -1.3536e-01],\n",
       "         [-1.2072e-01,  2.7006e-02,  1.8044e-01,  4.1878e-01, -1.0364e-01],\n",
       "         [ 3.8111e-01, -2.2946e-02,  2.5839e-01,  2.4130e-01, -1.0740e-01],\n",
       "         [-3.3150e-02,  2.9280e-01,  1.9836e-01,  2.9806e-01,  1.4560e-01],\n",
       "         [ 7.7858e-02, -1.5414e-01,  2.3339e-01, -3.3543e-01,  4.0004e-01],\n",
       "         [ 1.7734e-01, -1.1426e-01,  1.7307e-01, -1.7115e-01, -1.8904e-01],\n",
       "         [ 2.6908e-01,  1.3209e-01,  1.8652e-01,  1.7912e-01, -2.7271e-01],\n",
       "         [-3.4709e-01,  4.1720e-01,  4.1184e-01,  3.5988e-02, -2.3941e-01],\n",
       "         [-1.1712e-01,  1.8438e-01,  2.4691e-01,  9.1996e-02, -2.7728e-01],\n",
       "         [-2.9594e-01,  1.0397e-01,  4.7394e-02, -3.3931e-02, -1.1348e-01],\n",
       "         [-2.3272e-01,  4.1672e-02,  3.0926e-01,  1.3660e-01,  2.0779e-01],\n",
       "         [ 9.3341e-02, -2.7957e-02, -3.3425e-01, -4.0443e-01, -4.1367e-01],\n",
       "         [ 2.2369e-01, -1.6863e-01,  3.2370e-01,  3.3354e-01, -1.7733e-01],\n",
       "         [ 3.8447e-01, -1.9429e-01,  1.2601e-01,  2.8132e-01, -2.0527e-01],\n",
       "         [-7.0096e-02, -3.7151e-01, -1.1945e-01,  1.9953e-01,  7.8725e-02],\n",
       "         [ 3.1479e-01, -2.1641e-01,  3.4823e-01, -7.8155e-03,  1.3414e-01],\n",
       "         [ 1.5382e-01,  3.1670e-01, -2.8122e-01,  1.6193e-01, -1.5681e-01],\n",
       "         [ 1.3775e-01, -1.1823e-01,  1.4138e-01,  3.3092e-01,  5.1684e-02],\n",
       "         [-1.9191e-02, -2.0484e-01, -4.3662e-01, -2.0133e-01,  2.3697e-01],\n",
       "         [ 2.0930e-01,  6.1439e-02, -2.8726e-01, -6.9280e-02, -1.4551e-01],\n",
       "         [-9.4575e-02,  2.8705e-01, -2.5831e-01, -2.6368e-02, -9.7671e-02],\n",
       "         [-3.8200e-01, -1.4273e-02, -1.1975e-01,  3.7380e-01,  2.2390e-01],\n",
       "         [ 2.9962e-01,  3.8487e-01, -4.3390e-01, -1.5489e-01,  3.3437e-01],\n",
       "         [-2.3864e-01, -8.2327e-02, -2.3028e-01,  2.7372e-01, -4.4394e-01],\n",
       "         [ 3.8987e-01,  1.1378e-02, -2.7368e-01,  1.0719e-01, -3.2018e-01],\n",
       "         [-1.4908e-01, -6.9522e-02, -4.4986e-02, -2.9491e-01, -1.5096e-01],\n",
       "         [-6.5111e-02,  3.3436e-01,  7.0083e-02,  1.1759e-01, -1.7015e-01],\n",
       "         [-2.8626e-01, -1.1603e-02,  4.7129e-02, -4.1735e-01,  2.3547e-01],\n",
       "         [ 5.7216e-02, -3.1959e-02, -2.3331e-01, -3.1889e-02, -2.4870e-02],\n",
       "         [-3.1626e-01,  3.9260e-01, -4.2627e-01, -3.7381e-01, -4.0656e-01],\n",
       "         [ 2.6888e-01,  3.0712e-01, -4.0999e-01, -3.7243e-01, -1.8085e-01],\n",
       "         [-3.7365e-01,  1.8425e-02, -2.5641e-01, -3.6746e-01, -4.0820e-01],\n",
       "         [-1.2720e-02, -1.3586e-01,  1.7187e-01,  3.3910e-01, -2.0665e-01],\n",
       "         [-2.5841e-01,  2.9041e-01, -3.4351e-01,  2.5434e-01, -3.1360e-01],\n",
       "         [ 3.0597e-01,  3.5824e-01,  3.2050e-02,  3.3229e-01,  2.9993e-01],\n",
       "         [ 1.9791e-01, -2.9264e-01,  5.8426e-02,  1.1262e-01,  4.2845e-01],\n",
       "         [-2.5153e-01, -9.1212e-02,  1.6335e-01,  4.1123e-01,  4.0396e-01],\n",
       "         [-3.1962e-01, -3.7182e-01,  1.9534e-01, -3.9566e-01, -8.2956e-02],\n",
       "         [ 1.8386e-01,  3.4267e-01, -1.5617e-01, -3.7465e-01,  2.6658e-01],\n",
       "         [ 2.7007e-01, -4.6210e-03,  2.3270e-01,  1.7860e-01, -1.5386e-01],\n",
       "         [-2.7304e-01, -1.7735e-01, -3.8414e-01, -1.4682e-01, -3.2195e-01],\n",
       "         [-1.3653e-01,  3.6411e-01, -6.3543e-02,  3.6947e-01, -2.8031e-01],\n",
       "         [ 6.8385e-04, -1.4203e-01, -1.1558e-01,  1.1629e-01, -1.8031e-01],\n",
       "         [ 3.6191e-02,  3.2114e-01,  6.9228e-02,  3.6873e-01, -4.8770e-02],\n",
       "         [ 3.3476e-01, -1.4351e-02, -1.5120e-01, -3.4698e-01,  5.8704e-04],\n",
       "         [-3.7774e-01,  5.6375e-02, -9.2081e-02,  1.0465e-01,  5.4665e-02],\n",
       "         [-1.5096e-01, -3.5632e-01,  1.8263e-01, -2.3001e-01, -1.7539e-01],\n",
       "         [ 3.9317e-02,  9.5105e-02,  9.4273e-02,  1.3686e-01,  2.2251e-01],\n",
       "         [ 1.2690e-01,  3.4386e-01, -6.7915e-02, -3.6010e-01,  3.0274e-01],\n",
       "         [-2.3675e-01, -3.9633e-01, -1.9435e-01, -1.9282e-01, -1.1111e-01],\n",
       "         [-4.3636e-01, -7.3469e-02, -4.0108e-01,  8.0857e-02, -1.6556e-01],\n",
       "         [ 3.6690e-01,  3.1123e-01,  1.8941e-01, -2.6412e-01, -2.8126e-01],\n",
       "         [ 3.0247e-01, -4.0276e-01, -1.1643e-01,  1.1164e-01,  1.2554e-01],\n",
       "         [ 4.3765e-01, -2.4863e-01,  2.2387e-01, -2.5912e-01, -2.6450e-01],\n",
       "         [ 8.6856e-02,  1.3527e-01, -2.5387e-02, -1.7547e-01,  6.4256e-02],\n",
       "         [ 2.0010e-01, -3.7402e-01,  4.0631e-01,  1.9115e-01, -2.3400e-01],\n",
       "         [-3.2391e-01, -3.8204e-01,  2.1016e-01,  1.4926e-02, -4.3082e-01],\n",
       "         [-2.5196e-02,  2.4163e-01,  1.3233e-01, -1.5238e-02, -3.4731e-01],\n",
       "         [ 4.5933e-02,  2.7342e-01,  1.6823e-01, -2.6467e-01, -2.6247e-01],\n",
       "         [ 1.5272e-01,  2.4028e-01, -2.3813e-01, -3.4220e-01,  2.1530e-01],\n",
       "         [-1.6783e-01,  3.5908e-01, -4.1832e-01,  3.3546e-01, -3.5565e-01],\n",
       "         [-2.0437e-01, -2.8927e-01,  1.0713e-01,  6.1653e-02, -2.4214e-01],\n",
       "         [ 3.4400e-01,  2.7993e-01, -1.5343e-01, -2.0896e-01,  3.0548e-01],\n",
       "         [ 1.9669e-01,  3.6665e-01, -3.1459e-01, -1.7590e-01,  1.2589e-02],\n",
       "         [-3.7522e-01,  3.6796e-02,  7.3274e-02,  3.3962e-01, -4.0908e-01],\n",
       "         [ 3.2341e-01,  4.0109e-01, -4.1412e-01,  1.2162e-01, -2.2822e-01],\n",
       "         [-4.1336e-01, -1.4860e-01, -1.5243e-01,  1.2625e-01,  3.2040e-01],\n",
       "         [ 3.9255e-05, -2.8684e-01,  9.2321e-02, -2.5773e-01, -2.2723e-01],\n",
       "         [ 2.5746e-02, -1.6348e-01,  5.2957e-02,  3.8487e-01, -2.5689e-02],\n",
       "         [-1.4090e-01,  1.9298e-01, -9.6091e-02,  3.1066e-01,  1.7326e-02],\n",
       "         [-3.1094e-01, -1.4859e-01, -3.4025e-01, -3.9766e-01, -4.2042e-01],\n",
       "         [ 5.4063e-02, -3.5386e-01,  1.8165e-01,  1.4219e-01,  2.6351e-01],\n",
       "         [-2.0250e-01, -9.3177e-02, -2.2204e-01,  3.5276e-01, -1.9571e-01],\n",
       "         [-3.7965e-01,  3.4874e-02, -3.5023e-01, -7.5885e-02,  4.0624e-01],\n",
       "         [-9.2646e-02, -1.9129e-01, -1.3030e-01,  3.4740e-01, -1.6130e-01],\n",
       "         [-9.5648e-02, -3.8833e-01,  4.1436e-01, -2.8137e-01, -3.0629e-01],\n",
       "         [-3.1188e-01,  3.7215e-01, -2.5914e-01,  9.8490e-04, -3.7518e-01],\n",
       "         [-4.3326e-01,  2.5006e-01, -3.9654e-01, -2.7615e-01,  2.0364e-01],\n",
       "         [ 3.3173e-01,  2.8285e-01, -3.1189e-01,  3.5654e-01, -5.5311e-02],\n",
       "         [-3.9920e-01, -3.0210e-01,  3.8551e-01,  3.6320e-01,  1.7368e-01],\n",
       "         [-3.6992e-01, -3.3093e-01, -4.2266e-01, -1.3891e-01, -4.0997e-01],\n",
       "         [ 4.0067e-02,  4.4185e-03, -3.0284e-01,  8.9193e-02,  2.4450e-01],\n",
       "         [-7.5888e-02,  4.2793e-01,  9.5550e-03, -3.4462e-02, -3.4532e-01],\n",
       "         [ 2.6815e-02,  3.2120e-01, -3.4291e-01, -4.7684e-02,  4.8665e-02],\n",
       "         [ 1.7361e-01,  8.1951e-02, -3.8575e-01, -8.9168e-02,  9.7188e-02],\n",
       "         [-1.1039e-01, -7.1295e-02,  4.2410e-01,  9.9468e-02, -3.6044e-01],\n",
       "         [-3.9607e-01, -3.6464e-01, -1.1068e-01, -2.6199e-01, -2.3754e-01],\n",
       "         [-4.6179e-02, -2.7983e-01, -4.1312e-01, -7.4318e-03,  1.5156e-01],\n",
       "         [-3.0200e-01, -2.0084e-01, -2.1587e-01, -2.4329e-01,  3.3979e-01],\n",
       "         [-2.0310e-02, -3.4570e-01, -1.9304e-01, -3.8704e-01,  2.5938e-01],\n",
       "         [ 1.5148e-01,  3.4415e-01,  3.7157e-02, -2.0495e-01, -3.6818e-01],\n",
       "         [-2.2610e-02, -1.5556e-01,  7.7935e-02,  1.2688e-01, -1.9892e-01],\n",
       "         [-1.1026e-01,  1.7765e-01, -1.4825e-02,  2.5602e-01,  3.9347e-01],\n",
       "         [-3.5175e-01,  4.4479e-01, -4.4163e-01, -1.1963e-03,  2.4695e-02],\n",
       "         [-2.1764e-01, -1.6022e-01,  3.5034e-01,  2.7761e-01, -7.1522e-02],\n",
       "         [-1.7647e-01, -3.7609e-01,  2.1288e-01, -1.3632e-01, -4.1902e-02],\n",
       "         [ 2.3216e-01, -3.0628e-01,  1.7785e-01,  1.3253e-01, -2.3502e-01],\n",
       "         [-2.2708e-01,  3.8471e-01,  1.4483e-01,  4.2589e-01,  2.0143e-01],\n",
       "         [-3.6515e-01, -1.2497e-01, -4.3845e-01,  8.9293e-02,  2.2644e-01],\n",
       "         [-3.0778e-01,  8.8092e-02,  2.1771e-02, -1.3005e-01, -4.4085e-01],\n",
       "         [ 1.3495e-01, -1.3698e-01, -2.9836e-01, -2.2777e-01,  1.7616e-01],\n",
       "         [ 2.3955e-02,  1.3262e-01, -2.8022e-02, -4.0943e-01,  7.6261e-03],\n",
       "         [-4.3111e-01,  6.8284e-02, -4.1144e-01,  7.8341e-02, -4.2119e-01],\n",
       "         [-1.7166e-01,  3.0821e-01, -1.6106e-01,  2.1262e-01, -1.6086e-01],\n",
       "         [ 4.8201e-02,  2.3019e-01, -3.1427e-03, -2.8940e-01,  2.1119e-01],\n",
       "         [-3.5160e-02,  3.4539e-01,  3.3297e-01,  1.7894e-01, -1.9285e-01],\n",
       "         [ 3.4241e-01,  4.0001e-02,  1.0405e-01, -4.0956e-02,  2.3019e-01],\n",
       "         [ 3.1435e-01, -1.2900e-01, -3.3637e-01,  2.3975e-01, -8.9854e-02],\n",
       "         [ 3.1690e-01,  1.2460e-01, -3.7394e-01,  1.0643e-01, -1.8305e-01],\n",
       "         [-8.6544e-04,  4.2076e-01, -4.1031e-01,  1.4707e-01,  1.3518e-01],\n",
       "         [ 3.7461e-01,  6.0445e-02, -7.7404e-02,  2.1715e-01, -1.2752e-01],\n",
       "         [-3.3499e-01, -3.9886e-01, -3.0146e-01, -1.0497e-01, -1.3272e-02],\n",
       "         [-7.3284e-02,  3.5570e-01, -3.3958e-03,  9.7434e-02,  4.4289e-01],\n",
       "         [-2.5151e-01, -4.5891e-02, -3.1831e-01,  3.4341e-01, -1.8997e-01],\n",
       "         [-2.6544e-01, -2.3306e-01,  7.7320e-02, -3.2532e-01, -3.3626e-01],\n",
       "         [ 3.3580e-02, -2.1991e-01, -5.3886e-02, -3.7194e-01, -3.3277e-01],\n",
       "         [ 2.6210e-01,  2.3265e-01, -2.2859e-01, -2.9804e-01,  2.5432e-01],\n",
       "         [ 3.5772e-01,  1.7028e-01,  1.6513e-01, -8.8800e-02, -3.7151e-01],\n",
       "         [ 2.6244e-01, -3.8081e-01, -3.5407e-01, -5.2579e-02, -1.0039e-01],\n",
       "         [-3.7642e-01, -7.7953e-02,  4.0027e-01, -6.1418e-02, -2.3039e-01],\n",
       "         [ 2.3940e-01, -3.3577e-01,  1.2946e-01,  4.4334e-01, -8.6988e-02],\n",
       "         [-3.5044e-01,  4.1842e-01, -1.7480e-01,  2.9390e-01, -4.4399e-01],\n",
       "         [-3.9722e-01,  2.7450e-01,  3.3896e-01,  4.2472e-01,  1.2941e-01],\n",
       "         [ 1.4530e-01, -3.0983e-01,  2.7550e-02,  1.2061e-01,  4.4014e-01],\n",
       "         [ 2.6401e-01, -3.6762e-01,  2.0942e-01,  3.0925e-01, -1.8913e-01],\n",
       "         [-2.3259e-01,  1.9071e-01,  2.5126e-01, -4.4211e-01, -3.4306e-03],\n",
       "         [ 4.0373e-01,  5.0044e-03,  9.2628e-02, -1.8441e-01, -3.9620e-01],\n",
       "         [-2.8051e-01,  2.6410e-01, -3.0502e-01, -2.6903e-01,  7.3972e-02],\n",
       "         [-3.6899e-01, -1.0786e-02, -4.0055e-01,  3.8358e-01, -1.4937e-01],\n",
       "         [-2.4628e-01, -1.7250e-01, -3.4874e-01,  2.0258e-01, -5.9123e-02],\n",
       "         [-4.1166e-02,  2.0006e-01,  4.2864e-01, -2.2255e-01,  3.2705e-01],\n",
       "         [ 2.7655e-01,  8.8289e-03,  1.1905e-01,  4.4338e-01,  4.7043e-02],\n",
       "         [-2.6083e-01, -1.0714e-01, -2.8443e-01, -2.3009e-01, -2.9922e-01],\n",
       "         [ 2.6383e-01, -3.2505e-01, -8.5251e-02,  3.3070e-03, -1.6591e-01],\n",
       "         [-2.0126e-01,  1.1076e-01,  2.6638e-01, -2.3099e-01, -3.5218e-02],\n",
       "         [ 1.8739e-02, -4.2353e-01,  1.7356e-01,  7.2767e-03,  4.1093e-01],\n",
       "         [-1.9141e-01,  1.7790e-01,  3.1611e-01, -2.3652e-01, -2.5500e-02],\n",
       "         [-3.5316e-01,  2.6188e-01,  2.0028e-02, -1.4403e-01, -2.1297e-01],\n",
       "         [-1.3100e-01,  3.7280e-02, -6.1004e-02, -4.9801e-02, -2.7790e-01],\n",
       "         [ 2.1709e-01,  9.3222e-02,  3.7048e-01, -8.2408e-03,  3.0665e-01],\n",
       "         [-3.8634e-01, -1.8232e-01,  2.9231e-01, -3.3531e-03, -2.8198e-01],\n",
       "         [-2.5102e-01,  2.7495e-01,  4.0069e-01,  2.3665e-01,  2.1857e-01],\n",
       "         [-9.7500e-02,  1.2273e-01, -9.9925e-02, -1.1591e-01, -9.8559e-03],\n",
       "         [-3.4860e-01,  2.7449e-01, -7.2129e-02,  2.9945e-01,  1.5467e-01],\n",
       "         [ 2.9524e-02, -8.5421e-02, -4.1499e-01, -5.7507e-02, -4.1996e-01],\n",
       "         [-2.2538e-01,  4.0111e-01,  1.4363e-01,  1.1679e-01, -2.4258e-02],\n",
       "         [-1.6947e-02, -9.3284e-03, -9.8624e-02,  1.7827e-01,  8.9519e-03],\n",
       "         [ 2.2820e-01, -2.7210e-02,  3.8224e-01, -3.3470e-01, -2.0849e-02],\n",
       "         [ 1.4802e-01,  8.1792e-03,  2.2868e-01, -3.5480e-01, -1.3141e-01],\n",
       "         [-1.0872e-02,  2.9561e-01, -7.5607e-02,  5.6428e-02, -7.4549e-02],\n",
       "         [-2.5535e-01,  2.1408e-01,  3.3373e-01, -3.3100e-02,  1.0741e-01],\n",
       "         [-1.0275e-01, -1.5240e-01,  9.4777e-02, -3.3341e-01,  3.3067e-01],\n",
       "         [ 4.4115e-01, -2.4390e-01, -1.0535e-01, -1.7259e-01, -2.3521e-01],\n",
       "         [ 2.2817e-01, -3.1284e-01,  3.0402e-02,  1.3136e-01,  1.8373e-01],\n",
       "         [-3.4608e-01, -1.5087e-01,  1.1059e-01,  1.1333e-01, -6.1468e-02],\n",
       "         [ 4.1735e-02, -1.8999e-01, -2.0667e-01,  1.3526e-01, -3.2336e-01],\n",
       "         [ 5.5289e-03,  1.8741e-01,  3.6180e-01, -2.1877e-01, -1.5644e-01],\n",
       "         [-2.5250e-01,  3.4325e-01, -3.2962e-01, -1.5274e-01, -2.0196e-01],\n",
       "         [ 3.5029e-01, -3.9085e-01,  2.7044e-01,  1.9798e-01, -2.6373e-01],\n",
       "         [ 9.0214e-02, -5.5067e-02, -5.6063e-02,  1.8334e-01, -8.9741e-02],\n",
       "         [-2.6515e-01,  1.5914e-02, -2.0997e-01,  1.2524e-02,  1.0420e-01],\n",
       "         [-3.9149e-01,  1.9764e-01,  2.1911e-01, -1.1420e-01,  1.6574e-01],\n",
       "         [-3.8370e-02,  1.9626e-01, -4.1597e-01,  2.8543e-01, -4.4314e-01],\n",
       "         [ 2.0571e-01,  1.6546e-01, -2.7316e-03, -1.1343e-01, -3.4943e-01],\n",
       "         [ 2.8439e-01,  4.6147e-02,  3.7192e-01,  4.2837e-01,  2.3067e-01],\n",
       "         [-3.7232e-02,  2.2348e-02,  1.1165e-01, -2.6959e-01,  1.1937e-01],\n",
       "         [-3.0674e-01,  3.1413e-01,  2.5781e-01, -4.2789e-01,  3.1341e-02],\n",
       "         [ 2.2650e-01, -2.7622e-01, -2.5146e-01, -5.2879e-02, -1.6011e-02],\n",
       "         [-2.5091e-01, -2.0348e-01, -1.3776e-01,  2.5518e-01, -3.4654e-01],\n",
       "         [ 1.5759e-01, -2.3446e-01, -9.5549e-02, -1.4963e-01,  3.6198e-01],\n",
       "         [ 2.2161e-01, -2.8195e-01,  9.4097e-02, -2.4592e-02, -3.1805e-01],\n",
       "         [ 3.3620e-01,  4.4020e-01,  2.5855e-01,  3.6019e-01,  4.8915e-02],\n",
       "         [ 1.8838e-01, -9.9895e-02, -1.3225e-01,  4.1340e-01, -9.1231e-02],\n",
       "         [ 2.4371e-01,  3.2409e-01, -2.8500e-01,  1.1851e-01,  2.2460e-01],\n",
       "         [ 3.1174e-01,  2.7143e-01,  3.1175e-01, -3.8531e-01, -2.1999e-02],\n",
       "         [ 2.9246e-01,  1.1602e-01,  4.3298e-01, -4.0890e-01, -1.6455e-01],\n",
       "         [-1.4702e-01, -4.4702e-01, -2.3322e-01, -3.1818e-01,  2.3529e-01],\n",
       "         [-1.4630e-01,  4.9371e-02, -2.1916e-01,  2.1973e-02, -1.8320e-01],\n",
       "         [ 4.0773e-01,  3.1798e-02,  3.6743e-01,  3.5926e-01,  4.3657e-01],\n",
       "         [-2.2554e-01,  3.2164e-01, -3.3316e-01,  2.2762e-01, -2.4449e-01],\n",
       "         [-3.4455e-01, -1.7660e-01,  2.0618e-01, -4.8863e-02,  1.6093e-01],\n",
       "         [ 3.5225e-01, -3.9498e-01, -3.0812e-01,  3.9970e-01,  4.8796e-02],\n",
       "         [ 1.9464e-01,  4.4564e-01,  4.2259e-01, -2.9405e-01,  1.2781e-01],\n",
       "         [-2.3863e-01,  3.8826e-01,  3.8489e-01,  6.6587e-02, -1.5427e-03],\n",
       "         [-2.4457e-01,  3.5824e-02,  3.1420e-01,  3.9778e-01,  7.1620e-03],\n",
       "         [ 3.6357e-01,  9.4578e-02, -6.3229e-02, -1.6633e-02, -1.3776e-01],\n",
       "         [ 2.8847e-01, -3.2358e-01,  8.0707e-02, -1.4628e-01,  4.4192e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3470,  0.3213,  0.4015,  0.0758, -0.2129,  0.3727, -0.2206, -0.1706,\n",
       "          0.0834,  0.2347, -0.1822,  0.1656,  0.0672,  0.3212, -0.0528,  0.4451,\n",
       "         -0.4289, -0.2664, -0.4265,  0.3567, -0.1633, -0.4179, -0.2021, -0.2438,\n",
       "         -0.3830, -0.2776, -0.3335, -0.2128, -0.4058, -0.4132, -0.3479,  0.1789,\n",
       "          0.0365,  0.3314, -0.2143, -0.2754,  0.4271, -0.0931, -0.3281, -0.4330,\n",
       "         -0.3068,  0.4348, -0.1050, -0.4109, -0.2416, -0.3980,  0.0250,  0.3076,\n",
       "          0.3503, -0.1993, -0.2256,  0.3103,  0.3435,  0.4414,  0.4249, -0.2386,\n",
       "         -0.4357, -0.2201, -0.1931, -0.0244,  0.2602,  0.0651,  0.1308,  0.3631,\n",
       "          0.1688,  0.4254, -0.1464,  0.3181,  0.0675, -0.2771,  0.0192,  0.0055,\n",
       "         -0.2912, -0.0702, -0.4065,  0.3173,  0.0418,  0.2166,  0.0877, -0.1340,\n",
       "          0.1925,  0.3367,  0.4271, -0.3734, -0.3536, -0.1349, -0.2463, -0.1422,\n",
       "          0.1465, -0.4155, -0.0206, -0.0040,  0.1613,  0.1492,  0.2269,  0.0468,\n",
       "         -0.2108,  0.1458, -0.1489, -0.0040, -0.4145,  0.2041,  0.1638, -0.1399,\n",
       "         -0.3389,  0.2478,  0.4325, -0.0630, -0.1685,  0.3993, -0.2841, -0.3533,\n",
       "         -0.1910, -0.0805,  0.1518, -0.2308, -0.4436, -0.2515, -0.3903,  0.2021,\n",
       "          0.0367, -0.0370,  0.2501, -0.4223, -0.4010,  0.2598, -0.4261, -0.2257,\n",
       "          0.1338, -0.1453, -0.3625, -0.0650,  0.2455, -0.2479, -0.0210,  0.0195,\n",
       "          0.3439, -0.4157,  0.4094,  0.0413,  0.4264, -0.0630, -0.2401,  0.2277,\n",
       "          0.3873,  0.1511, -0.3089, -0.3465, -0.2010, -0.4199, -0.0810,  0.0860,\n",
       "          0.1048, -0.2205, -0.0993,  0.2924, -0.0440,  0.4402, -0.1496,  0.2314,\n",
       "          0.2169,  0.4459,  0.3618, -0.0876,  0.0413,  0.0279,  0.1974, -0.1641,\n",
       "         -0.0647, -0.2010, -0.0368, -0.3721,  0.2038, -0.2355, -0.0386, -0.3453,\n",
       "          0.2435, -0.0932,  0.3125, -0.3396, -0.3883,  0.3803, -0.1226,  0.0909,\n",
       "         -0.1975, -0.3769, -0.2276, -0.1676, -0.2072, -0.2635,  0.2155, -0.1034,\n",
       "          0.0621, -0.2978, -0.0912, -0.2384,  0.0139, -0.0095,  0.0177, -0.4173],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0053,  0.0699, -0.0657,  ...,  0.0550,  0.0261, -0.0430],\n",
       "         [ 0.0383, -0.0619,  0.0592,  ...,  0.0123,  0.0494, -0.0516],\n",
       "         [-0.0488, -0.0488, -0.0481,  ...,  0.0033,  0.0516,  0.0214],\n",
       "         ...,\n",
       "         [ 0.0702,  0.0165,  0.0283,  ..., -0.0102, -0.0571,  0.0100],\n",
       "         [-0.0650,  0.0244,  0.0400,  ..., -0.0701, -0.0262,  0.0544],\n",
       "         [ 0.0310,  0.0360, -0.0677,  ...,  0.0628,  0.0194, -0.0129]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0195, -0.0429, -0.0169,  0.0200, -0.0403,  0.0080,  0.0045,  0.0533,\n",
       "         -0.0277,  0.0569,  0.0669, -0.0157, -0.0033, -0.0670, -0.0068, -0.0095,\n",
       "         -0.0416,  0.0296, -0.0341,  0.0616,  0.0167, -0.0230, -0.0410, -0.0569,\n",
       "         -0.0098,  0.0005,  0.0511,  0.0679,  0.0238, -0.0073,  0.0159, -0.0042,\n",
       "          0.0047, -0.0123, -0.0398,  0.0554,  0.0651,  0.0249,  0.0509, -0.0038,\n",
       "         -0.0165, -0.0625, -0.0670, -0.0124,  0.0590, -0.0575, -0.0255, -0.0508,\n",
       "         -0.0472,  0.0273, -0.0147, -0.0619, -0.0248, -0.0627, -0.0384, -0.0319,\n",
       "         -0.0447,  0.0304,  0.0251,  0.0431, -0.0681, -0.0515,  0.0614, -0.0177,\n",
       "          0.0171,  0.0133,  0.0187, -0.0365, -0.0269,  0.0059,  0.0097, -0.0344,\n",
       "          0.0575,  0.0650, -0.0418, -0.0446, -0.0392, -0.0483, -0.0544,  0.0051,\n",
       "          0.0390, -0.0485,  0.0533,  0.0407, -0.0233,  0.0093,  0.0598,  0.0707,\n",
       "         -0.0243,  0.0280, -0.0487, -0.0053,  0.0289, -0.0629,  0.0583, -0.0032,\n",
       "          0.0478,  0.0115,  0.0694, -0.0148,  0.0414, -0.0623, -0.0406, -0.0240,\n",
       "         -0.0399, -0.0693,  0.0034,  0.0229,  0.0624,  0.0425, -0.0355,  0.0071,\n",
       "         -0.0050, -0.0567, -0.0352, -0.0339, -0.0568,  0.0122, -0.0314, -0.0104,\n",
       "         -0.0516,  0.0330,  0.0651, -0.0259,  0.0352, -0.0395, -0.0406,  0.0571,\n",
       "          0.0090, -0.0485,  0.0693, -0.0447, -0.0417,  0.0288, -0.0211, -0.0636,\n",
       "          0.0298,  0.0422, -0.0031, -0.0549, -0.0050,  0.0681, -0.0580, -0.0166,\n",
       "         -0.0174,  0.0042, -0.0645,  0.0402,  0.0315, -0.0416, -0.0450,  0.0325,\n",
       "         -0.0420,  0.0047, -0.0574,  0.0446, -0.0590, -0.0004,  0.0651,  0.0429,\n",
       "         -0.0560, -0.0436,  0.0014,  0.0679, -0.0561, -0.0547, -0.0198, -0.0398,\n",
       "         -0.0423,  0.0693, -0.0444,  0.0402, -0.0489,  0.0495, -0.0164, -0.0129,\n",
       "          0.0312,  0.0533, -0.0243, -0.0297, -0.0505, -0.0457,  0.0328,  0.0409,\n",
       "          0.0221, -0.0241,  0.0302,  0.0488,  0.0567, -0.0320, -0.0126, -0.0102,\n",
       "          0.0627,  0.0088, -0.0589,  0.0352,  0.0171,  0.0024, -0.0705,  0.0659],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0655,  0.0251, -0.0139,  0.0354, -0.0085, -0.0151, -0.0622,  0.0403,\n",
       "          -0.0743, -0.0604, -0.0047,  0.0183, -0.0134,  0.0602,  0.0632,  0.0486,\n",
       "           0.0031,  0.0438,  0.0568,  0.0611,  0.0377,  0.0488, -0.0505, -0.0278,\n",
       "          -0.0451,  0.0171, -0.0101, -0.0496,  0.0148,  0.0388, -0.0389,  0.0125,\n",
       "          -0.0078,  0.0581,  0.0030, -0.0248,  0.0186, -0.0812,  0.0286, -0.0147,\n",
       "           0.0184,  0.0115,  0.0294,  0.0340, -0.0498, -0.0423, -0.0125,  0.0512,\n",
       "          -0.0621, -0.0104, -0.0538,  0.0691,  0.0137,  0.0213, -0.0272, -0.0346,\n",
       "          -0.0144,  0.0019,  0.0033, -0.0444,  0.0421, -0.0663, -0.0626,  0.0602,\n",
       "          -0.0545, -0.0335,  0.0548, -0.0058,  0.0159, -0.0153,  0.0457,  0.0281,\n",
       "          -0.0108, -0.0145,  0.0558,  0.0088,  0.0496,  0.0200,  0.0119,  0.0228,\n",
       "           0.0214,  0.0525, -0.0375, -0.0396,  0.0609, -0.0190, -0.0328,  0.0176,\n",
       "           0.0325,  0.0162, -0.0262,  0.0513,  0.0663, -0.0527, -0.0588,  0.0496,\n",
       "          -0.0192, -0.0016, -0.0063, -0.0123,  0.0223, -0.0410,  0.0550,  0.0701,\n",
       "          -0.0488,  0.0568, -0.0083, -0.0704,  0.0443,  0.0361, -0.0210,  0.0685,\n",
       "           0.0085, -0.0146, -0.0224, -0.0440, -0.0574, -0.0772, -0.0133,  0.0053,\n",
       "          -0.0665, -0.0135, -0.0683, -0.0257,  0.0479, -0.0424, -0.0486, -0.0667,\n",
       "           0.0285, -0.0070, -0.0673,  0.0283,  0.0506,  0.0317,  0.0648, -0.0528,\n",
       "           0.0501,  0.0305, -0.0540, -0.0225, -0.0293, -0.0064,  0.0118, -0.0200,\n",
       "           0.0243, -0.0027, -0.0890,  0.0495,  0.0281, -0.0709,  0.0452,  0.0652,\n",
       "          -0.0649,  0.0608,  0.0418,  0.0016, -0.0389,  0.0683,  0.0211,  0.0518,\n",
       "           0.0142, -0.0497,  0.0164, -0.0014, -0.0211, -0.0132, -0.0625, -0.0662,\n",
       "          -0.0169, -0.0466,  0.0528, -0.0610, -0.0037,  0.0255,  0.0029, -0.0303,\n",
       "           0.0694,  0.0687,  0.0526,  0.0701,  0.0748,  0.0073, -0.0075, -0.0733,\n",
       "          -0.0302, -0.0597, -0.0330,  0.0655,  0.0513, -0.0113,  0.0215,  0.0402,\n",
       "           0.0517, -0.0040, -0.0699, -0.0630, -0.0512, -0.0433,  0.0005,  0.0251]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0442], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7144, 0.4328, 0.6364, 0.5766, 0.7359],\n",
      "        [0.4714, 0.6184, 0.8143, 0.5924, 0.0254]])\n",
      "tensor([[-4.7914e-05],\n",
      "        [ 6.8256e-02]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae8dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0ea37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
