{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.Linear(input_size, hidden1_size), #Lineare Transformation mit gespeicherten weights und biases\n",
    "            #nn.LayerNorm(hidden1_size),\n",
    "            nn.Tanh(), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            #nn.LayerNorm(hidden2_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden2_size, hidden3_size),\n",
    "            #nn.LayerNorm(hidden3_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden3_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (6): Tanh()\n",
      "    (7): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset_10000.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#T = log10(T)\n",
    "# T = T / 850\n",
    "# p = p / 1000\n",
    "\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 70, 100], gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 1/250, Loss: 0.1403\n",
      "Epoch 1/200, Iteration 2/250, Loss: 1.2192\n",
      "Epoch 1/200, Iteration 3/250, Loss: 2.8638\n",
      "Epoch 1/200, Iteration 4/250, Loss: 2.1933\n",
      "Epoch 1/200, Iteration 5/250, Loss: 0.9685\n",
      "Epoch 1/200, Iteration 6/250, Loss: 0.3322\n",
      "Epoch 1/200, Iteration 7/250, Loss: 0.8092\n",
      "Epoch 1/200, Iteration 8/250, Loss: 0.6676\n",
      "Epoch 1/200, Iteration 9/250, Loss: 0.3114\n",
      "Epoch 1/200, Iteration 10/250, Loss: 0.4122\n",
      "Epoch 1/200, Iteration 11/250, Loss: 0.3572\n",
      "Epoch 1/200, Iteration 12/250, Loss: 0.3870\n",
      "Epoch 1/200, Iteration 13/250, Loss: 0.4383\n",
      "Epoch 1/200, Iteration 14/250, Loss: 0.3826\n",
      "Epoch 1/200, Iteration 15/250, Loss: 0.1650\n",
      "Epoch 1/200, Iteration 16/250, Loss: 0.2924\n",
      "Epoch 1/200, Iteration 17/250, Loss: 0.4616\n",
      "Epoch 1/200, Iteration 18/250, Loss: 0.3874\n",
      "Epoch 1/200, Iteration 19/250, Loss: 0.1624\n",
      "Epoch 1/200, Iteration 20/250, Loss: 0.2440\n",
      "Epoch 1/200, Iteration 21/250, Loss: 0.3348\n",
      "Epoch 1/200, Iteration 22/250, Loss: 0.2210\n",
      "Epoch 1/200, Iteration 23/250, Loss: 0.2534\n",
      "Epoch 1/200, Iteration 24/250, Loss: 0.3051\n",
      "Epoch 1/200, Iteration 25/250, Loss: 0.2216\n",
      "Epoch 1/200, Iteration 26/250, Loss: 0.1206\n",
      "Epoch 1/200, Iteration 27/250, Loss: 0.1816\n",
      "Epoch 1/200, Iteration 28/250, Loss: 0.1355\n",
      "Epoch 1/200, Iteration 29/250, Loss: 0.1789\n",
      "Epoch 1/200, Iteration 30/250, Loss: 0.1856\n",
      "Epoch 1/200, Iteration 31/250, Loss: 0.1112\n",
      "Epoch 1/200, Iteration 32/250, Loss: 0.1456\n",
      "Epoch 1/200, Iteration 33/250, Loss: 0.0825\n",
      "Epoch 1/200, Iteration 34/250, Loss: 0.1236\n",
      "Epoch 1/200, Iteration 35/250, Loss: 0.1458\n",
      "Epoch 1/200, Iteration 36/250, Loss: 0.0895\n",
      "Epoch 1/200, Iteration 37/250, Loss: 0.1364\n",
      "Epoch 1/200, Iteration 38/250, Loss: 0.0706\n",
      "Epoch 1/200, Iteration 39/250, Loss: 0.0651\n",
      "Epoch 1/200, Iteration 40/250, Loss: 0.0446\n",
      "Epoch 1/200, Iteration 41/250, Loss: 0.0458\n",
      "Epoch 1/200, Iteration 42/250, Loss: 0.0527\n",
      "Epoch 1/200, Iteration 43/250, Loss: 0.0779\n",
      "Epoch 1/200, Iteration 44/250, Loss: 0.0671\n",
      "Epoch 1/200, Iteration 45/250, Loss: 0.1126\n",
      "Epoch 1/200, Iteration 46/250, Loss: 0.0620\n",
      "Epoch 1/200, Iteration 47/250, Loss: 0.0554\n",
      "Epoch 1/200, Iteration 48/250, Loss: 0.0654\n",
      "Epoch 1/200, Iteration 49/250, Loss: 0.0456\n",
      "Epoch 1/200, Iteration 50/250, Loss: 0.0589\n",
      "Epoch 1/200, Iteration 51/250, Loss: 0.0790\n",
      "Epoch 1/200, Iteration 52/250, Loss: 0.0727\n",
      "Epoch 1/200, Iteration 53/250, Loss: 0.0431\n",
      "Epoch 1/200, Iteration 54/250, Loss: 0.1116\n",
      "Epoch 1/200, Iteration 55/250, Loss: 0.0854\n",
      "Epoch 1/200, Iteration 56/250, Loss: 0.0894\n",
      "Epoch 1/200, Iteration 57/250, Loss: 0.0988\n",
      "Epoch 1/200, Iteration 58/250, Loss: 0.0766\n",
      "Epoch 1/200, Iteration 59/250, Loss: 0.0777\n",
      "Epoch 1/200, Iteration 60/250, Loss: 0.0831\n",
      "Epoch 1/200, Iteration 61/250, Loss: 0.1388\n",
      "Epoch 1/200, Iteration 62/250, Loss: 0.0385\n",
      "Epoch 1/200, Iteration 63/250, Loss: 0.0825\n",
      "Epoch 1/200, Iteration 64/250, Loss: 0.0470\n",
      "Epoch 1/200, Iteration 65/250, Loss: 0.0804\n",
      "Epoch 1/200, Iteration 66/250, Loss: 0.0718\n",
      "Epoch 1/200, Iteration 67/250, Loss: 0.0956\n",
      "Epoch 1/200, Iteration 68/250, Loss: 0.0786\n",
      "Epoch 1/200, Iteration 69/250, Loss: 0.0762\n",
      "Epoch 1/200, Iteration 70/250, Loss: 0.0662\n",
      "Epoch 1/200, Iteration 71/250, Loss: 0.0626\n",
      "Epoch 1/200, Iteration 72/250, Loss: 0.0881\n",
      "Epoch 1/200, Iteration 73/250, Loss: 0.0554\n",
      "Epoch 1/200, Iteration 74/250, Loss: 0.1462\n",
      "Epoch 1/200, Iteration 75/250, Loss: 0.1893\n",
      "Epoch 1/200, Iteration 76/250, Loss: 0.1028\n",
      "Epoch 1/200, Iteration 77/250, Loss: 0.0732\n",
      "Epoch 1/200, Iteration 78/250, Loss: 0.1571\n",
      "Epoch 1/200, Iteration 79/250, Loss: 0.1230\n",
      "Epoch 1/200, Iteration 80/250, Loss: 0.0614\n",
      "Epoch 1/200, Iteration 81/250, Loss: 0.0723\n",
      "Epoch 1/200, Iteration 82/250, Loss: 0.1213\n",
      "Epoch 1/200, Iteration 83/250, Loss: 0.0930\n",
      "Epoch 1/200, Iteration 84/250, Loss: 0.0572\n",
      "Epoch 1/200, Iteration 85/250, Loss: 0.0848\n",
      "Epoch 1/200, Iteration 86/250, Loss: 0.0794\n",
      "Epoch 1/200, Iteration 87/250, Loss: 0.0294\n",
      "Epoch 1/200, Iteration 88/250, Loss: 0.0372\n",
      "Epoch 1/200, Iteration 89/250, Loss: 0.0689\n",
      "Epoch 1/200, Iteration 90/250, Loss: 0.0544\n",
      "Epoch 1/200, Iteration 91/250, Loss: 0.0712\n",
      "Epoch 1/200, Iteration 92/250, Loss: 0.0509\n",
      "Epoch 1/200, Iteration 93/250, Loss: 0.0720\n",
      "Epoch 1/200, Iteration 94/250, Loss: 0.0521\n",
      "Epoch 1/200, Iteration 95/250, Loss: 0.0764\n",
      "Epoch 1/200, Iteration 96/250, Loss: 0.0268\n",
      "Epoch 1/200, Iteration 97/250, Loss: 0.0315\n",
      "Epoch 1/200, Iteration 98/250, Loss: 0.0501\n",
      "Epoch 1/200, Iteration 99/250, Loss: 0.0503\n",
      "Epoch 1/200, Iteration 100/250, Loss: 0.0617\n",
      "Epoch 1/200, Iteration 101/250, Loss: 0.0790\n",
      "Epoch 1/200, Iteration 102/250, Loss: 0.1173\n",
      "Epoch 1/200, Iteration 103/250, Loss: 0.0443\n",
      "Epoch 1/200, Iteration 104/250, Loss: 0.1224\n",
      "Epoch 1/200, Iteration 105/250, Loss: 0.0954\n",
      "Epoch 1/200, Iteration 106/250, Loss: 0.0995\n",
      "Epoch 1/200, Iteration 107/250, Loss: 0.1506\n",
      "Epoch 1/200, Iteration 108/250, Loss: 0.1282\n",
      "Epoch 1/200, Iteration 109/250, Loss: 0.0442\n",
      "Epoch 1/200, Iteration 110/250, Loss: 0.1039\n",
      "Epoch 1/200, Iteration 111/250, Loss: 0.0561\n",
      "Epoch 1/200, Iteration 112/250, Loss: 0.0443\n",
      "Epoch 1/200, Iteration 113/250, Loss: 0.0630\n",
      "Epoch 1/200, Iteration 114/250, Loss: 0.0360\n",
      "Epoch 1/200, Iteration 115/250, Loss: 0.0497\n",
      "Epoch 1/200, Iteration 116/250, Loss: 0.0574\n",
      "Epoch 1/200, Iteration 117/250, Loss: 0.0522\n",
      "Epoch 1/200, Iteration 118/250, Loss: 0.0421\n",
      "Epoch 1/200, Iteration 119/250, Loss: 0.0351\n",
      "Epoch 1/200, Iteration 120/250, Loss: 0.0217\n",
      "Epoch 1/200, Iteration 121/250, Loss: 0.0415\n",
      "Epoch 1/200, Iteration 122/250, Loss: 0.0405\n",
      "Epoch 1/200, Iteration 123/250, Loss: 0.0321\n",
      "Epoch 1/200, Iteration 124/250, Loss: 0.0504\n",
      "Epoch 1/200, Iteration 125/250, Loss: 0.0418\n",
      "Epoch 1/200, Iteration 126/250, Loss: 0.0287\n",
      "Epoch 1/200, Iteration 127/250, Loss: 0.0404\n",
      "Epoch 1/200, Iteration 128/250, Loss: 0.0576\n",
      "Epoch 1/200, Iteration 129/250, Loss: 0.0508\n",
      "Epoch 1/200, Iteration 130/250, Loss: 0.0546\n",
      "Epoch 1/200, Iteration 131/250, Loss: 0.0362\n",
      "Epoch 1/200, Iteration 132/250, Loss: 0.0878\n",
      "Epoch 1/200, Iteration 133/250, Loss: 0.0795\n",
      "Epoch 1/200, Iteration 134/250, Loss: 0.0438\n",
      "Epoch 1/200, Iteration 135/250, Loss: 0.0642\n",
      "Epoch 1/200, Iteration 136/250, Loss: 0.0535\n",
      "Epoch 1/200, Iteration 137/250, Loss: 0.0420\n",
      "Epoch 1/200, Iteration 138/250, Loss: 0.0584\n",
      "Epoch 1/200, Iteration 139/250, Loss: 0.0661\n",
      "Epoch 1/200, Iteration 140/250, Loss: 0.0333\n",
      "Epoch 1/200, Iteration 141/250, Loss: 0.0461\n",
      "Epoch 1/200, Iteration 142/250, Loss: 0.0443\n",
      "Epoch 1/200, Iteration 143/250, Loss: 0.0594\n",
      "Epoch 1/200, Iteration 144/250, Loss: 0.0560\n",
      "Epoch 1/200, Iteration 145/250, Loss: 0.0639\n",
      "Epoch 1/200, Iteration 146/250, Loss: 0.0370\n",
      "Epoch 1/200, Iteration 147/250, Loss: 0.0938\n",
      "Epoch 1/200, Iteration 148/250, Loss: 0.1033\n",
      "Epoch 1/200, Iteration 149/250, Loss: 0.0433\n",
      "Epoch 1/200, Iteration 150/250, Loss: 0.1016\n",
      "Epoch 1/200, Iteration 151/250, Loss: 0.0780\n",
      "Epoch 1/200, Iteration 152/250, Loss: 0.0512\n",
      "Epoch 1/200, Iteration 153/250, Loss: 0.0642\n",
      "Epoch 1/200, Iteration 154/250, Loss: 0.0322\n",
      "Epoch 1/200, Iteration 155/250, Loss: 0.0408\n",
      "Epoch 1/200, Iteration 156/250, Loss: 0.0411\n",
      "Epoch 1/200, Iteration 157/250, Loss: 0.0267\n",
      "Epoch 1/200, Iteration 158/250, Loss: 0.0349\n",
      "Epoch 1/200, Iteration 159/250, Loss: 0.0271\n",
      "Epoch 1/200, Iteration 160/250, Loss: 0.0563\n",
      "Epoch 1/200, Iteration 161/250, Loss: 0.0353\n",
      "Epoch 1/200, Iteration 162/250, Loss: 0.0508\n",
      "Epoch 1/200, Iteration 163/250, Loss: 0.0399\n",
      "Epoch 1/200, Iteration 164/250, Loss: 0.0367\n",
      "Epoch 1/200, Iteration 165/250, Loss: 0.0488\n",
      "Epoch 1/200, Iteration 166/250, Loss: 0.0295\n",
      "Epoch 1/200, Iteration 167/250, Loss: 0.1100\n",
      "Epoch 1/200, Iteration 168/250, Loss: 0.1095\n",
      "Epoch 1/200, Iteration 169/250, Loss: 0.0733\n",
      "Epoch 1/200, Iteration 170/250, Loss: 0.0361\n",
      "Epoch 1/200, Iteration 171/250, Loss: 0.0859\n",
      "Epoch 1/200, Iteration 172/250, Loss: 0.1135\n",
      "Epoch 1/200, Iteration 173/250, Loss: 0.0813\n",
      "Epoch 1/200, Iteration 174/250, Loss: 0.0376\n",
      "Epoch 1/200, Iteration 175/250, Loss: 0.0587\n",
      "Epoch 1/200, Iteration 176/250, Loss: 0.0737\n",
      "Epoch 1/200, Iteration 177/250, Loss: 0.0658\n",
      "Epoch 1/200, Iteration 178/250, Loss: 0.0546\n",
      "Epoch 1/200, Iteration 179/250, Loss: 0.0720\n",
      "Epoch 1/200, Iteration 180/250, Loss: 0.0981\n",
      "Epoch 1/200, Iteration 181/250, Loss: 0.1048\n",
      "Epoch 1/200, Iteration 182/250, Loss: 0.0773\n",
      "Epoch 1/200, Iteration 183/250, Loss: 0.0558\n",
      "Epoch 1/200, Iteration 184/250, Loss: 0.0560\n",
      "Epoch 1/200, Iteration 185/250, Loss: 0.0794\n",
      "Epoch 1/200, Iteration 186/250, Loss: 0.0628\n",
      "Epoch 1/200, Iteration 187/250, Loss: 0.1148\n",
      "Epoch 1/200, Iteration 188/250, Loss: 0.0475\n",
      "Epoch 1/200, Iteration 189/250, Loss: 0.1131\n",
      "Epoch 1/200, Iteration 190/250, Loss: 0.1133\n",
      "Epoch 1/200, Iteration 191/250, Loss: 0.0542\n",
      "Epoch 1/200, Iteration 192/250, Loss: 0.0910\n",
      "Epoch 1/200, Iteration 193/250, Loss: 0.0840\n",
      "Epoch 1/200, Iteration 194/250, Loss: 0.0663\n",
      "Epoch 1/200, Iteration 195/250, Loss: 0.0816\n",
      "Epoch 1/200, Iteration 196/250, Loss: 0.0765\n",
      "Epoch 1/200, Iteration 197/250, Loss: 0.0862\n",
      "Epoch 1/200, Iteration 198/250, Loss: 0.0781\n",
      "Epoch 1/200, Iteration 199/250, Loss: 0.0686\n",
      "Epoch 1/200, Iteration 200/250, Loss: 0.0662\n",
      "Epoch 1/200, Iteration 201/250, Loss: 0.0807\n",
      "Epoch 1/200, Iteration 202/250, Loss: 0.0582\n",
      "Epoch 1/200, Iteration 203/250, Loss: 0.0782\n",
      "Epoch 1/200, Iteration 204/250, Loss: 0.0435\n",
      "Epoch 1/200, Iteration 205/250, Loss: 0.1461\n",
      "Epoch 1/200, Iteration 206/250, Loss: 0.1139\n",
      "Epoch 1/200, Iteration 207/250, Loss: 0.1407\n",
      "Epoch 1/200, Iteration 208/250, Loss: 0.1363\n",
      "Epoch 1/200, Iteration 209/250, Loss: 0.0572\n",
      "Epoch 1/200, Iteration 210/250, Loss: 0.1123\n",
      "Epoch 1/200, Iteration 211/250, Loss: 0.1026\n",
      "Epoch 1/200, Iteration 212/250, Loss: 0.1081\n",
      "Epoch 1/200, Iteration 213/250, Loss: 0.1097\n",
      "Epoch 1/200, Iteration 214/250, Loss: 0.0554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 215/250, Loss: 0.1176\n",
      "Epoch 1/200, Iteration 216/250, Loss: 0.0510\n",
      "Epoch 1/200, Iteration 217/250, Loss: 0.0699\n",
      "Epoch 1/200, Iteration 218/250, Loss: 0.0483\n",
      "Epoch 1/200, Iteration 219/250, Loss: 0.0554\n",
      "Epoch 1/200, Iteration 220/250, Loss: 0.0593\n",
      "Epoch 1/200, Iteration 221/250, Loss: 0.0766\n",
      "Epoch 1/200, Iteration 222/250, Loss: 0.0831\n",
      "Epoch 1/200, Iteration 223/250, Loss: 0.0323\n",
      "Epoch 1/200, Iteration 224/250, Loss: 0.0400\n",
      "Epoch 1/200, Iteration 225/250, Loss: 0.0411\n",
      "Epoch 1/200, Iteration 226/250, Loss: 0.0444\n",
      "Epoch 1/200, Iteration 227/250, Loss: 0.0820\n",
      "Epoch 1/200, Iteration 228/250, Loss: 0.0510\n",
      "Epoch 1/200, Iteration 229/250, Loss: 0.0604\n",
      "Epoch 1/200, Iteration 230/250, Loss: 0.0479\n",
      "Epoch 1/200, Iteration 231/250, Loss: 0.0672\n",
      "Epoch 1/200, Iteration 232/250, Loss: 0.0364\n",
      "Epoch 1/200, Iteration 233/250, Loss: 0.0728\n",
      "Epoch 1/200, Iteration 234/250, Loss: 0.0448\n",
      "Epoch 1/200, Iteration 235/250, Loss: 0.0475\n",
      "Epoch 1/200, Iteration 236/250, Loss: 0.0651\n",
      "Epoch 1/200, Iteration 237/250, Loss: 0.0231\n",
      "Epoch 1/200, Iteration 238/250, Loss: 0.0668\n",
      "Epoch 1/200, Iteration 239/250, Loss: 0.0579\n",
      "Epoch 1/200, Iteration 240/250, Loss: 0.0785\n",
      "Epoch 1/200, Iteration 241/250, Loss: 0.0705\n",
      "Epoch 1/200, Iteration 242/250, Loss: 0.0545\n",
      "Epoch 1/200, Iteration 243/250, Loss: 0.0396\n",
      "Epoch 1/200, Iteration 244/250, Loss: 0.0409\n",
      "Epoch 1/200, Iteration 245/250, Loss: 0.0470\n",
      "Epoch 1/200, Iteration 246/250, Loss: 0.0414\n",
      "Epoch 1/200, Iteration 247/250, Loss: 0.0608\n",
      "Epoch 1/200, Iteration 248/250, Loss: 0.0421\n",
      "Epoch 1/200, Iteration 249/250, Loss: 0.0671\n",
      "Epoch 1/200, Iteration 250/250, Loss: 0.0539\n",
      "Train Error: \n",
      " Accuracy: 44.61%, Avg loss: 0.086482, MRE: 6.232984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.086177, MRE: 9.206126 \n",
      "\n",
      "Epoch 2/200, Iteration 1/250, Loss: 0.0917\n",
      "Epoch 2/200, Iteration 2/250, Loss: 0.0595\n",
      "Epoch 2/200, Iteration 3/250, Loss: 0.0618\n",
      "Epoch 2/200, Iteration 4/250, Loss: 0.1064\n",
      "Epoch 2/200, Iteration 5/250, Loss: 0.0476\n",
      "Epoch 2/200, Iteration 6/250, Loss: 0.0708\n",
      "Epoch 2/200, Iteration 7/250, Loss: 0.0437\n",
      "Epoch 2/200, Iteration 8/250, Loss: 0.0875\n",
      "Epoch 2/200, Iteration 9/250, Loss: 0.0936\n",
      "Epoch 2/200, Iteration 10/250, Loss: 0.0819\n",
      "Epoch 2/200, Iteration 11/250, Loss: 0.0786\n",
      "Epoch 2/200, Iteration 12/250, Loss: 0.0596\n",
      "Epoch 2/200, Iteration 13/250, Loss: 0.1258\n",
      "Epoch 2/200, Iteration 14/250, Loss: 0.0870\n",
      "Epoch 2/200, Iteration 15/250, Loss: 0.1006\n",
      "Epoch 2/200, Iteration 16/250, Loss: 0.0871\n",
      "Epoch 2/200, Iteration 17/250, Loss: 0.0608\n",
      "Epoch 2/200, Iteration 18/250, Loss: 0.0698\n",
      "Epoch 2/200, Iteration 19/250, Loss: 0.0503\n",
      "Epoch 2/200, Iteration 20/250, Loss: 0.0495\n",
      "Epoch 2/200, Iteration 21/250, Loss: 0.0565\n",
      "Epoch 2/200, Iteration 22/250, Loss: 0.0534\n",
      "Epoch 2/200, Iteration 23/250, Loss: 0.0665\n",
      "Epoch 2/200, Iteration 24/250, Loss: 0.0262\n",
      "Epoch 2/200, Iteration 25/250, Loss: 0.0784\n",
      "Epoch 2/200, Iteration 26/250, Loss: 0.0367\n",
      "Epoch 2/200, Iteration 27/250, Loss: 0.0377\n",
      "Epoch 2/200, Iteration 28/250, Loss: 0.0689\n",
      "Epoch 2/200, Iteration 29/250, Loss: 0.0334\n",
      "Epoch 2/200, Iteration 30/250, Loss: 0.0600\n",
      "Epoch 2/200, Iteration 31/250, Loss: 0.0484\n",
      "Epoch 2/200, Iteration 32/250, Loss: 0.0264\n",
      "Epoch 2/200, Iteration 33/250, Loss: 0.0447\n",
      "Epoch 2/200, Iteration 34/250, Loss: 0.0720\n",
      "Epoch 2/200, Iteration 35/250, Loss: 0.0442\n",
      "Epoch 2/200, Iteration 36/250, Loss: 0.0441\n",
      "Epoch 2/200, Iteration 37/250, Loss: 0.0332\n",
      "Epoch 2/200, Iteration 38/250, Loss: 0.0507\n",
      "Epoch 2/200, Iteration 39/250, Loss: 0.0654\n",
      "Epoch 2/200, Iteration 40/250, Loss: 0.0695\n",
      "Epoch 2/200, Iteration 41/250, Loss: 0.0429\n",
      "Epoch 2/200, Iteration 42/250, Loss: 0.0838\n",
      "Epoch 2/200, Iteration 43/250, Loss: 0.0628\n",
      "Epoch 2/200, Iteration 44/250, Loss: 0.0589\n",
      "Epoch 2/200, Iteration 45/250, Loss: 0.0431\n",
      "Epoch 2/200, Iteration 46/250, Loss: 0.0486\n",
      "Epoch 2/200, Iteration 47/250, Loss: 0.0274\n",
      "Epoch 2/200, Iteration 48/250, Loss: 0.0528\n",
      "Epoch 2/200, Iteration 49/250, Loss: 0.0415\n",
      "Epoch 2/200, Iteration 50/250, Loss: 0.0287\n",
      "Epoch 2/200, Iteration 51/250, Loss: 0.0609\n",
      "Epoch 2/200, Iteration 52/250, Loss: 0.0400\n",
      "Epoch 2/200, Iteration 53/250, Loss: 0.0679\n",
      "Epoch 2/200, Iteration 54/250, Loss: 0.0763\n",
      "Epoch 2/200, Iteration 55/250, Loss: 0.0327\n",
      "Epoch 2/200, Iteration 56/250, Loss: 0.0786\n",
      "Epoch 2/200, Iteration 57/250, Loss: 0.0623\n",
      "Epoch 2/200, Iteration 58/250, Loss: 0.0541\n",
      "Epoch 2/200, Iteration 59/250, Loss: 0.0685\n",
      "Epoch 2/200, Iteration 60/250, Loss: 0.0406\n",
      "Epoch 2/200, Iteration 61/250, Loss: 0.0484\n",
      "Epoch 2/200, Iteration 62/250, Loss: 0.0670\n",
      "Epoch 2/200, Iteration 63/250, Loss: 0.1027\n",
      "Epoch 2/200, Iteration 64/250, Loss: 0.0588\n",
      "Epoch 2/200, Iteration 65/250, Loss: 0.0482\n",
      "Epoch 2/200, Iteration 66/250, Loss: 0.0593\n",
      "Epoch 2/200, Iteration 67/250, Loss: 0.0530\n",
      "Epoch 2/200, Iteration 68/250, Loss: 0.0255\n",
      "Epoch 2/200, Iteration 69/250, Loss: 0.0241\n",
      "Epoch 2/200, Iteration 70/250, Loss: 0.0347\n",
      "Epoch 2/200, Iteration 71/250, Loss: 0.0477\n",
      "Epoch 2/200, Iteration 72/250, Loss: 0.0459\n",
      "Epoch 2/200, Iteration 73/250, Loss: 0.0699\n",
      "Epoch 2/200, Iteration 74/250, Loss: 0.0389\n",
      "Epoch 2/200, Iteration 75/250, Loss: 0.0807\n",
      "Epoch 2/200, Iteration 76/250, Loss: 0.0453\n",
      "Epoch 2/200, Iteration 77/250, Loss: 0.1025\n",
      "Epoch 2/200, Iteration 78/250, Loss: 0.1344\n",
      "Epoch 2/200, Iteration 79/250, Loss: 0.0724\n",
      "Epoch 2/200, Iteration 80/250, Loss: 0.0872\n",
      "Epoch 2/200, Iteration 81/250, Loss: 0.0752\n",
      "Epoch 2/200, Iteration 82/250, Loss: 0.0396\n",
      "Epoch 2/200, Iteration 83/250, Loss: 0.0768\n",
      "Epoch 2/200, Iteration 84/250, Loss: 0.0947\n",
      "Epoch 2/200, Iteration 85/250, Loss: 0.0847\n",
      "Epoch 2/200, Iteration 86/250, Loss: 0.0638\n",
      "Epoch 2/200, Iteration 87/250, Loss: 0.1078\n",
      "Epoch 2/200, Iteration 88/250, Loss: 0.1042\n",
      "Epoch 2/200, Iteration 89/250, Loss: 0.0334\n",
      "Epoch 2/200, Iteration 90/250, Loss: 0.1172\n",
      "Epoch 2/200, Iteration 91/250, Loss: 0.1034\n",
      "Epoch 2/200, Iteration 92/250, Loss: 0.1107\n",
      "Epoch 2/200, Iteration 93/250, Loss: 0.1292\n",
      "Epoch 2/200, Iteration 94/250, Loss: 0.0967\n",
      "Epoch 2/200, Iteration 95/250, Loss: 0.0327\n",
      "Epoch 2/200, Iteration 96/250, Loss: 0.1035\n",
      "Epoch 2/200, Iteration 97/250, Loss: 0.1502\n",
      "Epoch 2/200, Iteration 98/250, Loss: 0.0554\n",
      "Epoch 2/200, Iteration 99/250, Loss: 0.0651\n",
      "Epoch 2/200, Iteration 100/250, Loss: 0.0623\n",
      "Epoch 2/200, Iteration 101/250, Loss: 0.0610\n",
      "Epoch 2/200, Iteration 102/250, Loss: 0.0550\n",
      "Epoch 2/200, Iteration 103/250, Loss: 0.0676\n",
      "Epoch 2/200, Iteration 104/250, Loss: 0.0582\n",
      "Epoch 2/200, Iteration 105/250, Loss: 0.0745\n",
      "Epoch 2/200, Iteration 106/250, Loss: 0.0626\n",
      "Epoch 2/200, Iteration 107/250, Loss: 0.0713\n",
      "Epoch 2/200, Iteration 108/250, Loss: 0.0519\n",
      "Epoch 2/200, Iteration 109/250, Loss: 0.0580\n",
      "Epoch 2/200, Iteration 110/250, Loss: 0.0523\n",
      "Epoch 2/200, Iteration 111/250, Loss: 0.0380\n",
      "Epoch 2/200, Iteration 112/250, Loss: 0.0651\n",
      "Epoch 2/200, Iteration 113/250, Loss: 0.0444\n",
      "Epoch 2/200, Iteration 114/250, Loss: 0.1100\n",
      "Epoch 2/200, Iteration 115/250, Loss: 0.0696\n",
      "Epoch 2/200, Iteration 116/250, Loss: 0.0661\n",
      "Epoch 2/200, Iteration 117/250, Loss: 0.0960\n",
      "Epoch 2/200, Iteration 118/250, Loss: 0.0646\n",
      "Epoch 2/200, Iteration 119/250, Loss: 0.1110\n",
      "Epoch 2/200, Iteration 120/250, Loss: 0.0731\n",
      "Epoch 2/200, Iteration 121/250, Loss: 0.0488\n",
      "Epoch 2/200, Iteration 122/250, Loss: 0.1100\n",
      "Epoch 2/200, Iteration 123/250, Loss: 0.1208\n",
      "Epoch 2/200, Iteration 124/250, Loss: 0.0722\n",
      "Epoch 2/200, Iteration 125/250, Loss: 0.0801\n",
      "Epoch 2/200, Iteration 126/250, Loss: 0.1080\n",
      "Epoch 2/200, Iteration 127/250, Loss: 0.1591\n",
      "Epoch 2/200, Iteration 128/250, Loss: 0.1312\n",
      "Epoch 2/200, Iteration 129/250, Loss: 0.1370\n",
      "Epoch 2/200, Iteration 130/250, Loss: 0.1077\n",
      "Epoch 2/200, Iteration 131/250, Loss: 0.0771\n",
      "Epoch 2/200, Iteration 132/250, Loss: 0.0985\n",
      "Epoch 2/200, Iteration 133/250, Loss: 0.0998\n",
      "Epoch 2/200, Iteration 134/250, Loss: 0.0912\n",
      "Epoch 2/200, Iteration 135/250, Loss: 0.1100\n",
      "Epoch 2/200, Iteration 136/250, Loss: 0.0564\n",
      "Epoch 2/200, Iteration 137/250, Loss: 0.0701\n",
      "Epoch 2/200, Iteration 138/250, Loss: 0.0600\n",
      "Epoch 2/200, Iteration 139/250, Loss: 0.0569\n",
      "Epoch 2/200, Iteration 140/250, Loss: 0.0668\n",
      "Epoch 2/200, Iteration 141/250, Loss: 0.0560\n",
      "Epoch 2/200, Iteration 142/250, Loss: 0.0740\n",
      "Epoch 2/200, Iteration 143/250, Loss: 0.0868\n",
      "Epoch 2/200, Iteration 144/250, Loss: 0.0514\n",
      "Epoch 2/200, Iteration 145/250, Loss: 0.0507\n",
      "Epoch 2/200, Iteration 146/250, Loss: 0.0360\n",
      "Epoch 2/200, Iteration 147/250, Loss: 0.0623\n",
      "Epoch 2/200, Iteration 148/250, Loss: 0.0478\n",
      "Epoch 2/200, Iteration 149/250, Loss: 0.0489\n",
      "Epoch 2/200, Iteration 150/250, Loss: 0.0436\n",
      "Epoch 2/200, Iteration 151/250, Loss: 0.0606\n",
      "Epoch 2/200, Iteration 152/250, Loss: 0.0668\n",
      "Epoch 2/200, Iteration 153/250, Loss: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Iteration 154/250, Loss: 0.1026\n",
      "Epoch 2/200, Iteration 155/250, Loss: 0.1004\n",
      "Epoch 2/200, Iteration 156/250, Loss: 0.0646\n",
      "Epoch 2/200, Iteration 157/250, Loss: 0.0894\n",
      "Epoch 2/200, Iteration 158/250, Loss: 0.0928\n",
      "Epoch 2/200, Iteration 159/250, Loss: 0.0581\n",
      "Epoch 2/200, Iteration 160/250, Loss: 0.0918\n",
      "Epoch 2/200, Iteration 161/250, Loss: 0.0789\n",
      "Epoch 2/200, Iteration 162/250, Loss: 0.0852\n",
      "Epoch 2/200, Iteration 163/250, Loss: 0.0497\n",
      "Epoch 2/200, Iteration 164/250, Loss: 0.1209\n",
      "Epoch 2/200, Iteration 165/250, Loss: 0.0924\n",
      "Epoch 2/200, Iteration 166/250, Loss: 0.1113\n",
      "Epoch 2/200, Iteration 167/250, Loss: 0.1027\n",
      "Epoch 2/200, Iteration 168/250, Loss: 0.0692\n",
      "Epoch 2/200, Iteration 169/250, Loss: 0.1536\n",
      "Epoch 2/200, Iteration 170/250, Loss: 0.1047\n",
      "Epoch 2/200, Iteration 171/250, Loss: 0.1001\n",
      "Epoch 2/200, Iteration 172/250, Loss: 0.1370\n",
      "Epoch 2/200, Iteration 173/250, Loss: 0.0508\n",
      "Epoch 2/200, Iteration 174/250, Loss: 0.1106\n",
      "Epoch 2/200, Iteration 175/250, Loss: 0.1368\n",
      "Epoch 2/200, Iteration 176/250, Loss: 0.0526\n",
      "Epoch 2/200, Iteration 177/250, Loss: 0.0463\n",
      "Epoch 2/200, Iteration 178/250, Loss: 0.0434\n",
      "Epoch 2/200, Iteration 179/250, Loss: 0.0534\n",
      "Epoch 2/200, Iteration 180/250, Loss: 0.0723\n",
      "Epoch 2/200, Iteration 181/250, Loss: 0.0563\n",
      "Epoch 2/200, Iteration 182/250, Loss: 0.0598\n",
      "Epoch 2/200, Iteration 183/250, Loss: 0.0507\n",
      "Epoch 2/200, Iteration 184/250, Loss: 0.0416\n",
      "Epoch 2/200, Iteration 185/250, Loss: 0.0311\n",
      "Epoch 2/200, Iteration 186/250, Loss: 0.0647\n",
      "Epoch 2/200, Iteration 187/250, Loss: 0.0581\n",
      "Epoch 2/200, Iteration 188/250, Loss: 0.0653\n",
      "Epoch 2/200, Iteration 189/250, Loss: 0.0603\n",
      "Epoch 2/200, Iteration 190/250, Loss: 0.0439\n",
      "Epoch 2/200, Iteration 191/250, Loss: 0.0373\n",
      "Epoch 2/200, Iteration 192/250, Loss: 0.0743\n",
      "Epoch 2/200, Iteration 193/250, Loss: 0.0394\n",
      "Epoch 2/200, Iteration 194/250, Loss: 0.0674\n",
      "Epoch 2/200, Iteration 195/250, Loss: 0.0791\n",
      "Epoch 2/200, Iteration 196/250, Loss: 0.0577\n",
      "Epoch 2/200, Iteration 197/250, Loss: 0.0364\n",
      "Epoch 2/200, Iteration 198/250, Loss: 0.0517\n",
      "Epoch 2/200, Iteration 199/250, Loss: 0.0573\n",
      "Epoch 2/200, Iteration 200/250, Loss: 0.0581\n",
      "Epoch 2/200, Iteration 201/250, Loss: 0.0571\n",
      "Epoch 2/200, Iteration 202/250, Loss: 0.0702\n",
      "Epoch 2/200, Iteration 203/250, Loss: 0.0759\n",
      "Epoch 2/200, Iteration 204/250, Loss: 0.0986\n",
      "Epoch 2/200, Iteration 205/250, Loss: 0.0605\n",
      "Epoch 2/200, Iteration 206/250, Loss: 0.0930\n",
      "Epoch 2/200, Iteration 207/250, Loss: 0.0434\n",
      "Epoch 2/200, Iteration 208/250, Loss: 0.0747\n",
      "Epoch 2/200, Iteration 209/250, Loss: 0.0767\n",
      "Epoch 2/200, Iteration 210/250, Loss: 0.0251\n",
      "Epoch 2/200, Iteration 211/250, Loss: 0.1063\n",
      "Epoch 2/200, Iteration 212/250, Loss: 0.0632\n",
      "Epoch 2/200, Iteration 213/250, Loss: 0.0417\n",
      "Epoch 2/200, Iteration 214/250, Loss: 0.0775\n",
      "Epoch 2/200, Iteration 215/250, Loss: 0.1250\n",
      "Epoch 2/200, Iteration 216/250, Loss: 0.1050\n",
      "Epoch 2/200, Iteration 217/250, Loss: 0.0950\n",
      "Epoch 2/200, Iteration 218/250, Loss: 0.1047\n",
      "Epoch 2/200, Iteration 219/250, Loss: 0.0923\n",
      "Epoch 2/200, Iteration 220/250, Loss: 0.0701\n",
      "Epoch 2/200, Iteration 221/250, Loss: 0.0728\n",
      "Epoch 2/200, Iteration 222/250, Loss: 0.0447\n",
      "Epoch 2/200, Iteration 223/250, Loss: 0.1262\n",
      "Epoch 2/200, Iteration 224/250, Loss: 0.0960\n",
      "Epoch 2/200, Iteration 225/250, Loss: 0.1024\n",
      "Epoch 2/200, Iteration 226/250, Loss: 0.0643\n",
      "Epoch 2/200, Iteration 227/250, Loss: 0.0774\n",
      "Epoch 2/200, Iteration 228/250, Loss: 0.0734\n",
      "Epoch 2/200, Iteration 229/250, Loss: 0.0730\n",
      "Epoch 2/200, Iteration 230/250, Loss: 0.0609\n",
      "Epoch 2/200, Iteration 231/250, Loss: 0.0991\n",
      "Epoch 2/200, Iteration 232/250, Loss: 0.0509\n",
      "Epoch 2/200, Iteration 233/250, Loss: 0.0826\n",
      "Epoch 2/200, Iteration 234/250, Loss: 0.0729\n",
      "Epoch 2/200, Iteration 235/250, Loss: 0.0697\n",
      "Epoch 2/200, Iteration 236/250, Loss: 0.0469\n",
      "Epoch 2/200, Iteration 237/250, Loss: 0.0521\n",
      "Epoch 2/200, Iteration 238/250, Loss: 0.0678\n",
      "Epoch 2/200, Iteration 239/250, Loss: 0.0587\n",
      "Epoch 2/200, Iteration 240/250, Loss: 0.0687\n",
      "Epoch 2/200, Iteration 241/250, Loss: 0.0473\n",
      "Epoch 2/200, Iteration 242/250, Loss: 0.0795\n",
      "Epoch 2/200, Iteration 243/250, Loss: 0.0350\n",
      "Epoch 2/200, Iteration 244/250, Loss: 0.0774\n",
      "Epoch 2/200, Iteration 245/250, Loss: 0.0565\n",
      "Epoch 2/200, Iteration 246/250, Loss: 0.0444\n",
      "Epoch 2/200, Iteration 247/250, Loss: 0.0432\n",
      "Epoch 2/200, Iteration 248/250, Loss: 0.0570\n",
      "Epoch 2/200, Iteration 249/250, Loss: 0.0417\n",
      "Epoch 2/200, Iteration 250/250, Loss: 0.0460\n",
      "Train Error: \n",
      " Accuracy: 38.12%, Avg loss: 0.058948, MRE: 4.433197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 37.05%, Avg loss: 0.058483, MRE: 5.230236 \n",
      "\n",
      "Epoch 3/200, Iteration 1/250, Loss: 0.0646\n",
      "Epoch 3/200, Iteration 2/250, Loss: 0.0527\n",
      "Epoch 3/200, Iteration 3/250, Loss: 0.0585\n",
      "Epoch 3/200, Iteration 4/250, Loss: 0.0307\n",
      "Epoch 3/200, Iteration 5/250, Loss: 0.0817\n",
      "Epoch 3/200, Iteration 6/250, Loss: 0.0383\n",
      "Epoch 3/200, Iteration 7/250, Loss: 0.0777\n",
      "Epoch 3/200, Iteration 8/250, Loss: 0.0466\n",
      "Epoch 3/200, Iteration 9/250, Loss: 0.0491\n",
      "Epoch 3/200, Iteration 10/250, Loss: 0.0404\n",
      "Epoch 3/200, Iteration 11/250, Loss: 0.0545\n",
      "Epoch 3/200, Iteration 12/250, Loss: 0.0691\n",
      "Epoch 3/200, Iteration 13/250, Loss: 0.0315\n",
      "Epoch 3/200, Iteration 14/250, Loss: 0.0441\n",
      "Epoch 3/200, Iteration 15/250, Loss: 0.0516\n",
      "Epoch 3/200, Iteration 16/250, Loss: 0.0463\n",
      "Epoch 3/200, Iteration 17/250, Loss: 0.0486\n",
      "Epoch 3/200, Iteration 18/250, Loss: 0.0510\n",
      "Epoch 3/200, Iteration 19/250, Loss: 0.0728\n",
      "Epoch 3/200, Iteration 20/250, Loss: 0.0255\n",
      "Epoch 3/200, Iteration 21/250, Loss: 0.1287\n",
      "Epoch 3/200, Iteration 22/250, Loss: 0.1062\n",
      "Epoch 3/200, Iteration 23/250, Loss: 0.0598\n",
      "Epoch 3/200, Iteration 24/250, Loss: 0.0626\n",
      "Epoch 3/200, Iteration 25/250, Loss: 0.0330\n",
      "Epoch 3/200, Iteration 26/250, Loss: 0.0649\n",
      "Epoch 3/200, Iteration 27/250, Loss: 0.0616\n",
      "Epoch 3/200, Iteration 28/250, Loss: 0.0495\n",
      "Epoch 3/200, Iteration 29/250, Loss: 0.0547\n",
      "Epoch 3/200, Iteration 30/250, Loss: 0.0504\n",
      "Epoch 3/200, Iteration 31/250, Loss: 0.0700\n",
      "Epoch 3/200, Iteration 32/250, Loss: 0.0651\n",
      "Epoch 3/200, Iteration 33/250, Loss: 0.0438\n",
      "Epoch 3/200, Iteration 34/250, Loss: 0.0957\n",
      "Epoch 3/200, Iteration 35/250, Loss: 0.0472\n",
      "Epoch 3/200, Iteration 36/250, Loss: 0.0760\n",
      "Epoch 3/200, Iteration 37/250, Loss: 0.0767\n",
      "Epoch 3/200, Iteration 38/250, Loss: 0.0389\n",
      "Epoch 3/200, Iteration 39/250, Loss: 0.0604\n",
      "Epoch 3/200, Iteration 40/250, Loss: 0.0383\n",
      "Epoch 3/200, Iteration 41/250, Loss: 0.0637\n",
      "Epoch 3/200, Iteration 42/250, Loss: 0.0480\n",
      "Epoch 3/200, Iteration 43/250, Loss: 0.0579\n",
      "Epoch 3/200, Iteration 44/250, Loss: 0.0737\n",
      "Epoch 3/200, Iteration 45/250, Loss: 0.0612\n",
      "Epoch 3/200, Iteration 46/250, Loss: 0.0488\n",
      "Epoch 3/200, Iteration 47/250, Loss: 0.0617\n",
      "Epoch 3/200, Iteration 48/250, Loss: 0.0531\n",
      "Epoch 3/200, Iteration 49/250, Loss: 0.0706\n",
      "Epoch 3/200, Iteration 50/250, Loss: 0.0519\n",
      "Epoch 3/200, Iteration 51/250, Loss: 0.0383\n",
      "Epoch 3/200, Iteration 52/250, Loss: 0.0461\n",
      "Epoch 3/200, Iteration 53/250, Loss: 0.0500\n",
      "Epoch 3/200, Iteration 54/250, Loss: 0.0469\n",
      "Epoch 3/200, Iteration 55/250, Loss: 0.0288\n",
      "Epoch 3/200, Iteration 56/250, Loss: 0.0376\n",
      "Epoch 3/200, Iteration 57/250, Loss: 0.0519\n",
      "Epoch 3/200, Iteration 58/250, Loss: 0.0401\n",
      "Epoch 3/200, Iteration 59/250, Loss: 0.0450\n",
      "Epoch 3/200, Iteration 60/250, Loss: 0.0387\n",
      "Epoch 3/200, Iteration 61/250, Loss: 0.0403\n",
      "Epoch 3/200, Iteration 62/250, Loss: 0.0597\n",
      "Epoch 3/200, Iteration 63/250, Loss: 0.0564\n",
      "Epoch 3/200, Iteration 64/250, Loss: 0.0456\n",
      "Epoch 3/200, Iteration 65/250, Loss: 0.0638\n",
      "Epoch 3/200, Iteration 66/250, Loss: 0.0570\n",
      "Epoch 3/200, Iteration 67/250, Loss: 0.0154\n",
      "Epoch 3/200, Iteration 68/250, Loss: 0.0350\n",
      "Epoch 3/200, Iteration 69/250, Loss: 0.0349\n",
      "Epoch 3/200, Iteration 70/250, Loss: 0.0393\n",
      "Epoch 3/200, Iteration 71/250, Loss: 0.0378\n",
      "Epoch 3/200, Iteration 72/250, Loss: 0.0232\n",
      "Epoch 3/200, Iteration 73/250, Loss: 0.0397\n",
      "Epoch 3/200, Iteration 74/250, Loss: 0.0520\n",
      "Epoch 3/200, Iteration 75/250, Loss: 0.0243\n",
      "Epoch 3/200, Iteration 76/250, Loss: 0.0401\n",
      "Epoch 3/200, Iteration 77/250, Loss: 0.0528\n",
      "Epoch 3/200, Iteration 78/250, Loss: 0.0572\n",
      "Epoch 3/200, Iteration 79/250, Loss: 0.0372\n",
      "Epoch 3/200, Iteration 80/250, Loss: 0.0380\n",
      "Epoch 3/200, Iteration 81/250, Loss: 0.0312\n",
      "Epoch 3/200, Iteration 82/250, Loss: 0.0319\n",
      "Epoch 3/200, Iteration 83/250, Loss: 0.0768\n",
      "Epoch 3/200, Iteration 84/250, Loss: 0.0386\n",
      "Epoch 3/200, Iteration 85/250, Loss: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Iteration 86/250, Loss: 0.0282\n",
      "Epoch 3/200, Iteration 87/250, Loss: 0.0504\n",
      "Epoch 3/200, Iteration 88/250, Loss: 0.0672\n",
      "Epoch 3/200, Iteration 89/250, Loss: 0.0294\n",
      "Epoch 3/200, Iteration 90/250, Loss: 0.0349\n",
      "Epoch 3/200, Iteration 91/250, Loss: 0.0319\n",
      "Epoch 3/200, Iteration 92/250, Loss: 0.0400\n",
      "Epoch 3/200, Iteration 93/250, Loss: 0.0279\n",
      "Epoch 3/200, Iteration 94/250, Loss: 0.0308\n",
      "Epoch 3/200, Iteration 95/250, Loss: 0.0236\n",
      "Epoch 3/200, Iteration 96/250, Loss: 0.0566\n",
      "Epoch 3/200, Iteration 97/250, Loss: 0.0486\n",
      "Epoch 3/200, Iteration 98/250, Loss: 0.0473\n",
      "Epoch 3/200, Iteration 99/250, Loss: 0.0354\n",
      "Epoch 3/200, Iteration 100/250, Loss: 0.0435\n",
      "Epoch 3/200, Iteration 101/250, Loss: 0.0282\n",
      "Epoch 3/200, Iteration 102/250, Loss: 0.0826\n",
      "Epoch 3/200, Iteration 103/250, Loss: 0.0464\n",
      "Epoch 3/200, Iteration 104/250, Loss: 0.0317\n",
      "Epoch 3/200, Iteration 105/250, Loss: 0.0342\n",
      "Epoch 3/200, Iteration 106/250, Loss: 0.0806\n",
      "Epoch 3/200, Iteration 107/250, Loss: 0.0328\n",
      "Epoch 3/200, Iteration 108/250, Loss: 0.0349\n",
      "Epoch 3/200, Iteration 109/250, Loss: 0.0430\n",
      "Epoch 3/200, Iteration 110/250, Loss: 0.0310\n",
      "Epoch 3/200, Iteration 111/250, Loss: 0.0419\n",
      "Epoch 3/200, Iteration 112/250, Loss: 0.0185\n",
      "Epoch 3/200, Iteration 113/250, Loss: 0.0260\n",
      "Epoch 3/200, Iteration 114/250, Loss: 0.0232\n",
      "Epoch 3/200, Iteration 115/250, Loss: 0.0230\n",
      "Epoch 3/200, Iteration 116/250, Loss: 0.0436\n",
      "Epoch 3/200, Iteration 117/250, Loss: 0.0509\n",
      "Epoch 3/200, Iteration 118/250, Loss: 0.0490\n",
      "Epoch 3/200, Iteration 119/250, Loss: 0.0772\n",
      "Epoch 3/200, Iteration 120/250, Loss: 0.0452\n",
      "Epoch 3/200, Iteration 121/250, Loss: 0.0648\n",
      "Epoch 3/200, Iteration 122/250, Loss: 0.0685\n",
      "Epoch 3/200, Iteration 123/250, Loss: 0.0569\n",
      "Epoch 3/200, Iteration 124/250, Loss: 0.0328\n",
      "Epoch 3/200, Iteration 125/250, Loss: 0.0308\n",
      "Epoch 3/200, Iteration 126/250, Loss: 0.0845\n",
      "Epoch 3/200, Iteration 127/250, Loss: 0.0199\n",
      "Epoch 3/200, Iteration 128/250, Loss: 0.0261\n",
      "Epoch 3/200, Iteration 129/250, Loss: 0.0562\n",
      "Epoch 3/200, Iteration 130/250, Loss: 0.0423\n",
      "Epoch 3/200, Iteration 131/250, Loss: 0.0464\n",
      "Epoch 3/200, Iteration 132/250, Loss: 0.0765\n",
      "Epoch 3/200, Iteration 133/250, Loss: 0.0372\n",
      "Epoch 3/200, Iteration 134/250, Loss: 0.0616\n",
      "Epoch 3/200, Iteration 135/250, Loss: 0.0254\n",
      "Epoch 3/200, Iteration 136/250, Loss: 0.0578\n",
      "Epoch 3/200, Iteration 137/250, Loss: 0.0489\n",
      "Epoch 3/200, Iteration 138/250, Loss: 0.0430\n",
      "Epoch 3/200, Iteration 139/250, Loss: 0.0541\n",
      "Epoch 3/200, Iteration 140/250, Loss: 0.0453\n",
      "Epoch 3/200, Iteration 141/250, Loss: 0.0437\n",
      "Epoch 3/200, Iteration 142/250, Loss: 0.0284\n",
      "Epoch 3/200, Iteration 143/250, Loss: 0.0541\n",
      "Epoch 3/200, Iteration 144/250, Loss: 0.0638\n",
      "Epoch 3/200, Iteration 145/250, Loss: 0.0439\n",
      "Epoch 3/200, Iteration 146/250, Loss: 0.0528\n",
      "Epoch 3/200, Iteration 147/250, Loss: 0.0578\n",
      "Epoch 3/200, Iteration 148/250, Loss: 0.0531\n",
      "Epoch 3/200, Iteration 149/250, Loss: 0.0338\n",
      "Epoch 3/200, Iteration 150/250, Loss: 0.0377\n",
      "Epoch 3/200, Iteration 151/250, Loss: 0.0474\n",
      "Epoch 3/200, Iteration 152/250, Loss: 0.0375\n",
      "Epoch 3/200, Iteration 153/250, Loss: 0.0500\n",
      "Epoch 3/200, Iteration 154/250, Loss: 0.0368\n",
      "Epoch 3/200, Iteration 155/250, Loss: 0.0460\n",
      "Epoch 3/200, Iteration 156/250, Loss: 0.0744\n",
      "Epoch 3/200, Iteration 157/250, Loss: 0.0500\n",
      "Epoch 3/200, Iteration 158/250, Loss: 0.0730\n",
      "Epoch 3/200, Iteration 159/250, Loss: 0.0421\n",
      "Epoch 3/200, Iteration 160/250, Loss: 0.0502\n",
      "Epoch 3/200, Iteration 161/250, Loss: 0.0561\n",
      "Epoch 3/200, Iteration 162/250, Loss: 0.0277\n",
      "Epoch 3/200, Iteration 163/250, Loss: 0.0620\n",
      "Epoch 3/200, Iteration 164/250, Loss: 0.0649\n",
      "Epoch 3/200, Iteration 165/250, Loss: 0.0273\n",
      "Epoch 3/200, Iteration 166/250, Loss: 0.0476\n",
      "Epoch 3/200, Iteration 167/250, Loss: 0.0505\n",
      "Epoch 3/200, Iteration 168/250, Loss: 0.0270\n",
      "Epoch 3/200, Iteration 169/250, Loss: 0.0303\n",
      "Epoch 3/200, Iteration 170/250, Loss: 0.0602\n",
      "Epoch 3/200, Iteration 171/250, Loss: 0.0518\n",
      "Epoch 3/200, Iteration 172/250, Loss: 0.0452\n",
      "Epoch 3/200, Iteration 173/250, Loss: 0.0664\n",
      "Epoch 3/200, Iteration 174/250, Loss: 0.0248\n",
      "Epoch 3/200, Iteration 175/250, Loss: 0.0541\n",
      "Epoch 3/200, Iteration 176/250, Loss: 0.0405\n",
      "Epoch 3/200, Iteration 177/250, Loss: 0.0432\n",
      "Epoch 3/200, Iteration 178/250, Loss: 0.0388\n",
      "Epoch 3/200, Iteration 179/250, Loss: 0.0324\n",
      "Epoch 3/200, Iteration 180/250, Loss: 0.0430\n",
      "Epoch 3/200, Iteration 181/250, Loss: 0.0480\n",
      "Epoch 3/200, Iteration 182/250, Loss: 0.0584\n",
      "Epoch 3/200, Iteration 183/250, Loss: 0.0437\n",
      "Epoch 3/200, Iteration 184/250, Loss: 0.0389\n",
      "Epoch 3/200, Iteration 185/250, Loss: 0.0327\n",
      "Epoch 3/200, Iteration 186/250, Loss: 0.0443\n",
      "Epoch 3/200, Iteration 187/250, Loss: 0.0371\n",
      "Epoch 3/200, Iteration 188/250, Loss: 0.0449\n",
      "Epoch 3/200, Iteration 189/250, Loss: 0.0388\n",
      "Epoch 3/200, Iteration 190/250, Loss: 0.0746\n",
      "Epoch 3/200, Iteration 191/250, Loss: 0.0630\n",
      "Epoch 3/200, Iteration 192/250, Loss: 0.0456\n",
      "Epoch 3/200, Iteration 193/250, Loss: 0.0466\n",
      "Epoch 3/200, Iteration 194/250, Loss: 0.0813\n",
      "Epoch 3/200, Iteration 195/250, Loss: 0.0352\n",
      "Epoch 3/200, Iteration 196/250, Loss: 0.0598\n",
      "Epoch 3/200, Iteration 197/250, Loss: 0.0540\n",
      "Epoch 3/200, Iteration 198/250, Loss: 0.0410\n",
      "Epoch 3/200, Iteration 199/250, Loss: 0.0441\n",
      "Epoch 3/200, Iteration 200/250, Loss: 0.0665\n",
      "Epoch 3/200, Iteration 201/250, Loss: 0.0286\n",
      "Epoch 3/200, Iteration 202/250, Loss: 0.0571\n",
      "Epoch 3/200, Iteration 203/250, Loss: 0.0605\n",
      "Epoch 3/200, Iteration 204/250, Loss: 0.0654\n",
      "Epoch 3/200, Iteration 205/250, Loss: 0.0342\n",
      "Epoch 3/200, Iteration 206/250, Loss: 0.0502\n",
      "Epoch 3/200, Iteration 207/250, Loss: 0.0278\n",
      "Epoch 3/200, Iteration 208/250, Loss: 0.0260\n",
      "Epoch 3/200, Iteration 209/250, Loss: 0.0232\n",
      "Epoch 3/200, Iteration 210/250, Loss: 0.0282\n",
      "Epoch 3/200, Iteration 211/250, Loss: 0.0371\n",
      "Epoch 3/200, Iteration 212/250, Loss: 0.0422\n",
      "Epoch 3/200, Iteration 213/250, Loss: 0.0290\n",
      "Epoch 3/200, Iteration 214/250, Loss: 0.0372\n",
      "Epoch 3/200, Iteration 215/250, Loss: 0.0280\n",
      "Epoch 3/200, Iteration 216/250, Loss: 0.0337\n",
      "Epoch 3/200, Iteration 217/250, Loss: 0.0281\n",
      "Epoch 3/200, Iteration 218/250, Loss: 0.0438\n",
      "Epoch 3/200, Iteration 219/250, Loss: 0.0766\n",
      "Epoch 3/200, Iteration 220/250, Loss: 0.0742\n",
      "Epoch 3/200, Iteration 221/250, Loss: 0.0260\n",
      "Epoch 3/200, Iteration 222/250, Loss: 0.0666\n",
      "Epoch 3/200, Iteration 223/250, Loss: 0.0609\n",
      "Epoch 3/200, Iteration 224/250, Loss: 0.0333\n",
      "Epoch 3/200, Iteration 225/250, Loss: 0.0396\n",
      "Epoch 3/200, Iteration 226/250, Loss: 0.0367\n",
      "Epoch 3/200, Iteration 227/250, Loss: 0.0319\n",
      "Epoch 3/200, Iteration 228/250, Loss: 0.0560\n",
      "Epoch 3/200, Iteration 229/250, Loss: 0.0269\n",
      "Epoch 3/200, Iteration 230/250, Loss: 0.0385\n",
      "Epoch 3/200, Iteration 231/250, Loss: 0.0400\n",
      "Epoch 3/200, Iteration 232/250, Loss: 0.0380\n",
      "Epoch 3/200, Iteration 233/250, Loss: 0.0300\n",
      "Epoch 3/200, Iteration 234/250, Loss: 0.0340\n",
      "Epoch 3/200, Iteration 235/250, Loss: 0.0338\n",
      "Epoch 3/200, Iteration 236/250, Loss: 0.0403\n",
      "Epoch 3/200, Iteration 237/250, Loss: 0.1079\n",
      "Epoch 3/200, Iteration 238/250, Loss: 0.0682\n",
      "Epoch 3/200, Iteration 239/250, Loss: 0.0359\n",
      "Epoch 3/200, Iteration 240/250, Loss: 0.0761\n",
      "Epoch 3/200, Iteration 241/250, Loss: 0.0665\n",
      "Epoch 3/200, Iteration 242/250, Loss: 0.0282\n",
      "Epoch 3/200, Iteration 243/250, Loss: 0.0308\n",
      "Epoch 3/200, Iteration 244/250, Loss: 0.0545\n",
      "Epoch 3/200, Iteration 245/250, Loss: 0.0398\n",
      "Epoch 3/200, Iteration 246/250, Loss: 0.0403\n",
      "Epoch 3/200, Iteration 247/250, Loss: 0.0450\n",
      "Epoch 3/200, Iteration 248/250, Loss: 0.0522\n",
      "Epoch 3/200, Iteration 249/250, Loss: 0.0372\n",
      "Epoch 3/200, Iteration 250/250, Loss: 0.0589\n",
      "Train Error: \n",
      " Accuracy: 83.04%, Avg loss: 0.037601, MRE: 1.947102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.037764, MRE: 3.506627 \n",
      "\n",
      "Epoch 4/200, Iteration 1/250, Loss: 0.0465\n",
      "Epoch 4/200, Iteration 2/250, Loss: 0.0349\n",
      "Epoch 4/200, Iteration 3/250, Loss: 0.0765\n",
      "Epoch 4/200, Iteration 4/250, Loss: 0.0794\n",
      "Epoch 4/200, Iteration 5/250, Loss: 0.0759\n",
      "Epoch 4/200, Iteration 6/250, Loss: 0.0519\n",
      "Epoch 4/200, Iteration 7/250, Loss: 0.0386\n",
      "Epoch 4/200, Iteration 8/250, Loss: 0.0664\n",
      "Epoch 4/200, Iteration 9/250, Loss: 0.0467\n",
      "Epoch 4/200, Iteration 10/250, Loss: 0.0389\n",
      "Epoch 4/200, Iteration 11/250, Loss: 0.0665\n",
      "Epoch 4/200, Iteration 12/250, Loss: 0.0816\n",
      "Epoch 4/200, Iteration 13/250, Loss: 0.0579\n",
      "Epoch 4/200, Iteration 14/250, Loss: 0.0428\n",
      "Epoch 4/200, Iteration 15/250, Loss: 0.0408\n",
      "Epoch 4/200, Iteration 16/250, Loss: 0.0507\n",
      "Epoch 4/200, Iteration 17/250, Loss: 0.0468\n",
      "Epoch 4/200, Iteration 18/250, Loss: 0.0412\n",
      "Epoch 4/200, Iteration 19/250, Loss: 0.0268\n",
      "Epoch 4/200, Iteration 20/250, Loss: 0.0683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Iteration 21/250, Loss: 0.0680\n",
      "Epoch 4/200, Iteration 22/250, Loss: 0.0674\n",
      "Epoch 4/200, Iteration 23/250, Loss: 0.0361\n",
      "Epoch 4/200, Iteration 24/250, Loss: 0.0338\n",
      "Epoch 4/200, Iteration 25/250, Loss: 0.0306\n",
      "Epoch 4/200, Iteration 26/250, Loss: 0.0424\n",
      "Epoch 4/200, Iteration 27/250, Loss: 0.0308\n",
      "Epoch 4/200, Iteration 28/250, Loss: 0.0378\n",
      "Epoch 4/200, Iteration 29/250, Loss: 0.0472\n",
      "Epoch 4/200, Iteration 30/250, Loss: 0.0348\n",
      "Epoch 4/200, Iteration 31/250, Loss: 0.0267\n",
      "Epoch 4/200, Iteration 32/250, Loss: 0.0251\n",
      "Epoch 4/200, Iteration 33/250, Loss: 0.0290\n",
      "Epoch 4/200, Iteration 34/250, Loss: 0.0292\n",
      "Epoch 4/200, Iteration 35/250, Loss: 0.0207\n",
      "Epoch 4/200, Iteration 36/250, Loss: 0.0206\n",
      "Epoch 4/200, Iteration 37/250, Loss: 0.0291\n",
      "Epoch 4/200, Iteration 38/250, Loss: 0.0175\n",
      "Epoch 4/200, Iteration 39/250, Loss: 0.0428\n",
      "Epoch 4/200, Iteration 40/250, Loss: 0.0216\n",
      "Epoch 4/200, Iteration 41/250, Loss: 0.0169\n",
      "Epoch 4/200, Iteration 42/250, Loss: 0.0236\n",
      "Epoch 4/200, Iteration 43/250, Loss: 0.0271\n",
      "Epoch 4/200, Iteration 44/250, Loss: 0.0228\n",
      "Epoch 4/200, Iteration 45/250, Loss: 0.0294\n",
      "Epoch 4/200, Iteration 46/250, Loss: 0.0279\n",
      "Epoch 4/200, Iteration 47/250, Loss: 0.0229\n",
      "Epoch 4/200, Iteration 48/250, Loss: 0.0265\n",
      "Epoch 4/200, Iteration 49/250, Loss: 0.0477\n",
      "Epoch 4/200, Iteration 50/250, Loss: 0.0229\n",
      "Epoch 4/200, Iteration 51/250, Loss: 0.0305\n",
      "Epoch 4/200, Iteration 52/250, Loss: 0.0359\n",
      "Epoch 4/200, Iteration 53/250, Loss: 0.0635\n",
      "Epoch 4/200, Iteration 54/250, Loss: 0.0447\n",
      "Epoch 4/200, Iteration 55/250, Loss: 0.0310\n",
      "Epoch 4/200, Iteration 56/250, Loss: 0.0496\n",
      "Epoch 4/200, Iteration 57/250, Loss: 0.0418\n",
      "Epoch 4/200, Iteration 58/250, Loss: 0.0299\n",
      "Epoch 4/200, Iteration 59/250, Loss: 0.0430\n",
      "Epoch 4/200, Iteration 60/250, Loss: 0.0436\n",
      "Epoch 4/200, Iteration 61/250, Loss: 0.0434\n",
      "Epoch 4/200, Iteration 62/250, Loss: 0.0366\n",
      "Epoch 4/200, Iteration 63/250, Loss: 0.0448\n",
      "Epoch 4/200, Iteration 64/250, Loss: 0.0300\n",
      "Epoch 4/200, Iteration 65/250, Loss: 0.0477\n",
      "Epoch 4/200, Iteration 66/250, Loss: 0.0240\n",
      "Epoch 4/200, Iteration 67/250, Loss: 0.0310\n",
      "Epoch 4/200, Iteration 68/250, Loss: 0.0327\n",
      "Epoch 4/200, Iteration 69/250, Loss: 0.0263\n",
      "Epoch 4/200, Iteration 70/250, Loss: 0.0361\n",
      "Epoch 4/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 4/200, Iteration 72/250, Loss: 0.0236\n",
      "Epoch 4/200, Iteration 73/250, Loss: 0.0515\n",
      "Epoch 4/200, Iteration 74/250, Loss: 0.0445\n",
      "Epoch 4/200, Iteration 75/250, Loss: 0.0261\n",
      "Epoch 4/200, Iteration 76/250, Loss: 0.0507\n",
      "Epoch 4/200, Iteration 77/250, Loss: 0.0290\n",
      "Epoch 4/200, Iteration 78/250, Loss: 0.0306\n",
      "Epoch 4/200, Iteration 79/250, Loss: 0.0420\n",
      "Epoch 4/200, Iteration 80/250, Loss: 0.0303\n",
      "Epoch 4/200, Iteration 81/250, Loss: 0.0438\n",
      "Epoch 4/200, Iteration 82/250, Loss: 0.0395\n",
      "Epoch 4/200, Iteration 83/250, Loss: 0.0467\n",
      "Epoch 4/200, Iteration 84/250, Loss: 0.0268\n",
      "Epoch 4/200, Iteration 85/250, Loss: 0.0315\n",
      "Epoch 4/200, Iteration 86/250, Loss: 0.0512\n",
      "Epoch 4/200, Iteration 87/250, Loss: 0.0287\n",
      "Epoch 4/200, Iteration 88/250, Loss: 0.0256\n",
      "Epoch 4/200, Iteration 89/250, Loss: 0.0329\n",
      "Epoch 4/200, Iteration 90/250, Loss: 0.0291\n",
      "Epoch 4/200, Iteration 91/250, Loss: 0.0205\n",
      "Epoch 4/200, Iteration 92/250, Loss: 0.0455\n",
      "Epoch 4/200, Iteration 93/250, Loss: 0.0456\n",
      "Epoch 4/200, Iteration 94/250, Loss: 0.0511\n",
      "Epoch 4/200, Iteration 95/250, Loss: 0.0240\n",
      "Epoch 4/200, Iteration 96/250, Loss: 0.0279\n",
      "Epoch 4/200, Iteration 97/250, Loss: 0.0283\n",
      "Epoch 4/200, Iteration 98/250, Loss: 0.0335\n",
      "Epoch 4/200, Iteration 99/250, Loss: 0.0372\n",
      "Epoch 4/200, Iteration 100/250, Loss: 0.0369\n",
      "Epoch 4/200, Iteration 101/250, Loss: 0.0304\n",
      "Epoch 4/200, Iteration 102/250, Loss: 0.0251\n",
      "Epoch 4/200, Iteration 103/250, Loss: 0.0378\n",
      "Epoch 4/200, Iteration 104/250, Loss: 0.0322\n",
      "Epoch 4/200, Iteration 105/250, Loss: 0.0292\n",
      "Epoch 4/200, Iteration 106/250, Loss: 0.0256\n",
      "Epoch 4/200, Iteration 107/250, Loss: 0.0246\n",
      "Epoch 4/200, Iteration 108/250, Loss: 0.0189\n",
      "Epoch 4/200, Iteration 109/250, Loss: 0.0548\n",
      "Epoch 4/200, Iteration 110/250, Loss: 0.0276\n",
      "Epoch 4/200, Iteration 111/250, Loss: 0.0399\n",
      "Epoch 4/200, Iteration 112/250, Loss: 0.0276\n",
      "Epoch 4/200, Iteration 113/250, Loss: 0.0487\n",
      "Epoch 4/200, Iteration 114/250, Loss: 0.0374\n",
      "Epoch 4/200, Iteration 115/250, Loss: 0.0582\n",
      "Epoch 4/200, Iteration 116/250, Loss: 0.0353\n",
      "Epoch 4/200, Iteration 117/250, Loss: 0.0200\n",
      "Epoch 4/200, Iteration 118/250, Loss: 0.0426\n",
      "Epoch 4/200, Iteration 119/250, Loss: 0.0342\n",
      "Epoch 4/200, Iteration 120/250, Loss: 0.0181\n",
      "Epoch 4/200, Iteration 121/250, Loss: 0.0263\n",
      "Epoch 4/200, Iteration 122/250, Loss: 0.0357\n",
      "Epoch 4/200, Iteration 123/250, Loss: 0.0260\n",
      "Epoch 4/200, Iteration 124/250, Loss: 0.0190\n",
      "Epoch 4/200, Iteration 125/250, Loss: 0.0216\n",
      "Epoch 4/200, Iteration 126/250, Loss: 0.0346\n",
      "Epoch 4/200, Iteration 127/250, Loss: 0.0222\n",
      "Epoch 4/200, Iteration 128/250, Loss: 0.0303\n",
      "Epoch 4/200, Iteration 129/250, Loss: 0.0178\n",
      "Epoch 4/200, Iteration 130/250, Loss: 0.0369\n",
      "Epoch 4/200, Iteration 131/250, Loss: 0.0200\n",
      "Epoch 4/200, Iteration 132/250, Loss: 0.0191\n",
      "Epoch 4/200, Iteration 133/250, Loss: 0.0254\n",
      "Epoch 4/200, Iteration 134/250, Loss: 0.0097\n",
      "Epoch 4/200, Iteration 135/250, Loss: 0.0278\n",
      "Epoch 4/200, Iteration 136/250, Loss: 0.0177\n",
      "Epoch 4/200, Iteration 137/250, Loss: 0.0141\n",
      "Epoch 4/200, Iteration 138/250, Loss: 0.0320\n",
      "Epoch 4/200, Iteration 139/250, Loss: 0.0232\n",
      "Epoch 4/200, Iteration 140/250, Loss: 0.0269\n",
      "Epoch 4/200, Iteration 141/250, Loss: 0.0185\n",
      "Epoch 4/200, Iteration 142/250, Loss: 0.0301\n",
      "Epoch 4/200, Iteration 143/250, Loss: 0.0571\n",
      "Epoch 4/200, Iteration 144/250, Loss: 0.0192\n",
      "Epoch 4/200, Iteration 145/250, Loss: 0.0210\n",
      "Epoch 4/200, Iteration 146/250, Loss: 0.0335\n",
      "Epoch 4/200, Iteration 147/250, Loss: 0.0358\n",
      "Epoch 4/200, Iteration 148/250, Loss: 0.0235\n",
      "Epoch 4/200, Iteration 149/250, Loss: 0.0295\n",
      "Epoch 4/200, Iteration 150/250, Loss: 0.0379\n",
      "Epoch 4/200, Iteration 151/250, Loss: 0.0301\n",
      "Epoch 4/200, Iteration 152/250, Loss: 0.0302\n",
      "Epoch 4/200, Iteration 153/250, Loss: 0.0221\n",
      "Epoch 4/200, Iteration 154/250, Loss: 0.0341\n",
      "Epoch 4/200, Iteration 155/250, Loss: 0.0263\n",
      "Epoch 4/200, Iteration 156/250, Loss: 0.0150\n",
      "Epoch 4/200, Iteration 157/250, Loss: 0.0333\n",
      "Epoch 4/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 4/200, Iteration 159/250, Loss: 0.0127\n",
      "Epoch 4/200, Iteration 160/250, Loss: 0.0191\n",
      "Epoch 4/200, Iteration 161/250, Loss: 0.0137\n",
      "Epoch 4/200, Iteration 162/250, Loss: 0.0234\n",
      "Epoch 4/200, Iteration 163/250, Loss: 0.0279\n",
      "Epoch 4/200, Iteration 164/250, Loss: 0.0426\n",
      "Epoch 4/200, Iteration 165/250, Loss: 0.0165\n",
      "Epoch 4/200, Iteration 166/250, Loss: 0.0205\n",
      "Epoch 4/200, Iteration 167/250, Loss: 0.0181\n",
      "Epoch 4/200, Iteration 168/250, Loss: 0.0120\n",
      "Epoch 4/200, Iteration 169/250, Loss: 0.0204\n",
      "Epoch 4/200, Iteration 170/250, Loss: 0.0189\n",
      "Epoch 4/200, Iteration 171/250, Loss: 0.0226\n",
      "Epoch 4/200, Iteration 172/250, Loss: 0.0314\n",
      "Epoch 4/200, Iteration 173/250, Loss: 0.0239\n",
      "Epoch 4/200, Iteration 174/250, Loss: 0.0203\n",
      "Epoch 4/200, Iteration 175/250, Loss: 0.0226\n",
      "Epoch 4/200, Iteration 176/250, Loss: 0.0375\n",
      "Epoch 4/200, Iteration 177/250, Loss: 0.0269\n",
      "Epoch 4/200, Iteration 178/250, Loss: 0.0198\n",
      "Epoch 4/200, Iteration 179/250, Loss: 0.0499\n",
      "Epoch 4/200, Iteration 180/250, Loss: 0.0452\n",
      "Epoch 4/200, Iteration 181/250, Loss: 0.0303\n",
      "Epoch 4/200, Iteration 182/250, Loss: 0.0333\n",
      "Epoch 4/200, Iteration 183/250, Loss: 0.0536\n",
      "Epoch 4/200, Iteration 184/250, Loss: 0.0267\n",
      "Epoch 4/200, Iteration 185/250, Loss: 0.0336\n",
      "Epoch 4/200, Iteration 186/250, Loss: 0.0343\n",
      "Epoch 4/200, Iteration 187/250, Loss: 0.0275\n",
      "Epoch 4/200, Iteration 188/250, Loss: 0.0466\n",
      "Epoch 4/200, Iteration 189/250, Loss: 0.0283\n",
      "Epoch 4/200, Iteration 190/250, Loss: 0.0330\n",
      "Epoch 4/200, Iteration 191/250, Loss: 0.0447\n",
      "Epoch 4/200, Iteration 192/250, Loss: 0.0271\n",
      "Epoch 4/200, Iteration 193/250, Loss: 0.0538\n",
      "Epoch 4/200, Iteration 194/250, Loss: 0.0314\n",
      "Epoch 4/200, Iteration 195/250, Loss: 0.0192\n",
      "Epoch 4/200, Iteration 196/250, Loss: 0.0396\n",
      "Epoch 4/200, Iteration 197/250, Loss: 0.0156\n",
      "Epoch 4/200, Iteration 198/250, Loss: 0.0415\n",
      "Epoch 4/200, Iteration 199/250, Loss: 0.0208\n",
      "Epoch 4/200, Iteration 200/250, Loss: 0.0311\n",
      "Epoch 4/200, Iteration 201/250, Loss: 0.0353\n",
      "Epoch 4/200, Iteration 202/250, Loss: 0.0221\n",
      "Epoch 4/200, Iteration 203/250, Loss: 0.0308\n",
      "Epoch 4/200, Iteration 204/250, Loss: 0.0277\n",
      "Epoch 4/200, Iteration 205/250, Loss: 0.0210\n",
      "Epoch 4/200, Iteration 206/250, Loss: 0.0257\n",
      "Epoch 4/200, Iteration 207/250, Loss: 0.0197\n",
      "Epoch 4/200, Iteration 208/250, Loss: 0.0253\n",
      "Epoch 4/200, Iteration 209/250, Loss: 0.0214\n",
      "Epoch 4/200, Iteration 210/250, Loss: 0.0156\n",
      "Epoch 4/200, Iteration 211/250, Loss: 0.0293\n",
      "Epoch 4/200, Iteration 212/250, Loss: 0.0334\n",
      "Epoch 4/200, Iteration 213/250, Loss: 0.0634\n",
      "Epoch 4/200, Iteration 214/250, Loss: 0.0697\n",
      "Epoch 4/200, Iteration 215/250, Loss: 0.0283\n",
      "Epoch 4/200, Iteration 216/250, Loss: 0.0423\n",
      "Epoch 4/200, Iteration 217/250, Loss: 0.0304\n",
      "Epoch 4/200, Iteration 218/250, Loss: 0.0405\n",
      "Epoch 4/200, Iteration 219/250, Loss: 0.0298\n",
      "Epoch 4/200, Iteration 220/250, Loss: 0.0261\n",
      "Epoch 4/200, Iteration 221/250, Loss: 0.0212\n",
      "Epoch 4/200, Iteration 222/250, Loss: 0.0302\n",
      "Epoch 4/200, Iteration 223/250, Loss: 0.0130\n",
      "Epoch 4/200, Iteration 224/250, Loss: 0.0354\n",
      "Epoch 4/200, Iteration 225/250, Loss: 0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Iteration 226/250, Loss: 0.0196\n",
      "Epoch 4/200, Iteration 227/250, Loss: 0.0226\n",
      "Epoch 4/200, Iteration 228/250, Loss: 0.0276\n",
      "Epoch 4/200, Iteration 229/250, Loss: 0.0247\n",
      "Epoch 4/200, Iteration 230/250, Loss: 0.0383\n",
      "Epoch 4/200, Iteration 231/250, Loss: 0.0418\n",
      "Epoch 4/200, Iteration 232/250, Loss: 0.0282\n",
      "Epoch 4/200, Iteration 233/250, Loss: 0.0435\n",
      "Epoch 4/200, Iteration 234/250, Loss: 0.0386\n",
      "Epoch 4/200, Iteration 235/250, Loss: 0.0400\n",
      "Epoch 4/200, Iteration 236/250, Loss: 0.0464\n",
      "Epoch 4/200, Iteration 237/250, Loss: 0.0389\n",
      "Epoch 4/200, Iteration 238/250, Loss: 0.0239\n",
      "Epoch 4/200, Iteration 239/250, Loss: 0.0467\n",
      "Epoch 4/200, Iteration 240/250, Loss: 0.0396\n",
      "Epoch 4/200, Iteration 241/250, Loss: 0.0268\n",
      "Epoch 4/200, Iteration 242/250, Loss: 0.0280\n",
      "Epoch 4/200, Iteration 243/250, Loss: 0.0275\n",
      "Epoch 4/200, Iteration 244/250, Loss: 0.0290\n",
      "Epoch 4/200, Iteration 245/250, Loss: 0.0448\n",
      "Epoch 4/200, Iteration 246/250, Loss: 0.0377\n",
      "Epoch 4/200, Iteration 247/250, Loss: 0.0198\n",
      "Epoch 4/200, Iteration 248/250, Loss: 0.0569\n",
      "Epoch 4/200, Iteration 249/250, Loss: 0.0821\n",
      "Epoch 4/200, Iteration 250/250, Loss: 0.0497\n",
      "Train Error: \n",
      " Accuracy: 51.95%, Avg loss: 0.025508, MRE: 1.626788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.85%, Avg loss: 0.025627, MRE: 2.692453 \n",
      "\n",
      "Epoch 5/200, Iteration 1/250, Loss: 0.0386\n",
      "Epoch 5/200, Iteration 2/250, Loss: 0.0530\n",
      "Epoch 5/200, Iteration 3/250, Loss: 0.0342\n",
      "Epoch 5/200, Iteration 4/250, Loss: 0.0294\n",
      "Epoch 5/200, Iteration 5/250, Loss: 0.0411\n",
      "Epoch 5/200, Iteration 6/250, Loss: 0.0229\n",
      "Epoch 5/200, Iteration 7/250, Loss: 0.0245\n",
      "Epoch 5/200, Iteration 8/250, Loss: 0.0320\n",
      "Epoch 5/200, Iteration 9/250, Loss: 0.0282\n",
      "Epoch 5/200, Iteration 10/250, Loss: 0.0259\n",
      "Epoch 5/200, Iteration 11/250, Loss: 0.0357\n",
      "Epoch 5/200, Iteration 12/250, Loss: 0.0317\n",
      "Epoch 5/200, Iteration 13/250, Loss: 0.0366\n",
      "Epoch 5/200, Iteration 14/250, Loss: 0.0325\n",
      "Epoch 5/200, Iteration 15/250, Loss: 0.0330\n",
      "Epoch 5/200, Iteration 16/250, Loss: 0.0371\n",
      "Epoch 5/200, Iteration 17/250, Loss: 0.0415\n",
      "Epoch 5/200, Iteration 18/250, Loss: 0.0409\n",
      "Epoch 5/200, Iteration 19/250, Loss: 0.0310\n",
      "Epoch 5/200, Iteration 20/250, Loss: 0.0238\n",
      "Epoch 5/200, Iteration 21/250, Loss: 0.0434\n",
      "Epoch 5/200, Iteration 22/250, Loss: 0.0452\n",
      "Epoch 5/200, Iteration 23/250, Loss: 0.0295\n",
      "Epoch 5/200, Iteration 24/250, Loss: 0.0301\n",
      "Epoch 5/200, Iteration 25/250, Loss: 0.0373\n",
      "Epoch 5/200, Iteration 26/250, Loss: 0.0394\n",
      "Epoch 5/200, Iteration 27/250, Loss: 0.0300\n",
      "Epoch 5/200, Iteration 28/250, Loss: 0.0257\n",
      "Epoch 5/200, Iteration 29/250, Loss: 0.0288\n",
      "Epoch 5/200, Iteration 30/250, Loss: 0.0343\n",
      "Epoch 5/200, Iteration 31/250, Loss: 0.0357\n",
      "Epoch 5/200, Iteration 32/250, Loss: 0.0377\n",
      "Epoch 5/200, Iteration 33/250, Loss: 0.0245\n",
      "Epoch 5/200, Iteration 34/250, Loss: 0.0329\n",
      "Epoch 5/200, Iteration 35/250, Loss: 0.0415\n",
      "Epoch 5/200, Iteration 36/250, Loss: 0.0333\n",
      "Epoch 5/200, Iteration 37/250, Loss: 0.0285\n",
      "Epoch 5/200, Iteration 38/250, Loss: 0.0338\n",
      "Epoch 5/200, Iteration 39/250, Loss: 0.0298\n",
      "Epoch 5/200, Iteration 40/250, Loss: 0.0260\n",
      "Epoch 5/200, Iteration 41/250, Loss: 0.0310\n",
      "Epoch 5/200, Iteration 42/250, Loss: 0.0254\n",
      "Epoch 5/200, Iteration 43/250, Loss: 0.0209\n",
      "Epoch 5/200, Iteration 44/250, Loss: 0.0497\n",
      "Epoch 5/200, Iteration 45/250, Loss: 0.0209\n",
      "Epoch 5/200, Iteration 46/250, Loss: 0.0213\n",
      "Epoch 5/200, Iteration 47/250, Loss: 0.0192\n",
      "Epoch 5/200, Iteration 48/250, Loss: 0.0273\n",
      "Epoch 5/200, Iteration 49/250, Loss: 0.0240\n",
      "Epoch 5/200, Iteration 50/250, Loss: 0.0210\n",
      "Epoch 5/200, Iteration 51/250, Loss: 0.0240\n",
      "Epoch 5/200, Iteration 52/250, Loss: 0.0343\n",
      "Epoch 5/200, Iteration 53/250, Loss: 0.0281\n",
      "Epoch 5/200, Iteration 54/250, Loss: 0.0279\n",
      "Epoch 5/200, Iteration 55/250, Loss: 0.0249\n",
      "Epoch 5/200, Iteration 56/250, Loss: 0.0235\n",
      "Epoch 5/200, Iteration 57/250, Loss: 0.0295\n",
      "Epoch 5/200, Iteration 58/250, Loss: 0.0447\n",
      "Epoch 5/200, Iteration 59/250, Loss: 0.0253\n",
      "Epoch 5/200, Iteration 60/250, Loss: 0.0329\n",
      "Epoch 5/200, Iteration 61/250, Loss: 0.0248\n",
      "Epoch 5/200, Iteration 62/250, Loss: 0.0210\n",
      "Epoch 5/200, Iteration 63/250, Loss: 0.0168\n",
      "Epoch 5/200, Iteration 64/250, Loss: 0.0183\n",
      "Epoch 5/200, Iteration 65/250, Loss: 0.0300\n",
      "Epoch 5/200, Iteration 66/250, Loss: 0.0127\n",
      "Epoch 5/200, Iteration 67/250, Loss: 0.0138\n",
      "Epoch 5/200, Iteration 68/250, Loss: 0.0133\n",
      "Epoch 5/200, Iteration 69/250, Loss: 0.0199\n",
      "Epoch 5/200, Iteration 70/250, Loss: 0.0181\n",
      "Epoch 5/200, Iteration 71/250, Loss: 0.0346\n",
      "Epoch 5/200, Iteration 72/250, Loss: 0.0279\n",
      "Epoch 5/200, Iteration 73/250, Loss: 0.0333\n",
      "Epoch 5/200, Iteration 74/250, Loss: 0.0341\n",
      "Epoch 5/200, Iteration 75/250, Loss: 0.0749\n",
      "Epoch 5/200, Iteration 76/250, Loss: 0.0602\n",
      "Epoch 5/200, Iteration 77/250, Loss: 0.0598\n",
      "Epoch 5/200, Iteration 78/250, Loss: 0.0322\n",
      "Epoch 5/200, Iteration 79/250, Loss: 0.0233\n",
      "Epoch 5/200, Iteration 80/250, Loss: 0.0382\n",
      "Epoch 5/200, Iteration 81/250, Loss: 0.0459\n",
      "Epoch 5/200, Iteration 82/250, Loss: 0.0266\n",
      "Epoch 5/200, Iteration 83/250, Loss: 0.0206\n",
      "Epoch 5/200, Iteration 84/250, Loss: 0.0171\n",
      "Epoch 5/200, Iteration 85/250, Loss: 0.0231\n",
      "Epoch 5/200, Iteration 86/250, Loss: 0.0335\n",
      "Epoch 5/200, Iteration 87/250, Loss: 0.0195\n",
      "Epoch 5/200, Iteration 88/250, Loss: 0.0234\n",
      "Epoch 5/200, Iteration 89/250, Loss: 0.0286\n",
      "Epoch 5/200, Iteration 90/250, Loss: 0.0303\n",
      "Epoch 5/200, Iteration 91/250, Loss: 0.0208\n",
      "Epoch 5/200, Iteration 92/250, Loss: 0.0134\n",
      "Epoch 5/200, Iteration 93/250, Loss: 0.0282\n",
      "Epoch 5/200, Iteration 94/250, Loss: 0.0232\n",
      "Epoch 5/200, Iteration 95/250, Loss: 0.0277\n",
      "Epoch 5/200, Iteration 96/250, Loss: 0.0413\n",
      "Epoch 5/200, Iteration 97/250, Loss: 0.0445\n",
      "Epoch 5/200, Iteration 98/250, Loss: 0.0300\n",
      "Epoch 5/200, Iteration 99/250, Loss: 0.0180\n",
      "Epoch 5/200, Iteration 100/250, Loss: 0.0409\n",
      "Epoch 5/200, Iteration 101/250, Loss: 0.0309\n",
      "Epoch 5/200, Iteration 102/250, Loss: 0.0350\n",
      "Epoch 5/200, Iteration 103/250, Loss: 0.0536\n",
      "Epoch 5/200, Iteration 104/250, Loss: 0.0398\n",
      "Epoch 5/200, Iteration 105/250, Loss: 0.0287\n",
      "Epoch 5/200, Iteration 106/250, Loss: 0.0277\n",
      "Epoch 5/200, Iteration 107/250, Loss: 0.0413\n",
      "Epoch 5/200, Iteration 108/250, Loss: 0.0487\n",
      "Epoch 5/200, Iteration 109/250, Loss: 0.0368\n",
      "Epoch 5/200, Iteration 110/250, Loss: 0.0299\n",
      "Epoch 5/200, Iteration 111/250, Loss: 0.0514\n",
      "Epoch 5/200, Iteration 112/250, Loss: 0.0437\n",
      "Epoch 5/200, Iteration 113/250, Loss: 0.0269\n",
      "Epoch 5/200, Iteration 114/250, Loss: 0.0355\n",
      "Epoch 5/200, Iteration 115/250, Loss: 0.0512\n",
      "Epoch 5/200, Iteration 116/250, Loss: 0.0288\n",
      "Epoch 5/200, Iteration 117/250, Loss: 0.0258\n",
      "Epoch 5/200, Iteration 118/250, Loss: 0.0518\n",
      "Epoch 5/200, Iteration 119/250, Loss: 0.0353\n",
      "Epoch 5/200, Iteration 120/250, Loss: 0.0263\n",
      "Epoch 5/200, Iteration 121/250, Loss: 0.0197\n",
      "Epoch 5/200, Iteration 122/250, Loss: 0.0244\n",
      "Epoch 5/200, Iteration 123/250, Loss: 0.0384\n",
      "Epoch 5/200, Iteration 124/250, Loss: 0.0353\n",
      "Epoch 5/200, Iteration 125/250, Loss: 0.0375\n",
      "Epoch 5/200, Iteration 126/250, Loss: 0.0364\n",
      "Epoch 5/200, Iteration 127/250, Loss: 0.0341\n",
      "Epoch 5/200, Iteration 128/250, Loss: 0.0368\n",
      "Epoch 5/200, Iteration 129/250, Loss: 0.0596\n",
      "Epoch 5/200, Iteration 130/250, Loss: 0.0296\n",
      "Epoch 5/200, Iteration 131/250, Loss: 0.0343\n",
      "Epoch 5/200, Iteration 132/250, Loss: 0.0458\n",
      "Epoch 5/200, Iteration 133/250, Loss: 0.0926\n",
      "Epoch 5/200, Iteration 134/250, Loss: 0.0229\n",
      "Epoch 5/200, Iteration 135/250, Loss: 0.0441\n",
      "Epoch 5/200, Iteration 136/250, Loss: 0.0189\n",
      "Epoch 5/200, Iteration 137/250, Loss: 0.0300\n",
      "Epoch 5/200, Iteration 138/250, Loss: 0.0305\n",
      "Epoch 5/200, Iteration 139/250, Loss: 0.0266\n",
      "Epoch 5/200, Iteration 140/250, Loss: 0.0182\n",
      "Epoch 5/200, Iteration 141/250, Loss: 0.0241\n",
      "Epoch 5/200, Iteration 142/250, Loss: 0.0205\n",
      "Epoch 5/200, Iteration 143/250, Loss: 0.0254\n",
      "Epoch 5/200, Iteration 144/250, Loss: 0.0333\n",
      "Epoch 5/200, Iteration 145/250, Loss: 0.0218\n",
      "Epoch 5/200, Iteration 146/250, Loss: 0.0472\n",
      "Epoch 5/200, Iteration 147/250, Loss: 0.0338\n",
      "Epoch 5/200, Iteration 148/250, Loss: 0.0267\n",
      "Epoch 5/200, Iteration 149/250, Loss: 0.0155\n",
      "Epoch 5/200, Iteration 150/250, Loss: 0.0348\n",
      "Epoch 5/200, Iteration 151/250, Loss: 0.0435\n",
      "Epoch 5/200, Iteration 152/250, Loss: 0.0384\n",
      "Epoch 5/200, Iteration 153/250, Loss: 0.0139\n",
      "Epoch 5/200, Iteration 154/250, Loss: 0.0283\n",
      "Epoch 5/200, Iteration 155/250, Loss: 0.0212\n",
      "Epoch 5/200, Iteration 156/250, Loss: 0.0555\n",
      "Epoch 5/200, Iteration 157/250, Loss: 0.0206\n",
      "Epoch 5/200, Iteration 158/250, Loss: 0.0167\n",
      "Epoch 5/200, Iteration 159/250, Loss: 0.0352\n",
      "Epoch 5/200, Iteration 160/250, Loss: 0.0195\n",
      "Epoch 5/200, Iteration 161/250, Loss: 0.0359\n",
      "Epoch 5/200, Iteration 162/250, Loss: 0.0285\n",
      "Epoch 5/200, Iteration 163/250, Loss: 0.0323\n",
      "Epoch 5/200, Iteration 164/250, Loss: 0.0303\n",
      "Epoch 5/200, Iteration 165/250, Loss: 0.0274\n",
      "Epoch 5/200, Iteration 166/250, Loss: 0.0146\n",
      "Epoch 5/200, Iteration 167/250, Loss: 0.0485\n",
      "Epoch 5/200, Iteration 168/250, Loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Iteration 169/250, Loss: 0.0443\n",
      "Epoch 5/200, Iteration 170/250, Loss: 0.0365\n",
      "Epoch 5/200, Iteration 171/250, Loss: 0.0209\n",
      "Epoch 5/200, Iteration 172/250, Loss: 0.0341\n",
      "Epoch 5/200, Iteration 173/250, Loss: 0.0368\n",
      "Epoch 5/200, Iteration 174/250, Loss: 0.0466\n",
      "Epoch 5/200, Iteration 175/250, Loss: 0.0236\n",
      "Epoch 5/200, Iteration 176/250, Loss: 0.0241\n",
      "Epoch 5/200, Iteration 177/250, Loss: 0.0228\n",
      "Epoch 5/200, Iteration 178/250, Loss: 0.0272\n",
      "Epoch 5/200, Iteration 179/250, Loss: 0.0398\n",
      "Epoch 5/200, Iteration 180/250, Loss: 0.0215\n",
      "Epoch 5/200, Iteration 181/250, Loss: 0.0319\n",
      "Epoch 5/200, Iteration 182/250, Loss: 0.0401\n",
      "Epoch 5/200, Iteration 183/250, Loss: 0.0188\n",
      "Epoch 5/200, Iteration 184/250, Loss: 0.0207\n",
      "Epoch 5/200, Iteration 185/250, Loss: 0.0140\n",
      "Epoch 5/200, Iteration 186/250, Loss: 0.0240\n",
      "Epoch 5/200, Iteration 187/250, Loss: 0.0199\n",
      "Epoch 5/200, Iteration 188/250, Loss: 0.0248\n",
      "Epoch 5/200, Iteration 189/250, Loss: 0.0456\n",
      "Epoch 5/200, Iteration 190/250, Loss: 0.0339\n",
      "Epoch 5/200, Iteration 191/250, Loss: 0.0184\n",
      "Epoch 5/200, Iteration 192/250, Loss: 0.0251\n",
      "Epoch 5/200, Iteration 193/250, Loss: 0.0258\n",
      "Epoch 5/200, Iteration 194/250, Loss: 0.0297\n",
      "Epoch 5/200, Iteration 195/250, Loss: 0.0201\n",
      "Epoch 5/200, Iteration 196/250, Loss: 0.0218\n",
      "Epoch 5/200, Iteration 197/250, Loss: 0.0218\n",
      "Epoch 5/200, Iteration 198/250, Loss: 0.0233\n",
      "Epoch 5/200, Iteration 199/250, Loss: 0.0330\n",
      "Epoch 5/200, Iteration 200/250, Loss: 0.0357\n",
      "Epoch 5/200, Iteration 201/250, Loss: 0.0186\n",
      "Epoch 5/200, Iteration 202/250, Loss: 0.0336\n",
      "Epoch 5/200, Iteration 203/250, Loss: 0.0197\n",
      "Epoch 5/200, Iteration 204/250, Loss: 0.0200\n",
      "Epoch 5/200, Iteration 205/250, Loss: 0.0151\n",
      "Epoch 5/200, Iteration 206/250, Loss: 0.0167\n",
      "Epoch 5/200, Iteration 207/250, Loss: 0.0213\n",
      "Epoch 5/200, Iteration 208/250, Loss: 0.0165\n",
      "Epoch 5/200, Iteration 209/250, Loss: 0.0361\n",
      "Epoch 5/200, Iteration 210/250, Loss: 0.0363\n",
      "Epoch 5/200, Iteration 211/250, Loss: 0.0164\n",
      "Epoch 5/200, Iteration 212/250, Loss: 0.0319\n",
      "Epoch 5/200, Iteration 213/250, Loss: 0.0351\n",
      "Epoch 5/200, Iteration 214/250, Loss: 0.0693\n",
      "Epoch 5/200, Iteration 215/250, Loss: 0.0494\n",
      "Epoch 5/200, Iteration 216/250, Loss: 0.0228\n",
      "Epoch 5/200, Iteration 217/250, Loss: 0.0527\n",
      "Epoch 5/200, Iteration 218/250, Loss: 0.0237\n",
      "Epoch 5/200, Iteration 219/250, Loss: 0.0266\n",
      "Epoch 5/200, Iteration 220/250, Loss: 0.0430\n",
      "Epoch 5/200, Iteration 221/250, Loss: 0.0254\n",
      "Epoch 5/200, Iteration 222/250, Loss: 0.0325\n",
      "Epoch 5/200, Iteration 223/250, Loss: 0.0217\n",
      "Epoch 5/200, Iteration 224/250, Loss: 0.0130\n",
      "Epoch 5/200, Iteration 225/250, Loss: 0.0140\n",
      "Epoch 5/200, Iteration 226/250, Loss: 0.0160\n",
      "Epoch 5/200, Iteration 227/250, Loss: 0.0219\n",
      "Epoch 5/200, Iteration 228/250, Loss: 0.0146\n",
      "Epoch 5/200, Iteration 229/250, Loss: 0.0172\n",
      "Epoch 5/200, Iteration 230/250, Loss: 0.0273\n",
      "Epoch 5/200, Iteration 231/250, Loss: 0.0115\n",
      "Epoch 5/200, Iteration 232/250, Loss: 0.0193\n",
      "Epoch 5/200, Iteration 233/250, Loss: 0.0216\n",
      "Epoch 5/200, Iteration 234/250, Loss: 0.0238\n",
      "Epoch 5/200, Iteration 235/250, Loss: 0.0529\n",
      "Epoch 5/200, Iteration 236/250, Loss: 0.0182\n",
      "Epoch 5/200, Iteration 237/250, Loss: 0.0391\n",
      "Epoch 5/200, Iteration 238/250, Loss: 0.0173\n",
      "Epoch 5/200, Iteration 239/250, Loss: 0.0160\n",
      "Epoch 5/200, Iteration 240/250, Loss: 0.0305\n",
      "Epoch 5/200, Iteration 241/250, Loss: 0.0189\n",
      "Epoch 5/200, Iteration 242/250, Loss: 0.0273\n",
      "Epoch 5/200, Iteration 243/250, Loss: 0.0237\n",
      "Epoch 5/200, Iteration 244/250, Loss: 0.0277\n",
      "Epoch 5/200, Iteration 245/250, Loss: 0.0232\n",
      "Epoch 5/200, Iteration 246/250, Loss: 0.0147\n",
      "Epoch 5/200, Iteration 247/250, Loss: 0.0130\n",
      "Epoch 5/200, Iteration 248/250, Loss: 0.0361\n",
      "Epoch 5/200, Iteration 249/250, Loss: 0.0290\n",
      "Epoch 5/200, Iteration 250/250, Loss: 0.0260\n",
      "Train Error: \n",
      " Accuracy: 59.14%, Avg loss: 0.016861, MRE: 0.959693 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.017321, MRE: 1.301537 \n",
      "\n",
      "Epoch 6/200, Iteration 1/250, Loss: 0.0221\n",
      "Epoch 6/200, Iteration 2/250, Loss: 0.0302\n",
      "Epoch 6/200, Iteration 3/250, Loss: 0.0259\n",
      "Epoch 6/200, Iteration 4/250, Loss: 0.0158\n",
      "Epoch 6/200, Iteration 5/250, Loss: 0.0262\n",
      "Epoch 6/200, Iteration 6/250, Loss: 0.0222\n",
      "Epoch 6/200, Iteration 7/250, Loss: 0.0247\n",
      "Epoch 6/200, Iteration 8/250, Loss: 0.0309\n",
      "Epoch 6/200, Iteration 9/250, Loss: 0.0272\n",
      "Epoch 6/200, Iteration 10/250, Loss: 0.0148\n",
      "Epoch 6/200, Iteration 11/250, Loss: 0.0277\n",
      "Epoch 6/200, Iteration 12/250, Loss: 0.0201\n",
      "Epoch 6/200, Iteration 13/250, Loss: 0.0289\n",
      "Epoch 6/200, Iteration 14/250, Loss: 0.0156\n",
      "Epoch 6/200, Iteration 15/250, Loss: 0.0399\n",
      "Epoch 6/200, Iteration 16/250, Loss: 0.0177\n",
      "Epoch 6/200, Iteration 17/250, Loss: 0.0256\n",
      "Epoch 6/200, Iteration 18/250, Loss: 0.0204\n",
      "Epoch 6/200, Iteration 19/250, Loss: 0.0210\n",
      "Epoch 6/200, Iteration 20/250, Loss: 0.0178\n",
      "Epoch 6/200, Iteration 21/250, Loss: 0.0351\n",
      "Epoch 6/200, Iteration 22/250, Loss: 0.0272\n",
      "Epoch 6/200, Iteration 23/250, Loss: 0.0142\n",
      "Epoch 6/200, Iteration 24/250, Loss: 0.0221\n",
      "Epoch 6/200, Iteration 25/250, Loss: 0.0217\n",
      "Epoch 6/200, Iteration 26/250, Loss: 0.0151\n",
      "Epoch 6/200, Iteration 27/250, Loss: 0.0229\n",
      "Epoch 6/200, Iteration 28/250, Loss: 0.0290\n",
      "Epoch 6/200, Iteration 29/250, Loss: 0.0145\n",
      "Epoch 6/200, Iteration 30/250, Loss: 0.0179\n",
      "Epoch 6/200, Iteration 31/250, Loss: 0.0257\n",
      "Epoch 6/200, Iteration 32/250, Loss: 0.0201\n",
      "Epoch 6/200, Iteration 33/250, Loss: 0.0284\n",
      "Epoch 6/200, Iteration 34/250, Loss: 0.0144\n",
      "Epoch 6/200, Iteration 35/250, Loss: 0.0282\n",
      "Epoch 6/200, Iteration 36/250, Loss: 0.0398\n",
      "Epoch 6/200, Iteration 37/250, Loss: 0.0149\n",
      "Epoch 6/200, Iteration 38/250, Loss: 0.0124\n",
      "Epoch 6/200, Iteration 39/250, Loss: 0.0421\n",
      "Epoch 6/200, Iteration 40/250, Loss: 0.0306\n",
      "Epoch 6/200, Iteration 41/250, Loss: 0.0254\n",
      "Epoch 6/200, Iteration 42/250, Loss: 0.0423\n",
      "Epoch 6/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 6/200, Iteration 44/250, Loss: 0.0167\n",
      "Epoch 6/200, Iteration 45/250, Loss: 0.0229\n",
      "Epoch 6/200, Iteration 46/250, Loss: 0.0168\n",
      "Epoch 6/200, Iteration 47/250, Loss: 0.0260\n",
      "Epoch 6/200, Iteration 48/250, Loss: 0.0317\n",
      "Epoch 6/200, Iteration 49/250, Loss: 0.0129\n",
      "Epoch 6/200, Iteration 50/250, Loss: 0.0206\n",
      "Epoch 6/200, Iteration 51/250, Loss: 0.0377\n",
      "Epoch 6/200, Iteration 52/250, Loss: 0.0173\n",
      "Epoch 6/200, Iteration 53/250, Loss: 0.0243\n",
      "Epoch 6/200, Iteration 54/250, Loss: 0.0228\n",
      "Epoch 6/200, Iteration 55/250, Loss: 0.0348\n",
      "Epoch 6/200, Iteration 56/250, Loss: 0.0443\n",
      "Epoch 6/200, Iteration 57/250, Loss: 0.0398\n",
      "Epoch 6/200, Iteration 58/250, Loss: 0.0342\n",
      "Epoch 6/200, Iteration 59/250, Loss: 0.0158\n",
      "Epoch 6/200, Iteration 60/250, Loss: 0.0247\n",
      "Epoch 6/200, Iteration 61/250, Loss: 0.0532\n",
      "Epoch 6/200, Iteration 62/250, Loss: 0.0268\n",
      "Epoch 6/200, Iteration 63/250, Loss: 0.0449\n",
      "Epoch 6/200, Iteration 64/250, Loss: 0.0257\n",
      "Epoch 6/200, Iteration 65/250, Loss: 0.0372\n",
      "Epoch 6/200, Iteration 66/250, Loss: 0.0223\n",
      "Epoch 6/200, Iteration 67/250, Loss: 0.0218\n",
      "Epoch 6/200, Iteration 68/250, Loss: 0.0506\n",
      "Epoch 6/200, Iteration 69/250, Loss: 0.0582\n",
      "Epoch 6/200, Iteration 70/250, Loss: 0.0413\n",
      "Epoch 6/200, Iteration 71/250, Loss: 0.0341\n",
      "Epoch 6/200, Iteration 72/250, Loss: 0.0276\n",
      "Epoch 6/200, Iteration 73/250, Loss: 0.0141\n",
      "Epoch 6/200, Iteration 74/250, Loss: 0.0477\n",
      "Epoch 6/200, Iteration 75/250, Loss: 0.0271\n",
      "Epoch 6/200, Iteration 76/250, Loss: 0.0624\n",
      "Epoch 6/200, Iteration 77/250, Loss: 0.0324\n",
      "Epoch 6/200, Iteration 78/250, Loss: 0.0284\n",
      "Epoch 6/200, Iteration 79/250, Loss: 0.0163\n",
      "Epoch 6/200, Iteration 80/250, Loss: 0.0516\n",
      "Epoch 6/200, Iteration 81/250, Loss: 0.0280\n",
      "Epoch 6/200, Iteration 82/250, Loss: 0.0251\n",
      "Epoch 6/200, Iteration 83/250, Loss: 0.0322\n",
      "Epoch 6/200, Iteration 84/250, Loss: 0.0210\n",
      "Epoch 6/200, Iteration 85/250, Loss: 0.0220\n",
      "Epoch 6/200, Iteration 86/250, Loss: 0.0194\n",
      "Epoch 6/200, Iteration 87/250, Loss: 0.0238\n",
      "Epoch 6/200, Iteration 88/250, Loss: 0.0223\n",
      "Epoch 6/200, Iteration 89/250, Loss: 0.0229\n",
      "Epoch 6/200, Iteration 90/250, Loss: 0.0232\n",
      "Epoch 6/200, Iteration 91/250, Loss: 0.0175\n",
      "Epoch 6/200, Iteration 92/250, Loss: 0.0198\n",
      "Epoch 6/200, Iteration 93/250, Loss: 0.0192\n",
      "Epoch 6/200, Iteration 94/250, Loss: 0.0169\n",
      "Epoch 6/200, Iteration 95/250, Loss: 0.0202\n",
      "Epoch 6/200, Iteration 96/250, Loss: 0.0260\n",
      "Epoch 6/200, Iteration 97/250, Loss: 0.0182\n",
      "Epoch 6/200, Iteration 98/250, Loss: 0.0265\n",
      "Epoch 6/200, Iteration 99/250, Loss: 0.0215\n",
      "Epoch 6/200, Iteration 100/250, Loss: 0.0261\n",
      "Epoch 6/200, Iteration 101/250, Loss: 0.0494\n",
      "Epoch 6/200, Iteration 102/250, Loss: 0.0376\n",
      "Epoch 6/200, Iteration 103/250, Loss: 0.0382\n",
      "Epoch 6/200, Iteration 104/250, Loss: 0.0336\n",
      "Epoch 6/200, Iteration 105/250, Loss: 0.0352\n",
      "Epoch 6/200, Iteration 106/250, Loss: 0.0322\n",
      "Epoch 6/200, Iteration 107/250, Loss: 0.0280\n",
      "Epoch 6/200, Iteration 108/250, Loss: 0.0341\n",
      "Epoch 6/200, Iteration 109/250, Loss: 0.0291\n",
      "Epoch 6/200, Iteration 110/250, Loss: 0.0231\n",
      "Epoch 6/200, Iteration 111/250, Loss: 0.0270\n",
      "Epoch 6/200, Iteration 112/250, Loss: 0.0286\n",
      "Epoch 6/200, Iteration 113/250, Loss: 0.0262\n",
      "Epoch 6/200, Iteration 114/250, Loss: 0.0485\n",
      "Epoch 6/200, Iteration 115/250, Loss: 0.0330\n",
      "Epoch 6/200, Iteration 116/250, Loss: 0.0249\n",
      "Epoch 6/200, Iteration 117/250, Loss: 0.0220\n",
      "Epoch 6/200, Iteration 118/250, Loss: 0.0238\n",
      "Epoch 6/200, Iteration 119/250, Loss: 0.0270\n",
      "Epoch 6/200, Iteration 120/250, Loss: 0.0236\n",
      "Epoch 6/200, Iteration 121/250, Loss: 0.0158\n",
      "Epoch 6/200, Iteration 122/250, Loss: 0.0259\n",
      "Epoch 6/200, Iteration 123/250, Loss: 0.0229\n",
      "Epoch 6/200, Iteration 124/250, Loss: 0.0612\n",
      "Epoch 6/200, Iteration 125/250, Loss: 0.0145\n",
      "Epoch 6/200, Iteration 126/250, Loss: 0.0269\n",
      "Epoch 6/200, Iteration 127/250, Loss: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Iteration 128/250, Loss: 0.0171\n",
      "Epoch 6/200, Iteration 129/250, Loss: 0.0203\n",
      "Epoch 6/200, Iteration 130/250, Loss: 0.0275\n",
      "Epoch 6/200, Iteration 131/250, Loss: 0.0323\n",
      "Epoch 6/200, Iteration 132/250, Loss: 0.0141\n",
      "Epoch 6/200, Iteration 133/250, Loss: 0.0296\n",
      "Epoch 6/200, Iteration 134/250, Loss: 0.0140\n",
      "Epoch 6/200, Iteration 135/250, Loss: 0.0183\n",
      "Epoch 6/200, Iteration 136/250, Loss: 0.0124\n",
      "Epoch 6/200, Iteration 137/250, Loss: 0.0142\n",
      "Epoch 6/200, Iteration 138/250, Loss: 0.0342\n",
      "Epoch 6/200, Iteration 139/250, Loss: 0.0525\n",
      "Epoch 6/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 6/200, Iteration 141/250, Loss: 0.0421\n",
      "Epoch 6/200, Iteration 142/250, Loss: 0.0277\n",
      "Epoch 6/200, Iteration 143/250, Loss: 0.0143\n",
      "Epoch 6/200, Iteration 144/250, Loss: 0.0201\n",
      "Epoch 6/200, Iteration 145/250, Loss: 0.0442\n",
      "Epoch 6/200, Iteration 146/250, Loss: 0.0521\n",
      "Epoch 6/200, Iteration 147/250, Loss: 0.0326\n",
      "Epoch 6/200, Iteration 148/250, Loss: 0.0210\n",
      "Epoch 6/200, Iteration 149/250, Loss: 0.0359\n",
      "Epoch 6/200, Iteration 150/250, Loss: 0.0115\n",
      "Epoch 6/200, Iteration 151/250, Loss: 0.0206\n",
      "Epoch 6/200, Iteration 152/250, Loss: 0.0203\n",
      "Epoch 6/200, Iteration 153/250, Loss: 0.0161\n",
      "Epoch 6/200, Iteration 154/250, Loss: 0.0298\n",
      "Epoch 6/200, Iteration 155/250, Loss: 0.0244\n",
      "Epoch 6/200, Iteration 156/250, Loss: 0.0372\n",
      "Epoch 6/200, Iteration 157/250, Loss: 0.0539\n",
      "Epoch 6/200, Iteration 158/250, Loss: 0.0381\n",
      "Epoch 6/200, Iteration 159/250, Loss: 0.0158\n",
      "Epoch 6/200, Iteration 160/250, Loss: 0.0341\n",
      "Epoch 6/200, Iteration 161/250, Loss: 0.0193\n",
      "Epoch 6/200, Iteration 162/250, Loss: 0.0180\n",
      "Epoch 6/200, Iteration 163/250, Loss: 0.0163\n",
      "Epoch 6/200, Iteration 164/250, Loss: 0.0148\n",
      "Epoch 6/200, Iteration 165/250, Loss: 0.0263\n",
      "Epoch 6/200, Iteration 166/250, Loss: 0.0262\n",
      "Epoch 6/200, Iteration 167/250, Loss: 0.0215\n",
      "Epoch 6/200, Iteration 168/250, Loss: 0.0225\n",
      "Epoch 6/200, Iteration 169/250, Loss: 0.0445\n",
      "Epoch 6/200, Iteration 170/250, Loss: 0.0342\n",
      "Epoch 6/200, Iteration 171/250, Loss: 0.0136\n",
      "Epoch 6/200, Iteration 172/250, Loss: 0.0420\n",
      "Epoch 6/200, Iteration 173/250, Loss: 0.0246\n",
      "Epoch 6/200, Iteration 174/250, Loss: 0.0436\n",
      "Epoch 6/200, Iteration 175/250, Loss: 0.0362\n",
      "Epoch 6/200, Iteration 176/250, Loss: 0.0311\n",
      "Epoch 6/200, Iteration 177/250, Loss: 0.0166\n",
      "Epoch 6/200, Iteration 178/250, Loss: 0.0386\n",
      "Epoch 6/200, Iteration 179/250, Loss: 0.0370\n",
      "Epoch 6/200, Iteration 180/250, Loss: 0.0365\n",
      "Epoch 6/200, Iteration 181/250, Loss: 0.0274\n",
      "Epoch 6/200, Iteration 182/250, Loss: 0.0385\n",
      "Epoch 6/200, Iteration 183/250, Loss: 0.0118\n",
      "Epoch 6/200, Iteration 184/250, Loss: 0.0124\n",
      "Epoch 6/200, Iteration 185/250, Loss: 0.0192\n",
      "Epoch 6/200, Iteration 186/250, Loss: 0.0213\n",
      "Epoch 6/200, Iteration 187/250, Loss: 0.0228\n",
      "Epoch 6/200, Iteration 188/250, Loss: 0.0287\n",
      "Epoch 6/200, Iteration 189/250, Loss: 0.0292\n",
      "Epoch 6/200, Iteration 190/250, Loss: 0.0224\n",
      "Epoch 6/200, Iteration 191/250, Loss: 0.0413\n",
      "Epoch 6/200, Iteration 192/250, Loss: 0.0129\n",
      "Epoch 6/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 6/200, Iteration 194/250, Loss: 0.0410\n",
      "Epoch 6/200, Iteration 195/250, Loss: 0.0202\n",
      "Epoch 6/200, Iteration 196/250, Loss: 0.0220\n",
      "Epoch 6/200, Iteration 197/250, Loss: 0.0139\n",
      "Epoch 6/200, Iteration 198/250, Loss: 0.0326\n",
      "Epoch 6/200, Iteration 199/250, Loss: 0.0281\n",
      "Epoch 6/200, Iteration 200/250, Loss: 0.0252\n",
      "Epoch 6/200, Iteration 201/250, Loss: 0.0327\n",
      "Epoch 6/200, Iteration 202/250, Loss: 0.0233\n",
      "Epoch 6/200, Iteration 203/250, Loss: 0.0241\n",
      "Epoch 6/200, Iteration 204/250, Loss: 0.0143\n",
      "Epoch 6/200, Iteration 205/250, Loss: 0.0271\n",
      "Epoch 6/200, Iteration 206/250, Loss: 0.0281\n",
      "Epoch 6/200, Iteration 207/250, Loss: 0.0199\n",
      "Epoch 6/200, Iteration 208/250, Loss: 0.0175\n",
      "Epoch 6/200, Iteration 209/250, Loss: 0.0318\n",
      "Epoch 6/200, Iteration 210/250, Loss: 0.0273\n",
      "Epoch 6/200, Iteration 211/250, Loss: 0.0137\n",
      "Epoch 6/200, Iteration 212/250, Loss: 0.0116\n",
      "Epoch 6/200, Iteration 213/250, Loss: 0.0383\n",
      "Epoch 6/200, Iteration 214/250, Loss: 0.0169\n",
      "Epoch 6/200, Iteration 215/250, Loss: 0.0198\n",
      "Epoch 6/200, Iteration 216/250, Loss: 0.0536\n",
      "Epoch 6/200, Iteration 217/250, Loss: 0.0302\n",
      "Epoch 6/200, Iteration 218/250, Loss: 0.0369\n",
      "Epoch 6/200, Iteration 219/250, Loss: 0.0135\n",
      "Epoch 6/200, Iteration 220/250, Loss: 0.0191\n",
      "Epoch 6/200, Iteration 221/250, Loss: 0.0387\n",
      "Epoch 6/200, Iteration 222/250, Loss: 0.0442\n",
      "Epoch 6/200, Iteration 223/250, Loss: 0.0367\n",
      "Epoch 6/200, Iteration 224/250, Loss: 0.0412\n",
      "Epoch 6/200, Iteration 225/250, Loss: 0.0359\n",
      "Epoch 6/200, Iteration 226/250, Loss: 0.0262\n",
      "Epoch 6/200, Iteration 227/250, Loss: 0.0142\n",
      "Epoch 6/200, Iteration 228/250, Loss: 0.0138\n",
      "Epoch 6/200, Iteration 229/250, Loss: 0.0387\n",
      "Epoch 6/200, Iteration 230/250, Loss: 0.0345\n",
      "Epoch 6/200, Iteration 231/250, Loss: 0.0279\n",
      "Epoch 6/200, Iteration 232/250, Loss: 0.0269\n",
      "Epoch 6/200, Iteration 233/250, Loss: 0.0220\n",
      "Epoch 6/200, Iteration 234/250, Loss: 0.0276\n",
      "Epoch 6/200, Iteration 235/250, Loss: 0.0268\n",
      "Epoch 6/200, Iteration 236/250, Loss: 0.0192\n",
      "Epoch 6/200, Iteration 237/250, Loss: 0.0161\n",
      "Epoch 6/200, Iteration 238/250, Loss: 0.0355\n",
      "Epoch 6/200, Iteration 239/250, Loss: 0.0210\n",
      "Epoch 6/200, Iteration 240/250, Loss: 0.0191\n",
      "Epoch 6/200, Iteration 241/250, Loss: 0.0264\n",
      "Epoch 6/200, Iteration 242/250, Loss: 0.0262\n",
      "Epoch 6/200, Iteration 243/250, Loss: 0.0341\n",
      "Epoch 6/200, Iteration 244/250, Loss: 0.0181\n",
      "Epoch 6/200, Iteration 245/250, Loss: 0.0252\n",
      "Epoch 6/200, Iteration 246/250, Loss: 0.0273\n",
      "Epoch 6/200, Iteration 247/250, Loss: 0.0224\n",
      "Epoch 6/200, Iteration 248/250, Loss: 0.0474\n",
      "Epoch 6/200, Iteration 249/250, Loss: 0.0250\n",
      "Epoch 6/200, Iteration 250/250, Loss: 0.0274\n",
      "Train Error: \n",
      " Accuracy: 90.06%, Avg loss: 0.018805, MRE: 1.003358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.018850, MRE: 2.045150 \n",
      "\n",
      "Epoch 7/200, Iteration 1/250, Loss: 0.0361\n",
      "Epoch 7/200, Iteration 2/250, Loss: 0.0186\n",
      "Epoch 7/200, Iteration 3/250, Loss: 0.0137\n",
      "Epoch 7/200, Iteration 4/250, Loss: 0.0239\n",
      "Epoch 7/200, Iteration 5/250, Loss: 0.0155\n",
      "Epoch 7/200, Iteration 6/250, Loss: 0.0197\n",
      "Epoch 7/200, Iteration 7/250, Loss: 0.0656\n",
      "Epoch 7/200, Iteration 8/250, Loss: 0.0188\n",
      "Epoch 7/200, Iteration 9/250, Loss: 0.0158\n",
      "Epoch 7/200, Iteration 10/250, Loss: 0.0236\n",
      "Epoch 7/200, Iteration 11/250, Loss: 0.0174\n",
      "Epoch 7/200, Iteration 12/250, Loss: 0.0164\n",
      "Epoch 7/200, Iteration 13/250, Loss: 0.0214\n",
      "Epoch 7/200, Iteration 14/250, Loss: 0.0198\n",
      "Epoch 7/200, Iteration 15/250, Loss: 0.0332\n",
      "Epoch 7/200, Iteration 16/250, Loss: 0.0267\n",
      "Epoch 7/200, Iteration 17/250, Loss: 0.0237\n",
      "Epoch 7/200, Iteration 18/250, Loss: 0.0530\n",
      "Epoch 7/200, Iteration 19/250, Loss: 0.0245\n",
      "Epoch 7/200, Iteration 20/250, Loss: 0.0241\n",
      "Epoch 7/200, Iteration 21/250, Loss: 0.0254\n",
      "Epoch 7/200, Iteration 22/250, Loss: 0.0186\n",
      "Epoch 7/200, Iteration 23/250, Loss: 0.0175\n",
      "Epoch 7/200, Iteration 24/250, Loss: 0.0343\n",
      "Epoch 7/200, Iteration 25/250, Loss: 0.0369\n",
      "Epoch 7/200, Iteration 26/250, Loss: 0.0383\n",
      "Epoch 7/200, Iteration 27/250, Loss: 0.0314\n",
      "Epoch 7/200, Iteration 28/250, Loss: 0.0182\n",
      "Epoch 7/200, Iteration 29/250, Loss: 0.0217\n",
      "Epoch 7/200, Iteration 30/250, Loss: 0.0434\n",
      "Epoch 7/200, Iteration 31/250, Loss: 0.0219\n",
      "Epoch 7/200, Iteration 32/250, Loss: 0.0220\n",
      "Epoch 7/200, Iteration 33/250, Loss: 0.0311\n",
      "Epoch 7/200, Iteration 34/250, Loss: 0.0233\n",
      "Epoch 7/200, Iteration 35/250, Loss: 0.0216\n",
      "Epoch 7/200, Iteration 36/250, Loss: 0.0291\n",
      "Epoch 7/200, Iteration 37/250, Loss: 0.0353\n",
      "Epoch 7/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 7/200, Iteration 39/250, Loss: 0.0269\n",
      "Epoch 7/200, Iteration 40/250, Loss: 0.0234\n",
      "Epoch 7/200, Iteration 41/250, Loss: 0.0204\n",
      "Epoch 7/200, Iteration 42/250, Loss: 0.0228\n",
      "Epoch 7/200, Iteration 43/250, Loss: 0.0261\n",
      "Epoch 7/200, Iteration 44/250, Loss: 0.0158\n",
      "Epoch 7/200, Iteration 45/250, Loss: 0.0227\n",
      "Epoch 7/200, Iteration 46/250, Loss: 0.0246\n",
      "Epoch 7/200, Iteration 47/250, Loss: 0.0396\n",
      "Epoch 7/200, Iteration 48/250, Loss: 0.0186\n",
      "Epoch 7/200, Iteration 49/250, Loss: 0.0382\n",
      "Epoch 7/200, Iteration 50/250, Loss: 0.0249\n",
      "Epoch 7/200, Iteration 51/250, Loss: 0.0276\n",
      "Epoch 7/200, Iteration 52/250, Loss: 0.0243\n",
      "Epoch 7/200, Iteration 53/250, Loss: 0.0130\n",
      "Epoch 7/200, Iteration 54/250, Loss: 0.0345\n",
      "Epoch 7/200, Iteration 55/250, Loss: 0.0320\n",
      "Epoch 7/200, Iteration 56/250, Loss: 0.0200\n",
      "Epoch 7/200, Iteration 57/250, Loss: 0.0262\n",
      "Epoch 7/200, Iteration 58/250, Loss: 0.0239\n",
      "Epoch 7/200, Iteration 59/250, Loss: 0.0210\n",
      "Epoch 7/200, Iteration 60/250, Loss: 0.0460\n",
      "Epoch 7/200, Iteration 61/250, Loss: 0.0299\n",
      "Epoch 7/200, Iteration 62/250, Loss: 0.0272\n",
      "Epoch 7/200, Iteration 63/250, Loss: 0.0523\n",
      "Epoch 7/200, Iteration 64/250, Loss: 0.0531\n",
      "Epoch 7/200, Iteration 65/250, Loss: 0.0342\n",
      "Epoch 7/200, Iteration 66/250, Loss: 0.0178\n",
      "Epoch 7/200, Iteration 67/250, Loss: 0.0185\n",
      "Epoch 7/200, Iteration 68/250, Loss: 0.0155\n",
      "Epoch 7/200, Iteration 69/250, Loss: 0.0245\n",
      "Epoch 7/200, Iteration 70/250, Loss: 0.0198\n",
      "Epoch 7/200, Iteration 71/250, Loss: 0.0308\n",
      "Epoch 7/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 7/200, Iteration 73/250, Loss: 0.0119\n",
      "Epoch 7/200, Iteration 74/250, Loss: 0.0201\n",
      "Epoch 7/200, Iteration 75/250, Loss: 0.0357\n",
      "Epoch 7/200, Iteration 76/250, Loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Iteration 77/250, Loss: 0.0182\n",
      "Epoch 7/200, Iteration 78/250, Loss: 0.0343\n",
      "Epoch 7/200, Iteration 79/250, Loss: 0.0312\n",
      "Epoch 7/200, Iteration 80/250, Loss: 0.0279\n",
      "Epoch 7/200, Iteration 81/250, Loss: 0.0163\n",
      "Epoch 7/200, Iteration 82/250, Loss: 0.0156\n",
      "Epoch 7/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 7/200, Iteration 84/250, Loss: 0.0224\n",
      "Epoch 7/200, Iteration 85/250, Loss: 0.0147\n",
      "Epoch 7/200, Iteration 86/250, Loss: 0.0274\n",
      "Epoch 7/200, Iteration 87/250, Loss: 0.0192\n",
      "Epoch 7/200, Iteration 88/250, Loss: 0.0207\n",
      "Epoch 7/200, Iteration 89/250, Loss: 0.0179\n",
      "Epoch 7/200, Iteration 90/250, Loss: 0.0145\n",
      "Epoch 7/200, Iteration 91/250, Loss: 0.0163\n",
      "Epoch 7/200, Iteration 92/250, Loss: 0.0323\n",
      "Epoch 7/200, Iteration 93/250, Loss: 0.0236\n",
      "Epoch 7/200, Iteration 94/250, Loss: 0.0476\n",
      "Epoch 7/200, Iteration 95/250, Loss: 0.0238\n",
      "Epoch 7/200, Iteration 96/250, Loss: 0.0198\n",
      "Epoch 7/200, Iteration 97/250, Loss: 0.0147\n",
      "Epoch 7/200, Iteration 98/250, Loss: 0.0176\n",
      "Epoch 7/200, Iteration 99/250, Loss: 0.0259\n",
      "Epoch 7/200, Iteration 100/250, Loss: 0.0295\n",
      "Epoch 7/200, Iteration 101/250, Loss: 0.0140\n",
      "Epoch 7/200, Iteration 102/250, Loss: 0.0224\n",
      "Epoch 7/200, Iteration 103/250, Loss: 0.0224\n",
      "Epoch 7/200, Iteration 104/250, Loss: 0.0290\n",
      "Epoch 7/200, Iteration 105/250, Loss: 0.0124\n",
      "Epoch 7/200, Iteration 106/250, Loss: 0.0189\n",
      "Epoch 7/200, Iteration 107/250, Loss: 0.0178\n",
      "Epoch 7/200, Iteration 108/250, Loss: 0.0154\n",
      "Epoch 7/200, Iteration 109/250, Loss: 0.0257\n",
      "Epoch 7/200, Iteration 110/250, Loss: 0.0221\n",
      "Epoch 7/200, Iteration 111/250, Loss: 0.0167\n",
      "Epoch 7/200, Iteration 112/250, Loss: 0.0132\n",
      "Epoch 7/200, Iteration 113/250, Loss: 0.0334\n",
      "Epoch 7/200, Iteration 114/250, Loss: 0.0279\n",
      "Epoch 7/200, Iteration 115/250, Loss: 0.0170\n",
      "Epoch 7/200, Iteration 116/250, Loss: 0.0451\n",
      "Epoch 7/200, Iteration 117/250, Loss: 0.0305\n",
      "Epoch 7/200, Iteration 118/250, Loss: 0.0292\n",
      "Epoch 7/200, Iteration 119/250, Loss: 0.0250\n",
      "Epoch 7/200, Iteration 120/250, Loss: 0.0230\n",
      "Epoch 7/200, Iteration 121/250, Loss: 0.0197\n",
      "Epoch 7/200, Iteration 122/250, Loss: 0.0201\n",
      "Epoch 7/200, Iteration 123/250, Loss: 0.0276\n",
      "Epoch 7/200, Iteration 124/250, Loss: 0.0172\n",
      "Epoch 7/200, Iteration 125/250, Loss: 0.0175\n",
      "Epoch 7/200, Iteration 126/250, Loss: 0.0163\n",
      "Epoch 7/200, Iteration 127/250, Loss: 0.0243\n",
      "Epoch 7/200, Iteration 128/250, Loss: 0.0215\n",
      "Epoch 7/200, Iteration 129/250, Loss: 0.0203\n",
      "Epoch 7/200, Iteration 130/250, Loss: 0.0252\n",
      "Epoch 7/200, Iteration 131/250, Loss: 0.0259\n",
      "Epoch 7/200, Iteration 132/250, Loss: 0.0235\n",
      "Epoch 7/200, Iteration 133/250, Loss: 0.0257\n",
      "Epoch 7/200, Iteration 134/250, Loss: 0.0385\n",
      "Epoch 7/200, Iteration 135/250, Loss: 0.0171\n",
      "Epoch 7/200, Iteration 136/250, Loss: 0.0230\n",
      "Epoch 7/200, Iteration 137/250, Loss: 0.0183\n",
      "Epoch 7/200, Iteration 138/250, Loss: 0.0170\n",
      "Epoch 7/200, Iteration 139/250, Loss: 0.0197\n",
      "Epoch 7/200, Iteration 140/250, Loss: 0.0187\n",
      "Epoch 7/200, Iteration 141/250, Loss: 0.0163\n",
      "Epoch 7/200, Iteration 142/250, Loss: 0.0168\n",
      "Epoch 7/200, Iteration 143/250, Loss: 0.0128\n",
      "Epoch 7/200, Iteration 144/250, Loss: 0.0141\n",
      "Epoch 7/200, Iteration 145/250, Loss: 0.0157\n",
      "Epoch 7/200, Iteration 146/250, Loss: 0.0160\n",
      "Epoch 7/200, Iteration 147/250, Loss: 0.0135\n",
      "Epoch 7/200, Iteration 148/250, Loss: 0.0293\n",
      "Epoch 7/200, Iteration 149/250, Loss: 0.0263\n",
      "Epoch 7/200, Iteration 150/250, Loss: 0.0279\n",
      "Epoch 7/200, Iteration 151/250, Loss: 0.0299\n",
      "Epoch 7/200, Iteration 152/250, Loss: 0.0208\n",
      "Epoch 7/200, Iteration 153/250, Loss: 0.0332\n",
      "Epoch 7/200, Iteration 154/250, Loss: 0.0478\n",
      "Epoch 7/200, Iteration 155/250, Loss: 0.0268\n",
      "Epoch 7/200, Iteration 156/250, Loss: 0.0222\n",
      "Epoch 7/200, Iteration 157/250, Loss: 0.0148\n",
      "Epoch 7/200, Iteration 158/250, Loss: 0.0147\n",
      "Epoch 7/200, Iteration 159/250, Loss: 0.0334\n",
      "Epoch 7/200, Iteration 160/250, Loss: 0.0241\n",
      "Epoch 7/200, Iteration 161/250, Loss: 0.0282\n",
      "Epoch 7/200, Iteration 162/250, Loss: 0.0154\n",
      "Epoch 7/200, Iteration 163/250, Loss: 0.0136\n",
      "Epoch 7/200, Iteration 164/250, Loss: 0.0125\n",
      "Epoch 7/200, Iteration 165/250, Loss: 0.0173\n",
      "Epoch 7/200, Iteration 166/250, Loss: 0.0153\n",
      "Epoch 7/200, Iteration 167/250, Loss: 0.0135\n",
      "Epoch 7/200, Iteration 168/250, Loss: 0.0473\n",
      "Epoch 7/200, Iteration 169/250, Loss: 0.0586\n",
      "Epoch 7/200, Iteration 170/250, Loss: 0.0149\n",
      "Epoch 7/200, Iteration 171/250, Loss: 0.0314\n",
      "Epoch 7/200, Iteration 172/250, Loss: 0.0262\n",
      "Epoch 7/200, Iteration 173/250, Loss: 0.0155\n",
      "Epoch 7/200, Iteration 174/250, Loss: 0.0175\n",
      "Epoch 7/200, Iteration 175/250, Loss: 0.0124\n",
      "Epoch 7/200, Iteration 176/250, Loss: 0.0206\n",
      "Epoch 7/200, Iteration 177/250, Loss: 0.0216\n",
      "Epoch 7/200, Iteration 178/250, Loss: 0.0175\n",
      "Epoch 7/200, Iteration 179/250, Loss: 0.0247\n",
      "Epoch 7/200, Iteration 180/250, Loss: 0.0273\n",
      "Epoch 7/200, Iteration 181/250, Loss: 0.0290\n",
      "Epoch 7/200, Iteration 182/250, Loss: 0.0242\n",
      "Epoch 7/200, Iteration 183/250, Loss: 0.0254\n",
      "Epoch 7/200, Iteration 184/250, Loss: 0.0328\n",
      "Epoch 7/200, Iteration 185/250, Loss: 0.0158\n",
      "Epoch 7/200, Iteration 186/250, Loss: 0.0183\n",
      "Epoch 7/200, Iteration 187/250, Loss: 0.0162\n",
      "Epoch 7/200, Iteration 188/250, Loss: 0.0181\n",
      "Epoch 7/200, Iteration 189/250, Loss: 0.0159\n",
      "Epoch 7/200, Iteration 190/250, Loss: 0.0129\n",
      "Epoch 7/200, Iteration 191/250, Loss: 0.0310\n",
      "Epoch 7/200, Iteration 192/250, Loss: 0.0397\n",
      "Epoch 7/200, Iteration 193/250, Loss: 0.0357\n",
      "Epoch 7/200, Iteration 194/250, Loss: 0.0181\n",
      "Epoch 7/200, Iteration 195/250, Loss: 0.0215\n",
      "Epoch 7/200, Iteration 196/250, Loss: 0.0483\n",
      "Epoch 7/200, Iteration 197/250, Loss: 0.0189\n",
      "Epoch 7/200, Iteration 198/250, Loss: 0.0176\n",
      "Epoch 7/200, Iteration 199/250, Loss: 0.0232\n",
      "Epoch 7/200, Iteration 200/250, Loss: 0.0170\n",
      "Epoch 7/200, Iteration 201/250, Loss: 0.0294\n",
      "Epoch 7/200, Iteration 202/250, Loss: 0.0189\n",
      "Epoch 7/200, Iteration 203/250, Loss: 0.0140\n",
      "Epoch 7/200, Iteration 204/250, Loss: 0.0398\n",
      "Epoch 7/200, Iteration 205/250, Loss: 0.0428\n",
      "Epoch 7/200, Iteration 206/250, Loss: 0.0189\n",
      "Epoch 7/200, Iteration 207/250, Loss: 0.0314\n",
      "Epoch 7/200, Iteration 208/250, Loss: 0.0228\n",
      "Epoch 7/200, Iteration 209/250, Loss: 0.0203\n",
      "Epoch 7/200, Iteration 210/250, Loss: 0.0159\n",
      "Epoch 7/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 7/200, Iteration 212/250, Loss: 0.0178\n",
      "Epoch 7/200, Iteration 213/250, Loss: 0.0222\n",
      "Epoch 7/200, Iteration 214/250, Loss: 0.0218\n",
      "Epoch 7/200, Iteration 215/250, Loss: 0.0231\n",
      "Epoch 7/200, Iteration 216/250, Loss: 0.0215\n",
      "Epoch 7/200, Iteration 217/250, Loss: 0.0151\n",
      "Epoch 7/200, Iteration 218/250, Loss: 0.0342\n",
      "Epoch 7/200, Iteration 219/250, Loss: 0.0159\n",
      "Epoch 7/200, Iteration 220/250, Loss: 0.0132\n",
      "Epoch 7/200, Iteration 221/250, Loss: 0.0205\n",
      "Epoch 7/200, Iteration 222/250, Loss: 0.0232\n",
      "Epoch 7/200, Iteration 223/250, Loss: 0.0320\n",
      "Epoch 7/200, Iteration 224/250, Loss: 0.0537\n",
      "Epoch 7/200, Iteration 225/250, Loss: 0.0117\n",
      "Epoch 7/200, Iteration 226/250, Loss: 0.0208\n",
      "Epoch 7/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 7/200, Iteration 228/250, Loss: 0.0151\n",
      "Epoch 7/200, Iteration 229/250, Loss: 0.0182\n",
      "Epoch 7/200, Iteration 230/250, Loss: 0.0265\n",
      "Epoch 7/200, Iteration 231/250, Loss: 0.0263\n",
      "Epoch 7/200, Iteration 232/250, Loss: 0.0170\n",
      "Epoch 7/200, Iteration 233/250, Loss: 0.0133\n",
      "Epoch 7/200, Iteration 234/250, Loss: 0.0116\n",
      "Epoch 7/200, Iteration 235/250, Loss: 0.0149\n",
      "Epoch 7/200, Iteration 236/250, Loss: 0.0131\n",
      "Epoch 7/200, Iteration 237/250, Loss: 0.0256\n",
      "Epoch 7/200, Iteration 238/250, Loss: 0.0402\n",
      "Epoch 7/200, Iteration 239/250, Loss: 0.0198\n",
      "Epoch 7/200, Iteration 240/250, Loss: 0.0175\n",
      "Epoch 7/200, Iteration 241/250, Loss: 0.0324\n",
      "Epoch 7/200, Iteration 242/250, Loss: 0.0414\n",
      "Epoch 7/200, Iteration 243/250, Loss: 0.0296\n",
      "Epoch 7/200, Iteration 244/250, Loss: 0.0461\n",
      "Epoch 7/200, Iteration 245/250, Loss: 0.0240\n",
      "Epoch 7/200, Iteration 246/250, Loss: 0.0210\n",
      "Epoch 7/200, Iteration 247/250, Loss: 0.0177\n",
      "Epoch 7/200, Iteration 248/250, Loss: 0.0247\n",
      "Epoch 7/200, Iteration 249/250, Loss: 0.0347\n",
      "Epoch 7/200, Iteration 250/250, Loss: 0.0238\n",
      "Train Error: \n",
      " Accuracy: 92.94%, Avg loss: 0.019129, MRE: 1.381360 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.019456, MRE: 2.262657 \n",
      "\n",
      "Epoch 8/200, Iteration 1/250, Loss: 0.0443\n",
      "Epoch 8/200, Iteration 2/250, Loss: 0.0317\n",
      "Epoch 8/200, Iteration 3/250, Loss: 0.0203\n",
      "Epoch 8/200, Iteration 4/250, Loss: 0.0155\n",
      "Epoch 8/200, Iteration 5/250, Loss: 0.0177\n",
      "Epoch 8/200, Iteration 6/250, Loss: 0.0177\n",
      "Epoch 8/200, Iteration 7/250, Loss: 0.0171\n",
      "Epoch 8/200, Iteration 8/250, Loss: 0.0206\n",
      "Epoch 8/200, Iteration 9/250, Loss: 0.0220\n",
      "Epoch 8/200, Iteration 10/250, Loss: 0.0390\n",
      "Epoch 8/200, Iteration 11/250, Loss: 0.0231\n",
      "Epoch 8/200, Iteration 12/250, Loss: 0.0154\n",
      "Epoch 8/200, Iteration 13/250, Loss: 0.0188\n",
      "Epoch 8/200, Iteration 14/250, Loss: 0.0272\n",
      "Epoch 8/200, Iteration 15/250, Loss: 0.0320\n",
      "Epoch 8/200, Iteration 16/250, Loss: 0.0336\n",
      "Epoch 8/200, Iteration 17/250, Loss: 0.0149\n",
      "Epoch 8/200, Iteration 18/250, Loss: 0.0187\n",
      "Epoch 8/200, Iteration 19/250, Loss: 0.0215\n",
      "Epoch 8/200, Iteration 20/250, Loss: 0.0199\n",
      "Epoch 8/200, Iteration 21/250, Loss: 0.0430\n",
      "Epoch 8/200, Iteration 22/250, Loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 23/250, Loss: 0.0216\n",
      "Epoch 8/200, Iteration 24/250, Loss: 0.0396\n",
      "Epoch 8/200, Iteration 25/250, Loss: 0.0303\n",
      "Epoch 8/200, Iteration 26/250, Loss: 0.0170\n",
      "Epoch 8/200, Iteration 27/250, Loss: 0.0142\n",
      "Epoch 8/200, Iteration 28/250, Loss: 0.0218\n",
      "Epoch 8/200, Iteration 29/250, Loss: 0.0242\n",
      "Epoch 8/200, Iteration 30/250, Loss: 0.0210\n",
      "Epoch 8/200, Iteration 31/250, Loss: 0.0391\n",
      "Epoch 8/200, Iteration 32/250, Loss: 0.0191\n",
      "Epoch 8/200, Iteration 33/250, Loss: 0.0208\n",
      "Epoch 8/200, Iteration 34/250, Loss: 0.0182\n",
      "Epoch 8/200, Iteration 35/250, Loss: 0.0326\n",
      "Epoch 8/200, Iteration 36/250, Loss: 0.0151\n",
      "Epoch 8/200, Iteration 37/250, Loss: 0.0211\n",
      "Epoch 8/200, Iteration 38/250, Loss: 0.0261\n",
      "Epoch 8/200, Iteration 39/250, Loss: 0.0276\n",
      "Epoch 8/200, Iteration 40/250, Loss: 0.0175\n",
      "Epoch 8/200, Iteration 41/250, Loss: 0.0262\n",
      "Epoch 8/200, Iteration 42/250, Loss: 0.0241\n",
      "Epoch 8/200, Iteration 43/250, Loss: 0.0185\n",
      "Epoch 8/200, Iteration 44/250, Loss: 0.0175\n",
      "Epoch 8/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 8/200, Iteration 46/250, Loss: 0.0108\n",
      "Epoch 8/200, Iteration 47/250, Loss: 0.0158\n",
      "Epoch 8/200, Iteration 48/250, Loss: 0.0183\n",
      "Epoch 8/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 8/200, Iteration 50/250, Loss: 0.0113\n",
      "Epoch 8/200, Iteration 51/250, Loss: 0.0163\n",
      "Epoch 8/200, Iteration 52/250, Loss: 0.0258\n",
      "Epoch 8/200, Iteration 53/250, Loss: 0.0191\n",
      "Epoch 8/200, Iteration 54/250, Loss: 0.0159\n",
      "Epoch 8/200, Iteration 55/250, Loss: 0.0092\n",
      "Epoch 8/200, Iteration 56/250, Loss: 0.0116\n",
      "Epoch 8/200, Iteration 57/250, Loss: 0.0112\n",
      "Epoch 8/200, Iteration 58/250, Loss: 0.0128\n",
      "Epoch 8/200, Iteration 59/250, Loss: 0.0175\n",
      "Epoch 8/200, Iteration 60/250, Loss: 0.0150\n",
      "Epoch 8/200, Iteration 61/250, Loss: 0.0291\n",
      "Epoch 8/200, Iteration 62/250, Loss: 0.0403\n",
      "Epoch 8/200, Iteration 63/250, Loss: 0.0298\n",
      "Epoch 8/200, Iteration 64/250, Loss: 0.0170\n",
      "Epoch 8/200, Iteration 65/250, Loss: 0.0354\n",
      "Epoch 8/200, Iteration 66/250, Loss: 0.0329\n",
      "Epoch 8/200, Iteration 67/250, Loss: 0.0258\n",
      "Epoch 8/200, Iteration 68/250, Loss: 0.0229\n",
      "Epoch 8/200, Iteration 69/250, Loss: 0.0262\n",
      "Epoch 8/200, Iteration 70/250, Loss: 0.0176\n",
      "Epoch 8/200, Iteration 71/250, Loss: 0.0144\n",
      "Epoch 8/200, Iteration 72/250, Loss: 0.0371\n",
      "Epoch 8/200, Iteration 73/250, Loss: 0.0239\n",
      "Epoch 8/200, Iteration 74/250, Loss: 0.0162\n",
      "Epoch 8/200, Iteration 75/250, Loss: 0.0277\n",
      "Epoch 8/200, Iteration 76/250, Loss: 0.0133\n",
      "Epoch 8/200, Iteration 77/250, Loss: 0.0359\n",
      "Epoch 8/200, Iteration 78/250, Loss: 0.0136\n",
      "Epoch 8/200, Iteration 79/250, Loss: 0.0146\n",
      "Epoch 8/200, Iteration 80/250, Loss: 0.0188\n",
      "Epoch 8/200, Iteration 81/250, Loss: 0.0259\n",
      "Epoch 8/200, Iteration 82/250, Loss: 0.0277\n",
      "Epoch 8/200, Iteration 83/250, Loss: 0.0164\n",
      "Epoch 8/200, Iteration 84/250, Loss: 0.0217\n",
      "Epoch 8/200, Iteration 85/250, Loss: 0.0165\n",
      "Epoch 8/200, Iteration 86/250, Loss: 0.0117\n",
      "Epoch 8/200, Iteration 87/250, Loss: 0.0141\n",
      "Epoch 8/200, Iteration 88/250, Loss: 0.0320\n",
      "Epoch 8/200, Iteration 89/250, Loss: 0.0221\n",
      "Epoch 8/200, Iteration 90/250, Loss: 0.0158\n",
      "Epoch 8/200, Iteration 91/250, Loss: 0.0159\n",
      "Epoch 8/200, Iteration 92/250, Loss: 0.0187\n",
      "Epoch 8/200, Iteration 93/250, Loss: 0.0358\n",
      "Epoch 8/200, Iteration 94/250, Loss: 0.0263\n",
      "Epoch 8/200, Iteration 95/250, Loss: 0.0313\n",
      "Epoch 8/200, Iteration 96/250, Loss: 0.0303\n",
      "Epoch 8/200, Iteration 97/250, Loss: 0.0157\n",
      "Epoch 8/200, Iteration 98/250, Loss: 0.0122\n",
      "Epoch 8/200, Iteration 99/250, Loss: 0.0196\n",
      "Epoch 8/200, Iteration 100/250, Loss: 0.0122\n",
      "Epoch 8/200, Iteration 101/250, Loss: 0.0459\n",
      "Epoch 8/200, Iteration 102/250, Loss: 0.0133\n",
      "Epoch 8/200, Iteration 103/250, Loss: 0.0305\n",
      "Epoch 8/200, Iteration 104/250, Loss: 0.0145\n",
      "Epoch 8/200, Iteration 105/250, Loss: 0.0126\n",
      "Epoch 8/200, Iteration 106/250, Loss: 0.0229\n",
      "Epoch 8/200, Iteration 107/250, Loss: 0.0289\n",
      "Epoch 8/200, Iteration 108/250, Loss: 0.0193\n",
      "Epoch 8/200, Iteration 109/250, Loss: 0.0126\n",
      "Epoch 8/200, Iteration 110/250, Loss: 0.0174\n",
      "Epoch 8/200, Iteration 111/250, Loss: 0.0133\n",
      "Epoch 8/200, Iteration 112/250, Loss: 0.0095\n",
      "Epoch 8/200, Iteration 113/250, Loss: 0.0319\n",
      "Epoch 8/200, Iteration 114/250, Loss: 0.0430\n",
      "Epoch 8/200, Iteration 115/250, Loss: 0.0227\n",
      "Epoch 8/200, Iteration 116/250, Loss: 0.0262\n",
      "Epoch 8/200, Iteration 117/250, Loss: 0.0332\n",
      "Epoch 8/200, Iteration 118/250, Loss: 0.0334\n",
      "Epoch 8/200, Iteration 119/250, Loss: 0.0155\n",
      "Epoch 8/200, Iteration 120/250, Loss: 0.0348\n",
      "Epoch 8/200, Iteration 121/250, Loss: 0.0134\n",
      "Epoch 8/200, Iteration 122/250, Loss: 0.0251\n",
      "Epoch 8/200, Iteration 123/250, Loss: 0.0263\n",
      "Epoch 8/200, Iteration 124/250, Loss: 0.0335\n",
      "Epoch 8/200, Iteration 125/250, Loss: 0.0162\n",
      "Epoch 8/200, Iteration 126/250, Loss: 0.0148\n",
      "Epoch 8/200, Iteration 127/250, Loss: 0.0136\n",
      "Epoch 8/200, Iteration 128/250, Loss: 0.0148\n",
      "Epoch 8/200, Iteration 129/250, Loss: 0.0258\n",
      "Epoch 8/200, Iteration 130/250, Loss: 0.0282\n",
      "Epoch 8/200, Iteration 131/250, Loss: 0.0215\n",
      "Epoch 8/200, Iteration 132/250, Loss: 0.0176\n",
      "Epoch 8/200, Iteration 133/250, Loss: 0.0147\n",
      "Epoch 8/200, Iteration 134/250, Loss: 0.0204\n",
      "Epoch 8/200, Iteration 135/250, Loss: 0.0270\n",
      "Epoch 8/200, Iteration 136/250, Loss: 0.0196\n",
      "Epoch 8/200, Iteration 137/250, Loss: 0.0210\n",
      "Epoch 8/200, Iteration 138/250, Loss: 0.0250\n",
      "Epoch 8/200, Iteration 139/250, Loss: 0.0236\n",
      "Epoch 8/200, Iteration 140/250, Loss: 0.0251\n",
      "Epoch 8/200, Iteration 141/250, Loss: 0.0288\n",
      "Epoch 8/200, Iteration 142/250, Loss: 0.0533\n",
      "Epoch 8/200, Iteration 143/250, Loss: 0.0294\n",
      "Epoch 8/200, Iteration 144/250, Loss: 0.0227\n",
      "Epoch 8/200, Iteration 145/250, Loss: 0.0143\n",
      "Epoch 8/200, Iteration 146/250, Loss: 0.0116\n",
      "Epoch 8/200, Iteration 147/250, Loss: 0.0361\n",
      "Epoch 8/200, Iteration 148/250, Loss: 0.0253\n",
      "Epoch 8/200, Iteration 149/250, Loss: 0.0259\n",
      "Epoch 8/200, Iteration 150/250, Loss: 0.0330\n",
      "Epoch 8/200, Iteration 151/250, Loss: 0.0138\n",
      "Epoch 8/200, Iteration 152/250, Loss: 0.0100\n",
      "Epoch 8/200, Iteration 153/250, Loss: 0.0248\n",
      "Epoch 8/200, Iteration 154/250, Loss: 0.0116\n",
      "Epoch 8/200, Iteration 155/250, Loss: 0.0180\n",
      "Epoch 8/200, Iteration 156/250, Loss: 0.0181\n",
      "Epoch 8/200, Iteration 157/250, Loss: 0.0153\n",
      "Epoch 8/200, Iteration 158/250, Loss: 0.0142\n",
      "Epoch 8/200, Iteration 159/250, Loss: 0.0234\n",
      "Epoch 8/200, Iteration 160/250, Loss: 0.0312\n",
      "Epoch 8/200, Iteration 161/250, Loss: 0.0156\n",
      "Epoch 8/200, Iteration 162/250, Loss: 0.0363\n",
      "Epoch 8/200, Iteration 163/250, Loss: 0.0360\n",
      "Epoch 8/200, Iteration 164/250, Loss: 0.0327\n",
      "Epoch 8/200, Iteration 165/250, Loss: 0.0134\n",
      "Epoch 8/200, Iteration 166/250, Loss: 0.0261\n",
      "Epoch 8/200, Iteration 167/250, Loss: 0.0178\n",
      "Epoch 8/200, Iteration 168/250, Loss: 0.0159\n",
      "Epoch 8/200, Iteration 169/250, Loss: 0.0200\n",
      "Epoch 8/200, Iteration 170/250, Loss: 0.0285\n",
      "Epoch 8/200, Iteration 171/250, Loss: 0.0345\n",
      "Epoch 8/200, Iteration 172/250, Loss: 0.0274\n",
      "Epoch 8/200, Iteration 173/250, Loss: 0.0279\n",
      "Epoch 8/200, Iteration 174/250, Loss: 0.0165\n",
      "Epoch 8/200, Iteration 175/250, Loss: 0.0203\n",
      "Epoch 8/200, Iteration 176/250, Loss: 0.0401\n",
      "Epoch 8/200, Iteration 177/250, Loss: 0.0212\n",
      "Epoch 8/200, Iteration 178/250, Loss: 0.0329\n",
      "Epoch 8/200, Iteration 179/250, Loss: 0.0218\n",
      "Epoch 8/200, Iteration 180/250, Loss: 0.0318\n",
      "Epoch 8/200, Iteration 181/250, Loss: 0.0328\n",
      "Epoch 8/200, Iteration 182/250, Loss: 0.0326\n",
      "Epoch 8/200, Iteration 183/250, Loss: 0.0496\n",
      "Epoch 8/200, Iteration 184/250, Loss: 0.0362\n",
      "Epoch 8/200, Iteration 185/250, Loss: 0.0341\n",
      "Epoch 8/200, Iteration 186/250, Loss: 0.0306\n",
      "Epoch 8/200, Iteration 187/250, Loss: 0.0293\n",
      "Epoch 8/200, Iteration 188/250, Loss: 0.0210\n",
      "Epoch 8/200, Iteration 189/250, Loss: 0.0202\n",
      "Epoch 8/200, Iteration 190/250, Loss: 0.0163\n",
      "Epoch 8/200, Iteration 191/250, Loss: 0.0193\n",
      "Epoch 8/200, Iteration 192/250, Loss: 0.0327\n",
      "Epoch 8/200, Iteration 193/250, Loss: 0.0251\n",
      "Epoch 8/200, Iteration 194/250, Loss: 0.0578\n",
      "Epoch 8/200, Iteration 195/250, Loss: 0.0291\n",
      "Epoch 8/200, Iteration 196/250, Loss: 0.0252\n",
      "Epoch 8/200, Iteration 197/250, Loss: 0.0168\n",
      "Epoch 8/200, Iteration 198/250, Loss: 0.0237\n",
      "Epoch 8/200, Iteration 199/250, Loss: 0.0112\n",
      "Epoch 8/200, Iteration 200/250, Loss: 0.0274\n",
      "Epoch 8/200, Iteration 201/250, Loss: 0.0099\n",
      "Epoch 8/200, Iteration 202/250, Loss: 0.0204\n",
      "Epoch 8/200, Iteration 203/250, Loss: 0.0201\n",
      "Epoch 8/200, Iteration 204/250, Loss: 0.0446\n",
      "Epoch 8/200, Iteration 205/250, Loss: 0.0287\n",
      "Epoch 8/200, Iteration 206/250, Loss: 0.0211\n",
      "Epoch 8/200, Iteration 207/250, Loss: 0.0299\n",
      "Epoch 8/200, Iteration 208/250, Loss: 0.0140\n",
      "Epoch 8/200, Iteration 209/250, Loss: 0.0340\n",
      "Epoch 8/200, Iteration 210/250, Loss: 0.0225\n",
      "Epoch 8/200, Iteration 211/250, Loss: 0.0133\n",
      "Epoch 8/200, Iteration 212/250, Loss: 0.0162\n",
      "Epoch 8/200, Iteration 213/250, Loss: 0.0210\n",
      "Epoch 8/200, Iteration 214/250, Loss: 0.0149\n",
      "Epoch 8/200, Iteration 215/250, Loss: 0.0263\n",
      "Epoch 8/200, Iteration 216/250, Loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 217/250, Loss: 0.0146\n",
      "Epoch 8/200, Iteration 218/250, Loss: 0.0302\n",
      "Epoch 8/200, Iteration 219/250, Loss: 0.0223\n",
      "Epoch 8/200, Iteration 220/250, Loss: 0.0232\n",
      "Epoch 8/200, Iteration 221/250, Loss: 0.0261\n",
      "Epoch 8/200, Iteration 222/250, Loss: 0.0152\n",
      "Epoch 8/200, Iteration 223/250, Loss: 0.0299\n",
      "Epoch 8/200, Iteration 224/250, Loss: 0.0363\n",
      "Epoch 8/200, Iteration 225/250, Loss: 0.0142\n",
      "Epoch 8/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 8/200, Iteration 227/250, Loss: 0.0140\n",
      "Epoch 8/200, Iteration 228/250, Loss: 0.0099\n",
      "Epoch 8/200, Iteration 229/250, Loss: 0.0355\n",
      "Epoch 8/200, Iteration 230/250, Loss: 0.0181\n",
      "Epoch 8/200, Iteration 231/250, Loss: 0.0179\n",
      "Epoch 8/200, Iteration 232/250, Loss: 0.0237\n",
      "Epoch 8/200, Iteration 233/250, Loss: 0.0179\n",
      "Epoch 8/200, Iteration 234/250, Loss: 0.0424\n",
      "Epoch 8/200, Iteration 235/250, Loss: 0.0236\n",
      "Epoch 8/200, Iteration 236/250, Loss: 0.0222\n",
      "Epoch 8/200, Iteration 237/250, Loss: 0.0232\n",
      "Epoch 8/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 8/200, Iteration 239/250, Loss: 0.0272\n",
      "Epoch 8/200, Iteration 240/250, Loss: 0.0642\n",
      "Epoch 8/200, Iteration 241/250, Loss: 0.0392\n",
      "Epoch 8/200, Iteration 242/250, Loss: 0.0285\n",
      "Epoch 8/200, Iteration 243/250, Loss: 0.0271\n",
      "Epoch 8/200, Iteration 244/250, Loss: 0.0103\n",
      "Epoch 8/200, Iteration 245/250, Loss: 0.0245\n",
      "Epoch 8/200, Iteration 246/250, Loss: 0.0252\n",
      "Epoch 8/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 8/200, Iteration 248/250, Loss: 0.0171\n",
      "Epoch 8/200, Iteration 249/250, Loss: 0.0228\n",
      "Epoch 8/200, Iteration 250/250, Loss: 0.0316\n",
      "Train Error: \n",
      " Accuracy: 33.46%, Avg loss: 0.030875, MRE: 1.170375 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.031224, MRE: 1.142965 \n",
      "\n",
      "Epoch 9/200, Iteration 1/250, Loss: 0.0159\n",
      "Epoch 9/200, Iteration 2/250, Loss: 0.0338\n",
      "Epoch 9/200, Iteration 3/250, Loss: 0.0307\n",
      "Epoch 9/200, Iteration 4/250, Loss: 0.0283\n",
      "Epoch 9/200, Iteration 5/250, Loss: 0.0336\n",
      "Epoch 9/200, Iteration 6/250, Loss: 0.0202\n",
      "Epoch 9/200, Iteration 7/250, Loss: 0.0266\n",
      "Epoch 9/200, Iteration 8/250, Loss: 0.0240\n",
      "Epoch 9/200, Iteration 9/250, Loss: 0.0201\n",
      "Epoch 9/200, Iteration 10/250, Loss: 0.0155\n",
      "Epoch 9/200, Iteration 11/250, Loss: 0.0251\n",
      "Epoch 9/200, Iteration 12/250, Loss: 0.0140\n",
      "Epoch 9/200, Iteration 13/250, Loss: 0.0235\n",
      "Epoch 9/200, Iteration 14/250, Loss: 0.0206\n",
      "Epoch 9/200, Iteration 15/250, Loss: 0.0174\n",
      "Epoch 9/200, Iteration 16/250, Loss: 0.0180\n",
      "Epoch 9/200, Iteration 17/250, Loss: 0.0204\n",
      "Epoch 9/200, Iteration 18/250, Loss: 0.0156\n",
      "Epoch 9/200, Iteration 19/250, Loss: 0.0199\n",
      "Epoch 9/200, Iteration 20/250, Loss: 0.0457\n",
      "Epoch 9/200, Iteration 21/250, Loss: 0.0268\n",
      "Epoch 9/200, Iteration 22/250, Loss: 0.0210\n",
      "Epoch 9/200, Iteration 23/250, Loss: 0.0145\n",
      "Epoch 9/200, Iteration 24/250, Loss: 0.0155\n",
      "Epoch 9/200, Iteration 25/250, Loss: 0.0183\n",
      "Epoch 9/200, Iteration 26/250, Loss: 0.0219\n",
      "Epoch 9/200, Iteration 27/250, Loss: 0.0210\n",
      "Epoch 9/200, Iteration 28/250, Loss: 0.0154\n",
      "Epoch 9/200, Iteration 29/250, Loss: 0.0273\n",
      "Epoch 9/200, Iteration 30/250, Loss: 0.0162\n",
      "Epoch 9/200, Iteration 31/250, Loss: 0.0274\n",
      "Epoch 9/200, Iteration 32/250, Loss: 0.0426\n",
      "Epoch 9/200, Iteration 33/250, Loss: 0.0212\n",
      "Epoch 9/200, Iteration 34/250, Loss: 0.0178\n",
      "Epoch 9/200, Iteration 35/250, Loss: 0.0135\n",
      "Epoch 9/200, Iteration 36/250, Loss: 0.0351\n",
      "Epoch 9/200, Iteration 37/250, Loss: 0.0401\n",
      "Epoch 9/200, Iteration 38/250, Loss: 0.0501\n",
      "Epoch 9/200, Iteration 39/250, Loss: 0.0253\n",
      "Epoch 9/200, Iteration 40/250, Loss: 0.0138\n",
      "Epoch 9/200, Iteration 41/250, Loss: 0.0202\n",
      "Epoch 9/200, Iteration 42/250, Loss: 0.0317\n",
      "Epoch 9/200, Iteration 43/250, Loss: 0.0220\n",
      "Epoch 9/200, Iteration 44/250, Loss: 0.0434\n",
      "Epoch 9/200, Iteration 45/250, Loss: 0.0324\n",
      "Epoch 9/200, Iteration 46/250, Loss: 0.0148\n",
      "Epoch 9/200, Iteration 47/250, Loss: 0.0259\n",
      "Epoch 9/200, Iteration 48/250, Loss: 0.0263\n",
      "Epoch 9/200, Iteration 49/250, Loss: 0.0243\n",
      "Epoch 9/200, Iteration 50/250, Loss: 0.0377\n",
      "Epoch 9/200, Iteration 51/250, Loss: 0.0205\n",
      "Epoch 9/200, Iteration 52/250, Loss: 0.0149\n",
      "Epoch 9/200, Iteration 53/250, Loss: 0.0264\n",
      "Epoch 9/200, Iteration 54/250, Loss: 0.0138\n",
      "Epoch 9/200, Iteration 55/250, Loss: 0.0210\n",
      "Epoch 9/200, Iteration 56/250, Loss: 0.0379\n",
      "Epoch 9/200, Iteration 57/250, Loss: 0.0120\n",
      "Epoch 9/200, Iteration 58/250, Loss: 0.0137\n",
      "Epoch 9/200, Iteration 59/250, Loss: 0.0141\n",
      "Epoch 9/200, Iteration 60/250, Loss: 0.0104\n",
      "Epoch 9/200, Iteration 61/250, Loss: 0.0327\n",
      "Epoch 9/200, Iteration 62/250, Loss: 0.0119\n",
      "Epoch 9/200, Iteration 63/250, Loss: 0.0195\n",
      "Epoch 9/200, Iteration 64/250, Loss: 0.0137\n",
      "Epoch 9/200, Iteration 65/250, Loss: 0.0170\n",
      "Epoch 9/200, Iteration 66/250, Loss: 0.0460\n",
      "Epoch 9/200, Iteration 67/250, Loss: 0.0431\n",
      "Epoch 9/200, Iteration 68/250, Loss: 0.0283\n",
      "Epoch 9/200, Iteration 69/250, Loss: 0.0299\n",
      "Epoch 9/200, Iteration 70/250, Loss: 0.0229\n",
      "Epoch 9/200, Iteration 71/250, Loss: 0.0288\n",
      "Epoch 9/200, Iteration 72/250, Loss: 0.0311\n",
      "Epoch 9/200, Iteration 73/250, Loss: 0.0292\n",
      "Epoch 9/200, Iteration 74/250, Loss: 0.0341\n",
      "Epoch 9/200, Iteration 75/250, Loss: 0.0233\n",
      "Epoch 9/200, Iteration 76/250, Loss: 0.0170\n",
      "Epoch 9/200, Iteration 77/250, Loss: 0.0303\n",
      "Epoch 9/200, Iteration 78/250, Loss: 0.0257\n",
      "Epoch 9/200, Iteration 79/250, Loss: 0.0257\n",
      "Epoch 9/200, Iteration 80/250, Loss: 0.0252\n",
      "Epoch 9/200, Iteration 81/250, Loss: 0.0382\n",
      "Epoch 9/200, Iteration 82/250, Loss: 0.0163\n",
      "Epoch 9/200, Iteration 83/250, Loss: 0.0254\n",
      "Epoch 9/200, Iteration 84/250, Loss: 0.0226\n",
      "Epoch 9/200, Iteration 85/250, Loss: 0.0114\n",
      "Epoch 9/200, Iteration 86/250, Loss: 0.0159\n",
      "Epoch 9/200, Iteration 87/250, Loss: 0.0178\n",
      "Epoch 9/200, Iteration 88/250, Loss: 0.0326\n",
      "Epoch 9/200, Iteration 89/250, Loss: 0.0231\n",
      "Epoch 9/200, Iteration 90/250, Loss: 0.0232\n",
      "Epoch 9/200, Iteration 91/250, Loss: 0.0346\n",
      "Epoch 9/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 9/200, Iteration 93/250, Loss: 0.0192\n",
      "Epoch 9/200, Iteration 94/250, Loss: 0.0209\n",
      "Epoch 9/200, Iteration 95/250, Loss: 0.0194\n",
      "Epoch 9/200, Iteration 96/250, Loss: 0.0137\n",
      "Epoch 9/200, Iteration 97/250, Loss: 0.0339\n",
      "Epoch 9/200, Iteration 98/250, Loss: 0.0163\n",
      "Epoch 9/200, Iteration 99/250, Loss: 0.0122\n",
      "Epoch 9/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 9/200, Iteration 101/250, Loss: 0.0291\n",
      "Epoch 9/200, Iteration 102/250, Loss: 0.0249\n",
      "Epoch 9/200, Iteration 103/250, Loss: 0.0213\n",
      "Epoch 9/200, Iteration 104/250, Loss: 0.0206\n",
      "Epoch 9/200, Iteration 105/250, Loss: 0.0202\n",
      "Epoch 9/200, Iteration 106/250, Loss: 0.0287\n",
      "Epoch 9/200, Iteration 107/250, Loss: 0.0293\n",
      "Epoch 9/200, Iteration 108/250, Loss: 0.0143\n",
      "Epoch 9/200, Iteration 109/250, Loss: 0.0141\n",
      "Epoch 9/200, Iteration 110/250, Loss: 0.0278\n",
      "Epoch 9/200, Iteration 111/250, Loss: 0.0112\n",
      "Epoch 9/200, Iteration 112/250, Loss: 0.0142\n",
      "Epoch 9/200, Iteration 113/250, Loss: 0.0311\n",
      "Epoch 9/200, Iteration 114/250, Loss: 0.0135\n",
      "Epoch 9/200, Iteration 115/250, Loss: 0.0122\n",
      "Epoch 9/200, Iteration 116/250, Loss: 0.0148\n",
      "Epoch 9/200, Iteration 117/250, Loss: 0.0167\n",
      "Epoch 9/200, Iteration 118/250, Loss: 0.0141\n",
      "Epoch 9/200, Iteration 119/250, Loss: 0.0215\n",
      "Epoch 9/200, Iteration 120/250, Loss: 0.0294\n",
      "Epoch 9/200, Iteration 121/250, Loss: 0.0404\n",
      "Epoch 9/200, Iteration 122/250, Loss: 0.0270\n",
      "Epoch 9/200, Iteration 123/250, Loss: 0.0174\n",
      "Epoch 9/200, Iteration 124/250, Loss: 0.0267\n",
      "Epoch 9/200, Iteration 125/250, Loss: 0.0329\n",
      "Epoch 9/200, Iteration 126/250, Loss: 0.0459\n",
      "Epoch 9/200, Iteration 127/250, Loss: 0.0168\n",
      "Epoch 9/200, Iteration 128/250, Loss: 0.0222\n",
      "Epoch 9/200, Iteration 129/250, Loss: 0.0093\n",
      "Epoch 9/200, Iteration 130/250, Loss: 0.0205\n",
      "Epoch 9/200, Iteration 131/250, Loss: 0.0273\n",
      "Epoch 9/200, Iteration 132/250, Loss: 0.0185\n",
      "Epoch 9/200, Iteration 133/250, Loss: 0.0341\n",
      "Epoch 9/200, Iteration 134/250, Loss: 0.0723\n",
      "Epoch 9/200, Iteration 135/250, Loss: 0.0263\n",
      "Epoch 9/200, Iteration 136/250, Loss: 0.0208\n",
      "Epoch 9/200, Iteration 137/250, Loss: 0.0216\n",
      "Epoch 9/200, Iteration 138/250, Loss: 0.0113\n",
      "Epoch 9/200, Iteration 139/250, Loss: 0.0289\n",
      "Epoch 9/200, Iteration 140/250, Loss: 0.0429\n",
      "Epoch 9/200, Iteration 141/250, Loss: 0.0272\n",
      "Epoch 9/200, Iteration 142/250, Loss: 0.0218\n",
      "Epoch 9/200, Iteration 143/250, Loss: 0.0186\n",
      "Epoch 9/200, Iteration 144/250, Loss: 0.0235\n",
      "Epoch 9/200, Iteration 145/250, Loss: 0.0257\n",
      "Epoch 9/200, Iteration 146/250, Loss: 0.0332\n",
      "Epoch 9/200, Iteration 147/250, Loss: 0.0174\n",
      "Epoch 9/200, Iteration 148/250, Loss: 0.0120\n",
      "Epoch 9/200, Iteration 149/250, Loss: 0.0164\n",
      "Epoch 9/200, Iteration 150/250, Loss: 0.0189\n",
      "Epoch 9/200, Iteration 151/250, Loss: 0.0233\n",
      "Epoch 9/200, Iteration 152/250, Loss: 0.0116\n",
      "Epoch 9/200, Iteration 153/250, Loss: 0.0177\n",
      "Epoch 9/200, Iteration 154/250, Loss: 0.0164\n",
      "Epoch 9/200, Iteration 155/250, Loss: 0.0581\n",
      "Epoch 9/200, Iteration 156/250, Loss: 0.0143\n",
      "Epoch 9/200, Iteration 157/250, Loss: 0.0119\n",
      "Epoch 9/200, Iteration 158/250, Loss: 0.0132\n",
      "Epoch 9/200, Iteration 159/250, Loss: 0.0210\n",
      "Epoch 9/200, Iteration 160/250, Loss: 0.0213\n",
      "Epoch 9/200, Iteration 161/250, Loss: 0.0158\n",
      "Epoch 9/200, Iteration 162/250, Loss: 0.0290\n",
      "Epoch 9/200, Iteration 163/250, Loss: 0.0267\n",
      "Epoch 9/200, Iteration 164/250, Loss: 0.0291\n",
      "Epoch 9/200, Iteration 165/250, Loss: 0.0236\n",
      "Epoch 9/200, Iteration 166/250, Loss: 0.0187\n",
      "Epoch 9/200, Iteration 167/250, Loss: 0.0422\n",
      "Epoch 9/200, Iteration 168/250, Loss: 0.0233\n",
      "Epoch 9/200, Iteration 169/250, Loss: 0.0288\n",
      "Epoch 9/200, Iteration 170/250, Loss: 0.0312\n",
      "Epoch 9/200, Iteration 171/250, Loss: 0.0154\n",
      "Epoch 9/200, Iteration 172/250, Loss: 0.0231\n",
      "Epoch 9/200, Iteration 173/250, Loss: 0.0196\n",
      "Epoch 9/200, Iteration 174/250, Loss: 0.0153\n",
      "Epoch 9/200, Iteration 175/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Iteration 176/250, Loss: 0.0207\n",
      "Epoch 9/200, Iteration 177/250, Loss: 0.0198\n",
      "Epoch 9/200, Iteration 178/250, Loss: 0.0225\n",
      "Epoch 9/200, Iteration 179/250, Loss: 0.0246\n",
      "Epoch 9/200, Iteration 180/250, Loss: 0.0249\n",
      "Epoch 9/200, Iteration 181/250, Loss: 0.0344\n",
      "Epoch 9/200, Iteration 182/250, Loss: 0.0201\n",
      "Epoch 9/200, Iteration 183/250, Loss: 0.0192\n",
      "Epoch 9/200, Iteration 184/250, Loss: 0.0153\n",
      "Epoch 9/200, Iteration 185/250, Loss: 0.0183\n",
      "Epoch 9/200, Iteration 186/250, Loss: 0.0204\n",
      "Epoch 9/200, Iteration 187/250, Loss: 0.0435\n",
      "Epoch 9/200, Iteration 188/250, Loss: 0.0254\n",
      "Epoch 9/200, Iteration 189/250, Loss: 0.0178\n",
      "Epoch 9/200, Iteration 190/250, Loss: 0.0252\n",
      "Epoch 9/200, Iteration 191/250, Loss: 0.0084\n",
      "Epoch 9/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 9/200, Iteration 193/250, Loss: 0.0138\n",
      "Epoch 9/200, Iteration 194/250, Loss: 0.0331\n",
      "Epoch 9/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 9/200, Iteration 196/250, Loss: 0.0216\n",
      "Epoch 9/200, Iteration 197/250, Loss: 0.0178\n",
      "Epoch 9/200, Iteration 198/250, Loss: 0.0132\n",
      "Epoch 9/200, Iteration 199/250, Loss: 0.0143\n",
      "Epoch 9/200, Iteration 200/250, Loss: 0.0387\n",
      "Epoch 9/200, Iteration 201/250, Loss: 0.0425\n",
      "Epoch 9/200, Iteration 202/250, Loss: 0.0185\n",
      "Epoch 9/200, Iteration 203/250, Loss: 0.0183\n",
      "Epoch 9/200, Iteration 204/250, Loss: 0.0340\n",
      "Epoch 9/200, Iteration 205/250, Loss: 0.0127\n",
      "Epoch 9/200, Iteration 206/250, Loss: 0.0141\n",
      "Epoch 9/200, Iteration 207/250, Loss: 0.0177\n",
      "Epoch 9/200, Iteration 208/250, Loss: 0.0166\n",
      "Epoch 9/200, Iteration 209/250, Loss: 0.0240\n",
      "Epoch 9/200, Iteration 210/250, Loss: 0.0129\n",
      "Epoch 9/200, Iteration 211/250, Loss: 0.0121\n",
      "Epoch 9/200, Iteration 212/250, Loss: 0.0094\n",
      "Epoch 9/200, Iteration 213/250, Loss: 0.0208\n",
      "Epoch 9/200, Iteration 214/250, Loss: 0.0147\n",
      "Epoch 9/200, Iteration 215/250, Loss: 0.0115\n",
      "Epoch 9/200, Iteration 216/250, Loss: 0.0340\n",
      "Epoch 9/200, Iteration 217/250, Loss: 0.0208\n",
      "Epoch 9/200, Iteration 218/250, Loss: 0.0146\n",
      "Epoch 9/200, Iteration 219/250, Loss: 0.0226\n",
      "Epoch 9/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 9/200, Iteration 221/250, Loss: 0.0552\n",
      "Epoch 9/200, Iteration 222/250, Loss: 0.0745\n",
      "Epoch 9/200, Iteration 223/250, Loss: 0.0228\n",
      "Epoch 9/200, Iteration 224/250, Loss: 0.0329\n",
      "Epoch 9/200, Iteration 225/250, Loss: 0.0281\n",
      "Epoch 9/200, Iteration 226/250, Loss: 0.0374\n",
      "Epoch 9/200, Iteration 227/250, Loss: 0.0481\n",
      "Epoch 9/200, Iteration 228/250, Loss: 0.0130\n",
      "Epoch 9/200, Iteration 229/250, Loss: 0.0320\n",
      "Epoch 9/200, Iteration 230/250, Loss: 0.0231\n",
      "Epoch 9/200, Iteration 231/250, Loss: 0.0305\n",
      "Epoch 9/200, Iteration 232/250, Loss: 0.0224\n",
      "Epoch 9/200, Iteration 233/250, Loss: 0.0165\n",
      "Epoch 9/200, Iteration 234/250, Loss: 0.0257\n",
      "Epoch 9/200, Iteration 235/250, Loss: 0.0171\n",
      "Epoch 9/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 9/200, Iteration 237/250, Loss: 0.0518\n",
      "Epoch 9/200, Iteration 238/250, Loss: 0.0344\n",
      "Epoch 9/200, Iteration 239/250, Loss: 0.0125\n",
      "Epoch 9/200, Iteration 240/250, Loss: 0.0133\n",
      "Epoch 9/200, Iteration 241/250, Loss: 0.0348\n",
      "Epoch 9/200, Iteration 242/250, Loss: 0.0242\n",
      "Epoch 9/200, Iteration 243/250, Loss: 0.0404\n",
      "Epoch 9/200, Iteration 244/250, Loss: 0.0238\n",
      "Epoch 9/200, Iteration 245/250, Loss: 0.0199\n",
      "Epoch 9/200, Iteration 246/250, Loss: 0.0217\n",
      "Epoch 9/200, Iteration 247/250, Loss: 0.0232\n",
      "Epoch 9/200, Iteration 248/250, Loss: 0.0249\n",
      "Epoch 9/200, Iteration 249/250, Loss: 0.0273\n",
      "Epoch 9/200, Iteration 250/250, Loss: 0.0147\n",
      "Train Error: \n",
      " Accuracy: 87.91%, Avg loss: 0.012198, MRE: 0.736671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.012319, MRE: 1.485963 \n",
      "\n",
      "Epoch 10/200, Iteration 1/250, Loss: 0.0187\n",
      "Epoch 10/200, Iteration 2/250, Loss: 0.0154\n",
      "Epoch 10/200, Iteration 3/250, Loss: 0.0226\n",
      "Epoch 10/200, Iteration 4/250, Loss: 0.0446\n",
      "Epoch 10/200, Iteration 5/250, Loss: 0.0258\n",
      "Epoch 10/200, Iteration 6/250, Loss: 0.0260\n",
      "Epoch 10/200, Iteration 7/250, Loss: 0.0294\n",
      "Epoch 10/200, Iteration 8/250, Loss: 0.0175\n",
      "Epoch 10/200, Iteration 9/250, Loss: 0.0393\n",
      "Epoch 10/200, Iteration 10/250, Loss: 0.0395\n",
      "Epoch 10/200, Iteration 11/250, Loss: 0.0344\n",
      "Epoch 10/200, Iteration 12/250, Loss: 0.0424\n",
      "Epoch 10/200, Iteration 13/250, Loss: 0.0190\n",
      "Epoch 10/200, Iteration 14/250, Loss: 0.0361\n",
      "Epoch 10/200, Iteration 15/250, Loss: 0.0160\n",
      "Epoch 10/200, Iteration 16/250, Loss: 0.0159\n",
      "Epoch 10/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 10/200, Iteration 18/250, Loss: 0.0210\n",
      "Epoch 10/200, Iteration 19/250, Loss: 0.0196\n",
      "Epoch 10/200, Iteration 20/250, Loss: 0.0145\n",
      "Epoch 10/200, Iteration 21/250, Loss: 0.0169\n",
      "Epoch 10/200, Iteration 22/250, Loss: 0.0141\n",
      "Epoch 10/200, Iteration 23/250, Loss: 0.0085\n",
      "Epoch 10/200, Iteration 24/250, Loss: 0.0171\n",
      "Epoch 10/200, Iteration 25/250, Loss: 0.0209\n",
      "Epoch 10/200, Iteration 26/250, Loss: 0.0189\n",
      "Epoch 10/200, Iteration 27/250, Loss: 0.0177\n",
      "Epoch 10/200, Iteration 28/250, Loss: 0.0206\n",
      "Epoch 10/200, Iteration 29/250, Loss: 0.0090\n",
      "Epoch 10/200, Iteration 30/250, Loss: 0.0283\n",
      "Epoch 10/200, Iteration 31/250, Loss: 0.0197\n",
      "Epoch 10/200, Iteration 32/250, Loss: 0.0107\n",
      "Epoch 10/200, Iteration 33/250, Loss: 0.0254\n",
      "Epoch 10/200, Iteration 34/250, Loss: 0.0317\n",
      "Epoch 10/200, Iteration 35/250, Loss: 0.0251\n",
      "Epoch 10/200, Iteration 36/250, Loss: 0.0357\n",
      "Epoch 10/200, Iteration 37/250, Loss: 0.0214\n",
      "Epoch 10/200, Iteration 38/250, Loss: 0.0240\n",
      "Epoch 10/200, Iteration 39/250, Loss: 0.0190\n",
      "Epoch 10/200, Iteration 40/250, Loss: 0.0495\n",
      "Epoch 10/200, Iteration 41/250, Loss: 0.0295\n",
      "Epoch 10/200, Iteration 42/250, Loss: 0.0374\n",
      "Epoch 10/200, Iteration 43/250, Loss: 0.0268\n",
      "Epoch 10/200, Iteration 44/250, Loss: 0.0480\n",
      "Epoch 10/200, Iteration 45/250, Loss: 0.0204\n",
      "Epoch 10/200, Iteration 46/250, Loss: 0.0246\n",
      "Epoch 10/200, Iteration 47/250, Loss: 0.0333\n",
      "Epoch 10/200, Iteration 48/250, Loss: 0.0126\n",
      "Epoch 10/200, Iteration 49/250, Loss: 0.0217\n",
      "Epoch 10/200, Iteration 50/250, Loss: 0.0272\n",
      "Epoch 10/200, Iteration 51/250, Loss: 0.0344\n",
      "Epoch 10/200, Iteration 52/250, Loss: 0.0242\n",
      "Epoch 10/200, Iteration 53/250, Loss: 0.0160\n",
      "Epoch 10/200, Iteration 54/250, Loss: 0.0274\n",
      "Epoch 10/200, Iteration 55/250, Loss: 0.0339\n",
      "Epoch 10/200, Iteration 56/250, Loss: 0.0273\n",
      "Epoch 10/200, Iteration 57/250, Loss: 0.0338\n",
      "Epoch 10/200, Iteration 58/250, Loss: 0.0327\n",
      "Epoch 10/200, Iteration 59/250, Loss: 0.0293\n",
      "Epoch 10/200, Iteration 60/250, Loss: 0.0213\n",
      "Epoch 10/200, Iteration 61/250, Loss: 0.0181\n",
      "Epoch 10/200, Iteration 62/250, Loss: 0.0305\n",
      "Epoch 10/200, Iteration 63/250, Loss: 0.0268\n",
      "Epoch 10/200, Iteration 64/250, Loss: 0.0246\n",
      "Epoch 10/200, Iteration 65/250, Loss: 0.0389\n",
      "Epoch 10/200, Iteration 66/250, Loss: 0.0232\n",
      "Epoch 10/200, Iteration 67/250, Loss: 0.0205\n",
      "Epoch 10/200, Iteration 68/250, Loss: 0.0212\n",
      "Epoch 10/200, Iteration 69/250, Loss: 0.0216\n",
      "Epoch 10/200, Iteration 70/250, Loss: 0.0342\n",
      "Epoch 10/200, Iteration 71/250, Loss: 0.0111\n",
      "Epoch 10/200, Iteration 72/250, Loss: 0.0194\n",
      "Epoch 10/200, Iteration 73/250, Loss: 0.0399\n",
      "Epoch 10/200, Iteration 74/250, Loss: 0.0290\n",
      "Epoch 10/200, Iteration 75/250, Loss: 0.0162\n",
      "Epoch 10/200, Iteration 76/250, Loss: 0.0293\n",
      "Epoch 10/200, Iteration 77/250, Loss: 0.0161\n",
      "Epoch 10/200, Iteration 78/250, Loss: 0.0251\n",
      "Epoch 10/200, Iteration 79/250, Loss: 0.0249\n",
      "Epoch 10/200, Iteration 80/250, Loss: 0.0092\n",
      "Epoch 10/200, Iteration 81/250, Loss: 0.0197\n",
      "Epoch 10/200, Iteration 82/250, Loss: 0.0129\n",
      "Epoch 10/200, Iteration 83/250, Loss: 0.0630\n",
      "Epoch 10/200, Iteration 84/250, Loss: 0.0385\n",
      "Epoch 10/200, Iteration 85/250, Loss: 0.0383\n",
      "Epoch 10/200, Iteration 86/250, Loss: 0.0270\n",
      "Epoch 10/200, Iteration 87/250, Loss: 0.0478\n",
      "Epoch 10/200, Iteration 88/250, Loss: 0.0438\n",
      "Epoch 10/200, Iteration 89/250, Loss: 0.0245\n",
      "Epoch 10/200, Iteration 90/250, Loss: 0.0613\n",
      "Epoch 10/200, Iteration 91/250, Loss: 0.0171\n",
      "Epoch 10/200, Iteration 92/250, Loss: 0.0461\n",
      "Epoch 10/200, Iteration 93/250, Loss: 0.0227\n",
      "Epoch 10/200, Iteration 94/250, Loss: 0.0431\n",
      "Epoch 10/200, Iteration 95/250, Loss: 0.0672\n",
      "Epoch 10/200, Iteration 96/250, Loss: 0.0245\n",
      "Epoch 10/200, Iteration 97/250, Loss: 0.0416\n",
      "Epoch 10/200, Iteration 98/250, Loss: 0.0242\n",
      "Epoch 10/200, Iteration 99/250, Loss: 0.0321\n",
      "Epoch 10/200, Iteration 100/250, Loss: 0.0232\n",
      "Epoch 10/200, Iteration 101/250, Loss: 0.0207\n",
      "Epoch 10/200, Iteration 102/250, Loss: 0.0166\n",
      "Epoch 10/200, Iteration 103/250, Loss: 0.0157\n",
      "Epoch 10/200, Iteration 104/250, Loss: 0.0180\n",
      "Epoch 10/200, Iteration 105/250, Loss: 0.0491\n",
      "Epoch 10/200, Iteration 106/250, Loss: 0.0320\n",
      "Epoch 10/200, Iteration 107/250, Loss: 0.0212\n",
      "Epoch 10/200, Iteration 108/250, Loss: 0.0330\n",
      "Epoch 10/200, Iteration 109/250, Loss: 0.0258\n",
      "Epoch 10/200, Iteration 110/250, Loss: 0.0237\n",
      "Epoch 10/200, Iteration 111/250, Loss: 0.0153\n",
      "Epoch 10/200, Iteration 112/250, Loss: 0.0322\n",
      "Epoch 10/200, Iteration 113/250, Loss: 0.0184\n",
      "Epoch 10/200, Iteration 114/250, Loss: 0.0189\n",
      "Epoch 10/200, Iteration 115/250, Loss: 0.0140\n",
      "Epoch 10/200, Iteration 116/250, Loss: 0.0311\n",
      "Epoch 10/200, Iteration 117/250, Loss: 0.0213\n",
      "Epoch 10/200, Iteration 118/250, Loss: 0.0351\n",
      "Epoch 10/200, Iteration 119/250, Loss: 0.0251\n",
      "Epoch 10/200, Iteration 120/250, Loss: 0.0116\n",
      "Epoch 10/200, Iteration 121/250, Loss: 0.0172\n",
      "Epoch 10/200, Iteration 122/250, Loss: 0.0185\n",
      "Epoch 10/200, Iteration 123/250, Loss: 0.0284\n",
      "Epoch 10/200, Iteration 124/250, Loss: 0.0186\n",
      "Epoch 10/200, Iteration 125/250, Loss: 0.0412\n",
      "Epoch 10/200, Iteration 126/250, Loss: 0.0451\n",
      "Epoch 10/200, Iteration 127/250, Loss: 0.0590\n",
      "Epoch 10/200, Iteration 128/250, Loss: 0.0275\n",
      "Epoch 10/200, Iteration 129/250, Loss: 0.0225\n",
      "Epoch 10/200, Iteration 130/250, Loss: 0.0330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Iteration 131/250, Loss: 0.0228\n",
      "Epoch 10/200, Iteration 132/250, Loss: 0.0129\n",
      "Epoch 10/200, Iteration 133/250, Loss: 0.0199\n",
      "Epoch 10/200, Iteration 134/250, Loss: 0.0320\n",
      "Epoch 10/200, Iteration 135/250, Loss: 0.0290\n",
      "Epoch 10/200, Iteration 136/250, Loss: 0.0208\n",
      "Epoch 10/200, Iteration 137/250, Loss: 0.0179\n",
      "Epoch 10/200, Iteration 138/250, Loss: 0.0296\n",
      "Epoch 10/200, Iteration 139/250, Loss: 0.0152\n",
      "Epoch 10/200, Iteration 140/250, Loss: 0.0574\n",
      "Epoch 10/200, Iteration 141/250, Loss: 0.0110\n",
      "Epoch 10/200, Iteration 142/250, Loss: 0.0254\n",
      "Epoch 10/200, Iteration 143/250, Loss: 0.0345\n",
      "Epoch 10/200, Iteration 144/250, Loss: 0.0196\n",
      "Epoch 10/200, Iteration 145/250, Loss: 0.0282\n",
      "Epoch 10/200, Iteration 146/250, Loss: 0.0150\n",
      "Epoch 10/200, Iteration 147/250, Loss: 0.0099\n",
      "Epoch 10/200, Iteration 148/250, Loss: 0.0146\n",
      "Epoch 10/200, Iteration 149/250, Loss: 0.0367\n",
      "Epoch 10/200, Iteration 150/250, Loss: 0.0134\n",
      "Epoch 10/200, Iteration 151/250, Loss: 0.0517\n",
      "Epoch 10/200, Iteration 152/250, Loss: 0.0287\n",
      "Epoch 10/200, Iteration 153/250, Loss: 0.0146\n",
      "Epoch 10/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 10/200, Iteration 155/250, Loss: 0.0282\n",
      "Epoch 10/200, Iteration 156/250, Loss: 0.0125\n",
      "Epoch 10/200, Iteration 157/250, Loss: 0.0197\n",
      "Epoch 10/200, Iteration 158/250, Loss: 0.0297\n",
      "Epoch 10/200, Iteration 159/250, Loss: 0.0210\n",
      "Epoch 10/200, Iteration 160/250, Loss: 0.0282\n",
      "Epoch 10/200, Iteration 161/250, Loss: 0.0274\n",
      "Epoch 10/200, Iteration 162/250, Loss: 0.0265\n",
      "Epoch 10/200, Iteration 163/250, Loss: 0.0243\n",
      "Epoch 10/200, Iteration 164/250, Loss: 0.0145\n",
      "Epoch 10/200, Iteration 165/250, Loss: 0.0230\n",
      "Epoch 10/200, Iteration 166/250, Loss: 0.0115\n",
      "Epoch 10/200, Iteration 167/250, Loss: 0.0152\n",
      "Epoch 10/200, Iteration 168/250, Loss: 0.0155\n",
      "Epoch 10/200, Iteration 169/250, Loss: 0.0288\n",
      "Epoch 10/200, Iteration 170/250, Loss: 0.0223\n",
      "Epoch 10/200, Iteration 171/250, Loss: 0.0143\n",
      "Epoch 10/200, Iteration 172/250, Loss: 0.0176\n",
      "Epoch 10/200, Iteration 173/250, Loss: 0.0144\n",
      "Epoch 10/200, Iteration 174/250, Loss: 0.0248\n",
      "Epoch 10/200, Iteration 175/250, Loss: 0.0211\n",
      "Epoch 10/200, Iteration 176/250, Loss: 0.0115\n",
      "Epoch 10/200, Iteration 177/250, Loss: 0.0185\n",
      "Epoch 10/200, Iteration 178/250, Loss: 0.0288\n",
      "Epoch 10/200, Iteration 179/250, Loss: 0.0166\n",
      "Epoch 10/200, Iteration 180/250, Loss: 0.0127\n",
      "Epoch 10/200, Iteration 181/250, Loss: 0.0173\n",
      "Epoch 10/200, Iteration 182/250, Loss: 0.0237\n",
      "Epoch 10/200, Iteration 183/250, Loss: 0.0282\n",
      "Epoch 10/200, Iteration 184/250, Loss: 0.0259\n",
      "Epoch 10/200, Iteration 185/250, Loss: 0.0364\n",
      "Epoch 10/200, Iteration 186/250, Loss: 0.0345\n",
      "Epoch 10/200, Iteration 187/250, Loss: 0.0298\n",
      "Epoch 10/200, Iteration 188/250, Loss: 0.0257\n",
      "Epoch 10/200, Iteration 189/250, Loss: 0.0308\n",
      "Epoch 10/200, Iteration 190/250, Loss: 0.0358\n",
      "Epoch 10/200, Iteration 191/250, Loss: 0.0240\n",
      "Epoch 10/200, Iteration 192/250, Loss: 0.0453\n",
      "Epoch 10/200, Iteration 193/250, Loss: 0.0314\n",
      "Epoch 10/200, Iteration 194/250, Loss: 0.0518\n",
      "Epoch 10/200, Iteration 195/250, Loss: 0.0394\n",
      "Epoch 10/200, Iteration 196/250, Loss: 0.0208\n",
      "Epoch 10/200, Iteration 197/250, Loss: 0.0167\n",
      "Epoch 10/200, Iteration 198/250, Loss: 0.0284\n",
      "Epoch 10/200, Iteration 199/250, Loss: 0.0227\n",
      "Epoch 10/200, Iteration 200/250, Loss: 0.0177\n",
      "Epoch 10/200, Iteration 201/250, Loss: 0.0218\n",
      "Epoch 10/200, Iteration 202/250, Loss: 0.0142\n",
      "Epoch 10/200, Iteration 203/250, Loss: 0.0329\n",
      "Epoch 10/200, Iteration 204/250, Loss: 0.0219\n",
      "Epoch 10/200, Iteration 205/250, Loss: 0.0153\n",
      "Epoch 10/200, Iteration 206/250, Loss: 0.0188\n",
      "Epoch 10/200, Iteration 207/250, Loss: 0.0153\n",
      "Epoch 10/200, Iteration 208/250, Loss: 0.0301\n",
      "Epoch 10/200, Iteration 209/250, Loss: 0.0331\n",
      "Epoch 10/200, Iteration 210/250, Loss: 0.0406\n",
      "Epoch 10/200, Iteration 211/250, Loss: 0.0117\n",
      "Epoch 10/200, Iteration 212/250, Loss: 0.0303\n",
      "Epoch 10/200, Iteration 213/250, Loss: 0.0260\n",
      "Epoch 10/200, Iteration 214/250, Loss: 0.0408\n",
      "Epoch 10/200, Iteration 215/250, Loss: 0.0164\n",
      "Epoch 10/200, Iteration 216/250, Loss: 0.0179\n",
      "Epoch 10/200, Iteration 217/250, Loss: 0.0278\n",
      "Epoch 10/200, Iteration 218/250, Loss: 0.0227\n",
      "Epoch 10/200, Iteration 219/250, Loss: 0.0287\n",
      "Epoch 10/200, Iteration 220/250, Loss: 0.0253\n",
      "Epoch 10/200, Iteration 221/250, Loss: 0.0212\n",
      "Epoch 10/200, Iteration 222/250, Loss: 0.0287\n",
      "Epoch 10/200, Iteration 223/250, Loss: 0.0200\n",
      "Epoch 10/200, Iteration 224/250, Loss: 0.0265\n",
      "Epoch 10/200, Iteration 225/250, Loss: 0.0281\n",
      "Epoch 10/200, Iteration 226/250, Loss: 0.0489\n",
      "Epoch 10/200, Iteration 227/250, Loss: 0.0274\n",
      "Epoch 10/200, Iteration 228/250, Loss: 0.0336\n",
      "Epoch 10/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 10/200, Iteration 230/250, Loss: 0.0450\n",
      "Epoch 10/200, Iteration 231/250, Loss: 0.0343\n",
      "Epoch 10/200, Iteration 232/250, Loss: 0.0252\n",
      "Epoch 10/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 10/200, Iteration 234/250, Loss: 0.0401\n",
      "Epoch 10/200, Iteration 235/250, Loss: 0.0231\n",
      "Epoch 10/200, Iteration 236/250, Loss: 0.0514\n",
      "Epoch 10/200, Iteration 237/250, Loss: 0.0234\n",
      "Epoch 10/200, Iteration 238/250, Loss: 0.0204\n",
      "Epoch 10/200, Iteration 239/250, Loss: 0.0305\n",
      "Epoch 10/200, Iteration 240/250, Loss: 0.0342\n",
      "Epoch 10/200, Iteration 241/250, Loss: 0.0221\n",
      "Epoch 10/200, Iteration 242/250, Loss: 0.0269\n",
      "Epoch 10/200, Iteration 243/250, Loss: 0.0161\n",
      "Epoch 10/200, Iteration 244/250, Loss: 0.0176\n",
      "Epoch 10/200, Iteration 245/250, Loss: 0.0194\n",
      "Epoch 10/200, Iteration 246/250, Loss: 0.0319\n",
      "Epoch 10/200, Iteration 247/250, Loss: 0.0126\n",
      "Epoch 10/200, Iteration 248/250, Loss: 0.0266\n",
      "Epoch 10/200, Iteration 249/250, Loss: 0.0239\n",
      "Epoch 10/200, Iteration 250/250, Loss: 0.0193\n",
      "Train Error: \n",
      " Accuracy: 68.11%, Avg loss: 0.015121, MRE: 1.197783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.015179, MRE: 1.725133 \n",
      "\n",
      "Epoch 11/200, Iteration 1/250, Loss: 0.0448\n",
      "Epoch 11/200, Iteration 2/250, Loss: 0.0169\n",
      "Epoch 11/200, Iteration 3/250, Loss: 0.0237\n",
      "Epoch 11/200, Iteration 4/250, Loss: 0.0284\n",
      "Epoch 11/200, Iteration 5/250, Loss: 0.0177\n",
      "Epoch 11/200, Iteration 6/250, Loss: 0.0362\n",
      "Epoch 11/200, Iteration 7/250, Loss: 0.0230\n",
      "Epoch 11/200, Iteration 8/250, Loss: 0.0302\n",
      "Epoch 11/200, Iteration 9/250, Loss: 0.0265\n",
      "Epoch 11/200, Iteration 10/250, Loss: 0.0543\n",
      "Epoch 11/200, Iteration 11/250, Loss: 0.0231\n",
      "Epoch 11/200, Iteration 12/250, Loss: 0.0176\n",
      "Epoch 11/200, Iteration 13/250, Loss: 0.0233\n",
      "Epoch 11/200, Iteration 14/250, Loss: 0.0212\n",
      "Epoch 11/200, Iteration 15/250, Loss: 0.0374\n",
      "Epoch 11/200, Iteration 16/250, Loss: 0.0220\n",
      "Epoch 11/200, Iteration 17/250, Loss: 0.0341\n",
      "Epoch 11/200, Iteration 18/250, Loss: 0.0181\n",
      "Epoch 11/200, Iteration 19/250, Loss: 0.0227\n",
      "Epoch 11/200, Iteration 20/250, Loss: 0.0430\n",
      "Epoch 11/200, Iteration 21/250, Loss: 0.0212\n",
      "Epoch 11/200, Iteration 22/250, Loss: 0.0148\n",
      "Epoch 11/200, Iteration 23/250, Loss: 0.0335\n",
      "Epoch 11/200, Iteration 24/250, Loss: 0.0205\n",
      "Epoch 11/200, Iteration 25/250, Loss: 0.0162\n",
      "Epoch 11/200, Iteration 26/250, Loss: 0.0192\n",
      "Epoch 11/200, Iteration 27/250, Loss: 0.0239\n",
      "Epoch 11/200, Iteration 28/250, Loss: 0.0310\n",
      "Epoch 11/200, Iteration 29/250, Loss: 0.0226\n",
      "Epoch 11/200, Iteration 30/250, Loss: 0.0175\n",
      "Epoch 11/200, Iteration 31/250, Loss: 0.0197\n",
      "Epoch 11/200, Iteration 32/250, Loss: 0.0181\n",
      "Epoch 11/200, Iteration 33/250, Loss: 0.0195\n",
      "Epoch 11/200, Iteration 34/250, Loss: 0.0227\n",
      "Epoch 11/200, Iteration 35/250, Loss: 0.0138\n",
      "Epoch 11/200, Iteration 36/250, Loss: 0.0157\n",
      "Epoch 11/200, Iteration 37/250, Loss: 0.0454\n",
      "Epoch 11/200, Iteration 38/250, Loss: 0.0310\n",
      "Epoch 11/200, Iteration 39/250, Loss: 0.0287\n",
      "Epoch 11/200, Iteration 40/250, Loss: 0.0218\n",
      "Epoch 11/200, Iteration 41/250, Loss: 0.0197\n",
      "Epoch 11/200, Iteration 42/250, Loss: 0.0251\n",
      "Epoch 11/200, Iteration 43/250, Loss: 0.0239\n",
      "Epoch 11/200, Iteration 44/250, Loss: 0.0203\n",
      "Epoch 11/200, Iteration 45/250, Loss: 0.0204\n",
      "Epoch 11/200, Iteration 46/250, Loss: 0.0160\n",
      "Epoch 11/200, Iteration 47/250, Loss: 0.0443\n",
      "Epoch 11/200, Iteration 48/250, Loss: 0.0208\n",
      "Epoch 11/200, Iteration 49/250, Loss: 0.0258\n",
      "Epoch 11/200, Iteration 50/250, Loss: 0.0173\n",
      "Epoch 11/200, Iteration 51/250, Loss: 0.0202\n",
      "Epoch 11/200, Iteration 52/250, Loss: 0.0290\n",
      "Epoch 11/200, Iteration 53/250, Loss: 0.0232\n",
      "Epoch 11/200, Iteration 54/250, Loss: 0.0194\n",
      "Epoch 11/200, Iteration 55/250, Loss: 0.0173\n",
      "Epoch 11/200, Iteration 56/250, Loss: 0.0136\n",
      "Epoch 11/200, Iteration 57/250, Loss: 0.0137\n",
      "Epoch 11/200, Iteration 58/250, Loss: 0.0154\n",
      "Epoch 11/200, Iteration 59/250, Loss: 0.0299\n",
      "Epoch 11/200, Iteration 60/250, Loss: 0.0150\n",
      "Epoch 11/200, Iteration 61/250, Loss: 0.0230\n",
      "Epoch 11/200, Iteration 62/250, Loss: 0.0154\n",
      "Epoch 11/200, Iteration 63/250, Loss: 0.0217\n",
      "Epoch 11/200, Iteration 64/250, Loss: 0.0313\n",
      "Epoch 11/200, Iteration 65/250, Loss: 0.0108\n",
      "Epoch 11/200, Iteration 66/250, Loss: 0.0219\n",
      "Epoch 11/200, Iteration 67/250, Loss: 0.0274\n",
      "Epoch 11/200, Iteration 68/250, Loss: 0.0314\n",
      "Epoch 11/200, Iteration 69/250, Loss: 0.0312\n",
      "Epoch 11/200, Iteration 70/250, Loss: 0.0288\n",
      "Epoch 11/200, Iteration 71/250, Loss: 0.0174\n",
      "Epoch 11/200, Iteration 72/250, Loss: 0.0237\n",
      "Epoch 11/200, Iteration 73/250, Loss: 0.0240\n",
      "Epoch 11/200, Iteration 74/250, Loss: 0.0258\n",
      "Epoch 11/200, Iteration 75/250, Loss: 0.0209\n",
      "Epoch 11/200, Iteration 76/250, Loss: 0.0257\n",
      "Epoch 11/200, Iteration 77/250, Loss: 0.0195\n",
      "Epoch 11/200, Iteration 78/250, Loss: 0.0239\n",
      "Epoch 11/200, Iteration 79/250, Loss: 0.0123\n",
      "Epoch 11/200, Iteration 80/250, Loss: 0.0197\n",
      "Epoch 11/200, Iteration 81/250, Loss: 0.0214\n",
      "Epoch 11/200, Iteration 82/250, Loss: 0.0198\n",
      "Epoch 11/200, Iteration 83/250, Loss: 0.0103\n",
      "Epoch 11/200, Iteration 84/250, Loss: 0.0096\n",
      "Epoch 11/200, Iteration 85/250, Loss: 0.0258\n",
      "Epoch 11/200, Iteration 86/250, Loss: 0.0309\n",
      "Epoch 11/200, Iteration 87/250, Loss: 0.0102\n",
      "Epoch 11/200, Iteration 88/250, Loss: 0.0264\n",
      "Epoch 11/200, Iteration 89/250, Loss: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Iteration 90/250, Loss: 0.0283\n",
      "Epoch 11/200, Iteration 91/250, Loss: 0.0172\n",
      "Epoch 11/200, Iteration 92/250, Loss: 0.0170\n",
      "Epoch 11/200, Iteration 93/250, Loss: 0.0156\n",
      "Epoch 11/200, Iteration 94/250, Loss: 0.0150\n",
      "Epoch 11/200, Iteration 95/250, Loss: 0.0369\n",
      "Epoch 11/200, Iteration 96/250, Loss: 0.0271\n",
      "Epoch 11/200, Iteration 97/250, Loss: 0.0178\n",
      "Epoch 11/200, Iteration 98/250, Loss: 0.0320\n",
      "Epoch 11/200, Iteration 99/250, Loss: 0.0220\n",
      "Epoch 11/200, Iteration 100/250, Loss: 0.0339\n",
      "Epoch 11/200, Iteration 101/250, Loss: 0.0327\n",
      "Epoch 11/200, Iteration 102/250, Loss: 0.0356\n",
      "Epoch 11/200, Iteration 103/250, Loss: 0.0118\n",
      "Epoch 11/200, Iteration 104/250, Loss: 0.0211\n",
      "Epoch 11/200, Iteration 105/250, Loss: 0.0280\n",
      "Epoch 11/200, Iteration 106/250, Loss: 0.0182\n",
      "Epoch 11/200, Iteration 107/250, Loss: 0.0244\n",
      "Epoch 11/200, Iteration 108/250, Loss: 0.0244\n",
      "Epoch 11/200, Iteration 109/250, Loss: 0.0179\n",
      "Epoch 11/200, Iteration 110/250, Loss: 0.0231\n",
      "Epoch 11/200, Iteration 111/250, Loss: 0.0336\n",
      "Epoch 11/200, Iteration 112/250, Loss: 0.0239\n",
      "Epoch 11/200, Iteration 113/250, Loss: 0.0187\n",
      "Epoch 11/200, Iteration 114/250, Loss: 0.0148\n",
      "Epoch 11/200, Iteration 115/250, Loss: 0.0376\n",
      "Epoch 11/200, Iteration 116/250, Loss: 0.0373\n",
      "Epoch 11/200, Iteration 117/250, Loss: 0.0173\n",
      "Epoch 11/200, Iteration 118/250, Loss: 0.0349\n",
      "Epoch 11/200, Iteration 119/250, Loss: 0.0166\n",
      "Epoch 11/200, Iteration 120/250, Loss: 0.0286\n",
      "Epoch 11/200, Iteration 121/250, Loss: 0.0283\n",
      "Epoch 11/200, Iteration 122/250, Loss: 0.0147\n",
      "Epoch 11/200, Iteration 123/250, Loss: 0.0189\n",
      "Epoch 11/200, Iteration 124/250, Loss: 0.0517\n",
      "Epoch 11/200, Iteration 125/250, Loss: 0.0273\n",
      "Epoch 11/200, Iteration 126/250, Loss: 0.0177\n",
      "Epoch 11/200, Iteration 127/250, Loss: 0.0402\n",
      "Epoch 11/200, Iteration 128/250, Loss: 0.0319\n",
      "Epoch 11/200, Iteration 129/250, Loss: 0.0167\n",
      "Epoch 11/200, Iteration 130/250, Loss: 0.0371\n",
      "Epoch 11/200, Iteration 131/250, Loss: 0.0290\n",
      "Epoch 11/200, Iteration 132/250, Loss: 0.0159\n",
      "Epoch 11/200, Iteration 133/250, Loss: 0.0529\n",
      "Epoch 11/200, Iteration 134/250, Loss: 0.0399\n",
      "Epoch 11/200, Iteration 135/250, Loss: 0.0428\n",
      "Epoch 11/200, Iteration 136/250, Loss: 0.0373\n",
      "Epoch 11/200, Iteration 137/250, Loss: 0.0411\n",
      "Epoch 11/200, Iteration 138/250, Loss: 0.0134\n",
      "Epoch 11/200, Iteration 139/250, Loss: 0.0227\n",
      "Epoch 11/200, Iteration 140/250, Loss: 0.0163\n",
      "Epoch 11/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 11/200, Iteration 142/250, Loss: 0.0245\n",
      "Epoch 11/200, Iteration 143/250, Loss: 0.0138\n",
      "Epoch 11/200, Iteration 144/250, Loss: 0.0328\n",
      "Epoch 11/200, Iteration 145/250, Loss: 0.0358\n",
      "Epoch 11/200, Iteration 146/250, Loss: 0.0180\n",
      "Epoch 11/200, Iteration 147/250, Loss: 0.0357\n",
      "Epoch 11/200, Iteration 148/250, Loss: 0.0235\n",
      "Epoch 11/200, Iteration 149/250, Loss: 0.0126\n",
      "Epoch 11/200, Iteration 150/250, Loss: 0.0626\n",
      "Epoch 11/200, Iteration 151/250, Loss: 0.0359\n",
      "Epoch 11/200, Iteration 152/250, Loss: 0.0481\n",
      "Epoch 11/200, Iteration 153/250, Loss: 0.0719\n",
      "Epoch 11/200, Iteration 154/250, Loss: 0.0384\n",
      "Epoch 11/200, Iteration 155/250, Loss: 0.0399\n",
      "Epoch 11/200, Iteration 156/250, Loss: 0.0379\n",
      "Epoch 11/200, Iteration 157/250, Loss: 0.0812\n",
      "Epoch 11/200, Iteration 158/250, Loss: 0.0479\n",
      "Epoch 11/200, Iteration 159/250, Loss: 0.0389\n",
      "Epoch 11/200, Iteration 160/250, Loss: 0.0244\n",
      "Epoch 11/200, Iteration 161/250, Loss: 0.0254\n",
      "Epoch 11/200, Iteration 162/250, Loss: 0.0259\n",
      "Epoch 11/200, Iteration 163/250, Loss: 0.0192\n",
      "Epoch 11/200, Iteration 164/250, Loss: 0.0203\n",
      "Epoch 11/200, Iteration 165/250, Loss: 0.0186\n",
      "Epoch 11/200, Iteration 166/250, Loss: 0.0446\n",
      "Epoch 11/200, Iteration 167/250, Loss: 0.0237\n",
      "Epoch 11/200, Iteration 168/250, Loss: 0.0217\n",
      "Epoch 11/200, Iteration 169/250, Loss: 0.0477\n",
      "Epoch 11/200, Iteration 170/250, Loss: 0.0260\n",
      "Epoch 11/200, Iteration 171/250, Loss: 0.0253\n",
      "Epoch 11/200, Iteration 172/250, Loss: 0.0286\n",
      "Epoch 11/200, Iteration 173/250, Loss: 0.0224\n",
      "Epoch 11/200, Iteration 174/250, Loss: 0.0141\n",
      "Epoch 11/200, Iteration 175/250, Loss: 0.0155\n",
      "Epoch 11/200, Iteration 176/250, Loss: 0.0124\n",
      "Epoch 11/200, Iteration 177/250, Loss: 0.0154\n",
      "Epoch 11/200, Iteration 178/250, Loss: 0.0266\n",
      "Epoch 11/200, Iteration 179/250, Loss: 0.0235\n",
      "Epoch 11/200, Iteration 180/250, Loss: 0.0276\n",
      "Epoch 11/200, Iteration 181/250, Loss: 0.0216\n",
      "Epoch 11/200, Iteration 182/250, Loss: 0.0356\n",
      "Epoch 11/200, Iteration 183/250, Loss: 0.0165\n",
      "Epoch 11/200, Iteration 184/250, Loss: 0.0352\n",
      "Epoch 11/200, Iteration 185/250, Loss: 0.0628\n",
      "Epoch 11/200, Iteration 186/250, Loss: 0.0618\n",
      "Epoch 11/200, Iteration 187/250, Loss: 0.0378\n",
      "Epoch 11/200, Iteration 188/250, Loss: 0.0178\n",
      "Epoch 11/200, Iteration 189/250, Loss: 0.0139\n",
      "Epoch 11/200, Iteration 190/250, Loss: 0.0162\n",
      "Epoch 11/200, Iteration 191/250, Loss: 0.0165\n",
      "Epoch 11/200, Iteration 192/250, Loss: 0.0328\n",
      "Epoch 11/200, Iteration 193/250, Loss: 0.0261\n",
      "Epoch 11/200, Iteration 194/250, Loss: 0.0268\n",
      "Epoch 11/200, Iteration 195/250, Loss: 0.0266\n",
      "Epoch 11/200, Iteration 196/250, Loss: 0.0178\n",
      "Epoch 11/200, Iteration 197/250, Loss: 0.0128\n",
      "Epoch 11/200, Iteration 198/250, Loss: 0.0130\n",
      "Epoch 11/200, Iteration 199/250, Loss: 0.0305\n",
      "Epoch 11/200, Iteration 200/250, Loss: 0.0161\n",
      "Epoch 11/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 11/200, Iteration 202/250, Loss: 0.0147\n",
      "Epoch 11/200, Iteration 203/250, Loss: 0.0104\n",
      "Epoch 11/200, Iteration 204/250, Loss: 0.0102\n",
      "Epoch 11/200, Iteration 205/250, Loss: 0.0163\n",
      "Epoch 11/200, Iteration 206/250, Loss: 0.0215\n",
      "Epoch 11/200, Iteration 207/250, Loss: 0.0225\n",
      "Epoch 11/200, Iteration 208/250, Loss: 0.0334\n",
      "Epoch 11/200, Iteration 209/250, Loss: 0.0377\n",
      "Epoch 11/200, Iteration 210/250, Loss: 0.0216\n",
      "Epoch 11/200, Iteration 211/250, Loss: 0.0221\n",
      "Epoch 11/200, Iteration 212/250, Loss: 0.0172\n",
      "Epoch 11/200, Iteration 213/250, Loss: 0.0354\n",
      "Epoch 11/200, Iteration 214/250, Loss: 0.0237\n",
      "Epoch 11/200, Iteration 215/250, Loss: 0.0418\n",
      "Epoch 11/200, Iteration 216/250, Loss: 0.0179\n",
      "Epoch 11/200, Iteration 217/250, Loss: 0.0223\n",
      "Epoch 11/200, Iteration 218/250, Loss: 0.0326\n",
      "Epoch 11/200, Iteration 219/250, Loss: 0.0316\n",
      "Epoch 11/200, Iteration 220/250, Loss: 0.0284\n",
      "Epoch 11/200, Iteration 221/250, Loss: 0.0457\n",
      "Epoch 11/200, Iteration 222/250, Loss: 0.0207\n",
      "Epoch 11/200, Iteration 223/250, Loss: 0.0190\n",
      "Epoch 11/200, Iteration 224/250, Loss: 0.0154\n",
      "Epoch 11/200, Iteration 225/250, Loss: 0.0269\n",
      "Epoch 11/200, Iteration 226/250, Loss: 0.0200\n",
      "Epoch 11/200, Iteration 227/250, Loss: 0.0425\n",
      "Epoch 11/200, Iteration 228/250, Loss: 0.0263\n",
      "Epoch 11/200, Iteration 229/250, Loss: 0.0217\n",
      "Epoch 11/200, Iteration 230/250, Loss: 0.0311\n",
      "Epoch 11/200, Iteration 231/250, Loss: 0.0394\n",
      "Epoch 11/200, Iteration 232/250, Loss: 0.0233\n",
      "Epoch 11/200, Iteration 233/250, Loss: 0.0193\n",
      "Epoch 11/200, Iteration 234/250, Loss: 0.0451\n",
      "Epoch 11/200, Iteration 235/250, Loss: 0.0396\n",
      "Epoch 11/200, Iteration 236/250, Loss: 0.0392\n",
      "Epoch 11/200, Iteration 237/250, Loss: 0.0191\n",
      "Epoch 11/200, Iteration 238/250, Loss: 0.0682\n",
      "Epoch 11/200, Iteration 239/250, Loss: 0.0288\n",
      "Epoch 11/200, Iteration 240/250, Loss: 0.0283\n",
      "Epoch 11/200, Iteration 241/250, Loss: 0.0315\n",
      "Epoch 11/200, Iteration 242/250, Loss: 0.0138\n",
      "Epoch 11/200, Iteration 243/250, Loss: 0.0117\n",
      "Epoch 11/200, Iteration 244/250, Loss: 0.0201\n",
      "Epoch 11/200, Iteration 245/250, Loss: 0.0169\n",
      "Epoch 11/200, Iteration 246/250, Loss: 0.0142\n",
      "Epoch 11/200, Iteration 247/250, Loss: 0.0261\n",
      "Epoch 11/200, Iteration 248/250, Loss: 0.0333\n",
      "Epoch 11/200, Iteration 249/250, Loss: 0.0243\n",
      "Epoch 11/200, Iteration 250/250, Loss: 0.0219\n",
      "Train Error: \n",
      " Accuracy: 53.79%, Avg loss: 0.014725, MRE: 0.885464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.65%, Avg loss: 0.014492, MRE: 0.861796 \n",
      "\n",
      "Epoch 12/200, Iteration 1/250, Loss: 0.0217\n",
      "Epoch 12/200, Iteration 2/250, Loss: 0.0225\n",
      "Epoch 12/200, Iteration 3/250, Loss: 0.0175\n",
      "Epoch 12/200, Iteration 4/250, Loss: 0.0191\n",
      "Epoch 12/200, Iteration 5/250, Loss: 0.0208\n",
      "Epoch 12/200, Iteration 6/250, Loss: 0.0271\n",
      "Epoch 12/200, Iteration 7/250, Loss: 0.0181\n",
      "Epoch 12/200, Iteration 8/250, Loss: 0.0573\n",
      "Epoch 12/200, Iteration 9/250, Loss: 0.0171\n",
      "Epoch 12/200, Iteration 10/250, Loss: 0.0126\n",
      "Epoch 12/200, Iteration 11/250, Loss: 0.0208\n",
      "Epoch 12/200, Iteration 12/250, Loss: 0.0284\n",
      "Epoch 12/200, Iteration 13/250, Loss: 0.0202\n",
      "Epoch 12/200, Iteration 14/250, Loss: 0.0272\n",
      "Epoch 12/200, Iteration 15/250, Loss: 0.0211\n",
      "Epoch 12/200, Iteration 16/250, Loss: 0.0178\n",
      "Epoch 12/200, Iteration 17/250, Loss: 0.0135\n",
      "Epoch 12/200, Iteration 18/250, Loss: 0.0219\n",
      "Epoch 12/200, Iteration 19/250, Loss: 0.0206\n",
      "Epoch 12/200, Iteration 20/250, Loss: 0.0254\n",
      "Epoch 12/200, Iteration 21/250, Loss: 0.0357\n",
      "Epoch 12/200, Iteration 22/250, Loss: 0.0259\n",
      "Epoch 12/200, Iteration 23/250, Loss: 0.0290\n",
      "Epoch 12/200, Iteration 24/250, Loss: 0.0273\n",
      "Epoch 12/200, Iteration 25/250, Loss: 0.0114\n",
      "Epoch 12/200, Iteration 26/250, Loss: 0.0181\n",
      "Epoch 12/200, Iteration 27/250, Loss: 0.0131\n",
      "Epoch 12/200, Iteration 28/250, Loss: 0.0427\n",
      "Epoch 12/200, Iteration 29/250, Loss: 0.0311\n",
      "Epoch 12/200, Iteration 30/250, Loss: 0.0305\n",
      "Epoch 12/200, Iteration 31/250, Loss: 0.0618\n",
      "Epoch 12/200, Iteration 32/250, Loss: 0.0640\n",
      "Epoch 12/200, Iteration 33/250, Loss: 0.0225\n",
      "Epoch 12/200, Iteration 34/250, Loss: 0.0267\n",
      "Epoch 12/200, Iteration 35/250, Loss: 0.0264\n",
      "Epoch 12/200, Iteration 36/250, Loss: 0.0258\n",
      "Epoch 12/200, Iteration 37/250, Loss: 0.0174\n",
      "Epoch 12/200, Iteration 38/250, Loss: 0.0139\n",
      "Epoch 12/200, Iteration 39/250, Loss: 0.0211\n",
      "Epoch 12/200, Iteration 40/250, Loss: 0.0318\n",
      "Epoch 12/200, Iteration 41/250, Loss: 0.0440\n",
      "Epoch 12/200, Iteration 42/250, Loss: 0.0154\n",
      "Epoch 12/200, Iteration 43/250, Loss: 0.0187\n",
      "Epoch 12/200, Iteration 44/250, Loss: 0.0286\n",
      "Epoch 12/200, Iteration 45/250, Loss: 0.0248\n",
      "Epoch 12/200, Iteration 46/250, Loss: 0.0350\n",
      "Epoch 12/200, Iteration 47/250, Loss: 0.0386\n",
      "Epoch 12/200, Iteration 48/250, Loss: 0.0400\n",
      "Epoch 12/200, Iteration 49/250, Loss: 0.0294\n",
      "Epoch 12/200, Iteration 50/250, Loss: 0.0256\n",
      "Epoch 12/200, Iteration 51/250, Loss: 0.0328\n",
      "Epoch 12/200, Iteration 52/250, Loss: 0.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Iteration 53/250, Loss: 0.0340\n",
      "Epoch 12/200, Iteration 54/250, Loss: 0.0229\n",
      "Epoch 12/200, Iteration 55/250, Loss: 0.0290\n",
      "Epoch 12/200, Iteration 56/250, Loss: 0.0242\n",
      "Epoch 12/200, Iteration 57/250, Loss: 0.0259\n",
      "Epoch 12/200, Iteration 58/250, Loss: 0.0236\n",
      "Epoch 12/200, Iteration 59/250, Loss: 0.0184\n",
      "Epoch 12/200, Iteration 60/250, Loss: 0.0245\n",
      "Epoch 12/200, Iteration 61/250, Loss: 0.0308\n",
      "Epoch 12/200, Iteration 62/250, Loss: 0.0205\n",
      "Epoch 12/200, Iteration 63/250, Loss: 0.0187\n",
      "Epoch 12/200, Iteration 64/250, Loss: 0.0232\n",
      "Epoch 12/200, Iteration 65/250, Loss: 0.0238\n",
      "Epoch 12/200, Iteration 66/250, Loss: 0.0324\n",
      "Epoch 12/200, Iteration 67/250, Loss: 0.0262\n",
      "Epoch 12/200, Iteration 68/250, Loss: 0.0182\n",
      "Epoch 12/200, Iteration 69/250, Loss: 0.0151\n",
      "Epoch 12/200, Iteration 70/250, Loss: 0.0199\n",
      "Epoch 12/200, Iteration 71/250, Loss: 0.0252\n",
      "Epoch 12/200, Iteration 72/250, Loss: 0.0383\n",
      "Epoch 12/200, Iteration 73/250, Loss: 0.0243\n",
      "Epoch 12/200, Iteration 74/250, Loss: 0.0244\n",
      "Epoch 12/200, Iteration 75/250, Loss: 0.0309\n",
      "Epoch 12/200, Iteration 76/250, Loss: 0.0280\n",
      "Epoch 12/200, Iteration 77/250, Loss: 0.0141\n",
      "Epoch 12/200, Iteration 78/250, Loss: 0.0162\n",
      "Epoch 12/200, Iteration 79/250, Loss: 0.0167\n",
      "Epoch 12/200, Iteration 80/250, Loss: 0.0189\n",
      "Epoch 12/200, Iteration 81/250, Loss: 0.0300\n",
      "Epoch 12/200, Iteration 82/250, Loss: 0.0395\n",
      "Epoch 12/200, Iteration 83/250, Loss: 0.0482\n",
      "Epoch 12/200, Iteration 84/250, Loss: 0.0184\n",
      "Epoch 12/200, Iteration 85/250, Loss: 0.0176\n",
      "Epoch 12/200, Iteration 86/250, Loss: 0.0199\n",
      "Epoch 12/200, Iteration 87/250, Loss: 0.0123\n",
      "Epoch 12/200, Iteration 88/250, Loss: 0.0143\n",
      "Epoch 12/200, Iteration 89/250, Loss: 0.0272\n",
      "Epoch 12/200, Iteration 90/250, Loss: 0.0181\n",
      "Epoch 12/200, Iteration 91/250, Loss: 0.0169\n",
      "Epoch 12/200, Iteration 92/250, Loss: 0.0262\n",
      "Epoch 12/200, Iteration 93/250, Loss: 0.0167\n",
      "Epoch 12/200, Iteration 94/250, Loss: 0.0223\n",
      "Epoch 12/200, Iteration 95/250, Loss: 0.0303\n",
      "Epoch 12/200, Iteration 96/250, Loss: 0.0173\n",
      "Epoch 12/200, Iteration 97/250, Loss: 0.0406\n",
      "Epoch 12/200, Iteration 98/250, Loss: 0.0241\n",
      "Epoch 12/200, Iteration 99/250, Loss: 0.0188\n",
      "Epoch 12/200, Iteration 100/250, Loss: 0.0420\n",
      "Epoch 12/200, Iteration 101/250, Loss: 0.0109\n",
      "Epoch 12/200, Iteration 102/250, Loss: 0.0232\n",
      "Epoch 12/200, Iteration 103/250, Loss: 0.0146\n",
      "Epoch 12/200, Iteration 104/250, Loss: 0.0233\n",
      "Epoch 12/200, Iteration 105/250, Loss: 0.0222\n",
      "Epoch 12/200, Iteration 106/250, Loss: 0.0173\n",
      "Epoch 12/200, Iteration 107/250, Loss: 0.0150\n",
      "Epoch 12/200, Iteration 108/250, Loss: 0.0247\n",
      "Epoch 12/200, Iteration 109/250, Loss: 0.0124\n",
      "Epoch 12/200, Iteration 110/250, Loss: 0.0159\n",
      "Epoch 12/200, Iteration 111/250, Loss: 0.0131\n",
      "Epoch 12/200, Iteration 112/250, Loss: 0.0254\n",
      "Epoch 12/200, Iteration 113/250, Loss: 0.0197\n",
      "Epoch 12/200, Iteration 114/250, Loss: 0.0145\n",
      "Epoch 12/200, Iteration 115/250, Loss: 0.0136\n",
      "Epoch 12/200, Iteration 116/250, Loss: 0.0166\n",
      "Epoch 12/200, Iteration 117/250, Loss: 0.0162\n",
      "Epoch 12/200, Iteration 118/250, Loss: 0.0149\n",
      "Epoch 12/200, Iteration 119/250, Loss: 0.0213\n",
      "Epoch 12/200, Iteration 120/250, Loss: 0.0381\n",
      "Epoch 12/200, Iteration 121/250, Loss: 0.0124\n",
      "Epoch 12/200, Iteration 122/250, Loss: 0.0161\n",
      "Epoch 12/200, Iteration 123/250, Loss: 0.0213\n",
      "Epoch 12/200, Iteration 124/250, Loss: 0.0308\n",
      "Epoch 12/200, Iteration 125/250, Loss: 0.0229\n",
      "Epoch 12/200, Iteration 126/250, Loss: 0.0349\n",
      "Epoch 12/200, Iteration 127/250, Loss: 0.0225\n",
      "Epoch 12/200, Iteration 128/250, Loss: 0.0200\n",
      "Epoch 12/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 12/200, Iteration 130/250, Loss: 0.0272\n",
      "Epoch 12/200, Iteration 131/250, Loss: 0.0197\n",
      "Epoch 12/200, Iteration 132/250, Loss: 0.0362\n",
      "Epoch 12/200, Iteration 133/250, Loss: 0.0159\n",
      "Epoch 12/200, Iteration 134/250, Loss: 0.0129\n",
      "Epoch 12/200, Iteration 135/250, Loss: 0.0306\n",
      "Epoch 12/200, Iteration 136/250, Loss: 0.0211\n",
      "Epoch 12/200, Iteration 137/250, Loss: 0.0289\n",
      "Epoch 12/200, Iteration 138/250, Loss: 0.0208\n",
      "Epoch 12/200, Iteration 139/250, Loss: 0.0489\n",
      "Epoch 12/200, Iteration 140/250, Loss: 0.0200\n",
      "Epoch 12/200, Iteration 141/250, Loss: 0.0179\n",
      "Epoch 12/200, Iteration 142/250, Loss: 0.0142\n",
      "Epoch 12/200, Iteration 143/250, Loss: 0.0124\n",
      "Epoch 12/200, Iteration 144/250, Loss: 0.0168\n",
      "Epoch 12/200, Iteration 145/250, Loss: 0.0308\n",
      "Epoch 12/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 12/200, Iteration 147/250, Loss: 0.0352\n",
      "Epoch 12/200, Iteration 148/250, Loss: 0.0250\n",
      "Epoch 12/200, Iteration 149/250, Loss: 0.0260\n",
      "Epoch 12/200, Iteration 150/250, Loss: 0.0361\n",
      "Epoch 12/200, Iteration 151/250, Loss: 0.0175\n",
      "Epoch 12/200, Iteration 152/250, Loss: 0.0207\n",
      "Epoch 12/200, Iteration 153/250, Loss: 0.0241\n",
      "Epoch 12/200, Iteration 154/250, Loss: 0.0197\n",
      "Epoch 12/200, Iteration 155/250, Loss: 0.0195\n",
      "Epoch 12/200, Iteration 156/250, Loss: 0.0227\n",
      "Epoch 12/200, Iteration 157/250, Loss: 0.0132\n",
      "Epoch 12/200, Iteration 158/250, Loss: 0.0176\n",
      "Epoch 12/200, Iteration 159/250, Loss: 0.0221\n",
      "Epoch 12/200, Iteration 160/250, Loss: 0.0220\n",
      "Epoch 12/200, Iteration 161/250, Loss: 0.0190\n",
      "Epoch 12/200, Iteration 162/250, Loss: 0.0124\n",
      "Epoch 12/200, Iteration 163/250, Loss: 0.0418\n",
      "Epoch 12/200, Iteration 164/250, Loss: 0.0229\n",
      "Epoch 12/200, Iteration 165/250, Loss: 0.0139\n",
      "Epoch 12/200, Iteration 166/250, Loss: 0.0169\n",
      "Epoch 12/200, Iteration 167/250, Loss: 0.0552\n",
      "Epoch 12/200, Iteration 168/250, Loss: 0.0164\n",
      "Epoch 12/200, Iteration 169/250, Loss: 0.0196\n",
      "Epoch 12/200, Iteration 170/250, Loss: 0.0242\n",
      "Epoch 12/200, Iteration 171/250, Loss: 0.0141\n",
      "Epoch 12/200, Iteration 172/250, Loss: 0.0194\n",
      "Epoch 12/200, Iteration 173/250, Loss: 0.0227\n",
      "Epoch 12/200, Iteration 174/250, Loss: 0.0147\n",
      "Epoch 12/200, Iteration 175/250, Loss: 0.0131\n",
      "Epoch 12/200, Iteration 176/250, Loss: 0.0121\n",
      "Epoch 12/200, Iteration 177/250, Loss: 0.0225\n",
      "Epoch 12/200, Iteration 178/250, Loss: 0.0123\n",
      "Epoch 12/200, Iteration 179/250, Loss: 0.0226\n",
      "Epoch 12/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 12/200, Iteration 181/250, Loss: 0.0333\n",
      "Epoch 12/200, Iteration 182/250, Loss: 0.0306\n",
      "Epoch 12/200, Iteration 183/250, Loss: 0.0325\n",
      "Epoch 12/200, Iteration 184/250, Loss: 0.0272\n",
      "Epoch 12/200, Iteration 185/250, Loss: 0.0236\n",
      "Epoch 12/200, Iteration 186/250, Loss: 0.0176\n",
      "Epoch 12/200, Iteration 187/250, Loss: 0.0108\n",
      "Epoch 12/200, Iteration 188/250, Loss: 0.0153\n",
      "Epoch 12/200, Iteration 189/250, Loss: 0.0276\n",
      "Epoch 12/200, Iteration 190/250, Loss: 0.0489\n",
      "Epoch 12/200, Iteration 191/250, Loss: 0.0141\n",
      "Epoch 12/200, Iteration 192/250, Loss: 0.0483\n",
      "Epoch 12/200, Iteration 193/250, Loss: 0.0181\n",
      "Epoch 12/200, Iteration 194/250, Loss: 0.0201\n",
      "Epoch 12/200, Iteration 195/250, Loss: 0.0259\n",
      "Epoch 12/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 12/200, Iteration 197/250, Loss: 0.0181\n",
      "Epoch 12/200, Iteration 198/250, Loss: 0.0236\n",
      "Epoch 12/200, Iteration 199/250, Loss: 0.0156\n",
      "Epoch 12/200, Iteration 200/250, Loss: 0.0305\n",
      "Epoch 12/200, Iteration 201/250, Loss: 0.0153\n",
      "Epoch 12/200, Iteration 202/250, Loss: 0.0120\n",
      "Epoch 12/200, Iteration 203/250, Loss: 0.0311\n",
      "Epoch 12/200, Iteration 204/250, Loss: 0.0278\n",
      "Epoch 12/200, Iteration 205/250, Loss: 0.0185\n",
      "Epoch 12/200, Iteration 206/250, Loss: 0.0216\n",
      "Epoch 12/200, Iteration 207/250, Loss: 0.0185\n",
      "Epoch 12/200, Iteration 208/250, Loss: 0.0407\n",
      "Epoch 12/200, Iteration 209/250, Loss: 0.0197\n",
      "Epoch 12/200, Iteration 210/250, Loss: 0.0327\n",
      "Epoch 12/200, Iteration 211/250, Loss: 0.0233\n",
      "Epoch 12/200, Iteration 212/250, Loss: 0.0188\n",
      "Epoch 12/200, Iteration 213/250, Loss: 0.0350\n",
      "Epoch 12/200, Iteration 214/250, Loss: 0.0502\n",
      "Epoch 12/200, Iteration 215/250, Loss: 0.0436\n",
      "Epoch 12/200, Iteration 216/250, Loss: 0.0159\n",
      "Epoch 12/200, Iteration 217/250, Loss: 0.0304\n",
      "Epoch 12/200, Iteration 218/250, Loss: 0.0263\n",
      "Epoch 12/200, Iteration 219/250, Loss: 0.0133\n",
      "Epoch 12/200, Iteration 220/250, Loss: 0.0324\n",
      "Epoch 12/200, Iteration 221/250, Loss: 0.0137\n",
      "Epoch 12/200, Iteration 222/250, Loss: 0.0194\n",
      "Epoch 12/200, Iteration 223/250, Loss: 0.0111\n",
      "Epoch 12/200, Iteration 224/250, Loss: 0.0480\n",
      "Epoch 12/200, Iteration 225/250, Loss: 0.0371\n",
      "Epoch 12/200, Iteration 226/250, Loss: 0.0299\n",
      "Epoch 12/200, Iteration 227/250, Loss: 0.0132\n",
      "Epoch 12/200, Iteration 228/250, Loss: 0.0153\n",
      "Epoch 12/200, Iteration 229/250, Loss: 0.0618\n",
      "Epoch 12/200, Iteration 230/250, Loss: 0.0147\n",
      "Epoch 12/200, Iteration 231/250, Loss: 0.0255\n",
      "Epoch 12/200, Iteration 232/250, Loss: 0.0198\n",
      "Epoch 12/200, Iteration 233/250, Loss: 0.0470\n",
      "Epoch 12/200, Iteration 234/250, Loss: 0.0274\n",
      "Epoch 12/200, Iteration 235/250, Loss: 0.0228\n",
      "Epoch 12/200, Iteration 236/250, Loss: 0.0292\n",
      "Epoch 12/200, Iteration 237/250, Loss: 0.0265\n",
      "Epoch 12/200, Iteration 238/250, Loss: 0.0227\n",
      "Epoch 12/200, Iteration 239/250, Loss: 0.0154\n",
      "Epoch 12/200, Iteration 240/250, Loss: 0.0189\n",
      "Epoch 12/200, Iteration 241/250, Loss: 0.0195\n",
      "Epoch 12/200, Iteration 242/250, Loss: 0.0183\n",
      "Epoch 12/200, Iteration 243/250, Loss: 0.0175\n",
      "Epoch 12/200, Iteration 244/250, Loss: 0.0296\n",
      "Epoch 12/200, Iteration 245/250, Loss: 0.0261\n",
      "Epoch 12/200, Iteration 246/250, Loss: 0.0219\n",
      "Epoch 12/200, Iteration 247/250, Loss: 0.0349\n",
      "Epoch 12/200, Iteration 248/250, Loss: 0.0114\n",
      "Epoch 12/200, Iteration 249/250, Loss: 0.0156\n",
      "Epoch 12/200, Iteration 250/250, Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 68.21%, Avg loss: 0.011782, MRE: 0.812502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.011836, MRE: 1.174911 \n",
      "\n",
      "Epoch 13/200, Iteration 1/250, Loss: 0.0165\n",
      "Epoch 13/200, Iteration 2/250, Loss: 0.0245\n",
      "Epoch 13/200, Iteration 3/250, Loss: 0.0197\n",
      "Epoch 13/200, Iteration 4/250, Loss: 0.0272\n",
      "Epoch 13/200, Iteration 5/250, Loss: 0.0228\n",
      "Epoch 13/200, Iteration 6/250, Loss: 0.0149\n",
      "Epoch 13/200, Iteration 7/250, Loss: 0.0256\n",
      "Epoch 13/200, Iteration 8/250, Loss: 0.0144\n",
      "Epoch 13/200, Iteration 9/250, Loss: 0.0365\n",
      "Epoch 13/200, Iteration 10/250, Loss: 0.0264\n",
      "Epoch 13/200, Iteration 11/250, Loss: 0.0149\n",
      "Epoch 13/200, Iteration 12/250, Loss: 0.0457\n",
      "Epoch 13/200, Iteration 13/250, Loss: 0.0293\n",
      "Epoch 13/200, Iteration 14/250, Loss: 0.0360\n",
      "Epoch 13/200, Iteration 15/250, Loss: 0.0169\n",
      "Epoch 13/200, Iteration 16/250, Loss: 0.0329\n",
      "Epoch 13/200, Iteration 17/250, Loss: 0.0216\n",
      "Epoch 13/200, Iteration 18/250, Loss: 0.0311\n",
      "Epoch 13/200, Iteration 19/250, Loss: 0.0177\n",
      "Epoch 13/200, Iteration 20/250, Loss: 0.0123\n",
      "Epoch 13/200, Iteration 21/250, Loss: 0.0114\n",
      "Epoch 13/200, Iteration 22/250, Loss: 0.0159\n",
      "Epoch 13/200, Iteration 23/250, Loss: 0.0209\n",
      "Epoch 13/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 13/200, Iteration 25/250, Loss: 0.0162\n",
      "Epoch 13/200, Iteration 26/250, Loss: 0.0215\n",
      "Epoch 13/200, Iteration 27/250, Loss: 0.0212\n",
      "Epoch 13/200, Iteration 28/250, Loss: 0.0219\n",
      "Epoch 13/200, Iteration 29/250, Loss: 0.0142\n",
      "Epoch 13/200, Iteration 30/250, Loss: 0.0326\n",
      "Epoch 13/200, Iteration 31/250, Loss: 0.0186\n",
      "Epoch 13/200, Iteration 32/250, Loss: 0.0094\n",
      "Epoch 13/200, Iteration 33/250, Loss: 0.0185\n",
      "Epoch 13/200, Iteration 34/250, Loss: 0.0155\n",
      "Epoch 13/200, Iteration 35/250, Loss: 0.0161\n",
      "Epoch 13/200, Iteration 36/250, Loss: 0.0292\n",
      "Epoch 13/200, Iteration 37/250, Loss: 0.0231\n",
      "Epoch 13/200, Iteration 38/250, Loss: 0.0192\n",
      "Epoch 13/200, Iteration 39/250, Loss: 0.0123\n",
      "Epoch 13/200, Iteration 40/250, Loss: 0.0153\n",
      "Epoch 13/200, Iteration 41/250, Loss: 0.0137\n",
      "Epoch 13/200, Iteration 42/250, Loss: 0.0099\n",
      "Epoch 13/200, Iteration 43/250, Loss: 0.0231\n",
      "Epoch 13/200, Iteration 44/250, Loss: 0.0233\n",
      "Epoch 13/200, Iteration 45/250, Loss: 0.0124\n",
      "Epoch 13/200, Iteration 46/250, Loss: 0.0104\n",
      "Epoch 13/200, Iteration 47/250, Loss: 0.0277\n",
      "Epoch 13/200, Iteration 48/250, Loss: 0.0174\n",
      "Epoch 13/200, Iteration 49/250, Loss: 0.0237\n",
      "Epoch 13/200, Iteration 50/250, Loss: 0.0193\n",
      "Epoch 13/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 13/200, Iteration 52/250, Loss: 0.0406\n",
      "Epoch 13/200, Iteration 53/250, Loss: 0.0745\n",
      "Epoch 13/200, Iteration 54/250, Loss: 0.0270\n",
      "Epoch 13/200, Iteration 55/250, Loss: 0.0366\n",
      "Epoch 13/200, Iteration 56/250, Loss: 0.0268\n",
      "Epoch 13/200, Iteration 57/250, Loss: 0.0251\n",
      "Epoch 13/200, Iteration 58/250, Loss: 0.0142\n",
      "Epoch 13/200, Iteration 59/250, Loss: 0.0294\n",
      "Epoch 13/200, Iteration 60/250, Loss: 0.0183\n",
      "Epoch 13/200, Iteration 61/250, Loss: 0.0191\n",
      "Epoch 13/200, Iteration 62/250, Loss: 0.0331\n",
      "Epoch 13/200, Iteration 63/250, Loss: 0.0303\n",
      "Epoch 13/200, Iteration 64/250, Loss: 0.0136\n",
      "Epoch 13/200, Iteration 65/250, Loss: 0.0183\n",
      "Epoch 13/200, Iteration 66/250, Loss: 0.0285\n",
      "Epoch 13/200, Iteration 67/250, Loss: 0.0315\n",
      "Epoch 13/200, Iteration 68/250, Loss: 0.0219\n",
      "Epoch 13/200, Iteration 69/250, Loss: 0.0200\n",
      "Epoch 13/200, Iteration 70/250, Loss: 0.0372\n",
      "Epoch 13/200, Iteration 71/250, Loss: 0.0174\n",
      "Epoch 13/200, Iteration 72/250, Loss: 0.0322\n",
      "Epoch 13/200, Iteration 73/250, Loss: 0.0313\n",
      "Epoch 13/200, Iteration 74/250, Loss: 0.0266\n",
      "Epoch 13/200, Iteration 75/250, Loss: 0.0219\n",
      "Epoch 13/200, Iteration 76/250, Loss: 0.0458\n",
      "Epoch 13/200, Iteration 77/250, Loss: 0.0234\n",
      "Epoch 13/200, Iteration 78/250, Loss: 0.0382\n",
      "Epoch 13/200, Iteration 79/250, Loss: 0.0235\n",
      "Epoch 13/200, Iteration 80/250, Loss: 0.0383\n",
      "Epoch 13/200, Iteration 81/250, Loss: 0.0437\n",
      "Epoch 13/200, Iteration 82/250, Loss: 0.0226\n",
      "Epoch 13/200, Iteration 83/250, Loss: 0.0308\n",
      "Epoch 13/200, Iteration 84/250, Loss: 0.0159\n",
      "Epoch 13/200, Iteration 85/250, Loss: 0.0273\n",
      "Epoch 13/200, Iteration 86/250, Loss: 0.0215\n",
      "Epoch 13/200, Iteration 87/250, Loss: 0.0226\n",
      "Epoch 13/200, Iteration 88/250, Loss: 0.0433\n",
      "Epoch 13/200, Iteration 89/250, Loss: 0.0217\n",
      "Epoch 13/200, Iteration 90/250, Loss: 0.0317\n",
      "Epoch 13/200, Iteration 91/250, Loss: 0.0329\n",
      "Epoch 13/200, Iteration 92/250, Loss: 0.0353\n",
      "Epoch 13/200, Iteration 93/250, Loss: 0.0293\n",
      "Epoch 13/200, Iteration 94/250, Loss: 0.0202\n",
      "Epoch 13/200, Iteration 95/250, Loss: 0.0264\n",
      "Epoch 13/200, Iteration 96/250, Loss: 0.0334\n",
      "Epoch 13/200, Iteration 97/250, Loss: 0.0302\n",
      "Epoch 13/200, Iteration 98/250, Loss: 0.0247\n",
      "Epoch 13/200, Iteration 99/250, Loss: 0.0272\n",
      "Epoch 13/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 13/200, Iteration 101/250, Loss: 0.0127\n",
      "Epoch 13/200, Iteration 102/250, Loss: 0.0208\n",
      "Epoch 13/200, Iteration 103/250, Loss: 0.0156\n",
      "Epoch 13/200, Iteration 104/250, Loss: 0.0177\n",
      "Epoch 13/200, Iteration 105/250, Loss: 0.0219\n",
      "Epoch 13/200, Iteration 106/250, Loss: 0.0157\n",
      "Epoch 13/200, Iteration 107/250, Loss: 0.0146\n",
      "Epoch 13/200, Iteration 108/250, Loss: 0.0292\n",
      "Epoch 13/200, Iteration 109/250, Loss: 0.0104\n",
      "Epoch 13/200, Iteration 110/250, Loss: 0.0230\n",
      "Epoch 13/200, Iteration 111/250, Loss: 0.0251\n",
      "Epoch 13/200, Iteration 112/250, Loss: 0.0233\n",
      "Epoch 13/200, Iteration 113/250, Loss: 0.0214\n",
      "Epoch 13/200, Iteration 114/250, Loss: 0.0264\n",
      "Epoch 13/200, Iteration 115/250, Loss: 0.0247\n",
      "Epoch 13/200, Iteration 116/250, Loss: 0.0162\n",
      "Epoch 13/200, Iteration 117/250, Loss: 0.0181\n",
      "Epoch 13/200, Iteration 118/250, Loss: 0.0215\n",
      "Epoch 13/200, Iteration 119/250, Loss: 0.0255\n",
      "Epoch 13/200, Iteration 120/250, Loss: 0.0164\n",
      "Epoch 13/200, Iteration 121/250, Loss: 0.0152\n",
      "Epoch 13/200, Iteration 122/250, Loss: 0.0326\n",
      "Epoch 13/200, Iteration 123/250, Loss: 0.0166\n",
      "Epoch 13/200, Iteration 124/250, Loss: 0.0352\n",
      "Epoch 13/200, Iteration 125/250, Loss: 0.0220\n",
      "Epoch 13/200, Iteration 126/250, Loss: 0.0287\n",
      "Epoch 13/200, Iteration 127/250, Loss: 0.0117\n",
      "Epoch 13/200, Iteration 128/250, Loss: 0.0144\n",
      "Epoch 13/200, Iteration 129/250, Loss: 0.0394\n",
      "Epoch 13/200, Iteration 130/250, Loss: 0.0253\n",
      "Epoch 13/200, Iteration 131/250, Loss: 0.0142\n",
      "Epoch 13/200, Iteration 132/250, Loss: 0.0214\n",
      "Epoch 13/200, Iteration 133/250, Loss: 0.0292\n",
      "Epoch 13/200, Iteration 134/250, Loss: 0.0134\n",
      "Epoch 13/200, Iteration 135/250, Loss: 0.0421\n",
      "Epoch 13/200, Iteration 136/250, Loss: 0.0271\n",
      "Epoch 13/200, Iteration 137/250, Loss: 0.0310\n",
      "Epoch 13/200, Iteration 138/250, Loss: 0.0207\n",
      "Epoch 13/200, Iteration 139/250, Loss: 0.0187\n",
      "Epoch 13/200, Iteration 140/250, Loss: 0.0194\n",
      "Epoch 13/200, Iteration 141/250, Loss: 0.0198\n",
      "Epoch 13/200, Iteration 142/250, Loss: 0.0300\n",
      "Epoch 13/200, Iteration 143/250, Loss: 0.0296\n",
      "Epoch 13/200, Iteration 144/250, Loss: 0.0210\n",
      "Epoch 13/200, Iteration 145/250, Loss: 0.0154\n",
      "Epoch 13/200, Iteration 146/250, Loss: 0.0148\n",
      "Epoch 13/200, Iteration 147/250, Loss: 0.0281\n",
      "Epoch 13/200, Iteration 148/250, Loss: 0.0443\n",
      "Epoch 13/200, Iteration 149/250, Loss: 0.0174\n",
      "Epoch 13/200, Iteration 150/250, Loss: 0.0298\n",
      "Epoch 13/200, Iteration 151/250, Loss: 0.0269\n",
      "Epoch 13/200, Iteration 152/250, Loss: 0.0302\n",
      "Epoch 13/200, Iteration 153/250, Loss: 0.0213\n",
      "Epoch 13/200, Iteration 154/250, Loss: 0.0240\n",
      "Epoch 13/200, Iteration 155/250, Loss: 0.0423\n",
      "Epoch 13/200, Iteration 156/250, Loss: 0.0186\n",
      "Epoch 13/200, Iteration 157/250, Loss: 0.0276\n",
      "Epoch 13/200, Iteration 158/250, Loss: 0.0268\n",
      "Epoch 13/200, Iteration 159/250, Loss: 0.0293\n",
      "Epoch 13/200, Iteration 160/250, Loss: 0.0137\n",
      "Epoch 13/200, Iteration 161/250, Loss: 0.0144\n",
      "Epoch 13/200, Iteration 162/250, Loss: 0.0278\n",
      "Epoch 13/200, Iteration 163/250, Loss: 0.0368\n",
      "Epoch 13/200, Iteration 164/250, Loss: 0.0189\n",
      "Epoch 13/200, Iteration 165/250, Loss: 0.0329\n",
      "Epoch 13/200, Iteration 166/250, Loss: 0.0223\n",
      "Epoch 13/200, Iteration 167/250, Loss: 0.0210\n",
      "Epoch 13/200, Iteration 168/250, Loss: 0.0260\n",
      "Epoch 13/200, Iteration 169/250, Loss: 0.0183\n",
      "Epoch 13/200, Iteration 170/250, Loss: 0.0302\n",
      "Epoch 13/200, Iteration 171/250, Loss: 0.0335\n",
      "Epoch 13/200, Iteration 172/250, Loss: 0.0166\n",
      "Epoch 13/200, Iteration 173/250, Loss: 0.0237\n",
      "Epoch 13/200, Iteration 174/250, Loss: 0.0262\n",
      "Epoch 13/200, Iteration 175/250, Loss: 0.0169\n",
      "Epoch 13/200, Iteration 176/250, Loss: 0.0130\n",
      "Epoch 13/200, Iteration 177/250, Loss: 0.0231\n",
      "Epoch 13/200, Iteration 178/250, Loss: 0.0191\n",
      "Epoch 13/200, Iteration 179/250, Loss: 0.0152\n",
      "Epoch 13/200, Iteration 180/250, Loss: 0.0210\n",
      "Epoch 13/200, Iteration 181/250, Loss: 0.0247\n",
      "Epoch 13/200, Iteration 182/250, Loss: 0.0242\n",
      "Epoch 13/200, Iteration 183/250, Loss: 0.0332\n",
      "Epoch 13/200, Iteration 184/250, Loss: 0.0124\n",
      "Epoch 13/200, Iteration 185/250, Loss: 0.0209\n",
      "Epoch 13/200, Iteration 186/250, Loss: 0.0145\n",
      "Epoch 13/200, Iteration 187/250, Loss: 0.0281\n",
      "Epoch 13/200, Iteration 188/250, Loss: 0.0433\n",
      "Epoch 13/200, Iteration 189/250, Loss: 0.0276\n",
      "Epoch 13/200, Iteration 190/250, Loss: 0.0201\n",
      "Epoch 13/200, Iteration 191/250, Loss: 0.0307\n",
      "Epoch 13/200, Iteration 192/250, Loss: 0.0308\n",
      "Epoch 13/200, Iteration 193/250, Loss: 0.0199\n",
      "Epoch 13/200, Iteration 194/250, Loss: 0.0221\n",
      "Epoch 13/200, Iteration 195/250, Loss: 0.0314\n",
      "Epoch 13/200, Iteration 196/250, Loss: 0.0193\n",
      "Epoch 13/200, Iteration 197/250, Loss: 0.0140\n",
      "Epoch 13/200, Iteration 198/250, Loss: 0.0236\n",
      "Epoch 13/200, Iteration 199/250, Loss: 0.0210\n",
      "Epoch 13/200, Iteration 200/250, Loss: 0.0228\n",
      "Epoch 13/200, Iteration 201/250, Loss: 0.0236\n",
      "Epoch 13/200, Iteration 202/250, Loss: 0.0366\n",
      "Epoch 13/200, Iteration 203/250, Loss: 0.0219\n",
      "Epoch 13/200, Iteration 204/250, Loss: 0.0204\n",
      "Epoch 13/200, Iteration 205/250, Loss: 0.0171\n",
      "Epoch 13/200, Iteration 206/250, Loss: 0.0440\n",
      "Epoch 13/200, Iteration 207/250, Loss: 0.0223\n",
      "Epoch 13/200, Iteration 208/250, Loss: 0.0362\n",
      "Epoch 13/200, Iteration 209/250, Loss: 0.0443\n",
      "Epoch 13/200, Iteration 210/250, Loss: 0.0225\n",
      "Epoch 13/200, Iteration 211/250, Loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Iteration 212/250, Loss: 0.0149\n",
      "Epoch 13/200, Iteration 213/250, Loss: 0.0179\n",
      "Epoch 13/200, Iteration 214/250, Loss: 0.0224\n",
      "Epoch 13/200, Iteration 215/250, Loss: 0.0199\n",
      "Epoch 13/200, Iteration 216/250, Loss: 0.0423\n",
      "Epoch 13/200, Iteration 217/250, Loss: 0.0108\n",
      "Epoch 13/200, Iteration 218/250, Loss: 0.0178\n",
      "Epoch 13/200, Iteration 219/250, Loss: 0.0130\n",
      "Epoch 13/200, Iteration 220/250, Loss: 0.0118\n",
      "Epoch 13/200, Iteration 221/250, Loss: 0.0121\n",
      "Epoch 13/200, Iteration 222/250, Loss: 0.0116\n",
      "Epoch 13/200, Iteration 223/250, Loss: 0.0109\n",
      "Epoch 13/200, Iteration 224/250, Loss: 0.0217\n",
      "Epoch 13/200, Iteration 225/250, Loss: 0.0144\n",
      "Epoch 13/200, Iteration 226/250, Loss: 0.0255\n",
      "Epoch 13/200, Iteration 227/250, Loss: 0.0338\n",
      "Epoch 13/200, Iteration 228/250, Loss: 0.0161\n",
      "Epoch 13/200, Iteration 229/250, Loss: 0.0390\n",
      "Epoch 13/200, Iteration 230/250, Loss: 0.0192\n",
      "Epoch 13/200, Iteration 231/250, Loss: 0.0195\n",
      "Epoch 13/200, Iteration 232/250, Loss: 0.0307\n",
      "Epoch 13/200, Iteration 233/250, Loss: 0.0444\n",
      "Epoch 13/200, Iteration 234/250, Loss: 0.0193\n",
      "Epoch 13/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 13/200, Iteration 236/250, Loss: 0.0182\n",
      "Epoch 13/200, Iteration 237/250, Loss: 0.0200\n",
      "Epoch 13/200, Iteration 238/250, Loss: 0.0124\n",
      "Epoch 13/200, Iteration 239/250, Loss: 0.0104\n",
      "Epoch 13/200, Iteration 240/250, Loss: 0.0234\n",
      "Epoch 13/200, Iteration 241/250, Loss: 0.0167\n",
      "Epoch 13/200, Iteration 242/250, Loss: 0.0174\n",
      "Epoch 13/200, Iteration 243/250, Loss: 0.0120\n",
      "Epoch 13/200, Iteration 244/250, Loss: 0.0229\n",
      "Epoch 13/200, Iteration 245/250, Loss: 0.0195\n",
      "Epoch 13/200, Iteration 246/250, Loss: 0.0231\n",
      "Epoch 13/200, Iteration 247/250, Loss: 0.0207\n",
      "Epoch 13/200, Iteration 248/250, Loss: 0.0382\n",
      "Epoch 13/200, Iteration 249/250, Loss: 0.0239\n",
      "Epoch 13/200, Iteration 250/250, Loss: 0.0199\n",
      "Train Error: \n",
      " Accuracy: 93.33%, Avg loss: 0.019557, MRE: 1.725090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.45%, Avg loss: 0.019299, MRE: 2.537290 \n",
      "\n",
      "Epoch 14/200, Iteration 1/250, Loss: 0.0182\n",
      "Epoch 14/200, Iteration 2/250, Loss: 0.0251\n",
      "Epoch 14/200, Iteration 3/250, Loss: 0.0231\n",
      "Epoch 14/200, Iteration 4/250, Loss: 0.0462\n",
      "Epoch 14/200, Iteration 5/250, Loss: 0.0188\n",
      "Epoch 14/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 14/200, Iteration 7/250, Loss: 0.0210\n",
      "Epoch 14/200, Iteration 8/250, Loss: 0.0304\n",
      "Epoch 14/200, Iteration 9/250, Loss: 0.0169\n",
      "Epoch 14/200, Iteration 10/250, Loss: 0.0172\n",
      "Epoch 14/200, Iteration 11/250, Loss: 0.0383\n",
      "Epoch 14/200, Iteration 12/250, Loss: 0.0197\n",
      "Epoch 14/200, Iteration 13/250, Loss: 0.0241\n",
      "Epoch 14/200, Iteration 14/250, Loss: 0.0328\n",
      "Epoch 14/200, Iteration 15/250, Loss: 0.0130\n",
      "Epoch 14/200, Iteration 16/250, Loss: 0.0316\n",
      "Epoch 14/200, Iteration 17/250, Loss: 0.0399\n",
      "Epoch 14/200, Iteration 18/250, Loss: 0.0227\n",
      "Epoch 14/200, Iteration 19/250, Loss: 0.0129\n",
      "Epoch 14/200, Iteration 20/250, Loss: 0.0194\n",
      "Epoch 14/200, Iteration 21/250, Loss: 0.0228\n",
      "Epoch 14/200, Iteration 22/250, Loss: 0.0195\n",
      "Epoch 14/200, Iteration 23/250, Loss: 0.0226\n",
      "Epoch 14/200, Iteration 24/250, Loss: 0.0140\n",
      "Epoch 14/200, Iteration 25/250, Loss: 0.0279\n",
      "Epoch 14/200, Iteration 26/250, Loss: 0.0204\n",
      "Epoch 14/200, Iteration 27/250, Loss: 0.0196\n",
      "Epoch 14/200, Iteration 28/250, Loss: 0.0213\n",
      "Epoch 14/200, Iteration 29/250, Loss: 0.0190\n",
      "Epoch 14/200, Iteration 30/250, Loss: 0.0155\n",
      "Epoch 14/200, Iteration 31/250, Loss: 0.0212\n",
      "Epoch 14/200, Iteration 32/250, Loss: 0.0415\n",
      "Epoch 14/200, Iteration 33/250, Loss: 0.0192\n",
      "Epoch 14/200, Iteration 34/250, Loss: 0.0465\n",
      "Epoch 14/200, Iteration 35/250, Loss: 0.0293\n",
      "Epoch 14/200, Iteration 36/250, Loss: 0.0150\n",
      "Epoch 14/200, Iteration 37/250, Loss: 0.0117\n",
      "Epoch 14/200, Iteration 38/250, Loss: 0.0269\n",
      "Epoch 14/200, Iteration 39/250, Loss: 0.0215\n",
      "Epoch 14/200, Iteration 40/250, Loss: 0.0399\n",
      "Epoch 14/200, Iteration 41/250, Loss: 0.0318\n",
      "Epoch 14/200, Iteration 42/250, Loss: 0.0182\n",
      "Epoch 14/200, Iteration 43/250, Loss: 0.0155\n",
      "Epoch 14/200, Iteration 44/250, Loss: 0.0303\n",
      "Epoch 14/200, Iteration 45/250, Loss: 0.0184\n",
      "Epoch 14/200, Iteration 46/250, Loss: 0.0253\n",
      "Epoch 14/200, Iteration 47/250, Loss: 0.0184\n",
      "Epoch 14/200, Iteration 48/250, Loss: 0.0132\n",
      "Epoch 14/200, Iteration 49/250, Loss: 0.0129\n",
      "Epoch 14/200, Iteration 50/250, Loss: 0.0260\n",
      "Epoch 14/200, Iteration 51/250, Loss: 0.0263\n",
      "Epoch 14/200, Iteration 52/250, Loss: 0.0224\n",
      "Epoch 14/200, Iteration 53/250, Loss: 0.0178\n",
      "Epoch 14/200, Iteration 54/250, Loss: 0.0244\n",
      "Epoch 14/200, Iteration 55/250, Loss: 0.0387\n",
      "Epoch 14/200, Iteration 56/250, Loss: 0.0243\n",
      "Epoch 14/200, Iteration 57/250, Loss: 0.0255\n",
      "Epoch 14/200, Iteration 58/250, Loss: 0.0228\n",
      "Epoch 14/200, Iteration 59/250, Loss: 0.0284\n",
      "Epoch 14/200, Iteration 60/250, Loss: 0.0335\n",
      "Epoch 14/200, Iteration 61/250, Loss: 0.0226\n",
      "Epoch 14/200, Iteration 62/250, Loss: 0.0258\n",
      "Epoch 14/200, Iteration 63/250, Loss: 0.0123\n",
      "Epoch 14/200, Iteration 64/250, Loss: 0.0137\n",
      "Epoch 14/200, Iteration 65/250, Loss: 0.0194\n",
      "Epoch 14/200, Iteration 66/250, Loss: 0.0337\n",
      "Epoch 14/200, Iteration 67/250, Loss: 0.0301\n",
      "Epoch 14/200, Iteration 68/250, Loss: 0.0309\n",
      "Epoch 14/200, Iteration 69/250, Loss: 0.0310\n",
      "Epoch 14/200, Iteration 70/250, Loss: 0.0255\n",
      "Epoch 14/200, Iteration 71/250, Loss: 0.0205\n",
      "Epoch 14/200, Iteration 72/250, Loss: 0.0369\n",
      "Epoch 14/200, Iteration 73/250, Loss: 0.0223\n",
      "Epoch 14/200, Iteration 74/250, Loss: 0.0276\n",
      "Epoch 14/200, Iteration 75/250, Loss: 0.0228\n",
      "Epoch 14/200, Iteration 76/250, Loss: 0.0206\n",
      "Epoch 14/200, Iteration 77/250, Loss: 0.0133\n",
      "Epoch 14/200, Iteration 78/250, Loss: 0.0161\n",
      "Epoch 14/200, Iteration 79/250, Loss: 0.0133\n",
      "Epoch 14/200, Iteration 80/250, Loss: 0.0210\n",
      "Epoch 14/200, Iteration 81/250, Loss: 0.0137\n",
      "Epoch 14/200, Iteration 82/250, Loss: 0.0189\n",
      "Epoch 14/200, Iteration 83/250, Loss: 0.0476\n",
      "Epoch 14/200, Iteration 84/250, Loss: 0.0421\n",
      "Epoch 14/200, Iteration 85/250, Loss: 0.0143\n",
      "Epoch 14/200, Iteration 86/250, Loss: 0.0082\n",
      "Epoch 14/200, Iteration 87/250, Loss: 0.0119\n",
      "Epoch 14/200, Iteration 88/250, Loss: 0.0395\n",
      "Epoch 14/200, Iteration 89/250, Loss: 0.0171\n",
      "Epoch 14/200, Iteration 90/250, Loss: 0.0181\n",
      "Epoch 14/200, Iteration 91/250, Loss: 0.0155\n",
      "Epoch 14/200, Iteration 92/250, Loss: 0.0226\n",
      "Epoch 14/200, Iteration 93/250, Loss: 0.0304\n",
      "Epoch 14/200, Iteration 94/250, Loss: 0.0255\n",
      "Epoch 14/200, Iteration 95/250, Loss: 0.0293\n",
      "Epoch 14/200, Iteration 96/250, Loss: 0.0370\n",
      "Epoch 14/200, Iteration 97/250, Loss: 0.0184\n",
      "Epoch 14/200, Iteration 98/250, Loss: 0.0194\n",
      "Epoch 14/200, Iteration 99/250, Loss: 0.0205\n",
      "Epoch 14/200, Iteration 100/250, Loss: 0.0527\n",
      "Epoch 14/200, Iteration 101/250, Loss: 0.0193\n",
      "Epoch 14/200, Iteration 102/250, Loss: 0.0436\n",
      "Epoch 14/200, Iteration 103/250, Loss: 0.0611\n",
      "Epoch 14/200, Iteration 104/250, Loss: 0.0263\n",
      "Epoch 14/200, Iteration 105/250, Loss: 0.0180\n",
      "Epoch 14/200, Iteration 106/250, Loss: 0.0172\n",
      "Epoch 14/200, Iteration 107/250, Loss: 0.0169\n",
      "Epoch 14/200, Iteration 108/250, Loss: 0.0246\n",
      "Epoch 14/200, Iteration 109/250, Loss: 0.0296\n",
      "Epoch 14/200, Iteration 110/250, Loss: 0.0176\n",
      "Epoch 14/200, Iteration 111/250, Loss: 0.0154\n",
      "Epoch 14/200, Iteration 112/250, Loss: 0.0240\n",
      "Epoch 14/200, Iteration 113/250, Loss: 0.0334\n",
      "Epoch 14/200, Iteration 114/250, Loss: 0.0256\n",
      "Epoch 14/200, Iteration 115/250, Loss: 0.0174\n",
      "Epoch 14/200, Iteration 116/250, Loss: 0.0191\n",
      "Epoch 14/200, Iteration 117/250, Loss: 0.0228\n",
      "Epoch 14/200, Iteration 118/250, Loss: 0.0182\n",
      "Epoch 14/200, Iteration 119/250, Loss: 0.0341\n",
      "Epoch 14/200, Iteration 120/250, Loss: 0.0210\n",
      "Epoch 14/200, Iteration 121/250, Loss: 0.0258\n",
      "Epoch 14/200, Iteration 122/250, Loss: 0.0233\n",
      "Epoch 14/200, Iteration 123/250, Loss: 0.0457\n",
      "Epoch 14/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 14/200, Iteration 125/250, Loss: 0.0129\n",
      "Epoch 14/200, Iteration 126/250, Loss: 0.0168\n",
      "Epoch 14/200, Iteration 127/250, Loss: 0.0217\n",
      "Epoch 14/200, Iteration 128/250, Loss: 0.0199\n",
      "Epoch 14/200, Iteration 129/250, Loss: 0.0385\n",
      "Epoch 14/200, Iteration 130/250, Loss: 0.0198\n",
      "Epoch 14/200, Iteration 131/250, Loss: 0.0183\n",
      "Epoch 14/200, Iteration 132/250, Loss: 0.0151\n",
      "Epoch 14/200, Iteration 133/250, Loss: 0.0114\n",
      "Epoch 14/200, Iteration 134/250, Loss: 0.0164\n",
      "Epoch 14/200, Iteration 135/250, Loss: 0.0177\n",
      "Epoch 14/200, Iteration 136/250, Loss: 0.0219\n",
      "Epoch 14/200, Iteration 137/250, Loss: 0.0185\n",
      "Epoch 14/200, Iteration 138/250, Loss: 0.0394\n",
      "Epoch 14/200, Iteration 139/250, Loss: 0.0152\n",
      "Epoch 14/200, Iteration 140/250, Loss: 0.0204\n",
      "Epoch 14/200, Iteration 141/250, Loss: 0.0394\n",
      "Epoch 14/200, Iteration 142/250, Loss: 0.0183\n",
      "Epoch 14/200, Iteration 143/250, Loss: 0.0108\n",
      "Epoch 14/200, Iteration 144/250, Loss: 0.0091\n",
      "Epoch 14/200, Iteration 145/250, Loss: 0.0176\n",
      "Epoch 14/200, Iteration 146/250, Loss: 0.0333\n",
      "Epoch 14/200, Iteration 147/250, Loss: 0.0093\n",
      "Epoch 14/200, Iteration 148/250, Loss: 0.0225\n",
      "Epoch 14/200, Iteration 149/250, Loss: 0.0102\n",
      "Epoch 14/200, Iteration 150/250, Loss: 0.0322\n",
      "Epoch 14/200, Iteration 151/250, Loss: 0.0113\n",
      "Epoch 14/200, Iteration 152/250, Loss: 0.0305\n",
      "Epoch 14/200, Iteration 153/250, Loss: 0.0142\n",
      "Epoch 14/200, Iteration 154/250, Loss: 0.0195\n",
      "Epoch 14/200, Iteration 155/250, Loss: 0.0471\n",
      "Epoch 14/200, Iteration 156/250, Loss: 0.0131\n",
      "Epoch 14/200, Iteration 157/250, Loss: 0.0348\n",
      "Epoch 14/200, Iteration 158/250, Loss: 0.0113\n",
      "Epoch 14/200, Iteration 159/250, Loss: 0.0183\n",
      "Epoch 14/200, Iteration 160/250, Loss: 0.0223\n",
      "Epoch 14/200, Iteration 161/250, Loss: 0.0396\n",
      "Epoch 14/200, Iteration 162/250, Loss: 0.0147\n",
      "Epoch 14/200, Iteration 163/250, Loss: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Iteration 164/250, Loss: 0.0184\n",
      "Epoch 14/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 14/200, Iteration 166/250, Loss: 0.0195\n",
      "Epoch 14/200, Iteration 167/250, Loss: 0.0222\n",
      "Epoch 14/200, Iteration 168/250, Loss: 0.0178\n",
      "Epoch 14/200, Iteration 169/250, Loss: 0.0114\n",
      "Epoch 14/200, Iteration 170/250, Loss: 0.0146\n",
      "Epoch 14/200, Iteration 171/250, Loss: 0.0159\n",
      "Epoch 14/200, Iteration 172/250, Loss: 0.0314\n",
      "Epoch 14/200, Iteration 173/250, Loss: 0.0365\n",
      "Epoch 14/200, Iteration 174/250, Loss: 0.0138\n",
      "Epoch 14/200, Iteration 175/250, Loss: 0.0301\n",
      "Epoch 14/200, Iteration 176/250, Loss: 0.0318\n",
      "Epoch 14/200, Iteration 177/250, Loss: 0.0141\n",
      "Epoch 14/200, Iteration 178/250, Loss: 0.0121\n",
      "Epoch 14/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 14/200, Iteration 180/250, Loss: 0.0366\n",
      "Epoch 14/200, Iteration 181/250, Loss: 0.0334\n",
      "Epoch 14/200, Iteration 182/250, Loss: 0.0439\n",
      "Epoch 14/200, Iteration 183/250, Loss: 0.0293\n",
      "Epoch 14/200, Iteration 184/250, Loss: 0.0346\n",
      "Epoch 14/200, Iteration 185/250, Loss: 0.0164\n",
      "Epoch 14/200, Iteration 186/250, Loss: 0.0352\n",
      "Epoch 14/200, Iteration 187/250, Loss: 0.0170\n",
      "Epoch 14/200, Iteration 188/250, Loss: 0.0281\n",
      "Epoch 14/200, Iteration 189/250, Loss: 0.0280\n",
      "Epoch 14/200, Iteration 190/250, Loss: 0.0127\n",
      "Epoch 14/200, Iteration 191/250, Loss: 0.0268\n",
      "Epoch 14/200, Iteration 192/250, Loss: 0.0203\n",
      "Epoch 14/200, Iteration 193/250, Loss: 0.0145\n",
      "Epoch 14/200, Iteration 194/250, Loss: 0.0240\n",
      "Epoch 14/200, Iteration 195/250, Loss: 0.0276\n",
      "Epoch 14/200, Iteration 196/250, Loss: 0.0326\n",
      "Epoch 14/200, Iteration 197/250, Loss: 0.0313\n",
      "Epoch 14/200, Iteration 198/250, Loss: 0.0224\n",
      "Epoch 14/200, Iteration 199/250, Loss: 0.0198\n",
      "Epoch 14/200, Iteration 200/250, Loss: 0.0270\n",
      "Epoch 14/200, Iteration 201/250, Loss: 0.0172\n",
      "Epoch 14/200, Iteration 202/250, Loss: 0.0164\n",
      "Epoch 14/200, Iteration 203/250, Loss: 0.0302\n",
      "Epoch 14/200, Iteration 204/250, Loss: 0.0118\n",
      "Epoch 14/200, Iteration 205/250, Loss: 0.0475\n",
      "Epoch 14/200, Iteration 206/250, Loss: 0.0245\n",
      "Epoch 14/200, Iteration 207/250, Loss: 0.0122\n",
      "Epoch 14/200, Iteration 208/250, Loss: 0.0155\n",
      "Epoch 14/200, Iteration 209/250, Loss: 0.0233\n",
      "Epoch 14/200, Iteration 210/250, Loss: 0.0169\n",
      "Epoch 14/200, Iteration 211/250, Loss: 0.0124\n",
      "Epoch 14/200, Iteration 212/250, Loss: 0.0173\n",
      "Epoch 14/200, Iteration 213/250, Loss: 0.0190\n",
      "Epoch 14/200, Iteration 214/250, Loss: 0.0167\n",
      "Epoch 14/200, Iteration 215/250, Loss: 0.0206\n",
      "Epoch 14/200, Iteration 216/250, Loss: 0.0122\n",
      "Epoch 14/200, Iteration 217/250, Loss: 0.0188\n",
      "Epoch 14/200, Iteration 218/250, Loss: 0.0367\n",
      "Epoch 14/200, Iteration 219/250, Loss: 0.0193\n",
      "Epoch 14/200, Iteration 220/250, Loss: 0.0267\n",
      "Epoch 14/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 14/200, Iteration 222/250, Loss: 0.0147\n",
      "Epoch 14/200, Iteration 223/250, Loss: 0.0217\n",
      "Epoch 14/200, Iteration 224/250, Loss: 0.0317\n",
      "Epoch 14/200, Iteration 225/250, Loss: 0.0550\n",
      "Epoch 14/200, Iteration 226/250, Loss: 0.0302\n",
      "Epoch 14/200, Iteration 227/250, Loss: 0.0176\n",
      "Epoch 14/200, Iteration 228/250, Loss: 0.0287\n",
      "Epoch 14/200, Iteration 229/250, Loss: 0.0248\n",
      "Epoch 14/200, Iteration 230/250, Loss: 0.0426\n",
      "Epoch 14/200, Iteration 231/250, Loss: 0.0259\n",
      "Epoch 14/200, Iteration 232/250, Loss: 0.0137\n",
      "Epoch 14/200, Iteration 233/250, Loss: 0.0173\n",
      "Epoch 14/200, Iteration 234/250, Loss: 0.0273\n",
      "Epoch 14/200, Iteration 235/250, Loss: 0.0178\n",
      "Epoch 14/200, Iteration 236/250, Loss: 0.0162\n",
      "Epoch 14/200, Iteration 237/250, Loss: 0.0203\n",
      "Epoch 14/200, Iteration 238/250, Loss: 0.0307\n",
      "Epoch 14/200, Iteration 239/250, Loss: 0.0460\n",
      "Epoch 14/200, Iteration 240/250, Loss: 0.0364\n",
      "Epoch 14/200, Iteration 241/250, Loss: 0.0245\n",
      "Epoch 14/200, Iteration 242/250, Loss: 0.0127\n",
      "Epoch 14/200, Iteration 243/250, Loss: 0.0209\n",
      "Epoch 14/200, Iteration 244/250, Loss: 0.0165\n",
      "Epoch 14/200, Iteration 245/250, Loss: 0.0132\n",
      "Epoch 14/200, Iteration 246/250, Loss: 0.0291\n",
      "Epoch 14/200, Iteration 247/250, Loss: 0.0096\n",
      "Epoch 14/200, Iteration 248/250, Loss: 0.0170\n",
      "Epoch 14/200, Iteration 249/250, Loss: 0.0428\n",
      "Epoch 14/200, Iteration 250/250, Loss: 0.0188\n",
      "Train Error: \n",
      " Accuracy: 92.45%, Avg loss: 0.019085, MRE: 1.613413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.018623, MRE: 2.324489 \n",
      "\n",
      "Epoch 15/200, Iteration 1/250, Loss: 0.0116\n",
      "Epoch 15/200, Iteration 2/250, Loss: 0.0398\n",
      "Epoch 15/200, Iteration 3/250, Loss: 0.0300\n",
      "Epoch 15/200, Iteration 4/250, Loss: 0.0196\n",
      "Epoch 15/200, Iteration 5/250, Loss: 0.0124\n",
      "Epoch 15/200, Iteration 6/250, Loss: 0.0319\n",
      "Epoch 15/200, Iteration 7/250, Loss: 0.0232\n",
      "Epoch 15/200, Iteration 8/250, Loss: 0.0295\n",
      "Epoch 15/200, Iteration 9/250, Loss: 0.0287\n",
      "Epoch 15/200, Iteration 10/250, Loss: 0.0388\n",
      "Epoch 15/200, Iteration 11/250, Loss: 0.0233\n",
      "Epoch 15/200, Iteration 12/250, Loss: 0.0199\n",
      "Epoch 15/200, Iteration 13/250, Loss: 0.0134\n",
      "Epoch 15/200, Iteration 14/250, Loss: 0.0330\n",
      "Epoch 15/200, Iteration 15/250, Loss: 0.0221\n",
      "Epoch 15/200, Iteration 16/250, Loss: 0.0488\n",
      "Epoch 15/200, Iteration 17/250, Loss: 0.0285\n",
      "Epoch 15/200, Iteration 18/250, Loss: 0.0151\n",
      "Epoch 15/200, Iteration 19/250, Loss: 0.0189\n",
      "Epoch 15/200, Iteration 20/250, Loss: 0.0195\n",
      "Epoch 15/200, Iteration 21/250, Loss: 0.0222\n",
      "Epoch 15/200, Iteration 22/250, Loss: 0.0370\n",
      "Epoch 15/200, Iteration 23/250, Loss: 0.0166\n",
      "Epoch 15/200, Iteration 24/250, Loss: 0.0198\n",
      "Epoch 15/200, Iteration 25/250, Loss: 0.0180\n",
      "Epoch 15/200, Iteration 26/250, Loss: 0.0144\n",
      "Epoch 15/200, Iteration 27/250, Loss: 0.0232\n",
      "Epoch 15/200, Iteration 28/250, Loss: 0.0248\n",
      "Epoch 15/200, Iteration 29/250, Loss: 0.0391\n",
      "Epoch 15/200, Iteration 30/250, Loss: 0.0252\n",
      "Epoch 15/200, Iteration 31/250, Loss: 0.0262\n",
      "Epoch 15/200, Iteration 32/250, Loss: 0.0220\n",
      "Epoch 15/200, Iteration 33/250, Loss: 0.0190\n",
      "Epoch 15/200, Iteration 34/250, Loss: 0.0168\n",
      "Epoch 15/200, Iteration 35/250, Loss: 0.0145\n",
      "Epoch 15/200, Iteration 36/250, Loss: 0.0357\n",
      "Epoch 15/200, Iteration 37/250, Loss: 0.0333\n",
      "Epoch 15/200, Iteration 38/250, Loss: 0.0579\n",
      "Epoch 15/200, Iteration 39/250, Loss: 0.0337\n",
      "Epoch 15/200, Iteration 40/250, Loss: 0.0261\n",
      "Epoch 15/200, Iteration 41/250, Loss: 0.0169\n",
      "Epoch 15/200, Iteration 42/250, Loss: 0.0145\n",
      "Epoch 15/200, Iteration 43/250, Loss: 0.0242\n",
      "Epoch 15/200, Iteration 44/250, Loss: 0.0241\n",
      "Epoch 15/200, Iteration 45/250, Loss: 0.0200\n",
      "Epoch 15/200, Iteration 46/250, Loss: 0.0403\n",
      "Epoch 15/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 15/200, Iteration 48/250, Loss: 0.0169\n",
      "Epoch 15/200, Iteration 49/250, Loss: 0.0197\n",
      "Epoch 15/200, Iteration 50/250, Loss: 0.0141\n",
      "Epoch 15/200, Iteration 51/250, Loss: 0.0198\n",
      "Epoch 15/200, Iteration 52/250, Loss: 0.0229\n",
      "Epoch 15/200, Iteration 53/250, Loss: 0.0156\n",
      "Epoch 15/200, Iteration 54/250, Loss: 0.0148\n",
      "Epoch 15/200, Iteration 55/250, Loss: 0.0124\n",
      "Epoch 15/200, Iteration 56/250, Loss: 0.0160\n",
      "Epoch 15/200, Iteration 57/250, Loss: 0.0408\n",
      "Epoch 15/200, Iteration 58/250, Loss: 0.0207\n",
      "Epoch 15/200, Iteration 59/250, Loss: 0.0241\n",
      "Epoch 15/200, Iteration 60/250, Loss: 0.0383\n",
      "Epoch 15/200, Iteration 61/250, Loss: 0.0264\n",
      "Epoch 15/200, Iteration 62/250, Loss: 0.0284\n",
      "Epoch 15/200, Iteration 63/250, Loss: 0.0145\n",
      "Epoch 15/200, Iteration 64/250, Loss: 0.0376\n",
      "Epoch 15/200, Iteration 65/250, Loss: 0.0264\n",
      "Epoch 15/200, Iteration 66/250, Loss: 0.0269\n",
      "Epoch 15/200, Iteration 67/250, Loss: 0.0128\n",
      "Epoch 15/200, Iteration 68/250, Loss: 0.0409\n",
      "Epoch 15/200, Iteration 69/250, Loss: 0.0220\n",
      "Epoch 15/200, Iteration 70/250, Loss: 0.0323\n",
      "Epoch 15/200, Iteration 71/250, Loss: 0.0156\n",
      "Epoch 15/200, Iteration 72/250, Loss: 0.0337\n",
      "Epoch 15/200, Iteration 73/250, Loss: 0.0149\n",
      "Epoch 15/200, Iteration 74/250, Loss: 0.0109\n",
      "Epoch 15/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 15/200, Iteration 76/250, Loss: 0.0290\n",
      "Epoch 15/200, Iteration 77/250, Loss: 0.0190\n",
      "Epoch 15/200, Iteration 78/250, Loss: 0.0257\n",
      "Epoch 15/200, Iteration 79/250, Loss: 0.0163\n",
      "Epoch 15/200, Iteration 80/250, Loss: 0.0184\n",
      "Epoch 15/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 15/200, Iteration 82/250, Loss: 0.0118\n",
      "Epoch 15/200, Iteration 83/250, Loss: 0.0119\n",
      "Epoch 15/200, Iteration 84/250, Loss: 0.0082\n",
      "Epoch 15/200, Iteration 85/250, Loss: 0.0143\n",
      "Epoch 15/200, Iteration 86/250, Loss: 0.0112\n",
      "Epoch 15/200, Iteration 87/250, Loss: 0.0140\n",
      "Epoch 15/200, Iteration 88/250, Loss: 0.0130\n",
      "Epoch 15/200, Iteration 89/250, Loss: 0.0291\n",
      "Epoch 15/200, Iteration 90/250, Loss: 0.0151\n",
      "Epoch 15/200, Iteration 91/250, Loss: 0.0185\n",
      "Epoch 15/200, Iteration 92/250, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Iteration 93/250, Loss: 0.0107\n",
      "Epoch 15/200, Iteration 94/250, Loss: 0.0284\n",
      "Epoch 15/200, Iteration 95/250, Loss: 0.0115\n",
      "Epoch 15/200, Iteration 96/250, Loss: 0.0301\n",
      "Epoch 15/200, Iteration 97/250, Loss: 0.0167\n",
      "Epoch 15/200, Iteration 98/250, Loss: 0.0128\n",
      "Epoch 15/200, Iteration 99/250, Loss: 0.0180\n",
      "Epoch 15/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 15/200, Iteration 101/250, Loss: 0.0181\n",
      "Epoch 15/200, Iteration 102/250, Loss: 0.0191\n",
      "Epoch 15/200, Iteration 103/250, Loss: 0.0162\n",
      "Epoch 15/200, Iteration 104/250, Loss: 0.0240\n",
      "Epoch 15/200, Iteration 105/250, Loss: 0.0173\n",
      "Epoch 15/200, Iteration 106/250, Loss: 0.0269\n",
      "Epoch 15/200, Iteration 107/250, Loss: 0.0257\n",
      "Epoch 15/200, Iteration 108/250, Loss: 0.0212\n",
      "Epoch 15/200, Iteration 109/250, Loss: 0.0198\n",
      "Epoch 15/200, Iteration 110/250, Loss: 0.0168\n",
      "Epoch 15/200, Iteration 111/250, Loss: 0.0152\n",
      "Epoch 15/200, Iteration 112/250, Loss: 0.0274\n",
      "Epoch 15/200, Iteration 113/250, Loss: 0.0166\n",
      "Epoch 15/200, Iteration 114/250, Loss: 0.0131\n",
      "Epoch 15/200, Iteration 115/250, Loss: 0.0578\n",
      "Epoch 15/200, Iteration 116/250, Loss: 0.0299\n",
      "Epoch 15/200, Iteration 117/250, Loss: 0.0198\n",
      "Epoch 15/200, Iteration 118/250, Loss: 0.0170\n",
      "Epoch 15/200, Iteration 119/250, Loss: 0.0219\n",
      "Epoch 15/200, Iteration 120/250, Loss: 0.0134\n",
      "Epoch 15/200, Iteration 121/250, Loss: 0.0111\n",
      "Epoch 15/200, Iteration 122/250, Loss: 0.0189\n",
      "Epoch 15/200, Iteration 123/250, Loss: 0.0156\n",
      "Epoch 15/200, Iteration 124/250, Loss: 0.0134\n",
      "Epoch 15/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 15/200, Iteration 126/250, Loss: 0.0294\n",
      "Epoch 15/200, Iteration 127/250, Loss: 0.0104\n",
      "Epoch 15/200, Iteration 128/250, Loss: 0.0396\n",
      "Epoch 15/200, Iteration 129/250, Loss: 0.0146\n",
      "Epoch 15/200, Iteration 130/250, Loss: 0.0137\n",
      "Epoch 15/200, Iteration 131/250, Loss: 0.0156\n",
      "Epoch 15/200, Iteration 132/250, Loss: 0.0191\n",
      "Epoch 15/200, Iteration 133/250, Loss: 0.0219\n",
      "Epoch 15/200, Iteration 134/250, Loss: 0.0277\n",
      "Epoch 15/200, Iteration 135/250, Loss: 0.0397\n",
      "Epoch 15/200, Iteration 136/250, Loss: 0.0264\n",
      "Epoch 15/200, Iteration 137/250, Loss: 0.0164\n",
      "Epoch 15/200, Iteration 138/250, Loss: 0.0188\n",
      "Epoch 15/200, Iteration 139/250, Loss: 0.0340\n",
      "Epoch 15/200, Iteration 140/250, Loss: 0.0161\n",
      "Epoch 15/200, Iteration 141/250, Loss: 0.0173\n",
      "Epoch 15/200, Iteration 142/250, Loss: 0.0193\n",
      "Epoch 15/200, Iteration 143/250, Loss: 0.0422\n",
      "Epoch 15/200, Iteration 144/250, Loss: 0.0451\n",
      "Epoch 15/200, Iteration 145/250, Loss: 0.0225\n",
      "Epoch 15/200, Iteration 146/250, Loss: 0.0263\n",
      "Epoch 15/200, Iteration 147/250, Loss: 0.0417\n",
      "Epoch 15/200, Iteration 148/250, Loss: 0.0228\n",
      "Epoch 15/200, Iteration 149/250, Loss: 0.0294\n",
      "Epoch 15/200, Iteration 150/250, Loss: 0.0284\n",
      "Epoch 15/200, Iteration 151/250, Loss: 0.0316\n",
      "Epoch 15/200, Iteration 152/250, Loss: 0.0254\n",
      "Epoch 15/200, Iteration 153/250, Loss: 0.0478\n",
      "Epoch 15/200, Iteration 154/250, Loss: 0.0136\n",
      "Epoch 15/200, Iteration 155/250, Loss: 0.0188\n",
      "Epoch 15/200, Iteration 156/250, Loss: 0.0095\n",
      "Epoch 15/200, Iteration 157/250, Loss: 0.0264\n",
      "Epoch 15/200, Iteration 158/250, Loss: 0.0217\n",
      "Epoch 15/200, Iteration 159/250, Loss: 0.0161\n",
      "Epoch 15/200, Iteration 160/250, Loss: 0.0128\n",
      "Epoch 15/200, Iteration 161/250, Loss: 0.0374\n",
      "Epoch 15/200, Iteration 162/250, Loss: 0.0202\n",
      "Epoch 15/200, Iteration 163/250, Loss: 0.0411\n",
      "Epoch 15/200, Iteration 164/250, Loss: 0.0575\n",
      "Epoch 15/200, Iteration 165/250, Loss: 0.0544\n",
      "Epoch 15/200, Iteration 166/250, Loss: 0.0352\n",
      "Epoch 15/200, Iteration 167/250, Loss: 0.0337\n",
      "Epoch 15/200, Iteration 168/250, Loss: 0.0560\n",
      "Epoch 15/200, Iteration 169/250, Loss: 0.0365\n",
      "Epoch 15/200, Iteration 170/250, Loss: 0.0478\n",
      "Epoch 15/200, Iteration 171/250, Loss: 0.0201\n",
      "Epoch 15/200, Iteration 172/250, Loss: 0.0949\n",
      "Epoch 15/200, Iteration 173/250, Loss: 0.0512\n",
      "Epoch 15/200, Iteration 174/250, Loss: 0.0247\n",
      "Epoch 15/200, Iteration 175/250, Loss: 0.0278\n",
      "Epoch 15/200, Iteration 176/250, Loss: 0.0317\n",
      "Epoch 15/200, Iteration 177/250, Loss: 0.0183\n",
      "Epoch 15/200, Iteration 178/250, Loss: 0.0288\n",
      "Epoch 15/200, Iteration 179/250, Loss: 0.0415\n",
      "Epoch 15/200, Iteration 180/250, Loss: 0.0741\n",
      "Epoch 15/200, Iteration 181/250, Loss: 0.0248\n",
      "Epoch 15/200, Iteration 182/250, Loss: 0.0249\n",
      "Epoch 15/200, Iteration 183/250, Loss: 0.0328\n",
      "Epoch 15/200, Iteration 184/250, Loss: 0.0201\n",
      "Epoch 15/200, Iteration 185/250, Loss: 0.0487\n",
      "Epoch 15/200, Iteration 186/250, Loss: 0.0417\n",
      "Epoch 15/200, Iteration 187/250, Loss: 0.0357\n",
      "Epoch 15/200, Iteration 188/250, Loss: 0.0206\n",
      "Epoch 15/200, Iteration 189/250, Loss: 0.0195\n",
      "Epoch 15/200, Iteration 190/250, Loss: 0.0196\n",
      "Epoch 15/200, Iteration 191/250, Loss: 0.0252\n",
      "Epoch 15/200, Iteration 192/250, Loss: 0.0240\n",
      "Epoch 15/200, Iteration 193/250, Loss: 0.0209\n",
      "Epoch 15/200, Iteration 194/250, Loss: 0.0183\n",
      "Epoch 15/200, Iteration 195/250, Loss: 0.0331\n",
      "Epoch 15/200, Iteration 196/250, Loss: 0.0364\n",
      "Epoch 15/200, Iteration 197/250, Loss: 0.0494\n",
      "Epoch 15/200, Iteration 198/250, Loss: 0.0210\n",
      "Epoch 15/200, Iteration 199/250, Loss: 0.0383\n",
      "Epoch 15/200, Iteration 200/250, Loss: 0.0360\n",
      "Epoch 15/200, Iteration 201/250, Loss: 0.0345\n",
      "Epoch 15/200, Iteration 202/250, Loss: 0.0174\n",
      "Epoch 15/200, Iteration 203/250, Loss: 0.0185\n",
      "Epoch 15/200, Iteration 204/250, Loss: 0.0482\n",
      "Epoch 15/200, Iteration 205/250, Loss: 0.0323\n",
      "Epoch 15/200, Iteration 206/250, Loss: 0.0341\n",
      "Epoch 15/200, Iteration 207/250, Loss: 0.0262\n",
      "Epoch 15/200, Iteration 208/250, Loss: 0.0250\n",
      "Epoch 15/200, Iteration 209/250, Loss: 0.0292\n",
      "Epoch 15/200, Iteration 210/250, Loss: 0.0465\n",
      "Epoch 15/200, Iteration 211/250, Loss: 0.0210\n",
      "Epoch 15/200, Iteration 212/250, Loss: 0.0251\n",
      "Epoch 15/200, Iteration 213/250, Loss: 0.0239\n",
      "Epoch 15/200, Iteration 214/250, Loss: 0.0306\n",
      "Epoch 15/200, Iteration 215/250, Loss: 0.0312\n",
      "Epoch 15/200, Iteration 216/250, Loss: 0.0240\n",
      "Epoch 15/200, Iteration 217/250, Loss: 0.0430\n",
      "Epoch 15/200, Iteration 218/250, Loss: 0.0284\n",
      "Epoch 15/200, Iteration 219/250, Loss: 0.0123\n",
      "Epoch 15/200, Iteration 220/250, Loss: 0.0277\n",
      "Epoch 15/200, Iteration 221/250, Loss: 0.0455\n",
      "Epoch 15/200, Iteration 222/250, Loss: 0.0272\n",
      "Epoch 15/200, Iteration 223/250, Loss: 0.0126\n",
      "Epoch 15/200, Iteration 224/250, Loss: 0.0193\n",
      "Epoch 15/200, Iteration 225/250, Loss: 0.0360\n",
      "Epoch 15/200, Iteration 226/250, Loss: 0.0234\n",
      "Epoch 15/200, Iteration 227/250, Loss: 0.0184\n",
      "Epoch 15/200, Iteration 228/250, Loss: 0.0399\n",
      "Epoch 15/200, Iteration 229/250, Loss: 0.0354\n",
      "Epoch 15/200, Iteration 230/250, Loss: 0.0276\n",
      "Epoch 15/200, Iteration 231/250, Loss: 0.0328\n",
      "Epoch 15/200, Iteration 232/250, Loss: 0.0469\n",
      "Epoch 15/200, Iteration 233/250, Loss: 0.0176\n",
      "Epoch 15/200, Iteration 234/250, Loss: 0.0229\n",
      "Epoch 15/200, Iteration 235/250, Loss: 0.0153\n",
      "Epoch 15/200, Iteration 236/250, Loss: 0.0147\n",
      "Epoch 15/200, Iteration 237/250, Loss: 0.0261\n",
      "Epoch 15/200, Iteration 238/250, Loss: 0.0241\n",
      "Epoch 15/200, Iteration 239/250, Loss: 0.0119\n",
      "Epoch 15/200, Iteration 240/250, Loss: 0.0171\n",
      "Epoch 15/200, Iteration 241/250, Loss: 0.0199\n",
      "Epoch 15/200, Iteration 242/250, Loss: 0.0167\n",
      "Epoch 15/200, Iteration 243/250, Loss: 0.0240\n",
      "Epoch 15/200, Iteration 244/250, Loss: 0.0105\n",
      "Epoch 15/200, Iteration 245/250, Loss: 0.0320\n",
      "Epoch 15/200, Iteration 246/250, Loss: 0.0116\n",
      "Epoch 15/200, Iteration 247/250, Loss: 0.0238\n",
      "Epoch 15/200, Iteration 248/250, Loss: 0.0124\n",
      "Epoch 15/200, Iteration 249/250, Loss: 0.0307\n",
      "Epoch 15/200, Iteration 250/250, Loss: 0.0204\n",
      "Train Error: \n",
      " Accuracy: 53.67%, Avg loss: 0.013886, MRE: 1.276717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.25%, Avg loss: 0.013954, MRE: 1.472809 \n",
      "\n",
      "Epoch 16/200, Iteration 1/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 2/250, Loss: 0.0132\n",
      "Epoch 16/200, Iteration 3/250, Loss: 0.0213\n",
      "Epoch 16/200, Iteration 4/250, Loss: 0.0205\n",
      "Epoch 16/200, Iteration 5/250, Loss: 0.0242\n",
      "Epoch 16/200, Iteration 6/250, Loss: 0.0236\n",
      "Epoch 16/200, Iteration 7/250, Loss: 0.0372\n",
      "Epoch 16/200, Iteration 8/250, Loss: 0.0134\n",
      "Epoch 16/200, Iteration 9/250, Loss: 0.0305\n",
      "Epoch 16/200, Iteration 10/250, Loss: 0.0370\n",
      "Epoch 16/200, Iteration 11/250, Loss: 0.0220\n",
      "Epoch 16/200, Iteration 12/250, Loss: 0.0161\n",
      "Epoch 16/200, Iteration 13/250, Loss: 0.0127\n",
      "Epoch 16/200, Iteration 14/250, Loss: 0.0315\n",
      "Epoch 16/200, Iteration 15/250, Loss: 0.0263\n",
      "Epoch 16/200, Iteration 16/250, Loss: 0.0217\n",
      "Epoch 16/200, Iteration 17/250, Loss: 0.0155\n",
      "Epoch 16/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 16/200, Iteration 19/250, Loss: 0.0213\n",
      "Epoch 16/200, Iteration 20/250, Loss: 0.0270\n",
      "Epoch 16/200, Iteration 21/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 22/250, Loss: 0.0526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Iteration 23/250, Loss: 0.0230\n",
      "Epoch 16/200, Iteration 24/250, Loss: 0.0323\n",
      "Epoch 16/200, Iteration 25/250, Loss: 0.0302\n",
      "Epoch 16/200, Iteration 26/250, Loss: 0.0154\n",
      "Epoch 16/200, Iteration 27/250, Loss: 0.0176\n",
      "Epoch 16/200, Iteration 28/250, Loss: 0.0209\n",
      "Epoch 16/200, Iteration 29/250, Loss: 0.0132\n",
      "Epoch 16/200, Iteration 30/250, Loss: 0.0312\n",
      "Epoch 16/200, Iteration 31/250, Loss: 0.0198\n",
      "Epoch 16/200, Iteration 32/250, Loss: 0.0446\n",
      "Epoch 16/200, Iteration 33/250, Loss: 0.0277\n",
      "Epoch 16/200, Iteration 34/250, Loss: 0.0191\n",
      "Epoch 16/200, Iteration 35/250, Loss: 0.0189\n",
      "Epoch 16/200, Iteration 36/250, Loss: 0.0208\n",
      "Epoch 16/200, Iteration 37/250, Loss: 0.0173\n",
      "Epoch 16/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 16/200, Iteration 39/250, Loss: 0.0399\n",
      "Epoch 16/200, Iteration 40/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 41/250, Loss: 0.0354\n",
      "Epoch 16/200, Iteration 42/250, Loss: 0.0426\n",
      "Epoch 16/200, Iteration 43/250, Loss: 0.0311\n",
      "Epoch 16/200, Iteration 44/250, Loss: 0.0271\n",
      "Epoch 16/200, Iteration 45/250, Loss: 0.0204\n",
      "Epoch 16/200, Iteration 46/250, Loss: 0.0188\n",
      "Epoch 16/200, Iteration 47/250, Loss: 0.0226\n",
      "Epoch 16/200, Iteration 48/250, Loss: 0.0174\n",
      "Epoch 16/200, Iteration 49/250, Loss: 0.0160\n",
      "Epoch 16/200, Iteration 50/250, Loss: 0.0410\n",
      "Epoch 16/200, Iteration 51/250, Loss: 0.0543\n",
      "Epoch 16/200, Iteration 52/250, Loss: 0.0216\n",
      "Epoch 16/200, Iteration 53/250, Loss: 0.0276\n",
      "Epoch 16/200, Iteration 54/250, Loss: 0.0422\n",
      "Epoch 16/200, Iteration 55/250, Loss: 0.0228\n",
      "Epoch 16/200, Iteration 56/250, Loss: 0.0338\n",
      "Epoch 16/200, Iteration 57/250, Loss: 0.0225\n",
      "Epoch 16/200, Iteration 58/250, Loss: 0.0502\n",
      "Epoch 16/200, Iteration 59/250, Loss: 0.0642\n",
      "Epoch 16/200, Iteration 60/250, Loss: 0.0555\n",
      "Epoch 16/200, Iteration 61/250, Loss: 0.0373\n",
      "Epoch 16/200, Iteration 62/250, Loss: 0.0148\n",
      "Epoch 16/200, Iteration 63/250, Loss: 0.0410\n",
      "Epoch 16/200, Iteration 64/250, Loss: 0.0460\n",
      "Epoch 16/200, Iteration 65/250, Loss: 0.0376\n",
      "Epoch 16/200, Iteration 66/250, Loss: 0.0322\n",
      "Epoch 16/200, Iteration 67/250, Loss: 0.0584\n",
      "Epoch 16/200, Iteration 68/250, Loss: 0.0570\n",
      "Epoch 16/200, Iteration 69/250, Loss: 0.0368\n",
      "Epoch 16/200, Iteration 70/250, Loss: 0.0649\n",
      "Epoch 16/200, Iteration 71/250, Loss: 0.0309\n",
      "Epoch 16/200, Iteration 72/250, Loss: 0.0263\n",
      "Epoch 16/200, Iteration 73/250, Loss: 0.0391\n",
      "Epoch 16/200, Iteration 74/250, Loss: 0.0551\n",
      "Epoch 16/200, Iteration 75/250, Loss: 0.0155\n",
      "Epoch 16/200, Iteration 76/250, Loss: 0.0271\n",
      "Epoch 16/200, Iteration 77/250, Loss: 0.0295\n",
      "Epoch 16/200, Iteration 78/250, Loss: 0.0219\n",
      "Epoch 16/200, Iteration 79/250, Loss: 0.0310\n",
      "Epoch 16/200, Iteration 80/250, Loss: 0.0239\n",
      "Epoch 16/200, Iteration 81/250, Loss: 0.0746\n",
      "Epoch 16/200, Iteration 82/250, Loss: 0.0268\n",
      "Epoch 16/200, Iteration 83/250, Loss: 0.0331\n",
      "Epoch 16/200, Iteration 84/250, Loss: 0.0188\n",
      "Epoch 16/200, Iteration 85/250, Loss: 0.0356\n",
      "Epoch 16/200, Iteration 86/250, Loss: 0.0452\n",
      "Epoch 16/200, Iteration 87/250, Loss: 0.0178\n",
      "Epoch 16/200, Iteration 88/250, Loss: 0.0177\n",
      "Epoch 16/200, Iteration 89/250, Loss: 0.0272\n",
      "Epoch 16/200, Iteration 90/250, Loss: 0.0158\n",
      "Epoch 16/200, Iteration 91/250, Loss: 0.0130\n",
      "Epoch 16/200, Iteration 92/250, Loss: 0.0288\n",
      "Epoch 16/200, Iteration 93/250, Loss: 0.0277\n",
      "Epoch 16/200, Iteration 94/250, Loss: 0.0177\n",
      "Epoch 16/200, Iteration 95/250, Loss: 0.0417\n",
      "Epoch 16/200, Iteration 96/250, Loss: 0.0236\n",
      "Epoch 16/200, Iteration 97/250, Loss: 0.0430\n",
      "Epoch 16/200, Iteration 98/250, Loss: 0.0167\n",
      "Epoch 16/200, Iteration 99/250, Loss: 0.0214\n",
      "Epoch 16/200, Iteration 100/250, Loss: 0.0417\n",
      "Epoch 16/200, Iteration 101/250, Loss: 0.0265\n",
      "Epoch 16/200, Iteration 102/250, Loss: 0.0196\n",
      "Epoch 16/200, Iteration 103/250, Loss: 0.0181\n",
      "Epoch 16/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 16/200, Iteration 105/250, Loss: 0.0198\n",
      "Epoch 16/200, Iteration 106/250, Loss: 0.0190\n",
      "Epoch 16/200, Iteration 107/250, Loss: 0.0182\n",
      "Epoch 16/200, Iteration 108/250, Loss: 0.0474\n",
      "Epoch 16/200, Iteration 109/250, Loss: 0.0204\n",
      "Epoch 16/200, Iteration 110/250, Loss: 0.0265\n",
      "Epoch 16/200, Iteration 111/250, Loss: 0.0197\n",
      "Epoch 16/200, Iteration 112/250, Loss: 0.0265\n",
      "Epoch 16/200, Iteration 113/250, Loss: 0.0330\n",
      "Epoch 16/200, Iteration 114/250, Loss: 0.0167\n",
      "Epoch 16/200, Iteration 115/250, Loss: 0.0242\n",
      "Epoch 16/200, Iteration 116/250, Loss: 0.0210\n",
      "Epoch 16/200, Iteration 117/250, Loss: 0.0316\n",
      "Epoch 16/200, Iteration 118/250, Loss: 0.0287\n",
      "Epoch 16/200, Iteration 119/250, Loss: 0.0222\n",
      "Epoch 16/200, Iteration 120/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 121/250, Loss: 0.0247\n",
      "Epoch 16/200, Iteration 122/250, Loss: 0.0153\n",
      "Epoch 16/200, Iteration 123/250, Loss: 0.0315\n",
      "Epoch 16/200, Iteration 124/250, Loss: 0.0373\n",
      "Epoch 16/200, Iteration 125/250, Loss: 0.0303\n",
      "Epoch 16/200, Iteration 126/250, Loss: 0.0212\n",
      "Epoch 16/200, Iteration 127/250, Loss: 0.0300\n",
      "Epoch 16/200, Iteration 128/250, Loss: 0.0182\n",
      "Epoch 16/200, Iteration 129/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 130/250, Loss: 0.0277\n",
      "Epoch 16/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 16/200, Iteration 132/250, Loss: 0.0346\n",
      "Epoch 16/200, Iteration 133/250, Loss: 0.0411\n",
      "Epoch 16/200, Iteration 134/250, Loss: 0.0447\n",
      "Epoch 16/200, Iteration 135/250, Loss: 0.0180\n",
      "Epoch 16/200, Iteration 136/250, Loss: 0.0308\n",
      "Epoch 16/200, Iteration 137/250, Loss: 0.0299\n",
      "Epoch 16/200, Iteration 138/250, Loss: 0.0142\n",
      "Epoch 16/200, Iteration 139/250, Loss: 0.0262\n",
      "Epoch 16/200, Iteration 140/250, Loss: 0.0239\n",
      "Epoch 16/200, Iteration 141/250, Loss: 0.0370\n",
      "Epoch 16/200, Iteration 142/250, Loss: 0.0278\n",
      "Epoch 16/200, Iteration 143/250, Loss: 0.0182\n",
      "Epoch 16/200, Iteration 144/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 145/250, Loss: 0.0410\n",
      "Epoch 16/200, Iteration 146/250, Loss: 0.0272\n",
      "Epoch 16/200, Iteration 147/250, Loss: 0.0315\n",
      "Epoch 16/200, Iteration 148/250, Loss: 0.0302\n",
      "Epoch 16/200, Iteration 149/250, Loss: 0.0262\n",
      "Epoch 16/200, Iteration 150/250, Loss: 0.0200\n",
      "Epoch 16/200, Iteration 151/250, Loss: 0.0382\n",
      "Epoch 16/200, Iteration 152/250, Loss: 0.0336\n",
      "Epoch 16/200, Iteration 153/250, Loss: 0.0252\n",
      "Epoch 16/200, Iteration 154/250, Loss: 0.0385\n",
      "Epoch 16/200, Iteration 155/250, Loss: 0.0257\n",
      "Epoch 16/200, Iteration 156/250, Loss: 0.0155\n",
      "Epoch 16/200, Iteration 157/250, Loss: 0.0463\n",
      "Epoch 16/200, Iteration 158/250, Loss: 0.0346\n",
      "Epoch 16/200, Iteration 159/250, Loss: 0.0615\n",
      "Epoch 16/200, Iteration 160/250, Loss: 0.0460\n",
      "Epoch 16/200, Iteration 161/250, Loss: 0.0137\n",
      "Epoch 16/200, Iteration 162/250, Loss: 0.0262\n",
      "Epoch 16/200, Iteration 163/250, Loss: 0.0398\n",
      "Epoch 16/200, Iteration 164/250, Loss: 0.0259\n",
      "Epoch 16/200, Iteration 165/250, Loss: 0.0316\n",
      "Epoch 16/200, Iteration 166/250, Loss: 0.0496\n",
      "Epoch 16/200, Iteration 167/250, Loss: 0.0232\n",
      "Epoch 16/200, Iteration 168/250, Loss: 0.0116\n",
      "Epoch 16/200, Iteration 169/250, Loss: 0.0230\n",
      "Epoch 16/200, Iteration 170/250, Loss: 0.0167\n",
      "Epoch 16/200, Iteration 171/250, Loss: 0.0137\n",
      "Epoch 16/200, Iteration 172/250, Loss: 0.0410\n",
      "Epoch 16/200, Iteration 173/250, Loss: 0.0142\n",
      "Epoch 16/200, Iteration 174/250, Loss: 0.0185\n",
      "Epoch 16/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 16/200, Iteration 176/250, Loss: 0.0200\n",
      "Epoch 16/200, Iteration 177/250, Loss: 0.0182\n",
      "Epoch 16/200, Iteration 178/250, Loss: 0.0348\n",
      "Epoch 16/200, Iteration 179/250, Loss: 0.0283\n",
      "Epoch 16/200, Iteration 180/250, Loss: 0.0212\n",
      "Epoch 16/200, Iteration 181/250, Loss: 0.0323\n",
      "Epoch 16/200, Iteration 182/250, Loss: 0.0314\n",
      "Epoch 16/200, Iteration 183/250, Loss: 0.0336\n",
      "Epoch 16/200, Iteration 184/250, Loss: 0.0500\n",
      "Epoch 16/200, Iteration 185/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 186/250, Loss: 0.0185\n",
      "Epoch 16/200, Iteration 187/250, Loss: 0.0184\n",
      "Epoch 16/200, Iteration 188/250, Loss: 0.0343\n",
      "Epoch 16/200, Iteration 189/250, Loss: 0.0247\n",
      "Epoch 16/200, Iteration 190/250, Loss: 0.0300\n",
      "Epoch 16/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 16/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 16/200, Iteration 193/250, Loss: 0.0120\n",
      "Epoch 16/200, Iteration 194/250, Loss: 0.0233\n",
      "Epoch 16/200, Iteration 195/250, Loss: 0.0238\n",
      "Epoch 16/200, Iteration 196/250, Loss: 0.0225\n",
      "Epoch 16/200, Iteration 197/250, Loss: 0.0576\n",
      "Epoch 16/200, Iteration 198/250, Loss: 0.0328\n",
      "Epoch 16/200, Iteration 199/250, Loss: 0.0307\n",
      "Epoch 16/200, Iteration 200/250, Loss: 0.0451\n",
      "Epoch 16/200, Iteration 201/250, Loss: 0.0404\n",
      "Epoch 16/200, Iteration 202/250, Loss: 0.0319\n",
      "Epoch 16/200, Iteration 203/250, Loss: 0.0285\n",
      "Epoch 16/200, Iteration 204/250, Loss: 0.0171\n",
      "Epoch 16/200, Iteration 205/250, Loss: 0.0434\n",
      "Epoch 16/200, Iteration 206/250, Loss: 0.0308\n",
      "Epoch 16/200, Iteration 207/250, Loss: 0.0275\n",
      "Epoch 16/200, Iteration 208/250, Loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Iteration 209/250, Loss: 0.0228\n",
      "Epoch 16/200, Iteration 210/250, Loss: 0.0220\n",
      "Epoch 16/200, Iteration 211/250, Loss: 0.0168\n",
      "Epoch 16/200, Iteration 212/250, Loss: 0.0240\n",
      "Epoch 16/200, Iteration 213/250, Loss: 0.0386\n",
      "Epoch 16/200, Iteration 214/250, Loss: 0.0198\n",
      "Epoch 16/200, Iteration 215/250, Loss: 0.0231\n",
      "Epoch 16/200, Iteration 216/250, Loss: 0.0264\n",
      "Epoch 16/200, Iteration 217/250, Loss: 0.0227\n",
      "Epoch 16/200, Iteration 218/250, Loss: 0.0105\n",
      "Epoch 16/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 16/200, Iteration 220/250, Loss: 0.0136\n",
      "Epoch 16/200, Iteration 221/250, Loss: 0.0243\n",
      "Epoch 16/200, Iteration 222/250, Loss: 0.0313\n",
      "Epoch 16/200, Iteration 223/250, Loss: 0.0258\n",
      "Epoch 16/200, Iteration 224/250, Loss: 0.0298\n",
      "Epoch 16/200, Iteration 225/250, Loss: 0.0316\n",
      "Epoch 16/200, Iteration 226/250, Loss: 0.0229\n",
      "Epoch 16/200, Iteration 227/250, Loss: 0.0201\n",
      "Epoch 16/200, Iteration 228/250, Loss: 0.0223\n",
      "Epoch 16/200, Iteration 229/250, Loss: 0.0324\n",
      "Epoch 16/200, Iteration 230/250, Loss: 0.0551\n",
      "Epoch 16/200, Iteration 231/250, Loss: 0.0591\n",
      "Epoch 16/200, Iteration 232/250, Loss: 0.0387\n",
      "Epoch 16/200, Iteration 233/250, Loss: 0.0193\n",
      "Epoch 16/200, Iteration 234/250, Loss: 0.0447\n",
      "Epoch 16/200, Iteration 235/250, Loss: 0.0318\n",
      "Epoch 16/200, Iteration 236/250, Loss: 0.0219\n",
      "Epoch 16/200, Iteration 237/250, Loss: 0.0633\n",
      "Epoch 16/200, Iteration 238/250, Loss: 0.0251\n",
      "Epoch 16/200, Iteration 239/250, Loss: 0.0865\n",
      "Epoch 16/200, Iteration 240/250, Loss: 0.0279\n",
      "Epoch 16/200, Iteration 241/250, Loss: 0.0442\n",
      "Epoch 16/200, Iteration 242/250, Loss: 0.0270\n",
      "Epoch 16/200, Iteration 243/250, Loss: 0.0256\n",
      "Epoch 16/200, Iteration 244/250, Loss: 0.0818\n",
      "Epoch 16/200, Iteration 245/250, Loss: 0.0388\n",
      "Epoch 16/200, Iteration 246/250, Loss: 0.0393\n",
      "Epoch 16/200, Iteration 247/250, Loss: 0.0346\n",
      "Epoch 16/200, Iteration 248/250, Loss: 0.0477\n",
      "Epoch 16/200, Iteration 249/250, Loss: 0.0164\n",
      "Epoch 16/200, Iteration 250/250, Loss: 0.0468\n",
      "Train Error: \n",
      " Accuracy: 94.84%, Avg loss: 0.027907, MRE: 1.867758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.85%, Avg loss: 0.027557, MRE: 2.847703 \n",
      "\n",
      "Epoch 17/200, Iteration 1/250, Loss: 0.0264\n",
      "Epoch 17/200, Iteration 2/250, Loss: 0.0301\n",
      "Epoch 17/200, Iteration 3/250, Loss: 0.0722\n",
      "Epoch 17/200, Iteration 4/250, Loss: 0.0391\n",
      "Epoch 17/200, Iteration 5/250, Loss: 0.0314\n",
      "Epoch 17/200, Iteration 6/250, Loss: 0.0455\n",
      "Epoch 17/200, Iteration 7/250, Loss: 0.0404\n",
      "Epoch 17/200, Iteration 8/250, Loss: 0.0299\n",
      "Epoch 17/200, Iteration 9/250, Loss: 0.0279\n",
      "Epoch 17/200, Iteration 10/250, Loss: 0.0621\n",
      "Epoch 17/200, Iteration 11/250, Loss: 0.0618\n",
      "Epoch 17/200, Iteration 12/250, Loss: 0.0309\n",
      "Epoch 17/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 17/200, Iteration 14/250, Loss: 0.0340\n",
      "Epoch 17/200, Iteration 15/250, Loss: 0.0396\n",
      "Epoch 17/200, Iteration 16/250, Loss: 0.0156\n",
      "Epoch 17/200, Iteration 17/250, Loss: 0.0205\n",
      "Epoch 17/200, Iteration 18/250, Loss: 0.0179\n",
      "Epoch 17/200, Iteration 19/250, Loss: 0.0319\n",
      "Epoch 17/200, Iteration 20/250, Loss: 0.0454\n",
      "Epoch 17/200, Iteration 21/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 22/250, Loss: 0.0235\n",
      "Epoch 17/200, Iteration 23/250, Loss: 0.0208\n",
      "Epoch 17/200, Iteration 24/250, Loss: 0.0154\n",
      "Epoch 17/200, Iteration 25/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 26/250, Loss: 0.0118\n",
      "Epoch 17/200, Iteration 27/250, Loss: 0.0304\n",
      "Epoch 17/200, Iteration 28/250, Loss: 0.0300\n",
      "Epoch 17/200, Iteration 29/250, Loss: 0.0240\n",
      "Epoch 17/200, Iteration 30/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 31/250, Loss: 0.0158\n",
      "Epoch 17/200, Iteration 32/250, Loss: 0.0232\n",
      "Epoch 17/200, Iteration 33/250, Loss: 0.0296\n",
      "Epoch 17/200, Iteration 34/250, Loss: 0.0423\n",
      "Epoch 17/200, Iteration 35/250, Loss: 0.0192\n",
      "Epoch 17/200, Iteration 36/250, Loss: 0.0305\n",
      "Epoch 17/200, Iteration 37/250, Loss: 0.0207\n",
      "Epoch 17/200, Iteration 38/250, Loss: 0.0162\n",
      "Epoch 17/200, Iteration 39/250, Loss: 0.0137\n",
      "Epoch 17/200, Iteration 40/250, Loss: 0.0190\n",
      "Epoch 17/200, Iteration 41/250, Loss: 0.0164\n",
      "Epoch 17/200, Iteration 42/250, Loss: 0.0348\n",
      "Epoch 17/200, Iteration 43/250, Loss: 0.0170\n",
      "Epoch 17/200, Iteration 44/250, Loss: 0.0475\n",
      "Epoch 17/200, Iteration 45/250, Loss: 0.0203\n",
      "Epoch 17/200, Iteration 46/250, Loss: 0.0162\n",
      "Epoch 17/200, Iteration 47/250, Loss: 0.0405\n",
      "Epoch 17/200, Iteration 48/250, Loss: 0.0394\n",
      "Epoch 17/200, Iteration 49/250, Loss: 0.0275\n",
      "Epoch 17/200, Iteration 50/250, Loss: 0.0167\n",
      "Epoch 17/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 17/200, Iteration 52/250, Loss: 0.0164\n",
      "Epoch 17/200, Iteration 53/250, Loss: 0.0306\n",
      "Epoch 17/200, Iteration 54/250, Loss: 0.0243\n",
      "Epoch 17/200, Iteration 55/250, Loss: 0.0297\n",
      "Epoch 17/200, Iteration 56/250, Loss: 0.0209\n",
      "Epoch 17/200, Iteration 57/250, Loss: 0.0500\n",
      "Epoch 17/200, Iteration 58/250, Loss: 0.0174\n",
      "Epoch 17/200, Iteration 59/250, Loss: 0.0262\n",
      "Epoch 17/200, Iteration 60/250, Loss: 0.0269\n",
      "Epoch 17/200, Iteration 61/250, Loss: 0.0305\n",
      "Epoch 17/200, Iteration 62/250, Loss: 0.0232\n",
      "Epoch 17/200, Iteration 63/250, Loss: 0.0450\n",
      "Epoch 17/200, Iteration 64/250, Loss: 0.0425\n",
      "Epoch 17/200, Iteration 65/250, Loss: 0.0138\n",
      "Epoch 17/200, Iteration 66/250, Loss: 0.0131\n",
      "Epoch 17/200, Iteration 67/250, Loss: 0.0224\n",
      "Epoch 17/200, Iteration 68/250, Loss: 0.0261\n",
      "Epoch 17/200, Iteration 69/250, Loss: 0.0430\n",
      "Epoch 17/200, Iteration 70/250, Loss: 0.0215\n",
      "Epoch 17/200, Iteration 71/250, Loss: 0.0327\n",
      "Epoch 17/200, Iteration 72/250, Loss: 0.0153\n",
      "Epoch 17/200, Iteration 73/250, Loss: 0.0924\n",
      "Epoch 17/200, Iteration 74/250, Loss: 0.0261\n",
      "Epoch 17/200, Iteration 75/250, Loss: 0.0318\n",
      "Epoch 17/200, Iteration 76/250, Loss: 0.0589\n",
      "Epoch 17/200, Iteration 77/250, Loss: 0.0236\n",
      "Epoch 17/200, Iteration 78/250, Loss: 0.0278\n",
      "Epoch 17/200, Iteration 79/250, Loss: 0.0130\n",
      "Epoch 17/200, Iteration 80/250, Loss: 0.0837\n",
      "Epoch 17/200, Iteration 81/250, Loss: 0.0466\n",
      "Epoch 17/200, Iteration 82/250, Loss: 0.0193\n",
      "Epoch 17/200, Iteration 83/250, Loss: 0.0169\n",
      "Epoch 17/200, Iteration 84/250, Loss: 0.0268\n",
      "Epoch 17/200, Iteration 85/250, Loss: 0.0351\n",
      "Epoch 17/200, Iteration 86/250, Loss: 0.0365\n",
      "Epoch 17/200, Iteration 87/250, Loss: 0.0424\n",
      "Epoch 17/200, Iteration 88/250, Loss: 0.0250\n",
      "Epoch 17/200, Iteration 89/250, Loss: 0.0258\n",
      "Epoch 17/200, Iteration 90/250, Loss: 0.0570\n",
      "Epoch 17/200, Iteration 91/250, Loss: 0.0167\n",
      "Epoch 17/200, Iteration 92/250, Loss: 0.0174\n",
      "Epoch 17/200, Iteration 93/250, Loss: 0.0139\n",
      "Epoch 17/200, Iteration 94/250, Loss: 0.0220\n",
      "Epoch 17/200, Iteration 95/250, Loss: 0.0261\n",
      "Epoch 17/200, Iteration 96/250, Loss: 0.0390\n",
      "Epoch 17/200, Iteration 97/250, Loss: 0.0233\n",
      "Epoch 17/200, Iteration 98/250, Loss: 0.0609\n",
      "Epoch 17/200, Iteration 99/250, Loss: 0.0245\n",
      "Epoch 17/200, Iteration 100/250, Loss: 0.0434\n",
      "Epoch 17/200, Iteration 101/250, Loss: 0.0257\n",
      "Epoch 17/200, Iteration 102/250, Loss: 0.0129\n",
      "Epoch 17/200, Iteration 103/250, Loss: 0.0755\n",
      "Epoch 17/200, Iteration 104/250, Loss: 0.0257\n",
      "Epoch 17/200, Iteration 105/250, Loss: 0.0350\n",
      "Epoch 17/200, Iteration 106/250, Loss: 0.0499\n",
      "Epoch 17/200, Iteration 107/250, Loss: 0.0519\n",
      "Epoch 17/200, Iteration 108/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 109/250, Loss: 0.0392\n",
      "Epoch 17/200, Iteration 110/250, Loss: 0.0284\n",
      "Epoch 17/200, Iteration 111/250, Loss: 0.0276\n",
      "Epoch 17/200, Iteration 112/250, Loss: 0.0372\n",
      "Epoch 17/200, Iteration 113/250, Loss: 0.0183\n",
      "Epoch 17/200, Iteration 114/250, Loss: 0.0381\n",
      "Epoch 17/200, Iteration 115/250, Loss: 0.0470\n",
      "Epoch 17/200, Iteration 116/250, Loss: 0.0377\n",
      "Epoch 17/200, Iteration 117/250, Loss: 0.0305\n",
      "Epoch 17/200, Iteration 118/250, Loss: 0.0214\n",
      "Epoch 17/200, Iteration 119/250, Loss: 0.0145\n",
      "Epoch 17/200, Iteration 120/250, Loss: 0.0223\n",
      "Epoch 17/200, Iteration 121/250, Loss: 0.0306\n",
      "Epoch 17/200, Iteration 122/250, Loss: 0.0208\n",
      "Epoch 17/200, Iteration 123/250, Loss: 0.0191\n",
      "Epoch 17/200, Iteration 124/250, Loss: 0.0160\n",
      "Epoch 17/200, Iteration 125/250, Loss: 0.0150\n",
      "Epoch 17/200, Iteration 126/250, Loss: 0.0255\n",
      "Epoch 17/200, Iteration 127/250, Loss: 0.0507\n",
      "Epoch 17/200, Iteration 128/250, Loss: 0.0315\n",
      "Epoch 17/200, Iteration 129/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 130/250, Loss: 0.0210\n",
      "Epoch 17/200, Iteration 131/250, Loss: 0.0231\n",
      "Epoch 17/200, Iteration 132/250, Loss: 0.0183\n",
      "Epoch 17/200, Iteration 133/250, Loss: 0.0133\n",
      "Epoch 17/200, Iteration 134/250, Loss: 0.0494\n",
      "Epoch 17/200, Iteration 135/250, Loss: 0.0306\n",
      "Epoch 17/200, Iteration 136/250, Loss: 0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Iteration 137/250, Loss: 0.0377\n",
      "Epoch 17/200, Iteration 138/250, Loss: 0.0282\n",
      "Epoch 17/200, Iteration 139/250, Loss: 0.0188\n",
      "Epoch 17/200, Iteration 140/250, Loss: 0.0204\n",
      "Epoch 17/200, Iteration 141/250, Loss: 0.0647\n",
      "Epoch 17/200, Iteration 142/250, Loss: 0.0343\n",
      "Epoch 17/200, Iteration 143/250, Loss: 0.0225\n",
      "Epoch 17/200, Iteration 144/250, Loss: 0.0292\n",
      "Epoch 17/200, Iteration 145/250, Loss: 0.0239\n",
      "Epoch 17/200, Iteration 146/250, Loss: 0.0186\n",
      "Epoch 17/200, Iteration 147/250, Loss: 0.0333\n",
      "Epoch 17/200, Iteration 148/250, Loss: 0.0218\n",
      "Epoch 17/200, Iteration 149/250, Loss: 0.0373\n",
      "Epoch 17/200, Iteration 150/250, Loss: 0.0216\n",
      "Epoch 17/200, Iteration 151/250, Loss: 0.0332\n",
      "Epoch 17/200, Iteration 152/250, Loss: 0.0353\n",
      "Epoch 17/200, Iteration 153/250, Loss: 0.0329\n",
      "Epoch 17/200, Iteration 154/250, Loss: 0.0179\n",
      "Epoch 17/200, Iteration 155/250, Loss: 0.0181\n",
      "Epoch 17/200, Iteration 156/250, Loss: 0.0124\n",
      "Epoch 17/200, Iteration 157/250, Loss: 0.0148\n",
      "Epoch 17/200, Iteration 158/250, Loss: 0.0283\n",
      "Epoch 17/200, Iteration 159/250, Loss: 0.0145\n",
      "Epoch 17/200, Iteration 160/250, Loss: 0.0201\n",
      "Epoch 17/200, Iteration 161/250, Loss: 0.0384\n",
      "Epoch 17/200, Iteration 162/250, Loss: 0.0340\n",
      "Epoch 17/200, Iteration 163/250, Loss: 0.0421\n",
      "Epoch 17/200, Iteration 164/250, Loss: 0.0232\n",
      "Epoch 17/200, Iteration 165/250, Loss: 0.0158\n",
      "Epoch 17/200, Iteration 166/250, Loss: 0.0330\n",
      "Epoch 17/200, Iteration 167/250, Loss: 0.0257\n",
      "Epoch 17/200, Iteration 168/250, Loss: 0.0341\n",
      "Epoch 17/200, Iteration 169/250, Loss: 0.0455\n",
      "Epoch 17/200, Iteration 170/250, Loss: 0.0233\n",
      "Epoch 17/200, Iteration 171/250, Loss: 0.0128\n",
      "Epoch 17/200, Iteration 172/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 17/200, Iteration 174/250, Loss: 0.0263\n",
      "Epoch 17/200, Iteration 175/250, Loss: 0.0229\n",
      "Epoch 17/200, Iteration 176/250, Loss: 0.0185\n",
      "Epoch 17/200, Iteration 177/250, Loss: 0.0137\n",
      "Epoch 17/200, Iteration 178/250, Loss: 0.0242\n",
      "Epoch 17/200, Iteration 179/250, Loss: 0.0197\n",
      "Epoch 17/200, Iteration 180/250, Loss: 0.0136\n",
      "Epoch 17/200, Iteration 181/250, Loss: 0.0153\n",
      "Epoch 17/200, Iteration 182/250, Loss: 0.0159\n",
      "Epoch 17/200, Iteration 183/250, Loss: 0.0378\n",
      "Epoch 17/200, Iteration 184/250, Loss: 0.0182\n",
      "Epoch 17/200, Iteration 185/250, Loss: 0.0281\n",
      "Epoch 17/200, Iteration 186/250, Loss: 0.0494\n",
      "Epoch 17/200, Iteration 187/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 188/250, Loss: 0.0495\n",
      "Epoch 17/200, Iteration 189/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 190/250, Loss: 0.0220\n",
      "Epoch 17/200, Iteration 191/250, Loss: 0.0210\n",
      "Epoch 17/200, Iteration 192/250, Loss: 0.0208\n",
      "Epoch 17/200, Iteration 193/250, Loss: 0.0243\n",
      "Epoch 17/200, Iteration 194/250, Loss: 0.0314\n",
      "Epoch 17/200, Iteration 195/250, Loss: 0.0403\n",
      "Epoch 17/200, Iteration 196/250, Loss: 0.0234\n",
      "Epoch 17/200, Iteration 197/250, Loss: 0.0278\n",
      "Epoch 17/200, Iteration 198/250, Loss: 0.0255\n",
      "Epoch 17/200, Iteration 199/250, Loss: 0.0440\n",
      "Epoch 17/200, Iteration 200/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 17/200, Iteration 202/250, Loss: 0.0450\n",
      "Epoch 17/200, Iteration 203/250, Loss: 0.0246\n",
      "Epoch 17/200, Iteration 204/250, Loss: 0.0420\n",
      "Epoch 17/200, Iteration 205/250, Loss: 0.0189\n",
      "Epoch 17/200, Iteration 206/250, Loss: 0.0496\n",
      "Epoch 17/200, Iteration 207/250, Loss: 0.0551\n",
      "Epoch 17/200, Iteration 208/250, Loss: 0.0367\n",
      "Epoch 17/200, Iteration 209/250, Loss: 0.0143\n",
      "Epoch 17/200, Iteration 210/250, Loss: 0.0356\n",
      "Epoch 17/200, Iteration 211/250, Loss: 0.0351\n",
      "Epoch 17/200, Iteration 212/250, Loss: 0.0255\n",
      "Epoch 17/200, Iteration 213/250, Loss: 0.0499\n",
      "Epoch 17/200, Iteration 214/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 215/250, Loss: 0.0183\n",
      "Epoch 17/200, Iteration 216/250, Loss: 0.0111\n",
      "Epoch 17/200, Iteration 217/250, Loss: 0.0169\n",
      "Epoch 17/200, Iteration 218/250, Loss: 0.0243\n",
      "Epoch 17/200, Iteration 219/250, Loss: 0.0235\n",
      "Epoch 17/200, Iteration 220/250, Loss: 0.0219\n",
      "Epoch 17/200, Iteration 221/250, Loss: 0.0217\n",
      "Epoch 17/200, Iteration 222/250, Loss: 0.0152\n",
      "Epoch 17/200, Iteration 223/250, Loss: 0.0134\n",
      "Epoch 17/200, Iteration 224/250, Loss: 0.0190\n",
      "Epoch 17/200, Iteration 225/250, Loss: 0.0109\n",
      "Epoch 17/200, Iteration 226/250, Loss: 0.0154\n",
      "Epoch 17/200, Iteration 227/250, Loss: 0.0157\n",
      "Epoch 17/200, Iteration 228/250, Loss: 0.0400\n",
      "Epoch 17/200, Iteration 229/250, Loss: 0.0191\n",
      "Epoch 17/200, Iteration 230/250, Loss: 0.0143\n",
      "Epoch 17/200, Iteration 231/250, Loss: 0.0180\n",
      "Epoch 17/200, Iteration 232/250, Loss: 0.0113\n",
      "Epoch 17/200, Iteration 233/250, Loss: 0.0158\n",
      "Epoch 17/200, Iteration 234/250, Loss: 0.0156\n",
      "Epoch 17/200, Iteration 235/250, Loss: 0.0129\n",
      "Epoch 17/200, Iteration 236/250, Loss: 0.0172\n",
      "Epoch 17/200, Iteration 237/250, Loss: 0.0660\n",
      "Epoch 17/200, Iteration 238/250, Loss: 0.0155\n",
      "Epoch 17/200, Iteration 239/250, Loss: 0.0160\n",
      "Epoch 17/200, Iteration 240/250, Loss: 0.0223\n",
      "Epoch 17/200, Iteration 241/250, Loss: 0.0077\n",
      "Epoch 17/200, Iteration 242/250, Loss: 0.0316\n",
      "Epoch 17/200, Iteration 243/250, Loss: 0.0163\n",
      "Epoch 17/200, Iteration 244/250, Loss: 0.0713\n",
      "Epoch 17/200, Iteration 245/250, Loss: 0.0434\n",
      "Epoch 17/200, Iteration 246/250, Loss: 0.0141\n",
      "Epoch 17/200, Iteration 247/250, Loss: 0.0222\n",
      "Epoch 17/200, Iteration 248/250, Loss: 0.0173\n",
      "Epoch 17/200, Iteration 249/250, Loss: 0.0293\n",
      "Epoch 17/200, Iteration 250/250, Loss: 0.0165\n",
      "Train Error: \n",
      " Accuracy: 75.65%, Avg loss: 0.014836, MRE: 1.671299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.014487, MRE: 1.957694 \n",
      "\n",
      "Epoch 18/200, Iteration 1/250, Loss: 0.0263\n",
      "Epoch 18/200, Iteration 2/250, Loss: 0.0211\n",
      "Epoch 18/200, Iteration 3/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 4/250, Loss: 0.0226\n",
      "Epoch 18/200, Iteration 5/250, Loss: 0.0212\n",
      "Epoch 18/200, Iteration 6/250, Loss: 0.0248\n",
      "Epoch 18/200, Iteration 7/250, Loss: 0.0134\n",
      "Epoch 18/200, Iteration 8/250, Loss: 0.0368\n",
      "Epoch 18/200, Iteration 9/250, Loss: 0.0175\n",
      "Epoch 18/200, Iteration 10/250, Loss: 0.0106\n",
      "Epoch 18/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 18/200, Iteration 12/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 13/250, Loss: 0.0421\n",
      "Epoch 18/200, Iteration 14/250, Loss: 0.0259\n",
      "Epoch 18/200, Iteration 15/250, Loss: 0.0107\n",
      "Epoch 18/200, Iteration 16/250, Loss: 0.0390\n",
      "Epoch 18/200, Iteration 17/250, Loss: 0.0315\n",
      "Epoch 18/200, Iteration 18/250, Loss: 0.0197\n",
      "Epoch 18/200, Iteration 19/250, Loss: 0.0231\n",
      "Epoch 18/200, Iteration 20/250, Loss: 0.0247\n",
      "Epoch 18/200, Iteration 21/250, Loss: 0.0096\n",
      "Epoch 18/200, Iteration 22/250, Loss: 0.0250\n",
      "Epoch 18/200, Iteration 23/250, Loss: 0.0255\n",
      "Epoch 18/200, Iteration 24/250, Loss: 0.0229\n",
      "Epoch 18/200, Iteration 25/250, Loss: 0.0259\n",
      "Epoch 18/200, Iteration 26/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 27/250, Loss: 0.0252\n",
      "Epoch 18/200, Iteration 28/250, Loss: 0.0372\n",
      "Epoch 18/200, Iteration 29/250, Loss: 0.0279\n",
      "Epoch 18/200, Iteration 30/250, Loss: 0.0207\n",
      "Epoch 18/200, Iteration 31/250, Loss: 0.0437\n",
      "Epoch 18/200, Iteration 32/250, Loss: 0.0161\n",
      "Epoch 18/200, Iteration 33/250, Loss: 0.0094\n",
      "Epoch 18/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 18/200, Iteration 35/250, Loss: 0.0326\n",
      "Epoch 18/200, Iteration 36/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 37/250, Loss: 0.0283\n",
      "Epoch 18/200, Iteration 38/250, Loss: 0.0196\n",
      "Epoch 18/200, Iteration 39/250, Loss: 0.0485\n",
      "Epoch 18/200, Iteration 40/250, Loss: 0.0198\n",
      "Epoch 18/200, Iteration 41/250, Loss: 0.0202\n",
      "Epoch 18/200, Iteration 42/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 43/250, Loss: 0.0392\n",
      "Epoch 18/200, Iteration 44/250, Loss: 0.0117\n",
      "Epoch 18/200, Iteration 45/250, Loss: 0.0152\n",
      "Epoch 18/200, Iteration 46/250, Loss: 0.0193\n",
      "Epoch 18/200, Iteration 47/250, Loss: 0.0191\n",
      "Epoch 18/200, Iteration 48/250, Loss: 0.0146\n",
      "Epoch 18/200, Iteration 49/250, Loss: 0.0155\n",
      "Epoch 18/200, Iteration 50/250, Loss: 0.0382\n",
      "Epoch 18/200, Iteration 51/250, Loss: 0.0380\n",
      "Epoch 18/200, Iteration 52/250, Loss: 0.0249\n",
      "Epoch 18/200, Iteration 53/250, Loss: 0.0200\n",
      "Epoch 18/200, Iteration 54/250, Loss: 0.0241\n",
      "Epoch 18/200, Iteration 55/250, Loss: 0.0227\n",
      "Epoch 18/200, Iteration 56/250, Loss: 0.0293\n",
      "Epoch 18/200, Iteration 57/250, Loss: 0.0150\n",
      "Epoch 18/200, Iteration 58/250, Loss: 0.0212\n",
      "Epoch 18/200, Iteration 59/250, Loss: 0.0086\n",
      "Epoch 18/200, Iteration 60/250, Loss: 0.0120\n",
      "Epoch 18/200, Iteration 61/250, Loss: 0.0169\n",
      "Epoch 18/200, Iteration 62/250, Loss: 0.0258\n",
      "Epoch 18/200, Iteration 63/250, Loss: 0.0173\n",
      "Epoch 18/200, Iteration 64/250, Loss: 0.0231\n",
      "Epoch 18/200, Iteration 65/250, Loss: 0.0142\n",
      "Epoch 18/200, Iteration 66/250, Loss: 0.0085\n",
      "Epoch 18/200, Iteration 67/250, Loss: 0.0100\n",
      "Epoch 18/200, Iteration 68/250, Loss: 0.0156\n",
      "Epoch 18/200, Iteration 69/250, Loss: 0.0317\n",
      "Epoch 18/200, Iteration 70/250, Loss: 0.0268\n",
      "Epoch 18/200, Iteration 71/250, Loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Iteration 72/250, Loss: 0.0423\n",
      "Epoch 18/200, Iteration 73/250, Loss: 0.0134\n",
      "Epoch 18/200, Iteration 74/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 75/250, Loss: 0.0121\n",
      "Epoch 18/200, Iteration 76/250, Loss: 0.0307\n",
      "Epoch 18/200, Iteration 77/250, Loss: 0.0357\n",
      "Epoch 18/200, Iteration 78/250, Loss: 0.0137\n",
      "Epoch 18/200, Iteration 79/250, Loss: 0.0233\n",
      "Epoch 18/200, Iteration 80/250, Loss: 0.0204\n",
      "Epoch 18/200, Iteration 81/250, Loss: 0.0309\n",
      "Epoch 18/200, Iteration 82/250, Loss: 0.0236\n",
      "Epoch 18/200, Iteration 83/250, Loss: 0.0299\n",
      "Epoch 18/200, Iteration 84/250, Loss: 0.0345\n",
      "Epoch 18/200, Iteration 85/250, Loss: 0.0429\n",
      "Epoch 18/200, Iteration 86/250, Loss: 0.0189\n",
      "Epoch 18/200, Iteration 87/250, Loss: 0.0196\n",
      "Epoch 18/200, Iteration 88/250, Loss: 0.0148\n",
      "Epoch 18/200, Iteration 89/250, Loss: 0.0184\n",
      "Epoch 18/200, Iteration 90/250, Loss: 0.0153\n",
      "Epoch 18/200, Iteration 91/250, Loss: 0.0168\n",
      "Epoch 18/200, Iteration 92/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 93/250, Loss: 0.0181\n",
      "Epoch 18/200, Iteration 94/250, Loss: 0.0155\n",
      "Epoch 18/200, Iteration 95/250, Loss: 0.0177\n",
      "Epoch 18/200, Iteration 96/250, Loss: 0.0163\n",
      "Epoch 18/200, Iteration 97/250, Loss: 0.0378\n",
      "Epoch 18/200, Iteration 98/250, Loss: 0.0191\n",
      "Epoch 18/200, Iteration 99/250, Loss: 0.0318\n",
      "Epoch 18/200, Iteration 100/250, Loss: 0.0158\n",
      "Epoch 18/200, Iteration 101/250, Loss: 0.0178\n",
      "Epoch 18/200, Iteration 102/250, Loss: 0.0172\n",
      "Epoch 18/200, Iteration 103/250, Loss: 0.0127\n",
      "Epoch 18/200, Iteration 104/250, Loss: 0.0282\n",
      "Epoch 18/200, Iteration 105/250, Loss: 0.0195\n",
      "Epoch 18/200, Iteration 106/250, Loss: 0.0198\n",
      "Epoch 18/200, Iteration 107/250, Loss: 0.0271\n",
      "Epoch 18/200, Iteration 108/250, Loss: 0.0155\n",
      "Epoch 18/200, Iteration 109/250, Loss: 0.0135\n",
      "Epoch 18/200, Iteration 110/250, Loss: 0.0441\n",
      "Epoch 18/200, Iteration 111/250, Loss: 0.0326\n",
      "Epoch 18/200, Iteration 112/250, Loss: 0.0164\n",
      "Epoch 18/200, Iteration 113/250, Loss: 0.0194\n",
      "Epoch 18/200, Iteration 114/250, Loss: 0.0100\n",
      "Epoch 18/200, Iteration 115/250, Loss: 0.0230\n",
      "Epoch 18/200, Iteration 116/250, Loss: 0.0211\n",
      "Epoch 18/200, Iteration 117/250, Loss: 0.0132\n",
      "Epoch 18/200, Iteration 118/250, Loss: 0.0354\n",
      "Epoch 18/200, Iteration 119/250, Loss: 0.0266\n",
      "Epoch 18/200, Iteration 120/250, Loss: 0.0217\n",
      "Epoch 18/200, Iteration 121/250, Loss: 0.0164\n",
      "Epoch 18/200, Iteration 122/250, Loss: 0.0105\n",
      "Epoch 18/200, Iteration 123/250, Loss: 0.0128\n",
      "Epoch 18/200, Iteration 124/250, Loss: 0.0161\n",
      "Epoch 18/200, Iteration 125/250, Loss: 0.0299\n",
      "Epoch 18/200, Iteration 126/250, Loss: 0.0310\n",
      "Epoch 18/200, Iteration 127/250, Loss: 0.0165\n",
      "Epoch 18/200, Iteration 128/250, Loss: 0.0284\n",
      "Epoch 18/200, Iteration 129/250, Loss: 0.0360\n",
      "Epoch 18/200, Iteration 130/250, Loss: 0.0210\n",
      "Epoch 18/200, Iteration 131/250, Loss: 0.0137\n",
      "Epoch 18/200, Iteration 132/250, Loss: 0.0216\n",
      "Epoch 18/200, Iteration 133/250, Loss: 0.0126\n",
      "Epoch 18/200, Iteration 134/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 135/250, Loss: 0.0126\n",
      "Epoch 18/200, Iteration 136/250, Loss: 0.0184\n",
      "Epoch 18/200, Iteration 137/250, Loss: 0.0230\n",
      "Epoch 18/200, Iteration 138/250, Loss: 0.0267\n",
      "Epoch 18/200, Iteration 139/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 140/250, Loss: 0.0327\n",
      "Epoch 18/200, Iteration 141/250, Loss: 0.0359\n",
      "Epoch 18/200, Iteration 142/250, Loss: 0.0263\n",
      "Epoch 18/200, Iteration 143/250, Loss: 0.0167\n",
      "Epoch 18/200, Iteration 144/250, Loss: 0.0138\n",
      "Epoch 18/200, Iteration 145/250, Loss: 0.0290\n",
      "Epoch 18/200, Iteration 146/250, Loss: 0.0140\n",
      "Epoch 18/200, Iteration 147/250, Loss: 0.0206\n",
      "Epoch 18/200, Iteration 148/250, Loss: 0.0227\n",
      "Epoch 18/200, Iteration 149/250, Loss: 0.0173\n",
      "Epoch 18/200, Iteration 150/250, Loss: 0.0148\n",
      "Epoch 18/200, Iteration 151/250, Loss: 0.0334\n",
      "Epoch 18/200, Iteration 152/250, Loss: 0.0153\n",
      "Epoch 18/200, Iteration 153/250, Loss: 0.0182\n",
      "Epoch 18/200, Iteration 154/250, Loss: 0.0135\n",
      "Epoch 18/200, Iteration 155/250, Loss: 0.0205\n",
      "Epoch 18/200, Iteration 156/250, Loss: 0.0262\n",
      "Epoch 18/200, Iteration 157/250, Loss: 0.0289\n",
      "Epoch 18/200, Iteration 158/250, Loss: 0.0403\n",
      "Epoch 18/200, Iteration 159/250, Loss: 0.0276\n",
      "Epoch 18/200, Iteration 160/250, Loss: 0.0227\n",
      "Epoch 18/200, Iteration 161/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 162/250, Loss: 0.0249\n",
      "Epoch 18/200, Iteration 163/250, Loss: 0.0199\n",
      "Epoch 18/200, Iteration 164/250, Loss: 0.0166\n",
      "Epoch 18/200, Iteration 165/250, Loss: 0.0122\n",
      "Epoch 18/200, Iteration 166/250, Loss: 0.0382\n",
      "Epoch 18/200, Iteration 167/250, Loss: 0.0275\n",
      "Epoch 18/200, Iteration 168/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 169/250, Loss: 0.0315\n",
      "Epoch 18/200, Iteration 170/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 171/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 172/250, Loss: 0.0147\n",
      "Epoch 18/200, Iteration 173/250, Loss: 0.0129\n",
      "Epoch 18/200, Iteration 174/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 175/250, Loss: 0.0153\n",
      "Epoch 18/200, Iteration 176/250, Loss: 0.0464\n",
      "Epoch 18/200, Iteration 177/250, Loss: 0.0234\n",
      "Epoch 18/200, Iteration 178/250, Loss: 0.0098\n",
      "Epoch 18/200, Iteration 179/250, Loss: 0.0131\n",
      "Epoch 18/200, Iteration 180/250, Loss: 0.0134\n",
      "Epoch 18/200, Iteration 181/250, Loss: 0.0177\n",
      "Epoch 18/200, Iteration 182/250, Loss: 0.0385\n",
      "Epoch 18/200, Iteration 183/250, Loss: 0.0293\n",
      "Epoch 18/200, Iteration 184/250, Loss: 0.0108\n",
      "Epoch 18/200, Iteration 185/250, Loss: 0.0473\n",
      "Epoch 18/200, Iteration 186/250, Loss: 0.0266\n",
      "Epoch 18/200, Iteration 187/250, Loss: 0.0165\n",
      "Epoch 18/200, Iteration 188/250, Loss: 0.0124\n",
      "Epoch 18/200, Iteration 189/250, Loss: 0.0178\n",
      "Epoch 18/200, Iteration 190/250, Loss: 0.0131\n",
      "Epoch 18/200, Iteration 191/250, Loss: 0.0210\n",
      "Epoch 18/200, Iteration 192/250, Loss: 0.0178\n",
      "Epoch 18/200, Iteration 193/250, Loss: 0.0134\n",
      "Epoch 18/200, Iteration 194/250, Loss: 0.0189\n",
      "Epoch 18/200, Iteration 195/250, Loss: 0.0189\n",
      "Epoch 18/200, Iteration 196/250, Loss: 0.0216\n",
      "Epoch 18/200, Iteration 197/250, Loss: 0.0378\n",
      "Epoch 18/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 18/200, Iteration 199/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 200/250, Loss: 0.0402\n",
      "Epoch 18/200, Iteration 201/250, Loss: 0.0262\n",
      "Epoch 18/200, Iteration 202/250, Loss: 0.0226\n",
      "Epoch 18/200, Iteration 203/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 204/250, Loss: 0.0365\n",
      "Epoch 18/200, Iteration 205/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 206/250, Loss: 0.0474\n",
      "Epoch 18/200, Iteration 207/250, Loss: 0.0437\n",
      "Epoch 18/200, Iteration 208/250, Loss: 0.0316\n",
      "Epoch 18/200, Iteration 209/250, Loss: 0.0424\n",
      "Epoch 18/200, Iteration 210/250, Loss: 0.0345\n",
      "Epoch 18/200, Iteration 211/250, Loss: 0.0436\n",
      "Epoch 18/200, Iteration 212/250, Loss: 0.0236\n",
      "Epoch 18/200, Iteration 213/250, Loss: 0.0281\n",
      "Epoch 18/200, Iteration 214/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 215/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 216/250, Loss: 0.0211\n",
      "Epoch 18/200, Iteration 217/250, Loss: 0.0117\n",
      "Epoch 18/200, Iteration 218/250, Loss: 0.0531\n",
      "Epoch 18/200, Iteration 219/250, Loss: 0.0264\n",
      "Epoch 18/200, Iteration 220/250, Loss: 0.0209\n",
      "Epoch 18/200, Iteration 221/250, Loss: 0.0338\n",
      "Epoch 18/200, Iteration 222/250, Loss: 0.0261\n",
      "Epoch 18/200, Iteration 223/250, Loss: 0.0481\n",
      "Epoch 18/200, Iteration 224/250, Loss: 0.0211\n",
      "Epoch 18/200, Iteration 225/250, Loss: 0.0214\n",
      "Epoch 18/200, Iteration 226/250, Loss: 0.0293\n",
      "Epoch 18/200, Iteration 227/250, Loss: 0.0224\n",
      "Epoch 18/200, Iteration 228/250, Loss: 0.0217\n",
      "Epoch 18/200, Iteration 229/250, Loss: 0.0194\n",
      "Epoch 18/200, Iteration 230/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 231/250, Loss: 0.0199\n",
      "Epoch 18/200, Iteration 232/250, Loss: 0.0324\n",
      "Epoch 18/200, Iteration 233/250, Loss: 0.0209\n",
      "Epoch 18/200, Iteration 234/250, Loss: 0.0254\n",
      "Epoch 18/200, Iteration 235/250, Loss: 0.0292\n",
      "Epoch 18/200, Iteration 236/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 237/250, Loss: 0.0176\n",
      "Epoch 18/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 18/200, Iteration 239/250, Loss: 0.0166\n",
      "Epoch 18/200, Iteration 240/250, Loss: 0.0172\n",
      "Epoch 18/200, Iteration 241/250, Loss: 0.0146\n",
      "Epoch 18/200, Iteration 242/250, Loss: 0.0154\n",
      "Epoch 18/200, Iteration 243/250, Loss: 0.0192\n",
      "Epoch 18/200, Iteration 244/250, Loss: 0.0276\n",
      "Epoch 18/200, Iteration 245/250, Loss: 0.0185\n",
      "Epoch 18/200, Iteration 246/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 248/250, Loss: 0.0166\n",
      "Epoch 18/200, Iteration 249/250, Loss: 0.0258\n",
      "Epoch 18/200, Iteration 250/250, Loss: 0.0428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.015504, MRE: 1.641005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.05%, Avg loss: 0.015490, MRE: 1.658647 \n",
      "\n",
      "Epoch 19/200, Iteration 1/250, Loss: 0.0368\n",
      "Epoch 19/200, Iteration 2/250, Loss: 0.0228\n",
      "Epoch 19/200, Iteration 3/250, Loss: 0.0343\n",
      "Epoch 19/200, Iteration 4/250, Loss: 0.0185\n",
      "Epoch 19/200, Iteration 5/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 6/250, Loss: 0.0095\n",
      "Epoch 19/200, Iteration 7/250, Loss: 0.0182\n",
      "Epoch 19/200, Iteration 8/250, Loss: 0.0209\n",
      "Epoch 19/200, Iteration 9/250, Loss: 0.0131\n",
      "Epoch 19/200, Iteration 10/250, Loss: 0.0110\n",
      "Epoch 19/200, Iteration 11/250, Loss: 0.0298\n",
      "Epoch 19/200, Iteration 12/250, Loss: 0.0197\n",
      "Epoch 19/200, Iteration 13/250, Loss: 0.0136\n",
      "Epoch 19/200, Iteration 14/250, Loss: 0.0189\n",
      "Epoch 19/200, Iteration 15/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 16/250, Loss: 0.0232\n",
      "Epoch 19/200, Iteration 17/250, Loss: 0.0601\n",
      "Epoch 19/200, Iteration 18/250, Loss: 0.0256\n",
      "Epoch 19/200, Iteration 19/250, Loss: 0.0347\n",
      "Epoch 19/200, Iteration 20/250, Loss: 0.0301\n",
      "Epoch 19/200, Iteration 21/250, Loss: 0.0181\n",
      "Epoch 19/200, Iteration 22/250, Loss: 0.0220\n",
      "Epoch 19/200, Iteration 23/250, Loss: 0.0490\n",
      "Epoch 19/200, Iteration 24/250, Loss: 0.0145\n",
      "Epoch 19/200, Iteration 25/250, Loss: 0.0994\n",
      "Epoch 19/200, Iteration 26/250, Loss: 0.0444\n",
      "Epoch 19/200, Iteration 27/250, Loss: 0.0150\n",
      "Epoch 19/200, Iteration 28/250, Loss: 0.0192\n",
      "Epoch 19/200, Iteration 29/250, Loss: 0.0261\n",
      "Epoch 19/200, Iteration 30/250, Loss: 0.0145\n",
      "Epoch 19/200, Iteration 31/250, Loss: 0.0152\n",
      "Epoch 19/200, Iteration 32/250, Loss: 0.0335\n",
      "Epoch 19/200, Iteration 33/250, Loss: 0.0200\n",
      "Epoch 19/200, Iteration 34/250, Loss: 0.0173\n",
      "Epoch 19/200, Iteration 35/250, Loss: 0.0287\n",
      "Epoch 19/200, Iteration 36/250, Loss: 0.0404\n",
      "Epoch 19/200, Iteration 37/250, Loss: 0.0224\n",
      "Epoch 19/200, Iteration 38/250, Loss: 0.0332\n",
      "Epoch 19/200, Iteration 39/250, Loss: 0.0237\n",
      "Epoch 19/200, Iteration 40/250, Loss: 0.0245\n",
      "Epoch 19/200, Iteration 41/250, Loss: 0.0231\n",
      "Epoch 19/200, Iteration 42/250, Loss: 0.0268\n",
      "Epoch 19/200, Iteration 43/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 44/250, Loss: 0.0323\n",
      "Epoch 19/200, Iteration 45/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 46/250, Loss: 0.0206\n",
      "Epoch 19/200, Iteration 47/250, Loss: 0.0291\n",
      "Epoch 19/200, Iteration 48/250, Loss: 0.0117\n",
      "Epoch 19/200, Iteration 49/250, Loss: 0.0340\n",
      "Epoch 19/200, Iteration 50/250, Loss: 0.0291\n",
      "Epoch 19/200, Iteration 51/250, Loss: 0.0189\n",
      "Epoch 19/200, Iteration 52/250, Loss: 0.0098\n",
      "Epoch 19/200, Iteration 53/250, Loss: 0.0152\n",
      "Epoch 19/200, Iteration 54/250, Loss: 0.0121\n",
      "Epoch 19/200, Iteration 55/250, Loss: 0.0151\n",
      "Epoch 19/200, Iteration 56/250, Loss: 0.0171\n",
      "Epoch 19/200, Iteration 57/250, Loss: 0.0245\n",
      "Epoch 19/200, Iteration 58/250, Loss: 0.0378\n",
      "Epoch 19/200, Iteration 59/250, Loss: 0.0290\n",
      "Epoch 19/200, Iteration 60/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 61/250, Loss: 0.0134\n",
      "Epoch 19/200, Iteration 62/250, Loss: 0.0214\n",
      "Epoch 19/200, Iteration 63/250, Loss: 0.0210\n",
      "Epoch 19/200, Iteration 64/250, Loss: 0.0130\n",
      "Epoch 19/200, Iteration 65/250, Loss: 0.0178\n",
      "Epoch 19/200, Iteration 66/250, Loss: 0.0182\n",
      "Epoch 19/200, Iteration 67/250, Loss: 0.0158\n",
      "Epoch 19/200, Iteration 68/250, Loss: 0.0176\n",
      "Epoch 19/200, Iteration 69/250, Loss: 0.0409\n",
      "Epoch 19/200, Iteration 70/250, Loss: 0.0232\n",
      "Epoch 19/200, Iteration 71/250, Loss: 0.0202\n",
      "Epoch 19/200, Iteration 72/250, Loss: 0.0316\n",
      "Epoch 19/200, Iteration 73/250, Loss: 0.0518\n",
      "Epoch 19/200, Iteration 74/250, Loss: 0.0451\n",
      "Epoch 19/200, Iteration 75/250, Loss: 0.0127\n",
      "Epoch 19/200, Iteration 76/250, Loss: 0.0258\n",
      "Epoch 19/200, Iteration 77/250, Loss: 0.0410\n",
      "Epoch 19/200, Iteration 78/250, Loss: 0.0104\n",
      "Epoch 19/200, Iteration 79/250, Loss: 0.0179\n",
      "Epoch 19/200, Iteration 80/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 81/250, Loss: 0.0194\n",
      "Epoch 19/200, Iteration 82/250, Loss: 0.0457\n",
      "Epoch 19/200, Iteration 83/250, Loss: 0.0266\n",
      "Epoch 19/200, Iteration 84/250, Loss: 0.0436\n",
      "Epoch 19/200, Iteration 85/250, Loss: 0.0174\n",
      "Epoch 19/200, Iteration 86/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 87/250, Loss: 0.0221\n",
      "Epoch 19/200, Iteration 88/250, Loss: 0.0204\n",
      "Epoch 19/200, Iteration 89/250, Loss: 0.0101\n",
      "Epoch 19/200, Iteration 90/250, Loss: 0.0538\n",
      "Epoch 19/200, Iteration 91/250, Loss: 0.0254\n",
      "Epoch 19/200, Iteration 92/250, Loss: 0.0342\n",
      "Epoch 19/200, Iteration 93/250, Loss: 0.0227\n",
      "Epoch 19/200, Iteration 94/250, Loss: 0.0162\n",
      "Epoch 19/200, Iteration 95/250, Loss: 0.0186\n",
      "Epoch 19/200, Iteration 96/250, Loss: 0.0307\n",
      "Epoch 19/200, Iteration 97/250, Loss: 0.0158\n",
      "Epoch 19/200, Iteration 98/250, Loss: 0.0117\n",
      "Epoch 19/200, Iteration 99/250, Loss: 0.0349\n",
      "Epoch 19/200, Iteration 100/250, Loss: 0.0308\n",
      "Epoch 19/200, Iteration 101/250, Loss: 0.0231\n",
      "Epoch 19/200, Iteration 102/250, Loss: 0.0170\n",
      "Epoch 19/200, Iteration 103/250, Loss: 0.0164\n",
      "Epoch 19/200, Iteration 104/250, Loss: 0.0170\n",
      "Epoch 19/200, Iteration 105/250, Loss: 0.0294\n",
      "Epoch 19/200, Iteration 106/250, Loss: 0.0550\n",
      "Epoch 19/200, Iteration 107/250, Loss: 0.0265\n",
      "Epoch 19/200, Iteration 108/250, Loss: 0.0253\n",
      "Epoch 19/200, Iteration 109/250, Loss: 0.0304\n",
      "Epoch 19/200, Iteration 110/250, Loss: 0.0203\n",
      "Epoch 19/200, Iteration 111/250, Loss: 0.0299\n",
      "Epoch 19/200, Iteration 112/250, Loss: 0.0274\n",
      "Epoch 19/200, Iteration 113/250, Loss: 0.0131\n",
      "Epoch 19/200, Iteration 114/250, Loss: 0.0195\n",
      "Epoch 19/200, Iteration 115/250, Loss: 0.0198\n",
      "Epoch 19/200, Iteration 116/250, Loss: 0.0424\n",
      "Epoch 19/200, Iteration 117/250, Loss: 0.0111\n",
      "Epoch 19/200, Iteration 118/250, Loss: 0.0412\n",
      "Epoch 19/200, Iteration 119/250, Loss: 0.0205\n",
      "Epoch 19/200, Iteration 120/250, Loss: 0.0358\n",
      "Epoch 19/200, Iteration 121/250, Loss: 0.0364\n",
      "Epoch 19/200, Iteration 122/250, Loss: 0.0110\n",
      "Epoch 19/200, Iteration 123/250, Loss: 0.0214\n",
      "Epoch 19/200, Iteration 124/250, Loss: 0.0240\n",
      "Epoch 19/200, Iteration 125/250, Loss: 0.0118\n",
      "Epoch 19/200, Iteration 126/250, Loss: 0.0085\n",
      "Epoch 19/200, Iteration 127/250, Loss: 0.0352\n",
      "Epoch 19/200, Iteration 128/250, Loss: 0.0160\n",
      "Epoch 19/200, Iteration 129/250, Loss: 0.0148\n",
      "Epoch 19/200, Iteration 130/250, Loss: 0.0263\n",
      "Epoch 19/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 19/200, Iteration 132/250, Loss: 0.0205\n",
      "Epoch 19/200, Iteration 133/250, Loss: 0.0318\n",
      "Epoch 19/200, Iteration 134/250, Loss: 0.0194\n",
      "Epoch 19/200, Iteration 135/250, Loss: 0.0253\n",
      "Epoch 19/200, Iteration 136/250, Loss: 0.0227\n",
      "Epoch 19/200, Iteration 137/250, Loss: 0.0467\n",
      "Epoch 19/200, Iteration 138/250, Loss: 0.0321\n",
      "Epoch 19/200, Iteration 139/250, Loss: 0.0209\n",
      "Epoch 19/200, Iteration 140/250, Loss: 0.0224\n",
      "Epoch 19/200, Iteration 141/250, Loss: 0.0356\n",
      "Epoch 19/200, Iteration 142/250, Loss: 0.0148\n",
      "Epoch 19/200, Iteration 143/250, Loss: 0.0235\n",
      "Epoch 19/200, Iteration 144/250, Loss: 0.0736\n",
      "Epoch 19/200, Iteration 145/250, Loss: 0.0432\n",
      "Epoch 19/200, Iteration 146/250, Loss: 0.0295\n",
      "Epoch 19/200, Iteration 147/250, Loss: 0.0228\n",
      "Epoch 19/200, Iteration 148/250, Loss: 0.0363\n",
      "Epoch 19/200, Iteration 149/250, Loss: 0.0255\n",
      "Epoch 19/200, Iteration 150/250, Loss: 0.0244\n",
      "Epoch 19/200, Iteration 151/250, Loss: 0.0217\n",
      "Epoch 19/200, Iteration 152/250, Loss: 0.0234\n",
      "Epoch 19/200, Iteration 153/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 154/250, Loss: 0.0207\n",
      "Epoch 19/200, Iteration 155/250, Loss: 0.0180\n",
      "Epoch 19/200, Iteration 156/250, Loss: 0.0332\n",
      "Epoch 19/200, Iteration 157/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 158/250, Loss: 0.0210\n",
      "Epoch 19/200, Iteration 159/250, Loss: 0.0133\n",
      "Epoch 19/200, Iteration 160/250, Loss: 0.0442\n",
      "Epoch 19/200, Iteration 161/250, Loss: 0.0279\n",
      "Epoch 19/200, Iteration 162/250, Loss: 0.0235\n",
      "Epoch 19/200, Iteration 163/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 164/250, Loss: 0.0255\n",
      "Epoch 19/200, Iteration 165/250, Loss: 0.0538\n",
      "Epoch 19/200, Iteration 166/250, Loss: 0.0139\n",
      "Epoch 19/200, Iteration 167/250, Loss: 0.0220\n",
      "Epoch 19/200, Iteration 168/250, Loss: 0.0200\n",
      "Epoch 19/200, Iteration 169/250, Loss: 0.0144\n",
      "Epoch 19/200, Iteration 170/250, Loss: 0.0367\n",
      "Epoch 19/200, Iteration 171/250, Loss: 0.0110\n",
      "Epoch 19/200, Iteration 172/250, Loss: 0.0392\n",
      "Epoch 19/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 19/200, Iteration 174/250, Loss: 0.0162\n",
      "Epoch 19/200, Iteration 175/250, Loss: 0.0157\n",
      "Epoch 19/200, Iteration 176/250, Loss: 0.0140\n",
      "Epoch 19/200, Iteration 177/250, Loss: 0.0311\n",
      "Epoch 19/200, Iteration 178/250, Loss: 0.0375\n",
      "Epoch 19/200, Iteration 179/250, Loss: 0.0396\n",
      "Epoch 19/200, Iteration 180/250, Loss: 0.0246\n",
      "Epoch 19/200, Iteration 181/250, Loss: 0.0192\n",
      "Epoch 19/200, Iteration 182/250, Loss: 0.0506\n",
      "Epoch 19/200, Iteration 183/250, Loss: 0.0308\n",
      "Epoch 19/200, Iteration 184/250, Loss: 0.0277\n",
      "Epoch 19/200, Iteration 185/250, Loss: 0.0471\n",
      "Epoch 19/200, Iteration 186/250, Loss: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Iteration 187/250, Loss: 0.0272\n",
      "Epoch 19/200, Iteration 188/250, Loss: 0.0297\n",
      "Epoch 19/200, Iteration 189/250, Loss: 0.0155\n",
      "Epoch 19/200, Iteration 190/250, Loss: 0.0100\n",
      "Epoch 19/200, Iteration 191/250, Loss: 0.0224\n",
      "Epoch 19/200, Iteration 192/250, Loss: 0.0242\n",
      "Epoch 19/200, Iteration 193/250, Loss: 0.0476\n",
      "Epoch 19/200, Iteration 194/250, Loss: 0.0420\n",
      "Epoch 19/200, Iteration 195/250, Loss: 0.0500\n",
      "Epoch 19/200, Iteration 196/250, Loss: 0.0357\n",
      "Epoch 19/200, Iteration 197/250, Loss: 0.0400\n",
      "Epoch 19/200, Iteration 198/250, Loss: 0.0175\n",
      "Epoch 19/200, Iteration 199/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 200/250, Loss: 0.0183\n",
      "Epoch 19/200, Iteration 201/250, Loss: 0.0221\n",
      "Epoch 19/200, Iteration 202/250, Loss: 0.0228\n",
      "Epoch 19/200, Iteration 203/250, Loss: 0.0819\n",
      "Epoch 19/200, Iteration 204/250, Loss: 0.0317\n",
      "Epoch 19/200, Iteration 205/250, Loss: 0.0518\n",
      "Epoch 19/200, Iteration 206/250, Loss: 0.0305\n",
      "Epoch 19/200, Iteration 207/250, Loss: 0.0427\n",
      "Epoch 19/200, Iteration 208/250, Loss: 0.0338\n",
      "Epoch 19/200, Iteration 209/250, Loss: 0.0636\n",
      "Epoch 19/200, Iteration 210/250, Loss: 0.0329\n",
      "Epoch 19/200, Iteration 211/250, Loss: 0.0559\n",
      "Epoch 19/200, Iteration 212/250, Loss: 0.0540\n",
      "Epoch 19/200, Iteration 213/250, Loss: 0.0215\n",
      "Epoch 19/200, Iteration 214/250, Loss: 0.0717\n",
      "Epoch 19/200, Iteration 215/250, Loss: 0.0372\n",
      "Epoch 19/200, Iteration 216/250, Loss: 0.0169\n",
      "Epoch 19/200, Iteration 217/250, Loss: 0.0184\n",
      "Epoch 19/200, Iteration 218/250, Loss: 0.0147\n",
      "Epoch 19/200, Iteration 219/250, Loss: 0.0351\n",
      "Epoch 19/200, Iteration 220/250, Loss: 0.0178\n",
      "Epoch 19/200, Iteration 221/250, Loss: 0.0188\n",
      "Epoch 19/200, Iteration 222/250, Loss: 0.0161\n",
      "Epoch 19/200, Iteration 223/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 224/250, Loss: 0.0300\n",
      "Epoch 19/200, Iteration 225/250, Loss: 0.0308\n",
      "Epoch 19/200, Iteration 226/250, Loss: 0.0267\n",
      "Epoch 19/200, Iteration 227/250, Loss: 0.0152\n",
      "Epoch 19/200, Iteration 228/250, Loss: 0.0432\n",
      "Epoch 19/200, Iteration 229/250, Loss: 0.0265\n",
      "Epoch 19/200, Iteration 230/250, Loss: 0.0246\n",
      "Epoch 19/200, Iteration 231/250, Loss: 0.0167\n",
      "Epoch 19/200, Iteration 232/250, Loss: 0.0216\n",
      "Epoch 19/200, Iteration 233/250, Loss: 0.0401\n",
      "Epoch 19/200, Iteration 234/250, Loss: 0.0176\n",
      "Epoch 19/200, Iteration 235/250, Loss: 0.0181\n",
      "Epoch 19/200, Iteration 236/250, Loss: 0.0475\n",
      "Epoch 19/200, Iteration 237/250, Loss: 0.0342\n",
      "Epoch 19/200, Iteration 238/250, Loss: 0.0531\n",
      "Epoch 19/200, Iteration 239/250, Loss: 0.0514\n",
      "Epoch 19/200, Iteration 240/250, Loss: 0.0365\n",
      "Epoch 19/200, Iteration 241/250, Loss: 0.0200\n",
      "Epoch 19/200, Iteration 242/250, Loss: 0.0339\n",
      "Epoch 19/200, Iteration 243/250, Loss: 0.0159\n",
      "Epoch 19/200, Iteration 244/250, Loss: 0.0286\n",
      "Epoch 19/200, Iteration 245/250, Loss: 0.0382\n",
      "Epoch 19/200, Iteration 246/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 247/250, Loss: 0.0616\n",
      "Epoch 19/200, Iteration 248/250, Loss: 0.0251\n",
      "Epoch 19/200, Iteration 249/250, Loss: 0.0239\n",
      "Epoch 19/200, Iteration 250/250, Loss: 0.0168\n",
      "Train Error: \n",
      " Accuracy: 73.32%, Avg loss: 0.010620, MRE: 1.024885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.85%, Avg loss: 0.010594, MRE: 1.284173 \n",
      "\n",
      "Epoch 20/200, Iteration 1/250, Loss: 0.0205\n",
      "Epoch 20/200, Iteration 2/250, Loss: 0.0172\n",
      "Epoch 20/200, Iteration 3/250, Loss: 0.0178\n",
      "Epoch 20/200, Iteration 4/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 5/250, Loss: 0.0212\n",
      "Epoch 20/200, Iteration 6/250, Loss: 0.0446\n",
      "Epoch 20/200, Iteration 7/250, Loss: 0.0678\n",
      "Epoch 20/200, Iteration 8/250, Loss: 0.0187\n",
      "Epoch 20/200, Iteration 9/250, Loss: 0.0312\n",
      "Epoch 20/200, Iteration 10/250, Loss: 0.0697\n",
      "Epoch 20/200, Iteration 11/250, Loss: 0.0343\n",
      "Epoch 20/200, Iteration 12/250, Loss: 0.0239\n",
      "Epoch 20/200, Iteration 13/250, Loss: 0.0182\n",
      "Epoch 20/200, Iteration 14/250, Loss: 0.0143\n",
      "Epoch 20/200, Iteration 15/250, Loss: 0.0480\n",
      "Epoch 20/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 20/200, Iteration 17/250, Loss: 0.0118\n",
      "Epoch 20/200, Iteration 18/250, Loss: 0.0304\n",
      "Epoch 20/200, Iteration 19/250, Loss: 0.0202\n",
      "Epoch 20/200, Iteration 20/250, Loss: 0.0308\n",
      "Epoch 20/200, Iteration 21/250, Loss: 0.0185\n",
      "Epoch 20/200, Iteration 22/250, Loss: 0.0156\n",
      "Epoch 20/200, Iteration 23/250, Loss: 0.0396\n",
      "Epoch 20/200, Iteration 24/250, Loss: 0.0120\n",
      "Epoch 20/200, Iteration 25/250, Loss: 0.0245\n",
      "Epoch 20/200, Iteration 26/250, Loss: 0.0149\n",
      "Epoch 20/200, Iteration 27/250, Loss: 0.0412\n",
      "Epoch 20/200, Iteration 28/250, Loss: 0.0213\n",
      "Epoch 20/200, Iteration 29/250, Loss: 0.0221\n",
      "Epoch 20/200, Iteration 30/250, Loss: 0.0193\n",
      "Epoch 20/200, Iteration 31/250, Loss: 0.0186\n",
      "Epoch 20/200, Iteration 32/250, Loss: 0.0318\n",
      "Epoch 20/200, Iteration 33/250, Loss: 0.0223\n",
      "Epoch 20/200, Iteration 34/250, Loss: 0.0198\n",
      "Epoch 20/200, Iteration 35/250, Loss: 0.0183\n",
      "Epoch 20/200, Iteration 36/250, Loss: 0.0176\n",
      "Epoch 20/200, Iteration 37/250, Loss: 0.0633\n",
      "Epoch 20/200, Iteration 38/250, Loss: 0.0283\n",
      "Epoch 20/200, Iteration 39/250, Loss: 0.0222\n",
      "Epoch 20/200, Iteration 40/250, Loss: 0.0215\n",
      "Epoch 20/200, Iteration 41/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 42/250, Loss: 0.0199\n",
      "Epoch 20/200, Iteration 43/250, Loss: 0.0230\n",
      "Epoch 20/200, Iteration 44/250, Loss: 0.0122\n",
      "Epoch 20/200, Iteration 45/250, Loss: 0.0286\n",
      "Epoch 20/200, Iteration 46/250, Loss: 0.0505\n",
      "Epoch 20/200, Iteration 47/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 48/250, Loss: 0.0295\n",
      "Epoch 20/200, Iteration 49/250, Loss: 0.0293\n",
      "Epoch 20/200, Iteration 50/250, Loss: 0.0179\n",
      "Epoch 20/200, Iteration 51/250, Loss: 0.0254\n",
      "Epoch 20/200, Iteration 52/250, Loss: 0.0191\n",
      "Epoch 20/200, Iteration 53/250, Loss: 0.0190\n",
      "Epoch 20/200, Iteration 54/250, Loss: 0.0131\n",
      "Epoch 20/200, Iteration 55/250, Loss: 0.0183\n",
      "Epoch 20/200, Iteration 56/250, Loss: 0.0131\n",
      "Epoch 20/200, Iteration 57/250, Loss: 0.0330\n",
      "Epoch 20/200, Iteration 58/250, Loss: 0.0433\n",
      "Epoch 20/200, Iteration 59/250, Loss: 0.0181\n",
      "Epoch 20/200, Iteration 60/250, Loss: 0.0300\n",
      "Epoch 20/200, Iteration 61/250, Loss: 0.0158\n",
      "Epoch 20/200, Iteration 62/250, Loss: 0.0410\n",
      "Epoch 20/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 20/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 20/200, Iteration 65/250, Loss: 0.0175\n",
      "Epoch 20/200, Iteration 66/250, Loss: 0.0152\n",
      "Epoch 20/200, Iteration 67/250, Loss: 0.0182\n",
      "Epoch 20/200, Iteration 68/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 69/250, Loss: 0.0144\n",
      "Epoch 20/200, Iteration 70/250, Loss: 0.0127\n",
      "Epoch 20/200, Iteration 71/250, Loss: 0.0190\n",
      "Epoch 20/200, Iteration 72/250, Loss: 0.0351\n",
      "Epoch 20/200, Iteration 73/250, Loss: 0.0266\n",
      "Epoch 20/200, Iteration 74/250, Loss: 0.0269\n",
      "Epoch 20/200, Iteration 75/250, Loss: 0.0247\n",
      "Epoch 20/200, Iteration 76/250, Loss: 0.0316\n",
      "Epoch 20/200, Iteration 77/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 78/250, Loss: 0.0152\n",
      "Epoch 20/200, Iteration 79/250, Loss: 0.0138\n",
      "Epoch 20/200, Iteration 80/250, Loss: 0.0148\n",
      "Epoch 20/200, Iteration 81/250, Loss: 0.0153\n",
      "Epoch 20/200, Iteration 82/250, Loss: 0.0187\n",
      "Epoch 20/200, Iteration 83/250, Loss: 0.0153\n",
      "Epoch 20/200, Iteration 84/250, Loss: 0.0138\n",
      "Epoch 20/200, Iteration 85/250, Loss: 0.0134\n",
      "Epoch 20/200, Iteration 86/250, Loss: 0.0112\n",
      "Epoch 20/200, Iteration 87/250, Loss: 0.0121\n",
      "Epoch 20/200, Iteration 88/250, Loss: 0.0062\n",
      "Epoch 20/200, Iteration 89/250, Loss: 0.0188\n",
      "Epoch 20/200, Iteration 90/250, Loss: 0.0181\n",
      "Epoch 20/200, Iteration 91/250, Loss: 0.0243\n",
      "Epoch 20/200, Iteration 92/250, Loss: 0.0164\n",
      "Epoch 20/200, Iteration 93/250, Loss: 0.0209\n",
      "Epoch 20/200, Iteration 94/250, Loss: 0.0359\n",
      "Epoch 20/200, Iteration 95/250, Loss: 0.0219\n",
      "Epoch 20/200, Iteration 96/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 97/250, Loss: 0.0317\n",
      "Epoch 20/200, Iteration 98/250, Loss: 0.0289\n",
      "Epoch 20/200, Iteration 99/250, Loss: 0.0296\n",
      "Epoch 20/200, Iteration 100/250, Loss: 0.0357\n",
      "Epoch 20/200, Iteration 101/250, Loss: 0.0273\n",
      "Epoch 20/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 20/200, Iteration 103/250, Loss: 0.0253\n",
      "Epoch 20/200, Iteration 104/250, Loss: 0.0352\n",
      "Epoch 20/200, Iteration 105/250, Loss: 0.0199\n",
      "Epoch 20/200, Iteration 106/250, Loss: 0.0212\n",
      "Epoch 20/200, Iteration 107/250, Loss: 0.0099\n",
      "Epoch 20/200, Iteration 108/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 109/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 110/250, Loss: 0.0243\n",
      "Epoch 20/200, Iteration 111/250, Loss: 0.0187\n",
      "Epoch 20/200, Iteration 112/250, Loss: 0.0200\n",
      "Epoch 20/200, Iteration 113/250, Loss: 0.0245\n",
      "Epoch 20/200, Iteration 114/250, Loss: 0.0174\n",
      "Epoch 20/200, Iteration 115/250, Loss: 0.0195\n",
      "Epoch 20/200, Iteration 116/250, Loss: 0.0331\n",
      "Epoch 20/200, Iteration 117/250, Loss: 0.0474\n",
      "Epoch 20/200, Iteration 118/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 119/250, Loss: 0.0267\n",
      "Epoch 20/200, Iteration 120/250, Loss: 0.0201\n",
      "Epoch 20/200, Iteration 121/250, Loss: 0.0326\n",
      "Epoch 20/200, Iteration 122/250, Loss: 0.0149\n",
      "Epoch 20/200, Iteration 123/250, Loss: 0.0198\n",
      "Epoch 20/200, Iteration 124/250, Loss: 0.0197\n",
      "Epoch 20/200, Iteration 125/250, Loss: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Iteration 126/250, Loss: 0.0152\n",
      "Epoch 20/200, Iteration 127/250, Loss: 0.0193\n",
      "Epoch 20/200, Iteration 128/250, Loss: 0.0172\n",
      "Epoch 20/200, Iteration 129/250, Loss: 0.0332\n",
      "Epoch 20/200, Iteration 130/250, Loss: 0.0212\n",
      "Epoch 20/200, Iteration 131/250, Loss: 0.0130\n",
      "Epoch 20/200, Iteration 132/250, Loss: 0.0199\n",
      "Epoch 20/200, Iteration 133/250, Loss: 0.0097\n",
      "Epoch 20/200, Iteration 134/250, Loss: 0.0206\n",
      "Epoch 20/200, Iteration 135/250, Loss: 0.0274\n",
      "Epoch 20/200, Iteration 136/250, Loss: 0.0294\n",
      "Epoch 20/200, Iteration 137/250, Loss: 0.0318\n",
      "Epoch 20/200, Iteration 138/250, Loss: 0.0211\n",
      "Epoch 20/200, Iteration 139/250, Loss: 0.0171\n",
      "Epoch 20/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 20/200, Iteration 141/250, Loss: 0.0132\n",
      "Epoch 20/200, Iteration 142/250, Loss: 0.0203\n",
      "Epoch 20/200, Iteration 143/250, Loss: 0.0156\n",
      "Epoch 20/200, Iteration 144/250, Loss: 0.0379\n",
      "Epoch 20/200, Iteration 145/250, Loss: 0.0113\n",
      "Epoch 20/200, Iteration 146/250, Loss: 0.0198\n",
      "Epoch 20/200, Iteration 147/250, Loss: 0.0207\n",
      "Epoch 20/200, Iteration 148/250, Loss: 0.0123\n",
      "Epoch 20/200, Iteration 149/250, Loss: 0.0146\n",
      "Epoch 20/200, Iteration 150/250, Loss: 0.0070\n",
      "Epoch 20/200, Iteration 151/250, Loss: 0.0123\n",
      "Epoch 20/200, Iteration 152/250, Loss: 0.0176\n",
      "Epoch 20/200, Iteration 153/250, Loss: 0.0163\n",
      "Epoch 20/200, Iteration 154/250, Loss: 0.0085\n",
      "Epoch 20/200, Iteration 155/250, Loss: 0.0111\n",
      "Epoch 20/200, Iteration 156/250, Loss: 0.0226\n",
      "Epoch 20/200, Iteration 157/250, Loss: 0.0099\n",
      "Epoch 20/200, Iteration 158/250, Loss: 0.0543\n",
      "Epoch 20/200, Iteration 159/250, Loss: 0.0250\n",
      "Epoch 20/200, Iteration 160/250, Loss: 0.0081\n",
      "Epoch 20/200, Iteration 161/250, Loss: 0.0145\n",
      "Epoch 20/200, Iteration 162/250, Loss: 0.0217\n",
      "Epoch 20/200, Iteration 163/250, Loss: 0.0241\n",
      "Epoch 20/200, Iteration 164/250, Loss: 0.0399\n",
      "Epoch 20/200, Iteration 165/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 166/250, Loss: 0.0234\n",
      "Epoch 20/200, Iteration 167/250, Loss: 0.0205\n",
      "Epoch 20/200, Iteration 168/250, Loss: 0.0275\n",
      "Epoch 20/200, Iteration 169/250, Loss: 0.0237\n",
      "Epoch 20/200, Iteration 170/250, Loss: 0.0208\n",
      "Epoch 20/200, Iteration 171/250, Loss: 0.0143\n",
      "Epoch 20/200, Iteration 172/250, Loss: 0.0246\n",
      "Epoch 20/200, Iteration 173/250, Loss: 0.0151\n",
      "Epoch 20/200, Iteration 174/250, Loss: 0.0164\n",
      "Epoch 20/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 20/200, Iteration 176/250, Loss: 0.0118\n",
      "Epoch 20/200, Iteration 177/250, Loss: 0.0155\n",
      "Epoch 20/200, Iteration 178/250, Loss: 0.0230\n",
      "Epoch 20/200, Iteration 179/250, Loss: 0.0183\n",
      "Epoch 20/200, Iteration 180/250, Loss: 0.0211\n",
      "Epoch 20/200, Iteration 181/250, Loss: 0.0258\n",
      "Epoch 20/200, Iteration 182/250, Loss: 0.0209\n",
      "Epoch 20/200, Iteration 183/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 184/250, Loss: 0.0201\n",
      "Epoch 20/200, Iteration 185/250, Loss: 0.0303\n",
      "Epoch 20/200, Iteration 186/250, Loss: 0.0095\n",
      "Epoch 20/200, Iteration 187/250, Loss: 0.0182\n",
      "Epoch 20/200, Iteration 188/250, Loss: 0.0244\n",
      "Epoch 20/200, Iteration 189/250, Loss: 0.0288\n",
      "Epoch 20/200, Iteration 190/250, Loss: 0.0245\n",
      "Epoch 20/200, Iteration 191/250, Loss: 0.0302\n",
      "Epoch 20/200, Iteration 192/250, Loss: 0.0139\n",
      "Epoch 20/200, Iteration 193/250, Loss: 0.0431\n",
      "Epoch 20/200, Iteration 194/250, Loss: 0.0336\n",
      "Epoch 20/200, Iteration 195/250, Loss: 0.0149\n",
      "Epoch 20/200, Iteration 196/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 197/250, Loss: 0.0230\n",
      "Epoch 20/200, Iteration 198/250, Loss: 0.0092\n",
      "Epoch 20/200, Iteration 199/250, Loss: 0.0201\n",
      "Epoch 20/200, Iteration 200/250, Loss: 0.0364\n",
      "Epoch 20/200, Iteration 201/250, Loss: 0.0264\n",
      "Epoch 20/200, Iteration 202/250, Loss: 0.0360\n",
      "Epoch 20/200, Iteration 203/250, Loss: 0.0225\n",
      "Epoch 20/200, Iteration 204/250, Loss: 0.0354\n",
      "Epoch 20/200, Iteration 205/250, Loss: 0.0181\n",
      "Epoch 20/200, Iteration 206/250, Loss: 0.0140\n",
      "Epoch 20/200, Iteration 207/250, Loss: 0.0123\n",
      "Epoch 20/200, Iteration 208/250, Loss: 0.0157\n",
      "Epoch 20/200, Iteration 209/250, Loss: 0.0340\n",
      "Epoch 20/200, Iteration 210/250, Loss: 0.0152\n",
      "Epoch 20/200, Iteration 211/250, Loss: 0.0095\n",
      "Epoch 20/200, Iteration 212/250, Loss: 0.0279\n",
      "Epoch 20/200, Iteration 213/250, Loss: 0.0221\n",
      "Epoch 20/200, Iteration 214/250, Loss: 0.0161\n",
      "Epoch 20/200, Iteration 215/250, Loss: 0.0264\n",
      "Epoch 20/200, Iteration 216/250, Loss: 0.0356\n",
      "Epoch 20/200, Iteration 217/250, Loss: 0.0422\n",
      "Epoch 20/200, Iteration 218/250, Loss: 0.0365\n",
      "Epoch 20/200, Iteration 219/250, Loss: 0.0141\n",
      "Epoch 20/200, Iteration 220/250, Loss: 0.0150\n",
      "Epoch 20/200, Iteration 221/250, Loss: 0.0167\n",
      "Epoch 20/200, Iteration 222/250, Loss: 0.0100\n",
      "Epoch 20/200, Iteration 223/250, Loss: 0.0133\n",
      "Epoch 20/200, Iteration 224/250, Loss: 0.0304\n",
      "Epoch 20/200, Iteration 225/250, Loss: 0.0429\n",
      "Epoch 20/200, Iteration 226/250, Loss: 0.0199\n",
      "Epoch 20/200, Iteration 227/250, Loss: 0.0332\n",
      "Epoch 20/200, Iteration 228/250, Loss: 0.0169\n",
      "Epoch 20/200, Iteration 229/250, Loss: 0.0329\n",
      "Epoch 20/200, Iteration 230/250, Loss: 0.0141\n",
      "Epoch 20/200, Iteration 231/250, Loss: 0.0301\n",
      "Epoch 20/200, Iteration 232/250, Loss: 0.0198\n",
      "Epoch 20/200, Iteration 233/250, Loss: 0.0158\n",
      "Epoch 20/200, Iteration 234/250, Loss: 0.0573\n",
      "Epoch 20/200, Iteration 235/250, Loss: 0.0176\n",
      "Epoch 20/200, Iteration 236/250, Loss: 0.0245\n",
      "Epoch 20/200, Iteration 237/250, Loss: 0.0257\n",
      "Epoch 20/200, Iteration 238/250, Loss: 0.0129\n",
      "Epoch 20/200, Iteration 239/250, Loss: 0.0253\n",
      "Epoch 20/200, Iteration 240/250, Loss: 0.0214\n",
      "Epoch 20/200, Iteration 241/250, Loss: 0.0323\n",
      "Epoch 20/200, Iteration 242/250, Loss: 0.0177\n",
      "Epoch 20/200, Iteration 243/250, Loss: 0.0152\n",
      "Epoch 20/200, Iteration 244/250, Loss: 0.0263\n",
      "Epoch 20/200, Iteration 245/250, Loss: 0.0157\n",
      "Epoch 20/200, Iteration 246/250, Loss: 0.0113\n",
      "Epoch 20/200, Iteration 247/250, Loss: 0.0147\n",
      "Epoch 20/200, Iteration 248/250, Loss: 0.0388\n",
      "Epoch 20/200, Iteration 249/250, Loss: 0.0154\n",
      "Epoch 20/200, Iteration 250/250, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 90.96%, Avg loss: 0.012307, MRE: 1.147086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.012174, MRE: 1.244273 \n",
      "\n",
      "Epoch 21/200, Iteration 1/250, Loss: 0.0126\n",
      "Epoch 21/200, Iteration 2/250, Loss: 0.0169\n",
      "Epoch 21/200, Iteration 3/250, Loss: 0.0168\n",
      "Epoch 21/200, Iteration 4/250, Loss: 0.0280\n",
      "Epoch 21/200, Iteration 5/250, Loss: 0.0184\n",
      "Epoch 21/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 21/200, Iteration 7/250, Loss: 0.0391\n",
      "Epoch 21/200, Iteration 8/250, Loss: 0.0184\n",
      "Epoch 21/200, Iteration 9/250, Loss: 0.0448\n",
      "Epoch 21/200, Iteration 10/250, Loss: 0.0313\n",
      "Epoch 21/200, Iteration 11/250, Loss: 0.0240\n",
      "Epoch 21/200, Iteration 12/250, Loss: 0.0170\n",
      "Epoch 21/200, Iteration 13/250, Loss: 0.0113\n",
      "Epoch 21/200, Iteration 14/250, Loss: 0.0246\n",
      "Epoch 21/200, Iteration 15/250, Loss: 0.0130\n",
      "Epoch 21/200, Iteration 16/250, Loss: 0.0262\n",
      "Epoch 21/200, Iteration 17/250, Loss: 0.0229\n",
      "Epoch 21/200, Iteration 18/250, Loss: 0.0415\n",
      "Epoch 21/200, Iteration 19/250, Loss: 0.0149\n",
      "Epoch 21/200, Iteration 20/250, Loss: 0.0146\n",
      "Epoch 21/200, Iteration 21/250, Loss: 0.0417\n",
      "Epoch 21/200, Iteration 22/250, Loss: 0.0234\n",
      "Epoch 21/200, Iteration 23/250, Loss: 0.0144\n",
      "Epoch 21/200, Iteration 24/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 25/250, Loss: 0.0114\n",
      "Epoch 21/200, Iteration 26/250, Loss: 0.0120\n",
      "Epoch 21/200, Iteration 27/250, Loss: 0.0471\n",
      "Epoch 21/200, Iteration 28/250, Loss: 0.0107\n",
      "Epoch 21/200, Iteration 29/250, Loss: 0.0132\n",
      "Epoch 21/200, Iteration 30/250, Loss: 0.0189\n",
      "Epoch 21/200, Iteration 31/250, Loss: 0.0157\n",
      "Epoch 21/200, Iteration 32/250, Loss: 0.0163\n",
      "Epoch 21/200, Iteration 33/250, Loss: 0.0242\n",
      "Epoch 21/200, Iteration 34/250, Loss: 0.0230\n",
      "Epoch 21/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 21/200, Iteration 36/250, Loss: 0.0122\n",
      "Epoch 21/200, Iteration 37/250, Loss: 0.0172\n",
      "Epoch 21/200, Iteration 38/250, Loss: 0.0181\n",
      "Epoch 21/200, Iteration 39/250, Loss: 0.0224\n",
      "Epoch 21/200, Iteration 40/250, Loss: 0.0151\n",
      "Epoch 21/200, Iteration 41/250, Loss: 0.0172\n",
      "Epoch 21/200, Iteration 42/250, Loss: 0.0233\n",
      "Epoch 21/200, Iteration 43/250, Loss: 0.0513\n",
      "Epoch 21/200, Iteration 44/250, Loss: 0.0151\n",
      "Epoch 21/200, Iteration 45/250, Loss: 0.0157\n",
      "Epoch 21/200, Iteration 46/250, Loss: 0.0122\n",
      "Epoch 21/200, Iteration 47/250, Loss: 0.0263\n",
      "Epoch 21/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 21/200, Iteration 49/250, Loss: 0.0184\n",
      "Epoch 21/200, Iteration 50/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 51/250, Loss: 0.0147\n",
      "Epoch 21/200, Iteration 52/250, Loss: 0.0354\n",
      "Epoch 21/200, Iteration 53/250, Loss: 0.0332\n",
      "Epoch 21/200, Iteration 54/250, Loss: 0.0206\n",
      "Epoch 21/200, Iteration 55/250, Loss: 0.0380\n",
      "Epoch 21/200, Iteration 56/250, Loss: 0.0189\n",
      "Epoch 21/200, Iteration 57/250, Loss: 0.0164\n",
      "Epoch 21/200, Iteration 58/250, Loss: 0.0220\n",
      "Epoch 21/200, Iteration 59/250, Loss: 0.0145\n",
      "Epoch 21/200, Iteration 60/250, Loss: 0.0287\n",
      "Epoch 21/200, Iteration 61/250, Loss: 0.0315\n",
      "Epoch 21/200, Iteration 62/250, Loss: 0.0145\n",
      "Epoch 21/200, Iteration 63/250, Loss: 0.0288\n",
      "Epoch 21/200, Iteration 64/250, Loss: 0.0340\n",
      "Epoch 21/200, Iteration 65/250, Loss: 0.0135\n",
      "Epoch 21/200, Iteration 66/250, Loss: 0.0140\n",
      "Epoch 21/200, Iteration 67/250, Loss: 0.0112\n",
      "Epoch 21/200, Iteration 68/250, Loss: 0.0175\n",
      "Epoch 21/200, Iteration 69/250, Loss: 0.0204\n",
      "Epoch 21/200, Iteration 70/250, Loss: 0.0166\n",
      "Epoch 21/200, Iteration 71/250, Loss: 0.0138\n",
      "Epoch 21/200, Iteration 72/250, Loss: 0.0118\n",
      "Epoch 21/200, Iteration 73/250, Loss: 0.0495\n",
      "Epoch 21/200, Iteration 74/250, Loss: 0.0138\n",
      "Epoch 21/200, Iteration 75/250, Loss: 0.0236\n",
      "Epoch 21/200, Iteration 76/250, Loss: 0.0462\n",
      "Epoch 21/200, Iteration 77/250, Loss: 0.0367\n",
      "Epoch 21/200, Iteration 78/250, Loss: 0.0186\n",
      "Epoch 21/200, Iteration 79/250, Loss: 0.0265\n",
      "Epoch 21/200, Iteration 80/250, Loss: 0.0173\n",
      "Epoch 21/200, Iteration 81/250, Loss: 0.0225\n",
      "Epoch 21/200, Iteration 82/250, Loss: 0.0124\n",
      "Epoch 21/200, Iteration 83/250, Loss: 0.0185\n",
      "Epoch 21/200, Iteration 84/250, Loss: 0.0283\n",
      "Epoch 21/200, Iteration 85/250, Loss: 0.0403\n",
      "Epoch 21/200, Iteration 86/250, Loss: 0.0296\n",
      "Epoch 21/200, Iteration 87/250, Loss: 0.0185\n",
      "Epoch 21/200, Iteration 88/250, Loss: 0.0237\n",
      "Epoch 21/200, Iteration 89/250, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Iteration 90/250, Loss: 0.0179\n",
      "Epoch 21/200, Iteration 91/250, Loss: 0.0095\n",
      "Epoch 21/200, Iteration 92/250, Loss: 0.0266\n",
      "Epoch 21/200, Iteration 93/250, Loss: 0.0360\n",
      "Epoch 21/200, Iteration 94/250, Loss: 0.0262\n",
      "Epoch 21/200, Iteration 95/250, Loss: 0.0364\n",
      "Epoch 21/200, Iteration 96/250, Loss: 0.0203\n",
      "Epoch 21/200, Iteration 97/250, Loss: 0.0266\n",
      "Epoch 21/200, Iteration 98/250, Loss: 0.0280\n",
      "Epoch 21/200, Iteration 99/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 100/250, Loss: 0.0173\n",
      "Epoch 21/200, Iteration 101/250, Loss: 0.0285\n",
      "Epoch 21/200, Iteration 102/250, Loss: 0.0177\n",
      "Epoch 21/200, Iteration 103/250, Loss: 0.0139\n",
      "Epoch 21/200, Iteration 104/250, Loss: 0.0452\n",
      "Epoch 21/200, Iteration 105/250, Loss: 0.0301\n",
      "Epoch 21/200, Iteration 106/250, Loss: 0.0181\n",
      "Epoch 21/200, Iteration 107/250, Loss: 0.0234\n",
      "Epoch 21/200, Iteration 108/250, Loss: 0.0340\n",
      "Epoch 21/200, Iteration 109/250, Loss: 0.0339\n",
      "Epoch 21/200, Iteration 110/250, Loss: 0.0313\n",
      "Epoch 21/200, Iteration 111/250, Loss: 0.0145\n",
      "Epoch 21/200, Iteration 112/250, Loss: 0.0143\n",
      "Epoch 21/200, Iteration 113/250, Loss: 0.0393\n",
      "Epoch 21/200, Iteration 114/250, Loss: 0.0141\n",
      "Epoch 21/200, Iteration 115/250, Loss: 0.0123\n",
      "Epoch 21/200, Iteration 116/250, Loss: 0.0330\n",
      "Epoch 21/200, Iteration 117/250, Loss: 0.0300\n",
      "Epoch 21/200, Iteration 118/250, Loss: 0.0330\n",
      "Epoch 21/200, Iteration 119/250, Loss: 0.0190\n",
      "Epoch 21/200, Iteration 120/250, Loss: 0.0361\n",
      "Epoch 21/200, Iteration 121/250, Loss: 0.0357\n",
      "Epoch 21/200, Iteration 122/250, Loss: 0.0134\n",
      "Epoch 21/200, Iteration 123/250, Loss: 0.0147\n",
      "Epoch 21/200, Iteration 124/250, Loss: 0.0233\n",
      "Epoch 21/200, Iteration 125/250, Loss: 0.0135\n",
      "Epoch 21/200, Iteration 126/250, Loss: 0.0139\n",
      "Epoch 21/200, Iteration 127/250, Loss: 0.0236\n",
      "Epoch 21/200, Iteration 128/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 129/250, Loss: 0.0173\n",
      "Epoch 21/200, Iteration 130/250, Loss: 0.0222\n",
      "Epoch 21/200, Iteration 131/250, Loss: 0.0101\n",
      "Epoch 21/200, Iteration 132/250, Loss: 0.0350\n",
      "Epoch 21/200, Iteration 133/250, Loss: 0.0436\n",
      "Epoch 21/200, Iteration 134/250, Loss: 0.0526\n",
      "Epoch 21/200, Iteration 135/250, Loss: 0.0157\n",
      "Epoch 21/200, Iteration 136/250, Loss: 0.0270\n",
      "Epoch 21/200, Iteration 137/250, Loss: 0.0175\n",
      "Epoch 21/200, Iteration 138/250, Loss: 0.0295\n",
      "Epoch 21/200, Iteration 139/250, Loss: 0.0156\n",
      "Epoch 21/200, Iteration 140/250, Loss: 0.0210\n",
      "Epoch 21/200, Iteration 141/250, Loss: 0.0250\n",
      "Epoch 21/200, Iteration 142/250, Loss: 0.0165\n",
      "Epoch 21/200, Iteration 143/250, Loss: 0.0354\n",
      "Epoch 21/200, Iteration 144/250, Loss: 0.0274\n",
      "Epoch 21/200, Iteration 145/250, Loss: 0.0154\n",
      "Epoch 21/200, Iteration 146/250, Loss: 0.0135\n",
      "Epoch 21/200, Iteration 147/250, Loss: 0.0166\n",
      "Epoch 21/200, Iteration 148/250, Loss: 0.0230\n",
      "Epoch 21/200, Iteration 149/250, Loss: 0.0175\n",
      "Epoch 21/200, Iteration 150/250, Loss: 0.0131\n",
      "Epoch 21/200, Iteration 151/250, Loss: 0.0275\n",
      "Epoch 21/200, Iteration 152/250, Loss: 0.0092\n",
      "Epoch 21/200, Iteration 153/250, Loss: 0.0324\n",
      "Epoch 21/200, Iteration 154/250, Loss: 0.0182\n",
      "Epoch 21/200, Iteration 155/250, Loss: 0.0291\n",
      "Epoch 21/200, Iteration 156/250, Loss: 0.0200\n",
      "Epoch 21/200, Iteration 157/250, Loss: 0.0105\n",
      "Epoch 21/200, Iteration 158/250, Loss: 0.0285\n",
      "Epoch 21/200, Iteration 159/250, Loss: 0.0226\n",
      "Epoch 21/200, Iteration 160/250, Loss: 0.0219\n",
      "Epoch 21/200, Iteration 161/250, Loss: 0.0179\n",
      "Epoch 21/200, Iteration 162/250, Loss: 0.0283\n",
      "Epoch 21/200, Iteration 163/250, Loss: 0.0152\n",
      "Epoch 21/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 21/200, Iteration 165/250, Loss: 0.0140\n",
      "Epoch 21/200, Iteration 166/250, Loss: 0.0193\n",
      "Epoch 21/200, Iteration 167/250, Loss: 0.0179\n",
      "Epoch 21/200, Iteration 168/250, Loss: 0.0218\n",
      "Epoch 21/200, Iteration 169/250, Loss: 0.0223\n",
      "Epoch 21/200, Iteration 170/250, Loss: 0.0235\n",
      "Epoch 21/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 21/200, Iteration 172/250, Loss: 0.0248\n",
      "Epoch 21/200, Iteration 173/250, Loss: 0.0294\n",
      "Epoch 21/200, Iteration 174/250, Loss: 0.0117\n",
      "Epoch 21/200, Iteration 175/250, Loss: 0.0277\n",
      "Epoch 21/200, Iteration 176/250, Loss: 0.0288\n",
      "Epoch 21/200, Iteration 177/250, Loss: 0.0408\n",
      "Epoch 21/200, Iteration 178/250, Loss: 0.0239\n",
      "Epoch 21/200, Iteration 179/250, Loss: 0.0394\n",
      "Epoch 21/200, Iteration 180/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 181/250, Loss: 0.0411\n",
      "Epoch 21/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 21/200, Iteration 183/250, Loss: 0.0119\n",
      "Epoch 21/200, Iteration 184/250, Loss: 0.0143\n",
      "Epoch 21/200, Iteration 185/250, Loss: 0.0148\n",
      "Epoch 21/200, Iteration 186/250, Loss: 0.0228\n",
      "Epoch 21/200, Iteration 187/250, Loss: 0.0279\n",
      "Epoch 21/200, Iteration 188/250, Loss: 0.0130\n",
      "Epoch 21/200, Iteration 189/250, Loss: 0.0215\n",
      "Epoch 21/200, Iteration 190/250, Loss: 0.0165\n",
      "Epoch 21/200, Iteration 191/250, Loss: 0.0114\n",
      "Epoch 21/200, Iteration 192/250, Loss: 0.0118\n",
      "Epoch 21/200, Iteration 193/250, Loss: 0.0163\n",
      "Epoch 21/200, Iteration 194/250, Loss: 0.0156\n",
      "Epoch 21/200, Iteration 195/250, Loss: 0.0153\n",
      "Epoch 21/200, Iteration 196/250, Loss: 0.0124\n",
      "Epoch 21/200, Iteration 197/250, Loss: 0.0174\n",
      "Epoch 21/200, Iteration 198/250, Loss: 0.0113\n",
      "Epoch 21/200, Iteration 199/250, Loss: 0.0404\n",
      "Epoch 21/200, Iteration 200/250, Loss: 0.0212\n",
      "Epoch 21/200, Iteration 201/250, Loss: 0.0196\n",
      "Epoch 21/200, Iteration 202/250, Loss: 0.0236\n",
      "Epoch 21/200, Iteration 203/250, Loss: 0.0342\n",
      "Epoch 21/200, Iteration 204/250, Loss: 0.0203\n",
      "Epoch 21/200, Iteration 205/250, Loss: 0.0111\n",
      "Epoch 21/200, Iteration 206/250, Loss: 0.0196\n",
      "Epoch 21/200, Iteration 207/250, Loss: 0.0146\n",
      "Epoch 21/200, Iteration 208/250, Loss: 0.0363\n",
      "Epoch 21/200, Iteration 209/250, Loss: 0.0193\n",
      "Epoch 21/200, Iteration 210/250, Loss: 0.0247\n",
      "Epoch 21/200, Iteration 211/250, Loss: 0.0476\n",
      "Epoch 21/200, Iteration 212/250, Loss: 0.0159\n",
      "Epoch 21/200, Iteration 213/250, Loss: 0.0245\n",
      "Epoch 21/200, Iteration 214/250, Loss: 0.0248\n",
      "Epoch 21/200, Iteration 215/250, Loss: 0.0099\n",
      "Epoch 21/200, Iteration 216/250, Loss: 0.0124\n",
      "Epoch 21/200, Iteration 217/250, Loss: 0.0193\n",
      "Epoch 21/200, Iteration 218/250, Loss: 0.0119\n",
      "Epoch 21/200, Iteration 219/250, Loss: 0.0176\n",
      "Epoch 21/200, Iteration 220/250, Loss: 0.0133\n",
      "Epoch 21/200, Iteration 221/250, Loss: 0.0145\n",
      "Epoch 21/200, Iteration 222/250, Loss: 0.0113\n",
      "Epoch 21/200, Iteration 223/250, Loss: 0.0112\n",
      "Epoch 21/200, Iteration 224/250, Loss: 0.0205\n",
      "Epoch 21/200, Iteration 225/250, Loss: 0.0210\n",
      "Epoch 21/200, Iteration 226/250, Loss: 0.0113\n",
      "Epoch 21/200, Iteration 227/250, Loss: 0.0361\n",
      "Epoch 21/200, Iteration 228/250, Loss: 0.0304\n",
      "Epoch 21/200, Iteration 229/250, Loss: 0.0108\n",
      "Epoch 21/200, Iteration 230/250, Loss: 0.0185\n",
      "Epoch 21/200, Iteration 231/250, Loss: 0.0358\n",
      "Epoch 21/200, Iteration 232/250, Loss: 0.0212\n",
      "Epoch 21/200, Iteration 233/250, Loss: 0.0262\n",
      "Epoch 21/200, Iteration 234/250, Loss: 0.0272\n",
      "Epoch 21/200, Iteration 235/250, Loss: 0.0188\n",
      "Epoch 21/200, Iteration 236/250, Loss: 0.0277\n",
      "Epoch 21/200, Iteration 237/250, Loss: 0.0520\n",
      "Epoch 21/200, Iteration 238/250, Loss: 0.0333\n",
      "Epoch 21/200, Iteration 239/250, Loss: 0.0140\n",
      "Epoch 21/200, Iteration 240/250, Loss: 0.0790\n",
      "Epoch 21/200, Iteration 241/250, Loss: 0.0476\n",
      "Epoch 21/200, Iteration 242/250, Loss: 0.0249\n",
      "Epoch 21/200, Iteration 243/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 244/250, Loss: 0.0331\n",
      "Epoch 21/200, Iteration 245/250, Loss: 0.0139\n",
      "Epoch 21/200, Iteration 246/250, Loss: 0.0143\n",
      "Epoch 21/200, Iteration 247/250, Loss: 0.0529\n",
      "Epoch 21/200, Iteration 248/250, Loss: 0.0153\n",
      "Epoch 21/200, Iteration 249/250, Loss: 0.0120\n",
      "Epoch 21/200, Iteration 250/250, Loss: 0.0153\n",
      "Train Error: \n",
      " Accuracy: 49.46%, Avg loss: 0.012908, MRE: 1.066297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.45%, Avg loss: 0.013006, MRE: 1.260094 \n",
      "\n",
      "Epoch 22/200, Iteration 1/250, Loss: 0.0230\n",
      "Epoch 22/200, Iteration 2/250, Loss: 0.0291\n",
      "Epoch 22/200, Iteration 3/250, Loss: 0.0344\n",
      "Epoch 22/200, Iteration 4/250, Loss: 0.0308\n",
      "Epoch 22/200, Iteration 5/250, Loss: 0.0359\n",
      "Epoch 22/200, Iteration 6/250, Loss: 0.0335\n",
      "Epoch 22/200, Iteration 7/250, Loss: 0.0246\n",
      "Epoch 22/200, Iteration 8/250, Loss: 0.0387\n",
      "Epoch 22/200, Iteration 9/250, Loss: 0.0310\n",
      "Epoch 22/200, Iteration 10/250, Loss: 0.0201\n",
      "Epoch 22/200, Iteration 11/250, Loss: 0.0223\n",
      "Epoch 22/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 22/200, Iteration 13/250, Loss: 0.0123\n",
      "Epoch 22/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 22/200, Iteration 15/250, Loss: 0.0262\n",
      "Epoch 22/200, Iteration 16/250, Loss: 0.0203\n",
      "Epoch 22/200, Iteration 17/250, Loss: 0.0177\n",
      "Epoch 22/200, Iteration 18/250, Loss: 0.0240\n",
      "Epoch 22/200, Iteration 19/250, Loss: 0.0278\n",
      "Epoch 22/200, Iteration 20/250, Loss: 0.0379\n",
      "Epoch 22/200, Iteration 21/250, Loss: 0.0509\n",
      "Epoch 22/200, Iteration 22/250, Loss: 0.0246\n",
      "Epoch 22/200, Iteration 23/250, Loss: 0.0320\n",
      "Epoch 22/200, Iteration 24/250, Loss: 0.0392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Iteration 25/250, Loss: 0.0322\n",
      "Epoch 22/200, Iteration 26/250, Loss: 0.0426\n",
      "Epoch 22/200, Iteration 27/250, Loss: 0.0327\n",
      "Epoch 22/200, Iteration 28/250, Loss: 0.0186\n",
      "Epoch 22/200, Iteration 29/250, Loss: 0.0113\n",
      "Epoch 22/200, Iteration 30/250, Loss: 0.0170\n",
      "Epoch 22/200, Iteration 31/250, Loss: 0.0410\n",
      "Epoch 22/200, Iteration 32/250, Loss: 0.0637\n",
      "Epoch 22/200, Iteration 33/250, Loss: 0.0301\n",
      "Epoch 22/200, Iteration 34/250, Loss: 0.0133\n",
      "Epoch 22/200, Iteration 35/250, Loss: 0.0233\n",
      "Epoch 22/200, Iteration 36/250, Loss: 0.0099\n",
      "Epoch 22/200, Iteration 37/250, Loss: 0.0292\n",
      "Epoch 22/200, Iteration 38/250, Loss: 0.0219\n",
      "Epoch 22/200, Iteration 39/250, Loss: 0.0405\n",
      "Epoch 22/200, Iteration 40/250, Loss: 0.0263\n",
      "Epoch 22/200, Iteration 41/250, Loss: 0.0157\n",
      "Epoch 22/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 22/200, Iteration 43/250, Loss: 0.0206\n",
      "Epoch 22/200, Iteration 44/250, Loss: 0.0188\n",
      "Epoch 22/200, Iteration 45/250, Loss: 0.0177\n",
      "Epoch 22/200, Iteration 46/250, Loss: 0.0210\n",
      "Epoch 22/200, Iteration 47/250, Loss: 0.0244\n",
      "Epoch 22/200, Iteration 48/250, Loss: 0.0415\n",
      "Epoch 22/200, Iteration 49/250, Loss: 0.0343\n",
      "Epoch 22/200, Iteration 50/250, Loss: 0.0208\n",
      "Epoch 22/200, Iteration 51/250, Loss: 0.0305\n",
      "Epoch 22/200, Iteration 52/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 53/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 54/250, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 55/250, Loss: 0.0647\n",
      "Epoch 22/200, Iteration 56/250, Loss: 0.0171\n",
      "Epoch 22/200, Iteration 57/250, Loss: 0.0184\n",
      "Epoch 22/200, Iteration 58/250, Loss: 0.0196\n",
      "Epoch 22/200, Iteration 59/250, Loss: 0.0110\n",
      "Epoch 22/200, Iteration 60/250, Loss: 0.0161\n",
      "Epoch 22/200, Iteration 61/250, Loss: 0.0130\n",
      "Epoch 22/200, Iteration 62/250, Loss: 0.0181\n",
      "Epoch 22/200, Iteration 63/250, Loss: 0.0227\n",
      "Epoch 22/200, Iteration 64/250, Loss: 0.0420\n",
      "Epoch 22/200, Iteration 65/250, Loss: 0.0469\n",
      "Epoch 22/200, Iteration 66/250, Loss: 0.0121\n",
      "Epoch 22/200, Iteration 67/250, Loss: 0.0397\n",
      "Epoch 22/200, Iteration 68/250, Loss: 0.0216\n",
      "Epoch 22/200, Iteration 69/250, Loss: 0.0342\n",
      "Epoch 22/200, Iteration 70/250, Loss: 0.0213\n",
      "Epoch 22/200, Iteration 71/250, Loss: 0.0246\n",
      "Epoch 22/200, Iteration 72/250, Loss: 0.0157\n",
      "Epoch 22/200, Iteration 73/250, Loss: 0.0193\n",
      "Epoch 22/200, Iteration 74/250, Loss: 0.0124\n",
      "Epoch 22/200, Iteration 75/250, Loss: 0.0132\n",
      "Epoch 22/200, Iteration 76/250, Loss: 0.0282\n",
      "Epoch 22/200, Iteration 77/250, Loss: 0.0279\n",
      "Epoch 22/200, Iteration 78/250, Loss: 0.0193\n",
      "Epoch 22/200, Iteration 79/250, Loss: 0.0162\n",
      "Epoch 22/200, Iteration 80/250, Loss: 0.0162\n",
      "Epoch 22/200, Iteration 81/250, Loss: 0.0134\n",
      "Epoch 22/200, Iteration 82/250, Loss: 0.0116\n",
      "Epoch 22/200, Iteration 83/250, Loss: 0.0286\n",
      "Epoch 22/200, Iteration 84/250, Loss: 0.0200\n",
      "Epoch 22/200, Iteration 85/250, Loss: 0.0250\n",
      "Epoch 22/200, Iteration 86/250, Loss: 0.0191\n",
      "Epoch 22/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 22/200, Iteration 88/250, Loss: 0.0265\n",
      "Epoch 22/200, Iteration 89/250, Loss: 0.0151\n",
      "Epoch 22/200, Iteration 90/250, Loss: 0.0300\n",
      "Epoch 22/200, Iteration 91/250, Loss: 0.0095\n",
      "Epoch 22/200, Iteration 92/250, Loss: 0.0326\n",
      "Epoch 22/200, Iteration 93/250, Loss: 0.0180\n",
      "Epoch 22/200, Iteration 94/250, Loss: 0.0181\n",
      "Epoch 22/200, Iteration 95/250, Loss: 0.0188\n",
      "Epoch 22/200, Iteration 96/250, Loss: 0.0161\n",
      "Epoch 22/200, Iteration 97/250, Loss: 0.0196\n",
      "Epoch 22/200, Iteration 98/250, Loss: 0.0575\n",
      "Epoch 22/200, Iteration 99/250, Loss: 0.0232\n",
      "Epoch 22/200, Iteration 100/250, Loss: 0.0342\n",
      "Epoch 22/200, Iteration 101/250, Loss: 0.0094\n",
      "Epoch 22/200, Iteration 102/250, Loss: 0.0236\n",
      "Epoch 22/200, Iteration 103/250, Loss: 0.0147\n",
      "Epoch 22/200, Iteration 104/250, Loss: 0.0300\n",
      "Epoch 22/200, Iteration 105/250, Loss: 0.0234\n",
      "Epoch 22/200, Iteration 106/250, Loss: 0.0246\n",
      "Epoch 22/200, Iteration 107/250, Loss: 0.0180\n",
      "Epoch 22/200, Iteration 108/250, Loss: 0.0178\n",
      "Epoch 22/200, Iteration 109/250, Loss: 0.0195\n",
      "Epoch 22/200, Iteration 110/250, Loss: 0.0314\n",
      "Epoch 22/200, Iteration 111/250, Loss: 0.0088\n",
      "Epoch 22/200, Iteration 112/250, Loss: 0.0239\n",
      "Epoch 22/200, Iteration 113/250, Loss: 0.0260\n",
      "Epoch 22/200, Iteration 114/250, Loss: 0.0112\n",
      "Epoch 22/200, Iteration 115/250, Loss: 0.0213\n",
      "Epoch 22/200, Iteration 116/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 117/250, Loss: 0.0203\n",
      "Epoch 22/200, Iteration 118/250, Loss: 0.0238\n",
      "Epoch 22/200, Iteration 119/250, Loss: 0.0181\n",
      "Epoch 22/200, Iteration 120/250, Loss: 0.0182\n",
      "Epoch 22/200, Iteration 121/250, Loss: 0.0128\n",
      "Epoch 22/200, Iteration 122/250, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 123/250, Loss: 0.0164\n",
      "Epoch 22/200, Iteration 124/250, Loss: 0.0104\n",
      "Epoch 22/200, Iteration 125/250, Loss: 0.0138\n",
      "Epoch 22/200, Iteration 126/250, Loss: 0.0215\n",
      "Epoch 22/200, Iteration 127/250, Loss: 0.0234\n",
      "Epoch 22/200, Iteration 128/250, Loss: 0.0191\n",
      "Epoch 22/200, Iteration 129/250, Loss: 0.0157\n",
      "Epoch 22/200, Iteration 130/250, Loss: 0.0161\n",
      "Epoch 22/200, Iteration 131/250, Loss: 0.0322\n",
      "Epoch 22/200, Iteration 132/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 133/250, Loss: 0.0324\n",
      "Epoch 22/200, Iteration 134/250, Loss: 0.0190\n",
      "Epoch 22/200, Iteration 135/250, Loss: 0.0117\n",
      "Epoch 22/200, Iteration 136/250, Loss: 0.0334\n",
      "Epoch 22/200, Iteration 137/250, Loss: 0.0444\n",
      "Epoch 22/200, Iteration 138/250, Loss: 0.0351\n",
      "Epoch 22/200, Iteration 139/250, Loss: 0.0398\n",
      "Epoch 22/200, Iteration 140/250, Loss: 0.0174\n",
      "Epoch 22/200, Iteration 141/250, Loss: 0.0222\n",
      "Epoch 22/200, Iteration 142/250, Loss: 0.0222\n",
      "Epoch 22/200, Iteration 143/250, Loss: 0.0480\n",
      "Epoch 22/200, Iteration 144/250, Loss: 0.0171\n",
      "Epoch 22/200, Iteration 145/250, Loss: 0.0143\n",
      "Epoch 22/200, Iteration 146/250, Loss: 0.0295\n",
      "Epoch 22/200, Iteration 147/250, Loss: 0.0143\n",
      "Epoch 22/200, Iteration 148/250, Loss: 0.0162\n",
      "Epoch 22/200, Iteration 149/250, Loss: 0.0185\n",
      "Epoch 22/200, Iteration 150/250, Loss: 0.0211\n",
      "Epoch 22/200, Iteration 151/250, Loss: 0.0247\n",
      "Epoch 22/200, Iteration 152/250, Loss: 0.0318\n",
      "Epoch 22/200, Iteration 153/250, Loss: 0.0149\n",
      "Epoch 22/200, Iteration 154/250, Loss: 0.0386\n",
      "Epoch 22/200, Iteration 155/250, Loss: 0.0204\n",
      "Epoch 22/200, Iteration 156/250, Loss: 0.0172\n",
      "Epoch 22/200, Iteration 157/250, Loss: 0.0329\n",
      "Epoch 22/200, Iteration 158/250, Loss: 0.0208\n",
      "Epoch 22/200, Iteration 159/250, Loss: 0.0096\n",
      "Epoch 22/200, Iteration 160/250, Loss: 0.0156\n",
      "Epoch 22/200, Iteration 161/250, Loss: 0.0459\n",
      "Epoch 22/200, Iteration 162/250, Loss: 0.0169\n",
      "Epoch 22/200, Iteration 163/250, Loss: 0.0461\n",
      "Epoch 22/200, Iteration 164/250, Loss: 0.0099\n",
      "Epoch 22/200, Iteration 165/250, Loss: 0.0320\n",
      "Epoch 22/200, Iteration 166/250, Loss: 0.0206\n",
      "Epoch 22/200, Iteration 167/250, Loss: 0.0832\n",
      "Epoch 22/200, Iteration 168/250, Loss: 0.0391\n",
      "Epoch 22/200, Iteration 169/250, Loss: 0.0385\n",
      "Epoch 22/200, Iteration 170/250, Loss: 0.0471\n",
      "Epoch 22/200, Iteration 171/250, Loss: 0.0301\n",
      "Epoch 22/200, Iteration 172/250, Loss: 0.0321\n",
      "Epoch 22/200, Iteration 173/250, Loss: 0.0482\n",
      "Epoch 22/200, Iteration 174/250, Loss: 0.0283\n",
      "Epoch 22/200, Iteration 175/250, Loss: 0.0376\n",
      "Epoch 22/200, Iteration 176/250, Loss: 0.0611\n",
      "Epoch 22/200, Iteration 177/250, Loss: 0.0644\n",
      "Epoch 22/200, Iteration 178/250, Loss: 0.0409\n",
      "Epoch 22/200, Iteration 179/250, Loss: 0.0341\n",
      "Epoch 22/200, Iteration 180/250, Loss: 0.1678\n",
      "Epoch 22/200, Iteration 181/250, Loss: 0.0660\n",
      "Epoch 22/200, Iteration 182/250, Loss: 0.0705\n",
      "Epoch 22/200, Iteration 183/250, Loss: 0.0165\n",
      "Epoch 22/200, Iteration 184/250, Loss: 0.1005\n",
      "Epoch 22/200, Iteration 185/250, Loss: 0.0252\n",
      "Epoch 22/200, Iteration 186/250, Loss: 0.0553\n",
      "Epoch 22/200, Iteration 187/250, Loss: 0.0466\n",
      "Epoch 22/200, Iteration 188/250, Loss: 0.1121\n",
      "Epoch 22/200, Iteration 189/250, Loss: 0.1041\n",
      "Epoch 22/200, Iteration 190/250, Loss: 0.0752\n",
      "Epoch 22/200, Iteration 191/250, Loss: 0.0883\n",
      "Epoch 22/200, Iteration 192/250, Loss: 0.0578\n",
      "Epoch 22/200, Iteration 193/250, Loss: 0.1055\n",
      "Epoch 22/200, Iteration 194/250, Loss: 0.0531\n",
      "Epoch 22/200, Iteration 195/250, Loss: 0.0588\n",
      "Epoch 22/200, Iteration 196/250, Loss: 0.1128\n",
      "Epoch 22/200, Iteration 197/250, Loss: 0.0603\n",
      "Epoch 22/200, Iteration 198/250, Loss: 0.0400\n",
      "Epoch 22/200, Iteration 199/250, Loss: 0.0360\n",
      "Epoch 22/200, Iteration 200/250, Loss: 0.0847\n",
      "Epoch 22/200, Iteration 201/250, Loss: 0.0402\n",
      "Epoch 22/200, Iteration 202/250, Loss: 0.1309\n",
      "Epoch 22/200, Iteration 203/250, Loss: 0.1245\n",
      "Epoch 22/200, Iteration 204/250, Loss: 0.0661\n",
      "Epoch 22/200, Iteration 205/250, Loss: 0.0647\n",
      "Epoch 22/200, Iteration 206/250, Loss: 0.0370\n",
      "Epoch 22/200, Iteration 207/250, Loss: 0.0455\n",
      "Epoch 22/200, Iteration 208/250, Loss: 0.0742\n",
      "Epoch 22/200, Iteration 209/250, Loss: 0.0433\n",
      "Epoch 22/200, Iteration 210/250, Loss: 0.0888\n",
      "Epoch 22/200, Iteration 211/250, Loss: 0.1737\n",
      "Epoch 22/200, Iteration 212/250, Loss: 0.0323\n",
      "Epoch 22/200, Iteration 213/250, Loss: 0.0586\n",
      "Epoch 22/200, Iteration 214/250, Loss: 0.0438\n",
      "Epoch 22/200, Iteration 215/250, Loss: 0.0508\n",
      "Epoch 22/200, Iteration 216/250, Loss: 0.0356\n",
      "Epoch 22/200, Iteration 217/250, Loss: 0.0647\n",
      "Epoch 22/200, Iteration 218/250, Loss: 0.0326\n",
      "Epoch 22/200, Iteration 219/250, Loss: 0.0529\n",
      "Epoch 22/200, Iteration 220/250, Loss: 0.0684\n",
      "Epoch 22/200, Iteration 221/250, Loss: 0.0180\n",
      "Epoch 22/200, Iteration 222/250, Loss: 0.0415\n",
      "Epoch 22/200, Iteration 223/250, Loss: 0.0336\n",
      "Epoch 22/200, Iteration 224/250, Loss: 0.0577\n",
      "Epoch 22/200, Iteration 225/250, Loss: 0.0220\n",
      "Epoch 22/200, Iteration 226/250, Loss: 0.0913\n",
      "Epoch 22/200, Iteration 227/250, Loss: 0.0551\n",
      "Epoch 22/200, Iteration 228/250, Loss: 0.0400\n",
      "Epoch 22/200, Iteration 229/250, Loss: 0.1099\n",
      "Epoch 22/200, Iteration 230/250, Loss: 0.0948\n",
      "Epoch 22/200, Iteration 231/250, Loss: 0.0390\n",
      "Epoch 22/200, Iteration 232/250, Loss: 0.0259\n",
      "Epoch 22/200, Iteration 233/250, Loss: 0.1082\n",
      "Epoch 22/200, Iteration 234/250, Loss: 0.0151\n",
      "Epoch 22/200, Iteration 235/250, Loss: 0.0649\n",
      "Epoch 22/200, Iteration 236/250, Loss: 0.0371\n",
      "Epoch 22/200, Iteration 237/250, Loss: 0.0396\n",
      "Epoch 22/200, Iteration 238/250, Loss: 0.0921\n",
      "Epoch 22/200, Iteration 239/250, Loss: 0.0629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Iteration 240/250, Loss: 0.0448\n",
      "Epoch 22/200, Iteration 241/250, Loss: 0.0273\n",
      "Epoch 22/200, Iteration 242/250, Loss: 0.1072\n",
      "Epoch 22/200, Iteration 243/250, Loss: 0.0265\n",
      "Epoch 22/200, Iteration 244/250, Loss: 0.0636\n",
      "Epoch 22/200, Iteration 245/250, Loss: 0.1303\n",
      "Epoch 22/200, Iteration 246/250, Loss: 0.0433\n",
      "Epoch 22/200, Iteration 247/250, Loss: 0.0561\n",
      "Epoch 22/200, Iteration 248/250, Loss: 0.0786\n",
      "Epoch 22/200, Iteration 249/250, Loss: 0.0406\n",
      "Epoch 22/200, Iteration 250/250, Loss: 0.0552\n",
      "Train Error: \n",
      " Accuracy: 41.0%, Avg loss: 0.041851, MRE: 4.066812 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 0.041367, MRE: 5.053268 \n",
      "\n",
      "Epoch 23/200, Iteration 1/250, Loss: 0.0341\n",
      "Epoch 23/200, Iteration 2/250, Loss: 0.0686\n",
      "Epoch 23/200, Iteration 3/250, Loss: 0.0799\n",
      "Epoch 23/200, Iteration 4/250, Loss: 0.0474\n",
      "Epoch 23/200, Iteration 5/250, Loss: 0.0554\n",
      "Epoch 23/200, Iteration 6/250, Loss: 0.0371\n",
      "Epoch 23/200, Iteration 7/250, Loss: 0.1742\n",
      "Epoch 23/200, Iteration 8/250, Loss: 0.0409\n",
      "Epoch 23/200, Iteration 9/250, Loss: 0.0871\n",
      "Epoch 23/200, Iteration 10/250, Loss: 0.0299\n",
      "Epoch 23/200, Iteration 11/250, Loss: 0.0387\n",
      "Epoch 23/200, Iteration 12/250, Loss: 0.0736\n",
      "Epoch 23/200, Iteration 13/250, Loss: 0.0258\n",
      "Epoch 23/200, Iteration 14/250, Loss: 0.0370\n",
      "Epoch 23/200, Iteration 15/250, Loss: 0.0731\n",
      "Epoch 23/200, Iteration 16/250, Loss: 0.0283\n",
      "Epoch 23/200, Iteration 17/250, Loss: 0.0191\n",
      "Epoch 23/200, Iteration 18/250, Loss: 0.0397\n",
      "Epoch 23/200, Iteration 19/250, Loss: 0.0290\n",
      "Epoch 23/200, Iteration 20/250, Loss: 0.0924\n",
      "Epoch 23/200, Iteration 21/250, Loss: 0.0236\n",
      "Epoch 23/200, Iteration 22/250, Loss: 0.0318\n",
      "Epoch 23/200, Iteration 23/250, Loss: 0.0477\n",
      "Epoch 23/200, Iteration 24/250, Loss: 0.0252\n",
      "Epoch 23/200, Iteration 25/250, Loss: 0.0317\n",
      "Epoch 23/200, Iteration 26/250, Loss: 0.0346\n",
      "Epoch 23/200, Iteration 27/250, Loss: 0.0375\n",
      "Epoch 23/200, Iteration 28/250, Loss: 0.0390\n",
      "Epoch 23/200, Iteration 29/250, Loss: 0.0418\n",
      "Epoch 23/200, Iteration 30/250, Loss: 0.0205\n",
      "Epoch 23/200, Iteration 31/250, Loss: 0.0249\n",
      "Epoch 23/200, Iteration 32/250, Loss: 0.0280\n",
      "Epoch 23/200, Iteration 33/250, Loss: 0.0211\n",
      "Epoch 23/200, Iteration 34/250, Loss: 0.0539\n",
      "Epoch 23/200, Iteration 35/250, Loss: 0.0996\n",
      "Epoch 23/200, Iteration 36/250, Loss: 0.0110\n",
      "Epoch 23/200, Iteration 37/250, Loss: 0.0208\n",
      "Epoch 23/200, Iteration 38/250, Loss: 0.0490\n",
      "Epoch 23/200, Iteration 39/250, Loss: 0.0311\n",
      "Epoch 23/200, Iteration 40/250, Loss: 0.0363\n",
      "Epoch 23/200, Iteration 41/250, Loss: 0.0415\n",
      "Epoch 23/200, Iteration 42/250, Loss: 0.0221\n",
      "Epoch 23/200, Iteration 43/250, Loss: 0.0398\n",
      "Epoch 23/200, Iteration 44/250, Loss: 0.0161\n",
      "Epoch 23/200, Iteration 45/250, Loss: 0.0272\n",
      "Epoch 23/200, Iteration 46/250, Loss: 0.0569\n",
      "Epoch 23/200, Iteration 47/250, Loss: 0.0172\n",
      "Epoch 23/200, Iteration 48/250, Loss: 0.0234\n",
      "Epoch 23/200, Iteration 49/250, Loss: 0.0149\n",
      "Epoch 23/200, Iteration 50/250, Loss: 0.0256\n",
      "Epoch 23/200, Iteration 51/250, Loss: 0.0246\n",
      "Epoch 23/200, Iteration 52/250, Loss: 0.0142\n",
      "Epoch 23/200, Iteration 53/250, Loss: 0.0477\n",
      "Epoch 23/200, Iteration 54/250, Loss: 0.0203\n",
      "Epoch 23/200, Iteration 55/250, Loss: 0.0354\n",
      "Epoch 23/200, Iteration 56/250, Loss: 0.0112\n",
      "Epoch 23/200, Iteration 57/250, Loss: 0.0310\n",
      "Epoch 23/200, Iteration 58/250, Loss: 0.0144\n",
      "Epoch 23/200, Iteration 59/250, Loss: 0.0119\n",
      "Epoch 23/200, Iteration 60/250, Loss: 0.0122\n",
      "Epoch 23/200, Iteration 61/250, Loss: 0.0330\n",
      "Epoch 23/200, Iteration 62/250, Loss: 0.0291\n",
      "Epoch 23/200, Iteration 63/250, Loss: 0.0408\n",
      "Epoch 23/200, Iteration 64/250, Loss: 0.0386\n",
      "Epoch 23/200, Iteration 65/250, Loss: 0.0147\n",
      "Epoch 23/200, Iteration 66/250, Loss: 0.0198\n",
      "Epoch 23/200, Iteration 67/250, Loss: 0.0155\n",
      "Epoch 23/200, Iteration 68/250, Loss: 0.0422\n",
      "Epoch 23/200, Iteration 69/250, Loss: 0.0190\n",
      "Epoch 23/200, Iteration 70/250, Loss: 0.0353\n",
      "Epoch 23/200, Iteration 71/250, Loss: 0.0433\n",
      "Epoch 23/200, Iteration 72/250, Loss: 0.0423\n",
      "Epoch 23/200, Iteration 73/250, Loss: 0.0349\n",
      "Epoch 23/200, Iteration 74/250, Loss: 0.0485\n",
      "Epoch 23/200, Iteration 75/250, Loss: 0.0288\n",
      "Epoch 23/200, Iteration 76/250, Loss: 0.0540\n",
      "Epoch 23/200, Iteration 77/250, Loss: 0.0380\n",
      "Epoch 23/200, Iteration 78/250, Loss: 0.0489\n",
      "Epoch 23/200, Iteration 79/250, Loss: 0.0702\n",
      "Epoch 23/200, Iteration 80/250, Loss: 0.0603\n",
      "Epoch 23/200, Iteration 81/250, Loss: 0.0420\n",
      "Epoch 23/200, Iteration 82/250, Loss: 0.0854\n",
      "Epoch 23/200, Iteration 83/250, Loss: 0.0293\n",
      "Epoch 23/200, Iteration 84/250, Loss: 0.0678\n",
      "Epoch 23/200, Iteration 85/250, Loss: 0.0308\n",
      "Epoch 23/200, Iteration 86/250, Loss: 0.0177\n",
      "Epoch 23/200, Iteration 87/250, Loss: 0.0196\n",
      "Epoch 23/200, Iteration 88/250, Loss: 0.0245\n",
      "Epoch 23/200, Iteration 89/250, Loss: 0.0367\n",
      "Epoch 23/200, Iteration 90/250, Loss: 0.0345\n",
      "Epoch 23/200, Iteration 91/250, Loss: 0.0379\n",
      "Epoch 23/200, Iteration 92/250, Loss: 0.0326\n",
      "Epoch 23/200, Iteration 93/250, Loss: 0.0943\n",
      "Epoch 23/200, Iteration 94/250, Loss: 0.0586\n",
      "Epoch 23/200, Iteration 95/250, Loss: 0.0310\n",
      "Epoch 23/200, Iteration 96/250, Loss: 0.0237\n",
      "Epoch 23/200, Iteration 97/250, Loss: 0.0746\n",
      "Epoch 23/200, Iteration 98/250, Loss: 0.0208\n",
      "Epoch 23/200, Iteration 99/250, Loss: 0.0200\n",
      "Epoch 23/200, Iteration 100/250, Loss: 0.0225\n",
      "Epoch 23/200, Iteration 101/250, Loss: 0.0165\n",
      "Epoch 23/200, Iteration 102/250, Loss: 0.0162\n",
      "Epoch 23/200, Iteration 103/250, Loss: 0.0249\n",
      "Epoch 23/200, Iteration 104/250, Loss: 0.0285\n",
      "Epoch 23/200, Iteration 105/250, Loss: 0.0211\n",
      "Epoch 23/200, Iteration 106/250, Loss: 0.0327\n",
      "Epoch 23/200, Iteration 107/250, Loss: 0.0167\n",
      "Epoch 23/200, Iteration 108/250, Loss: 0.0865\n",
      "Epoch 23/200, Iteration 109/250, Loss: 0.0678\n",
      "Epoch 23/200, Iteration 110/250, Loss: 0.0552\n",
      "Epoch 23/200, Iteration 111/250, Loss: 0.0232\n",
      "Epoch 23/200, Iteration 112/250, Loss: 0.0193\n",
      "Epoch 23/200, Iteration 113/250, Loss: 0.0203\n",
      "Epoch 23/200, Iteration 114/250, Loss: 0.0203\n",
      "Epoch 23/200, Iteration 115/250, Loss: 0.0380\n",
      "Epoch 23/200, Iteration 116/250, Loss: 0.0295\n",
      "Epoch 23/200, Iteration 117/250, Loss: 0.0208\n",
      "Epoch 23/200, Iteration 118/250, Loss: 0.0305\n",
      "Epoch 23/200, Iteration 119/250, Loss: 0.0221\n",
      "Epoch 23/200, Iteration 120/250, Loss: 0.0343\n",
      "Epoch 23/200, Iteration 121/250, Loss: 0.0344\n",
      "Epoch 23/200, Iteration 122/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 123/250, Loss: 0.0210\n",
      "Epoch 23/200, Iteration 124/250, Loss: 0.0181\n",
      "Epoch 23/200, Iteration 125/250, Loss: 0.0264\n",
      "Epoch 23/200, Iteration 126/250, Loss: 0.0282\n",
      "Epoch 23/200, Iteration 127/250, Loss: 0.0318\n",
      "Epoch 23/200, Iteration 128/250, Loss: 0.0225\n",
      "Epoch 23/200, Iteration 129/250, Loss: 0.0159\n",
      "Epoch 23/200, Iteration 130/250, Loss: 0.0316\n",
      "Epoch 23/200, Iteration 131/250, Loss: 0.0165\n",
      "Epoch 23/200, Iteration 132/250, Loss: 0.0245\n",
      "Epoch 23/200, Iteration 133/250, Loss: 0.0291\n",
      "Epoch 23/200, Iteration 134/250, Loss: 0.0455\n",
      "Epoch 23/200, Iteration 135/250, Loss: 0.0222\n",
      "Epoch 23/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 23/200, Iteration 137/250, Loss: 0.0218\n",
      "Epoch 23/200, Iteration 138/250, Loss: 0.0195\n",
      "Epoch 23/200, Iteration 139/250, Loss: 0.0296\n",
      "Epoch 23/200, Iteration 140/250, Loss: 0.0311\n",
      "Epoch 23/200, Iteration 141/250, Loss: 0.0194\n",
      "Epoch 23/200, Iteration 142/250, Loss: 0.0450\n",
      "Epoch 23/200, Iteration 143/250, Loss: 0.0263\n",
      "Epoch 23/200, Iteration 144/250, Loss: 0.0410\n",
      "Epoch 23/200, Iteration 145/250, Loss: 0.0413\n",
      "Epoch 23/200, Iteration 146/250, Loss: 0.0276\n",
      "Epoch 23/200, Iteration 147/250, Loss: 0.0235\n",
      "Epoch 23/200, Iteration 148/250, Loss: 0.0442\n",
      "Epoch 23/200, Iteration 149/250, Loss: 0.0329\n",
      "Epoch 23/200, Iteration 150/250, Loss: 0.0175\n",
      "Epoch 23/200, Iteration 151/250, Loss: 0.0279\n",
      "Epoch 23/200, Iteration 152/250, Loss: 0.0333\n",
      "Epoch 23/200, Iteration 153/250, Loss: 0.0183\n",
      "Epoch 23/200, Iteration 154/250, Loss: 0.0216\n",
      "Epoch 23/200, Iteration 155/250, Loss: 0.0446\n",
      "Epoch 23/200, Iteration 156/250, Loss: 0.0257\n",
      "Epoch 23/200, Iteration 157/250, Loss: 0.0653\n",
      "Epoch 23/200, Iteration 158/250, Loss: 0.0286\n",
      "Epoch 23/200, Iteration 159/250, Loss: 0.0418\n",
      "Epoch 23/200, Iteration 160/250, Loss: 0.0346\n",
      "Epoch 23/200, Iteration 161/250, Loss: 0.0330\n",
      "Epoch 23/200, Iteration 162/250, Loss: 0.0183\n",
      "Epoch 23/200, Iteration 163/250, Loss: 0.0241\n",
      "Epoch 23/200, Iteration 164/250, Loss: 0.0273\n",
      "Epoch 23/200, Iteration 165/250, Loss: 0.0197\n",
      "Epoch 23/200, Iteration 166/250, Loss: 0.0239\n",
      "Epoch 23/200, Iteration 167/250, Loss: 0.0486\n",
      "Epoch 23/200, Iteration 168/250, Loss: 0.0410\n",
      "Epoch 23/200, Iteration 169/250, Loss: 0.0162\n",
      "Epoch 23/200, Iteration 170/250, Loss: 0.0431\n",
      "Epoch 23/200, Iteration 171/250, Loss: 0.0455\n",
      "Epoch 23/200, Iteration 172/250, Loss: 0.0174\n",
      "Epoch 23/200, Iteration 173/250, Loss: 0.0267\n",
      "Epoch 23/200, Iteration 174/250, Loss: 0.0487\n",
      "Epoch 23/200, Iteration 175/250, Loss: 0.0243\n",
      "Epoch 23/200, Iteration 176/250, Loss: 0.0256\n",
      "Epoch 23/200, Iteration 177/250, Loss: 0.0122\n",
      "Epoch 23/200, Iteration 178/250, Loss: 0.0135\n",
      "Epoch 23/200, Iteration 179/250, Loss: 0.0149\n",
      "Epoch 23/200, Iteration 180/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 181/250, Loss: 0.0175\n",
      "Epoch 23/200, Iteration 182/250, Loss: 0.0163\n",
      "Epoch 23/200, Iteration 183/250, Loss: 0.0183\n",
      "Epoch 23/200, Iteration 184/250, Loss: 0.0191\n",
      "Epoch 23/200, Iteration 185/250, Loss: 0.0114\n",
      "Epoch 23/200, Iteration 186/250, Loss: 0.0266\n",
      "Epoch 23/200, Iteration 187/250, Loss: 0.0142\n",
      "Epoch 23/200, Iteration 188/250, Loss: 0.0189\n",
      "Epoch 23/200, Iteration 189/250, Loss: 0.0121\n",
      "Epoch 23/200, Iteration 190/250, Loss: 0.0378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Iteration 191/250, Loss: 0.0132\n",
      "Epoch 23/200, Iteration 192/250, Loss: 0.0166\n",
      "Epoch 23/200, Iteration 193/250, Loss: 0.0210\n",
      "Epoch 23/200, Iteration 194/250, Loss: 0.0185\n",
      "Epoch 23/200, Iteration 195/250, Loss: 0.0291\n",
      "Epoch 23/200, Iteration 196/250, Loss: 0.0164\n",
      "Epoch 23/200, Iteration 197/250, Loss: 0.0333\n",
      "Epoch 23/200, Iteration 198/250, Loss: 0.0556\n",
      "Epoch 23/200, Iteration 199/250, Loss: 0.0199\n",
      "Epoch 23/200, Iteration 200/250, Loss: 0.0137\n",
      "Epoch 23/200, Iteration 201/250, Loss: 0.0360\n",
      "Epoch 23/200, Iteration 202/250, Loss: 0.0269\n",
      "Epoch 23/200, Iteration 203/250, Loss: 0.0213\n",
      "Epoch 23/200, Iteration 204/250, Loss: 0.0269\n",
      "Epoch 23/200, Iteration 205/250, Loss: 0.0248\n",
      "Epoch 23/200, Iteration 206/250, Loss: 0.0207\n",
      "Epoch 23/200, Iteration 207/250, Loss: 0.0283\n",
      "Epoch 23/200, Iteration 208/250, Loss: 0.0374\n",
      "Epoch 23/200, Iteration 209/250, Loss: 0.0184\n",
      "Epoch 23/200, Iteration 210/250, Loss: 0.0423\n",
      "Epoch 23/200, Iteration 211/250, Loss: 0.0295\n",
      "Epoch 23/200, Iteration 212/250, Loss: 0.0255\n",
      "Epoch 23/200, Iteration 213/250, Loss: 0.0354\n",
      "Epoch 23/200, Iteration 214/250, Loss: 0.0355\n",
      "Epoch 23/200, Iteration 215/250, Loss: 0.0759\n",
      "Epoch 23/200, Iteration 216/250, Loss: 0.0187\n",
      "Epoch 23/200, Iteration 217/250, Loss: 0.0646\n",
      "Epoch 23/200, Iteration 218/250, Loss: 0.0366\n",
      "Epoch 23/200, Iteration 219/250, Loss: 0.0192\n",
      "Epoch 23/200, Iteration 220/250, Loss: 0.0248\n",
      "Epoch 23/200, Iteration 221/250, Loss: 0.0242\n",
      "Epoch 23/200, Iteration 222/250, Loss: 0.0167\n",
      "Epoch 23/200, Iteration 223/250, Loss: 0.0164\n",
      "Epoch 23/200, Iteration 224/250, Loss: 0.0343\n",
      "Epoch 23/200, Iteration 225/250, Loss: 0.0173\n",
      "Epoch 23/200, Iteration 226/250, Loss: 0.0198\n",
      "Epoch 23/200, Iteration 227/250, Loss: 0.0154\n",
      "Epoch 23/200, Iteration 228/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 229/250, Loss: 0.0424\n",
      "Epoch 23/200, Iteration 230/250, Loss: 0.0361\n",
      "Epoch 23/200, Iteration 231/250, Loss: 0.0279\n",
      "Epoch 23/200, Iteration 232/250, Loss: 0.0231\n",
      "Epoch 23/200, Iteration 233/250, Loss: 0.0214\n",
      "Epoch 23/200, Iteration 234/250, Loss: 0.0275\n",
      "Epoch 23/200, Iteration 235/250, Loss: 0.0422\n",
      "Epoch 23/200, Iteration 236/250, Loss: 0.0349\n",
      "Epoch 23/200, Iteration 237/250, Loss: 0.0238\n",
      "Epoch 23/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 23/200, Iteration 239/250, Loss: 0.0265\n",
      "Epoch 23/200, Iteration 240/250, Loss: 0.0128\n",
      "Epoch 23/200, Iteration 241/250, Loss: 0.0333\n",
      "Epoch 23/200, Iteration 242/250, Loss: 0.0272\n",
      "Epoch 23/200, Iteration 243/250, Loss: 0.0268\n",
      "Epoch 23/200, Iteration 244/250, Loss: 0.0184\n",
      "Epoch 23/200, Iteration 245/250, Loss: 0.0163\n",
      "Epoch 23/200, Iteration 246/250, Loss: 0.0203\n",
      "Epoch 23/200, Iteration 247/250, Loss: 0.0143\n",
      "Epoch 23/200, Iteration 248/250, Loss: 0.0202\n",
      "Epoch 23/200, Iteration 249/250, Loss: 0.0232\n",
      "Epoch 23/200, Iteration 250/250, Loss: 0.0473\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.029906, MRE: 2.236990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.05%, Avg loss: 0.029434, MRE: 3.556637 \n",
      "\n",
      "Epoch 24/200, Iteration 1/250, Loss: 0.0207\n",
      "Epoch 24/200, Iteration 2/250, Loss: 0.0473\n",
      "Epoch 24/200, Iteration 3/250, Loss: 0.0300\n",
      "Epoch 24/200, Iteration 4/250, Loss: 0.0272\n",
      "Epoch 24/200, Iteration 5/250, Loss: 0.0405\n",
      "Epoch 24/200, Iteration 6/250, Loss: 0.0161\n",
      "Epoch 24/200, Iteration 7/250, Loss: 0.0320\n",
      "Epoch 24/200, Iteration 8/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 9/250, Loss: 0.0182\n",
      "Epoch 24/200, Iteration 10/250, Loss: 0.0127\n",
      "Epoch 24/200, Iteration 11/250, Loss: 0.0262\n",
      "Epoch 24/200, Iteration 12/250, Loss: 0.0262\n",
      "Epoch 24/200, Iteration 13/250, Loss: 0.0244\n",
      "Epoch 24/200, Iteration 14/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 15/250, Loss: 0.0155\n",
      "Epoch 24/200, Iteration 16/250, Loss: 0.0300\n",
      "Epoch 24/200, Iteration 17/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 18/250, Loss: 0.0164\n",
      "Epoch 24/200, Iteration 19/250, Loss: 0.0476\n",
      "Epoch 24/200, Iteration 20/250, Loss: 0.0456\n",
      "Epoch 24/200, Iteration 21/250, Loss: 0.0309\n",
      "Epoch 24/200, Iteration 22/250, Loss: 0.0587\n",
      "Epoch 24/200, Iteration 23/250, Loss: 0.0604\n",
      "Epoch 24/200, Iteration 24/250, Loss: 0.0245\n",
      "Epoch 24/200, Iteration 25/250, Loss: 0.0211\n",
      "Epoch 24/200, Iteration 26/250, Loss: 0.0187\n",
      "Epoch 24/200, Iteration 27/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 28/250, Loss: 0.0176\n",
      "Epoch 24/200, Iteration 29/250, Loss: 0.0314\n",
      "Epoch 24/200, Iteration 30/250, Loss: 0.0170\n",
      "Epoch 24/200, Iteration 31/250, Loss: 0.0261\n",
      "Epoch 24/200, Iteration 32/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 33/250, Loss: 0.0465\n",
      "Epoch 24/200, Iteration 34/250, Loss: 0.0238\n",
      "Epoch 24/200, Iteration 35/250, Loss: 0.0153\n",
      "Epoch 24/200, Iteration 36/250, Loss: 0.0262\n",
      "Epoch 24/200, Iteration 37/250, Loss: 0.0279\n",
      "Epoch 24/200, Iteration 38/250, Loss: 0.0246\n",
      "Epoch 24/200, Iteration 39/250, Loss: 0.0246\n",
      "Epoch 24/200, Iteration 40/250, Loss: 0.0389\n",
      "Epoch 24/200, Iteration 41/250, Loss: 0.0353\n",
      "Epoch 24/200, Iteration 42/250, Loss: 0.0271\n",
      "Epoch 24/200, Iteration 43/250, Loss: 0.0412\n",
      "Epoch 24/200, Iteration 44/250, Loss: 0.0249\n",
      "Epoch 24/200, Iteration 45/250, Loss: 0.0270\n",
      "Epoch 24/200, Iteration 46/250, Loss: 0.0143\n",
      "Epoch 24/200, Iteration 47/250, Loss: 0.0265\n",
      "Epoch 24/200, Iteration 48/250, Loss: 0.0235\n",
      "Epoch 24/200, Iteration 49/250, Loss: 0.0160\n",
      "Epoch 24/200, Iteration 50/250, Loss: 0.0226\n",
      "Epoch 24/200, Iteration 51/250, Loss: 0.0205\n",
      "Epoch 24/200, Iteration 52/250, Loss: 0.0150\n",
      "Epoch 24/200, Iteration 53/250, Loss: 0.0307\n",
      "Epoch 24/200, Iteration 54/250, Loss: 0.0344\n",
      "Epoch 24/200, Iteration 55/250, Loss: 0.0281\n",
      "Epoch 24/200, Iteration 56/250, Loss: 0.0376\n",
      "Epoch 24/200, Iteration 57/250, Loss: 0.0302\n",
      "Epoch 24/200, Iteration 58/250, Loss: 0.0360\n",
      "Epoch 24/200, Iteration 59/250, Loss: 0.0292\n",
      "Epoch 24/200, Iteration 60/250, Loss: 0.0196\n",
      "Epoch 24/200, Iteration 61/250, Loss: 0.0234\n",
      "Epoch 24/200, Iteration 62/250, Loss: 0.0128\n",
      "Epoch 24/200, Iteration 63/250, Loss: 0.0145\n",
      "Epoch 24/200, Iteration 64/250, Loss: 0.0502\n",
      "Epoch 24/200, Iteration 65/250, Loss: 0.0210\n",
      "Epoch 24/200, Iteration 66/250, Loss: 0.0367\n",
      "Epoch 24/200, Iteration 67/250, Loss: 0.0169\n",
      "Epoch 24/200, Iteration 68/250, Loss: 0.0159\n",
      "Epoch 24/200, Iteration 69/250, Loss: 0.0152\n",
      "Epoch 24/200, Iteration 70/250, Loss: 0.0388\n",
      "Epoch 24/200, Iteration 71/250, Loss: 0.0414\n",
      "Epoch 24/200, Iteration 72/250, Loss: 0.0195\n",
      "Epoch 24/200, Iteration 73/250, Loss: 0.0219\n",
      "Epoch 24/200, Iteration 74/250, Loss: 0.0514\n",
      "Epoch 24/200, Iteration 75/250, Loss: 0.0427\n",
      "Epoch 24/200, Iteration 76/250, Loss: 0.0672\n",
      "Epoch 24/200, Iteration 77/250, Loss: 0.0365\n",
      "Epoch 24/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 24/200, Iteration 79/250, Loss: 0.0476\n",
      "Epoch 24/200, Iteration 80/250, Loss: 0.0222\n",
      "Epoch 24/200, Iteration 81/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 82/250, Loss: 0.0236\n",
      "Epoch 24/200, Iteration 83/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 84/250, Loss: 0.0225\n",
      "Epoch 24/200, Iteration 85/250, Loss: 0.0271\n",
      "Epoch 24/200, Iteration 86/250, Loss: 0.0277\n",
      "Epoch 24/200, Iteration 87/250, Loss: 0.0146\n",
      "Epoch 24/200, Iteration 88/250, Loss: 0.0137\n",
      "Epoch 24/200, Iteration 89/250, Loss: 0.0160\n",
      "Epoch 24/200, Iteration 90/250, Loss: 0.0101\n",
      "Epoch 24/200, Iteration 91/250, Loss: 0.0332\n",
      "Epoch 24/200, Iteration 92/250, Loss: 0.0156\n",
      "Epoch 24/200, Iteration 93/250, Loss: 0.0234\n",
      "Epoch 24/200, Iteration 94/250, Loss: 0.0079\n",
      "Epoch 24/200, Iteration 95/250, Loss: 0.0500\n",
      "Epoch 24/200, Iteration 96/250, Loss: 0.0188\n",
      "Epoch 24/200, Iteration 97/250, Loss: 0.0194\n",
      "Epoch 24/200, Iteration 98/250, Loss: 0.0162\n",
      "Epoch 24/200, Iteration 99/250, Loss: 0.0312\n",
      "Epoch 24/200, Iteration 100/250, Loss: 0.0334\n",
      "Epoch 24/200, Iteration 101/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 102/250, Loss: 0.0151\n",
      "Epoch 24/200, Iteration 103/250, Loss: 0.0352\n",
      "Epoch 24/200, Iteration 104/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 105/250, Loss: 0.0548\n",
      "Epoch 24/200, Iteration 106/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 107/250, Loss: 0.0129\n",
      "Epoch 24/200, Iteration 108/250, Loss: 0.0208\n",
      "Epoch 24/200, Iteration 109/250, Loss: 0.0163\n",
      "Epoch 24/200, Iteration 110/250, Loss: 0.0127\n",
      "Epoch 24/200, Iteration 111/250, Loss: 0.0123\n",
      "Epoch 24/200, Iteration 112/250, Loss: 0.0202\n",
      "Epoch 24/200, Iteration 113/250, Loss: 0.0158\n",
      "Epoch 24/200, Iteration 114/250, Loss: 0.0182\n",
      "Epoch 24/200, Iteration 115/250, Loss: 0.0339\n",
      "Epoch 24/200, Iteration 116/250, Loss: 0.0256\n",
      "Epoch 24/200, Iteration 117/250, Loss: 0.0605\n",
      "Epoch 24/200, Iteration 118/250, Loss: 0.0518\n",
      "Epoch 24/200, Iteration 119/250, Loss: 0.0263\n",
      "Epoch 24/200, Iteration 120/250, Loss: 0.0252\n",
      "Epoch 24/200, Iteration 121/250, Loss: 0.0135\n",
      "Epoch 24/200, Iteration 122/250, Loss: 0.0322\n",
      "Epoch 24/200, Iteration 123/250, Loss: 0.0212\n",
      "Epoch 24/200, Iteration 124/250, Loss: 0.0165\n",
      "Epoch 24/200, Iteration 125/250, Loss: 0.0205\n",
      "Epoch 24/200, Iteration 126/250, Loss: 0.0115\n",
      "Epoch 24/200, Iteration 127/250, Loss: 0.0128\n",
      "Epoch 24/200, Iteration 128/250, Loss: 0.0232\n",
      "Epoch 24/200, Iteration 129/250, Loss: 0.0502\n",
      "Epoch 24/200, Iteration 130/250, Loss: 0.0513\n",
      "Epoch 24/200, Iteration 131/250, Loss: 0.0373\n",
      "Epoch 24/200, Iteration 132/250, Loss: 0.0354\n",
      "Epoch 24/200, Iteration 133/250, Loss: 0.0207\n",
      "Epoch 24/200, Iteration 134/250, Loss: 0.0226\n",
      "Epoch 24/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 24/200, Iteration 136/250, Loss: 0.0238\n",
      "Epoch 24/200, Iteration 137/250, Loss: 0.0093\n",
      "Epoch 24/200, Iteration 138/250, Loss: 0.0122\n",
      "Epoch 24/200, Iteration 139/250, Loss: 0.0373\n",
      "Epoch 24/200, Iteration 140/250, Loss: 0.0454\n",
      "Epoch 24/200, Iteration 141/250, Loss: 0.0158\n",
      "Epoch 24/200, Iteration 142/250, Loss: 0.0365\n",
      "Epoch 24/200, Iteration 143/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 144/250, Loss: 0.0324\n",
      "Epoch 24/200, Iteration 145/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Iteration 146/250, Loss: 0.0199\n",
      "Epoch 24/200, Iteration 147/250, Loss: 0.0157\n",
      "Epoch 24/200, Iteration 148/250, Loss: 0.0178\n",
      "Epoch 24/200, Iteration 149/250, Loss: 0.0247\n",
      "Epoch 24/200, Iteration 150/250, Loss: 0.0310\n",
      "Epoch 24/200, Iteration 151/250, Loss: 0.0310\n",
      "Epoch 24/200, Iteration 152/250, Loss: 0.0300\n",
      "Epoch 24/200, Iteration 153/250, Loss: 0.0186\n",
      "Epoch 24/200, Iteration 154/250, Loss: 0.0136\n",
      "Epoch 24/200, Iteration 155/250, Loss: 0.0238\n",
      "Epoch 24/200, Iteration 156/250, Loss: 0.0233\n",
      "Epoch 24/200, Iteration 157/250, Loss: 0.0128\n",
      "Epoch 24/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 24/200, Iteration 159/250, Loss: 0.0302\n",
      "Epoch 24/200, Iteration 160/250, Loss: 0.0427\n",
      "Epoch 24/200, Iteration 161/250, Loss: 0.0258\n",
      "Epoch 24/200, Iteration 162/250, Loss: 0.0255\n",
      "Epoch 24/200, Iteration 163/250, Loss: 0.0140\n",
      "Epoch 24/200, Iteration 164/250, Loss: 0.0234\n",
      "Epoch 24/200, Iteration 165/250, Loss: 0.0177\n",
      "Epoch 24/200, Iteration 166/250, Loss: 0.0625\n",
      "Epoch 24/200, Iteration 167/250, Loss: 0.0284\n",
      "Epoch 24/200, Iteration 168/250, Loss: 0.0140\n",
      "Epoch 24/200, Iteration 169/250, Loss: 0.0347\n",
      "Epoch 24/200, Iteration 170/250, Loss: 0.0147\n",
      "Epoch 24/200, Iteration 171/250, Loss: 0.0372\n",
      "Epoch 24/200, Iteration 172/250, Loss: 0.0466\n",
      "Epoch 24/200, Iteration 173/250, Loss: 0.0283\n",
      "Epoch 24/200, Iteration 174/250, Loss: 0.0394\n",
      "Epoch 24/200, Iteration 175/250, Loss: 0.0484\n",
      "Epoch 24/200, Iteration 176/250, Loss: 0.0189\n",
      "Epoch 24/200, Iteration 177/250, Loss: 0.0454\n",
      "Epoch 24/200, Iteration 178/250, Loss: 0.0119\n",
      "Epoch 24/200, Iteration 179/250, Loss: 0.0298\n",
      "Epoch 24/200, Iteration 180/250, Loss: 0.0241\n",
      "Epoch 24/200, Iteration 181/250, Loss: 0.0225\n",
      "Epoch 24/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 24/200, Iteration 183/250, Loss: 0.0319\n",
      "Epoch 24/200, Iteration 184/250, Loss: 0.0313\n",
      "Epoch 24/200, Iteration 185/250, Loss: 0.0170\n",
      "Epoch 24/200, Iteration 186/250, Loss: 0.0604\n",
      "Epoch 24/200, Iteration 187/250, Loss: 0.0200\n",
      "Epoch 24/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 24/200, Iteration 189/250, Loss: 0.0112\n",
      "Epoch 24/200, Iteration 190/250, Loss: 0.0236\n",
      "Epoch 24/200, Iteration 191/250, Loss: 0.0248\n",
      "Epoch 24/200, Iteration 192/250, Loss: 0.0214\n",
      "Epoch 24/200, Iteration 193/250, Loss: 0.0293\n",
      "Epoch 24/200, Iteration 194/250, Loss: 0.0214\n",
      "Epoch 24/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 24/200, Iteration 196/250, Loss: 0.0429\n",
      "Epoch 24/200, Iteration 197/250, Loss: 0.0189\n",
      "Epoch 24/200, Iteration 198/250, Loss: 0.0114\n",
      "Epoch 24/200, Iteration 199/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 200/250, Loss: 0.0252\n",
      "Epoch 24/200, Iteration 201/250, Loss: 0.0373\n",
      "Epoch 24/200, Iteration 202/250, Loss: 0.0221\n",
      "Epoch 24/200, Iteration 203/250, Loss: 0.0331\n",
      "Epoch 24/200, Iteration 204/250, Loss: 0.0341\n",
      "Epoch 24/200, Iteration 205/250, Loss: 0.0247\n",
      "Epoch 24/200, Iteration 206/250, Loss: 0.0332\n",
      "Epoch 24/200, Iteration 207/250, Loss: 0.0313\n",
      "Epoch 24/200, Iteration 208/250, Loss: 0.0195\n",
      "Epoch 24/200, Iteration 209/250, Loss: 0.0263\n",
      "Epoch 24/200, Iteration 210/250, Loss: 0.0194\n",
      "Epoch 24/200, Iteration 211/250, Loss: 0.0151\n",
      "Epoch 24/200, Iteration 212/250, Loss: 0.0173\n",
      "Epoch 24/200, Iteration 213/250, Loss: 0.0304\n",
      "Epoch 24/200, Iteration 214/250, Loss: 0.0166\n",
      "Epoch 24/200, Iteration 215/250, Loss: 0.0540\n",
      "Epoch 24/200, Iteration 216/250, Loss: 0.0146\n",
      "Epoch 24/200, Iteration 217/250, Loss: 0.0341\n",
      "Epoch 24/200, Iteration 218/250, Loss: 0.0388\n",
      "Epoch 24/200, Iteration 219/250, Loss: 0.0159\n",
      "Epoch 24/200, Iteration 220/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 221/250, Loss: 0.0258\n",
      "Epoch 24/200, Iteration 222/250, Loss: 0.0232\n",
      "Epoch 24/200, Iteration 223/250, Loss: 0.0296\n",
      "Epoch 24/200, Iteration 224/250, Loss: 0.0190\n",
      "Epoch 24/200, Iteration 225/250, Loss: 0.0162\n",
      "Epoch 24/200, Iteration 226/250, Loss: 0.0277\n",
      "Epoch 24/200, Iteration 227/250, Loss: 0.0206\n",
      "Epoch 24/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 24/200, Iteration 229/250, Loss: 0.0184\n",
      "Epoch 24/200, Iteration 230/250, Loss: 0.0159\n",
      "Epoch 24/200, Iteration 231/250, Loss: 0.0448\n",
      "Epoch 24/200, Iteration 232/250, Loss: 0.0573\n",
      "Epoch 24/200, Iteration 233/250, Loss: 0.0157\n",
      "Epoch 24/200, Iteration 234/250, Loss: 0.0185\n",
      "Epoch 24/200, Iteration 235/250, Loss: 0.0287\n",
      "Epoch 24/200, Iteration 236/250, Loss: 0.0159\n",
      "Epoch 24/200, Iteration 237/250, Loss: 0.0432\n",
      "Epoch 24/200, Iteration 238/250, Loss: 0.0146\n",
      "Epoch 24/200, Iteration 239/250, Loss: 0.0150\n",
      "Epoch 24/200, Iteration 240/250, Loss: 0.0089\n",
      "Epoch 24/200, Iteration 241/250, Loss: 0.0182\n",
      "Epoch 24/200, Iteration 242/250, Loss: 0.0136\n",
      "Epoch 24/200, Iteration 243/250, Loss: 0.0279\n",
      "Epoch 24/200, Iteration 244/250, Loss: 0.0131\n",
      "Epoch 24/200, Iteration 245/250, Loss: 0.0199\n",
      "Epoch 24/200, Iteration 246/250, Loss: 0.0304\n",
      "Epoch 24/200, Iteration 247/250, Loss: 0.0238\n",
      "Epoch 24/200, Iteration 248/250, Loss: 0.0096\n",
      "Epoch 24/200, Iteration 249/250, Loss: 0.0178\n",
      "Epoch 24/200, Iteration 250/250, Loss: 0.0245\n",
      "Train Error: \n",
      " Accuracy: 70.85%, Avg loss: 0.011354, MRE: 1.089331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.05%, Avg loss: 0.011332, MRE: 1.085814 \n",
      "\n",
      "Epoch 25/200, Iteration 1/250, Loss: 0.0164\n",
      "Epoch 25/200, Iteration 2/250, Loss: 0.0142\n",
      "Epoch 25/200, Iteration 3/250, Loss: 0.0186\n",
      "Epoch 25/200, Iteration 4/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 5/250, Loss: 0.0356\n",
      "Epoch 25/200, Iteration 6/250, Loss: 0.0272\n",
      "Epoch 25/200, Iteration 7/250, Loss: 0.0271\n",
      "Epoch 25/200, Iteration 8/250, Loss: 0.0186\n",
      "Epoch 25/200, Iteration 9/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 25/200, Iteration 11/250, Loss: 0.0177\n",
      "Epoch 25/200, Iteration 12/250, Loss: 0.0187\n",
      "Epoch 25/200, Iteration 13/250, Loss: 0.0162\n",
      "Epoch 25/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 25/200, Iteration 15/250, Loss: 0.0222\n",
      "Epoch 25/200, Iteration 16/250, Loss: 0.0339\n",
      "Epoch 25/200, Iteration 17/250, Loss: 0.0354\n",
      "Epoch 25/200, Iteration 18/250, Loss: 0.0159\n",
      "Epoch 25/200, Iteration 19/250, Loss: 0.0397\n",
      "Epoch 25/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 25/200, Iteration 21/250, Loss: 0.0204\n",
      "Epoch 25/200, Iteration 22/250, Loss: 0.0186\n",
      "Epoch 25/200, Iteration 23/250, Loss: 0.0506\n",
      "Epoch 25/200, Iteration 24/250, Loss: 0.0213\n",
      "Epoch 25/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 25/200, Iteration 26/250, Loss: 0.0135\n",
      "Epoch 25/200, Iteration 27/250, Loss: 0.0196\n",
      "Epoch 25/200, Iteration 28/250, Loss: 0.0144\n",
      "Epoch 25/200, Iteration 29/250, Loss: 0.0261\n",
      "Epoch 25/200, Iteration 30/250, Loss: 0.0087\n",
      "Epoch 25/200, Iteration 31/250, Loss: 0.0133\n",
      "Epoch 25/200, Iteration 32/250, Loss: 0.0142\n",
      "Epoch 25/200, Iteration 33/250, Loss: 0.0310\n",
      "Epoch 25/200, Iteration 34/250, Loss: 0.0349\n",
      "Epoch 25/200, Iteration 35/250, Loss: 0.0263\n",
      "Epoch 25/200, Iteration 36/250, Loss: 0.0310\n",
      "Epoch 25/200, Iteration 37/250, Loss: 0.0135\n",
      "Epoch 25/200, Iteration 38/250, Loss: 0.0355\n",
      "Epoch 25/200, Iteration 39/250, Loss: 0.0397\n",
      "Epoch 25/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 25/200, Iteration 41/250, Loss: 0.0234\n",
      "Epoch 25/200, Iteration 42/250, Loss: 0.0222\n",
      "Epoch 25/200, Iteration 43/250, Loss: 0.0133\n",
      "Epoch 25/200, Iteration 44/250, Loss: 0.0502\n",
      "Epoch 25/200, Iteration 45/250, Loss: 0.0139\n",
      "Epoch 25/200, Iteration 46/250, Loss: 0.0200\n",
      "Epoch 25/200, Iteration 47/250, Loss: 0.0280\n",
      "Epoch 25/200, Iteration 48/250, Loss: 0.0158\n",
      "Epoch 25/200, Iteration 49/250, Loss: 0.0193\n",
      "Epoch 25/200, Iteration 50/250, Loss: 0.0154\n",
      "Epoch 25/200, Iteration 51/250, Loss: 0.0297\n",
      "Epoch 25/200, Iteration 52/250, Loss: 0.0157\n",
      "Epoch 25/200, Iteration 53/250, Loss: 0.0143\n",
      "Epoch 25/200, Iteration 54/250, Loss: 0.0253\n",
      "Epoch 25/200, Iteration 55/250, Loss: 0.0164\n",
      "Epoch 25/200, Iteration 56/250, Loss: 0.0138\n",
      "Epoch 25/200, Iteration 57/250, Loss: 0.0291\n",
      "Epoch 25/200, Iteration 58/250, Loss: 0.0207\n",
      "Epoch 25/200, Iteration 59/250, Loss: 0.0154\n",
      "Epoch 25/200, Iteration 60/250, Loss: 0.0146\n",
      "Epoch 25/200, Iteration 61/250, Loss: 0.0169\n",
      "Epoch 25/200, Iteration 62/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 63/250, Loss: 0.0404\n",
      "Epoch 25/200, Iteration 64/250, Loss: 0.0169\n",
      "Epoch 25/200, Iteration 65/250, Loss: 0.0168\n",
      "Epoch 25/200, Iteration 66/250, Loss: 0.0225\n",
      "Epoch 25/200, Iteration 67/250, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 68/250, Loss: 0.0089\n",
      "Epoch 25/200, Iteration 69/250, Loss: 0.0180\n",
      "Epoch 25/200, Iteration 70/250, Loss: 0.0105\n",
      "Epoch 25/200, Iteration 71/250, Loss: 0.0230\n",
      "Epoch 25/200, Iteration 72/250, Loss: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Iteration 73/250, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 74/250, Loss: 0.0113\n",
      "Epoch 25/200, Iteration 75/250, Loss: 0.0235\n",
      "Epoch 25/200, Iteration 76/250, Loss: 0.0149\n",
      "Epoch 25/200, Iteration 77/250, Loss: 0.0134\n",
      "Epoch 25/200, Iteration 78/250, Loss: 0.0221\n",
      "Epoch 25/200, Iteration 79/250, Loss: 0.0199\n",
      "Epoch 25/200, Iteration 80/250, Loss: 0.0219\n",
      "Epoch 25/200, Iteration 81/250, Loss: 0.0276\n",
      "Epoch 25/200, Iteration 82/250, Loss: 0.0168\n",
      "Epoch 25/200, Iteration 83/250, Loss: 0.0183\n",
      "Epoch 25/200, Iteration 84/250, Loss: 0.0165\n",
      "Epoch 25/200, Iteration 85/250, Loss: 0.0139\n",
      "Epoch 25/200, Iteration 86/250, Loss: 0.0128\n",
      "Epoch 25/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 25/200, Iteration 88/250, Loss: 0.0096\n",
      "Epoch 25/200, Iteration 89/250, Loss: 0.0205\n",
      "Epoch 25/200, Iteration 90/250, Loss: 0.0151\n",
      "Epoch 25/200, Iteration 91/250, Loss: 0.0167\n",
      "Epoch 25/200, Iteration 92/250, Loss: 0.0142\n",
      "Epoch 25/200, Iteration 93/250, Loss: 0.0246\n",
      "Epoch 25/200, Iteration 94/250, Loss: 0.0282\n",
      "Epoch 25/200, Iteration 95/250, Loss: 0.0407\n",
      "Epoch 25/200, Iteration 96/250, Loss: 0.0126\n",
      "Epoch 25/200, Iteration 97/250, Loss: 0.0262\n",
      "Epoch 25/200, Iteration 98/250, Loss: 0.0126\n",
      "Epoch 25/200, Iteration 99/250, Loss: 0.0203\n",
      "Epoch 25/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 25/200, Iteration 101/250, Loss: 0.0399\n",
      "Epoch 25/200, Iteration 102/250, Loss: 0.0307\n",
      "Epoch 25/200, Iteration 103/250, Loss: 0.0243\n",
      "Epoch 25/200, Iteration 104/250, Loss: 0.0477\n",
      "Epoch 25/200, Iteration 105/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 106/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 25/200, Iteration 108/250, Loss: 0.0375\n",
      "Epoch 25/200, Iteration 109/250, Loss: 0.0245\n",
      "Epoch 25/200, Iteration 110/250, Loss: 0.0326\n",
      "Epoch 25/200, Iteration 111/250, Loss: 0.0151\n",
      "Epoch 25/200, Iteration 112/250, Loss: 0.0283\n",
      "Epoch 25/200, Iteration 113/250, Loss: 0.0147\n",
      "Epoch 25/200, Iteration 114/250, Loss: 0.0178\n",
      "Epoch 25/200, Iteration 115/250, Loss: 0.0140\n",
      "Epoch 25/200, Iteration 116/250, Loss: 0.0427\n",
      "Epoch 25/200, Iteration 117/250, Loss: 0.0386\n",
      "Epoch 25/200, Iteration 118/250, Loss: 0.0285\n",
      "Epoch 25/200, Iteration 119/250, Loss: 0.0190\n",
      "Epoch 25/200, Iteration 120/250, Loss: 0.0314\n",
      "Epoch 25/200, Iteration 121/250, Loss: 0.0451\n",
      "Epoch 25/200, Iteration 122/250, Loss: 0.0172\n",
      "Epoch 25/200, Iteration 123/250, Loss: 0.0170\n",
      "Epoch 25/200, Iteration 124/250, Loss: 0.0071\n",
      "Epoch 25/200, Iteration 125/250, Loss: 0.0378\n",
      "Epoch 25/200, Iteration 126/250, Loss: 0.0183\n",
      "Epoch 25/200, Iteration 127/250, Loss: 0.0197\n",
      "Epoch 25/200, Iteration 128/250, Loss: 0.0134\n",
      "Epoch 25/200, Iteration 129/250, Loss: 0.0167\n",
      "Epoch 25/200, Iteration 130/250, Loss: 0.0364\n",
      "Epoch 25/200, Iteration 131/250, Loss: 0.0291\n",
      "Epoch 25/200, Iteration 132/250, Loss: 0.0128\n",
      "Epoch 25/200, Iteration 133/250, Loss: 0.0234\n",
      "Epoch 25/200, Iteration 134/250, Loss: 0.0126\n",
      "Epoch 25/200, Iteration 135/250, Loss: 0.0318\n",
      "Epoch 25/200, Iteration 136/250, Loss: 0.0323\n",
      "Epoch 25/200, Iteration 137/250, Loss: 0.0282\n",
      "Epoch 25/200, Iteration 138/250, Loss: 0.0160\n",
      "Epoch 25/200, Iteration 139/250, Loss: 0.0260\n",
      "Epoch 25/200, Iteration 140/250, Loss: 0.0132\n",
      "Epoch 25/200, Iteration 141/250, Loss: 0.0298\n",
      "Epoch 25/200, Iteration 142/250, Loss: 0.0225\n",
      "Epoch 25/200, Iteration 143/250, Loss: 0.0273\n",
      "Epoch 25/200, Iteration 144/250, Loss: 0.0259\n",
      "Epoch 25/200, Iteration 145/250, Loss: 0.0258\n",
      "Epoch 25/200, Iteration 146/250, Loss: 0.0306\n",
      "Epoch 25/200, Iteration 147/250, Loss: 0.0112\n",
      "Epoch 25/200, Iteration 148/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 149/250, Loss: 0.0126\n",
      "Epoch 25/200, Iteration 150/250, Loss: 0.0174\n",
      "Epoch 25/200, Iteration 151/250, Loss: 0.0166\n",
      "Epoch 25/200, Iteration 152/250, Loss: 0.0206\n",
      "Epoch 25/200, Iteration 153/250, Loss: 0.0202\n",
      "Epoch 25/200, Iteration 154/250, Loss: 0.0281\n",
      "Epoch 25/200, Iteration 155/250, Loss: 0.0130\n",
      "Epoch 25/200, Iteration 156/250, Loss: 0.0127\n",
      "Epoch 25/200, Iteration 157/250, Loss: 0.0232\n",
      "Epoch 25/200, Iteration 158/250, Loss: 0.0124\n",
      "Epoch 25/200, Iteration 159/250, Loss: 0.0148\n",
      "Epoch 25/200, Iteration 160/250, Loss: 0.0163\n",
      "Epoch 25/200, Iteration 161/250, Loss: 0.0112\n",
      "Epoch 25/200, Iteration 162/250, Loss: 0.0441\n",
      "Epoch 25/200, Iteration 163/250, Loss: 0.0259\n",
      "Epoch 25/200, Iteration 164/250, Loss: 0.0206\n",
      "Epoch 25/200, Iteration 165/250, Loss: 0.0200\n",
      "Epoch 25/200, Iteration 166/250, Loss: 0.0190\n",
      "Epoch 25/200, Iteration 167/250, Loss: 0.0233\n",
      "Epoch 25/200, Iteration 168/250, Loss: 0.0230\n",
      "Epoch 25/200, Iteration 169/250, Loss: 0.0170\n",
      "Epoch 25/200, Iteration 170/250, Loss: 0.0133\n",
      "Epoch 25/200, Iteration 171/250, Loss: 0.0146\n",
      "Epoch 25/200, Iteration 172/250, Loss: 0.0127\n",
      "Epoch 25/200, Iteration 173/250, Loss: 0.0190\n",
      "Epoch 25/200, Iteration 174/250, Loss: 0.0269\n",
      "Epoch 25/200, Iteration 175/250, Loss: 0.0118\n",
      "Epoch 25/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 25/200, Iteration 177/250, Loss: 0.0104\n",
      "Epoch 25/200, Iteration 178/250, Loss: 0.0486\n",
      "Epoch 25/200, Iteration 179/250, Loss: 0.0385\n",
      "Epoch 25/200, Iteration 180/250, Loss: 0.0164\n",
      "Epoch 25/200, Iteration 181/250, Loss: 0.0146\n",
      "Epoch 25/200, Iteration 182/250, Loss: 0.0477\n",
      "Epoch 25/200, Iteration 183/250, Loss: 0.0309\n",
      "Epoch 25/200, Iteration 184/250, Loss: 0.0358\n",
      "Epoch 25/200, Iteration 185/250, Loss: 0.0200\n",
      "Epoch 25/200, Iteration 186/250, Loss: 0.0251\n",
      "Epoch 25/200, Iteration 187/250, Loss: 0.0474\n",
      "Epoch 25/200, Iteration 188/250, Loss: 0.0326\n",
      "Epoch 25/200, Iteration 189/250, Loss: 0.0165\n",
      "Epoch 25/200, Iteration 190/250, Loss: 0.0191\n",
      "Epoch 25/200, Iteration 191/250, Loss: 0.0534\n",
      "Epoch 25/200, Iteration 192/250, Loss: 0.0218\n",
      "Epoch 25/200, Iteration 193/250, Loss: 0.0181\n",
      "Epoch 25/200, Iteration 194/250, Loss: 0.0362\n",
      "Epoch 25/200, Iteration 195/250, Loss: 0.0259\n",
      "Epoch 25/200, Iteration 196/250, Loss: 0.0256\n",
      "Epoch 25/200, Iteration 197/250, Loss: 0.0295\n",
      "Epoch 25/200, Iteration 198/250, Loss: 0.0289\n",
      "Epoch 25/200, Iteration 199/250, Loss: 0.0197\n",
      "Epoch 25/200, Iteration 200/250, Loss: 0.0079\n",
      "Epoch 25/200, Iteration 201/250, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 202/250, Loss: 0.0172\n",
      "Epoch 25/200, Iteration 203/250, Loss: 0.0391\n",
      "Epoch 25/200, Iteration 204/250, Loss: 0.0371\n",
      "Epoch 25/200, Iteration 205/250, Loss: 0.0386\n",
      "Epoch 25/200, Iteration 206/250, Loss: 0.0279\n",
      "Epoch 25/200, Iteration 207/250, Loss: 0.0139\n",
      "Epoch 25/200, Iteration 208/250, Loss: 0.0281\n",
      "Epoch 25/200, Iteration 209/250, Loss: 0.0288\n",
      "Epoch 25/200, Iteration 210/250, Loss: 0.0273\n",
      "Epoch 25/200, Iteration 211/250, Loss: 0.0234\n",
      "Epoch 25/200, Iteration 212/250, Loss: 0.0192\n",
      "Epoch 25/200, Iteration 213/250, Loss: 0.0213\n",
      "Epoch 25/200, Iteration 214/250, Loss: 0.0232\n",
      "Epoch 25/200, Iteration 215/250, Loss: 0.0245\n",
      "Epoch 25/200, Iteration 216/250, Loss: 0.0309\n",
      "Epoch 25/200, Iteration 217/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 218/250, Loss: 0.0269\n",
      "Epoch 25/200, Iteration 219/250, Loss: 0.0120\n",
      "Epoch 25/200, Iteration 220/250, Loss: 0.0187\n",
      "Epoch 25/200, Iteration 221/250, Loss: 0.0256\n",
      "Epoch 25/200, Iteration 222/250, Loss: 0.0302\n",
      "Epoch 25/200, Iteration 223/250, Loss: 0.0438\n",
      "Epoch 25/200, Iteration 224/250, Loss: 0.0213\n",
      "Epoch 25/200, Iteration 225/250, Loss: 0.0432\n",
      "Epoch 25/200, Iteration 226/250, Loss: 0.0299\n",
      "Epoch 25/200, Iteration 227/250, Loss: 0.0414\n",
      "Epoch 25/200, Iteration 228/250, Loss: 0.0213\n",
      "Epoch 25/200, Iteration 229/250, Loss: 0.0406\n",
      "Epoch 25/200, Iteration 230/250, Loss: 0.0235\n",
      "Epoch 25/200, Iteration 231/250, Loss: 0.0292\n",
      "Epoch 25/200, Iteration 232/250, Loss: 0.0256\n",
      "Epoch 25/200, Iteration 233/250, Loss: 0.0281\n",
      "Epoch 25/200, Iteration 234/250, Loss: 0.0371\n",
      "Epoch 25/200, Iteration 235/250, Loss: 0.0152\n",
      "Epoch 25/200, Iteration 236/250, Loss: 0.0536\n",
      "Epoch 25/200, Iteration 237/250, Loss: 0.0280\n",
      "Epoch 25/200, Iteration 238/250, Loss: 0.0137\n",
      "Epoch 25/200, Iteration 239/250, Loss: 0.0343\n",
      "Epoch 25/200, Iteration 240/250, Loss: 0.0534\n",
      "Epoch 25/200, Iteration 241/250, Loss: 0.0219\n",
      "Epoch 25/200, Iteration 242/250, Loss: 0.0202\n",
      "Epoch 25/200, Iteration 243/250, Loss: 0.0114\n",
      "Epoch 25/200, Iteration 244/250, Loss: 0.0738\n",
      "Epoch 25/200, Iteration 245/250, Loss: 0.0556\n",
      "Epoch 25/200, Iteration 246/250, Loss: 0.0197\n",
      "Epoch 25/200, Iteration 247/250, Loss: 0.0294\n",
      "Epoch 25/200, Iteration 248/250, Loss: 0.0270\n",
      "Epoch 25/200, Iteration 249/250, Loss: 0.0292\n",
      "Epoch 25/200, Iteration 250/250, Loss: 0.0532\n",
      "Train Error: \n",
      " Accuracy: 22.09%, Avg loss: 0.038725, MRE: 4.106847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 21.85%, Avg loss: 0.038686, MRE: 5.579416 \n",
      "\n",
      "Epoch 26/200, Iteration 1/250, Loss: 0.0429\n",
      "Epoch 26/200, Iteration 2/250, Loss: 0.0128\n",
      "Epoch 26/200, Iteration 3/250, Loss: 0.0204\n",
      "Epoch 26/200, Iteration 4/250, Loss: 0.0248\n",
      "Epoch 26/200, Iteration 5/250, Loss: 0.0139\n",
      "Epoch 26/200, Iteration 6/250, Loss: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Iteration 7/250, Loss: 0.0261\n",
      "Epoch 26/200, Iteration 8/250, Loss: 0.0135\n",
      "Epoch 26/200, Iteration 9/250, Loss: 0.0227\n",
      "Epoch 26/200, Iteration 10/250, Loss: 0.0138\n",
      "Epoch 26/200, Iteration 11/250, Loss: 0.0155\n",
      "Epoch 26/200, Iteration 12/250, Loss: 0.0228\n",
      "Epoch 26/200, Iteration 13/250, Loss: 0.0173\n",
      "Epoch 26/200, Iteration 14/250, Loss: 0.0223\n",
      "Epoch 26/200, Iteration 15/250, Loss: 0.0331\n",
      "Epoch 26/200, Iteration 16/250, Loss: 0.0177\n",
      "Epoch 26/200, Iteration 17/250, Loss: 0.0215\n",
      "Epoch 26/200, Iteration 18/250, Loss: 0.0409\n",
      "Epoch 26/200, Iteration 19/250, Loss: 0.0179\n",
      "Epoch 26/200, Iteration 20/250, Loss: 0.0432\n",
      "Epoch 26/200, Iteration 21/250, Loss: 0.0165\n",
      "Epoch 26/200, Iteration 22/250, Loss: 0.0243\n",
      "Epoch 26/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 26/200, Iteration 24/250, Loss: 0.0239\n",
      "Epoch 26/200, Iteration 25/250, Loss: 0.0292\n",
      "Epoch 26/200, Iteration 26/250, Loss: 0.0168\n",
      "Epoch 26/200, Iteration 27/250, Loss: 0.0169\n",
      "Epoch 26/200, Iteration 28/250, Loss: 0.0213\n",
      "Epoch 26/200, Iteration 29/250, Loss: 0.0188\n",
      "Epoch 26/200, Iteration 30/250, Loss: 0.0193\n",
      "Epoch 26/200, Iteration 31/250, Loss: 0.0163\n",
      "Epoch 26/200, Iteration 32/250, Loss: 0.0159\n",
      "Epoch 26/200, Iteration 33/250, Loss: 0.0355\n",
      "Epoch 26/200, Iteration 34/250, Loss: 0.0173\n",
      "Epoch 26/200, Iteration 35/250, Loss: 0.0199\n",
      "Epoch 26/200, Iteration 36/250, Loss: 0.0333\n",
      "Epoch 26/200, Iteration 37/250, Loss: 0.0532\n",
      "Epoch 26/200, Iteration 38/250, Loss: 0.0322\n",
      "Epoch 26/200, Iteration 39/250, Loss: 0.0240\n",
      "Epoch 26/200, Iteration 40/250, Loss: 0.0288\n",
      "Epoch 26/200, Iteration 41/250, Loss: 0.0127\n",
      "Epoch 26/200, Iteration 42/250, Loss: 0.0340\n",
      "Epoch 26/200, Iteration 43/250, Loss: 0.0495\n",
      "Epoch 26/200, Iteration 44/250, Loss: 0.0159\n",
      "Epoch 26/200, Iteration 45/250, Loss: 0.0236\n",
      "Epoch 26/200, Iteration 46/250, Loss: 0.0348\n",
      "Epoch 26/200, Iteration 47/250, Loss: 0.0211\n",
      "Epoch 26/200, Iteration 48/250, Loss: 0.0298\n",
      "Epoch 26/200, Iteration 49/250, Loss: 0.0322\n",
      "Epoch 26/200, Iteration 50/250, Loss: 0.0191\n",
      "Epoch 26/200, Iteration 51/250, Loss: 0.0121\n",
      "Epoch 26/200, Iteration 52/250, Loss: 0.0334\n",
      "Epoch 26/200, Iteration 53/250, Loss: 0.0315\n",
      "Epoch 26/200, Iteration 54/250, Loss: 0.0225\n",
      "Epoch 26/200, Iteration 55/250, Loss: 0.0259\n",
      "Epoch 26/200, Iteration 56/250, Loss: 0.0134\n",
      "Epoch 26/200, Iteration 57/250, Loss: 0.0352\n",
      "Epoch 26/200, Iteration 58/250, Loss: 0.0440\n",
      "Epoch 26/200, Iteration 59/250, Loss: 0.0306\n",
      "Epoch 26/200, Iteration 60/250, Loss: 0.0613\n",
      "Epoch 26/200, Iteration 61/250, Loss: 0.0507\n",
      "Epoch 26/200, Iteration 62/250, Loss: 0.0367\n",
      "Epoch 26/200, Iteration 63/250, Loss: 0.0307\n",
      "Epoch 26/200, Iteration 64/250, Loss: 0.0445\n",
      "Epoch 26/200, Iteration 65/250, Loss: 0.0241\n",
      "Epoch 26/200, Iteration 66/250, Loss: 0.0308\n",
      "Epoch 26/200, Iteration 67/250, Loss: 0.0221\n",
      "Epoch 26/200, Iteration 68/250, Loss: 0.0346\n",
      "Epoch 26/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 26/200, Iteration 70/250, Loss: 0.0270\n",
      "Epoch 26/200, Iteration 71/250, Loss: 0.0265\n",
      "Epoch 26/200, Iteration 72/250, Loss: 0.0319\n",
      "Epoch 26/200, Iteration 73/250, Loss: 0.0296\n",
      "Epoch 26/200, Iteration 74/250, Loss: 0.0594\n",
      "Epoch 26/200, Iteration 75/250, Loss: 0.0304\n",
      "Epoch 26/200, Iteration 76/250, Loss: 0.0272\n",
      "Epoch 26/200, Iteration 77/250, Loss: 0.0174\n",
      "Epoch 26/200, Iteration 78/250, Loss: 0.0283\n",
      "Epoch 26/200, Iteration 79/250, Loss: 0.0155\n",
      "Epoch 26/200, Iteration 80/250, Loss: 0.0194\n",
      "Epoch 26/200, Iteration 81/250, Loss: 0.0318\n",
      "Epoch 26/200, Iteration 82/250, Loss: 0.0524\n",
      "Epoch 26/200, Iteration 83/250, Loss: 0.0478\n",
      "Epoch 26/200, Iteration 84/250, Loss: 0.0603\n",
      "Epoch 26/200, Iteration 85/250, Loss: 0.0449\n",
      "Epoch 26/200, Iteration 86/250, Loss: 0.0307\n",
      "Epoch 26/200, Iteration 87/250, Loss: 0.0457\n",
      "Epoch 26/200, Iteration 88/250, Loss: 0.0474\n",
      "Epoch 26/200, Iteration 89/250, Loss: 0.0244\n",
      "Epoch 26/200, Iteration 90/250, Loss: 0.0496\n",
      "Epoch 26/200, Iteration 91/250, Loss: 0.0219\n",
      "Epoch 26/200, Iteration 92/250, Loss: 0.0694\n",
      "Epoch 26/200, Iteration 93/250, Loss: 0.0344\n",
      "Epoch 26/200, Iteration 94/250, Loss: 0.0377\n",
      "Epoch 26/200, Iteration 95/250, Loss: 0.0279\n",
      "Epoch 26/200, Iteration 96/250, Loss: 0.0258\n",
      "Epoch 26/200, Iteration 97/250, Loss: 0.0505\n",
      "Epoch 26/200, Iteration 98/250, Loss: 0.0374\n",
      "Epoch 26/200, Iteration 99/250, Loss: 0.0281\n",
      "Epoch 26/200, Iteration 100/250, Loss: 0.0835\n",
      "Epoch 26/200, Iteration 101/250, Loss: 0.0758\n",
      "Epoch 26/200, Iteration 102/250, Loss: 0.0815\n",
      "Epoch 26/200, Iteration 103/250, Loss: 0.0275\n",
      "Epoch 26/200, Iteration 104/250, Loss: 0.0476\n",
      "Epoch 26/200, Iteration 105/250, Loss: 0.0435\n",
      "Epoch 26/200, Iteration 106/250, Loss: 0.0250\n",
      "Epoch 26/200, Iteration 107/250, Loss: 0.0203\n",
      "Epoch 26/200, Iteration 108/250, Loss: 0.0785\n",
      "Epoch 26/200, Iteration 109/250, Loss: 0.0227\n",
      "Epoch 26/200, Iteration 110/250, Loss: 0.0903\n",
      "Epoch 26/200, Iteration 111/250, Loss: 0.0658\n",
      "Epoch 26/200, Iteration 112/250, Loss: 0.0346\n",
      "Epoch 26/200, Iteration 113/250, Loss: 0.0390\n",
      "Epoch 26/200, Iteration 114/250, Loss: 0.0224\n",
      "Epoch 26/200, Iteration 115/250, Loss: 0.0268\n",
      "Epoch 26/200, Iteration 116/250, Loss: 0.0353\n",
      "Epoch 26/200, Iteration 117/250, Loss: 0.0382\n",
      "Epoch 26/200, Iteration 118/250, Loss: 0.0338\n",
      "Epoch 26/200, Iteration 119/250, Loss: 0.0340\n",
      "Epoch 26/200, Iteration 120/250, Loss: 0.0207\n",
      "Epoch 26/200, Iteration 121/250, Loss: 0.0201\n",
      "Epoch 26/200, Iteration 122/250, Loss: 0.0888\n",
      "Epoch 26/200, Iteration 123/250, Loss: 0.0490\n",
      "Epoch 26/200, Iteration 124/250, Loss: 0.0226\n",
      "Epoch 26/200, Iteration 125/250, Loss: 0.0296\n",
      "Epoch 26/200, Iteration 126/250, Loss: 0.0356\n",
      "Epoch 26/200, Iteration 127/250, Loss: 0.0962\n",
      "Epoch 26/200, Iteration 128/250, Loss: 0.0231\n",
      "Epoch 26/200, Iteration 129/250, Loss: 0.0161\n",
      "Epoch 26/200, Iteration 130/250, Loss: 0.0167\n",
      "Epoch 26/200, Iteration 131/250, Loss: 0.0190\n",
      "Epoch 26/200, Iteration 132/250, Loss: 0.0198\n",
      "Epoch 26/200, Iteration 133/250, Loss: 0.0146\n",
      "Epoch 26/200, Iteration 134/250, Loss: 0.0212\n",
      "Epoch 26/200, Iteration 135/250, Loss: 0.0620\n",
      "Epoch 26/200, Iteration 136/250, Loss: 0.0608\n",
      "Epoch 26/200, Iteration 137/250, Loss: 0.0463\n",
      "Epoch 26/200, Iteration 138/250, Loss: 0.0569\n",
      "Epoch 26/200, Iteration 139/250, Loss: 0.0407\n",
      "Epoch 26/200, Iteration 140/250, Loss: 0.0165\n",
      "Epoch 26/200, Iteration 141/250, Loss: 0.0269\n",
      "Epoch 26/200, Iteration 142/250, Loss: 0.0468\n",
      "Epoch 26/200, Iteration 143/250, Loss: 0.0431\n",
      "Epoch 26/200, Iteration 144/250, Loss: 0.0246\n",
      "Epoch 26/200, Iteration 145/250, Loss: 0.0250\n",
      "Epoch 26/200, Iteration 146/250, Loss: 0.0167\n",
      "Epoch 26/200, Iteration 147/250, Loss: 0.0362\n",
      "Epoch 26/200, Iteration 148/250, Loss: 0.0228\n",
      "Epoch 26/200, Iteration 149/250, Loss: 0.0322\n",
      "Epoch 26/200, Iteration 150/250, Loss: 0.0361\n",
      "Epoch 26/200, Iteration 151/250, Loss: 0.0168\n",
      "Epoch 26/200, Iteration 152/250, Loss: 0.0372\n",
      "Epoch 26/200, Iteration 153/250, Loss: 0.0357\n",
      "Epoch 26/200, Iteration 154/250, Loss: 0.0228\n",
      "Epoch 26/200, Iteration 155/250, Loss: 0.0424\n",
      "Epoch 26/200, Iteration 156/250, Loss: 0.0293\n",
      "Epoch 26/200, Iteration 157/250, Loss: 0.0408\n",
      "Epoch 26/200, Iteration 158/250, Loss: 0.0241\n",
      "Epoch 26/200, Iteration 159/250, Loss: 0.0286\n",
      "Epoch 26/200, Iteration 160/250, Loss: 0.0289\n",
      "Epoch 26/200, Iteration 161/250, Loss: 0.0540\n",
      "Epoch 26/200, Iteration 162/250, Loss: 0.0454\n",
      "Epoch 26/200, Iteration 163/250, Loss: 0.0206\n",
      "Epoch 26/200, Iteration 164/250, Loss: 0.0309\n",
      "Epoch 26/200, Iteration 165/250, Loss: 0.0383\n",
      "Epoch 26/200, Iteration 166/250, Loss: 0.0313\n",
      "Epoch 26/200, Iteration 167/250, Loss: 0.0816\n",
      "Epoch 26/200, Iteration 168/250, Loss: 0.0309\n",
      "Epoch 26/200, Iteration 169/250, Loss: 0.0448\n",
      "Epoch 26/200, Iteration 170/250, Loss: 0.0312\n",
      "Epoch 26/200, Iteration 171/250, Loss: 0.0259\n",
      "Epoch 26/200, Iteration 172/250, Loss: 0.0226\n",
      "Epoch 26/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 26/200, Iteration 174/250, Loss: 0.0332\n",
      "Epoch 26/200, Iteration 175/250, Loss: 0.0175\n",
      "Epoch 26/200, Iteration 176/250, Loss: 0.0239\n",
      "Epoch 26/200, Iteration 177/250, Loss: 0.0130\n",
      "Epoch 26/200, Iteration 178/250, Loss: 0.0150\n",
      "Epoch 26/200, Iteration 179/250, Loss: 0.0462\n",
      "Epoch 26/200, Iteration 180/250, Loss: 0.0215\n",
      "Epoch 26/200, Iteration 181/250, Loss: 0.0255\n",
      "Epoch 26/200, Iteration 182/250, Loss: 0.0215\n",
      "Epoch 26/200, Iteration 183/250, Loss: 0.0200\n",
      "Epoch 26/200, Iteration 184/250, Loss: 0.0357\n",
      "Epoch 26/200, Iteration 185/250, Loss: 0.0294\n",
      "Epoch 26/200, Iteration 186/250, Loss: 0.0424\n",
      "Epoch 26/200, Iteration 187/250, Loss: 0.0247\n",
      "Epoch 26/200, Iteration 188/250, Loss: 0.0321\n",
      "Epoch 26/200, Iteration 189/250, Loss: 0.0125\n",
      "Epoch 26/200, Iteration 190/250, Loss: 0.0205\n",
      "Epoch 26/200, Iteration 191/250, Loss: 0.0358\n",
      "Epoch 26/200, Iteration 192/250, Loss: 0.0149\n",
      "Epoch 26/200, Iteration 193/250, Loss: 0.0217\n",
      "Epoch 26/200, Iteration 194/250, Loss: 0.0413\n",
      "Epoch 26/200, Iteration 195/250, Loss: 0.0339\n",
      "Epoch 26/200, Iteration 196/250, Loss: 0.0443\n",
      "Epoch 26/200, Iteration 197/250, Loss: 0.0220\n",
      "Epoch 26/200, Iteration 198/250, Loss: 0.0768\n",
      "Epoch 26/200, Iteration 199/250, Loss: 0.0302\n",
      "Epoch 26/200, Iteration 200/250, Loss: 0.0527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Iteration 201/250, Loss: 0.0545\n",
      "Epoch 26/200, Iteration 202/250, Loss: 0.0160\n",
      "Epoch 26/200, Iteration 203/250, Loss: 0.0495\n",
      "Epoch 26/200, Iteration 204/250, Loss: 0.0284\n",
      "Epoch 26/200, Iteration 205/250, Loss: 0.0168\n",
      "Epoch 26/200, Iteration 206/250, Loss: 0.0207\n",
      "Epoch 26/200, Iteration 207/250, Loss: 0.0182\n",
      "Epoch 26/200, Iteration 208/250, Loss: 0.0134\n",
      "Epoch 26/200, Iteration 209/250, Loss: 0.0622\n",
      "Epoch 26/200, Iteration 210/250, Loss: 0.0334\n",
      "Epoch 26/200, Iteration 211/250, Loss: 0.0341\n",
      "Epoch 26/200, Iteration 212/250, Loss: 0.0296\n",
      "Epoch 26/200, Iteration 213/250, Loss: 0.0433\n",
      "Epoch 26/200, Iteration 214/250, Loss: 0.0261\n",
      "Epoch 26/200, Iteration 215/250, Loss: 0.0529\n",
      "Epoch 26/200, Iteration 216/250, Loss: 0.0216\n",
      "Epoch 26/200, Iteration 217/250, Loss: 0.0188\n",
      "Epoch 26/200, Iteration 218/250, Loss: 0.0287\n",
      "Epoch 26/200, Iteration 219/250, Loss: 0.0265\n",
      "Epoch 26/200, Iteration 220/250, Loss: 0.0313\n",
      "Epoch 26/200, Iteration 221/250, Loss: 0.0158\n",
      "Epoch 26/200, Iteration 222/250, Loss: 0.0493\n",
      "Epoch 26/200, Iteration 223/250, Loss: 0.0528\n",
      "Epoch 26/200, Iteration 224/250, Loss: 0.0350\n",
      "Epoch 26/200, Iteration 225/250, Loss: 0.0149\n",
      "Epoch 26/200, Iteration 226/250, Loss: 0.0389\n",
      "Epoch 26/200, Iteration 227/250, Loss: 0.0141\n",
      "Epoch 26/200, Iteration 228/250, Loss: 0.0175\n",
      "Epoch 26/200, Iteration 229/250, Loss: 0.0151\n",
      "Epoch 26/200, Iteration 230/250, Loss: 0.0111\n",
      "Epoch 26/200, Iteration 231/250, Loss: 0.0208\n",
      "Epoch 26/200, Iteration 232/250, Loss: 0.0312\n",
      "Epoch 26/200, Iteration 233/250, Loss: 0.0431\n",
      "Epoch 26/200, Iteration 234/250, Loss: 0.0195\n",
      "Epoch 26/200, Iteration 235/250, Loss: 0.0387\n",
      "Epoch 26/200, Iteration 236/250, Loss: 0.0168\n",
      "Epoch 26/200, Iteration 237/250, Loss: 0.0177\n",
      "Epoch 26/200, Iteration 238/250, Loss: 0.0189\n",
      "Epoch 26/200, Iteration 239/250, Loss: 0.0141\n",
      "Epoch 26/200, Iteration 240/250, Loss: 0.0155\n",
      "Epoch 26/200, Iteration 241/250, Loss: 0.0424\n",
      "Epoch 26/200, Iteration 242/250, Loss: 0.0220\n",
      "Epoch 26/200, Iteration 243/250, Loss: 0.0188\n",
      "Epoch 26/200, Iteration 244/250, Loss: 0.0176\n",
      "Epoch 26/200, Iteration 245/250, Loss: 0.0287\n",
      "Epoch 26/200, Iteration 246/250, Loss: 0.0151\n",
      "Epoch 26/200, Iteration 247/250, Loss: 0.0317\n",
      "Epoch 26/200, Iteration 248/250, Loss: 0.0130\n",
      "Epoch 26/200, Iteration 249/250, Loss: 0.0342\n",
      "Epoch 26/200, Iteration 250/250, Loss: 0.0400\n",
      "Train Error: \n",
      " Accuracy: 62.02%, Avg loss: 0.022241, MRE: 1.144032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.022670, MRE: 2.284981 \n",
      "\n",
      "Epoch 27/200, Iteration 1/250, Loss: 0.0207\n",
      "Epoch 27/200, Iteration 2/250, Loss: 0.0256\n",
      "Epoch 27/200, Iteration 3/250, Loss: 0.0188\n",
      "Epoch 27/200, Iteration 4/250, Loss: 0.0178\n",
      "Epoch 27/200, Iteration 5/250, Loss: 0.0184\n",
      "Epoch 27/200, Iteration 6/250, Loss: 0.0350\n",
      "Epoch 27/200, Iteration 7/250, Loss: 0.0174\n",
      "Epoch 27/200, Iteration 8/250, Loss: 0.0479\n",
      "Epoch 27/200, Iteration 9/250, Loss: 0.0201\n",
      "Epoch 27/200, Iteration 10/250, Loss: 0.0115\n",
      "Epoch 27/200, Iteration 11/250, Loss: 0.0356\n",
      "Epoch 27/200, Iteration 12/250, Loss: 0.0523\n",
      "Epoch 27/200, Iteration 13/250, Loss: 0.0325\n",
      "Epoch 27/200, Iteration 14/250, Loss: 0.0255\n",
      "Epoch 27/200, Iteration 15/250, Loss: 0.0391\n",
      "Epoch 27/200, Iteration 16/250, Loss: 0.0347\n",
      "Epoch 27/200, Iteration 17/250, Loss: 0.0342\n",
      "Epoch 27/200, Iteration 18/250, Loss: 0.0417\n",
      "Epoch 27/200, Iteration 19/250, Loss: 0.0198\n",
      "Epoch 27/200, Iteration 20/250, Loss: 0.0189\n",
      "Epoch 27/200, Iteration 21/250, Loss: 0.0278\n",
      "Epoch 27/200, Iteration 22/250, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 23/250, Loss: 0.0240\n",
      "Epoch 27/200, Iteration 24/250, Loss: 0.0132\n",
      "Epoch 27/200, Iteration 25/250, Loss: 0.0190\n",
      "Epoch 27/200, Iteration 26/250, Loss: 0.0404\n",
      "Epoch 27/200, Iteration 27/250, Loss: 0.0314\n",
      "Epoch 27/200, Iteration 28/250, Loss: 0.0173\n",
      "Epoch 27/200, Iteration 29/250, Loss: 0.0140\n",
      "Epoch 27/200, Iteration 30/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 31/250, Loss: 0.0191\n",
      "Epoch 27/200, Iteration 32/250, Loss: 0.0133\n",
      "Epoch 27/200, Iteration 33/250, Loss: 0.0377\n",
      "Epoch 27/200, Iteration 34/250, Loss: 0.0323\n",
      "Epoch 27/200, Iteration 35/250, Loss: 0.0112\n",
      "Epoch 27/200, Iteration 36/250, Loss: 0.0209\n",
      "Epoch 27/200, Iteration 37/250, Loss: 0.0121\n",
      "Epoch 27/200, Iteration 38/250, Loss: 0.0348\n",
      "Epoch 27/200, Iteration 39/250, Loss: 0.0291\n",
      "Epoch 27/200, Iteration 40/250, Loss: 0.0232\n",
      "Epoch 27/200, Iteration 41/250, Loss: 0.0251\n",
      "Epoch 27/200, Iteration 42/250, Loss: 0.0525\n",
      "Epoch 27/200, Iteration 43/250, Loss: 0.0260\n",
      "Epoch 27/200, Iteration 44/250, Loss: 0.0241\n",
      "Epoch 27/200, Iteration 45/250, Loss: 0.0340\n",
      "Epoch 27/200, Iteration 46/250, Loss: 0.0260\n",
      "Epoch 27/200, Iteration 47/250, Loss: 0.0349\n",
      "Epoch 27/200, Iteration 48/250, Loss: 0.0105\n",
      "Epoch 27/200, Iteration 49/250, Loss: 0.0105\n",
      "Epoch 27/200, Iteration 50/250, Loss: 0.0478\n",
      "Epoch 27/200, Iteration 51/250, Loss: 0.0167\n",
      "Epoch 27/200, Iteration 52/250, Loss: 0.0278\n",
      "Epoch 27/200, Iteration 53/250, Loss: 0.0171\n",
      "Epoch 27/200, Iteration 54/250, Loss: 0.0221\n",
      "Epoch 27/200, Iteration 55/250, Loss: 0.0591\n",
      "Epoch 27/200, Iteration 56/250, Loss: 0.0244\n",
      "Epoch 27/200, Iteration 57/250, Loss: 0.0134\n",
      "Epoch 27/200, Iteration 58/250, Loss: 0.0455\n",
      "Epoch 27/200, Iteration 59/250, Loss: 0.0273\n",
      "Epoch 27/200, Iteration 60/250, Loss: 0.0289\n",
      "Epoch 27/200, Iteration 61/250, Loss: 0.0351\n",
      "Epoch 27/200, Iteration 62/250, Loss: 0.0275\n",
      "Epoch 27/200, Iteration 63/250, Loss: 0.0149\n",
      "Epoch 27/200, Iteration 64/250, Loss: 0.0384\n",
      "Epoch 27/200, Iteration 65/250, Loss: 0.0171\n",
      "Epoch 27/200, Iteration 66/250, Loss: 0.0222\n",
      "Epoch 27/200, Iteration 67/250, Loss: 0.0268\n",
      "Epoch 27/200, Iteration 68/250, Loss: 0.0246\n",
      "Epoch 27/200, Iteration 69/250, Loss: 0.0320\n",
      "Epoch 27/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 27/200, Iteration 71/250, Loss: 0.0370\n",
      "Epoch 27/200, Iteration 72/250, Loss: 0.0269\n",
      "Epoch 27/200, Iteration 73/250, Loss: 0.0323\n",
      "Epoch 27/200, Iteration 74/250, Loss: 0.0236\n",
      "Epoch 27/200, Iteration 75/250, Loss: 0.0150\n",
      "Epoch 27/200, Iteration 76/250, Loss: 0.0293\n",
      "Epoch 27/200, Iteration 77/250, Loss: 0.0157\n",
      "Epoch 27/200, Iteration 78/250, Loss: 0.0276\n",
      "Epoch 27/200, Iteration 79/250, Loss: 0.0381\n",
      "Epoch 27/200, Iteration 80/250, Loss: 0.0398\n",
      "Epoch 27/200, Iteration 81/250, Loss: 0.0213\n",
      "Epoch 27/200, Iteration 82/250, Loss: 0.0186\n",
      "Epoch 27/200, Iteration 83/250, Loss: 0.0230\n",
      "Epoch 27/200, Iteration 84/250, Loss: 0.0235\n",
      "Epoch 27/200, Iteration 85/250, Loss: 0.0325\n",
      "Epoch 27/200, Iteration 86/250, Loss: 0.0105\n",
      "Epoch 27/200, Iteration 87/250, Loss: 0.0654\n",
      "Epoch 27/200, Iteration 88/250, Loss: 0.0223\n",
      "Epoch 27/200, Iteration 89/250, Loss: 0.0299\n",
      "Epoch 27/200, Iteration 90/250, Loss: 0.0266\n",
      "Epoch 27/200, Iteration 91/250, Loss: 0.0296\n",
      "Epoch 27/200, Iteration 92/250, Loss: 0.0123\n",
      "Epoch 27/200, Iteration 93/250, Loss: 0.0186\n",
      "Epoch 27/200, Iteration 94/250, Loss: 0.0149\n",
      "Epoch 27/200, Iteration 95/250, Loss: 0.0208\n",
      "Epoch 27/200, Iteration 96/250, Loss: 0.0352\n",
      "Epoch 27/200, Iteration 97/250, Loss: 0.0188\n",
      "Epoch 27/200, Iteration 98/250, Loss: 0.0244\n",
      "Epoch 27/200, Iteration 99/250, Loss: 0.0289\n",
      "Epoch 27/200, Iteration 100/250, Loss: 0.0337\n",
      "Epoch 27/200, Iteration 101/250, Loss: 0.0366\n",
      "Epoch 27/200, Iteration 102/250, Loss: 0.0287\n",
      "Epoch 27/200, Iteration 103/250, Loss: 0.0387\n",
      "Epoch 27/200, Iteration 104/250, Loss: 0.0214\n",
      "Epoch 27/200, Iteration 105/250, Loss: 0.0193\n",
      "Epoch 27/200, Iteration 106/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 107/250, Loss: 0.0245\n",
      "Epoch 27/200, Iteration 108/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 109/250, Loss: 0.0301\n",
      "Epoch 27/200, Iteration 110/250, Loss: 0.0269\n",
      "Epoch 27/200, Iteration 111/250, Loss: 0.0238\n",
      "Epoch 27/200, Iteration 112/250, Loss: 0.0505\n",
      "Epoch 27/200, Iteration 113/250, Loss: 0.0683\n",
      "Epoch 27/200, Iteration 114/250, Loss: 0.0364\n",
      "Epoch 27/200, Iteration 115/250, Loss: 0.0212\n",
      "Epoch 27/200, Iteration 116/250, Loss: 0.0498\n",
      "Epoch 27/200, Iteration 117/250, Loss: 0.0190\n",
      "Epoch 27/200, Iteration 118/250, Loss: 0.0334\n",
      "Epoch 27/200, Iteration 119/250, Loss: 0.0603\n",
      "Epoch 27/200, Iteration 120/250, Loss: 0.0359\n",
      "Epoch 27/200, Iteration 121/250, Loss: 0.0383\n",
      "Epoch 27/200, Iteration 122/250, Loss: 0.0122\n",
      "Epoch 27/200, Iteration 123/250, Loss: 0.0348\n",
      "Epoch 27/200, Iteration 124/250, Loss: 0.0269\n",
      "Epoch 27/200, Iteration 125/250, Loss: 0.0176\n",
      "Epoch 27/200, Iteration 126/250, Loss: 0.0243\n",
      "Epoch 27/200, Iteration 127/250, Loss: 0.0144\n",
      "Epoch 27/200, Iteration 128/250, Loss: 0.0162\n",
      "Epoch 27/200, Iteration 129/250, Loss: 0.0218\n",
      "Epoch 27/200, Iteration 130/250, Loss: 0.0143\n",
      "Epoch 27/200, Iteration 131/250, Loss: 0.0231\n",
      "Epoch 27/200, Iteration 132/250, Loss: 0.0179\n",
      "Epoch 27/200, Iteration 133/250, Loss: 0.0243\n",
      "Epoch 27/200, Iteration 134/250, Loss: 0.0545\n",
      "Epoch 27/200, Iteration 135/250, Loss: 0.0136\n",
      "Epoch 27/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 27/200, Iteration 137/250, Loss: 0.0172\n",
      "Epoch 27/200, Iteration 138/250, Loss: 0.0320\n",
      "Epoch 27/200, Iteration 139/250, Loss: 0.0195\n",
      "Epoch 27/200, Iteration 140/250, Loss: 0.0289\n",
      "Epoch 27/200, Iteration 141/250, Loss: 0.0351\n",
      "Epoch 27/200, Iteration 142/250, Loss: 0.0277\n",
      "Epoch 27/200, Iteration 143/250, Loss: 0.0373\n",
      "Epoch 27/200, Iteration 144/250, Loss: 0.0179\n",
      "Epoch 27/200, Iteration 145/250, Loss: 0.0273\n",
      "Epoch 27/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 27/200, Iteration 147/250, Loss: 0.0125\n",
      "Epoch 27/200, Iteration 148/250, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 149/250, Loss: 0.0309\n",
      "Epoch 27/200, Iteration 150/250, Loss: 0.0151\n",
      "Epoch 27/200, Iteration 151/250, Loss: 0.0137\n",
      "Epoch 27/200, Iteration 152/250, Loss: 0.0197\n",
      "Epoch 27/200, Iteration 153/250, Loss: 0.0174\n",
      "Epoch 27/200, Iteration 154/250, Loss: 0.0659\n",
      "Epoch 27/200, Iteration 155/250, Loss: 0.0126\n",
      "Epoch 27/200, Iteration 156/250, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 157/250, Loss: 0.0161\n",
      "Epoch 27/200, Iteration 158/250, Loss: 0.0125\n",
      "Epoch 27/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 27/200, Iteration 160/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 161/250, Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Iteration 162/250, Loss: 0.0124\n",
      "Epoch 27/200, Iteration 163/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 164/250, Loss: 0.0157\n",
      "Epoch 27/200, Iteration 165/250, Loss: 0.0170\n",
      "Epoch 27/200, Iteration 166/250, Loss: 0.0218\n",
      "Epoch 27/200, Iteration 167/250, Loss: 0.0252\n",
      "Epoch 27/200, Iteration 168/250, Loss: 0.0096\n",
      "Epoch 27/200, Iteration 169/250, Loss: 0.0083\n",
      "Epoch 27/200, Iteration 170/250, Loss: 0.0083\n",
      "Epoch 27/200, Iteration 171/250, Loss: 0.0263\n",
      "Epoch 27/200, Iteration 172/250, Loss: 0.0308\n",
      "Epoch 27/200, Iteration 173/250, Loss: 0.0172\n",
      "Epoch 27/200, Iteration 174/250, Loss: 0.0206\n",
      "Epoch 27/200, Iteration 175/250, Loss: 0.0123\n",
      "Epoch 27/200, Iteration 176/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 177/250, Loss: 0.0121\n",
      "Epoch 27/200, Iteration 178/250, Loss: 0.0169\n",
      "Epoch 27/200, Iteration 179/250, Loss: 0.0144\n",
      "Epoch 27/200, Iteration 180/250, Loss: 0.0497\n",
      "Epoch 27/200, Iteration 181/250, Loss: 0.0463\n",
      "Epoch 27/200, Iteration 182/250, Loss: 0.0485\n",
      "Epoch 27/200, Iteration 183/250, Loss: 0.0170\n",
      "Epoch 27/200, Iteration 184/250, Loss: 0.0272\n",
      "Epoch 27/200, Iteration 185/250, Loss: 0.0253\n",
      "Epoch 27/200, Iteration 186/250, Loss: 0.0169\n",
      "Epoch 27/200, Iteration 187/250, Loss: 0.0171\n",
      "Epoch 27/200, Iteration 188/250, Loss: 0.0330\n",
      "Epoch 27/200, Iteration 189/250, Loss: 0.0217\n",
      "Epoch 27/200, Iteration 190/250, Loss: 0.0125\n",
      "Epoch 27/200, Iteration 191/250, Loss: 0.0146\n",
      "Epoch 27/200, Iteration 192/250, Loss: 0.0287\n",
      "Epoch 27/200, Iteration 193/250, Loss: 0.0275\n",
      "Epoch 27/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 27/200, Iteration 195/250, Loss: 0.0244\n",
      "Epoch 27/200, Iteration 196/250, Loss: 0.0357\n",
      "Epoch 27/200, Iteration 197/250, Loss: 0.0218\n",
      "Epoch 27/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 27/200, Iteration 199/250, Loss: 0.0267\n",
      "Epoch 27/200, Iteration 200/250, Loss: 0.0183\n",
      "Epoch 27/200, Iteration 201/250, Loss: 0.0234\n",
      "Epoch 27/200, Iteration 202/250, Loss: 0.0194\n",
      "Epoch 27/200, Iteration 203/250, Loss: 0.0197\n",
      "Epoch 27/200, Iteration 204/250, Loss: 0.0259\n",
      "Epoch 27/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 27/200, Iteration 206/250, Loss: 0.0419\n",
      "Epoch 27/200, Iteration 207/250, Loss: 0.0110\n",
      "Epoch 27/200, Iteration 208/250, Loss: 0.0143\n",
      "Epoch 27/200, Iteration 209/250, Loss: 0.0255\n",
      "Epoch 27/200, Iteration 210/250, Loss: 0.0169\n",
      "Epoch 27/200, Iteration 211/250, Loss: 0.0163\n",
      "Epoch 27/200, Iteration 212/250, Loss: 0.0234\n",
      "Epoch 27/200, Iteration 213/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 214/250, Loss: 0.0275\n",
      "Epoch 27/200, Iteration 215/250, Loss: 0.0200\n",
      "Epoch 27/200, Iteration 216/250, Loss: 0.0208\n",
      "Epoch 27/200, Iteration 217/250, Loss: 0.0324\n",
      "Epoch 27/200, Iteration 218/250, Loss: 0.0200\n",
      "Epoch 27/200, Iteration 219/250, Loss: 0.0182\n",
      "Epoch 27/200, Iteration 220/250, Loss: 0.0232\n",
      "Epoch 27/200, Iteration 221/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 222/250, Loss: 0.0160\n",
      "Epoch 27/200, Iteration 223/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 224/250, Loss: 0.0311\n",
      "Epoch 27/200, Iteration 225/250, Loss: 0.0219\n",
      "Epoch 27/200, Iteration 226/250, Loss: 0.0116\n",
      "Epoch 27/200, Iteration 227/250, Loss: 0.0165\n",
      "Epoch 27/200, Iteration 228/250, Loss: 0.0128\n",
      "Epoch 27/200, Iteration 229/250, Loss: 0.0215\n",
      "Epoch 27/200, Iteration 230/250, Loss: 0.0251\n",
      "Epoch 27/200, Iteration 231/250, Loss: 0.0266\n",
      "Epoch 27/200, Iteration 232/250, Loss: 0.0306\n",
      "Epoch 27/200, Iteration 233/250, Loss: 0.0337\n",
      "Epoch 27/200, Iteration 234/250, Loss: 0.0333\n",
      "Epoch 27/200, Iteration 235/250, Loss: 0.0186\n",
      "Epoch 27/200, Iteration 236/250, Loss: 0.0372\n",
      "Epoch 27/200, Iteration 237/250, Loss: 0.0258\n",
      "Epoch 27/200, Iteration 238/250, Loss: 0.0331\n",
      "Epoch 27/200, Iteration 239/250, Loss: 0.0204\n",
      "Epoch 27/200, Iteration 240/250, Loss: 0.0277\n",
      "Epoch 27/200, Iteration 241/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 242/250, Loss: 0.0130\n",
      "Epoch 27/200, Iteration 243/250, Loss: 0.0268\n",
      "Epoch 27/200, Iteration 244/250, Loss: 0.0227\n",
      "Epoch 27/200, Iteration 245/250, Loss: 0.0402\n",
      "Epoch 27/200, Iteration 246/250, Loss: 0.0239\n",
      "Epoch 27/200, Iteration 247/250, Loss: 0.0518\n",
      "Epoch 27/200, Iteration 248/250, Loss: 0.0277\n",
      "Epoch 27/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 27/200, Iteration 250/250, Loss: 0.0491\n",
      "Train Error: \n",
      " Accuracy: 34.14%, Avg loss: 0.022664, MRE: 0.864878 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 34.0%, Avg loss: 0.022795, MRE: 1.037845 \n",
      "\n",
      "Epoch 28/200, Iteration 1/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 2/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 3/250, Loss: 0.0438\n",
      "Epoch 28/200, Iteration 4/250, Loss: 0.0301\n",
      "Epoch 28/200, Iteration 5/250, Loss: 0.0282\n",
      "Epoch 28/200, Iteration 6/250, Loss: 0.0683\n",
      "Epoch 28/200, Iteration 7/250, Loss: 0.0298\n",
      "Epoch 28/200, Iteration 8/250, Loss: 0.0198\n",
      "Epoch 28/200, Iteration 9/250, Loss: 0.0252\n",
      "Epoch 28/200, Iteration 10/250, Loss: 0.0263\n",
      "Epoch 28/200, Iteration 11/250, Loss: 0.0179\n",
      "Epoch 28/200, Iteration 12/250, Loss: 0.0245\n",
      "Epoch 28/200, Iteration 13/250, Loss: 0.0161\n",
      "Epoch 28/200, Iteration 14/250, Loss: 0.0124\n",
      "Epoch 28/200, Iteration 15/250, Loss: 0.0204\n",
      "Epoch 28/200, Iteration 16/250, Loss: 0.0159\n",
      "Epoch 28/200, Iteration 17/250, Loss: 0.0183\n",
      "Epoch 28/200, Iteration 18/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 19/250, Loss: 0.0155\n",
      "Epoch 28/200, Iteration 20/250, Loss: 0.0149\n",
      "Epoch 28/200, Iteration 21/250, Loss: 0.0147\n",
      "Epoch 28/200, Iteration 22/250, Loss: 0.0178\n",
      "Epoch 28/200, Iteration 23/250, Loss: 0.0298\n",
      "Epoch 28/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 28/200, Iteration 25/250, Loss: 0.0215\n",
      "Epoch 28/200, Iteration 26/250, Loss: 0.0181\n",
      "Epoch 28/200, Iteration 27/250, Loss: 0.0143\n",
      "Epoch 28/200, Iteration 28/250, Loss: 0.0120\n",
      "Epoch 28/200, Iteration 29/250, Loss: 0.0290\n",
      "Epoch 28/200, Iteration 30/250, Loss: 0.0170\n",
      "Epoch 28/200, Iteration 31/250, Loss: 0.0261\n",
      "Epoch 28/200, Iteration 32/250, Loss: 0.0176\n",
      "Epoch 28/200, Iteration 33/250, Loss: 0.0156\n",
      "Epoch 28/200, Iteration 34/250, Loss: 0.0150\n",
      "Epoch 28/200, Iteration 35/250, Loss: 0.0148\n",
      "Epoch 28/200, Iteration 36/250, Loss: 0.0167\n",
      "Epoch 28/200, Iteration 37/250, Loss: 0.0146\n",
      "Epoch 28/200, Iteration 38/250, Loss: 0.0163\n",
      "Epoch 28/200, Iteration 39/250, Loss: 0.0144\n",
      "Epoch 28/200, Iteration 40/250, Loss: 0.0113\n",
      "Epoch 28/200, Iteration 41/250, Loss: 0.0124\n",
      "Epoch 28/200, Iteration 42/250, Loss: 0.0147\n",
      "Epoch 28/200, Iteration 43/250, Loss: 0.0131\n",
      "Epoch 28/200, Iteration 44/250, Loss: 0.0129\n",
      "Epoch 28/200, Iteration 45/250, Loss: 0.0112\n",
      "Epoch 28/200, Iteration 46/250, Loss: 0.0161\n",
      "Epoch 28/200, Iteration 47/250, Loss: 0.0093\n",
      "Epoch 28/200, Iteration 48/250, Loss: 0.0202\n",
      "Epoch 28/200, Iteration 49/250, Loss: 0.0270\n",
      "Epoch 28/200, Iteration 50/250, Loss: 0.0259\n",
      "Epoch 28/200, Iteration 51/250, Loss: 0.0191\n",
      "Epoch 28/200, Iteration 52/250, Loss: 0.0436\n",
      "Epoch 28/200, Iteration 53/250, Loss: 0.0544\n",
      "Epoch 28/200, Iteration 54/250, Loss: 0.0285\n",
      "Epoch 28/200, Iteration 55/250, Loss: 0.0168\n",
      "Epoch 28/200, Iteration 56/250, Loss: 0.0120\n",
      "Epoch 28/200, Iteration 57/250, Loss: 0.0070\n",
      "Epoch 28/200, Iteration 58/250, Loss: 0.0352\n",
      "Epoch 28/200, Iteration 59/250, Loss: 0.0137\n",
      "Epoch 28/200, Iteration 60/250, Loss: 0.0333\n",
      "Epoch 28/200, Iteration 61/250, Loss: 0.0172\n",
      "Epoch 28/200, Iteration 62/250, Loss: 0.0173\n",
      "Epoch 28/200, Iteration 63/250, Loss: 0.0348\n",
      "Epoch 28/200, Iteration 64/250, Loss: 0.0101\n",
      "Epoch 28/200, Iteration 65/250, Loss: 0.0163\n",
      "Epoch 28/200, Iteration 66/250, Loss: 0.0124\n",
      "Epoch 28/200, Iteration 67/250, Loss: 0.0227\n",
      "Epoch 28/200, Iteration 68/250, Loss: 0.0139\n",
      "Epoch 28/200, Iteration 69/250, Loss: 0.0265\n",
      "Epoch 28/200, Iteration 70/250, Loss: 0.0457\n",
      "Epoch 28/200, Iteration 71/250, Loss: 0.0344\n",
      "Epoch 28/200, Iteration 72/250, Loss: 0.0338\n",
      "Epoch 28/200, Iteration 73/250, Loss: 0.0376\n",
      "Epoch 28/200, Iteration 74/250, Loss: 0.0180\n",
      "Epoch 28/200, Iteration 75/250, Loss: 0.0116\n",
      "Epoch 28/200, Iteration 76/250, Loss: 0.0151\n",
      "Epoch 28/200, Iteration 77/250, Loss: 0.0097\n",
      "Epoch 28/200, Iteration 78/250, Loss: 0.0112\n",
      "Epoch 28/200, Iteration 79/250, Loss: 0.0214\n",
      "Epoch 28/200, Iteration 80/250, Loss: 0.0129\n",
      "Epoch 28/200, Iteration 81/250, Loss: 0.0401\n",
      "Epoch 28/200, Iteration 82/250, Loss: 0.0222\n",
      "Epoch 28/200, Iteration 83/250, Loss: 0.0180\n",
      "Epoch 28/200, Iteration 84/250, Loss: 0.0151\n",
      "Epoch 28/200, Iteration 85/250, Loss: 0.0281\n",
      "Epoch 28/200, Iteration 86/250, Loss: 0.0156\n",
      "Epoch 28/200, Iteration 87/250, Loss: 0.0136\n",
      "Epoch 28/200, Iteration 88/250, Loss: 0.0176\n",
      "Epoch 28/200, Iteration 89/250, Loss: 0.0384\n",
      "Epoch 28/200, Iteration 90/250, Loss: 0.0215\n",
      "Epoch 28/200, Iteration 91/250, Loss: 0.0243\n",
      "Epoch 28/200, Iteration 92/250, Loss: 0.0277\n",
      "Epoch 28/200, Iteration 93/250, Loss: 0.0274\n",
      "Epoch 28/200, Iteration 94/250, Loss: 0.0141\n",
      "Epoch 28/200, Iteration 95/250, Loss: 0.0260\n",
      "Epoch 28/200, Iteration 96/250, Loss: 0.0116\n",
      "Epoch 28/200, Iteration 97/250, Loss: 0.0232\n",
      "Epoch 28/200, Iteration 98/250, Loss: 0.0164\n",
      "Epoch 28/200, Iteration 99/250, Loss: 0.0307\n",
      "Epoch 28/200, Iteration 100/250, Loss: 0.0347\n",
      "Epoch 28/200, Iteration 101/250, Loss: 0.0317\n",
      "Epoch 28/200, Iteration 102/250, Loss: 0.0220\n",
      "Epoch 28/200, Iteration 103/250, Loss: 0.0451\n",
      "Epoch 28/200, Iteration 104/250, Loss: 0.0208\n",
      "Epoch 28/200, Iteration 105/250, Loss: 0.0231\n",
      "Epoch 28/200, Iteration 106/250, Loss: 0.0246\n",
      "Epoch 28/200, Iteration 107/250, Loss: 0.0155\n",
      "Epoch 28/200, Iteration 108/250, Loss: 0.0130\n",
      "Epoch 28/200, Iteration 109/250, Loss: 0.0529\n",
      "Epoch 28/200, Iteration 110/250, Loss: 0.0218\n",
      "Epoch 28/200, Iteration 111/250, Loss: 0.0186\n",
      "Epoch 28/200, Iteration 112/250, Loss: 0.0131\n",
      "Epoch 28/200, Iteration 113/250, Loss: 0.0232\n",
      "Epoch 28/200, Iteration 114/250, Loss: 0.0189\n",
      "Epoch 28/200, Iteration 115/250, Loss: 0.0413\n",
      "Epoch 28/200, Iteration 116/250, Loss: 0.0519\n",
      "Epoch 28/200, Iteration 117/250, Loss: 0.0575\n",
      "Epoch 28/200, Iteration 118/250, Loss: 0.0217\n",
      "Epoch 28/200, Iteration 119/250, Loss: 0.0272\n",
      "Epoch 28/200, Iteration 120/250, Loss: 0.0133\n",
      "Epoch 28/200, Iteration 121/250, Loss: 0.0158\n",
      "Epoch 28/200, Iteration 122/250, Loss: 0.0318\n",
      "Epoch 28/200, Iteration 123/250, Loss: 0.0545\n",
      "Epoch 28/200, Iteration 124/250, Loss: 0.0201\n",
      "Epoch 28/200, Iteration 125/250, Loss: 0.0242\n",
      "Epoch 28/200, Iteration 126/250, Loss: 0.0223\n",
      "Epoch 28/200, Iteration 127/250, Loss: 0.0181\n",
      "Epoch 28/200, Iteration 128/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 129/250, Loss: 0.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Iteration 130/250, Loss: 0.0296\n",
      "Epoch 28/200, Iteration 131/250, Loss: 0.0321\n",
      "Epoch 28/200, Iteration 132/250, Loss: 0.0247\n",
      "Epoch 28/200, Iteration 133/250, Loss: 0.0147\n",
      "Epoch 28/200, Iteration 134/250, Loss: 0.0340\n",
      "Epoch 28/200, Iteration 135/250, Loss: 0.0422\n",
      "Epoch 28/200, Iteration 136/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 137/250, Loss: 0.0333\n",
      "Epoch 28/200, Iteration 138/250, Loss: 0.0327\n",
      "Epoch 28/200, Iteration 139/250, Loss: 0.0152\n",
      "Epoch 28/200, Iteration 140/250, Loss: 0.0177\n",
      "Epoch 28/200, Iteration 141/250, Loss: 0.0272\n",
      "Epoch 28/200, Iteration 142/250, Loss: 0.0239\n",
      "Epoch 28/200, Iteration 143/250, Loss: 0.0130\n",
      "Epoch 28/200, Iteration 144/250, Loss: 0.0249\n",
      "Epoch 28/200, Iteration 145/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 146/250, Loss: 0.0247\n",
      "Epoch 28/200, Iteration 147/250, Loss: 0.0366\n",
      "Epoch 28/200, Iteration 148/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 149/250, Loss: 0.0252\n",
      "Epoch 28/200, Iteration 150/250, Loss: 0.0239\n",
      "Epoch 28/200, Iteration 151/250, Loss: 0.0418\n",
      "Epoch 28/200, Iteration 152/250, Loss: 0.0278\n",
      "Epoch 28/200, Iteration 153/250, Loss: 0.0235\n",
      "Epoch 28/200, Iteration 154/250, Loss: 0.0208\n",
      "Epoch 28/200, Iteration 155/250, Loss: 0.0213\n",
      "Epoch 28/200, Iteration 156/250, Loss: 0.0113\n",
      "Epoch 28/200, Iteration 157/250, Loss: 0.0192\n",
      "Epoch 28/200, Iteration 158/250, Loss: 0.0366\n",
      "Epoch 28/200, Iteration 159/250, Loss: 0.0132\n",
      "Epoch 28/200, Iteration 160/250, Loss: 0.0165\n",
      "Epoch 28/200, Iteration 161/250, Loss: 0.0330\n",
      "Epoch 28/200, Iteration 162/250, Loss: 0.0403\n",
      "Epoch 28/200, Iteration 163/250, Loss: 0.0150\n",
      "Epoch 28/200, Iteration 164/250, Loss: 0.0174\n",
      "Epoch 28/200, Iteration 165/250, Loss: 0.0146\n",
      "Epoch 28/200, Iteration 166/250, Loss: 0.0247\n",
      "Epoch 28/200, Iteration 167/250, Loss: 0.0254\n",
      "Epoch 28/200, Iteration 168/250, Loss: 0.0122\n",
      "Epoch 28/200, Iteration 169/250, Loss: 0.0184\n",
      "Epoch 28/200, Iteration 170/250, Loss: 0.0348\n",
      "Epoch 28/200, Iteration 171/250, Loss: 0.0262\n",
      "Epoch 28/200, Iteration 172/250, Loss: 0.0152\n",
      "Epoch 28/200, Iteration 173/250, Loss: 0.0293\n",
      "Epoch 28/200, Iteration 174/250, Loss: 0.0694\n",
      "Epoch 28/200, Iteration 175/250, Loss: 0.0106\n",
      "Epoch 28/200, Iteration 176/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 177/250, Loss: 0.0200\n",
      "Epoch 28/200, Iteration 178/250, Loss: 0.0168\n",
      "Epoch 28/200, Iteration 179/250, Loss: 0.0155\n",
      "Epoch 28/200, Iteration 180/250, Loss: 0.0196\n",
      "Epoch 28/200, Iteration 181/250, Loss: 0.0297\n",
      "Epoch 28/200, Iteration 182/250, Loss: 0.0604\n",
      "Epoch 28/200, Iteration 183/250, Loss: 0.0255\n",
      "Epoch 28/200, Iteration 184/250, Loss: 0.0353\n",
      "Epoch 28/200, Iteration 185/250, Loss: 0.0145\n",
      "Epoch 28/200, Iteration 186/250, Loss: 0.0139\n",
      "Epoch 28/200, Iteration 187/250, Loss: 0.0198\n",
      "Epoch 28/200, Iteration 188/250, Loss: 0.0107\n",
      "Epoch 28/200, Iteration 189/250, Loss: 0.0315\n",
      "Epoch 28/200, Iteration 190/250, Loss: 0.0328\n",
      "Epoch 28/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 28/200, Iteration 192/250, Loss: 0.0162\n",
      "Epoch 28/200, Iteration 193/250, Loss: 0.0259\n",
      "Epoch 28/200, Iteration 194/250, Loss: 0.0284\n",
      "Epoch 28/200, Iteration 195/250, Loss: 0.0218\n",
      "Epoch 28/200, Iteration 196/250, Loss: 0.0267\n",
      "Epoch 28/200, Iteration 197/250, Loss: 0.0165\n",
      "Epoch 28/200, Iteration 198/250, Loss: 0.0255\n",
      "Epoch 28/200, Iteration 199/250, Loss: 0.0561\n",
      "Epoch 28/200, Iteration 200/250, Loss: 0.0248\n",
      "Epoch 28/200, Iteration 201/250, Loss: 0.0240\n",
      "Epoch 28/200, Iteration 202/250, Loss: 0.0160\n",
      "Epoch 28/200, Iteration 203/250, Loss: 0.0325\n",
      "Epoch 28/200, Iteration 204/250, Loss: 0.0222\n",
      "Epoch 28/200, Iteration 205/250, Loss: 0.0184\n",
      "Epoch 28/200, Iteration 206/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 207/250, Loss: 0.0382\n",
      "Epoch 28/200, Iteration 208/250, Loss: 0.0319\n",
      "Epoch 28/200, Iteration 209/250, Loss: 0.0293\n",
      "Epoch 28/200, Iteration 210/250, Loss: 0.0183\n",
      "Epoch 28/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 28/200, Iteration 212/250, Loss: 0.0259\n",
      "Epoch 28/200, Iteration 213/250, Loss: 0.0124\n",
      "Epoch 28/200, Iteration 214/250, Loss: 0.0099\n",
      "Epoch 28/200, Iteration 215/250, Loss: 0.0833\n",
      "Epoch 28/200, Iteration 216/250, Loss: 0.0384\n",
      "Epoch 28/200, Iteration 217/250, Loss: 0.0194\n",
      "Epoch 28/200, Iteration 218/250, Loss: 0.0208\n",
      "Epoch 28/200, Iteration 219/250, Loss: 0.0213\n",
      "Epoch 28/200, Iteration 220/250, Loss: 0.0212\n",
      "Epoch 28/200, Iteration 221/250, Loss: 0.0141\n",
      "Epoch 28/200, Iteration 222/250, Loss: 0.0264\n",
      "Epoch 28/200, Iteration 223/250, Loss: 0.1042\n",
      "Epoch 28/200, Iteration 224/250, Loss: 0.0566\n",
      "Epoch 28/200, Iteration 225/250, Loss: 0.0237\n",
      "Epoch 28/200, Iteration 226/250, Loss: 0.0306\n",
      "Epoch 28/200, Iteration 227/250, Loss: 0.0138\n",
      "Epoch 28/200, Iteration 228/250, Loss: 0.0119\n",
      "Epoch 28/200, Iteration 229/250, Loss: 0.0132\n",
      "Epoch 28/200, Iteration 230/250, Loss: 0.0139\n",
      "Epoch 28/200, Iteration 231/250, Loss: 0.0189\n",
      "Epoch 28/200, Iteration 232/250, Loss: 0.0288\n",
      "Epoch 28/200, Iteration 233/250, Loss: 0.0225\n",
      "Epoch 28/200, Iteration 234/250, Loss: 0.0196\n",
      "Epoch 28/200, Iteration 235/250, Loss: 0.0182\n",
      "Epoch 28/200, Iteration 236/250, Loss: 0.0293\n",
      "Epoch 28/200, Iteration 237/250, Loss: 0.0755\n",
      "Epoch 28/200, Iteration 238/250, Loss: 0.0171\n",
      "Epoch 28/200, Iteration 239/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 240/250, Loss: 0.0188\n",
      "Epoch 28/200, Iteration 241/250, Loss: 0.0142\n",
      "Epoch 28/200, Iteration 242/250, Loss: 0.0412\n",
      "Epoch 28/200, Iteration 243/250, Loss: 0.0892\n",
      "Epoch 28/200, Iteration 244/250, Loss: 0.0266\n",
      "Epoch 28/200, Iteration 245/250, Loss: 0.0301\n",
      "Epoch 28/200, Iteration 246/250, Loss: 0.0171\n",
      "Epoch 28/200, Iteration 247/250, Loss: 0.0395\n",
      "Epoch 28/200, Iteration 248/250, Loss: 0.0534\n",
      "Epoch 28/200, Iteration 249/250, Loss: 0.0411\n",
      "Epoch 28/200, Iteration 250/250, Loss: 0.0337\n",
      "Train Error: \n",
      " Accuracy: 63.29%, Avg loss: 0.012863, MRE: 0.946416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.012740, MRE: 1.129540 \n",
      "\n",
      "Epoch 29/200, Iteration 1/250, Loss: 0.0219\n",
      "Epoch 29/200, Iteration 2/250, Loss: 0.0159\n",
      "Epoch 29/200, Iteration 3/250, Loss: 0.0491\n",
      "Epoch 29/200, Iteration 4/250, Loss: 0.0244\n",
      "Epoch 29/200, Iteration 5/250, Loss: 0.0306\n",
      "Epoch 29/200, Iteration 6/250, Loss: 0.0265\n",
      "Epoch 29/200, Iteration 7/250, Loss: 0.0272\n",
      "Epoch 29/200, Iteration 8/250, Loss: 0.0421\n",
      "Epoch 29/200, Iteration 9/250, Loss: 0.0494\n",
      "Epoch 29/200, Iteration 10/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 11/250, Loss: 0.0126\n",
      "Epoch 29/200, Iteration 12/250, Loss: 0.0235\n",
      "Epoch 29/200, Iteration 13/250, Loss: 0.0448\n",
      "Epoch 29/200, Iteration 14/250, Loss: 0.0199\n",
      "Epoch 29/200, Iteration 15/250, Loss: 0.0687\n",
      "Epoch 29/200, Iteration 16/250, Loss: 0.0222\n",
      "Epoch 29/200, Iteration 17/250, Loss: 0.0517\n",
      "Epoch 29/200, Iteration 18/250, Loss: 0.0446\n",
      "Epoch 29/200, Iteration 19/250, Loss: 0.0140\n",
      "Epoch 29/200, Iteration 20/250, Loss: 0.0191\n",
      "Epoch 29/200, Iteration 21/250, Loss: 0.0302\n",
      "Epoch 29/200, Iteration 22/250, Loss: 0.0392\n",
      "Epoch 29/200, Iteration 23/250, Loss: 0.0275\n",
      "Epoch 29/200, Iteration 24/250, Loss: 0.0474\n",
      "Epoch 29/200, Iteration 25/250, Loss: 0.0170\n",
      "Epoch 29/200, Iteration 26/250, Loss: 0.0199\n",
      "Epoch 29/200, Iteration 27/250, Loss: 0.0607\n",
      "Epoch 29/200, Iteration 28/250, Loss: 0.0168\n",
      "Epoch 29/200, Iteration 29/250, Loss: 0.0786\n",
      "Epoch 29/200, Iteration 30/250, Loss: 0.0146\n",
      "Epoch 29/200, Iteration 31/250, Loss: 0.0259\n",
      "Epoch 29/200, Iteration 32/250, Loss: 0.0256\n",
      "Epoch 29/200, Iteration 33/250, Loss: 0.0296\n",
      "Epoch 29/200, Iteration 34/250, Loss: 0.0186\n",
      "Epoch 29/200, Iteration 35/250, Loss: 0.0317\n",
      "Epoch 29/200, Iteration 36/250, Loss: 0.0264\n",
      "Epoch 29/200, Iteration 37/250, Loss: 0.0361\n",
      "Epoch 29/200, Iteration 38/250, Loss: 0.0285\n",
      "Epoch 29/200, Iteration 39/250, Loss: 0.0260\n",
      "Epoch 29/200, Iteration 40/250, Loss: 0.0496\n",
      "Epoch 29/200, Iteration 41/250, Loss: 0.0240\n",
      "Epoch 29/200, Iteration 42/250, Loss: 0.0298\n",
      "Epoch 29/200, Iteration 43/250, Loss: 0.0157\n",
      "Epoch 29/200, Iteration 44/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 45/250, Loss: 0.0182\n",
      "Epoch 29/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 29/200, Iteration 47/250, Loss: 0.0276\n",
      "Epoch 29/200, Iteration 48/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 49/250, Loss: 0.0241\n",
      "Epoch 29/200, Iteration 50/250, Loss: 0.0185\n",
      "Epoch 29/200, Iteration 51/250, Loss: 0.0189\n",
      "Epoch 29/200, Iteration 52/250, Loss: 0.0224\n",
      "Epoch 29/200, Iteration 53/250, Loss: 0.0130\n",
      "Epoch 29/200, Iteration 54/250, Loss: 0.0272\n",
      "Epoch 29/200, Iteration 55/250, Loss: 0.0103\n",
      "Epoch 29/200, Iteration 56/250, Loss: 0.0087\n",
      "Epoch 29/200, Iteration 57/250, Loss: 0.0506\n",
      "Epoch 29/200, Iteration 58/250, Loss: 0.0404\n",
      "Epoch 29/200, Iteration 59/250, Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Iteration 60/250, Loss: 0.0170\n",
      "Epoch 29/200, Iteration 61/250, Loss: 0.0564\n",
      "Epoch 29/200, Iteration 62/250, Loss: 0.0279\n",
      "Epoch 29/200, Iteration 63/250, Loss: 0.0253\n",
      "Epoch 29/200, Iteration 64/250, Loss: 0.0354\n",
      "Epoch 29/200, Iteration 65/250, Loss: 0.0165\n",
      "Epoch 29/200, Iteration 66/250, Loss: 0.0278\n",
      "Epoch 29/200, Iteration 67/250, Loss: 0.0174\n",
      "Epoch 29/200, Iteration 68/250, Loss: 0.0227\n",
      "Epoch 29/200, Iteration 69/250, Loss: 0.0325\n",
      "Epoch 29/200, Iteration 70/250, Loss: 0.0167\n",
      "Epoch 29/200, Iteration 71/250, Loss: 0.0146\n",
      "Epoch 29/200, Iteration 72/250, Loss: 0.0387\n",
      "Epoch 29/200, Iteration 73/250, Loss: 0.0235\n",
      "Epoch 29/200, Iteration 74/250, Loss: 0.0342\n",
      "Epoch 29/200, Iteration 75/250, Loss: 0.0093\n",
      "Epoch 29/200, Iteration 76/250, Loss: 0.0194\n",
      "Epoch 29/200, Iteration 77/250, Loss: 0.0131\n",
      "Epoch 29/200, Iteration 78/250, Loss: 0.0238\n",
      "Epoch 29/200, Iteration 79/250, Loss: 0.0117\n",
      "Epoch 29/200, Iteration 80/250, Loss: 0.0312\n",
      "Epoch 29/200, Iteration 81/250, Loss: 0.0314\n",
      "Epoch 29/200, Iteration 82/250, Loss: 0.0528\n",
      "Epoch 29/200, Iteration 83/250, Loss: 0.0374\n",
      "Epoch 29/200, Iteration 84/250, Loss: 0.0158\n",
      "Epoch 29/200, Iteration 85/250, Loss: 0.0200\n",
      "Epoch 29/200, Iteration 86/250, Loss: 0.0193\n",
      "Epoch 29/200, Iteration 87/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 88/250, Loss: 0.0115\n",
      "Epoch 29/200, Iteration 89/250, Loss: 0.0454\n",
      "Epoch 29/200, Iteration 90/250, Loss: 0.0290\n",
      "Epoch 29/200, Iteration 91/250, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 92/250, Loss: 0.0193\n",
      "Epoch 29/200, Iteration 93/250, Loss: 0.0389\n",
      "Epoch 29/200, Iteration 94/250, Loss: 0.0277\n",
      "Epoch 29/200, Iteration 95/250, Loss: 0.0146\n",
      "Epoch 29/200, Iteration 96/250, Loss: 0.0400\n",
      "Epoch 29/200, Iteration 97/250, Loss: 0.0390\n",
      "Epoch 29/200, Iteration 98/250, Loss: 0.0131\n",
      "Epoch 29/200, Iteration 99/250, Loss: 0.0151\n",
      "Epoch 29/200, Iteration 100/250, Loss: 0.0567\n",
      "Epoch 29/200, Iteration 101/250, Loss: 0.0630\n",
      "Epoch 29/200, Iteration 102/250, Loss: 0.0447\n",
      "Epoch 29/200, Iteration 103/250, Loss: 0.0173\n",
      "Epoch 29/200, Iteration 104/250, Loss: 0.0258\n",
      "Epoch 29/200, Iteration 105/250, Loss: 0.0268\n",
      "Epoch 29/200, Iteration 106/250, Loss: 0.0285\n",
      "Epoch 29/200, Iteration 107/250, Loss: 0.0277\n",
      "Epoch 29/200, Iteration 108/250, Loss: 0.0191\n",
      "Epoch 29/200, Iteration 109/250, Loss: 0.0475\n",
      "Epoch 29/200, Iteration 110/250, Loss: 0.0342\n",
      "Epoch 29/200, Iteration 111/250, Loss: 0.0463\n",
      "Epoch 29/200, Iteration 112/250, Loss: 0.0440\n",
      "Epoch 29/200, Iteration 113/250, Loss: 0.0214\n",
      "Epoch 29/200, Iteration 114/250, Loss: 0.0217\n",
      "Epoch 29/200, Iteration 115/250, Loss: 0.0155\n",
      "Epoch 29/200, Iteration 116/250, Loss: 0.0525\n",
      "Epoch 29/200, Iteration 117/250, Loss: 0.0149\n",
      "Epoch 29/200, Iteration 118/250, Loss: 0.0305\n",
      "Epoch 29/200, Iteration 119/250, Loss: 0.0239\n",
      "Epoch 29/200, Iteration 120/250, Loss: 0.0544\n",
      "Epoch 29/200, Iteration 121/250, Loss: 0.0301\n",
      "Epoch 29/200, Iteration 122/250, Loss: 0.0300\n",
      "Epoch 29/200, Iteration 123/250, Loss: 0.0245\n",
      "Epoch 29/200, Iteration 124/250, Loss: 0.0228\n",
      "Epoch 29/200, Iteration 125/250, Loss: 0.0309\n",
      "Epoch 29/200, Iteration 126/250, Loss: 0.0439\n",
      "Epoch 29/200, Iteration 127/250, Loss: 0.0249\n",
      "Epoch 29/200, Iteration 128/250, Loss: 0.0457\n",
      "Epoch 29/200, Iteration 129/250, Loss: 0.0603\n",
      "Epoch 29/200, Iteration 130/250, Loss: 0.0290\n",
      "Epoch 29/200, Iteration 131/250, Loss: 0.0276\n",
      "Epoch 29/200, Iteration 132/250, Loss: 0.0301\n",
      "Epoch 29/200, Iteration 133/250, Loss: 0.0323\n",
      "Epoch 29/200, Iteration 134/250, Loss: 0.0231\n",
      "Epoch 29/200, Iteration 135/250, Loss: 0.0396\n",
      "Epoch 29/200, Iteration 136/250, Loss: 0.0147\n",
      "Epoch 29/200, Iteration 137/250, Loss: 0.0642\n",
      "Epoch 29/200, Iteration 138/250, Loss: 0.0191\n",
      "Epoch 29/200, Iteration 139/250, Loss: 0.0821\n",
      "Epoch 29/200, Iteration 140/250, Loss: 0.0453\n",
      "Epoch 29/200, Iteration 141/250, Loss: 0.0189\n",
      "Epoch 29/200, Iteration 142/250, Loss: 0.0652\n",
      "Epoch 29/200, Iteration 143/250, Loss: 0.0208\n",
      "Epoch 29/200, Iteration 144/250, Loss: 0.0446\n",
      "Epoch 29/200, Iteration 145/250, Loss: 0.0317\n",
      "Epoch 29/200, Iteration 146/250, Loss: 0.0465\n",
      "Epoch 29/200, Iteration 147/250, Loss: 0.0484\n",
      "Epoch 29/200, Iteration 148/250, Loss: 0.0407\n",
      "Epoch 29/200, Iteration 149/250, Loss: 0.0261\n",
      "Epoch 29/200, Iteration 150/250, Loss: 0.0166\n",
      "Epoch 29/200, Iteration 151/250, Loss: 0.0273\n",
      "Epoch 29/200, Iteration 152/250, Loss: 0.0334\n",
      "Epoch 29/200, Iteration 153/250, Loss: 0.0203\n",
      "Epoch 29/200, Iteration 154/250, Loss: 0.0100\n",
      "Epoch 29/200, Iteration 155/250, Loss: 0.0472\n",
      "Epoch 29/200, Iteration 156/250, Loss: 0.0234\n",
      "Epoch 29/200, Iteration 157/250, Loss: 0.0374\n",
      "Epoch 29/200, Iteration 158/250, Loss: 0.0268\n",
      "Epoch 29/200, Iteration 159/250, Loss: 0.0309\n",
      "Epoch 29/200, Iteration 160/250, Loss: 0.0474\n",
      "Epoch 29/200, Iteration 161/250, Loss: 0.0264\n",
      "Epoch 29/200, Iteration 162/250, Loss: 0.0195\n",
      "Epoch 29/200, Iteration 163/250, Loss: 0.0282\n",
      "Epoch 29/200, Iteration 164/250, Loss: 0.0543\n",
      "Epoch 29/200, Iteration 165/250, Loss: 0.0544\n",
      "Epoch 29/200, Iteration 166/250, Loss: 0.0601\n",
      "Epoch 29/200, Iteration 167/250, Loss: 0.0305\n",
      "Epoch 29/200, Iteration 168/250, Loss: 0.0336\n",
      "Epoch 29/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 29/200, Iteration 170/250, Loss: 0.0476\n",
      "Epoch 29/200, Iteration 171/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 172/250, Loss: 0.0462\n",
      "Epoch 29/200, Iteration 173/250, Loss: 0.0202\n",
      "Epoch 29/200, Iteration 174/250, Loss: 0.0304\n",
      "Epoch 29/200, Iteration 175/250, Loss: 0.0147\n",
      "Epoch 29/200, Iteration 176/250, Loss: 0.0229\n",
      "Epoch 29/200, Iteration 177/250, Loss: 0.0102\n",
      "Epoch 29/200, Iteration 178/250, Loss: 0.0352\n",
      "Epoch 29/200, Iteration 179/250, Loss: 0.0289\n",
      "Epoch 29/200, Iteration 180/250, Loss: 0.0281\n",
      "Epoch 29/200, Iteration 181/250, Loss: 0.0176\n",
      "Epoch 29/200, Iteration 182/250, Loss: 0.0130\n",
      "Epoch 29/200, Iteration 183/250, Loss: 0.0156\n",
      "Epoch 29/200, Iteration 184/250, Loss: 0.0223\n",
      "Epoch 29/200, Iteration 185/250, Loss: 0.0383\n",
      "Epoch 29/200, Iteration 186/250, Loss: 0.0104\n",
      "Epoch 29/200, Iteration 187/250, Loss: 0.0690\n",
      "Epoch 29/200, Iteration 188/250, Loss: 0.0338\n",
      "Epoch 29/200, Iteration 189/250, Loss: 0.0447\n",
      "Epoch 29/200, Iteration 190/250, Loss: 0.0663\n",
      "Epoch 29/200, Iteration 191/250, Loss: 0.0371\n",
      "Epoch 29/200, Iteration 192/250, Loss: 0.0141\n",
      "Epoch 29/200, Iteration 193/250, Loss: 0.0458\n",
      "Epoch 29/200, Iteration 194/250, Loss: 0.0154\n",
      "Epoch 29/200, Iteration 195/250, Loss: 0.0143\n",
      "Epoch 29/200, Iteration 196/250, Loss: 0.0142\n",
      "Epoch 29/200, Iteration 197/250, Loss: 0.0206\n",
      "Epoch 29/200, Iteration 198/250, Loss: 0.0399\n",
      "Epoch 29/200, Iteration 199/250, Loss: 0.0168\n",
      "Epoch 29/200, Iteration 200/250, Loss: 0.0192\n",
      "Epoch 29/200, Iteration 201/250, Loss: 0.0094\n",
      "Epoch 29/200, Iteration 202/250, Loss: 0.0230\n",
      "Epoch 29/200, Iteration 203/250, Loss: 0.0266\n",
      "Epoch 29/200, Iteration 204/250, Loss: 0.0228\n",
      "Epoch 29/200, Iteration 205/250, Loss: 0.0225\n",
      "Epoch 29/200, Iteration 206/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 207/250, Loss: 0.0361\n",
      "Epoch 29/200, Iteration 208/250, Loss: 0.0428\n",
      "Epoch 29/200, Iteration 209/250, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 210/250, Loss: 0.0156\n",
      "Epoch 29/200, Iteration 211/250, Loss: 0.0224\n",
      "Epoch 29/200, Iteration 212/250, Loss: 0.0381\n",
      "Epoch 29/200, Iteration 213/250, Loss: 0.0271\n",
      "Epoch 29/200, Iteration 214/250, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 215/250, Loss: 0.0213\n",
      "Epoch 29/200, Iteration 216/250, Loss: 0.0710\n",
      "Epoch 29/200, Iteration 217/250, Loss: 0.0335\n",
      "Epoch 29/200, Iteration 218/250, Loss: 0.0777\n",
      "Epoch 29/200, Iteration 219/250, Loss: 0.0408\n",
      "Epoch 29/200, Iteration 220/250, Loss: 0.0230\n",
      "Epoch 29/200, Iteration 221/250, Loss: 0.0389\n",
      "Epoch 29/200, Iteration 222/250, Loss: 0.0154\n",
      "Epoch 29/200, Iteration 223/250, Loss: 0.0620\n",
      "Epoch 29/200, Iteration 224/250, Loss: 0.0418\n",
      "Epoch 29/200, Iteration 225/250, Loss: 0.0198\n",
      "Epoch 29/200, Iteration 226/250, Loss: 0.0400\n",
      "Epoch 29/200, Iteration 227/250, Loss: 0.0235\n",
      "Epoch 29/200, Iteration 228/250, Loss: 0.0191\n",
      "Epoch 29/200, Iteration 229/250, Loss: 0.0200\n",
      "Epoch 29/200, Iteration 230/250, Loss: 0.0509\n",
      "Epoch 29/200, Iteration 231/250, Loss: 0.0393\n",
      "Epoch 29/200, Iteration 232/250, Loss: 0.1259\n",
      "Epoch 29/200, Iteration 233/250, Loss: 0.0494\n",
      "Epoch 29/200, Iteration 234/250, Loss: 0.2027\n",
      "Epoch 29/200, Iteration 235/250, Loss: 0.0213\n",
      "Epoch 29/200, Iteration 236/250, Loss: 0.0541\n",
      "Epoch 29/200, Iteration 237/250, Loss: 0.0278\n",
      "Epoch 29/200, Iteration 238/250, Loss: 0.0846\n",
      "Epoch 29/200, Iteration 239/250, Loss: 0.1917\n",
      "Epoch 29/200, Iteration 240/250, Loss: 0.0757\n",
      "Epoch 29/200, Iteration 241/250, Loss: 0.0625\n",
      "Epoch 29/200, Iteration 242/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 243/250, Loss: 0.0296\n",
      "Epoch 29/200, Iteration 244/250, Loss: 0.0403\n",
      "Epoch 29/200, Iteration 245/250, Loss: 0.1400\n",
      "Epoch 29/200, Iteration 246/250, Loss: 0.3176\n",
      "Epoch 29/200, Iteration 247/250, Loss: 0.0893\n",
      "Epoch 29/200, Iteration 248/250, Loss: 0.0723\n",
      "Epoch 29/200, Iteration 249/250, Loss: 0.0342\n",
      "Epoch 29/200, Iteration 250/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.023528, MRE: 1.600298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.024110, MRE: 3.765808 \n",
      "\n",
      "Epoch 30/200, Iteration 1/250, Loss: 0.0487\n",
      "Epoch 30/200, Iteration 2/250, Loss: 0.2851\n",
      "Epoch 30/200, Iteration 3/250, Loss: 0.0152\n",
      "Epoch 30/200, Iteration 4/250, Loss: 0.0721\n",
      "Epoch 30/200, Iteration 5/250, Loss: 0.1406\n",
      "Epoch 30/200, Iteration 6/250, Loss: 0.0548\n",
      "Epoch 30/200, Iteration 7/250, Loss: 0.0727\n",
      "Epoch 30/200, Iteration 8/250, Loss: 0.0593\n",
      "Epoch 30/200, Iteration 9/250, Loss: 0.0904\n",
      "Epoch 30/200, Iteration 10/250, Loss: 0.0323\n",
      "Epoch 30/200, Iteration 11/250, Loss: 0.0671\n",
      "Epoch 30/200, Iteration 12/250, Loss: 0.2599\n",
      "Epoch 30/200, Iteration 13/250, Loss: 0.0759\n",
      "Epoch 30/200, Iteration 14/250, Loss: 0.0454\n",
      "Epoch 30/200, Iteration 15/250, Loss: 0.0970\n",
      "Epoch 30/200, Iteration 16/250, Loss: 0.1422\n",
      "Epoch 30/200, Iteration 17/250, Loss: 0.2139\n",
      "Epoch 30/200, Iteration 18/250, Loss: 0.0343\n",
      "Epoch 30/200, Iteration 19/250, Loss: 0.0660\n",
      "Epoch 30/200, Iteration 20/250, Loss: 0.2403\n",
      "Epoch 30/200, Iteration 21/250, Loss: 0.0908\n",
      "Epoch 30/200, Iteration 22/250, Loss: 0.0358\n",
      "Epoch 30/200, Iteration 23/250, Loss: 0.2409\n",
      "Epoch 30/200, Iteration 24/250, Loss: 0.0858\n",
      "Epoch 30/200, Iteration 25/250, Loss: 0.0752\n",
      "Epoch 30/200, Iteration 26/250, Loss: 0.1429\n",
      "Epoch 30/200, Iteration 27/250, Loss: 0.0532\n",
      "Epoch 30/200, Iteration 28/250, Loss: 0.1177\n",
      "Epoch 30/200, Iteration 29/250, Loss: 0.0864\n",
      "Epoch 30/200, Iteration 30/250, Loss: 0.1151\n",
      "Epoch 30/200, Iteration 31/250, Loss: 0.0358\n",
      "Epoch 30/200, Iteration 32/250, Loss: 0.1164\n",
      "Epoch 30/200, Iteration 33/250, Loss: 0.0250\n",
      "Epoch 30/200, Iteration 34/250, Loss: 0.0562\n",
      "Epoch 30/200, Iteration 35/250, Loss: 0.0353\n",
      "Epoch 30/200, Iteration 36/250, Loss: 0.0344\n",
      "Epoch 30/200, Iteration 37/250, Loss: 0.0186\n",
      "Epoch 30/200, Iteration 38/250, Loss: 0.0748\n",
      "Epoch 30/200, Iteration 39/250, Loss: 0.0363\n",
      "Epoch 30/200, Iteration 40/250, Loss: 0.0835\n",
      "Epoch 30/200, Iteration 41/250, Loss: 0.0274\n",
      "Epoch 30/200, Iteration 42/250, Loss: 0.0764\n",
      "Epoch 30/200, Iteration 43/250, Loss: 0.0481\n",
      "Epoch 30/200, Iteration 44/250, Loss: 0.0384\n",
      "Epoch 30/200, Iteration 45/250, Loss: 0.0448\n",
      "Epoch 30/200, Iteration 46/250, Loss: 0.0554\n",
      "Epoch 30/200, Iteration 47/250, Loss: 0.0753\n",
      "Epoch 30/200, Iteration 48/250, Loss: 0.0259\n",
      "Epoch 30/200, Iteration 49/250, Loss: 0.0544\n",
      "Epoch 30/200, Iteration 50/250, Loss: 0.0650\n",
      "Epoch 30/200, Iteration 51/250, Loss: 0.0645\n",
      "Epoch 30/200, Iteration 52/250, Loss: 0.0999\n",
      "Epoch 30/200, Iteration 53/250, Loss: 0.0357\n",
      "Epoch 30/200, Iteration 54/250, Loss: 0.0375\n",
      "Epoch 30/200, Iteration 55/250, Loss: 0.0259\n",
      "Epoch 30/200, Iteration 56/250, Loss: 0.0462\n",
      "Epoch 30/200, Iteration 57/250, Loss: 0.0184\n",
      "Epoch 30/200, Iteration 58/250, Loss: 0.0526\n",
      "Epoch 30/200, Iteration 59/250, Loss: 0.0482\n",
      "Epoch 30/200, Iteration 60/250, Loss: 0.0534\n",
      "Epoch 30/200, Iteration 61/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 62/250, Loss: 0.0205\n",
      "Epoch 30/200, Iteration 63/250, Loss: 0.0419\n",
      "Epoch 30/200, Iteration 64/250, Loss: 0.0353\n",
      "Epoch 30/200, Iteration 65/250, Loss: 0.0266\n",
      "Epoch 30/200, Iteration 66/250, Loss: 0.0170\n",
      "Epoch 30/200, Iteration 67/250, Loss: 0.0243\n",
      "Epoch 30/200, Iteration 68/250, Loss: 0.0175\n",
      "Epoch 30/200, Iteration 69/250, Loss: 0.0370\n",
      "Epoch 30/200, Iteration 70/250, Loss: 0.0262\n",
      "Epoch 30/200, Iteration 71/250, Loss: 0.0216\n",
      "Epoch 30/200, Iteration 72/250, Loss: 0.0211\n",
      "Epoch 30/200, Iteration 73/250, Loss: 0.0235\n",
      "Epoch 30/200, Iteration 74/250, Loss: 0.0381\n",
      "Epoch 30/200, Iteration 75/250, Loss: 0.0227\n",
      "Epoch 30/200, Iteration 76/250, Loss: 0.0163\n",
      "Epoch 30/200, Iteration 77/250, Loss: 0.0351\n",
      "Epoch 30/200, Iteration 78/250, Loss: 0.0224\n",
      "Epoch 30/200, Iteration 79/250, Loss: 0.0246\n",
      "Epoch 30/200, Iteration 80/250, Loss: 0.0124\n",
      "Epoch 30/200, Iteration 81/250, Loss: 0.0439\n",
      "Epoch 30/200, Iteration 82/250, Loss: 0.0354\n",
      "Epoch 30/200, Iteration 83/250, Loss: 0.0187\n",
      "Epoch 30/200, Iteration 84/250, Loss: 0.0273\n",
      "Epoch 30/200, Iteration 85/250, Loss: 0.0240\n",
      "Epoch 30/200, Iteration 86/250, Loss: 0.0266\n",
      "Epoch 30/200, Iteration 87/250, Loss: 0.0286\n",
      "Epoch 30/200, Iteration 88/250, Loss: 0.0305\n",
      "Epoch 30/200, Iteration 89/250, Loss: 0.0214\n",
      "Epoch 30/200, Iteration 90/250, Loss: 0.0198\n",
      "Epoch 30/200, Iteration 91/250, Loss: 0.0352\n",
      "Epoch 30/200, Iteration 92/250, Loss: 0.0308\n",
      "Epoch 30/200, Iteration 93/250, Loss: 0.0348\n",
      "Epoch 30/200, Iteration 94/250, Loss: 0.0164\n",
      "Epoch 30/200, Iteration 95/250, Loss: 0.0172\n",
      "Epoch 30/200, Iteration 96/250, Loss: 0.0158\n",
      "Epoch 30/200, Iteration 97/250, Loss: 0.0129\n",
      "Epoch 30/200, Iteration 98/250, Loss: 0.0319\n",
      "Epoch 30/200, Iteration 99/250, Loss: 0.0374\n",
      "Epoch 30/200, Iteration 100/250, Loss: 0.0211\n",
      "Epoch 30/200, Iteration 101/250, Loss: 0.0278\n",
      "Epoch 30/200, Iteration 102/250, Loss: 0.0112\n",
      "Epoch 30/200, Iteration 103/250, Loss: 0.0562\n",
      "Epoch 30/200, Iteration 104/250, Loss: 0.0351\n",
      "Epoch 30/200, Iteration 105/250, Loss: 0.0173\n",
      "Epoch 30/200, Iteration 106/250, Loss: 0.0137\n",
      "Epoch 30/200, Iteration 107/250, Loss: 0.0130\n",
      "Epoch 30/200, Iteration 108/250, Loss: 0.0136\n",
      "Epoch 30/200, Iteration 109/250, Loss: 0.0130\n",
      "Epoch 30/200, Iteration 110/250, Loss: 0.0258\n",
      "Epoch 30/200, Iteration 111/250, Loss: 0.0121\n",
      "Epoch 30/200, Iteration 112/250, Loss: 0.0318\n",
      "Epoch 30/200, Iteration 113/250, Loss: 0.0134\n",
      "Epoch 30/200, Iteration 114/250, Loss: 0.0227\n",
      "Epoch 30/200, Iteration 115/250, Loss: 0.0114\n",
      "Epoch 30/200, Iteration 116/250, Loss: 0.0240\n",
      "Epoch 30/200, Iteration 117/250, Loss: 0.0265\n",
      "Epoch 30/200, Iteration 118/250, Loss: 0.0088\n",
      "Epoch 30/200, Iteration 119/250, Loss: 0.0354\n",
      "Epoch 30/200, Iteration 120/250, Loss: 0.0133\n",
      "Epoch 30/200, Iteration 121/250, Loss: 0.0098\n",
      "Epoch 30/200, Iteration 122/250, Loss: 0.0325\n",
      "Epoch 30/200, Iteration 123/250, Loss: 0.0206\n",
      "Epoch 30/200, Iteration 124/250, Loss: 0.0498\n",
      "Epoch 30/200, Iteration 125/250, Loss: 0.0218\n",
      "Epoch 30/200, Iteration 126/250, Loss: 0.0209\n",
      "Epoch 30/200, Iteration 127/250, Loss: 0.0175\n",
      "Epoch 30/200, Iteration 128/250, Loss: 0.0154\n",
      "Epoch 30/200, Iteration 129/250, Loss: 0.0544\n",
      "Epoch 30/200, Iteration 130/250, Loss: 0.0353\n",
      "Epoch 30/200, Iteration 131/250, Loss: 0.0177\n",
      "Epoch 30/200, Iteration 132/250, Loss: 0.0256\n",
      "Epoch 30/200, Iteration 133/250, Loss: 0.0500\n",
      "Epoch 30/200, Iteration 134/250, Loss: 0.0198\n",
      "Epoch 30/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 30/200, Iteration 136/250, Loss: 0.0137\n",
      "Epoch 30/200, Iteration 137/250, Loss: 0.0186\n",
      "Epoch 30/200, Iteration 138/250, Loss: 0.0137\n",
      "Epoch 30/200, Iteration 139/250, Loss: 0.0316\n",
      "Epoch 30/200, Iteration 140/250, Loss: 0.0110\n",
      "Epoch 30/200, Iteration 141/250, Loss: 0.0112\n",
      "Epoch 30/200, Iteration 142/250, Loss: 0.0152\n",
      "Epoch 30/200, Iteration 143/250, Loss: 0.0119\n",
      "Epoch 30/200, Iteration 144/250, Loss: 0.0345\n",
      "Epoch 30/200, Iteration 145/250, Loss: 0.0194\n",
      "Epoch 30/200, Iteration 146/250, Loss: 0.0139\n",
      "Epoch 30/200, Iteration 147/250, Loss: 0.0095\n",
      "Epoch 30/200, Iteration 148/250, Loss: 0.0169\n",
      "Epoch 30/200, Iteration 149/250, Loss: 0.0187\n",
      "Epoch 30/200, Iteration 150/250, Loss: 0.0375\n",
      "Epoch 30/200, Iteration 151/250, Loss: 0.0127\n",
      "Epoch 30/200, Iteration 152/250, Loss: 0.0118\n",
      "Epoch 30/200, Iteration 153/250, Loss: 0.0157\n",
      "Epoch 30/200, Iteration 154/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 155/250, Loss: 0.0338\n",
      "Epoch 30/200, Iteration 156/250, Loss: 0.0225\n",
      "Epoch 30/200, Iteration 157/250, Loss: 0.0233\n",
      "Epoch 30/200, Iteration 158/250, Loss: 0.0198\n",
      "Epoch 30/200, Iteration 159/250, Loss: 0.0312\n",
      "Epoch 30/200, Iteration 160/250, Loss: 0.0192\n",
      "Epoch 30/200, Iteration 161/250, Loss: 0.0186\n",
      "Epoch 30/200, Iteration 162/250, Loss: 0.0166\n",
      "Epoch 30/200, Iteration 163/250, Loss: 0.0232\n",
      "Epoch 30/200, Iteration 164/250, Loss: 0.0162\n",
      "Epoch 30/200, Iteration 165/250, Loss: 0.0162\n",
      "Epoch 30/200, Iteration 166/250, Loss: 0.0169\n",
      "Epoch 30/200, Iteration 167/250, Loss: 0.0232\n",
      "Epoch 30/200, Iteration 168/250, Loss: 0.0177\n",
      "Epoch 30/200, Iteration 169/250, Loss: 0.0424\n",
      "Epoch 30/200, Iteration 170/250, Loss: 0.0415\n",
      "Epoch 30/200, Iteration 171/250, Loss: 0.0130\n",
      "Epoch 30/200, Iteration 172/250, Loss: 0.0349\n",
      "Epoch 30/200, Iteration 173/250, Loss: 0.0151\n",
      "Epoch 30/200, Iteration 174/250, Loss: 0.0249\n",
      "Epoch 30/200, Iteration 175/250, Loss: 0.0099\n",
      "Epoch 30/200, Iteration 176/250, Loss: 0.0117\n",
      "Epoch 30/200, Iteration 177/250, Loss: 0.0332\n",
      "Epoch 30/200, Iteration 178/250, Loss: 0.0094\n",
      "Epoch 30/200, Iteration 179/250, Loss: 0.0182\n",
      "Epoch 30/200, Iteration 180/250, Loss: 0.0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Iteration 181/250, Loss: 0.0161\n",
      "Epoch 30/200, Iteration 182/250, Loss: 0.0229\n",
      "Epoch 30/200, Iteration 183/250, Loss: 0.0528\n",
      "Epoch 30/200, Iteration 184/250, Loss: 0.0391\n",
      "Epoch 30/200, Iteration 185/250, Loss: 0.0487\n",
      "Epoch 30/200, Iteration 186/250, Loss: 0.0123\n",
      "Epoch 30/200, Iteration 187/250, Loss: 0.0184\n",
      "Epoch 30/200, Iteration 188/250, Loss: 0.0166\n",
      "Epoch 30/200, Iteration 189/250, Loss: 0.0120\n",
      "Epoch 30/200, Iteration 190/250, Loss: 0.0254\n",
      "Epoch 30/200, Iteration 191/250, Loss: 0.0114\n",
      "Epoch 30/200, Iteration 192/250, Loss: 0.0234\n",
      "Epoch 30/200, Iteration 193/250, Loss: 0.0239\n",
      "Epoch 30/200, Iteration 194/250, Loss: 0.0182\n",
      "Epoch 30/200, Iteration 195/250, Loss: 0.0333\n",
      "Epoch 30/200, Iteration 196/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 197/250, Loss: 0.0081\n",
      "Epoch 30/200, Iteration 198/250, Loss: 0.0104\n",
      "Epoch 30/200, Iteration 199/250, Loss: 0.0105\n",
      "Epoch 30/200, Iteration 200/250, Loss: 0.0177\n",
      "Epoch 30/200, Iteration 201/250, Loss: 0.0216\n",
      "Epoch 30/200, Iteration 202/250, Loss: 0.0508\n",
      "Epoch 30/200, Iteration 203/250, Loss: 0.0219\n",
      "Epoch 30/200, Iteration 204/250, Loss: 0.0376\n",
      "Epoch 30/200, Iteration 205/250, Loss: 0.0293\n",
      "Epoch 30/200, Iteration 206/250, Loss: 0.0586\n",
      "Epoch 30/200, Iteration 207/250, Loss: 0.0301\n",
      "Epoch 30/200, Iteration 208/250, Loss: 0.0276\n",
      "Epoch 30/200, Iteration 209/250, Loss: 0.0208\n",
      "Epoch 30/200, Iteration 210/250, Loss: 0.0349\n",
      "Epoch 30/200, Iteration 211/250, Loss: 0.0399\n",
      "Epoch 30/200, Iteration 212/250, Loss: 0.0242\n",
      "Epoch 30/200, Iteration 213/250, Loss: 0.0475\n",
      "Epoch 30/200, Iteration 214/250, Loss: 0.0171\n",
      "Epoch 30/200, Iteration 215/250, Loss: 0.0248\n",
      "Epoch 30/200, Iteration 216/250, Loss: 0.0148\n",
      "Epoch 30/200, Iteration 217/250, Loss: 0.0139\n",
      "Epoch 30/200, Iteration 218/250, Loss: 0.0335\n",
      "Epoch 30/200, Iteration 219/250, Loss: 0.0382\n",
      "Epoch 30/200, Iteration 220/250, Loss: 0.0223\n",
      "Epoch 30/200, Iteration 221/250, Loss: 0.0189\n",
      "Epoch 30/200, Iteration 222/250, Loss: 0.0235\n",
      "Epoch 30/200, Iteration 223/250, Loss: 0.0301\n",
      "Epoch 30/200, Iteration 224/250, Loss: 0.0260\n",
      "Epoch 30/200, Iteration 225/250, Loss: 0.0156\n",
      "Epoch 30/200, Iteration 226/250, Loss: 0.0188\n",
      "Epoch 30/200, Iteration 227/250, Loss: 0.0194\n",
      "Epoch 30/200, Iteration 228/250, Loss: 0.0357\n",
      "Epoch 30/200, Iteration 229/250, Loss: 0.0125\n",
      "Epoch 30/200, Iteration 230/250, Loss: 0.0188\n",
      "Epoch 30/200, Iteration 231/250, Loss: 0.0153\n",
      "Epoch 30/200, Iteration 232/250, Loss: 0.0341\n",
      "Epoch 30/200, Iteration 233/250, Loss: 0.0437\n",
      "Epoch 30/200, Iteration 234/250, Loss: 0.0407\n",
      "Epoch 30/200, Iteration 235/250, Loss: 0.0280\n",
      "Epoch 30/200, Iteration 236/250, Loss: 0.0142\n",
      "Epoch 30/200, Iteration 237/250, Loss: 0.0209\n",
      "Epoch 30/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 30/200, Iteration 239/250, Loss: 0.0156\n",
      "Epoch 30/200, Iteration 240/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 241/250, Loss: 0.0121\n",
      "Epoch 30/200, Iteration 242/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 243/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 244/250, Loss: 0.0163\n",
      "Epoch 30/200, Iteration 245/250, Loss: 0.0124\n",
      "Epoch 30/200, Iteration 246/250, Loss: 0.0116\n",
      "Epoch 30/200, Iteration 247/250, Loss: 0.0173\n",
      "Epoch 30/200, Iteration 248/250, Loss: 0.0191\n",
      "Epoch 30/200, Iteration 249/250, Loss: 0.0324\n",
      "Epoch 30/200, Iteration 250/250, Loss: 0.0307\n",
      "Train Error: \n",
      " Accuracy: 91.51%, Avg loss: 0.014467, MRE: 1.063685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.014445, MRE: 1.750092 \n",
      "\n",
      "Epoch 31/200, Iteration 1/250, Loss: 0.0128\n",
      "Epoch 31/200, Iteration 2/250, Loss: 0.0134\n",
      "Epoch 31/200, Iteration 3/250, Loss: 0.0159\n",
      "Epoch 31/200, Iteration 4/250, Loss: 0.0124\n",
      "Epoch 31/200, Iteration 5/250, Loss: 0.0174\n",
      "Epoch 31/200, Iteration 6/250, Loss: 0.0190\n",
      "Epoch 31/200, Iteration 7/250, Loss: 0.0132\n",
      "Epoch 31/200, Iteration 8/250, Loss: 0.0096\n",
      "Epoch 31/200, Iteration 9/250, Loss: 0.0095\n",
      "Epoch 31/200, Iteration 10/250, Loss: 0.0412\n",
      "Epoch 31/200, Iteration 11/250, Loss: 0.0202\n",
      "Epoch 31/200, Iteration 12/250, Loss: 0.0185\n",
      "Epoch 31/200, Iteration 13/250, Loss: 0.0121\n",
      "Epoch 31/200, Iteration 14/250, Loss: 0.0091\n",
      "Epoch 31/200, Iteration 15/250, Loss: 0.0344\n",
      "Epoch 31/200, Iteration 16/250, Loss: 0.0158\n",
      "Epoch 31/200, Iteration 17/250, Loss: 0.0153\n",
      "Epoch 31/200, Iteration 18/250, Loss: 0.0106\n",
      "Epoch 31/200, Iteration 19/250, Loss: 0.0285\n",
      "Epoch 31/200, Iteration 20/250, Loss: 0.0284\n",
      "Epoch 31/200, Iteration 21/250, Loss: 0.0302\n",
      "Epoch 31/200, Iteration 22/250, Loss: 0.0150\n",
      "Epoch 31/200, Iteration 23/250, Loss: 0.0117\n",
      "Epoch 31/200, Iteration 24/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 31/200, Iteration 26/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 27/250, Loss: 0.0187\n",
      "Epoch 31/200, Iteration 28/250, Loss: 0.0206\n",
      "Epoch 31/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 31/200, Iteration 30/250, Loss: 0.0169\n",
      "Epoch 31/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 31/200, Iteration 32/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 33/250, Loss: 0.0138\n",
      "Epoch 31/200, Iteration 34/250, Loss: 0.0255\n",
      "Epoch 31/200, Iteration 35/250, Loss: 0.0143\n",
      "Epoch 31/200, Iteration 36/250, Loss: 0.0184\n",
      "Epoch 31/200, Iteration 37/250, Loss: 0.0110\n",
      "Epoch 31/200, Iteration 38/250, Loss: 0.0418\n",
      "Epoch 31/200, Iteration 39/250, Loss: 0.0128\n",
      "Epoch 31/200, Iteration 40/250, Loss: 0.0274\n",
      "Epoch 31/200, Iteration 41/250, Loss: 0.0099\n",
      "Epoch 31/200, Iteration 42/250, Loss: 0.0130\n",
      "Epoch 31/200, Iteration 43/250, Loss: 0.0183\n",
      "Epoch 31/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 31/200, Iteration 45/250, Loss: 0.0331\n",
      "Epoch 31/200, Iteration 46/250, Loss: 0.0077\n",
      "Epoch 31/200, Iteration 47/250, Loss: 0.0127\n",
      "Epoch 31/200, Iteration 48/250, Loss: 0.0151\n",
      "Epoch 31/200, Iteration 49/250, Loss: 0.0173\n",
      "Epoch 31/200, Iteration 50/250, Loss: 0.0154\n",
      "Epoch 31/200, Iteration 51/250, Loss: 0.0107\n",
      "Epoch 31/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 31/200, Iteration 53/250, Loss: 0.0260\n",
      "Epoch 31/200, Iteration 54/250, Loss: 0.0154\n",
      "Epoch 31/200, Iteration 55/250, Loss: 0.0163\n",
      "Epoch 31/200, Iteration 56/250, Loss: 0.0196\n",
      "Epoch 31/200, Iteration 57/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 58/250, Loss: 0.0126\n",
      "Epoch 31/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 31/200, Iteration 60/250, Loss: 0.0180\n",
      "Epoch 31/200, Iteration 61/250, Loss: 0.0145\n",
      "Epoch 31/200, Iteration 62/250, Loss: 0.0098\n",
      "Epoch 31/200, Iteration 63/250, Loss: 0.0203\n",
      "Epoch 31/200, Iteration 64/250, Loss: 0.0106\n",
      "Epoch 31/200, Iteration 65/250, Loss: 0.0134\n",
      "Epoch 31/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 31/200, Iteration 67/250, Loss: 0.0138\n",
      "Epoch 31/200, Iteration 68/250, Loss: 0.0191\n",
      "Epoch 31/200, Iteration 69/250, Loss: 0.0191\n",
      "Epoch 31/200, Iteration 70/250, Loss: 0.0355\n",
      "Epoch 31/200, Iteration 71/250, Loss: 0.0130\n",
      "Epoch 31/200, Iteration 72/250, Loss: 0.0288\n",
      "Epoch 31/200, Iteration 73/250, Loss: 0.0114\n",
      "Epoch 31/200, Iteration 74/250, Loss: 0.0331\n",
      "Epoch 31/200, Iteration 75/250, Loss: 0.0126\n",
      "Epoch 31/200, Iteration 76/250, Loss: 0.0280\n",
      "Epoch 31/200, Iteration 77/250, Loss: 0.0290\n",
      "Epoch 31/200, Iteration 78/250, Loss: 0.0256\n",
      "Epoch 31/200, Iteration 79/250, Loss: 0.0168\n",
      "Epoch 31/200, Iteration 80/250, Loss: 0.0170\n",
      "Epoch 31/200, Iteration 81/250, Loss: 0.0264\n",
      "Epoch 31/200, Iteration 82/250, Loss: 0.0314\n",
      "Epoch 31/200, Iteration 83/250, Loss: 0.0166\n",
      "Epoch 31/200, Iteration 84/250, Loss: 0.0400\n",
      "Epoch 31/200, Iteration 85/250, Loss: 0.0142\n",
      "Epoch 31/200, Iteration 86/250, Loss: 0.0210\n",
      "Epoch 31/200, Iteration 87/250, Loss: 0.0263\n",
      "Epoch 31/200, Iteration 88/250, Loss: 0.0159\n",
      "Epoch 31/200, Iteration 89/250, Loss: 0.0114\n",
      "Epoch 31/200, Iteration 90/250, Loss: 0.0107\n",
      "Epoch 31/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 31/200, Iteration 92/250, Loss: 0.0338\n",
      "Epoch 31/200, Iteration 93/250, Loss: 0.0185\n",
      "Epoch 31/200, Iteration 94/250, Loss: 0.0268\n",
      "Epoch 31/200, Iteration 95/250, Loss: 0.0226\n",
      "Epoch 31/200, Iteration 96/250, Loss: 0.0098\n",
      "Epoch 31/200, Iteration 97/250, Loss: 0.0083\n",
      "Epoch 31/200, Iteration 98/250, Loss: 0.0136\n",
      "Epoch 31/200, Iteration 99/250, Loss: 0.0107\n",
      "Epoch 31/200, Iteration 100/250, Loss: 0.0267\n",
      "Epoch 31/200, Iteration 101/250, Loss: 0.0085\n",
      "Epoch 31/200, Iteration 102/250, Loss: 0.0215\n",
      "Epoch 31/200, Iteration 103/250, Loss: 0.0299\n",
      "Epoch 31/200, Iteration 104/250, Loss: 0.0411\n",
      "Epoch 31/200, Iteration 105/250, Loss: 0.0130\n",
      "Epoch 31/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 31/200, Iteration 107/250, Loss: 0.0202\n",
      "Epoch 31/200, Iteration 108/250, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Iteration 109/250, Loss: 0.0115\n",
      "Epoch 31/200, Iteration 110/250, Loss: 0.0122\n",
      "Epoch 31/200, Iteration 111/250, Loss: 0.0146\n",
      "Epoch 31/200, Iteration 112/250, Loss: 0.0126\n",
      "Epoch 31/200, Iteration 113/250, Loss: 0.0148\n",
      "Epoch 31/200, Iteration 114/250, Loss: 0.0109\n",
      "Epoch 31/200, Iteration 115/250, Loss: 0.0146\n",
      "Epoch 31/200, Iteration 116/250, Loss: 0.0203\n",
      "Epoch 31/200, Iteration 117/250, Loss: 0.0175\n",
      "Epoch 31/200, Iteration 118/250, Loss: 0.0189\n",
      "Epoch 31/200, Iteration 119/250, Loss: 0.0139\n",
      "Epoch 31/200, Iteration 120/250, Loss: 0.0121\n",
      "Epoch 31/200, Iteration 121/250, Loss: 0.0111\n",
      "Epoch 31/200, Iteration 122/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 123/250, Loss: 0.0300\n",
      "Epoch 31/200, Iteration 124/250, Loss: 0.0208\n",
      "Epoch 31/200, Iteration 125/250, Loss: 0.0111\n",
      "Epoch 31/200, Iteration 126/250, Loss: 0.0093\n",
      "Epoch 31/200, Iteration 127/250, Loss: 0.0285\n",
      "Epoch 31/200, Iteration 128/250, Loss: 0.0106\n",
      "Epoch 31/200, Iteration 129/250, Loss: 0.0220\n",
      "Epoch 31/200, Iteration 130/250, Loss: 0.0211\n",
      "Epoch 31/200, Iteration 131/250, Loss: 0.0222\n",
      "Epoch 31/200, Iteration 132/250, Loss: 0.0085\n",
      "Epoch 31/200, Iteration 133/250, Loss: 0.0176\n",
      "Epoch 31/200, Iteration 134/250, Loss: 0.0172\n",
      "Epoch 31/200, Iteration 135/250, Loss: 0.0152\n",
      "Epoch 31/200, Iteration 136/250, Loss: 0.0135\n",
      "Epoch 31/200, Iteration 137/250, Loss: 0.0411\n",
      "Epoch 31/200, Iteration 138/250, Loss: 0.0114\n",
      "Epoch 31/200, Iteration 139/250, Loss: 0.0125\n",
      "Epoch 31/200, Iteration 140/250, Loss: 0.0088\n",
      "Epoch 31/200, Iteration 141/250, Loss: 0.0426\n",
      "Epoch 31/200, Iteration 142/250, Loss: 0.0096\n",
      "Epoch 31/200, Iteration 143/250, Loss: 0.0091\n",
      "Epoch 31/200, Iteration 144/250, Loss: 0.0110\n",
      "Epoch 31/200, Iteration 145/250, Loss: 0.0224\n",
      "Epoch 31/200, Iteration 146/250, Loss: 0.0343\n",
      "Epoch 31/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 31/200, Iteration 148/250, Loss: 0.0113\n",
      "Epoch 31/200, Iteration 149/250, Loss: 0.0304\n",
      "Epoch 31/200, Iteration 150/250, Loss: 0.0152\n",
      "Epoch 31/200, Iteration 151/250, Loss: 0.0157\n",
      "Epoch 31/200, Iteration 152/250, Loss: 0.0206\n",
      "Epoch 31/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 31/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 31/200, Iteration 155/250, Loss: 0.0143\n",
      "Epoch 31/200, Iteration 156/250, Loss: 0.0100\n",
      "Epoch 31/200, Iteration 157/250, Loss: 0.0156\n",
      "Epoch 31/200, Iteration 158/250, Loss: 0.0149\n",
      "Epoch 31/200, Iteration 159/250, Loss: 0.0233\n",
      "Epoch 31/200, Iteration 160/250, Loss: 0.0083\n",
      "Epoch 31/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 31/200, Iteration 162/250, Loss: 0.0105\n",
      "Epoch 31/200, Iteration 163/250, Loss: 0.0098\n",
      "Epoch 31/200, Iteration 164/250, Loss: 0.0095\n",
      "Epoch 31/200, Iteration 165/250, Loss: 0.0167\n",
      "Epoch 31/200, Iteration 166/250, Loss: 0.0454\n",
      "Epoch 31/200, Iteration 167/250, Loss: 0.0232\n",
      "Epoch 31/200, Iteration 168/250, Loss: 0.0273\n",
      "Epoch 31/200, Iteration 169/250, Loss: 0.0293\n",
      "Epoch 31/200, Iteration 170/250, Loss: 0.0107\n",
      "Epoch 31/200, Iteration 171/250, Loss: 0.0344\n",
      "Epoch 31/200, Iteration 172/250, Loss: 0.0310\n",
      "Epoch 31/200, Iteration 173/250, Loss: 0.0114\n",
      "Epoch 31/200, Iteration 174/250, Loss: 0.0223\n",
      "Epoch 31/200, Iteration 175/250, Loss: 0.0149\n",
      "Epoch 31/200, Iteration 176/250, Loss: 0.0184\n",
      "Epoch 31/200, Iteration 177/250, Loss: 0.0162\n",
      "Epoch 31/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 31/200, Iteration 179/250, Loss: 0.0064\n",
      "Epoch 31/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 31/200, Iteration 181/250, Loss: 0.0180\n",
      "Epoch 31/200, Iteration 182/250, Loss: 0.0144\n",
      "Epoch 31/200, Iteration 183/250, Loss: 0.0209\n",
      "Epoch 31/200, Iteration 184/250, Loss: 0.0085\n",
      "Epoch 31/200, Iteration 185/250, Loss: 0.0135\n",
      "Epoch 31/200, Iteration 186/250, Loss: 0.0240\n",
      "Epoch 31/200, Iteration 187/250, Loss: 0.0291\n",
      "Epoch 31/200, Iteration 188/250, Loss: 0.0199\n",
      "Epoch 31/200, Iteration 189/250, Loss: 0.0219\n",
      "Epoch 31/200, Iteration 190/250, Loss: 0.0133\n",
      "Epoch 31/200, Iteration 191/250, Loss: 0.0113\n",
      "Epoch 31/200, Iteration 192/250, Loss: 0.0193\n",
      "Epoch 31/200, Iteration 193/250, Loss: 0.0135\n",
      "Epoch 31/200, Iteration 194/250, Loss: 0.0325\n",
      "Epoch 31/200, Iteration 195/250, Loss: 0.0181\n",
      "Epoch 31/200, Iteration 196/250, Loss: 0.0110\n",
      "Epoch 31/200, Iteration 197/250, Loss: 0.0257\n",
      "Epoch 31/200, Iteration 198/250, Loss: 0.0131\n",
      "Epoch 31/200, Iteration 199/250, Loss: 0.0173\n",
      "Epoch 31/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 31/200, Iteration 201/250, Loss: 0.0148\n",
      "Epoch 31/200, Iteration 202/250, Loss: 0.0144\n",
      "Epoch 31/200, Iteration 203/250, Loss: 0.0337\n",
      "Epoch 31/200, Iteration 204/250, Loss: 0.0225\n",
      "Epoch 31/200, Iteration 205/250, Loss: 0.0221\n",
      "Epoch 31/200, Iteration 206/250, Loss: 0.0298\n",
      "Epoch 31/200, Iteration 207/250, Loss: 0.0132\n",
      "Epoch 31/200, Iteration 208/250, Loss: 0.0370\n",
      "Epoch 31/200, Iteration 209/250, Loss: 0.0169\n",
      "Epoch 31/200, Iteration 210/250, Loss: 0.0078\n",
      "Epoch 31/200, Iteration 211/250, Loss: 0.0306\n",
      "Epoch 31/200, Iteration 212/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 213/250, Loss: 0.0198\n",
      "Epoch 31/200, Iteration 214/250, Loss: 0.0169\n",
      "Epoch 31/200, Iteration 215/250, Loss: 0.0262\n",
      "Epoch 31/200, Iteration 216/250, Loss: 0.0105\n",
      "Epoch 31/200, Iteration 217/250, Loss: 0.0377\n",
      "Epoch 31/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 31/200, Iteration 219/250, Loss: 0.0208\n",
      "Epoch 31/200, Iteration 220/250, Loss: 0.0082\n",
      "Epoch 31/200, Iteration 221/250, Loss: 0.0277\n",
      "Epoch 31/200, Iteration 222/250, Loss: 0.0211\n",
      "Epoch 31/200, Iteration 223/250, Loss: 0.0159\n",
      "Epoch 31/200, Iteration 224/250, Loss: 0.0116\n",
      "Epoch 31/200, Iteration 225/250, Loss: 0.0174\n",
      "Epoch 31/200, Iteration 226/250, Loss: 0.0111\n",
      "Epoch 31/200, Iteration 227/250, Loss: 0.0102\n",
      "Epoch 31/200, Iteration 228/250, Loss: 0.0261\n",
      "Epoch 31/200, Iteration 229/250, Loss: 0.0313\n",
      "Epoch 31/200, Iteration 230/250, Loss: 0.0080\n",
      "Epoch 31/200, Iteration 231/250, Loss: 0.0203\n",
      "Epoch 31/200, Iteration 232/250, Loss: 0.0136\n",
      "Epoch 31/200, Iteration 233/250, Loss: 0.0132\n",
      "Epoch 31/200, Iteration 234/250, Loss: 0.0157\n",
      "Epoch 31/200, Iteration 235/250, Loss: 0.0254\n",
      "Epoch 31/200, Iteration 236/250, Loss: 0.0303\n",
      "Epoch 31/200, Iteration 237/250, Loss: 0.0353\n",
      "Epoch 31/200, Iteration 238/250, Loss: 0.0089\n",
      "Epoch 31/200, Iteration 239/250, Loss: 0.0133\n",
      "Epoch 31/200, Iteration 240/250, Loss: 0.0202\n",
      "Epoch 31/200, Iteration 241/250, Loss: 0.0092\n",
      "Epoch 31/200, Iteration 242/250, Loss: 0.0275\n",
      "Epoch 31/200, Iteration 243/250, Loss: 0.0096\n",
      "Epoch 31/200, Iteration 244/250, Loss: 0.0192\n",
      "Epoch 31/200, Iteration 245/250, Loss: 0.0132\n",
      "Epoch 31/200, Iteration 246/250, Loss: 0.0202\n",
      "Epoch 31/200, Iteration 247/250, Loss: 0.0163\n",
      "Epoch 31/200, Iteration 248/250, Loss: 0.0298\n",
      "Epoch 31/200, Iteration 249/250, Loss: 0.0096\n",
      "Epoch 31/200, Iteration 250/250, Loss: 0.0163\n",
      "Train Error: \n",
      " Accuracy: 84.04%, Avg loss: 0.007745, MRE: 0.699076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.007647, MRE: 1.009485 \n",
      "\n",
      "Epoch 32/200, Iteration 1/250, Loss: 0.0117\n",
      "Epoch 32/200, Iteration 2/250, Loss: 0.0156\n",
      "Epoch 32/200, Iteration 3/250, Loss: 0.0094\n",
      "Epoch 32/200, Iteration 4/250, Loss: 0.0137\n",
      "Epoch 32/200, Iteration 5/250, Loss: 0.0086\n",
      "Epoch 32/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 32/200, Iteration 7/250, Loss: 0.0176\n",
      "Epoch 32/200, Iteration 8/250, Loss: 0.0137\n",
      "Epoch 32/200, Iteration 9/250, Loss: 0.0084\n",
      "Epoch 32/200, Iteration 10/250, Loss: 0.0105\n",
      "Epoch 32/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 32/200, Iteration 12/250, Loss: 0.0088\n",
      "Epoch 32/200, Iteration 13/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 14/250, Loss: 0.0086\n",
      "Epoch 32/200, Iteration 15/250, Loss: 0.0205\n",
      "Epoch 32/200, Iteration 16/250, Loss: 0.0095\n",
      "Epoch 32/200, Iteration 17/250, Loss: 0.0103\n",
      "Epoch 32/200, Iteration 18/250, Loss: 0.0077\n",
      "Epoch 32/200, Iteration 19/250, Loss: 0.0177\n",
      "Epoch 32/200, Iteration 20/250, Loss: 0.0080\n",
      "Epoch 32/200, Iteration 21/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 22/250, Loss: 0.0277\n",
      "Epoch 32/200, Iteration 23/250, Loss: 0.0331\n",
      "Epoch 32/200, Iteration 24/250, Loss: 0.0160\n",
      "Epoch 32/200, Iteration 25/250, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 26/250, Loss: 0.0106\n",
      "Epoch 32/200, Iteration 27/250, Loss: 0.0185\n",
      "Epoch 32/200, Iteration 28/250, Loss: 0.0112\n",
      "Epoch 32/200, Iteration 29/250, Loss: 0.0134\n",
      "Epoch 32/200, Iteration 30/250, Loss: 0.0198\n",
      "Epoch 32/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 32/200, Iteration 32/250, Loss: 0.0229\n",
      "Epoch 32/200, Iteration 33/250, Loss: 0.0192\n",
      "Epoch 32/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 32/200, Iteration 35/250, Loss: 0.0115\n",
      "Epoch 32/200, Iteration 36/250, Loss: 0.0176\n",
      "Epoch 32/200, Iteration 37/250, Loss: 0.0314\n",
      "Epoch 32/200, Iteration 38/250, Loss: 0.0307\n",
      "Epoch 32/200, Iteration 39/250, Loss: 0.0168\n",
      "Epoch 32/200, Iteration 40/250, Loss: 0.0131\n",
      "Epoch 32/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 32/200, Iteration 42/250, Loss: 0.0194\n",
      "Epoch 32/200, Iteration 43/250, Loss: 0.0107\n",
      "Epoch 32/200, Iteration 44/250, Loss: 0.0157\n",
      "Epoch 32/200, Iteration 45/250, Loss: 0.0106\n",
      "Epoch 32/200, Iteration 46/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 47/250, Loss: 0.0185\n",
      "Epoch 32/200, Iteration 48/250, Loss: 0.0102\n",
      "Epoch 32/200, Iteration 49/250, Loss: 0.0120\n",
      "Epoch 32/200, Iteration 50/250, Loss: 0.0212\n",
      "Epoch 32/200, Iteration 51/250, Loss: 0.0111\n",
      "Epoch 32/200, Iteration 52/250, Loss: 0.0148\n",
      "Epoch 32/200, Iteration 53/250, Loss: 0.0143\n",
      "Epoch 32/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 32/200, Iteration 55/250, Loss: 0.0110\n",
      "Epoch 32/200, Iteration 56/250, Loss: 0.0220\n",
      "Epoch 32/200, Iteration 57/250, Loss: 0.0280\n",
      "Epoch 32/200, Iteration 58/250, Loss: 0.0158\n",
      "Epoch 32/200, Iteration 59/250, Loss: 0.0081\n",
      "Epoch 32/200, Iteration 60/250, Loss: 0.0111\n",
      "Epoch 32/200, Iteration 61/250, Loss: 0.0237\n",
      "Epoch 32/200, Iteration 62/250, Loss: 0.0169\n",
      "Epoch 32/200, Iteration 63/250, Loss: 0.0165\n",
      "Epoch 32/200, Iteration 64/250, Loss: 0.0087\n",
      "Epoch 32/200, Iteration 65/250, Loss: 0.0177\n",
      "Epoch 32/200, Iteration 66/250, Loss: 0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Iteration 67/250, Loss: 0.0075\n",
      "Epoch 32/200, Iteration 68/250, Loss: 0.0075\n",
      "Epoch 32/200, Iteration 69/250, Loss: 0.0103\n",
      "Epoch 32/200, Iteration 70/250, Loss: 0.0241\n",
      "Epoch 32/200, Iteration 71/250, Loss: 0.0126\n",
      "Epoch 32/200, Iteration 72/250, Loss: 0.0124\n",
      "Epoch 32/200, Iteration 73/250, Loss: 0.0199\n",
      "Epoch 32/200, Iteration 74/250, Loss: 0.0138\n",
      "Epoch 32/200, Iteration 75/250, Loss: 0.0131\n",
      "Epoch 32/200, Iteration 76/250, Loss: 0.0235\n",
      "Epoch 32/200, Iteration 77/250, Loss: 0.0120\n",
      "Epoch 32/200, Iteration 78/250, Loss: 0.0206\n",
      "Epoch 32/200, Iteration 79/250, Loss: 0.0109\n",
      "Epoch 32/200, Iteration 80/250, Loss: 0.0120\n",
      "Epoch 32/200, Iteration 81/250, Loss: 0.0148\n",
      "Epoch 32/200, Iteration 82/250, Loss: 0.0158\n",
      "Epoch 32/200, Iteration 83/250, Loss: 0.0416\n",
      "Epoch 32/200, Iteration 84/250, Loss: 0.0168\n",
      "Epoch 32/200, Iteration 85/250, Loss: 0.0262\n",
      "Epoch 32/200, Iteration 86/250, Loss: 0.0116\n",
      "Epoch 32/200, Iteration 87/250, Loss: 0.0128\n",
      "Epoch 32/200, Iteration 88/250, Loss: 0.0249\n",
      "Epoch 32/200, Iteration 89/250, Loss: 0.0075\n",
      "Epoch 32/200, Iteration 90/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 91/250, Loss: 0.0238\n",
      "Epoch 32/200, Iteration 92/250, Loss: 0.0150\n",
      "Epoch 32/200, Iteration 93/250, Loss: 0.0085\n",
      "Epoch 32/200, Iteration 94/250, Loss: 0.0084\n",
      "Epoch 32/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 32/200, Iteration 96/250, Loss: 0.0184\n",
      "Epoch 32/200, Iteration 97/250, Loss: 0.0193\n",
      "Epoch 32/200, Iteration 98/250, Loss: 0.0084\n",
      "Epoch 32/200, Iteration 99/250, Loss: 0.0285\n",
      "Epoch 32/200, Iteration 100/250, Loss: 0.0221\n",
      "Epoch 32/200, Iteration 101/250, Loss: 0.0091\n",
      "Epoch 32/200, Iteration 102/250, Loss: 0.0196\n",
      "Epoch 32/200, Iteration 103/250, Loss: 0.0158\n",
      "Epoch 32/200, Iteration 104/250, Loss: 0.0100\n",
      "Epoch 32/200, Iteration 105/250, Loss: 0.0135\n",
      "Epoch 32/200, Iteration 106/250, Loss: 0.0165\n",
      "Epoch 32/200, Iteration 107/250, Loss: 0.0217\n",
      "Epoch 32/200, Iteration 108/250, Loss: 0.0133\n",
      "Epoch 32/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 32/200, Iteration 110/250, Loss: 0.0127\n",
      "Epoch 32/200, Iteration 111/250, Loss: 0.0078\n",
      "Epoch 32/200, Iteration 112/250, Loss: 0.0083\n",
      "Epoch 32/200, Iteration 113/250, Loss: 0.0264\n",
      "Epoch 32/200, Iteration 114/250, Loss: 0.0322\n",
      "Epoch 32/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 32/200, Iteration 116/250, Loss: 0.0114\n",
      "Epoch 32/200, Iteration 117/250, Loss: 0.0265\n",
      "Epoch 32/200, Iteration 118/250, Loss: 0.0082\n",
      "Epoch 32/200, Iteration 119/250, Loss: 0.0244\n",
      "Epoch 32/200, Iteration 120/250, Loss: 0.0177\n",
      "Epoch 32/200, Iteration 121/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 122/250, Loss: 0.0073\n",
      "Epoch 32/200, Iteration 123/250, Loss: 0.0073\n",
      "Epoch 32/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 32/200, Iteration 125/250, Loss: 0.0163\n",
      "Epoch 32/200, Iteration 126/250, Loss: 0.0084\n",
      "Epoch 32/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 32/200, Iteration 128/250, Loss: 0.0089\n",
      "Epoch 32/200, Iteration 129/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 130/250, Loss: 0.0149\n",
      "Epoch 32/200, Iteration 131/250, Loss: 0.0143\n",
      "Epoch 32/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 32/200, Iteration 133/250, Loss: 0.0181\n",
      "Epoch 32/200, Iteration 134/250, Loss: 0.0263\n",
      "Epoch 32/200, Iteration 135/250, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 136/250, Loss: 0.0151\n",
      "Epoch 32/200, Iteration 137/250, Loss: 0.0190\n",
      "Epoch 32/200, Iteration 138/250, Loss: 0.0174\n",
      "Epoch 32/200, Iteration 139/250, Loss: 0.0269\n",
      "Epoch 32/200, Iteration 140/250, Loss: 0.0093\n",
      "Epoch 32/200, Iteration 141/250, Loss: 0.0235\n",
      "Epoch 32/200, Iteration 142/250, Loss: 0.0132\n",
      "Epoch 32/200, Iteration 143/250, Loss: 0.0285\n",
      "Epoch 32/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 32/200, Iteration 145/250, Loss: 0.0271\n",
      "Epoch 32/200, Iteration 146/250, Loss: 0.0491\n",
      "Epoch 32/200, Iteration 147/250, Loss: 0.0257\n",
      "Epoch 32/200, Iteration 148/250, Loss: 0.0467\n",
      "Epoch 32/200, Iteration 149/250, Loss: 0.0186\n",
      "Epoch 32/200, Iteration 150/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 151/250, Loss: 0.0067\n",
      "Epoch 32/200, Iteration 152/250, Loss: 0.0311\n",
      "Epoch 32/200, Iteration 153/250, Loss: 0.0134\n",
      "Epoch 32/200, Iteration 154/250, Loss: 0.0131\n",
      "Epoch 32/200, Iteration 155/250, Loss: 0.0122\n",
      "Epoch 32/200, Iteration 156/250, Loss: 0.0083\n",
      "Epoch 32/200, Iteration 157/250, Loss: 0.0240\n",
      "Epoch 32/200, Iteration 158/250, Loss: 0.0088\n",
      "Epoch 32/200, Iteration 159/250, Loss: 0.0175\n",
      "Epoch 32/200, Iteration 160/250, Loss: 0.0290\n",
      "Epoch 32/200, Iteration 161/250, Loss: 0.0102\n",
      "Epoch 32/200, Iteration 162/250, Loss: 0.0225\n",
      "Epoch 32/200, Iteration 163/250, Loss: 0.0134\n",
      "Epoch 32/200, Iteration 164/250, Loss: 0.0133\n",
      "Epoch 32/200, Iteration 165/250, Loss: 0.0093\n",
      "Epoch 32/200, Iteration 166/250, Loss: 0.0318\n",
      "Epoch 32/200, Iteration 167/250, Loss: 0.0112\n",
      "Epoch 32/200, Iteration 168/250, Loss: 0.0168\n",
      "Epoch 32/200, Iteration 169/250, Loss: 0.0295\n",
      "Epoch 32/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 32/200, Iteration 171/250, Loss: 0.0123\n",
      "Epoch 32/200, Iteration 172/250, Loss: 0.0339\n",
      "Epoch 32/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 32/200, Iteration 174/250, Loss: 0.0076\n",
      "Epoch 32/200, Iteration 175/250, Loss: 0.0149\n",
      "Epoch 32/200, Iteration 176/250, Loss: 0.0163\n",
      "Epoch 32/200, Iteration 177/250, Loss: 0.0261\n",
      "Epoch 32/200, Iteration 178/250, Loss: 0.0264\n",
      "Epoch 32/200, Iteration 179/250, Loss: 0.0169\n",
      "Epoch 32/200, Iteration 180/250, Loss: 0.0095\n",
      "Epoch 32/200, Iteration 181/250, Loss: 0.0247\n",
      "Epoch 32/200, Iteration 182/250, Loss: 0.0231\n",
      "Epoch 32/200, Iteration 183/250, Loss: 0.0119\n",
      "Epoch 32/200, Iteration 184/250, Loss: 0.0122\n",
      "Epoch 32/200, Iteration 185/250, Loss: 0.0181\n",
      "Epoch 32/200, Iteration 186/250, Loss: 0.0163\n",
      "Epoch 32/200, Iteration 187/250, Loss: 0.0255\n",
      "Epoch 32/200, Iteration 188/250, Loss: 0.0063\n",
      "Epoch 32/200, Iteration 189/250, Loss: 0.0292\n",
      "Epoch 32/200, Iteration 190/250, Loss: 0.0307\n",
      "Epoch 32/200, Iteration 191/250, Loss: 0.0154\n",
      "Epoch 32/200, Iteration 192/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 193/250, Loss: 0.0136\n",
      "Epoch 32/200, Iteration 194/250, Loss: 0.0190\n",
      "Epoch 32/200, Iteration 195/250, Loss: 0.0154\n",
      "Epoch 32/200, Iteration 196/250, Loss: 0.0328\n",
      "Epoch 32/200, Iteration 197/250, Loss: 0.0116\n",
      "Epoch 32/200, Iteration 198/250, Loss: 0.0146\n",
      "Epoch 32/200, Iteration 199/250, Loss: 0.0185\n",
      "Epoch 32/200, Iteration 200/250, Loss: 0.0142\n",
      "Epoch 32/200, Iteration 201/250, Loss: 0.0105\n",
      "Epoch 32/200, Iteration 202/250, Loss: 0.0146\n",
      "Epoch 32/200, Iteration 203/250, Loss: 0.0109\n",
      "Epoch 32/200, Iteration 204/250, Loss: 0.0170\n",
      "Epoch 32/200, Iteration 205/250, Loss: 0.0353\n",
      "Epoch 32/200, Iteration 206/250, Loss: 0.0502\n",
      "Epoch 32/200, Iteration 207/250, Loss: 0.0320\n",
      "Epoch 32/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 32/200, Iteration 209/250, Loss: 0.0113\n",
      "Epoch 32/200, Iteration 210/250, Loss: 0.0085\n",
      "Epoch 32/200, Iteration 211/250, Loss: 0.0316\n",
      "Epoch 32/200, Iteration 212/250, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 213/250, Loss: 0.0104\n",
      "Epoch 32/200, Iteration 214/250, Loss: 0.0130\n",
      "Epoch 32/200, Iteration 215/250, Loss: 0.0191\n",
      "Epoch 32/200, Iteration 216/250, Loss: 0.0162\n",
      "Epoch 32/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 32/200, Iteration 218/250, Loss: 0.0337\n",
      "Epoch 32/200, Iteration 219/250, Loss: 0.0082\n",
      "Epoch 32/200, Iteration 220/250, Loss: 0.0167\n",
      "Epoch 32/200, Iteration 221/250, Loss: 0.0090\n",
      "Epoch 32/200, Iteration 222/250, Loss: 0.0247\n",
      "Epoch 32/200, Iteration 223/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 224/250, Loss: 0.0196\n",
      "Epoch 32/200, Iteration 225/250, Loss: 0.0125\n",
      "Epoch 32/200, Iteration 226/250, Loss: 0.0174\n",
      "Epoch 32/200, Iteration 227/250, Loss: 0.0231\n",
      "Epoch 32/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 32/200, Iteration 229/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 230/250, Loss: 0.0054\n",
      "Epoch 32/200, Iteration 231/250, Loss: 0.0232\n",
      "Epoch 32/200, Iteration 232/250, Loss: 0.0168\n",
      "Epoch 32/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 32/200, Iteration 234/250, Loss: 0.0249\n",
      "Epoch 32/200, Iteration 235/250, Loss: 0.0212\n",
      "Epoch 32/200, Iteration 236/250, Loss: 0.0096\n",
      "Epoch 32/200, Iteration 237/250, Loss: 0.0250\n",
      "Epoch 32/200, Iteration 238/250, Loss: 0.0136\n",
      "Epoch 32/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 32/200, Iteration 240/250, Loss: 0.0274\n",
      "Epoch 32/200, Iteration 241/250, Loss: 0.0253\n",
      "Epoch 32/200, Iteration 242/250, Loss: 0.0321\n",
      "Epoch 32/200, Iteration 243/250, Loss: 0.0142\n",
      "Epoch 32/200, Iteration 244/250, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 32/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 32/200, Iteration 247/250, Loss: 0.0128\n",
      "Epoch 32/200, Iteration 248/250, Loss: 0.0116\n",
      "Epoch 32/200, Iteration 249/250, Loss: 0.0211\n",
      "Epoch 32/200, Iteration 250/250, Loss: 0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.74%, Avg loss: 0.008967, MRE: 0.987172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.008916, MRE: 1.318530 \n",
      "\n",
      "Epoch 33/200, Iteration 1/250, Loss: 0.0218\n",
      "Epoch 33/200, Iteration 2/250, Loss: 0.0173\n",
      "Epoch 33/200, Iteration 3/250, Loss: 0.0214\n",
      "Epoch 33/200, Iteration 4/250, Loss: 0.0309\n",
      "Epoch 33/200, Iteration 5/250, Loss: 0.0147\n",
      "Epoch 33/200, Iteration 6/250, Loss: 0.0109\n",
      "Epoch 33/200, Iteration 7/250, Loss: 0.0094\n",
      "Epoch 33/200, Iteration 8/250, Loss: 0.0465\n",
      "Epoch 33/200, Iteration 9/250, Loss: 0.0078\n",
      "Epoch 33/200, Iteration 10/250, Loss: 0.0382\n",
      "Epoch 33/200, Iteration 11/250, Loss: 0.0128\n",
      "Epoch 33/200, Iteration 12/250, Loss: 0.0113\n",
      "Epoch 33/200, Iteration 13/250, Loss: 0.0327\n",
      "Epoch 33/200, Iteration 14/250, Loss: 0.0273\n",
      "Epoch 33/200, Iteration 15/250, Loss: 0.0161\n",
      "Epoch 33/200, Iteration 16/250, Loss: 0.0232\n",
      "Epoch 33/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 33/200, Iteration 18/250, Loss: 0.0088\n",
      "Epoch 33/200, Iteration 19/250, Loss: 0.0109\n",
      "Epoch 33/200, Iteration 20/250, Loss: 0.0143\n",
      "Epoch 33/200, Iteration 21/250, Loss: 0.0317\n",
      "Epoch 33/200, Iteration 22/250, Loss: 0.0092\n",
      "Epoch 33/200, Iteration 23/250, Loss: 0.0131\n",
      "Epoch 33/200, Iteration 24/250, Loss: 0.0127\n",
      "Epoch 33/200, Iteration 25/250, Loss: 0.0111\n",
      "Epoch 33/200, Iteration 26/250, Loss: 0.0142\n",
      "Epoch 33/200, Iteration 27/250, Loss: 0.0169\n",
      "Epoch 33/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 33/200, Iteration 29/250, Loss: 0.0241\n",
      "Epoch 33/200, Iteration 30/250, Loss: 0.0124\n",
      "Epoch 33/200, Iteration 31/250, Loss: 0.0102\n",
      "Epoch 33/200, Iteration 32/250, Loss: 0.0246\n",
      "Epoch 33/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 33/200, Iteration 34/250, Loss: 0.0106\n",
      "Epoch 33/200, Iteration 35/250, Loss: 0.0145\n",
      "Epoch 33/200, Iteration 36/250, Loss: 0.0103\n",
      "Epoch 33/200, Iteration 37/250, Loss: 0.0371\n",
      "Epoch 33/200, Iteration 38/250, Loss: 0.0230\n",
      "Epoch 33/200, Iteration 39/250, Loss: 0.0187\n",
      "Epoch 33/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 33/200, Iteration 41/250, Loss: 0.0079\n",
      "Epoch 33/200, Iteration 42/250, Loss: 0.0194\n",
      "Epoch 33/200, Iteration 43/250, Loss: 0.0088\n",
      "Epoch 33/200, Iteration 44/250, Loss: 0.0086\n",
      "Epoch 33/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 33/200, Iteration 46/250, Loss: 0.0158\n",
      "Epoch 33/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 33/200, Iteration 48/250, Loss: 0.0318\n",
      "Epoch 33/200, Iteration 49/250, Loss: 0.0101\n",
      "Epoch 33/200, Iteration 50/250, Loss: 0.0251\n",
      "Epoch 33/200, Iteration 51/250, Loss: 0.0110\n",
      "Epoch 33/200, Iteration 52/250, Loss: 0.0078\n",
      "Epoch 33/200, Iteration 53/250, Loss: 0.0174\n",
      "Epoch 33/200, Iteration 54/250, Loss: 0.0151\n",
      "Epoch 33/200, Iteration 55/250, Loss: 0.0382\n",
      "Epoch 33/200, Iteration 56/250, Loss: 0.0135\n",
      "Epoch 33/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 33/200, Iteration 58/250, Loss: 0.0193\n",
      "Epoch 33/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 33/200, Iteration 60/250, Loss: 0.0138\n",
      "Epoch 33/200, Iteration 61/250, Loss: 0.0097\n",
      "Epoch 33/200, Iteration 62/250, Loss: 0.0244\n",
      "Epoch 33/200, Iteration 63/250, Loss: 0.0242\n",
      "Epoch 33/200, Iteration 64/250, Loss: 0.0098\n",
      "Epoch 33/200, Iteration 65/250, Loss: 0.0169\n",
      "Epoch 33/200, Iteration 66/250, Loss: 0.0122\n",
      "Epoch 33/200, Iteration 67/250, Loss: 0.0121\n",
      "Epoch 33/200, Iteration 68/250, Loss: 0.0155\n",
      "Epoch 33/200, Iteration 69/250, Loss: 0.0239\n",
      "Epoch 33/200, Iteration 70/250, Loss: 0.0200\n",
      "Epoch 33/200, Iteration 71/250, Loss: 0.0257\n",
      "Epoch 33/200, Iteration 72/250, Loss: 0.0178\n",
      "Epoch 33/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 33/200, Iteration 74/250, Loss: 0.0102\n",
      "Epoch 33/200, Iteration 75/250, Loss: 0.0188\n",
      "Epoch 33/200, Iteration 76/250, Loss: 0.0215\n",
      "Epoch 33/200, Iteration 77/250, Loss: 0.0101\n",
      "Epoch 33/200, Iteration 78/250, Loss: 0.0170\n",
      "Epoch 33/200, Iteration 79/250, Loss: 0.0330\n",
      "Epoch 33/200, Iteration 80/250, Loss: 0.0229\n",
      "Epoch 33/200, Iteration 81/250, Loss: 0.0207\n",
      "Epoch 33/200, Iteration 82/250, Loss: 0.0156\n",
      "Epoch 33/200, Iteration 83/250, Loss: 0.0078\n",
      "Epoch 33/200, Iteration 84/250, Loss: 0.0127\n",
      "Epoch 33/200, Iteration 85/250, Loss: 0.0154\n",
      "Epoch 33/200, Iteration 86/250, Loss: 0.0295\n",
      "Epoch 33/200, Iteration 87/250, Loss: 0.0149\n",
      "Epoch 33/200, Iteration 88/250, Loss: 0.0253\n",
      "Epoch 33/200, Iteration 89/250, Loss: 0.0159\n",
      "Epoch 33/200, Iteration 90/250, Loss: 0.0102\n",
      "Epoch 33/200, Iteration 91/250, Loss: 0.0094\n",
      "Epoch 33/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 33/200, Iteration 93/250, Loss: 0.0104\n",
      "Epoch 33/200, Iteration 94/250, Loss: 0.0280\n",
      "Epoch 33/200, Iteration 95/250, Loss: 0.0106\n",
      "Epoch 33/200, Iteration 96/250, Loss: 0.0092\n",
      "Epoch 33/200, Iteration 97/250, Loss: 0.0083\n",
      "Epoch 33/200, Iteration 98/250, Loss: 0.0152\n",
      "Epoch 33/200, Iteration 99/250, Loss: 0.0153\n",
      "Epoch 33/200, Iteration 100/250, Loss: 0.0135\n",
      "Epoch 33/200, Iteration 101/250, Loss: 0.0099\n",
      "Epoch 33/200, Iteration 102/250, Loss: 0.0149\n",
      "Epoch 33/200, Iteration 103/250, Loss: 0.0160\n",
      "Epoch 33/200, Iteration 104/250, Loss: 0.0169\n",
      "Epoch 33/200, Iteration 105/250, Loss: 0.0319\n",
      "Epoch 33/200, Iteration 106/250, Loss: 0.0181\n",
      "Epoch 33/200, Iteration 107/250, Loss: 0.0272\n",
      "Epoch 33/200, Iteration 108/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 33/200, Iteration 110/250, Loss: 0.0114\n",
      "Epoch 33/200, Iteration 111/250, Loss: 0.0200\n",
      "Epoch 33/200, Iteration 112/250, Loss: 0.0363\n",
      "Epoch 33/200, Iteration 113/250, Loss: 0.0144\n",
      "Epoch 33/200, Iteration 114/250, Loss: 0.0142\n",
      "Epoch 33/200, Iteration 115/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 33/200, Iteration 117/250, Loss: 0.0087\n",
      "Epoch 33/200, Iteration 118/250, Loss: 0.0085\n",
      "Epoch 33/200, Iteration 119/250, Loss: 0.0133\n",
      "Epoch 33/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 33/200, Iteration 121/250, Loss: 0.0139\n",
      "Epoch 33/200, Iteration 122/250, Loss: 0.0129\n",
      "Epoch 33/200, Iteration 123/250, Loss: 0.0161\n",
      "Epoch 33/200, Iteration 124/250, Loss: 0.0183\n",
      "Epoch 33/200, Iteration 125/250, Loss: 0.0219\n",
      "Epoch 33/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 33/200, Iteration 127/250, Loss: 0.0138\n",
      "Epoch 33/200, Iteration 128/250, Loss: 0.0222\n",
      "Epoch 33/200, Iteration 129/250, Loss: 0.0095\n",
      "Epoch 33/200, Iteration 130/250, Loss: 0.0091\n",
      "Epoch 33/200, Iteration 131/250, Loss: 0.0103\n",
      "Epoch 33/200, Iteration 132/250, Loss: 0.0216\n",
      "Epoch 33/200, Iteration 133/250, Loss: 0.0228\n",
      "Epoch 33/200, Iteration 134/250, Loss: 0.0274\n",
      "Epoch 33/200, Iteration 135/250, Loss: 0.0270\n",
      "Epoch 33/200, Iteration 136/250, Loss: 0.0262\n",
      "Epoch 33/200, Iteration 137/250, Loss: 0.0127\n",
      "Epoch 33/200, Iteration 138/250, Loss: 0.0103\n",
      "Epoch 33/200, Iteration 139/250, Loss: 0.0171\n",
      "Epoch 33/200, Iteration 140/250, Loss: 0.0085\n",
      "Epoch 33/200, Iteration 141/250, Loss: 0.0103\n",
      "Epoch 33/200, Iteration 142/250, Loss: 0.0116\n",
      "Epoch 33/200, Iteration 143/250, Loss: 0.0174\n",
      "Epoch 33/200, Iteration 144/250, Loss: 0.0172\n",
      "Epoch 33/200, Iteration 145/250, Loss: 0.0153\n",
      "Epoch 33/200, Iteration 146/250, Loss: 0.0307\n",
      "Epoch 33/200, Iteration 147/250, Loss: 0.0109\n",
      "Epoch 33/200, Iteration 148/250, Loss: 0.0319\n",
      "Epoch 33/200, Iteration 149/250, Loss: 0.0338\n",
      "Epoch 33/200, Iteration 150/250, Loss: 0.0287\n",
      "Epoch 33/200, Iteration 151/250, Loss: 0.0235\n",
      "Epoch 33/200, Iteration 152/250, Loss: 0.0225\n",
      "Epoch 33/200, Iteration 153/250, Loss: 0.0127\n",
      "Epoch 33/200, Iteration 154/250, Loss: 0.0121\n",
      "Epoch 33/200, Iteration 155/250, Loss: 0.0248\n",
      "Epoch 33/200, Iteration 156/250, Loss: 0.0104\n",
      "Epoch 33/200, Iteration 157/250, Loss: 0.0266\n",
      "Epoch 33/200, Iteration 158/250, Loss: 0.0104\n",
      "Epoch 33/200, Iteration 159/250, Loss: 0.0102\n",
      "Epoch 33/200, Iteration 160/250, Loss: 0.0133\n",
      "Epoch 33/200, Iteration 161/250, Loss: 0.0143\n",
      "Epoch 33/200, Iteration 162/250, Loss: 0.0107\n",
      "Epoch 33/200, Iteration 163/250, Loss: 0.0265\n",
      "Epoch 33/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 33/200, Iteration 165/250, Loss: 0.0157\n",
      "Epoch 33/200, Iteration 166/250, Loss: 0.0210\n",
      "Epoch 33/200, Iteration 167/250, Loss: 0.0127\n",
      "Epoch 33/200, Iteration 168/250, Loss: 0.0104\n",
      "Epoch 33/200, Iteration 169/250, Loss: 0.0124\n",
      "Epoch 33/200, Iteration 170/250, Loss: 0.0188\n",
      "Epoch 33/200, Iteration 171/250, Loss: 0.0109\n",
      "Epoch 33/200, Iteration 172/250, Loss: 0.0158\n",
      "Epoch 33/200, Iteration 173/250, Loss: 0.0151\n",
      "Epoch 33/200, Iteration 174/250, Loss: 0.0113\n",
      "Epoch 33/200, Iteration 175/250, Loss: 0.0183\n",
      "Epoch 33/200, Iteration 176/250, Loss: 0.0197\n",
      "Epoch 33/200, Iteration 177/250, Loss: 0.0590\n",
      "Epoch 33/200, Iteration 178/250, Loss: 0.0101\n",
      "Epoch 33/200, Iteration 179/250, Loss: 0.0114\n",
      "Epoch 33/200, Iteration 180/250, Loss: 0.0270\n",
      "Epoch 33/200, Iteration 181/250, Loss: 0.0117\n",
      "Epoch 33/200, Iteration 182/250, Loss: 0.0177\n",
      "Epoch 33/200, Iteration 183/250, Loss: 0.0110\n",
      "Epoch 33/200, Iteration 184/250, Loss: 0.0126\n",
      "Epoch 33/200, Iteration 185/250, Loss: 0.0238\n",
      "Epoch 33/200, Iteration 186/250, Loss: 0.0289\n",
      "Epoch 33/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 33/200, Iteration 188/250, Loss: 0.0188\n",
      "Epoch 33/200, Iteration 189/250, Loss: 0.0154\n",
      "Epoch 33/200, Iteration 190/250, Loss: 0.0265\n",
      "Epoch 33/200, Iteration 191/250, Loss: 0.0077\n",
      "Epoch 33/200, Iteration 192/250, Loss: 0.0118\n",
      "Epoch 33/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 33/200, Iteration 194/250, Loss: 0.0123\n",
      "Epoch 33/200, Iteration 195/250, Loss: 0.0194\n",
      "Epoch 33/200, Iteration 196/250, Loss: 0.0199\n",
      "Epoch 33/200, Iteration 197/250, Loss: 0.0150\n",
      "Epoch 33/200, Iteration 198/250, Loss: 0.0104\n",
      "Epoch 33/200, Iteration 199/250, Loss: 0.0123\n",
      "Epoch 33/200, Iteration 200/250, Loss: 0.0166\n",
      "Epoch 33/200, Iteration 201/250, Loss: 0.0119\n",
      "Epoch 33/200, Iteration 202/250, Loss: 0.0120\n",
      "Epoch 33/200, Iteration 203/250, Loss: 0.0128\n",
      "Epoch 33/200, Iteration 204/250, Loss: 0.0286\n",
      "Epoch 33/200, Iteration 205/250, Loss: 0.0187\n",
      "Epoch 33/200, Iteration 206/250, Loss: 0.0289\n",
      "Epoch 33/200, Iteration 207/250, Loss: 0.0121\n",
      "Epoch 33/200, Iteration 208/250, Loss: 0.0288\n",
      "Epoch 33/200, Iteration 209/250, Loss: 0.0124\n",
      "Epoch 33/200, Iteration 210/250, Loss: 0.0111\n",
      "Epoch 33/200, Iteration 211/250, Loss: 0.0180\n",
      "Epoch 33/200, Iteration 212/250, Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Iteration 213/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 214/250, Loss: 0.0308\n",
      "Epoch 33/200, Iteration 215/250, Loss: 0.0227\n",
      "Epoch 33/200, Iteration 216/250, Loss: 0.0089\n",
      "Epoch 33/200, Iteration 217/250, Loss: 0.0067\n",
      "Epoch 33/200, Iteration 218/250, Loss: 0.0200\n",
      "Epoch 33/200, Iteration 219/250, Loss: 0.0114\n",
      "Epoch 33/200, Iteration 220/250, Loss: 0.0207\n",
      "Epoch 33/200, Iteration 221/250, Loss: 0.0288\n",
      "Epoch 33/200, Iteration 222/250, Loss: 0.0225\n",
      "Epoch 33/200, Iteration 223/250, Loss: 0.0081\n",
      "Epoch 33/200, Iteration 224/250, Loss: 0.0363\n",
      "Epoch 33/200, Iteration 225/250, Loss: 0.0107\n",
      "Epoch 33/200, Iteration 226/250, Loss: 0.0121\n",
      "Epoch 33/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 33/200, Iteration 228/250, Loss: 0.0299\n",
      "Epoch 33/200, Iteration 229/250, Loss: 0.0302\n",
      "Epoch 33/200, Iteration 230/250, Loss: 0.0205\n",
      "Epoch 33/200, Iteration 231/250, Loss: 0.0166\n",
      "Epoch 33/200, Iteration 232/250, Loss: 0.0199\n",
      "Epoch 33/200, Iteration 233/250, Loss: 0.0328\n",
      "Epoch 33/200, Iteration 234/250, Loss: 0.0123\n",
      "Epoch 33/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 33/200, Iteration 236/250, Loss: 0.0117\n",
      "Epoch 33/200, Iteration 237/250, Loss: 0.0147\n",
      "Epoch 33/200, Iteration 238/250, Loss: 0.0455\n",
      "Epoch 33/200, Iteration 239/250, Loss: 0.0272\n",
      "Epoch 33/200, Iteration 240/250, Loss: 0.0334\n",
      "Epoch 33/200, Iteration 241/250, Loss: 0.0227\n",
      "Epoch 33/200, Iteration 242/250, Loss: 0.0113\n",
      "Epoch 33/200, Iteration 243/250, Loss: 0.0174\n",
      "Epoch 33/200, Iteration 244/250, Loss: 0.0453\n",
      "Epoch 33/200, Iteration 245/250, Loss: 0.0118\n",
      "Epoch 33/200, Iteration 246/250, Loss: 0.0179\n",
      "Epoch 33/200, Iteration 247/250, Loss: 0.0119\n",
      "Epoch 33/200, Iteration 248/250, Loss: 0.0148\n",
      "Epoch 33/200, Iteration 249/250, Loss: 0.0202\n",
      "Epoch 33/200, Iteration 250/250, Loss: 0.0078\n",
      "Train Error: \n",
      " Accuracy: 74.41%, Avg loss: 0.009111, MRE: 0.730469 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.009027, MRE: 0.980007 \n",
      "\n",
      "Epoch 34/200, Iteration 1/250, Loss: 0.0248\n",
      "Epoch 34/200, Iteration 2/250, Loss: 0.0130\n",
      "Epoch 34/200, Iteration 3/250, Loss: 0.0072\n",
      "Epoch 34/200, Iteration 4/250, Loss: 0.0213\n",
      "Epoch 34/200, Iteration 5/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 34/200, Iteration 7/250, Loss: 0.0141\n",
      "Epoch 34/200, Iteration 8/250, Loss: 0.0140\n",
      "Epoch 34/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 34/200, Iteration 10/250, Loss: 0.0146\n",
      "Epoch 34/200, Iteration 11/250, Loss: 0.0242\n",
      "Epoch 34/200, Iteration 12/250, Loss: 0.0257\n",
      "Epoch 34/200, Iteration 13/250, Loss: 0.0193\n",
      "Epoch 34/200, Iteration 14/250, Loss: 0.0111\n",
      "Epoch 34/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 34/200, Iteration 16/250, Loss: 0.0258\n",
      "Epoch 34/200, Iteration 17/250, Loss: 0.0228\n",
      "Epoch 34/200, Iteration 18/250, Loss: 0.0115\n",
      "Epoch 34/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 34/200, Iteration 20/250, Loss: 0.0203\n",
      "Epoch 34/200, Iteration 21/250, Loss: 0.0268\n",
      "Epoch 34/200, Iteration 22/250, Loss: 0.0144\n",
      "Epoch 34/200, Iteration 23/250, Loss: 0.0251\n",
      "Epoch 34/200, Iteration 24/250, Loss: 0.0114\n",
      "Epoch 34/200, Iteration 25/250, Loss: 0.0095\n",
      "Epoch 34/200, Iteration 26/250, Loss: 0.0164\n",
      "Epoch 34/200, Iteration 27/250, Loss: 0.0144\n",
      "Epoch 34/200, Iteration 28/250, Loss: 0.0102\n",
      "Epoch 34/200, Iteration 29/250, Loss: 0.0115\n",
      "Epoch 34/200, Iteration 30/250, Loss: 0.0115\n",
      "Epoch 34/200, Iteration 31/250, Loss: 0.0121\n",
      "Epoch 34/200, Iteration 32/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 33/250, Loss: 0.0176\n",
      "Epoch 34/200, Iteration 34/250, Loss: 0.0393\n",
      "Epoch 34/200, Iteration 35/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 36/250, Loss: 0.0181\n",
      "Epoch 34/200, Iteration 37/250, Loss: 0.0106\n",
      "Epoch 34/200, Iteration 38/250, Loss: 0.0119\n",
      "Epoch 34/200, Iteration 39/250, Loss: 0.0394\n",
      "Epoch 34/200, Iteration 40/250, Loss: 0.0309\n",
      "Epoch 34/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 34/200, Iteration 42/250, Loss: 0.0080\n",
      "Epoch 34/200, Iteration 43/250, Loss: 0.0126\n",
      "Epoch 34/200, Iteration 44/250, Loss: 0.0251\n",
      "Epoch 34/200, Iteration 45/250, Loss: 0.0129\n",
      "Epoch 34/200, Iteration 46/250, Loss: 0.0124\n",
      "Epoch 34/200, Iteration 47/250, Loss: 0.0183\n",
      "Epoch 34/200, Iteration 48/250, Loss: 0.0119\n",
      "Epoch 34/200, Iteration 49/250, Loss: 0.0403\n",
      "Epoch 34/200, Iteration 50/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 51/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 52/250, Loss: 0.0107\n",
      "Epoch 34/200, Iteration 53/250, Loss: 0.0216\n",
      "Epoch 34/200, Iteration 54/250, Loss: 0.0150\n",
      "Epoch 34/200, Iteration 55/250, Loss: 0.0253\n",
      "Epoch 34/200, Iteration 56/250, Loss: 0.0147\n",
      "Epoch 34/200, Iteration 57/250, Loss: 0.0103\n",
      "Epoch 34/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 34/200, Iteration 59/250, Loss: 0.0096\n",
      "Epoch 34/200, Iteration 60/250, Loss: 0.0120\n",
      "Epoch 34/200, Iteration 61/250, Loss: 0.0092\n",
      "Epoch 34/200, Iteration 62/250, Loss: 0.0201\n",
      "Epoch 34/200, Iteration 63/250, Loss: 0.0086\n",
      "Epoch 34/200, Iteration 64/250, Loss: 0.0189\n",
      "Epoch 34/200, Iteration 65/250, Loss: 0.0105\n",
      "Epoch 34/200, Iteration 66/250, Loss: 0.0083\n",
      "Epoch 34/200, Iteration 67/250, Loss: 0.0358\n",
      "Epoch 34/200, Iteration 68/250, Loss: 0.0099\n",
      "Epoch 34/200, Iteration 69/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 70/250, Loss: 0.0137\n",
      "Epoch 34/200, Iteration 71/250, Loss: 0.0185\n",
      "Epoch 34/200, Iteration 72/250, Loss: 0.0162\n",
      "Epoch 34/200, Iteration 73/250, Loss: 0.0163\n",
      "Epoch 34/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 34/200, Iteration 75/250, Loss: 0.0158\n",
      "Epoch 34/200, Iteration 76/250, Loss: 0.0142\n",
      "Epoch 34/200, Iteration 77/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 78/250, Loss: 0.0234\n",
      "Epoch 34/200, Iteration 79/250, Loss: 0.0285\n",
      "Epoch 34/200, Iteration 80/250, Loss: 0.0181\n",
      "Epoch 34/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 34/200, Iteration 82/250, Loss: 0.0111\n",
      "Epoch 34/200, Iteration 83/250, Loss: 0.0348\n",
      "Epoch 34/200, Iteration 84/250, Loss: 0.0101\n",
      "Epoch 34/200, Iteration 85/250, Loss: 0.0235\n",
      "Epoch 34/200, Iteration 86/250, Loss: 0.0138\n",
      "Epoch 34/200, Iteration 87/250, Loss: 0.0117\n",
      "Epoch 34/200, Iteration 88/250, Loss: 0.0317\n",
      "Epoch 34/200, Iteration 89/250, Loss: 0.0184\n",
      "Epoch 34/200, Iteration 90/250, Loss: 0.0118\n",
      "Epoch 34/200, Iteration 91/250, Loss: 0.0108\n",
      "Epoch 34/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 34/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 34/200, Iteration 94/250, Loss: 0.0147\n",
      "Epoch 34/200, Iteration 95/250, Loss: 0.0320\n",
      "Epoch 34/200, Iteration 96/250, Loss: 0.0156\n",
      "Epoch 34/200, Iteration 97/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 98/250, Loss: 0.0118\n",
      "Epoch 34/200, Iteration 99/250, Loss: 0.0097\n",
      "Epoch 34/200, Iteration 100/250, Loss: 0.0084\n",
      "Epoch 34/200, Iteration 101/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 102/250, Loss: 0.0338\n",
      "Epoch 34/200, Iteration 103/250, Loss: 0.0189\n",
      "Epoch 34/200, Iteration 104/250, Loss: 0.0139\n",
      "Epoch 34/200, Iteration 105/250, Loss: 0.0116\n",
      "Epoch 34/200, Iteration 106/250, Loss: 0.0089\n",
      "Epoch 34/200, Iteration 107/250, Loss: 0.0177\n",
      "Epoch 34/200, Iteration 108/250, Loss: 0.0090\n",
      "Epoch 34/200, Iteration 109/250, Loss: 0.0168\n",
      "Epoch 34/200, Iteration 110/250, Loss: 0.0104\n",
      "Epoch 34/200, Iteration 111/250, Loss: 0.0268\n",
      "Epoch 34/200, Iteration 112/250, Loss: 0.0091\n",
      "Epoch 34/200, Iteration 113/250, Loss: 0.0127\n",
      "Epoch 34/200, Iteration 114/250, Loss: 0.0240\n",
      "Epoch 34/200, Iteration 115/250, Loss: 0.0071\n",
      "Epoch 34/200, Iteration 116/250, Loss: 0.0134\n",
      "Epoch 34/200, Iteration 117/250, Loss: 0.0190\n",
      "Epoch 34/200, Iteration 118/250, Loss: 0.0252\n",
      "Epoch 34/200, Iteration 119/250, Loss: 0.0145\n",
      "Epoch 34/200, Iteration 120/250, Loss: 0.0367\n",
      "Epoch 34/200, Iteration 121/250, Loss: 0.0081\n",
      "Epoch 34/200, Iteration 122/250, Loss: 0.0132\n",
      "Epoch 34/200, Iteration 123/250, Loss: 0.0198\n",
      "Epoch 34/200, Iteration 124/250, Loss: 0.0098\n",
      "Epoch 34/200, Iteration 125/250, Loss: 0.0139\n",
      "Epoch 34/200, Iteration 126/250, Loss: 0.0122\n",
      "Epoch 34/200, Iteration 127/250, Loss: 0.0190\n",
      "Epoch 34/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 34/200, Iteration 129/250, Loss: 0.0143\n",
      "Epoch 34/200, Iteration 130/250, Loss: 0.0150\n",
      "Epoch 34/200, Iteration 131/250, Loss: 0.0096\n",
      "Epoch 34/200, Iteration 132/250, Loss: 0.0107\n",
      "Epoch 34/200, Iteration 133/250, Loss: 0.0074\n",
      "Epoch 34/200, Iteration 134/250, Loss: 0.0170\n",
      "Epoch 34/200, Iteration 135/250, Loss: 0.0347\n",
      "Epoch 34/200, Iteration 136/250, Loss: 0.0097\n",
      "Epoch 34/200, Iteration 137/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 138/250, Loss: 0.0267\n",
      "Epoch 34/200, Iteration 139/250, Loss: 0.0075\n",
      "Epoch 34/200, Iteration 140/250, Loss: 0.0075\n",
      "Epoch 34/200, Iteration 141/250, Loss: 0.0229\n",
      "Epoch 34/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 34/200, Iteration 143/250, Loss: 0.0100\n",
      "Epoch 34/200, Iteration 144/250, Loss: 0.0204\n",
      "Epoch 34/200, Iteration 145/250, Loss: 0.0167\n",
      "Epoch 34/200, Iteration 146/250, Loss: 0.0198\n",
      "Epoch 34/200, Iteration 147/250, Loss: 0.0242\n",
      "Epoch 34/200, Iteration 148/250, Loss: 0.0128\n",
      "Epoch 34/200, Iteration 149/250, Loss: 0.0305\n",
      "Epoch 34/200, Iteration 150/250, Loss: 0.0079\n",
      "Epoch 34/200, Iteration 151/250, Loss: 0.0145\n",
      "Epoch 34/200, Iteration 152/250, Loss: 0.0097\n",
      "Epoch 34/200, Iteration 153/250, Loss: 0.0167\n",
      "Epoch 34/200, Iteration 154/250, Loss: 0.0142\n",
      "Epoch 34/200, Iteration 155/250, Loss: 0.0089\n",
      "Epoch 34/200, Iteration 156/250, Loss: 0.0121\n",
      "Epoch 34/200, Iteration 157/250, Loss: 0.0132\n",
      "Epoch 34/200, Iteration 158/250, Loss: 0.0091\n",
      "Epoch 34/200, Iteration 159/250, Loss: 0.0122\n",
      "Epoch 34/200, Iteration 160/250, Loss: 0.0103\n",
      "Epoch 34/200, Iteration 161/250, Loss: 0.0402\n",
      "Epoch 34/200, Iteration 162/250, Loss: 0.0183\n",
      "Epoch 34/200, Iteration 163/250, Loss: 0.0072\n",
      "Epoch 34/200, Iteration 164/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 165/250, Loss: 0.0095\n",
      "Epoch 34/200, Iteration 166/250, Loss: 0.0107\n",
      "Epoch 34/200, Iteration 167/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 168/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 169/250, Loss: 0.0064\n",
      "Epoch 34/200, Iteration 170/250, Loss: 0.0156\n",
      "Epoch 34/200, Iteration 171/250, Loss: 0.0105\n",
      "Epoch 34/200, Iteration 172/250, Loss: 0.0070\n",
      "Epoch 34/200, Iteration 173/250, Loss: 0.0071\n",
      "Epoch 34/200, Iteration 174/250, Loss: 0.0097\n",
      "Epoch 34/200, Iteration 175/250, Loss: 0.0223\n",
      "Epoch 34/200, Iteration 176/250, Loss: 0.0215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Iteration 177/250, Loss: 0.0144\n",
      "Epoch 34/200, Iteration 178/250, Loss: 0.0187\n",
      "Epoch 34/200, Iteration 179/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 180/250, Loss: 0.0076\n",
      "Epoch 34/200, Iteration 181/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 34/200, Iteration 183/250, Loss: 0.0210\n",
      "Epoch 34/200, Iteration 184/250, Loss: 0.0074\n",
      "Epoch 34/200, Iteration 185/250, Loss: 0.0299\n",
      "Epoch 34/200, Iteration 186/250, Loss: 0.0093\n",
      "Epoch 34/200, Iteration 187/250, Loss: 0.0092\n",
      "Epoch 34/200, Iteration 188/250, Loss: 0.0116\n",
      "Epoch 34/200, Iteration 189/250, Loss: 0.0127\n",
      "Epoch 34/200, Iteration 190/250, Loss: 0.0115\n",
      "Epoch 34/200, Iteration 191/250, Loss: 0.0221\n",
      "Epoch 34/200, Iteration 192/250, Loss: 0.0122\n",
      "Epoch 34/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 34/200, Iteration 194/250, Loss: 0.0268\n",
      "Epoch 34/200, Iteration 195/250, Loss: 0.0134\n",
      "Epoch 34/200, Iteration 196/250, Loss: 0.0071\n",
      "Epoch 34/200, Iteration 197/250, Loss: 0.0132\n",
      "Epoch 34/200, Iteration 198/250, Loss: 0.0087\n",
      "Epoch 34/200, Iteration 199/250, Loss: 0.0100\n",
      "Epoch 34/200, Iteration 200/250, Loss: 0.0103\n",
      "Epoch 34/200, Iteration 201/250, Loss: 0.0123\n",
      "Epoch 34/200, Iteration 202/250, Loss: 0.0184\n",
      "Epoch 34/200, Iteration 203/250, Loss: 0.0087\n",
      "Epoch 34/200, Iteration 204/250, Loss: 0.0140\n",
      "Epoch 34/200, Iteration 205/250, Loss: 0.0100\n",
      "Epoch 34/200, Iteration 206/250, Loss: 0.0229\n",
      "Epoch 34/200, Iteration 207/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 208/250, Loss: 0.0107\n",
      "Epoch 34/200, Iteration 209/250, Loss: 0.0275\n",
      "Epoch 34/200, Iteration 210/250, Loss: 0.0163\n",
      "Epoch 34/200, Iteration 211/250, Loss: 0.0083\n",
      "Epoch 34/200, Iteration 212/250, Loss: 0.0193\n",
      "Epoch 34/200, Iteration 213/250, Loss: 0.0280\n",
      "Epoch 34/200, Iteration 214/250, Loss: 0.0125\n",
      "Epoch 34/200, Iteration 215/250, Loss: 0.0131\n",
      "Epoch 34/200, Iteration 216/250, Loss: 0.0154\n",
      "Epoch 34/200, Iteration 217/250, Loss: 0.0127\n",
      "Epoch 34/200, Iteration 218/250, Loss: 0.0089\n",
      "Epoch 34/200, Iteration 219/250, Loss: 0.0103\n",
      "Epoch 34/200, Iteration 220/250, Loss: 0.0174\n",
      "Epoch 34/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 34/200, Iteration 222/250, Loss: 0.0162\n",
      "Epoch 34/200, Iteration 223/250, Loss: 0.0207\n",
      "Epoch 34/200, Iteration 224/250, Loss: 0.0205\n",
      "Epoch 34/200, Iteration 225/250, Loss: 0.0075\n",
      "Epoch 34/200, Iteration 226/250, Loss: 0.0110\n",
      "Epoch 34/200, Iteration 227/250, Loss: 0.0173\n",
      "Epoch 34/200, Iteration 228/250, Loss: 0.0196\n",
      "Epoch 34/200, Iteration 229/250, Loss: 0.0099\n",
      "Epoch 34/200, Iteration 230/250, Loss: 0.0082\n",
      "Epoch 34/200, Iteration 231/250, Loss: 0.0104\n",
      "Epoch 34/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 34/200, Iteration 233/250, Loss: 0.0241\n",
      "Epoch 34/200, Iteration 234/250, Loss: 0.0092\n",
      "Epoch 34/200, Iteration 235/250, Loss: 0.0101\n",
      "Epoch 34/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 34/200, Iteration 237/250, Loss: 0.0084\n",
      "Epoch 34/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 34/200, Iteration 239/250, Loss: 0.0093\n",
      "Epoch 34/200, Iteration 240/250, Loss: 0.0106\n",
      "Epoch 34/200, Iteration 241/250, Loss: 0.0184\n",
      "Epoch 34/200, Iteration 242/250, Loss: 0.0118\n",
      "Epoch 34/200, Iteration 243/250, Loss: 0.0233\n",
      "Epoch 34/200, Iteration 244/250, Loss: 0.0231\n",
      "Epoch 34/200, Iteration 245/250, Loss: 0.0077\n",
      "Epoch 34/200, Iteration 246/250, Loss: 0.0125\n",
      "Epoch 34/200, Iteration 247/250, Loss: 0.0199\n",
      "Epoch 34/200, Iteration 248/250, Loss: 0.0084\n",
      "Epoch 34/200, Iteration 249/250, Loss: 0.0324\n",
      "Epoch 34/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.009648, MRE: 0.911177 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.009591, MRE: 1.643393 \n",
      "\n",
      "Epoch 35/200, Iteration 1/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 2/250, Loss: 0.0114\n",
      "Epoch 35/200, Iteration 3/250, Loss: 0.0093\n",
      "Epoch 35/200, Iteration 4/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 5/250, Loss: 0.0145\n",
      "Epoch 35/200, Iteration 6/250, Loss: 0.0093\n",
      "Epoch 35/200, Iteration 7/250, Loss: 0.0253\n",
      "Epoch 35/200, Iteration 8/250, Loss: 0.0118\n",
      "Epoch 35/200, Iteration 9/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 10/250, Loss: 0.0151\n",
      "Epoch 35/200, Iteration 11/250, Loss: 0.0526\n",
      "Epoch 35/200, Iteration 12/250, Loss: 0.0073\n",
      "Epoch 35/200, Iteration 13/250, Loss: 0.0166\n",
      "Epoch 35/200, Iteration 14/250, Loss: 0.0146\n",
      "Epoch 35/200, Iteration 15/250, Loss: 0.0157\n",
      "Epoch 35/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 35/200, Iteration 17/250, Loss: 0.0076\n",
      "Epoch 35/200, Iteration 18/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 35/200, Iteration 20/250, Loss: 0.0091\n",
      "Epoch 35/200, Iteration 21/250, Loss: 0.0108\n",
      "Epoch 35/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 35/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 35/200, Iteration 24/250, Loss: 0.0074\n",
      "Epoch 35/200, Iteration 25/250, Loss: 0.0119\n",
      "Epoch 35/200, Iteration 26/250, Loss: 0.0129\n",
      "Epoch 35/200, Iteration 27/250, Loss: 0.0151\n",
      "Epoch 35/200, Iteration 28/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 29/250, Loss: 0.0151\n",
      "Epoch 35/200, Iteration 30/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 31/250, Loss: 0.0148\n",
      "Epoch 35/200, Iteration 32/250, Loss: 0.0179\n",
      "Epoch 35/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 35/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 35/250, Loss: 0.0119\n",
      "Epoch 35/200, Iteration 36/250, Loss: 0.0077\n",
      "Epoch 35/200, Iteration 37/250, Loss: 0.0166\n",
      "Epoch 35/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 35/200, Iteration 39/250, Loss: 0.0190\n",
      "Epoch 35/200, Iteration 40/250, Loss: 0.0084\n",
      "Epoch 35/200, Iteration 41/250, Loss: 0.0338\n",
      "Epoch 35/200, Iteration 42/250, Loss: 0.0336\n",
      "Epoch 35/200, Iteration 43/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 44/250, Loss: 0.0113\n",
      "Epoch 35/200, Iteration 45/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 46/250, Loss: 0.0153\n",
      "Epoch 35/200, Iteration 47/250, Loss: 0.0195\n",
      "Epoch 35/200, Iteration 48/250, Loss: 0.0238\n",
      "Epoch 35/200, Iteration 49/250, Loss: 0.0200\n",
      "Epoch 35/200, Iteration 50/250, Loss: 0.0109\n",
      "Epoch 35/200, Iteration 51/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 52/250, Loss: 0.0296\n",
      "Epoch 35/200, Iteration 53/250, Loss: 0.0113\n",
      "Epoch 35/200, Iteration 54/250, Loss: 0.0137\n",
      "Epoch 35/200, Iteration 55/250, Loss: 0.0093\n",
      "Epoch 35/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 35/200, Iteration 57/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 58/250, Loss: 0.0097\n",
      "Epoch 35/200, Iteration 59/250, Loss: 0.0212\n",
      "Epoch 35/200, Iteration 60/250, Loss: 0.0163\n",
      "Epoch 35/200, Iteration 61/250, Loss: 0.0078\n",
      "Epoch 35/200, Iteration 62/250, Loss: 0.0096\n",
      "Epoch 35/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 64/250, Loss: 0.0096\n",
      "Epoch 35/200, Iteration 65/250, Loss: 0.0146\n",
      "Epoch 35/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 67/250, Loss: 0.0239\n",
      "Epoch 35/200, Iteration 68/250, Loss: 0.0381\n",
      "Epoch 35/200, Iteration 69/250, Loss: 0.0097\n",
      "Epoch 35/200, Iteration 70/250, Loss: 0.0123\n",
      "Epoch 35/200, Iteration 71/250, Loss: 0.0337\n",
      "Epoch 35/200, Iteration 72/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 73/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 74/250, Loss: 0.0183\n",
      "Epoch 35/200, Iteration 75/250, Loss: 0.0315\n",
      "Epoch 35/200, Iteration 76/250, Loss: 0.0082\n",
      "Epoch 35/200, Iteration 77/250, Loss: 0.0125\n",
      "Epoch 35/200, Iteration 78/250, Loss: 0.0081\n",
      "Epoch 35/200, Iteration 79/250, Loss: 0.0136\n",
      "Epoch 35/200, Iteration 80/250, Loss: 0.0077\n",
      "Epoch 35/200, Iteration 81/250, Loss: 0.0234\n",
      "Epoch 35/200, Iteration 82/250, Loss: 0.0117\n",
      "Epoch 35/200, Iteration 83/250, Loss: 0.0093\n",
      "Epoch 35/200, Iteration 84/250, Loss: 0.0242\n",
      "Epoch 35/200, Iteration 85/250, Loss: 0.0170\n",
      "Epoch 35/200, Iteration 86/250, Loss: 0.0096\n",
      "Epoch 35/200, Iteration 87/250, Loss: 0.0222\n",
      "Epoch 35/200, Iteration 88/250, Loss: 0.0161\n",
      "Epoch 35/200, Iteration 89/250, Loss: 0.0141\n",
      "Epoch 35/200, Iteration 90/250, Loss: 0.0238\n",
      "Epoch 35/200, Iteration 91/250, Loss: 0.0085\n",
      "Epoch 35/200, Iteration 92/250, Loss: 0.0091\n",
      "Epoch 35/200, Iteration 93/250, Loss: 0.0306\n",
      "Epoch 35/200, Iteration 94/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 35/200, Iteration 96/250, Loss: 0.0560\n",
      "Epoch 35/200, Iteration 97/250, Loss: 0.0201\n",
      "Epoch 35/200, Iteration 98/250, Loss: 0.0189\n",
      "Epoch 35/200, Iteration 99/250, Loss: 0.0118\n",
      "Epoch 35/200, Iteration 100/250, Loss: 0.0224\n",
      "Epoch 35/200, Iteration 101/250, Loss: 0.0119\n",
      "Epoch 35/200, Iteration 102/250, Loss: 0.0120\n",
      "Epoch 35/200, Iteration 103/250, Loss: 0.0148\n",
      "Epoch 35/200, Iteration 104/250, Loss: 0.0095\n",
      "Epoch 35/200, Iteration 105/250, Loss: 0.0220\n",
      "Epoch 35/200, Iteration 106/250, Loss: 0.0250\n",
      "Epoch 35/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 35/200, Iteration 108/250, Loss: 0.0269\n",
      "Epoch 35/200, Iteration 109/250, Loss: 0.0078\n",
      "Epoch 35/200, Iteration 110/250, Loss: 0.0082\n",
      "Epoch 35/200, Iteration 111/250, Loss: 0.0311\n",
      "Epoch 35/200, Iteration 112/250, Loss: 0.0090\n",
      "Epoch 35/200, Iteration 113/250, Loss: 0.0079\n",
      "Epoch 35/200, Iteration 114/250, Loss: 0.0243\n",
      "Epoch 35/200, Iteration 115/250, Loss: 0.0123\n",
      "Epoch 35/200, Iteration 116/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 117/250, Loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Iteration 118/250, Loss: 0.0116\n",
      "Epoch 35/200, Iteration 119/250, Loss: 0.0241\n",
      "Epoch 35/200, Iteration 120/250, Loss: 0.0134\n",
      "Epoch 35/200, Iteration 121/250, Loss: 0.0113\n",
      "Epoch 35/200, Iteration 122/250, Loss: 0.0205\n",
      "Epoch 35/200, Iteration 123/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 124/250, Loss: 0.0228\n",
      "Epoch 35/200, Iteration 125/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 126/250, Loss: 0.0111\n",
      "Epoch 35/200, Iteration 127/250, Loss: 0.0091\n",
      "Epoch 35/200, Iteration 128/250, Loss: 0.0390\n",
      "Epoch 35/200, Iteration 129/250, Loss: 0.0485\n",
      "Epoch 35/200, Iteration 130/250, Loss: 0.0280\n",
      "Epoch 35/200, Iteration 131/250, Loss: 0.0278\n",
      "Epoch 35/200, Iteration 132/250, Loss: 0.0420\n",
      "Epoch 35/200, Iteration 133/250, Loss: 0.0305\n",
      "Epoch 35/200, Iteration 134/250, Loss: 0.0105\n",
      "Epoch 35/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 35/200, Iteration 136/250, Loss: 0.0229\n",
      "Epoch 35/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 138/250, Loss: 0.0077\n",
      "Epoch 35/200, Iteration 139/250, Loss: 0.0429\n",
      "Epoch 35/200, Iteration 140/250, Loss: 0.0089\n",
      "Epoch 35/200, Iteration 141/250, Loss: 0.0090\n",
      "Epoch 35/200, Iteration 142/250, Loss: 0.0113\n",
      "Epoch 35/200, Iteration 143/250, Loss: 0.0303\n",
      "Epoch 35/200, Iteration 144/250, Loss: 0.0237\n",
      "Epoch 35/200, Iteration 145/250, Loss: 0.0146\n",
      "Epoch 35/200, Iteration 146/250, Loss: 0.0199\n",
      "Epoch 35/200, Iteration 147/250, Loss: 0.0284\n",
      "Epoch 35/200, Iteration 148/250, Loss: 0.0175\n",
      "Epoch 35/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 35/200, Iteration 150/250, Loss: 0.0476\n",
      "Epoch 35/200, Iteration 151/250, Loss: 0.0109\n",
      "Epoch 35/200, Iteration 152/250, Loss: 0.0101\n",
      "Epoch 35/200, Iteration 153/250, Loss: 0.0072\n",
      "Epoch 35/200, Iteration 154/250, Loss: 0.0094\n",
      "Epoch 35/200, Iteration 155/250, Loss: 0.0420\n",
      "Epoch 35/200, Iteration 156/250, Loss: 0.0110\n",
      "Epoch 35/200, Iteration 157/250, Loss: 0.0202\n",
      "Epoch 35/200, Iteration 158/250, Loss: 0.0173\n",
      "Epoch 35/200, Iteration 159/250, Loss: 0.0203\n",
      "Epoch 35/200, Iteration 160/250, Loss: 0.0084\n",
      "Epoch 35/200, Iteration 161/250, Loss: 0.0197\n",
      "Epoch 35/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 35/200, Iteration 163/250, Loss: 0.0129\n",
      "Epoch 35/200, Iteration 164/250, Loss: 0.0256\n",
      "Epoch 35/200, Iteration 165/250, Loss: 0.0415\n",
      "Epoch 35/200, Iteration 166/250, Loss: 0.0097\n",
      "Epoch 35/200, Iteration 167/250, Loss: 0.0131\n",
      "Epoch 35/200, Iteration 168/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 169/250, Loss: 0.0376\n",
      "Epoch 35/200, Iteration 170/250, Loss: 0.0243\n",
      "Epoch 35/200, Iteration 171/250, Loss: 0.0094\n",
      "Epoch 35/200, Iteration 172/250, Loss: 0.0070\n",
      "Epoch 35/200, Iteration 173/250, Loss: 0.0157\n",
      "Epoch 35/200, Iteration 174/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 175/250, Loss: 0.0126\n",
      "Epoch 35/200, Iteration 176/250, Loss: 0.0084\n",
      "Epoch 35/200, Iteration 177/250, Loss: 0.0099\n",
      "Epoch 35/200, Iteration 178/250, Loss: 0.0181\n",
      "Epoch 35/200, Iteration 179/250, Loss: 0.0090\n",
      "Epoch 35/200, Iteration 180/250, Loss: 0.0094\n",
      "Epoch 35/200, Iteration 181/250, Loss: 0.0160\n",
      "Epoch 35/200, Iteration 182/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 183/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 184/250, Loss: 0.0172\n",
      "Epoch 35/200, Iteration 185/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 186/250, Loss: 0.0205\n",
      "Epoch 35/200, Iteration 187/250, Loss: 0.0121\n",
      "Epoch 35/200, Iteration 188/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 189/250, Loss: 0.0111\n",
      "Epoch 35/200, Iteration 190/250, Loss: 0.0168\n",
      "Epoch 35/200, Iteration 191/250, Loss: 0.0146\n",
      "Epoch 35/200, Iteration 192/250, Loss: 0.0087\n",
      "Epoch 35/200, Iteration 193/250, Loss: 0.0233\n",
      "Epoch 35/200, Iteration 194/250, Loss: 0.0233\n",
      "Epoch 35/200, Iteration 195/250, Loss: 0.0221\n",
      "Epoch 35/200, Iteration 196/250, Loss: 0.0190\n",
      "Epoch 35/200, Iteration 197/250, Loss: 0.0141\n",
      "Epoch 35/200, Iteration 198/250, Loss: 0.0090\n",
      "Epoch 35/200, Iteration 199/250, Loss: 0.0183\n",
      "Epoch 35/200, Iteration 200/250, Loss: 0.0156\n",
      "Epoch 35/200, Iteration 201/250, Loss: 0.0112\n",
      "Epoch 35/200, Iteration 202/250, Loss: 0.0150\n",
      "Epoch 35/200, Iteration 203/250, Loss: 0.0084\n",
      "Epoch 35/200, Iteration 204/250, Loss: 0.0139\n",
      "Epoch 35/200, Iteration 205/250, Loss: 0.0131\n",
      "Epoch 35/200, Iteration 206/250, Loss: 0.0338\n",
      "Epoch 35/200, Iteration 207/250, Loss: 0.0086\n",
      "Epoch 35/200, Iteration 208/250, Loss: 0.0158\n",
      "Epoch 35/200, Iteration 209/250, Loss: 0.0085\n",
      "Epoch 35/200, Iteration 210/250, Loss: 0.0212\n",
      "Epoch 35/200, Iteration 211/250, Loss: 0.0133\n",
      "Epoch 35/200, Iteration 212/250, Loss: 0.0184\n",
      "Epoch 35/200, Iteration 213/250, Loss: 0.0077\n",
      "Epoch 35/200, Iteration 214/250, Loss: 0.0309\n",
      "Epoch 35/200, Iteration 215/250, Loss: 0.0139\n",
      "Epoch 35/200, Iteration 216/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 217/250, Loss: 0.0246\n",
      "Epoch 35/200, Iteration 218/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 219/250, Loss: 0.0149\n",
      "Epoch 35/200, Iteration 220/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 221/250, Loss: 0.0171\n",
      "Epoch 35/200, Iteration 222/250, Loss: 0.0154\n",
      "Epoch 35/200, Iteration 223/250, Loss: 0.0122\n",
      "Epoch 35/200, Iteration 224/250, Loss: 0.0205\n",
      "Epoch 35/200, Iteration 225/250, Loss: 0.0176\n",
      "Epoch 35/200, Iteration 226/250, Loss: 0.0427\n",
      "Epoch 35/200, Iteration 227/250, Loss: 0.0123\n",
      "Epoch 35/200, Iteration 228/250, Loss: 0.0232\n",
      "Epoch 35/200, Iteration 229/250, Loss: 0.0195\n",
      "Epoch 35/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 35/200, Iteration 231/250, Loss: 0.0273\n",
      "Epoch 35/200, Iteration 232/250, Loss: 0.0142\n",
      "Epoch 35/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 35/200, Iteration 234/250, Loss: 0.0146\n",
      "Epoch 35/200, Iteration 235/250, Loss: 0.0095\n",
      "Epoch 35/200, Iteration 236/250, Loss: 0.0197\n",
      "Epoch 35/200, Iteration 237/250, Loss: 0.0079\n",
      "Epoch 35/200, Iteration 238/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 239/250, Loss: 0.0253\n",
      "Epoch 35/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 35/200, Iteration 241/250, Loss: 0.0331\n",
      "Epoch 35/200, Iteration 242/250, Loss: 0.0202\n",
      "Epoch 35/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 35/200, Iteration 244/250, Loss: 0.0136\n",
      "Epoch 35/200, Iteration 245/250, Loss: 0.0195\n",
      "Epoch 35/200, Iteration 246/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 247/250, Loss: 0.0177\n",
      "Epoch 35/200, Iteration 248/250, Loss: 0.0150\n",
      "Epoch 35/200, Iteration 249/250, Loss: 0.0287\n",
      "Epoch 35/200, Iteration 250/250, Loss: 0.0143\n",
      "Train Error: \n",
      " Accuracy: 87.66%, Avg loss: 0.007858, MRE: 0.592521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.55%, Avg loss: 0.007841, MRE: 1.125206 \n",
      "\n",
      "Epoch 36/200, Iteration 1/250, Loss: 0.0107\n",
      "Epoch 36/200, Iteration 2/250, Loss: 0.0080\n",
      "Epoch 36/200, Iteration 3/250, Loss: 0.0265\n",
      "Epoch 36/200, Iteration 4/250, Loss: 0.0163\n",
      "Epoch 36/200, Iteration 5/250, Loss: 0.0144\n",
      "Epoch 36/200, Iteration 6/250, Loss: 0.0439\n",
      "Epoch 36/200, Iteration 7/250, Loss: 0.0080\n",
      "Epoch 36/200, Iteration 8/250, Loss: 0.0102\n",
      "Epoch 36/200, Iteration 9/250, Loss: 0.0139\n",
      "Epoch 36/200, Iteration 10/250, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 11/250, Loss: 0.0314\n",
      "Epoch 36/200, Iteration 12/250, Loss: 0.0167\n",
      "Epoch 36/200, Iteration 13/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 14/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 15/250, Loss: 0.0082\n",
      "Epoch 36/200, Iteration 16/250, Loss: 0.0100\n",
      "Epoch 36/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 36/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 19/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 20/250, Loss: 0.0076\n",
      "Epoch 36/200, Iteration 21/250, Loss: 0.0210\n",
      "Epoch 36/200, Iteration 22/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 23/250, Loss: 0.0222\n",
      "Epoch 36/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 25/250, Loss: 0.0116\n",
      "Epoch 36/200, Iteration 26/250, Loss: 0.0139\n",
      "Epoch 36/200, Iteration 27/250, Loss: 0.0090\n",
      "Epoch 36/200, Iteration 28/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 29/250, Loss: 0.0103\n",
      "Epoch 36/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 31/250, Loss: 0.0094\n",
      "Epoch 36/200, Iteration 32/250, Loss: 0.0171\n",
      "Epoch 36/200, Iteration 33/250, Loss: 0.0308\n",
      "Epoch 36/200, Iteration 34/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 35/250, Loss: 0.0079\n",
      "Epoch 36/200, Iteration 36/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 37/250, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 38/250, Loss: 0.0080\n",
      "Epoch 36/200, Iteration 39/250, Loss: 0.0308\n",
      "Epoch 36/200, Iteration 40/250, Loss: 0.0192\n",
      "Epoch 36/200, Iteration 41/250, Loss: 0.0117\n",
      "Epoch 36/200, Iteration 42/250, Loss: 0.0181\n",
      "Epoch 36/200, Iteration 43/250, Loss: 0.0095\n",
      "Epoch 36/200, Iteration 44/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 45/250, Loss: 0.0142\n",
      "Epoch 36/200, Iteration 46/250, Loss: 0.0090\n",
      "Epoch 36/200, Iteration 47/250, Loss: 0.0145\n",
      "Epoch 36/200, Iteration 48/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 49/250, Loss: 0.0172\n",
      "Epoch 36/200, Iteration 50/250, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Iteration 51/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 52/250, Loss: 0.0237\n",
      "Epoch 36/200, Iteration 53/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 54/250, Loss: 0.0203\n",
      "Epoch 36/200, Iteration 55/250, Loss: 0.0109\n",
      "Epoch 36/200, Iteration 56/250, Loss: 0.0222\n",
      "Epoch 36/200, Iteration 57/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 58/250, Loss: 0.0110\n",
      "Epoch 36/200, Iteration 59/250, Loss: 0.0182\n",
      "Epoch 36/200, Iteration 60/250, Loss: 0.0176\n",
      "Epoch 36/200, Iteration 61/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 62/250, Loss: 0.0180\n",
      "Epoch 36/200, Iteration 63/250, Loss: 0.0275\n",
      "Epoch 36/200, Iteration 64/250, Loss: 0.0113\n",
      "Epoch 36/200, Iteration 65/250, Loss: 0.0185\n",
      "Epoch 36/200, Iteration 66/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 67/250, Loss: 0.0417\n",
      "Epoch 36/200, Iteration 68/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 69/250, Loss: 0.0077\n",
      "Epoch 36/200, Iteration 70/250, Loss: 0.0237\n",
      "Epoch 36/200, Iteration 71/250, Loss: 0.0236\n",
      "Epoch 36/200, Iteration 72/250, Loss: 0.0328\n",
      "Epoch 36/200, Iteration 73/250, Loss: 0.0090\n",
      "Epoch 36/200, Iteration 74/250, Loss: 0.0106\n",
      "Epoch 36/200, Iteration 75/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 76/250, Loss: 0.0233\n",
      "Epoch 36/200, Iteration 77/250, Loss: 0.0395\n",
      "Epoch 36/200, Iteration 78/250, Loss: 0.0096\n",
      "Epoch 36/200, Iteration 79/250, Loss: 0.0062\n",
      "Epoch 36/200, Iteration 80/250, Loss: 0.0104\n",
      "Epoch 36/200, Iteration 81/250, Loss: 0.0537\n",
      "Epoch 36/200, Iteration 82/250, Loss: 0.0205\n",
      "Epoch 36/200, Iteration 83/250, Loss: 0.0099\n",
      "Epoch 36/200, Iteration 84/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 85/250, Loss: 0.0257\n",
      "Epoch 36/200, Iteration 86/250, Loss: 0.0189\n",
      "Epoch 36/200, Iteration 87/250, Loss: 0.0130\n",
      "Epoch 36/200, Iteration 88/250, Loss: 0.0250\n",
      "Epoch 36/200, Iteration 89/250, Loss: 0.0149\n",
      "Epoch 36/200, Iteration 90/250, Loss: 0.0192\n",
      "Epoch 36/200, Iteration 91/250, Loss: 0.0098\n",
      "Epoch 36/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 36/200, Iteration 93/250, Loss: 0.0330\n",
      "Epoch 36/200, Iteration 94/250, Loss: 0.0286\n",
      "Epoch 36/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 36/200, Iteration 96/250, Loss: 0.0216\n",
      "Epoch 36/200, Iteration 97/250, Loss: 0.0117\n",
      "Epoch 36/200, Iteration 98/250, Loss: 0.0175\n",
      "Epoch 36/200, Iteration 99/250, Loss: 0.0265\n",
      "Epoch 36/200, Iteration 100/250, Loss: 0.0100\n",
      "Epoch 36/200, Iteration 101/250, Loss: 0.0240\n",
      "Epoch 36/200, Iteration 102/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 103/250, Loss: 0.0385\n",
      "Epoch 36/200, Iteration 104/250, Loss: 0.0239\n",
      "Epoch 36/200, Iteration 105/250, Loss: 0.0309\n",
      "Epoch 36/200, Iteration 106/250, Loss: 0.0135\n",
      "Epoch 36/200, Iteration 107/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 108/250, Loss: 0.0281\n",
      "Epoch 36/200, Iteration 109/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 110/250, Loss: 0.0093\n",
      "Epoch 36/200, Iteration 111/250, Loss: 0.0145\n",
      "Epoch 36/200, Iteration 112/250, Loss: 0.0090\n",
      "Epoch 36/200, Iteration 113/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 114/250, Loss: 0.0267\n",
      "Epoch 36/200, Iteration 115/250, Loss: 0.0175\n",
      "Epoch 36/200, Iteration 116/250, Loss: 0.0190\n",
      "Epoch 36/200, Iteration 117/250, Loss: 0.0109\n",
      "Epoch 36/200, Iteration 118/250, Loss: 0.0129\n",
      "Epoch 36/200, Iteration 119/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 120/250, Loss: 0.0188\n",
      "Epoch 36/200, Iteration 121/250, Loss: 0.0191\n",
      "Epoch 36/200, Iteration 122/250, Loss: 0.0110\n",
      "Epoch 36/200, Iteration 123/250, Loss: 0.0097\n",
      "Epoch 36/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 36/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 126/250, Loss: 0.0230\n",
      "Epoch 36/200, Iteration 127/250, Loss: 0.0163\n",
      "Epoch 36/200, Iteration 128/250, Loss: 0.0227\n",
      "Epoch 36/200, Iteration 129/250, Loss: 0.0107\n",
      "Epoch 36/200, Iteration 130/250, Loss: 0.0070\n",
      "Epoch 36/200, Iteration 131/250, Loss: 0.0313\n",
      "Epoch 36/200, Iteration 132/250, Loss: 0.0216\n",
      "Epoch 36/200, Iteration 133/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 134/250, Loss: 0.0236\n",
      "Epoch 36/200, Iteration 135/250, Loss: 0.0129\n",
      "Epoch 36/200, Iteration 136/250, Loss: 0.0252\n",
      "Epoch 36/200, Iteration 137/250, Loss: 0.0244\n",
      "Epoch 36/200, Iteration 138/250, Loss: 0.0216\n",
      "Epoch 36/200, Iteration 139/250, Loss: 0.0085\n",
      "Epoch 36/200, Iteration 140/250, Loss: 0.0309\n",
      "Epoch 36/200, Iteration 141/250, Loss: 0.0139\n",
      "Epoch 36/200, Iteration 142/250, Loss: 0.0246\n",
      "Epoch 36/200, Iteration 143/250, Loss: 0.0261\n",
      "Epoch 36/200, Iteration 144/250, Loss: 0.0102\n",
      "Epoch 36/200, Iteration 145/250, Loss: 0.0087\n",
      "Epoch 36/200, Iteration 146/250, Loss: 0.0271\n",
      "Epoch 36/200, Iteration 147/250, Loss: 0.0142\n",
      "Epoch 36/200, Iteration 148/250, Loss: 0.0117\n",
      "Epoch 36/200, Iteration 149/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 150/250, Loss: 0.0140\n",
      "Epoch 36/200, Iteration 151/250, Loss: 0.0287\n",
      "Epoch 36/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 36/200, Iteration 153/250, Loss: 0.0181\n",
      "Epoch 36/200, Iteration 154/250, Loss: 0.0159\n",
      "Epoch 36/200, Iteration 155/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 156/250, Loss: 0.0115\n",
      "Epoch 36/200, Iteration 157/250, Loss: 0.0218\n",
      "Epoch 36/200, Iteration 158/250, Loss: 0.0293\n",
      "Epoch 36/200, Iteration 159/250, Loss: 0.0205\n",
      "Epoch 36/200, Iteration 160/250, Loss: 0.0210\n",
      "Epoch 36/200, Iteration 161/250, Loss: 0.0103\n",
      "Epoch 36/200, Iteration 162/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 163/250, Loss: 0.0276\n",
      "Epoch 36/200, Iteration 164/250, Loss: 0.0391\n",
      "Epoch 36/200, Iteration 165/250, Loss: 0.0114\n",
      "Epoch 36/200, Iteration 166/250, Loss: 0.0094\n",
      "Epoch 36/200, Iteration 167/250, Loss: 0.0107\n",
      "Epoch 36/200, Iteration 168/250, Loss: 0.0188\n",
      "Epoch 36/200, Iteration 169/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 170/250, Loss: 0.0106\n",
      "Epoch 36/200, Iteration 171/250, Loss: 0.0095\n",
      "Epoch 36/200, Iteration 172/250, Loss: 0.0055\n",
      "Epoch 36/200, Iteration 173/250, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 174/250, Loss: 0.0176\n",
      "Epoch 36/200, Iteration 175/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 176/250, Loss: 0.0214\n",
      "Epoch 36/200, Iteration 177/250, Loss: 0.0085\n",
      "Epoch 36/200, Iteration 178/250, Loss: 0.0267\n",
      "Epoch 36/200, Iteration 179/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 180/250, Loss: 0.0134\n",
      "Epoch 36/200, Iteration 181/250, Loss: 0.0216\n",
      "Epoch 36/200, Iteration 182/250, Loss: 0.0071\n",
      "Epoch 36/200, Iteration 183/250, Loss: 0.0111\n",
      "Epoch 36/200, Iteration 184/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 185/250, Loss: 0.0153\n",
      "Epoch 36/200, Iteration 186/250, Loss: 0.0097\n",
      "Epoch 36/200, Iteration 187/250, Loss: 0.0382\n",
      "Epoch 36/200, Iteration 188/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 189/250, Loss: 0.0228\n",
      "Epoch 36/200, Iteration 190/250, Loss: 0.0103\n",
      "Epoch 36/200, Iteration 191/250, Loss: 0.0112\n",
      "Epoch 36/200, Iteration 192/250, Loss: 0.0093\n",
      "Epoch 36/200, Iteration 193/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 194/250, Loss: 0.0269\n",
      "Epoch 36/200, Iteration 195/250, Loss: 0.0079\n",
      "Epoch 36/200, Iteration 196/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 197/250, Loss: 0.0252\n",
      "Epoch 36/200, Iteration 198/250, Loss: 0.0072\n",
      "Epoch 36/200, Iteration 199/250, Loss: 0.0271\n",
      "Epoch 36/200, Iteration 200/250, Loss: 0.0182\n",
      "Epoch 36/200, Iteration 201/250, Loss: 0.0102\n",
      "Epoch 36/200, Iteration 202/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 203/250, Loss: 0.0121\n",
      "Epoch 36/200, Iteration 204/250, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 205/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 206/250, Loss: 0.0188\n",
      "Epoch 36/200, Iteration 207/250, Loss: 0.0263\n",
      "Epoch 36/200, Iteration 208/250, Loss: 0.0139\n",
      "Epoch 36/200, Iteration 209/250, Loss: 0.0292\n",
      "Epoch 36/200, Iteration 210/250, Loss: 0.0164\n",
      "Epoch 36/200, Iteration 211/250, Loss: 0.0192\n",
      "Epoch 36/200, Iteration 212/250, Loss: 0.0074\n",
      "Epoch 36/200, Iteration 213/250, Loss: 0.0181\n",
      "Epoch 36/200, Iteration 214/250, Loss: 0.0287\n",
      "Epoch 36/200, Iteration 215/250, Loss: 0.0248\n",
      "Epoch 36/200, Iteration 216/250, Loss: 0.0163\n",
      "Epoch 36/200, Iteration 217/250, Loss: 0.0154\n",
      "Epoch 36/200, Iteration 218/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 219/250, Loss: 0.0098\n",
      "Epoch 36/200, Iteration 220/250, Loss: 0.0255\n",
      "Epoch 36/200, Iteration 221/250, Loss: 0.0203\n",
      "Epoch 36/200, Iteration 222/250, Loss: 0.0174\n",
      "Epoch 36/200, Iteration 223/250, Loss: 0.0167\n",
      "Epoch 36/200, Iteration 224/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 225/250, Loss: 0.0298\n",
      "Epoch 36/200, Iteration 226/250, Loss: 0.0084\n",
      "Epoch 36/200, Iteration 227/250, Loss: 0.0254\n",
      "Epoch 36/200, Iteration 228/250, Loss: 0.0073\n",
      "Epoch 36/200, Iteration 229/250, Loss: 0.0183\n",
      "Epoch 36/200, Iteration 230/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 231/250, Loss: 0.0168\n",
      "Epoch 36/200, Iteration 232/250, Loss: 0.0152\n",
      "Epoch 36/200, Iteration 233/250, Loss: 0.0083\n",
      "Epoch 36/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 235/250, Loss: 0.0083\n",
      "Epoch 36/200, Iteration 236/250, Loss: 0.0439\n",
      "Epoch 36/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 238/250, Loss: 0.0257\n",
      "Epoch 36/200, Iteration 239/250, Loss: 0.0303\n",
      "Epoch 36/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 36/200, Iteration 241/250, Loss: 0.0183\n",
      "Epoch 36/200, Iteration 242/250, Loss: 0.0076\n",
      "Epoch 36/200, Iteration 243/250, Loss: 0.0152\n",
      "Epoch 36/200, Iteration 244/250, Loss: 0.0206\n",
      "Epoch 36/200, Iteration 245/250, Loss: 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 36/200, Iteration 247/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 249/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 92.99%, Avg loss: 0.008457, MRE: 0.731163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.008427, MRE: 1.453310 \n",
      "\n",
      "Epoch 37/200, Iteration 1/250, Loss: 0.0246\n",
      "Epoch 37/200, Iteration 2/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 3/250, Loss: 0.0237\n",
      "Epoch 37/200, Iteration 4/250, Loss: 0.0176\n",
      "Epoch 37/200, Iteration 5/250, Loss: 0.0093\n",
      "Epoch 37/200, Iteration 6/250, Loss: 0.0158\n",
      "Epoch 37/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 8/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 9/250, Loss: 0.0146\n",
      "Epoch 37/200, Iteration 10/250, Loss: 0.0361\n",
      "Epoch 37/200, Iteration 11/250, Loss: 0.0096\n",
      "Epoch 37/200, Iteration 12/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 13/250, Loss: 0.0117\n",
      "Epoch 37/200, Iteration 14/250, Loss: 0.0286\n",
      "Epoch 37/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 37/200, Iteration 16/250, Loss: 0.0391\n",
      "Epoch 37/200, Iteration 17/250, Loss: 0.0304\n",
      "Epoch 37/200, Iteration 18/250, Loss: 0.0175\n",
      "Epoch 37/200, Iteration 19/250, Loss: 0.0069\n",
      "Epoch 37/200, Iteration 20/250, Loss: 0.0254\n",
      "Epoch 37/200, Iteration 21/250, Loss: 0.0100\n",
      "Epoch 37/200, Iteration 22/250, Loss: 0.0117\n",
      "Epoch 37/200, Iteration 23/250, Loss: 0.0140\n",
      "Epoch 37/200, Iteration 24/250, Loss: 0.0371\n",
      "Epoch 37/200, Iteration 25/250, Loss: 0.0106\n",
      "Epoch 37/200, Iteration 26/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 27/250, Loss: 0.0097\n",
      "Epoch 37/200, Iteration 28/250, Loss: 0.0185\n",
      "Epoch 37/200, Iteration 29/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 30/250, Loss: 0.0181\n",
      "Epoch 37/200, Iteration 31/250, Loss: 0.0173\n",
      "Epoch 37/200, Iteration 32/250, Loss: 0.0229\n",
      "Epoch 37/200, Iteration 33/250, Loss: 0.0178\n",
      "Epoch 37/200, Iteration 34/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 37/200, Iteration 36/250, Loss: 0.0074\n",
      "Epoch 37/200, Iteration 37/250, Loss: 0.0186\n",
      "Epoch 37/200, Iteration 38/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 39/250, Loss: 0.0270\n",
      "Epoch 37/200, Iteration 40/250, Loss: 0.0312\n",
      "Epoch 37/200, Iteration 41/250, Loss: 0.0121\n",
      "Epoch 37/200, Iteration 42/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 43/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 44/250, Loss: 0.0197\n",
      "Epoch 37/200, Iteration 45/250, Loss: 0.0315\n",
      "Epoch 37/200, Iteration 46/250, Loss: 0.0135\n",
      "Epoch 37/200, Iteration 47/250, Loss: 0.0103\n",
      "Epoch 37/200, Iteration 48/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 49/250, Loss: 0.0254\n",
      "Epoch 37/200, Iteration 50/250, Loss: 0.0145\n",
      "Epoch 37/200, Iteration 51/250, Loss: 0.0332\n",
      "Epoch 37/200, Iteration 52/250, Loss: 0.0111\n",
      "Epoch 37/200, Iteration 53/250, Loss: 0.0108\n",
      "Epoch 37/200, Iteration 54/250, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 37/200, Iteration 56/250, Loss: 0.0207\n",
      "Epoch 37/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 37/200, Iteration 58/250, Loss: 0.0197\n",
      "Epoch 37/200, Iteration 59/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 60/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 61/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 62/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 63/250, Loss: 0.0117\n",
      "Epoch 37/200, Iteration 64/250, Loss: 0.0201\n",
      "Epoch 37/200, Iteration 65/250, Loss: 0.0232\n",
      "Epoch 37/200, Iteration 66/250, Loss: 0.0100\n",
      "Epoch 37/200, Iteration 67/250, Loss: 0.0090\n",
      "Epoch 37/200, Iteration 68/250, Loss: 0.0083\n",
      "Epoch 37/200, Iteration 69/250, Loss: 0.0139\n",
      "Epoch 37/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 71/250, Loss: 0.0105\n",
      "Epoch 37/200, Iteration 72/250, Loss: 0.0104\n",
      "Epoch 37/200, Iteration 73/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 74/250, Loss: 0.0220\n",
      "Epoch 37/200, Iteration 75/250, Loss: 0.0208\n",
      "Epoch 37/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 37/200, Iteration 77/250, Loss: 0.0089\n",
      "Epoch 37/200, Iteration 78/250, Loss: 0.0104\n",
      "Epoch 37/200, Iteration 79/250, Loss: 0.0190\n",
      "Epoch 37/200, Iteration 80/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 81/250, Loss: 0.0108\n",
      "Epoch 37/200, Iteration 82/250, Loss: 0.0203\n",
      "Epoch 37/200, Iteration 83/250, Loss: 0.0107\n",
      "Epoch 37/200, Iteration 84/250, Loss: 0.0171\n",
      "Epoch 37/200, Iteration 85/250, Loss: 0.0101\n",
      "Epoch 37/200, Iteration 86/250, Loss: 0.0105\n",
      "Epoch 37/200, Iteration 87/250, Loss: 0.0083\n",
      "Epoch 37/200, Iteration 88/250, Loss: 0.0101\n",
      "Epoch 37/200, Iteration 89/250, Loss: 0.0318\n",
      "Epoch 37/200, Iteration 90/250, Loss: 0.0148\n",
      "Epoch 37/200, Iteration 91/250, Loss: 0.0192\n",
      "Epoch 37/200, Iteration 92/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 93/250, Loss: 0.0092\n",
      "Epoch 37/200, Iteration 94/250, Loss: 0.0128\n",
      "Epoch 37/200, Iteration 95/250, Loss: 0.0176\n",
      "Epoch 37/200, Iteration 96/250, Loss: 0.0102\n",
      "Epoch 37/200, Iteration 97/250, Loss: 0.0259\n",
      "Epoch 37/200, Iteration 98/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 99/250, Loss: 0.0179\n",
      "Epoch 37/200, Iteration 100/250, Loss: 0.0211\n",
      "Epoch 37/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 37/200, Iteration 102/250, Loss: 0.0083\n",
      "Epoch 37/200, Iteration 103/250, Loss: 0.0105\n",
      "Epoch 37/200, Iteration 104/250, Loss: 0.0118\n",
      "Epoch 37/200, Iteration 105/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 106/250, Loss: 0.0123\n",
      "Epoch 37/200, Iteration 107/250, Loss: 0.0263\n",
      "Epoch 37/200, Iteration 108/250, Loss: 0.0139\n",
      "Epoch 37/200, Iteration 109/250, Loss: 0.0151\n",
      "Epoch 37/200, Iteration 110/250, Loss: 0.0165\n",
      "Epoch 37/200, Iteration 111/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 112/250, Loss: 0.0175\n",
      "Epoch 37/200, Iteration 113/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 114/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 115/250, Loss: 0.0162\n",
      "Epoch 37/200, Iteration 116/250, Loss: 0.0104\n",
      "Epoch 37/200, Iteration 117/250, Loss: 0.0127\n",
      "Epoch 37/200, Iteration 118/250, Loss: 0.0146\n",
      "Epoch 37/200, Iteration 119/250, Loss: 0.0133\n",
      "Epoch 37/200, Iteration 120/250, Loss: 0.0063\n",
      "Epoch 37/200, Iteration 121/250, Loss: 0.0116\n",
      "Epoch 37/200, Iteration 122/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 123/250, Loss: 0.0073\n",
      "Epoch 37/200, Iteration 124/250, Loss: 0.0180\n",
      "Epoch 37/200, Iteration 125/250, Loss: 0.0178\n",
      "Epoch 37/200, Iteration 126/250, Loss: 0.0303\n",
      "Epoch 37/200, Iteration 127/250, Loss: 0.0076\n",
      "Epoch 37/200, Iteration 128/250, Loss: 0.0083\n",
      "Epoch 37/200, Iteration 129/250, Loss: 0.0142\n",
      "Epoch 37/200, Iteration 130/250, Loss: 0.0164\n",
      "Epoch 37/200, Iteration 131/250, Loss: 0.0076\n",
      "Epoch 37/200, Iteration 132/250, Loss: 0.0098\n",
      "Epoch 37/200, Iteration 133/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 134/250, Loss: 0.0182\n",
      "Epoch 37/200, Iteration 135/250, Loss: 0.0256\n",
      "Epoch 37/200, Iteration 136/250, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 137/250, Loss: 0.0140\n",
      "Epoch 37/200, Iteration 138/250, Loss: 0.0196\n",
      "Epoch 37/200, Iteration 139/250, Loss: 0.0258\n",
      "Epoch 37/200, Iteration 140/250, Loss: 0.0209\n",
      "Epoch 37/200, Iteration 141/250, Loss: 0.0157\n",
      "Epoch 37/200, Iteration 142/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 143/250, Loss: 0.0104\n",
      "Epoch 37/200, Iteration 144/250, Loss: 0.0106\n",
      "Epoch 37/200, Iteration 145/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 146/250, Loss: 0.0152\n",
      "Epoch 37/200, Iteration 147/250, Loss: 0.0146\n",
      "Epoch 37/200, Iteration 148/250, Loss: 0.0132\n",
      "Epoch 37/200, Iteration 149/250, Loss: 0.0216\n",
      "Epoch 37/200, Iteration 150/250, Loss: 0.0204\n",
      "Epoch 37/200, Iteration 151/250, Loss: 0.0077\n",
      "Epoch 37/200, Iteration 152/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 153/250, Loss: 0.0063\n",
      "Epoch 37/200, Iteration 154/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 155/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 156/250, Loss: 0.0217\n",
      "Epoch 37/200, Iteration 157/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 158/250, Loss: 0.0087\n",
      "Epoch 37/200, Iteration 159/250, Loss: 0.0198\n",
      "Epoch 37/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 37/200, Iteration 161/250, Loss: 0.0135\n",
      "Epoch 37/200, Iteration 162/250, Loss: 0.0147\n",
      "Epoch 37/200, Iteration 163/250, Loss: 0.0235\n",
      "Epoch 37/200, Iteration 164/250, Loss: 0.0091\n",
      "Epoch 37/200, Iteration 165/250, Loss: 0.0151\n",
      "Epoch 37/200, Iteration 166/250, Loss: 0.0091\n",
      "Epoch 37/200, Iteration 167/250, Loss: 0.0430\n",
      "Epoch 37/200, Iteration 168/250, Loss: 0.0094\n",
      "Epoch 37/200, Iteration 169/250, Loss: 0.0143\n",
      "Epoch 37/200, Iteration 170/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 171/250, Loss: 0.0101\n",
      "Epoch 37/200, Iteration 172/250, Loss: 0.0257\n",
      "Epoch 37/200, Iteration 173/250, Loss: 0.0097\n",
      "Epoch 37/200, Iteration 174/250, Loss: 0.0389\n",
      "Epoch 37/200, Iteration 175/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 176/250, Loss: 0.0344\n",
      "Epoch 37/200, Iteration 177/250, Loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Iteration 178/250, Loss: 0.0079\n",
      "Epoch 37/200, Iteration 179/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 180/250, Loss: 0.0102\n",
      "Epoch 37/200, Iteration 181/250, Loss: 0.0441\n",
      "Epoch 37/200, Iteration 182/250, Loss: 0.0127\n",
      "Epoch 37/200, Iteration 183/250, Loss: 0.0136\n",
      "Epoch 37/200, Iteration 184/250, Loss: 0.0070\n",
      "Epoch 37/200, Iteration 185/250, Loss: 0.0084\n",
      "Epoch 37/200, Iteration 186/250, Loss: 0.0175\n",
      "Epoch 37/200, Iteration 187/250, Loss: 0.0134\n",
      "Epoch 37/200, Iteration 188/250, Loss: 0.0090\n",
      "Epoch 37/200, Iteration 189/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 190/250, Loss: 0.0096\n",
      "Epoch 37/200, Iteration 191/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 192/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 193/250, Loss: 0.0090\n",
      "Epoch 37/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 195/250, Loss: 0.0209\n",
      "Epoch 37/200, Iteration 196/250, Loss: 0.0221\n",
      "Epoch 37/200, Iteration 197/250, Loss: 0.0214\n",
      "Epoch 37/200, Iteration 198/250, Loss: 0.0238\n",
      "Epoch 37/200, Iteration 199/250, Loss: 0.0305\n",
      "Epoch 37/200, Iteration 200/250, Loss: 0.0154\n",
      "Epoch 37/200, Iteration 201/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 202/250, Loss: 0.0143\n",
      "Epoch 37/200, Iteration 203/250, Loss: 0.0077\n",
      "Epoch 37/200, Iteration 204/250, Loss: 0.0207\n",
      "Epoch 37/200, Iteration 205/250, Loss: 0.0124\n",
      "Epoch 37/200, Iteration 206/250, Loss: 0.0147\n",
      "Epoch 37/200, Iteration 207/250, Loss: 0.0130\n",
      "Epoch 37/200, Iteration 208/250, Loss: 0.0241\n",
      "Epoch 37/200, Iteration 209/250, Loss: 0.0243\n",
      "Epoch 37/200, Iteration 210/250, Loss: 0.0152\n",
      "Epoch 37/200, Iteration 211/250, Loss: 0.0153\n",
      "Epoch 37/200, Iteration 212/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 213/250, Loss: 0.0221\n",
      "Epoch 37/200, Iteration 214/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 215/250, Loss: 0.0084\n",
      "Epoch 37/200, Iteration 216/250, Loss: 0.0077\n",
      "Epoch 37/200, Iteration 217/250, Loss: 0.0122\n",
      "Epoch 37/200, Iteration 218/250, Loss: 0.0102\n",
      "Epoch 37/200, Iteration 219/250, Loss: 0.0167\n",
      "Epoch 37/200, Iteration 220/250, Loss: 0.0324\n",
      "Epoch 37/200, Iteration 221/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 222/250, Loss: 0.0159\n",
      "Epoch 37/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 37/200, Iteration 224/250, Loss: 0.0235\n",
      "Epoch 37/200, Iteration 225/250, Loss: 0.0230\n",
      "Epoch 37/200, Iteration 226/250, Loss: 0.0127\n",
      "Epoch 37/200, Iteration 227/250, Loss: 0.0099\n",
      "Epoch 37/200, Iteration 228/250, Loss: 0.0288\n",
      "Epoch 37/200, Iteration 229/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 230/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 231/250, Loss: 0.0107\n",
      "Epoch 37/200, Iteration 232/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 233/250, Loss: 0.0260\n",
      "Epoch 37/200, Iteration 234/250, Loss: 0.0234\n",
      "Epoch 37/200, Iteration 235/250, Loss: 0.0122\n",
      "Epoch 37/200, Iteration 236/250, Loss: 0.0231\n",
      "Epoch 37/200, Iteration 237/250, Loss: 0.0244\n",
      "Epoch 37/200, Iteration 238/250, Loss: 0.0180\n",
      "Epoch 37/200, Iteration 239/250, Loss: 0.0397\n",
      "Epoch 37/200, Iteration 240/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 241/250, Loss: 0.0312\n",
      "Epoch 37/200, Iteration 242/250, Loss: 0.0180\n",
      "Epoch 37/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 244/250, Loss: 0.0129\n",
      "Epoch 37/200, Iteration 245/250, Loss: 0.0278\n",
      "Epoch 37/200, Iteration 246/250, Loss: 0.0148\n",
      "Epoch 37/200, Iteration 247/250, Loss: 0.0198\n",
      "Epoch 37/200, Iteration 248/250, Loss: 0.0205\n",
      "Epoch 37/200, Iteration 249/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 250/250, Loss: 0.0210\n",
      "Train Error: \n",
      " Accuracy: 90.75%, Avg loss: 0.006983, MRE: 0.627436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.006903, MRE: 1.024845 \n",
      "\n",
      "Epoch 38/200, Iteration 1/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 3/250, Loss: 0.0161\n",
      "Epoch 38/200, Iteration 4/250, Loss: 0.0258\n",
      "Epoch 38/200, Iteration 5/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 6/250, Loss: 0.0065\n",
      "Epoch 38/200, Iteration 7/250, Loss: 0.0175\n",
      "Epoch 38/200, Iteration 8/250, Loss: 0.0141\n",
      "Epoch 38/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 10/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 11/250, Loss: 0.0140\n",
      "Epoch 38/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 13/250, Loss: 0.0080\n",
      "Epoch 38/200, Iteration 14/250, Loss: 0.0120\n",
      "Epoch 38/200, Iteration 15/250, Loss: 0.0229\n",
      "Epoch 38/200, Iteration 16/250, Loss: 0.0053\n",
      "Epoch 38/200, Iteration 17/250, Loss: 0.0169\n",
      "Epoch 38/200, Iteration 18/250, Loss: 0.0253\n",
      "Epoch 38/200, Iteration 19/250, Loss: 0.0339\n",
      "Epoch 38/200, Iteration 20/250, Loss: 0.0105\n",
      "Epoch 38/200, Iteration 21/250, Loss: 0.0127\n",
      "Epoch 38/200, Iteration 22/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 23/250, Loss: 0.0156\n",
      "Epoch 38/200, Iteration 24/250, Loss: 0.0117\n",
      "Epoch 38/200, Iteration 25/250, Loss: 0.0087\n",
      "Epoch 38/200, Iteration 26/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 27/250, Loss: 0.0115\n",
      "Epoch 38/200, Iteration 28/250, Loss: 0.0086\n",
      "Epoch 38/200, Iteration 29/250, Loss: 0.0226\n",
      "Epoch 38/200, Iteration 30/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 31/250, Loss: 0.0169\n",
      "Epoch 38/200, Iteration 32/250, Loss: 0.0414\n",
      "Epoch 38/200, Iteration 33/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 34/250, Loss: 0.0291\n",
      "Epoch 38/200, Iteration 35/250, Loss: 0.0167\n",
      "Epoch 38/200, Iteration 36/250, Loss: 0.0094\n",
      "Epoch 38/200, Iteration 37/250, Loss: 0.0086\n",
      "Epoch 38/200, Iteration 38/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 39/250, Loss: 0.0092\n",
      "Epoch 38/200, Iteration 40/250, Loss: 0.0123\n",
      "Epoch 38/200, Iteration 41/250, Loss: 0.0161\n",
      "Epoch 38/200, Iteration 42/250, Loss: 0.0111\n",
      "Epoch 38/200, Iteration 43/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 44/250, Loss: 0.0155\n",
      "Epoch 38/200, Iteration 45/250, Loss: 0.0100\n",
      "Epoch 38/200, Iteration 46/250, Loss: 0.0076\n",
      "Epoch 38/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 38/200, Iteration 48/250, Loss: 0.0194\n",
      "Epoch 38/200, Iteration 49/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 50/250, Loss: 0.0192\n",
      "Epoch 38/200, Iteration 51/250, Loss: 0.0181\n",
      "Epoch 38/200, Iteration 52/250, Loss: 0.0242\n",
      "Epoch 38/200, Iteration 53/250, Loss: 0.0170\n",
      "Epoch 38/200, Iteration 54/250, Loss: 0.0070\n",
      "Epoch 38/200, Iteration 55/250, Loss: 0.0188\n",
      "Epoch 38/200, Iteration 56/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 57/250, Loss: 0.0145\n",
      "Epoch 38/200, Iteration 58/250, Loss: 0.0120\n",
      "Epoch 38/200, Iteration 59/250, Loss: 0.0160\n",
      "Epoch 38/200, Iteration 60/250, Loss: 0.0186\n",
      "Epoch 38/200, Iteration 61/250, Loss: 0.0298\n",
      "Epoch 38/200, Iteration 62/250, Loss: 0.0251\n",
      "Epoch 38/200, Iteration 63/250, Loss: 0.0181\n",
      "Epoch 38/200, Iteration 64/250, Loss: 0.0269\n",
      "Epoch 38/200, Iteration 65/250, Loss: 0.0092\n",
      "Epoch 38/200, Iteration 66/250, Loss: 0.0090\n",
      "Epoch 38/200, Iteration 67/250, Loss: 0.0083\n",
      "Epoch 38/200, Iteration 68/250, Loss: 0.0154\n",
      "Epoch 38/200, Iteration 69/250, Loss: 0.0140\n",
      "Epoch 38/200, Iteration 70/250, Loss: 0.0089\n",
      "Epoch 38/200, Iteration 71/250, Loss: 0.0170\n",
      "Epoch 38/200, Iteration 72/250, Loss: 0.0206\n",
      "Epoch 38/200, Iteration 73/250, Loss: 0.0154\n",
      "Epoch 38/200, Iteration 74/250, Loss: 0.0102\n",
      "Epoch 38/200, Iteration 75/250, Loss: 0.0237\n",
      "Epoch 38/200, Iteration 76/250, Loss: 0.0067\n",
      "Epoch 38/200, Iteration 77/250, Loss: 0.0178\n",
      "Epoch 38/200, Iteration 78/250, Loss: 0.0181\n",
      "Epoch 38/200, Iteration 79/250, Loss: 0.0095\n",
      "Epoch 38/200, Iteration 80/250, Loss: 0.0190\n",
      "Epoch 38/200, Iteration 81/250, Loss: 0.0151\n",
      "Epoch 38/200, Iteration 82/250, Loss: 0.0396\n",
      "Epoch 38/200, Iteration 83/250, Loss: 0.0078\n",
      "Epoch 38/200, Iteration 84/250, Loss: 0.0234\n",
      "Epoch 38/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 38/200, Iteration 86/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 87/250, Loss: 0.0111\n",
      "Epoch 38/200, Iteration 88/250, Loss: 0.0120\n",
      "Epoch 38/200, Iteration 89/250, Loss: 0.0240\n",
      "Epoch 38/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 38/200, Iteration 91/250, Loss: 0.0111\n",
      "Epoch 38/200, Iteration 92/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 93/250, Loss: 0.0135\n",
      "Epoch 38/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 38/200, Iteration 95/250, Loss: 0.0117\n",
      "Epoch 38/200, Iteration 96/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 97/250, Loss: 0.0125\n",
      "Epoch 38/200, Iteration 98/250, Loss: 0.0106\n",
      "Epoch 38/200, Iteration 99/250, Loss: 0.0084\n",
      "Epoch 38/200, Iteration 100/250, Loss: 0.0103\n",
      "Epoch 38/200, Iteration 101/250, Loss: 0.0070\n",
      "Epoch 38/200, Iteration 102/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 103/250, Loss: 0.0261\n",
      "Epoch 38/200, Iteration 104/250, Loss: 0.0069\n",
      "Epoch 38/200, Iteration 105/250, Loss: 0.0363\n",
      "Epoch 38/200, Iteration 106/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 107/250, Loss: 0.0227\n",
      "Epoch 38/200, Iteration 108/250, Loss: 0.0194\n",
      "Epoch 38/200, Iteration 109/250, Loss: 0.0147\n",
      "Epoch 38/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 111/250, Loss: 0.0217\n",
      "Epoch 38/200, Iteration 112/250, Loss: 0.0105\n",
      "Epoch 38/200, Iteration 113/250, Loss: 0.0145\n",
      "Epoch 38/200, Iteration 114/250, Loss: 0.0132\n",
      "Epoch 38/200, Iteration 115/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 116/250, Loss: 0.0137\n",
      "Epoch 38/200, Iteration 117/250, Loss: 0.0083\n",
      "Epoch 38/200, Iteration 118/250, Loss: 0.0083\n",
      "Epoch 38/200, Iteration 119/250, Loss: 0.0105\n",
      "Epoch 38/200, Iteration 120/250, Loss: 0.0315\n",
      "Epoch 38/200, Iteration 121/250, Loss: 0.0274\n",
      "Epoch 38/200, Iteration 122/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 123/250, Loss: 0.0220\n",
      "Epoch 38/200, Iteration 124/250, Loss: 0.0171\n",
      "Epoch 38/200, Iteration 125/250, Loss: 0.0273\n",
      "Epoch 38/200, Iteration 126/250, Loss: 0.0146\n",
      "Epoch 38/200, Iteration 127/250, Loss: 0.0259\n",
      "Epoch 38/200, Iteration 128/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 129/250, Loss: 0.0139\n",
      "Epoch 38/200, Iteration 130/250, Loss: 0.0175\n",
      "Epoch 38/200, Iteration 131/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 132/250, Loss: 0.0238\n",
      "Epoch 38/200, Iteration 133/250, Loss: 0.0077\n",
      "Epoch 38/200, Iteration 134/250, Loss: 0.0134\n",
      "Epoch 38/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 136/250, Loss: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Iteration 137/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 138/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 139/250, Loss: 0.0084\n",
      "Epoch 38/200, Iteration 140/250, Loss: 0.0100\n",
      "Epoch 38/200, Iteration 141/250, Loss: 0.0084\n",
      "Epoch 38/200, Iteration 142/250, Loss: 0.0187\n",
      "Epoch 38/200, Iteration 143/250, Loss: 0.0115\n",
      "Epoch 38/200, Iteration 144/250, Loss: 0.0097\n",
      "Epoch 38/200, Iteration 145/250, Loss: 0.0089\n",
      "Epoch 38/200, Iteration 146/250, Loss: 0.0147\n",
      "Epoch 38/200, Iteration 147/250, Loss: 0.0101\n",
      "Epoch 38/200, Iteration 148/250, Loss: 0.0203\n",
      "Epoch 38/200, Iteration 149/250, Loss: 0.0276\n",
      "Epoch 38/200, Iteration 150/250, Loss: 0.0242\n",
      "Epoch 38/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 152/250, Loss: 0.0166\n",
      "Epoch 38/200, Iteration 153/250, Loss: 0.0141\n",
      "Epoch 38/200, Iteration 154/250, Loss: 0.0163\n",
      "Epoch 38/200, Iteration 155/250, Loss: 0.0081\n",
      "Epoch 38/200, Iteration 156/250, Loss: 0.0103\n",
      "Epoch 38/200, Iteration 157/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 159/250, Loss: 0.0234\n",
      "Epoch 38/200, Iteration 160/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 161/250, Loss: 0.0129\n",
      "Epoch 38/200, Iteration 162/250, Loss: 0.0461\n",
      "Epoch 38/200, Iteration 163/250, Loss: 0.0152\n",
      "Epoch 38/200, Iteration 164/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 165/250, Loss: 0.0224\n",
      "Epoch 38/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 167/250, Loss: 0.0186\n",
      "Epoch 38/200, Iteration 168/250, Loss: 0.0232\n",
      "Epoch 38/200, Iteration 169/250, Loss: 0.0143\n",
      "Epoch 38/200, Iteration 170/250, Loss: 0.0516\n",
      "Epoch 38/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 38/200, Iteration 172/250, Loss: 0.0141\n",
      "Epoch 38/200, Iteration 173/250, Loss: 0.0273\n",
      "Epoch 38/200, Iteration 174/250, Loss: 0.0333\n",
      "Epoch 38/200, Iteration 175/250, Loss: 0.0254\n",
      "Epoch 38/200, Iteration 176/250, Loss: 0.0338\n",
      "Epoch 38/200, Iteration 177/250, Loss: 0.0225\n",
      "Epoch 38/200, Iteration 178/250, Loss: 0.0232\n",
      "Epoch 38/200, Iteration 179/250, Loss: 0.0158\n",
      "Epoch 38/200, Iteration 180/250, Loss: 0.0110\n",
      "Epoch 38/200, Iteration 181/250, Loss: 0.0139\n",
      "Epoch 38/200, Iteration 182/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 38/200, Iteration 184/250, Loss: 0.0156\n",
      "Epoch 38/200, Iteration 185/250, Loss: 0.0119\n",
      "Epoch 38/200, Iteration 186/250, Loss: 0.0147\n",
      "Epoch 38/200, Iteration 187/250, Loss: 0.0143\n",
      "Epoch 38/200, Iteration 188/250, Loss: 0.0142\n",
      "Epoch 38/200, Iteration 189/250, Loss: 0.0310\n",
      "Epoch 38/200, Iteration 190/250, Loss: 0.0113\n",
      "Epoch 38/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 192/250, Loss: 0.0129\n",
      "Epoch 38/200, Iteration 193/250, Loss: 0.0163\n",
      "Epoch 38/200, Iteration 194/250, Loss: 0.0189\n",
      "Epoch 38/200, Iteration 195/250, Loss: 0.0081\n",
      "Epoch 38/200, Iteration 196/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 197/250, Loss: 0.0069\n",
      "Epoch 38/200, Iteration 198/250, Loss: 0.0319\n",
      "Epoch 38/200, Iteration 199/250, Loss: 0.0158\n",
      "Epoch 38/200, Iteration 200/250, Loss: 0.0124\n",
      "Epoch 38/200, Iteration 201/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 202/250, Loss: 0.0175\n",
      "Epoch 38/200, Iteration 203/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 204/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 205/250, Loss: 0.0085\n",
      "Epoch 38/200, Iteration 206/250, Loss: 0.0155\n",
      "Epoch 38/200, Iteration 207/250, Loss: 0.0270\n",
      "Epoch 38/200, Iteration 208/250, Loss: 0.0297\n",
      "Epoch 38/200, Iteration 209/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 210/250, Loss: 0.0287\n",
      "Epoch 38/200, Iteration 211/250, Loss: 0.0179\n",
      "Epoch 38/200, Iteration 212/250, Loss: 0.0232\n",
      "Epoch 38/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 38/200, Iteration 214/250, Loss: 0.0199\n",
      "Epoch 38/200, Iteration 215/250, Loss: 0.0166\n",
      "Epoch 38/200, Iteration 216/250, Loss: 0.0320\n",
      "Epoch 38/200, Iteration 217/250, Loss: 0.0084\n",
      "Epoch 38/200, Iteration 218/250, Loss: 0.0307\n",
      "Epoch 38/200, Iteration 219/250, Loss: 0.0110\n",
      "Epoch 38/200, Iteration 220/250, Loss: 0.0269\n",
      "Epoch 38/200, Iteration 221/250, Loss: 0.0085\n",
      "Epoch 38/200, Iteration 222/250, Loss: 0.0349\n",
      "Epoch 38/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 38/200, Iteration 224/250, Loss: 0.0339\n",
      "Epoch 38/200, Iteration 225/250, Loss: 0.0157\n",
      "Epoch 38/200, Iteration 226/250, Loss: 0.0103\n",
      "Epoch 38/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 38/200, Iteration 228/250, Loss: 0.0061\n",
      "Epoch 38/200, Iteration 229/250, Loss: 0.0122\n",
      "Epoch 38/200, Iteration 230/250, Loss: 0.0244\n",
      "Epoch 38/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 232/250, Loss: 0.0139\n",
      "Epoch 38/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 38/200, Iteration 234/250, Loss: 0.0142\n",
      "Epoch 38/200, Iteration 235/250, Loss: 0.0193\n",
      "Epoch 38/200, Iteration 236/250, Loss: 0.0159\n",
      "Epoch 38/200, Iteration 237/250, Loss: 0.0165\n",
      "Epoch 38/200, Iteration 238/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 239/250, Loss: 0.0178\n",
      "Epoch 38/200, Iteration 240/250, Loss: 0.0167\n",
      "Epoch 38/200, Iteration 241/250, Loss: 0.0342\n",
      "Epoch 38/200, Iteration 242/250, Loss: 0.0420\n",
      "Epoch 38/200, Iteration 243/250, Loss: 0.0207\n",
      "Epoch 38/200, Iteration 244/250, Loss: 0.0125\n",
      "Epoch 38/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 38/200, Iteration 246/250, Loss: 0.0113\n",
      "Epoch 38/200, Iteration 247/250, Loss: 0.0086\n",
      "Epoch 38/200, Iteration 248/250, Loss: 0.0157\n",
      "Epoch 38/200, Iteration 249/250, Loss: 0.0112\n",
      "Epoch 38/200, Iteration 250/250, Loss: 0.0181\n",
      "Train Error: \n",
      " Accuracy: 88.05%, Avg loss: 0.007176, MRE: 0.676715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.007102, MRE: 0.977285 \n",
      "\n",
      "Epoch 39/200, Iteration 1/250, Loss: 0.0310\n",
      "Epoch 39/200, Iteration 2/250, Loss: 0.0243\n",
      "Epoch 39/200, Iteration 3/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 4/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 5/250, Loss: 0.0157\n",
      "Epoch 39/200, Iteration 6/250, Loss: 0.0127\n",
      "Epoch 39/200, Iteration 7/250, Loss: 0.0171\n",
      "Epoch 39/200, Iteration 8/250, Loss: 0.0165\n",
      "Epoch 39/200, Iteration 9/250, Loss: 0.0272\n",
      "Epoch 39/200, Iteration 10/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 11/250, Loss: 0.0124\n",
      "Epoch 39/200, Iteration 12/250, Loss: 0.0286\n",
      "Epoch 39/200, Iteration 13/250, Loss: 0.0116\n",
      "Epoch 39/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 15/250, Loss: 0.0173\n",
      "Epoch 39/200, Iteration 16/250, Loss: 0.0100\n",
      "Epoch 39/200, Iteration 17/250, Loss: 0.0077\n",
      "Epoch 39/200, Iteration 18/250, Loss: 0.0116\n",
      "Epoch 39/200, Iteration 19/250, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 20/250, Loss: 0.0089\n",
      "Epoch 39/200, Iteration 21/250, Loss: 0.0080\n",
      "Epoch 39/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 39/200, Iteration 23/250, Loss: 0.0209\n",
      "Epoch 39/200, Iteration 24/250, Loss: 0.0092\n",
      "Epoch 39/200, Iteration 25/250, Loss: 0.0179\n",
      "Epoch 39/200, Iteration 26/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 27/250, Loss: 0.0215\n",
      "Epoch 39/200, Iteration 28/250, Loss: 0.0232\n",
      "Epoch 39/200, Iteration 29/250, Loss: 0.0192\n",
      "Epoch 39/200, Iteration 30/250, Loss: 0.0087\n",
      "Epoch 39/200, Iteration 31/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 32/250, Loss: 0.0075\n",
      "Epoch 39/200, Iteration 33/250, Loss: 0.0305\n",
      "Epoch 39/200, Iteration 34/250, Loss: 0.0226\n",
      "Epoch 39/200, Iteration 35/250, Loss: 0.0323\n",
      "Epoch 39/200, Iteration 36/250, Loss: 0.0084\n",
      "Epoch 39/200, Iteration 37/250, Loss: 0.0112\n",
      "Epoch 39/200, Iteration 38/250, Loss: 0.0173\n",
      "Epoch 39/200, Iteration 39/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 40/250, Loss: 0.0179\n",
      "Epoch 39/200, Iteration 41/250, Loss: 0.0096\n",
      "Epoch 39/200, Iteration 42/250, Loss: 0.0163\n",
      "Epoch 39/200, Iteration 43/250, Loss: 0.0150\n",
      "Epoch 39/200, Iteration 44/250, Loss: 0.0127\n",
      "Epoch 39/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 46/250, Loss: 0.0212\n",
      "Epoch 39/200, Iteration 47/250, Loss: 0.0160\n",
      "Epoch 39/200, Iteration 48/250, Loss: 0.0198\n",
      "Epoch 39/200, Iteration 49/250, Loss: 0.0230\n",
      "Epoch 39/200, Iteration 50/250, Loss: 0.0152\n",
      "Epoch 39/200, Iteration 51/250, Loss: 0.0262\n",
      "Epoch 39/200, Iteration 52/250, Loss: 0.0103\n",
      "Epoch 39/200, Iteration 53/250, Loss: 0.0200\n",
      "Epoch 39/200, Iteration 54/250, Loss: 0.0222\n",
      "Epoch 39/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 39/200, Iteration 56/250, Loss: 0.0203\n",
      "Epoch 39/200, Iteration 57/250, Loss: 0.0135\n",
      "Epoch 39/200, Iteration 58/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 59/250, Loss: 0.0228\n",
      "Epoch 39/200, Iteration 60/250, Loss: 0.0112\n",
      "Epoch 39/200, Iteration 61/250, Loss: 0.0135\n",
      "Epoch 39/200, Iteration 62/250, Loss: 0.0060\n",
      "Epoch 39/200, Iteration 63/250, Loss: 0.0109\n",
      "Epoch 39/200, Iteration 64/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 65/250, Loss: 0.0113\n",
      "Epoch 39/200, Iteration 66/250, Loss: 0.0119\n",
      "Epoch 39/200, Iteration 67/250, Loss: 0.0251\n",
      "Epoch 39/200, Iteration 68/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 69/250, Loss: 0.0174\n",
      "Epoch 39/200, Iteration 70/250, Loss: 0.0139\n",
      "Epoch 39/200, Iteration 71/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 72/250, Loss: 0.0151\n",
      "Epoch 39/200, Iteration 73/250, Loss: 0.0291\n",
      "Epoch 39/200, Iteration 74/250, Loss: 0.0124\n",
      "Epoch 39/200, Iteration 75/250, Loss: 0.0086\n",
      "Epoch 39/200, Iteration 76/250, Loss: 0.0102\n",
      "Epoch 39/200, Iteration 77/250, Loss: 0.0098\n",
      "Epoch 39/200, Iteration 78/250, Loss: 0.0164\n",
      "Epoch 39/200, Iteration 79/250, Loss: 0.0211\n",
      "Epoch 39/200, Iteration 80/250, Loss: 0.0353\n",
      "Epoch 39/200, Iteration 81/250, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 82/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 83/250, Loss: 0.0192\n",
      "Epoch 39/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 85/250, Loss: 0.0181\n",
      "Epoch 39/200, Iteration 86/250, Loss: 0.0113\n",
      "Epoch 39/200, Iteration 87/250, Loss: 0.0221\n",
      "Epoch 39/200, Iteration 88/250, Loss: 0.0153\n",
      "Epoch 39/200, Iteration 89/250, Loss: 0.0201\n",
      "Epoch 39/200, Iteration 90/250, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Iteration 91/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 92/250, Loss: 0.0208\n",
      "Epoch 39/200, Iteration 93/250, Loss: 0.0530\n",
      "Epoch 39/200, Iteration 94/250, Loss: 0.0132\n",
      "Epoch 39/200, Iteration 95/250, Loss: 0.0100\n",
      "Epoch 39/200, Iteration 96/250, Loss: 0.0173\n",
      "Epoch 39/200, Iteration 97/250, Loss: 0.0250\n",
      "Epoch 39/200, Iteration 98/250, Loss: 0.0230\n",
      "Epoch 39/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 100/250, Loss: 0.0139\n",
      "Epoch 39/200, Iteration 101/250, Loss: 0.0279\n",
      "Epoch 39/200, Iteration 102/250, Loss: 0.0216\n",
      "Epoch 39/200, Iteration 103/250, Loss: 0.0134\n",
      "Epoch 39/200, Iteration 104/250, Loss: 0.0099\n",
      "Epoch 39/200, Iteration 105/250, Loss: 0.0096\n",
      "Epoch 39/200, Iteration 106/250, Loss: 0.0184\n",
      "Epoch 39/200, Iteration 107/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 109/250, Loss: 0.0163\n",
      "Epoch 39/200, Iteration 110/250, Loss: 0.0139\n",
      "Epoch 39/200, Iteration 111/250, Loss: 0.0193\n",
      "Epoch 39/200, Iteration 112/250, Loss: 0.0422\n",
      "Epoch 39/200, Iteration 113/250, Loss: 0.0097\n",
      "Epoch 39/200, Iteration 114/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 115/250, Loss: 0.0171\n",
      "Epoch 39/200, Iteration 116/250, Loss: 0.0143\n",
      "Epoch 39/200, Iteration 117/250, Loss: 0.0330\n",
      "Epoch 39/200, Iteration 118/250, Loss: 0.0072\n",
      "Epoch 39/200, Iteration 119/250, Loss: 0.0081\n",
      "Epoch 39/200, Iteration 120/250, Loss: 0.0148\n",
      "Epoch 39/200, Iteration 121/250, Loss: 0.0204\n",
      "Epoch 39/200, Iteration 122/250, Loss: 0.0222\n",
      "Epoch 39/200, Iteration 123/250, Loss: 0.0091\n",
      "Epoch 39/200, Iteration 124/250, Loss: 0.0242\n",
      "Epoch 39/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 39/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 39/200, Iteration 127/250, Loss: 0.0348\n",
      "Epoch 39/200, Iteration 128/250, Loss: 0.0113\n",
      "Epoch 39/200, Iteration 129/250, Loss: 0.0100\n",
      "Epoch 39/200, Iteration 130/250, Loss: 0.0094\n",
      "Epoch 39/200, Iteration 131/250, Loss: 0.0211\n",
      "Epoch 39/200, Iteration 132/250, Loss: 0.0312\n",
      "Epoch 39/200, Iteration 133/250, Loss: 0.0099\n",
      "Epoch 39/200, Iteration 134/250, Loss: 0.0086\n",
      "Epoch 39/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 39/200, Iteration 136/250, Loss: 0.0366\n",
      "Epoch 39/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 138/250, Loss: 0.0166\n",
      "Epoch 39/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 39/200, Iteration 140/250, Loss: 0.0133\n",
      "Epoch 39/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 39/200, Iteration 142/250, Loss: 0.0202\n",
      "Epoch 39/200, Iteration 143/250, Loss: 0.0356\n",
      "Epoch 39/200, Iteration 144/250, Loss: 0.0069\n",
      "Epoch 39/200, Iteration 145/250, Loss: 0.0102\n",
      "Epoch 39/200, Iteration 146/250, Loss: 0.0301\n",
      "Epoch 39/200, Iteration 147/250, Loss: 0.0256\n",
      "Epoch 39/200, Iteration 148/250, Loss: 0.0089\n",
      "Epoch 39/200, Iteration 149/250, Loss: 0.0161\n",
      "Epoch 39/200, Iteration 150/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 151/250, Loss: 0.0393\n",
      "Epoch 39/200, Iteration 152/250, Loss: 0.0166\n",
      "Epoch 39/200, Iteration 153/250, Loss: 0.0179\n",
      "Epoch 39/200, Iteration 154/250, Loss: 0.0134\n",
      "Epoch 39/200, Iteration 155/250, Loss: 0.0230\n",
      "Epoch 39/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 39/200, Iteration 158/250, Loss: 0.0147\n",
      "Epoch 39/200, Iteration 159/250, Loss: 0.0195\n",
      "Epoch 39/200, Iteration 160/250, Loss: 0.0140\n",
      "Epoch 39/200, Iteration 161/250, Loss: 0.0166\n",
      "Epoch 39/200, Iteration 162/250, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 163/250, Loss: 0.0113\n",
      "Epoch 39/200, Iteration 164/250, Loss: 0.0164\n",
      "Epoch 39/200, Iteration 165/250, Loss: 0.0318\n",
      "Epoch 39/200, Iteration 166/250, Loss: 0.0124\n",
      "Epoch 39/200, Iteration 167/250, Loss: 0.0458\n",
      "Epoch 39/200, Iteration 168/250, Loss: 0.0372\n",
      "Epoch 39/200, Iteration 169/250, Loss: 0.0418\n",
      "Epoch 39/200, Iteration 170/250, Loss: 0.0223\n",
      "Epoch 39/200, Iteration 171/250, Loss: 0.0077\n",
      "Epoch 39/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 39/200, Iteration 173/250, Loss: 0.0306\n",
      "Epoch 39/200, Iteration 174/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 175/250, Loss: 0.0275\n",
      "Epoch 39/200, Iteration 176/250, Loss: 0.0215\n",
      "Epoch 39/200, Iteration 177/250, Loss: 0.0204\n",
      "Epoch 39/200, Iteration 178/250, Loss: 0.0119\n",
      "Epoch 39/200, Iteration 179/250, Loss: 0.0235\n",
      "Epoch 39/200, Iteration 180/250, Loss: 0.0109\n",
      "Epoch 39/200, Iteration 181/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 182/250, Loss: 0.0080\n",
      "Epoch 39/200, Iteration 183/250, Loss: 0.0171\n",
      "Epoch 39/200, Iteration 184/250, Loss: 0.0269\n",
      "Epoch 39/200, Iteration 185/250, Loss: 0.0134\n",
      "Epoch 39/200, Iteration 186/250, Loss: 0.0084\n",
      "Epoch 39/200, Iteration 187/250, Loss: 0.0223\n",
      "Epoch 39/200, Iteration 188/250, Loss: 0.0078\n",
      "Epoch 39/200, Iteration 189/250, Loss: 0.0193\n",
      "Epoch 39/200, Iteration 190/250, Loss: 0.0322\n",
      "Epoch 39/200, Iteration 191/250, Loss: 0.0098\n",
      "Epoch 39/200, Iteration 192/250, Loss: 0.0255\n",
      "Epoch 39/200, Iteration 193/250, Loss: 0.0108\n",
      "Epoch 39/200, Iteration 194/250, Loss: 0.0211\n",
      "Epoch 39/200, Iteration 195/250, Loss: 0.0316\n",
      "Epoch 39/200, Iteration 196/250, Loss: 0.0085\n",
      "Epoch 39/200, Iteration 197/250, Loss: 0.0134\n",
      "Epoch 39/200, Iteration 198/250, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 199/250, Loss: 0.0152\n",
      "Epoch 39/200, Iteration 200/250, Loss: 0.0079\n",
      "Epoch 39/200, Iteration 201/250, Loss: 0.0195\n",
      "Epoch 39/200, Iteration 202/250, Loss: 0.0337\n",
      "Epoch 39/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 39/200, Iteration 204/250, Loss: 0.0187\n",
      "Epoch 39/200, Iteration 205/250, Loss: 0.0215\n",
      "Epoch 39/200, Iteration 206/250, Loss: 0.0319\n",
      "Epoch 39/200, Iteration 207/250, Loss: 0.0275\n",
      "Epoch 39/200, Iteration 208/250, Loss: 0.0118\n",
      "Epoch 39/200, Iteration 209/250, Loss: 0.0083\n",
      "Epoch 39/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 211/250, Loss: 0.0081\n",
      "Epoch 39/200, Iteration 212/250, Loss: 0.0098\n",
      "Epoch 39/200, Iteration 213/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 214/250, Loss: 0.0068\n",
      "Epoch 39/200, Iteration 215/250, Loss: 0.0251\n",
      "Epoch 39/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 39/200, Iteration 217/250, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 218/250, Loss: 0.0331\n",
      "Epoch 39/200, Iteration 219/250, Loss: 0.0276\n",
      "Epoch 39/200, Iteration 220/250, Loss: 0.0069\n",
      "Epoch 39/200, Iteration 221/250, Loss: 0.0161\n",
      "Epoch 39/200, Iteration 222/250, Loss: 0.0158\n",
      "Epoch 39/200, Iteration 223/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 39/200, Iteration 225/250, Loss: 0.0104\n",
      "Epoch 39/200, Iteration 226/250, Loss: 0.0087\n",
      "Epoch 39/200, Iteration 227/250, Loss: 0.0315\n",
      "Epoch 39/200, Iteration 228/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 229/250, Loss: 0.0246\n",
      "Epoch 39/200, Iteration 230/250, Loss: 0.0083\n",
      "Epoch 39/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 39/200, Iteration 232/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 233/250, Loss: 0.0490\n",
      "Epoch 39/200, Iteration 234/250, Loss: 0.0183\n",
      "Epoch 39/200, Iteration 235/250, Loss: 0.0387\n",
      "Epoch 39/200, Iteration 236/250, Loss: 0.0076\n",
      "Epoch 39/200, Iteration 237/250, Loss: 0.0383\n",
      "Epoch 39/200, Iteration 238/250, Loss: 0.0228\n",
      "Epoch 39/200, Iteration 239/250, Loss: 0.0125\n",
      "Epoch 39/200, Iteration 240/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 241/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 242/250, Loss: 0.0113\n",
      "Epoch 39/200, Iteration 243/250, Loss: 0.0158\n",
      "Epoch 39/200, Iteration 244/250, Loss: 0.0157\n",
      "Epoch 39/200, Iteration 245/250, Loss: 0.0081\n",
      "Epoch 39/200, Iteration 246/250, Loss: 0.0162\n",
      "Epoch 39/200, Iteration 247/250, Loss: 0.0216\n",
      "Epoch 39/200, Iteration 248/250, Loss: 0.0125\n",
      "Epoch 39/200, Iteration 249/250, Loss: 0.0296\n",
      "Epoch 39/200, Iteration 250/250, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 80.36%, Avg loss: 0.007699, MRE: 0.648669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.007754, MRE: 0.963368 \n",
      "\n",
      "Epoch 40/200, Iteration 1/250, Loss: 0.0173\n",
      "Epoch 40/200, Iteration 2/250, Loss: 0.0151\n",
      "Epoch 40/200, Iteration 3/250, Loss: 0.0085\n",
      "Epoch 40/200, Iteration 4/250, Loss: 0.0240\n",
      "Epoch 40/200, Iteration 5/250, Loss: 0.0092\n",
      "Epoch 40/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 7/250, Loss: 0.0099\n",
      "Epoch 40/200, Iteration 8/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 40/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 40/200, Iteration 11/250, Loss: 0.0207\n",
      "Epoch 40/200, Iteration 12/250, Loss: 0.0106\n",
      "Epoch 40/200, Iteration 13/250, Loss: 0.0239\n",
      "Epoch 40/200, Iteration 14/250, Loss: 0.0084\n",
      "Epoch 40/200, Iteration 15/250, Loss: 0.0155\n",
      "Epoch 40/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 40/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 40/200, Iteration 18/250, Loss: 0.0386\n",
      "Epoch 40/200, Iteration 19/250, Loss: 0.0283\n",
      "Epoch 40/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 21/250, Loss: 0.0070\n",
      "Epoch 40/200, Iteration 22/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 23/250, Loss: 0.0200\n",
      "Epoch 40/200, Iteration 24/250, Loss: 0.0126\n",
      "Epoch 40/200, Iteration 25/250, Loss: 0.0117\n",
      "Epoch 40/200, Iteration 26/250, Loss: 0.0188\n",
      "Epoch 40/200, Iteration 27/250, Loss: 0.0233\n",
      "Epoch 40/200, Iteration 28/250, Loss: 0.0100\n",
      "Epoch 40/200, Iteration 29/250, Loss: 0.0094\n",
      "Epoch 40/200, Iteration 30/250, Loss: 0.0297\n",
      "Epoch 40/200, Iteration 31/250, Loss: 0.0091\n",
      "Epoch 40/200, Iteration 32/250, Loss: 0.0140\n",
      "Epoch 40/200, Iteration 33/250, Loss: 0.0166\n",
      "Epoch 40/200, Iteration 34/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 35/250, Loss: 0.0200\n",
      "Epoch 40/200, Iteration 36/250, Loss: 0.0409\n",
      "Epoch 40/200, Iteration 37/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 38/250, Loss: 0.0138\n",
      "Epoch 40/200, Iteration 39/250, Loss: 0.0238\n",
      "Epoch 40/200, Iteration 40/250, Loss: 0.0217\n",
      "Epoch 40/200, Iteration 41/250, Loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Iteration 42/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 43/250, Loss: 0.0260\n",
      "Epoch 40/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 40/200, Iteration 45/250, Loss: 0.0177\n",
      "Epoch 40/200, Iteration 46/250, Loss: 0.0195\n",
      "Epoch 40/200, Iteration 47/250, Loss: 0.0149\n",
      "Epoch 40/200, Iteration 48/250, Loss: 0.0253\n",
      "Epoch 40/200, Iteration 49/250, Loss: 0.0106\n",
      "Epoch 40/200, Iteration 50/250, Loss: 0.0132\n",
      "Epoch 40/200, Iteration 51/250, Loss: 0.0129\n",
      "Epoch 40/200, Iteration 52/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 53/250, Loss: 0.0247\n",
      "Epoch 40/200, Iteration 54/250, Loss: 0.0101\n",
      "Epoch 40/200, Iteration 55/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 56/250, Loss: 0.0095\n",
      "Epoch 40/200, Iteration 57/250, Loss: 0.0321\n",
      "Epoch 40/200, Iteration 58/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 59/250, Loss: 0.0170\n",
      "Epoch 40/200, Iteration 60/250, Loss: 0.0124\n",
      "Epoch 40/200, Iteration 61/250, Loss: 0.0109\n",
      "Epoch 40/200, Iteration 62/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 63/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 64/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 65/250, Loss: 0.0312\n",
      "Epoch 40/200, Iteration 66/250, Loss: 0.0192\n",
      "Epoch 40/200, Iteration 67/250, Loss: 0.0260\n",
      "Epoch 40/200, Iteration 68/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 69/250, Loss: 0.0092\n",
      "Epoch 40/200, Iteration 70/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 71/250, Loss: 0.0085\n",
      "Epoch 40/200, Iteration 72/250, Loss: 0.0198\n",
      "Epoch 40/200, Iteration 73/250, Loss: 0.0239\n",
      "Epoch 40/200, Iteration 74/250, Loss: 0.0085\n",
      "Epoch 40/200, Iteration 75/250, Loss: 0.0143\n",
      "Epoch 40/200, Iteration 76/250, Loss: 0.0417\n",
      "Epoch 40/200, Iteration 77/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 78/250, Loss: 0.0096\n",
      "Epoch 40/200, Iteration 79/250, Loss: 0.0152\n",
      "Epoch 40/200, Iteration 80/250, Loss: 0.0080\n",
      "Epoch 40/200, Iteration 81/250, Loss: 0.0159\n",
      "Epoch 40/200, Iteration 82/250, Loss: 0.0085\n",
      "Epoch 40/200, Iteration 83/250, Loss: 0.0100\n",
      "Epoch 40/200, Iteration 84/250, Loss: 0.0084\n",
      "Epoch 40/200, Iteration 85/250, Loss: 0.0145\n",
      "Epoch 40/200, Iteration 86/250, Loss: 0.0200\n",
      "Epoch 40/200, Iteration 87/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 88/250, Loss: 0.0271\n",
      "Epoch 40/200, Iteration 89/250, Loss: 0.0291\n",
      "Epoch 40/200, Iteration 90/250, Loss: 0.0267\n",
      "Epoch 40/200, Iteration 91/250, Loss: 0.0250\n",
      "Epoch 40/200, Iteration 92/250, Loss: 0.0295\n",
      "Epoch 40/200, Iteration 93/250, Loss: 0.0164\n",
      "Epoch 40/200, Iteration 94/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 95/250, Loss: 0.0243\n",
      "Epoch 40/200, Iteration 96/250, Loss: 0.0144\n",
      "Epoch 40/200, Iteration 97/250, Loss: 0.0114\n",
      "Epoch 40/200, Iteration 98/250, Loss: 0.0087\n",
      "Epoch 40/200, Iteration 99/250, Loss: 0.0236\n",
      "Epoch 40/200, Iteration 100/250, Loss: 0.0099\n",
      "Epoch 40/200, Iteration 101/250, Loss: 0.0141\n",
      "Epoch 40/200, Iteration 102/250, Loss: 0.0073\n",
      "Epoch 40/200, Iteration 103/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 104/250, Loss: 0.0268\n",
      "Epoch 40/200, Iteration 105/250, Loss: 0.0079\n",
      "Epoch 40/200, Iteration 106/250, Loss: 0.0140\n",
      "Epoch 40/200, Iteration 107/250, Loss: 0.0549\n",
      "Epoch 40/200, Iteration 108/250, Loss: 0.0199\n",
      "Epoch 40/200, Iteration 109/250, Loss: 0.0169\n",
      "Epoch 40/200, Iteration 110/250, Loss: 0.0101\n",
      "Epoch 40/200, Iteration 111/250, Loss: 0.0077\n",
      "Epoch 40/200, Iteration 112/250, Loss: 0.0436\n",
      "Epoch 40/200, Iteration 113/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 114/250, Loss: 0.0080\n",
      "Epoch 40/200, Iteration 115/250, Loss: 0.0132\n",
      "Epoch 40/200, Iteration 116/250, Loss: 0.0115\n",
      "Epoch 40/200, Iteration 117/250, Loss: 0.0165\n",
      "Epoch 40/200, Iteration 118/250, Loss: 0.0160\n",
      "Epoch 40/200, Iteration 119/250, Loss: 0.0302\n",
      "Epoch 40/200, Iteration 120/250, Loss: 0.0084\n",
      "Epoch 40/200, Iteration 121/250, Loss: 0.0068\n",
      "Epoch 40/200, Iteration 122/250, Loss: 0.0327\n",
      "Epoch 40/200, Iteration 123/250, Loss: 0.0088\n",
      "Epoch 40/200, Iteration 124/250, Loss: 0.0375\n",
      "Epoch 40/200, Iteration 125/250, Loss: 0.0136\n",
      "Epoch 40/200, Iteration 126/250, Loss: 0.0147\n",
      "Epoch 40/200, Iteration 127/250, Loss: 0.0083\n",
      "Epoch 40/200, Iteration 128/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 129/250, Loss: 0.0311\n",
      "Epoch 40/200, Iteration 130/250, Loss: 0.0072\n",
      "Epoch 40/200, Iteration 131/250, Loss: 0.0171\n",
      "Epoch 40/200, Iteration 132/250, Loss: 0.0188\n",
      "Epoch 40/200, Iteration 133/250, Loss: 0.0142\n",
      "Epoch 40/200, Iteration 134/250, Loss: 0.0277\n",
      "Epoch 40/200, Iteration 135/250, Loss: 0.0135\n",
      "Epoch 40/200, Iteration 136/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 137/250, Loss: 0.0108\n",
      "Epoch 40/200, Iteration 138/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 139/250, Loss: 0.0064\n",
      "Epoch 40/200, Iteration 140/250, Loss: 0.0310\n",
      "Epoch 40/200, Iteration 141/250, Loss: 0.0066\n",
      "Epoch 40/200, Iteration 142/250, Loss: 0.0238\n",
      "Epoch 40/200, Iteration 143/250, Loss: 0.0247\n",
      "Epoch 40/200, Iteration 144/250, Loss: 0.0070\n",
      "Epoch 40/200, Iteration 145/250, Loss: 0.0187\n",
      "Epoch 40/200, Iteration 146/250, Loss: 0.0197\n",
      "Epoch 40/200, Iteration 147/250, Loss: 0.0078\n",
      "Epoch 40/200, Iteration 148/250, Loss: 0.0086\n",
      "Epoch 40/200, Iteration 149/250, Loss: 0.0165\n",
      "Epoch 40/200, Iteration 150/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 151/250, Loss: 0.0143\n",
      "Epoch 40/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 153/250, Loss: 0.0214\n",
      "Epoch 40/200, Iteration 154/250, Loss: 0.0292\n",
      "Epoch 40/200, Iteration 155/250, Loss: 0.0163\n",
      "Epoch 40/200, Iteration 156/250, Loss: 0.0429\n",
      "Epoch 40/200, Iteration 157/250, Loss: 0.0146\n",
      "Epoch 40/200, Iteration 158/250, Loss: 0.0359\n",
      "Epoch 40/200, Iteration 159/250, Loss: 0.0084\n",
      "Epoch 40/200, Iteration 160/250, Loss: 0.0376\n",
      "Epoch 40/200, Iteration 161/250, Loss: 0.0115\n",
      "Epoch 40/200, Iteration 162/250, Loss: 0.0127\n",
      "Epoch 40/200, Iteration 163/250, Loss: 0.0091\n",
      "Epoch 40/200, Iteration 164/250, Loss: 0.0170\n",
      "Epoch 40/200, Iteration 165/250, Loss: 0.0158\n",
      "Epoch 40/200, Iteration 166/250, Loss: 0.0160\n",
      "Epoch 40/200, Iteration 167/250, Loss: 0.0093\n",
      "Epoch 40/200, Iteration 168/250, Loss: 0.0114\n",
      "Epoch 40/200, Iteration 169/250, Loss: 0.0089\n",
      "Epoch 40/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 40/200, Iteration 172/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 173/250, Loss: 0.0164\n",
      "Epoch 40/200, Iteration 174/250, Loss: 0.0200\n",
      "Epoch 40/200, Iteration 175/250, Loss: 0.0068\n",
      "Epoch 40/200, Iteration 176/250, Loss: 0.0135\n",
      "Epoch 40/200, Iteration 177/250, Loss: 0.0358\n",
      "Epoch 40/200, Iteration 178/250, Loss: 0.0094\n",
      "Epoch 40/200, Iteration 179/250, Loss: 0.0097\n",
      "Epoch 40/200, Iteration 180/250, Loss: 0.0078\n",
      "Epoch 40/200, Iteration 181/250, Loss: 0.0089\n",
      "Epoch 40/200, Iteration 182/250, Loss: 0.0130\n",
      "Epoch 40/200, Iteration 183/250, Loss: 0.0203\n",
      "Epoch 40/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 40/200, Iteration 185/250, Loss: 0.0276\n",
      "Epoch 40/200, Iteration 186/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 187/250, Loss: 0.0290\n",
      "Epoch 40/200, Iteration 188/250, Loss: 0.0110\n",
      "Epoch 40/200, Iteration 189/250, Loss: 0.0213\n",
      "Epoch 40/200, Iteration 190/250, Loss: 0.0121\n",
      "Epoch 40/200, Iteration 191/250, Loss: 0.0112\n",
      "Epoch 40/200, Iteration 192/250, Loss: 0.0115\n",
      "Epoch 40/200, Iteration 193/250, Loss: 0.0188\n",
      "Epoch 40/200, Iteration 194/250, Loss: 0.0129\n",
      "Epoch 40/200, Iteration 195/250, Loss: 0.0354\n",
      "Epoch 40/200, Iteration 196/250, Loss: 0.0075\n",
      "Epoch 40/200, Iteration 197/250, Loss: 0.0273\n",
      "Epoch 40/200, Iteration 198/250, Loss: 0.0106\n",
      "Epoch 40/200, Iteration 199/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 200/250, Loss: 0.0219\n",
      "Epoch 40/200, Iteration 201/250, Loss: 0.0121\n",
      "Epoch 40/200, Iteration 202/250, Loss: 0.0176\n",
      "Epoch 40/200, Iteration 203/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 204/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 205/250, Loss: 0.0401\n",
      "Epoch 40/200, Iteration 206/250, Loss: 0.0260\n",
      "Epoch 40/200, Iteration 207/250, Loss: 0.0155\n",
      "Epoch 40/200, Iteration 208/250, Loss: 0.0140\n",
      "Epoch 40/200, Iteration 209/250, Loss: 0.0098\n",
      "Epoch 40/200, Iteration 210/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 211/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 212/250, Loss: 0.0091\n",
      "Epoch 40/200, Iteration 213/250, Loss: 0.0127\n",
      "Epoch 40/200, Iteration 214/250, Loss: 0.0084\n",
      "Epoch 40/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 216/250, Loss: 0.0191\n",
      "Epoch 40/200, Iteration 217/250, Loss: 0.0082\n",
      "Epoch 40/200, Iteration 218/250, Loss: 0.0105\n",
      "Epoch 40/200, Iteration 219/250, Loss: 0.0288\n",
      "Epoch 40/200, Iteration 220/250, Loss: 0.0347\n",
      "Epoch 40/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 40/200, Iteration 222/250, Loss: 0.0124\n",
      "Epoch 40/200, Iteration 223/250, Loss: 0.0160\n",
      "Epoch 40/200, Iteration 224/250, Loss: 0.0078\n",
      "Epoch 40/200, Iteration 225/250, Loss: 0.0091\n",
      "Epoch 40/200, Iteration 226/250, Loss: 0.0069\n",
      "Epoch 40/200, Iteration 227/250, Loss: 0.0110\n",
      "Epoch 40/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 229/250, Loss: 0.0097\n",
      "Epoch 40/200, Iteration 230/250, Loss: 0.0071\n",
      "Epoch 40/200, Iteration 231/250, Loss: 0.0265\n",
      "Epoch 40/200, Iteration 232/250, Loss: 0.0294\n",
      "Epoch 40/200, Iteration 233/250, Loss: 0.0162\n",
      "Epoch 40/200, Iteration 234/250, Loss: 0.0231\n",
      "Epoch 40/200, Iteration 235/250, Loss: 0.0223\n",
      "Epoch 40/200, Iteration 236/250, Loss: 0.0274\n",
      "Epoch 40/200, Iteration 237/250, Loss: 0.0143\n",
      "Epoch 40/200, Iteration 238/250, Loss: 0.0370\n",
      "Epoch 40/200, Iteration 239/250, Loss: 0.0101\n",
      "Epoch 40/200, Iteration 240/250, Loss: 0.0306\n",
      "Epoch 40/200, Iteration 241/250, Loss: 0.0116\n",
      "Epoch 40/200, Iteration 242/250, Loss: 0.0208\n",
      "Epoch 40/200, Iteration 243/250, Loss: 0.0081\n",
      "Epoch 40/200, Iteration 244/250, Loss: 0.0144\n",
      "Epoch 40/200, Iteration 245/250, Loss: 0.0364\n",
      "Epoch 40/200, Iteration 246/250, Loss: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Iteration 247/250, Loss: 0.0313\n",
      "Epoch 40/200, Iteration 248/250, Loss: 0.0148\n",
      "Epoch 40/200, Iteration 249/250, Loss: 0.0123\n",
      "Epoch 40/200, Iteration 250/250, Loss: 0.0223\n",
      "Train Error: \n",
      " Accuracy: 34.54%, Avg loss: 0.014201, MRE: 0.974284 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.014236, MRE: 1.026133 \n",
      "\n",
      "Epoch 41/200, Iteration 1/250, Loss: 0.0089\n",
      "Epoch 41/200, Iteration 2/250, Loss: 0.0178\n",
      "Epoch 41/200, Iteration 3/250, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 4/250, Loss: 0.0099\n",
      "Epoch 41/200, Iteration 5/250, Loss: 0.0287\n",
      "Epoch 41/200, Iteration 6/250, Loss: 0.0158\n",
      "Epoch 41/200, Iteration 7/250, Loss: 0.0221\n",
      "Epoch 41/200, Iteration 8/250, Loss: 0.0104\n",
      "Epoch 41/200, Iteration 9/250, Loss: 0.0094\n",
      "Epoch 41/200, Iteration 10/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 11/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 12/250, Loss: 0.0102\n",
      "Epoch 41/200, Iteration 13/250, Loss: 0.0254\n",
      "Epoch 41/200, Iteration 14/250, Loss: 0.0354\n",
      "Epoch 41/200, Iteration 15/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 16/250, Loss: 0.0150\n",
      "Epoch 41/200, Iteration 17/250, Loss: 0.0139\n",
      "Epoch 41/200, Iteration 18/250, Loss: 0.0230\n",
      "Epoch 41/200, Iteration 19/250, Loss: 0.0117\n",
      "Epoch 41/200, Iteration 20/250, Loss: 0.0191\n",
      "Epoch 41/200, Iteration 21/250, Loss: 0.0139\n",
      "Epoch 41/200, Iteration 22/250, Loss: 0.0268\n",
      "Epoch 41/200, Iteration 23/250, Loss: 0.0188\n",
      "Epoch 41/200, Iteration 24/250, Loss: 0.0283\n",
      "Epoch 41/200, Iteration 25/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 26/250, Loss: 0.0357\n",
      "Epoch 41/200, Iteration 27/250, Loss: 0.0172\n",
      "Epoch 41/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 41/200, Iteration 29/250, Loss: 0.0150\n",
      "Epoch 41/200, Iteration 30/250, Loss: 0.0245\n",
      "Epoch 41/200, Iteration 31/250, Loss: 0.0177\n",
      "Epoch 41/200, Iteration 32/250, Loss: 0.0213\n",
      "Epoch 41/200, Iteration 33/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 34/250, Loss: 0.0139\n",
      "Epoch 41/200, Iteration 35/250, Loss: 0.0207\n",
      "Epoch 41/200, Iteration 36/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 37/250, Loss: 0.0169\n",
      "Epoch 41/200, Iteration 38/250, Loss: 0.0227\n",
      "Epoch 41/200, Iteration 39/250, Loss: 0.0268\n",
      "Epoch 41/200, Iteration 40/250, Loss: 0.0242\n",
      "Epoch 41/200, Iteration 41/250, Loss: 0.0105\n",
      "Epoch 41/200, Iteration 42/250, Loss: 0.0296\n",
      "Epoch 41/200, Iteration 43/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 41/200, Iteration 45/250, Loss: 0.0281\n",
      "Epoch 41/200, Iteration 46/250, Loss: 0.0492\n",
      "Epoch 41/200, Iteration 47/250, Loss: 0.0151\n",
      "Epoch 41/200, Iteration 48/250, Loss: 0.0159\n",
      "Epoch 41/200, Iteration 49/250, Loss: 0.0153\n",
      "Epoch 41/200, Iteration 50/250, Loss: 0.0143\n",
      "Epoch 41/200, Iteration 51/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 52/250, Loss: 0.0099\n",
      "Epoch 41/200, Iteration 53/250, Loss: 0.0348\n",
      "Epoch 41/200, Iteration 54/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 55/250, Loss: 0.0210\n",
      "Epoch 41/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 57/250, Loss: 0.0103\n",
      "Epoch 41/200, Iteration 58/250, Loss: 0.0151\n",
      "Epoch 41/200, Iteration 59/250, Loss: 0.0226\n",
      "Epoch 41/200, Iteration 60/250, Loss: 0.0221\n",
      "Epoch 41/200, Iteration 61/250, Loss: 0.0215\n",
      "Epoch 41/200, Iteration 62/250, Loss: 0.0251\n",
      "Epoch 41/200, Iteration 63/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 64/250, Loss: 0.0143\n",
      "Epoch 41/200, Iteration 65/250, Loss: 0.0097\n",
      "Epoch 41/200, Iteration 66/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 67/250, Loss: 0.0232\n",
      "Epoch 41/200, Iteration 68/250, Loss: 0.0158\n",
      "Epoch 41/200, Iteration 69/250, Loss: 0.0176\n",
      "Epoch 41/200, Iteration 70/250, Loss: 0.0212\n",
      "Epoch 41/200, Iteration 71/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 72/250, Loss: 0.0220\n",
      "Epoch 41/200, Iteration 73/250, Loss: 0.0206\n",
      "Epoch 41/200, Iteration 74/250, Loss: 0.0189\n",
      "Epoch 41/200, Iteration 75/250, Loss: 0.0072\n",
      "Epoch 41/200, Iteration 76/250, Loss: 0.0130\n",
      "Epoch 41/200, Iteration 77/250, Loss: 0.0250\n",
      "Epoch 41/200, Iteration 78/250, Loss: 0.0107\n",
      "Epoch 41/200, Iteration 79/250, Loss: 0.0084\n",
      "Epoch 41/200, Iteration 80/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 41/200, Iteration 82/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 83/250, Loss: 0.0112\n",
      "Epoch 41/200, Iteration 84/250, Loss: 0.0135\n",
      "Epoch 41/200, Iteration 85/250, Loss: 0.0092\n",
      "Epoch 41/200, Iteration 86/250, Loss: 0.0244\n",
      "Epoch 41/200, Iteration 87/250, Loss: 0.0072\n",
      "Epoch 41/200, Iteration 88/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 89/250, Loss: 0.0118\n",
      "Epoch 41/200, Iteration 90/250, Loss: 0.0104\n",
      "Epoch 41/200, Iteration 91/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 92/250, Loss: 0.0288\n",
      "Epoch 41/200, Iteration 93/250, Loss: 0.0157\n",
      "Epoch 41/200, Iteration 94/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 95/250, Loss: 0.0299\n",
      "Epoch 41/200, Iteration 96/250, Loss: 0.0316\n",
      "Epoch 41/200, Iteration 97/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 98/250, Loss: 0.0133\n",
      "Epoch 41/200, Iteration 99/250, Loss: 0.0235\n",
      "Epoch 41/200, Iteration 100/250, Loss: 0.0126\n",
      "Epoch 41/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 41/200, Iteration 102/250, Loss: 0.0126\n",
      "Epoch 41/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 104/250, Loss: 0.0268\n",
      "Epoch 41/200, Iteration 105/250, Loss: 0.0098\n",
      "Epoch 41/200, Iteration 106/250, Loss: 0.0365\n",
      "Epoch 41/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 108/250, Loss: 0.0233\n",
      "Epoch 41/200, Iteration 109/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 110/250, Loss: 0.0207\n",
      "Epoch 41/200, Iteration 111/250, Loss: 0.0229\n",
      "Epoch 41/200, Iteration 112/250, Loss: 0.0229\n",
      "Epoch 41/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 41/200, Iteration 114/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 115/250, Loss: 0.0172\n",
      "Epoch 41/200, Iteration 116/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 117/250, Loss: 0.0311\n",
      "Epoch 41/200, Iteration 118/250, Loss: 0.0079\n",
      "Epoch 41/200, Iteration 119/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 120/250, Loss: 0.0101\n",
      "Epoch 41/200, Iteration 121/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 122/250, Loss: 0.0073\n",
      "Epoch 41/200, Iteration 123/250, Loss: 0.0124\n",
      "Epoch 41/200, Iteration 124/250, Loss: 0.0154\n",
      "Epoch 41/200, Iteration 125/250, Loss: 0.0079\n",
      "Epoch 41/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 41/200, Iteration 127/250, Loss: 0.0181\n",
      "Epoch 41/200, Iteration 128/250, Loss: 0.0185\n",
      "Epoch 41/200, Iteration 129/250, Loss: 0.0161\n",
      "Epoch 41/200, Iteration 130/250, Loss: 0.0178\n",
      "Epoch 41/200, Iteration 131/250, Loss: 0.0121\n",
      "Epoch 41/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 41/200, Iteration 133/250, Loss: 0.0208\n",
      "Epoch 41/200, Iteration 134/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 135/250, Loss: 0.0311\n",
      "Epoch 41/200, Iteration 136/250, Loss: 0.0218\n",
      "Epoch 41/200, Iteration 137/250, Loss: 0.0153\n",
      "Epoch 41/200, Iteration 138/250, Loss: 0.0165\n",
      "Epoch 41/200, Iteration 139/250, Loss: 0.0321\n",
      "Epoch 41/200, Iteration 140/250, Loss: 0.0095\n",
      "Epoch 41/200, Iteration 141/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 142/250, Loss: 0.0148\n",
      "Epoch 41/200, Iteration 143/250, Loss: 0.0157\n",
      "Epoch 41/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 41/200, Iteration 145/250, Loss: 0.0258\n",
      "Epoch 41/200, Iteration 146/250, Loss: 0.0129\n",
      "Epoch 41/200, Iteration 147/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 148/250, Loss: 0.0238\n",
      "Epoch 41/200, Iteration 149/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 150/250, Loss: 0.0131\n",
      "Epoch 41/200, Iteration 151/250, Loss: 0.0087\n",
      "Epoch 41/200, Iteration 152/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 153/250, Loss: 0.0069\n",
      "Epoch 41/200, Iteration 154/250, Loss: 0.0091\n",
      "Epoch 41/200, Iteration 155/250, Loss: 0.0145\n",
      "Epoch 41/200, Iteration 156/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 157/250, Loss: 0.0109\n",
      "Epoch 41/200, Iteration 158/250, Loss: 0.0168\n",
      "Epoch 41/200, Iteration 159/250, Loss: 0.0144\n",
      "Epoch 41/200, Iteration 160/250, Loss: 0.0086\n",
      "Epoch 41/200, Iteration 161/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 162/250, Loss: 0.0079\n",
      "Epoch 41/200, Iteration 163/250, Loss: 0.0272\n",
      "Epoch 41/200, Iteration 164/250, Loss: 0.0307\n",
      "Epoch 41/200, Iteration 165/250, Loss: 0.0066\n",
      "Epoch 41/200, Iteration 166/250, Loss: 0.0251\n",
      "Epoch 41/200, Iteration 167/250, Loss: 0.0128\n",
      "Epoch 41/200, Iteration 168/250, Loss: 0.0165\n",
      "Epoch 41/200, Iteration 169/250, Loss: 0.0233\n",
      "Epoch 41/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 41/200, Iteration 171/250, Loss: 0.0142\n",
      "Epoch 41/200, Iteration 172/250, Loss: 0.0099\n",
      "Epoch 41/200, Iteration 173/250, Loss: 0.0206\n",
      "Epoch 41/200, Iteration 174/250, Loss: 0.0101\n",
      "Epoch 41/200, Iteration 175/250, Loss: 0.0139\n",
      "Epoch 41/200, Iteration 176/250, Loss: 0.0331\n",
      "Epoch 41/200, Iteration 177/250, Loss: 0.0212\n",
      "Epoch 41/200, Iteration 178/250, Loss: 0.0162\n",
      "Epoch 41/200, Iteration 179/250, Loss: 0.0109\n",
      "Epoch 41/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 181/250, Loss: 0.0077\n",
      "Epoch 41/200, Iteration 182/250, Loss: 0.0257\n",
      "Epoch 41/200, Iteration 183/250, Loss: 0.0155\n",
      "Epoch 41/200, Iteration 184/250, Loss: 0.0297\n",
      "Epoch 41/200, Iteration 185/250, Loss: 0.0266\n",
      "Epoch 41/200, Iteration 186/250, Loss: 0.0133\n",
      "Epoch 41/200, Iteration 187/250, Loss: 0.0082\n",
      "Epoch 41/200, Iteration 188/250, Loss: 0.0238\n",
      "Epoch 41/200, Iteration 189/250, Loss: 0.0283\n",
      "Epoch 41/200, Iteration 190/250, Loss: 0.0312\n",
      "Epoch 41/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 193/250, Loss: 0.0155\n",
      "Epoch 41/200, Iteration 194/250, Loss: 0.0240\n",
      "Epoch 41/200, Iteration 195/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 196/250, Loss: 0.0205\n",
      "Epoch 41/200, Iteration 197/250, Loss: 0.0176\n",
      "Epoch 41/200, Iteration 198/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 199/250, Loss: 0.0173\n",
      "Epoch 41/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 41/200, Iteration 201/250, Loss: 0.0126\n",
      "Epoch 41/200, Iteration 202/250, Loss: 0.0149\n",
      "Epoch 41/200, Iteration 203/250, Loss: 0.0217\n",
      "Epoch 41/200, Iteration 204/250, Loss: 0.0103\n",
      "Epoch 41/200, Iteration 205/250, Loss: 0.0502\n",
      "Epoch 41/200, Iteration 206/250, Loss: 0.0098\n",
      "Epoch 41/200, Iteration 207/250, Loss: 0.0167\n",
      "Epoch 41/200, Iteration 208/250, Loss: 0.0108\n",
      "Epoch 41/200, Iteration 209/250, Loss: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Iteration 210/250, Loss: 0.0124\n",
      "Epoch 41/200, Iteration 211/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 212/250, Loss: 0.0094\n",
      "Epoch 41/200, Iteration 213/250, Loss: 0.0124\n",
      "Epoch 41/200, Iteration 214/250, Loss: 0.0058\n",
      "Epoch 41/200, Iteration 215/250, Loss: 0.0164\n",
      "Epoch 41/200, Iteration 216/250, Loss: 0.0086\n",
      "Epoch 41/200, Iteration 217/250, Loss: 0.0108\n",
      "Epoch 41/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 41/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 41/200, Iteration 220/250, Loss: 0.0112\n",
      "Epoch 41/200, Iteration 221/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 222/250, Loss: 0.0087\n",
      "Epoch 41/200, Iteration 223/250, Loss: 0.0250\n",
      "Epoch 41/200, Iteration 224/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 225/250, Loss: 0.0117\n",
      "Epoch 41/200, Iteration 226/250, Loss: 0.0147\n",
      "Epoch 41/200, Iteration 227/250, Loss: 0.0181\n",
      "Epoch 41/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 229/250, Loss: 0.0216\n",
      "Epoch 41/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 231/250, Loss: 0.0240\n",
      "Epoch 41/200, Iteration 232/250, Loss: 0.0216\n",
      "Epoch 41/200, Iteration 233/250, Loss: 0.0142\n",
      "Epoch 41/200, Iteration 234/250, Loss: 0.0156\n",
      "Epoch 41/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 41/200, Iteration 236/250, Loss: 0.0158\n",
      "Epoch 41/200, Iteration 237/250, Loss: 0.0204\n",
      "Epoch 41/200, Iteration 238/250, Loss: 0.0130\n",
      "Epoch 41/200, Iteration 239/250, Loss: 0.0221\n",
      "Epoch 41/200, Iteration 240/250, Loss: 0.0097\n",
      "Epoch 41/200, Iteration 241/250, Loss: 0.0157\n",
      "Epoch 41/200, Iteration 242/250, Loss: 0.0097\n",
      "Epoch 41/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 244/250, Loss: 0.0169\n",
      "Epoch 41/200, Iteration 245/250, Loss: 0.0171\n",
      "Epoch 41/200, Iteration 246/250, Loss: 0.0138\n",
      "Epoch 41/200, Iteration 247/250, Loss: 0.0168\n",
      "Epoch 41/200, Iteration 248/250, Loss: 0.0336\n",
      "Epoch 41/200, Iteration 249/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 250/250, Loss: 0.0365\n",
      "Train Error: \n",
      " Accuracy: 90.92%, Avg loss: 0.007006, MRE: 0.659610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.85%, Avg loss: 0.006950, MRE: 0.942046 \n",
      "\n",
      "Epoch 42/200, Iteration 1/250, Loss: 0.0150\n",
      "Epoch 42/200, Iteration 2/250, Loss: 0.0056\n",
      "Epoch 42/200, Iteration 3/250, Loss: 0.0232\n",
      "Epoch 42/200, Iteration 4/250, Loss: 0.0326\n",
      "Epoch 42/200, Iteration 5/250, Loss: 0.0494\n",
      "Epoch 42/200, Iteration 6/250, Loss: 0.0128\n",
      "Epoch 42/200, Iteration 7/250, Loss: 0.0383\n",
      "Epoch 42/200, Iteration 8/250, Loss: 0.0114\n",
      "Epoch 42/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 42/200, Iteration 10/250, Loss: 0.0203\n",
      "Epoch 42/200, Iteration 11/250, Loss: 0.0173\n",
      "Epoch 42/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 42/200, Iteration 13/250, Loss: 0.0190\n",
      "Epoch 42/200, Iteration 14/250, Loss: 0.0121\n",
      "Epoch 42/200, Iteration 15/250, Loss: 0.0193\n",
      "Epoch 42/200, Iteration 16/250, Loss: 0.0136\n",
      "Epoch 42/200, Iteration 17/250, Loss: 0.0184\n",
      "Epoch 42/200, Iteration 18/250, Loss: 0.0083\n",
      "Epoch 42/200, Iteration 19/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 20/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 42/200, Iteration 22/250, Loss: 0.0343\n",
      "Epoch 42/200, Iteration 23/250, Loss: 0.0079\n",
      "Epoch 42/200, Iteration 24/250, Loss: 0.0199\n",
      "Epoch 42/200, Iteration 25/250, Loss: 0.0190\n",
      "Epoch 42/200, Iteration 26/250, Loss: 0.0205\n",
      "Epoch 42/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 42/200, Iteration 28/250, Loss: 0.0091\n",
      "Epoch 42/200, Iteration 29/250, Loss: 0.0073\n",
      "Epoch 42/200, Iteration 30/250, Loss: 0.0135\n",
      "Epoch 42/200, Iteration 31/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 32/250, Loss: 0.0116\n",
      "Epoch 42/200, Iteration 33/250, Loss: 0.0070\n",
      "Epoch 42/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 35/250, Loss: 0.0119\n",
      "Epoch 42/200, Iteration 36/250, Loss: 0.0299\n",
      "Epoch 42/200, Iteration 37/250, Loss: 0.0140\n",
      "Epoch 42/200, Iteration 38/250, Loss: 0.0188\n",
      "Epoch 42/200, Iteration 39/250, Loss: 0.0191\n",
      "Epoch 42/200, Iteration 40/250, Loss: 0.0092\n",
      "Epoch 42/200, Iteration 41/250, Loss: 0.0151\n",
      "Epoch 42/200, Iteration 42/250, Loss: 0.0234\n",
      "Epoch 42/200, Iteration 43/250, Loss: 0.0242\n",
      "Epoch 42/200, Iteration 44/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 42/200, Iteration 47/250, Loss: 0.0095\n",
      "Epoch 42/200, Iteration 48/250, Loss: 0.0072\n",
      "Epoch 42/200, Iteration 49/250, Loss: 0.0205\n",
      "Epoch 42/200, Iteration 50/250, Loss: 0.0167\n",
      "Epoch 42/200, Iteration 51/250, Loss: 0.0109\n",
      "Epoch 42/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 53/250, Loss: 0.0390\n",
      "Epoch 42/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 42/200, Iteration 55/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 56/250, Loss: 0.0105\n",
      "Epoch 42/200, Iteration 57/250, Loss: 0.0084\n",
      "Epoch 42/200, Iteration 58/250, Loss: 0.0216\n",
      "Epoch 42/200, Iteration 59/250, Loss: 0.0292\n",
      "Epoch 42/200, Iteration 60/250, Loss: 0.0182\n",
      "Epoch 42/200, Iteration 61/250, Loss: 0.0142\n",
      "Epoch 42/200, Iteration 62/250, Loss: 0.0109\n",
      "Epoch 42/200, Iteration 63/250, Loss: 0.0275\n",
      "Epoch 42/200, Iteration 64/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 65/250, Loss: 0.0095\n",
      "Epoch 42/200, Iteration 66/250, Loss: 0.0136\n",
      "Epoch 42/200, Iteration 67/250, Loss: 0.0133\n",
      "Epoch 42/200, Iteration 68/250, Loss: 0.0087\n",
      "Epoch 42/200, Iteration 69/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 70/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 71/250, Loss: 0.0129\n",
      "Epoch 42/200, Iteration 72/250, Loss: 0.0135\n",
      "Epoch 42/200, Iteration 73/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 74/250, Loss: 0.0083\n",
      "Epoch 42/200, Iteration 75/250, Loss: 0.0084\n",
      "Epoch 42/200, Iteration 76/250, Loss: 0.0088\n",
      "Epoch 42/200, Iteration 77/250, Loss: 0.0119\n",
      "Epoch 42/200, Iteration 78/250, Loss: 0.0184\n",
      "Epoch 42/200, Iteration 79/250, Loss: 0.0089\n",
      "Epoch 42/200, Iteration 80/250, Loss: 0.0091\n",
      "Epoch 42/200, Iteration 81/250, Loss: 0.0150\n",
      "Epoch 42/200, Iteration 82/250, Loss: 0.0311\n",
      "Epoch 42/200, Iteration 83/250, Loss: 0.0327\n",
      "Epoch 42/200, Iteration 84/250, Loss: 0.0229\n",
      "Epoch 42/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 86/250, Loss: 0.0227\n",
      "Epoch 42/200, Iteration 87/250, Loss: 0.0271\n",
      "Epoch 42/200, Iteration 88/250, Loss: 0.0235\n",
      "Epoch 42/200, Iteration 89/250, Loss: 0.0150\n",
      "Epoch 42/200, Iteration 90/250, Loss: 0.0132\n",
      "Epoch 42/200, Iteration 91/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 92/250, Loss: 0.0177\n",
      "Epoch 42/200, Iteration 93/250, Loss: 0.0169\n",
      "Epoch 42/200, Iteration 94/250, Loss: 0.0217\n",
      "Epoch 42/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 42/200, Iteration 96/250, Loss: 0.0098\n",
      "Epoch 42/200, Iteration 97/250, Loss: 0.0197\n",
      "Epoch 42/200, Iteration 98/250, Loss: 0.0106\n",
      "Epoch 42/200, Iteration 99/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 100/250, Loss: 0.0124\n",
      "Epoch 42/200, Iteration 101/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 102/250, Loss: 0.0109\n",
      "Epoch 42/200, Iteration 103/250, Loss: 0.0144\n",
      "Epoch 42/200, Iteration 104/250, Loss: 0.0172\n",
      "Epoch 42/200, Iteration 105/250, Loss: 0.0089\n",
      "Epoch 42/200, Iteration 106/250, Loss: 0.0181\n",
      "Epoch 42/200, Iteration 107/250, Loss: 0.0226\n",
      "Epoch 42/200, Iteration 108/250, Loss: 0.0300\n",
      "Epoch 42/200, Iteration 109/250, Loss: 0.0078\n",
      "Epoch 42/200, Iteration 110/250, Loss: 0.0119\n",
      "Epoch 42/200, Iteration 111/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 112/250, Loss: 0.0118\n",
      "Epoch 42/200, Iteration 113/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 114/250, Loss: 0.0197\n",
      "Epoch 42/200, Iteration 115/250, Loss: 0.0096\n",
      "Epoch 42/200, Iteration 116/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 117/250, Loss: 0.0260\n",
      "Epoch 42/200, Iteration 118/250, Loss: 0.0125\n",
      "Epoch 42/200, Iteration 119/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 120/250, Loss: 0.0375\n",
      "Epoch 42/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 42/200, Iteration 122/250, Loss: 0.0180\n",
      "Epoch 42/200, Iteration 123/250, Loss: 0.0103\n",
      "Epoch 42/200, Iteration 124/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 125/250, Loss: 0.0110\n",
      "Epoch 42/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 42/200, Iteration 127/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 128/250, Loss: 0.0203\n",
      "Epoch 42/200, Iteration 129/250, Loss: 0.0217\n",
      "Epoch 42/200, Iteration 130/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 131/250, Loss: 0.0077\n",
      "Epoch 42/200, Iteration 132/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 133/250, Loss: 0.0255\n",
      "Epoch 42/200, Iteration 134/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 135/250, Loss: 0.0176\n",
      "Epoch 42/200, Iteration 136/250, Loss: 0.0283\n",
      "Epoch 42/200, Iteration 137/250, Loss: 0.0275\n",
      "Epoch 42/200, Iteration 138/250, Loss: 0.0169\n",
      "Epoch 42/200, Iteration 139/250, Loss: 0.0224\n",
      "Epoch 42/200, Iteration 140/250, Loss: 0.0141\n",
      "Epoch 42/200, Iteration 141/250, Loss: 0.0164\n",
      "Epoch 42/200, Iteration 142/250, Loss: 0.0126\n",
      "Epoch 42/200, Iteration 143/250, Loss: 0.0143\n",
      "Epoch 42/200, Iteration 144/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 145/250, Loss: 0.0322\n",
      "Epoch 42/200, Iteration 146/250, Loss: 0.0249\n",
      "Epoch 42/200, Iteration 147/250, Loss: 0.0269\n",
      "Epoch 42/200, Iteration 148/250, Loss: 0.0118\n",
      "Epoch 42/200, Iteration 149/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 150/250, Loss: 0.0154\n",
      "Epoch 42/200, Iteration 151/250, Loss: 0.0296\n",
      "Epoch 42/200, Iteration 152/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 153/250, Loss: 0.0191\n",
      "Epoch 42/200, Iteration 154/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 155/250, Loss: 0.0183\n",
      "Epoch 42/200, Iteration 156/250, Loss: 0.0084\n",
      "Epoch 42/200, Iteration 157/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 158/250, Loss: 0.0078\n",
      "Epoch 42/200, Iteration 159/250, Loss: 0.0114\n",
      "Epoch 42/200, Iteration 160/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 161/250, Loss: 0.0118\n",
      "Epoch 42/200, Iteration 162/250, Loss: 0.0178\n",
      "Epoch 42/200, Iteration 163/250, Loss: 0.0274\n",
      "Epoch 42/200, Iteration 164/250, Loss: 0.0160\n",
      "Epoch 42/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 42/200, Iteration 166/250, Loss: 0.0113\n",
      "Epoch 42/200, Iteration 167/250, Loss: 0.0201\n",
      "Epoch 42/200, Iteration 168/250, Loss: 0.0207\n",
      "Epoch 42/200, Iteration 169/250, Loss: 0.0172\n",
      "Epoch 42/200, Iteration 170/250, Loss: 0.0087\n",
      "Epoch 42/200, Iteration 171/250, Loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Iteration 172/250, Loss: 0.0103\n",
      "Epoch 42/200, Iteration 173/250, Loss: 0.0098\n",
      "Epoch 42/200, Iteration 174/250, Loss: 0.0327\n",
      "Epoch 42/200, Iteration 175/250, Loss: 0.0121\n",
      "Epoch 42/200, Iteration 176/250, Loss: 0.0177\n",
      "Epoch 42/200, Iteration 177/250, Loss: 0.0109\n",
      "Epoch 42/200, Iteration 178/250, Loss: 0.0077\n",
      "Epoch 42/200, Iteration 179/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 180/250, Loss: 0.0179\n",
      "Epoch 42/200, Iteration 181/250, Loss: 0.0282\n",
      "Epoch 42/200, Iteration 182/250, Loss: 0.0502\n",
      "Epoch 42/200, Iteration 183/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 184/250, Loss: 0.0222\n",
      "Epoch 42/200, Iteration 185/250, Loss: 0.0431\n",
      "Epoch 42/200, Iteration 186/250, Loss: 0.0439\n",
      "Epoch 42/200, Iteration 187/250, Loss: 0.0197\n",
      "Epoch 42/200, Iteration 188/250, Loss: 0.0182\n",
      "Epoch 42/200, Iteration 189/250, Loss: 0.0147\n",
      "Epoch 42/200, Iteration 190/250, Loss: 0.0240\n",
      "Epoch 42/200, Iteration 191/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 192/250, Loss: 0.0332\n",
      "Epoch 42/200, Iteration 193/250, Loss: 0.0293\n",
      "Epoch 42/200, Iteration 194/250, Loss: 0.0078\n",
      "Epoch 42/200, Iteration 195/250, Loss: 0.0215\n",
      "Epoch 42/200, Iteration 196/250, Loss: 0.0138\n",
      "Epoch 42/200, Iteration 197/250, Loss: 0.0259\n",
      "Epoch 42/200, Iteration 198/250, Loss: 0.0190\n",
      "Epoch 42/200, Iteration 199/250, Loss: 0.0245\n",
      "Epoch 42/200, Iteration 200/250, Loss: 0.0105\n",
      "Epoch 42/200, Iteration 201/250, Loss: 0.0217\n",
      "Epoch 42/200, Iteration 202/250, Loss: 0.0280\n",
      "Epoch 42/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 204/250, Loss: 0.0131\n",
      "Epoch 42/200, Iteration 205/250, Loss: 0.0198\n",
      "Epoch 42/200, Iteration 206/250, Loss: 0.0138\n",
      "Epoch 42/200, Iteration 207/250, Loss: 0.0140\n",
      "Epoch 42/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 209/250, Loss: 0.0189\n",
      "Epoch 42/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 42/200, Iteration 211/250, Loss: 0.0070\n",
      "Epoch 42/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 42/200, Iteration 213/250, Loss: 0.0113\n",
      "Epoch 42/200, Iteration 214/250, Loss: 0.0146\n",
      "Epoch 42/200, Iteration 215/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 216/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 217/250, Loss: 0.0116\n",
      "Epoch 42/200, Iteration 218/250, Loss: 0.0289\n",
      "Epoch 42/200, Iteration 219/250, Loss: 0.0256\n",
      "Epoch 42/200, Iteration 220/250, Loss: 0.0093\n",
      "Epoch 42/200, Iteration 221/250, Loss: 0.0116\n",
      "Epoch 42/200, Iteration 222/250, Loss: 0.0165\n",
      "Epoch 42/200, Iteration 223/250, Loss: 0.0209\n",
      "Epoch 42/200, Iteration 224/250, Loss: 0.0187\n",
      "Epoch 42/200, Iteration 225/250, Loss: 0.0175\n",
      "Epoch 42/200, Iteration 226/250, Loss: 0.0211\n",
      "Epoch 42/200, Iteration 227/250, Loss: 0.0162\n",
      "Epoch 42/200, Iteration 228/250, Loss: 0.0110\n",
      "Epoch 42/200, Iteration 229/250, Loss: 0.0115\n",
      "Epoch 42/200, Iteration 230/250, Loss: 0.0144\n",
      "Epoch 42/200, Iteration 231/250, Loss: 0.0139\n",
      "Epoch 42/200, Iteration 232/250, Loss: 0.0219\n",
      "Epoch 42/200, Iteration 233/250, Loss: 0.0249\n",
      "Epoch 42/200, Iteration 234/250, Loss: 0.0433\n",
      "Epoch 42/200, Iteration 235/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 236/250, Loss: 0.0256\n",
      "Epoch 42/200, Iteration 237/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 238/250, Loss: 0.0382\n",
      "Epoch 42/200, Iteration 239/250, Loss: 0.0102\n",
      "Epoch 42/200, Iteration 240/250, Loss: 0.0185\n",
      "Epoch 42/200, Iteration 241/250, Loss: 0.0143\n",
      "Epoch 42/200, Iteration 242/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 243/250, Loss: 0.0205\n",
      "Epoch 42/200, Iteration 244/250, Loss: 0.0105\n",
      "Epoch 42/200, Iteration 245/250, Loss: 0.0122\n",
      "Epoch 42/200, Iteration 246/250, Loss: 0.0110\n",
      "Epoch 42/200, Iteration 247/250, Loss: 0.0082\n",
      "Epoch 42/200, Iteration 248/250, Loss: 0.0122\n",
      "Epoch 42/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 42/200, Iteration 250/250, Loss: 0.0166\n",
      "Train Error: \n",
      " Accuracy: 88.46%, Avg loss: 0.007195, MRE: 0.642092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.007142, MRE: 1.019195 \n",
      "\n",
      "Epoch 43/200, Iteration 1/250, Loss: 0.0185\n",
      "Epoch 43/200, Iteration 2/250, Loss: 0.0267\n",
      "Epoch 43/200, Iteration 3/250, Loss: 0.0201\n",
      "Epoch 43/200, Iteration 4/250, Loss: 0.0279\n",
      "Epoch 43/200, Iteration 5/250, Loss: 0.0083\n",
      "Epoch 43/200, Iteration 6/250, Loss: 0.0166\n",
      "Epoch 43/200, Iteration 7/250, Loss: 0.0181\n",
      "Epoch 43/200, Iteration 8/250, Loss: 0.0173\n",
      "Epoch 43/200, Iteration 9/250, Loss: 0.0260\n",
      "Epoch 43/200, Iteration 10/250, Loss: 0.0083\n",
      "Epoch 43/200, Iteration 11/250, Loss: 0.0152\n",
      "Epoch 43/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 43/200, Iteration 13/250, Loss: 0.0241\n",
      "Epoch 43/200, Iteration 14/250, Loss: 0.0336\n",
      "Epoch 43/200, Iteration 15/250, Loss: 0.0171\n",
      "Epoch 43/200, Iteration 16/250, Loss: 0.0232\n",
      "Epoch 43/200, Iteration 17/250, Loss: 0.0207\n",
      "Epoch 43/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 43/200, Iteration 19/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 20/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 43/200, Iteration 22/250, Loss: 0.0210\n",
      "Epoch 43/200, Iteration 23/250, Loss: 0.0107\n",
      "Epoch 43/200, Iteration 24/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 25/250, Loss: 0.0123\n",
      "Epoch 43/200, Iteration 26/250, Loss: 0.0112\n",
      "Epoch 43/200, Iteration 27/250, Loss: 0.0089\n",
      "Epoch 43/200, Iteration 28/250, Loss: 0.0111\n",
      "Epoch 43/200, Iteration 29/250, Loss: 0.0124\n",
      "Epoch 43/200, Iteration 30/250, Loss: 0.0079\n",
      "Epoch 43/200, Iteration 31/250, Loss: 0.0199\n",
      "Epoch 43/200, Iteration 32/250, Loss: 0.0128\n",
      "Epoch 43/200, Iteration 33/250, Loss: 0.0263\n",
      "Epoch 43/200, Iteration 34/250, Loss: 0.0086\n",
      "Epoch 43/200, Iteration 35/250, Loss: 0.0134\n",
      "Epoch 43/200, Iteration 36/250, Loss: 0.0094\n",
      "Epoch 43/200, Iteration 37/250, Loss: 0.0196\n",
      "Epoch 43/200, Iteration 38/250, Loss: 0.0124\n",
      "Epoch 43/200, Iteration 39/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 41/250, Loss: 0.0143\n",
      "Epoch 43/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 43/200, Iteration 43/250, Loss: 0.0153\n",
      "Epoch 43/200, Iteration 44/250, Loss: 0.0277\n",
      "Epoch 43/200, Iteration 45/250, Loss: 0.0198\n",
      "Epoch 43/200, Iteration 46/250, Loss: 0.0438\n",
      "Epoch 43/200, Iteration 47/250, Loss: 0.0144\n",
      "Epoch 43/200, Iteration 48/250, Loss: 0.0140\n",
      "Epoch 43/200, Iteration 49/250, Loss: 0.0121\n",
      "Epoch 43/200, Iteration 50/250, Loss: 0.0171\n",
      "Epoch 43/200, Iteration 51/250, Loss: 0.0078\n",
      "Epoch 43/200, Iteration 52/250, Loss: 0.0127\n",
      "Epoch 43/200, Iteration 53/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 54/250, Loss: 0.0098\n",
      "Epoch 43/200, Iteration 55/250, Loss: 0.0082\n",
      "Epoch 43/200, Iteration 56/250, Loss: 0.0091\n",
      "Epoch 43/200, Iteration 57/250, Loss: 0.0092\n",
      "Epoch 43/200, Iteration 58/250, Loss: 0.0077\n",
      "Epoch 43/200, Iteration 59/250, Loss: 0.0085\n",
      "Epoch 43/200, Iteration 60/250, Loss: 0.0128\n",
      "Epoch 43/200, Iteration 61/250, Loss: 0.0110\n",
      "Epoch 43/200, Iteration 62/250, Loss: 0.0239\n",
      "Epoch 43/200, Iteration 63/250, Loss: 0.0113\n",
      "Epoch 43/200, Iteration 64/250, Loss: 0.0095\n",
      "Epoch 43/200, Iteration 65/250, Loss: 0.0430\n",
      "Epoch 43/200, Iteration 66/250, Loss: 0.0080\n",
      "Epoch 43/200, Iteration 67/250, Loss: 0.0186\n",
      "Epoch 43/200, Iteration 68/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 43/200, Iteration 70/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 71/250, Loss: 0.0181\n",
      "Epoch 43/200, Iteration 72/250, Loss: 0.0108\n",
      "Epoch 43/200, Iteration 73/250, Loss: 0.0182\n",
      "Epoch 43/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 43/200, Iteration 75/250, Loss: 0.0098\n",
      "Epoch 43/200, Iteration 76/250, Loss: 0.0162\n",
      "Epoch 43/200, Iteration 77/250, Loss: 0.0076\n",
      "Epoch 43/200, Iteration 78/250, Loss: 0.0104\n",
      "Epoch 43/200, Iteration 79/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 80/250, Loss: 0.0132\n",
      "Epoch 43/200, Iteration 81/250, Loss: 0.0177\n",
      "Epoch 43/200, Iteration 82/250, Loss: 0.0222\n",
      "Epoch 43/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 43/200, Iteration 84/250, Loss: 0.0083\n",
      "Epoch 43/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 86/250, Loss: 0.0115\n",
      "Epoch 43/200, Iteration 87/250, Loss: 0.0192\n",
      "Epoch 43/200, Iteration 88/250, Loss: 0.0104\n",
      "Epoch 43/200, Iteration 89/250, Loss: 0.0091\n",
      "Epoch 43/200, Iteration 90/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 92/250, Loss: 0.0145\n",
      "Epoch 43/200, Iteration 93/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 94/250, Loss: 0.0159\n",
      "Epoch 43/200, Iteration 95/250, Loss: 0.0092\n",
      "Epoch 43/200, Iteration 96/250, Loss: 0.0069\n",
      "Epoch 43/200, Iteration 97/250, Loss: 0.0072\n",
      "Epoch 43/200, Iteration 98/250, Loss: 0.0369\n",
      "Epoch 43/200, Iteration 99/250, Loss: 0.0212\n",
      "Epoch 43/200, Iteration 100/250, Loss: 0.0086\n",
      "Epoch 43/200, Iteration 101/250, Loss: 0.0105\n",
      "Epoch 43/200, Iteration 102/250, Loss: 0.0087\n",
      "Epoch 43/200, Iteration 103/250, Loss: 0.0079\n",
      "Epoch 43/200, Iteration 104/250, Loss: 0.0305\n",
      "Epoch 43/200, Iteration 105/250, Loss: 0.0232\n",
      "Epoch 43/200, Iteration 106/250, Loss: 0.0123\n",
      "Epoch 43/200, Iteration 107/250, Loss: 0.0245\n",
      "Epoch 43/200, Iteration 108/250, Loss: 0.0125\n",
      "Epoch 43/200, Iteration 109/250, Loss: 0.0169\n",
      "Epoch 43/200, Iteration 110/250, Loss: 0.0102\n",
      "Epoch 43/200, Iteration 111/250, Loss: 0.0087\n",
      "Epoch 43/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 43/200, Iteration 113/250, Loss: 0.0094\n",
      "Epoch 43/200, Iteration 114/250, Loss: 0.0193\n",
      "Epoch 43/200, Iteration 115/250, Loss: 0.0185\n",
      "Epoch 43/200, Iteration 116/250, Loss: 0.0118\n",
      "Epoch 43/200, Iteration 117/250, Loss: 0.0240\n",
      "Epoch 43/200, Iteration 118/250, Loss: 0.0161\n",
      "Epoch 43/200, Iteration 119/250, Loss: 0.0183\n",
      "Epoch 43/200, Iteration 120/250, Loss: 0.0090\n",
      "Epoch 43/200, Iteration 121/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 122/250, Loss: 0.0143\n",
      "Epoch 43/200, Iteration 123/250, Loss: 0.0276\n",
      "Epoch 43/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 125/250, Loss: 0.0337\n",
      "Epoch 43/200, Iteration 126/250, Loss: 0.0133\n",
      "Epoch 43/200, Iteration 127/250, Loss: 0.0094\n",
      "Epoch 43/200, Iteration 128/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 129/250, Loss: 0.0209\n",
      "Epoch 43/200, Iteration 130/250, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Iteration 131/250, Loss: 0.0123\n",
      "Epoch 43/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 133/250, Loss: 0.0383\n",
      "Epoch 43/200, Iteration 134/250, Loss: 0.0179\n",
      "Epoch 43/200, Iteration 135/250, Loss: 0.0195\n",
      "Epoch 43/200, Iteration 136/250, Loss: 0.0061\n",
      "Epoch 43/200, Iteration 137/250, Loss: 0.0190\n",
      "Epoch 43/200, Iteration 138/250, Loss: 0.0083\n",
      "Epoch 43/200, Iteration 139/250, Loss: 0.0202\n",
      "Epoch 43/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 141/250, Loss: 0.0132\n",
      "Epoch 43/200, Iteration 142/250, Loss: 0.0124\n",
      "Epoch 43/200, Iteration 143/250, Loss: 0.0246\n",
      "Epoch 43/200, Iteration 144/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 145/250, Loss: 0.0095\n",
      "Epoch 43/200, Iteration 146/250, Loss: 0.0111\n",
      "Epoch 43/200, Iteration 147/250, Loss: 0.0119\n",
      "Epoch 43/200, Iteration 148/250, Loss: 0.0144\n",
      "Epoch 43/200, Iteration 149/250, Loss: 0.0238\n",
      "Epoch 43/200, Iteration 150/250, Loss: 0.0196\n",
      "Epoch 43/200, Iteration 151/250, Loss: 0.0169\n",
      "Epoch 43/200, Iteration 152/250, Loss: 0.0195\n",
      "Epoch 43/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 154/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 155/250, Loss: 0.0071\n",
      "Epoch 43/200, Iteration 156/250, Loss: 0.0075\n",
      "Epoch 43/200, Iteration 157/250, Loss: 0.0078\n",
      "Epoch 43/200, Iteration 158/250, Loss: 0.0081\n",
      "Epoch 43/200, Iteration 159/250, Loss: 0.0192\n",
      "Epoch 43/200, Iteration 160/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 161/250, Loss: 0.0063\n",
      "Epoch 43/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 163/250, Loss: 0.0212\n",
      "Epoch 43/200, Iteration 164/250, Loss: 0.0159\n",
      "Epoch 43/200, Iteration 165/250, Loss: 0.0137\n",
      "Epoch 43/200, Iteration 166/250, Loss: 0.0170\n",
      "Epoch 43/200, Iteration 167/250, Loss: 0.0173\n",
      "Epoch 43/200, Iteration 168/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 169/250, Loss: 0.0098\n",
      "Epoch 43/200, Iteration 170/250, Loss: 0.0098\n",
      "Epoch 43/200, Iteration 171/250, Loss: 0.0181\n",
      "Epoch 43/200, Iteration 172/250, Loss: 0.0293\n",
      "Epoch 43/200, Iteration 173/250, Loss: 0.0143\n",
      "Epoch 43/200, Iteration 174/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 175/250, Loss: 0.0428\n",
      "Epoch 43/200, Iteration 176/250, Loss: 0.0213\n",
      "Epoch 43/200, Iteration 177/250, Loss: 0.0084\n",
      "Epoch 43/200, Iteration 178/250, Loss: 0.0149\n",
      "Epoch 43/200, Iteration 179/250, Loss: 0.0121\n",
      "Epoch 43/200, Iteration 180/250, Loss: 0.0126\n",
      "Epoch 43/200, Iteration 181/250, Loss: 0.0252\n",
      "Epoch 43/200, Iteration 182/250, Loss: 0.0126\n",
      "Epoch 43/200, Iteration 183/250, Loss: 0.0154\n",
      "Epoch 43/200, Iteration 184/250, Loss: 0.0237\n",
      "Epoch 43/200, Iteration 185/250, Loss: 0.0127\n",
      "Epoch 43/200, Iteration 186/250, Loss: 0.0263\n",
      "Epoch 43/200, Iteration 187/250, Loss: 0.0203\n",
      "Epoch 43/200, Iteration 188/250, Loss: 0.0218\n",
      "Epoch 43/200, Iteration 189/250, Loss: 0.0318\n",
      "Epoch 43/200, Iteration 190/250, Loss: 0.0143\n",
      "Epoch 43/200, Iteration 191/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 192/250, Loss: 0.0218\n",
      "Epoch 43/200, Iteration 193/250, Loss: 0.0320\n",
      "Epoch 43/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 43/200, Iteration 195/250, Loss: 0.0167\n",
      "Epoch 43/200, Iteration 196/250, Loss: 0.0186\n",
      "Epoch 43/200, Iteration 197/250, Loss: 0.0147\n",
      "Epoch 43/200, Iteration 198/250, Loss: 0.0115\n",
      "Epoch 43/200, Iteration 199/250, Loss: 0.0184\n",
      "Epoch 43/200, Iteration 200/250, Loss: 0.0349\n",
      "Epoch 43/200, Iteration 201/250, Loss: 0.0160\n",
      "Epoch 43/200, Iteration 202/250, Loss: 0.0255\n",
      "Epoch 43/200, Iteration 203/250, Loss: 0.0114\n",
      "Epoch 43/200, Iteration 204/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 205/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 206/250, Loss: 0.0239\n",
      "Epoch 43/200, Iteration 207/250, Loss: 0.0203\n",
      "Epoch 43/200, Iteration 208/250, Loss: 0.0099\n",
      "Epoch 43/200, Iteration 209/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 210/250, Loss: 0.0097\n",
      "Epoch 43/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 43/200, Iteration 212/250, Loss: 0.0182\n",
      "Epoch 43/200, Iteration 213/250, Loss: 0.0236\n",
      "Epoch 43/200, Iteration 214/250, Loss: 0.0155\n",
      "Epoch 43/200, Iteration 215/250, Loss: 0.0111\n",
      "Epoch 43/200, Iteration 216/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 217/250, Loss: 0.0404\n",
      "Epoch 43/200, Iteration 218/250, Loss: 0.0075\n",
      "Epoch 43/200, Iteration 219/250, Loss: 0.0107\n",
      "Epoch 43/200, Iteration 220/250, Loss: 0.0223\n",
      "Epoch 43/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 43/200, Iteration 222/250, Loss: 0.0149\n",
      "Epoch 43/200, Iteration 223/250, Loss: 0.0279\n",
      "Epoch 43/200, Iteration 224/250, Loss: 0.0195\n",
      "Epoch 43/200, Iteration 225/250, Loss: 0.0238\n",
      "Epoch 43/200, Iteration 226/250, Loss: 0.0220\n",
      "Epoch 43/200, Iteration 227/250, Loss: 0.0159\n",
      "Epoch 43/200, Iteration 228/250, Loss: 0.0124\n",
      "Epoch 43/200, Iteration 229/250, Loss: 0.0239\n",
      "Epoch 43/200, Iteration 230/250, Loss: 0.0327\n",
      "Epoch 43/200, Iteration 231/250, Loss: 0.0327\n",
      "Epoch 43/200, Iteration 232/250, Loss: 0.0118\n",
      "Epoch 43/200, Iteration 233/250, Loss: 0.0277\n",
      "Epoch 43/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 43/200, Iteration 235/250, Loss: 0.0272\n",
      "Epoch 43/200, Iteration 236/250, Loss: 0.0113\n",
      "Epoch 43/200, Iteration 237/250, Loss: 0.0147\n",
      "Epoch 43/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 239/250, Loss: 0.0238\n",
      "Epoch 43/200, Iteration 240/250, Loss: 0.0104\n",
      "Epoch 43/200, Iteration 241/250, Loss: 0.0177\n",
      "Epoch 43/200, Iteration 242/250, Loss: 0.0076\n",
      "Epoch 43/200, Iteration 243/250, Loss: 0.0108\n",
      "Epoch 43/200, Iteration 244/250, Loss: 0.0075\n",
      "Epoch 43/200, Iteration 245/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 246/250, Loss: 0.0159\n",
      "Epoch 43/200, Iteration 247/250, Loss: 0.0080\n",
      "Epoch 43/200, Iteration 248/250, Loss: 0.0195\n",
      "Epoch 43/200, Iteration 249/250, Loss: 0.0214\n",
      "Epoch 43/200, Iteration 250/250, Loss: 0.0094\n",
      "Train Error: \n",
      " Accuracy: 86.76%, Avg loss: 0.007052, MRE: 0.638923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.95%, Avg loss: 0.007020, MRE: 0.828834 \n",
      "\n",
      "Epoch 44/200, Iteration 1/250, Loss: 0.0138\n",
      "Epoch 44/200, Iteration 2/250, Loss: 0.0098\n",
      "Epoch 44/200, Iteration 3/250, Loss: 0.0066\n",
      "Epoch 44/200, Iteration 4/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 6/250, Loss: 0.0291\n",
      "Epoch 44/200, Iteration 7/250, Loss: 0.0216\n",
      "Epoch 44/200, Iteration 8/250, Loss: 0.0130\n",
      "Epoch 44/200, Iteration 9/250, Loss: 0.0188\n",
      "Epoch 44/200, Iteration 10/250, Loss: 0.0232\n",
      "Epoch 44/200, Iteration 11/250, Loss: 0.0083\n",
      "Epoch 44/200, Iteration 12/250, Loss: 0.0156\n",
      "Epoch 44/200, Iteration 13/250, Loss: 0.0097\n",
      "Epoch 44/200, Iteration 14/250, Loss: 0.0364\n",
      "Epoch 44/200, Iteration 15/250, Loss: 0.0148\n",
      "Epoch 44/200, Iteration 16/250, Loss: 0.0150\n",
      "Epoch 44/200, Iteration 17/250, Loss: 0.0112\n",
      "Epoch 44/200, Iteration 18/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 19/250, Loss: 0.0111\n",
      "Epoch 44/200, Iteration 20/250, Loss: 0.0098\n",
      "Epoch 44/200, Iteration 21/250, Loss: 0.0086\n",
      "Epoch 44/200, Iteration 22/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 44/200, Iteration 24/250, Loss: 0.0164\n",
      "Epoch 44/200, Iteration 25/250, Loss: 0.0128\n",
      "Epoch 44/200, Iteration 26/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 27/250, Loss: 0.0437\n",
      "Epoch 44/200, Iteration 28/250, Loss: 0.0509\n",
      "Epoch 44/200, Iteration 29/250, Loss: 0.0476\n",
      "Epoch 44/200, Iteration 30/250, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 31/250, Loss: 0.0163\n",
      "Epoch 44/200, Iteration 32/250, Loss: 0.0130\n",
      "Epoch 44/200, Iteration 33/250, Loss: 0.0114\n",
      "Epoch 44/200, Iteration 34/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 35/250, Loss: 0.0085\n",
      "Epoch 44/200, Iteration 36/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 37/250, Loss: 0.0128\n",
      "Epoch 44/200, Iteration 38/250, Loss: 0.0085\n",
      "Epoch 44/200, Iteration 39/250, Loss: 0.0180\n",
      "Epoch 44/200, Iteration 40/250, Loss: 0.0206\n",
      "Epoch 44/200, Iteration 41/250, Loss: 0.0116\n",
      "Epoch 44/200, Iteration 42/250, Loss: 0.0182\n",
      "Epoch 44/200, Iteration 43/250, Loss: 0.0160\n",
      "Epoch 44/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 44/200, Iteration 45/250, Loss: 0.0077\n",
      "Epoch 44/200, Iteration 46/250, Loss: 0.0283\n",
      "Epoch 44/200, Iteration 47/250, Loss: 0.0260\n",
      "Epoch 44/200, Iteration 48/250, Loss: 0.0255\n",
      "Epoch 44/200, Iteration 49/250, Loss: 0.0076\n",
      "Epoch 44/200, Iteration 50/250, Loss: 0.0105\n",
      "Epoch 44/200, Iteration 51/250, Loss: 0.0086\n",
      "Epoch 44/200, Iteration 52/250, Loss: 0.0310\n",
      "Epoch 44/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 54/250, Loss: 0.0138\n",
      "Epoch 44/200, Iteration 55/250, Loss: 0.0175\n",
      "Epoch 44/200, Iteration 56/250, Loss: 0.0075\n",
      "Epoch 44/200, Iteration 57/250, Loss: 0.0177\n",
      "Epoch 44/200, Iteration 58/250, Loss: 0.0157\n",
      "Epoch 44/200, Iteration 59/250, Loss: 0.0276\n",
      "Epoch 44/200, Iteration 60/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 61/250, Loss: 0.0137\n",
      "Epoch 44/200, Iteration 62/250, Loss: 0.0250\n",
      "Epoch 44/200, Iteration 63/250, Loss: 0.0069\n",
      "Epoch 44/200, Iteration 64/250, Loss: 0.0275\n",
      "Epoch 44/200, Iteration 65/250, Loss: 0.0225\n",
      "Epoch 44/200, Iteration 66/250, Loss: 0.0107\n",
      "Epoch 44/200, Iteration 67/250, Loss: 0.0094\n",
      "Epoch 44/200, Iteration 68/250, Loss: 0.0130\n",
      "Epoch 44/200, Iteration 69/250, Loss: 0.0206\n",
      "Epoch 44/200, Iteration 70/250, Loss: 0.0303\n",
      "Epoch 44/200, Iteration 71/250, Loss: 0.0246\n",
      "Epoch 44/200, Iteration 72/250, Loss: 0.0117\n",
      "Epoch 44/200, Iteration 73/250, Loss: 0.0134\n",
      "Epoch 44/200, Iteration 74/250, Loss: 0.0140\n",
      "Epoch 44/200, Iteration 75/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 76/250, Loss: 0.0084\n",
      "Epoch 44/200, Iteration 77/250, Loss: 0.0092\n",
      "Epoch 44/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 44/200, Iteration 79/250, Loss: 0.0145\n",
      "Epoch 44/200, Iteration 80/250, Loss: 0.0210\n",
      "Epoch 44/200, Iteration 81/250, Loss: 0.0089\n",
      "Epoch 44/200, Iteration 82/250, Loss: 0.0358\n",
      "Epoch 44/200, Iteration 83/250, Loss: 0.0240\n",
      "Epoch 44/200, Iteration 84/250, Loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Iteration 85/250, Loss: 0.0139\n",
      "Epoch 44/200, Iteration 86/250, Loss: 0.0304\n",
      "Epoch 44/200, Iteration 87/250, Loss: 0.0254\n",
      "Epoch 44/200, Iteration 88/250, Loss: 0.0099\n",
      "Epoch 44/200, Iteration 89/250, Loss: 0.0167\n",
      "Epoch 44/200, Iteration 90/250, Loss: 0.0142\n",
      "Epoch 44/200, Iteration 91/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 92/250, Loss: 0.0143\n",
      "Epoch 44/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 44/200, Iteration 94/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 95/250, Loss: 0.0128\n",
      "Epoch 44/200, Iteration 96/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 97/250, Loss: 0.0356\n",
      "Epoch 44/200, Iteration 98/250, Loss: 0.0258\n",
      "Epoch 44/200, Iteration 99/250, Loss: 0.0178\n",
      "Epoch 44/200, Iteration 100/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 101/250, Loss: 0.0092\n",
      "Epoch 44/200, Iteration 102/250, Loss: 0.0247\n",
      "Epoch 44/200, Iteration 103/250, Loss: 0.0215\n",
      "Epoch 44/200, Iteration 104/250, Loss: 0.0139\n",
      "Epoch 44/200, Iteration 105/250, Loss: 0.0174\n",
      "Epoch 44/200, Iteration 106/250, Loss: 0.0203\n",
      "Epoch 44/200, Iteration 107/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 108/250, Loss: 0.0184\n",
      "Epoch 44/200, Iteration 109/250, Loss: 0.0087\n",
      "Epoch 44/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 111/250, Loss: 0.0102\n",
      "Epoch 44/200, Iteration 112/250, Loss: 0.0122\n",
      "Epoch 44/200, Iteration 113/250, Loss: 0.0123\n",
      "Epoch 44/200, Iteration 114/250, Loss: 0.0131\n",
      "Epoch 44/200, Iteration 115/250, Loss: 0.0172\n",
      "Epoch 44/200, Iteration 116/250, Loss: 0.0221\n",
      "Epoch 44/200, Iteration 117/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 118/250, Loss: 0.0090\n",
      "Epoch 44/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 120/250, Loss: 0.0158\n",
      "Epoch 44/200, Iteration 121/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 122/250, Loss: 0.0203\n",
      "Epoch 44/200, Iteration 123/250, Loss: 0.0204\n",
      "Epoch 44/200, Iteration 124/250, Loss: 0.0166\n",
      "Epoch 44/200, Iteration 125/250, Loss: 0.0279\n",
      "Epoch 44/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 44/200, Iteration 127/250, Loss: 0.0258\n",
      "Epoch 44/200, Iteration 128/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 129/250, Loss: 0.0152\n",
      "Epoch 44/200, Iteration 130/250, Loss: 0.0186\n",
      "Epoch 44/200, Iteration 131/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 132/250, Loss: 0.0087\n",
      "Epoch 44/200, Iteration 133/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 44/200, Iteration 135/250, Loss: 0.0156\n",
      "Epoch 44/200, Iteration 136/250, Loss: 0.0229\n",
      "Epoch 44/200, Iteration 137/250, Loss: 0.0114\n",
      "Epoch 44/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 44/200, Iteration 139/250, Loss: 0.0259\n",
      "Epoch 44/200, Iteration 140/250, Loss: 0.0187\n",
      "Epoch 44/200, Iteration 141/250, Loss: 0.0219\n",
      "Epoch 44/200, Iteration 142/250, Loss: 0.0195\n",
      "Epoch 44/200, Iteration 143/250, Loss: 0.0147\n",
      "Epoch 44/200, Iteration 144/250, Loss: 0.0149\n",
      "Epoch 44/200, Iteration 145/250, Loss: 0.0151\n",
      "Epoch 44/200, Iteration 146/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 147/250, Loss: 0.0142\n",
      "Epoch 44/200, Iteration 148/250, Loss: 0.0137\n",
      "Epoch 44/200, Iteration 149/250, Loss: 0.0154\n",
      "Epoch 44/200, Iteration 150/250, Loss: 0.0086\n",
      "Epoch 44/200, Iteration 151/250, Loss: 0.0191\n",
      "Epoch 44/200, Iteration 152/250, Loss: 0.0296\n",
      "Epoch 44/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 44/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 44/200, Iteration 155/250, Loss: 0.0177\n",
      "Epoch 44/200, Iteration 156/250, Loss: 0.0158\n",
      "Epoch 44/200, Iteration 157/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 158/250, Loss: 0.0187\n",
      "Epoch 44/200, Iteration 159/250, Loss: 0.0162\n",
      "Epoch 44/200, Iteration 160/250, Loss: 0.0336\n",
      "Epoch 44/200, Iteration 161/250, Loss: 0.0357\n",
      "Epoch 44/200, Iteration 162/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 163/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 164/250, Loss: 0.0237\n",
      "Epoch 44/200, Iteration 165/250, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 166/250, Loss: 0.0122\n",
      "Epoch 44/200, Iteration 167/250, Loss: 0.0118\n",
      "Epoch 44/200, Iteration 168/250, Loss: 0.0154\n",
      "Epoch 44/200, Iteration 169/250, Loss: 0.0280\n",
      "Epoch 44/200, Iteration 170/250, Loss: 0.0111\n",
      "Epoch 44/200, Iteration 171/250, Loss: 0.0305\n",
      "Epoch 44/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 173/250, Loss: 0.0172\n",
      "Epoch 44/200, Iteration 174/250, Loss: 0.0151\n",
      "Epoch 44/200, Iteration 175/250, Loss: 0.0098\n",
      "Epoch 44/200, Iteration 176/250, Loss: 0.0205\n",
      "Epoch 44/200, Iteration 177/250, Loss: 0.0131\n",
      "Epoch 44/200, Iteration 178/250, Loss: 0.0078\n",
      "Epoch 44/200, Iteration 179/250, Loss: 0.0220\n",
      "Epoch 44/200, Iteration 180/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 181/250, Loss: 0.0126\n",
      "Epoch 44/200, Iteration 182/250, Loss: 0.0088\n",
      "Epoch 44/200, Iteration 183/250, Loss: 0.0082\n",
      "Epoch 44/200, Iteration 184/250, Loss: 0.0186\n",
      "Epoch 44/200, Iteration 185/250, Loss: 0.0094\n",
      "Epoch 44/200, Iteration 186/250, Loss: 0.0141\n",
      "Epoch 44/200, Iteration 187/250, Loss: 0.0126\n",
      "Epoch 44/200, Iteration 188/250, Loss: 0.0255\n",
      "Epoch 44/200, Iteration 189/250, Loss: 0.0207\n",
      "Epoch 44/200, Iteration 190/250, Loss: 0.0089\n",
      "Epoch 44/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 192/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 193/250, Loss: 0.0194\n",
      "Epoch 44/200, Iteration 194/250, Loss: 0.0168\n",
      "Epoch 44/200, Iteration 195/250, Loss: 0.0084\n",
      "Epoch 44/200, Iteration 196/250, Loss: 0.0175\n",
      "Epoch 44/200, Iteration 197/250, Loss: 0.0244\n",
      "Epoch 44/200, Iteration 198/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 199/250, Loss: 0.0101\n",
      "Epoch 44/200, Iteration 200/250, Loss: 0.0237\n",
      "Epoch 44/200, Iteration 201/250, Loss: 0.0187\n",
      "Epoch 44/200, Iteration 202/250, Loss: 0.0317\n",
      "Epoch 44/200, Iteration 203/250, Loss: 0.0137\n",
      "Epoch 44/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 44/200, Iteration 205/250, Loss: 0.0259\n",
      "Epoch 44/200, Iteration 206/250, Loss: 0.0149\n",
      "Epoch 44/200, Iteration 207/250, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 208/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 209/250, Loss: 0.0082\n",
      "Epoch 44/200, Iteration 210/250, Loss: 0.0195\n",
      "Epoch 44/200, Iteration 211/250, Loss: 0.0084\n",
      "Epoch 44/200, Iteration 212/250, Loss: 0.0168\n",
      "Epoch 44/200, Iteration 213/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 214/250, Loss: 0.0214\n",
      "Epoch 44/200, Iteration 215/250, Loss: 0.0145\n",
      "Epoch 44/200, Iteration 216/250, Loss: 0.0105\n",
      "Epoch 44/200, Iteration 217/250, Loss: 0.0098\n",
      "Epoch 44/200, Iteration 218/250, Loss: 0.0076\n",
      "Epoch 44/200, Iteration 219/250, Loss: 0.0324\n",
      "Epoch 44/200, Iteration 220/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 44/200, Iteration 222/250, Loss: 0.0111\n",
      "Epoch 44/200, Iteration 223/250, Loss: 0.0095\n",
      "Epoch 44/200, Iteration 224/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 225/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 226/250, Loss: 0.0123\n",
      "Epoch 44/200, Iteration 227/250, Loss: 0.0150\n",
      "Epoch 44/200, Iteration 228/250, Loss: 0.0299\n",
      "Epoch 44/200, Iteration 229/250, Loss: 0.0149\n",
      "Epoch 44/200, Iteration 230/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 231/250, Loss: 0.0212\n",
      "Epoch 44/200, Iteration 232/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 233/250, Loss: 0.0185\n",
      "Epoch 44/200, Iteration 234/250, Loss: 0.0215\n",
      "Epoch 44/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 44/200, Iteration 236/250, Loss: 0.0147\n",
      "Epoch 44/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 238/250, Loss: 0.0176\n",
      "Epoch 44/200, Iteration 239/250, Loss: 0.0165\n",
      "Epoch 44/200, Iteration 240/250, Loss: 0.0122\n",
      "Epoch 44/200, Iteration 241/250, Loss: 0.0107\n",
      "Epoch 44/200, Iteration 242/250, Loss: 0.0091\n",
      "Epoch 44/200, Iteration 243/250, Loss: 0.0218\n",
      "Epoch 44/200, Iteration 244/250, Loss: 0.0262\n",
      "Epoch 44/200, Iteration 245/250, Loss: 0.0115\n",
      "Epoch 44/200, Iteration 246/250, Loss: 0.0094\n",
      "Epoch 44/200, Iteration 247/250, Loss: 0.0186\n",
      "Epoch 44/200, Iteration 248/250, Loss: 0.0161\n",
      "Epoch 44/200, Iteration 249/250, Loss: 0.0102\n",
      "Epoch 44/200, Iteration 250/250, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.007998, MRE: 0.672670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.007985, MRE: 0.857333 \n",
      "\n",
      "Epoch 45/200, Iteration 1/250, Loss: 0.0117\n",
      "Epoch 45/200, Iteration 2/250, Loss: 0.0205\n",
      "Epoch 45/200, Iteration 3/250, Loss: 0.0187\n",
      "Epoch 45/200, Iteration 4/250, Loss: 0.0082\n",
      "Epoch 45/200, Iteration 5/250, Loss: 0.0381\n",
      "Epoch 45/200, Iteration 6/250, Loss: 0.0188\n",
      "Epoch 45/200, Iteration 7/250, Loss: 0.0098\n",
      "Epoch 45/200, Iteration 8/250, Loss: 0.0169\n",
      "Epoch 45/200, Iteration 9/250, Loss: 0.0183\n",
      "Epoch 45/200, Iteration 10/250, Loss: 0.0099\n",
      "Epoch 45/200, Iteration 11/250, Loss: 0.0146\n",
      "Epoch 45/200, Iteration 12/250, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Iteration 13/250, Loss: 0.0111\n",
      "Epoch 45/200, Iteration 14/250, Loss: 0.0267\n",
      "Epoch 45/200, Iteration 15/250, Loss: 0.0242\n",
      "Epoch 45/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 45/200, Iteration 17/250, Loss: 0.0197\n",
      "Epoch 45/200, Iteration 18/250, Loss: 0.0141\n",
      "Epoch 45/200, Iteration 19/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 20/250, Loss: 0.0195\n",
      "Epoch 45/200, Iteration 21/250, Loss: 0.0438\n",
      "Epoch 45/200, Iteration 22/250, Loss: 0.0169\n",
      "Epoch 45/200, Iteration 23/250, Loss: 0.0174\n",
      "Epoch 45/200, Iteration 24/250, Loss: 0.0369\n",
      "Epoch 45/200, Iteration 25/250, Loss: 0.0151\n",
      "Epoch 45/200, Iteration 26/250, Loss: 0.0230\n",
      "Epoch 45/200, Iteration 27/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 28/250, Loss: 0.0336\n",
      "Epoch 45/200, Iteration 29/250, Loss: 0.0143\n",
      "Epoch 45/200, Iteration 30/250, Loss: 0.0251\n",
      "Epoch 45/200, Iteration 31/250, Loss: 0.0141\n",
      "Epoch 45/200, Iteration 32/250, Loss: 0.0096\n",
      "Epoch 45/200, Iteration 33/250, Loss: 0.0379\n",
      "Epoch 45/200, Iteration 34/250, Loss: 0.0090\n",
      "Epoch 45/200, Iteration 35/250, Loss: 0.0188\n",
      "Epoch 45/200, Iteration 36/250, Loss: 0.0076\n",
      "Epoch 45/200, Iteration 37/250, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 38/250, Loss: 0.0326\n",
      "Epoch 45/200, Iteration 39/250, Loss: 0.0125\n",
      "Epoch 45/200, Iteration 40/250, Loss: 0.0244\n",
      "Epoch 45/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 42/250, Loss: 0.0243\n",
      "Epoch 45/200, Iteration 43/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 44/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 45/250, Loss: 0.0133\n",
      "Epoch 45/200, Iteration 46/250, Loss: 0.0225\n",
      "Epoch 45/200, Iteration 47/250, Loss: 0.0269\n",
      "Epoch 45/200, Iteration 48/250, Loss: 0.0080\n",
      "Epoch 45/200, Iteration 49/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 50/250, Loss: 0.0173\n",
      "Epoch 45/200, Iteration 51/250, Loss: 0.0091\n",
      "Epoch 45/200, Iteration 52/250, Loss: 0.0290\n",
      "Epoch 45/200, Iteration 53/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 54/250, Loss: 0.0092\n",
      "Epoch 45/200, Iteration 55/250, Loss: 0.0090\n",
      "Epoch 45/200, Iteration 56/250, Loss: 0.0163\n",
      "Epoch 45/200, Iteration 57/250, Loss: 0.0185\n",
      "Epoch 45/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 45/200, Iteration 59/250, Loss: 0.0095\n",
      "Epoch 45/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 45/200, Iteration 61/250, Loss: 0.0117\n",
      "Epoch 45/200, Iteration 62/250, Loss: 0.0229\n",
      "Epoch 45/200, Iteration 63/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 64/250, Loss: 0.0096\n",
      "Epoch 45/200, Iteration 65/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 66/250, Loss: 0.0318\n",
      "Epoch 45/200, Iteration 67/250, Loss: 0.0149\n",
      "Epoch 45/200, Iteration 68/250, Loss: 0.0154\n",
      "Epoch 45/200, Iteration 69/250, Loss: 0.0166\n",
      "Epoch 45/200, Iteration 70/250, Loss: 0.0086\n",
      "Epoch 45/200, Iteration 71/250, Loss: 0.0071\n",
      "Epoch 45/200, Iteration 72/250, Loss: 0.0084\n",
      "Epoch 45/200, Iteration 73/250, Loss: 0.0096\n",
      "Epoch 45/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 45/200, Iteration 75/250, Loss: 0.0211\n",
      "Epoch 45/200, Iteration 76/250, Loss: 0.0111\n",
      "Epoch 45/200, Iteration 77/250, Loss: 0.0133\n",
      "Epoch 45/200, Iteration 78/250, Loss: 0.0266\n",
      "Epoch 45/200, Iteration 79/250, Loss: 0.0197\n",
      "Epoch 45/200, Iteration 80/250, Loss: 0.0186\n",
      "Epoch 45/200, Iteration 81/250, Loss: 0.0140\n",
      "Epoch 45/200, Iteration 82/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 83/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 84/250, Loss: 0.0057\n",
      "Epoch 45/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 45/200, Iteration 86/250, Loss: 0.0081\n",
      "Epoch 45/200, Iteration 87/250, Loss: 0.0223\n",
      "Epoch 45/200, Iteration 88/250, Loss: 0.0119\n",
      "Epoch 45/200, Iteration 89/250, Loss: 0.0383\n",
      "Epoch 45/200, Iteration 90/250, Loss: 0.0107\n",
      "Epoch 45/200, Iteration 91/250, Loss: 0.0080\n",
      "Epoch 45/200, Iteration 92/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 93/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 94/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 95/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 96/250, Loss: 0.0178\n",
      "Epoch 45/200, Iteration 97/250, Loss: 0.0080\n",
      "Epoch 45/200, Iteration 98/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 99/250, Loss: 0.0088\n",
      "Epoch 45/200, Iteration 100/250, Loss: 0.0074\n",
      "Epoch 45/200, Iteration 101/250, Loss: 0.0143\n",
      "Epoch 45/200, Iteration 102/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 103/250, Loss: 0.0296\n",
      "Epoch 45/200, Iteration 104/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 105/250, Loss: 0.0166\n",
      "Epoch 45/200, Iteration 106/250, Loss: 0.0117\n",
      "Epoch 45/200, Iteration 107/250, Loss: 0.0142\n",
      "Epoch 45/200, Iteration 108/250, Loss: 0.0077\n",
      "Epoch 45/200, Iteration 109/250, Loss: 0.0109\n",
      "Epoch 45/200, Iteration 110/250, Loss: 0.0177\n",
      "Epoch 45/200, Iteration 111/250, Loss: 0.0108\n",
      "Epoch 45/200, Iteration 112/250, Loss: 0.0165\n",
      "Epoch 45/200, Iteration 113/250, Loss: 0.0164\n",
      "Epoch 45/200, Iteration 114/250, Loss: 0.0132\n",
      "Epoch 45/200, Iteration 115/250, Loss: 0.0124\n",
      "Epoch 45/200, Iteration 116/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 45/200, Iteration 118/250, Loss: 0.0256\n",
      "Epoch 45/200, Iteration 119/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 120/250, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 121/250, Loss: 0.0084\n",
      "Epoch 45/200, Iteration 122/250, Loss: 0.0211\n",
      "Epoch 45/200, Iteration 123/250, Loss: 0.0129\n",
      "Epoch 45/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 125/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 126/250, Loss: 0.0181\n",
      "Epoch 45/200, Iteration 127/250, Loss: 0.0089\n",
      "Epoch 45/200, Iteration 128/250, Loss: 0.0083\n",
      "Epoch 45/200, Iteration 129/250, Loss: 0.0067\n",
      "Epoch 45/200, Iteration 130/250, Loss: 0.0134\n",
      "Epoch 45/200, Iteration 131/250, Loss: 0.0075\n",
      "Epoch 45/200, Iteration 132/250, Loss: 0.0288\n",
      "Epoch 45/200, Iteration 133/250, Loss: 0.0200\n",
      "Epoch 45/200, Iteration 134/250, Loss: 0.0209\n",
      "Epoch 45/200, Iteration 135/250, Loss: 0.0192\n",
      "Epoch 45/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 45/200, Iteration 137/250, Loss: 0.0230\n",
      "Epoch 45/200, Iteration 138/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 139/250, Loss: 0.0304\n",
      "Epoch 45/200, Iteration 140/250, Loss: 0.0086\n",
      "Epoch 45/200, Iteration 141/250, Loss: 0.0208\n",
      "Epoch 45/200, Iteration 142/250, Loss: 0.0235\n",
      "Epoch 45/200, Iteration 143/250, Loss: 0.0169\n",
      "Epoch 45/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 45/200, Iteration 145/250, Loss: 0.0142\n",
      "Epoch 45/200, Iteration 146/250, Loss: 0.0388\n",
      "Epoch 45/200, Iteration 147/250, Loss: 0.0469\n",
      "Epoch 45/200, Iteration 148/250, Loss: 0.0170\n",
      "Epoch 45/200, Iteration 149/250, Loss: 0.0194\n",
      "Epoch 45/200, Iteration 150/250, Loss: 0.0195\n",
      "Epoch 45/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 152/250, Loss: 0.0150\n",
      "Epoch 45/200, Iteration 153/250, Loss: 0.0113\n",
      "Epoch 45/200, Iteration 154/250, Loss: 0.0141\n",
      "Epoch 45/200, Iteration 155/250, Loss: 0.0085\n",
      "Epoch 45/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 45/200, Iteration 157/250, Loss: 0.0072\n",
      "Epoch 45/200, Iteration 158/250, Loss: 0.0214\n",
      "Epoch 45/200, Iteration 159/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 160/250, Loss: 0.0083\n",
      "Epoch 45/200, Iteration 161/250, Loss: 0.0140\n",
      "Epoch 45/200, Iteration 162/250, Loss: 0.0189\n",
      "Epoch 45/200, Iteration 163/250, Loss: 0.0213\n",
      "Epoch 45/200, Iteration 164/250, Loss: 0.0242\n",
      "Epoch 45/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 45/200, Iteration 166/250, Loss: 0.0228\n",
      "Epoch 45/200, Iteration 167/250, Loss: 0.0154\n",
      "Epoch 45/200, Iteration 168/250, Loss: 0.0212\n",
      "Epoch 45/200, Iteration 169/250, Loss: 0.0072\n",
      "Epoch 45/200, Iteration 170/250, Loss: 0.0235\n",
      "Epoch 45/200, Iteration 171/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 172/250, Loss: 0.0417\n",
      "Epoch 45/200, Iteration 173/250, Loss: 0.0104\n",
      "Epoch 45/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 45/200, Iteration 175/250, Loss: 0.0161\n",
      "Epoch 45/200, Iteration 176/250, Loss: 0.0099\n",
      "Epoch 45/200, Iteration 177/250, Loss: 0.0207\n",
      "Epoch 45/200, Iteration 178/250, Loss: 0.0098\n",
      "Epoch 45/200, Iteration 179/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 180/250, Loss: 0.0201\n",
      "Epoch 45/200, Iteration 181/250, Loss: 0.0101\n",
      "Epoch 45/200, Iteration 182/250, Loss: 0.0208\n",
      "Epoch 45/200, Iteration 183/250, Loss: 0.0208\n",
      "Epoch 45/200, Iteration 184/250, Loss: 0.0198\n",
      "Epoch 45/200, Iteration 185/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 186/250, Loss: 0.0111\n",
      "Epoch 45/200, Iteration 187/250, Loss: 0.0120\n",
      "Epoch 45/200, Iteration 188/250, Loss: 0.0368\n",
      "Epoch 45/200, Iteration 189/250, Loss: 0.0082\n",
      "Epoch 45/200, Iteration 190/250, Loss: 0.0299\n",
      "Epoch 45/200, Iteration 191/250, Loss: 0.0174\n",
      "Epoch 45/200, Iteration 192/250, Loss: 0.0106\n",
      "Epoch 45/200, Iteration 193/250, Loss: 0.0231\n",
      "Epoch 45/200, Iteration 194/250, Loss: 0.0385\n",
      "Epoch 45/200, Iteration 195/250, Loss: 0.0167\n",
      "Epoch 45/200, Iteration 196/250, Loss: 0.0187\n",
      "Epoch 45/200, Iteration 197/250, Loss: 0.0200\n",
      "Epoch 45/200, Iteration 198/250, Loss: 0.0225\n",
      "Epoch 45/200, Iteration 199/250, Loss: 0.0150\n",
      "Epoch 45/200, Iteration 200/250, Loss: 0.0092\n",
      "Epoch 45/200, Iteration 201/250, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 202/250, Loss: 0.0165\n",
      "Epoch 45/200, Iteration 203/250, Loss: 0.0300\n",
      "Epoch 45/200, Iteration 204/250, Loss: 0.0092\n",
      "Epoch 45/200, Iteration 205/250, Loss: 0.0476\n",
      "Epoch 45/200, Iteration 206/250, Loss: 0.0137\n",
      "Epoch 45/200, Iteration 207/250, Loss: 0.0192\n",
      "Epoch 45/200, Iteration 208/250, Loss: 0.0153\n",
      "Epoch 45/200, Iteration 209/250, Loss: 0.0097\n",
      "Epoch 45/200, Iteration 210/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Iteration 211/250, Loss: 0.0154\n",
      "Epoch 45/200, Iteration 212/250, Loss: 0.0123\n",
      "Epoch 45/200, Iteration 213/250, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 214/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 215/250, Loss: 0.0073\n",
      "Epoch 45/200, Iteration 216/250, Loss: 0.0232\n",
      "Epoch 45/200, Iteration 217/250, Loss: 0.0330\n",
      "Epoch 45/200, Iteration 218/250, Loss: 0.0258\n",
      "Epoch 45/200, Iteration 219/250, Loss: 0.0185\n",
      "Epoch 45/200, Iteration 220/250, Loss: 0.0144\n",
      "Epoch 45/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 222/250, Loss: 0.0180\n",
      "Epoch 45/200, Iteration 223/250, Loss: 0.0101\n",
      "Epoch 45/200, Iteration 224/250, Loss: 0.0184\n",
      "Epoch 45/200, Iteration 225/250, Loss: 0.0226\n",
      "Epoch 45/200, Iteration 226/250, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 227/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 228/250, Loss: 0.0088\n",
      "Epoch 45/200, Iteration 229/250, Loss: 0.0268\n",
      "Epoch 45/200, Iteration 230/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 231/250, Loss: 0.0156\n",
      "Epoch 45/200, Iteration 232/250, Loss: 0.0246\n",
      "Epoch 45/200, Iteration 233/250, Loss: 0.0159\n",
      "Epoch 45/200, Iteration 234/250, Loss: 0.0298\n",
      "Epoch 45/200, Iteration 235/250, Loss: 0.0193\n",
      "Epoch 45/200, Iteration 236/250, Loss: 0.0361\n",
      "Epoch 45/200, Iteration 237/250, Loss: 0.0271\n",
      "Epoch 45/200, Iteration 238/250, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 239/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 240/250, Loss: 0.0152\n",
      "Epoch 45/200, Iteration 241/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 242/250, Loss: 0.0223\n",
      "Epoch 45/200, Iteration 243/250, Loss: 0.0279\n",
      "Epoch 45/200, Iteration 244/250, Loss: 0.0228\n",
      "Epoch 45/200, Iteration 245/250, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 246/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 247/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 249/250, Loss: 0.0286\n",
      "Epoch 45/200, Iteration 250/250, Loss: 0.0123\n",
      "Train Error: \n",
      " Accuracy: 90.55%, Avg loss: 0.007743, MRE: 0.666794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.007696, MRE: 1.076535 \n",
      "\n",
      "Epoch 46/200, Iteration 1/250, Loss: 0.0328\n",
      "Epoch 46/200, Iteration 2/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 3/250, Loss: 0.0150\n",
      "Epoch 46/200, Iteration 4/250, Loss: 0.0137\n",
      "Epoch 46/200, Iteration 5/250, Loss: 0.0093\n",
      "Epoch 46/200, Iteration 6/250, Loss: 0.0078\n",
      "Epoch 46/200, Iteration 7/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 8/250, Loss: 0.0144\n",
      "Epoch 46/200, Iteration 9/250, Loss: 0.0154\n",
      "Epoch 46/200, Iteration 10/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 11/250, Loss: 0.0367\n",
      "Epoch 46/200, Iteration 12/250, Loss: 0.0133\n",
      "Epoch 46/200, Iteration 13/250, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 14/250, Loss: 0.0337\n",
      "Epoch 46/200, Iteration 15/250, Loss: 0.0165\n",
      "Epoch 46/200, Iteration 16/250, Loss: 0.0128\n",
      "Epoch 46/200, Iteration 17/250, Loss: 0.0080\n",
      "Epoch 46/200, Iteration 18/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 19/250, Loss: 0.0109\n",
      "Epoch 46/200, Iteration 20/250, Loss: 0.0088\n",
      "Epoch 46/200, Iteration 21/250, Loss: 0.0142\n",
      "Epoch 46/200, Iteration 22/250, Loss: 0.0270\n",
      "Epoch 46/200, Iteration 23/250, Loss: 0.0111\n",
      "Epoch 46/200, Iteration 24/250, Loss: 0.0075\n",
      "Epoch 46/200, Iteration 25/250, Loss: 0.0080\n",
      "Epoch 46/200, Iteration 26/250, Loss: 0.0109\n",
      "Epoch 46/200, Iteration 27/250, Loss: 0.0088\n",
      "Epoch 46/200, Iteration 28/250, Loss: 0.0081\n",
      "Epoch 46/200, Iteration 29/250, Loss: 0.0097\n",
      "Epoch 46/200, Iteration 30/250, Loss: 0.0095\n",
      "Epoch 46/200, Iteration 31/250, Loss: 0.0195\n",
      "Epoch 46/200, Iteration 32/250, Loss: 0.0146\n",
      "Epoch 46/200, Iteration 33/250, Loss: 0.0272\n",
      "Epoch 46/200, Iteration 34/250, Loss: 0.0108\n",
      "Epoch 46/200, Iteration 35/250, Loss: 0.0092\n",
      "Epoch 46/200, Iteration 36/250, Loss: 0.0134\n",
      "Epoch 46/200, Iteration 37/250, Loss: 0.0200\n",
      "Epoch 46/200, Iteration 38/250, Loss: 0.0228\n",
      "Epoch 46/200, Iteration 39/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 40/250, Loss: 0.0096\n",
      "Epoch 46/200, Iteration 41/250, Loss: 0.0203\n",
      "Epoch 46/200, Iteration 42/250, Loss: 0.0113\n",
      "Epoch 46/200, Iteration 43/250, Loss: 0.0081\n",
      "Epoch 46/200, Iteration 44/250, Loss: 0.0157\n",
      "Epoch 46/200, Iteration 45/250, Loss: 0.0132\n",
      "Epoch 46/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 46/200, Iteration 48/250, Loss: 0.0310\n",
      "Epoch 46/200, Iteration 49/250, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 50/250, Loss: 0.0280\n",
      "Epoch 46/200, Iteration 51/250, Loss: 0.0126\n",
      "Epoch 46/200, Iteration 52/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 53/250, Loss: 0.0333\n",
      "Epoch 46/200, Iteration 54/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 55/250, Loss: 0.0209\n",
      "Epoch 46/200, Iteration 56/250, Loss: 0.0256\n",
      "Epoch 46/200, Iteration 57/250, Loss: 0.0178\n",
      "Epoch 46/200, Iteration 58/250, Loss: 0.0075\n",
      "Epoch 46/200, Iteration 59/250, Loss: 0.0132\n",
      "Epoch 46/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 46/200, Iteration 61/250, Loss: 0.0094\n",
      "Epoch 46/200, Iteration 62/250, Loss: 0.0201\n",
      "Epoch 46/200, Iteration 63/250, Loss: 0.0090\n",
      "Epoch 46/200, Iteration 64/250, Loss: 0.0201\n",
      "Epoch 46/200, Iteration 65/250, Loss: 0.0102\n",
      "Epoch 46/200, Iteration 66/250, Loss: 0.0203\n",
      "Epoch 46/200, Iteration 67/250, Loss: 0.0071\n",
      "Epoch 46/200, Iteration 68/250, Loss: 0.0225\n",
      "Epoch 46/200, Iteration 69/250, Loss: 0.0097\n",
      "Epoch 46/200, Iteration 70/250, Loss: 0.0246\n",
      "Epoch 46/200, Iteration 71/250, Loss: 0.0168\n",
      "Epoch 46/200, Iteration 72/250, Loss: 0.0220\n",
      "Epoch 46/200, Iteration 73/250, Loss: 0.0120\n",
      "Epoch 46/200, Iteration 74/250, Loss: 0.0150\n",
      "Epoch 46/200, Iteration 75/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 76/250, Loss: 0.0118\n",
      "Epoch 46/200, Iteration 77/250, Loss: 0.0203\n",
      "Epoch 46/200, Iteration 78/250, Loss: 0.0087\n",
      "Epoch 46/200, Iteration 79/250, Loss: 0.0101\n",
      "Epoch 46/200, Iteration 80/250, Loss: 0.0064\n",
      "Epoch 46/200, Iteration 81/250, Loss: 0.0229\n",
      "Epoch 46/200, Iteration 82/250, Loss: 0.0249\n",
      "Epoch 46/200, Iteration 83/250, Loss: 0.0132\n",
      "Epoch 46/200, Iteration 84/250, Loss: 0.0298\n",
      "Epoch 46/200, Iteration 85/250, Loss: 0.0162\n",
      "Epoch 46/200, Iteration 86/250, Loss: 0.0158\n",
      "Epoch 46/200, Iteration 87/250, Loss: 0.0208\n",
      "Epoch 46/200, Iteration 88/250, Loss: 0.0241\n",
      "Epoch 46/200, Iteration 89/250, Loss: 0.0106\n",
      "Epoch 46/200, Iteration 90/250, Loss: 0.0072\n",
      "Epoch 46/200, Iteration 91/250, Loss: 0.0157\n",
      "Epoch 46/200, Iteration 92/250, Loss: 0.0285\n",
      "Epoch 46/200, Iteration 93/250, Loss: 0.0090\n",
      "Epoch 46/200, Iteration 94/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 95/250, Loss: 0.0356\n",
      "Epoch 46/200, Iteration 96/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 97/250, Loss: 0.0271\n",
      "Epoch 46/200, Iteration 98/250, Loss: 0.0145\n",
      "Epoch 46/200, Iteration 99/250, Loss: 0.0094\n",
      "Epoch 46/200, Iteration 100/250, Loss: 0.0235\n",
      "Epoch 46/200, Iteration 101/250, Loss: 0.0148\n",
      "Epoch 46/200, Iteration 102/250, Loss: 0.0221\n",
      "Epoch 46/200, Iteration 103/250, Loss: 0.0204\n",
      "Epoch 46/200, Iteration 104/250, Loss: 0.0197\n",
      "Epoch 46/200, Iteration 105/250, Loss: 0.0224\n",
      "Epoch 46/200, Iteration 106/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 107/250, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 108/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 109/250, Loss: 0.0115\n",
      "Epoch 46/200, Iteration 110/250, Loss: 0.0074\n",
      "Epoch 46/200, Iteration 111/250, Loss: 0.0143\n",
      "Epoch 46/200, Iteration 112/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 113/250, Loss: 0.0104\n",
      "Epoch 46/200, Iteration 114/250, Loss: 0.0126\n",
      "Epoch 46/200, Iteration 115/250, Loss: 0.0256\n",
      "Epoch 46/200, Iteration 116/250, Loss: 0.0071\n",
      "Epoch 46/200, Iteration 117/250, Loss: 0.0195\n",
      "Epoch 46/200, Iteration 118/250, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 119/250, Loss: 0.0122\n",
      "Epoch 46/200, Iteration 120/250, Loss: 0.0338\n",
      "Epoch 46/200, Iteration 121/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 122/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 123/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 124/250, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 46/200, Iteration 126/250, Loss: 0.0104\n",
      "Epoch 46/200, Iteration 127/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 128/250, Loss: 0.0094\n",
      "Epoch 46/200, Iteration 129/250, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 130/250, Loss: 0.0271\n",
      "Epoch 46/200, Iteration 131/250, Loss: 0.0220\n",
      "Epoch 46/200, Iteration 132/250, Loss: 0.0100\n",
      "Epoch 46/200, Iteration 133/250, Loss: 0.0081\n",
      "Epoch 46/200, Iteration 134/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 135/250, Loss: 0.0138\n",
      "Epoch 46/200, Iteration 136/250, Loss: 0.0092\n",
      "Epoch 46/200, Iteration 137/250, Loss: 0.0110\n",
      "Epoch 46/200, Iteration 138/250, Loss: 0.0289\n",
      "Epoch 46/200, Iteration 139/250, Loss: 0.0132\n",
      "Epoch 46/200, Iteration 140/250, Loss: 0.0119\n",
      "Epoch 46/200, Iteration 141/250, Loss: 0.0147\n",
      "Epoch 46/200, Iteration 142/250, Loss: 0.0153\n",
      "Epoch 46/200, Iteration 143/250, Loss: 0.0124\n",
      "Epoch 46/200, Iteration 144/250, Loss: 0.0188\n",
      "Epoch 46/200, Iteration 145/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 146/250, Loss: 0.0073\n",
      "Epoch 46/200, Iteration 147/250, Loss: 0.0121\n",
      "Epoch 46/200, Iteration 148/250, Loss: 0.0074\n",
      "Epoch 46/200, Iteration 149/250, Loss: 0.0101\n",
      "Epoch 46/200, Iteration 150/250, Loss: 0.0090\n",
      "Epoch 46/200, Iteration 151/250, Loss: 0.0141\n",
      "Epoch 46/200, Iteration 152/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 153/250, Loss: 0.0106\n",
      "Epoch 46/200, Iteration 154/250, Loss: 0.0122\n",
      "Epoch 46/200, Iteration 155/250, Loss: 0.0110\n",
      "Epoch 46/200, Iteration 156/250, Loss: 0.0145\n",
      "Epoch 46/200, Iteration 157/250, Loss: 0.0107\n",
      "Epoch 46/200, Iteration 158/250, Loss: 0.0174\n",
      "Epoch 46/200, Iteration 159/250, Loss: 0.0244\n",
      "Epoch 46/200, Iteration 160/250, Loss: 0.0187\n",
      "Epoch 46/200, Iteration 161/250, Loss: 0.0106\n",
      "Epoch 46/200, Iteration 162/250, Loss: 0.0285\n",
      "Epoch 46/200, Iteration 163/250, Loss: 0.0260\n",
      "Epoch 46/200, Iteration 164/250, Loss: 0.0117\n",
      "Epoch 46/200, Iteration 165/250, Loss: 0.0115\n",
      "Epoch 46/200, Iteration 166/250, Loss: 0.0148\n",
      "Epoch 46/200, Iteration 167/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 168/250, Loss: 0.0295\n",
      "Epoch 46/200, Iteration 169/250, Loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Iteration 170/250, Loss: 0.0319\n",
      "Epoch 46/200, Iteration 171/250, Loss: 0.0193\n",
      "Epoch 46/200, Iteration 172/250, Loss: 0.0155\n",
      "Epoch 46/200, Iteration 173/250, Loss: 0.0128\n",
      "Epoch 46/200, Iteration 174/250, Loss: 0.0357\n",
      "Epoch 46/200, Iteration 175/250, Loss: 0.0067\n",
      "Epoch 46/200, Iteration 176/250, Loss: 0.0079\n",
      "Epoch 46/200, Iteration 177/250, Loss: 0.0172\n",
      "Epoch 46/200, Iteration 178/250, Loss: 0.0260\n",
      "Epoch 46/200, Iteration 179/250, Loss: 0.0095\n",
      "Epoch 46/200, Iteration 180/250, Loss: 0.0103\n",
      "Epoch 46/200, Iteration 181/250, Loss: 0.0358\n",
      "Epoch 46/200, Iteration 182/250, Loss: 0.0076\n",
      "Epoch 46/200, Iteration 183/250, Loss: 0.0138\n",
      "Epoch 46/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 46/200, Iteration 185/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 186/250, Loss: 0.0177\n",
      "Epoch 46/200, Iteration 187/250, Loss: 0.0185\n",
      "Epoch 46/200, Iteration 188/250, Loss: 0.0200\n",
      "Epoch 46/200, Iteration 189/250, Loss: 0.0174\n",
      "Epoch 46/200, Iteration 190/250, Loss: 0.0087\n",
      "Epoch 46/200, Iteration 191/250, Loss: 0.0172\n",
      "Epoch 46/200, Iteration 192/250, Loss: 0.0177\n",
      "Epoch 46/200, Iteration 193/250, Loss: 0.0140\n",
      "Epoch 46/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 46/200, Iteration 195/250, Loss: 0.0102\n",
      "Epoch 46/200, Iteration 196/250, Loss: 0.0090\n",
      "Epoch 46/200, Iteration 197/250, Loss: 0.0266\n",
      "Epoch 46/200, Iteration 198/250, Loss: 0.0111\n",
      "Epoch 46/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 46/200, Iteration 200/250, Loss: 0.0121\n",
      "Epoch 46/200, Iteration 201/250, Loss: 0.0095\n",
      "Epoch 46/200, Iteration 202/250, Loss: 0.0120\n",
      "Epoch 46/200, Iteration 203/250, Loss: 0.0082\n",
      "Epoch 46/200, Iteration 204/250, Loss: 0.0259\n",
      "Epoch 46/200, Iteration 205/250, Loss: 0.0284\n",
      "Epoch 46/200, Iteration 206/250, Loss: 0.0091\n",
      "Epoch 46/200, Iteration 207/250, Loss: 0.0166\n",
      "Epoch 46/200, Iteration 208/250, Loss: 0.0159\n",
      "Epoch 46/200, Iteration 209/250, Loss: 0.0269\n",
      "Epoch 46/200, Iteration 210/250, Loss: 0.0194\n",
      "Epoch 46/200, Iteration 211/250, Loss: 0.0159\n",
      "Epoch 46/200, Iteration 212/250, Loss: 0.0228\n",
      "Epoch 46/200, Iteration 213/250, Loss: 0.0340\n",
      "Epoch 46/200, Iteration 214/250, Loss: 0.0145\n",
      "Epoch 46/200, Iteration 215/250, Loss: 0.0155\n",
      "Epoch 46/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 46/200, Iteration 217/250, Loss: 0.0078\n",
      "Epoch 46/200, Iteration 218/250, Loss: 0.0093\n",
      "Epoch 46/200, Iteration 219/250, Loss: 0.0143\n",
      "Epoch 46/200, Iteration 220/250, Loss: 0.0236\n",
      "Epoch 46/200, Iteration 221/250, Loss: 0.0232\n",
      "Epoch 46/200, Iteration 222/250, Loss: 0.0323\n",
      "Epoch 46/200, Iteration 223/250, Loss: 0.0120\n",
      "Epoch 46/200, Iteration 224/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 225/250, Loss: 0.0227\n",
      "Epoch 46/200, Iteration 226/250, Loss: 0.0171\n",
      "Epoch 46/200, Iteration 227/250, Loss: 0.0572\n",
      "Epoch 46/200, Iteration 228/250, Loss: 0.0187\n",
      "Epoch 46/200, Iteration 229/250, Loss: 0.0104\n",
      "Epoch 46/200, Iteration 230/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 231/250, Loss: 0.0118\n",
      "Epoch 46/200, Iteration 232/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 233/250, Loss: 0.0582\n",
      "Epoch 46/200, Iteration 234/250, Loss: 0.0100\n",
      "Epoch 46/200, Iteration 235/250, Loss: 0.0200\n",
      "Epoch 46/200, Iteration 236/250, Loss: 0.0175\n",
      "Epoch 46/200, Iteration 237/250, Loss: 0.0414\n",
      "Epoch 46/200, Iteration 238/250, Loss: 0.0266\n",
      "Epoch 46/200, Iteration 239/250, Loss: 0.0134\n",
      "Epoch 46/200, Iteration 240/250, Loss: 0.0102\n",
      "Epoch 46/200, Iteration 241/250, Loss: 0.0190\n",
      "Epoch 46/200, Iteration 242/250, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 243/250, Loss: 0.0129\n",
      "Epoch 46/200, Iteration 244/250, Loss: 0.0198\n",
      "Epoch 46/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 46/200, Iteration 246/250, Loss: 0.0434\n",
      "Epoch 46/200, Iteration 247/250, Loss: 0.0240\n",
      "Epoch 46/200, Iteration 248/250, Loss: 0.0066\n",
      "Epoch 46/200, Iteration 249/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 54.05%, Avg loss: 0.011956, MRE: 0.862130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.45%, Avg loss: 0.011917, MRE: 1.055019 \n",
      "\n",
      "Epoch 47/200, Iteration 1/250, Loss: 0.0158\n",
      "Epoch 47/200, Iteration 2/250, Loss: 0.0203\n",
      "Epoch 47/200, Iteration 3/250, Loss: 0.0215\n",
      "Epoch 47/200, Iteration 4/250, Loss: 0.0304\n",
      "Epoch 47/200, Iteration 5/250, Loss: 0.0133\n",
      "Epoch 47/200, Iteration 6/250, Loss: 0.0482\n",
      "Epoch 47/200, Iteration 7/250, Loss: 0.0094\n",
      "Epoch 47/200, Iteration 8/250, Loss: 0.0089\n",
      "Epoch 47/200, Iteration 9/250, Loss: 0.0081\n",
      "Epoch 47/200, Iteration 10/250, Loss: 0.0117\n",
      "Epoch 47/200, Iteration 11/250, Loss: 0.0176\n",
      "Epoch 47/200, Iteration 12/250, Loss: 0.0125\n",
      "Epoch 47/200, Iteration 13/250, Loss: 0.0179\n",
      "Epoch 47/200, Iteration 14/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 15/250, Loss: 0.0171\n",
      "Epoch 47/200, Iteration 16/250, Loss: 0.0079\n",
      "Epoch 47/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 18/250, Loss: 0.0131\n",
      "Epoch 47/200, Iteration 19/250, Loss: 0.0129\n",
      "Epoch 47/200, Iteration 20/250, Loss: 0.0216\n",
      "Epoch 47/200, Iteration 21/250, Loss: 0.0265\n",
      "Epoch 47/200, Iteration 22/250, Loss: 0.0162\n",
      "Epoch 47/200, Iteration 23/250, Loss: 0.0078\n",
      "Epoch 47/200, Iteration 24/250, Loss: 0.0091\n",
      "Epoch 47/200, Iteration 25/250, Loss: 0.0119\n",
      "Epoch 47/200, Iteration 26/250, Loss: 0.0086\n",
      "Epoch 47/200, Iteration 27/250, Loss: 0.0549\n",
      "Epoch 47/200, Iteration 28/250, Loss: 0.0251\n",
      "Epoch 47/200, Iteration 29/250, Loss: 0.0601\n",
      "Epoch 47/200, Iteration 30/250, Loss: 0.0178\n",
      "Epoch 47/200, Iteration 31/250, Loss: 0.0156\n",
      "Epoch 47/200, Iteration 32/250, Loss: 0.0259\n",
      "Epoch 47/200, Iteration 33/250, Loss: 0.0130\n",
      "Epoch 47/200, Iteration 34/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 35/250, Loss: 0.0312\n",
      "Epoch 47/200, Iteration 36/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 37/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 38/250, Loss: 0.0095\n",
      "Epoch 47/200, Iteration 39/250, Loss: 0.0107\n",
      "Epoch 47/200, Iteration 40/250, Loss: 0.0206\n",
      "Epoch 47/200, Iteration 41/250, Loss: 0.0088\n",
      "Epoch 47/200, Iteration 42/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 43/250, Loss: 0.0152\n",
      "Epoch 47/200, Iteration 44/250, Loss: 0.0204\n",
      "Epoch 47/200, Iteration 45/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 46/250, Loss: 0.0330\n",
      "Epoch 47/200, Iteration 47/250, Loss: 0.0117\n",
      "Epoch 47/200, Iteration 48/250, Loss: 0.0234\n",
      "Epoch 47/200, Iteration 49/250, Loss: 0.0120\n",
      "Epoch 47/200, Iteration 50/250, Loss: 0.0104\n",
      "Epoch 47/200, Iteration 51/250, Loss: 0.0216\n",
      "Epoch 47/200, Iteration 52/250, Loss: 0.0109\n",
      "Epoch 47/200, Iteration 53/250, Loss: 0.0305\n",
      "Epoch 47/200, Iteration 54/250, Loss: 0.0169\n",
      "Epoch 47/200, Iteration 55/250, Loss: 0.0086\n",
      "Epoch 47/200, Iteration 56/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 57/250, Loss: 0.0213\n",
      "Epoch 47/200, Iteration 58/250, Loss: 0.0091\n",
      "Epoch 47/200, Iteration 59/250, Loss: 0.0163\n",
      "Epoch 47/200, Iteration 60/250, Loss: 0.0251\n",
      "Epoch 47/200, Iteration 61/250, Loss: 0.0238\n",
      "Epoch 47/200, Iteration 62/250, Loss: 0.0094\n",
      "Epoch 47/200, Iteration 63/250, Loss: 0.0246\n",
      "Epoch 47/200, Iteration 64/250, Loss: 0.0416\n",
      "Epoch 47/200, Iteration 65/250, Loss: 0.0097\n",
      "Epoch 47/200, Iteration 66/250, Loss: 0.0123\n",
      "Epoch 47/200, Iteration 67/250, Loss: 0.0150\n",
      "Epoch 47/200, Iteration 68/250, Loss: 0.0109\n",
      "Epoch 47/200, Iteration 69/250, Loss: 0.0108\n",
      "Epoch 47/200, Iteration 70/250, Loss: 0.0152\n",
      "Epoch 47/200, Iteration 71/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 72/250, Loss: 0.0116\n",
      "Epoch 47/200, Iteration 73/250, Loss: 0.0066\n",
      "Epoch 47/200, Iteration 74/250, Loss: 0.0108\n",
      "Epoch 47/200, Iteration 75/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 76/250, Loss: 0.0175\n",
      "Epoch 47/200, Iteration 77/250, Loss: 0.0214\n",
      "Epoch 47/200, Iteration 78/250, Loss: 0.0136\n",
      "Epoch 47/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 47/200, Iteration 80/250, Loss: 0.0322\n",
      "Epoch 47/200, Iteration 81/250, Loss: 0.0113\n",
      "Epoch 47/200, Iteration 82/250, Loss: 0.0129\n",
      "Epoch 47/200, Iteration 83/250, Loss: 0.0306\n",
      "Epoch 47/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 47/200, Iteration 85/250, Loss: 0.0094\n",
      "Epoch 47/200, Iteration 86/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 87/250, Loss: 0.0128\n",
      "Epoch 47/200, Iteration 88/250, Loss: 0.0125\n",
      "Epoch 47/200, Iteration 89/250, Loss: 0.0090\n",
      "Epoch 47/200, Iteration 90/250, Loss: 0.0492\n",
      "Epoch 47/200, Iteration 91/250, Loss: 0.0127\n",
      "Epoch 47/200, Iteration 92/250, Loss: 0.0122\n",
      "Epoch 47/200, Iteration 93/250, Loss: 0.0279\n",
      "Epoch 47/200, Iteration 94/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 95/250, Loss: 0.0200\n",
      "Epoch 47/200, Iteration 96/250, Loss: 0.0127\n",
      "Epoch 47/200, Iteration 97/250, Loss: 0.0131\n",
      "Epoch 47/200, Iteration 98/250, Loss: 0.0185\n",
      "Epoch 47/200, Iteration 99/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 100/250, Loss: 0.0154\n",
      "Epoch 47/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 47/200, Iteration 102/250, Loss: 0.0225\n",
      "Epoch 47/200, Iteration 103/250, Loss: 0.0245\n",
      "Epoch 47/200, Iteration 104/250, Loss: 0.0091\n",
      "Epoch 47/200, Iteration 105/250, Loss: 0.0069\n",
      "Epoch 47/200, Iteration 106/250, Loss: 0.0092\n",
      "Epoch 47/200, Iteration 107/250, Loss: 0.0182\n",
      "Epoch 47/200, Iteration 108/250, Loss: 0.0141\n",
      "Epoch 47/200, Iteration 109/250, Loss: 0.0160\n",
      "Epoch 47/200, Iteration 110/250, Loss: 0.0123\n",
      "Epoch 47/200, Iteration 111/250, Loss: 0.0098\n",
      "Epoch 47/200, Iteration 112/250, Loss: 0.0091\n",
      "Epoch 47/200, Iteration 113/250, Loss: 0.0202\n",
      "Epoch 47/200, Iteration 114/250, Loss: 0.0076\n",
      "Epoch 47/200, Iteration 115/250, Loss: 0.0125\n",
      "Epoch 47/200, Iteration 116/250, Loss: 0.0301\n",
      "Epoch 47/200, Iteration 117/250, Loss: 0.0171\n",
      "Epoch 47/200, Iteration 118/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 119/250, Loss: 0.0093\n",
      "Epoch 47/200, Iteration 120/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 121/250, Loss: 0.0152\n",
      "Epoch 47/200, Iteration 122/250, Loss: 0.0128\n",
      "Epoch 47/200, Iteration 123/250, Loss: 0.0102\n",
      "Epoch 47/200, Iteration 124/250, Loss: 0.0133\n",
      "Epoch 47/200, Iteration 125/250, Loss: 0.0346\n",
      "Epoch 47/200, Iteration 126/250, Loss: 0.0305\n",
      "Epoch 47/200, Iteration 127/250, Loss: 0.0152\n",
      "Epoch 47/200, Iteration 128/250, Loss: 0.0284\n",
      "Epoch 47/200, Iteration 129/250, Loss: 0.0159\n",
      "Epoch 47/200, Iteration 130/250, Loss: 0.0134\n",
      "Epoch 47/200, Iteration 131/250, Loss: 0.0140\n",
      "Epoch 47/200, Iteration 132/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 133/250, Loss: 0.0104\n",
      "Epoch 47/200, Iteration 134/250, Loss: 0.0263\n",
      "Epoch 47/200, Iteration 135/250, Loss: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Iteration 136/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 137/250, Loss: 0.0283\n",
      "Epoch 47/200, Iteration 138/250, Loss: 0.0267\n",
      "Epoch 47/200, Iteration 139/250, Loss: 0.0209\n",
      "Epoch 47/200, Iteration 140/250, Loss: 0.0170\n",
      "Epoch 47/200, Iteration 141/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 142/250, Loss: 0.0316\n",
      "Epoch 47/200, Iteration 143/250, Loss: 0.0233\n",
      "Epoch 47/200, Iteration 144/250, Loss: 0.0074\n",
      "Epoch 47/200, Iteration 145/250, Loss: 0.0219\n",
      "Epoch 47/200, Iteration 146/250, Loss: 0.0190\n",
      "Epoch 47/200, Iteration 147/250, Loss: 0.0124\n",
      "Epoch 47/200, Iteration 148/250, Loss: 0.0187\n",
      "Epoch 47/200, Iteration 149/250, Loss: 0.0220\n",
      "Epoch 47/200, Iteration 150/250, Loss: 0.0221\n",
      "Epoch 47/200, Iteration 151/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 152/250, Loss: 0.0110\n",
      "Epoch 47/200, Iteration 153/250, Loss: 0.0125\n",
      "Epoch 47/200, Iteration 154/250, Loss: 0.0219\n",
      "Epoch 47/200, Iteration 155/250, Loss: 0.0134\n",
      "Epoch 47/200, Iteration 156/250, Loss: 0.0144\n",
      "Epoch 47/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 47/200, Iteration 158/250, Loss: 0.0247\n",
      "Epoch 47/200, Iteration 159/250, Loss: 0.0140\n",
      "Epoch 47/200, Iteration 160/250, Loss: 0.0075\n",
      "Epoch 47/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 47/200, Iteration 162/250, Loss: 0.0266\n",
      "Epoch 47/200, Iteration 163/250, Loss: 0.0110\n",
      "Epoch 47/200, Iteration 164/250, Loss: 0.0146\n",
      "Epoch 47/200, Iteration 165/250, Loss: 0.0198\n",
      "Epoch 47/200, Iteration 166/250, Loss: 0.0216\n",
      "Epoch 47/200, Iteration 167/250, Loss: 0.0067\n",
      "Epoch 47/200, Iteration 168/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 169/250, Loss: 0.0110\n",
      "Epoch 47/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 47/200, Iteration 171/250, Loss: 0.0098\n",
      "Epoch 47/200, Iteration 172/250, Loss: 0.0152\n",
      "Epoch 47/200, Iteration 173/250, Loss: 0.0303\n",
      "Epoch 47/200, Iteration 174/250, Loss: 0.0093\n",
      "Epoch 47/200, Iteration 175/250, Loss: 0.0226\n",
      "Epoch 47/200, Iteration 176/250, Loss: 0.0070\n",
      "Epoch 47/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 47/200, Iteration 178/250, Loss: 0.0164\n",
      "Epoch 47/200, Iteration 179/250, Loss: 0.0181\n",
      "Epoch 47/200, Iteration 180/250, Loss: 0.0130\n",
      "Epoch 47/200, Iteration 181/250, Loss: 0.0178\n",
      "Epoch 47/200, Iteration 182/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 183/250, Loss: 0.0109\n",
      "Epoch 47/200, Iteration 184/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 186/250, Loss: 0.0087\n",
      "Epoch 47/200, Iteration 187/250, Loss: 0.0222\n",
      "Epoch 47/200, Iteration 188/250, Loss: 0.0397\n",
      "Epoch 47/200, Iteration 189/250, Loss: 0.0315\n",
      "Epoch 47/200, Iteration 190/250, Loss: 0.0079\n",
      "Epoch 47/200, Iteration 191/250, Loss: 0.0162\n",
      "Epoch 47/200, Iteration 192/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 193/250, Loss: 0.0138\n",
      "Epoch 47/200, Iteration 194/250, Loss: 0.0100\n",
      "Epoch 47/200, Iteration 195/250, Loss: 0.0217\n",
      "Epoch 47/200, Iteration 196/250, Loss: 0.0189\n",
      "Epoch 47/200, Iteration 197/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 198/250, Loss: 0.0154\n",
      "Epoch 47/200, Iteration 199/250, Loss: 0.0093\n",
      "Epoch 47/200, Iteration 200/250, Loss: 0.0216\n",
      "Epoch 47/200, Iteration 201/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 202/250, Loss: 0.0092\n",
      "Epoch 47/200, Iteration 203/250, Loss: 0.0116\n",
      "Epoch 47/200, Iteration 204/250, Loss: 0.0165\n",
      "Epoch 47/200, Iteration 205/250, Loss: 0.0100\n",
      "Epoch 47/200, Iteration 206/250, Loss: 0.0139\n",
      "Epoch 47/200, Iteration 207/250, Loss: 0.0161\n",
      "Epoch 47/200, Iteration 208/250, Loss: 0.0148\n",
      "Epoch 47/200, Iteration 209/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 210/250, Loss: 0.0092\n",
      "Epoch 47/200, Iteration 211/250, Loss: 0.0197\n",
      "Epoch 47/200, Iteration 212/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 214/250, Loss: 0.0235\n",
      "Epoch 47/200, Iteration 215/250, Loss: 0.0130\n",
      "Epoch 47/200, Iteration 216/250, Loss: 0.0287\n",
      "Epoch 47/200, Iteration 217/250, Loss: 0.0180\n",
      "Epoch 47/200, Iteration 218/250, Loss: 0.0067\n",
      "Epoch 47/200, Iteration 219/250, Loss: 0.0240\n",
      "Epoch 47/200, Iteration 220/250, Loss: 0.0208\n",
      "Epoch 47/200, Iteration 221/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 222/250, Loss: 0.0099\n",
      "Epoch 47/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 47/200, Iteration 224/250, Loss: 0.0187\n",
      "Epoch 47/200, Iteration 225/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 226/250, Loss: 0.0299\n",
      "Epoch 47/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 228/250, Loss: 0.0203\n",
      "Epoch 47/200, Iteration 229/250, Loss: 0.0149\n",
      "Epoch 47/200, Iteration 230/250, Loss: 0.0082\n",
      "Epoch 47/200, Iteration 231/250, Loss: 0.0087\n",
      "Epoch 47/200, Iteration 232/250, Loss: 0.0187\n",
      "Epoch 47/200, Iteration 233/250, Loss: 0.0319\n",
      "Epoch 47/200, Iteration 234/250, Loss: 0.0108\n",
      "Epoch 47/200, Iteration 235/250, Loss: 0.0307\n",
      "Epoch 47/200, Iteration 236/250, Loss: 0.0204\n",
      "Epoch 47/200, Iteration 237/250, Loss: 0.0394\n",
      "Epoch 47/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 47/200, Iteration 239/250, Loss: 0.0139\n",
      "Epoch 47/200, Iteration 240/250, Loss: 0.0254\n",
      "Epoch 47/200, Iteration 241/250, Loss: 0.0404\n",
      "Epoch 47/200, Iteration 242/250, Loss: 0.0079\n",
      "Epoch 47/200, Iteration 243/250, Loss: 0.0076\n",
      "Epoch 47/200, Iteration 244/250, Loss: 0.0088\n",
      "Epoch 47/200, Iteration 245/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 246/250, Loss: 0.0428\n",
      "Epoch 47/200, Iteration 247/250, Loss: 0.0068\n",
      "Epoch 47/200, Iteration 248/250, Loss: 0.0124\n",
      "Epoch 47/200, Iteration 249/250, Loss: 0.0483\n",
      "Epoch 47/200, Iteration 250/250, Loss: 0.0171\n",
      "Train Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.010754, MRE: 0.576238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.55%, Avg loss: 0.010956, MRE: 1.032542 \n",
      "\n",
      "Epoch 48/200, Iteration 1/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 2/250, Loss: 0.0132\n",
      "Epoch 48/200, Iteration 3/250, Loss: 0.0154\n",
      "Epoch 48/200, Iteration 4/250, Loss: 0.0261\n",
      "Epoch 48/200, Iteration 5/250, Loss: 0.0094\n",
      "Epoch 48/200, Iteration 6/250, Loss: 0.0155\n",
      "Epoch 48/200, Iteration 7/250, Loss: 0.0120\n",
      "Epoch 48/200, Iteration 8/250, Loss: 0.0361\n",
      "Epoch 48/200, Iteration 9/250, Loss: 0.0251\n",
      "Epoch 48/200, Iteration 10/250, Loss: 0.0138\n",
      "Epoch 48/200, Iteration 11/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 48/200, Iteration 13/250, Loss: 0.0163\n",
      "Epoch 48/200, Iteration 14/250, Loss: 0.0221\n",
      "Epoch 48/200, Iteration 15/250, Loss: 0.0185\n",
      "Epoch 48/200, Iteration 16/250, Loss: 0.0201\n",
      "Epoch 48/200, Iteration 17/250, Loss: 0.0076\n",
      "Epoch 48/200, Iteration 18/250, Loss: 0.0169\n",
      "Epoch 48/200, Iteration 19/250, Loss: 0.0147\n",
      "Epoch 48/200, Iteration 20/250, Loss: 0.0306\n",
      "Epoch 48/200, Iteration 21/250, Loss: 0.0122\n",
      "Epoch 48/200, Iteration 22/250, Loss: 0.0113\n",
      "Epoch 48/200, Iteration 23/250, Loss: 0.0141\n",
      "Epoch 48/200, Iteration 24/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 48/200, Iteration 26/250, Loss: 0.0156\n",
      "Epoch 48/200, Iteration 27/250, Loss: 0.0217\n",
      "Epoch 48/200, Iteration 28/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 29/250, Loss: 0.0077\n",
      "Epoch 48/200, Iteration 30/250, Loss: 0.0169\n",
      "Epoch 48/200, Iteration 31/250, Loss: 0.0078\n",
      "Epoch 48/200, Iteration 32/250, Loss: 0.0194\n",
      "Epoch 48/200, Iteration 33/250, Loss: 0.0212\n",
      "Epoch 48/200, Iteration 34/250, Loss: 0.0190\n",
      "Epoch 48/200, Iteration 35/250, Loss: 0.0073\n",
      "Epoch 48/200, Iteration 36/250, Loss: 0.0091\n",
      "Epoch 48/200, Iteration 37/250, Loss: 0.0109\n",
      "Epoch 48/200, Iteration 38/250, Loss: 0.0458\n",
      "Epoch 48/200, Iteration 39/250, Loss: 0.0161\n",
      "Epoch 48/200, Iteration 40/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 41/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 42/250, Loss: 0.0183\n",
      "Epoch 48/200, Iteration 43/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 44/250, Loss: 0.0077\n",
      "Epoch 48/200, Iteration 45/250, Loss: 0.0102\n",
      "Epoch 48/200, Iteration 46/250, Loss: 0.0206\n",
      "Epoch 48/200, Iteration 47/250, Loss: 0.0344\n",
      "Epoch 48/200, Iteration 48/250, Loss: 0.0130\n",
      "Epoch 48/200, Iteration 49/250, Loss: 0.0274\n",
      "Epoch 48/200, Iteration 50/250, Loss: 0.0387\n",
      "Epoch 48/200, Iteration 51/250, Loss: 0.0088\n",
      "Epoch 48/200, Iteration 52/250, Loss: 0.0567\n",
      "Epoch 48/200, Iteration 53/250, Loss: 0.0260\n",
      "Epoch 48/200, Iteration 54/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 55/250, Loss: 0.0192\n",
      "Epoch 48/200, Iteration 56/250, Loss: 0.0355\n",
      "Epoch 48/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 58/250, Loss: 0.0152\n",
      "Epoch 48/200, Iteration 59/250, Loss: 0.0350\n",
      "Epoch 48/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 48/200, Iteration 62/250, Loss: 0.0157\n",
      "Epoch 48/200, Iteration 63/250, Loss: 0.0155\n",
      "Epoch 48/200, Iteration 64/250, Loss: 0.0140\n",
      "Epoch 48/200, Iteration 65/250, Loss: 0.0106\n",
      "Epoch 48/200, Iteration 66/250, Loss: 0.0337\n",
      "Epoch 48/200, Iteration 67/250, Loss: 0.0333\n",
      "Epoch 48/200, Iteration 68/250, Loss: 0.0080\n",
      "Epoch 48/200, Iteration 69/250, Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Iteration 70/250, Loss: 0.0211\n",
      "Epoch 48/200, Iteration 71/250, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 72/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 73/250, Loss: 0.0236\n",
      "Epoch 48/200, Iteration 74/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 75/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 76/250, Loss: 0.0099\n",
      "Epoch 48/200, Iteration 77/250, Loss: 0.0260\n",
      "Epoch 48/200, Iteration 78/250, Loss: 0.0203\n",
      "Epoch 48/200, Iteration 79/250, Loss: 0.0162\n",
      "Epoch 48/200, Iteration 80/250, Loss: 0.0178\n",
      "Epoch 48/200, Iteration 81/250, Loss: 0.0144\n",
      "Epoch 48/200, Iteration 82/250, Loss: 0.0082\n",
      "Epoch 48/200, Iteration 83/250, Loss: 0.0112\n",
      "Epoch 48/200, Iteration 84/250, Loss: 0.0121\n",
      "Epoch 48/200, Iteration 85/250, Loss: 0.0306\n",
      "Epoch 48/200, Iteration 86/250, Loss: 0.0120\n",
      "Epoch 48/200, Iteration 87/250, Loss: 0.0236\n",
      "Epoch 48/200, Iteration 88/250, Loss: 0.0292\n",
      "Epoch 48/200, Iteration 89/250, Loss: 0.0135\n",
      "Epoch 48/200, Iteration 90/250, Loss: 0.0131\n",
      "Epoch 48/200, Iteration 91/250, Loss: 0.0339\n",
      "Epoch 48/200, Iteration 92/250, Loss: 0.0439\n",
      "Epoch 48/200, Iteration 93/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 94/250, Loss: 0.0116\n",
      "Epoch 48/200, Iteration 95/250, Loss: 0.0284\n",
      "Epoch 48/200, Iteration 96/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 97/250, Loss: 0.0094\n",
      "Epoch 48/200, Iteration 98/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 99/250, Loss: 0.0087\n",
      "Epoch 48/200, Iteration 100/250, Loss: 0.0179\n",
      "Epoch 48/200, Iteration 101/250, Loss: 0.0251\n",
      "Epoch 48/200, Iteration 102/250, Loss: 0.0118\n",
      "Epoch 48/200, Iteration 103/250, Loss: 0.0077\n",
      "Epoch 48/200, Iteration 104/250, Loss: 0.0081\n",
      "Epoch 48/200, Iteration 105/250, Loss: 0.0080\n",
      "Epoch 48/200, Iteration 106/250, Loss: 0.0133\n",
      "Epoch 48/200, Iteration 107/250, Loss: 0.0087\n",
      "Epoch 48/200, Iteration 108/250, Loss: 0.0228\n",
      "Epoch 48/200, Iteration 109/250, Loss: 0.0240\n",
      "Epoch 48/200, Iteration 110/250, Loss: 0.0227\n",
      "Epoch 48/200, Iteration 111/250, Loss: 0.0085\n",
      "Epoch 48/200, Iteration 112/250, Loss: 0.0182\n",
      "Epoch 48/200, Iteration 113/250, Loss: 0.0344\n",
      "Epoch 48/200, Iteration 114/250, Loss: 0.0223\n",
      "Epoch 48/200, Iteration 115/250, Loss: 0.0222\n",
      "Epoch 48/200, Iteration 116/250, Loss: 0.0109\n",
      "Epoch 48/200, Iteration 117/250, Loss: 0.0081\n",
      "Epoch 48/200, Iteration 118/250, Loss: 0.0251\n",
      "Epoch 48/200, Iteration 119/250, Loss: 0.0132\n",
      "Epoch 48/200, Iteration 120/250, Loss: 0.0357\n",
      "Epoch 48/200, Iteration 121/250, Loss: 0.0136\n",
      "Epoch 48/200, Iteration 122/250, Loss: 0.0156\n",
      "Epoch 48/200, Iteration 123/250, Loss: 0.0168\n",
      "Epoch 48/200, Iteration 124/250, Loss: 0.0178\n",
      "Epoch 48/200, Iteration 125/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 48/200, Iteration 127/250, Loss: 0.0240\n",
      "Epoch 48/200, Iteration 128/250, Loss: 0.0340\n",
      "Epoch 48/200, Iteration 129/250, Loss: 0.0327\n",
      "Epoch 48/200, Iteration 130/250, Loss: 0.0162\n",
      "Epoch 48/200, Iteration 131/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 132/250, Loss: 0.0170\n",
      "Epoch 48/200, Iteration 133/250, Loss: 0.0214\n",
      "Epoch 48/200, Iteration 134/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 135/250, Loss: 0.0288\n",
      "Epoch 48/200, Iteration 136/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 137/250, Loss: 0.0212\n",
      "Epoch 48/200, Iteration 138/250, Loss: 0.0081\n",
      "Epoch 48/200, Iteration 139/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 140/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 141/250, Loss: 0.0142\n",
      "Epoch 48/200, Iteration 142/250, Loss: 0.0289\n",
      "Epoch 48/200, Iteration 143/250, Loss: 0.0228\n",
      "Epoch 48/200, Iteration 144/250, Loss: 0.0197\n",
      "Epoch 48/200, Iteration 145/250, Loss: 0.0115\n",
      "Epoch 48/200, Iteration 146/250, Loss: 0.0217\n",
      "Epoch 48/200, Iteration 147/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 148/250, Loss: 0.0163\n",
      "Epoch 48/200, Iteration 149/250, Loss: 0.0092\n",
      "Epoch 48/200, Iteration 150/250, Loss: 0.0132\n",
      "Epoch 48/200, Iteration 151/250, Loss: 0.0104\n",
      "Epoch 48/200, Iteration 152/250, Loss: 0.0172\n",
      "Epoch 48/200, Iteration 153/250, Loss: 0.0092\n",
      "Epoch 48/200, Iteration 154/250, Loss: 0.0097\n",
      "Epoch 48/200, Iteration 155/250, Loss: 0.0238\n",
      "Epoch 48/200, Iteration 156/250, Loss: 0.0176\n",
      "Epoch 48/200, Iteration 157/250, Loss: 0.0367\n",
      "Epoch 48/200, Iteration 158/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 159/250, Loss: 0.0182\n",
      "Epoch 48/200, Iteration 160/250, Loss: 0.0104\n",
      "Epoch 48/200, Iteration 161/250, Loss: 0.0216\n",
      "Epoch 48/200, Iteration 162/250, Loss: 0.0086\n",
      "Epoch 48/200, Iteration 163/250, Loss: 0.0172\n",
      "Epoch 48/200, Iteration 164/250, Loss: 0.0151\n",
      "Epoch 48/200, Iteration 165/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 166/250, Loss: 0.0174\n",
      "Epoch 48/200, Iteration 167/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 168/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 169/250, Loss: 0.0122\n",
      "Epoch 48/200, Iteration 170/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 171/250, Loss: 0.0182\n",
      "Epoch 48/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 173/250, Loss: 0.0167\n",
      "Epoch 48/200, Iteration 174/250, Loss: 0.0158\n",
      "Epoch 48/200, Iteration 175/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 176/250, Loss: 0.0203\n",
      "Epoch 48/200, Iteration 177/250, Loss: 0.0195\n",
      "Epoch 48/200, Iteration 178/250, Loss: 0.0276\n",
      "Epoch 48/200, Iteration 179/250, Loss: 0.0167\n",
      "Epoch 48/200, Iteration 180/250, Loss: 0.0119\n",
      "Epoch 48/200, Iteration 181/250, Loss: 0.0071\n",
      "Epoch 48/200, Iteration 182/250, Loss: 0.0216\n",
      "Epoch 48/200, Iteration 183/250, Loss: 0.0094\n",
      "Epoch 48/200, Iteration 184/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 185/250, Loss: 0.0227\n",
      "Epoch 48/200, Iteration 186/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 187/250, Loss: 0.0140\n",
      "Epoch 48/200, Iteration 188/250, Loss: 0.0072\n",
      "Epoch 48/200, Iteration 189/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 190/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 191/250, Loss: 0.0103\n",
      "Epoch 48/200, Iteration 192/250, Loss: 0.0212\n",
      "Epoch 48/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 48/200, Iteration 194/250, Loss: 0.0140\n",
      "Epoch 48/200, Iteration 195/250, Loss: 0.0187\n",
      "Epoch 48/200, Iteration 196/250, Loss: 0.0178\n",
      "Epoch 48/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 48/200, Iteration 198/250, Loss: 0.0285\n",
      "Epoch 48/200, Iteration 199/250, Loss: 0.0093\n",
      "Epoch 48/200, Iteration 200/250, Loss: 0.0139\n",
      "Epoch 48/200, Iteration 201/250, Loss: 0.0102\n",
      "Epoch 48/200, Iteration 202/250, Loss: 0.0095\n",
      "Epoch 48/200, Iteration 203/250, Loss: 0.0130\n",
      "Epoch 48/200, Iteration 204/250, Loss: 0.0209\n",
      "Epoch 48/200, Iteration 205/250, Loss: 0.0191\n",
      "Epoch 48/200, Iteration 206/250, Loss: 0.0310\n",
      "Epoch 48/200, Iteration 207/250, Loss: 0.0224\n",
      "Epoch 48/200, Iteration 208/250, Loss: 0.0200\n",
      "Epoch 48/200, Iteration 209/250, Loss: 0.0309\n",
      "Epoch 48/200, Iteration 210/250, Loss: 0.0484\n",
      "Epoch 48/200, Iteration 211/250, Loss: 0.0225\n",
      "Epoch 48/200, Iteration 212/250, Loss: 0.0229\n",
      "Epoch 48/200, Iteration 213/250, Loss: 0.0122\n",
      "Epoch 48/200, Iteration 214/250, Loss: 0.0215\n",
      "Epoch 48/200, Iteration 215/250, Loss: 0.0104\n",
      "Epoch 48/200, Iteration 216/250, Loss: 0.0113\n",
      "Epoch 48/200, Iteration 217/250, Loss: 0.0129\n",
      "Epoch 48/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 48/200, Iteration 219/250, Loss: 0.0172\n",
      "Epoch 48/200, Iteration 220/250, Loss: 0.0156\n",
      "Epoch 48/200, Iteration 221/250, Loss: 0.0204\n",
      "Epoch 48/200, Iteration 222/250, Loss: 0.0115\n",
      "Epoch 48/200, Iteration 223/250, Loss: 0.0085\n",
      "Epoch 48/200, Iteration 224/250, Loss: 0.0131\n",
      "Epoch 48/200, Iteration 225/250, Loss: 0.0139\n",
      "Epoch 48/200, Iteration 226/250, Loss: 0.0228\n",
      "Epoch 48/200, Iteration 227/250, Loss: 0.0157\n",
      "Epoch 48/200, Iteration 228/250, Loss: 0.0058\n",
      "Epoch 48/200, Iteration 229/250, Loss: 0.0204\n",
      "Epoch 48/200, Iteration 230/250, Loss: 0.0086\n",
      "Epoch 48/200, Iteration 231/250, Loss: 0.0101\n",
      "Epoch 48/200, Iteration 232/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 233/250, Loss: 0.0105\n",
      "Epoch 48/200, Iteration 234/250, Loss: 0.0225\n",
      "Epoch 48/200, Iteration 235/250, Loss: 0.0078\n",
      "Epoch 48/200, Iteration 236/250, Loss: 0.0474\n",
      "Epoch 48/200, Iteration 237/250, Loss: 0.0110\n",
      "Epoch 48/200, Iteration 238/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 239/250, Loss: 0.0067\n",
      "Epoch 48/200, Iteration 240/250, Loss: 0.0160\n",
      "Epoch 48/200, Iteration 241/250, Loss: 0.0075\n",
      "Epoch 48/200, Iteration 242/250, Loss: 0.0172\n",
      "Epoch 48/200, Iteration 243/250, Loss: 0.0233\n",
      "Epoch 48/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 48/200, Iteration 245/250, Loss: 0.0071\n",
      "Epoch 48/200, Iteration 246/250, Loss: 0.0200\n",
      "Epoch 48/200, Iteration 247/250, Loss: 0.0209\n",
      "Epoch 48/200, Iteration 248/250, Loss: 0.0245\n",
      "Epoch 48/200, Iteration 249/250, Loss: 0.0141\n",
      "Epoch 48/200, Iteration 250/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.47%, Avg loss: 0.009062, MRE: 0.837434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.009006, MRE: 1.303475 \n",
      "\n",
      "Epoch 49/200, Iteration 1/250, Loss: 0.0163\n",
      "Epoch 49/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 3/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 49/200, Iteration 5/250, Loss: 0.0113\n",
      "Epoch 49/200, Iteration 6/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 7/250, Loss: 0.0091\n",
      "Epoch 49/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 49/200, Iteration 9/250, Loss: 0.0144\n",
      "Epoch 49/200, Iteration 10/250, Loss: 0.0120\n",
      "Epoch 49/200, Iteration 11/250, Loss: 0.0361\n",
      "Epoch 49/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 13/250, Loss: 0.0135\n",
      "Epoch 49/200, Iteration 14/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 15/250, Loss: 0.0326\n",
      "Epoch 49/200, Iteration 16/250, Loss: 0.0293\n",
      "Epoch 49/200, Iteration 17/250, Loss: 0.0152\n",
      "Epoch 49/200, Iteration 18/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 19/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 20/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 21/250, Loss: 0.0139\n",
      "Epoch 49/200, Iteration 22/250, Loss: 0.0193\n",
      "Epoch 49/200, Iteration 23/250, Loss: 0.0357\n",
      "Epoch 49/200, Iteration 24/250, Loss: 0.0135\n",
      "Epoch 49/200, Iteration 25/250, Loss: 0.0248\n",
      "Epoch 49/200, Iteration 26/250, Loss: 0.0147\n",
      "Epoch 49/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 49/200, Iteration 28/250, Loss: 0.0154\n",
      "Epoch 49/200, Iteration 29/250, Loss: 0.0089\n",
      "Epoch 49/200, Iteration 30/250, Loss: 0.0113\n",
      "Epoch 49/200, Iteration 31/250, Loss: 0.0082\n",
      "Epoch 49/200, Iteration 32/250, Loss: 0.0166\n",
      "Epoch 49/200, Iteration 33/250, Loss: 0.0287\n",
      "Epoch 49/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 49/200, Iteration 35/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 36/250, Loss: 0.0265\n",
      "Epoch 49/200, Iteration 37/250, Loss: 0.0182\n",
      "Epoch 49/200, Iteration 38/250, Loss: 0.0142\n",
      "Epoch 49/200, Iteration 39/250, Loss: 0.0132\n",
      "Epoch 49/200, Iteration 40/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 41/250, Loss: 0.0304\n",
      "Epoch 49/200, Iteration 42/250, Loss: 0.0298\n",
      "Epoch 49/200, Iteration 43/250, Loss: 0.0205\n",
      "Epoch 49/200, Iteration 44/250, Loss: 0.0216\n",
      "Epoch 49/200, Iteration 45/250, Loss: 0.0149\n",
      "Epoch 49/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 47/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 48/250, Loss: 0.0116\n",
      "Epoch 49/200, Iteration 49/250, Loss: 0.0210\n",
      "Epoch 49/200, Iteration 50/250, Loss: 0.0076\n",
      "Epoch 49/200, Iteration 51/250, Loss: 0.0081\n",
      "Epoch 49/200, Iteration 52/250, Loss: 0.0150\n",
      "Epoch 49/200, Iteration 53/250, Loss: 0.0237\n",
      "Epoch 49/200, Iteration 54/250, Loss: 0.0147\n",
      "Epoch 49/200, Iteration 55/250, Loss: 0.0066\n",
      "Epoch 49/200, Iteration 56/250, Loss: 0.0152\n",
      "Epoch 49/200, Iteration 57/250, Loss: 0.0204\n",
      "Epoch 49/200, Iteration 58/250, Loss: 0.0075\n",
      "Epoch 49/200, Iteration 59/250, Loss: 0.0327\n",
      "Epoch 49/200, Iteration 60/250, Loss: 0.0111\n",
      "Epoch 49/200, Iteration 61/250, Loss: 0.0230\n",
      "Epoch 49/200, Iteration 62/250, Loss: 0.0213\n",
      "Epoch 49/200, Iteration 63/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 64/250, Loss: 0.0141\n",
      "Epoch 49/200, Iteration 65/250, Loss: 0.0206\n",
      "Epoch 49/200, Iteration 66/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 67/250, Loss: 0.0198\n",
      "Epoch 49/200, Iteration 68/250, Loss: 0.0199\n",
      "Epoch 49/200, Iteration 69/250, Loss: 0.0169\n",
      "Epoch 49/200, Iteration 70/250, Loss: 0.0140\n",
      "Epoch 49/200, Iteration 71/250, Loss: 0.0288\n",
      "Epoch 49/200, Iteration 72/250, Loss: 0.0145\n",
      "Epoch 49/200, Iteration 73/250, Loss: 0.0151\n",
      "Epoch 49/200, Iteration 74/250, Loss: 0.0168\n",
      "Epoch 49/200, Iteration 75/250, Loss: 0.0142\n",
      "Epoch 49/200, Iteration 76/250, Loss: 0.0176\n",
      "Epoch 49/200, Iteration 77/250, Loss: 0.0180\n",
      "Epoch 49/200, Iteration 78/250, Loss: 0.0194\n",
      "Epoch 49/200, Iteration 79/250, Loss: 0.0082\n",
      "Epoch 49/200, Iteration 80/250, Loss: 0.0105\n",
      "Epoch 49/200, Iteration 81/250, Loss: 0.0169\n",
      "Epoch 49/200, Iteration 82/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 83/250, Loss: 0.0157\n",
      "Epoch 49/200, Iteration 84/250, Loss: 0.0118\n",
      "Epoch 49/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 49/200, Iteration 86/250, Loss: 0.0145\n",
      "Epoch 49/200, Iteration 87/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 88/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 89/250, Loss: 0.0155\n",
      "Epoch 49/200, Iteration 90/250, Loss: 0.0128\n",
      "Epoch 49/200, Iteration 91/250, Loss: 0.0076\n",
      "Epoch 49/200, Iteration 92/250, Loss: 0.0217\n",
      "Epoch 49/200, Iteration 93/250, Loss: 0.0232\n",
      "Epoch 49/200, Iteration 94/250, Loss: 0.0198\n",
      "Epoch 49/200, Iteration 95/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 96/250, Loss: 0.0420\n",
      "Epoch 49/200, Iteration 97/250, Loss: 0.0171\n",
      "Epoch 49/200, Iteration 98/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 99/250, Loss: 0.0106\n",
      "Epoch 49/200, Iteration 100/250, Loss: 0.0089\n",
      "Epoch 49/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 49/200, Iteration 102/250, Loss: 0.0143\n",
      "Epoch 49/200, Iteration 103/250, Loss: 0.0080\n",
      "Epoch 49/200, Iteration 104/250, Loss: 0.0155\n",
      "Epoch 49/200, Iteration 105/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 106/250, Loss: 0.0188\n",
      "Epoch 49/200, Iteration 107/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 49/200, Iteration 109/250, Loss: 0.0251\n",
      "Epoch 49/200, Iteration 110/250, Loss: 0.0222\n",
      "Epoch 49/200, Iteration 111/250, Loss: 0.0127\n",
      "Epoch 49/200, Iteration 112/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 113/250, Loss: 0.0081\n",
      "Epoch 49/200, Iteration 114/250, Loss: 0.0203\n",
      "Epoch 49/200, Iteration 115/250, Loss: 0.0286\n",
      "Epoch 49/200, Iteration 116/250, Loss: 0.0145\n",
      "Epoch 49/200, Iteration 117/250, Loss: 0.0339\n",
      "Epoch 49/200, Iteration 118/250, Loss: 0.0135\n",
      "Epoch 49/200, Iteration 119/250, Loss: 0.0124\n",
      "Epoch 49/200, Iteration 120/250, Loss: 0.0255\n",
      "Epoch 49/200, Iteration 121/250, Loss: 0.0270\n",
      "Epoch 49/200, Iteration 122/250, Loss: 0.0174\n",
      "Epoch 49/200, Iteration 123/250, Loss: 0.0184\n",
      "Epoch 49/200, Iteration 124/250, Loss: 0.0092\n",
      "Epoch 49/200, Iteration 125/250, Loss: 0.0113\n",
      "Epoch 49/200, Iteration 126/250, Loss: 0.0103\n",
      "Epoch 49/200, Iteration 127/250, Loss: 0.0375\n",
      "Epoch 49/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 129/250, Loss: 0.0200\n",
      "Epoch 49/200, Iteration 130/250, Loss: 0.0125\n",
      "Epoch 49/200, Iteration 131/250, Loss: 0.0334\n",
      "Epoch 49/200, Iteration 132/250, Loss: 0.0262\n",
      "Epoch 49/200, Iteration 133/250, Loss: 0.0135\n",
      "Epoch 49/200, Iteration 134/250, Loss: 0.0211\n",
      "Epoch 49/200, Iteration 135/250, Loss: 0.0306\n",
      "Epoch 49/200, Iteration 136/250, Loss: 0.0125\n",
      "Epoch 49/200, Iteration 137/250, Loss: 0.0177\n",
      "Epoch 49/200, Iteration 138/250, Loss: 0.0107\n",
      "Epoch 49/200, Iteration 139/250, Loss: 0.0144\n",
      "Epoch 49/200, Iteration 140/250, Loss: 0.0318\n",
      "Epoch 49/200, Iteration 141/250, Loss: 0.0130\n",
      "Epoch 49/200, Iteration 142/250, Loss: 0.0225\n",
      "Epoch 49/200, Iteration 143/250, Loss: 0.0197\n",
      "Epoch 49/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 49/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 146/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 147/250, Loss: 0.0158\n",
      "Epoch 49/200, Iteration 148/250, Loss: 0.0107\n",
      "Epoch 49/200, Iteration 149/250, Loss: 0.0119\n",
      "Epoch 49/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 49/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 49/200, Iteration 152/250, Loss: 0.0224\n",
      "Epoch 49/200, Iteration 153/250, Loss: 0.0337\n",
      "Epoch 49/200, Iteration 154/250, Loss: 0.0086\n",
      "Epoch 49/200, Iteration 155/250, Loss: 0.0128\n",
      "Epoch 49/200, Iteration 156/250, Loss: 0.0169\n",
      "Epoch 49/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 49/200, Iteration 158/250, Loss: 0.0375\n",
      "Epoch 49/200, Iteration 159/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 160/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 161/250, Loss: 0.0227\n",
      "Epoch 49/200, Iteration 162/250, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 163/250, Loss: 0.0103\n",
      "Epoch 49/200, Iteration 164/250, Loss: 0.0150\n",
      "Epoch 49/200, Iteration 165/250, Loss: 0.0088\n",
      "Epoch 49/200, Iteration 166/250, Loss: 0.0188\n",
      "Epoch 49/200, Iteration 167/250, Loss: 0.0220\n",
      "Epoch 49/200, Iteration 168/250, Loss: 0.0150\n",
      "Epoch 49/200, Iteration 169/250, Loss: 0.0119\n",
      "Epoch 49/200, Iteration 170/250, Loss: 0.0260\n",
      "Epoch 49/200, Iteration 171/250, Loss: 0.0170\n",
      "Epoch 49/200, Iteration 172/250, Loss: 0.0238\n",
      "Epoch 49/200, Iteration 173/250, Loss: 0.0141\n",
      "Epoch 49/200, Iteration 174/250, Loss: 0.0149\n",
      "Epoch 49/200, Iteration 175/250, Loss: 0.0157\n",
      "Epoch 49/200, Iteration 176/250, Loss: 0.0107\n",
      "Epoch 49/200, Iteration 177/250, Loss: 0.0086\n",
      "Epoch 49/200, Iteration 178/250, Loss: 0.0078\n",
      "Epoch 49/200, Iteration 179/250, Loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Iteration 180/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 181/250, Loss: 0.0295\n",
      "Epoch 49/200, Iteration 182/250, Loss: 0.0096\n",
      "Epoch 49/200, Iteration 183/250, Loss: 0.0109\n",
      "Epoch 49/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 185/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 186/250, Loss: 0.0215\n",
      "Epoch 49/200, Iteration 187/250, Loss: 0.0155\n",
      "Epoch 49/200, Iteration 188/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 189/250, Loss: 0.0106\n",
      "Epoch 49/200, Iteration 190/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 191/250, Loss: 0.0235\n",
      "Epoch 49/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 49/200, Iteration 193/250, Loss: 0.0087\n",
      "Epoch 49/200, Iteration 194/250, Loss: 0.0148\n",
      "Epoch 49/200, Iteration 195/250, Loss: 0.0085\n",
      "Epoch 49/200, Iteration 196/250, Loss: 0.0155\n",
      "Epoch 49/200, Iteration 197/250, Loss: 0.0207\n",
      "Epoch 49/200, Iteration 198/250, Loss: 0.0153\n",
      "Epoch 49/200, Iteration 199/250, Loss: 0.0271\n",
      "Epoch 49/200, Iteration 200/250, Loss: 0.0125\n",
      "Epoch 49/200, Iteration 201/250, Loss: 0.0083\n",
      "Epoch 49/200, Iteration 202/250, Loss: 0.0176\n",
      "Epoch 49/200, Iteration 203/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 204/250, Loss: 0.0142\n",
      "Epoch 49/200, Iteration 205/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 206/250, Loss: 0.0539\n",
      "Epoch 49/200, Iteration 207/250, Loss: 0.0236\n",
      "Epoch 49/200, Iteration 208/250, Loss: 0.0168\n",
      "Epoch 49/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 49/200, Iteration 210/250, Loss: 0.0064\n",
      "Epoch 49/200, Iteration 211/250, Loss: 0.0242\n",
      "Epoch 49/200, Iteration 212/250, Loss: 0.0096\n",
      "Epoch 49/200, Iteration 213/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 214/250, Loss: 0.0083\n",
      "Epoch 49/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 49/200, Iteration 216/250, Loss: 0.0152\n",
      "Epoch 49/200, Iteration 217/250, Loss: 0.0190\n",
      "Epoch 49/200, Iteration 218/250, Loss: 0.0197\n",
      "Epoch 49/200, Iteration 219/250, Loss: 0.0420\n",
      "Epoch 49/200, Iteration 220/250, Loss: 0.0129\n",
      "Epoch 49/200, Iteration 221/250, Loss: 0.0096\n",
      "Epoch 49/200, Iteration 222/250, Loss: 0.0094\n",
      "Epoch 49/200, Iteration 223/250, Loss: 0.0263\n",
      "Epoch 49/200, Iteration 224/250, Loss: 0.0107\n",
      "Epoch 49/200, Iteration 225/250, Loss: 0.0233\n",
      "Epoch 49/200, Iteration 226/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 227/250, Loss: 0.0602\n",
      "Epoch 49/200, Iteration 228/250, Loss: 0.0172\n",
      "Epoch 49/200, Iteration 229/250, Loss: 0.0152\n",
      "Epoch 49/200, Iteration 230/250, Loss: 0.0331\n",
      "Epoch 49/200, Iteration 231/250, Loss: 0.0156\n",
      "Epoch 49/200, Iteration 232/250, Loss: 0.0133\n",
      "Epoch 49/200, Iteration 233/250, Loss: 0.0122\n",
      "Epoch 49/200, Iteration 234/250, Loss: 0.0363\n",
      "Epoch 49/200, Iteration 235/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 236/250, Loss: 0.0188\n",
      "Epoch 49/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 49/200, Iteration 238/250, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 239/250, Loss: 0.0088\n",
      "Epoch 49/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 241/250, Loss: 0.0206\n",
      "Epoch 49/200, Iteration 242/250, Loss: 0.0102\n",
      "Epoch 49/200, Iteration 243/250, Loss: 0.0130\n",
      "Epoch 49/200, Iteration 244/250, Loss: 0.0120\n",
      "Epoch 49/200, Iteration 245/250, Loss: 0.0079\n",
      "Epoch 49/200, Iteration 246/250, Loss: 0.0192\n",
      "Epoch 49/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 248/250, Loss: 0.0256\n",
      "Epoch 49/200, Iteration 249/250, Loss: 0.0157\n",
      "Epoch 49/200, Iteration 250/250, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 87.75%, Avg loss: 0.007415, MRE: 0.651389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.95%, Avg loss: 0.007511, MRE: 1.028108 \n",
      "\n",
      "Epoch 50/200, Iteration 1/250, Loss: 0.0267\n",
      "Epoch 50/200, Iteration 2/250, Loss: 0.0116\n",
      "Epoch 50/200, Iteration 3/250, Loss: 0.0217\n",
      "Epoch 50/200, Iteration 4/250, Loss: 0.0272\n",
      "Epoch 50/200, Iteration 5/250, Loss: 0.0161\n",
      "Epoch 50/200, Iteration 6/250, Loss: 0.0097\n",
      "Epoch 50/200, Iteration 7/250, Loss: 0.0436\n",
      "Epoch 50/200, Iteration 8/250, Loss: 0.0169\n",
      "Epoch 50/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 50/200, Iteration 10/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 11/250, Loss: 0.0121\n",
      "Epoch 50/200, Iteration 12/250, Loss: 0.0163\n",
      "Epoch 50/200, Iteration 13/250, Loss: 0.0195\n",
      "Epoch 50/200, Iteration 14/250, Loss: 0.0167\n",
      "Epoch 50/200, Iteration 15/250, Loss: 0.0083\n",
      "Epoch 50/200, Iteration 16/250, Loss: 0.0184\n",
      "Epoch 50/200, Iteration 17/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 18/250, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 19/250, Loss: 0.0184\n",
      "Epoch 50/200, Iteration 20/250, Loss: 0.0190\n",
      "Epoch 50/200, Iteration 21/250, Loss: 0.0175\n",
      "Epoch 50/200, Iteration 22/250, Loss: 0.0078\n",
      "Epoch 50/200, Iteration 23/250, Loss: 0.0076\n",
      "Epoch 50/200, Iteration 24/250, Loss: 0.0160\n",
      "Epoch 50/200, Iteration 25/250, Loss: 0.0130\n",
      "Epoch 50/200, Iteration 26/250, Loss: 0.0148\n",
      "Epoch 50/200, Iteration 27/250, Loss: 0.0374\n",
      "Epoch 50/200, Iteration 28/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 29/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 30/250, Loss: 0.0102\n",
      "Epoch 50/200, Iteration 31/250, Loss: 0.0111\n",
      "Epoch 50/200, Iteration 32/250, Loss: 0.0353\n",
      "Epoch 50/200, Iteration 33/250, Loss: 0.0176\n",
      "Epoch 50/200, Iteration 34/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 35/250, Loss: 0.0322\n",
      "Epoch 50/200, Iteration 36/250, Loss: 0.0144\n",
      "Epoch 50/200, Iteration 37/250, Loss: 0.0251\n",
      "Epoch 50/200, Iteration 38/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 39/250, Loss: 0.0123\n",
      "Epoch 50/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 41/250, Loss: 0.0075\n",
      "Epoch 50/200, Iteration 42/250, Loss: 0.0119\n",
      "Epoch 50/200, Iteration 43/250, Loss: 0.0285\n",
      "Epoch 50/200, Iteration 44/250, Loss: 0.0094\n",
      "Epoch 50/200, Iteration 45/250, Loss: 0.0266\n",
      "Epoch 50/200, Iteration 46/250, Loss: 0.0123\n",
      "Epoch 50/200, Iteration 47/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 48/250, Loss: 0.0211\n",
      "Epoch 50/200, Iteration 49/250, Loss: 0.0355\n",
      "Epoch 50/200, Iteration 50/250, Loss: 0.0052\n",
      "Epoch 50/200, Iteration 51/250, Loss: 0.0113\n",
      "Epoch 50/200, Iteration 52/250, Loss: 0.0088\n",
      "Epoch 50/200, Iteration 53/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 54/250, Loss: 0.0206\n",
      "Epoch 50/200, Iteration 55/250, Loss: 0.0113\n",
      "Epoch 50/200, Iteration 56/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 57/250, Loss: 0.0204\n",
      "Epoch 50/200, Iteration 58/250, Loss: 0.0151\n",
      "Epoch 50/200, Iteration 59/250, Loss: 0.0276\n",
      "Epoch 50/200, Iteration 60/250, Loss: 0.0153\n",
      "Epoch 50/200, Iteration 61/250, Loss: 0.0235\n",
      "Epoch 50/200, Iteration 62/250, Loss: 0.0098\n",
      "Epoch 50/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 64/250, Loss: 0.0133\n",
      "Epoch 50/200, Iteration 65/250, Loss: 0.0534\n",
      "Epoch 50/200, Iteration 66/250, Loss: 0.0106\n",
      "Epoch 50/200, Iteration 67/250, Loss: 0.0087\n",
      "Epoch 50/200, Iteration 68/250, Loss: 0.0117\n",
      "Epoch 50/200, Iteration 69/250, Loss: 0.0064\n",
      "Epoch 50/200, Iteration 70/250, Loss: 0.0123\n",
      "Epoch 50/200, Iteration 71/250, Loss: 0.0103\n",
      "Epoch 50/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 50/200, Iteration 73/250, Loss: 0.0145\n",
      "Epoch 50/200, Iteration 74/250, Loss: 0.0113\n",
      "Epoch 50/200, Iteration 75/250, Loss: 0.0073\n",
      "Epoch 50/200, Iteration 76/250, Loss: 0.0083\n",
      "Epoch 50/200, Iteration 77/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 78/250, Loss: 0.0164\n",
      "Epoch 50/200, Iteration 79/250, Loss: 0.0088\n",
      "Epoch 50/200, Iteration 80/250, Loss: 0.0076\n",
      "Epoch 50/200, Iteration 81/250, Loss: 0.0112\n",
      "Epoch 50/200, Iteration 82/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 83/250, Loss: 0.0086\n",
      "Epoch 50/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 50/200, Iteration 85/250, Loss: 0.0182\n",
      "Epoch 50/200, Iteration 86/250, Loss: 0.0157\n",
      "Epoch 50/200, Iteration 87/250, Loss: 0.0087\n",
      "Epoch 50/200, Iteration 88/250, Loss: 0.0191\n",
      "Epoch 50/200, Iteration 89/250, Loss: 0.0118\n",
      "Epoch 50/200, Iteration 90/250, Loss: 0.0189\n",
      "Epoch 50/200, Iteration 91/250, Loss: 0.0221\n",
      "Epoch 50/200, Iteration 92/250, Loss: 0.0155\n",
      "Epoch 50/200, Iteration 93/250, Loss: 0.0223\n",
      "Epoch 50/200, Iteration 94/250, Loss: 0.0170\n",
      "Epoch 50/200, Iteration 95/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 96/250, Loss: 0.0230\n",
      "Epoch 50/200, Iteration 97/250, Loss: 0.0148\n",
      "Epoch 50/200, Iteration 98/250, Loss: 0.0080\n",
      "Epoch 50/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 50/200, Iteration 100/250, Loss: 0.0181\n",
      "Epoch 50/200, Iteration 101/250, Loss: 0.0171\n",
      "Epoch 50/200, Iteration 102/250, Loss: 0.0274\n",
      "Epoch 50/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 50/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 50/200, Iteration 105/250, Loss: 0.0264\n",
      "Epoch 50/200, Iteration 106/250, Loss: 0.0208\n",
      "Epoch 50/200, Iteration 107/250, Loss: 0.0230\n",
      "Epoch 50/200, Iteration 108/250, Loss: 0.0369\n",
      "Epoch 50/200, Iteration 109/250, Loss: 0.0262\n",
      "Epoch 50/200, Iteration 110/250, Loss: 0.0152\n",
      "Epoch 50/200, Iteration 111/250, Loss: 0.0097\n",
      "Epoch 50/200, Iteration 112/250, Loss: 0.0138\n",
      "Epoch 50/200, Iteration 113/250, Loss: 0.0550\n",
      "Epoch 50/200, Iteration 114/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 115/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 116/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 117/250, Loss: 0.0260\n",
      "Epoch 50/200, Iteration 118/250, Loss: 0.0274\n",
      "Epoch 50/200, Iteration 119/250, Loss: 0.0252\n",
      "Epoch 50/200, Iteration 120/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 121/250, Loss: 0.0176\n",
      "Epoch 50/200, Iteration 122/250, Loss: 0.0170\n",
      "Epoch 50/200, Iteration 123/250, Loss: 0.0279\n",
      "Epoch 50/200, Iteration 124/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 125/250, Loss: 0.0215\n",
      "Epoch 50/200, Iteration 126/250, Loss: 0.0064\n",
      "Epoch 50/200, Iteration 127/250, Loss: 0.0139\n",
      "Epoch 50/200, Iteration 128/250, Loss: 0.0228\n",
      "Epoch 50/200, Iteration 129/250, Loss: 0.0119\n",
      "Epoch 50/200, Iteration 130/250, Loss: 0.0202\n",
      "Epoch 50/200, Iteration 131/250, Loss: 0.0159\n",
      "Epoch 50/200, Iteration 132/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 133/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Iteration 134/250, Loss: 0.0313\n",
      "Epoch 50/200, Iteration 135/250, Loss: 0.0152\n",
      "Epoch 50/200, Iteration 136/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 137/250, Loss: 0.0129\n",
      "Epoch 50/200, Iteration 138/250, Loss: 0.0062\n",
      "Epoch 50/200, Iteration 139/250, Loss: 0.0315\n",
      "Epoch 50/200, Iteration 140/250, Loss: 0.0498\n",
      "Epoch 50/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 50/200, Iteration 142/250, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 143/250, Loss: 0.0120\n",
      "Epoch 50/200, Iteration 144/250, Loss: 0.0211\n",
      "Epoch 50/200, Iteration 145/250, Loss: 0.0284\n",
      "Epoch 50/200, Iteration 146/250, Loss: 0.0093\n",
      "Epoch 50/200, Iteration 147/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 148/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 149/250, Loss: 0.0130\n",
      "Epoch 50/200, Iteration 150/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 151/250, Loss: 0.0108\n",
      "Epoch 50/200, Iteration 152/250, Loss: 0.0170\n",
      "Epoch 50/200, Iteration 153/250, Loss: 0.0149\n",
      "Epoch 50/200, Iteration 154/250, Loss: 0.0109\n",
      "Epoch 50/200, Iteration 155/250, Loss: 0.0105\n",
      "Epoch 50/200, Iteration 156/250, Loss: 0.0099\n",
      "Epoch 50/200, Iteration 157/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 158/250, Loss: 0.0090\n",
      "Epoch 50/200, Iteration 159/250, Loss: 0.0177\n",
      "Epoch 50/200, Iteration 160/250, Loss: 0.0144\n",
      "Epoch 50/200, Iteration 161/250, Loss: 0.0187\n",
      "Epoch 50/200, Iteration 162/250, Loss: 0.0258\n",
      "Epoch 50/200, Iteration 163/250, Loss: 0.0206\n",
      "Epoch 50/200, Iteration 164/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 165/250, Loss: 0.0170\n",
      "Epoch 50/200, Iteration 166/250, Loss: 0.0190\n",
      "Epoch 50/200, Iteration 167/250, Loss: 0.0293\n",
      "Epoch 50/200, Iteration 168/250, Loss: 0.0159\n",
      "Epoch 50/200, Iteration 169/250, Loss: 0.0174\n",
      "Epoch 50/200, Iteration 170/250, Loss: 0.0270\n",
      "Epoch 50/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 172/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 173/250, Loss: 0.0159\n",
      "Epoch 50/200, Iteration 174/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 175/250, Loss: 0.0169\n",
      "Epoch 50/200, Iteration 176/250, Loss: 0.0126\n",
      "Epoch 50/200, Iteration 177/250, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 178/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 179/250, Loss: 0.0190\n",
      "Epoch 50/200, Iteration 180/250, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 181/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 182/250, Loss: 0.0119\n",
      "Epoch 50/200, Iteration 183/250, Loss: 0.0262\n",
      "Epoch 50/200, Iteration 184/250, Loss: 0.0143\n",
      "Epoch 50/200, Iteration 185/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 186/250, Loss: 0.0164\n",
      "Epoch 50/200, Iteration 187/250, Loss: 0.0107\n",
      "Epoch 50/200, Iteration 188/250, Loss: 0.0083\n",
      "Epoch 50/200, Iteration 189/250, Loss: 0.0127\n",
      "Epoch 50/200, Iteration 190/250, Loss: 0.0129\n",
      "Epoch 50/200, Iteration 191/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 192/250, Loss: 0.0156\n",
      "Epoch 50/200, Iteration 193/250, Loss: 0.0223\n",
      "Epoch 50/200, Iteration 194/250, Loss: 0.0067\n",
      "Epoch 50/200, Iteration 195/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 196/250, Loss: 0.0119\n",
      "Epoch 50/200, Iteration 197/250, Loss: 0.0146\n",
      "Epoch 50/200, Iteration 198/250, Loss: 0.0146\n",
      "Epoch 50/200, Iteration 199/250, Loss: 0.0086\n",
      "Epoch 50/200, Iteration 200/250, Loss: 0.0099\n",
      "Epoch 50/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 50/200, Iteration 202/250, Loss: 0.0070\n",
      "Epoch 50/200, Iteration 203/250, Loss: 0.0151\n",
      "Epoch 50/200, Iteration 204/250, Loss: 0.0179\n",
      "Epoch 50/200, Iteration 205/250, Loss: 0.0201\n",
      "Epoch 50/200, Iteration 206/250, Loss: 0.0234\n",
      "Epoch 50/200, Iteration 207/250, Loss: 0.0111\n",
      "Epoch 50/200, Iteration 208/250, Loss: 0.0174\n",
      "Epoch 50/200, Iteration 209/250, Loss: 0.0315\n",
      "Epoch 50/200, Iteration 210/250, Loss: 0.0272\n",
      "Epoch 50/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 212/250, Loss: 0.0133\n",
      "Epoch 50/200, Iteration 213/250, Loss: 0.0243\n",
      "Epoch 50/200, Iteration 214/250, Loss: 0.0120\n",
      "Epoch 50/200, Iteration 215/250, Loss: 0.0125\n",
      "Epoch 50/200, Iteration 216/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 217/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 218/250, Loss: 0.0275\n",
      "Epoch 50/200, Iteration 219/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 220/250, Loss: 0.0155\n",
      "Epoch 50/200, Iteration 221/250, Loss: 0.0073\n",
      "Epoch 50/200, Iteration 222/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 223/250, Loss: 0.0102\n",
      "Epoch 50/200, Iteration 224/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 226/250, Loss: 0.0107\n",
      "Epoch 50/200, Iteration 227/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 228/250, Loss: 0.0176\n",
      "Epoch 50/200, Iteration 229/250, Loss: 0.0239\n",
      "Epoch 50/200, Iteration 230/250, Loss: 0.0228\n",
      "Epoch 50/200, Iteration 231/250, Loss: 0.0252\n",
      "Epoch 50/200, Iteration 232/250, Loss: 0.0089\n",
      "Epoch 50/200, Iteration 233/250, Loss: 0.0366\n",
      "Epoch 50/200, Iteration 234/250, Loss: 0.0102\n",
      "Epoch 50/200, Iteration 235/250, Loss: 0.0108\n",
      "Epoch 50/200, Iteration 236/250, Loss: 0.0307\n",
      "Epoch 50/200, Iteration 237/250, Loss: 0.0062\n",
      "Epoch 50/200, Iteration 238/250, Loss: 0.0082\n",
      "Epoch 50/200, Iteration 239/250, Loss: 0.0230\n",
      "Epoch 50/200, Iteration 240/250, Loss: 0.0153\n",
      "Epoch 50/200, Iteration 241/250, Loss: 0.0400\n",
      "Epoch 50/200, Iteration 242/250, Loss: 0.0095\n",
      "Epoch 50/200, Iteration 243/250, Loss: 0.0134\n",
      "Epoch 50/200, Iteration 244/250, Loss: 0.0117\n",
      "Epoch 50/200, Iteration 245/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 246/250, Loss: 0.0134\n",
      "Epoch 50/200, Iteration 247/250, Loss: 0.0296\n",
      "Epoch 50/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 50/200, Iteration 249/250, Loss: 0.0178\n",
      "Epoch 50/200, Iteration 250/250, Loss: 0.0145\n",
      "Train Error: \n",
      " Accuracy: 93.65%, Avg loss: 0.007688, MRE: 0.585122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.55%, Avg loss: 0.007616, MRE: 0.881121 \n",
      "\n",
      "Epoch 51/200, Iteration 1/250, Loss: 0.0216\n",
      "Epoch 51/200, Iteration 2/250, Loss: 0.0200\n",
      "Epoch 51/200, Iteration 3/250, Loss: 0.0144\n",
      "Epoch 51/200, Iteration 4/250, Loss: 0.0270\n",
      "Epoch 51/200, Iteration 5/250, Loss: 0.0168\n",
      "Epoch 51/200, Iteration 6/250, Loss: 0.0207\n",
      "Epoch 51/200, Iteration 7/250, Loss: 0.0134\n",
      "Epoch 51/200, Iteration 8/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 9/250, Loss: 0.0202\n",
      "Epoch 51/200, Iteration 10/250, Loss: 0.0154\n",
      "Epoch 51/200, Iteration 11/250, Loss: 0.0144\n",
      "Epoch 51/200, Iteration 12/250, Loss: 0.0279\n",
      "Epoch 51/200, Iteration 13/250, Loss: 0.0225\n",
      "Epoch 51/200, Iteration 14/250, Loss: 0.0199\n",
      "Epoch 51/200, Iteration 15/250, Loss: 0.0126\n",
      "Epoch 51/200, Iteration 16/250, Loss: 0.0159\n",
      "Epoch 51/200, Iteration 17/250, Loss: 0.0171\n",
      "Epoch 51/200, Iteration 18/250, Loss: 0.0208\n",
      "Epoch 51/200, Iteration 19/250, Loss: 0.0133\n",
      "Epoch 51/200, Iteration 20/250, Loss: 0.0089\n",
      "Epoch 51/200, Iteration 21/250, Loss: 0.0196\n",
      "Epoch 51/200, Iteration 22/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 23/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 24/250, Loss: 0.0220\n",
      "Epoch 51/200, Iteration 25/250, Loss: 0.0168\n",
      "Epoch 51/200, Iteration 26/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 27/250, Loss: 0.0194\n",
      "Epoch 51/200, Iteration 28/250, Loss: 0.0268\n",
      "Epoch 51/200, Iteration 29/250, Loss: 0.0146\n",
      "Epoch 51/200, Iteration 30/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 31/250, Loss: 0.0247\n",
      "Epoch 51/200, Iteration 32/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 33/250, Loss: 0.0111\n",
      "Epoch 51/200, Iteration 34/250, Loss: 0.0137\n",
      "Epoch 51/200, Iteration 35/250, Loss: 0.0099\n",
      "Epoch 51/200, Iteration 36/250, Loss: 0.0300\n",
      "Epoch 51/200, Iteration 37/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 38/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 39/250, Loss: 0.0197\n",
      "Epoch 51/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 41/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 42/250, Loss: 0.0221\n",
      "Epoch 51/200, Iteration 43/250, Loss: 0.0210\n",
      "Epoch 51/200, Iteration 44/250, Loss: 0.0111\n",
      "Epoch 51/200, Iteration 45/250, Loss: 0.0098\n",
      "Epoch 51/200, Iteration 46/250, Loss: 0.0140\n",
      "Epoch 51/200, Iteration 47/250, Loss: 0.0253\n",
      "Epoch 51/200, Iteration 48/250, Loss: 0.0164\n",
      "Epoch 51/200, Iteration 49/250, Loss: 0.0159\n",
      "Epoch 51/200, Iteration 50/250, Loss: 0.0241\n",
      "Epoch 51/200, Iteration 51/250, Loss: 0.0150\n",
      "Epoch 51/200, Iteration 52/250, Loss: 0.0241\n",
      "Epoch 51/200, Iteration 53/250, Loss: 0.0118\n",
      "Epoch 51/200, Iteration 54/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 55/250, Loss: 0.0091\n",
      "Epoch 51/200, Iteration 56/250, Loss: 0.0136\n",
      "Epoch 51/200, Iteration 57/250, Loss: 0.0086\n",
      "Epoch 51/200, Iteration 58/250, Loss: 0.0224\n",
      "Epoch 51/200, Iteration 59/250, Loss: 0.0120\n",
      "Epoch 51/200, Iteration 60/250, Loss: 0.0141\n",
      "Epoch 51/200, Iteration 61/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 62/250, Loss: 0.0187\n",
      "Epoch 51/200, Iteration 63/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 64/250, Loss: 0.0151\n",
      "Epoch 51/200, Iteration 65/250, Loss: 0.0078\n",
      "Epoch 51/200, Iteration 66/250, Loss: 0.0169\n",
      "Epoch 51/200, Iteration 67/250, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Iteration 68/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 69/250, Loss: 0.0280\n",
      "Epoch 51/200, Iteration 70/250, Loss: 0.0087\n",
      "Epoch 51/200, Iteration 71/250, Loss: 0.0209\n",
      "Epoch 51/200, Iteration 72/250, Loss: 0.0250\n",
      "Epoch 51/200, Iteration 73/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 74/250, Loss: 0.0310\n",
      "Epoch 51/200, Iteration 75/250, Loss: 0.0088\n",
      "Epoch 51/200, Iteration 76/250, Loss: 0.0156\n",
      "Epoch 51/200, Iteration 77/250, Loss: 0.0196\n",
      "Epoch 51/200, Iteration 78/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 79/250, Loss: 0.0192\n",
      "Epoch 51/200, Iteration 80/250, Loss: 0.0125\n",
      "Epoch 51/200, Iteration 81/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 82/250, Loss: 0.0281\n",
      "Epoch 51/200, Iteration 83/250, Loss: 0.0212\n",
      "Epoch 51/200, Iteration 84/250, Loss: 0.0180\n",
      "Epoch 51/200, Iteration 85/250, Loss: 0.0116\n",
      "Epoch 51/200, Iteration 86/250, Loss: 0.0118\n",
      "Epoch 51/200, Iteration 87/250, Loss: 0.0385\n",
      "Epoch 51/200, Iteration 88/250, Loss: 0.0108\n",
      "Epoch 51/200, Iteration 89/250, Loss: 0.0110\n",
      "Epoch 51/200, Iteration 90/250, Loss: 0.0208\n",
      "Epoch 51/200, Iteration 91/250, Loss: 0.0087\n",
      "Epoch 51/200, Iteration 92/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 93/250, Loss: 0.0214\n",
      "Epoch 51/200, Iteration 94/250, Loss: 0.0123\n",
      "Epoch 51/200, Iteration 95/250, Loss: 0.0102\n",
      "Epoch 51/200, Iteration 96/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 97/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 98/250, Loss: 0.0200\n",
      "Epoch 51/200, Iteration 99/250, Loss: 0.0153\n",
      "Epoch 51/200, Iteration 100/250, Loss: 0.0273\n",
      "Epoch 51/200, Iteration 101/250, Loss: 0.0317\n",
      "Epoch 51/200, Iteration 102/250, Loss: 0.0280\n",
      "Epoch 51/200, Iteration 103/250, Loss: 0.0110\n",
      "Epoch 51/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 51/200, Iteration 105/250, Loss: 0.0204\n",
      "Epoch 51/200, Iteration 106/250, Loss: 0.0185\n",
      "Epoch 51/200, Iteration 107/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 108/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 109/250, Loss: 0.0098\n",
      "Epoch 51/200, Iteration 110/250, Loss: 0.0157\n",
      "Epoch 51/200, Iteration 111/250, Loss: 0.0158\n",
      "Epoch 51/200, Iteration 112/250, Loss: 0.0090\n",
      "Epoch 51/200, Iteration 113/250, Loss: 0.0082\n",
      "Epoch 51/200, Iteration 114/250, Loss: 0.0082\n",
      "Epoch 51/200, Iteration 115/250, Loss: 0.0121\n",
      "Epoch 51/200, Iteration 116/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 117/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 118/250, Loss: 0.0139\n",
      "Epoch 51/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 51/200, Iteration 120/250, Loss: 0.0396\n",
      "Epoch 51/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 51/200, Iteration 122/250, Loss: 0.0163\n",
      "Epoch 51/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 51/200, Iteration 124/250, Loss: 0.0155\n",
      "Epoch 51/200, Iteration 125/250, Loss: 0.0089\n",
      "Epoch 51/200, Iteration 126/250, Loss: 0.0184\n",
      "Epoch 51/200, Iteration 127/250, Loss: 0.0082\n",
      "Epoch 51/200, Iteration 128/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 129/250, Loss: 0.0141\n",
      "Epoch 51/200, Iteration 130/250, Loss: 0.0187\n",
      "Epoch 51/200, Iteration 131/250, Loss: 0.0201\n",
      "Epoch 51/200, Iteration 132/250, Loss: 0.0123\n",
      "Epoch 51/200, Iteration 133/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 134/250, Loss: 0.0151\n",
      "Epoch 51/200, Iteration 135/250, Loss: 0.0140\n",
      "Epoch 51/200, Iteration 136/250, Loss: 0.0216\n",
      "Epoch 51/200, Iteration 137/250, Loss: 0.0079\n",
      "Epoch 51/200, Iteration 138/250, Loss: 0.0075\n",
      "Epoch 51/200, Iteration 139/250, Loss: 0.0097\n",
      "Epoch 51/200, Iteration 140/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 141/250, Loss: 0.0116\n",
      "Epoch 51/200, Iteration 142/250, Loss: 0.0283\n",
      "Epoch 51/200, Iteration 143/250, Loss: 0.0238\n",
      "Epoch 51/200, Iteration 144/250, Loss: 0.0234\n",
      "Epoch 51/200, Iteration 145/250, Loss: 0.0194\n",
      "Epoch 51/200, Iteration 146/250, Loss: 0.0078\n",
      "Epoch 51/200, Iteration 147/250, Loss: 0.0170\n",
      "Epoch 51/200, Iteration 148/250, Loss: 0.0111\n",
      "Epoch 51/200, Iteration 149/250, Loss: 0.0094\n",
      "Epoch 51/200, Iteration 150/250, Loss: 0.0128\n",
      "Epoch 51/200, Iteration 151/250, Loss: 0.0118\n",
      "Epoch 51/200, Iteration 152/250, Loss: 0.0068\n",
      "Epoch 51/200, Iteration 153/250, Loss: 0.0165\n",
      "Epoch 51/200, Iteration 154/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 155/250, Loss: 0.0152\n",
      "Epoch 51/200, Iteration 156/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 51/200, Iteration 158/250, Loss: 0.0140\n",
      "Epoch 51/200, Iteration 159/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 160/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 161/250, Loss: 0.0173\n",
      "Epoch 51/200, Iteration 162/250, Loss: 0.0326\n",
      "Epoch 51/200, Iteration 163/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 164/250, Loss: 0.0399\n",
      "Epoch 51/200, Iteration 165/250, Loss: 0.0107\n",
      "Epoch 51/200, Iteration 166/250, Loss: 0.0128\n",
      "Epoch 51/200, Iteration 167/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 168/250, Loss: 0.0084\n",
      "Epoch 51/200, Iteration 169/250, Loss: 0.0266\n",
      "Epoch 51/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 171/250, Loss: 0.0141\n",
      "Epoch 51/200, Iteration 172/250, Loss: 0.0077\n",
      "Epoch 51/200, Iteration 173/250, Loss: 0.0152\n",
      "Epoch 51/200, Iteration 174/250, Loss: 0.0133\n",
      "Epoch 51/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 51/200, Iteration 176/250, Loss: 0.0126\n",
      "Epoch 51/200, Iteration 177/250, Loss: 0.0115\n",
      "Epoch 51/200, Iteration 178/250, Loss: 0.0209\n",
      "Epoch 51/200, Iteration 179/250, Loss: 0.0078\n",
      "Epoch 51/200, Iteration 180/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 181/250, Loss: 0.0214\n",
      "Epoch 51/200, Iteration 182/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 183/250, Loss: 0.0239\n",
      "Epoch 51/200, Iteration 184/250, Loss: 0.0187\n",
      "Epoch 51/200, Iteration 185/250, Loss: 0.0199\n",
      "Epoch 51/200, Iteration 186/250, Loss: 0.0156\n",
      "Epoch 51/200, Iteration 187/250, Loss: 0.0183\n",
      "Epoch 51/200, Iteration 188/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 189/250, Loss: 0.0154\n",
      "Epoch 51/200, Iteration 190/250, Loss: 0.0114\n",
      "Epoch 51/200, Iteration 191/250, Loss: 0.0129\n",
      "Epoch 51/200, Iteration 192/250, Loss: 0.0161\n",
      "Epoch 51/200, Iteration 193/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 51/200, Iteration 195/250, Loss: 0.0071\n",
      "Epoch 51/200, Iteration 196/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 197/250, Loss: 0.0154\n",
      "Epoch 51/200, Iteration 198/250, Loss: 0.0324\n",
      "Epoch 51/200, Iteration 199/250, Loss: 0.0102\n",
      "Epoch 51/200, Iteration 200/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 201/250, Loss: 0.0166\n",
      "Epoch 51/200, Iteration 202/250, Loss: 0.0164\n",
      "Epoch 51/200, Iteration 203/250, Loss: 0.0148\n",
      "Epoch 51/200, Iteration 204/250, Loss: 0.0077\n",
      "Epoch 51/200, Iteration 205/250, Loss: 0.0098\n",
      "Epoch 51/200, Iteration 206/250, Loss: 0.0189\n",
      "Epoch 51/200, Iteration 207/250, Loss: 0.0133\n",
      "Epoch 51/200, Iteration 208/250, Loss: 0.0139\n",
      "Epoch 51/200, Iteration 209/250, Loss: 0.0154\n",
      "Epoch 51/200, Iteration 210/250, Loss: 0.0269\n",
      "Epoch 51/200, Iteration 211/250, Loss: 0.0161\n",
      "Epoch 51/200, Iteration 212/250, Loss: 0.0164\n",
      "Epoch 51/200, Iteration 213/250, Loss: 0.0333\n",
      "Epoch 51/200, Iteration 214/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 215/250, Loss: 0.0285\n",
      "Epoch 51/200, Iteration 216/250, Loss: 0.0151\n",
      "Epoch 51/200, Iteration 217/250, Loss: 0.0172\n",
      "Epoch 51/200, Iteration 218/250, Loss: 0.0150\n",
      "Epoch 51/200, Iteration 219/250, Loss: 0.0434\n",
      "Epoch 51/200, Iteration 220/250, Loss: 0.0126\n",
      "Epoch 51/200, Iteration 221/250, Loss: 0.0105\n",
      "Epoch 51/200, Iteration 222/250, Loss: 0.0174\n",
      "Epoch 51/200, Iteration 223/250, Loss: 0.0178\n",
      "Epoch 51/200, Iteration 224/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 225/250, Loss: 0.0163\n",
      "Epoch 51/200, Iteration 226/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 227/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 228/250, Loss: 0.0093\n",
      "Epoch 51/200, Iteration 229/250, Loss: 0.0240\n",
      "Epoch 51/200, Iteration 230/250, Loss: 0.0156\n",
      "Epoch 51/200, Iteration 231/250, Loss: 0.0193\n",
      "Epoch 51/200, Iteration 232/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 233/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 234/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 235/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 236/250, Loss: 0.0114\n",
      "Epoch 51/200, Iteration 237/250, Loss: 0.0148\n",
      "Epoch 51/200, Iteration 238/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 239/250, Loss: 0.0173\n",
      "Epoch 51/200, Iteration 240/250, Loss: 0.0274\n",
      "Epoch 51/200, Iteration 241/250, Loss: 0.0248\n",
      "Epoch 51/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 51/200, Iteration 243/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 244/250, Loss: 0.0184\n",
      "Epoch 51/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 51/200, Iteration 246/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 247/250, Loss: 0.0189\n",
      "Epoch 51/200, Iteration 248/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 51/200, Iteration 250/250, Loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 86.72%, Avg loss: 0.007141, MRE: 0.626320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.007075, MRE: 0.945761 \n",
      "\n",
      "Epoch 52/200, Iteration 1/250, Loss: 0.0094\n",
      "Epoch 52/200, Iteration 2/250, Loss: 0.0152\n",
      "Epoch 52/200, Iteration 3/250, Loss: 0.0137\n",
      "Epoch 52/200, Iteration 4/250, Loss: 0.0123\n",
      "Epoch 52/200, Iteration 5/250, Loss: 0.0121\n",
      "Epoch 52/200, Iteration 6/250, Loss: 0.0232\n",
      "Epoch 52/200, Iteration 7/250, Loss: 0.0101\n",
      "Epoch 52/200, Iteration 8/250, Loss: 0.0277\n",
      "Epoch 52/200, Iteration 9/250, Loss: 0.0085\n",
      "Epoch 52/200, Iteration 10/250, Loss: 0.0172\n",
      "Epoch 52/200, Iteration 11/250, Loss: 0.0212\n",
      "Epoch 52/200, Iteration 12/250, Loss: 0.0159\n",
      "Epoch 52/200, Iteration 13/250, Loss: 0.0075\n",
      "Epoch 52/200, Iteration 14/250, Loss: 0.0127\n",
      "Epoch 52/200, Iteration 15/250, Loss: 0.0134\n",
      "Epoch 52/200, Iteration 16/250, Loss: 0.0143\n",
      "Epoch 52/200, Iteration 17/250, Loss: 0.0141\n",
      "Epoch 52/200, Iteration 18/250, Loss: 0.0132\n",
      "Epoch 52/200, Iteration 19/250, Loss: 0.0323\n",
      "Epoch 52/200, Iteration 20/250, Loss: 0.0149\n",
      "Epoch 52/200, Iteration 21/250, Loss: 0.0134\n",
      "Epoch 52/200, Iteration 22/250, Loss: 0.0085\n",
      "Epoch 52/200, Iteration 23/250, Loss: 0.0087\n",
      "Epoch 52/200, Iteration 24/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 25/250, Loss: 0.0118\n",
      "Epoch 52/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 52/200, Iteration 27/250, Loss: 0.0097\n",
      "Epoch 52/200, Iteration 28/250, Loss: 0.0173\n",
      "Epoch 52/200, Iteration 29/250, Loss: 0.0216\n",
      "Epoch 52/200, Iteration 30/250, Loss: 0.0127\n",
      "Epoch 52/200, Iteration 31/250, Loss: 0.0123\n",
      "Epoch 52/200, Iteration 32/250, Loss: 0.0221\n",
      "Epoch 52/200, Iteration 33/250, Loss: 0.0209\n",
      "Epoch 52/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 52/200, Iteration 35/250, Loss: 0.0117\n",
      "Epoch 52/200, Iteration 36/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 37/250, Loss: 0.0273\n",
      "Epoch 52/200, Iteration 38/250, Loss: 0.0132\n",
      "Epoch 52/200, Iteration 39/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 40/250, Loss: 0.0152\n",
      "Epoch 52/200, Iteration 41/250, Loss: 0.0186\n",
      "Epoch 52/200, Iteration 42/250, Loss: 0.0296\n",
      "Epoch 52/200, Iteration 43/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 44/250, Loss: 0.0100\n",
      "Epoch 52/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 52/200, Iteration 46/250, Loss: 0.0099\n",
      "Epoch 52/200, Iteration 47/250, Loss: 0.0098\n",
      "Epoch 52/200, Iteration 48/250, Loss: 0.0264\n",
      "Epoch 52/200, Iteration 49/250, Loss: 0.0105\n",
      "Epoch 52/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 52/200, Iteration 51/250, Loss: 0.0284\n",
      "Epoch 52/200, Iteration 52/250, Loss: 0.0105\n",
      "Epoch 52/200, Iteration 53/250, Loss: 0.0275\n",
      "Epoch 52/200, Iteration 54/250, Loss: 0.0143\n",
      "Epoch 52/200, Iteration 55/250, Loss: 0.0089\n",
      "Epoch 52/200, Iteration 56/250, Loss: 0.0119\n",
      "Epoch 52/200, Iteration 57/250, Loss: 0.0069\n",
      "Epoch 52/200, Iteration 58/250, Loss: 0.0107\n",
      "Epoch 52/200, Iteration 59/250, Loss: 0.0187\n",
      "Epoch 52/200, Iteration 60/250, Loss: 0.0140\n",
      "Epoch 52/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 52/200, Iteration 62/250, Loss: 0.0198\n",
      "Epoch 52/200, Iteration 63/250, Loss: 0.0162\n",
      "Epoch 52/200, Iteration 64/250, Loss: 0.0114\n",
      "Epoch 52/200, Iteration 65/250, Loss: 0.0111\n",
      "Epoch 52/200, Iteration 66/250, Loss: 0.0077\n",
      "Epoch 52/200, Iteration 67/250, Loss: 0.0109\n",
      "Epoch 52/200, Iteration 68/250, Loss: 0.0192\n",
      "Epoch 52/200, Iteration 69/250, Loss: 0.0168\n",
      "Epoch 52/200, Iteration 70/250, Loss: 0.0134\n",
      "Epoch 52/200, Iteration 71/250, Loss: 0.0162\n",
      "Epoch 52/200, Iteration 72/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 73/250, Loss: 0.0066\n",
      "Epoch 52/200, Iteration 74/250, Loss: 0.0275\n",
      "Epoch 52/200, Iteration 75/250, Loss: 0.0126\n",
      "Epoch 52/200, Iteration 76/250, Loss: 0.0258\n",
      "Epoch 52/200, Iteration 77/250, Loss: 0.0159\n",
      "Epoch 52/200, Iteration 78/250, Loss: 0.0229\n",
      "Epoch 52/200, Iteration 79/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 80/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 81/250, Loss: 0.0160\n",
      "Epoch 52/200, Iteration 82/250, Loss: 0.0170\n",
      "Epoch 52/200, Iteration 83/250, Loss: 0.0208\n",
      "Epoch 52/200, Iteration 84/250, Loss: 0.0115\n",
      "Epoch 52/200, Iteration 85/250, Loss: 0.0090\n",
      "Epoch 52/200, Iteration 86/250, Loss: 0.0205\n",
      "Epoch 52/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 52/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 52/200, Iteration 89/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 90/250, Loss: 0.0313\n",
      "Epoch 52/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 52/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 52/200, Iteration 93/250, Loss: 0.0148\n",
      "Epoch 52/200, Iteration 94/250, Loss: 0.0136\n",
      "Epoch 52/200, Iteration 95/250, Loss: 0.0285\n",
      "Epoch 52/200, Iteration 96/250, Loss: 0.0086\n",
      "Epoch 52/200, Iteration 97/250, Loss: 0.0166\n",
      "Epoch 52/200, Iteration 98/250, Loss: 0.0168\n",
      "Epoch 52/200, Iteration 99/250, Loss: 0.0252\n",
      "Epoch 52/200, Iteration 100/250, Loss: 0.0173\n",
      "Epoch 52/200, Iteration 101/250, Loss: 0.0085\n",
      "Epoch 52/200, Iteration 102/250, Loss: 0.0144\n",
      "Epoch 52/200, Iteration 103/250, Loss: 0.0196\n",
      "Epoch 52/200, Iteration 104/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 105/250, Loss: 0.0224\n",
      "Epoch 52/200, Iteration 106/250, Loss: 0.0251\n",
      "Epoch 52/200, Iteration 107/250, Loss: 0.0206\n",
      "Epoch 52/200, Iteration 108/250, Loss: 0.0306\n",
      "Epoch 52/200, Iteration 109/250, Loss: 0.0136\n",
      "Epoch 52/200, Iteration 110/250, Loss: 0.0125\n",
      "Epoch 52/200, Iteration 111/250, Loss: 0.0210\n",
      "Epoch 52/200, Iteration 112/250, Loss: 0.0207\n",
      "Epoch 52/200, Iteration 113/250, Loss: 0.0130\n",
      "Epoch 52/200, Iteration 114/250, Loss: 0.0126\n",
      "Epoch 52/200, Iteration 115/250, Loss: 0.0370\n",
      "Epoch 52/200, Iteration 116/250, Loss: 0.0233\n",
      "Epoch 52/200, Iteration 117/250, Loss: 0.0264\n",
      "Epoch 52/200, Iteration 118/250, Loss: 0.0289\n",
      "Epoch 52/200, Iteration 119/250, Loss: 0.0146\n",
      "Epoch 52/200, Iteration 120/250, Loss: 0.0198\n",
      "Epoch 52/200, Iteration 121/250, Loss: 0.0091\n",
      "Epoch 52/200, Iteration 122/250, Loss: 0.0183\n",
      "Epoch 52/200, Iteration 123/250, Loss: 0.0075\n",
      "Epoch 52/200, Iteration 124/250, Loss: 0.0118\n",
      "Epoch 52/200, Iteration 125/250, Loss: 0.0074\n",
      "Epoch 52/200, Iteration 126/250, Loss: 0.0176\n",
      "Epoch 52/200, Iteration 127/250, Loss: 0.0125\n",
      "Epoch 52/200, Iteration 128/250, Loss: 0.0088\n",
      "Epoch 52/200, Iteration 129/250, Loss: 0.0083\n",
      "Epoch 52/200, Iteration 130/250, Loss: 0.0096\n",
      "Epoch 52/200, Iteration 131/250, Loss: 0.0123\n",
      "Epoch 52/200, Iteration 132/250, Loss: 0.0143\n",
      "Epoch 52/200, Iteration 133/250, Loss: 0.0232\n",
      "Epoch 52/200, Iteration 134/250, Loss: 0.0112\n",
      "Epoch 52/200, Iteration 135/250, Loss: 0.0092\n",
      "Epoch 52/200, Iteration 136/250, Loss: 0.0220\n",
      "Epoch 52/200, Iteration 137/250, Loss: 0.0504\n",
      "Epoch 52/200, Iteration 138/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 139/250, Loss: 0.0180\n",
      "Epoch 52/200, Iteration 140/250, Loss: 0.0179\n",
      "Epoch 52/200, Iteration 141/250, Loss: 0.0204\n",
      "Epoch 52/200, Iteration 142/250, Loss: 0.0069\n",
      "Epoch 52/200, Iteration 143/250, Loss: 0.0093\n",
      "Epoch 52/200, Iteration 144/250, Loss: 0.0176\n",
      "Epoch 52/200, Iteration 145/250, Loss: 0.0335\n",
      "Epoch 52/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 52/200, Iteration 147/250, Loss: 0.0609\n",
      "Epoch 52/200, Iteration 148/250, Loss: 0.0200\n",
      "Epoch 52/200, Iteration 149/250, Loss: 0.0179\n",
      "Epoch 52/200, Iteration 150/250, Loss: 0.0156\n",
      "Epoch 52/200, Iteration 151/250, Loss: 0.0232\n",
      "Epoch 52/200, Iteration 152/250, Loss: 0.0247\n",
      "Epoch 52/200, Iteration 153/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 154/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 155/250, Loss: 0.0077\n",
      "Epoch 52/200, Iteration 156/250, Loss: 0.0130\n",
      "Epoch 52/200, Iteration 157/250, Loss: 0.0152\n",
      "Epoch 52/200, Iteration 158/250, Loss: 0.0145\n",
      "Epoch 52/200, Iteration 159/250, Loss: 0.0196\n",
      "Epoch 52/200, Iteration 160/250, Loss: 0.0073\n",
      "Epoch 52/200, Iteration 161/250, Loss: 0.0290\n",
      "Epoch 52/200, Iteration 162/250, Loss: 0.0124\n",
      "Epoch 52/200, Iteration 163/250, Loss: 0.0109\n",
      "Epoch 52/200, Iteration 164/250, Loss: 0.0257\n",
      "Epoch 52/200, Iteration 165/250, Loss: 0.0186\n",
      "Epoch 52/200, Iteration 166/250, Loss: 0.0096\n",
      "Epoch 52/200, Iteration 167/250, Loss: 0.0142\n",
      "Epoch 52/200, Iteration 168/250, Loss: 0.0123\n",
      "Epoch 52/200, Iteration 169/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 170/250, Loss: 0.0180\n",
      "Epoch 52/200, Iteration 171/250, Loss: 0.0231\n",
      "Epoch 52/200, Iteration 172/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 173/250, Loss: 0.0121\n",
      "Epoch 52/200, Iteration 174/250, Loss: 0.0131\n",
      "Epoch 52/200, Iteration 175/250, Loss: 0.0084\n",
      "Epoch 52/200, Iteration 176/250, Loss: 0.0138\n",
      "Epoch 52/200, Iteration 177/250, Loss: 0.0103\n",
      "Epoch 52/200, Iteration 178/250, Loss: 0.0081\n",
      "Epoch 52/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 52/200, Iteration 180/250, Loss: 0.0194\n",
      "Epoch 52/200, Iteration 181/250, Loss: 0.0128\n",
      "Epoch 52/200, Iteration 182/250, Loss: 0.0187\n",
      "Epoch 52/200, Iteration 183/250, Loss: 0.0248\n",
      "Epoch 52/200, Iteration 184/250, Loss: 0.0200\n",
      "Epoch 52/200, Iteration 185/250, Loss: 0.0421\n",
      "Epoch 52/200, Iteration 186/250, Loss: 0.0212\n",
      "Epoch 52/200, Iteration 187/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 52/200, Iteration 189/250, Loss: 0.0148\n",
      "Epoch 52/200, Iteration 190/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 192/250, Loss: 0.0139\n",
      "Epoch 52/200, Iteration 193/250, Loss: 0.0108\n",
      "Epoch 52/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 52/200, Iteration 195/250, Loss: 0.0133\n",
      "Epoch 52/200, Iteration 196/250, Loss: 0.0076\n",
      "Epoch 52/200, Iteration 197/250, Loss: 0.0097\n",
      "Epoch 52/200, Iteration 198/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 199/250, Loss: 0.0269\n",
      "Epoch 52/200, Iteration 200/250, Loss: 0.0198\n",
      "Epoch 52/200, Iteration 201/250, Loss: 0.0370\n",
      "Epoch 52/200, Iteration 202/250, Loss: 0.0063\n",
      "Epoch 52/200, Iteration 203/250, Loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Iteration 204/250, Loss: 0.0097\n",
      "Epoch 52/200, Iteration 205/250, Loss: 0.0301\n",
      "Epoch 52/200, Iteration 206/250, Loss: 0.0091\n",
      "Epoch 52/200, Iteration 207/250, Loss: 0.0090\n",
      "Epoch 52/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 209/250, Loss: 0.0122\n",
      "Epoch 52/200, Iteration 210/250, Loss: 0.0177\n",
      "Epoch 52/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 52/200, Iteration 212/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 213/250, Loss: 0.0165\n",
      "Epoch 52/200, Iteration 214/250, Loss: 0.0122\n",
      "Epoch 52/200, Iteration 215/250, Loss: 0.0101\n",
      "Epoch 52/200, Iteration 216/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 217/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 218/250, Loss: 0.0075\n",
      "Epoch 52/200, Iteration 219/250, Loss: 0.0065\n",
      "Epoch 52/200, Iteration 220/250, Loss: 0.0117\n",
      "Epoch 52/200, Iteration 221/250, Loss: 0.0233\n",
      "Epoch 52/200, Iteration 222/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 223/250, Loss: 0.0267\n",
      "Epoch 52/200, Iteration 224/250, Loss: 0.0162\n",
      "Epoch 52/200, Iteration 225/250, Loss: 0.0248\n",
      "Epoch 52/200, Iteration 226/250, Loss: 0.0145\n",
      "Epoch 52/200, Iteration 227/250, Loss: 0.0084\n",
      "Epoch 52/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 52/200, Iteration 229/250, Loss: 0.0167\n",
      "Epoch 52/200, Iteration 230/250, Loss: 0.0208\n",
      "Epoch 52/200, Iteration 231/250, Loss: 0.0098\n",
      "Epoch 52/200, Iteration 232/250, Loss: 0.0076\n",
      "Epoch 52/200, Iteration 233/250, Loss: 0.0208\n",
      "Epoch 52/200, Iteration 234/250, Loss: 0.0205\n",
      "Epoch 52/200, Iteration 235/250, Loss: 0.0329\n",
      "Epoch 52/200, Iteration 236/250, Loss: 0.0236\n",
      "Epoch 52/200, Iteration 237/250, Loss: 0.0136\n",
      "Epoch 52/200, Iteration 238/250, Loss: 0.0173\n",
      "Epoch 52/200, Iteration 239/250, Loss: 0.0070\n",
      "Epoch 52/200, Iteration 240/250, Loss: 0.0149\n",
      "Epoch 52/200, Iteration 241/250, Loss: 0.0105\n",
      "Epoch 52/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 52/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 52/200, Iteration 244/250, Loss: 0.0095\n",
      "Epoch 52/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 52/200, Iteration 246/250, Loss: 0.0402\n",
      "Epoch 52/200, Iteration 247/250, Loss: 0.0143\n",
      "Epoch 52/200, Iteration 248/250, Loss: 0.0167\n",
      "Epoch 52/200, Iteration 249/250, Loss: 0.0183\n",
      "Epoch 52/200, Iteration 250/250, Loss: 0.0107\n",
      "Train Error: \n",
      " Accuracy: 82.41%, Avg loss: 0.007299, MRE: 0.592435 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.007286, MRE: 0.811198 \n",
      "\n",
      "Epoch 53/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 53/200, Iteration 2/250, Loss: 0.0239\n",
      "Epoch 53/200, Iteration 3/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 4/250, Loss: 0.0073\n",
      "Epoch 53/200, Iteration 5/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 6/250, Loss: 0.0161\n",
      "Epoch 53/200, Iteration 7/250, Loss: 0.0275\n",
      "Epoch 53/200, Iteration 8/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 9/250, Loss: 0.0155\n",
      "Epoch 53/200, Iteration 10/250, Loss: 0.0181\n",
      "Epoch 53/200, Iteration 11/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 12/250, Loss: 0.0195\n",
      "Epoch 53/200, Iteration 13/250, Loss: 0.0170\n",
      "Epoch 53/200, Iteration 14/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 15/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 16/250, Loss: 0.0286\n",
      "Epoch 53/200, Iteration 17/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 18/250, Loss: 0.0295\n",
      "Epoch 53/200, Iteration 19/250, Loss: 0.0113\n",
      "Epoch 53/200, Iteration 20/250, Loss: 0.0118\n",
      "Epoch 53/200, Iteration 21/250, Loss: 0.0084\n",
      "Epoch 53/200, Iteration 22/250, Loss: 0.0261\n",
      "Epoch 53/200, Iteration 23/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 24/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 25/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 26/250, Loss: 0.0159\n",
      "Epoch 53/200, Iteration 27/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 28/250, Loss: 0.0134\n",
      "Epoch 53/200, Iteration 29/250, Loss: 0.0116\n",
      "Epoch 53/200, Iteration 30/250, Loss: 0.0215\n",
      "Epoch 53/200, Iteration 31/250, Loss: 0.0355\n",
      "Epoch 53/200, Iteration 32/250, Loss: 0.0079\n",
      "Epoch 53/200, Iteration 33/250, Loss: 0.0108\n",
      "Epoch 53/200, Iteration 34/250, Loss: 0.0091\n",
      "Epoch 53/200, Iteration 35/250, Loss: 0.0165\n",
      "Epoch 53/200, Iteration 36/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 37/250, Loss: 0.0183\n",
      "Epoch 53/200, Iteration 38/250, Loss: 0.0129\n",
      "Epoch 53/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 40/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 41/250, Loss: 0.0261\n",
      "Epoch 53/200, Iteration 42/250, Loss: 0.0091\n",
      "Epoch 53/200, Iteration 43/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 44/250, Loss: 0.0293\n",
      "Epoch 53/200, Iteration 45/250, Loss: 0.0232\n",
      "Epoch 53/200, Iteration 46/250, Loss: 0.0276\n",
      "Epoch 53/200, Iteration 47/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 48/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 49/250, Loss: 0.0139\n",
      "Epoch 53/200, Iteration 50/250, Loss: 0.0108\n",
      "Epoch 53/200, Iteration 51/250, Loss: 0.0101\n",
      "Epoch 53/200, Iteration 52/250, Loss: 0.0181\n",
      "Epoch 53/200, Iteration 53/250, Loss: 0.0075\n",
      "Epoch 53/200, Iteration 54/250, Loss: 0.0180\n",
      "Epoch 53/200, Iteration 55/250, Loss: 0.0186\n",
      "Epoch 53/200, Iteration 56/250, Loss: 0.0078\n",
      "Epoch 53/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 53/200, Iteration 58/250, Loss: 0.0172\n",
      "Epoch 53/200, Iteration 59/250, Loss: 0.0260\n",
      "Epoch 53/200, Iteration 60/250, Loss: 0.0148\n",
      "Epoch 53/200, Iteration 61/250, Loss: 0.0088\n",
      "Epoch 53/200, Iteration 62/250, Loss: 0.0170\n",
      "Epoch 53/200, Iteration 63/250, Loss: 0.0173\n",
      "Epoch 53/200, Iteration 64/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 53/200, Iteration 66/250, Loss: 0.0201\n",
      "Epoch 53/200, Iteration 67/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 68/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 69/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 70/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 71/250, Loss: 0.0193\n",
      "Epoch 53/200, Iteration 72/250, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 73/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 74/250, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 75/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 76/250, Loss: 0.0197\n",
      "Epoch 53/200, Iteration 77/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 78/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 79/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 80/250, Loss: 0.0172\n",
      "Epoch 53/200, Iteration 81/250, Loss: 0.0084\n",
      "Epoch 53/200, Iteration 82/250, Loss: 0.0217\n",
      "Epoch 53/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 53/200, Iteration 84/250, Loss: 0.0081\n",
      "Epoch 53/200, Iteration 85/250, Loss: 0.0295\n",
      "Epoch 53/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 87/250, Loss: 0.0079\n",
      "Epoch 53/200, Iteration 88/250, Loss: 0.0154\n",
      "Epoch 53/200, Iteration 89/250, Loss: 0.0107\n",
      "Epoch 53/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 91/250, Loss: 0.0214\n",
      "Epoch 53/200, Iteration 92/250, Loss: 0.0202\n",
      "Epoch 53/200, Iteration 93/250, Loss: 0.0402\n",
      "Epoch 53/200, Iteration 94/250, Loss: 0.0084\n",
      "Epoch 53/200, Iteration 95/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 96/250, Loss: 0.0224\n",
      "Epoch 53/200, Iteration 97/250, Loss: 0.0080\n",
      "Epoch 53/200, Iteration 98/250, Loss: 0.0126\n",
      "Epoch 53/200, Iteration 99/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 100/250, Loss: 0.0147\n",
      "Epoch 53/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 53/200, Iteration 102/250, Loss: 0.0175\n",
      "Epoch 53/200, Iteration 103/250, Loss: 0.0140\n",
      "Epoch 53/200, Iteration 104/250, Loss: 0.0283\n",
      "Epoch 53/200, Iteration 105/250, Loss: 0.0151\n",
      "Epoch 53/200, Iteration 106/250, Loss: 0.0162\n",
      "Epoch 53/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 108/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 109/250, Loss: 0.0148\n",
      "Epoch 53/200, Iteration 110/250, Loss: 0.0089\n",
      "Epoch 53/200, Iteration 111/250, Loss: 0.0175\n",
      "Epoch 53/200, Iteration 112/250, Loss: 0.0190\n",
      "Epoch 53/200, Iteration 113/250, Loss: 0.0128\n",
      "Epoch 53/200, Iteration 114/250, Loss: 0.0152\n",
      "Epoch 53/200, Iteration 115/250, Loss: 0.0144\n",
      "Epoch 53/200, Iteration 116/250, Loss: 0.0212\n",
      "Epoch 53/200, Iteration 117/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 118/250, Loss: 0.0262\n",
      "Epoch 53/200, Iteration 119/250, Loss: 0.0098\n",
      "Epoch 53/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 53/200, Iteration 121/250, Loss: 0.0173\n",
      "Epoch 53/200, Iteration 122/250, Loss: 0.0170\n",
      "Epoch 53/200, Iteration 123/250, Loss: 0.0196\n",
      "Epoch 53/200, Iteration 124/250, Loss: 0.0174\n",
      "Epoch 53/200, Iteration 125/250, Loss: 0.0202\n",
      "Epoch 53/200, Iteration 126/250, Loss: 0.0206\n",
      "Epoch 53/200, Iteration 127/250, Loss: 0.0176\n",
      "Epoch 53/200, Iteration 128/250, Loss: 0.0385\n",
      "Epoch 53/200, Iteration 129/250, Loss: 0.0243\n",
      "Epoch 53/200, Iteration 130/250, Loss: 0.0145\n",
      "Epoch 53/200, Iteration 131/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 132/250, Loss: 0.0107\n",
      "Epoch 53/200, Iteration 133/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 134/250, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 135/250, Loss: 0.0143\n",
      "Epoch 53/200, Iteration 136/250, Loss: 0.0098\n",
      "Epoch 53/200, Iteration 137/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 138/250, Loss: 0.0069\n",
      "Epoch 53/200, Iteration 139/250, Loss: 0.0234\n",
      "Epoch 53/200, Iteration 140/250, Loss: 0.0272\n",
      "Epoch 53/200, Iteration 141/250, Loss: 0.0518\n",
      "Epoch 53/200, Iteration 142/250, Loss: 0.0114\n",
      "Epoch 53/200, Iteration 143/250, Loss: 0.0176\n",
      "Epoch 53/200, Iteration 144/250, Loss: 0.0154\n",
      "Epoch 53/200, Iteration 145/250, Loss: 0.0155\n",
      "Epoch 53/200, Iteration 146/250, Loss: 0.0334\n",
      "Epoch 53/200, Iteration 147/250, Loss: 0.0102\n",
      "Epoch 53/200, Iteration 148/250, Loss: 0.0419\n",
      "Epoch 53/200, Iteration 149/250, Loss: 0.0632\n",
      "Epoch 53/200, Iteration 150/250, Loss: 0.0664\n",
      "Epoch 53/200, Iteration 151/250, Loss: 0.0275\n",
      "Epoch 53/200, Iteration 152/250, Loss: 0.0147\n",
      "Epoch 53/200, Iteration 153/250, Loss: 0.0104\n",
      "Epoch 53/200, Iteration 154/250, Loss: 0.0301\n",
      "Epoch 53/200, Iteration 155/250, Loss: 0.0239\n",
      "Epoch 53/200, Iteration 156/250, Loss: 0.0217\n",
      "Epoch 53/200, Iteration 157/250, Loss: 0.0180\n",
      "Epoch 53/200, Iteration 158/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 159/250, Loss: 0.0137\n",
      "Epoch 53/200, Iteration 160/250, Loss: 0.0165\n",
      "Epoch 53/200, Iteration 161/250, Loss: 0.0104\n",
      "Epoch 53/200, Iteration 162/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Iteration 163/250, Loss: 0.0134\n",
      "Epoch 53/200, Iteration 164/250, Loss: 0.0198\n",
      "Epoch 53/200, Iteration 165/250, Loss: 0.0165\n",
      "Epoch 53/200, Iteration 166/250, Loss: 0.0327\n",
      "Epoch 53/200, Iteration 167/250, Loss: 0.0179\n",
      "Epoch 53/200, Iteration 168/250, Loss: 0.0208\n",
      "Epoch 53/200, Iteration 169/250, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 170/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 171/250, Loss: 0.0095\n",
      "Epoch 53/200, Iteration 172/250, Loss: 0.0145\n",
      "Epoch 53/200, Iteration 173/250, Loss: 0.0161\n",
      "Epoch 53/200, Iteration 174/250, Loss: 0.0205\n",
      "Epoch 53/200, Iteration 175/250, Loss: 0.0116\n",
      "Epoch 53/200, Iteration 176/250, Loss: 0.0448\n",
      "Epoch 53/200, Iteration 177/250, Loss: 0.0185\n",
      "Epoch 53/200, Iteration 178/250, Loss: 0.0272\n",
      "Epoch 53/200, Iteration 179/250, Loss: 0.0108\n",
      "Epoch 53/200, Iteration 180/250, Loss: 0.0154\n",
      "Epoch 53/200, Iteration 181/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 53/200, Iteration 183/250, Loss: 0.0108\n",
      "Epoch 53/200, Iteration 184/250, Loss: 0.0082\n",
      "Epoch 53/200, Iteration 185/250, Loss: 0.0156\n",
      "Epoch 53/200, Iteration 186/250, Loss: 0.0233\n",
      "Epoch 53/200, Iteration 187/250, Loss: 0.0327\n",
      "Epoch 53/200, Iteration 188/250, Loss: 0.0258\n",
      "Epoch 53/200, Iteration 189/250, Loss: 0.0232\n",
      "Epoch 53/200, Iteration 190/250, Loss: 0.0183\n",
      "Epoch 53/200, Iteration 191/250, Loss: 0.0261\n",
      "Epoch 53/200, Iteration 192/250, Loss: 0.0189\n",
      "Epoch 53/200, Iteration 193/250, Loss: 0.0143\n",
      "Epoch 53/200, Iteration 194/250, Loss: 0.0175\n",
      "Epoch 53/200, Iteration 195/250, Loss: 0.0463\n",
      "Epoch 53/200, Iteration 196/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 197/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 53/200, Iteration 199/250, Loss: 0.0253\n",
      "Epoch 53/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 53/200, Iteration 202/250, Loss: 0.0121\n",
      "Epoch 53/200, Iteration 203/250, Loss: 0.0224\n",
      "Epoch 53/200, Iteration 204/250, Loss: 0.0188\n",
      "Epoch 53/200, Iteration 205/250, Loss: 0.0157\n",
      "Epoch 53/200, Iteration 206/250, Loss: 0.0189\n",
      "Epoch 53/200, Iteration 207/250, Loss: 0.0320\n",
      "Epoch 53/200, Iteration 208/250, Loss: 0.0109\n",
      "Epoch 53/200, Iteration 209/250, Loss: 0.0166\n",
      "Epoch 53/200, Iteration 210/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 211/250, Loss: 0.0129\n",
      "Epoch 53/200, Iteration 212/250, Loss: 0.0308\n",
      "Epoch 53/200, Iteration 213/250, Loss: 0.0342\n",
      "Epoch 53/200, Iteration 214/250, Loss: 0.0303\n",
      "Epoch 53/200, Iteration 215/250, Loss: 0.0253\n",
      "Epoch 53/200, Iteration 216/250, Loss: 0.0224\n",
      "Epoch 53/200, Iteration 217/250, Loss: 0.0163\n",
      "Epoch 53/200, Iteration 218/250, Loss: 0.0185\n",
      "Epoch 53/200, Iteration 219/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 220/250, Loss: 0.0148\n",
      "Epoch 53/200, Iteration 221/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 222/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 223/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 224/250, Loss: 0.0152\n",
      "Epoch 53/200, Iteration 225/250, Loss: 0.0184\n",
      "Epoch 53/200, Iteration 226/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 227/250, Loss: 0.0180\n",
      "Epoch 53/200, Iteration 228/250, Loss: 0.0145\n",
      "Epoch 53/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 230/250, Loss: 0.0399\n",
      "Epoch 53/200, Iteration 231/250, Loss: 0.0168\n",
      "Epoch 53/200, Iteration 232/250, Loss: 0.0109\n",
      "Epoch 53/200, Iteration 233/250, Loss: 0.0109\n",
      "Epoch 53/200, Iteration 234/250, Loss: 0.0214\n",
      "Epoch 53/200, Iteration 235/250, Loss: 0.0331\n",
      "Epoch 53/200, Iteration 236/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 237/250, Loss: 0.0073\n",
      "Epoch 53/200, Iteration 238/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 53/200, Iteration 240/250, Loss: 0.0089\n",
      "Epoch 53/200, Iteration 241/250, Loss: 0.0176\n",
      "Epoch 53/200, Iteration 242/250, Loss: 0.0219\n",
      "Epoch 53/200, Iteration 243/250, Loss: 0.0170\n",
      "Epoch 53/200, Iteration 244/250, Loss: 0.0138\n",
      "Epoch 53/200, Iteration 245/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 246/250, Loss: 0.0130\n",
      "Epoch 53/200, Iteration 247/250, Loss: 0.0194\n",
      "Epoch 53/200, Iteration 248/250, Loss: 0.0126\n",
      "Epoch 53/200, Iteration 249/250, Loss: 0.0089\n",
      "Epoch 53/200, Iteration 250/250, Loss: 0.0180\n",
      "Train Error: \n",
      " Accuracy: 83.05%, Avg loss: 0.007524, MRE: 0.644233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.007522, MRE: 0.981309 \n",
      "\n",
      "Epoch 54/200, Iteration 1/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 2/250, Loss: 0.0090\n",
      "Epoch 54/200, Iteration 3/250, Loss: 0.0110\n",
      "Epoch 54/200, Iteration 4/250, Loss: 0.0098\n",
      "Epoch 54/200, Iteration 5/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 6/250, Loss: 0.0135\n",
      "Epoch 54/200, Iteration 7/250, Loss: 0.0083\n",
      "Epoch 54/200, Iteration 8/250, Loss: 0.0203\n",
      "Epoch 54/200, Iteration 9/250, Loss: 0.0082\n",
      "Epoch 54/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 11/250, Loss: 0.0186\n",
      "Epoch 54/200, Iteration 12/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 13/250, Loss: 0.0280\n",
      "Epoch 54/200, Iteration 14/250, Loss: 0.0310\n",
      "Epoch 54/200, Iteration 15/250, Loss: 0.0145\n",
      "Epoch 54/200, Iteration 16/250, Loss: 0.0135\n",
      "Epoch 54/200, Iteration 17/250, Loss: 0.0081\n",
      "Epoch 54/200, Iteration 18/250, Loss: 0.0151\n",
      "Epoch 54/200, Iteration 19/250, Loss: 0.0341\n",
      "Epoch 54/200, Iteration 20/250, Loss: 0.0143\n",
      "Epoch 54/200, Iteration 21/250, Loss: 0.0418\n",
      "Epoch 54/200, Iteration 22/250, Loss: 0.0240\n",
      "Epoch 54/200, Iteration 23/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 24/250, Loss: 0.0336\n",
      "Epoch 54/200, Iteration 25/250, Loss: 0.0094\n",
      "Epoch 54/200, Iteration 26/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 27/250, Loss: 0.0175\n",
      "Epoch 54/200, Iteration 28/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 29/250, Loss: 0.0225\n",
      "Epoch 54/200, Iteration 30/250, Loss: 0.0171\n",
      "Epoch 54/200, Iteration 31/250, Loss: 0.0140\n",
      "Epoch 54/200, Iteration 32/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 33/250, Loss: 0.0201\n",
      "Epoch 54/200, Iteration 34/250, Loss: 0.0135\n",
      "Epoch 54/200, Iteration 35/250, Loss: 0.0229\n",
      "Epoch 54/200, Iteration 36/250, Loss: 0.0115\n",
      "Epoch 54/200, Iteration 37/250, Loss: 0.0134\n",
      "Epoch 54/200, Iteration 38/250, Loss: 0.0095\n",
      "Epoch 54/200, Iteration 39/250, Loss: 0.0123\n",
      "Epoch 54/200, Iteration 40/250, Loss: 0.0149\n",
      "Epoch 54/200, Iteration 41/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 42/250, Loss: 0.0104\n",
      "Epoch 54/200, Iteration 43/250, Loss: 0.0147\n",
      "Epoch 54/200, Iteration 44/250, Loss: 0.0131\n",
      "Epoch 54/200, Iteration 45/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 46/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 47/250, Loss: 0.0061\n",
      "Epoch 54/200, Iteration 48/250, Loss: 0.0127\n",
      "Epoch 54/200, Iteration 49/250, Loss: 0.0181\n",
      "Epoch 54/200, Iteration 50/250, Loss: 0.0098\n",
      "Epoch 54/200, Iteration 51/250, Loss: 0.0160\n",
      "Epoch 54/200, Iteration 52/250, Loss: 0.0179\n",
      "Epoch 54/200, Iteration 53/250, Loss: 0.0196\n",
      "Epoch 54/200, Iteration 54/250, Loss: 0.0080\n",
      "Epoch 54/200, Iteration 55/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 56/250, Loss: 0.0170\n",
      "Epoch 54/200, Iteration 57/250, Loss: 0.0190\n",
      "Epoch 54/200, Iteration 58/250, Loss: 0.0179\n",
      "Epoch 54/200, Iteration 59/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 60/250, Loss: 0.0138\n",
      "Epoch 54/200, Iteration 61/250, Loss: 0.0082\n",
      "Epoch 54/200, Iteration 62/250, Loss: 0.0176\n",
      "Epoch 54/200, Iteration 63/250, Loss: 0.0334\n",
      "Epoch 54/200, Iteration 64/250, Loss: 0.0170\n",
      "Epoch 54/200, Iteration 65/250, Loss: 0.0366\n",
      "Epoch 54/200, Iteration 66/250, Loss: 0.0394\n",
      "Epoch 54/200, Iteration 67/250, Loss: 0.0178\n",
      "Epoch 54/200, Iteration 68/250, Loss: 0.0376\n",
      "Epoch 54/200, Iteration 69/250, Loss: 0.0275\n",
      "Epoch 54/200, Iteration 70/250, Loss: 0.0226\n",
      "Epoch 54/200, Iteration 71/250, Loss: 0.0076\n",
      "Epoch 54/200, Iteration 72/250, Loss: 0.0077\n",
      "Epoch 54/200, Iteration 73/250, Loss: 0.0129\n",
      "Epoch 54/200, Iteration 74/250, Loss: 0.0363\n",
      "Epoch 54/200, Iteration 75/250, Loss: 0.0144\n",
      "Epoch 54/200, Iteration 76/250, Loss: 0.0148\n",
      "Epoch 54/200, Iteration 77/250, Loss: 0.0059\n",
      "Epoch 54/200, Iteration 78/250, Loss: 0.0270\n",
      "Epoch 54/200, Iteration 79/250, Loss: 0.0095\n",
      "Epoch 54/200, Iteration 80/250, Loss: 0.0111\n",
      "Epoch 54/200, Iteration 81/250, Loss: 0.0442\n",
      "Epoch 54/200, Iteration 82/250, Loss: 0.0070\n",
      "Epoch 54/200, Iteration 83/250, Loss: 0.0112\n",
      "Epoch 54/200, Iteration 84/250, Loss: 0.0169\n",
      "Epoch 54/200, Iteration 85/250, Loss: 0.0076\n",
      "Epoch 54/200, Iteration 86/250, Loss: 0.0235\n",
      "Epoch 54/200, Iteration 87/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 88/250, Loss: 0.0149\n",
      "Epoch 54/200, Iteration 89/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 90/250, Loss: 0.0150\n",
      "Epoch 54/200, Iteration 91/250, Loss: 0.0117\n",
      "Epoch 54/200, Iteration 92/250, Loss: 0.0189\n",
      "Epoch 54/200, Iteration 93/250, Loss: 0.0220\n",
      "Epoch 54/200, Iteration 94/250, Loss: 0.0206\n",
      "Epoch 54/200, Iteration 95/250, Loss: 0.0201\n",
      "Epoch 54/200, Iteration 96/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 97/250, Loss: 0.0176\n",
      "Epoch 54/200, Iteration 98/250, Loss: 0.0145\n",
      "Epoch 54/200, Iteration 99/250, Loss: 0.0141\n",
      "Epoch 54/200, Iteration 100/250, Loss: 0.0284\n",
      "Epoch 54/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 54/200, Iteration 102/250, Loss: 0.0377\n",
      "Epoch 54/200, Iteration 103/250, Loss: 0.0110\n",
      "Epoch 54/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 54/200, Iteration 105/250, Loss: 0.0100\n",
      "Epoch 54/200, Iteration 106/250, Loss: 0.0131\n",
      "Epoch 54/200, Iteration 107/250, Loss: 0.0212\n",
      "Epoch 54/200, Iteration 108/250, Loss: 0.0183\n",
      "Epoch 54/200, Iteration 109/250, Loss: 0.0166\n",
      "Epoch 54/200, Iteration 110/250, Loss: 0.0090\n",
      "Epoch 54/200, Iteration 111/250, Loss: 0.0252\n",
      "Epoch 54/200, Iteration 112/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 113/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 114/250, Loss: 0.0088\n",
      "Epoch 54/200, Iteration 115/250, Loss: 0.0188\n",
      "Epoch 54/200, Iteration 116/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 117/250, Loss: 0.0232\n",
      "Epoch 54/200, Iteration 118/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 119/250, Loss: 0.0196\n",
      "Epoch 54/200, Iteration 120/250, Loss: 0.0140\n",
      "Epoch 54/200, Iteration 121/250, Loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200, Iteration 122/250, Loss: 0.0265\n",
      "Epoch 54/200, Iteration 123/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 124/250, Loss: 0.0192\n",
      "Epoch 54/200, Iteration 125/250, Loss: 0.0105\n",
      "Epoch 54/200, Iteration 126/250, Loss: 0.0275\n",
      "Epoch 54/200, Iteration 127/250, Loss: 0.0175\n",
      "Epoch 54/200, Iteration 128/250, Loss: 0.0289\n",
      "Epoch 54/200, Iteration 129/250, Loss: 0.0387\n",
      "Epoch 54/200, Iteration 130/250, Loss: 0.0143\n",
      "Epoch 54/200, Iteration 131/250, Loss: 0.0173\n",
      "Epoch 54/200, Iteration 132/250, Loss: 0.0266\n",
      "Epoch 54/200, Iteration 133/250, Loss: 0.0246\n",
      "Epoch 54/200, Iteration 134/250, Loss: 0.0159\n",
      "Epoch 54/200, Iteration 135/250, Loss: 0.0178\n",
      "Epoch 54/200, Iteration 136/250, Loss: 0.0221\n",
      "Epoch 54/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 54/200, Iteration 138/250, Loss: 0.0148\n",
      "Epoch 54/200, Iteration 139/250, Loss: 0.0116\n",
      "Epoch 54/200, Iteration 140/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 141/250, Loss: 0.0268\n",
      "Epoch 54/200, Iteration 142/250, Loss: 0.0242\n",
      "Epoch 54/200, Iteration 143/250, Loss: 0.0283\n",
      "Epoch 54/200, Iteration 144/250, Loss: 0.0096\n",
      "Epoch 54/200, Iteration 145/250, Loss: 0.0291\n",
      "Epoch 54/200, Iteration 146/250, Loss: 0.0462\n",
      "Epoch 54/200, Iteration 147/250, Loss: 0.0132\n",
      "Epoch 54/200, Iteration 148/250, Loss: 0.0191\n",
      "Epoch 54/200, Iteration 149/250, Loss: 0.0188\n",
      "Epoch 54/200, Iteration 150/250, Loss: 0.0219\n",
      "Epoch 54/200, Iteration 151/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 54/200, Iteration 153/250, Loss: 0.0254\n",
      "Epoch 54/200, Iteration 154/250, Loss: 0.0247\n",
      "Epoch 54/200, Iteration 155/250, Loss: 0.0139\n",
      "Epoch 54/200, Iteration 156/250, Loss: 0.0300\n",
      "Epoch 54/200, Iteration 157/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 158/250, Loss: 0.0281\n",
      "Epoch 54/200, Iteration 159/250, Loss: 0.0097\n",
      "Epoch 54/200, Iteration 160/250, Loss: 0.0126\n",
      "Epoch 54/200, Iteration 161/250, Loss: 0.0235\n",
      "Epoch 54/200, Iteration 162/250, Loss: 0.0197\n",
      "Epoch 54/200, Iteration 163/250, Loss: 0.0153\n",
      "Epoch 54/200, Iteration 164/250, Loss: 0.0077\n",
      "Epoch 54/200, Iteration 165/250, Loss: 0.0137\n",
      "Epoch 54/200, Iteration 166/250, Loss: 0.0105\n",
      "Epoch 54/200, Iteration 167/250, Loss: 0.0141\n",
      "Epoch 54/200, Iteration 168/250, Loss: 0.0151\n",
      "Epoch 54/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 170/250, Loss: 0.0169\n",
      "Epoch 54/200, Iteration 171/250, Loss: 0.0171\n",
      "Epoch 54/200, Iteration 172/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 173/250, Loss: 0.0218\n",
      "Epoch 54/200, Iteration 174/250, Loss: 0.0079\n",
      "Epoch 54/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 176/250, Loss: 0.0199\n",
      "Epoch 54/200, Iteration 177/250, Loss: 0.0174\n",
      "Epoch 54/200, Iteration 178/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 54/200, Iteration 180/250, Loss: 0.0142\n",
      "Epoch 54/200, Iteration 181/250, Loss: 0.0132\n",
      "Epoch 54/200, Iteration 182/250, Loss: 0.0335\n",
      "Epoch 54/200, Iteration 183/250, Loss: 0.0133\n",
      "Epoch 54/200, Iteration 184/250, Loss: 0.0220\n",
      "Epoch 54/200, Iteration 185/250, Loss: 0.0196\n",
      "Epoch 54/200, Iteration 186/250, Loss: 0.0163\n",
      "Epoch 54/200, Iteration 187/250, Loss: 0.0134\n",
      "Epoch 54/200, Iteration 188/250, Loss: 0.0078\n",
      "Epoch 54/200, Iteration 189/250, Loss: 0.0249\n",
      "Epoch 54/200, Iteration 190/250, Loss: 0.0220\n",
      "Epoch 54/200, Iteration 191/250, Loss: 0.0155\n",
      "Epoch 54/200, Iteration 192/250, Loss: 0.0246\n",
      "Epoch 54/200, Iteration 193/250, Loss: 0.0174\n",
      "Epoch 54/200, Iteration 194/250, Loss: 0.0076\n",
      "Epoch 54/200, Iteration 195/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 196/250, Loss: 0.0224\n",
      "Epoch 54/200, Iteration 197/250, Loss: 0.0305\n",
      "Epoch 54/200, Iteration 198/250, Loss: 0.0106\n",
      "Epoch 54/200, Iteration 199/250, Loss: 0.0287\n",
      "Epoch 54/200, Iteration 200/250, Loss: 0.0131\n",
      "Epoch 54/200, Iteration 201/250, Loss: 0.0167\n",
      "Epoch 54/200, Iteration 202/250, Loss: 0.0155\n",
      "Epoch 54/200, Iteration 203/250, Loss: 0.0175\n",
      "Epoch 54/200, Iteration 204/250, Loss: 0.0106\n",
      "Epoch 54/200, Iteration 205/250, Loss: 0.0103\n",
      "Epoch 54/200, Iteration 206/250, Loss: 0.0200\n",
      "Epoch 54/200, Iteration 207/250, Loss: 0.0137\n",
      "Epoch 54/200, Iteration 208/250, Loss: 0.0278\n",
      "Epoch 54/200, Iteration 209/250, Loss: 0.0202\n",
      "Epoch 54/200, Iteration 210/250, Loss: 0.0073\n",
      "Epoch 54/200, Iteration 211/250, Loss: 0.0110\n",
      "Epoch 54/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 54/200, Iteration 213/250, Loss: 0.0170\n",
      "Epoch 54/200, Iteration 214/250, Loss: 0.0228\n",
      "Epoch 54/200, Iteration 215/250, Loss: 0.0112\n",
      "Epoch 54/200, Iteration 216/250, Loss: 0.0136\n",
      "Epoch 54/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 218/250, Loss: 0.0103\n",
      "Epoch 54/200, Iteration 219/250, Loss: 0.0216\n",
      "Epoch 54/200, Iteration 220/250, Loss: 0.0071\n",
      "Epoch 54/200, Iteration 221/250, Loss: 0.0317\n",
      "Epoch 54/200, Iteration 222/250, Loss: 0.0179\n",
      "Epoch 54/200, Iteration 223/250, Loss: 0.0106\n",
      "Epoch 54/200, Iteration 224/250, Loss: 0.0066\n",
      "Epoch 54/200, Iteration 225/250, Loss: 0.0245\n",
      "Epoch 54/200, Iteration 226/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 227/250, Loss: 0.0092\n",
      "Epoch 54/200, Iteration 228/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 229/250, Loss: 0.0095\n",
      "Epoch 54/200, Iteration 230/250, Loss: 0.0077\n",
      "Epoch 54/200, Iteration 231/250, Loss: 0.0136\n",
      "Epoch 54/200, Iteration 232/250, Loss: 0.0111\n",
      "Epoch 54/200, Iteration 233/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 234/250, Loss: 0.0265\n",
      "Epoch 54/200, Iteration 235/250, Loss: 0.0285\n",
      "Epoch 54/200, Iteration 236/250, Loss: 0.0431\n",
      "Epoch 54/200, Iteration 237/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 238/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 239/250, Loss: 0.0285\n",
      "Epoch 54/200, Iteration 240/250, Loss: 0.0348\n",
      "Epoch 54/200, Iteration 241/250, Loss: 0.0127\n",
      "Epoch 54/200, Iteration 242/250, Loss: 0.0160\n",
      "Epoch 54/200, Iteration 243/250, Loss: 0.0391\n",
      "Epoch 54/200, Iteration 244/250, Loss: 0.0134\n",
      "Epoch 54/200, Iteration 245/250, Loss: 0.0141\n",
      "Epoch 54/200, Iteration 246/250, Loss: 0.0092\n",
      "Epoch 54/200, Iteration 247/250, Loss: 0.0349\n",
      "Epoch 54/200, Iteration 248/250, Loss: 0.0172\n",
      "Epoch 54/200, Iteration 249/250, Loss: 0.0194\n",
      "Epoch 54/200, Iteration 250/250, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 94.81%, Avg loss: 0.008493, MRE: 0.758674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.008460, MRE: 1.344874 \n",
      "\n",
      "Epoch 55/200, Iteration 1/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 2/250, Loss: 0.0180\n",
      "Epoch 55/200, Iteration 3/250, Loss: 0.0090\n",
      "Epoch 55/200, Iteration 4/250, Loss: 0.0099\n",
      "Epoch 55/200, Iteration 5/250, Loss: 0.0091\n",
      "Epoch 55/200, Iteration 6/250, Loss: 0.0145\n",
      "Epoch 55/200, Iteration 7/250, Loss: 0.0105\n",
      "Epoch 55/200, Iteration 8/250, Loss: 0.0127\n",
      "Epoch 55/200, Iteration 9/250, Loss: 0.0201\n",
      "Epoch 55/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 55/200, Iteration 11/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 12/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 13/250, Loss: 0.0091\n",
      "Epoch 55/200, Iteration 14/250, Loss: 0.0093\n",
      "Epoch 55/200, Iteration 15/250, Loss: 0.0154\n",
      "Epoch 55/200, Iteration 16/250, Loss: 0.0080\n",
      "Epoch 55/200, Iteration 17/250, Loss: 0.0129\n",
      "Epoch 55/200, Iteration 18/250, Loss: 0.0157\n",
      "Epoch 55/200, Iteration 19/250, Loss: 0.0091\n",
      "Epoch 55/200, Iteration 20/250, Loss: 0.0244\n",
      "Epoch 55/200, Iteration 21/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 22/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 23/250, Loss: 0.0077\n",
      "Epoch 55/200, Iteration 24/250, Loss: 0.0162\n",
      "Epoch 55/200, Iteration 25/250, Loss: 0.0082\n",
      "Epoch 55/200, Iteration 26/250, Loss: 0.0149\n",
      "Epoch 55/200, Iteration 27/250, Loss: 0.0117\n",
      "Epoch 55/200, Iteration 28/250, Loss: 0.0259\n",
      "Epoch 55/200, Iteration 29/250, Loss: 0.0159\n",
      "Epoch 55/200, Iteration 30/250, Loss: 0.0203\n",
      "Epoch 55/200, Iteration 31/250, Loss: 0.0063\n",
      "Epoch 55/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 33/250, Loss: 0.0098\n",
      "Epoch 55/200, Iteration 34/250, Loss: 0.0161\n",
      "Epoch 55/200, Iteration 35/250, Loss: 0.0374\n",
      "Epoch 55/200, Iteration 36/250, Loss: 0.0262\n",
      "Epoch 55/200, Iteration 37/250, Loss: 0.0097\n",
      "Epoch 55/200, Iteration 38/250, Loss: 0.0119\n",
      "Epoch 55/200, Iteration 39/250, Loss: 0.0117\n",
      "Epoch 55/200, Iteration 40/250, Loss: 0.0141\n",
      "Epoch 55/200, Iteration 41/250, Loss: 0.0150\n",
      "Epoch 55/200, Iteration 42/250, Loss: 0.0220\n",
      "Epoch 55/200, Iteration 43/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 44/250, Loss: 0.0217\n",
      "Epoch 55/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 55/200, Iteration 46/250, Loss: 0.0113\n",
      "Epoch 55/200, Iteration 47/250, Loss: 0.0189\n",
      "Epoch 55/200, Iteration 48/250, Loss: 0.0269\n",
      "Epoch 55/200, Iteration 49/250, Loss: 0.0226\n",
      "Epoch 55/200, Iteration 50/250, Loss: 0.0084\n",
      "Epoch 55/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 55/200, Iteration 52/250, Loss: 0.0224\n",
      "Epoch 55/200, Iteration 53/250, Loss: 0.0157\n",
      "Epoch 55/200, Iteration 54/250, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 55/250, Loss: 0.0098\n",
      "Epoch 55/200, Iteration 56/250, Loss: 0.0179\n",
      "Epoch 55/200, Iteration 57/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 58/250, Loss: 0.0175\n",
      "Epoch 55/200, Iteration 59/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 60/250, Loss: 0.0145\n",
      "Epoch 55/200, Iteration 61/250, Loss: 0.0216\n",
      "Epoch 55/200, Iteration 62/250, Loss: 0.0151\n",
      "Epoch 55/200, Iteration 63/250, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Iteration 64/250, Loss: 0.0170\n",
      "Epoch 55/200, Iteration 65/250, Loss: 0.0071\n",
      "Epoch 55/200, Iteration 66/250, Loss: 0.0078\n",
      "Epoch 55/200, Iteration 67/250, Loss: 0.0194\n",
      "Epoch 55/200, Iteration 68/250, Loss: 0.0189\n",
      "Epoch 55/200, Iteration 69/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 70/250, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 55/200, Iteration 72/250, Loss: 0.0108\n",
      "Epoch 55/200, Iteration 73/250, Loss: 0.0181\n",
      "Epoch 55/200, Iteration 74/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 76/250, Loss: 0.0069\n",
      "Epoch 55/200, Iteration 77/250, Loss: 0.0073\n",
      "Epoch 55/200, Iteration 78/250, Loss: 0.0127\n",
      "Epoch 55/200, Iteration 79/250, Loss: 0.0129\n",
      "Epoch 55/200, Iteration 80/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 55/200, Iteration 82/250, Loss: 0.0178\n",
      "Epoch 55/200, Iteration 83/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 84/250, Loss: 0.0194\n",
      "Epoch 55/200, Iteration 85/250, Loss: 0.0103\n",
      "Epoch 55/200, Iteration 86/250, Loss: 0.0131\n",
      "Epoch 55/200, Iteration 87/250, Loss: 0.0085\n",
      "Epoch 55/200, Iteration 88/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 89/250, Loss: 0.0168\n",
      "Epoch 55/200, Iteration 90/250, Loss: 0.0096\n",
      "Epoch 55/200, Iteration 91/250, Loss: 0.0118\n",
      "Epoch 55/200, Iteration 92/250, Loss: 0.0304\n",
      "Epoch 55/200, Iteration 93/250, Loss: 0.0134\n",
      "Epoch 55/200, Iteration 94/250, Loss: 0.0284\n",
      "Epoch 55/200, Iteration 95/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 96/250, Loss: 0.0095\n",
      "Epoch 55/200, Iteration 97/250, Loss: 0.0231\n",
      "Epoch 55/200, Iteration 98/250, Loss: 0.0405\n",
      "Epoch 55/200, Iteration 99/250, Loss: 0.0254\n",
      "Epoch 55/200, Iteration 100/250, Loss: 0.0119\n",
      "Epoch 55/200, Iteration 101/250, Loss: 0.0090\n",
      "Epoch 55/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 55/200, Iteration 103/250, Loss: 0.0126\n",
      "Epoch 55/200, Iteration 104/250, Loss: 0.0090\n",
      "Epoch 55/200, Iteration 105/250, Loss: 0.0286\n",
      "Epoch 55/200, Iteration 106/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 55/200, Iteration 108/250, Loss: 0.0236\n",
      "Epoch 55/200, Iteration 109/250, Loss: 0.0077\n",
      "Epoch 55/200, Iteration 110/250, Loss: 0.0088\n",
      "Epoch 55/200, Iteration 111/250, Loss: 0.0121\n",
      "Epoch 55/200, Iteration 112/250, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 113/250, Loss: 0.0093\n",
      "Epoch 55/200, Iteration 114/250, Loss: 0.0124\n",
      "Epoch 55/200, Iteration 115/250, Loss: 0.0406\n",
      "Epoch 55/200, Iteration 116/250, Loss: 0.0135\n",
      "Epoch 55/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 55/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 119/250, Loss: 0.0155\n",
      "Epoch 55/200, Iteration 120/250, Loss: 0.0104\n",
      "Epoch 55/200, Iteration 121/250, Loss: 0.0108\n",
      "Epoch 55/200, Iteration 122/250, Loss: 0.0295\n",
      "Epoch 55/200, Iteration 123/250, Loss: 0.0158\n",
      "Epoch 55/200, Iteration 124/250, Loss: 0.0226\n",
      "Epoch 55/200, Iteration 125/250, Loss: 0.0154\n",
      "Epoch 55/200, Iteration 126/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 127/250, Loss: 0.0094\n",
      "Epoch 55/200, Iteration 128/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 129/250, Loss: 0.0112\n",
      "Epoch 55/200, Iteration 130/250, Loss: 0.0111\n",
      "Epoch 55/200, Iteration 131/250, Loss: 0.0256\n",
      "Epoch 55/200, Iteration 132/250, Loss: 0.0351\n",
      "Epoch 55/200, Iteration 133/250, Loss: 0.0141\n",
      "Epoch 55/200, Iteration 134/250, Loss: 0.0134\n",
      "Epoch 55/200, Iteration 135/250, Loss: 0.0331\n",
      "Epoch 55/200, Iteration 136/250, Loss: 0.0218\n",
      "Epoch 55/200, Iteration 137/250, Loss: 0.0160\n",
      "Epoch 55/200, Iteration 138/250, Loss: 0.0082\n",
      "Epoch 55/200, Iteration 139/250, Loss: 0.0088\n",
      "Epoch 55/200, Iteration 140/250, Loss: 0.0095\n",
      "Epoch 55/200, Iteration 141/250, Loss: 0.0095\n",
      "Epoch 55/200, Iteration 142/250, Loss: 0.0187\n",
      "Epoch 55/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 55/200, Iteration 144/250, Loss: 0.0133\n",
      "Epoch 55/200, Iteration 145/250, Loss: 0.0077\n",
      "Epoch 55/200, Iteration 146/250, Loss: 0.0160\n",
      "Epoch 55/200, Iteration 147/250, Loss: 0.0139\n",
      "Epoch 55/200, Iteration 148/250, Loss: 0.0146\n",
      "Epoch 55/200, Iteration 149/250, Loss: 0.0151\n",
      "Epoch 55/200, Iteration 150/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 151/250, Loss: 0.0106\n",
      "Epoch 55/200, Iteration 152/250, Loss: 0.0099\n",
      "Epoch 55/200, Iteration 153/250, Loss: 0.0081\n",
      "Epoch 55/200, Iteration 154/250, Loss: 0.0127\n",
      "Epoch 55/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 55/200, Iteration 156/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 55/200, Iteration 158/250, Loss: 0.0138\n",
      "Epoch 55/200, Iteration 159/250, Loss: 0.0077\n",
      "Epoch 55/200, Iteration 160/250, Loss: 0.0149\n",
      "Epoch 55/200, Iteration 161/250, Loss: 0.0291\n",
      "Epoch 55/200, Iteration 162/250, Loss: 0.0250\n",
      "Epoch 55/200, Iteration 163/250, Loss: 0.0183\n",
      "Epoch 55/200, Iteration 164/250, Loss: 0.0067\n",
      "Epoch 55/200, Iteration 165/250, Loss: 0.0131\n",
      "Epoch 55/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 55/200, Iteration 167/250, Loss: 0.0095\n",
      "Epoch 55/200, Iteration 168/250, Loss: 0.0106\n",
      "Epoch 55/200, Iteration 169/250, Loss: 0.0307\n",
      "Epoch 55/200, Iteration 170/250, Loss: 0.0164\n",
      "Epoch 55/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 172/250, Loss: 0.0139\n",
      "Epoch 55/200, Iteration 173/250, Loss: 0.0073\n",
      "Epoch 55/200, Iteration 174/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 175/250, Loss: 0.0141\n",
      "Epoch 55/200, Iteration 176/250, Loss: 0.0191\n",
      "Epoch 55/200, Iteration 177/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 178/250, Loss: 0.0160\n",
      "Epoch 55/200, Iteration 179/250, Loss: 0.0141\n",
      "Epoch 55/200, Iteration 180/250, Loss: 0.0153\n",
      "Epoch 55/200, Iteration 181/250, Loss: 0.0116\n",
      "Epoch 55/200, Iteration 182/250, Loss: 0.0107\n",
      "Epoch 55/200, Iteration 183/250, Loss: 0.0112\n",
      "Epoch 55/200, Iteration 184/250, Loss: 0.0126\n",
      "Epoch 55/200, Iteration 185/250, Loss: 0.0105\n",
      "Epoch 55/200, Iteration 186/250, Loss: 0.0262\n",
      "Epoch 55/200, Iteration 187/250, Loss: 0.0149\n",
      "Epoch 55/200, Iteration 188/250, Loss: 0.0129\n",
      "Epoch 55/200, Iteration 189/250, Loss: 0.0225\n",
      "Epoch 55/200, Iteration 190/250, Loss: 0.0314\n",
      "Epoch 55/200, Iteration 191/250, Loss: 0.0310\n",
      "Epoch 55/200, Iteration 192/250, Loss: 0.0289\n",
      "Epoch 55/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 55/200, Iteration 194/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 195/250, Loss: 0.0159\n",
      "Epoch 55/200, Iteration 196/250, Loss: 0.0109\n",
      "Epoch 55/200, Iteration 197/250, Loss: 0.0049\n",
      "Epoch 55/200, Iteration 198/250, Loss: 0.0139\n",
      "Epoch 55/200, Iteration 199/250, Loss: 0.0336\n",
      "Epoch 55/200, Iteration 200/250, Loss: 0.0075\n",
      "Epoch 55/200, Iteration 201/250, Loss: 0.0208\n",
      "Epoch 55/200, Iteration 202/250, Loss: 0.0272\n",
      "Epoch 55/200, Iteration 203/250, Loss: 0.0359\n",
      "Epoch 55/200, Iteration 204/250, Loss: 0.0144\n",
      "Epoch 55/200, Iteration 205/250, Loss: 0.0342\n",
      "Epoch 55/200, Iteration 206/250, Loss: 0.0076\n",
      "Epoch 55/200, Iteration 207/250, Loss: 0.0091\n",
      "Epoch 55/200, Iteration 208/250, Loss: 0.0121\n",
      "Epoch 55/200, Iteration 209/250, Loss: 0.0185\n",
      "Epoch 55/200, Iteration 210/250, Loss: 0.0262\n",
      "Epoch 55/200, Iteration 211/250, Loss: 0.0146\n",
      "Epoch 55/200, Iteration 212/250, Loss: 0.0321\n",
      "Epoch 55/200, Iteration 213/250, Loss: 0.0201\n",
      "Epoch 55/200, Iteration 214/250, Loss: 0.0213\n",
      "Epoch 55/200, Iteration 215/250, Loss: 0.0144\n",
      "Epoch 55/200, Iteration 216/250, Loss: 0.0177\n",
      "Epoch 55/200, Iteration 217/250, Loss: 0.0239\n",
      "Epoch 55/200, Iteration 218/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 219/250, Loss: 0.0211\n",
      "Epoch 55/200, Iteration 220/250, Loss: 0.0287\n",
      "Epoch 55/200, Iteration 221/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 222/250, Loss: 0.0102\n",
      "Epoch 55/200, Iteration 223/250, Loss: 0.0127\n",
      "Epoch 55/200, Iteration 224/250, Loss: 0.0131\n",
      "Epoch 55/200, Iteration 225/250, Loss: 0.0074\n",
      "Epoch 55/200, Iteration 226/250, Loss: 0.0090\n",
      "Epoch 55/200, Iteration 227/250, Loss: 0.0121\n",
      "Epoch 55/200, Iteration 228/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 229/250, Loss: 0.0353\n",
      "Epoch 55/200, Iteration 230/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 231/250, Loss: 0.0162\n",
      "Epoch 55/200, Iteration 232/250, Loss: 0.0082\n",
      "Epoch 55/200, Iteration 233/250, Loss: 0.0072\n",
      "Epoch 55/200, Iteration 234/250, Loss: 0.0388\n",
      "Epoch 55/200, Iteration 235/250, Loss: 0.0093\n",
      "Epoch 55/200, Iteration 236/250, Loss: 0.0067\n",
      "Epoch 55/200, Iteration 237/250, Loss: 0.0209\n",
      "Epoch 55/200, Iteration 238/250, Loss: 0.0083\n",
      "Epoch 55/200, Iteration 239/250, Loss: 0.0148\n",
      "Epoch 55/200, Iteration 240/250, Loss: 0.0359\n",
      "Epoch 55/200, Iteration 241/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 242/250, Loss: 0.0190\n",
      "Epoch 55/200, Iteration 243/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 55/200, Iteration 245/250, Loss: 0.0109\n",
      "Epoch 55/200, Iteration 246/250, Loss: 0.0150\n",
      "Epoch 55/200, Iteration 247/250, Loss: 0.0105\n",
      "Epoch 55/200, Iteration 248/250, Loss: 0.0181\n",
      "Epoch 55/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 55/200, Iteration 250/250, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 92.83%, Avg loss: 0.006793, MRE: 0.703368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.006657, MRE: 0.755185 \n",
      "\n",
      "Epoch 56/200, Iteration 1/250, Loss: 0.0246\n",
      "Epoch 56/200, Iteration 2/250, Loss: 0.0068\n",
      "Epoch 56/200, Iteration 3/250, Loss: 0.0078\n",
      "Epoch 56/200, Iteration 4/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 5/250, Loss: 0.0222\n",
      "Epoch 56/200, Iteration 6/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 7/250, Loss: 0.0162\n",
      "Epoch 56/200, Iteration 8/250, Loss: 0.0230\n",
      "Epoch 56/200, Iteration 9/250, Loss: 0.0163\n",
      "Epoch 56/200, Iteration 10/250, Loss: 0.0134\n",
      "Epoch 56/200, Iteration 11/250, Loss: 0.0115\n",
      "Epoch 56/200, Iteration 12/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 13/250, Loss: 0.0137\n",
      "Epoch 56/200, Iteration 14/250, Loss: 0.0173\n",
      "Epoch 56/200, Iteration 15/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 16/250, Loss: 0.0243\n",
      "Epoch 56/200, Iteration 17/250, Loss: 0.0348\n",
      "Epoch 56/200, Iteration 18/250, Loss: 0.0113\n",
      "Epoch 56/200, Iteration 19/250, Loss: 0.0204\n",
      "Epoch 56/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 56/200, Iteration 21/250, Loss: 0.0158\n",
      "Epoch 56/200, Iteration 22/250, Loss: 0.0237\n",
      "Epoch 56/200, Iteration 23/250, Loss: 0.0183\n",
      "Epoch 56/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 56/200, Iteration 25/250, Loss: 0.0140\n",
      "Epoch 56/200, Iteration 26/250, Loss: 0.0435\n",
      "Epoch 56/200, Iteration 27/250, Loss: 0.0104\n",
      "Epoch 56/200, Iteration 28/250, Loss: 0.0082\n",
      "Epoch 56/200, Iteration 29/250, Loss: 0.0159\n",
      "Epoch 56/200, Iteration 30/250, Loss: 0.0118\n",
      "Epoch 56/200, Iteration 31/250, Loss: 0.0327\n",
      "Epoch 56/200, Iteration 32/250, Loss: 0.0181\n",
      "Epoch 56/200, Iteration 33/250, Loss: 0.0079\n",
      "Epoch 56/200, Iteration 34/250, Loss: 0.0213\n",
      "Epoch 56/200, Iteration 35/250, Loss: 0.0163\n",
      "Epoch 56/200, Iteration 36/250, Loss: 0.0082\n",
      "Epoch 56/200, Iteration 37/250, Loss: 0.0107\n",
      "Epoch 56/200, Iteration 38/250, Loss: 0.0170\n",
      "Epoch 56/200, Iteration 39/250, Loss: 0.0270\n",
      "Epoch 56/200, Iteration 40/250, Loss: 0.0157\n",
      "Epoch 56/200, Iteration 41/250, Loss: 0.0141\n",
      "Epoch 56/200, Iteration 42/250, Loss: 0.0239\n",
      "Epoch 56/200, Iteration 43/250, Loss: 0.0230\n",
      "Epoch 56/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 56/200, Iteration 45/250, Loss: 0.0292\n",
      "Epoch 56/200, Iteration 46/250, Loss: 0.0117\n",
      "Epoch 56/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 56/200, Iteration 48/250, Loss: 0.0102\n",
      "Epoch 56/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 56/200, Iteration 50/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 51/250, Loss: 0.0102\n",
      "Epoch 56/200, Iteration 52/250, Loss: 0.0220\n",
      "Epoch 56/200, Iteration 53/250, Loss: 0.0185\n",
      "Epoch 56/200, Iteration 54/250, Loss: 0.0245\n",
      "Epoch 56/200, Iteration 55/250, Loss: 0.0257\n",
      "Epoch 56/200, Iteration 56/250, Loss: 0.0126\n",
      "Epoch 56/200, Iteration 57/250, Loss: 0.0136\n",
      "Epoch 56/200, Iteration 58/250, Loss: 0.0122\n",
      "Epoch 56/200, Iteration 59/250, Loss: 0.0157\n",
      "Epoch 56/200, Iteration 60/250, Loss: 0.0112\n",
      "Epoch 56/200, Iteration 61/250, Loss: 0.0289\n",
      "Epoch 56/200, Iteration 62/250, Loss: 0.0129\n",
      "Epoch 56/200, Iteration 63/250, Loss: 0.0131\n",
      "Epoch 56/200, Iteration 64/250, Loss: 0.0114\n",
      "Epoch 56/200, Iteration 65/250, Loss: 0.0186\n",
      "Epoch 56/200, Iteration 66/250, Loss: 0.0232\n",
      "Epoch 56/200, Iteration 67/250, Loss: 0.0186\n",
      "Epoch 56/200, Iteration 68/250, Loss: 0.0249\n",
      "Epoch 56/200, Iteration 69/250, Loss: 0.0088\n",
      "Epoch 56/200, Iteration 70/250, Loss: 0.0159\n",
      "Epoch 56/200, Iteration 71/250, Loss: 0.0191\n",
      "Epoch 56/200, Iteration 72/250, Loss: 0.0086\n",
      "Epoch 56/200, Iteration 73/250, Loss: 0.0185\n",
      "Epoch 56/200, Iteration 74/250, Loss: 0.0130\n",
      "Epoch 56/200, Iteration 75/250, Loss: 0.0174\n",
      "Epoch 56/200, Iteration 76/250, Loss: 0.0076\n",
      "Epoch 56/200, Iteration 77/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 78/250, Loss: 0.0100\n",
      "Epoch 56/200, Iteration 79/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 80/250, Loss: 0.0084\n",
      "Epoch 56/200, Iteration 81/250, Loss: 0.0169\n",
      "Epoch 56/200, Iteration 82/250, Loss: 0.0178\n",
      "Epoch 56/200, Iteration 83/250, Loss: 0.0169\n",
      "Epoch 56/200, Iteration 84/250, Loss: 0.0085\n",
      "Epoch 56/200, Iteration 85/250, Loss: 0.0210\n",
      "Epoch 56/200, Iteration 86/250, Loss: 0.0213\n",
      "Epoch 56/200, Iteration 87/250, Loss: 0.0098\n",
      "Epoch 56/200, Iteration 88/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 89/250, Loss: 0.0158\n",
      "Epoch 56/200, Iteration 90/250, Loss: 0.0093\n",
      "Epoch 56/200, Iteration 91/250, Loss: 0.0126\n",
      "Epoch 56/200, Iteration 92/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 93/250, Loss: 0.0176\n",
      "Epoch 56/200, Iteration 94/250, Loss: 0.0144\n",
      "Epoch 56/200, Iteration 95/250, Loss: 0.0206\n",
      "Epoch 56/200, Iteration 96/250, Loss: 0.0164\n",
      "Epoch 56/200, Iteration 97/250, Loss: 0.0088\n",
      "Epoch 56/200, Iteration 98/250, Loss: 0.0060\n",
      "Epoch 56/200, Iteration 99/250, Loss: 0.0326\n",
      "Epoch 56/200, Iteration 100/250, Loss: 0.0243\n",
      "Epoch 56/200, Iteration 101/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 102/250, Loss: 0.0110\n",
      "Epoch 56/200, Iteration 103/250, Loss: 0.0264\n",
      "Epoch 56/200, Iteration 104/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 105/250, Loss: 0.0106\n",
      "Epoch 56/200, Iteration 106/250, Loss: 0.0120\n",
      "Epoch 56/200, Iteration 107/250, Loss: 0.0357\n",
      "Epoch 56/200, Iteration 108/250, Loss: 0.0170\n",
      "Epoch 56/200, Iteration 109/250, Loss: 0.0358\n",
      "Epoch 56/200, Iteration 110/250, Loss: 0.0148\n",
      "Epoch 56/200, Iteration 111/250, Loss: 0.0377\n",
      "Epoch 56/200, Iteration 112/250, Loss: 0.0256\n",
      "Epoch 56/200, Iteration 113/250, Loss: 0.0127\n",
      "Epoch 56/200, Iteration 114/250, Loss: 0.0104\n",
      "Epoch 56/200, Iteration 115/250, Loss: 0.0180\n",
      "Epoch 56/200, Iteration 116/250, Loss: 0.0255\n",
      "Epoch 56/200, Iteration 117/250, Loss: 0.0252\n",
      "Epoch 56/200, Iteration 118/250, Loss: 0.0305\n",
      "Epoch 56/200, Iteration 119/250, Loss: 0.0091\n",
      "Epoch 56/200, Iteration 120/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 121/250, Loss: 0.0105\n",
      "Epoch 56/200, Iteration 122/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 123/250, Loss: 0.0087\n",
      "Epoch 56/200, Iteration 124/250, Loss: 0.0105\n",
      "Epoch 56/200, Iteration 125/250, Loss: 0.0076\n",
      "Epoch 56/200, Iteration 126/250, Loss: 0.0183\n",
      "Epoch 56/200, Iteration 127/250, Loss: 0.0150\n",
      "Epoch 56/200, Iteration 128/250, Loss: 0.0087\n",
      "Epoch 56/200, Iteration 129/250, Loss: 0.0150\n",
      "Epoch 56/200, Iteration 130/250, Loss: 0.0089\n",
      "Epoch 56/200, Iteration 131/250, Loss: 0.0098\n",
      "Epoch 56/200, Iteration 132/250, Loss: 0.0095\n",
      "Epoch 56/200, Iteration 133/250, Loss: 0.0144\n",
      "Epoch 56/200, Iteration 134/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 135/250, Loss: 0.0156\n",
      "Epoch 56/200, Iteration 136/250, Loss: 0.0196\n",
      "Epoch 56/200, Iteration 137/250, Loss: 0.0195\n",
      "Epoch 56/200, Iteration 138/250, Loss: 0.0115\n",
      "Epoch 56/200, Iteration 139/250, Loss: 0.0127\n",
      "Epoch 56/200, Iteration 140/250, Loss: 0.0148\n",
      "Epoch 56/200, Iteration 141/250, Loss: 0.0138\n",
      "Epoch 56/200, Iteration 142/250, Loss: 0.0168\n",
      "Epoch 56/200, Iteration 143/250, Loss: 0.0078\n",
      "Epoch 56/200, Iteration 144/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 145/250, Loss: 0.0153\n",
      "Epoch 56/200, Iteration 146/250, Loss: 0.0202\n",
      "Epoch 56/200, Iteration 147/250, Loss: 0.0124\n",
      "Epoch 56/200, Iteration 148/250, Loss: 0.0174\n",
      "Epoch 56/200, Iteration 149/250, Loss: 0.0089\n",
      "Epoch 56/200, Iteration 150/250, Loss: 0.0101\n",
      "Epoch 56/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 56/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 153/250, Loss: 0.0120\n",
      "Epoch 56/200, Iteration 154/250, Loss: 0.0381\n",
      "Epoch 56/200, Iteration 155/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 156/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 157/250, Loss: 0.0173\n",
      "Epoch 56/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 56/200, Iteration 159/250, Loss: 0.0148\n",
      "Epoch 56/200, Iteration 160/250, Loss: 0.0149\n",
      "Epoch 56/200, Iteration 161/250, Loss: 0.0126\n",
      "Epoch 56/200, Iteration 162/250, Loss: 0.0076\n",
      "Epoch 56/200, Iteration 163/250, Loss: 0.0143\n",
      "Epoch 56/200, Iteration 164/250, Loss: 0.0182\n",
      "Epoch 56/200, Iteration 165/250, Loss: 0.0086\n",
      "Epoch 56/200, Iteration 166/250, Loss: 0.0099\n",
      "Epoch 56/200, Iteration 167/250, Loss: 0.0092\n",
      "Epoch 56/200, Iteration 168/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 169/250, Loss: 0.0117\n",
      "Epoch 56/200, Iteration 170/250, Loss: 0.0150\n",
      "Epoch 56/200, Iteration 171/250, Loss: 0.0108\n",
      "Epoch 56/200, Iteration 172/250, Loss: 0.0104\n",
      "Epoch 56/200, Iteration 173/250, Loss: 0.0199\n",
      "Epoch 56/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 56/200, Iteration 175/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 176/250, Loss: 0.0149\n",
      "Epoch 56/200, Iteration 177/250, Loss: 0.0203\n",
      "Epoch 56/200, Iteration 178/250, Loss: 0.0268\n",
      "Epoch 56/200, Iteration 179/250, Loss: 0.0231\n",
      "Epoch 56/200, Iteration 180/250, Loss: 0.0130\n",
      "Epoch 56/200, Iteration 181/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 182/250, Loss: 0.0270\n",
      "Epoch 56/200, Iteration 183/250, Loss: 0.0162\n",
      "Epoch 56/200, Iteration 184/250, Loss: 0.0064\n",
      "Epoch 56/200, Iteration 185/250, Loss: 0.0168\n",
      "Epoch 56/200, Iteration 186/250, Loss: 0.0430\n",
      "Epoch 56/200, Iteration 187/250, Loss: 0.0245\n",
      "Epoch 56/200, Iteration 188/250, Loss: 0.0068\n",
      "Epoch 56/200, Iteration 189/250, Loss: 0.0181\n",
      "Epoch 56/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 56/200, Iteration 191/250, Loss: 0.0125\n",
      "Epoch 56/200, Iteration 192/250, Loss: 0.0177\n",
      "Epoch 56/200, Iteration 193/250, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Iteration 194/250, Loss: 0.0086\n",
      "Epoch 56/200, Iteration 195/250, Loss: 0.0101\n",
      "Epoch 56/200, Iteration 196/250, Loss: 0.0156\n",
      "Epoch 56/200, Iteration 197/250, Loss: 0.0174\n",
      "Epoch 56/200, Iteration 198/250, Loss: 0.0182\n",
      "Epoch 56/200, Iteration 199/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 200/250, Loss: 0.0295\n",
      "Epoch 56/200, Iteration 201/250, Loss: 0.0151\n",
      "Epoch 56/200, Iteration 202/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 203/250, Loss: 0.0108\n",
      "Epoch 56/200, Iteration 204/250, Loss: 0.0264\n",
      "Epoch 56/200, Iteration 205/250, Loss: 0.0090\n",
      "Epoch 56/200, Iteration 206/250, Loss: 0.0110\n",
      "Epoch 56/200, Iteration 207/250, Loss: 0.0151\n",
      "Epoch 56/200, Iteration 208/250, Loss: 0.0127\n",
      "Epoch 56/200, Iteration 209/250, Loss: 0.0277\n",
      "Epoch 56/200, Iteration 210/250, Loss: 0.0224\n",
      "Epoch 56/200, Iteration 211/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 212/250, Loss: 0.0223\n",
      "Epoch 56/200, Iteration 213/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 214/250, Loss: 0.0130\n",
      "Epoch 56/200, Iteration 215/250, Loss: 0.0142\n",
      "Epoch 56/200, Iteration 216/250, Loss: 0.0102\n",
      "Epoch 56/200, Iteration 217/250, Loss: 0.0240\n",
      "Epoch 56/200, Iteration 218/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 219/250, Loss: 0.0052\n",
      "Epoch 56/200, Iteration 220/250, Loss: 0.0356\n",
      "Epoch 56/200, Iteration 221/250, Loss: 0.0152\n",
      "Epoch 56/200, Iteration 222/250, Loss: 0.0206\n",
      "Epoch 56/200, Iteration 223/250, Loss: 0.0089\n",
      "Epoch 56/200, Iteration 224/250, Loss: 0.0143\n",
      "Epoch 56/200, Iteration 225/250, Loss: 0.0112\n",
      "Epoch 56/200, Iteration 226/250, Loss: 0.0241\n",
      "Epoch 56/200, Iteration 227/250, Loss: 0.0415\n",
      "Epoch 56/200, Iteration 228/250, Loss: 0.0220\n",
      "Epoch 56/200, Iteration 229/250, Loss: 0.0138\n",
      "Epoch 56/200, Iteration 230/250, Loss: 0.0177\n",
      "Epoch 56/200, Iteration 231/250, Loss: 0.0092\n",
      "Epoch 56/200, Iteration 232/250, Loss: 0.0076\n",
      "Epoch 56/200, Iteration 233/250, Loss: 0.0136\n",
      "Epoch 56/200, Iteration 234/250, Loss: 0.0142\n",
      "Epoch 56/200, Iteration 235/250, Loss: 0.0087\n",
      "Epoch 56/200, Iteration 236/250, Loss: 0.0267\n",
      "Epoch 56/200, Iteration 237/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 238/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 239/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 240/250, Loss: 0.0237\n",
      "Epoch 56/200, Iteration 241/250, Loss: 0.0113\n",
      "Epoch 56/200, Iteration 242/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 56/200, Iteration 244/250, Loss: 0.0152\n",
      "Epoch 56/200, Iteration 245/250, Loss: 0.0190\n",
      "Epoch 56/200, Iteration 246/250, Loss: 0.0118\n",
      "Epoch 56/200, Iteration 247/250, Loss: 0.0072\n",
      "Epoch 56/200, Iteration 248/250, Loss: 0.0157\n",
      "Epoch 56/200, Iteration 249/250, Loss: 0.0203\n",
      "Epoch 56/200, Iteration 250/250, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006867, MRE: 0.652583 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.25%, Avg loss: 0.006750, MRE: 0.671641 \n",
      "\n",
      "Epoch 57/200, Iteration 1/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 2/250, Loss: 0.0224\n",
      "Epoch 57/200, Iteration 3/250, Loss: 0.0145\n",
      "Epoch 57/200, Iteration 4/250, Loss: 0.0166\n",
      "Epoch 57/200, Iteration 5/250, Loss: 0.0270\n",
      "Epoch 57/200, Iteration 6/250, Loss: 0.0167\n",
      "Epoch 57/200, Iteration 7/250, Loss: 0.0101\n",
      "Epoch 57/200, Iteration 8/250, Loss: 0.0180\n",
      "Epoch 57/200, Iteration 9/250, Loss: 0.0149\n",
      "Epoch 57/200, Iteration 10/250, Loss: 0.0109\n",
      "Epoch 57/200, Iteration 11/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 12/250, Loss: 0.0122\n",
      "Epoch 57/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 57/200, Iteration 14/250, Loss: 0.0380\n",
      "Epoch 57/200, Iteration 15/250, Loss: 0.0271\n",
      "Epoch 57/200, Iteration 16/250, Loss: 0.0238\n",
      "Epoch 57/200, Iteration 17/250, Loss: 0.0237\n",
      "Epoch 57/200, Iteration 18/250, Loss: 0.0225\n",
      "Epoch 57/200, Iteration 19/250, Loss: 0.0164\n",
      "Epoch 57/200, Iteration 20/250, Loss: 0.0099\n",
      "Epoch 57/200, Iteration 21/250, Loss: 0.0174\n",
      "Epoch 57/200, Iteration 22/250, Loss: 0.0254\n",
      "Epoch 57/200, Iteration 23/250, Loss: 0.0303\n",
      "Epoch 57/200, Iteration 24/250, Loss: 0.0250\n",
      "Epoch 57/200, Iteration 25/250, Loss: 0.0093\n",
      "Epoch 57/200, Iteration 26/250, Loss: 0.0137\n",
      "Epoch 57/200, Iteration 27/250, Loss: 0.0086\n",
      "Epoch 57/200, Iteration 28/250, Loss: 0.0135\n",
      "Epoch 57/200, Iteration 29/250, Loss: 0.0206\n",
      "Epoch 57/200, Iteration 30/250, Loss: 0.0181\n",
      "Epoch 57/200, Iteration 31/250, Loss: 0.0280\n",
      "Epoch 57/200, Iteration 32/250, Loss: 0.0117\n",
      "Epoch 57/200, Iteration 33/250, Loss: 0.0218\n",
      "Epoch 57/200, Iteration 34/250, Loss: 0.0153\n",
      "Epoch 57/200, Iteration 35/250, Loss: 0.0088\n",
      "Epoch 57/200, Iteration 36/250, Loss: 0.0202\n",
      "Epoch 57/200, Iteration 37/250, Loss: 0.0082\n",
      "Epoch 57/200, Iteration 38/250, Loss: 0.0344\n",
      "Epoch 57/200, Iteration 39/250, Loss: 0.0095\n",
      "Epoch 57/200, Iteration 40/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 41/250, Loss: 0.0207\n",
      "Epoch 57/200, Iteration 42/250, Loss: 0.0106\n",
      "Epoch 57/200, Iteration 43/250, Loss: 0.0343\n",
      "Epoch 57/200, Iteration 44/250, Loss: 0.0086\n",
      "Epoch 57/200, Iteration 45/250, Loss: 0.0096\n",
      "Epoch 57/200, Iteration 46/250, Loss: 0.0102\n",
      "Epoch 57/200, Iteration 47/250, Loss: 0.0116\n",
      "Epoch 57/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 57/200, Iteration 49/250, Loss: 0.0091\n",
      "Epoch 57/200, Iteration 50/250, Loss: 0.0187\n",
      "Epoch 57/200, Iteration 51/250, Loss: 0.0085\n",
      "Epoch 57/200, Iteration 52/250, Loss: 0.0180\n",
      "Epoch 57/200, Iteration 53/250, Loss: 0.0263\n",
      "Epoch 57/200, Iteration 54/250, Loss: 0.0107\n",
      "Epoch 57/200, Iteration 55/250, Loss: 0.0233\n",
      "Epoch 57/200, Iteration 56/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 57/250, Loss: 0.0152\n",
      "Epoch 57/200, Iteration 58/250, Loss: 0.0101\n",
      "Epoch 57/200, Iteration 59/250, Loss: 0.0125\n",
      "Epoch 57/200, Iteration 60/250, Loss: 0.0149\n",
      "Epoch 57/200, Iteration 61/250, Loss: 0.0159\n",
      "Epoch 57/200, Iteration 62/250, Loss: 0.0160\n",
      "Epoch 57/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 57/200, Iteration 64/250, Loss: 0.0108\n",
      "Epoch 57/200, Iteration 65/250, Loss: 0.0146\n",
      "Epoch 57/200, Iteration 66/250, Loss: 0.0235\n",
      "Epoch 57/200, Iteration 67/250, Loss: 0.0232\n",
      "Epoch 57/200, Iteration 68/250, Loss: 0.0098\n",
      "Epoch 57/200, Iteration 69/250, Loss: 0.0155\n",
      "Epoch 57/200, Iteration 70/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 71/250, Loss: 0.0287\n",
      "Epoch 57/200, Iteration 72/250, Loss: 0.0270\n",
      "Epoch 57/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 57/200, Iteration 74/250, Loss: 0.0152\n",
      "Epoch 57/200, Iteration 75/250, Loss: 0.0168\n",
      "Epoch 57/200, Iteration 76/250, Loss: 0.0099\n",
      "Epoch 57/200, Iteration 77/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 78/250, Loss: 0.0422\n",
      "Epoch 57/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 80/250, Loss: 0.0226\n",
      "Epoch 57/200, Iteration 81/250, Loss: 0.0238\n",
      "Epoch 57/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 85/250, Loss: 0.0188\n",
      "Epoch 57/200, Iteration 86/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 87/250, Loss: 0.0184\n",
      "Epoch 57/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 57/200, Iteration 89/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 90/250, Loss: 0.0069\n",
      "Epoch 57/200, Iteration 91/250, Loss: 0.0071\n",
      "Epoch 57/200, Iteration 92/250, Loss: 0.0158\n",
      "Epoch 57/200, Iteration 93/250, Loss: 0.0086\n",
      "Epoch 57/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 57/200, Iteration 95/250, Loss: 0.0075\n",
      "Epoch 57/200, Iteration 96/250, Loss: 0.0258\n",
      "Epoch 57/200, Iteration 97/250, Loss: 0.0360\n",
      "Epoch 57/200, Iteration 98/250, Loss: 0.0098\n",
      "Epoch 57/200, Iteration 99/250, Loss: 0.0143\n",
      "Epoch 57/200, Iteration 100/250, Loss: 0.0197\n",
      "Epoch 57/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 102/250, Loss: 0.0131\n",
      "Epoch 57/200, Iteration 103/250, Loss: 0.0149\n",
      "Epoch 57/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 57/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 106/250, Loss: 0.0185\n",
      "Epoch 57/200, Iteration 107/250, Loss: 0.0171\n",
      "Epoch 57/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 57/200, Iteration 109/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 57/200, Iteration 111/250, Loss: 0.0156\n",
      "Epoch 57/200, Iteration 112/250, Loss: 0.0176\n",
      "Epoch 57/200, Iteration 113/250, Loss: 0.0158\n",
      "Epoch 57/200, Iteration 114/250, Loss: 0.0167\n",
      "Epoch 57/200, Iteration 115/250, Loss: 0.0255\n",
      "Epoch 57/200, Iteration 116/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 57/200, Iteration 118/250, Loss: 0.0064\n",
      "Epoch 57/200, Iteration 119/250, Loss: 0.0157\n",
      "Epoch 57/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 57/200, Iteration 121/250, Loss: 0.0238\n",
      "Epoch 57/200, Iteration 122/250, Loss: 0.0096\n",
      "Epoch 57/200, Iteration 123/250, Loss: 0.0146\n",
      "Epoch 57/200, Iteration 124/250, Loss: 0.0251\n",
      "Epoch 57/200, Iteration 125/250, Loss: 0.0223\n",
      "Epoch 57/200, Iteration 126/250, Loss: 0.0124\n",
      "Epoch 57/200, Iteration 127/250, Loss: 0.0448\n",
      "Epoch 57/200, Iteration 128/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 129/250, Loss: 0.0123\n",
      "Epoch 57/200, Iteration 130/250, Loss: 0.0169\n",
      "Epoch 57/200, Iteration 131/250, Loss: 0.0086\n",
      "Epoch 57/200, Iteration 132/250, Loss: 0.0139\n",
      "Epoch 57/200, Iteration 133/250, Loss: 0.0172\n",
      "Epoch 57/200, Iteration 134/250, Loss: 0.0135\n",
      "Epoch 57/200, Iteration 135/250, Loss: 0.0157\n",
      "Epoch 57/200, Iteration 136/250, Loss: 0.0151\n",
      "Epoch 57/200, Iteration 137/250, Loss: 0.0150\n",
      "Epoch 57/200, Iteration 138/250, Loss: 0.0090\n",
      "Epoch 57/200, Iteration 139/250, Loss: 0.0111\n",
      "Epoch 57/200, Iteration 140/250, Loss: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Iteration 141/250, Loss: 0.0292\n",
      "Epoch 57/200, Iteration 142/250, Loss: 0.0155\n",
      "Epoch 57/200, Iteration 143/250, Loss: 0.0197\n",
      "Epoch 57/200, Iteration 144/250, Loss: 0.0178\n",
      "Epoch 57/200, Iteration 145/250, Loss: 0.0179\n",
      "Epoch 57/200, Iteration 146/250, Loss: 0.0195\n",
      "Epoch 57/200, Iteration 147/250, Loss: 0.0173\n",
      "Epoch 57/200, Iteration 148/250, Loss: 0.0315\n",
      "Epoch 57/200, Iteration 149/250, Loss: 0.0160\n",
      "Epoch 57/200, Iteration 150/250, Loss: 0.0119\n",
      "Epoch 57/200, Iteration 151/250, Loss: 0.0174\n",
      "Epoch 57/200, Iteration 152/250, Loss: 0.0183\n",
      "Epoch 57/200, Iteration 153/250, Loss: 0.0149\n",
      "Epoch 57/200, Iteration 154/250, Loss: 0.0131\n",
      "Epoch 57/200, Iteration 155/250, Loss: 0.0209\n",
      "Epoch 57/200, Iteration 156/250, Loss: 0.0343\n",
      "Epoch 57/200, Iteration 157/250, Loss: 0.0358\n",
      "Epoch 57/200, Iteration 158/250, Loss: 0.0100\n",
      "Epoch 57/200, Iteration 159/250, Loss: 0.0217\n",
      "Epoch 57/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 57/200, Iteration 161/250, Loss: 0.0161\n",
      "Epoch 57/200, Iteration 162/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 163/250, Loss: 0.0141\n",
      "Epoch 57/200, Iteration 164/250, Loss: 0.0198\n",
      "Epoch 57/200, Iteration 165/250, Loss: 0.0156\n",
      "Epoch 57/200, Iteration 166/250, Loss: 0.0268\n",
      "Epoch 57/200, Iteration 167/250, Loss: 0.0165\n",
      "Epoch 57/200, Iteration 168/250, Loss: 0.0156\n",
      "Epoch 57/200, Iteration 169/250, Loss: 0.0143\n",
      "Epoch 57/200, Iteration 170/250, Loss: 0.0212\n",
      "Epoch 57/200, Iteration 171/250, Loss: 0.0362\n",
      "Epoch 57/200, Iteration 172/250, Loss: 0.0217\n",
      "Epoch 57/200, Iteration 173/250, Loss: 0.0146\n",
      "Epoch 57/200, Iteration 174/250, Loss: 0.0168\n",
      "Epoch 57/200, Iteration 175/250, Loss: 0.0267\n",
      "Epoch 57/200, Iteration 176/250, Loss: 0.0183\n",
      "Epoch 57/200, Iteration 177/250, Loss: 0.0133\n",
      "Epoch 57/200, Iteration 178/250, Loss: 0.0075\n",
      "Epoch 57/200, Iteration 179/250, Loss: 0.0084\n",
      "Epoch 57/200, Iteration 180/250, Loss: 0.0139\n",
      "Epoch 57/200, Iteration 181/250, Loss: 0.0189\n",
      "Epoch 57/200, Iteration 182/250, Loss: 0.0089\n",
      "Epoch 57/200, Iteration 183/250, Loss: 0.0090\n",
      "Epoch 57/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 185/250, Loss: 0.0164\n",
      "Epoch 57/200, Iteration 186/250, Loss: 0.0124\n",
      "Epoch 57/200, Iteration 187/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 188/250, Loss: 0.0216\n",
      "Epoch 57/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 57/200, Iteration 190/250, Loss: 0.0511\n",
      "Epoch 57/200, Iteration 191/250, Loss: 0.0132\n",
      "Epoch 57/200, Iteration 192/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 193/250, Loss: 0.0178\n",
      "Epoch 57/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 57/200, Iteration 195/250, Loss: 0.0065\n",
      "Epoch 57/200, Iteration 196/250, Loss: 0.0188\n",
      "Epoch 57/200, Iteration 197/250, Loss: 0.0191\n",
      "Epoch 57/200, Iteration 198/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 199/250, Loss: 0.0291\n",
      "Epoch 57/200, Iteration 200/250, Loss: 0.0109\n",
      "Epoch 57/200, Iteration 201/250, Loss: 0.0104\n",
      "Epoch 57/200, Iteration 202/250, Loss: 0.0256\n",
      "Epoch 57/200, Iteration 203/250, Loss: 0.0192\n",
      "Epoch 57/200, Iteration 204/250, Loss: 0.0190\n",
      "Epoch 57/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 57/200, Iteration 206/250, Loss: 0.0122\n",
      "Epoch 57/200, Iteration 207/250, Loss: 0.0101\n",
      "Epoch 57/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 57/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 57/200, Iteration 210/250, Loss: 0.0084\n",
      "Epoch 57/200, Iteration 211/250, Loss: 0.0106\n",
      "Epoch 57/200, Iteration 212/250, Loss: 0.0141\n",
      "Epoch 57/200, Iteration 213/250, Loss: 0.0305\n",
      "Epoch 57/200, Iteration 214/250, Loss: 0.0167\n",
      "Epoch 57/200, Iteration 215/250, Loss: 0.0118\n",
      "Epoch 57/200, Iteration 216/250, Loss: 0.0280\n",
      "Epoch 57/200, Iteration 217/250, Loss: 0.0161\n",
      "Epoch 57/200, Iteration 218/250, Loss: 0.0080\n",
      "Epoch 57/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 57/200, Iteration 220/250, Loss: 0.0316\n",
      "Epoch 57/200, Iteration 221/250, Loss: 0.0151\n",
      "Epoch 57/200, Iteration 222/250, Loss: 0.0118\n",
      "Epoch 57/200, Iteration 223/250, Loss: 0.0156\n",
      "Epoch 57/200, Iteration 224/250, Loss: 0.0138\n",
      "Epoch 57/200, Iteration 225/250, Loss: 0.0150\n",
      "Epoch 57/200, Iteration 226/250, Loss: 0.0119\n",
      "Epoch 57/200, Iteration 227/250, Loss: 0.0237\n",
      "Epoch 57/200, Iteration 228/250, Loss: 0.0116\n",
      "Epoch 57/200, Iteration 229/250, Loss: 0.0089\n",
      "Epoch 57/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 57/200, Iteration 231/250, Loss: 0.0130\n",
      "Epoch 57/200, Iteration 232/250, Loss: 0.0094\n",
      "Epoch 57/200, Iteration 233/250, Loss: 0.0425\n",
      "Epoch 57/200, Iteration 234/250, Loss: 0.0193\n",
      "Epoch 57/200, Iteration 235/250, Loss: 0.0109\n",
      "Epoch 57/200, Iteration 236/250, Loss: 0.0144\n",
      "Epoch 57/200, Iteration 237/250, Loss: 0.0243\n",
      "Epoch 57/200, Iteration 238/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 239/250, Loss: 0.0104\n",
      "Epoch 57/200, Iteration 240/250, Loss: 0.0239\n",
      "Epoch 57/200, Iteration 241/250, Loss: 0.0323\n",
      "Epoch 57/200, Iteration 242/250, Loss: 0.0234\n",
      "Epoch 57/200, Iteration 243/250, Loss: 0.0361\n",
      "Epoch 57/200, Iteration 244/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 246/250, Loss: 0.0210\n",
      "Epoch 57/200, Iteration 247/250, Loss: 0.0119\n",
      "Epoch 57/200, Iteration 248/250, Loss: 0.0335\n",
      "Epoch 57/200, Iteration 249/250, Loss: 0.0255\n",
      "Epoch 57/200, Iteration 250/250, Loss: 0.0126\n",
      "Train Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.007572, MRE: 0.616287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007692, MRE: 1.086435 \n",
      "\n",
      "Epoch 58/200, Iteration 1/250, Loss: 0.0193\n",
      "Epoch 58/200, Iteration 2/250, Loss: 0.0198\n",
      "Epoch 58/200, Iteration 3/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 4/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 5/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 6/250, Loss: 0.0117\n",
      "Epoch 58/200, Iteration 7/250, Loss: 0.0159\n",
      "Epoch 58/200, Iteration 8/250, Loss: 0.0117\n",
      "Epoch 58/200, Iteration 9/250, Loss: 0.0326\n",
      "Epoch 58/200, Iteration 10/250, Loss: 0.0111\n",
      "Epoch 58/200, Iteration 11/250, Loss: 0.0137\n",
      "Epoch 58/200, Iteration 12/250, Loss: 0.0161\n",
      "Epoch 58/200, Iteration 13/250, Loss: 0.0258\n",
      "Epoch 58/200, Iteration 14/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 15/250, Loss: 0.0257\n",
      "Epoch 58/200, Iteration 16/250, Loss: 0.0123\n",
      "Epoch 58/200, Iteration 17/250, Loss: 0.0161\n",
      "Epoch 58/200, Iteration 18/250, Loss: 0.0112\n",
      "Epoch 58/200, Iteration 19/250, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 20/250, Loss: 0.0463\n",
      "Epoch 58/200, Iteration 21/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 23/250, Loss: 0.0185\n",
      "Epoch 58/200, Iteration 24/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 25/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 26/250, Loss: 0.0320\n",
      "Epoch 58/200, Iteration 27/250, Loss: 0.0103\n",
      "Epoch 58/200, Iteration 28/250, Loss: 0.0174\n",
      "Epoch 58/200, Iteration 29/250, Loss: 0.0083\n",
      "Epoch 58/200, Iteration 30/250, Loss: 0.0093\n",
      "Epoch 58/200, Iteration 31/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 32/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 33/250, Loss: 0.0263\n",
      "Epoch 58/200, Iteration 34/250, Loss: 0.0081\n",
      "Epoch 58/200, Iteration 35/250, Loss: 0.0193\n",
      "Epoch 58/200, Iteration 36/250, Loss: 0.0078\n",
      "Epoch 58/200, Iteration 37/250, Loss: 0.0093\n",
      "Epoch 58/200, Iteration 38/250, Loss: 0.0102\n",
      "Epoch 58/200, Iteration 39/250, Loss: 0.0080\n",
      "Epoch 58/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 41/250, Loss: 0.0077\n",
      "Epoch 58/200, Iteration 42/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 43/250, Loss: 0.0088\n",
      "Epoch 58/200, Iteration 44/250, Loss: 0.0205\n",
      "Epoch 58/200, Iteration 45/250, Loss: 0.0093\n",
      "Epoch 58/200, Iteration 46/250, Loss: 0.0195\n",
      "Epoch 58/200, Iteration 47/250, Loss: 0.0225\n",
      "Epoch 58/200, Iteration 48/250, Loss: 0.0407\n",
      "Epoch 58/200, Iteration 49/250, Loss: 0.0193\n",
      "Epoch 58/200, Iteration 50/250, Loss: 0.0160\n",
      "Epoch 58/200, Iteration 51/250, Loss: 0.0196\n",
      "Epoch 58/200, Iteration 52/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 53/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 54/250, Loss: 0.0176\n",
      "Epoch 58/200, Iteration 55/250, Loss: 0.0142\n",
      "Epoch 58/200, Iteration 56/250, Loss: 0.0172\n",
      "Epoch 58/200, Iteration 57/250, Loss: 0.0085\n",
      "Epoch 58/200, Iteration 58/250, Loss: 0.0454\n",
      "Epoch 58/200, Iteration 59/250, Loss: 0.0248\n",
      "Epoch 58/200, Iteration 60/250, Loss: 0.0141\n",
      "Epoch 58/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 58/200, Iteration 62/250, Loss: 0.0163\n",
      "Epoch 58/200, Iteration 63/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 64/250, Loss: 0.0114\n",
      "Epoch 58/200, Iteration 65/250, Loss: 0.0123\n",
      "Epoch 58/200, Iteration 66/250, Loss: 0.0085\n",
      "Epoch 58/200, Iteration 67/250, Loss: 0.0104\n",
      "Epoch 58/200, Iteration 68/250, Loss: 0.0259\n",
      "Epoch 58/200, Iteration 69/250, Loss: 0.0144\n",
      "Epoch 58/200, Iteration 70/250, Loss: 0.0147\n",
      "Epoch 58/200, Iteration 71/250, Loss: 0.0098\n",
      "Epoch 58/200, Iteration 72/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 73/250, Loss: 0.0173\n",
      "Epoch 58/200, Iteration 74/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 75/250, Loss: 0.0083\n",
      "Epoch 58/200, Iteration 76/250, Loss: 0.0100\n",
      "Epoch 58/200, Iteration 77/250, Loss: 0.0122\n",
      "Epoch 58/200, Iteration 78/250, Loss: 0.0138\n",
      "Epoch 58/200, Iteration 79/250, Loss: 0.0121\n",
      "Epoch 58/200, Iteration 80/250, Loss: 0.0236\n",
      "Epoch 58/200, Iteration 81/250, Loss: 0.0249\n",
      "Epoch 58/200, Iteration 82/250, Loss: 0.0430\n",
      "Epoch 58/200, Iteration 83/250, Loss: 0.0225\n",
      "Epoch 58/200, Iteration 84/250, Loss: 0.0339\n",
      "Epoch 58/200, Iteration 85/250, Loss: 0.0095\n",
      "Epoch 58/200, Iteration 86/250, Loss: 0.0323\n",
      "Epoch 58/200, Iteration 87/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 88/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 89/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 91/250, Loss: 0.0308\n",
      "Epoch 58/200, Iteration 92/250, Loss: 0.0182\n",
      "Epoch 58/200, Iteration 93/250, Loss: 0.0119\n",
      "Epoch 58/200, Iteration 94/250, Loss: 0.0089\n",
      "Epoch 58/200, Iteration 95/250, Loss: 0.0368\n",
      "Epoch 58/200, Iteration 96/250, Loss: 0.0120\n",
      "Epoch 58/200, Iteration 97/250, Loss: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Iteration 98/250, Loss: 0.0079\n",
      "Epoch 58/200, Iteration 99/250, Loss: 0.0101\n",
      "Epoch 58/200, Iteration 100/250, Loss: 0.0174\n",
      "Epoch 58/200, Iteration 101/250, Loss: 0.0126\n",
      "Epoch 58/200, Iteration 102/250, Loss: 0.0224\n",
      "Epoch 58/200, Iteration 103/250, Loss: 0.0200\n",
      "Epoch 58/200, Iteration 104/250, Loss: 0.0103\n",
      "Epoch 58/200, Iteration 105/250, Loss: 0.0206\n",
      "Epoch 58/200, Iteration 106/250, Loss: 0.0081\n",
      "Epoch 58/200, Iteration 107/250, Loss: 0.0112\n",
      "Epoch 58/200, Iteration 108/250, Loss: 0.0142\n",
      "Epoch 58/200, Iteration 109/250, Loss: 0.0111\n",
      "Epoch 58/200, Iteration 110/250, Loss: 0.0117\n",
      "Epoch 58/200, Iteration 111/250, Loss: 0.0216\n",
      "Epoch 58/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 58/200, Iteration 113/250, Loss: 0.0165\n",
      "Epoch 58/200, Iteration 114/250, Loss: 0.0325\n",
      "Epoch 58/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 58/200, Iteration 116/250, Loss: 0.0157\n",
      "Epoch 58/200, Iteration 117/250, Loss: 0.0180\n",
      "Epoch 58/200, Iteration 118/250, Loss: 0.0151\n",
      "Epoch 58/200, Iteration 119/250, Loss: 0.0079\n",
      "Epoch 58/200, Iteration 120/250, Loss: 0.0162\n",
      "Epoch 58/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 58/200, Iteration 122/250, Loss: 0.0093\n",
      "Epoch 58/200, Iteration 123/250, Loss: 0.0139\n",
      "Epoch 58/200, Iteration 124/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 125/250, Loss: 0.0174\n",
      "Epoch 58/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 58/200, Iteration 127/250, Loss: 0.0087\n",
      "Epoch 58/200, Iteration 128/250, Loss: 0.0141\n",
      "Epoch 58/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 130/250, Loss: 0.0149\n",
      "Epoch 58/200, Iteration 131/250, Loss: 0.0148\n",
      "Epoch 58/200, Iteration 132/250, Loss: 0.0082\n",
      "Epoch 58/200, Iteration 133/250, Loss: 0.0162\n",
      "Epoch 58/200, Iteration 134/250, Loss: 0.0149\n",
      "Epoch 58/200, Iteration 135/250, Loss: 0.0089\n",
      "Epoch 58/200, Iteration 136/250, Loss: 0.0155\n",
      "Epoch 58/200, Iteration 137/250, Loss: 0.0095\n",
      "Epoch 58/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 58/200, Iteration 139/250, Loss: 0.0191\n",
      "Epoch 58/200, Iteration 140/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 141/250, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 142/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 143/250, Loss: 0.0338\n",
      "Epoch 58/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 145/250, Loss: 0.0142\n",
      "Epoch 58/200, Iteration 146/250, Loss: 0.0231\n",
      "Epoch 58/200, Iteration 147/250, Loss: 0.0084\n",
      "Epoch 58/200, Iteration 148/250, Loss: 0.0064\n",
      "Epoch 58/200, Iteration 149/250, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 150/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 58/200, Iteration 152/250, Loss: 0.0094\n",
      "Epoch 58/200, Iteration 153/250, Loss: 0.0144\n",
      "Epoch 58/200, Iteration 154/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 155/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 156/250, Loss: 0.0167\n",
      "Epoch 58/200, Iteration 157/250, Loss: 0.0316\n",
      "Epoch 58/200, Iteration 158/250, Loss: 0.0232\n",
      "Epoch 58/200, Iteration 159/250, Loss: 0.0185\n",
      "Epoch 58/200, Iteration 160/250, Loss: 0.0088\n",
      "Epoch 58/200, Iteration 161/250, Loss: 0.0111\n",
      "Epoch 58/200, Iteration 162/250, Loss: 0.0260\n",
      "Epoch 58/200, Iteration 163/250, Loss: 0.0154\n",
      "Epoch 58/200, Iteration 164/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 165/250, Loss: 0.0080\n",
      "Epoch 58/200, Iteration 166/250, Loss: 0.0168\n",
      "Epoch 58/200, Iteration 167/250, Loss: 0.0120\n",
      "Epoch 58/200, Iteration 168/250, Loss: 0.0413\n",
      "Epoch 58/200, Iteration 169/250, Loss: 0.0332\n",
      "Epoch 58/200, Iteration 170/250, Loss: 0.0094\n",
      "Epoch 58/200, Iteration 171/250, Loss: 0.0131\n",
      "Epoch 58/200, Iteration 172/250, Loss: 0.0148\n",
      "Epoch 58/200, Iteration 173/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 174/250, Loss: 0.0153\n",
      "Epoch 58/200, Iteration 175/250, Loss: 0.0240\n",
      "Epoch 58/200, Iteration 176/250, Loss: 0.0117\n",
      "Epoch 58/200, Iteration 177/250, Loss: 0.0185\n",
      "Epoch 58/200, Iteration 178/250, Loss: 0.0268\n",
      "Epoch 58/200, Iteration 179/250, Loss: 0.0104\n",
      "Epoch 58/200, Iteration 180/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 181/250, Loss: 0.0132\n",
      "Epoch 58/200, Iteration 182/250, Loss: 0.0328\n",
      "Epoch 58/200, Iteration 183/250, Loss: 0.0183\n",
      "Epoch 58/200, Iteration 184/250, Loss: 0.0235\n",
      "Epoch 58/200, Iteration 185/250, Loss: 0.0100\n",
      "Epoch 58/200, Iteration 186/250, Loss: 0.0069\n",
      "Epoch 58/200, Iteration 187/250, Loss: 0.0088\n",
      "Epoch 58/200, Iteration 188/250, Loss: 0.0105\n",
      "Epoch 58/200, Iteration 189/250, Loss: 0.0187\n",
      "Epoch 58/200, Iteration 190/250, Loss: 0.0280\n",
      "Epoch 58/200, Iteration 191/250, Loss: 0.0201\n",
      "Epoch 58/200, Iteration 192/250, Loss: 0.0240\n",
      "Epoch 58/200, Iteration 193/250, Loss: 0.0278\n",
      "Epoch 58/200, Iteration 194/250, Loss: 0.0273\n",
      "Epoch 58/200, Iteration 195/250, Loss: 0.0229\n",
      "Epoch 58/200, Iteration 196/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 197/250, Loss: 0.0148\n",
      "Epoch 58/200, Iteration 198/250, Loss: 0.0153\n",
      "Epoch 58/200, Iteration 199/250, Loss: 0.0263\n",
      "Epoch 58/200, Iteration 200/250, Loss: 0.0197\n",
      "Epoch 58/200, Iteration 201/250, Loss: 0.0304\n",
      "Epoch 58/200, Iteration 202/250, Loss: 0.0327\n",
      "Epoch 58/200, Iteration 203/250, Loss: 0.0337\n",
      "Epoch 58/200, Iteration 204/250, Loss: 0.0171\n",
      "Epoch 58/200, Iteration 205/250, Loss: 0.0078\n",
      "Epoch 58/200, Iteration 206/250, Loss: 0.0107\n",
      "Epoch 58/200, Iteration 207/250, Loss: 0.0285\n",
      "Epoch 58/200, Iteration 208/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 209/250, Loss: 0.0077\n",
      "Epoch 58/200, Iteration 210/250, Loss: 0.0106\n",
      "Epoch 58/200, Iteration 211/250, Loss: 0.0282\n",
      "Epoch 58/200, Iteration 212/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 213/250, Loss: 0.0094\n",
      "Epoch 58/200, Iteration 214/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 215/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 216/250, Loss: 0.0106\n",
      "Epoch 58/200, Iteration 217/250, Loss: 0.0218\n",
      "Epoch 58/200, Iteration 218/250, Loss: 0.0072\n",
      "Epoch 58/200, Iteration 219/250, Loss: 0.0092\n",
      "Epoch 58/200, Iteration 220/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 221/250, Loss: 0.0228\n",
      "Epoch 58/200, Iteration 222/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 223/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 224/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 225/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 226/250, Loss: 0.0157\n",
      "Epoch 58/200, Iteration 227/250, Loss: 0.0150\n",
      "Epoch 58/200, Iteration 228/250, Loss: 0.0157\n",
      "Epoch 58/200, Iteration 229/250, Loss: 0.0235\n",
      "Epoch 58/200, Iteration 230/250, Loss: 0.0103\n",
      "Epoch 58/200, Iteration 231/250, Loss: 0.0089\n",
      "Epoch 58/200, Iteration 232/250, Loss: 0.0224\n",
      "Epoch 58/200, Iteration 233/250, Loss: 0.0174\n",
      "Epoch 58/200, Iteration 234/250, Loss: 0.0126\n",
      "Epoch 58/200, Iteration 235/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 236/250, Loss: 0.0161\n",
      "Epoch 58/200, Iteration 237/250, Loss: 0.0092\n",
      "Epoch 58/200, Iteration 238/250, Loss: 0.0091\n",
      "Epoch 58/200, Iteration 239/250, Loss: 0.0207\n",
      "Epoch 58/200, Iteration 240/250, Loss: 0.0095\n",
      "Epoch 58/200, Iteration 241/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 242/250, Loss: 0.0148\n",
      "Epoch 58/200, Iteration 243/250, Loss: 0.0289\n",
      "Epoch 58/200, Iteration 244/250, Loss: 0.0141\n",
      "Epoch 58/200, Iteration 245/250, Loss: 0.0281\n",
      "Epoch 58/200, Iteration 246/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 247/250, Loss: 0.0114\n",
      "Epoch 58/200, Iteration 248/250, Loss: 0.0100\n",
      "Epoch 58/200, Iteration 249/250, Loss: 0.0184\n",
      "Epoch 58/200, Iteration 250/250, Loss: 0.0190\n",
      "Train Error: \n",
      " Accuracy: 90.58%, Avg loss: 0.006825, MRE: 0.671164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.15%, Avg loss: 0.006796, MRE: 0.790853 \n",
      "\n",
      "Epoch 59/200, Iteration 1/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 2/250, Loss: 0.0214\n",
      "Epoch 59/200, Iteration 3/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 4/250, Loss: 0.0257\n",
      "Epoch 59/200, Iteration 5/250, Loss: 0.0206\n",
      "Epoch 59/200, Iteration 6/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 59/200, Iteration 8/250, Loss: 0.0215\n",
      "Epoch 59/200, Iteration 9/250, Loss: 0.0080\n",
      "Epoch 59/200, Iteration 10/250, Loss: 0.0154\n",
      "Epoch 59/200, Iteration 11/250, Loss: 0.0238\n",
      "Epoch 59/200, Iteration 12/250, Loss: 0.0063\n",
      "Epoch 59/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 59/200, Iteration 14/250, Loss: 0.0201\n",
      "Epoch 59/200, Iteration 15/250, Loss: 0.0222\n",
      "Epoch 59/200, Iteration 16/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 17/250, Loss: 0.0155\n",
      "Epoch 59/200, Iteration 18/250, Loss: 0.0275\n",
      "Epoch 59/200, Iteration 19/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 20/250, Loss: 0.0150\n",
      "Epoch 59/200, Iteration 21/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 22/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 23/250, Loss: 0.0195\n",
      "Epoch 59/200, Iteration 24/250, Loss: 0.0220\n",
      "Epoch 59/200, Iteration 25/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 26/250, Loss: 0.0114\n",
      "Epoch 59/200, Iteration 27/250, Loss: 0.0130\n",
      "Epoch 59/200, Iteration 28/250, Loss: 0.0236\n",
      "Epoch 59/200, Iteration 29/250, Loss: 0.0128\n",
      "Epoch 59/200, Iteration 30/250, Loss: 0.0115\n",
      "Epoch 59/200, Iteration 31/250, Loss: 0.0094\n",
      "Epoch 59/200, Iteration 32/250, Loss: 0.0071\n",
      "Epoch 59/200, Iteration 33/250, Loss: 0.0256\n",
      "Epoch 59/200, Iteration 34/250, Loss: 0.0080\n",
      "Epoch 59/200, Iteration 35/250, Loss: 0.0133\n",
      "Epoch 59/200, Iteration 36/250, Loss: 0.0100\n",
      "Epoch 59/200, Iteration 37/250, Loss: 0.0132\n",
      "Epoch 59/200, Iteration 38/250, Loss: 0.0149\n",
      "Epoch 59/200, Iteration 39/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 40/250, Loss: 0.0098\n",
      "Epoch 59/200, Iteration 41/250, Loss: 0.0107\n",
      "Epoch 59/200, Iteration 42/250, Loss: 0.0175\n",
      "Epoch 59/200, Iteration 43/250, Loss: 0.0104\n",
      "Epoch 59/200, Iteration 44/250, Loss: 0.0157\n",
      "Epoch 59/200, Iteration 45/250, Loss: 0.0100\n",
      "Epoch 59/200, Iteration 46/250, Loss: 0.0203\n",
      "Epoch 59/200, Iteration 47/250, Loss: 0.0151\n",
      "Epoch 59/200, Iteration 48/250, Loss: 0.0133\n",
      "Epoch 59/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 59/200, Iteration 50/250, Loss: 0.0121\n",
      "Epoch 59/200, Iteration 51/250, Loss: 0.0081\n",
      "Epoch 59/200, Iteration 52/250, Loss: 0.0149\n",
      "Epoch 59/200, Iteration 53/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 54/250, Loss: 0.0252\n",
      "Epoch 59/200, Iteration 55/250, Loss: 0.0161\n",
      "Epoch 59/200, Iteration 56/250, Loss: 0.0153\n",
      "Epoch 59/200, Iteration 57/250, Loss: 0.0104\n",
      "Epoch 59/200, Iteration 58/250, Loss: 0.0273\n",
      "Epoch 59/200, Iteration 59/250, Loss: 0.0139\n",
      "Epoch 59/200, Iteration 60/250, Loss: 0.0094\n",
      "Epoch 59/200, Iteration 61/250, Loss: 0.0145\n",
      "Epoch 59/200, Iteration 62/250, Loss: 0.0079\n",
      "Epoch 59/200, Iteration 63/250, Loss: 0.0276\n",
      "Epoch 59/200, Iteration 64/250, Loss: 0.0309\n",
      "Epoch 59/200, Iteration 65/250, Loss: 0.0233\n",
      "Epoch 59/200, Iteration 66/250, Loss: 0.0296\n",
      "Epoch 59/200, Iteration 67/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 68/250, Loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Iteration 69/250, Loss: 0.0104\n",
      "Epoch 59/200, Iteration 70/250, Loss: 0.0095\n",
      "Epoch 59/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 59/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 59/200, Iteration 73/250, Loss: 0.0153\n",
      "Epoch 59/200, Iteration 74/250, Loss: 0.0176\n",
      "Epoch 59/200, Iteration 75/250, Loss: 0.0382\n",
      "Epoch 59/200, Iteration 76/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 77/250, Loss: 0.0202\n",
      "Epoch 59/200, Iteration 78/250, Loss: 0.0267\n",
      "Epoch 59/200, Iteration 79/250, Loss: 0.0306\n",
      "Epoch 59/200, Iteration 80/250, Loss: 0.0102\n",
      "Epoch 59/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 59/200, Iteration 82/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 83/250, Loss: 0.0183\n",
      "Epoch 59/200, Iteration 84/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 85/250, Loss: 0.0131\n",
      "Epoch 59/200, Iteration 86/250, Loss: 0.0066\n",
      "Epoch 59/200, Iteration 87/250, Loss: 0.0105\n",
      "Epoch 59/200, Iteration 88/250, Loss: 0.0175\n",
      "Epoch 59/200, Iteration 89/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 90/250, Loss: 0.0084\n",
      "Epoch 59/200, Iteration 91/250, Loss: 0.0185\n",
      "Epoch 59/200, Iteration 92/250, Loss: 0.0214\n",
      "Epoch 59/200, Iteration 93/250, Loss: 0.0268\n",
      "Epoch 59/200, Iteration 94/250, Loss: 0.0115\n",
      "Epoch 59/200, Iteration 95/250, Loss: 0.0386\n",
      "Epoch 59/200, Iteration 96/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 97/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 98/250, Loss: 0.0101\n",
      "Epoch 59/200, Iteration 99/250, Loss: 0.0303\n",
      "Epoch 59/200, Iteration 100/250, Loss: 0.0125\n",
      "Epoch 59/200, Iteration 101/250, Loss: 0.0140\n",
      "Epoch 59/200, Iteration 102/250, Loss: 0.0095\n",
      "Epoch 59/200, Iteration 103/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 104/250, Loss: 0.0377\n",
      "Epoch 59/200, Iteration 105/250, Loss: 0.0170\n",
      "Epoch 59/200, Iteration 106/250, Loss: 0.0134\n",
      "Epoch 59/200, Iteration 107/250, Loss: 0.0334\n",
      "Epoch 59/200, Iteration 108/250, Loss: 0.0082\n",
      "Epoch 59/200, Iteration 109/250, Loss: 0.0343\n",
      "Epoch 59/200, Iteration 110/250, Loss: 0.0092\n",
      "Epoch 59/200, Iteration 111/250, Loss: 0.0127\n",
      "Epoch 59/200, Iteration 112/250, Loss: 0.0088\n",
      "Epoch 59/200, Iteration 113/250, Loss: 0.0129\n",
      "Epoch 59/200, Iteration 114/250, Loss: 0.0125\n",
      "Epoch 59/200, Iteration 115/250, Loss: 0.0115\n",
      "Epoch 59/200, Iteration 116/250, Loss: 0.0119\n",
      "Epoch 59/200, Iteration 117/250, Loss: 0.0069\n",
      "Epoch 59/200, Iteration 118/250, Loss: 0.0253\n",
      "Epoch 59/200, Iteration 119/250, Loss: 0.0110\n",
      "Epoch 59/200, Iteration 120/250, Loss: 0.0114\n",
      "Epoch 59/200, Iteration 121/250, Loss: 0.0118\n",
      "Epoch 59/200, Iteration 122/250, Loss: 0.0170\n",
      "Epoch 59/200, Iteration 123/250, Loss: 0.0095\n",
      "Epoch 59/200, Iteration 124/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 125/250, Loss: 0.0143\n",
      "Epoch 59/200, Iteration 126/250, Loss: 0.0283\n",
      "Epoch 59/200, Iteration 127/250, Loss: 0.0208\n",
      "Epoch 59/200, Iteration 128/250, Loss: 0.0198\n",
      "Epoch 59/200, Iteration 129/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 130/250, Loss: 0.0194\n",
      "Epoch 59/200, Iteration 131/250, Loss: 0.0229\n",
      "Epoch 59/200, Iteration 132/250, Loss: 0.0165\n",
      "Epoch 59/200, Iteration 133/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 134/250, Loss: 0.0155\n",
      "Epoch 59/200, Iteration 135/250, Loss: 0.0133\n",
      "Epoch 59/200, Iteration 136/250, Loss: 0.0081\n",
      "Epoch 59/200, Iteration 137/250, Loss: 0.0113\n",
      "Epoch 59/200, Iteration 138/250, Loss: 0.0210\n",
      "Epoch 59/200, Iteration 139/250, Loss: 0.0103\n",
      "Epoch 59/200, Iteration 140/250, Loss: 0.0322\n",
      "Epoch 59/200, Iteration 141/250, Loss: 0.0261\n",
      "Epoch 59/200, Iteration 142/250, Loss: 0.0185\n",
      "Epoch 59/200, Iteration 143/250, Loss: 0.0087\n",
      "Epoch 59/200, Iteration 144/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 145/250, Loss: 0.0076\n",
      "Epoch 59/200, Iteration 146/250, Loss: 0.0073\n",
      "Epoch 59/200, Iteration 147/250, Loss: 0.0202\n",
      "Epoch 59/200, Iteration 148/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 149/250, Loss: 0.0102\n",
      "Epoch 59/200, Iteration 150/250, Loss: 0.0155\n",
      "Epoch 59/200, Iteration 151/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 152/250, Loss: 0.0313\n",
      "Epoch 59/200, Iteration 153/250, Loss: 0.0118\n",
      "Epoch 59/200, Iteration 154/250, Loss: 0.0099\n",
      "Epoch 59/200, Iteration 155/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 156/250, Loss: 0.0235\n",
      "Epoch 59/200, Iteration 157/250, Loss: 0.0080\n",
      "Epoch 59/200, Iteration 158/250, Loss: 0.0083\n",
      "Epoch 59/200, Iteration 159/250, Loss: 0.0238\n",
      "Epoch 59/200, Iteration 160/250, Loss: 0.0143\n",
      "Epoch 59/200, Iteration 161/250, Loss: 0.0220\n",
      "Epoch 59/200, Iteration 162/250, Loss: 0.0098\n",
      "Epoch 59/200, Iteration 163/250, Loss: 0.0084\n",
      "Epoch 59/200, Iteration 164/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 165/250, Loss: 0.0178\n",
      "Epoch 59/200, Iteration 166/250, Loss: 0.0227\n",
      "Epoch 59/200, Iteration 167/250, Loss: 0.0247\n",
      "Epoch 59/200, Iteration 168/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 169/250, Loss: 0.0141\n",
      "Epoch 59/200, Iteration 170/250, Loss: 0.0211\n",
      "Epoch 59/200, Iteration 171/250, Loss: 0.0259\n",
      "Epoch 59/200, Iteration 172/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 173/250, Loss: 0.0157\n",
      "Epoch 59/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 175/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 176/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 177/250, Loss: 0.0147\n",
      "Epoch 59/200, Iteration 178/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 179/250, Loss: 0.0379\n",
      "Epoch 59/200, Iteration 180/250, Loss: 0.0202\n",
      "Epoch 59/200, Iteration 181/250, Loss: 0.0114\n",
      "Epoch 59/200, Iteration 182/250, Loss: 0.0190\n",
      "Epoch 59/200, Iteration 183/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 184/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 185/250, Loss: 0.0403\n",
      "Epoch 59/200, Iteration 186/250, Loss: 0.0088\n",
      "Epoch 59/200, Iteration 187/250, Loss: 0.0183\n",
      "Epoch 59/200, Iteration 188/250, Loss: 0.0168\n",
      "Epoch 59/200, Iteration 189/250, Loss: 0.0075\n",
      "Epoch 59/200, Iteration 190/250, Loss: 0.0094\n",
      "Epoch 59/200, Iteration 191/250, Loss: 0.0119\n",
      "Epoch 59/200, Iteration 192/250, Loss: 0.0170\n",
      "Epoch 59/200, Iteration 193/250, Loss: 0.0121\n",
      "Epoch 59/200, Iteration 194/250, Loss: 0.0221\n",
      "Epoch 59/200, Iteration 195/250, Loss: 0.0248\n",
      "Epoch 59/200, Iteration 196/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 197/250, Loss: 0.0129\n",
      "Epoch 59/200, Iteration 198/250, Loss: 0.0132\n",
      "Epoch 59/200, Iteration 199/250, Loss: 0.0076\n",
      "Epoch 59/200, Iteration 200/250, Loss: 0.0172\n",
      "Epoch 59/200, Iteration 201/250, Loss: 0.0188\n",
      "Epoch 59/200, Iteration 202/250, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 203/250, Loss: 0.0080\n",
      "Epoch 59/200, Iteration 204/250, Loss: 0.0336\n",
      "Epoch 59/200, Iteration 205/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 206/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 207/250, Loss: 0.0089\n",
      "Epoch 59/200, Iteration 208/250, Loss: 0.0332\n",
      "Epoch 59/200, Iteration 209/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 210/250, Loss: 0.0102\n",
      "Epoch 59/200, Iteration 211/250, Loss: 0.0249\n",
      "Epoch 59/200, Iteration 212/250, Loss: 0.0140\n",
      "Epoch 59/200, Iteration 213/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 214/250, Loss: 0.0274\n",
      "Epoch 59/200, Iteration 215/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 216/250, Loss: 0.0118\n",
      "Epoch 59/200, Iteration 217/250, Loss: 0.0130\n",
      "Epoch 59/200, Iteration 218/250, Loss: 0.0248\n",
      "Epoch 59/200, Iteration 219/250, Loss: 0.0277\n",
      "Epoch 59/200, Iteration 220/250, Loss: 0.0123\n",
      "Epoch 59/200, Iteration 221/250, Loss: 0.0123\n",
      "Epoch 59/200, Iteration 222/250, Loss: 0.0065\n",
      "Epoch 59/200, Iteration 223/250, Loss: 0.0137\n",
      "Epoch 59/200, Iteration 224/250, Loss: 0.0257\n",
      "Epoch 59/200, Iteration 225/250, Loss: 0.0104\n",
      "Epoch 59/200, Iteration 226/250, Loss: 0.0106\n",
      "Epoch 59/200, Iteration 227/250, Loss: 0.0134\n",
      "Epoch 59/200, Iteration 228/250, Loss: 0.0082\n",
      "Epoch 59/200, Iteration 229/250, Loss: 0.0235\n",
      "Epoch 59/200, Iteration 230/250, Loss: 0.0316\n",
      "Epoch 59/200, Iteration 231/250, Loss: 0.0122\n",
      "Epoch 59/200, Iteration 232/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 233/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 234/250, Loss: 0.0236\n",
      "Epoch 59/200, Iteration 235/250, Loss: 0.0259\n",
      "Epoch 59/200, Iteration 236/250, Loss: 0.0115\n",
      "Epoch 59/200, Iteration 237/250, Loss: 0.0112\n",
      "Epoch 59/200, Iteration 238/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 239/250, Loss: 0.0137\n",
      "Epoch 59/200, Iteration 240/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 243/250, Loss: 0.0236\n",
      "Epoch 59/200, Iteration 244/250, Loss: 0.0151\n",
      "Epoch 59/200, Iteration 245/250, Loss: 0.0100\n",
      "Epoch 59/200, Iteration 246/250, Loss: 0.0229\n",
      "Epoch 59/200, Iteration 247/250, Loss: 0.0182\n",
      "Epoch 59/200, Iteration 248/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 249/250, Loss: 0.0183\n",
      "Epoch 59/200, Iteration 250/250, Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 86.91%, Avg loss: 0.007028, MRE: 0.578692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.007096, MRE: 0.991437 \n",
      "\n",
      "Epoch 60/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 60/200, Iteration 2/250, Loss: 0.0196\n",
      "Epoch 60/200, Iteration 3/250, Loss: 0.0217\n",
      "Epoch 60/200, Iteration 4/250, Loss: 0.0092\n",
      "Epoch 60/200, Iteration 5/250, Loss: 0.0202\n",
      "Epoch 60/200, Iteration 6/250, Loss: 0.0087\n",
      "Epoch 60/200, Iteration 7/250, Loss: 0.0235\n",
      "Epoch 60/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 60/200, Iteration 9/250, Loss: 0.0166\n",
      "Epoch 60/200, Iteration 10/250, Loss: 0.0144\n",
      "Epoch 60/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 60/200, Iteration 12/250, Loss: 0.0115\n",
      "Epoch 60/200, Iteration 13/250, Loss: 0.0156\n",
      "Epoch 60/200, Iteration 14/250, Loss: 0.0178\n",
      "Epoch 60/200, Iteration 15/250, Loss: 0.0285\n",
      "Epoch 60/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 17/250, Loss: 0.0187\n",
      "Epoch 60/200, Iteration 18/250, Loss: 0.0140\n",
      "Epoch 60/200, Iteration 19/250, Loss: 0.0083\n",
      "Epoch 60/200, Iteration 20/250, Loss: 0.0174\n",
      "Epoch 60/200, Iteration 21/250, Loss: 0.0151\n",
      "Epoch 60/200, Iteration 22/250, Loss: 0.0431\n",
      "Epoch 60/200, Iteration 23/250, Loss: 0.0192\n",
      "Epoch 60/200, Iteration 24/250, Loss: 0.0127\n",
      "Epoch 60/200, Iteration 25/250, Loss: 0.0113\n",
      "Epoch 60/200, Iteration 26/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 27/250, Loss: 0.0070\n",
      "Epoch 60/200, Iteration 28/250, Loss: 0.0288\n",
      "Epoch 60/200, Iteration 29/250, Loss: 0.0095\n",
      "Epoch 60/200, Iteration 30/250, Loss: 0.0180\n",
      "Epoch 60/200, Iteration 31/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 32/250, Loss: 0.0213\n",
      "Epoch 60/200, Iteration 33/250, Loss: 0.0188\n",
      "Epoch 60/200, Iteration 34/250, Loss: 0.0148\n",
      "Epoch 60/200, Iteration 35/250, Loss: 0.0206\n",
      "Epoch 60/200, Iteration 36/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 37/250, Loss: 0.0175\n",
      "Epoch 60/200, Iteration 38/250, Loss: 0.0149\n",
      "Epoch 60/200, Iteration 39/250, Loss: 0.0297\n",
      "Epoch 60/200, Iteration 40/250, Loss: 0.0220\n",
      "Epoch 60/200, Iteration 41/250, Loss: 0.0219\n",
      "Epoch 60/200, Iteration 42/250, Loss: 0.0145\n",
      "Epoch 60/200, Iteration 43/250, Loss: 0.0074\n",
      "Epoch 60/200, Iteration 44/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 45/250, Loss: 0.0156\n",
      "Epoch 60/200, Iteration 46/250, Loss: 0.0358\n",
      "Epoch 60/200, Iteration 47/250, Loss: 0.0220\n",
      "Epoch 60/200, Iteration 48/250, Loss: 0.0321\n",
      "Epoch 60/200, Iteration 49/250, Loss: 0.0464\n",
      "Epoch 60/200, Iteration 50/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 51/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 52/250, Loss: 0.0256\n",
      "Epoch 60/200, Iteration 53/250, Loss: 0.0248\n",
      "Epoch 60/200, Iteration 54/250, Loss: 0.0217\n",
      "Epoch 60/200, Iteration 55/250, Loss: 0.0357\n",
      "Epoch 60/200, Iteration 56/250, Loss: 0.0196\n",
      "Epoch 60/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 60/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 60/200, Iteration 59/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 60/250, Loss: 0.0083\n",
      "Epoch 60/200, Iteration 61/250, Loss: 0.0174\n",
      "Epoch 60/200, Iteration 62/250, Loss: 0.0351\n",
      "Epoch 60/200, Iteration 63/250, Loss: 0.0277\n",
      "Epoch 60/200, Iteration 64/250, Loss: 0.0081\n",
      "Epoch 60/200, Iteration 65/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 66/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 67/250, Loss: 0.0315\n",
      "Epoch 60/200, Iteration 68/250, Loss: 0.0236\n",
      "Epoch 60/200, Iteration 69/250, Loss: 0.0218\n",
      "Epoch 60/200, Iteration 70/250, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 71/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 72/250, Loss: 0.0169\n",
      "Epoch 60/200, Iteration 73/250, Loss: 0.0176\n",
      "Epoch 60/200, Iteration 74/250, Loss: 0.0084\n",
      "Epoch 60/200, Iteration 75/250, Loss: 0.0143\n",
      "Epoch 60/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 60/200, Iteration 77/250, Loss: 0.0077\n",
      "Epoch 60/200, Iteration 78/250, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 79/250, Loss: 0.0252\n",
      "Epoch 60/200, Iteration 80/250, Loss: 0.0146\n",
      "Epoch 60/200, Iteration 81/250, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 82/250, Loss: 0.0153\n",
      "Epoch 60/200, Iteration 83/250, Loss: 0.0096\n",
      "Epoch 60/200, Iteration 84/250, Loss: 0.0393\n",
      "Epoch 60/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 60/200, Iteration 86/250, Loss: 0.0113\n",
      "Epoch 60/200, Iteration 87/250, Loss: 0.0224\n",
      "Epoch 60/200, Iteration 88/250, Loss: 0.0162\n",
      "Epoch 60/200, Iteration 89/250, Loss: 0.0088\n",
      "Epoch 60/200, Iteration 90/250, Loss: 0.0072\n",
      "Epoch 60/200, Iteration 91/250, Loss: 0.0164\n",
      "Epoch 60/200, Iteration 92/250, Loss: 0.0098\n",
      "Epoch 60/200, Iteration 93/250, Loss: 0.0099\n",
      "Epoch 60/200, Iteration 94/250, Loss: 0.0197\n",
      "Epoch 60/200, Iteration 95/250, Loss: 0.0273\n",
      "Epoch 60/200, Iteration 96/250, Loss: 0.0162\n",
      "Epoch 60/200, Iteration 97/250, Loss: 0.0230\n",
      "Epoch 60/200, Iteration 98/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 100/250, Loss: 0.0190\n",
      "Epoch 60/200, Iteration 101/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 102/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 103/250, Loss: 0.0115\n",
      "Epoch 60/200, Iteration 104/250, Loss: 0.0111\n",
      "Epoch 60/200, Iteration 105/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 106/250, Loss: 0.0073\n",
      "Epoch 60/200, Iteration 107/250, Loss: 0.0155\n",
      "Epoch 60/200, Iteration 108/250, Loss: 0.0153\n",
      "Epoch 60/200, Iteration 109/250, Loss: 0.0135\n",
      "Epoch 60/200, Iteration 110/250, Loss: 0.0221\n",
      "Epoch 60/200, Iteration 111/250, Loss: 0.0101\n",
      "Epoch 60/200, Iteration 112/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 113/250, Loss: 0.0170\n",
      "Epoch 60/200, Iteration 114/250, Loss: 0.0152\n",
      "Epoch 60/200, Iteration 115/250, Loss: 0.0234\n",
      "Epoch 60/200, Iteration 116/250, Loss: 0.0096\n",
      "Epoch 60/200, Iteration 117/250, Loss: 0.0127\n",
      "Epoch 60/200, Iteration 118/250, Loss: 0.0285\n",
      "Epoch 60/200, Iteration 119/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 121/250, Loss: 0.0161\n",
      "Epoch 60/200, Iteration 122/250, Loss: 0.0144\n",
      "Epoch 60/200, Iteration 123/250, Loss: 0.0212\n",
      "Epoch 60/200, Iteration 124/250, Loss: 0.0172\n",
      "Epoch 60/200, Iteration 125/250, Loss: 0.0093\n",
      "Epoch 60/200, Iteration 126/250, Loss: 0.0266\n",
      "Epoch 60/200, Iteration 127/250, Loss: 0.0260\n",
      "Epoch 60/200, Iteration 128/250, Loss: 0.0269\n",
      "Epoch 60/200, Iteration 129/250, Loss: 0.0197\n",
      "Epoch 60/200, Iteration 130/250, Loss: 0.0125\n",
      "Epoch 60/200, Iteration 131/250, Loss: 0.0095\n",
      "Epoch 60/200, Iteration 132/250, Loss: 0.0257\n",
      "Epoch 60/200, Iteration 133/250, Loss: 0.0177\n",
      "Epoch 60/200, Iteration 134/250, Loss: 0.0192\n",
      "Epoch 60/200, Iteration 135/250, Loss: 0.0103\n",
      "Epoch 60/200, Iteration 136/250, Loss: 0.0119\n",
      "Epoch 60/200, Iteration 137/250, Loss: 0.0150\n",
      "Epoch 60/200, Iteration 138/250, Loss: 0.0090\n",
      "Epoch 60/200, Iteration 139/250, Loss: 0.0178\n",
      "Epoch 60/200, Iteration 140/250, Loss: 0.0109\n",
      "Epoch 60/200, Iteration 141/250, Loss: 0.0082\n",
      "Epoch 60/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 60/200, Iteration 143/250, Loss: 0.0125\n",
      "Epoch 60/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 60/200, Iteration 145/250, Loss: 0.0248\n",
      "Epoch 60/200, Iteration 146/250, Loss: 0.0090\n",
      "Epoch 60/200, Iteration 147/250, Loss: 0.0152\n",
      "Epoch 60/200, Iteration 148/250, Loss: 0.0101\n",
      "Epoch 60/200, Iteration 149/250, Loss: 0.0185\n",
      "Epoch 60/200, Iteration 150/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 151/250, Loss: 0.0190\n",
      "Epoch 60/200, Iteration 152/250, Loss: 0.0121\n",
      "Epoch 60/200, Iteration 153/250, Loss: 0.0182\n",
      "Epoch 60/200, Iteration 154/250, Loss: 0.0284\n",
      "Epoch 60/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 156/250, Loss: 0.0099\n",
      "Epoch 60/200, Iteration 157/250, Loss: 0.0077\n",
      "Epoch 60/200, Iteration 158/250, Loss: 0.0096\n",
      "Epoch 60/200, Iteration 159/250, Loss: 0.0352\n",
      "Epoch 60/200, Iteration 160/250, Loss: 0.0234\n",
      "Epoch 60/200, Iteration 161/250, Loss: 0.0132\n",
      "Epoch 60/200, Iteration 162/250, Loss: 0.0164\n",
      "Epoch 60/200, Iteration 163/250, Loss: 0.0084\n",
      "Epoch 60/200, Iteration 164/250, Loss: 0.0175\n",
      "Epoch 60/200, Iteration 165/250, Loss: 0.0086\n",
      "Epoch 60/200, Iteration 166/250, Loss: 0.0394\n",
      "Epoch 60/200, Iteration 167/250, Loss: 0.0075\n",
      "Epoch 60/200, Iteration 168/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 169/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 170/250, Loss: 0.0460\n",
      "Epoch 60/200, Iteration 171/250, Loss: 0.0345\n",
      "Epoch 60/200, Iteration 172/250, Loss: 0.0263\n",
      "Epoch 60/200, Iteration 173/250, Loss: 0.0208\n",
      "Epoch 60/200, Iteration 174/250, Loss: 0.0133\n",
      "Epoch 60/200, Iteration 175/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 176/250, Loss: 0.0167\n",
      "Epoch 60/200, Iteration 177/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 178/250, Loss: 0.0089\n",
      "Epoch 60/200, Iteration 179/250, Loss: 0.0270\n",
      "Epoch 60/200, Iteration 180/250, Loss: 0.0237\n",
      "Epoch 60/200, Iteration 181/250, Loss: 0.0227\n",
      "Epoch 60/200, Iteration 182/250, Loss: 0.0282\n",
      "Epoch 60/200, Iteration 183/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 184/250, Loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Iteration 185/250, Loss: 0.0311\n",
      "Epoch 60/200, Iteration 186/250, Loss: 0.0087\n",
      "Epoch 60/200, Iteration 187/250, Loss: 0.0080\n",
      "Epoch 60/200, Iteration 188/250, Loss: 0.0148\n",
      "Epoch 60/200, Iteration 189/250, Loss: 0.0415\n",
      "Epoch 60/200, Iteration 190/250, Loss: 0.0146\n",
      "Epoch 60/200, Iteration 191/250, Loss: 0.0146\n",
      "Epoch 60/200, Iteration 192/250, Loss: 0.0191\n",
      "Epoch 60/200, Iteration 193/250, Loss: 0.0202\n",
      "Epoch 60/200, Iteration 194/250, Loss: 0.0167\n",
      "Epoch 60/200, Iteration 195/250, Loss: 0.0113\n",
      "Epoch 60/200, Iteration 196/250, Loss: 0.0103\n",
      "Epoch 60/200, Iteration 197/250, Loss: 0.0110\n",
      "Epoch 60/200, Iteration 198/250, Loss: 0.0098\n",
      "Epoch 60/200, Iteration 199/250, Loss: 0.0492\n",
      "Epoch 60/200, Iteration 200/250, Loss: 0.0084\n",
      "Epoch 60/200, Iteration 201/250, Loss: 0.0093\n",
      "Epoch 60/200, Iteration 202/250, Loss: 0.0099\n",
      "Epoch 60/200, Iteration 203/250, Loss: 0.0091\n",
      "Epoch 60/200, Iteration 204/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 205/250, Loss: 0.0237\n",
      "Epoch 60/200, Iteration 206/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 207/250, Loss: 0.0150\n",
      "Epoch 60/200, Iteration 208/250, Loss: 0.0116\n",
      "Epoch 60/200, Iteration 209/250, Loss: 0.0314\n",
      "Epoch 60/200, Iteration 210/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 211/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 212/250, Loss: 0.0075\n",
      "Epoch 60/200, Iteration 213/250, Loss: 0.0201\n",
      "Epoch 60/200, Iteration 214/250, Loss: 0.0130\n",
      "Epoch 60/200, Iteration 215/250, Loss: 0.0198\n",
      "Epoch 60/200, Iteration 216/250, Loss: 0.0249\n",
      "Epoch 60/200, Iteration 217/250, Loss: 0.0168\n",
      "Epoch 60/200, Iteration 218/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 219/250, Loss: 0.0136\n",
      "Epoch 60/200, Iteration 220/250, Loss: 0.0279\n",
      "Epoch 60/200, Iteration 221/250, Loss: 0.0157\n",
      "Epoch 60/200, Iteration 222/250, Loss: 0.0232\n",
      "Epoch 60/200, Iteration 223/250, Loss: 0.0234\n",
      "Epoch 60/200, Iteration 224/250, Loss: 0.0308\n",
      "Epoch 60/200, Iteration 225/250, Loss: 0.0116\n",
      "Epoch 60/200, Iteration 226/250, Loss: 0.0073\n",
      "Epoch 60/200, Iteration 227/250, Loss: 0.0136\n",
      "Epoch 60/200, Iteration 228/250, Loss: 0.0448\n",
      "Epoch 60/200, Iteration 229/250, Loss: 0.0109\n",
      "Epoch 60/200, Iteration 230/250, Loss: 0.0115\n",
      "Epoch 60/200, Iteration 231/250, Loss: 0.0143\n",
      "Epoch 60/200, Iteration 232/250, Loss: 0.0180\n",
      "Epoch 60/200, Iteration 233/250, Loss: 0.0324\n",
      "Epoch 60/200, Iteration 234/250, Loss: 0.0091\n",
      "Epoch 60/200, Iteration 235/250, Loss: 0.0176\n",
      "Epoch 60/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 60/200, Iteration 237/250, Loss: 0.0253\n",
      "Epoch 60/200, Iteration 238/250, Loss: 0.0173\n",
      "Epoch 60/200, Iteration 239/250, Loss: 0.0096\n",
      "Epoch 60/200, Iteration 240/250, Loss: 0.0174\n",
      "Epoch 60/200, Iteration 241/250, Loss: 0.0101\n",
      "Epoch 60/200, Iteration 242/250, Loss: 0.0178\n",
      "Epoch 60/200, Iteration 243/250, Loss: 0.0220\n",
      "Epoch 60/200, Iteration 244/250, Loss: 0.0193\n",
      "Epoch 60/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 60/200, Iteration 246/250, Loss: 0.0229\n",
      "Epoch 60/200, Iteration 247/250, Loss: 0.0174\n",
      "Epoch 60/200, Iteration 248/250, Loss: 0.0197\n",
      "Epoch 60/200, Iteration 249/250, Loss: 0.0079\n",
      "Epoch 60/200, Iteration 250/250, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 84.38%, Avg loss: 0.007560, MRE: 0.680424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.007622, MRE: 1.053948 \n",
      "\n",
      "Epoch 61/200, Iteration 1/250, Loss: 0.0174\n",
      "Epoch 61/200, Iteration 2/250, Loss: 0.0170\n",
      "Epoch 61/200, Iteration 3/250, Loss: 0.0148\n",
      "Epoch 61/200, Iteration 4/250, Loss: 0.0159\n",
      "Epoch 61/200, Iteration 5/250, Loss: 0.0120\n",
      "Epoch 61/200, Iteration 6/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 7/250, Loss: 0.0184\n",
      "Epoch 61/200, Iteration 8/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 9/250, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 10/250, Loss: 0.0258\n",
      "Epoch 61/200, Iteration 11/250, Loss: 0.0186\n",
      "Epoch 61/200, Iteration 12/250, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 13/250, Loss: 0.0200\n",
      "Epoch 61/200, Iteration 14/250, Loss: 0.0194\n",
      "Epoch 61/200, Iteration 15/250, Loss: 0.0211\n",
      "Epoch 61/200, Iteration 16/250, Loss: 0.0071\n",
      "Epoch 61/200, Iteration 17/250, Loss: 0.0188\n",
      "Epoch 61/200, Iteration 18/250, Loss: 0.0137\n",
      "Epoch 61/200, Iteration 19/250, Loss: 0.0180\n",
      "Epoch 61/200, Iteration 20/250, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 21/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 22/250, Loss: 0.0113\n",
      "Epoch 61/200, Iteration 23/250, Loss: 0.0203\n",
      "Epoch 61/200, Iteration 24/250, Loss: 0.0132\n",
      "Epoch 61/200, Iteration 25/250, Loss: 0.0113\n",
      "Epoch 61/200, Iteration 26/250, Loss: 0.0142\n",
      "Epoch 61/200, Iteration 27/250, Loss: 0.0462\n",
      "Epoch 61/200, Iteration 28/250, Loss: 0.0089\n",
      "Epoch 61/200, Iteration 29/250, Loss: 0.0137\n",
      "Epoch 61/200, Iteration 30/250, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 31/250, Loss: 0.0155\n",
      "Epoch 61/200, Iteration 32/250, Loss: 0.0091\n",
      "Epoch 61/200, Iteration 33/250, Loss: 0.0226\n",
      "Epoch 61/200, Iteration 34/250, Loss: 0.0159\n",
      "Epoch 61/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 61/200, Iteration 36/250, Loss: 0.0066\n",
      "Epoch 61/200, Iteration 37/250, Loss: 0.0078\n",
      "Epoch 61/200, Iteration 38/250, Loss: 0.0174\n",
      "Epoch 61/200, Iteration 39/250, Loss: 0.0115\n",
      "Epoch 61/200, Iteration 40/250, Loss: 0.0100\n",
      "Epoch 61/200, Iteration 41/250, Loss: 0.0181\n",
      "Epoch 61/200, Iteration 42/250, Loss: 0.0090\n",
      "Epoch 61/200, Iteration 43/250, Loss: 0.0070\n",
      "Epoch 61/200, Iteration 44/250, Loss: 0.0109\n",
      "Epoch 61/200, Iteration 45/250, Loss: 0.0244\n",
      "Epoch 61/200, Iteration 46/250, Loss: 0.0267\n",
      "Epoch 61/200, Iteration 47/250, Loss: 0.0228\n",
      "Epoch 61/200, Iteration 48/250, Loss: 0.0235\n",
      "Epoch 61/200, Iteration 49/250, Loss: 0.0142\n",
      "Epoch 61/200, Iteration 50/250, Loss: 0.0173\n",
      "Epoch 61/200, Iteration 51/250, Loss: 0.0149\n",
      "Epoch 61/200, Iteration 52/250, Loss: 0.0160\n",
      "Epoch 61/200, Iteration 53/250, Loss: 0.0117\n",
      "Epoch 61/200, Iteration 54/250, Loss: 0.0192\n",
      "Epoch 61/200, Iteration 55/250, Loss: 0.0109\n",
      "Epoch 61/200, Iteration 56/250, Loss: 0.0208\n",
      "Epoch 61/200, Iteration 57/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 58/250, Loss: 0.0245\n",
      "Epoch 61/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 61/200, Iteration 60/250, Loss: 0.0081\n",
      "Epoch 61/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 62/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 63/250, Loss: 0.0152\n",
      "Epoch 61/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 61/200, Iteration 65/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 66/250, Loss: 0.0252\n",
      "Epoch 61/200, Iteration 67/250, Loss: 0.0140\n",
      "Epoch 61/200, Iteration 68/250, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 69/250, Loss: 0.0078\n",
      "Epoch 61/200, Iteration 70/250, Loss: 0.0158\n",
      "Epoch 61/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 72/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 73/250, Loss: 0.0136\n",
      "Epoch 61/200, Iteration 74/250, Loss: 0.0096\n",
      "Epoch 61/200, Iteration 75/250, Loss: 0.0199\n",
      "Epoch 61/200, Iteration 76/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 77/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 78/250, Loss: 0.0259\n",
      "Epoch 61/200, Iteration 79/250, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 80/250, Loss: 0.0087\n",
      "Epoch 61/200, Iteration 81/250, Loss: 0.0175\n",
      "Epoch 61/200, Iteration 82/250, Loss: 0.0212\n",
      "Epoch 61/200, Iteration 83/250, Loss: 0.0091\n",
      "Epoch 61/200, Iteration 84/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 85/250, Loss: 0.0173\n",
      "Epoch 61/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 61/200, Iteration 87/250, Loss: 0.0279\n",
      "Epoch 61/200, Iteration 88/250, Loss: 0.0128\n",
      "Epoch 61/200, Iteration 89/250, Loss: 0.0325\n",
      "Epoch 61/200, Iteration 90/250, Loss: 0.0187\n",
      "Epoch 61/200, Iteration 91/250, Loss: 0.0194\n",
      "Epoch 61/200, Iteration 92/250, Loss: 0.0326\n",
      "Epoch 61/200, Iteration 93/250, Loss: 0.0087\n",
      "Epoch 61/200, Iteration 94/250, Loss: 0.0146\n",
      "Epoch 61/200, Iteration 95/250, Loss: 0.0114\n",
      "Epoch 61/200, Iteration 96/250, Loss: 0.0186\n",
      "Epoch 61/200, Iteration 97/250, Loss: 0.0191\n",
      "Epoch 61/200, Iteration 98/250, Loss: 0.0132\n",
      "Epoch 61/200, Iteration 99/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 100/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 101/250, Loss: 0.0217\n",
      "Epoch 61/200, Iteration 102/250, Loss: 0.0114\n",
      "Epoch 61/200, Iteration 103/250, Loss: 0.0129\n",
      "Epoch 61/200, Iteration 104/250, Loss: 0.0093\n",
      "Epoch 61/200, Iteration 105/250, Loss: 0.0220\n",
      "Epoch 61/200, Iteration 106/250, Loss: 0.0330\n",
      "Epoch 61/200, Iteration 107/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 108/250, Loss: 0.0282\n",
      "Epoch 61/200, Iteration 109/250, Loss: 0.0070\n",
      "Epoch 61/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 111/250, Loss: 0.0147\n",
      "Epoch 61/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 61/200, Iteration 113/250, Loss: 0.0256\n",
      "Epoch 61/200, Iteration 114/250, Loss: 0.0174\n",
      "Epoch 61/200, Iteration 115/250, Loss: 0.0091\n",
      "Epoch 61/200, Iteration 116/250, Loss: 0.0273\n",
      "Epoch 61/200, Iteration 117/250, Loss: 0.0239\n",
      "Epoch 61/200, Iteration 118/250, Loss: 0.0260\n",
      "Epoch 61/200, Iteration 119/250, Loss: 0.0387\n",
      "Epoch 61/200, Iteration 120/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 121/250, Loss: 0.0168\n",
      "Epoch 61/200, Iteration 122/250, Loss: 0.0085\n",
      "Epoch 61/200, Iteration 123/250, Loss: 0.0114\n",
      "Epoch 61/200, Iteration 124/250, Loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200, Iteration 125/250, Loss: 0.0224\n",
      "Epoch 61/200, Iteration 126/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 127/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 128/250, Loss: 0.0067\n",
      "Epoch 61/200, Iteration 129/250, Loss: 0.0242\n",
      "Epoch 61/200, Iteration 130/250, Loss: 0.0103\n",
      "Epoch 61/200, Iteration 131/250, Loss: 0.0195\n",
      "Epoch 61/200, Iteration 132/250, Loss: 0.0213\n",
      "Epoch 61/200, Iteration 133/250, Loss: 0.0087\n",
      "Epoch 61/200, Iteration 134/250, Loss: 0.0072\n",
      "Epoch 61/200, Iteration 135/250, Loss: 0.0224\n",
      "Epoch 61/200, Iteration 136/250, Loss: 0.0161\n",
      "Epoch 61/200, Iteration 137/250, Loss: 0.0082\n",
      "Epoch 61/200, Iteration 138/250, Loss: 0.0137\n",
      "Epoch 61/200, Iteration 139/250, Loss: 0.0127\n",
      "Epoch 61/200, Iteration 140/250, Loss: 0.0408\n",
      "Epoch 61/200, Iteration 141/250, Loss: 0.0108\n",
      "Epoch 61/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 61/200, Iteration 143/250, Loss: 0.0140\n",
      "Epoch 61/200, Iteration 144/250, Loss: 0.0159\n",
      "Epoch 61/200, Iteration 145/250, Loss: 0.0184\n",
      "Epoch 61/200, Iteration 146/250, Loss: 0.0153\n",
      "Epoch 61/200, Iteration 147/250, Loss: 0.0347\n",
      "Epoch 61/200, Iteration 148/250, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 149/250, Loss: 0.0127\n",
      "Epoch 61/200, Iteration 150/250, Loss: 0.0079\n",
      "Epoch 61/200, Iteration 151/250, Loss: 0.0153\n",
      "Epoch 61/200, Iteration 152/250, Loss: 0.0101\n",
      "Epoch 61/200, Iteration 153/250, Loss: 0.0078\n",
      "Epoch 61/200, Iteration 154/250, Loss: 0.0157\n",
      "Epoch 61/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 61/200, Iteration 156/250, Loss: 0.0210\n",
      "Epoch 61/200, Iteration 157/250, Loss: 0.0147\n",
      "Epoch 61/200, Iteration 158/250, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 159/250, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 160/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 161/250, Loss: 0.0350\n",
      "Epoch 61/200, Iteration 162/250, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 163/250, Loss: 0.0124\n",
      "Epoch 61/200, Iteration 164/250, Loss: 0.0207\n",
      "Epoch 61/200, Iteration 165/250, Loss: 0.0214\n",
      "Epoch 61/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 167/250, Loss: 0.0144\n",
      "Epoch 61/200, Iteration 168/250, Loss: 0.0273\n",
      "Epoch 61/200, Iteration 169/250, Loss: 0.0326\n",
      "Epoch 61/200, Iteration 170/250, Loss: 0.0088\n",
      "Epoch 61/200, Iteration 171/250, Loss: 0.0261\n",
      "Epoch 61/200, Iteration 172/250, Loss: 0.0215\n",
      "Epoch 61/200, Iteration 173/250, Loss: 0.0149\n",
      "Epoch 61/200, Iteration 174/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 175/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 176/250, Loss: 0.0100\n",
      "Epoch 61/200, Iteration 177/250, Loss: 0.0267\n",
      "Epoch 61/200, Iteration 178/250, Loss: 0.0075\n",
      "Epoch 61/200, Iteration 179/250, Loss: 0.0087\n",
      "Epoch 61/200, Iteration 180/250, Loss: 0.0105\n",
      "Epoch 61/200, Iteration 181/250, Loss: 0.0246\n",
      "Epoch 61/200, Iteration 182/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 183/250, Loss: 0.0157\n",
      "Epoch 61/200, Iteration 184/250, Loss: 0.0155\n",
      "Epoch 61/200, Iteration 185/250, Loss: 0.0265\n",
      "Epoch 61/200, Iteration 186/250, Loss: 0.0326\n",
      "Epoch 61/200, Iteration 187/250, Loss: 0.0214\n",
      "Epoch 61/200, Iteration 188/250, Loss: 0.0203\n",
      "Epoch 61/200, Iteration 189/250, Loss: 0.0292\n",
      "Epoch 61/200, Iteration 190/250, Loss: 0.0097\n",
      "Epoch 61/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 61/200, Iteration 192/250, Loss: 0.0152\n",
      "Epoch 61/200, Iteration 193/250, Loss: 0.0182\n",
      "Epoch 61/200, Iteration 194/250, Loss: 0.0201\n",
      "Epoch 61/200, Iteration 195/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 196/250, Loss: 0.0224\n",
      "Epoch 61/200, Iteration 197/250, Loss: 0.0209\n",
      "Epoch 61/200, Iteration 198/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 199/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 200/250, Loss: 0.0317\n",
      "Epoch 61/200, Iteration 201/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 202/250, Loss: 0.0146\n",
      "Epoch 61/200, Iteration 203/250, Loss: 0.0089\n",
      "Epoch 61/200, Iteration 204/250, Loss: 0.0075\n",
      "Epoch 61/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 61/200, Iteration 206/250, Loss: 0.0211\n",
      "Epoch 61/200, Iteration 207/250, Loss: 0.0112\n",
      "Epoch 61/200, Iteration 208/250, Loss: 0.0166\n",
      "Epoch 61/200, Iteration 209/250, Loss: 0.0237\n",
      "Epoch 61/200, Iteration 210/250, Loss: 0.0130\n",
      "Epoch 61/200, Iteration 211/250, Loss: 0.0186\n",
      "Epoch 61/200, Iteration 212/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 213/250, Loss: 0.0160\n",
      "Epoch 61/200, Iteration 214/250, Loss: 0.0110\n",
      "Epoch 61/200, Iteration 215/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 216/250, Loss: 0.0112\n",
      "Epoch 61/200, Iteration 217/250, Loss: 0.0166\n",
      "Epoch 61/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 61/200, Iteration 219/250, Loss: 0.0120\n",
      "Epoch 61/200, Iteration 220/250, Loss: 0.0387\n",
      "Epoch 61/200, Iteration 221/250, Loss: 0.0110\n",
      "Epoch 61/200, Iteration 222/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 223/250, Loss: 0.0110\n",
      "Epoch 61/200, Iteration 224/250, Loss: 0.0158\n",
      "Epoch 61/200, Iteration 225/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 226/250, Loss: 0.0266\n",
      "Epoch 61/200, Iteration 227/250, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 228/250, Loss: 0.0293\n",
      "Epoch 61/200, Iteration 229/250, Loss: 0.0155\n",
      "Epoch 61/200, Iteration 230/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 231/250, Loss: 0.0235\n",
      "Epoch 61/200, Iteration 232/250, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 233/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 234/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 235/250, Loss: 0.0186\n",
      "Epoch 61/200, Iteration 236/250, Loss: 0.0117\n",
      "Epoch 61/200, Iteration 237/250, Loss: 0.0270\n",
      "Epoch 61/200, Iteration 238/250, Loss: 0.0388\n",
      "Epoch 61/200, Iteration 239/250, Loss: 0.0364\n",
      "Epoch 61/200, Iteration 240/250, Loss: 0.0144\n",
      "Epoch 61/200, Iteration 241/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 242/250, Loss: 0.0155\n",
      "Epoch 61/200, Iteration 243/250, Loss: 0.0363\n",
      "Epoch 61/200, Iteration 244/250, Loss: 0.0142\n",
      "Epoch 61/200, Iteration 245/250, Loss: 0.0121\n",
      "Epoch 61/200, Iteration 246/250, Loss: 0.0091\n",
      "Epoch 61/200, Iteration 247/250, Loss: 0.0160\n",
      "Epoch 61/200, Iteration 248/250, Loss: 0.0135\n",
      "Epoch 61/200, Iteration 249/250, Loss: 0.0139\n",
      "Epoch 61/200, Iteration 250/250, Loss: 0.0228\n",
      "Train Error: \n",
      " Accuracy: 83.11%, Avg loss: 0.007437, MRE: 0.617598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.007528, MRE: 0.946013 \n",
      "\n",
      "Epoch 62/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 62/200, Iteration 2/250, Loss: 0.0275\n",
      "Epoch 62/200, Iteration 3/250, Loss: 0.0132\n",
      "Epoch 62/200, Iteration 4/250, Loss: 0.0207\n",
      "Epoch 62/200, Iteration 5/250, Loss: 0.0144\n",
      "Epoch 62/200, Iteration 6/250, Loss: 0.0138\n",
      "Epoch 62/200, Iteration 7/250, Loss: 0.0146\n",
      "Epoch 62/200, Iteration 8/250, Loss: 0.0376\n",
      "Epoch 62/200, Iteration 9/250, Loss: 0.0139\n",
      "Epoch 62/200, Iteration 10/250, Loss: 0.0188\n",
      "Epoch 62/200, Iteration 11/250, Loss: 0.0125\n",
      "Epoch 62/200, Iteration 12/250, Loss: 0.0116\n",
      "Epoch 62/200, Iteration 13/250, Loss: 0.0088\n",
      "Epoch 62/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 62/200, Iteration 15/250, Loss: 0.0113\n",
      "Epoch 62/200, Iteration 16/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 17/250, Loss: 0.0069\n",
      "Epoch 62/200, Iteration 18/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 19/250, Loss: 0.0154\n",
      "Epoch 62/200, Iteration 20/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 21/250, Loss: 0.0274\n",
      "Epoch 62/200, Iteration 22/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 24/250, Loss: 0.0162\n",
      "Epoch 62/200, Iteration 25/250, Loss: 0.0073\n",
      "Epoch 62/200, Iteration 26/250, Loss: 0.0113\n",
      "Epoch 62/200, Iteration 27/250, Loss: 0.0098\n",
      "Epoch 62/200, Iteration 28/250, Loss: 0.0062\n",
      "Epoch 62/200, Iteration 29/250, Loss: 0.0159\n",
      "Epoch 62/200, Iteration 30/250, Loss: 0.0140\n",
      "Epoch 62/200, Iteration 31/250, Loss: 0.0244\n",
      "Epoch 62/200, Iteration 32/250, Loss: 0.0083\n",
      "Epoch 62/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 35/250, Loss: 0.0082\n",
      "Epoch 62/200, Iteration 36/250, Loss: 0.0204\n",
      "Epoch 62/200, Iteration 37/250, Loss: 0.0090\n",
      "Epoch 62/200, Iteration 38/250, Loss: 0.0190\n",
      "Epoch 62/200, Iteration 39/250, Loss: 0.0116\n",
      "Epoch 62/200, Iteration 40/250, Loss: 0.0142\n",
      "Epoch 62/200, Iteration 41/250, Loss: 0.0142\n",
      "Epoch 62/200, Iteration 42/250, Loss: 0.0075\n",
      "Epoch 62/200, Iteration 43/250, Loss: 0.0267\n",
      "Epoch 62/200, Iteration 44/250, Loss: 0.0121\n",
      "Epoch 62/200, Iteration 45/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 46/250, Loss: 0.0118\n",
      "Epoch 62/200, Iteration 47/250, Loss: 0.0131\n",
      "Epoch 62/200, Iteration 48/250, Loss: 0.0197\n",
      "Epoch 62/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 50/250, Loss: 0.0086\n",
      "Epoch 62/200, Iteration 51/250, Loss: 0.0198\n",
      "Epoch 62/200, Iteration 52/250, Loss: 0.0076\n",
      "Epoch 62/200, Iteration 53/250, Loss: 0.0077\n",
      "Epoch 62/200, Iteration 54/250, Loss: 0.0190\n",
      "Epoch 62/200, Iteration 55/250, Loss: 0.0103\n",
      "Epoch 62/200, Iteration 56/250, Loss: 0.0080\n",
      "Epoch 62/200, Iteration 57/250, Loss: 0.0232\n",
      "Epoch 62/200, Iteration 58/250, Loss: 0.0307\n",
      "Epoch 62/200, Iteration 59/250, Loss: 0.0244\n",
      "Epoch 62/200, Iteration 60/250, Loss: 0.0131\n",
      "Epoch 62/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 62/200, Iteration 62/250, Loss: 0.0293\n",
      "Epoch 62/200, Iteration 63/250, Loss: 0.0136\n",
      "Epoch 62/200, Iteration 64/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 65/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 66/250, Loss: 0.0237\n",
      "Epoch 62/200, Iteration 67/250, Loss: 0.0088\n",
      "Epoch 62/200, Iteration 68/250, Loss: 0.0193\n",
      "Epoch 62/200, Iteration 69/250, Loss: 0.0079\n",
      "Epoch 62/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 71/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 72/250, Loss: 0.0073\n",
      "Epoch 62/200, Iteration 73/250, Loss: 0.0334\n",
      "Epoch 62/200, Iteration 74/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 76/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 77/250, Loss: 0.0154\n",
      "Epoch 62/200, Iteration 78/250, Loss: 0.0186\n",
      "Epoch 62/200, Iteration 79/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 80/250, Loss: 0.0071\n",
      "Epoch 62/200, Iteration 81/250, Loss: 0.0098\n",
      "Epoch 62/200, Iteration 82/250, Loss: 0.0182\n",
      "Epoch 62/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 62/200, Iteration 84/250, Loss: 0.0094\n",
      "Epoch 62/200, Iteration 85/250, Loss: 0.0087\n",
      "Epoch 62/200, Iteration 86/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 87/250, Loss: 0.0251\n",
      "Epoch 62/200, Iteration 88/250, Loss: 0.0113\n",
      "Epoch 62/200, Iteration 89/250, Loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200, Iteration 90/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 91/250, Loss: 0.0162\n",
      "Epoch 62/200, Iteration 92/250, Loss: 0.0163\n",
      "Epoch 62/200, Iteration 93/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 94/250, Loss: 0.0148\n",
      "Epoch 62/200, Iteration 95/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 96/250, Loss: 0.0243\n",
      "Epoch 62/200, Iteration 97/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 98/250, Loss: 0.0161\n",
      "Epoch 62/200, Iteration 99/250, Loss: 0.0216\n",
      "Epoch 62/200, Iteration 100/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 101/250, Loss: 0.0246\n",
      "Epoch 62/200, Iteration 102/250, Loss: 0.0211\n",
      "Epoch 62/200, Iteration 103/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 104/250, Loss: 0.0204\n",
      "Epoch 62/200, Iteration 105/250, Loss: 0.0297\n",
      "Epoch 62/200, Iteration 106/250, Loss: 0.0170\n",
      "Epoch 62/200, Iteration 107/250, Loss: 0.0185\n",
      "Epoch 62/200, Iteration 108/250, Loss: 0.0146\n",
      "Epoch 62/200, Iteration 109/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 110/250, Loss: 0.0201\n",
      "Epoch 62/200, Iteration 111/250, Loss: 0.0114\n",
      "Epoch 62/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 62/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 62/200, Iteration 114/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 115/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 116/250, Loss: 0.0187\n",
      "Epoch 62/200, Iteration 117/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 118/250, Loss: 0.0079\n",
      "Epoch 62/200, Iteration 119/250, Loss: 0.0207\n",
      "Epoch 62/200, Iteration 120/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 121/250, Loss: 0.0245\n",
      "Epoch 62/200, Iteration 122/250, Loss: 0.0232\n",
      "Epoch 62/200, Iteration 123/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 124/250, Loss: 0.0182\n",
      "Epoch 62/200, Iteration 125/250, Loss: 0.0450\n",
      "Epoch 62/200, Iteration 126/250, Loss: 0.0133\n",
      "Epoch 62/200, Iteration 127/250, Loss: 0.0141\n",
      "Epoch 62/200, Iteration 128/250, Loss: 0.0123\n",
      "Epoch 62/200, Iteration 129/250, Loss: 0.0095\n",
      "Epoch 62/200, Iteration 130/250, Loss: 0.0138\n",
      "Epoch 62/200, Iteration 131/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 62/200, Iteration 133/250, Loss: 0.0085\n",
      "Epoch 62/200, Iteration 134/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 135/250, Loss: 0.0189\n",
      "Epoch 62/200, Iteration 136/250, Loss: 0.0132\n",
      "Epoch 62/200, Iteration 137/250, Loss: 0.0202\n",
      "Epoch 62/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 62/200, Iteration 139/250, Loss: 0.0177\n",
      "Epoch 62/200, Iteration 140/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 141/250, Loss: 0.0135\n",
      "Epoch 62/200, Iteration 142/250, Loss: 0.0128\n",
      "Epoch 62/200, Iteration 143/250, Loss: 0.0246\n",
      "Epoch 62/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 145/250, Loss: 0.0075\n",
      "Epoch 62/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 147/250, Loss: 0.0323\n",
      "Epoch 62/200, Iteration 148/250, Loss: 0.0135\n",
      "Epoch 62/200, Iteration 149/250, Loss: 0.0152\n",
      "Epoch 62/200, Iteration 150/250, Loss: 0.0109\n",
      "Epoch 62/200, Iteration 151/250, Loss: 0.0198\n",
      "Epoch 62/200, Iteration 152/250, Loss: 0.0284\n",
      "Epoch 62/200, Iteration 153/250, Loss: 0.0087\n",
      "Epoch 62/200, Iteration 154/250, Loss: 0.0177\n",
      "Epoch 62/200, Iteration 155/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 156/250, Loss: 0.0094\n",
      "Epoch 62/200, Iteration 157/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 158/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 159/250, Loss: 0.0138\n",
      "Epoch 62/200, Iteration 160/250, Loss: 0.0128\n",
      "Epoch 62/200, Iteration 161/250, Loss: 0.0097\n",
      "Epoch 62/200, Iteration 162/250, Loss: 0.0065\n",
      "Epoch 62/200, Iteration 163/250, Loss: 0.0290\n",
      "Epoch 62/200, Iteration 164/250, Loss: 0.0193\n",
      "Epoch 62/200, Iteration 165/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 166/250, Loss: 0.0262\n",
      "Epoch 62/200, Iteration 167/250, Loss: 0.0213\n",
      "Epoch 62/200, Iteration 168/250, Loss: 0.0081\n",
      "Epoch 62/200, Iteration 169/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 170/250, Loss: 0.0233\n",
      "Epoch 62/200, Iteration 171/250, Loss: 0.0150\n",
      "Epoch 62/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 62/200, Iteration 175/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 176/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 177/250, Loss: 0.0134\n",
      "Epoch 62/200, Iteration 178/250, Loss: 0.0111\n",
      "Epoch 62/200, Iteration 179/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 180/250, Loss: 0.0133\n",
      "Epoch 62/200, Iteration 181/250, Loss: 0.0171\n",
      "Epoch 62/200, Iteration 182/250, Loss: 0.0242\n",
      "Epoch 62/200, Iteration 183/250, Loss: 0.0287\n",
      "Epoch 62/200, Iteration 184/250, Loss: 0.0074\n",
      "Epoch 62/200, Iteration 185/250, Loss: 0.0094\n",
      "Epoch 62/200, Iteration 186/250, Loss: 0.0124\n",
      "Epoch 62/200, Iteration 187/250, Loss: 0.0115\n",
      "Epoch 62/200, Iteration 188/250, Loss: 0.0402\n",
      "Epoch 62/200, Iteration 189/250, Loss: 0.0120\n",
      "Epoch 62/200, Iteration 190/250, Loss: 0.0268\n",
      "Epoch 62/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 62/200, Iteration 192/250, Loss: 0.0200\n",
      "Epoch 62/200, Iteration 193/250, Loss: 0.0111\n",
      "Epoch 62/200, Iteration 194/250, Loss: 0.0127\n",
      "Epoch 62/200, Iteration 195/250, Loss: 0.0218\n",
      "Epoch 62/200, Iteration 196/250, Loss: 0.0127\n",
      "Epoch 62/200, Iteration 197/250, Loss: 0.0104\n",
      "Epoch 62/200, Iteration 198/250, Loss: 0.0110\n",
      "Epoch 62/200, Iteration 199/250, Loss: 0.0149\n",
      "Epoch 62/200, Iteration 200/250, Loss: 0.0250\n",
      "Epoch 62/200, Iteration 201/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 202/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 203/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 204/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 205/250, Loss: 0.0117\n",
      "Epoch 62/200, Iteration 206/250, Loss: 0.0140\n",
      "Epoch 62/200, Iteration 207/250, Loss: 0.0133\n",
      "Epoch 62/200, Iteration 208/250, Loss: 0.0128\n",
      "Epoch 62/200, Iteration 209/250, Loss: 0.0082\n",
      "Epoch 62/200, Iteration 210/250, Loss: 0.0334\n",
      "Epoch 62/200, Iteration 211/250, Loss: 0.0112\n",
      "Epoch 62/200, Iteration 212/250, Loss: 0.0290\n",
      "Epoch 62/200, Iteration 213/250, Loss: 0.0289\n",
      "Epoch 62/200, Iteration 214/250, Loss: 0.0149\n",
      "Epoch 62/200, Iteration 215/250, Loss: 0.0115\n",
      "Epoch 62/200, Iteration 216/250, Loss: 0.0183\n",
      "Epoch 62/200, Iteration 217/250, Loss: 0.0160\n",
      "Epoch 62/200, Iteration 218/250, Loss: 0.0183\n",
      "Epoch 62/200, Iteration 219/250, Loss: 0.0087\n",
      "Epoch 62/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 221/250, Loss: 0.0104\n",
      "Epoch 62/200, Iteration 222/250, Loss: 0.0136\n",
      "Epoch 62/200, Iteration 223/250, Loss: 0.0232\n",
      "Epoch 62/200, Iteration 224/250, Loss: 0.0125\n",
      "Epoch 62/200, Iteration 225/250, Loss: 0.0158\n",
      "Epoch 62/200, Iteration 226/250, Loss: 0.0113\n",
      "Epoch 62/200, Iteration 227/250, Loss: 0.0134\n",
      "Epoch 62/200, Iteration 228/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 62/200, Iteration 230/250, Loss: 0.0106\n",
      "Epoch 62/200, Iteration 231/250, Loss: 0.0239\n",
      "Epoch 62/200, Iteration 232/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 233/250, Loss: 0.0166\n",
      "Epoch 62/200, Iteration 234/250, Loss: 0.0181\n",
      "Epoch 62/200, Iteration 235/250, Loss: 0.0118\n",
      "Epoch 62/200, Iteration 236/250, Loss: 0.0185\n",
      "Epoch 62/200, Iteration 237/250, Loss: 0.0268\n",
      "Epoch 62/200, Iteration 238/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 239/250, Loss: 0.0134\n",
      "Epoch 62/200, Iteration 240/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 241/250, Loss: 0.0229\n",
      "Epoch 62/200, Iteration 242/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 243/250, Loss: 0.0153\n",
      "Epoch 62/200, Iteration 244/250, Loss: 0.0216\n",
      "Epoch 62/200, Iteration 245/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 246/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 247/250, Loss: 0.0150\n",
      "Epoch 62/200, Iteration 248/250, Loss: 0.0111\n",
      "Epoch 62/200, Iteration 249/250, Loss: 0.0112\n",
      "Epoch 62/200, Iteration 250/250, Loss: 0.0123\n",
      "Train Error: \n",
      " Accuracy: 92.14%, Avg loss: 0.006641, MRE: 0.700572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.006638, MRE: 1.022519 \n",
      "\n",
      "Epoch 63/200, Iteration 1/250, Loss: 0.0130\n",
      "Epoch 63/200, Iteration 2/250, Loss: 0.0087\n",
      "Epoch 63/200, Iteration 3/250, Loss: 0.0174\n",
      "Epoch 63/200, Iteration 4/250, Loss: 0.0155\n",
      "Epoch 63/200, Iteration 5/250, Loss: 0.0240\n",
      "Epoch 63/200, Iteration 6/250, Loss: 0.0149\n",
      "Epoch 63/200, Iteration 7/250, Loss: 0.0058\n",
      "Epoch 63/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 9/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 10/250, Loss: 0.0119\n",
      "Epoch 63/200, Iteration 11/250, Loss: 0.0084\n",
      "Epoch 63/200, Iteration 12/250, Loss: 0.0184\n",
      "Epoch 63/200, Iteration 13/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 14/250, Loss: 0.0224\n",
      "Epoch 63/200, Iteration 15/250, Loss: 0.0054\n",
      "Epoch 63/200, Iteration 16/250, Loss: 0.0182\n",
      "Epoch 63/200, Iteration 17/250, Loss: 0.0073\n",
      "Epoch 63/200, Iteration 18/250, Loss: 0.0207\n",
      "Epoch 63/200, Iteration 19/250, Loss: 0.0136\n",
      "Epoch 63/200, Iteration 20/250, Loss: 0.0208\n",
      "Epoch 63/200, Iteration 21/250, Loss: 0.0124\n",
      "Epoch 63/200, Iteration 22/250, Loss: 0.0194\n",
      "Epoch 63/200, Iteration 23/250, Loss: 0.0102\n",
      "Epoch 63/200, Iteration 24/250, Loss: 0.0119\n",
      "Epoch 63/200, Iteration 25/250, Loss: 0.0080\n",
      "Epoch 63/200, Iteration 26/250, Loss: 0.0142\n",
      "Epoch 63/200, Iteration 27/250, Loss: 0.0166\n",
      "Epoch 63/200, Iteration 28/250, Loss: 0.0187\n",
      "Epoch 63/200, Iteration 29/250, Loss: 0.0083\n",
      "Epoch 63/200, Iteration 30/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 31/250, Loss: 0.0384\n",
      "Epoch 63/200, Iteration 32/250, Loss: 0.0247\n",
      "Epoch 63/200, Iteration 33/250, Loss: 0.0210\n",
      "Epoch 63/200, Iteration 34/250, Loss: 0.0164\n",
      "Epoch 63/200, Iteration 35/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 36/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 37/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 39/250, Loss: 0.0160\n",
      "Epoch 63/200, Iteration 40/250, Loss: 0.0089\n",
      "Epoch 63/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 63/200, Iteration 42/250, Loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Iteration 43/250, Loss: 0.0077\n",
      "Epoch 63/200, Iteration 44/250, Loss: 0.0125\n",
      "Epoch 63/200, Iteration 45/250, Loss: 0.0163\n",
      "Epoch 63/200, Iteration 46/250, Loss: 0.0063\n",
      "Epoch 63/200, Iteration 47/250, Loss: 0.0152\n",
      "Epoch 63/200, Iteration 48/250, Loss: 0.0344\n",
      "Epoch 63/200, Iteration 49/250, Loss: 0.0193\n",
      "Epoch 63/200, Iteration 50/250, Loss: 0.0118\n",
      "Epoch 63/200, Iteration 51/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 52/250, Loss: 0.0178\n",
      "Epoch 63/200, Iteration 53/250, Loss: 0.0220\n",
      "Epoch 63/200, Iteration 54/250, Loss: 0.0152\n",
      "Epoch 63/200, Iteration 55/250, Loss: 0.0658\n",
      "Epoch 63/200, Iteration 56/250, Loss: 0.0175\n",
      "Epoch 63/200, Iteration 57/250, Loss: 0.0120\n",
      "Epoch 63/200, Iteration 58/250, Loss: 0.0125\n",
      "Epoch 63/200, Iteration 59/250, Loss: 0.0172\n",
      "Epoch 63/200, Iteration 60/250, Loss: 0.0153\n",
      "Epoch 63/200, Iteration 61/250, Loss: 0.0076\n",
      "Epoch 63/200, Iteration 62/250, Loss: 0.0216\n",
      "Epoch 63/200, Iteration 63/250, Loss: 0.0101\n",
      "Epoch 63/200, Iteration 64/250, Loss: 0.0137\n",
      "Epoch 63/200, Iteration 65/250, Loss: 0.0227\n",
      "Epoch 63/200, Iteration 66/250, Loss: 0.0173\n",
      "Epoch 63/200, Iteration 67/250, Loss: 0.0160\n",
      "Epoch 63/200, Iteration 68/250, Loss: 0.0144\n",
      "Epoch 63/200, Iteration 69/250, Loss: 0.0101\n",
      "Epoch 63/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 63/200, Iteration 71/250, Loss: 0.0123\n",
      "Epoch 63/200, Iteration 72/250, Loss: 0.0117\n",
      "Epoch 63/200, Iteration 73/250, Loss: 0.0170\n",
      "Epoch 63/200, Iteration 74/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 75/250, Loss: 0.0101\n",
      "Epoch 63/200, Iteration 76/250, Loss: 0.0207\n",
      "Epoch 63/200, Iteration 77/250, Loss: 0.0180\n",
      "Epoch 63/200, Iteration 78/250, Loss: 0.0098\n",
      "Epoch 63/200, Iteration 79/250, Loss: 0.0411\n",
      "Epoch 63/200, Iteration 80/250, Loss: 0.0306\n",
      "Epoch 63/200, Iteration 81/250, Loss: 0.0141\n",
      "Epoch 63/200, Iteration 82/250, Loss: 0.0200\n",
      "Epoch 63/200, Iteration 83/250, Loss: 0.0103\n",
      "Epoch 63/200, Iteration 84/250, Loss: 0.0078\n",
      "Epoch 63/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 63/200, Iteration 86/250, Loss: 0.0212\n",
      "Epoch 63/200, Iteration 87/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 88/250, Loss: 0.0161\n",
      "Epoch 63/200, Iteration 89/250, Loss: 0.0180\n",
      "Epoch 63/200, Iteration 90/250, Loss: 0.0177\n",
      "Epoch 63/200, Iteration 91/250, Loss: 0.0192\n",
      "Epoch 63/200, Iteration 92/250, Loss: 0.0140\n",
      "Epoch 63/200, Iteration 93/250, Loss: 0.0218\n",
      "Epoch 63/200, Iteration 94/250, Loss: 0.0186\n",
      "Epoch 63/200, Iteration 95/250, Loss: 0.0308\n",
      "Epoch 63/200, Iteration 96/250, Loss: 0.0147\n",
      "Epoch 63/200, Iteration 97/250, Loss: 0.0230\n",
      "Epoch 63/200, Iteration 98/250, Loss: 0.0112\n",
      "Epoch 63/200, Iteration 99/250, Loss: 0.0140\n",
      "Epoch 63/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 63/200, Iteration 101/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 102/250, Loss: 0.0099\n",
      "Epoch 63/200, Iteration 103/250, Loss: 0.0079\n",
      "Epoch 63/200, Iteration 104/250, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 105/250, Loss: 0.0076\n",
      "Epoch 63/200, Iteration 106/250, Loss: 0.0150\n",
      "Epoch 63/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 108/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 109/250, Loss: 0.0157\n",
      "Epoch 63/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 63/200, Iteration 111/250, Loss: 0.0129\n",
      "Epoch 63/200, Iteration 112/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 113/250, Loss: 0.0403\n",
      "Epoch 63/200, Iteration 114/250, Loss: 0.0204\n",
      "Epoch 63/200, Iteration 115/250, Loss: 0.0303\n",
      "Epoch 63/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 117/250, Loss: 0.0232\n",
      "Epoch 63/200, Iteration 118/250, Loss: 0.0079\n",
      "Epoch 63/200, Iteration 119/250, Loss: 0.0086\n",
      "Epoch 63/200, Iteration 120/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 121/250, Loss: 0.0163\n",
      "Epoch 63/200, Iteration 122/250, Loss: 0.0101\n",
      "Epoch 63/200, Iteration 123/250, Loss: 0.0225\n",
      "Epoch 63/200, Iteration 124/250, Loss: 0.0185\n",
      "Epoch 63/200, Iteration 125/250, Loss: 0.0259\n",
      "Epoch 63/200, Iteration 126/250, Loss: 0.0322\n",
      "Epoch 63/200, Iteration 127/250, Loss: 0.0176\n",
      "Epoch 63/200, Iteration 128/250, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 129/250, Loss: 0.0335\n",
      "Epoch 63/200, Iteration 130/250, Loss: 0.0162\n",
      "Epoch 63/200, Iteration 131/250, Loss: 0.0102\n",
      "Epoch 63/200, Iteration 132/250, Loss: 0.0372\n",
      "Epoch 63/200, Iteration 133/250, Loss: 0.0072\n",
      "Epoch 63/200, Iteration 134/250, Loss: 0.0187\n",
      "Epoch 63/200, Iteration 135/250, Loss: 0.0070\n",
      "Epoch 63/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 137/250, Loss: 0.0192\n",
      "Epoch 63/200, Iteration 138/250, Loss: 0.0392\n",
      "Epoch 63/200, Iteration 139/250, Loss: 0.0131\n",
      "Epoch 63/200, Iteration 140/250, Loss: 0.0354\n",
      "Epoch 63/200, Iteration 141/250, Loss: 0.0114\n",
      "Epoch 63/200, Iteration 142/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 143/250, Loss: 0.0163\n",
      "Epoch 63/200, Iteration 144/250, Loss: 0.0482\n",
      "Epoch 63/200, Iteration 145/250, Loss: 0.0271\n",
      "Epoch 63/200, Iteration 146/250, Loss: 0.0123\n",
      "Epoch 63/200, Iteration 147/250, Loss: 0.0176\n",
      "Epoch 63/200, Iteration 148/250, Loss: 0.0078\n",
      "Epoch 63/200, Iteration 149/250, Loss: 0.0207\n",
      "Epoch 63/200, Iteration 150/250, Loss: 0.0148\n",
      "Epoch 63/200, Iteration 151/250, Loss: 0.0241\n",
      "Epoch 63/200, Iteration 152/250, Loss: 0.0072\n",
      "Epoch 63/200, Iteration 153/250, Loss: 0.0129\n",
      "Epoch 63/200, Iteration 154/250, Loss: 0.0165\n",
      "Epoch 63/200, Iteration 155/250, Loss: 0.0245\n",
      "Epoch 63/200, Iteration 156/250, Loss: 0.0160\n",
      "Epoch 63/200, Iteration 157/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 158/250, Loss: 0.0165\n",
      "Epoch 63/200, Iteration 159/250, Loss: 0.0108\n",
      "Epoch 63/200, Iteration 160/250, Loss: 0.0139\n",
      "Epoch 63/200, Iteration 161/250, Loss: 0.0134\n",
      "Epoch 63/200, Iteration 162/250, Loss: 0.0207\n",
      "Epoch 63/200, Iteration 163/250, Loss: 0.0223\n",
      "Epoch 63/200, Iteration 164/250, Loss: 0.0154\n",
      "Epoch 63/200, Iteration 165/250, Loss: 0.0184\n",
      "Epoch 63/200, Iteration 166/250, Loss: 0.0248\n",
      "Epoch 63/200, Iteration 167/250, Loss: 0.0202\n",
      "Epoch 63/200, Iteration 168/250, Loss: 0.0169\n",
      "Epoch 63/200, Iteration 169/250, Loss: 0.0157\n",
      "Epoch 63/200, Iteration 170/250, Loss: 0.0390\n",
      "Epoch 63/200, Iteration 171/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 172/250, Loss: 0.0116\n",
      "Epoch 63/200, Iteration 173/250, Loss: 0.0103\n",
      "Epoch 63/200, Iteration 174/250, Loss: 0.0211\n",
      "Epoch 63/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 63/200, Iteration 176/250, Loss: 0.0165\n",
      "Epoch 63/200, Iteration 177/250, Loss: 0.0411\n",
      "Epoch 63/200, Iteration 178/250, Loss: 0.0173\n",
      "Epoch 63/200, Iteration 179/250, Loss: 0.0249\n",
      "Epoch 63/200, Iteration 180/250, Loss: 0.0117\n",
      "Epoch 63/200, Iteration 181/250, Loss: 0.0123\n",
      "Epoch 63/200, Iteration 182/250, Loss: 0.0190\n",
      "Epoch 63/200, Iteration 183/250, Loss: 0.0102\n",
      "Epoch 63/200, Iteration 184/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 185/250, Loss: 0.0238\n",
      "Epoch 63/200, Iteration 186/250, Loss: 0.0363\n",
      "Epoch 63/200, Iteration 187/250, Loss: 0.0315\n",
      "Epoch 63/200, Iteration 188/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 189/250, Loss: 0.0162\n",
      "Epoch 63/200, Iteration 190/250, Loss: 0.0126\n",
      "Epoch 63/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 63/200, Iteration 192/250, Loss: 0.0176\n",
      "Epoch 63/200, Iteration 193/250, Loss: 0.0217\n",
      "Epoch 63/200, Iteration 194/250, Loss: 0.0181\n",
      "Epoch 63/200, Iteration 195/250, Loss: 0.0099\n",
      "Epoch 63/200, Iteration 196/250, Loss: 0.0064\n",
      "Epoch 63/200, Iteration 197/250, Loss: 0.0201\n",
      "Epoch 63/200, Iteration 198/250, Loss: 0.0169\n",
      "Epoch 63/200, Iteration 199/250, Loss: 0.0306\n",
      "Epoch 63/200, Iteration 200/250, Loss: 0.0069\n",
      "Epoch 63/200, Iteration 201/250, Loss: 0.0225\n",
      "Epoch 63/200, Iteration 202/250, Loss: 0.0148\n",
      "Epoch 63/200, Iteration 203/250, Loss: 0.0144\n",
      "Epoch 63/200, Iteration 204/250, Loss: 0.0149\n",
      "Epoch 63/200, Iteration 205/250, Loss: 0.0250\n",
      "Epoch 63/200, Iteration 206/250, Loss: 0.0176\n",
      "Epoch 63/200, Iteration 207/250, Loss: 0.0250\n",
      "Epoch 63/200, Iteration 208/250, Loss: 0.0235\n",
      "Epoch 63/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 210/250, Loss: 0.0152\n",
      "Epoch 63/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 212/250, Loss: 0.0245\n",
      "Epoch 63/200, Iteration 213/250, Loss: 0.0181\n",
      "Epoch 63/200, Iteration 214/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 215/250, Loss: 0.0064\n",
      "Epoch 63/200, Iteration 216/250, Loss: 0.0258\n",
      "Epoch 63/200, Iteration 217/250, Loss: 0.0204\n",
      "Epoch 63/200, Iteration 218/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 219/250, Loss: 0.0203\n",
      "Epoch 63/200, Iteration 220/250, Loss: 0.0217\n",
      "Epoch 63/200, Iteration 221/250, Loss: 0.0132\n",
      "Epoch 63/200, Iteration 222/250, Loss: 0.0215\n",
      "Epoch 63/200, Iteration 223/250, Loss: 0.0175\n",
      "Epoch 63/200, Iteration 224/250, Loss: 0.0189\n",
      "Epoch 63/200, Iteration 225/250, Loss: 0.0081\n",
      "Epoch 63/200, Iteration 226/250, Loss: 0.0068\n",
      "Epoch 63/200, Iteration 227/250, Loss: 0.0219\n",
      "Epoch 63/200, Iteration 228/250, Loss: 0.0195\n",
      "Epoch 63/200, Iteration 229/250, Loss: 0.0174\n",
      "Epoch 63/200, Iteration 230/250, Loss: 0.0087\n",
      "Epoch 63/200, Iteration 231/250, Loss: 0.0250\n",
      "Epoch 63/200, Iteration 232/250, Loss: 0.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Iteration 233/250, Loss: 0.0304\n",
      "Epoch 63/200, Iteration 234/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 235/250, Loss: 0.0142\n",
      "Epoch 63/200, Iteration 236/250, Loss: 0.0089\n",
      "Epoch 63/200, Iteration 237/250, Loss: 0.0224\n",
      "Epoch 63/200, Iteration 238/250, Loss: 0.0190\n",
      "Epoch 63/200, Iteration 239/250, Loss: 0.0163\n",
      "Epoch 63/200, Iteration 240/250, Loss: 0.0271\n",
      "Epoch 63/200, Iteration 241/250, Loss: 0.0079\n",
      "Epoch 63/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 243/250, Loss: 0.0175\n",
      "Epoch 63/200, Iteration 244/250, Loss: 0.0244\n",
      "Epoch 63/200, Iteration 245/250, Loss: 0.0324\n",
      "Epoch 63/200, Iteration 246/250, Loss: 0.0084\n",
      "Epoch 63/200, Iteration 247/250, Loss: 0.0311\n",
      "Epoch 63/200, Iteration 248/250, Loss: 0.0143\n",
      "Epoch 63/200, Iteration 249/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 250/250, Loss: 0.0096\n",
      "Train Error: \n",
      " Accuracy: 89.65%, Avg loss: 0.007524, MRE: 0.691773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.95%, Avg loss: 0.007508, MRE: 1.078628 \n",
      "\n",
      "Epoch 64/200, Iteration 1/250, Loss: 0.0201\n",
      "Epoch 64/200, Iteration 2/250, Loss: 0.0165\n",
      "Epoch 64/200, Iteration 3/250, Loss: 0.0155\n",
      "Epoch 64/200, Iteration 4/250, Loss: 0.0103\n",
      "Epoch 64/200, Iteration 5/250, Loss: 0.0104\n",
      "Epoch 64/200, Iteration 6/250, Loss: 0.0187\n",
      "Epoch 64/200, Iteration 7/250, Loss: 0.0172\n",
      "Epoch 64/200, Iteration 8/250, Loss: 0.0200\n",
      "Epoch 64/200, Iteration 9/250, Loss: 0.0131\n",
      "Epoch 64/200, Iteration 10/250, Loss: 0.0106\n",
      "Epoch 64/200, Iteration 11/250, Loss: 0.0141\n",
      "Epoch 64/200, Iteration 12/250, Loss: 0.0090\n",
      "Epoch 64/200, Iteration 13/250, Loss: 0.0149\n",
      "Epoch 64/200, Iteration 14/250, Loss: 0.0100\n",
      "Epoch 64/200, Iteration 15/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 16/250, Loss: 0.0105\n",
      "Epoch 64/200, Iteration 17/250, Loss: 0.0127\n",
      "Epoch 64/200, Iteration 18/250, Loss: 0.0140\n",
      "Epoch 64/200, Iteration 19/250, Loss: 0.0159\n",
      "Epoch 64/200, Iteration 20/250, Loss: 0.0365\n",
      "Epoch 64/200, Iteration 21/250, Loss: 0.0246\n",
      "Epoch 64/200, Iteration 22/250, Loss: 0.0143\n",
      "Epoch 64/200, Iteration 23/250, Loss: 0.0264\n",
      "Epoch 64/200, Iteration 24/250, Loss: 0.0301\n",
      "Epoch 64/200, Iteration 25/250, Loss: 0.0202\n",
      "Epoch 64/200, Iteration 26/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 27/250, Loss: 0.0086\n",
      "Epoch 64/200, Iteration 28/250, Loss: 0.0157\n",
      "Epoch 64/200, Iteration 29/250, Loss: 0.0120\n",
      "Epoch 64/200, Iteration 30/250, Loss: 0.0191\n",
      "Epoch 64/200, Iteration 31/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 32/250, Loss: 0.0190\n",
      "Epoch 64/200, Iteration 33/250, Loss: 0.0186\n",
      "Epoch 64/200, Iteration 34/250, Loss: 0.0182\n",
      "Epoch 64/200, Iteration 35/250, Loss: 0.0184\n",
      "Epoch 64/200, Iteration 36/250, Loss: 0.0211\n",
      "Epoch 64/200, Iteration 37/250, Loss: 0.0155\n",
      "Epoch 64/200, Iteration 38/250, Loss: 0.0160\n",
      "Epoch 64/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 64/200, Iteration 40/250, Loss: 0.0166\n",
      "Epoch 64/200, Iteration 41/250, Loss: 0.0107\n",
      "Epoch 64/200, Iteration 42/250, Loss: 0.0084\n",
      "Epoch 64/200, Iteration 43/250, Loss: 0.0071\n",
      "Epoch 64/200, Iteration 44/250, Loss: 0.0213\n",
      "Epoch 64/200, Iteration 45/250, Loss: 0.0296\n",
      "Epoch 64/200, Iteration 46/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 47/250, Loss: 0.0207\n",
      "Epoch 64/200, Iteration 48/250, Loss: 0.0102\n",
      "Epoch 64/200, Iteration 49/250, Loss: 0.0111\n",
      "Epoch 64/200, Iteration 50/250, Loss: 0.0233\n",
      "Epoch 64/200, Iteration 51/250, Loss: 0.0370\n",
      "Epoch 64/200, Iteration 52/250, Loss: 0.0141\n",
      "Epoch 64/200, Iteration 53/250, Loss: 0.0154\n",
      "Epoch 64/200, Iteration 54/250, Loss: 0.0083\n",
      "Epoch 64/200, Iteration 55/250, Loss: 0.0100\n",
      "Epoch 64/200, Iteration 56/250, Loss: 0.0137\n",
      "Epoch 64/200, Iteration 57/250, Loss: 0.0127\n",
      "Epoch 64/200, Iteration 58/250, Loss: 0.0289\n",
      "Epoch 64/200, Iteration 59/250, Loss: 0.0172\n",
      "Epoch 64/200, Iteration 60/250, Loss: 0.0074\n",
      "Epoch 64/200, Iteration 61/250, Loss: 0.0121\n",
      "Epoch 64/200, Iteration 62/250, Loss: 0.0091\n",
      "Epoch 64/200, Iteration 63/250, Loss: 0.0162\n",
      "Epoch 64/200, Iteration 64/250, Loss: 0.0165\n",
      "Epoch 64/200, Iteration 65/250, Loss: 0.0168\n",
      "Epoch 64/200, Iteration 66/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 67/250, Loss: 0.0270\n",
      "Epoch 64/200, Iteration 68/250, Loss: 0.0160\n",
      "Epoch 64/200, Iteration 69/250, Loss: 0.0081\n",
      "Epoch 64/200, Iteration 70/250, Loss: 0.0142\n",
      "Epoch 64/200, Iteration 71/250, Loss: 0.0095\n",
      "Epoch 64/200, Iteration 72/250, Loss: 0.0186\n",
      "Epoch 64/200, Iteration 73/250, Loss: 0.0117\n",
      "Epoch 64/200, Iteration 74/250, Loss: 0.0135\n",
      "Epoch 64/200, Iteration 75/250, Loss: 0.0095\n",
      "Epoch 64/200, Iteration 76/250, Loss: 0.0126\n",
      "Epoch 64/200, Iteration 77/250, Loss: 0.0311\n",
      "Epoch 64/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 64/200, Iteration 79/250, Loss: 0.0101\n",
      "Epoch 64/200, Iteration 80/250, Loss: 0.0234\n",
      "Epoch 64/200, Iteration 81/250, Loss: 0.0063\n",
      "Epoch 64/200, Iteration 82/250, Loss: 0.0073\n",
      "Epoch 64/200, Iteration 83/250, Loss: 0.0192\n",
      "Epoch 64/200, Iteration 84/250, Loss: 0.0321\n",
      "Epoch 64/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 86/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 87/250, Loss: 0.0285\n",
      "Epoch 64/200, Iteration 88/250, Loss: 0.0126\n",
      "Epoch 64/200, Iteration 89/250, Loss: 0.0065\n",
      "Epoch 64/200, Iteration 90/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 91/250, Loss: 0.0281\n",
      "Epoch 64/200, Iteration 92/250, Loss: 0.0135\n",
      "Epoch 64/200, Iteration 93/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 94/250, Loss: 0.0221\n",
      "Epoch 64/200, Iteration 95/250, Loss: 0.0178\n",
      "Epoch 64/200, Iteration 96/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 97/250, Loss: 0.0258\n",
      "Epoch 64/200, Iteration 98/250, Loss: 0.0136\n",
      "Epoch 64/200, Iteration 99/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 100/250, Loss: 0.0098\n",
      "Epoch 64/200, Iteration 101/250, Loss: 0.0153\n",
      "Epoch 64/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 64/200, Iteration 103/250, Loss: 0.0124\n",
      "Epoch 64/200, Iteration 104/250, Loss: 0.0171\n",
      "Epoch 64/200, Iteration 105/250, Loss: 0.0253\n",
      "Epoch 64/200, Iteration 106/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 107/250, Loss: 0.0124\n",
      "Epoch 64/200, Iteration 108/250, Loss: 0.0337\n",
      "Epoch 64/200, Iteration 109/250, Loss: 0.0153\n",
      "Epoch 64/200, Iteration 110/250, Loss: 0.0142\n",
      "Epoch 64/200, Iteration 111/250, Loss: 0.0195\n",
      "Epoch 64/200, Iteration 112/250, Loss: 0.0366\n",
      "Epoch 64/200, Iteration 113/250, Loss: 0.0163\n",
      "Epoch 64/200, Iteration 114/250, Loss: 0.0081\n",
      "Epoch 64/200, Iteration 115/250, Loss: 0.0159\n",
      "Epoch 64/200, Iteration 116/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 117/250, Loss: 0.0179\n",
      "Epoch 64/200, Iteration 118/250, Loss: 0.0077\n",
      "Epoch 64/200, Iteration 119/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 120/250, Loss: 0.0113\n",
      "Epoch 64/200, Iteration 121/250, Loss: 0.0179\n",
      "Epoch 64/200, Iteration 122/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 123/250, Loss: 0.0189\n",
      "Epoch 64/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 64/200, Iteration 125/250, Loss: 0.0199\n",
      "Epoch 64/200, Iteration 126/250, Loss: 0.0064\n",
      "Epoch 64/200, Iteration 127/250, Loss: 0.0423\n",
      "Epoch 64/200, Iteration 128/250, Loss: 0.0080\n",
      "Epoch 64/200, Iteration 129/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 130/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 131/250, Loss: 0.0451\n",
      "Epoch 64/200, Iteration 132/250, Loss: 0.0161\n",
      "Epoch 64/200, Iteration 133/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 134/250, Loss: 0.0126\n",
      "Epoch 64/200, Iteration 135/250, Loss: 0.0125\n",
      "Epoch 64/200, Iteration 136/250, Loss: 0.0165\n",
      "Epoch 64/200, Iteration 137/250, Loss: 0.0094\n",
      "Epoch 64/200, Iteration 138/250, Loss: 0.0148\n",
      "Epoch 64/200, Iteration 139/250, Loss: 0.0111\n",
      "Epoch 64/200, Iteration 140/250, Loss: 0.0106\n",
      "Epoch 64/200, Iteration 141/250, Loss: 0.0145\n",
      "Epoch 64/200, Iteration 142/250, Loss: 0.0134\n",
      "Epoch 64/200, Iteration 143/250, Loss: 0.0163\n",
      "Epoch 64/200, Iteration 144/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 145/250, Loss: 0.0175\n",
      "Epoch 64/200, Iteration 146/250, Loss: 0.0091\n",
      "Epoch 64/200, Iteration 147/250, Loss: 0.0086\n",
      "Epoch 64/200, Iteration 148/250, Loss: 0.0149\n",
      "Epoch 64/200, Iteration 149/250, Loss: 0.0086\n",
      "Epoch 64/200, Iteration 150/250, Loss: 0.0246\n",
      "Epoch 64/200, Iteration 151/250, Loss: 0.0078\n",
      "Epoch 64/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 64/200, Iteration 153/250, Loss: 0.0085\n",
      "Epoch 64/200, Iteration 154/250, Loss: 0.0133\n",
      "Epoch 64/200, Iteration 155/250, Loss: 0.0138\n",
      "Epoch 64/200, Iteration 156/250, Loss: 0.0128\n",
      "Epoch 64/200, Iteration 157/250, Loss: 0.0163\n",
      "Epoch 64/200, Iteration 158/250, Loss: 0.0144\n",
      "Epoch 64/200, Iteration 159/250, Loss: 0.0102\n",
      "Epoch 64/200, Iteration 160/250, Loss: 0.0152\n",
      "Epoch 64/200, Iteration 161/250, Loss: 0.0226\n",
      "Epoch 64/200, Iteration 162/250, Loss: 0.0147\n",
      "Epoch 64/200, Iteration 163/250, Loss: 0.0311\n",
      "Epoch 64/200, Iteration 164/250, Loss: 0.0352\n",
      "Epoch 64/200, Iteration 165/250, Loss: 0.0326\n",
      "Epoch 64/200, Iteration 166/250, Loss: 0.0093\n",
      "Epoch 64/200, Iteration 167/250, Loss: 0.0179\n",
      "Epoch 64/200, Iteration 168/250, Loss: 0.0169\n",
      "Epoch 64/200, Iteration 169/250, Loss: 0.0197\n",
      "Epoch 64/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 64/200, Iteration 171/250, Loss: 0.0120\n",
      "Epoch 64/200, Iteration 172/250, Loss: 0.0138\n",
      "Epoch 64/200, Iteration 173/250, Loss: 0.0079\n",
      "Epoch 64/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 64/200, Iteration 175/250, Loss: 0.0300\n",
      "Epoch 64/200, Iteration 176/250, Loss: 0.0255\n",
      "Epoch 64/200, Iteration 177/250, Loss: 0.0328\n",
      "Epoch 64/200, Iteration 178/250, Loss: 0.0324\n",
      "Epoch 64/200, Iteration 179/250, Loss: 0.0116\n",
      "Epoch 64/200, Iteration 180/250, Loss: 0.0082\n",
      "Epoch 64/200, Iteration 181/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 182/250, Loss: 0.0162\n",
      "Epoch 64/200, Iteration 183/250, Loss: 0.0151\n",
      "Epoch 64/200, Iteration 184/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 185/250, Loss: 0.0246\n",
      "Epoch 64/200, Iteration 186/250, Loss: 0.0255\n",
      "Epoch 64/200, Iteration 187/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 188/250, Loss: 0.0251\n",
      "Epoch 64/200, Iteration 189/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200, Iteration 190/250, Loss: 0.0226\n",
      "Epoch 64/200, Iteration 191/250, Loss: 0.0246\n",
      "Epoch 64/200, Iteration 192/250, Loss: 0.0093\n",
      "Epoch 64/200, Iteration 193/250, Loss: 0.0073\n",
      "Epoch 64/200, Iteration 194/250, Loss: 0.0290\n",
      "Epoch 64/200, Iteration 195/250, Loss: 0.0138\n",
      "Epoch 64/200, Iteration 196/250, Loss: 0.0076\n",
      "Epoch 64/200, Iteration 197/250, Loss: 0.0154\n",
      "Epoch 64/200, Iteration 198/250, Loss: 0.0161\n",
      "Epoch 64/200, Iteration 199/250, Loss: 0.0093\n",
      "Epoch 64/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 64/200, Iteration 201/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 202/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 203/250, Loss: 0.0153\n",
      "Epoch 64/200, Iteration 204/250, Loss: 0.0357\n",
      "Epoch 64/200, Iteration 205/250, Loss: 0.0205\n",
      "Epoch 64/200, Iteration 206/250, Loss: 0.0105\n",
      "Epoch 64/200, Iteration 207/250, Loss: 0.0278\n",
      "Epoch 64/200, Iteration 208/250, Loss: 0.0186\n",
      "Epoch 64/200, Iteration 209/250, Loss: 0.0168\n",
      "Epoch 64/200, Iteration 210/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 211/250, Loss: 0.0130\n",
      "Epoch 64/200, Iteration 212/250, Loss: 0.0227\n",
      "Epoch 64/200, Iteration 213/250, Loss: 0.0147\n",
      "Epoch 64/200, Iteration 214/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 215/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 216/250, Loss: 0.0136\n",
      "Epoch 64/200, Iteration 217/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 218/250, Loss: 0.0320\n",
      "Epoch 64/200, Iteration 219/250, Loss: 0.0064\n",
      "Epoch 64/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 64/200, Iteration 221/250, Loss: 0.0073\n",
      "Epoch 64/200, Iteration 222/250, Loss: 0.0213\n",
      "Epoch 64/200, Iteration 223/250, Loss: 0.0221\n",
      "Epoch 64/200, Iteration 224/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 225/250, Loss: 0.0146\n",
      "Epoch 64/200, Iteration 226/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 227/250, Loss: 0.0060\n",
      "Epoch 64/200, Iteration 228/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 64/200, Iteration 230/250, Loss: 0.0171\n",
      "Epoch 64/200, Iteration 231/250, Loss: 0.0350\n",
      "Epoch 64/200, Iteration 232/250, Loss: 0.0264\n",
      "Epoch 64/200, Iteration 233/250, Loss: 0.0222\n",
      "Epoch 64/200, Iteration 234/250, Loss: 0.0375\n",
      "Epoch 64/200, Iteration 235/250, Loss: 0.0217\n",
      "Epoch 64/200, Iteration 236/250, Loss: 0.0355\n",
      "Epoch 64/200, Iteration 237/250, Loss: 0.0199\n",
      "Epoch 64/200, Iteration 238/250, Loss: 0.0092\n",
      "Epoch 64/200, Iteration 239/250, Loss: 0.0075\n",
      "Epoch 64/200, Iteration 240/250, Loss: 0.0140\n",
      "Epoch 64/200, Iteration 241/250, Loss: 0.0130\n",
      "Epoch 64/200, Iteration 242/250, Loss: 0.0178\n",
      "Epoch 64/200, Iteration 243/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 244/250, Loss: 0.0065\n",
      "Epoch 64/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 64/200, Iteration 246/250, Loss: 0.0181\n",
      "Epoch 64/200, Iteration 247/250, Loss: 0.0107\n",
      "Epoch 64/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 64/200, Iteration 249/250, Loss: 0.0146\n",
      "Epoch 64/200, Iteration 250/250, Loss: 0.0131\n",
      "Train Error: \n",
      " Accuracy: 89.95%, Avg loss: 0.007160, MRE: 0.632372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.35%, Avg loss: 0.007106, MRE: 0.922703 \n",
      "\n",
      "Epoch 65/200, Iteration 1/250, Loss: 0.0262\n",
      "Epoch 65/200, Iteration 2/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 3/250, Loss: 0.0177\n",
      "Epoch 65/200, Iteration 4/250, Loss: 0.0223\n",
      "Epoch 65/200, Iteration 5/250, Loss: 0.0196\n",
      "Epoch 65/200, Iteration 6/250, Loss: 0.0192\n",
      "Epoch 65/200, Iteration 7/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 9/250, Loss: 0.0137\n",
      "Epoch 65/200, Iteration 10/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 11/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 12/250, Loss: 0.0077\n",
      "Epoch 65/200, Iteration 13/250, Loss: 0.0073\n",
      "Epoch 65/200, Iteration 14/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 15/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 16/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 17/250, Loss: 0.0200\n",
      "Epoch 65/200, Iteration 18/250, Loss: 0.0074\n",
      "Epoch 65/200, Iteration 19/250, Loss: 0.0256\n",
      "Epoch 65/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 65/200, Iteration 21/250, Loss: 0.0226\n",
      "Epoch 65/200, Iteration 22/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 23/250, Loss: 0.0111\n",
      "Epoch 65/200, Iteration 24/250, Loss: 0.0320\n",
      "Epoch 65/200, Iteration 25/250, Loss: 0.0342\n",
      "Epoch 65/200, Iteration 26/250, Loss: 0.0150\n",
      "Epoch 65/200, Iteration 27/250, Loss: 0.0134\n",
      "Epoch 65/200, Iteration 28/250, Loss: 0.0179\n",
      "Epoch 65/200, Iteration 29/250, Loss: 0.0145\n",
      "Epoch 65/200, Iteration 30/250, Loss: 0.0292\n",
      "Epoch 65/200, Iteration 31/250, Loss: 0.0052\n",
      "Epoch 65/200, Iteration 32/250, Loss: 0.0119\n",
      "Epoch 65/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 65/200, Iteration 34/250, Loss: 0.0114\n",
      "Epoch 65/200, Iteration 35/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 36/250, Loss: 0.0110\n",
      "Epoch 65/200, Iteration 37/250, Loss: 0.0138\n",
      "Epoch 65/200, Iteration 38/250, Loss: 0.0175\n",
      "Epoch 65/200, Iteration 39/250, Loss: 0.0353\n",
      "Epoch 65/200, Iteration 40/250, Loss: 0.0183\n",
      "Epoch 65/200, Iteration 41/250, Loss: 0.0370\n",
      "Epoch 65/200, Iteration 42/250, Loss: 0.0125\n",
      "Epoch 65/200, Iteration 43/250, Loss: 0.0141\n",
      "Epoch 65/200, Iteration 44/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 45/250, Loss: 0.0087\n",
      "Epoch 65/200, Iteration 46/250, Loss: 0.0229\n",
      "Epoch 65/200, Iteration 47/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 48/250, Loss: 0.0153\n",
      "Epoch 65/200, Iteration 49/250, Loss: 0.0215\n",
      "Epoch 65/200, Iteration 50/250, Loss: 0.0139\n",
      "Epoch 65/200, Iteration 51/250, Loss: 0.0147\n",
      "Epoch 65/200, Iteration 52/250, Loss: 0.0098\n",
      "Epoch 65/200, Iteration 53/250, Loss: 0.0344\n",
      "Epoch 65/200, Iteration 54/250, Loss: 0.0081\n",
      "Epoch 65/200, Iteration 55/250, Loss: 0.0235\n",
      "Epoch 65/200, Iteration 56/250, Loss: 0.0082\n",
      "Epoch 65/200, Iteration 57/250, Loss: 0.0337\n",
      "Epoch 65/200, Iteration 58/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 59/250, Loss: 0.0204\n",
      "Epoch 65/200, Iteration 60/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 61/250, Loss: 0.0110\n",
      "Epoch 65/200, Iteration 62/250, Loss: 0.0373\n",
      "Epoch 65/200, Iteration 63/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 64/250, Loss: 0.0092\n",
      "Epoch 65/200, Iteration 65/250, Loss: 0.0430\n",
      "Epoch 65/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 65/200, Iteration 67/250, Loss: 0.0228\n",
      "Epoch 65/200, Iteration 68/250, Loss: 0.0126\n",
      "Epoch 65/200, Iteration 69/250, Loss: 0.0154\n",
      "Epoch 65/200, Iteration 70/250, Loss: 0.0130\n",
      "Epoch 65/200, Iteration 71/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 65/200, Iteration 73/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 74/250, Loss: 0.0071\n",
      "Epoch 65/200, Iteration 75/250, Loss: 0.0162\n",
      "Epoch 65/200, Iteration 76/250, Loss: 0.0084\n",
      "Epoch 65/200, Iteration 77/250, Loss: 0.0092\n",
      "Epoch 65/200, Iteration 78/250, Loss: 0.0160\n",
      "Epoch 65/200, Iteration 79/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 80/250, Loss: 0.0131\n",
      "Epoch 65/200, Iteration 81/250, Loss: 0.0071\n",
      "Epoch 65/200, Iteration 82/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 83/250, Loss: 0.0219\n",
      "Epoch 65/200, Iteration 84/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 85/250, Loss: 0.0187\n",
      "Epoch 65/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 87/250, Loss: 0.0122\n",
      "Epoch 65/200, Iteration 88/250, Loss: 0.0251\n",
      "Epoch 65/200, Iteration 89/250, Loss: 0.0360\n",
      "Epoch 65/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 65/200, Iteration 91/250, Loss: 0.0134\n",
      "Epoch 65/200, Iteration 92/250, Loss: 0.0133\n",
      "Epoch 65/200, Iteration 93/250, Loss: 0.0099\n",
      "Epoch 65/200, Iteration 94/250, Loss: 0.0079\n",
      "Epoch 65/200, Iteration 95/250, Loss: 0.0140\n",
      "Epoch 65/200, Iteration 96/250, Loss: 0.0111\n",
      "Epoch 65/200, Iteration 97/250, Loss: 0.0180\n",
      "Epoch 65/200, Iteration 98/250, Loss: 0.0220\n",
      "Epoch 65/200, Iteration 99/250, Loss: 0.0199\n",
      "Epoch 65/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 101/250, Loss: 0.0122\n",
      "Epoch 65/200, Iteration 102/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 103/250, Loss: 0.0150\n",
      "Epoch 65/200, Iteration 104/250, Loss: 0.0233\n",
      "Epoch 65/200, Iteration 105/250, Loss: 0.0075\n",
      "Epoch 65/200, Iteration 106/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 107/250, Loss: 0.0155\n",
      "Epoch 65/200, Iteration 108/250, Loss: 0.0401\n",
      "Epoch 65/200, Iteration 109/250, Loss: 0.0102\n",
      "Epoch 65/200, Iteration 110/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 111/250, Loss: 0.0187\n",
      "Epoch 65/200, Iteration 112/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 113/250, Loss: 0.0149\n",
      "Epoch 65/200, Iteration 114/250, Loss: 0.0075\n",
      "Epoch 65/200, Iteration 115/250, Loss: 0.0101\n",
      "Epoch 65/200, Iteration 116/250, Loss: 0.0133\n",
      "Epoch 65/200, Iteration 117/250, Loss: 0.0075\n",
      "Epoch 65/200, Iteration 118/250, Loss: 0.0188\n",
      "Epoch 65/200, Iteration 119/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 120/250, Loss: 0.0209\n",
      "Epoch 65/200, Iteration 121/250, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 122/250, Loss: 0.0108\n",
      "Epoch 65/200, Iteration 123/250, Loss: 0.0270\n",
      "Epoch 65/200, Iteration 124/250, Loss: 0.0154\n",
      "Epoch 65/200, Iteration 125/250, Loss: 0.0182\n",
      "Epoch 65/200, Iteration 126/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 127/250, Loss: 0.0198\n",
      "Epoch 65/200, Iteration 128/250, Loss: 0.0230\n",
      "Epoch 65/200, Iteration 129/250, Loss: 0.0160\n",
      "Epoch 65/200, Iteration 130/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 131/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 132/250, Loss: 0.0282\n",
      "Epoch 65/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 134/250, Loss: 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200, Iteration 135/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 136/250, Loss: 0.0165\n",
      "Epoch 65/200, Iteration 137/250, Loss: 0.0083\n",
      "Epoch 65/200, Iteration 138/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 139/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 140/250, Loss: 0.0104\n",
      "Epoch 65/200, Iteration 141/250, Loss: 0.0174\n",
      "Epoch 65/200, Iteration 142/250, Loss: 0.0197\n",
      "Epoch 65/200, Iteration 143/250, Loss: 0.0123\n",
      "Epoch 65/200, Iteration 144/250, Loss: 0.0073\n",
      "Epoch 65/200, Iteration 145/250, Loss: 0.0164\n",
      "Epoch 65/200, Iteration 146/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 147/250, Loss: 0.0306\n",
      "Epoch 65/200, Iteration 148/250, Loss: 0.0214\n",
      "Epoch 65/200, Iteration 149/250, Loss: 0.0096\n",
      "Epoch 65/200, Iteration 150/250, Loss: 0.0226\n",
      "Epoch 65/200, Iteration 151/250, Loss: 0.0131\n",
      "Epoch 65/200, Iteration 152/250, Loss: 0.0332\n",
      "Epoch 65/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 154/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 155/250, Loss: 0.0278\n",
      "Epoch 65/200, Iteration 156/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 157/250, Loss: 0.0169\n",
      "Epoch 65/200, Iteration 158/250, Loss: 0.0087\n",
      "Epoch 65/200, Iteration 159/250, Loss: 0.0131\n",
      "Epoch 65/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 65/200, Iteration 161/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 162/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 163/250, Loss: 0.0118\n",
      "Epoch 65/200, Iteration 164/250, Loss: 0.0116\n",
      "Epoch 65/200, Iteration 165/250, Loss: 0.0190\n",
      "Epoch 65/200, Iteration 166/250, Loss: 0.0401\n",
      "Epoch 65/200, Iteration 167/250, Loss: 0.0256\n",
      "Epoch 65/200, Iteration 168/250, Loss: 0.0077\n",
      "Epoch 65/200, Iteration 169/250, Loss: 0.0146\n",
      "Epoch 65/200, Iteration 170/250, Loss: 0.0164\n",
      "Epoch 65/200, Iteration 171/250, Loss: 0.0188\n",
      "Epoch 65/200, Iteration 172/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 173/250, Loss: 0.0135\n",
      "Epoch 65/200, Iteration 174/250, Loss: 0.0147\n",
      "Epoch 65/200, Iteration 175/250, Loss: 0.0175\n",
      "Epoch 65/200, Iteration 176/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 178/250, Loss: 0.0092\n",
      "Epoch 65/200, Iteration 179/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 180/250, Loss: 0.0120\n",
      "Epoch 65/200, Iteration 181/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 182/250, Loss: 0.0084\n",
      "Epoch 65/200, Iteration 183/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 184/250, Loss: 0.0081\n",
      "Epoch 65/200, Iteration 185/250, Loss: 0.0141\n",
      "Epoch 65/200, Iteration 186/250, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 187/250, Loss: 0.0116\n",
      "Epoch 65/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 189/250, Loss: 0.0287\n",
      "Epoch 65/200, Iteration 190/250, Loss: 0.0104\n",
      "Epoch 65/200, Iteration 191/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 65/200, Iteration 193/250, Loss: 0.0067\n",
      "Epoch 65/200, Iteration 194/250, Loss: 0.0271\n",
      "Epoch 65/200, Iteration 195/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 196/250, Loss: 0.0232\n",
      "Epoch 65/200, Iteration 197/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 198/250, Loss: 0.0129\n",
      "Epoch 65/200, Iteration 199/250, Loss: 0.0119\n",
      "Epoch 65/200, Iteration 200/250, Loss: 0.0101\n",
      "Epoch 65/200, Iteration 201/250, Loss: 0.0207\n",
      "Epoch 65/200, Iteration 202/250, Loss: 0.0134\n",
      "Epoch 65/200, Iteration 203/250, Loss: 0.0132\n",
      "Epoch 65/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 205/250, Loss: 0.0236\n",
      "Epoch 65/200, Iteration 206/250, Loss: 0.0070\n",
      "Epoch 65/200, Iteration 207/250, Loss: 0.0117\n",
      "Epoch 65/200, Iteration 208/250, Loss: 0.0083\n",
      "Epoch 65/200, Iteration 209/250, Loss: 0.0104\n",
      "Epoch 65/200, Iteration 210/250, Loss: 0.0071\n",
      "Epoch 65/200, Iteration 211/250, Loss: 0.0122\n",
      "Epoch 65/200, Iteration 212/250, Loss: 0.0133\n",
      "Epoch 65/200, Iteration 213/250, Loss: 0.0306\n",
      "Epoch 65/200, Iteration 214/250, Loss: 0.0171\n",
      "Epoch 65/200, Iteration 215/250, Loss: 0.0250\n",
      "Epoch 65/200, Iteration 216/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 65/200, Iteration 218/250, Loss: 0.0170\n",
      "Epoch 65/200, Iteration 219/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 220/250, Loss: 0.0165\n",
      "Epoch 65/200, Iteration 221/250, Loss: 0.0141\n",
      "Epoch 65/200, Iteration 222/250, Loss: 0.0198\n",
      "Epoch 65/200, Iteration 223/250, Loss: 0.0122\n",
      "Epoch 65/200, Iteration 224/250, Loss: 0.0263\n",
      "Epoch 65/200, Iteration 225/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 226/250, Loss: 0.0137\n",
      "Epoch 65/200, Iteration 227/250, Loss: 0.0124\n",
      "Epoch 65/200, Iteration 228/250, Loss: 0.0137\n",
      "Epoch 65/200, Iteration 229/250, Loss: 0.0080\n",
      "Epoch 65/200, Iteration 230/250, Loss: 0.0522\n",
      "Epoch 65/200, Iteration 231/250, Loss: 0.0183\n",
      "Epoch 65/200, Iteration 232/250, Loss: 0.0120\n",
      "Epoch 65/200, Iteration 233/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 234/250, Loss: 0.0108\n",
      "Epoch 65/200, Iteration 235/250, Loss: 0.0124\n",
      "Epoch 65/200, Iteration 236/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 237/250, Loss: 0.0079\n",
      "Epoch 65/200, Iteration 238/250, Loss: 0.0183\n",
      "Epoch 65/200, Iteration 239/250, Loss: 0.0144\n",
      "Epoch 65/200, Iteration 240/250, Loss: 0.0209\n",
      "Epoch 65/200, Iteration 241/250, Loss: 0.0161\n",
      "Epoch 65/200, Iteration 242/250, Loss: 0.0229\n",
      "Epoch 65/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 244/250, Loss: 0.0158\n",
      "Epoch 65/200, Iteration 245/250, Loss: 0.0135\n",
      "Epoch 65/200, Iteration 246/250, Loss: 0.0208\n",
      "Epoch 65/200, Iteration 247/250, Loss: 0.0204\n",
      "Epoch 65/200, Iteration 248/250, Loss: 0.0108\n",
      "Epoch 65/200, Iteration 249/250, Loss: 0.0087\n",
      "Epoch 65/200, Iteration 250/250, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 97.05%, Avg loss: 0.007131, MRE: 0.762404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.007125, MRE: 1.192883 \n",
      "\n",
      "Epoch 66/200, Iteration 1/250, Loss: 0.0240\n",
      "Epoch 66/200, Iteration 2/250, Loss: 0.0181\n",
      "Epoch 66/200, Iteration 3/250, Loss: 0.0076\n",
      "Epoch 66/200, Iteration 4/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 5/250, Loss: 0.0236\n",
      "Epoch 66/200, Iteration 6/250, Loss: 0.0230\n",
      "Epoch 66/200, Iteration 7/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 8/250, Loss: 0.0304\n",
      "Epoch 66/200, Iteration 9/250, Loss: 0.0143\n",
      "Epoch 66/200, Iteration 10/250, Loss: 0.0130\n",
      "Epoch 66/200, Iteration 11/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 12/250, Loss: 0.0139\n",
      "Epoch 66/200, Iteration 13/250, Loss: 0.0242\n",
      "Epoch 66/200, Iteration 14/250, Loss: 0.0177\n",
      "Epoch 66/200, Iteration 15/250, Loss: 0.0251\n",
      "Epoch 66/200, Iteration 16/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 17/250, Loss: 0.0122\n",
      "Epoch 66/200, Iteration 18/250, Loss: 0.0183\n",
      "Epoch 66/200, Iteration 19/250, Loss: 0.0160\n",
      "Epoch 66/200, Iteration 20/250, Loss: 0.0150\n",
      "Epoch 66/200, Iteration 21/250, Loss: 0.0181\n",
      "Epoch 66/200, Iteration 22/250, Loss: 0.0341\n",
      "Epoch 66/200, Iteration 23/250, Loss: 0.0097\n",
      "Epoch 66/200, Iteration 24/250, Loss: 0.0162\n",
      "Epoch 66/200, Iteration 25/250, Loss: 0.0120\n",
      "Epoch 66/200, Iteration 26/250, Loss: 0.0091\n",
      "Epoch 66/200, Iteration 27/250, Loss: 0.0204\n",
      "Epoch 66/200, Iteration 28/250, Loss: 0.0278\n",
      "Epoch 66/200, Iteration 29/250, Loss: 0.0204\n",
      "Epoch 66/200, Iteration 30/250, Loss: 0.0112\n",
      "Epoch 66/200, Iteration 31/250, Loss: 0.0085\n",
      "Epoch 66/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 66/200, Iteration 33/250, Loss: 0.0195\n",
      "Epoch 66/200, Iteration 34/250, Loss: 0.0276\n",
      "Epoch 66/200, Iteration 35/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 36/250, Loss: 0.0174\n",
      "Epoch 66/200, Iteration 37/250, Loss: 0.0360\n",
      "Epoch 66/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 66/200, Iteration 39/250, Loss: 0.0124\n",
      "Epoch 66/200, Iteration 40/250, Loss: 0.0317\n",
      "Epoch 66/200, Iteration 41/250, Loss: 0.0132\n",
      "Epoch 66/200, Iteration 42/250, Loss: 0.0161\n",
      "Epoch 66/200, Iteration 43/250, Loss: 0.0182\n",
      "Epoch 66/200, Iteration 44/250, Loss: 0.0166\n",
      "Epoch 66/200, Iteration 45/250, Loss: 0.0175\n",
      "Epoch 66/200, Iteration 46/250, Loss: 0.0104\n",
      "Epoch 66/200, Iteration 47/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 48/250, Loss: 0.0226\n",
      "Epoch 66/200, Iteration 49/250, Loss: 0.0314\n",
      "Epoch 66/200, Iteration 50/250, Loss: 0.0155\n",
      "Epoch 66/200, Iteration 51/250, Loss: 0.0151\n",
      "Epoch 66/200, Iteration 52/250, Loss: 0.0140\n",
      "Epoch 66/200, Iteration 53/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 54/250, Loss: 0.0185\n",
      "Epoch 66/200, Iteration 55/250, Loss: 0.0059\n",
      "Epoch 66/200, Iteration 56/250, Loss: 0.0243\n",
      "Epoch 66/200, Iteration 57/250, Loss: 0.0119\n",
      "Epoch 66/200, Iteration 58/250, Loss: 0.0124\n",
      "Epoch 66/200, Iteration 59/250, Loss: 0.0151\n",
      "Epoch 66/200, Iteration 60/250, Loss: 0.0164\n",
      "Epoch 66/200, Iteration 61/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 62/250, Loss: 0.0228\n",
      "Epoch 66/200, Iteration 63/250, Loss: 0.0096\n",
      "Epoch 66/200, Iteration 64/250, Loss: 0.0106\n",
      "Epoch 66/200, Iteration 65/250, Loss: 0.0275\n",
      "Epoch 66/200, Iteration 66/250, Loss: 0.0448\n",
      "Epoch 66/200, Iteration 67/250, Loss: 0.0140\n",
      "Epoch 66/200, Iteration 68/250, Loss: 0.0339\n",
      "Epoch 66/200, Iteration 69/250, Loss: 0.0179\n",
      "Epoch 66/200, Iteration 70/250, Loss: 0.0133\n",
      "Epoch 66/200, Iteration 71/250, Loss: 0.0134\n",
      "Epoch 66/200, Iteration 72/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 73/250, Loss: 0.0135\n",
      "Epoch 66/200, Iteration 74/250, Loss: 0.0438\n",
      "Epoch 66/200, Iteration 75/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 76/250, Loss: 0.0077\n",
      "Epoch 66/200, Iteration 77/250, Loss: 0.0143\n",
      "Epoch 66/200, Iteration 78/250, Loss: 0.0105\n",
      "Epoch 66/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 80/250, Loss: 0.0185\n",
      "Epoch 66/200, Iteration 81/250, Loss: 0.0220\n",
      "Epoch 66/200, Iteration 82/250, Loss: 0.0126\n",
      "Epoch 66/200, Iteration 83/250, Loss: 0.0229\n",
      "Epoch 66/200, Iteration 84/250, Loss: 0.0142\n",
      "Epoch 66/200, Iteration 85/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 86/250, Loss: 0.0320\n",
      "Epoch 66/200, Iteration 87/250, Loss: 0.0142\n",
      "Epoch 66/200, Iteration 88/250, Loss: 0.0236\n",
      "Epoch 66/200, Iteration 89/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 90/250, Loss: 0.0151\n",
      "Epoch 66/200, Iteration 91/250, Loss: 0.0200\n",
      "Epoch 66/200, Iteration 92/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200, Iteration 93/250, Loss: 0.0166\n",
      "Epoch 66/200, Iteration 94/250, Loss: 0.0082\n",
      "Epoch 66/200, Iteration 95/250, Loss: 0.0116\n",
      "Epoch 66/200, Iteration 96/250, Loss: 0.0205\n",
      "Epoch 66/200, Iteration 97/250, Loss: 0.0229\n",
      "Epoch 66/200, Iteration 98/250, Loss: 0.0107\n",
      "Epoch 66/200, Iteration 99/250, Loss: 0.0080\n",
      "Epoch 66/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 101/250, Loss: 0.0186\n",
      "Epoch 66/200, Iteration 102/250, Loss: 0.0171\n",
      "Epoch 66/200, Iteration 103/250, Loss: 0.0131\n",
      "Epoch 66/200, Iteration 104/250, Loss: 0.0121\n",
      "Epoch 66/200, Iteration 105/250, Loss: 0.0144\n",
      "Epoch 66/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 66/200, Iteration 107/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 108/250, Loss: 0.0094\n",
      "Epoch 66/200, Iteration 109/250, Loss: 0.0162\n",
      "Epoch 66/200, Iteration 110/250, Loss: 0.0279\n",
      "Epoch 66/200, Iteration 111/250, Loss: 0.0193\n",
      "Epoch 66/200, Iteration 112/250, Loss: 0.0192\n",
      "Epoch 66/200, Iteration 113/250, Loss: 0.0086\n",
      "Epoch 66/200, Iteration 114/250, Loss: 0.0097\n",
      "Epoch 66/200, Iteration 115/250, Loss: 0.0265\n",
      "Epoch 66/200, Iteration 116/250, Loss: 0.0239\n",
      "Epoch 66/200, Iteration 117/250, Loss: 0.0245\n",
      "Epoch 66/200, Iteration 118/250, Loss: 0.0092\n",
      "Epoch 66/200, Iteration 119/250, Loss: 0.0119\n",
      "Epoch 66/200, Iteration 120/250, Loss: 0.0144\n",
      "Epoch 66/200, Iteration 121/250, Loss: 0.0102\n",
      "Epoch 66/200, Iteration 122/250, Loss: 0.0320\n",
      "Epoch 66/200, Iteration 123/250, Loss: 0.0211\n",
      "Epoch 66/200, Iteration 124/250, Loss: 0.0109\n",
      "Epoch 66/200, Iteration 125/250, Loss: 0.0204\n",
      "Epoch 66/200, Iteration 126/250, Loss: 0.0213\n",
      "Epoch 66/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 128/250, Loss: 0.0214\n",
      "Epoch 66/200, Iteration 129/250, Loss: 0.0181\n",
      "Epoch 66/200, Iteration 130/250, Loss: 0.0223\n",
      "Epoch 66/200, Iteration 131/250, Loss: 0.0102\n",
      "Epoch 66/200, Iteration 132/250, Loss: 0.0147\n",
      "Epoch 66/200, Iteration 133/250, Loss: 0.0369\n",
      "Epoch 66/200, Iteration 134/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 135/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 137/250, Loss: 0.0138\n",
      "Epoch 66/200, Iteration 138/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 139/250, Loss: 0.0387\n",
      "Epoch 66/200, Iteration 140/250, Loss: 0.0105\n",
      "Epoch 66/200, Iteration 141/250, Loss: 0.0125\n",
      "Epoch 66/200, Iteration 142/250, Loss: 0.0069\n",
      "Epoch 66/200, Iteration 143/250, Loss: 0.0112\n",
      "Epoch 66/200, Iteration 144/250, Loss: 0.0257\n",
      "Epoch 66/200, Iteration 145/250, Loss: 0.0139\n",
      "Epoch 66/200, Iteration 146/250, Loss: 0.0207\n",
      "Epoch 66/200, Iteration 147/250, Loss: 0.0188\n",
      "Epoch 66/200, Iteration 148/250, Loss: 0.0252\n",
      "Epoch 66/200, Iteration 149/250, Loss: 0.0124\n",
      "Epoch 66/200, Iteration 150/250, Loss: 0.0115\n",
      "Epoch 66/200, Iteration 151/250, Loss: 0.0154\n",
      "Epoch 66/200, Iteration 152/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 153/250, Loss: 0.0358\n",
      "Epoch 66/200, Iteration 154/250, Loss: 0.0190\n",
      "Epoch 66/200, Iteration 155/250, Loss: 0.0469\n",
      "Epoch 66/200, Iteration 156/250, Loss: 0.0120\n",
      "Epoch 66/200, Iteration 157/250, Loss: 0.0179\n",
      "Epoch 66/200, Iteration 158/250, Loss: 0.0192\n",
      "Epoch 66/200, Iteration 159/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 160/250, Loss: 0.0160\n",
      "Epoch 66/200, Iteration 161/250, Loss: 0.0192\n",
      "Epoch 66/200, Iteration 162/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 163/250, Loss: 0.0141\n",
      "Epoch 66/200, Iteration 164/250, Loss: 0.0127\n",
      "Epoch 66/200, Iteration 165/250, Loss: 0.0141\n",
      "Epoch 66/200, Iteration 166/250, Loss: 0.0078\n",
      "Epoch 66/200, Iteration 167/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 66/200, Iteration 169/250, Loss: 0.0072\n",
      "Epoch 66/200, Iteration 170/250, Loss: 0.0233\n",
      "Epoch 66/200, Iteration 171/250, Loss: 0.0169\n",
      "Epoch 66/200, Iteration 172/250, Loss: 0.0353\n",
      "Epoch 66/200, Iteration 173/250, Loss: 0.0171\n",
      "Epoch 66/200, Iteration 174/250, Loss: 0.0107\n",
      "Epoch 66/200, Iteration 175/250, Loss: 0.0205\n",
      "Epoch 66/200, Iteration 176/250, Loss: 0.0177\n",
      "Epoch 66/200, Iteration 177/250, Loss: 0.0247\n",
      "Epoch 66/200, Iteration 178/250, Loss: 0.0327\n",
      "Epoch 66/200, Iteration 179/250, Loss: 0.0110\n",
      "Epoch 66/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 66/200, Iteration 181/250, Loss: 0.0075\n",
      "Epoch 66/200, Iteration 182/250, Loss: 0.0141\n",
      "Epoch 66/200, Iteration 183/250, Loss: 0.0248\n",
      "Epoch 66/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 66/200, Iteration 185/250, Loss: 0.0156\n",
      "Epoch 66/200, Iteration 186/250, Loss: 0.0143\n",
      "Epoch 66/200, Iteration 187/250, Loss: 0.0081\n",
      "Epoch 66/200, Iteration 188/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 189/250, Loss: 0.0188\n",
      "Epoch 66/200, Iteration 190/250, Loss: 0.0142\n",
      "Epoch 66/200, Iteration 191/250, Loss: 0.0123\n",
      "Epoch 66/200, Iteration 192/250, Loss: 0.0164\n",
      "Epoch 66/200, Iteration 193/250, Loss: 0.0114\n",
      "Epoch 66/200, Iteration 194/250, Loss: 0.0178\n",
      "Epoch 66/200, Iteration 195/250, Loss: 0.0081\n",
      "Epoch 66/200, Iteration 196/250, Loss: 0.0150\n",
      "Epoch 66/200, Iteration 197/250, Loss: 0.0153\n",
      "Epoch 66/200, Iteration 198/250, Loss: 0.0190\n",
      "Epoch 66/200, Iteration 199/250, Loss: 0.0083\n",
      "Epoch 66/200, Iteration 200/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 201/250, Loss: 0.0107\n",
      "Epoch 66/200, Iteration 202/250, Loss: 0.0197\n",
      "Epoch 66/200, Iteration 203/250, Loss: 0.0379\n",
      "Epoch 66/200, Iteration 204/250, Loss: 0.0208\n",
      "Epoch 66/200, Iteration 205/250, Loss: 0.0080\n",
      "Epoch 66/200, Iteration 206/250, Loss: 0.0205\n",
      "Epoch 66/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 208/250, Loss: 0.0367\n",
      "Epoch 66/200, Iteration 209/250, Loss: 0.0150\n",
      "Epoch 66/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 66/200, Iteration 211/250, Loss: 0.0251\n",
      "Epoch 66/200, Iteration 212/250, Loss: 0.0082\n",
      "Epoch 66/200, Iteration 213/250, Loss: 0.0193\n",
      "Epoch 66/200, Iteration 214/250, Loss: 0.0181\n",
      "Epoch 66/200, Iteration 215/250, Loss: 0.0253\n",
      "Epoch 66/200, Iteration 216/250, Loss: 0.0353\n",
      "Epoch 66/200, Iteration 217/250, Loss: 0.0164\n",
      "Epoch 66/200, Iteration 218/250, Loss: 0.0193\n",
      "Epoch 66/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 66/200, Iteration 220/250, Loss: 0.0104\n",
      "Epoch 66/200, Iteration 221/250, Loss: 0.0335\n",
      "Epoch 66/200, Iteration 222/250, Loss: 0.0171\n",
      "Epoch 66/200, Iteration 223/250, Loss: 0.0270\n",
      "Epoch 66/200, Iteration 224/250, Loss: 0.0220\n",
      "Epoch 66/200, Iteration 225/250, Loss: 0.0169\n",
      "Epoch 66/200, Iteration 226/250, Loss: 0.0087\n",
      "Epoch 66/200, Iteration 227/250, Loss: 0.0173\n",
      "Epoch 66/200, Iteration 228/250, Loss: 0.0293\n",
      "Epoch 66/200, Iteration 229/250, Loss: 0.0090\n",
      "Epoch 66/200, Iteration 230/250, Loss: 0.0081\n",
      "Epoch 66/200, Iteration 231/250, Loss: 0.0189\n",
      "Epoch 66/200, Iteration 232/250, Loss: 0.0250\n",
      "Epoch 66/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 66/200, Iteration 234/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 235/250, Loss: 0.0250\n",
      "Epoch 66/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 66/200, Iteration 237/250, Loss: 0.0165\n",
      "Epoch 66/200, Iteration 238/250, Loss: 0.0144\n",
      "Epoch 66/200, Iteration 239/250, Loss: 0.0302\n",
      "Epoch 66/200, Iteration 240/250, Loss: 0.0158\n",
      "Epoch 66/200, Iteration 241/250, Loss: 0.0124\n",
      "Epoch 66/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 66/200, Iteration 243/250, Loss: 0.0154\n",
      "Epoch 66/200, Iteration 244/250, Loss: 0.0281\n",
      "Epoch 66/200, Iteration 245/250, Loss: 0.0088\n",
      "Epoch 66/200, Iteration 246/250, Loss: 0.0189\n",
      "Epoch 66/200, Iteration 247/250, Loss: 0.0072\n",
      "Epoch 66/200, Iteration 248/250, Loss: 0.0082\n",
      "Epoch 66/200, Iteration 249/250, Loss: 0.0384\n",
      "Epoch 66/200, Iteration 250/250, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 96.91%, Avg loss: 0.007331, MRE: 0.705887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.95%, Avg loss: 0.007246, MRE: 1.261720 \n",
      "\n",
      "Epoch 67/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 67/200, Iteration 2/250, Loss: 0.0218\n",
      "Epoch 67/200, Iteration 3/250, Loss: 0.0240\n",
      "Epoch 67/200, Iteration 4/250, Loss: 0.0132\n",
      "Epoch 67/200, Iteration 5/250, Loss: 0.0225\n",
      "Epoch 67/200, Iteration 6/250, Loss: 0.0260\n",
      "Epoch 67/200, Iteration 7/250, Loss: 0.0088\n",
      "Epoch 67/200, Iteration 8/250, Loss: 0.0406\n",
      "Epoch 67/200, Iteration 9/250, Loss: 0.0225\n",
      "Epoch 67/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 11/250, Loss: 0.0076\n",
      "Epoch 67/200, Iteration 12/250, Loss: 0.0196\n",
      "Epoch 67/200, Iteration 13/250, Loss: 0.0212\n",
      "Epoch 67/200, Iteration 14/250, Loss: 0.0157\n",
      "Epoch 67/200, Iteration 15/250, Loss: 0.0077\n",
      "Epoch 67/200, Iteration 16/250, Loss: 0.0155\n",
      "Epoch 67/200, Iteration 17/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 18/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 19/250, Loss: 0.0284\n",
      "Epoch 67/200, Iteration 20/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 21/250, Loss: 0.0197\n",
      "Epoch 67/200, Iteration 22/250, Loss: 0.0167\n",
      "Epoch 67/200, Iteration 23/250, Loss: 0.0119\n",
      "Epoch 67/200, Iteration 24/250, Loss: 0.0088\n",
      "Epoch 67/200, Iteration 25/250, Loss: 0.0071\n",
      "Epoch 67/200, Iteration 26/250, Loss: 0.0374\n",
      "Epoch 67/200, Iteration 27/250, Loss: 0.0213\n",
      "Epoch 67/200, Iteration 28/250, Loss: 0.0079\n",
      "Epoch 67/200, Iteration 29/250, Loss: 0.0094\n",
      "Epoch 67/200, Iteration 30/250, Loss: 0.0091\n",
      "Epoch 67/200, Iteration 31/250, Loss: 0.0217\n",
      "Epoch 67/200, Iteration 32/250, Loss: 0.0280\n",
      "Epoch 67/200, Iteration 33/250, Loss: 0.0062\n",
      "Epoch 67/200, Iteration 34/250, Loss: 0.0318\n",
      "Epoch 67/200, Iteration 35/250, Loss: 0.0291\n",
      "Epoch 67/200, Iteration 36/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 37/250, Loss: 0.0176\n",
      "Epoch 67/200, Iteration 38/250, Loss: 0.0273\n",
      "Epoch 67/200, Iteration 39/250, Loss: 0.0384\n",
      "Epoch 67/200, Iteration 40/250, Loss: 0.0249\n",
      "Epoch 67/200, Iteration 41/250, Loss: 0.0090\n",
      "Epoch 67/200, Iteration 42/250, Loss: 0.0284\n",
      "Epoch 67/200, Iteration 43/250, Loss: 0.0298\n",
      "Epoch 67/200, Iteration 44/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 45/250, Loss: 0.0143\n",
      "Epoch 67/200, Iteration 46/250, Loss: 0.0150\n",
      "Epoch 67/200, Iteration 47/250, Loss: 0.0301\n",
      "Epoch 67/200, Iteration 48/250, Loss: 0.0190\n",
      "Epoch 67/200, Iteration 49/250, Loss: 0.0146\n",
      "Epoch 67/200, Iteration 50/250, Loss: 0.0259\n",
      "Epoch 67/200, Iteration 51/250, Loss: 0.0130\n",
      "Epoch 67/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 53/250, Loss: 0.0162\n",
      "Epoch 67/200, Iteration 54/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 55/250, Loss: 0.0210\n",
      "Epoch 67/200, Iteration 56/250, Loss: 0.0079\n",
      "Epoch 67/200, Iteration 57/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 58/250, Loss: 0.0147\n",
      "Epoch 67/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 60/250, Loss: 0.0195\n",
      "Epoch 67/200, Iteration 61/250, Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200, Iteration 62/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 63/250, Loss: 0.0197\n",
      "Epoch 67/200, Iteration 64/250, Loss: 0.0259\n",
      "Epoch 67/200, Iteration 65/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 66/250, Loss: 0.0159\n",
      "Epoch 67/200, Iteration 67/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 68/250, Loss: 0.0205\n",
      "Epoch 67/200, Iteration 69/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 70/250, Loss: 0.0071\n",
      "Epoch 67/200, Iteration 71/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 72/250, Loss: 0.0135\n",
      "Epoch 67/200, Iteration 73/250, Loss: 0.0123\n",
      "Epoch 67/200, Iteration 74/250, Loss: 0.0405\n",
      "Epoch 67/200, Iteration 75/250, Loss: 0.0074\n",
      "Epoch 67/200, Iteration 76/250, Loss: 0.0376\n",
      "Epoch 67/200, Iteration 77/250, Loss: 0.0174\n",
      "Epoch 67/200, Iteration 78/250, Loss: 0.0176\n",
      "Epoch 67/200, Iteration 79/250, Loss: 0.0084\n",
      "Epoch 67/200, Iteration 80/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 81/250, Loss: 0.0175\n",
      "Epoch 67/200, Iteration 82/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 84/250, Loss: 0.0095\n",
      "Epoch 67/200, Iteration 85/250, Loss: 0.0176\n",
      "Epoch 67/200, Iteration 86/250, Loss: 0.0097\n",
      "Epoch 67/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 88/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 89/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 90/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 91/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 92/250, Loss: 0.0114\n",
      "Epoch 67/200, Iteration 93/250, Loss: 0.0182\n",
      "Epoch 67/200, Iteration 94/250, Loss: 0.0180\n",
      "Epoch 67/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 96/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 97/250, Loss: 0.0151\n",
      "Epoch 67/200, Iteration 98/250, Loss: 0.0104\n",
      "Epoch 67/200, Iteration 99/250, Loss: 0.0206\n",
      "Epoch 67/200, Iteration 100/250, Loss: 0.0192\n",
      "Epoch 67/200, Iteration 101/250, Loss: 0.0084\n",
      "Epoch 67/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 67/200, Iteration 103/250, Loss: 0.0347\n",
      "Epoch 67/200, Iteration 104/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 105/250, Loss: 0.0083\n",
      "Epoch 67/200, Iteration 106/250, Loss: 0.0123\n",
      "Epoch 67/200, Iteration 107/250, Loss: 0.0152\n",
      "Epoch 67/200, Iteration 108/250, Loss: 0.0185\n",
      "Epoch 67/200, Iteration 109/250, Loss: 0.0108\n",
      "Epoch 67/200, Iteration 110/250, Loss: 0.0127\n",
      "Epoch 67/200, Iteration 111/250, Loss: 0.0122\n",
      "Epoch 67/200, Iteration 112/250, Loss: 0.0204\n",
      "Epoch 67/200, Iteration 113/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 114/250, Loss: 0.0478\n",
      "Epoch 67/200, Iteration 115/250, Loss: 0.0224\n",
      "Epoch 67/200, Iteration 116/250, Loss: 0.0095\n",
      "Epoch 67/200, Iteration 117/250, Loss: 0.0118\n",
      "Epoch 67/200, Iteration 118/250, Loss: 0.0174\n",
      "Epoch 67/200, Iteration 119/250, Loss: 0.0267\n",
      "Epoch 67/200, Iteration 120/250, Loss: 0.0122\n",
      "Epoch 67/200, Iteration 121/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 67/200, Iteration 123/250, Loss: 0.0190\n",
      "Epoch 67/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 67/200, Iteration 125/250, Loss: 0.0148\n",
      "Epoch 67/200, Iteration 126/250, Loss: 0.0215\n",
      "Epoch 67/200, Iteration 127/250, Loss: 0.0097\n",
      "Epoch 67/200, Iteration 128/250, Loss: 0.0187\n",
      "Epoch 67/200, Iteration 129/250, Loss: 0.0203\n",
      "Epoch 67/200, Iteration 130/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 131/250, Loss: 0.0160\n",
      "Epoch 67/200, Iteration 132/250, Loss: 0.0091\n",
      "Epoch 67/200, Iteration 133/250, Loss: 0.0094\n",
      "Epoch 67/200, Iteration 134/250, Loss: 0.0191\n",
      "Epoch 67/200, Iteration 135/250, Loss: 0.0096\n",
      "Epoch 67/200, Iteration 136/250, Loss: 0.0319\n",
      "Epoch 67/200, Iteration 137/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 138/250, Loss: 0.0256\n",
      "Epoch 67/200, Iteration 139/250, Loss: 0.0456\n",
      "Epoch 67/200, Iteration 140/250, Loss: 0.0241\n",
      "Epoch 67/200, Iteration 141/250, Loss: 0.0170\n",
      "Epoch 67/200, Iteration 142/250, Loss: 0.0189\n",
      "Epoch 67/200, Iteration 143/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 144/250, Loss: 0.0149\n",
      "Epoch 67/200, Iteration 145/250, Loss: 0.0128\n",
      "Epoch 67/200, Iteration 146/250, Loss: 0.0182\n",
      "Epoch 67/200, Iteration 147/250, Loss: 0.0225\n",
      "Epoch 67/200, Iteration 148/250, Loss: 0.0090\n",
      "Epoch 67/200, Iteration 149/250, Loss: 0.0314\n",
      "Epoch 67/200, Iteration 150/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 151/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 152/250, Loss: 0.0089\n",
      "Epoch 67/200, Iteration 153/250, Loss: 0.0203\n",
      "Epoch 67/200, Iteration 154/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 155/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 156/250, Loss: 0.0230\n",
      "Epoch 67/200, Iteration 157/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 158/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 159/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 67/200, Iteration 161/250, Loss: 0.0175\n",
      "Epoch 67/200, Iteration 162/250, Loss: 0.0334\n",
      "Epoch 67/200, Iteration 163/250, Loss: 0.0135\n",
      "Epoch 67/200, Iteration 164/250, Loss: 0.0289\n",
      "Epoch 67/200, Iteration 165/250, Loss: 0.0176\n",
      "Epoch 67/200, Iteration 166/250, Loss: 0.0187\n",
      "Epoch 67/200, Iteration 167/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 168/250, Loss: 0.0147\n",
      "Epoch 67/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 67/200, Iteration 170/250, Loss: 0.0093\n",
      "Epoch 67/200, Iteration 171/250, Loss: 0.0072\n",
      "Epoch 67/200, Iteration 172/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 173/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 174/250, Loss: 0.0293\n",
      "Epoch 67/200, Iteration 175/250, Loss: 0.0132\n",
      "Epoch 67/200, Iteration 176/250, Loss: 0.0261\n",
      "Epoch 67/200, Iteration 177/250, Loss: 0.0185\n",
      "Epoch 67/200, Iteration 178/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 179/250, Loss: 0.0121\n",
      "Epoch 67/200, Iteration 180/250, Loss: 0.0133\n",
      "Epoch 67/200, Iteration 181/250, Loss: 0.0141\n",
      "Epoch 67/200, Iteration 182/250, Loss: 0.0059\n",
      "Epoch 67/200, Iteration 183/250, Loss: 0.0090\n",
      "Epoch 67/200, Iteration 184/250, Loss: 0.0125\n",
      "Epoch 67/200, Iteration 185/250, Loss: 0.0064\n",
      "Epoch 67/200, Iteration 186/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 187/250, Loss: 0.0334\n",
      "Epoch 67/200, Iteration 188/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 189/250, Loss: 0.0175\n",
      "Epoch 67/200, Iteration 190/250, Loss: 0.0112\n",
      "Epoch 67/200, Iteration 191/250, Loss: 0.0382\n",
      "Epoch 67/200, Iteration 192/250, Loss: 0.0151\n",
      "Epoch 67/200, Iteration 193/250, Loss: 0.0318\n",
      "Epoch 67/200, Iteration 194/250, Loss: 0.0088\n",
      "Epoch 67/200, Iteration 195/250, Loss: 0.0181\n",
      "Epoch 67/200, Iteration 196/250, Loss: 0.0095\n",
      "Epoch 67/200, Iteration 197/250, Loss: 0.0084\n",
      "Epoch 67/200, Iteration 198/250, Loss: 0.0083\n",
      "Epoch 67/200, Iteration 199/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 200/250, Loss: 0.0143\n",
      "Epoch 67/200, Iteration 201/250, Loss: 0.0191\n",
      "Epoch 67/200, Iteration 202/250, Loss: 0.0135\n",
      "Epoch 67/200, Iteration 203/250, Loss: 0.0159\n",
      "Epoch 67/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 67/200, Iteration 205/250, Loss: 0.0231\n",
      "Epoch 67/200, Iteration 206/250, Loss: 0.0133\n",
      "Epoch 67/200, Iteration 207/250, Loss: 0.0146\n",
      "Epoch 67/200, Iteration 208/250, Loss: 0.0123\n",
      "Epoch 67/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 67/200, Iteration 210/250, Loss: 0.0209\n",
      "Epoch 67/200, Iteration 211/250, Loss: 0.0095\n",
      "Epoch 67/200, Iteration 212/250, Loss: 0.0312\n",
      "Epoch 67/200, Iteration 213/250, Loss: 0.0112\n",
      "Epoch 67/200, Iteration 214/250, Loss: 0.0141\n",
      "Epoch 67/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 67/200, Iteration 216/250, Loss: 0.0203\n",
      "Epoch 67/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 218/250, Loss: 0.0140\n",
      "Epoch 67/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 67/200, Iteration 220/250, Loss: 0.0182\n",
      "Epoch 67/200, Iteration 221/250, Loss: 0.0232\n",
      "Epoch 67/200, Iteration 222/250, Loss: 0.0142\n",
      "Epoch 67/200, Iteration 223/250, Loss: 0.0194\n",
      "Epoch 67/200, Iteration 224/250, Loss: 0.0159\n",
      "Epoch 67/200, Iteration 225/250, Loss: 0.0150\n",
      "Epoch 67/200, Iteration 226/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 227/250, Loss: 0.0154\n",
      "Epoch 67/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 67/200, Iteration 229/250, Loss: 0.0087\n",
      "Epoch 67/200, Iteration 230/250, Loss: 0.0211\n",
      "Epoch 67/200, Iteration 231/250, Loss: 0.0098\n",
      "Epoch 67/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 233/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 234/250, Loss: 0.0080\n",
      "Epoch 67/200, Iteration 235/250, Loss: 0.0117\n",
      "Epoch 67/200, Iteration 236/250, Loss: 0.0101\n",
      "Epoch 67/200, Iteration 237/250, Loss: 0.0179\n",
      "Epoch 67/200, Iteration 238/250, Loss: 0.0148\n",
      "Epoch 67/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 67/200, Iteration 240/250, Loss: 0.0160\n",
      "Epoch 67/200, Iteration 241/250, Loss: 0.0122\n",
      "Epoch 67/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 67/200, Iteration 243/250, Loss: 0.0096\n",
      "Epoch 67/200, Iteration 244/250, Loss: 0.0326\n",
      "Epoch 67/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 246/250, Loss: 0.0128\n",
      "Epoch 67/200, Iteration 247/250, Loss: 0.0076\n",
      "Epoch 67/200, Iteration 248/250, Loss: 0.0099\n",
      "Epoch 67/200, Iteration 249/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 250/250, Loss: 0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.14%, Avg loss: 0.012912, MRE: 1.343081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.45%, Avg loss: 0.012812, MRE: 1.694788 \n",
      "\n",
      "Epoch 68/200, Iteration 1/250, Loss: 0.0109\n",
      "Epoch 68/200, Iteration 2/250, Loss: 0.0290\n",
      "Epoch 68/200, Iteration 3/250, Loss: 0.0117\n",
      "Epoch 68/200, Iteration 4/250, Loss: 0.0093\n",
      "Epoch 68/200, Iteration 5/250, Loss: 0.0301\n",
      "Epoch 68/200, Iteration 6/250, Loss: 0.0166\n",
      "Epoch 68/200, Iteration 7/250, Loss: 0.0312\n",
      "Epoch 68/200, Iteration 8/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 9/250, Loss: 0.0161\n",
      "Epoch 68/200, Iteration 10/250, Loss: 0.0094\n",
      "Epoch 68/200, Iteration 11/250, Loss: 0.0181\n",
      "Epoch 68/200, Iteration 12/250, Loss: 0.0163\n",
      "Epoch 68/200, Iteration 13/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 14/250, Loss: 0.0193\n",
      "Epoch 68/200, Iteration 15/250, Loss: 0.0345\n",
      "Epoch 68/200, Iteration 16/250, Loss: 0.0437\n",
      "Epoch 68/200, Iteration 17/250, Loss: 0.0142\n",
      "Epoch 68/200, Iteration 18/250, Loss: 0.0300\n",
      "Epoch 68/200, Iteration 19/250, Loss: 0.0242\n",
      "Epoch 68/200, Iteration 20/250, Loss: 0.0143\n",
      "Epoch 68/200, Iteration 21/250, Loss: 0.0085\n",
      "Epoch 68/200, Iteration 22/250, Loss: 0.0187\n",
      "Epoch 68/200, Iteration 23/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 24/250, Loss: 0.0227\n",
      "Epoch 68/200, Iteration 25/250, Loss: 0.0182\n",
      "Epoch 68/200, Iteration 26/250, Loss: 0.0093\n",
      "Epoch 68/200, Iteration 27/250, Loss: 0.0089\n",
      "Epoch 68/200, Iteration 28/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 29/250, Loss: 0.0187\n",
      "Epoch 68/200, Iteration 30/250, Loss: 0.0125\n",
      "Epoch 68/200, Iteration 31/250, Loss: 0.0215\n",
      "Epoch 68/200, Iteration 32/250, Loss: 0.0145\n",
      "Epoch 68/200, Iteration 33/250, Loss: 0.0165\n",
      "Epoch 68/200, Iteration 34/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 35/250, Loss: 0.0095\n",
      "Epoch 68/200, Iteration 36/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 37/250, Loss: 0.0139\n",
      "Epoch 68/200, Iteration 38/250, Loss: 0.0248\n",
      "Epoch 68/200, Iteration 39/250, Loss: 0.0079\n",
      "Epoch 68/200, Iteration 40/250, Loss: 0.0083\n",
      "Epoch 68/200, Iteration 41/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 42/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 43/250, Loss: 0.0096\n",
      "Epoch 68/200, Iteration 44/250, Loss: 0.0095\n",
      "Epoch 68/200, Iteration 45/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 46/250, Loss: 0.0149\n",
      "Epoch 68/200, Iteration 47/250, Loss: 0.0281\n",
      "Epoch 68/200, Iteration 48/250, Loss: 0.0083\n",
      "Epoch 68/200, Iteration 49/250, Loss: 0.0164\n",
      "Epoch 68/200, Iteration 50/250, Loss: 0.0221\n",
      "Epoch 68/200, Iteration 51/250, Loss: 0.0179\n",
      "Epoch 68/200, Iteration 52/250, Loss: 0.0153\n",
      "Epoch 68/200, Iteration 53/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 68/200, Iteration 55/250, Loss: 0.0091\n",
      "Epoch 68/200, Iteration 56/250, Loss: 0.0201\n",
      "Epoch 68/200, Iteration 57/250, Loss: 0.0091\n",
      "Epoch 68/200, Iteration 58/250, Loss: 0.0113\n",
      "Epoch 68/200, Iteration 59/250, Loss: 0.0107\n",
      "Epoch 68/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 68/200, Iteration 61/250, Loss: 0.0307\n",
      "Epoch 68/200, Iteration 62/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 63/250, Loss: 0.0140\n",
      "Epoch 68/200, Iteration 64/250, Loss: 0.0110\n",
      "Epoch 68/200, Iteration 65/250, Loss: 0.0056\n",
      "Epoch 68/200, Iteration 66/250, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 67/250, Loss: 0.0110\n",
      "Epoch 68/200, Iteration 68/250, Loss: 0.0116\n",
      "Epoch 68/200, Iteration 69/250, Loss: 0.0190\n",
      "Epoch 68/200, Iteration 70/250, Loss: 0.0489\n",
      "Epoch 68/200, Iteration 71/250, Loss: 0.0292\n",
      "Epoch 68/200, Iteration 72/250, Loss: 0.0140\n",
      "Epoch 68/200, Iteration 73/250, Loss: 0.0143\n",
      "Epoch 68/200, Iteration 74/250, Loss: 0.0212\n",
      "Epoch 68/200, Iteration 75/250, Loss: 0.0437\n",
      "Epoch 68/200, Iteration 76/250, Loss: 0.0087\n",
      "Epoch 68/200, Iteration 77/250, Loss: 0.0307\n",
      "Epoch 68/200, Iteration 78/250, Loss: 0.0176\n",
      "Epoch 68/200, Iteration 79/250, Loss: 0.0292\n",
      "Epoch 68/200, Iteration 80/250, Loss: 0.0066\n",
      "Epoch 68/200, Iteration 81/250, Loss: 0.0384\n",
      "Epoch 68/200, Iteration 82/250, Loss: 0.0202\n",
      "Epoch 68/200, Iteration 83/250, Loss: 0.0110\n",
      "Epoch 68/200, Iteration 84/250, Loss: 0.0103\n",
      "Epoch 68/200, Iteration 85/250, Loss: 0.0247\n",
      "Epoch 68/200, Iteration 86/250, Loss: 0.0077\n",
      "Epoch 68/200, Iteration 87/250, Loss: 0.0208\n",
      "Epoch 68/200, Iteration 88/250, Loss: 0.0060\n",
      "Epoch 68/200, Iteration 89/250, Loss: 0.0163\n",
      "Epoch 68/200, Iteration 90/250, Loss: 0.0153\n",
      "Epoch 68/200, Iteration 91/250, Loss: 0.0276\n",
      "Epoch 68/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 93/250, Loss: 0.0114\n",
      "Epoch 68/200, Iteration 94/250, Loss: 0.0169\n",
      "Epoch 68/200, Iteration 95/250, Loss: 0.0141\n",
      "Epoch 68/200, Iteration 96/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 68/200, Iteration 98/250, Loss: 0.0108\n",
      "Epoch 68/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 101/250, Loss: 0.0369\n",
      "Epoch 68/200, Iteration 102/250, Loss: 0.0251\n",
      "Epoch 68/200, Iteration 103/250, Loss: 0.0185\n",
      "Epoch 68/200, Iteration 104/250, Loss: 0.0188\n",
      "Epoch 68/200, Iteration 105/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 106/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 107/250, Loss: 0.0427\n",
      "Epoch 68/200, Iteration 108/250, Loss: 0.0208\n",
      "Epoch 68/200, Iteration 109/250, Loss: 0.0082\n",
      "Epoch 68/200, Iteration 110/250, Loss: 0.0282\n",
      "Epoch 68/200, Iteration 111/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 112/250, Loss: 0.0161\n",
      "Epoch 68/200, Iteration 113/250, Loss: 0.0161\n",
      "Epoch 68/200, Iteration 114/250, Loss: 0.0220\n",
      "Epoch 68/200, Iteration 115/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 116/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 117/250, Loss: 0.0086\n",
      "Epoch 68/200, Iteration 118/250, Loss: 0.0112\n",
      "Epoch 68/200, Iteration 119/250, Loss: 0.0248\n",
      "Epoch 68/200, Iteration 120/250, Loss: 0.0195\n",
      "Epoch 68/200, Iteration 121/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 122/250, Loss: 0.0425\n",
      "Epoch 68/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 124/250, Loss: 0.0112\n",
      "Epoch 68/200, Iteration 125/250, Loss: 0.0341\n",
      "Epoch 68/200, Iteration 126/250, Loss: 0.0123\n",
      "Epoch 68/200, Iteration 127/250, Loss: 0.0239\n",
      "Epoch 68/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 68/200, Iteration 129/250, Loss: 0.0107\n",
      "Epoch 68/200, Iteration 130/250, Loss: 0.0119\n",
      "Epoch 68/200, Iteration 131/250, Loss: 0.0201\n",
      "Epoch 68/200, Iteration 132/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 133/250, Loss: 0.0200\n",
      "Epoch 68/200, Iteration 134/250, Loss: 0.0156\n",
      "Epoch 68/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 136/250, Loss: 0.0361\n",
      "Epoch 68/200, Iteration 137/250, Loss: 0.0144\n",
      "Epoch 68/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 68/200, Iteration 139/250, Loss: 0.0217\n",
      "Epoch 68/200, Iteration 140/250, Loss: 0.0149\n",
      "Epoch 68/200, Iteration 141/250, Loss: 0.0138\n",
      "Epoch 68/200, Iteration 142/250, Loss: 0.0304\n",
      "Epoch 68/200, Iteration 143/250, Loss: 0.0156\n",
      "Epoch 68/200, Iteration 144/250, Loss: 0.0202\n",
      "Epoch 68/200, Iteration 145/250, Loss: 0.0117\n",
      "Epoch 68/200, Iteration 146/250, Loss: 0.0142\n",
      "Epoch 68/200, Iteration 147/250, Loss: 0.0130\n",
      "Epoch 68/200, Iteration 148/250, Loss: 0.0125\n",
      "Epoch 68/200, Iteration 149/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 150/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 151/250, Loss: 0.0113\n",
      "Epoch 68/200, Iteration 152/250, Loss: 0.0207\n",
      "Epoch 68/200, Iteration 153/250, Loss: 0.0115\n",
      "Epoch 68/200, Iteration 154/250, Loss: 0.0264\n",
      "Epoch 68/200, Iteration 155/250, Loss: 0.0133\n",
      "Epoch 68/200, Iteration 156/250, Loss: 0.0194\n",
      "Epoch 68/200, Iteration 157/250, Loss: 0.0177\n",
      "Epoch 68/200, Iteration 158/250, Loss: 0.0144\n",
      "Epoch 68/200, Iteration 159/250, Loss: 0.0114\n",
      "Epoch 68/200, Iteration 160/250, Loss: 0.0208\n",
      "Epoch 68/200, Iteration 161/250, Loss: 0.0124\n",
      "Epoch 68/200, Iteration 162/250, Loss: 0.0117\n",
      "Epoch 68/200, Iteration 163/250, Loss: 0.0132\n",
      "Epoch 68/200, Iteration 164/250, Loss: 0.0388\n",
      "Epoch 68/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 68/200, Iteration 166/250, Loss: 0.0195\n",
      "Epoch 68/200, Iteration 167/250, Loss: 0.0082\n",
      "Epoch 68/200, Iteration 168/250, Loss: 0.0139\n",
      "Epoch 68/200, Iteration 169/250, Loss: 0.0088\n",
      "Epoch 68/200, Iteration 170/250, Loss: 0.0276\n",
      "Epoch 68/200, Iteration 171/250, Loss: 0.0191\n",
      "Epoch 68/200, Iteration 172/250, Loss: 0.0178\n",
      "Epoch 68/200, Iteration 173/250, Loss: 0.0319\n",
      "Epoch 68/200, Iteration 174/250, Loss: 0.0087\n",
      "Epoch 68/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 68/200, Iteration 176/250, Loss: 0.0186\n",
      "Epoch 68/200, Iteration 177/250, Loss: 0.0066\n",
      "Epoch 68/200, Iteration 178/250, Loss: 0.0357\n",
      "Epoch 68/200, Iteration 179/250, Loss: 0.0063\n",
      "Epoch 68/200, Iteration 180/250, Loss: 0.0142\n",
      "Epoch 68/200, Iteration 181/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 182/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 183/250, Loss: 0.0126\n",
      "Epoch 68/200, Iteration 184/250, Loss: 0.0113\n",
      "Epoch 68/200, Iteration 185/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 186/250, Loss: 0.0197\n",
      "Epoch 68/200, Iteration 187/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 188/250, Loss: 0.0134\n",
      "Epoch 68/200, Iteration 189/250, Loss: 0.0153\n",
      "Epoch 68/200, Iteration 190/250, Loss: 0.0192\n",
      "Epoch 68/200, Iteration 191/250, Loss: 0.0351\n",
      "Epoch 68/200, Iteration 192/250, Loss: 0.0354\n",
      "Epoch 68/200, Iteration 193/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200, Iteration 194/250, Loss: 0.0130\n",
      "Epoch 68/200, Iteration 195/250, Loss: 0.0192\n",
      "Epoch 68/200, Iteration 196/250, Loss: 0.0196\n",
      "Epoch 68/200, Iteration 197/250, Loss: 0.0207\n",
      "Epoch 68/200, Iteration 198/250, Loss: 0.0164\n",
      "Epoch 68/200, Iteration 199/250, Loss: 0.0126\n",
      "Epoch 68/200, Iteration 200/250, Loss: 0.0421\n",
      "Epoch 68/200, Iteration 201/250, Loss: 0.0142\n",
      "Epoch 68/200, Iteration 202/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 203/250, Loss: 0.0212\n",
      "Epoch 68/200, Iteration 204/250, Loss: 0.0168\n",
      "Epoch 68/200, Iteration 205/250, Loss: 0.0174\n",
      "Epoch 68/200, Iteration 206/250, Loss: 0.0331\n",
      "Epoch 68/200, Iteration 207/250, Loss: 0.0157\n",
      "Epoch 68/200, Iteration 208/250, Loss: 0.0187\n",
      "Epoch 68/200, Iteration 209/250, Loss: 0.0093\n",
      "Epoch 68/200, Iteration 210/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 211/250, Loss: 0.0204\n",
      "Epoch 68/200, Iteration 212/250, Loss: 0.0147\n",
      "Epoch 68/200, Iteration 213/250, Loss: 0.0132\n",
      "Epoch 68/200, Iteration 214/250, Loss: 0.0129\n",
      "Epoch 68/200, Iteration 215/250, Loss: 0.0075\n",
      "Epoch 68/200, Iteration 216/250, Loss: 0.0322\n",
      "Epoch 68/200, Iteration 217/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 218/250, Loss: 0.0112\n",
      "Epoch 68/200, Iteration 219/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 220/250, Loss: 0.0199\n",
      "Epoch 68/200, Iteration 221/250, Loss: 0.0109\n",
      "Epoch 68/200, Iteration 222/250, Loss: 0.0103\n",
      "Epoch 68/200, Iteration 223/250, Loss: 0.0180\n",
      "Epoch 68/200, Iteration 224/250, Loss: 0.0068\n",
      "Epoch 68/200, Iteration 225/250, Loss: 0.0154\n",
      "Epoch 68/200, Iteration 226/250, Loss: 0.0077\n",
      "Epoch 68/200, Iteration 227/250, Loss: 0.0250\n",
      "Epoch 68/200, Iteration 228/250, Loss: 0.0500\n",
      "Epoch 68/200, Iteration 229/250, Loss: 0.0225\n",
      "Epoch 68/200, Iteration 230/250, Loss: 0.0193\n",
      "Epoch 68/200, Iteration 231/250, Loss: 0.0233\n",
      "Epoch 68/200, Iteration 232/250, Loss: 0.0208\n",
      "Epoch 68/200, Iteration 233/250, Loss: 0.0248\n",
      "Epoch 68/200, Iteration 234/250, Loss: 0.0191\n",
      "Epoch 68/200, Iteration 235/250, Loss: 0.0115\n",
      "Epoch 68/200, Iteration 236/250, Loss: 0.0258\n",
      "Epoch 68/200, Iteration 237/250, Loss: 0.0194\n",
      "Epoch 68/200, Iteration 238/250, Loss: 0.0078\n",
      "Epoch 68/200, Iteration 239/250, Loss: 0.0329\n",
      "Epoch 68/200, Iteration 240/250, Loss: 0.0065\n",
      "Epoch 68/200, Iteration 241/250, Loss: 0.0106\n",
      "Epoch 68/200, Iteration 242/250, Loss: 0.0330\n",
      "Epoch 68/200, Iteration 243/250, Loss: 0.0221\n",
      "Epoch 68/200, Iteration 244/250, Loss: 0.0175\n",
      "Epoch 68/200, Iteration 245/250, Loss: 0.0216\n",
      "Epoch 68/200, Iteration 246/250, Loss: 0.0146\n",
      "Epoch 68/200, Iteration 247/250, Loss: 0.0081\n",
      "Epoch 68/200, Iteration 248/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 249/250, Loss: 0.0108\n",
      "Epoch 68/200, Iteration 250/250, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 84.59%, Avg loss: 0.007098, MRE: 0.624078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007171, MRE: 1.008978 \n",
      "\n",
      "Epoch 69/200, Iteration 1/250, Loss: 0.0118\n",
      "Epoch 69/200, Iteration 2/250, Loss: 0.0446\n",
      "Epoch 69/200, Iteration 3/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 4/250, Loss: 0.0186\n",
      "Epoch 69/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 69/200, Iteration 6/250, Loss: 0.0164\n",
      "Epoch 69/200, Iteration 7/250, Loss: 0.0097\n",
      "Epoch 69/200, Iteration 8/250, Loss: 0.0086\n",
      "Epoch 69/200, Iteration 9/250, Loss: 0.0336\n",
      "Epoch 69/200, Iteration 10/250, Loss: 0.0086\n",
      "Epoch 69/200, Iteration 11/250, Loss: 0.0093\n",
      "Epoch 69/200, Iteration 12/250, Loss: 0.0061\n",
      "Epoch 69/200, Iteration 13/250, Loss: 0.0167\n",
      "Epoch 69/200, Iteration 14/250, Loss: 0.0169\n",
      "Epoch 69/200, Iteration 15/250, Loss: 0.0174\n",
      "Epoch 69/200, Iteration 16/250, Loss: 0.0215\n",
      "Epoch 69/200, Iteration 17/250, Loss: 0.0390\n",
      "Epoch 69/200, Iteration 18/250, Loss: 0.0202\n",
      "Epoch 69/200, Iteration 19/250, Loss: 0.0347\n",
      "Epoch 69/200, Iteration 20/250, Loss: 0.0238\n",
      "Epoch 69/200, Iteration 21/250, Loss: 0.0225\n",
      "Epoch 69/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 69/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 69/200, Iteration 24/250, Loss: 0.0065\n",
      "Epoch 69/200, Iteration 25/250, Loss: 0.0138\n",
      "Epoch 69/200, Iteration 26/250, Loss: 0.0090\n",
      "Epoch 69/200, Iteration 27/250, Loss: 0.0159\n",
      "Epoch 69/200, Iteration 28/250, Loss: 0.0211\n",
      "Epoch 69/200, Iteration 29/250, Loss: 0.0112\n",
      "Epoch 69/200, Iteration 30/250, Loss: 0.0090\n",
      "Epoch 69/200, Iteration 31/250, Loss: 0.0258\n",
      "Epoch 69/200, Iteration 32/250, Loss: 0.0204\n",
      "Epoch 69/200, Iteration 33/250, Loss: 0.0280\n",
      "Epoch 69/200, Iteration 34/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 35/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 36/250, Loss: 0.0194\n",
      "Epoch 69/200, Iteration 37/250, Loss: 0.0105\n",
      "Epoch 69/200, Iteration 38/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 69/200, Iteration 40/250, Loss: 0.0102\n",
      "Epoch 69/200, Iteration 41/250, Loss: 0.0116\n",
      "Epoch 69/200, Iteration 42/250, Loss: 0.0178\n",
      "Epoch 69/200, Iteration 43/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 44/250, Loss: 0.0073\n",
      "Epoch 69/200, Iteration 45/250, Loss: 0.0116\n",
      "Epoch 69/200, Iteration 46/250, Loss: 0.0191\n",
      "Epoch 69/200, Iteration 47/250, Loss: 0.0136\n",
      "Epoch 69/200, Iteration 48/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 49/250, Loss: 0.0239\n",
      "Epoch 69/200, Iteration 50/250, Loss: 0.0132\n",
      "Epoch 69/200, Iteration 51/250, Loss: 0.0193\n",
      "Epoch 69/200, Iteration 52/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 53/250, Loss: 0.0208\n",
      "Epoch 69/200, Iteration 54/250, Loss: 0.0236\n",
      "Epoch 69/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 69/200, Iteration 56/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 57/250, Loss: 0.0307\n",
      "Epoch 69/200, Iteration 58/250, Loss: 0.0533\n",
      "Epoch 69/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 69/200, Iteration 60/250, Loss: 0.0132\n",
      "Epoch 69/200, Iteration 61/250, Loss: 0.0325\n",
      "Epoch 69/200, Iteration 62/250, Loss: 0.0161\n",
      "Epoch 69/200, Iteration 63/250, Loss: 0.0196\n",
      "Epoch 69/200, Iteration 64/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 65/250, Loss: 0.0090\n",
      "Epoch 69/200, Iteration 66/250, Loss: 0.0079\n",
      "Epoch 69/200, Iteration 67/250, Loss: 0.0245\n",
      "Epoch 69/200, Iteration 68/250, Loss: 0.0108\n",
      "Epoch 69/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 69/200, Iteration 70/250, Loss: 0.0075\n",
      "Epoch 69/200, Iteration 71/250, Loss: 0.0085\n",
      "Epoch 69/200, Iteration 72/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 73/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 74/250, Loss: 0.0132\n",
      "Epoch 69/200, Iteration 75/250, Loss: 0.0324\n",
      "Epoch 69/200, Iteration 76/250, Loss: 0.0109\n",
      "Epoch 69/200, Iteration 77/250, Loss: 0.0146\n",
      "Epoch 69/200, Iteration 78/250, Loss: 0.0218\n",
      "Epoch 69/200, Iteration 79/250, Loss: 0.0232\n",
      "Epoch 69/200, Iteration 80/250, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 81/250, Loss: 0.0075\n",
      "Epoch 69/200, Iteration 82/250, Loss: 0.0125\n",
      "Epoch 69/200, Iteration 83/250, Loss: 0.0381\n",
      "Epoch 69/200, Iteration 84/250, Loss: 0.0170\n",
      "Epoch 69/200, Iteration 85/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 86/250, Loss: 0.0170\n",
      "Epoch 69/200, Iteration 87/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 88/250, Loss: 0.0117\n",
      "Epoch 69/200, Iteration 89/250, Loss: 0.0131\n",
      "Epoch 69/200, Iteration 90/250, Loss: 0.0185\n",
      "Epoch 69/200, Iteration 91/250, Loss: 0.0337\n",
      "Epoch 69/200, Iteration 92/250, Loss: 0.0088\n",
      "Epoch 69/200, Iteration 93/250, Loss: 0.0125\n",
      "Epoch 69/200, Iteration 94/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 95/250, Loss: 0.0098\n",
      "Epoch 69/200, Iteration 96/250, Loss: 0.0270\n",
      "Epoch 69/200, Iteration 97/250, Loss: 0.0063\n",
      "Epoch 69/200, Iteration 98/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 99/250, Loss: 0.0469\n",
      "Epoch 69/200, Iteration 100/250, Loss: 0.0211\n",
      "Epoch 69/200, Iteration 101/250, Loss: 0.0184\n",
      "Epoch 69/200, Iteration 102/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 103/250, Loss: 0.0127\n",
      "Epoch 69/200, Iteration 104/250, Loss: 0.0261\n",
      "Epoch 69/200, Iteration 105/250, Loss: 0.0155\n",
      "Epoch 69/200, Iteration 106/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 107/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 108/250, Loss: 0.0083\n",
      "Epoch 69/200, Iteration 109/250, Loss: 0.0349\n",
      "Epoch 69/200, Iteration 110/250, Loss: 0.0146\n",
      "Epoch 69/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 69/200, Iteration 112/250, Loss: 0.0286\n",
      "Epoch 69/200, Iteration 113/250, Loss: 0.0136\n",
      "Epoch 69/200, Iteration 114/250, Loss: 0.0116\n",
      "Epoch 69/200, Iteration 115/250, Loss: 0.0314\n",
      "Epoch 69/200, Iteration 116/250, Loss: 0.0164\n",
      "Epoch 69/200, Iteration 117/250, Loss: 0.0300\n",
      "Epoch 69/200, Iteration 118/250, Loss: 0.0155\n",
      "Epoch 69/200, Iteration 119/250, Loss: 0.0103\n",
      "Epoch 69/200, Iteration 120/250, Loss: 0.0080\n",
      "Epoch 69/200, Iteration 121/250, Loss: 0.0121\n",
      "Epoch 69/200, Iteration 122/250, Loss: 0.0111\n",
      "Epoch 69/200, Iteration 123/250, Loss: 0.0088\n",
      "Epoch 69/200, Iteration 124/250, Loss: 0.0203\n",
      "Epoch 69/200, Iteration 125/250, Loss: 0.0256\n",
      "Epoch 69/200, Iteration 126/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 127/250, Loss: 0.0106\n",
      "Epoch 69/200, Iteration 128/250, Loss: 0.0233\n",
      "Epoch 69/200, Iteration 129/250, Loss: 0.0143\n",
      "Epoch 69/200, Iteration 130/250, Loss: 0.0113\n",
      "Epoch 69/200, Iteration 131/250, Loss: 0.0414\n",
      "Epoch 69/200, Iteration 132/250, Loss: 0.0237\n",
      "Epoch 69/200, Iteration 133/250, Loss: 0.0155\n",
      "Epoch 69/200, Iteration 134/250, Loss: 0.0221\n",
      "Epoch 69/200, Iteration 135/250, Loss: 0.0177\n",
      "Epoch 69/200, Iteration 136/250, Loss: 0.0114\n",
      "Epoch 69/200, Iteration 137/250, Loss: 0.0075\n",
      "Epoch 69/200, Iteration 138/250, Loss: 0.0134\n",
      "Epoch 69/200, Iteration 139/250, Loss: 0.0167\n",
      "Epoch 69/200, Iteration 140/250, Loss: 0.0168\n",
      "Epoch 69/200, Iteration 141/250, Loss: 0.0233\n",
      "Epoch 69/200, Iteration 142/250, Loss: 0.0168\n",
      "Epoch 69/200, Iteration 143/250, Loss: 0.0263\n",
      "Epoch 69/200, Iteration 144/250, Loss: 0.0171\n",
      "Epoch 69/200, Iteration 145/250, Loss: 0.0070\n",
      "Epoch 69/200, Iteration 146/250, Loss: 0.0295\n",
      "Epoch 69/200, Iteration 147/250, Loss: 0.0165\n",
      "Epoch 69/200, Iteration 148/250, Loss: 0.0257\n",
      "Epoch 69/200, Iteration 149/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 150/250, Loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 69/200, Iteration 152/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 153/250, Loss: 0.0219\n",
      "Epoch 69/200, Iteration 154/250, Loss: 0.0166\n",
      "Epoch 69/200, Iteration 155/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 156/250, Loss: 0.0109\n",
      "Epoch 69/200, Iteration 157/250, Loss: 0.0082\n",
      "Epoch 69/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 159/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 160/250, Loss: 0.0141\n",
      "Epoch 69/200, Iteration 161/250, Loss: 0.0118\n",
      "Epoch 69/200, Iteration 162/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 163/250, Loss: 0.0092\n",
      "Epoch 69/200, Iteration 164/250, Loss: 0.0126\n",
      "Epoch 69/200, Iteration 165/250, Loss: 0.0312\n",
      "Epoch 69/200, Iteration 166/250, Loss: 0.0107\n",
      "Epoch 69/200, Iteration 167/250, Loss: 0.0344\n",
      "Epoch 69/200, Iteration 168/250, Loss: 0.0254\n",
      "Epoch 69/200, Iteration 169/250, Loss: 0.0163\n",
      "Epoch 69/200, Iteration 170/250, Loss: 0.0212\n",
      "Epoch 69/200, Iteration 171/250, Loss: 0.0104\n",
      "Epoch 69/200, Iteration 172/250, Loss: 0.0300\n",
      "Epoch 69/200, Iteration 173/250, Loss: 0.0139\n",
      "Epoch 69/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 175/250, Loss: 0.0167\n",
      "Epoch 69/200, Iteration 176/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 177/250, Loss: 0.0115\n",
      "Epoch 69/200, Iteration 178/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 179/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 180/250, Loss: 0.0222\n",
      "Epoch 69/200, Iteration 181/250, Loss: 0.0254\n",
      "Epoch 69/200, Iteration 182/250, Loss: 0.0099\n",
      "Epoch 69/200, Iteration 183/250, Loss: 0.0278\n",
      "Epoch 69/200, Iteration 184/250, Loss: 0.0260\n",
      "Epoch 69/200, Iteration 185/250, Loss: 0.0130\n",
      "Epoch 69/200, Iteration 186/250, Loss: 0.0201\n",
      "Epoch 69/200, Iteration 187/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 188/250, Loss: 0.0246\n",
      "Epoch 69/200, Iteration 189/250, Loss: 0.0301\n",
      "Epoch 69/200, Iteration 190/250, Loss: 0.0125\n",
      "Epoch 69/200, Iteration 191/250, Loss: 0.0173\n",
      "Epoch 69/200, Iteration 192/250, Loss: 0.0123\n",
      "Epoch 69/200, Iteration 193/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 194/250, Loss: 0.0084\n",
      "Epoch 69/200, Iteration 195/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 196/250, Loss: 0.0085\n",
      "Epoch 69/200, Iteration 197/250, Loss: 0.0208\n",
      "Epoch 69/200, Iteration 198/250, Loss: 0.0182\n",
      "Epoch 69/200, Iteration 199/250, Loss: 0.0206\n",
      "Epoch 69/200, Iteration 200/250, Loss: 0.0312\n",
      "Epoch 69/200, Iteration 201/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 202/250, Loss: 0.0425\n",
      "Epoch 69/200, Iteration 203/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 204/250, Loss: 0.0189\n",
      "Epoch 69/200, Iteration 205/250, Loss: 0.0335\n",
      "Epoch 69/200, Iteration 206/250, Loss: 0.0269\n",
      "Epoch 69/200, Iteration 207/250, Loss: 0.0167\n",
      "Epoch 69/200, Iteration 208/250, Loss: 0.0147\n",
      "Epoch 69/200, Iteration 209/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 210/250, Loss: 0.0273\n",
      "Epoch 69/200, Iteration 211/250, Loss: 0.0175\n",
      "Epoch 69/200, Iteration 212/250, Loss: 0.0109\n",
      "Epoch 69/200, Iteration 213/250, Loss: 0.0205\n",
      "Epoch 69/200, Iteration 214/250, Loss: 0.0313\n",
      "Epoch 69/200, Iteration 215/250, Loss: 0.0114\n",
      "Epoch 69/200, Iteration 216/250, Loss: 0.0184\n",
      "Epoch 69/200, Iteration 217/250, Loss: 0.0149\n",
      "Epoch 69/200, Iteration 218/250, Loss: 0.0207\n",
      "Epoch 69/200, Iteration 219/250, Loss: 0.0405\n",
      "Epoch 69/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 221/250, Loss: 0.0298\n",
      "Epoch 69/200, Iteration 222/250, Loss: 0.0269\n",
      "Epoch 69/200, Iteration 223/250, Loss: 0.0213\n",
      "Epoch 69/200, Iteration 224/250, Loss: 0.0143\n",
      "Epoch 69/200, Iteration 225/250, Loss: 0.0165\n",
      "Epoch 69/200, Iteration 226/250, Loss: 0.0064\n",
      "Epoch 69/200, Iteration 227/250, Loss: 0.0165\n",
      "Epoch 69/200, Iteration 228/250, Loss: 0.0161\n",
      "Epoch 69/200, Iteration 229/250, Loss: 0.0083\n",
      "Epoch 69/200, Iteration 230/250, Loss: 0.0214\n",
      "Epoch 69/200, Iteration 231/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 232/250, Loss: 0.0206\n",
      "Epoch 69/200, Iteration 233/250, Loss: 0.0184\n",
      "Epoch 69/200, Iteration 234/250, Loss: 0.0099\n",
      "Epoch 69/200, Iteration 235/250, Loss: 0.0063\n",
      "Epoch 69/200, Iteration 236/250, Loss: 0.0442\n",
      "Epoch 69/200, Iteration 237/250, Loss: 0.0137\n",
      "Epoch 69/200, Iteration 238/250, Loss: 0.0141\n",
      "Epoch 69/200, Iteration 239/250, Loss: 0.0218\n",
      "Epoch 69/200, Iteration 240/250, Loss: 0.0102\n",
      "Epoch 69/200, Iteration 241/250, Loss: 0.0187\n",
      "Epoch 69/200, Iteration 242/250, Loss: 0.0176\n",
      "Epoch 69/200, Iteration 243/250, Loss: 0.0163\n",
      "Epoch 69/200, Iteration 244/250, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 245/250, Loss: 0.0105\n",
      "Epoch 69/200, Iteration 246/250, Loss: 0.0170\n",
      "Epoch 69/200, Iteration 247/250, Loss: 0.0140\n",
      "Epoch 69/200, Iteration 248/250, Loss: 0.0074\n",
      "Epoch 69/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 69/200, Iteration 250/250, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.007007, MRE: 0.683736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.006935, MRE: 1.246127 \n",
      "\n",
      "Epoch 70/200, Iteration 1/250, Loss: 0.0110\n",
      "Epoch 70/200, Iteration 2/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 3/250, Loss: 0.0191\n",
      "Epoch 70/200, Iteration 4/250, Loss: 0.0246\n",
      "Epoch 70/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 70/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 70/200, Iteration 7/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 8/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 9/250, Loss: 0.0119\n",
      "Epoch 70/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 11/250, Loss: 0.0160\n",
      "Epoch 70/200, Iteration 12/250, Loss: 0.0158\n",
      "Epoch 70/200, Iteration 13/250, Loss: 0.0146\n",
      "Epoch 70/200, Iteration 14/250, Loss: 0.0135\n",
      "Epoch 70/200, Iteration 15/250, Loss: 0.0163\n",
      "Epoch 70/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 70/200, Iteration 17/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 18/250, Loss: 0.0105\n",
      "Epoch 70/200, Iteration 19/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 20/250, Loss: 0.0124\n",
      "Epoch 70/200, Iteration 21/250, Loss: 0.0352\n",
      "Epoch 70/200, Iteration 22/250, Loss: 0.0163\n",
      "Epoch 70/200, Iteration 23/250, Loss: 0.0178\n",
      "Epoch 70/200, Iteration 24/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 25/250, Loss: 0.0107\n",
      "Epoch 70/200, Iteration 26/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 27/250, Loss: 0.0117\n",
      "Epoch 70/200, Iteration 28/250, Loss: 0.0093\n",
      "Epoch 70/200, Iteration 29/250, Loss: 0.0422\n",
      "Epoch 70/200, Iteration 30/250, Loss: 0.0230\n",
      "Epoch 70/200, Iteration 31/250, Loss: 0.0233\n",
      "Epoch 70/200, Iteration 32/250, Loss: 0.0197\n",
      "Epoch 70/200, Iteration 33/250, Loss: 0.0189\n",
      "Epoch 70/200, Iteration 34/250, Loss: 0.0188\n",
      "Epoch 70/200, Iteration 35/250, Loss: 0.0189\n",
      "Epoch 70/200, Iteration 36/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 37/250, Loss: 0.0154\n",
      "Epoch 70/200, Iteration 38/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 39/250, Loss: 0.0265\n",
      "Epoch 70/200, Iteration 40/250, Loss: 0.0147\n",
      "Epoch 70/200, Iteration 41/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 42/250, Loss: 0.0239\n",
      "Epoch 70/200, Iteration 43/250, Loss: 0.0177\n",
      "Epoch 70/200, Iteration 44/250, Loss: 0.0125\n",
      "Epoch 70/200, Iteration 45/250, Loss: 0.0286\n",
      "Epoch 70/200, Iteration 46/250, Loss: 0.0419\n",
      "Epoch 70/200, Iteration 47/250, Loss: 0.0150\n",
      "Epoch 70/200, Iteration 48/250, Loss: 0.0088\n",
      "Epoch 70/200, Iteration 49/250, Loss: 0.0245\n",
      "Epoch 70/200, Iteration 50/250, Loss: 0.0207\n",
      "Epoch 70/200, Iteration 51/250, Loss: 0.0130\n",
      "Epoch 70/200, Iteration 52/250, Loss: 0.0079\n",
      "Epoch 70/200, Iteration 53/250, Loss: 0.0359\n",
      "Epoch 70/200, Iteration 54/250, Loss: 0.0179\n",
      "Epoch 70/200, Iteration 55/250, Loss: 0.0128\n",
      "Epoch 70/200, Iteration 56/250, Loss: 0.0131\n",
      "Epoch 70/200, Iteration 57/250, Loss: 0.0166\n",
      "Epoch 70/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 70/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 70/200, Iteration 60/250, Loss: 0.0194\n",
      "Epoch 70/200, Iteration 61/250, Loss: 0.0177\n",
      "Epoch 70/200, Iteration 62/250, Loss: 0.0203\n",
      "Epoch 70/200, Iteration 63/250, Loss: 0.0104\n",
      "Epoch 70/200, Iteration 64/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 65/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 70/200, Iteration 67/250, Loss: 0.0143\n",
      "Epoch 70/200, Iteration 68/250, Loss: 0.0123\n",
      "Epoch 70/200, Iteration 69/250, Loss: 0.0228\n",
      "Epoch 70/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 70/200, Iteration 71/250, Loss: 0.0068\n",
      "Epoch 70/200, Iteration 72/250, Loss: 0.0259\n",
      "Epoch 70/200, Iteration 73/250, Loss: 0.0172\n",
      "Epoch 70/200, Iteration 74/250, Loss: 0.0165\n",
      "Epoch 70/200, Iteration 75/250, Loss: 0.0144\n",
      "Epoch 70/200, Iteration 76/250, Loss: 0.0077\n",
      "Epoch 70/200, Iteration 77/250, Loss: 0.0133\n",
      "Epoch 70/200, Iteration 78/250, Loss: 0.0200\n",
      "Epoch 70/200, Iteration 79/250, Loss: 0.0107\n",
      "Epoch 70/200, Iteration 80/250, Loss: 0.0368\n",
      "Epoch 70/200, Iteration 81/250, Loss: 0.0121\n",
      "Epoch 70/200, Iteration 82/250, Loss: 0.0069\n",
      "Epoch 70/200, Iteration 83/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 84/250, Loss: 0.0189\n",
      "Epoch 70/200, Iteration 85/250, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 86/250, Loss: 0.0303\n",
      "Epoch 70/200, Iteration 87/250, Loss: 0.0280\n",
      "Epoch 70/200, Iteration 88/250, Loss: 0.0184\n",
      "Epoch 70/200, Iteration 89/250, Loss: 0.0098\n",
      "Epoch 70/200, Iteration 90/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 91/250, Loss: 0.0347\n",
      "Epoch 70/200, Iteration 92/250, Loss: 0.0076\n",
      "Epoch 70/200, Iteration 93/250, Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200, Iteration 94/250, Loss: 0.0201\n",
      "Epoch 70/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 70/200, Iteration 96/250, Loss: 0.0112\n",
      "Epoch 70/200, Iteration 97/250, Loss: 0.0224\n",
      "Epoch 70/200, Iteration 98/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 99/250, Loss: 0.0151\n",
      "Epoch 70/200, Iteration 100/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 102/250, Loss: 0.0146\n",
      "Epoch 70/200, Iteration 103/250, Loss: 0.0227\n",
      "Epoch 70/200, Iteration 104/250, Loss: 0.0353\n",
      "Epoch 70/200, Iteration 105/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 106/250, Loss: 0.0217\n",
      "Epoch 70/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 70/200, Iteration 108/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 109/250, Loss: 0.0070\n",
      "Epoch 70/200, Iteration 110/250, Loss: 0.0172\n",
      "Epoch 70/200, Iteration 111/250, Loss: 0.0172\n",
      "Epoch 70/200, Iteration 112/250, Loss: 0.0138\n",
      "Epoch 70/200, Iteration 113/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 114/250, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 115/250, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 116/250, Loss: 0.0123\n",
      "Epoch 70/200, Iteration 117/250, Loss: 0.0117\n",
      "Epoch 70/200, Iteration 118/250, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 119/250, Loss: 0.0151\n",
      "Epoch 70/200, Iteration 120/250, Loss: 0.0097\n",
      "Epoch 70/200, Iteration 121/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 122/250, Loss: 0.0104\n",
      "Epoch 70/200, Iteration 123/250, Loss: 0.0072\n",
      "Epoch 70/200, Iteration 124/250, Loss: 0.0384\n",
      "Epoch 70/200, Iteration 125/250, Loss: 0.0084\n",
      "Epoch 70/200, Iteration 126/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 127/250, Loss: 0.0192\n",
      "Epoch 70/200, Iteration 128/250, Loss: 0.0210\n",
      "Epoch 70/200, Iteration 129/250, Loss: 0.0220\n",
      "Epoch 70/200, Iteration 130/250, Loss: 0.0131\n",
      "Epoch 70/200, Iteration 131/250, Loss: 0.0173\n",
      "Epoch 70/200, Iteration 132/250, Loss: 0.0140\n",
      "Epoch 70/200, Iteration 133/250, Loss: 0.0169\n",
      "Epoch 70/200, Iteration 134/250, Loss: 0.0113\n",
      "Epoch 70/200, Iteration 135/250, Loss: 0.0119\n",
      "Epoch 70/200, Iteration 136/250, Loss: 0.0267\n",
      "Epoch 70/200, Iteration 137/250, Loss: 0.0244\n",
      "Epoch 70/200, Iteration 138/250, Loss: 0.0377\n",
      "Epoch 70/200, Iteration 139/250, Loss: 0.0259\n",
      "Epoch 70/200, Iteration 140/250, Loss: 0.0118\n",
      "Epoch 70/200, Iteration 141/250, Loss: 0.0111\n",
      "Epoch 70/200, Iteration 142/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 143/250, Loss: 0.0229\n",
      "Epoch 70/200, Iteration 144/250, Loss: 0.0259\n",
      "Epoch 70/200, Iteration 145/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 146/250, Loss: 0.0188\n",
      "Epoch 70/200, Iteration 147/250, Loss: 0.0142\n",
      "Epoch 70/200, Iteration 148/250, Loss: 0.0197\n",
      "Epoch 70/200, Iteration 149/250, Loss: 0.0120\n",
      "Epoch 70/200, Iteration 150/250, Loss: 0.0112\n",
      "Epoch 70/200, Iteration 151/250, Loss: 0.0111\n",
      "Epoch 70/200, Iteration 152/250, Loss: 0.0311\n",
      "Epoch 70/200, Iteration 153/250, Loss: 0.0166\n",
      "Epoch 70/200, Iteration 154/250, Loss: 0.0299\n",
      "Epoch 70/200, Iteration 155/250, Loss: 0.0064\n",
      "Epoch 70/200, Iteration 156/250, Loss: 0.0230\n",
      "Epoch 70/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 70/200, Iteration 158/250, Loss: 0.0120\n",
      "Epoch 70/200, Iteration 159/250, Loss: 0.0121\n",
      "Epoch 70/200, Iteration 160/250, Loss: 0.0205\n",
      "Epoch 70/200, Iteration 161/250, Loss: 0.0083\n",
      "Epoch 70/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 70/200, Iteration 163/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 164/250, Loss: 0.0171\n",
      "Epoch 70/200, Iteration 165/250, Loss: 0.0162\n",
      "Epoch 70/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 70/200, Iteration 167/250, Loss: 0.0150\n",
      "Epoch 70/200, Iteration 168/250, Loss: 0.0329\n",
      "Epoch 70/200, Iteration 169/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 170/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 171/250, Loss: 0.0146\n",
      "Epoch 70/200, Iteration 172/250, Loss: 0.0146\n",
      "Epoch 70/200, Iteration 173/250, Loss: 0.0243\n",
      "Epoch 70/200, Iteration 174/250, Loss: 0.0227\n",
      "Epoch 70/200, Iteration 175/250, Loss: 0.0190\n",
      "Epoch 70/200, Iteration 176/250, Loss: 0.0118\n",
      "Epoch 70/200, Iteration 177/250, Loss: 0.0138\n",
      "Epoch 70/200, Iteration 178/250, Loss: 0.0158\n",
      "Epoch 70/200, Iteration 179/250, Loss: 0.0201\n",
      "Epoch 70/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 70/200, Iteration 181/250, Loss: 0.0084\n",
      "Epoch 70/200, Iteration 182/250, Loss: 0.0322\n",
      "Epoch 70/200, Iteration 183/250, Loss: 0.0155\n",
      "Epoch 70/200, Iteration 184/250, Loss: 0.0194\n",
      "Epoch 70/200, Iteration 185/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 186/250, Loss: 0.0174\n",
      "Epoch 70/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 188/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 189/250, Loss: 0.0080\n",
      "Epoch 70/200, Iteration 190/250, Loss: 0.0290\n",
      "Epoch 70/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 192/250, Loss: 0.0243\n",
      "Epoch 70/200, Iteration 193/250, Loss: 0.0175\n",
      "Epoch 70/200, Iteration 194/250, Loss: 0.0091\n",
      "Epoch 70/200, Iteration 195/250, Loss: 0.0083\n",
      "Epoch 70/200, Iteration 196/250, Loss: 0.0155\n",
      "Epoch 70/200, Iteration 197/250, Loss: 0.0384\n",
      "Epoch 70/200, Iteration 198/250, Loss: 0.0205\n",
      "Epoch 70/200, Iteration 199/250, Loss: 0.0135\n",
      "Epoch 70/200, Iteration 200/250, Loss: 0.0148\n",
      "Epoch 70/200, Iteration 201/250, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 202/250, Loss: 0.0421\n",
      "Epoch 70/200, Iteration 203/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 204/250, Loss: 0.0113\n",
      "Epoch 70/200, Iteration 205/250, Loss: 0.0214\n",
      "Epoch 70/200, Iteration 206/250, Loss: 0.0268\n",
      "Epoch 70/200, Iteration 207/250, Loss: 0.0182\n",
      "Epoch 70/200, Iteration 208/250, Loss: 0.0276\n",
      "Epoch 70/200, Iteration 209/250, Loss: 0.0138\n",
      "Epoch 70/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 70/200, Iteration 211/250, Loss: 0.0443\n",
      "Epoch 70/200, Iteration 212/250, Loss: 0.0117\n",
      "Epoch 70/200, Iteration 213/250, Loss: 0.0073\n",
      "Epoch 70/200, Iteration 214/250, Loss: 0.0217\n",
      "Epoch 70/200, Iteration 215/250, Loss: 0.0261\n",
      "Epoch 70/200, Iteration 216/250, Loss: 0.0065\n",
      "Epoch 70/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 70/200, Iteration 218/250, Loss: 0.0166\n",
      "Epoch 70/200, Iteration 219/250, Loss: 0.0152\n",
      "Epoch 70/200, Iteration 220/250, Loss: 0.0152\n",
      "Epoch 70/200, Iteration 221/250, Loss: 0.0199\n",
      "Epoch 70/200, Iteration 222/250, Loss: 0.0233\n",
      "Epoch 70/200, Iteration 223/250, Loss: 0.0088\n",
      "Epoch 70/200, Iteration 224/250, Loss: 0.0216\n",
      "Epoch 70/200, Iteration 225/250, Loss: 0.0175\n",
      "Epoch 70/200, Iteration 226/250, Loss: 0.0196\n",
      "Epoch 70/200, Iteration 227/250, Loss: 0.0183\n",
      "Epoch 70/200, Iteration 228/250, Loss: 0.0337\n",
      "Epoch 70/200, Iteration 229/250, Loss: 0.0087\n",
      "Epoch 70/200, Iteration 230/250, Loss: 0.0282\n",
      "Epoch 70/200, Iteration 231/250, Loss: 0.0222\n",
      "Epoch 70/200, Iteration 232/250, Loss: 0.0123\n",
      "Epoch 70/200, Iteration 233/250, Loss: 0.0181\n",
      "Epoch 70/200, Iteration 234/250, Loss: 0.0397\n",
      "Epoch 70/200, Iteration 235/250, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 236/250, Loss: 0.0228\n",
      "Epoch 70/200, Iteration 237/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 238/250, Loss: 0.0265\n",
      "Epoch 70/200, Iteration 239/250, Loss: 0.0077\n",
      "Epoch 70/200, Iteration 240/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 241/250, Loss: 0.0150\n",
      "Epoch 70/200, Iteration 242/250, Loss: 0.0287\n",
      "Epoch 70/200, Iteration 243/250, Loss: 0.0299\n",
      "Epoch 70/200, Iteration 244/250, Loss: 0.0170\n",
      "Epoch 70/200, Iteration 245/250, Loss: 0.0238\n",
      "Epoch 70/200, Iteration 246/250, Loss: 0.0078\n",
      "Epoch 70/200, Iteration 247/250, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 248/250, Loss: 0.0158\n",
      "Epoch 70/200, Iteration 249/250, Loss: 0.0117\n",
      "Epoch 70/200, Iteration 250/250, Loss: 0.0269\n",
      "Train Error: \n",
      " Accuracy: 81.62%, Avg loss: 0.007224, MRE: 0.647681 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.35%, Avg loss: 0.007275, MRE: 0.974855 \n",
      "\n",
      "Epoch 71/200, Iteration 1/250, Loss: 0.0204\n",
      "Epoch 71/200, Iteration 2/250, Loss: 0.0239\n",
      "Epoch 71/200, Iteration 3/250, Loss: 0.0253\n",
      "Epoch 71/200, Iteration 4/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 5/250, Loss: 0.0188\n",
      "Epoch 71/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 71/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 71/200, Iteration 8/250, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 9/250, Loss: 0.0142\n",
      "Epoch 71/200, Iteration 10/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 11/250, Loss: 0.0178\n",
      "Epoch 71/200, Iteration 12/250, Loss: 0.0177\n",
      "Epoch 71/200, Iteration 13/250, Loss: 0.0121\n",
      "Epoch 71/200, Iteration 14/250, Loss: 0.0086\n",
      "Epoch 71/200, Iteration 15/250, Loss: 0.0138\n",
      "Epoch 71/200, Iteration 16/250, Loss: 0.0114\n",
      "Epoch 71/200, Iteration 17/250, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 18/250, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 19/250, Loss: 0.0166\n",
      "Epoch 71/200, Iteration 20/250, Loss: 0.0098\n",
      "Epoch 71/200, Iteration 21/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 22/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 24/250, Loss: 0.0172\n",
      "Epoch 71/200, Iteration 25/250, Loss: 0.0163\n",
      "Epoch 71/200, Iteration 26/250, Loss: 0.0085\n",
      "Epoch 71/200, Iteration 27/250, Loss: 0.0080\n",
      "Epoch 71/200, Iteration 28/250, Loss: 0.0433\n",
      "Epoch 71/200, Iteration 29/250, Loss: 0.0177\n",
      "Epoch 71/200, Iteration 30/250, Loss: 0.0101\n",
      "Epoch 71/200, Iteration 31/250, Loss: 0.0228\n",
      "Epoch 71/200, Iteration 32/250, Loss: 0.0471\n",
      "Epoch 71/200, Iteration 33/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 34/250, Loss: 0.0187\n",
      "Epoch 71/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 71/200, Iteration 36/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 37/250, Loss: 0.0175\n",
      "Epoch 71/200, Iteration 38/250, Loss: 0.0177\n",
      "Epoch 71/200, Iteration 39/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 40/250, Loss: 0.0255\n",
      "Epoch 71/200, Iteration 41/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 42/250, Loss: 0.0069\n",
      "Epoch 71/200, Iteration 43/250, Loss: 0.0262\n",
      "Epoch 71/200, Iteration 44/250, Loss: 0.0053\n",
      "Epoch 71/200, Iteration 45/250, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 46/250, Loss: 0.0295\n",
      "Epoch 71/200, Iteration 47/250, Loss: 0.0115\n",
      "Epoch 71/200, Iteration 48/250, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 49/250, Loss: 0.0217\n",
      "Epoch 71/200, Iteration 50/250, Loss: 0.0163\n",
      "Epoch 71/200, Iteration 51/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 52/250, Loss: 0.0207\n",
      "Epoch 71/200, Iteration 53/250, Loss: 0.0309\n",
      "Epoch 71/200, Iteration 54/250, Loss: 0.0234\n",
      "Epoch 71/200, Iteration 55/250, Loss: 0.0115\n",
      "Epoch 71/200, Iteration 56/250, Loss: 0.0122\n",
      "Epoch 71/200, Iteration 57/250, Loss: 0.0243\n",
      "Epoch 71/200, Iteration 58/250, Loss: 0.0143\n",
      "Epoch 71/200, Iteration 59/250, Loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 71/200, Iteration 61/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 62/250, Loss: 0.0259\n",
      "Epoch 71/200, Iteration 63/250, Loss: 0.0065\n",
      "Epoch 71/200, Iteration 64/250, Loss: 0.0398\n",
      "Epoch 71/200, Iteration 65/250, Loss: 0.0071\n",
      "Epoch 71/200, Iteration 66/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 67/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 68/250, Loss: 0.0172\n",
      "Epoch 71/200, Iteration 69/250, Loss: 0.0170\n",
      "Epoch 71/200, Iteration 70/250, Loss: 0.0207\n",
      "Epoch 71/200, Iteration 71/250, Loss: 0.0107\n",
      "Epoch 71/200, Iteration 72/250, Loss: 0.0234\n",
      "Epoch 71/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 71/200, Iteration 74/250, Loss: 0.0114\n",
      "Epoch 71/200, Iteration 75/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 76/250, Loss: 0.0239\n",
      "Epoch 71/200, Iteration 77/250, Loss: 0.0178\n",
      "Epoch 71/200, Iteration 78/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 79/250, Loss: 0.0424\n",
      "Epoch 71/200, Iteration 80/250, Loss: 0.0083\n",
      "Epoch 71/200, Iteration 81/250, Loss: 0.0125\n",
      "Epoch 71/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 71/200, Iteration 83/250, Loss: 0.0181\n",
      "Epoch 71/200, Iteration 84/250, Loss: 0.0266\n",
      "Epoch 71/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 71/200, Iteration 86/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 87/250, Loss: 0.0118\n",
      "Epoch 71/200, Iteration 88/250, Loss: 0.0096\n",
      "Epoch 71/200, Iteration 89/250, Loss: 0.0139\n",
      "Epoch 71/200, Iteration 90/250, Loss: 0.0276\n",
      "Epoch 71/200, Iteration 91/250, Loss: 0.0221\n",
      "Epoch 71/200, Iteration 92/250, Loss: 0.0177\n",
      "Epoch 71/200, Iteration 93/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 94/250, Loss: 0.0113\n",
      "Epoch 71/200, Iteration 95/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 96/250, Loss: 0.0159\n",
      "Epoch 71/200, Iteration 97/250, Loss: 0.0192\n",
      "Epoch 71/200, Iteration 98/250, Loss: 0.0063\n",
      "Epoch 71/200, Iteration 99/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 100/250, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 101/250, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 102/250, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 103/250, Loss: 0.0096\n",
      "Epoch 71/200, Iteration 104/250, Loss: 0.0112\n",
      "Epoch 71/200, Iteration 105/250, Loss: 0.0068\n",
      "Epoch 71/200, Iteration 106/250, Loss: 0.0188\n",
      "Epoch 71/200, Iteration 107/250, Loss: 0.0067\n",
      "Epoch 71/200, Iteration 108/250, Loss: 0.0195\n",
      "Epoch 71/200, Iteration 109/250, Loss: 0.0077\n",
      "Epoch 71/200, Iteration 110/250, Loss: 0.0136\n",
      "Epoch 71/200, Iteration 111/250, Loss: 0.0072\n",
      "Epoch 71/200, Iteration 112/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 113/250, Loss: 0.0080\n",
      "Epoch 71/200, Iteration 114/250, Loss: 0.0267\n",
      "Epoch 71/200, Iteration 115/250, Loss: 0.0120\n",
      "Epoch 71/200, Iteration 116/250, Loss: 0.0119\n",
      "Epoch 71/200, Iteration 117/250, Loss: 0.0079\n",
      "Epoch 71/200, Iteration 118/250, Loss: 0.0169\n",
      "Epoch 71/200, Iteration 119/250, Loss: 0.0077\n",
      "Epoch 71/200, Iteration 120/250, Loss: 0.0067\n",
      "Epoch 71/200, Iteration 121/250, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 122/250, Loss: 0.0237\n",
      "Epoch 71/200, Iteration 123/250, Loss: 0.0228\n",
      "Epoch 71/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 125/250, Loss: 0.0099\n",
      "Epoch 71/200, Iteration 126/250, Loss: 0.0218\n",
      "Epoch 71/200, Iteration 127/250, Loss: 0.0150\n",
      "Epoch 71/200, Iteration 128/250, Loss: 0.0099\n",
      "Epoch 71/200, Iteration 129/250, Loss: 0.0169\n",
      "Epoch 71/200, Iteration 130/250, Loss: 0.0228\n",
      "Epoch 71/200, Iteration 131/250, Loss: 0.0159\n",
      "Epoch 71/200, Iteration 132/250, Loss: 0.0163\n",
      "Epoch 71/200, Iteration 133/250, Loss: 0.0173\n",
      "Epoch 71/200, Iteration 134/250, Loss: 0.0147\n",
      "Epoch 71/200, Iteration 135/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 136/250, Loss: 0.0440\n",
      "Epoch 71/200, Iteration 137/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 138/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 139/250, Loss: 0.0194\n",
      "Epoch 71/200, Iteration 140/250, Loss: 0.0210\n",
      "Epoch 71/200, Iteration 141/250, Loss: 0.0227\n",
      "Epoch 71/200, Iteration 142/250, Loss: 0.0162\n",
      "Epoch 71/200, Iteration 143/250, Loss: 0.0295\n",
      "Epoch 71/200, Iteration 144/250, Loss: 0.0180\n",
      "Epoch 71/200, Iteration 145/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 146/250, Loss: 0.0166\n",
      "Epoch 71/200, Iteration 147/250, Loss: 0.0087\n",
      "Epoch 71/200, Iteration 148/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 149/250, Loss: 0.0169\n",
      "Epoch 71/200, Iteration 150/250, Loss: 0.0076\n",
      "Epoch 71/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 152/250, Loss: 0.0155\n",
      "Epoch 71/200, Iteration 153/250, Loss: 0.0072\n",
      "Epoch 71/200, Iteration 154/250, Loss: 0.0257\n",
      "Epoch 71/200, Iteration 155/250, Loss: 0.0279\n",
      "Epoch 71/200, Iteration 156/250, Loss: 0.0085\n",
      "Epoch 71/200, Iteration 157/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 158/250, Loss: 0.0140\n",
      "Epoch 71/200, Iteration 159/250, Loss: 0.0247\n",
      "Epoch 71/200, Iteration 160/250, Loss: 0.0227\n",
      "Epoch 71/200, Iteration 161/250, Loss: 0.0164\n",
      "Epoch 71/200, Iteration 162/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 163/250, Loss: 0.0183\n",
      "Epoch 71/200, Iteration 164/250, Loss: 0.0138\n",
      "Epoch 71/200, Iteration 165/250, Loss: 0.0187\n",
      "Epoch 71/200, Iteration 166/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 167/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 168/250, Loss: 0.0080\n",
      "Epoch 71/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 71/200, Iteration 170/250, Loss: 0.0271\n",
      "Epoch 71/200, Iteration 171/250, Loss: 0.0073\n",
      "Epoch 71/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 173/250, Loss: 0.0108\n",
      "Epoch 71/200, Iteration 174/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 175/250, Loss: 0.0170\n",
      "Epoch 71/200, Iteration 176/250, Loss: 0.0146\n",
      "Epoch 71/200, Iteration 177/250, Loss: 0.0184\n",
      "Epoch 71/200, Iteration 178/250, Loss: 0.0210\n",
      "Epoch 71/200, Iteration 179/250, Loss: 0.0103\n",
      "Epoch 71/200, Iteration 180/250, Loss: 0.0097\n",
      "Epoch 71/200, Iteration 181/250, Loss: 0.0204\n",
      "Epoch 71/200, Iteration 182/250, Loss: 0.0247\n",
      "Epoch 71/200, Iteration 183/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 184/250, Loss: 0.0074\n",
      "Epoch 71/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 186/250, Loss: 0.0078\n",
      "Epoch 71/200, Iteration 187/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 188/250, Loss: 0.0083\n",
      "Epoch 71/200, Iteration 189/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 190/250, Loss: 0.0209\n",
      "Epoch 71/200, Iteration 191/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 192/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 193/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 195/250, Loss: 0.0214\n",
      "Epoch 71/200, Iteration 196/250, Loss: 0.0202\n",
      "Epoch 71/200, Iteration 197/250, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 71/200, Iteration 199/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 200/250, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 201/250, Loss: 0.0161\n",
      "Epoch 71/200, Iteration 202/250, Loss: 0.0156\n",
      "Epoch 71/200, Iteration 203/250, Loss: 0.0073\n",
      "Epoch 71/200, Iteration 204/250, Loss: 0.0260\n",
      "Epoch 71/200, Iteration 205/250, Loss: 0.0163\n",
      "Epoch 71/200, Iteration 206/250, Loss: 0.0306\n",
      "Epoch 71/200, Iteration 207/250, Loss: 0.0183\n",
      "Epoch 71/200, Iteration 208/250, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 209/250, Loss: 0.0144\n",
      "Epoch 71/200, Iteration 210/250, Loss: 0.0131\n",
      "Epoch 71/200, Iteration 211/250, Loss: 0.0114\n",
      "Epoch 71/200, Iteration 212/250, Loss: 0.0153\n",
      "Epoch 71/200, Iteration 213/250, Loss: 0.0121\n",
      "Epoch 71/200, Iteration 214/250, Loss: 0.0117\n",
      "Epoch 71/200, Iteration 215/250, Loss: 0.0112\n",
      "Epoch 71/200, Iteration 216/250, Loss: 0.0112\n",
      "Epoch 71/200, Iteration 217/250, Loss: 0.0176\n",
      "Epoch 71/200, Iteration 218/250, Loss: 0.0077\n",
      "Epoch 71/200, Iteration 219/250, Loss: 0.0072\n",
      "Epoch 71/200, Iteration 220/250, Loss: 0.0207\n",
      "Epoch 71/200, Iteration 221/250, Loss: 0.0075\n",
      "Epoch 71/200, Iteration 222/250, Loss: 0.0113\n",
      "Epoch 71/200, Iteration 223/250, Loss: 0.0071\n",
      "Epoch 71/200, Iteration 224/250, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 226/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 227/250, Loss: 0.0106\n",
      "Epoch 71/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 71/200, Iteration 229/250, Loss: 0.0294\n",
      "Epoch 71/200, Iteration 230/250, Loss: 0.0270\n",
      "Epoch 71/200, Iteration 231/250, Loss: 0.0166\n",
      "Epoch 71/200, Iteration 232/250, Loss: 0.0247\n",
      "Epoch 71/200, Iteration 233/250, Loss: 0.0178\n",
      "Epoch 71/200, Iteration 234/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 235/250, Loss: 0.0131\n",
      "Epoch 71/200, Iteration 236/250, Loss: 0.0074\n",
      "Epoch 71/200, Iteration 237/250, Loss: 0.0160\n",
      "Epoch 71/200, Iteration 238/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200, Iteration 239/250, Loss: 0.0280\n",
      "Epoch 71/200, Iteration 240/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 241/250, Loss: 0.0120\n",
      "Epoch 71/200, Iteration 242/250, Loss: 0.0164\n",
      "Epoch 71/200, Iteration 243/250, Loss: 0.0351\n",
      "Epoch 71/200, Iteration 244/250, Loss: 0.0144\n",
      "Epoch 71/200, Iteration 245/250, Loss: 0.0078\n",
      "Epoch 71/200, Iteration 246/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 247/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 248/250, Loss: 0.0214\n",
      "Epoch 71/200, Iteration 249/250, Loss: 0.0146\n",
      "Epoch 71/200, Iteration 250/250, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 81.16%, Avg loss: 0.007309, MRE: 0.666079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.007313, MRE: 0.909533 \n",
      "\n",
      "Epoch 72/200, Iteration 1/250, Loss: 0.0107\n",
      "Epoch 72/200, Iteration 2/250, Loss: 0.0172\n",
      "Epoch 72/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 72/200, Iteration 4/250, Loss: 0.0207\n",
      "Epoch 72/200, Iteration 5/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 6/250, Loss: 0.0153\n",
      "Epoch 72/200, Iteration 7/250, Loss: 0.0214\n",
      "Epoch 72/200, Iteration 8/250, Loss: 0.0233\n",
      "Epoch 72/200, Iteration 9/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 10/250, Loss: 0.0151\n",
      "Epoch 72/200, Iteration 11/250, Loss: 0.0095\n",
      "Epoch 72/200, Iteration 12/250, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 13/250, Loss: 0.0248\n",
      "Epoch 72/200, Iteration 14/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 72/200, Iteration 16/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 17/250, Loss: 0.0118\n",
      "Epoch 72/200, Iteration 18/250, Loss: 0.0127\n",
      "Epoch 72/200, Iteration 19/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 20/250, Loss: 0.0085\n",
      "Epoch 72/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 22/250, Loss: 0.0135\n",
      "Epoch 72/200, Iteration 23/250, Loss: 0.0051\n",
      "Epoch 72/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 72/200, Iteration 25/250, Loss: 0.0323\n",
      "Epoch 72/200, Iteration 26/250, Loss: 0.0120\n",
      "Epoch 72/200, Iteration 27/250, Loss: 0.0131\n",
      "Epoch 72/200, Iteration 28/250, Loss: 0.0069\n",
      "Epoch 72/200, Iteration 29/250, Loss: 0.0183\n",
      "Epoch 72/200, Iteration 30/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 31/250, Loss: 0.0242\n",
      "Epoch 72/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 72/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 72/200, Iteration 34/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 35/250, Loss: 0.0070\n",
      "Epoch 72/200, Iteration 36/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 37/250, Loss: 0.0145\n",
      "Epoch 72/200, Iteration 38/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 39/250, Loss: 0.0198\n",
      "Epoch 72/200, Iteration 40/250, Loss: 0.0190\n",
      "Epoch 72/200, Iteration 41/250, Loss: 0.0142\n",
      "Epoch 72/200, Iteration 42/250, Loss: 0.0247\n",
      "Epoch 72/200, Iteration 43/250, Loss: 0.0078\n",
      "Epoch 72/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 72/200, Iteration 45/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 46/250, Loss: 0.0198\n",
      "Epoch 72/200, Iteration 47/250, Loss: 0.0216\n",
      "Epoch 72/200, Iteration 48/250, Loss: 0.0178\n",
      "Epoch 72/200, Iteration 49/250, Loss: 0.0119\n",
      "Epoch 72/200, Iteration 50/250, Loss: 0.0073\n",
      "Epoch 72/200, Iteration 51/250, Loss: 0.0123\n",
      "Epoch 72/200, Iteration 52/250, Loss: 0.0155\n",
      "Epoch 72/200, Iteration 53/250, Loss: 0.0132\n",
      "Epoch 72/200, Iteration 54/250, Loss: 0.0112\n",
      "Epoch 72/200, Iteration 55/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 56/250, Loss: 0.0384\n",
      "Epoch 72/200, Iteration 57/250, Loss: 0.0162\n",
      "Epoch 72/200, Iteration 58/250, Loss: 0.0097\n",
      "Epoch 72/200, Iteration 59/250, Loss: 0.0278\n",
      "Epoch 72/200, Iteration 60/250, Loss: 0.0206\n",
      "Epoch 72/200, Iteration 61/250, Loss: 0.0141\n",
      "Epoch 72/200, Iteration 62/250, Loss: 0.0110\n",
      "Epoch 72/200, Iteration 63/250, Loss: 0.0082\n",
      "Epoch 72/200, Iteration 64/250, Loss: 0.0127\n",
      "Epoch 72/200, Iteration 65/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 66/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 67/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 68/250, Loss: 0.0184\n",
      "Epoch 72/200, Iteration 69/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 70/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 71/250, Loss: 0.0109\n",
      "Epoch 72/200, Iteration 72/250, Loss: 0.0190\n",
      "Epoch 72/200, Iteration 73/250, Loss: 0.0077\n",
      "Epoch 72/200, Iteration 74/250, Loss: 0.0112\n",
      "Epoch 72/200, Iteration 75/250, Loss: 0.0194\n",
      "Epoch 72/200, Iteration 76/250, Loss: 0.0077\n",
      "Epoch 72/200, Iteration 77/250, Loss: 0.0145\n",
      "Epoch 72/200, Iteration 78/250, Loss: 0.0120\n",
      "Epoch 72/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 80/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 81/250, Loss: 0.0145\n",
      "Epoch 72/200, Iteration 82/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 83/250, Loss: 0.0083\n",
      "Epoch 72/200, Iteration 84/250, Loss: 0.0155\n",
      "Epoch 72/200, Iteration 85/250, Loss: 0.0133\n",
      "Epoch 72/200, Iteration 86/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 87/250, Loss: 0.0104\n",
      "Epoch 72/200, Iteration 88/250, Loss: 0.0174\n",
      "Epoch 72/200, Iteration 89/250, Loss: 0.0223\n",
      "Epoch 72/200, Iteration 90/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 91/250, Loss: 0.0129\n",
      "Epoch 72/200, Iteration 92/250, Loss: 0.0123\n",
      "Epoch 72/200, Iteration 93/250, Loss: 0.0164\n",
      "Epoch 72/200, Iteration 94/250, Loss: 0.0203\n",
      "Epoch 72/200, Iteration 95/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 96/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 97/250, Loss: 0.0171\n",
      "Epoch 72/200, Iteration 98/250, Loss: 0.0115\n",
      "Epoch 72/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 72/200, Iteration 100/250, Loss: 0.0076\n",
      "Epoch 72/200, Iteration 101/250, Loss: 0.0125\n",
      "Epoch 72/200, Iteration 102/250, Loss: 0.0117\n",
      "Epoch 72/200, Iteration 103/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 104/250, Loss: 0.0168\n",
      "Epoch 72/200, Iteration 105/250, Loss: 0.0183\n",
      "Epoch 72/200, Iteration 106/250, Loss: 0.0082\n",
      "Epoch 72/200, Iteration 107/250, Loss: 0.0142\n",
      "Epoch 72/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 109/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 110/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 111/250, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 112/250, Loss: 0.0195\n",
      "Epoch 72/200, Iteration 113/250, Loss: 0.0135\n",
      "Epoch 72/200, Iteration 114/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 115/250, Loss: 0.0096\n",
      "Epoch 72/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 72/200, Iteration 117/250, Loss: 0.0096\n",
      "Epoch 72/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 119/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 120/250, Loss: 0.0210\n",
      "Epoch 72/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 72/200, Iteration 122/250, Loss: 0.0074\n",
      "Epoch 72/200, Iteration 123/250, Loss: 0.0375\n",
      "Epoch 72/200, Iteration 124/250, Loss: 0.0070\n",
      "Epoch 72/200, Iteration 125/250, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 126/250, Loss: 0.0289\n",
      "Epoch 72/200, Iteration 127/250, Loss: 0.0188\n",
      "Epoch 72/200, Iteration 128/250, Loss: 0.0130\n",
      "Epoch 72/200, Iteration 129/250, Loss: 0.0206\n",
      "Epoch 72/200, Iteration 130/250, Loss: 0.0189\n",
      "Epoch 72/200, Iteration 131/250, Loss: 0.0115\n",
      "Epoch 72/200, Iteration 132/250, Loss: 0.0074\n",
      "Epoch 72/200, Iteration 133/250, Loss: 0.0068\n",
      "Epoch 72/200, Iteration 134/250, Loss: 0.0130\n",
      "Epoch 72/200, Iteration 135/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 136/250, Loss: 0.0135\n",
      "Epoch 72/200, Iteration 137/250, Loss: 0.0082\n",
      "Epoch 72/200, Iteration 138/250, Loss: 0.0083\n",
      "Epoch 72/200, Iteration 139/250, Loss: 0.0094\n",
      "Epoch 72/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 141/250, Loss: 0.0275\n",
      "Epoch 72/200, Iteration 142/250, Loss: 0.0121\n",
      "Epoch 72/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 72/200, Iteration 144/250, Loss: 0.0148\n",
      "Epoch 72/200, Iteration 145/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 146/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 147/250, Loss: 0.0361\n",
      "Epoch 72/200, Iteration 148/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 149/250, Loss: 0.0194\n",
      "Epoch 72/200, Iteration 150/250, Loss: 0.0176\n",
      "Epoch 72/200, Iteration 151/250, Loss: 0.0077\n",
      "Epoch 72/200, Iteration 152/250, Loss: 0.0169\n",
      "Epoch 72/200, Iteration 153/250, Loss: 0.0063\n",
      "Epoch 72/200, Iteration 154/250, Loss: 0.0082\n",
      "Epoch 72/200, Iteration 155/250, Loss: 0.0262\n",
      "Epoch 72/200, Iteration 156/250, Loss: 0.0080\n",
      "Epoch 72/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 72/200, Iteration 158/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 159/250, Loss: 0.0133\n",
      "Epoch 72/200, Iteration 160/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 161/250, Loss: 0.0077\n",
      "Epoch 72/200, Iteration 162/250, Loss: 0.0131\n",
      "Epoch 72/200, Iteration 163/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 165/250, Loss: 0.0133\n",
      "Epoch 72/200, Iteration 166/250, Loss: 0.0171\n",
      "Epoch 72/200, Iteration 167/250, Loss: 0.0075\n",
      "Epoch 72/200, Iteration 168/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 169/250, Loss: 0.0255\n",
      "Epoch 72/200, Iteration 170/250, Loss: 0.0164\n",
      "Epoch 72/200, Iteration 171/250, Loss: 0.0218\n",
      "Epoch 72/200, Iteration 172/250, Loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200, Iteration 173/250, Loss: 0.0396\n",
      "Epoch 72/200, Iteration 174/250, Loss: 0.0221\n",
      "Epoch 72/200, Iteration 175/250, Loss: 0.0172\n",
      "Epoch 72/200, Iteration 176/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 177/250, Loss: 0.0342\n",
      "Epoch 72/200, Iteration 178/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 179/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 180/250, Loss: 0.0243\n",
      "Epoch 72/200, Iteration 181/250, Loss: 0.0161\n",
      "Epoch 72/200, Iteration 182/250, Loss: 0.0247\n",
      "Epoch 72/200, Iteration 183/250, Loss: 0.0071\n",
      "Epoch 72/200, Iteration 184/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 185/250, Loss: 0.0191\n",
      "Epoch 72/200, Iteration 186/250, Loss: 0.0137\n",
      "Epoch 72/200, Iteration 187/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 188/250, Loss: 0.0127\n",
      "Epoch 72/200, Iteration 189/250, Loss: 0.0175\n",
      "Epoch 72/200, Iteration 190/250, Loss: 0.0167\n",
      "Epoch 72/200, Iteration 191/250, Loss: 0.0065\n",
      "Epoch 72/200, Iteration 192/250, Loss: 0.0127\n",
      "Epoch 72/200, Iteration 193/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 194/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 195/250, Loss: 0.0240\n",
      "Epoch 72/200, Iteration 196/250, Loss: 0.0096\n",
      "Epoch 72/200, Iteration 197/250, Loss: 0.0103\n",
      "Epoch 72/200, Iteration 198/250, Loss: 0.0219\n",
      "Epoch 72/200, Iteration 199/250, Loss: 0.0327\n",
      "Epoch 72/200, Iteration 200/250, Loss: 0.0086\n",
      "Epoch 72/200, Iteration 201/250, Loss: 0.0094\n",
      "Epoch 72/200, Iteration 202/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 203/250, Loss: 0.0193\n",
      "Epoch 72/200, Iteration 204/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 205/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 206/250, Loss: 0.0205\n",
      "Epoch 72/200, Iteration 207/250, Loss: 0.0168\n",
      "Epoch 72/200, Iteration 208/250, Loss: 0.0112\n",
      "Epoch 72/200, Iteration 209/250, Loss: 0.0130\n",
      "Epoch 72/200, Iteration 210/250, Loss: 0.0114\n",
      "Epoch 72/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 72/200, Iteration 212/250, Loss: 0.0103\n",
      "Epoch 72/200, Iteration 213/250, Loss: 0.0229\n",
      "Epoch 72/200, Iteration 214/250, Loss: 0.0229\n",
      "Epoch 72/200, Iteration 215/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 216/250, Loss: 0.0126\n",
      "Epoch 72/200, Iteration 217/250, Loss: 0.0229\n",
      "Epoch 72/200, Iteration 218/250, Loss: 0.0086\n",
      "Epoch 72/200, Iteration 219/250, Loss: 0.0207\n",
      "Epoch 72/200, Iteration 220/250, Loss: 0.0202\n",
      "Epoch 72/200, Iteration 221/250, Loss: 0.0248\n",
      "Epoch 72/200, Iteration 222/250, Loss: 0.0189\n",
      "Epoch 72/200, Iteration 223/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 224/250, Loss: 0.0190\n",
      "Epoch 72/200, Iteration 225/250, Loss: 0.0063\n",
      "Epoch 72/200, Iteration 226/250, Loss: 0.0121\n",
      "Epoch 72/200, Iteration 227/250, Loss: 0.0135\n",
      "Epoch 72/200, Iteration 228/250, Loss: 0.0373\n",
      "Epoch 72/200, Iteration 229/250, Loss: 0.0273\n",
      "Epoch 72/200, Iteration 230/250, Loss: 0.0231\n",
      "Epoch 72/200, Iteration 231/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 232/250, Loss: 0.0118\n",
      "Epoch 72/200, Iteration 233/250, Loss: 0.0095\n",
      "Epoch 72/200, Iteration 234/250, Loss: 0.0068\n",
      "Epoch 72/200, Iteration 235/250, Loss: 0.0152\n",
      "Epoch 72/200, Iteration 236/250, Loss: 0.0164\n",
      "Epoch 72/200, Iteration 237/250, Loss: 0.0212\n",
      "Epoch 72/200, Iteration 238/250, Loss: 0.0234\n",
      "Epoch 72/200, Iteration 239/250, Loss: 0.0139\n",
      "Epoch 72/200, Iteration 240/250, Loss: 0.0079\n",
      "Epoch 72/200, Iteration 241/250, Loss: 0.0086\n",
      "Epoch 72/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 243/250, Loss: 0.0247\n",
      "Epoch 72/200, Iteration 244/250, Loss: 0.0097\n",
      "Epoch 72/200, Iteration 245/250, Loss: 0.0263\n",
      "Epoch 72/200, Iteration 246/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 247/250, Loss: 0.0157\n",
      "Epoch 72/200, Iteration 248/250, Loss: 0.0141\n",
      "Epoch 72/200, Iteration 249/250, Loss: 0.0156\n",
      "Epoch 72/200, Iteration 250/250, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 96.33%, Avg loss: 0.007490, MRE: 0.749254 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.45%, Avg loss: 0.007401, MRE: 1.282224 \n",
      "\n",
      "Epoch 73/200, Iteration 1/250, Loss: 0.0191\n",
      "Epoch 73/200, Iteration 2/250, Loss: 0.0291\n",
      "Epoch 73/200, Iteration 3/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 4/250, Loss: 0.0335\n",
      "Epoch 73/200, Iteration 5/250, Loss: 0.0188\n",
      "Epoch 73/200, Iteration 6/250, Loss: 0.0110\n",
      "Epoch 73/200, Iteration 7/250, Loss: 0.0137\n",
      "Epoch 73/200, Iteration 8/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 9/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 10/250, Loss: 0.0331\n",
      "Epoch 73/200, Iteration 11/250, Loss: 0.0117\n",
      "Epoch 73/200, Iteration 12/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 13/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 14/250, Loss: 0.0141\n",
      "Epoch 73/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 73/200, Iteration 17/250, Loss: 0.0086\n",
      "Epoch 73/200, Iteration 18/250, Loss: 0.0219\n",
      "Epoch 73/200, Iteration 19/250, Loss: 0.0425\n",
      "Epoch 73/200, Iteration 20/250, Loss: 0.0194\n",
      "Epoch 73/200, Iteration 21/250, Loss: 0.0115\n",
      "Epoch 73/200, Iteration 22/250, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 73/200, Iteration 24/250, Loss: 0.0202\n",
      "Epoch 73/200, Iteration 25/250, Loss: 0.0211\n",
      "Epoch 73/200, Iteration 26/250, Loss: 0.0235\n",
      "Epoch 73/200, Iteration 27/250, Loss: 0.0065\n",
      "Epoch 73/200, Iteration 28/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 29/250, Loss: 0.0214\n",
      "Epoch 73/200, Iteration 30/250, Loss: 0.0281\n",
      "Epoch 73/200, Iteration 31/250, Loss: 0.0120\n",
      "Epoch 73/200, Iteration 32/250, Loss: 0.0141\n",
      "Epoch 73/200, Iteration 33/250, Loss: 0.0061\n",
      "Epoch 73/200, Iteration 34/250, Loss: 0.0272\n",
      "Epoch 73/200, Iteration 35/250, Loss: 0.0080\n",
      "Epoch 73/200, Iteration 36/250, Loss: 0.0263\n",
      "Epoch 73/200, Iteration 37/250, Loss: 0.0200\n",
      "Epoch 73/200, Iteration 38/250, Loss: 0.0234\n",
      "Epoch 73/200, Iteration 39/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 40/250, Loss: 0.0159\n",
      "Epoch 73/200, Iteration 41/250, Loss: 0.0058\n",
      "Epoch 73/200, Iteration 42/250, Loss: 0.0169\n",
      "Epoch 73/200, Iteration 43/250, Loss: 0.0229\n",
      "Epoch 73/200, Iteration 44/250, Loss: 0.0210\n",
      "Epoch 73/200, Iteration 45/250, Loss: 0.0108\n",
      "Epoch 73/200, Iteration 46/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 47/250, Loss: 0.0323\n",
      "Epoch 73/200, Iteration 48/250, Loss: 0.0357\n",
      "Epoch 73/200, Iteration 49/250, Loss: 0.0114\n",
      "Epoch 73/200, Iteration 50/250, Loss: 0.0280\n",
      "Epoch 73/200, Iteration 51/250, Loss: 0.0216\n",
      "Epoch 73/200, Iteration 52/250, Loss: 0.0287\n",
      "Epoch 73/200, Iteration 53/250, Loss: 0.0147\n",
      "Epoch 73/200, Iteration 54/250, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 55/250, Loss: 0.0181\n",
      "Epoch 73/200, Iteration 56/250, Loss: 0.0143\n",
      "Epoch 73/200, Iteration 57/250, Loss: 0.0295\n",
      "Epoch 73/200, Iteration 58/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 59/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 60/250, Loss: 0.0147\n",
      "Epoch 73/200, Iteration 61/250, Loss: 0.0278\n",
      "Epoch 73/200, Iteration 62/250, Loss: 0.0142\n",
      "Epoch 73/200, Iteration 63/250, Loss: 0.0112\n",
      "Epoch 73/200, Iteration 64/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 65/250, Loss: 0.0075\n",
      "Epoch 73/200, Iteration 66/250, Loss: 0.0098\n",
      "Epoch 73/200, Iteration 67/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 68/250, Loss: 0.0223\n",
      "Epoch 73/200, Iteration 69/250, Loss: 0.0161\n",
      "Epoch 73/200, Iteration 70/250, Loss: 0.0209\n",
      "Epoch 73/200, Iteration 71/250, Loss: 0.0196\n",
      "Epoch 73/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 73/250, Loss: 0.0085\n",
      "Epoch 73/200, Iteration 74/250, Loss: 0.0250\n",
      "Epoch 73/200, Iteration 75/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 76/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 77/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 78/250, Loss: 0.0177\n",
      "Epoch 73/200, Iteration 79/250, Loss: 0.0157\n",
      "Epoch 73/200, Iteration 80/250, Loss: 0.0165\n",
      "Epoch 73/200, Iteration 81/250, Loss: 0.0232\n",
      "Epoch 73/200, Iteration 82/250, Loss: 0.0199\n",
      "Epoch 73/200, Iteration 83/250, Loss: 0.0199\n",
      "Epoch 73/200, Iteration 84/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 85/250, Loss: 0.0117\n",
      "Epoch 73/200, Iteration 86/250, Loss: 0.0144\n",
      "Epoch 73/200, Iteration 87/250, Loss: 0.0123\n",
      "Epoch 73/200, Iteration 88/250, Loss: 0.0073\n",
      "Epoch 73/200, Iteration 89/250, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 90/250, Loss: 0.0144\n",
      "Epoch 73/200, Iteration 91/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 92/250, Loss: 0.0156\n",
      "Epoch 73/200, Iteration 93/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 94/250, Loss: 0.0098\n",
      "Epoch 73/200, Iteration 95/250, Loss: 0.0243\n",
      "Epoch 73/200, Iteration 96/250, Loss: 0.0158\n",
      "Epoch 73/200, Iteration 97/250, Loss: 0.0076\n",
      "Epoch 73/200, Iteration 98/250, Loss: 0.0083\n",
      "Epoch 73/200, Iteration 99/250, Loss: 0.0079\n",
      "Epoch 73/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 73/200, Iteration 101/250, Loss: 0.0187\n",
      "Epoch 73/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 103/250, Loss: 0.0342\n",
      "Epoch 73/200, Iteration 104/250, Loss: 0.0196\n",
      "Epoch 73/200, Iteration 105/250, Loss: 0.0314\n",
      "Epoch 73/200, Iteration 106/250, Loss: 0.0311\n",
      "Epoch 73/200, Iteration 107/250, Loss: 0.0136\n",
      "Epoch 73/200, Iteration 108/250, Loss: 0.0294\n",
      "Epoch 73/200, Iteration 109/250, Loss: 0.0123\n",
      "Epoch 73/200, Iteration 110/250, Loss: 0.0174\n",
      "Epoch 73/200, Iteration 111/250, Loss: 0.0110\n",
      "Epoch 73/200, Iteration 112/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 113/250, Loss: 0.0074\n",
      "Epoch 73/200, Iteration 114/250, Loss: 0.0078\n",
      "Epoch 73/200, Iteration 115/250, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 116/250, Loss: 0.0150\n",
      "Epoch 73/200, Iteration 117/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 118/250, Loss: 0.0248\n",
      "Epoch 73/200, Iteration 119/250, Loss: 0.0073\n",
      "Epoch 73/200, Iteration 120/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 73/200, Iteration 122/250, Loss: 0.0310\n",
      "Epoch 73/200, Iteration 123/250, Loss: 0.0148\n",
      "Epoch 73/200, Iteration 124/250, Loss: 0.0084\n",
      "Epoch 73/200, Iteration 125/250, Loss: 0.0115\n",
      "Epoch 73/200, Iteration 126/250, Loss: 0.0163\n",
      "Epoch 73/200, Iteration 127/250, Loss: 0.0135\n",
      "Epoch 73/200, Iteration 128/250, Loss: 0.0148\n",
      "Epoch 73/200, Iteration 129/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 130/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 131/250, Loss: 0.0090\n",
      "Epoch 73/200, Iteration 132/250, Loss: 0.0251\n",
      "Epoch 73/200, Iteration 133/250, Loss: 0.0189\n",
      "Epoch 73/200, Iteration 134/250, Loss: 0.0215\n",
      "Epoch 73/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 136/250, Loss: 0.0131\n",
      "Epoch 73/200, Iteration 137/250, Loss: 0.0197\n",
      "Epoch 73/200, Iteration 138/250, Loss: 0.0394\n",
      "Epoch 73/200, Iteration 139/250, Loss: 0.0265\n",
      "Epoch 73/200, Iteration 140/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 141/250, Loss: 0.0204\n",
      "Epoch 73/200, Iteration 142/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 143/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 144/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Iteration 145/250, Loss: 0.0135\n",
      "Epoch 73/200, Iteration 146/250, Loss: 0.0260\n",
      "Epoch 73/200, Iteration 147/250, Loss: 0.0139\n",
      "Epoch 73/200, Iteration 148/250, Loss: 0.0121\n",
      "Epoch 73/200, Iteration 149/250, Loss: 0.0130\n",
      "Epoch 73/200, Iteration 150/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 151/250, Loss: 0.0216\n",
      "Epoch 73/200, Iteration 152/250, Loss: 0.0106\n",
      "Epoch 73/200, Iteration 153/250, Loss: 0.0111\n",
      "Epoch 73/200, Iteration 154/250, Loss: 0.0234\n",
      "Epoch 73/200, Iteration 155/250, Loss: 0.0174\n",
      "Epoch 73/200, Iteration 156/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 157/250, Loss: 0.0128\n",
      "Epoch 73/200, Iteration 158/250, Loss: 0.0416\n",
      "Epoch 73/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 160/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 161/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 162/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 163/250, Loss: 0.0278\n",
      "Epoch 73/200, Iteration 164/250, Loss: 0.0174\n",
      "Epoch 73/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 73/200, Iteration 166/250, Loss: 0.0136\n",
      "Epoch 73/200, Iteration 167/250, Loss: 0.0121\n",
      "Epoch 73/200, Iteration 168/250, Loss: 0.0091\n",
      "Epoch 73/200, Iteration 169/250, Loss: 0.0299\n",
      "Epoch 73/200, Iteration 170/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 171/250, Loss: 0.0098\n",
      "Epoch 73/200, Iteration 172/250, Loss: 0.0181\n",
      "Epoch 73/200, Iteration 173/250, Loss: 0.0080\n",
      "Epoch 73/200, Iteration 174/250, Loss: 0.0074\n",
      "Epoch 73/200, Iteration 175/250, Loss: 0.0097\n",
      "Epoch 73/200, Iteration 176/250, Loss: 0.0187\n",
      "Epoch 73/200, Iteration 177/250, Loss: 0.0174\n",
      "Epoch 73/200, Iteration 178/250, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 179/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 180/250, Loss: 0.0144\n",
      "Epoch 73/200, Iteration 181/250, Loss: 0.0070\n",
      "Epoch 73/200, Iteration 182/250, Loss: 0.0126\n",
      "Epoch 73/200, Iteration 183/250, Loss: 0.0177\n",
      "Epoch 73/200, Iteration 184/250, Loss: 0.0087\n",
      "Epoch 73/200, Iteration 185/250, Loss: 0.0125\n",
      "Epoch 73/200, Iteration 186/250, Loss: 0.0085\n",
      "Epoch 73/200, Iteration 187/250, Loss: 0.0147\n",
      "Epoch 73/200, Iteration 188/250, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 189/250, Loss: 0.0123\n",
      "Epoch 73/200, Iteration 190/250, Loss: 0.0128\n",
      "Epoch 73/200, Iteration 191/250, Loss: 0.0076\n",
      "Epoch 73/200, Iteration 192/250, Loss: 0.0076\n",
      "Epoch 73/200, Iteration 193/250, Loss: 0.0083\n",
      "Epoch 73/200, Iteration 194/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 195/250, Loss: 0.0155\n",
      "Epoch 73/200, Iteration 196/250, Loss: 0.0084\n",
      "Epoch 73/200, Iteration 197/250, Loss: 0.0245\n",
      "Epoch 73/200, Iteration 198/250, Loss: 0.0151\n",
      "Epoch 73/200, Iteration 199/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 200/250, Loss: 0.0083\n",
      "Epoch 73/200, Iteration 201/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 202/250, Loss: 0.0369\n",
      "Epoch 73/200, Iteration 203/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 204/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 205/250, Loss: 0.0138\n",
      "Epoch 73/200, Iteration 206/250, Loss: 0.0331\n",
      "Epoch 73/200, Iteration 207/250, Loss: 0.0208\n",
      "Epoch 73/200, Iteration 208/250, Loss: 0.0144\n",
      "Epoch 73/200, Iteration 209/250, Loss: 0.0203\n",
      "Epoch 73/200, Iteration 210/250, Loss: 0.0171\n",
      "Epoch 73/200, Iteration 211/250, Loss: 0.0131\n",
      "Epoch 73/200, Iteration 212/250, Loss: 0.0192\n",
      "Epoch 73/200, Iteration 213/250, Loss: 0.0136\n",
      "Epoch 73/200, Iteration 214/250, Loss: 0.0200\n",
      "Epoch 73/200, Iteration 215/250, Loss: 0.0216\n",
      "Epoch 73/200, Iteration 216/250, Loss: 0.0153\n",
      "Epoch 73/200, Iteration 217/250, Loss: 0.0072\n",
      "Epoch 73/200, Iteration 218/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 219/250, Loss: 0.0256\n",
      "Epoch 73/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 221/250, Loss: 0.0080\n",
      "Epoch 73/200, Iteration 222/250, Loss: 0.0120\n",
      "Epoch 73/200, Iteration 223/250, Loss: 0.0176\n",
      "Epoch 73/200, Iteration 224/250, Loss: 0.0210\n",
      "Epoch 73/200, Iteration 225/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 226/250, Loss: 0.0364\n",
      "Epoch 73/200, Iteration 227/250, Loss: 0.0188\n",
      "Epoch 73/200, Iteration 228/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 229/250, Loss: 0.0137\n",
      "Epoch 73/200, Iteration 230/250, Loss: 0.0155\n",
      "Epoch 73/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 73/200, Iteration 232/250, Loss: 0.0244\n",
      "Epoch 73/200, Iteration 233/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 234/250, Loss: 0.0138\n",
      "Epoch 73/200, Iteration 235/250, Loss: 0.0090\n",
      "Epoch 73/200, Iteration 236/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 73/200, Iteration 238/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 239/250, Loss: 0.0090\n",
      "Epoch 73/200, Iteration 240/250, Loss: 0.0258\n",
      "Epoch 73/200, Iteration 241/250, Loss: 0.0134\n",
      "Epoch 73/200, Iteration 242/250, Loss: 0.0059\n",
      "Epoch 73/200, Iteration 243/250, Loss: 0.0294\n",
      "Epoch 73/200, Iteration 244/250, Loss: 0.0098\n",
      "Epoch 73/200, Iteration 245/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 246/250, Loss: 0.0085\n",
      "Epoch 73/200, Iteration 247/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 249/250, Loss: 0.0136\n",
      "Epoch 73/200, Iteration 250/250, Loss: 0.0117\n",
      "Train Error: \n",
      " Accuracy: 96.15%, Avg loss: 0.006944, MRE: 0.687329 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.006861, MRE: 1.208774 \n",
      "\n",
      "Epoch 74/200, Iteration 1/250, Loss: 0.0121\n",
      "Epoch 74/200, Iteration 2/250, Loss: 0.0178\n",
      "Epoch 74/200, Iteration 3/250, Loss: 0.0130\n",
      "Epoch 74/200, Iteration 4/250, Loss: 0.0167\n",
      "Epoch 74/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 6/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 7/250, Loss: 0.0177\n",
      "Epoch 74/200, Iteration 8/250, Loss: 0.0144\n",
      "Epoch 74/200, Iteration 9/250, Loss: 0.0161\n",
      "Epoch 74/200, Iteration 10/250, Loss: 0.0171\n",
      "Epoch 74/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 74/200, Iteration 12/250, Loss: 0.0189\n",
      "Epoch 74/200, Iteration 13/250, Loss: 0.0191\n",
      "Epoch 74/200, Iteration 14/250, Loss: 0.0163\n",
      "Epoch 74/200, Iteration 15/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 16/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 17/250, Loss: 0.0095\n",
      "Epoch 74/200, Iteration 18/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 19/250, Loss: 0.0165\n",
      "Epoch 74/200, Iteration 20/250, Loss: 0.0128\n",
      "Epoch 74/200, Iteration 21/250, Loss: 0.0177\n",
      "Epoch 74/200, Iteration 22/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 23/250, Loss: 0.0190\n",
      "Epoch 74/200, Iteration 24/250, Loss: 0.0169\n",
      "Epoch 74/200, Iteration 25/250, Loss: 0.0156\n",
      "Epoch 74/200, Iteration 26/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 27/250, Loss: 0.0195\n",
      "Epoch 74/200, Iteration 28/250, Loss: 0.0064\n",
      "Epoch 74/200, Iteration 29/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 30/250, Loss: 0.0176\n",
      "Epoch 74/200, Iteration 31/250, Loss: 0.0139\n",
      "Epoch 74/200, Iteration 32/250, Loss: 0.0080\n",
      "Epoch 74/200, Iteration 33/250, Loss: 0.0283\n",
      "Epoch 74/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 74/200, Iteration 35/250, Loss: 0.0081\n",
      "Epoch 74/200, Iteration 36/250, Loss: 0.0197\n",
      "Epoch 74/200, Iteration 37/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 38/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 39/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 40/250, Loss: 0.0205\n",
      "Epoch 74/200, Iteration 41/250, Loss: 0.0281\n",
      "Epoch 74/200, Iteration 42/250, Loss: 0.0182\n",
      "Epoch 74/200, Iteration 43/250, Loss: 0.0187\n",
      "Epoch 74/200, Iteration 44/250, Loss: 0.0277\n",
      "Epoch 74/200, Iteration 45/250, Loss: 0.0284\n",
      "Epoch 74/200, Iteration 46/250, Loss: 0.0133\n",
      "Epoch 74/200, Iteration 47/250, Loss: 0.0193\n",
      "Epoch 74/200, Iteration 48/250, Loss: 0.0065\n",
      "Epoch 74/200, Iteration 49/250, Loss: 0.0260\n",
      "Epoch 74/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 74/200, Iteration 52/250, Loss: 0.0119\n",
      "Epoch 74/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 74/200, Iteration 54/250, Loss: 0.0107\n",
      "Epoch 74/200, Iteration 55/250, Loss: 0.0120\n",
      "Epoch 74/200, Iteration 56/250, Loss: 0.0269\n",
      "Epoch 74/200, Iteration 57/250, Loss: 0.0099\n",
      "Epoch 74/200, Iteration 58/250, Loss: 0.0296\n",
      "Epoch 74/200, Iteration 59/250, Loss: 0.0078\n",
      "Epoch 74/200, Iteration 60/250, Loss: 0.0202\n",
      "Epoch 74/200, Iteration 61/250, Loss: 0.0221\n",
      "Epoch 74/200, Iteration 62/250, Loss: 0.0275\n",
      "Epoch 74/200, Iteration 63/250, Loss: 0.0140\n",
      "Epoch 74/200, Iteration 64/250, Loss: 0.0165\n",
      "Epoch 74/200, Iteration 65/250, Loss: 0.0146\n",
      "Epoch 74/200, Iteration 66/250, Loss: 0.0203\n",
      "Epoch 74/200, Iteration 67/250, Loss: 0.0240\n",
      "Epoch 74/200, Iteration 68/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 69/250, Loss: 0.0142\n",
      "Epoch 74/200, Iteration 70/250, Loss: 0.0136\n",
      "Epoch 74/200, Iteration 71/250, Loss: 0.0088\n",
      "Epoch 74/200, Iteration 72/250, Loss: 0.0254\n",
      "Epoch 74/200, Iteration 73/250, Loss: 0.0100\n",
      "Epoch 74/200, Iteration 74/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 75/250, Loss: 0.0205\n",
      "Epoch 74/200, Iteration 76/250, Loss: 0.0090\n",
      "Epoch 74/200, Iteration 77/250, Loss: 0.0155\n",
      "Epoch 74/200, Iteration 78/250, Loss: 0.0201\n",
      "Epoch 74/200, Iteration 79/250, Loss: 0.0065\n",
      "Epoch 74/200, Iteration 80/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 81/250, Loss: 0.0146\n",
      "Epoch 74/200, Iteration 82/250, Loss: 0.0134\n",
      "Epoch 74/200, Iteration 83/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 84/250, Loss: 0.0414\n",
      "Epoch 74/200, Iteration 85/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 86/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 87/250, Loss: 0.0273\n",
      "Epoch 74/200, Iteration 88/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 89/250, Loss: 0.0140\n",
      "Epoch 74/200, Iteration 90/250, Loss: 0.0076\n",
      "Epoch 74/200, Iteration 91/250, Loss: 0.0213\n",
      "Epoch 74/200, Iteration 92/250, Loss: 0.0094\n",
      "Epoch 74/200, Iteration 93/250, Loss: 0.0140\n",
      "Epoch 74/200, Iteration 94/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 95/250, Loss: 0.0234\n",
      "Epoch 74/200, Iteration 96/250, Loss: 0.0125\n",
      "Epoch 74/200, Iteration 97/250, Loss: 0.0176\n",
      "Epoch 74/200, Iteration 98/250, Loss: 0.0268\n",
      "Epoch 74/200, Iteration 99/250, Loss: 0.0095\n",
      "Epoch 74/200, Iteration 100/250, Loss: 0.0083\n",
      "Epoch 74/200, Iteration 101/250, Loss: 0.0081\n",
      "Epoch 74/200, Iteration 102/250, Loss: 0.0256\n",
      "Epoch 74/200, Iteration 103/250, Loss: 0.0084\n",
      "Epoch 74/200, Iteration 104/250, Loss: 0.0139\n",
      "Epoch 74/200, Iteration 105/250, Loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200, Iteration 106/250, Loss: 0.0094\n",
      "Epoch 74/200, Iteration 107/250, Loss: 0.0200\n",
      "Epoch 74/200, Iteration 108/250, Loss: 0.0295\n",
      "Epoch 74/200, Iteration 109/250, Loss: 0.0214\n",
      "Epoch 74/200, Iteration 110/250, Loss: 0.0119\n",
      "Epoch 74/200, Iteration 111/250, Loss: 0.0129\n",
      "Epoch 74/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 74/200, Iteration 113/250, Loss: 0.0092\n",
      "Epoch 74/200, Iteration 114/250, Loss: 0.0093\n",
      "Epoch 74/200, Iteration 115/250, Loss: 0.0127\n",
      "Epoch 74/200, Iteration 116/250, Loss: 0.0094\n",
      "Epoch 74/200, Iteration 117/250, Loss: 0.0177\n",
      "Epoch 74/200, Iteration 118/250, Loss: 0.0135\n",
      "Epoch 74/200, Iteration 119/250, Loss: 0.0404\n",
      "Epoch 74/200, Iteration 120/250, Loss: 0.0222\n",
      "Epoch 74/200, Iteration 121/250, Loss: 0.0104\n",
      "Epoch 74/200, Iteration 122/250, Loss: 0.0158\n",
      "Epoch 74/200, Iteration 123/250, Loss: 0.0121\n",
      "Epoch 74/200, Iteration 124/250, Loss: 0.0230\n",
      "Epoch 74/200, Iteration 125/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 126/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 127/250, Loss: 0.0076\n",
      "Epoch 74/200, Iteration 128/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 129/250, Loss: 0.0096\n",
      "Epoch 74/200, Iteration 130/250, Loss: 0.0118\n",
      "Epoch 74/200, Iteration 131/250, Loss: 0.0155\n",
      "Epoch 74/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 74/200, Iteration 133/250, Loss: 0.0044\n",
      "Epoch 74/200, Iteration 134/250, Loss: 0.0083\n",
      "Epoch 74/200, Iteration 135/250, Loss: 0.0163\n",
      "Epoch 74/200, Iteration 136/250, Loss: 0.0196\n",
      "Epoch 74/200, Iteration 137/250, Loss: 0.0075\n",
      "Epoch 74/200, Iteration 138/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 139/250, Loss: 0.0176\n",
      "Epoch 74/200, Iteration 140/250, Loss: 0.0218\n",
      "Epoch 74/200, Iteration 141/250, Loss: 0.0248\n",
      "Epoch 74/200, Iteration 142/250, Loss: 0.0166\n",
      "Epoch 74/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 144/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 145/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 146/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 147/250, Loss: 0.0081\n",
      "Epoch 74/200, Iteration 148/250, Loss: 0.0165\n",
      "Epoch 74/200, Iteration 149/250, Loss: 0.0115\n",
      "Epoch 74/200, Iteration 150/250, Loss: 0.0090\n",
      "Epoch 74/200, Iteration 151/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 152/250, Loss: 0.0100\n",
      "Epoch 74/200, Iteration 153/250, Loss: 0.0128\n",
      "Epoch 74/200, Iteration 154/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 155/250, Loss: 0.0166\n",
      "Epoch 74/200, Iteration 156/250, Loss: 0.0174\n",
      "Epoch 74/200, Iteration 157/250, Loss: 0.0157\n",
      "Epoch 74/200, Iteration 158/250, Loss: 0.0121\n",
      "Epoch 74/200, Iteration 159/250, Loss: 0.0114\n",
      "Epoch 74/200, Iteration 160/250, Loss: 0.0127\n",
      "Epoch 74/200, Iteration 161/250, Loss: 0.0188\n",
      "Epoch 74/200, Iteration 162/250, Loss: 0.0129\n",
      "Epoch 74/200, Iteration 163/250, Loss: 0.0143\n",
      "Epoch 74/200, Iteration 164/250, Loss: 0.0075\n",
      "Epoch 74/200, Iteration 165/250, Loss: 0.0091\n",
      "Epoch 74/200, Iteration 166/250, Loss: 0.0171\n",
      "Epoch 74/200, Iteration 167/250, Loss: 0.0258\n",
      "Epoch 74/200, Iteration 168/250, Loss: 0.0085\n",
      "Epoch 74/200, Iteration 169/250, Loss: 0.0074\n",
      "Epoch 74/200, Iteration 170/250, Loss: 0.0064\n",
      "Epoch 74/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 74/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 74/200, Iteration 173/250, Loss: 0.0114\n",
      "Epoch 74/200, Iteration 174/250, Loss: 0.0079\n",
      "Epoch 74/200, Iteration 175/250, Loss: 0.0131\n",
      "Epoch 74/200, Iteration 176/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 177/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 178/250, Loss: 0.0682\n",
      "Epoch 74/200, Iteration 179/250, Loss: 0.0268\n",
      "Epoch 74/200, Iteration 180/250, Loss: 0.0125\n",
      "Epoch 74/200, Iteration 181/250, Loss: 0.0181\n",
      "Epoch 74/200, Iteration 182/250, Loss: 0.0113\n",
      "Epoch 74/200, Iteration 183/250, Loss: 0.0181\n",
      "Epoch 74/200, Iteration 184/250, Loss: 0.0077\n",
      "Epoch 74/200, Iteration 185/250, Loss: 0.0063\n",
      "Epoch 74/200, Iteration 186/250, Loss: 0.0147\n",
      "Epoch 74/200, Iteration 187/250, Loss: 0.0079\n",
      "Epoch 74/200, Iteration 188/250, Loss: 0.0080\n",
      "Epoch 74/200, Iteration 189/250, Loss: 0.0360\n",
      "Epoch 74/200, Iteration 190/250, Loss: 0.0193\n",
      "Epoch 74/200, Iteration 191/250, Loss: 0.0131\n",
      "Epoch 74/200, Iteration 192/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 193/250, Loss: 0.0086\n",
      "Epoch 74/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 74/200, Iteration 195/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 74/200, Iteration 197/250, Loss: 0.0093\n",
      "Epoch 74/200, Iteration 198/250, Loss: 0.0236\n",
      "Epoch 74/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 74/200, Iteration 200/250, Loss: 0.0128\n",
      "Epoch 74/200, Iteration 201/250, Loss: 0.0164\n",
      "Epoch 74/200, Iteration 202/250, Loss: 0.0299\n",
      "Epoch 74/200, Iteration 203/250, Loss: 0.0142\n",
      "Epoch 74/200, Iteration 204/250, Loss: 0.0189\n",
      "Epoch 74/200, Iteration 205/250, Loss: 0.0160\n",
      "Epoch 74/200, Iteration 206/250, Loss: 0.0283\n",
      "Epoch 74/200, Iteration 207/250, Loss: 0.0088\n",
      "Epoch 74/200, Iteration 208/250, Loss: 0.0258\n",
      "Epoch 74/200, Iteration 209/250, Loss: 0.0273\n",
      "Epoch 74/200, Iteration 210/250, Loss: 0.0134\n",
      "Epoch 74/200, Iteration 211/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 212/250, Loss: 0.0104\n",
      "Epoch 74/200, Iteration 213/250, Loss: 0.0185\n",
      "Epoch 74/200, Iteration 214/250, Loss: 0.0076\n",
      "Epoch 74/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 74/200, Iteration 216/250, Loss: 0.0244\n",
      "Epoch 74/200, Iteration 217/250, Loss: 0.0143\n",
      "Epoch 74/200, Iteration 218/250, Loss: 0.0292\n",
      "Epoch 74/200, Iteration 219/250, Loss: 0.0216\n",
      "Epoch 74/200, Iteration 220/250, Loss: 0.0149\n",
      "Epoch 74/200, Iteration 221/250, Loss: 0.0346\n",
      "Epoch 74/200, Iteration 222/250, Loss: 0.0441\n",
      "Epoch 74/200, Iteration 223/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 224/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 225/250, Loss: 0.0105\n",
      "Epoch 74/200, Iteration 226/250, Loss: 0.0179\n",
      "Epoch 74/200, Iteration 227/250, Loss: 0.0107\n",
      "Epoch 74/200, Iteration 228/250, Loss: 0.0105\n",
      "Epoch 74/200, Iteration 229/250, Loss: 0.0058\n",
      "Epoch 74/200, Iteration 230/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 231/250, Loss: 0.0131\n",
      "Epoch 74/200, Iteration 232/250, Loss: 0.0158\n",
      "Epoch 74/200, Iteration 233/250, Loss: 0.0133\n",
      "Epoch 74/200, Iteration 234/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 235/250, Loss: 0.0171\n",
      "Epoch 74/200, Iteration 236/250, Loss: 0.0266\n",
      "Epoch 74/200, Iteration 237/250, Loss: 0.0190\n",
      "Epoch 74/200, Iteration 238/250, Loss: 0.0175\n",
      "Epoch 74/200, Iteration 239/250, Loss: 0.0131\n",
      "Epoch 74/200, Iteration 240/250, Loss: 0.0225\n",
      "Epoch 74/200, Iteration 241/250, Loss: 0.0235\n",
      "Epoch 74/200, Iteration 242/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 243/250, Loss: 0.0153\n",
      "Epoch 74/200, Iteration 244/250, Loss: 0.0194\n",
      "Epoch 74/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 74/200, Iteration 246/250, Loss: 0.0126\n",
      "Epoch 74/200, Iteration 247/250, Loss: 0.0164\n",
      "Epoch 74/200, Iteration 248/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 249/250, Loss: 0.0100\n",
      "Epoch 74/200, Iteration 250/250, Loss: 0.0114\n",
      "Train Error: \n",
      " Accuracy: 94.67%, Avg loss: 0.006761, MRE: 0.667404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.05%, Avg loss: 0.006685, MRE: 1.192591 \n",
      "\n",
      "Epoch 75/200, Iteration 1/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 75/200, Iteration 3/250, Loss: 0.0132\n",
      "Epoch 75/200, Iteration 4/250, Loss: 0.0082\n",
      "Epoch 75/200, Iteration 5/250, Loss: 0.0156\n",
      "Epoch 75/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 7/250, Loss: 0.0123\n",
      "Epoch 75/200, Iteration 8/250, Loss: 0.0162\n",
      "Epoch 75/200, Iteration 9/250, Loss: 0.0088\n",
      "Epoch 75/200, Iteration 10/250, Loss: 0.0073\n",
      "Epoch 75/200, Iteration 11/250, Loss: 0.0080\n",
      "Epoch 75/200, Iteration 12/250, Loss: 0.0102\n",
      "Epoch 75/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 75/200, Iteration 14/250, Loss: 0.0081\n",
      "Epoch 75/200, Iteration 15/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 16/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 17/250, Loss: 0.0301\n",
      "Epoch 75/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 19/250, Loss: 0.0256\n",
      "Epoch 75/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 75/200, Iteration 21/250, Loss: 0.0153\n",
      "Epoch 75/200, Iteration 22/250, Loss: 0.0069\n",
      "Epoch 75/200, Iteration 23/250, Loss: 0.0112\n",
      "Epoch 75/200, Iteration 24/250, Loss: 0.0114\n",
      "Epoch 75/200, Iteration 25/250, Loss: 0.0244\n",
      "Epoch 75/200, Iteration 26/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 27/250, Loss: 0.0151\n",
      "Epoch 75/200, Iteration 28/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 29/250, Loss: 0.0142\n",
      "Epoch 75/200, Iteration 30/250, Loss: 0.0126\n",
      "Epoch 75/200, Iteration 31/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 32/250, Loss: 0.0215\n",
      "Epoch 75/200, Iteration 33/250, Loss: 0.0073\n",
      "Epoch 75/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 75/200, Iteration 35/250, Loss: 0.0118\n",
      "Epoch 75/200, Iteration 36/250, Loss: 0.0094\n",
      "Epoch 75/200, Iteration 37/250, Loss: 0.0068\n",
      "Epoch 75/200, Iteration 38/250, Loss: 0.0144\n",
      "Epoch 75/200, Iteration 39/250, Loss: 0.0140\n",
      "Epoch 75/200, Iteration 40/250, Loss: 0.0110\n",
      "Epoch 75/200, Iteration 41/250, Loss: 0.0102\n",
      "Epoch 75/200, Iteration 42/250, Loss: 0.0215\n",
      "Epoch 75/200, Iteration 43/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 44/250, Loss: 0.0075\n",
      "Epoch 75/200, Iteration 45/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 46/250, Loss: 0.0289\n",
      "Epoch 75/200, Iteration 47/250, Loss: 0.0185\n",
      "Epoch 75/200, Iteration 48/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 49/250, Loss: 0.0287\n",
      "Epoch 75/200, Iteration 50/250, Loss: 0.0251\n",
      "Epoch 75/200, Iteration 51/250, Loss: 0.0237\n",
      "Epoch 75/200, Iteration 52/250, Loss: 0.0087\n",
      "Epoch 75/200, Iteration 53/250, Loss: 0.0126\n",
      "Epoch 75/200, Iteration 54/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 55/250, Loss: 0.0081\n",
      "Epoch 75/200, Iteration 56/250, Loss: 0.0258\n",
      "Epoch 75/200, Iteration 57/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 58/250, Loss: 0.0185\n",
      "Epoch 75/200, Iteration 59/250, Loss: 0.0102\n",
      "Epoch 75/200, Iteration 60/250, Loss: 0.0149\n",
      "Epoch 75/200, Iteration 61/250, Loss: 0.0104\n",
      "Epoch 75/200, Iteration 62/250, Loss: 0.0264\n",
      "Epoch 75/200, Iteration 63/250, Loss: 0.0114\n",
      "Epoch 75/200, Iteration 64/250, Loss: 0.0138\n",
      "Epoch 75/200, Iteration 65/250, Loss: 0.0125\n",
      "Epoch 75/200, Iteration 66/250, Loss: 0.0186\n",
      "Epoch 75/200, Iteration 67/250, Loss: 0.0080\n",
      "Epoch 75/200, Iteration 68/250, Loss: 0.0122\n",
      "Epoch 75/200, Iteration 69/250, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Iteration 70/250, Loss: 0.0113\n",
      "Epoch 75/200, Iteration 71/250, Loss: 0.0228\n",
      "Epoch 75/200, Iteration 72/250, Loss: 0.0203\n",
      "Epoch 75/200, Iteration 73/250, Loss: 0.0127\n",
      "Epoch 75/200, Iteration 74/250, Loss: 0.0125\n",
      "Epoch 75/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 76/250, Loss: 0.0234\n",
      "Epoch 75/200, Iteration 77/250, Loss: 0.0141\n",
      "Epoch 75/200, Iteration 78/250, Loss: 0.0152\n",
      "Epoch 75/200, Iteration 79/250, Loss: 0.0309\n",
      "Epoch 75/200, Iteration 80/250, Loss: 0.0089\n",
      "Epoch 75/200, Iteration 81/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 82/250, Loss: 0.0176\n",
      "Epoch 75/200, Iteration 83/250, Loss: 0.0174\n",
      "Epoch 75/200, Iteration 84/250, Loss: 0.0316\n",
      "Epoch 75/200, Iteration 85/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 86/250, Loss: 0.0094\n",
      "Epoch 75/200, Iteration 87/250, Loss: 0.0111\n",
      "Epoch 75/200, Iteration 88/250, Loss: 0.0073\n",
      "Epoch 75/200, Iteration 89/250, Loss: 0.0121\n",
      "Epoch 75/200, Iteration 90/250, Loss: 0.0176\n",
      "Epoch 75/200, Iteration 91/250, Loss: 0.0122\n",
      "Epoch 75/200, Iteration 92/250, Loss: 0.0120\n",
      "Epoch 75/200, Iteration 93/250, Loss: 0.0190\n",
      "Epoch 75/200, Iteration 94/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 95/250, Loss: 0.0123\n",
      "Epoch 75/200, Iteration 96/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 97/250, Loss: 0.0115\n",
      "Epoch 75/200, Iteration 98/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 99/250, Loss: 0.0182\n",
      "Epoch 75/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 75/200, Iteration 101/250, Loss: 0.0106\n",
      "Epoch 75/200, Iteration 102/250, Loss: 0.0076\n",
      "Epoch 75/200, Iteration 103/250, Loss: 0.0219\n",
      "Epoch 75/200, Iteration 104/250, Loss: 0.0070\n",
      "Epoch 75/200, Iteration 105/250, Loss: 0.0210\n",
      "Epoch 75/200, Iteration 106/250, Loss: 0.0258\n",
      "Epoch 75/200, Iteration 107/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 108/250, Loss: 0.0351\n",
      "Epoch 75/200, Iteration 109/250, Loss: 0.0073\n",
      "Epoch 75/200, Iteration 110/250, Loss: 0.0115\n",
      "Epoch 75/200, Iteration 111/250, Loss: 0.0104\n",
      "Epoch 75/200, Iteration 112/250, Loss: 0.0280\n",
      "Epoch 75/200, Iteration 113/250, Loss: 0.0108\n",
      "Epoch 75/200, Iteration 114/250, Loss: 0.0092\n",
      "Epoch 75/200, Iteration 115/250, Loss: 0.0087\n",
      "Epoch 75/200, Iteration 116/250, Loss: 0.0101\n",
      "Epoch 75/200, Iteration 117/250, Loss: 0.0057\n",
      "Epoch 75/200, Iteration 118/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 119/250, Loss: 0.0120\n",
      "Epoch 75/200, Iteration 120/250, Loss: 0.0157\n",
      "Epoch 75/200, Iteration 121/250, Loss: 0.0209\n",
      "Epoch 75/200, Iteration 122/250, Loss: 0.0132\n",
      "Epoch 75/200, Iteration 123/250, Loss: 0.0245\n",
      "Epoch 75/200, Iteration 124/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 125/250, Loss: 0.0086\n",
      "Epoch 75/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 75/200, Iteration 127/250, Loss: 0.0415\n",
      "Epoch 75/200, Iteration 128/250, Loss: 0.0074\n",
      "Epoch 75/200, Iteration 129/250, Loss: 0.0115\n",
      "Epoch 75/200, Iteration 130/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 131/250, Loss: 0.0283\n",
      "Epoch 75/200, Iteration 132/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 133/250, Loss: 0.0079\n",
      "Epoch 75/200, Iteration 134/250, Loss: 0.0149\n",
      "Epoch 75/200, Iteration 135/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 136/250, Loss: 0.0252\n",
      "Epoch 75/200, Iteration 137/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 138/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 139/250, Loss: 0.0093\n",
      "Epoch 75/200, Iteration 140/250, Loss: 0.0117\n",
      "Epoch 75/200, Iteration 141/250, Loss: 0.0211\n",
      "Epoch 75/200, Iteration 142/250, Loss: 0.0218\n",
      "Epoch 75/200, Iteration 143/250, Loss: 0.0172\n",
      "Epoch 75/200, Iteration 144/250, Loss: 0.0067\n",
      "Epoch 75/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 75/200, Iteration 146/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 148/250, Loss: 0.0314\n",
      "Epoch 75/200, Iteration 149/250, Loss: 0.0064\n",
      "Epoch 75/200, Iteration 150/250, Loss: 0.0267\n",
      "Epoch 75/200, Iteration 151/250, Loss: 0.0145\n",
      "Epoch 75/200, Iteration 152/250, Loss: 0.0158\n",
      "Epoch 75/200, Iteration 153/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 154/250, Loss: 0.0072\n",
      "Epoch 75/200, Iteration 155/250, Loss: 0.0132\n",
      "Epoch 75/200, Iteration 156/250, Loss: 0.0080\n",
      "Epoch 75/200, Iteration 157/250, Loss: 0.0135\n",
      "Epoch 75/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 75/200, Iteration 159/250, Loss: 0.0143\n",
      "Epoch 75/200, Iteration 160/250, Loss: 0.0067\n",
      "Epoch 75/200, Iteration 161/250, Loss: 0.0201\n",
      "Epoch 75/200, Iteration 162/250, Loss: 0.0108\n",
      "Epoch 75/200, Iteration 163/250, Loss: 0.0127\n",
      "Epoch 75/200, Iteration 164/250, Loss: 0.0218\n",
      "Epoch 75/200, Iteration 165/250, Loss: 0.0126\n",
      "Epoch 75/200, Iteration 166/250, Loss: 0.0088\n",
      "Epoch 75/200, Iteration 167/250, Loss: 0.0218\n",
      "Epoch 75/200, Iteration 168/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 169/250, Loss: 0.0222\n",
      "Epoch 75/200, Iteration 170/250, Loss: 0.0172\n",
      "Epoch 75/200, Iteration 171/250, Loss: 0.0385\n",
      "Epoch 75/200, Iteration 172/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 173/250, Loss: 0.0090\n",
      "Epoch 75/200, Iteration 174/250, Loss: 0.0114\n",
      "Epoch 75/200, Iteration 175/250, Loss: 0.0267\n",
      "Epoch 75/200, Iteration 176/250, Loss: 0.0350\n",
      "Epoch 75/200, Iteration 177/250, Loss: 0.0270\n",
      "Epoch 75/200, Iteration 178/250, Loss: 0.0197\n",
      "Epoch 75/200, Iteration 179/250, Loss: 0.0300\n",
      "Epoch 75/200, Iteration 180/250, Loss: 0.0125\n",
      "Epoch 75/200, Iteration 181/250, Loss: 0.0171\n",
      "Epoch 75/200, Iteration 182/250, Loss: 0.0118\n",
      "Epoch 75/200, Iteration 183/250, Loss: 0.0136\n",
      "Epoch 75/200, Iteration 184/250, Loss: 0.0075\n",
      "Epoch 75/200, Iteration 185/250, Loss: 0.0225\n",
      "Epoch 75/200, Iteration 186/250, Loss: 0.0140\n",
      "Epoch 75/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 188/250, Loss: 0.0355\n",
      "Epoch 75/200, Iteration 189/250, Loss: 0.0188\n",
      "Epoch 75/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 75/200, Iteration 191/250, Loss: 0.0131\n",
      "Epoch 75/200, Iteration 192/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 193/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 194/250, Loss: 0.0105\n",
      "Epoch 75/200, Iteration 195/250, Loss: 0.0175\n",
      "Epoch 75/200, Iteration 196/250, Loss: 0.0115\n",
      "Epoch 75/200, Iteration 197/250, Loss: 0.0143\n",
      "Epoch 75/200, Iteration 198/250, Loss: 0.0079\n",
      "Epoch 75/200, Iteration 199/250, Loss: 0.0162\n",
      "Epoch 75/200, Iteration 200/250, Loss: 0.0193\n",
      "Epoch 75/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 202/250, Loss: 0.0238\n",
      "Epoch 75/200, Iteration 203/250, Loss: 0.0078\n",
      "Epoch 75/200, Iteration 204/250, Loss: 0.0121\n",
      "Epoch 75/200, Iteration 205/250, Loss: 0.0270\n",
      "Epoch 75/200, Iteration 206/250, Loss: 0.0074\n",
      "Epoch 75/200, Iteration 207/250, Loss: 0.0267\n",
      "Epoch 75/200, Iteration 208/250, Loss: 0.0091\n",
      "Epoch 75/200, Iteration 209/250, Loss: 0.0184\n",
      "Epoch 75/200, Iteration 210/250, Loss: 0.0161\n",
      "Epoch 75/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 75/200, Iteration 212/250, Loss: 0.0082\n",
      "Epoch 75/200, Iteration 213/250, Loss: 0.0379\n",
      "Epoch 75/200, Iteration 214/250, Loss: 0.0134\n",
      "Epoch 75/200, Iteration 215/250, Loss: 0.0116\n",
      "Epoch 75/200, Iteration 216/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 217/250, Loss: 0.0133\n",
      "Epoch 75/200, Iteration 218/250, Loss: 0.0123\n",
      "Epoch 75/200, Iteration 219/250, Loss: 0.0124\n",
      "Epoch 75/200, Iteration 220/250, Loss: 0.0072\n",
      "Epoch 75/200, Iteration 221/250, Loss: 0.0171\n",
      "Epoch 75/200, Iteration 222/250, Loss: 0.0156\n",
      "Epoch 75/200, Iteration 223/250, Loss: 0.0088\n",
      "Epoch 75/200, Iteration 224/250, Loss: 0.0104\n",
      "Epoch 75/200, Iteration 225/250, Loss: 0.0133\n",
      "Epoch 75/200, Iteration 226/250, Loss: 0.0134\n",
      "Epoch 75/200, Iteration 227/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 228/250, Loss: 0.0144\n",
      "Epoch 75/200, Iteration 229/250, Loss: 0.0162\n",
      "Epoch 75/200, Iteration 230/250, Loss: 0.0192\n",
      "Epoch 75/200, Iteration 231/250, Loss: 0.0209\n",
      "Epoch 75/200, Iteration 232/250, Loss: 0.0073\n",
      "Epoch 75/200, Iteration 233/250, Loss: 0.0069\n",
      "Epoch 75/200, Iteration 234/250, Loss: 0.0083\n",
      "Epoch 75/200, Iteration 235/250, Loss: 0.0142\n",
      "Epoch 75/200, Iteration 236/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 237/250, Loss: 0.0185\n",
      "Epoch 75/200, Iteration 238/250, Loss: 0.0106\n",
      "Epoch 75/200, Iteration 239/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 240/250, Loss: 0.0075\n",
      "Epoch 75/200, Iteration 241/250, Loss: 0.0114\n",
      "Epoch 75/200, Iteration 242/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 243/250, Loss: 0.0313\n",
      "Epoch 75/200, Iteration 244/250, Loss: 0.0149\n",
      "Epoch 75/200, Iteration 245/250, Loss: 0.0167\n",
      "Epoch 75/200, Iteration 246/250, Loss: 0.0170\n",
      "Epoch 75/200, Iteration 247/250, Loss: 0.0114\n",
      "Epoch 75/200, Iteration 248/250, Loss: 0.0061\n",
      "Epoch 75/200, Iteration 249/250, Loss: 0.0207\n",
      "Epoch 75/200, Iteration 250/250, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.05%, Avg loss: 0.007098, MRE: 0.680204 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.05%, Avg loss: 0.007003, MRE: 1.154580 \n",
      "\n",
      "Epoch 76/200, Iteration 1/250, Loss: 0.0192\n",
      "Epoch 76/200, Iteration 2/250, Loss: 0.0081\n",
      "Epoch 76/200, Iteration 3/250, Loss: 0.0082\n",
      "Epoch 76/200, Iteration 4/250, Loss: 0.0186\n",
      "Epoch 76/200, Iteration 5/250, Loss: 0.0111\n",
      "Epoch 76/200, Iteration 6/250, Loss: 0.0135\n",
      "Epoch 76/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 8/250, Loss: 0.0182\n",
      "Epoch 76/200, Iteration 9/250, Loss: 0.0082\n",
      "Epoch 76/200, Iteration 10/250, Loss: 0.0108\n",
      "Epoch 76/200, Iteration 11/250, Loss: 0.0155\n",
      "Epoch 76/200, Iteration 12/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 13/250, Loss: 0.0112\n",
      "Epoch 76/200, Iteration 14/250, Loss: 0.0100\n",
      "Epoch 76/200, Iteration 15/250, Loss: 0.0093\n",
      "Epoch 76/200, Iteration 16/250, Loss: 0.0247\n",
      "Epoch 76/200, Iteration 17/250, Loss: 0.0112\n",
      "Epoch 76/200, Iteration 18/250, Loss: 0.0140\n",
      "Epoch 76/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 76/200, Iteration 20/250, Loss: 0.0102\n",
      "Epoch 76/200, Iteration 21/250, Loss: 0.0129\n",
      "Epoch 76/200, Iteration 22/250, Loss: 0.0187\n",
      "Epoch 76/200, Iteration 23/250, Loss: 0.0098\n",
      "Epoch 76/200, Iteration 24/250, Loss: 0.0187\n",
      "Epoch 76/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 26/250, Loss: 0.0249\n",
      "Epoch 76/200, Iteration 27/250, Loss: 0.0089\n",
      "Epoch 76/200, Iteration 28/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 29/250, Loss: 0.0095\n",
      "Epoch 76/200, Iteration 30/250, Loss: 0.0123\n",
      "Epoch 76/200, Iteration 31/250, Loss: 0.0140\n",
      "Epoch 76/200, Iteration 32/250, Loss: 0.0127\n",
      "Epoch 76/200, Iteration 33/250, Loss: 0.0230\n",
      "Epoch 76/200, Iteration 34/250, Loss: 0.0131\n",
      "Epoch 76/200, Iteration 35/250, Loss: 0.0298\n",
      "Epoch 76/200, Iteration 36/250, Loss: 0.0116\n",
      "Epoch 76/200, Iteration 37/250, Loss: 0.0054\n",
      "Epoch 76/200, Iteration 38/250, Loss: 0.0154\n",
      "Epoch 76/200, Iteration 39/250, Loss: 0.0142\n",
      "Epoch 76/200, Iteration 40/250, Loss: 0.0133\n",
      "Epoch 76/200, Iteration 41/250, Loss: 0.0065\n",
      "Epoch 76/200, Iteration 42/250, Loss: 0.0078\n",
      "Epoch 76/200, Iteration 43/250, Loss: 0.0126\n",
      "Epoch 76/200, Iteration 44/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 45/250, Loss: 0.0131\n",
      "Epoch 76/200, Iteration 46/250, Loss: 0.0076\n",
      "Epoch 76/200, Iteration 47/250, Loss: 0.0091\n",
      "Epoch 76/200, Iteration 48/250, Loss: 0.0168\n",
      "Epoch 76/200, Iteration 49/250, Loss: 0.0295\n",
      "Epoch 76/200, Iteration 50/250, Loss: 0.0160\n",
      "Epoch 76/200, Iteration 51/250, Loss: 0.0132\n",
      "Epoch 76/200, Iteration 52/250, Loss: 0.0121\n",
      "Epoch 76/200, Iteration 53/250, Loss: 0.0068\n",
      "Epoch 76/200, Iteration 54/250, Loss: 0.0172\n",
      "Epoch 76/200, Iteration 55/250, Loss: 0.0210\n",
      "Epoch 76/200, Iteration 56/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 57/250, Loss: 0.0078\n",
      "Epoch 76/200, Iteration 58/250, Loss: 0.0130\n",
      "Epoch 76/200, Iteration 59/250, Loss: 0.0150\n",
      "Epoch 76/200, Iteration 60/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 62/250, Loss: 0.0168\n",
      "Epoch 76/200, Iteration 63/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 64/250, Loss: 0.0266\n",
      "Epoch 76/200, Iteration 65/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 66/250, Loss: 0.0187\n",
      "Epoch 76/200, Iteration 67/250, Loss: 0.0145\n",
      "Epoch 76/200, Iteration 68/250, Loss: 0.0132\n",
      "Epoch 76/200, Iteration 69/250, Loss: 0.0098\n",
      "Epoch 76/200, Iteration 70/250, Loss: 0.0439\n",
      "Epoch 76/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 76/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 76/200, Iteration 73/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 76/200, Iteration 75/250, Loss: 0.0136\n",
      "Epoch 76/200, Iteration 76/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 77/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 78/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 79/250, Loss: 0.0370\n",
      "Epoch 76/200, Iteration 80/250, Loss: 0.0407\n",
      "Epoch 76/200, Iteration 81/250, Loss: 0.0163\n",
      "Epoch 76/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 83/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 84/250, Loss: 0.0091\n",
      "Epoch 76/200, Iteration 85/250, Loss: 0.0168\n",
      "Epoch 76/200, Iteration 86/250, Loss: 0.0212\n",
      "Epoch 76/200, Iteration 87/250, Loss: 0.0202\n",
      "Epoch 76/200, Iteration 88/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 89/250, Loss: 0.0093\n",
      "Epoch 76/200, Iteration 90/250, Loss: 0.0133\n",
      "Epoch 76/200, Iteration 91/250, Loss: 0.0158\n",
      "Epoch 76/200, Iteration 92/250, Loss: 0.0240\n",
      "Epoch 76/200, Iteration 93/250, Loss: 0.0134\n",
      "Epoch 76/200, Iteration 94/250, Loss: 0.0211\n",
      "Epoch 76/200, Iteration 95/250, Loss: 0.0167\n",
      "Epoch 76/200, Iteration 96/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 97/250, Loss: 0.0130\n",
      "Epoch 76/200, Iteration 98/250, Loss: 0.0133\n",
      "Epoch 76/200, Iteration 99/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 76/200, Iteration 102/250, Loss: 0.0113\n",
      "Epoch 76/200, Iteration 103/250, Loss: 0.0159\n",
      "Epoch 76/200, Iteration 104/250, Loss: 0.0279\n",
      "Epoch 76/200, Iteration 105/250, Loss: 0.0213\n",
      "Epoch 76/200, Iteration 106/250, Loss: 0.0074\n",
      "Epoch 76/200, Iteration 107/250, Loss: 0.0194\n",
      "Epoch 76/200, Iteration 108/250, Loss: 0.0220\n",
      "Epoch 76/200, Iteration 109/250, Loss: 0.0482\n",
      "Epoch 76/200, Iteration 110/250, Loss: 0.0186\n",
      "Epoch 76/200, Iteration 111/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 112/250, Loss: 0.0276\n",
      "Epoch 76/200, Iteration 113/250, Loss: 0.0265\n",
      "Epoch 76/200, Iteration 114/250, Loss: 0.0176\n",
      "Epoch 76/200, Iteration 115/250, Loss: 0.0163\n",
      "Epoch 76/200, Iteration 116/250, Loss: 0.0137\n",
      "Epoch 76/200, Iteration 117/250, Loss: 0.0190\n",
      "Epoch 76/200, Iteration 118/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 119/250, Loss: 0.0346\n",
      "Epoch 76/200, Iteration 120/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 121/250, Loss: 0.0099\n",
      "Epoch 76/200, Iteration 122/250, Loss: 0.0177\n",
      "Epoch 76/200, Iteration 123/250, Loss: 0.0355\n",
      "Epoch 76/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 76/200, Iteration 125/250, Loss: 0.0049\n",
      "Epoch 76/200, Iteration 126/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 127/250, Loss: 0.0435\n",
      "Epoch 76/200, Iteration 128/250, Loss: 0.0096\n",
      "Epoch 76/200, Iteration 129/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 130/250, Loss: 0.0134\n",
      "Epoch 76/200, Iteration 131/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 132/250, Loss: 0.0183\n",
      "Epoch 76/200, Iteration 133/250, Loss: 0.0071\n",
      "Epoch 76/200, Iteration 134/250, Loss: 0.0198\n",
      "Epoch 76/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 76/200, Iteration 136/250, Loss: 0.0144\n",
      "Epoch 76/200, Iteration 137/250, Loss: 0.0195\n",
      "Epoch 76/200, Iteration 138/250, Loss: 0.0121\n",
      "Epoch 76/200, Iteration 139/250, Loss: 0.0179\n",
      "Epoch 76/200, Iteration 140/250, Loss: 0.0068\n",
      "Epoch 76/200, Iteration 141/250, Loss: 0.0221\n",
      "Epoch 76/200, Iteration 142/250, Loss: 0.0197\n",
      "Epoch 76/200, Iteration 143/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 144/250, Loss: 0.0105\n",
      "Epoch 76/200, Iteration 145/250, Loss: 0.0250\n",
      "Epoch 76/200, Iteration 146/250, Loss: 0.0085\n",
      "Epoch 76/200, Iteration 147/250, Loss: 0.0119\n",
      "Epoch 76/200, Iteration 148/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 149/250, Loss: 0.0160\n",
      "Epoch 76/200, Iteration 150/250, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 151/250, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 152/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 153/250, Loss: 0.0192\n",
      "Epoch 76/200, Iteration 154/250, Loss: 0.0285\n",
      "Epoch 76/200, Iteration 155/250, Loss: 0.0124\n",
      "Epoch 76/200, Iteration 156/250, Loss: 0.0250\n",
      "Epoch 76/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 76/200, Iteration 158/250, Loss: 0.0157\n",
      "Epoch 76/200, Iteration 159/250, Loss: 0.0174\n",
      "Epoch 76/200, Iteration 160/250, Loss: 0.0237\n",
      "Epoch 76/200, Iteration 161/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 162/250, Loss: 0.0157\n",
      "Epoch 76/200, Iteration 163/250, Loss: 0.0071\n",
      "Epoch 76/200, Iteration 164/250, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 165/250, Loss: 0.0107\n",
      "Epoch 76/200, Iteration 166/250, Loss: 0.0179\n",
      "Epoch 76/200, Iteration 167/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 168/250, Loss: 0.0169\n",
      "Epoch 76/200, Iteration 169/250, Loss: 0.0121\n",
      "Epoch 76/200, Iteration 170/250, Loss: 0.0289\n",
      "Epoch 76/200, Iteration 171/250, Loss: 0.0082\n",
      "Epoch 76/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 76/200, Iteration 173/250, Loss: 0.0171\n",
      "Epoch 76/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 76/200, Iteration 175/250, Loss: 0.0086\n",
      "Epoch 76/200, Iteration 176/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 177/250, Loss: 0.0182\n",
      "Epoch 76/200, Iteration 178/250, Loss: 0.0187\n",
      "Epoch 76/200, Iteration 179/250, Loss: 0.0165\n",
      "Epoch 76/200, Iteration 180/250, Loss: 0.0408\n",
      "Epoch 76/200, Iteration 181/250, Loss: 0.0095\n",
      "Epoch 76/200, Iteration 182/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 183/250, Loss: 0.0172\n",
      "Epoch 76/200, Iteration 184/250, Loss: 0.0178\n",
      "Epoch 76/200, Iteration 185/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 186/250, Loss: 0.0469\n",
      "Epoch 76/200, Iteration 187/250, Loss: 0.0184\n",
      "Epoch 76/200, Iteration 188/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 189/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 190/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 191/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 192/250, Loss: 0.0136\n",
      "Epoch 76/200, Iteration 193/250, Loss: 0.0125\n",
      "Epoch 76/200, Iteration 194/250, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 76/200, Iteration 196/250, Loss: 0.0257\n",
      "Epoch 76/200, Iteration 197/250, Loss: 0.0224\n",
      "Epoch 76/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 76/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 76/200, Iteration 200/250, Loss: 0.0146\n",
      "Epoch 76/200, Iteration 201/250, Loss: 0.0244\n",
      "Epoch 76/200, Iteration 202/250, Loss: 0.0108\n",
      "Epoch 76/200, Iteration 203/250, Loss: 0.0055\n",
      "Epoch 76/200, Iteration 204/250, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 205/250, Loss: 0.0215\n",
      "Epoch 76/200, Iteration 206/250, Loss: 0.0112\n",
      "Epoch 76/200, Iteration 207/250, Loss: 0.0143\n",
      "Epoch 76/200, Iteration 208/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 209/250, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 210/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 211/250, Loss: 0.0072\n",
      "Epoch 76/200, Iteration 212/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 213/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 214/250, Loss: 0.0146\n",
      "Epoch 76/200, Iteration 215/250, Loss: 0.0087\n",
      "Epoch 76/200, Iteration 216/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 217/250, Loss: 0.0227\n",
      "Epoch 76/200, Iteration 218/250, Loss: 0.0078\n",
      "Epoch 76/200, Iteration 219/250, Loss: 0.0076\n",
      "Epoch 76/200, Iteration 220/250, Loss: 0.0186\n",
      "Epoch 76/200, Iteration 221/250, Loss: 0.0105\n",
      "Epoch 76/200, Iteration 222/250, Loss: 0.0074\n",
      "Epoch 76/200, Iteration 223/250, Loss: 0.0099\n",
      "Epoch 76/200, Iteration 224/250, Loss: 0.0165\n",
      "Epoch 76/200, Iteration 225/250, Loss: 0.0092\n",
      "Epoch 76/200, Iteration 226/250, Loss: 0.0118\n",
      "Epoch 76/200, Iteration 227/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 228/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 229/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 230/250, Loss: 0.0100\n",
      "Epoch 76/200, Iteration 231/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 232/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 233/250, Loss: 0.0260\n",
      "Epoch 76/200, Iteration 234/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 235/250, Loss: 0.0241\n",
      "Epoch 76/200, Iteration 236/250, Loss: 0.0125\n",
      "Epoch 76/200, Iteration 237/250, Loss: 0.0250\n",
      "Epoch 76/200, Iteration 238/250, Loss: 0.0207\n",
      "Epoch 76/200, Iteration 239/250, Loss: 0.0149\n",
      "Epoch 76/200, Iteration 240/250, Loss: 0.0086\n",
      "Epoch 76/200, Iteration 241/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 242/250, Loss: 0.0138\n",
      "Epoch 76/200, Iteration 243/250, Loss: 0.0206\n",
      "Epoch 76/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 245/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 246/250, Loss: 0.0088\n",
      "Epoch 76/200, Iteration 247/250, Loss: 0.0187\n",
      "Epoch 76/200, Iteration 248/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 249/250, Loss: 0.0076\n",
      "Epoch 76/200, Iteration 250/250, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 88.89%, Avg loss: 0.006401, MRE: 0.608888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.006389, MRE: 0.980400 \n",
      "\n",
      "Epoch 77/200, Iteration 1/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 2/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 3/250, Loss: 0.0140\n",
      "Epoch 77/200, Iteration 4/250, Loss: 0.0117\n",
      "Epoch 77/200, Iteration 5/250, Loss: 0.0111\n",
      "Epoch 77/200, Iteration 6/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 8/250, Loss: 0.0169\n",
      "Epoch 77/200, Iteration 9/250, Loss: 0.0339\n",
      "Epoch 77/200, Iteration 10/250, Loss: 0.0120\n",
      "Epoch 77/200, Iteration 11/250, Loss: 0.0403\n",
      "Epoch 77/200, Iteration 12/250, Loss: 0.0197\n",
      "Epoch 77/200, Iteration 13/250, Loss: 0.0161\n",
      "Epoch 77/200, Iteration 14/250, Loss: 0.0195\n",
      "Epoch 77/200, Iteration 15/250, Loss: 0.0153\n",
      "Epoch 77/200, Iteration 16/250, Loss: 0.0399\n",
      "Epoch 77/200, Iteration 17/250, Loss: 0.0099\n",
      "Epoch 77/200, Iteration 18/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 19/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 20/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 21/250, Loss: 0.0111\n",
      "Epoch 77/200, Iteration 22/250, Loss: 0.0228\n",
      "Epoch 77/200, Iteration 23/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 25/250, Loss: 0.0211\n",
      "Epoch 77/200, Iteration 26/250, Loss: 0.0187\n",
      "Epoch 77/200, Iteration 27/250, Loss: 0.0108\n",
      "Epoch 77/200, Iteration 28/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 29/250, Loss: 0.0116\n",
      "Epoch 77/200, Iteration 30/250, Loss: 0.0164\n",
      "Epoch 77/200, Iteration 31/250, Loss: 0.0127\n",
      "Epoch 77/200, Iteration 32/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 33/250, Loss: 0.0190\n",
      "Epoch 77/200, Iteration 34/250, Loss: 0.0159\n",
      "Epoch 77/200, Iteration 35/250, Loss: 0.0091\n",
      "Epoch 77/200, Iteration 36/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 37/250, Loss: 0.0197\n",
      "Epoch 77/200, Iteration 38/250, Loss: 0.0356\n",
      "Epoch 77/200, Iteration 39/250, Loss: 0.0076\n",
      "Epoch 77/200, Iteration 40/250, Loss: 0.0214\n",
      "Epoch 77/200, Iteration 41/250, Loss: 0.0155\n",
      "Epoch 77/200, Iteration 42/250, Loss: 0.0124\n",
      "Epoch 77/200, Iteration 43/250, Loss: 0.0191\n",
      "Epoch 77/200, Iteration 44/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 45/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 46/250, Loss: 0.0140\n",
      "Epoch 77/200, Iteration 47/250, Loss: 0.0104\n",
      "Epoch 77/200, Iteration 48/250, Loss: 0.0069\n",
      "Epoch 77/200, Iteration 49/250, Loss: 0.0319\n",
      "Epoch 77/200, Iteration 50/250, Loss: 0.0059\n",
      "Epoch 77/200, Iteration 51/250, Loss: 0.0297\n",
      "Epoch 77/200, Iteration 52/250, Loss: 0.0223\n",
      "Epoch 77/200, Iteration 53/250, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 54/250, Loss: 0.0169\n",
      "Epoch 77/200, Iteration 55/250, Loss: 0.0075\n",
      "Epoch 77/200, Iteration 56/250, Loss: 0.0185\n",
      "Epoch 77/200, Iteration 57/250, Loss: 0.0168\n",
      "Epoch 77/200, Iteration 58/250, Loss: 0.0093\n",
      "Epoch 77/200, Iteration 59/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 60/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 61/250, Loss: 0.0306\n",
      "Epoch 77/200, Iteration 62/250, Loss: 0.0221\n",
      "Epoch 77/200, Iteration 63/250, Loss: 0.0087\n",
      "Epoch 77/200, Iteration 64/250, Loss: 0.0083\n",
      "Epoch 77/200, Iteration 65/250, Loss: 0.0092\n",
      "Epoch 77/200, Iteration 66/250, Loss: 0.0099\n",
      "Epoch 77/200, Iteration 67/250, Loss: 0.0094\n",
      "Epoch 77/200, Iteration 68/250, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 69/250, Loss: 0.0251\n",
      "Epoch 77/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 77/200, Iteration 71/250, Loss: 0.0129\n",
      "Epoch 77/200, Iteration 72/250, Loss: 0.0139\n",
      "Epoch 77/200, Iteration 73/250, Loss: 0.0114\n",
      "Epoch 77/200, Iteration 74/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 75/250, Loss: 0.0082\n",
      "Epoch 77/200, Iteration 76/250, Loss: 0.0108\n",
      "Epoch 77/200, Iteration 77/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 78/250, Loss: 0.0214\n",
      "Epoch 77/200, Iteration 79/250, Loss: 0.0263\n",
      "Epoch 77/200, Iteration 80/250, Loss: 0.0151\n",
      "Epoch 77/200, Iteration 81/250, Loss: 0.0228\n",
      "Epoch 77/200, Iteration 82/250, Loss: 0.0122\n",
      "Epoch 77/200, Iteration 83/250, Loss: 0.0119\n",
      "Epoch 77/200, Iteration 84/250, Loss: 0.0078\n",
      "Epoch 77/200, Iteration 85/250, Loss: 0.0160\n",
      "Epoch 77/200, Iteration 86/250, Loss: 0.0161\n",
      "Epoch 77/200, Iteration 87/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 88/250, Loss: 0.0095\n",
      "Epoch 77/200, Iteration 89/250, Loss: 0.0193\n",
      "Epoch 77/200, Iteration 90/250, Loss: 0.0228\n",
      "Epoch 77/200, Iteration 91/250, Loss: 0.0224\n",
      "Epoch 77/200, Iteration 92/250, Loss: 0.0164\n",
      "Epoch 77/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 77/200, Iteration 94/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 95/250, Loss: 0.0078\n",
      "Epoch 77/200, Iteration 96/250, Loss: 0.0113\n",
      "Epoch 77/200, Iteration 97/250, Loss: 0.0088\n",
      "Epoch 77/200, Iteration 98/250, Loss: 0.0228\n",
      "Epoch 77/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 100/250, Loss: 0.0234\n",
      "Epoch 77/200, Iteration 101/250, Loss: 0.0132\n",
      "Epoch 77/200, Iteration 102/250, Loss: 0.0217\n",
      "Epoch 77/200, Iteration 103/250, Loss: 0.0116\n",
      "Epoch 77/200, Iteration 104/250, Loss: 0.0217\n",
      "Epoch 77/200, Iteration 105/250, Loss: 0.0083\n",
      "Epoch 77/200, Iteration 106/250, Loss: 0.0128\n",
      "Epoch 77/200, Iteration 107/250, Loss: 0.0091\n",
      "Epoch 77/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 109/250, Loss: 0.0097\n",
      "Epoch 77/200, Iteration 110/250, Loss: 0.0165\n",
      "Epoch 77/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 77/200, Iteration 112/250, Loss: 0.0182\n",
      "Epoch 77/200, Iteration 113/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 114/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 115/250, Loss: 0.0163\n",
      "Epoch 77/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 77/200, Iteration 117/250, Loss: 0.0093\n",
      "Epoch 77/200, Iteration 118/250, Loss: 0.0114\n",
      "Epoch 77/200, Iteration 119/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 120/250, Loss: 0.0122\n",
      "Epoch 77/200, Iteration 121/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 122/250, Loss: 0.0168\n",
      "Epoch 77/200, Iteration 123/250, Loss: 0.0102\n",
      "Epoch 77/200, Iteration 124/250, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 125/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 126/250, Loss: 0.0144\n",
      "Epoch 77/200, Iteration 127/250, Loss: 0.0116\n",
      "Epoch 77/200, Iteration 128/250, Loss: 0.0154\n",
      "Epoch 77/200, Iteration 129/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 130/250, Loss: 0.0068\n",
      "Epoch 77/200, Iteration 131/250, Loss: 0.0108\n",
      "Epoch 77/200, Iteration 132/250, Loss: 0.0129\n",
      "Epoch 77/200, Iteration 133/250, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 134/250, Loss: 0.0214\n",
      "Epoch 77/200, Iteration 135/250, Loss: 0.0093\n",
      "Epoch 77/200, Iteration 136/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 137/250, Loss: 0.0129\n",
      "Epoch 77/200, Iteration 138/250, Loss: 0.0190\n",
      "Epoch 77/200, Iteration 139/250, Loss: 0.0127\n",
      "Epoch 77/200, Iteration 140/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 141/250, Loss: 0.0227\n",
      "Epoch 77/200, Iteration 142/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 143/250, Loss: 0.0185\n",
      "Epoch 77/200, Iteration 144/250, Loss: 0.0217\n",
      "Epoch 77/200, Iteration 145/250, Loss: 0.0255\n",
      "Epoch 77/200, Iteration 146/250, Loss: 0.0195\n",
      "Epoch 77/200, Iteration 147/250, Loss: 0.0183\n",
      "Epoch 77/200, Iteration 148/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 149/250, Loss: 0.0245\n",
      "Epoch 77/200, Iteration 150/250, Loss: 0.0171\n",
      "Epoch 77/200, Iteration 151/250, Loss: 0.0125\n",
      "Epoch 77/200, Iteration 152/250, Loss: 0.0082\n",
      "Epoch 77/200, Iteration 153/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 154/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 155/250, Loss: 0.0094\n",
      "Epoch 77/200, Iteration 156/250, Loss: 0.0089\n",
      "Epoch 77/200, Iteration 157/250, Loss: 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200, Iteration 158/250, Loss: 0.0086\n",
      "Epoch 77/200, Iteration 159/250, Loss: 0.0260\n",
      "Epoch 77/200, Iteration 160/250, Loss: 0.0317\n",
      "Epoch 77/200, Iteration 161/250, Loss: 0.0082\n",
      "Epoch 77/200, Iteration 162/250, Loss: 0.0166\n",
      "Epoch 77/200, Iteration 163/250, Loss: 0.0096\n",
      "Epoch 77/200, Iteration 164/250, Loss: 0.0224\n",
      "Epoch 77/200, Iteration 165/250, Loss: 0.0124\n",
      "Epoch 77/200, Iteration 166/250, Loss: 0.0094\n",
      "Epoch 77/200, Iteration 167/250, Loss: 0.0393\n",
      "Epoch 77/200, Iteration 168/250, Loss: 0.0362\n",
      "Epoch 77/200, Iteration 169/250, Loss: 0.0173\n",
      "Epoch 77/200, Iteration 170/250, Loss: 0.0208\n",
      "Epoch 77/200, Iteration 171/250, Loss: 0.0225\n",
      "Epoch 77/200, Iteration 172/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 173/250, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 174/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 175/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 176/250, Loss: 0.0133\n",
      "Epoch 77/200, Iteration 177/250, Loss: 0.0151\n",
      "Epoch 77/200, Iteration 178/250, Loss: 0.0051\n",
      "Epoch 77/200, Iteration 179/250, Loss: 0.0082\n",
      "Epoch 77/200, Iteration 180/250, Loss: 0.0156\n",
      "Epoch 77/200, Iteration 181/250, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 182/250, Loss: 0.0118\n",
      "Epoch 77/200, Iteration 183/250, Loss: 0.0096\n",
      "Epoch 77/200, Iteration 184/250, Loss: 0.0255\n",
      "Epoch 77/200, Iteration 185/250, Loss: 0.0098\n",
      "Epoch 77/200, Iteration 186/250, Loss: 0.0062\n",
      "Epoch 77/200, Iteration 187/250, Loss: 0.0144\n",
      "Epoch 77/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 77/200, Iteration 189/250, Loss: 0.0308\n",
      "Epoch 77/200, Iteration 190/250, Loss: 0.0073\n",
      "Epoch 77/200, Iteration 191/250, Loss: 0.0158\n",
      "Epoch 77/200, Iteration 192/250, Loss: 0.0074\n",
      "Epoch 77/200, Iteration 193/250, Loss: 0.0276\n",
      "Epoch 77/200, Iteration 194/250, Loss: 0.0126\n",
      "Epoch 77/200, Iteration 195/250, Loss: 0.0098\n",
      "Epoch 77/200, Iteration 196/250, Loss: 0.0086\n",
      "Epoch 77/200, Iteration 197/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 198/250, Loss: 0.0114\n",
      "Epoch 77/200, Iteration 199/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 200/250, Loss: 0.0174\n",
      "Epoch 77/200, Iteration 201/250, Loss: 0.0108\n",
      "Epoch 77/200, Iteration 202/250, Loss: 0.0169\n",
      "Epoch 77/200, Iteration 203/250, Loss: 0.0066\n",
      "Epoch 77/200, Iteration 204/250, Loss: 0.0157\n",
      "Epoch 77/200, Iteration 205/250, Loss: 0.0206\n",
      "Epoch 77/200, Iteration 206/250, Loss: 0.0130\n",
      "Epoch 77/200, Iteration 207/250, Loss: 0.0113\n",
      "Epoch 77/200, Iteration 208/250, Loss: 0.0100\n",
      "Epoch 77/200, Iteration 209/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 77/200, Iteration 211/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 77/200, Iteration 213/250, Loss: 0.0147\n",
      "Epoch 77/200, Iteration 214/250, Loss: 0.0088\n",
      "Epoch 77/200, Iteration 215/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 216/250, Loss: 0.0168\n",
      "Epoch 77/200, Iteration 217/250, Loss: 0.0113\n",
      "Epoch 77/200, Iteration 218/250, Loss: 0.0068\n",
      "Epoch 77/200, Iteration 219/250, Loss: 0.0058\n",
      "Epoch 77/200, Iteration 220/250, Loss: 0.0173\n",
      "Epoch 77/200, Iteration 221/250, Loss: 0.0120\n",
      "Epoch 77/200, Iteration 222/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 223/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 224/250, Loss: 0.0132\n",
      "Epoch 77/200, Iteration 225/250, Loss: 0.0126\n",
      "Epoch 77/200, Iteration 226/250, Loss: 0.0236\n",
      "Epoch 77/200, Iteration 227/250, Loss: 0.0176\n",
      "Epoch 77/200, Iteration 228/250, Loss: 0.0201\n",
      "Epoch 77/200, Iteration 229/250, Loss: 0.0098\n",
      "Epoch 77/200, Iteration 230/250, Loss: 0.0211\n",
      "Epoch 77/200, Iteration 231/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 232/250, Loss: 0.0183\n",
      "Epoch 77/200, Iteration 233/250, Loss: 0.0240\n",
      "Epoch 77/200, Iteration 234/250, Loss: 0.0072\n",
      "Epoch 77/200, Iteration 235/250, Loss: 0.0166\n",
      "Epoch 77/200, Iteration 236/250, Loss: 0.0138\n",
      "Epoch 77/200, Iteration 237/250, Loss: 0.0130\n",
      "Epoch 77/200, Iteration 238/250, Loss: 0.0089\n",
      "Epoch 77/200, Iteration 239/250, Loss: 0.0373\n",
      "Epoch 77/200, Iteration 240/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 241/250, Loss: 0.0180\n",
      "Epoch 77/200, Iteration 242/250, Loss: 0.0274\n",
      "Epoch 77/200, Iteration 243/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 244/250, Loss: 0.0170\n",
      "Epoch 77/200, Iteration 245/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 246/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 247/250, Loss: 0.0096\n",
      "Epoch 77/200, Iteration 248/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 249/250, Loss: 0.0144\n",
      "Epoch 77/200, Iteration 250/250, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 92.53%, Avg loss: 0.006088, MRE: 0.586523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.65%, Avg loss: 0.006075, MRE: 0.930873 \n",
      "\n",
      "Epoch 78/200, Iteration 1/250, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 2/250, Loss: 0.0112\n",
      "Epoch 78/200, Iteration 3/250, Loss: 0.0320\n",
      "Epoch 78/200, Iteration 4/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 6/250, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 7/250, Loss: 0.0079\n",
      "Epoch 78/200, Iteration 8/250, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 9/250, Loss: 0.0077\n",
      "Epoch 78/200, Iteration 10/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 11/250, Loss: 0.0182\n",
      "Epoch 78/200, Iteration 12/250, Loss: 0.0205\n",
      "Epoch 78/200, Iteration 13/250, Loss: 0.0142\n",
      "Epoch 78/200, Iteration 14/250, Loss: 0.0077\n",
      "Epoch 78/200, Iteration 15/250, Loss: 0.0108\n",
      "Epoch 78/200, Iteration 16/250, Loss: 0.0122\n",
      "Epoch 78/200, Iteration 17/250, Loss: 0.0221\n",
      "Epoch 78/200, Iteration 18/250, Loss: 0.0080\n",
      "Epoch 78/200, Iteration 19/250, Loss: 0.0142\n",
      "Epoch 78/200, Iteration 20/250, Loss: 0.0337\n",
      "Epoch 78/200, Iteration 21/250, Loss: 0.0143\n",
      "Epoch 78/200, Iteration 22/250, Loss: 0.0252\n",
      "Epoch 78/200, Iteration 23/250, Loss: 0.0089\n",
      "Epoch 78/200, Iteration 24/250, Loss: 0.0140\n",
      "Epoch 78/200, Iteration 25/250, Loss: 0.0308\n",
      "Epoch 78/200, Iteration 26/250, Loss: 0.0078\n",
      "Epoch 78/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 78/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 78/200, Iteration 29/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 30/250, Loss: 0.0104\n",
      "Epoch 78/200, Iteration 31/250, Loss: 0.0209\n",
      "Epoch 78/200, Iteration 32/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 78/200, Iteration 34/250, Loss: 0.0140\n",
      "Epoch 78/200, Iteration 35/250, Loss: 0.0212\n",
      "Epoch 78/200, Iteration 36/250, Loss: 0.0115\n",
      "Epoch 78/200, Iteration 37/250, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 38/250, Loss: 0.0321\n",
      "Epoch 78/200, Iteration 39/250, Loss: 0.0292\n",
      "Epoch 78/200, Iteration 40/250, Loss: 0.0167\n",
      "Epoch 78/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 42/250, Loss: 0.0073\n",
      "Epoch 78/200, Iteration 43/250, Loss: 0.0186\n",
      "Epoch 78/200, Iteration 44/250, Loss: 0.0073\n",
      "Epoch 78/200, Iteration 45/250, Loss: 0.0122\n",
      "Epoch 78/200, Iteration 46/250, Loss: 0.0129\n",
      "Epoch 78/200, Iteration 47/250, Loss: 0.0100\n",
      "Epoch 78/200, Iteration 48/250, Loss: 0.0156\n",
      "Epoch 78/200, Iteration 49/250, Loss: 0.0079\n",
      "Epoch 78/200, Iteration 50/250, Loss: 0.0097\n",
      "Epoch 78/200, Iteration 51/250, Loss: 0.0118\n",
      "Epoch 78/200, Iteration 52/250, Loss: 0.0128\n",
      "Epoch 78/200, Iteration 53/250, Loss: 0.0199\n",
      "Epoch 78/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 78/200, Iteration 55/250, Loss: 0.0077\n",
      "Epoch 78/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 57/250, Loss: 0.0164\n",
      "Epoch 78/200, Iteration 58/250, Loss: 0.0155\n",
      "Epoch 78/200, Iteration 59/250, Loss: 0.0070\n",
      "Epoch 78/200, Iteration 60/250, Loss: 0.0117\n",
      "Epoch 78/200, Iteration 61/250, Loss: 0.0114\n",
      "Epoch 78/200, Iteration 62/250, Loss: 0.0099\n",
      "Epoch 78/200, Iteration 63/250, Loss: 0.0208\n",
      "Epoch 78/200, Iteration 64/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 65/250, Loss: 0.0082\n",
      "Epoch 78/200, Iteration 66/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 67/250, Loss: 0.0092\n",
      "Epoch 78/200, Iteration 68/250, Loss: 0.0133\n",
      "Epoch 78/200, Iteration 69/250, Loss: 0.0079\n",
      "Epoch 78/200, Iteration 70/250, Loss: 0.0125\n",
      "Epoch 78/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 78/200, Iteration 72/250, Loss: 0.0135\n",
      "Epoch 78/200, Iteration 73/250, Loss: 0.0288\n",
      "Epoch 78/200, Iteration 74/250, Loss: 0.0101\n",
      "Epoch 78/200, Iteration 75/250, Loss: 0.0085\n",
      "Epoch 78/200, Iteration 76/250, Loss: 0.0247\n",
      "Epoch 78/200, Iteration 77/250, Loss: 0.0150\n",
      "Epoch 78/200, Iteration 78/250, Loss: 0.0288\n",
      "Epoch 78/200, Iteration 79/250, Loss: 0.0131\n",
      "Epoch 78/200, Iteration 80/250, Loss: 0.0225\n",
      "Epoch 78/200, Iteration 81/250, Loss: 0.0178\n",
      "Epoch 78/200, Iteration 82/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 83/250, Loss: 0.0162\n",
      "Epoch 78/200, Iteration 84/250, Loss: 0.0105\n",
      "Epoch 78/200, Iteration 85/250, Loss: 0.0148\n",
      "Epoch 78/200, Iteration 86/250, Loss: 0.0176\n",
      "Epoch 78/200, Iteration 87/250, Loss: 0.0104\n",
      "Epoch 78/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 78/200, Iteration 89/250, Loss: 0.0203\n",
      "Epoch 78/200, Iteration 90/250, Loss: 0.0240\n",
      "Epoch 78/200, Iteration 91/250, Loss: 0.0260\n",
      "Epoch 78/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 78/200, Iteration 93/250, Loss: 0.0295\n",
      "Epoch 78/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 78/200, Iteration 95/250, Loss: 0.0173\n",
      "Epoch 78/200, Iteration 96/250, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 97/250, Loss: 0.0087\n",
      "Epoch 78/200, Iteration 98/250, Loss: 0.0063\n",
      "Epoch 78/200, Iteration 99/250, Loss: 0.0118\n",
      "Epoch 78/200, Iteration 100/250, Loss: 0.0148\n",
      "Epoch 78/200, Iteration 101/250, Loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200, Iteration 102/250, Loss: 0.0103\n",
      "Epoch 78/200, Iteration 103/250, Loss: 0.0219\n",
      "Epoch 78/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 78/200, Iteration 105/250, Loss: 0.0277\n",
      "Epoch 78/200, Iteration 106/250, Loss: 0.0174\n",
      "Epoch 78/200, Iteration 107/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 108/250, Loss: 0.0098\n",
      "Epoch 78/200, Iteration 109/250, Loss: 0.0086\n",
      "Epoch 78/200, Iteration 110/250, Loss: 0.0063\n",
      "Epoch 78/200, Iteration 111/250, Loss: 0.0145\n",
      "Epoch 78/200, Iteration 112/250, Loss: 0.0113\n",
      "Epoch 78/200, Iteration 113/250, Loss: 0.0072\n",
      "Epoch 78/200, Iteration 114/250, Loss: 0.0064\n",
      "Epoch 78/200, Iteration 115/250, Loss: 0.0172\n",
      "Epoch 78/200, Iteration 116/250, Loss: 0.0159\n",
      "Epoch 78/200, Iteration 117/250, Loss: 0.0141\n",
      "Epoch 78/200, Iteration 118/250, Loss: 0.0235\n",
      "Epoch 78/200, Iteration 119/250, Loss: 0.0140\n",
      "Epoch 78/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 121/250, Loss: 0.0153\n",
      "Epoch 78/200, Iteration 122/250, Loss: 0.0194\n",
      "Epoch 78/200, Iteration 123/250, Loss: 0.0227\n",
      "Epoch 78/200, Iteration 124/250, Loss: 0.0152\n",
      "Epoch 78/200, Iteration 125/250, Loss: 0.0194\n",
      "Epoch 78/200, Iteration 126/250, Loss: 0.0069\n",
      "Epoch 78/200, Iteration 127/250, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 128/250, Loss: 0.0113\n",
      "Epoch 78/200, Iteration 129/250, Loss: 0.0150\n",
      "Epoch 78/200, Iteration 130/250, Loss: 0.0119\n",
      "Epoch 78/200, Iteration 131/250, Loss: 0.0280\n",
      "Epoch 78/200, Iteration 132/250, Loss: 0.0202\n",
      "Epoch 78/200, Iteration 133/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 134/250, Loss: 0.0223\n",
      "Epoch 78/200, Iteration 135/250, Loss: 0.0070\n",
      "Epoch 78/200, Iteration 136/250, Loss: 0.0112\n",
      "Epoch 78/200, Iteration 137/250, Loss: 0.0108\n",
      "Epoch 78/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 78/200, Iteration 139/250, Loss: 0.0223\n",
      "Epoch 78/200, Iteration 140/250, Loss: 0.0302\n",
      "Epoch 78/200, Iteration 141/250, Loss: 0.0102\n",
      "Epoch 78/200, Iteration 142/250, Loss: 0.0106\n",
      "Epoch 78/200, Iteration 143/250, Loss: 0.0190\n",
      "Epoch 78/200, Iteration 144/250, Loss: 0.0181\n",
      "Epoch 78/200, Iteration 145/250, Loss: 0.0198\n",
      "Epoch 78/200, Iteration 146/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 147/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 148/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 149/250, Loss: 0.0074\n",
      "Epoch 78/200, Iteration 150/250, Loss: 0.0242\n",
      "Epoch 78/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 152/250, Loss: 0.0086\n",
      "Epoch 78/200, Iteration 153/250, Loss: 0.0156\n",
      "Epoch 78/200, Iteration 154/250, Loss: 0.0161\n",
      "Epoch 78/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 156/250, Loss: 0.0421\n",
      "Epoch 78/200, Iteration 157/250, Loss: 0.0346\n",
      "Epoch 78/200, Iteration 158/250, Loss: 0.0102\n",
      "Epoch 78/200, Iteration 159/250, Loss: 0.0161\n",
      "Epoch 78/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 78/200, Iteration 161/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 162/250, Loss: 0.0323\n",
      "Epoch 78/200, Iteration 163/250, Loss: 0.0176\n",
      "Epoch 78/200, Iteration 164/250, Loss: 0.0197\n",
      "Epoch 78/200, Iteration 165/250, Loss: 0.0225\n",
      "Epoch 78/200, Iteration 166/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 167/250, Loss: 0.0080\n",
      "Epoch 78/200, Iteration 168/250, Loss: 0.0309\n",
      "Epoch 78/200, Iteration 169/250, Loss: 0.0191\n",
      "Epoch 78/200, Iteration 170/250, Loss: 0.0234\n",
      "Epoch 78/200, Iteration 171/250, Loss: 0.0253\n",
      "Epoch 78/200, Iteration 172/250, Loss: 0.0135\n",
      "Epoch 78/200, Iteration 173/250, Loss: 0.0100\n",
      "Epoch 78/200, Iteration 174/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 175/250, Loss: 0.0221\n",
      "Epoch 78/200, Iteration 176/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 177/250, Loss: 0.0241\n",
      "Epoch 78/200, Iteration 178/250, Loss: 0.0168\n",
      "Epoch 78/200, Iteration 179/250, Loss: 0.0234\n",
      "Epoch 78/200, Iteration 180/250, Loss: 0.0104\n",
      "Epoch 78/200, Iteration 181/250, Loss: 0.0288\n",
      "Epoch 78/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 78/200, Iteration 183/250, Loss: 0.0250\n",
      "Epoch 78/200, Iteration 184/250, Loss: 0.0141\n",
      "Epoch 78/200, Iteration 185/250, Loss: 0.0136\n",
      "Epoch 78/200, Iteration 186/250, Loss: 0.0103\n",
      "Epoch 78/200, Iteration 187/250, Loss: 0.0114\n",
      "Epoch 78/200, Iteration 188/250, Loss: 0.0200\n",
      "Epoch 78/200, Iteration 189/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 190/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 191/250, Loss: 0.0113\n",
      "Epoch 78/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 193/250, Loss: 0.0131\n",
      "Epoch 78/200, Iteration 194/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 78/200, Iteration 196/250, Loss: 0.0397\n",
      "Epoch 78/200, Iteration 197/250, Loss: 0.0128\n",
      "Epoch 78/200, Iteration 198/250, Loss: 0.0300\n",
      "Epoch 78/200, Iteration 199/250, Loss: 0.0082\n",
      "Epoch 78/200, Iteration 200/250, Loss: 0.0182\n",
      "Epoch 78/200, Iteration 201/250, Loss: 0.0155\n",
      "Epoch 78/200, Iteration 202/250, Loss: 0.0181\n",
      "Epoch 78/200, Iteration 203/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 204/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 205/250, Loss: 0.0155\n",
      "Epoch 78/200, Iteration 206/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 207/250, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 208/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 78/200, Iteration 210/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 211/250, Loss: 0.0073\n",
      "Epoch 78/200, Iteration 212/250, Loss: 0.0150\n",
      "Epoch 78/200, Iteration 213/250, Loss: 0.0100\n",
      "Epoch 78/200, Iteration 214/250, Loss: 0.0079\n",
      "Epoch 78/200, Iteration 215/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 216/250, Loss: 0.0258\n",
      "Epoch 78/200, Iteration 217/250, Loss: 0.0391\n",
      "Epoch 78/200, Iteration 218/250, Loss: 0.0139\n",
      "Epoch 78/200, Iteration 219/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 220/250, Loss: 0.0144\n",
      "Epoch 78/200, Iteration 221/250, Loss: 0.0131\n",
      "Epoch 78/200, Iteration 222/250, Loss: 0.0111\n",
      "Epoch 78/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 78/200, Iteration 224/250, Loss: 0.0316\n",
      "Epoch 78/200, Iteration 225/250, Loss: 0.0129\n",
      "Epoch 78/200, Iteration 226/250, Loss: 0.0184\n",
      "Epoch 78/200, Iteration 227/250, Loss: 0.0128\n",
      "Epoch 78/200, Iteration 228/250, Loss: 0.0153\n",
      "Epoch 78/200, Iteration 229/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 230/250, Loss: 0.0084\n",
      "Epoch 78/200, Iteration 231/250, Loss: 0.0081\n",
      "Epoch 78/200, Iteration 232/250, Loss: 0.0093\n",
      "Epoch 78/200, Iteration 233/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 234/250, Loss: 0.0057\n",
      "Epoch 78/200, Iteration 235/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 236/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 237/250, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 238/250, Loss: 0.0250\n",
      "Epoch 78/200, Iteration 239/250, Loss: 0.0089\n",
      "Epoch 78/200, Iteration 240/250, Loss: 0.0160\n",
      "Epoch 78/200, Iteration 241/250, Loss: 0.0217\n",
      "Epoch 78/200, Iteration 242/250, Loss: 0.0169\n",
      "Epoch 78/200, Iteration 243/250, Loss: 0.0112\n",
      "Epoch 78/200, Iteration 244/250, Loss: 0.0249\n",
      "Epoch 78/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 246/250, Loss: 0.0152\n",
      "Epoch 78/200, Iteration 247/250, Loss: 0.0226\n",
      "Epoch 78/200, Iteration 248/250, Loss: 0.0116\n",
      "Epoch 78/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 78/200, Iteration 250/250, Loss: 0.0134\n",
      "Train Error: \n",
      " Accuracy: 91.61%, Avg loss: 0.006545, MRE: 0.620427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.35%, Avg loss: 0.006473, MRE: 1.009151 \n",
      "\n",
      "Epoch 79/200, Iteration 1/250, Loss: 0.0119\n",
      "Epoch 79/200, Iteration 2/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 3/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 4/250, Loss: 0.0149\n",
      "Epoch 79/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 79/200, Iteration 6/250, Loss: 0.0126\n",
      "Epoch 79/200, Iteration 7/250, Loss: 0.0222\n",
      "Epoch 79/200, Iteration 8/250, Loss: 0.0080\n",
      "Epoch 79/200, Iteration 9/250, Loss: 0.0134\n",
      "Epoch 79/200, Iteration 10/250, Loss: 0.0083\n",
      "Epoch 79/200, Iteration 11/250, Loss: 0.0105\n",
      "Epoch 79/200, Iteration 12/250, Loss: 0.0208\n",
      "Epoch 79/200, Iteration 13/250, Loss: 0.0192\n",
      "Epoch 79/200, Iteration 14/250, Loss: 0.0128\n",
      "Epoch 79/200, Iteration 15/250, Loss: 0.0091\n",
      "Epoch 79/200, Iteration 16/250, Loss: 0.0099\n",
      "Epoch 79/200, Iteration 17/250, Loss: 0.0174\n",
      "Epoch 79/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 79/200, Iteration 19/250, Loss: 0.0070\n",
      "Epoch 79/200, Iteration 20/250, Loss: 0.0210\n",
      "Epoch 79/200, Iteration 21/250, Loss: 0.0129\n",
      "Epoch 79/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 79/200, Iteration 23/250, Loss: 0.0195\n",
      "Epoch 79/200, Iteration 24/250, Loss: 0.0164\n",
      "Epoch 79/200, Iteration 25/250, Loss: 0.0221\n",
      "Epoch 79/200, Iteration 26/250, Loss: 0.0072\n",
      "Epoch 79/200, Iteration 27/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 28/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 29/250, Loss: 0.0075\n",
      "Epoch 79/200, Iteration 30/250, Loss: 0.0079\n",
      "Epoch 79/200, Iteration 31/250, Loss: 0.0107\n",
      "Epoch 79/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 79/200, Iteration 33/250, Loss: 0.0180\n",
      "Epoch 79/200, Iteration 34/250, Loss: 0.0188\n",
      "Epoch 79/200, Iteration 35/250, Loss: 0.0370\n",
      "Epoch 79/200, Iteration 36/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 37/250, Loss: 0.0250\n",
      "Epoch 79/200, Iteration 38/250, Loss: 0.0091\n",
      "Epoch 79/200, Iteration 39/250, Loss: 0.0073\n",
      "Epoch 79/200, Iteration 40/250, Loss: 0.0086\n",
      "Epoch 79/200, Iteration 41/250, Loss: 0.0174\n",
      "Epoch 79/200, Iteration 42/250, Loss: 0.0115\n",
      "Epoch 79/200, Iteration 43/250, Loss: 0.0167\n",
      "Epoch 79/200, Iteration 44/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 45/250, Loss: 0.0088\n",
      "Epoch 79/200, Iteration 46/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 47/250, Loss: 0.0135\n",
      "Epoch 79/200, Iteration 48/250, Loss: 0.0166\n",
      "Epoch 79/200, Iteration 49/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 50/250, Loss: 0.0089\n",
      "Epoch 79/200, Iteration 51/250, Loss: 0.0199\n",
      "Epoch 79/200, Iteration 52/250, Loss: 0.0221\n",
      "Epoch 79/200, Iteration 53/250, Loss: 0.0101\n",
      "Epoch 79/200, Iteration 54/250, Loss: 0.0230\n",
      "Epoch 79/200, Iteration 55/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 56/250, Loss: 0.0261\n",
      "Epoch 79/200, Iteration 57/250, Loss: 0.0159\n",
      "Epoch 79/200, Iteration 58/250, Loss: 0.0144\n",
      "Epoch 79/200, Iteration 59/250, Loss: 0.0109\n",
      "Epoch 79/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 79/200, Iteration 61/250, Loss: 0.0241\n",
      "Epoch 79/200, Iteration 62/250, Loss: 0.0360\n",
      "Epoch 79/200, Iteration 63/250, Loss: 0.0093\n",
      "Epoch 79/200, Iteration 64/250, Loss: 0.0445\n",
      "Epoch 79/200, Iteration 65/250, Loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200, Iteration 66/250, Loss: 0.0102\n",
      "Epoch 79/200, Iteration 67/250, Loss: 0.0130\n",
      "Epoch 79/200, Iteration 68/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 69/250, Loss: 0.0161\n",
      "Epoch 79/200, Iteration 70/250, Loss: 0.0175\n",
      "Epoch 79/200, Iteration 71/250, Loss: 0.0080\n",
      "Epoch 79/200, Iteration 72/250, Loss: 0.0218\n",
      "Epoch 79/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 74/250, Loss: 0.0119\n",
      "Epoch 79/200, Iteration 75/250, Loss: 0.0158\n",
      "Epoch 79/200, Iteration 76/250, Loss: 0.0290\n",
      "Epoch 79/200, Iteration 77/250, Loss: 0.0129\n",
      "Epoch 79/200, Iteration 78/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 79/200, Iteration 80/250, Loss: 0.0176\n",
      "Epoch 79/200, Iteration 81/250, Loss: 0.0285\n",
      "Epoch 79/200, Iteration 82/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 83/250, Loss: 0.0210\n",
      "Epoch 79/200, Iteration 84/250, Loss: 0.0268\n",
      "Epoch 79/200, Iteration 85/250, Loss: 0.0291\n",
      "Epoch 79/200, Iteration 86/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 87/250, Loss: 0.0203\n",
      "Epoch 79/200, Iteration 88/250, Loss: 0.0139\n",
      "Epoch 79/200, Iteration 89/250, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 90/250, Loss: 0.0187\n",
      "Epoch 79/200, Iteration 91/250, Loss: 0.0193\n",
      "Epoch 79/200, Iteration 92/250, Loss: 0.0088\n",
      "Epoch 79/200, Iteration 93/250, Loss: 0.0077\n",
      "Epoch 79/200, Iteration 94/250, Loss: 0.0313\n",
      "Epoch 79/200, Iteration 95/250, Loss: 0.0103\n",
      "Epoch 79/200, Iteration 96/250, Loss: 0.0189\n",
      "Epoch 79/200, Iteration 97/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 98/250, Loss: 0.0202\n",
      "Epoch 79/200, Iteration 99/250, Loss: 0.0130\n",
      "Epoch 79/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 101/250, Loss: 0.0097\n",
      "Epoch 79/200, Iteration 102/250, Loss: 0.0140\n",
      "Epoch 79/200, Iteration 103/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 104/250, Loss: 0.0087\n",
      "Epoch 79/200, Iteration 105/250, Loss: 0.0214\n",
      "Epoch 79/200, Iteration 106/250, Loss: 0.0220\n",
      "Epoch 79/200, Iteration 107/250, Loss: 0.0132\n",
      "Epoch 79/200, Iteration 108/250, Loss: 0.0115\n",
      "Epoch 79/200, Iteration 109/250, Loss: 0.0071\n",
      "Epoch 79/200, Iteration 110/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 111/250, Loss: 0.0399\n",
      "Epoch 79/200, Iteration 112/250, Loss: 0.0301\n",
      "Epoch 79/200, Iteration 113/250, Loss: 0.0106\n",
      "Epoch 79/200, Iteration 114/250, Loss: 0.0136\n",
      "Epoch 79/200, Iteration 115/250, Loss: 0.0150\n",
      "Epoch 79/200, Iteration 116/250, Loss: 0.0277\n",
      "Epoch 79/200, Iteration 117/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 118/250, Loss: 0.0148\n",
      "Epoch 79/200, Iteration 119/250, Loss: 0.0129\n",
      "Epoch 79/200, Iteration 120/250, Loss: 0.0122\n",
      "Epoch 79/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 79/200, Iteration 122/250, Loss: 0.0171\n",
      "Epoch 79/200, Iteration 123/250, Loss: 0.0069\n",
      "Epoch 79/200, Iteration 124/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 125/250, Loss: 0.0047\n",
      "Epoch 79/200, Iteration 126/250, Loss: 0.0218\n",
      "Epoch 79/200, Iteration 127/250, Loss: 0.0086\n",
      "Epoch 79/200, Iteration 128/250, Loss: 0.0239\n",
      "Epoch 79/200, Iteration 129/250, Loss: 0.0070\n",
      "Epoch 79/200, Iteration 130/250, Loss: 0.0087\n",
      "Epoch 79/200, Iteration 131/250, Loss: 0.0180\n",
      "Epoch 79/200, Iteration 132/250, Loss: 0.0142\n",
      "Epoch 79/200, Iteration 133/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 134/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 135/250, Loss: 0.0076\n",
      "Epoch 79/200, Iteration 136/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 137/250, Loss: 0.0340\n",
      "Epoch 79/200, Iteration 138/250, Loss: 0.0172\n",
      "Epoch 79/200, Iteration 139/250, Loss: 0.0132\n",
      "Epoch 79/200, Iteration 140/250, Loss: 0.0239\n",
      "Epoch 79/200, Iteration 141/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 142/250, Loss: 0.0159\n",
      "Epoch 79/200, Iteration 143/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 144/250, Loss: 0.0167\n",
      "Epoch 79/200, Iteration 145/250, Loss: 0.0070\n",
      "Epoch 79/200, Iteration 146/250, Loss: 0.0184\n",
      "Epoch 79/200, Iteration 147/250, Loss: 0.0110\n",
      "Epoch 79/200, Iteration 148/250, Loss: 0.0265\n",
      "Epoch 79/200, Iteration 149/250, Loss: 0.0126\n",
      "Epoch 79/200, Iteration 150/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 151/250, Loss: 0.0109\n",
      "Epoch 79/200, Iteration 152/250, Loss: 0.0263\n",
      "Epoch 79/200, Iteration 153/250, Loss: 0.0272\n",
      "Epoch 79/200, Iteration 154/250, Loss: 0.0297\n",
      "Epoch 79/200, Iteration 155/250, Loss: 0.0227\n",
      "Epoch 79/200, Iteration 156/250, Loss: 0.0080\n",
      "Epoch 79/200, Iteration 157/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 158/250, Loss: 0.0084\n",
      "Epoch 79/200, Iteration 159/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 160/250, Loss: 0.0100\n",
      "Epoch 79/200, Iteration 161/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 162/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 163/250, Loss: 0.0169\n",
      "Epoch 79/200, Iteration 164/250, Loss: 0.0213\n",
      "Epoch 79/200, Iteration 165/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 166/250, Loss: 0.0220\n",
      "Epoch 79/200, Iteration 167/250, Loss: 0.0254\n",
      "Epoch 79/200, Iteration 168/250, Loss: 0.0103\n",
      "Epoch 79/200, Iteration 169/250, Loss: 0.0106\n",
      "Epoch 79/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 79/200, Iteration 171/250, Loss: 0.0142\n",
      "Epoch 79/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 79/200, Iteration 173/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 79/200, Iteration 175/250, Loss: 0.0190\n",
      "Epoch 79/200, Iteration 176/250, Loss: 0.0147\n",
      "Epoch 79/200, Iteration 177/250, Loss: 0.0085\n",
      "Epoch 79/200, Iteration 178/250, Loss: 0.0103\n",
      "Epoch 79/200, Iteration 179/250, Loss: 0.0078\n",
      "Epoch 79/200, Iteration 180/250, Loss: 0.0390\n",
      "Epoch 79/200, Iteration 181/250, Loss: 0.0082\n",
      "Epoch 79/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 79/200, Iteration 183/250, Loss: 0.0228\n",
      "Epoch 79/200, Iteration 184/250, Loss: 0.0179\n",
      "Epoch 79/200, Iteration 185/250, Loss: 0.0177\n",
      "Epoch 79/200, Iteration 186/250, Loss: 0.0084\n",
      "Epoch 79/200, Iteration 187/250, Loss: 0.0230\n",
      "Epoch 79/200, Iteration 188/250, Loss: 0.0203\n",
      "Epoch 79/200, Iteration 189/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 190/250, Loss: 0.0315\n",
      "Epoch 79/200, Iteration 191/250, Loss: 0.0155\n",
      "Epoch 79/200, Iteration 192/250, Loss: 0.0106\n",
      "Epoch 79/200, Iteration 193/250, Loss: 0.0128\n",
      "Epoch 79/200, Iteration 194/250, Loss: 0.0222\n",
      "Epoch 79/200, Iteration 195/250, Loss: 0.0109\n",
      "Epoch 79/200, Iteration 196/250, Loss: 0.0111\n",
      "Epoch 79/200, Iteration 197/250, Loss: 0.0217\n",
      "Epoch 79/200, Iteration 198/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 79/200, Iteration 200/250, Loss: 0.0081\n",
      "Epoch 79/200, Iteration 201/250, Loss: 0.0132\n",
      "Epoch 79/200, Iteration 202/250, Loss: 0.0184\n",
      "Epoch 79/200, Iteration 203/250, Loss: 0.0096\n",
      "Epoch 79/200, Iteration 204/250, Loss: 0.0158\n",
      "Epoch 79/200, Iteration 205/250, Loss: 0.0126\n",
      "Epoch 79/200, Iteration 206/250, Loss: 0.0149\n",
      "Epoch 79/200, Iteration 207/250, Loss: 0.0146\n",
      "Epoch 79/200, Iteration 208/250, Loss: 0.0134\n",
      "Epoch 79/200, Iteration 209/250, Loss: 0.0410\n",
      "Epoch 79/200, Iteration 210/250, Loss: 0.0198\n",
      "Epoch 79/200, Iteration 211/250, Loss: 0.0247\n",
      "Epoch 79/200, Iteration 212/250, Loss: 0.0139\n",
      "Epoch 79/200, Iteration 213/250, Loss: 0.0142\n",
      "Epoch 79/200, Iteration 214/250, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 215/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 216/250, Loss: 0.0117\n",
      "Epoch 79/200, Iteration 217/250, Loss: 0.0144\n",
      "Epoch 79/200, Iteration 218/250, Loss: 0.0170\n",
      "Epoch 79/200, Iteration 219/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 220/250, Loss: 0.0151\n",
      "Epoch 79/200, Iteration 221/250, Loss: 0.0326\n",
      "Epoch 79/200, Iteration 222/250, Loss: 0.0136\n",
      "Epoch 79/200, Iteration 223/250, Loss: 0.0159\n",
      "Epoch 79/200, Iteration 224/250, Loss: 0.0085\n",
      "Epoch 79/200, Iteration 225/250, Loss: 0.0308\n",
      "Epoch 79/200, Iteration 226/250, Loss: 0.0087\n",
      "Epoch 79/200, Iteration 227/250, Loss: 0.0255\n",
      "Epoch 79/200, Iteration 228/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 229/250, Loss: 0.0221\n",
      "Epoch 79/200, Iteration 230/250, Loss: 0.0116\n",
      "Epoch 79/200, Iteration 231/250, Loss: 0.0074\n",
      "Epoch 79/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 79/200, Iteration 233/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 234/250, Loss: 0.0183\n",
      "Epoch 79/200, Iteration 235/250, Loss: 0.0162\n",
      "Epoch 79/200, Iteration 236/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 237/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 238/250, Loss: 0.0212\n",
      "Epoch 79/200, Iteration 239/250, Loss: 0.0078\n",
      "Epoch 79/200, Iteration 240/250, Loss: 0.0262\n",
      "Epoch 79/200, Iteration 241/250, Loss: 0.0097\n",
      "Epoch 79/200, Iteration 242/250, Loss: 0.0237\n",
      "Epoch 79/200, Iteration 243/250, Loss: 0.0193\n",
      "Epoch 79/200, Iteration 244/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 245/250, Loss: 0.0192\n",
      "Epoch 79/200, Iteration 246/250, Loss: 0.0106\n",
      "Epoch 79/200, Iteration 247/250, Loss: 0.0181\n",
      "Epoch 79/200, Iteration 248/250, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 249/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 250/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 92.83%, Avg loss: 0.006148, MRE: 0.623232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.006118, MRE: 1.001753 \n",
      "\n",
      "Epoch 80/200, Iteration 1/250, Loss: 0.0354\n",
      "Epoch 80/200, Iteration 2/250, Loss: 0.0176\n",
      "Epoch 80/200, Iteration 3/250, Loss: 0.0144\n",
      "Epoch 80/200, Iteration 4/250, Loss: 0.0136\n",
      "Epoch 80/200, Iteration 5/250, Loss: 0.0243\n",
      "Epoch 80/200, Iteration 6/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 7/250, Loss: 0.0302\n",
      "Epoch 80/200, Iteration 8/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 9/250, Loss: 0.0098\n",
      "Epoch 80/200, Iteration 10/250, Loss: 0.0449\n",
      "Epoch 80/200, Iteration 11/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 12/250, Loss: 0.0137\n",
      "Epoch 80/200, Iteration 13/250, Loss: 0.0209\n",
      "Epoch 80/200, Iteration 14/250, Loss: 0.0270\n",
      "Epoch 80/200, Iteration 15/250, Loss: 0.0080\n",
      "Epoch 80/200, Iteration 16/250, Loss: 0.0167\n",
      "Epoch 80/200, Iteration 17/250, Loss: 0.0146\n",
      "Epoch 80/200, Iteration 18/250, Loss: 0.0064\n",
      "Epoch 80/200, Iteration 19/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 20/250, Loss: 0.0147\n",
      "Epoch 80/200, Iteration 21/250, Loss: 0.0265\n",
      "Epoch 80/200, Iteration 22/250, Loss: 0.0093\n",
      "Epoch 80/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 80/200, Iteration 24/250, Loss: 0.0125\n",
      "Epoch 80/200, Iteration 25/250, Loss: 0.0070\n",
      "Epoch 80/200, Iteration 26/250, Loss: 0.0350\n",
      "Epoch 80/200, Iteration 27/250, Loss: 0.0318\n",
      "Epoch 80/200, Iteration 28/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 29/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 30/250, Loss: 0.0206\n",
      "Epoch 80/200, Iteration 31/250, Loss: 0.0065\n",
      "Epoch 80/200, Iteration 32/250, Loss: 0.0177\n",
      "Epoch 80/200, Iteration 33/250, Loss: 0.0332\n",
      "Epoch 80/200, Iteration 34/250, Loss: 0.0180\n",
      "Epoch 80/200, Iteration 35/250, Loss: 0.0103\n",
      "Epoch 80/200, Iteration 36/250, Loss: 0.0124\n",
      "Epoch 80/200, Iteration 37/250, Loss: 0.0158\n",
      "Epoch 80/200, Iteration 38/250, Loss: 0.0198\n",
      "Epoch 80/200, Iteration 39/250, Loss: 0.0121\n",
      "Epoch 80/200, Iteration 40/250, Loss: 0.0146\n",
      "Epoch 80/200, Iteration 41/250, Loss: 0.0080\n",
      "Epoch 80/200, Iteration 42/250, Loss: 0.0166\n",
      "Epoch 80/200, Iteration 43/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 44/250, Loss: 0.0245\n",
      "Epoch 80/200, Iteration 45/250, Loss: 0.0079\n",
      "Epoch 80/200, Iteration 46/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 47/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 48/250, Loss: 0.0212\n",
      "Epoch 80/200, Iteration 49/250, Loss: 0.0110\n",
      "Epoch 80/200, Iteration 50/250, Loss: 0.0106\n",
      "Epoch 80/200, Iteration 51/250, Loss: 0.0128\n",
      "Epoch 80/200, Iteration 52/250, Loss: 0.0087\n",
      "Epoch 80/200, Iteration 53/250, Loss: 0.0155\n",
      "Epoch 80/200, Iteration 54/250, Loss: 0.0143\n",
      "Epoch 80/200, Iteration 55/250, Loss: 0.0139\n",
      "Epoch 80/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 80/200, Iteration 57/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 58/250, Loss: 0.0268\n",
      "Epoch 80/200, Iteration 59/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 60/250, Loss: 0.0198\n",
      "Epoch 80/200, Iteration 61/250, Loss: 0.0171\n",
      "Epoch 80/200, Iteration 62/250, Loss: 0.0125\n",
      "Epoch 80/200, Iteration 63/250, Loss: 0.0077\n",
      "Epoch 80/200, Iteration 64/250, Loss: 0.0223\n",
      "Epoch 80/200, Iteration 65/250, Loss: 0.0162\n",
      "Epoch 80/200, Iteration 66/250, Loss: 0.0309\n",
      "Epoch 80/200, Iteration 67/250, Loss: 0.0161\n",
      "Epoch 80/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 69/250, Loss: 0.0116\n",
      "Epoch 80/200, Iteration 70/250, Loss: 0.0093\n",
      "Epoch 80/200, Iteration 71/250, Loss: 0.0234\n",
      "Epoch 80/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 73/250, Loss: 0.0172\n",
      "Epoch 80/200, Iteration 74/250, Loss: 0.0107\n",
      "Epoch 80/200, Iteration 75/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 76/250, Loss: 0.0316\n",
      "Epoch 80/200, Iteration 77/250, Loss: 0.0077\n",
      "Epoch 80/200, Iteration 78/250, Loss: 0.0271\n",
      "Epoch 80/200, Iteration 79/250, Loss: 0.0074\n",
      "Epoch 80/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 80/200, Iteration 81/250, Loss: 0.0277\n",
      "Epoch 80/200, Iteration 82/250, Loss: 0.0156\n",
      "Epoch 80/200, Iteration 83/250, Loss: 0.0144\n",
      "Epoch 80/200, Iteration 84/250, Loss: 0.0182\n",
      "Epoch 80/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 80/200, Iteration 86/250, Loss: 0.0189\n",
      "Epoch 80/200, Iteration 87/250, Loss: 0.0163\n",
      "Epoch 80/200, Iteration 88/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 89/250, Loss: 0.0098\n",
      "Epoch 80/200, Iteration 90/250, Loss: 0.0146\n",
      "Epoch 80/200, Iteration 91/250, Loss: 0.0335\n",
      "Epoch 80/200, Iteration 92/250, Loss: 0.0354\n",
      "Epoch 80/200, Iteration 93/250, Loss: 0.0145\n",
      "Epoch 80/200, Iteration 94/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 95/250, Loss: 0.0081\n",
      "Epoch 80/200, Iteration 96/250, Loss: 0.0127\n",
      "Epoch 80/200, Iteration 97/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 98/250, Loss: 0.0251\n",
      "Epoch 80/200, Iteration 99/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 100/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 101/250, Loss: 0.0194\n",
      "Epoch 80/200, Iteration 102/250, Loss: 0.0095\n",
      "Epoch 80/200, Iteration 103/250, Loss: 0.0079\n",
      "Epoch 80/200, Iteration 104/250, Loss: 0.0122\n",
      "Epoch 80/200, Iteration 105/250, Loss: 0.0119\n",
      "Epoch 80/200, Iteration 106/250, Loss: 0.0136\n",
      "Epoch 80/200, Iteration 107/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 108/250, Loss: 0.0114\n",
      "Epoch 80/200, Iteration 109/250, Loss: 0.0262\n",
      "Epoch 80/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 80/200, Iteration 111/250, Loss: 0.0333\n",
      "Epoch 80/200, Iteration 112/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 113/250, Loss: 0.0269\n",
      "Epoch 80/200, Iteration 114/250, Loss: 0.0161\n",
      "Epoch 80/200, Iteration 115/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 116/250, Loss: 0.0139\n",
      "Epoch 80/200, Iteration 117/250, Loss: 0.0121\n",
      "Epoch 80/200, Iteration 118/250, Loss: 0.0066\n",
      "Epoch 80/200, Iteration 119/250, Loss: 0.0219\n",
      "Epoch 80/200, Iteration 120/250, Loss: 0.0163\n",
      "Epoch 80/200, Iteration 121/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 122/250, Loss: 0.0173\n",
      "Epoch 80/200, Iteration 123/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 124/250, Loss: 0.0186\n",
      "Epoch 80/200, Iteration 125/250, Loss: 0.0076\n",
      "Epoch 80/200, Iteration 126/250, Loss: 0.0156\n",
      "Epoch 80/200, Iteration 127/250, Loss: 0.0126\n",
      "Epoch 80/200, Iteration 128/250, Loss: 0.0103\n",
      "Epoch 80/200, Iteration 129/250, Loss: 0.0242\n",
      "Epoch 80/200, Iteration 130/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 131/250, Loss: 0.0249\n",
      "Epoch 80/200, Iteration 132/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 133/250, Loss: 0.0370\n",
      "Epoch 80/200, Iteration 134/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 135/250, Loss: 0.0163\n",
      "Epoch 80/200, Iteration 136/250, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 137/250, Loss: 0.0076\n",
      "Epoch 80/200, Iteration 138/250, Loss: 0.0121\n",
      "Epoch 80/200, Iteration 139/250, Loss: 0.0165\n",
      "Epoch 80/200, Iteration 140/250, Loss: 0.0200\n",
      "Epoch 80/200, Iteration 141/250, Loss: 0.0265\n",
      "Epoch 80/200, Iteration 142/250, Loss: 0.0061\n",
      "Epoch 80/200, Iteration 143/250, Loss: 0.0101\n",
      "Epoch 80/200, Iteration 144/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 145/250, Loss: 0.0118\n",
      "Epoch 80/200, Iteration 146/250, Loss: 0.0250\n",
      "Epoch 80/200, Iteration 147/250, Loss: 0.0097\n",
      "Epoch 80/200, Iteration 148/250, Loss: 0.0273\n",
      "Epoch 80/200, Iteration 149/250, Loss: 0.0368\n",
      "Epoch 80/200, Iteration 150/250, Loss: 0.0198\n",
      "Epoch 80/200, Iteration 151/250, Loss: 0.0132\n",
      "Epoch 80/200, Iteration 152/250, Loss: 0.0124\n",
      "Epoch 80/200, Iteration 153/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 154/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 155/250, Loss: 0.0175\n",
      "Epoch 80/200, Iteration 156/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 157/250, Loss: 0.0162\n",
      "Epoch 80/200, Iteration 158/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 159/250, Loss: 0.0194\n",
      "Epoch 80/200, Iteration 160/250, Loss: 0.0093\n",
      "Epoch 80/200, Iteration 161/250, Loss: 0.0361\n",
      "Epoch 80/200, Iteration 162/250, Loss: 0.0072\n",
      "Epoch 80/200, Iteration 163/250, Loss: 0.0080\n",
      "Epoch 80/200, Iteration 164/250, Loss: 0.0133\n",
      "Epoch 80/200, Iteration 165/250, Loss: 0.0127\n",
      "Epoch 80/200, Iteration 166/250, Loss: 0.0187\n",
      "Epoch 80/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 168/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 169/250, Loss: 0.0081\n",
      "Epoch 80/200, Iteration 170/250, Loss: 0.0073\n",
      "Epoch 80/200, Iteration 171/250, Loss: 0.0075\n",
      "Epoch 80/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 80/200, Iteration 173/250, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 174/250, Loss: 0.0159\n",
      "Epoch 80/200, Iteration 175/250, Loss: 0.0106\n",
      "Epoch 80/200, Iteration 176/250, Loss: 0.0125\n",
      "Epoch 80/200, Iteration 177/250, Loss: 0.0106\n",
      "Epoch 80/200, Iteration 178/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 179/250, Loss: 0.0189\n",
      "Epoch 80/200, Iteration 180/250, Loss: 0.0188\n",
      "Epoch 80/200, Iteration 181/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 182/250, Loss: 0.0079\n",
      "Epoch 80/200, Iteration 183/250, Loss: 0.0127\n",
      "Epoch 80/200, Iteration 184/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 185/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 186/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 188/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 189/250, Loss: 0.0142\n",
      "Epoch 80/200, Iteration 190/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 191/250, Loss: 0.0122\n",
      "Epoch 80/200, Iteration 192/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 80/200, Iteration 194/250, Loss: 0.0272\n",
      "Epoch 80/200, Iteration 195/250, Loss: 0.0160\n",
      "Epoch 80/200, Iteration 196/250, Loss: 0.0290\n",
      "Epoch 80/200, Iteration 197/250, Loss: 0.0084\n",
      "Epoch 80/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 80/200, Iteration 199/250, Loss: 0.0254\n",
      "Epoch 80/200, Iteration 200/250, Loss: 0.0093\n",
      "Epoch 80/200, Iteration 201/250, Loss: 0.0187\n",
      "Epoch 80/200, Iteration 202/250, Loss: 0.0235\n",
      "Epoch 80/200, Iteration 203/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 204/250, Loss: 0.0185\n",
      "Epoch 80/200, Iteration 205/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 206/250, Loss: 0.0176\n",
      "Epoch 80/200, Iteration 207/250, Loss: 0.0072\n",
      "Epoch 80/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 80/200, Iteration 209/250, Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Iteration 210/250, Loss: 0.0181\n",
      "Epoch 80/200, Iteration 211/250, Loss: 0.0098\n",
      "Epoch 80/200, Iteration 212/250, Loss: 0.0121\n",
      "Epoch 80/200, Iteration 213/250, Loss: 0.0102\n",
      "Epoch 80/200, Iteration 214/250, Loss: 0.0070\n",
      "Epoch 80/200, Iteration 215/250, Loss: 0.0101\n",
      "Epoch 80/200, Iteration 216/250, Loss: 0.0186\n",
      "Epoch 80/200, Iteration 217/250, Loss: 0.0134\n",
      "Epoch 80/200, Iteration 218/250, Loss: 0.0147\n",
      "Epoch 80/200, Iteration 219/250, Loss: 0.0113\n",
      "Epoch 80/200, Iteration 220/250, Loss: 0.0233\n",
      "Epoch 80/200, Iteration 221/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 222/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 80/200, Iteration 224/250, Loss: 0.0091\n",
      "Epoch 80/200, Iteration 225/250, Loss: 0.0092\n",
      "Epoch 80/200, Iteration 226/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 227/250, Loss: 0.0166\n",
      "Epoch 80/200, Iteration 228/250, Loss: 0.0140\n",
      "Epoch 80/200, Iteration 229/250, Loss: 0.0327\n",
      "Epoch 80/200, Iteration 230/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 231/250, Loss: 0.0101\n",
      "Epoch 80/200, Iteration 232/250, Loss: 0.0195\n",
      "Epoch 80/200, Iteration 233/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 234/250, Loss: 0.0294\n",
      "Epoch 80/200, Iteration 235/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 80/200, Iteration 237/250, Loss: 0.0165\n",
      "Epoch 80/200, Iteration 238/250, Loss: 0.0277\n",
      "Epoch 80/200, Iteration 239/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 240/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 241/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 242/250, Loss: 0.0149\n",
      "Epoch 80/200, Iteration 243/250, Loss: 0.0249\n",
      "Epoch 80/200, Iteration 244/250, Loss: 0.0360\n",
      "Epoch 80/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 80/200, Iteration 246/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 247/250, Loss: 0.0181\n",
      "Epoch 80/200, Iteration 248/250, Loss: 0.0266\n",
      "Epoch 80/200, Iteration 249/250, Loss: 0.0245\n",
      "Epoch 80/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 62.58%, Avg loss: 0.009229, MRE: 0.689423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.85%, Avg loss: 0.009195, MRE: 0.771498 \n",
      "\n",
      "Epoch 81/200, Iteration 1/250, Loss: 0.0242\n",
      "Epoch 81/200, Iteration 2/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 3/250, Loss: 0.0231\n",
      "Epoch 81/200, Iteration 4/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 5/250, Loss: 0.0191\n",
      "Epoch 81/200, Iteration 6/250, Loss: 0.0089\n",
      "Epoch 81/200, Iteration 7/250, Loss: 0.0222\n",
      "Epoch 81/200, Iteration 8/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 9/250, Loss: 0.0113\n",
      "Epoch 81/200, Iteration 10/250, Loss: 0.0131\n",
      "Epoch 81/200, Iteration 11/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 12/250, Loss: 0.0148\n",
      "Epoch 81/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 81/200, Iteration 14/250, Loss: 0.0187\n",
      "Epoch 81/200, Iteration 15/250, Loss: 0.0118\n",
      "Epoch 81/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 81/200, Iteration 17/250, Loss: 0.0144\n",
      "Epoch 81/200, Iteration 18/250, Loss: 0.0096\n",
      "Epoch 81/200, Iteration 19/250, Loss: 0.0220\n",
      "Epoch 81/200, Iteration 20/250, Loss: 0.0224\n",
      "Epoch 81/200, Iteration 21/250, Loss: 0.0092\n",
      "Epoch 81/200, Iteration 22/250, Loss: 0.0131\n",
      "Epoch 81/200, Iteration 23/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 24/250, Loss: 0.0191\n",
      "Epoch 81/200, Iteration 25/250, Loss: 0.0164\n",
      "Epoch 81/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 81/200, Iteration 27/250, Loss: 0.0092\n",
      "Epoch 81/200, Iteration 28/250, Loss: 0.0267\n",
      "Epoch 81/200, Iteration 29/250, Loss: 0.0078\n",
      "Epoch 81/200, Iteration 30/250, Loss: 0.0409\n",
      "Epoch 81/200, Iteration 31/250, Loss: 0.0149\n",
      "Epoch 81/200, Iteration 32/250, Loss: 0.0189\n",
      "Epoch 81/200, Iteration 33/250, Loss: 0.0269\n",
      "Epoch 81/200, Iteration 34/250, Loss: 0.0140\n",
      "Epoch 81/200, Iteration 35/250, Loss: 0.0112\n",
      "Epoch 81/200, Iteration 36/250, Loss: 0.0108\n",
      "Epoch 81/200, Iteration 37/250, Loss: 0.0257\n",
      "Epoch 81/200, Iteration 38/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 39/250, Loss: 0.0128\n",
      "Epoch 81/200, Iteration 40/250, Loss: 0.0072\n",
      "Epoch 81/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 81/200, Iteration 42/250, Loss: 0.0085\n",
      "Epoch 81/200, Iteration 43/250, Loss: 0.0223\n",
      "Epoch 81/200, Iteration 44/250, Loss: 0.0067\n",
      "Epoch 81/200, Iteration 45/250, Loss: 0.0123\n",
      "Epoch 81/200, Iteration 46/250, Loss: 0.0210\n",
      "Epoch 81/200, Iteration 47/250, Loss: 0.0184\n",
      "Epoch 81/200, Iteration 48/250, Loss: 0.0124\n",
      "Epoch 81/200, Iteration 49/250, Loss: 0.0161\n",
      "Epoch 81/200, Iteration 50/250, Loss: 0.0183\n",
      "Epoch 81/200, Iteration 51/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 52/250, Loss: 0.0076\n",
      "Epoch 81/200, Iteration 53/250, Loss: 0.0159\n",
      "Epoch 81/200, Iteration 54/250, Loss: 0.0107\n",
      "Epoch 81/200, Iteration 55/250, Loss: 0.0253\n",
      "Epoch 81/200, Iteration 56/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 57/250, Loss: 0.0068\n",
      "Epoch 81/200, Iteration 58/250, Loss: 0.0115\n",
      "Epoch 81/200, Iteration 59/250, Loss: 0.0088\n",
      "Epoch 81/200, Iteration 60/250, Loss: 0.0108\n",
      "Epoch 81/200, Iteration 61/250, Loss: 0.0118\n",
      "Epoch 81/200, Iteration 62/250, Loss: 0.0171\n",
      "Epoch 81/200, Iteration 63/250, Loss: 0.0210\n",
      "Epoch 81/200, Iteration 64/250, Loss: 0.0079\n",
      "Epoch 81/200, Iteration 65/250, Loss: 0.0203\n",
      "Epoch 81/200, Iteration 66/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 67/250, Loss: 0.0101\n",
      "Epoch 81/200, Iteration 68/250, Loss: 0.0143\n",
      "Epoch 81/200, Iteration 69/250, Loss: 0.0141\n",
      "Epoch 81/200, Iteration 70/250, Loss: 0.0311\n",
      "Epoch 81/200, Iteration 71/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 72/250, Loss: 0.0129\n",
      "Epoch 81/200, Iteration 73/250, Loss: 0.0234\n",
      "Epoch 81/200, Iteration 74/250, Loss: 0.0320\n",
      "Epoch 81/200, Iteration 75/250, Loss: 0.0117\n",
      "Epoch 81/200, Iteration 76/250, Loss: 0.0108\n",
      "Epoch 81/200, Iteration 77/250, Loss: 0.0093\n",
      "Epoch 81/200, Iteration 78/250, Loss: 0.0088\n",
      "Epoch 81/200, Iteration 79/250, Loss: 0.0168\n",
      "Epoch 81/200, Iteration 80/250, Loss: 0.0217\n",
      "Epoch 81/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 82/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 83/250, Loss: 0.0173\n",
      "Epoch 81/200, Iteration 84/250, Loss: 0.0188\n",
      "Epoch 81/200, Iteration 85/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 86/250, Loss: 0.0129\n",
      "Epoch 81/200, Iteration 87/250, Loss: 0.0150\n",
      "Epoch 81/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 81/200, Iteration 89/250, Loss: 0.0142\n",
      "Epoch 81/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 91/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 92/250, Loss: 0.0077\n",
      "Epoch 81/200, Iteration 93/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 94/250, Loss: 0.0191\n",
      "Epoch 81/200, Iteration 95/250, Loss: 0.0111\n",
      "Epoch 81/200, Iteration 96/250, Loss: 0.0279\n",
      "Epoch 81/200, Iteration 97/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 98/250, Loss: 0.0089\n",
      "Epoch 81/200, Iteration 99/250, Loss: 0.0121\n",
      "Epoch 81/200, Iteration 100/250, Loss: 0.0114\n",
      "Epoch 81/200, Iteration 101/250, Loss: 0.0204\n",
      "Epoch 81/200, Iteration 102/250, Loss: 0.0341\n",
      "Epoch 81/200, Iteration 103/250, Loss: 0.0142\n",
      "Epoch 81/200, Iteration 104/250, Loss: 0.0165\n",
      "Epoch 81/200, Iteration 105/250, Loss: 0.0114\n",
      "Epoch 81/200, Iteration 106/250, Loss: 0.0355\n",
      "Epoch 81/200, Iteration 107/250, Loss: 0.0293\n",
      "Epoch 81/200, Iteration 108/250, Loss: 0.0272\n",
      "Epoch 81/200, Iteration 109/250, Loss: 0.0067\n",
      "Epoch 81/200, Iteration 110/250, Loss: 0.0157\n",
      "Epoch 81/200, Iteration 111/250, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 112/250, Loss: 0.0112\n",
      "Epoch 81/200, Iteration 113/250, Loss: 0.0248\n",
      "Epoch 81/200, Iteration 114/250, Loss: 0.0177\n",
      "Epoch 81/200, Iteration 115/250, Loss: 0.0061\n",
      "Epoch 81/200, Iteration 116/250, Loss: 0.0197\n",
      "Epoch 81/200, Iteration 117/250, Loss: 0.0081\n",
      "Epoch 81/200, Iteration 118/250, Loss: 0.0288\n",
      "Epoch 81/200, Iteration 119/250, Loss: 0.0168\n",
      "Epoch 81/200, Iteration 120/250, Loss: 0.0096\n",
      "Epoch 81/200, Iteration 121/250, Loss: 0.0165\n",
      "Epoch 81/200, Iteration 122/250, Loss: 0.0197\n",
      "Epoch 81/200, Iteration 123/250, Loss: 0.0142\n",
      "Epoch 81/200, Iteration 124/250, Loss: 0.0119\n",
      "Epoch 81/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 126/250, Loss: 0.0234\n",
      "Epoch 81/200, Iteration 127/250, Loss: 0.0185\n",
      "Epoch 81/200, Iteration 128/250, Loss: 0.0118\n",
      "Epoch 81/200, Iteration 129/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 130/250, Loss: 0.0070\n",
      "Epoch 81/200, Iteration 131/250, Loss: 0.0085\n",
      "Epoch 81/200, Iteration 132/250, Loss: 0.0112\n",
      "Epoch 81/200, Iteration 133/250, Loss: 0.0244\n",
      "Epoch 81/200, Iteration 134/250, Loss: 0.0262\n",
      "Epoch 81/200, Iteration 135/250, Loss: 0.0078\n",
      "Epoch 81/200, Iteration 136/250, Loss: 0.0115\n",
      "Epoch 81/200, Iteration 137/250, Loss: 0.0096\n",
      "Epoch 81/200, Iteration 138/250, Loss: 0.0213\n",
      "Epoch 81/200, Iteration 139/250, Loss: 0.0082\n",
      "Epoch 81/200, Iteration 140/250, Loss: 0.0103\n",
      "Epoch 81/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 81/200, Iteration 142/250, Loss: 0.0144\n",
      "Epoch 81/200, Iteration 143/250, Loss: 0.0243\n",
      "Epoch 81/200, Iteration 144/250, Loss: 0.0129\n",
      "Epoch 81/200, Iteration 145/250, Loss: 0.0070\n",
      "Epoch 81/200, Iteration 146/250, Loss: 0.0149\n",
      "Epoch 81/200, Iteration 147/250, Loss: 0.0115\n",
      "Epoch 81/200, Iteration 148/250, Loss: 0.0242\n",
      "Epoch 81/200, Iteration 149/250, Loss: 0.0190\n",
      "Epoch 81/200, Iteration 150/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 151/250, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200, Iteration 152/250, Loss: 0.0191\n",
      "Epoch 81/200, Iteration 153/250, Loss: 0.0079\n",
      "Epoch 81/200, Iteration 154/250, Loss: 0.0081\n",
      "Epoch 81/200, Iteration 155/250, Loss: 0.0436\n",
      "Epoch 81/200, Iteration 156/250, Loss: 0.0077\n",
      "Epoch 81/200, Iteration 157/250, Loss: 0.0078\n",
      "Epoch 81/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 159/250, Loss: 0.0162\n",
      "Epoch 81/200, Iteration 160/250, Loss: 0.0204\n",
      "Epoch 81/200, Iteration 161/250, Loss: 0.0083\n",
      "Epoch 81/200, Iteration 162/250, Loss: 0.0104\n",
      "Epoch 81/200, Iteration 163/250, Loss: 0.0189\n",
      "Epoch 81/200, Iteration 164/250, Loss: 0.0241\n",
      "Epoch 81/200, Iteration 165/250, Loss: 0.0281\n",
      "Epoch 81/200, Iteration 166/250, Loss: 0.0097\n",
      "Epoch 81/200, Iteration 167/250, Loss: 0.0095\n",
      "Epoch 81/200, Iteration 168/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 169/250, Loss: 0.0253\n",
      "Epoch 81/200, Iteration 170/250, Loss: 0.0246\n",
      "Epoch 81/200, Iteration 171/250, Loss: 0.0197\n",
      "Epoch 81/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 81/200, Iteration 173/250, Loss: 0.0143\n",
      "Epoch 81/200, Iteration 174/250, Loss: 0.0309\n",
      "Epoch 81/200, Iteration 175/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 176/250, Loss: 0.0088\n",
      "Epoch 81/200, Iteration 177/250, Loss: 0.0138\n",
      "Epoch 81/200, Iteration 178/250, Loss: 0.0110\n",
      "Epoch 81/200, Iteration 179/250, Loss: 0.0181\n",
      "Epoch 81/200, Iteration 180/250, Loss: 0.0148\n",
      "Epoch 81/200, Iteration 181/250, Loss: 0.0201\n",
      "Epoch 81/200, Iteration 182/250, Loss: 0.0091\n",
      "Epoch 81/200, Iteration 183/250, Loss: 0.0264\n",
      "Epoch 81/200, Iteration 184/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 185/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 186/250, Loss: 0.0076\n",
      "Epoch 81/200, Iteration 187/250, Loss: 0.0101\n",
      "Epoch 81/200, Iteration 188/250, Loss: 0.0205\n",
      "Epoch 81/200, Iteration 189/250, Loss: 0.0155\n",
      "Epoch 81/200, Iteration 190/250, Loss: 0.0122\n",
      "Epoch 81/200, Iteration 191/250, Loss: 0.0231\n",
      "Epoch 81/200, Iteration 192/250, Loss: 0.0093\n",
      "Epoch 81/200, Iteration 193/250, Loss: 0.0250\n",
      "Epoch 81/200, Iteration 194/250, Loss: 0.0078\n",
      "Epoch 81/200, Iteration 195/250, Loss: 0.0194\n",
      "Epoch 81/200, Iteration 196/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 197/250, Loss: 0.0115\n",
      "Epoch 81/200, Iteration 198/250, Loss: 0.0150\n",
      "Epoch 81/200, Iteration 199/250, Loss: 0.0286\n",
      "Epoch 81/200, Iteration 200/250, Loss: 0.0093\n",
      "Epoch 81/200, Iteration 201/250, Loss: 0.0306\n",
      "Epoch 81/200, Iteration 202/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 203/250, Loss: 0.0154\n",
      "Epoch 81/200, Iteration 204/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 205/250, Loss: 0.0147\n",
      "Epoch 81/200, Iteration 206/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 208/250, Loss: 0.0167\n",
      "Epoch 81/200, Iteration 209/250, Loss: 0.0194\n",
      "Epoch 81/200, Iteration 210/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 211/250, Loss: 0.0342\n",
      "Epoch 81/200, Iteration 212/250, Loss: 0.0077\n",
      "Epoch 81/200, Iteration 213/250, Loss: 0.0139\n",
      "Epoch 81/200, Iteration 214/250, Loss: 0.0094\n",
      "Epoch 81/200, Iteration 215/250, Loss: 0.0179\n",
      "Epoch 81/200, Iteration 216/250, Loss: 0.0185\n",
      "Epoch 81/200, Iteration 217/250, Loss: 0.0219\n",
      "Epoch 81/200, Iteration 218/250, Loss: 0.0309\n",
      "Epoch 81/200, Iteration 219/250, Loss: 0.0140\n",
      "Epoch 81/200, Iteration 220/250, Loss: 0.0256\n",
      "Epoch 81/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 222/250, Loss: 0.0262\n",
      "Epoch 81/200, Iteration 223/250, Loss: 0.0253\n",
      "Epoch 81/200, Iteration 224/250, Loss: 0.0082\n",
      "Epoch 81/200, Iteration 225/250, Loss: 0.0146\n",
      "Epoch 81/200, Iteration 226/250, Loss: 0.0232\n",
      "Epoch 81/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 229/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 230/250, Loss: 0.0357\n",
      "Epoch 81/200, Iteration 231/250, Loss: 0.0192\n",
      "Epoch 81/200, Iteration 232/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 233/250, Loss: 0.0236\n",
      "Epoch 81/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 81/200, Iteration 235/250, Loss: 0.0120\n",
      "Epoch 81/200, Iteration 236/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 237/250, Loss: 0.0110\n",
      "Epoch 81/200, Iteration 238/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 239/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 240/250, Loss: 0.0065\n",
      "Epoch 81/200, Iteration 241/250, Loss: 0.0079\n",
      "Epoch 81/200, Iteration 242/250, Loss: 0.0143\n",
      "Epoch 81/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 244/250, Loss: 0.0281\n",
      "Epoch 81/200, Iteration 245/250, Loss: 0.0088\n",
      "Epoch 81/200, Iteration 246/250, Loss: 0.0079\n",
      "Epoch 81/200, Iteration 247/250, Loss: 0.0184\n",
      "Epoch 81/200, Iteration 248/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 249/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 250/250, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 89.05%, Avg loss: 0.006534, MRE: 0.602594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.006554, MRE: 0.891435 \n",
      "\n",
      "Epoch 82/200, Iteration 1/250, Loss: 0.0069\n",
      "Epoch 82/200, Iteration 2/250, Loss: 0.0129\n",
      "Epoch 82/200, Iteration 3/250, Loss: 0.0160\n",
      "Epoch 82/200, Iteration 4/250, Loss: 0.0267\n",
      "Epoch 82/200, Iteration 5/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 6/250, Loss: 0.0182\n",
      "Epoch 82/200, Iteration 7/250, Loss: 0.0282\n",
      "Epoch 82/200, Iteration 8/250, Loss: 0.0091\n",
      "Epoch 82/200, Iteration 9/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 10/250, Loss: 0.0157\n",
      "Epoch 82/200, Iteration 11/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 12/250, Loss: 0.0327\n",
      "Epoch 82/200, Iteration 13/250, Loss: 0.0110\n",
      "Epoch 82/200, Iteration 14/250, Loss: 0.0090\n",
      "Epoch 82/200, Iteration 15/250, Loss: 0.0220\n",
      "Epoch 82/200, Iteration 16/250, Loss: 0.0173\n",
      "Epoch 82/200, Iteration 17/250, Loss: 0.0207\n",
      "Epoch 82/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 82/200, Iteration 19/250, Loss: 0.0107\n",
      "Epoch 82/200, Iteration 20/250, Loss: 0.0115\n",
      "Epoch 82/200, Iteration 21/250, Loss: 0.0369\n",
      "Epoch 82/200, Iteration 22/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 23/250, Loss: 0.0086\n",
      "Epoch 82/200, Iteration 24/250, Loss: 0.0121\n",
      "Epoch 82/200, Iteration 25/250, Loss: 0.0257\n",
      "Epoch 82/200, Iteration 26/250, Loss: 0.0239\n",
      "Epoch 82/200, Iteration 27/250, Loss: 0.0272\n",
      "Epoch 82/200, Iteration 28/250, Loss: 0.0117\n",
      "Epoch 82/200, Iteration 29/250, Loss: 0.0208\n",
      "Epoch 82/200, Iteration 30/250, Loss: 0.0125\n",
      "Epoch 82/200, Iteration 31/250, Loss: 0.0322\n",
      "Epoch 82/200, Iteration 32/250, Loss: 0.0102\n",
      "Epoch 82/200, Iteration 33/250, Loss: 0.0096\n",
      "Epoch 82/200, Iteration 34/250, Loss: 0.0065\n",
      "Epoch 82/200, Iteration 35/250, Loss: 0.0238\n",
      "Epoch 82/200, Iteration 36/250, Loss: 0.0189\n",
      "Epoch 82/200, Iteration 37/250, Loss: 0.0156\n",
      "Epoch 82/200, Iteration 38/250, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 39/250, Loss: 0.0197\n",
      "Epoch 82/200, Iteration 40/250, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 41/250, Loss: 0.0104\n",
      "Epoch 82/200, Iteration 42/250, Loss: 0.0212\n",
      "Epoch 82/200, Iteration 43/250, Loss: 0.0097\n",
      "Epoch 82/200, Iteration 44/250, Loss: 0.0170\n",
      "Epoch 82/200, Iteration 45/250, Loss: 0.0184\n",
      "Epoch 82/200, Iteration 46/250, Loss: 0.0335\n",
      "Epoch 82/200, Iteration 47/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 48/250, Loss: 0.0099\n",
      "Epoch 82/200, Iteration 49/250, Loss: 0.0075\n",
      "Epoch 82/200, Iteration 50/250, Loss: 0.0084\n",
      "Epoch 82/200, Iteration 51/250, Loss: 0.0255\n",
      "Epoch 82/200, Iteration 52/250, Loss: 0.0093\n",
      "Epoch 82/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 82/200, Iteration 54/250, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 55/250, Loss: 0.0175\n",
      "Epoch 82/200, Iteration 56/250, Loss: 0.0230\n",
      "Epoch 82/200, Iteration 57/250, Loss: 0.0223\n",
      "Epoch 82/200, Iteration 58/250, Loss: 0.0142\n",
      "Epoch 82/200, Iteration 59/250, Loss: 0.0125\n",
      "Epoch 82/200, Iteration 60/250, Loss: 0.0117\n",
      "Epoch 82/200, Iteration 61/250, Loss: 0.0114\n",
      "Epoch 82/200, Iteration 62/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 63/250, Loss: 0.0146\n",
      "Epoch 82/200, Iteration 64/250, Loss: 0.0146\n",
      "Epoch 82/200, Iteration 65/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 66/250, Loss: 0.0152\n",
      "Epoch 82/200, Iteration 67/250, Loss: 0.0176\n",
      "Epoch 82/200, Iteration 68/250, Loss: 0.0148\n",
      "Epoch 82/200, Iteration 69/250, Loss: 0.0089\n",
      "Epoch 82/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 82/200, Iteration 71/250, Loss: 0.0280\n",
      "Epoch 82/200, Iteration 72/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 73/250, Loss: 0.0119\n",
      "Epoch 82/200, Iteration 74/250, Loss: 0.0091\n",
      "Epoch 82/200, Iteration 75/250, Loss: 0.0090\n",
      "Epoch 82/200, Iteration 76/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 77/250, Loss: 0.0086\n",
      "Epoch 82/200, Iteration 78/250, Loss: 0.0173\n",
      "Epoch 82/200, Iteration 79/250, Loss: 0.0157\n",
      "Epoch 82/200, Iteration 80/250, Loss: 0.0076\n",
      "Epoch 82/200, Iteration 81/250, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 82/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 83/250, Loss: 0.0092\n",
      "Epoch 82/200, Iteration 84/250, Loss: 0.0076\n",
      "Epoch 82/200, Iteration 85/250, Loss: 0.0322\n",
      "Epoch 82/200, Iteration 86/250, Loss: 0.0194\n",
      "Epoch 82/200, Iteration 87/250, Loss: 0.0331\n",
      "Epoch 82/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 82/200, Iteration 89/250, Loss: 0.0088\n",
      "Epoch 82/200, Iteration 90/250, Loss: 0.0141\n",
      "Epoch 82/200, Iteration 91/250, Loss: 0.0131\n",
      "Epoch 82/200, Iteration 92/250, Loss: 0.0148\n",
      "Epoch 82/200, Iteration 93/250, Loss: 0.0224\n",
      "Epoch 82/200, Iteration 94/250, Loss: 0.0130\n",
      "Epoch 82/200, Iteration 95/250, Loss: 0.0172\n",
      "Epoch 82/200, Iteration 96/250, Loss: 0.0220\n",
      "Epoch 82/200, Iteration 97/250, Loss: 0.0102\n",
      "Epoch 82/200, Iteration 98/250, Loss: 0.0230\n",
      "Epoch 82/200, Iteration 99/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 100/250, Loss: 0.0066\n",
      "Epoch 82/200, Iteration 101/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 102/250, Loss: 0.0200\n",
      "Epoch 82/200, Iteration 103/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 104/250, Loss: 0.0337\n",
      "Epoch 82/200, Iteration 105/250, Loss: 0.0107\n",
      "Epoch 82/200, Iteration 106/250, Loss: 0.0221\n",
      "Epoch 82/200, Iteration 107/250, Loss: 0.0056\n",
      "Epoch 82/200, Iteration 108/250, Loss: 0.0180\n",
      "Epoch 82/200, Iteration 109/250, Loss: 0.0193\n",
      "Epoch 82/200, Iteration 110/250, Loss: 0.0161\n",
      "Epoch 82/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 82/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 113/250, Loss: 0.0160\n",
      "Epoch 82/200, Iteration 114/250, Loss: 0.0202\n",
      "Epoch 82/200, Iteration 115/250, Loss: 0.0220\n",
      "Epoch 82/200, Iteration 116/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 82/200, Iteration 118/250, Loss: 0.0112\n",
      "Epoch 82/200, Iteration 119/250, Loss: 0.0107\n",
      "Epoch 82/200, Iteration 120/250, Loss: 0.0158\n",
      "Epoch 82/200, Iteration 121/250, Loss: 0.0110\n",
      "Epoch 82/200, Iteration 122/250, Loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200, Iteration 123/250, Loss: 0.0264\n",
      "Epoch 82/200, Iteration 124/250, Loss: 0.0227\n",
      "Epoch 82/200, Iteration 125/250, Loss: 0.0156\n",
      "Epoch 82/200, Iteration 126/250, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 127/250, Loss: 0.0085\n",
      "Epoch 82/200, Iteration 128/250, Loss: 0.0154\n",
      "Epoch 82/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 82/200, Iteration 130/250, Loss: 0.0086\n",
      "Epoch 82/200, Iteration 131/250, Loss: 0.0140\n",
      "Epoch 82/200, Iteration 132/250, Loss: 0.0173\n",
      "Epoch 82/200, Iteration 133/250, Loss: 0.0263\n",
      "Epoch 82/200, Iteration 134/250, Loss: 0.0084\n",
      "Epoch 82/200, Iteration 135/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 136/250, Loss: 0.0197\n",
      "Epoch 82/200, Iteration 137/250, Loss: 0.0208\n",
      "Epoch 82/200, Iteration 138/250, Loss: 0.0200\n",
      "Epoch 82/200, Iteration 139/250, Loss: 0.0077\n",
      "Epoch 82/200, Iteration 140/250, Loss: 0.0104\n",
      "Epoch 82/200, Iteration 141/250, Loss: 0.0193\n",
      "Epoch 82/200, Iteration 142/250, Loss: 0.0181\n",
      "Epoch 82/200, Iteration 143/250, Loss: 0.0098\n",
      "Epoch 82/200, Iteration 144/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 145/250, Loss: 0.0185\n",
      "Epoch 82/200, Iteration 146/250, Loss: 0.0066\n",
      "Epoch 82/200, Iteration 147/250, Loss: 0.0283\n",
      "Epoch 82/200, Iteration 148/250, Loss: 0.0232\n",
      "Epoch 82/200, Iteration 149/250, Loss: 0.0107\n",
      "Epoch 82/200, Iteration 150/250, Loss: 0.0164\n",
      "Epoch 82/200, Iteration 151/250, Loss: 0.0059\n",
      "Epoch 82/200, Iteration 152/250, Loss: 0.0165\n",
      "Epoch 82/200, Iteration 153/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 154/250, Loss: 0.0114\n",
      "Epoch 82/200, Iteration 155/250, Loss: 0.0127\n",
      "Epoch 82/200, Iteration 156/250, Loss: 0.0344\n",
      "Epoch 82/200, Iteration 157/250, Loss: 0.0271\n",
      "Epoch 82/200, Iteration 158/250, Loss: 0.0115\n",
      "Epoch 82/200, Iteration 159/250, Loss: 0.0264\n",
      "Epoch 82/200, Iteration 160/250, Loss: 0.0239\n",
      "Epoch 82/200, Iteration 161/250, Loss: 0.0230\n",
      "Epoch 82/200, Iteration 162/250, Loss: 0.0213\n",
      "Epoch 82/200, Iteration 163/250, Loss: 0.0075\n",
      "Epoch 82/200, Iteration 164/250, Loss: 0.0138\n",
      "Epoch 82/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 82/200, Iteration 166/250, Loss: 0.0119\n",
      "Epoch 82/200, Iteration 167/250, Loss: 0.0138\n",
      "Epoch 82/200, Iteration 168/250, Loss: 0.0121\n",
      "Epoch 82/200, Iteration 169/250, Loss: 0.0098\n",
      "Epoch 82/200, Iteration 170/250, Loss: 0.0240\n",
      "Epoch 82/200, Iteration 171/250, Loss: 0.0174\n",
      "Epoch 82/200, Iteration 172/250, Loss: 0.0060\n",
      "Epoch 82/200, Iteration 173/250, Loss: 0.0111\n",
      "Epoch 82/200, Iteration 174/250, Loss: 0.0125\n",
      "Epoch 82/200, Iteration 175/250, Loss: 0.0096\n",
      "Epoch 82/200, Iteration 176/250, Loss: 0.0294\n",
      "Epoch 82/200, Iteration 177/250, Loss: 0.0111\n",
      "Epoch 82/200, Iteration 178/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 179/250, Loss: 0.0111\n",
      "Epoch 82/200, Iteration 180/250, Loss: 0.0173\n",
      "Epoch 82/200, Iteration 181/250, Loss: 0.0190\n",
      "Epoch 82/200, Iteration 182/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 183/250, Loss: 0.0151\n",
      "Epoch 82/200, Iteration 184/250, Loss: 0.0092\n",
      "Epoch 82/200, Iteration 185/250, Loss: 0.0188\n",
      "Epoch 82/200, Iteration 186/250, Loss: 0.0169\n",
      "Epoch 82/200, Iteration 187/250, Loss: 0.0126\n",
      "Epoch 82/200, Iteration 188/250, Loss: 0.0172\n",
      "Epoch 82/200, Iteration 189/250, Loss: 0.0193\n",
      "Epoch 82/200, Iteration 190/250, Loss: 0.0160\n",
      "Epoch 82/200, Iteration 191/250, Loss: 0.0189\n",
      "Epoch 82/200, Iteration 192/250, Loss: 0.0195\n",
      "Epoch 82/200, Iteration 193/250, Loss: 0.0406\n",
      "Epoch 82/200, Iteration 194/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 195/250, Loss: 0.0246\n",
      "Epoch 82/200, Iteration 196/250, Loss: 0.0086\n",
      "Epoch 82/200, Iteration 197/250, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 198/250, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 199/250, Loss: 0.0180\n",
      "Epoch 82/200, Iteration 200/250, Loss: 0.0092\n",
      "Epoch 82/200, Iteration 201/250, Loss: 0.0132\n",
      "Epoch 82/200, Iteration 202/250, Loss: 0.0174\n",
      "Epoch 82/200, Iteration 203/250, Loss: 0.0067\n",
      "Epoch 82/200, Iteration 204/250, Loss: 0.0152\n",
      "Epoch 82/200, Iteration 205/250, Loss: 0.0121\n",
      "Epoch 82/200, Iteration 206/250, Loss: 0.0140\n",
      "Epoch 82/200, Iteration 207/250, Loss: 0.0300\n",
      "Epoch 82/200, Iteration 208/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 209/250, Loss: 0.0227\n",
      "Epoch 82/200, Iteration 210/250, Loss: 0.0147\n",
      "Epoch 82/200, Iteration 211/250, Loss: 0.0133\n",
      "Epoch 82/200, Iteration 212/250, Loss: 0.0232\n",
      "Epoch 82/200, Iteration 213/250, Loss: 0.0077\n",
      "Epoch 82/200, Iteration 214/250, Loss: 0.0085\n",
      "Epoch 82/200, Iteration 215/250, Loss: 0.0150\n",
      "Epoch 82/200, Iteration 216/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 217/250, Loss: 0.0381\n",
      "Epoch 82/200, Iteration 218/250, Loss: 0.0141\n",
      "Epoch 82/200, Iteration 219/250, Loss: 0.0321\n",
      "Epoch 82/200, Iteration 220/250, Loss: 0.0262\n",
      "Epoch 82/200, Iteration 221/250, Loss: 0.0213\n",
      "Epoch 82/200, Iteration 222/250, Loss: 0.0074\n",
      "Epoch 82/200, Iteration 223/250, Loss: 0.0294\n",
      "Epoch 82/200, Iteration 224/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 225/250, Loss: 0.0190\n",
      "Epoch 82/200, Iteration 226/250, Loss: 0.0223\n",
      "Epoch 82/200, Iteration 227/250, Loss: 0.0219\n",
      "Epoch 82/200, Iteration 228/250, Loss: 0.0152\n",
      "Epoch 82/200, Iteration 229/250, Loss: 0.0381\n",
      "Epoch 82/200, Iteration 230/250, Loss: 0.0143\n",
      "Epoch 82/200, Iteration 231/250, Loss: 0.0067\n",
      "Epoch 82/200, Iteration 232/250, Loss: 0.0278\n",
      "Epoch 82/200, Iteration 233/250, Loss: 0.0181\n",
      "Epoch 82/200, Iteration 234/250, Loss: 0.0173\n",
      "Epoch 82/200, Iteration 235/250, Loss: 0.0135\n",
      "Epoch 82/200, Iteration 236/250, Loss: 0.0092\n",
      "Epoch 82/200, Iteration 237/250, Loss: 0.0078\n",
      "Epoch 82/200, Iteration 238/250, Loss: 0.0080\n",
      "Epoch 82/200, Iteration 239/250, Loss: 0.0196\n",
      "Epoch 82/200, Iteration 240/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 241/250, Loss: 0.0144\n",
      "Epoch 82/200, Iteration 242/250, Loss: 0.0105\n",
      "Epoch 82/200, Iteration 243/250, Loss: 0.0190\n",
      "Epoch 82/200, Iteration 244/250, Loss: 0.0175\n",
      "Epoch 82/200, Iteration 245/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 246/250, Loss: 0.0224\n",
      "Epoch 82/200, Iteration 247/250, Loss: 0.0054\n",
      "Epoch 82/200, Iteration 248/250, Loss: 0.0071\n",
      "Epoch 82/200, Iteration 249/250, Loss: 0.0112\n",
      "Epoch 82/200, Iteration 250/250, Loss: 0.0065\n",
      "Train Error: \n",
      " Accuracy: 93.67%, Avg loss: 0.006279, MRE: 0.598698 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.006287, MRE: 1.040464 \n",
      "\n",
      "Epoch 83/200, Iteration 1/250, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 2/250, Loss: 0.0161\n",
      "Epoch 83/200, Iteration 3/250, Loss: 0.0095\n",
      "Epoch 83/200, Iteration 4/250, Loss: 0.0273\n",
      "Epoch 83/200, Iteration 5/250, Loss: 0.0088\n",
      "Epoch 83/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 83/200, Iteration 7/250, Loss: 0.0139\n",
      "Epoch 83/200, Iteration 8/250, Loss: 0.0174\n",
      "Epoch 83/200, Iteration 9/250, Loss: 0.0103\n",
      "Epoch 83/200, Iteration 10/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 11/250, Loss: 0.0170\n",
      "Epoch 83/200, Iteration 12/250, Loss: 0.0114\n",
      "Epoch 83/200, Iteration 13/250, Loss: 0.0154\n",
      "Epoch 83/200, Iteration 14/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 15/250, Loss: 0.0063\n",
      "Epoch 83/200, Iteration 16/250, Loss: 0.0071\n",
      "Epoch 83/200, Iteration 17/250, Loss: 0.0166\n",
      "Epoch 83/200, Iteration 18/250, Loss: 0.0119\n",
      "Epoch 83/200, Iteration 19/250, Loss: 0.0185\n",
      "Epoch 83/200, Iteration 20/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 21/250, Loss: 0.0406\n",
      "Epoch 83/200, Iteration 22/250, Loss: 0.0074\n",
      "Epoch 83/200, Iteration 23/250, Loss: 0.0164\n",
      "Epoch 83/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 25/250, Loss: 0.0240\n",
      "Epoch 83/200, Iteration 26/250, Loss: 0.0075\n",
      "Epoch 83/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 83/200, Iteration 28/250, Loss: 0.0110\n",
      "Epoch 83/200, Iteration 29/250, Loss: 0.0203\n",
      "Epoch 83/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 31/250, Loss: 0.0146\n",
      "Epoch 83/200, Iteration 32/250, Loss: 0.0116\n",
      "Epoch 83/200, Iteration 33/250, Loss: 0.0135\n",
      "Epoch 83/200, Iteration 34/250, Loss: 0.0185\n",
      "Epoch 83/200, Iteration 35/250, Loss: 0.0185\n",
      "Epoch 83/200, Iteration 36/250, Loss: 0.0173\n",
      "Epoch 83/200, Iteration 37/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 38/250, Loss: 0.0168\n",
      "Epoch 83/200, Iteration 39/250, Loss: 0.0163\n",
      "Epoch 83/200, Iteration 40/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 41/250, Loss: 0.0237\n",
      "Epoch 83/200, Iteration 42/250, Loss: 0.0198\n",
      "Epoch 83/200, Iteration 43/250, Loss: 0.0067\n",
      "Epoch 83/200, Iteration 44/250, Loss: 0.0209\n",
      "Epoch 83/200, Iteration 45/250, Loss: 0.0073\n",
      "Epoch 83/200, Iteration 46/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 47/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 83/200, Iteration 49/250, Loss: 0.0300\n",
      "Epoch 83/200, Iteration 50/250, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 83/200, Iteration 52/250, Loss: 0.0079\n",
      "Epoch 83/200, Iteration 53/250, Loss: 0.0238\n",
      "Epoch 83/200, Iteration 54/250, Loss: 0.0187\n",
      "Epoch 83/200, Iteration 55/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 56/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 57/250, Loss: 0.0174\n",
      "Epoch 83/200, Iteration 58/250, Loss: 0.0111\n",
      "Epoch 83/200, Iteration 59/250, Loss: 0.0316\n",
      "Epoch 83/200, Iteration 60/250, Loss: 0.0227\n",
      "Epoch 83/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 83/200, Iteration 62/250, Loss: 0.0141\n",
      "Epoch 83/200, Iteration 63/250, Loss: 0.0074\n",
      "Epoch 83/200, Iteration 64/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 65/250, Loss: 0.0163\n",
      "Epoch 83/200, Iteration 66/250, Loss: 0.0218\n",
      "Epoch 83/200, Iteration 67/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 68/250, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 69/250, Loss: 0.0078\n",
      "Epoch 83/200, Iteration 70/250, Loss: 0.0146\n",
      "Epoch 83/200, Iteration 71/250, Loss: 0.0296\n",
      "Epoch 83/200, Iteration 72/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 73/250, Loss: 0.0067\n",
      "Epoch 83/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 83/200, Iteration 75/250, Loss: 0.0077\n",
      "Epoch 83/200, Iteration 76/250, Loss: 0.0115\n",
      "Epoch 83/200, Iteration 77/250, Loss: 0.0128\n",
      "Epoch 83/200, Iteration 78/250, Loss: 0.0188\n",
      "Epoch 83/200, Iteration 79/250, Loss: 0.0107\n",
      "Epoch 83/200, Iteration 80/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 81/250, Loss: 0.0189\n",
      "Epoch 83/200, Iteration 82/250, Loss: 0.0074\n",
      "Epoch 83/200, Iteration 83/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 84/250, Loss: 0.0285\n",
      "Epoch 83/200, Iteration 85/250, Loss: 0.0075\n",
      "Epoch 83/200, Iteration 86/250, Loss: 0.0254\n",
      "Epoch 83/200, Iteration 87/250, Loss: 0.0188\n",
      "Epoch 83/200, Iteration 88/250, Loss: 0.0192\n",
      "Epoch 83/200, Iteration 89/250, Loss: 0.0210\n",
      "Epoch 83/200, Iteration 90/250, Loss: 0.0078\n",
      "Epoch 83/200, Iteration 91/250, Loss: 0.0169\n",
      "Epoch 83/200, Iteration 92/250, Loss: 0.0149\n",
      "Epoch 83/200, Iteration 93/250, Loss: 0.0158\n",
      "Epoch 83/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 95/250, Loss: 0.0120\n",
      "Epoch 83/200, Iteration 96/250, Loss: 0.0221\n",
      "Epoch 83/200, Iteration 97/250, Loss: 0.0098\n",
      "Epoch 83/200, Iteration 98/250, Loss: 0.0172\n",
      "Epoch 83/200, Iteration 99/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 100/250, Loss: 0.0160\n",
      "Epoch 83/200, Iteration 101/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 83/200, Iteration 103/250, Loss: 0.0143\n",
      "Epoch 83/200, Iteration 104/250, Loss: 0.0178\n",
      "Epoch 83/200, Iteration 105/250, Loss: 0.0213\n",
      "Epoch 83/200, Iteration 106/250, Loss: 0.0097\n",
      "Epoch 83/200, Iteration 107/250, Loss: 0.0061\n",
      "Epoch 83/200, Iteration 108/250, Loss: 0.0093\n",
      "Epoch 83/200, Iteration 109/250, Loss: 0.0108\n",
      "Epoch 83/200, Iteration 110/250, Loss: 0.0144\n",
      "Epoch 83/200, Iteration 111/250, Loss: 0.0098\n",
      "Epoch 83/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 83/200, Iteration 113/250, Loss: 0.0238\n",
      "Epoch 83/200, Iteration 114/250, Loss: 0.0151\n",
      "Epoch 83/200, Iteration 115/250, Loss: 0.0235\n",
      "Epoch 83/200, Iteration 116/250, Loss: 0.0185\n",
      "Epoch 83/200, Iteration 117/250, Loss: 0.0094\n",
      "Epoch 83/200, Iteration 118/250, Loss: 0.0146\n",
      "Epoch 83/200, Iteration 119/250, Loss: 0.0115\n",
      "Epoch 83/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 121/250, Loss: 0.0128\n",
      "Epoch 83/200, Iteration 122/250, Loss: 0.0073\n",
      "Epoch 83/200, Iteration 123/250, Loss: 0.0120\n",
      "Epoch 83/200, Iteration 124/250, Loss: 0.0119\n",
      "Epoch 83/200, Iteration 125/250, Loss: 0.0110\n",
      "Epoch 83/200, Iteration 126/250, Loss: 0.0304\n",
      "Epoch 83/200, Iteration 127/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 83/200, Iteration 129/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 130/250, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 131/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 132/250, Loss: 0.0093\n",
      "Epoch 83/200, Iteration 133/250, Loss: 0.0129\n",
      "Epoch 83/200, Iteration 134/250, Loss: 0.0169\n",
      "Epoch 83/200, Iteration 135/250, Loss: 0.0158\n",
      "Epoch 83/200, Iteration 136/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 137/250, Loss: 0.0075\n",
      "Epoch 83/200, Iteration 138/250, Loss: 0.0105\n",
      "Epoch 83/200, Iteration 139/250, Loss: 0.0133\n",
      "Epoch 83/200, Iteration 140/250, Loss: 0.0255\n",
      "Epoch 83/200, Iteration 141/250, Loss: 0.0153\n",
      "Epoch 83/200, Iteration 142/250, Loss: 0.0147\n",
      "Epoch 83/200, Iteration 143/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 145/250, Loss: 0.0321\n",
      "Epoch 83/200, Iteration 146/250, Loss: 0.0138\n",
      "Epoch 83/200, Iteration 147/250, Loss: 0.0147\n",
      "Epoch 83/200, Iteration 148/250, Loss: 0.0263\n",
      "Epoch 83/200, Iteration 149/250, Loss: 0.0108\n",
      "Epoch 83/200, Iteration 150/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 151/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 152/250, Loss: 0.0128\n",
      "Epoch 83/200, Iteration 153/250, Loss: 0.0081\n",
      "Epoch 83/200, Iteration 154/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 155/250, Loss: 0.0153\n",
      "Epoch 83/200, Iteration 156/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 157/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 158/250, Loss: 0.0107\n",
      "Epoch 83/200, Iteration 159/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 160/250, Loss: 0.0123\n",
      "Epoch 83/200, Iteration 161/250, Loss: 0.0134\n",
      "Epoch 83/200, Iteration 162/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 163/250, Loss: 0.0151\n",
      "Epoch 83/200, Iteration 164/250, Loss: 0.0225\n",
      "Epoch 83/200, Iteration 165/250, Loss: 0.0145\n",
      "Epoch 83/200, Iteration 166/250, Loss: 0.0214\n",
      "Epoch 83/200, Iteration 167/250, Loss: 0.0109\n",
      "Epoch 83/200, Iteration 168/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 169/250, Loss: 0.0081\n",
      "Epoch 83/200, Iteration 170/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 171/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 172/250, Loss: 0.0162\n",
      "Epoch 83/200, Iteration 173/250, Loss: 0.0170\n",
      "Epoch 83/200, Iteration 174/250, Loss: 0.0255\n",
      "Epoch 83/200, Iteration 175/250, Loss: 0.0117\n",
      "Epoch 83/200, Iteration 176/250, Loss: 0.0307\n",
      "Epoch 83/200, Iteration 177/250, Loss: 0.0153\n",
      "Epoch 83/200, Iteration 178/250, Loss: 0.0112\n",
      "Epoch 83/200, Iteration 179/250, Loss: 0.0180\n",
      "Epoch 83/200, Iteration 180/250, Loss: 0.0228\n",
      "Epoch 83/200, Iteration 181/250, Loss: 0.0158\n",
      "Epoch 83/200, Iteration 182/250, Loss: 0.0260\n",
      "Epoch 83/200, Iteration 183/250, Loss: 0.0181\n",
      "Epoch 83/200, Iteration 184/250, Loss: 0.0108\n",
      "Epoch 83/200, Iteration 185/250, Loss: 0.0097\n",
      "Epoch 83/200, Iteration 186/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 188/250, Loss: 0.0191\n",
      "Epoch 83/200, Iteration 189/250, Loss: 0.0136\n",
      "Epoch 83/200, Iteration 190/250, Loss: 0.0129\n",
      "Epoch 83/200, Iteration 191/250, Loss: 0.0135\n",
      "Epoch 83/200, Iteration 192/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 193/250, Loss: 0.0055\n",
      "Epoch 83/200, Iteration 194/250, Loss: 0.0123\n",
      "Epoch 83/200, Iteration 195/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 196/250, Loss: 0.0081\n",
      "Epoch 83/200, Iteration 197/250, Loss: 0.0241\n",
      "Epoch 83/200, Iteration 198/250, Loss: 0.0213\n",
      "Epoch 83/200, Iteration 199/250, Loss: 0.0212\n",
      "Epoch 83/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 83/200, Iteration 201/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 202/250, Loss: 0.0129\n",
      "Epoch 83/200, Iteration 203/250, Loss: 0.0121\n",
      "Epoch 83/200, Iteration 204/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 205/250, Loss: 0.0221\n",
      "Epoch 83/200, Iteration 206/250, Loss: 0.0237\n",
      "Epoch 83/200, Iteration 207/250, Loss: 0.0088\n",
      "Epoch 83/200, Iteration 208/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 209/250, Loss: 0.0077\n",
      "Epoch 83/200, Iteration 210/250, Loss: 0.0202\n",
      "Epoch 83/200, Iteration 211/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 212/250, Loss: 0.0133\n",
      "Epoch 83/200, Iteration 213/250, Loss: 0.0104\n",
      "Epoch 83/200, Iteration 214/250, Loss: 0.0181\n",
      "Epoch 83/200, Iteration 215/250, Loss: 0.0181\n",
      "Epoch 83/200, Iteration 216/250, Loss: 0.0192\n",
      "Epoch 83/200, Iteration 217/250, Loss: 0.0269\n",
      "Epoch 83/200, Iteration 218/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 219/250, Loss: 0.0096\n",
      "Epoch 83/200, Iteration 220/250, Loss: 0.0367\n",
      "Epoch 83/200, Iteration 221/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 222/250, Loss: 0.0135\n",
      "Epoch 83/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 224/250, Loss: 0.0095\n",
      "Epoch 83/200, Iteration 225/250, Loss: 0.0162\n",
      "Epoch 83/200, Iteration 226/250, Loss: 0.0216\n",
      "Epoch 83/200, Iteration 227/250, Loss: 0.0215\n",
      "Epoch 83/200, Iteration 228/250, Loss: 0.0285\n",
      "Epoch 83/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 230/250, Loss: 0.0160\n",
      "Epoch 83/200, Iteration 231/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 232/250, Loss: 0.0105\n",
      "Epoch 83/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 83/200, Iteration 234/250, Loss: 0.0125\n",
      "Epoch 83/200, Iteration 235/250, Loss: 0.0170\n",
      "Epoch 83/200, Iteration 236/250, Loss: 0.0178\n",
      "Epoch 83/200, Iteration 237/250, Loss: 0.0104\n",
      "Epoch 83/200, Iteration 238/250, Loss: 0.0234\n",
      "Epoch 83/200, Iteration 239/250, Loss: 0.0069\n",
      "Epoch 83/200, Iteration 240/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 241/250, Loss: 0.0289\n",
      "Epoch 83/200, Iteration 242/250, Loss: 0.0171\n",
      "Epoch 83/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 83/200, Iteration 244/250, Loss: 0.0207\n",
      "Epoch 83/200, Iteration 245/250, Loss: 0.0070\n",
      "Epoch 83/200, Iteration 246/250, Loss: 0.0131\n",
      "Epoch 83/200, Iteration 247/250, Loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Iteration 248/250, Loss: 0.0197\n",
      "Epoch 83/200, Iteration 249/250, Loss: 0.0168\n",
      "Epoch 83/200, Iteration 250/250, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 89.11%, Avg loss: 0.006734, MRE: 0.637640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.006770, MRE: 1.014504 \n",
      "\n",
      "Epoch 84/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 84/200, Iteration 2/250, Loss: 0.0063\n",
      "Epoch 84/200, Iteration 3/250, Loss: 0.0082\n",
      "Epoch 84/200, Iteration 4/250, Loss: 0.0180\n",
      "Epoch 84/200, Iteration 5/250, Loss: 0.0177\n",
      "Epoch 84/200, Iteration 6/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 7/250, Loss: 0.0268\n",
      "Epoch 84/200, Iteration 8/250, Loss: 0.0192\n",
      "Epoch 84/200, Iteration 9/250, Loss: 0.0220\n",
      "Epoch 84/200, Iteration 10/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 11/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 12/250, Loss: 0.0281\n",
      "Epoch 84/200, Iteration 13/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 14/250, Loss: 0.0141\n",
      "Epoch 84/200, Iteration 15/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 16/250, Loss: 0.0080\n",
      "Epoch 84/200, Iteration 17/250, Loss: 0.0175\n",
      "Epoch 84/200, Iteration 18/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 19/250, Loss: 0.0376\n",
      "Epoch 84/200, Iteration 20/250, Loss: 0.0092\n",
      "Epoch 84/200, Iteration 21/250, Loss: 0.0092\n",
      "Epoch 84/200, Iteration 22/250, Loss: 0.0133\n",
      "Epoch 84/200, Iteration 23/250, Loss: 0.0298\n",
      "Epoch 84/200, Iteration 24/250, Loss: 0.0148\n",
      "Epoch 84/200, Iteration 25/250, Loss: 0.0075\n",
      "Epoch 84/200, Iteration 26/250, Loss: 0.0075\n",
      "Epoch 84/200, Iteration 27/250, Loss: 0.0095\n",
      "Epoch 84/200, Iteration 28/250, Loss: 0.0187\n",
      "Epoch 84/200, Iteration 29/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 30/250, Loss: 0.0062\n",
      "Epoch 84/200, Iteration 31/250, Loss: 0.0358\n",
      "Epoch 84/200, Iteration 32/250, Loss: 0.0326\n",
      "Epoch 84/200, Iteration 33/250, Loss: 0.0161\n",
      "Epoch 84/200, Iteration 34/250, Loss: 0.0178\n",
      "Epoch 84/200, Iteration 35/250, Loss: 0.0214\n",
      "Epoch 84/200, Iteration 36/250, Loss: 0.0132\n",
      "Epoch 84/200, Iteration 37/250, Loss: 0.0223\n",
      "Epoch 84/200, Iteration 38/250, Loss: 0.0152\n",
      "Epoch 84/200, Iteration 39/250, Loss: 0.0071\n",
      "Epoch 84/200, Iteration 40/250, Loss: 0.0198\n",
      "Epoch 84/200, Iteration 41/250, Loss: 0.0262\n",
      "Epoch 84/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 84/200, Iteration 43/250, Loss: 0.0231\n",
      "Epoch 84/200, Iteration 44/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 45/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 46/250, Loss: 0.0194\n",
      "Epoch 84/200, Iteration 47/250, Loss: 0.0145\n",
      "Epoch 84/200, Iteration 48/250, Loss: 0.0074\n",
      "Epoch 84/200, Iteration 49/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 50/250, Loss: 0.0167\n",
      "Epoch 84/200, Iteration 51/250, Loss: 0.0083\n",
      "Epoch 84/200, Iteration 52/250, Loss: 0.0195\n",
      "Epoch 84/200, Iteration 53/250, Loss: 0.0128\n",
      "Epoch 84/200, Iteration 54/250, Loss: 0.0129\n",
      "Epoch 84/200, Iteration 55/250, Loss: 0.0312\n",
      "Epoch 84/200, Iteration 56/250, Loss: 0.0078\n",
      "Epoch 84/200, Iteration 57/250, Loss: 0.0091\n",
      "Epoch 84/200, Iteration 58/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 59/250, Loss: 0.0073\n",
      "Epoch 84/200, Iteration 60/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 61/250, Loss: 0.0102\n",
      "Epoch 84/200, Iteration 62/250, Loss: 0.0107\n",
      "Epoch 84/200, Iteration 63/250, Loss: 0.0162\n",
      "Epoch 84/200, Iteration 64/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 65/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 66/250, Loss: 0.0170\n",
      "Epoch 84/200, Iteration 67/250, Loss: 0.0363\n",
      "Epoch 84/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 69/250, Loss: 0.0139\n",
      "Epoch 84/200, Iteration 70/250, Loss: 0.0360\n",
      "Epoch 84/200, Iteration 71/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 72/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 73/250, Loss: 0.0183\n",
      "Epoch 84/200, Iteration 74/250, Loss: 0.0108\n",
      "Epoch 84/200, Iteration 75/250, Loss: 0.0156\n",
      "Epoch 84/200, Iteration 76/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 77/250, Loss: 0.0300\n",
      "Epoch 84/200, Iteration 78/250, Loss: 0.0141\n",
      "Epoch 84/200, Iteration 79/250, Loss: 0.0089\n",
      "Epoch 84/200, Iteration 80/250, Loss: 0.0143\n",
      "Epoch 84/200, Iteration 81/250, Loss: 0.0198\n",
      "Epoch 84/200, Iteration 82/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 83/250, Loss: 0.0091\n",
      "Epoch 84/200, Iteration 84/250, Loss: 0.0131\n",
      "Epoch 84/200, Iteration 85/250, Loss: 0.0153\n",
      "Epoch 84/200, Iteration 86/250, Loss: 0.0352\n",
      "Epoch 84/200, Iteration 87/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 88/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 89/250, Loss: 0.0393\n",
      "Epoch 84/200, Iteration 90/250, Loss: 0.0161\n",
      "Epoch 84/200, Iteration 91/250, Loss: 0.0229\n",
      "Epoch 84/200, Iteration 92/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 93/250, Loss: 0.0348\n",
      "Epoch 84/200, Iteration 94/250, Loss: 0.0167\n",
      "Epoch 84/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 84/200, Iteration 96/250, Loss: 0.0156\n",
      "Epoch 84/200, Iteration 97/250, Loss: 0.0114\n",
      "Epoch 84/200, Iteration 98/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 99/250, Loss: 0.0130\n",
      "Epoch 84/200, Iteration 100/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 101/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 102/250, Loss: 0.0122\n",
      "Epoch 84/200, Iteration 103/250, Loss: 0.0165\n",
      "Epoch 84/200, Iteration 104/250, Loss: 0.0383\n",
      "Epoch 84/200, Iteration 105/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 106/250, Loss: 0.0205\n",
      "Epoch 84/200, Iteration 107/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 108/250, Loss: 0.0169\n",
      "Epoch 84/200, Iteration 109/250, Loss: 0.0105\n",
      "Epoch 84/200, Iteration 110/250, Loss: 0.0147\n",
      "Epoch 84/200, Iteration 111/250, Loss: 0.0192\n",
      "Epoch 84/200, Iteration 112/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 113/250, Loss: 0.0255\n",
      "Epoch 84/200, Iteration 114/250, Loss: 0.0077\n",
      "Epoch 84/200, Iteration 115/250, Loss: 0.0056\n",
      "Epoch 84/200, Iteration 116/250, Loss: 0.0291\n",
      "Epoch 84/200, Iteration 117/250, Loss: 0.0128\n",
      "Epoch 84/200, Iteration 118/250, Loss: 0.0087\n",
      "Epoch 84/200, Iteration 119/250, Loss: 0.0091\n",
      "Epoch 84/200, Iteration 120/250, Loss: 0.0200\n",
      "Epoch 84/200, Iteration 121/250, Loss: 0.0252\n",
      "Epoch 84/200, Iteration 122/250, Loss: 0.0107\n",
      "Epoch 84/200, Iteration 123/250, Loss: 0.0205\n",
      "Epoch 84/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 125/250, Loss: 0.0177\n",
      "Epoch 84/200, Iteration 126/250, Loss: 0.0085\n",
      "Epoch 84/200, Iteration 127/250, Loss: 0.0263\n",
      "Epoch 84/200, Iteration 128/250, Loss: 0.0185\n",
      "Epoch 84/200, Iteration 129/250, Loss: 0.0119\n",
      "Epoch 84/200, Iteration 130/250, Loss: 0.0073\n",
      "Epoch 84/200, Iteration 131/250, Loss: 0.0120\n",
      "Epoch 84/200, Iteration 132/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 133/250, Loss: 0.0287\n",
      "Epoch 84/200, Iteration 134/250, Loss: 0.0111\n",
      "Epoch 84/200, Iteration 135/250, Loss: 0.0182\n",
      "Epoch 84/200, Iteration 136/250, Loss: 0.0181\n",
      "Epoch 84/200, Iteration 137/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 138/250, Loss: 0.0184\n",
      "Epoch 84/200, Iteration 139/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 140/250, Loss: 0.0112\n",
      "Epoch 84/200, Iteration 141/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 142/250, Loss: 0.0058\n",
      "Epoch 84/200, Iteration 143/250, Loss: 0.0133\n",
      "Epoch 84/200, Iteration 144/250, Loss: 0.0211\n",
      "Epoch 84/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 146/250, Loss: 0.0084\n",
      "Epoch 84/200, Iteration 147/250, Loss: 0.0114\n",
      "Epoch 84/200, Iteration 148/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 84/200, Iteration 150/250, Loss: 0.0150\n",
      "Epoch 84/200, Iteration 151/250, Loss: 0.0133\n",
      "Epoch 84/200, Iteration 152/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 153/250, Loss: 0.0419\n",
      "Epoch 84/200, Iteration 154/250, Loss: 0.0261\n",
      "Epoch 84/200, Iteration 155/250, Loss: 0.0144\n",
      "Epoch 84/200, Iteration 156/250, Loss: 0.0323\n",
      "Epoch 84/200, Iteration 157/250, Loss: 0.0104\n",
      "Epoch 84/200, Iteration 158/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 159/250, Loss: 0.0189\n",
      "Epoch 84/200, Iteration 160/250, Loss: 0.0439\n",
      "Epoch 84/200, Iteration 161/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 162/250, Loss: 0.0197\n",
      "Epoch 84/200, Iteration 163/250, Loss: 0.0105\n",
      "Epoch 84/200, Iteration 164/250, Loss: 0.0134\n",
      "Epoch 84/200, Iteration 165/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 166/250, Loss: 0.0237\n",
      "Epoch 84/200, Iteration 167/250, Loss: 0.0086\n",
      "Epoch 84/200, Iteration 168/250, Loss: 0.0085\n",
      "Epoch 84/200, Iteration 169/250, Loss: 0.0212\n",
      "Epoch 84/200, Iteration 170/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 171/250, Loss: 0.0131\n",
      "Epoch 84/200, Iteration 172/250, Loss: 0.0161\n",
      "Epoch 84/200, Iteration 173/250, Loss: 0.0112\n",
      "Epoch 84/200, Iteration 174/250, Loss: 0.0084\n",
      "Epoch 84/200, Iteration 175/250, Loss: 0.0131\n",
      "Epoch 84/200, Iteration 176/250, Loss: 0.0195\n",
      "Epoch 84/200, Iteration 177/250, Loss: 0.0086\n",
      "Epoch 84/200, Iteration 178/250, Loss: 0.0130\n",
      "Epoch 84/200, Iteration 179/250, Loss: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200, Iteration 180/250, Loss: 0.0240\n",
      "Epoch 84/200, Iteration 181/250, Loss: 0.0234\n",
      "Epoch 84/200, Iteration 182/250, Loss: 0.0075\n",
      "Epoch 84/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 84/200, Iteration 184/250, Loss: 0.0167\n",
      "Epoch 84/200, Iteration 185/250, Loss: 0.0232\n",
      "Epoch 84/200, Iteration 186/250, Loss: 0.0105\n",
      "Epoch 84/200, Iteration 187/250, Loss: 0.0181\n",
      "Epoch 84/200, Iteration 188/250, Loss: 0.0095\n",
      "Epoch 84/200, Iteration 189/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 190/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 191/250, Loss: 0.0078\n",
      "Epoch 84/200, Iteration 192/250, Loss: 0.0160\n",
      "Epoch 84/200, Iteration 193/250, Loss: 0.0116\n",
      "Epoch 84/200, Iteration 194/250, Loss: 0.0190\n",
      "Epoch 84/200, Iteration 195/250, Loss: 0.0088\n",
      "Epoch 84/200, Iteration 196/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 197/250, Loss: 0.0170\n",
      "Epoch 84/200, Iteration 198/250, Loss: 0.0083\n",
      "Epoch 84/200, Iteration 199/250, Loss: 0.0163\n",
      "Epoch 84/200, Iteration 200/250, Loss: 0.0130\n",
      "Epoch 84/200, Iteration 201/250, Loss: 0.0125\n",
      "Epoch 84/200, Iteration 202/250, Loss: 0.0079\n",
      "Epoch 84/200, Iteration 203/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 204/250, Loss: 0.0123\n",
      "Epoch 84/200, Iteration 205/250, Loss: 0.0152\n",
      "Epoch 84/200, Iteration 206/250, Loss: 0.0200\n",
      "Epoch 84/200, Iteration 207/250, Loss: 0.0112\n",
      "Epoch 84/200, Iteration 208/250, Loss: 0.0312\n",
      "Epoch 84/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 84/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 84/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 84/200, Iteration 212/250, Loss: 0.0226\n",
      "Epoch 84/200, Iteration 213/250, Loss: 0.0122\n",
      "Epoch 84/200, Iteration 214/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 215/250, Loss: 0.0081\n",
      "Epoch 84/200, Iteration 216/250, Loss: 0.0114\n",
      "Epoch 84/200, Iteration 217/250, Loss: 0.0296\n",
      "Epoch 84/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 84/200, Iteration 219/250, Loss: 0.0278\n",
      "Epoch 84/200, Iteration 220/250, Loss: 0.0304\n",
      "Epoch 84/200, Iteration 221/250, Loss: 0.0063\n",
      "Epoch 84/200, Iteration 222/250, Loss: 0.0294\n",
      "Epoch 84/200, Iteration 223/250, Loss: 0.0181\n",
      "Epoch 84/200, Iteration 224/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 225/250, Loss: 0.0130\n",
      "Epoch 84/200, Iteration 226/250, Loss: 0.0065\n",
      "Epoch 84/200, Iteration 227/250, Loss: 0.0135\n",
      "Epoch 84/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 84/200, Iteration 229/250, Loss: 0.0182\n",
      "Epoch 84/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 231/250, Loss: 0.0131\n",
      "Epoch 84/200, Iteration 232/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 233/250, Loss: 0.0102\n",
      "Epoch 84/200, Iteration 234/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 235/250, Loss: 0.0184\n",
      "Epoch 84/200, Iteration 236/250, Loss: 0.0091\n",
      "Epoch 84/200, Iteration 237/250, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 238/250, Loss: 0.0129\n",
      "Epoch 84/200, Iteration 239/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 240/250, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 241/250, Loss: 0.0073\n",
      "Epoch 84/200, Iteration 242/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 243/250, Loss: 0.0140\n",
      "Epoch 84/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 245/250, Loss: 0.0216\n",
      "Epoch 84/200, Iteration 246/250, Loss: 0.0133\n",
      "Epoch 84/200, Iteration 247/250, Loss: 0.0070\n",
      "Epoch 84/200, Iteration 248/250, Loss: 0.0123\n",
      "Epoch 84/200, Iteration 249/250, Loss: 0.0292\n",
      "Epoch 84/200, Iteration 250/250, Loss: 0.0112\n",
      "Train Error: \n",
      " Accuracy: 76.17%, Avg loss: 0.007691, MRE: 0.688533 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.25%, Avg loss: 0.007726, MRE: 0.803874 \n",
      "\n",
      "Epoch 85/200, Iteration 1/250, Loss: 0.0191\n",
      "Epoch 85/200, Iteration 2/250, Loss: 0.0193\n",
      "Epoch 85/200, Iteration 3/250, Loss: 0.0160\n",
      "Epoch 85/200, Iteration 4/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 5/250, Loss: 0.0299\n",
      "Epoch 85/200, Iteration 6/250, Loss: 0.0148\n",
      "Epoch 85/200, Iteration 7/250, Loss: 0.0140\n",
      "Epoch 85/200, Iteration 8/250, Loss: 0.0082\n",
      "Epoch 85/200, Iteration 9/250, Loss: 0.0123\n",
      "Epoch 85/200, Iteration 10/250, Loss: 0.0249\n",
      "Epoch 85/200, Iteration 11/250, Loss: 0.0098\n",
      "Epoch 85/200, Iteration 12/250, Loss: 0.0174\n",
      "Epoch 85/200, Iteration 13/250, Loss: 0.0415\n",
      "Epoch 85/200, Iteration 14/250, Loss: 0.0131\n",
      "Epoch 85/200, Iteration 15/250, Loss: 0.0299\n",
      "Epoch 85/200, Iteration 16/250, Loss: 0.0066\n",
      "Epoch 85/200, Iteration 17/250, Loss: 0.0090\n",
      "Epoch 85/200, Iteration 18/250, Loss: 0.0310\n",
      "Epoch 85/200, Iteration 19/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 20/250, Loss: 0.0098\n",
      "Epoch 85/200, Iteration 21/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 85/200, Iteration 23/250, Loss: 0.0200\n",
      "Epoch 85/200, Iteration 24/250, Loss: 0.0170\n",
      "Epoch 85/200, Iteration 25/250, Loss: 0.0285\n",
      "Epoch 85/200, Iteration 26/250, Loss: 0.0261\n",
      "Epoch 85/200, Iteration 27/250, Loss: 0.0080\n",
      "Epoch 85/200, Iteration 28/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 29/250, Loss: 0.0131\n",
      "Epoch 85/200, Iteration 30/250, Loss: 0.0057\n",
      "Epoch 85/200, Iteration 31/250, Loss: 0.0361\n",
      "Epoch 85/200, Iteration 32/250, Loss: 0.0156\n",
      "Epoch 85/200, Iteration 33/250, Loss: 0.0138\n",
      "Epoch 85/200, Iteration 34/250, Loss: 0.0101\n",
      "Epoch 85/200, Iteration 35/250, Loss: 0.0143\n",
      "Epoch 85/200, Iteration 36/250, Loss: 0.0135\n",
      "Epoch 85/200, Iteration 37/250, Loss: 0.0256\n",
      "Epoch 85/200, Iteration 38/250, Loss: 0.0153\n",
      "Epoch 85/200, Iteration 39/250, Loss: 0.0326\n",
      "Epoch 85/200, Iteration 40/250, Loss: 0.0074\n",
      "Epoch 85/200, Iteration 41/250, Loss: 0.0180\n",
      "Epoch 85/200, Iteration 42/250, Loss: 0.0099\n",
      "Epoch 85/200, Iteration 43/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 44/250, Loss: 0.0101\n",
      "Epoch 85/200, Iteration 45/250, Loss: 0.0112\n",
      "Epoch 85/200, Iteration 46/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 47/250, Loss: 0.0277\n",
      "Epoch 85/200, Iteration 48/250, Loss: 0.0137\n",
      "Epoch 85/200, Iteration 49/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 50/250, Loss: 0.0037\n",
      "Epoch 85/200, Iteration 51/250, Loss: 0.0226\n",
      "Epoch 85/200, Iteration 52/250, Loss: 0.0105\n",
      "Epoch 85/200, Iteration 53/250, Loss: 0.0146\n",
      "Epoch 85/200, Iteration 54/250, Loss: 0.0072\n",
      "Epoch 85/200, Iteration 55/250, Loss: 0.0125\n",
      "Epoch 85/200, Iteration 56/250, Loss: 0.0076\n",
      "Epoch 85/200, Iteration 57/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 58/250, Loss: 0.0089\n",
      "Epoch 85/200, Iteration 59/250, Loss: 0.0081\n",
      "Epoch 85/200, Iteration 60/250, Loss: 0.0124\n",
      "Epoch 85/200, Iteration 61/250, Loss: 0.0076\n",
      "Epoch 85/200, Iteration 62/250, Loss: 0.0154\n",
      "Epoch 85/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 85/200, Iteration 64/250, Loss: 0.0078\n",
      "Epoch 85/200, Iteration 65/250, Loss: 0.0091\n",
      "Epoch 85/200, Iteration 66/250, Loss: 0.0102\n",
      "Epoch 85/200, Iteration 67/250, Loss: 0.0165\n",
      "Epoch 85/200, Iteration 68/250, Loss: 0.0153\n",
      "Epoch 85/200, Iteration 69/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 70/250, Loss: 0.0166\n",
      "Epoch 85/200, Iteration 71/250, Loss: 0.0135\n",
      "Epoch 85/200, Iteration 72/250, Loss: 0.0143\n",
      "Epoch 85/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 85/200, Iteration 74/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 75/250, Loss: 0.0219\n",
      "Epoch 85/200, Iteration 76/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 77/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 78/250, Loss: 0.0175\n",
      "Epoch 85/200, Iteration 79/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 80/250, Loss: 0.0180\n",
      "Epoch 85/200, Iteration 81/250, Loss: 0.0329\n",
      "Epoch 85/200, Iteration 82/250, Loss: 0.0190\n",
      "Epoch 85/200, Iteration 83/250, Loss: 0.0285\n",
      "Epoch 85/200, Iteration 84/250, Loss: 0.0110\n",
      "Epoch 85/200, Iteration 85/250, Loss: 0.0153\n",
      "Epoch 85/200, Iteration 86/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 85/200, Iteration 88/250, Loss: 0.0154\n",
      "Epoch 85/200, Iteration 89/250, Loss: 0.0161\n",
      "Epoch 85/200, Iteration 90/250, Loss: 0.0188\n",
      "Epoch 85/200, Iteration 91/250, Loss: 0.0146\n",
      "Epoch 85/200, Iteration 92/250, Loss: 0.0079\n",
      "Epoch 85/200, Iteration 93/250, Loss: 0.0156\n",
      "Epoch 85/200, Iteration 94/250, Loss: 0.0091\n",
      "Epoch 85/200, Iteration 95/250, Loss: 0.0282\n",
      "Epoch 85/200, Iteration 96/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 97/250, Loss: 0.0201\n",
      "Epoch 85/200, Iteration 98/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 99/250, Loss: 0.0164\n",
      "Epoch 85/200, Iteration 100/250, Loss: 0.0217\n",
      "Epoch 85/200, Iteration 101/250, Loss: 0.0332\n",
      "Epoch 85/200, Iteration 102/250, Loss: 0.0230\n",
      "Epoch 85/200, Iteration 103/250, Loss: 0.0217\n",
      "Epoch 85/200, Iteration 104/250, Loss: 0.0109\n",
      "Epoch 85/200, Iteration 105/250, Loss: 0.0099\n",
      "Epoch 85/200, Iteration 106/250, Loss: 0.0130\n",
      "Epoch 85/200, Iteration 107/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 108/250, Loss: 0.0173\n",
      "Epoch 85/200, Iteration 109/250, Loss: 0.0167\n",
      "Epoch 85/200, Iteration 110/250, Loss: 0.0128\n",
      "Epoch 85/200, Iteration 111/250, Loss: 0.0140\n",
      "Epoch 85/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 85/200, Iteration 113/250, Loss: 0.0196\n",
      "Epoch 85/200, Iteration 114/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 115/250, Loss: 0.0099\n",
      "Epoch 85/200, Iteration 116/250, Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200, Iteration 117/250, Loss: 0.0079\n",
      "Epoch 85/200, Iteration 118/250, Loss: 0.0086\n",
      "Epoch 85/200, Iteration 119/250, Loss: 0.0085\n",
      "Epoch 85/200, Iteration 120/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 121/250, Loss: 0.0226\n",
      "Epoch 85/200, Iteration 122/250, Loss: 0.0137\n",
      "Epoch 85/200, Iteration 123/250, Loss: 0.0084\n",
      "Epoch 85/200, Iteration 124/250, Loss: 0.0209\n",
      "Epoch 85/200, Iteration 125/250, Loss: 0.0115\n",
      "Epoch 85/200, Iteration 126/250, Loss: 0.0126\n",
      "Epoch 85/200, Iteration 127/250, Loss: 0.0135\n",
      "Epoch 85/200, Iteration 128/250, Loss: 0.0246\n",
      "Epoch 85/200, Iteration 129/250, Loss: 0.0259\n",
      "Epoch 85/200, Iteration 130/250, Loss: 0.0236\n",
      "Epoch 85/200, Iteration 131/250, Loss: 0.0182\n",
      "Epoch 85/200, Iteration 132/250, Loss: 0.0109\n",
      "Epoch 85/200, Iteration 133/250, Loss: 0.0070\n",
      "Epoch 85/200, Iteration 134/250, Loss: 0.0106\n",
      "Epoch 85/200, Iteration 135/250, Loss: 0.0091\n",
      "Epoch 85/200, Iteration 136/250, Loss: 0.0074\n",
      "Epoch 85/200, Iteration 137/250, Loss: 0.0060\n",
      "Epoch 85/200, Iteration 138/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 139/250, Loss: 0.0089\n",
      "Epoch 85/200, Iteration 140/250, Loss: 0.0134\n",
      "Epoch 85/200, Iteration 141/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 142/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 143/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 144/250, Loss: 0.0101\n",
      "Epoch 85/200, Iteration 145/250, Loss: 0.0124\n",
      "Epoch 85/200, Iteration 146/250, Loss: 0.0077\n",
      "Epoch 85/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 85/200, Iteration 148/250, Loss: 0.0139\n",
      "Epoch 85/200, Iteration 149/250, Loss: 0.0190\n",
      "Epoch 85/200, Iteration 150/250, Loss: 0.0172\n",
      "Epoch 85/200, Iteration 151/250, Loss: 0.0156\n",
      "Epoch 85/200, Iteration 152/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 153/250, Loss: 0.0266\n",
      "Epoch 85/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 85/200, Iteration 155/250, Loss: 0.0094\n",
      "Epoch 85/200, Iteration 156/250, Loss: 0.0097\n",
      "Epoch 85/200, Iteration 157/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 158/250, Loss: 0.0263\n",
      "Epoch 85/200, Iteration 159/250, Loss: 0.0076\n",
      "Epoch 85/200, Iteration 160/250, Loss: 0.0208\n",
      "Epoch 85/200, Iteration 161/250, Loss: 0.0290\n",
      "Epoch 85/200, Iteration 162/250, Loss: 0.0140\n",
      "Epoch 85/200, Iteration 163/250, Loss: 0.0182\n",
      "Epoch 85/200, Iteration 164/250, Loss: 0.0126\n",
      "Epoch 85/200, Iteration 165/250, Loss: 0.0067\n",
      "Epoch 85/200, Iteration 166/250, Loss: 0.0229\n",
      "Epoch 85/200, Iteration 167/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 168/250, Loss: 0.0086\n",
      "Epoch 85/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 85/200, Iteration 170/250, Loss: 0.0184\n",
      "Epoch 85/200, Iteration 171/250, Loss: 0.0319\n",
      "Epoch 85/200, Iteration 172/250, Loss: 0.0047\n",
      "Epoch 85/200, Iteration 173/250, Loss: 0.0174\n",
      "Epoch 85/200, Iteration 174/250, Loss: 0.0166\n",
      "Epoch 85/200, Iteration 175/250, Loss: 0.0255\n",
      "Epoch 85/200, Iteration 176/250, Loss: 0.0235\n",
      "Epoch 85/200, Iteration 177/250, Loss: 0.0082\n",
      "Epoch 85/200, Iteration 178/250, Loss: 0.0089\n",
      "Epoch 85/200, Iteration 179/250, Loss: 0.0127\n",
      "Epoch 85/200, Iteration 180/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 181/250, Loss: 0.0161\n",
      "Epoch 85/200, Iteration 182/250, Loss: 0.0147\n",
      "Epoch 85/200, Iteration 183/250, Loss: 0.0068\n",
      "Epoch 85/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 85/200, Iteration 185/250, Loss: 0.0183\n",
      "Epoch 85/200, Iteration 186/250, Loss: 0.0126\n",
      "Epoch 85/200, Iteration 187/250, Loss: 0.0209\n",
      "Epoch 85/200, Iteration 188/250, Loss: 0.0107\n",
      "Epoch 85/200, Iteration 189/250, Loss: 0.0192\n",
      "Epoch 85/200, Iteration 190/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 191/250, Loss: 0.0142\n",
      "Epoch 85/200, Iteration 192/250, Loss: 0.0084\n",
      "Epoch 85/200, Iteration 193/250, Loss: 0.0194\n",
      "Epoch 85/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 85/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 85/200, Iteration 196/250, Loss: 0.0154\n",
      "Epoch 85/200, Iteration 197/250, Loss: 0.0147\n",
      "Epoch 85/200, Iteration 198/250, Loss: 0.0176\n",
      "Epoch 85/200, Iteration 199/250, Loss: 0.0266\n",
      "Epoch 85/200, Iteration 200/250, Loss: 0.0097\n",
      "Epoch 85/200, Iteration 201/250, Loss: 0.0229\n",
      "Epoch 85/200, Iteration 202/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 203/250, Loss: 0.0163\n",
      "Epoch 85/200, Iteration 204/250, Loss: 0.0280\n",
      "Epoch 85/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 85/200, Iteration 206/250, Loss: 0.0169\n",
      "Epoch 85/200, Iteration 207/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 208/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 209/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 210/250, Loss: 0.0224\n",
      "Epoch 85/200, Iteration 211/250, Loss: 0.0232\n",
      "Epoch 85/200, Iteration 212/250, Loss: 0.0179\n",
      "Epoch 85/200, Iteration 213/250, Loss: 0.0398\n",
      "Epoch 85/200, Iteration 214/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 215/250, Loss: 0.0080\n",
      "Epoch 85/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 85/200, Iteration 217/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 218/250, Loss: 0.0221\n",
      "Epoch 85/200, Iteration 219/250, Loss: 0.0061\n",
      "Epoch 85/200, Iteration 220/250, Loss: 0.0138\n",
      "Epoch 85/200, Iteration 221/250, Loss: 0.0144\n",
      "Epoch 85/200, Iteration 222/250, Loss: 0.0205\n",
      "Epoch 85/200, Iteration 223/250, Loss: 0.0061\n",
      "Epoch 85/200, Iteration 224/250, Loss: 0.0112\n",
      "Epoch 85/200, Iteration 225/250, Loss: 0.0159\n",
      "Epoch 85/200, Iteration 226/250, Loss: 0.0188\n",
      "Epoch 85/200, Iteration 227/250, Loss: 0.0078\n",
      "Epoch 85/200, Iteration 228/250, Loss: 0.0217\n",
      "Epoch 85/200, Iteration 229/250, Loss: 0.0077\n",
      "Epoch 85/200, Iteration 230/250, Loss: 0.0250\n",
      "Epoch 85/200, Iteration 231/250, Loss: 0.0138\n",
      "Epoch 85/200, Iteration 232/250, Loss: 0.0119\n",
      "Epoch 85/200, Iteration 233/250, Loss: 0.0148\n",
      "Epoch 85/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 85/200, Iteration 235/250, Loss: 0.0199\n",
      "Epoch 85/200, Iteration 236/250, Loss: 0.0146\n",
      "Epoch 85/200, Iteration 237/250, Loss: 0.0055\n",
      "Epoch 85/200, Iteration 238/250, Loss: 0.0363\n",
      "Epoch 85/200, Iteration 239/250, Loss: 0.0097\n",
      "Epoch 85/200, Iteration 240/250, Loss: 0.0122\n",
      "Epoch 85/200, Iteration 241/250, Loss: 0.0218\n",
      "Epoch 85/200, Iteration 242/250, Loss: 0.0243\n",
      "Epoch 85/200, Iteration 243/250, Loss: 0.0164\n",
      "Epoch 85/200, Iteration 244/250, Loss: 0.0190\n",
      "Epoch 85/200, Iteration 245/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 246/250, Loss: 0.0092\n",
      "Epoch 85/200, Iteration 247/250, Loss: 0.0085\n",
      "Epoch 85/200, Iteration 248/250, Loss: 0.0135\n",
      "Epoch 85/200, Iteration 249/250, Loss: 0.0107\n",
      "Epoch 85/200, Iteration 250/250, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.006224, MRE: 0.658511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.006195, MRE: 1.026060 \n",
      "\n",
      "Epoch 86/200, Iteration 1/250, Loss: 0.0212\n",
      "Epoch 86/200, Iteration 2/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 3/250, Loss: 0.0190\n",
      "Epoch 86/200, Iteration 4/250, Loss: 0.0141\n",
      "Epoch 86/200, Iteration 5/250, Loss: 0.0130\n",
      "Epoch 86/200, Iteration 6/250, Loss: 0.0075\n",
      "Epoch 86/200, Iteration 7/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 8/250, Loss: 0.0193\n",
      "Epoch 86/200, Iteration 9/250, Loss: 0.0113\n",
      "Epoch 86/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 86/200, Iteration 11/250, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 12/250, Loss: 0.0253\n",
      "Epoch 86/200, Iteration 13/250, Loss: 0.0095\n",
      "Epoch 86/200, Iteration 14/250, Loss: 0.0261\n",
      "Epoch 86/200, Iteration 15/250, Loss: 0.0153\n",
      "Epoch 86/200, Iteration 16/250, Loss: 0.0512\n",
      "Epoch 86/200, Iteration 17/250, Loss: 0.0187\n",
      "Epoch 86/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 86/200, Iteration 19/250, Loss: 0.0092\n",
      "Epoch 86/200, Iteration 20/250, Loss: 0.0276\n",
      "Epoch 86/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 86/200, Iteration 22/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 23/250, Loss: 0.0166\n",
      "Epoch 86/200, Iteration 24/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 25/250, Loss: 0.0203\n",
      "Epoch 86/200, Iteration 26/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 27/250, Loss: 0.0224\n",
      "Epoch 86/200, Iteration 28/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 29/250, Loss: 0.0135\n",
      "Epoch 86/200, Iteration 30/250, Loss: 0.0167\n",
      "Epoch 86/200, Iteration 31/250, Loss: 0.0286\n",
      "Epoch 86/200, Iteration 32/250, Loss: 0.0140\n",
      "Epoch 86/200, Iteration 33/250, Loss: 0.0280\n",
      "Epoch 86/200, Iteration 34/250, Loss: 0.0089\n",
      "Epoch 86/200, Iteration 35/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 36/250, Loss: 0.0145\n",
      "Epoch 86/200, Iteration 37/250, Loss: 0.0131\n",
      "Epoch 86/200, Iteration 38/250, Loss: 0.0102\n",
      "Epoch 86/200, Iteration 39/250, Loss: 0.0205\n",
      "Epoch 86/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 86/200, Iteration 41/250, Loss: 0.0179\n",
      "Epoch 86/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 86/200, Iteration 43/250, Loss: 0.0113\n",
      "Epoch 86/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 86/200, Iteration 45/250, Loss: 0.0403\n",
      "Epoch 86/200, Iteration 46/250, Loss: 0.0173\n",
      "Epoch 86/200, Iteration 47/250, Loss: 0.0105\n",
      "Epoch 86/200, Iteration 48/250, Loss: 0.0128\n",
      "Epoch 86/200, Iteration 49/250, Loss: 0.0116\n",
      "Epoch 86/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 51/250, Loss: 0.0143\n",
      "Epoch 86/200, Iteration 52/250, Loss: 0.0069\n",
      "Epoch 86/200, Iteration 53/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 54/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 56/250, Loss: 0.0243\n",
      "Epoch 86/200, Iteration 57/250, Loss: 0.0199\n",
      "Epoch 86/200, Iteration 58/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 59/250, Loss: 0.0078\n",
      "Epoch 86/200, Iteration 60/250, Loss: 0.0283\n",
      "Epoch 86/200, Iteration 61/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 62/250, Loss: 0.0062\n",
      "Epoch 86/200, Iteration 63/250, Loss: 0.0095\n",
      "Epoch 86/200, Iteration 64/250, Loss: 0.0108\n",
      "Epoch 86/200, Iteration 65/250, Loss: 0.0109\n",
      "Epoch 86/200, Iteration 66/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 67/250, Loss: 0.0134\n",
      "Epoch 86/200, Iteration 68/250, Loss: 0.0148\n",
      "Epoch 86/200, Iteration 69/250, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 70/250, Loss: 0.0330\n",
      "Epoch 86/200, Iteration 71/250, Loss: 0.0118\n",
      "Epoch 86/200, Iteration 72/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 73/250, Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200, Iteration 74/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 76/250, Loss: 0.0163\n",
      "Epoch 86/200, Iteration 77/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 78/250, Loss: 0.0140\n",
      "Epoch 86/200, Iteration 79/250, Loss: 0.0119\n",
      "Epoch 86/200, Iteration 80/250, Loss: 0.0168\n",
      "Epoch 86/200, Iteration 81/250, Loss: 0.0146\n",
      "Epoch 86/200, Iteration 82/250, Loss: 0.0083\n",
      "Epoch 86/200, Iteration 83/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 84/250, Loss: 0.0120\n",
      "Epoch 86/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 86/200, Iteration 86/250, Loss: 0.0080\n",
      "Epoch 86/200, Iteration 87/250, Loss: 0.0347\n",
      "Epoch 86/200, Iteration 88/250, Loss: 0.0141\n",
      "Epoch 86/200, Iteration 89/250, Loss: 0.0470\n",
      "Epoch 86/200, Iteration 90/250, Loss: 0.0076\n",
      "Epoch 86/200, Iteration 91/250, Loss: 0.0132\n",
      "Epoch 86/200, Iteration 92/250, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 93/250, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 94/250, Loss: 0.0099\n",
      "Epoch 86/200, Iteration 95/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 96/250, Loss: 0.0196\n",
      "Epoch 86/200, Iteration 97/250, Loss: 0.0060\n",
      "Epoch 86/200, Iteration 98/250, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 99/250, Loss: 0.0184\n",
      "Epoch 86/200, Iteration 100/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 101/250, Loss: 0.0123\n",
      "Epoch 86/200, Iteration 102/250, Loss: 0.0089\n",
      "Epoch 86/200, Iteration 103/250, Loss: 0.0222\n",
      "Epoch 86/200, Iteration 104/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 105/250, Loss: 0.0150\n",
      "Epoch 86/200, Iteration 106/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 107/250, Loss: 0.0134\n",
      "Epoch 86/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 109/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 110/250, Loss: 0.0149\n",
      "Epoch 86/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 112/250, Loss: 0.0145\n",
      "Epoch 86/200, Iteration 113/250, Loss: 0.0186\n",
      "Epoch 86/200, Iteration 114/250, Loss: 0.0376\n",
      "Epoch 86/200, Iteration 115/250, Loss: 0.0149\n",
      "Epoch 86/200, Iteration 116/250, Loss: 0.0126\n",
      "Epoch 86/200, Iteration 117/250, Loss: 0.0165\n",
      "Epoch 86/200, Iteration 118/250, Loss: 0.0094\n",
      "Epoch 86/200, Iteration 119/250, Loss: 0.0201\n",
      "Epoch 86/200, Iteration 120/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 121/250, Loss: 0.0152\n",
      "Epoch 86/200, Iteration 122/250, Loss: 0.0102\n",
      "Epoch 86/200, Iteration 123/250, Loss: 0.0230\n",
      "Epoch 86/200, Iteration 124/250, Loss: 0.0079\n",
      "Epoch 86/200, Iteration 125/250, Loss: 0.0126\n",
      "Epoch 86/200, Iteration 126/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 127/250, Loss: 0.0088\n",
      "Epoch 86/200, Iteration 128/250, Loss: 0.0231\n",
      "Epoch 86/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 86/200, Iteration 130/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 131/250, Loss: 0.0078\n",
      "Epoch 86/200, Iteration 132/250, Loss: 0.0308\n",
      "Epoch 86/200, Iteration 133/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 134/250, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 135/250, Loss: 0.0265\n",
      "Epoch 86/200, Iteration 136/250, Loss: 0.0076\n",
      "Epoch 86/200, Iteration 137/250, Loss: 0.0200\n",
      "Epoch 86/200, Iteration 138/250, Loss: 0.0215\n",
      "Epoch 86/200, Iteration 139/250, Loss: 0.0273\n",
      "Epoch 86/200, Iteration 140/250, Loss: 0.0054\n",
      "Epoch 86/200, Iteration 141/250, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 142/250, Loss: 0.0134\n",
      "Epoch 86/200, Iteration 143/250, Loss: 0.0199\n",
      "Epoch 86/200, Iteration 144/250, Loss: 0.0251\n",
      "Epoch 86/200, Iteration 145/250, Loss: 0.0101\n",
      "Epoch 86/200, Iteration 146/250, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 147/250, Loss: 0.0148\n",
      "Epoch 86/200, Iteration 148/250, Loss: 0.0276\n",
      "Epoch 86/200, Iteration 149/250, Loss: 0.0245\n",
      "Epoch 86/200, Iteration 150/250, Loss: 0.0217\n",
      "Epoch 86/200, Iteration 151/250, Loss: 0.0133\n",
      "Epoch 86/200, Iteration 152/250, Loss: 0.0201\n",
      "Epoch 86/200, Iteration 153/250, Loss: 0.0071\n",
      "Epoch 86/200, Iteration 154/250, Loss: 0.0077\n",
      "Epoch 86/200, Iteration 155/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 156/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 157/250, Loss: 0.0135\n",
      "Epoch 86/200, Iteration 158/250, Loss: 0.0140\n",
      "Epoch 86/200, Iteration 159/250, Loss: 0.0081\n",
      "Epoch 86/200, Iteration 160/250, Loss: 0.0216\n",
      "Epoch 86/200, Iteration 161/250, Loss: 0.0087\n",
      "Epoch 86/200, Iteration 162/250, Loss: 0.0137\n",
      "Epoch 86/200, Iteration 163/250, Loss: 0.0203\n",
      "Epoch 86/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 86/200, Iteration 165/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 166/250, Loss: 0.0263\n",
      "Epoch 86/200, Iteration 167/250, Loss: 0.0291\n",
      "Epoch 86/200, Iteration 168/250, Loss: 0.0172\n",
      "Epoch 86/200, Iteration 169/250, Loss: 0.0164\n",
      "Epoch 86/200, Iteration 170/250, Loss: 0.0294\n",
      "Epoch 86/200, Iteration 171/250, Loss: 0.0235\n",
      "Epoch 86/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 86/200, Iteration 173/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 174/250, Loss: 0.0310\n",
      "Epoch 86/200, Iteration 175/250, Loss: 0.0156\n",
      "Epoch 86/200, Iteration 176/250, Loss: 0.0157\n",
      "Epoch 86/200, Iteration 177/250, Loss: 0.0172\n",
      "Epoch 86/200, Iteration 178/250, Loss: 0.0077\n",
      "Epoch 86/200, Iteration 179/250, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 180/250, Loss: 0.0104\n",
      "Epoch 86/200, Iteration 181/250, Loss: 0.0167\n",
      "Epoch 86/200, Iteration 182/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 183/250, Loss: 0.0072\n",
      "Epoch 86/200, Iteration 184/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 185/250, Loss: 0.0082\n",
      "Epoch 86/200, Iteration 186/250, Loss: 0.0139\n",
      "Epoch 86/200, Iteration 187/250, Loss: 0.0099\n",
      "Epoch 86/200, Iteration 188/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 189/250, Loss: 0.0045\n",
      "Epoch 86/200, Iteration 190/250, Loss: 0.0131\n",
      "Epoch 86/200, Iteration 191/250, Loss: 0.0228\n",
      "Epoch 86/200, Iteration 192/250, Loss: 0.0109\n",
      "Epoch 86/200, Iteration 193/250, Loss: 0.0104\n",
      "Epoch 86/200, Iteration 194/250, Loss: 0.0094\n",
      "Epoch 86/200, Iteration 195/250, Loss: 0.0277\n",
      "Epoch 86/200, Iteration 196/250, Loss: 0.0076\n",
      "Epoch 86/200, Iteration 197/250, Loss: 0.0180\n",
      "Epoch 86/200, Iteration 198/250, Loss: 0.0173\n",
      "Epoch 86/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 86/200, Iteration 200/250, Loss: 0.0127\n",
      "Epoch 86/200, Iteration 201/250, Loss: 0.0240\n",
      "Epoch 86/200, Iteration 202/250, Loss: 0.0096\n",
      "Epoch 86/200, Iteration 203/250, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 205/250, Loss: 0.0089\n",
      "Epoch 86/200, Iteration 206/250, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 207/250, Loss: 0.0096\n",
      "Epoch 86/200, Iteration 208/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 209/250, Loss: 0.0080\n",
      "Epoch 86/200, Iteration 210/250, Loss: 0.0184\n",
      "Epoch 86/200, Iteration 211/250, Loss: 0.0163\n",
      "Epoch 86/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 86/200, Iteration 213/250, Loss: 0.0099\n",
      "Epoch 86/200, Iteration 214/250, Loss: 0.0123\n",
      "Epoch 86/200, Iteration 215/250, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 216/250, Loss: 0.0097\n",
      "Epoch 86/200, Iteration 217/250, Loss: 0.0140\n",
      "Epoch 86/200, Iteration 218/250, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 219/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 220/250, Loss: 0.0080\n",
      "Epoch 86/200, Iteration 221/250, Loss: 0.0246\n",
      "Epoch 86/200, Iteration 222/250, Loss: 0.0259\n",
      "Epoch 86/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 86/200, Iteration 224/250, Loss: 0.0089\n",
      "Epoch 86/200, Iteration 225/250, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 226/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 227/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 228/250, Loss: 0.0170\n",
      "Epoch 86/200, Iteration 229/250, Loss: 0.0355\n",
      "Epoch 86/200, Iteration 230/250, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 231/250, Loss: 0.0149\n",
      "Epoch 86/200, Iteration 232/250, Loss: 0.0194\n",
      "Epoch 86/200, Iteration 233/250, Loss: 0.0329\n",
      "Epoch 86/200, Iteration 234/250, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 235/250, Loss: 0.0167\n",
      "Epoch 86/200, Iteration 236/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 237/250, Loss: 0.0080\n",
      "Epoch 86/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 86/200, Iteration 239/250, Loss: 0.0068\n",
      "Epoch 86/200, Iteration 240/250, Loss: 0.0180\n",
      "Epoch 86/200, Iteration 241/250, Loss: 0.0163\n",
      "Epoch 86/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 86/200, Iteration 243/250, Loss: 0.0158\n",
      "Epoch 86/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 245/250, Loss: 0.0133\n",
      "Epoch 86/200, Iteration 246/250, Loss: 0.0180\n",
      "Epoch 86/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 86/200, Iteration 248/250, Loss: 0.0265\n",
      "Epoch 86/200, Iteration 249/250, Loss: 0.0075\n",
      "Epoch 86/200, Iteration 250/250, Loss: 0.0147\n",
      "Train Error: \n",
      " Accuracy: 90.38%, Avg loss: 0.006362, MRE: 0.627294 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.006408, MRE: 0.934006 \n",
      "\n",
      "Epoch 87/200, Iteration 1/250, Loss: 0.0169\n",
      "Epoch 87/200, Iteration 2/250, Loss: 0.0121\n",
      "Epoch 87/200, Iteration 3/250, Loss: 0.0222\n",
      "Epoch 87/200, Iteration 4/250, Loss: 0.0083\n",
      "Epoch 87/200, Iteration 5/250, Loss: 0.0144\n",
      "Epoch 87/200, Iteration 6/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 7/250, Loss: 0.0333\n",
      "Epoch 87/200, Iteration 8/250, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200, Iteration 9/250, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 10/250, Loss: 0.0139\n",
      "Epoch 87/200, Iteration 11/250, Loss: 0.0136\n",
      "Epoch 87/200, Iteration 12/250, Loss: 0.0089\n",
      "Epoch 87/200, Iteration 13/250, Loss: 0.0135\n",
      "Epoch 87/200, Iteration 14/250, Loss: 0.0192\n",
      "Epoch 87/200, Iteration 15/250, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 16/250, Loss: 0.0078\n",
      "Epoch 87/200, Iteration 17/250, Loss: 0.0181\n",
      "Epoch 87/200, Iteration 18/250, Loss: 0.0090\n",
      "Epoch 87/200, Iteration 19/250, Loss: 0.0103\n",
      "Epoch 87/200, Iteration 20/250, Loss: 0.0149\n",
      "Epoch 87/200, Iteration 21/250, Loss: 0.0112\n",
      "Epoch 87/200, Iteration 22/250, Loss: 0.0096\n",
      "Epoch 87/200, Iteration 23/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 24/250, Loss: 0.0062\n",
      "Epoch 87/200, Iteration 25/250, Loss: 0.0170\n",
      "Epoch 87/200, Iteration 26/250, Loss: 0.0236\n",
      "Epoch 87/200, Iteration 27/250, Loss: 0.0162\n",
      "Epoch 87/200, Iteration 28/250, Loss: 0.0393\n",
      "Epoch 87/200, Iteration 29/250, Loss: 0.0082\n",
      "Epoch 87/200, Iteration 30/250, Loss: 0.0424\n",
      "Epoch 87/200, Iteration 31/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 32/250, Loss: 0.0165\n",
      "Epoch 87/200, Iteration 33/250, Loss: 0.0258\n",
      "Epoch 87/200, Iteration 34/250, Loss: 0.0118\n",
      "Epoch 87/200, Iteration 35/250, Loss: 0.0355\n",
      "Epoch 87/200, Iteration 36/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 37/250, Loss: 0.0207\n",
      "Epoch 87/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 87/200, Iteration 39/250, Loss: 0.0150\n",
      "Epoch 87/200, Iteration 40/250, Loss: 0.0250\n",
      "Epoch 87/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 87/200, Iteration 42/250, Loss: 0.0233\n",
      "Epoch 87/200, Iteration 43/250, Loss: 0.0058\n",
      "Epoch 87/200, Iteration 44/250, Loss: 0.0131\n",
      "Epoch 87/200, Iteration 45/250, Loss: 0.0176\n",
      "Epoch 87/200, Iteration 46/250, Loss: 0.0325\n",
      "Epoch 87/200, Iteration 47/250, Loss: 0.0153\n",
      "Epoch 87/200, Iteration 48/250, Loss: 0.0100\n",
      "Epoch 87/200, Iteration 49/250, Loss: 0.0239\n",
      "Epoch 87/200, Iteration 50/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 51/250, Loss: 0.0225\n",
      "Epoch 87/200, Iteration 52/250, Loss: 0.0115\n",
      "Epoch 87/200, Iteration 53/250, Loss: 0.0193\n",
      "Epoch 87/200, Iteration 54/250, Loss: 0.0364\n",
      "Epoch 87/200, Iteration 55/250, Loss: 0.0081\n",
      "Epoch 87/200, Iteration 56/250, Loss: 0.0273\n",
      "Epoch 87/200, Iteration 57/250, Loss: 0.0233\n",
      "Epoch 87/200, Iteration 58/250, Loss: 0.0094\n",
      "Epoch 87/200, Iteration 59/250, Loss: 0.0198\n",
      "Epoch 87/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 87/200, Iteration 61/250, Loss: 0.0323\n",
      "Epoch 87/200, Iteration 62/250, Loss: 0.0311\n",
      "Epoch 87/200, Iteration 63/250, Loss: 0.0250\n",
      "Epoch 87/200, Iteration 64/250, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 65/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 66/250, Loss: 0.0147\n",
      "Epoch 87/200, Iteration 67/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 68/250, Loss: 0.0312\n",
      "Epoch 87/200, Iteration 69/250, Loss: 0.0142\n",
      "Epoch 87/200, Iteration 70/250, Loss: 0.0089\n",
      "Epoch 87/200, Iteration 71/250, Loss: 0.0248\n",
      "Epoch 87/200, Iteration 72/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 73/250, Loss: 0.0095\n",
      "Epoch 87/200, Iteration 74/250, Loss: 0.0095\n",
      "Epoch 87/200, Iteration 75/250, Loss: 0.0153\n",
      "Epoch 87/200, Iteration 76/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 77/250, Loss: 0.0079\n",
      "Epoch 87/200, Iteration 78/250, Loss: 0.0160\n",
      "Epoch 87/200, Iteration 79/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 80/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 81/250, Loss: 0.0088\n",
      "Epoch 87/200, Iteration 82/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 83/250, Loss: 0.0113\n",
      "Epoch 87/200, Iteration 84/250, Loss: 0.0190\n",
      "Epoch 87/200, Iteration 85/250, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 86/250, Loss: 0.0084\n",
      "Epoch 87/200, Iteration 87/250, Loss: 0.0053\n",
      "Epoch 87/200, Iteration 88/250, Loss: 0.0072\n",
      "Epoch 87/200, Iteration 89/250, Loss: 0.0096\n",
      "Epoch 87/200, Iteration 90/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 91/250, Loss: 0.0081\n",
      "Epoch 87/200, Iteration 92/250, Loss: 0.0306\n",
      "Epoch 87/200, Iteration 93/250, Loss: 0.0100\n",
      "Epoch 87/200, Iteration 94/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 95/250, Loss: 0.0094\n",
      "Epoch 87/200, Iteration 96/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 97/250, Loss: 0.0143\n",
      "Epoch 87/200, Iteration 98/250, Loss: 0.0225\n",
      "Epoch 87/200, Iteration 99/250, Loss: 0.0192\n",
      "Epoch 87/200, Iteration 100/250, Loss: 0.0114\n",
      "Epoch 87/200, Iteration 101/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 102/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 103/250, Loss: 0.0272\n",
      "Epoch 87/200, Iteration 104/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 105/250, Loss: 0.0290\n",
      "Epoch 87/200, Iteration 106/250, Loss: 0.0277\n",
      "Epoch 87/200, Iteration 107/250, Loss: 0.0141\n",
      "Epoch 87/200, Iteration 108/250, Loss: 0.0504\n",
      "Epoch 87/200, Iteration 109/250, Loss: 0.0264\n",
      "Epoch 87/200, Iteration 110/250, Loss: 0.0233\n",
      "Epoch 87/200, Iteration 111/250, Loss: 0.0248\n",
      "Epoch 87/200, Iteration 112/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 113/250, Loss: 0.0083\n",
      "Epoch 87/200, Iteration 114/250, Loss: 0.0116\n",
      "Epoch 87/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 116/250, Loss: 0.0176\n",
      "Epoch 87/200, Iteration 117/250, Loss: 0.0318\n",
      "Epoch 87/200, Iteration 118/250, Loss: 0.0113\n",
      "Epoch 87/200, Iteration 119/250, Loss: 0.0067\n",
      "Epoch 87/200, Iteration 120/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 121/250, Loss: 0.0107\n",
      "Epoch 87/200, Iteration 122/250, Loss: 0.0121\n",
      "Epoch 87/200, Iteration 123/250, Loss: 0.0115\n",
      "Epoch 87/200, Iteration 124/250, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 125/250, Loss: 0.0142\n",
      "Epoch 87/200, Iteration 126/250, Loss: 0.0242\n",
      "Epoch 87/200, Iteration 127/250, Loss: 0.0233\n",
      "Epoch 87/200, Iteration 128/250, Loss: 0.0241\n",
      "Epoch 87/200, Iteration 129/250, Loss: 0.0073\n",
      "Epoch 87/200, Iteration 130/250, Loss: 0.0121\n",
      "Epoch 87/200, Iteration 131/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 132/250, Loss: 0.0164\n",
      "Epoch 87/200, Iteration 133/250, Loss: 0.0118\n",
      "Epoch 87/200, Iteration 134/250, Loss: 0.0071\n",
      "Epoch 87/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 87/200, Iteration 136/250, Loss: 0.0116\n",
      "Epoch 87/200, Iteration 137/250, Loss: 0.0082\n",
      "Epoch 87/200, Iteration 138/250, Loss: 0.0076\n",
      "Epoch 87/200, Iteration 139/250, Loss: 0.0161\n",
      "Epoch 87/200, Iteration 140/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 141/250, Loss: 0.0260\n",
      "Epoch 87/200, Iteration 142/250, Loss: 0.0199\n",
      "Epoch 87/200, Iteration 143/250, Loss: 0.0083\n",
      "Epoch 87/200, Iteration 144/250, Loss: 0.0073\n",
      "Epoch 87/200, Iteration 145/250, Loss: 0.0144\n",
      "Epoch 87/200, Iteration 146/250, Loss: 0.0317\n",
      "Epoch 87/200, Iteration 147/250, Loss: 0.0108\n",
      "Epoch 87/200, Iteration 148/250, Loss: 0.0114\n",
      "Epoch 87/200, Iteration 149/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 150/250, Loss: 0.0113\n",
      "Epoch 87/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 87/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 87/200, Iteration 153/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 154/250, Loss: 0.0283\n",
      "Epoch 87/200, Iteration 155/250, Loss: 0.0101\n",
      "Epoch 87/200, Iteration 156/250, Loss: 0.0173\n",
      "Epoch 87/200, Iteration 157/250, Loss: 0.0218\n",
      "Epoch 87/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 87/200, Iteration 159/250, Loss: 0.0066\n",
      "Epoch 87/200, Iteration 160/250, Loss: 0.0076\n",
      "Epoch 87/200, Iteration 161/250, Loss: 0.0126\n",
      "Epoch 87/200, Iteration 162/250, Loss: 0.0241\n",
      "Epoch 87/200, Iteration 163/250, Loss: 0.0072\n",
      "Epoch 87/200, Iteration 164/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 165/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 166/250, Loss: 0.0075\n",
      "Epoch 87/200, Iteration 167/250, Loss: 0.0226\n",
      "Epoch 87/200, Iteration 168/250, Loss: 0.0115\n",
      "Epoch 87/200, Iteration 169/250, Loss: 0.0205\n",
      "Epoch 87/200, Iteration 170/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 171/250, Loss: 0.0077\n",
      "Epoch 87/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 173/250, Loss: 0.0201\n",
      "Epoch 87/200, Iteration 174/250, Loss: 0.0414\n",
      "Epoch 87/200, Iteration 175/250, Loss: 0.0088\n",
      "Epoch 87/200, Iteration 176/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 177/250, Loss: 0.0106\n",
      "Epoch 87/200, Iteration 178/250, Loss: 0.0067\n",
      "Epoch 87/200, Iteration 179/250, Loss: 0.0086\n",
      "Epoch 87/200, Iteration 180/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 181/250, Loss: 0.0063\n",
      "Epoch 87/200, Iteration 182/250, Loss: 0.0244\n",
      "Epoch 87/200, Iteration 183/250, Loss: 0.0097\n",
      "Epoch 87/200, Iteration 184/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 185/250, Loss: 0.0190\n",
      "Epoch 87/200, Iteration 186/250, Loss: 0.0136\n",
      "Epoch 87/200, Iteration 187/250, Loss: 0.0208\n",
      "Epoch 87/200, Iteration 188/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 189/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 190/250, Loss: 0.0250\n",
      "Epoch 87/200, Iteration 191/250, Loss: 0.0090\n",
      "Epoch 87/200, Iteration 192/250, Loss: 0.0200\n",
      "Epoch 87/200, Iteration 193/250, Loss: 0.0082\n",
      "Epoch 87/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 87/200, Iteration 195/250, Loss: 0.0171\n",
      "Epoch 87/200, Iteration 196/250, Loss: 0.0189\n",
      "Epoch 87/200, Iteration 197/250, Loss: 0.0487\n",
      "Epoch 87/200, Iteration 198/250, Loss: 0.0059\n",
      "Epoch 87/200, Iteration 199/250, Loss: 0.0317\n",
      "Epoch 87/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 87/200, Iteration 202/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 203/250, Loss: 0.0077\n",
      "Epoch 87/200, Iteration 204/250, Loss: 0.0173\n",
      "Epoch 87/200, Iteration 205/250, Loss: 0.0218\n",
      "Epoch 87/200, Iteration 206/250, Loss: 0.0066\n",
      "Epoch 87/200, Iteration 207/250, Loss: 0.0112\n",
      "Epoch 87/200, Iteration 208/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 209/250, Loss: 0.0215\n",
      "Epoch 87/200, Iteration 210/250, Loss: 0.0131\n",
      "Epoch 87/200, Iteration 211/250, Loss: 0.0069\n",
      "Epoch 87/200, Iteration 212/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200, Iteration 213/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 214/250, Loss: 0.0174\n",
      "Epoch 87/200, Iteration 215/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 216/250, Loss: 0.0141\n",
      "Epoch 87/200, Iteration 217/250, Loss: 0.0173\n",
      "Epoch 87/200, Iteration 218/250, Loss: 0.0180\n",
      "Epoch 87/200, Iteration 219/250, Loss: 0.0169\n",
      "Epoch 87/200, Iteration 220/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 221/250, Loss: 0.0101\n",
      "Epoch 87/200, Iteration 222/250, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 223/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 224/250, Loss: 0.0193\n",
      "Epoch 87/200, Iteration 225/250, Loss: 0.0313\n",
      "Epoch 87/200, Iteration 226/250, Loss: 0.0273\n",
      "Epoch 87/200, Iteration 227/250, Loss: 0.0332\n",
      "Epoch 87/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 229/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 230/250, Loss: 0.0095\n",
      "Epoch 87/200, Iteration 231/250, Loss: 0.0211\n",
      "Epoch 87/200, Iteration 232/250, Loss: 0.0113\n",
      "Epoch 87/200, Iteration 233/250, Loss: 0.0077\n",
      "Epoch 87/200, Iteration 234/250, Loss: 0.0227\n",
      "Epoch 87/200, Iteration 235/250, Loss: 0.0227\n",
      "Epoch 87/200, Iteration 236/250, Loss: 0.0250\n",
      "Epoch 87/200, Iteration 237/250, Loss: 0.0129\n",
      "Epoch 87/200, Iteration 238/250, Loss: 0.0088\n",
      "Epoch 87/200, Iteration 239/250, Loss: 0.0257\n",
      "Epoch 87/200, Iteration 240/250, Loss: 0.0094\n",
      "Epoch 87/200, Iteration 241/250, Loss: 0.0197\n",
      "Epoch 87/200, Iteration 242/250, Loss: 0.0138\n",
      "Epoch 87/200, Iteration 243/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 244/250, Loss: 0.0141\n",
      "Epoch 87/200, Iteration 245/250, Loss: 0.0102\n",
      "Epoch 87/200, Iteration 246/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 247/250, Loss: 0.0064\n",
      "Epoch 87/200, Iteration 248/250, Loss: 0.0206\n",
      "Epoch 87/200, Iteration 249/250, Loss: 0.0283\n",
      "Epoch 87/200, Iteration 250/250, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 91.53%, Avg loss: 0.006188, MRE: 0.606539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.75%, Avg loss: 0.006204, MRE: 0.866407 \n",
      "\n",
      "Epoch 88/200, Iteration 1/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 2/250, Loss: 0.0235\n",
      "Epoch 88/200, Iteration 3/250, Loss: 0.0133\n",
      "Epoch 88/200, Iteration 4/250, Loss: 0.0135\n",
      "Epoch 88/200, Iteration 5/250, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 6/250, Loss: 0.0150\n",
      "Epoch 88/200, Iteration 7/250, Loss: 0.0163\n",
      "Epoch 88/200, Iteration 8/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 9/250, Loss: 0.0100\n",
      "Epoch 88/200, Iteration 10/250, Loss: 0.0378\n",
      "Epoch 88/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 88/200, Iteration 12/250, Loss: 0.0113\n",
      "Epoch 88/200, Iteration 13/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 14/250, Loss: 0.0156\n",
      "Epoch 88/200, Iteration 15/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 16/250, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 17/250, Loss: 0.0117\n",
      "Epoch 88/200, Iteration 18/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 19/250, Loss: 0.0169\n",
      "Epoch 88/200, Iteration 20/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 21/250, Loss: 0.0215\n",
      "Epoch 88/200, Iteration 22/250, Loss: 0.0104\n",
      "Epoch 88/200, Iteration 23/250, Loss: 0.0126\n",
      "Epoch 88/200, Iteration 24/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 25/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 26/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 27/250, Loss: 0.0164\n",
      "Epoch 88/200, Iteration 28/250, Loss: 0.0273\n",
      "Epoch 88/200, Iteration 29/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 30/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 31/250, Loss: 0.0215\n",
      "Epoch 88/200, Iteration 32/250, Loss: 0.0163\n",
      "Epoch 88/200, Iteration 33/250, Loss: 0.0286\n",
      "Epoch 88/200, Iteration 34/250, Loss: 0.0128\n",
      "Epoch 88/200, Iteration 35/250, Loss: 0.0116\n",
      "Epoch 88/200, Iteration 36/250, Loss: 0.0165\n",
      "Epoch 88/200, Iteration 37/250, Loss: 0.0105\n",
      "Epoch 88/200, Iteration 38/250, Loss: 0.0078\n",
      "Epoch 88/200, Iteration 39/250, Loss: 0.0209\n",
      "Epoch 88/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 41/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 42/250, Loss: 0.0097\n",
      "Epoch 88/200, Iteration 43/250, Loss: 0.0062\n",
      "Epoch 88/200, Iteration 44/250, Loss: 0.0231\n",
      "Epoch 88/200, Iteration 45/250, Loss: 0.0113\n",
      "Epoch 88/200, Iteration 46/250, Loss: 0.0102\n",
      "Epoch 88/200, Iteration 47/250, Loss: 0.0222\n",
      "Epoch 88/200, Iteration 48/250, Loss: 0.0066\n",
      "Epoch 88/200, Iteration 49/250, Loss: 0.0084\n",
      "Epoch 88/200, Iteration 50/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 88/200, Iteration 52/250, Loss: 0.0072\n",
      "Epoch 88/200, Iteration 53/250, Loss: 0.0234\n",
      "Epoch 88/200, Iteration 54/250, Loss: 0.0151\n",
      "Epoch 88/200, Iteration 55/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 88/200, Iteration 57/250, Loss: 0.0408\n",
      "Epoch 88/200, Iteration 58/250, Loss: 0.0228\n",
      "Epoch 88/200, Iteration 59/250, Loss: 0.0140\n",
      "Epoch 88/200, Iteration 60/250, Loss: 0.0296\n",
      "Epoch 88/200, Iteration 61/250, Loss: 0.0243\n",
      "Epoch 88/200, Iteration 62/250, Loss: 0.0196\n",
      "Epoch 88/200, Iteration 63/250, Loss: 0.0267\n",
      "Epoch 88/200, Iteration 64/250, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 65/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 88/200, Iteration 67/250, Loss: 0.0115\n",
      "Epoch 88/200, Iteration 68/250, Loss: 0.0072\n",
      "Epoch 88/200, Iteration 69/250, Loss: 0.0130\n",
      "Epoch 88/200, Iteration 70/250, Loss: 0.0089\n",
      "Epoch 88/200, Iteration 71/250, Loss: 0.0234\n",
      "Epoch 88/200, Iteration 72/250, Loss: 0.0130\n",
      "Epoch 88/200, Iteration 73/250, Loss: 0.0112\n",
      "Epoch 88/200, Iteration 74/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 75/250, Loss: 0.0108\n",
      "Epoch 88/200, Iteration 76/250, Loss: 0.0220\n",
      "Epoch 88/200, Iteration 77/250, Loss: 0.0327\n",
      "Epoch 88/200, Iteration 78/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 79/250, Loss: 0.0185\n",
      "Epoch 88/200, Iteration 80/250, Loss: 0.0347\n",
      "Epoch 88/200, Iteration 81/250, Loss: 0.0083\n",
      "Epoch 88/200, Iteration 82/250, Loss: 0.0167\n",
      "Epoch 88/200, Iteration 83/250, Loss: 0.0094\n",
      "Epoch 88/200, Iteration 84/250, Loss: 0.0116\n",
      "Epoch 88/200, Iteration 85/250, Loss: 0.0074\n",
      "Epoch 88/200, Iteration 86/250, Loss: 0.0095\n",
      "Epoch 88/200, Iteration 87/250, Loss: 0.0268\n",
      "Epoch 88/200, Iteration 88/250, Loss: 0.0223\n",
      "Epoch 88/200, Iteration 89/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 90/250, Loss: 0.0084\n",
      "Epoch 88/200, Iteration 91/250, Loss: 0.0197\n",
      "Epoch 88/200, Iteration 92/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 93/250, Loss: 0.0224\n",
      "Epoch 88/200, Iteration 94/250, Loss: 0.0165\n",
      "Epoch 88/200, Iteration 95/250, Loss: 0.0349\n",
      "Epoch 88/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 97/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 98/250, Loss: 0.0220\n",
      "Epoch 88/200, Iteration 99/250, Loss: 0.0230\n",
      "Epoch 88/200, Iteration 100/250, Loss: 0.0106\n",
      "Epoch 88/200, Iteration 101/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 102/250, Loss: 0.0097\n",
      "Epoch 88/200, Iteration 103/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 88/200, Iteration 105/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 106/250, Loss: 0.0170\n",
      "Epoch 88/200, Iteration 107/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 109/250, Loss: 0.0102\n",
      "Epoch 88/200, Iteration 110/250, Loss: 0.0308\n",
      "Epoch 88/200, Iteration 111/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 113/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 114/250, Loss: 0.0179\n",
      "Epoch 88/200, Iteration 115/250, Loss: 0.0175\n",
      "Epoch 88/200, Iteration 116/250, Loss: 0.0161\n",
      "Epoch 88/200, Iteration 117/250, Loss: 0.0161\n",
      "Epoch 88/200, Iteration 118/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 119/250, Loss: 0.0105\n",
      "Epoch 88/200, Iteration 120/250, Loss: 0.0106\n",
      "Epoch 88/200, Iteration 121/250, Loss: 0.0084\n",
      "Epoch 88/200, Iteration 122/250, Loss: 0.0067\n",
      "Epoch 88/200, Iteration 123/250, Loss: 0.0143\n",
      "Epoch 88/200, Iteration 124/250, Loss: 0.0125\n",
      "Epoch 88/200, Iteration 125/250, Loss: 0.0067\n",
      "Epoch 88/200, Iteration 126/250, Loss: 0.0224\n",
      "Epoch 88/200, Iteration 127/250, Loss: 0.0074\n",
      "Epoch 88/200, Iteration 128/250, Loss: 0.0324\n",
      "Epoch 88/200, Iteration 129/250, Loss: 0.0173\n",
      "Epoch 88/200, Iteration 130/250, Loss: 0.0061\n",
      "Epoch 88/200, Iteration 131/250, Loss: 0.0171\n",
      "Epoch 88/200, Iteration 132/250, Loss: 0.0205\n",
      "Epoch 88/200, Iteration 133/250, Loss: 0.0086\n",
      "Epoch 88/200, Iteration 134/250, Loss: 0.0075\n",
      "Epoch 88/200, Iteration 135/250, Loss: 0.0122\n",
      "Epoch 88/200, Iteration 136/250, Loss: 0.0076\n",
      "Epoch 88/200, Iteration 137/250, Loss: 0.0362\n",
      "Epoch 88/200, Iteration 138/250, Loss: 0.0098\n",
      "Epoch 88/200, Iteration 139/250, Loss: 0.0101\n",
      "Epoch 88/200, Iteration 140/250, Loss: 0.0172\n",
      "Epoch 88/200, Iteration 141/250, Loss: 0.0173\n",
      "Epoch 88/200, Iteration 142/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 143/250, Loss: 0.0176\n",
      "Epoch 88/200, Iteration 144/250, Loss: 0.0203\n",
      "Epoch 88/200, Iteration 145/250, Loss: 0.0171\n",
      "Epoch 88/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 88/200, Iteration 147/250, Loss: 0.0083\n",
      "Epoch 88/200, Iteration 148/250, Loss: 0.0194\n",
      "Epoch 88/200, Iteration 149/250, Loss: 0.0140\n",
      "Epoch 88/200, Iteration 150/250, Loss: 0.0092\n",
      "Epoch 88/200, Iteration 151/250, Loss: 0.0183\n",
      "Epoch 88/200, Iteration 152/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 153/250, Loss: 0.0066\n",
      "Epoch 88/200, Iteration 154/250, Loss: 0.0076\n",
      "Epoch 88/200, Iteration 155/250, Loss: 0.0199\n",
      "Epoch 88/200, Iteration 156/250, Loss: 0.0302\n",
      "Epoch 88/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 158/250, Loss: 0.0142\n",
      "Epoch 88/200, Iteration 159/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 161/250, Loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200, Iteration 162/250, Loss: 0.0241\n",
      "Epoch 88/200, Iteration 163/250, Loss: 0.0145\n",
      "Epoch 88/200, Iteration 164/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 165/250, Loss: 0.0081\n",
      "Epoch 88/200, Iteration 166/250, Loss: 0.0426\n",
      "Epoch 88/200, Iteration 167/250, Loss: 0.0127\n",
      "Epoch 88/200, Iteration 168/250, Loss: 0.0116\n",
      "Epoch 88/200, Iteration 169/250, Loss: 0.0189\n",
      "Epoch 88/200, Iteration 170/250, Loss: 0.0150\n",
      "Epoch 88/200, Iteration 171/250, Loss: 0.0128\n",
      "Epoch 88/200, Iteration 172/250, Loss: 0.0060\n",
      "Epoch 88/200, Iteration 173/250, Loss: 0.0154\n",
      "Epoch 88/200, Iteration 174/250, Loss: 0.0268\n",
      "Epoch 88/200, Iteration 175/250, Loss: 0.0144\n",
      "Epoch 88/200, Iteration 176/250, Loss: 0.0242\n",
      "Epoch 88/200, Iteration 177/250, Loss: 0.0177\n",
      "Epoch 88/200, Iteration 178/250, Loss: 0.0083\n",
      "Epoch 88/200, Iteration 179/250, Loss: 0.0080\n",
      "Epoch 88/200, Iteration 180/250, Loss: 0.0157\n",
      "Epoch 88/200, Iteration 181/250, Loss: 0.0078\n",
      "Epoch 88/200, Iteration 182/250, Loss: 0.0130\n",
      "Epoch 88/200, Iteration 183/250, Loss: 0.0093\n",
      "Epoch 88/200, Iteration 184/250, Loss: 0.0122\n",
      "Epoch 88/200, Iteration 185/250, Loss: 0.0091\n",
      "Epoch 88/200, Iteration 186/250, Loss: 0.0264\n",
      "Epoch 88/200, Iteration 187/250, Loss: 0.0221\n",
      "Epoch 88/200, Iteration 188/250, Loss: 0.0220\n",
      "Epoch 88/200, Iteration 189/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 190/250, Loss: 0.0239\n",
      "Epoch 88/200, Iteration 191/250, Loss: 0.0080\n",
      "Epoch 88/200, Iteration 192/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 193/250, Loss: 0.0324\n",
      "Epoch 88/200, Iteration 194/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 195/250, Loss: 0.0059\n",
      "Epoch 88/200, Iteration 196/250, Loss: 0.0150\n",
      "Epoch 88/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 88/200, Iteration 198/250, Loss: 0.0163\n",
      "Epoch 88/200, Iteration 199/250, Loss: 0.0180\n",
      "Epoch 88/200, Iteration 200/250, Loss: 0.0245\n",
      "Epoch 88/200, Iteration 201/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 202/250, Loss: 0.0182\n",
      "Epoch 88/200, Iteration 203/250, Loss: 0.0144\n",
      "Epoch 88/200, Iteration 204/250, Loss: 0.0101\n",
      "Epoch 88/200, Iteration 205/250, Loss: 0.0207\n",
      "Epoch 88/200, Iteration 206/250, Loss: 0.0142\n",
      "Epoch 88/200, Iteration 207/250, Loss: 0.0122\n",
      "Epoch 88/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 209/250, Loss: 0.0195\n",
      "Epoch 88/200, Iteration 210/250, Loss: 0.0407\n",
      "Epoch 88/200, Iteration 211/250, Loss: 0.0275\n",
      "Epoch 88/200, Iteration 212/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 213/250, Loss: 0.0398\n",
      "Epoch 88/200, Iteration 214/250, Loss: 0.0185\n",
      "Epoch 88/200, Iteration 215/250, Loss: 0.0258\n",
      "Epoch 88/200, Iteration 216/250, Loss: 0.0134\n",
      "Epoch 88/200, Iteration 217/250, Loss: 0.0200\n",
      "Epoch 88/200, Iteration 218/250, Loss: 0.0154\n",
      "Epoch 88/200, Iteration 219/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 220/250, Loss: 0.0233\n",
      "Epoch 88/200, Iteration 221/250, Loss: 0.0113\n",
      "Epoch 88/200, Iteration 222/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 223/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 224/250, Loss: 0.0117\n",
      "Epoch 88/200, Iteration 225/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 226/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 227/250, Loss: 0.0101\n",
      "Epoch 88/200, Iteration 228/250, Loss: 0.0193\n",
      "Epoch 88/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 230/250, Loss: 0.0227\n",
      "Epoch 88/200, Iteration 231/250, Loss: 0.0343\n",
      "Epoch 88/200, Iteration 232/250, Loss: 0.0063\n",
      "Epoch 88/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 88/200, Iteration 234/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 235/250, Loss: 0.0098\n",
      "Epoch 88/200, Iteration 236/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 237/250, Loss: 0.0112\n",
      "Epoch 88/200, Iteration 238/250, Loss: 0.0106\n",
      "Epoch 88/200, Iteration 239/250, Loss: 0.0230\n",
      "Epoch 88/200, Iteration 240/250, Loss: 0.0189\n",
      "Epoch 88/200, Iteration 241/250, Loss: 0.0125\n",
      "Epoch 88/200, Iteration 242/250, Loss: 0.0075\n",
      "Epoch 88/200, Iteration 243/250, Loss: 0.0166\n",
      "Epoch 88/200, Iteration 244/250, Loss: 0.0074\n",
      "Epoch 88/200, Iteration 245/250, Loss: 0.0153\n",
      "Epoch 88/200, Iteration 246/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 247/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 248/250, Loss: 0.0127\n",
      "Epoch 88/200, Iteration 249/250, Loss: 0.0345\n",
      "Epoch 88/200, Iteration 250/250, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.006084, MRE: 0.623472 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.006060, MRE: 1.041214 \n",
      "\n",
      "Epoch 89/200, Iteration 1/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 2/250, Loss: 0.0079\n",
      "Epoch 89/200, Iteration 3/250, Loss: 0.0166\n",
      "Epoch 89/200, Iteration 4/250, Loss: 0.0226\n",
      "Epoch 89/200, Iteration 5/250, Loss: 0.0054\n",
      "Epoch 89/200, Iteration 6/250, Loss: 0.0071\n",
      "Epoch 89/200, Iteration 7/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 8/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 9/250, Loss: 0.0113\n",
      "Epoch 89/200, Iteration 10/250, Loss: 0.0152\n",
      "Epoch 89/200, Iteration 11/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 12/250, Loss: 0.0171\n",
      "Epoch 89/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 89/200, Iteration 14/250, Loss: 0.0098\n",
      "Epoch 89/200, Iteration 15/250, Loss: 0.0258\n",
      "Epoch 89/200, Iteration 16/250, Loss: 0.0310\n",
      "Epoch 89/200, Iteration 17/250, Loss: 0.0058\n",
      "Epoch 89/200, Iteration 18/250, Loss: 0.0150\n",
      "Epoch 89/200, Iteration 19/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 20/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 21/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 22/250, Loss: 0.0126\n",
      "Epoch 89/200, Iteration 23/250, Loss: 0.0156\n",
      "Epoch 89/200, Iteration 24/250, Loss: 0.0083\n",
      "Epoch 89/200, Iteration 25/250, Loss: 0.0090\n",
      "Epoch 89/200, Iteration 26/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 27/250, Loss: 0.0129\n",
      "Epoch 89/200, Iteration 28/250, Loss: 0.0163\n",
      "Epoch 89/200, Iteration 29/250, Loss: 0.0258\n",
      "Epoch 89/200, Iteration 30/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 31/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 33/250, Loss: 0.0095\n",
      "Epoch 89/200, Iteration 34/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 35/250, Loss: 0.0140\n",
      "Epoch 89/200, Iteration 36/250, Loss: 0.0115\n",
      "Epoch 89/200, Iteration 37/250, Loss: 0.0191\n",
      "Epoch 89/200, Iteration 38/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 39/250, Loss: 0.0146\n",
      "Epoch 89/200, Iteration 40/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 41/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 42/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 43/250, Loss: 0.0202\n",
      "Epoch 89/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 45/250, Loss: 0.0165\n",
      "Epoch 89/200, Iteration 46/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 47/250, Loss: 0.0115\n",
      "Epoch 89/200, Iteration 48/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 49/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 50/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 51/250, Loss: 0.0083\n",
      "Epoch 89/200, Iteration 52/250, Loss: 0.0122\n",
      "Epoch 89/200, Iteration 53/250, Loss: 0.0146\n",
      "Epoch 89/200, Iteration 54/250, Loss: 0.0060\n",
      "Epoch 89/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 56/250, Loss: 0.0084\n",
      "Epoch 89/200, Iteration 57/250, Loss: 0.0082\n",
      "Epoch 89/200, Iteration 58/250, Loss: 0.0093\n",
      "Epoch 89/200, Iteration 59/250, Loss: 0.0142\n",
      "Epoch 89/200, Iteration 60/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 61/250, Loss: 0.0125\n",
      "Epoch 89/200, Iteration 62/250, Loss: 0.0155\n",
      "Epoch 89/200, Iteration 63/250, Loss: 0.0165\n",
      "Epoch 89/200, Iteration 64/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 65/250, Loss: 0.0247\n",
      "Epoch 89/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 89/200, Iteration 67/250, Loss: 0.0108\n",
      "Epoch 89/200, Iteration 68/250, Loss: 0.0146\n",
      "Epoch 89/200, Iteration 69/250, Loss: 0.0075\n",
      "Epoch 89/200, Iteration 70/250, Loss: 0.0150\n",
      "Epoch 89/200, Iteration 71/250, Loss: 0.0170\n",
      "Epoch 89/200, Iteration 72/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 73/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 74/250, Loss: 0.0098\n",
      "Epoch 89/200, Iteration 75/250, Loss: 0.0122\n",
      "Epoch 89/200, Iteration 76/250, Loss: 0.0219\n",
      "Epoch 89/200, Iteration 77/250, Loss: 0.0244\n",
      "Epoch 89/200, Iteration 78/250, Loss: 0.0383\n",
      "Epoch 89/200, Iteration 79/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 80/250, Loss: 0.0305\n",
      "Epoch 89/200, Iteration 81/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 82/250, Loss: 0.0105\n",
      "Epoch 89/200, Iteration 83/250, Loss: 0.0075\n",
      "Epoch 89/200, Iteration 84/250, Loss: 0.0122\n",
      "Epoch 89/200, Iteration 85/250, Loss: 0.0227\n",
      "Epoch 89/200, Iteration 86/250, Loss: 0.0096\n",
      "Epoch 89/200, Iteration 87/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 88/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 89/250, Loss: 0.0199\n",
      "Epoch 89/200, Iteration 90/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 91/250, Loss: 0.0148\n",
      "Epoch 89/200, Iteration 92/250, Loss: 0.0332\n",
      "Epoch 89/200, Iteration 93/250, Loss: 0.0315\n",
      "Epoch 89/200, Iteration 94/250, Loss: 0.0073\n",
      "Epoch 89/200, Iteration 95/250, Loss: 0.0197\n",
      "Epoch 89/200, Iteration 96/250, Loss: 0.0206\n",
      "Epoch 89/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 89/200, Iteration 98/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 99/250, Loss: 0.0158\n",
      "Epoch 89/200, Iteration 100/250, Loss: 0.0186\n",
      "Epoch 89/200, Iteration 101/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 102/250, Loss: 0.0141\n",
      "Epoch 89/200, Iteration 103/250, Loss: 0.0142\n",
      "Epoch 89/200, Iteration 104/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 105/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 106/250, Loss: 0.0121\n",
      "Epoch 89/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 108/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 109/250, Loss: 0.0208\n",
      "Epoch 89/200, Iteration 110/250, Loss: 0.0090\n",
      "Epoch 89/200, Iteration 111/250, Loss: 0.0275\n",
      "Epoch 89/200, Iteration 112/250, Loss: 0.0218\n",
      "Epoch 89/200, Iteration 113/250, Loss: 0.0206\n",
      "Epoch 89/200, Iteration 114/250, Loss: 0.0115\n",
      "Epoch 89/200, Iteration 115/250, Loss: 0.0082\n",
      "Epoch 89/200, Iteration 116/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 117/250, Loss: 0.0088\n",
      "Epoch 89/200, Iteration 118/250, Loss: 0.0158\n",
      "Epoch 89/200, Iteration 119/250, Loss: 0.0097\n",
      "Epoch 89/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 89/200, Iteration 121/250, Loss: 0.0071\n",
      "Epoch 89/200, Iteration 122/250, Loss: 0.0164\n",
      "Epoch 89/200, Iteration 123/250, Loss: 0.0153\n",
      "Epoch 89/200, Iteration 124/250, Loss: 0.0062\n",
      "Epoch 89/200, Iteration 125/250, Loss: 0.0216\n",
      "Epoch 89/200, Iteration 126/250, Loss: 0.0096\n",
      "Epoch 89/200, Iteration 127/250, Loss: 0.0160\n",
      "Epoch 89/200, Iteration 128/250, Loss: 0.0200\n",
      "Epoch 89/200, Iteration 129/250, Loss: 0.0104\n",
      "Epoch 89/200, Iteration 130/250, Loss: 0.0147\n",
      "Epoch 89/200, Iteration 131/250, Loss: 0.0184\n",
      "Epoch 89/200, Iteration 132/250, Loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200, Iteration 133/250, Loss: 0.0171\n",
      "Epoch 89/200, Iteration 134/250, Loss: 0.0123\n",
      "Epoch 89/200, Iteration 135/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 136/250, Loss: 0.0439\n",
      "Epoch 89/200, Iteration 137/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 138/250, Loss: 0.0128\n",
      "Epoch 89/200, Iteration 139/250, Loss: 0.0248\n",
      "Epoch 89/200, Iteration 140/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 142/250, Loss: 0.0077\n",
      "Epoch 89/200, Iteration 143/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 144/250, Loss: 0.0230\n",
      "Epoch 89/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 146/250, Loss: 0.0114\n",
      "Epoch 89/200, Iteration 147/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 148/250, Loss: 0.0193\n",
      "Epoch 89/200, Iteration 149/250, Loss: 0.0190\n",
      "Epoch 89/200, Iteration 150/250, Loss: 0.0102\n",
      "Epoch 89/200, Iteration 151/250, Loss: 0.0080\n",
      "Epoch 89/200, Iteration 152/250, Loss: 0.0192\n",
      "Epoch 89/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 154/250, Loss: 0.0215\n",
      "Epoch 89/200, Iteration 155/250, Loss: 0.0156\n",
      "Epoch 89/200, Iteration 156/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 157/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 158/250, Loss: 0.0299\n",
      "Epoch 89/200, Iteration 159/250, Loss: 0.0185\n",
      "Epoch 89/200, Iteration 160/250, Loss: 0.0148\n",
      "Epoch 89/200, Iteration 161/250, Loss: 0.0377\n",
      "Epoch 89/200, Iteration 162/250, Loss: 0.0186\n",
      "Epoch 89/200, Iteration 163/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 164/250, Loss: 0.0125\n",
      "Epoch 89/200, Iteration 165/250, Loss: 0.0169\n",
      "Epoch 89/200, Iteration 166/250, Loss: 0.0195\n",
      "Epoch 89/200, Iteration 167/250, Loss: 0.0246\n",
      "Epoch 89/200, Iteration 168/250, Loss: 0.0124\n",
      "Epoch 89/200, Iteration 169/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 170/250, Loss: 0.0365\n",
      "Epoch 89/200, Iteration 171/250, Loss: 0.0291\n",
      "Epoch 89/200, Iteration 172/250, Loss: 0.0318\n",
      "Epoch 89/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 174/250, Loss: 0.0090\n",
      "Epoch 89/200, Iteration 175/250, Loss: 0.0219\n",
      "Epoch 89/200, Iteration 176/250, Loss: 0.0137\n",
      "Epoch 89/200, Iteration 177/250, Loss: 0.0265\n",
      "Epoch 89/200, Iteration 178/250, Loss: 0.0126\n",
      "Epoch 89/200, Iteration 179/250, Loss: 0.0118\n",
      "Epoch 89/200, Iteration 180/250, Loss: 0.0365\n",
      "Epoch 89/200, Iteration 181/250, Loss: 0.0080\n",
      "Epoch 89/200, Iteration 182/250, Loss: 0.0082\n",
      "Epoch 89/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 184/250, Loss: 0.0053\n",
      "Epoch 89/200, Iteration 185/250, Loss: 0.0202\n",
      "Epoch 89/200, Iteration 186/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 187/250, Loss: 0.0177\n",
      "Epoch 89/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 189/250, Loss: 0.0180\n",
      "Epoch 89/200, Iteration 190/250, Loss: 0.0233\n",
      "Epoch 89/200, Iteration 191/250, Loss: 0.0149\n",
      "Epoch 89/200, Iteration 192/250, Loss: 0.0161\n",
      "Epoch 89/200, Iteration 193/250, Loss: 0.0179\n",
      "Epoch 89/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 195/250, Loss: 0.0079\n",
      "Epoch 89/200, Iteration 196/250, Loss: 0.0063\n",
      "Epoch 89/200, Iteration 197/250, Loss: 0.0242\n",
      "Epoch 89/200, Iteration 198/250, Loss: 0.0212\n",
      "Epoch 89/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 89/200, Iteration 200/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 201/250, Loss: 0.0286\n",
      "Epoch 89/200, Iteration 202/250, Loss: 0.0110\n",
      "Epoch 89/200, Iteration 203/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 89/200, Iteration 205/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 206/250, Loss: 0.0091\n",
      "Epoch 89/200, Iteration 207/250, Loss: 0.0135\n",
      "Epoch 89/200, Iteration 208/250, Loss: 0.0065\n",
      "Epoch 89/200, Iteration 209/250, Loss: 0.0374\n",
      "Epoch 89/200, Iteration 210/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 211/250, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 212/250, Loss: 0.0121\n",
      "Epoch 89/200, Iteration 213/250, Loss: 0.0298\n",
      "Epoch 89/200, Iteration 214/250, Loss: 0.0103\n",
      "Epoch 89/200, Iteration 215/250, Loss: 0.0083\n",
      "Epoch 89/200, Iteration 216/250, Loss: 0.0219\n",
      "Epoch 89/200, Iteration 217/250, Loss: 0.0180\n",
      "Epoch 89/200, Iteration 218/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 89/200, Iteration 220/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 221/250, Loss: 0.0266\n",
      "Epoch 89/200, Iteration 222/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 223/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 224/250, Loss: 0.0246\n",
      "Epoch 89/200, Iteration 225/250, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 226/250, Loss: 0.0225\n",
      "Epoch 89/200, Iteration 227/250, Loss: 0.0072\n",
      "Epoch 89/200, Iteration 228/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 229/250, Loss: 0.0144\n",
      "Epoch 89/200, Iteration 230/250, Loss: 0.0095\n",
      "Epoch 89/200, Iteration 231/250, Loss: 0.0210\n",
      "Epoch 89/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 89/200, Iteration 233/250, Loss: 0.0278\n",
      "Epoch 89/200, Iteration 234/250, Loss: 0.0253\n",
      "Epoch 89/200, Iteration 235/250, Loss: 0.0240\n",
      "Epoch 89/200, Iteration 236/250, Loss: 0.0104\n",
      "Epoch 89/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 238/250, Loss: 0.0077\n",
      "Epoch 89/200, Iteration 239/250, Loss: 0.0233\n",
      "Epoch 89/200, Iteration 240/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 241/250, Loss: 0.0091\n",
      "Epoch 89/200, Iteration 242/250, Loss: 0.0105\n",
      "Epoch 89/200, Iteration 243/250, Loss: 0.0160\n",
      "Epoch 89/200, Iteration 244/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 245/250, Loss: 0.0145\n",
      "Epoch 89/200, Iteration 246/250, Loss: 0.0180\n",
      "Epoch 89/200, Iteration 247/250, Loss: 0.0159\n",
      "Epoch 89/200, Iteration 248/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 249/250, Loss: 0.0155\n",
      "Epoch 89/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 94.97%, Avg loss: 0.006039, MRE: 0.632959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.55%, Avg loss: 0.006030, MRE: 1.050673 \n",
      "\n",
      "Epoch 90/200, Iteration 1/250, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 2/250, Loss: 0.0218\n",
      "Epoch 90/200, Iteration 3/250, Loss: 0.0230\n",
      "Epoch 90/200, Iteration 4/250, Loss: 0.0075\n",
      "Epoch 90/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 6/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 7/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 8/250, Loss: 0.0111\n",
      "Epoch 90/200, Iteration 9/250, Loss: 0.0241\n",
      "Epoch 90/200, Iteration 10/250, Loss: 0.0410\n",
      "Epoch 90/200, Iteration 11/250, Loss: 0.0065\n",
      "Epoch 90/200, Iteration 12/250, Loss: 0.0118\n",
      "Epoch 90/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 90/200, Iteration 14/250, Loss: 0.0125\n",
      "Epoch 90/200, Iteration 15/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 16/250, Loss: 0.0325\n",
      "Epoch 90/200, Iteration 17/250, Loss: 0.0189\n",
      "Epoch 90/200, Iteration 18/250, Loss: 0.0150\n",
      "Epoch 90/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 90/200, Iteration 20/250, Loss: 0.0159\n",
      "Epoch 90/200, Iteration 21/250, Loss: 0.0109\n",
      "Epoch 90/200, Iteration 22/250, Loss: 0.0096\n",
      "Epoch 90/200, Iteration 23/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 24/250, Loss: 0.0184\n",
      "Epoch 90/200, Iteration 25/250, Loss: 0.0093\n",
      "Epoch 90/200, Iteration 26/250, Loss: 0.0227\n",
      "Epoch 90/200, Iteration 27/250, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 28/250, Loss: 0.0231\n",
      "Epoch 90/200, Iteration 29/250, Loss: 0.0115\n",
      "Epoch 90/200, Iteration 30/250, Loss: 0.0163\n",
      "Epoch 90/200, Iteration 31/250, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 33/250, Loss: 0.0123\n",
      "Epoch 90/200, Iteration 34/250, Loss: 0.0185\n",
      "Epoch 90/200, Iteration 35/250, Loss: 0.0182\n",
      "Epoch 90/200, Iteration 36/250, Loss: 0.0108\n",
      "Epoch 90/200, Iteration 37/250, Loss: 0.0192\n",
      "Epoch 90/200, Iteration 38/250, Loss: 0.0209\n",
      "Epoch 90/200, Iteration 39/250, Loss: 0.0082\n",
      "Epoch 90/200, Iteration 40/250, Loss: 0.0202\n",
      "Epoch 90/200, Iteration 41/250, Loss: 0.0172\n",
      "Epoch 90/200, Iteration 42/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 43/250, Loss: 0.0260\n",
      "Epoch 90/200, Iteration 44/250, Loss: 0.0343\n",
      "Epoch 90/200, Iteration 45/250, Loss: 0.0203\n",
      "Epoch 90/200, Iteration 46/250, Loss: 0.0313\n",
      "Epoch 90/200, Iteration 47/250, Loss: 0.0076\n",
      "Epoch 90/200, Iteration 48/250, Loss: 0.0064\n",
      "Epoch 90/200, Iteration 49/250, Loss: 0.0088\n",
      "Epoch 90/200, Iteration 50/250, Loss: 0.0321\n",
      "Epoch 90/200, Iteration 51/250, Loss: 0.0108\n",
      "Epoch 90/200, Iteration 52/250, Loss: 0.0065\n",
      "Epoch 90/200, Iteration 53/250, Loss: 0.0156\n",
      "Epoch 90/200, Iteration 54/250, Loss: 0.0076\n",
      "Epoch 90/200, Iteration 55/250, Loss: 0.0162\n",
      "Epoch 90/200, Iteration 56/250, Loss: 0.0270\n",
      "Epoch 90/200, Iteration 57/250, Loss: 0.0190\n",
      "Epoch 90/200, Iteration 58/250, Loss: 0.0142\n",
      "Epoch 90/200, Iteration 59/250, Loss: 0.0170\n",
      "Epoch 90/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 61/250, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 62/250, Loss: 0.0118\n",
      "Epoch 90/200, Iteration 63/250, Loss: 0.0304\n",
      "Epoch 90/200, Iteration 64/250, Loss: 0.0109\n",
      "Epoch 90/200, Iteration 65/250, Loss: 0.0203\n",
      "Epoch 90/200, Iteration 66/250, Loss: 0.0195\n",
      "Epoch 90/200, Iteration 67/250, Loss: 0.0245\n",
      "Epoch 90/200, Iteration 68/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 69/250, Loss: 0.0151\n",
      "Epoch 90/200, Iteration 70/250, Loss: 0.0343\n",
      "Epoch 90/200, Iteration 71/250, Loss: 0.0231\n",
      "Epoch 90/200, Iteration 72/250, Loss: 0.0279\n",
      "Epoch 90/200, Iteration 73/250, Loss: 0.0148\n",
      "Epoch 90/200, Iteration 74/250, Loss: 0.0242\n",
      "Epoch 90/200, Iteration 75/250, Loss: 0.0285\n",
      "Epoch 90/200, Iteration 76/250, Loss: 0.0130\n",
      "Epoch 90/200, Iteration 77/250, Loss: 0.0097\n",
      "Epoch 90/200, Iteration 78/250, Loss: 0.0208\n",
      "Epoch 90/200, Iteration 79/250, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 80/250, Loss: 0.0231\n",
      "Epoch 90/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 90/200, Iteration 82/250, Loss: 0.0245\n",
      "Epoch 90/200, Iteration 83/250, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 84/250, Loss: 0.0168\n",
      "Epoch 90/200, Iteration 85/250, Loss: 0.0174\n",
      "Epoch 90/200, Iteration 86/250, Loss: 0.0160\n",
      "Epoch 90/200, Iteration 87/250, Loss: 0.0066\n",
      "Epoch 90/200, Iteration 88/250, Loss: 0.0215\n",
      "Epoch 90/200, Iteration 89/250, Loss: 0.0250\n",
      "Epoch 90/200, Iteration 90/250, Loss: 0.0165\n",
      "Epoch 90/200, Iteration 91/250, Loss: 0.0129\n",
      "Epoch 90/200, Iteration 92/250, Loss: 0.0099\n",
      "Epoch 90/200, Iteration 93/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 94/250, Loss: 0.0165\n",
      "Epoch 90/200, Iteration 95/250, Loss: 0.0183\n",
      "Epoch 90/200, Iteration 96/250, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 97/250, Loss: 0.0381\n",
      "Epoch 90/200, Iteration 98/250, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200, Iteration 99/250, Loss: 0.0308\n",
      "Epoch 90/200, Iteration 100/250, Loss: 0.0102\n",
      "Epoch 90/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 90/200, Iteration 102/250, Loss: 0.0170\n",
      "Epoch 90/200, Iteration 103/250, Loss: 0.0121\n",
      "Epoch 90/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 90/200, Iteration 105/250, Loss: 0.0210\n",
      "Epoch 90/200, Iteration 106/250, Loss: 0.0160\n",
      "Epoch 90/200, Iteration 107/250, Loss: 0.0141\n",
      "Epoch 90/200, Iteration 108/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 90/200, Iteration 110/250, Loss: 0.0078\n",
      "Epoch 90/200, Iteration 111/250, Loss: 0.0129\n",
      "Epoch 90/200, Iteration 112/250, Loss: 0.0283\n",
      "Epoch 90/200, Iteration 113/250, Loss: 0.0266\n",
      "Epoch 90/200, Iteration 114/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 115/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 116/250, Loss: 0.0162\n",
      "Epoch 90/200, Iteration 117/250, Loss: 0.0089\n",
      "Epoch 90/200, Iteration 118/250, Loss: 0.0270\n",
      "Epoch 90/200, Iteration 119/250, Loss: 0.0214\n",
      "Epoch 90/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 90/200, Iteration 121/250, Loss: 0.0116\n",
      "Epoch 90/200, Iteration 122/250, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 123/250, Loss: 0.0089\n",
      "Epoch 90/200, Iteration 124/250, Loss: 0.0141\n",
      "Epoch 90/200, Iteration 125/250, Loss: 0.0077\n",
      "Epoch 90/200, Iteration 126/250, Loss: 0.0162\n",
      "Epoch 90/200, Iteration 127/250, Loss: 0.0151\n",
      "Epoch 90/200, Iteration 128/250, Loss: 0.0156\n",
      "Epoch 90/200, Iteration 129/250, Loss: 0.0188\n",
      "Epoch 90/200, Iteration 130/250, Loss: 0.0102\n",
      "Epoch 90/200, Iteration 131/250, Loss: 0.0088\n",
      "Epoch 90/200, Iteration 132/250, Loss: 0.0210\n",
      "Epoch 90/200, Iteration 133/250, Loss: 0.0089\n",
      "Epoch 90/200, Iteration 134/250, Loss: 0.0089\n",
      "Epoch 90/200, Iteration 135/250, Loss: 0.0266\n",
      "Epoch 90/200, Iteration 136/250, Loss: 0.0225\n",
      "Epoch 90/200, Iteration 137/250, Loss: 0.0073\n",
      "Epoch 90/200, Iteration 138/250, Loss: 0.0333\n",
      "Epoch 90/200, Iteration 139/250, Loss: 0.0162\n",
      "Epoch 90/200, Iteration 140/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 90/200, Iteration 142/250, Loss: 0.0401\n",
      "Epoch 90/200, Iteration 143/250, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 144/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 145/250, Loss: 0.0123\n",
      "Epoch 90/200, Iteration 146/250, Loss: 0.0156\n",
      "Epoch 90/200, Iteration 147/250, Loss: 0.0114\n",
      "Epoch 90/200, Iteration 148/250, Loss: 0.0279\n",
      "Epoch 90/200, Iteration 149/250, Loss: 0.0171\n",
      "Epoch 90/200, Iteration 150/250, Loss: 0.0168\n",
      "Epoch 90/200, Iteration 151/250, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 152/250, Loss: 0.0172\n",
      "Epoch 90/200, Iteration 153/250, Loss: 0.0082\n",
      "Epoch 90/200, Iteration 154/250, Loss: 0.0177\n",
      "Epoch 90/200, Iteration 155/250, Loss: 0.0154\n",
      "Epoch 90/200, Iteration 156/250, Loss: 0.0285\n",
      "Epoch 90/200, Iteration 157/250, Loss: 0.0219\n",
      "Epoch 90/200, Iteration 158/250, Loss: 0.0078\n",
      "Epoch 90/200, Iteration 159/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 160/250, Loss: 0.0146\n",
      "Epoch 90/200, Iteration 161/250, Loss: 0.0149\n",
      "Epoch 90/200, Iteration 162/250, Loss: 0.0173\n",
      "Epoch 90/200, Iteration 163/250, Loss: 0.0273\n",
      "Epoch 90/200, Iteration 164/250, Loss: 0.0127\n",
      "Epoch 90/200, Iteration 165/250, Loss: 0.0182\n",
      "Epoch 90/200, Iteration 166/250, Loss: 0.0162\n",
      "Epoch 90/200, Iteration 167/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 90/200, Iteration 169/250, Loss: 0.0182\n",
      "Epoch 90/200, Iteration 170/250, Loss: 0.0176\n",
      "Epoch 90/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 90/200, Iteration 172/250, Loss: 0.0170\n",
      "Epoch 90/200, Iteration 173/250, Loss: 0.0131\n",
      "Epoch 90/200, Iteration 174/250, Loss: 0.0068\n",
      "Epoch 90/200, Iteration 175/250, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 176/250, Loss: 0.0345\n",
      "Epoch 90/200, Iteration 177/250, Loss: 0.0087\n",
      "Epoch 90/200, Iteration 178/250, Loss: 0.0079\n",
      "Epoch 90/200, Iteration 179/250, Loss: 0.0097\n",
      "Epoch 90/200, Iteration 180/250, Loss: 0.0157\n",
      "Epoch 90/200, Iteration 181/250, Loss: 0.0133\n",
      "Epoch 90/200, Iteration 182/250, Loss: 0.0049\n",
      "Epoch 90/200, Iteration 183/250, Loss: 0.0137\n",
      "Epoch 90/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 185/250, Loss: 0.0188\n",
      "Epoch 90/200, Iteration 186/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 187/250, Loss: 0.0236\n",
      "Epoch 90/200, Iteration 188/250, Loss: 0.0144\n",
      "Epoch 90/200, Iteration 189/250, Loss: 0.0052\n",
      "Epoch 90/200, Iteration 190/250, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 191/250, Loss: 0.0213\n",
      "Epoch 90/200, Iteration 192/250, Loss: 0.0148\n",
      "Epoch 90/200, Iteration 193/250, Loss: 0.0124\n",
      "Epoch 90/200, Iteration 194/250, Loss: 0.0179\n",
      "Epoch 90/200, Iteration 195/250, Loss: 0.0241\n",
      "Epoch 90/200, Iteration 196/250, Loss: 0.0204\n",
      "Epoch 90/200, Iteration 197/250, Loss: 0.0119\n",
      "Epoch 90/200, Iteration 198/250, Loss: 0.0120\n",
      "Epoch 90/200, Iteration 199/250, Loss: 0.0075\n",
      "Epoch 90/200, Iteration 200/250, Loss: 0.0075\n",
      "Epoch 90/200, Iteration 201/250, Loss: 0.0306\n",
      "Epoch 90/200, Iteration 202/250, Loss: 0.0178\n",
      "Epoch 90/200, Iteration 203/250, Loss: 0.0140\n",
      "Epoch 90/200, Iteration 204/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 206/250, Loss: 0.0227\n",
      "Epoch 90/200, Iteration 207/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 208/250, Loss: 0.0170\n",
      "Epoch 90/200, Iteration 209/250, Loss: 0.0205\n",
      "Epoch 90/200, Iteration 210/250, Loss: 0.0167\n",
      "Epoch 90/200, Iteration 211/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 212/250, Loss: 0.0083\n",
      "Epoch 90/200, Iteration 213/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 214/250, Loss: 0.0192\n",
      "Epoch 90/200, Iteration 215/250, Loss: 0.0071\n",
      "Epoch 90/200, Iteration 216/250, Loss: 0.0199\n",
      "Epoch 90/200, Iteration 217/250, Loss: 0.0134\n",
      "Epoch 90/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 219/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 220/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 221/250, Loss: 0.0172\n",
      "Epoch 90/200, Iteration 222/250, Loss: 0.0216\n",
      "Epoch 90/200, Iteration 223/250, Loss: 0.0096\n",
      "Epoch 90/200, Iteration 224/250, Loss: 0.0087\n",
      "Epoch 90/200, Iteration 225/250, Loss: 0.0120\n",
      "Epoch 90/200, Iteration 226/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 227/250, Loss: 0.0142\n",
      "Epoch 90/200, Iteration 228/250, Loss: 0.0395\n",
      "Epoch 90/200, Iteration 229/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 230/250, Loss: 0.0082\n",
      "Epoch 90/200, Iteration 231/250, Loss: 0.0184\n",
      "Epoch 90/200, Iteration 232/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 233/250, Loss: 0.0237\n",
      "Epoch 90/200, Iteration 234/250, Loss: 0.0186\n",
      "Epoch 90/200, Iteration 235/250, Loss: 0.0111\n",
      "Epoch 90/200, Iteration 236/250, Loss: 0.0083\n",
      "Epoch 90/200, Iteration 237/250, Loss: 0.0437\n",
      "Epoch 90/200, Iteration 238/250, Loss: 0.0203\n",
      "Epoch 90/200, Iteration 239/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 240/250, Loss: 0.0174\n",
      "Epoch 90/200, Iteration 241/250, Loss: 0.0182\n",
      "Epoch 90/200, Iteration 242/250, Loss: 0.0088\n",
      "Epoch 90/200, Iteration 243/250, Loss: 0.0133\n",
      "Epoch 90/200, Iteration 244/250, Loss: 0.0228\n",
      "Epoch 90/200, Iteration 245/250, Loss: 0.0071\n",
      "Epoch 90/200, Iteration 246/250, Loss: 0.0196\n",
      "Epoch 90/200, Iteration 247/250, Loss: 0.0224\n",
      "Epoch 90/200, Iteration 248/250, Loss: 0.0090\n",
      "Epoch 90/200, Iteration 249/250, Loss: 0.0189\n",
      "Epoch 90/200, Iteration 250/250, Loss: 0.0233\n",
      "Train Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.006287, MRE: 0.599253 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.006335, MRE: 0.924680 \n",
      "\n",
      "Epoch 91/200, Iteration 1/250, Loss: 0.0245\n",
      "Epoch 91/200, Iteration 2/250, Loss: 0.0207\n",
      "Epoch 91/200, Iteration 3/250, Loss: 0.0280\n",
      "Epoch 91/200, Iteration 4/250, Loss: 0.0105\n",
      "Epoch 91/200, Iteration 5/250, Loss: 0.0544\n",
      "Epoch 91/200, Iteration 6/250, Loss: 0.0143\n",
      "Epoch 91/200, Iteration 7/250, Loss: 0.0103\n",
      "Epoch 91/200, Iteration 8/250, Loss: 0.0265\n",
      "Epoch 91/200, Iteration 9/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 10/250, Loss: 0.0171\n",
      "Epoch 91/200, Iteration 11/250, Loss: 0.0143\n",
      "Epoch 91/200, Iteration 12/250, Loss: 0.0167\n",
      "Epoch 91/200, Iteration 13/250, Loss: 0.0185\n",
      "Epoch 91/200, Iteration 14/250, Loss: 0.0070\n",
      "Epoch 91/200, Iteration 15/250, Loss: 0.0124\n",
      "Epoch 91/200, Iteration 16/250, Loss: 0.0084\n",
      "Epoch 91/200, Iteration 17/250, Loss: 0.0121\n",
      "Epoch 91/200, Iteration 18/250, Loss: 0.0209\n",
      "Epoch 91/200, Iteration 19/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 20/250, Loss: 0.0145\n",
      "Epoch 91/200, Iteration 21/250, Loss: 0.0144\n",
      "Epoch 91/200, Iteration 22/250, Loss: 0.0075\n",
      "Epoch 91/200, Iteration 23/250, Loss: 0.0239\n",
      "Epoch 91/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 25/250, Loss: 0.0129\n",
      "Epoch 91/200, Iteration 26/250, Loss: 0.0196\n",
      "Epoch 91/200, Iteration 27/250, Loss: 0.0136\n",
      "Epoch 91/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 91/200, Iteration 29/250, Loss: 0.0246\n",
      "Epoch 91/200, Iteration 30/250, Loss: 0.0285\n",
      "Epoch 91/200, Iteration 31/250, Loss: 0.0197\n",
      "Epoch 91/200, Iteration 32/250, Loss: 0.0197\n",
      "Epoch 91/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 91/200, Iteration 34/250, Loss: 0.0183\n",
      "Epoch 91/200, Iteration 35/250, Loss: 0.0241\n",
      "Epoch 91/200, Iteration 36/250, Loss: 0.0252\n",
      "Epoch 91/200, Iteration 37/250, Loss: 0.0222\n",
      "Epoch 91/200, Iteration 38/250, Loss: 0.0084\n",
      "Epoch 91/200, Iteration 39/250, Loss: 0.0140\n",
      "Epoch 91/200, Iteration 40/250, Loss: 0.0162\n",
      "Epoch 91/200, Iteration 41/250, Loss: 0.0117\n",
      "Epoch 91/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 43/250, Loss: 0.0145\n",
      "Epoch 91/200, Iteration 44/250, Loss: 0.0201\n",
      "Epoch 91/200, Iteration 45/250, Loss: 0.0119\n",
      "Epoch 91/200, Iteration 46/250, Loss: 0.0162\n",
      "Epoch 91/200, Iteration 47/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 48/250, Loss: 0.0071\n",
      "Epoch 91/200, Iteration 49/250, Loss: 0.0129\n",
      "Epoch 91/200, Iteration 50/250, Loss: 0.0156\n",
      "Epoch 91/200, Iteration 51/250, Loss: 0.0138\n",
      "Epoch 91/200, Iteration 52/250, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 91/200, Iteration 54/250, Loss: 0.0184\n",
      "Epoch 91/200, Iteration 55/250, Loss: 0.0258\n",
      "Epoch 91/200, Iteration 56/250, Loss: 0.0126\n",
      "Epoch 91/200, Iteration 57/250, Loss: 0.0109\n",
      "Epoch 91/200, Iteration 58/250, Loss: 0.0283\n",
      "Epoch 91/200, Iteration 59/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 60/250, Loss: 0.0066\n",
      "Epoch 91/200, Iteration 61/250, Loss: 0.0076\n",
      "Epoch 91/200, Iteration 62/250, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 63/250, Loss: 0.0196\n",
      "Epoch 91/200, Iteration 64/250, Loss: 0.0064\n",
      "Epoch 91/200, Iteration 65/250, Loss: 0.0207\n",
      "Epoch 91/200, Iteration 66/250, Loss: 0.0229\n",
      "Epoch 91/200, Iteration 67/250, Loss: 0.0114\n",
      "Epoch 91/200, Iteration 68/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 69/250, Loss: 0.0168\n",
      "Epoch 91/200, Iteration 70/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 71/250, Loss: 0.0113\n",
      "Epoch 91/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 91/200, Iteration 73/250, Loss: 0.0196\n",
      "Epoch 91/200, Iteration 74/250, Loss: 0.0157\n",
      "Epoch 91/200, Iteration 75/250, Loss: 0.0130\n",
      "Epoch 91/200, Iteration 76/250, Loss: 0.0271\n",
      "Epoch 91/200, Iteration 77/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 78/250, Loss: 0.0158\n",
      "Epoch 91/200, Iteration 79/250, Loss: 0.0151\n",
      "Epoch 91/200, Iteration 80/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 81/250, Loss: 0.0181\n",
      "Epoch 91/200, Iteration 82/250, Loss: 0.0102\n",
      "Epoch 91/200, Iteration 83/250, Loss: 0.0105\n",
      "Epoch 91/200, Iteration 84/250, Loss: 0.0082\n",
      "Epoch 91/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 87/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 91/200, Iteration 89/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 90/250, Loss: 0.0270\n",
      "Epoch 91/200, Iteration 91/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 92/250, Loss: 0.0058\n",
      "Epoch 91/200, Iteration 93/250, Loss: 0.0094\n",
      "Epoch 91/200, Iteration 94/250, Loss: 0.0091\n",
      "Epoch 91/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 96/250, Loss: 0.0155\n",
      "Epoch 91/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 91/200, Iteration 98/250, Loss: 0.0323\n",
      "Epoch 91/200, Iteration 99/250, Loss: 0.0181\n",
      "Epoch 91/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 91/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 91/200, Iteration 102/250, Loss: 0.0198\n",
      "Epoch 91/200, Iteration 103/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 91/200, Iteration 105/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 106/250, Loss: 0.0254\n",
      "Epoch 91/200, Iteration 107/250, Loss: 0.0116\n",
      "Epoch 91/200, Iteration 108/250, Loss: 0.0230\n",
      "Epoch 91/200, Iteration 109/250, Loss: 0.0191\n",
      "Epoch 91/200, Iteration 110/250, Loss: 0.0178\n",
      "Epoch 91/200, Iteration 111/250, Loss: 0.0114\n",
      "Epoch 91/200, Iteration 112/250, Loss: 0.0062\n",
      "Epoch 91/200, Iteration 113/250, Loss: 0.0070\n",
      "Epoch 91/200, Iteration 114/250, Loss: 0.0213\n",
      "Epoch 91/200, Iteration 115/250, Loss: 0.0138\n",
      "Epoch 91/200, Iteration 116/250, Loss: 0.0291\n",
      "Epoch 91/200, Iteration 117/250, Loss: 0.0201\n",
      "Epoch 91/200, Iteration 118/250, Loss: 0.0490\n",
      "Epoch 91/200, Iteration 119/250, Loss: 0.0073\n",
      "Epoch 91/200, Iteration 120/250, Loss: 0.0242\n",
      "Epoch 91/200, Iteration 121/250, Loss: 0.0189\n",
      "Epoch 91/200, Iteration 122/250, Loss: 0.0067\n",
      "Epoch 91/200, Iteration 123/250, Loss: 0.0255\n",
      "Epoch 91/200, Iteration 124/250, Loss: 0.0110\n",
      "Epoch 91/200, Iteration 125/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 126/250, Loss: 0.0184\n",
      "Epoch 91/200, Iteration 127/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 128/250, Loss: 0.0166\n",
      "Epoch 91/200, Iteration 129/250, Loss: 0.0504\n",
      "Epoch 91/200, Iteration 130/250, Loss: 0.0095\n",
      "Epoch 91/200, Iteration 131/250, Loss: 0.0153\n",
      "Epoch 91/200, Iteration 132/250, Loss: 0.0087\n",
      "Epoch 91/200, Iteration 133/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 134/250, Loss: 0.0091\n",
      "Epoch 91/200, Iteration 135/250, Loss: 0.0084\n",
      "Epoch 91/200, Iteration 136/250, Loss: 0.0144\n",
      "Epoch 91/200, Iteration 137/250, Loss: 0.0153\n",
      "Epoch 91/200, Iteration 138/250, Loss: 0.0216\n",
      "Epoch 91/200, Iteration 139/250, Loss: 0.0384\n",
      "Epoch 91/200, Iteration 140/250, Loss: 0.0164\n",
      "Epoch 91/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 142/250, Loss: 0.0322\n",
      "Epoch 91/200, Iteration 143/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 144/250, Loss: 0.0158\n",
      "Epoch 91/200, Iteration 145/250, Loss: 0.0176\n",
      "Epoch 91/200, Iteration 146/250, Loss: 0.0142\n",
      "Epoch 91/200, Iteration 147/250, Loss: 0.0153\n",
      "Epoch 91/200, Iteration 148/250, Loss: 0.0079\n",
      "Epoch 91/200, Iteration 149/250, Loss: 0.0114\n",
      "Epoch 91/200, Iteration 150/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 151/250, Loss: 0.0238\n",
      "Epoch 91/200, Iteration 152/250, Loss: 0.0124\n",
      "Epoch 91/200, Iteration 153/250, Loss: 0.0158\n",
      "Epoch 91/200, Iteration 154/250, Loss: 0.0274\n",
      "Epoch 91/200, Iteration 155/250, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 156/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 157/250, Loss: 0.0263\n",
      "Epoch 91/200, Iteration 158/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 160/250, Loss: 0.0153\n",
      "Epoch 91/200, Iteration 161/250, Loss: 0.0527\n",
      "Epoch 91/200, Iteration 162/250, Loss: 0.0250\n",
      "Epoch 91/200, Iteration 163/250, Loss: 0.0162\n",
      "Epoch 91/200, Iteration 164/250, Loss: 0.0183\n",
      "Epoch 91/200, Iteration 165/250, Loss: 0.0142\n",
      "Epoch 91/200, Iteration 166/250, Loss: 0.0169\n",
      "Epoch 91/200, Iteration 167/250, Loss: 0.0116\n",
      "Epoch 91/200, Iteration 168/250, Loss: 0.0085\n",
      "Epoch 91/200, Iteration 169/250, Loss: 0.0094\n",
      "Epoch 91/200, Iteration 170/250, Loss: 0.0070\n",
      "Epoch 91/200, Iteration 171/250, Loss: 0.0125\n",
      "Epoch 91/200, Iteration 172/250, Loss: 0.0192\n",
      "Epoch 91/200, Iteration 173/250, Loss: 0.0072\n",
      "Epoch 91/200, Iteration 174/250, Loss: 0.0178\n",
      "Epoch 91/200, Iteration 175/250, Loss: 0.0112\n",
      "Epoch 91/200, Iteration 176/250, Loss: 0.0104\n",
      "Epoch 91/200, Iteration 177/250, Loss: 0.0147\n",
      "Epoch 91/200, Iteration 178/250, Loss: 0.0106\n",
      "Epoch 91/200, Iteration 179/250, Loss: 0.0051\n",
      "Epoch 91/200, Iteration 180/250, Loss: 0.0154\n",
      "Epoch 91/200, Iteration 181/250, Loss: 0.0069\n",
      "Epoch 91/200, Iteration 182/250, Loss: 0.0107\n",
      "Epoch 91/200, Iteration 183/250, Loss: 0.0074\n",
      "Epoch 91/200, Iteration 184/250, Loss: 0.0307\n",
      "Epoch 91/200, Iteration 185/250, Loss: 0.0223\n",
      "Epoch 91/200, Iteration 186/250, Loss: 0.0136\n",
      "Epoch 91/200, Iteration 187/250, Loss: 0.0091\n",
      "Epoch 91/200, Iteration 188/250, Loss: 0.0138\n",
      "Epoch 91/200, Iteration 189/250, Loss: 0.0069\n",
      "Epoch 91/200, Iteration 190/250, Loss: 0.0219\n",
      "Epoch 91/200, Iteration 191/250, Loss: 0.0222\n",
      "Epoch 91/200, Iteration 192/250, Loss: 0.0127\n",
      "Epoch 91/200, Iteration 193/250, Loss: 0.0180\n",
      "Epoch 91/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 195/250, Loss: 0.0186\n",
      "Epoch 91/200, Iteration 196/250, Loss: 0.0090\n",
      "Epoch 91/200, Iteration 197/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 199/250, Loss: 0.0114\n",
      "Epoch 91/200, Iteration 200/250, Loss: 0.0225\n",
      "Epoch 91/200, Iteration 201/250, Loss: 0.0135\n",
      "Epoch 91/200, Iteration 202/250, Loss: 0.0119\n",
      "Epoch 91/200, Iteration 203/250, Loss: 0.0165\n",
      "Epoch 91/200, Iteration 204/250, Loss: 0.0077\n",
      "Epoch 91/200, Iteration 205/250, Loss: 0.0108\n",
      "Epoch 91/200, Iteration 206/250, Loss: 0.0069\n",
      "Epoch 91/200, Iteration 207/250, Loss: 0.0139\n",
      "Epoch 91/200, Iteration 208/250, Loss: 0.0099\n",
      "Epoch 91/200, Iteration 209/250, Loss: 0.0254\n",
      "Epoch 91/200, Iteration 210/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 211/250, Loss: 0.0093\n",
      "Epoch 91/200, Iteration 212/250, Loss: 0.0205\n",
      "Epoch 91/200, Iteration 213/250, Loss: 0.0400\n",
      "Epoch 91/200, Iteration 214/250, Loss: 0.0112\n",
      "Epoch 91/200, Iteration 215/250, Loss: 0.0085\n",
      "Epoch 91/200, Iteration 216/250, Loss: 0.0070\n",
      "Epoch 91/200, Iteration 217/250, Loss: 0.0269\n",
      "Epoch 91/200, Iteration 218/250, Loss: 0.0129\n",
      "Epoch 91/200, Iteration 219/250, Loss: 0.0100\n",
      "Epoch 91/200, Iteration 220/250, Loss: 0.0199\n",
      "Epoch 91/200, Iteration 221/250, Loss: 0.0173\n",
      "Epoch 91/200, Iteration 222/250, Loss: 0.0113\n",
      "Epoch 91/200, Iteration 223/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 224/250, Loss: 0.0080\n",
      "Epoch 91/200, Iteration 225/250, Loss: 0.0086\n",
      "Epoch 91/200, Iteration 226/250, Loss: 0.0137\n",
      "Epoch 91/200, Iteration 227/250, Loss: 0.0209\n",
      "Epoch 91/200, Iteration 228/250, Loss: 0.0103\n",
      "Epoch 91/200, Iteration 229/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 230/250, Loss: 0.0157\n",
      "Epoch 91/200, Iteration 231/250, Loss: 0.0109\n",
      "Epoch 91/200, Iteration 232/250, Loss: 0.0195\n",
      "Epoch 91/200, Iteration 233/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 234/250, Loss: 0.0301\n",
      "Epoch 91/200, Iteration 235/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 91/200, Iteration 237/250, Loss: 0.0110\n",
      "Epoch 91/200, Iteration 238/250, Loss: 0.0244\n",
      "Epoch 91/200, Iteration 239/250, Loss: 0.0132\n",
      "Epoch 91/200, Iteration 240/250, Loss: 0.0255\n",
      "Epoch 91/200, Iteration 241/250, Loss: 0.0127\n",
      "Epoch 91/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 243/250, Loss: 0.0304\n",
      "Epoch 91/200, Iteration 244/250, Loss: 0.0171\n",
      "Epoch 91/200, Iteration 245/250, Loss: 0.0352\n",
      "Epoch 91/200, Iteration 246/250, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 247/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 248/250, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 249/250, Loss: 0.0075\n",
      "Epoch 91/200, Iteration 250/250, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.006621, MRE: 0.638537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.55%, Avg loss: 0.006695, MRE: 0.932046 \n",
      "\n",
      "Epoch 92/200, Iteration 1/250, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 2/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 3/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 4/250, Loss: 0.0182\n",
      "Epoch 92/200, Iteration 5/250, Loss: 0.0100\n",
      "Epoch 92/200, Iteration 6/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 7/250, Loss: 0.0248\n",
      "Epoch 92/200, Iteration 8/250, Loss: 0.0097\n",
      "Epoch 92/200, Iteration 9/250, Loss: 0.0271\n",
      "Epoch 92/200, Iteration 10/250, Loss: 0.0231\n",
      "Epoch 92/200, Iteration 11/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 12/250, Loss: 0.0134\n",
      "Epoch 92/200, Iteration 13/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 14/250, Loss: 0.0076\n",
      "Epoch 92/200, Iteration 15/250, Loss: 0.0108\n",
      "Epoch 92/200, Iteration 16/250, Loss: 0.0117\n",
      "Epoch 92/200, Iteration 17/250, Loss: 0.0087\n",
      "Epoch 92/200, Iteration 18/250, Loss: 0.0221\n",
      "Epoch 92/200, Iteration 19/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 92/200, Iteration 21/250, Loss: 0.0135\n",
      "Epoch 92/200, Iteration 22/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 23/250, Loss: 0.0114\n",
      "Epoch 92/200, Iteration 24/250, Loss: 0.0102\n",
      "Epoch 92/200, Iteration 25/250, Loss: 0.0173\n",
      "Epoch 92/200, Iteration 26/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 27/250, Loss: 0.0169\n",
      "Epoch 92/200, Iteration 28/250, Loss: 0.0154\n",
      "Epoch 92/200, Iteration 29/250, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 30/250, Loss: 0.0126\n",
      "Epoch 92/200, Iteration 31/250, Loss: 0.0190\n",
      "Epoch 92/200, Iteration 32/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 33/250, Loss: 0.0198\n",
      "Epoch 92/200, Iteration 34/250, Loss: 0.0130\n",
      "Epoch 92/200, Iteration 35/250, Loss: 0.0303\n",
      "Epoch 92/200, Iteration 36/250, Loss: 0.0106\n",
      "Epoch 92/200, Iteration 37/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 38/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 92/200, Iteration 40/250, Loss: 0.0255\n",
      "Epoch 92/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 42/250, Loss: 0.0161\n",
      "Epoch 92/200, Iteration 43/250, Loss: 0.0172\n",
      "Epoch 92/200, Iteration 44/250, Loss: 0.0110\n",
      "Epoch 92/200, Iteration 45/250, Loss: 0.0130\n",
      "Epoch 92/200, Iteration 46/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 47/250, Loss: 0.0149\n",
      "Epoch 92/200, Iteration 48/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 49/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 50/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 92/200, Iteration 52/250, Loss: 0.0197\n",
      "Epoch 92/200, Iteration 53/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 54/250, Loss: 0.0131\n",
      "Epoch 92/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 56/250, Loss: 0.0182\n",
      "Epoch 92/200, Iteration 57/250, Loss: 0.0193\n",
      "Epoch 92/200, Iteration 58/250, Loss: 0.0180\n",
      "Epoch 92/200, Iteration 59/250, Loss: 0.0181\n",
      "Epoch 92/200, Iteration 60/250, Loss: 0.0256\n",
      "Epoch 92/200, Iteration 61/250, Loss: 0.0294\n",
      "Epoch 92/200, Iteration 62/250, Loss: 0.0123\n",
      "Epoch 92/200, Iteration 63/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 64/250, Loss: 0.0138\n",
      "Epoch 92/200, Iteration 65/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 66/250, Loss: 0.0066\n",
      "Epoch 92/200, Iteration 67/250, Loss: 0.0155\n",
      "Epoch 92/200, Iteration 68/250, Loss: 0.0167\n",
      "Epoch 92/200, Iteration 69/250, Loss: 0.0073\n",
      "Epoch 92/200, Iteration 70/250, Loss: 0.0451\n",
      "Epoch 92/200, Iteration 71/250, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 92/200, Iteration 73/250, Loss: 0.0124\n",
      "Epoch 92/200, Iteration 74/250, Loss: 0.0166\n",
      "Epoch 92/200, Iteration 75/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 76/250, Loss: 0.0146\n",
      "Epoch 92/200, Iteration 77/250, Loss: 0.0101\n",
      "Epoch 92/200, Iteration 78/250, Loss: 0.0102\n",
      "Epoch 92/200, Iteration 79/250, Loss: 0.0150\n",
      "Epoch 92/200, Iteration 80/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 81/250, Loss: 0.0127\n",
      "Epoch 92/200, Iteration 82/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 83/250, Loss: 0.0098\n",
      "Epoch 92/200, Iteration 84/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 85/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 86/250, Loss: 0.0182\n",
      "Epoch 92/200, Iteration 87/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 88/250, Loss: 0.0077\n",
      "Epoch 92/200, Iteration 89/250, Loss: 0.0171\n",
      "Epoch 92/200, Iteration 90/250, Loss: 0.0153\n",
      "Epoch 92/200, Iteration 91/250, Loss: 0.0301\n",
      "Epoch 92/200, Iteration 92/250, Loss: 0.0227\n",
      "Epoch 92/200, Iteration 93/250, Loss: 0.0170\n",
      "Epoch 92/200, Iteration 94/250, Loss: 0.0148\n",
      "Epoch 92/200, Iteration 95/250, Loss: 0.0176\n",
      "Epoch 92/200, Iteration 96/250, Loss: 0.0052\n",
      "Epoch 92/200, Iteration 97/250, Loss: 0.0229\n",
      "Epoch 92/200, Iteration 98/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 100/250, Loss: 0.0287\n",
      "Epoch 92/200, Iteration 101/250, Loss: 0.0275\n",
      "Epoch 92/200, Iteration 102/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 103/250, Loss: 0.0073\n",
      "Epoch 92/200, Iteration 104/250, Loss: 0.0207\n",
      "Epoch 92/200, Iteration 105/250, Loss: 0.0152\n",
      "Epoch 92/200, Iteration 106/250, Loss: 0.0075\n",
      "Epoch 92/200, Iteration 107/250, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 108/250, Loss: 0.0202\n",
      "Epoch 92/200, Iteration 109/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 110/250, Loss: 0.0123\n",
      "Epoch 92/200, Iteration 111/250, Loss: 0.0080\n",
      "Epoch 92/200, Iteration 112/250, Loss: 0.0100\n",
      "Epoch 92/200, Iteration 113/250, Loss: 0.0097\n",
      "Epoch 92/200, Iteration 114/250, Loss: 0.0073\n",
      "Epoch 92/200, Iteration 115/250, Loss: 0.0101\n",
      "Epoch 92/200, Iteration 116/250, Loss: 0.0098\n",
      "Epoch 92/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 118/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 119/250, Loss: 0.0133\n",
      "Epoch 92/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 92/200, Iteration 121/250, Loss: 0.0131\n",
      "Epoch 92/200, Iteration 122/250, Loss: 0.0124\n",
      "Epoch 92/200, Iteration 123/250, Loss: 0.0068\n",
      "Epoch 92/200, Iteration 124/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 125/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 126/250, Loss: 0.0214\n",
      "Epoch 92/200, Iteration 127/250, Loss: 0.0070\n",
      "Epoch 92/200, Iteration 128/250, Loss: 0.0158\n",
      "Epoch 92/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 131/250, Loss: 0.0137\n",
      "Epoch 92/200, Iteration 132/250, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 133/250, Loss: 0.0182\n",
      "Epoch 92/200, Iteration 134/250, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 135/250, Loss: 0.0169\n",
      "Epoch 92/200, Iteration 136/250, Loss: 0.0198\n",
      "Epoch 92/200, Iteration 137/250, Loss: 0.0100\n",
      "Epoch 92/200, Iteration 138/250, Loss: 0.0175\n",
      "Epoch 92/200, Iteration 139/250, Loss: 0.0142\n",
      "Epoch 92/200, Iteration 140/250, Loss: 0.0115\n",
      "Epoch 92/200, Iteration 141/250, Loss: 0.0227\n",
      "Epoch 92/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 143/250, Loss: 0.0182\n",
      "Epoch 92/200, Iteration 144/250, Loss: 0.0309\n",
      "Epoch 92/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 146/250, Loss: 0.0089\n",
      "Epoch 92/200, Iteration 147/250, Loss: 0.0110\n",
      "Epoch 92/200, Iteration 148/250, Loss: 0.0132\n",
      "Epoch 92/200, Iteration 149/250, Loss: 0.0160\n",
      "Epoch 92/200, Iteration 150/250, Loss: 0.0203\n",
      "Epoch 92/200, Iteration 151/250, Loss: 0.0129\n",
      "Epoch 92/200, Iteration 152/250, Loss: 0.0110\n",
      "Epoch 92/200, Iteration 153/250, Loss: 0.0159\n",
      "Epoch 92/200, Iteration 154/250, Loss: 0.0147\n",
      "Epoch 92/200, Iteration 155/250, Loss: 0.0158\n",
      "Epoch 92/200, Iteration 156/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 157/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 158/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 159/250, Loss: 0.0241\n",
      "Epoch 92/200, Iteration 160/250, Loss: 0.0171\n",
      "Epoch 92/200, Iteration 161/250, Loss: 0.0121\n",
      "Epoch 92/200, Iteration 162/250, Loss: 0.0077\n",
      "Epoch 92/200, Iteration 163/250, Loss: 0.0167\n",
      "Epoch 92/200, Iteration 164/250, Loss: 0.0089\n",
      "Epoch 92/200, Iteration 165/250, Loss: 0.0315\n",
      "Epoch 92/200, Iteration 166/250, Loss: 0.0314\n",
      "Epoch 92/200, Iteration 167/250, Loss: 0.0214\n",
      "Epoch 92/200, Iteration 168/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 169/250, Loss: 0.0130\n",
      "Epoch 92/200, Iteration 170/250, Loss: 0.0136\n",
      "Epoch 92/200, Iteration 171/250, Loss: 0.0122\n",
      "Epoch 92/200, Iteration 172/250, Loss: 0.0152\n",
      "Epoch 92/200, Iteration 173/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 174/250, Loss: 0.0160\n",
      "Epoch 92/200, Iteration 175/250, Loss: 0.0104\n",
      "Epoch 92/200, Iteration 176/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 177/250, Loss: 0.0088\n",
      "Epoch 92/200, Iteration 178/250, Loss: 0.0144\n",
      "Epoch 92/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 92/200, Iteration 180/250, Loss: 0.0142\n",
      "Epoch 92/200, Iteration 181/250, Loss: 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200, Iteration 182/250, Loss: 0.0095\n",
      "Epoch 92/200, Iteration 183/250, Loss: 0.0130\n",
      "Epoch 92/200, Iteration 184/250, Loss: 0.0145\n",
      "Epoch 92/200, Iteration 185/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 187/250, Loss: 0.0077\n",
      "Epoch 92/200, Iteration 188/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 190/250, Loss: 0.0071\n",
      "Epoch 92/200, Iteration 191/250, Loss: 0.0199\n",
      "Epoch 92/200, Iteration 192/250, Loss: 0.0292\n",
      "Epoch 92/200, Iteration 193/250, Loss: 0.0176\n",
      "Epoch 92/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 92/200, Iteration 195/250, Loss: 0.0163\n",
      "Epoch 92/200, Iteration 196/250, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 197/250, Loss: 0.0246\n",
      "Epoch 92/200, Iteration 198/250, Loss: 0.0135\n",
      "Epoch 92/200, Iteration 199/250, Loss: 0.0210\n",
      "Epoch 92/200, Iteration 200/250, Loss: 0.0297\n",
      "Epoch 92/200, Iteration 201/250, Loss: 0.0121\n",
      "Epoch 92/200, Iteration 202/250, Loss: 0.0137\n",
      "Epoch 92/200, Iteration 203/250, Loss: 0.0074\n",
      "Epoch 92/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 205/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 206/250, Loss: 0.0195\n",
      "Epoch 92/200, Iteration 207/250, Loss: 0.0157\n",
      "Epoch 92/200, Iteration 208/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 209/250, Loss: 0.0104\n",
      "Epoch 92/200, Iteration 210/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 211/250, Loss: 0.0219\n",
      "Epoch 92/200, Iteration 212/250, Loss: 0.0196\n",
      "Epoch 92/200, Iteration 213/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 214/250, Loss: 0.0110\n",
      "Epoch 92/200, Iteration 215/250, Loss: 0.0170\n",
      "Epoch 92/200, Iteration 216/250, Loss: 0.0212\n",
      "Epoch 92/200, Iteration 217/250, Loss: 0.0345\n",
      "Epoch 92/200, Iteration 218/250, Loss: 0.0110\n",
      "Epoch 92/200, Iteration 219/250, Loss: 0.0081\n",
      "Epoch 92/200, Iteration 220/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 221/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 222/250, Loss: 0.0406\n",
      "Epoch 92/200, Iteration 223/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 224/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 225/250, Loss: 0.0075\n",
      "Epoch 92/200, Iteration 226/250, Loss: 0.0079\n",
      "Epoch 92/200, Iteration 227/250, Loss: 0.0296\n",
      "Epoch 92/200, Iteration 228/250, Loss: 0.0163\n",
      "Epoch 92/200, Iteration 229/250, Loss: 0.0114\n",
      "Epoch 92/200, Iteration 230/250, Loss: 0.0084\n",
      "Epoch 92/200, Iteration 231/250, Loss: 0.0117\n",
      "Epoch 92/200, Iteration 232/250, Loss: 0.0205\n",
      "Epoch 92/200, Iteration 233/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 234/250, Loss: 0.0173\n",
      "Epoch 92/200, Iteration 235/250, Loss: 0.0060\n",
      "Epoch 92/200, Iteration 236/250, Loss: 0.0240\n",
      "Epoch 92/200, Iteration 237/250, Loss: 0.0128\n",
      "Epoch 92/200, Iteration 238/250, Loss: 0.0072\n",
      "Epoch 92/200, Iteration 239/250, Loss: 0.0108\n",
      "Epoch 92/200, Iteration 240/250, Loss: 0.0366\n",
      "Epoch 92/200, Iteration 241/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 242/250, Loss: 0.0088\n",
      "Epoch 92/200, Iteration 243/250, Loss: 0.0095\n",
      "Epoch 92/200, Iteration 244/250, Loss: 0.0191\n",
      "Epoch 92/200, Iteration 245/250, Loss: 0.0195\n",
      "Epoch 92/200, Iteration 246/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 247/250, Loss: 0.0192\n",
      "Epoch 92/200, Iteration 248/250, Loss: 0.0145\n",
      "Epoch 92/200, Iteration 249/250, Loss: 0.0152\n",
      "Epoch 92/200, Iteration 250/250, Loss: 0.0270\n",
      "Train Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.008226, MRE: 0.674361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.008229, MRE: 0.829623 \n",
      "\n",
      "Epoch 93/200, Iteration 1/250, Loss: 0.0351\n",
      "Epoch 93/200, Iteration 2/250, Loss: 0.0319\n",
      "Epoch 93/200, Iteration 3/250, Loss: 0.0145\n",
      "Epoch 93/200, Iteration 4/250, Loss: 0.0119\n",
      "Epoch 93/200, Iteration 5/250, Loss: 0.0214\n",
      "Epoch 93/200, Iteration 6/250, Loss: 0.0194\n",
      "Epoch 93/200, Iteration 7/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 8/250, Loss: 0.0438\n",
      "Epoch 93/200, Iteration 9/250, Loss: 0.0068\n",
      "Epoch 93/200, Iteration 10/250, Loss: 0.0087\n",
      "Epoch 93/200, Iteration 11/250, Loss: 0.0050\n",
      "Epoch 93/200, Iteration 12/250, Loss: 0.0142\n",
      "Epoch 93/200, Iteration 13/250, Loss: 0.0193\n",
      "Epoch 93/200, Iteration 14/250, Loss: 0.0187\n",
      "Epoch 93/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 93/200, Iteration 16/250, Loss: 0.0128\n",
      "Epoch 93/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 93/200, Iteration 18/250, Loss: 0.0127\n",
      "Epoch 93/200, Iteration 19/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 20/250, Loss: 0.0074\n",
      "Epoch 93/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 22/250, Loss: 0.0130\n",
      "Epoch 93/200, Iteration 23/250, Loss: 0.0208\n",
      "Epoch 93/200, Iteration 24/250, Loss: 0.0137\n",
      "Epoch 93/200, Iteration 25/250, Loss: 0.0116\n",
      "Epoch 93/200, Iteration 26/250, Loss: 0.0148\n",
      "Epoch 93/200, Iteration 27/250, Loss: 0.0160\n",
      "Epoch 93/200, Iteration 28/250, Loss: 0.0175\n",
      "Epoch 93/200, Iteration 29/250, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 30/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 31/250, Loss: 0.0091\n",
      "Epoch 93/200, Iteration 32/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 33/250, Loss: 0.0212\n",
      "Epoch 93/200, Iteration 34/250, Loss: 0.0089\n",
      "Epoch 93/200, Iteration 35/250, Loss: 0.0158\n",
      "Epoch 93/200, Iteration 36/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 37/250, Loss: 0.0156\n",
      "Epoch 93/200, Iteration 38/250, Loss: 0.0161\n",
      "Epoch 93/200, Iteration 39/250, Loss: 0.0160\n",
      "Epoch 93/200, Iteration 40/250, Loss: 0.0291\n",
      "Epoch 93/200, Iteration 41/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 42/250, Loss: 0.0174\n",
      "Epoch 93/200, Iteration 43/250, Loss: 0.0107\n",
      "Epoch 93/200, Iteration 44/250, Loss: 0.0135\n",
      "Epoch 93/200, Iteration 45/250, Loss: 0.0146\n",
      "Epoch 93/200, Iteration 46/250, Loss: 0.0084\n",
      "Epoch 93/200, Iteration 47/250, Loss: 0.0229\n",
      "Epoch 93/200, Iteration 48/250, Loss: 0.0294\n",
      "Epoch 93/200, Iteration 49/250, Loss: 0.0167\n",
      "Epoch 93/200, Iteration 50/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 51/250, Loss: 0.0169\n",
      "Epoch 93/200, Iteration 52/250, Loss: 0.0114\n",
      "Epoch 93/200, Iteration 53/250, Loss: 0.0337\n",
      "Epoch 93/200, Iteration 54/250, Loss: 0.0119\n",
      "Epoch 93/200, Iteration 55/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 56/250, Loss: 0.0135\n",
      "Epoch 93/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 93/200, Iteration 58/250, Loss: 0.0188\n",
      "Epoch 93/200, Iteration 59/250, Loss: 0.0183\n",
      "Epoch 93/200, Iteration 60/250, Loss: 0.0154\n",
      "Epoch 93/200, Iteration 61/250, Loss: 0.0285\n",
      "Epoch 93/200, Iteration 62/250, Loss: 0.0151\n",
      "Epoch 93/200, Iteration 63/250, Loss: 0.0170\n",
      "Epoch 93/200, Iteration 64/250, Loss: 0.0134\n",
      "Epoch 93/200, Iteration 65/250, Loss: 0.0138\n",
      "Epoch 93/200, Iteration 66/250, Loss: 0.0113\n",
      "Epoch 93/200, Iteration 67/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 68/250, Loss: 0.0123\n",
      "Epoch 93/200, Iteration 69/250, Loss: 0.0149\n",
      "Epoch 93/200, Iteration 70/250, Loss: 0.0116\n",
      "Epoch 93/200, Iteration 71/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 72/250, Loss: 0.0275\n",
      "Epoch 93/200, Iteration 73/250, Loss: 0.0193\n",
      "Epoch 93/200, Iteration 74/250, Loss: 0.0062\n",
      "Epoch 93/200, Iteration 75/250, Loss: 0.0104\n",
      "Epoch 93/200, Iteration 76/250, Loss: 0.0188\n",
      "Epoch 93/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 78/250, Loss: 0.0075\n",
      "Epoch 93/200, Iteration 79/250, Loss: 0.0135\n",
      "Epoch 93/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 93/200, Iteration 81/250, Loss: 0.0170\n",
      "Epoch 93/200, Iteration 82/250, Loss: 0.0152\n",
      "Epoch 93/200, Iteration 83/250, Loss: 0.0144\n",
      "Epoch 93/200, Iteration 84/250, Loss: 0.0203\n",
      "Epoch 93/200, Iteration 85/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 86/250, Loss: 0.0259\n",
      "Epoch 93/200, Iteration 87/250, Loss: 0.0130\n",
      "Epoch 93/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 89/250, Loss: 0.0230\n",
      "Epoch 93/200, Iteration 90/250, Loss: 0.0087\n",
      "Epoch 93/200, Iteration 91/250, Loss: 0.0117\n",
      "Epoch 93/200, Iteration 92/250, Loss: 0.0220\n",
      "Epoch 93/200, Iteration 93/250, Loss: 0.0055\n",
      "Epoch 93/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 93/200, Iteration 95/250, Loss: 0.0130\n",
      "Epoch 93/200, Iteration 96/250, Loss: 0.0098\n",
      "Epoch 93/200, Iteration 97/250, Loss: 0.0328\n",
      "Epoch 93/200, Iteration 98/250, Loss: 0.0205\n",
      "Epoch 93/200, Iteration 99/250, Loss: 0.0134\n",
      "Epoch 93/200, Iteration 100/250, Loss: 0.0072\n",
      "Epoch 93/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 102/250, Loss: 0.0131\n",
      "Epoch 93/200, Iteration 103/250, Loss: 0.0079\n",
      "Epoch 93/200, Iteration 104/250, Loss: 0.0121\n",
      "Epoch 93/200, Iteration 105/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 106/250, Loss: 0.0237\n",
      "Epoch 93/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 108/250, Loss: 0.0075\n",
      "Epoch 93/200, Iteration 109/250, Loss: 0.0290\n",
      "Epoch 93/200, Iteration 110/250, Loss: 0.0072\n",
      "Epoch 93/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 112/250, Loss: 0.0095\n",
      "Epoch 93/200, Iteration 113/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 114/250, Loss: 0.0107\n",
      "Epoch 93/200, Iteration 115/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 116/250, Loss: 0.0188\n",
      "Epoch 93/200, Iteration 117/250, Loss: 0.0117\n",
      "Epoch 93/200, Iteration 118/250, Loss: 0.0155\n",
      "Epoch 93/200, Iteration 119/250, Loss: 0.0298\n",
      "Epoch 93/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 93/200, Iteration 121/250, Loss: 0.0057\n",
      "Epoch 93/200, Iteration 122/250, Loss: 0.0197\n",
      "Epoch 93/200, Iteration 123/250, Loss: 0.0264\n",
      "Epoch 93/200, Iteration 124/250, Loss: 0.0161\n",
      "Epoch 93/200, Iteration 125/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 126/250, Loss: 0.0234\n",
      "Epoch 93/200, Iteration 127/250, Loss: 0.0068\n",
      "Epoch 93/200, Iteration 128/250, Loss: 0.0281\n",
      "Epoch 93/200, Iteration 129/250, Loss: 0.0166\n",
      "Epoch 93/200, Iteration 130/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 131/250, Loss: 0.0297\n",
      "Epoch 93/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 93/200, Iteration 133/250, Loss: 0.0098\n",
      "Epoch 93/200, Iteration 134/250, Loss: 0.0281\n",
      "Epoch 93/200, Iteration 135/250, Loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200, Iteration 136/250, Loss: 0.0166\n",
      "Epoch 93/200, Iteration 137/250, Loss: 0.0102\n",
      "Epoch 93/200, Iteration 138/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 139/250, Loss: 0.0156\n",
      "Epoch 93/200, Iteration 140/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 93/200, Iteration 142/250, Loss: 0.0355\n",
      "Epoch 93/200, Iteration 143/250, Loss: 0.0141\n",
      "Epoch 93/200, Iteration 144/250, Loss: 0.0087\n",
      "Epoch 93/200, Iteration 145/250, Loss: 0.0177\n",
      "Epoch 93/200, Iteration 146/250, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 147/250, Loss: 0.0150\n",
      "Epoch 93/200, Iteration 148/250, Loss: 0.0111\n",
      "Epoch 93/200, Iteration 149/250, Loss: 0.0134\n",
      "Epoch 93/200, Iteration 150/250, Loss: 0.0122\n",
      "Epoch 93/200, Iteration 151/250, Loss: 0.0231\n",
      "Epoch 93/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 93/200, Iteration 153/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 154/250, Loss: 0.0213\n",
      "Epoch 93/200, Iteration 155/250, Loss: 0.0108\n",
      "Epoch 93/200, Iteration 156/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 157/250, Loss: 0.0303\n",
      "Epoch 93/200, Iteration 158/250, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 159/250, Loss: 0.0157\n",
      "Epoch 93/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 161/250, Loss: 0.0263\n",
      "Epoch 93/200, Iteration 162/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 163/250, Loss: 0.0370\n",
      "Epoch 93/200, Iteration 164/250, Loss: 0.0079\n",
      "Epoch 93/200, Iteration 165/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 166/250, Loss: 0.0168\n",
      "Epoch 93/200, Iteration 167/250, Loss: 0.0261\n",
      "Epoch 93/200, Iteration 168/250, Loss: 0.0112\n",
      "Epoch 93/200, Iteration 169/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 170/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 171/250, Loss: 0.0181\n",
      "Epoch 93/200, Iteration 172/250, Loss: 0.0050\n",
      "Epoch 93/200, Iteration 173/250, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 174/250, Loss: 0.0171\n",
      "Epoch 93/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 176/250, Loss: 0.0153\n",
      "Epoch 93/200, Iteration 177/250, Loss: 0.0075\n",
      "Epoch 93/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 179/250, Loss: 0.0169\n",
      "Epoch 93/200, Iteration 180/250, Loss: 0.0187\n",
      "Epoch 93/200, Iteration 181/250, Loss: 0.0127\n",
      "Epoch 93/200, Iteration 182/250, Loss: 0.0170\n",
      "Epoch 93/200, Iteration 183/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 184/250, Loss: 0.0116\n",
      "Epoch 93/200, Iteration 185/250, Loss: 0.0114\n",
      "Epoch 93/200, Iteration 186/250, Loss: 0.0183\n",
      "Epoch 93/200, Iteration 187/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 188/250, Loss: 0.0184\n",
      "Epoch 93/200, Iteration 189/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 190/250, Loss: 0.0138\n",
      "Epoch 93/200, Iteration 191/250, Loss: 0.0070\n",
      "Epoch 93/200, Iteration 192/250, Loss: 0.0135\n",
      "Epoch 93/200, Iteration 193/250, Loss: 0.0161\n",
      "Epoch 93/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 93/200, Iteration 195/250, Loss: 0.0072\n",
      "Epoch 93/200, Iteration 196/250, Loss: 0.0171\n",
      "Epoch 93/200, Iteration 197/250, Loss: 0.0071\n",
      "Epoch 93/200, Iteration 198/250, Loss: 0.0202\n",
      "Epoch 93/200, Iteration 199/250, Loss: 0.0087\n",
      "Epoch 93/200, Iteration 200/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 201/250, Loss: 0.0173\n",
      "Epoch 93/200, Iteration 202/250, Loss: 0.0179\n",
      "Epoch 93/200, Iteration 203/250, Loss: 0.0142\n",
      "Epoch 93/200, Iteration 204/250, Loss: 0.0102\n",
      "Epoch 93/200, Iteration 205/250, Loss: 0.0087\n",
      "Epoch 93/200, Iteration 206/250, Loss: 0.0199\n",
      "Epoch 93/200, Iteration 207/250, Loss: 0.0112\n",
      "Epoch 93/200, Iteration 208/250, Loss: 0.0281\n",
      "Epoch 93/200, Iteration 209/250, Loss: 0.0310\n",
      "Epoch 93/200, Iteration 210/250, Loss: 0.0094\n",
      "Epoch 93/200, Iteration 211/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 212/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 213/250, Loss: 0.0156\n",
      "Epoch 93/200, Iteration 214/250, Loss: 0.0230\n",
      "Epoch 93/200, Iteration 215/250, Loss: 0.0249\n",
      "Epoch 93/200, Iteration 216/250, Loss: 0.0148\n",
      "Epoch 93/200, Iteration 217/250, Loss: 0.0337\n",
      "Epoch 93/200, Iteration 218/250, Loss: 0.0108\n",
      "Epoch 93/200, Iteration 219/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 220/250, Loss: 0.0082\n",
      "Epoch 93/200, Iteration 221/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 222/250, Loss: 0.0064\n",
      "Epoch 93/200, Iteration 223/250, Loss: 0.0082\n",
      "Epoch 93/200, Iteration 224/250, Loss: 0.0186\n",
      "Epoch 93/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 226/250, Loss: 0.0143\n",
      "Epoch 93/200, Iteration 227/250, Loss: 0.0176\n",
      "Epoch 93/200, Iteration 228/250, Loss: 0.0084\n",
      "Epoch 93/200, Iteration 229/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 230/250, Loss: 0.0227\n",
      "Epoch 93/200, Iteration 231/250, Loss: 0.0116\n",
      "Epoch 93/200, Iteration 232/250, Loss: 0.0074\n",
      "Epoch 93/200, Iteration 233/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 234/250, Loss: 0.0138\n",
      "Epoch 93/200, Iteration 235/250, Loss: 0.0331\n",
      "Epoch 93/200, Iteration 236/250, Loss: 0.0419\n",
      "Epoch 93/200, Iteration 237/250, Loss: 0.0206\n",
      "Epoch 93/200, Iteration 238/250, Loss: 0.0101\n",
      "Epoch 93/200, Iteration 239/250, Loss: 0.0074\n",
      "Epoch 93/200, Iteration 240/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 241/250, Loss: 0.0203\n",
      "Epoch 93/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 93/200, Iteration 243/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 244/250, Loss: 0.0123\n",
      "Epoch 93/200, Iteration 245/250, Loss: 0.0243\n",
      "Epoch 93/200, Iteration 246/250, Loss: 0.0145\n",
      "Epoch 93/200, Iteration 247/250, Loss: 0.0083\n",
      "Epoch 93/200, Iteration 248/250, Loss: 0.0255\n",
      "Epoch 93/200, Iteration 249/250, Loss: 0.0155\n",
      "Epoch 93/200, Iteration 250/250, Loss: 0.0071\n",
      "Train Error: \n",
      " Accuracy: 92.11%, Avg loss: 0.006055, MRE: 0.617106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.006048, MRE: 0.945854 \n",
      "\n",
      "Epoch 94/200, Iteration 1/250, Loss: 0.0250\n",
      "Epoch 94/200, Iteration 2/250, Loss: 0.0182\n",
      "Epoch 94/200, Iteration 3/250, Loss: 0.0122\n",
      "Epoch 94/200, Iteration 4/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 5/250, Loss: 0.0085\n",
      "Epoch 94/200, Iteration 6/250, Loss: 0.0153\n",
      "Epoch 94/200, Iteration 7/250, Loss: 0.0188\n",
      "Epoch 94/200, Iteration 8/250, Loss: 0.0240\n",
      "Epoch 94/200, Iteration 9/250, Loss: 0.0089\n",
      "Epoch 94/200, Iteration 10/250, Loss: 0.0062\n",
      "Epoch 94/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 94/200, Iteration 12/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 14/250, Loss: 0.0171\n",
      "Epoch 94/200, Iteration 15/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 16/250, Loss: 0.0245\n",
      "Epoch 94/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 94/200, Iteration 18/250, Loss: 0.0145\n",
      "Epoch 94/200, Iteration 19/250, Loss: 0.0359\n",
      "Epoch 94/200, Iteration 20/250, Loss: 0.0157\n",
      "Epoch 94/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 22/250, Loss: 0.0212\n",
      "Epoch 94/200, Iteration 23/250, Loss: 0.0208\n",
      "Epoch 94/200, Iteration 24/250, Loss: 0.0182\n",
      "Epoch 94/200, Iteration 25/250, Loss: 0.0079\n",
      "Epoch 94/200, Iteration 26/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 27/250, Loss: 0.0441\n",
      "Epoch 94/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 94/200, Iteration 29/250, Loss: 0.0137\n",
      "Epoch 94/200, Iteration 30/250, Loss: 0.0148\n",
      "Epoch 94/200, Iteration 31/250, Loss: 0.0127\n",
      "Epoch 94/200, Iteration 32/250, Loss: 0.0262\n",
      "Epoch 94/200, Iteration 33/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 34/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 35/250, Loss: 0.0085\n",
      "Epoch 94/200, Iteration 36/250, Loss: 0.0054\n",
      "Epoch 94/200, Iteration 37/250, Loss: 0.0350\n",
      "Epoch 94/200, Iteration 38/250, Loss: 0.0200\n",
      "Epoch 94/200, Iteration 39/250, Loss: 0.0153\n",
      "Epoch 94/200, Iteration 40/250, Loss: 0.0143\n",
      "Epoch 94/200, Iteration 41/250, Loss: 0.0187\n",
      "Epoch 94/200, Iteration 42/250, Loss: 0.0314\n",
      "Epoch 94/200, Iteration 43/250, Loss: 0.0090\n",
      "Epoch 94/200, Iteration 44/250, Loss: 0.0083\n",
      "Epoch 94/200, Iteration 45/250, Loss: 0.0214\n",
      "Epoch 94/200, Iteration 46/250, Loss: 0.0288\n",
      "Epoch 94/200, Iteration 47/250, Loss: 0.0191\n",
      "Epoch 94/200, Iteration 48/250, Loss: 0.0078\n",
      "Epoch 94/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 50/250, Loss: 0.0068\n",
      "Epoch 94/200, Iteration 51/250, Loss: 0.0230\n",
      "Epoch 94/200, Iteration 52/250, Loss: 0.0094\n",
      "Epoch 94/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 94/200, Iteration 54/250, Loss: 0.0189\n",
      "Epoch 94/200, Iteration 55/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 56/250, Loss: 0.0091\n",
      "Epoch 94/200, Iteration 57/250, Loss: 0.0090\n",
      "Epoch 94/200, Iteration 58/250, Loss: 0.0333\n",
      "Epoch 94/200, Iteration 59/250, Loss: 0.0142\n",
      "Epoch 94/200, Iteration 60/250, Loss: 0.0154\n",
      "Epoch 94/200, Iteration 61/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 62/250, Loss: 0.0073\n",
      "Epoch 94/200, Iteration 63/250, Loss: 0.0183\n",
      "Epoch 94/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 94/200, Iteration 65/250, Loss: 0.0079\n",
      "Epoch 94/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 94/200, Iteration 67/250, Loss: 0.0068\n",
      "Epoch 94/200, Iteration 68/250, Loss: 0.0069\n",
      "Epoch 94/200, Iteration 69/250, Loss: 0.0118\n",
      "Epoch 94/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 94/200, Iteration 71/250, Loss: 0.0192\n",
      "Epoch 94/200, Iteration 72/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 73/250, Loss: 0.0111\n",
      "Epoch 94/200, Iteration 74/250, Loss: 0.0121\n",
      "Epoch 94/200, Iteration 75/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 76/250, Loss: 0.0087\n",
      "Epoch 94/200, Iteration 77/250, Loss: 0.0167\n",
      "Epoch 94/200, Iteration 78/250, Loss: 0.0124\n",
      "Epoch 94/200, Iteration 79/250, Loss: 0.0088\n",
      "Epoch 94/200, Iteration 80/250, Loss: 0.0145\n",
      "Epoch 94/200, Iteration 81/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 82/250, Loss: 0.0063\n",
      "Epoch 94/200, Iteration 83/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 84/250, Loss: 0.0124\n",
      "Epoch 94/200, Iteration 85/250, Loss: 0.0236\n",
      "Epoch 94/200, Iteration 86/250, Loss: 0.0121\n",
      "Epoch 94/200, Iteration 87/250, Loss: 0.0080\n",
      "Epoch 94/200, Iteration 88/250, Loss: 0.0079\n",
      "Epoch 94/200, Iteration 89/250, Loss: 0.0192\n",
      "Epoch 94/200, Iteration 90/250, Loss: 0.0139\n",
      "Epoch 94/200, Iteration 91/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 92/250, Loss: 0.0076\n",
      "Epoch 94/200, Iteration 93/250, Loss: 0.0170\n",
      "Epoch 94/200, Iteration 94/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 95/250, Loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200, Iteration 96/250, Loss: 0.0146\n",
      "Epoch 94/200, Iteration 97/250, Loss: 0.0078\n",
      "Epoch 94/200, Iteration 98/250, Loss: 0.0203\n",
      "Epoch 94/200, Iteration 99/250, Loss: 0.0233\n",
      "Epoch 94/200, Iteration 100/250, Loss: 0.0167\n",
      "Epoch 94/200, Iteration 101/250, Loss: 0.0196\n",
      "Epoch 94/200, Iteration 102/250, Loss: 0.0094\n",
      "Epoch 94/200, Iteration 103/250, Loss: 0.0286\n",
      "Epoch 94/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 105/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 106/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 94/200, Iteration 108/250, Loss: 0.0222\n",
      "Epoch 94/200, Iteration 109/250, Loss: 0.0118\n",
      "Epoch 94/200, Iteration 110/250, Loss: 0.0237\n",
      "Epoch 94/200, Iteration 111/250, Loss: 0.0058\n",
      "Epoch 94/200, Iteration 112/250, Loss: 0.0087\n",
      "Epoch 94/200, Iteration 113/250, Loss: 0.0168\n",
      "Epoch 94/200, Iteration 114/250, Loss: 0.0372\n",
      "Epoch 94/200, Iteration 115/250, Loss: 0.0140\n",
      "Epoch 94/200, Iteration 116/250, Loss: 0.0119\n",
      "Epoch 94/200, Iteration 117/250, Loss: 0.0329\n",
      "Epoch 94/200, Iteration 118/250, Loss: 0.0246\n",
      "Epoch 94/200, Iteration 119/250, Loss: 0.0245\n",
      "Epoch 94/200, Iteration 120/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 121/250, Loss: 0.0250\n",
      "Epoch 94/200, Iteration 122/250, Loss: 0.0129\n",
      "Epoch 94/200, Iteration 123/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 124/250, Loss: 0.0288\n",
      "Epoch 94/200, Iteration 125/250, Loss: 0.0208\n",
      "Epoch 94/200, Iteration 126/250, Loss: 0.0174\n",
      "Epoch 94/200, Iteration 127/250, Loss: 0.0139\n",
      "Epoch 94/200, Iteration 128/250, Loss: 0.0076\n",
      "Epoch 94/200, Iteration 129/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 130/250, Loss: 0.0151\n",
      "Epoch 94/200, Iteration 131/250, Loss: 0.0206\n",
      "Epoch 94/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 94/200, Iteration 133/250, Loss: 0.0097\n",
      "Epoch 94/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 135/250, Loss: 0.0188\n",
      "Epoch 94/200, Iteration 136/250, Loss: 0.0127\n",
      "Epoch 94/200, Iteration 137/250, Loss: 0.0158\n",
      "Epoch 94/200, Iteration 138/250, Loss: 0.0171\n",
      "Epoch 94/200, Iteration 139/250, Loss: 0.0077\n",
      "Epoch 94/200, Iteration 140/250, Loss: 0.0158\n",
      "Epoch 94/200, Iteration 141/250, Loss: 0.0130\n",
      "Epoch 94/200, Iteration 142/250, Loss: 0.0066\n",
      "Epoch 94/200, Iteration 143/250, Loss: 0.0112\n",
      "Epoch 94/200, Iteration 144/250, Loss: 0.0194\n",
      "Epoch 94/200, Iteration 145/250, Loss: 0.0364\n",
      "Epoch 94/200, Iteration 146/250, Loss: 0.0097\n",
      "Epoch 94/200, Iteration 147/250, Loss: 0.0155\n",
      "Epoch 94/200, Iteration 148/250, Loss: 0.0083\n",
      "Epoch 94/200, Iteration 149/250, Loss: 0.0243\n",
      "Epoch 94/200, Iteration 150/250, Loss: 0.0125\n",
      "Epoch 94/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 94/200, Iteration 152/250, Loss: 0.0129\n",
      "Epoch 94/200, Iteration 153/250, Loss: 0.0213\n",
      "Epoch 94/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 94/200, Iteration 155/250, Loss: 0.0238\n",
      "Epoch 94/200, Iteration 156/250, Loss: 0.0153\n",
      "Epoch 94/200, Iteration 157/250, Loss: 0.0136\n",
      "Epoch 94/200, Iteration 158/250, Loss: 0.0151\n",
      "Epoch 94/200, Iteration 159/250, Loss: 0.0079\n",
      "Epoch 94/200, Iteration 160/250, Loss: 0.0180\n",
      "Epoch 94/200, Iteration 161/250, Loss: 0.0134\n",
      "Epoch 94/200, Iteration 162/250, Loss: 0.0174\n",
      "Epoch 94/200, Iteration 163/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 164/250, Loss: 0.0218\n",
      "Epoch 94/200, Iteration 165/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 166/250, Loss: 0.0184\n",
      "Epoch 94/200, Iteration 167/250, Loss: 0.0071\n",
      "Epoch 94/200, Iteration 168/250, Loss: 0.0221\n",
      "Epoch 94/200, Iteration 169/250, Loss: 0.0284\n",
      "Epoch 94/200, Iteration 170/250, Loss: 0.0094\n",
      "Epoch 94/200, Iteration 171/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 172/250, Loss: 0.0259\n",
      "Epoch 94/200, Iteration 173/250, Loss: 0.0073\n",
      "Epoch 94/200, Iteration 174/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 175/250, Loss: 0.0268\n",
      "Epoch 94/200, Iteration 176/250, Loss: 0.0115\n",
      "Epoch 94/200, Iteration 177/250, Loss: 0.0086\n",
      "Epoch 94/200, Iteration 178/250, Loss: 0.0168\n",
      "Epoch 94/200, Iteration 179/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 180/250, Loss: 0.0095\n",
      "Epoch 94/200, Iteration 181/250, Loss: 0.0143\n",
      "Epoch 94/200, Iteration 182/250, Loss: 0.0218\n",
      "Epoch 94/200, Iteration 183/250, Loss: 0.0246\n",
      "Epoch 94/200, Iteration 184/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 185/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 186/250, Loss: 0.0220\n",
      "Epoch 94/200, Iteration 187/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 188/250, Loss: 0.0086\n",
      "Epoch 94/200, Iteration 189/250, Loss: 0.0341\n",
      "Epoch 94/200, Iteration 190/250, Loss: 0.0412\n",
      "Epoch 94/200, Iteration 191/250, Loss: 0.0186\n",
      "Epoch 94/200, Iteration 192/250, Loss: 0.0372\n",
      "Epoch 94/200, Iteration 193/250, Loss: 0.0215\n",
      "Epoch 94/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 94/200, Iteration 195/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 196/250, Loss: 0.0239\n",
      "Epoch 94/200, Iteration 197/250, Loss: 0.0138\n",
      "Epoch 94/200, Iteration 198/250, Loss: 0.0213\n",
      "Epoch 94/200, Iteration 199/250, Loss: 0.0182\n",
      "Epoch 94/200, Iteration 200/250, Loss: 0.0081\n",
      "Epoch 94/200, Iteration 201/250, Loss: 0.0110\n",
      "Epoch 94/200, Iteration 202/250, Loss: 0.0139\n",
      "Epoch 94/200, Iteration 203/250, Loss: 0.0082\n",
      "Epoch 94/200, Iteration 204/250, Loss: 0.0211\n",
      "Epoch 94/200, Iteration 205/250, Loss: 0.0143\n",
      "Epoch 94/200, Iteration 206/250, Loss: 0.0221\n",
      "Epoch 94/200, Iteration 207/250, Loss: 0.0220\n",
      "Epoch 94/200, Iteration 208/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 209/250, Loss: 0.0065\n",
      "Epoch 94/200, Iteration 210/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 211/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 213/250, Loss: 0.0069\n",
      "Epoch 94/200, Iteration 214/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 215/250, Loss: 0.0183\n",
      "Epoch 94/200, Iteration 216/250, Loss: 0.0062\n",
      "Epoch 94/200, Iteration 217/250, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 94/200, Iteration 219/250, Loss: 0.0192\n",
      "Epoch 94/200, Iteration 220/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 221/250, Loss: 0.0211\n",
      "Epoch 94/200, Iteration 222/250, Loss: 0.0086\n",
      "Epoch 94/200, Iteration 223/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 224/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 225/250, Loss: 0.0178\n",
      "Epoch 94/200, Iteration 226/250, Loss: 0.0152\n",
      "Epoch 94/200, Iteration 227/250, Loss: 0.0181\n",
      "Epoch 94/200, Iteration 228/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 229/250, Loss: 0.0193\n",
      "Epoch 94/200, Iteration 230/250, Loss: 0.0215\n",
      "Epoch 94/200, Iteration 231/250, Loss: 0.0228\n",
      "Epoch 94/200, Iteration 232/250, Loss: 0.0223\n",
      "Epoch 94/200, Iteration 233/250, Loss: 0.0268\n",
      "Epoch 94/200, Iteration 234/250, Loss: 0.0153\n",
      "Epoch 94/200, Iteration 235/250, Loss: 0.0168\n",
      "Epoch 94/200, Iteration 236/250, Loss: 0.0078\n",
      "Epoch 94/200, Iteration 237/250, Loss: 0.0206\n",
      "Epoch 94/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 239/250, Loss: 0.0090\n",
      "Epoch 94/200, Iteration 240/250, Loss: 0.0295\n",
      "Epoch 94/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 94/200, Iteration 242/250, Loss: 0.0230\n",
      "Epoch 94/200, Iteration 243/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 244/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 245/250, Loss: 0.0273\n",
      "Epoch 94/200, Iteration 246/250, Loss: 0.0119\n",
      "Epoch 94/200, Iteration 247/250, Loss: 0.0091\n",
      "Epoch 94/200, Iteration 248/250, Loss: 0.0226\n",
      "Epoch 94/200, Iteration 249/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 250/250, Loss: 0.0120\n",
      "Train Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.006421, MRE: 0.617278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.006348, MRE: 1.143765 \n",
      "\n",
      "Epoch 95/200, Iteration 1/250, Loss: 0.0189\n",
      "Epoch 95/200, Iteration 2/250, Loss: 0.0093\n",
      "Epoch 95/200, Iteration 3/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 4/250, Loss: 0.0113\n",
      "Epoch 95/200, Iteration 5/250, Loss: 0.0123\n",
      "Epoch 95/200, Iteration 6/250, Loss: 0.0149\n",
      "Epoch 95/200, Iteration 7/250, Loss: 0.0072\n",
      "Epoch 95/200, Iteration 8/250, Loss: 0.0224\n",
      "Epoch 95/200, Iteration 9/250, Loss: 0.0236\n",
      "Epoch 95/200, Iteration 10/250, Loss: 0.0257\n",
      "Epoch 95/200, Iteration 11/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 12/250, Loss: 0.0234\n",
      "Epoch 95/200, Iteration 13/250, Loss: 0.0080\n",
      "Epoch 95/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 15/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 16/250, Loss: 0.0068\n",
      "Epoch 95/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 95/200, Iteration 18/250, Loss: 0.0130\n",
      "Epoch 95/200, Iteration 19/250, Loss: 0.0122\n",
      "Epoch 95/200, Iteration 20/250, Loss: 0.0147\n",
      "Epoch 95/200, Iteration 21/250, Loss: 0.0256\n",
      "Epoch 95/200, Iteration 22/250, Loss: 0.0162\n",
      "Epoch 95/200, Iteration 23/250, Loss: 0.0214\n",
      "Epoch 95/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 95/200, Iteration 25/250, Loss: 0.0115\n",
      "Epoch 95/200, Iteration 26/250, Loss: 0.0100\n",
      "Epoch 95/200, Iteration 27/250, Loss: 0.0104\n",
      "Epoch 95/200, Iteration 28/250, Loss: 0.0185\n",
      "Epoch 95/200, Iteration 29/250, Loss: 0.0266\n",
      "Epoch 95/200, Iteration 30/250, Loss: 0.0098\n",
      "Epoch 95/200, Iteration 31/250, Loss: 0.0248\n",
      "Epoch 95/200, Iteration 32/250, Loss: 0.0068\n",
      "Epoch 95/200, Iteration 33/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 34/250, Loss: 0.0269\n",
      "Epoch 95/200, Iteration 35/250, Loss: 0.0261\n",
      "Epoch 95/200, Iteration 36/250, Loss: 0.0086\n",
      "Epoch 95/200, Iteration 37/250, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 38/250, Loss: 0.0125\n",
      "Epoch 95/200, Iteration 39/250, Loss: 0.0189\n",
      "Epoch 95/200, Iteration 40/250, Loss: 0.0066\n",
      "Epoch 95/200, Iteration 41/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 43/250, Loss: 0.0163\n",
      "Epoch 95/200, Iteration 44/250, Loss: 0.0084\n",
      "Epoch 95/200, Iteration 45/250, Loss: 0.0150\n",
      "Epoch 95/200, Iteration 46/250, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 47/250, Loss: 0.0133\n",
      "Epoch 95/200, Iteration 48/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 49/250, Loss: 0.0250\n",
      "Epoch 95/200, Iteration 50/250, Loss: 0.0109\n",
      "Epoch 95/200, Iteration 51/250, Loss: 0.0111\n",
      "Epoch 95/200, Iteration 52/250, Loss: 0.0164\n",
      "Epoch 95/200, Iteration 53/250, Loss: 0.0106\n",
      "Epoch 95/200, Iteration 54/250, Loss: 0.0204\n",
      "Epoch 95/200, Iteration 55/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 57/250, Loss: 0.0272\n",
      "Epoch 95/200, Iteration 58/250, Loss: 0.0223\n",
      "Epoch 95/200, Iteration 59/250, Loss: 0.0267\n",
      "Epoch 95/200, Iteration 60/250, Loss: 0.0077\n",
      "Epoch 95/200, Iteration 61/250, Loss: 0.0086\n",
      "Epoch 95/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 95/200, Iteration 63/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 64/250, Loss: 0.0264\n",
      "Epoch 95/200, Iteration 65/250, Loss: 0.0069\n",
      "Epoch 95/200, Iteration 66/250, Loss: 0.0102\n",
      "Epoch 95/200, Iteration 67/250, Loss: 0.0267\n",
      "Epoch 95/200, Iteration 68/250, Loss: 0.0151\n",
      "Epoch 95/200, Iteration 69/250, Loss: 0.0074\n",
      "Epoch 95/200, Iteration 70/250, Loss: 0.0138\n",
      "Epoch 95/200, Iteration 71/250, Loss: 0.0191\n",
      "Epoch 95/200, Iteration 72/250, Loss: 0.0171\n",
      "Epoch 95/200, Iteration 73/250, Loss: 0.0155\n",
      "Epoch 95/200, Iteration 74/250, Loss: 0.0212\n",
      "Epoch 95/200, Iteration 75/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 76/250, Loss: 0.0143\n",
      "Epoch 95/200, Iteration 77/250, Loss: 0.0107\n",
      "Epoch 95/200, Iteration 78/250, Loss: 0.0114\n",
      "Epoch 95/200, Iteration 79/250, Loss: 0.0089\n",
      "Epoch 95/200, Iteration 80/250, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 81/250, Loss: 0.0115\n",
      "Epoch 95/200, Iteration 82/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 83/250, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 84/250, Loss: 0.0083\n",
      "Epoch 95/200, Iteration 85/250, Loss: 0.0162\n",
      "Epoch 95/200, Iteration 86/250, Loss: 0.0246\n",
      "Epoch 95/200, Iteration 87/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 89/250, Loss: 0.0173\n",
      "Epoch 95/200, Iteration 90/250, Loss: 0.0182\n",
      "Epoch 95/200, Iteration 91/250, Loss: 0.0144\n",
      "Epoch 95/200, Iteration 92/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 93/250, Loss: 0.0184\n",
      "Epoch 95/200, Iteration 94/250, Loss: 0.0105\n",
      "Epoch 95/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 95/200, Iteration 96/250, Loss: 0.0201\n",
      "Epoch 95/200, Iteration 97/250, Loss: 0.0078\n",
      "Epoch 95/200, Iteration 98/250, Loss: 0.0121\n",
      "Epoch 95/200, Iteration 99/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 100/250, Loss: 0.0222\n",
      "Epoch 95/200, Iteration 101/250, Loss: 0.0121\n",
      "Epoch 95/200, Iteration 102/250, Loss: 0.0115\n",
      "Epoch 95/200, Iteration 103/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 104/250, Loss: 0.0240\n",
      "Epoch 95/200, Iteration 105/250, Loss: 0.0158\n",
      "Epoch 95/200, Iteration 106/250, Loss: 0.0086\n",
      "Epoch 95/200, Iteration 107/250, Loss: 0.0208\n",
      "Epoch 95/200, Iteration 108/250, Loss: 0.0078\n",
      "Epoch 95/200, Iteration 109/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 110/250, Loss: 0.0128\n",
      "Epoch 95/200, Iteration 111/250, Loss: 0.0195\n",
      "Epoch 95/200, Iteration 112/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 113/250, Loss: 0.0345\n",
      "Epoch 95/200, Iteration 114/250, Loss: 0.0300\n",
      "Epoch 95/200, Iteration 115/250, Loss: 0.0178\n",
      "Epoch 95/200, Iteration 116/250, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 117/250, Loss: 0.0157\n",
      "Epoch 95/200, Iteration 118/250, Loss: 0.0145\n",
      "Epoch 95/200, Iteration 119/250, Loss: 0.0109\n",
      "Epoch 95/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 95/200, Iteration 121/250, Loss: 0.0118\n",
      "Epoch 95/200, Iteration 122/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 123/250, Loss: 0.0349\n",
      "Epoch 95/200, Iteration 124/250, Loss: 0.0099\n",
      "Epoch 95/200, Iteration 125/250, Loss: 0.0154\n",
      "Epoch 95/200, Iteration 126/250, Loss: 0.0220\n",
      "Epoch 95/200, Iteration 127/250, Loss: 0.0214\n",
      "Epoch 95/200, Iteration 128/250, Loss: 0.0188\n",
      "Epoch 95/200, Iteration 129/250, Loss: 0.0123\n",
      "Epoch 95/200, Iteration 130/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 131/250, Loss: 0.0105\n",
      "Epoch 95/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 95/200, Iteration 133/250, Loss: 0.0142\n",
      "Epoch 95/200, Iteration 134/250, Loss: 0.0221\n",
      "Epoch 95/200, Iteration 135/250, Loss: 0.0083\n",
      "Epoch 95/200, Iteration 136/250, Loss: 0.0147\n",
      "Epoch 95/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 95/200, Iteration 138/250, Loss: 0.0100\n",
      "Epoch 95/200, Iteration 139/250, Loss: 0.0124\n",
      "Epoch 95/200, Iteration 140/250, Loss: 0.0220\n",
      "Epoch 95/200, Iteration 141/250, Loss: 0.0260\n",
      "Epoch 95/200, Iteration 142/250, Loss: 0.0211\n",
      "Epoch 95/200, Iteration 143/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 95/200, Iteration 145/250, Loss: 0.0203\n",
      "Epoch 95/200, Iteration 146/250, Loss: 0.0158\n",
      "Epoch 95/200, Iteration 147/250, Loss: 0.0118\n",
      "Epoch 95/200, Iteration 148/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 150/250, Loss: 0.0284\n",
      "Epoch 95/200, Iteration 151/250, Loss: 0.0226\n",
      "Epoch 95/200, Iteration 152/250, Loss: 0.0169\n",
      "Epoch 95/200, Iteration 153/250, Loss: 0.0328\n",
      "Epoch 95/200, Iteration 154/250, Loss: 0.0126\n",
      "Epoch 95/200, Iteration 155/250, Loss: 0.0318\n",
      "Epoch 95/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 95/200, Iteration 157/250, Loss: 0.0161\n",
      "Epoch 95/200, Iteration 158/250, Loss: 0.0164\n",
      "Epoch 95/200, Iteration 159/250, Loss: 0.0219\n",
      "Epoch 95/200, Iteration 160/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 161/250, Loss: 0.0310\n",
      "Epoch 95/200, Iteration 162/250, Loss: 0.0144\n",
      "Epoch 95/200, Iteration 163/250, Loss: 0.0175\n",
      "Epoch 95/200, Iteration 164/250, Loss: 0.0106\n",
      "Epoch 95/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 95/200, Iteration 166/250, Loss: 0.0217\n",
      "Epoch 95/200, Iteration 167/250, Loss: 0.0135\n",
      "Epoch 95/200, Iteration 168/250, Loss: 0.0203\n",
      "Epoch 95/200, Iteration 169/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 170/250, Loss: 0.0273\n",
      "Epoch 95/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 95/200, Iteration 172/250, Loss: 0.0120\n",
      "Epoch 95/200, Iteration 173/250, Loss: 0.0070\n",
      "Epoch 95/200, Iteration 174/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 175/250, Loss: 0.0105\n",
      "Epoch 95/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 95/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 178/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 179/250, Loss: 0.0146\n",
      "Epoch 95/200, Iteration 180/250, Loss: 0.0128\n",
      "Epoch 95/200, Iteration 181/250, Loss: 0.0147\n",
      "Epoch 95/200, Iteration 182/250, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 183/250, Loss: 0.0086\n",
      "Epoch 95/200, Iteration 184/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 185/250, Loss: 0.0251\n",
      "Epoch 95/200, Iteration 186/250, Loss: 0.0155\n",
      "Epoch 95/200, Iteration 187/250, Loss: 0.0144\n",
      "Epoch 95/200, Iteration 188/250, Loss: 0.0201\n",
      "Epoch 95/200, Iteration 189/250, Loss: 0.0098\n",
      "Epoch 95/200, Iteration 190/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 191/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 192/250, Loss: 0.0111\n",
      "Epoch 95/200, Iteration 193/250, Loss: 0.0246\n",
      "Epoch 95/200, Iteration 194/250, Loss: 0.0201\n",
      "Epoch 95/200, Iteration 195/250, Loss: 0.0093\n",
      "Epoch 95/200, Iteration 196/250, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 197/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 199/250, Loss: 0.0124\n",
      "Epoch 95/200, Iteration 200/250, Loss: 0.0130\n",
      "Epoch 95/200, Iteration 201/250, Loss: 0.0184\n",
      "Epoch 95/200, Iteration 202/250, Loss: 0.0194\n",
      "Epoch 95/200, Iteration 203/250, Loss: 0.0114\n",
      "Epoch 95/200, Iteration 204/250, Loss: 0.0145\n",
      "Epoch 95/200, Iteration 205/250, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 206/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 207/250, Loss: 0.0148\n",
      "Epoch 95/200, Iteration 208/250, Loss: 0.0201\n",
      "Epoch 95/200, Iteration 209/250, Loss: 0.0123\n",
      "Epoch 95/200, Iteration 210/250, Loss: 0.0188\n",
      "Epoch 95/200, Iteration 211/250, Loss: 0.0203\n",
      "Epoch 95/200, Iteration 212/250, Loss: 0.0117\n",
      "Epoch 95/200, Iteration 213/250, Loss: 0.0077\n",
      "Epoch 95/200, Iteration 214/250, Loss: 0.0203\n",
      "Epoch 95/200, Iteration 215/250, Loss: 0.0236\n",
      "Epoch 95/200, Iteration 216/250, Loss: 0.0194\n",
      "Epoch 95/200, Iteration 217/250, Loss: 0.0207\n",
      "Epoch 95/200, Iteration 218/250, Loss: 0.0122\n",
      "Epoch 95/200, Iteration 219/250, Loss: 0.0175\n",
      "Epoch 95/200, Iteration 220/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 221/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 222/250, Loss: 0.0212\n",
      "Epoch 95/200, Iteration 223/250, Loss: 0.0211\n",
      "Epoch 95/200, Iteration 224/250, Loss: 0.0226\n",
      "Epoch 95/200, Iteration 225/250, Loss: 0.0311\n",
      "Epoch 95/200, Iteration 226/250, Loss: 0.0104\n",
      "Epoch 95/200, Iteration 227/250, Loss: 0.0161\n",
      "Epoch 95/200, Iteration 228/250, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 229/250, Loss: 0.0113\n",
      "Epoch 95/200, Iteration 230/250, Loss: 0.0138\n",
      "Epoch 95/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 95/200, Iteration 232/250, Loss: 0.0219\n",
      "Epoch 95/200, Iteration 233/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 95/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 95/200, Iteration 236/250, Loss: 0.0154\n",
      "Epoch 95/200, Iteration 237/250, Loss: 0.0189\n",
      "Epoch 95/200, Iteration 238/250, Loss: 0.0260\n",
      "Epoch 95/200, Iteration 239/250, Loss: 0.0272\n",
      "Epoch 95/200, Iteration 240/250, Loss: 0.0117\n",
      "Epoch 95/200, Iteration 241/250, Loss: 0.0294\n",
      "Epoch 95/200, Iteration 242/250, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 243/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 244/250, Loss: 0.0210\n",
      "Epoch 95/200, Iteration 245/250, Loss: 0.0097\n",
      "Epoch 95/200, Iteration 246/250, Loss: 0.0204\n",
      "Epoch 95/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 95/200, Iteration 248/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 249/250, Loss: 0.0143\n",
      "Epoch 95/200, Iteration 250/250, Loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 92.64%, Avg loss: 0.005935, MRE: 0.580607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.005937, MRE: 0.893740 \n",
      "\n",
      "Epoch 96/200, Iteration 1/250, Loss: 0.0329\n",
      "Epoch 96/200, Iteration 2/250, Loss: 0.0227\n",
      "Epoch 96/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 4/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 5/250, Loss: 0.0142\n",
      "Epoch 96/200, Iteration 6/250, Loss: 0.0511\n",
      "Epoch 96/200, Iteration 7/250, Loss: 0.0103\n",
      "Epoch 96/200, Iteration 8/250, Loss: 0.0241\n",
      "Epoch 96/200, Iteration 9/250, Loss: 0.0100\n",
      "Epoch 96/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 11/250, Loss: 0.0083\n",
      "Epoch 96/200, Iteration 12/250, Loss: 0.0166\n",
      "Epoch 96/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 14/250, Loss: 0.0134\n",
      "Epoch 96/200, Iteration 15/250, Loss: 0.0217\n",
      "Epoch 96/200, Iteration 16/250, Loss: 0.0221\n",
      "Epoch 96/200, Iteration 17/250, Loss: 0.0091\n",
      "Epoch 96/200, Iteration 18/250, Loss: 0.0173\n",
      "Epoch 96/200, Iteration 19/250, Loss: 0.0317\n",
      "Epoch 96/200, Iteration 20/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 21/250, Loss: 0.0147\n",
      "Epoch 96/200, Iteration 22/250, Loss: 0.0222\n",
      "Epoch 96/200, Iteration 23/250, Loss: 0.0197\n",
      "Epoch 96/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 96/200, Iteration 25/250, Loss: 0.0164\n",
      "Epoch 96/200, Iteration 26/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 27/250, Loss: 0.0090\n",
      "Epoch 96/200, Iteration 28/250, Loss: 0.0229\n",
      "Epoch 96/200, Iteration 29/250, Loss: 0.0198\n",
      "Epoch 96/200, Iteration 30/250, Loss: 0.0113\n",
      "Epoch 96/200, Iteration 31/250, Loss: 0.0245\n",
      "Epoch 96/200, Iteration 32/250, Loss: 0.0264\n",
      "Epoch 96/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 34/250, Loss: 0.0088\n",
      "Epoch 96/200, Iteration 35/250, Loss: 0.0311\n",
      "Epoch 96/200, Iteration 36/250, Loss: 0.0118\n",
      "Epoch 96/200, Iteration 37/250, Loss: 0.0098\n",
      "Epoch 96/200, Iteration 38/250, Loss: 0.0054\n",
      "Epoch 96/200, Iteration 39/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 40/250, Loss: 0.0210\n",
      "Epoch 96/200, Iteration 41/250, Loss: 0.0198\n",
      "Epoch 96/200, Iteration 42/250, Loss: 0.0240\n",
      "Epoch 96/200, Iteration 43/250, Loss: 0.0287\n",
      "Epoch 96/200, Iteration 44/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 45/250, Loss: 0.0132\n",
      "Epoch 96/200, Iteration 46/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 47/250, Loss: 0.0067\n",
      "Epoch 96/200, Iteration 48/250, Loss: 0.0118\n",
      "Epoch 96/200, Iteration 49/250, Loss: 0.0177\n",
      "Epoch 96/200, Iteration 50/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 51/250, Loss: 0.0193\n",
      "Epoch 96/200, Iteration 52/250, Loss: 0.0448\n",
      "Epoch 96/200, Iteration 53/250, Loss: 0.0211\n",
      "Epoch 96/200, Iteration 54/250, Loss: 0.0212\n",
      "Epoch 96/200, Iteration 55/250, Loss: 0.0136\n",
      "Epoch 96/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 96/200, Iteration 57/250, Loss: 0.0106\n",
      "Epoch 96/200, Iteration 58/250, Loss: 0.0092\n",
      "Epoch 96/200, Iteration 59/250, Loss: 0.0162\n",
      "Epoch 96/200, Iteration 60/250, Loss: 0.0082\n",
      "Epoch 96/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 96/200, Iteration 62/250, Loss: 0.0091\n",
      "Epoch 96/200, Iteration 63/250, Loss: 0.0089\n",
      "Epoch 96/200, Iteration 64/250, Loss: 0.0237\n",
      "Epoch 96/200, Iteration 65/250, Loss: 0.0072\n",
      "Epoch 96/200, Iteration 66/250, Loss: 0.0146\n",
      "Epoch 96/200, Iteration 67/250, Loss: 0.0206\n",
      "Epoch 96/200, Iteration 68/250, Loss: 0.0115\n",
      "Epoch 96/200, Iteration 69/250, Loss: 0.0232\n",
      "Epoch 96/200, Iteration 70/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 71/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 72/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 73/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 74/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 75/250, Loss: 0.0300\n",
      "Epoch 96/200, Iteration 76/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 77/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 78/250, Loss: 0.0169\n",
      "Epoch 96/200, Iteration 79/250, Loss: 0.0097\n",
      "Epoch 96/200, Iteration 80/250, Loss: 0.0141\n",
      "Epoch 96/200, Iteration 81/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 82/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 83/250, Loss: 0.0211\n",
      "Epoch 96/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 96/200, Iteration 85/250, Loss: 0.0177\n",
      "Epoch 96/200, Iteration 86/250, Loss: 0.0065\n",
      "Epoch 96/200, Iteration 87/250, Loss: 0.0212\n",
      "Epoch 96/200, Iteration 88/250, Loss: 0.0100\n",
      "Epoch 96/200, Iteration 89/250, Loss: 0.0116\n",
      "Epoch 96/200, Iteration 90/250, Loss: 0.0258\n",
      "Epoch 96/200, Iteration 91/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 92/250, Loss: 0.0129\n",
      "Epoch 96/200, Iteration 93/250, Loss: 0.0298\n",
      "Epoch 96/200, Iteration 94/250, Loss: 0.0119\n",
      "Epoch 96/200, Iteration 95/250, Loss: 0.0221\n",
      "Epoch 96/200, Iteration 96/250, Loss: 0.0150\n",
      "Epoch 96/200, Iteration 97/250, Loss: 0.0146\n",
      "Epoch 96/200, Iteration 98/250, Loss: 0.0370\n",
      "Epoch 96/200, Iteration 99/250, Loss: 0.0095\n",
      "Epoch 96/200, Iteration 100/250, Loss: 0.0092\n",
      "Epoch 96/200, Iteration 101/250, Loss: 0.0205\n",
      "Epoch 96/200, Iteration 102/250, Loss: 0.0077\n",
      "Epoch 96/200, Iteration 103/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 104/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 105/250, Loss: 0.0047\n",
      "Epoch 96/200, Iteration 106/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 107/250, Loss: 0.0187\n",
      "Epoch 96/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 96/200, Iteration 109/250, Loss: 0.0076\n",
      "Epoch 96/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 111/250, Loss: 0.0132\n",
      "Epoch 96/200, Iteration 112/250, Loss: 0.0263\n",
      "Epoch 96/200, Iteration 113/250, Loss: 0.0146\n",
      "Epoch 96/200, Iteration 114/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 115/250, Loss: 0.0143\n",
      "Epoch 96/200, Iteration 116/250, Loss: 0.0159\n",
      "Epoch 96/200, Iteration 117/250, Loss: 0.0188\n",
      "Epoch 96/200, Iteration 118/250, Loss: 0.0095\n",
      "Epoch 96/200, Iteration 119/250, Loss: 0.0074\n",
      "Epoch 96/200, Iteration 120/250, Loss: 0.0084\n",
      "Epoch 96/200, Iteration 121/250, Loss: 0.0074\n",
      "Epoch 96/200, Iteration 122/250, Loss: 0.0163\n",
      "Epoch 96/200, Iteration 123/250, Loss: 0.0165\n",
      "Epoch 96/200, Iteration 124/250, Loss: 0.0085\n",
      "Epoch 96/200, Iteration 125/250, Loss: 0.0292\n",
      "Epoch 96/200, Iteration 126/250, Loss: 0.0142\n",
      "Epoch 96/200, Iteration 127/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 128/250, Loss: 0.0088\n",
      "Epoch 96/200, Iteration 129/250, Loss: 0.0366\n",
      "Epoch 96/200, Iteration 130/250, Loss: 0.0198\n",
      "Epoch 96/200, Iteration 131/250, Loss: 0.0228\n",
      "Epoch 96/200, Iteration 132/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 133/250, Loss: 0.0068\n",
      "Epoch 96/200, Iteration 134/250, Loss: 0.0201\n",
      "Epoch 96/200, Iteration 135/250, Loss: 0.0077\n",
      "Epoch 96/200, Iteration 136/250, Loss: 0.0127\n",
      "Epoch 96/200, Iteration 137/250, Loss: 0.0100\n",
      "Epoch 96/200, Iteration 138/250, Loss: 0.0082\n",
      "Epoch 96/200, Iteration 139/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 140/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 141/250, Loss: 0.0076\n",
      "Epoch 96/200, Iteration 142/250, Loss: 0.0159\n",
      "Epoch 96/200, Iteration 143/250, Loss: 0.0073\n",
      "Epoch 96/200, Iteration 144/250, Loss: 0.0117\n",
      "Epoch 96/200, Iteration 145/250, Loss: 0.0266\n",
      "Epoch 96/200, Iteration 146/250, Loss: 0.0312\n",
      "Epoch 96/200, Iteration 147/250, Loss: 0.0218\n",
      "Epoch 96/200, Iteration 148/250, Loss: 0.0115\n",
      "Epoch 96/200, Iteration 149/250, Loss: 0.0153\n",
      "Epoch 96/200, Iteration 150/250, Loss: 0.0068\n",
      "Epoch 96/200, Iteration 151/250, Loss: 0.0182\n",
      "Epoch 96/200, Iteration 152/250, Loss: 0.0244\n",
      "Epoch 96/200, Iteration 153/250, Loss: 0.0274\n",
      "Epoch 96/200, Iteration 154/250, Loss: 0.0236\n",
      "Epoch 96/200, Iteration 155/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 156/250, Loss: 0.0380\n",
      "Epoch 96/200, Iteration 157/250, Loss: 0.0090\n",
      "Epoch 96/200, Iteration 158/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 159/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 160/250, Loss: 0.0162\n",
      "Epoch 96/200, Iteration 161/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 162/250, Loss: 0.0091\n",
      "Epoch 96/200, Iteration 163/250, Loss: 0.0178\n",
      "Epoch 96/200, Iteration 164/250, Loss: 0.0094\n",
      "Epoch 96/200, Iteration 165/250, Loss: 0.0179\n",
      "Epoch 96/200, Iteration 166/250, Loss: 0.0180\n",
      "Epoch 96/200, Iteration 167/250, Loss: 0.0081\n",
      "Epoch 96/200, Iteration 168/250, Loss: 0.0155\n",
      "Epoch 96/200, Iteration 169/250, Loss: 0.0185\n",
      "Epoch 96/200, Iteration 170/250, Loss: 0.0100\n",
      "Epoch 96/200, Iteration 171/250, Loss: 0.0306\n",
      "Epoch 96/200, Iteration 172/250, Loss: 0.0314\n",
      "Epoch 96/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 96/200, Iteration 174/250, Loss: 0.0077\n",
      "Epoch 96/200, Iteration 175/250, Loss: 0.0068\n",
      "Epoch 96/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 96/200, Iteration 177/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 178/250, Loss: 0.0114\n",
      "Epoch 96/200, Iteration 179/250, Loss: 0.0276\n",
      "Epoch 96/200, Iteration 180/250, Loss: 0.0352\n",
      "Epoch 96/200, Iteration 181/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 182/250, Loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200, Iteration 183/250, Loss: 0.0196\n",
      "Epoch 96/200, Iteration 184/250, Loss: 0.0094\n",
      "Epoch 96/200, Iteration 185/250, Loss: 0.0265\n",
      "Epoch 96/200, Iteration 186/250, Loss: 0.0160\n",
      "Epoch 96/200, Iteration 187/250, Loss: 0.0251\n",
      "Epoch 96/200, Iteration 188/250, Loss: 0.0121\n",
      "Epoch 96/200, Iteration 189/250, Loss: 0.0095\n",
      "Epoch 96/200, Iteration 190/250, Loss: 0.0213\n",
      "Epoch 96/200, Iteration 191/250, Loss: 0.0074\n",
      "Epoch 96/200, Iteration 192/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 193/250, Loss: 0.0311\n",
      "Epoch 96/200, Iteration 194/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 195/250, Loss: 0.0188\n",
      "Epoch 96/200, Iteration 196/250, Loss: 0.0097\n",
      "Epoch 96/200, Iteration 197/250, Loss: 0.0084\n",
      "Epoch 96/200, Iteration 198/250, Loss: 0.0183\n",
      "Epoch 96/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 200/250, Loss: 0.0181\n",
      "Epoch 96/200, Iteration 201/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 202/250, Loss: 0.0151\n",
      "Epoch 96/200, Iteration 203/250, Loss: 0.0342\n",
      "Epoch 96/200, Iteration 204/250, Loss: 0.0250\n",
      "Epoch 96/200, Iteration 205/250, Loss: 0.0124\n",
      "Epoch 96/200, Iteration 206/250, Loss: 0.0139\n",
      "Epoch 96/200, Iteration 207/250, Loss: 0.0356\n",
      "Epoch 96/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 96/200, Iteration 209/250, Loss: 0.0119\n",
      "Epoch 96/200, Iteration 210/250, Loss: 0.0133\n",
      "Epoch 96/200, Iteration 211/250, Loss: 0.0115\n",
      "Epoch 96/200, Iteration 212/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 213/250, Loss: 0.0073\n",
      "Epoch 96/200, Iteration 214/250, Loss: 0.0263\n",
      "Epoch 96/200, Iteration 215/250, Loss: 0.0281\n",
      "Epoch 96/200, Iteration 216/250, Loss: 0.0302\n",
      "Epoch 96/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 96/200, Iteration 218/250, Loss: 0.0183\n",
      "Epoch 96/200, Iteration 219/250, Loss: 0.0073\n",
      "Epoch 96/200, Iteration 220/250, Loss: 0.0130\n",
      "Epoch 96/200, Iteration 221/250, Loss: 0.0255\n",
      "Epoch 96/200, Iteration 222/250, Loss: 0.0075\n",
      "Epoch 96/200, Iteration 223/250, Loss: 0.0198\n",
      "Epoch 96/200, Iteration 224/250, Loss: 0.0073\n",
      "Epoch 96/200, Iteration 225/250, Loss: 0.0115\n",
      "Epoch 96/200, Iteration 226/250, Loss: 0.0193\n",
      "Epoch 96/200, Iteration 227/250, Loss: 0.0240\n",
      "Epoch 96/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 96/200, Iteration 229/250, Loss: 0.0210\n",
      "Epoch 96/200, Iteration 230/250, Loss: 0.0267\n",
      "Epoch 96/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 232/250, Loss: 0.0208\n",
      "Epoch 96/200, Iteration 233/250, Loss: 0.0088\n",
      "Epoch 96/200, Iteration 234/250, Loss: 0.0144\n",
      "Epoch 96/200, Iteration 235/250, Loss: 0.0225\n",
      "Epoch 96/200, Iteration 236/250, Loss: 0.0195\n",
      "Epoch 96/200, Iteration 237/250, Loss: 0.0117\n",
      "Epoch 96/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 96/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 96/200, Iteration 240/250, Loss: 0.0174\n",
      "Epoch 96/200, Iteration 241/250, Loss: 0.0081\n",
      "Epoch 96/200, Iteration 242/250, Loss: 0.0189\n",
      "Epoch 96/200, Iteration 243/250, Loss: 0.0139\n",
      "Epoch 96/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 96/200, Iteration 245/250, Loss: 0.0128\n",
      "Epoch 96/200, Iteration 246/250, Loss: 0.0055\n",
      "Epoch 96/200, Iteration 247/250, Loss: 0.0143\n",
      "Epoch 96/200, Iteration 248/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 249/250, Loss: 0.0106\n",
      "Epoch 96/200, Iteration 250/250, Loss: 0.0205\n",
      "Train Error: \n",
      " Accuracy: 94.86%, Avg loss: 0.006081, MRE: 0.572655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.006071, MRE: 0.940413 \n",
      "\n",
      "Epoch 97/200, Iteration 1/250, Loss: 0.0212\n",
      "Epoch 97/200, Iteration 2/250, Loss: 0.0083\n",
      "Epoch 97/200, Iteration 3/250, Loss: 0.0142\n",
      "Epoch 97/200, Iteration 4/250, Loss: 0.0174\n",
      "Epoch 97/200, Iteration 5/250, Loss: 0.0083\n",
      "Epoch 97/200, Iteration 6/250, Loss: 0.0167\n",
      "Epoch 97/200, Iteration 7/250, Loss: 0.0239\n",
      "Epoch 97/200, Iteration 8/250, Loss: 0.0257\n",
      "Epoch 97/200, Iteration 9/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 10/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 11/250, Loss: 0.0224\n",
      "Epoch 97/200, Iteration 12/250, Loss: 0.0140\n",
      "Epoch 97/200, Iteration 13/250, Loss: 0.0281\n",
      "Epoch 97/200, Iteration 14/250, Loss: 0.0108\n",
      "Epoch 97/200, Iteration 15/250, Loss: 0.0116\n",
      "Epoch 97/200, Iteration 16/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 17/250, Loss: 0.0217\n",
      "Epoch 97/200, Iteration 18/250, Loss: 0.0066\n",
      "Epoch 97/200, Iteration 19/250, Loss: 0.0068\n",
      "Epoch 97/200, Iteration 20/250, Loss: 0.0123\n",
      "Epoch 97/200, Iteration 21/250, Loss: 0.0084\n",
      "Epoch 97/200, Iteration 22/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 23/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 24/250, Loss: 0.0101\n",
      "Epoch 97/200, Iteration 25/250, Loss: 0.0168\n",
      "Epoch 97/200, Iteration 26/250, Loss: 0.0123\n",
      "Epoch 97/200, Iteration 27/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 28/250, Loss: 0.0095\n",
      "Epoch 97/200, Iteration 29/250, Loss: 0.0127\n",
      "Epoch 97/200, Iteration 30/250, Loss: 0.0150\n",
      "Epoch 97/200, Iteration 31/250, Loss: 0.0176\n",
      "Epoch 97/200, Iteration 32/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 33/250, Loss: 0.0083\n",
      "Epoch 97/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 97/200, Iteration 35/250, Loss: 0.0131\n",
      "Epoch 97/200, Iteration 36/250, Loss: 0.0106\n",
      "Epoch 97/200, Iteration 37/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 38/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 39/250, Loss: 0.0067\n",
      "Epoch 97/200, Iteration 40/250, Loss: 0.0113\n",
      "Epoch 97/200, Iteration 41/250, Loss: 0.0135\n",
      "Epoch 97/200, Iteration 42/250, Loss: 0.0087\n",
      "Epoch 97/200, Iteration 43/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 44/250, Loss: 0.0286\n",
      "Epoch 97/200, Iteration 45/250, Loss: 0.0212\n",
      "Epoch 97/200, Iteration 46/250, Loss: 0.0110\n",
      "Epoch 97/200, Iteration 47/250, Loss: 0.0136\n",
      "Epoch 97/200, Iteration 48/250, Loss: 0.0080\n",
      "Epoch 97/200, Iteration 49/250, Loss: 0.0206\n",
      "Epoch 97/200, Iteration 50/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 51/250, Loss: 0.0104\n",
      "Epoch 97/200, Iteration 52/250, Loss: 0.0145\n",
      "Epoch 97/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 97/200, Iteration 54/250, Loss: 0.0116\n",
      "Epoch 97/200, Iteration 55/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 56/250, Loss: 0.0169\n",
      "Epoch 97/200, Iteration 57/250, Loss: 0.0088\n",
      "Epoch 97/200, Iteration 58/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 59/250, Loss: 0.0202\n",
      "Epoch 97/200, Iteration 60/250, Loss: 0.0262\n",
      "Epoch 97/200, Iteration 61/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 62/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 63/250, Loss: 0.0219\n",
      "Epoch 97/200, Iteration 64/250, Loss: 0.0127\n",
      "Epoch 97/200, Iteration 65/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 66/250, Loss: 0.0090\n",
      "Epoch 97/200, Iteration 67/250, Loss: 0.0073\n",
      "Epoch 97/200, Iteration 68/250, Loss: 0.0143\n",
      "Epoch 97/200, Iteration 69/250, Loss: 0.0173\n",
      "Epoch 97/200, Iteration 70/250, Loss: 0.0260\n",
      "Epoch 97/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 97/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 97/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 74/250, Loss: 0.0337\n",
      "Epoch 97/200, Iteration 75/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 76/250, Loss: 0.0104\n",
      "Epoch 97/200, Iteration 77/250, Loss: 0.0122\n",
      "Epoch 97/200, Iteration 78/250, Loss: 0.0199\n",
      "Epoch 97/200, Iteration 79/250, Loss: 0.0155\n",
      "Epoch 97/200, Iteration 80/250, Loss: 0.0226\n",
      "Epoch 97/200, Iteration 81/250, Loss: 0.0169\n",
      "Epoch 97/200, Iteration 82/250, Loss: 0.0239\n",
      "Epoch 97/200, Iteration 83/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 84/250, Loss: 0.0248\n",
      "Epoch 97/200, Iteration 85/250, Loss: 0.0075\n",
      "Epoch 97/200, Iteration 86/250, Loss: 0.0108\n",
      "Epoch 97/200, Iteration 87/250, Loss: 0.0156\n",
      "Epoch 97/200, Iteration 88/250, Loss: 0.0073\n",
      "Epoch 97/200, Iteration 89/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 90/250, Loss: 0.0136\n",
      "Epoch 97/200, Iteration 91/250, Loss: 0.0196\n",
      "Epoch 97/200, Iteration 92/250, Loss: 0.0431\n",
      "Epoch 97/200, Iteration 93/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 94/250, Loss: 0.0139\n",
      "Epoch 97/200, Iteration 95/250, Loss: 0.0107\n",
      "Epoch 97/200, Iteration 96/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 97/250, Loss: 0.0172\n",
      "Epoch 97/200, Iteration 98/250, Loss: 0.0148\n",
      "Epoch 97/200, Iteration 99/250, Loss: 0.0255\n",
      "Epoch 97/200, Iteration 100/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 101/250, Loss: 0.0172\n",
      "Epoch 97/200, Iteration 102/250, Loss: 0.0062\n",
      "Epoch 97/200, Iteration 103/250, Loss: 0.0181\n",
      "Epoch 97/200, Iteration 104/250, Loss: 0.0137\n",
      "Epoch 97/200, Iteration 105/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 106/250, Loss: 0.0137\n",
      "Epoch 97/200, Iteration 107/250, Loss: 0.0168\n",
      "Epoch 97/200, Iteration 108/250, Loss: 0.0142\n",
      "Epoch 97/200, Iteration 109/250, Loss: 0.0161\n",
      "Epoch 97/200, Iteration 110/250, Loss: 0.0227\n",
      "Epoch 97/200, Iteration 111/250, Loss: 0.0212\n",
      "Epoch 97/200, Iteration 112/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 113/250, Loss: 0.0143\n",
      "Epoch 97/200, Iteration 114/250, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 115/250, Loss: 0.0078\n",
      "Epoch 97/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 117/250, Loss: 0.0193\n",
      "Epoch 97/200, Iteration 118/250, Loss: 0.0125\n",
      "Epoch 97/200, Iteration 119/250, Loss: 0.0157\n",
      "Epoch 97/200, Iteration 120/250, Loss: 0.0334\n",
      "Epoch 97/200, Iteration 121/250, Loss: 0.0076\n",
      "Epoch 97/200, Iteration 122/250, Loss: 0.0153\n",
      "Epoch 97/200, Iteration 123/250, Loss: 0.0124\n",
      "Epoch 97/200, Iteration 124/250, Loss: 0.0074\n",
      "Epoch 97/200, Iteration 125/250, Loss: 0.0248\n",
      "Epoch 97/200, Iteration 126/250, Loss: 0.0196\n",
      "Epoch 97/200, Iteration 127/250, Loss: 0.0158\n",
      "Epoch 97/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 129/250, Loss: 0.0256\n",
      "Epoch 97/200, Iteration 130/250, Loss: 0.0178\n",
      "Epoch 97/200, Iteration 131/250, Loss: 0.0136\n",
      "Epoch 97/200, Iteration 132/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 133/250, Loss: 0.0582\n",
      "Epoch 97/200, Iteration 134/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 135/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 136/250, Loss: 0.0272\n",
      "Epoch 97/200, Iteration 137/250, Loss: 0.0218\n",
      "Epoch 97/200, Iteration 138/250, Loss: 0.0354\n",
      "Epoch 97/200, Iteration 139/250, Loss: 0.0195\n",
      "Epoch 97/200, Iteration 140/250, Loss: 0.0309\n",
      "Epoch 97/200, Iteration 141/250, Loss: 0.0068\n",
      "Epoch 97/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 97/200, Iteration 143/250, Loss: 0.0245\n",
      "Epoch 97/200, Iteration 144/250, Loss: 0.0080\n",
      "Epoch 97/200, Iteration 145/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 146/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 147/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 148/250, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 149/250, Loss: 0.0181\n",
      "Epoch 97/200, Iteration 150/250, Loss: 0.0064\n",
      "Epoch 97/200, Iteration 151/250, Loss: 0.0178\n",
      "Epoch 97/200, Iteration 152/250, Loss: 0.0415\n",
      "Epoch 97/200, Iteration 153/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 154/250, Loss: 0.0108\n",
      "Epoch 97/200, Iteration 155/250, Loss: 0.0068\n",
      "Epoch 97/200, Iteration 156/250, Loss: 0.0144\n",
      "Epoch 97/200, Iteration 157/250, Loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200, Iteration 158/250, Loss: 0.0074\n",
      "Epoch 97/200, Iteration 159/250, Loss: 0.0179\n",
      "Epoch 97/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 161/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 162/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 163/250, Loss: 0.0133\n",
      "Epoch 97/200, Iteration 164/250, Loss: 0.0077\n",
      "Epoch 97/200, Iteration 165/250, Loss: 0.0102\n",
      "Epoch 97/200, Iteration 166/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 167/250, Loss: 0.0141\n",
      "Epoch 97/200, Iteration 168/250, Loss: 0.0185\n",
      "Epoch 97/200, Iteration 169/250, Loss: 0.0207\n",
      "Epoch 97/200, Iteration 170/250, Loss: 0.0152\n",
      "Epoch 97/200, Iteration 171/250, Loss: 0.0417\n",
      "Epoch 97/200, Iteration 172/250, Loss: 0.0145\n",
      "Epoch 97/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 97/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 175/250, Loss: 0.0162\n",
      "Epoch 97/200, Iteration 176/250, Loss: 0.0084\n",
      "Epoch 97/200, Iteration 177/250, Loss: 0.0132\n",
      "Epoch 97/200, Iteration 178/250, Loss: 0.0073\n",
      "Epoch 97/200, Iteration 179/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 180/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 181/250, Loss: 0.0355\n",
      "Epoch 97/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 97/200, Iteration 183/250, Loss: 0.0199\n",
      "Epoch 97/200, Iteration 184/250, Loss: 0.0258\n",
      "Epoch 97/200, Iteration 185/250, Loss: 0.0078\n",
      "Epoch 97/200, Iteration 186/250, Loss: 0.0126\n",
      "Epoch 97/200, Iteration 187/250, Loss: 0.0196\n",
      "Epoch 97/200, Iteration 188/250, Loss: 0.0107\n",
      "Epoch 97/200, Iteration 189/250, Loss: 0.0245\n",
      "Epoch 97/200, Iteration 190/250, Loss: 0.0158\n",
      "Epoch 97/200, Iteration 191/250, Loss: 0.0102\n",
      "Epoch 97/200, Iteration 192/250, Loss: 0.0082\n",
      "Epoch 97/200, Iteration 193/250, Loss: 0.0228\n",
      "Epoch 97/200, Iteration 194/250, Loss: 0.0124\n",
      "Epoch 97/200, Iteration 195/250, Loss: 0.0102\n",
      "Epoch 97/200, Iteration 196/250, Loss: 0.0076\n",
      "Epoch 97/200, Iteration 197/250, Loss: 0.0340\n",
      "Epoch 97/200, Iteration 198/250, Loss: 0.0163\n",
      "Epoch 97/200, Iteration 199/250, Loss: 0.0166\n",
      "Epoch 97/200, Iteration 200/250, Loss: 0.0123\n",
      "Epoch 97/200, Iteration 201/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 202/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 203/250, Loss: 0.0262\n",
      "Epoch 97/200, Iteration 204/250, Loss: 0.0120\n",
      "Epoch 97/200, Iteration 205/250, Loss: 0.0394\n",
      "Epoch 97/200, Iteration 206/250, Loss: 0.0321\n",
      "Epoch 97/200, Iteration 207/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 208/250, Loss: 0.0190\n",
      "Epoch 97/200, Iteration 209/250, Loss: 0.0258\n",
      "Epoch 97/200, Iteration 210/250, Loss: 0.0299\n",
      "Epoch 97/200, Iteration 211/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 212/250, Loss: 0.0194\n",
      "Epoch 97/200, Iteration 213/250, Loss: 0.0208\n",
      "Epoch 97/200, Iteration 214/250, Loss: 0.0175\n",
      "Epoch 97/200, Iteration 215/250, Loss: 0.0104\n",
      "Epoch 97/200, Iteration 216/250, Loss: 0.0161\n",
      "Epoch 97/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 218/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 219/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 220/250, Loss: 0.0077\n",
      "Epoch 97/200, Iteration 221/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 222/250, Loss: 0.0160\n",
      "Epoch 97/200, Iteration 223/250, Loss: 0.0107\n",
      "Epoch 97/200, Iteration 224/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 225/250, Loss: 0.0272\n",
      "Epoch 97/200, Iteration 226/250, Loss: 0.0294\n",
      "Epoch 97/200, Iteration 227/250, Loss: 0.0082\n",
      "Epoch 97/200, Iteration 228/250, Loss: 0.0169\n",
      "Epoch 97/200, Iteration 229/250, Loss: 0.0108\n",
      "Epoch 97/200, Iteration 230/250, Loss: 0.0232\n",
      "Epoch 97/200, Iteration 231/250, Loss: 0.0098\n",
      "Epoch 97/200, Iteration 232/250, Loss: 0.0112\n",
      "Epoch 97/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 97/200, Iteration 234/250, Loss: 0.0084\n",
      "Epoch 97/200, Iteration 235/250, Loss: 0.0113\n",
      "Epoch 97/200, Iteration 236/250, Loss: 0.0189\n",
      "Epoch 97/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 97/200, Iteration 238/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 97/200, Iteration 240/250, Loss: 0.0087\n",
      "Epoch 97/200, Iteration 241/250, Loss: 0.0366\n",
      "Epoch 97/200, Iteration 242/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 243/250, Loss: 0.0276\n",
      "Epoch 97/200, Iteration 244/250, Loss: 0.0244\n",
      "Epoch 97/200, Iteration 245/250, Loss: 0.0198\n",
      "Epoch 97/200, Iteration 246/250, Loss: 0.0187\n",
      "Epoch 97/200, Iteration 247/250, Loss: 0.0070\n",
      "Epoch 97/200, Iteration 248/250, Loss: 0.0175\n",
      "Epoch 97/200, Iteration 249/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 250/250, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 96.97%, Avg loss: 0.007656, MRE: 0.698499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.95%, Avg loss: 0.007542, MRE: 1.364799 \n",
      "\n",
      "Epoch 98/200, Iteration 1/250, Loss: 0.0172\n",
      "Epoch 98/200, Iteration 2/250, Loss: 0.0384\n",
      "Epoch 98/200, Iteration 3/250, Loss: 0.0137\n",
      "Epoch 98/200, Iteration 4/250, Loss: 0.0216\n",
      "Epoch 98/200, Iteration 5/250, Loss: 0.0128\n",
      "Epoch 98/200, Iteration 6/250, Loss: 0.0113\n",
      "Epoch 98/200, Iteration 7/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 8/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 9/250, Loss: 0.0240\n",
      "Epoch 98/200, Iteration 10/250, Loss: 0.0154\n",
      "Epoch 98/200, Iteration 11/250, Loss: 0.0268\n",
      "Epoch 98/200, Iteration 12/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 13/250, Loss: 0.0202\n",
      "Epoch 98/200, Iteration 14/250, Loss: 0.0165\n",
      "Epoch 98/200, Iteration 15/250, Loss: 0.0150\n",
      "Epoch 98/200, Iteration 16/250, Loss: 0.0086\n",
      "Epoch 98/200, Iteration 17/250, Loss: 0.0179\n",
      "Epoch 98/200, Iteration 18/250, Loss: 0.0075\n",
      "Epoch 98/200, Iteration 19/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 20/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 21/250, Loss: 0.0127\n",
      "Epoch 98/200, Iteration 22/250, Loss: 0.0092\n",
      "Epoch 98/200, Iteration 23/250, Loss: 0.0097\n",
      "Epoch 98/200, Iteration 24/250, Loss: 0.0146\n",
      "Epoch 98/200, Iteration 25/250, Loss: 0.0303\n",
      "Epoch 98/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 98/200, Iteration 27/250, Loss: 0.0139\n",
      "Epoch 98/200, Iteration 28/250, Loss: 0.0224\n",
      "Epoch 98/200, Iteration 29/250, Loss: 0.0141\n",
      "Epoch 98/200, Iteration 30/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 31/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 32/250, Loss: 0.0164\n",
      "Epoch 98/200, Iteration 33/250, Loss: 0.0122\n",
      "Epoch 98/200, Iteration 34/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 35/250, Loss: 0.0307\n",
      "Epoch 98/200, Iteration 36/250, Loss: 0.0262\n",
      "Epoch 98/200, Iteration 37/250, Loss: 0.0068\n",
      "Epoch 98/200, Iteration 38/250, Loss: 0.0127\n",
      "Epoch 98/200, Iteration 39/250, Loss: 0.0159\n",
      "Epoch 98/200, Iteration 40/250, Loss: 0.0224\n",
      "Epoch 98/200, Iteration 41/250, Loss: 0.0170\n",
      "Epoch 98/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 98/200, Iteration 43/250, Loss: 0.0245\n",
      "Epoch 98/200, Iteration 44/250, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 45/250, Loss: 0.0127\n",
      "Epoch 98/200, Iteration 46/250, Loss: 0.0070\n",
      "Epoch 98/200, Iteration 47/250, Loss: 0.0085\n",
      "Epoch 98/200, Iteration 48/250, Loss: 0.0257\n",
      "Epoch 98/200, Iteration 49/250, Loss: 0.0173\n",
      "Epoch 98/200, Iteration 50/250, Loss: 0.0119\n",
      "Epoch 98/200, Iteration 51/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 52/250, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 53/250, Loss: 0.0311\n",
      "Epoch 98/200, Iteration 54/250, Loss: 0.0336\n",
      "Epoch 98/200, Iteration 55/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 56/250, Loss: 0.0184\n",
      "Epoch 98/200, Iteration 57/250, Loss: 0.0221\n",
      "Epoch 98/200, Iteration 58/250, Loss: 0.0221\n",
      "Epoch 98/200, Iteration 59/250, Loss: 0.0234\n",
      "Epoch 98/200, Iteration 60/250, Loss: 0.0146\n",
      "Epoch 98/200, Iteration 61/250, Loss: 0.0206\n",
      "Epoch 98/200, Iteration 62/250, Loss: 0.0166\n",
      "Epoch 98/200, Iteration 63/250, Loss: 0.0154\n",
      "Epoch 98/200, Iteration 64/250, Loss: 0.0200\n",
      "Epoch 98/200, Iteration 65/250, Loss: 0.0144\n",
      "Epoch 98/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 98/200, Iteration 67/250, Loss: 0.0190\n",
      "Epoch 98/200, Iteration 68/250, Loss: 0.0073\n",
      "Epoch 98/200, Iteration 69/250, Loss: 0.0161\n",
      "Epoch 98/200, Iteration 70/250, Loss: 0.0102\n",
      "Epoch 98/200, Iteration 71/250, Loss: 0.0152\n",
      "Epoch 98/200, Iteration 72/250, Loss: 0.0247\n",
      "Epoch 98/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 98/200, Iteration 74/250, Loss: 0.0119\n",
      "Epoch 98/200, Iteration 75/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 76/250, Loss: 0.0164\n",
      "Epoch 98/200, Iteration 77/250, Loss: 0.0089\n",
      "Epoch 98/200, Iteration 78/250, Loss: 0.0256\n",
      "Epoch 98/200, Iteration 79/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 81/250, Loss: 0.0173\n",
      "Epoch 98/200, Iteration 82/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 83/250, Loss: 0.0070\n",
      "Epoch 98/200, Iteration 84/250, Loss: 0.0221\n",
      "Epoch 98/200, Iteration 85/250, Loss: 0.0264\n",
      "Epoch 98/200, Iteration 86/250, Loss: 0.0084\n",
      "Epoch 98/200, Iteration 87/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 88/250, Loss: 0.0402\n",
      "Epoch 98/200, Iteration 89/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 90/250, Loss: 0.0367\n",
      "Epoch 98/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 92/250, Loss: 0.0122\n",
      "Epoch 98/200, Iteration 93/250, Loss: 0.0071\n",
      "Epoch 98/200, Iteration 94/250, Loss: 0.0237\n",
      "Epoch 98/200, Iteration 95/250, Loss: 0.0128\n",
      "Epoch 98/200, Iteration 96/250, Loss: 0.0097\n",
      "Epoch 98/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 98/200, Iteration 98/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 99/250, Loss: 0.0192\n",
      "Epoch 98/200, Iteration 100/250, Loss: 0.0053\n",
      "Epoch 98/200, Iteration 101/250, Loss: 0.0152\n",
      "Epoch 98/200, Iteration 102/250, Loss: 0.0140\n",
      "Epoch 98/200, Iteration 103/250, Loss: 0.0062\n",
      "Epoch 98/200, Iteration 104/250, Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200, Iteration 105/250, Loss: 0.0225\n",
      "Epoch 98/200, Iteration 106/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 107/250, Loss: 0.0091\n",
      "Epoch 98/200, Iteration 108/250, Loss: 0.0124\n",
      "Epoch 98/200, Iteration 109/250, Loss: 0.0083\n",
      "Epoch 98/200, Iteration 110/250, Loss: 0.0069\n",
      "Epoch 98/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 98/200, Iteration 112/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 113/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 114/250, Loss: 0.0359\n",
      "Epoch 98/200, Iteration 115/250, Loss: 0.0183\n",
      "Epoch 98/200, Iteration 116/250, Loss: 0.0088\n",
      "Epoch 98/200, Iteration 117/250, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 118/250, Loss: 0.0083\n",
      "Epoch 98/200, Iteration 119/250, Loss: 0.0204\n",
      "Epoch 98/200, Iteration 120/250, Loss: 0.0226\n",
      "Epoch 98/200, Iteration 121/250, Loss: 0.0198\n",
      "Epoch 98/200, Iteration 122/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 123/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 124/250, Loss: 0.0182\n",
      "Epoch 98/200, Iteration 125/250, Loss: 0.0189\n",
      "Epoch 98/200, Iteration 126/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 127/250, Loss: 0.0118\n",
      "Epoch 98/200, Iteration 128/250, Loss: 0.0083\n",
      "Epoch 98/200, Iteration 129/250, Loss: 0.0114\n",
      "Epoch 98/200, Iteration 130/250, Loss: 0.0149\n",
      "Epoch 98/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 98/200, Iteration 132/250, Loss: 0.0133\n",
      "Epoch 98/200, Iteration 133/250, Loss: 0.0137\n",
      "Epoch 98/200, Iteration 134/250, Loss: 0.0172\n",
      "Epoch 98/200, Iteration 135/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 136/250, Loss: 0.0114\n",
      "Epoch 98/200, Iteration 137/250, Loss: 0.0114\n",
      "Epoch 98/200, Iteration 138/250, Loss: 0.0069\n",
      "Epoch 98/200, Iteration 139/250, Loss: 0.0199\n",
      "Epoch 98/200, Iteration 140/250, Loss: 0.0152\n",
      "Epoch 98/200, Iteration 141/250, Loss: 0.0073\n",
      "Epoch 98/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 143/250, Loss: 0.0328\n",
      "Epoch 98/200, Iteration 144/250, Loss: 0.0088\n",
      "Epoch 98/200, Iteration 145/250, Loss: 0.0195\n",
      "Epoch 98/200, Iteration 146/250, Loss: 0.0090\n",
      "Epoch 98/200, Iteration 147/250, Loss: 0.0064\n",
      "Epoch 98/200, Iteration 148/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 149/250, Loss: 0.0118\n",
      "Epoch 98/200, Iteration 150/250, Loss: 0.0114\n",
      "Epoch 98/200, Iteration 151/250, Loss: 0.0071\n",
      "Epoch 98/200, Iteration 152/250, Loss: 0.0200\n",
      "Epoch 98/200, Iteration 153/250, Loss: 0.0141\n",
      "Epoch 98/200, Iteration 154/250, Loss: 0.0151\n",
      "Epoch 98/200, Iteration 155/250, Loss: 0.0128\n",
      "Epoch 98/200, Iteration 156/250, Loss: 0.0131\n",
      "Epoch 98/200, Iteration 157/250, Loss: 0.0178\n",
      "Epoch 98/200, Iteration 158/250, Loss: 0.0154\n",
      "Epoch 98/200, Iteration 159/250, Loss: 0.0193\n",
      "Epoch 98/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 98/200, Iteration 161/250, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 162/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 163/250, Loss: 0.0399\n",
      "Epoch 98/200, Iteration 164/250, Loss: 0.0144\n",
      "Epoch 98/200, Iteration 165/250, Loss: 0.0232\n",
      "Epoch 98/200, Iteration 166/250, Loss: 0.0153\n",
      "Epoch 98/200, Iteration 167/250, Loss: 0.0099\n",
      "Epoch 98/200, Iteration 168/250, Loss: 0.0101\n",
      "Epoch 98/200, Iteration 169/250, Loss: 0.0114\n",
      "Epoch 98/200, Iteration 170/250, Loss: 0.0167\n",
      "Epoch 98/200, Iteration 171/250, Loss: 0.0216\n",
      "Epoch 98/200, Iteration 172/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 173/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 174/250, Loss: 0.0066\n",
      "Epoch 98/200, Iteration 175/250, Loss: 0.0180\n",
      "Epoch 98/200, Iteration 176/250, Loss: 0.0158\n",
      "Epoch 98/200, Iteration 177/250, Loss: 0.0117\n",
      "Epoch 98/200, Iteration 178/250, Loss: 0.0073\n",
      "Epoch 98/200, Iteration 179/250, Loss: 0.0068\n",
      "Epoch 98/200, Iteration 180/250, Loss: 0.0238\n",
      "Epoch 98/200, Iteration 181/250, Loss: 0.0113\n",
      "Epoch 98/200, Iteration 182/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 184/250, Loss: 0.0252\n",
      "Epoch 98/200, Iteration 185/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 186/250, Loss: 0.0067\n",
      "Epoch 98/200, Iteration 187/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 188/250, Loss: 0.0172\n",
      "Epoch 98/200, Iteration 189/250, Loss: 0.0140\n",
      "Epoch 98/200, Iteration 190/250, Loss: 0.0104\n",
      "Epoch 98/200, Iteration 191/250, Loss: 0.0189\n",
      "Epoch 98/200, Iteration 192/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 193/250, Loss: 0.0088\n",
      "Epoch 98/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 98/200, Iteration 195/250, Loss: 0.0348\n",
      "Epoch 98/200, Iteration 196/250, Loss: 0.0113\n",
      "Epoch 98/200, Iteration 197/250, Loss: 0.0065\n",
      "Epoch 98/200, Iteration 198/250, Loss: 0.0086\n",
      "Epoch 98/200, Iteration 199/250, Loss: 0.0225\n",
      "Epoch 98/200, Iteration 200/250, Loss: 0.0084\n",
      "Epoch 98/200, Iteration 201/250, Loss: 0.0077\n",
      "Epoch 98/200, Iteration 202/250, Loss: 0.0185\n",
      "Epoch 98/200, Iteration 203/250, Loss: 0.0072\n",
      "Epoch 98/200, Iteration 204/250, Loss: 0.0168\n",
      "Epoch 98/200, Iteration 205/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 206/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 207/250, Loss: 0.0151\n",
      "Epoch 98/200, Iteration 208/250, Loss: 0.0075\n",
      "Epoch 98/200, Iteration 209/250, Loss: 0.0090\n",
      "Epoch 98/200, Iteration 210/250, Loss: 0.0293\n",
      "Epoch 98/200, Iteration 211/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 212/250, Loss: 0.0347\n",
      "Epoch 98/200, Iteration 213/250, Loss: 0.0177\n",
      "Epoch 98/200, Iteration 214/250, Loss: 0.0111\n",
      "Epoch 98/200, Iteration 215/250, Loss: 0.0335\n",
      "Epoch 98/200, Iteration 216/250, Loss: 0.0072\n",
      "Epoch 98/200, Iteration 217/250, Loss: 0.0121\n",
      "Epoch 98/200, Iteration 218/250, Loss: 0.0134\n",
      "Epoch 98/200, Iteration 219/250, Loss: 0.0135\n",
      "Epoch 98/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 221/250, Loss: 0.0105\n",
      "Epoch 98/200, Iteration 222/250, Loss: 0.0194\n",
      "Epoch 98/200, Iteration 223/250, Loss: 0.0155\n",
      "Epoch 98/200, Iteration 224/250, Loss: 0.0543\n",
      "Epoch 98/200, Iteration 225/250, Loss: 0.0122\n",
      "Epoch 98/200, Iteration 226/250, Loss: 0.0148\n",
      "Epoch 98/200, Iteration 227/250, Loss: 0.0067\n",
      "Epoch 98/200, Iteration 228/250, Loss: 0.0182\n",
      "Epoch 98/200, Iteration 229/250, Loss: 0.0187\n",
      "Epoch 98/200, Iteration 230/250, Loss: 0.0143\n",
      "Epoch 98/200, Iteration 231/250, Loss: 0.0079\n",
      "Epoch 98/200, Iteration 232/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 233/250, Loss: 0.0159\n",
      "Epoch 98/200, Iteration 234/250, Loss: 0.0253\n",
      "Epoch 98/200, Iteration 235/250, Loss: 0.0171\n",
      "Epoch 98/200, Iteration 236/250, Loss: 0.0125\n",
      "Epoch 98/200, Iteration 237/250, Loss: 0.0124\n",
      "Epoch 98/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 239/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 240/250, Loss: 0.0284\n",
      "Epoch 98/200, Iteration 241/250, Loss: 0.0184\n",
      "Epoch 98/200, Iteration 242/250, Loss: 0.0170\n",
      "Epoch 98/200, Iteration 243/250, Loss: 0.0099\n",
      "Epoch 98/200, Iteration 244/250, Loss: 0.0098\n",
      "Epoch 98/200, Iteration 245/250, Loss: 0.0168\n",
      "Epoch 98/200, Iteration 246/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 247/250, Loss: 0.0098\n",
      "Epoch 98/200, Iteration 248/250, Loss: 0.0079\n",
      "Epoch 98/200, Iteration 249/250, Loss: 0.0155\n",
      "Epoch 98/200, Iteration 250/250, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 94.64%, Avg loss: 0.005876, MRE: 0.619621 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.15%, Avg loss: 0.005854, MRE: 0.991500 \n",
      "\n",
      "Epoch 99/200, Iteration 1/250, Loss: 0.0127\n",
      "Epoch 99/200, Iteration 2/250, Loss: 0.0192\n",
      "Epoch 99/200, Iteration 3/250, Loss: 0.0271\n",
      "Epoch 99/200, Iteration 4/250, Loss: 0.0198\n",
      "Epoch 99/200, Iteration 5/250, Loss: 0.0116\n",
      "Epoch 99/200, Iteration 6/250, Loss: 0.0114\n",
      "Epoch 99/200, Iteration 7/250, Loss: 0.0263\n",
      "Epoch 99/200, Iteration 8/250, Loss: 0.0140\n",
      "Epoch 99/200, Iteration 9/250, Loss: 0.0132\n",
      "Epoch 99/200, Iteration 10/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 12/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 13/250, Loss: 0.0259\n",
      "Epoch 99/200, Iteration 14/250, Loss: 0.0219\n",
      "Epoch 99/200, Iteration 15/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 16/250, Loss: 0.0247\n",
      "Epoch 99/200, Iteration 17/250, Loss: 0.0130\n",
      "Epoch 99/200, Iteration 18/250, Loss: 0.0304\n",
      "Epoch 99/200, Iteration 19/250, Loss: 0.0178\n",
      "Epoch 99/200, Iteration 20/250, Loss: 0.0324\n",
      "Epoch 99/200, Iteration 21/250, Loss: 0.0162\n",
      "Epoch 99/200, Iteration 22/250, Loss: 0.0157\n",
      "Epoch 99/200, Iteration 23/250, Loss: 0.0229\n",
      "Epoch 99/200, Iteration 24/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 25/250, Loss: 0.0160\n",
      "Epoch 99/200, Iteration 26/250, Loss: 0.0132\n",
      "Epoch 99/200, Iteration 27/250, Loss: 0.0325\n",
      "Epoch 99/200, Iteration 28/250, Loss: 0.0081\n",
      "Epoch 99/200, Iteration 29/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 30/250, Loss: 0.0260\n",
      "Epoch 99/200, Iteration 31/250, Loss: 0.0131\n",
      "Epoch 99/200, Iteration 32/250, Loss: 0.0231\n",
      "Epoch 99/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 99/200, Iteration 34/250, Loss: 0.0090\n",
      "Epoch 99/200, Iteration 35/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 36/250, Loss: 0.0282\n",
      "Epoch 99/200, Iteration 37/250, Loss: 0.0097\n",
      "Epoch 99/200, Iteration 38/250, Loss: 0.0205\n",
      "Epoch 99/200, Iteration 39/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 40/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 41/250, Loss: 0.0153\n",
      "Epoch 99/200, Iteration 42/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 43/250, Loss: 0.0211\n",
      "Epoch 99/200, Iteration 44/250, Loss: 0.0241\n",
      "Epoch 99/200, Iteration 45/250, Loss: 0.0184\n",
      "Epoch 99/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 47/250, Loss: 0.0207\n",
      "Epoch 99/200, Iteration 48/250, Loss: 0.0186\n",
      "Epoch 99/200, Iteration 49/250, Loss: 0.0282\n",
      "Epoch 99/200, Iteration 50/250, Loss: 0.0221\n",
      "Epoch 99/200, Iteration 51/250, Loss: 0.0284\n",
      "Epoch 99/200, Iteration 52/250, Loss: 0.0145\n",
      "Epoch 99/200, Iteration 53/250, Loss: 0.0208\n",
      "Epoch 99/200, Iteration 54/250, Loss: 0.0277\n",
      "Epoch 99/200, Iteration 55/250, Loss: 0.0071\n",
      "Epoch 99/200, Iteration 56/250, Loss: 0.0199\n",
      "Epoch 99/200, Iteration 57/250, Loss: 0.0063\n",
      "Epoch 99/200, Iteration 58/250, Loss: 0.0141\n",
      "Epoch 99/200, Iteration 59/250, Loss: 0.0070\n",
      "Epoch 99/200, Iteration 60/250, Loss: 0.0147\n",
      "Epoch 99/200, Iteration 61/250, Loss: 0.0213\n",
      "Epoch 99/200, Iteration 62/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 63/250, Loss: 0.0081\n",
      "Epoch 99/200, Iteration 64/250, Loss: 0.0160\n",
      "Epoch 99/200, Iteration 65/250, Loss: 0.0076\n",
      "Epoch 99/200, Iteration 66/250, Loss: 0.0181\n",
      "Epoch 99/200, Iteration 67/250, Loss: 0.0311\n",
      "Epoch 99/200, Iteration 68/250, Loss: 0.0210\n",
      "Epoch 99/200, Iteration 69/250, Loss: 0.0058\n",
      "Epoch 99/200, Iteration 70/250, Loss: 0.0055\n",
      "Epoch 99/200, Iteration 71/250, Loss: 0.0190\n",
      "Epoch 99/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 73/250, Loss: 0.0320\n",
      "Epoch 99/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 99/200, Iteration 75/250, Loss: 0.0361\n",
      "Epoch 99/200, Iteration 76/250, Loss: 0.0075\n",
      "Epoch 99/200, Iteration 77/250, Loss: 0.0129\n",
      "Epoch 99/200, Iteration 78/250, Loss: 0.0216\n",
      "Epoch 99/200, Iteration 79/250, Loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200, Iteration 80/250, Loss: 0.0166\n",
      "Epoch 99/200, Iteration 81/250, Loss: 0.0108\n",
      "Epoch 99/200, Iteration 82/250, Loss: 0.0254\n",
      "Epoch 99/200, Iteration 83/250, Loss: 0.0284\n",
      "Epoch 99/200, Iteration 84/250, Loss: 0.0138\n",
      "Epoch 99/200, Iteration 85/250, Loss: 0.0595\n",
      "Epoch 99/200, Iteration 86/250, Loss: 0.0272\n",
      "Epoch 99/200, Iteration 87/250, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 88/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 89/250, Loss: 0.0130\n",
      "Epoch 99/200, Iteration 90/250, Loss: 0.0071\n",
      "Epoch 99/200, Iteration 91/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 92/250, Loss: 0.0169\n",
      "Epoch 99/200, Iteration 93/250, Loss: 0.0176\n",
      "Epoch 99/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 99/200, Iteration 95/250, Loss: 0.0122\n",
      "Epoch 99/200, Iteration 96/250, Loss: 0.0090\n",
      "Epoch 99/200, Iteration 97/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 98/250, Loss: 0.0124\n",
      "Epoch 99/200, Iteration 99/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 100/250, Loss: 0.0261\n",
      "Epoch 99/200, Iteration 101/250, Loss: 0.0150\n",
      "Epoch 99/200, Iteration 102/250, Loss: 0.0158\n",
      "Epoch 99/200, Iteration 103/250, Loss: 0.0076\n",
      "Epoch 99/200, Iteration 104/250, Loss: 0.0166\n",
      "Epoch 99/200, Iteration 105/250, Loss: 0.0119\n",
      "Epoch 99/200, Iteration 106/250, Loss: 0.0127\n",
      "Epoch 99/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 108/250, Loss: 0.0063\n",
      "Epoch 99/200, Iteration 109/250, Loss: 0.0073\n",
      "Epoch 99/200, Iteration 110/250, Loss: 0.0348\n",
      "Epoch 99/200, Iteration 111/250, Loss: 0.0215\n",
      "Epoch 99/200, Iteration 112/250, Loss: 0.0185\n",
      "Epoch 99/200, Iteration 113/250, Loss: 0.0083\n",
      "Epoch 99/200, Iteration 114/250, Loss: 0.0274\n",
      "Epoch 99/200, Iteration 115/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 116/250, Loss: 0.0145\n",
      "Epoch 99/200, Iteration 117/250, Loss: 0.0069\n",
      "Epoch 99/200, Iteration 118/250, Loss: 0.0168\n",
      "Epoch 99/200, Iteration 119/250, Loss: 0.0077\n",
      "Epoch 99/200, Iteration 120/250, Loss: 0.0136\n",
      "Epoch 99/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 122/250, Loss: 0.0069\n",
      "Epoch 99/200, Iteration 123/250, Loss: 0.0059\n",
      "Epoch 99/200, Iteration 124/250, Loss: 0.0089\n",
      "Epoch 99/200, Iteration 125/250, Loss: 0.0142\n",
      "Epoch 99/200, Iteration 126/250, Loss: 0.0136\n",
      "Epoch 99/200, Iteration 127/250, Loss: 0.0090\n",
      "Epoch 99/200, Iteration 128/250, Loss: 0.0074\n",
      "Epoch 99/200, Iteration 129/250, Loss: 0.0169\n",
      "Epoch 99/200, Iteration 130/250, Loss: 0.0112\n",
      "Epoch 99/200, Iteration 131/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 132/250, Loss: 0.0117\n",
      "Epoch 99/200, Iteration 133/250, Loss: 0.0207\n",
      "Epoch 99/200, Iteration 134/250, Loss: 0.0154\n",
      "Epoch 99/200, Iteration 135/250, Loss: 0.0064\n",
      "Epoch 99/200, Iteration 136/250, Loss: 0.0084\n",
      "Epoch 99/200, Iteration 137/250, Loss: 0.0112\n",
      "Epoch 99/200, Iteration 138/250, Loss: 0.0076\n",
      "Epoch 99/200, Iteration 139/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 140/250, Loss: 0.0234\n",
      "Epoch 99/200, Iteration 141/250, Loss: 0.0177\n",
      "Epoch 99/200, Iteration 142/250, Loss: 0.0127\n",
      "Epoch 99/200, Iteration 143/250, Loss: 0.0097\n",
      "Epoch 99/200, Iteration 144/250, Loss: 0.0080\n",
      "Epoch 99/200, Iteration 145/250, Loss: 0.0445\n",
      "Epoch 99/200, Iteration 146/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 147/250, Loss: 0.0077\n",
      "Epoch 99/200, Iteration 148/250, Loss: 0.0148\n",
      "Epoch 99/200, Iteration 149/250, Loss: 0.0356\n",
      "Epoch 99/200, Iteration 150/250, Loss: 0.0101\n",
      "Epoch 99/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 99/200, Iteration 152/250, Loss: 0.0149\n",
      "Epoch 99/200, Iteration 153/250, Loss: 0.0253\n",
      "Epoch 99/200, Iteration 154/250, Loss: 0.0119\n",
      "Epoch 99/200, Iteration 155/250, Loss: 0.0092\n",
      "Epoch 99/200, Iteration 156/250, Loss: 0.0069\n",
      "Epoch 99/200, Iteration 157/250, Loss: 0.0130\n",
      "Epoch 99/200, Iteration 158/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 99/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 161/250, Loss: 0.0169\n",
      "Epoch 99/200, Iteration 162/250, Loss: 0.0122\n",
      "Epoch 99/200, Iteration 163/250, Loss: 0.0171\n",
      "Epoch 99/200, Iteration 164/250, Loss: 0.0143\n",
      "Epoch 99/200, Iteration 165/250, Loss: 0.0189\n",
      "Epoch 99/200, Iteration 166/250, Loss: 0.0154\n",
      "Epoch 99/200, Iteration 167/250, Loss: 0.0174\n",
      "Epoch 99/200, Iteration 168/250, Loss: 0.0194\n",
      "Epoch 99/200, Iteration 169/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 170/250, Loss: 0.0069\n",
      "Epoch 99/200, Iteration 171/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 172/250, Loss: 0.0341\n",
      "Epoch 99/200, Iteration 173/250, Loss: 0.0056\n",
      "Epoch 99/200, Iteration 174/250, Loss: 0.0283\n",
      "Epoch 99/200, Iteration 175/250, Loss: 0.0257\n",
      "Epoch 99/200, Iteration 176/250, Loss: 0.0177\n",
      "Epoch 99/200, Iteration 177/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 178/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 179/250, Loss: 0.0078\n",
      "Epoch 99/200, Iteration 180/250, Loss: 0.0073\n",
      "Epoch 99/200, Iteration 181/250, Loss: 0.0074\n",
      "Epoch 99/200, Iteration 182/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 183/250, Loss: 0.0189\n",
      "Epoch 99/200, Iteration 184/250, Loss: 0.0195\n",
      "Epoch 99/200, Iteration 185/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 186/250, Loss: 0.0158\n",
      "Epoch 99/200, Iteration 187/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 188/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 189/250, Loss: 0.0120\n",
      "Epoch 99/200, Iteration 190/250, Loss: 0.0083\n",
      "Epoch 99/200, Iteration 191/250, Loss: 0.0242\n",
      "Epoch 99/200, Iteration 192/250, Loss: 0.0137\n",
      "Epoch 99/200, Iteration 193/250, Loss: 0.0124\n",
      "Epoch 99/200, Iteration 194/250, Loss: 0.0092\n",
      "Epoch 99/200, Iteration 195/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 196/250, Loss: 0.0131\n",
      "Epoch 99/200, Iteration 197/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 198/250, Loss: 0.0089\n",
      "Epoch 99/200, Iteration 199/250, Loss: 0.0272\n",
      "Epoch 99/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 99/200, Iteration 201/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 202/250, Loss: 0.0221\n",
      "Epoch 99/200, Iteration 203/250, Loss: 0.0073\n",
      "Epoch 99/200, Iteration 204/250, Loss: 0.0140\n",
      "Epoch 99/200, Iteration 205/250, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 206/250, Loss: 0.0129\n",
      "Epoch 99/200, Iteration 207/250, Loss: 0.0124\n",
      "Epoch 99/200, Iteration 208/250, Loss: 0.0114\n",
      "Epoch 99/200, Iteration 209/250, Loss: 0.0155\n",
      "Epoch 99/200, Iteration 210/250, Loss: 0.0116\n",
      "Epoch 99/200, Iteration 211/250, Loss: 0.0202\n",
      "Epoch 99/200, Iteration 212/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 213/250, Loss: 0.0122\n",
      "Epoch 99/200, Iteration 214/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 215/250, Loss: 0.0240\n",
      "Epoch 99/200, Iteration 216/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 217/250, Loss: 0.0204\n",
      "Epoch 99/200, Iteration 218/250, Loss: 0.0137\n",
      "Epoch 99/200, Iteration 219/250, Loss: 0.0100\n",
      "Epoch 99/200, Iteration 220/250, Loss: 0.0073\n",
      "Epoch 99/200, Iteration 221/250, Loss: 0.0060\n",
      "Epoch 99/200, Iteration 222/250, Loss: 0.0258\n",
      "Epoch 99/200, Iteration 223/250, Loss: 0.0070\n",
      "Epoch 99/200, Iteration 224/250, Loss: 0.0145\n",
      "Epoch 99/200, Iteration 225/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 226/250, Loss: 0.0249\n",
      "Epoch 99/200, Iteration 227/250, Loss: 0.0157\n",
      "Epoch 99/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 99/200, Iteration 229/250, Loss: 0.0209\n",
      "Epoch 99/200, Iteration 230/250, Loss: 0.0110\n",
      "Epoch 99/200, Iteration 231/250, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 232/250, Loss: 0.0220\n",
      "Epoch 99/200, Iteration 233/250, Loss: 0.0097\n",
      "Epoch 99/200, Iteration 234/250, Loss: 0.0184\n",
      "Epoch 99/200, Iteration 235/250, Loss: 0.0141\n",
      "Epoch 99/200, Iteration 236/250, Loss: 0.0277\n",
      "Epoch 99/200, Iteration 237/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 238/250, Loss: 0.0115\n",
      "Epoch 99/200, Iteration 239/250, Loss: 0.0330\n",
      "Epoch 99/200, Iteration 240/250, Loss: 0.0115\n",
      "Epoch 99/200, Iteration 241/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 242/250, Loss: 0.0178\n",
      "Epoch 99/200, Iteration 243/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 244/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 245/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 246/250, Loss: 0.0339\n",
      "Epoch 99/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 99/200, Iteration 248/250, Loss: 0.0166\n",
      "Epoch 99/200, Iteration 249/250, Loss: 0.0172\n",
      "Epoch 99/200, Iteration 250/250, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 93.39%, Avg loss: 0.006097, MRE: 0.631433 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.006096, MRE: 0.988178 \n",
      "\n",
      "Epoch 100/200, Iteration 1/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 2/250, Loss: 0.0244\n",
      "Epoch 100/200, Iteration 3/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 4/250, Loss: 0.0174\n",
      "Epoch 100/200, Iteration 5/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 6/250, Loss: 0.0399\n",
      "Epoch 100/200, Iteration 7/250, Loss: 0.0113\n",
      "Epoch 100/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 100/200, Iteration 9/250, Loss: 0.0149\n",
      "Epoch 100/200, Iteration 10/250, Loss: 0.0134\n",
      "Epoch 100/200, Iteration 11/250, Loss: 0.0105\n",
      "Epoch 100/200, Iteration 12/250, Loss: 0.0251\n",
      "Epoch 100/200, Iteration 13/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 14/250, Loss: 0.0193\n",
      "Epoch 100/200, Iteration 15/250, Loss: 0.0178\n",
      "Epoch 100/200, Iteration 16/250, Loss: 0.0065\n",
      "Epoch 100/200, Iteration 17/250, Loss: 0.0123\n",
      "Epoch 100/200, Iteration 18/250, Loss: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Iteration 19/250, Loss: 0.0209\n",
      "Epoch 100/200, Iteration 20/250, Loss: 0.0170\n",
      "Epoch 100/200, Iteration 21/250, Loss: 0.0266\n",
      "Epoch 100/200, Iteration 22/250, Loss: 0.0251\n",
      "Epoch 100/200, Iteration 23/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 24/250, Loss: 0.0217\n",
      "Epoch 100/200, Iteration 25/250, Loss: 0.0223\n",
      "Epoch 100/200, Iteration 26/250, Loss: 0.0087\n",
      "Epoch 100/200, Iteration 27/250, Loss: 0.0165\n",
      "Epoch 100/200, Iteration 28/250, Loss: 0.0179\n",
      "Epoch 100/200, Iteration 29/250, Loss: 0.0150\n",
      "Epoch 100/200, Iteration 30/250, Loss: 0.0209\n",
      "Epoch 100/200, Iteration 31/250, Loss: 0.0220\n",
      "Epoch 100/200, Iteration 32/250, Loss: 0.0157\n",
      "Epoch 100/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 34/250, Loss: 0.0178\n",
      "Epoch 100/200, Iteration 35/250, Loss: 0.0165\n",
      "Epoch 100/200, Iteration 36/250, Loss: 0.0090\n",
      "Epoch 100/200, Iteration 37/250, Loss: 0.0238\n",
      "Epoch 100/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 100/200, Iteration 39/250, Loss: 0.0076\n",
      "Epoch 100/200, Iteration 40/250, Loss: 0.0129\n",
      "Epoch 100/200, Iteration 41/250, Loss: 0.0169\n",
      "Epoch 100/200, Iteration 42/250, Loss: 0.0153\n",
      "Epoch 100/200, Iteration 43/250, Loss: 0.0172\n",
      "Epoch 100/200, Iteration 44/250, Loss: 0.0143\n",
      "Epoch 100/200, Iteration 45/250, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 46/250, Loss: 0.0225\n",
      "Epoch 100/200, Iteration 47/250, Loss: 0.0159\n",
      "Epoch 100/200, Iteration 48/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 49/250, Loss: 0.0084\n",
      "Epoch 100/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 51/250, Loss: 0.0104\n",
      "Epoch 100/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 53/250, Loss: 0.0209\n",
      "Epoch 100/200, Iteration 54/250, Loss: 0.0179\n",
      "Epoch 100/200, Iteration 55/250, Loss: 0.0311\n",
      "Epoch 100/200, Iteration 56/250, Loss: 0.0210\n",
      "Epoch 100/200, Iteration 57/250, Loss: 0.0300\n",
      "Epoch 100/200, Iteration 58/250, Loss: 0.0263\n",
      "Epoch 100/200, Iteration 59/250, Loss: 0.0419\n",
      "Epoch 100/200, Iteration 60/250, Loss: 0.0128\n",
      "Epoch 100/200, Iteration 61/250, Loss: 0.0320\n",
      "Epoch 100/200, Iteration 62/250, Loss: 0.0147\n",
      "Epoch 100/200, Iteration 63/250, Loss: 0.0140\n",
      "Epoch 100/200, Iteration 64/250, Loss: 0.0124\n",
      "Epoch 100/200, Iteration 65/250, Loss: 0.0169\n",
      "Epoch 100/200, Iteration 66/250, Loss: 0.0074\n",
      "Epoch 100/200, Iteration 67/250, Loss: 0.0072\n",
      "Epoch 100/200, Iteration 68/250, Loss: 0.0232\n",
      "Epoch 100/200, Iteration 69/250, Loss: 0.0184\n",
      "Epoch 100/200, Iteration 70/250, Loss: 0.0160\n",
      "Epoch 100/200, Iteration 71/250, Loss: 0.0110\n",
      "Epoch 100/200, Iteration 72/250, Loss: 0.0297\n",
      "Epoch 100/200, Iteration 73/250, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 74/250, Loss: 0.0219\n",
      "Epoch 100/200, Iteration 75/250, Loss: 0.0160\n",
      "Epoch 100/200, Iteration 76/250, Loss: 0.0229\n",
      "Epoch 100/200, Iteration 77/250, Loss: 0.0104\n",
      "Epoch 100/200, Iteration 78/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 79/250, Loss: 0.0069\n",
      "Epoch 100/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 100/200, Iteration 81/250, Loss: 0.0119\n",
      "Epoch 100/200, Iteration 82/250, Loss: 0.0304\n",
      "Epoch 100/200, Iteration 83/250, Loss: 0.0101\n",
      "Epoch 100/200, Iteration 84/250, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 85/250, Loss: 0.0132\n",
      "Epoch 100/200, Iteration 86/250, Loss: 0.0125\n",
      "Epoch 100/200, Iteration 87/250, Loss: 0.0089\n",
      "Epoch 100/200, Iteration 88/250, Loss: 0.0192\n",
      "Epoch 100/200, Iteration 89/250, Loss: 0.0223\n",
      "Epoch 100/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 91/250, Loss: 0.0072\n",
      "Epoch 100/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 100/200, Iteration 93/250, Loss: 0.0186\n",
      "Epoch 100/200, Iteration 94/250, Loss: 0.0080\n",
      "Epoch 100/200, Iteration 95/250, Loss: 0.0242\n",
      "Epoch 100/200, Iteration 96/250, Loss: 0.0138\n",
      "Epoch 100/200, Iteration 97/250, Loss: 0.0150\n",
      "Epoch 100/200, Iteration 98/250, Loss: 0.0174\n",
      "Epoch 100/200, Iteration 99/250, Loss: 0.0193\n",
      "Epoch 100/200, Iteration 100/250, Loss: 0.0134\n",
      "Epoch 100/200, Iteration 101/250, Loss: 0.0139\n",
      "Epoch 100/200, Iteration 102/250, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 103/250, Loss: 0.0092\n",
      "Epoch 100/200, Iteration 104/250, Loss: 0.0180\n",
      "Epoch 100/200, Iteration 105/250, Loss: 0.0205\n",
      "Epoch 100/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 107/250, Loss: 0.0075\n",
      "Epoch 100/200, Iteration 108/250, Loss: 0.0131\n",
      "Epoch 100/200, Iteration 109/250, Loss: 0.0164\n",
      "Epoch 100/200, Iteration 110/250, Loss: 0.0220\n",
      "Epoch 100/200, Iteration 111/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 112/250, Loss: 0.0137\n",
      "Epoch 100/200, Iteration 113/250, Loss: 0.0108\n",
      "Epoch 100/200, Iteration 114/250, Loss: 0.0058\n",
      "Epoch 100/200, Iteration 115/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 116/250, Loss: 0.0368\n",
      "Epoch 100/200, Iteration 117/250, Loss: 0.0259\n",
      "Epoch 100/200, Iteration 118/250, Loss: 0.0087\n",
      "Epoch 100/200, Iteration 119/250, Loss: 0.0160\n",
      "Epoch 100/200, Iteration 120/250, Loss: 0.0177\n",
      "Epoch 100/200, Iteration 121/250, Loss: 0.0074\n",
      "Epoch 100/200, Iteration 122/250, Loss: 0.0135\n",
      "Epoch 100/200, Iteration 123/250, Loss: 0.0212\n",
      "Epoch 100/200, Iteration 124/250, Loss: 0.0253\n",
      "Epoch 100/200, Iteration 125/250, Loss: 0.0105\n",
      "Epoch 100/200, Iteration 126/250, Loss: 0.0155\n",
      "Epoch 100/200, Iteration 127/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 128/250, Loss: 0.0063\n",
      "Epoch 100/200, Iteration 129/250, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 130/250, Loss: 0.0131\n",
      "Epoch 100/200, Iteration 131/250, Loss: 0.0106\n",
      "Epoch 100/200, Iteration 132/250, Loss: 0.0077\n",
      "Epoch 100/200, Iteration 133/250, Loss: 0.0131\n",
      "Epoch 100/200, Iteration 134/250, Loss: 0.0136\n",
      "Epoch 100/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 100/200, Iteration 136/250, Loss: 0.0178\n",
      "Epoch 100/200, Iteration 137/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 138/250, Loss: 0.0196\n",
      "Epoch 100/200, Iteration 139/250, Loss: 0.0176\n",
      "Epoch 100/200, Iteration 140/250, Loss: 0.0174\n",
      "Epoch 100/200, Iteration 141/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 142/250, Loss: 0.0210\n",
      "Epoch 100/200, Iteration 143/250, Loss: 0.0232\n",
      "Epoch 100/200, Iteration 144/250, Loss: 0.0370\n",
      "Epoch 100/200, Iteration 145/250, Loss: 0.0073\n",
      "Epoch 100/200, Iteration 146/250, Loss: 0.0094\n",
      "Epoch 100/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 100/200, Iteration 148/250, Loss: 0.0116\n",
      "Epoch 100/200, Iteration 149/250, Loss: 0.0076\n",
      "Epoch 100/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 151/250, Loss: 0.0083\n",
      "Epoch 100/200, Iteration 152/250, Loss: 0.0235\n",
      "Epoch 100/200, Iteration 153/250, Loss: 0.0100\n",
      "Epoch 100/200, Iteration 154/250, Loss: 0.0306\n",
      "Epoch 100/200, Iteration 155/250, Loss: 0.0181\n",
      "Epoch 100/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 100/200, Iteration 157/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 158/250, Loss: 0.0262\n",
      "Epoch 100/200, Iteration 159/250, Loss: 0.0153\n",
      "Epoch 100/200, Iteration 160/250, Loss: 0.0136\n",
      "Epoch 100/200, Iteration 161/250, Loss: 0.0212\n",
      "Epoch 100/200, Iteration 162/250, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 163/250, Loss: 0.0106\n",
      "Epoch 100/200, Iteration 164/250, Loss: 0.0194\n",
      "Epoch 100/200, Iteration 165/250, Loss: 0.0083\n",
      "Epoch 100/200, Iteration 166/250, Loss: 0.0139\n",
      "Epoch 100/200, Iteration 167/250, Loss: 0.0085\n",
      "Epoch 100/200, Iteration 168/250, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 169/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 170/250, Loss: 0.0280\n",
      "Epoch 100/200, Iteration 171/250, Loss: 0.0108\n",
      "Epoch 100/200, Iteration 172/250, Loss: 0.0180\n",
      "Epoch 100/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 100/200, Iteration 174/250, Loss: 0.0174\n",
      "Epoch 100/200, Iteration 175/250, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 176/250, Loss: 0.0167\n",
      "Epoch 100/200, Iteration 177/250, Loss: 0.0079\n",
      "Epoch 100/200, Iteration 178/250, Loss: 0.0084\n",
      "Epoch 100/200, Iteration 179/250, Loss: 0.0284\n",
      "Epoch 100/200, Iteration 180/250, Loss: 0.0123\n",
      "Epoch 100/200, Iteration 181/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 182/250, Loss: 0.0116\n",
      "Epoch 100/200, Iteration 183/250, Loss: 0.0101\n",
      "Epoch 100/200, Iteration 184/250, Loss: 0.0175\n",
      "Epoch 100/200, Iteration 185/250, Loss: 0.0284\n",
      "Epoch 100/200, Iteration 186/250, Loss: 0.0283\n",
      "Epoch 100/200, Iteration 187/250, Loss: 0.0156\n",
      "Epoch 100/200, Iteration 188/250, Loss: 0.0274\n",
      "Epoch 100/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 100/200, Iteration 190/250, Loss: 0.0108\n",
      "Epoch 100/200, Iteration 191/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 192/250, Loss: 0.0097\n",
      "Epoch 100/200, Iteration 193/250, Loss: 0.0089\n",
      "Epoch 100/200, Iteration 194/250, Loss: 0.0131\n",
      "Epoch 100/200, Iteration 195/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 196/250, Loss: 0.0249\n",
      "Epoch 100/200, Iteration 197/250, Loss: 0.0070\n",
      "Epoch 100/200, Iteration 198/250, Loss: 0.0125\n",
      "Epoch 100/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 100/200, Iteration 200/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 201/250, Loss: 0.0086\n",
      "Epoch 100/200, Iteration 202/250, Loss: 0.0085\n",
      "Epoch 100/200, Iteration 203/250, Loss: 0.0149\n",
      "Epoch 100/200, Iteration 204/250, Loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Iteration 205/250, Loss: 0.0107\n",
      "Epoch 100/200, Iteration 206/250, Loss: 0.0154\n",
      "Epoch 100/200, Iteration 207/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 208/250, Loss: 0.0337\n",
      "Epoch 100/200, Iteration 209/250, Loss: 0.0127\n",
      "Epoch 100/200, Iteration 210/250, Loss: 0.0223\n",
      "Epoch 100/200, Iteration 211/250, Loss: 0.0200\n",
      "Epoch 100/200, Iteration 212/250, Loss: 0.0073\n",
      "Epoch 100/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 100/200, Iteration 214/250, Loss: 0.0094\n",
      "Epoch 100/200, Iteration 215/250, Loss: 0.0127\n",
      "Epoch 100/200, Iteration 216/250, Loss: 0.0134\n",
      "Epoch 100/200, Iteration 217/250, Loss: 0.0161\n",
      "Epoch 100/200, Iteration 218/250, Loss: 0.0124\n",
      "Epoch 100/200, Iteration 219/250, Loss: 0.0208\n",
      "Epoch 100/200, Iteration 220/250, Loss: 0.0201\n",
      "Epoch 100/200, Iteration 221/250, Loss: 0.0247\n",
      "Epoch 100/200, Iteration 222/250, Loss: 0.0121\n",
      "Epoch 100/200, Iteration 223/250, Loss: 0.0100\n",
      "Epoch 100/200, Iteration 224/250, Loss: 0.0054\n",
      "Epoch 100/200, Iteration 225/250, Loss: 0.0096\n",
      "Epoch 100/200, Iteration 226/250, Loss: 0.0247\n",
      "Epoch 100/200, Iteration 227/250, Loss: 0.0074\n",
      "Epoch 100/200, Iteration 228/250, Loss: 0.0344\n",
      "Epoch 100/200, Iteration 229/250, Loss: 0.0236\n",
      "Epoch 100/200, Iteration 230/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 231/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 232/250, Loss: 0.0212\n",
      "Epoch 100/200, Iteration 233/250, Loss: 0.0229\n",
      "Epoch 100/200, Iteration 234/250, Loss: 0.0315\n",
      "Epoch 100/200, Iteration 235/250, Loss: 0.0186\n",
      "Epoch 100/200, Iteration 236/250, Loss: 0.0108\n",
      "Epoch 100/200, Iteration 237/250, Loss: 0.0151\n",
      "Epoch 100/200, Iteration 238/250, Loss: 0.0121\n",
      "Epoch 100/200, Iteration 239/250, Loss: 0.0073\n",
      "Epoch 100/200, Iteration 240/250, Loss: 0.0193\n",
      "Epoch 100/200, Iteration 241/250, Loss: 0.0211\n",
      "Epoch 100/200, Iteration 242/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 243/250, Loss: 0.0106\n",
      "Epoch 100/200, Iteration 244/250, Loss: 0.0136\n",
      "Epoch 100/200, Iteration 245/250, Loss: 0.0145\n",
      "Epoch 100/200, Iteration 246/250, Loss: 0.0358\n",
      "Epoch 100/200, Iteration 247/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 248/250, Loss: 0.0138\n",
      "Epoch 100/200, Iteration 249/250, Loss: 0.0087\n",
      "Epoch 100/200, Iteration 250/250, Loss: 0.0127\n",
      "Train Error: \n",
      " Accuracy: 88.49%, Avg loss: 0.006199, MRE: 0.616010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.25%, Avg loss: 0.006237, MRE: 0.973711 \n",
      "\n",
      "Epoch 101/200, Iteration 1/250, Loss: 0.0044\n",
      "Epoch 101/200, Iteration 2/250, Loss: 0.0276\n",
      "Epoch 101/200, Iteration 3/250, Loss: 0.0156\n",
      "Epoch 101/200, Iteration 4/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 5/250, Loss: 0.0213\n",
      "Epoch 101/200, Iteration 6/250, Loss: 0.0196\n",
      "Epoch 101/200, Iteration 7/250, Loss: 0.0089\n",
      "Epoch 101/200, Iteration 8/250, Loss: 0.0173\n",
      "Epoch 101/200, Iteration 9/250, Loss: 0.0053\n",
      "Epoch 101/200, Iteration 10/250, Loss: 0.0116\n",
      "Epoch 101/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 12/250, Loss: 0.0150\n",
      "Epoch 101/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 101/200, Iteration 14/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 15/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 16/250, Loss: 0.0073\n",
      "Epoch 101/200, Iteration 17/250, Loss: 0.0188\n",
      "Epoch 101/200, Iteration 18/250, Loss: 0.0184\n",
      "Epoch 101/200, Iteration 19/250, Loss: 0.0081\n",
      "Epoch 101/200, Iteration 20/250, Loss: 0.0184\n",
      "Epoch 101/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 101/200, Iteration 22/250, Loss: 0.0190\n",
      "Epoch 101/200, Iteration 23/250, Loss: 0.0076\n",
      "Epoch 101/200, Iteration 24/250, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 25/250, Loss: 0.0123\n",
      "Epoch 101/200, Iteration 26/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 27/250, Loss: 0.0179\n",
      "Epoch 101/200, Iteration 28/250, Loss: 0.0130\n",
      "Epoch 101/200, Iteration 29/250, Loss: 0.0074\n",
      "Epoch 101/200, Iteration 30/250, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 31/250, Loss: 0.0098\n",
      "Epoch 101/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 101/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 101/200, Iteration 34/250, Loss: 0.0343\n",
      "Epoch 101/200, Iteration 35/250, Loss: 0.0125\n",
      "Epoch 101/200, Iteration 36/250, Loss: 0.0249\n",
      "Epoch 101/200, Iteration 37/250, Loss: 0.0107\n",
      "Epoch 101/200, Iteration 38/250, Loss: 0.0184\n",
      "Epoch 101/200, Iteration 39/250, Loss: 0.0127\n",
      "Epoch 101/200, Iteration 40/250, Loss: 0.0158\n",
      "Epoch 101/200, Iteration 41/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 42/250, Loss: 0.0144\n",
      "Epoch 101/200, Iteration 43/250, Loss: 0.0104\n",
      "Epoch 101/200, Iteration 44/250, Loss: 0.0136\n",
      "Epoch 101/200, Iteration 45/250, Loss: 0.0175\n",
      "Epoch 101/200, Iteration 46/250, Loss: 0.0109\n",
      "Epoch 101/200, Iteration 47/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 101/200, Iteration 49/250, Loss: 0.0159\n",
      "Epoch 101/200, Iteration 50/250, Loss: 0.0377\n",
      "Epoch 101/200, Iteration 51/250, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 52/250, Loss: 0.0140\n",
      "Epoch 101/200, Iteration 53/250, Loss: 0.0172\n",
      "Epoch 101/200, Iteration 54/250, Loss: 0.0173\n",
      "Epoch 101/200, Iteration 55/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 56/250, Loss: 0.0211\n",
      "Epoch 101/200, Iteration 57/250, Loss: 0.0081\n",
      "Epoch 101/200, Iteration 58/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 59/250, Loss: 0.0144\n",
      "Epoch 101/200, Iteration 60/250, Loss: 0.0164\n",
      "Epoch 101/200, Iteration 61/250, Loss: 0.0112\n",
      "Epoch 101/200, Iteration 62/250, Loss: 0.0344\n",
      "Epoch 101/200, Iteration 63/250, Loss: 0.0365\n",
      "Epoch 101/200, Iteration 64/250, Loss: 0.0180\n",
      "Epoch 101/200, Iteration 65/250, Loss: 0.0104\n",
      "Epoch 101/200, Iteration 66/250, Loss: 0.0203\n",
      "Epoch 101/200, Iteration 67/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 68/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 69/250, Loss: 0.0302\n",
      "Epoch 101/200, Iteration 70/250, Loss: 0.0131\n",
      "Epoch 101/200, Iteration 71/250, Loss: 0.0254\n",
      "Epoch 101/200, Iteration 72/250, Loss: 0.0076\n",
      "Epoch 101/200, Iteration 73/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 74/250, Loss: 0.0108\n",
      "Epoch 101/200, Iteration 75/250, Loss: 0.0073\n",
      "Epoch 101/200, Iteration 76/250, Loss: 0.0138\n",
      "Epoch 101/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 101/200, Iteration 78/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 80/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 81/250, Loss: 0.0078\n",
      "Epoch 101/200, Iteration 82/250, Loss: 0.0205\n",
      "Epoch 101/200, Iteration 83/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 84/250, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 85/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 86/250, Loss: 0.0240\n",
      "Epoch 101/200, Iteration 87/250, Loss: 0.0128\n",
      "Epoch 101/200, Iteration 88/250, Loss: 0.0076\n",
      "Epoch 101/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 90/250, Loss: 0.0122\n",
      "Epoch 101/200, Iteration 91/250, Loss: 0.0112\n",
      "Epoch 101/200, Iteration 92/250, Loss: 0.0259\n",
      "Epoch 101/200, Iteration 93/250, Loss: 0.0247\n",
      "Epoch 101/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 101/200, Iteration 95/250, Loss: 0.0189\n",
      "Epoch 101/200, Iteration 96/250, Loss: 0.0186\n",
      "Epoch 101/200, Iteration 97/250, Loss: 0.0191\n",
      "Epoch 101/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 101/200, Iteration 99/250, Loss: 0.0114\n",
      "Epoch 101/200, Iteration 100/250, Loss: 0.0234\n",
      "Epoch 101/200, Iteration 101/250, Loss: 0.0142\n",
      "Epoch 101/200, Iteration 102/250, Loss: 0.0079\n",
      "Epoch 101/200, Iteration 103/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 104/250, Loss: 0.0205\n",
      "Epoch 101/200, Iteration 105/250, Loss: 0.0232\n",
      "Epoch 101/200, Iteration 106/250, Loss: 0.0132\n",
      "Epoch 101/200, Iteration 107/250, Loss: 0.0185\n",
      "Epoch 101/200, Iteration 108/250, Loss: 0.0121\n",
      "Epoch 101/200, Iteration 109/250, Loss: 0.0117\n",
      "Epoch 101/200, Iteration 110/250, Loss: 0.0201\n",
      "Epoch 101/200, Iteration 111/250, Loss: 0.0149\n",
      "Epoch 101/200, Iteration 112/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 113/250, Loss: 0.0237\n",
      "Epoch 101/200, Iteration 114/250, Loss: 0.0151\n",
      "Epoch 101/200, Iteration 115/250, Loss: 0.0179\n",
      "Epoch 101/200, Iteration 116/250, Loss: 0.0123\n",
      "Epoch 101/200, Iteration 117/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 118/250, Loss: 0.0131\n",
      "Epoch 101/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 101/200, Iteration 120/250, Loss: 0.0224\n",
      "Epoch 101/200, Iteration 121/250, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 122/250, Loss: 0.0075\n",
      "Epoch 101/200, Iteration 123/250, Loss: 0.0088\n",
      "Epoch 101/200, Iteration 124/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 125/250, Loss: 0.0230\n",
      "Epoch 101/200, Iteration 126/250, Loss: 0.0185\n",
      "Epoch 101/200, Iteration 127/250, Loss: 0.0141\n",
      "Epoch 101/200, Iteration 128/250, Loss: 0.0181\n",
      "Epoch 101/200, Iteration 129/250, Loss: 0.0198\n",
      "Epoch 101/200, Iteration 130/250, Loss: 0.0276\n",
      "Epoch 101/200, Iteration 131/250, Loss: 0.0140\n",
      "Epoch 101/200, Iteration 132/250, Loss: 0.0122\n",
      "Epoch 101/200, Iteration 133/250, Loss: 0.0140\n",
      "Epoch 101/200, Iteration 134/250, Loss: 0.0089\n",
      "Epoch 101/200, Iteration 135/250, Loss: 0.0276\n",
      "Epoch 101/200, Iteration 136/250, Loss: 0.0073\n",
      "Epoch 101/200, Iteration 137/250, Loss: 0.0142\n",
      "Epoch 101/200, Iteration 138/250, Loss: 0.0084\n",
      "Epoch 101/200, Iteration 139/250, Loss: 0.0129\n",
      "Epoch 101/200, Iteration 140/250, Loss: 0.0068\n",
      "Epoch 101/200, Iteration 141/250, Loss: 0.0226\n",
      "Epoch 101/200, Iteration 142/250, Loss: 0.0127\n",
      "Epoch 101/200, Iteration 143/250, Loss: 0.0199\n",
      "Epoch 101/200, Iteration 144/250, Loss: 0.0081\n",
      "Epoch 101/200, Iteration 145/250, Loss: 0.0061\n",
      "Epoch 101/200, Iteration 146/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 147/250, Loss: 0.0192\n",
      "Epoch 101/200, Iteration 148/250, Loss: 0.0076\n",
      "Epoch 101/200, Iteration 149/250, Loss: 0.0120\n",
      "Epoch 101/200, Iteration 150/250, Loss: 0.0075\n",
      "Epoch 101/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 101/200, Iteration 152/250, Loss: 0.0292\n",
      "Epoch 101/200, Iteration 153/250, Loss: 0.0245\n",
      "Epoch 101/200, Iteration 154/250, Loss: 0.0172\n",
      "Epoch 101/200, Iteration 155/250, Loss: 0.0196\n",
      "Epoch 101/200, Iteration 156/250, Loss: 0.0248\n",
      "Epoch 101/200, Iteration 157/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 158/250, Loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200, Iteration 159/250, Loss: 0.0175\n",
      "Epoch 101/200, Iteration 160/250, Loss: 0.0110\n",
      "Epoch 101/200, Iteration 161/250, Loss: 0.0229\n",
      "Epoch 101/200, Iteration 162/250, Loss: 0.0191\n",
      "Epoch 101/200, Iteration 163/250, Loss: 0.0175\n",
      "Epoch 101/200, Iteration 164/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 165/250, Loss: 0.0281\n",
      "Epoch 101/200, Iteration 166/250, Loss: 0.0075\n",
      "Epoch 101/200, Iteration 167/250, Loss: 0.0149\n",
      "Epoch 101/200, Iteration 168/250, Loss: 0.0342\n",
      "Epoch 101/200, Iteration 169/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 170/250, Loss: 0.0228\n",
      "Epoch 101/200, Iteration 171/250, Loss: 0.0185\n",
      "Epoch 101/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 173/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 174/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 175/250, Loss: 0.0166\n",
      "Epoch 101/200, Iteration 176/250, Loss: 0.0106\n",
      "Epoch 101/200, Iteration 177/250, Loss: 0.0168\n",
      "Epoch 101/200, Iteration 178/250, Loss: 0.0179\n",
      "Epoch 101/200, Iteration 179/250, Loss: 0.0082\n",
      "Epoch 101/200, Iteration 180/250, Loss: 0.0079\n",
      "Epoch 101/200, Iteration 181/250, Loss: 0.0291\n",
      "Epoch 101/200, Iteration 182/250, Loss: 0.0061\n",
      "Epoch 101/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 101/200, Iteration 184/250, Loss: 0.0163\n",
      "Epoch 101/200, Iteration 185/250, Loss: 0.0079\n",
      "Epoch 101/200, Iteration 186/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 187/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 188/250, Loss: 0.0224\n",
      "Epoch 101/200, Iteration 189/250, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 190/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 191/250, Loss: 0.0161\n",
      "Epoch 101/200, Iteration 192/250, Loss: 0.0135\n",
      "Epoch 101/200, Iteration 193/250, Loss: 0.0216\n",
      "Epoch 101/200, Iteration 194/250, Loss: 0.0171\n",
      "Epoch 101/200, Iteration 195/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 196/250, Loss: 0.0133\n",
      "Epoch 101/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 101/200, Iteration 198/250, Loss: 0.0178\n",
      "Epoch 101/200, Iteration 199/250, Loss: 0.0156\n",
      "Epoch 101/200, Iteration 200/250, Loss: 0.0316\n",
      "Epoch 101/200, Iteration 201/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 202/250, Loss: 0.0136\n",
      "Epoch 101/200, Iteration 203/250, Loss: 0.0150\n",
      "Epoch 101/200, Iteration 204/250, Loss: 0.0189\n",
      "Epoch 101/200, Iteration 205/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 206/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 207/250, Loss: 0.0089\n",
      "Epoch 101/200, Iteration 208/250, Loss: 0.0156\n",
      "Epoch 101/200, Iteration 209/250, Loss: 0.0120\n",
      "Epoch 101/200, Iteration 210/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 211/250, Loss: 0.0098\n",
      "Epoch 101/200, Iteration 212/250, Loss: 0.0142\n",
      "Epoch 101/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 214/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 215/250, Loss: 0.0160\n",
      "Epoch 101/200, Iteration 216/250, Loss: 0.0089\n",
      "Epoch 101/200, Iteration 217/250, Loss: 0.0243\n",
      "Epoch 101/200, Iteration 218/250, Loss: 0.0265\n",
      "Epoch 101/200, Iteration 219/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 220/250, Loss: 0.0302\n",
      "Epoch 101/200, Iteration 221/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 222/250, Loss: 0.0148\n",
      "Epoch 101/200, Iteration 223/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 224/250, Loss: 0.0085\n",
      "Epoch 101/200, Iteration 225/250, Loss: 0.0099\n",
      "Epoch 101/200, Iteration 226/250, Loss: 0.0204\n",
      "Epoch 101/200, Iteration 227/250, Loss: 0.0265\n",
      "Epoch 101/200, Iteration 228/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 229/250, Loss: 0.0114\n",
      "Epoch 101/200, Iteration 230/250, Loss: 0.0240\n",
      "Epoch 101/200, Iteration 231/250, Loss: 0.0130\n",
      "Epoch 101/200, Iteration 232/250, Loss: 0.0100\n",
      "Epoch 101/200, Iteration 233/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 234/250, Loss: 0.0193\n",
      "Epoch 101/200, Iteration 235/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 236/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 237/250, Loss: 0.0113\n",
      "Epoch 101/200, Iteration 238/250, Loss: 0.0181\n",
      "Epoch 101/200, Iteration 239/250, Loss: 0.0287\n",
      "Epoch 101/200, Iteration 240/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 241/250, Loss: 0.0249\n",
      "Epoch 101/200, Iteration 242/250, Loss: 0.0396\n",
      "Epoch 101/200, Iteration 243/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 244/250, Loss: 0.0178\n",
      "Epoch 101/200, Iteration 245/250, Loss: 0.0128\n",
      "Epoch 101/200, Iteration 246/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 247/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 248/250, Loss: 0.0175\n",
      "Epoch 101/200, Iteration 249/250, Loss: 0.0117\n",
      "Epoch 101/200, Iteration 250/250, Loss: 0.0087\n",
      "Train Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.006617, MRE: 0.673986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.006536, MRE: 1.172195 \n",
      "\n",
      "Epoch 102/200, Iteration 1/250, Loss: 0.0212\n",
      "Epoch 102/200, Iteration 2/250, Loss: 0.0226\n",
      "Epoch 102/200, Iteration 3/250, Loss: 0.0256\n",
      "Epoch 102/200, Iteration 4/250, Loss: 0.0250\n",
      "Epoch 102/200, Iteration 5/250, Loss: 0.0176\n",
      "Epoch 102/200, Iteration 6/250, Loss: 0.0143\n",
      "Epoch 102/200, Iteration 7/250, Loss: 0.0155\n",
      "Epoch 102/200, Iteration 8/250, Loss: 0.0070\n",
      "Epoch 102/200, Iteration 9/250, Loss: 0.0163\n",
      "Epoch 102/200, Iteration 10/250, Loss: 0.0188\n",
      "Epoch 102/200, Iteration 11/250, Loss: 0.0074\n",
      "Epoch 102/200, Iteration 12/250, Loss: 0.0130\n",
      "Epoch 102/200, Iteration 13/250, Loss: 0.0213\n",
      "Epoch 102/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 102/200, Iteration 15/250, Loss: 0.0087\n",
      "Epoch 102/200, Iteration 16/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 17/250, Loss: 0.0141\n",
      "Epoch 102/200, Iteration 18/250, Loss: 0.0145\n",
      "Epoch 102/200, Iteration 19/250, Loss: 0.0100\n",
      "Epoch 102/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 21/250, Loss: 0.0111\n",
      "Epoch 102/200, Iteration 22/250, Loss: 0.0107\n",
      "Epoch 102/200, Iteration 23/250, Loss: 0.0240\n",
      "Epoch 102/200, Iteration 24/250, Loss: 0.0191\n",
      "Epoch 102/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 102/200, Iteration 26/250, Loss: 0.0180\n",
      "Epoch 102/200, Iteration 27/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 28/250, Loss: 0.0074\n",
      "Epoch 102/200, Iteration 29/250, Loss: 0.0232\n",
      "Epoch 102/200, Iteration 30/250, Loss: 0.0138\n",
      "Epoch 102/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 32/250, Loss: 0.0097\n",
      "Epoch 102/200, Iteration 33/250, Loss: 0.0289\n",
      "Epoch 102/200, Iteration 34/250, Loss: 0.0146\n",
      "Epoch 102/200, Iteration 35/250, Loss: 0.0235\n",
      "Epoch 102/200, Iteration 36/250, Loss: 0.0216\n",
      "Epoch 102/200, Iteration 37/250, Loss: 0.0178\n",
      "Epoch 102/200, Iteration 38/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 39/250, Loss: 0.0323\n",
      "Epoch 102/200, Iteration 40/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 41/250, Loss: 0.0320\n",
      "Epoch 102/200, Iteration 42/250, Loss: 0.0072\n",
      "Epoch 102/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 44/250, Loss: 0.0136\n",
      "Epoch 102/200, Iteration 45/250, Loss: 0.0181\n",
      "Epoch 102/200, Iteration 46/250, Loss: 0.0191\n",
      "Epoch 102/200, Iteration 47/250, Loss: 0.0160\n",
      "Epoch 102/200, Iteration 48/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 49/250, Loss: 0.0240\n",
      "Epoch 102/200, Iteration 50/250, Loss: 0.0221\n",
      "Epoch 102/200, Iteration 51/250, Loss: 0.0071\n",
      "Epoch 102/200, Iteration 52/250, Loss: 0.0135\n",
      "Epoch 102/200, Iteration 53/250, Loss: 0.0089\n",
      "Epoch 102/200, Iteration 54/250, Loss: 0.0078\n",
      "Epoch 102/200, Iteration 55/250, Loss: 0.0203\n",
      "Epoch 102/200, Iteration 56/250, Loss: 0.0099\n",
      "Epoch 102/200, Iteration 57/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 58/250, Loss: 0.0178\n",
      "Epoch 102/200, Iteration 59/250, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 60/250, Loss: 0.0113\n",
      "Epoch 102/200, Iteration 61/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 62/250, Loss: 0.0116\n",
      "Epoch 102/200, Iteration 63/250, Loss: 0.0159\n",
      "Epoch 102/200, Iteration 64/250, Loss: 0.0190\n",
      "Epoch 102/200, Iteration 65/250, Loss: 0.0144\n",
      "Epoch 102/200, Iteration 66/250, Loss: 0.0109\n",
      "Epoch 102/200, Iteration 67/250, Loss: 0.0129\n",
      "Epoch 102/200, Iteration 68/250, Loss: 0.0247\n",
      "Epoch 102/200, Iteration 69/250, Loss: 0.0280\n",
      "Epoch 102/200, Iteration 70/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 71/250, Loss: 0.0082\n",
      "Epoch 102/200, Iteration 72/250, Loss: 0.0475\n",
      "Epoch 102/200, Iteration 73/250, Loss: 0.0095\n",
      "Epoch 102/200, Iteration 74/250, Loss: 0.0147\n",
      "Epoch 102/200, Iteration 75/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 76/250, Loss: 0.0335\n",
      "Epoch 102/200, Iteration 77/250, Loss: 0.0072\n",
      "Epoch 102/200, Iteration 78/250, Loss: 0.0080\n",
      "Epoch 102/200, Iteration 79/250, Loss: 0.0131\n",
      "Epoch 102/200, Iteration 80/250, Loss: 0.0178\n",
      "Epoch 102/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 82/250, Loss: 0.0158\n",
      "Epoch 102/200, Iteration 83/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 84/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 86/250, Loss: 0.0125\n",
      "Epoch 102/200, Iteration 87/250, Loss: 0.0270\n",
      "Epoch 102/200, Iteration 88/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 89/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 90/250, Loss: 0.0267\n",
      "Epoch 102/200, Iteration 91/250, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 92/250, Loss: 0.0078\n",
      "Epoch 102/200, Iteration 93/250, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 94/250, Loss: 0.0110\n",
      "Epoch 102/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 102/200, Iteration 96/250, Loss: 0.0293\n",
      "Epoch 102/200, Iteration 97/250, Loss: 0.0112\n",
      "Epoch 102/200, Iteration 98/250, Loss: 0.0156\n",
      "Epoch 102/200, Iteration 99/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 100/250, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 101/250, Loss: 0.0159\n",
      "Epoch 102/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 102/200, Iteration 103/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 104/250, Loss: 0.0162\n",
      "Epoch 102/200, Iteration 105/250, Loss: 0.0234\n",
      "Epoch 102/200, Iteration 106/250, Loss: 0.0164\n",
      "Epoch 102/200, Iteration 107/250, Loss: 0.0243\n",
      "Epoch 102/200, Iteration 108/250, Loss: 0.0300\n",
      "Epoch 102/200, Iteration 109/250, Loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200, Iteration 110/250, Loss: 0.0164\n",
      "Epoch 102/200, Iteration 111/250, Loss: 0.0179\n",
      "Epoch 102/200, Iteration 112/250, Loss: 0.0100\n",
      "Epoch 102/200, Iteration 113/250, Loss: 0.0138\n",
      "Epoch 102/200, Iteration 114/250, Loss: 0.0193\n",
      "Epoch 102/200, Iteration 115/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 116/250, Loss: 0.0117\n",
      "Epoch 102/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 102/200, Iteration 118/250, Loss: 0.0062\n",
      "Epoch 102/200, Iteration 119/250, Loss: 0.0250\n",
      "Epoch 102/200, Iteration 120/250, Loss: 0.0112\n",
      "Epoch 102/200, Iteration 121/250, Loss: 0.0154\n",
      "Epoch 102/200, Iteration 122/250, Loss: 0.0150\n",
      "Epoch 102/200, Iteration 123/250, Loss: 0.0114\n",
      "Epoch 102/200, Iteration 124/250, Loss: 0.0139\n",
      "Epoch 102/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 126/250, Loss: 0.0204\n",
      "Epoch 102/200, Iteration 127/250, Loss: 0.0365\n",
      "Epoch 102/200, Iteration 128/250, Loss: 0.0107\n",
      "Epoch 102/200, Iteration 129/250, Loss: 0.0076\n",
      "Epoch 102/200, Iteration 130/250, Loss: 0.0096\n",
      "Epoch 102/200, Iteration 131/250, Loss: 0.0146\n",
      "Epoch 102/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 133/250, Loss: 0.0184\n",
      "Epoch 102/200, Iteration 134/250, Loss: 0.0179\n",
      "Epoch 102/200, Iteration 135/250, Loss: 0.0166\n",
      "Epoch 102/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 102/200, Iteration 137/250, Loss: 0.0162\n",
      "Epoch 102/200, Iteration 138/250, Loss: 0.0095\n",
      "Epoch 102/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 102/200, Iteration 141/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 142/250, Loss: 0.0063\n",
      "Epoch 102/200, Iteration 143/250, Loss: 0.0113\n",
      "Epoch 102/200, Iteration 144/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 145/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 146/250, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 147/250, Loss: 0.0137\n",
      "Epoch 102/200, Iteration 148/250, Loss: 0.0224\n",
      "Epoch 102/200, Iteration 149/250, Loss: 0.0125\n",
      "Epoch 102/200, Iteration 150/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 151/250, Loss: 0.0179\n",
      "Epoch 102/200, Iteration 152/250, Loss: 0.0187\n",
      "Epoch 102/200, Iteration 153/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 154/250, Loss: 0.0306\n",
      "Epoch 102/200, Iteration 155/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 156/250, Loss: 0.0180\n",
      "Epoch 102/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 158/250, Loss: 0.0087\n",
      "Epoch 102/200, Iteration 159/250, Loss: 0.0161\n",
      "Epoch 102/200, Iteration 160/250, Loss: 0.0380\n",
      "Epoch 102/200, Iteration 161/250, Loss: 0.0121\n",
      "Epoch 102/200, Iteration 162/250, Loss: 0.0345\n",
      "Epoch 102/200, Iteration 163/250, Loss: 0.0179\n",
      "Epoch 102/200, Iteration 164/250, Loss: 0.0293\n",
      "Epoch 102/200, Iteration 165/250, Loss: 0.0269\n",
      "Epoch 102/200, Iteration 166/250, Loss: 0.0065\n",
      "Epoch 102/200, Iteration 167/250, Loss: 0.0128\n",
      "Epoch 102/200, Iteration 168/250, Loss: 0.0201\n",
      "Epoch 102/200, Iteration 169/250, Loss: 0.0184\n",
      "Epoch 102/200, Iteration 170/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 171/250, Loss: 0.0208\n",
      "Epoch 102/200, Iteration 172/250, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 173/250, Loss: 0.0135\n",
      "Epoch 102/200, Iteration 174/250, Loss: 0.0212\n",
      "Epoch 102/200, Iteration 175/250, Loss: 0.0244\n",
      "Epoch 102/200, Iteration 176/250, Loss: 0.0089\n",
      "Epoch 102/200, Iteration 177/250, Loss: 0.0185\n",
      "Epoch 102/200, Iteration 178/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 179/250, Loss: 0.0149\n",
      "Epoch 102/200, Iteration 180/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 181/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 182/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 183/250, Loss: 0.0184\n",
      "Epoch 102/200, Iteration 184/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 185/250, Loss: 0.0116\n",
      "Epoch 102/200, Iteration 186/250, Loss: 0.0233\n",
      "Epoch 102/200, Iteration 187/250, Loss: 0.0143\n",
      "Epoch 102/200, Iteration 188/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 189/250, Loss: 0.0122\n",
      "Epoch 102/200, Iteration 190/250, Loss: 0.0342\n",
      "Epoch 102/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 192/250, Loss: 0.0219\n",
      "Epoch 102/200, Iteration 193/250, Loss: 0.0191\n",
      "Epoch 102/200, Iteration 194/250, Loss: 0.0124\n",
      "Epoch 102/200, Iteration 195/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 196/250, Loss: 0.0215\n",
      "Epoch 102/200, Iteration 197/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 198/250, Loss: 0.0185\n",
      "Epoch 102/200, Iteration 199/250, Loss: 0.0067\n",
      "Epoch 102/200, Iteration 200/250, Loss: 0.0327\n",
      "Epoch 102/200, Iteration 201/250, Loss: 0.0159\n",
      "Epoch 102/200, Iteration 202/250, Loss: 0.0108\n",
      "Epoch 102/200, Iteration 203/250, Loss: 0.0171\n",
      "Epoch 102/200, Iteration 204/250, Loss: 0.0147\n",
      "Epoch 102/200, Iteration 205/250, Loss: 0.0151\n",
      "Epoch 102/200, Iteration 206/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 207/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 208/250, Loss: 0.0182\n",
      "Epoch 102/200, Iteration 209/250, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 210/250, Loss: 0.0268\n",
      "Epoch 102/200, Iteration 211/250, Loss: 0.0065\n",
      "Epoch 102/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 213/250, Loss: 0.0134\n",
      "Epoch 102/200, Iteration 214/250, Loss: 0.0243\n",
      "Epoch 102/200, Iteration 215/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 216/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 217/250, Loss: 0.0152\n",
      "Epoch 102/200, Iteration 218/250, Loss: 0.0180\n",
      "Epoch 102/200, Iteration 219/250, Loss: 0.0097\n",
      "Epoch 102/200, Iteration 220/250, Loss: 0.0096\n",
      "Epoch 102/200, Iteration 221/250, Loss: 0.0127\n",
      "Epoch 102/200, Iteration 222/250, Loss: 0.0184\n",
      "Epoch 102/200, Iteration 223/250, Loss: 0.0183\n",
      "Epoch 102/200, Iteration 224/250, Loss: 0.0122\n",
      "Epoch 102/200, Iteration 225/250, Loss: 0.0110\n",
      "Epoch 102/200, Iteration 226/250, Loss: 0.0206\n",
      "Epoch 102/200, Iteration 227/250, Loss: 0.0195\n",
      "Epoch 102/200, Iteration 228/250, Loss: 0.0175\n",
      "Epoch 102/200, Iteration 229/250, Loss: 0.0129\n",
      "Epoch 102/200, Iteration 230/250, Loss: 0.0179\n",
      "Epoch 102/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 102/200, Iteration 233/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 234/250, Loss: 0.0157\n",
      "Epoch 102/200, Iteration 235/250, Loss: 0.0165\n",
      "Epoch 102/200, Iteration 236/250, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 102/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 239/250, Loss: 0.0214\n",
      "Epoch 102/200, Iteration 240/250, Loss: 0.0239\n",
      "Epoch 102/200, Iteration 241/250, Loss: 0.0073\n",
      "Epoch 102/200, Iteration 242/250, Loss: 0.0095\n",
      "Epoch 102/200, Iteration 243/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 244/250, Loss: 0.0246\n",
      "Epoch 102/200, Iteration 245/250, Loss: 0.0068\n",
      "Epoch 102/200, Iteration 246/250, Loss: 0.0231\n",
      "Epoch 102/200, Iteration 247/250, Loss: 0.0149\n",
      "Epoch 102/200, Iteration 248/250, Loss: 0.0131\n",
      "Epoch 102/200, Iteration 249/250, Loss: 0.0146\n",
      "Epoch 102/200, Iteration 250/250, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 95.49%, Avg loss: 0.005987, MRE: 0.629017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.85%, Avg loss: 0.005964, MRE: 1.090687 \n",
      "\n",
      "Epoch 103/200, Iteration 1/250, Loss: 0.0135\n",
      "Epoch 103/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 3/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 4/250, Loss: 0.0056\n",
      "Epoch 103/200, Iteration 5/250, Loss: 0.0247\n",
      "Epoch 103/200, Iteration 6/250, Loss: 0.0179\n",
      "Epoch 103/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 103/200, Iteration 8/250, Loss: 0.0122\n",
      "Epoch 103/200, Iteration 9/250, Loss: 0.0253\n",
      "Epoch 103/200, Iteration 10/250, Loss: 0.0065\n",
      "Epoch 103/200, Iteration 11/250, Loss: 0.0207\n",
      "Epoch 103/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 103/200, Iteration 13/250, Loss: 0.0182\n",
      "Epoch 103/200, Iteration 14/250, Loss: 0.0142\n",
      "Epoch 103/200, Iteration 15/250, Loss: 0.0269\n",
      "Epoch 103/200, Iteration 16/250, Loss: 0.0159\n",
      "Epoch 103/200, Iteration 17/250, Loss: 0.0187\n",
      "Epoch 103/200, Iteration 18/250, Loss: 0.0162\n",
      "Epoch 103/200, Iteration 19/250, Loss: 0.0090\n",
      "Epoch 103/200, Iteration 20/250, Loss: 0.0086\n",
      "Epoch 103/200, Iteration 21/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 22/250, Loss: 0.0388\n",
      "Epoch 103/200, Iteration 23/250, Loss: 0.0163\n",
      "Epoch 103/200, Iteration 24/250, Loss: 0.0307\n",
      "Epoch 103/200, Iteration 25/250, Loss: 0.0181\n",
      "Epoch 103/200, Iteration 26/250, Loss: 0.0092\n",
      "Epoch 103/200, Iteration 27/250, Loss: 0.0094\n",
      "Epoch 103/200, Iteration 28/250, Loss: 0.0057\n",
      "Epoch 103/200, Iteration 29/250, Loss: 0.0211\n",
      "Epoch 103/200, Iteration 30/250, Loss: 0.0119\n",
      "Epoch 103/200, Iteration 31/250, Loss: 0.0276\n",
      "Epoch 103/200, Iteration 32/250, Loss: 0.0143\n",
      "Epoch 103/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 34/250, Loss: 0.0253\n",
      "Epoch 103/200, Iteration 35/250, Loss: 0.0100\n",
      "Epoch 103/200, Iteration 36/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 37/250, Loss: 0.0173\n",
      "Epoch 103/200, Iteration 38/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 39/250, Loss: 0.0179\n",
      "Epoch 103/200, Iteration 40/250, Loss: 0.0083\n",
      "Epoch 103/200, Iteration 41/250, Loss: 0.0259\n",
      "Epoch 103/200, Iteration 42/250, Loss: 0.0189\n",
      "Epoch 103/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 103/200, Iteration 44/250, Loss: 0.0082\n",
      "Epoch 103/200, Iteration 45/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 46/250, Loss: 0.0147\n",
      "Epoch 103/200, Iteration 47/250, Loss: 0.0170\n",
      "Epoch 103/200, Iteration 48/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 49/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 50/250, Loss: 0.0128\n",
      "Epoch 103/200, Iteration 51/250, Loss: 0.0128\n",
      "Epoch 103/200, Iteration 52/250, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 53/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 54/250, Loss: 0.0110\n",
      "Epoch 103/200, Iteration 55/250, Loss: 0.0149\n",
      "Epoch 103/200, Iteration 56/250, Loss: 0.0138\n",
      "Epoch 103/200, Iteration 57/250, Loss: 0.0120\n",
      "Epoch 103/200, Iteration 58/250, Loss: 0.0091\n",
      "Epoch 103/200, Iteration 59/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200, Iteration 60/250, Loss: 0.0235\n",
      "Epoch 103/200, Iteration 61/250, Loss: 0.0177\n",
      "Epoch 103/200, Iteration 62/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 63/250, Loss: 0.0116\n",
      "Epoch 103/200, Iteration 64/250, Loss: 0.0410\n",
      "Epoch 103/200, Iteration 65/250, Loss: 0.0132\n",
      "Epoch 103/200, Iteration 66/250, Loss: 0.0122\n",
      "Epoch 103/200, Iteration 67/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 68/250, Loss: 0.0154\n",
      "Epoch 103/200, Iteration 69/250, Loss: 0.0102\n",
      "Epoch 103/200, Iteration 70/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 71/250, Loss: 0.0244\n",
      "Epoch 103/200, Iteration 72/250, Loss: 0.0271\n",
      "Epoch 103/200, Iteration 73/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 74/250, Loss: 0.0173\n",
      "Epoch 103/200, Iteration 75/250, Loss: 0.0097\n",
      "Epoch 103/200, Iteration 76/250, Loss: 0.0266\n",
      "Epoch 103/200, Iteration 77/250, Loss: 0.0061\n",
      "Epoch 103/200, Iteration 78/250, Loss: 0.0155\n",
      "Epoch 103/200, Iteration 79/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 80/250, Loss: 0.0148\n",
      "Epoch 103/200, Iteration 81/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 83/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 84/250, Loss: 0.0171\n",
      "Epoch 103/200, Iteration 85/250, Loss: 0.0286\n",
      "Epoch 103/200, Iteration 86/250, Loss: 0.0094\n",
      "Epoch 103/200, Iteration 87/250, Loss: 0.0218\n",
      "Epoch 103/200, Iteration 88/250, Loss: 0.0111\n",
      "Epoch 103/200, Iteration 89/250, Loss: 0.0154\n",
      "Epoch 103/200, Iteration 90/250, Loss: 0.0092\n",
      "Epoch 103/200, Iteration 91/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 92/250, Loss: 0.0086\n",
      "Epoch 103/200, Iteration 93/250, Loss: 0.0190\n",
      "Epoch 103/200, Iteration 94/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 95/250, Loss: 0.0313\n",
      "Epoch 103/200, Iteration 96/250, Loss: 0.0223\n",
      "Epoch 103/200, Iteration 97/250, Loss: 0.0173\n",
      "Epoch 103/200, Iteration 98/250, Loss: 0.0123\n",
      "Epoch 103/200, Iteration 99/250, Loss: 0.0304\n",
      "Epoch 103/200, Iteration 100/250, Loss: 0.0113\n",
      "Epoch 103/200, Iteration 101/250, Loss: 0.0074\n",
      "Epoch 103/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 103/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 104/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 105/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 106/250, Loss: 0.0145\n",
      "Epoch 103/200, Iteration 107/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 108/250, Loss: 0.0204\n",
      "Epoch 103/200, Iteration 109/250, Loss: 0.0244\n",
      "Epoch 103/200, Iteration 110/250, Loss: 0.0071\n",
      "Epoch 103/200, Iteration 111/250, Loss: 0.0180\n",
      "Epoch 103/200, Iteration 112/250, Loss: 0.0217\n",
      "Epoch 103/200, Iteration 113/250, Loss: 0.0232\n",
      "Epoch 103/200, Iteration 114/250, Loss: 0.0211\n",
      "Epoch 103/200, Iteration 115/250, Loss: 0.0206\n",
      "Epoch 103/200, Iteration 116/250, Loss: 0.0152\n",
      "Epoch 103/200, Iteration 117/250, Loss: 0.0197\n",
      "Epoch 103/200, Iteration 118/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 119/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 120/250, Loss: 0.0143\n",
      "Epoch 103/200, Iteration 121/250, Loss: 0.0195\n",
      "Epoch 103/200, Iteration 122/250, Loss: 0.0067\n",
      "Epoch 103/200, Iteration 123/250, Loss: 0.0082\n",
      "Epoch 103/200, Iteration 124/250, Loss: 0.0142\n",
      "Epoch 103/200, Iteration 125/250, Loss: 0.0121\n",
      "Epoch 103/200, Iteration 126/250, Loss: 0.0186\n",
      "Epoch 103/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 103/200, Iteration 128/250, Loss: 0.0135\n",
      "Epoch 103/200, Iteration 129/250, Loss: 0.0259\n",
      "Epoch 103/200, Iteration 130/250, Loss: 0.0102\n",
      "Epoch 103/200, Iteration 131/250, Loss: 0.0185\n",
      "Epoch 103/200, Iteration 132/250, Loss: 0.0097\n",
      "Epoch 103/200, Iteration 133/250, Loss: 0.0173\n",
      "Epoch 103/200, Iteration 134/250, Loss: 0.0279\n",
      "Epoch 103/200, Iteration 135/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 136/250, Loss: 0.0088\n",
      "Epoch 103/200, Iteration 137/250, Loss: 0.0074\n",
      "Epoch 103/200, Iteration 138/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 139/250, Loss: 0.0125\n",
      "Epoch 103/200, Iteration 140/250, Loss: 0.0207\n",
      "Epoch 103/200, Iteration 141/250, Loss: 0.0181\n",
      "Epoch 103/200, Iteration 142/250, Loss: 0.0063\n",
      "Epoch 103/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 103/200, Iteration 144/250, Loss: 0.0263\n",
      "Epoch 103/200, Iteration 145/250, Loss: 0.0122\n",
      "Epoch 103/200, Iteration 146/250, Loss: 0.0302\n",
      "Epoch 103/200, Iteration 147/250, Loss: 0.0245\n",
      "Epoch 103/200, Iteration 148/250, Loss: 0.0233\n",
      "Epoch 103/200, Iteration 149/250, Loss: 0.0237\n",
      "Epoch 103/200, Iteration 150/250, Loss: 0.0163\n",
      "Epoch 103/200, Iteration 151/250, Loss: 0.0082\n",
      "Epoch 103/200, Iteration 152/250, Loss: 0.0072\n",
      "Epoch 103/200, Iteration 153/250, Loss: 0.0159\n",
      "Epoch 103/200, Iteration 154/250, Loss: 0.0356\n",
      "Epoch 103/200, Iteration 155/250, Loss: 0.0110\n",
      "Epoch 103/200, Iteration 156/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 157/250, Loss: 0.0167\n",
      "Epoch 103/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 159/250, Loss: 0.0222\n",
      "Epoch 103/200, Iteration 160/250, Loss: 0.0175\n",
      "Epoch 103/200, Iteration 161/250, Loss: 0.0088\n",
      "Epoch 103/200, Iteration 162/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 163/250, Loss: 0.0152\n",
      "Epoch 103/200, Iteration 164/250, Loss: 0.0125\n",
      "Epoch 103/200, Iteration 165/250, Loss: 0.0151\n",
      "Epoch 103/200, Iteration 166/250, Loss: 0.0071\n",
      "Epoch 103/200, Iteration 167/250, Loss: 0.0223\n",
      "Epoch 103/200, Iteration 168/250, Loss: 0.0153\n",
      "Epoch 103/200, Iteration 169/250, Loss: 0.0147\n",
      "Epoch 103/200, Iteration 170/250, Loss: 0.0094\n",
      "Epoch 103/200, Iteration 171/250, Loss: 0.0116\n",
      "Epoch 103/200, Iteration 172/250, Loss: 0.0112\n",
      "Epoch 103/200, Iteration 173/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 174/250, Loss: 0.0150\n",
      "Epoch 103/200, Iteration 175/250, Loss: 0.0127\n",
      "Epoch 103/200, Iteration 176/250, Loss: 0.0182\n",
      "Epoch 103/200, Iteration 177/250, Loss: 0.0140\n",
      "Epoch 103/200, Iteration 178/250, Loss: 0.0219\n",
      "Epoch 103/200, Iteration 179/250, Loss: 0.0367\n",
      "Epoch 103/200, Iteration 180/250, Loss: 0.0132\n",
      "Epoch 103/200, Iteration 181/250, Loss: 0.0286\n",
      "Epoch 103/200, Iteration 182/250, Loss: 0.0207\n",
      "Epoch 103/200, Iteration 183/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 184/250, Loss: 0.0310\n",
      "Epoch 103/200, Iteration 185/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 186/250, Loss: 0.0241\n",
      "Epoch 103/200, Iteration 187/250, Loss: 0.0234\n",
      "Epoch 103/200, Iteration 188/250, Loss: 0.0103\n",
      "Epoch 103/200, Iteration 189/250, Loss: 0.0073\n",
      "Epoch 103/200, Iteration 190/250, Loss: 0.0259\n",
      "Epoch 103/200, Iteration 191/250, Loss: 0.0249\n",
      "Epoch 103/200, Iteration 192/250, Loss: 0.0076\n",
      "Epoch 103/200, Iteration 193/250, Loss: 0.0237\n",
      "Epoch 103/200, Iteration 194/250, Loss: 0.0367\n",
      "Epoch 103/200, Iteration 195/250, Loss: 0.0113\n",
      "Epoch 103/200, Iteration 196/250, Loss: 0.0326\n",
      "Epoch 103/200, Iteration 197/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 199/250, Loss: 0.0084\n",
      "Epoch 103/200, Iteration 200/250, Loss: 0.0070\n",
      "Epoch 103/200, Iteration 201/250, Loss: 0.0271\n",
      "Epoch 103/200, Iteration 202/250, Loss: 0.0104\n",
      "Epoch 103/200, Iteration 203/250, Loss: 0.0125\n",
      "Epoch 103/200, Iteration 204/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 205/250, Loss: 0.0102\n",
      "Epoch 103/200, Iteration 206/250, Loss: 0.0113\n",
      "Epoch 103/200, Iteration 207/250, Loss: 0.0196\n",
      "Epoch 103/200, Iteration 208/250, Loss: 0.0120\n",
      "Epoch 103/200, Iteration 209/250, Loss: 0.0198\n",
      "Epoch 103/200, Iteration 210/250, Loss: 0.0077\n",
      "Epoch 103/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 212/250, Loss: 0.0135\n",
      "Epoch 103/200, Iteration 213/250, Loss: 0.0259\n",
      "Epoch 103/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 215/250, Loss: 0.0179\n",
      "Epoch 103/200, Iteration 216/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 217/250, Loss: 0.0237\n",
      "Epoch 103/200, Iteration 218/250, Loss: 0.0257\n",
      "Epoch 103/200, Iteration 219/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 220/250, Loss: 0.0160\n",
      "Epoch 103/200, Iteration 221/250, Loss: 0.0211\n",
      "Epoch 103/200, Iteration 222/250, Loss: 0.0125\n",
      "Epoch 103/200, Iteration 223/250, Loss: 0.0083\n",
      "Epoch 103/200, Iteration 224/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 225/250, Loss: 0.0150\n",
      "Epoch 103/200, Iteration 226/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 227/250, Loss: 0.0160\n",
      "Epoch 103/200, Iteration 228/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 103/200, Iteration 230/250, Loss: 0.0213\n",
      "Epoch 103/200, Iteration 231/250, Loss: 0.0112\n",
      "Epoch 103/200, Iteration 232/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 233/250, Loss: 0.0090\n",
      "Epoch 103/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 103/200, Iteration 235/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 236/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 237/250, Loss: 0.0127\n",
      "Epoch 103/200, Iteration 238/250, Loss: 0.0177\n",
      "Epoch 103/200, Iteration 239/250, Loss: 0.0063\n",
      "Epoch 103/200, Iteration 240/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 241/250, Loss: 0.0158\n",
      "Epoch 103/200, Iteration 242/250, Loss: 0.0137\n",
      "Epoch 103/200, Iteration 243/250, Loss: 0.0220\n",
      "Epoch 103/200, Iteration 244/250, Loss: 0.0121\n",
      "Epoch 103/200, Iteration 245/250, Loss: 0.0130\n",
      "Epoch 103/200, Iteration 246/250, Loss: 0.0153\n",
      "Epoch 103/200, Iteration 247/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 248/250, Loss: 0.0084\n",
      "Epoch 103/200, Iteration 249/250, Loss: 0.0138\n",
      "Epoch 103/200, Iteration 250/250, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.45%, Avg loss: 0.006058, MRE: 0.623840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.95%, Avg loss: 0.006078, MRE: 1.041826 \n",
      "\n",
      "Epoch 104/200, Iteration 1/250, Loss: 0.0187\n",
      "Epoch 104/200, Iteration 2/250, Loss: 0.0145\n",
      "Epoch 104/200, Iteration 3/250, Loss: 0.0257\n",
      "Epoch 104/200, Iteration 4/250, Loss: 0.0088\n",
      "Epoch 104/200, Iteration 5/250, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 6/250, Loss: 0.0213\n",
      "Epoch 104/200, Iteration 7/250, Loss: 0.0140\n",
      "Epoch 104/200, Iteration 8/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 9/250, Loss: 0.0143\n",
      "Epoch 104/200, Iteration 10/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 11/250, Loss: 0.0303\n",
      "Epoch 104/200, Iteration 12/250, Loss: 0.0067\n",
      "Epoch 104/200, Iteration 13/250, Loss: 0.0212\n",
      "Epoch 104/200, Iteration 14/250, Loss: 0.0330\n",
      "Epoch 104/200, Iteration 15/250, Loss: 0.0161\n",
      "Epoch 104/200, Iteration 16/250, Loss: 0.0061\n",
      "Epoch 104/200, Iteration 17/250, Loss: 0.0264\n",
      "Epoch 104/200, Iteration 18/250, Loss: 0.0278\n",
      "Epoch 104/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 104/200, Iteration 20/250, Loss: 0.0132\n",
      "Epoch 104/200, Iteration 21/250, Loss: 0.0183\n",
      "Epoch 104/200, Iteration 22/250, Loss: 0.0201\n",
      "Epoch 104/200, Iteration 23/250, Loss: 0.0210\n",
      "Epoch 104/200, Iteration 24/250, Loss: 0.0068\n",
      "Epoch 104/200, Iteration 25/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 26/250, Loss: 0.0077\n",
      "Epoch 104/200, Iteration 27/250, Loss: 0.0158\n",
      "Epoch 104/200, Iteration 28/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 104/200, Iteration 30/250, Loss: 0.0462\n",
      "Epoch 104/200, Iteration 31/250, Loss: 0.0087\n",
      "Epoch 104/200, Iteration 32/250, Loss: 0.0071\n",
      "Epoch 104/200, Iteration 33/250, Loss: 0.0077\n",
      "Epoch 104/200, Iteration 34/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 35/250, Loss: 0.0088\n",
      "Epoch 104/200, Iteration 36/250, Loss: 0.0100\n",
      "Epoch 104/200, Iteration 37/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 38/250, Loss: 0.0122\n",
      "Epoch 104/200, Iteration 39/250, Loss: 0.0061\n",
      "Epoch 104/200, Iteration 40/250, Loss: 0.0191\n",
      "Epoch 104/200, Iteration 41/250, Loss: 0.0198\n",
      "Epoch 104/200, Iteration 42/250, Loss: 0.0124\n",
      "Epoch 104/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 44/250, Loss: 0.0206\n",
      "Epoch 104/200, Iteration 45/250, Loss: 0.0103\n",
      "Epoch 104/200, Iteration 46/250, Loss: 0.0158\n",
      "Epoch 104/200, Iteration 47/250, Loss: 0.0196\n",
      "Epoch 104/200, Iteration 48/250, Loss: 0.0379\n",
      "Epoch 104/200, Iteration 49/250, Loss: 0.0132\n",
      "Epoch 104/200, Iteration 50/250, Loss: 0.0115\n",
      "Epoch 104/200, Iteration 51/250, Loss: 0.0077\n",
      "Epoch 104/200, Iteration 52/250, Loss: 0.0152\n",
      "Epoch 104/200, Iteration 53/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 54/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 55/250, Loss: 0.0102\n",
      "Epoch 104/200, Iteration 56/250, Loss: 0.0378\n",
      "Epoch 104/200, Iteration 57/250, Loss: 0.0112\n",
      "Epoch 104/200, Iteration 58/250, Loss: 0.0192\n",
      "Epoch 104/200, Iteration 59/250, Loss: 0.0163\n",
      "Epoch 104/200, Iteration 60/250, Loss: 0.0061\n",
      "Epoch 104/200, Iteration 61/250, Loss: 0.0063\n",
      "Epoch 104/200, Iteration 62/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 63/250, Loss: 0.0067\n",
      "Epoch 104/200, Iteration 64/250, Loss: 0.0203\n",
      "Epoch 104/200, Iteration 65/250, Loss: 0.0189\n",
      "Epoch 104/200, Iteration 66/250, Loss: 0.0125\n",
      "Epoch 104/200, Iteration 67/250, Loss: 0.0123\n",
      "Epoch 104/200, Iteration 68/250, Loss: 0.0072\n",
      "Epoch 104/200, Iteration 69/250, Loss: 0.0192\n",
      "Epoch 104/200, Iteration 70/250, Loss: 0.0207\n",
      "Epoch 104/200, Iteration 71/250, Loss: 0.0664\n",
      "Epoch 104/200, Iteration 72/250, Loss: 0.0133\n",
      "Epoch 104/200, Iteration 73/250, Loss: 0.0177\n",
      "Epoch 104/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 75/250, Loss: 0.0100\n",
      "Epoch 104/200, Iteration 76/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 77/250, Loss: 0.0221\n",
      "Epoch 104/200, Iteration 78/250, Loss: 0.0123\n",
      "Epoch 104/200, Iteration 79/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 80/250, Loss: 0.0191\n",
      "Epoch 104/200, Iteration 81/250, Loss: 0.0122\n",
      "Epoch 104/200, Iteration 82/250, Loss: 0.0249\n",
      "Epoch 104/200, Iteration 83/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 84/250, Loss: 0.0114\n",
      "Epoch 104/200, Iteration 85/250, Loss: 0.0205\n",
      "Epoch 104/200, Iteration 86/250, Loss: 0.0182\n",
      "Epoch 104/200, Iteration 87/250, Loss: 0.0158\n",
      "Epoch 104/200, Iteration 88/250, Loss: 0.0078\n",
      "Epoch 104/200, Iteration 89/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 90/250, Loss: 0.0091\n",
      "Epoch 104/200, Iteration 91/250, Loss: 0.0210\n",
      "Epoch 104/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 93/250, Loss: 0.0174\n",
      "Epoch 104/200, Iteration 94/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 104/200, Iteration 96/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 104/200, Iteration 98/250, Loss: 0.0109\n",
      "Epoch 104/200, Iteration 99/250, Loss: 0.0309\n",
      "Epoch 104/200, Iteration 100/250, Loss: 0.0193\n",
      "Epoch 104/200, Iteration 101/250, Loss: 0.0187\n",
      "Epoch 104/200, Iteration 102/250, Loss: 0.0211\n",
      "Epoch 104/200, Iteration 103/250, Loss: 0.0243\n",
      "Epoch 104/200, Iteration 104/250, Loss: 0.0130\n",
      "Epoch 104/200, Iteration 105/250, Loss: 0.0116\n",
      "Epoch 104/200, Iteration 106/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 107/250, Loss: 0.0203\n",
      "Epoch 104/200, Iteration 108/250, Loss: 0.0174\n",
      "Epoch 104/200, Iteration 109/250, Loss: 0.0180\n",
      "Epoch 104/200, Iteration 110/250, Loss: 0.0231\n",
      "Epoch 104/200, Iteration 111/250, Loss: 0.0130\n",
      "Epoch 104/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 104/200, Iteration 113/250, Loss: 0.0177\n",
      "Epoch 104/200, Iteration 114/250, Loss: 0.0142\n",
      "Epoch 104/200, Iteration 115/250, Loss: 0.0112\n",
      "Epoch 104/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 104/200, Iteration 117/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 118/250, Loss: 0.0135\n",
      "Epoch 104/200, Iteration 119/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 120/250, Loss: 0.0129\n",
      "Epoch 104/200, Iteration 121/250, Loss: 0.0115\n",
      "Epoch 104/200, Iteration 122/250, Loss: 0.0129\n",
      "Epoch 104/200, Iteration 123/250, Loss: 0.0128\n",
      "Epoch 104/200, Iteration 124/250, Loss: 0.0104\n",
      "Epoch 104/200, Iteration 125/250, Loss: 0.0127\n",
      "Epoch 104/200, Iteration 126/250, Loss: 0.0077\n",
      "Epoch 104/200, Iteration 127/250, Loss: 0.0216\n",
      "Epoch 104/200, Iteration 128/250, Loss: 0.0122\n",
      "Epoch 104/200, Iteration 129/250, Loss: 0.0081\n",
      "Epoch 104/200, Iteration 130/250, Loss: 0.0072\n",
      "Epoch 104/200, Iteration 131/250, Loss: 0.0203\n",
      "Epoch 104/200, Iteration 132/250, Loss: 0.0233\n",
      "Epoch 104/200, Iteration 133/250, Loss: 0.0257\n",
      "Epoch 104/200, Iteration 134/250, Loss: 0.0273\n",
      "Epoch 104/200, Iteration 135/250, Loss: 0.0133\n",
      "Epoch 104/200, Iteration 136/250, Loss: 0.0197\n",
      "Epoch 104/200, Iteration 137/250, Loss: 0.0090\n",
      "Epoch 104/200, Iteration 138/250, Loss: 0.0128\n",
      "Epoch 104/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 140/250, Loss: 0.0114\n",
      "Epoch 104/200, Iteration 141/250, Loss: 0.0264\n",
      "Epoch 104/200, Iteration 142/250, Loss: 0.0116\n",
      "Epoch 104/200, Iteration 143/250, Loss: 0.0207\n",
      "Epoch 104/200, Iteration 144/250, Loss: 0.0112\n",
      "Epoch 104/200, Iteration 145/250, Loss: 0.0228\n",
      "Epoch 104/200, Iteration 146/250, Loss: 0.0129\n",
      "Epoch 104/200, Iteration 147/250, Loss: 0.0136\n",
      "Epoch 104/200, Iteration 148/250, Loss: 0.0136\n",
      "Epoch 104/200, Iteration 149/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 150/250, Loss: 0.0133\n",
      "Epoch 104/200, Iteration 151/250, Loss: 0.0072\n",
      "Epoch 104/200, Iteration 152/250, Loss: 0.0081\n",
      "Epoch 104/200, Iteration 153/250, Loss: 0.0067\n",
      "Epoch 104/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 104/200, Iteration 155/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 156/250, Loss: 0.0161\n",
      "Epoch 104/200, Iteration 157/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 158/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 159/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 160/250, Loss: 0.0165\n",
      "Epoch 104/200, Iteration 161/250, Loss: 0.0141\n",
      "Epoch 104/200, Iteration 162/250, Loss: 0.0175\n",
      "Epoch 104/200, Iteration 163/250, Loss: 0.0267\n",
      "Epoch 104/200, Iteration 164/250, Loss: 0.0101\n",
      "Epoch 104/200, Iteration 165/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 166/250, Loss: 0.0139\n",
      "Epoch 104/200, Iteration 167/250, Loss: 0.0196\n",
      "Epoch 104/200, Iteration 168/250, Loss: 0.0091\n",
      "Epoch 104/200, Iteration 169/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 170/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 171/250, Loss: 0.0190\n",
      "Epoch 104/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 104/200, Iteration 173/250, Loss: 0.0076\n",
      "Epoch 104/200, Iteration 174/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 175/250, Loss: 0.0057\n",
      "Epoch 104/200, Iteration 176/250, Loss: 0.0261\n",
      "Epoch 104/200, Iteration 177/250, Loss: 0.0094\n",
      "Epoch 104/200, Iteration 178/250, Loss: 0.0253\n",
      "Epoch 104/200, Iteration 179/250, Loss: 0.0189\n",
      "Epoch 104/200, Iteration 180/250, Loss: 0.0150\n",
      "Epoch 104/200, Iteration 181/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 182/250, Loss: 0.0185\n",
      "Epoch 104/200, Iteration 183/250, Loss: 0.0066\n",
      "Epoch 104/200, Iteration 184/250, Loss: 0.0065\n",
      "Epoch 104/200, Iteration 185/250, Loss: 0.0185\n",
      "Epoch 104/200, Iteration 186/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 104/200, Iteration 188/250, Loss: 0.0208\n",
      "Epoch 104/200, Iteration 189/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 190/250, Loss: 0.0118\n",
      "Epoch 104/200, Iteration 191/250, Loss: 0.0290\n",
      "Epoch 104/200, Iteration 192/250, Loss: 0.0127\n",
      "Epoch 104/200, Iteration 193/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 194/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 195/250, Loss: 0.0175\n",
      "Epoch 104/200, Iteration 196/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 197/250, Loss: 0.0125\n",
      "Epoch 104/200, Iteration 198/250, Loss: 0.0087\n",
      "Epoch 104/200, Iteration 199/250, Loss: 0.0087\n",
      "Epoch 104/200, Iteration 200/250, Loss: 0.0093\n",
      "Epoch 104/200, Iteration 201/250, Loss: 0.0186\n",
      "Epoch 104/200, Iteration 202/250, Loss: 0.0092\n",
      "Epoch 104/200, Iteration 203/250, Loss: 0.0287\n",
      "Epoch 104/200, Iteration 204/250, Loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200, Iteration 205/250, Loss: 0.0070\n",
      "Epoch 104/200, Iteration 206/250, Loss: 0.0139\n",
      "Epoch 104/200, Iteration 207/250, Loss: 0.0128\n",
      "Epoch 104/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 104/200, Iteration 209/250, Loss: 0.0092\n",
      "Epoch 104/200, Iteration 210/250, Loss: 0.0073\n",
      "Epoch 104/200, Iteration 211/250, Loss: 0.0107\n",
      "Epoch 104/200, Iteration 212/250, Loss: 0.0171\n",
      "Epoch 104/200, Iteration 213/250, Loss: 0.0089\n",
      "Epoch 104/200, Iteration 214/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 215/250, Loss: 0.0153\n",
      "Epoch 104/200, Iteration 216/250, Loss: 0.0102\n",
      "Epoch 104/200, Iteration 217/250, Loss: 0.0257\n",
      "Epoch 104/200, Iteration 218/250, Loss: 0.0159\n",
      "Epoch 104/200, Iteration 219/250, Loss: 0.0197\n",
      "Epoch 104/200, Iteration 220/250, Loss: 0.0104\n",
      "Epoch 104/200, Iteration 221/250, Loss: 0.0108\n",
      "Epoch 104/200, Iteration 222/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 223/250, Loss: 0.0118\n",
      "Epoch 104/200, Iteration 224/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 225/250, Loss: 0.0318\n",
      "Epoch 104/200, Iteration 226/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 227/250, Loss: 0.0208\n",
      "Epoch 104/200, Iteration 228/250, Loss: 0.0158\n",
      "Epoch 104/200, Iteration 229/250, Loss: 0.0115\n",
      "Epoch 104/200, Iteration 230/250, Loss: 0.0081\n",
      "Epoch 104/200, Iteration 231/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 232/250, Loss: 0.0075\n",
      "Epoch 104/200, Iteration 233/250, Loss: 0.0142\n",
      "Epoch 104/200, Iteration 234/250, Loss: 0.0287\n",
      "Epoch 104/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 236/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 237/250, Loss: 0.0091\n",
      "Epoch 104/200, Iteration 238/250, Loss: 0.0098\n",
      "Epoch 104/200, Iteration 239/250, Loss: 0.0185\n",
      "Epoch 104/200, Iteration 240/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 241/250, Loss: 0.0163\n",
      "Epoch 104/200, Iteration 242/250, Loss: 0.0089\n",
      "Epoch 104/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 104/200, Iteration 244/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 245/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 246/250, Loss: 0.0134\n",
      "Epoch 104/200, Iteration 247/250, Loss: 0.0115\n",
      "Epoch 104/200, Iteration 248/250, Loss: 0.0073\n",
      "Epoch 104/200, Iteration 249/250, Loss: 0.0174\n",
      "Epoch 104/200, Iteration 250/250, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 96.45%, Avg loss: 0.005901, MRE: 0.645398 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005865, MRE: 1.052286 \n",
      "\n",
      "Epoch 105/200, Iteration 1/250, Loss: 0.0223\n",
      "Epoch 105/200, Iteration 2/250, Loss: 0.0081\n",
      "Epoch 105/200, Iteration 3/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 105/200, Iteration 5/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 6/250, Loss: 0.0110\n",
      "Epoch 105/200, Iteration 7/250, Loss: 0.0389\n",
      "Epoch 105/200, Iteration 8/250, Loss: 0.0112\n",
      "Epoch 105/200, Iteration 9/250, Loss: 0.0157\n",
      "Epoch 105/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 105/200, Iteration 11/250, Loss: 0.0160\n",
      "Epoch 105/200, Iteration 12/250, Loss: 0.0462\n",
      "Epoch 105/200, Iteration 13/250, Loss: 0.0081\n",
      "Epoch 105/200, Iteration 14/250, Loss: 0.0180\n",
      "Epoch 105/200, Iteration 15/250, Loss: 0.0166\n",
      "Epoch 105/200, Iteration 16/250, Loss: 0.0152\n",
      "Epoch 105/200, Iteration 17/250, Loss: 0.0186\n",
      "Epoch 105/200, Iteration 18/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 19/250, Loss: 0.0139\n",
      "Epoch 105/200, Iteration 20/250, Loss: 0.0210\n",
      "Epoch 105/200, Iteration 21/250, Loss: 0.0148\n",
      "Epoch 105/200, Iteration 22/250, Loss: 0.0100\n",
      "Epoch 105/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 105/200, Iteration 24/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 25/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 26/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 27/250, Loss: 0.0098\n",
      "Epoch 105/200, Iteration 28/250, Loss: 0.0069\n",
      "Epoch 105/200, Iteration 29/250, Loss: 0.0090\n",
      "Epoch 105/200, Iteration 30/250, Loss: 0.0073\n",
      "Epoch 105/200, Iteration 31/250, Loss: 0.0117\n",
      "Epoch 105/200, Iteration 32/250, Loss: 0.0232\n",
      "Epoch 105/200, Iteration 33/250, Loss: 0.0066\n",
      "Epoch 105/200, Iteration 34/250, Loss: 0.0115\n",
      "Epoch 105/200, Iteration 35/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 36/250, Loss: 0.0155\n",
      "Epoch 105/200, Iteration 37/250, Loss: 0.0224\n",
      "Epoch 105/200, Iteration 38/250, Loss: 0.0342\n",
      "Epoch 105/200, Iteration 39/250, Loss: 0.0150\n",
      "Epoch 105/200, Iteration 40/250, Loss: 0.0299\n",
      "Epoch 105/200, Iteration 41/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 42/250, Loss: 0.0064\n",
      "Epoch 105/200, Iteration 43/250, Loss: 0.0169\n",
      "Epoch 105/200, Iteration 44/250, Loss: 0.0121\n",
      "Epoch 105/200, Iteration 45/250, Loss: 0.0175\n",
      "Epoch 105/200, Iteration 46/250, Loss: 0.0115\n",
      "Epoch 105/200, Iteration 47/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 48/250, Loss: 0.0218\n",
      "Epoch 105/200, Iteration 49/250, Loss: 0.0145\n",
      "Epoch 105/200, Iteration 50/250, Loss: 0.0429\n",
      "Epoch 105/200, Iteration 51/250, Loss: 0.0158\n",
      "Epoch 105/200, Iteration 52/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 105/200, Iteration 54/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 55/250, Loss: 0.0091\n",
      "Epoch 105/200, Iteration 56/250, Loss: 0.0159\n",
      "Epoch 105/200, Iteration 57/250, Loss: 0.0191\n",
      "Epoch 105/200, Iteration 58/250, Loss: 0.0190\n",
      "Epoch 105/200, Iteration 59/250, Loss: 0.0176\n",
      "Epoch 105/200, Iteration 60/250, Loss: 0.0131\n",
      "Epoch 105/200, Iteration 61/250, Loss: 0.0183\n",
      "Epoch 105/200, Iteration 62/250, Loss: 0.0115\n",
      "Epoch 105/200, Iteration 63/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 64/250, Loss: 0.0118\n",
      "Epoch 105/200, Iteration 65/250, Loss: 0.0162\n",
      "Epoch 105/200, Iteration 66/250, Loss: 0.0143\n",
      "Epoch 105/200, Iteration 67/250, Loss: 0.0146\n",
      "Epoch 105/200, Iteration 68/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 69/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 70/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 71/250, Loss: 0.0084\n",
      "Epoch 105/200, Iteration 72/250, Loss: 0.0084\n",
      "Epoch 105/200, Iteration 73/250, Loss: 0.0059\n",
      "Epoch 105/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 105/200, Iteration 75/250, Loss: 0.0381\n",
      "Epoch 105/200, Iteration 76/250, Loss: 0.0066\n",
      "Epoch 105/200, Iteration 77/250, Loss: 0.0129\n",
      "Epoch 105/200, Iteration 78/250, Loss: 0.0327\n",
      "Epoch 105/200, Iteration 79/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 80/250, Loss: 0.0120\n",
      "Epoch 105/200, Iteration 81/250, Loss: 0.0164\n",
      "Epoch 105/200, Iteration 82/250, Loss: 0.0168\n",
      "Epoch 105/200, Iteration 83/250, Loss: 0.0183\n",
      "Epoch 105/200, Iteration 84/250, Loss: 0.0111\n",
      "Epoch 105/200, Iteration 85/250, Loss: 0.0074\n",
      "Epoch 105/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 87/250, Loss: 0.0147\n",
      "Epoch 105/200, Iteration 88/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 89/250, Loss: 0.0074\n",
      "Epoch 105/200, Iteration 90/250, Loss: 0.0152\n",
      "Epoch 105/200, Iteration 91/250, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 92/250, Loss: 0.0107\n",
      "Epoch 105/200, Iteration 93/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 94/250, Loss: 0.0070\n",
      "Epoch 105/200, Iteration 95/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 96/250, Loss: 0.0259\n",
      "Epoch 105/200, Iteration 97/250, Loss: 0.0185\n",
      "Epoch 105/200, Iteration 98/250, Loss: 0.0125\n",
      "Epoch 105/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 105/200, Iteration 100/250, Loss: 0.0198\n",
      "Epoch 105/200, Iteration 101/250, Loss: 0.0119\n",
      "Epoch 105/200, Iteration 102/250, Loss: 0.0127\n",
      "Epoch 105/200, Iteration 103/250, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 104/250, Loss: 0.0117\n",
      "Epoch 105/200, Iteration 105/250, Loss: 0.0128\n",
      "Epoch 105/200, Iteration 106/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 107/250, Loss: 0.0129\n",
      "Epoch 105/200, Iteration 108/250, Loss: 0.0146\n",
      "Epoch 105/200, Iteration 109/250, Loss: 0.0096\n",
      "Epoch 105/200, Iteration 110/250, Loss: 0.0231\n",
      "Epoch 105/200, Iteration 111/250, Loss: 0.0135\n",
      "Epoch 105/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 105/200, Iteration 113/250, Loss: 0.0128\n",
      "Epoch 105/200, Iteration 114/250, Loss: 0.0068\n",
      "Epoch 105/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 105/200, Iteration 116/250, Loss: 0.0171\n",
      "Epoch 105/200, Iteration 117/250, Loss: 0.0246\n",
      "Epoch 105/200, Iteration 118/250, Loss: 0.0171\n",
      "Epoch 105/200, Iteration 119/250, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 105/200, Iteration 121/250, Loss: 0.0246\n",
      "Epoch 105/200, Iteration 122/250, Loss: 0.0118\n",
      "Epoch 105/200, Iteration 123/250, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 124/250, Loss: 0.0194\n",
      "Epoch 105/200, Iteration 125/250, Loss: 0.0140\n",
      "Epoch 105/200, Iteration 126/250, Loss: 0.0235\n",
      "Epoch 105/200, Iteration 127/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 128/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 130/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 131/250, Loss: 0.0114\n",
      "Epoch 105/200, Iteration 132/250, Loss: 0.0074\n",
      "Epoch 105/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 105/200, Iteration 134/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 135/250, Loss: 0.0068\n",
      "Epoch 105/200, Iteration 136/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 137/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 105/200, Iteration 139/250, Loss: 0.0119\n",
      "Epoch 105/200, Iteration 140/250, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 141/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 142/250, Loss: 0.0165\n",
      "Epoch 105/200, Iteration 143/250, Loss: 0.0117\n",
      "Epoch 105/200, Iteration 144/250, Loss: 0.0180\n",
      "Epoch 105/200, Iteration 145/250, Loss: 0.0192\n",
      "Epoch 105/200, Iteration 146/250, Loss: 0.0288\n",
      "Epoch 105/200, Iteration 147/250, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 148/250, Loss: 0.0240\n",
      "Epoch 105/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 150/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 151/250, Loss: 0.0139\n",
      "Epoch 105/200, Iteration 152/250, Loss: 0.0248\n",
      "Epoch 105/200, Iteration 153/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 105/200, Iteration 155/250, Loss: 0.0170\n",
      "Epoch 105/200, Iteration 156/250, Loss: 0.0179\n",
      "Epoch 105/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 158/250, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200, Iteration 159/250, Loss: 0.0218\n",
      "Epoch 105/200, Iteration 160/250, Loss: 0.0076\n",
      "Epoch 105/200, Iteration 161/250, Loss: 0.0234\n",
      "Epoch 105/200, Iteration 162/250, Loss: 0.0074\n",
      "Epoch 105/200, Iteration 163/250, Loss: 0.0135\n",
      "Epoch 105/200, Iteration 164/250, Loss: 0.0122\n",
      "Epoch 105/200, Iteration 165/250, Loss: 0.0147\n",
      "Epoch 105/200, Iteration 166/250, Loss: 0.0124\n",
      "Epoch 105/200, Iteration 167/250, Loss: 0.0124\n",
      "Epoch 105/200, Iteration 168/250, Loss: 0.0062\n",
      "Epoch 105/200, Iteration 169/250, Loss: 0.0221\n",
      "Epoch 105/200, Iteration 170/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 171/250, Loss: 0.0133\n",
      "Epoch 105/200, Iteration 172/250, Loss: 0.0142\n",
      "Epoch 105/200, Iteration 173/250, Loss: 0.0263\n",
      "Epoch 105/200, Iteration 174/250, Loss: 0.0146\n",
      "Epoch 105/200, Iteration 175/250, Loss: 0.0201\n",
      "Epoch 105/200, Iteration 176/250, Loss: 0.0157\n",
      "Epoch 105/200, Iteration 177/250, Loss: 0.0098\n",
      "Epoch 105/200, Iteration 178/250, Loss: 0.0329\n",
      "Epoch 105/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 180/250, Loss: 0.0165\n",
      "Epoch 105/200, Iteration 181/250, Loss: 0.0091\n",
      "Epoch 105/200, Iteration 182/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 183/250, Loss: 0.0126\n",
      "Epoch 105/200, Iteration 184/250, Loss: 0.0257\n",
      "Epoch 105/200, Iteration 185/250, Loss: 0.0075\n",
      "Epoch 105/200, Iteration 186/250, Loss: 0.0484\n",
      "Epoch 105/200, Iteration 187/250, Loss: 0.0175\n",
      "Epoch 105/200, Iteration 188/250, Loss: 0.0123\n",
      "Epoch 105/200, Iteration 189/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 190/250, Loss: 0.0112\n",
      "Epoch 105/200, Iteration 191/250, Loss: 0.0188\n",
      "Epoch 105/200, Iteration 192/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 193/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 195/250, Loss: 0.0109\n",
      "Epoch 105/200, Iteration 196/250, Loss: 0.0084\n",
      "Epoch 105/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 198/250, Loss: 0.0105\n",
      "Epoch 105/200, Iteration 199/250, Loss: 0.0169\n",
      "Epoch 105/200, Iteration 200/250, Loss: 0.0298\n",
      "Epoch 105/200, Iteration 201/250, Loss: 0.0184\n",
      "Epoch 105/200, Iteration 202/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 203/250, Loss: 0.0112\n",
      "Epoch 105/200, Iteration 204/250, Loss: 0.0192\n",
      "Epoch 105/200, Iteration 205/250, Loss: 0.0126\n",
      "Epoch 105/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 207/250, Loss: 0.0158\n",
      "Epoch 105/200, Iteration 208/250, Loss: 0.0082\n",
      "Epoch 105/200, Iteration 209/250, Loss: 0.0100\n",
      "Epoch 105/200, Iteration 210/250, Loss: 0.0362\n",
      "Epoch 105/200, Iteration 211/250, Loss: 0.0097\n",
      "Epoch 105/200, Iteration 212/250, Loss: 0.0115\n",
      "Epoch 105/200, Iteration 213/250, Loss: 0.0125\n",
      "Epoch 105/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 105/200, Iteration 215/250, Loss: 0.0089\n",
      "Epoch 105/200, Iteration 216/250, Loss: 0.0272\n",
      "Epoch 105/200, Iteration 217/250, Loss: 0.0068\n",
      "Epoch 105/200, Iteration 218/250, Loss: 0.0193\n",
      "Epoch 105/200, Iteration 219/250, Loss: 0.0176\n",
      "Epoch 105/200, Iteration 220/250, Loss: 0.0174\n",
      "Epoch 105/200, Iteration 221/250, Loss: 0.0122\n",
      "Epoch 105/200, Iteration 222/250, Loss: 0.0135\n",
      "Epoch 105/200, Iteration 223/250, Loss: 0.0145\n",
      "Epoch 105/200, Iteration 224/250, Loss: 0.0203\n",
      "Epoch 105/200, Iteration 225/250, Loss: 0.0134\n",
      "Epoch 105/200, Iteration 226/250, Loss: 0.0106\n",
      "Epoch 105/200, Iteration 227/250, Loss: 0.0100\n",
      "Epoch 105/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 105/200, Iteration 229/250, Loss: 0.0234\n",
      "Epoch 105/200, Iteration 230/250, Loss: 0.0147\n",
      "Epoch 105/200, Iteration 231/250, Loss: 0.0071\n",
      "Epoch 105/200, Iteration 232/250, Loss: 0.0154\n",
      "Epoch 105/200, Iteration 233/250, Loss: 0.0067\n",
      "Epoch 105/200, Iteration 234/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 235/250, Loss: 0.0125\n",
      "Epoch 105/200, Iteration 236/250, Loss: 0.0212\n",
      "Epoch 105/200, Iteration 237/250, Loss: 0.0175\n",
      "Epoch 105/200, Iteration 238/250, Loss: 0.0106\n",
      "Epoch 105/200, Iteration 239/250, Loss: 0.0128\n",
      "Epoch 105/200, Iteration 240/250, Loss: 0.0057\n",
      "Epoch 105/200, Iteration 241/250, Loss: 0.0157\n",
      "Epoch 105/200, Iteration 242/250, Loss: 0.0187\n",
      "Epoch 105/200, Iteration 243/250, Loss: 0.0083\n",
      "Epoch 105/200, Iteration 244/250, Loss: 0.0130\n",
      "Epoch 105/200, Iteration 245/250, Loss: 0.0261\n",
      "Epoch 105/200, Iteration 246/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 247/250, Loss: 0.0273\n",
      "Epoch 105/200, Iteration 248/250, Loss: 0.0303\n",
      "Epoch 105/200, Iteration 249/250, Loss: 0.0074\n",
      "Epoch 105/200, Iteration 250/250, Loss: 0.0195\n",
      "Train Error: \n",
      " Accuracy: 93.46%, Avg loss: 0.006001, MRE: 0.616003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.006059, MRE: 0.971970 \n",
      "\n",
      "Epoch 106/200, Iteration 1/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 2/250, Loss: 0.0261\n",
      "Epoch 106/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 106/200, Iteration 4/250, Loss: 0.0100\n",
      "Epoch 106/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 6/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 7/250, Loss: 0.0166\n",
      "Epoch 106/200, Iteration 8/250, Loss: 0.0070\n",
      "Epoch 106/200, Iteration 9/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 10/250, Loss: 0.0251\n",
      "Epoch 106/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 12/250, Loss: 0.0125\n",
      "Epoch 106/200, Iteration 13/250, Loss: 0.0176\n",
      "Epoch 106/200, Iteration 14/250, Loss: 0.0200\n",
      "Epoch 106/200, Iteration 15/250, Loss: 0.0172\n",
      "Epoch 106/200, Iteration 16/250, Loss: 0.0192\n",
      "Epoch 106/200, Iteration 17/250, Loss: 0.0158\n",
      "Epoch 106/200, Iteration 18/250, Loss: 0.0155\n",
      "Epoch 106/200, Iteration 19/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 20/250, Loss: 0.0167\n",
      "Epoch 106/200, Iteration 21/250, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 22/250, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 23/250, Loss: 0.0135\n",
      "Epoch 106/200, Iteration 24/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 25/250, Loss: 0.0232\n",
      "Epoch 106/200, Iteration 26/250, Loss: 0.0296\n",
      "Epoch 106/200, Iteration 27/250, Loss: 0.0224\n",
      "Epoch 106/200, Iteration 28/250, Loss: 0.0104\n",
      "Epoch 106/200, Iteration 29/250, Loss: 0.0280\n",
      "Epoch 106/200, Iteration 30/250, Loss: 0.0076\n",
      "Epoch 106/200, Iteration 31/250, Loss: 0.0214\n",
      "Epoch 106/200, Iteration 32/250, Loss: 0.0184\n",
      "Epoch 106/200, Iteration 33/250, Loss: 0.0149\n",
      "Epoch 106/200, Iteration 34/250, Loss: 0.0125\n",
      "Epoch 106/200, Iteration 35/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 36/250, Loss: 0.0141\n",
      "Epoch 106/200, Iteration 37/250, Loss: 0.0145\n",
      "Epoch 106/200, Iteration 38/250, Loss: 0.0290\n",
      "Epoch 106/200, Iteration 39/250, Loss: 0.0055\n",
      "Epoch 106/200, Iteration 40/250, Loss: 0.0093\n",
      "Epoch 106/200, Iteration 41/250, Loss: 0.0137\n",
      "Epoch 106/200, Iteration 42/250, Loss: 0.0159\n",
      "Epoch 106/200, Iteration 43/250, Loss: 0.0087\n",
      "Epoch 106/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 106/200, Iteration 46/250, Loss: 0.0374\n",
      "Epoch 106/200, Iteration 47/250, Loss: 0.0149\n",
      "Epoch 106/200, Iteration 48/250, Loss: 0.0171\n",
      "Epoch 106/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 106/200, Iteration 50/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 51/250, Loss: 0.0229\n",
      "Epoch 106/200, Iteration 52/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 53/250, Loss: 0.0233\n",
      "Epoch 106/200, Iteration 54/250, Loss: 0.0264\n",
      "Epoch 106/200, Iteration 55/250, Loss: 0.0059\n",
      "Epoch 106/200, Iteration 56/250, Loss: 0.0060\n",
      "Epoch 106/200, Iteration 57/250, Loss: 0.0100\n",
      "Epoch 106/200, Iteration 58/250, Loss: 0.0111\n",
      "Epoch 106/200, Iteration 59/250, Loss: 0.0233\n",
      "Epoch 106/200, Iteration 60/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 61/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 62/250, Loss: 0.0088\n",
      "Epoch 106/200, Iteration 63/250, Loss: 0.0116\n",
      "Epoch 106/200, Iteration 64/250, Loss: 0.0284\n",
      "Epoch 106/200, Iteration 65/250, Loss: 0.0216\n",
      "Epoch 106/200, Iteration 66/250, Loss: 0.0079\n",
      "Epoch 106/200, Iteration 67/250, Loss: 0.0086\n",
      "Epoch 106/200, Iteration 68/250, Loss: 0.0069\n",
      "Epoch 106/200, Iteration 69/250, Loss: 0.0092\n",
      "Epoch 106/200, Iteration 70/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 71/250, Loss: 0.0180\n",
      "Epoch 106/200, Iteration 72/250, Loss: 0.0163\n",
      "Epoch 106/200, Iteration 73/250, Loss: 0.0128\n",
      "Epoch 106/200, Iteration 74/250, Loss: 0.0214\n",
      "Epoch 106/200, Iteration 75/250, Loss: 0.0092\n",
      "Epoch 106/200, Iteration 76/250, Loss: 0.0119\n",
      "Epoch 106/200, Iteration 77/250, Loss: 0.0221\n",
      "Epoch 106/200, Iteration 78/250, Loss: 0.0173\n",
      "Epoch 106/200, Iteration 79/250, Loss: 0.0157\n",
      "Epoch 106/200, Iteration 80/250, Loss: 0.0086\n",
      "Epoch 106/200, Iteration 81/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 82/250, Loss: 0.0112\n",
      "Epoch 106/200, Iteration 83/250, Loss: 0.0188\n",
      "Epoch 106/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 106/200, Iteration 85/250, Loss: 0.0168\n",
      "Epoch 106/200, Iteration 86/250, Loss: 0.0121\n",
      "Epoch 106/200, Iteration 87/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 88/250, Loss: 0.0323\n",
      "Epoch 106/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 106/200, Iteration 90/250, Loss: 0.0153\n",
      "Epoch 106/200, Iteration 91/250, Loss: 0.0257\n",
      "Epoch 106/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 106/200, Iteration 93/250, Loss: 0.0146\n",
      "Epoch 106/200, Iteration 94/250, Loss: 0.0196\n",
      "Epoch 106/200, Iteration 95/250, Loss: 0.0089\n",
      "Epoch 106/200, Iteration 96/250, Loss: 0.0120\n",
      "Epoch 106/200, Iteration 97/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 98/250, Loss: 0.0261\n",
      "Epoch 106/200, Iteration 99/250, Loss: 0.0202\n",
      "Epoch 106/200, Iteration 100/250, Loss: 0.0311\n",
      "Epoch 106/200, Iteration 101/250, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 102/250, Loss: 0.0192\n",
      "Epoch 106/200, Iteration 103/250, Loss: 0.0237\n",
      "Epoch 106/200, Iteration 104/250, Loss: 0.0123\n",
      "Epoch 106/200, Iteration 105/250, Loss: 0.0119\n",
      "Epoch 106/200, Iteration 106/250, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 107/250, Loss: 0.0172\n",
      "Epoch 106/200, Iteration 108/250, Loss: 0.0132\n",
      "Epoch 106/200, Iteration 109/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 110/250, Loss: 0.0125\n",
      "Epoch 106/200, Iteration 111/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 113/250, Loss: 0.0348\n",
      "Epoch 106/200, Iteration 114/250, Loss: 0.0140\n",
      "Epoch 106/200, Iteration 115/250, Loss: 0.0125\n",
      "Epoch 106/200, Iteration 116/250, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200, Iteration 117/250, Loss: 0.0271\n",
      "Epoch 106/200, Iteration 118/250, Loss: 0.0275\n",
      "Epoch 106/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 106/200, Iteration 120/250, Loss: 0.0161\n",
      "Epoch 106/200, Iteration 121/250, Loss: 0.0235\n",
      "Epoch 106/200, Iteration 122/250, Loss: 0.0074\n",
      "Epoch 106/200, Iteration 123/250, Loss: 0.0241\n",
      "Epoch 106/200, Iteration 124/250, Loss: 0.0056\n",
      "Epoch 106/200, Iteration 125/250, Loss: 0.0080\n",
      "Epoch 106/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 106/200, Iteration 127/250, Loss: 0.0067\n",
      "Epoch 106/200, Iteration 128/250, Loss: 0.0106\n",
      "Epoch 106/200, Iteration 129/250, Loss: 0.0356\n",
      "Epoch 106/200, Iteration 130/250, Loss: 0.0103\n",
      "Epoch 106/200, Iteration 131/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 132/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 133/250, Loss: 0.0077\n",
      "Epoch 106/200, Iteration 134/250, Loss: 0.0343\n",
      "Epoch 106/200, Iteration 135/250, Loss: 0.0301\n",
      "Epoch 106/200, Iteration 136/250, Loss: 0.0329\n",
      "Epoch 106/200, Iteration 137/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 138/250, Loss: 0.0274\n",
      "Epoch 106/200, Iteration 139/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 140/250, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 141/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 142/250, Loss: 0.0072\n",
      "Epoch 106/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 144/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 145/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 146/250, Loss: 0.0222\n",
      "Epoch 106/200, Iteration 147/250, Loss: 0.0337\n",
      "Epoch 106/200, Iteration 148/250, Loss: 0.0267\n",
      "Epoch 106/200, Iteration 149/250, Loss: 0.0187\n",
      "Epoch 106/200, Iteration 150/250, Loss: 0.0318\n",
      "Epoch 106/200, Iteration 151/250, Loss: 0.0171\n",
      "Epoch 106/200, Iteration 152/250, Loss: 0.0191\n",
      "Epoch 106/200, Iteration 153/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 154/250, Loss: 0.0093\n",
      "Epoch 106/200, Iteration 155/250, Loss: 0.0250\n",
      "Epoch 106/200, Iteration 156/250, Loss: 0.0192\n",
      "Epoch 106/200, Iteration 157/250, Loss: 0.0154\n",
      "Epoch 106/200, Iteration 158/250, Loss: 0.0171\n",
      "Epoch 106/200, Iteration 159/250, Loss: 0.0087\n",
      "Epoch 106/200, Iteration 160/250, Loss: 0.0285\n",
      "Epoch 106/200, Iteration 161/250, Loss: 0.0203\n",
      "Epoch 106/200, Iteration 162/250, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 163/250, Loss: 0.0230\n",
      "Epoch 106/200, Iteration 164/250, Loss: 0.0070\n",
      "Epoch 106/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 166/250, Loss: 0.0276\n",
      "Epoch 106/200, Iteration 167/250, Loss: 0.0115\n",
      "Epoch 106/200, Iteration 168/250, Loss: 0.0309\n",
      "Epoch 106/200, Iteration 169/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 170/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 171/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 172/250, Loss: 0.0110\n",
      "Epoch 106/200, Iteration 173/250, Loss: 0.0176\n",
      "Epoch 106/200, Iteration 174/250, Loss: 0.0115\n",
      "Epoch 106/200, Iteration 175/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 176/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 177/250, Loss: 0.0125\n",
      "Epoch 106/200, Iteration 178/250, Loss: 0.0230\n",
      "Epoch 106/200, Iteration 179/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 180/250, Loss: 0.0351\n",
      "Epoch 106/200, Iteration 181/250, Loss: 0.0079\n",
      "Epoch 106/200, Iteration 182/250, Loss: 0.0113\n",
      "Epoch 106/200, Iteration 183/250, Loss: 0.0069\n",
      "Epoch 106/200, Iteration 184/250, Loss: 0.0077\n",
      "Epoch 106/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 106/200, Iteration 186/250, Loss: 0.0136\n",
      "Epoch 106/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 106/200, Iteration 188/250, Loss: 0.0188\n",
      "Epoch 106/200, Iteration 189/250, Loss: 0.0198\n",
      "Epoch 106/200, Iteration 190/250, Loss: 0.0066\n",
      "Epoch 106/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 106/200, Iteration 192/250, Loss: 0.0263\n",
      "Epoch 106/200, Iteration 193/250, Loss: 0.0148\n",
      "Epoch 106/200, Iteration 194/250, Loss: 0.0065\n",
      "Epoch 106/200, Iteration 195/250, Loss: 0.0163\n",
      "Epoch 106/200, Iteration 196/250, Loss: 0.0254\n",
      "Epoch 106/200, Iteration 197/250, Loss: 0.0159\n",
      "Epoch 106/200, Iteration 198/250, Loss: 0.0189\n",
      "Epoch 106/200, Iteration 199/250, Loss: 0.0194\n",
      "Epoch 106/200, Iteration 200/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 201/250, Loss: 0.0288\n",
      "Epoch 106/200, Iteration 202/250, Loss: 0.0076\n",
      "Epoch 106/200, Iteration 203/250, Loss: 0.0145\n",
      "Epoch 106/200, Iteration 204/250, Loss: 0.0151\n",
      "Epoch 106/200, Iteration 205/250, Loss: 0.0200\n",
      "Epoch 106/200, Iteration 206/250, Loss: 0.0180\n",
      "Epoch 106/200, Iteration 207/250, Loss: 0.0153\n",
      "Epoch 106/200, Iteration 208/250, Loss: 0.0139\n",
      "Epoch 106/200, Iteration 209/250, Loss: 0.0156\n",
      "Epoch 106/200, Iteration 210/250, Loss: 0.0088\n",
      "Epoch 106/200, Iteration 211/250, Loss: 0.0175\n",
      "Epoch 106/200, Iteration 212/250, Loss: 0.0206\n",
      "Epoch 106/200, Iteration 213/250, Loss: 0.0171\n",
      "Epoch 106/200, Iteration 214/250, Loss: 0.0177\n",
      "Epoch 106/200, Iteration 215/250, Loss: 0.0222\n",
      "Epoch 106/200, Iteration 216/250, Loss: 0.0219\n",
      "Epoch 106/200, Iteration 217/250, Loss: 0.0118\n",
      "Epoch 106/200, Iteration 218/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 219/250, Loss: 0.0096\n",
      "Epoch 106/200, Iteration 220/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 221/250, Loss: 0.0178\n",
      "Epoch 106/200, Iteration 222/250, Loss: 0.0115\n",
      "Epoch 106/200, Iteration 223/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 224/250, Loss: 0.0189\n",
      "Epoch 106/200, Iteration 225/250, Loss: 0.0130\n",
      "Epoch 106/200, Iteration 226/250, Loss: 0.0087\n",
      "Epoch 106/200, Iteration 227/250, Loss: 0.0424\n",
      "Epoch 106/200, Iteration 228/250, Loss: 0.0156\n",
      "Epoch 106/200, Iteration 229/250, Loss: 0.0077\n",
      "Epoch 106/200, Iteration 230/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 231/250, Loss: 0.0109\n",
      "Epoch 106/200, Iteration 232/250, Loss: 0.0080\n",
      "Epoch 106/200, Iteration 233/250, Loss: 0.0090\n",
      "Epoch 106/200, Iteration 234/250, Loss: 0.0145\n",
      "Epoch 106/200, Iteration 235/250, Loss: 0.0074\n",
      "Epoch 106/200, Iteration 236/250, Loss: 0.0100\n",
      "Epoch 106/200, Iteration 237/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 238/250, Loss: 0.0155\n",
      "Epoch 106/200, Iteration 239/250, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 240/250, Loss: 0.0275\n",
      "Epoch 106/200, Iteration 241/250, Loss: 0.0331\n",
      "Epoch 106/200, Iteration 242/250, Loss: 0.0162\n",
      "Epoch 106/200, Iteration 243/250, Loss: 0.0379\n",
      "Epoch 106/200, Iteration 244/250, Loss: 0.0160\n",
      "Epoch 106/200, Iteration 245/250, Loss: 0.0112\n",
      "Epoch 106/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 106/200, Iteration 247/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 248/250, Loss: 0.0139\n",
      "Epoch 106/200, Iteration 249/250, Loss: 0.0133\n",
      "Epoch 106/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 98.11%, Avg loss: 0.007235, MRE: 0.695247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.007173, MRE: 1.210045 \n",
      "\n",
      "Epoch 107/200, Iteration 1/250, Loss: 0.0131\n",
      "Epoch 107/200, Iteration 2/250, Loss: 0.0186\n",
      "Epoch 107/200, Iteration 3/250, Loss: 0.0092\n",
      "Epoch 107/200, Iteration 4/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 5/250, Loss: 0.0056\n",
      "Epoch 107/200, Iteration 6/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 7/250, Loss: 0.0074\n",
      "Epoch 107/200, Iteration 8/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 9/250, Loss: 0.0323\n",
      "Epoch 107/200, Iteration 10/250, Loss: 0.0081\n",
      "Epoch 107/200, Iteration 11/250, Loss: 0.0186\n",
      "Epoch 107/200, Iteration 12/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 13/250, Loss: 0.0091\n",
      "Epoch 107/200, Iteration 14/250, Loss: 0.0126\n",
      "Epoch 107/200, Iteration 15/250, Loss: 0.0242\n",
      "Epoch 107/200, Iteration 16/250, Loss: 0.0097\n",
      "Epoch 107/200, Iteration 17/250, Loss: 0.0096\n",
      "Epoch 107/200, Iteration 18/250, Loss: 0.0086\n",
      "Epoch 107/200, Iteration 19/250, Loss: 0.0204\n",
      "Epoch 107/200, Iteration 20/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 21/250, Loss: 0.0288\n",
      "Epoch 107/200, Iteration 22/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 23/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 24/250, Loss: 0.0299\n",
      "Epoch 107/200, Iteration 25/250, Loss: 0.0084\n",
      "Epoch 107/200, Iteration 26/250, Loss: 0.0165\n",
      "Epoch 107/200, Iteration 27/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 28/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 29/250, Loss: 0.0124\n",
      "Epoch 107/200, Iteration 30/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 31/250, Loss: 0.0052\n",
      "Epoch 107/200, Iteration 32/250, Loss: 0.0138\n",
      "Epoch 107/200, Iteration 33/250, Loss: 0.0130\n",
      "Epoch 107/200, Iteration 34/250, Loss: 0.0466\n",
      "Epoch 107/200, Iteration 35/250, Loss: 0.0146\n",
      "Epoch 107/200, Iteration 36/250, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 37/250, Loss: 0.0171\n",
      "Epoch 107/200, Iteration 38/250, Loss: 0.0154\n",
      "Epoch 107/200, Iteration 39/250, Loss: 0.0160\n",
      "Epoch 107/200, Iteration 40/250, Loss: 0.0084\n",
      "Epoch 107/200, Iteration 41/250, Loss: 0.0272\n",
      "Epoch 107/200, Iteration 42/250, Loss: 0.0245\n",
      "Epoch 107/200, Iteration 43/250, Loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200, Iteration 44/250, Loss: 0.0087\n",
      "Epoch 107/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 107/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 47/250, Loss: 0.0221\n",
      "Epoch 107/200, Iteration 48/250, Loss: 0.0230\n",
      "Epoch 107/200, Iteration 49/250, Loss: 0.0119\n",
      "Epoch 107/200, Iteration 50/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 51/250, Loss: 0.0143\n",
      "Epoch 107/200, Iteration 52/250, Loss: 0.0107\n",
      "Epoch 107/200, Iteration 53/250, Loss: 0.0074\n",
      "Epoch 107/200, Iteration 54/250, Loss: 0.0063\n",
      "Epoch 107/200, Iteration 55/250, Loss: 0.0063\n",
      "Epoch 107/200, Iteration 56/250, Loss: 0.0251\n",
      "Epoch 107/200, Iteration 57/250, Loss: 0.0150\n",
      "Epoch 107/200, Iteration 58/250, Loss: 0.0078\n",
      "Epoch 107/200, Iteration 59/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 60/250, Loss: 0.0169\n",
      "Epoch 107/200, Iteration 61/250, Loss: 0.0170\n",
      "Epoch 107/200, Iteration 62/250, Loss: 0.0092\n",
      "Epoch 107/200, Iteration 63/250, Loss: 0.0229\n",
      "Epoch 107/200, Iteration 64/250, Loss: 0.0095\n",
      "Epoch 107/200, Iteration 65/250, Loss: 0.0081\n",
      "Epoch 107/200, Iteration 66/250, Loss: 0.0252\n",
      "Epoch 107/200, Iteration 67/250, Loss: 0.0086\n",
      "Epoch 107/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 107/200, Iteration 69/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 107/200, Iteration 71/250, Loss: 0.0166\n",
      "Epoch 107/200, Iteration 72/250, Loss: 0.0303\n",
      "Epoch 107/200, Iteration 73/250, Loss: 0.0119\n",
      "Epoch 107/200, Iteration 74/250, Loss: 0.0275\n",
      "Epoch 107/200, Iteration 75/250, Loss: 0.0247\n",
      "Epoch 107/200, Iteration 76/250, Loss: 0.0202\n",
      "Epoch 107/200, Iteration 77/250, Loss: 0.0277\n",
      "Epoch 107/200, Iteration 78/250, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 79/250, Loss: 0.0288\n",
      "Epoch 107/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 107/200, Iteration 81/250, Loss: 0.0237\n",
      "Epoch 107/200, Iteration 82/250, Loss: 0.0191\n",
      "Epoch 107/200, Iteration 83/250, Loss: 0.0141\n",
      "Epoch 107/200, Iteration 84/250, Loss: 0.0200\n",
      "Epoch 107/200, Iteration 85/250, Loss: 0.0213\n",
      "Epoch 107/200, Iteration 86/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 87/250, Loss: 0.0105\n",
      "Epoch 107/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 89/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 90/250, Loss: 0.0074\n",
      "Epoch 107/200, Iteration 91/250, Loss: 0.0115\n",
      "Epoch 107/200, Iteration 92/250, Loss: 0.0119\n",
      "Epoch 107/200, Iteration 93/250, Loss: 0.0180\n",
      "Epoch 107/200, Iteration 94/250, Loss: 0.0234\n",
      "Epoch 107/200, Iteration 95/250, Loss: 0.0220\n",
      "Epoch 107/200, Iteration 96/250, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 97/250, Loss: 0.0268\n",
      "Epoch 107/200, Iteration 98/250, Loss: 0.0086\n",
      "Epoch 107/200, Iteration 99/250, Loss: 0.0166\n",
      "Epoch 107/200, Iteration 100/250, Loss: 0.0095\n",
      "Epoch 107/200, Iteration 101/250, Loss: 0.0270\n",
      "Epoch 107/200, Iteration 102/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 103/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 104/250, Loss: 0.0176\n",
      "Epoch 107/200, Iteration 105/250, Loss: 0.0061\n",
      "Epoch 107/200, Iteration 106/250, Loss: 0.0060\n",
      "Epoch 107/200, Iteration 107/250, Loss: 0.0368\n",
      "Epoch 107/200, Iteration 108/250, Loss: 0.0136\n",
      "Epoch 107/200, Iteration 109/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 110/250, Loss: 0.0071\n",
      "Epoch 107/200, Iteration 111/250, Loss: 0.0257\n",
      "Epoch 107/200, Iteration 112/250, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 113/250, Loss: 0.0089\n",
      "Epoch 107/200, Iteration 114/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 115/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 116/250, Loss: 0.0124\n",
      "Epoch 107/200, Iteration 117/250, Loss: 0.0102\n",
      "Epoch 107/200, Iteration 118/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 119/250, Loss: 0.0164\n",
      "Epoch 107/200, Iteration 120/250, Loss: 0.0087\n",
      "Epoch 107/200, Iteration 121/250, Loss: 0.0090\n",
      "Epoch 107/200, Iteration 122/250, Loss: 0.0139\n",
      "Epoch 107/200, Iteration 123/250, Loss: 0.0235\n",
      "Epoch 107/200, Iteration 124/250, Loss: 0.0239\n",
      "Epoch 107/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 126/250, Loss: 0.0092\n",
      "Epoch 107/200, Iteration 127/250, Loss: 0.0191\n",
      "Epoch 107/200, Iteration 128/250, Loss: 0.0314\n",
      "Epoch 107/200, Iteration 129/250, Loss: 0.0235\n",
      "Epoch 107/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 107/200, Iteration 131/250, Loss: 0.0156\n",
      "Epoch 107/200, Iteration 132/250, Loss: 0.0155\n",
      "Epoch 107/200, Iteration 133/250, Loss: 0.0168\n",
      "Epoch 107/200, Iteration 134/250, Loss: 0.0089\n",
      "Epoch 107/200, Iteration 135/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 136/250, Loss: 0.0237\n",
      "Epoch 107/200, Iteration 137/250, Loss: 0.0132\n",
      "Epoch 107/200, Iteration 138/250, Loss: 0.0222\n",
      "Epoch 107/200, Iteration 139/250, Loss: 0.0183\n",
      "Epoch 107/200, Iteration 140/250, Loss: 0.0127\n",
      "Epoch 107/200, Iteration 141/250, Loss: 0.0119\n",
      "Epoch 107/200, Iteration 142/250, Loss: 0.0175\n",
      "Epoch 107/200, Iteration 143/250, Loss: 0.0142\n",
      "Epoch 107/200, Iteration 144/250, Loss: 0.0132\n",
      "Epoch 107/200, Iteration 145/250, Loss: 0.0383\n",
      "Epoch 107/200, Iteration 146/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 147/250, Loss: 0.0171\n",
      "Epoch 107/200, Iteration 148/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 149/250, Loss: 0.0181\n",
      "Epoch 107/200, Iteration 150/250, Loss: 0.0134\n",
      "Epoch 107/200, Iteration 151/250, Loss: 0.0120\n",
      "Epoch 107/200, Iteration 152/250, Loss: 0.0141\n",
      "Epoch 107/200, Iteration 153/250, Loss: 0.0224\n",
      "Epoch 107/200, Iteration 154/250, Loss: 0.0189\n",
      "Epoch 107/200, Iteration 155/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 156/250, Loss: 0.0198\n",
      "Epoch 107/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 158/250, Loss: 0.0115\n",
      "Epoch 107/200, Iteration 159/250, Loss: 0.0263\n",
      "Epoch 107/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 107/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 107/200, Iteration 162/250, Loss: 0.0176\n",
      "Epoch 107/200, Iteration 163/250, Loss: 0.0208\n",
      "Epoch 107/200, Iteration 164/250, Loss: 0.0388\n",
      "Epoch 107/200, Iteration 165/250, Loss: 0.0064\n",
      "Epoch 107/200, Iteration 166/250, Loss: 0.0198\n",
      "Epoch 107/200, Iteration 167/250, Loss: 0.0106\n",
      "Epoch 107/200, Iteration 168/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 169/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 170/250, Loss: 0.0254\n",
      "Epoch 107/200, Iteration 171/250, Loss: 0.0079\n",
      "Epoch 107/200, Iteration 172/250, Loss: 0.0116\n",
      "Epoch 107/200, Iteration 173/250, Loss: 0.0110\n",
      "Epoch 107/200, Iteration 174/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 175/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 176/250, Loss: 0.0090\n",
      "Epoch 107/200, Iteration 177/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 178/250, Loss: 0.0121\n",
      "Epoch 107/200, Iteration 179/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 107/200, Iteration 181/250, Loss: 0.0146\n",
      "Epoch 107/200, Iteration 182/250, Loss: 0.0218\n",
      "Epoch 107/200, Iteration 183/250, Loss: 0.0154\n",
      "Epoch 107/200, Iteration 184/250, Loss: 0.0210\n",
      "Epoch 107/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 107/200, Iteration 186/250, Loss: 0.0113\n",
      "Epoch 107/200, Iteration 187/250, Loss: 0.0129\n",
      "Epoch 107/200, Iteration 188/250, Loss: 0.0147\n",
      "Epoch 107/200, Iteration 189/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 190/250, Loss: 0.0102\n",
      "Epoch 107/200, Iteration 191/250, Loss: 0.0082\n",
      "Epoch 107/200, Iteration 192/250, Loss: 0.0149\n",
      "Epoch 107/200, Iteration 193/250, Loss: 0.0099\n",
      "Epoch 107/200, Iteration 194/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 195/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 196/250, Loss: 0.0180\n",
      "Epoch 107/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 107/200, Iteration 198/250, Loss: 0.0267\n",
      "Epoch 107/200, Iteration 199/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 200/250, Loss: 0.0095\n",
      "Epoch 107/200, Iteration 201/250, Loss: 0.0151\n",
      "Epoch 107/200, Iteration 202/250, Loss: 0.0086\n",
      "Epoch 107/200, Iteration 203/250, Loss: 0.0105\n",
      "Epoch 107/200, Iteration 204/250, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 205/250, Loss: 0.0213\n",
      "Epoch 107/200, Iteration 206/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 207/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 208/250, Loss: 0.0163\n",
      "Epoch 107/200, Iteration 209/250, Loss: 0.0173\n",
      "Epoch 107/200, Iteration 210/250, Loss: 0.0137\n",
      "Epoch 107/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 107/200, Iteration 212/250, Loss: 0.0216\n",
      "Epoch 107/200, Iteration 213/250, Loss: 0.0173\n",
      "Epoch 107/200, Iteration 214/250, Loss: 0.0378\n",
      "Epoch 107/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 107/200, Iteration 216/250, Loss: 0.0151\n",
      "Epoch 107/200, Iteration 217/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 218/250, Loss: 0.0043\n",
      "Epoch 107/200, Iteration 219/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 220/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 221/250, Loss: 0.0283\n",
      "Epoch 107/200, Iteration 222/250, Loss: 0.0265\n",
      "Epoch 107/200, Iteration 223/250, Loss: 0.0095\n",
      "Epoch 107/200, Iteration 224/250, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 225/250, Loss: 0.0099\n",
      "Epoch 107/200, Iteration 226/250, Loss: 0.0177\n",
      "Epoch 107/200, Iteration 227/250, Loss: 0.0163\n",
      "Epoch 107/200, Iteration 228/250, Loss: 0.0120\n",
      "Epoch 107/200, Iteration 229/250, Loss: 0.0245\n",
      "Epoch 107/200, Iteration 230/250, Loss: 0.0250\n",
      "Epoch 107/200, Iteration 231/250, Loss: 0.0093\n",
      "Epoch 107/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 107/200, Iteration 233/250, Loss: 0.0127\n",
      "Epoch 107/200, Iteration 234/250, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 235/250, Loss: 0.0086\n",
      "Epoch 107/200, Iteration 236/250, Loss: 0.0176\n",
      "Epoch 107/200, Iteration 237/250, Loss: 0.0153\n",
      "Epoch 107/200, Iteration 238/250, Loss: 0.0181\n",
      "Epoch 107/200, Iteration 239/250, Loss: 0.0070\n",
      "Epoch 107/200, Iteration 240/250, Loss: 0.0087\n",
      "Epoch 107/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 242/250, Loss: 0.0260\n",
      "Epoch 107/200, Iteration 243/250, Loss: 0.0087\n",
      "Epoch 107/200, Iteration 244/250, Loss: 0.0140\n",
      "Epoch 107/200, Iteration 245/250, Loss: 0.0391\n",
      "Epoch 107/200, Iteration 246/250, Loss: 0.0081\n",
      "Epoch 107/200, Iteration 247/250, Loss: 0.0132\n",
      "Epoch 107/200, Iteration 248/250, Loss: 0.0079\n",
      "Epoch 107/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 107/200, Iteration 250/250, Loss: 0.0444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.19%, Avg loss: 0.006190, MRE: 0.651646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.006242, MRE: 0.979289 \n",
      "\n",
      "Epoch 108/200, Iteration 1/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 2/250, Loss: 0.0072\n",
      "Epoch 108/200, Iteration 3/250, Loss: 0.0189\n",
      "Epoch 108/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 108/200, Iteration 6/250, Loss: 0.0074\n",
      "Epoch 108/200, Iteration 7/250, Loss: 0.0113\n",
      "Epoch 108/200, Iteration 8/250, Loss: 0.0111\n",
      "Epoch 108/200, Iteration 9/250, Loss: 0.0133\n",
      "Epoch 108/200, Iteration 10/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 11/250, Loss: 0.0330\n",
      "Epoch 108/200, Iteration 12/250, Loss: 0.0135\n",
      "Epoch 108/200, Iteration 13/250, Loss: 0.0080\n",
      "Epoch 108/200, Iteration 14/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 15/250, Loss: 0.0208\n",
      "Epoch 108/200, Iteration 16/250, Loss: 0.0105\n",
      "Epoch 108/200, Iteration 17/250, Loss: 0.0169\n",
      "Epoch 108/200, Iteration 18/250, Loss: 0.0157\n",
      "Epoch 108/200, Iteration 19/250, Loss: 0.0268\n",
      "Epoch 108/200, Iteration 20/250, Loss: 0.0204\n",
      "Epoch 108/200, Iteration 21/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 22/250, Loss: 0.0293\n",
      "Epoch 108/200, Iteration 23/250, Loss: 0.0138\n",
      "Epoch 108/200, Iteration 24/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 25/250, Loss: 0.0142\n",
      "Epoch 108/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 108/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 108/200, Iteration 28/250, Loss: 0.0182\n",
      "Epoch 108/200, Iteration 29/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 30/250, Loss: 0.0073\n",
      "Epoch 108/200, Iteration 31/250, Loss: 0.0120\n",
      "Epoch 108/200, Iteration 32/250, Loss: 0.0125\n",
      "Epoch 108/200, Iteration 33/250, Loss: 0.0196\n",
      "Epoch 108/200, Iteration 34/250, Loss: 0.0214\n",
      "Epoch 108/200, Iteration 35/250, Loss: 0.0247\n",
      "Epoch 108/200, Iteration 36/250, Loss: 0.0181\n",
      "Epoch 108/200, Iteration 37/250, Loss: 0.0176\n",
      "Epoch 108/200, Iteration 38/250, Loss: 0.0072\n",
      "Epoch 108/200, Iteration 39/250, Loss: 0.0189\n",
      "Epoch 108/200, Iteration 40/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 41/250, Loss: 0.0271\n",
      "Epoch 108/200, Iteration 42/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 43/250, Loss: 0.0144\n",
      "Epoch 108/200, Iteration 44/250, Loss: 0.0111\n",
      "Epoch 108/200, Iteration 45/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 46/250, Loss: 0.0367\n",
      "Epoch 108/200, Iteration 47/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 48/250, Loss: 0.0160\n",
      "Epoch 108/200, Iteration 49/250, Loss: 0.0171\n",
      "Epoch 108/200, Iteration 50/250, Loss: 0.0135\n",
      "Epoch 108/200, Iteration 51/250, Loss: 0.0190\n",
      "Epoch 108/200, Iteration 52/250, Loss: 0.0071\n",
      "Epoch 108/200, Iteration 53/250, Loss: 0.0231\n",
      "Epoch 108/200, Iteration 54/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 55/250, Loss: 0.0093\n",
      "Epoch 108/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 57/250, Loss: 0.0228\n",
      "Epoch 108/200, Iteration 58/250, Loss: 0.0277\n",
      "Epoch 108/200, Iteration 59/250, Loss: 0.0076\n",
      "Epoch 108/200, Iteration 60/250, Loss: 0.0127\n",
      "Epoch 108/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 108/200, Iteration 62/250, Loss: 0.0074\n",
      "Epoch 108/200, Iteration 63/250, Loss: 0.0085\n",
      "Epoch 108/200, Iteration 64/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 65/250, Loss: 0.0165\n",
      "Epoch 108/200, Iteration 66/250, Loss: 0.0066\n",
      "Epoch 108/200, Iteration 67/250, Loss: 0.0130\n",
      "Epoch 108/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 108/200, Iteration 69/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 70/250, Loss: 0.0120\n",
      "Epoch 108/200, Iteration 71/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 108/200, Iteration 73/250, Loss: 0.0161\n",
      "Epoch 108/200, Iteration 74/250, Loss: 0.0170\n",
      "Epoch 108/200, Iteration 75/250, Loss: 0.0188\n",
      "Epoch 108/200, Iteration 76/250, Loss: 0.0344\n",
      "Epoch 108/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 108/200, Iteration 78/250, Loss: 0.0118\n",
      "Epoch 108/200, Iteration 79/250, Loss: 0.0383\n",
      "Epoch 108/200, Iteration 80/250, Loss: 0.0268\n",
      "Epoch 108/200, Iteration 81/250, Loss: 0.0274\n",
      "Epoch 108/200, Iteration 82/250, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 83/250, Loss: 0.0071\n",
      "Epoch 108/200, Iteration 84/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 85/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 86/250, Loss: 0.0170\n",
      "Epoch 108/200, Iteration 87/250, Loss: 0.0122\n",
      "Epoch 108/200, Iteration 88/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 89/250, Loss: 0.0162\n",
      "Epoch 108/200, Iteration 90/250, Loss: 0.0158\n",
      "Epoch 108/200, Iteration 91/250, Loss: 0.0090\n",
      "Epoch 108/200, Iteration 92/250, Loss: 0.0155\n",
      "Epoch 108/200, Iteration 93/250, Loss: 0.0172\n",
      "Epoch 108/200, Iteration 94/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 95/250, Loss: 0.0206\n",
      "Epoch 108/200, Iteration 96/250, Loss: 0.0071\n",
      "Epoch 108/200, Iteration 97/250, Loss: 0.0221\n",
      "Epoch 108/200, Iteration 98/250, Loss: 0.0075\n",
      "Epoch 108/200, Iteration 99/250, Loss: 0.0211\n",
      "Epoch 108/200, Iteration 100/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 101/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 102/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 103/250, Loss: 0.0235\n",
      "Epoch 108/200, Iteration 104/250, Loss: 0.0229\n",
      "Epoch 108/200, Iteration 105/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 106/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 107/250, Loss: 0.0072\n",
      "Epoch 108/200, Iteration 108/250, Loss: 0.0161\n",
      "Epoch 108/200, Iteration 109/250, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 110/250, Loss: 0.0180\n",
      "Epoch 108/200, Iteration 111/250, Loss: 0.0193\n",
      "Epoch 108/200, Iteration 112/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 113/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 114/250, Loss: 0.0136\n",
      "Epoch 108/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 108/200, Iteration 116/250, Loss: 0.0290\n",
      "Epoch 108/200, Iteration 117/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 118/250, Loss: 0.0143\n",
      "Epoch 108/200, Iteration 119/250, Loss: 0.0259\n",
      "Epoch 108/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 121/250, Loss: 0.0107\n",
      "Epoch 108/200, Iteration 122/250, Loss: 0.0092\n",
      "Epoch 108/200, Iteration 123/250, Loss: 0.0089\n",
      "Epoch 108/200, Iteration 124/250, Loss: 0.0123\n",
      "Epoch 108/200, Iteration 125/250, Loss: 0.0178\n",
      "Epoch 108/200, Iteration 126/250, Loss: 0.0123\n",
      "Epoch 108/200, Iteration 127/250, Loss: 0.0072\n",
      "Epoch 108/200, Iteration 128/250, Loss: 0.0245\n",
      "Epoch 108/200, Iteration 129/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 130/250, Loss: 0.0134\n",
      "Epoch 108/200, Iteration 131/250, Loss: 0.0220\n",
      "Epoch 108/200, Iteration 132/250, Loss: 0.0239\n",
      "Epoch 108/200, Iteration 133/250, Loss: 0.0182\n",
      "Epoch 108/200, Iteration 134/250, Loss: 0.0066\n",
      "Epoch 108/200, Iteration 135/250, Loss: 0.0197\n",
      "Epoch 108/200, Iteration 136/250, Loss: 0.0209\n",
      "Epoch 108/200, Iteration 137/250, Loss: 0.0231\n",
      "Epoch 108/200, Iteration 138/250, Loss: 0.0248\n",
      "Epoch 108/200, Iteration 139/250, Loss: 0.0177\n",
      "Epoch 108/200, Iteration 140/250, Loss: 0.0074\n",
      "Epoch 108/200, Iteration 141/250, Loss: 0.0213\n",
      "Epoch 108/200, Iteration 142/250, Loss: 0.0208\n",
      "Epoch 108/200, Iteration 143/250, Loss: 0.0210\n",
      "Epoch 108/200, Iteration 144/250, Loss: 0.0174\n",
      "Epoch 108/200, Iteration 145/250, Loss: 0.0204\n",
      "Epoch 108/200, Iteration 146/250, Loss: 0.0078\n",
      "Epoch 108/200, Iteration 147/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 148/250, Loss: 0.0140\n",
      "Epoch 108/200, Iteration 149/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 150/250, Loss: 0.0067\n",
      "Epoch 108/200, Iteration 151/250, Loss: 0.0168\n",
      "Epoch 108/200, Iteration 152/250, Loss: 0.0185\n",
      "Epoch 108/200, Iteration 153/250, Loss: 0.0163\n",
      "Epoch 108/200, Iteration 154/250, Loss: 0.0068\n",
      "Epoch 108/200, Iteration 155/250, Loss: 0.0119\n",
      "Epoch 108/200, Iteration 156/250, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 157/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 158/250, Loss: 0.0081\n",
      "Epoch 108/200, Iteration 159/250, Loss: 0.0154\n",
      "Epoch 108/200, Iteration 160/250, Loss: 0.0277\n",
      "Epoch 108/200, Iteration 161/250, Loss: 0.0147\n",
      "Epoch 108/200, Iteration 162/250, Loss: 0.0100\n",
      "Epoch 108/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 108/200, Iteration 164/250, Loss: 0.0180\n",
      "Epoch 108/200, Iteration 165/250, Loss: 0.0120\n",
      "Epoch 108/200, Iteration 166/250, Loss: 0.0267\n",
      "Epoch 108/200, Iteration 167/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 168/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 170/250, Loss: 0.0421\n",
      "Epoch 108/200, Iteration 171/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 172/250, Loss: 0.0178\n",
      "Epoch 108/200, Iteration 173/250, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 174/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 108/200, Iteration 176/250, Loss: 0.0114\n",
      "Epoch 108/200, Iteration 177/250, Loss: 0.0196\n",
      "Epoch 108/200, Iteration 178/250, Loss: 0.0303\n",
      "Epoch 108/200, Iteration 179/250, Loss: 0.0166\n",
      "Epoch 108/200, Iteration 180/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 181/250, Loss: 0.0181\n",
      "Epoch 108/200, Iteration 182/250, Loss: 0.0147\n",
      "Epoch 108/200, Iteration 183/250, Loss: 0.0166\n",
      "Epoch 108/200, Iteration 184/250, Loss: 0.0258\n",
      "Epoch 108/200, Iteration 185/250, Loss: 0.0066\n",
      "Epoch 108/200, Iteration 186/250, Loss: 0.0116\n",
      "Epoch 108/200, Iteration 187/250, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200, Iteration 188/250, Loss: 0.0265\n",
      "Epoch 108/200, Iteration 189/250, Loss: 0.0098\n",
      "Epoch 108/200, Iteration 190/250, Loss: 0.0076\n",
      "Epoch 108/200, Iteration 191/250, Loss: 0.0114\n",
      "Epoch 108/200, Iteration 192/250, Loss: 0.0125\n",
      "Epoch 108/200, Iteration 193/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 194/250, Loss: 0.0152\n",
      "Epoch 108/200, Iteration 195/250, Loss: 0.0180\n",
      "Epoch 108/200, Iteration 196/250, Loss: 0.0115\n",
      "Epoch 108/200, Iteration 197/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 198/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 199/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 200/250, Loss: 0.0174\n",
      "Epoch 108/200, Iteration 201/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 202/250, Loss: 0.0134\n",
      "Epoch 108/200, Iteration 203/250, Loss: 0.0089\n",
      "Epoch 108/200, Iteration 204/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 205/250, Loss: 0.0119\n",
      "Epoch 108/200, Iteration 206/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 207/250, Loss: 0.0166\n",
      "Epoch 108/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 209/250, Loss: 0.0328\n",
      "Epoch 108/200, Iteration 210/250, Loss: 0.0154\n",
      "Epoch 108/200, Iteration 211/250, Loss: 0.0105\n",
      "Epoch 108/200, Iteration 212/250, Loss: 0.0253\n",
      "Epoch 108/200, Iteration 213/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 214/250, Loss: 0.0326\n",
      "Epoch 108/200, Iteration 215/250, Loss: 0.0127\n",
      "Epoch 108/200, Iteration 216/250, Loss: 0.0117\n",
      "Epoch 108/200, Iteration 217/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 218/250, Loss: 0.0122\n",
      "Epoch 108/200, Iteration 219/250, Loss: 0.0307\n",
      "Epoch 108/200, Iteration 220/250, Loss: 0.0109\n",
      "Epoch 108/200, Iteration 221/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 222/250, Loss: 0.0063\n",
      "Epoch 108/200, Iteration 223/250, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 224/250, Loss: 0.0107\n",
      "Epoch 108/200, Iteration 225/250, Loss: 0.0193\n",
      "Epoch 108/200, Iteration 226/250, Loss: 0.0278\n",
      "Epoch 108/200, Iteration 227/250, Loss: 0.0065\n",
      "Epoch 108/200, Iteration 228/250, Loss: 0.0094\n",
      "Epoch 108/200, Iteration 229/250, Loss: 0.0232\n",
      "Epoch 108/200, Iteration 230/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 231/250, Loss: 0.0085\n",
      "Epoch 108/200, Iteration 232/250, Loss: 0.0074\n",
      "Epoch 108/200, Iteration 233/250, Loss: 0.0293\n",
      "Epoch 108/200, Iteration 234/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 235/250, Loss: 0.0148\n",
      "Epoch 108/200, Iteration 236/250, Loss: 0.0166\n",
      "Epoch 108/200, Iteration 237/250, Loss: 0.0127\n",
      "Epoch 108/200, Iteration 238/250, Loss: 0.0113\n",
      "Epoch 108/200, Iteration 239/250, Loss: 0.0191\n",
      "Epoch 108/200, Iteration 240/250, Loss: 0.0242\n",
      "Epoch 108/200, Iteration 241/250, Loss: 0.0211\n",
      "Epoch 108/200, Iteration 242/250, Loss: 0.0066\n",
      "Epoch 108/200, Iteration 243/250, Loss: 0.0114\n",
      "Epoch 108/200, Iteration 244/250, Loss: 0.0081\n",
      "Epoch 108/200, Iteration 245/250, Loss: 0.0117\n",
      "Epoch 108/200, Iteration 246/250, Loss: 0.0195\n",
      "Epoch 108/200, Iteration 247/250, Loss: 0.0238\n",
      "Epoch 108/200, Iteration 248/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 250/250, Loss: 0.0282\n",
      "Train Error: \n",
      " Accuracy: 90.04%, Avg loss: 0.006170, MRE: 0.611547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.85%, Avg loss: 0.006229, MRE: 0.937920 \n",
      "\n",
      "Epoch 109/200, Iteration 1/250, Loss: 0.0129\n",
      "Epoch 109/200, Iteration 2/250, Loss: 0.0127\n",
      "Epoch 109/200, Iteration 3/250, Loss: 0.0102\n",
      "Epoch 109/200, Iteration 4/250, Loss: 0.0153\n",
      "Epoch 109/200, Iteration 5/250, Loss: 0.0262\n",
      "Epoch 109/200, Iteration 6/250, Loss: 0.0526\n",
      "Epoch 109/200, Iteration 7/250, Loss: 0.0258\n",
      "Epoch 109/200, Iteration 8/250, Loss: 0.0165\n",
      "Epoch 109/200, Iteration 9/250, Loss: 0.0168\n",
      "Epoch 109/200, Iteration 10/250, Loss: 0.0071\n",
      "Epoch 109/200, Iteration 11/250, Loss: 0.0112\n",
      "Epoch 109/200, Iteration 12/250, Loss: 0.0071\n",
      "Epoch 109/200, Iteration 13/250, Loss: 0.0133\n",
      "Epoch 109/200, Iteration 14/250, Loss: 0.0103\n",
      "Epoch 109/200, Iteration 15/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 16/250, Loss: 0.0052\n",
      "Epoch 109/200, Iteration 17/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 18/250, Loss: 0.0130\n",
      "Epoch 109/200, Iteration 19/250, Loss: 0.0160\n",
      "Epoch 109/200, Iteration 20/250, Loss: 0.0095\n",
      "Epoch 109/200, Iteration 21/250, Loss: 0.0174\n",
      "Epoch 109/200, Iteration 22/250, Loss: 0.0126\n",
      "Epoch 109/200, Iteration 23/250, Loss: 0.0099\n",
      "Epoch 109/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 109/200, Iteration 25/250, Loss: 0.0192\n",
      "Epoch 109/200, Iteration 26/250, Loss: 0.0400\n",
      "Epoch 109/200, Iteration 27/250, Loss: 0.0237\n",
      "Epoch 109/200, Iteration 28/250, Loss: 0.0069\n",
      "Epoch 109/200, Iteration 29/250, Loss: 0.0080\n",
      "Epoch 109/200, Iteration 30/250, Loss: 0.0075\n",
      "Epoch 109/200, Iteration 31/250, Loss: 0.0208\n",
      "Epoch 109/200, Iteration 32/250, Loss: 0.0221\n",
      "Epoch 109/200, Iteration 33/250, Loss: 0.0178\n",
      "Epoch 109/200, Iteration 34/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 35/250, Loss: 0.0433\n",
      "Epoch 109/200, Iteration 36/250, Loss: 0.0067\n",
      "Epoch 109/200, Iteration 37/250, Loss: 0.0147\n",
      "Epoch 109/200, Iteration 38/250, Loss: 0.0211\n",
      "Epoch 109/200, Iteration 39/250, Loss: 0.0066\n",
      "Epoch 109/200, Iteration 40/250, Loss: 0.0078\n",
      "Epoch 109/200, Iteration 41/250, Loss: 0.0062\n",
      "Epoch 109/200, Iteration 42/250, Loss: 0.0095\n",
      "Epoch 109/200, Iteration 43/250, Loss: 0.0103\n",
      "Epoch 109/200, Iteration 44/250, Loss: 0.0209\n",
      "Epoch 109/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 46/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 47/250, Loss: 0.0293\n",
      "Epoch 109/200, Iteration 48/250, Loss: 0.0320\n",
      "Epoch 109/200, Iteration 49/250, Loss: 0.0210\n",
      "Epoch 109/200, Iteration 50/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 51/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 52/250, Loss: 0.0151\n",
      "Epoch 109/200, Iteration 53/250, Loss: 0.0225\n",
      "Epoch 109/200, Iteration 54/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 55/250, Loss: 0.0070\n",
      "Epoch 109/200, Iteration 56/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 109/200, Iteration 58/250, Loss: 0.0133\n",
      "Epoch 109/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 109/200, Iteration 60/250, Loss: 0.0106\n",
      "Epoch 109/200, Iteration 61/250, Loss: 0.0092\n",
      "Epoch 109/200, Iteration 62/250, Loss: 0.0219\n",
      "Epoch 109/200, Iteration 63/250, Loss: 0.0288\n",
      "Epoch 109/200, Iteration 64/250, Loss: 0.0110\n",
      "Epoch 109/200, Iteration 65/250, Loss: 0.0172\n",
      "Epoch 109/200, Iteration 66/250, Loss: 0.0145\n",
      "Epoch 109/200, Iteration 67/250, Loss: 0.0120\n",
      "Epoch 109/200, Iteration 68/250, Loss: 0.0136\n",
      "Epoch 109/200, Iteration 69/250, Loss: 0.0104\n",
      "Epoch 109/200, Iteration 70/250, Loss: 0.0147\n",
      "Epoch 109/200, Iteration 71/250, Loss: 0.0197\n",
      "Epoch 109/200, Iteration 72/250, Loss: 0.0086\n",
      "Epoch 109/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 109/200, Iteration 74/250, Loss: 0.0273\n",
      "Epoch 109/200, Iteration 75/250, Loss: 0.0114\n",
      "Epoch 109/200, Iteration 76/250, Loss: 0.0147\n",
      "Epoch 109/200, Iteration 77/250, Loss: 0.0077\n",
      "Epoch 109/200, Iteration 78/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 79/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 80/250, Loss: 0.0153\n",
      "Epoch 109/200, Iteration 81/250, Loss: 0.0120\n",
      "Epoch 109/200, Iteration 82/250, Loss: 0.0288\n",
      "Epoch 109/200, Iteration 83/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 84/250, Loss: 0.0166\n",
      "Epoch 109/200, Iteration 85/250, Loss: 0.0279\n",
      "Epoch 109/200, Iteration 86/250, Loss: 0.0318\n",
      "Epoch 109/200, Iteration 87/250, Loss: 0.0120\n",
      "Epoch 109/200, Iteration 88/250, Loss: 0.0101\n",
      "Epoch 109/200, Iteration 89/250, Loss: 0.0195\n",
      "Epoch 109/200, Iteration 90/250, Loss: 0.0172\n",
      "Epoch 109/200, Iteration 91/250, Loss: 0.0136\n",
      "Epoch 109/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 109/200, Iteration 93/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 94/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 95/250, Loss: 0.0152\n",
      "Epoch 109/200, Iteration 96/250, Loss: 0.0093\n",
      "Epoch 109/200, Iteration 97/250, Loss: 0.0181\n",
      "Epoch 109/200, Iteration 98/250, Loss: 0.0177\n",
      "Epoch 109/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 109/200, Iteration 100/250, Loss: 0.0113\n",
      "Epoch 109/200, Iteration 101/250, Loss: 0.0197\n",
      "Epoch 109/200, Iteration 102/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 103/250, Loss: 0.0202\n",
      "Epoch 109/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 109/200, Iteration 105/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 106/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 107/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 108/250, Loss: 0.0355\n",
      "Epoch 109/200, Iteration 109/250, Loss: 0.0103\n",
      "Epoch 109/200, Iteration 110/250, Loss: 0.0261\n",
      "Epoch 109/200, Iteration 111/250, Loss: 0.0072\n",
      "Epoch 109/200, Iteration 112/250, Loss: 0.0114\n",
      "Epoch 109/200, Iteration 113/250, Loss: 0.0352\n",
      "Epoch 109/200, Iteration 114/250, Loss: 0.0259\n",
      "Epoch 109/200, Iteration 115/250, Loss: 0.0076\n",
      "Epoch 109/200, Iteration 116/250, Loss: 0.0296\n",
      "Epoch 109/200, Iteration 117/250, Loss: 0.0067\n",
      "Epoch 109/200, Iteration 118/250, Loss: 0.0242\n",
      "Epoch 109/200, Iteration 119/250, Loss: 0.0172\n",
      "Epoch 109/200, Iteration 120/250, Loss: 0.0101\n",
      "Epoch 109/200, Iteration 121/250, Loss: 0.0099\n",
      "Epoch 109/200, Iteration 122/250, Loss: 0.0125\n",
      "Epoch 109/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 109/200, Iteration 124/250, Loss: 0.0171\n",
      "Epoch 109/200, Iteration 125/250, Loss: 0.0133\n",
      "Epoch 109/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 109/200, Iteration 127/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 128/250, Loss: 0.0453\n",
      "Epoch 109/200, Iteration 129/250, Loss: 0.0159\n",
      "Epoch 109/200, Iteration 130/250, Loss: 0.0138\n",
      "Epoch 109/200, Iteration 131/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 132/250, Loss: 0.0159\n",
      "Epoch 109/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 134/250, Loss: 0.0077\n",
      "Epoch 109/200, Iteration 135/250, Loss: 0.0146\n",
      "Epoch 109/200, Iteration 136/250, Loss: 0.0216\n",
      "Epoch 109/200, Iteration 137/250, Loss: 0.0077\n",
      "Epoch 109/200, Iteration 138/250, Loss: 0.0117\n",
      "Epoch 109/200, Iteration 139/250, Loss: 0.0080\n",
      "Epoch 109/200, Iteration 140/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 141/250, Loss: 0.0369\n",
      "Epoch 109/200, Iteration 142/250, Loss: 0.0139\n",
      "Epoch 109/200, Iteration 143/250, Loss: 0.0075\n",
      "Epoch 109/200, Iteration 144/250, Loss: 0.0271\n",
      "Epoch 109/200, Iteration 145/250, Loss: 0.0071\n",
      "Epoch 109/200, Iteration 146/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 147/250, Loss: 0.0088\n",
      "Epoch 109/200, Iteration 148/250, Loss: 0.0187\n",
      "Epoch 109/200, Iteration 149/250, Loss: 0.0117\n",
      "Epoch 109/200, Iteration 150/250, Loss: 0.0111\n",
      "Epoch 109/200, Iteration 151/250, Loss: 0.0299\n",
      "Epoch 109/200, Iteration 152/250, Loss: 0.0177\n",
      "Epoch 109/200, Iteration 153/250, Loss: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200, Iteration 154/250, Loss: 0.0278\n",
      "Epoch 109/200, Iteration 155/250, Loss: 0.0316\n",
      "Epoch 109/200, Iteration 156/250, Loss: 0.0264\n",
      "Epoch 109/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 109/200, Iteration 158/250, Loss: 0.0252\n",
      "Epoch 109/200, Iteration 159/250, Loss: 0.0410\n",
      "Epoch 109/200, Iteration 160/250, Loss: 0.0116\n",
      "Epoch 109/200, Iteration 161/250, Loss: 0.0213\n",
      "Epoch 109/200, Iteration 162/250, Loss: 0.0287\n",
      "Epoch 109/200, Iteration 163/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 109/200, Iteration 165/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 166/250, Loss: 0.0116\n",
      "Epoch 109/200, Iteration 167/250, Loss: 0.0139\n",
      "Epoch 109/200, Iteration 168/250, Loss: 0.0103\n",
      "Epoch 109/200, Iteration 169/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 170/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 171/250, Loss: 0.0192\n",
      "Epoch 109/200, Iteration 172/250, Loss: 0.0499\n",
      "Epoch 109/200, Iteration 173/250, Loss: 0.0323\n",
      "Epoch 109/200, Iteration 174/250, Loss: 0.0133\n",
      "Epoch 109/200, Iteration 175/250, Loss: 0.0183\n",
      "Epoch 109/200, Iteration 176/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 177/250, Loss: 0.0173\n",
      "Epoch 109/200, Iteration 178/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 179/250, Loss: 0.0367\n",
      "Epoch 109/200, Iteration 180/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 181/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 182/250, Loss: 0.0178\n",
      "Epoch 109/200, Iteration 183/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 184/250, Loss: 0.0147\n",
      "Epoch 109/200, Iteration 185/250, Loss: 0.0352\n",
      "Epoch 109/200, Iteration 186/250, Loss: 0.0130\n",
      "Epoch 109/200, Iteration 187/250, Loss: 0.0134\n",
      "Epoch 109/200, Iteration 188/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 189/250, Loss: 0.0096\n",
      "Epoch 109/200, Iteration 190/250, Loss: 0.0088\n",
      "Epoch 109/200, Iteration 191/250, Loss: 0.0096\n",
      "Epoch 109/200, Iteration 192/250, Loss: 0.0120\n",
      "Epoch 109/200, Iteration 193/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 194/250, Loss: 0.0179\n",
      "Epoch 109/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 196/250, Loss: 0.0060\n",
      "Epoch 109/200, Iteration 197/250, Loss: 0.0175\n",
      "Epoch 109/200, Iteration 198/250, Loss: 0.0203\n",
      "Epoch 109/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 109/200, Iteration 200/250, Loss: 0.0216\n",
      "Epoch 109/200, Iteration 201/250, Loss: 0.0239\n",
      "Epoch 109/200, Iteration 202/250, Loss: 0.0211\n",
      "Epoch 109/200, Iteration 203/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 204/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 205/250, Loss: 0.0139\n",
      "Epoch 109/200, Iteration 206/250, Loss: 0.0113\n",
      "Epoch 109/200, Iteration 207/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 208/250, Loss: 0.0128\n",
      "Epoch 109/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 210/250, Loss: 0.0126\n",
      "Epoch 109/200, Iteration 211/250, Loss: 0.0163\n",
      "Epoch 109/200, Iteration 212/250, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 213/250, Loss: 0.0059\n",
      "Epoch 109/200, Iteration 214/250, Loss: 0.0079\n",
      "Epoch 109/200, Iteration 215/250, Loss: 0.0263\n",
      "Epoch 109/200, Iteration 216/250, Loss: 0.0129\n",
      "Epoch 109/200, Iteration 217/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 218/250, Loss: 0.0121\n",
      "Epoch 109/200, Iteration 219/250, Loss: 0.0096\n",
      "Epoch 109/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 109/200, Iteration 221/250, Loss: 0.0128\n",
      "Epoch 109/200, Iteration 222/250, Loss: 0.0263\n",
      "Epoch 109/200, Iteration 223/250, Loss: 0.0101\n",
      "Epoch 109/200, Iteration 224/250, Loss: 0.0164\n",
      "Epoch 109/200, Iteration 225/250, Loss: 0.0092\n",
      "Epoch 109/200, Iteration 226/250, Loss: 0.0219\n",
      "Epoch 109/200, Iteration 227/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 228/250, Loss: 0.0144\n",
      "Epoch 109/200, Iteration 229/250, Loss: 0.0220\n",
      "Epoch 109/200, Iteration 230/250, Loss: 0.0155\n",
      "Epoch 109/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 232/250, Loss: 0.0111\n",
      "Epoch 109/200, Iteration 233/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 234/250, Loss: 0.0249\n",
      "Epoch 109/200, Iteration 235/250, Loss: 0.0158\n",
      "Epoch 109/200, Iteration 236/250, Loss: 0.0099\n",
      "Epoch 109/200, Iteration 237/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 238/250, Loss: 0.0164\n",
      "Epoch 109/200, Iteration 239/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 240/250, Loss: 0.0197\n",
      "Epoch 109/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 242/250, Loss: 0.0210\n",
      "Epoch 109/200, Iteration 243/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 244/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 245/250, Loss: 0.0449\n",
      "Epoch 109/200, Iteration 246/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 247/250, Loss: 0.0093\n",
      "Epoch 109/200, Iteration 248/250, Loss: 0.0199\n",
      "Epoch 109/200, Iteration 249/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 250/250, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 93.95%, Avg loss: 0.006076, MRE: 0.617289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.006081, MRE: 0.931568 \n",
      "\n",
      "Epoch 110/200, Iteration 1/250, Loss: 0.0218\n",
      "Epoch 110/200, Iteration 2/250, Loss: 0.0082\n",
      "Epoch 110/200, Iteration 3/250, Loss: 0.0088\n",
      "Epoch 110/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 110/200, Iteration 5/250, Loss: 0.0128\n",
      "Epoch 110/200, Iteration 6/250, Loss: 0.0130\n",
      "Epoch 110/200, Iteration 7/250, Loss: 0.0149\n",
      "Epoch 110/200, Iteration 8/250, Loss: 0.0116\n",
      "Epoch 110/200, Iteration 9/250, Loss: 0.0082\n",
      "Epoch 110/200, Iteration 10/250, Loss: 0.0189\n",
      "Epoch 110/200, Iteration 11/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 12/250, Loss: 0.0114\n",
      "Epoch 110/200, Iteration 13/250, Loss: 0.0155\n",
      "Epoch 110/200, Iteration 14/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 15/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 16/250, Loss: 0.0143\n",
      "Epoch 110/200, Iteration 17/250, Loss: 0.0074\n",
      "Epoch 110/200, Iteration 18/250, Loss: 0.0169\n",
      "Epoch 110/200, Iteration 19/250, Loss: 0.0093\n",
      "Epoch 110/200, Iteration 20/250, Loss: 0.0200\n",
      "Epoch 110/200, Iteration 21/250, Loss: 0.0131\n",
      "Epoch 110/200, Iteration 22/250, Loss: 0.0155\n",
      "Epoch 110/200, Iteration 23/250, Loss: 0.0074\n",
      "Epoch 110/200, Iteration 24/250, Loss: 0.0119\n",
      "Epoch 110/200, Iteration 25/250, Loss: 0.0102\n",
      "Epoch 110/200, Iteration 26/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 27/250, Loss: 0.0327\n",
      "Epoch 110/200, Iteration 28/250, Loss: 0.0076\n",
      "Epoch 110/200, Iteration 29/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 30/250, Loss: 0.0113\n",
      "Epoch 110/200, Iteration 31/250, Loss: 0.0153\n",
      "Epoch 110/200, Iteration 32/250, Loss: 0.0119\n",
      "Epoch 110/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 110/200, Iteration 34/250, Loss: 0.0133\n",
      "Epoch 110/200, Iteration 35/250, Loss: 0.0074\n",
      "Epoch 110/200, Iteration 36/250, Loss: 0.0244\n",
      "Epoch 110/200, Iteration 37/250, Loss: 0.0172\n",
      "Epoch 110/200, Iteration 38/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 39/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 40/250, Loss: 0.0119\n",
      "Epoch 110/200, Iteration 41/250, Loss: 0.0234\n",
      "Epoch 110/200, Iteration 42/250, Loss: 0.0184\n",
      "Epoch 110/200, Iteration 43/250, Loss: 0.0140\n",
      "Epoch 110/200, Iteration 44/250, Loss: 0.0366\n",
      "Epoch 110/200, Iteration 45/250, Loss: 0.0359\n",
      "Epoch 110/200, Iteration 46/250, Loss: 0.0068\n",
      "Epoch 110/200, Iteration 47/250, Loss: 0.0118\n",
      "Epoch 110/200, Iteration 48/250, Loss: 0.0055\n",
      "Epoch 110/200, Iteration 49/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 110/200, Iteration 51/250, Loss: 0.0080\n",
      "Epoch 110/200, Iteration 52/250, Loss: 0.0122\n",
      "Epoch 110/200, Iteration 53/250, Loss: 0.0150\n",
      "Epoch 110/200, Iteration 54/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 55/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 56/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 57/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 58/250, Loss: 0.0117\n",
      "Epoch 110/200, Iteration 59/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 110/200, Iteration 61/250, Loss: 0.0156\n",
      "Epoch 110/200, Iteration 62/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 63/250, Loss: 0.0230\n",
      "Epoch 110/200, Iteration 64/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 65/250, Loss: 0.0145\n",
      "Epoch 110/200, Iteration 66/250, Loss: 0.0292\n",
      "Epoch 110/200, Iteration 67/250, Loss: 0.0151\n",
      "Epoch 110/200, Iteration 68/250, Loss: 0.0097\n",
      "Epoch 110/200, Iteration 69/250, Loss: 0.0096\n",
      "Epoch 110/200, Iteration 70/250, Loss: 0.0290\n",
      "Epoch 110/200, Iteration 71/250, Loss: 0.0165\n",
      "Epoch 110/200, Iteration 72/250, Loss: 0.0135\n",
      "Epoch 110/200, Iteration 73/250, Loss: 0.0153\n",
      "Epoch 110/200, Iteration 74/250, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 75/250, Loss: 0.0070\n",
      "Epoch 110/200, Iteration 76/250, Loss: 0.0331\n",
      "Epoch 110/200, Iteration 77/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 78/250, Loss: 0.0300\n",
      "Epoch 110/200, Iteration 79/250, Loss: 0.0164\n",
      "Epoch 110/200, Iteration 80/250, Loss: 0.0236\n",
      "Epoch 110/200, Iteration 81/250, Loss: 0.0304\n",
      "Epoch 110/200, Iteration 82/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 83/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 84/250, Loss: 0.0082\n",
      "Epoch 110/200, Iteration 85/250, Loss: 0.0066\n",
      "Epoch 110/200, Iteration 86/250, Loss: 0.0093\n",
      "Epoch 110/200, Iteration 87/250, Loss: 0.0102\n",
      "Epoch 110/200, Iteration 88/250, Loss: 0.0238\n",
      "Epoch 110/200, Iteration 89/250, Loss: 0.0211\n",
      "Epoch 110/200, Iteration 90/250, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 91/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 92/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 93/250, Loss: 0.0135\n",
      "Epoch 110/200, Iteration 94/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 95/250, Loss: 0.0054\n",
      "Epoch 110/200, Iteration 96/250, Loss: 0.0068\n",
      "Epoch 110/200, Iteration 97/250, Loss: 0.0200\n",
      "Epoch 110/200, Iteration 98/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 99/250, Loss: 0.0251\n",
      "Epoch 110/200, Iteration 100/250, Loss: 0.0239\n",
      "Epoch 110/200, Iteration 101/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 102/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 103/250, Loss: 0.0194\n",
      "Epoch 110/200, Iteration 104/250, Loss: 0.0131\n",
      "Epoch 110/200, Iteration 105/250, Loss: 0.0165\n",
      "Epoch 110/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 110/200, Iteration 107/250, Loss: 0.0147\n",
      "Epoch 110/200, Iteration 108/250, Loss: 0.0128\n",
      "Epoch 110/200, Iteration 109/250, Loss: 0.0088\n",
      "Epoch 110/200, Iteration 110/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 111/250, Loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200, Iteration 112/250, Loss: 0.0133\n",
      "Epoch 110/200, Iteration 113/250, Loss: 0.0387\n",
      "Epoch 110/200, Iteration 114/250, Loss: 0.0074\n",
      "Epoch 110/200, Iteration 115/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 116/250, Loss: 0.0270\n",
      "Epoch 110/200, Iteration 117/250, Loss: 0.0308\n",
      "Epoch 110/200, Iteration 118/250, Loss: 0.0193\n",
      "Epoch 110/200, Iteration 119/250, Loss: 0.0193\n",
      "Epoch 110/200, Iteration 120/250, Loss: 0.0109\n",
      "Epoch 110/200, Iteration 121/250, Loss: 0.0118\n",
      "Epoch 110/200, Iteration 122/250, Loss: 0.0145\n",
      "Epoch 110/200, Iteration 123/250, Loss: 0.0109\n",
      "Epoch 110/200, Iteration 124/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 125/250, Loss: 0.0285\n",
      "Epoch 110/200, Iteration 126/250, Loss: 0.0083\n",
      "Epoch 110/200, Iteration 127/250, Loss: 0.0206\n",
      "Epoch 110/200, Iteration 128/250, Loss: 0.0124\n",
      "Epoch 110/200, Iteration 129/250, Loss: 0.0160\n",
      "Epoch 110/200, Iteration 130/250, Loss: 0.0405\n",
      "Epoch 110/200, Iteration 131/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 132/250, Loss: 0.0197\n",
      "Epoch 110/200, Iteration 133/250, Loss: 0.0280\n",
      "Epoch 110/200, Iteration 134/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 135/250, Loss: 0.0233\n",
      "Epoch 110/200, Iteration 136/250, Loss: 0.0099\n",
      "Epoch 110/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 110/200, Iteration 138/250, Loss: 0.0264\n",
      "Epoch 110/200, Iteration 139/250, Loss: 0.0099\n",
      "Epoch 110/200, Iteration 140/250, Loss: 0.0120\n",
      "Epoch 110/200, Iteration 141/250, Loss: 0.0108\n",
      "Epoch 110/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 143/250, Loss: 0.0102\n",
      "Epoch 110/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 145/250, Loss: 0.0219\n",
      "Epoch 110/200, Iteration 146/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 147/250, Loss: 0.0198\n",
      "Epoch 110/200, Iteration 148/250, Loss: 0.0162\n",
      "Epoch 110/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 150/250, Loss: 0.0274\n",
      "Epoch 110/200, Iteration 151/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 153/250, Loss: 0.0149\n",
      "Epoch 110/200, Iteration 154/250, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 155/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 156/250, Loss: 0.0201\n",
      "Epoch 110/200, Iteration 157/250, Loss: 0.0124\n",
      "Epoch 110/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 110/200, Iteration 159/250, Loss: 0.0066\n",
      "Epoch 110/200, Iteration 160/250, Loss: 0.0078\n",
      "Epoch 110/200, Iteration 161/250, Loss: 0.0114\n",
      "Epoch 110/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 110/200, Iteration 163/250, Loss: 0.0137\n",
      "Epoch 110/200, Iteration 164/250, Loss: 0.0155\n",
      "Epoch 110/200, Iteration 165/250, Loss: 0.0212\n",
      "Epoch 110/200, Iteration 166/250, Loss: 0.0264\n",
      "Epoch 110/200, Iteration 167/250, Loss: 0.0140\n",
      "Epoch 110/200, Iteration 168/250, Loss: 0.0159\n",
      "Epoch 110/200, Iteration 169/250, Loss: 0.0232\n",
      "Epoch 110/200, Iteration 170/250, Loss: 0.0099\n",
      "Epoch 110/200, Iteration 171/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 172/250, Loss: 0.0124\n",
      "Epoch 110/200, Iteration 173/250, Loss: 0.0138\n",
      "Epoch 110/200, Iteration 174/250, Loss: 0.0123\n",
      "Epoch 110/200, Iteration 175/250, Loss: 0.0113\n",
      "Epoch 110/200, Iteration 176/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 177/250, Loss: 0.0143\n",
      "Epoch 110/200, Iteration 178/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 179/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 180/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 181/250, Loss: 0.0202\n",
      "Epoch 110/200, Iteration 182/250, Loss: 0.0122\n",
      "Epoch 110/200, Iteration 183/250, Loss: 0.0159\n",
      "Epoch 110/200, Iteration 184/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 185/250, Loss: 0.0130\n",
      "Epoch 110/200, Iteration 186/250, Loss: 0.0118\n",
      "Epoch 110/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 110/200, Iteration 188/250, Loss: 0.0214\n",
      "Epoch 110/200, Iteration 189/250, Loss: 0.0250\n",
      "Epoch 110/200, Iteration 190/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 191/250, Loss: 0.0171\n",
      "Epoch 110/200, Iteration 192/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 193/250, Loss: 0.0075\n",
      "Epoch 110/200, Iteration 194/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 195/250, Loss: 0.0108\n",
      "Epoch 110/200, Iteration 196/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 197/250, Loss: 0.0297\n",
      "Epoch 110/200, Iteration 198/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 199/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 201/250, Loss: 0.0102\n",
      "Epoch 110/200, Iteration 202/250, Loss: 0.0253\n",
      "Epoch 110/200, Iteration 203/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 204/250, Loss: 0.0129\n",
      "Epoch 110/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 206/250, Loss: 0.0125\n",
      "Epoch 110/200, Iteration 207/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 208/250, Loss: 0.0182\n",
      "Epoch 110/200, Iteration 209/250, Loss: 0.0111\n",
      "Epoch 110/200, Iteration 210/250, Loss: 0.0116\n",
      "Epoch 110/200, Iteration 211/250, Loss: 0.0150\n",
      "Epoch 110/200, Iteration 212/250, Loss: 0.0147\n",
      "Epoch 110/200, Iteration 213/250, Loss: 0.0126\n",
      "Epoch 110/200, Iteration 214/250, Loss: 0.0143\n",
      "Epoch 110/200, Iteration 215/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 216/250, Loss: 0.0074\n",
      "Epoch 110/200, Iteration 217/250, Loss: 0.0204\n",
      "Epoch 110/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 219/250, Loss: 0.0173\n",
      "Epoch 110/200, Iteration 220/250, Loss: 0.0200\n",
      "Epoch 110/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 223/250, Loss: 0.0096\n",
      "Epoch 110/200, Iteration 224/250, Loss: 0.0253\n",
      "Epoch 110/200, Iteration 225/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 226/250, Loss: 0.0057\n",
      "Epoch 110/200, Iteration 227/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 228/250, Loss: 0.0083\n",
      "Epoch 110/200, Iteration 229/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 230/250, Loss: 0.0226\n",
      "Epoch 110/200, Iteration 231/250, Loss: 0.0130\n",
      "Epoch 110/200, Iteration 232/250, Loss: 0.0196\n",
      "Epoch 110/200, Iteration 233/250, Loss: 0.0139\n",
      "Epoch 110/200, Iteration 234/250, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 235/250, Loss: 0.0184\n",
      "Epoch 110/200, Iteration 236/250, Loss: 0.0077\n",
      "Epoch 110/200, Iteration 237/250, Loss: 0.0164\n",
      "Epoch 110/200, Iteration 238/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 239/250, Loss: 0.0085\n",
      "Epoch 110/200, Iteration 240/250, Loss: 0.0261\n",
      "Epoch 110/200, Iteration 241/250, Loss: 0.0087\n",
      "Epoch 110/200, Iteration 242/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 243/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 244/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 110/200, Iteration 246/250, Loss: 0.0220\n",
      "Epoch 110/200, Iteration 247/250, Loss: 0.0068\n",
      "Epoch 110/200, Iteration 248/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 249/250, Loss: 0.0190\n",
      "Epoch 110/200, Iteration 250/250, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 85.99%, Avg loss: 0.006725, MRE: 0.634203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.95%, Avg loss: 0.006806, MRE: 0.983000 \n",
      "\n",
      "Epoch 111/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 111/200, Iteration 2/250, Loss: 0.0082\n",
      "Epoch 111/200, Iteration 3/250, Loss: 0.0200\n",
      "Epoch 111/200, Iteration 4/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 111/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 7/250, Loss: 0.0186\n",
      "Epoch 111/200, Iteration 8/250, Loss: 0.0220\n",
      "Epoch 111/200, Iteration 9/250, Loss: 0.0067\n",
      "Epoch 111/200, Iteration 10/250, Loss: 0.0065\n",
      "Epoch 111/200, Iteration 11/250, Loss: 0.0141\n",
      "Epoch 111/200, Iteration 12/250, Loss: 0.0087\n",
      "Epoch 111/200, Iteration 13/250, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 14/250, Loss: 0.0082\n",
      "Epoch 111/200, Iteration 15/250, Loss: 0.0546\n",
      "Epoch 111/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 111/200, Iteration 17/250, Loss: 0.0093\n",
      "Epoch 111/200, Iteration 18/250, Loss: 0.0183\n",
      "Epoch 111/200, Iteration 19/250, Loss: 0.0110\n",
      "Epoch 111/200, Iteration 20/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 21/250, Loss: 0.0098\n",
      "Epoch 111/200, Iteration 22/250, Loss: 0.0238\n",
      "Epoch 111/200, Iteration 23/250, Loss: 0.0066\n",
      "Epoch 111/200, Iteration 24/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 25/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 26/250, Loss: 0.0148\n",
      "Epoch 111/200, Iteration 27/250, Loss: 0.0130\n",
      "Epoch 111/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 111/200, Iteration 29/250, Loss: 0.0058\n",
      "Epoch 111/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 31/250, Loss: 0.0378\n",
      "Epoch 111/200, Iteration 32/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 33/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 34/250, Loss: 0.0227\n",
      "Epoch 111/200, Iteration 35/250, Loss: 0.0229\n",
      "Epoch 111/200, Iteration 36/250, Loss: 0.0207\n",
      "Epoch 111/200, Iteration 37/250, Loss: 0.0078\n",
      "Epoch 111/200, Iteration 38/250, Loss: 0.0135\n",
      "Epoch 111/200, Iteration 39/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 40/250, Loss: 0.0058\n",
      "Epoch 111/200, Iteration 41/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 43/250, Loss: 0.0107\n",
      "Epoch 111/200, Iteration 44/250, Loss: 0.0252\n",
      "Epoch 111/200, Iteration 45/250, Loss: 0.0133\n",
      "Epoch 111/200, Iteration 46/250, Loss: 0.0249\n",
      "Epoch 111/200, Iteration 47/250, Loss: 0.0127\n",
      "Epoch 111/200, Iteration 48/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 49/250, Loss: 0.0257\n",
      "Epoch 111/200, Iteration 50/250, Loss: 0.0216\n",
      "Epoch 111/200, Iteration 51/250, Loss: 0.0140\n",
      "Epoch 111/200, Iteration 52/250, Loss: 0.0193\n",
      "Epoch 111/200, Iteration 53/250, Loss: 0.0167\n",
      "Epoch 111/200, Iteration 54/250, Loss: 0.0118\n",
      "Epoch 111/200, Iteration 55/250, Loss: 0.0111\n",
      "Epoch 111/200, Iteration 56/250, Loss: 0.0103\n",
      "Epoch 111/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 58/250, Loss: 0.0092\n",
      "Epoch 111/200, Iteration 59/250, Loss: 0.0242\n",
      "Epoch 111/200, Iteration 60/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 61/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 62/250, Loss: 0.0248\n",
      "Epoch 111/200, Iteration 63/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 64/250, Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200, Iteration 65/250, Loss: 0.0213\n",
      "Epoch 111/200, Iteration 66/250, Loss: 0.0115\n",
      "Epoch 111/200, Iteration 67/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 68/250, Loss: 0.0079\n",
      "Epoch 111/200, Iteration 69/250, Loss: 0.0209\n",
      "Epoch 111/200, Iteration 70/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 71/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 72/250, Loss: 0.0171\n",
      "Epoch 111/200, Iteration 73/250, Loss: 0.0169\n",
      "Epoch 111/200, Iteration 74/250, Loss: 0.0216\n",
      "Epoch 111/200, Iteration 75/250, Loss: 0.0135\n",
      "Epoch 111/200, Iteration 76/250, Loss: 0.0175\n",
      "Epoch 111/200, Iteration 77/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 78/250, Loss: 0.0123\n",
      "Epoch 111/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 80/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 81/250, Loss: 0.0136\n",
      "Epoch 111/200, Iteration 82/250, Loss: 0.0155\n",
      "Epoch 111/200, Iteration 83/250, Loss: 0.0214\n",
      "Epoch 111/200, Iteration 84/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 85/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 86/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 87/250, Loss: 0.0131\n",
      "Epoch 111/200, Iteration 88/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 89/250, Loss: 0.0206\n",
      "Epoch 111/200, Iteration 90/250, Loss: 0.0184\n",
      "Epoch 111/200, Iteration 91/250, Loss: 0.0089\n",
      "Epoch 111/200, Iteration 92/250, Loss: 0.0109\n",
      "Epoch 111/200, Iteration 93/250, Loss: 0.0201\n",
      "Epoch 111/200, Iteration 94/250, Loss: 0.0228\n",
      "Epoch 111/200, Iteration 95/250, Loss: 0.0327\n",
      "Epoch 111/200, Iteration 96/250, Loss: 0.0074\n",
      "Epoch 111/200, Iteration 97/250, Loss: 0.0149\n",
      "Epoch 111/200, Iteration 98/250, Loss: 0.0101\n",
      "Epoch 111/200, Iteration 99/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 100/250, Loss: 0.0144\n",
      "Epoch 111/200, Iteration 101/250, Loss: 0.0097\n",
      "Epoch 111/200, Iteration 102/250, Loss: 0.0270\n",
      "Epoch 111/200, Iteration 103/250, Loss: 0.0069\n",
      "Epoch 111/200, Iteration 104/250, Loss: 0.0093\n",
      "Epoch 111/200, Iteration 105/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 106/250, Loss: 0.0098\n",
      "Epoch 111/200, Iteration 107/250, Loss: 0.0246\n",
      "Epoch 111/200, Iteration 108/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 109/250, Loss: 0.0075\n",
      "Epoch 111/200, Iteration 110/250, Loss: 0.0093\n",
      "Epoch 111/200, Iteration 111/250, Loss: 0.0151\n",
      "Epoch 111/200, Iteration 112/250, Loss: 0.0292\n",
      "Epoch 111/200, Iteration 113/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 114/250, Loss: 0.0175\n",
      "Epoch 111/200, Iteration 115/250, Loss: 0.0262\n",
      "Epoch 111/200, Iteration 116/250, Loss: 0.0068\n",
      "Epoch 111/200, Iteration 117/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 119/250, Loss: 0.0110\n",
      "Epoch 111/200, Iteration 120/250, Loss: 0.0253\n",
      "Epoch 111/200, Iteration 121/250, Loss: 0.0192\n",
      "Epoch 111/200, Iteration 122/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 123/250, Loss: 0.0148\n",
      "Epoch 111/200, Iteration 124/250, Loss: 0.0508\n",
      "Epoch 111/200, Iteration 125/250, Loss: 0.0080\n",
      "Epoch 111/200, Iteration 126/250, Loss: 0.0164\n",
      "Epoch 111/200, Iteration 127/250, Loss: 0.0174\n",
      "Epoch 111/200, Iteration 128/250, Loss: 0.0166\n",
      "Epoch 111/200, Iteration 129/250, Loss: 0.0133\n",
      "Epoch 111/200, Iteration 130/250, Loss: 0.0071\n",
      "Epoch 111/200, Iteration 131/250, Loss: 0.0339\n",
      "Epoch 111/200, Iteration 132/250, Loss: 0.0238\n",
      "Epoch 111/200, Iteration 133/250, Loss: 0.0120\n",
      "Epoch 111/200, Iteration 134/250, Loss: 0.0081\n",
      "Epoch 111/200, Iteration 135/250, Loss: 0.0076\n",
      "Epoch 111/200, Iteration 136/250, Loss: 0.0115\n",
      "Epoch 111/200, Iteration 137/250, Loss: 0.0115\n",
      "Epoch 111/200, Iteration 138/250, Loss: 0.0108\n",
      "Epoch 111/200, Iteration 139/250, Loss: 0.0073\n",
      "Epoch 111/200, Iteration 140/250, Loss: 0.0171\n",
      "Epoch 111/200, Iteration 141/250, Loss: 0.0090\n",
      "Epoch 111/200, Iteration 142/250, Loss: 0.0246\n",
      "Epoch 111/200, Iteration 143/250, Loss: 0.0079\n",
      "Epoch 111/200, Iteration 144/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 145/250, Loss: 0.0249\n",
      "Epoch 111/200, Iteration 146/250, Loss: 0.0054\n",
      "Epoch 111/200, Iteration 147/250, Loss: 0.0290\n",
      "Epoch 111/200, Iteration 148/250, Loss: 0.0266\n",
      "Epoch 111/200, Iteration 149/250, Loss: 0.0148\n",
      "Epoch 111/200, Iteration 150/250, Loss: 0.0242\n",
      "Epoch 111/200, Iteration 151/250, Loss: 0.0120\n",
      "Epoch 111/200, Iteration 152/250, Loss: 0.0175\n",
      "Epoch 111/200, Iteration 153/250, Loss: 0.0157\n",
      "Epoch 111/200, Iteration 154/250, Loss: 0.0192\n",
      "Epoch 111/200, Iteration 155/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 156/250, Loss: 0.0218\n",
      "Epoch 111/200, Iteration 157/250, Loss: 0.0157\n",
      "Epoch 111/200, Iteration 158/250, Loss: 0.0339\n",
      "Epoch 111/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 111/200, Iteration 161/250, Loss: 0.0144\n",
      "Epoch 111/200, Iteration 162/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 163/250, Loss: 0.0314\n",
      "Epoch 111/200, Iteration 164/250, Loss: 0.0074\n",
      "Epoch 111/200, Iteration 165/250, Loss: 0.0439\n",
      "Epoch 111/200, Iteration 166/250, Loss: 0.0073\n",
      "Epoch 111/200, Iteration 167/250, Loss: 0.0134\n",
      "Epoch 111/200, Iteration 168/250, Loss: 0.0143\n",
      "Epoch 111/200, Iteration 169/250, Loss: 0.0278\n",
      "Epoch 111/200, Iteration 170/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 171/250, Loss: 0.0190\n",
      "Epoch 111/200, Iteration 172/250, Loss: 0.0086\n",
      "Epoch 111/200, Iteration 173/250, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 174/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 175/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 176/250, Loss: 0.0259\n",
      "Epoch 111/200, Iteration 177/250, Loss: 0.0147\n",
      "Epoch 111/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 111/200, Iteration 179/250, Loss: 0.0164\n",
      "Epoch 111/200, Iteration 180/250, Loss: 0.0108\n",
      "Epoch 111/200, Iteration 181/250, Loss: 0.0087\n",
      "Epoch 111/200, Iteration 182/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 183/250, Loss: 0.0107\n",
      "Epoch 111/200, Iteration 184/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 185/250, Loss: 0.0113\n",
      "Epoch 111/200, Iteration 186/250, Loss: 0.0258\n",
      "Epoch 111/200, Iteration 187/250, Loss: 0.0134\n",
      "Epoch 111/200, Iteration 188/250, Loss: 0.0167\n",
      "Epoch 111/200, Iteration 189/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 190/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 191/250, Loss: 0.0179\n",
      "Epoch 111/200, Iteration 192/250, Loss: 0.0103\n",
      "Epoch 111/200, Iteration 193/250, Loss: 0.0150\n",
      "Epoch 111/200, Iteration 194/250, Loss: 0.0108\n",
      "Epoch 111/200, Iteration 195/250, Loss: 0.0152\n",
      "Epoch 111/200, Iteration 196/250, Loss: 0.0239\n",
      "Epoch 111/200, Iteration 197/250, Loss: 0.0227\n",
      "Epoch 111/200, Iteration 198/250, Loss: 0.0150\n",
      "Epoch 111/200, Iteration 199/250, Loss: 0.0166\n",
      "Epoch 111/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 201/250, Loss: 0.0084\n",
      "Epoch 111/200, Iteration 202/250, Loss: 0.0255\n",
      "Epoch 111/200, Iteration 203/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 204/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 205/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 206/250, Loss: 0.0093\n",
      "Epoch 111/200, Iteration 207/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 208/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 209/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 210/250, Loss: 0.0091\n",
      "Epoch 111/200, Iteration 211/250, Loss: 0.0161\n",
      "Epoch 111/200, Iteration 212/250, Loss: 0.0130\n",
      "Epoch 111/200, Iteration 213/250, Loss: 0.0191\n",
      "Epoch 111/200, Iteration 214/250, Loss: 0.0148\n",
      "Epoch 111/200, Iteration 215/250, Loss: 0.0089\n",
      "Epoch 111/200, Iteration 216/250, Loss: 0.0442\n",
      "Epoch 111/200, Iteration 217/250, Loss: 0.0138\n",
      "Epoch 111/200, Iteration 218/250, Loss: 0.0080\n",
      "Epoch 111/200, Iteration 219/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 220/250, Loss: 0.0147\n",
      "Epoch 111/200, Iteration 221/250, Loss: 0.0136\n",
      "Epoch 111/200, Iteration 222/250, Loss: 0.0140\n",
      "Epoch 111/200, Iteration 223/250, Loss: 0.0069\n",
      "Epoch 111/200, Iteration 224/250, Loss: 0.0120\n",
      "Epoch 111/200, Iteration 225/250, Loss: 0.0097\n",
      "Epoch 111/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 111/200, Iteration 227/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 228/250, Loss: 0.0089\n",
      "Epoch 111/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 230/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 232/250, Loss: 0.0109\n",
      "Epoch 111/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 234/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 235/250, Loss: 0.0291\n",
      "Epoch 111/200, Iteration 236/250, Loss: 0.0143\n",
      "Epoch 111/200, Iteration 237/250, Loss: 0.0230\n",
      "Epoch 111/200, Iteration 238/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 239/250, Loss: 0.0192\n",
      "Epoch 111/200, Iteration 240/250, Loss: 0.0159\n",
      "Epoch 111/200, Iteration 241/250, Loss: 0.0165\n",
      "Epoch 111/200, Iteration 242/250, Loss: 0.0143\n",
      "Epoch 111/200, Iteration 243/250, Loss: 0.0112\n",
      "Epoch 111/200, Iteration 244/250, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200, Iteration 245/250, Loss: 0.0078\n",
      "Epoch 111/200, Iteration 246/250, Loss: 0.0435\n",
      "Epoch 111/200, Iteration 247/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 248/250, Loss: 0.0095\n",
      "Epoch 111/200, Iteration 249/250, Loss: 0.0224\n",
      "Epoch 111/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 93.27%, Avg loss: 0.005860, MRE: 0.609185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.005877, MRE: 0.960391 \n",
      "\n",
      "Epoch 112/200, Iteration 1/250, Loss: 0.0123\n",
      "Epoch 112/200, Iteration 2/250, Loss: 0.0166\n",
      "Epoch 112/200, Iteration 3/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 4/250, Loss: 0.0064\n",
      "Epoch 112/200, Iteration 5/250, Loss: 0.0263\n",
      "Epoch 112/200, Iteration 6/250, Loss: 0.0188\n",
      "Epoch 112/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 112/200, Iteration 8/250, Loss: 0.0070\n",
      "Epoch 112/200, Iteration 9/250, Loss: 0.0084\n",
      "Epoch 112/200, Iteration 10/250, Loss: 0.0114\n",
      "Epoch 112/200, Iteration 11/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 12/250, Loss: 0.0082\n",
      "Epoch 112/200, Iteration 13/250, Loss: 0.0134\n",
      "Epoch 112/200, Iteration 14/250, Loss: 0.0097\n",
      "Epoch 112/200, Iteration 15/250, Loss: 0.0198\n",
      "Epoch 112/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 112/200, Iteration 17/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 18/250, Loss: 0.0154\n",
      "Epoch 112/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 112/200, Iteration 20/250, Loss: 0.0174\n",
      "Epoch 112/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 22/250, Loss: 0.0231\n",
      "Epoch 112/200, Iteration 23/250, Loss: 0.0083\n",
      "Epoch 112/200, Iteration 24/250, Loss: 0.0141\n",
      "Epoch 112/200, Iteration 25/250, Loss: 0.0115\n",
      "Epoch 112/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 112/200, Iteration 27/250, Loss: 0.0168\n",
      "Epoch 112/200, Iteration 28/250, Loss: 0.0062\n",
      "Epoch 112/200, Iteration 29/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 30/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 31/250, Loss: 0.0166\n",
      "Epoch 112/200, Iteration 32/250, Loss: 0.0184\n",
      "Epoch 112/200, Iteration 33/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 34/250, Loss: 0.0135\n",
      "Epoch 112/200, Iteration 35/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 36/250, Loss: 0.0226\n",
      "Epoch 112/200, Iteration 37/250, Loss: 0.0132\n",
      "Epoch 112/200, Iteration 38/250, Loss: 0.0270\n",
      "Epoch 112/200, Iteration 39/250, Loss: 0.0137\n",
      "Epoch 112/200, Iteration 40/250, Loss: 0.0157\n",
      "Epoch 112/200, Iteration 41/250, Loss: 0.0108\n",
      "Epoch 112/200, Iteration 42/250, Loss: 0.0086\n",
      "Epoch 112/200, Iteration 43/250, Loss: 0.0140\n",
      "Epoch 112/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 112/200, Iteration 45/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 46/250, Loss: 0.0056\n",
      "Epoch 112/200, Iteration 47/250, Loss: 0.0120\n",
      "Epoch 112/200, Iteration 48/250, Loss: 0.0097\n",
      "Epoch 112/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 50/250, Loss: 0.0086\n",
      "Epoch 112/200, Iteration 51/250, Loss: 0.0187\n",
      "Epoch 112/200, Iteration 52/250, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 53/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 54/250, Loss: 0.0096\n",
      "Epoch 112/200, Iteration 55/250, Loss: 0.0234\n",
      "Epoch 112/200, Iteration 56/250, Loss: 0.0065\n",
      "Epoch 112/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 112/200, Iteration 58/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 112/200, Iteration 60/250, Loss: 0.0124\n",
      "Epoch 112/200, Iteration 61/250, Loss: 0.0218\n",
      "Epoch 112/200, Iteration 62/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 63/250, Loss: 0.0186\n",
      "Epoch 112/200, Iteration 64/250, Loss: 0.0060\n",
      "Epoch 112/200, Iteration 65/250, Loss: 0.0137\n",
      "Epoch 112/200, Iteration 66/250, Loss: 0.0090\n",
      "Epoch 112/200, Iteration 67/250, Loss: 0.0156\n",
      "Epoch 112/200, Iteration 68/250, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 69/250, Loss: 0.0170\n",
      "Epoch 112/200, Iteration 70/250, Loss: 0.0135\n",
      "Epoch 112/200, Iteration 71/250, Loss: 0.0082\n",
      "Epoch 112/200, Iteration 72/250, Loss: 0.0144\n",
      "Epoch 112/200, Iteration 73/250, Loss: 0.0239\n",
      "Epoch 112/200, Iteration 74/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 75/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 76/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 77/250, Loss: 0.0351\n",
      "Epoch 112/200, Iteration 78/250, Loss: 0.0255\n",
      "Epoch 112/200, Iteration 79/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 80/250, Loss: 0.0107\n",
      "Epoch 112/200, Iteration 81/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 82/250, Loss: 0.0178\n",
      "Epoch 112/200, Iteration 83/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 84/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 85/250, Loss: 0.0110\n",
      "Epoch 112/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 87/250, Loss: 0.0156\n",
      "Epoch 112/200, Iteration 88/250, Loss: 0.0148\n",
      "Epoch 112/200, Iteration 89/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 90/250, Loss: 0.0186\n",
      "Epoch 112/200, Iteration 91/250, Loss: 0.0128\n",
      "Epoch 112/200, Iteration 92/250, Loss: 0.0191\n",
      "Epoch 112/200, Iteration 93/250, Loss: 0.0187\n",
      "Epoch 112/200, Iteration 94/250, Loss: 0.0185\n",
      "Epoch 112/200, Iteration 95/250, Loss: 0.0248\n",
      "Epoch 112/200, Iteration 96/250, Loss: 0.0292\n",
      "Epoch 112/200, Iteration 97/250, Loss: 0.0074\n",
      "Epoch 112/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 99/250, Loss: 0.0262\n",
      "Epoch 112/200, Iteration 100/250, Loss: 0.0068\n",
      "Epoch 112/200, Iteration 101/250, Loss: 0.0327\n",
      "Epoch 112/200, Iteration 102/250, Loss: 0.0141\n",
      "Epoch 112/200, Iteration 103/250, Loss: 0.0144\n",
      "Epoch 112/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 105/250, Loss: 0.0167\n",
      "Epoch 112/200, Iteration 106/250, Loss: 0.0197\n",
      "Epoch 112/200, Iteration 107/250, Loss: 0.0243\n",
      "Epoch 112/200, Iteration 108/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 109/250, Loss: 0.0120\n",
      "Epoch 112/200, Iteration 110/250, Loss: 0.0181\n",
      "Epoch 112/200, Iteration 111/250, Loss: 0.0130\n",
      "Epoch 112/200, Iteration 112/250, Loss: 0.0138\n",
      "Epoch 112/200, Iteration 113/250, Loss: 0.0245\n",
      "Epoch 112/200, Iteration 114/250, Loss: 0.0324\n",
      "Epoch 112/200, Iteration 115/250, Loss: 0.0312\n",
      "Epoch 112/200, Iteration 116/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 117/250, Loss: 0.0135\n",
      "Epoch 112/200, Iteration 118/250, Loss: 0.0065\n",
      "Epoch 112/200, Iteration 119/250, Loss: 0.0142\n",
      "Epoch 112/200, Iteration 120/250, Loss: 0.0171\n",
      "Epoch 112/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 112/200, Iteration 122/250, Loss: 0.0250\n",
      "Epoch 112/200, Iteration 123/250, Loss: 0.0276\n",
      "Epoch 112/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 112/200, Iteration 125/250, Loss: 0.0408\n",
      "Epoch 112/200, Iteration 126/250, Loss: 0.0140\n",
      "Epoch 112/200, Iteration 127/250, Loss: 0.0237\n",
      "Epoch 112/200, Iteration 128/250, Loss: 0.0230\n",
      "Epoch 112/200, Iteration 129/250, Loss: 0.0170\n",
      "Epoch 112/200, Iteration 130/250, Loss: 0.0100\n",
      "Epoch 112/200, Iteration 131/250, Loss: 0.0081\n",
      "Epoch 112/200, Iteration 132/250, Loss: 0.0157\n",
      "Epoch 112/200, Iteration 133/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 112/200, Iteration 135/250, Loss: 0.0313\n",
      "Epoch 112/200, Iteration 136/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 137/250, Loss: 0.0069\n",
      "Epoch 112/200, Iteration 138/250, Loss: 0.0153\n",
      "Epoch 112/200, Iteration 139/250, Loss: 0.0063\n",
      "Epoch 112/200, Iteration 140/250, Loss: 0.0210\n",
      "Epoch 112/200, Iteration 141/250, Loss: 0.0234\n",
      "Epoch 112/200, Iteration 142/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 143/250, Loss: 0.0147\n",
      "Epoch 112/200, Iteration 144/250, Loss: 0.0236\n",
      "Epoch 112/200, Iteration 145/250, Loss: 0.0213\n",
      "Epoch 112/200, Iteration 146/250, Loss: 0.0127\n",
      "Epoch 112/200, Iteration 147/250, Loss: 0.0224\n",
      "Epoch 112/200, Iteration 148/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 149/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 150/250, Loss: 0.0074\n",
      "Epoch 112/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 152/250, Loss: 0.0123\n",
      "Epoch 112/200, Iteration 153/250, Loss: 0.0139\n",
      "Epoch 112/200, Iteration 154/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 155/250, Loss: 0.0064\n",
      "Epoch 112/200, Iteration 156/250, Loss: 0.0277\n",
      "Epoch 112/200, Iteration 157/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 158/250, Loss: 0.0193\n",
      "Epoch 112/200, Iteration 159/250, Loss: 0.0078\n",
      "Epoch 112/200, Iteration 160/250, Loss: 0.0112\n",
      "Epoch 112/200, Iteration 161/250, Loss: 0.0284\n",
      "Epoch 112/200, Iteration 162/250, Loss: 0.0089\n",
      "Epoch 112/200, Iteration 163/250, Loss: 0.0232\n",
      "Epoch 112/200, Iteration 164/250, Loss: 0.0158\n",
      "Epoch 112/200, Iteration 165/250, Loss: 0.0052\n",
      "Epoch 112/200, Iteration 166/250, Loss: 0.0128\n",
      "Epoch 112/200, Iteration 167/250, Loss: 0.0177\n",
      "Epoch 112/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 169/250, Loss: 0.0129\n",
      "Epoch 112/200, Iteration 170/250, Loss: 0.0124\n",
      "Epoch 112/200, Iteration 171/250, Loss: 0.0153\n",
      "Epoch 112/200, Iteration 172/250, Loss: 0.0145\n",
      "Epoch 112/200, Iteration 173/250, Loss: 0.0123\n",
      "Epoch 112/200, Iteration 174/250, Loss: 0.0164\n",
      "Epoch 112/200, Iteration 175/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 176/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 177/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 178/250, Loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200, Iteration 179/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 180/250, Loss: 0.0226\n",
      "Epoch 112/200, Iteration 181/250, Loss: 0.0066\n",
      "Epoch 112/200, Iteration 182/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 183/250, Loss: 0.0113\n",
      "Epoch 112/200, Iteration 184/250, Loss: 0.0243\n",
      "Epoch 112/200, Iteration 185/250, Loss: 0.0238\n",
      "Epoch 112/200, Iteration 186/250, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 187/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 188/250, Loss: 0.0133\n",
      "Epoch 112/200, Iteration 189/250, Loss: 0.0090\n",
      "Epoch 112/200, Iteration 190/250, Loss: 0.0212\n",
      "Epoch 112/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 112/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 112/200, Iteration 193/250, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 195/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 196/250, Loss: 0.0107\n",
      "Epoch 112/200, Iteration 197/250, Loss: 0.0119\n",
      "Epoch 112/200, Iteration 198/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 199/250, Loss: 0.0164\n",
      "Epoch 112/200, Iteration 200/250, Loss: 0.0159\n",
      "Epoch 112/200, Iteration 201/250, Loss: 0.0068\n",
      "Epoch 112/200, Iteration 202/250, Loss: 0.0198\n",
      "Epoch 112/200, Iteration 203/250, Loss: 0.0160\n",
      "Epoch 112/200, Iteration 204/250, Loss: 0.0119\n",
      "Epoch 112/200, Iteration 205/250, Loss: 0.0169\n",
      "Epoch 112/200, Iteration 206/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 207/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 208/250, Loss: 0.0189\n",
      "Epoch 112/200, Iteration 209/250, Loss: 0.0059\n",
      "Epoch 112/200, Iteration 210/250, Loss: 0.0189\n",
      "Epoch 112/200, Iteration 211/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 212/250, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 213/250, Loss: 0.0159\n",
      "Epoch 112/200, Iteration 214/250, Loss: 0.0065\n",
      "Epoch 112/200, Iteration 215/250, Loss: 0.0114\n",
      "Epoch 112/200, Iteration 216/250, Loss: 0.0311\n",
      "Epoch 112/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 112/200, Iteration 218/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 112/200, Iteration 220/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 221/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 222/250, Loss: 0.0118\n",
      "Epoch 112/200, Iteration 223/250, Loss: 0.0082\n",
      "Epoch 112/200, Iteration 224/250, Loss: 0.0112\n",
      "Epoch 112/200, Iteration 225/250, Loss: 0.0166\n",
      "Epoch 112/200, Iteration 226/250, Loss: 0.0144\n",
      "Epoch 112/200, Iteration 227/250, Loss: 0.0189\n",
      "Epoch 112/200, Iteration 228/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 229/250, Loss: 0.0137\n",
      "Epoch 112/200, Iteration 230/250, Loss: 0.0240\n",
      "Epoch 112/200, Iteration 231/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 232/250, Loss: 0.0252\n",
      "Epoch 112/200, Iteration 233/250, Loss: 0.0126\n",
      "Epoch 112/200, Iteration 234/250, Loss: 0.0145\n",
      "Epoch 112/200, Iteration 235/250, Loss: 0.0128\n",
      "Epoch 112/200, Iteration 236/250, Loss: 0.0112\n",
      "Epoch 112/200, Iteration 237/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 238/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 239/250, Loss: 0.0082\n",
      "Epoch 112/200, Iteration 240/250, Loss: 0.0204\n",
      "Epoch 112/200, Iteration 241/250, Loss: 0.0167\n",
      "Epoch 112/200, Iteration 242/250, Loss: 0.0136\n",
      "Epoch 112/200, Iteration 243/250, Loss: 0.0105\n",
      "Epoch 112/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 245/250, Loss: 0.0183\n",
      "Epoch 112/200, Iteration 246/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 247/250, Loss: 0.0367\n",
      "Epoch 112/200, Iteration 248/250, Loss: 0.0174\n",
      "Epoch 112/200, Iteration 249/250, Loss: 0.0125\n",
      "Epoch 112/200, Iteration 250/250, Loss: 0.0288\n",
      "Train Error: \n",
      " Accuracy: 78.06%, Avg loss: 0.007515, MRE: 0.658322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.35%, Avg loss: 0.007575, MRE: 0.883557 \n",
      "\n",
      "Epoch 113/200, Iteration 1/250, Loss: 0.0299\n",
      "Epoch 113/200, Iteration 2/250, Loss: 0.0109\n",
      "Epoch 113/200, Iteration 3/250, Loss: 0.0148\n",
      "Epoch 113/200, Iteration 4/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 5/250, Loss: 0.0129\n",
      "Epoch 113/200, Iteration 6/250, Loss: 0.0142\n",
      "Epoch 113/200, Iteration 7/250, Loss: 0.0056\n",
      "Epoch 113/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 113/200, Iteration 10/250, Loss: 0.0110\n",
      "Epoch 113/200, Iteration 11/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 12/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 13/250, Loss: 0.0391\n",
      "Epoch 113/200, Iteration 14/250, Loss: 0.0177\n",
      "Epoch 113/200, Iteration 15/250, Loss: 0.0078\n",
      "Epoch 113/200, Iteration 16/250, Loss: 0.0096\n",
      "Epoch 113/200, Iteration 17/250, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 18/250, Loss: 0.0152\n",
      "Epoch 113/200, Iteration 19/250, Loss: 0.0272\n",
      "Epoch 113/200, Iteration 20/250, Loss: 0.0128\n",
      "Epoch 113/200, Iteration 21/250, Loss: 0.0064\n",
      "Epoch 113/200, Iteration 22/250, Loss: 0.0154\n",
      "Epoch 113/200, Iteration 23/250, Loss: 0.0238\n",
      "Epoch 113/200, Iteration 24/250, Loss: 0.0213\n",
      "Epoch 113/200, Iteration 25/250, Loss: 0.0210\n",
      "Epoch 113/200, Iteration 26/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 113/200, Iteration 28/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 29/250, Loss: 0.0151\n",
      "Epoch 113/200, Iteration 30/250, Loss: 0.0096\n",
      "Epoch 113/200, Iteration 31/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 32/250, Loss: 0.0113\n",
      "Epoch 113/200, Iteration 33/250, Loss: 0.0201\n",
      "Epoch 113/200, Iteration 34/250, Loss: 0.0067\n",
      "Epoch 113/200, Iteration 35/250, Loss: 0.0068\n",
      "Epoch 113/200, Iteration 36/250, Loss: 0.0131\n",
      "Epoch 113/200, Iteration 37/250, Loss: 0.0118\n",
      "Epoch 113/200, Iteration 38/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 39/250, Loss: 0.0156\n",
      "Epoch 113/200, Iteration 40/250, Loss: 0.0082\n",
      "Epoch 113/200, Iteration 41/250, Loss: 0.0237\n",
      "Epoch 113/200, Iteration 42/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 43/250, Loss: 0.0195\n",
      "Epoch 113/200, Iteration 44/250, Loss: 0.0086\n",
      "Epoch 113/200, Iteration 45/250, Loss: 0.0098\n",
      "Epoch 113/200, Iteration 46/250, Loss: 0.0072\n",
      "Epoch 113/200, Iteration 47/250, Loss: 0.0116\n",
      "Epoch 113/200, Iteration 48/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 49/250, Loss: 0.0272\n",
      "Epoch 113/200, Iteration 50/250, Loss: 0.0110\n",
      "Epoch 113/200, Iteration 51/250, Loss: 0.0122\n",
      "Epoch 113/200, Iteration 52/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 53/250, Loss: 0.0115\n",
      "Epoch 113/200, Iteration 54/250, Loss: 0.0313\n",
      "Epoch 113/200, Iteration 55/250, Loss: 0.0147\n",
      "Epoch 113/200, Iteration 56/250, Loss: 0.0115\n",
      "Epoch 113/200, Iteration 57/250, Loss: 0.0372\n",
      "Epoch 113/200, Iteration 58/250, Loss: 0.0119\n",
      "Epoch 113/200, Iteration 59/250, Loss: 0.0062\n",
      "Epoch 113/200, Iteration 60/250, Loss: 0.0122\n",
      "Epoch 113/200, Iteration 61/250, Loss: 0.0065\n",
      "Epoch 113/200, Iteration 62/250, Loss: 0.0370\n",
      "Epoch 113/200, Iteration 63/250, Loss: 0.0149\n",
      "Epoch 113/200, Iteration 64/250, Loss: 0.0115\n",
      "Epoch 113/200, Iteration 65/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 66/250, Loss: 0.0141\n",
      "Epoch 113/200, Iteration 67/250, Loss: 0.0146\n",
      "Epoch 113/200, Iteration 68/250, Loss: 0.0102\n",
      "Epoch 113/200, Iteration 69/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 70/250, Loss: 0.0187\n",
      "Epoch 113/200, Iteration 71/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 72/250, Loss: 0.0215\n",
      "Epoch 113/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 113/200, Iteration 74/250, Loss: 0.0451\n",
      "Epoch 113/200, Iteration 75/250, Loss: 0.0076\n",
      "Epoch 113/200, Iteration 76/250, Loss: 0.0102\n",
      "Epoch 113/200, Iteration 77/250, Loss: 0.0129\n",
      "Epoch 113/200, Iteration 78/250, Loss: 0.0069\n",
      "Epoch 113/200, Iteration 79/250, Loss: 0.0134\n",
      "Epoch 113/200, Iteration 80/250, Loss: 0.0177\n",
      "Epoch 113/200, Iteration 81/250, Loss: 0.0089\n",
      "Epoch 113/200, Iteration 82/250, Loss: 0.0104\n",
      "Epoch 113/200, Iteration 83/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 84/250, Loss: 0.0081\n",
      "Epoch 113/200, Iteration 85/250, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 86/250, Loss: 0.0142\n",
      "Epoch 113/200, Iteration 87/250, Loss: 0.0171\n",
      "Epoch 113/200, Iteration 88/250, Loss: 0.0076\n",
      "Epoch 113/200, Iteration 89/250, Loss: 0.0242\n",
      "Epoch 113/200, Iteration 90/250, Loss: 0.0176\n",
      "Epoch 113/200, Iteration 91/250, Loss: 0.0292\n",
      "Epoch 113/200, Iteration 92/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 93/250, Loss: 0.0150\n",
      "Epoch 113/200, Iteration 94/250, Loss: 0.0080\n",
      "Epoch 113/200, Iteration 95/250, Loss: 0.0077\n",
      "Epoch 113/200, Iteration 96/250, Loss: 0.0167\n",
      "Epoch 113/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 113/200, Iteration 98/250, Loss: 0.0081\n",
      "Epoch 113/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 113/200, Iteration 100/250, Loss: 0.0145\n",
      "Epoch 113/200, Iteration 101/250, Loss: 0.0065\n",
      "Epoch 113/200, Iteration 102/250, Loss: 0.0157\n",
      "Epoch 113/200, Iteration 103/250, Loss: 0.0146\n",
      "Epoch 113/200, Iteration 104/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 105/250, Loss: 0.0157\n",
      "Epoch 113/200, Iteration 106/250, Loss: 0.0189\n",
      "Epoch 113/200, Iteration 107/250, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 108/250, Loss: 0.0113\n",
      "Epoch 113/200, Iteration 109/250, Loss: 0.0079\n",
      "Epoch 113/200, Iteration 110/250, Loss: 0.0194\n",
      "Epoch 113/200, Iteration 111/250, Loss: 0.0223\n",
      "Epoch 113/200, Iteration 112/250, Loss: 0.0101\n",
      "Epoch 113/200, Iteration 113/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 114/250, Loss: 0.0236\n",
      "Epoch 113/200, Iteration 115/250, Loss: 0.0160\n",
      "Epoch 113/200, Iteration 116/250, Loss: 0.0093\n",
      "Epoch 113/200, Iteration 117/250, Loss: 0.0110\n",
      "Epoch 113/200, Iteration 118/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 119/250, Loss: 0.0172\n",
      "Epoch 113/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 113/200, Iteration 121/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200, Iteration 122/250, Loss: 0.0099\n",
      "Epoch 113/200, Iteration 123/250, Loss: 0.0330\n",
      "Epoch 113/200, Iteration 124/250, Loss: 0.0068\n",
      "Epoch 113/200, Iteration 125/250, Loss: 0.0181\n",
      "Epoch 113/200, Iteration 126/250, Loss: 0.0076\n",
      "Epoch 113/200, Iteration 127/250, Loss: 0.0232\n",
      "Epoch 113/200, Iteration 128/250, Loss: 0.0262\n",
      "Epoch 113/200, Iteration 129/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 130/250, Loss: 0.0289\n",
      "Epoch 113/200, Iteration 131/250, Loss: 0.0195\n",
      "Epoch 113/200, Iteration 132/250, Loss: 0.0285\n",
      "Epoch 113/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 134/250, Loss: 0.0468\n",
      "Epoch 113/200, Iteration 135/250, Loss: 0.0147\n",
      "Epoch 113/200, Iteration 136/250, Loss: 0.0288\n",
      "Epoch 113/200, Iteration 137/250, Loss: 0.0209\n",
      "Epoch 113/200, Iteration 138/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 139/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 140/250, Loss: 0.0127\n",
      "Epoch 113/200, Iteration 141/250, Loss: 0.0075\n",
      "Epoch 113/200, Iteration 142/250, Loss: 0.0229\n",
      "Epoch 113/200, Iteration 143/250, Loss: 0.0161\n",
      "Epoch 113/200, Iteration 144/250, Loss: 0.0101\n",
      "Epoch 113/200, Iteration 145/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 146/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 147/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 148/250, Loss: 0.0118\n",
      "Epoch 113/200, Iteration 149/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 150/250, Loss: 0.0325\n",
      "Epoch 113/200, Iteration 151/250, Loss: 0.0142\n",
      "Epoch 113/200, Iteration 152/250, Loss: 0.0078\n",
      "Epoch 113/200, Iteration 153/250, Loss: 0.0073\n",
      "Epoch 113/200, Iteration 154/250, Loss: 0.0154\n",
      "Epoch 113/200, Iteration 155/250, Loss: 0.0081\n",
      "Epoch 113/200, Iteration 156/250, Loss: 0.0141\n",
      "Epoch 113/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 113/200, Iteration 158/250, Loss: 0.0126\n",
      "Epoch 113/200, Iteration 159/250, Loss: 0.0067\n",
      "Epoch 113/200, Iteration 160/250, Loss: 0.0076\n",
      "Epoch 113/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 113/200, Iteration 162/250, Loss: 0.0145\n",
      "Epoch 113/200, Iteration 163/250, Loss: 0.0333\n",
      "Epoch 113/200, Iteration 164/250, Loss: 0.0105\n",
      "Epoch 113/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 113/200, Iteration 166/250, Loss: 0.0072\n",
      "Epoch 113/200, Iteration 167/250, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 168/250, Loss: 0.0192\n",
      "Epoch 113/200, Iteration 169/250, Loss: 0.0071\n",
      "Epoch 113/200, Iteration 170/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 171/250, Loss: 0.0272\n",
      "Epoch 113/200, Iteration 172/250, Loss: 0.0126\n",
      "Epoch 113/200, Iteration 173/250, Loss: 0.0097\n",
      "Epoch 113/200, Iteration 174/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 175/250, Loss: 0.0372\n",
      "Epoch 113/200, Iteration 176/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 177/250, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 178/250, Loss: 0.0130\n",
      "Epoch 113/200, Iteration 179/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 180/250, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 181/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 182/250, Loss: 0.0175\n",
      "Epoch 113/200, Iteration 183/250, Loss: 0.0114\n",
      "Epoch 113/200, Iteration 184/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 185/250, Loss: 0.0406\n",
      "Epoch 113/200, Iteration 186/250, Loss: 0.0197\n",
      "Epoch 113/200, Iteration 187/250, Loss: 0.0192\n",
      "Epoch 113/200, Iteration 188/250, Loss: 0.0184\n",
      "Epoch 113/200, Iteration 189/250, Loss: 0.0149\n",
      "Epoch 113/200, Iteration 190/250, Loss: 0.0169\n",
      "Epoch 113/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 113/200, Iteration 192/250, Loss: 0.0156\n",
      "Epoch 113/200, Iteration 193/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 194/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 195/250, Loss: 0.0199\n",
      "Epoch 113/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 113/200, Iteration 197/250, Loss: 0.0326\n",
      "Epoch 113/200, Iteration 198/250, Loss: 0.0139\n",
      "Epoch 113/200, Iteration 199/250, Loss: 0.0135\n",
      "Epoch 113/200, Iteration 200/250, Loss: 0.0154\n",
      "Epoch 113/200, Iteration 201/250, Loss: 0.0181\n",
      "Epoch 113/200, Iteration 202/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 203/250, Loss: 0.0191\n",
      "Epoch 113/200, Iteration 204/250, Loss: 0.0145\n",
      "Epoch 113/200, Iteration 205/250, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 206/250, Loss: 0.0150\n",
      "Epoch 113/200, Iteration 207/250, Loss: 0.0149\n",
      "Epoch 113/200, Iteration 208/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 209/250, Loss: 0.0082\n",
      "Epoch 113/200, Iteration 210/250, Loss: 0.0176\n",
      "Epoch 113/200, Iteration 211/250, Loss: 0.0185\n",
      "Epoch 113/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 113/200, Iteration 213/250, Loss: 0.0135\n",
      "Epoch 113/200, Iteration 214/250, Loss: 0.0108\n",
      "Epoch 113/200, Iteration 215/250, Loss: 0.0312\n",
      "Epoch 113/200, Iteration 216/250, Loss: 0.0145\n",
      "Epoch 113/200, Iteration 217/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 218/250, Loss: 0.0153\n",
      "Epoch 113/200, Iteration 219/250, Loss: 0.0148\n",
      "Epoch 113/200, Iteration 220/250, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 221/250, Loss: 0.0121\n",
      "Epoch 113/200, Iteration 222/250, Loss: 0.0197\n",
      "Epoch 113/200, Iteration 223/250, Loss: 0.0130\n",
      "Epoch 113/200, Iteration 224/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 225/250, Loss: 0.0070\n",
      "Epoch 113/200, Iteration 226/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 227/250, Loss: 0.0207\n",
      "Epoch 113/200, Iteration 228/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 229/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 230/250, Loss: 0.0409\n",
      "Epoch 113/200, Iteration 231/250, Loss: 0.0106\n",
      "Epoch 113/200, Iteration 232/250, Loss: 0.0051\n",
      "Epoch 113/200, Iteration 233/250, Loss: 0.0110\n",
      "Epoch 113/200, Iteration 234/250, Loss: 0.0384\n",
      "Epoch 113/200, Iteration 235/250, Loss: 0.0132\n",
      "Epoch 113/200, Iteration 236/250, Loss: 0.0131\n",
      "Epoch 113/200, Iteration 237/250, Loss: 0.0150\n",
      "Epoch 113/200, Iteration 238/250, Loss: 0.0137\n",
      "Epoch 113/200, Iteration 239/250, Loss: 0.0095\n",
      "Epoch 113/200, Iteration 240/250, Loss: 0.0169\n",
      "Epoch 113/200, Iteration 241/250, Loss: 0.0100\n",
      "Epoch 113/200, Iteration 242/250, Loss: 0.0168\n",
      "Epoch 113/200, Iteration 243/250, Loss: 0.0095\n",
      "Epoch 113/200, Iteration 244/250, Loss: 0.0167\n",
      "Epoch 113/200, Iteration 245/250, Loss: 0.0219\n",
      "Epoch 113/200, Iteration 246/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 247/250, Loss: 0.0101\n",
      "Epoch 113/200, Iteration 248/250, Loss: 0.0185\n",
      "Epoch 113/200, Iteration 249/250, Loss: 0.0188\n",
      "Epoch 113/200, Iteration 250/250, Loss: 0.0107\n",
      "Train Error: \n",
      " Accuracy: 90.16%, Avg loss: 0.006385, MRE: 0.630887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.85%, Avg loss: 0.006435, MRE: 0.971914 \n",
      "\n",
      "Epoch 114/200, Iteration 1/250, Loss: 0.0094\n",
      "Epoch 114/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 3/250, Loss: 0.0221\n",
      "Epoch 114/200, Iteration 4/250, Loss: 0.0088\n",
      "Epoch 114/200, Iteration 5/250, Loss: 0.0113\n",
      "Epoch 114/200, Iteration 6/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 114/200, Iteration 8/250, Loss: 0.0257\n",
      "Epoch 114/200, Iteration 9/250, Loss: 0.0130\n",
      "Epoch 114/200, Iteration 10/250, Loss: 0.0158\n",
      "Epoch 114/200, Iteration 11/250, Loss: 0.0180\n",
      "Epoch 114/200, Iteration 12/250, Loss: 0.0138\n",
      "Epoch 114/200, Iteration 13/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 14/250, Loss: 0.0134\n",
      "Epoch 114/200, Iteration 15/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 114/200, Iteration 17/250, Loss: 0.0120\n",
      "Epoch 114/200, Iteration 18/250, Loss: 0.0199\n",
      "Epoch 114/200, Iteration 19/250, Loss: 0.0162\n",
      "Epoch 114/200, Iteration 20/250, Loss: 0.0176\n",
      "Epoch 114/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 22/250, Loss: 0.0178\n",
      "Epoch 114/200, Iteration 23/250, Loss: 0.0088\n",
      "Epoch 114/200, Iteration 24/250, Loss: 0.0255\n",
      "Epoch 114/200, Iteration 25/250, Loss: 0.0223\n",
      "Epoch 114/200, Iteration 26/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 27/250, Loss: 0.0166\n",
      "Epoch 114/200, Iteration 28/250, Loss: 0.0153\n",
      "Epoch 114/200, Iteration 29/250, Loss: 0.0079\n",
      "Epoch 114/200, Iteration 30/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 31/250, Loss: 0.0186\n",
      "Epoch 114/200, Iteration 32/250, Loss: 0.0067\n",
      "Epoch 114/200, Iteration 33/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 34/250, Loss: 0.0079\n",
      "Epoch 114/200, Iteration 35/250, Loss: 0.0376\n",
      "Epoch 114/200, Iteration 36/250, Loss: 0.0070\n",
      "Epoch 114/200, Iteration 37/250, Loss: 0.0188\n",
      "Epoch 114/200, Iteration 38/250, Loss: 0.0283\n",
      "Epoch 114/200, Iteration 39/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 40/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 41/250, Loss: 0.0154\n",
      "Epoch 114/200, Iteration 42/250, Loss: 0.0189\n",
      "Epoch 114/200, Iteration 43/250, Loss: 0.0082\n",
      "Epoch 114/200, Iteration 44/250, Loss: 0.0147\n",
      "Epoch 114/200, Iteration 45/250, Loss: 0.0205\n",
      "Epoch 114/200, Iteration 46/250, Loss: 0.0199\n",
      "Epoch 114/200, Iteration 47/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 48/250, Loss: 0.0095\n",
      "Epoch 114/200, Iteration 49/250, Loss: 0.0155\n",
      "Epoch 114/200, Iteration 50/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 51/250, Loss: 0.0237\n",
      "Epoch 114/200, Iteration 52/250, Loss: 0.0179\n",
      "Epoch 114/200, Iteration 53/250, Loss: 0.0136\n",
      "Epoch 114/200, Iteration 54/250, Loss: 0.0130\n",
      "Epoch 114/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 56/250, Loss: 0.0272\n",
      "Epoch 114/200, Iteration 57/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 58/250, Loss: 0.0064\n",
      "Epoch 114/200, Iteration 59/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 61/250, Loss: 0.0250\n",
      "Epoch 114/200, Iteration 62/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 63/250, Loss: 0.0206\n",
      "Epoch 114/200, Iteration 64/250, Loss: 0.0177\n",
      "Epoch 114/200, Iteration 65/250, Loss: 0.0071\n",
      "Epoch 114/200, Iteration 66/250, Loss: 0.0092\n",
      "Epoch 114/200, Iteration 67/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 68/250, Loss: 0.0114\n",
      "Epoch 114/200, Iteration 69/250, Loss: 0.0079\n",
      "Epoch 114/200, Iteration 70/250, Loss: 0.0182\n",
      "Epoch 114/200, Iteration 71/250, Loss: 0.0186\n",
      "Epoch 114/200, Iteration 72/250, Loss: 0.0184\n",
      "Epoch 114/200, Iteration 73/250, Loss: 0.0135\n",
      "Epoch 114/200, Iteration 74/250, Loss: 0.0090\n",
      "Epoch 114/200, Iteration 75/250, Loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200, Iteration 76/250, Loss: 0.0082\n",
      "Epoch 114/200, Iteration 77/250, Loss: 0.0091\n",
      "Epoch 114/200, Iteration 78/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 80/250, Loss: 0.0094\n",
      "Epoch 114/200, Iteration 81/250, Loss: 0.0134\n",
      "Epoch 114/200, Iteration 82/250, Loss: 0.0115\n",
      "Epoch 114/200, Iteration 83/250, Loss: 0.0151\n",
      "Epoch 114/200, Iteration 84/250, Loss: 0.0223\n",
      "Epoch 114/200, Iteration 85/250, Loss: 0.0165\n",
      "Epoch 114/200, Iteration 86/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 87/250, Loss: 0.0178\n",
      "Epoch 114/200, Iteration 88/250, Loss: 0.0166\n",
      "Epoch 114/200, Iteration 89/250, Loss: 0.0125\n",
      "Epoch 114/200, Iteration 90/250, Loss: 0.0113\n",
      "Epoch 114/200, Iteration 91/250, Loss: 0.0097\n",
      "Epoch 114/200, Iteration 92/250, Loss: 0.0126\n",
      "Epoch 114/200, Iteration 93/250, Loss: 0.0092\n",
      "Epoch 114/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 114/200, Iteration 95/250, Loss: 0.0103\n",
      "Epoch 114/200, Iteration 96/250, Loss: 0.0075\n",
      "Epoch 114/200, Iteration 97/250, Loss: 0.0153\n",
      "Epoch 114/200, Iteration 98/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 114/200, Iteration 100/250, Loss: 0.0193\n",
      "Epoch 114/200, Iteration 101/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 102/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 103/250, Loss: 0.0078\n",
      "Epoch 114/200, Iteration 104/250, Loss: 0.0169\n",
      "Epoch 114/200, Iteration 105/250, Loss: 0.0128\n",
      "Epoch 114/200, Iteration 106/250, Loss: 0.0136\n",
      "Epoch 114/200, Iteration 107/250, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 108/250, Loss: 0.0110\n",
      "Epoch 114/200, Iteration 109/250, Loss: 0.0114\n",
      "Epoch 114/200, Iteration 110/250, Loss: 0.0112\n",
      "Epoch 114/200, Iteration 111/250, Loss: 0.0159\n",
      "Epoch 114/200, Iteration 112/250, Loss: 0.0072\n",
      "Epoch 114/200, Iteration 113/250, Loss: 0.0103\n",
      "Epoch 114/200, Iteration 114/250, Loss: 0.0118\n",
      "Epoch 114/200, Iteration 115/250, Loss: 0.0262\n",
      "Epoch 114/200, Iteration 116/250, Loss: 0.0154\n",
      "Epoch 114/200, Iteration 117/250, Loss: 0.0173\n",
      "Epoch 114/200, Iteration 118/250, Loss: 0.0223\n",
      "Epoch 114/200, Iteration 119/250, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 120/250, Loss: 0.0066\n",
      "Epoch 114/200, Iteration 121/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 122/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 123/250, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 124/250, Loss: 0.0137\n",
      "Epoch 114/200, Iteration 125/250, Loss: 0.0132\n",
      "Epoch 114/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 127/250, Loss: 0.0061\n",
      "Epoch 114/200, Iteration 128/250, Loss: 0.0097\n",
      "Epoch 114/200, Iteration 129/250, Loss: 0.0324\n",
      "Epoch 114/200, Iteration 130/250, Loss: 0.0143\n",
      "Epoch 114/200, Iteration 131/250, Loss: 0.0062\n",
      "Epoch 114/200, Iteration 132/250, Loss: 0.0117\n",
      "Epoch 114/200, Iteration 133/250, Loss: 0.0121\n",
      "Epoch 114/200, Iteration 134/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 135/250, Loss: 0.0147\n",
      "Epoch 114/200, Iteration 136/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 137/250, Loss: 0.0124\n",
      "Epoch 114/200, Iteration 138/250, Loss: 0.0171\n",
      "Epoch 114/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 114/200, Iteration 140/250, Loss: 0.0073\n",
      "Epoch 114/200, Iteration 141/250, Loss: 0.0126\n",
      "Epoch 114/200, Iteration 142/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 143/250, Loss: 0.0146\n",
      "Epoch 114/200, Iteration 144/250, Loss: 0.0154\n",
      "Epoch 114/200, Iteration 145/250, Loss: 0.0066\n",
      "Epoch 114/200, Iteration 146/250, Loss: 0.0111\n",
      "Epoch 114/200, Iteration 147/250, Loss: 0.0413\n",
      "Epoch 114/200, Iteration 148/250, Loss: 0.0190\n",
      "Epoch 114/200, Iteration 149/250, Loss: 0.0118\n",
      "Epoch 114/200, Iteration 150/250, Loss: 0.0077\n",
      "Epoch 114/200, Iteration 151/250, Loss: 0.0111\n",
      "Epoch 114/200, Iteration 152/250, Loss: 0.0156\n",
      "Epoch 114/200, Iteration 153/250, Loss: 0.0208\n",
      "Epoch 114/200, Iteration 154/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 155/250, Loss: 0.0280\n",
      "Epoch 114/200, Iteration 156/250, Loss: 0.0098\n",
      "Epoch 114/200, Iteration 157/250, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 158/250, Loss: 0.0177\n",
      "Epoch 114/200, Iteration 159/250, Loss: 0.0195\n",
      "Epoch 114/200, Iteration 160/250, Loss: 0.0162\n",
      "Epoch 114/200, Iteration 161/250, Loss: 0.0068\n",
      "Epoch 114/200, Iteration 162/250, Loss: 0.0150\n",
      "Epoch 114/200, Iteration 163/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 164/250, Loss: 0.0189\n",
      "Epoch 114/200, Iteration 165/250, Loss: 0.0097\n",
      "Epoch 114/200, Iteration 166/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 167/250, Loss: 0.0385\n",
      "Epoch 114/200, Iteration 168/250, Loss: 0.0104\n",
      "Epoch 114/200, Iteration 169/250, Loss: 0.0178\n",
      "Epoch 114/200, Iteration 170/250, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 171/250, Loss: 0.0170\n",
      "Epoch 114/200, Iteration 172/250, Loss: 0.0109\n",
      "Epoch 114/200, Iteration 173/250, Loss: 0.0164\n",
      "Epoch 114/200, Iteration 174/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 175/250, Loss: 0.0123\n",
      "Epoch 114/200, Iteration 176/250, Loss: 0.0165\n",
      "Epoch 114/200, Iteration 177/250, Loss: 0.0178\n",
      "Epoch 114/200, Iteration 178/250, Loss: 0.0111\n",
      "Epoch 114/200, Iteration 179/250, Loss: 0.0362\n",
      "Epoch 114/200, Iteration 180/250, Loss: 0.0065\n",
      "Epoch 114/200, Iteration 181/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 182/250, Loss: 0.0330\n",
      "Epoch 114/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 184/250, Loss: 0.0212\n",
      "Epoch 114/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 114/200, Iteration 186/250, Loss: 0.0161\n",
      "Epoch 114/200, Iteration 187/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 188/250, Loss: 0.0102\n",
      "Epoch 114/200, Iteration 189/250, Loss: 0.0222\n",
      "Epoch 114/200, Iteration 190/250, Loss: 0.0260\n",
      "Epoch 114/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 192/250, Loss: 0.0181\n",
      "Epoch 114/200, Iteration 193/250, Loss: 0.0119\n",
      "Epoch 114/200, Iteration 194/250, Loss: 0.0193\n",
      "Epoch 114/200, Iteration 195/250, Loss: 0.0091\n",
      "Epoch 114/200, Iteration 196/250, Loss: 0.0063\n",
      "Epoch 114/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 198/250, Loss: 0.0198\n",
      "Epoch 114/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 114/200, Iteration 200/250, Loss: 0.0078\n",
      "Epoch 114/200, Iteration 201/250, Loss: 0.0103\n",
      "Epoch 114/200, Iteration 202/250, Loss: 0.0084\n",
      "Epoch 114/200, Iteration 203/250, Loss: 0.0070\n",
      "Epoch 114/200, Iteration 204/250, Loss: 0.0153\n",
      "Epoch 114/200, Iteration 205/250, Loss: 0.0076\n",
      "Epoch 114/200, Iteration 206/250, Loss: 0.0131\n",
      "Epoch 114/200, Iteration 207/250, Loss: 0.0248\n",
      "Epoch 114/200, Iteration 208/250, Loss: 0.0212\n",
      "Epoch 114/200, Iteration 209/250, Loss: 0.0116\n",
      "Epoch 114/200, Iteration 210/250, Loss: 0.0091\n",
      "Epoch 114/200, Iteration 211/250, Loss: 0.0116\n",
      "Epoch 114/200, Iteration 212/250, Loss: 0.0149\n",
      "Epoch 114/200, Iteration 213/250, Loss: 0.0265\n",
      "Epoch 114/200, Iteration 214/250, Loss: 0.0120\n",
      "Epoch 114/200, Iteration 215/250, Loss: 0.0196\n",
      "Epoch 114/200, Iteration 216/250, Loss: 0.0180\n",
      "Epoch 114/200, Iteration 217/250, Loss: 0.0123\n",
      "Epoch 114/200, Iteration 218/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 219/250, Loss: 0.0211\n",
      "Epoch 114/200, Iteration 220/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 114/200, Iteration 222/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 223/250, Loss: 0.0143\n",
      "Epoch 114/200, Iteration 224/250, Loss: 0.0261\n",
      "Epoch 114/200, Iteration 225/250, Loss: 0.0200\n",
      "Epoch 114/200, Iteration 226/250, Loss: 0.0153\n",
      "Epoch 114/200, Iteration 227/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 228/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 229/250, Loss: 0.0177\n",
      "Epoch 114/200, Iteration 230/250, Loss: 0.0201\n",
      "Epoch 114/200, Iteration 231/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 232/250, Loss: 0.0165\n",
      "Epoch 114/200, Iteration 233/250, Loss: 0.0304\n",
      "Epoch 114/200, Iteration 234/250, Loss: 0.0138\n",
      "Epoch 114/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 114/200, Iteration 236/250, Loss: 0.0232\n",
      "Epoch 114/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 238/250, Loss: 0.0315\n",
      "Epoch 114/200, Iteration 239/250, Loss: 0.0152\n",
      "Epoch 114/200, Iteration 240/250, Loss: 0.0215\n",
      "Epoch 114/200, Iteration 241/250, Loss: 0.0169\n",
      "Epoch 114/200, Iteration 242/250, Loss: 0.0074\n",
      "Epoch 114/200, Iteration 243/250, Loss: 0.0213\n",
      "Epoch 114/200, Iteration 244/250, Loss: 0.0173\n",
      "Epoch 114/200, Iteration 245/250, Loss: 0.0082\n",
      "Epoch 114/200, Iteration 246/250, Loss: 0.0187\n",
      "Epoch 114/200, Iteration 247/250, Loss: 0.0112\n",
      "Epoch 114/200, Iteration 248/250, Loss: 0.0136\n",
      "Epoch 114/200, Iteration 249/250, Loss: 0.0074\n",
      "Epoch 114/200, Iteration 250/250, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 85.58%, Avg loss: 0.006622, MRE: 0.640530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.55%, Avg loss: 0.006674, MRE: 0.899833 \n",
      "\n",
      "Epoch 115/200, Iteration 1/250, Loss: 0.0102\n",
      "Epoch 115/200, Iteration 2/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 115/200, Iteration 4/250, Loss: 0.0140\n",
      "Epoch 115/200, Iteration 5/250, Loss: 0.0066\n",
      "Epoch 115/200, Iteration 6/250, Loss: 0.0123\n",
      "Epoch 115/200, Iteration 7/250, Loss: 0.0195\n",
      "Epoch 115/200, Iteration 8/250, Loss: 0.0145\n",
      "Epoch 115/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 10/250, Loss: 0.0100\n",
      "Epoch 115/200, Iteration 11/250, Loss: 0.0243\n",
      "Epoch 115/200, Iteration 12/250, Loss: 0.0172\n",
      "Epoch 115/200, Iteration 13/250, Loss: 0.0147\n",
      "Epoch 115/200, Iteration 14/250, Loss: 0.0112\n",
      "Epoch 115/200, Iteration 15/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 16/250, Loss: 0.0194\n",
      "Epoch 115/200, Iteration 17/250, Loss: 0.0064\n",
      "Epoch 115/200, Iteration 18/250, Loss: 0.0286\n",
      "Epoch 115/200, Iteration 19/250, Loss: 0.0082\n",
      "Epoch 115/200, Iteration 20/250, Loss: 0.0432\n",
      "Epoch 115/200, Iteration 21/250, Loss: 0.0169\n",
      "Epoch 115/200, Iteration 22/250, Loss: 0.0076\n",
      "Epoch 115/200, Iteration 23/250, Loss: 0.0131\n",
      "Epoch 115/200, Iteration 24/250, Loss: 0.0102\n",
      "Epoch 115/200, Iteration 25/250, Loss: 0.0212\n",
      "Epoch 115/200, Iteration 26/250, Loss: 0.0090\n",
      "Epoch 115/200, Iteration 27/250, Loss: 0.0206\n",
      "Epoch 115/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 115/200, Iteration 29/250, Loss: 0.0073\n",
      "Epoch 115/200, Iteration 30/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 31/250, Loss: 0.0298\n",
      "Epoch 115/200, Iteration 32/250, Loss: 0.0191\n",
      "Epoch 115/200, Iteration 33/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 34/250, Loss: 0.0321\n",
      "Epoch 115/200, Iteration 35/250, Loss: 0.0108\n",
      "Epoch 115/200, Iteration 36/250, Loss: 0.0190\n",
      "Epoch 115/200, Iteration 37/250, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 40/250, Loss: 0.0164\n",
      "Epoch 115/200, Iteration 41/250, Loss: 0.0080\n",
      "Epoch 115/200, Iteration 42/250, Loss: 0.0064\n",
      "Epoch 115/200, Iteration 43/250, Loss: 0.0085\n",
      "Epoch 115/200, Iteration 44/250, Loss: 0.0253\n",
      "Epoch 115/200, Iteration 45/250, Loss: 0.0286\n",
      "Epoch 115/200, Iteration 46/250, Loss: 0.0078\n",
      "Epoch 115/200, Iteration 47/250, Loss: 0.0298\n",
      "Epoch 115/200, Iteration 48/250, Loss: 0.0092\n",
      "Epoch 115/200, Iteration 49/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 50/250, Loss: 0.0236\n",
      "Epoch 115/200, Iteration 51/250, Loss: 0.0123\n",
      "Epoch 115/200, Iteration 52/250, Loss: 0.0115\n",
      "Epoch 115/200, Iteration 53/250, Loss: 0.0234\n",
      "Epoch 115/200, Iteration 54/250, Loss: 0.0209\n",
      "Epoch 115/200, Iteration 55/250, Loss: 0.0140\n",
      "Epoch 115/200, Iteration 56/250, Loss: 0.0075\n",
      "Epoch 115/200, Iteration 57/250, Loss: 0.0241\n",
      "Epoch 115/200, Iteration 58/250, Loss: 0.0114\n",
      "Epoch 115/200, Iteration 59/250, Loss: 0.0422\n",
      "Epoch 115/200, Iteration 60/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 61/250, Loss: 0.0150\n",
      "Epoch 115/200, Iteration 62/250, Loss: 0.0081\n",
      "Epoch 115/200, Iteration 63/250, Loss: 0.0138\n",
      "Epoch 115/200, Iteration 64/250, Loss: 0.0166\n",
      "Epoch 115/200, Iteration 65/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 67/250, Loss: 0.0123\n",
      "Epoch 115/200, Iteration 68/250, Loss: 0.0068\n",
      "Epoch 115/200, Iteration 69/250, Loss: 0.0212\n",
      "Epoch 115/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 115/200, Iteration 71/250, Loss: 0.0090\n",
      "Epoch 115/200, Iteration 72/250, Loss: 0.0311\n",
      "Epoch 115/200, Iteration 73/250, Loss: 0.0267\n",
      "Epoch 115/200, Iteration 74/250, Loss: 0.0142\n",
      "Epoch 115/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 115/200, Iteration 76/250, Loss: 0.0107\n",
      "Epoch 115/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 115/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 115/200, Iteration 79/250, Loss: 0.0152\n",
      "Epoch 115/200, Iteration 80/250, Loss: 0.0284\n",
      "Epoch 115/200, Iteration 81/250, Loss: 0.0138\n",
      "Epoch 115/200, Iteration 82/250, Loss: 0.0286\n",
      "Epoch 115/200, Iteration 83/250, Loss: 0.0135\n",
      "Epoch 115/200, Iteration 84/250, Loss: 0.0445\n",
      "Epoch 115/200, Iteration 85/250, Loss: 0.0190\n",
      "Epoch 115/200, Iteration 86/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 87/250, Loss: 0.0105\n",
      "Epoch 115/200, Iteration 88/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 89/250, Loss: 0.0153\n",
      "Epoch 115/200, Iteration 90/250, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 91/250, Loss: 0.0246\n",
      "Epoch 115/200, Iteration 92/250, Loss: 0.0145\n",
      "Epoch 115/200, Iteration 93/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 94/250, Loss: 0.0094\n",
      "Epoch 115/200, Iteration 95/250, Loss: 0.0085\n",
      "Epoch 115/200, Iteration 96/250, Loss: 0.0052\n",
      "Epoch 115/200, Iteration 97/250, Loss: 0.0254\n",
      "Epoch 115/200, Iteration 98/250, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 115/200, Iteration 100/250, Loss: 0.0241\n",
      "Epoch 115/200, Iteration 101/250, Loss: 0.0425\n",
      "Epoch 115/200, Iteration 102/250, Loss: 0.0083\n",
      "Epoch 115/200, Iteration 103/250, Loss: 0.0078\n",
      "Epoch 115/200, Iteration 104/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 105/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 106/250, Loss: 0.0302\n",
      "Epoch 115/200, Iteration 107/250, Loss: 0.0166\n",
      "Epoch 115/200, Iteration 108/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 109/250, Loss: 0.0069\n",
      "Epoch 115/200, Iteration 110/250, Loss: 0.0220\n",
      "Epoch 115/200, Iteration 111/250, Loss: 0.0232\n",
      "Epoch 115/200, Iteration 112/250, Loss: 0.0231\n",
      "Epoch 115/200, Iteration 113/250, Loss: 0.0127\n",
      "Epoch 115/200, Iteration 114/250, Loss: 0.0133\n",
      "Epoch 115/200, Iteration 115/250, Loss: 0.0321\n",
      "Epoch 115/200, Iteration 116/250, Loss: 0.0108\n",
      "Epoch 115/200, Iteration 117/250, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 118/250, Loss: 0.0256\n",
      "Epoch 115/200, Iteration 119/250, Loss: 0.0463\n",
      "Epoch 115/200, Iteration 120/250, Loss: 0.0119\n",
      "Epoch 115/200, Iteration 121/250, Loss: 0.0073\n",
      "Epoch 115/200, Iteration 122/250, Loss: 0.0304\n",
      "Epoch 115/200, Iteration 123/250, Loss: 0.0122\n",
      "Epoch 115/200, Iteration 124/250, Loss: 0.0161\n",
      "Epoch 115/200, Iteration 125/250, Loss: 0.0100\n",
      "Epoch 115/200, Iteration 126/250, Loss: 0.0309\n",
      "Epoch 115/200, Iteration 127/250, Loss: 0.0171\n",
      "Epoch 115/200, Iteration 128/250, Loss: 0.0097\n",
      "Epoch 115/200, Iteration 129/250, Loss: 0.0143\n",
      "Epoch 115/200, Iteration 130/250, Loss: 0.0180\n",
      "Epoch 115/200, Iteration 131/250, Loss: 0.0131\n",
      "Epoch 115/200, Iteration 132/250, Loss: 0.0263\n",
      "Epoch 115/200, Iteration 133/250, Loss: 0.0211\n",
      "Epoch 115/200, Iteration 134/250, Loss: 0.0204\n",
      "Epoch 115/200, Iteration 135/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 136/250, Loss: 0.0159\n",
      "Epoch 115/200, Iteration 137/250, Loss: 0.0270\n",
      "Epoch 115/200, Iteration 138/250, Loss: 0.0138\n",
      "Epoch 115/200, Iteration 139/250, Loss: 0.0146\n",
      "Epoch 115/200, Iteration 140/250, Loss: 0.0339\n",
      "Epoch 115/200, Iteration 141/250, Loss: 0.0090\n",
      "Epoch 115/200, Iteration 142/250, Loss: 0.0371\n",
      "Epoch 115/200, Iteration 143/250, Loss: 0.0134\n",
      "Epoch 115/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 115/200, Iteration 145/250, Loss: 0.0207\n",
      "Epoch 115/200, Iteration 146/250, Loss: 0.0114\n",
      "Epoch 115/200, Iteration 147/250, Loss: 0.0138\n",
      "Epoch 115/200, Iteration 148/250, Loss: 0.0084\n",
      "Epoch 115/200, Iteration 149/250, Loss: 0.0122\n",
      "Epoch 115/200, Iteration 150/250, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 151/250, Loss: 0.0289\n",
      "Epoch 115/200, Iteration 152/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 153/250, Loss: 0.0116\n",
      "Epoch 115/200, Iteration 154/250, Loss: 0.0137\n",
      "Epoch 115/200, Iteration 155/250, Loss: 0.0100\n",
      "Epoch 115/200, Iteration 156/250, Loss: 0.0156\n",
      "Epoch 115/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 115/200, Iteration 158/250, Loss: 0.0064\n",
      "Epoch 115/200, Iteration 159/250, Loss: 0.0086\n",
      "Epoch 115/200, Iteration 160/250, Loss: 0.0252\n",
      "Epoch 115/200, Iteration 161/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 162/250, Loss: 0.0117\n",
      "Epoch 115/200, Iteration 163/250, Loss: 0.0084\n",
      "Epoch 115/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 115/200, Iteration 165/250, Loss: 0.0080\n",
      "Epoch 115/200, Iteration 166/250, Loss: 0.0142\n",
      "Epoch 115/200, Iteration 167/250, Loss: 0.0097\n",
      "Epoch 115/200, Iteration 168/250, Loss: 0.0145\n",
      "Epoch 115/200, Iteration 169/250, Loss: 0.0071\n",
      "Epoch 115/200, Iteration 170/250, Loss: 0.0134\n",
      "Epoch 115/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 115/200, Iteration 172/250, Loss: 0.0126\n",
      "Epoch 115/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 174/250, Loss: 0.0335\n",
      "Epoch 115/200, Iteration 175/250, Loss: 0.0131\n",
      "Epoch 115/200, Iteration 176/250, Loss: 0.0285\n",
      "Epoch 115/200, Iteration 177/250, Loss: 0.0078\n",
      "Epoch 115/200, Iteration 178/250, Loss: 0.0074\n",
      "Epoch 115/200, Iteration 179/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 180/250, Loss: 0.0414\n",
      "Epoch 115/200, Iteration 181/250, Loss: 0.0105\n",
      "Epoch 115/200, Iteration 182/250, Loss: 0.0068\n",
      "Epoch 115/200, Iteration 183/250, Loss: 0.0182\n",
      "Epoch 115/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 115/200, Iteration 185/250, Loss: 0.0165\n",
      "Epoch 115/200, Iteration 186/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 187/250, Loss: 0.0087\n",
      "Epoch 115/200, Iteration 188/250, Loss: 0.0369\n",
      "Epoch 115/200, Iteration 189/250, Loss: 0.0178\n",
      "Epoch 115/200, Iteration 190/250, Loss: 0.0256\n",
      "Epoch 115/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 115/200, Iteration 192/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 194/250, Loss: 0.0110\n",
      "Epoch 115/200, Iteration 195/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 196/250, Loss: 0.0124\n",
      "Epoch 115/200, Iteration 197/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 198/250, Loss: 0.0097\n",
      "Epoch 115/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 200/250, Loss: 0.0100\n",
      "Epoch 115/200, Iteration 201/250, Loss: 0.0153\n",
      "Epoch 115/200, Iteration 202/250, Loss: 0.0172\n",
      "Epoch 115/200, Iteration 203/250, Loss: 0.0087\n",
      "Epoch 115/200, Iteration 204/250, Loss: 0.0260\n",
      "Epoch 115/200, Iteration 205/250, Loss: 0.0118\n",
      "Epoch 115/200, Iteration 206/250, Loss: 0.0077\n",
      "Epoch 115/200, Iteration 207/250, Loss: 0.0171\n",
      "Epoch 115/200, Iteration 208/250, Loss: 0.0338\n",
      "Epoch 115/200, Iteration 209/250, Loss: 0.0114\n",
      "Epoch 115/200, Iteration 210/250, Loss: 0.0144\n",
      "Epoch 115/200, Iteration 211/250, Loss: 0.0160\n",
      "Epoch 115/200, Iteration 212/250, Loss: 0.0119\n",
      "Epoch 115/200, Iteration 213/250, Loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200, Iteration 214/250, Loss: 0.0121\n",
      "Epoch 115/200, Iteration 215/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 216/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 217/250, Loss: 0.0083\n",
      "Epoch 115/200, Iteration 218/250, Loss: 0.0282\n",
      "Epoch 115/200, Iteration 219/250, Loss: 0.0110\n",
      "Epoch 115/200, Iteration 220/250, Loss: 0.0182\n",
      "Epoch 115/200, Iteration 221/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 222/250, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 223/250, Loss: 0.0151\n",
      "Epoch 115/200, Iteration 224/250, Loss: 0.0230\n",
      "Epoch 115/200, Iteration 225/250, Loss: 0.0227\n",
      "Epoch 115/200, Iteration 226/250, Loss: 0.0143\n",
      "Epoch 115/200, Iteration 227/250, Loss: 0.0132\n",
      "Epoch 115/200, Iteration 228/250, Loss: 0.0121\n",
      "Epoch 115/200, Iteration 229/250, Loss: 0.0101\n",
      "Epoch 115/200, Iteration 230/250, Loss: 0.0167\n",
      "Epoch 115/200, Iteration 231/250, Loss: 0.0115\n",
      "Epoch 115/200, Iteration 232/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 233/250, Loss: 0.0137\n",
      "Epoch 115/200, Iteration 234/250, Loss: 0.0113\n",
      "Epoch 115/200, Iteration 235/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 236/250, Loss: 0.0050\n",
      "Epoch 115/200, Iteration 237/250, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 238/250, Loss: 0.0153\n",
      "Epoch 115/200, Iteration 239/250, Loss: 0.0156\n",
      "Epoch 115/200, Iteration 240/250, Loss: 0.0133\n",
      "Epoch 115/200, Iteration 241/250, Loss: 0.0200\n",
      "Epoch 115/200, Iteration 242/250, Loss: 0.0117\n",
      "Epoch 115/200, Iteration 243/250, Loss: 0.0085\n",
      "Epoch 115/200, Iteration 244/250, Loss: 0.0156\n",
      "Epoch 115/200, Iteration 245/250, Loss: 0.0329\n",
      "Epoch 115/200, Iteration 246/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 247/250, Loss: 0.0232\n",
      "Epoch 115/200, Iteration 248/250, Loss: 0.0104\n",
      "Epoch 115/200, Iteration 249/250, Loss: 0.0107\n",
      "Epoch 115/200, Iteration 250/250, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.006474, MRE: 0.626011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.45%, Avg loss: 0.006500, MRE: 0.824087 \n",
      "\n",
      "Epoch 116/200, Iteration 1/250, Loss: 0.0114\n",
      "Epoch 116/200, Iteration 2/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 3/250, Loss: 0.0080\n",
      "Epoch 116/200, Iteration 4/250, Loss: 0.0109\n",
      "Epoch 116/200, Iteration 5/250, Loss: 0.0137\n",
      "Epoch 116/200, Iteration 6/250, Loss: 0.0100\n",
      "Epoch 116/200, Iteration 7/250, Loss: 0.0113\n",
      "Epoch 116/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 116/200, Iteration 9/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 116/200, Iteration 11/250, Loss: 0.0214\n",
      "Epoch 116/200, Iteration 12/250, Loss: 0.0137\n",
      "Epoch 116/200, Iteration 13/250, Loss: 0.0373\n",
      "Epoch 116/200, Iteration 14/250, Loss: 0.0326\n",
      "Epoch 116/200, Iteration 15/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 16/250, Loss: 0.0105\n",
      "Epoch 116/200, Iteration 17/250, Loss: 0.0171\n",
      "Epoch 116/200, Iteration 18/250, Loss: 0.0187\n",
      "Epoch 116/200, Iteration 19/250, Loss: 0.0124\n",
      "Epoch 116/200, Iteration 20/250, Loss: 0.0122\n",
      "Epoch 116/200, Iteration 21/250, Loss: 0.0149\n",
      "Epoch 116/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 23/250, Loss: 0.0215\n",
      "Epoch 116/200, Iteration 24/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 26/250, Loss: 0.0227\n",
      "Epoch 116/200, Iteration 27/250, Loss: 0.0138\n",
      "Epoch 116/200, Iteration 28/250, Loss: 0.0116\n",
      "Epoch 116/200, Iteration 29/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 30/250, Loss: 0.0107\n",
      "Epoch 116/200, Iteration 31/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 32/250, Loss: 0.0053\n",
      "Epoch 116/200, Iteration 33/250, Loss: 0.0083\n",
      "Epoch 116/200, Iteration 34/250, Loss: 0.0204\n",
      "Epoch 116/200, Iteration 35/250, Loss: 0.0188\n",
      "Epoch 116/200, Iteration 36/250, Loss: 0.0062\n",
      "Epoch 116/200, Iteration 37/250, Loss: 0.0165\n",
      "Epoch 116/200, Iteration 38/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 39/250, Loss: 0.0153\n",
      "Epoch 116/200, Iteration 40/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 41/250, Loss: 0.0112\n",
      "Epoch 116/200, Iteration 42/250, Loss: 0.0307\n",
      "Epoch 116/200, Iteration 43/250, Loss: 0.0240\n",
      "Epoch 116/200, Iteration 44/250, Loss: 0.0124\n",
      "Epoch 116/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 46/250, Loss: 0.0121\n",
      "Epoch 116/200, Iteration 47/250, Loss: 0.0127\n",
      "Epoch 116/200, Iteration 48/250, Loss: 0.0222\n",
      "Epoch 116/200, Iteration 49/250, Loss: 0.0150\n",
      "Epoch 116/200, Iteration 50/250, Loss: 0.0154\n",
      "Epoch 116/200, Iteration 51/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 52/250, Loss: 0.0148\n",
      "Epoch 116/200, Iteration 53/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 54/250, Loss: 0.0133\n",
      "Epoch 116/200, Iteration 55/250, Loss: 0.0286\n",
      "Epoch 116/200, Iteration 56/250, Loss: 0.0221\n",
      "Epoch 116/200, Iteration 57/250, Loss: 0.0128\n",
      "Epoch 116/200, Iteration 58/250, Loss: 0.0123\n",
      "Epoch 116/200, Iteration 59/250, Loss: 0.0261\n",
      "Epoch 116/200, Iteration 60/250, Loss: 0.0251\n",
      "Epoch 116/200, Iteration 61/250, Loss: 0.0118\n",
      "Epoch 116/200, Iteration 62/250, Loss: 0.0108\n",
      "Epoch 116/200, Iteration 63/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 64/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 65/250, Loss: 0.0111\n",
      "Epoch 116/200, Iteration 66/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 67/250, Loss: 0.0157\n",
      "Epoch 116/200, Iteration 68/250, Loss: 0.0131\n",
      "Epoch 116/200, Iteration 69/250, Loss: 0.0112\n",
      "Epoch 116/200, Iteration 70/250, Loss: 0.0072\n",
      "Epoch 116/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 116/200, Iteration 72/250, Loss: 0.0174\n",
      "Epoch 116/200, Iteration 73/250, Loss: 0.0374\n",
      "Epoch 116/200, Iteration 74/250, Loss: 0.0055\n",
      "Epoch 116/200, Iteration 75/250, Loss: 0.0187\n",
      "Epoch 116/200, Iteration 76/250, Loss: 0.0100\n",
      "Epoch 116/200, Iteration 77/250, Loss: 0.0156\n",
      "Epoch 116/200, Iteration 78/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 79/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 80/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 81/250, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 82/250, Loss: 0.0248\n",
      "Epoch 116/200, Iteration 83/250, Loss: 0.0118\n",
      "Epoch 116/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 116/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 86/250, Loss: 0.0269\n",
      "Epoch 116/200, Iteration 87/250, Loss: 0.0143\n",
      "Epoch 116/200, Iteration 88/250, Loss: 0.0076\n",
      "Epoch 116/200, Iteration 89/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 91/250, Loss: 0.0069\n",
      "Epoch 116/200, Iteration 92/250, Loss: 0.0155\n",
      "Epoch 116/200, Iteration 93/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 94/250, Loss: 0.0409\n",
      "Epoch 116/200, Iteration 95/250, Loss: 0.0125\n",
      "Epoch 116/200, Iteration 96/250, Loss: 0.0226\n",
      "Epoch 116/200, Iteration 97/250, Loss: 0.0238\n",
      "Epoch 116/200, Iteration 98/250, Loss: 0.0231\n",
      "Epoch 116/200, Iteration 99/250, Loss: 0.0069\n",
      "Epoch 116/200, Iteration 100/250, Loss: 0.0255\n",
      "Epoch 116/200, Iteration 101/250, Loss: 0.0272\n",
      "Epoch 116/200, Iteration 102/250, Loss: 0.0160\n",
      "Epoch 116/200, Iteration 103/250, Loss: 0.0239\n",
      "Epoch 116/200, Iteration 104/250, Loss: 0.0135\n",
      "Epoch 116/200, Iteration 105/250, Loss: 0.0093\n",
      "Epoch 116/200, Iteration 106/250, Loss: 0.0167\n",
      "Epoch 116/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 116/200, Iteration 108/250, Loss: 0.0135\n",
      "Epoch 116/200, Iteration 109/250, Loss: 0.0091\n",
      "Epoch 116/200, Iteration 110/250, Loss: 0.0116\n",
      "Epoch 116/200, Iteration 111/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 112/250, Loss: 0.0136\n",
      "Epoch 116/200, Iteration 113/250, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 114/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 115/250, Loss: 0.0101\n",
      "Epoch 116/200, Iteration 116/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 117/250, Loss: 0.0127\n",
      "Epoch 116/200, Iteration 118/250, Loss: 0.0162\n",
      "Epoch 116/200, Iteration 119/250, Loss: 0.0111\n",
      "Epoch 116/200, Iteration 120/250, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 121/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 122/250, Loss: 0.0103\n",
      "Epoch 116/200, Iteration 123/250, Loss: 0.0244\n",
      "Epoch 116/200, Iteration 124/250, Loss: 0.0244\n",
      "Epoch 116/200, Iteration 125/250, Loss: 0.0130\n",
      "Epoch 116/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 116/200, Iteration 127/250, Loss: 0.0077\n",
      "Epoch 116/200, Iteration 128/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 129/250, Loss: 0.0212\n",
      "Epoch 116/200, Iteration 130/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 131/250, Loss: 0.0243\n",
      "Epoch 116/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 116/200, Iteration 133/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 134/250, Loss: 0.0087\n",
      "Epoch 116/200, Iteration 135/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 137/250, Loss: 0.0111\n",
      "Epoch 116/200, Iteration 138/250, Loss: 0.0203\n",
      "Epoch 116/200, Iteration 139/250, Loss: 0.0156\n",
      "Epoch 116/200, Iteration 140/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 141/250, Loss: 0.0192\n",
      "Epoch 116/200, Iteration 142/250, Loss: 0.0074\n",
      "Epoch 116/200, Iteration 143/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 145/250, Loss: 0.0076\n",
      "Epoch 116/200, Iteration 146/250, Loss: 0.0163\n",
      "Epoch 116/200, Iteration 147/250, Loss: 0.0112\n",
      "Epoch 116/200, Iteration 148/250, Loss: 0.0067\n",
      "Epoch 116/200, Iteration 149/250, Loss: 0.0132\n",
      "Epoch 116/200, Iteration 150/250, Loss: 0.0196\n",
      "Epoch 116/200, Iteration 151/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 152/250, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 153/250, Loss: 0.0155\n",
      "Epoch 116/200, Iteration 154/250, Loss: 0.0271\n",
      "Epoch 116/200, Iteration 155/250, Loss: 0.0213\n",
      "Epoch 116/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 116/200, Iteration 157/250, Loss: 0.0180\n",
      "Epoch 116/200, Iteration 158/250, Loss: 0.0201\n",
      "Epoch 116/200, Iteration 159/250, Loss: 0.0267\n",
      "Epoch 116/200, Iteration 160/250, Loss: 0.0253\n",
      "Epoch 116/200, Iteration 161/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 162/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 164/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 165/250, Loss: 0.0114\n",
      "Epoch 116/200, Iteration 166/250, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200, Iteration 167/250, Loss: 0.0130\n",
      "Epoch 116/200, Iteration 168/250, Loss: 0.0125\n",
      "Epoch 116/200, Iteration 169/250, Loss: 0.0080\n",
      "Epoch 116/200, Iteration 170/250, Loss: 0.0227\n",
      "Epoch 116/200, Iteration 171/250, Loss: 0.0237\n",
      "Epoch 116/200, Iteration 172/250, Loss: 0.0157\n",
      "Epoch 116/200, Iteration 173/250, Loss: 0.0123\n",
      "Epoch 116/200, Iteration 174/250, Loss: 0.0097\n",
      "Epoch 116/200, Iteration 175/250, Loss: 0.0176\n",
      "Epoch 116/200, Iteration 176/250, Loss: 0.0064\n",
      "Epoch 116/200, Iteration 177/250, Loss: 0.0093\n",
      "Epoch 116/200, Iteration 178/250, Loss: 0.0119\n",
      "Epoch 116/200, Iteration 179/250, Loss: 0.0172\n",
      "Epoch 116/200, Iteration 180/250, Loss: 0.0075\n",
      "Epoch 116/200, Iteration 181/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 182/250, Loss: 0.0207\n",
      "Epoch 116/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 184/250, Loss: 0.0091\n",
      "Epoch 116/200, Iteration 185/250, Loss: 0.0091\n",
      "Epoch 116/200, Iteration 186/250, Loss: 0.0165\n",
      "Epoch 116/200, Iteration 187/250, Loss: 0.0159\n",
      "Epoch 116/200, Iteration 188/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 189/250, Loss: 0.0292\n",
      "Epoch 116/200, Iteration 190/250, Loss: 0.0075\n",
      "Epoch 116/200, Iteration 191/250, Loss: 0.0349\n",
      "Epoch 116/200, Iteration 192/250, Loss: 0.0175\n",
      "Epoch 116/200, Iteration 193/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 194/250, Loss: 0.0111\n",
      "Epoch 116/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 116/200, Iteration 196/250, Loss: 0.0128\n",
      "Epoch 116/200, Iteration 197/250, Loss: 0.0103\n",
      "Epoch 116/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 199/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 200/250, Loss: 0.0107\n",
      "Epoch 116/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 202/250, Loss: 0.0101\n",
      "Epoch 116/200, Iteration 203/250, Loss: 0.0152\n",
      "Epoch 116/200, Iteration 204/250, Loss: 0.0326\n",
      "Epoch 116/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 206/250, Loss: 0.0105\n",
      "Epoch 116/200, Iteration 207/250, Loss: 0.0168\n",
      "Epoch 116/200, Iteration 208/250, Loss: 0.0120\n",
      "Epoch 116/200, Iteration 209/250, Loss: 0.0174\n",
      "Epoch 116/200, Iteration 210/250, Loss: 0.0192\n",
      "Epoch 116/200, Iteration 211/250, Loss: 0.0183\n",
      "Epoch 116/200, Iteration 212/250, Loss: 0.0133\n",
      "Epoch 116/200, Iteration 213/250, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 214/250, Loss: 0.0138\n",
      "Epoch 116/200, Iteration 215/250, Loss: 0.0081\n",
      "Epoch 116/200, Iteration 216/250, Loss: 0.0274\n",
      "Epoch 116/200, Iteration 217/250, Loss: 0.0081\n",
      "Epoch 116/200, Iteration 218/250, Loss: 0.0309\n",
      "Epoch 116/200, Iteration 219/250, Loss: 0.0154\n",
      "Epoch 116/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 221/250, Loss: 0.0097\n",
      "Epoch 116/200, Iteration 222/250, Loss: 0.0098\n",
      "Epoch 116/200, Iteration 223/250, Loss: 0.0131\n",
      "Epoch 116/200, Iteration 224/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 225/250, Loss: 0.0113\n",
      "Epoch 116/200, Iteration 226/250, Loss: 0.0114\n",
      "Epoch 116/200, Iteration 227/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 228/250, Loss: 0.0087\n",
      "Epoch 116/200, Iteration 229/250, Loss: 0.0213\n",
      "Epoch 116/200, Iteration 230/250, Loss: 0.0074\n",
      "Epoch 116/200, Iteration 231/250, Loss: 0.0226\n",
      "Epoch 116/200, Iteration 232/250, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 233/250, Loss: 0.0152\n",
      "Epoch 116/200, Iteration 234/250, Loss: 0.0070\n",
      "Epoch 116/200, Iteration 235/250, Loss: 0.0093\n",
      "Epoch 116/200, Iteration 236/250, Loss: 0.0113\n",
      "Epoch 116/200, Iteration 237/250, Loss: 0.0188\n",
      "Epoch 116/200, Iteration 238/250, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 239/250, Loss: 0.0100\n",
      "Epoch 116/200, Iteration 240/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 241/250, Loss: 0.0114\n",
      "Epoch 116/200, Iteration 242/250, Loss: 0.0076\n",
      "Epoch 116/200, Iteration 243/250, Loss: 0.0092\n",
      "Epoch 116/200, Iteration 244/250, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 246/250, Loss: 0.0154\n",
      "Epoch 116/200, Iteration 247/250, Loss: 0.0108\n",
      "Epoch 116/200, Iteration 248/250, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 116/200, Iteration 250/250, Loss: 0.0096\n",
      "Train Error: \n",
      " Accuracy: 94.47%, Avg loss: 0.005949, MRE: 0.633987 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.005938, MRE: 1.088349 \n",
      "\n",
      "Epoch 117/200, Iteration 1/250, Loss: 0.0164\n",
      "Epoch 117/200, Iteration 2/250, Loss: 0.0082\n",
      "Epoch 117/200, Iteration 3/250, Loss: 0.0102\n",
      "Epoch 117/200, Iteration 4/250, Loss: 0.0112\n",
      "Epoch 117/200, Iteration 5/250, Loss: 0.0147\n",
      "Epoch 117/200, Iteration 6/250, Loss: 0.0135\n",
      "Epoch 117/200, Iteration 7/250, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 8/250, Loss: 0.0151\n",
      "Epoch 117/200, Iteration 9/250, Loss: 0.0153\n",
      "Epoch 117/200, Iteration 10/250, Loss: 0.0099\n",
      "Epoch 117/200, Iteration 11/250, Loss: 0.0076\n",
      "Epoch 117/200, Iteration 12/250, Loss: 0.0152\n",
      "Epoch 117/200, Iteration 13/250, Loss: 0.0059\n",
      "Epoch 117/200, Iteration 14/250, Loss: 0.0181\n",
      "Epoch 117/200, Iteration 15/250, Loss: 0.0263\n",
      "Epoch 117/200, Iteration 16/250, Loss: 0.0247\n",
      "Epoch 117/200, Iteration 17/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 18/250, Loss: 0.0093\n",
      "Epoch 117/200, Iteration 19/250, Loss: 0.0159\n",
      "Epoch 117/200, Iteration 20/250, Loss: 0.0335\n",
      "Epoch 117/200, Iteration 21/250, Loss: 0.0102\n",
      "Epoch 117/200, Iteration 22/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 23/250, Loss: 0.0069\n",
      "Epoch 117/200, Iteration 24/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 25/250, Loss: 0.0253\n",
      "Epoch 117/200, Iteration 26/250, Loss: 0.0104\n",
      "Epoch 117/200, Iteration 27/250, Loss: 0.0071\n",
      "Epoch 117/200, Iteration 28/250, Loss: 0.0168\n",
      "Epoch 117/200, Iteration 29/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 30/250, Loss: 0.0145\n",
      "Epoch 117/200, Iteration 31/250, Loss: 0.0125\n",
      "Epoch 117/200, Iteration 32/250, Loss: 0.0433\n",
      "Epoch 117/200, Iteration 33/250, Loss: 0.0211\n",
      "Epoch 117/200, Iteration 34/250, Loss: 0.0068\n",
      "Epoch 117/200, Iteration 35/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 36/250, Loss: 0.0246\n",
      "Epoch 117/200, Iteration 37/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 38/250, Loss: 0.0159\n",
      "Epoch 117/200, Iteration 39/250, Loss: 0.0210\n",
      "Epoch 117/200, Iteration 40/250, Loss: 0.0178\n",
      "Epoch 117/200, Iteration 41/250, Loss: 0.0167\n",
      "Epoch 117/200, Iteration 42/250, Loss: 0.0136\n",
      "Epoch 117/200, Iteration 43/250, Loss: 0.0298\n",
      "Epoch 117/200, Iteration 44/250, Loss: 0.0167\n",
      "Epoch 117/200, Iteration 45/250, Loss: 0.0079\n",
      "Epoch 117/200, Iteration 46/250, Loss: 0.0162\n",
      "Epoch 117/200, Iteration 47/250, Loss: 0.0079\n",
      "Epoch 117/200, Iteration 48/250, Loss: 0.0154\n",
      "Epoch 117/200, Iteration 49/250, Loss: 0.0312\n",
      "Epoch 117/200, Iteration 50/250, Loss: 0.0199\n",
      "Epoch 117/200, Iteration 51/250, Loss: 0.0218\n",
      "Epoch 117/200, Iteration 52/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 53/250, Loss: 0.0338\n",
      "Epoch 117/200, Iteration 54/250, Loss: 0.0122\n",
      "Epoch 117/200, Iteration 55/250, Loss: 0.0160\n",
      "Epoch 117/200, Iteration 56/250, Loss: 0.0201\n",
      "Epoch 117/200, Iteration 57/250, Loss: 0.0082\n",
      "Epoch 117/200, Iteration 58/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 59/250, Loss: 0.0113\n",
      "Epoch 117/200, Iteration 60/250, Loss: 0.0130\n",
      "Epoch 117/200, Iteration 61/250, Loss: 0.0161\n",
      "Epoch 117/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 117/200, Iteration 63/250, Loss: 0.0158\n",
      "Epoch 117/200, Iteration 64/250, Loss: 0.0183\n",
      "Epoch 117/200, Iteration 65/250, Loss: 0.0132\n",
      "Epoch 117/200, Iteration 66/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 67/250, Loss: 0.0175\n",
      "Epoch 117/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 117/200, Iteration 69/250, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 70/250, Loss: 0.0146\n",
      "Epoch 117/200, Iteration 71/250, Loss: 0.0209\n",
      "Epoch 117/200, Iteration 72/250, Loss: 0.0187\n",
      "Epoch 117/200, Iteration 73/250, Loss: 0.0266\n",
      "Epoch 117/200, Iteration 74/250, Loss: 0.0093\n",
      "Epoch 117/200, Iteration 75/250, Loss: 0.0189\n",
      "Epoch 117/200, Iteration 76/250, Loss: 0.0176\n",
      "Epoch 117/200, Iteration 77/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 79/250, Loss: 0.0099\n",
      "Epoch 117/200, Iteration 80/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 81/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 82/250, Loss: 0.0060\n",
      "Epoch 117/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 117/200, Iteration 84/250, Loss: 0.0127\n",
      "Epoch 117/200, Iteration 85/250, Loss: 0.0170\n",
      "Epoch 117/200, Iteration 86/250, Loss: 0.0074\n",
      "Epoch 117/200, Iteration 87/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 88/250, Loss: 0.0100\n",
      "Epoch 117/200, Iteration 89/250, Loss: 0.0224\n",
      "Epoch 117/200, Iteration 90/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 117/200, Iteration 92/250, Loss: 0.0157\n",
      "Epoch 117/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 94/250, Loss: 0.0056\n",
      "Epoch 117/200, Iteration 95/250, Loss: 0.0132\n",
      "Epoch 117/200, Iteration 96/250, Loss: 0.0169\n",
      "Epoch 117/200, Iteration 97/250, Loss: 0.0085\n",
      "Epoch 117/200, Iteration 98/250, Loss: 0.0395\n",
      "Epoch 117/200, Iteration 99/250, Loss: 0.0146\n",
      "Epoch 117/200, Iteration 100/250, Loss: 0.0120\n",
      "Epoch 117/200, Iteration 101/250, Loss: 0.0079\n",
      "Epoch 117/200, Iteration 102/250, Loss: 0.0115\n",
      "Epoch 117/200, Iteration 103/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 104/250, Loss: 0.0048\n",
      "Epoch 117/200, Iteration 105/250, Loss: 0.0130\n",
      "Epoch 117/200, Iteration 106/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 107/250, Loss: 0.0137\n",
      "Epoch 117/200, Iteration 108/250, Loss: 0.0163\n",
      "Epoch 117/200, Iteration 109/250, Loss: 0.0094\n",
      "Epoch 117/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 117/200, Iteration 111/250, Loss: 0.0232\n",
      "Epoch 117/200, Iteration 112/250, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200, Iteration 113/250, Loss: 0.0287\n",
      "Epoch 117/200, Iteration 114/250, Loss: 0.0229\n",
      "Epoch 117/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 117/200, Iteration 116/250, Loss: 0.0135\n",
      "Epoch 117/200, Iteration 117/250, Loss: 0.0343\n",
      "Epoch 117/200, Iteration 118/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 119/250, Loss: 0.0090\n",
      "Epoch 117/200, Iteration 120/250, Loss: 0.0158\n",
      "Epoch 117/200, Iteration 121/250, Loss: 0.0089\n",
      "Epoch 117/200, Iteration 122/250, Loss: 0.0164\n",
      "Epoch 117/200, Iteration 123/250, Loss: 0.0141\n",
      "Epoch 117/200, Iteration 124/250, Loss: 0.0209\n",
      "Epoch 117/200, Iteration 125/250, Loss: 0.0214\n",
      "Epoch 117/200, Iteration 126/250, Loss: 0.0201\n",
      "Epoch 117/200, Iteration 127/250, Loss: 0.0155\n",
      "Epoch 117/200, Iteration 128/250, Loss: 0.0059\n",
      "Epoch 117/200, Iteration 129/250, Loss: 0.0119\n",
      "Epoch 117/200, Iteration 130/250, Loss: 0.0132\n",
      "Epoch 117/200, Iteration 131/250, Loss: 0.0154\n",
      "Epoch 117/200, Iteration 132/250, Loss: 0.0105\n",
      "Epoch 117/200, Iteration 133/250, Loss: 0.0248\n",
      "Epoch 117/200, Iteration 134/250, Loss: 0.0098\n",
      "Epoch 117/200, Iteration 135/250, Loss: 0.0085\n",
      "Epoch 117/200, Iteration 136/250, Loss: 0.0122\n",
      "Epoch 117/200, Iteration 137/250, Loss: 0.0149\n",
      "Epoch 117/200, Iteration 138/250, Loss: 0.0090\n",
      "Epoch 117/200, Iteration 139/250, Loss: 0.0174\n",
      "Epoch 117/200, Iteration 140/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 141/250, Loss: 0.0108\n",
      "Epoch 117/200, Iteration 142/250, Loss: 0.0145\n",
      "Epoch 117/200, Iteration 143/250, Loss: 0.0139\n",
      "Epoch 117/200, Iteration 144/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 145/250, Loss: 0.0129\n",
      "Epoch 117/200, Iteration 146/250, Loss: 0.0185\n",
      "Epoch 117/200, Iteration 147/250, Loss: 0.0141\n",
      "Epoch 117/200, Iteration 148/250, Loss: 0.0237\n",
      "Epoch 117/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 150/250, Loss: 0.0158\n",
      "Epoch 117/200, Iteration 151/250, Loss: 0.0149\n",
      "Epoch 117/200, Iteration 152/250, Loss: 0.0281\n",
      "Epoch 117/200, Iteration 153/250, Loss: 0.0106\n",
      "Epoch 117/200, Iteration 154/250, Loss: 0.0068\n",
      "Epoch 117/200, Iteration 155/250, Loss: 0.0171\n",
      "Epoch 117/200, Iteration 156/250, Loss: 0.0093\n",
      "Epoch 117/200, Iteration 157/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 158/250, Loss: 0.0162\n",
      "Epoch 117/200, Iteration 159/250, Loss: 0.0239\n",
      "Epoch 117/200, Iteration 160/250, Loss: 0.0141\n",
      "Epoch 117/200, Iteration 161/250, Loss: 0.0196\n",
      "Epoch 117/200, Iteration 162/250, Loss: 0.0129\n",
      "Epoch 117/200, Iteration 163/250, Loss: 0.0151\n",
      "Epoch 117/200, Iteration 164/250, Loss: 0.0066\n",
      "Epoch 117/200, Iteration 165/250, Loss: 0.0185\n",
      "Epoch 117/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 117/200, Iteration 167/250, Loss: 0.0173\n",
      "Epoch 117/200, Iteration 168/250, Loss: 0.0115\n",
      "Epoch 117/200, Iteration 169/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 170/250, Loss: 0.0111\n",
      "Epoch 117/200, Iteration 171/250, Loss: 0.0105\n",
      "Epoch 117/200, Iteration 172/250, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 173/250, Loss: 0.0158\n",
      "Epoch 117/200, Iteration 174/250, Loss: 0.0110\n",
      "Epoch 117/200, Iteration 175/250, Loss: 0.0097\n",
      "Epoch 117/200, Iteration 176/250, Loss: 0.0120\n",
      "Epoch 117/200, Iteration 177/250, Loss: 0.0111\n",
      "Epoch 117/200, Iteration 178/250, Loss: 0.0185\n",
      "Epoch 117/200, Iteration 179/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 180/250, Loss: 0.0072\n",
      "Epoch 117/200, Iteration 181/250, Loss: 0.0142\n",
      "Epoch 117/200, Iteration 182/250, Loss: 0.0200\n",
      "Epoch 117/200, Iteration 183/250, Loss: 0.0127\n",
      "Epoch 117/200, Iteration 184/250, Loss: 0.0120\n",
      "Epoch 117/200, Iteration 185/250, Loss: 0.0118\n",
      "Epoch 117/200, Iteration 186/250, Loss: 0.0069\n",
      "Epoch 117/200, Iteration 187/250, Loss: 0.0195\n",
      "Epoch 117/200, Iteration 188/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 189/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 190/250, Loss: 0.0234\n",
      "Epoch 117/200, Iteration 191/250, Loss: 0.0142\n",
      "Epoch 117/200, Iteration 192/250, Loss: 0.0239\n",
      "Epoch 117/200, Iteration 193/250, Loss: 0.0131\n",
      "Epoch 117/200, Iteration 194/250, Loss: 0.0083\n",
      "Epoch 117/200, Iteration 195/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 196/250, Loss: 0.0320\n",
      "Epoch 117/200, Iteration 197/250, Loss: 0.0242\n",
      "Epoch 117/200, Iteration 198/250, Loss: 0.0121\n",
      "Epoch 117/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 117/200, Iteration 200/250, Loss: 0.0200\n",
      "Epoch 117/200, Iteration 201/250, Loss: 0.0077\n",
      "Epoch 117/200, Iteration 202/250, Loss: 0.0125\n",
      "Epoch 117/200, Iteration 203/250, Loss: 0.0209\n",
      "Epoch 117/200, Iteration 204/250, Loss: 0.0187\n",
      "Epoch 117/200, Iteration 205/250, Loss: 0.0115\n",
      "Epoch 117/200, Iteration 206/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 207/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 208/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 209/250, Loss: 0.0203\n",
      "Epoch 117/200, Iteration 210/250, Loss: 0.0172\n",
      "Epoch 117/200, Iteration 211/250, Loss: 0.0154\n",
      "Epoch 117/200, Iteration 212/250, Loss: 0.0146\n",
      "Epoch 117/200, Iteration 213/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 214/250, Loss: 0.0152\n",
      "Epoch 117/200, Iteration 215/250, Loss: 0.0183\n",
      "Epoch 117/200, Iteration 216/250, Loss: 0.0248\n",
      "Epoch 117/200, Iteration 217/250, Loss: 0.0218\n",
      "Epoch 117/200, Iteration 218/250, Loss: 0.0056\n",
      "Epoch 117/200, Iteration 219/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 220/250, Loss: 0.0081\n",
      "Epoch 117/200, Iteration 221/250, Loss: 0.0074\n",
      "Epoch 117/200, Iteration 222/250, Loss: 0.0308\n",
      "Epoch 117/200, Iteration 223/250, Loss: 0.0140\n",
      "Epoch 117/200, Iteration 224/250, Loss: 0.0218\n",
      "Epoch 117/200, Iteration 225/250, Loss: 0.0153\n",
      "Epoch 117/200, Iteration 226/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 227/250, Loss: 0.0146\n",
      "Epoch 117/200, Iteration 228/250, Loss: 0.0098\n",
      "Epoch 117/200, Iteration 229/250, Loss: 0.0187\n",
      "Epoch 117/200, Iteration 230/250, Loss: 0.0094\n",
      "Epoch 117/200, Iteration 231/250, Loss: 0.0250\n",
      "Epoch 117/200, Iteration 232/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 233/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 234/250, Loss: 0.0179\n",
      "Epoch 117/200, Iteration 235/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 236/250, Loss: 0.0150\n",
      "Epoch 117/200, Iteration 237/250, Loss: 0.0192\n",
      "Epoch 117/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 117/200, Iteration 239/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 240/250, Loss: 0.0135\n",
      "Epoch 117/200, Iteration 241/250, Loss: 0.0200\n",
      "Epoch 117/200, Iteration 242/250, Loss: 0.0078\n",
      "Epoch 117/200, Iteration 243/250, Loss: 0.0137\n",
      "Epoch 117/200, Iteration 244/250, Loss: 0.0040\n",
      "Epoch 117/200, Iteration 245/250, Loss: 0.0296\n",
      "Epoch 117/200, Iteration 246/250, Loss: 0.0224\n",
      "Epoch 117/200, Iteration 247/250, Loss: 0.0223\n",
      "Epoch 117/200, Iteration 248/250, Loss: 0.0113\n",
      "Epoch 117/200, Iteration 249/250, Loss: 0.0140\n",
      "Epoch 117/200, Iteration 250/250, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 95.05%, Avg loss: 0.005936, MRE: 0.627912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.95%, Avg loss: 0.005940, MRE: 1.076517 \n",
      "\n",
      "Epoch 118/200, Iteration 1/250, Loss: 0.0156\n",
      "Epoch 118/200, Iteration 2/250, Loss: 0.0197\n",
      "Epoch 118/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 4/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 5/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 6/250, Loss: 0.0129\n",
      "Epoch 118/200, Iteration 7/250, Loss: 0.0066\n",
      "Epoch 118/200, Iteration 8/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 9/250, Loss: 0.0301\n",
      "Epoch 118/200, Iteration 10/250, Loss: 0.0173\n",
      "Epoch 118/200, Iteration 11/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 12/250, Loss: 0.0235\n",
      "Epoch 118/200, Iteration 13/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 14/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 15/250, Loss: 0.0176\n",
      "Epoch 118/200, Iteration 16/250, Loss: 0.0176\n",
      "Epoch 118/200, Iteration 17/250, Loss: 0.0138\n",
      "Epoch 118/200, Iteration 18/250, Loss: 0.0304\n",
      "Epoch 118/200, Iteration 19/250, Loss: 0.0065\n",
      "Epoch 118/200, Iteration 20/250, Loss: 0.0187\n",
      "Epoch 118/200, Iteration 21/250, Loss: 0.0432\n",
      "Epoch 118/200, Iteration 22/250, Loss: 0.0273\n",
      "Epoch 118/200, Iteration 23/250, Loss: 0.0182\n",
      "Epoch 118/200, Iteration 24/250, Loss: 0.0154\n",
      "Epoch 118/200, Iteration 25/250, Loss: 0.0131\n",
      "Epoch 118/200, Iteration 26/250, Loss: 0.0147\n",
      "Epoch 118/200, Iteration 27/250, Loss: 0.0188\n",
      "Epoch 118/200, Iteration 28/250, Loss: 0.0343\n",
      "Epoch 118/200, Iteration 29/250, Loss: 0.0153\n",
      "Epoch 118/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 31/250, Loss: 0.0133\n",
      "Epoch 118/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 118/200, Iteration 33/250, Loss: 0.0111\n",
      "Epoch 118/200, Iteration 34/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 35/250, Loss: 0.0099\n",
      "Epoch 118/200, Iteration 36/250, Loss: 0.0220\n",
      "Epoch 118/200, Iteration 37/250, Loss: 0.0340\n",
      "Epoch 118/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 118/200, Iteration 39/250, Loss: 0.0070\n",
      "Epoch 118/200, Iteration 40/250, Loss: 0.0154\n",
      "Epoch 118/200, Iteration 41/250, Loss: 0.0172\n",
      "Epoch 118/200, Iteration 42/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 43/250, Loss: 0.0274\n",
      "Epoch 118/200, Iteration 44/250, Loss: 0.0082\n",
      "Epoch 118/200, Iteration 45/250, Loss: 0.0209\n",
      "Epoch 118/200, Iteration 46/250, Loss: 0.0182\n",
      "Epoch 118/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 118/200, Iteration 48/250, Loss: 0.0302\n",
      "Epoch 118/200, Iteration 49/250, Loss: 0.0219\n",
      "Epoch 118/200, Iteration 50/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 51/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 52/250, Loss: 0.0148\n",
      "Epoch 118/200, Iteration 53/250, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 54/250, Loss: 0.0173\n",
      "Epoch 118/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 118/200, Iteration 56/250, Loss: 0.0172\n",
      "Epoch 118/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 118/200, Iteration 59/250, Loss: 0.0156\n",
      "Epoch 118/200, Iteration 60/250, Loss: 0.0140\n",
      "Epoch 118/200, Iteration 61/250, Loss: 0.0093\n",
      "Epoch 118/200, Iteration 62/250, Loss: 0.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200, Iteration 63/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 64/250, Loss: 0.0076\n",
      "Epoch 118/200, Iteration 65/250, Loss: 0.0206\n",
      "Epoch 118/200, Iteration 66/250, Loss: 0.0221\n",
      "Epoch 118/200, Iteration 67/250, Loss: 0.0240\n",
      "Epoch 118/200, Iteration 68/250, Loss: 0.0081\n",
      "Epoch 118/200, Iteration 69/250, Loss: 0.0157\n",
      "Epoch 118/200, Iteration 70/250, Loss: 0.0136\n",
      "Epoch 118/200, Iteration 71/250, Loss: 0.0120\n",
      "Epoch 118/200, Iteration 72/250, Loss: 0.0199\n",
      "Epoch 118/200, Iteration 73/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 74/250, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 75/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 76/250, Loss: 0.0133\n",
      "Epoch 118/200, Iteration 77/250, Loss: 0.0073\n",
      "Epoch 118/200, Iteration 78/250, Loss: 0.0149\n",
      "Epoch 118/200, Iteration 79/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 80/250, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 118/200, Iteration 82/250, Loss: 0.0358\n",
      "Epoch 118/200, Iteration 83/250, Loss: 0.0163\n",
      "Epoch 118/200, Iteration 84/250, Loss: 0.0085\n",
      "Epoch 118/200, Iteration 85/250, Loss: 0.0144\n",
      "Epoch 118/200, Iteration 86/250, Loss: 0.0181\n",
      "Epoch 118/200, Iteration 87/250, Loss: 0.0124\n",
      "Epoch 118/200, Iteration 88/250, Loss: 0.0091\n",
      "Epoch 118/200, Iteration 89/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 90/250, Loss: 0.0323\n",
      "Epoch 118/200, Iteration 91/250, Loss: 0.0121\n",
      "Epoch 118/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 93/250, Loss: 0.0125\n",
      "Epoch 118/200, Iteration 94/250, Loss: 0.0279\n",
      "Epoch 118/200, Iteration 95/250, Loss: 0.0606\n",
      "Epoch 118/200, Iteration 96/250, Loss: 0.0258\n",
      "Epoch 118/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 118/200, Iteration 98/250, Loss: 0.0124\n",
      "Epoch 118/200, Iteration 99/250, Loss: 0.0268\n",
      "Epoch 118/200, Iteration 100/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 101/250, Loss: 0.0073\n",
      "Epoch 118/200, Iteration 102/250, Loss: 0.0398\n",
      "Epoch 118/200, Iteration 103/250, Loss: 0.0212\n",
      "Epoch 118/200, Iteration 104/250, Loss: 0.0149\n",
      "Epoch 118/200, Iteration 105/250, Loss: 0.0156\n",
      "Epoch 118/200, Iteration 106/250, Loss: 0.0345\n",
      "Epoch 118/200, Iteration 107/250, Loss: 0.0141\n",
      "Epoch 118/200, Iteration 108/250, Loss: 0.0210\n",
      "Epoch 118/200, Iteration 109/250, Loss: 0.0065\n",
      "Epoch 118/200, Iteration 110/250, Loss: 0.0136\n",
      "Epoch 118/200, Iteration 111/250, Loss: 0.0335\n",
      "Epoch 118/200, Iteration 112/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 113/250, Loss: 0.0303\n",
      "Epoch 118/200, Iteration 114/250, Loss: 0.0121\n",
      "Epoch 118/200, Iteration 115/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 116/250, Loss: 0.0070\n",
      "Epoch 118/200, Iteration 117/250, Loss: 0.0218\n",
      "Epoch 118/200, Iteration 118/250, Loss: 0.0265\n",
      "Epoch 118/200, Iteration 119/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 120/250, Loss: 0.0179\n",
      "Epoch 118/200, Iteration 121/250, Loss: 0.0086\n",
      "Epoch 118/200, Iteration 122/250, Loss: 0.0206\n",
      "Epoch 118/200, Iteration 123/250, Loss: 0.0171\n",
      "Epoch 118/200, Iteration 124/250, Loss: 0.0116\n",
      "Epoch 118/200, Iteration 125/250, Loss: 0.0144\n",
      "Epoch 118/200, Iteration 126/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 127/250, Loss: 0.0239\n",
      "Epoch 118/200, Iteration 128/250, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 129/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 130/250, Loss: 0.0107\n",
      "Epoch 118/200, Iteration 131/250, Loss: 0.0319\n",
      "Epoch 118/200, Iteration 132/250, Loss: 0.0129\n",
      "Epoch 118/200, Iteration 133/250, Loss: 0.0187\n",
      "Epoch 118/200, Iteration 134/250, Loss: 0.0086\n",
      "Epoch 118/200, Iteration 135/250, Loss: 0.0144\n",
      "Epoch 118/200, Iteration 136/250, Loss: 0.0204\n",
      "Epoch 118/200, Iteration 137/250, Loss: 0.0164\n",
      "Epoch 118/200, Iteration 138/250, Loss: 0.0069\n",
      "Epoch 118/200, Iteration 139/250, Loss: 0.0097\n",
      "Epoch 118/200, Iteration 140/250, Loss: 0.0105\n",
      "Epoch 118/200, Iteration 141/250, Loss: 0.0138\n",
      "Epoch 118/200, Iteration 142/250, Loss: 0.0084\n",
      "Epoch 118/200, Iteration 143/250, Loss: 0.0155\n",
      "Epoch 118/200, Iteration 144/250, Loss: 0.0179\n",
      "Epoch 118/200, Iteration 145/250, Loss: 0.0074\n",
      "Epoch 118/200, Iteration 146/250, Loss: 0.0064\n",
      "Epoch 118/200, Iteration 147/250, Loss: 0.0192\n",
      "Epoch 118/200, Iteration 148/250, Loss: 0.0146\n",
      "Epoch 118/200, Iteration 149/250, Loss: 0.0135\n",
      "Epoch 118/200, Iteration 150/250, Loss: 0.0060\n",
      "Epoch 118/200, Iteration 151/250, Loss: 0.0129\n",
      "Epoch 118/200, Iteration 152/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 153/250, Loss: 0.0139\n",
      "Epoch 118/200, Iteration 154/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 155/250, Loss: 0.0116\n",
      "Epoch 118/200, Iteration 156/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 157/250, Loss: 0.0182\n",
      "Epoch 118/200, Iteration 158/250, Loss: 0.0068\n",
      "Epoch 118/200, Iteration 159/250, Loss: 0.0167\n",
      "Epoch 118/200, Iteration 160/250, Loss: 0.0076\n",
      "Epoch 118/200, Iteration 161/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 118/200, Iteration 163/250, Loss: 0.0070\n",
      "Epoch 118/200, Iteration 164/250, Loss: 0.0310\n",
      "Epoch 118/200, Iteration 165/250, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 166/250, Loss: 0.0120\n",
      "Epoch 118/200, Iteration 167/250, Loss: 0.0153\n",
      "Epoch 118/200, Iteration 168/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 169/250, Loss: 0.0124\n",
      "Epoch 118/200, Iteration 170/250, Loss: 0.0075\n",
      "Epoch 118/200, Iteration 171/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 172/250, Loss: 0.0084\n",
      "Epoch 118/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 118/200, Iteration 174/250, Loss: 0.0146\n",
      "Epoch 118/200, Iteration 175/250, Loss: 0.0113\n",
      "Epoch 118/200, Iteration 176/250, Loss: 0.0080\n",
      "Epoch 118/200, Iteration 177/250, Loss: 0.0092\n",
      "Epoch 118/200, Iteration 178/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 179/250, Loss: 0.0084\n",
      "Epoch 118/200, Iteration 180/250, Loss: 0.0116\n",
      "Epoch 118/200, Iteration 181/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 182/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 183/250, Loss: 0.0225\n",
      "Epoch 118/200, Iteration 184/250, Loss: 0.0267\n",
      "Epoch 118/200, Iteration 185/250, Loss: 0.0238\n",
      "Epoch 118/200, Iteration 186/250, Loss: 0.0128\n",
      "Epoch 118/200, Iteration 187/250, Loss: 0.0120\n",
      "Epoch 118/200, Iteration 188/250, Loss: 0.0209\n",
      "Epoch 118/200, Iteration 189/250, Loss: 0.0067\n",
      "Epoch 118/200, Iteration 190/250, Loss: 0.0114\n",
      "Epoch 118/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 192/250, Loss: 0.0184\n",
      "Epoch 118/200, Iteration 193/250, Loss: 0.0085\n",
      "Epoch 118/200, Iteration 194/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 195/250, Loss: 0.0167\n",
      "Epoch 118/200, Iteration 196/250, Loss: 0.0240\n",
      "Epoch 118/200, Iteration 197/250, Loss: 0.0099\n",
      "Epoch 118/200, Iteration 198/250, Loss: 0.0129\n",
      "Epoch 118/200, Iteration 199/250, Loss: 0.0142\n",
      "Epoch 118/200, Iteration 200/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 201/250, Loss: 0.0094\n",
      "Epoch 118/200, Iteration 202/250, Loss: 0.0195\n",
      "Epoch 118/200, Iteration 203/250, Loss: 0.0278\n",
      "Epoch 118/200, Iteration 204/250, Loss: 0.0177\n",
      "Epoch 118/200, Iteration 205/250, Loss: 0.0081\n",
      "Epoch 118/200, Iteration 206/250, Loss: 0.0150\n",
      "Epoch 118/200, Iteration 207/250, Loss: 0.0352\n",
      "Epoch 118/200, Iteration 208/250, Loss: 0.0417\n",
      "Epoch 118/200, Iteration 209/250, Loss: 0.0230\n",
      "Epoch 118/200, Iteration 210/250, Loss: 0.0145\n",
      "Epoch 118/200, Iteration 211/250, Loss: 0.0118\n",
      "Epoch 118/200, Iteration 212/250, Loss: 0.0161\n",
      "Epoch 118/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 214/250, Loss: 0.0136\n",
      "Epoch 118/200, Iteration 215/250, Loss: 0.0090\n",
      "Epoch 118/200, Iteration 216/250, Loss: 0.0131\n",
      "Epoch 118/200, Iteration 217/250, Loss: 0.0360\n",
      "Epoch 118/200, Iteration 218/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 118/200, Iteration 220/250, Loss: 0.0174\n",
      "Epoch 118/200, Iteration 221/250, Loss: 0.0219\n",
      "Epoch 118/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 118/200, Iteration 223/250, Loss: 0.0149\n",
      "Epoch 118/200, Iteration 224/250, Loss: 0.0121\n",
      "Epoch 118/200, Iteration 225/250, Loss: 0.0086\n",
      "Epoch 118/200, Iteration 226/250, Loss: 0.0099\n",
      "Epoch 118/200, Iteration 227/250, Loss: 0.0069\n",
      "Epoch 118/200, Iteration 228/250, Loss: 0.0141\n",
      "Epoch 118/200, Iteration 229/250, Loss: 0.0294\n",
      "Epoch 118/200, Iteration 230/250, Loss: 0.0260\n",
      "Epoch 118/200, Iteration 231/250, Loss: 0.0243\n",
      "Epoch 118/200, Iteration 232/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 233/250, Loss: 0.0350\n",
      "Epoch 118/200, Iteration 234/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 235/250, Loss: 0.0210\n",
      "Epoch 118/200, Iteration 236/250, Loss: 0.0121\n",
      "Epoch 118/200, Iteration 237/250, Loss: 0.0140\n",
      "Epoch 118/200, Iteration 238/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 239/250, Loss: 0.0165\n",
      "Epoch 118/200, Iteration 240/250, Loss: 0.0304\n",
      "Epoch 118/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 243/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 244/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200, Iteration 245/250, Loss: 0.0151\n",
      "Epoch 118/200, Iteration 246/250, Loss: 0.0217\n",
      "Epoch 118/200, Iteration 247/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 248/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 249/250, Loss: 0.0167\n",
      "Epoch 118/200, Iteration 250/250, Loss: 0.0155\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.006507, MRE: 0.664558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.006439, MRE: 1.114222 \n",
      "\n",
      "Epoch 119/200, Iteration 1/250, Loss: 0.0138\n",
      "Epoch 119/200, Iteration 2/250, Loss: 0.0112\n",
      "Epoch 119/200, Iteration 3/250, Loss: 0.0137\n",
      "Epoch 119/200, Iteration 4/250, Loss: 0.0065\n",
      "Epoch 119/200, Iteration 5/250, Loss: 0.0202\n",
      "Epoch 119/200, Iteration 6/250, Loss: 0.0222\n",
      "Epoch 119/200, Iteration 7/250, Loss: 0.0097\n",
      "Epoch 119/200, Iteration 8/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 9/250, Loss: 0.0135\n",
      "Epoch 119/200, Iteration 10/250, Loss: 0.0262\n",
      "Epoch 119/200, Iteration 11/250, Loss: 0.0144\n",
      "Epoch 119/200, Iteration 12/250, Loss: 0.0147\n",
      "Epoch 119/200, Iteration 13/250, Loss: 0.0213\n",
      "Epoch 119/200, Iteration 14/250, Loss: 0.0137\n",
      "Epoch 119/200, Iteration 15/250, Loss: 0.0290\n",
      "Epoch 119/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 119/200, Iteration 17/250, Loss: 0.0266\n",
      "Epoch 119/200, Iteration 18/250, Loss: 0.0143\n",
      "Epoch 119/200, Iteration 19/250, Loss: 0.0292\n",
      "Epoch 119/200, Iteration 20/250, Loss: 0.0261\n",
      "Epoch 119/200, Iteration 21/250, Loss: 0.0172\n",
      "Epoch 119/200, Iteration 22/250, Loss: 0.0076\n",
      "Epoch 119/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 119/200, Iteration 24/250, Loss: 0.0161\n",
      "Epoch 119/200, Iteration 25/250, Loss: 0.0126\n",
      "Epoch 119/200, Iteration 26/250, Loss: 0.0069\n",
      "Epoch 119/200, Iteration 27/250, Loss: 0.0228\n",
      "Epoch 119/200, Iteration 28/250, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 29/250, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 30/250, Loss: 0.0168\n",
      "Epoch 119/200, Iteration 31/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 32/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 33/250, Loss: 0.0118\n",
      "Epoch 119/200, Iteration 34/250, Loss: 0.0215\n",
      "Epoch 119/200, Iteration 35/250, Loss: 0.0192\n",
      "Epoch 119/200, Iteration 36/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 37/250, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 39/250, Loss: 0.0121\n",
      "Epoch 119/200, Iteration 40/250, Loss: 0.0095\n",
      "Epoch 119/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 119/200, Iteration 42/250, Loss: 0.0384\n",
      "Epoch 119/200, Iteration 43/250, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 44/250, Loss: 0.0185\n",
      "Epoch 119/200, Iteration 45/250, Loss: 0.0098\n",
      "Epoch 119/200, Iteration 46/250, Loss: 0.0230\n",
      "Epoch 119/200, Iteration 47/250, Loss: 0.0288\n",
      "Epoch 119/200, Iteration 48/250, Loss: 0.0218\n",
      "Epoch 119/200, Iteration 49/250, Loss: 0.0271\n",
      "Epoch 119/200, Iteration 50/250, Loss: 0.0346\n",
      "Epoch 119/200, Iteration 51/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 52/250, Loss: 0.0174\n",
      "Epoch 119/200, Iteration 53/250, Loss: 0.0126\n",
      "Epoch 119/200, Iteration 54/250, Loss: 0.0117\n",
      "Epoch 119/200, Iteration 55/250, Loss: 0.0144\n",
      "Epoch 119/200, Iteration 56/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 57/250, Loss: 0.0116\n",
      "Epoch 119/200, Iteration 58/250, Loss: 0.0206\n",
      "Epoch 119/200, Iteration 59/250, Loss: 0.0200\n",
      "Epoch 119/200, Iteration 60/250, Loss: 0.0208\n",
      "Epoch 119/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 119/200, Iteration 62/250, Loss: 0.0215\n",
      "Epoch 119/200, Iteration 63/250, Loss: 0.0206\n",
      "Epoch 119/200, Iteration 64/250, Loss: 0.0081\n",
      "Epoch 119/200, Iteration 65/250, Loss: 0.0242\n",
      "Epoch 119/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 67/250, Loss: 0.0057\n",
      "Epoch 119/200, Iteration 68/250, Loss: 0.0261\n",
      "Epoch 119/200, Iteration 69/250, Loss: 0.0082\n",
      "Epoch 119/200, Iteration 70/250, Loss: 0.0140\n",
      "Epoch 119/200, Iteration 71/250, Loss: 0.0097\n",
      "Epoch 119/200, Iteration 72/250, Loss: 0.0073\n",
      "Epoch 119/200, Iteration 73/250, Loss: 0.0152\n",
      "Epoch 119/200, Iteration 74/250, Loss: 0.0097\n",
      "Epoch 119/200, Iteration 75/250, Loss: 0.0142\n",
      "Epoch 119/200, Iteration 76/250, Loss: 0.0200\n",
      "Epoch 119/200, Iteration 77/250, Loss: 0.0135\n",
      "Epoch 119/200, Iteration 78/250, Loss: 0.0151\n",
      "Epoch 119/200, Iteration 79/250, Loss: 0.0118\n",
      "Epoch 119/200, Iteration 80/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 81/250, Loss: 0.0252\n",
      "Epoch 119/200, Iteration 82/250, Loss: 0.0228\n",
      "Epoch 119/200, Iteration 83/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 84/250, Loss: 0.0168\n",
      "Epoch 119/200, Iteration 85/250, Loss: 0.0219\n",
      "Epoch 119/200, Iteration 86/250, Loss: 0.0099\n",
      "Epoch 119/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 119/200, Iteration 88/250, Loss: 0.0116\n",
      "Epoch 119/200, Iteration 89/250, Loss: 0.0149\n",
      "Epoch 119/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 119/200, Iteration 91/250, Loss: 0.0186\n",
      "Epoch 119/200, Iteration 92/250, Loss: 0.0154\n",
      "Epoch 119/200, Iteration 93/250, Loss: 0.0093\n",
      "Epoch 119/200, Iteration 94/250, Loss: 0.0131\n",
      "Epoch 119/200, Iteration 95/250, Loss: 0.0167\n",
      "Epoch 119/200, Iteration 96/250, Loss: 0.0189\n",
      "Epoch 119/200, Iteration 97/250, Loss: 0.0160\n",
      "Epoch 119/200, Iteration 98/250, Loss: 0.0152\n",
      "Epoch 119/200, Iteration 99/250, Loss: 0.0140\n",
      "Epoch 119/200, Iteration 100/250, Loss: 0.0246\n",
      "Epoch 119/200, Iteration 101/250, Loss: 0.0285\n",
      "Epoch 119/200, Iteration 102/250, Loss: 0.0192\n",
      "Epoch 119/200, Iteration 103/250, Loss: 0.0304\n",
      "Epoch 119/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 119/200, Iteration 106/250, Loss: 0.0081\n",
      "Epoch 119/200, Iteration 107/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 108/250, Loss: 0.0063\n",
      "Epoch 119/200, Iteration 109/250, Loss: 0.0112\n",
      "Epoch 119/200, Iteration 110/250, Loss: 0.0157\n",
      "Epoch 119/200, Iteration 111/250, Loss: 0.0143\n",
      "Epoch 119/200, Iteration 112/250, Loss: 0.0164\n",
      "Epoch 119/200, Iteration 113/250, Loss: 0.0112\n",
      "Epoch 119/200, Iteration 114/250, Loss: 0.0216\n",
      "Epoch 119/200, Iteration 115/250, Loss: 0.0107\n",
      "Epoch 119/200, Iteration 116/250, Loss: 0.0123\n",
      "Epoch 119/200, Iteration 117/250, Loss: 0.0111\n",
      "Epoch 119/200, Iteration 118/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 119/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 119/200, Iteration 122/250, Loss: 0.0166\n",
      "Epoch 119/200, Iteration 123/250, Loss: 0.0191\n",
      "Epoch 119/200, Iteration 124/250, Loss: 0.0284\n",
      "Epoch 119/200, Iteration 125/250, Loss: 0.0161\n",
      "Epoch 119/200, Iteration 126/250, Loss: 0.0109\n",
      "Epoch 119/200, Iteration 127/250, Loss: 0.0107\n",
      "Epoch 119/200, Iteration 128/250, Loss: 0.0119\n",
      "Epoch 119/200, Iteration 129/250, Loss: 0.0239\n",
      "Epoch 119/200, Iteration 130/250, Loss: 0.0185\n",
      "Epoch 119/200, Iteration 131/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 132/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 133/250, Loss: 0.0144\n",
      "Epoch 119/200, Iteration 134/250, Loss: 0.0122\n",
      "Epoch 119/200, Iteration 135/250, Loss: 0.0067\n",
      "Epoch 119/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 137/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 138/250, Loss: 0.0115\n",
      "Epoch 119/200, Iteration 139/250, Loss: 0.0141\n",
      "Epoch 119/200, Iteration 140/250, Loss: 0.0070\n",
      "Epoch 119/200, Iteration 141/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 142/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 143/250, Loss: 0.0218\n",
      "Epoch 119/200, Iteration 144/250, Loss: 0.0115\n",
      "Epoch 119/200, Iteration 145/250, Loss: 0.0157\n",
      "Epoch 119/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 119/200, Iteration 147/250, Loss: 0.0096\n",
      "Epoch 119/200, Iteration 148/250, Loss: 0.0095\n",
      "Epoch 119/200, Iteration 149/250, Loss: 0.0114\n",
      "Epoch 119/200, Iteration 150/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 151/250, Loss: 0.0085\n",
      "Epoch 119/200, Iteration 152/250, Loss: 0.0237\n",
      "Epoch 119/200, Iteration 153/250, Loss: 0.0097\n",
      "Epoch 119/200, Iteration 154/250, Loss: 0.0161\n",
      "Epoch 119/200, Iteration 155/250, Loss: 0.0275\n",
      "Epoch 119/200, Iteration 156/250, Loss: 0.0168\n",
      "Epoch 119/200, Iteration 157/250, Loss: 0.0058\n",
      "Epoch 119/200, Iteration 158/250, Loss: 0.0147\n",
      "Epoch 119/200, Iteration 159/250, Loss: 0.0122\n",
      "Epoch 119/200, Iteration 160/250, Loss: 0.0259\n",
      "Epoch 119/200, Iteration 161/250, Loss: 0.0176\n",
      "Epoch 119/200, Iteration 162/250, Loss: 0.0160\n",
      "Epoch 119/200, Iteration 163/250, Loss: 0.0133\n",
      "Epoch 119/200, Iteration 164/250, Loss: 0.0077\n",
      "Epoch 119/200, Iteration 165/250, Loss: 0.0083\n",
      "Epoch 119/200, Iteration 166/250, Loss: 0.0133\n",
      "Epoch 119/200, Iteration 167/250, Loss: 0.0117\n",
      "Epoch 119/200, Iteration 168/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 169/250, Loss: 0.0263\n",
      "Epoch 119/200, Iteration 170/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 171/250, Loss: 0.0168\n",
      "Epoch 119/200, Iteration 172/250, Loss: 0.0140\n",
      "Epoch 119/200, Iteration 173/250, Loss: 0.0271\n",
      "Epoch 119/200, Iteration 174/250, Loss: 0.0100\n",
      "Epoch 119/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 176/250, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 177/250, Loss: 0.0197\n",
      "Epoch 119/200, Iteration 178/250, Loss: 0.0078\n",
      "Epoch 119/200, Iteration 179/250, Loss: 0.0138\n",
      "Epoch 119/200, Iteration 180/250, Loss: 0.0486\n",
      "Epoch 119/200, Iteration 181/250, Loss: 0.0047\n",
      "Epoch 119/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 119/200, Iteration 183/250, Loss: 0.0287\n",
      "Epoch 119/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 119/200, Iteration 185/250, Loss: 0.0375\n",
      "Epoch 119/200, Iteration 186/250, Loss: 0.0167\n",
      "Epoch 119/200, Iteration 187/250, Loss: 0.0153\n",
      "Epoch 119/200, Iteration 188/250, Loss: 0.0141\n",
      "Epoch 119/200, Iteration 189/250, Loss: 0.0129\n",
      "Epoch 119/200, Iteration 190/250, Loss: 0.0275\n",
      "Epoch 119/200, Iteration 191/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 192/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 193/250, Loss: 0.0275\n",
      "Epoch 119/200, Iteration 194/250, Loss: 0.0286\n",
      "Epoch 119/200, Iteration 195/250, Loss: 0.0154\n",
      "Epoch 119/200, Iteration 196/250, Loss: 0.0141\n",
      "Epoch 119/200, Iteration 197/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 198/250, Loss: 0.0255\n",
      "Epoch 119/200, Iteration 199/250, Loss: 0.0143\n",
      "Epoch 119/200, Iteration 200/250, Loss: 0.0229\n",
      "Epoch 119/200, Iteration 201/250, Loss: 0.0059\n",
      "Epoch 119/200, Iteration 202/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 203/250, Loss: 0.0140\n",
      "Epoch 119/200, Iteration 204/250, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 205/250, Loss: 0.0137\n",
      "Epoch 119/200, Iteration 206/250, Loss: 0.0098\n",
      "Epoch 119/200, Iteration 207/250, Loss: 0.0105\n",
      "Epoch 119/200, Iteration 208/250, Loss: 0.0265\n",
      "Epoch 119/200, Iteration 209/250, Loss: 0.0152\n",
      "Epoch 119/200, Iteration 210/250, Loss: 0.0184\n",
      "Epoch 119/200, Iteration 211/250, Loss: 0.0116\n",
      "Epoch 119/200, Iteration 212/250, Loss: 0.0366\n",
      "Epoch 119/200, Iteration 213/250, Loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200, Iteration 214/250, Loss: 0.0136\n",
      "Epoch 119/200, Iteration 215/250, Loss: 0.0169\n",
      "Epoch 119/200, Iteration 216/250, Loss: 0.0186\n",
      "Epoch 119/200, Iteration 217/250, Loss: 0.0162\n",
      "Epoch 119/200, Iteration 218/250, Loss: 0.0281\n",
      "Epoch 119/200, Iteration 219/250, Loss: 0.0103\n",
      "Epoch 119/200, Iteration 220/250, Loss: 0.0121\n",
      "Epoch 119/200, Iteration 221/250, Loss: 0.0154\n",
      "Epoch 119/200, Iteration 222/250, Loss: 0.0228\n",
      "Epoch 119/200, Iteration 223/250, Loss: 0.0105\n",
      "Epoch 119/200, Iteration 224/250, Loss: 0.0095\n",
      "Epoch 119/200, Iteration 225/250, Loss: 0.0085\n",
      "Epoch 119/200, Iteration 226/250, Loss: 0.0158\n",
      "Epoch 119/200, Iteration 227/250, Loss: 0.0108\n",
      "Epoch 119/200, Iteration 228/250, Loss: 0.0087\n",
      "Epoch 119/200, Iteration 229/250, Loss: 0.0159\n",
      "Epoch 119/200, Iteration 230/250, Loss: 0.0259\n",
      "Epoch 119/200, Iteration 231/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 232/250, Loss: 0.0222\n",
      "Epoch 119/200, Iteration 233/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 234/250, Loss: 0.0110\n",
      "Epoch 119/200, Iteration 235/250, Loss: 0.0405\n",
      "Epoch 119/200, Iteration 236/250, Loss: 0.0062\n",
      "Epoch 119/200, Iteration 237/250, Loss: 0.0158\n",
      "Epoch 119/200, Iteration 238/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 239/250, Loss: 0.0105\n",
      "Epoch 119/200, Iteration 240/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 241/250, Loss: 0.0157\n",
      "Epoch 119/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 119/200, Iteration 243/250, Loss: 0.0240\n",
      "Epoch 119/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 119/200, Iteration 245/250, Loss: 0.0218\n",
      "Epoch 119/200, Iteration 246/250, Loss: 0.0057\n",
      "Epoch 119/200, Iteration 247/250, Loss: 0.0141\n",
      "Epoch 119/200, Iteration 248/250, Loss: 0.0108\n",
      "Epoch 119/200, Iteration 249/250, Loss: 0.0253\n",
      "Epoch 119/200, Iteration 250/250, Loss: 0.0159\n",
      "Train Error: \n",
      " Accuracy: 96.74%, Avg loss: 0.006203, MRE: 0.641620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.55%, Avg loss: 0.006207, MRE: 0.968719 \n",
      "\n",
      "Epoch 120/200, Iteration 1/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 2/250, Loss: 0.0160\n",
      "Epoch 120/200, Iteration 3/250, Loss: 0.0213\n",
      "Epoch 120/200, Iteration 4/250, Loss: 0.0366\n",
      "Epoch 120/200, Iteration 5/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 6/250, Loss: 0.0353\n",
      "Epoch 120/200, Iteration 7/250, Loss: 0.0186\n",
      "Epoch 120/200, Iteration 8/250, Loss: 0.0150\n",
      "Epoch 120/200, Iteration 9/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 10/250, Loss: 0.0072\n",
      "Epoch 120/200, Iteration 11/250, Loss: 0.0102\n",
      "Epoch 120/200, Iteration 12/250, Loss: 0.0156\n",
      "Epoch 120/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 120/200, Iteration 14/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 15/250, Loss: 0.0190\n",
      "Epoch 120/200, Iteration 16/250, Loss: 0.0089\n",
      "Epoch 120/200, Iteration 17/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 18/250, Loss: 0.0081\n",
      "Epoch 120/200, Iteration 19/250, Loss: 0.0090\n",
      "Epoch 120/200, Iteration 20/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 21/250, Loss: 0.0164\n",
      "Epoch 120/200, Iteration 22/250, Loss: 0.0074\n",
      "Epoch 120/200, Iteration 23/250, Loss: 0.0180\n",
      "Epoch 120/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 25/250, Loss: 0.0135\n",
      "Epoch 120/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 120/200, Iteration 27/250, Loss: 0.0155\n",
      "Epoch 120/200, Iteration 28/250, Loss: 0.0133\n",
      "Epoch 120/200, Iteration 29/250, Loss: 0.0061\n",
      "Epoch 120/200, Iteration 30/250, Loss: 0.0208\n",
      "Epoch 120/200, Iteration 31/250, Loss: 0.0086\n",
      "Epoch 120/200, Iteration 32/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 33/250, Loss: 0.0085\n",
      "Epoch 120/200, Iteration 34/250, Loss: 0.0129\n",
      "Epoch 120/200, Iteration 35/250, Loss: 0.0140\n",
      "Epoch 120/200, Iteration 36/250, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 37/250, Loss: 0.0177\n",
      "Epoch 120/200, Iteration 38/250, Loss: 0.0188\n",
      "Epoch 120/200, Iteration 39/250, Loss: 0.0171\n",
      "Epoch 120/200, Iteration 40/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 41/250, Loss: 0.0109\n",
      "Epoch 120/200, Iteration 42/250, Loss: 0.0211\n",
      "Epoch 120/200, Iteration 43/250, Loss: 0.0075\n",
      "Epoch 120/200, Iteration 44/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 45/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 46/250, Loss: 0.0152\n",
      "Epoch 120/200, Iteration 47/250, Loss: 0.0091\n",
      "Epoch 120/200, Iteration 48/250, Loss: 0.0091\n",
      "Epoch 120/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 50/250, Loss: 0.0231\n",
      "Epoch 120/200, Iteration 51/250, Loss: 0.0164\n",
      "Epoch 120/200, Iteration 52/250, Loss: 0.0081\n",
      "Epoch 120/200, Iteration 53/250, Loss: 0.0086\n",
      "Epoch 120/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 120/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 120/200, Iteration 56/250, Loss: 0.0215\n",
      "Epoch 120/200, Iteration 57/250, Loss: 0.0190\n",
      "Epoch 120/200, Iteration 58/250, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 59/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 60/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 61/250, Loss: 0.0255\n",
      "Epoch 120/200, Iteration 62/250, Loss: 0.0214\n",
      "Epoch 120/200, Iteration 63/250, Loss: 0.0292\n",
      "Epoch 120/200, Iteration 64/250, Loss: 0.0084\n",
      "Epoch 120/200, Iteration 65/250, Loss: 0.0152\n",
      "Epoch 120/200, Iteration 66/250, Loss: 0.0269\n",
      "Epoch 120/200, Iteration 67/250, Loss: 0.0080\n",
      "Epoch 120/200, Iteration 68/250, Loss: 0.0140\n",
      "Epoch 120/200, Iteration 69/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 70/250, Loss: 0.0272\n",
      "Epoch 120/200, Iteration 71/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 72/250, Loss: 0.0116\n",
      "Epoch 120/200, Iteration 73/250, Loss: 0.0180\n",
      "Epoch 120/200, Iteration 74/250, Loss: 0.0137\n",
      "Epoch 120/200, Iteration 75/250, Loss: 0.0068\n",
      "Epoch 120/200, Iteration 76/250, Loss: 0.0185\n",
      "Epoch 120/200, Iteration 77/250, Loss: 0.0256\n",
      "Epoch 120/200, Iteration 78/250, Loss: 0.0120\n",
      "Epoch 120/200, Iteration 79/250, Loss: 0.0078\n",
      "Epoch 120/200, Iteration 80/250, Loss: 0.0125\n",
      "Epoch 120/200, Iteration 81/250, Loss: 0.0158\n",
      "Epoch 120/200, Iteration 82/250, Loss: 0.0271\n",
      "Epoch 120/200, Iteration 83/250, Loss: 0.0185\n",
      "Epoch 120/200, Iteration 84/250, Loss: 0.0099\n",
      "Epoch 120/200, Iteration 85/250, Loss: 0.0116\n",
      "Epoch 120/200, Iteration 86/250, Loss: 0.0122\n",
      "Epoch 120/200, Iteration 87/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 120/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 120/200, Iteration 90/250, Loss: 0.0116\n",
      "Epoch 120/200, Iteration 91/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 92/250, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 93/250, Loss: 0.0276\n",
      "Epoch 120/200, Iteration 94/250, Loss: 0.0121\n",
      "Epoch 120/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 96/250, Loss: 0.0072\n",
      "Epoch 120/200, Iteration 97/250, Loss: 0.0334\n",
      "Epoch 120/200, Iteration 98/250, Loss: 0.0243\n",
      "Epoch 120/200, Iteration 99/250, Loss: 0.0156\n",
      "Epoch 120/200, Iteration 100/250, Loss: 0.0176\n",
      "Epoch 120/200, Iteration 101/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 102/250, Loss: 0.0155\n",
      "Epoch 120/200, Iteration 103/250, Loss: 0.0121\n",
      "Epoch 120/200, Iteration 104/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 105/250, Loss: 0.0094\n",
      "Epoch 120/200, Iteration 106/250, Loss: 0.0223\n",
      "Epoch 120/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 120/200, Iteration 108/250, Loss: 0.0121\n",
      "Epoch 120/200, Iteration 109/250, Loss: 0.0145\n",
      "Epoch 120/200, Iteration 110/250, Loss: 0.0075\n",
      "Epoch 120/200, Iteration 111/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 112/250, Loss: 0.0144\n",
      "Epoch 120/200, Iteration 113/250, Loss: 0.0174\n",
      "Epoch 120/200, Iteration 114/250, Loss: 0.0111\n",
      "Epoch 120/200, Iteration 115/250, Loss: 0.0237\n",
      "Epoch 120/200, Iteration 116/250, Loss: 0.0227\n",
      "Epoch 120/200, Iteration 117/250, Loss: 0.0146\n",
      "Epoch 120/200, Iteration 118/250, Loss: 0.0110\n",
      "Epoch 120/200, Iteration 119/250, Loss: 0.0122\n",
      "Epoch 120/200, Iteration 120/250, Loss: 0.0082\n",
      "Epoch 120/200, Iteration 121/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 122/250, Loss: 0.0092\n",
      "Epoch 120/200, Iteration 123/250, Loss: 0.0153\n",
      "Epoch 120/200, Iteration 124/250, Loss: 0.0187\n",
      "Epoch 120/200, Iteration 125/250, Loss: 0.0052\n",
      "Epoch 120/200, Iteration 126/250, Loss: 0.0053\n",
      "Epoch 120/200, Iteration 127/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 128/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 129/250, Loss: 0.0256\n",
      "Epoch 120/200, Iteration 130/250, Loss: 0.0159\n",
      "Epoch 120/200, Iteration 131/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 132/250, Loss: 0.0052\n",
      "Epoch 120/200, Iteration 133/250, Loss: 0.0136\n",
      "Epoch 120/200, Iteration 134/250, Loss: 0.0080\n",
      "Epoch 120/200, Iteration 135/250, Loss: 0.0092\n",
      "Epoch 120/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 137/250, Loss: 0.0278\n",
      "Epoch 120/200, Iteration 138/250, Loss: 0.0063\n",
      "Epoch 120/200, Iteration 139/250, Loss: 0.0116\n",
      "Epoch 120/200, Iteration 140/250, Loss: 0.0147\n",
      "Epoch 120/200, Iteration 141/250, Loss: 0.0064\n",
      "Epoch 120/200, Iteration 142/250, Loss: 0.0089\n",
      "Epoch 120/200, Iteration 143/250, Loss: 0.0065\n",
      "Epoch 120/200, Iteration 144/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 145/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 146/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 147/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 148/250, Loss: 0.0097\n",
      "Epoch 120/200, Iteration 149/250, Loss: 0.0359\n",
      "Epoch 120/200, Iteration 150/250, Loss: 0.0077\n",
      "Epoch 120/200, Iteration 151/250, Loss: 0.0084\n",
      "Epoch 120/200, Iteration 152/250, Loss: 0.0214\n",
      "Epoch 120/200, Iteration 153/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 154/250, Loss: 0.0194\n",
      "Epoch 120/200, Iteration 155/250, Loss: 0.0074\n",
      "Epoch 120/200, Iteration 156/250, Loss: 0.0262\n",
      "Epoch 120/200, Iteration 157/250, Loss: 0.0106\n",
      "Epoch 120/200, Iteration 158/250, Loss: 0.0119\n",
      "Epoch 120/200, Iteration 159/250, Loss: 0.0221\n",
      "Epoch 120/200, Iteration 160/250, Loss: 0.0093\n",
      "Epoch 120/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 120/200, Iteration 162/250, Loss: 0.0179\n",
      "Epoch 120/200, Iteration 163/250, Loss: 0.0168\n",
      "Epoch 120/200, Iteration 164/250, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Iteration 165/250, Loss: 0.0138\n",
      "Epoch 120/200, Iteration 166/250, Loss: 0.0180\n",
      "Epoch 120/200, Iteration 167/250, Loss: 0.0096\n",
      "Epoch 120/200, Iteration 168/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 169/250, Loss: 0.0085\n",
      "Epoch 120/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 171/250, Loss: 0.0126\n",
      "Epoch 120/200, Iteration 172/250, Loss: 0.0138\n",
      "Epoch 120/200, Iteration 173/250, Loss: 0.0171\n",
      "Epoch 120/200, Iteration 174/250, Loss: 0.0158\n",
      "Epoch 120/200, Iteration 175/250, Loss: 0.0182\n",
      "Epoch 120/200, Iteration 176/250, Loss: 0.0295\n",
      "Epoch 120/200, Iteration 177/250, Loss: 0.0256\n",
      "Epoch 120/200, Iteration 178/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 179/250, Loss: 0.0137\n",
      "Epoch 120/200, Iteration 180/250, Loss: 0.0141\n",
      "Epoch 120/200, Iteration 181/250, Loss: 0.0120\n",
      "Epoch 120/200, Iteration 182/250, Loss: 0.0099\n",
      "Epoch 120/200, Iteration 183/250, Loss: 0.0119\n",
      "Epoch 120/200, Iteration 184/250, Loss: 0.0131\n",
      "Epoch 120/200, Iteration 185/250, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 186/250, Loss: 0.0163\n",
      "Epoch 120/200, Iteration 187/250, Loss: 0.0259\n",
      "Epoch 120/200, Iteration 188/250, Loss: 0.0236\n",
      "Epoch 120/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 120/200, Iteration 190/250, Loss: 0.0076\n",
      "Epoch 120/200, Iteration 191/250, Loss: 0.0130\n",
      "Epoch 120/200, Iteration 192/250, Loss: 0.0094\n",
      "Epoch 120/200, Iteration 193/250, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 194/250, Loss: 0.0134\n",
      "Epoch 120/200, Iteration 195/250, Loss: 0.0266\n",
      "Epoch 120/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 120/200, Iteration 197/250, Loss: 0.0079\n",
      "Epoch 120/200, Iteration 198/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 199/250, Loss: 0.0075\n",
      "Epoch 120/200, Iteration 200/250, Loss: 0.0233\n",
      "Epoch 120/200, Iteration 201/250, Loss: 0.0096\n",
      "Epoch 120/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 120/200, Iteration 203/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 204/250, Loss: 0.0169\n",
      "Epoch 120/200, Iteration 205/250, Loss: 0.0096\n",
      "Epoch 120/200, Iteration 206/250, Loss: 0.0161\n",
      "Epoch 120/200, Iteration 207/250, Loss: 0.0215\n",
      "Epoch 120/200, Iteration 208/250, Loss: 0.0228\n",
      "Epoch 120/200, Iteration 209/250, Loss: 0.0073\n",
      "Epoch 120/200, Iteration 210/250, Loss: 0.0241\n",
      "Epoch 120/200, Iteration 211/250, Loss: 0.0096\n",
      "Epoch 120/200, Iteration 212/250, Loss: 0.0115\n",
      "Epoch 120/200, Iteration 213/250, Loss: 0.0255\n",
      "Epoch 120/200, Iteration 214/250, Loss: 0.0197\n",
      "Epoch 120/200, Iteration 215/250, Loss: 0.0148\n",
      "Epoch 120/200, Iteration 216/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 217/250, Loss: 0.0063\n",
      "Epoch 120/200, Iteration 218/250, Loss: 0.0097\n",
      "Epoch 120/200, Iteration 219/250, Loss: 0.0070\n",
      "Epoch 120/200, Iteration 220/250, Loss: 0.0157\n",
      "Epoch 120/200, Iteration 221/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 222/250, Loss: 0.0353\n",
      "Epoch 120/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 224/250, Loss: 0.0197\n",
      "Epoch 120/200, Iteration 225/250, Loss: 0.0125\n",
      "Epoch 120/200, Iteration 226/250, Loss: 0.0134\n",
      "Epoch 120/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 120/200, Iteration 228/250, Loss: 0.0337\n",
      "Epoch 120/200, Iteration 229/250, Loss: 0.0211\n",
      "Epoch 120/200, Iteration 230/250, Loss: 0.0137\n",
      "Epoch 120/200, Iteration 231/250, Loss: 0.0145\n",
      "Epoch 120/200, Iteration 232/250, Loss: 0.0077\n",
      "Epoch 120/200, Iteration 233/250, Loss: 0.0137\n",
      "Epoch 120/200, Iteration 234/250, Loss: 0.0123\n",
      "Epoch 120/200, Iteration 235/250, Loss: 0.0170\n",
      "Epoch 120/200, Iteration 236/250, Loss: 0.0236\n",
      "Epoch 120/200, Iteration 237/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 120/200, Iteration 239/250, Loss: 0.0165\n",
      "Epoch 120/200, Iteration 240/250, Loss: 0.0203\n",
      "Epoch 120/200, Iteration 241/250, Loss: 0.0254\n",
      "Epoch 120/200, Iteration 242/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 243/250, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 244/250, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 245/250, Loss: 0.0133\n",
      "Epoch 120/200, Iteration 246/250, Loss: 0.0083\n",
      "Epoch 120/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 248/250, Loss: 0.0121\n",
      "Epoch 120/200, Iteration 249/250, Loss: 0.0109\n",
      "Epoch 120/200, Iteration 250/250, Loss: 0.0152\n",
      "Train Error: \n",
      " Accuracy: 75.15%, Avg loss: 0.007904, MRE: 0.653839 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.35%, Avg loss: 0.007909, MRE: 0.794769 \n",
      "\n",
      "Epoch 121/200, Iteration 1/250, Loss: 0.0113\n",
      "Epoch 121/200, Iteration 2/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 3/250, Loss: 0.0055\n",
      "Epoch 121/200, Iteration 4/250, Loss: 0.0058\n",
      "Epoch 121/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 7/250, Loss: 0.0086\n",
      "Epoch 121/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 121/200, Iteration 9/250, Loss: 0.0190\n",
      "Epoch 121/200, Iteration 10/250, Loss: 0.0125\n",
      "Epoch 121/200, Iteration 11/250, Loss: 0.0078\n",
      "Epoch 121/200, Iteration 12/250, Loss: 0.0121\n",
      "Epoch 121/200, Iteration 13/250, Loss: 0.0140\n",
      "Epoch 121/200, Iteration 14/250, Loss: 0.0111\n",
      "Epoch 121/200, Iteration 15/250, Loss: 0.0069\n",
      "Epoch 121/200, Iteration 16/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 17/250, Loss: 0.0130\n",
      "Epoch 121/200, Iteration 18/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 121/200, Iteration 20/250, Loss: 0.0223\n",
      "Epoch 121/200, Iteration 21/250, Loss: 0.0138\n",
      "Epoch 121/200, Iteration 22/250, Loss: 0.0075\n",
      "Epoch 121/200, Iteration 23/250, Loss: 0.0116\n",
      "Epoch 121/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 121/200, Iteration 25/250, Loss: 0.0182\n",
      "Epoch 121/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 121/200, Iteration 27/250, Loss: 0.0256\n",
      "Epoch 121/200, Iteration 28/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 30/250, Loss: 0.0333\n",
      "Epoch 121/200, Iteration 31/250, Loss: 0.0093\n",
      "Epoch 121/200, Iteration 32/250, Loss: 0.0144\n",
      "Epoch 121/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 121/200, Iteration 34/250, Loss: 0.0164\n",
      "Epoch 121/200, Iteration 35/250, Loss: 0.0131\n",
      "Epoch 121/200, Iteration 36/250, Loss: 0.0126\n",
      "Epoch 121/200, Iteration 37/250, Loss: 0.0190\n",
      "Epoch 121/200, Iteration 38/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 39/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 40/250, Loss: 0.0169\n",
      "Epoch 121/200, Iteration 41/250, Loss: 0.0155\n",
      "Epoch 121/200, Iteration 42/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 43/250, Loss: 0.0136\n",
      "Epoch 121/200, Iteration 44/250, Loss: 0.0122\n",
      "Epoch 121/200, Iteration 45/250, Loss: 0.0118\n",
      "Epoch 121/200, Iteration 46/250, Loss: 0.0121\n",
      "Epoch 121/200, Iteration 47/250, Loss: 0.0129\n",
      "Epoch 121/200, Iteration 48/250, Loss: 0.0084\n",
      "Epoch 121/200, Iteration 49/250, Loss: 0.0267\n",
      "Epoch 121/200, Iteration 50/250, Loss: 0.0192\n",
      "Epoch 121/200, Iteration 51/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 52/250, Loss: 0.0192\n",
      "Epoch 121/200, Iteration 53/250, Loss: 0.0163\n",
      "Epoch 121/200, Iteration 54/250, Loss: 0.0071\n",
      "Epoch 121/200, Iteration 55/250, Loss: 0.0147\n",
      "Epoch 121/200, Iteration 56/250, Loss: 0.0184\n",
      "Epoch 121/200, Iteration 57/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 58/250, Loss: 0.0077\n",
      "Epoch 121/200, Iteration 59/250, Loss: 0.0128\n",
      "Epoch 121/200, Iteration 60/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 61/250, Loss: 0.0108\n",
      "Epoch 121/200, Iteration 62/250, Loss: 0.0120\n",
      "Epoch 121/200, Iteration 63/250, Loss: 0.0099\n",
      "Epoch 121/200, Iteration 64/250, Loss: 0.0074\n",
      "Epoch 121/200, Iteration 65/250, Loss: 0.0084\n",
      "Epoch 121/200, Iteration 66/250, Loss: 0.0151\n",
      "Epoch 121/200, Iteration 67/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 68/250, Loss: 0.0083\n",
      "Epoch 121/200, Iteration 69/250, Loss: 0.0219\n",
      "Epoch 121/200, Iteration 70/250, Loss: 0.0118\n",
      "Epoch 121/200, Iteration 71/250, Loss: 0.0242\n",
      "Epoch 121/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 121/200, Iteration 73/250, Loss: 0.0225\n",
      "Epoch 121/200, Iteration 74/250, Loss: 0.0103\n",
      "Epoch 121/200, Iteration 75/250, Loss: 0.0168\n",
      "Epoch 121/200, Iteration 76/250, Loss: 0.0108\n",
      "Epoch 121/200, Iteration 77/250, Loss: 0.0145\n",
      "Epoch 121/200, Iteration 78/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 79/250, Loss: 0.0077\n",
      "Epoch 121/200, Iteration 80/250, Loss: 0.0117\n",
      "Epoch 121/200, Iteration 81/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 83/250, Loss: 0.0082\n",
      "Epoch 121/200, Iteration 84/250, Loss: 0.0055\n",
      "Epoch 121/200, Iteration 85/250, Loss: 0.0163\n",
      "Epoch 121/200, Iteration 86/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 87/250, Loss: 0.0227\n",
      "Epoch 121/200, Iteration 88/250, Loss: 0.0157\n",
      "Epoch 121/200, Iteration 89/250, Loss: 0.0056\n",
      "Epoch 121/200, Iteration 90/250, Loss: 0.0073\n",
      "Epoch 121/200, Iteration 91/250, Loss: 0.0091\n",
      "Epoch 121/200, Iteration 92/250, Loss: 0.0136\n",
      "Epoch 121/200, Iteration 93/250, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 94/250, Loss: 0.0093\n",
      "Epoch 121/200, Iteration 95/250, Loss: 0.0196\n",
      "Epoch 121/200, Iteration 96/250, Loss: 0.0264\n",
      "Epoch 121/200, Iteration 97/250, Loss: 0.0233\n",
      "Epoch 121/200, Iteration 98/250, Loss: 0.0201\n",
      "Epoch 121/200, Iteration 99/250, Loss: 0.0187\n",
      "Epoch 121/200, Iteration 100/250, Loss: 0.0278\n",
      "Epoch 121/200, Iteration 101/250, Loss: 0.0233\n",
      "Epoch 121/200, Iteration 102/250, Loss: 0.0194\n",
      "Epoch 121/200, Iteration 103/250, Loss: 0.0194\n",
      "Epoch 121/200, Iteration 104/250, Loss: 0.0192\n",
      "Epoch 121/200, Iteration 105/250, Loss: 0.0196\n",
      "Epoch 121/200, Iteration 106/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 107/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 108/250, Loss: 0.0129\n",
      "Epoch 121/200, Iteration 109/250, Loss: 0.0294\n",
      "Epoch 121/200, Iteration 110/250, Loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200, Iteration 111/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 112/250, Loss: 0.0352\n",
      "Epoch 121/200, Iteration 113/250, Loss: 0.0131\n",
      "Epoch 121/200, Iteration 114/250, Loss: 0.0058\n",
      "Epoch 121/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 121/200, Iteration 116/250, Loss: 0.0179\n",
      "Epoch 121/200, Iteration 117/250, Loss: 0.0148\n",
      "Epoch 121/200, Iteration 118/250, Loss: 0.0112\n",
      "Epoch 121/200, Iteration 119/250, Loss: 0.0303\n",
      "Epoch 121/200, Iteration 120/250, Loss: 0.0094\n",
      "Epoch 121/200, Iteration 121/250, Loss: 0.0074\n",
      "Epoch 121/200, Iteration 122/250, Loss: 0.0174\n",
      "Epoch 121/200, Iteration 123/250, Loss: 0.0246\n",
      "Epoch 121/200, Iteration 124/250, Loss: 0.0123\n",
      "Epoch 121/200, Iteration 125/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 126/250, Loss: 0.0252\n",
      "Epoch 121/200, Iteration 127/250, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 128/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 129/250, Loss: 0.0170\n",
      "Epoch 121/200, Iteration 130/250, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 131/250, Loss: 0.0082\n",
      "Epoch 121/200, Iteration 132/250, Loss: 0.0096\n",
      "Epoch 121/200, Iteration 133/250, Loss: 0.0171\n",
      "Epoch 121/200, Iteration 134/250, Loss: 0.0139\n",
      "Epoch 121/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 121/200, Iteration 136/250, Loss: 0.0134\n",
      "Epoch 121/200, Iteration 137/250, Loss: 0.0168\n",
      "Epoch 121/200, Iteration 138/250, Loss: 0.0158\n",
      "Epoch 121/200, Iteration 139/250, Loss: 0.0108\n",
      "Epoch 121/200, Iteration 140/250, Loss: 0.0077\n",
      "Epoch 121/200, Iteration 141/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 142/250, Loss: 0.0113\n",
      "Epoch 121/200, Iteration 143/250, Loss: 0.0125\n",
      "Epoch 121/200, Iteration 144/250, Loss: 0.0125\n",
      "Epoch 121/200, Iteration 145/250, Loss: 0.0081\n",
      "Epoch 121/200, Iteration 146/250, Loss: 0.0136\n",
      "Epoch 121/200, Iteration 147/250, Loss: 0.0146\n",
      "Epoch 121/200, Iteration 148/250, Loss: 0.0136\n",
      "Epoch 121/200, Iteration 149/250, Loss: 0.0178\n",
      "Epoch 121/200, Iteration 150/250, Loss: 0.0246\n",
      "Epoch 121/200, Iteration 151/250, Loss: 0.0119\n",
      "Epoch 121/200, Iteration 152/250, Loss: 0.0092\n",
      "Epoch 121/200, Iteration 153/250, Loss: 0.0119\n",
      "Epoch 121/200, Iteration 154/250, Loss: 0.0342\n",
      "Epoch 121/200, Iteration 155/250, Loss: 0.0085\n",
      "Epoch 121/200, Iteration 156/250, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 157/250, Loss: 0.0119\n",
      "Epoch 121/200, Iteration 158/250, Loss: 0.0069\n",
      "Epoch 121/200, Iteration 159/250, Loss: 0.0191\n",
      "Epoch 121/200, Iteration 160/250, Loss: 0.0260\n",
      "Epoch 121/200, Iteration 161/250, Loss: 0.0105\n",
      "Epoch 121/200, Iteration 162/250, Loss: 0.0213\n",
      "Epoch 121/200, Iteration 163/250, Loss: 0.0154\n",
      "Epoch 121/200, Iteration 164/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 165/250, Loss: 0.0160\n",
      "Epoch 121/200, Iteration 166/250, Loss: 0.0091\n",
      "Epoch 121/200, Iteration 167/250, Loss: 0.0147\n",
      "Epoch 121/200, Iteration 168/250, Loss: 0.0169\n",
      "Epoch 121/200, Iteration 169/250, Loss: 0.0074\n",
      "Epoch 121/200, Iteration 170/250, Loss: 0.0074\n",
      "Epoch 121/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 172/250, Loss: 0.0148\n",
      "Epoch 121/200, Iteration 173/250, Loss: 0.0159\n",
      "Epoch 121/200, Iteration 174/250, Loss: 0.0094\n",
      "Epoch 121/200, Iteration 175/250, Loss: 0.0160\n",
      "Epoch 121/200, Iteration 176/250, Loss: 0.0190\n",
      "Epoch 121/200, Iteration 177/250, Loss: 0.0095\n",
      "Epoch 121/200, Iteration 178/250, Loss: 0.0250\n",
      "Epoch 121/200, Iteration 179/250, Loss: 0.0291\n",
      "Epoch 121/200, Iteration 180/250, Loss: 0.0146\n",
      "Epoch 121/200, Iteration 181/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 182/250, Loss: 0.0127\n",
      "Epoch 121/200, Iteration 183/250, Loss: 0.0249\n",
      "Epoch 121/200, Iteration 184/250, Loss: 0.0064\n",
      "Epoch 121/200, Iteration 185/250, Loss: 0.0270\n",
      "Epoch 121/200, Iteration 186/250, Loss: 0.0207\n",
      "Epoch 121/200, Iteration 187/250, Loss: 0.0245\n",
      "Epoch 121/200, Iteration 188/250, Loss: 0.0115\n",
      "Epoch 121/200, Iteration 189/250, Loss: 0.0069\n",
      "Epoch 121/200, Iteration 190/250, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 191/250, Loss: 0.0241\n",
      "Epoch 121/200, Iteration 192/250, Loss: 0.0162\n",
      "Epoch 121/200, Iteration 193/250, Loss: 0.0160\n",
      "Epoch 121/200, Iteration 194/250, Loss: 0.0267\n",
      "Epoch 121/200, Iteration 195/250, Loss: 0.0216\n",
      "Epoch 121/200, Iteration 196/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 197/250, Loss: 0.0153\n",
      "Epoch 121/200, Iteration 198/250, Loss: 0.0233\n",
      "Epoch 121/200, Iteration 199/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 200/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 201/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 202/250, Loss: 0.0118\n",
      "Epoch 121/200, Iteration 203/250, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 204/250, Loss: 0.0105\n",
      "Epoch 121/200, Iteration 205/250, Loss: 0.0246\n",
      "Epoch 121/200, Iteration 206/250, Loss: 0.0156\n",
      "Epoch 121/200, Iteration 207/250, Loss: 0.0073\n",
      "Epoch 121/200, Iteration 208/250, Loss: 0.0230\n",
      "Epoch 121/200, Iteration 209/250, Loss: 0.0202\n",
      "Epoch 121/200, Iteration 210/250, Loss: 0.0272\n",
      "Epoch 121/200, Iteration 211/250, Loss: 0.0316\n",
      "Epoch 121/200, Iteration 212/250, Loss: 0.0178\n",
      "Epoch 121/200, Iteration 213/250, Loss: 0.0146\n",
      "Epoch 121/200, Iteration 214/250, Loss: 0.0180\n",
      "Epoch 121/200, Iteration 215/250, Loss: 0.0189\n",
      "Epoch 121/200, Iteration 216/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 217/250, Loss: 0.0175\n",
      "Epoch 121/200, Iteration 218/250, Loss: 0.0067\n",
      "Epoch 121/200, Iteration 219/250, Loss: 0.0151\n",
      "Epoch 121/200, Iteration 220/250, Loss: 0.0064\n",
      "Epoch 121/200, Iteration 221/250, Loss: 0.0087\n",
      "Epoch 121/200, Iteration 222/250, Loss: 0.0214\n",
      "Epoch 121/200, Iteration 223/250, Loss: 0.0084\n",
      "Epoch 121/200, Iteration 224/250, Loss: 0.0228\n",
      "Epoch 121/200, Iteration 225/250, Loss: 0.0132\n",
      "Epoch 121/200, Iteration 226/250, Loss: 0.0067\n",
      "Epoch 121/200, Iteration 227/250, Loss: 0.0148\n",
      "Epoch 121/200, Iteration 228/250, Loss: 0.0136\n",
      "Epoch 121/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 121/200, Iteration 230/250, Loss: 0.0111\n",
      "Epoch 121/200, Iteration 231/250, Loss: 0.0165\n",
      "Epoch 121/200, Iteration 232/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 233/250, Loss: 0.0096\n",
      "Epoch 121/200, Iteration 234/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 236/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 237/250, Loss: 0.0179\n",
      "Epoch 121/200, Iteration 238/250, Loss: 0.0069\n",
      "Epoch 121/200, Iteration 239/250, Loss: 0.0134\n",
      "Epoch 121/200, Iteration 240/250, Loss: 0.0123\n",
      "Epoch 121/200, Iteration 241/250, Loss: 0.0178\n",
      "Epoch 121/200, Iteration 242/250, Loss: 0.0128\n",
      "Epoch 121/200, Iteration 243/250, Loss: 0.0238\n",
      "Epoch 121/200, Iteration 244/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 245/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 246/250, Loss: 0.0094\n",
      "Epoch 121/200, Iteration 247/250, Loss: 0.0127\n",
      "Epoch 121/200, Iteration 248/250, Loss: 0.0127\n",
      "Epoch 121/200, Iteration 249/250, Loss: 0.0152\n",
      "Epoch 121/200, Iteration 250/250, Loss: 0.0260\n",
      "Train Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.006636, MRE: 0.687512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.85%, Avg loss: 0.006543, MRE: 1.086758 \n",
      "\n",
      "Epoch 122/200, Iteration 1/250, Loss: 0.0108\n",
      "Epoch 122/200, Iteration 2/250, Loss: 0.0223\n",
      "Epoch 122/200, Iteration 3/250, Loss: 0.0231\n",
      "Epoch 122/200, Iteration 4/250, Loss: 0.0103\n",
      "Epoch 122/200, Iteration 5/250, Loss: 0.0296\n",
      "Epoch 122/200, Iteration 6/250, Loss: 0.0135\n",
      "Epoch 122/200, Iteration 7/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 8/250, Loss: 0.0272\n",
      "Epoch 122/200, Iteration 9/250, Loss: 0.0136\n",
      "Epoch 122/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 11/250, Loss: 0.0154\n",
      "Epoch 122/200, Iteration 12/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 13/250, Loss: 0.0191\n",
      "Epoch 122/200, Iteration 14/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 15/250, Loss: 0.0248\n",
      "Epoch 122/200, Iteration 16/250, Loss: 0.0101\n",
      "Epoch 122/200, Iteration 17/250, Loss: 0.0105\n",
      "Epoch 122/200, Iteration 18/250, Loss: 0.0149\n",
      "Epoch 122/200, Iteration 19/250, Loss: 0.0175\n",
      "Epoch 122/200, Iteration 20/250, Loss: 0.0115\n",
      "Epoch 122/200, Iteration 21/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 22/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 23/250, Loss: 0.0100\n",
      "Epoch 122/200, Iteration 24/250, Loss: 0.0169\n",
      "Epoch 122/200, Iteration 25/250, Loss: 0.0213\n",
      "Epoch 122/200, Iteration 26/250, Loss: 0.0355\n",
      "Epoch 122/200, Iteration 27/250, Loss: 0.0169\n",
      "Epoch 122/200, Iteration 28/250, Loss: 0.0206\n",
      "Epoch 122/200, Iteration 29/250, Loss: 0.0099\n",
      "Epoch 122/200, Iteration 30/250, Loss: 0.0105\n",
      "Epoch 122/200, Iteration 31/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 122/200, Iteration 33/250, Loss: 0.0099\n",
      "Epoch 122/200, Iteration 34/250, Loss: 0.0377\n",
      "Epoch 122/200, Iteration 35/250, Loss: 0.0227\n",
      "Epoch 122/200, Iteration 36/250, Loss: 0.0101\n",
      "Epoch 122/200, Iteration 37/250, Loss: 0.0104\n",
      "Epoch 122/200, Iteration 38/250, Loss: 0.0210\n",
      "Epoch 122/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 40/250, Loss: 0.0244\n",
      "Epoch 122/200, Iteration 41/250, Loss: 0.0129\n",
      "Epoch 122/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 122/200, Iteration 43/250, Loss: 0.0114\n",
      "Epoch 122/200, Iteration 44/250, Loss: 0.0141\n",
      "Epoch 122/200, Iteration 45/250, Loss: 0.0295\n",
      "Epoch 122/200, Iteration 46/250, Loss: 0.0198\n",
      "Epoch 122/200, Iteration 47/250, Loss: 0.0099\n",
      "Epoch 122/200, Iteration 48/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 49/250, Loss: 0.0069\n",
      "Epoch 122/200, Iteration 50/250, Loss: 0.0197\n",
      "Epoch 122/200, Iteration 51/250, Loss: 0.0215\n",
      "Epoch 122/200, Iteration 52/250, Loss: 0.0112\n",
      "Epoch 122/200, Iteration 53/250, Loss: 0.0090\n",
      "Epoch 122/200, Iteration 54/250, Loss: 0.0082\n",
      "Epoch 122/200, Iteration 55/250, Loss: 0.0080\n",
      "Epoch 122/200, Iteration 56/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 57/250, Loss: 0.0148\n",
      "Epoch 122/200, Iteration 58/250, Loss: 0.0074\n",
      "Epoch 122/200, Iteration 59/250, Loss: 0.0131\n",
      "Epoch 122/200, Iteration 60/250, Loss: 0.0062\n",
      "Epoch 122/200, Iteration 61/250, Loss: 0.0152\n",
      "Epoch 122/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 122/200, Iteration 63/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 122/200, Iteration 65/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200, Iteration 66/250, Loss: 0.0104\n",
      "Epoch 122/200, Iteration 67/250, Loss: 0.0178\n",
      "Epoch 122/200, Iteration 68/250, Loss: 0.0104\n",
      "Epoch 122/200, Iteration 69/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 70/250, Loss: 0.0408\n",
      "Epoch 122/200, Iteration 71/250, Loss: 0.0071\n",
      "Epoch 122/200, Iteration 72/250, Loss: 0.0113\n",
      "Epoch 122/200, Iteration 73/250, Loss: 0.0149\n",
      "Epoch 122/200, Iteration 74/250, Loss: 0.0197\n",
      "Epoch 122/200, Iteration 75/250, Loss: 0.0278\n",
      "Epoch 122/200, Iteration 76/250, Loss: 0.0236\n",
      "Epoch 122/200, Iteration 77/250, Loss: 0.0254\n",
      "Epoch 122/200, Iteration 78/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 79/250, Loss: 0.0189\n",
      "Epoch 122/200, Iteration 80/250, Loss: 0.0082\n",
      "Epoch 122/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 122/200, Iteration 82/250, Loss: 0.0130\n",
      "Epoch 122/200, Iteration 83/250, Loss: 0.0160\n",
      "Epoch 122/200, Iteration 84/250, Loss: 0.0199\n",
      "Epoch 122/200, Iteration 85/250, Loss: 0.0130\n",
      "Epoch 122/200, Iteration 86/250, Loss: 0.0226\n",
      "Epoch 122/200, Iteration 87/250, Loss: 0.0206\n",
      "Epoch 122/200, Iteration 88/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 89/250, Loss: 0.0133\n",
      "Epoch 122/200, Iteration 90/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 91/250, Loss: 0.0126\n",
      "Epoch 122/200, Iteration 92/250, Loss: 0.0085\n",
      "Epoch 122/200, Iteration 93/250, Loss: 0.0140\n",
      "Epoch 122/200, Iteration 94/250, Loss: 0.0265\n",
      "Epoch 122/200, Iteration 95/250, Loss: 0.0197\n",
      "Epoch 122/200, Iteration 96/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 97/250, Loss: 0.0092\n",
      "Epoch 122/200, Iteration 98/250, Loss: 0.0072\n",
      "Epoch 122/200, Iteration 99/250, Loss: 0.0147\n",
      "Epoch 122/200, Iteration 100/250, Loss: 0.0116\n",
      "Epoch 122/200, Iteration 101/250, Loss: 0.0218\n",
      "Epoch 122/200, Iteration 102/250, Loss: 0.0310\n",
      "Epoch 122/200, Iteration 103/250, Loss: 0.0090\n",
      "Epoch 122/200, Iteration 104/250, Loss: 0.0208\n",
      "Epoch 122/200, Iteration 105/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 106/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 107/250, Loss: 0.0121\n",
      "Epoch 122/200, Iteration 108/250, Loss: 0.0216\n",
      "Epoch 122/200, Iteration 109/250, Loss: 0.0179\n",
      "Epoch 122/200, Iteration 110/250, Loss: 0.0099\n",
      "Epoch 122/200, Iteration 111/250, Loss: 0.0115\n",
      "Epoch 122/200, Iteration 112/250, Loss: 0.0185\n",
      "Epoch 122/200, Iteration 113/250, Loss: 0.0319\n",
      "Epoch 122/200, Iteration 114/250, Loss: 0.0179\n",
      "Epoch 122/200, Iteration 115/250, Loss: 0.0063\n",
      "Epoch 122/200, Iteration 116/250, Loss: 0.0072\n",
      "Epoch 122/200, Iteration 117/250, Loss: 0.0233\n",
      "Epoch 122/200, Iteration 118/250, Loss: 0.0142\n",
      "Epoch 122/200, Iteration 119/250, Loss: 0.0257\n",
      "Epoch 122/200, Iteration 120/250, Loss: 0.0157\n",
      "Epoch 122/200, Iteration 121/250, Loss: 0.0116\n",
      "Epoch 122/200, Iteration 122/250, Loss: 0.0233\n",
      "Epoch 122/200, Iteration 123/250, Loss: 0.0073\n",
      "Epoch 122/200, Iteration 124/250, Loss: 0.0279\n",
      "Epoch 122/200, Iteration 125/250, Loss: 0.0145\n",
      "Epoch 122/200, Iteration 126/250, Loss: 0.0075\n",
      "Epoch 122/200, Iteration 127/250, Loss: 0.0098\n",
      "Epoch 122/200, Iteration 128/250, Loss: 0.0136\n",
      "Epoch 122/200, Iteration 129/250, Loss: 0.0087\n",
      "Epoch 122/200, Iteration 130/250, Loss: 0.0077\n",
      "Epoch 122/200, Iteration 131/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 132/250, Loss: 0.0080\n",
      "Epoch 122/200, Iteration 133/250, Loss: 0.0080\n",
      "Epoch 122/200, Iteration 134/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 135/250, Loss: 0.0173\n",
      "Epoch 122/200, Iteration 136/250, Loss: 0.0077\n",
      "Epoch 122/200, Iteration 137/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 138/250, Loss: 0.0147\n",
      "Epoch 122/200, Iteration 139/250, Loss: 0.0128\n",
      "Epoch 122/200, Iteration 140/250, Loss: 0.0084\n",
      "Epoch 122/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 122/200, Iteration 142/250, Loss: 0.0077\n",
      "Epoch 122/200, Iteration 143/250, Loss: 0.0297\n",
      "Epoch 122/200, Iteration 144/250, Loss: 0.0256\n",
      "Epoch 122/200, Iteration 145/250, Loss: 0.0126\n",
      "Epoch 122/200, Iteration 146/250, Loss: 0.0062\n",
      "Epoch 122/200, Iteration 147/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 148/250, Loss: 0.0064\n",
      "Epoch 122/200, Iteration 149/250, Loss: 0.0136\n",
      "Epoch 122/200, Iteration 150/250, Loss: 0.0240\n",
      "Epoch 122/200, Iteration 151/250, Loss: 0.0101\n",
      "Epoch 122/200, Iteration 152/250, Loss: 0.0229\n",
      "Epoch 122/200, Iteration 153/250, Loss: 0.0123\n",
      "Epoch 122/200, Iteration 154/250, Loss: 0.0186\n",
      "Epoch 122/200, Iteration 155/250, Loss: 0.0073\n",
      "Epoch 122/200, Iteration 156/250, Loss: 0.0191\n",
      "Epoch 122/200, Iteration 157/250, Loss: 0.0238\n",
      "Epoch 122/200, Iteration 158/250, Loss: 0.0161\n",
      "Epoch 122/200, Iteration 159/250, Loss: 0.0100\n",
      "Epoch 122/200, Iteration 160/250, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 161/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 162/250, Loss: 0.0261\n",
      "Epoch 122/200, Iteration 163/250, Loss: 0.0125\n",
      "Epoch 122/200, Iteration 164/250, Loss: 0.0281\n",
      "Epoch 122/200, Iteration 165/250, Loss: 0.0113\n",
      "Epoch 122/200, Iteration 166/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 167/250, Loss: 0.0121\n",
      "Epoch 122/200, Iteration 168/250, Loss: 0.0144\n",
      "Epoch 122/200, Iteration 169/250, Loss: 0.0121\n",
      "Epoch 122/200, Iteration 170/250, Loss: 0.0144\n",
      "Epoch 122/200, Iteration 171/250, Loss: 0.0135\n",
      "Epoch 122/200, Iteration 172/250, Loss: 0.0087\n",
      "Epoch 122/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 174/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 176/250, Loss: 0.0135\n",
      "Epoch 122/200, Iteration 177/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 178/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 179/250, Loss: 0.0147\n",
      "Epoch 122/200, Iteration 180/250, Loss: 0.0140\n",
      "Epoch 122/200, Iteration 181/250, Loss: 0.0087\n",
      "Epoch 122/200, Iteration 182/250, Loss: 0.0152\n",
      "Epoch 122/200, Iteration 183/250, Loss: 0.0067\n",
      "Epoch 122/200, Iteration 184/250, Loss: 0.0070\n",
      "Epoch 122/200, Iteration 185/250, Loss: 0.0207\n",
      "Epoch 122/200, Iteration 186/250, Loss: 0.0154\n",
      "Epoch 122/200, Iteration 187/250, Loss: 0.0114\n",
      "Epoch 122/200, Iteration 188/250, Loss: 0.0164\n",
      "Epoch 122/200, Iteration 189/250, Loss: 0.0114\n",
      "Epoch 122/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 122/200, Iteration 191/250, Loss: 0.0143\n",
      "Epoch 122/200, Iteration 192/250, Loss: 0.0224\n",
      "Epoch 122/200, Iteration 193/250, Loss: 0.0084\n",
      "Epoch 122/200, Iteration 194/250, Loss: 0.0124\n",
      "Epoch 122/200, Iteration 195/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 196/250, Loss: 0.0079\n",
      "Epoch 122/200, Iteration 197/250, Loss: 0.0119\n",
      "Epoch 122/200, Iteration 198/250, Loss: 0.0187\n",
      "Epoch 122/200, Iteration 199/250, Loss: 0.0064\n",
      "Epoch 122/200, Iteration 200/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 201/250, Loss: 0.0068\n",
      "Epoch 122/200, Iteration 202/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 203/250, Loss: 0.0148\n",
      "Epoch 122/200, Iteration 204/250, Loss: 0.0092\n",
      "Epoch 122/200, Iteration 205/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 206/250, Loss: 0.0113\n",
      "Epoch 122/200, Iteration 207/250, Loss: 0.0119\n",
      "Epoch 122/200, Iteration 208/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 209/250, Loss: 0.0093\n",
      "Epoch 122/200, Iteration 210/250, Loss: 0.0279\n",
      "Epoch 122/200, Iteration 211/250, Loss: 0.0070\n",
      "Epoch 122/200, Iteration 212/250, Loss: 0.0225\n",
      "Epoch 122/200, Iteration 213/250, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 214/250, Loss: 0.0148\n",
      "Epoch 122/200, Iteration 215/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 216/250, Loss: 0.0195\n",
      "Epoch 122/200, Iteration 217/250, Loss: 0.0062\n",
      "Epoch 122/200, Iteration 218/250, Loss: 0.0219\n",
      "Epoch 122/200, Iteration 219/250, Loss: 0.0138\n",
      "Epoch 122/200, Iteration 220/250, Loss: 0.0096\n",
      "Epoch 122/200, Iteration 221/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 222/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 122/200, Iteration 224/250, Loss: 0.0112\n",
      "Epoch 122/200, Iteration 225/250, Loss: 0.0097\n",
      "Epoch 122/200, Iteration 226/250, Loss: 0.0095\n",
      "Epoch 122/200, Iteration 227/250, Loss: 0.0088\n",
      "Epoch 122/200, Iteration 228/250, Loss: 0.0118\n",
      "Epoch 122/200, Iteration 229/250, Loss: 0.0172\n",
      "Epoch 122/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 122/200, Iteration 231/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 232/250, Loss: 0.0180\n",
      "Epoch 122/200, Iteration 233/250, Loss: 0.0065\n",
      "Epoch 122/200, Iteration 234/250, Loss: 0.0206\n",
      "Epoch 122/200, Iteration 235/250, Loss: 0.0068\n",
      "Epoch 122/200, Iteration 236/250, Loss: 0.0249\n",
      "Epoch 122/200, Iteration 237/250, Loss: 0.0082\n",
      "Epoch 122/200, Iteration 238/250, Loss: 0.0186\n",
      "Epoch 122/200, Iteration 239/250, Loss: 0.0328\n",
      "Epoch 122/200, Iteration 240/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 241/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 122/200, Iteration 243/250, Loss: 0.0129\n",
      "Epoch 122/200, Iteration 244/250, Loss: 0.0167\n",
      "Epoch 122/200, Iteration 245/250, Loss: 0.0112\n",
      "Epoch 122/200, Iteration 246/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 247/250, Loss: 0.0118\n",
      "Epoch 122/200, Iteration 248/250, Loss: 0.0232\n",
      "Epoch 122/200, Iteration 249/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 250/250, Loss: 0.0311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 80.61%, Avg loss: 0.007242, MRE: 0.654946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.007335, MRE: 0.933091 \n",
      "\n",
      "Epoch 123/200, Iteration 1/250, Loss: 0.0080\n",
      "Epoch 123/200, Iteration 2/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 3/250, Loss: 0.0219\n",
      "Epoch 123/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 123/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 123/200, Iteration 6/250, Loss: 0.0224\n",
      "Epoch 123/200, Iteration 7/250, Loss: 0.0174\n",
      "Epoch 123/200, Iteration 8/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 9/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 123/200, Iteration 11/250, Loss: 0.0101\n",
      "Epoch 123/200, Iteration 12/250, Loss: 0.0106\n",
      "Epoch 123/200, Iteration 13/250, Loss: 0.0078\n",
      "Epoch 123/200, Iteration 14/250, Loss: 0.0162\n",
      "Epoch 123/200, Iteration 15/250, Loss: 0.0109\n",
      "Epoch 123/200, Iteration 16/250, Loss: 0.0142\n",
      "Epoch 123/200, Iteration 17/250, Loss: 0.0166\n",
      "Epoch 123/200, Iteration 18/250, Loss: 0.0109\n",
      "Epoch 123/200, Iteration 19/250, Loss: 0.0408\n",
      "Epoch 123/200, Iteration 20/250, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 21/250, Loss: 0.0296\n",
      "Epoch 123/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 23/250, Loss: 0.0193\n",
      "Epoch 123/200, Iteration 24/250, Loss: 0.0342\n",
      "Epoch 123/200, Iteration 25/250, Loss: 0.0093\n",
      "Epoch 123/200, Iteration 26/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 27/250, Loss: 0.0114\n",
      "Epoch 123/200, Iteration 28/250, Loss: 0.0217\n",
      "Epoch 123/200, Iteration 29/250, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 30/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 31/250, Loss: 0.0119\n",
      "Epoch 123/200, Iteration 32/250, Loss: 0.0174\n",
      "Epoch 123/200, Iteration 33/250, Loss: 0.0122\n",
      "Epoch 123/200, Iteration 34/250, Loss: 0.0341\n",
      "Epoch 123/200, Iteration 35/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 36/250, Loss: 0.0167\n",
      "Epoch 123/200, Iteration 37/250, Loss: 0.0332\n",
      "Epoch 123/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 123/200, Iteration 39/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 40/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 41/250, Loss: 0.0122\n",
      "Epoch 123/200, Iteration 42/250, Loss: 0.0284\n",
      "Epoch 123/200, Iteration 43/250, Loss: 0.0234\n",
      "Epoch 123/200, Iteration 44/250, Loss: 0.0454\n",
      "Epoch 123/200, Iteration 45/250, Loss: 0.0205\n",
      "Epoch 123/200, Iteration 46/250, Loss: 0.0069\n",
      "Epoch 123/200, Iteration 47/250, Loss: 0.0152\n",
      "Epoch 123/200, Iteration 48/250, Loss: 0.0209\n",
      "Epoch 123/200, Iteration 49/250, Loss: 0.0092\n",
      "Epoch 123/200, Iteration 50/250, Loss: 0.0301\n",
      "Epoch 123/200, Iteration 51/250, Loss: 0.0183\n",
      "Epoch 123/200, Iteration 52/250, Loss: 0.0167\n",
      "Epoch 123/200, Iteration 53/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 54/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 55/250, Loss: 0.0124\n",
      "Epoch 123/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 123/200, Iteration 57/250, Loss: 0.0310\n",
      "Epoch 123/200, Iteration 58/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 59/250, Loss: 0.0193\n",
      "Epoch 123/200, Iteration 60/250, Loss: 0.0194\n",
      "Epoch 123/200, Iteration 61/250, Loss: 0.0187\n",
      "Epoch 123/200, Iteration 62/250, Loss: 0.0090\n",
      "Epoch 123/200, Iteration 63/250, Loss: 0.0083\n",
      "Epoch 123/200, Iteration 64/250, Loss: 0.0062\n",
      "Epoch 123/200, Iteration 65/250, Loss: 0.0114\n",
      "Epoch 123/200, Iteration 66/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 67/250, Loss: 0.0227\n",
      "Epoch 123/200, Iteration 68/250, Loss: 0.0203\n",
      "Epoch 123/200, Iteration 69/250, Loss: 0.0175\n",
      "Epoch 123/200, Iteration 70/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 71/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 72/250, Loss: 0.0162\n",
      "Epoch 123/200, Iteration 73/250, Loss: 0.0092\n",
      "Epoch 123/200, Iteration 74/250, Loss: 0.0073\n",
      "Epoch 123/200, Iteration 75/250, Loss: 0.0166\n",
      "Epoch 123/200, Iteration 76/250, Loss: 0.0182\n",
      "Epoch 123/200, Iteration 77/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 79/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 80/250, Loss: 0.0075\n",
      "Epoch 123/200, Iteration 81/250, Loss: 0.0135\n",
      "Epoch 123/200, Iteration 82/250, Loss: 0.0169\n",
      "Epoch 123/200, Iteration 83/250, Loss: 0.0164\n",
      "Epoch 123/200, Iteration 84/250, Loss: 0.0069\n",
      "Epoch 123/200, Iteration 85/250, Loss: 0.0072\n",
      "Epoch 123/200, Iteration 86/250, Loss: 0.0149\n",
      "Epoch 123/200, Iteration 87/250, Loss: 0.0093\n",
      "Epoch 123/200, Iteration 88/250, Loss: 0.0272\n",
      "Epoch 123/200, Iteration 89/250, Loss: 0.0194\n",
      "Epoch 123/200, Iteration 90/250, Loss: 0.0303\n",
      "Epoch 123/200, Iteration 91/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 92/250, Loss: 0.0167\n",
      "Epoch 123/200, Iteration 93/250, Loss: 0.0069\n",
      "Epoch 123/200, Iteration 94/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 95/250, Loss: 0.0187\n",
      "Epoch 123/200, Iteration 96/250, Loss: 0.0071\n",
      "Epoch 123/200, Iteration 97/250, Loss: 0.0222\n",
      "Epoch 123/200, Iteration 98/250, Loss: 0.0133\n",
      "Epoch 123/200, Iteration 99/250, Loss: 0.0117\n",
      "Epoch 123/200, Iteration 100/250, Loss: 0.0286\n",
      "Epoch 123/200, Iteration 101/250, Loss: 0.0129\n",
      "Epoch 123/200, Iteration 102/250, Loss: 0.0190\n",
      "Epoch 123/200, Iteration 103/250, Loss: 0.0199\n",
      "Epoch 123/200, Iteration 104/250, Loss: 0.0065\n",
      "Epoch 123/200, Iteration 105/250, Loss: 0.0166\n",
      "Epoch 123/200, Iteration 106/250, Loss: 0.0115\n",
      "Epoch 123/200, Iteration 107/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 108/250, Loss: 0.0221\n",
      "Epoch 123/200, Iteration 109/250, Loss: 0.0082\n",
      "Epoch 123/200, Iteration 110/250, Loss: 0.0056\n",
      "Epoch 123/200, Iteration 111/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 123/200, Iteration 113/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 114/250, Loss: 0.0116\n",
      "Epoch 123/200, Iteration 115/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 116/250, Loss: 0.0193\n",
      "Epoch 123/200, Iteration 117/250, Loss: 0.0162\n",
      "Epoch 123/200, Iteration 118/250, Loss: 0.0219\n",
      "Epoch 123/200, Iteration 119/250, Loss: 0.0183\n",
      "Epoch 123/200, Iteration 120/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 121/250, Loss: 0.0114\n",
      "Epoch 123/200, Iteration 122/250, Loss: 0.0140\n",
      "Epoch 123/200, Iteration 123/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 124/250, Loss: 0.0354\n",
      "Epoch 123/200, Iteration 125/250, Loss: 0.0125\n",
      "Epoch 123/200, Iteration 126/250, Loss: 0.0247\n",
      "Epoch 123/200, Iteration 127/250, Loss: 0.0190\n",
      "Epoch 123/200, Iteration 128/250, Loss: 0.0158\n",
      "Epoch 123/200, Iteration 129/250, Loss: 0.0145\n",
      "Epoch 123/200, Iteration 130/250, Loss: 0.0136\n",
      "Epoch 123/200, Iteration 131/250, Loss: 0.0206\n",
      "Epoch 123/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 133/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 134/250, Loss: 0.0099\n",
      "Epoch 123/200, Iteration 135/250, Loss: 0.0076\n",
      "Epoch 123/200, Iteration 136/250, Loss: 0.0177\n",
      "Epoch 123/200, Iteration 137/250, Loss: 0.0169\n",
      "Epoch 123/200, Iteration 138/250, Loss: 0.0327\n",
      "Epoch 123/200, Iteration 139/250, Loss: 0.0127\n",
      "Epoch 123/200, Iteration 140/250, Loss: 0.0302\n",
      "Epoch 123/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 123/200, Iteration 143/250, Loss: 0.0118\n",
      "Epoch 123/200, Iteration 144/250, Loss: 0.0190\n",
      "Epoch 123/200, Iteration 145/250, Loss: 0.0191\n",
      "Epoch 123/200, Iteration 146/250, Loss: 0.0186\n",
      "Epoch 123/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 123/200, Iteration 148/250, Loss: 0.0244\n",
      "Epoch 123/200, Iteration 149/250, Loss: 0.0181\n",
      "Epoch 123/200, Iteration 150/250, Loss: 0.0319\n",
      "Epoch 123/200, Iteration 151/250, Loss: 0.0141\n",
      "Epoch 123/200, Iteration 152/250, Loss: 0.0278\n",
      "Epoch 123/200, Iteration 153/250, Loss: 0.0127\n",
      "Epoch 123/200, Iteration 154/250, Loss: 0.0365\n",
      "Epoch 123/200, Iteration 155/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 156/250, Loss: 0.0199\n",
      "Epoch 123/200, Iteration 157/250, Loss: 0.0145\n",
      "Epoch 123/200, Iteration 158/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 159/250, Loss: 0.0077\n",
      "Epoch 123/200, Iteration 160/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 161/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 162/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 163/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 165/250, Loss: 0.0066\n",
      "Epoch 123/200, Iteration 166/250, Loss: 0.0110\n",
      "Epoch 123/200, Iteration 167/250, Loss: 0.0342\n",
      "Epoch 123/200, Iteration 168/250, Loss: 0.0123\n",
      "Epoch 123/200, Iteration 169/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 170/250, Loss: 0.0198\n",
      "Epoch 123/200, Iteration 171/250, Loss: 0.0170\n",
      "Epoch 123/200, Iteration 172/250, Loss: 0.0084\n",
      "Epoch 123/200, Iteration 173/250, Loss: 0.0202\n",
      "Epoch 123/200, Iteration 174/250, Loss: 0.0288\n",
      "Epoch 123/200, Iteration 175/250, Loss: 0.0088\n",
      "Epoch 123/200, Iteration 176/250, Loss: 0.0120\n",
      "Epoch 123/200, Iteration 177/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 178/250, Loss: 0.0113\n",
      "Epoch 123/200, Iteration 179/250, Loss: 0.0070\n",
      "Epoch 123/200, Iteration 180/250, Loss: 0.0422\n",
      "Epoch 123/200, Iteration 181/250, Loss: 0.0138\n",
      "Epoch 123/200, Iteration 182/250, Loss: 0.0064\n",
      "Epoch 123/200, Iteration 183/250, Loss: 0.0404\n",
      "Epoch 123/200, Iteration 184/250, Loss: 0.0204\n",
      "Epoch 123/200, Iteration 185/250, Loss: 0.0141\n",
      "Epoch 123/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 187/250, Loss: 0.0190\n",
      "Epoch 123/200, Iteration 188/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 189/250, Loss: 0.0115\n",
      "Epoch 123/200, Iteration 190/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 191/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 192/250, Loss: 0.0101\n",
      "Epoch 123/200, Iteration 193/250, Loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 123/200, Iteration 195/250, Loss: 0.0175\n",
      "Epoch 123/200, Iteration 196/250, Loss: 0.0194\n",
      "Epoch 123/200, Iteration 197/250, Loss: 0.0396\n",
      "Epoch 123/200, Iteration 198/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 199/250, Loss: 0.0147\n",
      "Epoch 123/200, Iteration 200/250, Loss: 0.0205\n",
      "Epoch 123/200, Iteration 201/250, Loss: 0.0090\n",
      "Epoch 123/200, Iteration 202/250, Loss: 0.0198\n",
      "Epoch 123/200, Iteration 203/250, Loss: 0.0096\n",
      "Epoch 123/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 205/250, Loss: 0.0364\n",
      "Epoch 123/200, Iteration 206/250, Loss: 0.0262\n",
      "Epoch 123/200, Iteration 207/250, Loss: 0.0156\n",
      "Epoch 123/200, Iteration 208/250, Loss: 0.0176\n",
      "Epoch 123/200, Iteration 209/250, Loss: 0.0117\n",
      "Epoch 123/200, Iteration 210/250, Loss: 0.0286\n",
      "Epoch 123/200, Iteration 211/250, Loss: 0.0203\n",
      "Epoch 123/200, Iteration 212/250, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 213/250, Loss: 0.0096\n",
      "Epoch 123/200, Iteration 214/250, Loss: 0.0159\n",
      "Epoch 123/200, Iteration 215/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 216/250, Loss: 0.0244\n",
      "Epoch 123/200, Iteration 217/250, Loss: 0.0149\n",
      "Epoch 123/200, Iteration 218/250, Loss: 0.0081\n",
      "Epoch 123/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 220/250, Loss: 0.0165\n",
      "Epoch 123/200, Iteration 221/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 222/250, Loss: 0.0128\n",
      "Epoch 123/200, Iteration 223/250, Loss: 0.0143\n",
      "Epoch 123/200, Iteration 224/250, Loss: 0.0120\n",
      "Epoch 123/200, Iteration 225/250, Loss: 0.0062\n",
      "Epoch 123/200, Iteration 226/250, Loss: 0.0084\n",
      "Epoch 123/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 123/200, Iteration 228/250, Loss: 0.0144\n",
      "Epoch 123/200, Iteration 229/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 230/250, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 233/250, Loss: 0.0128\n",
      "Epoch 123/200, Iteration 234/250, Loss: 0.0088\n",
      "Epoch 123/200, Iteration 235/250, Loss: 0.0155\n",
      "Epoch 123/200, Iteration 236/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 237/250, Loss: 0.0078\n",
      "Epoch 123/200, Iteration 238/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 239/250, Loss: 0.0306\n",
      "Epoch 123/200, Iteration 240/250, Loss: 0.0086\n",
      "Epoch 123/200, Iteration 241/250, Loss: 0.0173\n",
      "Epoch 123/200, Iteration 242/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 243/250, Loss: 0.0065\n",
      "Epoch 123/200, Iteration 244/250, Loss: 0.0093\n",
      "Epoch 123/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 246/250, Loss: 0.0216\n",
      "Epoch 123/200, Iteration 247/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 248/250, Loss: 0.0202\n",
      "Epoch 123/200, Iteration 249/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 250/250, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 87.83%, Avg loss: 0.006455, MRE: 0.621289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.85%, Avg loss: 0.006501, MRE: 0.912552 \n",
      "\n",
      "Epoch 124/200, Iteration 1/250, Loss: 0.0204\n",
      "Epoch 124/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 124/200, Iteration 3/250, Loss: 0.0072\n",
      "Epoch 124/200, Iteration 4/250, Loss: 0.0237\n",
      "Epoch 124/200, Iteration 5/250, Loss: 0.0105\n",
      "Epoch 124/200, Iteration 6/250, Loss: 0.0134\n",
      "Epoch 124/200, Iteration 7/250, Loss: 0.0126\n",
      "Epoch 124/200, Iteration 8/250, Loss: 0.0244\n",
      "Epoch 124/200, Iteration 9/250, Loss: 0.0126\n",
      "Epoch 124/200, Iteration 10/250, Loss: 0.0075\n",
      "Epoch 124/200, Iteration 11/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 124/200, Iteration 13/250, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 14/250, Loss: 0.0080\n",
      "Epoch 124/200, Iteration 15/250, Loss: 0.0112\n",
      "Epoch 124/200, Iteration 16/250, Loss: 0.0109\n",
      "Epoch 124/200, Iteration 17/250, Loss: 0.0084\n",
      "Epoch 124/200, Iteration 18/250, Loss: 0.0091\n",
      "Epoch 124/200, Iteration 19/250, Loss: 0.0085\n",
      "Epoch 124/200, Iteration 20/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 21/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 22/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 23/250, Loss: 0.0077\n",
      "Epoch 124/200, Iteration 24/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 25/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 26/250, Loss: 0.0065\n",
      "Epoch 124/200, Iteration 27/250, Loss: 0.0101\n",
      "Epoch 124/200, Iteration 28/250, Loss: 0.0245\n",
      "Epoch 124/200, Iteration 29/250, Loss: 0.0133\n",
      "Epoch 124/200, Iteration 30/250, Loss: 0.0141\n",
      "Epoch 124/200, Iteration 31/250, Loss: 0.0079\n",
      "Epoch 124/200, Iteration 32/250, Loss: 0.0145\n",
      "Epoch 124/200, Iteration 33/250, Loss: 0.0166\n",
      "Epoch 124/200, Iteration 34/250, Loss: 0.0149\n",
      "Epoch 124/200, Iteration 35/250, Loss: 0.0247\n",
      "Epoch 124/200, Iteration 36/250, Loss: 0.0162\n",
      "Epoch 124/200, Iteration 37/250, Loss: 0.0091\n",
      "Epoch 124/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 124/200, Iteration 39/250, Loss: 0.0310\n",
      "Epoch 124/200, Iteration 40/250, Loss: 0.0142\n",
      "Epoch 124/200, Iteration 41/250, Loss: 0.0126\n",
      "Epoch 124/200, Iteration 42/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 43/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 44/250, Loss: 0.0175\n",
      "Epoch 124/200, Iteration 45/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 46/250, Loss: 0.0174\n",
      "Epoch 124/200, Iteration 47/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 48/250, Loss: 0.0168\n",
      "Epoch 124/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 50/250, Loss: 0.0352\n",
      "Epoch 124/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 124/200, Iteration 52/250, Loss: 0.0118\n",
      "Epoch 124/200, Iteration 53/250, Loss: 0.0077\n",
      "Epoch 124/200, Iteration 54/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 55/250, Loss: 0.0193\n",
      "Epoch 124/200, Iteration 56/250, Loss: 0.0185\n",
      "Epoch 124/200, Iteration 57/250, Loss: 0.0155\n",
      "Epoch 124/200, Iteration 58/250, Loss: 0.0211\n",
      "Epoch 124/200, Iteration 59/250, Loss: 0.0160\n",
      "Epoch 124/200, Iteration 60/250, Loss: 0.0140\n",
      "Epoch 124/200, Iteration 61/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 62/250, Loss: 0.0127\n",
      "Epoch 124/200, Iteration 63/250, Loss: 0.0085\n",
      "Epoch 124/200, Iteration 64/250, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 65/250, Loss: 0.0120\n",
      "Epoch 124/200, Iteration 66/250, Loss: 0.0138\n",
      "Epoch 124/200, Iteration 67/250, Loss: 0.0143\n",
      "Epoch 124/200, Iteration 68/250, Loss: 0.0421\n",
      "Epoch 124/200, Iteration 69/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 70/250, Loss: 0.0175\n",
      "Epoch 124/200, Iteration 71/250, Loss: 0.0109\n",
      "Epoch 124/200, Iteration 72/250, Loss: 0.0214\n",
      "Epoch 124/200, Iteration 73/250, Loss: 0.0157\n",
      "Epoch 124/200, Iteration 74/250, Loss: 0.0225\n",
      "Epoch 124/200, Iteration 75/250, Loss: 0.0185\n",
      "Epoch 124/200, Iteration 76/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 77/250, Loss: 0.0292\n",
      "Epoch 124/200, Iteration 78/250, Loss: 0.0343\n",
      "Epoch 124/200, Iteration 79/250, Loss: 0.0133\n",
      "Epoch 124/200, Iteration 80/250, Loss: 0.0153\n",
      "Epoch 124/200, Iteration 81/250, Loss: 0.0108\n",
      "Epoch 124/200, Iteration 82/250, Loss: 0.0243\n",
      "Epoch 124/200, Iteration 83/250, Loss: 0.0178\n",
      "Epoch 124/200, Iteration 84/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 85/250, Loss: 0.0110\n",
      "Epoch 124/200, Iteration 86/250, Loss: 0.0073\n",
      "Epoch 124/200, Iteration 87/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 88/250, Loss: 0.0220\n",
      "Epoch 124/200, Iteration 89/250, Loss: 0.0176\n",
      "Epoch 124/200, Iteration 90/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 91/250, Loss: 0.0088\n",
      "Epoch 124/200, Iteration 92/250, Loss: 0.0168\n",
      "Epoch 124/200, Iteration 93/250, Loss: 0.0185\n",
      "Epoch 124/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 95/250, Loss: 0.0349\n",
      "Epoch 124/200, Iteration 96/250, Loss: 0.0136\n",
      "Epoch 124/200, Iteration 97/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 99/250, Loss: 0.0138\n",
      "Epoch 124/200, Iteration 100/250, Loss: 0.0142\n",
      "Epoch 124/200, Iteration 101/250, Loss: 0.0437\n",
      "Epoch 124/200, Iteration 102/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 103/250, Loss: 0.0108\n",
      "Epoch 124/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 105/250, Loss: 0.0265\n",
      "Epoch 124/200, Iteration 106/250, Loss: 0.0148\n",
      "Epoch 124/200, Iteration 107/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 108/250, Loss: 0.0243\n",
      "Epoch 124/200, Iteration 109/250, Loss: 0.0120\n",
      "Epoch 124/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 111/250, Loss: 0.0172\n",
      "Epoch 124/200, Iteration 112/250, Loss: 0.0159\n",
      "Epoch 124/200, Iteration 113/250, Loss: 0.0166\n",
      "Epoch 124/200, Iteration 114/250, Loss: 0.0156\n",
      "Epoch 124/200, Iteration 115/250, Loss: 0.0210\n",
      "Epoch 124/200, Iteration 116/250, Loss: 0.0118\n",
      "Epoch 124/200, Iteration 117/250, Loss: 0.0162\n",
      "Epoch 124/200, Iteration 118/250, Loss: 0.0223\n",
      "Epoch 124/200, Iteration 119/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 120/250, Loss: 0.0129\n",
      "Epoch 124/200, Iteration 121/250, Loss: 0.0091\n",
      "Epoch 124/200, Iteration 122/250, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200, Iteration 123/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 124/250, Loss: 0.0266\n",
      "Epoch 124/200, Iteration 125/250, Loss: 0.0170\n",
      "Epoch 124/200, Iteration 126/250, Loss: 0.0130\n",
      "Epoch 124/200, Iteration 127/250, Loss: 0.0115\n",
      "Epoch 124/200, Iteration 128/250, Loss: 0.0194\n",
      "Epoch 124/200, Iteration 129/250, Loss: 0.0073\n",
      "Epoch 124/200, Iteration 130/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 131/250, Loss: 0.0133\n",
      "Epoch 124/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 124/200, Iteration 133/250, Loss: 0.0134\n",
      "Epoch 124/200, Iteration 134/250, Loss: 0.0208\n",
      "Epoch 124/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 124/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 137/250, Loss: 0.0148\n",
      "Epoch 124/200, Iteration 138/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 139/250, Loss: 0.0269\n",
      "Epoch 124/200, Iteration 140/250, Loss: 0.0141\n",
      "Epoch 124/200, Iteration 141/250, Loss: 0.0191\n",
      "Epoch 124/200, Iteration 142/250, Loss: 0.0230\n",
      "Epoch 124/200, Iteration 143/250, Loss: 0.0082\n",
      "Epoch 124/200, Iteration 144/250, Loss: 0.0199\n",
      "Epoch 124/200, Iteration 145/250, Loss: 0.0188\n",
      "Epoch 124/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 124/200, Iteration 147/250, Loss: 0.0096\n",
      "Epoch 124/200, Iteration 148/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 149/250, Loss: 0.0224\n",
      "Epoch 124/200, Iteration 150/250, Loss: 0.0083\n",
      "Epoch 124/200, Iteration 151/250, Loss: 0.0079\n",
      "Epoch 124/200, Iteration 152/250, Loss: 0.0180\n",
      "Epoch 124/200, Iteration 153/250, Loss: 0.0186\n",
      "Epoch 124/200, Iteration 154/250, Loss: 0.0104\n",
      "Epoch 124/200, Iteration 155/250, Loss: 0.0109\n",
      "Epoch 124/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 124/200, Iteration 157/250, Loss: 0.0256\n",
      "Epoch 124/200, Iteration 158/250, Loss: 0.0109\n",
      "Epoch 124/200, Iteration 159/250, Loss: 0.0075\n",
      "Epoch 124/200, Iteration 160/250, Loss: 0.0135\n",
      "Epoch 124/200, Iteration 161/250, Loss: 0.0165\n",
      "Epoch 124/200, Iteration 162/250, Loss: 0.0340\n",
      "Epoch 124/200, Iteration 163/250, Loss: 0.0329\n",
      "Epoch 124/200, Iteration 164/250, Loss: 0.0296\n",
      "Epoch 124/200, Iteration 165/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 166/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 167/250, Loss: 0.0080\n",
      "Epoch 124/200, Iteration 168/250, Loss: 0.0093\n",
      "Epoch 124/200, Iteration 169/250, Loss: 0.0109\n",
      "Epoch 124/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 124/200, Iteration 171/250, Loss: 0.0202\n",
      "Epoch 124/200, Iteration 172/250, Loss: 0.0211\n",
      "Epoch 124/200, Iteration 173/250, Loss: 0.0132\n",
      "Epoch 124/200, Iteration 174/250, Loss: 0.0075\n",
      "Epoch 124/200, Iteration 175/250, Loss: 0.0083\n",
      "Epoch 124/200, Iteration 176/250, Loss: 0.0130\n",
      "Epoch 124/200, Iteration 177/250, Loss: 0.0232\n",
      "Epoch 124/200, Iteration 178/250, Loss: 0.0164\n",
      "Epoch 124/200, Iteration 179/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 180/250, Loss: 0.0093\n",
      "Epoch 124/200, Iteration 181/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 182/250, Loss: 0.0191\n",
      "Epoch 124/200, Iteration 183/250, Loss: 0.0123\n",
      "Epoch 124/200, Iteration 184/250, Loss: 0.0165\n",
      "Epoch 124/200, Iteration 185/250, Loss: 0.0235\n",
      "Epoch 124/200, Iteration 186/250, Loss: 0.0306\n",
      "Epoch 124/200, Iteration 187/250, Loss: 0.0316\n",
      "Epoch 124/200, Iteration 188/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 189/250, Loss: 0.0174\n",
      "Epoch 124/200, Iteration 190/250, Loss: 0.0151\n",
      "Epoch 124/200, Iteration 191/250, Loss: 0.0229\n",
      "Epoch 124/200, Iteration 192/250, Loss: 0.0093\n",
      "Epoch 124/200, Iteration 193/250, Loss: 0.0182\n",
      "Epoch 124/200, Iteration 194/250, Loss: 0.0146\n",
      "Epoch 124/200, Iteration 195/250, Loss: 0.0275\n",
      "Epoch 124/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 124/200, Iteration 197/250, Loss: 0.0245\n",
      "Epoch 124/200, Iteration 198/250, Loss: 0.0381\n",
      "Epoch 124/200, Iteration 199/250, Loss: 0.0190\n",
      "Epoch 124/200, Iteration 200/250, Loss: 0.0080\n",
      "Epoch 124/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 124/200, Iteration 202/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 203/250, Loss: 0.0098\n",
      "Epoch 124/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 124/200, Iteration 205/250, Loss: 0.0124\n",
      "Epoch 124/200, Iteration 206/250, Loss: 0.0191\n",
      "Epoch 124/200, Iteration 207/250, Loss: 0.0177\n",
      "Epoch 124/200, Iteration 208/250, Loss: 0.0066\n",
      "Epoch 124/200, Iteration 209/250, Loss: 0.0226\n",
      "Epoch 124/200, Iteration 210/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 211/250, Loss: 0.0252\n",
      "Epoch 124/200, Iteration 212/250, Loss: 0.0096\n",
      "Epoch 124/200, Iteration 213/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 214/250, Loss: 0.0158\n",
      "Epoch 124/200, Iteration 215/250, Loss: 0.0174\n",
      "Epoch 124/200, Iteration 216/250, Loss: 0.0133\n",
      "Epoch 124/200, Iteration 217/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 218/250, Loss: 0.0177\n",
      "Epoch 124/200, Iteration 219/250, Loss: 0.0161\n",
      "Epoch 124/200, Iteration 220/250, Loss: 0.0130\n",
      "Epoch 124/200, Iteration 221/250, Loss: 0.0187\n",
      "Epoch 124/200, Iteration 222/250, Loss: 0.0148\n",
      "Epoch 124/200, Iteration 223/250, Loss: 0.0132\n",
      "Epoch 124/200, Iteration 224/250, Loss: 0.0099\n",
      "Epoch 124/200, Iteration 225/250, Loss: 0.0058\n",
      "Epoch 124/200, Iteration 226/250, Loss: 0.0205\n",
      "Epoch 124/200, Iteration 227/250, Loss: 0.0139\n",
      "Epoch 124/200, Iteration 228/250, Loss: 0.0073\n",
      "Epoch 124/200, Iteration 229/250, Loss: 0.0169\n",
      "Epoch 124/200, Iteration 230/250, Loss: 0.0081\n",
      "Epoch 124/200, Iteration 231/250, Loss: 0.0069\n",
      "Epoch 124/200, Iteration 232/250, Loss: 0.0183\n",
      "Epoch 124/200, Iteration 233/250, Loss: 0.0110\n",
      "Epoch 124/200, Iteration 234/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 235/250, Loss: 0.0108\n",
      "Epoch 124/200, Iteration 236/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 237/250, Loss: 0.0139\n",
      "Epoch 124/200, Iteration 238/250, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 239/250, Loss: 0.0247\n",
      "Epoch 124/200, Iteration 240/250, Loss: 0.0189\n",
      "Epoch 124/200, Iteration 241/250, Loss: 0.0166\n",
      "Epoch 124/200, Iteration 242/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 243/250, Loss: 0.0333\n",
      "Epoch 124/200, Iteration 244/250, Loss: 0.0159\n",
      "Epoch 124/200, Iteration 245/250, Loss: 0.0180\n",
      "Epoch 124/200, Iteration 246/250, Loss: 0.0085\n",
      "Epoch 124/200, Iteration 247/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 248/250, Loss: 0.0082\n",
      "Epoch 124/200, Iteration 249/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 82.62%, Avg loss: 0.007184, MRE: 0.620144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.75%, Avg loss: 0.007296, MRE: 0.945717 \n",
      "\n",
      "Epoch 125/200, Iteration 1/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 2/250, Loss: 0.0136\n",
      "Epoch 125/200, Iteration 3/250, Loss: 0.0192\n",
      "Epoch 125/200, Iteration 4/250, Loss: 0.0112\n",
      "Epoch 125/200, Iteration 5/250, Loss: 0.0199\n",
      "Epoch 125/200, Iteration 6/250, Loss: 0.0173\n",
      "Epoch 125/200, Iteration 7/250, Loss: 0.0075\n",
      "Epoch 125/200, Iteration 8/250, Loss: 0.0126\n",
      "Epoch 125/200, Iteration 9/250, Loss: 0.0114\n",
      "Epoch 125/200, Iteration 10/250, Loss: 0.0067\n",
      "Epoch 125/200, Iteration 11/250, Loss: 0.0163\n",
      "Epoch 125/200, Iteration 12/250, Loss: 0.0224\n",
      "Epoch 125/200, Iteration 13/250, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 14/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 15/250, Loss: 0.0077\n",
      "Epoch 125/200, Iteration 16/250, Loss: 0.0207\n",
      "Epoch 125/200, Iteration 17/250, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 18/250, Loss: 0.0152\n",
      "Epoch 125/200, Iteration 19/250, Loss: 0.0190\n",
      "Epoch 125/200, Iteration 20/250, Loss: 0.0116\n",
      "Epoch 125/200, Iteration 21/250, Loss: 0.0095\n",
      "Epoch 125/200, Iteration 22/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 23/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 24/250, Loss: 0.0155\n",
      "Epoch 125/200, Iteration 25/250, Loss: 0.0094\n",
      "Epoch 125/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 125/200, Iteration 27/250, Loss: 0.0182\n",
      "Epoch 125/200, Iteration 28/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 29/250, Loss: 0.0176\n",
      "Epoch 125/200, Iteration 30/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 31/250, Loss: 0.0161\n",
      "Epoch 125/200, Iteration 32/250, Loss: 0.0071\n",
      "Epoch 125/200, Iteration 33/250, Loss: 0.0086\n",
      "Epoch 125/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 125/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 125/200, Iteration 36/250, Loss: 0.0174\n",
      "Epoch 125/200, Iteration 37/250, Loss: 0.0169\n",
      "Epoch 125/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 125/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 125/200, Iteration 40/250, Loss: 0.0168\n",
      "Epoch 125/200, Iteration 41/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 42/250, Loss: 0.0133\n",
      "Epoch 125/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 44/250, Loss: 0.0133\n",
      "Epoch 125/200, Iteration 45/250, Loss: 0.0158\n",
      "Epoch 125/200, Iteration 46/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 47/250, Loss: 0.0257\n",
      "Epoch 125/200, Iteration 48/250, Loss: 0.0166\n",
      "Epoch 125/200, Iteration 49/250, Loss: 0.0113\n",
      "Epoch 125/200, Iteration 50/250, Loss: 0.0194\n",
      "Epoch 125/200, Iteration 51/250, Loss: 0.0354\n",
      "Epoch 125/200, Iteration 52/250, Loss: 0.0146\n",
      "Epoch 125/200, Iteration 53/250, Loss: 0.0232\n",
      "Epoch 125/200, Iteration 54/250, Loss: 0.0212\n",
      "Epoch 125/200, Iteration 55/250, Loss: 0.0222\n",
      "Epoch 125/200, Iteration 56/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 57/250, Loss: 0.0114\n",
      "Epoch 125/200, Iteration 58/250, Loss: 0.0241\n",
      "Epoch 125/200, Iteration 59/250, Loss: 0.0141\n",
      "Epoch 125/200, Iteration 60/250, Loss: 0.0186\n",
      "Epoch 125/200, Iteration 61/250, Loss: 0.0125\n",
      "Epoch 125/200, Iteration 62/250, Loss: 0.0076\n",
      "Epoch 125/200, Iteration 63/250, Loss: 0.0122\n",
      "Epoch 125/200, Iteration 64/250, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200, Iteration 65/250, Loss: 0.0163\n",
      "Epoch 125/200, Iteration 66/250, Loss: 0.0230\n",
      "Epoch 125/200, Iteration 67/250, Loss: 0.0083\n",
      "Epoch 125/200, Iteration 68/250, Loss: 0.0185\n",
      "Epoch 125/200, Iteration 69/250, Loss: 0.0238\n",
      "Epoch 125/200, Iteration 70/250, Loss: 0.0172\n",
      "Epoch 125/200, Iteration 71/250, Loss: 0.0196\n",
      "Epoch 125/200, Iteration 72/250, Loss: 0.0312\n",
      "Epoch 125/200, Iteration 73/250, Loss: 0.0154\n",
      "Epoch 125/200, Iteration 74/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 75/250, Loss: 0.0200\n",
      "Epoch 125/200, Iteration 76/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 77/250, Loss: 0.0071\n",
      "Epoch 125/200, Iteration 78/250, Loss: 0.0331\n",
      "Epoch 125/200, Iteration 79/250, Loss: 0.0049\n",
      "Epoch 125/200, Iteration 80/250, Loss: 0.0197\n",
      "Epoch 125/200, Iteration 81/250, Loss: 0.0123\n",
      "Epoch 125/200, Iteration 82/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 83/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 84/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 85/250, Loss: 0.0174\n",
      "Epoch 125/200, Iteration 86/250, Loss: 0.0271\n",
      "Epoch 125/200, Iteration 87/250, Loss: 0.0102\n",
      "Epoch 125/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 125/200, Iteration 89/250, Loss: 0.0063\n",
      "Epoch 125/200, Iteration 90/250, Loss: 0.0315\n",
      "Epoch 125/200, Iteration 91/250, Loss: 0.0250\n",
      "Epoch 125/200, Iteration 92/250, Loss: 0.0065\n",
      "Epoch 125/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 94/250, Loss: 0.0328\n",
      "Epoch 125/200, Iteration 95/250, Loss: 0.0097\n",
      "Epoch 125/200, Iteration 96/250, Loss: 0.0115\n",
      "Epoch 125/200, Iteration 97/250, Loss: 0.0150\n",
      "Epoch 125/200, Iteration 98/250, Loss: 0.0126\n",
      "Epoch 125/200, Iteration 99/250, Loss: 0.0318\n",
      "Epoch 125/200, Iteration 100/250, Loss: 0.0200\n",
      "Epoch 125/200, Iteration 101/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 102/250, Loss: 0.0145\n",
      "Epoch 125/200, Iteration 103/250, Loss: 0.0215\n",
      "Epoch 125/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 125/200, Iteration 105/250, Loss: 0.0096\n",
      "Epoch 125/200, Iteration 106/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 107/250, Loss: 0.0207\n",
      "Epoch 125/200, Iteration 108/250, Loss: 0.0116\n",
      "Epoch 125/200, Iteration 109/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 110/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 111/250, Loss: 0.0254\n",
      "Epoch 125/200, Iteration 112/250, Loss: 0.0070\n",
      "Epoch 125/200, Iteration 113/250, Loss: 0.0071\n",
      "Epoch 125/200, Iteration 114/250, Loss: 0.0182\n",
      "Epoch 125/200, Iteration 115/250, Loss: 0.0319\n",
      "Epoch 125/200, Iteration 116/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 117/250, Loss: 0.0326\n",
      "Epoch 125/200, Iteration 118/250, Loss: 0.0177\n",
      "Epoch 125/200, Iteration 119/250, Loss: 0.0234\n",
      "Epoch 125/200, Iteration 120/250, Loss: 0.0106\n",
      "Epoch 125/200, Iteration 121/250, Loss: 0.0152\n",
      "Epoch 125/200, Iteration 122/250, Loss: 0.0141\n",
      "Epoch 125/200, Iteration 123/250, Loss: 0.0135\n",
      "Epoch 125/200, Iteration 124/250, Loss: 0.0134\n",
      "Epoch 125/200, Iteration 125/250, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 126/250, Loss: 0.0190\n",
      "Epoch 125/200, Iteration 127/250, Loss: 0.0123\n",
      "Epoch 125/200, Iteration 128/250, Loss: 0.0084\n",
      "Epoch 125/200, Iteration 129/250, Loss: 0.0130\n",
      "Epoch 125/200, Iteration 130/250, Loss: 0.0215\n",
      "Epoch 125/200, Iteration 131/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 132/250, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 133/250, Loss: 0.0189\n",
      "Epoch 125/200, Iteration 134/250, Loss: 0.0172\n",
      "Epoch 125/200, Iteration 135/250, Loss: 0.0299\n",
      "Epoch 125/200, Iteration 136/250, Loss: 0.0086\n",
      "Epoch 125/200, Iteration 137/250, Loss: 0.0318\n",
      "Epoch 125/200, Iteration 138/250, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 139/250, Loss: 0.0130\n",
      "Epoch 125/200, Iteration 140/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 141/250, Loss: 0.0103\n",
      "Epoch 125/200, Iteration 142/250, Loss: 0.0203\n",
      "Epoch 125/200, Iteration 143/250, Loss: 0.0174\n",
      "Epoch 125/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 145/250, Loss: 0.0130\n",
      "Epoch 125/200, Iteration 146/250, Loss: 0.0209\n",
      "Epoch 125/200, Iteration 147/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 148/250, Loss: 0.0131\n",
      "Epoch 125/200, Iteration 149/250, Loss: 0.0225\n",
      "Epoch 125/200, Iteration 150/250, Loss: 0.0114\n",
      "Epoch 125/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 125/200, Iteration 152/250, Loss: 0.0230\n",
      "Epoch 125/200, Iteration 153/250, Loss: 0.0063\n",
      "Epoch 125/200, Iteration 154/250, Loss: 0.0226\n",
      "Epoch 125/200, Iteration 155/250, Loss: 0.0095\n",
      "Epoch 125/200, Iteration 156/250, Loss: 0.0163\n",
      "Epoch 125/200, Iteration 157/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 158/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 159/250, Loss: 0.0083\n",
      "Epoch 125/200, Iteration 160/250, Loss: 0.0108\n",
      "Epoch 125/200, Iteration 161/250, Loss: 0.0188\n",
      "Epoch 125/200, Iteration 162/250, Loss: 0.0244\n",
      "Epoch 125/200, Iteration 163/250, Loss: 0.0203\n",
      "Epoch 125/200, Iteration 164/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 166/250, Loss: 0.0184\n",
      "Epoch 125/200, Iteration 167/250, Loss: 0.0263\n",
      "Epoch 125/200, Iteration 168/250, Loss: 0.0188\n",
      "Epoch 125/200, Iteration 169/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 170/250, Loss: 0.0193\n",
      "Epoch 125/200, Iteration 171/250, Loss: 0.0101\n",
      "Epoch 125/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 125/200, Iteration 173/250, Loss: 0.0131\n",
      "Epoch 125/200, Iteration 174/250, Loss: 0.0088\n",
      "Epoch 125/200, Iteration 175/250, Loss: 0.0069\n",
      "Epoch 125/200, Iteration 176/250, Loss: 0.0241\n",
      "Epoch 125/200, Iteration 177/250, Loss: 0.0139\n",
      "Epoch 125/200, Iteration 178/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 179/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 180/250, Loss: 0.0069\n",
      "Epoch 125/200, Iteration 181/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 182/250, Loss: 0.0072\n",
      "Epoch 125/200, Iteration 183/250, Loss: 0.0320\n",
      "Epoch 125/200, Iteration 184/250, Loss: 0.0111\n",
      "Epoch 125/200, Iteration 185/250, Loss: 0.0108\n",
      "Epoch 125/200, Iteration 186/250, Loss: 0.0231\n",
      "Epoch 125/200, Iteration 187/250, Loss: 0.0128\n",
      "Epoch 125/200, Iteration 188/250, Loss: 0.0177\n",
      "Epoch 125/200, Iteration 189/250, Loss: 0.0117\n",
      "Epoch 125/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 125/200, Iteration 191/250, Loss: 0.0066\n",
      "Epoch 125/200, Iteration 192/250, Loss: 0.0125\n",
      "Epoch 125/200, Iteration 193/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 195/250, Loss: 0.0100\n",
      "Epoch 125/200, Iteration 196/250, Loss: 0.0141\n",
      "Epoch 125/200, Iteration 197/250, Loss: 0.0111\n",
      "Epoch 125/200, Iteration 198/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 199/250, Loss: 0.0085\n",
      "Epoch 125/200, Iteration 200/250, Loss: 0.0181\n",
      "Epoch 125/200, Iteration 201/250, Loss: 0.0114\n",
      "Epoch 125/200, Iteration 202/250, Loss: 0.0073\n",
      "Epoch 125/200, Iteration 203/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 204/250, Loss: 0.0071\n",
      "Epoch 125/200, Iteration 205/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 206/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 207/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 208/250, Loss: 0.0152\n",
      "Epoch 125/200, Iteration 209/250, Loss: 0.0173\n",
      "Epoch 125/200, Iteration 210/250, Loss: 0.0115\n",
      "Epoch 125/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 212/250, Loss: 0.0150\n",
      "Epoch 125/200, Iteration 213/250, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 214/250, Loss: 0.0128\n",
      "Epoch 125/200, Iteration 215/250, Loss: 0.0086\n",
      "Epoch 125/200, Iteration 216/250, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 217/250, Loss: 0.0064\n",
      "Epoch 125/200, Iteration 218/250, Loss: 0.0084\n",
      "Epoch 125/200, Iteration 219/250, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 220/250, Loss: 0.0159\n",
      "Epoch 125/200, Iteration 221/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 222/250, Loss: 0.0117\n",
      "Epoch 125/200, Iteration 223/250, Loss: 0.0119\n",
      "Epoch 125/200, Iteration 224/250, Loss: 0.0155\n",
      "Epoch 125/200, Iteration 225/250, Loss: 0.0098\n",
      "Epoch 125/200, Iteration 226/250, Loss: 0.0101\n",
      "Epoch 125/200, Iteration 227/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 228/250, Loss: 0.0165\n",
      "Epoch 125/200, Iteration 229/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 231/250, Loss: 0.0067\n",
      "Epoch 125/200, Iteration 232/250, Loss: 0.0142\n",
      "Epoch 125/200, Iteration 233/250, Loss: 0.0179\n",
      "Epoch 125/200, Iteration 234/250, Loss: 0.0173\n",
      "Epoch 125/200, Iteration 235/250, Loss: 0.0256\n",
      "Epoch 125/200, Iteration 236/250, Loss: 0.0205\n",
      "Epoch 125/200, Iteration 237/250, Loss: 0.0157\n",
      "Epoch 125/200, Iteration 238/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 239/250, Loss: 0.0113\n",
      "Epoch 125/200, Iteration 240/250, Loss: 0.0149\n",
      "Epoch 125/200, Iteration 241/250, Loss: 0.0186\n",
      "Epoch 125/200, Iteration 242/250, Loss: 0.0115\n",
      "Epoch 125/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 125/200, Iteration 244/250, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200, Iteration 245/250, Loss: 0.0084\n",
      "Epoch 125/200, Iteration 246/250, Loss: 0.0190\n",
      "Epoch 125/200, Iteration 247/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 248/250, Loss: 0.0117\n",
      "Epoch 125/200, Iteration 249/250, Loss: 0.0254\n",
      "Epoch 125/200, Iteration 250/250, Loss: 0.0243\n",
      "Train Error: \n",
      " Accuracy: 95.26%, Avg loss: 0.005887, MRE: 0.620904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.95%, Avg loss: 0.005931, MRE: 1.009734 \n",
      "\n",
      "Epoch 126/200, Iteration 1/250, Loss: 0.0124\n",
      "Epoch 126/200, Iteration 2/250, Loss: 0.0107\n",
      "Epoch 126/200, Iteration 3/250, Loss: 0.0140\n",
      "Epoch 126/200, Iteration 4/250, Loss: 0.0114\n",
      "Epoch 126/200, Iteration 5/250, Loss: 0.0156\n",
      "Epoch 126/200, Iteration 6/250, Loss: 0.0340\n",
      "Epoch 126/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 126/200, Iteration 8/250, Loss: 0.0065\n",
      "Epoch 126/200, Iteration 9/250, Loss: 0.0107\n",
      "Epoch 126/200, Iteration 10/250, Loss: 0.0175\n",
      "Epoch 126/200, Iteration 11/250, Loss: 0.0238\n",
      "Epoch 126/200, Iteration 12/250, Loss: 0.0182\n",
      "Epoch 126/200, Iteration 13/250, Loss: 0.0074\n",
      "Epoch 126/200, Iteration 14/250, Loss: 0.0256\n",
      "Epoch 126/200, Iteration 15/250, Loss: 0.0102\n",
      "Epoch 126/200, Iteration 16/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 17/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 18/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 19/250, Loss: 0.0145\n",
      "Epoch 126/200, Iteration 20/250, Loss: 0.0139\n",
      "Epoch 126/200, Iteration 21/250, Loss: 0.0151\n",
      "Epoch 126/200, Iteration 22/250, Loss: 0.0080\n",
      "Epoch 126/200, Iteration 23/250, Loss: 0.0066\n",
      "Epoch 126/200, Iteration 24/250, Loss: 0.0105\n",
      "Epoch 126/200, Iteration 25/250, Loss: 0.0175\n",
      "Epoch 126/200, Iteration 26/250, Loss: 0.0247\n",
      "Epoch 126/200, Iteration 27/250, Loss: 0.0162\n",
      "Epoch 126/200, Iteration 28/250, Loss: 0.0048\n",
      "Epoch 126/200, Iteration 29/250, Loss: 0.0168\n",
      "Epoch 126/200, Iteration 30/250, Loss: 0.0070\n",
      "Epoch 126/200, Iteration 31/250, Loss: 0.0122\n",
      "Epoch 126/200, Iteration 32/250, Loss: 0.0124\n",
      "Epoch 126/200, Iteration 33/250, Loss: 0.0160\n",
      "Epoch 126/200, Iteration 34/250, Loss: 0.0210\n",
      "Epoch 126/200, Iteration 35/250, Loss: 0.0200\n",
      "Epoch 126/200, Iteration 36/250, Loss: 0.0066\n",
      "Epoch 126/200, Iteration 37/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 38/250, Loss: 0.0123\n",
      "Epoch 126/200, Iteration 39/250, Loss: 0.0090\n",
      "Epoch 126/200, Iteration 40/250, Loss: 0.0208\n",
      "Epoch 126/200, Iteration 41/250, Loss: 0.0131\n",
      "Epoch 126/200, Iteration 42/250, Loss: 0.0060\n",
      "Epoch 126/200, Iteration 43/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 44/250, Loss: 0.0151\n",
      "Epoch 126/200, Iteration 45/250, Loss: 0.0100\n",
      "Epoch 126/200, Iteration 46/250, Loss: 0.0070\n",
      "Epoch 126/200, Iteration 47/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 48/250, Loss: 0.0125\n",
      "Epoch 126/200, Iteration 49/250, Loss: 0.0169\n",
      "Epoch 126/200, Iteration 50/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 126/200, Iteration 52/250, Loss: 0.0251\n",
      "Epoch 126/200, Iteration 53/250, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 54/250, Loss: 0.0224\n",
      "Epoch 126/200, Iteration 55/250, Loss: 0.0081\n",
      "Epoch 126/200, Iteration 56/250, Loss: 0.0235\n",
      "Epoch 126/200, Iteration 57/250, Loss: 0.0081\n",
      "Epoch 126/200, Iteration 58/250, Loss: 0.0129\n",
      "Epoch 126/200, Iteration 59/250, Loss: 0.0116\n",
      "Epoch 126/200, Iteration 60/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 61/250, Loss: 0.0176\n",
      "Epoch 126/200, Iteration 62/250, Loss: 0.0245\n",
      "Epoch 126/200, Iteration 63/250, Loss: 0.0193\n",
      "Epoch 126/200, Iteration 64/250, Loss: 0.0084\n",
      "Epoch 126/200, Iteration 65/250, Loss: 0.0094\n",
      "Epoch 126/200, Iteration 66/250, Loss: 0.0139\n",
      "Epoch 126/200, Iteration 67/250, Loss: 0.0063\n",
      "Epoch 126/200, Iteration 68/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 69/250, Loss: 0.0237\n",
      "Epoch 126/200, Iteration 70/250, Loss: 0.0160\n",
      "Epoch 126/200, Iteration 71/250, Loss: 0.0124\n",
      "Epoch 126/200, Iteration 72/250, Loss: 0.0063\n",
      "Epoch 126/200, Iteration 73/250, Loss: 0.0130\n",
      "Epoch 126/200, Iteration 74/250, Loss: 0.0128\n",
      "Epoch 126/200, Iteration 75/250, Loss: 0.0164\n",
      "Epoch 126/200, Iteration 76/250, Loss: 0.0209\n",
      "Epoch 126/200, Iteration 77/250, Loss: 0.0180\n",
      "Epoch 126/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 126/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 80/250, Loss: 0.0068\n",
      "Epoch 126/200, Iteration 81/250, Loss: 0.0113\n",
      "Epoch 126/200, Iteration 82/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 83/250, Loss: 0.0091\n",
      "Epoch 126/200, Iteration 84/250, Loss: 0.0184\n",
      "Epoch 126/200, Iteration 85/250, Loss: 0.0136\n",
      "Epoch 126/200, Iteration 86/250, Loss: 0.0086\n",
      "Epoch 126/200, Iteration 87/250, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 88/250, Loss: 0.0126\n",
      "Epoch 126/200, Iteration 89/250, Loss: 0.0287\n",
      "Epoch 126/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 126/200, Iteration 91/250, Loss: 0.0116\n",
      "Epoch 126/200, Iteration 92/250, Loss: 0.0169\n",
      "Epoch 126/200, Iteration 93/250, Loss: 0.0232\n",
      "Epoch 126/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 95/250, Loss: 0.0144\n",
      "Epoch 126/200, Iteration 96/250, Loss: 0.0146\n",
      "Epoch 126/200, Iteration 97/250, Loss: 0.0138\n",
      "Epoch 126/200, Iteration 98/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 99/250, Loss: 0.0245\n",
      "Epoch 126/200, Iteration 100/250, Loss: 0.0340\n",
      "Epoch 126/200, Iteration 101/250, Loss: 0.0402\n",
      "Epoch 126/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 103/250, Loss: 0.0173\n",
      "Epoch 126/200, Iteration 104/250, Loss: 0.0154\n",
      "Epoch 126/200, Iteration 105/250, Loss: 0.0126\n",
      "Epoch 126/200, Iteration 106/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 107/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 126/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 126/200, Iteration 110/250, Loss: 0.0078\n",
      "Epoch 126/200, Iteration 111/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 112/250, Loss: 0.0128\n",
      "Epoch 126/200, Iteration 113/250, Loss: 0.0205\n",
      "Epoch 126/200, Iteration 114/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 115/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 116/250, Loss: 0.0108\n",
      "Epoch 126/200, Iteration 117/250, Loss: 0.0080\n",
      "Epoch 126/200, Iteration 118/250, Loss: 0.0258\n",
      "Epoch 126/200, Iteration 119/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 120/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 121/250, Loss: 0.0242\n",
      "Epoch 126/200, Iteration 122/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 123/250, Loss: 0.0393\n",
      "Epoch 126/200, Iteration 124/250, Loss: 0.0285\n",
      "Epoch 126/200, Iteration 125/250, Loss: 0.0091\n",
      "Epoch 126/200, Iteration 126/250, Loss: 0.0235\n",
      "Epoch 126/200, Iteration 127/250, Loss: 0.0263\n",
      "Epoch 126/200, Iteration 128/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 129/250, Loss: 0.0192\n",
      "Epoch 126/200, Iteration 130/250, Loss: 0.0134\n",
      "Epoch 126/200, Iteration 131/250, Loss: 0.0090\n",
      "Epoch 126/200, Iteration 132/250, Loss: 0.0193\n",
      "Epoch 126/200, Iteration 133/250, Loss: 0.0156\n",
      "Epoch 126/200, Iteration 134/250, Loss: 0.0069\n",
      "Epoch 126/200, Iteration 135/250, Loss: 0.0368\n",
      "Epoch 126/200, Iteration 136/250, Loss: 0.0103\n",
      "Epoch 126/200, Iteration 137/250, Loss: 0.0145\n",
      "Epoch 126/200, Iteration 138/250, Loss: 0.0328\n",
      "Epoch 126/200, Iteration 139/250, Loss: 0.0188\n",
      "Epoch 126/200, Iteration 140/250, Loss: 0.0095\n",
      "Epoch 126/200, Iteration 141/250, Loss: 0.0154\n",
      "Epoch 126/200, Iteration 142/250, Loss: 0.0058\n",
      "Epoch 126/200, Iteration 143/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 144/250, Loss: 0.0312\n",
      "Epoch 126/200, Iteration 145/250, Loss: 0.0183\n",
      "Epoch 126/200, Iteration 146/250, Loss: 0.0136\n",
      "Epoch 126/200, Iteration 147/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 148/250, Loss: 0.0129\n",
      "Epoch 126/200, Iteration 149/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 150/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 151/250, Loss: 0.0343\n",
      "Epoch 126/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 126/200, Iteration 153/250, Loss: 0.0115\n",
      "Epoch 126/200, Iteration 154/250, Loss: 0.0309\n",
      "Epoch 126/200, Iteration 155/250, Loss: 0.0090\n",
      "Epoch 126/200, Iteration 156/250, Loss: 0.0297\n",
      "Epoch 126/200, Iteration 157/250, Loss: 0.0242\n",
      "Epoch 126/200, Iteration 158/250, Loss: 0.0249\n",
      "Epoch 126/200, Iteration 159/250, Loss: 0.0192\n",
      "Epoch 126/200, Iteration 160/250, Loss: 0.0133\n",
      "Epoch 126/200, Iteration 161/250, Loss: 0.0132\n",
      "Epoch 126/200, Iteration 162/250, Loss: 0.0232\n",
      "Epoch 126/200, Iteration 163/250, Loss: 0.0172\n",
      "Epoch 126/200, Iteration 164/250, Loss: 0.0079\n",
      "Epoch 126/200, Iteration 165/250, Loss: 0.0206\n",
      "Epoch 126/200, Iteration 166/250, Loss: 0.0119\n",
      "Epoch 126/200, Iteration 167/250, Loss: 0.0129\n",
      "Epoch 126/200, Iteration 168/250, Loss: 0.0289\n",
      "Epoch 126/200, Iteration 169/250, Loss: 0.0079\n",
      "Epoch 126/200, Iteration 170/250, Loss: 0.0236\n",
      "Epoch 126/200, Iteration 171/250, Loss: 0.0073\n",
      "Epoch 126/200, Iteration 172/250, Loss: 0.0071\n",
      "Epoch 126/200, Iteration 173/250, Loss: 0.0143\n",
      "Epoch 126/200, Iteration 174/250, Loss: 0.0113\n",
      "Epoch 126/200, Iteration 175/250, Loss: 0.0159\n",
      "Epoch 126/200, Iteration 176/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 177/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 178/250, Loss: 0.0179\n",
      "Epoch 126/200, Iteration 179/250, Loss: 0.0091\n",
      "Epoch 126/200, Iteration 180/250, Loss: 0.0193\n",
      "Epoch 126/200, Iteration 181/250, Loss: 0.0318\n",
      "Epoch 126/200, Iteration 182/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 183/250, Loss: 0.0267\n",
      "Epoch 126/200, Iteration 184/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 185/250, Loss: 0.0157\n",
      "Epoch 126/200, Iteration 186/250, Loss: 0.0123\n",
      "Epoch 126/200, Iteration 187/250, Loss: 0.0188\n",
      "Epoch 126/200, Iteration 188/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 189/250, Loss: 0.0241\n",
      "Epoch 126/200, Iteration 190/250, Loss: 0.0248\n",
      "Epoch 126/200, Iteration 191/250, Loss: 0.0140\n",
      "Epoch 126/200, Iteration 192/250, Loss: 0.0159\n",
      "Epoch 126/200, Iteration 193/250, Loss: 0.0218\n",
      "Epoch 126/200, Iteration 194/250, Loss: 0.0188\n",
      "Epoch 126/200, Iteration 195/250, Loss: 0.0179\n",
      "Epoch 126/200, Iteration 196/250, Loss: 0.0095\n",
      "Epoch 126/200, Iteration 197/250, Loss: 0.0252\n",
      "Epoch 126/200, Iteration 198/250, Loss: 0.0122\n",
      "Epoch 126/200, Iteration 199/250, Loss: 0.0216\n",
      "Epoch 126/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 201/250, Loss: 0.0204\n",
      "Epoch 126/200, Iteration 202/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 203/250, Loss: 0.0382\n",
      "Epoch 126/200, Iteration 204/250, Loss: 0.0155\n",
      "Epoch 126/200, Iteration 205/250, Loss: 0.0161\n",
      "Epoch 126/200, Iteration 206/250, Loss: 0.0122\n",
      "Epoch 126/200, Iteration 207/250, Loss: 0.0137\n",
      "Epoch 126/200, Iteration 208/250, Loss: 0.0346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200, Iteration 209/250, Loss: 0.0115\n",
      "Epoch 126/200, Iteration 210/250, Loss: 0.0255\n",
      "Epoch 126/200, Iteration 211/250, Loss: 0.0124\n",
      "Epoch 126/200, Iteration 212/250, Loss: 0.0132\n",
      "Epoch 126/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 126/200, Iteration 214/250, Loss: 0.0179\n",
      "Epoch 126/200, Iteration 215/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 216/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 217/250, Loss: 0.0167\n",
      "Epoch 126/200, Iteration 218/250, Loss: 0.0210\n",
      "Epoch 126/200, Iteration 219/250, Loss: 0.0148\n",
      "Epoch 126/200, Iteration 220/250, Loss: 0.0175\n",
      "Epoch 126/200, Iteration 221/250, Loss: 0.0134\n",
      "Epoch 126/200, Iteration 222/250, Loss: 0.0169\n",
      "Epoch 126/200, Iteration 223/250, Loss: 0.0137\n",
      "Epoch 126/200, Iteration 224/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 225/250, Loss: 0.0133\n",
      "Epoch 126/200, Iteration 226/250, Loss: 0.0182\n",
      "Epoch 126/200, Iteration 227/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 228/250, Loss: 0.0088\n",
      "Epoch 126/200, Iteration 229/250, Loss: 0.0122\n",
      "Epoch 126/200, Iteration 230/250, Loss: 0.0086\n",
      "Epoch 126/200, Iteration 231/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 232/250, Loss: 0.0095\n",
      "Epoch 126/200, Iteration 233/250, Loss: 0.0120\n",
      "Epoch 126/200, Iteration 234/250, Loss: 0.0196\n",
      "Epoch 126/200, Iteration 235/250, Loss: 0.0114\n",
      "Epoch 126/200, Iteration 236/250, Loss: 0.0095\n",
      "Epoch 126/200, Iteration 237/250, Loss: 0.0340\n",
      "Epoch 126/200, Iteration 238/250, Loss: 0.0062\n",
      "Epoch 126/200, Iteration 239/250, Loss: 0.0176\n",
      "Epoch 126/200, Iteration 240/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 241/250, Loss: 0.0197\n",
      "Epoch 126/200, Iteration 242/250, Loss: 0.0144\n",
      "Epoch 126/200, Iteration 243/250, Loss: 0.0095\n",
      "Epoch 126/200, Iteration 244/250, Loss: 0.0127\n",
      "Epoch 126/200, Iteration 245/250, Loss: 0.0180\n",
      "Epoch 126/200, Iteration 246/250, Loss: 0.0181\n",
      "Epoch 126/200, Iteration 247/250, Loss: 0.0122\n",
      "Epoch 126/200, Iteration 248/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 249/250, Loss: 0.0107\n",
      "Epoch 126/200, Iteration 250/250, Loss: 0.0389\n",
      "Train Error: \n",
      " Accuracy: 90.12%, Avg loss: 0.006141, MRE: 0.630544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.35%, Avg loss: 0.006176, MRE: 0.965175 \n",
      "\n",
      "Epoch 127/200, Iteration 1/250, Loss: 0.0145\n",
      "Epoch 127/200, Iteration 2/250, Loss: 0.0075\n",
      "Epoch 127/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 127/200, Iteration 4/250, Loss: 0.0187\n",
      "Epoch 127/200, Iteration 5/250, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 6/250, Loss: 0.0220\n",
      "Epoch 127/200, Iteration 7/250, Loss: 0.0110\n",
      "Epoch 127/200, Iteration 8/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 9/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 10/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 11/250, Loss: 0.0235\n",
      "Epoch 127/200, Iteration 12/250, Loss: 0.0119\n",
      "Epoch 127/200, Iteration 13/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 14/250, Loss: 0.0112\n",
      "Epoch 127/200, Iteration 15/250, Loss: 0.0162\n",
      "Epoch 127/200, Iteration 16/250, Loss: 0.0191\n",
      "Epoch 127/200, Iteration 17/250, Loss: 0.0222\n",
      "Epoch 127/200, Iteration 18/250, Loss: 0.0197\n",
      "Epoch 127/200, Iteration 19/250, Loss: 0.0182\n",
      "Epoch 127/200, Iteration 20/250, Loss: 0.0285\n",
      "Epoch 127/200, Iteration 21/250, Loss: 0.0084\n",
      "Epoch 127/200, Iteration 22/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 23/250, Loss: 0.0168\n",
      "Epoch 127/200, Iteration 24/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 25/250, Loss: 0.0074\n",
      "Epoch 127/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 27/250, Loss: 0.0103\n",
      "Epoch 127/200, Iteration 28/250, Loss: 0.0126\n",
      "Epoch 127/200, Iteration 29/250, Loss: 0.0215\n",
      "Epoch 127/200, Iteration 30/250, Loss: 0.0186\n",
      "Epoch 127/200, Iteration 31/250, Loss: 0.0160\n",
      "Epoch 127/200, Iteration 32/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 33/250, Loss: 0.0073\n",
      "Epoch 127/200, Iteration 34/250, Loss: 0.0094\n",
      "Epoch 127/200, Iteration 35/250, Loss: 0.0097\n",
      "Epoch 127/200, Iteration 36/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 37/250, Loss: 0.0083\n",
      "Epoch 127/200, Iteration 38/250, Loss: 0.0125\n",
      "Epoch 127/200, Iteration 39/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 40/250, Loss: 0.0233\n",
      "Epoch 127/200, Iteration 41/250, Loss: 0.0054\n",
      "Epoch 127/200, Iteration 42/250, Loss: 0.0070\n",
      "Epoch 127/200, Iteration 43/250, Loss: 0.0162\n",
      "Epoch 127/200, Iteration 44/250, Loss: 0.0069\n",
      "Epoch 127/200, Iteration 45/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 46/250, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 47/250, Loss: 0.0309\n",
      "Epoch 127/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 127/200, Iteration 49/250, Loss: 0.0094\n",
      "Epoch 127/200, Iteration 50/250, Loss: 0.0220\n",
      "Epoch 127/200, Iteration 51/250, Loss: 0.0181\n",
      "Epoch 127/200, Iteration 52/250, Loss: 0.0102\n",
      "Epoch 127/200, Iteration 53/250, Loss: 0.0212\n",
      "Epoch 127/200, Iteration 54/250, Loss: 0.0248\n",
      "Epoch 127/200, Iteration 55/250, Loss: 0.0059\n",
      "Epoch 127/200, Iteration 56/250, Loss: 0.0136\n",
      "Epoch 127/200, Iteration 57/250, Loss: 0.0189\n",
      "Epoch 127/200, Iteration 58/250, Loss: 0.0110\n",
      "Epoch 127/200, Iteration 59/250, Loss: 0.0159\n",
      "Epoch 127/200, Iteration 60/250, Loss: 0.0285\n",
      "Epoch 127/200, Iteration 61/250, Loss: 0.0087\n",
      "Epoch 127/200, Iteration 62/250, Loss: 0.0157\n",
      "Epoch 127/200, Iteration 63/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 64/250, Loss: 0.0236\n",
      "Epoch 127/200, Iteration 65/250, Loss: 0.0093\n",
      "Epoch 127/200, Iteration 66/250, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 67/250, Loss: 0.0240\n",
      "Epoch 127/200, Iteration 68/250, Loss: 0.0158\n",
      "Epoch 127/200, Iteration 69/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 70/250, Loss: 0.0083\n",
      "Epoch 127/200, Iteration 71/250, Loss: 0.0103\n",
      "Epoch 127/200, Iteration 72/250, Loss: 0.0063\n",
      "Epoch 127/200, Iteration 73/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 127/200, Iteration 75/250, Loss: 0.0145\n",
      "Epoch 127/200, Iteration 76/250, Loss: 0.0193\n",
      "Epoch 127/200, Iteration 77/250, Loss: 0.0225\n",
      "Epoch 127/200, Iteration 78/250, Loss: 0.0076\n",
      "Epoch 127/200, Iteration 79/250, Loss: 0.0200\n",
      "Epoch 127/200, Iteration 80/250, Loss: 0.0059\n",
      "Epoch 127/200, Iteration 81/250, Loss: 0.0137\n",
      "Epoch 127/200, Iteration 82/250, Loss: 0.0086\n",
      "Epoch 127/200, Iteration 83/250, Loss: 0.0158\n",
      "Epoch 127/200, Iteration 84/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 86/250, Loss: 0.0157\n",
      "Epoch 127/200, Iteration 87/250, Loss: 0.0168\n",
      "Epoch 127/200, Iteration 88/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 89/250, Loss: 0.0378\n",
      "Epoch 127/200, Iteration 90/250, Loss: 0.0132\n",
      "Epoch 127/200, Iteration 91/250, Loss: 0.0094\n",
      "Epoch 127/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 127/200, Iteration 93/250, Loss: 0.0157\n",
      "Epoch 127/200, Iteration 94/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 95/250, Loss: 0.0065\n",
      "Epoch 127/200, Iteration 96/250, Loss: 0.0088\n",
      "Epoch 127/200, Iteration 97/250, Loss: 0.0328\n",
      "Epoch 127/200, Iteration 98/250, Loss: 0.0140\n",
      "Epoch 127/200, Iteration 99/250, Loss: 0.0155\n",
      "Epoch 127/200, Iteration 100/250, Loss: 0.0138\n",
      "Epoch 127/200, Iteration 101/250, Loss: 0.0346\n",
      "Epoch 127/200, Iteration 102/250, Loss: 0.0094\n",
      "Epoch 127/200, Iteration 103/250, Loss: 0.0267\n",
      "Epoch 127/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 105/250, Loss: 0.0131\n",
      "Epoch 127/200, Iteration 106/250, Loss: 0.0184\n",
      "Epoch 127/200, Iteration 107/250, Loss: 0.0179\n",
      "Epoch 127/200, Iteration 108/250, Loss: 0.0198\n",
      "Epoch 127/200, Iteration 109/250, Loss: 0.0132\n",
      "Epoch 127/200, Iteration 110/250, Loss: 0.0100\n",
      "Epoch 127/200, Iteration 111/250, Loss: 0.0076\n",
      "Epoch 127/200, Iteration 112/250, Loss: 0.0178\n",
      "Epoch 127/200, Iteration 113/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 114/250, Loss: 0.0084\n",
      "Epoch 127/200, Iteration 115/250, Loss: 0.0199\n",
      "Epoch 127/200, Iteration 116/250, Loss: 0.0117\n",
      "Epoch 127/200, Iteration 117/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 118/250, Loss: 0.0232\n",
      "Epoch 127/200, Iteration 119/250, Loss: 0.0075\n",
      "Epoch 127/200, Iteration 120/250, Loss: 0.0075\n",
      "Epoch 127/200, Iteration 121/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 122/250, Loss: 0.0158\n",
      "Epoch 127/200, Iteration 123/250, Loss: 0.0161\n",
      "Epoch 127/200, Iteration 124/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 125/250, Loss: 0.0158\n",
      "Epoch 127/200, Iteration 126/250, Loss: 0.0170\n",
      "Epoch 127/200, Iteration 127/250, Loss: 0.0164\n",
      "Epoch 127/200, Iteration 128/250, Loss: 0.0120\n",
      "Epoch 127/200, Iteration 129/250, Loss: 0.0071\n",
      "Epoch 127/200, Iteration 130/250, Loss: 0.0255\n",
      "Epoch 127/200, Iteration 131/250, Loss: 0.0180\n",
      "Epoch 127/200, Iteration 132/250, Loss: 0.0170\n",
      "Epoch 127/200, Iteration 133/250, Loss: 0.0125\n",
      "Epoch 127/200, Iteration 134/250, Loss: 0.0068\n",
      "Epoch 127/200, Iteration 135/250, Loss: 0.0176\n",
      "Epoch 127/200, Iteration 136/250, Loss: 0.0091\n",
      "Epoch 127/200, Iteration 137/250, Loss: 0.0152\n",
      "Epoch 127/200, Iteration 138/250, Loss: 0.0069\n",
      "Epoch 127/200, Iteration 139/250, Loss: 0.0073\n",
      "Epoch 127/200, Iteration 140/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 141/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 142/250, Loss: 0.0071\n",
      "Epoch 127/200, Iteration 143/250, Loss: 0.0099\n",
      "Epoch 127/200, Iteration 144/250, Loss: 0.0080\n",
      "Epoch 127/200, Iteration 145/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 146/250, Loss: 0.0200\n",
      "Epoch 127/200, Iteration 147/250, Loss: 0.0217\n",
      "Epoch 127/200, Iteration 148/250, Loss: 0.0152\n",
      "Epoch 127/200, Iteration 149/250, Loss: 0.0202\n",
      "Epoch 127/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 127/200, Iteration 151/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 152/250, Loss: 0.0145\n",
      "Epoch 127/200, Iteration 153/250, Loss: 0.0102\n",
      "Epoch 127/200, Iteration 154/250, Loss: 0.0148\n",
      "Epoch 127/200, Iteration 155/250, Loss: 0.0149\n",
      "Epoch 127/200, Iteration 156/250, Loss: 0.0213\n",
      "Epoch 127/200, Iteration 157/250, Loss: 0.0180\n",
      "Epoch 127/200, Iteration 158/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 159/250, Loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200, Iteration 160/250, Loss: 0.0341\n",
      "Epoch 127/200, Iteration 161/250, Loss: 0.0152\n",
      "Epoch 127/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 163/250, Loss: 0.0204\n",
      "Epoch 127/200, Iteration 164/250, Loss: 0.0124\n",
      "Epoch 127/200, Iteration 165/250, Loss: 0.0052\n",
      "Epoch 127/200, Iteration 166/250, Loss: 0.0238\n",
      "Epoch 127/200, Iteration 167/250, Loss: 0.0084\n",
      "Epoch 127/200, Iteration 168/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 169/250, Loss: 0.0202\n",
      "Epoch 127/200, Iteration 170/250, Loss: 0.0194\n",
      "Epoch 127/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 127/200, Iteration 172/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 173/250, Loss: 0.0173\n",
      "Epoch 127/200, Iteration 174/250, Loss: 0.0240\n",
      "Epoch 127/200, Iteration 175/250, Loss: 0.0174\n",
      "Epoch 127/200, Iteration 176/250, Loss: 0.0139\n",
      "Epoch 127/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 178/250, Loss: 0.0129\n",
      "Epoch 127/200, Iteration 179/250, Loss: 0.0050\n",
      "Epoch 127/200, Iteration 180/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 181/250, Loss: 0.0138\n",
      "Epoch 127/200, Iteration 182/250, Loss: 0.0151\n",
      "Epoch 127/200, Iteration 183/250, Loss: 0.0074\n",
      "Epoch 127/200, Iteration 184/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 185/250, Loss: 0.0068\n",
      "Epoch 127/200, Iteration 186/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 187/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 188/250, Loss: 0.0068\n",
      "Epoch 127/200, Iteration 189/250, Loss: 0.0315\n",
      "Epoch 127/200, Iteration 190/250, Loss: 0.0149\n",
      "Epoch 127/200, Iteration 191/250, Loss: 0.0135\n",
      "Epoch 127/200, Iteration 192/250, Loss: 0.0104\n",
      "Epoch 127/200, Iteration 193/250, Loss: 0.0173\n",
      "Epoch 127/200, Iteration 194/250, Loss: 0.0215\n",
      "Epoch 127/200, Iteration 195/250, Loss: 0.0078\n",
      "Epoch 127/200, Iteration 196/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 197/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 127/200, Iteration 199/250, Loss: 0.0173\n",
      "Epoch 127/200, Iteration 200/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 201/250, Loss: 0.0112\n",
      "Epoch 127/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 127/200, Iteration 203/250, Loss: 0.0202\n",
      "Epoch 127/200, Iteration 204/250, Loss: 0.0131\n",
      "Epoch 127/200, Iteration 205/250, Loss: 0.0112\n",
      "Epoch 127/200, Iteration 206/250, Loss: 0.0189\n",
      "Epoch 127/200, Iteration 207/250, Loss: 0.0134\n",
      "Epoch 127/200, Iteration 208/250, Loss: 0.0088\n",
      "Epoch 127/200, Iteration 209/250, Loss: 0.0071\n",
      "Epoch 127/200, Iteration 210/250, Loss: 0.0100\n",
      "Epoch 127/200, Iteration 211/250, Loss: 0.0095\n",
      "Epoch 127/200, Iteration 212/250, Loss: 0.0120\n",
      "Epoch 127/200, Iteration 213/250, Loss: 0.0081\n",
      "Epoch 127/200, Iteration 214/250, Loss: 0.0157\n",
      "Epoch 127/200, Iteration 215/250, Loss: 0.0306\n",
      "Epoch 127/200, Iteration 216/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 217/250, Loss: 0.0074\n",
      "Epoch 127/200, Iteration 218/250, Loss: 0.0143\n",
      "Epoch 127/200, Iteration 219/250, Loss: 0.0140\n",
      "Epoch 127/200, Iteration 220/250, Loss: 0.0226\n",
      "Epoch 127/200, Iteration 221/250, Loss: 0.0233\n",
      "Epoch 127/200, Iteration 222/250, Loss: 0.0091\n",
      "Epoch 127/200, Iteration 223/250, Loss: 0.0236\n",
      "Epoch 127/200, Iteration 224/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 225/250, Loss: 0.0076\n",
      "Epoch 127/200, Iteration 226/250, Loss: 0.0099\n",
      "Epoch 127/200, Iteration 227/250, Loss: 0.0129\n",
      "Epoch 127/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 127/200, Iteration 229/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 230/250, Loss: 0.0152\n",
      "Epoch 127/200, Iteration 231/250, Loss: 0.0173\n",
      "Epoch 127/200, Iteration 232/250, Loss: 0.0241\n",
      "Epoch 127/200, Iteration 233/250, Loss: 0.0095\n",
      "Epoch 127/200, Iteration 234/250, Loss: 0.0057\n",
      "Epoch 127/200, Iteration 235/250, Loss: 0.0210\n",
      "Epoch 127/200, Iteration 236/250, Loss: 0.0125\n",
      "Epoch 127/200, Iteration 237/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 238/250, Loss: 0.0089\n",
      "Epoch 127/200, Iteration 239/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 240/250, Loss: 0.0254\n",
      "Epoch 127/200, Iteration 241/250, Loss: 0.0078\n",
      "Epoch 127/200, Iteration 242/250, Loss: 0.0137\n",
      "Epoch 127/200, Iteration 243/250, Loss: 0.0082\n",
      "Epoch 127/200, Iteration 244/250, Loss: 0.0123\n",
      "Epoch 127/200, Iteration 245/250, Loss: 0.0335\n",
      "Epoch 127/200, Iteration 246/250, Loss: 0.0261\n",
      "Epoch 127/200, Iteration 247/250, Loss: 0.0160\n",
      "Epoch 127/200, Iteration 248/250, Loss: 0.0191\n",
      "Epoch 127/200, Iteration 249/250, Loss: 0.0242\n",
      "Epoch 127/200, Iteration 250/250, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 86.64%, Avg loss: 0.006414, MRE: 0.627184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.55%, Avg loss: 0.006481, MRE: 0.930224 \n",
      "\n",
      "Epoch 128/200, Iteration 1/250, Loss: 0.0106\n",
      "Epoch 128/200, Iteration 2/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 3/250, Loss: 0.0235\n",
      "Epoch 128/200, Iteration 4/250, Loss: 0.0259\n",
      "Epoch 128/200, Iteration 5/250, Loss: 0.0162\n",
      "Epoch 128/200, Iteration 6/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 7/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 8/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 9/250, Loss: 0.0194\n",
      "Epoch 128/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 128/200, Iteration 11/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 12/250, Loss: 0.0329\n",
      "Epoch 128/200, Iteration 13/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 14/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 128/200, Iteration 16/250, Loss: 0.0060\n",
      "Epoch 128/200, Iteration 17/250, Loss: 0.0089\n",
      "Epoch 128/200, Iteration 18/250, Loss: 0.0149\n",
      "Epoch 128/200, Iteration 19/250, Loss: 0.0158\n",
      "Epoch 128/200, Iteration 20/250, Loss: 0.0169\n",
      "Epoch 128/200, Iteration 21/250, Loss: 0.0274\n",
      "Epoch 128/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 128/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 24/250, Loss: 0.0111\n",
      "Epoch 128/200, Iteration 25/250, Loss: 0.0080\n",
      "Epoch 128/200, Iteration 26/250, Loss: 0.0113\n",
      "Epoch 128/200, Iteration 27/250, Loss: 0.0177\n",
      "Epoch 128/200, Iteration 28/250, Loss: 0.0207\n",
      "Epoch 128/200, Iteration 29/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 30/250, Loss: 0.0248\n",
      "Epoch 128/200, Iteration 31/250, Loss: 0.0302\n",
      "Epoch 128/200, Iteration 32/250, Loss: 0.0131\n",
      "Epoch 128/200, Iteration 33/250, Loss: 0.0159\n",
      "Epoch 128/200, Iteration 34/250, Loss: 0.0083\n",
      "Epoch 128/200, Iteration 35/250, Loss: 0.0152\n",
      "Epoch 128/200, Iteration 36/250, Loss: 0.0109\n",
      "Epoch 128/200, Iteration 37/250, Loss: 0.0127\n",
      "Epoch 128/200, Iteration 38/250, Loss: 0.0138\n",
      "Epoch 128/200, Iteration 39/250, Loss: 0.0196\n",
      "Epoch 128/200, Iteration 40/250, Loss: 0.0165\n",
      "Epoch 128/200, Iteration 41/250, Loss: 0.0167\n",
      "Epoch 128/200, Iteration 42/250, Loss: 0.0107\n",
      "Epoch 128/200, Iteration 43/250, Loss: 0.0134\n",
      "Epoch 128/200, Iteration 44/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 45/250, Loss: 0.0316\n",
      "Epoch 128/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 47/250, Loss: 0.0127\n",
      "Epoch 128/200, Iteration 48/250, Loss: 0.0207\n",
      "Epoch 128/200, Iteration 49/250, Loss: 0.0158\n",
      "Epoch 128/200, Iteration 50/250, Loss: 0.0129\n",
      "Epoch 128/200, Iteration 51/250, Loss: 0.0152\n",
      "Epoch 128/200, Iteration 52/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 128/200, Iteration 54/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 55/250, Loss: 0.0080\n",
      "Epoch 128/200, Iteration 56/250, Loss: 0.0085\n",
      "Epoch 128/200, Iteration 57/250, Loss: 0.0294\n",
      "Epoch 128/200, Iteration 58/250, Loss: 0.0482\n",
      "Epoch 128/200, Iteration 59/250, Loss: 0.0184\n",
      "Epoch 128/200, Iteration 60/250, Loss: 0.0133\n",
      "Epoch 128/200, Iteration 61/250, Loss: 0.0096\n",
      "Epoch 128/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 128/200, Iteration 63/250, Loss: 0.0089\n",
      "Epoch 128/200, Iteration 64/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 65/250, Loss: 0.0128\n",
      "Epoch 128/200, Iteration 66/250, Loss: 0.0142\n",
      "Epoch 128/200, Iteration 67/250, Loss: 0.0255\n",
      "Epoch 128/200, Iteration 68/250, Loss: 0.0221\n",
      "Epoch 128/200, Iteration 69/250, Loss: 0.0129\n",
      "Epoch 128/200, Iteration 70/250, Loss: 0.0248\n",
      "Epoch 128/200, Iteration 71/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 72/250, Loss: 0.0084\n",
      "Epoch 128/200, Iteration 73/250, Loss: 0.0186\n",
      "Epoch 128/200, Iteration 74/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 75/250, Loss: 0.0069\n",
      "Epoch 128/200, Iteration 76/250, Loss: 0.0124\n",
      "Epoch 128/200, Iteration 77/250, Loss: 0.0072\n",
      "Epoch 128/200, Iteration 78/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 79/250, Loss: 0.0225\n",
      "Epoch 128/200, Iteration 80/250, Loss: 0.0110\n",
      "Epoch 128/200, Iteration 81/250, Loss: 0.0079\n",
      "Epoch 128/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 128/200, Iteration 83/250, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 84/250, Loss: 0.0175\n",
      "Epoch 128/200, Iteration 85/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 86/250, Loss: 0.0109\n",
      "Epoch 128/200, Iteration 87/250, Loss: 0.0162\n",
      "Epoch 128/200, Iteration 88/250, Loss: 0.0079\n",
      "Epoch 128/200, Iteration 89/250, Loss: 0.0076\n",
      "Epoch 128/200, Iteration 90/250, Loss: 0.0141\n",
      "Epoch 128/200, Iteration 91/250, Loss: 0.0221\n",
      "Epoch 128/200, Iteration 92/250, Loss: 0.0229\n",
      "Epoch 128/200, Iteration 93/250, Loss: 0.0370\n",
      "Epoch 128/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 95/250, Loss: 0.0137\n",
      "Epoch 128/200, Iteration 96/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 97/250, Loss: 0.0070\n",
      "Epoch 128/200, Iteration 98/250, Loss: 0.0166\n",
      "Epoch 128/200, Iteration 99/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 100/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 101/250, Loss: 0.0239\n",
      "Epoch 128/200, Iteration 102/250, Loss: 0.0150\n",
      "Epoch 128/200, Iteration 103/250, Loss: 0.0273\n",
      "Epoch 128/200, Iteration 104/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 105/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 106/250, Loss: 0.0068\n",
      "Epoch 128/200, Iteration 107/250, Loss: 0.0098\n",
      "Epoch 128/200, Iteration 108/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 109/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 110/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 111/250, Loss: 0.0306\n",
      "Epoch 128/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 128/200, Iteration 114/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 115/250, Loss: 0.0208\n",
      "Epoch 128/200, Iteration 116/250, Loss: 0.0551\n",
      "Epoch 128/200, Iteration 117/250, Loss: 0.0217\n",
      "Epoch 128/200, Iteration 118/250, Loss: 0.0075\n",
      "Epoch 128/200, Iteration 119/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 120/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 121/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 122/250, Loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200, Iteration 123/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 124/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 125/250, Loss: 0.0184\n",
      "Epoch 128/200, Iteration 126/250, Loss: 0.0076\n",
      "Epoch 128/200, Iteration 127/250, Loss: 0.0145\n",
      "Epoch 128/200, Iteration 128/250, Loss: 0.0190\n",
      "Epoch 128/200, Iteration 129/250, Loss: 0.0073\n",
      "Epoch 128/200, Iteration 130/250, Loss: 0.0140\n",
      "Epoch 128/200, Iteration 131/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 132/250, Loss: 0.0134\n",
      "Epoch 128/200, Iteration 133/250, Loss: 0.0320\n",
      "Epoch 128/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 135/250, Loss: 0.0180\n",
      "Epoch 128/200, Iteration 136/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 137/250, Loss: 0.0078\n",
      "Epoch 128/200, Iteration 138/250, Loss: 0.0240\n",
      "Epoch 128/200, Iteration 139/250, Loss: 0.0444\n",
      "Epoch 128/200, Iteration 140/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 141/250, Loss: 0.0123\n",
      "Epoch 128/200, Iteration 142/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 143/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 144/250, Loss: 0.0132\n",
      "Epoch 128/200, Iteration 145/250, Loss: 0.0120\n",
      "Epoch 128/200, Iteration 146/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 147/250, Loss: 0.0338\n",
      "Epoch 128/200, Iteration 148/250, Loss: 0.0196\n",
      "Epoch 128/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 128/200, Iteration 150/250, Loss: 0.0226\n",
      "Epoch 128/200, Iteration 151/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 152/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 153/250, Loss: 0.0110\n",
      "Epoch 128/200, Iteration 154/250, Loss: 0.0066\n",
      "Epoch 128/200, Iteration 155/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 156/250, Loss: 0.0106\n",
      "Epoch 128/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 128/200, Iteration 159/250, Loss: 0.0123\n",
      "Epoch 128/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 161/250, Loss: 0.0067\n",
      "Epoch 128/200, Iteration 162/250, Loss: 0.0084\n",
      "Epoch 128/200, Iteration 163/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 164/250, Loss: 0.0316\n",
      "Epoch 128/200, Iteration 165/250, Loss: 0.0071\n",
      "Epoch 128/200, Iteration 166/250, Loss: 0.0100\n",
      "Epoch 128/200, Iteration 167/250, Loss: 0.0300\n",
      "Epoch 128/200, Iteration 168/250, Loss: 0.0206\n",
      "Epoch 128/200, Iteration 169/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 170/250, Loss: 0.0186\n",
      "Epoch 128/200, Iteration 171/250, Loss: 0.0194\n",
      "Epoch 128/200, Iteration 172/250, Loss: 0.0080\n",
      "Epoch 128/200, Iteration 173/250, Loss: 0.0179\n",
      "Epoch 128/200, Iteration 174/250, Loss: 0.0147\n",
      "Epoch 128/200, Iteration 175/250, Loss: 0.0185\n",
      "Epoch 128/200, Iteration 176/250, Loss: 0.0208\n",
      "Epoch 128/200, Iteration 177/250, Loss: 0.0114\n",
      "Epoch 128/200, Iteration 178/250, Loss: 0.0149\n",
      "Epoch 128/200, Iteration 179/250, Loss: 0.0111\n",
      "Epoch 128/200, Iteration 180/250, Loss: 0.0111\n",
      "Epoch 128/200, Iteration 181/250, Loss: 0.0055\n",
      "Epoch 128/200, Iteration 182/250, Loss: 0.0160\n",
      "Epoch 128/200, Iteration 183/250, Loss: 0.0078\n",
      "Epoch 128/200, Iteration 184/250, Loss: 0.0142\n",
      "Epoch 128/200, Iteration 185/250, Loss: 0.0146\n",
      "Epoch 128/200, Iteration 186/250, Loss: 0.0164\n",
      "Epoch 128/200, Iteration 187/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 188/250, Loss: 0.0131\n",
      "Epoch 128/200, Iteration 189/250, Loss: 0.0058\n",
      "Epoch 128/200, Iteration 190/250, Loss: 0.0179\n",
      "Epoch 128/200, Iteration 191/250, Loss: 0.0084\n",
      "Epoch 128/200, Iteration 192/250, Loss: 0.0183\n",
      "Epoch 128/200, Iteration 193/250, Loss: 0.0066\n",
      "Epoch 128/200, Iteration 194/250, Loss: 0.0096\n",
      "Epoch 128/200, Iteration 195/250, Loss: 0.0133\n",
      "Epoch 128/200, Iteration 196/250, Loss: 0.0154\n",
      "Epoch 128/200, Iteration 197/250, Loss: 0.0207\n",
      "Epoch 128/200, Iteration 198/250, Loss: 0.0215\n",
      "Epoch 128/200, Iteration 199/250, Loss: 0.0171\n",
      "Epoch 128/200, Iteration 200/250, Loss: 0.0212\n",
      "Epoch 128/200, Iteration 201/250, Loss: 0.0195\n",
      "Epoch 128/200, Iteration 202/250, Loss: 0.0207\n",
      "Epoch 128/200, Iteration 203/250, Loss: 0.0111\n",
      "Epoch 128/200, Iteration 204/250, Loss: 0.0100\n",
      "Epoch 128/200, Iteration 205/250, Loss: 0.0274\n",
      "Epoch 128/200, Iteration 206/250, Loss: 0.0063\n",
      "Epoch 128/200, Iteration 207/250, Loss: 0.0100\n",
      "Epoch 128/200, Iteration 208/250, Loss: 0.0106\n",
      "Epoch 128/200, Iteration 209/250, Loss: 0.0229\n",
      "Epoch 128/200, Iteration 210/250, Loss: 0.0286\n",
      "Epoch 128/200, Iteration 211/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 212/250, Loss: 0.0175\n",
      "Epoch 128/200, Iteration 213/250, Loss: 0.0144\n",
      "Epoch 128/200, Iteration 214/250, Loss: 0.0346\n",
      "Epoch 128/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 128/200, Iteration 217/250, Loss: 0.0389\n",
      "Epoch 128/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 219/250, Loss: 0.0151\n",
      "Epoch 128/200, Iteration 220/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 221/250, Loss: 0.0054\n",
      "Epoch 128/200, Iteration 222/250, Loss: 0.0088\n",
      "Epoch 128/200, Iteration 223/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 224/250, Loss: 0.0117\n",
      "Epoch 128/200, Iteration 225/250, Loss: 0.0074\n",
      "Epoch 128/200, Iteration 226/250, Loss: 0.0160\n",
      "Epoch 128/200, Iteration 227/250, Loss: 0.0386\n",
      "Epoch 128/200, Iteration 228/250, Loss: 0.0089\n",
      "Epoch 128/200, Iteration 229/250, Loss: 0.0137\n",
      "Epoch 128/200, Iteration 230/250, Loss: 0.0110\n",
      "Epoch 128/200, Iteration 231/250, Loss: 0.0194\n",
      "Epoch 128/200, Iteration 232/250, Loss: 0.0230\n",
      "Epoch 128/200, Iteration 233/250, Loss: 0.0178\n",
      "Epoch 128/200, Iteration 234/250, Loss: 0.0114\n",
      "Epoch 128/200, Iteration 235/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 236/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 237/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 238/250, Loss: 0.0132\n",
      "Epoch 128/200, Iteration 239/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 240/250, Loss: 0.0214\n",
      "Epoch 128/200, Iteration 241/250, Loss: 0.0195\n",
      "Epoch 128/200, Iteration 242/250, Loss: 0.0090\n",
      "Epoch 128/200, Iteration 243/250, Loss: 0.0135\n",
      "Epoch 128/200, Iteration 244/250, Loss: 0.0145\n",
      "Epoch 128/200, Iteration 245/250, Loss: 0.0054\n",
      "Epoch 128/200, Iteration 246/250, Loss: 0.0077\n",
      "Epoch 128/200, Iteration 247/250, Loss: 0.0138\n",
      "Epoch 128/200, Iteration 248/250, Loss: 0.0107\n",
      "Epoch 128/200, Iteration 249/250, Loss: 0.0140\n",
      "Epoch 128/200, Iteration 250/250, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 89.44%, Avg loss: 0.006335, MRE: 0.615527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.15%, Avg loss: 0.006354, MRE: 0.870666 \n",
      "\n",
      "Epoch 129/200, Iteration 1/250, Loss: 0.0140\n",
      "Epoch 129/200, Iteration 2/250, Loss: 0.0169\n",
      "Epoch 129/200, Iteration 3/250, Loss: 0.0075\n",
      "Epoch 129/200, Iteration 4/250, Loss: 0.0159\n",
      "Epoch 129/200, Iteration 5/250, Loss: 0.0204\n",
      "Epoch 129/200, Iteration 6/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 7/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 8/250, Loss: 0.0114\n",
      "Epoch 129/200, Iteration 9/250, Loss: 0.0284\n",
      "Epoch 129/200, Iteration 10/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 11/250, Loss: 0.0131\n",
      "Epoch 129/200, Iteration 12/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 13/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 14/250, Loss: 0.0146\n",
      "Epoch 129/200, Iteration 15/250, Loss: 0.0144\n",
      "Epoch 129/200, Iteration 16/250, Loss: 0.0142\n",
      "Epoch 129/200, Iteration 17/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 19/250, Loss: 0.0272\n",
      "Epoch 129/200, Iteration 20/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 21/250, Loss: 0.0273\n",
      "Epoch 129/200, Iteration 22/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 23/250, Loss: 0.0176\n",
      "Epoch 129/200, Iteration 24/250, Loss: 0.0062\n",
      "Epoch 129/200, Iteration 25/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 26/250, Loss: 0.0070\n",
      "Epoch 129/200, Iteration 27/250, Loss: 0.0085\n",
      "Epoch 129/200, Iteration 28/250, Loss: 0.0105\n",
      "Epoch 129/200, Iteration 29/250, Loss: 0.0110\n",
      "Epoch 129/200, Iteration 30/250, Loss: 0.0176\n",
      "Epoch 129/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 129/200, Iteration 32/250, Loss: 0.0220\n",
      "Epoch 129/200, Iteration 33/250, Loss: 0.0216\n",
      "Epoch 129/200, Iteration 34/250, Loss: 0.0167\n",
      "Epoch 129/200, Iteration 35/250, Loss: 0.0117\n",
      "Epoch 129/200, Iteration 36/250, Loss: 0.0133\n",
      "Epoch 129/200, Iteration 37/250, Loss: 0.0077\n",
      "Epoch 129/200, Iteration 38/250, Loss: 0.0100\n",
      "Epoch 129/200, Iteration 39/250, Loss: 0.0107\n",
      "Epoch 129/200, Iteration 40/250, Loss: 0.0195\n",
      "Epoch 129/200, Iteration 41/250, Loss: 0.0078\n",
      "Epoch 129/200, Iteration 42/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 43/250, Loss: 0.0277\n",
      "Epoch 129/200, Iteration 44/250, Loss: 0.0166\n",
      "Epoch 129/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 129/200, Iteration 46/250, Loss: 0.0218\n",
      "Epoch 129/200, Iteration 47/250, Loss: 0.0109\n",
      "Epoch 129/200, Iteration 48/250, Loss: 0.0180\n",
      "Epoch 129/200, Iteration 49/250, Loss: 0.0066\n",
      "Epoch 129/200, Iteration 50/250, Loss: 0.0289\n",
      "Epoch 129/200, Iteration 51/250, Loss: 0.0245\n",
      "Epoch 129/200, Iteration 52/250, Loss: 0.0188\n",
      "Epoch 129/200, Iteration 53/250, Loss: 0.0091\n",
      "Epoch 129/200, Iteration 54/250, Loss: 0.0218\n",
      "Epoch 129/200, Iteration 55/250, Loss: 0.0184\n",
      "Epoch 129/200, Iteration 56/250, Loss: 0.0145\n",
      "Epoch 129/200, Iteration 57/250, Loss: 0.0123\n",
      "Epoch 129/200, Iteration 58/250, Loss: 0.0150\n",
      "Epoch 129/200, Iteration 59/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 60/250, Loss: 0.0159\n",
      "Epoch 129/200, Iteration 61/250, Loss: 0.0107\n",
      "Epoch 129/200, Iteration 62/250, Loss: 0.0071\n",
      "Epoch 129/200, Iteration 63/250, Loss: 0.0313\n",
      "Epoch 129/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 65/250, Loss: 0.0070\n",
      "Epoch 129/200, Iteration 66/250, Loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200, Iteration 67/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 68/250, Loss: 0.0137\n",
      "Epoch 129/200, Iteration 69/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 70/250, Loss: 0.0215\n",
      "Epoch 129/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 72/250, Loss: 0.0274\n",
      "Epoch 129/200, Iteration 73/250, Loss: 0.0248\n",
      "Epoch 129/200, Iteration 74/250, Loss: 0.0104\n",
      "Epoch 129/200, Iteration 75/250, Loss: 0.0137\n",
      "Epoch 129/200, Iteration 76/250, Loss: 0.0345\n",
      "Epoch 129/200, Iteration 77/250, Loss: 0.0242\n",
      "Epoch 129/200, Iteration 78/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 79/250, Loss: 0.0180\n",
      "Epoch 129/200, Iteration 80/250, Loss: 0.0270\n",
      "Epoch 129/200, Iteration 81/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 82/250, Loss: 0.0125\n",
      "Epoch 129/200, Iteration 83/250, Loss: 0.0241\n",
      "Epoch 129/200, Iteration 84/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 85/250, Loss: 0.0190\n",
      "Epoch 129/200, Iteration 86/250, Loss: 0.0175\n",
      "Epoch 129/200, Iteration 87/250, Loss: 0.0181\n",
      "Epoch 129/200, Iteration 88/250, Loss: 0.0145\n",
      "Epoch 129/200, Iteration 89/250, Loss: 0.0114\n",
      "Epoch 129/200, Iteration 90/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 91/250, Loss: 0.0049\n",
      "Epoch 129/200, Iteration 92/250, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 93/250, Loss: 0.0080\n",
      "Epoch 129/200, Iteration 94/250, Loss: 0.0081\n",
      "Epoch 129/200, Iteration 95/250, Loss: 0.0118\n",
      "Epoch 129/200, Iteration 96/250, Loss: 0.0189\n",
      "Epoch 129/200, Iteration 97/250, Loss: 0.0095\n",
      "Epoch 129/200, Iteration 98/250, Loss: 0.0273\n",
      "Epoch 129/200, Iteration 99/250, Loss: 0.0301\n",
      "Epoch 129/200, Iteration 100/250, Loss: 0.0072\n",
      "Epoch 129/200, Iteration 101/250, Loss: 0.0145\n",
      "Epoch 129/200, Iteration 102/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 103/250, Loss: 0.0275\n",
      "Epoch 129/200, Iteration 104/250, Loss: 0.0140\n",
      "Epoch 129/200, Iteration 105/250, Loss: 0.0224\n",
      "Epoch 129/200, Iteration 106/250, Loss: 0.0246\n",
      "Epoch 129/200, Iteration 107/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 108/250, Loss: 0.0304\n",
      "Epoch 129/200, Iteration 109/250, Loss: 0.0123\n",
      "Epoch 129/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 129/200, Iteration 111/250, Loss: 0.0101\n",
      "Epoch 129/200, Iteration 112/250, Loss: 0.0074\n",
      "Epoch 129/200, Iteration 113/250, Loss: 0.0114\n",
      "Epoch 129/200, Iteration 114/250, Loss: 0.0212\n",
      "Epoch 129/200, Iteration 115/250, Loss: 0.0121\n",
      "Epoch 129/200, Iteration 116/250, Loss: 0.0088\n",
      "Epoch 129/200, Iteration 117/250, Loss: 0.0215\n",
      "Epoch 129/200, Iteration 118/250, Loss: 0.0234\n",
      "Epoch 129/200, Iteration 119/250, Loss: 0.0270\n",
      "Epoch 129/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 129/200, Iteration 121/250, Loss: 0.0156\n",
      "Epoch 129/200, Iteration 122/250, Loss: 0.0155\n",
      "Epoch 129/200, Iteration 123/250, Loss: 0.0095\n",
      "Epoch 129/200, Iteration 124/250, Loss: 0.0084\n",
      "Epoch 129/200, Iteration 125/250, Loss: 0.0328\n",
      "Epoch 129/200, Iteration 126/250, Loss: 0.0105\n",
      "Epoch 129/200, Iteration 127/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 129/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 130/250, Loss: 0.0133\n",
      "Epoch 129/200, Iteration 131/250, Loss: 0.0139\n",
      "Epoch 129/200, Iteration 132/250, Loss: 0.0120\n",
      "Epoch 129/200, Iteration 133/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 135/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 136/250, Loss: 0.0153\n",
      "Epoch 129/200, Iteration 137/250, Loss: 0.0307\n",
      "Epoch 129/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 129/200, Iteration 139/250, Loss: 0.0066\n",
      "Epoch 129/200, Iteration 140/250, Loss: 0.0184\n",
      "Epoch 129/200, Iteration 141/250, Loss: 0.0099\n",
      "Epoch 129/200, Iteration 142/250, Loss: 0.0168\n",
      "Epoch 129/200, Iteration 143/250, Loss: 0.0147\n",
      "Epoch 129/200, Iteration 144/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 145/250, Loss: 0.0091\n",
      "Epoch 129/200, Iteration 146/250, Loss: 0.0178\n",
      "Epoch 129/200, Iteration 147/250, Loss: 0.0120\n",
      "Epoch 129/200, Iteration 148/250, Loss: 0.0124\n",
      "Epoch 129/200, Iteration 149/250, Loss: 0.0099\n",
      "Epoch 129/200, Iteration 150/250, Loss: 0.0180\n",
      "Epoch 129/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 129/200, Iteration 152/250, Loss: 0.0124\n",
      "Epoch 129/200, Iteration 153/250, Loss: 0.0079\n",
      "Epoch 129/200, Iteration 154/250, Loss: 0.0100\n",
      "Epoch 129/200, Iteration 155/250, Loss: 0.0148\n",
      "Epoch 129/200, Iteration 156/250, Loss: 0.0109\n",
      "Epoch 129/200, Iteration 157/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 158/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 159/250, Loss: 0.0142\n",
      "Epoch 129/200, Iteration 160/250, Loss: 0.0080\n",
      "Epoch 129/200, Iteration 161/250, Loss: 0.0081\n",
      "Epoch 129/200, Iteration 162/250, Loss: 0.0193\n",
      "Epoch 129/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 129/200, Iteration 164/250, Loss: 0.0085\n",
      "Epoch 129/200, Iteration 165/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 166/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 167/250, Loss: 0.0142\n",
      "Epoch 129/200, Iteration 168/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 169/250, Loss: 0.0120\n",
      "Epoch 129/200, Iteration 170/250, Loss: 0.0196\n",
      "Epoch 129/200, Iteration 171/250, Loss: 0.0229\n",
      "Epoch 129/200, Iteration 172/250, Loss: 0.0170\n",
      "Epoch 129/200, Iteration 173/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 174/250, Loss: 0.0146\n",
      "Epoch 129/200, Iteration 175/250, Loss: 0.0215\n",
      "Epoch 129/200, Iteration 176/250, Loss: 0.0131\n",
      "Epoch 129/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 129/200, Iteration 178/250, Loss: 0.0236\n",
      "Epoch 129/200, Iteration 179/250, Loss: 0.0137\n",
      "Epoch 129/200, Iteration 180/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 181/250, Loss: 0.0073\n",
      "Epoch 129/200, Iteration 182/250, Loss: 0.0069\n",
      "Epoch 129/200, Iteration 183/250, Loss: 0.0180\n",
      "Epoch 129/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 185/250, Loss: 0.0110\n",
      "Epoch 129/200, Iteration 186/250, Loss: 0.0110\n",
      "Epoch 129/200, Iteration 187/250, Loss: 0.0086\n",
      "Epoch 129/200, Iteration 188/250, Loss: 0.0128\n",
      "Epoch 129/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 129/200, Iteration 190/250, Loss: 0.0158\n",
      "Epoch 129/200, Iteration 191/250, Loss: 0.0149\n",
      "Epoch 129/200, Iteration 192/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 193/250, Loss: 0.0144\n",
      "Epoch 129/200, Iteration 194/250, Loss: 0.0078\n",
      "Epoch 129/200, Iteration 195/250, Loss: 0.0192\n",
      "Epoch 129/200, Iteration 196/250, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 197/250, Loss: 0.0116\n",
      "Epoch 129/200, Iteration 198/250, Loss: 0.0162\n",
      "Epoch 129/200, Iteration 199/250, Loss: 0.0257\n",
      "Epoch 129/200, Iteration 200/250, Loss: 0.0077\n",
      "Epoch 129/200, Iteration 201/250, Loss: 0.0167\n",
      "Epoch 129/200, Iteration 202/250, Loss: 0.0141\n",
      "Epoch 129/200, Iteration 203/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 204/250, Loss: 0.0287\n",
      "Epoch 129/200, Iteration 205/250, Loss: 0.0303\n",
      "Epoch 129/200, Iteration 206/250, Loss: 0.0134\n",
      "Epoch 129/200, Iteration 207/250, Loss: 0.0130\n",
      "Epoch 129/200, Iteration 208/250, Loss: 0.0188\n",
      "Epoch 129/200, Iteration 209/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 210/250, Loss: 0.0278\n",
      "Epoch 129/200, Iteration 211/250, Loss: 0.0063\n",
      "Epoch 129/200, Iteration 212/250, Loss: 0.0199\n",
      "Epoch 129/200, Iteration 213/250, Loss: 0.0104\n",
      "Epoch 129/200, Iteration 214/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 215/250, Loss: 0.0153\n",
      "Epoch 129/200, Iteration 216/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 217/250, Loss: 0.0052\n",
      "Epoch 129/200, Iteration 218/250, Loss: 0.0079\n",
      "Epoch 129/200, Iteration 219/250, Loss: 0.0255\n",
      "Epoch 129/200, Iteration 220/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 129/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 129/200, Iteration 223/250, Loss: 0.0070\n",
      "Epoch 129/200, Iteration 224/250, Loss: 0.0192\n",
      "Epoch 129/200, Iteration 225/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 226/250, Loss: 0.0084\n",
      "Epoch 129/200, Iteration 227/250, Loss: 0.0130\n",
      "Epoch 129/200, Iteration 228/250, Loss: 0.0186\n",
      "Epoch 129/200, Iteration 229/250, Loss: 0.0276\n",
      "Epoch 129/200, Iteration 230/250, Loss: 0.0123\n",
      "Epoch 129/200, Iteration 231/250, Loss: 0.0446\n",
      "Epoch 129/200, Iteration 232/250, Loss: 0.0377\n",
      "Epoch 129/200, Iteration 233/250, Loss: 0.0181\n",
      "Epoch 129/200, Iteration 234/250, Loss: 0.0091\n",
      "Epoch 129/200, Iteration 235/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 236/250, Loss: 0.0081\n",
      "Epoch 129/200, Iteration 237/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 238/250, Loss: 0.0097\n",
      "Epoch 129/200, Iteration 239/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 240/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 241/250, Loss: 0.0109\n",
      "Epoch 129/200, Iteration 242/250, Loss: 0.0084\n",
      "Epoch 129/200, Iteration 243/250, Loss: 0.0168\n",
      "Epoch 129/200, Iteration 244/250, Loss: 0.0217\n",
      "Epoch 129/200, Iteration 245/250, Loss: 0.0167\n",
      "Epoch 129/200, Iteration 246/250, Loss: 0.0147\n",
      "Epoch 129/200, Iteration 247/250, Loss: 0.0191\n",
      "Epoch 129/200, Iteration 248/250, Loss: 0.0144\n",
      "Epoch 129/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 250/250, Loss: 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.36%, Avg loss: 0.006155, MRE: 0.618731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.35%, Avg loss: 0.006164, MRE: 0.994175 \n",
      "\n",
      "Epoch 130/200, Iteration 1/250, Loss: 0.0094\n",
      "Epoch 130/200, Iteration 2/250, Loss: 0.0070\n",
      "Epoch 130/200, Iteration 3/250, Loss: 0.0188\n",
      "Epoch 130/200, Iteration 4/250, Loss: 0.0191\n",
      "Epoch 130/200, Iteration 5/250, Loss: 0.0125\n",
      "Epoch 130/200, Iteration 6/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 7/250, Loss: 0.0086\n",
      "Epoch 130/200, Iteration 8/250, Loss: 0.0132\n",
      "Epoch 130/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 10/250, Loss: 0.0135\n",
      "Epoch 130/200, Iteration 11/250, Loss: 0.0141\n",
      "Epoch 130/200, Iteration 12/250, Loss: 0.0207\n",
      "Epoch 130/200, Iteration 13/250, Loss: 0.0227\n",
      "Epoch 130/200, Iteration 14/250, Loss: 0.0100\n",
      "Epoch 130/200, Iteration 15/250, Loss: 0.0063\n",
      "Epoch 130/200, Iteration 16/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 17/250, Loss: 0.0087\n",
      "Epoch 130/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 19/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 20/250, Loss: 0.0109\n",
      "Epoch 130/200, Iteration 21/250, Loss: 0.0328\n",
      "Epoch 130/200, Iteration 22/250, Loss: 0.0139\n",
      "Epoch 130/200, Iteration 23/250, Loss: 0.0200\n",
      "Epoch 130/200, Iteration 24/250, Loss: 0.0063\n",
      "Epoch 130/200, Iteration 25/250, Loss: 0.0076\n",
      "Epoch 130/200, Iteration 26/250, Loss: 0.0170\n",
      "Epoch 130/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 130/200, Iteration 28/250, Loss: 0.0150\n",
      "Epoch 130/200, Iteration 29/250, Loss: 0.0065\n",
      "Epoch 130/200, Iteration 30/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 31/250, Loss: 0.0149\n",
      "Epoch 130/200, Iteration 32/250, Loss: 0.0113\n",
      "Epoch 130/200, Iteration 33/250, Loss: 0.0106\n",
      "Epoch 130/200, Iteration 34/250, Loss: 0.0214\n",
      "Epoch 130/200, Iteration 35/250, Loss: 0.0071\n",
      "Epoch 130/200, Iteration 36/250, Loss: 0.0165\n",
      "Epoch 130/200, Iteration 37/250, Loss: 0.0134\n",
      "Epoch 130/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 130/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 40/250, Loss: 0.0116\n",
      "Epoch 130/200, Iteration 41/250, Loss: 0.0124\n",
      "Epoch 130/200, Iteration 42/250, Loss: 0.0246\n",
      "Epoch 130/200, Iteration 43/250, Loss: 0.0075\n",
      "Epoch 130/200, Iteration 44/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 45/250, Loss: 0.0150\n",
      "Epoch 130/200, Iteration 46/250, Loss: 0.0297\n",
      "Epoch 130/200, Iteration 47/250, Loss: 0.0289\n",
      "Epoch 130/200, Iteration 48/250, Loss: 0.0125\n",
      "Epoch 130/200, Iteration 49/250, Loss: 0.0165\n",
      "Epoch 130/200, Iteration 50/250, Loss: 0.0389\n",
      "Epoch 130/200, Iteration 51/250, Loss: 0.0180\n",
      "Epoch 130/200, Iteration 52/250, Loss: 0.0261\n",
      "Epoch 130/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 130/200, Iteration 54/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 55/250, Loss: 0.0080\n",
      "Epoch 130/200, Iteration 56/250, Loss: 0.0164\n",
      "Epoch 130/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 130/200, Iteration 58/250, Loss: 0.0116\n",
      "Epoch 130/200, Iteration 59/250, Loss: 0.0172\n",
      "Epoch 130/200, Iteration 60/250, Loss: 0.0228\n",
      "Epoch 130/200, Iteration 61/250, Loss: 0.0097\n",
      "Epoch 130/200, Iteration 62/250, Loss: 0.0233\n",
      "Epoch 130/200, Iteration 63/250, Loss: 0.0089\n",
      "Epoch 130/200, Iteration 64/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 65/250, Loss: 0.0146\n",
      "Epoch 130/200, Iteration 66/250, Loss: 0.0069\n",
      "Epoch 130/200, Iteration 67/250, Loss: 0.0219\n",
      "Epoch 130/200, Iteration 68/250, Loss: 0.0195\n",
      "Epoch 130/200, Iteration 69/250, Loss: 0.0178\n",
      "Epoch 130/200, Iteration 70/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 71/250, Loss: 0.0159\n",
      "Epoch 130/200, Iteration 72/250, Loss: 0.0170\n",
      "Epoch 130/200, Iteration 73/250, Loss: 0.0095\n",
      "Epoch 130/200, Iteration 74/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 75/250, Loss: 0.0168\n",
      "Epoch 130/200, Iteration 76/250, Loss: 0.0335\n",
      "Epoch 130/200, Iteration 77/250, Loss: 0.0186\n",
      "Epoch 130/200, Iteration 78/250, Loss: 0.0182\n",
      "Epoch 130/200, Iteration 79/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 80/250, Loss: 0.0278\n",
      "Epoch 130/200, Iteration 81/250, Loss: 0.0133\n",
      "Epoch 130/200, Iteration 82/250, Loss: 0.0250\n",
      "Epoch 130/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 130/200, Iteration 84/250, Loss: 0.0406\n",
      "Epoch 130/200, Iteration 85/250, Loss: 0.0208\n",
      "Epoch 130/200, Iteration 86/250, Loss: 0.0173\n",
      "Epoch 130/200, Iteration 87/250, Loss: 0.0097\n",
      "Epoch 130/200, Iteration 88/250, Loss: 0.0286\n",
      "Epoch 130/200, Iteration 89/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 91/250, Loss: 0.0182\n",
      "Epoch 130/200, Iteration 92/250, Loss: 0.0154\n",
      "Epoch 130/200, Iteration 93/250, Loss: 0.0114\n",
      "Epoch 130/200, Iteration 94/250, Loss: 0.0071\n",
      "Epoch 130/200, Iteration 95/250, Loss: 0.0151\n",
      "Epoch 130/200, Iteration 96/250, Loss: 0.0187\n",
      "Epoch 130/200, Iteration 97/250, Loss: 0.0476\n",
      "Epoch 130/200, Iteration 98/250, Loss: 0.0084\n",
      "Epoch 130/200, Iteration 99/250, Loss: 0.0270\n",
      "Epoch 130/200, Iteration 100/250, Loss: 0.0078\n",
      "Epoch 130/200, Iteration 101/250, Loss: 0.0215\n",
      "Epoch 130/200, Iteration 102/250, Loss: 0.0065\n",
      "Epoch 130/200, Iteration 103/250, Loss: 0.0232\n",
      "Epoch 130/200, Iteration 104/250, Loss: 0.0150\n",
      "Epoch 130/200, Iteration 105/250, Loss: 0.0120\n",
      "Epoch 130/200, Iteration 106/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 107/250, Loss: 0.0084\n",
      "Epoch 130/200, Iteration 108/250, Loss: 0.0150\n",
      "Epoch 130/200, Iteration 109/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 110/250, Loss: 0.0166\n",
      "Epoch 130/200, Iteration 111/250, Loss: 0.0331\n",
      "Epoch 130/200, Iteration 112/250, Loss: 0.0125\n",
      "Epoch 130/200, Iteration 113/250, Loss: 0.0104\n",
      "Epoch 130/200, Iteration 114/250, Loss: 0.0127\n",
      "Epoch 130/200, Iteration 115/250, Loss: 0.0175\n",
      "Epoch 130/200, Iteration 116/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 117/250, Loss: 0.0292\n",
      "Epoch 130/200, Iteration 118/250, Loss: 0.0176\n",
      "Epoch 130/200, Iteration 119/250, Loss: 0.0128\n",
      "Epoch 130/200, Iteration 120/250, Loss: 0.0119\n",
      "Epoch 130/200, Iteration 121/250, Loss: 0.0159\n",
      "Epoch 130/200, Iteration 122/250, Loss: 0.0134\n",
      "Epoch 130/200, Iteration 123/250, Loss: 0.0164\n",
      "Epoch 130/200, Iteration 124/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 125/250, Loss: 0.0138\n",
      "Epoch 130/200, Iteration 126/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 127/250, Loss: 0.0103\n",
      "Epoch 130/200, Iteration 128/250, Loss: 0.0327\n",
      "Epoch 130/200, Iteration 129/250, Loss: 0.0198\n",
      "Epoch 130/200, Iteration 130/250, Loss: 0.0100\n",
      "Epoch 130/200, Iteration 131/250, Loss: 0.0075\n",
      "Epoch 130/200, Iteration 132/250, Loss: 0.0128\n",
      "Epoch 130/200, Iteration 133/250, Loss: 0.0101\n",
      "Epoch 130/200, Iteration 134/250, Loss: 0.0119\n",
      "Epoch 130/200, Iteration 135/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 137/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 138/250, Loss: 0.0346\n",
      "Epoch 130/200, Iteration 139/250, Loss: 0.0178\n",
      "Epoch 130/200, Iteration 140/250, Loss: 0.0252\n",
      "Epoch 130/200, Iteration 141/250, Loss: 0.0113\n",
      "Epoch 130/200, Iteration 142/250, Loss: 0.0131\n",
      "Epoch 130/200, Iteration 143/250, Loss: 0.0109\n",
      "Epoch 130/200, Iteration 144/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 145/250, Loss: 0.0075\n",
      "Epoch 130/200, Iteration 146/250, Loss: 0.0101\n",
      "Epoch 130/200, Iteration 147/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 148/250, Loss: 0.0266\n",
      "Epoch 130/200, Iteration 149/250, Loss: 0.0314\n",
      "Epoch 130/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 151/250, Loss: 0.0123\n",
      "Epoch 130/200, Iteration 152/250, Loss: 0.0089\n",
      "Epoch 130/200, Iteration 153/250, Loss: 0.0124\n",
      "Epoch 130/200, Iteration 154/250, Loss: 0.0114\n",
      "Epoch 130/200, Iteration 155/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 156/250, Loss: 0.0312\n",
      "Epoch 130/200, Iteration 157/250, Loss: 0.0173\n",
      "Epoch 130/200, Iteration 158/250, Loss: 0.0060\n",
      "Epoch 130/200, Iteration 159/250, Loss: 0.0069\n",
      "Epoch 130/200, Iteration 160/250, Loss: 0.0170\n",
      "Epoch 130/200, Iteration 161/250, Loss: 0.0084\n",
      "Epoch 130/200, Iteration 162/250, Loss: 0.0216\n",
      "Epoch 130/200, Iteration 163/250, Loss: 0.0238\n",
      "Epoch 130/200, Iteration 164/250, Loss: 0.0176\n",
      "Epoch 130/200, Iteration 165/250, Loss: 0.0067\n",
      "Epoch 130/200, Iteration 166/250, Loss: 0.0113\n",
      "Epoch 130/200, Iteration 167/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 168/250, Loss: 0.0056\n",
      "Epoch 130/200, Iteration 169/250, Loss: 0.0166\n",
      "Epoch 130/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 130/200, Iteration 171/250, Loss: 0.0137\n",
      "Epoch 130/200, Iteration 172/250, Loss: 0.0157\n",
      "Epoch 130/200, Iteration 173/250, Loss: 0.0077\n",
      "Epoch 130/200, Iteration 174/250, Loss: 0.0177\n",
      "Epoch 130/200, Iteration 175/250, Loss: 0.0057\n",
      "Epoch 130/200, Iteration 176/250, Loss: 0.0284\n",
      "Epoch 130/200, Iteration 177/250, Loss: 0.0129\n",
      "Epoch 130/200, Iteration 178/250, Loss: 0.0165\n",
      "Epoch 130/200, Iteration 179/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 180/250, Loss: 0.0212\n",
      "Epoch 130/200, Iteration 181/250, Loss: 0.0212\n",
      "Epoch 130/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 130/200, Iteration 183/250, Loss: 0.0250\n",
      "Epoch 130/200, Iteration 184/250, Loss: 0.0132\n",
      "Epoch 130/200, Iteration 185/250, Loss: 0.0101\n",
      "Epoch 130/200, Iteration 186/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 187/250, Loss: 0.0063\n",
      "Epoch 130/200, Iteration 188/250, Loss: 0.0129\n",
      "Epoch 130/200, Iteration 189/250, Loss: 0.0179\n",
      "Epoch 130/200, Iteration 190/250, Loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200, Iteration 191/250, Loss: 0.0098\n",
      "Epoch 130/200, Iteration 192/250, Loss: 0.0064\n",
      "Epoch 130/200, Iteration 193/250, Loss: 0.0106\n",
      "Epoch 130/200, Iteration 194/250, Loss: 0.0118\n",
      "Epoch 130/200, Iteration 195/250, Loss: 0.0136\n",
      "Epoch 130/200, Iteration 196/250, Loss: 0.0191\n",
      "Epoch 130/200, Iteration 197/250, Loss: 0.0153\n",
      "Epoch 130/200, Iteration 198/250, Loss: 0.0166\n",
      "Epoch 130/200, Iteration 199/250, Loss: 0.0087\n",
      "Epoch 130/200, Iteration 200/250, Loss: 0.0170\n",
      "Epoch 130/200, Iteration 201/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 202/250, Loss: 0.0096\n",
      "Epoch 130/200, Iteration 203/250, Loss: 0.0215\n",
      "Epoch 130/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 205/250, Loss: 0.0194\n",
      "Epoch 130/200, Iteration 206/250, Loss: 0.0064\n",
      "Epoch 130/200, Iteration 207/250, Loss: 0.0064\n",
      "Epoch 130/200, Iteration 208/250, Loss: 0.0108\n",
      "Epoch 130/200, Iteration 209/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 210/250, Loss: 0.0228\n",
      "Epoch 130/200, Iteration 211/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 212/250, Loss: 0.0191\n",
      "Epoch 130/200, Iteration 213/250, Loss: 0.0163\n",
      "Epoch 130/200, Iteration 214/250, Loss: 0.0339\n",
      "Epoch 130/200, Iteration 215/250, Loss: 0.0069\n",
      "Epoch 130/200, Iteration 216/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 217/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 218/250, Loss: 0.0279\n",
      "Epoch 130/200, Iteration 219/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 220/250, Loss: 0.0197\n",
      "Epoch 130/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 130/200, Iteration 222/250, Loss: 0.0236\n",
      "Epoch 130/200, Iteration 223/250, Loss: 0.0282\n",
      "Epoch 130/200, Iteration 224/250, Loss: 0.0177\n",
      "Epoch 130/200, Iteration 225/250, Loss: 0.0200\n",
      "Epoch 130/200, Iteration 226/250, Loss: 0.0295\n",
      "Epoch 130/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 228/250, Loss: 0.0173\n",
      "Epoch 130/200, Iteration 229/250, Loss: 0.0064\n",
      "Epoch 130/200, Iteration 230/250, Loss: 0.0187\n",
      "Epoch 130/200, Iteration 231/250, Loss: 0.0138\n",
      "Epoch 130/200, Iteration 232/250, Loss: 0.0154\n",
      "Epoch 130/200, Iteration 233/250, Loss: 0.0338\n",
      "Epoch 130/200, Iteration 234/250, Loss: 0.0065\n",
      "Epoch 130/200, Iteration 235/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 236/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 237/250, Loss: 0.0322\n",
      "Epoch 130/200, Iteration 238/250, Loss: 0.0207\n",
      "Epoch 130/200, Iteration 239/250, Loss: 0.0134\n",
      "Epoch 130/200, Iteration 240/250, Loss: 0.0174\n",
      "Epoch 130/200, Iteration 241/250, Loss: 0.0135\n",
      "Epoch 130/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 130/200, Iteration 243/250, Loss: 0.0172\n",
      "Epoch 130/200, Iteration 244/250, Loss: 0.0210\n",
      "Epoch 130/200, Iteration 245/250, Loss: 0.0226\n",
      "Epoch 130/200, Iteration 246/250, Loss: 0.0269\n",
      "Epoch 130/200, Iteration 247/250, Loss: 0.0142\n",
      "Epoch 130/200, Iteration 248/250, Loss: 0.0069\n",
      "Epoch 130/200, Iteration 249/250, Loss: 0.0138\n",
      "Epoch 130/200, Iteration 250/250, Loss: 0.0198\n",
      "Train Error: \n",
      " Accuracy: 96.08%, Avg loss: 0.006396, MRE: 0.634116 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.006395, MRE: 1.081198 \n",
      "\n",
      "Epoch 131/200, Iteration 1/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 2/250, Loss: 0.0107\n",
      "Epoch 131/200, Iteration 3/250, Loss: 0.0237\n",
      "Epoch 131/200, Iteration 4/250, Loss: 0.0241\n",
      "Epoch 131/200, Iteration 5/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 6/250, Loss: 0.0306\n",
      "Epoch 131/200, Iteration 7/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 8/250, Loss: 0.0148\n",
      "Epoch 131/200, Iteration 9/250, Loss: 0.0071\n",
      "Epoch 131/200, Iteration 10/250, Loss: 0.0231\n",
      "Epoch 131/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 131/200, Iteration 13/250, Loss: 0.0113\n",
      "Epoch 131/200, Iteration 14/250, Loss: 0.0134\n",
      "Epoch 131/200, Iteration 15/250, Loss: 0.0063\n",
      "Epoch 131/200, Iteration 16/250, Loss: 0.0183\n",
      "Epoch 131/200, Iteration 17/250, Loss: 0.0208\n",
      "Epoch 131/200, Iteration 18/250, Loss: 0.0113\n",
      "Epoch 131/200, Iteration 19/250, Loss: 0.0070\n",
      "Epoch 131/200, Iteration 20/250, Loss: 0.0109\n",
      "Epoch 131/200, Iteration 21/250, Loss: 0.0364\n",
      "Epoch 131/200, Iteration 22/250, Loss: 0.0178\n",
      "Epoch 131/200, Iteration 23/250, Loss: 0.0063\n",
      "Epoch 131/200, Iteration 24/250, Loss: 0.0198\n",
      "Epoch 131/200, Iteration 25/250, Loss: 0.0083\n",
      "Epoch 131/200, Iteration 26/250, Loss: 0.0280\n",
      "Epoch 131/200, Iteration 27/250, Loss: 0.0082\n",
      "Epoch 131/200, Iteration 28/250, Loss: 0.0171\n",
      "Epoch 131/200, Iteration 29/250, Loss: 0.0092\n",
      "Epoch 131/200, Iteration 30/250, Loss: 0.0187\n",
      "Epoch 131/200, Iteration 31/250, Loss: 0.0142\n",
      "Epoch 131/200, Iteration 32/250, Loss: 0.0076\n",
      "Epoch 131/200, Iteration 33/250, Loss: 0.0174\n",
      "Epoch 131/200, Iteration 34/250, Loss: 0.0149\n",
      "Epoch 131/200, Iteration 35/250, Loss: 0.0181\n",
      "Epoch 131/200, Iteration 36/250, Loss: 0.0245\n",
      "Epoch 131/200, Iteration 37/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 38/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 39/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 40/250, Loss: 0.0200\n",
      "Epoch 131/200, Iteration 41/250, Loss: 0.0076\n",
      "Epoch 131/200, Iteration 42/250, Loss: 0.0270\n",
      "Epoch 131/200, Iteration 43/250, Loss: 0.0152\n",
      "Epoch 131/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 131/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 131/200, Iteration 46/250, Loss: 0.0261\n",
      "Epoch 131/200, Iteration 47/250, Loss: 0.0091\n",
      "Epoch 131/200, Iteration 48/250, Loss: 0.0060\n",
      "Epoch 131/200, Iteration 49/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 50/250, Loss: 0.0183\n",
      "Epoch 131/200, Iteration 51/250, Loss: 0.0231\n",
      "Epoch 131/200, Iteration 52/250, Loss: 0.0325\n",
      "Epoch 131/200, Iteration 53/250, Loss: 0.0084\n",
      "Epoch 131/200, Iteration 54/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 55/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 56/250, Loss: 0.0271\n",
      "Epoch 131/200, Iteration 57/250, Loss: 0.0196\n",
      "Epoch 131/200, Iteration 58/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 60/250, Loss: 0.0195\n",
      "Epoch 131/200, Iteration 61/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 62/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 63/250, Loss: 0.0186\n",
      "Epoch 131/200, Iteration 64/250, Loss: 0.0145\n",
      "Epoch 131/200, Iteration 65/250, Loss: 0.0384\n",
      "Epoch 131/200, Iteration 66/250, Loss: 0.0209\n",
      "Epoch 131/200, Iteration 67/250, Loss: 0.0184\n",
      "Epoch 131/200, Iteration 68/250, Loss: 0.0179\n",
      "Epoch 131/200, Iteration 69/250, Loss: 0.0138\n",
      "Epoch 131/200, Iteration 70/250, Loss: 0.0080\n",
      "Epoch 131/200, Iteration 71/250, Loss: 0.0216\n",
      "Epoch 131/200, Iteration 72/250, Loss: 0.0257\n",
      "Epoch 131/200, Iteration 73/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 74/250, Loss: 0.0258\n",
      "Epoch 131/200, Iteration 75/250, Loss: 0.0161\n",
      "Epoch 131/200, Iteration 76/250, Loss: 0.0070\n",
      "Epoch 131/200, Iteration 77/250, Loss: 0.0172\n",
      "Epoch 131/200, Iteration 78/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 79/250, Loss: 0.0153\n",
      "Epoch 131/200, Iteration 80/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 81/250, Loss: 0.0164\n",
      "Epoch 131/200, Iteration 82/250, Loss: 0.0155\n",
      "Epoch 131/200, Iteration 83/250, Loss: 0.0243\n",
      "Epoch 131/200, Iteration 84/250, Loss: 0.0330\n",
      "Epoch 131/200, Iteration 85/250, Loss: 0.0129\n",
      "Epoch 131/200, Iteration 86/250, Loss: 0.0140\n",
      "Epoch 131/200, Iteration 87/250, Loss: 0.0082\n",
      "Epoch 131/200, Iteration 88/250, Loss: 0.0155\n",
      "Epoch 131/200, Iteration 89/250, Loss: 0.0109\n",
      "Epoch 131/200, Iteration 90/250, Loss: 0.0197\n",
      "Epoch 131/200, Iteration 91/250, Loss: 0.0231\n",
      "Epoch 131/200, Iteration 92/250, Loss: 0.0087\n",
      "Epoch 131/200, Iteration 93/250, Loss: 0.0107\n",
      "Epoch 131/200, Iteration 94/250, Loss: 0.0215\n",
      "Epoch 131/200, Iteration 95/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 96/250, Loss: 0.0121\n",
      "Epoch 131/200, Iteration 97/250, Loss: 0.0209\n",
      "Epoch 131/200, Iteration 98/250, Loss: 0.0083\n",
      "Epoch 131/200, Iteration 99/250, Loss: 0.0225\n",
      "Epoch 131/200, Iteration 100/250, Loss: 0.0181\n",
      "Epoch 131/200, Iteration 101/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 102/250, Loss: 0.0178\n",
      "Epoch 131/200, Iteration 103/250, Loss: 0.0226\n",
      "Epoch 131/200, Iteration 104/250, Loss: 0.0129\n",
      "Epoch 131/200, Iteration 105/250, Loss: 0.0270\n",
      "Epoch 131/200, Iteration 106/250, Loss: 0.0173\n",
      "Epoch 131/200, Iteration 107/250, Loss: 0.0098\n",
      "Epoch 131/200, Iteration 108/250, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 109/250, Loss: 0.0208\n",
      "Epoch 131/200, Iteration 110/250, Loss: 0.0099\n",
      "Epoch 131/200, Iteration 111/250, Loss: 0.0380\n",
      "Epoch 131/200, Iteration 112/250, Loss: 0.0306\n",
      "Epoch 131/200, Iteration 113/250, Loss: 0.0076\n",
      "Epoch 131/200, Iteration 114/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 115/250, Loss: 0.0240\n",
      "Epoch 131/200, Iteration 116/250, Loss: 0.0117\n",
      "Epoch 131/200, Iteration 117/250, Loss: 0.0143\n",
      "Epoch 131/200, Iteration 118/250, Loss: 0.0198\n",
      "Epoch 131/200, Iteration 119/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 120/250, Loss: 0.0074\n",
      "Epoch 131/200, Iteration 121/250, Loss: 0.0122\n",
      "Epoch 131/200, Iteration 122/250, Loss: 0.0116\n",
      "Epoch 131/200, Iteration 123/250, Loss: 0.0200\n",
      "Epoch 131/200, Iteration 124/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 125/250, Loss: 0.0099\n",
      "Epoch 131/200, Iteration 126/250, Loss: 0.0203\n",
      "Epoch 131/200, Iteration 127/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 128/250, Loss: 0.0140\n",
      "Epoch 131/200, Iteration 129/250, Loss: 0.0173\n",
      "Epoch 131/200, Iteration 130/250, Loss: 0.0175\n",
      "Epoch 131/200, Iteration 131/250, Loss: 0.0133\n",
      "Epoch 131/200, Iteration 132/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 133/250, Loss: 0.0144\n",
      "Epoch 131/200, Iteration 134/250, Loss: 0.0067\n",
      "Epoch 131/200, Iteration 135/250, Loss: 0.0485\n",
      "Epoch 131/200, Iteration 136/250, Loss: 0.0089\n",
      "Epoch 131/200, Iteration 137/250, Loss: 0.0173\n",
      "Epoch 131/200, Iteration 138/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 139/250, Loss: 0.0111\n",
      "Epoch 131/200, Iteration 140/250, Loss: 0.0149\n",
      "Epoch 131/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 142/250, Loss: 0.0132\n",
      "Epoch 131/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 131/200, Iteration 144/250, Loss: 0.0078\n",
      "Epoch 131/200, Iteration 145/250, Loss: 0.0197\n",
      "Epoch 131/200, Iteration 146/250, Loss: 0.0078\n",
      "Epoch 131/200, Iteration 147/250, Loss: 0.0198\n",
      "Epoch 131/200, Iteration 148/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 149/250, Loss: 0.0089\n",
      "Epoch 131/200, Iteration 150/250, Loss: 0.0074\n",
      "Epoch 131/200, Iteration 151/250, Loss: 0.0244\n",
      "Epoch 131/200, Iteration 152/250, Loss: 0.0154\n",
      "Epoch 131/200, Iteration 153/250, Loss: 0.0252\n",
      "Epoch 131/200, Iteration 154/250, Loss: 0.0122\n",
      "Epoch 131/200, Iteration 155/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 156/250, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 157/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 158/250, Loss: 0.0144\n",
      "Epoch 131/200, Iteration 159/250, Loss: 0.0224\n",
      "Epoch 131/200, Iteration 160/250, Loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200, Iteration 161/250, Loss: 0.0136\n",
      "Epoch 131/200, Iteration 162/250, Loss: 0.0116\n",
      "Epoch 131/200, Iteration 163/250, Loss: 0.0191\n",
      "Epoch 131/200, Iteration 164/250, Loss: 0.0197\n",
      "Epoch 131/200, Iteration 165/250, Loss: 0.0171\n",
      "Epoch 131/200, Iteration 166/250, Loss: 0.0157\n",
      "Epoch 131/200, Iteration 167/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 168/250, Loss: 0.0245\n",
      "Epoch 131/200, Iteration 169/250, Loss: 0.0081\n",
      "Epoch 131/200, Iteration 170/250, Loss: 0.0097\n",
      "Epoch 131/200, Iteration 171/250, Loss: 0.0127\n",
      "Epoch 131/200, Iteration 172/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 173/250, Loss: 0.0054\n",
      "Epoch 131/200, Iteration 174/250, Loss: 0.0082\n",
      "Epoch 131/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 131/200, Iteration 176/250, Loss: 0.0153\n",
      "Epoch 131/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 178/250, Loss: 0.0131\n",
      "Epoch 131/200, Iteration 179/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 180/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 181/250, Loss: 0.0127\n",
      "Epoch 131/200, Iteration 182/250, Loss: 0.0208\n",
      "Epoch 131/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 131/200, Iteration 184/250, Loss: 0.0181\n",
      "Epoch 131/200, Iteration 185/250, Loss: 0.0137\n",
      "Epoch 131/200, Iteration 186/250, Loss: 0.0073\n",
      "Epoch 131/200, Iteration 187/250, Loss: 0.0067\n",
      "Epoch 131/200, Iteration 188/250, Loss: 0.0074\n",
      "Epoch 131/200, Iteration 189/250, Loss: 0.0109\n",
      "Epoch 131/200, Iteration 190/250, Loss: 0.0285\n",
      "Epoch 131/200, Iteration 191/250, Loss: 0.0216\n",
      "Epoch 131/200, Iteration 192/250, Loss: 0.0085\n",
      "Epoch 131/200, Iteration 193/250, Loss: 0.0257\n",
      "Epoch 131/200, Iteration 194/250, Loss: 0.0273\n",
      "Epoch 131/200, Iteration 195/250, Loss: 0.0083\n",
      "Epoch 131/200, Iteration 196/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 197/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 198/250, Loss: 0.0233\n",
      "Epoch 131/200, Iteration 199/250, Loss: 0.0138\n",
      "Epoch 131/200, Iteration 200/250, Loss: 0.0139\n",
      "Epoch 131/200, Iteration 201/250, Loss: 0.0274\n",
      "Epoch 131/200, Iteration 202/250, Loss: 0.0091\n",
      "Epoch 131/200, Iteration 203/250, Loss: 0.0130\n",
      "Epoch 131/200, Iteration 204/250, Loss: 0.0205\n",
      "Epoch 131/200, Iteration 205/250, Loss: 0.0160\n",
      "Epoch 131/200, Iteration 206/250, Loss: 0.0114\n",
      "Epoch 131/200, Iteration 207/250, Loss: 0.0182\n",
      "Epoch 131/200, Iteration 208/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 210/250, Loss: 0.0194\n",
      "Epoch 131/200, Iteration 211/250, Loss: 0.0162\n",
      "Epoch 131/200, Iteration 212/250, Loss: 0.0140\n",
      "Epoch 131/200, Iteration 213/250, Loss: 0.0167\n",
      "Epoch 131/200, Iteration 214/250, Loss: 0.0215\n",
      "Epoch 131/200, Iteration 215/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 216/250, Loss: 0.0221\n",
      "Epoch 131/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 218/250, Loss: 0.0119\n",
      "Epoch 131/200, Iteration 219/250, Loss: 0.0091\n",
      "Epoch 131/200, Iteration 220/250, Loss: 0.0101\n",
      "Epoch 131/200, Iteration 221/250, Loss: 0.0167\n",
      "Epoch 131/200, Iteration 222/250, Loss: 0.0080\n",
      "Epoch 131/200, Iteration 223/250, Loss: 0.0140\n",
      "Epoch 131/200, Iteration 224/250, Loss: 0.0186\n",
      "Epoch 131/200, Iteration 225/250, Loss: 0.0173\n",
      "Epoch 131/200, Iteration 226/250, Loss: 0.0116\n",
      "Epoch 131/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 131/200, Iteration 228/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 229/250, Loss: 0.0243\n",
      "Epoch 131/200, Iteration 230/250, Loss: 0.0059\n",
      "Epoch 131/200, Iteration 231/250, Loss: 0.0107\n",
      "Epoch 131/200, Iteration 232/250, Loss: 0.0178\n",
      "Epoch 131/200, Iteration 233/250, Loss: 0.0137\n",
      "Epoch 131/200, Iteration 234/250, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 235/250, Loss: 0.0253\n",
      "Epoch 131/200, Iteration 236/250, Loss: 0.0159\n",
      "Epoch 131/200, Iteration 237/250, Loss: 0.0113\n",
      "Epoch 131/200, Iteration 238/250, Loss: 0.0128\n",
      "Epoch 131/200, Iteration 239/250, Loss: 0.0169\n",
      "Epoch 131/200, Iteration 240/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 241/250, Loss: 0.0064\n",
      "Epoch 131/200, Iteration 242/250, Loss: 0.0139\n",
      "Epoch 131/200, Iteration 243/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 244/250, Loss: 0.0065\n",
      "Epoch 131/200, Iteration 245/250, Loss: 0.0099\n",
      "Epoch 131/200, Iteration 246/250, Loss: 0.0133\n",
      "Epoch 131/200, Iteration 247/250, Loss: 0.0177\n",
      "Epoch 131/200, Iteration 248/250, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 249/250, Loss: 0.0122\n",
      "Epoch 131/200, Iteration 250/250, Loss: 0.0119\n",
      "Train Error: \n",
      " Accuracy: 90.29%, Avg loss: 0.006156, MRE: 0.602696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.15%, Avg loss: 0.006208, MRE: 0.900681 \n",
      "\n",
      "Epoch 132/200, Iteration 1/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 2/250, Loss: 0.0205\n",
      "Epoch 132/200, Iteration 3/250, Loss: 0.0148\n",
      "Epoch 132/200, Iteration 4/250, Loss: 0.0073\n",
      "Epoch 132/200, Iteration 5/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 6/250, Loss: 0.0112\n",
      "Epoch 132/200, Iteration 7/250, Loss: 0.0057\n",
      "Epoch 132/200, Iteration 8/250, Loss: 0.0235\n",
      "Epoch 132/200, Iteration 9/250, Loss: 0.0184\n",
      "Epoch 132/200, Iteration 10/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 11/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 12/250, Loss: 0.0144\n",
      "Epoch 132/200, Iteration 13/250, Loss: 0.0153\n",
      "Epoch 132/200, Iteration 14/250, Loss: 0.0192\n",
      "Epoch 132/200, Iteration 15/250, Loss: 0.0182\n",
      "Epoch 132/200, Iteration 16/250, Loss: 0.0177\n",
      "Epoch 132/200, Iteration 17/250, Loss: 0.0156\n",
      "Epoch 132/200, Iteration 18/250, Loss: 0.0173\n",
      "Epoch 132/200, Iteration 19/250, Loss: 0.0051\n",
      "Epoch 132/200, Iteration 20/250, Loss: 0.0169\n",
      "Epoch 132/200, Iteration 21/250, Loss: 0.0260\n",
      "Epoch 132/200, Iteration 22/250, Loss: 0.0216\n",
      "Epoch 132/200, Iteration 23/250, Loss: 0.0216\n",
      "Epoch 132/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 132/200, Iteration 25/250, Loss: 0.0122\n",
      "Epoch 132/200, Iteration 26/250, Loss: 0.0081\n",
      "Epoch 132/200, Iteration 27/250, Loss: 0.0134\n",
      "Epoch 132/200, Iteration 28/250, Loss: 0.0183\n",
      "Epoch 132/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 30/250, Loss: 0.0120\n",
      "Epoch 132/200, Iteration 31/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 32/250, Loss: 0.0254\n",
      "Epoch 132/200, Iteration 33/250, Loss: 0.0119\n",
      "Epoch 132/200, Iteration 34/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 35/250, Loss: 0.0253\n",
      "Epoch 132/200, Iteration 36/250, Loss: 0.0160\n",
      "Epoch 132/200, Iteration 37/250, Loss: 0.0111\n",
      "Epoch 132/200, Iteration 38/250, Loss: 0.0119\n",
      "Epoch 132/200, Iteration 39/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 40/250, Loss: 0.0131\n",
      "Epoch 132/200, Iteration 41/250, Loss: 0.0135\n",
      "Epoch 132/200, Iteration 42/250, Loss: 0.0063\n",
      "Epoch 132/200, Iteration 43/250, Loss: 0.0096\n",
      "Epoch 132/200, Iteration 44/250, Loss: 0.0299\n",
      "Epoch 132/200, Iteration 45/250, Loss: 0.0067\n",
      "Epoch 132/200, Iteration 46/250, Loss: 0.0140\n",
      "Epoch 132/200, Iteration 47/250, Loss: 0.0268\n",
      "Epoch 132/200, Iteration 48/250, Loss: 0.0172\n",
      "Epoch 132/200, Iteration 49/250, Loss: 0.0104\n",
      "Epoch 132/200, Iteration 50/250, Loss: 0.0084\n",
      "Epoch 132/200, Iteration 51/250, Loss: 0.0107\n",
      "Epoch 132/200, Iteration 52/250, Loss: 0.0272\n",
      "Epoch 132/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 132/200, Iteration 54/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 55/250, Loss: 0.0070\n",
      "Epoch 132/200, Iteration 56/250, Loss: 0.0074\n",
      "Epoch 132/200, Iteration 57/250, Loss: 0.0203\n",
      "Epoch 132/200, Iteration 58/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 132/200, Iteration 60/250, Loss: 0.0153\n",
      "Epoch 132/200, Iteration 61/250, Loss: 0.0129\n",
      "Epoch 132/200, Iteration 62/250, Loss: 0.0125\n",
      "Epoch 132/200, Iteration 63/250, Loss: 0.0103\n",
      "Epoch 132/200, Iteration 64/250, Loss: 0.0085\n",
      "Epoch 132/200, Iteration 65/250, Loss: 0.0266\n",
      "Epoch 132/200, Iteration 66/250, Loss: 0.0146\n",
      "Epoch 132/200, Iteration 67/250, Loss: 0.0146\n",
      "Epoch 132/200, Iteration 68/250, Loss: 0.0254\n",
      "Epoch 132/200, Iteration 69/250, Loss: 0.0173\n",
      "Epoch 132/200, Iteration 70/250, Loss: 0.0199\n",
      "Epoch 132/200, Iteration 71/250, Loss: 0.0303\n",
      "Epoch 132/200, Iteration 72/250, Loss: 0.0122\n",
      "Epoch 132/200, Iteration 73/250, Loss: 0.0096\n",
      "Epoch 132/200, Iteration 74/250, Loss: 0.0326\n",
      "Epoch 132/200, Iteration 75/250, Loss: 0.0187\n",
      "Epoch 132/200, Iteration 76/250, Loss: 0.0165\n",
      "Epoch 132/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 78/250, Loss: 0.0318\n",
      "Epoch 132/200, Iteration 79/250, Loss: 0.0189\n",
      "Epoch 132/200, Iteration 80/250, Loss: 0.0233\n",
      "Epoch 132/200, Iteration 81/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 82/250, Loss: 0.0327\n",
      "Epoch 132/200, Iteration 83/250, Loss: 0.0174\n",
      "Epoch 132/200, Iteration 84/250, Loss: 0.0238\n",
      "Epoch 132/200, Iteration 85/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 86/250, Loss: 0.0101\n",
      "Epoch 132/200, Iteration 87/250, Loss: 0.0269\n",
      "Epoch 132/200, Iteration 88/250, Loss: 0.0190\n",
      "Epoch 132/200, Iteration 89/250, Loss: 0.0176\n",
      "Epoch 132/200, Iteration 90/250, Loss: 0.0192\n",
      "Epoch 132/200, Iteration 91/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 132/200, Iteration 93/250, Loss: 0.0239\n",
      "Epoch 132/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 132/200, Iteration 95/250, Loss: 0.0089\n",
      "Epoch 132/200, Iteration 96/250, Loss: 0.0160\n",
      "Epoch 132/200, Iteration 97/250, Loss: 0.0089\n",
      "Epoch 132/200, Iteration 98/250, Loss: 0.0095\n",
      "Epoch 132/200, Iteration 99/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 100/250, Loss: 0.0269\n",
      "Epoch 132/200, Iteration 101/250, Loss: 0.0195\n",
      "Epoch 132/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 132/200, Iteration 103/250, Loss: 0.0126\n",
      "Epoch 132/200, Iteration 104/250, Loss: 0.0132\n",
      "Epoch 132/200, Iteration 105/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 106/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 107/250, Loss: 0.0179\n",
      "Epoch 132/200, Iteration 108/250, Loss: 0.0062\n",
      "Epoch 132/200, Iteration 109/250, Loss: 0.0101\n",
      "Epoch 132/200, Iteration 110/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 111/250, Loss: 0.0111\n",
      "Epoch 132/200, Iteration 112/250, Loss: 0.0157\n",
      "Epoch 132/200, Iteration 113/250, Loss: 0.0187\n",
      "Epoch 132/200, Iteration 114/250, Loss: 0.0061\n",
      "Epoch 132/200, Iteration 115/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200, Iteration 116/250, Loss: 0.0107\n",
      "Epoch 132/200, Iteration 117/250, Loss: 0.0094\n",
      "Epoch 132/200, Iteration 118/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 132/200, Iteration 120/250, Loss: 0.0071\n",
      "Epoch 132/200, Iteration 121/250, Loss: 0.0277\n",
      "Epoch 132/200, Iteration 122/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 123/250, Loss: 0.0192\n",
      "Epoch 132/200, Iteration 124/250, Loss: 0.0213\n",
      "Epoch 132/200, Iteration 125/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 126/250, Loss: 0.0159\n",
      "Epoch 132/200, Iteration 127/250, Loss: 0.0146\n",
      "Epoch 132/200, Iteration 128/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 129/250, Loss: 0.0116\n",
      "Epoch 132/200, Iteration 130/250, Loss: 0.0060\n",
      "Epoch 132/200, Iteration 131/250, Loss: 0.0099\n",
      "Epoch 132/200, Iteration 132/250, Loss: 0.0176\n",
      "Epoch 132/200, Iteration 133/250, Loss: 0.0099\n",
      "Epoch 132/200, Iteration 134/250, Loss: 0.0097\n",
      "Epoch 132/200, Iteration 135/250, Loss: 0.0149\n",
      "Epoch 132/200, Iteration 136/250, Loss: 0.0164\n",
      "Epoch 132/200, Iteration 137/250, Loss: 0.0088\n",
      "Epoch 132/200, Iteration 138/250, Loss: 0.0105\n",
      "Epoch 132/200, Iteration 139/250, Loss: 0.0107\n",
      "Epoch 132/200, Iteration 140/250, Loss: 0.0110\n",
      "Epoch 132/200, Iteration 141/250, Loss: 0.0124\n",
      "Epoch 132/200, Iteration 142/250, Loss: 0.0129\n",
      "Epoch 132/200, Iteration 143/250, Loss: 0.0342\n",
      "Epoch 132/200, Iteration 144/250, Loss: 0.0141\n",
      "Epoch 132/200, Iteration 145/250, Loss: 0.0107\n",
      "Epoch 132/200, Iteration 146/250, Loss: 0.0115\n",
      "Epoch 132/200, Iteration 147/250, Loss: 0.0167\n",
      "Epoch 132/200, Iteration 148/250, Loss: 0.0088\n",
      "Epoch 132/200, Iteration 149/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 150/250, Loss: 0.0101\n",
      "Epoch 132/200, Iteration 151/250, Loss: 0.0088\n",
      "Epoch 132/200, Iteration 152/250, Loss: 0.0104\n",
      "Epoch 132/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 132/200, Iteration 154/250, Loss: 0.0101\n",
      "Epoch 132/200, Iteration 155/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 156/250, Loss: 0.0143\n",
      "Epoch 132/200, Iteration 157/250, Loss: 0.0072\n",
      "Epoch 132/200, Iteration 158/250, Loss: 0.0302\n",
      "Epoch 132/200, Iteration 159/250, Loss: 0.0302\n",
      "Epoch 132/200, Iteration 160/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 132/200, Iteration 162/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 163/250, Loss: 0.0226\n",
      "Epoch 132/200, Iteration 164/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 165/250, Loss: 0.0205\n",
      "Epoch 132/200, Iteration 166/250, Loss: 0.0225\n",
      "Epoch 132/200, Iteration 167/250, Loss: 0.0132\n",
      "Epoch 132/200, Iteration 168/250, Loss: 0.0067\n",
      "Epoch 132/200, Iteration 169/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 170/250, Loss: 0.0166\n",
      "Epoch 132/200, Iteration 171/250, Loss: 0.0178\n",
      "Epoch 132/200, Iteration 172/250, Loss: 0.0368\n",
      "Epoch 132/200, Iteration 173/250, Loss: 0.0210\n",
      "Epoch 132/200, Iteration 174/250, Loss: 0.0116\n",
      "Epoch 132/200, Iteration 175/250, Loss: 0.0136\n",
      "Epoch 132/200, Iteration 176/250, Loss: 0.0128\n",
      "Epoch 132/200, Iteration 177/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 178/250, Loss: 0.0153\n",
      "Epoch 132/200, Iteration 179/250, Loss: 0.0077\n",
      "Epoch 132/200, Iteration 180/250, Loss: 0.0173\n",
      "Epoch 132/200, Iteration 181/250, Loss: 0.0081\n",
      "Epoch 132/200, Iteration 182/250, Loss: 0.0129\n",
      "Epoch 132/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 132/200, Iteration 184/250, Loss: 0.0268\n",
      "Epoch 132/200, Iteration 185/250, Loss: 0.0267\n",
      "Epoch 132/200, Iteration 186/250, Loss: 0.0078\n",
      "Epoch 132/200, Iteration 187/250, Loss: 0.0162\n",
      "Epoch 132/200, Iteration 188/250, Loss: 0.0167\n",
      "Epoch 132/200, Iteration 189/250, Loss: 0.0353\n",
      "Epoch 132/200, Iteration 190/250, Loss: 0.0148\n",
      "Epoch 132/200, Iteration 191/250, Loss: 0.0273\n",
      "Epoch 132/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 193/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 194/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 195/250, Loss: 0.0164\n",
      "Epoch 132/200, Iteration 196/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 197/250, Loss: 0.0403\n",
      "Epoch 132/200, Iteration 198/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 199/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 200/250, Loss: 0.0192\n",
      "Epoch 132/200, Iteration 201/250, Loss: 0.0151\n",
      "Epoch 132/200, Iteration 202/250, Loss: 0.0280\n",
      "Epoch 132/200, Iteration 203/250, Loss: 0.0103\n",
      "Epoch 132/200, Iteration 204/250, Loss: 0.0216\n",
      "Epoch 132/200, Iteration 205/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 206/250, Loss: 0.0177\n",
      "Epoch 132/200, Iteration 207/250, Loss: 0.0281\n",
      "Epoch 132/200, Iteration 208/250, Loss: 0.0202\n",
      "Epoch 132/200, Iteration 209/250, Loss: 0.0211\n",
      "Epoch 132/200, Iteration 210/250, Loss: 0.0079\n",
      "Epoch 132/200, Iteration 211/250, Loss: 0.0179\n",
      "Epoch 132/200, Iteration 212/250, Loss: 0.0191\n",
      "Epoch 132/200, Iteration 213/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 214/250, Loss: 0.0211\n",
      "Epoch 132/200, Iteration 215/250, Loss: 0.0135\n",
      "Epoch 132/200, Iteration 216/250, Loss: 0.0196\n",
      "Epoch 132/200, Iteration 217/250, Loss: 0.0131\n",
      "Epoch 132/200, Iteration 218/250, Loss: 0.0254\n",
      "Epoch 132/200, Iteration 219/250, Loss: 0.0163\n",
      "Epoch 132/200, Iteration 220/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 221/250, Loss: 0.0267\n",
      "Epoch 132/200, Iteration 222/250, Loss: 0.0130\n",
      "Epoch 132/200, Iteration 223/250, Loss: 0.0151\n",
      "Epoch 132/200, Iteration 224/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 225/250, Loss: 0.0366\n",
      "Epoch 132/200, Iteration 226/250, Loss: 0.0170\n",
      "Epoch 132/200, Iteration 227/250, Loss: 0.0067\n",
      "Epoch 132/200, Iteration 228/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 229/250, Loss: 0.0181\n",
      "Epoch 132/200, Iteration 230/250, Loss: 0.0088\n",
      "Epoch 132/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 132/200, Iteration 232/250, Loss: 0.0067\n",
      "Epoch 132/200, Iteration 233/250, Loss: 0.0100\n",
      "Epoch 132/200, Iteration 234/250, Loss: 0.0145\n",
      "Epoch 132/200, Iteration 235/250, Loss: 0.0137\n",
      "Epoch 132/200, Iteration 236/250, Loss: 0.0093\n",
      "Epoch 132/200, Iteration 237/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 238/250, Loss: 0.0139\n",
      "Epoch 132/200, Iteration 239/250, Loss: 0.0489\n",
      "Epoch 132/200, Iteration 240/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 241/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 132/200, Iteration 243/250, Loss: 0.0145\n",
      "Epoch 132/200, Iteration 244/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 132/200, Iteration 246/250, Loss: 0.0227\n",
      "Epoch 132/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 132/200, Iteration 248/250, Loss: 0.0084\n",
      "Epoch 132/200, Iteration 249/250, Loss: 0.0300\n",
      "Epoch 132/200, Iteration 250/250, Loss: 0.0122\n",
      "Train Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.005998, MRE: 0.616560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.006036, MRE: 1.022307 \n",
      "\n",
      "Epoch 133/200, Iteration 1/250, Loss: 0.0114\n",
      "Epoch 133/200, Iteration 2/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 3/250, Loss: 0.0120\n",
      "Epoch 133/200, Iteration 4/250, Loss: 0.0161\n",
      "Epoch 133/200, Iteration 5/250, Loss: 0.0156\n",
      "Epoch 133/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 7/250, Loss: 0.0167\n",
      "Epoch 133/200, Iteration 8/250, Loss: 0.0145\n",
      "Epoch 133/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 10/250, Loss: 0.0223\n",
      "Epoch 133/200, Iteration 11/250, Loss: 0.0086\n",
      "Epoch 133/200, Iteration 12/250, Loss: 0.0193\n",
      "Epoch 133/200, Iteration 13/250, Loss: 0.0079\n",
      "Epoch 133/200, Iteration 14/250, Loss: 0.0147\n",
      "Epoch 133/200, Iteration 15/250, Loss: 0.0147\n",
      "Epoch 133/200, Iteration 16/250, Loss: 0.0308\n",
      "Epoch 133/200, Iteration 17/250, Loss: 0.0230\n",
      "Epoch 133/200, Iteration 18/250, Loss: 0.0119\n",
      "Epoch 133/200, Iteration 19/250, Loss: 0.0108\n",
      "Epoch 133/200, Iteration 20/250, Loss: 0.0184\n",
      "Epoch 133/200, Iteration 21/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 23/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 24/250, Loss: 0.0132\n",
      "Epoch 133/200, Iteration 25/250, Loss: 0.0123\n",
      "Epoch 133/200, Iteration 26/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 27/250, Loss: 0.0190\n",
      "Epoch 133/200, Iteration 28/250, Loss: 0.0212\n",
      "Epoch 133/200, Iteration 29/250, Loss: 0.0122\n",
      "Epoch 133/200, Iteration 30/250, Loss: 0.0078\n",
      "Epoch 133/200, Iteration 31/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 32/250, Loss: 0.0201\n",
      "Epoch 133/200, Iteration 33/250, Loss: 0.0171\n",
      "Epoch 133/200, Iteration 34/250, Loss: 0.0317\n",
      "Epoch 133/200, Iteration 35/250, Loss: 0.0240\n",
      "Epoch 133/200, Iteration 36/250, Loss: 0.0168\n",
      "Epoch 133/200, Iteration 37/250, Loss: 0.0168\n",
      "Epoch 133/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 39/250, Loss: 0.0113\n",
      "Epoch 133/200, Iteration 40/250, Loss: 0.0289\n",
      "Epoch 133/200, Iteration 41/250, Loss: 0.0170\n",
      "Epoch 133/200, Iteration 42/250, Loss: 0.0078\n",
      "Epoch 133/200, Iteration 43/250, Loss: 0.0384\n",
      "Epoch 133/200, Iteration 44/250, Loss: 0.0084\n",
      "Epoch 133/200, Iteration 45/250, Loss: 0.0169\n",
      "Epoch 133/200, Iteration 46/250, Loss: 0.0120\n",
      "Epoch 133/200, Iteration 47/250, Loss: 0.0202\n",
      "Epoch 133/200, Iteration 48/250, Loss: 0.0110\n",
      "Epoch 133/200, Iteration 49/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 50/250, Loss: 0.0222\n",
      "Epoch 133/200, Iteration 51/250, Loss: 0.0092\n",
      "Epoch 133/200, Iteration 52/250, Loss: 0.0164\n",
      "Epoch 133/200, Iteration 53/250, Loss: 0.0173\n",
      "Epoch 133/200, Iteration 54/250, Loss: 0.0069\n",
      "Epoch 133/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 56/250, Loss: 0.0066\n",
      "Epoch 133/200, Iteration 57/250, Loss: 0.0395\n",
      "Epoch 133/200, Iteration 58/250, Loss: 0.0113\n",
      "Epoch 133/200, Iteration 59/250, Loss: 0.0061\n",
      "Epoch 133/200, Iteration 60/250, Loss: 0.0233\n",
      "Epoch 133/200, Iteration 61/250, Loss: 0.0269\n",
      "Epoch 133/200, Iteration 62/250, Loss: 0.0068\n",
      "Epoch 133/200, Iteration 63/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 64/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 65/250, Loss: 0.0111\n",
      "Epoch 133/200, Iteration 66/250, Loss: 0.0134\n",
      "Epoch 133/200, Iteration 67/250, Loss: 0.0151\n",
      "Epoch 133/200, Iteration 68/250, Loss: 0.0089\n",
      "Epoch 133/200, Iteration 69/250, Loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 133/200, Iteration 71/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 72/250, Loss: 0.0178\n",
      "Epoch 133/200, Iteration 73/250, Loss: 0.0269\n",
      "Epoch 133/200, Iteration 74/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 75/250, Loss: 0.0241\n",
      "Epoch 133/200, Iteration 76/250, Loss: 0.0260\n",
      "Epoch 133/200, Iteration 77/250, Loss: 0.0072\n",
      "Epoch 133/200, Iteration 78/250, Loss: 0.0165\n",
      "Epoch 133/200, Iteration 79/250, Loss: 0.0079\n",
      "Epoch 133/200, Iteration 80/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 81/250, Loss: 0.0133\n",
      "Epoch 133/200, Iteration 82/250, Loss: 0.0194\n",
      "Epoch 133/200, Iteration 83/250, Loss: 0.0104\n",
      "Epoch 133/200, Iteration 84/250, Loss: 0.0230\n",
      "Epoch 133/200, Iteration 85/250, Loss: 0.0071\n",
      "Epoch 133/200, Iteration 86/250, Loss: 0.0091\n",
      "Epoch 133/200, Iteration 87/250, Loss: 0.0139\n",
      "Epoch 133/200, Iteration 88/250, Loss: 0.0047\n",
      "Epoch 133/200, Iteration 89/250, Loss: 0.0104\n",
      "Epoch 133/200, Iteration 90/250, Loss: 0.0145\n",
      "Epoch 133/200, Iteration 91/250, Loss: 0.0066\n",
      "Epoch 133/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 93/250, Loss: 0.0121\n",
      "Epoch 133/200, Iteration 94/250, Loss: 0.0060\n",
      "Epoch 133/200, Iteration 95/250, Loss: 0.0070\n",
      "Epoch 133/200, Iteration 96/250, Loss: 0.0383\n",
      "Epoch 133/200, Iteration 97/250, Loss: 0.0072\n",
      "Epoch 133/200, Iteration 98/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 99/250, Loss: 0.0070\n",
      "Epoch 133/200, Iteration 100/250, Loss: 0.0287\n",
      "Epoch 133/200, Iteration 101/250, Loss: 0.0186\n",
      "Epoch 133/200, Iteration 102/250, Loss: 0.0111\n",
      "Epoch 133/200, Iteration 103/250, Loss: 0.0100\n",
      "Epoch 133/200, Iteration 104/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 105/250, Loss: 0.0125\n",
      "Epoch 133/200, Iteration 106/250, Loss: 0.0192\n",
      "Epoch 133/200, Iteration 107/250, Loss: 0.0073\n",
      "Epoch 133/200, Iteration 108/250, Loss: 0.0155\n",
      "Epoch 133/200, Iteration 109/250, Loss: 0.0476\n",
      "Epoch 133/200, Iteration 110/250, Loss: 0.0143\n",
      "Epoch 133/200, Iteration 111/250, Loss: 0.0278\n",
      "Epoch 133/200, Iteration 112/250, Loss: 0.0105\n",
      "Epoch 133/200, Iteration 113/250, Loss: 0.0139\n",
      "Epoch 133/200, Iteration 114/250, Loss: 0.0111\n",
      "Epoch 133/200, Iteration 115/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 133/200, Iteration 117/250, Loss: 0.0111\n",
      "Epoch 133/200, Iteration 118/250, Loss: 0.0282\n",
      "Epoch 133/200, Iteration 119/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 120/250, Loss: 0.0149\n",
      "Epoch 133/200, Iteration 121/250, Loss: 0.0123\n",
      "Epoch 133/200, Iteration 122/250, Loss: 0.0277\n",
      "Epoch 133/200, Iteration 123/250, Loss: 0.0192\n",
      "Epoch 133/200, Iteration 124/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 125/250, Loss: 0.0175\n",
      "Epoch 133/200, Iteration 126/250, Loss: 0.0247\n",
      "Epoch 133/200, Iteration 127/250, Loss: 0.0109\n",
      "Epoch 133/200, Iteration 128/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 129/250, Loss: 0.0089\n",
      "Epoch 133/200, Iteration 130/250, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 131/250, Loss: 0.0175\n",
      "Epoch 133/200, Iteration 132/250, Loss: 0.0087\n",
      "Epoch 133/200, Iteration 133/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 134/250, Loss: 0.0179\n",
      "Epoch 133/200, Iteration 135/250, Loss: 0.0292\n",
      "Epoch 133/200, Iteration 136/250, Loss: 0.0077\n",
      "Epoch 133/200, Iteration 137/250, Loss: 0.0223\n",
      "Epoch 133/200, Iteration 138/250, Loss: 0.0139\n",
      "Epoch 133/200, Iteration 139/250, Loss: 0.0112\n",
      "Epoch 133/200, Iteration 140/250, Loss: 0.0121\n",
      "Epoch 133/200, Iteration 141/250, Loss: 0.0069\n",
      "Epoch 133/200, Iteration 142/250, Loss: 0.0320\n",
      "Epoch 133/200, Iteration 143/250, Loss: 0.0100\n",
      "Epoch 133/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 145/250, Loss: 0.0129\n",
      "Epoch 133/200, Iteration 146/250, Loss: 0.0164\n",
      "Epoch 133/200, Iteration 147/250, Loss: 0.0321\n",
      "Epoch 133/200, Iteration 148/250, Loss: 0.0238\n",
      "Epoch 133/200, Iteration 149/250, Loss: 0.0207\n",
      "Epoch 133/200, Iteration 150/250, Loss: 0.0186\n",
      "Epoch 133/200, Iteration 151/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 152/250, Loss: 0.0169\n",
      "Epoch 133/200, Iteration 153/250, Loss: 0.0380\n",
      "Epoch 133/200, Iteration 154/250, Loss: 0.0117\n",
      "Epoch 133/200, Iteration 155/250, Loss: 0.0086\n",
      "Epoch 133/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 133/200, Iteration 157/250, Loss: 0.0080\n",
      "Epoch 133/200, Iteration 158/250, Loss: 0.0070\n",
      "Epoch 133/200, Iteration 159/250, Loss: 0.0164\n",
      "Epoch 133/200, Iteration 160/250, Loss: 0.0274\n",
      "Epoch 133/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 162/250, Loss: 0.0153\n",
      "Epoch 133/200, Iteration 163/250, Loss: 0.0134\n",
      "Epoch 133/200, Iteration 164/250, Loss: 0.0104\n",
      "Epoch 133/200, Iteration 165/250, Loss: 0.0247\n",
      "Epoch 133/200, Iteration 166/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 167/250, Loss: 0.0167\n",
      "Epoch 133/200, Iteration 168/250, Loss: 0.0088\n",
      "Epoch 133/200, Iteration 169/250, Loss: 0.0076\n",
      "Epoch 133/200, Iteration 170/250, Loss: 0.0066\n",
      "Epoch 133/200, Iteration 171/250, Loss: 0.0203\n",
      "Epoch 133/200, Iteration 172/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 173/250, Loss: 0.0277\n",
      "Epoch 133/200, Iteration 174/250, Loss: 0.0112\n",
      "Epoch 133/200, Iteration 175/250, Loss: 0.0161\n",
      "Epoch 133/200, Iteration 176/250, Loss: 0.0111\n",
      "Epoch 133/200, Iteration 177/250, Loss: 0.0117\n",
      "Epoch 133/200, Iteration 178/250, Loss: 0.0146\n",
      "Epoch 133/200, Iteration 179/250, Loss: 0.0322\n",
      "Epoch 133/200, Iteration 180/250, Loss: 0.0265\n",
      "Epoch 133/200, Iteration 181/250, Loss: 0.0252\n",
      "Epoch 133/200, Iteration 182/250, Loss: 0.0163\n",
      "Epoch 133/200, Iteration 183/250, Loss: 0.0168\n",
      "Epoch 133/200, Iteration 184/250, Loss: 0.0147\n",
      "Epoch 133/200, Iteration 185/250, Loss: 0.0371\n",
      "Epoch 133/200, Iteration 186/250, Loss: 0.0246\n",
      "Epoch 133/200, Iteration 187/250, Loss: 0.0272\n",
      "Epoch 133/200, Iteration 188/250, Loss: 0.0073\n",
      "Epoch 133/200, Iteration 189/250, Loss: 0.0071\n",
      "Epoch 133/200, Iteration 190/250, Loss: 0.0255\n",
      "Epoch 133/200, Iteration 191/250, Loss: 0.0065\n",
      "Epoch 133/200, Iteration 192/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 193/250, Loss: 0.0300\n",
      "Epoch 133/200, Iteration 194/250, Loss: 0.0213\n",
      "Epoch 133/200, Iteration 195/250, Loss: 0.0210\n",
      "Epoch 133/200, Iteration 196/250, Loss: 0.0213\n",
      "Epoch 133/200, Iteration 197/250, Loss: 0.0199\n",
      "Epoch 133/200, Iteration 198/250, Loss: 0.0209\n",
      "Epoch 133/200, Iteration 199/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 200/250, Loss: 0.0144\n",
      "Epoch 133/200, Iteration 201/250, Loss: 0.0107\n",
      "Epoch 133/200, Iteration 202/250, Loss: 0.0180\n",
      "Epoch 133/200, Iteration 203/250, Loss: 0.0156\n",
      "Epoch 133/200, Iteration 204/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 205/250, Loss: 0.0123\n",
      "Epoch 133/200, Iteration 206/250, Loss: 0.0133\n",
      "Epoch 133/200, Iteration 207/250, Loss: 0.0247\n",
      "Epoch 133/200, Iteration 208/250, Loss: 0.0373\n",
      "Epoch 133/200, Iteration 209/250, Loss: 0.0088\n",
      "Epoch 133/200, Iteration 210/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 211/250, Loss: 0.0089\n",
      "Epoch 133/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 133/200, Iteration 213/250, Loss: 0.0222\n",
      "Epoch 133/200, Iteration 214/250, Loss: 0.0134\n",
      "Epoch 133/200, Iteration 215/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 133/200, Iteration 217/250, Loss: 0.0173\n",
      "Epoch 133/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 133/200, Iteration 219/250, Loss: 0.0126\n",
      "Epoch 133/200, Iteration 220/250, Loss: 0.0073\n",
      "Epoch 133/200, Iteration 221/250, Loss: 0.0297\n",
      "Epoch 133/200, Iteration 222/250, Loss: 0.0144\n",
      "Epoch 133/200, Iteration 223/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 224/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 225/250, Loss: 0.0233\n",
      "Epoch 133/200, Iteration 226/250, Loss: 0.0100\n",
      "Epoch 133/200, Iteration 227/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 228/250, Loss: 0.0119\n",
      "Epoch 133/200, Iteration 229/250, Loss: 0.0182\n",
      "Epoch 133/200, Iteration 230/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 231/250, Loss: 0.0221\n",
      "Epoch 133/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 233/250, Loss: 0.0170\n",
      "Epoch 133/200, Iteration 234/250, Loss: 0.0135\n",
      "Epoch 133/200, Iteration 235/250, Loss: 0.0219\n",
      "Epoch 133/200, Iteration 236/250, Loss: 0.0284\n",
      "Epoch 133/200, Iteration 237/250, Loss: 0.0346\n",
      "Epoch 133/200, Iteration 238/250, Loss: 0.0231\n",
      "Epoch 133/200, Iteration 239/250, Loss: 0.0162\n",
      "Epoch 133/200, Iteration 240/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 241/250, Loss: 0.0088\n",
      "Epoch 133/200, Iteration 242/250, Loss: 0.0184\n",
      "Epoch 133/200, Iteration 243/250, Loss: 0.0202\n",
      "Epoch 133/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 133/200, Iteration 246/250, Loss: 0.0224\n",
      "Epoch 133/200, Iteration 247/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 248/250, Loss: 0.0232\n",
      "Epoch 133/200, Iteration 249/250, Loss: 0.0122\n",
      "Epoch 133/200, Iteration 250/250, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.21%, Avg loss: 0.005780, MRE: 0.601531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.005822, MRE: 0.882446 \n",
      "\n",
      "Epoch 134/200, Iteration 1/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 2/250, Loss: 0.0118\n",
      "Epoch 134/200, Iteration 3/250, Loss: 0.0229\n",
      "Epoch 134/200, Iteration 4/250, Loss: 0.0196\n",
      "Epoch 134/200, Iteration 5/250, Loss: 0.0232\n",
      "Epoch 134/200, Iteration 6/250, Loss: 0.0263\n",
      "Epoch 134/200, Iteration 7/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 8/250, Loss: 0.0097\n",
      "Epoch 134/200, Iteration 9/250, Loss: 0.0150\n",
      "Epoch 134/200, Iteration 10/250, Loss: 0.0074\n",
      "Epoch 134/200, Iteration 11/250, Loss: 0.0100\n",
      "Epoch 134/200, Iteration 12/250, Loss: 0.0134\n",
      "Epoch 134/200, Iteration 13/250, Loss: 0.0100\n",
      "Epoch 134/200, Iteration 14/250, Loss: 0.0159\n",
      "Epoch 134/200, Iteration 15/250, Loss: 0.0061\n",
      "Epoch 134/200, Iteration 16/250, Loss: 0.0083\n",
      "Epoch 134/200, Iteration 17/250, Loss: 0.0138\n",
      "Epoch 134/200, Iteration 18/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 19/250, Loss: 0.0194\n",
      "Epoch 134/200, Iteration 20/250, Loss: 0.0179\n",
      "Epoch 134/200, Iteration 21/250, Loss: 0.0095\n",
      "Epoch 134/200, Iteration 22/250, Loss: 0.0121\n",
      "Epoch 134/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 134/200, Iteration 24/250, Loss: 0.0094\n",
      "Epoch 134/200, Iteration 25/250, Loss: 0.0127\n",
      "Epoch 134/200, Iteration 26/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 27/250, Loss: 0.0069\n",
      "Epoch 134/200, Iteration 28/250, Loss: 0.0199\n",
      "Epoch 134/200, Iteration 29/250, Loss: 0.0059\n",
      "Epoch 134/200, Iteration 30/250, Loss: 0.0139\n",
      "Epoch 134/200, Iteration 31/250, Loss: 0.0259\n",
      "Epoch 134/200, Iteration 32/250, Loss: 0.0323\n",
      "Epoch 134/200, Iteration 33/250, Loss: 0.0266\n",
      "Epoch 134/200, Iteration 34/250, Loss: 0.0080\n",
      "Epoch 134/200, Iteration 35/250, Loss: 0.0162\n",
      "Epoch 134/200, Iteration 36/250, Loss: 0.0159\n",
      "Epoch 134/200, Iteration 37/250, Loss: 0.0184\n",
      "Epoch 134/200, Iteration 38/250, Loss: 0.0084\n",
      "Epoch 134/200, Iteration 39/250, Loss: 0.0198\n",
      "Epoch 134/200, Iteration 40/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 41/250, Loss: 0.0098\n",
      "Epoch 134/200, Iteration 42/250, Loss: 0.0081\n",
      "Epoch 134/200, Iteration 43/250, Loss: 0.0112\n",
      "Epoch 134/200, Iteration 44/250, Loss: 0.0208\n",
      "Epoch 134/200, Iteration 45/250, Loss: 0.0322\n",
      "Epoch 134/200, Iteration 46/250, Loss: 0.0097\n",
      "Epoch 134/200, Iteration 47/250, Loss: 0.0127\n",
      "Epoch 134/200, Iteration 48/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 49/250, Loss: 0.0063\n",
      "Epoch 134/200, Iteration 50/250, Loss: 0.0092\n",
      "Epoch 134/200, Iteration 51/250, Loss: 0.0070\n",
      "Epoch 134/200, Iteration 52/250, Loss: 0.0073\n",
      "Epoch 134/200, Iteration 53/250, Loss: 0.0262\n",
      "Epoch 134/200, Iteration 54/250, Loss: 0.0094\n",
      "Epoch 134/200, Iteration 55/250, Loss: 0.0196\n",
      "Epoch 134/200, Iteration 56/250, Loss: 0.0123\n",
      "Epoch 134/200, Iteration 57/250, Loss: 0.0177\n",
      "Epoch 134/200, Iteration 58/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 59/250, Loss: 0.0079\n",
      "Epoch 134/200, Iteration 60/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 61/250, Loss: 0.0100\n",
      "Epoch 134/200, Iteration 62/250, Loss: 0.0095\n",
      "Epoch 134/200, Iteration 63/250, Loss: 0.0190\n",
      "Epoch 134/200, Iteration 64/250, Loss: 0.0143\n",
      "Epoch 134/200, Iteration 65/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 66/250, Loss: 0.0067\n",
      "Epoch 134/200, Iteration 67/250, Loss: 0.0163\n",
      "Epoch 134/200, Iteration 68/250, Loss: 0.0149\n",
      "Epoch 134/200, Iteration 69/250, Loss: 0.0376\n",
      "Epoch 134/200, Iteration 70/250, Loss: 0.0122\n",
      "Epoch 134/200, Iteration 71/250, Loss: 0.0090\n",
      "Epoch 134/200, Iteration 72/250, Loss: 0.0181\n",
      "Epoch 134/200, Iteration 73/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 134/200, Iteration 75/250, Loss: 0.0080\n",
      "Epoch 134/200, Iteration 76/250, Loss: 0.0079\n",
      "Epoch 134/200, Iteration 77/250, Loss: 0.0082\n",
      "Epoch 134/200, Iteration 78/250, Loss: 0.0108\n",
      "Epoch 134/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 80/250, Loss: 0.0083\n",
      "Epoch 134/200, Iteration 81/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 82/250, Loss: 0.0076\n",
      "Epoch 134/200, Iteration 83/250, Loss: 0.0086\n",
      "Epoch 134/200, Iteration 84/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 85/250, Loss: 0.0113\n",
      "Epoch 134/200, Iteration 86/250, Loss: 0.0148\n",
      "Epoch 134/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 88/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 89/250, Loss: 0.0082\n",
      "Epoch 134/200, Iteration 90/250, Loss: 0.0194\n",
      "Epoch 134/200, Iteration 91/250, Loss: 0.0240\n",
      "Epoch 134/200, Iteration 92/250, Loss: 0.0177\n",
      "Epoch 134/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 94/250, Loss: 0.0109\n",
      "Epoch 134/200, Iteration 95/250, Loss: 0.0233\n",
      "Epoch 134/200, Iteration 96/250, Loss: 0.0354\n",
      "Epoch 134/200, Iteration 97/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 98/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 99/250, Loss: 0.0088\n",
      "Epoch 134/200, Iteration 100/250, Loss: 0.0167\n",
      "Epoch 134/200, Iteration 101/250, Loss: 0.0253\n",
      "Epoch 134/200, Iteration 102/250, Loss: 0.0066\n",
      "Epoch 134/200, Iteration 103/250, Loss: 0.0112\n",
      "Epoch 134/200, Iteration 104/250, Loss: 0.0104\n",
      "Epoch 134/200, Iteration 105/250, Loss: 0.0148\n",
      "Epoch 134/200, Iteration 106/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 107/250, Loss: 0.0090\n",
      "Epoch 134/200, Iteration 108/250, Loss: 0.0075\n",
      "Epoch 134/200, Iteration 109/250, Loss: 0.0135\n",
      "Epoch 134/200, Iteration 110/250, Loss: 0.0218\n",
      "Epoch 134/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 134/200, Iteration 112/250, Loss: 0.0274\n",
      "Epoch 134/200, Iteration 113/250, Loss: 0.0113\n",
      "Epoch 134/200, Iteration 114/250, Loss: 0.0073\n",
      "Epoch 134/200, Iteration 115/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 116/250, Loss: 0.0090\n",
      "Epoch 134/200, Iteration 117/250, Loss: 0.0248\n",
      "Epoch 134/200, Iteration 118/250, Loss: 0.0082\n",
      "Epoch 134/200, Iteration 119/250, Loss: 0.0187\n",
      "Epoch 134/200, Iteration 120/250, Loss: 0.0184\n",
      "Epoch 134/200, Iteration 121/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 122/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 123/250, Loss: 0.0265\n",
      "Epoch 134/200, Iteration 124/250, Loss: 0.0127\n",
      "Epoch 134/200, Iteration 125/250, Loss: 0.0181\n",
      "Epoch 134/200, Iteration 126/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 127/250, Loss: 0.0193\n",
      "Epoch 134/200, Iteration 128/250, Loss: 0.0388\n",
      "Epoch 134/200, Iteration 129/250, Loss: 0.0139\n",
      "Epoch 134/200, Iteration 130/250, Loss: 0.0201\n",
      "Epoch 134/200, Iteration 131/250, Loss: 0.0319\n",
      "Epoch 134/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 134/200, Iteration 133/250, Loss: 0.0126\n",
      "Epoch 134/200, Iteration 134/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 135/250, Loss: 0.0221\n",
      "Epoch 134/200, Iteration 136/250, Loss: 0.0086\n",
      "Epoch 134/200, Iteration 137/250, Loss: 0.0065\n",
      "Epoch 134/200, Iteration 138/250, Loss: 0.0257\n",
      "Epoch 134/200, Iteration 139/250, Loss: 0.0190\n",
      "Epoch 134/200, Iteration 140/250, Loss: 0.0070\n",
      "Epoch 134/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 134/200, Iteration 142/250, Loss: 0.0275\n",
      "Epoch 134/200, Iteration 143/250, Loss: 0.0201\n",
      "Epoch 134/200, Iteration 144/250, Loss: 0.0149\n",
      "Epoch 134/200, Iteration 145/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 146/250, Loss: 0.0246\n",
      "Epoch 134/200, Iteration 147/250, Loss: 0.0198\n",
      "Epoch 134/200, Iteration 148/250, Loss: 0.0206\n",
      "Epoch 134/200, Iteration 149/250, Loss: 0.0062\n",
      "Epoch 134/200, Iteration 150/250, Loss: 0.0218\n",
      "Epoch 134/200, Iteration 151/250, Loss: 0.0296\n",
      "Epoch 134/200, Iteration 152/250, Loss: 0.0160\n",
      "Epoch 134/200, Iteration 153/250, Loss: 0.0068\n",
      "Epoch 134/200, Iteration 154/250, Loss: 0.0108\n",
      "Epoch 134/200, Iteration 155/250, Loss: 0.0103\n",
      "Epoch 134/200, Iteration 156/250, Loss: 0.0125\n",
      "Epoch 134/200, Iteration 157/250, Loss: 0.0281\n",
      "Epoch 134/200, Iteration 158/250, Loss: 0.0236\n",
      "Epoch 134/200, Iteration 159/250, Loss: 0.0191\n",
      "Epoch 134/200, Iteration 160/250, Loss: 0.0197\n",
      "Epoch 134/200, Iteration 161/250, Loss: 0.0161\n",
      "Epoch 134/200, Iteration 162/250, Loss: 0.0102\n",
      "Epoch 134/200, Iteration 163/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 164/250, Loss: 0.0147\n",
      "Epoch 134/200, Iteration 165/250, Loss: 0.0095\n",
      "Epoch 134/200, Iteration 166/250, Loss: 0.0498\n",
      "Epoch 134/200, Iteration 167/250, Loss: 0.0084\n",
      "Epoch 134/200, Iteration 168/250, Loss: 0.0235\n",
      "Epoch 134/200, Iteration 169/250, Loss: 0.0209\n",
      "Epoch 134/200, Iteration 170/250, Loss: 0.0120\n",
      "Epoch 134/200, Iteration 171/250, Loss: 0.0339\n",
      "Epoch 134/200, Iteration 172/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 173/250, Loss: 0.0135\n",
      "Epoch 134/200, Iteration 174/250, Loss: 0.0269\n",
      "Epoch 134/200, Iteration 175/250, Loss: 0.0133\n",
      "Epoch 134/200, Iteration 176/250, Loss: 0.0117\n",
      "Epoch 134/200, Iteration 177/250, Loss: 0.0149\n",
      "Epoch 134/200, Iteration 178/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 179/250, Loss: 0.0130\n",
      "Epoch 134/200, Iteration 180/250, Loss: 0.0276\n",
      "Epoch 134/200, Iteration 181/250, Loss: 0.0087\n",
      "Epoch 134/200, Iteration 182/250, Loss: 0.0139\n",
      "Epoch 134/200, Iteration 183/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 184/250, Loss: 0.0300\n",
      "Epoch 134/200, Iteration 185/250, Loss: 0.0089\n",
      "Epoch 134/200, Iteration 186/250, Loss: 0.0081\n",
      "Epoch 134/200, Iteration 187/250, Loss: 0.0060\n",
      "Epoch 134/200, Iteration 188/250, Loss: 0.0258\n",
      "Epoch 134/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 134/200, Iteration 190/250, Loss: 0.0150\n",
      "Epoch 134/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 134/200, Iteration 192/250, Loss: 0.0270\n",
      "Epoch 134/200, Iteration 193/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 194/250, Loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200, Iteration 195/250, Loss: 0.0063\n",
      "Epoch 134/200, Iteration 196/250, Loss: 0.0240\n",
      "Epoch 134/200, Iteration 197/250, Loss: 0.0088\n",
      "Epoch 134/200, Iteration 198/250, Loss: 0.0143\n",
      "Epoch 134/200, Iteration 199/250, Loss: 0.0173\n",
      "Epoch 134/200, Iteration 200/250, Loss: 0.0144\n",
      "Epoch 134/200, Iteration 201/250, Loss: 0.0208\n",
      "Epoch 134/200, Iteration 202/250, Loss: 0.0134\n",
      "Epoch 134/200, Iteration 203/250, Loss: 0.0205\n",
      "Epoch 134/200, Iteration 204/250, Loss: 0.0288\n",
      "Epoch 134/200, Iteration 205/250, Loss: 0.0160\n",
      "Epoch 134/200, Iteration 206/250, Loss: 0.0160\n",
      "Epoch 134/200, Iteration 207/250, Loss: 0.0247\n",
      "Epoch 134/200, Iteration 208/250, Loss: 0.0089\n",
      "Epoch 134/200, Iteration 209/250, Loss: 0.0123\n",
      "Epoch 134/200, Iteration 210/250, Loss: 0.0155\n",
      "Epoch 134/200, Iteration 211/250, Loss: 0.0157\n",
      "Epoch 134/200, Iteration 212/250, Loss: 0.0138\n",
      "Epoch 134/200, Iteration 213/250, Loss: 0.0123\n",
      "Epoch 134/200, Iteration 214/250, Loss: 0.0077\n",
      "Epoch 134/200, Iteration 215/250, Loss: 0.0360\n",
      "Epoch 134/200, Iteration 216/250, Loss: 0.0112\n",
      "Epoch 134/200, Iteration 217/250, Loss: 0.0080\n",
      "Epoch 134/200, Iteration 218/250, Loss: 0.0355\n",
      "Epoch 134/200, Iteration 219/250, Loss: 0.0249\n",
      "Epoch 134/200, Iteration 220/250, Loss: 0.0189\n",
      "Epoch 134/200, Iteration 221/250, Loss: 0.0322\n",
      "Epoch 134/200, Iteration 222/250, Loss: 0.0078\n",
      "Epoch 134/200, Iteration 223/250, Loss: 0.0158\n",
      "Epoch 134/200, Iteration 224/250, Loss: 0.0161\n",
      "Epoch 134/200, Iteration 225/250, Loss: 0.0331\n",
      "Epoch 134/200, Iteration 226/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 227/250, Loss: 0.0144\n",
      "Epoch 134/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 134/200, Iteration 229/250, Loss: 0.0206\n",
      "Epoch 134/200, Iteration 230/250, Loss: 0.0167\n",
      "Epoch 134/200, Iteration 231/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 232/250, Loss: 0.0295\n",
      "Epoch 134/200, Iteration 233/250, Loss: 0.0243\n",
      "Epoch 134/200, Iteration 234/250, Loss: 0.0333\n",
      "Epoch 134/200, Iteration 235/250, Loss: 0.0236\n",
      "Epoch 134/200, Iteration 236/250, Loss: 0.0203\n",
      "Epoch 134/200, Iteration 237/250, Loss: 0.0231\n",
      "Epoch 134/200, Iteration 238/250, Loss: 0.0160\n",
      "Epoch 134/200, Iteration 239/250, Loss: 0.0097\n",
      "Epoch 134/200, Iteration 240/250, Loss: 0.0083\n",
      "Epoch 134/200, Iteration 241/250, Loss: 0.0255\n",
      "Epoch 134/200, Iteration 242/250, Loss: 0.0179\n",
      "Epoch 134/200, Iteration 243/250, Loss: 0.0422\n",
      "Epoch 134/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 245/250, Loss: 0.0176\n",
      "Epoch 134/200, Iteration 246/250, Loss: 0.0192\n",
      "Epoch 134/200, Iteration 247/250, Loss: 0.0194\n",
      "Epoch 134/200, Iteration 248/250, Loss: 0.0190\n",
      "Epoch 134/200, Iteration 249/250, Loss: 0.0246\n",
      "Epoch 134/200, Iteration 250/250, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 97.71%, Avg loss: 0.006445, MRE: 0.659866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.006360, MRE: 1.135079 \n",
      "\n",
      "Epoch 135/200, Iteration 1/250, Loss: 0.0086\n",
      "Epoch 135/200, Iteration 2/250, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 3/250, Loss: 0.0074\n",
      "Epoch 135/200, Iteration 4/250, Loss: 0.0343\n",
      "Epoch 135/200, Iteration 5/250, Loss: 0.0145\n",
      "Epoch 135/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 7/250, Loss: 0.0128\n",
      "Epoch 135/200, Iteration 8/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 9/250, Loss: 0.0148\n",
      "Epoch 135/200, Iteration 10/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 11/250, Loss: 0.0140\n",
      "Epoch 135/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 135/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 14/250, Loss: 0.0070\n",
      "Epoch 135/200, Iteration 15/250, Loss: 0.0173\n",
      "Epoch 135/200, Iteration 16/250, Loss: 0.0161\n",
      "Epoch 135/200, Iteration 17/250, Loss: 0.0166\n",
      "Epoch 135/200, Iteration 18/250, Loss: 0.0231\n",
      "Epoch 135/200, Iteration 19/250, Loss: 0.0252\n",
      "Epoch 135/200, Iteration 20/250, Loss: 0.0137\n",
      "Epoch 135/200, Iteration 21/250, Loss: 0.0144\n",
      "Epoch 135/200, Iteration 22/250, Loss: 0.0081\n",
      "Epoch 135/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 24/250, Loss: 0.0224\n",
      "Epoch 135/200, Iteration 25/250, Loss: 0.0076\n",
      "Epoch 135/200, Iteration 26/250, Loss: 0.0163\n",
      "Epoch 135/200, Iteration 27/250, Loss: 0.0123\n",
      "Epoch 135/200, Iteration 28/250, Loss: 0.0126\n",
      "Epoch 135/200, Iteration 29/250, Loss: 0.0156\n",
      "Epoch 135/200, Iteration 30/250, Loss: 0.0123\n",
      "Epoch 135/200, Iteration 31/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 32/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 33/250, Loss: 0.0147\n",
      "Epoch 135/200, Iteration 34/250, Loss: 0.0136\n",
      "Epoch 135/200, Iteration 35/250, Loss: 0.0081\n",
      "Epoch 135/200, Iteration 36/250, Loss: 0.0248\n",
      "Epoch 135/200, Iteration 37/250, Loss: 0.0125\n",
      "Epoch 135/200, Iteration 38/250, Loss: 0.0287\n",
      "Epoch 135/200, Iteration 39/250, Loss: 0.0191\n",
      "Epoch 135/200, Iteration 40/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 135/200, Iteration 42/250, Loss: 0.0108\n",
      "Epoch 135/200, Iteration 43/250, Loss: 0.0129\n",
      "Epoch 135/200, Iteration 44/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 45/250, Loss: 0.0150\n",
      "Epoch 135/200, Iteration 46/250, Loss: 0.0063\n",
      "Epoch 135/200, Iteration 47/250, Loss: 0.0114\n",
      "Epoch 135/200, Iteration 48/250, Loss: 0.0191\n",
      "Epoch 135/200, Iteration 49/250, Loss: 0.0135\n",
      "Epoch 135/200, Iteration 50/250, Loss: 0.0197\n",
      "Epoch 135/200, Iteration 51/250, Loss: 0.0158\n",
      "Epoch 135/200, Iteration 52/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 53/250, Loss: 0.0194\n",
      "Epoch 135/200, Iteration 54/250, Loss: 0.0321\n",
      "Epoch 135/200, Iteration 55/250, Loss: 0.0356\n",
      "Epoch 135/200, Iteration 56/250, Loss: 0.0217\n",
      "Epoch 135/200, Iteration 57/250, Loss: 0.0062\n",
      "Epoch 135/200, Iteration 58/250, Loss: 0.0065\n",
      "Epoch 135/200, Iteration 59/250, Loss: 0.0185\n",
      "Epoch 135/200, Iteration 60/250, Loss: 0.0088\n",
      "Epoch 135/200, Iteration 61/250, Loss: 0.0175\n",
      "Epoch 135/200, Iteration 62/250, Loss: 0.0263\n",
      "Epoch 135/200, Iteration 63/250, Loss: 0.0115\n",
      "Epoch 135/200, Iteration 64/250, Loss: 0.0128\n",
      "Epoch 135/200, Iteration 65/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 66/250, Loss: 0.0145\n",
      "Epoch 135/200, Iteration 67/250, Loss: 0.0299\n",
      "Epoch 135/200, Iteration 68/250, Loss: 0.0073\n",
      "Epoch 135/200, Iteration 69/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 70/250, Loss: 0.0113\n",
      "Epoch 135/200, Iteration 71/250, Loss: 0.0142\n",
      "Epoch 135/200, Iteration 72/250, Loss: 0.0109\n",
      "Epoch 135/200, Iteration 73/250, Loss: 0.0204\n",
      "Epoch 135/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 135/200, Iteration 75/250, Loss: 0.0162\n",
      "Epoch 135/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 135/200, Iteration 77/250, Loss: 0.0141\n",
      "Epoch 135/200, Iteration 78/250, Loss: 0.0138\n",
      "Epoch 135/200, Iteration 79/250, Loss: 0.0109\n",
      "Epoch 135/200, Iteration 80/250, Loss: 0.0153\n",
      "Epoch 135/200, Iteration 81/250, Loss: 0.0078\n",
      "Epoch 135/200, Iteration 82/250, Loss: 0.0206\n",
      "Epoch 135/200, Iteration 83/250, Loss: 0.0176\n",
      "Epoch 135/200, Iteration 84/250, Loss: 0.0095\n",
      "Epoch 135/200, Iteration 85/250, Loss: 0.0198\n",
      "Epoch 135/200, Iteration 86/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 87/250, Loss: 0.0136\n",
      "Epoch 135/200, Iteration 88/250, Loss: 0.0160\n",
      "Epoch 135/200, Iteration 89/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 90/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 91/250, Loss: 0.0191\n",
      "Epoch 135/200, Iteration 92/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 93/250, Loss: 0.0159\n",
      "Epoch 135/200, Iteration 94/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 95/250, Loss: 0.0120\n",
      "Epoch 135/200, Iteration 96/250, Loss: 0.0086\n",
      "Epoch 135/200, Iteration 97/250, Loss: 0.0129\n",
      "Epoch 135/200, Iteration 98/250, Loss: 0.0076\n",
      "Epoch 135/200, Iteration 99/250, Loss: 0.0229\n",
      "Epoch 135/200, Iteration 100/250, Loss: 0.0201\n",
      "Epoch 135/200, Iteration 101/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 102/250, Loss: 0.0155\n",
      "Epoch 135/200, Iteration 103/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 104/250, Loss: 0.0352\n",
      "Epoch 135/200, Iteration 105/250, Loss: 0.0173\n",
      "Epoch 135/200, Iteration 106/250, Loss: 0.0137\n",
      "Epoch 135/200, Iteration 107/250, Loss: 0.0121\n",
      "Epoch 135/200, Iteration 108/250, Loss: 0.0080\n",
      "Epoch 135/200, Iteration 109/250, Loss: 0.0135\n",
      "Epoch 135/200, Iteration 110/250, Loss: 0.0089\n",
      "Epoch 135/200, Iteration 111/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 112/250, Loss: 0.0200\n",
      "Epoch 135/200, Iteration 113/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 114/250, Loss: 0.0095\n",
      "Epoch 135/200, Iteration 115/250, Loss: 0.0326\n",
      "Epoch 135/200, Iteration 116/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 117/250, Loss: 0.0205\n",
      "Epoch 135/200, Iteration 118/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 119/250, Loss: 0.0132\n",
      "Epoch 135/200, Iteration 120/250, Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200, Iteration 121/250, Loss: 0.0077\n",
      "Epoch 135/200, Iteration 122/250, Loss: 0.0067\n",
      "Epoch 135/200, Iteration 123/250, Loss: 0.0261\n",
      "Epoch 135/200, Iteration 124/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 135/200, Iteration 126/250, Loss: 0.0062\n",
      "Epoch 135/200, Iteration 127/250, Loss: 0.0059\n",
      "Epoch 135/200, Iteration 128/250, Loss: 0.0072\n",
      "Epoch 135/200, Iteration 129/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 130/250, Loss: 0.0146\n",
      "Epoch 135/200, Iteration 131/250, Loss: 0.0161\n",
      "Epoch 135/200, Iteration 132/250, Loss: 0.0179\n",
      "Epoch 135/200, Iteration 133/250, Loss: 0.0223\n",
      "Epoch 135/200, Iteration 134/250, Loss: 0.0088\n",
      "Epoch 135/200, Iteration 135/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 136/250, Loss: 0.0084\n",
      "Epoch 135/200, Iteration 137/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 138/250, Loss: 0.0151\n",
      "Epoch 135/200, Iteration 139/250, Loss: 0.0149\n",
      "Epoch 135/200, Iteration 140/250, Loss: 0.0272\n",
      "Epoch 135/200, Iteration 141/250, Loss: 0.0067\n",
      "Epoch 135/200, Iteration 142/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 143/250, Loss: 0.0371\n",
      "Epoch 135/200, Iteration 144/250, Loss: 0.0269\n",
      "Epoch 135/200, Iteration 145/250, Loss: 0.0214\n",
      "Epoch 135/200, Iteration 146/250, Loss: 0.0194\n",
      "Epoch 135/200, Iteration 147/250, Loss: 0.0112\n",
      "Epoch 135/200, Iteration 148/250, Loss: 0.0244\n",
      "Epoch 135/200, Iteration 149/250, Loss: 0.0117\n",
      "Epoch 135/200, Iteration 150/250, Loss: 0.0262\n",
      "Epoch 135/200, Iteration 151/250, Loss: 0.0357\n",
      "Epoch 135/200, Iteration 152/250, Loss: 0.0139\n",
      "Epoch 135/200, Iteration 153/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 135/200, Iteration 155/250, Loss: 0.0164\n",
      "Epoch 135/200, Iteration 156/250, Loss: 0.0077\n",
      "Epoch 135/200, Iteration 157/250, Loss: 0.0141\n",
      "Epoch 135/200, Iteration 158/250, Loss: 0.0176\n",
      "Epoch 135/200, Iteration 159/250, Loss: 0.0202\n",
      "Epoch 135/200, Iteration 160/250, Loss: 0.0156\n",
      "Epoch 135/200, Iteration 161/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 162/250, Loss: 0.0206\n",
      "Epoch 135/200, Iteration 163/250, Loss: 0.0078\n",
      "Epoch 135/200, Iteration 164/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 165/250, Loss: 0.0089\n",
      "Epoch 135/200, Iteration 166/250, Loss: 0.0153\n",
      "Epoch 135/200, Iteration 167/250, Loss: 0.0171\n",
      "Epoch 135/200, Iteration 168/250, Loss: 0.0063\n",
      "Epoch 135/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 170/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 171/250, Loss: 0.0250\n",
      "Epoch 135/200, Iteration 172/250, Loss: 0.0099\n",
      "Epoch 135/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 135/200, Iteration 174/250, Loss: 0.0223\n",
      "Epoch 135/200, Iteration 175/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 176/250, Loss: 0.0411\n",
      "Epoch 135/200, Iteration 177/250, Loss: 0.0194\n",
      "Epoch 135/200, Iteration 178/250, Loss: 0.0123\n",
      "Epoch 135/200, Iteration 179/250, Loss: 0.0077\n",
      "Epoch 135/200, Iteration 180/250, Loss: 0.0131\n",
      "Epoch 135/200, Iteration 181/250, Loss: 0.0162\n",
      "Epoch 135/200, Iteration 182/250, Loss: 0.0133\n",
      "Epoch 135/200, Iteration 183/250, Loss: 0.0148\n",
      "Epoch 135/200, Iteration 184/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 185/250, Loss: 0.0146\n",
      "Epoch 135/200, Iteration 186/250, Loss: 0.0105\n",
      "Epoch 135/200, Iteration 187/250, Loss: 0.0250\n",
      "Epoch 135/200, Iteration 188/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 189/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 190/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 191/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 192/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 193/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 194/250, Loss: 0.0173\n",
      "Epoch 135/200, Iteration 195/250, Loss: 0.0067\n",
      "Epoch 135/200, Iteration 196/250, Loss: 0.0112\n",
      "Epoch 135/200, Iteration 197/250, Loss: 0.0231\n",
      "Epoch 135/200, Iteration 198/250, Loss: 0.0125\n",
      "Epoch 135/200, Iteration 199/250, Loss: 0.0107\n",
      "Epoch 135/200, Iteration 200/250, Loss: 0.0147\n",
      "Epoch 135/200, Iteration 201/250, Loss: 0.0177\n",
      "Epoch 135/200, Iteration 202/250, Loss: 0.0173\n",
      "Epoch 135/200, Iteration 203/250, Loss: 0.0170\n",
      "Epoch 135/200, Iteration 204/250, Loss: 0.0236\n",
      "Epoch 135/200, Iteration 205/250, Loss: 0.0113\n",
      "Epoch 135/200, Iteration 206/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 207/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 208/250, Loss: 0.0153\n",
      "Epoch 135/200, Iteration 209/250, Loss: 0.0161\n",
      "Epoch 135/200, Iteration 210/250, Loss: 0.0162\n",
      "Epoch 135/200, Iteration 211/250, Loss: 0.0088\n",
      "Epoch 135/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 213/250, Loss: 0.0073\n",
      "Epoch 135/200, Iteration 214/250, Loss: 0.0309\n",
      "Epoch 135/200, Iteration 215/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 216/250, Loss: 0.0101\n",
      "Epoch 135/200, Iteration 217/250, Loss: 0.0142\n",
      "Epoch 135/200, Iteration 218/250, Loss: 0.0182\n",
      "Epoch 135/200, Iteration 219/250, Loss: 0.0151\n",
      "Epoch 135/200, Iteration 220/250, Loss: 0.0214\n",
      "Epoch 135/200, Iteration 221/250, Loss: 0.0069\n",
      "Epoch 135/200, Iteration 222/250, Loss: 0.0095\n",
      "Epoch 135/200, Iteration 223/250, Loss: 0.0141\n",
      "Epoch 135/200, Iteration 224/250, Loss: 0.0212\n",
      "Epoch 135/200, Iteration 225/250, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 226/250, Loss: 0.0128\n",
      "Epoch 135/200, Iteration 227/250, Loss: 0.0110\n",
      "Epoch 135/200, Iteration 228/250, Loss: 0.0146\n",
      "Epoch 135/200, Iteration 229/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 230/250, Loss: 0.0234\n",
      "Epoch 135/200, Iteration 231/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 232/250, Loss: 0.0069\n",
      "Epoch 135/200, Iteration 233/250, Loss: 0.0146\n",
      "Epoch 135/200, Iteration 234/250, Loss: 0.0298\n",
      "Epoch 135/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 236/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 237/250, Loss: 0.0201\n",
      "Epoch 135/200, Iteration 238/250, Loss: 0.0341\n",
      "Epoch 135/200, Iteration 239/250, Loss: 0.0133\n",
      "Epoch 135/200, Iteration 240/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 241/250, Loss: 0.0192\n",
      "Epoch 135/200, Iteration 242/250, Loss: 0.0099\n",
      "Epoch 135/200, Iteration 243/250, Loss: 0.0263\n",
      "Epoch 135/200, Iteration 244/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 245/250, Loss: 0.0272\n",
      "Epoch 135/200, Iteration 246/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 247/250, Loss: 0.0114\n",
      "Epoch 135/200, Iteration 248/250, Loss: 0.0139\n",
      "Epoch 135/200, Iteration 249/250, Loss: 0.0163\n",
      "Epoch 135/200, Iteration 250/250, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 82.69%, Avg loss: 0.007078, MRE: 0.626916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.007177, MRE: 0.920433 \n",
      "\n",
      "Epoch 136/200, Iteration 1/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 2/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 3/250, Loss: 0.0184\n",
      "Epoch 136/200, Iteration 4/250, Loss: 0.0183\n",
      "Epoch 136/200, Iteration 5/250, Loss: 0.0136\n",
      "Epoch 136/200, Iteration 6/250, Loss: 0.0140\n",
      "Epoch 136/200, Iteration 7/250, Loss: 0.0368\n",
      "Epoch 136/200, Iteration 8/250, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 9/250, Loss: 0.0145\n",
      "Epoch 136/200, Iteration 10/250, Loss: 0.0182\n",
      "Epoch 136/200, Iteration 11/250, Loss: 0.0175\n",
      "Epoch 136/200, Iteration 12/250, Loss: 0.0140\n",
      "Epoch 136/200, Iteration 13/250, Loss: 0.0074\n",
      "Epoch 136/200, Iteration 14/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 15/250, Loss: 0.0115\n",
      "Epoch 136/200, Iteration 16/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 17/250, Loss: 0.0193\n",
      "Epoch 136/200, Iteration 18/250, Loss: 0.0164\n",
      "Epoch 136/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 136/200, Iteration 20/250, Loss: 0.0181\n",
      "Epoch 136/200, Iteration 21/250, Loss: 0.0059\n",
      "Epoch 136/200, Iteration 22/250, Loss: 0.0103\n",
      "Epoch 136/200, Iteration 23/250, Loss: 0.0206\n",
      "Epoch 136/200, Iteration 24/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 25/250, Loss: 0.0105\n",
      "Epoch 136/200, Iteration 26/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 136/200, Iteration 28/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 29/250, Loss: 0.0176\n",
      "Epoch 136/200, Iteration 30/250, Loss: 0.0123\n",
      "Epoch 136/200, Iteration 31/250, Loss: 0.0136\n",
      "Epoch 136/200, Iteration 32/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 33/250, Loss: 0.0199\n",
      "Epoch 136/200, Iteration 34/250, Loss: 0.0389\n",
      "Epoch 136/200, Iteration 35/250, Loss: 0.0219\n",
      "Epoch 136/200, Iteration 36/250, Loss: 0.0420\n",
      "Epoch 136/200, Iteration 37/250, Loss: 0.0082\n",
      "Epoch 136/200, Iteration 38/250, Loss: 0.0127\n",
      "Epoch 136/200, Iteration 39/250, Loss: 0.0151\n",
      "Epoch 136/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 136/200, Iteration 41/250, Loss: 0.0230\n",
      "Epoch 136/200, Iteration 42/250, Loss: 0.0241\n",
      "Epoch 136/200, Iteration 43/250, Loss: 0.0093\n",
      "Epoch 136/200, Iteration 44/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 45/250, Loss: 0.0215\n",
      "Epoch 136/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 47/250, Loss: 0.0148\n",
      "Epoch 136/200, Iteration 48/250, Loss: 0.0086\n",
      "Epoch 136/200, Iteration 49/250, Loss: 0.0170\n",
      "Epoch 136/200, Iteration 50/250, Loss: 0.0075\n",
      "Epoch 136/200, Iteration 51/250, Loss: 0.0090\n",
      "Epoch 136/200, Iteration 52/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 53/250, Loss: 0.0061\n",
      "Epoch 136/200, Iteration 54/250, Loss: 0.0089\n",
      "Epoch 136/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 56/250, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 57/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 58/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 59/250, Loss: 0.0058\n",
      "Epoch 136/200, Iteration 60/250, Loss: 0.0131\n",
      "Epoch 136/200, Iteration 61/250, Loss: 0.0144\n",
      "Epoch 136/200, Iteration 62/250, Loss: 0.0268\n",
      "Epoch 136/200, Iteration 63/250, Loss: 0.0080\n",
      "Epoch 136/200, Iteration 64/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 65/250, Loss: 0.0204\n",
      "Epoch 136/200, Iteration 66/250, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200, Iteration 67/250, Loss: 0.0147\n",
      "Epoch 136/200, Iteration 68/250, Loss: 0.0208\n",
      "Epoch 136/200, Iteration 69/250, Loss: 0.0215\n",
      "Epoch 136/200, Iteration 70/250, Loss: 0.0172\n",
      "Epoch 136/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 136/200, Iteration 72/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 73/250, Loss: 0.0279\n",
      "Epoch 136/200, Iteration 74/250, Loss: 0.0090\n",
      "Epoch 136/200, Iteration 75/250, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 76/250, Loss: 0.0170\n",
      "Epoch 136/200, Iteration 77/250, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 78/250, Loss: 0.0107\n",
      "Epoch 136/200, Iteration 79/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 80/250, Loss: 0.0139\n",
      "Epoch 136/200, Iteration 81/250, Loss: 0.0155\n",
      "Epoch 136/200, Iteration 82/250, Loss: 0.0325\n",
      "Epoch 136/200, Iteration 83/250, Loss: 0.0230\n",
      "Epoch 136/200, Iteration 84/250, Loss: 0.0198\n",
      "Epoch 136/200, Iteration 85/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 86/250, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 87/250, Loss: 0.0102\n",
      "Epoch 136/200, Iteration 88/250, Loss: 0.0361\n",
      "Epoch 136/200, Iteration 89/250, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 90/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 91/250, Loss: 0.0313\n",
      "Epoch 136/200, Iteration 92/250, Loss: 0.0121\n",
      "Epoch 136/200, Iteration 93/250, Loss: 0.0115\n",
      "Epoch 136/200, Iteration 94/250, Loss: 0.0200\n",
      "Epoch 136/200, Iteration 95/250, Loss: 0.0153\n",
      "Epoch 136/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 136/200, Iteration 97/250, Loss: 0.0150\n",
      "Epoch 136/200, Iteration 98/250, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 99/250, Loss: 0.0040\n",
      "Epoch 136/200, Iteration 100/250, Loss: 0.0108\n",
      "Epoch 136/200, Iteration 101/250, Loss: 0.0069\n",
      "Epoch 136/200, Iteration 102/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 103/250, Loss: 0.0134\n",
      "Epoch 136/200, Iteration 104/250, Loss: 0.0266\n",
      "Epoch 136/200, Iteration 105/250, Loss: 0.0148\n",
      "Epoch 136/200, Iteration 106/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 107/250, Loss: 0.0205\n",
      "Epoch 136/200, Iteration 108/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 109/250, Loss: 0.0233\n",
      "Epoch 136/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 112/250, Loss: 0.0059\n",
      "Epoch 136/200, Iteration 113/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 114/250, Loss: 0.0393\n",
      "Epoch 136/200, Iteration 115/250, Loss: 0.0311\n",
      "Epoch 136/200, Iteration 116/250, Loss: 0.0243\n",
      "Epoch 136/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 118/250, Loss: 0.0145\n",
      "Epoch 136/200, Iteration 119/250, Loss: 0.0127\n",
      "Epoch 136/200, Iteration 120/250, Loss: 0.0086\n",
      "Epoch 136/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 122/250, Loss: 0.0082\n",
      "Epoch 136/200, Iteration 123/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 125/250, Loss: 0.0141\n",
      "Epoch 136/200, Iteration 126/250, Loss: 0.0074\n",
      "Epoch 136/200, Iteration 127/250, Loss: 0.0229\n",
      "Epoch 136/200, Iteration 128/250, Loss: 0.0128\n",
      "Epoch 136/200, Iteration 129/250, Loss: 0.0186\n",
      "Epoch 136/200, Iteration 130/250, Loss: 0.0154\n",
      "Epoch 136/200, Iteration 131/250, Loss: 0.0091\n",
      "Epoch 136/200, Iteration 132/250, Loss: 0.0191\n",
      "Epoch 136/200, Iteration 133/250, Loss: 0.0094\n",
      "Epoch 136/200, Iteration 134/250, Loss: 0.0155\n",
      "Epoch 136/200, Iteration 135/250, Loss: 0.0303\n",
      "Epoch 136/200, Iteration 136/250, Loss: 0.0167\n",
      "Epoch 136/200, Iteration 137/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 138/250, Loss: 0.0188\n",
      "Epoch 136/200, Iteration 139/250, Loss: 0.0080\n",
      "Epoch 136/200, Iteration 140/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 141/250, Loss: 0.0119\n",
      "Epoch 136/200, Iteration 142/250, Loss: 0.0073\n",
      "Epoch 136/200, Iteration 143/250, Loss: 0.0112\n",
      "Epoch 136/200, Iteration 144/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 145/250, Loss: 0.0078\n",
      "Epoch 136/200, Iteration 146/250, Loss: 0.0250\n",
      "Epoch 136/200, Iteration 147/250, Loss: 0.0172\n",
      "Epoch 136/200, Iteration 148/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 149/250, Loss: 0.0166\n",
      "Epoch 136/200, Iteration 150/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 136/200, Iteration 152/250, Loss: 0.0172\n",
      "Epoch 136/200, Iteration 153/250, Loss: 0.0299\n",
      "Epoch 136/200, Iteration 154/250, Loss: 0.0069\n",
      "Epoch 136/200, Iteration 155/250, Loss: 0.0065\n",
      "Epoch 136/200, Iteration 156/250, Loss: 0.0136\n",
      "Epoch 136/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 136/200, Iteration 158/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 136/200, Iteration 160/250, Loss: 0.0119\n",
      "Epoch 136/200, Iteration 161/250, Loss: 0.0102\n",
      "Epoch 136/200, Iteration 162/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 163/250, Loss: 0.0100\n",
      "Epoch 136/200, Iteration 164/250, Loss: 0.0202\n",
      "Epoch 136/200, Iteration 165/250, Loss: 0.0093\n",
      "Epoch 136/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 167/250, Loss: 0.0082\n",
      "Epoch 136/200, Iteration 168/250, Loss: 0.0132\n",
      "Epoch 136/200, Iteration 169/250, Loss: 0.0140\n",
      "Epoch 136/200, Iteration 170/250, Loss: 0.0150\n",
      "Epoch 136/200, Iteration 171/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 172/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 173/250, Loss: 0.0173\n",
      "Epoch 136/200, Iteration 174/250, Loss: 0.0092\n",
      "Epoch 136/200, Iteration 175/250, Loss: 0.0123\n",
      "Epoch 136/200, Iteration 176/250, Loss: 0.0133\n",
      "Epoch 136/200, Iteration 177/250, Loss: 0.0152\n",
      "Epoch 136/200, Iteration 178/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 179/250, Loss: 0.0122\n",
      "Epoch 136/200, Iteration 180/250, Loss: 0.0164\n",
      "Epoch 136/200, Iteration 181/250, Loss: 0.0216\n",
      "Epoch 136/200, Iteration 182/250, Loss: 0.0155\n",
      "Epoch 136/200, Iteration 183/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 136/200, Iteration 185/250, Loss: 0.0109\n",
      "Epoch 136/200, Iteration 186/250, Loss: 0.0381\n",
      "Epoch 136/200, Iteration 187/250, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 188/250, Loss: 0.0088\n",
      "Epoch 136/200, Iteration 189/250, Loss: 0.0154\n",
      "Epoch 136/200, Iteration 190/250, Loss: 0.0090\n",
      "Epoch 136/200, Iteration 191/250, Loss: 0.0261\n",
      "Epoch 136/200, Iteration 192/250, Loss: 0.0068\n",
      "Epoch 136/200, Iteration 193/250, Loss: 0.0112\n",
      "Epoch 136/200, Iteration 194/250, Loss: 0.0090\n",
      "Epoch 136/200, Iteration 195/250, Loss: 0.0164\n",
      "Epoch 136/200, Iteration 196/250, Loss: 0.0121\n",
      "Epoch 136/200, Iteration 197/250, Loss: 0.0246\n",
      "Epoch 136/200, Iteration 198/250, Loss: 0.0347\n",
      "Epoch 136/200, Iteration 199/250, Loss: 0.0127\n",
      "Epoch 136/200, Iteration 200/250, Loss: 0.0149\n",
      "Epoch 136/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 202/250, Loss: 0.0168\n",
      "Epoch 136/200, Iteration 203/250, Loss: 0.0266\n",
      "Epoch 136/200, Iteration 204/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 205/250, Loss: 0.0144\n",
      "Epoch 136/200, Iteration 206/250, Loss: 0.0126\n",
      "Epoch 136/200, Iteration 207/250, Loss: 0.0131\n",
      "Epoch 136/200, Iteration 208/250, Loss: 0.0105\n",
      "Epoch 136/200, Iteration 209/250, Loss: 0.0469\n",
      "Epoch 136/200, Iteration 210/250, Loss: 0.0074\n",
      "Epoch 136/200, Iteration 211/250, Loss: 0.0077\n",
      "Epoch 136/200, Iteration 212/250, Loss: 0.0135\n",
      "Epoch 136/200, Iteration 213/250, Loss: 0.0139\n",
      "Epoch 136/200, Iteration 214/250, Loss: 0.0179\n",
      "Epoch 136/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 216/250, Loss: 0.0314\n",
      "Epoch 136/200, Iteration 217/250, Loss: 0.0108\n",
      "Epoch 136/200, Iteration 218/250, Loss: 0.0168\n",
      "Epoch 136/200, Iteration 219/250, Loss: 0.0232\n",
      "Epoch 136/200, Iteration 220/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 221/250, Loss: 0.0160\n",
      "Epoch 136/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 136/200, Iteration 223/250, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 225/250, Loss: 0.0146\n",
      "Epoch 136/200, Iteration 226/250, Loss: 0.0086\n",
      "Epoch 136/200, Iteration 227/250, Loss: 0.0168\n",
      "Epoch 136/200, Iteration 228/250, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 229/250, Loss: 0.0167\n",
      "Epoch 136/200, Iteration 230/250, Loss: 0.0180\n",
      "Epoch 136/200, Iteration 231/250, Loss: 0.0235\n",
      "Epoch 136/200, Iteration 232/250, Loss: 0.0107\n",
      "Epoch 136/200, Iteration 233/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 234/250, Loss: 0.0217\n",
      "Epoch 136/200, Iteration 235/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 236/250, Loss: 0.0198\n",
      "Epoch 136/200, Iteration 237/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 136/200, Iteration 239/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 240/250, Loss: 0.0207\n",
      "Epoch 136/200, Iteration 241/250, Loss: 0.0077\n",
      "Epoch 136/200, Iteration 242/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 243/250, Loss: 0.0389\n",
      "Epoch 136/200, Iteration 244/250, Loss: 0.0190\n",
      "Epoch 136/200, Iteration 245/250, Loss: 0.0103\n",
      "Epoch 136/200, Iteration 246/250, Loss: 0.0149\n",
      "Epoch 136/200, Iteration 247/250, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 248/250, Loss: 0.0130\n",
      "Epoch 136/200, Iteration 249/250, Loss: 0.0099\n",
      "Epoch 136/200, Iteration 250/250, Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.24%, Avg loss: 0.006489, MRE: 0.628015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006442, MRE: 1.027891 \n",
      "\n",
      "Epoch 137/200, Iteration 1/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 2/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 3/250, Loss: 0.0176\n",
      "Epoch 137/200, Iteration 4/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 5/250, Loss: 0.0317\n",
      "Epoch 137/200, Iteration 6/250, Loss: 0.0130\n",
      "Epoch 137/200, Iteration 7/250, Loss: 0.0127\n",
      "Epoch 137/200, Iteration 8/250, Loss: 0.0225\n",
      "Epoch 137/200, Iteration 9/250, Loss: 0.0236\n",
      "Epoch 137/200, Iteration 10/250, Loss: 0.0158\n",
      "Epoch 137/200, Iteration 11/250, Loss: 0.0171\n",
      "Epoch 137/200, Iteration 12/250, Loss: 0.0152\n",
      "Epoch 137/200, Iteration 13/250, Loss: 0.0140\n",
      "Epoch 137/200, Iteration 14/250, Loss: 0.0357\n",
      "Epoch 137/200, Iteration 15/250, Loss: 0.0128\n",
      "Epoch 137/200, Iteration 16/250, Loss: 0.0083\n",
      "Epoch 137/200, Iteration 17/250, Loss: 0.0074\n",
      "Epoch 137/200, Iteration 18/250, Loss: 0.0219\n",
      "Epoch 137/200, Iteration 19/250, Loss: 0.0340\n",
      "Epoch 137/200, Iteration 20/250, Loss: 0.0157\n",
      "Epoch 137/200, Iteration 21/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 22/250, Loss: 0.0068\n",
      "Epoch 137/200, Iteration 23/250, Loss: 0.0182\n",
      "Epoch 137/200, Iteration 24/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 25/250, Loss: 0.0248\n",
      "Epoch 137/200, Iteration 26/250, Loss: 0.0246\n",
      "Epoch 137/200, Iteration 27/250, Loss: 0.0112\n",
      "Epoch 137/200, Iteration 28/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 29/250, Loss: 0.0205\n",
      "Epoch 137/200, Iteration 30/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 31/250, Loss: 0.0299\n",
      "Epoch 137/200, Iteration 32/250, Loss: 0.0110\n",
      "Epoch 137/200, Iteration 33/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 34/250, Loss: 0.0123\n",
      "Epoch 137/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 137/200, Iteration 36/250, Loss: 0.0193\n",
      "Epoch 137/200, Iteration 37/250, Loss: 0.0126\n",
      "Epoch 137/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 137/200, Iteration 39/250, Loss: 0.0150\n",
      "Epoch 137/200, Iteration 40/250, Loss: 0.0098\n",
      "Epoch 137/200, Iteration 41/250, Loss: 0.0083\n",
      "Epoch 137/200, Iteration 42/250, Loss: 0.0232\n",
      "Epoch 137/200, Iteration 43/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 44/250, Loss: 0.0101\n",
      "Epoch 137/200, Iteration 45/250, Loss: 0.0062\n",
      "Epoch 137/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 137/200, Iteration 47/250, Loss: 0.0124\n",
      "Epoch 137/200, Iteration 48/250, Loss: 0.0134\n",
      "Epoch 137/200, Iteration 49/250, Loss: 0.0490\n",
      "Epoch 137/200, Iteration 50/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 51/250, Loss: 0.0287\n",
      "Epoch 137/200, Iteration 52/250, Loss: 0.0082\n",
      "Epoch 137/200, Iteration 53/250, Loss: 0.0192\n",
      "Epoch 137/200, Iteration 54/250, Loss: 0.0128\n",
      "Epoch 137/200, Iteration 55/250, Loss: 0.0111\n",
      "Epoch 137/200, Iteration 56/250, Loss: 0.0070\n",
      "Epoch 137/200, Iteration 57/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 58/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 59/250, Loss: 0.0233\n",
      "Epoch 137/200, Iteration 60/250, Loss: 0.0067\n",
      "Epoch 137/200, Iteration 61/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 62/250, Loss: 0.0109\n",
      "Epoch 137/200, Iteration 63/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 64/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 65/250, Loss: 0.0202\n",
      "Epoch 137/200, Iteration 66/250, Loss: 0.0323\n",
      "Epoch 137/200, Iteration 67/250, Loss: 0.0082\n",
      "Epoch 137/200, Iteration 68/250, Loss: 0.0107\n",
      "Epoch 137/200, Iteration 69/250, Loss: 0.0143\n",
      "Epoch 137/200, Iteration 70/250, Loss: 0.0305\n",
      "Epoch 137/200, Iteration 71/250, Loss: 0.0174\n",
      "Epoch 137/200, Iteration 72/250, Loss: 0.0177\n",
      "Epoch 137/200, Iteration 73/250, Loss: 0.0110\n",
      "Epoch 137/200, Iteration 74/250, Loss: 0.0158\n",
      "Epoch 137/200, Iteration 75/250, Loss: 0.0294\n",
      "Epoch 137/200, Iteration 76/250, Loss: 0.0068\n",
      "Epoch 137/200, Iteration 77/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 78/250, Loss: 0.0101\n",
      "Epoch 137/200, Iteration 79/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 80/250, Loss: 0.0193\n",
      "Epoch 137/200, Iteration 81/250, Loss: 0.0195\n",
      "Epoch 137/200, Iteration 82/250, Loss: 0.0156\n",
      "Epoch 137/200, Iteration 83/250, Loss: 0.0183\n",
      "Epoch 137/200, Iteration 84/250, Loss: 0.0147\n",
      "Epoch 137/200, Iteration 85/250, Loss: 0.0139\n",
      "Epoch 137/200, Iteration 86/250, Loss: 0.0259\n",
      "Epoch 137/200, Iteration 87/250, Loss: 0.0137\n",
      "Epoch 137/200, Iteration 88/250, Loss: 0.0117\n",
      "Epoch 137/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 137/200, Iteration 90/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 91/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 92/250, Loss: 0.0087\n",
      "Epoch 137/200, Iteration 93/250, Loss: 0.0108\n",
      "Epoch 137/200, Iteration 94/250, Loss: 0.0182\n",
      "Epoch 137/200, Iteration 95/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 96/250, Loss: 0.0080\n",
      "Epoch 137/200, Iteration 97/250, Loss: 0.0269\n",
      "Epoch 137/200, Iteration 98/250, Loss: 0.0150\n",
      "Epoch 137/200, Iteration 99/250, Loss: 0.0112\n",
      "Epoch 137/200, Iteration 100/250, Loss: 0.0273\n",
      "Epoch 137/200, Iteration 101/250, Loss: 0.0153\n",
      "Epoch 137/200, Iteration 102/250, Loss: 0.0081\n",
      "Epoch 137/200, Iteration 103/250, Loss: 0.0184\n",
      "Epoch 137/200, Iteration 104/250, Loss: 0.0089\n",
      "Epoch 137/200, Iteration 105/250, Loss: 0.0212\n",
      "Epoch 137/200, Iteration 106/250, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 107/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 108/250, Loss: 0.0205\n",
      "Epoch 137/200, Iteration 109/250, Loss: 0.0134\n",
      "Epoch 137/200, Iteration 110/250, Loss: 0.0211\n",
      "Epoch 137/200, Iteration 111/250, Loss: 0.0146\n",
      "Epoch 137/200, Iteration 112/250, Loss: 0.0070\n",
      "Epoch 137/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 114/250, Loss: 0.0092\n",
      "Epoch 137/200, Iteration 115/250, Loss: 0.0092\n",
      "Epoch 137/200, Iteration 116/250, Loss: 0.0102\n",
      "Epoch 137/200, Iteration 117/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 118/250, Loss: 0.0073\n",
      "Epoch 137/200, Iteration 119/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 120/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 121/250, Loss: 0.0156\n",
      "Epoch 137/200, Iteration 122/250, Loss: 0.0108\n",
      "Epoch 137/200, Iteration 123/250, Loss: 0.0109\n",
      "Epoch 137/200, Iteration 124/250, Loss: 0.0143\n",
      "Epoch 137/200, Iteration 125/250, Loss: 0.0203\n",
      "Epoch 137/200, Iteration 126/250, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 127/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 128/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 129/250, Loss: 0.0079\n",
      "Epoch 137/200, Iteration 130/250, Loss: 0.0197\n",
      "Epoch 137/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 137/200, Iteration 132/250, Loss: 0.0132\n",
      "Epoch 137/200, Iteration 133/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 134/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 135/250, Loss: 0.0144\n",
      "Epoch 137/200, Iteration 136/250, Loss: 0.0078\n",
      "Epoch 137/200, Iteration 137/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 138/250, Loss: 0.0254\n",
      "Epoch 137/200, Iteration 139/250, Loss: 0.0221\n",
      "Epoch 137/200, Iteration 140/250, Loss: 0.0070\n",
      "Epoch 137/200, Iteration 141/250, Loss: 0.0087\n",
      "Epoch 137/200, Iteration 142/250, Loss: 0.0080\n",
      "Epoch 137/200, Iteration 143/250, Loss: 0.0102\n",
      "Epoch 137/200, Iteration 144/250, Loss: 0.0076\n",
      "Epoch 137/200, Iteration 145/250, Loss: 0.0163\n",
      "Epoch 137/200, Iteration 146/250, Loss: 0.0292\n",
      "Epoch 137/200, Iteration 147/250, Loss: 0.0113\n",
      "Epoch 137/200, Iteration 148/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 149/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 150/250, Loss: 0.0141\n",
      "Epoch 137/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 137/200, Iteration 153/250, Loss: 0.0109\n",
      "Epoch 137/200, Iteration 154/250, Loss: 0.0120\n",
      "Epoch 137/200, Iteration 155/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 156/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 137/200, Iteration 158/250, Loss: 0.0196\n",
      "Epoch 137/200, Iteration 159/250, Loss: 0.0132\n",
      "Epoch 137/200, Iteration 160/250, Loss: 0.0101\n",
      "Epoch 137/200, Iteration 161/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 162/250, Loss: 0.0061\n",
      "Epoch 137/200, Iteration 163/250, Loss: 0.0312\n",
      "Epoch 137/200, Iteration 164/250, Loss: 0.0194\n",
      "Epoch 137/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 166/250, Loss: 0.0177\n",
      "Epoch 137/200, Iteration 167/250, Loss: 0.0128\n",
      "Epoch 137/200, Iteration 168/250, Loss: 0.0204\n",
      "Epoch 137/200, Iteration 169/250, Loss: 0.0185\n",
      "Epoch 137/200, Iteration 170/250, Loss: 0.0154\n",
      "Epoch 137/200, Iteration 171/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 172/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 173/250, Loss: 0.0065\n",
      "Epoch 137/200, Iteration 174/250, Loss: 0.0112\n",
      "Epoch 137/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 137/200, Iteration 176/250, Loss: 0.0160\n",
      "Epoch 137/200, Iteration 177/250, Loss: 0.0077\n",
      "Epoch 137/200, Iteration 178/250, Loss: 0.0078\n",
      "Epoch 137/200, Iteration 179/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 180/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 181/250, Loss: 0.0072\n",
      "Epoch 137/200, Iteration 182/250, Loss: 0.0070\n",
      "Epoch 137/200, Iteration 183/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 184/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 185/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 186/250, Loss: 0.0087\n",
      "Epoch 137/200, Iteration 187/250, Loss: 0.0349\n",
      "Epoch 137/200, Iteration 188/250, Loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200, Iteration 189/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 190/250, Loss: 0.0157\n",
      "Epoch 137/200, Iteration 191/250, Loss: 0.0231\n",
      "Epoch 137/200, Iteration 192/250, Loss: 0.0158\n",
      "Epoch 137/200, Iteration 193/250, Loss: 0.0250\n",
      "Epoch 137/200, Iteration 194/250, Loss: 0.0090\n",
      "Epoch 137/200, Iteration 195/250, Loss: 0.0295\n",
      "Epoch 137/200, Iteration 196/250, Loss: 0.0247\n",
      "Epoch 137/200, Iteration 197/250, Loss: 0.0112\n",
      "Epoch 137/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 200/250, Loss: 0.0078\n",
      "Epoch 137/200, Iteration 201/250, Loss: 0.0348\n",
      "Epoch 137/200, Iteration 202/250, Loss: 0.0161\n",
      "Epoch 137/200, Iteration 203/250, Loss: 0.0395\n",
      "Epoch 137/200, Iteration 204/250, Loss: 0.0118\n",
      "Epoch 137/200, Iteration 205/250, Loss: 0.0172\n",
      "Epoch 137/200, Iteration 206/250, Loss: 0.0347\n",
      "Epoch 137/200, Iteration 207/250, Loss: 0.0420\n",
      "Epoch 137/200, Iteration 208/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 209/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 210/250, Loss: 0.0249\n",
      "Epoch 137/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 137/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 137/200, Iteration 213/250, Loss: 0.0130\n",
      "Epoch 137/200, Iteration 214/250, Loss: 0.0096\n",
      "Epoch 137/200, Iteration 215/250, Loss: 0.0076\n",
      "Epoch 137/200, Iteration 216/250, Loss: 0.0202\n",
      "Epoch 137/200, Iteration 217/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 218/250, Loss: 0.0133\n",
      "Epoch 137/200, Iteration 219/250, Loss: 0.0253\n",
      "Epoch 137/200, Iteration 220/250, Loss: 0.0176\n",
      "Epoch 137/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 137/200, Iteration 222/250, Loss: 0.0201\n",
      "Epoch 137/200, Iteration 223/250, Loss: 0.0127\n",
      "Epoch 137/200, Iteration 224/250, Loss: 0.0075\n",
      "Epoch 137/200, Iteration 225/250, Loss: 0.0146\n",
      "Epoch 137/200, Iteration 226/250, Loss: 0.0083\n",
      "Epoch 137/200, Iteration 227/250, Loss: 0.0156\n",
      "Epoch 137/200, Iteration 228/250, Loss: 0.0280\n",
      "Epoch 137/200, Iteration 229/250, Loss: 0.0119\n",
      "Epoch 137/200, Iteration 230/250, Loss: 0.0132\n",
      "Epoch 137/200, Iteration 231/250, Loss: 0.0078\n",
      "Epoch 137/200, Iteration 232/250, Loss: 0.0079\n",
      "Epoch 137/200, Iteration 233/250, Loss: 0.0158\n",
      "Epoch 137/200, Iteration 234/250, Loss: 0.0127\n",
      "Epoch 137/200, Iteration 235/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 236/250, Loss: 0.0246\n",
      "Epoch 137/200, Iteration 237/250, Loss: 0.0134\n",
      "Epoch 137/200, Iteration 238/250, Loss: 0.0197\n",
      "Epoch 137/200, Iteration 239/250, Loss: 0.0140\n",
      "Epoch 137/200, Iteration 240/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 241/250, Loss: 0.0066\n",
      "Epoch 137/200, Iteration 242/250, Loss: 0.0118\n",
      "Epoch 137/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 244/250, Loss: 0.0148\n",
      "Epoch 137/200, Iteration 245/250, Loss: 0.0139\n",
      "Epoch 137/200, Iteration 246/250, Loss: 0.0294\n",
      "Epoch 137/200, Iteration 247/250, Loss: 0.0148\n",
      "Epoch 137/200, Iteration 248/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 249/250, Loss: 0.0088\n",
      "Epoch 137/200, Iteration 250/250, Loss: 0.0242\n",
      "Train Error: \n",
      " Accuracy: 94.94%, Avg loss: 0.006463, MRE: 0.627419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.95%, Avg loss: 0.006516, MRE: 0.970313 \n",
      "\n",
      "Epoch 138/200, Iteration 1/250, Loss: 0.0070\n",
      "Epoch 138/200, Iteration 2/250, Loss: 0.0170\n",
      "Epoch 138/200, Iteration 3/250, Loss: 0.0065\n",
      "Epoch 138/200, Iteration 4/250, Loss: 0.0082\n",
      "Epoch 138/200, Iteration 5/250, Loss: 0.0252\n",
      "Epoch 138/200, Iteration 6/250, Loss: 0.0092\n",
      "Epoch 138/200, Iteration 7/250, Loss: 0.0102\n",
      "Epoch 138/200, Iteration 8/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 9/250, Loss: 0.0101\n",
      "Epoch 138/200, Iteration 10/250, Loss: 0.0238\n",
      "Epoch 138/200, Iteration 11/250, Loss: 0.0116\n",
      "Epoch 138/200, Iteration 12/250, Loss: 0.0152\n",
      "Epoch 138/200, Iteration 13/250, Loss: 0.0412\n",
      "Epoch 138/200, Iteration 14/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 15/250, Loss: 0.0129\n",
      "Epoch 138/200, Iteration 16/250, Loss: 0.0250\n",
      "Epoch 138/200, Iteration 17/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 18/250, Loss: 0.0081\n",
      "Epoch 138/200, Iteration 19/250, Loss: 0.0164\n",
      "Epoch 138/200, Iteration 20/250, Loss: 0.0106\n",
      "Epoch 138/200, Iteration 21/250, Loss: 0.0105\n",
      "Epoch 138/200, Iteration 22/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 23/250, Loss: 0.0267\n",
      "Epoch 138/200, Iteration 24/250, Loss: 0.0223\n",
      "Epoch 138/200, Iteration 25/250, Loss: 0.0101\n",
      "Epoch 138/200, Iteration 26/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 27/250, Loss: 0.0119\n",
      "Epoch 138/200, Iteration 28/250, Loss: 0.0177\n",
      "Epoch 138/200, Iteration 29/250, Loss: 0.0127\n",
      "Epoch 138/200, Iteration 30/250, Loss: 0.0172\n",
      "Epoch 138/200, Iteration 31/250, Loss: 0.0104\n",
      "Epoch 138/200, Iteration 32/250, Loss: 0.0162\n",
      "Epoch 138/200, Iteration 33/250, Loss: 0.0152\n",
      "Epoch 138/200, Iteration 34/250, Loss: 0.0133\n",
      "Epoch 138/200, Iteration 35/250, Loss: 0.0146\n",
      "Epoch 138/200, Iteration 36/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 37/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 38/250, Loss: 0.0113\n",
      "Epoch 138/200, Iteration 39/250, Loss: 0.0059\n",
      "Epoch 138/200, Iteration 40/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 41/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 42/250, Loss: 0.0288\n",
      "Epoch 138/200, Iteration 43/250, Loss: 0.0253\n",
      "Epoch 138/200, Iteration 44/250, Loss: 0.0167\n",
      "Epoch 138/200, Iteration 45/250, Loss: 0.0183\n",
      "Epoch 138/200, Iteration 46/250, Loss: 0.0171\n",
      "Epoch 138/200, Iteration 47/250, Loss: 0.0298\n",
      "Epoch 138/200, Iteration 48/250, Loss: 0.0155\n",
      "Epoch 138/200, Iteration 49/250, Loss: 0.0167\n",
      "Epoch 138/200, Iteration 50/250, Loss: 0.0181\n",
      "Epoch 138/200, Iteration 51/250, Loss: 0.0172\n",
      "Epoch 138/200, Iteration 52/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 53/250, Loss: 0.0202\n",
      "Epoch 138/200, Iteration 54/250, Loss: 0.0099\n",
      "Epoch 138/200, Iteration 55/250, Loss: 0.0120\n",
      "Epoch 138/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 138/200, Iteration 57/250, Loss: 0.0276\n",
      "Epoch 138/200, Iteration 58/250, Loss: 0.0172\n",
      "Epoch 138/200, Iteration 59/250, Loss: 0.0133\n",
      "Epoch 138/200, Iteration 60/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 61/250, Loss: 0.0090\n",
      "Epoch 138/200, Iteration 62/250, Loss: 0.0112\n",
      "Epoch 138/200, Iteration 63/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 64/250, Loss: 0.0127\n",
      "Epoch 138/200, Iteration 65/250, Loss: 0.0108\n",
      "Epoch 138/200, Iteration 66/250, Loss: 0.0144\n",
      "Epoch 138/200, Iteration 67/250, Loss: 0.0112\n",
      "Epoch 138/200, Iteration 68/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 69/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 70/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 71/250, Loss: 0.0120\n",
      "Epoch 138/200, Iteration 72/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 73/250, Loss: 0.0146\n",
      "Epoch 138/200, Iteration 74/250, Loss: 0.0198\n",
      "Epoch 138/200, Iteration 75/250, Loss: 0.0136\n",
      "Epoch 138/200, Iteration 76/250, Loss: 0.0169\n",
      "Epoch 138/200, Iteration 77/250, Loss: 0.0106\n",
      "Epoch 138/200, Iteration 78/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 79/250, Loss: 0.0087\n",
      "Epoch 138/200, Iteration 80/250, Loss: 0.0143\n",
      "Epoch 138/200, Iteration 81/250, Loss: 0.0135\n",
      "Epoch 138/200, Iteration 82/250, Loss: 0.0134\n",
      "Epoch 138/200, Iteration 83/250, Loss: 0.0148\n",
      "Epoch 138/200, Iteration 84/250, Loss: 0.0117\n",
      "Epoch 138/200, Iteration 85/250, Loss: 0.0177\n",
      "Epoch 138/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 138/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 88/250, Loss: 0.0144\n",
      "Epoch 138/200, Iteration 89/250, Loss: 0.0117\n",
      "Epoch 138/200, Iteration 90/250, Loss: 0.0365\n",
      "Epoch 138/200, Iteration 91/250, Loss: 0.0076\n",
      "Epoch 138/200, Iteration 92/250, Loss: 0.0160\n",
      "Epoch 138/200, Iteration 93/250, Loss: 0.0152\n",
      "Epoch 138/200, Iteration 94/250, Loss: 0.0118\n",
      "Epoch 138/200, Iteration 95/250, Loss: 0.0099\n",
      "Epoch 138/200, Iteration 96/250, Loss: 0.0159\n",
      "Epoch 138/200, Iteration 97/250, Loss: 0.0308\n",
      "Epoch 138/200, Iteration 98/250, Loss: 0.0055\n",
      "Epoch 138/200, Iteration 99/250, Loss: 0.0202\n",
      "Epoch 138/200, Iteration 100/250, Loss: 0.0360\n",
      "Epoch 138/200, Iteration 101/250, Loss: 0.0234\n",
      "Epoch 138/200, Iteration 102/250, Loss: 0.0110\n",
      "Epoch 138/200, Iteration 103/250, Loss: 0.0224\n",
      "Epoch 138/200, Iteration 104/250, Loss: 0.0067\n",
      "Epoch 138/200, Iteration 105/250, Loss: 0.0104\n",
      "Epoch 138/200, Iteration 106/250, Loss: 0.0148\n",
      "Epoch 138/200, Iteration 107/250, Loss: 0.0069\n",
      "Epoch 138/200, Iteration 108/250, Loss: 0.0189\n",
      "Epoch 138/200, Iteration 109/250, Loss: 0.0076\n",
      "Epoch 138/200, Iteration 110/250, Loss: 0.0229\n",
      "Epoch 138/200, Iteration 111/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 112/250, Loss: 0.0193\n",
      "Epoch 138/200, Iteration 113/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 114/250, Loss: 0.0263\n",
      "Epoch 138/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 138/200, Iteration 116/250, Loss: 0.0073\n",
      "Epoch 138/200, Iteration 117/250, Loss: 0.0080\n",
      "Epoch 138/200, Iteration 118/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 119/250, Loss: 0.0071\n",
      "Epoch 138/200, Iteration 120/250, Loss: 0.0087\n",
      "Epoch 138/200, Iteration 121/250, Loss: 0.0070\n",
      "Epoch 138/200, Iteration 122/250, Loss: 0.0065\n",
      "Epoch 138/200, Iteration 123/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 124/250, Loss: 0.0165\n",
      "Epoch 138/200, Iteration 125/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200, Iteration 126/250, Loss: 0.0167\n",
      "Epoch 138/200, Iteration 127/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 128/250, Loss: 0.0235\n",
      "Epoch 138/200, Iteration 129/250, Loss: 0.0142\n",
      "Epoch 138/200, Iteration 130/250, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 131/250, Loss: 0.0100\n",
      "Epoch 138/200, Iteration 132/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 133/250, Loss: 0.0247\n",
      "Epoch 138/200, Iteration 134/250, Loss: 0.0102\n",
      "Epoch 138/200, Iteration 135/250, Loss: 0.0183\n",
      "Epoch 138/200, Iteration 136/250, Loss: 0.0322\n",
      "Epoch 138/200, Iteration 137/250, Loss: 0.0207\n",
      "Epoch 138/200, Iteration 138/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 139/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 140/250, Loss: 0.0079\n",
      "Epoch 138/200, Iteration 141/250, Loss: 0.0134\n",
      "Epoch 138/200, Iteration 142/250, Loss: 0.0136\n",
      "Epoch 138/200, Iteration 143/250, Loss: 0.0221\n",
      "Epoch 138/200, Iteration 144/250, Loss: 0.0133\n",
      "Epoch 138/200, Iteration 145/250, Loss: 0.0314\n",
      "Epoch 138/200, Iteration 146/250, Loss: 0.0113\n",
      "Epoch 138/200, Iteration 147/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 148/250, Loss: 0.0210\n",
      "Epoch 138/200, Iteration 149/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 150/250, Loss: 0.0094\n",
      "Epoch 138/200, Iteration 151/250, Loss: 0.0220\n",
      "Epoch 138/200, Iteration 152/250, Loss: 0.0147\n",
      "Epoch 138/200, Iteration 153/250, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 154/250, Loss: 0.0216\n",
      "Epoch 138/200, Iteration 155/250, Loss: 0.0108\n",
      "Epoch 138/200, Iteration 156/250, Loss: 0.0082\n",
      "Epoch 138/200, Iteration 157/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 158/250, Loss: 0.0204\n",
      "Epoch 138/200, Iteration 159/250, Loss: 0.0146\n",
      "Epoch 138/200, Iteration 160/250, Loss: 0.0257\n",
      "Epoch 138/200, Iteration 161/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 162/250, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 163/250, Loss: 0.0326\n",
      "Epoch 138/200, Iteration 164/250, Loss: 0.0152\n",
      "Epoch 138/200, Iteration 165/250, Loss: 0.0144\n",
      "Epoch 138/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 168/250, Loss: 0.0184\n",
      "Epoch 138/200, Iteration 169/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 170/250, Loss: 0.0225\n",
      "Epoch 138/200, Iteration 171/250, Loss: 0.0411\n",
      "Epoch 138/200, Iteration 172/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 173/250, Loss: 0.0063\n",
      "Epoch 138/200, Iteration 174/250, Loss: 0.0389\n",
      "Epoch 138/200, Iteration 175/250, Loss: 0.0105\n",
      "Epoch 138/200, Iteration 176/250, Loss: 0.0106\n",
      "Epoch 138/200, Iteration 177/250, Loss: 0.0152\n",
      "Epoch 138/200, Iteration 178/250, Loss: 0.0088\n",
      "Epoch 138/200, Iteration 179/250, Loss: 0.0213\n",
      "Epoch 138/200, Iteration 180/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 181/250, Loss: 0.0080\n",
      "Epoch 138/200, Iteration 182/250, Loss: 0.0299\n",
      "Epoch 138/200, Iteration 183/250, Loss: 0.0134\n",
      "Epoch 138/200, Iteration 184/250, Loss: 0.0222\n",
      "Epoch 138/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 138/200, Iteration 186/250, Loss: 0.0090\n",
      "Epoch 138/200, Iteration 187/250, Loss: 0.0154\n",
      "Epoch 138/200, Iteration 188/250, Loss: 0.0155\n",
      "Epoch 138/200, Iteration 189/250, Loss: 0.0178\n",
      "Epoch 138/200, Iteration 190/250, Loss: 0.0216\n",
      "Epoch 138/200, Iteration 191/250, Loss: 0.0072\n",
      "Epoch 138/200, Iteration 192/250, Loss: 0.0131\n",
      "Epoch 138/200, Iteration 193/250, Loss: 0.0216\n",
      "Epoch 138/200, Iteration 194/250, Loss: 0.0154\n",
      "Epoch 138/200, Iteration 195/250, Loss: 0.0115\n",
      "Epoch 138/200, Iteration 196/250, Loss: 0.0104\n",
      "Epoch 138/200, Iteration 197/250, Loss: 0.0126\n",
      "Epoch 138/200, Iteration 198/250, Loss: 0.0061\n",
      "Epoch 138/200, Iteration 199/250, Loss: 0.0271\n",
      "Epoch 138/200, Iteration 200/250, Loss: 0.0237\n",
      "Epoch 138/200, Iteration 201/250, Loss: 0.0075\n",
      "Epoch 138/200, Iteration 202/250, Loss: 0.0395\n",
      "Epoch 138/200, Iteration 203/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 204/250, Loss: 0.0146\n",
      "Epoch 138/200, Iteration 205/250, Loss: 0.0358\n",
      "Epoch 138/200, Iteration 206/250, Loss: 0.0143\n",
      "Epoch 138/200, Iteration 207/250, Loss: 0.0163\n",
      "Epoch 138/200, Iteration 208/250, Loss: 0.0234\n",
      "Epoch 138/200, Iteration 209/250, Loss: 0.0254\n",
      "Epoch 138/200, Iteration 210/250, Loss: 0.0229\n",
      "Epoch 138/200, Iteration 211/250, Loss: 0.0232\n",
      "Epoch 138/200, Iteration 212/250, Loss: 0.0156\n",
      "Epoch 138/200, Iteration 213/250, Loss: 0.0100\n",
      "Epoch 138/200, Iteration 214/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 215/250, Loss: 0.0192\n",
      "Epoch 138/200, Iteration 216/250, Loss: 0.0201\n",
      "Epoch 138/200, Iteration 217/250, Loss: 0.0113\n",
      "Epoch 138/200, Iteration 218/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 219/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 220/250, Loss: 0.0200\n",
      "Epoch 138/200, Iteration 221/250, Loss: 0.0280\n",
      "Epoch 138/200, Iteration 222/250, Loss: 0.0116\n",
      "Epoch 138/200, Iteration 223/250, Loss: 0.0092\n",
      "Epoch 138/200, Iteration 224/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 225/250, Loss: 0.0139\n",
      "Epoch 138/200, Iteration 226/250, Loss: 0.0096\n",
      "Epoch 138/200, Iteration 227/250, Loss: 0.0192\n",
      "Epoch 138/200, Iteration 228/250, Loss: 0.0368\n",
      "Epoch 138/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 138/200, Iteration 230/250, Loss: 0.0494\n",
      "Epoch 138/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 138/200, Iteration 232/250, Loss: 0.0071\n",
      "Epoch 138/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 138/200, Iteration 234/250, Loss: 0.0199\n",
      "Epoch 138/200, Iteration 235/250, Loss: 0.0098\n",
      "Epoch 138/200, Iteration 236/250, Loss: 0.0241\n",
      "Epoch 138/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 138/200, Iteration 238/250, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 138/200, Iteration 240/250, Loss: 0.0066\n",
      "Epoch 138/200, Iteration 241/250, Loss: 0.0296\n",
      "Epoch 138/200, Iteration 242/250, Loss: 0.0188\n",
      "Epoch 138/200, Iteration 243/250, Loss: 0.0229\n",
      "Epoch 138/200, Iteration 244/250, Loss: 0.0184\n",
      "Epoch 138/200, Iteration 245/250, Loss: 0.0260\n",
      "Epoch 138/200, Iteration 246/250, Loss: 0.0216\n",
      "Epoch 138/200, Iteration 247/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 248/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 249/250, Loss: 0.0138\n",
      "Epoch 138/200, Iteration 250/250, Loss: 0.0089\n",
      "Train Error: \n",
      " Accuracy: 94.99%, Avg loss: 0.005714, MRE: 0.604948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.005717, MRE: 1.008821 \n",
      "\n",
      "Epoch 139/200, Iteration 1/250, Loss: 0.0190\n",
      "Epoch 139/200, Iteration 2/250, Loss: 0.0146\n",
      "Epoch 139/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 139/200, Iteration 4/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 5/250, Loss: 0.0061\n",
      "Epoch 139/200, Iteration 6/250, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 7/250, Loss: 0.0462\n",
      "Epoch 139/200, Iteration 8/250, Loss: 0.0187\n",
      "Epoch 139/200, Iteration 9/250, Loss: 0.0190\n",
      "Epoch 139/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 11/250, Loss: 0.0122\n",
      "Epoch 139/200, Iteration 12/250, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 13/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 14/250, Loss: 0.0078\n",
      "Epoch 139/200, Iteration 15/250, Loss: 0.0218\n",
      "Epoch 139/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 139/200, Iteration 17/250, Loss: 0.0150\n",
      "Epoch 139/200, Iteration 18/250, Loss: 0.0199\n",
      "Epoch 139/200, Iteration 19/250, Loss: 0.0337\n",
      "Epoch 139/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 21/250, Loss: 0.0074\n",
      "Epoch 139/200, Iteration 22/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 23/250, Loss: 0.0193\n",
      "Epoch 139/200, Iteration 24/250, Loss: 0.0063\n",
      "Epoch 139/200, Iteration 25/250, Loss: 0.0127\n",
      "Epoch 139/200, Iteration 26/250, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 27/250, Loss: 0.0102\n",
      "Epoch 139/200, Iteration 28/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 29/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 30/250, Loss: 0.0297\n",
      "Epoch 139/200, Iteration 31/250, Loss: 0.0100\n",
      "Epoch 139/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 33/250, Loss: 0.0095\n",
      "Epoch 139/200, Iteration 34/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 35/250, Loss: 0.0178\n",
      "Epoch 139/200, Iteration 36/250, Loss: 0.0149\n",
      "Epoch 139/200, Iteration 37/250, Loss: 0.0167\n",
      "Epoch 139/200, Iteration 38/250, Loss: 0.0151\n",
      "Epoch 139/200, Iteration 39/250, Loss: 0.0400\n",
      "Epoch 139/200, Iteration 40/250, Loss: 0.0187\n",
      "Epoch 139/200, Iteration 41/250, Loss: 0.0109\n",
      "Epoch 139/200, Iteration 42/250, Loss: 0.0072\n",
      "Epoch 139/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 44/250, Loss: 0.0142\n",
      "Epoch 139/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 139/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 139/200, Iteration 47/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 48/250, Loss: 0.0123\n",
      "Epoch 139/200, Iteration 49/250, Loss: 0.0279\n",
      "Epoch 139/200, Iteration 50/250, Loss: 0.0105\n",
      "Epoch 139/200, Iteration 51/250, Loss: 0.0154\n",
      "Epoch 139/200, Iteration 52/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 54/250, Loss: 0.0145\n",
      "Epoch 139/200, Iteration 55/250, Loss: 0.0213\n",
      "Epoch 139/200, Iteration 56/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 57/250, Loss: 0.0158\n",
      "Epoch 139/200, Iteration 58/250, Loss: 0.0073\n",
      "Epoch 139/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 139/200, Iteration 60/250, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 61/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/200, Iteration 62/250, Loss: 0.0301\n",
      "Epoch 139/200, Iteration 63/250, Loss: 0.0134\n",
      "Epoch 139/200, Iteration 64/250, Loss: 0.0110\n",
      "Epoch 139/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 66/250, Loss: 0.0067\n",
      "Epoch 139/200, Iteration 67/250, Loss: 0.0152\n",
      "Epoch 139/200, Iteration 68/250, Loss: 0.0130\n",
      "Epoch 139/200, Iteration 69/250, Loss: 0.0070\n",
      "Epoch 139/200, Iteration 70/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 71/250, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 72/250, Loss: 0.0156\n",
      "Epoch 139/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 139/200, Iteration 74/250, Loss: 0.0166\n",
      "Epoch 139/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 76/250, Loss: 0.0144\n",
      "Epoch 139/200, Iteration 77/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 78/250, Loss: 0.0190\n",
      "Epoch 139/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 139/200, Iteration 80/250, Loss: 0.0111\n",
      "Epoch 139/200, Iteration 81/250, Loss: 0.0175\n",
      "Epoch 139/200, Iteration 82/250, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 83/250, Loss: 0.0205\n",
      "Epoch 139/200, Iteration 84/250, Loss: 0.0156\n",
      "Epoch 139/200, Iteration 85/250, Loss: 0.0152\n",
      "Epoch 139/200, Iteration 86/250, Loss: 0.0147\n",
      "Epoch 139/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 88/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 89/250, Loss: 0.0073\n",
      "Epoch 139/200, Iteration 90/250, Loss: 0.0071\n",
      "Epoch 139/200, Iteration 91/250, Loss: 0.0147\n",
      "Epoch 139/200, Iteration 92/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 93/250, Loss: 0.0170\n",
      "Epoch 139/200, Iteration 94/250, Loss: 0.0246\n",
      "Epoch 139/200, Iteration 95/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 96/250, Loss: 0.0134\n",
      "Epoch 139/200, Iteration 97/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 98/250, Loss: 0.0102\n",
      "Epoch 139/200, Iteration 99/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 100/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 101/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 102/250, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 103/250, Loss: 0.0254\n",
      "Epoch 139/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 139/200, Iteration 105/250, Loss: 0.0110\n",
      "Epoch 139/200, Iteration 106/250, Loss: 0.0105\n",
      "Epoch 139/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 108/250, Loss: 0.0190\n",
      "Epoch 139/200, Iteration 109/250, Loss: 0.0061\n",
      "Epoch 139/200, Iteration 110/250, Loss: 0.0123\n",
      "Epoch 139/200, Iteration 111/250, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 112/250, Loss: 0.0130\n",
      "Epoch 139/200, Iteration 113/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 114/250, Loss: 0.0180\n",
      "Epoch 139/200, Iteration 115/250, Loss: 0.0170\n",
      "Epoch 139/200, Iteration 116/250, Loss: 0.0067\n",
      "Epoch 139/200, Iteration 117/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 118/250, Loss: 0.0122\n",
      "Epoch 139/200, Iteration 119/250, Loss: 0.0145\n",
      "Epoch 139/200, Iteration 120/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 121/250, Loss: 0.0176\n",
      "Epoch 139/200, Iteration 122/250, Loss: 0.0229\n",
      "Epoch 139/200, Iteration 123/250, Loss: 0.0165\n",
      "Epoch 139/200, Iteration 124/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 125/250, Loss: 0.0224\n",
      "Epoch 139/200, Iteration 126/250, Loss: 0.0084\n",
      "Epoch 139/200, Iteration 127/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 128/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 129/250, Loss: 0.0118\n",
      "Epoch 139/200, Iteration 130/250, Loss: 0.0128\n",
      "Epoch 139/200, Iteration 131/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 132/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 133/250, Loss: 0.0134\n",
      "Epoch 139/200, Iteration 134/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 135/250, Loss: 0.0163\n",
      "Epoch 139/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 137/250, Loss: 0.0434\n",
      "Epoch 139/200, Iteration 138/250, Loss: 0.0089\n",
      "Epoch 139/200, Iteration 139/250, Loss: 0.0139\n",
      "Epoch 139/200, Iteration 140/250, Loss: 0.0111\n",
      "Epoch 139/200, Iteration 141/250, Loss: 0.0072\n",
      "Epoch 139/200, Iteration 142/250, Loss: 0.0171\n",
      "Epoch 139/200, Iteration 143/250, Loss: 0.0131\n",
      "Epoch 139/200, Iteration 144/250, Loss: 0.0165\n",
      "Epoch 139/200, Iteration 145/250, Loss: 0.0163\n",
      "Epoch 139/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 139/200, Iteration 147/250, Loss: 0.0145\n",
      "Epoch 139/200, Iteration 148/250, Loss: 0.0306\n",
      "Epoch 139/200, Iteration 149/250, Loss: 0.0136\n",
      "Epoch 139/200, Iteration 150/250, Loss: 0.0093\n",
      "Epoch 139/200, Iteration 151/250, Loss: 0.0095\n",
      "Epoch 139/200, Iteration 152/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 153/250, Loss: 0.0120\n",
      "Epoch 139/200, Iteration 154/250, Loss: 0.0273\n",
      "Epoch 139/200, Iteration 155/250, Loss: 0.0284\n",
      "Epoch 139/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 157/250, Loss: 0.0152\n",
      "Epoch 139/200, Iteration 158/250, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 159/250, Loss: 0.0185\n",
      "Epoch 139/200, Iteration 160/250, Loss: 0.0186\n",
      "Epoch 139/200, Iteration 161/250, Loss: 0.0227\n",
      "Epoch 139/200, Iteration 162/250, Loss: 0.0082\n",
      "Epoch 139/200, Iteration 163/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 164/250, Loss: 0.0292\n",
      "Epoch 139/200, Iteration 165/250, Loss: 0.0072\n",
      "Epoch 139/200, Iteration 166/250, Loss: 0.0105\n",
      "Epoch 139/200, Iteration 167/250, Loss: 0.0153\n",
      "Epoch 139/200, Iteration 168/250, Loss: 0.0254\n",
      "Epoch 139/200, Iteration 169/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 170/250, Loss: 0.0173\n",
      "Epoch 139/200, Iteration 171/250, Loss: 0.0071\n",
      "Epoch 139/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 139/200, Iteration 173/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 174/250, Loss: 0.0154\n",
      "Epoch 139/200, Iteration 175/250, Loss: 0.0141\n",
      "Epoch 139/200, Iteration 176/250, Loss: 0.0224\n",
      "Epoch 139/200, Iteration 177/250, Loss: 0.0148\n",
      "Epoch 139/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 139/200, Iteration 179/250, Loss: 0.0094\n",
      "Epoch 139/200, Iteration 180/250, Loss: 0.0110\n",
      "Epoch 139/200, Iteration 181/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 182/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 183/250, Loss: 0.0232\n",
      "Epoch 139/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 185/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 186/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 187/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 188/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 189/250, Loss: 0.0086\n",
      "Epoch 139/200, Iteration 190/250, Loss: 0.0135\n",
      "Epoch 139/200, Iteration 191/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 192/250, Loss: 0.0072\n",
      "Epoch 139/200, Iteration 193/250, Loss: 0.0210\n",
      "Epoch 139/200, Iteration 194/250, Loss: 0.0116\n",
      "Epoch 139/200, Iteration 195/250, Loss: 0.0130\n",
      "Epoch 139/200, Iteration 196/250, Loss: 0.0069\n",
      "Epoch 139/200, Iteration 197/250, Loss: 0.0261\n",
      "Epoch 139/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 139/200, Iteration 199/250, Loss: 0.0078\n",
      "Epoch 139/200, Iteration 200/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 201/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 202/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 203/250, Loss: 0.0103\n",
      "Epoch 139/200, Iteration 204/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 205/250, Loss: 0.0117\n",
      "Epoch 139/200, Iteration 206/250, Loss: 0.0192\n",
      "Epoch 139/200, Iteration 207/250, Loss: 0.0269\n",
      "Epoch 139/200, Iteration 208/250, Loss: 0.0226\n",
      "Epoch 139/200, Iteration 209/250, Loss: 0.0255\n",
      "Epoch 139/200, Iteration 210/250, Loss: 0.0086\n",
      "Epoch 139/200, Iteration 211/250, Loss: 0.0094\n",
      "Epoch 139/200, Iteration 212/250, Loss: 0.0285\n",
      "Epoch 139/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 214/250, Loss: 0.0076\n",
      "Epoch 139/200, Iteration 215/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 216/250, Loss: 0.0076\n",
      "Epoch 139/200, Iteration 217/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 219/250, Loss: 0.0253\n",
      "Epoch 139/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 221/250, Loss: 0.0116\n",
      "Epoch 139/200, Iteration 222/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 223/250, Loss: 0.0099\n",
      "Epoch 139/200, Iteration 224/250, Loss: 0.0059\n",
      "Epoch 139/200, Iteration 225/250, Loss: 0.0095\n",
      "Epoch 139/200, Iteration 226/250, Loss: 0.0215\n",
      "Epoch 139/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 139/200, Iteration 228/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 229/250, Loss: 0.0189\n",
      "Epoch 139/200, Iteration 230/250, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 231/250, Loss: 0.0220\n",
      "Epoch 139/200, Iteration 232/250, Loss: 0.0120\n",
      "Epoch 139/200, Iteration 233/250, Loss: 0.0118\n",
      "Epoch 139/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 139/200, Iteration 235/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 236/250, Loss: 0.0503\n",
      "Epoch 139/200, Iteration 237/250, Loss: 0.0113\n",
      "Epoch 139/200, Iteration 238/250, Loss: 0.0419\n",
      "Epoch 139/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 240/250, Loss: 0.0203\n",
      "Epoch 139/200, Iteration 241/250, Loss: 0.0151\n",
      "Epoch 139/200, Iteration 242/250, Loss: 0.0235\n",
      "Epoch 139/200, Iteration 243/250, Loss: 0.0074\n",
      "Epoch 139/200, Iteration 244/250, Loss: 0.0126\n",
      "Epoch 139/200, Iteration 245/250, Loss: 0.0266\n",
      "Epoch 139/200, Iteration 246/250, Loss: 0.0148\n",
      "Epoch 139/200, Iteration 247/250, Loss: 0.0133\n",
      "Epoch 139/200, Iteration 248/250, Loss: 0.0179\n",
      "Epoch 139/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 139/200, Iteration 250/250, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.005878, MRE: 0.604197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.005843, MRE: 1.064798 \n",
      "\n",
      "Epoch 140/200, Iteration 1/250, Loss: 0.0069\n",
      "Epoch 140/200, Iteration 2/250, Loss: 0.0140\n",
      "Epoch 140/200, Iteration 3/250, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 4/250, Loss: 0.0132\n",
      "Epoch 140/200, Iteration 5/250, Loss: 0.0144\n",
      "Epoch 140/200, Iteration 6/250, Loss: 0.0157\n",
      "Epoch 140/200, Iteration 7/250, Loss: 0.0379\n",
      "Epoch 140/200, Iteration 8/250, Loss: 0.0149\n",
      "Epoch 140/200, Iteration 9/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 10/250, Loss: 0.0150\n",
      "Epoch 140/200, Iteration 11/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 12/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 13/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 14/250, Loss: 0.0083\n",
      "Epoch 140/200, Iteration 15/250, Loss: 0.0130\n",
      "Epoch 140/200, Iteration 16/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 18/250, Loss: 0.0087\n",
      "Epoch 140/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 140/200, Iteration 20/250, Loss: 0.0125\n",
      "Epoch 140/200, Iteration 21/250, Loss: 0.0103\n",
      "Epoch 140/200, Iteration 22/250, Loss: 0.0110\n",
      "Epoch 140/200, Iteration 23/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 24/250, Loss: 0.0222\n",
      "Epoch 140/200, Iteration 25/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 26/250, Loss: 0.0339\n",
      "Epoch 140/200, Iteration 27/250, Loss: 0.0114\n",
      "Epoch 140/200, Iteration 28/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 29/250, Loss: 0.0176\n",
      "Epoch 140/200, Iteration 30/250, Loss: 0.0363\n",
      "Epoch 140/200, Iteration 31/250, Loss: 0.0403\n",
      "Epoch 140/200, Iteration 32/250, Loss: 0.0301\n",
      "Epoch 140/200, Iteration 33/250, Loss: 0.0201\n",
      "Epoch 140/200, Iteration 34/250, Loss: 0.0233\n",
      "Epoch 140/200, Iteration 35/250, Loss: 0.0172\n",
      "Epoch 140/200, Iteration 36/250, Loss: 0.0143\n",
      "Epoch 140/200, Iteration 37/250, Loss: 0.0232\n",
      "Epoch 140/200, Iteration 38/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 39/250, Loss: 0.0073\n",
      "Epoch 140/200, Iteration 40/250, Loss: 0.0067\n",
      "Epoch 140/200, Iteration 41/250, Loss: 0.0079\n",
      "Epoch 140/200, Iteration 42/250, Loss: 0.0291\n",
      "Epoch 140/200, Iteration 43/250, Loss: 0.0248\n",
      "Epoch 140/200, Iteration 44/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 45/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 46/250, Loss: 0.0069\n",
      "Epoch 140/200, Iteration 47/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 48/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 49/250, Loss: 0.0324\n",
      "Epoch 140/200, Iteration 50/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 51/250, Loss: 0.0069\n",
      "Epoch 140/200, Iteration 52/250, Loss: 0.0191\n",
      "Epoch 140/200, Iteration 53/250, Loss: 0.0098\n",
      "Epoch 140/200, Iteration 54/250, Loss: 0.0229\n",
      "Epoch 140/200, Iteration 55/250, Loss: 0.0211\n",
      "Epoch 140/200, Iteration 56/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 57/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 58/250, Loss: 0.0157\n",
      "Epoch 140/200, Iteration 59/250, Loss: 0.0179\n",
      "Epoch 140/200, Iteration 60/250, Loss: 0.0193\n",
      "Epoch 140/200, Iteration 61/250, Loss: 0.0160\n",
      "Epoch 140/200, Iteration 62/250, Loss: 0.0116\n",
      "Epoch 140/200, Iteration 63/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 64/250, Loss: 0.0107\n",
      "Epoch 140/200, Iteration 65/250, Loss: 0.0178\n",
      "Epoch 140/200, Iteration 66/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 67/250, Loss: 0.0135\n",
      "Epoch 140/200, Iteration 68/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 69/250, Loss: 0.0225\n",
      "Epoch 140/200, Iteration 70/250, Loss: 0.0149\n",
      "Epoch 140/200, Iteration 71/250, Loss: 0.0275\n",
      "Epoch 140/200, Iteration 72/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 73/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 74/250, Loss: 0.0075\n",
      "Epoch 140/200, Iteration 75/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 76/250, Loss: 0.0213\n",
      "Epoch 140/200, Iteration 77/250, Loss: 0.0139\n",
      "Epoch 140/200, Iteration 78/250, Loss: 0.0176\n",
      "Epoch 140/200, Iteration 79/250, Loss: 0.0128\n",
      "Epoch 140/200, Iteration 80/250, Loss: 0.0090\n",
      "Epoch 140/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 140/200, Iteration 82/250, Loss: 0.0247\n",
      "Epoch 140/200, Iteration 83/250, Loss: 0.0154\n",
      "Epoch 140/200, Iteration 84/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 85/250, Loss: 0.0167\n",
      "Epoch 140/200, Iteration 86/250, Loss: 0.0144\n",
      "Epoch 140/200, Iteration 87/250, Loss: 0.0197\n",
      "Epoch 140/200, Iteration 88/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 89/250, Loss: 0.0081\n",
      "Epoch 140/200, Iteration 90/250, Loss: 0.0137\n",
      "Epoch 140/200, Iteration 91/250, Loss: 0.0247\n",
      "Epoch 140/200, Iteration 92/250, Loss: 0.0064\n",
      "Epoch 140/200, Iteration 93/250, Loss: 0.0169\n",
      "Epoch 140/200, Iteration 94/250, Loss: 0.0084\n",
      "Epoch 140/200, Iteration 95/250, Loss: 0.0103\n",
      "Epoch 140/200, Iteration 96/250, Loss: 0.0122\n",
      "Epoch 140/200, Iteration 97/250, Loss: 0.0146\n",
      "Epoch 140/200, Iteration 98/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 99/250, Loss: 0.0370\n",
      "Epoch 140/200, Iteration 100/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 102/250, Loss: 0.0471\n",
      "Epoch 140/200, Iteration 103/250, Loss: 0.0128\n",
      "Epoch 140/200, Iteration 104/250, Loss: 0.0158\n",
      "Epoch 140/200, Iteration 105/250, Loss: 0.0154\n",
      "Epoch 140/200, Iteration 106/250, Loss: 0.0168\n",
      "Epoch 140/200, Iteration 107/250, Loss: 0.0264\n",
      "Epoch 140/200, Iteration 108/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 109/250, Loss: 0.0110\n",
      "Epoch 140/200, Iteration 110/250, Loss: 0.0205\n",
      "Epoch 140/200, Iteration 111/250, Loss: 0.0297\n",
      "Epoch 140/200, Iteration 112/250, Loss: 0.0179\n",
      "Epoch 140/200, Iteration 113/250, Loss: 0.0065\n",
      "Epoch 140/200, Iteration 114/250, Loss: 0.0129\n",
      "Epoch 140/200, Iteration 115/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 116/250, Loss: 0.0216\n",
      "Epoch 140/200, Iteration 117/250, Loss: 0.0097\n",
      "Epoch 140/200, Iteration 118/250, Loss: 0.0138\n",
      "Epoch 140/200, Iteration 119/250, Loss: 0.0133\n",
      "Epoch 140/200, Iteration 120/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 121/250, Loss: 0.0121\n",
      "Epoch 140/200, Iteration 122/250, Loss: 0.0166\n",
      "Epoch 140/200, Iteration 123/250, Loss: 0.0126\n",
      "Epoch 140/200, Iteration 124/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 125/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 126/250, Loss: 0.0153\n",
      "Epoch 140/200, Iteration 127/250, Loss: 0.0520\n",
      "Epoch 140/200, Iteration 128/250, Loss: 0.0166\n",
      "Epoch 140/200, Iteration 129/250, Loss: 0.0218\n",
      "Epoch 140/200, Iteration 130/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 131/250, Loss: 0.0133\n",
      "Epoch 140/200, Iteration 132/250, Loss: 0.0054\n",
      "Epoch 140/200, Iteration 133/250, Loss: 0.0220\n",
      "Epoch 140/200, Iteration 134/250, Loss: 0.0157\n",
      "Epoch 140/200, Iteration 135/250, Loss: 0.0248\n",
      "Epoch 140/200, Iteration 136/250, Loss: 0.0305\n",
      "Epoch 140/200, Iteration 137/250, Loss: 0.0181\n",
      "Epoch 140/200, Iteration 138/250, Loss: 0.0146\n",
      "Epoch 140/200, Iteration 139/250, Loss: 0.0222\n",
      "Epoch 140/200, Iteration 140/250, Loss: 0.0244\n",
      "Epoch 140/200, Iteration 141/250, Loss: 0.0320\n",
      "Epoch 140/200, Iteration 142/250, Loss: 0.0085\n",
      "Epoch 140/200, Iteration 143/250, Loss: 0.0071\n",
      "Epoch 140/200, Iteration 144/250, Loss: 0.0069\n",
      "Epoch 140/200, Iteration 145/250, Loss: 0.0151\n",
      "Epoch 140/200, Iteration 146/250, Loss: 0.0206\n",
      "Epoch 140/200, Iteration 147/250, Loss: 0.0202\n",
      "Epoch 140/200, Iteration 148/250, Loss: 0.0213\n",
      "Epoch 140/200, Iteration 149/250, Loss: 0.0260\n",
      "Epoch 140/200, Iteration 150/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 151/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 152/250, Loss: 0.0182\n",
      "Epoch 140/200, Iteration 153/250, Loss: 0.0206\n",
      "Epoch 140/200, Iteration 154/250, Loss: 0.0076\n",
      "Epoch 140/200, Iteration 155/250, Loss: 0.0130\n",
      "Epoch 140/200, Iteration 156/250, Loss: 0.0152\n",
      "Epoch 140/200, Iteration 157/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 158/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 159/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 160/250, Loss: 0.0083\n",
      "Epoch 140/200, Iteration 161/250, Loss: 0.0133\n",
      "Epoch 140/200, Iteration 162/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 163/250, Loss: 0.0125\n",
      "Epoch 140/200, Iteration 164/250, Loss: 0.0147\n",
      "Epoch 140/200, Iteration 165/250, Loss: 0.0164\n",
      "Epoch 140/200, Iteration 166/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 167/250, Loss: 0.0073\n",
      "Epoch 140/200, Iteration 168/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 169/250, Loss: 0.0239\n",
      "Epoch 140/200, Iteration 170/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 171/250, Loss: 0.0065\n",
      "Epoch 140/200, Iteration 172/250, Loss: 0.0130\n",
      "Epoch 140/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 140/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 140/200, Iteration 175/250, Loss: 0.0166\n",
      "Epoch 140/200, Iteration 176/250, Loss: 0.0176\n",
      "Epoch 140/200, Iteration 177/250, Loss: 0.0175\n",
      "Epoch 140/200, Iteration 178/250, Loss: 0.0138\n",
      "Epoch 140/200, Iteration 179/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 180/250, Loss: 0.0161\n",
      "Epoch 140/200, Iteration 181/250, Loss: 0.0165\n",
      "Epoch 140/200, Iteration 182/250, Loss: 0.0067\n",
      "Epoch 140/200, Iteration 183/250, Loss: 0.0073\n",
      "Epoch 140/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 140/200, Iteration 185/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 186/250, Loss: 0.0159\n",
      "Epoch 140/200, Iteration 187/250, Loss: 0.0141\n",
      "Epoch 140/200, Iteration 188/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 189/250, Loss: 0.0169\n",
      "Epoch 140/200, Iteration 190/250, Loss: 0.0161\n",
      "Epoch 140/200, Iteration 191/250, Loss: 0.0077\n",
      "Epoch 140/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 140/200, Iteration 193/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 194/250, Loss: 0.0139\n",
      "Epoch 140/200, Iteration 195/250, Loss: 0.0183\n",
      "Epoch 140/200, Iteration 196/250, Loss: 0.0269\n",
      "Epoch 140/200, Iteration 197/250, Loss: 0.0242\n",
      "Epoch 140/200, Iteration 198/250, Loss: 0.0221\n",
      "Epoch 140/200, Iteration 199/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 200/250, Loss: 0.0078\n",
      "Epoch 140/200, Iteration 201/250, Loss: 0.0112\n",
      "Epoch 140/200, Iteration 202/250, Loss: 0.0176\n",
      "Epoch 140/200, Iteration 203/250, Loss: 0.0190\n",
      "Epoch 140/200, Iteration 204/250, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Iteration 205/250, Loss: 0.0232\n",
      "Epoch 140/200, Iteration 206/250, Loss: 0.0073\n",
      "Epoch 140/200, Iteration 207/250, Loss: 0.0255\n",
      "Epoch 140/200, Iteration 208/250, Loss: 0.0141\n",
      "Epoch 140/200, Iteration 209/250, Loss: 0.0230\n",
      "Epoch 140/200, Iteration 210/250, Loss: 0.0277\n",
      "Epoch 140/200, Iteration 211/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 212/250, Loss: 0.0123\n",
      "Epoch 140/200, Iteration 213/250, Loss: 0.0189\n",
      "Epoch 140/200, Iteration 214/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 215/250, Loss: 0.0219\n",
      "Epoch 140/200, Iteration 216/250, Loss: 0.0151\n",
      "Epoch 140/200, Iteration 217/250, Loss: 0.0068\n",
      "Epoch 140/200, Iteration 218/250, Loss: 0.0124\n",
      "Epoch 140/200, Iteration 219/250, Loss: 0.0276\n",
      "Epoch 140/200, Iteration 220/250, Loss: 0.0072\n",
      "Epoch 140/200, Iteration 221/250, Loss: 0.0261\n",
      "Epoch 140/200, Iteration 222/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 223/250, Loss: 0.0089\n",
      "Epoch 140/200, Iteration 224/250, Loss: 0.0199\n",
      "Epoch 140/200, Iteration 225/250, Loss: 0.0144\n",
      "Epoch 140/200, Iteration 226/250, Loss: 0.0178\n",
      "Epoch 140/200, Iteration 227/250, Loss: 0.0116\n",
      "Epoch 140/200, Iteration 228/250, Loss: 0.0131\n",
      "Epoch 140/200, Iteration 229/250, Loss: 0.0147\n",
      "Epoch 140/200, Iteration 230/250, Loss: 0.0148\n",
      "Epoch 140/200, Iteration 231/250, Loss: 0.0105\n",
      "Epoch 140/200, Iteration 232/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 233/250, Loss: 0.0135\n",
      "Epoch 140/200, Iteration 234/250, Loss: 0.0143\n",
      "Epoch 140/200, Iteration 235/250, Loss: 0.0178\n",
      "Epoch 140/200, Iteration 236/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 237/250, Loss: 0.0242\n",
      "Epoch 140/200, Iteration 238/250, Loss: 0.0159\n",
      "Epoch 140/200, Iteration 239/250, Loss: 0.0089\n",
      "Epoch 140/200, Iteration 240/250, Loss: 0.0208\n",
      "Epoch 140/200, Iteration 241/250, Loss: 0.0269\n",
      "Epoch 140/200, Iteration 242/250, Loss: 0.0124\n",
      "Epoch 140/200, Iteration 243/250, Loss: 0.0053\n",
      "Epoch 140/200, Iteration 244/250, Loss: 0.0188\n",
      "Epoch 140/200, Iteration 245/250, Loss: 0.0116\n",
      "Epoch 140/200, Iteration 246/250, Loss: 0.0346\n",
      "Epoch 140/200, Iteration 247/250, Loss: 0.0051\n",
      "Epoch 140/200, Iteration 248/250, Loss: 0.0168\n",
      "Epoch 140/200, Iteration 249/250, Loss: 0.0378\n",
      "Epoch 140/200, Iteration 250/250, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 78.57%, Avg loss: 0.007290, MRE: 0.655775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.85%, Avg loss: 0.007304, MRE: 0.754505 \n",
      "\n",
      "Epoch 141/200, Iteration 1/250, Loss: 0.0215\n",
      "Epoch 141/200, Iteration 2/250, Loss: 0.0066\n",
      "Epoch 141/200, Iteration 3/250, Loss: 0.0210\n",
      "Epoch 141/200, Iteration 4/250, Loss: 0.0163\n",
      "Epoch 141/200, Iteration 5/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 6/250, Loss: 0.0200\n",
      "Epoch 141/200, Iteration 7/250, Loss: 0.0273\n",
      "Epoch 141/200, Iteration 8/250, Loss: 0.0173\n",
      "Epoch 141/200, Iteration 9/250, Loss: 0.0064\n",
      "Epoch 141/200, Iteration 10/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 11/250, Loss: 0.0146\n",
      "Epoch 141/200, Iteration 12/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 13/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 14/250, Loss: 0.0245\n",
      "Epoch 141/200, Iteration 15/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 16/250, Loss: 0.0421\n",
      "Epoch 141/200, Iteration 17/250, Loss: 0.0078\n",
      "Epoch 141/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 141/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 141/200, Iteration 20/250, Loss: 0.0306\n",
      "Epoch 141/200, Iteration 21/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 141/200, Iteration 23/250, Loss: 0.0132\n",
      "Epoch 141/200, Iteration 24/250, Loss: 0.0112\n",
      "Epoch 141/200, Iteration 25/250, Loss: 0.0073\n",
      "Epoch 141/200, Iteration 26/250, Loss: 0.0152\n",
      "Epoch 141/200, Iteration 27/250, Loss: 0.0115\n",
      "Epoch 141/200, Iteration 28/250, Loss: 0.0192\n",
      "Epoch 141/200, Iteration 29/250, Loss: 0.0082\n",
      "Epoch 141/200, Iteration 30/250, Loss: 0.0089\n",
      "Epoch 141/200, Iteration 31/250, Loss: 0.0150\n",
      "Epoch 141/200, Iteration 32/250, Loss: 0.0121\n",
      "Epoch 141/200, Iteration 33/250, Loss: 0.0108\n",
      "Epoch 141/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 141/200, Iteration 35/250, Loss: 0.0314\n",
      "Epoch 141/200, Iteration 36/250, Loss: 0.0174\n",
      "Epoch 141/200, Iteration 37/250, Loss: 0.0142\n",
      "Epoch 141/200, Iteration 38/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 39/250, Loss: 0.0219\n",
      "Epoch 141/200, Iteration 40/250, Loss: 0.0123\n",
      "Epoch 141/200, Iteration 41/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 42/250, Loss: 0.0358\n",
      "Epoch 141/200, Iteration 43/250, Loss: 0.0129\n",
      "Epoch 141/200, Iteration 44/250, Loss: 0.0076\n",
      "Epoch 141/200, Iteration 45/250, Loss: 0.0119\n",
      "Epoch 141/200, Iteration 46/250, Loss: 0.0087\n",
      "Epoch 141/200, Iteration 47/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 48/250, Loss: 0.0202\n",
      "Epoch 141/200, Iteration 49/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 51/250, Loss: 0.0103\n",
      "Epoch 141/200, Iteration 52/250, Loss: 0.0369\n",
      "Epoch 141/200, Iteration 53/250, Loss: 0.0126\n",
      "Epoch 141/200, Iteration 54/250, Loss: 0.0122\n",
      "Epoch 141/200, Iteration 55/250, Loss: 0.0082\n",
      "Epoch 141/200, Iteration 56/250, Loss: 0.0208\n",
      "Epoch 141/200, Iteration 57/250, Loss: 0.0202\n",
      "Epoch 141/200, Iteration 58/250, Loss: 0.0188\n",
      "Epoch 141/200, Iteration 59/250, Loss: 0.0201\n",
      "Epoch 141/200, Iteration 60/250, Loss: 0.0129\n",
      "Epoch 141/200, Iteration 61/250, Loss: 0.0079\n",
      "Epoch 141/200, Iteration 62/250, Loss: 0.0146\n",
      "Epoch 141/200, Iteration 63/250, Loss: 0.0175\n",
      "Epoch 141/200, Iteration 64/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 65/250, Loss: 0.0049\n",
      "Epoch 141/200, Iteration 66/250, Loss: 0.0153\n",
      "Epoch 141/200, Iteration 67/250, Loss: 0.0108\n",
      "Epoch 141/200, Iteration 68/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 69/250, Loss: 0.0105\n",
      "Epoch 141/200, Iteration 70/250, Loss: 0.0082\n",
      "Epoch 141/200, Iteration 71/250, Loss: 0.0163\n",
      "Epoch 141/200, Iteration 72/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 141/200, Iteration 74/250, Loss: 0.0079\n",
      "Epoch 141/200, Iteration 75/250, Loss: 0.0067\n",
      "Epoch 141/200, Iteration 76/250, Loss: 0.0267\n",
      "Epoch 141/200, Iteration 77/250, Loss: 0.0220\n",
      "Epoch 141/200, Iteration 78/250, Loss: 0.0276\n",
      "Epoch 141/200, Iteration 79/250, Loss: 0.0291\n",
      "Epoch 141/200, Iteration 80/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 81/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 82/250, Loss: 0.0112\n",
      "Epoch 141/200, Iteration 83/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 84/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 85/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 86/250, Loss: 0.0146\n",
      "Epoch 141/200, Iteration 87/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 88/250, Loss: 0.0227\n",
      "Epoch 141/200, Iteration 89/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 90/250, Loss: 0.0180\n",
      "Epoch 141/200, Iteration 91/250, Loss: 0.0101\n",
      "Epoch 141/200, Iteration 92/250, Loss: 0.0156\n",
      "Epoch 141/200, Iteration 93/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 94/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 95/250, Loss: 0.0137\n",
      "Epoch 141/200, Iteration 96/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 97/250, Loss: 0.0269\n",
      "Epoch 141/200, Iteration 98/250, Loss: 0.0178\n",
      "Epoch 141/200, Iteration 99/250, Loss: 0.0220\n",
      "Epoch 141/200, Iteration 100/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 101/250, Loss: 0.0399\n",
      "Epoch 141/200, Iteration 102/250, Loss: 0.0137\n",
      "Epoch 141/200, Iteration 103/250, Loss: 0.0064\n",
      "Epoch 141/200, Iteration 104/250, Loss: 0.0136\n",
      "Epoch 141/200, Iteration 105/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 106/250, Loss: 0.0060\n",
      "Epoch 141/200, Iteration 107/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 108/250, Loss: 0.0078\n",
      "Epoch 141/200, Iteration 109/250, Loss: 0.0265\n",
      "Epoch 141/200, Iteration 110/250, Loss: 0.0070\n",
      "Epoch 141/200, Iteration 111/250, Loss: 0.0256\n",
      "Epoch 141/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 141/200, Iteration 113/250, Loss: 0.0161\n",
      "Epoch 141/200, Iteration 114/250, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 115/250, Loss: 0.0234\n",
      "Epoch 141/200, Iteration 116/250, Loss: 0.0132\n",
      "Epoch 141/200, Iteration 117/250, Loss: 0.0067\n",
      "Epoch 141/200, Iteration 118/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 141/200, Iteration 120/250, Loss: 0.0075\n",
      "Epoch 141/200, Iteration 121/250, Loss: 0.0119\n",
      "Epoch 141/200, Iteration 122/250, Loss: 0.0194\n",
      "Epoch 141/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 141/200, Iteration 124/250, Loss: 0.0294\n",
      "Epoch 141/200, Iteration 125/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 126/250, Loss: 0.0101\n",
      "Epoch 141/200, Iteration 127/250, Loss: 0.0168\n",
      "Epoch 141/200, Iteration 128/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 129/250, Loss: 0.0146\n",
      "Epoch 141/200, Iteration 130/250, Loss: 0.0115\n",
      "Epoch 141/200, Iteration 131/250, Loss: 0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200, Iteration 132/250, Loss: 0.0086\n",
      "Epoch 141/200, Iteration 133/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 134/250, Loss: 0.0283\n",
      "Epoch 141/200, Iteration 135/250, Loss: 0.0135\n",
      "Epoch 141/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 137/250, Loss: 0.0110\n",
      "Epoch 141/200, Iteration 138/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 139/250, Loss: 0.0089\n",
      "Epoch 141/200, Iteration 140/250, Loss: 0.0172\n",
      "Epoch 141/200, Iteration 141/250, Loss: 0.0092\n",
      "Epoch 141/200, Iteration 142/250, Loss: 0.0386\n",
      "Epoch 141/200, Iteration 143/250, Loss: 0.0205\n",
      "Epoch 141/200, Iteration 144/250, Loss: 0.0259\n",
      "Epoch 141/200, Iteration 145/250, Loss: 0.0111\n",
      "Epoch 141/200, Iteration 146/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 147/250, Loss: 0.0137\n",
      "Epoch 141/200, Iteration 148/250, Loss: 0.0207\n",
      "Epoch 141/200, Iteration 149/250, Loss: 0.0197\n",
      "Epoch 141/200, Iteration 150/250, Loss: 0.0327\n",
      "Epoch 141/200, Iteration 151/250, Loss: 0.0115\n",
      "Epoch 141/200, Iteration 152/250, Loss: 0.0160\n",
      "Epoch 141/200, Iteration 153/250, Loss: 0.0198\n",
      "Epoch 141/200, Iteration 154/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 141/200, Iteration 156/250, Loss: 0.0205\n",
      "Epoch 141/200, Iteration 157/250, Loss: 0.0190\n",
      "Epoch 141/200, Iteration 158/250, Loss: 0.0208\n",
      "Epoch 141/200, Iteration 159/250, Loss: 0.0121\n",
      "Epoch 141/200, Iteration 160/250, Loss: 0.0082\n",
      "Epoch 141/200, Iteration 161/250, Loss: 0.0212\n",
      "Epoch 141/200, Iteration 162/250, Loss: 0.0279\n",
      "Epoch 141/200, Iteration 163/250, Loss: 0.0389\n",
      "Epoch 141/200, Iteration 164/250, Loss: 0.0111\n",
      "Epoch 141/200, Iteration 165/250, Loss: 0.0311\n",
      "Epoch 141/200, Iteration 166/250, Loss: 0.0103\n",
      "Epoch 141/200, Iteration 167/250, Loss: 0.0058\n",
      "Epoch 141/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 169/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 170/250, Loss: 0.0228\n",
      "Epoch 141/200, Iteration 171/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 172/250, Loss: 0.0256\n",
      "Epoch 141/200, Iteration 173/250, Loss: 0.0320\n",
      "Epoch 141/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 175/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 177/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 178/250, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 179/250, Loss: 0.0082\n",
      "Epoch 141/200, Iteration 180/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 181/250, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 182/250, Loss: 0.0186\n",
      "Epoch 141/200, Iteration 183/250, Loss: 0.0148\n",
      "Epoch 141/200, Iteration 184/250, Loss: 0.0244\n",
      "Epoch 141/200, Iteration 185/250, Loss: 0.0143\n",
      "Epoch 141/200, Iteration 186/250, Loss: 0.0325\n",
      "Epoch 141/200, Iteration 187/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 188/250, Loss: 0.0087\n",
      "Epoch 141/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 141/200, Iteration 191/250, Loss: 0.0257\n",
      "Epoch 141/200, Iteration 192/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 141/200, Iteration 194/250, Loss: 0.0214\n",
      "Epoch 141/200, Iteration 195/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 196/250, Loss: 0.0087\n",
      "Epoch 141/200, Iteration 197/250, Loss: 0.0169\n",
      "Epoch 141/200, Iteration 198/250, Loss: 0.0225\n",
      "Epoch 141/200, Iteration 199/250, Loss: 0.0167\n",
      "Epoch 141/200, Iteration 200/250, Loss: 0.0063\n",
      "Epoch 141/200, Iteration 201/250, Loss: 0.0232\n",
      "Epoch 141/200, Iteration 202/250, Loss: 0.0111\n",
      "Epoch 141/200, Iteration 203/250, Loss: 0.0106\n",
      "Epoch 141/200, Iteration 204/250, Loss: 0.0138\n",
      "Epoch 141/200, Iteration 205/250, Loss: 0.0130\n",
      "Epoch 141/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 141/200, Iteration 207/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 208/250, Loss: 0.0143\n",
      "Epoch 141/200, Iteration 209/250, Loss: 0.0116\n",
      "Epoch 141/200, Iteration 210/250, Loss: 0.0086\n",
      "Epoch 141/200, Iteration 211/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 212/250, Loss: 0.0071\n",
      "Epoch 141/200, Iteration 213/250, Loss: 0.0115\n",
      "Epoch 141/200, Iteration 214/250, Loss: 0.0068\n",
      "Epoch 141/200, Iteration 215/250, Loss: 0.0257\n",
      "Epoch 141/200, Iteration 216/250, Loss: 0.0231\n",
      "Epoch 141/200, Iteration 217/250, Loss: 0.0118\n",
      "Epoch 141/200, Iteration 218/250, Loss: 0.0267\n",
      "Epoch 141/200, Iteration 219/250, Loss: 0.0202\n",
      "Epoch 141/200, Iteration 220/250, Loss: 0.0133\n",
      "Epoch 141/200, Iteration 221/250, Loss: 0.0201\n",
      "Epoch 141/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 223/250, Loss: 0.0222\n",
      "Epoch 141/200, Iteration 224/250, Loss: 0.0487\n",
      "Epoch 141/200, Iteration 225/250, Loss: 0.0119\n",
      "Epoch 141/200, Iteration 226/250, Loss: 0.0232\n",
      "Epoch 141/200, Iteration 227/250, Loss: 0.0057\n",
      "Epoch 141/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 141/200, Iteration 229/250, Loss: 0.0219\n",
      "Epoch 141/200, Iteration 230/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 231/250, Loss: 0.0189\n",
      "Epoch 141/200, Iteration 232/250, Loss: 0.0155\n",
      "Epoch 141/200, Iteration 233/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 235/250, Loss: 0.0110\n",
      "Epoch 141/200, Iteration 236/250, Loss: 0.0275\n",
      "Epoch 141/200, Iteration 237/250, Loss: 0.0271\n",
      "Epoch 141/200, Iteration 238/250, Loss: 0.0062\n",
      "Epoch 141/200, Iteration 239/250, Loss: 0.0288\n",
      "Epoch 141/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 241/250, Loss: 0.0261\n",
      "Epoch 141/200, Iteration 242/250, Loss: 0.0199\n",
      "Epoch 141/200, Iteration 243/250, Loss: 0.0205\n",
      "Epoch 141/200, Iteration 244/250, Loss: 0.0201\n",
      "Epoch 141/200, Iteration 245/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 246/250, Loss: 0.0396\n",
      "Epoch 141/200, Iteration 247/250, Loss: 0.0122\n",
      "Epoch 141/200, Iteration 248/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 249/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 250/250, Loss: 0.0068\n",
      "Train Error: \n",
      " Accuracy: 84.94%, Avg loss: 0.006614, MRE: 0.616164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006655, MRE: 0.834777 \n",
      "\n",
      "Epoch 142/200, Iteration 1/250, Loss: 0.0119\n",
      "Epoch 142/200, Iteration 2/250, Loss: 0.0165\n",
      "Epoch 142/200, Iteration 3/250, Loss: 0.0149\n",
      "Epoch 142/200, Iteration 4/250, Loss: 0.0166\n",
      "Epoch 142/200, Iteration 5/250, Loss: 0.0106\n",
      "Epoch 142/200, Iteration 6/250, Loss: 0.0205\n",
      "Epoch 142/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 8/250, Loss: 0.0164\n",
      "Epoch 142/200, Iteration 9/250, Loss: 0.0065\n",
      "Epoch 142/200, Iteration 10/250, Loss: 0.0174\n",
      "Epoch 142/200, Iteration 11/250, Loss: 0.0087\n",
      "Epoch 142/200, Iteration 12/250, Loss: 0.0087\n",
      "Epoch 142/200, Iteration 13/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 14/250, Loss: 0.0293\n",
      "Epoch 142/200, Iteration 15/250, Loss: 0.0189\n",
      "Epoch 142/200, Iteration 16/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 17/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 18/250, Loss: 0.0170\n",
      "Epoch 142/200, Iteration 19/250, Loss: 0.0103\n",
      "Epoch 142/200, Iteration 20/250, Loss: 0.0183\n",
      "Epoch 142/200, Iteration 21/250, Loss: 0.0135\n",
      "Epoch 142/200, Iteration 22/250, Loss: 0.0098\n",
      "Epoch 142/200, Iteration 23/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 24/250, Loss: 0.0115\n",
      "Epoch 142/200, Iteration 25/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 26/250, Loss: 0.0074\n",
      "Epoch 142/200, Iteration 27/250, Loss: 0.0112\n",
      "Epoch 142/200, Iteration 28/250, Loss: 0.0280\n",
      "Epoch 142/200, Iteration 29/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 30/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 31/250, Loss: 0.0148\n",
      "Epoch 142/200, Iteration 32/250, Loss: 0.0273\n",
      "Epoch 142/200, Iteration 33/250, Loss: 0.0213\n",
      "Epoch 142/200, Iteration 34/250, Loss: 0.0060\n",
      "Epoch 142/200, Iteration 35/250, Loss: 0.0241\n",
      "Epoch 142/200, Iteration 36/250, Loss: 0.0242\n",
      "Epoch 142/200, Iteration 37/250, Loss: 0.0222\n",
      "Epoch 142/200, Iteration 38/250, Loss: 0.0056\n",
      "Epoch 142/200, Iteration 39/250, Loss: 0.0084\n",
      "Epoch 142/200, Iteration 40/250, Loss: 0.0133\n",
      "Epoch 142/200, Iteration 41/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 42/250, Loss: 0.0100\n",
      "Epoch 142/200, Iteration 43/250, Loss: 0.0246\n",
      "Epoch 142/200, Iteration 44/250, Loss: 0.0214\n",
      "Epoch 142/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 46/250, Loss: 0.0127\n",
      "Epoch 142/200, Iteration 47/250, Loss: 0.0120\n",
      "Epoch 142/200, Iteration 48/250, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 49/250, Loss: 0.0164\n",
      "Epoch 142/200, Iteration 50/250, Loss: 0.0242\n",
      "Epoch 142/200, Iteration 51/250, Loss: 0.0169\n",
      "Epoch 142/200, Iteration 52/250, Loss: 0.0189\n",
      "Epoch 142/200, Iteration 53/250, Loss: 0.0146\n",
      "Epoch 142/200, Iteration 54/250, Loss: 0.0084\n",
      "Epoch 142/200, Iteration 55/250, Loss: 0.0137\n",
      "Epoch 142/200, Iteration 56/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 57/250, Loss: 0.0106\n",
      "Epoch 142/200, Iteration 58/250, Loss: 0.0059\n",
      "Epoch 142/200, Iteration 59/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 60/250, Loss: 0.0254\n",
      "Epoch 142/200, Iteration 61/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 62/250, Loss: 0.0068\n",
      "Epoch 142/200, Iteration 63/250, Loss: 0.0134\n",
      "Epoch 142/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 65/250, Loss: 0.0247\n",
      "Epoch 142/200, Iteration 66/250, Loss: 0.0277\n",
      "Epoch 142/200, Iteration 67/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 68/250, Loss: 0.0137\n",
      "Epoch 142/200, Iteration 69/250, Loss: 0.0127\n",
      "Epoch 142/200, Iteration 70/250, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 71/250, Loss: 0.0370\n",
      "Epoch 142/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 73/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 74/250, Loss: 0.0199\n",
      "Epoch 142/200, Iteration 75/250, Loss: 0.0173\n",
      "Epoch 142/200, Iteration 76/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 77/250, Loss: 0.0066\n",
      "Epoch 142/200, Iteration 78/250, Loss: 0.0171\n",
      "Epoch 142/200, Iteration 79/250, Loss: 0.0126\n",
      "Epoch 142/200, Iteration 80/250, Loss: 0.0189\n",
      "Epoch 142/200, Iteration 81/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 82/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 83/250, Loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200, Iteration 84/250, Loss: 0.0125\n",
      "Epoch 142/200, Iteration 85/250, Loss: 0.0214\n",
      "Epoch 142/200, Iteration 86/250, Loss: 0.0187\n",
      "Epoch 142/200, Iteration 87/250, Loss: 0.0161\n",
      "Epoch 142/200, Iteration 88/250, Loss: 0.0143\n",
      "Epoch 142/200, Iteration 89/250, Loss: 0.0122\n",
      "Epoch 142/200, Iteration 90/250, Loss: 0.0170\n",
      "Epoch 142/200, Iteration 91/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 92/250, Loss: 0.0069\n",
      "Epoch 142/200, Iteration 93/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 94/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 95/250, Loss: 0.0077\n",
      "Epoch 142/200, Iteration 96/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 97/250, Loss: 0.0142\n",
      "Epoch 142/200, Iteration 98/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 99/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 100/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 101/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 102/250, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 103/250, Loss: 0.0164\n",
      "Epoch 142/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 105/250, Loss: 0.0267\n",
      "Epoch 142/200, Iteration 106/250, Loss: 0.0120\n",
      "Epoch 142/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 108/250, Loss: 0.0173\n",
      "Epoch 142/200, Iteration 109/250, Loss: 0.0120\n",
      "Epoch 142/200, Iteration 110/250, Loss: 0.0105\n",
      "Epoch 142/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 112/250, Loss: 0.0115\n",
      "Epoch 142/200, Iteration 113/250, Loss: 0.0206\n",
      "Epoch 142/200, Iteration 114/250, Loss: 0.0155\n",
      "Epoch 142/200, Iteration 115/250, Loss: 0.0294\n",
      "Epoch 142/200, Iteration 116/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 117/250, Loss: 0.0231\n",
      "Epoch 142/200, Iteration 118/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 119/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 120/250, Loss: 0.0084\n",
      "Epoch 142/200, Iteration 121/250, Loss: 0.0129\n",
      "Epoch 142/200, Iteration 122/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 123/250, Loss: 0.0126\n",
      "Epoch 142/200, Iteration 124/250, Loss: 0.0159\n",
      "Epoch 142/200, Iteration 125/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 127/250, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 128/250, Loss: 0.0097\n",
      "Epoch 142/200, Iteration 129/250, Loss: 0.0226\n",
      "Epoch 142/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 131/250, Loss: 0.0140\n",
      "Epoch 142/200, Iteration 132/250, Loss: 0.0078\n",
      "Epoch 142/200, Iteration 133/250, Loss: 0.0207\n",
      "Epoch 142/200, Iteration 134/250, Loss: 0.0230\n",
      "Epoch 142/200, Iteration 135/250, Loss: 0.0129\n",
      "Epoch 142/200, Iteration 136/250, Loss: 0.0089\n",
      "Epoch 142/200, Iteration 137/250, Loss: 0.0266\n",
      "Epoch 142/200, Iteration 138/250, Loss: 0.0153\n",
      "Epoch 142/200, Iteration 139/250, Loss: 0.0154\n",
      "Epoch 142/200, Iteration 140/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 141/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 142/250, Loss: 0.0197\n",
      "Epoch 142/200, Iteration 143/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 144/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 145/250, Loss: 0.0316\n",
      "Epoch 142/200, Iteration 146/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 147/250, Loss: 0.0128\n",
      "Epoch 142/200, Iteration 148/250, Loss: 0.0110\n",
      "Epoch 142/200, Iteration 149/250, Loss: 0.0231\n",
      "Epoch 142/200, Iteration 150/250, Loss: 0.0134\n",
      "Epoch 142/200, Iteration 151/250, Loss: 0.0118\n",
      "Epoch 142/200, Iteration 152/250, Loss: 0.0103\n",
      "Epoch 142/200, Iteration 153/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 155/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 156/250, Loss: 0.0079\n",
      "Epoch 142/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 158/250, Loss: 0.0173\n",
      "Epoch 142/200, Iteration 159/250, Loss: 0.0218\n",
      "Epoch 142/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 142/200, Iteration 161/250, Loss: 0.0226\n",
      "Epoch 142/200, Iteration 162/250, Loss: 0.0118\n",
      "Epoch 142/200, Iteration 163/250, Loss: 0.0091\n",
      "Epoch 142/200, Iteration 164/250, Loss: 0.0136\n",
      "Epoch 142/200, Iteration 165/250, Loss: 0.0202\n",
      "Epoch 142/200, Iteration 166/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 167/250, Loss: 0.0123\n",
      "Epoch 142/200, Iteration 168/250, Loss: 0.0205\n",
      "Epoch 142/200, Iteration 169/250, Loss: 0.0124\n",
      "Epoch 142/200, Iteration 170/250, Loss: 0.0206\n",
      "Epoch 142/200, Iteration 171/250, Loss: 0.0176\n",
      "Epoch 142/200, Iteration 172/250, Loss: 0.0205\n",
      "Epoch 142/200, Iteration 173/250, Loss: 0.0139\n",
      "Epoch 142/200, Iteration 174/250, Loss: 0.0163\n",
      "Epoch 142/200, Iteration 175/250, Loss: 0.0173\n",
      "Epoch 142/200, Iteration 176/250, Loss: 0.0163\n",
      "Epoch 142/200, Iteration 177/250, Loss: 0.0152\n",
      "Epoch 142/200, Iteration 178/250, Loss: 0.0140\n",
      "Epoch 142/200, Iteration 179/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 180/250, Loss: 0.0305\n",
      "Epoch 142/200, Iteration 181/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 182/250, Loss: 0.0113\n",
      "Epoch 142/200, Iteration 183/250, Loss: 0.0128\n",
      "Epoch 142/200, Iteration 184/250, Loss: 0.0110\n",
      "Epoch 142/200, Iteration 185/250, Loss: 0.0134\n",
      "Epoch 142/200, Iteration 186/250, Loss: 0.0063\n",
      "Epoch 142/200, Iteration 187/250, Loss: 0.0146\n",
      "Epoch 142/200, Iteration 188/250, Loss: 0.0200\n",
      "Epoch 142/200, Iteration 189/250, Loss: 0.0291\n",
      "Epoch 142/200, Iteration 190/250, Loss: 0.0328\n",
      "Epoch 142/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 192/250, Loss: 0.0124\n",
      "Epoch 142/200, Iteration 193/250, Loss: 0.0184\n",
      "Epoch 142/200, Iteration 194/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 195/250, Loss: 0.0110\n",
      "Epoch 142/200, Iteration 196/250, Loss: 0.0127\n",
      "Epoch 142/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 198/250, Loss: 0.0073\n",
      "Epoch 142/200, Iteration 199/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 200/250, Loss: 0.0267\n",
      "Epoch 142/200, Iteration 201/250, Loss: 0.0251\n",
      "Epoch 142/200, Iteration 202/250, Loss: 0.0232\n",
      "Epoch 142/200, Iteration 203/250, Loss: 0.0151\n",
      "Epoch 142/200, Iteration 204/250, Loss: 0.0126\n",
      "Epoch 142/200, Iteration 205/250, Loss: 0.0120\n",
      "Epoch 142/200, Iteration 206/250, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 207/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 208/250, Loss: 0.0121\n",
      "Epoch 142/200, Iteration 209/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 210/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 211/250, Loss: 0.0111\n",
      "Epoch 142/200, Iteration 212/250, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 213/250, Loss: 0.0176\n",
      "Epoch 142/200, Iteration 214/250, Loss: 0.0078\n",
      "Epoch 142/200, Iteration 215/250, Loss: 0.0194\n",
      "Epoch 142/200, Iteration 216/250, Loss: 0.0148\n",
      "Epoch 142/200, Iteration 217/250, Loss: 0.0058\n",
      "Epoch 142/200, Iteration 218/250, Loss: 0.0073\n",
      "Epoch 142/200, Iteration 219/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 220/250, Loss: 0.0089\n",
      "Epoch 142/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 142/200, Iteration 222/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 223/250, Loss: 0.0125\n",
      "Epoch 142/200, Iteration 224/250, Loss: 0.0126\n",
      "Epoch 142/200, Iteration 225/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 226/250, Loss: 0.0201\n",
      "Epoch 142/200, Iteration 227/250, Loss: 0.0146\n",
      "Epoch 142/200, Iteration 228/250, Loss: 0.0089\n",
      "Epoch 142/200, Iteration 229/250, Loss: 0.0169\n",
      "Epoch 142/200, Iteration 230/250, Loss: 0.0136\n",
      "Epoch 142/200, Iteration 231/250, Loss: 0.0196\n",
      "Epoch 142/200, Iteration 232/250, Loss: 0.0112\n",
      "Epoch 142/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 142/200, Iteration 234/250, Loss: 0.0198\n",
      "Epoch 142/200, Iteration 235/250, Loss: 0.0226\n",
      "Epoch 142/200, Iteration 236/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 237/250, Loss: 0.0362\n",
      "Epoch 142/200, Iteration 238/250, Loss: 0.0178\n",
      "Epoch 142/200, Iteration 239/250, Loss: 0.0219\n",
      "Epoch 142/200, Iteration 240/250, Loss: 0.0111\n",
      "Epoch 142/200, Iteration 241/250, Loss: 0.0135\n",
      "Epoch 142/200, Iteration 242/250, Loss: 0.0204\n",
      "Epoch 142/200, Iteration 243/250, Loss: 0.0144\n",
      "Epoch 142/200, Iteration 244/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 142/200, Iteration 247/250, Loss: 0.0255\n",
      "Epoch 142/200, Iteration 248/250, Loss: 0.0338\n",
      "Epoch 142/200, Iteration 249/250, Loss: 0.0100\n",
      "Epoch 142/200, Iteration 250/250, Loss: 0.0313\n",
      "Train Error: \n",
      " Accuracy: 97.78%, Avg loss: 0.009242, MRE: 0.889858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.009089, MRE: 1.566889 \n",
      "\n",
      "Epoch 143/200, Iteration 1/250, Loss: 0.0102\n",
      "Epoch 143/200, Iteration 2/250, Loss: 0.0156\n",
      "Epoch 143/200, Iteration 3/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 4/250, Loss: 0.0131\n",
      "Epoch 143/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 6/250, Loss: 0.0184\n",
      "Epoch 143/200, Iteration 7/250, Loss: 0.0091\n",
      "Epoch 143/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 143/200, Iteration 9/250, Loss: 0.0166\n",
      "Epoch 143/200, Iteration 10/250, Loss: 0.0169\n",
      "Epoch 143/200, Iteration 11/250, Loss: 0.0142\n",
      "Epoch 143/200, Iteration 12/250, Loss: 0.0210\n",
      "Epoch 143/200, Iteration 13/250, Loss: 0.0178\n",
      "Epoch 143/200, Iteration 14/250, Loss: 0.0152\n",
      "Epoch 143/200, Iteration 15/250, Loss: 0.0248\n",
      "Epoch 143/200, Iteration 16/250, Loss: 0.0188\n",
      "Epoch 143/200, Iteration 17/250, Loss: 0.0204\n",
      "Epoch 143/200, Iteration 18/250, Loss: 0.0141\n",
      "Epoch 143/200, Iteration 19/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 143/200, Iteration 21/250, Loss: 0.0102\n",
      "Epoch 143/200, Iteration 22/250, Loss: 0.0132\n",
      "Epoch 143/200, Iteration 23/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 24/250, Loss: 0.0167\n",
      "Epoch 143/200, Iteration 25/250, Loss: 0.0250\n",
      "Epoch 143/200, Iteration 26/250, Loss: 0.0298\n",
      "Epoch 143/200, Iteration 27/250, Loss: 0.0077\n",
      "Epoch 143/200, Iteration 28/250, Loss: 0.0065\n",
      "Epoch 143/200, Iteration 29/250, Loss: 0.0081\n",
      "Epoch 143/200, Iteration 30/250, Loss: 0.0233\n",
      "Epoch 143/200, Iteration 31/250, Loss: 0.0095\n",
      "Epoch 143/200, Iteration 32/250, Loss: 0.0188\n",
      "Epoch 143/200, Iteration 33/250, Loss: 0.0079\n",
      "Epoch 143/200, Iteration 34/250, Loss: 0.0117\n",
      "Epoch 143/200, Iteration 35/250, Loss: 0.0076\n",
      "Epoch 143/200, Iteration 36/250, Loss: 0.0187\n",
      "Epoch 143/200, Iteration 37/250, Loss: 0.0122\n",
      "Epoch 143/200, Iteration 38/250, Loss: 0.0158\n",
      "Epoch 143/200, Iteration 39/250, Loss: 0.0264\n",
      "Epoch 143/200, Iteration 40/250, Loss: 0.0079\n",
      "Epoch 143/200, Iteration 41/250, Loss: 0.0186\n",
      "Epoch 143/200, Iteration 42/250, Loss: 0.0166\n",
      "Epoch 143/200, Iteration 43/250, Loss: 0.0147\n",
      "Epoch 143/200, Iteration 44/250, Loss: 0.0106\n",
      "Epoch 143/200, Iteration 45/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 46/250, Loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200, Iteration 47/250, Loss: 0.0160\n",
      "Epoch 143/200, Iteration 48/250, Loss: 0.0184\n",
      "Epoch 143/200, Iteration 49/250, Loss: 0.0088\n",
      "Epoch 143/200, Iteration 50/250, Loss: 0.0188\n",
      "Epoch 143/200, Iteration 51/250, Loss: 0.0158\n",
      "Epoch 143/200, Iteration 52/250, Loss: 0.0114\n",
      "Epoch 143/200, Iteration 53/250, Loss: 0.0223\n",
      "Epoch 143/200, Iteration 54/250, Loss: 0.0069\n",
      "Epoch 143/200, Iteration 55/250, Loss: 0.0334\n",
      "Epoch 143/200, Iteration 56/250, Loss: 0.0164\n",
      "Epoch 143/200, Iteration 57/250, Loss: 0.0192\n",
      "Epoch 143/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 143/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 143/200, Iteration 60/250, Loss: 0.0208\n",
      "Epoch 143/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 62/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 63/250, Loss: 0.0084\n",
      "Epoch 143/200, Iteration 64/250, Loss: 0.0203\n",
      "Epoch 143/200, Iteration 65/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 66/250, Loss: 0.0138\n",
      "Epoch 143/200, Iteration 67/250, Loss: 0.0118\n",
      "Epoch 143/200, Iteration 68/250, Loss: 0.0165\n",
      "Epoch 143/200, Iteration 69/250, Loss: 0.0232\n",
      "Epoch 143/200, Iteration 70/250, Loss: 0.0154\n",
      "Epoch 143/200, Iteration 71/250, Loss: 0.0223\n",
      "Epoch 143/200, Iteration 72/250, Loss: 0.0080\n",
      "Epoch 143/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 74/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 75/250, Loss: 0.0249\n",
      "Epoch 143/200, Iteration 76/250, Loss: 0.0147\n",
      "Epoch 143/200, Iteration 77/250, Loss: 0.0117\n",
      "Epoch 143/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 143/200, Iteration 79/250, Loss: 0.0183\n",
      "Epoch 143/200, Iteration 80/250, Loss: 0.0214\n",
      "Epoch 143/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 83/250, Loss: 0.0313\n",
      "Epoch 143/200, Iteration 84/250, Loss: 0.0076\n",
      "Epoch 143/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 143/200, Iteration 86/250, Loss: 0.0068\n",
      "Epoch 143/200, Iteration 87/250, Loss: 0.0068\n",
      "Epoch 143/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 143/200, Iteration 89/250, Loss: 0.0162\n",
      "Epoch 143/200, Iteration 90/250, Loss: 0.0081\n",
      "Epoch 143/200, Iteration 91/250, Loss: 0.0136\n",
      "Epoch 143/200, Iteration 92/250, Loss: 0.0129\n",
      "Epoch 143/200, Iteration 93/250, Loss: 0.0169\n",
      "Epoch 143/200, Iteration 94/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 95/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 96/250, Loss: 0.0249\n",
      "Epoch 143/200, Iteration 97/250, Loss: 0.0100\n",
      "Epoch 143/200, Iteration 98/250, Loss: 0.0139\n",
      "Epoch 143/200, Iteration 99/250, Loss: 0.0419\n",
      "Epoch 143/200, Iteration 100/250, Loss: 0.0379\n",
      "Epoch 143/200, Iteration 101/250, Loss: 0.0116\n",
      "Epoch 143/200, Iteration 102/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 103/250, Loss: 0.0197\n",
      "Epoch 143/200, Iteration 104/250, Loss: 0.0129\n",
      "Epoch 143/200, Iteration 105/250, Loss: 0.0050\n",
      "Epoch 143/200, Iteration 106/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 143/200, Iteration 108/250, Loss: 0.0238\n",
      "Epoch 143/200, Iteration 109/250, Loss: 0.0110\n",
      "Epoch 143/200, Iteration 110/250, Loss: 0.0198\n",
      "Epoch 143/200, Iteration 111/250, Loss: 0.0190\n",
      "Epoch 143/200, Iteration 112/250, Loss: 0.0467\n",
      "Epoch 143/200, Iteration 113/250, Loss: 0.0181\n",
      "Epoch 143/200, Iteration 114/250, Loss: 0.0103\n",
      "Epoch 143/200, Iteration 115/250, Loss: 0.0126\n",
      "Epoch 143/200, Iteration 116/250, Loss: 0.0096\n",
      "Epoch 143/200, Iteration 117/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 118/250, Loss: 0.0075\n",
      "Epoch 143/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 143/200, Iteration 120/250, Loss: 0.0212\n",
      "Epoch 143/200, Iteration 121/250, Loss: 0.0062\n",
      "Epoch 143/200, Iteration 122/250, Loss: 0.0142\n",
      "Epoch 143/200, Iteration 123/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 124/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 125/250, Loss: 0.0113\n",
      "Epoch 143/200, Iteration 126/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 127/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 128/250, Loss: 0.0061\n",
      "Epoch 143/200, Iteration 129/250, Loss: 0.0286\n",
      "Epoch 143/200, Iteration 130/250, Loss: 0.0088\n",
      "Epoch 143/200, Iteration 131/250, Loss: 0.0115\n",
      "Epoch 143/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 133/250, Loss: 0.0252\n",
      "Epoch 143/200, Iteration 134/250, Loss: 0.0135\n",
      "Epoch 143/200, Iteration 135/250, Loss: 0.0147\n",
      "Epoch 143/200, Iteration 136/250, Loss: 0.0106\n",
      "Epoch 143/200, Iteration 137/250, Loss: 0.0205\n",
      "Epoch 143/200, Iteration 138/250, Loss: 0.0144\n",
      "Epoch 143/200, Iteration 139/250, Loss: 0.0136\n",
      "Epoch 143/200, Iteration 140/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 142/250, Loss: 0.0148\n",
      "Epoch 143/200, Iteration 143/250, Loss: 0.0350\n",
      "Epoch 143/200, Iteration 144/250, Loss: 0.0160\n",
      "Epoch 143/200, Iteration 145/250, Loss: 0.0213\n",
      "Epoch 143/200, Iteration 146/250, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 147/250, Loss: 0.0149\n",
      "Epoch 143/200, Iteration 148/250, Loss: 0.0233\n",
      "Epoch 143/200, Iteration 149/250, Loss: 0.0231\n",
      "Epoch 143/200, Iteration 150/250, Loss: 0.0181\n",
      "Epoch 143/200, Iteration 151/250, Loss: 0.0197\n",
      "Epoch 143/200, Iteration 152/250, Loss: 0.0139\n",
      "Epoch 143/200, Iteration 153/250, Loss: 0.0252\n",
      "Epoch 143/200, Iteration 154/250, Loss: 0.0165\n",
      "Epoch 143/200, Iteration 155/250, Loss: 0.0150\n",
      "Epoch 143/200, Iteration 156/250, Loss: 0.0111\n",
      "Epoch 143/200, Iteration 157/250, Loss: 0.0314\n",
      "Epoch 143/200, Iteration 158/250, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 159/250, Loss: 0.0131\n",
      "Epoch 143/200, Iteration 160/250, Loss: 0.0446\n",
      "Epoch 143/200, Iteration 161/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 162/250, Loss: 0.0216\n",
      "Epoch 143/200, Iteration 163/250, Loss: 0.0220\n",
      "Epoch 143/200, Iteration 164/250, Loss: 0.0171\n",
      "Epoch 143/200, Iteration 165/250, Loss: 0.0117\n",
      "Epoch 143/200, Iteration 166/250, Loss: 0.0117\n",
      "Epoch 143/200, Iteration 167/250, Loss: 0.0221\n",
      "Epoch 143/200, Iteration 168/250, Loss: 0.0208\n",
      "Epoch 143/200, Iteration 169/250, Loss: 0.0237\n",
      "Epoch 143/200, Iteration 170/250, Loss: 0.0111\n",
      "Epoch 143/200, Iteration 171/250, Loss: 0.0059\n",
      "Epoch 143/200, Iteration 172/250, Loss: 0.0120\n",
      "Epoch 143/200, Iteration 173/250, Loss: 0.0165\n",
      "Epoch 143/200, Iteration 174/250, Loss: 0.0077\n",
      "Epoch 143/200, Iteration 175/250, Loss: 0.0331\n",
      "Epoch 143/200, Iteration 176/250, Loss: 0.0071\n",
      "Epoch 143/200, Iteration 177/250, Loss: 0.0174\n",
      "Epoch 143/200, Iteration 178/250, Loss: 0.0168\n",
      "Epoch 143/200, Iteration 179/250, Loss: 0.0087\n",
      "Epoch 143/200, Iteration 180/250, Loss: 0.0124\n",
      "Epoch 143/200, Iteration 181/250, Loss: 0.0173\n",
      "Epoch 143/200, Iteration 182/250, Loss: 0.0120\n",
      "Epoch 143/200, Iteration 183/250, Loss: 0.0163\n",
      "Epoch 143/200, Iteration 184/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 185/250, Loss: 0.0149\n",
      "Epoch 143/200, Iteration 186/250, Loss: 0.0195\n",
      "Epoch 143/200, Iteration 187/250, Loss: 0.0080\n",
      "Epoch 143/200, Iteration 188/250, Loss: 0.0157\n",
      "Epoch 143/200, Iteration 189/250, Loss: 0.0270\n",
      "Epoch 143/200, Iteration 190/250, Loss: 0.0210\n",
      "Epoch 143/200, Iteration 191/250, Loss: 0.0145\n",
      "Epoch 143/200, Iteration 192/250, Loss: 0.0057\n",
      "Epoch 143/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 194/250, Loss: 0.0166\n",
      "Epoch 143/200, Iteration 195/250, Loss: 0.0233\n",
      "Epoch 143/200, Iteration 196/250, Loss: 0.0137\n",
      "Epoch 143/200, Iteration 197/250, Loss: 0.0205\n",
      "Epoch 143/200, Iteration 198/250, Loss: 0.0126\n",
      "Epoch 143/200, Iteration 199/250, Loss: 0.0189\n",
      "Epoch 143/200, Iteration 200/250, Loss: 0.0164\n",
      "Epoch 143/200, Iteration 201/250, Loss: 0.0225\n",
      "Epoch 143/200, Iteration 202/250, Loss: 0.0080\n",
      "Epoch 143/200, Iteration 203/250, Loss: 0.0248\n",
      "Epoch 143/200, Iteration 204/250, Loss: 0.0254\n",
      "Epoch 143/200, Iteration 205/250, Loss: 0.0085\n",
      "Epoch 143/200, Iteration 206/250, Loss: 0.0182\n",
      "Epoch 143/200, Iteration 207/250, Loss: 0.0080\n",
      "Epoch 143/200, Iteration 208/250, Loss: 0.0189\n",
      "Epoch 143/200, Iteration 209/250, Loss: 0.0234\n",
      "Epoch 143/200, Iteration 210/250, Loss: 0.0220\n",
      "Epoch 143/200, Iteration 211/250, Loss: 0.0124\n",
      "Epoch 143/200, Iteration 212/250, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 213/250, Loss: 0.0110\n",
      "Epoch 143/200, Iteration 214/250, Loss: 0.0255\n",
      "Epoch 143/200, Iteration 215/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 216/250, Loss: 0.0147\n",
      "Epoch 143/200, Iteration 217/250, Loss: 0.0210\n",
      "Epoch 143/200, Iteration 218/250, Loss: 0.0124\n",
      "Epoch 143/200, Iteration 219/250, Loss: 0.0094\n",
      "Epoch 143/200, Iteration 220/250, Loss: 0.0056\n",
      "Epoch 143/200, Iteration 221/250, Loss: 0.0090\n",
      "Epoch 143/200, Iteration 222/250, Loss: 0.0077\n",
      "Epoch 143/200, Iteration 223/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 224/250, Loss: 0.0140\n",
      "Epoch 143/200, Iteration 225/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 226/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 227/250, Loss: 0.0149\n",
      "Epoch 143/200, Iteration 228/250, Loss: 0.0276\n",
      "Epoch 143/200, Iteration 229/250, Loss: 0.0152\n",
      "Epoch 143/200, Iteration 230/250, Loss: 0.0374\n",
      "Epoch 143/200, Iteration 231/250, Loss: 0.0176\n",
      "Epoch 143/200, Iteration 232/250, Loss: 0.0241\n",
      "Epoch 143/200, Iteration 233/250, Loss: 0.0089\n",
      "Epoch 143/200, Iteration 234/250, Loss: 0.0189\n",
      "Epoch 143/200, Iteration 235/250, Loss: 0.0134\n",
      "Epoch 143/200, Iteration 236/250, Loss: 0.0280\n",
      "Epoch 143/200, Iteration 237/250, Loss: 0.0130\n",
      "Epoch 143/200, Iteration 238/250, Loss: 0.0163\n",
      "Epoch 143/200, Iteration 239/250, Loss: 0.0263\n",
      "Epoch 143/200, Iteration 240/250, Loss: 0.0118\n",
      "Epoch 143/200, Iteration 241/250, Loss: 0.0130\n",
      "Epoch 143/200, Iteration 242/250, Loss: 0.0085\n",
      "Epoch 143/200, Iteration 243/250, Loss: 0.0152\n",
      "Epoch 143/200, Iteration 244/250, Loss: 0.0072\n",
      "Epoch 143/200, Iteration 245/250, Loss: 0.0396\n",
      "Epoch 143/200, Iteration 246/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 247/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 248/250, Loss: 0.0173\n",
      "Epoch 143/200, Iteration 249/250, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 250/250, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.89%, Avg loss: 0.006370, MRE: 0.611434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.006425, MRE: 0.983456 \n",
      "\n",
      "Epoch 144/200, Iteration 1/250, Loss: 0.0062\n",
      "Epoch 144/200, Iteration 2/250, Loss: 0.0155\n",
      "Epoch 144/200, Iteration 3/250, Loss: 0.0125\n",
      "Epoch 144/200, Iteration 4/250, Loss: 0.0122\n",
      "Epoch 144/200, Iteration 5/250, Loss: 0.0198\n",
      "Epoch 144/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 7/250, Loss: 0.0143\n",
      "Epoch 144/200, Iteration 8/250, Loss: 0.0436\n",
      "Epoch 144/200, Iteration 9/250, Loss: 0.0079\n",
      "Epoch 144/200, Iteration 10/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 11/250, Loss: 0.0145\n",
      "Epoch 144/200, Iteration 12/250, Loss: 0.0068\n",
      "Epoch 144/200, Iteration 13/250, Loss: 0.0148\n",
      "Epoch 144/200, Iteration 14/250, Loss: 0.0126\n",
      "Epoch 144/200, Iteration 15/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 16/250, Loss: 0.0128\n",
      "Epoch 144/200, Iteration 17/250, Loss: 0.0099\n",
      "Epoch 144/200, Iteration 18/250, Loss: 0.0074\n",
      "Epoch 144/200, Iteration 19/250, Loss: 0.0420\n",
      "Epoch 144/200, Iteration 20/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 21/250, Loss: 0.0097\n",
      "Epoch 144/200, Iteration 22/250, Loss: 0.0074\n",
      "Epoch 144/200, Iteration 23/250, Loss: 0.0077\n",
      "Epoch 144/200, Iteration 24/250, Loss: 0.0112\n",
      "Epoch 144/200, Iteration 25/250, Loss: 0.0086\n",
      "Epoch 144/200, Iteration 26/250, Loss: 0.0323\n",
      "Epoch 144/200, Iteration 27/250, Loss: 0.0214\n",
      "Epoch 144/200, Iteration 28/250, Loss: 0.0119\n",
      "Epoch 144/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 144/200, Iteration 30/250, Loss: 0.0189\n",
      "Epoch 144/200, Iteration 31/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 32/250, Loss: 0.0160\n",
      "Epoch 144/200, Iteration 33/250, Loss: 0.0295\n",
      "Epoch 144/200, Iteration 34/250, Loss: 0.0110\n",
      "Epoch 144/200, Iteration 35/250, Loss: 0.0105\n",
      "Epoch 144/200, Iteration 36/250, Loss: 0.0101\n",
      "Epoch 144/200, Iteration 37/250, Loss: 0.0248\n",
      "Epoch 144/200, Iteration 38/250, Loss: 0.0141\n",
      "Epoch 144/200, Iteration 39/250, Loss: 0.0124\n",
      "Epoch 144/200, Iteration 40/250, Loss: 0.0080\n",
      "Epoch 144/200, Iteration 41/250, Loss: 0.0248\n",
      "Epoch 144/200, Iteration 42/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 43/250, Loss: 0.0204\n",
      "Epoch 144/200, Iteration 44/250, Loss: 0.0223\n",
      "Epoch 144/200, Iteration 45/250, Loss: 0.0127\n",
      "Epoch 144/200, Iteration 46/250, Loss: 0.0071\n",
      "Epoch 144/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 144/200, Iteration 48/250, Loss: 0.0167\n",
      "Epoch 144/200, Iteration 49/250, Loss: 0.0065\n",
      "Epoch 144/200, Iteration 50/250, Loss: 0.0071\n",
      "Epoch 144/200, Iteration 51/250, Loss: 0.0123\n",
      "Epoch 144/200, Iteration 52/250, Loss: 0.0167\n",
      "Epoch 144/200, Iteration 53/250, Loss: 0.0172\n",
      "Epoch 144/200, Iteration 54/250, Loss: 0.0161\n",
      "Epoch 144/200, Iteration 55/250, Loss: 0.0090\n",
      "Epoch 144/200, Iteration 56/250, Loss: 0.0182\n",
      "Epoch 144/200, Iteration 57/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 58/250, Loss: 0.0087\n",
      "Epoch 144/200, Iteration 59/250, Loss: 0.0274\n",
      "Epoch 144/200, Iteration 60/250, Loss: 0.0166\n",
      "Epoch 144/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 62/250, Loss: 0.0151\n",
      "Epoch 144/200, Iteration 63/250, Loss: 0.0067\n",
      "Epoch 144/200, Iteration 64/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 65/250, Loss: 0.0145\n",
      "Epoch 144/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 67/250, Loss: 0.0181\n",
      "Epoch 144/200, Iteration 68/250, Loss: 0.0298\n",
      "Epoch 144/200, Iteration 69/250, Loss: 0.0148\n",
      "Epoch 144/200, Iteration 70/250, Loss: 0.0093\n",
      "Epoch 144/200, Iteration 71/250, Loss: 0.0087\n",
      "Epoch 144/200, Iteration 72/250, Loss: 0.0147\n",
      "Epoch 144/200, Iteration 73/250, Loss: 0.0117\n",
      "Epoch 144/200, Iteration 74/250, Loss: 0.0096\n",
      "Epoch 144/200, Iteration 75/250, Loss: 0.0199\n",
      "Epoch 144/200, Iteration 76/250, Loss: 0.0172\n",
      "Epoch 144/200, Iteration 77/250, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 78/250, Loss: 0.0265\n",
      "Epoch 144/200, Iteration 79/250, Loss: 0.0240\n",
      "Epoch 144/200, Iteration 80/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 81/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 82/250, Loss: 0.0147\n",
      "Epoch 144/200, Iteration 83/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 84/250, Loss: 0.0190\n",
      "Epoch 144/200, Iteration 85/250, Loss: 0.0069\n",
      "Epoch 144/200, Iteration 86/250, Loss: 0.0200\n",
      "Epoch 144/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 88/250, Loss: 0.0200\n",
      "Epoch 144/200, Iteration 89/250, Loss: 0.0162\n",
      "Epoch 144/200, Iteration 90/250, Loss: 0.0244\n",
      "Epoch 144/200, Iteration 91/250, Loss: 0.0176\n",
      "Epoch 144/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 144/200, Iteration 93/250, Loss: 0.0139\n",
      "Epoch 144/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 95/250, Loss: 0.0088\n",
      "Epoch 144/200, Iteration 96/250, Loss: 0.0073\n",
      "Epoch 144/200, Iteration 97/250, Loss: 0.0140\n",
      "Epoch 144/200, Iteration 98/250, Loss: 0.0137\n",
      "Epoch 144/200, Iteration 99/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 100/250, Loss: 0.0166\n",
      "Epoch 144/200, Iteration 101/250, Loss: 0.0178\n",
      "Epoch 144/200, Iteration 102/250, Loss: 0.0160\n",
      "Epoch 144/200, Iteration 103/250, Loss: 0.0158\n",
      "Epoch 144/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 105/250, Loss: 0.0091\n",
      "Epoch 144/200, Iteration 106/250, Loss: 0.0129\n",
      "Epoch 144/200, Iteration 107/250, Loss: 0.0130\n",
      "Epoch 144/200, Iteration 108/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 109/250, Loss: 0.0155\n",
      "Epoch 144/200, Iteration 110/250, Loss: 0.0155\n",
      "Epoch 144/200, Iteration 111/250, Loss: 0.0236\n",
      "Epoch 144/200, Iteration 112/250, Loss: 0.0080\n",
      "Epoch 144/200, Iteration 113/250, Loss: 0.0125\n",
      "Epoch 144/200, Iteration 114/250, Loss: 0.0077\n",
      "Epoch 144/200, Iteration 115/250, Loss: 0.0110\n",
      "Epoch 144/200, Iteration 116/250, Loss: 0.0080\n",
      "Epoch 144/200, Iteration 117/250, Loss: 0.0320\n",
      "Epoch 144/200, Iteration 118/250, Loss: 0.0384\n",
      "Epoch 144/200, Iteration 119/250, Loss: 0.0196\n",
      "Epoch 144/200, Iteration 120/250, Loss: 0.0134\n",
      "Epoch 144/200, Iteration 121/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 122/250, Loss: 0.0161\n",
      "Epoch 144/200, Iteration 123/250, Loss: 0.0240\n",
      "Epoch 144/200, Iteration 124/250, Loss: 0.0086\n",
      "Epoch 144/200, Iteration 125/250, Loss: 0.0225\n",
      "Epoch 144/200, Iteration 126/250, Loss: 0.0295\n",
      "Epoch 144/200, Iteration 127/250, Loss: 0.0079\n",
      "Epoch 144/200, Iteration 128/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 129/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 130/250, Loss: 0.0159\n",
      "Epoch 144/200, Iteration 131/250, Loss: 0.0203\n",
      "Epoch 144/200, Iteration 132/250, Loss: 0.0140\n",
      "Epoch 144/200, Iteration 133/250, Loss: 0.0101\n",
      "Epoch 144/200, Iteration 134/250, Loss: 0.0265\n",
      "Epoch 144/200, Iteration 135/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 136/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 137/250, Loss: 0.0115\n",
      "Epoch 144/200, Iteration 138/250, Loss: 0.0247\n",
      "Epoch 144/200, Iteration 139/250, Loss: 0.0201\n",
      "Epoch 144/200, Iteration 140/250, Loss: 0.0171\n",
      "Epoch 144/200, Iteration 141/250, Loss: 0.0161\n",
      "Epoch 144/200, Iteration 142/250, Loss: 0.0104\n",
      "Epoch 144/200, Iteration 143/250, Loss: 0.0147\n",
      "Epoch 144/200, Iteration 144/250, Loss: 0.0096\n",
      "Epoch 144/200, Iteration 145/250, Loss: 0.0074\n",
      "Epoch 144/200, Iteration 146/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 147/250, Loss: 0.0080\n",
      "Epoch 144/200, Iteration 148/250, Loss: 0.0063\n",
      "Epoch 144/200, Iteration 149/250, Loss: 0.0161\n",
      "Epoch 144/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 144/200, Iteration 151/250, Loss: 0.0115\n",
      "Epoch 144/200, Iteration 152/250, Loss: 0.0154\n",
      "Epoch 144/200, Iteration 153/250, Loss: 0.0212\n",
      "Epoch 144/200, Iteration 154/250, Loss: 0.0169\n",
      "Epoch 144/200, Iteration 155/250, Loss: 0.0129\n",
      "Epoch 144/200, Iteration 156/250, Loss: 0.0101\n",
      "Epoch 144/200, Iteration 157/250, Loss: 0.0118\n",
      "Epoch 144/200, Iteration 158/250, Loss: 0.0070\n",
      "Epoch 144/200, Iteration 159/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 160/250, Loss: 0.0068\n",
      "Epoch 144/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 144/200, Iteration 162/250, Loss: 0.0130\n",
      "Epoch 144/200, Iteration 163/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 164/250, Loss: 0.0127\n",
      "Epoch 144/200, Iteration 165/250, Loss: 0.0073\n",
      "Epoch 144/200, Iteration 166/250, Loss: 0.0149\n",
      "Epoch 144/200, Iteration 167/250, Loss: 0.0175\n",
      "Epoch 144/200, Iteration 168/250, Loss: 0.0119\n",
      "Epoch 144/200, Iteration 169/250, Loss: 0.0097\n",
      "Epoch 144/200, Iteration 170/250, Loss: 0.0347\n",
      "Epoch 144/200, Iteration 171/250, Loss: 0.0320\n",
      "Epoch 144/200, Iteration 172/250, Loss: 0.0315\n",
      "Epoch 144/200, Iteration 173/250, Loss: 0.0106\n",
      "Epoch 144/200, Iteration 174/250, Loss: 0.0093\n",
      "Epoch 144/200, Iteration 175/250, Loss: 0.0294\n",
      "Epoch 144/200, Iteration 176/250, Loss: 0.0116\n",
      "Epoch 144/200, Iteration 177/250, Loss: 0.0183\n",
      "Epoch 144/200, Iteration 178/250, Loss: 0.0139\n",
      "Epoch 144/200, Iteration 179/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 180/250, Loss: 0.0108\n",
      "Epoch 144/200, Iteration 181/250, Loss: 0.0099\n",
      "Epoch 144/200, Iteration 182/250, Loss: 0.0109\n",
      "Epoch 144/200, Iteration 183/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 184/250, Loss: 0.0226\n",
      "Epoch 144/200, Iteration 185/250, Loss: 0.0139\n",
      "Epoch 144/200, Iteration 186/250, Loss: 0.0116\n",
      "Epoch 144/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 144/200, Iteration 188/250, Loss: 0.0186\n",
      "Epoch 144/200, Iteration 189/250, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200, Iteration 190/250, Loss: 0.0405\n",
      "Epoch 144/200, Iteration 191/250, Loss: 0.0159\n",
      "Epoch 144/200, Iteration 192/250, Loss: 0.0070\n",
      "Epoch 144/200, Iteration 193/250, Loss: 0.0231\n",
      "Epoch 144/200, Iteration 194/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 195/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 196/250, Loss: 0.0171\n",
      "Epoch 144/200, Iteration 197/250, Loss: 0.0056\n",
      "Epoch 144/200, Iteration 198/250, Loss: 0.0129\n",
      "Epoch 144/200, Iteration 199/250, Loss: 0.0373\n",
      "Epoch 144/200, Iteration 200/250, Loss: 0.0315\n",
      "Epoch 144/200, Iteration 201/250, Loss: 0.0224\n",
      "Epoch 144/200, Iteration 202/250, Loss: 0.0095\n",
      "Epoch 144/200, Iteration 203/250, Loss: 0.0112\n",
      "Epoch 144/200, Iteration 204/250, Loss: 0.0190\n",
      "Epoch 144/200, Iteration 205/250, Loss: 0.0077\n",
      "Epoch 144/200, Iteration 206/250, Loss: 0.0192\n",
      "Epoch 144/200, Iteration 207/250, Loss: 0.0085\n",
      "Epoch 144/200, Iteration 208/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 209/250, Loss: 0.0096\n",
      "Epoch 144/200, Iteration 210/250, Loss: 0.0155\n",
      "Epoch 144/200, Iteration 211/250, Loss: 0.0418\n",
      "Epoch 144/200, Iteration 212/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 213/250, Loss: 0.0259\n",
      "Epoch 144/200, Iteration 214/250, Loss: 0.0074\n",
      "Epoch 144/200, Iteration 215/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 216/250, Loss: 0.0121\n",
      "Epoch 144/200, Iteration 217/250, Loss: 0.0140\n",
      "Epoch 144/200, Iteration 218/250, Loss: 0.0126\n",
      "Epoch 144/200, Iteration 219/250, Loss: 0.0138\n",
      "Epoch 144/200, Iteration 220/250, Loss: 0.0172\n",
      "Epoch 144/200, Iteration 221/250, Loss: 0.0087\n",
      "Epoch 144/200, Iteration 222/250, Loss: 0.0081\n",
      "Epoch 144/200, Iteration 223/250, Loss: 0.0082\n",
      "Epoch 144/200, Iteration 224/250, Loss: 0.0166\n",
      "Epoch 144/200, Iteration 225/250, Loss: 0.0153\n",
      "Epoch 144/200, Iteration 226/250, Loss: 0.0298\n",
      "Epoch 144/200, Iteration 227/250, Loss: 0.0218\n",
      "Epoch 144/200, Iteration 228/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 229/250, Loss: 0.0198\n",
      "Epoch 144/200, Iteration 230/250, Loss: 0.0061\n",
      "Epoch 144/200, Iteration 231/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 232/250, Loss: 0.0258\n",
      "Epoch 144/200, Iteration 233/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 234/250, Loss: 0.0133\n",
      "Epoch 144/200, Iteration 235/250, Loss: 0.0169\n",
      "Epoch 144/200, Iteration 236/250, Loss: 0.0095\n",
      "Epoch 144/200, Iteration 237/250, Loss: 0.0199\n",
      "Epoch 144/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 239/250, Loss: 0.0088\n",
      "Epoch 144/200, Iteration 240/250, Loss: 0.0184\n",
      "Epoch 144/200, Iteration 241/250, Loss: 0.0100\n",
      "Epoch 144/200, Iteration 242/250, Loss: 0.0194\n",
      "Epoch 144/200, Iteration 243/250, Loss: 0.0144\n",
      "Epoch 144/200, Iteration 244/250, Loss: 0.0151\n",
      "Epoch 144/200, Iteration 245/250, Loss: 0.0234\n",
      "Epoch 144/200, Iteration 246/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 247/250, Loss: 0.0150\n",
      "Epoch 144/200, Iteration 248/250, Loss: 0.0244\n",
      "Epoch 144/200, Iteration 249/250, Loss: 0.0174\n",
      "Epoch 144/200, Iteration 250/250, Loss: 0.0184\n",
      "Train Error: \n",
      " Accuracy: 97.54%, Avg loss: 0.007674, MRE: 0.828479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.007580, MRE: 1.374273 \n",
      "\n",
      "Epoch 145/200, Iteration 1/250, Loss: 0.0133\n",
      "Epoch 145/200, Iteration 2/250, Loss: 0.0070\n",
      "Epoch 145/200, Iteration 3/250, Loss: 0.0224\n",
      "Epoch 145/200, Iteration 4/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 5/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 6/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 7/250, Loss: 0.0138\n",
      "Epoch 145/200, Iteration 8/250, Loss: 0.0181\n",
      "Epoch 145/200, Iteration 9/250, Loss: 0.0179\n",
      "Epoch 145/200, Iteration 10/250, Loss: 0.0160\n",
      "Epoch 145/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 12/250, Loss: 0.0216\n",
      "Epoch 145/200, Iteration 13/250, Loss: 0.0077\n",
      "Epoch 145/200, Iteration 14/250, Loss: 0.0125\n",
      "Epoch 145/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 145/200, Iteration 16/250, Loss: 0.0135\n",
      "Epoch 145/200, Iteration 17/250, Loss: 0.0071\n",
      "Epoch 145/200, Iteration 18/250, Loss: 0.0440\n",
      "Epoch 145/200, Iteration 19/250, Loss: 0.0258\n",
      "Epoch 145/200, Iteration 20/250, Loss: 0.0151\n",
      "Epoch 145/200, Iteration 21/250, Loss: 0.0082\n",
      "Epoch 145/200, Iteration 22/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 23/250, Loss: 0.0237\n",
      "Epoch 145/200, Iteration 24/250, Loss: 0.0350\n",
      "Epoch 145/200, Iteration 25/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 26/250, Loss: 0.0149\n",
      "Epoch 145/200, Iteration 27/250, Loss: 0.0099\n",
      "Epoch 145/200, Iteration 28/250, Loss: 0.0209\n",
      "Epoch 145/200, Iteration 29/250, Loss: 0.0160\n",
      "Epoch 145/200, Iteration 30/250, Loss: 0.0240\n",
      "Epoch 145/200, Iteration 31/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 32/250, Loss: 0.0114\n",
      "Epoch 145/200, Iteration 33/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 145/200, Iteration 35/250, Loss: 0.0130\n",
      "Epoch 145/200, Iteration 36/250, Loss: 0.0199\n",
      "Epoch 145/200, Iteration 37/250, Loss: 0.0076\n",
      "Epoch 145/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 145/200, Iteration 39/250, Loss: 0.0176\n",
      "Epoch 145/200, Iteration 40/250, Loss: 0.0085\n",
      "Epoch 145/200, Iteration 41/250, Loss: 0.0237\n",
      "Epoch 145/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 43/250, Loss: 0.0173\n",
      "Epoch 145/200, Iteration 44/250, Loss: 0.0091\n",
      "Epoch 145/200, Iteration 45/250, Loss: 0.0180\n",
      "Epoch 145/200, Iteration 46/250, Loss: 0.0113\n",
      "Epoch 145/200, Iteration 47/250, Loss: 0.0289\n",
      "Epoch 145/200, Iteration 48/250, Loss: 0.0125\n",
      "Epoch 145/200, Iteration 49/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 50/250, Loss: 0.0102\n",
      "Epoch 145/200, Iteration 51/250, Loss: 0.0091\n",
      "Epoch 145/200, Iteration 52/250, Loss: 0.0274\n",
      "Epoch 145/200, Iteration 53/250, Loss: 0.0078\n",
      "Epoch 145/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 145/200, Iteration 55/250, Loss: 0.0121\n",
      "Epoch 145/200, Iteration 56/250, Loss: 0.0170\n",
      "Epoch 145/200, Iteration 57/250, Loss: 0.0082\n",
      "Epoch 145/200, Iteration 58/250, Loss: 0.0167\n",
      "Epoch 145/200, Iteration 59/250, Loss: 0.0071\n",
      "Epoch 145/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 145/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 145/200, Iteration 63/250, Loss: 0.0068\n",
      "Epoch 145/200, Iteration 64/250, Loss: 0.0069\n",
      "Epoch 145/200, Iteration 65/250, Loss: 0.0350\n",
      "Epoch 145/200, Iteration 66/250, Loss: 0.0084\n",
      "Epoch 145/200, Iteration 67/250, Loss: 0.0185\n",
      "Epoch 145/200, Iteration 68/250, Loss: 0.0191\n",
      "Epoch 145/200, Iteration 69/250, Loss: 0.0157\n",
      "Epoch 145/200, Iteration 70/250, Loss: 0.0096\n",
      "Epoch 145/200, Iteration 71/250, Loss: 0.0072\n",
      "Epoch 145/200, Iteration 72/250, Loss: 0.0146\n",
      "Epoch 145/200, Iteration 73/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 74/250, Loss: 0.0136\n",
      "Epoch 145/200, Iteration 75/250, Loss: 0.0150\n",
      "Epoch 145/200, Iteration 76/250, Loss: 0.0194\n",
      "Epoch 145/200, Iteration 77/250, Loss: 0.0259\n",
      "Epoch 145/200, Iteration 78/250, Loss: 0.0086\n",
      "Epoch 145/200, Iteration 79/250, Loss: 0.0172\n",
      "Epoch 145/200, Iteration 80/250, Loss: 0.0316\n",
      "Epoch 145/200, Iteration 81/250, Loss: 0.0102\n",
      "Epoch 145/200, Iteration 82/250, Loss: 0.0133\n",
      "Epoch 145/200, Iteration 83/250, Loss: 0.0087\n",
      "Epoch 145/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 145/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 145/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 87/250, Loss: 0.0144\n",
      "Epoch 145/200, Iteration 88/250, Loss: 0.0124\n",
      "Epoch 145/200, Iteration 89/250, Loss: 0.0186\n",
      "Epoch 145/200, Iteration 90/250, Loss: 0.0206\n",
      "Epoch 145/200, Iteration 91/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 92/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 93/250, Loss: 0.0099\n",
      "Epoch 145/200, Iteration 94/250, Loss: 0.0264\n",
      "Epoch 145/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 145/200, Iteration 96/250, Loss: 0.0314\n",
      "Epoch 145/200, Iteration 97/250, Loss: 0.0105\n",
      "Epoch 145/200, Iteration 98/250, Loss: 0.0127\n",
      "Epoch 145/200, Iteration 99/250, Loss: 0.0100\n",
      "Epoch 145/200, Iteration 100/250, Loss: 0.0064\n",
      "Epoch 145/200, Iteration 101/250, Loss: 0.0077\n",
      "Epoch 145/200, Iteration 102/250, Loss: 0.0277\n",
      "Epoch 145/200, Iteration 103/250, Loss: 0.0142\n",
      "Epoch 145/200, Iteration 104/250, Loss: 0.0202\n",
      "Epoch 145/200, Iteration 105/250, Loss: 0.0138\n",
      "Epoch 145/200, Iteration 106/250, Loss: 0.0155\n",
      "Epoch 145/200, Iteration 107/250, Loss: 0.0086\n",
      "Epoch 145/200, Iteration 108/250, Loss: 0.0082\n",
      "Epoch 145/200, Iteration 109/250, Loss: 0.0104\n",
      "Epoch 145/200, Iteration 110/250, Loss: 0.0199\n",
      "Epoch 145/200, Iteration 111/250, Loss: 0.0195\n",
      "Epoch 145/200, Iteration 112/250, Loss: 0.0264\n",
      "Epoch 145/200, Iteration 113/250, Loss: 0.0170\n",
      "Epoch 145/200, Iteration 114/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 115/250, Loss: 0.0119\n",
      "Epoch 145/200, Iteration 116/250, Loss: 0.0066\n",
      "Epoch 145/200, Iteration 117/250, Loss: 0.0075\n",
      "Epoch 145/200, Iteration 118/250, Loss: 0.0351\n",
      "Epoch 145/200, Iteration 119/250, Loss: 0.0213\n",
      "Epoch 145/200, Iteration 120/250, Loss: 0.0102\n",
      "Epoch 145/200, Iteration 121/250, Loss: 0.0154\n",
      "Epoch 145/200, Iteration 122/250, Loss: 0.0174\n",
      "Epoch 145/200, Iteration 123/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 124/250, Loss: 0.0118\n",
      "Epoch 145/200, Iteration 125/250, Loss: 0.0080\n",
      "Epoch 145/200, Iteration 126/250, Loss: 0.0172\n",
      "Epoch 145/200, Iteration 127/250, Loss: 0.0105\n",
      "Epoch 145/200, Iteration 128/250, Loss: 0.0106\n",
      "Epoch 145/200, Iteration 129/250, Loss: 0.0140\n",
      "Epoch 145/200, Iteration 130/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 131/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 132/250, Loss: 0.0217\n",
      "Epoch 145/200, Iteration 133/250, Loss: 0.0213\n",
      "Epoch 145/200, Iteration 134/250, Loss: 0.0104\n",
      "Epoch 145/200, Iteration 135/250, Loss: 0.0377\n",
      "Epoch 145/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 145/200, Iteration 137/250, Loss: 0.0067\n",
      "Epoch 145/200, Iteration 138/250, Loss: 0.0081\n",
      "Epoch 145/200, Iteration 139/250, Loss: 0.0069\n",
      "Epoch 145/200, Iteration 140/250, Loss: 0.0145\n",
      "Epoch 145/200, Iteration 141/250, Loss: 0.0136\n",
      "Epoch 145/200, Iteration 142/250, Loss: 0.0071\n",
      "Epoch 145/200, Iteration 143/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 145/200, Iteration 145/250, Loss: 0.0087\n",
      "Epoch 145/200, Iteration 146/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 147/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 148/250, Loss: 0.0082\n",
      "Epoch 145/200, Iteration 149/250, Loss: 0.0097\n",
      "Epoch 145/200, Iteration 150/250, Loss: 0.0075\n",
      "Epoch 145/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 152/250, Loss: 0.0117\n",
      "Epoch 145/200, Iteration 153/250, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200, Iteration 154/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 155/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 156/250, Loss: 0.0174\n",
      "Epoch 145/200, Iteration 157/250, Loss: 0.0068\n",
      "Epoch 145/200, Iteration 158/250, Loss: 0.0114\n",
      "Epoch 145/200, Iteration 159/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 160/250, Loss: 0.0085\n",
      "Epoch 145/200, Iteration 161/250, Loss: 0.0155\n",
      "Epoch 145/200, Iteration 162/250, Loss: 0.0212\n",
      "Epoch 145/200, Iteration 163/250, Loss: 0.0066\n",
      "Epoch 145/200, Iteration 164/250, Loss: 0.0216\n",
      "Epoch 145/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 166/250, Loss: 0.0195\n",
      "Epoch 145/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 145/200, Iteration 168/250, Loss: 0.0208\n",
      "Epoch 145/200, Iteration 169/250, Loss: 0.0057\n",
      "Epoch 145/200, Iteration 170/250, Loss: 0.0303\n",
      "Epoch 145/200, Iteration 171/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 173/250, Loss: 0.0117\n",
      "Epoch 145/200, Iteration 174/250, Loss: 0.0192\n",
      "Epoch 145/200, Iteration 175/250, Loss: 0.0076\n",
      "Epoch 145/200, Iteration 176/250, Loss: 0.0067\n",
      "Epoch 145/200, Iteration 177/250, Loss: 0.0092\n",
      "Epoch 145/200, Iteration 178/250, Loss: 0.0245\n",
      "Epoch 145/200, Iteration 179/250, Loss: 0.0153\n",
      "Epoch 145/200, Iteration 180/250, Loss: 0.0055\n",
      "Epoch 145/200, Iteration 181/250, Loss: 0.0242\n",
      "Epoch 145/200, Iteration 182/250, Loss: 0.0068\n",
      "Epoch 145/200, Iteration 183/250, Loss: 0.0156\n",
      "Epoch 145/200, Iteration 184/250, Loss: 0.0179\n",
      "Epoch 145/200, Iteration 185/250, Loss: 0.0068\n",
      "Epoch 145/200, Iteration 186/250, Loss: 0.0116\n",
      "Epoch 145/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 145/200, Iteration 188/250, Loss: 0.0228\n",
      "Epoch 145/200, Iteration 189/250, Loss: 0.0165\n",
      "Epoch 145/200, Iteration 190/250, Loss: 0.0253\n",
      "Epoch 145/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 192/250, Loss: 0.0158\n",
      "Epoch 145/200, Iteration 193/250, Loss: 0.0076\n",
      "Epoch 145/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 145/200, Iteration 195/250, Loss: 0.0162\n",
      "Epoch 145/200, Iteration 196/250, Loss: 0.0121\n",
      "Epoch 145/200, Iteration 197/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 199/250, Loss: 0.0265\n",
      "Epoch 145/200, Iteration 200/250, Loss: 0.0075\n",
      "Epoch 145/200, Iteration 201/250, Loss: 0.0243\n",
      "Epoch 145/200, Iteration 202/250, Loss: 0.0207\n",
      "Epoch 145/200, Iteration 203/250, Loss: 0.0230\n",
      "Epoch 145/200, Iteration 204/250, Loss: 0.0084\n",
      "Epoch 145/200, Iteration 205/250, Loss: 0.0123\n",
      "Epoch 145/200, Iteration 206/250, Loss: 0.0113\n",
      "Epoch 145/200, Iteration 207/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 208/250, Loss: 0.0190\n",
      "Epoch 145/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 145/200, Iteration 210/250, Loss: 0.0077\n",
      "Epoch 145/200, Iteration 211/250, Loss: 0.0155\n",
      "Epoch 145/200, Iteration 212/250, Loss: 0.0165\n",
      "Epoch 145/200, Iteration 213/250, Loss: 0.0157\n",
      "Epoch 145/200, Iteration 214/250, Loss: 0.0167\n",
      "Epoch 145/200, Iteration 215/250, Loss: 0.0103\n",
      "Epoch 145/200, Iteration 216/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 217/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 218/250, Loss: 0.0086\n",
      "Epoch 145/200, Iteration 219/250, Loss: 0.0074\n",
      "Epoch 145/200, Iteration 220/250, Loss: 0.0063\n",
      "Epoch 145/200, Iteration 221/250, Loss: 0.0108\n",
      "Epoch 145/200, Iteration 222/250, Loss: 0.0143\n",
      "Epoch 145/200, Iteration 223/250, Loss: 0.0110\n",
      "Epoch 145/200, Iteration 224/250, Loss: 0.0217\n",
      "Epoch 145/200, Iteration 225/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 226/250, Loss: 0.0101\n",
      "Epoch 145/200, Iteration 227/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 228/250, Loss: 0.0153\n",
      "Epoch 145/200, Iteration 229/250, Loss: 0.0119\n",
      "Epoch 145/200, Iteration 230/250, Loss: 0.0283\n",
      "Epoch 145/200, Iteration 231/250, Loss: 0.0107\n",
      "Epoch 145/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 145/200, Iteration 233/250, Loss: 0.0219\n",
      "Epoch 145/200, Iteration 234/250, Loss: 0.0147\n",
      "Epoch 145/200, Iteration 235/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 236/250, Loss: 0.0432\n",
      "Epoch 145/200, Iteration 237/250, Loss: 0.0134\n",
      "Epoch 145/200, Iteration 238/250, Loss: 0.0281\n",
      "Epoch 145/200, Iteration 239/250, Loss: 0.0290\n",
      "Epoch 145/200, Iteration 240/250, Loss: 0.0169\n",
      "Epoch 145/200, Iteration 241/250, Loss: 0.0123\n",
      "Epoch 145/200, Iteration 242/250, Loss: 0.0161\n",
      "Epoch 145/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 145/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 145/200, Iteration 245/250, Loss: 0.0119\n",
      "Epoch 145/200, Iteration 246/250, Loss: 0.0137\n",
      "Epoch 145/200, Iteration 247/250, Loss: 0.0236\n",
      "Epoch 145/200, Iteration 248/250, Loss: 0.0145\n",
      "Epoch 145/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 145/200, Iteration 250/250, Loss: 0.0092\n",
      "Train Error: \n",
      " Accuracy: 60.02%, Avg loss: 0.009376, MRE: 0.792232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.009358, MRE: 0.830735 \n",
      "\n",
      "Epoch 146/200, Iteration 1/250, Loss: 0.0170\n",
      "Epoch 146/200, Iteration 2/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 3/250, Loss: 0.0163\n",
      "Epoch 146/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 146/200, Iteration 5/250, Loss: 0.0202\n",
      "Epoch 146/200, Iteration 6/250, Loss: 0.0122\n",
      "Epoch 146/200, Iteration 7/250, Loss: 0.0186\n",
      "Epoch 146/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 146/200, Iteration 9/250, Loss: 0.0087\n",
      "Epoch 146/200, Iteration 10/250, Loss: 0.0100\n",
      "Epoch 146/200, Iteration 11/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 12/250, Loss: 0.0370\n",
      "Epoch 146/200, Iteration 13/250, Loss: 0.0119\n",
      "Epoch 146/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 146/200, Iteration 15/250, Loss: 0.0236\n",
      "Epoch 146/200, Iteration 16/250, Loss: 0.0104\n",
      "Epoch 146/200, Iteration 17/250, Loss: 0.0053\n",
      "Epoch 146/200, Iteration 18/250, Loss: 0.0128\n",
      "Epoch 146/200, Iteration 19/250, Loss: 0.0262\n",
      "Epoch 146/200, Iteration 20/250, Loss: 0.0154\n",
      "Epoch 146/200, Iteration 21/250, Loss: 0.0208\n",
      "Epoch 146/200, Iteration 22/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 23/250, Loss: 0.0118\n",
      "Epoch 146/200, Iteration 24/250, Loss: 0.0300\n",
      "Epoch 146/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 146/200, Iteration 26/250, Loss: 0.0150\n",
      "Epoch 146/200, Iteration 27/250, Loss: 0.0375\n",
      "Epoch 146/200, Iteration 28/250, Loss: 0.0247\n",
      "Epoch 146/200, Iteration 29/250, Loss: 0.0105\n",
      "Epoch 146/200, Iteration 30/250, Loss: 0.0351\n",
      "Epoch 146/200, Iteration 31/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 32/250, Loss: 0.0088\n",
      "Epoch 146/200, Iteration 33/250, Loss: 0.0177\n",
      "Epoch 146/200, Iteration 34/250, Loss: 0.0139\n",
      "Epoch 146/200, Iteration 35/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 36/250, Loss: 0.0253\n",
      "Epoch 146/200, Iteration 37/250, Loss: 0.0222\n",
      "Epoch 146/200, Iteration 38/250, Loss: 0.0127\n",
      "Epoch 146/200, Iteration 39/250, Loss: 0.0116\n",
      "Epoch 146/200, Iteration 40/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 41/250, Loss: 0.0156\n",
      "Epoch 146/200, Iteration 42/250, Loss: 0.0298\n",
      "Epoch 146/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 44/250, Loss: 0.0183\n",
      "Epoch 146/200, Iteration 45/250, Loss: 0.0080\n",
      "Epoch 146/200, Iteration 46/250, Loss: 0.0085\n",
      "Epoch 146/200, Iteration 47/250, Loss: 0.0288\n",
      "Epoch 146/200, Iteration 48/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 49/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 50/250, Loss: 0.0057\n",
      "Epoch 146/200, Iteration 51/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 52/250, Loss: 0.0195\n",
      "Epoch 146/200, Iteration 53/250, Loss: 0.0054\n",
      "Epoch 146/200, Iteration 54/250, Loss: 0.0230\n",
      "Epoch 146/200, Iteration 55/250, Loss: 0.0073\n",
      "Epoch 146/200, Iteration 56/250, Loss: 0.0276\n",
      "Epoch 146/200, Iteration 57/250, Loss: 0.0192\n",
      "Epoch 146/200, Iteration 58/250, Loss: 0.0093\n",
      "Epoch 146/200, Iteration 59/250, Loss: 0.0282\n",
      "Epoch 146/200, Iteration 60/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 61/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 62/250, Loss: 0.0071\n",
      "Epoch 146/200, Iteration 63/250, Loss: 0.0174\n",
      "Epoch 146/200, Iteration 64/250, Loss: 0.0148\n",
      "Epoch 146/200, Iteration 65/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 66/250, Loss: 0.0074\n",
      "Epoch 146/200, Iteration 67/250, Loss: 0.0088\n",
      "Epoch 146/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 69/250, Loss: 0.0115\n",
      "Epoch 146/200, Iteration 70/250, Loss: 0.0184\n",
      "Epoch 146/200, Iteration 71/250, Loss: 0.0313\n",
      "Epoch 146/200, Iteration 72/250, Loss: 0.0241\n",
      "Epoch 146/200, Iteration 73/250, Loss: 0.0232\n",
      "Epoch 146/200, Iteration 74/250, Loss: 0.0133\n",
      "Epoch 146/200, Iteration 75/250, Loss: 0.0363\n",
      "Epoch 146/200, Iteration 76/250, Loss: 0.0248\n",
      "Epoch 146/200, Iteration 77/250, Loss: 0.0168\n",
      "Epoch 146/200, Iteration 78/250, Loss: 0.0427\n",
      "Epoch 146/200, Iteration 79/250, Loss: 0.0056\n",
      "Epoch 146/200, Iteration 80/250, Loss: 0.0144\n",
      "Epoch 146/200, Iteration 81/250, Loss: 0.0082\n",
      "Epoch 146/200, Iteration 82/250, Loss: 0.0144\n",
      "Epoch 146/200, Iteration 83/250, Loss: 0.0199\n",
      "Epoch 146/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 146/200, Iteration 85/250, Loss: 0.0141\n",
      "Epoch 146/200, Iteration 86/250, Loss: 0.0164\n",
      "Epoch 146/200, Iteration 87/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 88/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 89/250, Loss: 0.0173\n",
      "Epoch 146/200, Iteration 90/250, Loss: 0.0435\n",
      "Epoch 146/200, Iteration 91/250, Loss: 0.0211\n",
      "Epoch 146/200, Iteration 92/250, Loss: 0.0099\n",
      "Epoch 146/200, Iteration 93/250, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200, Iteration 94/250, Loss: 0.0221\n",
      "Epoch 146/200, Iteration 95/250, Loss: 0.0244\n",
      "Epoch 146/200, Iteration 96/250, Loss: 0.0070\n",
      "Epoch 146/200, Iteration 97/250, Loss: 0.0123\n",
      "Epoch 146/200, Iteration 98/250, Loss: 0.0142\n",
      "Epoch 146/200, Iteration 99/250, Loss: 0.0070\n",
      "Epoch 146/200, Iteration 100/250, Loss: 0.0073\n",
      "Epoch 146/200, Iteration 101/250, Loss: 0.0133\n",
      "Epoch 146/200, Iteration 102/250, Loss: 0.0080\n",
      "Epoch 146/200, Iteration 103/250, Loss: 0.0194\n",
      "Epoch 146/200, Iteration 104/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 105/250, Loss: 0.0170\n",
      "Epoch 146/200, Iteration 106/250, Loss: 0.0240\n",
      "Epoch 146/200, Iteration 107/250, Loss: 0.0142\n",
      "Epoch 146/200, Iteration 108/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 109/250, Loss: 0.0158\n",
      "Epoch 146/200, Iteration 110/250, Loss: 0.0150\n",
      "Epoch 146/200, Iteration 111/250, Loss: 0.0227\n",
      "Epoch 146/200, Iteration 112/250, Loss: 0.0088\n",
      "Epoch 146/200, Iteration 113/250, Loss: 0.0181\n",
      "Epoch 146/200, Iteration 114/250, Loss: 0.0213\n",
      "Epoch 146/200, Iteration 115/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 116/250, Loss: 0.0209\n",
      "Epoch 146/200, Iteration 117/250, Loss: 0.0073\n",
      "Epoch 146/200, Iteration 118/250, Loss: 0.0125\n",
      "Epoch 146/200, Iteration 119/250, Loss: 0.0177\n",
      "Epoch 146/200, Iteration 120/250, Loss: 0.0186\n",
      "Epoch 146/200, Iteration 121/250, Loss: 0.0140\n",
      "Epoch 146/200, Iteration 122/250, Loss: 0.0172\n",
      "Epoch 146/200, Iteration 123/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 146/200, Iteration 125/250, Loss: 0.0078\n",
      "Epoch 146/200, Iteration 126/250, Loss: 0.0412\n",
      "Epoch 146/200, Iteration 127/250, Loss: 0.0080\n",
      "Epoch 146/200, Iteration 128/250, Loss: 0.0122\n",
      "Epoch 146/200, Iteration 129/250, Loss: 0.0176\n",
      "Epoch 146/200, Iteration 130/250, Loss: 0.0153\n",
      "Epoch 146/200, Iteration 131/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 132/250, Loss: 0.0213\n",
      "Epoch 146/200, Iteration 133/250, Loss: 0.0145\n",
      "Epoch 146/200, Iteration 134/250, Loss: 0.0228\n",
      "Epoch 146/200, Iteration 135/250, Loss: 0.0234\n",
      "Epoch 146/200, Iteration 136/250, Loss: 0.0069\n",
      "Epoch 146/200, Iteration 137/250, Loss: 0.0234\n",
      "Epoch 146/200, Iteration 138/250, Loss: 0.0092\n",
      "Epoch 146/200, Iteration 139/250, Loss: 0.0141\n",
      "Epoch 146/200, Iteration 140/250, Loss: 0.0255\n",
      "Epoch 146/200, Iteration 141/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 142/250, Loss: 0.0071\n",
      "Epoch 146/200, Iteration 143/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 144/250, Loss: 0.0118\n",
      "Epoch 146/200, Iteration 145/250, Loss: 0.0137\n",
      "Epoch 146/200, Iteration 146/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 147/250, Loss: 0.0122\n",
      "Epoch 146/200, Iteration 148/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 149/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 150/250, Loss: 0.0102\n",
      "Epoch 146/200, Iteration 151/250, Loss: 0.0141\n",
      "Epoch 146/200, Iteration 152/250, Loss: 0.0187\n",
      "Epoch 146/200, Iteration 153/250, Loss: 0.0296\n",
      "Epoch 146/200, Iteration 154/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 155/250, Loss: 0.0143\n",
      "Epoch 146/200, Iteration 156/250, Loss: 0.0155\n",
      "Epoch 146/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 158/250, Loss: 0.0061\n",
      "Epoch 146/200, Iteration 159/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 160/250, Loss: 0.0215\n",
      "Epoch 146/200, Iteration 161/250, Loss: 0.0232\n",
      "Epoch 146/200, Iteration 162/250, Loss: 0.0221\n",
      "Epoch 146/200, Iteration 163/250, Loss: 0.0239\n",
      "Epoch 146/200, Iteration 164/250, Loss: 0.0191\n",
      "Epoch 146/200, Iteration 165/250, Loss: 0.0285\n",
      "Epoch 146/200, Iteration 166/250, Loss: 0.0151\n",
      "Epoch 146/200, Iteration 167/250, Loss: 0.0052\n",
      "Epoch 146/200, Iteration 168/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 169/250, Loss: 0.0120\n",
      "Epoch 146/200, Iteration 170/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 171/250, Loss: 0.0082\n",
      "Epoch 146/200, Iteration 172/250, Loss: 0.0147\n",
      "Epoch 146/200, Iteration 173/250, Loss: 0.0101\n",
      "Epoch 146/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 175/250, Loss: 0.0084\n",
      "Epoch 146/200, Iteration 176/250, Loss: 0.0197\n",
      "Epoch 146/200, Iteration 177/250, Loss: 0.0330\n",
      "Epoch 146/200, Iteration 178/250, Loss: 0.0193\n",
      "Epoch 146/200, Iteration 179/250, Loss: 0.0195\n",
      "Epoch 146/200, Iteration 180/250, Loss: 0.0136\n",
      "Epoch 146/200, Iteration 181/250, Loss: 0.0124\n",
      "Epoch 146/200, Iteration 182/250, Loss: 0.0245\n",
      "Epoch 146/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 146/200, Iteration 184/250, Loss: 0.0180\n",
      "Epoch 146/200, Iteration 185/250, Loss: 0.0157\n",
      "Epoch 146/200, Iteration 186/250, Loss: 0.0247\n",
      "Epoch 146/200, Iteration 187/250, Loss: 0.0226\n",
      "Epoch 146/200, Iteration 188/250, Loss: 0.0193\n",
      "Epoch 146/200, Iteration 189/250, Loss: 0.0256\n",
      "Epoch 146/200, Iteration 190/250, Loss: 0.0103\n",
      "Epoch 146/200, Iteration 191/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 192/250, Loss: 0.0359\n",
      "Epoch 146/200, Iteration 193/250, Loss: 0.0087\n",
      "Epoch 146/200, Iteration 194/250, Loss: 0.0127\n",
      "Epoch 146/200, Iteration 195/250, Loss: 0.0134\n",
      "Epoch 146/200, Iteration 196/250, Loss: 0.0082\n",
      "Epoch 146/200, Iteration 197/250, Loss: 0.0154\n",
      "Epoch 146/200, Iteration 198/250, Loss: 0.0219\n",
      "Epoch 146/200, Iteration 199/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 200/250, Loss: 0.0222\n",
      "Epoch 146/200, Iteration 201/250, Loss: 0.0073\n",
      "Epoch 146/200, Iteration 202/250, Loss: 0.0291\n",
      "Epoch 146/200, Iteration 203/250, Loss: 0.0125\n",
      "Epoch 146/200, Iteration 204/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 205/250, Loss: 0.0150\n",
      "Epoch 146/200, Iteration 206/250, Loss: 0.0141\n",
      "Epoch 146/200, Iteration 207/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 208/250, Loss: 0.0065\n",
      "Epoch 146/200, Iteration 209/250, Loss: 0.0131\n",
      "Epoch 146/200, Iteration 210/250, Loss: 0.0058\n",
      "Epoch 146/200, Iteration 211/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 212/250, Loss: 0.0191\n",
      "Epoch 146/200, Iteration 213/250, Loss: 0.0178\n",
      "Epoch 146/200, Iteration 214/250, Loss: 0.0165\n",
      "Epoch 146/200, Iteration 215/250, Loss: 0.0235\n",
      "Epoch 146/200, Iteration 216/250, Loss: 0.0082\n",
      "Epoch 146/200, Iteration 217/250, Loss: 0.0151\n",
      "Epoch 146/200, Iteration 218/250, Loss: 0.0124\n",
      "Epoch 146/200, Iteration 219/250, Loss: 0.0106\n",
      "Epoch 146/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 146/200, Iteration 221/250, Loss: 0.0063\n",
      "Epoch 146/200, Iteration 222/250, Loss: 0.0287\n",
      "Epoch 146/200, Iteration 223/250, Loss: 0.0120\n",
      "Epoch 146/200, Iteration 224/250, Loss: 0.0107\n",
      "Epoch 146/200, Iteration 225/250, Loss: 0.0216\n",
      "Epoch 146/200, Iteration 226/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 227/250, Loss: 0.0271\n",
      "Epoch 146/200, Iteration 228/250, Loss: 0.0358\n",
      "Epoch 146/200, Iteration 229/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 231/250, Loss: 0.0178\n",
      "Epoch 146/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 146/200, Iteration 233/250, Loss: 0.0106\n",
      "Epoch 146/200, Iteration 234/250, Loss: 0.0225\n",
      "Epoch 146/200, Iteration 235/250, Loss: 0.0203\n",
      "Epoch 146/200, Iteration 236/250, Loss: 0.0132\n",
      "Epoch 146/200, Iteration 237/250, Loss: 0.0157\n",
      "Epoch 146/200, Iteration 238/250, Loss: 0.0071\n",
      "Epoch 146/200, Iteration 239/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 240/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 241/250, Loss: 0.0235\n",
      "Epoch 146/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 146/200, Iteration 243/250, Loss: 0.0155\n",
      "Epoch 146/200, Iteration 244/250, Loss: 0.0102\n",
      "Epoch 146/200, Iteration 245/250, Loss: 0.0169\n",
      "Epoch 146/200, Iteration 246/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 247/250, Loss: 0.0105\n",
      "Epoch 146/200, Iteration 248/250, Loss: 0.0339\n",
      "Epoch 146/200, Iteration 249/250, Loss: 0.0215\n",
      "Epoch 146/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 97.42%, Avg loss: 0.006411, MRE: 0.658973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.45%, Avg loss: 0.006339, MRE: 1.042975 \n",
      "\n",
      "Epoch 147/200, Iteration 1/250, Loss: 0.0077\n",
      "Epoch 147/200, Iteration 2/250, Loss: 0.0153\n",
      "Epoch 147/200, Iteration 3/250, Loss: 0.0094\n",
      "Epoch 147/200, Iteration 4/250, Loss: 0.0259\n",
      "Epoch 147/200, Iteration 5/250, Loss: 0.0115\n",
      "Epoch 147/200, Iteration 6/250, Loss: 0.0195\n",
      "Epoch 147/200, Iteration 7/250, Loss: 0.0094\n",
      "Epoch 147/200, Iteration 8/250, Loss: 0.0070\n",
      "Epoch 147/200, Iteration 9/250, Loss: 0.0115\n",
      "Epoch 147/200, Iteration 10/250, Loss: 0.0093\n",
      "Epoch 147/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 147/200, Iteration 12/250, Loss: 0.0245\n",
      "Epoch 147/200, Iteration 13/250, Loss: 0.0146\n",
      "Epoch 147/200, Iteration 14/250, Loss: 0.0109\n",
      "Epoch 147/200, Iteration 15/250, Loss: 0.0139\n",
      "Epoch 147/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 147/200, Iteration 17/250, Loss: 0.0186\n",
      "Epoch 147/200, Iteration 18/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 19/250, Loss: 0.0234\n",
      "Epoch 147/200, Iteration 20/250, Loss: 0.0084\n",
      "Epoch 147/200, Iteration 21/250, Loss: 0.0091\n",
      "Epoch 147/200, Iteration 22/250, Loss: 0.0126\n",
      "Epoch 147/200, Iteration 23/250, Loss: 0.0167\n",
      "Epoch 147/200, Iteration 24/250, Loss: 0.0208\n",
      "Epoch 147/200, Iteration 25/250, Loss: 0.0133\n",
      "Epoch 147/200, Iteration 26/250, Loss: 0.0203\n",
      "Epoch 147/200, Iteration 27/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 28/250, Loss: 0.0098\n",
      "Epoch 147/200, Iteration 29/250, Loss: 0.0245\n",
      "Epoch 147/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 147/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 32/250, Loss: 0.0106\n",
      "Epoch 147/200, Iteration 33/250, Loss: 0.0073\n",
      "Epoch 147/200, Iteration 34/250, Loss: 0.0222\n",
      "Epoch 147/200, Iteration 35/250, Loss: 0.0395\n",
      "Epoch 147/200, Iteration 36/250, Loss: 0.0231\n",
      "Epoch 147/200, Iteration 37/250, Loss: 0.0085\n",
      "Epoch 147/200, Iteration 38/250, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 39/250, Loss: 0.0114\n",
      "Epoch 147/200, Iteration 40/250, Loss: 0.0164\n",
      "Epoch 147/200, Iteration 41/250, Loss: 0.0066\n",
      "Epoch 147/200, Iteration 42/250, Loss: 0.0160\n",
      "Epoch 147/200, Iteration 43/250, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200, Iteration 44/250, Loss: 0.0190\n",
      "Epoch 147/200, Iteration 45/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 46/250, Loss: 0.0147\n",
      "Epoch 147/200, Iteration 47/250, Loss: 0.0129\n",
      "Epoch 147/200, Iteration 48/250, Loss: 0.0109\n",
      "Epoch 147/200, Iteration 49/250, Loss: 0.0108\n",
      "Epoch 147/200, Iteration 50/250, Loss: 0.0243\n",
      "Epoch 147/200, Iteration 51/250, Loss: 0.0161\n",
      "Epoch 147/200, Iteration 52/250, Loss: 0.0231\n",
      "Epoch 147/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 147/200, Iteration 54/250, Loss: 0.0101\n",
      "Epoch 147/200, Iteration 55/250, Loss: 0.0077\n",
      "Epoch 147/200, Iteration 56/250, Loss: 0.0149\n",
      "Epoch 147/200, Iteration 57/250, Loss: 0.0125\n",
      "Epoch 147/200, Iteration 58/250, Loss: 0.0139\n",
      "Epoch 147/200, Iteration 59/250, Loss: 0.0084\n",
      "Epoch 147/200, Iteration 60/250, Loss: 0.0155\n",
      "Epoch 147/200, Iteration 61/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 62/250, Loss: 0.0290\n",
      "Epoch 147/200, Iteration 63/250, Loss: 0.0106\n",
      "Epoch 147/200, Iteration 64/250, Loss: 0.0190\n",
      "Epoch 147/200, Iteration 65/250, Loss: 0.0164\n",
      "Epoch 147/200, Iteration 66/250, Loss: 0.0069\n",
      "Epoch 147/200, Iteration 67/250, Loss: 0.0127\n",
      "Epoch 147/200, Iteration 68/250, Loss: 0.0251\n",
      "Epoch 147/200, Iteration 69/250, Loss: 0.0076\n",
      "Epoch 147/200, Iteration 70/250, Loss: 0.0099\n",
      "Epoch 147/200, Iteration 71/250, Loss: 0.0151\n",
      "Epoch 147/200, Iteration 72/250, Loss: 0.0218\n",
      "Epoch 147/200, Iteration 73/250, Loss: 0.0134\n",
      "Epoch 147/200, Iteration 74/250, Loss: 0.0107\n",
      "Epoch 147/200, Iteration 75/250, Loss: 0.0084\n",
      "Epoch 147/200, Iteration 76/250, Loss: 0.0196\n",
      "Epoch 147/200, Iteration 77/250, Loss: 0.0094\n",
      "Epoch 147/200, Iteration 78/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 79/250, Loss: 0.0107\n",
      "Epoch 147/200, Iteration 80/250, Loss: 0.0200\n",
      "Epoch 147/200, Iteration 81/250, Loss: 0.0175\n",
      "Epoch 147/200, Iteration 82/250, Loss: 0.0144\n",
      "Epoch 147/200, Iteration 83/250, Loss: 0.0146\n",
      "Epoch 147/200, Iteration 84/250, Loss: 0.0148\n",
      "Epoch 147/200, Iteration 85/250, Loss: 0.0229\n",
      "Epoch 147/200, Iteration 86/250, Loss: 0.0222\n",
      "Epoch 147/200, Iteration 87/250, Loss: 0.0216\n",
      "Epoch 147/200, Iteration 88/250, Loss: 0.0260\n",
      "Epoch 147/200, Iteration 89/250, Loss: 0.0118\n",
      "Epoch 147/200, Iteration 90/250, Loss: 0.0367\n",
      "Epoch 147/200, Iteration 91/250, Loss: 0.0119\n",
      "Epoch 147/200, Iteration 92/250, Loss: 0.0272\n",
      "Epoch 147/200, Iteration 93/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 147/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 96/250, Loss: 0.0174\n",
      "Epoch 147/200, Iteration 97/250, Loss: 0.0204\n",
      "Epoch 147/200, Iteration 98/250, Loss: 0.0163\n",
      "Epoch 147/200, Iteration 99/250, Loss: 0.0190\n",
      "Epoch 147/200, Iteration 100/250, Loss: 0.0154\n",
      "Epoch 147/200, Iteration 101/250, Loss: 0.0233\n",
      "Epoch 147/200, Iteration 102/250, Loss: 0.0161\n",
      "Epoch 147/200, Iteration 103/250, Loss: 0.0208\n",
      "Epoch 147/200, Iteration 104/250, Loss: 0.0189\n",
      "Epoch 147/200, Iteration 105/250, Loss: 0.0107\n",
      "Epoch 147/200, Iteration 106/250, Loss: 0.0320\n",
      "Epoch 147/200, Iteration 107/250, Loss: 0.0133\n",
      "Epoch 147/200, Iteration 108/250, Loss: 0.0116\n",
      "Epoch 147/200, Iteration 109/250, Loss: 0.0139\n",
      "Epoch 147/200, Iteration 110/250, Loss: 0.0225\n",
      "Epoch 147/200, Iteration 111/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 112/250, Loss: 0.0133\n",
      "Epoch 147/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 147/200, Iteration 114/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 115/250, Loss: 0.0226\n",
      "Epoch 147/200, Iteration 116/250, Loss: 0.0155\n",
      "Epoch 147/200, Iteration 117/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 118/250, Loss: 0.0304\n",
      "Epoch 147/200, Iteration 119/250, Loss: 0.0145\n",
      "Epoch 147/200, Iteration 120/250, Loss: 0.0173\n",
      "Epoch 147/200, Iteration 121/250, Loss: 0.0080\n",
      "Epoch 147/200, Iteration 122/250, Loss: 0.0081\n",
      "Epoch 147/200, Iteration 123/250, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 124/250, Loss: 0.0145\n",
      "Epoch 147/200, Iteration 125/250, Loss: 0.0164\n",
      "Epoch 147/200, Iteration 126/250, Loss: 0.0106\n",
      "Epoch 147/200, Iteration 127/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 128/250, Loss: 0.0252\n",
      "Epoch 147/200, Iteration 129/250, Loss: 0.0144\n",
      "Epoch 147/200, Iteration 130/250, Loss: 0.0068\n",
      "Epoch 147/200, Iteration 131/250, Loss: 0.0255\n",
      "Epoch 147/200, Iteration 132/250, Loss: 0.0117\n",
      "Epoch 147/200, Iteration 133/250, Loss: 0.0121\n",
      "Epoch 147/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 147/200, Iteration 135/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 137/250, Loss: 0.0229\n",
      "Epoch 147/200, Iteration 138/250, Loss: 0.0154\n",
      "Epoch 147/200, Iteration 139/250, Loss: 0.0092\n",
      "Epoch 147/200, Iteration 140/250, Loss: 0.0202\n",
      "Epoch 147/200, Iteration 141/250, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 142/250, Loss: 0.0107\n",
      "Epoch 147/200, Iteration 143/250, Loss: 0.0130\n",
      "Epoch 147/200, Iteration 144/250, Loss: 0.0140\n",
      "Epoch 147/200, Iteration 145/250, Loss: 0.0236\n",
      "Epoch 147/200, Iteration 146/250, Loss: 0.0104\n",
      "Epoch 147/200, Iteration 147/250, Loss: 0.0137\n",
      "Epoch 147/200, Iteration 148/250, Loss: 0.0194\n",
      "Epoch 147/200, Iteration 149/250, Loss: 0.0114\n",
      "Epoch 147/200, Iteration 150/250, Loss: 0.0277\n",
      "Epoch 147/200, Iteration 151/250, Loss: 0.0167\n",
      "Epoch 147/200, Iteration 152/250, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 153/250, Loss: 0.0260\n",
      "Epoch 147/200, Iteration 154/250, Loss: 0.0079\n",
      "Epoch 147/200, Iteration 155/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 156/250, Loss: 0.0208\n",
      "Epoch 147/200, Iteration 157/250, Loss: 0.0077\n",
      "Epoch 147/200, Iteration 158/250, Loss: 0.0424\n",
      "Epoch 147/200, Iteration 159/250, Loss: 0.0268\n",
      "Epoch 147/200, Iteration 160/250, Loss: 0.0092\n",
      "Epoch 147/200, Iteration 161/250, Loss: 0.0101\n",
      "Epoch 147/200, Iteration 162/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 163/250, Loss: 0.0150\n",
      "Epoch 147/200, Iteration 164/250, Loss: 0.0206\n",
      "Epoch 147/200, Iteration 165/250, Loss: 0.0174\n",
      "Epoch 147/200, Iteration 166/250, Loss: 0.0370\n",
      "Epoch 147/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 147/200, Iteration 168/250, Loss: 0.0242\n",
      "Epoch 147/200, Iteration 169/250, Loss: 0.0131\n",
      "Epoch 147/200, Iteration 170/250, Loss: 0.0162\n",
      "Epoch 147/200, Iteration 171/250, Loss: 0.0238\n",
      "Epoch 147/200, Iteration 172/250, Loss: 0.0105\n",
      "Epoch 147/200, Iteration 173/250, Loss: 0.0104\n",
      "Epoch 147/200, Iteration 174/250, Loss: 0.0128\n",
      "Epoch 147/200, Iteration 175/250, Loss: 0.0235\n",
      "Epoch 147/200, Iteration 176/250, Loss: 0.0120\n",
      "Epoch 147/200, Iteration 177/250, Loss: 0.0092\n",
      "Epoch 147/200, Iteration 178/250, Loss: 0.0104\n",
      "Epoch 147/200, Iteration 179/250, Loss: 0.0177\n",
      "Epoch 147/200, Iteration 180/250, Loss: 0.0211\n",
      "Epoch 147/200, Iteration 181/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 182/250, Loss: 0.0153\n",
      "Epoch 147/200, Iteration 183/250, Loss: 0.0119\n",
      "Epoch 147/200, Iteration 184/250, Loss: 0.0056\n",
      "Epoch 147/200, Iteration 185/250, Loss: 0.0198\n",
      "Epoch 147/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 147/200, Iteration 187/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 188/250, Loss: 0.0076\n",
      "Epoch 147/200, Iteration 189/250, Loss: 0.0276\n",
      "Epoch 147/200, Iteration 190/250, Loss: 0.0158\n",
      "Epoch 147/200, Iteration 191/250, Loss: 0.0175\n",
      "Epoch 147/200, Iteration 192/250, Loss: 0.0229\n",
      "Epoch 147/200, Iteration 193/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 194/250, Loss: 0.0168\n",
      "Epoch 147/200, Iteration 195/250, Loss: 0.0083\n",
      "Epoch 147/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 147/200, Iteration 197/250, Loss: 0.0180\n",
      "Epoch 147/200, Iteration 198/250, Loss: 0.0060\n",
      "Epoch 147/200, Iteration 199/250, Loss: 0.0223\n",
      "Epoch 147/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 147/200, Iteration 201/250, Loss: 0.0277\n",
      "Epoch 147/200, Iteration 202/250, Loss: 0.0269\n",
      "Epoch 147/200, Iteration 203/250, Loss: 0.0232\n",
      "Epoch 147/200, Iteration 204/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 205/250, Loss: 0.0237\n",
      "Epoch 147/200, Iteration 206/250, Loss: 0.0161\n",
      "Epoch 147/200, Iteration 207/250, Loss: 0.0079\n",
      "Epoch 147/200, Iteration 208/250, Loss: 0.0068\n",
      "Epoch 147/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 147/200, Iteration 210/250, Loss: 0.0170\n",
      "Epoch 147/200, Iteration 211/250, Loss: 0.0151\n",
      "Epoch 147/200, Iteration 212/250, Loss: 0.0127\n",
      "Epoch 147/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 147/200, Iteration 214/250, Loss: 0.0144\n",
      "Epoch 147/200, Iteration 215/250, Loss: 0.0272\n",
      "Epoch 147/200, Iteration 216/250, Loss: 0.0105\n",
      "Epoch 147/200, Iteration 217/250, Loss: 0.0203\n",
      "Epoch 147/200, Iteration 218/250, Loss: 0.0072\n",
      "Epoch 147/200, Iteration 219/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 220/250, Loss: 0.0125\n",
      "Epoch 147/200, Iteration 221/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 222/250, Loss: 0.0078\n",
      "Epoch 147/200, Iteration 223/250, Loss: 0.0192\n",
      "Epoch 147/200, Iteration 224/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 225/250, Loss: 0.0150\n",
      "Epoch 147/200, Iteration 226/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 227/250, Loss: 0.0101\n",
      "Epoch 147/200, Iteration 228/250, Loss: 0.0136\n",
      "Epoch 147/200, Iteration 229/250, Loss: 0.0269\n",
      "Epoch 147/200, Iteration 230/250, Loss: 0.0229\n",
      "Epoch 147/200, Iteration 231/250, Loss: 0.0186\n",
      "Epoch 147/200, Iteration 232/250, Loss: 0.0221\n",
      "Epoch 147/200, Iteration 233/250, Loss: 0.0149\n",
      "Epoch 147/200, Iteration 234/250, Loss: 0.0356\n",
      "Epoch 147/200, Iteration 235/250, Loss: 0.0129\n",
      "Epoch 147/200, Iteration 236/250, Loss: 0.0091\n",
      "Epoch 147/200, Iteration 237/250, Loss: 0.0123\n",
      "Epoch 147/200, Iteration 238/250, Loss: 0.0135\n",
      "Epoch 147/200, Iteration 239/250, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200, Iteration 240/250, Loss: 0.0068\n",
      "Epoch 147/200, Iteration 241/250, Loss: 0.0172\n",
      "Epoch 147/200, Iteration 242/250, Loss: 0.0281\n",
      "Epoch 147/200, Iteration 243/250, Loss: 0.0076\n",
      "Epoch 147/200, Iteration 244/250, Loss: 0.0111\n",
      "Epoch 147/200, Iteration 245/250, Loss: 0.0296\n",
      "Epoch 147/200, Iteration 246/250, Loss: 0.0151\n",
      "Epoch 147/200, Iteration 247/250, Loss: 0.0114\n",
      "Epoch 147/200, Iteration 248/250, Loss: 0.0099\n",
      "Epoch 147/200, Iteration 249/250, Loss: 0.0193\n",
      "Epoch 147/200, Iteration 250/250, Loss: 0.0074\n",
      "Train Error: \n",
      " Accuracy: 89.28%, Avg loss: 0.006178, MRE: 0.615157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.65%, Avg loss: 0.006212, MRE: 0.926793 \n",
      "\n",
      "Epoch 148/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 2/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 3/250, Loss: 0.0079\n",
      "Epoch 148/200, Iteration 4/250, Loss: 0.0063\n",
      "Epoch 148/200, Iteration 5/250, Loss: 0.0162\n",
      "Epoch 148/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 148/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 148/200, Iteration 8/250, Loss: 0.0139\n",
      "Epoch 148/200, Iteration 9/250, Loss: 0.0266\n",
      "Epoch 148/200, Iteration 10/250, Loss: 0.0126\n",
      "Epoch 148/200, Iteration 11/250, Loss: 0.0192\n",
      "Epoch 148/200, Iteration 12/250, Loss: 0.0295\n",
      "Epoch 148/200, Iteration 13/250, Loss: 0.0211\n",
      "Epoch 148/200, Iteration 14/250, Loss: 0.0075\n",
      "Epoch 148/200, Iteration 15/250, Loss: 0.0222\n",
      "Epoch 148/200, Iteration 16/250, Loss: 0.0095\n",
      "Epoch 148/200, Iteration 17/250, Loss: 0.0145\n",
      "Epoch 148/200, Iteration 18/250, Loss: 0.0105\n",
      "Epoch 148/200, Iteration 19/250, Loss: 0.0222\n",
      "Epoch 148/200, Iteration 20/250, Loss: 0.0130\n",
      "Epoch 148/200, Iteration 21/250, Loss: 0.0290\n",
      "Epoch 148/200, Iteration 22/250, Loss: 0.0070\n",
      "Epoch 148/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 148/200, Iteration 24/250, Loss: 0.0183\n",
      "Epoch 148/200, Iteration 25/250, Loss: 0.0181\n",
      "Epoch 148/200, Iteration 26/250, Loss: 0.0129\n",
      "Epoch 148/200, Iteration 27/250, Loss: 0.0135\n",
      "Epoch 148/200, Iteration 28/250, Loss: 0.0160\n",
      "Epoch 148/200, Iteration 29/250, Loss: 0.0082\n",
      "Epoch 148/200, Iteration 30/250, Loss: 0.0096\n",
      "Epoch 148/200, Iteration 31/250, Loss: 0.0315\n",
      "Epoch 148/200, Iteration 32/250, Loss: 0.0086\n",
      "Epoch 148/200, Iteration 33/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 34/250, Loss: 0.0079\n",
      "Epoch 148/200, Iteration 35/250, Loss: 0.0127\n",
      "Epoch 148/200, Iteration 36/250, Loss: 0.0201\n",
      "Epoch 148/200, Iteration 37/250, Loss: 0.0152\n",
      "Epoch 148/200, Iteration 38/250, Loss: 0.0090\n",
      "Epoch 148/200, Iteration 39/250, Loss: 0.0252\n",
      "Epoch 148/200, Iteration 40/250, Loss: 0.0103\n",
      "Epoch 148/200, Iteration 41/250, Loss: 0.0109\n",
      "Epoch 148/200, Iteration 42/250, Loss: 0.0279\n",
      "Epoch 148/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 44/250, Loss: 0.0196\n",
      "Epoch 148/200, Iteration 45/250, Loss: 0.0142\n",
      "Epoch 148/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 148/200, Iteration 47/250, Loss: 0.0081\n",
      "Epoch 148/200, Iteration 48/250, Loss: 0.0138\n",
      "Epoch 148/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 148/200, Iteration 51/250, Loss: 0.0210\n",
      "Epoch 148/200, Iteration 52/250, Loss: 0.0161\n",
      "Epoch 148/200, Iteration 53/250, Loss: 0.0108\n",
      "Epoch 148/200, Iteration 54/250, Loss: 0.0090\n",
      "Epoch 148/200, Iteration 55/250, Loss: 0.0422\n",
      "Epoch 148/200, Iteration 56/250, Loss: 0.0158\n",
      "Epoch 148/200, Iteration 57/250, Loss: 0.0145\n",
      "Epoch 148/200, Iteration 58/250, Loss: 0.0119\n",
      "Epoch 148/200, Iteration 59/250, Loss: 0.0069\n",
      "Epoch 148/200, Iteration 60/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 61/250, Loss: 0.0116\n",
      "Epoch 148/200, Iteration 62/250, Loss: 0.0263\n",
      "Epoch 148/200, Iteration 63/250, Loss: 0.0255\n",
      "Epoch 148/200, Iteration 64/250, Loss: 0.0113\n",
      "Epoch 148/200, Iteration 65/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 66/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 67/250, Loss: 0.0229\n",
      "Epoch 148/200, Iteration 68/250, Loss: 0.0153\n",
      "Epoch 148/200, Iteration 69/250, Loss: 0.0087\n",
      "Epoch 148/200, Iteration 70/250, Loss: 0.0052\n",
      "Epoch 148/200, Iteration 71/250, Loss: 0.0180\n",
      "Epoch 148/200, Iteration 72/250, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 73/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 74/250, Loss: 0.0137\n",
      "Epoch 148/200, Iteration 75/250, Loss: 0.0090\n",
      "Epoch 148/200, Iteration 76/250, Loss: 0.0176\n",
      "Epoch 148/200, Iteration 77/250, Loss: 0.0293\n",
      "Epoch 148/200, Iteration 78/250, Loss: 0.0048\n",
      "Epoch 148/200, Iteration 79/250, Loss: 0.0086\n",
      "Epoch 148/200, Iteration 80/250, Loss: 0.0152\n",
      "Epoch 148/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 148/200, Iteration 82/250, Loss: 0.0248\n",
      "Epoch 148/200, Iteration 83/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 84/250, Loss: 0.0073\n",
      "Epoch 148/200, Iteration 85/250, Loss: 0.0068\n",
      "Epoch 148/200, Iteration 86/250, Loss: 0.0110\n",
      "Epoch 148/200, Iteration 87/250, Loss: 0.0070\n",
      "Epoch 148/200, Iteration 88/250, Loss: 0.0472\n",
      "Epoch 148/200, Iteration 89/250, Loss: 0.0250\n",
      "Epoch 148/200, Iteration 90/250, Loss: 0.0072\n",
      "Epoch 148/200, Iteration 91/250, Loss: 0.0120\n",
      "Epoch 148/200, Iteration 92/250, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 93/250, Loss: 0.0100\n",
      "Epoch 148/200, Iteration 94/250, Loss: 0.0162\n",
      "Epoch 148/200, Iteration 95/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 96/250, Loss: 0.0144\n",
      "Epoch 148/200, Iteration 97/250, Loss: 0.0183\n",
      "Epoch 148/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 148/200, Iteration 100/250, Loss: 0.0087\n",
      "Epoch 148/200, Iteration 101/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 102/250, Loss: 0.0084\n",
      "Epoch 148/200, Iteration 103/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 104/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 105/250, Loss: 0.0108\n",
      "Epoch 148/200, Iteration 106/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 107/250, Loss: 0.0132\n",
      "Epoch 148/200, Iteration 108/250, Loss: 0.0157\n",
      "Epoch 148/200, Iteration 109/250, Loss: 0.0178\n",
      "Epoch 148/200, Iteration 110/250, Loss: 0.0191\n",
      "Epoch 148/200, Iteration 111/250, Loss: 0.0190\n",
      "Epoch 148/200, Iteration 112/250, Loss: 0.0189\n",
      "Epoch 148/200, Iteration 113/250, Loss: 0.0115\n",
      "Epoch 148/200, Iteration 114/250, Loss: 0.0211\n",
      "Epoch 148/200, Iteration 115/250, Loss: 0.0227\n",
      "Epoch 148/200, Iteration 116/250, Loss: 0.0078\n",
      "Epoch 148/200, Iteration 117/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 118/250, Loss: 0.0109\n",
      "Epoch 148/200, Iteration 119/250, Loss: 0.0089\n",
      "Epoch 148/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 121/250, Loss: 0.0073\n",
      "Epoch 148/200, Iteration 122/250, Loss: 0.0108\n",
      "Epoch 148/200, Iteration 123/250, Loss: 0.0204\n",
      "Epoch 148/200, Iteration 124/250, Loss: 0.0221\n",
      "Epoch 148/200, Iteration 125/250, Loss: 0.0148\n",
      "Epoch 148/200, Iteration 126/250, Loss: 0.0285\n",
      "Epoch 148/200, Iteration 127/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 128/250, Loss: 0.0108\n",
      "Epoch 148/200, Iteration 129/250, Loss: 0.0124\n",
      "Epoch 148/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 148/200, Iteration 131/250, Loss: 0.0267\n",
      "Epoch 148/200, Iteration 132/250, Loss: 0.0158\n",
      "Epoch 148/200, Iteration 133/250, Loss: 0.0141\n",
      "Epoch 148/200, Iteration 134/250, Loss: 0.0213\n",
      "Epoch 148/200, Iteration 135/250, Loss: 0.0143\n",
      "Epoch 148/200, Iteration 136/250, Loss: 0.0113\n",
      "Epoch 148/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 148/200, Iteration 138/250, Loss: 0.0144\n",
      "Epoch 148/200, Iteration 139/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 140/250, Loss: 0.0146\n",
      "Epoch 148/200, Iteration 141/250, Loss: 0.0246\n",
      "Epoch 148/200, Iteration 142/250, Loss: 0.0061\n",
      "Epoch 148/200, Iteration 143/250, Loss: 0.0074\n",
      "Epoch 148/200, Iteration 144/250, Loss: 0.0191\n",
      "Epoch 148/200, Iteration 145/250, Loss: 0.0177\n",
      "Epoch 148/200, Iteration 146/250, Loss: 0.0131\n",
      "Epoch 148/200, Iteration 147/250, Loss: 0.0075\n",
      "Epoch 148/200, Iteration 148/250, Loss: 0.0218\n",
      "Epoch 148/200, Iteration 149/250, Loss: 0.0279\n",
      "Epoch 148/200, Iteration 150/250, Loss: 0.0121\n",
      "Epoch 148/200, Iteration 151/250, Loss: 0.0133\n",
      "Epoch 148/200, Iteration 152/250, Loss: 0.0270\n",
      "Epoch 148/200, Iteration 153/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 154/250, Loss: 0.0366\n",
      "Epoch 148/200, Iteration 155/250, Loss: 0.0087\n",
      "Epoch 148/200, Iteration 156/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 157/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 158/250, Loss: 0.0147\n",
      "Epoch 148/200, Iteration 159/250, Loss: 0.0170\n",
      "Epoch 148/200, Iteration 160/250, Loss: 0.0218\n",
      "Epoch 148/200, Iteration 161/250, Loss: 0.0238\n",
      "Epoch 148/200, Iteration 162/250, Loss: 0.0109\n",
      "Epoch 148/200, Iteration 163/250, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 164/250, Loss: 0.0065\n",
      "Epoch 148/200, Iteration 165/250, Loss: 0.0130\n",
      "Epoch 148/200, Iteration 166/250, Loss: 0.0203\n",
      "Epoch 148/200, Iteration 167/250, Loss: 0.0144\n",
      "Epoch 148/200, Iteration 168/250, Loss: 0.0181\n",
      "Epoch 148/200, Iteration 169/250, Loss: 0.0137\n",
      "Epoch 148/200, Iteration 170/250, Loss: 0.0161\n",
      "Epoch 148/200, Iteration 171/250, Loss: 0.0117\n",
      "Epoch 148/200, Iteration 172/250, Loss: 0.0231\n",
      "Epoch 148/200, Iteration 173/250, Loss: 0.0125\n",
      "Epoch 148/200, Iteration 174/250, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 175/250, Loss: 0.0153\n",
      "Epoch 148/200, Iteration 176/250, Loss: 0.0061\n",
      "Epoch 148/200, Iteration 177/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 178/250, Loss: 0.0125\n",
      "Epoch 148/200, Iteration 179/250, Loss: 0.0142\n",
      "Epoch 148/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 148/200, Iteration 181/250, Loss: 0.0123\n",
      "Epoch 148/200, Iteration 182/250, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 183/250, Loss: 0.0182\n",
      "Epoch 148/200, Iteration 184/250, Loss: 0.0159\n",
      "Epoch 148/200, Iteration 185/250, Loss: 0.0119\n",
      "Epoch 148/200, Iteration 186/250, Loss: 0.0138\n",
      "Epoch 148/200, Iteration 187/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 188/250, Loss: 0.0377\n",
      "Epoch 148/200, Iteration 189/250, Loss: 0.0346\n",
      "Epoch 148/200, Iteration 190/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 191/250, Loss: 0.0093\n",
      "Epoch 148/200, Iteration 192/250, Loss: 0.0337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200, Iteration 193/250, Loss: 0.0272\n",
      "Epoch 148/200, Iteration 194/250, Loss: 0.0058\n",
      "Epoch 148/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 196/250, Loss: 0.0116\n",
      "Epoch 148/200, Iteration 197/250, Loss: 0.0080\n",
      "Epoch 148/200, Iteration 198/250, Loss: 0.0209\n",
      "Epoch 148/200, Iteration 199/250, Loss: 0.0187\n",
      "Epoch 148/200, Iteration 200/250, Loss: 0.0134\n",
      "Epoch 148/200, Iteration 201/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 202/250, Loss: 0.0177\n",
      "Epoch 148/200, Iteration 203/250, Loss: 0.0345\n",
      "Epoch 148/200, Iteration 204/250, Loss: 0.0181\n",
      "Epoch 148/200, Iteration 205/250, Loss: 0.0156\n",
      "Epoch 148/200, Iteration 206/250, Loss: 0.0155\n",
      "Epoch 148/200, Iteration 207/250, Loss: 0.0162\n",
      "Epoch 148/200, Iteration 208/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 209/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 210/250, Loss: 0.0134\n",
      "Epoch 148/200, Iteration 211/250, Loss: 0.0181\n",
      "Epoch 148/200, Iteration 212/250, Loss: 0.0072\n",
      "Epoch 148/200, Iteration 213/250, Loss: 0.0223\n",
      "Epoch 148/200, Iteration 214/250, Loss: 0.0194\n",
      "Epoch 148/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 216/250, Loss: 0.0123\n",
      "Epoch 148/200, Iteration 217/250, Loss: 0.0071\n",
      "Epoch 148/200, Iteration 218/250, Loss: 0.0235\n",
      "Epoch 148/200, Iteration 219/250, Loss: 0.0132\n",
      "Epoch 148/200, Iteration 220/250, Loss: 0.0127\n",
      "Epoch 148/200, Iteration 221/250, Loss: 0.0065\n",
      "Epoch 148/200, Iteration 222/250, Loss: 0.0083\n",
      "Epoch 148/200, Iteration 223/250, Loss: 0.0176\n",
      "Epoch 148/200, Iteration 224/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 225/250, Loss: 0.0087\n",
      "Epoch 148/200, Iteration 226/250, Loss: 0.0078\n",
      "Epoch 148/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 148/200, Iteration 228/250, Loss: 0.0249\n",
      "Epoch 148/200, Iteration 229/250, Loss: 0.0136\n",
      "Epoch 148/200, Iteration 230/250, Loss: 0.0140\n",
      "Epoch 148/200, Iteration 231/250, Loss: 0.0168\n",
      "Epoch 148/200, Iteration 232/250, Loss: 0.0170\n",
      "Epoch 148/200, Iteration 233/250, Loss: 0.0109\n",
      "Epoch 148/200, Iteration 234/250, Loss: 0.0196\n",
      "Epoch 148/200, Iteration 235/250, Loss: 0.0157\n",
      "Epoch 148/200, Iteration 236/250, Loss: 0.0080\n",
      "Epoch 148/200, Iteration 237/250, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 148/200, Iteration 239/250, Loss: 0.0121\n",
      "Epoch 148/200, Iteration 240/250, Loss: 0.0132\n",
      "Epoch 148/200, Iteration 241/250, Loss: 0.0232\n",
      "Epoch 148/200, Iteration 242/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 243/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 244/250, Loss: 0.0058\n",
      "Epoch 148/200, Iteration 245/250, Loss: 0.0117\n",
      "Epoch 148/200, Iteration 246/250, Loss: 0.0237\n",
      "Epoch 148/200, Iteration 247/250, Loss: 0.0151\n",
      "Epoch 148/200, Iteration 248/250, Loss: 0.0192\n",
      "Epoch 148/200, Iteration 249/250, Loss: 0.0184\n",
      "Epoch 148/200, Iteration 250/250, Loss: 0.0187\n",
      "Train Error: \n",
      " Accuracy: 87.49%, Avg loss: 0.006205, MRE: 0.627616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.006247, MRE: 0.900217 \n",
      "\n",
      "Epoch 149/200, Iteration 1/250, Loss: 0.0343\n",
      "Epoch 149/200, Iteration 2/250, Loss: 0.0224\n",
      "Epoch 149/200, Iteration 3/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 4/250, Loss: 0.0098\n",
      "Epoch 149/200, Iteration 5/250, Loss: 0.0085\n",
      "Epoch 149/200, Iteration 6/250, Loss: 0.0291\n",
      "Epoch 149/200, Iteration 7/250, Loss: 0.0106\n",
      "Epoch 149/200, Iteration 8/250, Loss: 0.0133\n",
      "Epoch 149/200, Iteration 9/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 149/200, Iteration 11/250, Loss: 0.0092\n",
      "Epoch 149/200, Iteration 12/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 149/200, Iteration 14/250, Loss: 0.0126\n",
      "Epoch 149/200, Iteration 15/250, Loss: 0.0199\n",
      "Epoch 149/200, Iteration 16/250, Loss: 0.0188\n",
      "Epoch 149/200, Iteration 17/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 18/250, Loss: 0.0116\n",
      "Epoch 149/200, Iteration 19/250, Loss: 0.0142\n",
      "Epoch 149/200, Iteration 20/250, Loss: 0.0088\n",
      "Epoch 149/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 149/200, Iteration 22/250, Loss: 0.0247\n",
      "Epoch 149/200, Iteration 23/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 24/250, Loss: 0.0160\n",
      "Epoch 149/200, Iteration 25/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 26/250, Loss: 0.0267\n",
      "Epoch 149/200, Iteration 27/250, Loss: 0.0253\n",
      "Epoch 149/200, Iteration 28/250, Loss: 0.0203\n",
      "Epoch 149/200, Iteration 29/250, Loss: 0.0140\n",
      "Epoch 149/200, Iteration 30/250, Loss: 0.0153\n",
      "Epoch 149/200, Iteration 31/250, Loss: 0.0149\n",
      "Epoch 149/200, Iteration 32/250, Loss: 0.0128\n",
      "Epoch 149/200, Iteration 33/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 34/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 35/250, Loss: 0.0145\n",
      "Epoch 149/200, Iteration 36/250, Loss: 0.0105\n",
      "Epoch 149/200, Iteration 37/250, Loss: 0.0104\n",
      "Epoch 149/200, Iteration 38/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 149/200, Iteration 40/250, Loss: 0.0228\n",
      "Epoch 149/200, Iteration 41/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 42/250, Loss: 0.0111\n",
      "Epoch 149/200, Iteration 43/250, Loss: 0.0423\n",
      "Epoch 149/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 149/200, Iteration 45/250, Loss: 0.0236\n",
      "Epoch 149/200, Iteration 46/250, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 47/250, Loss: 0.0122\n",
      "Epoch 149/200, Iteration 48/250, Loss: 0.0117\n",
      "Epoch 149/200, Iteration 49/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 50/250, Loss: 0.0057\n",
      "Epoch 149/200, Iteration 51/250, Loss: 0.0137\n",
      "Epoch 149/200, Iteration 52/250, Loss: 0.0145\n",
      "Epoch 149/200, Iteration 53/250, Loss: 0.0221\n",
      "Epoch 149/200, Iteration 54/250, Loss: 0.0089\n",
      "Epoch 149/200, Iteration 55/250, Loss: 0.0106\n",
      "Epoch 149/200, Iteration 56/250, Loss: 0.0307\n",
      "Epoch 149/200, Iteration 57/250, Loss: 0.0197\n",
      "Epoch 149/200, Iteration 58/250, Loss: 0.0277\n",
      "Epoch 149/200, Iteration 59/250, Loss: 0.0104\n",
      "Epoch 149/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 149/200, Iteration 61/250, Loss: 0.0247\n",
      "Epoch 149/200, Iteration 62/250, Loss: 0.0151\n",
      "Epoch 149/200, Iteration 63/250, Loss: 0.0102\n",
      "Epoch 149/200, Iteration 64/250, Loss: 0.0150\n",
      "Epoch 149/200, Iteration 65/250, Loss: 0.0141\n",
      "Epoch 149/200, Iteration 66/250, Loss: 0.0167\n",
      "Epoch 149/200, Iteration 67/250, Loss: 0.0135\n",
      "Epoch 149/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 149/200, Iteration 69/250, Loss: 0.0092\n",
      "Epoch 149/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 149/200, Iteration 71/250, Loss: 0.0227\n",
      "Epoch 149/200, Iteration 72/250, Loss: 0.0106\n",
      "Epoch 149/200, Iteration 73/250, Loss: 0.0087\n",
      "Epoch 149/200, Iteration 74/250, Loss: 0.0109\n",
      "Epoch 149/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 76/250, Loss: 0.0160\n",
      "Epoch 149/200, Iteration 77/250, Loss: 0.0111\n",
      "Epoch 149/200, Iteration 78/250, Loss: 0.0325\n",
      "Epoch 149/200, Iteration 79/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 80/250, Loss: 0.0155\n",
      "Epoch 149/200, Iteration 81/250, Loss: 0.0311\n",
      "Epoch 149/200, Iteration 82/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 149/200, Iteration 84/250, Loss: 0.0105\n",
      "Epoch 149/200, Iteration 85/250, Loss: 0.0289\n",
      "Epoch 149/200, Iteration 86/250, Loss: 0.0164\n",
      "Epoch 149/200, Iteration 87/250, Loss: 0.0142\n",
      "Epoch 149/200, Iteration 88/250, Loss: 0.0183\n",
      "Epoch 149/200, Iteration 89/250, Loss: 0.0143\n",
      "Epoch 149/200, Iteration 90/250, Loss: 0.0100\n",
      "Epoch 149/200, Iteration 91/250, Loss: 0.0135\n",
      "Epoch 149/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 93/250, Loss: 0.0169\n",
      "Epoch 149/200, Iteration 94/250, Loss: 0.0258\n",
      "Epoch 149/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 149/200, Iteration 96/250, Loss: 0.0132\n",
      "Epoch 149/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 98/250, Loss: 0.0130\n",
      "Epoch 149/200, Iteration 99/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 100/250, Loss: 0.0195\n",
      "Epoch 149/200, Iteration 101/250, Loss: 0.0107\n",
      "Epoch 149/200, Iteration 102/250, Loss: 0.0123\n",
      "Epoch 149/200, Iteration 103/250, Loss: 0.0138\n",
      "Epoch 149/200, Iteration 104/250, Loss: 0.0141\n",
      "Epoch 149/200, Iteration 105/250, Loss: 0.0073\n",
      "Epoch 149/200, Iteration 106/250, Loss: 0.0169\n",
      "Epoch 149/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 149/200, Iteration 108/250, Loss: 0.0161\n",
      "Epoch 149/200, Iteration 109/250, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 110/250, Loss: 0.0114\n",
      "Epoch 149/200, Iteration 111/250, Loss: 0.0058\n",
      "Epoch 149/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 113/250, Loss: 0.0063\n",
      "Epoch 149/200, Iteration 114/250, Loss: 0.0065\n",
      "Epoch 149/200, Iteration 115/250, Loss: 0.0104\n",
      "Epoch 149/200, Iteration 116/250, Loss: 0.0139\n",
      "Epoch 149/200, Iteration 117/250, Loss: 0.0150\n",
      "Epoch 149/200, Iteration 118/250, Loss: 0.0353\n",
      "Epoch 149/200, Iteration 119/250, Loss: 0.0137\n",
      "Epoch 149/200, Iteration 120/250, Loss: 0.0107\n",
      "Epoch 149/200, Iteration 121/250, Loss: 0.0245\n",
      "Epoch 149/200, Iteration 122/250, Loss: 0.0143\n",
      "Epoch 149/200, Iteration 123/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 124/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 125/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 126/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 127/250, Loss: 0.0128\n",
      "Epoch 149/200, Iteration 128/250, Loss: 0.0205\n",
      "Epoch 149/200, Iteration 129/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 130/250, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200, Iteration 131/250, Loss: 0.0118\n",
      "Epoch 149/200, Iteration 132/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 133/250, Loss: 0.0117\n",
      "Epoch 149/200, Iteration 134/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 135/250, Loss: 0.0162\n",
      "Epoch 149/200, Iteration 136/250, Loss: 0.0358\n",
      "Epoch 149/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 149/200, Iteration 138/250, Loss: 0.0075\n",
      "Epoch 149/200, Iteration 139/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 140/250, Loss: 0.0263\n",
      "Epoch 149/200, Iteration 141/250, Loss: 0.0133\n",
      "Epoch 149/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 144/250, Loss: 0.0160\n",
      "Epoch 149/200, Iteration 145/250, Loss: 0.0181\n",
      "Epoch 149/200, Iteration 146/250, Loss: 0.0185\n",
      "Epoch 149/200, Iteration 147/250, Loss: 0.0369\n",
      "Epoch 149/200, Iteration 148/250, Loss: 0.0142\n",
      "Epoch 149/200, Iteration 149/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 150/250, Loss: 0.0213\n",
      "Epoch 149/200, Iteration 151/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 152/250, Loss: 0.0234\n",
      "Epoch 149/200, Iteration 153/250, Loss: 0.0208\n",
      "Epoch 149/200, Iteration 154/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 155/250, Loss: 0.0100\n",
      "Epoch 149/200, Iteration 156/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 157/250, Loss: 0.0076\n",
      "Epoch 149/200, Iteration 158/250, Loss: 0.0151\n",
      "Epoch 149/200, Iteration 159/250, Loss: 0.0066\n",
      "Epoch 149/200, Iteration 160/250, Loss: 0.0321\n",
      "Epoch 149/200, Iteration 161/250, Loss: 0.0087\n",
      "Epoch 149/200, Iteration 162/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 163/250, Loss: 0.0146\n",
      "Epoch 149/200, Iteration 164/250, Loss: 0.0117\n",
      "Epoch 149/200, Iteration 165/250, Loss: 0.0137\n",
      "Epoch 149/200, Iteration 166/250, Loss: 0.0087\n",
      "Epoch 149/200, Iteration 167/250, Loss: 0.0327\n",
      "Epoch 149/200, Iteration 168/250, Loss: 0.0151\n",
      "Epoch 149/200, Iteration 169/250, Loss: 0.0164\n",
      "Epoch 149/200, Iteration 170/250, Loss: 0.0420\n",
      "Epoch 149/200, Iteration 171/250, Loss: 0.0208\n",
      "Epoch 149/200, Iteration 172/250, Loss: 0.0185\n",
      "Epoch 149/200, Iteration 173/250, Loss: 0.0183\n",
      "Epoch 149/200, Iteration 174/250, Loss: 0.0145\n",
      "Epoch 149/200, Iteration 175/250, Loss: 0.0074\n",
      "Epoch 149/200, Iteration 176/250, Loss: 0.0121\n",
      "Epoch 149/200, Iteration 177/250, Loss: 0.0129\n",
      "Epoch 149/200, Iteration 178/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 179/250, Loss: 0.0159\n",
      "Epoch 149/200, Iteration 180/250, Loss: 0.0188\n",
      "Epoch 149/200, Iteration 181/250, Loss: 0.0140\n",
      "Epoch 149/200, Iteration 182/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 183/250, Loss: 0.0139\n",
      "Epoch 149/200, Iteration 184/250, Loss: 0.0194\n",
      "Epoch 149/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 149/200, Iteration 186/250, Loss: 0.0139\n",
      "Epoch 149/200, Iteration 187/250, Loss: 0.0190\n",
      "Epoch 149/200, Iteration 188/250, Loss: 0.0185\n",
      "Epoch 149/200, Iteration 189/250, Loss: 0.0337\n",
      "Epoch 149/200, Iteration 190/250, Loss: 0.0139\n",
      "Epoch 149/200, Iteration 191/250, Loss: 0.0162\n",
      "Epoch 149/200, Iteration 192/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 193/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 194/250, Loss: 0.0200\n",
      "Epoch 149/200, Iteration 195/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 196/250, Loss: 0.0227\n",
      "Epoch 149/200, Iteration 197/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 198/250, Loss: 0.0222\n",
      "Epoch 149/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 149/200, Iteration 200/250, Loss: 0.0053\n",
      "Epoch 149/200, Iteration 201/250, Loss: 0.0165\n",
      "Epoch 149/200, Iteration 202/250, Loss: 0.0154\n",
      "Epoch 149/200, Iteration 203/250, Loss: 0.0148\n",
      "Epoch 149/200, Iteration 204/250, Loss: 0.0126\n",
      "Epoch 149/200, Iteration 205/250, Loss: 0.0250\n",
      "Epoch 149/200, Iteration 206/250, Loss: 0.0142\n",
      "Epoch 149/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 208/250, Loss: 0.0156\n",
      "Epoch 149/200, Iteration 209/250, Loss: 0.0136\n",
      "Epoch 149/200, Iteration 210/250, Loss: 0.0137\n",
      "Epoch 149/200, Iteration 211/250, Loss: 0.0232\n",
      "Epoch 149/200, Iteration 212/250, Loss: 0.0125\n",
      "Epoch 149/200, Iteration 213/250, Loss: 0.0238\n",
      "Epoch 149/200, Iteration 214/250, Loss: 0.0231\n",
      "Epoch 149/200, Iteration 215/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 216/250, Loss: 0.0270\n",
      "Epoch 149/200, Iteration 217/250, Loss: 0.0194\n",
      "Epoch 149/200, Iteration 218/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 219/250, Loss: 0.0293\n",
      "Epoch 149/200, Iteration 220/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 221/250, Loss: 0.0194\n",
      "Epoch 149/200, Iteration 222/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 223/250, Loss: 0.0161\n",
      "Epoch 149/200, Iteration 224/250, Loss: 0.0271\n",
      "Epoch 149/200, Iteration 225/250, Loss: 0.0135\n",
      "Epoch 149/200, Iteration 226/250, Loss: 0.0314\n",
      "Epoch 149/200, Iteration 227/250, Loss: 0.0093\n",
      "Epoch 149/200, Iteration 228/250, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 229/250, Loss: 0.0125\n",
      "Epoch 149/200, Iteration 230/250, Loss: 0.0163\n",
      "Epoch 149/200, Iteration 231/250, Loss: 0.0145\n",
      "Epoch 149/200, Iteration 232/250, Loss: 0.0166\n",
      "Epoch 149/200, Iteration 233/250, Loss: 0.0116\n",
      "Epoch 149/200, Iteration 234/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 235/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 236/250, Loss: 0.0241\n",
      "Epoch 149/200, Iteration 237/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 238/250, Loss: 0.0299\n",
      "Epoch 149/200, Iteration 239/250, Loss: 0.0073\n",
      "Epoch 149/200, Iteration 240/250, Loss: 0.0111\n",
      "Epoch 149/200, Iteration 241/250, Loss: 0.0316\n",
      "Epoch 149/200, Iteration 242/250, Loss: 0.0161\n",
      "Epoch 149/200, Iteration 243/250, Loss: 0.0072\n",
      "Epoch 149/200, Iteration 244/250, Loss: 0.0148\n",
      "Epoch 149/200, Iteration 245/250, Loss: 0.0109\n",
      "Epoch 149/200, Iteration 246/250, Loss: 0.0194\n",
      "Epoch 149/200, Iteration 247/250, Loss: 0.0210\n",
      "Epoch 149/200, Iteration 248/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 249/250, Loss: 0.0136\n",
      "Epoch 149/200, Iteration 250/250, Loss: 0.0132\n",
      "Train Error: \n",
      " Accuracy: 96.11%, Avg loss: 0.005856, MRE: 0.634826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.005824, MRE: 1.049067 \n",
      "\n",
      "Epoch 150/200, Iteration 1/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 2/250, Loss: 0.0118\n",
      "Epoch 150/200, Iteration 3/250, Loss: 0.0165\n",
      "Epoch 150/200, Iteration 4/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 5/250, Loss: 0.0348\n",
      "Epoch 150/200, Iteration 6/250, Loss: 0.0073\n",
      "Epoch 150/200, Iteration 7/250, Loss: 0.0129\n",
      "Epoch 150/200, Iteration 8/250, Loss: 0.0304\n",
      "Epoch 150/200, Iteration 9/250, Loss: 0.0183\n",
      "Epoch 150/200, Iteration 10/250, Loss: 0.0210\n",
      "Epoch 150/200, Iteration 11/250, Loss: 0.0095\n",
      "Epoch 150/200, Iteration 12/250, Loss: 0.0221\n",
      "Epoch 150/200, Iteration 13/250, Loss: 0.0117\n",
      "Epoch 150/200, Iteration 14/250, Loss: 0.0248\n",
      "Epoch 150/200, Iteration 15/250, Loss: 0.0092\n",
      "Epoch 150/200, Iteration 16/250, Loss: 0.0148\n",
      "Epoch 150/200, Iteration 17/250, Loss: 0.0292\n",
      "Epoch 150/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 150/200, Iteration 19/250, Loss: 0.0194\n",
      "Epoch 150/200, Iteration 20/250, Loss: 0.0193\n",
      "Epoch 150/200, Iteration 21/250, Loss: 0.0141\n",
      "Epoch 150/200, Iteration 22/250, Loss: 0.0289\n",
      "Epoch 150/200, Iteration 23/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 24/250, Loss: 0.0174\n",
      "Epoch 150/200, Iteration 25/250, Loss: 0.0101\n",
      "Epoch 150/200, Iteration 26/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 27/250, Loss: 0.0244\n",
      "Epoch 150/200, Iteration 28/250, Loss: 0.0096\n",
      "Epoch 150/200, Iteration 29/250, Loss: 0.0215\n",
      "Epoch 150/200, Iteration 30/250, Loss: 0.0173\n",
      "Epoch 150/200, Iteration 31/250, Loss: 0.0189\n",
      "Epoch 150/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 150/200, Iteration 33/250, Loss: 0.0243\n",
      "Epoch 150/200, Iteration 34/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 35/250, Loss: 0.0117\n",
      "Epoch 150/200, Iteration 36/250, Loss: 0.0110\n",
      "Epoch 150/200, Iteration 37/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 38/250, Loss: 0.0215\n",
      "Epoch 150/200, Iteration 39/250, Loss: 0.0316\n",
      "Epoch 150/200, Iteration 40/250, Loss: 0.0100\n",
      "Epoch 150/200, Iteration 41/250, Loss: 0.0154\n",
      "Epoch 150/200, Iteration 42/250, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 43/250, Loss: 0.0124\n",
      "Epoch 150/200, Iteration 44/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 45/250, Loss: 0.0274\n",
      "Epoch 150/200, Iteration 46/250, Loss: 0.0150\n",
      "Epoch 150/200, Iteration 47/250, Loss: 0.0242\n",
      "Epoch 150/200, Iteration 48/250, Loss: 0.0325\n",
      "Epoch 150/200, Iteration 49/250, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 50/250, Loss: 0.0087\n",
      "Epoch 150/200, Iteration 51/250, Loss: 0.0074\n",
      "Epoch 150/200, Iteration 52/250, Loss: 0.0061\n",
      "Epoch 150/200, Iteration 53/250, Loss: 0.0108\n",
      "Epoch 150/200, Iteration 54/250, Loss: 0.0114\n",
      "Epoch 150/200, Iteration 55/250, Loss: 0.0100\n",
      "Epoch 150/200, Iteration 56/250, Loss: 0.0085\n",
      "Epoch 150/200, Iteration 57/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 58/250, Loss: 0.0103\n",
      "Epoch 150/200, Iteration 59/250, Loss: 0.0096\n",
      "Epoch 150/200, Iteration 60/250, Loss: 0.0439\n",
      "Epoch 150/200, Iteration 61/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 62/250, Loss: 0.0255\n",
      "Epoch 150/200, Iteration 63/250, Loss: 0.0118\n",
      "Epoch 150/200, Iteration 64/250, Loss: 0.0290\n",
      "Epoch 150/200, Iteration 65/250, Loss: 0.0114\n",
      "Epoch 150/200, Iteration 66/250, Loss: 0.0116\n",
      "Epoch 150/200, Iteration 67/250, Loss: 0.0176\n",
      "Epoch 150/200, Iteration 68/250, Loss: 0.0238\n",
      "Epoch 150/200, Iteration 69/250, Loss: 0.0085\n",
      "Epoch 150/200, Iteration 70/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 71/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 72/250, Loss: 0.0252\n",
      "Epoch 150/200, Iteration 73/250, Loss: 0.0124\n",
      "Epoch 150/200, Iteration 74/250, Loss: 0.0128\n",
      "Epoch 150/200, Iteration 75/250, Loss: 0.0289\n",
      "Epoch 150/200, Iteration 76/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 150/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 150/200, Iteration 79/250, Loss: 0.0224\n",
      "Epoch 150/200, Iteration 80/250, Loss: 0.0152\n",
      "Epoch 150/200, Iteration 81/250, Loss: 0.0164\n",
      "Epoch 150/200, Iteration 82/250, Loss: 0.0074\n",
      "Epoch 150/200, Iteration 83/250, Loss: 0.0097\n",
      "Epoch 150/200, Iteration 84/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 85/250, Loss: 0.0167\n",
      "Epoch 150/200, Iteration 86/250, Loss: 0.0069\n",
      "Epoch 150/200, Iteration 87/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 88/250, Loss: 0.0127\n",
      "Epoch 150/200, Iteration 89/250, Loss: 0.0148\n",
      "Epoch 150/200, Iteration 90/250, Loss: 0.0226\n",
      "Epoch 150/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 150/200, Iteration 92/250, Loss: 0.0056\n",
      "Epoch 150/200, Iteration 93/250, Loss: 0.0207\n",
      "Epoch 150/200, Iteration 94/250, Loss: 0.0234\n",
      "Epoch 150/200, Iteration 95/250, Loss: 0.0305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200, Iteration 96/250, Loss: 0.0139\n",
      "Epoch 150/200, Iteration 97/250, Loss: 0.0221\n",
      "Epoch 150/200, Iteration 98/250, Loss: 0.0073\n",
      "Epoch 150/200, Iteration 99/250, Loss: 0.0107\n",
      "Epoch 150/200, Iteration 100/250, Loss: 0.0119\n",
      "Epoch 150/200, Iteration 101/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 102/250, Loss: 0.0082\n",
      "Epoch 150/200, Iteration 103/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 104/250, Loss: 0.0133\n",
      "Epoch 150/200, Iteration 105/250, Loss: 0.0136\n",
      "Epoch 150/200, Iteration 106/250, Loss: 0.0173\n",
      "Epoch 150/200, Iteration 107/250, Loss: 0.0225\n",
      "Epoch 150/200, Iteration 108/250, Loss: 0.0240\n",
      "Epoch 150/200, Iteration 109/250, Loss: 0.0169\n",
      "Epoch 150/200, Iteration 110/250, Loss: 0.0107\n",
      "Epoch 150/200, Iteration 111/250, Loss: 0.0195\n",
      "Epoch 150/200, Iteration 112/250, Loss: 0.0175\n",
      "Epoch 150/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 150/200, Iteration 114/250, Loss: 0.0219\n",
      "Epoch 150/200, Iteration 115/250, Loss: 0.0227\n",
      "Epoch 150/200, Iteration 116/250, Loss: 0.0122\n",
      "Epoch 150/200, Iteration 117/250, Loss: 0.0138\n",
      "Epoch 150/200, Iteration 118/250, Loss: 0.0205\n",
      "Epoch 150/200, Iteration 119/250, Loss: 0.0275\n",
      "Epoch 150/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 150/200, Iteration 121/250, Loss: 0.0128\n",
      "Epoch 150/200, Iteration 122/250, Loss: 0.0214\n",
      "Epoch 150/200, Iteration 123/250, Loss: 0.0066\n",
      "Epoch 150/200, Iteration 124/250, Loss: 0.0232\n",
      "Epoch 150/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 126/250, Loss: 0.0330\n",
      "Epoch 150/200, Iteration 127/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 128/250, Loss: 0.0099\n",
      "Epoch 150/200, Iteration 129/250, Loss: 0.0131\n",
      "Epoch 150/200, Iteration 130/250, Loss: 0.0198\n",
      "Epoch 150/200, Iteration 131/250, Loss: 0.0106\n",
      "Epoch 150/200, Iteration 132/250, Loss: 0.0219\n",
      "Epoch 150/200, Iteration 133/250, Loss: 0.0062\n",
      "Epoch 150/200, Iteration 134/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 135/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 136/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 137/250, Loss: 0.0210\n",
      "Epoch 150/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 150/200, Iteration 139/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 140/250, Loss: 0.0111\n",
      "Epoch 150/200, Iteration 141/250, Loss: 0.0061\n",
      "Epoch 150/200, Iteration 142/250, Loss: 0.0091\n",
      "Epoch 150/200, Iteration 143/250, Loss: 0.0278\n",
      "Epoch 150/200, Iteration 144/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 145/250, Loss: 0.0271\n",
      "Epoch 150/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 150/200, Iteration 147/250, Loss: 0.0122\n",
      "Epoch 150/200, Iteration 148/250, Loss: 0.0121\n",
      "Epoch 150/200, Iteration 149/250, Loss: 0.0092\n",
      "Epoch 150/200, Iteration 150/250, Loss: 0.0249\n",
      "Epoch 150/200, Iteration 151/250, Loss: 0.0293\n",
      "Epoch 150/200, Iteration 152/250, Loss: 0.0095\n",
      "Epoch 150/200, Iteration 153/250, Loss: 0.0099\n",
      "Epoch 150/200, Iteration 154/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 155/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 156/250, Loss: 0.0161\n",
      "Epoch 150/200, Iteration 157/250, Loss: 0.0107\n",
      "Epoch 150/200, Iteration 158/250, Loss: 0.0111\n",
      "Epoch 150/200, Iteration 159/250, Loss: 0.0277\n",
      "Epoch 150/200, Iteration 160/250, Loss: 0.0171\n",
      "Epoch 150/200, Iteration 161/250, Loss: 0.0059\n",
      "Epoch 150/200, Iteration 162/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 163/250, Loss: 0.0119\n",
      "Epoch 150/200, Iteration 164/250, Loss: 0.0224\n",
      "Epoch 150/200, Iteration 165/250, Loss: 0.0153\n",
      "Epoch 150/200, Iteration 166/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 167/250, Loss: 0.0252\n",
      "Epoch 150/200, Iteration 168/250, Loss: 0.0119\n",
      "Epoch 150/200, Iteration 169/250, Loss: 0.0360\n",
      "Epoch 150/200, Iteration 170/250, Loss: 0.0118\n",
      "Epoch 150/200, Iteration 171/250, Loss: 0.0165\n",
      "Epoch 150/200, Iteration 172/250, Loss: 0.0142\n",
      "Epoch 150/200, Iteration 173/250, Loss: 0.0237\n",
      "Epoch 150/200, Iteration 174/250, Loss: 0.0191\n",
      "Epoch 150/200, Iteration 175/250, Loss: 0.0213\n",
      "Epoch 150/200, Iteration 176/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 177/250, Loss: 0.0339\n",
      "Epoch 150/200, Iteration 178/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 179/250, Loss: 0.0189\n",
      "Epoch 150/200, Iteration 180/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 181/250, Loss: 0.0282\n",
      "Epoch 150/200, Iteration 182/250, Loss: 0.0140\n",
      "Epoch 150/200, Iteration 183/250, Loss: 0.0270\n",
      "Epoch 150/200, Iteration 184/250, Loss: 0.0102\n",
      "Epoch 150/200, Iteration 185/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 186/250, Loss: 0.0390\n",
      "Epoch 150/200, Iteration 187/250, Loss: 0.0084\n",
      "Epoch 150/200, Iteration 188/250, Loss: 0.0066\n",
      "Epoch 150/200, Iteration 189/250, Loss: 0.0099\n",
      "Epoch 150/200, Iteration 190/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 191/250, Loss: 0.0313\n",
      "Epoch 150/200, Iteration 192/250, Loss: 0.0170\n",
      "Epoch 150/200, Iteration 193/250, Loss: 0.0293\n",
      "Epoch 150/200, Iteration 194/250, Loss: 0.0304\n",
      "Epoch 150/200, Iteration 195/250, Loss: 0.0123\n",
      "Epoch 150/200, Iteration 196/250, Loss: 0.0165\n",
      "Epoch 150/200, Iteration 197/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 198/250, Loss: 0.0076\n",
      "Epoch 150/200, Iteration 199/250, Loss: 0.0091\n",
      "Epoch 150/200, Iteration 200/250, Loss: 0.0247\n",
      "Epoch 150/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 150/200, Iteration 202/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 203/250, Loss: 0.0106\n",
      "Epoch 150/200, Iteration 204/250, Loss: 0.0161\n",
      "Epoch 150/200, Iteration 205/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 206/250, Loss: 0.0158\n",
      "Epoch 150/200, Iteration 207/250, Loss: 0.0116\n",
      "Epoch 150/200, Iteration 208/250, Loss: 0.0220\n",
      "Epoch 150/200, Iteration 209/250, Loss: 0.0075\n",
      "Epoch 150/200, Iteration 210/250, Loss: 0.0169\n",
      "Epoch 150/200, Iteration 211/250, Loss: 0.0174\n",
      "Epoch 150/200, Iteration 212/250, Loss: 0.0077\n",
      "Epoch 150/200, Iteration 213/250, Loss: 0.0313\n",
      "Epoch 150/200, Iteration 214/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 215/250, Loss: 0.0237\n",
      "Epoch 150/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 150/200, Iteration 217/250, Loss: 0.0074\n",
      "Epoch 150/200, Iteration 218/250, Loss: 0.0102\n",
      "Epoch 150/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 220/250, Loss: 0.0135\n",
      "Epoch 150/200, Iteration 221/250, Loss: 0.0236\n",
      "Epoch 150/200, Iteration 222/250, Loss: 0.0266\n",
      "Epoch 150/200, Iteration 223/250, Loss: 0.0102\n",
      "Epoch 150/200, Iteration 224/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 225/250, Loss: 0.0171\n",
      "Epoch 150/200, Iteration 226/250, Loss: 0.0220\n",
      "Epoch 150/200, Iteration 227/250, Loss: 0.0304\n",
      "Epoch 150/200, Iteration 228/250, Loss: 0.0312\n",
      "Epoch 150/200, Iteration 229/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 230/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 231/250, Loss: 0.0075\n",
      "Epoch 150/200, Iteration 232/250, Loss: 0.0286\n",
      "Epoch 150/200, Iteration 233/250, Loss: 0.0104\n",
      "Epoch 150/200, Iteration 234/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 235/250, Loss: 0.0140\n",
      "Epoch 150/200, Iteration 236/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 237/250, Loss: 0.0191\n",
      "Epoch 150/200, Iteration 238/250, Loss: 0.0078\n",
      "Epoch 150/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 150/200, Iteration 240/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 241/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 242/250, Loss: 0.0108\n",
      "Epoch 150/200, Iteration 243/250, Loss: 0.0159\n",
      "Epoch 150/200, Iteration 244/250, Loss: 0.0084\n",
      "Epoch 150/200, Iteration 245/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 246/250, Loss: 0.0177\n",
      "Epoch 150/200, Iteration 247/250, Loss: 0.0131\n",
      "Epoch 150/200, Iteration 248/250, Loss: 0.0162\n",
      "Epoch 150/200, Iteration 249/250, Loss: 0.0098\n",
      "Epoch 150/200, Iteration 250/250, Loss: 0.0110\n",
      "Train Error: \n",
      " Accuracy: 89.58%, Avg loss: 0.005985, MRE: 0.593372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.25%, Avg loss: 0.006019, MRE: 0.850515 \n",
      "\n",
      "Epoch 151/200, Iteration 1/250, Loss: 0.0184\n",
      "Epoch 151/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 3/250, Loss: 0.0251\n",
      "Epoch 151/200, Iteration 4/250, Loss: 0.0104\n",
      "Epoch 151/200, Iteration 5/250, Loss: 0.0244\n",
      "Epoch 151/200, Iteration 6/250, Loss: 0.0216\n",
      "Epoch 151/200, Iteration 7/250, Loss: 0.0102\n",
      "Epoch 151/200, Iteration 8/250, Loss: 0.0124\n",
      "Epoch 151/200, Iteration 9/250, Loss: 0.0139\n",
      "Epoch 151/200, Iteration 10/250, Loss: 0.0108\n",
      "Epoch 151/200, Iteration 11/250, Loss: 0.0124\n",
      "Epoch 151/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 151/200, Iteration 13/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 14/250, Loss: 0.0186\n",
      "Epoch 151/200, Iteration 15/250, Loss: 0.0163\n",
      "Epoch 151/200, Iteration 16/250, Loss: 0.0185\n",
      "Epoch 151/200, Iteration 17/250, Loss: 0.0202\n",
      "Epoch 151/200, Iteration 18/250, Loss: 0.0219\n",
      "Epoch 151/200, Iteration 19/250, Loss: 0.0135\n",
      "Epoch 151/200, Iteration 20/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 21/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 22/250, Loss: 0.0224\n",
      "Epoch 151/200, Iteration 23/250, Loss: 0.0206\n",
      "Epoch 151/200, Iteration 24/250, Loss: 0.0054\n",
      "Epoch 151/200, Iteration 25/250, Loss: 0.0111\n",
      "Epoch 151/200, Iteration 26/250, Loss: 0.0087\n",
      "Epoch 151/200, Iteration 27/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 28/250, Loss: 0.0165\n",
      "Epoch 151/200, Iteration 29/250, Loss: 0.0230\n",
      "Epoch 151/200, Iteration 30/250, Loss: 0.0156\n",
      "Epoch 151/200, Iteration 31/250, Loss: 0.0147\n",
      "Epoch 151/200, Iteration 32/250, Loss: 0.0210\n",
      "Epoch 151/200, Iteration 33/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 34/250, Loss: 0.0153\n",
      "Epoch 151/200, Iteration 35/250, Loss: 0.0070\n",
      "Epoch 151/200, Iteration 36/250, Loss: 0.0142\n",
      "Epoch 151/200, Iteration 37/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 38/250, Loss: 0.0329\n",
      "Epoch 151/200, Iteration 39/250, Loss: 0.0207\n",
      "Epoch 151/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 41/250, Loss: 0.0079\n",
      "Epoch 151/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 151/200, Iteration 43/250, Loss: 0.0126\n",
      "Epoch 151/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 151/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 151/200, Iteration 46/250, Loss: 0.0137\n",
      "Epoch 151/200, Iteration 47/250, Loss: 0.0275\n",
      "Epoch 151/200, Iteration 48/250, Loss: 0.0468\n",
      "Epoch 151/200, Iteration 49/250, Loss: 0.0240\n",
      "Epoch 151/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 151/200, Iteration 51/250, Loss: 0.0307\n",
      "Epoch 151/200, Iteration 52/250, Loss: 0.0336\n",
      "Epoch 151/200, Iteration 53/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 54/250, Loss: 0.0130\n",
      "Epoch 151/200, Iteration 55/250, Loss: 0.0110\n",
      "Epoch 151/200, Iteration 56/250, Loss: 0.0140\n",
      "Epoch 151/200, Iteration 57/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 58/250, Loss: 0.0130\n",
      "Epoch 151/200, Iteration 59/250, Loss: 0.0086\n",
      "Epoch 151/200, Iteration 60/250, Loss: 0.0126\n",
      "Epoch 151/200, Iteration 61/250, Loss: 0.0074\n",
      "Epoch 151/200, Iteration 62/250, Loss: 0.0123\n",
      "Epoch 151/200, Iteration 63/250, Loss: 0.0370\n",
      "Epoch 151/200, Iteration 64/250, Loss: 0.0232\n",
      "Epoch 151/200, Iteration 65/250, Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 67/250, Loss: 0.0090\n",
      "Epoch 151/200, Iteration 68/250, Loss: 0.0219\n",
      "Epoch 151/200, Iteration 69/250, Loss: 0.0303\n",
      "Epoch 151/200, Iteration 70/250, Loss: 0.0139\n",
      "Epoch 151/200, Iteration 71/250, Loss: 0.0176\n",
      "Epoch 151/200, Iteration 72/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 73/250, Loss: 0.0127\n",
      "Epoch 151/200, Iteration 74/250, Loss: 0.0372\n",
      "Epoch 151/200, Iteration 75/250, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 76/250, Loss: 0.0111\n",
      "Epoch 151/200, Iteration 77/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 78/250, Loss: 0.0166\n",
      "Epoch 151/200, Iteration 79/250, Loss: 0.0209\n",
      "Epoch 151/200, Iteration 80/250, Loss: 0.0168\n",
      "Epoch 151/200, Iteration 81/250, Loss: 0.0255\n",
      "Epoch 151/200, Iteration 82/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 151/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 151/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 151/200, Iteration 86/250, Loss: 0.0066\n",
      "Epoch 151/200, Iteration 87/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 88/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 89/250, Loss: 0.0171\n",
      "Epoch 151/200, Iteration 90/250, Loss: 0.0088\n",
      "Epoch 151/200, Iteration 91/250, Loss: 0.0131\n",
      "Epoch 151/200, Iteration 92/250, Loss: 0.0264\n",
      "Epoch 151/200, Iteration 93/250, Loss: 0.0237\n",
      "Epoch 151/200, Iteration 94/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 151/200, Iteration 96/250, Loss: 0.0161\n",
      "Epoch 151/200, Iteration 97/250, Loss: 0.0253\n",
      "Epoch 151/200, Iteration 98/250, Loss: 0.0117\n",
      "Epoch 151/200, Iteration 99/250, Loss: 0.0288\n",
      "Epoch 151/200, Iteration 100/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 101/250, Loss: 0.0172\n",
      "Epoch 151/200, Iteration 102/250, Loss: 0.0121\n",
      "Epoch 151/200, Iteration 103/250, Loss: 0.0194\n",
      "Epoch 151/200, Iteration 104/250, Loss: 0.0090\n",
      "Epoch 151/200, Iteration 105/250, Loss: 0.0144\n",
      "Epoch 151/200, Iteration 106/250, Loss: 0.0166\n",
      "Epoch 151/200, Iteration 107/250, Loss: 0.0318\n",
      "Epoch 151/200, Iteration 108/250, Loss: 0.0249\n",
      "Epoch 151/200, Iteration 109/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 110/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 111/250, Loss: 0.0341\n",
      "Epoch 151/200, Iteration 112/250, Loss: 0.0158\n",
      "Epoch 151/200, Iteration 113/250, Loss: 0.0217\n",
      "Epoch 151/200, Iteration 114/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 115/250, Loss: 0.0122\n",
      "Epoch 151/200, Iteration 116/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 117/250, Loss: 0.0385\n",
      "Epoch 151/200, Iteration 118/250, Loss: 0.0067\n",
      "Epoch 151/200, Iteration 119/250, Loss: 0.0142\n",
      "Epoch 151/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 151/200, Iteration 121/250, Loss: 0.0224\n",
      "Epoch 151/200, Iteration 122/250, Loss: 0.0064\n",
      "Epoch 151/200, Iteration 123/250, Loss: 0.0165\n",
      "Epoch 151/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 151/200, Iteration 125/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 126/250, Loss: 0.0232\n",
      "Epoch 151/200, Iteration 127/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 128/250, Loss: 0.0341\n",
      "Epoch 151/200, Iteration 129/250, Loss: 0.0136\n",
      "Epoch 151/200, Iteration 130/250, Loss: 0.0264\n",
      "Epoch 151/200, Iteration 131/250, Loss: 0.0120\n",
      "Epoch 151/200, Iteration 132/250, Loss: 0.0155\n",
      "Epoch 151/200, Iteration 133/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 134/250, Loss: 0.0250\n",
      "Epoch 151/200, Iteration 135/250, Loss: 0.0137\n",
      "Epoch 151/200, Iteration 136/250, Loss: 0.0107\n",
      "Epoch 151/200, Iteration 137/250, Loss: 0.0207\n",
      "Epoch 151/200, Iteration 138/250, Loss: 0.0226\n",
      "Epoch 151/200, Iteration 139/250, Loss: 0.0220\n",
      "Epoch 151/200, Iteration 140/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 141/250, Loss: 0.0247\n",
      "Epoch 151/200, Iteration 142/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 143/250, Loss: 0.0153\n",
      "Epoch 151/200, Iteration 144/250, Loss: 0.0073\n",
      "Epoch 151/200, Iteration 145/250, Loss: 0.0243\n",
      "Epoch 151/200, Iteration 146/250, Loss: 0.0511\n",
      "Epoch 151/200, Iteration 147/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 148/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 149/250, Loss: 0.0155\n",
      "Epoch 151/200, Iteration 150/250, Loss: 0.0185\n",
      "Epoch 151/200, Iteration 151/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 152/250, Loss: 0.0369\n",
      "Epoch 151/200, Iteration 153/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 154/250, Loss: 0.0075\n",
      "Epoch 151/200, Iteration 155/250, Loss: 0.0152\n",
      "Epoch 151/200, Iteration 156/250, Loss: 0.0277\n",
      "Epoch 151/200, Iteration 157/250, Loss: 0.0079\n",
      "Epoch 151/200, Iteration 158/250, Loss: 0.0269\n",
      "Epoch 151/200, Iteration 159/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 160/250, Loss: 0.0206\n",
      "Epoch 151/200, Iteration 161/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 162/250, Loss: 0.0101\n",
      "Epoch 151/200, Iteration 163/250, Loss: 0.0213\n",
      "Epoch 151/200, Iteration 164/250, Loss: 0.0144\n",
      "Epoch 151/200, Iteration 165/250, Loss: 0.0074\n",
      "Epoch 151/200, Iteration 166/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 167/250, Loss: 0.0129\n",
      "Epoch 151/200, Iteration 168/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 169/250, Loss: 0.0044\n",
      "Epoch 151/200, Iteration 170/250, Loss: 0.0215\n",
      "Epoch 151/200, Iteration 171/250, Loss: 0.0225\n",
      "Epoch 151/200, Iteration 172/250, Loss: 0.0113\n",
      "Epoch 151/200, Iteration 173/250, Loss: 0.0084\n",
      "Epoch 151/200, Iteration 174/250, Loss: 0.0094\n",
      "Epoch 151/200, Iteration 175/250, Loss: 0.0133\n",
      "Epoch 151/200, Iteration 176/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 177/250, Loss: 0.0356\n",
      "Epoch 151/200, Iteration 178/250, Loss: 0.0107\n",
      "Epoch 151/200, Iteration 179/250, Loss: 0.0105\n",
      "Epoch 151/200, Iteration 180/250, Loss: 0.0179\n",
      "Epoch 151/200, Iteration 181/250, Loss: 0.0149\n",
      "Epoch 151/200, Iteration 182/250, Loss: 0.0181\n",
      "Epoch 151/200, Iteration 183/250, Loss: 0.0123\n",
      "Epoch 151/200, Iteration 184/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 185/250, Loss: 0.0393\n",
      "Epoch 151/200, Iteration 186/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 187/250, Loss: 0.0118\n",
      "Epoch 151/200, Iteration 188/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 189/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 190/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 192/250, Loss: 0.0140\n",
      "Epoch 151/200, Iteration 193/250, Loss: 0.0137\n",
      "Epoch 151/200, Iteration 194/250, Loss: 0.0173\n",
      "Epoch 151/200, Iteration 195/250, Loss: 0.0136\n",
      "Epoch 151/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 151/200, Iteration 197/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 151/200, Iteration 199/250, Loss: 0.0132\n",
      "Epoch 151/200, Iteration 200/250, Loss: 0.0288\n",
      "Epoch 151/200, Iteration 201/250, Loss: 0.0175\n",
      "Epoch 151/200, Iteration 202/250, Loss: 0.0094\n",
      "Epoch 151/200, Iteration 203/250, Loss: 0.0236\n",
      "Epoch 151/200, Iteration 204/250, Loss: 0.0097\n",
      "Epoch 151/200, Iteration 205/250, Loss: 0.0212\n",
      "Epoch 151/200, Iteration 206/250, Loss: 0.0143\n",
      "Epoch 151/200, Iteration 207/250, Loss: 0.0110\n",
      "Epoch 151/200, Iteration 208/250, Loss: 0.0122\n",
      "Epoch 151/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 151/200, Iteration 210/250, Loss: 0.0181\n",
      "Epoch 151/200, Iteration 211/250, Loss: 0.0491\n",
      "Epoch 151/200, Iteration 212/250, Loss: 0.0108\n",
      "Epoch 151/200, Iteration 213/250, Loss: 0.0110\n",
      "Epoch 151/200, Iteration 214/250, Loss: 0.0156\n",
      "Epoch 151/200, Iteration 215/250, Loss: 0.0085\n",
      "Epoch 151/200, Iteration 216/250, Loss: 0.0230\n",
      "Epoch 151/200, Iteration 217/250, Loss: 0.0076\n",
      "Epoch 151/200, Iteration 218/250, Loss: 0.0139\n",
      "Epoch 151/200, Iteration 219/250, Loss: 0.0131\n",
      "Epoch 151/200, Iteration 220/250, Loss: 0.0160\n",
      "Epoch 151/200, Iteration 221/250, Loss: 0.0113\n",
      "Epoch 151/200, Iteration 222/250, Loss: 0.0372\n",
      "Epoch 151/200, Iteration 223/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 224/250, Loss: 0.0107\n",
      "Epoch 151/200, Iteration 225/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 226/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 151/200, Iteration 228/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 229/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 230/250, Loss: 0.0151\n",
      "Epoch 151/200, Iteration 231/250, Loss: 0.0177\n",
      "Epoch 151/200, Iteration 232/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 233/250, Loss: 0.0137\n",
      "Epoch 151/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 151/200, Iteration 235/250, Loss: 0.0081\n",
      "Epoch 151/200, Iteration 236/250, Loss: 0.0075\n",
      "Epoch 151/200, Iteration 237/250, Loss: 0.0182\n",
      "Epoch 151/200, Iteration 238/250, Loss: 0.0255\n",
      "Epoch 151/200, Iteration 239/250, Loss: 0.0218\n",
      "Epoch 151/200, Iteration 240/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 241/250, Loss: 0.0144\n",
      "Epoch 151/200, Iteration 242/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 243/250, Loss: 0.0200\n",
      "Epoch 151/200, Iteration 244/250, Loss: 0.0121\n",
      "Epoch 151/200, Iteration 245/250, Loss: 0.0074\n",
      "Epoch 151/200, Iteration 246/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 247/250, Loss: 0.0093\n",
      "Epoch 151/200, Iteration 248/250, Loss: 0.0062\n",
      "Epoch 151/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 151/200, Iteration 250/250, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 86.74%, Avg loss: 0.006691, MRE: 0.593409 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.15%, Avg loss: 0.006779, MRE: 0.862578 \n",
      "\n",
      "Epoch 152/200, Iteration 1/250, Loss: 0.0098\n",
      "Epoch 152/200, Iteration 2/250, Loss: 0.0140\n",
      "Epoch 152/200, Iteration 3/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 4/250, Loss: 0.0146\n",
      "Epoch 152/200, Iteration 5/250, Loss: 0.0184\n",
      "Epoch 152/200, Iteration 6/250, Loss: 0.0299\n",
      "Epoch 152/200, Iteration 7/250, Loss: 0.0124\n",
      "Epoch 152/200, Iteration 8/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 9/250, Loss: 0.0169\n",
      "Epoch 152/200, Iteration 10/250, Loss: 0.0156\n",
      "Epoch 152/200, Iteration 11/250, Loss: 0.0216\n",
      "Epoch 152/200, Iteration 12/250, Loss: 0.0065\n",
      "Epoch 152/200, Iteration 13/250, Loss: 0.0052\n",
      "Epoch 152/200, Iteration 14/250, Loss: 0.0123\n",
      "Epoch 152/200, Iteration 15/250, Loss: 0.0318\n",
      "Epoch 152/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 17/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 18/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 19/250, Loss: 0.0307\n",
      "Epoch 152/200, Iteration 20/250, Loss: 0.0121\n",
      "Epoch 152/200, Iteration 21/250, Loss: 0.0059\n",
      "Epoch 152/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 152/200, Iteration 23/250, Loss: 0.0132\n",
      "Epoch 152/200, Iteration 24/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 25/250, Loss: 0.0192\n",
      "Epoch 152/200, Iteration 26/250, Loss: 0.0072\n",
      "Epoch 152/200, Iteration 27/250, Loss: 0.0098\n",
      "Epoch 152/200, Iteration 28/250, Loss: 0.0094\n",
      "Epoch 152/200, Iteration 29/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 30/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 31/250, Loss: 0.0071\n",
      "Epoch 152/200, Iteration 32/250, Loss: 0.0075\n",
      "Epoch 152/200, Iteration 33/250, Loss: 0.0157\n",
      "Epoch 152/200, Iteration 34/250, Loss: 0.0117\n",
      "Epoch 152/200, Iteration 35/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 36/250, Loss: 0.0141\n",
      "Epoch 152/200, Iteration 37/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 38/250, Loss: 0.0199\n",
      "Epoch 152/200, Iteration 39/250, Loss: 0.0207\n",
      "Epoch 152/200, Iteration 40/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 41/250, Loss: 0.0122\n",
      "Epoch 152/200, Iteration 42/250, Loss: 0.0186\n",
      "Epoch 152/200, Iteration 43/250, Loss: 0.0168\n",
      "Epoch 152/200, Iteration 44/250, Loss: 0.0147\n",
      "Epoch 152/200, Iteration 45/250, Loss: 0.0153\n",
      "Epoch 152/200, Iteration 46/250, Loss: 0.0161\n",
      "Epoch 152/200, Iteration 47/250, Loss: 0.0173\n",
      "Epoch 152/200, Iteration 48/250, Loss: 0.0178\n",
      "Epoch 152/200, Iteration 49/250, Loss: 0.0085\n",
      "Epoch 152/200, Iteration 50/250, Loss: 0.0094\n",
      "Epoch 152/200, Iteration 51/250, Loss: 0.0256\n",
      "Epoch 152/200, Iteration 52/250, Loss: 0.0187\n",
      "Epoch 152/200, Iteration 53/250, Loss: 0.0218\n",
      "Epoch 152/200, Iteration 54/250, Loss: 0.0138\n",
      "Epoch 152/200, Iteration 55/250, Loss: 0.0148\n",
      "Epoch 152/200, Iteration 56/250, Loss: 0.0255\n",
      "Epoch 152/200, Iteration 57/250, Loss: 0.0114\n",
      "Epoch 152/200, Iteration 58/250, Loss: 0.0203\n",
      "Epoch 152/200, Iteration 59/250, Loss: 0.0186\n",
      "Epoch 152/200, Iteration 60/250, Loss: 0.0353\n",
      "Epoch 152/200, Iteration 61/250, Loss: 0.0162\n",
      "Epoch 152/200, Iteration 62/250, Loss: 0.0087\n",
      "Epoch 152/200, Iteration 63/250, Loss: 0.0192\n",
      "Epoch 152/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 152/200, Iteration 65/250, Loss: 0.0078\n",
      "Epoch 152/200, Iteration 66/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 67/250, Loss: 0.0321\n",
      "Epoch 152/200, Iteration 68/250, Loss: 0.0156\n",
      "Epoch 152/200, Iteration 69/250, Loss: 0.0151\n",
      "Epoch 152/200, Iteration 70/250, Loss: 0.0141\n",
      "Epoch 152/200, Iteration 71/250, Loss: 0.0150\n",
      "Epoch 152/200, Iteration 72/250, Loss: 0.0120\n",
      "Epoch 152/200, Iteration 73/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 74/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 152/200, Iteration 77/250, Loss: 0.0173\n",
      "Epoch 152/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 79/250, Loss: 0.0272\n",
      "Epoch 152/200, Iteration 80/250, Loss: 0.0264\n",
      "Epoch 152/200, Iteration 81/250, Loss: 0.0144\n",
      "Epoch 152/200, Iteration 82/250, Loss: 0.0161\n",
      "Epoch 152/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 84/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 85/250, Loss: 0.0189\n",
      "Epoch 152/200, Iteration 86/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 88/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 89/250, Loss: 0.0170\n",
      "Epoch 152/200, Iteration 90/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 91/250, Loss: 0.0143\n",
      "Epoch 152/200, Iteration 92/250, Loss: 0.0113\n",
      "Epoch 152/200, Iteration 93/250, Loss: 0.0259\n",
      "Epoch 152/200, Iteration 94/250, Loss: 0.0099\n",
      "Epoch 152/200, Iteration 95/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 96/250, Loss: 0.0216\n",
      "Epoch 152/200, Iteration 97/250, Loss: 0.0060\n",
      "Epoch 152/200, Iteration 98/250, Loss: 0.0140\n",
      "Epoch 152/200, Iteration 99/250, Loss: 0.0265\n",
      "Epoch 152/200, Iteration 100/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 152/200, Iteration 102/250, Loss: 0.0188\n",
      "Epoch 152/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 152/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 152/200, Iteration 105/250, Loss: 0.0136\n",
      "Epoch 152/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 107/250, Loss: 0.0172\n",
      "Epoch 152/200, Iteration 108/250, Loss: 0.0334\n",
      "Epoch 152/200, Iteration 109/250, Loss: 0.0105\n",
      "Epoch 152/200, Iteration 110/250, Loss: 0.0083\n",
      "Epoch 152/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 152/200, Iteration 112/250, Loss: 0.0097\n",
      "Epoch 152/200, Iteration 113/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 114/250, Loss: 0.0140\n",
      "Epoch 152/200, Iteration 115/250, Loss: 0.0172\n",
      "Epoch 152/200, Iteration 116/250, Loss: 0.0172\n",
      "Epoch 152/200, Iteration 117/250, Loss: 0.0069\n",
      "Epoch 152/200, Iteration 118/250, Loss: 0.0099\n",
      "Epoch 152/200, Iteration 119/250, Loss: 0.0405\n",
      "Epoch 152/200, Iteration 120/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 121/250, Loss: 0.0369\n",
      "Epoch 152/200, Iteration 122/250, Loss: 0.0119\n",
      "Epoch 152/200, Iteration 123/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 124/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 125/250, Loss: 0.0056\n",
      "Epoch 152/200, Iteration 126/250, Loss: 0.0166\n",
      "Epoch 152/200, Iteration 127/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 128/250, Loss: 0.0202\n",
      "Epoch 152/200, Iteration 129/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 130/250, Loss: 0.0140\n",
      "Epoch 152/200, Iteration 131/250, Loss: 0.0201\n",
      "Epoch 152/200, Iteration 132/250, Loss: 0.0196\n",
      "Epoch 152/200, Iteration 133/250, Loss: 0.0320\n",
      "Epoch 152/200, Iteration 134/250, Loss: 0.0326\n",
      "Epoch 152/200, Iteration 135/250, Loss: 0.0138\n",
      "Epoch 152/200, Iteration 136/250, Loss: 0.0372\n",
      "Epoch 152/200, Iteration 137/250, Loss: 0.0246\n",
      "Epoch 152/200, Iteration 138/250, Loss: 0.0186\n",
      "Epoch 152/200, Iteration 139/250, Loss: 0.0232\n",
      "Epoch 152/200, Iteration 140/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 141/250, Loss: 0.0253\n",
      "Epoch 152/200, Iteration 142/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 143/250, Loss: 0.0382\n",
      "Epoch 152/200, Iteration 144/250, Loss: 0.0076\n",
      "Epoch 152/200, Iteration 145/250, Loss: 0.0148\n",
      "Epoch 152/200, Iteration 146/250, Loss: 0.0076\n",
      "Epoch 152/200, Iteration 147/250, Loss: 0.0119\n",
      "Epoch 152/200, Iteration 148/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 149/250, Loss: 0.0316\n",
      "Epoch 152/200, Iteration 150/250, Loss: 0.0129\n",
      "Epoch 152/200, Iteration 151/250, Loss: 0.0120\n",
      "Epoch 152/200, Iteration 152/250, Loss: 0.0186\n",
      "Epoch 152/200, Iteration 153/250, Loss: 0.0273\n",
      "Epoch 152/200, Iteration 154/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 155/250, Loss: 0.0188\n",
      "Epoch 152/200, Iteration 156/250, Loss: 0.0210\n",
      "Epoch 152/200, Iteration 157/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 158/250, Loss: 0.0329\n",
      "Epoch 152/200, Iteration 159/250, Loss: 0.0191\n",
      "Epoch 152/200, Iteration 160/250, Loss: 0.0108\n",
      "Epoch 152/200, Iteration 161/250, Loss: 0.0194\n",
      "Epoch 152/200, Iteration 162/250, Loss: 0.0112\n",
      "Epoch 152/200, Iteration 163/250, Loss: 0.0127\n",
      "Epoch 152/200, Iteration 164/250, Loss: 0.0260\n",
      "Epoch 152/200, Iteration 165/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 166/250, Loss: 0.0088\n",
      "Epoch 152/200, Iteration 167/250, Loss: 0.0101\n",
      "Epoch 152/200, Iteration 168/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 152/200, Iteration 170/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 171/250, Loss: 0.0072\n",
      "Epoch 152/200, Iteration 172/250, Loss: 0.0121\n",
      "Epoch 152/200, Iteration 173/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 152/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 152/200, Iteration 176/250, Loss: 0.0097\n",
      "Epoch 152/200, Iteration 177/250, Loss: 0.0153\n",
      "Epoch 152/200, Iteration 178/250, Loss: 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200, Iteration 179/250, Loss: 0.0324\n",
      "Epoch 152/200, Iteration 180/250, Loss: 0.0132\n",
      "Epoch 152/200, Iteration 181/250, Loss: 0.0167\n",
      "Epoch 152/200, Iteration 182/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 183/250, Loss: 0.0068\n",
      "Epoch 152/200, Iteration 184/250, Loss: 0.0230\n",
      "Epoch 152/200, Iteration 185/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 186/250, Loss: 0.0152\n",
      "Epoch 152/200, Iteration 187/250, Loss: 0.0073\n",
      "Epoch 152/200, Iteration 188/250, Loss: 0.0193\n",
      "Epoch 152/200, Iteration 189/250, Loss: 0.0253\n",
      "Epoch 152/200, Iteration 190/250, Loss: 0.0113\n",
      "Epoch 152/200, Iteration 191/250, Loss: 0.0218\n",
      "Epoch 152/200, Iteration 192/250, Loss: 0.0169\n",
      "Epoch 152/200, Iteration 193/250, Loss: 0.0167\n",
      "Epoch 152/200, Iteration 194/250, Loss: 0.0354\n",
      "Epoch 152/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 152/200, Iteration 196/250, Loss: 0.0146\n",
      "Epoch 152/200, Iteration 197/250, Loss: 0.0265\n",
      "Epoch 152/200, Iteration 198/250, Loss: 0.0073\n",
      "Epoch 152/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 152/200, Iteration 200/250, Loss: 0.0135\n",
      "Epoch 152/200, Iteration 201/250, Loss: 0.0175\n",
      "Epoch 152/200, Iteration 202/250, Loss: 0.0113\n",
      "Epoch 152/200, Iteration 203/250, Loss: 0.0153\n",
      "Epoch 152/200, Iteration 204/250, Loss: 0.0287\n",
      "Epoch 152/200, Iteration 205/250, Loss: 0.0145\n",
      "Epoch 152/200, Iteration 206/250, Loss: 0.0156\n",
      "Epoch 152/200, Iteration 207/250, Loss: 0.0070\n",
      "Epoch 152/200, Iteration 208/250, Loss: 0.0159\n",
      "Epoch 152/200, Iteration 209/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 210/250, Loss: 0.0068\n",
      "Epoch 152/200, Iteration 211/250, Loss: 0.0140\n",
      "Epoch 152/200, Iteration 212/250, Loss: 0.0068\n",
      "Epoch 152/200, Iteration 213/250, Loss: 0.0158\n",
      "Epoch 152/200, Iteration 214/250, Loss: 0.0126\n",
      "Epoch 152/200, Iteration 215/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 216/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 217/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 218/250, Loss: 0.0152\n",
      "Epoch 152/200, Iteration 219/250, Loss: 0.0170\n",
      "Epoch 152/200, Iteration 220/250, Loss: 0.0136\n",
      "Epoch 152/200, Iteration 221/250, Loss: 0.0486\n",
      "Epoch 152/200, Iteration 222/250, Loss: 0.0103\n",
      "Epoch 152/200, Iteration 223/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 224/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 225/250, Loss: 0.0138\n",
      "Epoch 152/200, Iteration 226/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 227/250, Loss: 0.0112\n",
      "Epoch 152/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 152/200, Iteration 229/250, Loss: 0.0136\n",
      "Epoch 152/200, Iteration 230/250, Loss: 0.0115\n",
      "Epoch 152/200, Iteration 231/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 232/250, Loss: 0.0191\n",
      "Epoch 152/200, Iteration 233/250, Loss: 0.0301\n",
      "Epoch 152/200, Iteration 234/250, Loss: 0.0288\n",
      "Epoch 152/200, Iteration 235/250, Loss: 0.0210\n",
      "Epoch 152/200, Iteration 236/250, Loss: 0.0187\n",
      "Epoch 152/200, Iteration 237/250, Loss: 0.0067\n",
      "Epoch 152/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 239/250, Loss: 0.0144\n",
      "Epoch 152/200, Iteration 240/250, Loss: 0.0149\n",
      "Epoch 152/200, Iteration 241/250, Loss: 0.0109\n",
      "Epoch 152/200, Iteration 242/250, Loss: 0.0165\n",
      "Epoch 152/200, Iteration 243/250, Loss: 0.0254\n",
      "Epoch 152/200, Iteration 244/250, Loss: 0.0105\n",
      "Epoch 152/200, Iteration 245/250, Loss: 0.0085\n",
      "Epoch 152/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 152/200, Iteration 247/250, Loss: 0.0288\n",
      "Epoch 152/200, Iteration 248/250, Loss: 0.0086\n",
      "Epoch 152/200, Iteration 249/250, Loss: 0.0188\n",
      "Epoch 152/200, Iteration 250/250, Loss: 0.0138\n",
      "Train Error: \n",
      " Accuracy: 98.05%, Avg loss: 0.008457, MRE: 0.797436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.008293, MRE: 1.363270 \n",
      "\n",
      "Epoch 153/200, Iteration 1/250, Loss: 0.0203\n",
      "Epoch 153/200, Iteration 2/250, Loss: 0.0345\n",
      "Epoch 153/200, Iteration 3/250, Loss: 0.0145\n",
      "Epoch 153/200, Iteration 4/250, Loss: 0.0312\n",
      "Epoch 153/200, Iteration 5/250, Loss: 0.0115\n",
      "Epoch 153/200, Iteration 6/250, Loss: 0.0210\n",
      "Epoch 153/200, Iteration 7/250, Loss: 0.0086\n",
      "Epoch 153/200, Iteration 8/250, Loss: 0.0085\n",
      "Epoch 153/200, Iteration 9/250, Loss: 0.0198\n",
      "Epoch 153/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 153/200, Iteration 11/250, Loss: 0.0102\n",
      "Epoch 153/200, Iteration 12/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 13/250, Loss: 0.0263\n",
      "Epoch 153/200, Iteration 14/250, Loss: 0.0120\n",
      "Epoch 153/200, Iteration 15/250, Loss: 0.0151\n",
      "Epoch 153/200, Iteration 16/250, Loss: 0.0111\n",
      "Epoch 153/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 153/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 153/200, Iteration 19/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 20/250, Loss: 0.0146\n",
      "Epoch 153/200, Iteration 21/250, Loss: 0.0068\n",
      "Epoch 153/200, Iteration 22/250, Loss: 0.0131\n",
      "Epoch 153/200, Iteration 23/250, Loss: 0.0104\n",
      "Epoch 153/200, Iteration 24/250, Loss: 0.0125\n",
      "Epoch 153/200, Iteration 25/250, Loss: 0.0086\n",
      "Epoch 153/200, Iteration 26/250, Loss: 0.0368\n",
      "Epoch 153/200, Iteration 27/250, Loss: 0.0152\n",
      "Epoch 153/200, Iteration 28/250, Loss: 0.0102\n",
      "Epoch 153/200, Iteration 29/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 30/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 31/250, Loss: 0.0081\n",
      "Epoch 153/200, Iteration 32/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 33/250, Loss: 0.0144\n",
      "Epoch 153/200, Iteration 34/250, Loss: 0.0163\n",
      "Epoch 153/200, Iteration 35/250, Loss: 0.0104\n",
      "Epoch 153/200, Iteration 36/250, Loss: 0.0204\n",
      "Epoch 153/200, Iteration 37/250, Loss: 0.0159\n",
      "Epoch 153/200, Iteration 38/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 40/250, Loss: 0.0079\n",
      "Epoch 153/200, Iteration 41/250, Loss: 0.0246\n",
      "Epoch 153/200, Iteration 42/250, Loss: 0.0128\n",
      "Epoch 153/200, Iteration 43/250, Loss: 0.0151\n",
      "Epoch 153/200, Iteration 44/250, Loss: 0.0099\n",
      "Epoch 153/200, Iteration 45/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 46/250, Loss: 0.0109\n",
      "Epoch 153/200, Iteration 47/250, Loss: 0.0215\n",
      "Epoch 153/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 153/200, Iteration 49/250, Loss: 0.0165\n",
      "Epoch 153/200, Iteration 50/250, Loss: 0.0173\n",
      "Epoch 153/200, Iteration 51/250, Loss: 0.0194\n",
      "Epoch 153/200, Iteration 52/250, Loss: 0.0106\n",
      "Epoch 153/200, Iteration 53/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 54/250, Loss: 0.0077\n",
      "Epoch 153/200, Iteration 55/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 56/250, Loss: 0.0336\n",
      "Epoch 153/200, Iteration 57/250, Loss: 0.0148\n",
      "Epoch 153/200, Iteration 58/250, Loss: 0.0142\n",
      "Epoch 153/200, Iteration 59/250, Loss: 0.0162\n",
      "Epoch 153/200, Iteration 60/250, Loss: 0.0425\n",
      "Epoch 153/200, Iteration 61/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 62/250, Loss: 0.0190\n",
      "Epoch 153/200, Iteration 63/250, Loss: 0.0307\n",
      "Epoch 153/200, Iteration 64/250, Loss: 0.0230\n",
      "Epoch 153/200, Iteration 65/250, Loss: 0.0101\n",
      "Epoch 153/200, Iteration 66/250, Loss: 0.0281\n",
      "Epoch 153/200, Iteration 67/250, Loss: 0.0254\n",
      "Epoch 153/200, Iteration 68/250, Loss: 0.0080\n",
      "Epoch 153/200, Iteration 69/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 70/250, Loss: 0.0140\n",
      "Epoch 153/200, Iteration 71/250, Loss: 0.0188\n",
      "Epoch 153/200, Iteration 72/250, Loss: 0.0112\n",
      "Epoch 153/200, Iteration 73/250, Loss: 0.0147\n",
      "Epoch 153/200, Iteration 74/250, Loss: 0.0286\n",
      "Epoch 153/200, Iteration 75/250, Loss: 0.0114\n",
      "Epoch 153/200, Iteration 76/250, Loss: 0.0241\n",
      "Epoch 153/200, Iteration 77/250, Loss: 0.0195\n",
      "Epoch 153/200, Iteration 78/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 79/250, Loss: 0.0170\n",
      "Epoch 153/200, Iteration 80/250, Loss: 0.0233\n",
      "Epoch 153/200, Iteration 81/250, Loss: 0.0141\n",
      "Epoch 153/200, Iteration 82/250, Loss: 0.0236\n",
      "Epoch 153/200, Iteration 83/250, Loss: 0.0154\n",
      "Epoch 153/200, Iteration 84/250, Loss: 0.0082\n",
      "Epoch 153/200, Iteration 85/250, Loss: 0.0096\n",
      "Epoch 153/200, Iteration 86/250, Loss: 0.0077\n",
      "Epoch 153/200, Iteration 87/250, Loss: 0.0220\n",
      "Epoch 153/200, Iteration 88/250, Loss: 0.0125\n",
      "Epoch 153/200, Iteration 89/250, Loss: 0.0075\n",
      "Epoch 153/200, Iteration 90/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 91/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 92/250, Loss: 0.0228\n",
      "Epoch 153/200, Iteration 93/250, Loss: 0.0435\n",
      "Epoch 153/200, Iteration 94/250, Loss: 0.0076\n",
      "Epoch 153/200, Iteration 95/250, Loss: 0.0079\n",
      "Epoch 153/200, Iteration 96/250, Loss: 0.0056\n",
      "Epoch 153/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 153/200, Iteration 98/250, Loss: 0.0249\n",
      "Epoch 153/200, Iteration 99/250, Loss: 0.0529\n",
      "Epoch 153/200, Iteration 100/250, Loss: 0.0301\n",
      "Epoch 153/200, Iteration 101/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 102/250, Loss: 0.0154\n",
      "Epoch 153/200, Iteration 103/250, Loss: 0.0186\n",
      "Epoch 153/200, Iteration 104/250, Loss: 0.0067\n",
      "Epoch 153/200, Iteration 105/250, Loss: 0.0093\n",
      "Epoch 153/200, Iteration 106/250, Loss: 0.0201\n",
      "Epoch 153/200, Iteration 107/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 108/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 109/250, Loss: 0.0108\n",
      "Epoch 153/200, Iteration 110/250, Loss: 0.0117\n",
      "Epoch 153/200, Iteration 111/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 112/250, Loss: 0.0138\n",
      "Epoch 153/200, Iteration 113/250, Loss: 0.0131\n",
      "Epoch 153/200, Iteration 114/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 153/200, Iteration 116/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 153/200, Iteration 118/250, Loss: 0.0124\n",
      "Epoch 153/200, Iteration 119/250, Loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200, Iteration 120/250, Loss: 0.0178\n",
      "Epoch 153/200, Iteration 121/250, Loss: 0.0153\n",
      "Epoch 153/200, Iteration 122/250, Loss: 0.0248\n",
      "Epoch 153/200, Iteration 123/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 124/250, Loss: 0.0146\n",
      "Epoch 153/200, Iteration 125/250, Loss: 0.0269\n",
      "Epoch 153/200, Iteration 126/250, Loss: 0.0243\n",
      "Epoch 153/200, Iteration 127/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 128/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 129/250, Loss: 0.0070\n",
      "Epoch 153/200, Iteration 130/250, Loss: 0.0163\n",
      "Epoch 153/200, Iteration 131/250, Loss: 0.0207\n",
      "Epoch 153/200, Iteration 132/250, Loss: 0.0125\n",
      "Epoch 153/200, Iteration 133/250, Loss: 0.0298\n",
      "Epoch 153/200, Iteration 134/250, Loss: 0.0109\n",
      "Epoch 153/200, Iteration 135/250, Loss: 0.0096\n",
      "Epoch 153/200, Iteration 136/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 137/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 138/250, Loss: 0.0347\n",
      "Epoch 153/200, Iteration 139/250, Loss: 0.0231\n",
      "Epoch 153/200, Iteration 140/250, Loss: 0.0152\n",
      "Epoch 153/200, Iteration 141/250, Loss: 0.0228\n",
      "Epoch 153/200, Iteration 142/250, Loss: 0.0172\n",
      "Epoch 153/200, Iteration 143/250, Loss: 0.0094\n",
      "Epoch 153/200, Iteration 144/250, Loss: 0.0074\n",
      "Epoch 153/200, Iteration 145/250, Loss: 0.0170\n",
      "Epoch 153/200, Iteration 146/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 147/250, Loss: 0.0190\n",
      "Epoch 153/200, Iteration 148/250, Loss: 0.0112\n",
      "Epoch 153/200, Iteration 149/250, Loss: 0.0257\n",
      "Epoch 153/200, Iteration 150/250, Loss: 0.0164\n",
      "Epoch 153/200, Iteration 151/250, Loss: 0.0085\n",
      "Epoch 153/200, Iteration 152/250, Loss: 0.0077\n",
      "Epoch 153/200, Iteration 153/250, Loss: 0.0388\n",
      "Epoch 153/200, Iteration 154/250, Loss: 0.0265\n",
      "Epoch 153/200, Iteration 155/250, Loss: 0.0215\n",
      "Epoch 153/200, Iteration 156/250, Loss: 0.0218\n",
      "Epoch 153/200, Iteration 157/250, Loss: 0.0096\n",
      "Epoch 153/200, Iteration 158/250, Loss: 0.0165\n",
      "Epoch 153/200, Iteration 159/250, Loss: 0.0072\n",
      "Epoch 153/200, Iteration 160/250, Loss: 0.0099\n",
      "Epoch 153/200, Iteration 161/250, Loss: 0.0165\n",
      "Epoch 153/200, Iteration 162/250, Loss: 0.0173\n",
      "Epoch 153/200, Iteration 163/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 164/250, Loss: 0.0141\n",
      "Epoch 153/200, Iteration 165/250, Loss: 0.0121\n",
      "Epoch 153/200, Iteration 166/250, Loss: 0.0096\n",
      "Epoch 153/200, Iteration 167/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 168/250, Loss: 0.0146\n",
      "Epoch 153/200, Iteration 169/250, Loss: 0.0228\n",
      "Epoch 153/200, Iteration 170/250, Loss: 0.0150\n",
      "Epoch 153/200, Iteration 171/250, Loss: 0.0127\n",
      "Epoch 153/200, Iteration 172/250, Loss: 0.0216\n",
      "Epoch 153/200, Iteration 173/250, Loss: 0.0193\n",
      "Epoch 153/200, Iteration 174/250, Loss: 0.0301\n",
      "Epoch 153/200, Iteration 175/250, Loss: 0.0151\n",
      "Epoch 153/200, Iteration 176/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 177/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 178/250, Loss: 0.0138\n",
      "Epoch 153/200, Iteration 179/250, Loss: 0.0295\n",
      "Epoch 153/200, Iteration 180/250, Loss: 0.0091\n",
      "Epoch 153/200, Iteration 181/250, Loss: 0.0257\n",
      "Epoch 153/200, Iteration 182/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 183/250, Loss: 0.0169\n",
      "Epoch 153/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 153/200, Iteration 185/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 186/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 187/250, Loss: 0.0387\n",
      "Epoch 153/200, Iteration 188/250, Loss: 0.0075\n",
      "Epoch 153/200, Iteration 189/250, Loss: 0.0286\n",
      "Epoch 153/200, Iteration 190/250, Loss: 0.0099\n",
      "Epoch 153/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 192/250, Loss: 0.0273\n",
      "Epoch 153/200, Iteration 193/250, Loss: 0.0119\n",
      "Epoch 153/200, Iteration 194/250, Loss: 0.0260\n",
      "Epoch 153/200, Iteration 195/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 196/250, Loss: 0.0075\n",
      "Epoch 153/200, Iteration 197/250, Loss: 0.0148\n",
      "Epoch 153/200, Iteration 198/250, Loss: 0.0140\n",
      "Epoch 153/200, Iteration 199/250, Loss: 0.0170\n",
      "Epoch 153/200, Iteration 200/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 201/250, Loss: 0.0076\n",
      "Epoch 153/200, Iteration 202/250, Loss: 0.0128\n",
      "Epoch 153/200, Iteration 203/250, Loss: 0.0076\n",
      "Epoch 153/200, Iteration 204/250, Loss: 0.0187\n",
      "Epoch 153/200, Iteration 205/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 206/250, Loss: 0.0122\n",
      "Epoch 153/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 153/200, Iteration 208/250, Loss: 0.0122\n",
      "Epoch 153/200, Iteration 209/250, Loss: 0.0075\n",
      "Epoch 153/200, Iteration 210/250, Loss: 0.0183\n",
      "Epoch 153/200, Iteration 211/250, Loss: 0.0160\n",
      "Epoch 153/200, Iteration 212/250, Loss: 0.0171\n",
      "Epoch 153/200, Iteration 213/250, Loss: 0.0093\n",
      "Epoch 153/200, Iteration 214/250, Loss: 0.0165\n",
      "Epoch 153/200, Iteration 215/250, Loss: 0.0244\n",
      "Epoch 153/200, Iteration 216/250, Loss: 0.0219\n",
      "Epoch 153/200, Iteration 217/250, Loss: 0.0166\n",
      "Epoch 153/200, Iteration 218/250, Loss: 0.0248\n",
      "Epoch 153/200, Iteration 219/250, Loss: 0.0139\n",
      "Epoch 153/200, Iteration 220/250, Loss: 0.0381\n",
      "Epoch 153/200, Iteration 221/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 222/250, Loss: 0.0118\n",
      "Epoch 153/200, Iteration 223/250, Loss: 0.0093\n",
      "Epoch 153/200, Iteration 224/250, Loss: 0.0322\n",
      "Epoch 153/200, Iteration 225/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 226/250, Loss: 0.0117\n",
      "Epoch 153/200, Iteration 227/250, Loss: 0.0203\n",
      "Epoch 153/200, Iteration 228/250, Loss: 0.0252\n",
      "Epoch 153/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 230/250, Loss: 0.0115\n",
      "Epoch 153/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 232/250, Loss: 0.0064\n",
      "Epoch 153/200, Iteration 233/250, Loss: 0.0480\n",
      "Epoch 153/200, Iteration 234/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 235/250, Loss: 0.0124\n",
      "Epoch 153/200, Iteration 236/250, Loss: 0.0179\n",
      "Epoch 153/200, Iteration 237/250, Loss: 0.0142\n",
      "Epoch 153/200, Iteration 238/250, Loss: 0.0295\n",
      "Epoch 153/200, Iteration 239/250, Loss: 0.0189\n",
      "Epoch 153/200, Iteration 240/250, Loss: 0.0239\n",
      "Epoch 153/200, Iteration 241/250, Loss: 0.0163\n",
      "Epoch 153/200, Iteration 242/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 243/250, Loss: 0.0076\n",
      "Epoch 153/200, Iteration 244/250, Loss: 0.0168\n",
      "Epoch 153/200, Iteration 245/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 246/250, Loss: 0.0104\n",
      "Epoch 153/200, Iteration 247/250, Loss: 0.0062\n",
      "Epoch 153/200, Iteration 248/250, Loss: 0.0173\n",
      "Epoch 153/200, Iteration 249/250, Loss: 0.0229\n",
      "Epoch 153/200, Iteration 250/250, Loss: 0.0186\n",
      "Train Error: \n",
      " Accuracy: 90.26%, Avg loss: 0.006011, MRE: 0.612329 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.75%, Avg loss: 0.006037, MRE: 0.860196 \n",
      "\n",
      "Epoch 154/200, Iteration 1/250, Loss: 0.0086\n",
      "Epoch 154/200, Iteration 2/250, Loss: 0.0182\n",
      "Epoch 154/200, Iteration 3/250, Loss: 0.0083\n",
      "Epoch 154/200, Iteration 4/250, Loss: 0.0115\n",
      "Epoch 154/200, Iteration 5/250, Loss: 0.0219\n",
      "Epoch 154/200, Iteration 6/250, Loss: 0.0198\n",
      "Epoch 154/200, Iteration 7/250, Loss: 0.0088\n",
      "Epoch 154/200, Iteration 8/250, Loss: 0.0152\n",
      "Epoch 154/200, Iteration 9/250, Loss: 0.0105\n",
      "Epoch 154/200, Iteration 10/250, Loss: 0.0145\n",
      "Epoch 154/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 12/250, Loss: 0.0246\n",
      "Epoch 154/200, Iteration 13/250, Loss: 0.0076\n",
      "Epoch 154/200, Iteration 14/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 15/250, Loss: 0.0262\n",
      "Epoch 154/200, Iteration 16/250, Loss: 0.0143\n",
      "Epoch 154/200, Iteration 17/250, Loss: 0.0107\n",
      "Epoch 154/200, Iteration 18/250, Loss: 0.0138\n",
      "Epoch 154/200, Iteration 19/250, Loss: 0.0271\n",
      "Epoch 154/200, Iteration 20/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 21/250, Loss: 0.0188\n",
      "Epoch 154/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 154/200, Iteration 23/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 24/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 25/250, Loss: 0.0112\n",
      "Epoch 154/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 154/200, Iteration 27/250, Loss: 0.0170\n",
      "Epoch 154/200, Iteration 28/250, Loss: 0.0113\n",
      "Epoch 154/200, Iteration 29/250, Loss: 0.0292\n",
      "Epoch 154/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 154/200, Iteration 31/250, Loss: 0.0153\n",
      "Epoch 154/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 33/250, Loss: 0.0088\n",
      "Epoch 154/200, Iteration 34/250, Loss: 0.0195\n",
      "Epoch 154/200, Iteration 35/250, Loss: 0.0086\n",
      "Epoch 154/200, Iteration 36/250, Loss: 0.0270\n",
      "Epoch 154/200, Iteration 37/250, Loss: 0.0184\n",
      "Epoch 154/200, Iteration 38/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 39/250, Loss: 0.0192\n",
      "Epoch 154/200, Iteration 40/250, Loss: 0.0337\n",
      "Epoch 154/200, Iteration 41/250, Loss: 0.0250\n",
      "Epoch 154/200, Iteration 42/250, Loss: 0.0136\n",
      "Epoch 154/200, Iteration 43/250, Loss: 0.0141\n",
      "Epoch 154/200, Iteration 44/250, Loss: 0.0060\n",
      "Epoch 154/200, Iteration 45/250, Loss: 0.0218\n",
      "Epoch 154/200, Iteration 46/250, Loss: 0.0077\n",
      "Epoch 154/200, Iteration 47/250, Loss: 0.0117\n",
      "Epoch 154/200, Iteration 48/250, Loss: 0.0245\n",
      "Epoch 154/200, Iteration 49/250, Loss: 0.0064\n",
      "Epoch 154/200, Iteration 50/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 51/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 52/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 53/250, Loss: 0.0163\n",
      "Epoch 154/200, Iteration 54/250, Loss: 0.0215\n",
      "Epoch 154/200, Iteration 55/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 56/250, Loss: 0.0312\n",
      "Epoch 154/200, Iteration 57/250, Loss: 0.0057\n",
      "Epoch 154/200, Iteration 58/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 59/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 60/250, Loss: 0.0207\n",
      "Epoch 154/200, Iteration 61/250, Loss: 0.0184\n",
      "Epoch 154/200, Iteration 62/250, Loss: 0.0302\n",
      "Epoch 154/200, Iteration 63/250, Loss: 0.0213\n",
      "Epoch 154/200, Iteration 64/250, Loss: 0.0153\n",
      "Epoch 154/200, Iteration 65/250, Loss: 0.0171\n",
      "Epoch 154/200, Iteration 66/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 67/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 68/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 69/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 70/250, Loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200, Iteration 71/250, Loss: 0.0195\n",
      "Epoch 154/200, Iteration 72/250, Loss: 0.0218\n",
      "Epoch 154/200, Iteration 73/250, Loss: 0.0252\n",
      "Epoch 154/200, Iteration 74/250, Loss: 0.0170\n",
      "Epoch 154/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 76/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 77/250, Loss: 0.0254\n",
      "Epoch 154/200, Iteration 78/250, Loss: 0.0163\n",
      "Epoch 154/200, Iteration 79/250, Loss: 0.0244\n",
      "Epoch 154/200, Iteration 80/250, Loss: 0.0198\n",
      "Epoch 154/200, Iteration 81/250, Loss: 0.0203\n",
      "Epoch 154/200, Iteration 82/250, Loss: 0.0378\n",
      "Epoch 154/200, Iteration 83/250, Loss: 0.0114\n",
      "Epoch 154/200, Iteration 84/250, Loss: 0.0187\n",
      "Epoch 154/200, Iteration 85/250, Loss: 0.0180\n",
      "Epoch 154/200, Iteration 86/250, Loss: 0.0263\n",
      "Epoch 154/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 154/200, Iteration 88/250, Loss: 0.0065\n",
      "Epoch 154/200, Iteration 89/250, Loss: 0.0139\n",
      "Epoch 154/200, Iteration 90/250, Loss: 0.0074\n",
      "Epoch 154/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 92/250, Loss: 0.0121\n",
      "Epoch 154/200, Iteration 93/250, Loss: 0.0121\n",
      "Epoch 154/200, Iteration 94/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 95/250, Loss: 0.0083\n",
      "Epoch 154/200, Iteration 96/250, Loss: 0.0105\n",
      "Epoch 154/200, Iteration 97/250, Loss: 0.0257\n",
      "Epoch 154/200, Iteration 98/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 99/250, Loss: 0.0115\n",
      "Epoch 154/200, Iteration 100/250, Loss: 0.0110\n",
      "Epoch 154/200, Iteration 101/250, Loss: 0.0184\n",
      "Epoch 154/200, Iteration 102/250, Loss: 0.0126\n",
      "Epoch 154/200, Iteration 103/250, Loss: 0.0083\n",
      "Epoch 154/200, Iteration 104/250, Loss: 0.0082\n",
      "Epoch 154/200, Iteration 105/250, Loss: 0.0153\n",
      "Epoch 154/200, Iteration 106/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 107/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 108/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 109/250, Loss: 0.0130\n",
      "Epoch 154/200, Iteration 110/250, Loss: 0.0317\n",
      "Epoch 154/200, Iteration 111/250, Loss: 0.0182\n",
      "Epoch 154/200, Iteration 112/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 113/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 114/250, Loss: 0.0240\n",
      "Epoch 154/200, Iteration 115/250, Loss: 0.0142\n",
      "Epoch 154/200, Iteration 116/250, Loss: 0.0091\n",
      "Epoch 154/200, Iteration 117/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 118/250, Loss: 0.0179\n",
      "Epoch 154/200, Iteration 119/250, Loss: 0.0162\n",
      "Epoch 154/200, Iteration 120/250, Loss: 0.0062\n",
      "Epoch 154/200, Iteration 121/250, Loss: 0.0055\n",
      "Epoch 154/200, Iteration 122/250, Loss: 0.0367\n",
      "Epoch 154/200, Iteration 123/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 124/250, Loss: 0.0278\n",
      "Epoch 154/200, Iteration 125/250, Loss: 0.0102\n",
      "Epoch 154/200, Iteration 126/250, Loss: 0.0132\n",
      "Epoch 154/200, Iteration 127/250, Loss: 0.0113\n",
      "Epoch 154/200, Iteration 128/250, Loss: 0.0083\n",
      "Epoch 154/200, Iteration 129/250, Loss: 0.0066\n",
      "Epoch 154/200, Iteration 130/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 131/250, Loss: 0.0138\n",
      "Epoch 154/200, Iteration 132/250, Loss: 0.0211\n",
      "Epoch 154/200, Iteration 133/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 134/250, Loss: 0.0083\n",
      "Epoch 154/200, Iteration 135/250, Loss: 0.0497\n",
      "Epoch 154/200, Iteration 136/250, Loss: 0.0067\n",
      "Epoch 154/200, Iteration 137/250, Loss: 0.0288\n",
      "Epoch 154/200, Iteration 138/250, Loss: 0.0221\n",
      "Epoch 154/200, Iteration 139/250, Loss: 0.0161\n",
      "Epoch 154/200, Iteration 140/250, Loss: 0.0119\n",
      "Epoch 154/200, Iteration 141/250, Loss: 0.0297\n",
      "Epoch 154/200, Iteration 142/250, Loss: 0.0094\n",
      "Epoch 154/200, Iteration 143/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 144/250, Loss: 0.0077\n",
      "Epoch 154/200, Iteration 145/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 146/250, Loss: 0.0217\n",
      "Epoch 154/200, Iteration 147/250, Loss: 0.0087\n",
      "Epoch 154/200, Iteration 148/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 149/250, Loss: 0.0187\n",
      "Epoch 154/200, Iteration 150/250, Loss: 0.0158\n",
      "Epoch 154/200, Iteration 151/250, Loss: 0.0418\n",
      "Epoch 154/200, Iteration 152/250, Loss: 0.0061\n",
      "Epoch 154/200, Iteration 153/250, Loss: 0.0066\n",
      "Epoch 154/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 154/200, Iteration 155/250, Loss: 0.0185\n",
      "Epoch 154/200, Iteration 156/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 157/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 158/250, Loss: 0.0171\n",
      "Epoch 154/200, Iteration 159/250, Loss: 0.0129\n",
      "Epoch 154/200, Iteration 160/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 161/250, Loss: 0.0171\n",
      "Epoch 154/200, Iteration 162/250, Loss: 0.0183\n",
      "Epoch 154/200, Iteration 163/250, Loss: 0.0276\n",
      "Epoch 154/200, Iteration 164/250, Loss: 0.0104\n",
      "Epoch 154/200, Iteration 165/250, Loss: 0.0091\n",
      "Epoch 154/200, Iteration 166/250, Loss: 0.0233\n",
      "Epoch 154/200, Iteration 167/250, Loss: 0.0153\n",
      "Epoch 154/200, Iteration 168/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 169/250, Loss: 0.0192\n",
      "Epoch 154/200, Iteration 170/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 171/250, Loss: 0.0313\n",
      "Epoch 154/200, Iteration 172/250, Loss: 0.0211\n",
      "Epoch 154/200, Iteration 173/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 174/250, Loss: 0.0082\n",
      "Epoch 154/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 154/200, Iteration 176/250, Loss: 0.0158\n",
      "Epoch 154/200, Iteration 177/250, Loss: 0.0162\n",
      "Epoch 154/200, Iteration 178/250, Loss: 0.0274\n",
      "Epoch 154/200, Iteration 179/250, Loss: 0.0209\n",
      "Epoch 154/200, Iteration 180/250, Loss: 0.0185\n",
      "Epoch 154/200, Iteration 181/250, Loss: 0.0197\n",
      "Epoch 154/200, Iteration 182/250, Loss: 0.0160\n",
      "Epoch 154/200, Iteration 183/250, Loss: 0.0164\n",
      "Epoch 154/200, Iteration 184/250, Loss: 0.0147\n",
      "Epoch 154/200, Iteration 185/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 186/250, Loss: 0.0076\n",
      "Epoch 154/200, Iteration 187/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 188/250, Loss: 0.0214\n",
      "Epoch 154/200, Iteration 189/250, Loss: 0.0194\n",
      "Epoch 154/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 191/250, Loss: 0.0119\n",
      "Epoch 154/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 193/250, Loss: 0.0177\n",
      "Epoch 154/200, Iteration 194/250, Loss: 0.0209\n",
      "Epoch 154/200, Iteration 195/250, Loss: 0.0391\n",
      "Epoch 154/200, Iteration 196/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 197/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 198/250, Loss: 0.0189\n",
      "Epoch 154/200, Iteration 199/250, Loss: 0.0074\n",
      "Epoch 154/200, Iteration 200/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 201/250, Loss: 0.0195\n",
      "Epoch 154/200, Iteration 202/250, Loss: 0.0102\n",
      "Epoch 154/200, Iteration 203/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 204/250, Loss: 0.0120\n",
      "Epoch 154/200, Iteration 205/250, Loss: 0.0071\n",
      "Epoch 154/200, Iteration 206/250, Loss: 0.0185\n",
      "Epoch 154/200, Iteration 207/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 208/250, Loss: 0.0183\n",
      "Epoch 154/200, Iteration 209/250, Loss: 0.0257\n",
      "Epoch 154/200, Iteration 210/250, Loss: 0.0082\n",
      "Epoch 154/200, Iteration 211/250, Loss: 0.0369\n",
      "Epoch 154/200, Iteration 212/250, Loss: 0.0161\n",
      "Epoch 154/200, Iteration 213/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 214/250, Loss: 0.0064\n",
      "Epoch 154/200, Iteration 215/250, Loss: 0.0136\n",
      "Epoch 154/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 217/250, Loss: 0.0318\n",
      "Epoch 154/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 154/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 220/250, Loss: 0.0073\n",
      "Epoch 154/200, Iteration 221/250, Loss: 0.0110\n",
      "Epoch 154/200, Iteration 222/250, Loss: 0.0346\n",
      "Epoch 154/200, Iteration 223/250, Loss: 0.0257\n",
      "Epoch 154/200, Iteration 224/250, Loss: 0.0091\n",
      "Epoch 154/200, Iteration 225/250, Loss: 0.0113\n",
      "Epoch 154/200, Iteration 226/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 227/250, Loss: 0.0107\n",
      "Epoch 154/200, Iteration 228/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 229/250, Loss: 0.0197\n",
      "Epoch 154/200, Iteration 230/250, Loss: 0.0148\n",
      "Epoch 154/200, Iteration 231/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 232/250, Loss: 0.0213\n",
      "Epoch 154/200, Iteration 233/250, Loss: 0.0072\n",
      "Epoch 154/200, Iteration 234/250, Loss: 0.0151\n",
      "Epoch 154/200, Iteration 235/250, Loss: 0.0092\n",
      "Epoch 154/200, Iteration 236/250, Loss: 0.0169\n",
      "Epoch 154/200, Iteration 237/250, Loss: 0.0167\n",
      "Epoch 154/200, Iteration 238/250, Loss: 0.0225\n",
      "Epoch 154/200, Iteration 239/250, Loss: 0.0065\n",
      "Epoch 154/200, Iteration 240/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 241/250, Loss: 0.0166\n",
      "Epoch 154/200, Iteration 242/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 243/250, Loss: 0.0228\n",
      "Epoch 154/200, Iteration 244/250, Loss: 0.0242\n",
      "Epoch 154/200, Iteration 245/250, Loss: 0.0064\n",
      "Epoch 154/200, Iteration 246/250, Loss: 0.0196\n",
      "Epoch 154/200, Iteration 247/250, Loss: 0.0165\n",
      "Epoch 154/200, Iteration 248/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 249/250, Loss: 0.0220\n",
      "Epoch 154/200, Iteration 250/250, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.93%, Avg loss: 0.005869, MRE: 0.629646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.85%, Avg loss: 0.005879, MRE: 1.059486 \n",
      "\n",
      "Epoch 155/200, Iteration 1/250, Loss: 0.0139\n",
      "Epoch 155/200, Iteration 2/250, Loss: 0.0128\n",
      "Epoch 155/200, Iteration 3/250, Loss: 0.0264\n",
      "Epoch 155/200, Iteration 4/250, Loss: 0.0111\n",
      "Epoch 155/200, Iteration 5/250, Loss: 0.0111\n",
      "Epoch 155/200, Iteration 6/250, Loss: 0.0062\n",
      "Epoch 155/200, Iteration 7/250, Loss: 0.0320\n",
      "Epoch 155/200, Iteration 8/250, Loss: 0.0155\n",
      "Epoch 155/200, Iteration 9/250, Loss: 0.0260\n",
      "Epoch 155/200, Iteration 10/250, Loss: 0.0243\n",
      "Epoch 155/200, Iteration 11/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 12/250, Loss: 0.0295\n",
      "Epoch 155/200, Iteration 13/250, Loss: 0.0135\n",
      "Epoch 155/200, Iteration 14/250, Loss: 0.0090\n",
      "Epoch 155/200, Iteration 15/250, Loss: 0.0118\n",
      "Epoch 155/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 155/200, Iteration 17/250, Loss: 0.0119\n",
      "Epoch 155/200, Iteration 18/250, Loss: 0.0163\n",
      "Epoch 155/200, Iteration 19/250, Loss: 0.0081\n",
      "Epoch 155/200, Iteration 20/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 21/250, Loss: 0.0451\n",
      "Epoch 155/200, Iteration 22/250, Loss: 0.0163\n",
      "Epoch 155/200, Iteration 23/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 24/250, Loss: 0.0257\n",
      "Epoch 155/200, Iteration 25/250, Loss: 0.0132\n",
      "Epoch 155/200, Iteration 26/250, Loss: 0.0073\n",
      "Epoch 155/200, Iteration 27/250, Loss: 0.0241\n",
      "Epoch 155/200, Iteration 28/250, Loss: 0.0110\n",
      "Epoch 155/200, Iteration 29/250, Loss: 0.0327\n",
      "Epoch 155/200, Iteration 30/250, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 31/250, Loss: 0.0341\n",
      "Epoch 155/200, Iteration 32/250, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 33/250, Loss: 0.0289\n",
      "Epoch 155/200, Iteration 34/250, Loss: 0.0229\n",
      "Epoch 155/200, Iteration 35/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 36/250, Loss: 0.0249\n",
      "Epoch 155/200, Iteration 37/250, Loss: 0.0317\n",
      "Epoch 155/200, Iteration 38/250, Loss: 0.0099\n",
      "Epoch 155/200, Iteration 39/250, Loss: 0.0246\n",
      "Epoch 155/200, Iteration 40/250, Loss: 0.0081\n",
      "Epoch 155/200, Iteration 41/250, Loss: 0.0130\n",
      "Epoch 155/200, Iteration 42/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 43/250, Loss: 0.0239\n",
      "Epoch 155/200, Iteration 44/250, Loss: 0.0221\n",
      "Epoch 155/200, Iteration 45/250, Loss: 0.0112\n",
      "Epoch 155/200, Iteration 46/250, Loss: 0.0255\n",
      "Epoch 155/200, Iteration 47/250, Loss: 0.0223\n",
      "Epoch 155/200, Iteration 48/250, Loss: 0.0114\n",
      "Epoch 155/200, Iteration 49/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 50/250, Loss: 0.0218\n",
      "Epoch 155/200, Iteration 51/250, Loss: 0.0181\n",
      "Epoch 155/200, Iteration 52/250, Loss: 0.0178\n",
      "Epoch 155/200, Iteration 53/250, Loss: 0.0185\n",
      "Epoch 155/200, Iteration 54/250, Loss: 0.0081\n",
      "Epoch 155/200, Iteration 55/250, Loss: 0.0223\n",
      "Epoch 155/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 57/250, Loss: 0.0207\n",
      "Epoch 155/200, Iteration 58/250, Loss: 0.0232\n",
      "Epoch 155/200, Iteration 59/250, Loss: 0.0158\n",
      "Epoch 155/200, Iteration 60/250, Loss: 0.0236\n",
      "Epoch 155/200, Iteration 61/250, Loss: 0.0145\n",
      "Epoch 155/200, Iteration 62/250, Loss: 0.0243\n",
      "Epoch 155/200, Iteration 63/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 64/250, Loss: 0.0129\n",
      "Epoch 155/200, Iteration 65/250, Loss: 0.0210\n",
      "Epoch 155/200, Iteration 66/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 67/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 68/250, Loss: 0.0221\n",
      "Epoch 155/200, Iteration 69/250, Loss: 0.0204\n",
      "Epoch 155/200, Iteration 70/250, Loss: 0.0115\n",
      "Epoch 155/200, Iteration 71/250, Loss: 0.0191\n",
      "Epoch 155/200, Iteration 72/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 155/200, Iteration 74/250, Loss: 0.0075\n",
      "Epoch 155/200, Iteration 75/250, Loss: 0.0121\n",
      "Epoch 155/200, Iteration 76/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 77/250, Loss: 0.0227\n",
      "Epoch 155/200, Iteration 78/250, Loss: 0.0235\n",
      "Epoch 155/200, Iteration 79/250, Loss: 0.0191\n",
      "Epoch 155/200, Iteration 80/250, Loss: 0.0142\n",
      "Epoch 155/200, Iteration 81/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 82/250, Loss: 0.0160\n",
      "Epoch 155/200, Iteration 83/250, Loss: 0.0121\n",
      "Epoch 155/200, Iteration 84/250, Loss: 0.0225\n",
      "Epoch 155/200, Iteration 85/250, Loss: 0.0140\n",
      "Epoch 155/200, Iteration 86/250, Loss: 0.0221\n",
      "Epoch 155/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 88/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 89/250, Loss: 0.0150\n",
      "Epoch 155/200, Iteration 90/250, Loss: 0.0102\n",
      "Epoch 155/200, Iteration 91/250, Loss: 0.0081\n",
      "Epoch 155/200, Iteration 92/250, Loss: 0.0120\n",
      "Epoch 155/200, Iteration 93/250, Loss: 0.0090\n",
      "Epoch 155/200, Iteration 94/250, Loss: 0.0075\n",
      "Epoch 155/200, Iteration 95/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 96/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 155/200, Iteration 98/250, Loss: 0.0217\n",
      "Epoch 155/200, Iteration 99/250, Loss: 0.0079\n",
      "Epoch 155/200, Iteration 100/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 101/250, Loss: 0.0135\n",
      "Epoch 155/200, Iteration 102/250, Loss: 0.0229\n",
      "Epoch 155/200, Iteration 103/250, Loss: 0.0091\n",
      "Epoch 155/200, Iteration 104/250, Loss: 0.0343\n",
      "Epoch 155/200, Iteration 105/250, Loss: 0.0259\n",
      "Epoch 155/200, Iteration 106/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 107/250, Loss: 0.0177\n",
      "Epoch 155/200, Iteration 108/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 109/250, Loss: 0.0108\n",
      "Epoch 155/200, Iteration 110/250, Loss: 0.0084\n",
      "Epoch 155/200, Iteration 111/250, Loss: 0.0105\n",
      "Epoch 155/200, Iteration 112/250, Loss: 0.0128\n",
      "Epoch 155/200, Iteration 113/250, Loss: 0.0170\n",
      "Epoch 155/200, Iteration 114/250, Loss: 0.0137\n",
      "Epoch 155/200, Iteration 115/250, Loss: 0.0062\n",
      "Epoch 155/200, Iteration 116/250, Loss: 0.0161\n",
      "Epoch 155/200, Iteration 117/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 118/250, Loss: 0.0249\n",
      "Epoch 155/200, Iteration 119/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 120/250, Loss: 0.0140\n",
      "Epoch 155/200, Iteration 121/250, Loss: 0.0342\n",
      "Epoch 155/200, Iteration 122/250, Loss: 0.0108\n",
      "Epoch 155/200, Iteration 123/250, Loss: 0.0300\n",
      "Epoch 155/200, Iteration 124/250, Loss: 0.0109\n",
      "Epoch 155/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 126/250, Loss: 0.0140\n",
      "Epoch 155/200, Iteration 127/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 129/250, Loss: 0.0197\n",
      "Epoch 155/200, Iteration 130/250, Loss: 0.0144\n",
      "Epoch 155/200, Iteration 131/250, Loss: 0.0357\n",
      "Epoch 155/200, Iteration 132/250, Loss: 0.0144\n",
      "Epoch 155/200, Iteration 133/250, Loss: 0.0112\n",
      "Epoch 155/200, Iteration 134/250, Loss: 0.0108\n",
      "Epoch 155/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 137/250, Loss: 0.0203\n",
      "Epoch 155/200, Iteration 138/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 139/250, Loss: 0.0158\n",
      "Epoch 155/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 141/250, Loss: 0.0172\n",
      "Epoch 155/200, Iteration 142/250, Loss: 0.0065\n",
      "Epoch 155/200, Iteration 143/250, Loss: 0.0149\n",
      "Epoch 155/200, Iteration 144/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 145/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 147/250, Loss: 0.0227\n",
      "Epoch 155/200, Iteration 148/250, Loss: 0.0129\n",
      "Epoch 155/200, Iteration 149/250, Loss: 0.0279\n",
      "Epoch 155/200, Iteration 150/250, Loss: 0.0224\n",
      "Epoch 155/200, Iteration 151/250, Loss: 0.0318\n",
      "Epoch 155/200, Iteration 152/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 153/250, Loss: 0.0179\n",
      "Epoch 155/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 155/200, Iteration 155/250, Loss: 0.0118\n",
      "Epoch 155/200, Iteration 156/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 157/250, Loss: 0.0103\n",
      "Epoch 155/200, Iteration 158/250, Loss: 0.0313\n",
      "Epoch 155/200, Iteration 159/250, Loss: 0.0159\n",
      "Epoch 155/200, Iteration 160/250, Loss: 0.0139\n",
      "Epoch 155/200, Iteration 161/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 162/250, Loss: 0.0205\n",
      "Epoch 155/200, Iteration 163/250, Loss: 0.0086\n",
      "Epoch 155/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 155/200, Iteration 165/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 166/250, Loss: 0.0310\n",
      "Epoch 155/200, Iteration 167/250, Loss: 0.0068\n",
      "Epoch 155/200, Iteration 168/250, Loss: 0.0166\n",
      "Epoch 155/200, Iteration 169/250, Loss: 0.0155\n",
      "Epoch 155/200, Iteration 170/250, Loss: 0.0075\n",
      "Epoch 155/200, Iteration 171/250, Loss: 0.0112\n",
      "Epoch 155/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 155/200, Iteration 173/250, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 174/250, Loss: 0.0309\n",
      "Epoch 155/200, Iteration 175/250, Loss: 0.0157\n",
      "Epoch 155/200, Iteration 176/250, Loss: 0.0063\n",
      "Epoch 155/200, Iteration 177/250, Loss: 0.0114\n",
      "Epoch 155/200, Iteration 178/250, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 179/250, Loss: 0.0090\n",
      "Epoch 155/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 155/200, Iteration 181/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 182/250, Loss: 0.0131\n",
      "Epoch 155/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 155/200, Iteration 184/250, Loss: 0.0260\n",
      "Epoch 155/200, Iteration 185/250, Loss: 0.0125\n",
      "Epoch 155/200, Iteration 186/250, Loss: 0.0115\n",
      "Epoch 155/200, Iteration 187/250, Loss: 0.0215\n",
      "Epoch 155/200, Iteration 188/250, Loss: 0.0212\n",
      "Epoch 155/200, Iteration 189/250, Loss: 0.0300\n",
      "Epoch 155/200, Iteration 190/250, Loss: 0.0107\n",
      "Epoch 155/200, Iteration 191/250, Loss: 0.0086\n",
      "Epoch 155/200, Iteration 192/250, Loss: 0.0126\n",
      "Epoch 155/200, Iteration 193/250, Loss: 0.0182\n",
      "Epoch 155/200, Iteration 194/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 195/250, Loss: 0.0293\n",
      "Epoch 155/200, Iteration 196/250, Loss: 0.0077\n",
      "Epoch 155/200, Iteration 197/250, Loss: 0.0110\n",
      "Epoch 155/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 199/250, Loss: 0.0261\n",
      "Epoch 155/200, Iteration 200/250, Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 202/250, Loss: 0.0131\n",
      "Epoch 155/200, Iteration 203/250, Loss: 0.0311\n",
      "Epoch 155/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 155/200, Iteration 206/250, Loss: 0.0147\n",
      "Epoch 155/200, Iteration 207/250, Loss: 0.0297\n",
      "Epoch 155/200, Iteration 208/250, Loss: 0.0066\n",
      "Epoch 155/200, Iteration 209/250, Loss: 0.0082\n",
      "Epoch 155/200, Iteration 210/250, Loss: 0.0062\n",
      "Epoch 155/200, Iteration 211/250, Loss: 0.0070\n",
      "Epoch 155/200, Iteration 212/250, Loss: 0.0115\n",
      "Epoch 155/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 155/200, Iteration 214/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 216/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 217/250, Loss: 0.0090\n",
      "Epoch 155/200, Iteration 218/250, Loss: 0.0071\n",
      "Epoch 155/200, Iteration 219/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 220/250, Loss: 0.0071\n",
      "Epoch 155/200, Iteration 221/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 222/250, Loss: 0.0135\n",
      "Epoch 155/200, Iteration 223/250, Loss: 0.0099\n",
      "Epoch 155/200, Iteration 224/250, Loss: 0.0106\n",
      "Epoch 155/200, Iteration 225/250, Loss: 0.0119\n",
      "Epoch 155/200, Iteration 226/250, Loss: 0.0132\n",
      "Epoch 155/200, Iteration 227/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 228/250, Loss: 0.0119\n",
      "Epoch 155/200, Iteration 229/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 230/250, Loss: 0.0237\n",
      "Epoch 155/200, Iteration 231/250, Loss: 0.0114\n",
      "Epoch 155/200, Iteration 232/250, Loss: 0.0079\n",
      "Epoch 155/200, Iteration 233/250, Loss: 0.0072\n",
      "Epoch 155/200, Iteration 234/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 235/250, Loss: 0.0180\n",
      "Epoch 155/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 155/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 155/200, Iteration 238/250, Loss: 0.0186\n",
      "Epoch 155/200, Iteration 239/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 240/250, Loss: 0.0102\n",
      "Epoch 155/200, Iteration 241/250, Loss: 0.0122\n",
      "Epoch 155/200, Iteration 242/250, Loss: 0.0185\n",
      "Epoch 155/200, Iteration 243/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 244/250, Loss: 0.0241\n",
      "Epoch 155/200, Iteration 245/250, Loss: 0.0113\n",
      "Epoch 155/200, Iteration 246/250, Loss: 0.0237\n",
      "Epoch 155/200, Iteration 247/250, Loss: 0.0089\n",
      "Epoch 155/200, Iteration 248/250, Loss: 0.0277\n",
      "Epoch 155/200, Iteration 249/250, Loss: 0.0136\n",
      "Epoch 155/200, Iteration 250/250, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 98.05%, Avg loss: 0.007258, MRE: 0.698352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.007166, MRE: 1.247513 \n",
      "\n",
      "Epoch 156/200, Iteration 1/250, Loss: 0.0134\n",
      "Epoch 156/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 156/200, Iteration 3/250, Loss: 0.0305\n",
      "Epoch 156/200, Iteration 4/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 6/250, Loss: 0.0071\n",
      "Epoch 156/200, Iteration 7/250, Loss: 0.0172\n",
      "Epoch 156/200, Iteration 8/250, Loss: 0.0081\n",
      "Epoch 156/200, Iteration 9/250, Loss: 0.0227\n",
      "Epoch 156/200, Iteration 10/250, Loss: 0.0310\n",
      "Epoch 156/200, Iteration 11/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 12/250, Loss: 0.0231\n",
      "Epoch 156/200, Iteration 13/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 14/250, Loss: 0.0192\n",
      "Epoch 156/200, Iteration 15/250, Loss: 0.0338\n",
      "Epoch 156/200, Iteration 16/250, Loss: 0.0070\n",
      "Epoch 156/200, Iteration 17/250, Loss: 0.0317\n",
      "Epoch 156/200, Iteration 18/250, Loss: 0.0163\n",
      "Epoch 156/200, Iteration 19/250, Loss: 0.0142\n",
      "Epoch 156/200, Iteration 20/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 21/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 22/250, Loss: 0.0190\n",
      "Epoch 156/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 156/200, Iteration 24/250, Loss: 0.0078\n",
      "Epoch 156/200, Iteration 25/250, Loss: 0.0211\n",
      "Epoch 156/200, Iteration 26/250, Loss: 0.0154\n",
      "Epoch 156/200, Iteration 27/250, Loss: 0.0254\n",
      "Epoch 156/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 29/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 30/250, Loss: 0.0246\n",
      "Epoch 156/200, Iteration 31/250, Loss: 0.0100\n",
      "Epoch 156/200, Iteration 32/250, Loss: 0.0177\n",
      "Epoch 156/200, Iteration 33/250, Loss: 0.0055\n",
      "Epoch 156/200, Iteration 34/250, Loss: 0.0277\n",
      "Epoch 156/200, Iteration 35/250, Loss: 0.0163\n",
      "Epoch 156/200, Iteration 36/250, Loss: 0.0305\n",
      "Epoch 156/200, Iteration 37/250, Loss: 0.0100\n",
      "Epoch 156/200, Iteration 38/250, Loss: 0.0293\n",
      "Epoch 156/200, Iteration 39/250, Loss: 0.0078\n",
      "Epoch 156/200, Iteration 40/250, Loss: 0.0245\n",
      "Epoch 156/200, Iteration 41/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 156/200, Iteration 43/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 44/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 45/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 46/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 47/250, Loss: 0.0089\n",
      "Epoch 156/200, Iteration 48/250, Loss: 0.0156\n",
      "Epoch 156/200, Iteration 49/250, Loss: 0.0174\n",
      "Epoch 156/200, Iteration 50/250, Loss: 0.0079\n",
      "Epoch 156/200, Iteration 51/250, Loss: 0.0318\n",
      "Epoch 156/200, Iteration 52/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 53/250, Loss: 0.0135\n",
      "Epoch 156/200, Iteration 54/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 55/250, Loss: 0.0264\n",
      "Epoch 156/200, Iteration 56/250, Loss: 0.0067\n",
      "Epoch 156/200, Iteration 57/250, Loss: 0.0051\n",
      "Epoch 156/200, Iteration 58/250, Loss: 0.0076\n",
      "Epoch 156/200, Iteration 59/250, Loss: 0.0244\n",
      "Epoch 156/200, Iteration 60/250, Loss: 0.0100\n",
      "Epoch 156/200, Iteration 61/250, Loss: 0.0142\n",
      "Epoch 156/200, Iteration 62/250, Loss: 0.0144\n",
      "Epoch 156/200, Iteration 63/250, Loss: 0.0136\n",
      "Epoch 156/200, Iteration 64/250, Loss: 0.0105\n",
      "Epoch 156/200, Iteration 65/250, Loss: 0.0189\n",
      "Epoch 156/200, Iteration 66/250, Loss: 0.0104\n",
      "Epoch 156/200, Iteration 67/250, Loss: 0.0089\n",
      "Epoch 156/200, Iteration 68/250, Loss: 0.0167\n",
      "Epoch 156/200, Iteration 69/250, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 70/250, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 71/250, Loss: 0.0155\n",
      "Epoch 156/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 73/250, Loss: 0.0138\n",
      "Epoch 156/200, Iteration 74/250, Loss: 0.0064\n",
      "Epoch 156/200, Iteration 75/250, Loss: 0.0083\n",
      "Epoch 156/200, Iteration 76/250, Loss: 0.0240\n",
      "Epoch 156/200, Iteration 77/250, Loss: 0.0162\n",
      "Epoch 156/200, Iteration 78/250, Loss: 0.0171\n",
      "Epoch 156/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 156/200, Iteration 80/250, Loss: 0.0094\n",
      "Epoch 156/200, Iteration 81/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 82/250, Loss: 0.0079\n",
      "Epoch 156/200, Iteration 83/250, Loss: 0.0227\n",
      "Epoch 156/200, Iteration 84/250, Loss: 0.0069\n",
      "Epoch 156/200, Iteration 85/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 86/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 87/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 88/250, Loss: 0.0414\n",
      "Epoch 156/200, Iteration 89/250, Loss: 0.0160\n",
      "Epoch 156/200, Iteration 90/250, Loss: 0.0193\n",
      "Epoch 156/200, Iteration 91/250, Loss: 0.0083\n",
      "Epoch 156/200, Iteration 92/250, Loss: 0.0168\n",
      "Epoch 156/200, Iteration 93/250, Loss: 0.0148\n",
      "Epoch 156/200, Iteration 94/250, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 95/250, Loss: 0.0267\n",
      "Epoch 156/200, Iteration 96/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 97/250, Loss: 0.0121\n",
      "Epoch 156/200, Iteration 98/250, Loss: 0.0097\n",
      "Epoch 156/200, Iteration 99/250, Loss: 0.0147\n",
      "Epoch 156/200, Iteration 100/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 101/250, Loss: 0.0298\n",
      "Epoch 156/200, Iteration 102/250, Loss: 0.0262\n",
      "Epoch 156/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 104/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 105/250, Loss: 0.0235\n",
      "Epoch 156/200, Iteration 106/250, Loss: 0.0083\n",
      "Epoch 156/200, Iteration 107/250, Loss: 0.0199\n",
      "Epoch 156/200, Iteration 108/250, Loss: 0.0162\n",
      "Epoch 156/200, Iteration 109/250, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 110/250, Loss: 0.0248\n",
      "Epoch 156/200, Iteration 111/250, Loss: 0.0157\n",
      "Epoch 156/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 113/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 114/250, Loss: 0.0165\n",
      "Epoch 156/200, Iteration 115/250, Loss: 0.0106\n",
      "Epoch 156/200, Iteration 116/250, Loss: 0.0172\n",
      "Epoch 156/200, Iteration 117/250, Loss: 0.0130\n",
      "Epoch 156/200, Iteration 118/250, Loss: 0.0261\n",
      "Epoch 156/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 156/200, Iteration 120/250, Loss: 0.0166\n",
      "Epoch 156/200, Iteration 121/250, Loss: 0.0228\n",
      "Epoch 156/200, Iteration 122/250, Loss: 0.0229\n",
      "Epoch 156/200, Iteration 123/250, Loss: 0.0123\n",
      "Epoch 156/200, Iteration 124/250, Loss: 0.0165\n",
      "Epoch 156/200, Iteration 125/250, Loss: 0.0108\n",
      "Epoch 156/200, Iteration 126/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 127/250, Loss: 0.0063\n",
      "Epoch 156/200, Iteration 128/250, Loss: 0.0212\n",
      "Epoch 156/200, Iteration 129/250, Loss: 0.0146\n",
      "Epoch 156/200, Iteration 130/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 131/250, Loss: 0.0102\n",
      "Epoch 156/200, Iteration 132/250, Loss: 0.0139\n",
      "Epoch 156/200, Iteration 133/250, Loss: 0.0106\n",
      "Epoch 156/200, Iteration 134/250, Loss: 0.0158\n",
      "Epoch 156/200, Iteration 135/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 136/250, Loss: 0.0187\n",
      "Epoch 156/200, Iteration 137/250, Loss: 0.0081\n",
      "Epoch 156/200, Iteration 138/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 139/250, Loss: 0.0173\n",
      "Epoch 156/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 156/200, Iteration 141/250, Loss: 0.0061\n",
      "Epoch 156/200, Iteration 142/250, Loss: 0.0067\n",
      "Epoch 156/200, Iteration 143/250, Loss: 0.0099\n",
      "Epoch 156/200, Iteration 144/250, Loss: 0.0230\n",
      "Epoch 156/200, Iteration 145/250, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200, Iteration 146/250, Loss: 0.0187\n",
      "Epoch 156/200, Iteration 147/250, Loss: 0.0131\n",
      "Epoch 156/200, Iteration 148/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 149/250, Loss: 0.0061\n",
      "Epoch 156/200, Iteration 150/250, Loss: 0.0082\n",
      "Epoch 156/200, Iteration 151/250, Loss: 0.0119\n",
      "Epoch 156/200, Iteration 152/250, Loss: 0.0132\n",
      "Epoch 156/200, Iteration 153/250, Loss: 0.0134\n",
      "Epoch 156/200, Iteration 154/250, Loss: 0.0100\n",
      "Epoch 156/200, Iteration 155/250, Loss: 0.0132\n",
      "Epoch 156/200, Iteration 156/250, Loss: 0.0054\n",
      "Epoch 156/200, Iteration 157/250, Loss: 0.0171\n",
      "Epoch 156/200, Iteration 158/250, Loss: 0.0138\n",
      "Epoch 156/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 156/200, Iteration 160/250, Loss: 0.0110\n",
      "Epoch 156/200, Iteration 161/250, Loss: 0.0264\n",
      "Epoch 156/200, Iteration 162/250, Loss: 0.0091\n",
      "Epoch 156/200, Iteration 163/250, Loss: 0.0237\n",
      "Epoch 156/200, Iteration 164/250, Loss: 0.0098\n",
      "Epoch 156/200, Iteration 165/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 166/250, Loss: 0.0196\n",
      "Epoch 156/200, Iteration 167/250, Loss: 0.0198\n",
      "Epoch 156/200, Iteration 168/250, Loss: 0.0083\n",
      "Epoch 156/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 156/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 171/250, Loss: 0.0143\n",
      "Epoch 156/200, Iteration 172/250, Loss: 0.0174\n",
      "Epoch 156/200, Iteration 173/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 174/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 175/250, Loss: 0.0233\n",
      "Epoch 156/200, Iteration 176/250, Loss: 0.0253\n",
      "Epoch 156/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 156/200, Iteration 178/250, Loss: 0.0205\n",
      "Epoch 156/200, Iteration 179/250, Loss: 0.0312\n",
      "Epoch 156/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 156/200, Iteration 181/250, Loss: 0.0062\n",
      "Epoch 156/200, Iteration 182/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 183/250, Loss: 0.0120\n",
      "Epoch 156/200, Iteration 184/250, Loss: 0.0172\n",
      "Epoch 156/200, Iteration 185/250, Loss: 0.0231\n",
      "Epoch 156/200, Iteration 186/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 187/250, Loss: 0.0145\n",
      "Epoch 156/200, Iteration 188/250, Loss: 0.0100\n",
      "Epoch 156/200, Iteration 189/250, Loss: 0.0284\n",
      "Epoch 156/200, Iteration 190/250, Loss: 0.0185\n",
      "Epoch 156/200, Iteration 191/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 192/250, Loss: 0.0157\n",
      "Epoch 156/200, Iteration 193/250, Loss: 0.0127\n",
      "Epoch 156/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 195/250, Loss: 0.0252\n",
      "Epoch 156/200, Iteration 196/250, Loss: 0.0136\n",
      "Epoch 156/200, Iteration 197/250, Loss: 0.0066\n",
      "Epoch 156/200, Iteration 198/250, Loss: 0.0160\n",
      "Epoch 156/200, Iteration 199/250, Loss: 0.0063\n",
      "Epoch 156/200, Iteration 200/250, Loss: 0.0109\n",
      "Epoch 156/200, Iteration 201/250, Loss: 0.0069\n",
      "Epoch 156/200, Iteration 202/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 203/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 204/250, Loss: 0.0160\n",
      "Epoch 156/200, Iteration 205/250, Loss: 0.0130\n",
      "Epoch 156/200, Iteration 206/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 207/250, Loss: 0.0179\n",
      "Epoch 156/200, Iteration 208/250, Loss: 0.0127\n",
      "Epoch 156/200, Iteration 209/250, Loss: 0.0157\n",
      "Epoch 156/200, Iteration 210/250, Loss: 0.0210\n",
      "Epoch 156/200, Iteration 211/250, Loss: 0.0151\n",
      "Epoch 156/200, Iteration 212/250, Loss: 0.0363\n",
      "Epoch 156/200, Iteration 213/250, Loss: 0.0183\n",
      "Epoch 156/200, Iteration 214/250, Loss: 0.0173\n",
      "Epoch 156/200, Iteration 215/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 216/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 217/250, Loss: 0.0094\n",
      "Epoch 156/200, Iteration 218/250, Loss: 0.0221\n",
      "Epoch 156/200, Iteration 219/250, Loss: 0.0184\n",
      "Epoch 156/200, Iteration 220/250, Loss: 0.0216\n",
      "Epoch 156/200, Iteration 221/250, Loss: 0.0269\n",
      "Epoch 156/200, Iteration 222/250, Loss: 0.0078\n",
      "Epoch 156/200, Iteration 223/250, Loss: 0.0183\n",
      "Epoch 156/200, Iteration 224/250, Loss: 0.0161\n",
      "Epoch 156/200, Iteration 225/250, Loss: 0.0088\n",
      "Epoch 156/200, Iteration 226/250, Loss: 0.0058\n",
      "Epoch 156/200, Iteration 227/250, Loss: 0.0140\n",
      "Epoch 156/200, Iteration 228/250, Loss: 0.0091\n",
      "Epoch 156/200, Iteration 229/250, Loss: 0.0070\n",
      "Epoch 156/200, Iteration 230/250, Loss: 0.0194\n",
      "Epoch 156/200, Iteration 231/250, Loss: 0.0296\n",
      "Epoch 156/200, Iteration 232/250, Loss: 0.0092\n",
      "Epoch 156/200, Iteration 233/250, Loss: 0.0088\n",
      "Epoch 156/200, Iteration 234/250, Loss: 0.0336\n",
      "Epoch 156/200, Iteration 235/250, Loss: 0.0077\n",
      "Epoch 156/200, Iteration 236/250, Loss: 0.0092\n",
      "Epoch 156/200, Iteration 237/250, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 238/250, Loss: 0.0278\n",
      "Epoch 156/200, Iteration 239/250, Loss: 0.0099\n",
      "Epoch 156/200, Iteration 240/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 241/250, Loss: 0.0077\n",
      "Epoch 156/200, Iteration 242/250, Loss: 0.0068\n",
      "Epoch 156/200, Iteration 243/250, Loss: 0.0178\n",
      "Epoch 156/200, Iteration 244/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 245/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 246/250, Loss: 0.0137\n",
      "Epoch 156/200, Iteration 247/250, Loss: 0.0081\n",
      "Epoch 156/200, Iteration 248/250, Loss: 0.0245\n",
      "Epoch 156/200, Iteration 249/250, Loss: 0.0082\n",
      "Epoch 156/200, Iteration 250/250, Loss: 0.0150\n",
      "Train Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.007161, MRE: 0.623835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.05%, Avg loss: 0.007228, MRE: 0.890044 \n",
      "\n",
      "Epoch 157/200, Iteration 1/250, Loss: 0.0071\n",
      "Epoch 157/200, Iteration 2/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 3/250, Loss: 0.0197\n",
      "Epoch 157/200, Iteration 4/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 5/250, Loss: 0.0136\n",
      "Epoch 157/200, Iteration 6/250, Loss: 0.0168\n",
      "Epoch 157/200, Iteration 7/250, Loss: 0.0180\n",
      "Epoch 157/200, Iteration 8/250, Loss: 0.0306\n",
      "Epoch 157/200, Iteration 9/250, Loss: 0.0184\n",
      "Epoch 157/200, Iteration 10/250, Loss: 0.0402\n",
      "Epoch 157/200, Iteration 11/250, Loss: 0.0081\n",
      "Epoch 157/200, Iteration 12/250, Loss: 0.0127\n",
      "Epoch 157/200, Iteration 13/250, Loss: 0.0094\n",
      "Epoch 157/200, Iteration 14/250, Loss: 0.0228\n",
      "Epoch 157/200, Iteration 15/250, Loss: 0.0222\n",
      "Epoch 157/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 157/200, Iteration 17/250, Loss: 0.0120\n",
      "Epoch 157/200, Iteration 18/250, Loss: 0.0059\n",
      "Epoch 157/200, Iteration 19/250, Loss: 0.0297\n",
      "Epoch 157/200, Iteration 20/250, Loss: 0.0078\n",
      "Epoch 157/200, Iteration 21/250, Loss: 0.0095\n",
      "Epoch 157/200, Iteration 22/250, Loss: 0.0212\n",
      "Epoch 157/200, Iteration 23/250, Loss: 0.0075\n",
      "Epoch 157/200, Iteration 24/250, Loss: 0.0087\n",
      "Epoch 157/200, Iteration 25/250, Loss: 0.0170\n",
      "Epoch 157/200, Iteration 26/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 27/250, Loss: 0.0095\n",
      "Epoch 157/200, Iteration 28/250, Loss: 0.0061\n",
      "Epoch 157/200, Iteration 29/250, Loss: 0.0085\n",
      "Epoch 157/200, Iteration 30/250, Loss: 0.0262\n",
      "Epoch 157/200, Iteration 31/250, Loss: 0.0207\n",
      "Epoch 157/200, Iteration 32/250, Loss: 0.0171\n",
      "Epoch 157/200, Iteration 33/250, Loss: 0.0114\n",
      "Epoch 157/200, Iteration 34/250, Loss: 0.0142\n",
      "Epoch 157/200, Iteration 35/250, Loss: 0.0153\n",
      "Epoch 157/200, Iteration 36/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 37/250, Loss: 0.0282\n",
      "Epoch 157/200, Iteration 38/250, Loss: 0.0188\n",
      "Epoch 157/200, Iteration 39/250, Loss: 0.0136\n",
      "Epoch 157/200, Iteration 40/250, Loss: 0.0079\n",
      "Epoch 157/200, Iteration 41/250, Loss: 0.0070\n",
      "Epoch 157/200, Iteration 42/250, Loss: 0.0093\n",
      "Epoch 157/200, Iteration 43/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 44/250, Loss: 0.0077\n",
      "Epoch 157/200, Iteration 45/250, Loss: 0.0095\n",
      "Epoch 157/200, Iteration 46/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 47/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 157/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 50/250, Loss: 0.0084\n",
      "Epoch 157/200, Iteration 51/250, Loss: 0.0179\n",
      "Epoch 157/200, Iteration 52/250, Loss: 0.0081\n",
      "Epoch 157/200, Iteration 53/250, Loss: 0.0272\n",
      "Epoch 157/200, Iteration 54/250, Loss: 0.0141\n",
      "Epoch 157/200, Iteration 55/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 56/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 57/250, Loss: 0.0071\n",
      "Epoch 157/200, Iteration 58/250, Loss: 0.0125\n",
      "Epoch 157/200, Iteration 59/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 60/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 61/250, Loss: 0.0118\n",
      "Epoch 157/200, Iteration 62/250, Loss: 0.0109\n",
      "Epoch 157/200, Iteration 63/250, Loss: 0.0156\n",
      "Epoch 157/200, Iteration 64/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 65/250, Loss: 0.0085\n",
      "Epoch 157/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 157/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 157/200, Iteration 68/250, Loss: 0.0114\n",
      "Epoch 157/200, Iteration 69/250, Loss: 0.0163\n",
      "Epoch 157/200, Iteration 70/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 71/250, Loss: 0.0243\n",
      "Epoch 157/200, Iteration 72/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 73/250, Loss: 0.0224\n",
      "Epoch 157/200, Iteration 74/250, Loss: 0.0126\n",
      "Epoch 157/200, Iteration 75/250, Loss: 0.0065\n",
      "Epoch 157/200, Iteration 76/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 77/250, Loss: 0.0122\n",
      "Epoch 157/200, Iteration 78/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 79/250, Loss: 0.0202\n",
      "Epoch 157/200, Iteration 80/250, Loss: 0.0133\n",
      "Epoch 157/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 157/200, Iteration 82/250, Loss: 0.0186\n",
      "Epoch 157/200, Iteration 83/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 84/250, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200, Iteration 85/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 86/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 87/250, Loss: 0.0101\n",
      "Epoch 157/200, Iteration 88/250, Loss: 0.0117\n",
      "Epoch 157/200, Iteration 89/250, Loss: 0.0139\n",
      "Epoch 157/200, Iteration 90/250, Loss: 0.0189\n",
      "Epoch 157/200, Iteration 91/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 92/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 93/250, Loss: 0.0172\n",
      "Epoch 157/200, Iteration 94/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 95/250, Loss: 0.0268\n",
      "Epoch 157/200, Iteration 96/250, Loss: 0.0157\n",
      "Epoch 157/200, Iteration 97/250, Loss: 0.0110\n",
      "Epoch 157/200, Iteration 98/250, Loss: 0.0178\n",
      "Epoch 157/200, Iteration 99/250, Loss: 0.0187\n",
      "Epoch 157/200, Iteration 100/250, Loss: 0.0064\n",
      "Epoch 157/200, Iteration 101/250, Loss: 0.0076\n",
      "Epoch 157/200, Iteration 102/250, Loss: 0.0170\n",
      "Epoch 157/200, Iteration 103/250, Loss: 0.0225\n",
      "Epoch 157/200, Iteration 104/250, Loss: 0.0079\n",
      "Epoch 157/200, Iteration 105/250, Loss: 0.0183\n",
      "Epoch 157/200, Iteration 106/250, Loss: 0.0204\n",
      "Epoch 157/200, Iteration 107/250, Loss: 0.0182\n",
      "Epoch 157/200, Iteration 108/250, Loss: 0.0153\n",
      "Epoch 157/200, Iteration 109/250, Loss: 0.0195\n",
      "Epoch 157/200, Iteration 110/250, Loss: 0.0167\n",
      "Epoch 157/200, Iteration 111/250, Loss: 0.0101\n",
      "Epoch 157/200, Iteration 112/250, Loss: 0.0079\n",
      "Epoch 157/200, Iteration 113/250, Loss: 0.0126\n",
      "Epoch 157/200, Iteration 114/250, Loss: 0.0169\n",
      "Epoch 157/200, Iteration 115/250, Loss: 0.0277\n",
      "Epoch 157/200, Iteration 116/250, Loss: 0.0124\n",
      "Epoch 157/200, Iteration 117/250, Loss: 0.0151\n",
      "Epoch 157/200, Iteration 118/250, Loss: 0.0171\n",
      "Epoch 157/200, Iteration 119/250, Loss: 0.0082\n",
      "Epoch 157/200, Iteration 120/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 157/200, Iteration 122/250, Loss: 0.0070\n",
      "Epoch 157/200, Iteration 123/250, Loss: 0.0066\n",
      "Epoch 157/200, Iteration 124/250, Loss: 0.0159\n",
      "Epoch 157/200, Iteration 125/250, Loss: 0.0287\n",
      "Epoch 157/200, Iteration 126/250, Loss: 0.0136\n",
      "Epoch 157/200, Iteration 127/250, Loss: 0.0125\n",
      "Epoch 157/200, Iteration 128/250, Loss: 0.0194\n",
      "Epoch 157/200, Iteration 129/250, Loss: 0.0198\n",
      "Epoch 157/200, Iteration 130/250, Loss: 0.0115\n",
      "Epoch 157/200, Iteration 131/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 133/250, Loss: 0.0069\n",
      "Epoch 157/200, Iteration 134/250, Loss: 0.0315\n",
      "Epoch 157/200, Iteration 135/250, Loss: 0.0176\n",
      "Epoch 157/200, Iteration 136/250, Loss: 0.0168\n",
      "Epoch 157/200, Iteration 137/250, Loss: 0.0117\n",
      "Epoch 157/200, Iteration 138/250, Loss: 0.0078\n",
      "Epoch 157/200, Iteration 139/250, Loss: 0.0075\n",
      "Epoch 157/200, Iteration 140/250, Loss: 0.0166\n",
      "Epoch 157/200, Iteration 141/250, Loss: 0.0124\n",
      "Epoch 157/200, Iteration 142/250, Loss: 0.0143\n",
      "Epoch 157/200, Iteration 143/250, Loss: 0.0093\n",
      "Epoch 157/200, Iteration 144/250, Loss: 0.0089\n",
      "Epoch 157/200, Iteration 145/250, Loss: 0.0200\n",
      "Epoch 157/200, Iteration 146/250, Loss: 0.0049\n",
      "Epoch 157/200, Iteration 147/250, Loss: 0.0078\n",
      "Epoch 157/200, Iteration 148/250, Loss: 0.0064\n",
      "Epoch 157/200, Iteration 149/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 150/250, Loss: 0.0069\n",
      "Epoch 157/200, Iteration 151/250, Loss: 0.0121\n",
      "Epoch 157/200, Iteration 152/250, Loss: 0.0075\n",
      "Epoch 157/200, Iteration 153/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 154/250, Loss: 0.0210\n",
      "Epoch 157/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 157/200, Iteration 156/250, Loss: 0.0188\n",
      "Epoch 157/200, Iteration 157/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 158/250, Loss: 0.0227\n",
      "Epoch 157/200, Iteration 159/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 161/250, Loss: 0.0240\n",
      "Epoch 157/200, Iteration 162/250, Loss: 0.0220\n",
      "Epoch 157/200, Iteration 163/250, Loss: 0.0094\n",
      "Epoch 157/200, Iteration 164/250, Loss: 0.0414\n",
      "Epoch 157/200, Iteration 165/250, Loss: 0.0111\n",
      "Epoch 157/200, Iteration 166/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 167/250, Loss: 0.0099\n",
      "Epoch 157/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 169/250, Loss: 0.0201\n",
      "Epoch 157/200, Iteration 170/250, Loss: 0.0150\n",
      "Epoch 157/200, Iteration 171/250, Loss: 0.0113\n",
      "Epoch 157/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 157/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 174/250, Loss: 0.0154\n",
      "Epoch 157/200, Iteration 175/250, Loss: 0.0148\n",
      "Epoch 157/200, Iteration 176/250, Loss: 0.0101\n",
      "Epoch 157/200, Iteration 177/250, Loss: 0.0127\n",
      "Epoch 157/200, Iteration 178/250, Loss: 0.0194\n",
      "Epoch 157/200, Iteration 179/250, Loss: 0.0216\n",
      "Epoch 157/200, Iteration 180/250, Loss: 0.0068\n",
      "Epoch 157/200, Iteration 181/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 182/250, Loss: 0.0194\n",
      "Epoch 157/200, Iteration 183/250, Loss: 0.0091\n",
      "Epoch 157/200, Iteration 184/250, Loss: 0.0072\n",
      "Epoch 157/200, Iteration 185/250, Loss: 0.0276\n",
      "Epoch 157/200, Iteration 186/250, Loss: 0.0081\n",
      "Epoch 157/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 157/200, Iteration 188/250, Loss: 0.0066\n",
      "Epoch 157/200, Iteration 189/250, Loss: 0.0082\n",
      "Epoch 157/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 157/200, Iteration 191/250, Loss: 0.0206\n",
      "Epoch 157/200, Iteration 192/250, Loss: 0.0432\n",
      "Epoch 157/200, Iteration 193/250, Loss: 0.0069\n",
      "Epoch 157/200, Iteration 194/250, Loss: 0.0203\n",
      "Epoch 157/200, Iteration 195/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 196/250, Loss: 0.0155\n",
      "Epoch 157/200, Iteration 197/250, Loss: 0.0263\n",
      "Epoch 157/200, Iteration 198/250, Loss: 0.0194\n",
      "Epoch 157/200, Iteration 199/250, Loss: 0.0147\n",
      "Epoch 157/200, Iteration 200/250, Loss: 0.0060\n",
      "Epoch 157/200, Iteration 201/250, Loss: 0.0332\n",
      "Epoch 157/200, Iteration 202/250, Loss: 0.0093\n",
      "Epoch 157/200, Iteration 203/250, Loss: 0.0246\n",
      "Epoch 157/200, Iteration 204/250, Loss: 0.0113\n",
      "Epoch 157/200, Iteration 205/250, Loss: 0.0099\n",
      "Epoch 157/200, Iteration 206/250, Loss: 0.0192\n",
      "Epoch 157/200, Iteration 207/250, Loss: 0.0311\n",
      "Epoch 157/200, Iteration 208/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 209/250, Loss: 0.0100\n",
      "Epoch 157/200, Iteration 210/250, Loss: 0.0155\n",
      "Epoch 157/200, Iteration 211/250, Loss: 0.0191\n",
      "Epoch 157/200, Iteration 212/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 213/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 214/250, Loss: 0.0071\n",
      "Epoch 157/200, Iteration 215/250, Loss: 0.0206\n",
      "Epoch 157/200, Iteration 216/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 217/250, Loss: 0.0200\n",
      "Epoch 157/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 157/200, Iteration 219/250, Loss: 0.0110\n",
      "Epoch 157/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 221/250, Loss: 0.0123\n",
      "Epoch 157/200, Iteration 222/250, Loss: 0.0462\n",
      "Epoch 157/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 157/200, Iteration 224/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 225/250, Loss: 0.0135\n",
      "Epoch 157/200, Iteration 226/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 227/250, Loss: 0.0175\n",
      "Epoch 157/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 157/200, Iteration 229/250, Loss: 0.0253\n",
      "Epoch 157/200, Iteration 230/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 157/200, Iteration 232/250, Loss: 0.0155\n",
      "Epoch 157/200, Iteration 233/250, Loss: 0.0119\n",
      "Epoch 157/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 157/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 236/250, Loss: 0.0125\n",
      "Epoch 157/200, Iteration 237/250, Loss: 0.0249\n",
      "Epoch 157/200, Iteration 238/250, Loss: 0.0166\n",
      "Epoch 157/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 157/200, Iteration 240/250, Loss: 0.0188\n",
      "Epoch 157/200, Iteration 241/250, Loss: 0.0407\n",
      "Epoch 157/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 157/200, Iteration 243/250, Loss: 0.0191\n",
      "Epoch 157/200, Iteration 244/250, Loss: 0.0258\n",
      "Epoch 157/200, Iteration 245/250, Loss: 0.0249\n",
      "Epoch 157/200, Iteration 246/250, Loss: 0.0199\n",
      "Epoch 157/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 157/200, Iteration 248/250, Loss: 0.0160\n",
      "Epoch 157/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 250/250, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 93.03%, Avg loss: 0.006074, MRE: 0.617430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.006144, MRE: 0.958983 \n",
      "\n",
      "Epoch 158/200, Iteration 1/250, Loss: 0.0145\n",
      "Epoch 158/200, Iteration 2/250, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 3/250, Loss: 0.0095\n",
      "Epoch 158/200, Iteration 4/250, Loss: 0.0072\n",
      "Epoch 158/200, Iteration 5/250, Loss: 0.0270\n",
      "Epoch 158/200, Iteration 6/250, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200, Iteration 7/250, Loss: 0.0073\n",
      "Epoch 158/200, Iteration 8/250, Loss: 0.0134\n",
      "Epoch 158/200, Iteration 9/250, Loss: 0.0267\n",
      "Epoch 158/200, Iteration 10/250, Loss: 0.0155\n",
      "Epoch 158/200, Iteration 11/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 12/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 13/250, Loss: 0.0073\n",
      "Epoch 158/200, Iteration 14/250, Loss: 0.0210\n",
      "Epoch 158/200, Iteration 15/250, Loss: 0.0220\n",
      "Epoch 158/200, Iteration 16/250, Loss: 0.0331\n",
      "Epoch 158/200, Iteration 17/250, Loss: 0.0131\n",
      "Epoch 158/200, Iteration 18/250, Loss: 0.0146\n",
      "Epoch 158/200, Iteration 19/250, Loss: 0.0092\n",
      "Epoch 158/200, Iteration 20/250, Loss: 0.0096\n",
      "Epoch 158/200, Iteration 21/250, Loss: 0.0073\n",
      "Epoch 158/200, Iteration 22/250, Loss: 0.0175\n",
      "Epoch 158/200, Iteration 23/250, Loss: 0.0233\n",
      "Epoch 158/200, Iteration 24/250, Loss: 0.0142\n",
      "Epoch 158/200, Iteration 25/250, Loss: 0.0227\n",
      "Epoch 158/200, Iteration 26/250, Loss: 0.0095\n",
      "Epoch 158/200, Iteration 27/250, Loss: 0.0213\n",
      "Epoch 158/200, Iteration 28/250, Loss: 0.0194\n",
      "Epoch 158/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 30/250, Loss: 0.0200\n",
      "Epoch 158/200, Iteration 31/250, Loss: 0.0070\n",
      "Epoch 158/200, Iteration 32/250, Loss: 0.0224\n",
      "Epoch 158/200, Iteration 33/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 34/250, Loss: 0.0091\n",
      "Epoch 158/200, Iteration 35/250, Loss: 0.0086\n",
      "Epoch 158/200, Iteration 36/250, Loss: 0.0098\n",
      "Epoch 158/200, Iteration 37/250, Loss: 0.0118\n",
      "Epoch 158/200, Iteration 38/250, Loss: 0.0086\n",
      "Epoch 158/200, Iteration 39/250, Loss: 0.0219\n",
      "Epoch 158/200, Iteration 40/250, Loss: 0.0347\n",
      "Epoch 158/200, Iteration 41/250, Loss: 0.0296\n",
      "Epoch 158/200, Iteration 42/250, Loss: 0.0191\n",
      "Epoch 158/200, Iteration 43/250, Loss: 0.0104\n",
      "Epoch 158/200, Iteration 44/250, Loss: 0.0076\n",
      "Epoch 158/200, Iteration 45/250, Loss: 0.0138\n",
      "Epoch 158/200, Iteration 46/250, Loss: 0.0070\n",
      "Epoch 158/200, Iteration 47/250, Loss: 0.0102\n",
      "Epoch 158/200, Iteration 48/250, Loss: 0.0479\n",
      "Epoch 158/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 50/250, Loss: 0.0175\n",
      "Epoch 158/200, Iteration 51/250, Loss: 0.0104\n",
      "Epoch 158/200, Iteration 52/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 53/250, Loss: 0.0321\n",
      "Epoch 158/200, Iteration 54/250, Loss: 0.0150\n",
      "Epoch 158/200, Iteration 55/250, Loss: 0.0155\n",
      "Epoch 158/200, Iteration 56/250, Loss: 0.0339\n",
      "Epoch 158/200, Iteration 57/250, Loss: 0.0194\n",
      "Epoch 158/200, Iteration 58/250, Loss: 0.0194\n",
      "Epoch 158/200, Iteration 59/250, Loss: 0.0170\n",
      "Epoch 158/200, Iteration 60/250, Loss: 0.0304\n",
      "Epoch 158/200, Iteration 61/250, Loss: 0.0113\n",
      "Epoch 158/200, Iteration 62/250, Loss: 0.0151\n",
      "Epoch 158/200, Iteration 63/250, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 64/250, Loss: 0.0206\n",
      "Epoch 158/200, Iteration 65/250, Loss: 0.0217\n",
      "Epoch 158/200, Iteration 66/250, Loss: 0.0083\n",
      "Epoch 158/200, Iteration 67/250, Loss: 0.0269\n",
      "Epoch 158/200, Iteration 68/250, Loss: 0.0130\n",
      "Epoch 158/200, Iteration 69/250, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 70/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 71/250, Loss: 0.0209\n",
      "Epoch 158/200, Iteration 72/250, Loss: 0.0146\n",
      "Epoch 158/200, Iteration 73/250, Loss: 0.0075\n",
      "Epoch 158/200, Iteration 74/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 75/250, Loss: 0.0074\n",
      "Epoch 158/200, Iteration 76/250, Loss: 0.0076\n",
      "Epoch 158/200, Iteration 77/250, Loss: 0.0180\n",
      "Epoch 158/200, Iteration 78/250, Loss: 0.0134\n",
      "Epoch 158/200, Iteration 79/250, Loss: 0.0068\n",
      "Epoch 158/200, Iteration 80/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 81/250, Loss: 0.0254\n",
      "Epoch 158/200, Iteration 82/250, Loss: 0.0104\n",
      "Epoch 158/200, Iteration 83/250, Loss: 0.0118\n",
      "Epoch 158/200, Iteration 84/250, Loss: 0.0400\n",
      "Epoch 158/200, Iteration 85/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 86/250, Loss: 0.0178\n",
      "Epoch 158/200, Iteration 87/250, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 88/250, Loss: 0.0133\n",
      "Epoch 158/200, Iteration 89/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 90/250, Loss: 0.0302\n",
      "Epoch 158/200, Iteration 91/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 92/250, Loss: 0.0196\n",
      "Epoch 158/200, Iteration 93/250, Loss: 0.0186\n",
      "Epoch 158/200, Iteration 94/250, Loss: 0.0145\n",
      "Epoch 158/200, Iteration 95/250, Loss: 0.0267\n",
      "Epoch 158/200, Iteration 96/250, Loss: 0.0187\n",
      "Epoch 158/200, Iteration 97/250, Loss: 0.0143\n",
      "Epoch 158/200, Iteration 98/250, Loss: 0.0253\n",
      "Epoch 158/200, Iteration 99/250, Loss: 0.0177\n",
      "Epoch 158/200, Iteration 100/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 101/250, Loss: 0.0270\n",
      "Epoch 158/200, Iteration 102/250, Loss: 0.0218\n",
      "Epoch 158/200, Iteration 103/250, Loss: 0.0227\n",
      "Epoch 158/200, Iteration 104/250, Loss: 0.0097\n",
      "Epoch 158/200, Iteration 105/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 106/250, Loss: 0.0271\n",
      "Epoch 158/200, Iteration 107/250, Loss: 0.0267\n",
      "Epoch 158/200, Iteration 108/250, Loss: 0.0223\n",
      "Epoch 158/200, Iteration 109/250, Loss: 0.0099\n",
      "Epoch 158/200, Iteration 110/250, Loss: 0.0227\n",
      "Epoch 158/200, Iteration 111/250, Loss: 0.0254\n",
      "Epoch 158/200, Iteration 112/250, Loss: 0.0215\n",
      "Epoch 158/200, Iteration 113/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 114/250, Loss: 0.0180\n",
      "Epoch 158/200, Iteration 115/250, Loss: 0.0153\n",
      "Epoch 158/200, Iteration 116/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 117/250, Loss: 0.0212\n",
      "Epoch 158/200, Iteration 118/250, Loss: 0.0217\n",
      "Epoch 158/200, Iteration 119/250, Loss: 0.0193\n",
      "Epoch 158/200, Iteration 120/250, Loss: 0.0349\n",
      "Epoch 158/200, Iteration 121/250, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 122/250, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 123/250, Loss: 0.0279\n",
      "Epoch 158/200, Iteration 124/250, Loss: 0.0334\n",
      "Epoch 158/200, Iteration 125/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 126/250, Loss: 0.0234\n",
      "Epoch 158/200, Iteration 127/250, Loss: 0.0091\n",
      "Epoch 158/200, Iteration 128/250, Loss: 0.0135\n",
      "Epoch 158/200, Iteration 129/250, Loss: 0.0064\n",
      "Epoch 158/200, Iteration 130/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 131/250, Loss: 0.0217\n",
      "Epoch 158/200, Iteration 132/250, Loss: 0.0160\n",
      "Epoch 158/200, Iteration 133/250, Loss: 0.0184\n",
      "Epoch 158/200, Iteration 134/250, Loss: 0.0157\n",
      "Epoch 158/200, Iteration 135/250, Loss: 0.0320\n",
      "Epoch 158/200, Iteration 136/250, Loss: 0.0087\n",
      "Epoch 158/200, Iteration 137/250, Loss: 0.0227\n",
      "Epoch 158/200, Iteration 138/250, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 139/250, Loss: 0.0286\n",
      "Epoch 158/200, Iteration 140/250, Loss: 0.0057\n",
      "Epoch 158/200, Iteration 141/250, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 158/200, Iteration 143/250, Loss: 0.0075\n",
      "Epoch 158/200, Iteration 144/250, Loss: 0.0069\n",
      "Epoch 158/200, Iteration 145/250, Loss: 0.0137\n",
      "Epoch 158/200, Iteration 146/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 147/250, Loss: 0.0073\n",
      "Epoch 158/200, Iteration 148/250, Loss: 0.0113\n",
      "Epoch 158/200, Iteration 149/250, Loss: 0.0160\n",
      "Epoch 158/200, Iteration 150/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 151/250, Loss: 0.0277\n",
      "Epoch 158/200, Iteration 152/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 153/250, Loss: 0.0188\n",
      "Epoch 158/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 155/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 156/250, Loss: 0.0071\n",
      "Epoch 158/200, Iteration 157/250, Loss: 0.0082\n",
      "Epoch 158/200, Iteration 158/250, Loss: 0.0142\n",
      "Epoch 158/200, Iteration 159/250, Loss: 0.0174\n",
      "Epoch 158/200, Iteration 160/250, Loss: 0.0132\n",
      "Epoch 158/200, Iteration 161/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 162/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 163/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 164/250, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 165/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 166/250, Loss: 0.0089\n",
      "Epoch 158/200, Iteration 167/250, Loss: 0.0098\n",
      "Epoch 158/200, Iteration 168/250, Loss: 0.0194\n",
      "Epoch 158/200, Iteration 169/250, Loss: 0.0212\n",
      "Epoch 158/200, Iteration 170/250, Loss: 0.0093\n",
      "Epoch 158/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 158/200, Iteration 172/250, Loss: 0.0278\n",
      "Epoch 158/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 158/200, Iteration 175/250, Loss: 0.0397\n",
      "Epoch 158/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 158/200, Iteration 177/250, Loss: 0.0079\n",
      "Epoch 158/200, Iteration 178/250, Loss: 0.0125\n",
      "Epoch 158/200, Iteration 179/250, Loss: 0.0133\n",
      "Epoch 158/200, Iteration 180/250, Loss: 0.0325\n",
      "Epoch 158/200, Iteration 181/250, Loss: 0.0155\n",
      "Epoch 158/200, Iteration 182/250, Loss: 0.0071\n",
      "Epoch 158/200, Iteration 183/250, Loss: 0.0091\n",
      "Epoch 158/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 158/200, Iteration 185/250, Loss: 0.0093\n",
      "Epoch 158/200, Iteration 186/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 187/250, Loss: 0.0150\n",
      "Epoch 158/200, Iteration 188/250, Loss: 0.0202\n",
      "Epoch 158/200, Iteration 189/250, Loss: 0.0239\n",
      "Epoch 158/200, Iteration 190/250, Loss: 0.0176\n",
      "Epoch 158/200, Iteration 191/250, Loss: 0.0184\n",
      "Epoch 158/200, Iteration 192/250, Loss: 0.0228\n",
      "Epoch 158/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 158/200, Iteration 194/250, Loss: 0.0090\n",
      "Epoch 158/200, Iteration 195/250, Loss: 0.0078\n",
      "Epoch 158/200, Iteration 196/250, Loss: 0.0058\n",
      "Epoch 158/200, Iteration 197/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 198/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 199/250, Loss: 0.0126\n",
      "Epoch 158/200, Iteration 200/250, Loss: 0.0080\n",
      "Epoch 158/200, Iteration 201/250, Loss: 0.0132\n",
      "Epoch 158/200, Iteration 202/250, Loss: 0.0124\n",
      "Epoch 158/200, Iteration 203/250, Loss: 0.0128\n",
      "Epoch 158/200, Iteration 204/250, Loss: 0.0204\n",
      "Epoch 158/200, Iteration 205/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 206/250, Loss: 0.0078\n",
      "Epoch 158/200, Iteration 207/250, Loss: 0.0086\n",
      "Epoch 158/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 158/200, Iteration 209/250, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 210/250, Loss: 0.0263\n",
      "Epoch 158/200, Iteration 211/250, Loss: 0.0346\n",
      "Epoch 158/200, Iteration 212/250, Loss: 0.0142\n",
      "Epoch 158/200, Iteration 213/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 214/250, Loss: 0.0140\n",
      "Epoch 158/200, Iteration 215/250, Loss: 0.0148\n",
      "Epoch 158/200, Iteration 216/250, Loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200, Iteration 217/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 218/250, Loss: 0.0162\n",
      "Epoch 158/200, Iteration 219/250, Loss: 0.0139\n",
      "Epoch 158/200, Iteration 220/250, Loss: 0.0141\n",
      "Epoch 158/200, Iteration 221/250, Loss: 0.0213\n",
      "Epoch 158/200, Iteration 222/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 223/250, Loss: 0.0092\n",
      "Epoch 158/200, Iteration 224/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 225/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 226/250, Loss: 0.0131\n",
      "Epoch 158/200, Iteration 227/250, Loss: 0.0255\n",
      "Epoch 158/200, Iteration 228/250, Loss: 0.0202\n",
      "Epoch 158/200, Iteration 229/250, Loss: 0.0160\n",
      "Epoch 158/200, Iteration 230/250, Loss: 0.0139\n",
      "Epoch 158/200, Iteration 231/250, Loss: 0.0241\n",
      "Epoch 158/200, Iteration 232/250, Loss: 0.0096\n",
      "Epoch 158/200, Iteration 233/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 234/250, Loss: 0.0116\n",
      "Epoch 158/200, Iteration 235/250, Loss: 0.0288\n",
      "Epoch 158/200, Iteration 236/250, Loss: 0.0110\n",
      "Epoch 158/200, Iteration 237/250, Loss: 0.0116\n",
      "Epoch 158/200, Iteration 238/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 239/250, Loss: 0.0324\n",
      "Epoch 158/200, Iteration 240/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 241/250, Loss: 0.0211\n",
      "Epoch 158/200, Iteration 242/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 243/250, Loss: 0.0130\n",
      "Epoch 158/200, Iteration 244/250, Loss: 0.0075\n",
      "Epoch 158/200, Iteration 245/250, Loss: 0.0119\n",
      "Epoch 158/200, Iteration 246/250, Loss: 0.0221\n",
      "Epoch 158/200, Iteration 247/250, Loss: 0.0275\n",
      "Epoch 158/200, Iteration 248/250, Loss: 0.0120\n",
      "Epoch 158/200, Iteration 249/250, Loss: 0.0193\n",
      "Epoch 158/200, Iteration 250/250, Loss: 0.0227\n",
      "Train Error: \n",
      " Accuracy: 97.35%, Avg loss: 0.006158, MRE: 0.621593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.006104, MRE: 1.026506 \n",
      "\n",
      "Epoch 159/200, Iteration 1/250, Loss: 0.0164\n",
      "Epoch 159/200, Iteration 2/250, Loss: 0.0215\n",
      "Epoch 159/200, Iteration 3/250, Loss: 0.0173\n",
      "Epoch 159/200, Iteration 4/250, Loss: 0.0262\n",
      "Epoch 159/200, Iteration 5/250, Loss: 0.0147\n",
      "Epoch 159/200, Iteration 6/250, Loss: 0.0161\n",
      "Epoch 159/200, Iteration 7/250, Loss: 0.0169\n",
      "Epoch 159/200, Iteration 8/250, Loss: 0.0062\n",
      "Epoch 159/200, Iteration 9/250, Loss: 0.0427\n",
      "Epoch 159/200, Iteration 10/250, Loss: 0.0168\n",
      "Epoch 159/200, Iteration 11/250, Loss: 0.0171\n",
      "Epoch 159/200, Iteration 12/250, Loss: 0.0223\n",
      "Epoch 159/200, Iteration 13/250, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 15/250, Loss: 0.0125\n",
      "Epoch 159/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 17/250, Loss: 0.0105\n",
      "Epoch 159/200, Iteration 18/250, Loss: 0.0131\n",
      "Epoch 159/200, Iteration 19/250, Loss: 0.0193\n",
      "Epoch 159/200, Iteration 20/250, Loss: 0.0111\n",
      "Epoch 159/200, Iteration 21/250, Loss: 0.0175\n",
      "Epoch 159/200, Iteration 22/250, Loss: 0.0284\n",
      "Epoch 159/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 159/200, Iteration 25/250, Loss: 0.0182\n",
      "Epoch 159/200, Iteration 26/250, Loss: 0.0050\n",
      "Epoch 159/200, Iteration 27/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 28/250, Loss: 0.0117\n",
      "Epoch 159/200, Iteration 29/250, Loss: 0.0382\n",
      "Epoch 159/200, Iteration 30/250, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 31/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 32/250, Loss: 0.0136\n",
      "Epoch 159/200, Iteration 33/250, Loss: 0.0097\n",
      "Epoch 159/200, Iteration 34/250, Loss: 0.0173\n",
      "Epoch 159/200, Iteration 35/250, Loss: 0.0154\n",
      "Epoch 159/200, Iteration 36/250, Loss: 0.0210\n",
      "Epoch 159/200, Iteration 37/250, Loss: 0.0098\n",
      "Epoch 159/200, Iteration 38/250, Loss: 0.0098\n",
      "Epoch 159/200, Iteration 39/250, Loss: 0.0090\n",
      "Epoch 159/200, Iteration 40/250, Loss: 0.0147\n",
      "Epoch 159/200, Iteration 41/250, Loss: 0.0103\n",
      "Epoch 159/200, Iteration 42/250, Loss: 0.0132\n",
      "Epoch 159/200, Iteration 43/250, Loss: 0.0252\n",
      "Epoch 159/200, Iteration 44/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 45/250, Loss: 0.0123\n",
      "Epoch 159/200, Iteration 46/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 47/250, Loss: 0.0205\n",
      "Epoch 159/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 49/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 50/250, Loss: 0.0156\n",
      "Epoch 159/200, Iteration 51/250, Loss: 0.0274\n",
      "Epoch 159/200, Iteration 52/250, Loss: 0.0061\n",
      "Epoch 159/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 54/250, Loss: 0.0124\n",
      "Epoch 159/200, Iteration 55/250, Loss: 0.0154\n",
      "Epoch 159/200, Iteration 56/250, Loss: 0.0101\n",
      "Epoch 159/200, Iteration 57/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 58/250, Loss: 0.0166\n",
      "Epoch 159/200, Iteration 59/250, Loss: 0.0131\n",
      "Epoch 159/200, Iteration 60/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 61/250, Loss: 0.0120\n",
      "Epoch 159/200, Iteration 62/250, Loss: 0.0217\n",
      "Epoch 159/200, Iteration 63/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 64/250, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 65/250, Loss: 0.0348\n",
      "Epoch 159/200, Iteration 66/250, Loss: 0.0232\n",
      "Epoch 159/200, Iteration 67/250, Loss: 0.0131\n",
      "Epoch 159/200, Iteration 68/250, Loss: 0.0124\n",
      "Epoch 159/200, Iteration 69/250, Loss: 0.0338\n",
      "Epoch 159/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 159/200, Iteration 71/250, Loss: 0.0127\n",
      "Epoch 159/200, Iteration 72/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 73/250, Loss: 0.0073\n",
      "Epoch 159/200, Iteration 74/250, Loss: 0.0322\n",
      "Epoch 159/200, Iteration 75/250, Loss: 0.0134\n",
      "Epoch 159/200, Iteration 76/250, Loss: 0.0262\n",
      "Epoch 159/200, Iteration 77/250, Loss: 0.0079\n",
      "Epoch 159/200, Iteration 78/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 79/250, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 80/250, Loss: 0.0144\n",
      "Epoch 159/200, Iteration 81/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 82/250, Loss: 0.0073\n",
      "Epoch 159/200, Iteration 83/250, Loss: 0.0102\n",
      "Epoch 159/200, Iteration 84/250, Loss: 0.0075\n",
      "Epoch 159/200, Iteration 85/250, Loss: 0.0199\n",
      "Epoch 159/200, Iteration 86/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 87/250, Loss: 0.0256\n",
      "Epoch 159/200, Iteration 88/250, Loss: 0.0113\n",
      "Epoch 159/200, Iteration 89/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 90/250, Loss: 0.0191\n",
      "Epoch 159/200, Iteration 91/250, Loss: 0.0158\n",
      "Epoch 159/200, Iteration 92/250, Loss: 0.0164\n",
      "Epoch 159/200, Iteration 93/250, Loss: 0.0095\n",
      "Epoch 159/200, Iteration 94/250, Loss: 0.0191\n",
      "Epoch 159/200, Iteration 95/250, Loss: 0.0139\n",
      "Epoch 159/200, Iteration 96/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 97/250, Loss: 0.0156\n",
      "Epoch 159/200, Iteration 98/250, Loss: 0.0107\n",
      "Epoch 159/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 159/200, Iteration 100/250, Loss: 0.0199\n",
      "Epoch 159/200, Iteration 101/250, Loss: 0.0183\n",
      "Epoch 159/200, Iteration 102/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 103/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 105/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 106/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 159/200, Iteration 108/250, Loss: 0.0071\n",
      "Epoch 159/200, Iteration 109/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 110/250, Loss: 0.0321\n",
      "Epoch 159/200, Iteration 111/250, Loss: 0.0179\n",
      "Epoch 159/200, Iteration 112/250, Loss: 0.0262\n",
      "Epoch 159/200, Iteration 113/250, Loss: 0.0189\n",
      "Epoch 159/200, Iteration 114/250, Loss: 0.0055\n",
      "Epoch 159/200, Iteration 115/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 116/250, Loss: 0.0070\n",
      "Epoch 159/200, Iteration 117/250, Loss: 0.0244\n",
      "Epoch 159/200, Iteration 118/250, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 119/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 121/250, Loss: 0.0114\n",
      "Epoch 159/200, Iteration 122/250, Loss: 0.0233\n",
      "Epoch 159/200, Iteration 123/250, Loss: 0.0095\n",
      "Epoch 159/200, Iteration 124/250, Loss: 0.0142\n",
      "Epoch 159/200, Iteration 125/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 126/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 127/250, Loss: 0.0160\n",
      "Epoch 159/200, Iteration 128/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 130/250, Loss: 0.0136\n",
      "Epoch 159/200, Iteration 131/250, Loss: 0.0309\n",
      "Epoch 159/200, Iteration 132/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 133/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 134/250, Loss: 0.0077\n",
      "Epoch 159/200, Iteration 135/250, Loss: 0.0083\n",
      "Epoch 159/200, Iteration 136/250, Loss: 0.0239\n",
      "Epoch 159/200, Iteration 137/250, Loss: 0.0199\n",
      "Epoch 159/200, Iteration 138/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 139/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 140/250, Loss: 0.0141\n",
      "Epoch 159/200, Iteration 141/250, Loss: 0.0150\n",
      "Epoch 159/200, Iteration 142/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 143/250, Loss: 0.0169\n",
      "Epoch 159/200, Iteration 144/250, Loss: 0.0067\n",
      "Epoch 159/200, Iteration 145/250, Loss: 0.0094\n",
      "Epoch 159/200, Iteration 146/250, Loss: 0.0136\n",
      "Epoch 159/200, Iteration 147/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 148/250, Loss: 0.0047\n",
      "Epoch 159/200, Iteration 149/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 150/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 151/250, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 152/250, Loss: 0.0200\n",
      "Epoch 159/200, Iteration 153/250, Loss: 0.0127\n",
      "Epoch 159/200, Iteration 154/250, Loss: 0.0209\n",
      "Epoch 159/200, Iteration 155/250, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 156/250, Loss: 0.0270\n",
      "Epoch 159/200, Iteration 157/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 158/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 159/250, Loss: 0.0080\n",
      "Epoch 159/200, Iteration 160/250, Loss: 0.0214\n",
      "Epoch 159/200, Iteration 161/250, Loss: 0.0084\n",
      "Epoch 159/200, Iteration 162/250, Loss: 0.0082\n",
      "Epoch 159/200, Iteration 163/250, Loss: 0.0162\n",
      "Epoch 159/200, Iteration 164/250, Loss: 0.0335\n",
      "Epoch 159/200, Iteration 165/250, Loss: 0.0239\n",
      "Epoch 159/200, Iteration 166/250, Loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200, Iteration 167/250, Loss: 0.0396\n",
      "Epoch 159/200, Iteration 168/250, Loss: 0.0071\n",
      "Epoch 159/200, Iteration 169/250, Loss: 0.0269\n",
      "Epoch 159/200, Iteration 170/250, Loss: 0.0102\n",
      "Epoch 159/200, Iteration 171/250, Loss: 0.0175\n",
      "Epoch 159/200, Iteration 172/250, Loss: 0.0347\n",
      "Epoch 159/200, Iteration 173/250, Loss: 0.0164\n",
      "Epoch 159/200, Iteration 174/250, Loss: 0.0209\n",
      "Epoch 159/200, Iteration 175/250, Loss: 0.0074\n",
      "Epoch 159/200, Iteration 176/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 177/250, Loss: 0.0075\n",
      "Epoch 159/200, Iteration 178/250, Loss: 0.0090\n",
      "Epoch 159/200, Iteration 179/250, Loss: 0.0142\n",
      "Epoch 159/200, Iteration 180/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 181/250, Loss: 0.0139\n",
      "Epoch 159/200, Iteration 182/250, Loss: 0.0089\n",
      "Epoch 159/200, Iteration 183/250, Loss: 0.0304\n",
      "Epoch 159/200, Iteration 184/250, Loss: 0.0219\n",
      "Epoch 159/200, Iteration 185/250, Loss: 0.0084\n",
      "Epoch 159/200, Iteration 186/250, Loss: 0.0254\n",
      "Epoch 159/200, Iteration 187/250, Loss: 0.0174\n",
      "Epoch 159/200, Iteration 188/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 189/250, Loss: 0.0091\n",
      "Epoch 159/200, Iteration 190/250, Loss: 0.0220\n",
      "Epoch 159/200, Iteration 191/250, Loss: 0.0333\n",
      "Epoch 159/200, Iteration 192/250, Loss: 0.0194\n",
      "Epoch 159/200, Iteration 193/250, Loss: 0.0140\n",
      "Epoch 159/200, Iteration 194/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 195/250, Loss: 0.0187\n",
      "Epoch 159/200, Iteration 196/250, Loss: 0.0189\n",
      "Epoch 159/200, Iteration 197/250, Loss: 0.0196\n",
      "Epoch 159/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 199/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 200/250, Loss: 0.0097\n",
      "Epoch 159/200, Iteration 201/250, Loss: 0.0127\n",
      "Epoch 159/200, Iteration 202/250, Loss: 0.0160\n",
      "Epoch 159/200, Iteration 203/250, Loss: 0.0117\n",
      "Epoch 159/200, Iteration 204/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 205/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 206/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 207/250, Loss: 0.0120\n",
      "Epoch 159/200, Iteration 208/250, Loss: 0.0113\n",
      "Epoch 159/200, Iteration 209/250, Loss: 0.0228\n",
      "Epoch 159/200, Iteration 210/250, Loss: 0.0160\n",
      "Epoch 159/200, Iteration 211/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 212/250, Loss: 0.0254\n",
      "Epoch 159/200, Iteration 213/250, Loss: 0.0141\n",
      "Epoch 159/200, Iteration 214/250, Loss: 0.0135\n",
      "Epoch 159/200, Iteration 215/250, Loss: 0.0158\n",
      "Epoch 159/200, Iteration 216/250, Loss: 0.0185\n",
      "Epoch 159/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 218/250, Loss: 0.0089\n",
      "Epoch 159/200, Iteration 219/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 220/250, Loss: 0.0168\n",
      "Epoch 159/200, Iteration 221/250, Loss: 0.0169\n",
      "Epoch 159/200, Iteration 222/250, Loss: 0.0167\n",
      "Epoch 159/200, Iteration 223/250, Loss: 0.0226\n",
      "Epoch 159/200, Iteration 224/250, Loss: 0.0174\n",
      "Epoch 159/200, Iteration 225/250, Loss: 0.0097\n",
      "Epoch 159/200, Iteration 226/250, Loss: 0.0167\n",
      "Epoch 159/200, Iteration 227/250, Loss: 0.0295\n",
      "Epoch 159/200, Iteration 228/250, Loss: 0.0249\n",
      "Epoch 159/200, Iteration 229/250, Loss: 0.0064\n",
      "Epoch 159/200, Iteration 230/250, Loss: 0.0312\n",
      "Epoch 159/200, Iteration 231/250, Loss: 0.0140\n",
      "Epoch 159/200, Iteration 232/250, Loss: 0.0103\n",
      "Epoch 159/200, Iteration 233/250, Loss: 0.0103\n",
      "Epoch 159/200, Iteration 234/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 235/250, Loss: 0.0127\n",
      "Epoch 159/200, Iteration 236/250, Loss: 0.0063\n",
      "Epoch 159/200, Iteration 237/250, Loss: 0.0124\n",
      "Epoch 159/200, Iteration 238/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 239/250, Loss: 0.0102\n",
      "Epoch 159/200, Iteration 240/250, Loss: 0.0104\n",
      "Epoch 159/200, Iteration 241/250, Loss: 0.0144\n",
      "Epoch 159/200, Iteration 242/250, Loss: 0.0074\n",
      "Epoch 159/200, Iteration 243/250, Loss: 0.0123\n",
      "Epoch 159/200, Iteration 244/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 245/250, Loss: 0.0188\n",
      "Epoch 159/200, Iteration 246/250, Loss: 0.0240\n",
      "Epoch 159/200, Iteration 247/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 248/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 249/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 250/250, Loss: 0.0199\n",
      "Train Error: \n",
      " Accuracy: 90.26%, Avg loss: 0.006346, MRE: 0.616572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.006381, MRE: 0.911501 \n",
      "\n",
      "Epoch 160/200, Iteration 1/250, Loss: 0.0219\n",
      "Epoch 160/200, Iteration 2/250, Loss: 0.0205\n",
      "Epoch 160/200, Iteration 3/250, Loss: 0.0094\n",
      "Epoch 160/200, Iteration 4/250, Loss: 0.0151\n",
      "Epoch 160/200, Iteration 5/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 6/250, Loss: 0.0092\n",
      "Epoch 160/200, Iteration 7/250, Loss: 0.0221\n",
      "Epoch 160/200, Iteration 8/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 9/250, Loss: 0.0190\n",
      "Epoch 160/200, Iteration 10/250, Loss: 0.0146\n",
      "Epoch 160/200, Iteration 11/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 12/250, Loss: 0.0194\n",
      "Epoch 160/200, Iteration 13/250, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 14/250, Loss: 0.0102\n",
      "Epoch 160/200, Iteration 15/250, Loss: 0.0210\n",
      "Epoch 160/200, Iteration 16/250, Loss: 0.0215\n",
      "Epoch 160/200, Iteration 17/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 18/250, Loss: 0.0095\n",
      "Epoch 160/200, Iteration 19/250, Loss: 0.0130\n",
      "Epoch 160/200, Iteration 20/250, Loss: 0.0203\n",
      "Epoch 160/200, Iteration 21/250, Loss: 0.0126\n",
      "Epoch 160/200, Iteration 22/250, Loss: 0.0054\n",
      "Epoch 160/200, Iteration 23/250, Loss: 0.0313\n",
      "Epoch 160/200, Iteration 24/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 25/250, Loss: 0.0304\n",
      "Epoch 160/200, Iteration 26/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 27/250, Loss: 0.0226\n",
      "Epoch 160/200, Iteration 28/250, Loss: 0.0178\n",
      "Epoch 160/200, Iteration 29/250, Loss: 0.0129\n",
      "Epoch 160/200, Iteration 30/250, Loss: 0.0160\n",
      "Epoch 160/200, Iteration 31/250, Loss: 0.0318\n",
      "Epoch 160/200, Iteration 32/250, Loss: 0.0067\n",
      "Epoch 160/200, Iteration 33/250, Loss: 0.0068\n",
      "Epoch 160/200, Iteration 34/250, Loss: 0.0161\n",
      "Epoch 160/200, Iteration 35/250, Loss: 0.0177\n",
      "Epoch 160/200, Iteration 36/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 37/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 38/250, Loss: 0.0185\n",
      "Epoch 160/200, Iteration 39/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 40/250, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 41/250, Loss: 0.0133\n",
      "Epoch 160/200, Iteration 42/250, Loss: 0.0142\n",
      "Epoch 160/200, Iteration 43/250, Loss: 0.0057\n",
      "Epoch 160/200, Iteration 44/250, Loss: 0.0277\n",
      "Epoch 160/200, Iteration 45/250, Loss: 0.0162\n",
      "Epoch 160/200, Iteration 46/250, Loss: 0.0171\n",
      "Epoch 160/200, Iteration 47/250, Loss: 0.0088\n",
      "Epoch 160/200, Iteration 48/250, Loss: 0.0277\n",
      "Epoch 160/200, Iteration 49/250, Loss: 0.0211\n",
      "Epoch 160/200, Iteration 50/250, Loss: 0.0122\n",
      "Epoch 160/200, Iteration 51/250, Loss: 0.0092\n",
      "Epoch 160/200, Iteration 52/250, Loss: 0.0094\n",
      "Epoch 160/200, Iteration 53/250, Loss: 0.0198\n",
      "Epoch 160/200, Iteration 54/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 55/250, Loss: 0.0135\n",
      "Epoch 160/200, Iteration 56/250, Loss: 0.0069\n",
      "Epoch 160/200, Iteration 57/250, Loss: 0.0302\n",
      "Epoch 160/200, Iteration 58/250, Loss: 0.0215\n",
      "Epoch 160/200, Iteration 59/250, Loss: 0.0212\n",
      "Epoch 160/200, Iteration 60/250, Loss: 0.0106\n",
      "Epoch 160/200, Iteration 61/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 62/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 63/250, Loss: 0.0133\n",
      "Epoch 160/200, Iteration 64/250, Loss: 0.0080\n",
      "Epoch 160/200, Iteration 65/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 66/250, Loss: 0.0135\n",
      "Epoch 160/200, Iteration 67/250, Loss: 0.0113\n",
      "Epoch 160/200, Iteration 68/250, Loss: 0.0340\n",
      "Epoch 160/200, Iteration 69/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 70/250, Loss: 0.0245\n",
      "Epoch 160/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 160/200, Iteration 72/250, Loss: 0.0136\n",
      "Epoch 160/200, Iteration 73/250, Loss: 0.0046\n",
      "Epoch 160/200, Iteration 74/250, Loss: 0.0229\n",
      "Epoch 160/200, Iteration 75/250, Loss: 0.0225\n",
      "Epoch 160/200, Iteration 76/250, Loss: 0.0113\n",
      "Epoch 160/200, Iteration 77/250, Loss: 0.0234\n",
      "Epoch 160/200, Iteration 78/250, Loss: 0.0065\n",
      "Epoch 160/200, Iteration 79/250, Loss: 0.0146\n",
      "Epoch 160/200, Iteration 80/250, Loss: 0.0147\n",
      "Epoch 160/200, Iteration 81/250, Loss: 0.0132\n",
      "Epoch 160/200, Iteration 82/250, Loss: 0.0161\n",
      "Epoch 160/200, Iteration 83/250, Loss: 0.0111\n",
      "Epoch 160/200, Iteration 84/250, Loss: 0.0157\n",
      "Epoch 160/200, Iteration 85/250, Loss: 0.0222\n",
      "Epoch 160/200, Iteration 86/250, Loss: 0.0114\n",
      "Epoch 160/200, Iteration 87/250, Loss: 0.0174\n",
      "Epoch 160/200, Iteration 88/250, Loss: 0.0066\n",
      "Epoch 160/200, Iteration 89/250, Loss: 0.0073\n",
      "Epoch 160/200, Iteration 90/250, Loss: 0.0170\n",
      "Epoch 160/200, Iteration 91/250, Loss: 0.0285\n",
      "Epoch 160/200, Iteration 92/250, Loss: 0.0064\n",
      "Epoch 160/200, Iteration 93/250, Loss: 0.0088\n",
      "Epoch 160/200, Iteration 94/250, Loss: 0.0141\n",
      "Epoch 160/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 96/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 97/250, Loss: 0.0195\n",
      "Epoch 160/200, Iteration 98/250, Loss: 0.0203\n",
      "Epoch 160/200, Iteration 99/250, Loss: 0.0120\n",
      "Epoch 160/200, Iteration 100/250, Loss: 0.0156\n",
      "Epoch 160/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 160/200, Iteration 102/250, Loss: 0.0219\n",
      "Epoch 160/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 160/200, Iteration 104/250, Loss: 0.0128\n",
      "Epoch 160/200, Iteration 105/250, Loss: 0.0219\n",
      "Epoch 160/200, Iteration 106/250, Loss: 0.0243\n",
      "Epoch 160/200, Iteration 107/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 108/250, Loss: 0.0268\n",
      "Epoch 160/200, Iteration 109/250, Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 160/200, Iteration 111/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 112/250, Loss: 0.0127\n",
      "Epoch 160/200, Iteration 113/250, Loss: 0.0139\n",
      "Epoch 160/200, Iteration 114/250, Loss: 0.0087\n",
      "Epoch 160/200, Iteration 115/250, Loss: 0.0104\n",
      "Epoch 160/200, Iteration 116/250, Loss: 0.0267\n",
      "Epoch 160/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 160/200, Iteration 118/250, Loss: 0.0066\n",
      "Epoch 160/200, Iteration 119/250, Loss: 0.0077\n",
      "Epoch 160/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 160/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 160/200, Iteration 122/250, Loss: 0.0084\n",
      "Epoch 160/200, Iteration 123/250, Loss: 0.0125\n",
      "Epoch 160/200, Iteration 124/250, Loss: 0.0155\n",
      "Epoch 160/200, Iteration 125/250, Loss: 0.0085\n",
      "Epoch 160/200, Iteration 126/250, Loss: 0.0200\n",
      "Epoch 160/200, Iteration 127/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 128/250, Loss: 0.0092\n",
      "Epoch 160/200, Iteration 129/250, Loss: 0.0181\n",
      "Epoch 160/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 131/250, Loss: 0.0149\n",
      "Epoch 160/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 133/250, Loss: 0.0194\n",
      "Epoch 160/200, Iteration 134/250, Loss: 0.0189\n",
      "Epoch 160/200, Iteration 135/250, Loss: 0.0079\n",
      "Epoch 160/200, Iteration 136/250, Loss: 0.0233\n",
      "Epoch 160/200, Iteration 137/250, Loss: 0.0122\n",
      "Epoch 160/200, Iteration 138/250, Loss: 0.0103\n",
      "Epoch 160/200, Iteration 139/250, Loss: 0.0211\n",
      "Epoch 160/200, Iteration 140/250, Loss: 0.0200\n",
      "Epoch 160/200, Iteration 141/250, Loss: 0.0109\n",
      "Epoch 160/200, Iteration 142/250, Loss: 0.0255\n",
      "Epoch 160/200, Iteration 143/250, Loss: 0.0143\n",
      "Epoch 160/200, Iteration 144/250, Loss: 0.0272\n",
      "Epoch 160/200, Iteration 145/250, Loss: 0.0128\n",
      "Epoch 160/200, Iteration 146/250, Loss: 0.0359\n",
      "Epoch 160/200, Iteration 147/250, Loss: 0.0089\n",
      "Epoch 160/200, Iteration 148/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 149/250, Loss: 0.0078\n",
      "Epoch 160/200, Iteration 150/250, Loss: 0.0087\n",
      "Epoch 160/200, Iteration 151/250, Loss: 0.0222\n",
      "Epoch 160/200, Iteration 152/250, Loss: 0.0206\n",
      "Epoch 160/200, Iteration 153/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 154/250, Loss: 0.0114\n",
      "Epoch 160/200, Iteration 155/250, Loss: 0.0182\n",
      "Epoch 160/200, Iteration 156/250, Loss: 0.0258\n",
      "Epoch 160/200, Iteration 157/250, Loss: 0.0089\n",
      "Epoch 160/200, Iteration 158/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 159/250, Loss: 0.0071\n",
      "Epoch 160/200, Iteration 160/250, Loss: 0.0219\n",
      "Epoch 160/200, Iteration 161/250, Loss: 0.0204\n",
      "Epoch 160/200, Iteration 162/250, Loss: 0.0212\n",
      "Epoch 160/200, Iteration 163/250, Loss: 0.0065\n",
      "Epoch 160/200, Iteration 164/250, Loss: 0.0080\n",
      "Epoch 160/200, Iteration 165/250, Loss: 0.0078\n",
      "Epoch 160/200, Iteration 166/250, Loss: 0.0196\n",
      "Epoch 160/200, Iteration 167/250, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 168/250, Loss: 0.0142\n",
      "Epoch 160/200, Iteration 169/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 170/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 171/250, Loss: 0.0165\n",
      "Epoch 160/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 160/200, Iteration 173/250, Loss: 0.0191\n",
      "Epoch 160/200, Iteration 174/250, Loss: 0.0556\n",
      "Epoch 160/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 160/200, Iteration 176/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 178/250, Loss: 0.0119\n",
      "Epoch 160/200, Iteration 179/250, Loss: 0.0123\n",
      "Epoch 160/200, Iteration 180/250, Loss: 0.0172\n",
      "Epoch 160/200, Iteration 181/250, Loss: 0.0074\n",
      "Epoch 160/200, Iteration 182/250, Loss: 0.0295\n",
      "Epoch 160/200, Iteration 183/250, Loss: 0.0258\n",
      "Epoch 160/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 185/250, Loss: 0.0119\n",
      "Epoch 160/200, Iteration 186/250, Loss: 0.0136\n",
      "Epoch 160/200, Iteration 187/250, Loss: 0.0188\n",
      "Epoch 160/200, Iteration 188/250, Loss: 0.0157\n",
      "Epoch 160/200, Iteration 189/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 190/250, Loss: 0.0096\n",
      "Epoch 160/200, Iteration 191/250, Loss: 0.0084\n",
      "Epoch 160/200, Iteration 192/250, Loss: 0.0119\n",
      "Epoch 160/200, Iteration 193/250, Loss: 0.0191\n",
      "Epoch 160/200, Iteration 194/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 195/250, Loss: 0.0113\n",
      "Epoch 160/200, Iteration 196/250, Loss: 0.0337\n",
      "Epoch 160/200, Iteration 197/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 198/250, Loss: 0.0123\n",
      "Epoch 160/200, Iteration 199/250, Loss: 0.0121\n",
      "Epoch 160/200, Iteration 200/250, Loss: 0.0275\n",
      "Epoch 160/200, Iteration 201/250, Loss: 0.0069\n",
      "Epoch 160/200, Iteration 202/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 203/250, Loss: 0.0089\n",
      "Epoch 160/200, Iteration 204/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 205/250, Loss: 0.0137\n",
      "Epoch 160/200, Iteration 206/250, Loss: 0.0073\n",
      "Epoch 160/200, Iteration 207/250, Loss: 0.0068\n",
      "Epoch 160/200, Iteration 208/250, Loss: 0.0254\n",
      "Epoch 160/200, Iteration 209/250, Loss: 0.0146\n",
      "Epoch 160/200, Iteration 210/250, Loss: 0.0162\n",
      "Epoch 160/200, Iteration 211/250, Loss: 0.0153\n",
      "Epoch 160/200, Iteration 212/250, Loss: 0.0082\n",
      "Epoch 160/200, Iteration 213/250, Loss: 0.0277\n",
      "Epoch 160/200, Iteration 214/250, Loss: 0.0291\n",
      "Epoch 160/200, Iteration 215/250, Loss: 0.0076\n",
      "Epoch 160/200, Iteration 216/250, Loss: 0.0086\n",
      "Epoch 160/200, Iteration 217/250, Loss: 0.0176\n",
      "Epoch 160/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 219/250, Loss: 0.0056\n",
      "Epoch 160/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 160/200, Iteration 221/250, Loss: 0.0192\n",
      "Epoch 160/200, Iteration 222/250, Loss: 0.0074\n",
      "Epoch 160/200, Iteration 223/250, Loss: 0.0263\n",
      "Epoch 160/200, Iteration 224/250, Loss: 0.0189\n",
      "Epoch 160/200, Iteration 225/250, Loss: 0.0201\n",
      "Epoch 160/200, Iteration 226/250, Loss: 0.0149\n",
      "Epoch 160/200, Iteration 227/250, Loss: 0.0100\n",
      "Epoch 160/200, Iteration 228/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 160/200, Iteration 230/250, Loss: 0.0088\n",
      "Epoch 160/200, Iteration 231/250, Loss: 0.0062\n",
      "Epoch 160/200, Iteration 232/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 233/250, Loss: 0.0146\n",
      "Epoch 160/200, Iteration 234/250, Loss: 0.0118\n",
      "Epoch 160/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 236/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 237/250, Loss: 0.0161\n",
      "Epoch 160/200, Iteration 238/250, Loss: 0.0062\n",
      "Epoch 160/200, Iteration 239/250, Loss: 0.0165\n",
      "Epoch 160/200, Iteration 240/250, Loss: 0.0078\n",
      "Epoch 160/200, Iteration 241/250, Loss: 0.0164\n",
      "Epoch 160/200, Iteration 242/250, Loss: 0.0122\n",
      "Epoch 160/200, Iteration 243/250, Loss: 0.0208\n",
      "Epoch 160/200, Iteration 244/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 245/250, Loss: 0.0118\n",
      "Epoch 160/200, Iteration 246/250, Loss: 0.0215\n",
      "Epoch 160/200, Iteration 247/250, Loss: 0.0249\n",
      "Epoch 160/200, Iteration 248/250, Loss: 0.0186\n",
      "Epoch 160/200, Iteration 249/250, Loss: 0.0139\n",
      "Epoch 160/200, Iteration 250/250, Loss: 0.0307\n",
      "Train Error: \n",
      " Accuracy: 97.96%, Avg loss: 0.006552, MRE: 0.666395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.15%, Avg loss: 0.006467, MRE: 1.158095 \n",
      "\n",
      "Epoch 161/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 161/200, Iteration 2/250, Loss: 0.0200\n",
      "Epoch 161/200, Iteration 3/250, Loss: 0.0179\n",
      "Epoch 161/200, Iteration 4/250, Loss: 0.0363\n",
      "Epoch 161/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 161/200, Iteration 6/250, Loss: 0.0083\n",
      "Epoch 161/200, Iteration 7/250, Loss: 0.0180\n",
      "Epoch 161/200, Iteration 8/250, Loss: 0.0274\n",
      "Epoch 161/200, Iteration 9/250, Loss: 0.0160\n",
      "Epoch 161/200, Iteration 10/250, Loss: 0.0152\n",
      "Epoch 161/200, Iteration 11/250, Loss: 0.0211\n",
      "Epoch 161/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 13/250, Loss: 0.0055\n",
      "Epoch 161/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 161/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 161/200, Iteration 16/250, Loss: 0.0123\n",
      "Epoch 161/200, Iteration 17/250, Loss: 0.0156\n",
      "Epoch 161/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 161/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 161/200, Iteration 20/250, Loss: 0.0124\n",
      "Epoch 161/200, Iteration 21/250, Loss: 0.0271\n",
      "Epoch 161/200, Iteration 22/250, Loss: 0.0123\n",
      "Epoch 161/200, Iteration 23/250, Loss: 0.0355\n",
      "Epoch 161/200, Iteration 24/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 25/250, Loss: 0.0143\n",
      "Epoch 161/200, Iteration 26/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 27/250, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 28/250, Loss: 0.0066\n",
      "Epoch 161/200, Iteration 29/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 30/250, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 31/250, Loss: 0.0187\n",
      "Epoch 161/200, Iteration 32/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 33/250, Loss: 0.0218\n",
      "Epoch 161/200, Iteration 34/250, Loss: 0.0311\n",
      "Epoch 161/200, Iteration 35/250, Loss: 0.0074\n",
      "Epoch 161/200, Iteration 36/250, Loss: 0.0133\n",
      "Epoch 161/200, Iteration 37/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 161/200, Iteration 39/250, Loss: 0.0131\n",
      "Epoch 161/200, Iteration 40/250, Loss: 0.0222\n",
      "Epoch 161/200, Iteration 41/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 42/250, Loss: 0.0351\n",
      "Epoch 161/200, Iteration 43/250, Loss: 0.0210\n",
      "Epoch 161/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 45/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 46/250, Loss: 0.0358\n",
      "Epoch 161/200, Iteration 47/250, Loss: 0.0142\n",
      "Epoch 161/200, Iteration 48/250, Loss: 0.0250\n",
      "Epoch 161/200, Iteration 49/250, Loss: 0.0095\n",
      "Epoch 161/200, Iteration 50/250, Loss: 0.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200, Iteration 51/250, Loss: 0.0149\n",
      "Epoch 161/200, Iteration 52/250, Loss: 0.0360\n",
      "Epoch 161/200, Iteration 53/250, Loss: 0.0259\n",
      "Epoch 161/200, Iteration 54/250, Loss: 0.0082\n",
      "Epoch 161/200, Iteration 55/250, Loss: 0.0095\n",
      "Epoch 161/200, Iteration 56/250, Loss: 0.0342\n",
      "Epoch 161/200, Iteration 57/250, Loss: 0.0096\n",
      "Epoch 161/200, Iteration 58/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 59/250, Loss: 0.0074\n",
      "Epoch 161/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 61/250, Loss: 0.0155\n",
      "Epoch 161/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 161/200, Iteration 63/250, Loss: 0.0108\n",
      "Epoch 161/200, Iteration 64/250, Loss: 0.0231\n",
      "Epoch 161/200, Iteration 65/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 66/250, Loss: 0.0142\n",
      "Epoch 161/200, Iteration 67/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 68/250, Loss: 0.0337\n",
      "Epoch 161/200, Iteration 69/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 70/250, Loss: 0.0086\n",
      "Epoch 161/200, Iteration 71/250, Loss: 0.0072\n",
      "Epoch 161/200, Iteration 72/250, Loss: 0.0327\n",
      "Epoch 161/200, Iteration 73/250, Loss: 0.0059\n",
      "Epoch 161/200, Iteration 74/250, Loss: 0.0227\n",
      "Epoch 161/200, Iteration 75/250, Loss: 0.0115\n",
      "Epoch 161/200, Iteration 76/250, Loss: 0.0084\n",
      "Epoch 161/200, Iteration 77/250, Loss: 0.0278\n",
      "Epoch 161/200, Iteration 78/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 80/250, Loss: 0.0095\n",
      "Epoch 161/200, Iteration 81/250, Loss: 0.0125\n",
      "Epoch 161/200, Iteration 82/250, Loss: 0.0231\n",
      "Epoch 161/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 84/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 85/250, Loss: 0.0167\n",
      "Epoch 161/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 161/200, Iteration 87/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 88/250, Loss: 0.0353\n",
      "Epoch 161/200, Iteration 89/250, Loss: 0.0115\n",
      "Epoch 161/200, Iteration 90/250, Loss: 0.0489\n",
      "Epoch 161/200, Iteration 91/250, Loss: 0.0106\n",
      "Epoch 161/200, Iteration 92/250, Loss: 0.0085\n",
      "Epoch 161/200, Iteration 93/250, Loss: 0.0073\n",
      "Epoch 161/200, Iteration 94/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 95/250, Loss: 0.0247\n",
      "Epoch 161/200, Iteration 96/250, Loss: 0.0375\n",
      "Epoch 161/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 161/200, Iteration 98/250, Loss: 0.0302\n",
      "Epoch 161/200, Iteration 99/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 100/250, Loss: 0.0302\n",
      "Epoch 161/200, Iteration 101/250, Loss: 0.0089\n",
      "Epoch 161/200, Iteration 102/250, Loss: 0.0133\n",
      "Epoch 161/200, Iteration 103/250, Loss: 0.0248\n",
      "Epoch 161/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 105/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 106/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 107/250, Loss: 0.0089\n",
      "Epoch 161/200, Iteration 108/250, Loss: 0.0200\n",
      "Epoch 161/200, Iteration 109/250, Loss: 0.0115\n",
      "Epoch 161/200, Iteration 110/250, Loss: 0.0145\n",
      "Epoch 161/200, Iteration 111/250, Loss: 0.0116\n",
      "Epoch 161/200, Iteration 112/250, Loss: 0.0072\n",
      "Epoch 161/200, Iteration 113/250, Loss: 0.0094\n",
      "Epoch 161/200, Iteration 114/250, Loss: 0.0111\n",
      "Epoch 161/200, Iteration 115/250, Loss: 0.0072\n",
      "Epoch 161/200, Iteration 116/250, Loss: 0.0059\n",
      "Epoch 161/200, Iteration 117/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 118/250, Loss: 0.0158\n",
      "Epoch 161/200, Iteration 119/250, Loss: 0.0132\n",
      "Epoch 161/200, Iteration 120/250, Loss: 0.0223\n",
      "Epoch 161/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 161/200, Iteration 122/250, Loss: 0.0246\n",
      "Epoch 161/200, Iteration 123/250, Loss: 0.0144\n",
      "Epoch 161/200, Iteration 124/250, Loss: 0.0178\n",
      "Epoch 161/200, Iteration 125/250, Loss: 0.0085\n",
      "Epoch 161/200, Iteration 126/250, Loss: 0.0292\n",
      "Epoch 161/200, Iteration 127/250, Loss: 0.0122\n",
      "Epoch 161/200, Iteration 128/250, Loss: 0.0293\n",
      "Epoch 161/200, Iteration 129/250, Loss: 0.0203\n",
      "Epoch 161/200, Iteration 130/250, Loss: 0.0098\n",
      "Epoch 161/200, Iteration 131/250, Loss: 0.0087\n",
      "Epoch 161/200, Iteration 132/250, Loss: 0.0240\n",
      "Epoch 161/200, Iteration 133/250, Loss: 0.0081\n",
      "Epoch 161/200, Iteration 134/250, Loss: 0.0089\n",
      "Epoch 161/200, Iteration 135/250, Loss: 0.0161\n",
      "Epoch 161/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 161/200, Iteration 137/250, Loss: 0.0197\n",
      "Epoch 161/200, Iteration 138/250, Loss: 0.0097\n",
      "Epoch 161/200, Iteration 139/250, Loss: 0.0089\n",
      "Epoch 161/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 141/250, Loss: 0.0166\n",
      "Epoch 161/200, Iteration 142/250, Loss: 0.0074\n",
      "Epoch 161/200, Iteration 143/250, Loss: 0.0295\n",
      "Epoch 161/200, Iteration 144/250, Loss: 0.0138\n",
      "Epoch 161/200, Iteration 145/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 146/250, Loss: 0.0195\n",
      "Epoch 161/200, Iteration 147/250, Loss: 0.0309\n",
      "Epoch 161/200, Iteration 148/250, Loss: 0.0388\n",
      "Epoch 161/200, Iteration 149/250, Loss: 0.0190\n",
      "Epoch 161/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 151/250, Loss: 0.0164\n",
      "Epoch 161/200, Iteration 152/250, Loss: 0.0241\n",
      "Epoch 161/200, Iteration 153/250, Loss: 0.0152\n",
      "Epoch 161/200, Iteration 154/250, Loss: 0.0069\n",
      "Epoch 161/200, Iteration 155/250, Loss: 0.0116\n",
      "Epoch 161/200, Iteration 156/250, Loss: 0.0129\n",
      "Epoch 161/200, Iteration 157/250, Loss: 0.0075\n",
      "Epoch 161/200, Iteration 158/250, Loss: 0.0234\n",
      "Epoch 161/200, Iteration 159/250, Loss: 0.0071\n",
      "Epoch 161/200, Iteration 160/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 161/250, Loss: 0.0151\n",
      "Epoch 161/200, Iteration 162/250, Loss: 0.0105\n",
      "Epoch 161/200, Iteration 163/250, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 164/250, Loss: 0.0145\n",
      "Epoch 161/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 161/200, Iteration 166/250, Loss: 0.0130\n",
      "Epoch 161/200, Iteration 167/250, Loss: 0.0296\n",
      "Epoch 161/200, Iteration 168/250, Loss: 0.0189\n",
      "Epoch 161/200, Iteration 169/250, Loss: 0.0141\n",
      "Epoch 161/200, Iteration 170/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 171/250, Loss: 0.0150\n",
      "Epoch 161/200, Iteration 172/250, Loss: 0.0252\n",
      "Epoch 161/200, Iteration 173/250, Loss: 0.0161\n",
      "Epoch 161/200, Iteration 174/250, Loss: 0.0168\n",
      "Epoch 161/200, Iteration 175/250, Loss: 0.0123\n",
      "Epoch 161/200, Iteration 176/250, Loss: 0.0163\n",
      "Epoch 161/200, Iteration 177/250, Loss: 0.0255\n",
      "Epoch 161/200, Iteration 178/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 179/250, Loss: 0.0165\n",
      "Epoch 161/200, Iteration 180/250, Loss: 0.0237\n",
      "Epoch 161/200, Iteration 181/250, Loss: 0.0062\n",
      "Epoch 161/200, Iteration 182/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 183/250, Loss: 0.0136\n",
      "Epoch 161/200, Iteration 184/250, Loss: 0.0094\n",
      "Epoch 161/200, Iteration 185/250, Loss: 0.0104\n",
      "Epoch 161/200, Iteration 186/250, Loss: 0.0096\n",
      "Epoch 161/200, Iteration 187/250, Loss: 0.0378\n",
      "Epoch 161/200, Iteration 188/250, Loss: 0.0146\n",
      "Epoch 161/200, Iteration 189/250, Loss: 0.0127\n",
      "Epoch 161/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 161/200, Iteration 191/250, Loss: 0.0134\n",
      "Epoch 161/200, Iteration 192/250, Loss: 0.0097\n",
      "Epoch 161/200, Iteration 193/250, Loss: 0.0152\n",
      "Epoch 161/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 195/250, Loss: 0.0174\n",
      "Epoch 161/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 161/200, Iteration 197/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 198/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 199/250, Loss: 0.0118\n",
      "Epoch 161/200, Iteration 200/250, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 201/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 202/250, Loss: 0.0106\n",
      "Epoch 161/200, Iteration 203/250, Loss: 0.0173\n",
      "Epoch 161/200, Iteration 204/250, Loss: 0.0086\n",
      "Epoch 161/200, Iteration 205/250, Loss: 0.0245\n",
      "Epoch 161/200, Iteration 206/250, Loss: 0.0188\n",
      "Epoch 161/200, Iteration 207/250, Loss: 0.0117\n",
      "Epoch 161/200, Iteration 208/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 209/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 210/250, Loss: 0.0121\n",
      "Epoch 161/200, Iteration 211/250, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 212/250, Loss: 0.0314\n",
      "Epoch 161/200, Iteration 213/250, Loss: 0.0172\n",
      "Epoch 161/200, Iteration 214/250, Loss: 0.0080\n",
      "Epoch 161/200, Iteration 215/250, Loss: 0.0175\n",
      "Epoch 161/200, Iteration 216/250, Loss: 0.0129\n",
      "Epoch 161/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 161/200, Iteration 218/250, Loss: 0.0259\n",
      "Epoch 161/200, Iteration 219/250, Loss: 0.0117\n",
      "Epoch 161/200, Iteration 220/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 221/250, Loss: 0.0080\n",
      "Epoch 161/200, Iteration 222/250, Loss: 0.0213\n",
      "Epoch 161/200, Iteration 223/250, Loss: 0.0172\n",
      "Epoch 161/200, Iteration 224/250, Loss: 0.0178\n",
      "Epoch 161/200, Iteration 225/250, Loss: 0.0216\n",
      "Epoch 161/200, Iteration 226/250, Loss: 0.0101\n",
      "Epoch 161/200, Iteration 227/250, Loss: 0.0082\n",
      "Epoch 161/200, Iteration 228/250, Loss: 0.0273\n",
      "Epoch 161/200, Iteration 229/250, Loss: 0.0080\n",
      "Epoch 161/200, Iteration 230/250, Loss: 0.0231\n",
      "Epoch 161/200, Iteration 231/250, Loss: 0.0083\n",
      "Epoch 161/200, Iteration 232/250, Loss: 0.0074\n",
      "Epoch 161/200, Iteration 233/250, Loss: 0.0238\n",
      "Epoch 161/200, Iteration 234/250, Loss: 0.0357\n",
      "Epoch 161/200, Iteration 235/250, Loss: 0.0153\n",
      "Epoch 161/200, Iteration 236/250, Loss: 0.0275\n",
      "Epoch 161/200, Iteration 237/250, Loss: 0.0257\n",
      "Epoch 161/200, Iteration 238/250, Loss: 0.0160\n",
      "Epoch 161/200, Iteration 239/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 240/250, Loss: 0.0150\n",
      "Epoch 161/200, Iteration 241/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 242/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 243/250, Loss: 0.0132\n",
      "Epoch 161/200, Iteration 244/250, Loss: 0.0275\n",
      "Epoch 161/200, Iteration 245/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 246/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200, Iteration 247/250, Loss: 0.0120\n",
      "Epoch 161/200, Iteration 248/250, Loss: 0.0072\n",
      "Epoch 161/200, Iteration 249/250, Loss: 0.0189\n",
      "Epoch 161/200, Iteration 250/250, Loss: 0.0206\n",
      "Train Error: \n",
      " Accuracy: 96.64%, Avg loss: 0.005975, MRE: 0.608952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.005991, MRE: 0.987131 \n",
      "\n",
      "Epoch 162/200, Iteration 1/250, Loss: 0.0150\n",
      "Epoch 162/200, Iteration 2/250, Loss: 0.0182\n",
      "Epoch 162/200, Iteration 3/250, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 4/250, Loss: 0.0104\n",
      "Epoch 162/200, Iteration 5/250, Loss: 0.0300\n",
      "Epoch 162/200, Iteration 6/250, Loss: 0.0190\n",
      "Epoch 162/200, Iteration 7/250, Loss: 0.0155\n",
      "Epoch 162/200, Iteration 8/250, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 9/250, Loss: 0.0128\n",
      "Epoch 162/200, Iteration 10/250, Loss: 0.0102\n",
      "Epoch 162/200, Iteration 11/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 12/250, Loss: 0.0070\n",
      "Epoch 162/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 14/250, Loss: 0.0202\n",
      "Epoch 162/200, Iteration 15/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 16/250, Loss: 0.0099\n",
      "Epoch 162/200, Iteration 17/250, Loss: 0.0286\n",
      "Epoch 162/200, Iteration 18/250, Loss: 0.0115\n",
      "Epoch 162/200, Iteration 19/250, Loss: 0.0122\n",
      "Epoch 162/200, Iteration 20/250, Loss: 0.0078\n",
      "Epoch 162/200, Iteration 21/250, Loss: 0.0089\n",
      "Epoch 162/200, Iteration 22/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 162/200, Iteration 24/250, Loss: 0.0047\n",
      "Epoch 162/200, Iteration 25/250, Loss: 0.0213\n",
      "Epoch 162/200, Iteration 26/250, Loss: 0.0236\n",
      "Epoch 162/200, Iteration 27/250, Loss: 0.0156\n",
      "Epoch 162/200, Iteration 28/250, Loss: 0.0396\n",
      "Epoch 162/200, Iteration 29/250, Loss: 0.0183\n",
      "Epoch 162/200, Iteration 30/250, Loss: 0.0173\n",
      "Epoch 162/200, Iteration 31/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 32/250, Loss: 0.0086\n",
      "Epoch 162/200, Iteration 33/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 34/250, Loss: 0.0203\n",
      "Epoch 162/200, Iteration 35/250, Loss: 0.0136\n",
      "Epoch 162/200, Iteration 36/250, Loss: 0.0077\n",
      "Epoch 162/200, Iteration 37/250, Loss: 0.0068\n",
      "Epoch 162/200, Iteration 38/250, Loss: 0.0139\n",
      "Epoch 162/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 162/200, Iteration 40/250, Loss: 0.0264\n",
      "Epoch 162/200, Iteration 41/250, Loss: 0.0160\n",
      "Epoch 162/200, Iteration 42/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 43/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 45/250, Loss: 0.0175\n",
      "Epoch 162/200, Iteration 46/250, Loss: 0.0172\n",
      "Epoch 162/200, Iteration 47/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 48/250, Loss: 0.0077\n",
      "Epoch 162/200, Iteration 49/250, Loss: 0.0306\n",
      "Epoch 162/200, Iteration 50/250, Loss: 0.0100\n",
      "Epoch 162/200, Iteration 51/250, Loss: 0.0277\n",
      "Epoch 162/200, Iteration 52/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 53/250, Loss: 0.0106\n",
      "Epoch 162/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 162/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 162/200, Iteration 56/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 57/250, Loss: 0.0111\n",
      "Epoch 162/200, Iteration 58/250, Loss: 0.0074\n",
      "Epoch 162/200, Iteration 59/250, Loss: 0.0185\n",
      "Epoch 162/200, Iteration 60/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 162/200, Iteration 62/250, Loss: 0.0106\n",
      "Epoch 162/200, Iteration 63/250, Loss: 0.0243\n",
      "Epoch 162/200, Iteration 64/250, Loss: 0.0233\n",
      "Epoch 162/200, Iteration 65/250, Loss: 0.0154\n",
      "Epoch 162/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 162/200, Iteration 67/250, Loss: 0.0081\n",
      "Epoch 162/200, Iteration 68/250, Loss: 0.0246\n",
      "Epoch 162/200, Iteration 69/250, Loss: 0.0226\n",
      "Epoch 162/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 162/200, Iteration 72/250, Loss: 0.0123\n",
      "Epoch 162/200, Iteration 73/250, Loss: 0.0144\n",
      "Epoch 162/200, Iteration 74/250, Loss: 0.0057\n",
      "Epoch 162/200, Iteration 75/250, Loss: 0.0216\n",
      "Epoch 162/200, Iteration 76/250, Loss: 0.0079\n",
      "Epoch 162/200, Iteration 77/250, Loss: 0.0289\n",
      "Epoch 162/200, Iteration 78/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 79/250, Loss: 0.0173\n",
      "Epoch 162/200, Iteration 80/250, Loss: 0.0156\n",
      "Epoch 162/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 162/200, Iteration 83/250, Loss: 0.0117\n",
      "Epoch 162/200, Iteration 84/250, Loss: 0.0104\n",
      "Epoch 162/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 86/250, Loss: 0.0069\n",
      "Epoch 162/200, Iteration 87/250, Loss: 0.0137\n",
      "Epoch 162/200, Iteration 88/250, Loss: 0.0131\n",
      "Epoch 162/200, Iteration 89/250, Loss: 0.0225\n",
      "Epoch 162/200, Iteration 90/250, Loss: 0.0161\n",
      "Epoch 162/200, Iteration 91/250, Loss: 0.0058\n",
      "Epoch 162/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 162/200, Iteration 93/250, Loss: 0.0337\n",
      "Epoch 162/200, Iteration 94/250, Loss: 0.0063\n",
      "Epoch 162/200, Iteration 95/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 96/250, Loss: 0.0104\n",
      "Epoch 162/200, Iteration 97/250, Loss: 0.0206\n",
      "Epoch 162/200, Iteration 98/250, Loss: 0.0272\n",
      "Epoch 162/200, Iteration 99/250, Loss: 0.0098\n",
      "Epoch 162/200, Iteration 100/250, Loss: 0.0084\n",
      "Epoch 162/200, Iteration 101/250, Loss: 0.0153\n",
      "Epoch 162/200, Iteration 102/250, Loss: 0.0071\n",
      "Epoch 162/200, Iteration 103/250, Loss: 0.0153\n",
      "Epoch 162/200, Iteration 104/250, Loss: 0.0186\n",
      "Epoch 162/200, Iteration 105/250, Loss: 0.0275\n",
      "Epoch 162/200, Iteration 106/250, Loss: 0.0112\n",
      "Epoch 162/200, Iteration 107/250, Loss: 0.0084\n",
      "Epoch 162/200, Iteration 108/250, Loss: 0.0055\n",
      "Epoch 162/200, Iteration 109/250, Loss: 0.0070\n",
      "Epoch 162/200, Iteration 110/250, Loss: 0.0269\n",
      "Epoch 162/200, Iteration 111/250, Loss: 0.0081\n",
      "Epoch 162/200, Iteration 112/250, Loss: 0.0133\n",
      "Epoch 162/200, Iteration 113/250, Loss: 0.0195\n",
      "Epoch 162/200, Iteration 114/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 115/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 116/250, Loss: 0.0152\n",
      "Epoch 162/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 162/200, Iteration 118/250, Loss: 0.0145\n",
      "Epoch 162/200, Iteration 119/250, Loss: 0.0177\n",
      "Epoch 162/200, Iteration 120/250, Loss: 0.0200\n",
      "Epoch 162/200, Iteration 121/250, Loss: 0.0283\n",
      "Epoch 162/200, Iteration 122/250, Loss: 0.0239\n",
      "Epoch 162/200, Iteration 123/250, Loss: 0.0132\n",
      "Epoch 162/200, Iteration 124/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 125/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 126/250, Loss: 0.0064\n",
      "Epoch 162/200, Iteration 127/250, Loss: 0.0174\n",
      "Epoch 162/200, Iteration 128/250, Loss: 0.0242\n",
      "Epoch 162/200, Iteration 129/250, Loss: 0.0065\n",
      "Epoch 162/200, Iteration 130/250, Loss: 0.0226\n",
      "Epoch 162/200, Iteration 131/250, Loss: 0.0197\n",
      "Epoch 162/200, Iteration 132/250, Loss: 0.0079\n",
      "Epoch 162/200, Iteration 133/250, Loss: 0.0258\n",
      "Epoch 162/200, Iteration 134/250, Loss: 0.0108\n",
      "Epoch 162/200, Iteration 135/250, Loss: 0.0299\n",
      "Epoch 162/200, Iteration 136/250, Loss: 0.0345\n",
      "Epoch 162/200, Iteration 137/250, Loss: 0.0127\n",
      "Epoch 162/200, Iteration 138/250, Loss: 0.0071\n",
      "Epoch 162/200, Iteration 139/250, Loss: 0.0497\n",
      "Epoch 162/200, Iteration 140/250, Loss: 0.0140\n",
      "Epoch 162/200, Iteration 141/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 142/250, Loss: 0.0251\n",
      "Epoch 162/200, Iteration 143/250, Loss: 0.0222\n",
      "Epoch 162/200, Iteration 144/250, Loss: 0.0093\n",
      "Epoch 162/200, Iteration 145/250, Loss: 0.0209\n",
      "Epoch 162/200, Iteration 146/250, Loss: 0.0137\n",
      "Epoch 162/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 148/250, Loss: 0.0144\n",
      "Epoch 162/200, Iteration 149/250, Loss: 0.0255\n",
      "Epoch 162/200, Iteration 150/250, Loss: 0.0109\n",
      "Epoch 162/200, Iteration 151/250, Loss: 0.0070\n",
      "Epoch 162/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 162/200, Iteration 153/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 154/250, Loss: 0.0156\n",
      "Epoch 162/200, Iteration 155/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 156/250, Loss: 0.0073\n",
      "Epoch 162/200, Iteration 157/250, Loss: 0.0200\n",
      "Epoch 162/200, Iteration 158/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 159/250, Loss: 0.0109\n",
      "Epoch 162/200, Iteration 160/250, Loss: 0.0092\n",
      "Epoch 162/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 162/200, Iteration 162/250, Loss: 0.0126\n",
      "Epoch 162/200, Iteration 163/250, Loss: 0.0242\n",
      "Epoch 162/200, Iteration 164/250, Loss: 0.0122\n",
      "Epoch 162/200, Iteration 165/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 166/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 167/250, Loss: 0.0250\n",
      "Epoch 162/200, Iteration 168/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 169/250, Loss: 0.0348\n",
      "Epoch 162/200, Iteration 170/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 171/250, Loss: 0.0110\n",
      "Epoch 162/200, Iteration 172/250, Loss: 0.0241\n",
      "Epoch 162/200, Iteration 173/250, Loss: 0.0127\n",
      "Epoch 162/200, Iteration 174/250, Loss: 0.0079\n",
      "Epoch 162/200, Iteration 175/250, Loss: 0.0102\n",
      "Epoch 162/200, Iteration 176/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 177/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 178/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 179/250, Loss: 0.0266\n",
      "Epoch 162/200, Iteration 180/250, Loss: 0.0082\n",
      "Epoch 162/200, Iteration 181/250, Loss: 0.0112\n",
      "Epoch 162/200, Iteration 182/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 183/250, Loss: 0.0072\n",
      "Epoch 162/200, Iteration 184/250, Loss: 0.0074\n",
      "Epoch 162/200, Iteration 185/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 186/250, Loss: 0.0059\n",
      "Epoch 162/200, Iteration 187/250, Loss: 0.0133\n",
      "Epoch 162/200, Iteration 188/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 189/250, Loss: 0.0158\n",
      "Epoch 162/200, Iteration 190/250, Loss: 0.0078\n",
      "Epoch 162/200, Iteration 191/250, Loss: 0.0221\n",
      "Epoch 162/200, Iteration 192/250, Loss: 0.0141\n",
      "Epoch 162/200, Iteration 193/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 194/250, Loss: 0.0082\n",
      "Epoch 162/200, Iteration 195/250, Loss: 0.0145\n",
      "Epoch 162/200, Iteration 196/250, Loss: 0.0150\n",
      "Epoch 162/200, Iteration 197/250, Loss: 0.0296\n",
      "Epoch 162/200, Iteration 198/250, Loss: 0.0280\n",
      "Epoch 162/200, Iteration 199/250, Loss: 0.0133\n",
      "Epoch 162/200, Iteration 200/250, Loss: 0.0116\n",
      "Epoch 162/200, Iteration 201/250, Loss: 0.0256\n",
      "Epoch 162/200, Iteration 202/250, Loss: 0.0135\n",
      "Epoch 162/200, Iteration 203/250, Loss: 0.0206\n",
      "Epoch 162/200, Iteration 204/250, Loss: 0.0207\n",
      "Epoch 162/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 162/200, Iteration 206/250, Loss: 0.0221\n",
      "Epoch 162/200, Iteration 207/250, Loss: 0.0111\n",
      "Epoch 162/200, Iteration 208/250, Loss: 0.0289\n",
      "Epoch 162/200, Iteration 209/250, Loss: 0.0286\n",
      "Epoch 162/200, Iteration 210/250, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200, Iteration 211/250, Loss: 0.0134\n",
      "Epoch 162/200, Iteration 212/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 213/250, Loss: 0.0113\n",
      "Epoch 162/200, Iteration 214/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 215/250, Loss: 0.0212\n",
      "Epoch 162/200, Iteration 216/250, Loss: 0.0151\n",
      "Epoch 162/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 218/250, Loss: 0.0127\n",
      "Epoch 162/200, Iteration 219/250, Loss: 0.0117\n",
      "Epoch 162/200, Iteration 220/250, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 221/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 222/250, Loss: 0.0203\n",
      "Epoch 162/200, Iteration 223/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 224/250, Loss: 0.0218\n",
      "Epoch 162/200, Iteration 225/250, Loss: 0.0214\n",
      "Epoch 162/200, Iteration 226/250, Loss: 0.0132\n",
      "Epoch 162/200, Iteration 227/250, Loss: 0.0081\n",
      "Epoch 162/200, Iteration 228/250, Loss: 0.0201\n",
      "Epoch 162/200, Iteration 229/250, Loss: 0.0208\n",
      "Epoch 162/200, Iteration 230/250, Loss: 0.0205\n",
      "Epoch 162/200, Iteration 231/250, Loss: 0.0133\n",
      "Epoch 162/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 233/250, Loss: 0.0086\n",
      "Epoch 162/200, Iteration 234/250, Loss: 0.0069\n",
      "Epoch 162/200, Iteration 235/250, Loss: 0.0101\n",
      "Epoch 162/200, Iteration 236/250, Loss: 0.0223\n",
      "Epoch 162/200, Iteration 237/250, Loss: 0.0160\n",
      "Epoch 162/200, Iteration 238/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 239/250, Loss: 0.0131\n",
      "Epoch 162/200, Iteration 240/250, Loss: 0.0086\n",
      "Epoch 162/200, Iteration 241/250, Loss: 0.0079\n",
      "Epoch 162/200, Iteration 242/250, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 243/250, Loss: 0.0098\n",
      "Epoch 162/200, Iteration 244/250, Loss: 0.0234\n",
      "Epoch 162/200, Iteration 245/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 246/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 247/250, Loss: 0.0184\n",
      "Epoch 162/200, Iteration 248/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 249/250, Loss: 0.0226\n",
      "Epoch 162/200, Iteration 250/250, Loss: 0.0144\n",
      "Train Error: \n",
      " Accuracy: 75.75%, Avg loss: 0.007660, MRE: 0.651630 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.65%, Avg loss: 0.007743, MRE: 0.903472 \n",
      "\n",
      "Epoch 163/200, Iteration 1/250, Loss: 0.0170\n",
      "Epoch 163/200, Iteration 2/250, Loss: 0.0113\n",
      "Epoch 163/200, Iteration 3/250, Loss: 0.0227\n",
      "Epoch 163/200, Iteration 4/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 5/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 6/250, Loss: 0.0061\n",
      "Epoch 163/200, Iteration 7/250, Loss: 0.0148\n",
      "Epoch 163/200, Iteration 8/250, Loss: 0.0257\n",
      "Epoch 163/200, Iteration 9/250, Loss: 0.0151\n",
      "Epoch 163/200, Iteration 10/250, Loss: 0.0059\n",
      "Epoch 163/200, Iteration 11/250, Loss: 0.0084\n",
      "Epoch 163/200, Iteration 12/250, Loss: 0.0085\n",
      "Epoch 163/200, Iteration 13/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 14/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 15/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 16/250, Loss: 0.0239\n",
      "Epoch 163/200, Iteration 17/250, Loss: 0.0200\n",
      "Epoch 163/200, Iteration 18/250, Loss: 0.0177\n",
      "Epoch 163/200, Iteration 19/250, Loss: 0.0291\n",
      "Epoch 163/200, Iteration 20/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 21/250, Loss: 0.0291\n",
      "Epoch 163/200, Iteration 22/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 24/250, Loss: 0.0247\n",
      "Epoch 163/200, Iteration 25/250, Loss: 0.0158\n",
      "Epoch 163/200, Iteration 26/250, Loss: 0.0164\n",
      "Epoch 163/200, Iteration 27/250, Loss: 0.0130\n",
      "Epoch 163/200, Iteration 28/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 29/250, Loss: 0.0280\n",
      "Epoch 163/200, Iteration 30/250, Loss: 0.0156\n",
      "Epoch 163/200, Iteration 31/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 32/250, Loss: 0.0100\n",
      "Epoch 163/200, Iteration 33/250, Loss: 0.0164\n",
      "Epoch 163/200, Iteration 34/250, Loss: 0.0203\n",
      "Epoch 163/200, Iteration 35/250, Loss: 0.0143\n",
      "Epoch 163/200, Iteration 36/250, Loss: 0.0115\n",
      "Epoch 163/200, Iteration 37/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 38/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 39/250, Loss: 0.0259\n",
      "Epoch 163/200, Iteration 40/250, Loss: 0.0294\n",
      "Epoch 163/200, Iteration 41/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 42/250, Loss: 0.0172\n",
      "Epoch 163/200, Iteration 43/250, Loss: 0.0164\n",
      "Epoch 163/200, Iteration 44/250, Loss: 0.0195\n",
      "Epoch 163/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 46/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 47/250, Loss: 0.0208\n",
      "Epoch 163/200, Iteration 48/250, Loss: 0.0113\n",
      "Epoch 163/200, Iteration 49/250, Loss: 0.0159\n",
      "Epoch 163/200, Iteration 50/250, Loss: 0.0168\n",
      "Epoch 163/200, Iteration 51/250, Loss: 0.0124\n",
      "Epoch 163/200, Iteration 52/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 54/250, Loss: 0.0157\n",
      "Epoch 163/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 163/200, Iteration 56/250, Loss: 0.0114\n",
      "Epoch 163/200, Iteration 57/250, Loss: 0.0270\n",
      "Epoch 163/200, Iteration 58/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 60/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 61/250, Loss: 0.0078\n",
      "Epoch 163/200, Iteration 62/250, Loss: 0.0119\n",
      "Epoch 163/200, Iteration 63/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 64/250, Loss: 0.0104\n",
      "Epoch 163/200, Iteration 65/250, Loss: 0.0144\n",
      "Epoch 163/200, Iteration 66/250, Loss: 0.0127\n",
      "Epoch 163/200, Iteration 67/250, Loss: 0.0064\n",
      "Epoch 163/200, Iteration 68/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 69/250, Loss: 0.0213\n",
      "Epoch 163/200, Iteration 70/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 71/250, Loss: 0.0077\n",
      "Epoch 163/200, Iteration 72/250, Loss: 0.0162\n",
      "Epoch 163/200, Iteration 73/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 74/250, Loss: 0.0288\n",
      "Epoch 163/200, Iteration 75/250, Loss: 0.0139\n",
      "Epoch 163/200, Iteration 76/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 77/250, Loss: 0.0269\n",
      "Epoch 163/200, Iteration 78/250, Loss: 0.0065\n",
      "Epoch 163/200, Iteration 79/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 80/250, Loss: 0.0096\n",
      "Epoch 163/200, Iteration 81/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 82/250, Loss: 0.0087\n",
      "Epoch 163/200, Iteration 83/250, Loss: 0.0099\n",
      "Epoch 163/200, Iteration 84/250, Loss: 0.0178\n",
      "Epoch 163/200, Iteration 85/250, Loss: 0.0185\n",
      "Epoch 163/200, Iteration 86/250, Loss: 0.0096\n",
      "Epoch 163/200, Iteration 87/250, Loss: 0.0119\n",
      "Epoch 163/200, Iteration 88/250, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 89/250, Loss: 0.0348\n",
      "Epoch 163/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 163/200, Iteration 91/250, Loss: 0.0292\n",
      "Epoch 163/200, Iteration 92/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 93/250, Loss: 0.0209\n",
      "Epoch 163/200, Iteration 94/250, Loss: 0.0313\n",
      "Epoch 163/200, Iteration 95/250, Loss: 0.0060\n",
      "Epoch 163/200, Iteration 96/250, Loss: 0.0415\n",
      "Epoch 163/200, Iteration 97/250, Loss: 0.0347\n",
      "Epoch 163/200, Iteration 98/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 99/250, Loss: 0.0160\n",
      "Epoch 163/200, Iteration 100/250, Loss: 0.0104\n",
      "Epoch 163/200, Iteration 101/250, Loss: 0.0060\n",
      "Epoch 163/200, Iteration 102/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 103/250, Loss: 0.0167\n",
      "Epoch 163/200, Iteration 104/250, Loss: 0.0274\n",
      "Epoch 163/200, Iteration 105/250, Loss: 0.0130\n",
      "Epoch 163/200, Iteration 106/250, Loss: 0.0074\n",
      "Epoch 163/200, Iteration 107/250, Loss: 0.0124\n",
      "Epoch 163/200, Iteration 108/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 109/250, Loss: 0.0057\n",
      "Epoch 163/200, Iteration 110/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 111/250, Loss: 0.0171\n",
      "Epoch 163/200, Iteration 112/250, Loss: 0.0158\n",
      "Epoch 163/200, Iteration 113/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 114/250, Loss: 0.0082\n",
      "Epoch 163/200, Iteration 115/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 116/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 117/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 118/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 119/250, Loss: 0.0134\n",
      "Epoch 163/200, Iteration 120/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 121/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 122/250, Loss: 0.0316\n",
      "Epoch 163/200, Iteration 123/250, Loss: 0.0478\n",
      "Epoch 163/200, Iteration 124/250, Loss: 0.0366\n",
      "Epoch 163/200, Iteration 125/250, Loss: 0.0182\n",
      "Epoch 163/200, Iteration 126/250, Loss: 0.0271\n",
      "Epoch 163/200, Iteration 127/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 128/250, Loss: 0.0213\n",
      "Epoch 163/200, Iteration 129/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 130/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 131/250, Loss: 0.0214\n",
      "Epoch 163/200, Iteration 132/250, Loss: 0.0142\n",
      "Epoch 163/200, Iteration 133/250, Loss: 0.0083\n",
      "Epoch 163/200, Iteration 134/250, Loss: 0.0078\n",
      "Epoch 163/200, Iteration 135/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 136/250, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 137/250, Loss: 0.0178\n",
      "Epoch 163/200, Iteration 138/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 139/250, Loss: 0.0335\n",
      "Epoch 163/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 163/200, Iteration 141/250, Loss: 0.0113\n",
      "Epoch 163/200, Iteration 142/250, Loss: 0.0094\n",
      "Epoch 163/200, Iteration 143/250, Loss: 0.0172\n",
      "Epoch 163/200, Iteration 144/250, Loss: 0.0175\n",
      "Epoch 163/200, Iteration 145/250, Loss: 0.0152\n",
      "Epoch 163/200, Iteration 146/250, Loss: 0.0204\n",
      "Epoch 163/200, Iteration 147/250, Loss: 0.0179\n",
      "Epoch 163/200, Iteration 148/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 149/250, Loss: 0.0207\n",
      "Epoch 163/200, Iteration 150/250, Loss: 0.0135\n",
      "Epoch 163/200, Iteration 151/250, Loss: 0.0136\n",
      "Epoch 163/200, Iteration 152/250, Loss: 0.0100\n",
      "Epoch 163/200, Iteration 153/250, Loss: 0.0169\n",
      "Epoch 163/200, Iteration 154/250, Loss: 0.0251\n",
      "Epoch 163/200, Iteration 155/250, Loss: 0.0217\n",
      "Epoch 163/200, Iteration 156/250, Loss: 0.0136\n",
      "Epoch 163/200, Iteration 157/250, Loss: 0.0116\n",
      "Epoch 163/200, Iteration 158/250, Loss: 0.0419\n",
      "Epoch 163/200, Iteration 159/250, Loss: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200, Iteration 160/250, Loss: 0.0082\n",
      "Epoch 163/200, Iteration 161/250, Loss: 0.0085\n",
      "Epoch 163/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 163/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 164/250, Loss: 0.0118\n",
      "Epoch 163/200, Iteration 165/250, Loss: 0.0136\n",
      "Epoch 163/200, Iteration 166/250, Loss: 0.0179\n",
      "Epoch 163/200, Iteration 167/250, Loss: 0.0081\n",
      "Epoch 163/200, Iteration 168/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 169/250, Loss: 0.0353\n",
      "Epoch 163/200, Iteration 170/250, Loss: 0.0147\n",
      "Epoch 163/200, Iteration 171/250, Loss: 0.0122\n",
      "Epoch 163/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 163/200, Iteration 173/250, Loss: 0.0061\n",
      "Epoch 163/200, Iteration 174/250, Loss: 0.0138\n",
      "Epoch 163/200, Iteration 175/250, Loss: 0.0224\n",
      "Epoch 163/200, Iteration 176/250, Loss: 0.0078\n",
      "Epoch 163/200, Iteration 177/250, Loss: 0.0140\n",
      "Epoch 163/200, Iteration 178/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 179/250, Loss: 0.0146\n",
      "Epoch 163/200, Iteration 180/250, Loss: 0.0210\n",
      "Epoch 163/200, Iteration 181/250, Loss: 0.0085\n",
      "Epoch 163/200, Iteration 182/250, Loss: 0.0175\n",
      "Epoch 163/200, Iteration 183/250, Loss: 0.0120\n",
      "Epoch 163/200, Iteration 184/250, Loss: 0.0129\n",
      "Epoch 163/200, Iteration 185/250, Loss: 0.0203\n",
      "Epoch 163/200, Iteration 186/250, Loss: 0.0221\n",
      "Epoch 163/200, Iteration 187/250, Loss: 0.0067\n",
      "Epoch 163/200, Iteration 188/250, Loss: 0.0098\n",
      "Epoch 163/200, Iteration 189/250, Loss: 0.0255\n",
      "Epoch 163/200, Iteration 190/250, Loss: 0.0159\n",
      "Epoch 163/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 163/200, Iteration 192/250, Loss: 0.0130\n",
      "Epoch 163/200, Iteration 193/250, Loss: 0.0147\n",
      "Epoch 163/200, Iteration 194/250, Loss: 0.0293\n",
      "Epoch 163/200, Iteration 195/250, Loss: 0.0204\n",
      "Epoch 163/200, Iteration 196/250, Loss: 0.0090\n",
      "Epoch 163/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 199/250, Loss: 0.0274\n",
      "Epoch 163/200, Iteration 200/250, Loss: 0.0310\n",
      "Epoch 163/200, Iteration 201/250, Loss: 0.0177\n",
      "Epoch 163/200, Iteration 202/250, Loss: 0.0215\n",
      "Epoch 163/200, Iteration 203/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 163/200, Iteration 205/250, Loss: 0.0082\n",
      "Epoch 163/200, Iteration 206/250, Loss: 0.0096\n",
      "Epoch 163/200, Iteration 207/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 208/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 209/250, Loss: 0.0153\n",
      "Epoch 163/200, Iteration 210/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 211/250, Loss: 0.0142\n",
      "Epoch 163/200, Iteration 212/250, Loss: 0.0135\n",
      "Epoch 163/200, Iteration 213/250, Loss: 0.0392\n",
      "Epoch 163/200, Iteration 214/250, Loss: 0.0258\n",
      "Epoch 163/200, Iteration 215/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 216/250, Loss: 0.0177\n",
      "Epoch 163/200, Iteration 217/250, Loss: 0.0276\n",
      "Epoch 163/200, Iteration 218/250, Loss: 0.0176\n",
      "Epoch 163/200, Iteration 219/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 220/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 221/250, Loss: 0.0060\n",
      "Epoch 163/200, Iteration 222/250, Loss: 0.0147\n",
      "Epoch 163/200, Iteration 223/250, Loss: 0.0146\n",
      "Epoch 163/200, Iteration 224/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 225/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 226/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 227/250, Loss: 0.0340\n",
      "Epoch 163/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 163/200, Iteration 229/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 230/250, Loss: 0.0120\n",
      "Epoch 163/200, Iteration 231/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 232/250, Loss: 0.0338\n",
      "Epoch 163/200, Iteration 233/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 234/250, Loss: 0.0143\n",
      "Epoch 163/200, Iteration 235/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 236/250, Loss: 0.0084\n",
      "Epoch 163/200, Iteration 237/250, Loss: 0.0235\n",
      "Epoch 163/200, Iteration 238/250, Loss: 0.0090\n",
      "Epoch 163/200, Iteration 239/250, Loss: 0.0206\n",
      "Epoch 163/200, Iteration 240/250, Loss: 0.0175\n",
      "Epoch 163/200, Iteration 241/250, Loss: 0.0078\n",
      "Epoch 163/200, Iteration 242/250, Loss: 0.0264\n",
      "Epoch 163/200, Iteration 243/250, Loss: 0.0190\n",
      "Epoch 163/200, Iteration 244/250, Loss: 0.0098\n",
      "Epoch 163/200, Iteration 245/250, Loss: 0.0155\n",
      "Epoch 163/200, Iteration 246/250, Loss: 0.0067\n",
      "Epoch 163/200, Iteration 247/250, Loss: 0.0155\n",
      "Epoch 163/200, Iteration 248/250, Loss: 0.0094\n",
      "Epoch 163/200, Iteration 249/250, Loss: 0.0165\n",
      "Epoch 163/200, Iteration 250/250, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 95.31%, Avg loss: 0.005717, MRE: 0.612628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.005748, MRE: 0.987570 \n",
      "\n",
      "Epoch 164/200, Iteration 1/250, Loss: 0.0187\n",
      "Epoch 164/200, Iteration 2/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 3/250, Loss: 0.0161\n",
      "Epoch 164/200, Iteration 4/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 5/250, Loss: 0.0405\n",
      "Epoch 164/200, Iteration 6/250, Loss: 0.0089\n",
      "Epoch 164/200, Iteration 7/250, Loss: 0.0255\n",
      "Epoch 164/200, Iteration 8/250, Loss: 0.0132\n",
      "Epoch 164/200, Iteration 9/250, Loss: 0.0083\n",
      "Epoch 164/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 12/250, Loss: 0.0206\n",
      "Epoch 164/200, Iteration 13/250, Loss: 0.0147\n",
      "Epoch 164/200, Iteration 14/250, Loss: 0.0099\n",
      "Epoch 164/200, Iteration 15/250, Loss: 0.0252\n",
      "Epoch 164/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 164/200, Iteration 17/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 18/250, Loss: 0.0194\n",
      "Epoch 164/200, Iteration 19/250, Loss: 0.0107\n",
      "Epoch 164/200, Iteration 20/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 21/250, Loss: 0.0160\n",
      "Epoch 164/200, Iteration 22/250, Loss: 0.0266\n",
      "Epoch 164/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 164/200, Iteration 24/250, Loss: 0.0231\n",
      "Epoch 164/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 164/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 164/200, Iteration 27/250, Loss: 0.0129\n",
      "Epoch 164/200, Iteration 28/250, Loss: 0.0121\n",
      "Epoch 164/200, Iteration 29/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 30/250, Loss: 0.0134\n",
      "Epoch 164/200, Iteration 31/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 32/250, Loss: 0.0351\n",
      "Epoch 164/200, Iteration 33/250, Loss: 0.0203\n",
      "Epoch 164/200, Iteration 34/250, Loss: 0.0137\n",
      "Epoch 164/200, Iteration 35/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 36/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 37/250, Loss: 0.0154\n",
      "Epoch 164/200, Iteration 38/250, Loss: 0.0262\n",
      "Epoch 164/200, Iteration 39/250, Loss: 0.0272\n",
      "Epoch 164/200, Iteration 40/250, Loss: 0.0072\n",
      "Epoch 164/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 42/250, Loss: 0.0070\n",
      "Epoch 164/200, Iteration 43/250, Loss: 0.0082\n",
      "Epoch 164/200, Iteration 44/250, Loss: 0.0236\n",
      "Epoch 164/200, Iteration 45/250, Loss: 0.0089\n",
      "Epoch 164/200, Iteration 46/250, Loss: 0.0173\n",
      "Epoch 164/200, Iteration 47/250, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 48/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 49/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 50/250, Loss: 0.0136\n",
      "Epoch 164/200, Iteration 51/250, Loss: 0.0230\n",
      "Epoch 164/200, Iteration 52/250, Loss: 0.0170\n",
      "Epoch 164/200, Iteration 53/250, Loss: 0.0233\n",
      "Epoch 164/200, Iteration 54/250, Loss: 0.0148\n",
      "Epoch 164/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 56/250, Loss: 0.0069\n",
      "Epoch 164/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 164/200, Iteration 58/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 59/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 60/250, Loss: 0.0086\n",
      "Epoch 164/200, Iteration 61/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 62/250, Loss: 0.0182\n",
      "Epoch 164/200, Iteration 63/250, Loss: 0.0102\n",
      "Epoch 164/200, Iteration 64/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 65/250, Loss: 0.0151\n",
      "Epoch 164/200, Iteration 66/250, Loss: 0.0098\n",
      "Epoch 164/200, Iteration 67/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 68/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 69/250, Loss: 0.0068\n",
      "Epoch 164/200, Iteration 70/250, Loss: 0.0074\n",
      "Epoch 164/200, Iteration 71/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 72/250, Loss: 0.0179\n",
      "Epoch 164/200, Iteration 73/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 74/250, Loss: 0.0326\n",
      "Epoch 164/200, Iteration 75/250, Loss: 0.0105\n",
      "Epoch 164/200, Iteration 76/250, Loss: 0.0284\n",
      "Epoch 164/200, Iteration 77/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 78/250, Loss: 0.0075\n",
      "Epoch 164/200, Iteration 79/250, Loss: 0.0097\n",
      "Epoch 164/200, Iteration 80/250, Loss: 0.0218\n",
      "Epoch 164/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 164/200, Iteration 82/250, Loss: 0.0064\n",
      "Epoch 164/200, Iteration 83/250, Loss: 0.0216\n",
      "Epoch 164/200, Iteration 84/250, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 85/250, Loss: 0.0187\n",
      "Epoch 164/200, Iteration 86/250, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200, Iteration 87/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 88/250, Loss: 0.0307\n",
      "Epoch 164/200, Iteration 89/250, Loss: 0.0079\n",
      "Epoch 164/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 164/200, Iteration 91/250, Loss: 0.0234\n",
      "Epoch 164/200, Iteration 92/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 93/250, Loss: 0.0102\n",
      "Epoch 164/200, Iteration 94/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 95/250, Loss: 0.0066\n",
      "Epoch 164/200, Iteration 96/250, Loss: 0.0193\n",
      "Epoch 164/200, Iteration 97/250, Loss: 0.0146\n",
      "Epoch 164/200, Iteration 98/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 99/250, Loss: 0.0171\n",
      "Epoch 164/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 101/250, Loss: 0.0225\n",
      "Epoch 164/200, Iteration 102/250, Loss: 0.0122\n",
      "Epoch 164/200, Iteration 103/250, Loss: 0.0095\n",
      "Epoch 164/200, Iteration 104/250, Loss: 0.0143\n",
      "Epoch 164/200, Iteration 105/250, Loss: 0.0280\n",
      "Epoch 164/200, Iteration 106/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 107/250, Loss: 0.0242\n",
      "Epoch 164/200, Iteration 108/250, Loss: 0.0107\n",
      "Epoch 164/200, Iteration 109/250, Loss: 0.0170\n",
      "Epoch 164/200, Iteration 110/250, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 111/250, Loss: 0.0141\n",
      "Epoch 164/200, Iteration 112/250, Loss: 0.0274\n",
      "Epoch 164/200, Iteration 113/250, Loss: 0.0130\n",
      "Epoch 164/200, Iteration 114/250, Loss: 0.0114\n",
      "Epoch 164/200, Iteration 115/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 116/250, Loss: 0.0162\n",
      "Epoch 164/200, Iteration 117/250, Loss: 0.0140\n",
      "Epoch 164/200, Iteration 118/250, Loss: 0.0121\n",
      "Epoch 164/200, Iteration 119/250, Loss: 0.0162\n",
      "Epoch 164/200, Iteration 120/250, Loss: 0.0149\n",
      "Epoch 164/200, Iteration 121/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 122/250, Loss: 0.0121\n",
      "Epoch 164/200, Iteration 123/250, Loss: 0.0067\n",
      "Epoch 164/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 164/200, Iteration 125/250, Loss: 0.0118\n",
      "Epoch 164/200, Iteration 126/250, Loss: 0.0250\n",
      "Epoch 164/200, Iteration 127/250, Loss: 0.0134\n",
      "Epoch 164/200, Iteration 128/250, Loss: 0.0105\n",
      "Epoch 164/200, Iteration 129/250, Loss: 0.0111\n",
      "Epoch 164/200, Iteration 130/250, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 131/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 132/250, Loss: 0.0097\n",
      "Epoch 164/200, Iteration 133/250, Loss: 0.0170\n",
      "Epoch 164/200, Iteration 134/250, Loss: 0.0192\n",
      "Epoch 164/200, Iteration 135/250, Loss: 0.0377\n",
      "Epoch 164/200, Iteration 136/250, Loss: 0.0062\n",
      "Epoch 164/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 138/250, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 139/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 140/250, Loss: 0.0200\n",
      "Epoch 164/200, Iteration 141/250, Loss: 0.0159\n",
      "Epoch 164/200, Iteration 142/250, Loss: 0.0148\n",
      "Epoch 164/200, Iteration 143/250, Loss: 0.0157\n",
      "Epoch 164/200, Iteration 144/250, Loss: 0.0074\n",
      "Epoch 164/200, Iteration 145/250, Loss: 0.0111\n",
      "Epoch 164/200, Iteration 146/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 147/250, Loss: 0.0166\n",
      "Epoch 164/200, Iteration 148/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 149/250, Loss: 0.0113\n",
      "Epoch 164/200, Iteration 150/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 151/250, Loss: 0.0170\n",
      "Epoch 164/200, Iteration 152/250, Loss: 0.0176\n",
      "Epoch 164/200, Iteration 153/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 154/250, Loss: 0.0077\n",
      "Epoch 164/200, Iteration 155/250, Loss: 0.0085\n",
      "Epoch 164/200, Iteration 156/250, Loss: 0.0223\n",
      "Epoch 164/200, Iteration 157/250, Loss: 0.0091\n",
      "Epoch 164/200, Iteration 158/250, Loss: 0.0199\n",
      "Epoch 164/200, Iteration 159/250, Loss: 0.0249\n",
      "Epoch 164/200, Iteration 160/250, Loss: 0.0070\n",
      "Epoch 164/200, Iteration 161/250, Loss: 0.0146\n",
      "Epoch 164/200, Iteration 162/250, Loss: 0.0206\n",
      "Epoch 164/200, Iteration 163/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 164/250, Loss: 0.0148\n",
      "Epoch 164/200, Iteration 165/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 166/250, Loss: 0.0086\n",
      "Epoch 164/200, Iteration 167/250, Loss: 0.0068\n",
      "Epoch 164/200, Iteration 168/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 169/250, Loss: 0.0177\n",
      "Epoch 164/200, Iteration 170/250, Loss: 0.0257\n",
      "Epoch 164/200, Iteration 171/250, Loss: 0.0080\n",
      "Epoch 164/200, Iteration 172/250, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 173/250, Loss: 0.0122\n",
      "Epoch 164/200, Iteration 174/250, Loss: 0.0056\n",
      "Epoch 164/200, Iteration 175/250, Loss: 0.0217\n",
      "Epoch 164/200, Iteration 176/250, Loss: 0.0184\n",
      "Epoch 164/200, Iteration 177/250, Loss: 0.0457\n",
      "Epoch 164/200, Iteration 178/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 179/250, Loss: 0.0329\n",
      "Epoch 164/200, Iteration 180/250, Loss: 0.0135\n",
      "Epoch 164/200, Iteration 181/250, Loss: 0.0152\n",
      "Epoch 164/200, Iteration 182/250, Loss: 0.0172\n",
      "Epoch 164/200, Iteration 183/250, Loss: 0.0232\n",
      "Epoch 164/200, Iteration 184/250, Loss: 0.0276\n",
      "Epoch 164/200, Iteration 185/250, Loss: 0.0058\n",
      "Epoch 164/200, Iteration 186/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 187/250, Loss: 0.0100\n",
      "Epoch 164/200, Iteration 188/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 190/250, Loss: 0.0120\n",
      "Epoch 164/200, Iteration 191/250, Loss: 0.0284\n",
      "Epoch 164/200, Iteration 192/250, Loss: 0.0239\n",
      "Epoch 164/200, Iteration 193/250, Loss: 0.0199\n",
      "Epoch 164/200, Iteration 194/250, Loss: 0.0223\n",
      "Epoch 164/200, Iteration 195/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 196/250, Loss: 0.0114\n",
      "Epoch 164/200, Iteration 197/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 198/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 164/200, Iteration 200/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 201/250, Loss: 0.0177\n",
      "Epoch 164/200, Iteration 202/250, Loss: 0.0128\n",
      "Epoch 164/200, Iteration 203/250, Loss: 0.0146\n",
      "Epoch 164/200, Iteration 204/250, Loss: 0.0071\n",
      "Epoch 164/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 164/200, Iteration 206/250, Loss: 0.0066\n",
      "Epoch 164/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 208/250, Loss: 0.0083\n",
      "Epoch 164/200, Iteration 209/250, Loss: 0.0062\n",
      "Epoch 164/200, Iteration 210/250, Loss: 0.0125\n",
      "Epoch 164/200, Iteration 211/250, Loss: 0.0185\n",
      "Epoch 164/200, Iteration 212/250, Loss: 0.0225\n",
      "Epoch 164/200, Iteration 213/250, Loss: 0.0201\n",
      "Epoch 164/200, Iteration 214/250, Loss: 0.0145\n",
      "Epoch 164/200, Iteration 215/250, Loss: 0.0152\n",
      "Epoch 164/200, Iteration 216/250, Loss: 0.0121\n",
      "Epoch 164/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 164/200, Iteration 218/250, Loss: 0.0077\n",
      "Epoch 164/200, Iteration 219/250, Loss: 0.0138\n",
      "Epoch 164/200, Iteration 220/250, Loss: 0.0302\n",
      "Epoch 164/200, Iteration 221/250, Loss: 0.0345\n",
      "Epoch 164/200, Iteration 222/250, Loss: 0.0193\n",
      "Epoch 164/200, Iteration 223/250, Loss: 0.0082\n",
      "Epoch 164/200, Iteration 224/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 225/250, Loss: 0.0297\n",
      "Epoch 164/200, Iteration 226/250, Loss: 0.0179\n",
      "Epoch 164/200, Iteration 227/250, Loss: 0.0211\n",
      "Epoch 164/200, Iteration 228/250, Loss: 0.0136\n",
      "Epoch 164/200, Iteration 229/250, Loss: 0.0065\n",
      "Epoch 164/200, Iteration 230/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 231/250, Loss: 0.0093\n",
      "Epoch 164/200, Iteration 232/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 233/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 234/250, Loss: 0.0149\n",
      "Epoch 164/200, Iteration 235/250, Loss: 0.0146\n",
      "Epoch 164/200, Iteration 236/250, Loss: 0.0066\n",
      "Epoch 164/200, Iteration 237/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 238/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 239/250, Loss: 0.0210\n",
      "Epoch 164/200, Iteration 240/250, Loss: 0.0186\n",
      "Epoch 164/200, Iteration 241/250, Loss: 0.0181\n",
      "Epoch 164/200, Iteration 242/250, Loss: 0.0141\n",
      "Epoch 164/200, Iteration 243/250, Loss: 0.0166\n",
      "Epoch 164/200, Iteration 244/250, Loss: 0.0188\n",
      "Epoch 164/200, Iteration 245/250, Loss: 0.0144\n",
      "Epoch 164/200, Iteration 246/250, Loss: 0.0073\n",
      "Epoch 164/200, Iteration 247/250, Loss: 0.0184\n",
      "Epoch 164/200, Iteration 248/250, Loss: 0.0205\n",
      "Epoch 164/200, Iteration 249/250, Loss: 0.0303\n",
      "Epoch 164/200, Iteration 250/250, Loss: 0.0116\n",
      "Train Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.007319, MRE: 0.746182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.95%, Avg loss: 0.007179, MRE: 1.268308 \n",
      "\n",
      "Epoch 165/200, Iteration 1/250, Loss: 0.0299\n",
      "Epoch 165/200, Iteration 2/250, Loss: 0.0118\n",
      "Epoch 165/200, Iteration 3/250, Loss: 0.0124\n",
      "Epoch 165/200, Iteration 4/250, Loss: 0.0112\n",
      "Epoch 165/200, Iteration 5/250, Loss: 0.0165\n",
      "Epoch 165/200, Iteration 6/250, Loss: 0.0091\n",
      "Epoch 165/200, Iteration 7/250, Loss: 0.0099\n",
      "Epoch 165/200, Iteration 8/250, Loss: 0.0324\n",
      "Epoch 165/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 165/200, Iteration 10/250, Loss: 0.0147\n",
      "Epoch 165/200, Iteration 11/250, Loss: 0.0184\n",
      "Epoch 165/200, Iteration 12/250, Loss: 0.0264\n",
      "Epoch 165/200, Iteration 13/250, Loss: 0.0110\n",
      "Epoch 165/200, Iteration 14/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 15/250, Loss: 0.0091\n",
      "Epoch 165/200, Iteration 16/250, Loss: 0.0098\n",
      "Epoch 165/200, Iteration 17/250, Loss: 0.0278\n",
      "Epoch 165/200, Iteration 18/250, Loss: 0.0085\n",
      "Epoch 165/200, Iteration 19/250, Loss: 0.0182\n",
      "Epoch 165/200, Iteration 20/250, Loss: 0.0158\n",
      "Epoch 165/200, Iteration 21/250, Loss: 0.0077\n",
      "Epoch 165/200, Iteration 22/250, Loss: 0.0064\n",
      "Epoch 165/200, Iteration 23/250, Loss: 0.0204\n",
      "Epoch 165/200, Iteration 24/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 25/250, Loss: 0.0173\n",
      "Epoch 165/200, Iteration 26/250, Loss: 0.0220\n",
      "Epoch 165/200, Iteration 27/250, Loss: 0.0111\n",
      "Epoch 165/200, Iteration 28/250, Loss: 0.0080\n",
      "Epoch 165/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 165/200, Iteration 30/250, Loss: 0.0179\n",
      "Epoch 165/200, Iteration 31/250, Loss: 0.0198\n",
      "Epoch 165/200, Iteration 32/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 33/250, Loss: 0.0071\n",
      "Epoch 165/200, Iteration 34/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 35/250, Loss: 0.0203\n",
      "Epoch 165/200, Iteration 36/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 37/250, Loss: 0.0151\n",
      "Epoch 165/200, Iteration 38/250, Loss: 0.0148\n",
      "Epoch 165/200, Iteration 39/250, Loss: 0.0078\n",
      "Epoch 165/200, Iteration 40/250, Loss: 0.0140\n",
      "Epoch 165/200, Iteration 41/250, Loss: 0.0218\n",
      "Epoch 165/200, Iteration 42/250, Loss: 0.0195\n",
      "Epoch 165/200, Iteration 43/250, Loss: 0.0075\n",
      "Epoch 165/200, Iteration 44/250, Loss: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 46/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 47/250, Loss: 0.0316\n",
      "Epoch 165/200, Iteration 48/250, Loss: 0.0084\n",
      "Epoch 165/200, Iteration 49/250, Loss: 0.0111\n",
      "Epoch 165/200, Iteration 50/250, Loss: 0.0130\n",
      "Epoch 165/200, Iteration 51/250, Loss: 0.0089\n",
      "Epoch 165/200, Iteration 52/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 53/250, Loss: 0.0217\n",
      "Epoch 165/200, Iteration 54/250, Loss: 0.0176\n",
      "Epoch 165/200, Iteration 55/250, Loss: 0.0223\n",
      "Epoch 165/200, Iteration 56/250, Loss: 0.0225\n",
      "Epoch 165/200, Iteration 57/250, Loss: 0.0093\n",
      "Epoch 165/200, Iteration 58/250, Loss: 0.0453\n",
      "Epoch 165/200, Iteration 59/250, Loss: 0.0198\n",
      "Epoch 165/200, Iteration 60/250, Loss: 0.0200\n",
      "Epoch 165/200, Iteration 61/250, Loss: 0.0121\n",
      "Epoch 165/200, Iteration 62/250, Loss: 0.0140\n",
      "Epoch 165/200, Iteration 63/250, Loss: 0.0178\n",
      "Epoch 165/200, Iteration 64/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 65/250, Loss: 0.0244\n",
      "Epoch 165/200, Iteration 66/250, Loss: 0.0113\n",
      "Epoch 165/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 165/200, Iteration 68/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 69/250, Loss: 0.0234\n",
      "Epoch 165/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 71/250, Loss: 0.0129\n",
      "Epoch 165/200, Iteration 72/250, Loss: 0.0108\n",
      "Epoch 165/200, Iteration 73/250, Loss: 0.0148\n",
      "Epoch 165/200, Iteration 74/250, Loss: 0.0176\n",
      "Epoch 165/200, Iteration 75/250, Loss: 0.0277\n",
      "Epoch 165/200, Iteration 76/250, Loss: 0.0158\n",
      "Epoch 165/200, Iteration 77/250, Loss: 0.0183\n",
      "Epoch 165/200, Iteration 78/250, Loss: 0.0307\n",
      "Epoch 165/200, Iteration 79/250, Loss: 0.0155\n",
      "Epoch 165/200, Iteration 80/250, Loss: 0.0085\n",
      "Epoch 165/200, Iteration 81/250, Loss: 0.0136\n",
      "Epoch 165/200, Iteration 82/250, Loss: 0.0173\n",
      "Epoch 165/200, Iteration 83/250, Loss: 0.0124\n",
      "Epoch 165/200, Iteration 84/250, Loss: 0.0175\n",
      "Epoch 165/200, Iteration 85/250, Loss: 0.0104\n",
      "Epoch 165/200, Iteration 86/250, Loss: 0.0087\n",
      "Epoch 165/200, Iteration 87/250, Loss: 0.0144\n",
      "Epoch 165/200, Iteration 88/250, Loss: 0.0173\n",
      "Epoch 165/200, Iteration 89/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 90/250, Loss: 0.0204\n",
      "Epoch 165/200, Iteration 91/250, Loss: 0.0217\n",
      "Epoch 165/200, Iteration 92/250, Loss: 0.0231\n",
      "Epoch 165/200, Iteration 93/250, Loss: 0.0121\n",
      "Epoch 165/200, Iteration 94/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 95/250, Loss: 0.0262\n",
      "Epoch 165/200, Iteration 96/250, Loss: 0.0313\n",
      "Epoch 165/200, Iteration 97/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 98/250, Loss: 0.0108\n",
      "Epoch 165/200, Iteration 99/250, Loss: 0.0253\n",
      "Epoch 165/200, Iteration 100/250, Loss: 0.0102\n",
      "Epoch 165/200, Iteration 101/250, Loss: 0.0062\n",
      "Epoch 165/200, Iteration 102/250, Loss: 0.0087\n",
      "Epoch 165/200, Iteration 103/250, Loss: 0.0131\n",
      "Epoch 165/200, Iteration 104/250, Loss: 0.0243\n",
      "Epoch 165/200, Iteration 105/250, Loss: 0.0076\n",
      "Epoch 165/200, Iteration 106/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 107/250, Loss: 0.0153\n",
      "Epoch 165/200, Iteration 108/250, Loss: 0.0301\n",
      "Epoch 165/200, Iteration 109/250, Loss: 0.0089\n",
      "Epoch 165/200, Iteration 110/250, Loss: 0.0251\n",
      "Epoch 165/200, Iteration 111/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 112/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 113/250, Loss: 0.0162\n",
      "Epoch 165/200, Iteration 114/250, Loss: 0.0179\n",
      "Epoch 165/200, Iteration 115/250, Loss: 0.0141\n",
      "Epoch 165/200, Iteration 116/250, Loss: 0.0099\n",
      "Epoch 165/200, Iteration 117/250, Loss: 0.0112\n",
      "Epoch 165/200, Iteration 118/250, Loss: 0.0119\n",
      "Epoch 165/200, Iteration 119/250, Loss: 0.0194\n",
      "Epoch 165/200, Iteration 120/250, Loss: 0.0127\n",
      "Epoch 165/200, Iteration 121/250, Loss: 0.0390\n",
      "Epoch 165/200, Iteration 122/250, Loss: 0.0189\n",
      "Epoch 165/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 165/200, Iteration 124/250, Loss: 0.0099\n",
      "Epoch 165/200, Iteration 125/250, Loss: 0.0184\n",
      "Epoch 165/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 165/200, Iteration 127/250, Loss: 0.0299\n",
      "Epoch 165/200, Iteration 128/250, Loss: 0.0223\n",
      "Epoch 165/200, Iteration 129/250, Loss: 0.0107\n",
      "Epoch 165/200, Iteration 130/250, Loss: 0.0219\n",
      "Epoch 165/200, Iteration 131/250, Loss: 0.0273\n",
      "Epoch 165/200, Iteration 132/250, Loss: 0.0338\n",
      "Epoch 165/200, Iteration 133/250, Loss: 0.0230\n",
      "Epoch 165/200, Iteration 134/250, Loss: 0.0107\n",
      "Epoch 165/200, Iteration 135/250, Loss: 0.0127\n",
      "Epoch 165/200, Iteration 136/250, Loss: 0.0289\n",
      "Epoch 165/200, Iteration 137/250, Loss: 0.0211\n",
      "Epoch 165/200, Iteration 138/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 139/250, Loss: 0.0210\n",
      "Epoch 165/200, Iteration 140/250, Loss: 0.0155\n",
      "Epoch 165/200, Iteration 141/250, Loss: 0.0168\n",
      "Epoch 165/200, Iteration 142/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 143/250, Loss: 0.0126\n",
      "Epoch 165/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 165/200, Iteration 145/250, Loss: 0.0142\n",
      "Epoch 165/200, Iteration 146/250, Loss: 0.0121\n",
      "Epoch 165/200, Iteration 147/250, Loss: 0.0235\n",
      "Epoch 165/200, Iteration 148/250, Loss: 0.0096\n",
      "Epoch 165/200, Iteration 149/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 150/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 151/250, Loss: 0.0229\n",
      "Epoch 165/200, Iteration 152/250, Loss: 0.0195\n",
      "Epoch 165/200, Iteration 153/250, Loss: 0.0414\n",
      "Epoch 165/200, Iteration 154/250, Loss: 0.0093\n",
      "Epoch 165/200, Iteration 155/250, Loss: 0.0072\n",
      "Epoch 165/200, Iteration 156/250, Loss: 0.0172\n",
      "Epoch 165/200, Iteration 157/250, Loss: 0.0160\n",
      "Epoch 165/200, Iteration 158/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 159/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 160/250, Loss: 0.0157\n",
      "Epoch 165/200, Iteration 161/250, Loss: 0.0287\n",
      "Epoch 165/200, Iteration 162/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 163/250, Loss: 0.0078\n",
      "Epoch 165/200, Iteration 164/250, Loss: 0.0280\n",
      "Epoch 165/200, Iteration 165/250, Loss: 0.0102\n",
      "Epoch 165/200, Iteration 166/250, Loss: 0.0201\n",
      "Epoch 165/200, Iteration 167/250, Loss: 0.0110\n",
      "Epoch 165/200, Iteration 168/250, Loss: 0.0057\n",
      "Epoch 165/200, Iteration 169/250, Loss: 0.0317\n",
      "Epoch 165/200, Iteration 170/250, Loss: 0.0111\n",
      "Epoch 165/200, Iteration 171/250, Loss: 0.0092\n",
      "Epoch 165/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 165/200, Iteration 173/250, Loss: 0.0058\n",
      "Epoch 165/200, Iteration 174/250, Loss: 0.0084\n",
      "Epoch 165/200, Iteration 175/250, Loss: 0.0078\n",
      "Epoch 165/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 165/200, Iteration 177/250, Loss: 0.0084\n",
      "Epoch 165/200, Iteration 178/250, Loss: 0.0195\n",
      "Epoch 165/200, Iteration 179/250, Loss: 0.0228\n",
      "Epoch 165/200, Iteration 180/250, Loss: 0.0068\n",
      "Epoch 165/200, Iteration 181/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 182/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 183/250, Loss: 0.0043\n",
      "Epoch 165/200, Iteration 184/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 185/250, Loss: 0.0095\n",
      "Epoch 165/200, Iteration 186/250, Loss: 0.0112\n",
      "Epoch 165/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 165/200, Iteration 188/250, Loss: 0.0157\n",
      "Epoch 165/200, Iteration 189/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 190/250, Loss: 0.0184\n",
      "Epoch 165/200, Iteration 191/250, Loss: 0.0109\n",
      "Epoch 165/200, Iteration 192/250, Loss: 0.0267\n",
      "Epoch 165/200, Iteration 193/250, Loss: 0.0151\n",
      "Epoch 165/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 165/200, Iteration 195/250, Loss: 0.0179\n",
      "Epoch 165/200, Iteration 196/250, Loss: 0.0229\n",
      "Epoch 165/200, Iteration 197/250, Loss: 0.0072\n",
      "Epoch 165/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 199/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 200/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 201/250, Loss: 0.0121\n",
      "Epoch 165/200, Iteration 202/250, Loss: 0.0243\n",
      "Epoch 165/200, Iteration 203/250, Loss: 0.0075\n",
      "Epoch 165/200, Iteration 204/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 205/250, Loss: 0.0057\n",
      "Epoch 165/200, Iteration 206/250, Loss: 0.0094\n",
      "Epoch 165/200, Iteration 207/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 208/250, Loss: 0.0215\n",
      "Epoch 165/200, Iteration 209/250, Loss: 0.0095\n",
      "Epoch 165/200, Iteration 210/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 211/250, Loss: 0.0062\n",
      "Epoch 165/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 213/250, Loss: 0.0095\n",
      "Epoch 165/200, Iteration 214/250, Loss: 0.0063\n",
      "Epoch 165/200, Iteration 215/250, Loss: 0.0110\n",
      "Epoch 165/200, Iteration 216/250, Loss: 0.0166\n",
      "Epoch 165/200, Iteration 217/250, Loss: 0.0103\n",
      "Epoch 165/200, Iteration 218/250, Loss: 0.0209\n",
      "Epoch 165/200, Iteration 219/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 165/200, Iteration 221/250, Loss: 0.0054\n",
      "Epoch 165/200, Iteration 222/250, Loss: 0.0209\n",
      "Epoch 165/200, Iteration 223/250, Loss: 0.0067\n",
      "Epoch 165/200, Iteration 224/250, Loss: 0.0147\n",
      "Epoch 165/200, Iteration 225/250, Loss: 0.0226\n",
      "Epoch 165/200, Iteration 226/250, Loss: 0.0103\n",
      "Epoch 165/200, Iteration 227/250, Loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200, Iteration 228/250, Loss: 0.0166\n",
      "Epoch 165/200, Iteration 229/250, Loss: 0.0150\n",
      "Epoch 165/200, Iteration 230/250, Loss: 0.0060\n",
      "Epoch 165/200, Iteration 231/250, Loss: 0.0111\n",
      "Epoch 165/200, Iteration 232/250, Loss: 0.0189\n",
      "Epoch 165/200, Iteration 233/250, Loss: 0.0169\n",
      "Epoch 165/200, Iteration 234/250, Loss: 0.0048\n",
      "Epoch 165/200, Iteration 235/250, Loss: 0.0159\n",
      "Epoch 165/200, Iteration 236/250, Loss: 0.0096\n",
      "Epoch 165/200, Iteration 237/250, Loss: 0.0142\n",
      "Epoch 165/200, Iteration 238/250, Loss: 0.0064\n",
      "Epoch 165/200, Iteration 239/250, Loss: 0.0092\n",
      "Epoch 165/200, Iteration 240/250, Loss: 0.0087\n",
      "Epoch 165/200, Iteration 241/250, Loss: 0.0127\n",
      "Epoch 165/200, Iteration 242/250, Loss: 0.0177\n",
      "Epoch 165/200, Iteration 243/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 244/250, Loss: 0.0183\n",
      "Epoch 165/200, Iteration 245/250, Loss: 0.0173\n",
      "Epoch 165/200, Iteration 246/250, Loss: 0.0126\n",
      "Epoch 165/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 165/200, Iteration 248/250, Loss: 0.0092\n",
      "Epoch 165/200, Iteration 249/250, Loss: 0.0118\n",
      "Epoch 165/200, Iteration 250/250, Loss: 0.0096\n",
      "Train Error: \n",
      " Accuracy: 91.61%, Avg loss: 0.005834, MRE: 0.612690 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.35%, Avg loss: 0.005862, MRE: 0.925718 \n",
      "\n",
      "Epoch 166/200, Iteration 1/250, Loss: 0.0130\n",
      "Epoch 166/200, Iteration 2/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 3/250, Loss: 0.0327\n",
      "Epoch 166/200, Iteration 4/250, Loss: 0.0264\n",
      "Epoch 166/200, Iteration 5/250, Loss: 0.0082\n",
      "Epoch 166/200, Iteration 6/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 7/250, Loss: 0.0137\n",
      "Epoch 166/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 166/200, Iteration 9/250, Loss: 0.0145\n",
      "Epoch 166/200, Iteration 10/250, Loss: 0.0241\n",
      "Epoch 166/200, Iteration 11/250, Loss: 0.0321\n",
      "Epoch 166/200, Iteration 12/250, Loss: 0.0101\n",
      "Epoch 166/200, Iteration 13/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 14/250, Loss: 0.0208\n",
      "Epoch 166/200, Iteration 15/250, Loss: 0.0219\n",
      "Epoch 166/200, Iteration 16/250, Loss: 0.0232\n",
      "Epoch 166/200, Iteration 17/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 18/250, Loss: 0.0110\n",
      "Epoch 166/200, Iteration 19/250, Loss: 0.0091\n",
      "Epoch 166/200, Iteration 20/250, Loss: 0.0195\n",
      "Epoch 166/200, Iteration 21/250, Loss: 0.0080\n",
      "Epoch 166/200, Iteration 22/250, Loss: 0.0253\n",
      "Epoch 166/200, Iteration 23/250, Loss: 0.0180\n",
      "Epoch 166/200, Iteration 24/250, Loss: 0.0176\n",
      "Epoch 166/200, Iteration 25/250, Loss: 0.0069\n",
      "Epoch 166/200, Iteration 26/250, Loss: 0.0090\n",
      "Epoch 166/200, Iteration 27/250, Loss: 0.0144\n",
      "Epoch 166/200, Iteration 28/250, Loss: 0.0105\n",
      "Epoch 166/200, Iteration 29/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 30/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 31/250, Loss: 0.0086\n",
      "Epoch 166/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 166/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 166/200, Iteration 34/250, Loss: 0.0097\n",
      "Epoch 166/200, Iteration 35/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 36/250, Loss: 0.0074\n",
      "Epoch 166/200, Iteration 37/250, Loss: 0.0105\n",
      "Epoch 166/200, Iteration 38/250, Loss: 0.0097\n",
      "Epoch 166/200, Iteration 39/250, Loss: 0.0214\n",
      "Epoch 166/200, Iteration 40/250, Loss: 0.0106\n",
      "Epoch 166/200, Iteration 41/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 42/250, Loss: 0.0138\n",
      "Epoch 166/200, Iteration 43/250, Loss: 0.0089\n",
      "Epoch 166/200, Iteration 44/250, Loss: 0.0222\n",
      "Epoch 166/200, Iteration 45/250, Loss: 0.0078\n",
      "Epoch 166/200, Iteration 46/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 47/250, Loss: 0.0107\n",
      "Epoch 166/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 166/200, Iteration 49/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 50/250, Loss: 0.0171\n",
      "Epoch 166/200, Iteration 51/250, Loss: 0.0174\n",
      "Epoch 166/200, Iteration 52/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 53/250, Loss: 0.0115\n",
      "Epoch 166/200, Iteration 54/250, Loss: 0.0193\n",
      "Epoch 166/200, Iteration 55/250, Loss: 0.0231\n",
      "Epoch 166/200, Iteration 56/250, Loss: 0.0106\n",
      "Epoch 166/200, Iteration 57/250, Loss: 0.0052\n",
      "Epoch 166/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 166/200, Iteration 59/250, Loss: 0.0220\n",
      "Epoch 166/200, Iteration 60/250, Loss: 0.0080\n",
      "Epoch 166/200, Iteration 61/250, Loss: 0.0170\n",
      "Epoch 166/200, Iteration 62/250, Loss: 0.0185\n",
      "Epoch 166/200, Iteration 63/250, Loss: 0.0147\n",
      "Epoch 166/200, Iteration 64/250, Loss: 0.0071\n",
      "Epoch 166/200, Iteration 65/250, Loss: 0.0242\n",
      "Epoch 166/200, Iteration 66/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 67/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 68/250, Loss: 0.0247\n",
      "Epoch 166/200, Iteration 69/250, Loss: 0.0181\n",
      "Epoch 166/200, Iteration 70/250, Loss: 0.0263\n",
      "Epoch 166/200, Iteration 71/250, Loss: 0.0152\n",
      "Epoch 166/200, Iteration 72/250, Loss: 0.0098\n",
      "Epoch 166/200, Iteration 73/250, Loss: 0.0216\n",
      "Epoch 166/200, Iteration 74/250, Loss: 0.0143\n",
      "Epoch 166/200, Iteration 75/250, Loss: 0.0096\n",
      "Epoch 166/200, Iteration 76/250, Loss: 0.0407\n",
      "Epoch 166/200, Iteration 77/250, Loss: 0.0099\n",
      "Epoch 166/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 166/200, Iteration 79/250, Loss: 0.0317\n",
      "Epoch 166/200, Iteration 80/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 81/250, Loss: 0.0152\n",
      "Epoch 166/200, Iteration 82/250, Loss: 0.0098\n",
      "Epoch 166/200, Iteration 83/250, Loss: 0.0176\n",
      "Epoch 166/200, Iteration 84/250, Loss: 0.0269\n",
      "Epoch 166/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 86/250, Loss: 0.0142\n",
      "Epoch 166/200, Iteration 87/250, Loss: 0.0134\n",
      "Epoch 166/200, Iteration 88/250, Loss: 0.0251\n",
      "Epoch 166/200, Iteration 89/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 90/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 91/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 92/250, Loss: 0.0221\n",
      "Epoch 166/200, Iteration 93/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 94/250, Loss: 0.0070\n",
      "Epoch 166/200, Iteration 95/250, Loss: 0.0148\n",
      "Epoch 166/200, Iteration 96/250, Loss: 0.0113\n",
      "Epoch 166/200, Iteration 97/250, Loss: 0.0106\n",
      "Epoch 166/200, Iteration 98/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 99/250, Loss: 0.0249\n",
      "Epoch 166/200, Iteration 100/250, Loss: 0.0157\n",
      "Epoch 166/200, Iteration 101/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 102/250, Loss: 0.0074\n",
      "Epoch 166/200, Iteration 103/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 104/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 106/250, Loss: 0.0080\n",
      "Epoch 166/200, Iteration 107/250, Loss: 0.0171\n",
      "Epoch 166/200, Iteration 108/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 109/250, Loss: 0.0113\n",
      "Epoch 166/200, Iteration 110/250, Loss: 0.0110\n",
      "Epoch 166/200, Iteration 111/250, Loss: 0.0318\n",
      "Epoch 166/200, Iteration 112/250, Loss: 0.0126\n",
      "Epoch 166/200, Iteration 113/250, Loss: 0.0113\n",
      "Epoch 166/200, Iteration 114/250, Loss: 0.0203\n",
      "Epoch 166/200, Iteration 115/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 116/250, Loss: 0.0218\n",
      "Epoch 166/200, Iteration 117/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 118/250, Loss: 0.0133\n",
      "Epoch 166/200, Iteration 119/250, Loss: 0.0266\n",
      "Epoch 166/200, Iteration 120/250, Loss: 0.0212\n",
      "Epoch 166/200, Iteration 121/250, Loss: 0.0198\n",
      "Epoch 166/200, Iteration 122/250, Loss: 0.0130\n",
      "Epoch 166/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 166/200, Iteration 124/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 125/250, Loss: 0.0076\n",
      "Epoch 166/200, Iteration 126/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 127/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 166/200, Iteration 129/250, Loss: 0.0132\n",
      "Epoch 166/200, Iteration 130/250, Loss: 0.0149\n",
      "Epoch 166/200, Iteration 131/250, Loss: 0.0166\n",
      "Epoch 166/200, Iteration 132/250, Loss: 0.0111\n",
      "Epoch 166/200, Iteration 133/250, Loss: 0.0062\n",
      "Epoch 166/200, Iteration 134/250, Loss: 0.0218\n",
      "Epoch 166/200, Iteration 135/250, Loss: 0.0184\n",
      "Epoch 166/200, Iteration 136/250, Loss: 0.0160\n",
      "Epoch 166/200, Iteration 137/250, Loss: 0.0135\n",
      "Epoch 166/200, Iteration 138/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 139/250, Loss: 0.0254\n",
      "Epoch 166/200, Iteration 140/250, Loss: 0.0115\n",
      "Epoch 166/200, Iteration 141/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 142/250, Loss: 0.0294\n",
      "Epoch 166/200, Iteration 143/250, Loss: 0.0229\n",
      "Epoch 166/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 166/200, Iteration 145/250, Loss: 0.0188\n",
      "Epoch 166/200, Iteration 146/250, Loss: 0.0149\n",
      "Epoch 166/200, Iteration 147/250, Loss: 0.0148\n",
      "Epoch 166/200, Iteration 148/250, Loss: 0.0168\n",
      "Epoch 166/200, Iteration 149/250, Loss: 0.0177\n",
      "Epoch 166/200, Iteration 150/250, Loss: 0.0125\n",
      "Epoch 166/200, Iteration 151/250, Loss: 0.0157\n",
      "Epoch 166/200, Iteration 152/250, Loss: 0.0244\n",
      "Epoch 166/200, Iteration 153/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 154/250, Loss: 0.0198\n",
      "Epoch 166/200, Iteration 155/250, Loss: 0.0075\n",
      "Epoch 166/200, Iteration 156/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 157/250, Loss: 0.0161\n",
      "Epoch 166/200, Iteration 158/250, Loss: 0.0080\n",
      "Epoch 166/200, Iteration 159/250, Loss: 0.0169\n",
      "Epoch 166/200, Iteration 160/250, Loss: 0.0088\n",
      "Epoch 166/200, Iteration 161/250, Loss: 0.0086\n",
      "Epoch 166/200, Iteration 162/250, Loss: 0.0232\n",
      "Epoch 166/200, Iteration 163/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 164/250, Loss: 0.0333\n",
      "Epoch 166/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 166/200, Iteration 166/250, Loss: 0.0210\n",
      "Epoch 166/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 166/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 169/250, Loss: 0.0071\n",
      "Epoch 166/200, Iteration 170/250, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200, Iteration 171/250, Loss: 0.0118\n",
      "Epoch 166/200, Iteration 172/250, Loss: 0.0153\n",
      "Epoch 166/200, Iteration 173/250, Loss: 0.0113\n",
      "Epoch 166/200, Iteration 174/250, Loss: 0.0186\n",
      "Epoch 166/200, Iteration 175/250, Loss: 0.0214\n",
      "Epoch 166/200, Iteration 176/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 177/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 178/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 179/250, Loss: 0.0280\n",
      "Epoch 166/200, Iteration 180/250, Loss: 0.0251\n",
      "Epoch 166/200, Iteration 181/250, Loss: 0.0076\n",
      "Epoch 166/200, Iteration 182/250, Loss: 0.0064\n",
      "Epoch 166/200, Iteration 183/250, Loss: 0.0115\n",
      "Epoch 166/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 166/200, Iteration 185/250, Loss: 0.0211\n",
      "Epoch 166/200, Iteration 186/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 187/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 188/250, Loss: 0.0060\n",
      "Epoch 166/200, Iteration 189/250, Loss: 0.0123\n",
      "Epoch 166/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 191/250, Loss: 0.0157\n",
      "Epoch 166/200, Iteration 192/250, Loss: 0.0158\n",
      "Epoch 166/200, Iteration 193/250, Loss: 0.0123\n",
      "Epoch 166/200, Iteration 194/250, Loss: 0.0084\n",
      "Epoch 166/200, Iteration 195/250, Loss: 0.0191\n",
      "Epoch 166/200, Iteration 196/250, Loss: 0.0108\n",
      "Epoch 166/200, Iteration 197/250, Loss: 0.0262\n",
      "Epoch 166/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 166/200, Iteration 199/250, Loss: 0.0251\n",
      "Epoch 166/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 201/250, Loss: 0.0134\n",
      "Epoch 166/200, Iteration 202/250, Loss: 0.0272\n",
      "Epoch 166/200, Iteration 203/250, Loss: 0.0282\n",
      "Epoch 166/200, Iteration 204/250, Loss: 0.0130\n",
      "Epoch 166/200, Iteration 205/250, Loss: 0.0081\n",
      "Epoch 166/200, Iteration 206/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 207/250, Loss: 0.0162\n",
      "Epoch 166/200, Iteration 208/250, Loss: 0.0159\n",
      "Epoch 166/200, Iteration 209/250, Loss: 0.0171\n",
      "Epoch 166/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 166/200, Iteration 211/250, Loss: 0.0188\n",
      "Epoch 166/200, Iteration 212/250, Loss: 0.0150\n",
      "Epoch 166/200, Iteration 213/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 214/250, Loss: 0.0308\n",
      "Epoch 166/200, Iteration 215/250, Loss: 0.0213\n",
      "Epoch 166/200, Iteration 216/250, Loss: 0.0162\n",
      "Epoch 166/200, Iteration 217/250, Loss: 0.0149\n",
      "Epoch 166/200, Iteration 218/250, Loss: 0.0169\n",
      "Epoch 166/200, Iteration 219/250, Loss: 0.0201\n",
      "Epoch 166/200, Iteration 220/250, Loss: 0.0066\n",
      "Epoch 166/200, Iteration 221/250, Loss: 0.0065\n",
      "Epoch 166/200, Iteration 222/250, Loss: 0.0272\n",
      "Epoch 166/200, Iteration 223/250, Loss: 0.0140\n",
      "Epoch 166/200, Iteration 224/250, Loss: 0.0217\n",
      "Epoch 166/200, Iteration 225/250, Loss: 0.0081\n",
      "Epoch 166/200, Iteration 226/250, Loss: 0.0173\n",
      "Epoch 166/200, Iteration 227/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 228/250, Loss: 0.0167\n",
      "Epoch 166/200, Iteration 229/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 230/250, Loss: 0.0078\n",
      "Epoch 166/200, Iteration 231/250, Loss: 0.0135\n",
      "Epoch 166/200, Iteration 232/250, Loss: 0.0158\n",
      "Epoch 166/200, Iteration 233/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 234/250, Loss: 0.0089\n",
      "Epoch 166/200, Iteration 235/250, Loss: 0.0139\n",
      "Epoch 166/200, Iteration 236/250, Loss: 0.0303\n",
      "Epoch 166/200, Iteration 237/250, Loss: 0.0206\n",
      "Epoch 166/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 166/200, Iteration 239/250, Loss: 0.0149\n",
      "Epoch 166/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 166/200, Iteration 241/250, Loss: 0.0098\n",
      "Epoch 166/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 243/250, Loss: 0.0141\n",
      "Epoch 166/200, Iteration 244/250, Loss: 0.0291\n",
      "Epoch 166/200, Iteration 245/250, Loss: 0.0481\n",
      "Epoch 166/200, Iteration 246/250, Loss: 0.0341\n",
      "Epoch 166/200, Iteration 247/250, Loss: 0.0139\n",
      "Epoch 166/200, Iteration 248/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 249/250, Loss: 0.0184\n",
      "Epoch 166/200, Iteration 250/250, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 77.09%, Avg loss: 0.007525, MRE: 0.638065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.007615, MRE: 0.864308 \n",
      "\n",
      "Epoch 167/200, Iteration 1/250, Loss: 0.0093\n",
      "Epoch 167/200, Iteration 2/250, Loss: 0.0107\n",
      "Epoch 167/200, Iteration 3/250, Loss: 0.0161\n",
      "Epoch 167/200, Iteration 4/250, Loss: 0.0131\n",
      "Epoch 167/200, Iteration 5/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 167/200, Iteration 7/250, Loss: 0.0064\n",
      "Epoch 167/200, Iteration 8/250, Loss: 0.0106\n",
      "Epoch 167/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 10/250, Loss: 0.0085\n",
      "Epoch 167/200, Iteration 11/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 12/250, Loss: 0.0056\n",
      "Epoch 167/200, Iteration 13/250, Loss: 0.0104\n",
      "Epoch 167/200, Iteration 14/250, Loss: 0.0164\n",
      "Epoch 167/200, Iteration 15/250, Loss: 0.0117\n",
      "Epoch 167/200, Iteration 16/250, Loss: 0.0386\n",
      "Epoch 167/200, Iteration 17/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 18/250, Loss: 0.0189\n",
      "Epoch 167/200, Iteration 19/250, Loss: 0.0096\n",
      "Epoch 167/200, Iteration 20/250, Loss: 0.0235\n",
      "Epoch 167/200, Iteration 21/250, Loss: 0.0221\n",
      "Epoch 167/200, Iteration 22/250, Loss: 0.0128\n",
      "Epoch 167/200, Iteration 23/250, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 24/250, Loss: 0.0195\n",
      "Epoch 167/200, Iteration 25/250, Loss: 0.0083\n",
      "Epoch 167/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 167/200, Iteration 27/250, Loss: 0.0077\n",
      "Epoch 167/200, Iteration 28/250, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 29/250, Loss: 0.0131\n",
      "Epoch 167/200, Iteration 30/250, Loss: 0.0123\n",
      "Epoch 167/200, Iteration 31/250, Loss: 0.0154\n",
      "Epoch 167/200, Iteration 32/250, Loss: 0.0084\n",
      "Epoch 167/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 167/200, Iteration 34/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 35/250, Loss: 0.0202\n",
      "Epoch 167/200, Iteration 36/250, Loss: 0.0258\n",
      "Epoch 167/200, Iteration 37/250, Loss: 0.0181\n",
      "Epoch 167/200, Iteration 38/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 39/250, Loss: 0.0070\n",
      "Epoch 167/200, Iteration 40/250, Loss: 0.0233\n",
      "Epoch 167/200, Iteration 41/250, Loss: 0.0086\n",
      "Epoch 167/200, Iteration 42/250, Loss: 0.0122\n",
      "Epoch 167/200, Iteration 43/250, Loss: 0.0153\n",
      "Epoch 167/200, Iteration 44/250, Loss: 0.0179\n",
      "Epoch 167/200, Iteration 45/250, Loss: 0.0146\n",
      "Epoch 167/200, Iteration 46/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 47/250, Loss: 0.0119\n",
      "Epoch 167/200, Iteration 48/250, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 49/250, Loss: 0.0074\n",
      "Epoch 167/200, Iteration 50/250, Loss: 0.0240\n",
      "Epoch 167/200, Iteration 51/250, Loss: 0.0095\n",
      "Epoch 167/200, Iteration 52/250, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 53/250, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 54/250, Loss: 0.0202\n",
      "Epoch 167/200, Iteration 55/250, Loss: 0.0366\n",
      "Epoch 167/200, Iteration 56/250, Loss: 0.0079\n",
      "Epoch 167/200, Iteration 57/250, Loss: 0.0193\n",
      "Epoch 167/200, Iteration 58/250, Loss: 0.0108\n",
      "Epoch 167/200, Iteration 59/250, Loss: 0.0083\n",
      "Epoch 167/200, Iteration 60/250, Loss: 0.0085\n",
      "Epoch 167/200, Iteration 61/250, Loss: 0.0210\n",
      "Epoch 167/200, Iteration 62/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 63/250, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 65/250, Loss: 0.0134\n",
      "Epoch 167/200, Iteration 66/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 67/250, Loss: 0.0116\n",
      "Epoch 167/200, Iteration 68/250, Loss: 0.0120\n",
      "Epoch 167/200, Iteration 69/250, Loss: 0.0113\n",
      "Epoch 167/200, Iteration 70/250, Loss: 0.0120\n",
      "Epoch 167/200, Iteration 71/250, Loss: 0.0361\n",
      "Epoch 167/200, Iteration 72/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 73/250, Loss: 0.0156\n",
      "Epoch 167/200, Iteration 74/250, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 75/250, Loss: 0.0164\n",
      "Epoch 167/200, Iteration 76/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 167/200, Iteration 78/250, Loss: 0.0232\n",
      "Epoch 167/200, Iteration 79/250, Loss: 0.0062\n",
      "Epoch 167/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 81/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 82/250, Loss: 0.0167\n",
      "Epoch 167/200, Iteration 83/250, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 84/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 85/250, Loss: 0.0235\n",
      "Epoch 167/200, Iteration 86/250, Loss: 0.0284\n",
      "Epoch 167/200, Iteration 87/250, Loss: 0.0111\n",
      "Epoch 167/200, Iteration 88/250, Loss: 0.0177\n",
      "Epoch 167/200, Iteration 89/250, Loss: 0.0068\n",
      "Epoch 167/200, Iteration 90/250, Loss: 0.0180\n",
      "Epoch 167/200, Iteration 91/250, Loss: 0.0127\n",
      "Epoch 167/200, Iteration 92/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 93/250, Loss: 0.0121\n",
      "Epoch 167/200, Iteration 94/250, Loss: 0.0142\n",
      "Epoch 167/200, Iteration 95/250, Loss: 0.0213\n",
      "Epoch 167/200, Iteration 96/250, Loss: 0.0094\n",
      "Epoch 167/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 98/250, Loss: 0.0123\n",
      "Epoch 167/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 167/200, Iteration 100/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 101/250, Loss: 0.0074\n",
      "Epoch 167/200, Iteration 102/250, Loss: 0.0132\n",
      "Epoch 167/200, Iteration 103/250, Loss: 0.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200, Iteration 104/250, Loss: 0.0249\n",
      "Epoch 167/200, Iteration 105/250, Loss: 0.0173\n",
      "Epoch 167/200, Iteration 106/250, Loss: 0.0123\n",
      "Epoch 167/200, Iteration 107/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 108/250, Loss: 0.0098\n",
      "Epoch 167/200, Iteration 109/250, Loss: 0.0064\n",
      "Epoch 167/200, Iteration 110/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 111/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 112/250, Loss: 0.0167\n",
      "Epoch 167/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 114/250, Loss: 0.0260\n",
      "Epoch 167/200, Iteration 115/250, Loss: 0.0228\n",
      "Epoch 167/200, Iteration 116/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 117/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 118/250, Loss: 0.0118\n",
      "Epoch 167/200, Iteration 119/250, Loss: 0.0254\n",
      "Epoch 167/200, Iteration 120/250, Loss: 0.0061\n",
      "Epoch 167/200, Iteration 121/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 122/250, Loss: 0.0171\n",
      "Epoch 167/200, Iteration 123/250, Loss: 0.0183\n",
      "Epoch 167/200, Iteration 124/250, Loss: 0.0332\n",
      "Epoch 167/200, Iteration 125/250, Loss: 0.0117\n",
      "Epoch 167/200, Iteration 126/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 167/200, Iteration 128/250, Loss: 0.0205\n",
      "Epoch 167/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 130/250, Loss: 0.0222\n",
      "Epoch 167/200, Iteration 131/250, Loss: 0.0153\n",
      "Epoch 167/200, Iteration 132/250, Loss: 0.0174\n",
      "Epoch 167/200, Iteration 133/250, Loss: 0.0171\n",
      "Epoch 167/200, Iteration 134/250, Loss: 0.0220\n",
      "Epoch 167/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 167/200, Iteration 136/250, Loss: 0.0123\n",
      "Epoch 167/200, Iteration 137/250, Loss: 0.0130\n",
      "Epoch 167/200, Iteration 138/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 167/200, Iteration 140/250, Loss: 0.0053\n",
      "Epoch 167/200, Iteration 141/250, Loss: 0.0139\n",
      "Epoch 167/200, Iteration 142/250, Loss: 0.0206\n",
      "Epoch 167/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 167/200, Iteration 144/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 145/250, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 146/250, Loss: 0.0136\n",
      "Epoch 167/200, Iteration 147/250, Loss: 0.0339\n",
      "Epoch 167/200, Iteration 148/250, Loss: 0.0170\n",
      "Epoch 167/200, Iteration 149/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 150/250, Loss: 0.0069\n",
      "Epoch 167/200, Iteration 151/250, Loss: 0.0108\n",
      "Epoch 167/200, Iteration 152/250, Loss: 0.0228\n",
      "Epoch 167/200, Iteration 153/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 154/250, Loss: 0.0151\n",
      "Epoch 167/200, Iteration 155/250, Loss: 0.0235\n",
      "Epoch 167/200, Iteration 156/250, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 157/250, Loss: 0.0127\n",
      "Epoch 167/200, Iteration 158/250, Loss: 0.0133\n",
      "Epoch 167/200, Iteration 159/250, Loss: 0.0205\n",
      "Epoch 167/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 161/250, Loss: 0.0204\n",
      "Epoch 167/200, Iteration 162/250, Loss: 0.0197\n",
      "Epoch 167/200, Iteration 163/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 164/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 165/250, Loss: 0.0266\n",
      "Epoch 167/200, Iteration 166/250, Loss: 0.0073\n",
      "Epoch 167/200, Iteration 167/250, Loss: 0.0090\n",
      "Epoch 167/200, Iteration 168/250, Loss: 0.0101\n",
      "Epoch 167/200, Iteration 169/250, Loss: 0.0121\n",
      "Epoch 167/200, Iteration 170/250, Loss: 0.0340\n",
      "Epoch 167/200, Iteration 171/250, Loss: 0.0230\n",
      "Epoch 167/200, Iteration 172/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 173/250, Loss: 0.0141\n",
      "Epoch 167/200, Iteration 174/250, Loss: 0.0188\n",
      "Epoch 167/200, Iteration 175/250, Loss: 0.0111\n",
      "Epoch 167/200, Iteration 176/250, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 177/250, Loss: 0.0210\n",
      "Epoch 167/200, Iteration 178/250, Loss: 0.0203\n",
      "Epoch 167/200, Iteration 179/250, Loss: 0.0175\n",
      "Epoch 167/200, Iteration 180/250, Loss: 0.0147\n",
      "Epoch 167/200, Iteration 181/250, Loss: 0.0133\n",
      "Epoch 167/200, Iteration 182/250, Loss: 0.0242\n",
      "Epoch 167/200, Iteration 183/250, Loss: 0.0226\n",
      "Epoch 167/200, Iteration 184/250, Loss: 0.0237\n",
      "Epoch 167/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 167/200, Iteration 186/250, Loss: 0.0193\n",
      "Epoch 167/200, Iteration 187/250, Loss: 0.0199\n",
      "Epoch 167/200, Iteration 188/250, Loss: 0.0187\n",
      "Epoch 167/200, Iteration 189/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 190/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 167/200, Iteration 192/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 194/250, Loss: 0.0364\n",
      "Epoch 167/200, Iteration 195/250, Loss: 0.0071\n",
      "Epoch 167/200, Iteration 196/250, Loss: 0.0094\n",
      "Epoch 167/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 167/200, Iteration 198/250, Loss: 0.0086\n",
      "Epoch 167/200, Iteration 199/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 200/250, Loss: 0.0366\n",
      "Epoch 167/200, Iteration 201/250, Loss: 0.0061\n",
      "Epoch 167/200, Iteration 202/250, Loss: 0.0101\n",
      "Epoch 167/200, Iteration 203/250, Loss: 0.0086\n",
      "Epoch 167/200, Iteration 204/250, Loss: 0.0151\n",
      "Epoch 167/200, Iteration 205/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 206/250, Loss: 0.0118\n",
      "Epoch 167/200, Iteration 207/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 208/250, Loss: 0.0067\n",
      "Epoch 167/200, Iteration 209/250, Loss: 0.0179\n",
      "Epoch 167/200, Iteration 210/250, Loss: 0.0083\n",
      "Epoch 167/200, Iteration 211/250, Loss: 0.0243\n",
      "Epoch 167/200, Iteration 212/250, Loss: 0.0122\n",
      "Epoch 167/200, Iteration 213/250, Loss: 0.0274\n",
      "Epoch 167/200, Iteration 214/250, Loss: 0.0290\n",
      "Epoch 167/200, Iteration 215/250, Loss: 0.0159\n",
      "Epoch 167/200, Iteration 216/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 217/250, Loss: 0.0239\n",
      "Epoch 167/200, Iteration 218/250, Loss: 0.0189\n",
      "Epoch 167/200, Iteration 219/250, Loss: 0.0241\n",
      "Epoch 167/200, Iteration 220/250, Loss: 0.0098\n",
      "Epoch 167/200, Iteration 221/250, Loss: 0.0202\n",
      "Epoch 167/200, Iteration 222/250, Loss: 0.0130\n",
      "Epoch 167/200, Iteration 223/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 224/250, Loss: 0.0079\n",
      "Epoch 167/200, Iteration 225/250, Loss: 0.0072\n",
      "Epoch 167/200, Iteration 226/250, Loss: 0.0116\n",
      "Epoch 167/200, Iteration 227/250, Loss: 0.0200\n",
      "Epoch 167/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 167/200, Iteration 229/250, Loss: 0.0152\n",
      "Epoch 167/200, Iteration 230/250, Loss: 0.0140\n",
      "Epoch 167/200, Iteration 231/250, Loss: 0.0249\n",
      "Epoch 167/200, Iteration 232/250, Loss: 0.0098\n",
      "Epoch 167/200, Iteration 233/250, Loss: 0.0125\n",
      "Epoch 167/200, Iteration 234/250, Loss: 0.0132\n",
      "Epoch 167/200, Iteration 235/250, Loss: 0.0272\n",
      "Epoch 167/200, Iteration 236/250, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 237/250, Loss: 0.0375\n",
      "Epoch 167/200, Iteration 238/250, Loss: 0.0175\n",
      "Epoch 167/200, Iteration 239/250, Loss: 0.0187\n",
      "Epoch 167/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 241/250, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 243/250, Loss: 0.0072\n",
      "Epoch 167/200, Iteration 244/250, Loss: 0.0093\n",
      "Epoch 167/200, Iteration 245/250, Loss: 0.0135\n",
      "Epoch 167/200, Iteration 246/250, Loss: 0.0165\n",
      "Epoch 167/200, Iteration 247/250, Loss: 0.0232\n",
      "Epoch 167/200, Iteration 248/250, Loss: 0.0081\n",
      "Epoch 167/200, Iteration 249/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 250/250, Loss: 0.0077\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.005614, MRE: 0.608745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.005581, MRE: 1.006691 \n",
      "\n",
      "Epoch 168/200, Iteration 1/250, Loss: 0.0281\n",
      "Epoch 168/200, Iteration 2/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 3/250, Loss: 0.0120\n",
      "Epoch 168/200, Iteration 4/250, Loss: 0.0101\n",
      "Epoch 168/200, Iteration 5/250, Loss: 0.0306\n",
      "Epoch 168/200, Iteration 6/250, Loss: 0.0077\n",
      "Epoch 168/200, Iteration 7/250, Loss: 0.0076\n",
      "Epoch 168/200, Iteration 8/250, Loss: 0.0223\n",
      "Epoch 168/200, Iteration 9/250, Loss: 0.0184\n",
      "Epoch 168/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 168/200, Iteration 11/250, Loss: 0.0453\n",
      "Epoch 168/200, Iteration 12/250, Loss: 0.0125\n",
      "Epoch 168/200, Iteration 13/250, Loss: 0.0086\n",
      "Epoch 168/200, Iteration 14/250, Loss: 0.0375\n",
      "Epoch 168/200, Iteration 15/250, Loss: 0.0088\n",
      "Epoch 168/200, Iteration 16/250, Loss: 0.0046\n",
      "Epoch 168/200, Iteration 17/250, Loss: 0.0177\n",
      "Epoch 168/200, Iteration 18/250, Loss: 0.0097\n",
      "Epoch 168/200, Iteration 19/250, Loss: 0.0345\n",
      "Epoch 168/200, Iteration 20/250, Loss: 0.0284\n",
      "Epoch 168/200, Iteration 21/250, Loss: 0.0146\n",
      "Epoch 168/200, Iteration 22/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 23/250, Loss: 0.0186\n",
      "Epoch 168/200, Iteration 24/250, Loss: 0.0140\n",
      "Epoch 168/200, Iteration 25/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 26/250, Loss: 0.0315\n",
      "Epoch 168/200, Iteration 27/250, Loss: 0.0136\n",
      "Epoch 168/200, Iteration 28/250, Loss: 0.0114\n",
      "Epoch 168/200, Iteration 29/250, Loss: 0.0184\n",
      "Epoch 168/200, Iteration 30/250, Loss: 0.0160\n",
      "Epoch 168/200, Iteration 31/250, Loss: 0.0193\n",
      "Epoch 168/200, Iteration 32/250, Loss: 0.0142\n",
      "Epoch 168/200, Iteration 33/250, Loss: 0.0061\n",
      "Epoch 168/200, Iteration 34/250, Loss: 0.0133\n",
      "Epoch 168/200, Iteration 35/250, Loss: 0.0122\n",
      "Epoch 168/200, Iteration 36/250, Loss: 0.0219\n",
      "Epoch 168/200, Iteration 37/250, Loss: 0.0238\n",
      "Epoch 168/200, Iteration 38/250, Loss: 0.0069\n",
      "Epoch 168/200, Iteration 39/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 40/250, Loss: 0.0072\n",
      "Epoch 168/200, Iteration 41/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 42/250, Loss: 0.0081\n",
      "Epoch 168/200, Iteration 43/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 44/250, Loss: 0.0041\n",
      "Epoch 168/200, Iteration 45/250, Loss: 0.0192\n",
      "Epoch 168/200, Iteration 46/250, Loss: 0.0204\n",
      "Epoch 168/200, Iteration 47/250, Loss: 0.0178\n",
      "Epoch 168/200, Iteration 48/250, Loss: 0.0201\n",
      "Epoch 168/200, Iteration 49/250, Loss: 0.0077\n",
      "Epoch 168/200, Iteration 50/250, Loss: 0.0387\n",
      "Epoch 168/200, Iteration 51/250, Loss: 0.0095\n",
      "Epoch 168/200, Iteration 52/250, Loss: 0.0131\n",
      "Epoch 168/200, Iteration 53/250, Loss: 0.0154\n",
      "Epoch 168/200, Iteration 54/250, Loss: 0.0075\n",
      "Epoch 168/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 168/200, Iteration 56/250, Loss: 0.0081\n",
      "Epoch 168/200, Iteration 57/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 58/250, Loss: 0.0149\n",
      "Epoch 168/200, Iteration 59/250, Loss: 0.0230\n",
      "Epoch 168/200, Iteration 60/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 61/250, Loss: 0.0085\n",
      "Epoch 168/200, Iteration 62/250, Loss: 0.0155\n",
      "Epoch 168/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 168/200, Iteration 64/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 65/250, Loss: 0.0130\n",
      "Epoch 168/200, Iteration 66/250, Loss: 0.0094\n",
      "Epoch 168/200, Iteration 67/250, Loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200, Iteration 68/250, Loss: 0.0155\n",
      "Epoch 168/200, Iteration 69/250, Loss: 0.0108\n",
      "Epoch 168/200, Iteration 70/250, Loss: 0.0189\n",
      "Epoch 168/200, Iteration 71/250, Loss: 0.0127\n",
      "Epoch 168/200, Iteration 72/250, Loss: 0.0359\n",
      "Epoch 168/200, Iteration 73/250, Loss: 0.0066\n",
      "Epoch 168/200, Iteration 74/250, Loss: 0.0079\n",
      "Epoch 168/200, Iteration 75/250, Loss: 0.0225\n",
      "Epoch 168/200, Iteration 76/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 77/250, Loss: 0.0108\n",
      "Epoch 168/200, Iteration 78/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 79/250, Loss: 0.0188\n",
      "Epoch 168/200, Iteration 80/250, Loss: 0.0085\n",
      "Epoch 168/200, Iteration 81/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 82/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 83/250, Loss: 0.0097\n",
      "Epoch 168/200, Iteration 84/250, Loss: 0.0200\n",
      "Epoch 168/200, Iteration 85/250, Loss: 0.0254\n",
      "Epoch 168/200, Iteration 86/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 87/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 88/250, Loss: 0.0170\n",
      "Epoch 168/200, Iteration 89/250, Loss: 0.0216\n",
      "Epoch 168/200, Iteration 90/250, Loss: 0.0134\n",
      "Epoch 168/200, Iteration 91/250, Loss: 0.0160\n",
      "Epoch 168/200, Iteration 92/250, Loss: 0.0076\n",
      "Epoch 168/200, Iteration 93/250, Loss: 0.0290\n",
      "Epoch 168/200, Iteration 94/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 95/250, Loss: 0.0317\n",
      "Epoch 168/200, Iteration 96/250, Loss: 0.0084\n",
      "Epoch 168/200, Iteration 97/250, Loss: 0.0151\n",
      "Epoch 168/200, Iteration 98/250, Loss: 0.0150\n",
      "Epoch 168/200, Iteration 99/250, Loss: 0.0072\n",
      "Epoch 168/200, Iteration 100/250, Loss: 0.0106\n",
      "Epoch 168/200, Iteration 101/250, Loss: 0.0075\n",
      "Epoch 168/200, Iteration 102/250, Loss: 0.0079\n",
      "Epoch 168/200, Iteration 103/250, Loss: 0.0195\n",
      "Epoch 168/200, Iteration 104/250, Loss: 0.0138\n",
      "Epoch 168/200, Iteration 105/250, Loss: 0.0064\n",
      "Epoch 168/200, Iteration 106/250, Loss: 0.0065\n",
      "Epoch 168/200, Iteration 107/250, Loss: 0.0084\n",
      "Epoch 168/200, Iteration 108/250, Loss: 0.0112\n",
      "Epoch 168/200, Iteration 109/250, Loss: 0.0155\n",
      "Epoch 168/200, Iteration 110/250, Loss: 0.0170\n",
      "Epoch 168/200, Iteration 111/250, Loss: 0.0185\n",
      "Epoch 168/200, Iteration 112/250, Loss: 0.0260\n",
      "Epoch 168/200, Iteration 113/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 114/250, Loss: 0.0139\n",
      "Epoch 168/200, Iteration 115/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 116/250, Loss: 0.0163\n",
      "Epoch 168/200, Iteration 117/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 118/250, Loss: 0.0088\n",
      "Epoch 168/200, Iteration 119/250, Loss: 0.0165\n",
      "Epoch 168/200, Iteration 120/250, Loss: 0.0054\n",
      "Epoch 168/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 122/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 124/250, Loss: 0.0205\n",
      "Epoch 168/200, Iteration 125/250, Loss: 0.0307\n",
      "Epoch 168/200, Iteration 126/250, Loss: 0.0086\n",
      "Epoch 168/200, Iteration 127/250, Loss: 0.0132\n",
      "Epoch 168/200, Iteration 128/250, Loss: 0.0136\n",
      "Epoch 168/200, Iteration 129/250, Loss: 0.0187\n",
      "Epoch 168/200, Iteration 130/250, Loss: 0.0232\n",
      "Epoch 168/200, Iteration 131/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 132/250, Loss: 0.0130\n",
      "Epoch 168/200, Iteration 133/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 134/250, Loss: 0.0181\n",
      "Epoch 168/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 136/250, Loss: 0.0072\n",
      "Epoch 168/200, Iteration 137/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 138/250, Loss: 0.0064\n",
      "Epoch 168/200, Iteration 139/250, Loss: 0.0221\n",
      "Epoch 168/200, Iteration 140/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 141/250, Loss: 0.0073\n",
      "Epoch 168/200, Iteration 142/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 143/250, Loss: 0.0096\n",
      "Epoch 168/200, Iteration 144/250, Loss: 0.0089\n",
      "Epoch 168/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 168/200, Iteration 146/250, Loss: 0.0075\n",
      "Epoch 168/200, Iteration 147/250, Loss: 0.0185\n",
      "Epoch 168/200, Iteration 148/250, Loss: 0.0153\n",
      "Epoch 168/200, Iteration 149/250, Loss: 0.0123\n",
      "Epoch 168/200, Iteration 150/250, Loss: 0.0172\n",
      "Epoch 168/200, Iteration 151/250, Loss: 0.0193\n",
      "Epoch 168/200, Iteration 152/250, Loss: 0.0174\n",
      "Epoch 168/200, Iteration 153/250, Loss: 0.0398\n",
      "Epoch 168/200, Iteration 154/250, Loss: 0.0127\n",
      "Epoch 168/200, Iteration 155/250, Loss: 0.0118\n",
      "Epoch 168/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 157/250, Loss: 0.0187\n",
      "Epoch 168/200, Iteration 158/250, Loss: 0.0333\n",
      "Epoch 168/200, Iteration 159/250, Loss: 0.0218\n",
      "Epoch 168/200, Iteration 160/250, Loss: 0.0215\n",
      "Epoch 168/200, Iteration 161/250, Loss: 0.0103\n",
      "Epoch 168/200, Iteration 162/250, Loss: 0.0111\n",
      "Epoch 168/200, Iteration 163/250, Loss: 0.0228\n",
      "Epoch 168/200, Iteration 164/250, Loss: 0.0210\n",
      "Epoch 168/200, Iteration 165/250, Loss: 0.0096\n",
      "Epoch 168/200, Iteration 166/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 168/200, Iteration 168/250, Loss: 0.0205\n",
      "Epoch 168/200, Iteration 169/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 170/250, Loss: 0.0083\n",
      "Epoch 168/200, Iteration 171/250, Loss: 0.0069\n",
      "Epoch 168/200, Iteration 172/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 173/250, Loss: 0.0108\n",
      "Epoch 168/200, Iteration 174/250, Loss: 0.0057\n",
      "Epoch 168/200, Iteration 175/250, Loss: 0.0202\n",
      "Epoch 168/200, Iteration 176/250, Loss: 0.0479\n",
      "Epoch 168/200, Iteration 177/250, Loss: 0.0139\n",
      "Epoch 168/200, Iteration 178/250, Loss: 0.0101\n",
      "Epoch 168/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 168/200, Iteration 180/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 181/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 182/250, Loss: 0.0129\n",
      "Epoch 168/200, Iteration 183/250, Loss: 0.0132\n",
      "Epoch 168/200, Iteration 184/250, Loss: 0.0142\n",
      "Epoch 168/200, Iteration 185/250, Loss: 0.0196\n",
      "Epoch 168/200, Iteration 186/250, Loss: 0.0268\n",
      "Epoch 168/200, Iteration 187/250, Loss: 0.0180\n",
      "Epoch 168/200, Iteration 188/250, Loss: 0.0160\n",
      "Epoch 168/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 168/200, Iteration 190/250, Loss: 0.0237\n",
      "Epoch 168/200, Iteration 191/250, Loss: 0.0086\n",
      "Epoch 168/200, Iteration 192/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 193/250, Loss: 0.0203\n",
      "Epoch 168/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 168/200, Iteration 196/250, Loss: 0.0187\n",
      "Epoch 168/200, Iteration 197/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 198/250, Loss: 0.0083\n",
      "Epoch 168/200, Iteration 199/250, Loss: 0.0240\n",
      "Epoch 168/200, Iteration 200/250, Loss: 0.0205\n",
      "Epoch 168/200, Iteration 201/250, Loss: 0.0103\n",
      "Epoch 168/200, Iteration 202/250, Loss: 0.0182\n",
      "Epoch 168/200, Iteration 203/250, Loss: 0.0080\n",
      "Epoch 168/200, Iteration 204/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 205/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 206/250, Loss: 0.0057\n",
      "Epoch 168/200, Iteration 207/250, Loss: 0.0203\n",
      "Epoch 168/200, Iteration 208/250, Loss: 0.0201\n",
      "Epoch 168/200, Iteration 209/250, Loss: 0.0071\n",
      "Epoch 168/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 168/200, Iteration 211/250, Loss: 0.0129\n",
      "Epoch 168/200, Iteration 212/250, Loss: 0.0198\n",
      "Epoch 168/200, Iteration 213/250, Loss: 0.0080\n",
      "Epoch 168/200, Iteration 214/250, Loss: 0.0204\n",
      "Epoch 168/200, Iteration 215/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 216/250, Loss: 0.0146\n",
      "Epoch 168/200, Iteration 217/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 218/250, Loss: 0.0137\n",
      "Epoch 168/200, Iteration 219/250, Loss: 0.0163\n",
      "Epoch 168/200, Iteration 220/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 221/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 222/250, Loss: 0.0190\n",
      "Epoch 168/200, Iteration 223/250, Loss: 0.0191\n",
      "Epoch 168/200, Iteration 224/250, Loss: 0.0148\n",
      "Epoch 168/200, Iteration 225/250, Loss: 0.0118\n",
      "Epoch 168/200, Iteration 226/250, Loss: 0.0275\n",
      "Epoch 168/200, Iteration 227/250, Loss: 0.0136\n",
      "Epoch 168/200, Iteration 228/250, Loss: 0.0173\n",
      "Epoch 168/200, Iteration 229/250, Loss: 0.0161\n",
      "Epoch 168/200, Iteration 230/250, Loss: 0.0217\n",
      "Epoch 168/200, Iteration 231/250, Loss: 0.0120\n",
      "Epoch 168/200, Iteration 232/250, Loss: 0.0129\n",
      "Epoch 168/200, Iteration 233/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 234/250, Loss: 0.0144\n",
      "Epoch 168/200, Iteration 235/250, Loss: 0.0070\n",
      "Epoch 168/200, Iteration 236/250, Loss: 0.0056\n",
      "Epoch 168/200, Iteration 237/250, Loss: 0.0165\n",
      "Epoch 168/200, Iteration 238/250, Loss: 0.0327\n",
      "Epoch 168/200, Iteration 239/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 240/250, Loss: 0.0119\n",
      "Epoch 168/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 168/200, Iteration 242/250, Loss: 0.0243\n",
      "Epoch 168/200, Iteration 243/250, Loss: 0.0146\n",
      "Epoch 168/200, Iteration 244/250, Loss: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200, Iteration 245/250, Loss: 0.0152\n",
      "Epoch 168/200, Iteration 246/250, Loss: 0.0154\n",
      "Epoch 168/200, Iteration 247/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 248/250, Loss: 0.0139\n",
      "Epoch 168/200, Iteration 249/250, Loss: 0.0134\n",
      "Epoch 168/200, Iteration 250/250, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 97.36%, Avg loss: 0.006022, MRE: 0.666873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.005970, MRE: 1.012745 \n",
      "\n",
      "Epoch 169/200, Iteration 1/250, Loss: 0.0189\n",
      "Epoch 169/200, Iteration 2/250, Loss: 0.0261\n",
      "Epoch 169/200, Iteration 3/250, Loss: 0.0117\n",
      "Epoch 169/200, Iteration 4/250, Loss: 0.0165\n",
      "Epoch 169/200, Iteration 5/250, Loss: 0.0057\n",
      "Epoch 169/200, Iteration 6/250, Loss: 0.0115\n",
      "Epoch 169/200, Iteration 7/250, Loss: 0.0106\n",
      "Epoch 169/200, Iteration 8/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 9/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 10/250, Loss: 0.0228\n",
      "Epoch 169/200, Iteration 11/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 12/250, Loss: 0.0303\n",
      "Epoch 169/200, Iteration 13/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 14/250, Loss: 0.0263\n",
      "Epoch 169/200, Iteration 15/250, Loss: 0.0212\n",
      "Epoch 169/200, Iteration 16/250, Loss: 0.0073\n",
      "Epoch 169/200, Iteration 17/250, Loss: 0.0067\n",
      "Epoch 169/200, Iteration 18/250, Loss: 0.0116\n",
      "Epoch 169/200, Iteration 19/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 20/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 21/250, Loss: 0.0231\n",
      "Epoch 169/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 169/200, Iteration 23/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 24/250, Loss: 0.0111\n",
      "Epoch 169/200, Iteration 25/250, Loss: 0.0155\n",
      "Epoch 169/200, Iteration 26/250, Loss: 0.0076\n",
      "Epoch 169/200, Iteration 27/250, Loss: 0.0291\n",
      "Epoch 169/200, Iteration 28/250, Loss: 0.0142\n",
      "Epoch 169/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 169/200, Iteration 30/250, Loss: 0.0144\n",
      "Epoch 169/200, Iteration 31/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 32/250, Loss: 0.0090\n",
      "Epoch 169/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 169/200, Iteration 35/250, Loss: 0.0154\n",
      "Epoch 169/200, Iteration 36/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 37/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 38/250, Loss: 0.0128\n",
      "Epoch 169/200, Iteration 39/250, Loss: 0.0161\n",
      "Epoch 169/200, Iteration 40/250, Loss: 0.0065\n",
      "Epoch 169/200, Iteration 41/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 42/250, Loss: 0.0143\n",
      "Epoch 169/200, Iteration 43/250, Loss: 0.0196\n",
      "Epoch 169/200, Iteration 44/250, Loss: 0.0129\n",
      "Epoch 169/200, Iteration 45/250, Loss: 0.0152\n",
      "Epoch 169/200, Iteration 46/250, Loss: 0.0206\n",
      "Epoch 169/200, Iteration 47/250, Loss: 0.0141\n",
      "Epoch 169/200, Iteration 48/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 49/250, Loss: 0.0153\n",
      "Epoch 169/200, Iteration 50/250, Loss: 0.0106\n",
      "Epoch 169/200, Iteration 51/250, Loss: 0.0207\n",
      "Epoch 169/200, Iteration 52/250, Loss: 0.0330\n",
      "Epoch 169/200, Iteration 53/250, Loss: 0.0182\n",
      "Epoch 169/200, Iteration 54/250, Loss: 0.0347\n",
      "Epoch 169/200, Iteration 55/250, Loss: 0.0058\n",
      "Epoch 169/200, Iteration 56/250, Loss: 0.0165\n",
      "Epoch 169/200, Iteration 57/250, Loss: 0.0166\n",
      "Epoch 169/200, Iteration 58/250, Loss: 0.0360\n",
      "Epoch 169/200, Iteration 59/250, Loss: 0.0235\n",
      "Epoch 169/200, Iteration 60/250, Loss: 0.0329\n",
      "Epoch 169/200, Iteration 61/250, Loss: 0.0176\n",
      "Epoch 169/200, Iteration 62/250, Loss: 0.0149\n",
      "Epoch 169/200, Iteration 63/250, Loss: 0.0111\n",
      "Epoch 169/200, Iteration 64/250, Loss: 0.0159\n",
      "Epoch 169/200, Iteration 65/250, Loss: 0.0202\n",
      "Epoch 169/200, Iteration 66/250, Loss: 0.0154\n",
      "Epoch 169/200, Iteration 67/250, Loss: 0.0093\n",
      "Epoch 169/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 169/200, Iteration 69/250, Loss: 0.0116\n",
      "Epoch 169/200, Iteration 70/250, Loss: 0.0114\n",
      "Epoch 169/200, Iteration 71/250, Loss: 0.0155\n",
      "Epoch 169/200, Iteration 72/250, Loss: 0.0107\n",
      "Epoch 169/200, Iteration 73/250, Loss: 0.0134\n",
      "Epoch 169/200, Iteration 74/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 75/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 76/250, Loss: 0.0120\n",
      "Epoch 169/200, Iteration 77/250, Loss: 0.0411\n",
      "Epoch 169/200, Iteration 78/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 79/250, Loss: 0.0122\n",
      "Epoch 169/200, Iteration 80/250, Loss: 0.0278\n",
      "Epoch 169/200, Iteration 81/250, Loss: 0.0075\n",
      "Epoch 169/200, Iteration 82/250, Loss: 0.0079\n",
      "Epoch 169/200, Iteration 83/250, Loss: 0.0231\n",
      "Epoch 169/200, Iteration 84/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 85/250, Loss: 0.0097\n",
      "Epoch 169/200, Iteration 86/250, Loss: 0.0069\n",
      "Epoch 169/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 88/250, Loss: 0.0262\n",
      "Epoch 169/200, Iteration 89/250, Loss: 0.0198\n",
      "Epoch 169/200, Iteration 90/250, Loss: 0.0385\n",
      "Epoch 169/200, Iteration 91/250, Loss: 0.0248\n",
      "Epoch 169/200, Iteration 92/250, Loss: 0.0104\n",
      "Epoch 169/200, Iteration 93/250, Loss: 0.0148\n",
      "Epoch 169/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 169/200, Iteration 95/250, Loss: 0.0372\n",
      "Epoch 169/200, Iteration 96/250, Loss: 0.0211\n",
      "Epoch 169/200, Iteration 97/250, Loss: 0.0128\n",
      "Epoch 169/200, Iteration 98/250, Loss: 0.0080\n",
      "Epoch 169/200, Iteration 99/250, Loss: 0.0329\n",
      "Epoch 169/200, Iteration 100/250, Loss: 0.0148\n",
      "Epoch 169/200, Iteration 101/250, Loss: 0.0122\n",
      "Epoch 169/200, Iteration 102/250, Loss: 0.0178\n",
      "Epoch 169/200, Iteration 103/250, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 104/250, Loss: 0.0204\n",
      "Epoch 169/200, Iteration 105/250, Loss: 0.0102\n",
      "Epoch 169/200, Iteration 106/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 107/250, Loss: 0.0144\n",
      "Epoch 169/200, Iteration 108/250, Loss: 0.0198\n",
      "Epoch 169/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 169/200, Iteration 110/250, Loss: 0.0239\n",
      "Epoch 169/200, Iteration 111/250, Loss: 0.0127\n",
      "Epoch 169/200, Iteration 112/250, Loss: 0.0256\n",
      "Epoch 169/200, Iteration 113/250, Loss: 0.0169\n",
      "Epoch 169/200, Iteration 114/250, Loss: 0.0142\n",
      "Epoch 169/200, Iteration 115/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 169/200, Iteration 117/250, Loss: 0.0097\n",
      "Epoch 169/200, Iteration 118/250, Loss: 0.0132\n",
      "Epoch 169/200, Iteration 119/250, Loss: 0.0187\n",
      "Epoch 169/200, Iteration 120/250, Loss: 0.0155\n",
      "Epoch 169/200, Iteration 121/250, Loss: 0.0220\n",
      "Epoch 169/200, Iteration 122/250, Loss: 0.0096\n",
      "Epoch 169/200, Iteration 123/250, Loss: 0.0170\n",
      "Epoch 169/200, Iteration 124/250, Loss: 0.0114\n",
      "Epoch 169/200, Iteration 125/250, Loss: 0.0133\n",
      "Epoch 169/200, Iteration 126/250, Loss: 0.0134\n",
      "Epoch 169/200, Iteration 127/250, Loss: 0.0166\n",
      "Epoch 169/200, Iteration 128/250, Loss: 0.0185\n",
      "Epoch 169/200, Iteration 129/250, Loss: 0.0242\n",
      "Epoch 169/200, Iteration 130/250, Loss: 0.0080\n",
      "Epoch 169/200, Iteration 131/250, Loss: 0.0128\n",
      "Epoch 169/200, Iteration 132/250, Loss: 0.0160\n",
      "Epoch 169/200, Iteration 133/250, Loss: 0.0102\n",
      "Epoch 169/200, Iteration 134/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 169/200, Iteration 136/250, Loss: 0.0156\n",
      "Epoch 169/200, Iteration 137/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 138/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 139/250, Loss: 0.0078\n",
      "Epoch 169/200, Iteration 140/250, Loss: 0.0269\n",
      "Epoch 169/200, Iteration 141/250, Loss: 0.0140\n",
      "Epoch 169/200, Iteration 142/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 143/250, Loss: 0.0144\n",
      "Epoch 169/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 169/200, Iteration 145/250, Loss: 0.0084\n",
      "Epoch 169/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 169/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 169/200, Iteration 148/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 149/250, Loss: 0.0155\n",
      "Epoch 169/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 151/250, Loss: 0.0106\n",
      "Epoch 169/200, Iteration 152/250, Loss: 0.0072\n",
      "Epoch 169/200, Iteration 153/250, Loss: 0.0089\n",
      "Epoch 169/200, Iteration 154/250, Loss: 0.0074\n",
      "Epoch 169/200, Iteration 155/250, Loss: 0.0053\n",
      "Epoch 169/200, Iteration 156/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 157/250, Loss: 0.0222\n",
      "Epoch 169/200, Iteration 158/250, Loss: 0.0123\n",
      "Epoch 169/200, Iteration 159/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 160/250, Loss: 0.0064\n",
      "Epoch 169/200, Iteration 161/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 162/250, Loss: 0.0099\n",
      "Epoch 169/200, Iteration 163/250, Loss: 0.0147\n",
      "Epoch 169/200, Iteration 164/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 165/250, Loss: 0.0061\n",
      "Epoch 169/200, Iteration 166/250, Loss: 0.0082\n",
      "Epoch 169/200, Iteration 167/250, Loss: 0.0110\n",
      "Epoch 169/200, Iteration 168/250, Loss: 0.0053\n",
      "Epoch 169/200, Iteration 169/250, Loss: 0.0106\n",
      "Epoch 169/200, Iteration 170/250, Loss: 0.0123\n",
      "Epoch 169/200, Iteration 171/250, Loss: 0.0095\n",
      "Epoch 169/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 169/200, Iteration 173/250, Loss: 0.0214\n",
      "Epoch 169/200, Iteration 174/250, Loss: 0.0067\n",
      "Epoch 169/200, Iteration 175/250, Loss: 0.0172\n",
      "Epoch 169/200, Iteration 176/250, Loss: 0.0211\n",
      "Epoch 169/200, Iteration 177/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 178/250, Loss: 0.0178\n",
      "Epoch 169/200, Iteration 179/250, Loss: 0.0218\n",
      "Epoch 169/200, Iteration 180/250, Loss: 0.0153\n",
      "Epoch 169/200, Iteration 181/250, Loss: 0.0181\n",
      "Epoch 169/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 169/200, Iteration 183/250, Loss: 0.0194\n",
      "Epoch 169/200, Iteration 184/250, Loss: 0.0190\n",
      "Epoch 169/200, Iteration 185/250, Loss: 0.0086\n",
      "Epoch 169/200, Iteration 186/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 187/250, Loss: 0.0182\n",
      "Epoch 169/200, Iteration 188/250, Loss: 0.0099\n",
      "Epoch 169/200, Iteration 189/250, Loss: 0.0205\n",
      "Epoch 169/200, Iteration 190/250, Loss: 0.0110\n",
      "Epoch 169/200, Iteration 191/250, Loss: 0.0099\n",
      "Epoch 169/200, Iteration 192/250, Loss: 0.0072\n",
      "Epoch 169/200, Iteration 193/250, Loss: 0.0256\n",
      "Epoch 169/200, Iteration 194/250, Loss: 0.0265\n",
      "Epoch 169/200, Iteration 195/250, Loss: 0.0090\n",
      "Epoch 169/200, Iteration 196/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 197/250, Loss: 0.0121\n",
      "Epoch 169/200, Iteration 198/250, Loss: 0.0158\n",
      "Epoch 169/200, Iteration 199/250, Loss: 0.0153\n",
      "Epoch 169/200, Iteration 200/250, Loss: 0.0298\n",
      "Epoch 169/200, Iteration 201/250, Loss: 0.0340\n",
      "Epoch 169/200, Iteration 202/250, Loss: 0.0134\n",
      "Epoch 169/200, Iteration 203/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 204/250, Loss: 0.0093\n",
      "Epoch 169/200, Iteration 205/250, Loss: 0.0222\n",
      "Epoch 169/200, Iteration 206/250, Loss: 0.0291\n",
      "Epoch 169/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 208/250, Loss: 0.0251\n",
      "Epoch 169/200, Iteration 209/250, Loss: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200, Iteration 210/250, Loss: 0.0167\n",
      "Epoch 169/200, Iteration 211/250, Loss: 0.0114\n",
      "Epoch 169/200, Iteration 212/250, Loss: 0.0104\n",
      "Epoch 169/200, Iteration 213/250, Loss: 0.0140\n",
      "Epoch 169/200, Iteration 214/250, Loss: 0.0232\n",
      "Epoch 169/200, Iteration 215/250, Loss: 0.0114\n",
      "Epoch 169/200, Iteration 216/250, Loss: 0.0254\n",
      "Epoch 169/200, Iteration 217/250, Loss: 0.0497\n",
      "Epoch 169/200, Iteration 218/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 219/250, Loss: 0.0123\n",
      "Epoch 169/200, Iteration 220/250, Loss: 0.0121\n",
      "Epoch 169/200, Iteration 221/250, Loss: 0.0140\n",
      "Epoch 169/200, Iteration 222/250, Loss: 0.0078\n",
      "Epoch 169/200, Iteration 223/250, Loss: 0.0378\n",
      "Epoch 169/200, Iteration 224/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 225/250, Loss: 0.0163\n",
      "Epoch 169/200, Iteration 226/250, Loss: 0.0263\n",
      "Epoch 169/200, Iteration 227/250, Loss: 0.0088\n",
      "Epoch 169/200, Iteration 228/250, Loss: 0.0092\n",
      "Epoch 169/200, Iteration 229/250, Loss: 0.0256\n",
      "Epoch 169/200, Iteration 230/250, Loss: 0.0083\n",
      "Epoch 169/200, Iteration 231/250, Loss: 0.0265\n",
      "Epoch 169/200, Iteration 232/250, Loss: 0.0230\n",
      "Epoch 169/200, Iteration 233/250, Loss: 0.0164\n",
      "Epoch 169/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 169/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 169/200, Iteration 236/250, Loss: 0.0080\n",
      "Epoch 169/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 169/200, Iteration 238/250, Loss: 0.0101\n",
      "Epoch 169/200, Iteration 239/250, Loss: 0.0178\n",
      "Epoch 169/200, Iteration 240/250, Loss: 0.0131\n",
      "Epoch 169/200, Iteration 241/250, Loss: 0.0246\n",
      "Epoch 169/200, Iteration 242/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 243/250, Loss: 0.0072\n",
      "Epoch 169/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 245/250, Loss: 0.0092\n",
      "Epoch 169/200, Iteration 246/250, Loss: 0.0082\n",
      "Epoch 169/200, Iteration 247/250, Loss: 0.0305\n",
      "Epoch 169/200, Iteration 248/250, Loss: 0.0100\n",
      "Epoch 169/200, Iteration 249/250, Loss: 0.0177\n",
      "Epoch 169/200, Iteration 250/250, Loss: 0.0138\n",
      "Train Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.007179, MRE: 0.629873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.65%, Avg loss: 0.007204, MRE: 0.750110 \n",
      "\n",
      "Epoch 170/200, Iteration 1/250, Loss: 0.0077\n",
      "Epoch 170/200, Iteration 2/250, Loss: 0.0192\n",
      "Epoch 170/200, Iteration 3/250, Loss: 0.0232\n",
      "Epoch 170/200, Iteration 4/250, Loss: 0.0090\n",
      "Epoch 170/200, Iteration 5/250, Loss: 0.0124\n",
      "Epoch 170/200, Iteration 6/250, Loss: 0.0280\n",
      "Epoch 170/200, Iteration 7/250, Loss: 0.0142\n",
      "Epoch 170/200, Iteration 8/250, Loss: 0.0123\n",
      "Epoch 170/200, Iteration 9/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 10/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 11/250, Loss: 0.0162\n",
      "Epoch 170/200, Iteration 12/250, Loss: 0.0127\n",
      "Epoch 170/200, Iteration 13/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 14/250, Loss: 0.0160\n",
      "Epoch 170/200, Iteration 15/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 16/250, Loss: 0.0101\n",
      "Epoch 170/200, Iteration 17/250, Loss: 0.0308\n",
      "Epoch 170/200, Iteration 18/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 19/250, Loss: 0.0178\n",
      "Epoch 170/200, Iteration 20/250, Loss: 0.0133\n",
      "Epoch 170/200, Iteration 21/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 22/250, Loss: 0.0269\n",
      "Epoch 170/200, Iteration 23/250, Loss: 0.0054\n",
      "Epoch 170/200, Iteration 24/250, Loss: 0.0130\n",
      "Epoch 170/200, Iteration 25/250, Loss: 0.0134\n",
      "Epoch 170/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 27/250, Loss: 0.0131\n",
      "Epoch 170/200, Iteration 28/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 29/250, Loss: 0.0144\n",
      "Epoch 170/200, Iteration 30/250, Loss: 0.0155\n",
      "Epoch 170/200, Iteration 31/250, Loss: 0.0203\n",
      "Epoch 170/200, Iteration 32/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 33/250, Loss: 0.0083\n",
      "Epoch 170/200, Iteration 34/250, Loss: 0.0078\n",
      "Epoch 170/200, Iteration 35/250, Loss: 0.0159\n",
      "Epoch 170/200, Iteration 36/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 37/250, Loss: 0.0180\n",
      "Epoch 170/200, Iteration 38/250, Loss: 0.0065\n",
      "Epoch 170/200, Iteration 39/250, Loss: 0.0156\n",
      "Epoch 170/200, Iteration 40/250, Loss: 0.0070\n",
      "Epoch 170/200, Iteration 41/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 170/200, Iteration 43/250, Loss: 0.0262\n",
      "Epoch 170/200, Iteration 44/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 45/250, Loss: 0.0170\n",
      "Epoch 170/200, Iteration 46/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 47/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 48/250, Loss: 0.0166\n",
      "Epoch 170/200, Iteration 49/250, Loss: 0.0222\n",
      "Epoch 170/200, Iteration 50/250, Loss: 0.0325\n",
      "Epoch 170/200, Iteration 51/250, Loss: 0.0099\n",
      "Epoch 170/200, Iteration 52/250, Loss: 0.0164\n",
      "Epoch 170/200, Iteration 53/250, Loss: 0.0104\n",
      "Epoch 170/200, Iteration 54/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 55/250, Loss: 0.0136\n",
      "Epoch 170/200, Iteration 56/250, Loss: 0.0180\n",
      "Epoch 170/200, Iteration 57/250, Loss: 0.0069\n",
      "Epoch 170/200, Iteration 58/250, Loss: 0.0118\n",
      "Epoch 170/200, Iteration 59/250, Loss: 0.0149\n",
      "Epoch 170/200, Iteration 60/250, Loss: 0.0086\n",
      "Epoch 170/200, Iteration 61/250, Loss: 0.0335\n",
      "Epoch 170/200, Iteration 62/250, Loss: 0.0102\n",
      "Epoch 170/200, Iteration 63/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 64/250, Loss: 0.0091\n",
      "Epoch 170/200, Iteration 65/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 66/250, Loss: 0.0156\n",
      "Epoch 170/200, Iteration 67/250, Loss: 0.0202\n",
      "Epoch 170/200, Iteration 68/250, Loss: 0.0258\n",
      "Epoch 170/200, Iteration 69/250, Loss: 0.0096\n",
      "Epoch 170/200, Iteration 70/250, Loss: 0.0249\n",
      "Epoch 170/200, Iteration 71/250, Loss: 0.0114\n",
      "Epoch 170/200, Iteration 72/250, Loss: 0.0066\n",
      "Epoch 170/200, Iteration 73/250, Loss: 0.0173\n",
      "Epoch 170/200, Iteration 74/250, Loss: 0.0110\n",
      "Epoch 170/200, Iteration 75/250, Loss: 0.0155\n",
      "Epoch 170/200, Iteration 76/250, Loss: 0.0179\n",
      "Epoch 170/200, Iteration 77/250, Loss: 0.0195\n",
      "Epoch 170/200, Iteration 78/250, Loss: 0.0187\n",
      "Epoch 170/200, Iteration 79/250, Loss: 0.0085\n",
      "Epoch 170/200, Iteration 80/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 81/250, Loss: 0.0162\n",
      "Epoch 170/200, Iteration 82/250, Loss: 0.0147\n",
      "Epoch 170/200, Iteration 83/250, Loss: 0.0298\n",
      "Epoch 170/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 170/200, Iteration 85/250, Loss: 0.0054\n",
      "Epoch 170/200, Iteration 86/250, Loss: 0.0210\n",
      "Epoch 170/200, Iteration 87/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 88/250, Loss: 0.0071\n",
      "Epoch 170/200, Iteration 89/250, Loss: 0.0150\n",
      "Epoch 170/200, Iteration 90/250, Loss: 0.0075\n",
      "Epoch 170/200, Iteration 91/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 92/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 93/250, Loss: 0.0109\n",
      "Epoch 170/200, Iteration 94/250, Loss: 0.0198\n",
      "Epoch 170/200, Iteration 95/250, Loss: 0.0088\n",
      "Epoch 170/200, Iteration 96/250, Loss: 0.0103\n",
      "Epoch 170/200, Iteration 97/250, Loss: 0.0098\n",
      "Epoch 170/200, Iteration 98/250, Loss: 0.0247\n",
      "Epoch 170/200, Iteration 99/250, Loss: 0.0293\n",
      "Epoch 170/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 101/250, Loss: 0.0131\n",
      "Epoch 170/200, Iteration 102/250, Loss: 0.0118\n",
      "Epoch 170/200, Iteration 103/250, Loss: 0.0091\n",
      "Epoch 170/200, Iteration 104/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 105/250, Loss: 0.0130\n",
      "Epoch 170/200, Iteration 106/250, Loss: 0.0367\n",
      "Epoch 170/200, Iteration 107/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 108/250, Loss: 0.0161\n",
      "Epoch 170/200, Iteration 109/250, Loss: 0.0095\n",
      "Epoch 170/200, Iteration 110/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 111/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 112/250, Loss: 0.0332\n",
      "Epoch 170/200, Iteration 113/250, Loss: 0.0161\n",
      "Epoch 170/200, Iteration 114/250, Loss: 0.0156\n",
      "Epoch 170/200, Iteration 115/250, Loss: 0.0106\n",
      "Epoch 170/200, Iteration 116/250, Loss: 0.0077\n",
      "Epoch 170/200, Iteration 117/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 118/250, Loss: 0.0092\n",
      "Epoch 170/200, Iteration 119/250, Loss: 0.0118\n",
      "Epoch 170/200, Iteration 120/250, Loss: 0.0264\n",
      "Epoch 170/200, Iteration 121/250, Loss: 0.0348\n",
      "Epoch 170/200, Iteration 122/250, Loss: 0.0087\n",
      "Epoch 170/200, Iteration 123/250, Loss: 0.0285\n",
      "Epoch 170/200, Iteration 124/250, Loss: 0.0072\n",
      "Epoch 170/200, Iteration 125/250, Loss: 0.0086\n",
      "Epoch 170/200, Iteration 126/250, Loss: 0.0279\n",
      "Epoch 170/200, Iteration 127/250, Loss: 0.0089\n",
      "Epoch 170/200, Iteration 128/250, Loss: 0.0164\n",
      "Epoch 170/200, Iteration 129/250, Loss: 0.0311\n",
      "Epoch 170/200, Iteration 130/250, Loss: 0.0096\n",
      "Epoch 170/200, Iteration 131/250, Loss: 0.0104\n",
      "Epoch 170/200, Iteration 132/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 170/200, Iteration 134/250, Loss: 0.0092\n",
      "Epoch 170/200, Iteration 135/250, Loss: 0.0155\n",
      "Epoch 170/200, Iteration 136/250, Loss: 0.0116\n",
      "Epoch 170/200, Iteration 137/250, Loss: 0.0228\n",
      "Epoch 170/200, Iteration 138/250, Loss: 0.0366\n",
      "Epoch 170/200, Iteration 139/250, Loss: 0.0171\n",
      "Epoch 170/200, Iteration 140/250, Loss: 0.0264\n",
      "Epoch 170/200, Iteration 141/250, Loss: 0.0142\n",
      "Epoch 170/200, Iteration 142/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 143/250, Loss: 0.0109\n",
      "Epoch 170/200, Iteration 144/250, Loss: 0.0095\n",
      "Epoch 170/200, Iteration 145/250, Loss: 0.0173\n",
      "Epoch 170/200, Iteration 146/250, Loss: 0.0326\n",
      "Epoch 170/200, Iteration 147/250, Loss: 0.0068\n",
      "Epoch 170/200, Iteration 148/250, Loss: 0.0152\n",
      "Epoch 170/200, Iteration 149/250, Loss: 0.0069\n",
      "Epoch 170/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 170/200, Iteration 151/250, Loss: 0.0089\n",
      "Epoch 170/200, Iteration 152/250, Loss: 0.0077\n",
      "Epoch 170/200, Iteration 153/250, Loss: 0.0220\n",
      "Epoch 170/200, Iteration 154/250, Loss: 0.0098\n",
      "Epoch 170/200, Iteration 155/250, Loss: 0.0235\n",
      "Epoch 170/200, Iteration 156/250, Loss: 0.0081\n",
      "Epoch 170/200, Iteration 157/250, Loss: 0.0216\n",
      "Epoch 170/200, Iteration 158/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200, Iteration 159/250, Loss: 0.0110\n",
      "Epoch 170/200, Iteration 160/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 161/250, Loss: 0.0123\n",
      "Epoch 170/200, Iteration 162/250, Loss: 0.0128\n",
      "Epoch 170/200, Iteration 163/250, Loss: 0.0114\n",
      "Epoch 170/200, Iteration 164/250, Loss: 0.0226\n",
      "Epoch 170/200, Iteration 165/250, Loss: 0.0074\n",
      "Epoch 170/200, Iteration 166/250, Loss: 0.0185\n",
      "Epoch 170/200, Iteration 167/250, Loss: 0.0278\n",
      "Epoch 170/200, Iteration 168/250, Loss: 0.0303\n",
      "Epoch 170/200, Iteration 169/250, Loss: 0.0123\n",
      "Epoch 170/200, Iteration 170/250, Loss: 0.0122\n",
      "Epoch 170/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 170/200, Iteration 172/250, Loss: 0.0304\n",
      "Epoch 170/200, Iteration 173/250, Loss: 0.0164\n",
      "Epoch 170/200, Iteration 174/250, Loss: 0.0194\n",
      "Epoch 170/200, Iteration 175/250, Loss: 0.0217\n",
      "Epoch 170/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 177/250, Loss: 0.0265\n",
      "Epoch 170/200, Iteration 178/250, Loss: 0.0092\n",
      "Epoch 170/200, Iteration 179/250, Loss: 0.0095\n",
      "Epoch 170/200, Iteration 180/250, Loss: 0.0095\n",
      "Epoch 170/200, Iteration 181/250, Loss: 0.0074\n",
      "Epoch 170/200, Iteration 182/250, Loss: 0.0224\n",
      "Epoch 170/200, Iteration 183/250, Loss: 0.0245\n",
      "Epoch 170/200, Iteration 184/250, Loss: 0.0299\n",
      "Epoch 170/200, Iteration 185/250, Loss: 0.0369\n",
      "Epoch 170/200, Iteration 186/250, Loss: 0.0145\n",
      "Epoch 170/200, Iteration 187/250, Loss: 0.0136\n",
      "Epoch 170/200, Iteration 188/250, Loss: 0.0158\n",
      "Epoch 170/200, Iteration 189/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 190/250, Loss: 0.0098\n",
      "Epoch 170/200, Iteration 191/250, Loss: 0.0082\n",
      "Epoch 170/200, Iteration 192/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 193/250, Loss: 0.0050\n",
      "Epoch 170/200, Iteration 194/250, Loss: 0.0158\n",
      "Epoch 170/200, Iteration 195/250, Loss: 0.0133\n",
      "Epoch 170/200, Iteration 196/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 197/250, Loss: 0.0326\n",
      "Epoch 170/200, Iteration 198/250, Loss: 0.0217\n",
      "Epoch 170/200, Iteration 199/250, Loss: 0.0118\n",
      "Epoch 170/200, Iteration 200/250, Loss: 0.0090\n",
      "Epoch 170/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 170/200, Iteration 202/250, Loss: 0.0060\n",
      "Epoch 170/200, Iteration 203/250, Loss: 0.0203\n",
      "Epoch 170/200, Iteration 204/250, Loss: 0.0153\n",
      "Epoch 170/200, Iteration 205/250, Loss: 0.0173\n",
      "Epoch 170/200, Iteration 206/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 170/200, Iteration 208/250, Loss: 0.0060\n",
      "Epoch 170/200, Iteration 209/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 210/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 211/250, Loss: 0.0147\n",
      "Epoch 170/200, Iteration 212/250, Loss: 0.0071\n",
      "Epoch 170/200, Iteration 213/250, Loss: 0.0085\n",
      "Epoch 170/200, Iteration 214/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 215/250, Loss: 0.0097\n",
      "Epoch 170/200, Iteration 216/250, Loss: 0.0049\n",
      "Epoch 170/200, Iteration 217/250, Loss: 0.0104\n",
      "Epoch 170/200, Iteration 218/250, Loss: 0.0177\n",
      "Epoch 170/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 170/200, Iteration 220/250, Loss: 0.0069\n",
      "Epoch 170/200, Iteration 221/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 222/250, Loss: 0.0166\n",
      "Epoch 170/200, Iteration 223/250, Loss: 0.0254\n",
      "Epoch 170/200, Iteration 224/250, Loss: 0.0245\n",
      "Epoch 170/200, Iteration 225/250, Loss: 0.0178\n",
      "Epoch 170/200, Iteration 226/250, Loss: 0.0306\n",
      "Epoch 170/200, Iteration 227/250, Loss: 0.0124\n",
      "Epoch 170/200, Iteration 228/250, Loss: 0.0099\n",
      "Epoch 170/200, Iteration 229/250, Loss: 0.0159\n",
      "Epoch 170/200, Iteration 230/250, Loss: 0.0120\n",
      "Epoch 170/200, Iteration 231/250, Loss: 0.0152\n",
      "Epoch 170/200, Iteration 232/250, Loss: 0.0165\n",
      "Epoch 170/200, Iteration 233/250, Loss: 0.0305\n",
      "Epoch 170/200, Iteration 234/250, Loss: 0.0097\n",
      "Epoch 170/200, Iteration 235/250, Loss: 0.0146\n",
      "Epoch 170/200, Iteration 236/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 237/250, Loss: 0.0072\n",
      "Epoch 170/200, Iteration 238/250, Loss: 0.0195\n",
      "Epoch 170/200, Iteration 239/250, Loss: 0.0134\n",
      "Epoch 170/200, Iteration 240/250, Loss: 0.0195\n",
      "Epoch 170/200, Iteration 241/250, Loss: 0.0091\n",
      "Epoch 170/200, Iteration 242/250, Loss: 0.0277\n",
      "Epoch 170/200, Iteration 243/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 244/250, Loss: 0.0275\n",
      "Epoch 170/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 170/200, Iteration 246/250, Loss: 0.0086\n",
      "Epoch 170/200, Iteration 247/250, Loss: 0.0090\n",
      "Epoch 170/200, Iteration 248/250, Loss: 0.0103\n",
      "Epoch 170/200, Iteration 249/250, Loss: 0.0152\n",
      "Epoch 170/200, Iteration 250/250, Loss: 0.0172\n",
      "Train Error: \n",
      " Accuracy: 96.06%, Avg loss: 0.006627, MRE: 0.657963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.05%, Avg loss: 0.006611, MRE: 1.230926 \n",
      "\n",
      "Epoch 171/200, Iteration 1/250, Loss: 0.0134\n",
      "Epoch 171/200, Iteration 2/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 3/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 4/250, Loss: 0.0233\n",
      "Epoch 171/200, Iteration 5/250, Loss: 0.0056\n",
      "Epoch 171/200, Iteration 6/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 7/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 8/250, Loss: 0.0058\n",
      "Epoch 171/200, Iteration 9/250, Loss: 0.0112\n",
      "Epoch 171/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 171/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 171/200, Iteration 13/250, Loss: 0.0109\n",
      "Epoch 171/200, Iteration 14/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 171/200, Iteration 16/250, Loss: 0.0079\n",
      "Epoch 171/200, Iteration 17/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 18/250, Loss: 0.0385\n",
      "Epoch 171/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 171/200, Iteration 20/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 21/250, Loss: 0.0163\n",
      "Epoch 171/200, Iteration 22/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 23/250, Loss: 0.0157\n",
      "Epoch 171/200, Iteration 24/250, Loss: 0.0174\n",
      "Epoch 171/200, Iteration 25/250, Loss: 0.0141\n",
      "Epoch 171/200, Iteration 26/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 28/250, Loss: 0.0151\n",
      "Epoch 171/200, Iteration 29/250, Loss: 0.0078\n",
      "Epoch 171/200, Iteration 30/250, Loss: 0.0066\n",
      "Epoch 171/200, Iteration 31/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 32/250, Loss: 0.0097\n",
      "Epoch 171/200, Iteration 33/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 34/250, Loss: 0.0121\n",
      "Epoch 171/200, Iteration 35/250, Loss: 0.0090\n",
      "Epoch 171/200, Iteration 36/250, Loss: 0.0288\n",
      "Epoch 171/200, Iteration 37/250, Loss: 0.0139\n",
      "Epoch 171/200, Iteration 38/250, Loss: 0.0073\n",
      "Epoch 171/200, Iteration 39/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 40/250, Loss: 0.0222\n",
      "Epoch 171/200, Iteration 41/250, Loss: 0.0138\n",
      "Epoch 171/200, Iteration 42/250, Loss: 0.0115\n",
      "Epoch 171/200, Iteration 43/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 44/250, Loss: 0.0206\n",
      "Epoch 171/200, Iteration 45/250, Loss: 0.0133\n",
      "Epoch 171/200, Iteration 46/250, Loss: 0.0075\n",
      "Epoch 171/200, Iteration 47/250, Loss: 0.0326\n",
      "Epoch 171/200, Iteration 48/250, Loss: 0.0293\n",
      "Epoch 171/200, Iteration 49/250, Loss: 0.0241\n",
      "Epoch 171/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 171/200, Iteration 51/250, Loss: 0.0095\n",
      "Epoch 171/200, Iteration 52/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 53/250, Loss: 0.0173\n",
      "Epoch 171/200, Iteration 54/250, Loss: 0.0085\n",
      "Epoch 171/200, Iteration 55/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 56/250, Loss: 0.0113\n",
      "Epoch 171/200, Iteration 57/250, Loss: 0.0083\n",
      "Epoch 171/200, Iteration 58/250, Loss: 0.0122\n",
      "Epoch 171/200, Iteration 59/250, Loss: 0.0168\n",
      "Epoch 171/200, Iteration 60/250, Loss: 0.0209\n",
      "Epoch 171/200, Iteration 61/250, Loss: 0.0207\n",
      "Epoch 171/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 171/200, Iteration 63/250, Loss: 0.0132\n",
      "Epoch 171/200, Iteration 64/250, Loss: 0.0078\n",
      "Epoch 171/200, Iteration 65/250, Loss: 0.0262\n",
      "Epoch 171/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 67/250, Loss: 0.0163\n",
      "Epoch 171/200, Iteration 68/250, Loss: 0.0080\n",
      "Epoch 171/200, Iteration 69/250, Loss: 0.0085\n",
      "Epoch 171/200, Iteration 70/250, Loss: 0.0066\n",
      "Epoch 171/200, Iteration 71/250, Loss: 0.0169\n",
      "Epoch 171/200, Iteration 72/250, Loss: 0.0147\n",
      "Epoch 171/200, Iteration 73/250, Loss: 0.0084\n",
      "Epoch 171/200, Iteration 74/250, Loss: 0.0174\n",
      "Epoch 171/200, Iteration 75/250, Loss: 0.0092\n",
      "Epoch 171/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 77/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 78/250, Loss: 0.0073\n",
      "Epoch 171/200, Iteration 79/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 80/250, Loss: 0.0128\n",
      "Epoch 171/200, Iteration 81/250, Loss: 0.0250\n",
      "Epoch 171/200, Iteration 82/250, Loss: 0.0261\n",
      "Epoch 171/200, Iteration 83/250, Loss: 0.0168\n",
      "Epoch 171/200, Iteration 84/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 85/250, Loss: 0.0265\n",
      "Epoch 171/200, Iteration 86/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 87/250, Loss: 0.0086\n",
      "Epoch 171/200, Iteration 88/250, Loss: 0.0187\n",
      "Epoch 171/200, Iteration 89/250, Loss: 0.0147\n",
      "Epoch 171/200, Iteration 90/250, Loss: 0.0143\n",
      "Epoch 171/200, Iteration 91/250, Loss: 0.0077\n",
      "Epoch 171/200, Iteration 92/250, Loss: 0.0151\n",
      "Epoch 171/200, Iteration 93/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 94/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200, Iteration 95/250, Loss: 0.0166\n",
      "Epoch 171/200, Iteration 96/250, Loss: 0.0095\n",
      "Epoch 171/200, Iteration 97/250, Loss: 0.0272\n",
      "Epoch 171/200, Iteration 98/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 99/250, Loss: 0.0138\n",
      "Epoch 171/200, Iteration 100/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 101/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 102/250, Loss: 0.0229\n",
      "Epoch 171/200, Iteration 103/250, Loss: 0.0076\n",
      "Epoch 171/200, Iteration 104/250, Loss: 0.0311\n",
      "Epoch 171/200, Iteration 105/250, Loss: 0.0322\n",
      "Epoch 171/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 107/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 108/250, Loss: 0.0089\n",
      "Epoch 171/200, Iteration 109/250, Loss: 0.0138\n",
      "Epoch 171/200, Iteration 110/250, Loss: 0.0182\n",
      "Epoch 171/200, Iteration 111/250, Loss: 0.0365\n",
      "Epoch 171/200, Iteration 112/250, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 113/250, Loss: 0.0318\n",
      "Epoch 171/200, Iteration 114/250, Loss: 0.0141\n",
      "Epoch 171/200, Iteration 115/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 116/250, Loss: 0.0090\n",
      "Epoch 171/200, Iteration 117/250, Loss: 0.0083\n",
      "Epoch 171/200, Iteration 118/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 119/250, Loss: 0.0203\n",
      "Epoch 171/200, Iteration 120/250, Loss: 0.0164\n",
      "Epoch 171/200, Iteration 121/250, Loss: 0.0177\n",
      "Epoch 171/200, Iteration 122/250, Loss: 0.0174\n",
      "Epoch 171/200, Iteration 123/250, Loss: 0.0069\n",
      "Epoch 171/200, Iteration 124/250, Loss: 0.0077\n",
      "Epoch 171/200, Iteration 125/250, Loss: 0.0155\n",
      "Epoch 171/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 171/200, Iteration 127/250, Loss: 0.0083\n",
      "Epoch 171/200, Iteration 128/250, Loss: 0.0177\n",
      "Epoch 171/200, Iteration 129/250, Loss: 0.0117\n",
      "Epoch 171/200, Iteration 130/250, Loss: 0.0152\n",
      "Epoch 171/200, Iteration 131/250, Loss: 0.0385\n",
      "Epoch 171/200, Iteration 132/250, Loss: 0.0273\n",
      "Epoch 171/200, Iteration 133/250, Loss: 0.0286\n",
      "Epoch 171/200, Iteration 134/250, Loss: 0.0221\n",
      "Epoch 171/200, Iteration 135/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 136/250, Loss: 0.0143\n",
      "Epoch 171/200, Iteration 137/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 138/250, Loss: 0.0199\n",
      "Epoch 171/200, Iteration 139/250, Loss: 0.0160\n",
      "Epoch 171/200, Iteration 140/250, Loss: 0.0062\n",
      "Epoch 171/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 142/250, Loss: 0.0092\n",
      "Epoch 171/200, Iteration 143/250, Loss: 0.0172\n",
      "Epoch 171/200, Iteration 144/250, Loss: 0.0316\n",
      "Epoch 171/200, Iteration 145/250, Loss: 0.0107\n",
      "Epoch 171/200, Iteration 146/250, Loss: 0.0243\n",
      "Epoch 171/200, Iteration 147/250, Loss: 0.0073\n",
      "Epoch 171/200, Iteration 148/250, Loss: 0.0096\n",
      "Epoch 171/200, Iteration 149/250, Loss: 0.0077\n",
      "Epoch 171/200, Iteration 150/250, Loss: 0.0128\n",
      "Epoch 171/200, Iteration 151/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 152/250, Loss: 0.0218\n",
      "Epoch 171/200, Iteration 153/250, Loss: 0.0150\n",
      "Epoch 171/200, Iteration 154/250, Loss: 0.0097\n",
      "Epoch 171/200, Iteration 155/250, Loss: 0.0051\n",
      "Epoch 171/200, Iteration 156/250, Loss: 0.0197\n",
      "Epoch 171/200, Iteration 157/250, Loss: 0.0302\n",
      "Epoch 171/200, Iteration 158/250, Loss: 0.0108\n",
      "Epoch 171/200, Iteration 159/250, Loss: 0.0300\n",
      "Epoch 171/200, Iteration 160/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 161/250, Loss: 0.0075\n",
      "Epoch 171/200, Iteration 162/250, Loss: 0.0180\n",
      "Epoch 171/200, Iteration 163/250, Loss: 0.0147\n",
      "Epoch 171/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 165/250, Loss: 0.0133\n",
      "Epoch 171/200, Iteration 166/250, Loss: 0.0174\n",
      "Epoch 171/200, Iteration 167/250, Loss: 0.0153\n",
      "Epoch 171/200, Iteration 168/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 169/250, Loss: 0.0319\n",
      "Epoch 171/200, Iteration 170/250, Loss: 0.0228\n",
      "Epoch 171/200, Iteration 171/250, Loss: 0.0163\n",
      "Epoch 171/200, Iteration 172/250, Loss: 0.0151\n",
      "Epoch 171/200, Iteration 173/250, Loss: 0.0072\n",
      "Epoch 171/200, Iteration 174/250, Loss: 0.0137\n",
      "Epoch 171/200, Iteration 175/250, Loss: 0.0188\n",
      "Epoch 171/200, Iteration 176/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 177/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 178/250, Loss: 0.0133\n",
      "Epoch 171/200, Iteration 179/250, Loss: 0.0147\n",
      "Epoch 171/200, Iteration 180/250, Loss: 0.0166\n",
      "Epoch 171/200, Iteration 181/250, Loss: 0.0124\n",
      "Epoch 171/200, Iteration 182/250, Loss: 0.0249\n",
      "Epoch 171/200, Iteration 183/250, Loss: 0.0286\n",
      "Epoch 171/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 171/200, Iteration 185/250, Loss: 0.0089\n",
      "Epoch 171/200, Iteration 186/250, Loss: 0.0051\n",
      "Epoch 171/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 188/250, Loss: 0.0114\n",
      "Epoch 171/200, Iteration 189/250, Loss: 0.0131\n",
      "Epoch 171/200, Iteration 190/250, Loss: 0.0077\n",
      "Epoch 171/200, Iteration 191/250, Loss: 0.0237\n",
      "Epoch 171/200, Iteration 192/250, Loss: 0.0072\n",
      "Epoch 171/200, Iteration 193/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 195/250, Loss: 0.0193\n",
      "Epoch 171/200, Iteration 196/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 197/250, Loss: 0.0122\n",
      "Epoch 171/200, Iteration 198/250, Loss: 0.0073\n",
      "Epoch 171/200, Iteration 199/250, Loss: 0.0145\n",
      "Epoch 171/200, Iteration 200/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 201/250, Loss: 0.0257\n",
      "Epoch 171/200, Iteration 202/250, Loss: 0.0300\n",
      "Epoch 171/200, Iteration 203/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 204/250, Loss: 0.0192\n",
      "Epoch 171/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 171/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 171/200, Iteration 207/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 208/250, Loss: 0.0240\n",
      "Epoch 171/200, Iteration 209/250, Loss: 0.0142\n",
      "Epoch 171/200, Iteration 210/250, Loss: 0.0297\n",
      "Epoch 171/200, Iteration 211/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 212/250, Loss: 0.0076\n",
      "Epoch 171/200, Iteration 213/250, Loss: 0.0152\n",
      "Epoch 171/200, Iteration 214/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 215/250, Loss: 0.0051\n",
      "Epoch 171/200, Iteration 216/250, Loss: 0.0057\n",
      "Epoch 171/200, Iteration 217/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 218/250, Loss: 0.0271\n",
      "Epoch 171/200, Iteration 219/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 220/250, Loss: 0.0114\n",
      "Epoch 171/200, Iteration 221/250, Loss: 0.0085\n",
      "Epoch 171/200, Iteration 222/250, Loss: 0.0187\n",
      "Epoch 171/200, Iteration 223/250, Loss: 0.0069\n",
      "Epoch 171/200, Iteration 224/250, Loss: 0.0108\n",
      "Epoch 171/200, Iteration 225/250, Loss: 0.0136\n",
      "Epoch 171/200, Iteration 226/250, Loss: 0.0150\n",
      "Epoch 171/200, Iteration 227/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 228/250, Loss: 0.0080\n",
      "Epoch 171/200, Iteration 229/250, Loss: 0.0201\n",
      "Epoch 171/200, Iteration 230/250, Loss: 0.0112\n",
      "Epoch 171/200, Iteration 231/250, Loss: 0.0182\n",
      "Epoch 171/200, Iteration 232/250, Loss: 0.0148\n",
      "Epoch 171/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 234/250, Loss: 0.0131\n",
      "Epoch 171/200, Iteration 235/250, Loss: 0.0225\n",
      "Epoch 171/200, Iteration 236/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 237/250, Loss: 0.0243\n",
      "Epoch 171/200, Iteration 238/250, Loss: 0.0049\n",
      "Epoch 171/200, Iteration 239/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 240/250, Loss: 0.0175\n",
      "Epoch 171/200, Iteration 241/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 243/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 244/250, Loss: 0.0069\n",
      "Epoch 171/200, Iteration 245/250, Loss: 0.0114\n",
      "Epoch 171/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 247/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 248/250, Loss: 0.0220\n",
      "Epoch 171/200, Iteration 249/250, Loss: 0.0275\n",
      "Epoch 171/200, Iteration 250/250, Loss: 0.0173\n",
      "Train Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.005716, MRE: 0.624426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005688, MRE: 1.025045 \n",
      "\n",
      "Epoch 172/200, Iteration 1/250, Loss: 0.0077\n",
      "Epoch 172/200, Iteration 2/250, Loss: 0.0183\n",
      "Epoch 172/200, Iteration 3/250, Loss: 0.0208\n",
      "Epoch 172/200, Iteration 4/250, Loss: 0.0251\n",
      "Epoch 172/200, Iteration 5/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 6/250, Loss: 0.0194\n",
      "Epoch 172/200, Iteration 7/250, Loss: 0.0120\n",
      "Epoch 172/200, Iteration 8/250, Loss: 0.0180\n",
      "Epoch 172/200, Iteration 9/250, Loss: 0.0163\n",
      "Epoch 172/200, Iteration 10/250, Loss: 0.0084\n",
      "Epoch 172/200, Iteration 11/250, Loss: 0.0159\n",
      "Epoch 172/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 172/200, Iteration 13/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 14/250, Loss: 0.0169\n",
      "Epoch 172/200, Iteration 15/250, Loss: 0.0197\n",
      "Epoch 172/200, Iteration 16/250, Loss: 0.0088\n",
      "Epoch 172/200, Iteration 17/250, Loss: 0.0089\n",
      "Epoch 172/200, Iteration 18/250, Loss: 0.0157\n",
      "Epoch 172/200, Iteration 19/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 20/250, Loss: 0.0193\n",
      "Epoch 172/200, Iteration 21/250, Loss: 0.0144\n",
      "Epoch 172/200, Iteration 22/250, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 172/200, Iteration 24/250, Loss: 0.0146\n",
      "Epoch 172/200, Iteration 25/250, Loss: 0.0187\n",
      "Epoch 172/200, Iteration 26/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 27/250, Loss: 0.0258\n",
      "Epoch 172/200, Iteration 28/250, Loss: 0.0149\n",
      "Epoch 172/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 172/200, Iteration 30/250, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 31/250, Loss: 0.0086\n",
      "Epoch 172/200, Iteration 32/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 33/250, Loss: 0.0114\n",
      "Epoch 172/200, Iteration 34/250, Loss: 0.0140\n",
      "Epoch 172/200, Iteration 35/250, Loss: 0.0134\n",
      "Epoch 172/200, Iteration 36/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 37/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 38/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 39/250, Loss: 0.0254\n",
      "Epoch 172/200, Iteration 40/250, Loss: 0.0113\n",
      "Epoch 172/200, Iteration 41/250, Loss: 0.0082\n",
      "Epoch 172/200, Iteration 42/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 43/250, Loss: 0.0063\n",
      "Epoch 172/200, Iteration 44/250, Loss: 0.0271\n",
      "Epoch 172/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 46/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 47/250, Loss: 0.0079\n",
      "Epoch 172/200, Iteration 48/250, Loss: 0.0083\n",
      "Epoch 172/200, Iteration 49/250, Loss: 0.0125\n",
      "Epoch 172/200, Iteration 50/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 51/250, Loss: 0.0166\n",
      "Epoch 172/200, Iteration 52/250, Loss: 0.0131\n",
      "Epoch 172/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 172/200, Iteration 54/250, Loss: 0.0097\n",
      "Epoch 172/200, Iteration 55/250, Loss: 0.0107\n",
      "Epoch 172/200, Iteration 56/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 57/250, Loss: 0.0122\n",
      "Epoch 172/200, Iteration 58/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 172/200, Iteration 60/250, Loss: 0.0122\n",
      "Epoch 172/200, Iteration 61/250, Loss: 0.0142\n",
      "Epoch 172/200, Iteration 62/250, Loss: 0.0148\n",
      "Epoch 172/200, Iteration 63/250, Loss: 0.0181\n",
      "Epoch 172/200, Iteration 64/250, Loss: 0.0088\n",
      "Epoch 172/200, Iteration 65/250, Loss: 0.0082\n",
      "Epoch 172/200, Iteration 66/250, Loss: 0.0276\n",
      "Epoch 172/200, Iteration 67/250, Loss: 0.0182\n",
      "Epoch 172/200, Iteration 68/250, Loss: 0.0109\n",
      "Epoch 172/200, Iteration 69/250, Loss: 0.0092\n",
      "Epoch 172/200, Iteration 70/250, Loss: 0.0165\n",
      "Epoch 172/200, Iteration 71/250, Loss: 0.0129\n",
      "Epoch 172/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 172/200, Iteration 73/250, Loss: 0.0204\n",
      "Epoch 172/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 172/200, Iteration 75/250, Loss: 0.0160\n",
      "Epoch 172/200, Iteration 76/250, Loss: 0.0401\n",
      "Epoch 172/200, Iteration 77/250, Loss: 0.0126\n",
      "Epoch 172/200, Iteration 78/250, Loss: 0.0395\n",
      "Epoch 172/200, Iteration 79/250, Loss: 0.0080\n",
      "Epoch 172/200, Iteration 80/250, Loss: 0.0185\n",
      "Epoch 172/200, Iteration 81/250, Loss: 0.0177\n",
      "Epoch 172/200, Iteration 82/250, Loss: 0.0079\n",
      "Epoch 172/200, Iteration 83/250, Loss: 0.0176\n",
      "Epoch 172/200, Iteration 84/250, Loss: 0.0158\n",
      "Epoch 172/200, Iteration 85/250, Loss: 0.0159\n",
      "Epoch 172/200, Iteration 86/250, Loss: 0.0101\n",
      "Epoch 172/200, Iteration 87/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 88/250, Loss: 0.0084\n",
      "Epoch 172/200, Iteration 89/250, Loss: 0.0097\n",
      "Epoch 172/200, Iteration 90/250, Loss: 0.0162\n",
      "Epoch 172/200, Iteration 91/250, Loss: 0.0121\n",
      "Epoch 172/200, Iteration 92/250, Loss: 0.0103\n",
      "Epoch 172/200, Iteration 93/250, Loss: 0.0197\n",
      "Epoch 172/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 95/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 96/250, Loss: 0.0272\n",
      "Epoch 172/200, Iteration 97/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 98/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 99/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 101/250, Loss: 0.0229\n",
      "Epoch 172/200, Iteration 102/250, Loss: 0.0058\n",
      "Epoch 172/200, Iteration 103/250, Loss: 0.0155\n",
      "Epoch 172/200, Iteration 104/250, Loss: 0.0130\n",
      "Epoch 172/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 172/200, Iteration 106/250, Loss: 0.0232\n",
      "Epoch 172/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 172/200, Iteration 108/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 109/250, Loss: 0.0263\n",
      "Epoch 172/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 111/250, Loss: 0.0150\n",
      "Epoch 172/200, Iteration 112/250, Loss: 0.0142\n",
      "Epoch 172/200, Iteration 113/250, Loss: 0.0110\n",
      "Epoch 172/200, Iteration 114/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 115/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 172/200, Iteration 117/250, Loss: 0.0174\n",
      "Epoch 172/200, Iteration 118/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 119/250, Loss: 0.0177\n",
      "Epoch 172/200, Iteration 120/250, Loss: 0.0059\n",
      "Epoch 172/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 172/200, Iteration 122/250, Loss: 0.0209\n",
      "Epoch 172/200, Iteration 123/250, Loss: 0.0164\n",
      "Epoch 172/200, Iteration 124/250, Loss: 0.0256\n",
      "Epoch 172/200, Iteration 125/250, Loss: 0.0221\n",
      "Epoch 172/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 172/200, Iteration 127/250, Loss: 0.0123\n",
      "Epoch 172/200, Iteration 128/250, Loss: 0.0343\n",
      "Epoch 172/200, Iteration 129/250, Loss: 0.0096\n",
      "Epoch 172/200, Iteration 130/250, Loss: 0.0073\n",
      "Epoch 172/200, Iteration 131/250, Loss: 0.0147\n",
      "Epoch 172/200, Iteration 132/250, Loss: 0.0147\n",
      "Epoch 172/200, Iteration 133/250, Loss: 0.0328\n",
      "Epoch 172/200, Iteration 134/250, Loss: 0.0162\n",
      "Epoch 172/200, Iteration 135/250, Loss: 0.0168\n",
      "Epoch 172/200, Iteration 136/250, Loss: 0.0245\n",
      "Epoch 172/200, Iteration 137/250, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 138/250, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 139/250, Loss: 0.0100\n",
      "Epoch 172/200, Iteration 140/250, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 141/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 142/250, Loss: 0.0113\n",
      "Epoch 172/200, Iteration 143/250, Loss: 0.0207\n",
      "Epoch 172/200, Iteration 144/250, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 145/250, Loss: 0.0140\n",
      "Epoch 172/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 172/200, Iteration 147/250, Loss: 0.0055\n",
      "Epoch 172/200, Iteration 148/250, Loss: 0.0124\n",
      "Epoch 172/200, Iteration 149/250, Loss: 0.0072\n",
      "Epoch 172/200, Iteration 150/250, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 152/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 153/250, Loss: 0.0118\n",
      "Epoch 172/200, Iteration 154/250, Loss: 0.0169\n",
      "Epoch 172/200, Iteration 155/250, Loss: 0.0275\n",
      "Epoch 172/200, Iteration 156/250, Loss: 0.0058\n",
      "Epoch 172/200, Iteration 157/250, Loss: 0.0068\n",
      "Epoch 172/200, Iteration 158/250, Loss: 0.0089\n",
      "Epoch 172/200, Iteration 159/250, Loss: 0.0098\n",
      "Epoch 172/200, Iteration 160/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 161/250, Loss: 0.0274\n",
      "Epoch 172/200, Iteration 162/250, Loss: 0.0080\n",
      "Epoch 172/200, Iteration 163/250, Loss: 0.0060\n",
      "Epoch 172/200, Iteration 164/250, Loss: 0.0203\n",
      "Epoch 172/200, Iteration 165/250, Loss: 0.0128\n",
      "Epoch 172/200, Iteration 166/250, Loss: 0.0107\n",
      "Epoch 172/200, Iteration 167/250, Loss: 0.0072\n",
      "Epoch 172/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 169/250, Loss: 0.0199\n",
      "Epoch 172/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 171/250, Loss: 0.0398\n",
      "Epoch 172/200, Iteration 172/250, Loss: 0.0198\n",
      "Epoch 172/200, Iteration 173/250, Loss: 0.0158\n",
      "Epoch 172/200, Iteration 174/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 175/250, Loss: 0.0164\n",
      "Epoch 172/200, Iteration 176/250, Loss: 0.0144\n",
      "Epoch 172/200, Iteration 177/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 178/250, Loss: 0.0109\n",
      "Epoch 172/200, Iteration 179/250, Loss: 0.0292\n",
      "Epoch 172/200, Iteration 180/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 181/250, Loss: 0.0097\n",
      "Epoch 172/200, Iteration 182/250, Loss: 0.0209\n",
      "Epoch 172/200, Iteration 183/250, Loss: 0.0120\n",
      "Epoch 172/200, Iteration 184/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 185/250, Loss: 0.0237\n",
      "Epoch 172/200, Iteration 186/250, Loss: 0.0298\n",
      "Epoch 172/200, Iteration 187/250, Loss: 0.0138\n",
      "Epoch 172/200, Iteration 188/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 189/250, Loss: 0.0373\n",
      "Epoch 172/200, Iteration 190/250, Loss: 0.0305\n",
      "Epoch 172/200, Iteration 191/250, Loss: 0.0154\n",
      "Epoch 172/200, Iteration 192/250, Loss: 0.0291\n",
      "Epoch 172/200, Iteration 193/250, Loss: 0.0071\n",
      "Epoch 172/200, Iteration 194/250, Loss: 0.0069\n",
      "Epoch 172/200, Iteration 195/250, Loss: 0.0123\n",
      "Epoch 172/200, Iteration 196/250, Loss: 0.0063\n",
      "Epoch 172/200, Iteration 197/250, Loss: 0.0340\n",
      "Epoch 172/200, Iteration 198/250, Loss: 0.0230\n",
      "Epoch 172/200, Iteration 199/250, Loss: 0.0186\n",
      "Epoch 172/200, Iteration 200/250, Loss: 0.0132\n",
      "Epoch 172/200, Iteration 201/250, Loss: 0.0147\n",
      "Epoch 172/200, Iteration 202/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 203/250, Loss: 0.0088\n",
      "Epoch 172/200, Iteration 204/250, Loss: 0.0288\n",
      "Epoch 172/200, Iteration 205/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 206/250, Loss: 0.0056\n",
      "Epoch 172/200, Iteration 207/250, Loss: 0.0105\n",
      "Epoch 172/200, Iteration 208/250, Loss: 0.0229\n",
      "Epoch 172/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 172/200, Iteration 210/250, Loss: 0.0276\n",
      "Epoch 172/200, Iteration 211/250, Loss: 0.0135\n",
      "Epoch 172/200, Iteration 212/250, Loss: 0.0310\n",
      "Epoch 172/200, Iteration 213/250, Loss: 0.0128\n",
      "Epoch 172/200, Iteration 214/250, Loss: 0.0064\n",
      "Epoch 172/200, Iteration 215/250, Loss: 0.0246\n",
      "Epoch 172/200, Iteration 216/250, Loss: 0.0236\n",
      "Epoch 172/200, Iteration 217/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 218/250, Loss: 0.0110\n",
      "Epoch 172/200, Iteration 219/250, Loss: 0.0288\n",
      "Epoch 172/200, Iteration 220/250, Loss: 0.0271\n",
      "Epoch 172/200, Iteration 221/250, Loss: 0.0074\n",
      "Epoch 172/200, Iteration 222/250, Loss: 0.0095\n",
      "Epoch 172/200, Iteration 223/250, Loss: 0.0255\n",
      "Epoch 172/200, Iteration 224/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 225/250, Loss: 0.0152\n",
      "Epoch 172/200, Iteration 226/250, Loss: 0.0126\n",
      "Epoch 172/200, Iteration 227/250, Loss: 0.0142\n",
      "Epoch 172/200, Iteration 228/250, Loss: 0.0093\n",
      "Epoch 172/200, Iteration 229/250, Loss: 0.0191\n",
      "Epoch 172/200, Iteration 230/250, Loss: 0.0193\n",
      "Epoch 172/200, Iteration 231/250, Loss: 0.0079\n",
      "Epoch 172/200, Iteration 232/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 233/250, Loss: 0.0068\n",
      "Epoch 172/200, Iteration 234/250, Loss: 0.0100\n",
      "Epoch 172/200, Iteration 235/250, Loss: 0.0209\n",
      "Epoch 172/200, Iteration 236/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 237/250, Loss: 0.0150\n",
      "Epoch 172/200, Iteration 238/250, Loss: 0.0156\n",
      "Epoch 172/200, Iteration 239/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 240/250, Loss: 0.0138\n",
      "Epoch 172/200, Iteration 241/250, Loss: 0.0167\n",
      "Epoch 172/200, Iteration 242/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200, Iteration 243/250, Loss: 0.0103\n",
      "Epoch 172/200, Iteration 244/250, Loss: 0.0206\n",
      "Epoch 172/200, Iteration 245/250, Loss: 0.0099\n",
      "Epoch 172/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 172/200, Iteration 247/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 248/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 172/200, Iteration 250/250, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 96.56%, Avg loss: 0.005911, MRE: 0.605803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.005886, MRE: 0.986477 \n",
      "\n",
      "Epoch 173/200, Iteration 1/250, Loss: 0.0239\n",
      "Epoch 173/200, Iteration 2/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 3/250, Loss: 0.0118\n",
      "Epoch 173/200, Iteration 4/250, Loss: 0.0108\n",
      "Epoch 173/200, Iteration 5/250, Loss: 0.0135\n",
      "Epoch 173/200, Iteration 6/250, Loss: 0.0199\n",
      "Epoch 173/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 173/200, Iteration 8/250, Loss: 0.0126\n",
      "Epoch 173/200, Iteration 9/250, Loss: 0.0142\n",
      "Epoch 173/200, Iteration 10/250, Loss: 0.0091\n",
      "Epoch 173/200, Iteration 11/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 12/250, Loss: 0.0072\n",
      "Epoch 173/200, Iteration 13/250, Loss: 0.0267\n",
      "Epoch 173/200, Iteration 14/250, Loss: 0.0156\n",
      "Epoch 173/200, Iteration 15/250, Loss: 0.0159\n",
      "Epoch 173/200, Iteration 16/250, Loss: 0.0284\n",
      "Epoch 173/200, Iteration 17/250, Loss: 0.0077\n",
      "Epoch 173/200, Iteration 18/250, Loss: 0.0150\n",
      "Epoch 173/200, Iteration 19/250, Loss: 0.0130\n",
      "Epoch 173/200, Iteration 20/250, Loss: 0.0241\n",
      "Epoch 173/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 173/200, Iteration 22/250, Loss: 0.0094\n",
      "Epoch 173/200, Iteration 23/250, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 24/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 25/250, Loss: 0.0246\n",
      "Epoch 173/200, Iteration 26/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 27/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 28/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 29/250, Loss: 0.0202\n",
      "Epoch 173/200, Iteration 30/250, Loss: 0.0118\n",
      "Epoch 173/200, Iteration 31/250, Loss: 0.0080\n",
      "Epoch 173/200, Iteration 32/250, Loss: 0.0137\n",
      "Epoch 173/200, Iteration 33/250, Loss: 0.0122\n",
      "Epoch 173/200, Iteration 34/250, Loss: 0.0168\n",
      "Epoch 173/200, Iteration 35/250, Loss: 0.0065\n",
      "Epoch 173/200, Iteration 36/250, Loss: 0.0131\n",
      "Epoch 173/200, Iteration 37/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 173/200, Iteration 39/250, Loss: 0.0142\n",
      "Epoch 173/200, Iteration 40/250, Loss: 0.0277\n",
      "Epoch 173/200, Iteration 41/250, Loss: 0.0171\n",
      "Epoch 173/200, Iteration 42/250, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 43/250, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 44/250, Loss: 0.0056\n",
      "Epoch 173/200, Iteration 45/250, Loss: 0.0192\n",
      "Epoch 173/200, Iteration 46/250, Loss: 0.0253\n",
      "Epoch 173/200, Iteration 47/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 48/250, Loss: 0.0154\n",
      "Epoch 173/200, Iteration 49/250, Loss: 0.0084\n",
      "Epoch 173/200, Iteration 50/250, Loss: 0.0103\n",
      "Epoch 173/200, Iteration 51/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 52/250, Loss: 0.0208\n",
      "Epoch 173/200, Iteration 53/250, Loss: 0.0177\n",
      "Epoch 173/200, Iteration 54/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 55/250, Loss: 0.0119\n",
      "Epoch 173/200, Iteration 56/250, Loss: 0.0309\n",
      "Epoch 173/200, Iteration 57/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 58/250, Loss: 0.0100\n",
      "Epoch 173/200, Iteration 59/250, Loss: 0.0432\n",
      "Epoch 173/200, Iteration 60/250, Loss: 0.0150\n",
      "Epoch 173/200, Iteration 61/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 62/250, Loss: 0.0087\n",
      "Epoch 173/200, Iteration 63/250, Loss: 0.0194\n",
      "Epoch 173/200, Iteration 64/250, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 65/250, Loss: 0.0076\n",
      "Epoch 173/200, Iteration 66/250, Loss: 0.0137\n",
      "Epoch 173/200, Iteration 67/250, Loss: 0.0153\n",
      "Epoch 173/200, Iteration 68/250, Loss: 0.0166\n",
      "Epoch 173/200, Iteration 69/250, Loss: 0.0146\n",
      "Epoch 173/200, Iteration 70/250, Loss: 0.0179\n",
      "Epoch 173/200, Iteration 71/250, Loss: 0.0263\n",
      "Epoch 173/200, Iteration 72/250, Loss: 0.0279\n",
      "Epoch 173/200, Iteration 73/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 74/250, Loss: 0.0076\n",
      "Epoch 173/200, Iteration 75/250, Loss: 0.0070\n",
      "Epoch 173/200, Iteration 76/250, Loss: 0.0152\n",
      "Epoch 173/200, Iteration 77/250, Loss: 0.0261\n",
      "Epoch 173/200, Iteration 78/250, Loss: 0.0086\n",
      "Epoch 173/200, Iteration 79/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 80/250, Loss: 0.0126\n",
      "Epoch 173/200, Iteration 81/250, Loss: 0.0071\n",
      "Epoch 173/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 83/250, Loss: 0.0190\n",
      "Epoch 173/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 85/250, Loss: 0.0086\n",
      "Epoch 173/200, Iteration 86/250, Loss: 0.0132\n",
      "Epoch 173/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 173/200, Iteration 88/250, Loss: 0.0087\n",
      "Epoch 173/200, Iteration 89/250, Loss: 0.0059\n",
      "Epoch 173/200, Iteration 90/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 91/250, Loss: 0.0144\n",
      "Epoch 173/200, Iteration 92/250, Loss: 0.0084\n",
      "Epoch 173/200, Iteration 93/250, Loss: 0.0307\n",
      "Epoch 173/200, Iteration 94/250, Loss: 0.0070\n",
      "Epoch 173/200, Iteration 95/250, Loss: 0.0107\n",
      "Epoch 173/200, Iteration 96/250, Loss: 0.0248\n",
      "Epoch 173/200, Iteration 97/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 98/250, Loss: 0.0155\n",
      "Epoch 173/200, Iteration 99/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 101/250, Loss: 0.0149\n",
      "Epoch 173/200, Iteration 102/250, Loss: 0.0252\n",
      "Epoch 173/200, Iteration 103/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 104/250, Loss: 0.0288\n",
      "Epoch 173/200, Iteration 105/250, Loss: 0.0121\n",
      "Epoch 173/200, Iteration 106/250, Loss: 0.0181\n",
      "Epoch 173/200, Iteration 107/250, Loss: 0.0128\n",
      "Epoch 173/200, Iteration 108/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 109/250, Loss: 0.0235\n",
      "Epoch 173/200, Iteration 110/250, Loss: 0.0243\n",
      "Epoch 173/200, Iteration 111/250, Loss: 0.0069\n",
      "Epoch 173/200, Iteration 112/250, Loss: 0.0146\n",
      "Epoch 173/200, Iteration 113/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 114/250, Loss: 0.0161\n",
      "Epoch 173/200, Iteration 115/250, Loss: 0.0161\n",
      "Epoch 173/200, Iteration 116/250, Loss: 0.0225\n",
      "Epoch 173/200, Iteration 117/250, Loss: 0.0157\n",
      "Epoch 173/200, Iteration 118/250, Loss: 0.0078\n",
      "Epoch 173/200, Iteration 119/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 120/250, Loss: 0.0149\n",
      "Epoch 173/200, Iteration 121/250, Loss: 0.0076\n",
      "Epoch 173/200, Iteration 122/250, Loss: 0.0213\n",
      "Epoch 173/200, Iteration 123/250, Loss: 0.0087\n",
      "Epoch 173/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 173/200, Iteration 125/250, Loss: 0.0091\n",
      "Epoch 173/200, Iteration 126/250, Loss: 0.0176\n",
      "Epoch 173/200, Iteration 127/250, Loss: 0.0079\n",
      "Epoch 173/200, Iteration 128/250, Loss: 0.0241\n",
      "Epoch 173/200, Iteration 129/250, Loss: 0.0108\n",
      "Epoch 173/200, Iteration 130/250, Loss: 0.0130\n",
      "Epoch 173/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 132/250, Loss: 0.0133\n",
      "Epoch 173/200, Iteration 133/250, Loss: 0.0233\n",
      "Epoch 173/200, Iteration 134/250, Loss: 0.0078\n",
      "Epoch 173/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 173/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 173/200, Iteration 137/250, Loss: 0.0114\n",
      "Epoch 173/200, Iteration 138/250, Loss: 0.0123\n",
      "Epoch 173/200, Iteration 139/250, Loss: 0.0143\n",
      "Epoch 173/200, Iteration 140/250, Loss: 0.0395\n",
      "Epoch 173/200, Iteration 141/250, Loss: 0.0057\n",
      "Epoch 173/200, Iteration 142/250, Loss: 0.0088\n",
      "Epoch 173/200, Iteration 143/250, Loss: 0.0256\n",
      "Epoch 173/200, Iteration 144/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 145/250, Loss: 0.0207\n",
      "Epoch 173/200, Iteration 146/250, Loss: 0.0160\n",
      "Epoch 173/200, Iteration 147/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 148/250, Loss: 0.0077\n",
      "Epoch 173/200, Iteration 149/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 150/250, Loss: 0.0185\n",
      "Epoch 173/200, Iteration 151/250, Loss: 0.0125\n",
      "Epoch 173/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 153/250, Loss: 0.0157\n",
      "Epoch 173/200, Iteration 154/250, Loss: 0.0340\n",
      "Epoch 173/200, Iteration 155/250, Loss: 0.0101\n",
      "Epoch 173/200, Iteration 156/250, Loss: 0.0181\n",
      "Epoch 173/200, Iteration 157/250, Loss: 0.0104\n",
      "Epoch 173/200, Iteration 158/250, Loss: 0.0187\n",
      "Epoch 173/200, Iteration 159/250, Loss: 0.0311\n",
      "Epoch 173/200, Iteration 160/250, Loss: 0.0163\n",
      "Epoch 173/200, Iteration 161/250, Loss: 0.0314\n",
      "Epoch 173/200, Iteration 162/250, Loss: 0.0081\n",
      "Epoch 173/200, Iteration 163/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 164/250, Loss: 0.0101\n",
      "Epoch 173/200, Iteration 165/250, Loss: 0.0108\n",
      "Epoch 173/200, Iteration 166/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 167/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 168/250, Loss: 0.0105\n",
      "Epoch 173/200, Iteration 169/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 170/250, Loss: 0.0116\n",
      "Epoch 173/200, Iteration 171/250, Loss: 0.0130\n",
      "Epoch 173/200, Iteration 172/250, Loss: 0.0176\n",
      "Epoch 173/200, Iteration 173/250, Loss: 0.0079\n",
      "Epoch 173/200, Iteration 174/250, Loss: 0.0081\n",
      "Epoch 173/200, Iteration 175/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 176/250, Loss: 0.0074\n",
      "Epoch 173/200, Iteration 177/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 178/250, Loss: 0.0227\n",
      "Epoch 173/200, Iteration 179/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 173/200, Iteration 181/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 182/250, Loss: 0.0338\n",
      "Epoch 173/200, Iteration 183/250, Loss: 0.0090\n",
      "Epoch 173/200, Iteration 184/250, Loss: 0.0133\n",
      "Epoch 173/200, Iteration 185/250, Loss: 0.0133\n",
      "Epoch 173/200, Iteration 186/250, Loss: 0.0089\n",
      "Epoch 173/200, Iteration 187/250, Loss: 0.0212\n",
      "Epoch 173/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 189/250, Loss: 0.0209\n",
      "Epoch 173/200, Iteration 190/250, Loss: 0.0195\n",
      "Epoch 173/200, Iteration 191/250, Loss: 0.0152\n",
      "Epoch 173/200, Iteration 192/250, Loss: 0.0100\n",
      "Epoch 173/200, Iteration 193/250, Loss: 0.0089\n",
      "Epoch 173/200, Iteration 194/250, Loss: 0.0207\n",
      "Epoch 173/200, Iteration 195/250, Loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200, Iteration 196/250, Loss: 0.0081\n",
      "Epoch 173/200, Iteration 197/250, Loss: 0.0066\n",
      "Epoch 173/200, Iteration 198/250, Loss: 0.0213\n",
      "Epoch 173/200, Iteration 199/250, Loss: 0.0094\n",
      "Epoch 173/200, Iteration 200/250, Loss: 0.0101\n",
      "Epoch 173/200, Iteration 201/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 202/250, Loss: 0.0171\n",
      "Epoch 173/200, Iteration 203/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 204/250, Loss: 0.0179\n",
      "Epoch 173/200, Iteration 205/250, Loss: 0.0204\n",
      "Epoch 173/200, Iteration 206/250, Loss: 0.0208\n",
      "Epoch 173/200, Iteration 207/250, Loss: 0.0120\n",
      "Epoch 173/200, Iteration 208/250, Loss: 0.0067\n",
      "Epoch 173/200, Iteration 209/250, Loss: 0.0103\n",
      "Epoch 173/200, Iteration 210/250, Loss: 0.0396\n",
      "Epoch 173/200, Iteration 211/250, Loss: 0.0272\n",
      "Epoch 173/200, Iteration 212/250, Loss: 0.0130\n",
      "Epoch 173/200, Iteration 213/250, Loss: 0.0159\n",
      "Epoch 173/200, Iteration 214/250, Loss: 0.0086\n",
      "Epoch 173/200, Iteration 215/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 216/250, Loss: 0.0328\n",
      "Epoch 173/200, Iteration 217/250, Loss: 0.0154\n",
      "Epoch 173/200, Iteration 218/250, Loss: 0.0084\n",
      "Epoch 173/200, Iteration 219/250, Loss: 0.0109\n",
      "Epoch 173/200, Iteration 220/250, Loss: 0.0260\n",
      "Epoch 173/200, Iteration 221/250, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 222/250, Loss: 0.0132\n",
      "Epoch 173/200, Iteration 223/250, Loss: 0.0159\n",
      "Epoch 173/200, Iteration 224/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 225/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 226/250, Loss: 0.0274\n",
      "Epoch 173/200, Iteration 227/250, Loss: 0.0127\n",
      "Epoch 173/200, Iteration 228/250, Loss: 0.0072\n",
      "Epoch 173/200, Iteration 229/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 230/250, Loss: 0.0134\n",
      "Epoch 173/200, Iteration 231/250, Loss: 0.0154\n",
      "Epoch 173/200, Iteration 232/250, Loss: 0.0228\n",
      "Epoch 173/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 173/200, Iteration 234/250, Loss: 0.0474\n",
      "Epoch 173/200, Iteration 235/250, Loss: 0.0197\n",
      "Epoch 173/200, Iteration 236/250, Loss: 0.0133\n",
      "Epoch 173/200, Iteration 237/250, Loss: 0.0167\n",
      "Epoch 173/200, Iteration 238/250, Loss: 0.0223\n",
      "Epoch 173/200, Iteration 239/250, Loss: 0.0398\n",
      "Epoch 173/200, Iteration 240/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 241/250, Loss: 0.0135\n",
      "Epoch 173/200, Iteration 242/250, Loss: 0.0105\n",
      "Epoch 173/200, Iteration 243/250, Loss: 0.0078\n",
      "Epoch 173/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 173/200, Iteration 245/250, Loss: 0.0149\n",
      "Epoch 173/200, Iteration 246/250, Loss: 0.0188\n",
      "Epoch 173/200, Iteration 247/250, Loss: 0.0205\n",
      "Epoch 173/200, Iteration 248/250, Loss: 0.0245\n",
      "Epoch 173/200, Iteration 249/250, Loss: 0.0188\n",
      "Epoch 173/200, Iteration 250/250, Loss: 0.0125\n",
      "Train Error: \n",
      " Accuracy: 94.49%, Avg loss: 0.005900, MRE: 0.618247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.005925, MRE: 1.012892 \n",
      "\n",
      "Epoch 174/200, Iteration 1/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 2/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 3/250, Loss: 0.0107\n",
      "Epoch 174/200, Iteration 4/250, Loss: 0.0074\n",
      "Epoch 174/200, Iteration 5/250, Loss: 0.0143\n",
      "Epoch 174/200, Iteration 6/250, Loss: 0.0069\n",
      "Epoch 174/200, Iteration 7/250, Loss: 0.0158\n",
      "Epoch 174/200, Iteration 8/250, Loss: 0.0140\n",
      "Epoch 174/200, Iteration 9/250, Loss: 0.0220\n",
      "Epoch 174/200, Iteration 10/250, Loss: 0.0131\n",
      "Epoch 174/200, Iteration 11/250, Loss: 0.0086\n",
      "Epoch 174/200, Iteration 12/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 13/250, Loss: 0.0100\n",
      "Epoch 174/200, Iteration 14/250, Loss: 0.0180\n",
      "Epoch 174/200, Iteration 15/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 16/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 174/200, Iteration 18/250, Loss: 0.0283\n",
      "Epoch 174/200, Iteration 19/250, Loss: 0.0167\n",
      "Epoch 174/200, Iteration 20/250, Loss: 0.0375\n",
      "Epoch 174/200, Iteration 21/250, Loss: 0.0072\n",
      "Epoch 174/200, Iteration 22/250, Loss: 0.0157\n",
      "Epoch 174/200, Iteration 23/250, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 24/250, Loss: 0.0193\n",
      "Epoch 174/200, Iteration 25/250, Loss: 0.0143\n",
      "Epoch 174/200, Iteration 26/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 27/250, Loss: 0.0147\n",
      "Epoch 174/200, Iteration 28/250, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 29/250, Loss: 0.0269\n",
      "Epoch 174/200, Iteration 30/250, Loss: 0.0207\n",
      "Epoch 174/200, Iteration 31/250, Loss: 0.0167\n",
      "Epoch 174/200, Iteration 32/250, Loss: 0.0297\n",
      "Epoch 174/200, Iteration 33/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 34/250, Loss: 0.0110\n",
      "Epoch 174/200, Iteration 35/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 36/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 37/250, Loss: 0.0141\n",
      "Epoch 174/200, Iteration 38/250, Loss: 0.0140\n",
      "Epoch 174/200, Iteration 39/250, Loss: 0.0164\n",
      "Epoch 174/200, Iteration 40/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 41/250, Loss: 0.0303\n",
      "Epoch 174/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 43/250, Loss: 0.0126\n",
      "Epoch 174/200, Iteration 44/250, Loss: 0.0205\n",
      "Epoch 174/200, Iteration 45/250, Loss: 0.0083\n",
      "Epoch 174/200, Iteration 46/250, Loss: 0.0084\n",
      "Epoch 174/200, Iteration 47/250, Loss: 0.0083\n",
      "Epoch 174/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 174/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 174/200, Iteration 50/250, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 51/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 52/250, Loss: 0.0110\n",
      "Epoch 174/200, Iteration 53/250, Loss: 0.0149\n",
      "Epoch 174/200, Iteration 54/250, Loss: 0.0078\n",
      "Epoch 174/200, Iteration 55/250, Loss: 0.0105\n",
      "Epoch 174/200, Iteration 56/250, Loss: 0.0185\n",
      "Epoch 174/200, Iteration 57/250, Loss: 0.0139\n",
      "Epoch 174/200, Iteration 58/250, Loss: 0.0304\n",
      "Epoch 174/200, Iteration 59/250, Loss: 0.0115\n",
      "Epoch 174/200, Iteration 60/250, Loss: 0.0175\n",
      "Epoch 174/200, Iteration 61/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 62/250, Loss: 0.0068\n",
      "Epoch 174/200, Iteration 63/250, Loss: 0.0081\n",
      "Epoch 174/200, Iteration 64/250, Loss: 0.0256\n",
      "Epoch 174/200, Iteration 65/250, Loss: 0.0139\n",
      "Epoch 174/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 174/200, Iteration 67/250, Loss: 0.0200\n",
      "Epoch 174/200, Iteration 68/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 69/250, Loss: 0.0156\n",
      "Epoch 174/200, Iteration 70/250, Loss: 0.0087\n",
      "Epoch 174/200, Iteration 71/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 72/250, Loss: 0.0068\n",
      "Epoch 174/200, Iteration 73/250, Loss: 0.0110\n",
      "Epoch 174/200, Iteration 74/250, Loss: 0.0196\n",
      "Epoch 174/200, Iteration 75/250, Loss: 0.0229\n",
      "Epoch 174/200, Iteration 76/250, Loss: 0.0172\n",
      "Epoch 174/200, Iteration 77/250, Loss: 0.0158\n",
      "Epoch 174/200, Iteration 78/250, Loss: 0.0429\n",
      "Epoch 174/200, Iteration 79/250, Loss: 0.0198\n",
      "Epoch 174/200, Iteration 80/250, Loss: 0.0149\n",
      "Epoch 174/200, Iteration 81/250, Loss: 0.0074\n",
      "Epoch 174/200, Iteration 82/250, Loss: 0.0295\n",
      "Epoch 174/200, Iteration 83/250, Loss: 0.0095\n",
      "Epoch 174/200, Iteration 84/250, Loss: 0.0141\n",
      "Epoch 174/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 174/200, Iteration 86/250, Loss: 0.0134\n",
      "Epoch 174/200, Iteration 87/250, Loss: 0.0190\n",
      "Epoch 174/200, Iteration 88/250, Loss: 0.0230\n",
      "Epoch 174/200, Iteration 89/250, Loss: 0.0125\n",
      "Epoch 174/200, Iteration 90/250, Loss: 0.0164\n",
      "Epoch 174/200, Iteration 91/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 174/200, Iteration 93/250, Loss: 0.0185\n",
      "Epoch 174/200, Iteration 94/250, Loss: 0.0136\n",
      "Epoch 174/200, Iteration 95/250, Loss: 0.0173\n",
      "Epoch 174/200, Iteration 96/250, Loss: 0.0089\n",
      "Epoch 174/200, Iteration 97/250, Loss: 0.0134\n",
      "Epoch 174/200, Iteration 98/250, Loss: 0.0184\n",
      "Epoch 174/200, Iteration 99/250, Loss: 0.0067\n",
      "Epoch 174/200, Iteration 100/250, Loss: 0.0075\n",
      "Epoch 174/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 174/200, Iteration 102/250, Loss: 0.0290\n",
      "Epoch 174/200, Iteration 103/250, Loss: 0.0172\n",
      "Epoch 174/200, Iteration 104/250, Loss: 0.0195\n",
      "Epoch 174/200, Iteration 105/250, Loss: 0.0183\n",
      "Epoch 174/200, Iteration 106/250, Loss: 0.0136\n",
      "Epoch 174/200, Iteration 107/250, Loss: 0.0217\n",
      "Epoch 174/200, Iteration 108/250, Loss: 0.0077\n",
      "Epoch 174/200, Iteration 109/250, Loss: 0.0093\n",
      "Epoch 174/200, Iteration 110/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 111/250, Loss: 0.0127\n",
      "Epoch 174/200, Iteration 112/250, Loss: 0.0306\n",
      "Epoch 174/200, Iteration 113/250, Loss: 0.0195\n",
      "Epoch 174/200, Iteration 114/250, Loss: 0.0127\n",
      "Epoch 174/200, Iteration 115/250, Loss: 0.0180\n",
      "Epoch 174/200, Iteration 116/250, Loss: 0.0134\n",
      "Epoch 174/200, Iteration 117/250, Loss: 0.0261\n",
      "Epoch 174/200, Iteration 118/250, Loss: 0.0117\n",
      "Epoch 174/200, Iteration 119/250, Loss: 0.0203\n",
      "Epoch 174/200, Iteration 120/250, Loss: 0.0182\n",
      "Epoch 174/200, Iteration 121/250, Loss: 0.0219\n",
      "Epoch 174/200, Iteration 122/250, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200, Iteration 123/250, Loss: 0.0204\n",
      "Epoch 174/200, Iteration 124/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 125/250, Loss: 0.0111\n",
      "Epoch 174/200, Iteration 126/250, Loss: 0.0146\n",
      "Epoch 174/200, Iteration 127/250, Loss: 0.0055\n",
      "Epoch 174/200, Iteration 128/250, Loss: 0.0192\n",
      "Epoch 174/200, Iteration 129/250, Loss: 0.0064\n",
      "Epoch 174/200, Iteration 130/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 131/250, Loss: 0.0101\n",
      "Epoch 174/200, Iteration 132/250, Loss: 0.0115\n",
      "Epoch 174/200, Iteration 133/250, Loss: 0.0084\n",
      "Epoch 174/200, Iteration 134/250, Loss: 0.0234\n",
      "Epoch 174/200, Iteration 135/250, Loss: 0.0183\n",
      "Epoch 174/200, Iteration 136/250, Loss: 0.0261\n",
      "Epoch 174/200, Iteration 137/250, Loss: 0.0114\n",
      "Epoch 174/200, Iteration 138/250, Loss: 0.0122\n",
      "Epoch 174/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 174/200, Iteration 140/250, Loss: 0.0089\n",
      "Epoch 174/200, Iteration 141/250, Loss: 0.0099\n",
      "Epoch 174/200, Iteration 142/250, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 143/250, Loss: 0.0119\n",
      "Epoch 174/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 174/200, Iteration 145/250, Loss: 0.0222\n",
      "Epoch 174/200, Iteration 146/250, Loss: 0.0065\n",
      "Epoch 174/200, Iteration 147/250, Loss: 0.0136\n",
      "Epoch 174/200, Iteration 148/250, Loss: 0.0153\n",
      "Epoch 174/200, Iteration 149/250, Loss: 0.0334\n",
      "Epoch 174/200, Iteration 150/250, Loss: 0.0112\n",
      "Epoch 174/200, Iteration 151/250, Loss: 0.0221\n",
      "Epoch 174/200, Iteration 152/250, Loss: 0.0117\n",
      "Epoch 174/200, Iteration 153/250, Loss: 0.0263\n",
      "Epoch 174/200, Iteration 154/250, Loss: 0.0326\n",
      "Epoch 174/200, Iteration 155/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 156/250, Loss: 0.0376\n",
      "Epoch 174/200, Iteration 157/250, Loss: 0.0240\n",
      "Epoch 174/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 174/200, Iteration 159/250, Loss: 0.0200\n",
      "Epoch 174/200, Iteration 160/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 161/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 162/250, Loss: 0.0201\n",
      "Epoch 174/200, Iteration 163/250, Loss: 0.0173\n",
      "Epoch 174/200, Iteration 164/250, Loss: 0.0138\n",
      "Epoch 174/200, Iteration 165/250, Loss: 0.0071\n",
      "Epoch 174/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 174/200, Iteration 167/250, Loss: 0.0180\n",
      "Epoch 174/200, Iteration 168/250, Loss: 0.0208\n",
      "Epoch 174/200, Iteration 169/250, Loss: 0.0385\n",
      "Epoch 174/200, Iteration 170/250, Loss: 0.0233\n",
      "Epoch 174/200, Iteration 171/250, Loss: 0.0137\n",
      "Epoch 174/200, Iteration 172/250, Loss: 0.0074\n",
      "Epoch 174/200, Iteration 173/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 174/200, Iteration 175/250, Loss: 0.0159\n",
      "Epoch 174/200, Iteration 176/250, Loss: 0.0145\n",
      "Epoch 174/200, Iteration 177/250, Loss: 0.0164\n",
      "Epoch 174/200, Iteration 178/250, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 179/250, Loss: 0.0184\n",
      "Epoch 174/200, Iteration 180/250, Loss: 0.0368\n",
      "Epoch 174/200, Iteration 181/250, Loss: 0.0194\n",
      "Epoch 174/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 183/250, Loss: 0.0098\n",
      "Epoch 174/200, Iteration 184/250, Loss: 0.0137\n",
      "Epoch 174/200, Iteration 185/250, Loss: 0.0254\n",
      "Epoch 174/200, Iteration 186/250, Loss: 0.0208\n",
      "Epoch 174/200, Iteration 187/250, Loss: 0.0060\n",
      "Epoch 174/200, Iteration 188/250, Loss: 0.0073\n",
      "Epoch 174/200, Iteration 189/250, Loss: 0.0057\n",
      "Epoch 174/200, Iteration 190/250, Loss: 0.0185\n",
      "Epoch 174/200, Iteration 191/250, Loss: 0.0147\n",
      "Epoch 174/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 193/250, Loss: 0.0262\n",
      "Epoch 174/200, Iteration 194/250, Loss: 0.0246\n",
      "Epoch 174/200, Iteration 195/250, Loss: 0.0209\n",
      "Epoch 174/200, Iteration 196/250, Loss: 0.0190\n",
      "Epoch 174/200, Iteration 197/250, Loss: 0.0136\n",
      "Epoch 174/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 174/200, Iteration 199/250, Loss: 0.0125\n",
      "Epoch 174/200, Iteration 200/250, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 201/250, Loss: 0.0143\n",
      "Epoch 174/200, Iteration 202/250, Loss: 0.0077\n",
      "Epoch 174/200, Iteration 203/250, Loss: 0.0081\n",
      "Epoch 174/200, Iteration 204/250, Loss: 0.0122\n",
      "Epoch 174/200, Iteration 205/250, Loss: 0.0170\n",
      "Epoch 174/200, Iteration 206/250, Loss: 0.0201\n",
      "Epoch 174/200, Iteration 207/250, Loss: 0.0303\n",
      "Epoch 174/200, Iteration 208/250, Loss: 0.0073\n",
      "Epoch 174/200, Iteration 209/250, Loss: 0.0194\n",
      "Epoch 174/200, Iteration 210/250, Loss: 0.0350\n",
      "Epoch 174/200, Iteration 211/250, Loss: 0.0067\n",
      "Epoch 174/200, Iteration 212/250, Loss: 0.0166\n",
      "Epoch 174/200, Iteration 213/250, Loss: 0.0140\n",
      "Epoch 174/200, Iteration 214/250, Loss: 0.0075\n",
      "Epoch 174/200, Iteration 215/250, Loss: 0.0301\n",
      "Epoch 174/200, Iteration 216/250, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 217/250, Loss: 0.0129\n",
      "Epoch 174/200, Iteration 218/250, Loss: 0.0075\n",
      "Epoch 174/200, Iteration 219/250, Loss: 0.0182\n",
      "Epoch 174/200, Iteration 220/250, Loss: 0.0240\n",
      "Epoch 174/200, Iteration 221/250, Loss: 0.0177\n",
      "Epoch 174/200, Iteration 222/250, Loss: 0.0213\n",
      "Epoch 174/200, Iteration 223/250, Loss: 0.0145\n",
      "Epoch 174/200, Iteration 224/250, Loss: 0.0257\n",
      "Epoch 174/200, Iteration 225/250, Loss: 0.0351\n",
      "Epoch 174/200, Iteration 226/250, Loss: 0.0129\n",
      "Epoch 174/200, Iteration 227/250, Loss: 0.0163\n",
      "Epoch 174/200, Iteration 228/250, Loss: 0.0086\n",
      "Epoch 174/200, Iteration 229/250, Loss: 0.0133\n",
      "Epoch 174/200, Iteration 230/250, Loss: 0.0196\n",
      "Epoch 174/200, Iteration 231/250, Loss: 0.0099\n",
      "Epoch 174/200, Iteration 232/250, Loss: 0.0145\n",
      "Epoch 174/200, Iteration 233/250, Loss: 0.0088\n",
      "Epoch 174/200, Iteration 234/250, Loss: 0.0167\n",
      "Epoch 174/200, Iteration 235/250, Loss: 0.0245\n",
      "Epoch 174/200, Iteration 236/250, Loss: 0.0099\n",
      "Epoch 174/200, Iteration 237/250, Loss: 0.0175\n",
      "Epoch 174/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 239/250, Loss: 0.0191\n",
      "Epoch 174/200, Iteration 240/250, Loss: 0.0075\n",
      "Epoch 174/200, Iteration 241/250, Loss: 0.0127\n",
      "Epoch 174/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 174/200, Iteration 243/250, Loss: 0.0170\n",
      "Epoch 174/200, Iteration 244/250, Loss: 0.0173\n",
      "Epoch 174/200, Iteration 245/250, Loss: 0.0111\n",
      "Epoch 174/200, Iteration 246/250, Loss: 0.0198\n",
      "Epoch 174/200, Iteration 247/250, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 248/250, Loss: 0.0096\n",
      "Epoch 174/200, Iteration 249/250, Loss: 0.0143\n",
      "Epoch 174/200, Iteration 250/250, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 77.26%, Avg loss: 0.007450, MRE: 0.634815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.75%, Avg loss: 0.007477, MRE: 0.756006 \n",
      "\n",
      "Epoch 175/200, Iteration 1/250, Loss: 0.0141\n",
      "Epoch 175/200, Iteration 2/250, Loss: 0.0123\n",
      "Epoch 175/200, Iteration 3/250, Loss: 0.0175\n",
      "Epoch 175/200, Iteration 4/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 5/250, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 6/250, Loss: 0.0115\n",
      "Epoch 175/200, Iteration 7/250, Loss: 0.0070\n",
      "Epoch 175/200, Iteration 8/250, Loss: 0.0184\n",
      "Epoch 175/200, Iteration 9/250, Loss: 0.0110\n",
      "Epoch 175/200, Iteration 10/250, Loss: 0.0188\n",
      "Epoch 175/200, Iteration 11/250, Loss: 0.0288\n",
      "Epoch 175/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 13/250, Loss: 0.0138\n",
      "Epoch 175/200, Iteration 14/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 15/250, Loss: 0.0271\n",
      "Epoch 175/200, Iteration 16/250, Loss: 0.0327\n",
      "Epoch 175/200, Iteration 17/250, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 18/250, Loss: 0.0360\n",
      "Epoch 175/200, Iteration 19/250, Loss: 0.0282\n",
      "Epoch 175/200, Iteration 20/250, Loss: 0.0160\n",
      "Epoch 175/200, Iteration 21/250, Loss: 0.0183\n",
      "Epoch 175/200, Iteration 22/250, Loss: 0.0108\n",
      "Epoch 175/200, Iteration 23/250, Loss: 0.0210\n",
      "Epoch 175/200, Iteration 24/250, Loss: 0.0068\n",
      "Epoch 175/200, Iteration 25/250, Loss: 0.0122\n",
      "Epoch 175/200, Iteration 26/250, Loss: 0.0142\n",
      "Epoch 175/200, Iteration 27/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 28/250, Loss: 0.0175\n",
      "Epoch 175/200, Iteration 29/250, Loss: 0.0120\n",
      "Epoch 175/200, Iteration 30/250, Loss: 0.0136\n",
      "Epoch 175/200, Iteration 31/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 32/250, Loss: 0.0131\n",
      "Epoch 175/200, Iteration 33/250, Loss: 0.0089\n",
      "Epoch 175/200, Iteration 34/250, Loss: 0.0262\n",
      "Epoch 175/200, Iteration 35/250, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 36/250, Loss: 0.0140\n",
      "Epoch 175/200, Iteration 37/250, Loss: 0.0123\n",
      "Epoch 175/200, Iteration 38/250, Loss: 0.0346\n",
      "Epoch 175/200, Iteration 39/250, Loss: 0.0154\n",
      "Epoch 175/200, Iteration 40/250, Loss: 0.0208\n",
      "Epoch 175/200, Iteration 41/250, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 42/250, Loss: 0.0238\n",
      "Epoch 175/200, Iteration 43/250, Loss: 0.0101\n",
      "Epoch 175/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 45/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 46/250, Loss: 0.0134\n",
      "Epoch 175/200, Iteration 47/250, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200, Iteration 48/250, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 49/250, Loss: 0.0284\n",
      "Epoch 175/200, Iteration 50/250, Loss: 0.0068\n",
      "Epoch 175/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 175/200, Iteration 52/250, Loss: 0.0176\n",
      "Epoch 175/200, Iteration 53/250, Loss: 0.0091\n",
      "Epoch 175/200, Iteration 54/250, Loss: 0.0174\n",
      "Epoch 175/200, Iteration 55/250, Loss: 0.0264\n",
      "Epoch 175/200, Iteration 56/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 57/250, Loss: 0.0079\n",
      "Epoch 175/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 59/250, Loss: 0.0129\n",
      "Epoch 175/200, Iteration 60/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 61/250, Loss: 0.0082\n",
      "Epoch 175/200, Iteration 62/250, Loss: 0.0162\n",
      "Epoch 175/200, Iteration 63/250, Loss: 0.0086\n",
      "Epoch 175/200, Iteration 64/250, Loss: 0.0143\n",
      "Epoch 175/200, Iteration 65/250, Loss: 0.0110\n",
      "Epoch 175/200, Iteration 66/250, Loss: 0.0199\n",
      "Epoch 175/200, Iteration 67/250, Loss: 0.0094\n",
      "Epoch 175/200, Iteration 68/250, Loss: 0.0186\n",
      "Epoch 175/200, Iteration 69/250, Loss: 0.0083\n",
      "Epoch 175/200, Iteration 70/250, Loss: 0.0137\n",
      "Epoch 175/200, Iteration 71/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 72/250, Loss: 0.0270\n",
      "Epoch 175/200, Iteration 73/250, Loss: 0.0074\n",
      "Epoch 175/200, Iteration 74/250, Loss: 0.0083\n",
      "Epoch 175/200, Iteration 75/250, Loss: 0.0121\n",
      "Epoch 175/200, Iteration 76/250, Loss: 0.0167\n",
      "Epoch 175/200, Iteration 77/250, Loss: 0.0067\n",
      "Epoch 175/200, Iteration 78/250, Loss: 0.0137\n",
      "Epoch 175/200, Iteration 79/250, Loss: 0.0117\n",
      "Epoch 175/200, Iteration 80/250, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 81/250, Loss: 0.0337\n",
      "Epoch 175/200, Iteration 82/250, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 83/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 84/250, Loss: 0.0269\n",
      "Epoch 175/200, Iteration 85/250, Loss: 0.0222\n",
      "Epoch 175/200, Iteration 86/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 175/200, Iteration 88/250, Loss: 0.0240\n",
      "Epoch 175/200, Iteration 89/250, Loss: 0.0070\n",
      "Epoch 175/200, Iteration 90/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 91/250, Loss: 0.0225\n",
      "Epoch 175/200, Iteration 92/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 93/250, Loss: 0.0089\n",
      "Epoch 175/200, Iteration 94/250, Loss: 0.0096\n",
      "Epoch 175/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 175/200, Iteration 96/250, Loss: 0.0230\n",
      "Epoch 175/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 175/200, Iteration 98/250, Loss: 0.0095\n",
      "Epoch 175/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 175/200, Iteration 100/250, Loss: 0.0076\n",
      "Epoch 175/200, Iteration 101/250, Loss: 0.0120\n",
      "Epoch 175/200, Iteration 102/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 103/250, Loss: 0.0177\n",
      "Epoch 175/200, Iteration 104/250, Loss: 0.0120\n",
      "Epoch 175/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 175/200, Iteration 106/250, Loss: 0.0307\n",
      "Epoch 175/200, Iteration 107/250, Loss: 0.0243\n",
      "Epoch 175/200, Iteration 108/250, Loss: 0.0248\n",
      "Epoch 175/200, Iteration 109/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 110/250, Loss: 0.0205\n",
      "Epoch 175/200, Iteration 111/250, Loss: 0.0139\n",
      "Epoch 175/200, Iteration 112/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 113/250, Loss: 0.0146\n",
      "Epoch 175/200, Iteration 114/250, Loss: 0.0236\n",
      "Epoch 175/200, Iteration 115/250, Loss: 0.0082\n",
      "Epoch 175/200, Iteration 116/250, Loss: 0.0053\n",
      "Epoch 175/200, Iteration 117/250, Loss: 0.0115\n",
      "Epoch 175/200, Iteration 118/250, Loss: 0.0121\n",
      "Epoch 175/200, Iteration 119/250, Loss: 0.0211\n",
      "Epoch 175/200, Iteration 120/250, Loss: 0.0182\n",
      "Epoch 175/200, Iteration 121/250, Loss: 0.0067\n",
      "Epoch 175/200, Iteration 122/250, Loss: 0.0099\n",
      "Epoch 175/200, Iteration 123/250, Loss: 0.0204\n",
      "Epoch 175/200, Iteration 124/250, Loss: 0.0064\n",
      "Epoch 175/200, Iteration 125/250, Loss: 0.0131\n",
      "Epoch 175/200, Iteration 126/250, Loss: 0.0209\n",
      "Epoch 175/200, Iteration 127/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 128/250, Loss: 0.0120\n",
      "Epoch 175/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 175/200, Iteration 130/250, Loss: 0.0061\n",
      "Epoch 175/200, Iteration 131/250, Loss: 0.0161\n",
      "Epoch 175/200, Iteration 132/250, Loss: 0.0165\n",
      "Epoch 175/200, Iteration 133/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 134/250, Loss: 0.0067\n",
      "Epoch 175/200, Iteration 135/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 136/250, Loss: 0.0121\n",
      "Epoch 175/200, Iteration 137/250, Loss: 0.0101\n",
      "Epoch 175/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 175/200, Iteration 139/250, Loss: 0.0128\n",
      "Epoch 175/200, Iteration 140/250, Loss: 0.0226\n",
      "Epoch 175/200, Iteration 141/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 142/250, Loss: 0.0081\n",
      "Epoch 175/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 175/200, Iteration 144/250, Loss: 0.0219\n",
      "Epoch 175/200, Iteration 145/250, Loss: 0.0064\n",
      "Epoch 175/200, Iteration 146/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 147/250, Loss: 0.0153\n",
      "Epoch 175/200, Iteration 148/250, Loss: 0.0093\n",
      "Epoch 175/200, Iteration 149/250, Loss: 0.0077\n",
      "Epoch 175/200, Iteration 150/250, Loss: 0.0150\n",
      "Epoch 175/200, Iteration 151/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 152/250, Loss: 0.0068\n",
      "Epoch 175/200, Iteration 153/250, Loss: 0.0372\n",
      "Epoch 175/200, Iteration 154/250, Loss: 0.0195\n",
      "Epoch 175/200, Iteration 155/250, Loss: 0.0098\n",
      "Epoch 175/200, Iteration 156/250, Loss: 0.0147\n",
      "Epoch 175/200, Iteration 157/250, Loss: 0.0278\n",
      "Epoch 175/200, Iteration 158/250, Loss: 0.0165\n",
      "Epoch 175/200, Iteration 159/250, Loss: 0.0193\n",
      "Epoch 175/200, Iteration 160/250, Loss: 0.0281\n",
      "Epoch 175/200, Iteration 161/250, Loss: 0.0171\n",
      "Epoch 175/200, Iteration 162/250, Loss: 0.0077\n",
      "Epoch 175/200, Iteration 163/250, Loss: 0.0161\n",
      "Epoch 175/200, Iteration 164/250, Loss: 0.0162\n",
      "Epoch 175/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 175/200, Iteration 166/250, Loss: 0.0270\n",
      "Epoch 175/200, Iteration 167/250, Loss: 0.0196\n",
      "Epoch 175/200, Iteration 168/250, Loss: 0.0228\n",
      "Epoch 175/200, Iteration 169/250, Loss: 0.0076\n",
      "Epoch 175/200, Iteration 170/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 171/250, Loss: 0.0091\n",
      "Epoch 175/200, Iteration 172/250, Loss: 0.0322\n",
      "Epoch 175/200, Iteration 173/250, Loss: 0.0156\n",
      "Epoch 175/200, Iteration 174/250, Loss: 0.0237\n",
      "Epoch 175/200, Iteration 175/250, Loss: 0.0293\n",
      "Epoch 175/200, Iteration 176/250, Loss: 0.0289\n",
      "Epoch 175/200, Iteration 177/250, Loss: 0.0193\n",
      "Epoch 175/200, Iteration 178/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 179/250, Loss: 0.0108\n",
      "Epoch 175/200, Iteration 180/250, Loss: 0.0437\n",
      "Epoch 175/200, Iteration 181/250, Loss: 0.0078\n",
      "Epoch 175/200, Iteration 182/250, Loss: 0.0261\n",
      "Epoch 175/200, Iteration 183/250, Loss: 0.0130\n",
      "Epoch 175/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 185/250, Loss: 0.0109\n",
      "Epoch 175/200, Iteration 186/250, Loss: 0.0081\n",
      "Epoch 175/200, Iteration 187/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 188/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 189/250, Loss: 0.0136\n",
      "Epoch 175/200, Iteration 190/250, Loss: 0.0173\n",
      "Epoch 175/200, Iteration 191/250, Loss: 0.0135\n",
      "Epoch 175/200, Iteration 192/250, Loss: 0.0269\n",
      "Epoch 175/200, Iteration 193/250, Loss: 0.0129\n",
      "Epoch 175/200, Iteration 194/250, Loss: 0.0072\n",
      "Epoch 175/200, Iteration 195/250, Loss: 0.0142\n",
      "Epoch 175/200, Iteration 196/250, Loss: 0.0110\n",
      "Epoch 175/200, Iteration 197/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 198/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 199/250, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 200/250, Loss: 0.0083\n",
      "Epoch 175/200, Iteration 201/250, Loss: 0.0119\n",
      "Epoch 175/200, Iteration 202/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 203/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 204/250, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 205/250, Loss: 0.0156\n",
      "Epoch 175/200, Iteration 206/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 207/250, Loss: 0.0358\n",
      "Epoch 175/200, Iteration 208/250, Loss: 0.0222\n",
      "Epoch 175/200, Iteration 209/250, Loss: 0.0115\n",
      "Epoch 175/200, Iteration 210/250, Loss: 0.0166\n",
      "Epoch 175/200, Iteration 211/250, Loss: 0.0061\n",
      "Epoch 175/200, Iteration 212/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 213/250, Loss: 0.0346\n",
      "Epoch 175/200, Iteration 214/250, Loss: 0.0100\n",
      "Epoch 175/200, Iteration 215/250, Loss: 0.0098\n",
      "Epoch 175/200, Iteration 216/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 217/250, Loss: 0.0115\n",
      "Epoch 175/200, Iteration 218/250, Loss: 0.0163\n",
      "Epoch 175/200, Iteration 219/250, Loss: 0.0088\n",
      "Epoch 175/200, Iteration 220/250, Loss: 0.0098\n",
      "Epoch 175/200, Iteration 221/250, Loss: 0.0192\n",
      "Epoch 175/200, Iteration 222/250, Loss: 0.0375\n",
      "Epoch 175/200, Iteration 223/250, Loss: 0.0184\n",
      "Epoch 175/200, Iteration 224/250, Loss: 0.0178\n",
      "Epoch 175/200, Iteration 225/250, Loss: 0.0227\n",
      "Epoch 175/200, Iteration 226/250, Loss: 0.0249\n",
      "Epoch 175/200, Iteration 227/250, Loss: 0.0125\n",
      "Epoch 175/200, Iteration 228/250, Loss: 0.0157\n",
      "Epoch 175/200, Iteration 229/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 230/250, Loss: 0.0294\n",
      "Epoch 175/200, Iteration 231/250, Loss: 0.0269\n",
      "Epoch 175/200, Iteration 232/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 233/250, Loss: 0.0152\n",
      "Epoch 175/200, Iteration 234/250, Loss: 0.0125\n",
      "Epoch 175/200, Iteration 235/250, Loss: 0.0088\n",
      "Epoch 175/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 175/200, Iteration 237/250, Loss: 0.0196\n",
      "Epoch 175/200, Iteration 238/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 239/250, Loss: 0.0139\n",
      "Epoch 175/200, Iteration 240/250, Loss: 0.0153\n",
      "Epoch 175/200, Iteration 241/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 242/250, Loss: 0.0226\n",
      "Epoch 175/200, Iteration 243/250, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 244/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 245/250, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200, Iteration 246/250, Loss: 0.0277\n",
      "Epoch 175/200, Iteration 247/250, Loss: 0.0094\n",
      "Epoch 175/200, Iteration 248/250, Loss: 0.0170\n",
      "Epoch 175/200, Iteration 249/250, Loss: 0.0189\n",
      "Epoch 175/200, Iteration 250/250, Loss: 0.0166\n",
      "Train Error: \n",
      " Accuracy: 93.64%, Avg loss: 0.005732, MRE: 0.599656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.35%, Avg loss: 0.005779, MRE: 0.861373 \n",
      "\n",
      "Epoch 176/200, Iteration 1/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 2/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 3/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 4/250, Loss: 0.0062\n",
      "Epoch 176/200, Iteration 5/250, Loss: 0.0125\n",
      "Epoch 176/200, Iteration 6/250, Loss: 0.0149\n",
      "Epoch 176/200, Iteration 7/250, Loss: 0.0273\n",
      "Epoch 176/200, Iteration 8/250, Loss: 0.0279\n",
      "Epoch 176/200, Iteration 9/250, Loss: 0.0203\n",
      "Epoch 176/200, Iteration 10/250, Loss: 0.0153\n",
      "Epoch 176/200, Iteration 11/250, Loss: 0.0147\n",
      "Epoch 176/200, Iteration 12/250, Loss: 0.0184\n",
      "Epoch 176/200, Iteration 13/250, Loss: 0.0110\n",
      "Epoch 176/200, Iteration 14/250, Loss: 0.0068\n",
      "Epoch 176/200, Iteration 15/250, Loss: 0.0069\n",
      "Epoch 176/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 17/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 18/250, Loss: 0.0244\n",
      "Epoch 176/200, Iteration 19/250, Loss: 0.0210\n",
      "Epoch 176/200, Iteration 20/250, Loss: 0.0099\n",
      "Epoch 176/200, Iteration 21/250, Loss: 0.0157\n",
      "Epoch 176/200, Iteration 22/250, Loss: 0.0080\n",
      "Epoch 176/200, Iteration 23/250, Loss: 0.0069\n",
      "Epoch 176/200, Iteration 24/250, Loss: 0.0082\n",
      "Epoch 176/200, Iteration 25/250, Loss: 0.0232\n",
      "Epoch 176/200, Iteration 26/250, Loss: 0.0127\n",
      "Epoch 176/200, Iteration 27/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 28/250, Loss: 0.0056\n",
      "Epoch 176/200, Iteration 29/250, Loss: 0.0236\n",
      "Epoch 176/200, Iteration 30/250, Loss: 0.0273\n",
      "Epoch 176/200, Iteration 31/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 32/250, Loss: 0.0208\n",
      "Epoch 176/200, Iteration 33/250, Loss: 0.0160\n",
      "Epoch 176/200, Iteration 34/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 35/250, Loss: 0.0226\n",
      "Epoch 176/200, Iteration 36/250, Loss: 0.0244\n",
      "Epoch 176/200, Iteration 37/250, Loss: 0.0159\n",
      "Epoch 176/200, Iteration 38/250, Loss: 0.0172\n",
      "Epoch 176/200, Iteration 39/250, Loss: 0.0274\n",
      "Epoch 176/200, Iteration 40/250, Loss: 0.0126\n",
      "Epoch 176/200, Iteration 41/250, Loss: 0.0379\n",
      "Epoch 176/200, Iteration 42/250, Loss: 0.0080\n",
      "Epoch 176/200, Iteration 43/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 44/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 45/250, Loss: 0.0349\n",
      "Epoch 176/200, Iteration 46/250, Loss: 0.0165\n",
      "Epoch 176/200, Iteration 47/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 48/250, Loss: 0.0135\n",
      "Epoch 176/200, Iteration 49/250, Loss: 0.0126\n",
      "Epoch 176/200, Iteration 50/250, Loss: 0.0118\n",
      "Epoch 176/200, Iteration 51/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 52/250, Loss: 0.0275\n",
      "Epoch 176/200, Iteration 53/250, Loss: 0.0185\n",
      "Epoch 176/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 176/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 176/200, Iteration 56/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 176/200, Iteration 58/250, Loss: 0.0087\n",
      "Epoch 176/200, Iteration 59/250, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 60/250, Loss: 0.0113\n",
      "Epoch 176/200, Iteration 61/250, Loss: 0.0171\n",
      "Epoch 176/200, Iteration 62/250, Loss: 0.0141\n",
      "Epoch 176/200, Iteration 63/250, Loss: 0.0217\n",
      "Epoch 176/200, Iteration 64/250, Loss: 0.0213\n",
      "Epoch 176/200, Iteration 65/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 66/250, Loss: 0.0273\n",
      "Epoch 176/200, Iteration 67/250, Loss: 0.0174\n",
      "Epoch 176/200, Iteration 68/250, Loss: 0.0097\n",
      "Epoch 176/200, Iteration 69/250, Loss: 0.0202\n",
      "Epoch 176/200, Iteration 70/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 71/250, Loss: 0.0160\n",
      "Epoch 176/200, Iteration 72/250, Loss: 0.0068\n",
      "Epoch 176/200, Iteration 73/250, Loss: 0.0172\n",
      "Epoch 176/200, Iteration 74/250, Loss: 0.0128\n",
      "Epoch 176/200, Iteration 75/250, Loss: 0.0085\n",
      "Epoch 176/200, Iteration 76/250, Loss: 0.0076\n",
      "Epoch 176/200, Iteration 77/250, Loss: 0.0184\n",
      "Epoch 176/200, Iteration 78/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 79/250, Loss: 0.0169\n",
      "Epoch 176/200, Iteration 80/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 81/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 82/250, Loss: 0.0215\n",
      "Epoch 176/200, Iteration 83/250, Loss: 0.0076\n",
      "Epoch 176/200, Iteration 84/250, Loss: 0.0075\n",
      "Epoch 176/200, Iteration 85/250, Loss: 0.0181\n",
      "Epoch 176/200, Iteration 86/250, Loss: 0.0059\n",
      "Epoch 176/200, Iteration 87/250, Loss: 0.0170\n",
      "Epoch 176/200, Iteration 88/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 89/250, Loss: 0.0080\n",
      "Epoch 176/200, Iteration 90/250, Loss: 0.0147\n",
      "Epoch 176/200, Iteration 91/250, Loss: 0.0253\n",
      "Epoch 176/200, Iteration 92/250, Loss: 0.0166\n",
      "Epoch 176/200, Iteration 93/250, Loss: 0.0173\n",
      "Epoch 176/200, Iteration 94/250, Loss: 0.0292\n",
      "Epoch 176/200, Iteration 95/250, Loss: 0.0274\n",
      "Epoch 176/200, Iteration 96/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 97/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 98/250, Loss: 0.0092\n",
      "Epoch 176/200, Iteration 99/250, Loss: 0.0242\n",
      "Epoch 176/200, Iteration 100/250, Loss: 0.0095\n",
      "Epoch 176/200, Iteration 101/250, Loss: 0.0196\n",
      "Epoch 176/200, Iteration 102/250, Loss: 0.0102\n",
      "Epoch 176/200, Iteration 103/250, Loss: 0.0087\n",
      "Epoch 176/200, Iteration 104/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 105/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 106/250, Loss: 0.0094\n",
      "Epoch 176/200, Iteration 107/250, Loss: 0.0403\n",
      "Epoch 176/200, Iteration 108/250, Loss: 0.0266\n",
      "Epoch 176/200, Iteration 109/250, Loss: 0.0186\n",
      "Epoch 176/200, Iteration 110/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 111/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 112/250, Loss: 0.0077\n",
      "Epoch 176/200, Iteration 113/250, Loss: 0.0247\n",
      "Epoch 176/200, Iteration 114/250, Loss: 0.0145\n",
      "Epoch 176/200, Iteration 115/250, Loss: 0.0192\n",
      "Epoch 176/200, Iteration 116/250, Loss: 0.0306\n",
      "Epoch 176/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 176/200, Iteration 118/250, Loss: 0.0182\n",
      "Epoch 176/200, Iteration 119/250, Loss: 0.0198\n",
      "Epoch 176/200, Iteration 120/250, Loss: 0.0215\n",
      "Epoch 176/200, Iteration 121/250, Loss: 0.0141\n",
      "Epoch 176/200, Iteration 122/250, Loss: 0.0241\n",
      "Epoch 176/200, Iteration 123/250, Loss: 0.0086\n",
      "Epoch 176/200, Iteration 124/250, Loss: 0.0070\n",
      "Epoch 176/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 126/250, Loss: 0.0148\n",
      "Epoch 176/200, Iteration 127/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 128/250, Loss: 0.0315\n",
      "Epoch 176/200, Iteration 129/250, Loss: 0.0319\n",
      "Epoch 176/200, Iteration 130/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 131/250, Loss: 0.0110\n",
      "Epoch 176/200, Iteration 132/250, Loss: 0.0072\n",
      "Epoch 176/200, Iteration 133/250, Loss: 0.0146\n",
      "Epoch 176/200, Iteration 134/250, Loss: 0.0136\n",
      "Epoch 176/200, Iteration 135/250, Loss: 0.0198\n",
      "Epoch 176/200, Iteration 136/250, Loss: 0.0275\n",
      "Epoch 176/200, Iteration 137/250, Loss: 0.0148\n",
      "Epoch 176/200, Iteration 138/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 139/250, Loss: 0.0149\n",
      "Epoch 176/200, Iteration 140/250, Loss: 0.0155\n",
      "Epoch 176/200, Iteration 141/250, Loss: 0.0093\n",
      "Epoch 176/200, Iteration 142/250, Loss: 0.0122\n",
      "Epoch 176/200, Iteration 143/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 145/250, Loss: 0.0163\n",
      "Epoch 176/200, Iteration 146/250, Loss: 0.0219\n",
      "Epoch 176/200, Iteration 147/250, Loss: 0.0178\n",
      "Epoch 176/200, Iteration 148/250, Loss: 0.0102\n",
      "Epoch 176/200, Iteration 149/250, Loss: 0.0129\n",
      "Epoch 176/200, Iteration 150/250, Loss: 0.0131\n",
      "Epoch 176/200, Iteration 151/250, Loss: 0.0228\n",
      "Epoch 176/200, Iteration 152/250, Loss: 0.0139\n",
      "Epoch 176/200, Iteration 153/250, Loss: 0.0053\n",
      "Epoch 176/200, Iteration 154/250, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 155/250, Loss: 0.0194\n",
      "Epoch 176/200, Iteration 156/250, Loss: 0.0145\n",
      "Epoch 176/200, Iteration 157/250, Loss: 0.0109\n",
      "Epoch 176/200, Iteration 158/250, Loss: 0.0128\n",
      "Epoch 176/200, Iteration 159/250, Loss: 0.0118\n",
      "Epoch 176/200, Iteration 160/250, Loss: 0.0170\n",
      "Epoch 176/200, Iteration 161/250, Loss: 0.0148\n",
      "Epoch 176/200, Iteration 162/250, Loss: 0.0134\n",
      "Epoch 176/200, Iteration 163/250, Loss: 0.0061\n",
      "Epoch 176/200, Iteration 164/250, Loss: 0.0082\n",
      "Epoch 176/200, Iteration 165/250, Loss: 0.0117\n",
      "Epoch 176/200, Iteration 166/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 167/250, Loss: 0.0084\n",
      "Epoch 176/200, Iteration 168/250, Loss: 0.0236\n",
      "Epoch 176/200, Iteration 169/250, Loss: 0.0064\n",
      "Epoch 176/200, Iteration 170/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 171/250, Loss: 0.0325\n",
      "Epoch 176/200, Iteration 172/250, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 173/250, Loss: 0.0107\n",
      "Epoch 176/200, Iteration 174/250, Loss: 0.0162\n",
      "Epoch 176/200, Iteration 175/250, Loss: 0.0139\n",
      "Epoch 176/200, Iteration 176/250, Loss: 0.0127\n",
      "Epoch 176/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 176/200, Iteration 178/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 179/250, Loss: 0.0314\n",
      "Epoch 176/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 176/200, Iteration 181/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 182/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 183/250, Loss: 0.0157\n",
      "Epoch 176/200, Iteration 184/250, Loss: 0.0209\n",
      "Epoch 176/200, Iteration 185/250, Loss: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 187/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 188/250, Loss: 0.0123\n",
      "Epoch 176/200, Iteration 189/250, Loss: 0.0121\n",
      "Epoch 176/200, Iteration 190/250, Loss: 0.0175\n",
      "Epoch 176/200, Iteration 191/250, Loss: 0.0182\n",
      "Epoch 176/200, Iteration 192/250, Loss: 0.0142\n",
      "Epoch 176/200, Iteration 193/250, Loss: 0.0250\n",
      "Epoch 176/200, Iteration 194/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 195/250, Loss: 0.0207\n",
      "Epoch 176/200, Iteration 196/250, Loss: 0.0085\n",
      "Epoch 176/200, Iteration 197/250, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 198/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 199/250, Loss: 0.0196\n",
      "Epoch 176/200, Iteration 200/250, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 201/250, Loss: 0.0163\n",
      "Epoch 176/200, Iteration 202/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 203/250, Loss: 0.0224\n",
      "Epoch 176/200, Iteration 204/250, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 205/250, Loss: 0.0056\n",
      "Epoch 176/200, Iteration 206/250, Loss: 0.0159\n",
      "Epoch 176/200, Iteration 207/250, Loss: 0.0150\n",
      "Epoch 176/200, Iteration 208/250, Loss: 0.0180\n",
      "Epoch 176/200, Iteration 209/250, Loss: 0.0167\n",
      "Epoch 176/200, Iteration 210/250, Loss: 0.0181\n",
      "Epoch 176/200, Iteration 211/250, Loss: 0.0210\n",
      "Epoch 176/200, Iteration 212/250, Loss: 0.0276\n",
      "Epoch 176/200, Iteration 213/250, Loss: 0.0096\n",
      "Epoch 176/200, Iteration 214/250, Loss: 0.0308\n",
      "Epoch 176/200, Iteration 215/250, Loss: 0.0141\n",
      "Epoch 176/200, Iteration 216/250, Loss: 0.0134\n",
      "Epoch 176/200, Iteration 217/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 218/250, Loss: 0.0087\n",
      "Epoch 176/200, Iteration 219/250, Loss: 0.0367\n",
      "Epoch 176/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 221/250, Loss: 0.0220\n",
      "Epoch 176/200, Iteration 222/250, Loss: 0.0171\n",
      "Epoch 176/200, Iteration 223/250, Loss: 0.0297\n",
      "Epoch 176/200, Iteration 224/250, Loss: 0.0194\n",
      "Epoch 176/200, Iteration 225/250, Loss: 0.0187\n",
      "Epoch 176/200, Iteration 226/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 227/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 228/250, Loss: 0.0323\n",
      "Epoch 176/200, Iteration 229/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 230/250, Loss: 0.0099\n",
      "Epoch 176/200, Iteration 231/250, Loss: 0.0330\n",
      "Epoch 176/200, Iteration 232/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 233/250, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 234/250, Loss: 0.0384\n",
      "Epoch 176/200, Iteration 235/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 236/250, Loss: 0.0141\n",
      "Epoch 176/200, Iteration 237/250, Loss: 0.0136\n",
      "Epoch 176/200, Iteration 238/250, Loss: 0.0123\n",
      "Epoch 176/200, Iteration 239/250, Loss: 0.0058\n",
      "Epoch 176/200, Iteration 240/250, Loss: 0.0157\n",
      "Epoch 176/200, Iteration 241/250, Loss: 0.0181\n",
      "Epoch 176/200, Iteration 242/250, Loss: 0.0124\n",
      "Epoch 176/200, Iteration 243/250, Loss: 0.0065\n",
      "Epoch 176/200, Iteration 244/250, Loss: 0.0335\n",
      "Epoch 176/200, Iteration 245/250, Loss: 0.0340\n",
      "Epoch 176/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 247/250, Loss: 0.0096\n",
      "Epoch 176/200, Iteration 248/250, Loss: 0.0262\n",
      "Epoch 176/200, Iteration 249/250, Loss: 0.0163\n",
      "Epoch 176/200, Iteration 250/250, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 92.54%, Avg loss: 0.005916, MRE: 0.602440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.005962, MRE: 0.836763 \n",
      "\n",
      "Epoch 177/200, Iteration 1/250, Loss: 0.0092\n",
      "Epoch 177/200, Iteration 2/250, Loss: 0.0103\n",
      "Epoch 177/200, Iteration 3/250, Loss: 0.0287\n",
      "Epoch 177/200, Iteration 4/250, Loss: 0.0262\n",
      "Epoch 177/200, Iteration 5/250, Loss: 0.0080\n",
      "Epoch 177/200, Iteration 6/250, Loss: 0.0075\n",
      "Epoch 177/200, Iteration 7/250, Loss: 0.0067\n",
      "Epoch 177/200, Iteration 8/250, Loss: 0.0097\n",
      "Epoch 177/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 177/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 177/200, Iteration 11/250, Loss: 0.0290\n",
      "Epoch 177/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 177/200, Iteration 13/250, Loss: 0.0237\n",
      "Epoch 177/200, Iteration 14/250, Loss: 0.0304\n",
      "Epoch 177/200, Iteration 15/250, Loss: 0.0108\n",
      "Epoch 177/200, Iteration 16/250, Loss: 0.0279\n",
      "Epoch 177/200, Iteration 17/250, Loss: 0.0110\n",
      "Epoch 177/200, Iteration 18/250, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 19/250, Loss: 0.0228\n",
      "Epoch 177/200, Iteration 20/250, Loss: 0.0207\n",
      "Epoch 177/200, Iteration 21/250, Loss: 0.0341\n",
      "Epoch 177/200, Iteration 22/250, Loss: 0.0114\n",
      "Epoch 177/200, Iteration 23/250, Loss: 0.0366\n",
      "Epoch 177/200, Iteration 24/250, Loss: 0.0130\n",
      "Epoch 177/200, Iteration 25/250, Loss: 0.0154\n",
      "Epoch 177/200, Iteration 26/250, Loss: 0.0130\n",
      "Epoch 177/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 177/200, Iteration 28/250, Loss: 0.0301\n",
      "Epoch 177/200, Iteration 29/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 30/250, Loss: 0.0109\n",
      "Epoch 177/200, Iteration 31/250, Loss: 0.0113\n",
      "Epoch 177/200, Iteration 32/250, Loss: 0.0140\n",
      "Epoch 177/200, Iteration 33/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 34/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 35/250, Loss: 0.0150\n",
      "Epoch 177/200, Iteration 36/250, Loss: 0.0176\n",
      "Epoch 177/200, Iteration 37/250, Loss: 0.0113\n",
      "Epoch 177/200, Iteration 38/250, Loss: 0.0273\n",
      "Epoch 177/200, Iteration 39/250, Loss: 0.0153\n",
      "Epoch 177/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 41/250, Loss: 0.0281\n",
      "Epoch 177/200, Iteration 42/250, Loss: 0.0148\n",
      "Epoch 177/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 44/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 45/250, Loss: 0.0073\n",
      "Epoch 177/200, Iteration 46/250, Loss: 0.0122\n",
      "Epoch 177/200, Iteration 47/250, Loss: 0.0272\n",
      "Epoch 177/200, Iteration 48/250, Loss: 0.0083\n",
      "Epoch 177/200, Iteration 49/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 50/250, Loss: 0.0186\n",
      "Epoch 177/200, Iteration 51/250, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 52/250, Loss: 0.0183\n",
      "Epoch 177/200, Iteration 53/250, Loss: 0.0263\n",
      "Epoch 177/200, Iteration 54/250, Loss: 0.0122\n",
      "Epoch 177/200, Iteration 55/250, Loss: 0.0287\n",
      "Epoch 177/200, Iteration 56/250, Loss: 0.0158\n",
      "Epoch 177/200, Iteration 57/250, Loss: 0.0084\n",
      "Epoch 177/200, Iteration 58/250, Loss: 0.0225\n",
      "Epoch 177/200, Iteration 59/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 60/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 62/250, Loss: 0.0070\n",
      "Epoch 177/200, Iteration 63/250, Loss: 0.0147\n",
      "Epoch 177/200, Iteration 64/250, Loss: 0.0184\n",
      "Epoch 177/200, Iteration 65/250, Loss: 0.0207\n",
      "Epoch 177/200, Iteration 66/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 67/250, Loss: 0.0205\n",
      "Epoch 177/200, Iteration 68/250, Loss: 0.0217\n",
      "Epoch 177/200, Iteration 69/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 70/250, Loss: 0.0388\n",
      "Epoch 177/200, Iteration 71/250, Loss: 0.0051\n",
      "Epoch 177/200, Iteration 72/250, Loss: 0.0124\n",
      "Epoch 177/200, Iteration 73/250, Loss: 0.0316\n",
      "Epoch 177/200, Iteration 74/250, Loss: 0.0178\n",
      "Epoch 177/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 177/200, Iteration 76/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 77/250, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 78/250, Loss: 0.0132\n",
      "Epoch 177/200, Iteration 79/250, Loss: 0.0312\n",
      "Epoch 177/200, Iteration 80/250, Loss: 0.0132\n",
      "Epoch 177/200, Iteration 81/250, Loss: 0.0132\n",
      "Epoch 177/200, Iteration 82/250, Loss: 0.0170\n",
      "Epoch 177/200, Iteration 83/250, Loss: 0.0480\n",
      "Epoch 177/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 177/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 177/200, Iteration 86/250, Loss: 0.0230\n",
      "Epoch 177/200, Iteration 87/250, Loss: 0.0167\n",
      "Epoch 177/200, Iteration 88/250, Loss: 0.0141\n",
      "Epoch 177/200, Iteration 89/250, Loss: 0.0276\n",
      "Epoch 177/200, Iteration 90/250, Loss: 0.0163\n",
      "Epoch 177/200, Iteration 91/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 92/250, Loss: 0.0153\n",
      "Epoch 177/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 177/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 177/200, Iteration 95/250, Loss: 0.0092\n",
      "Epoch 177/200, Iteration 96/250, Loss: 0.0223\n",
      "Epoch 177/200, Iteration 97/250, Loss: 0.0239\n",
      "Epoch 177/200, Iteration 98/250, Loss: 0.0099\n",
      "Epoch 177/200, Iteration 99/250, Loss: 0.0110\n",
      "Epoch 177/200, Iteration 100/250, Loss: 0.0169\n",
      "Epoch 177/200, Iteration 101/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 102/250, Loss: 0.0291\n",
      "Epoch 177/200, Iteration 103/250, Loss: 0.0072\n",
      "Epoch 177/200, Iteration 104/250, Loss: 0.0279\n",
      "Epoch 177/200, Iteration 105/250, Loss: 0.0109\n",
      "Epoch 177/200, Iteration 106/250, Loss: 0.0228\n",
      "Epoch 177/200, Iteration 107/250, Loss: 0.0302\n",
      "Epoch 177/200, Iteration 108/250, Loss: 0.0175\n",
      "Epoch 177/200, Iteration 109/250, Loss: 0.0069\n",
      "Epoch 177/200, Iteration 110/250, Loss: 0.0110\n",
      "Epoch 177/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 177/200, Iteration 112/250, Loss: 0.0140\n",
      "Epoch 177/200, Iteration 113/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 114/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 115/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 116/250, Loss: 0.0165\n",
      "Epoch 177/200, Iteration 117/250, Loss: 0.0210\n",
      "Epoch 177/200, Iteration 118/250, Loss: 0.0235\n",
      "Epoch 177/200, Iteration 119/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 120/250, Loss: 0.0213\n",
      "Epoch 177/200, Iteration 121/250, Loss: 0.0060\n",
      "Epoch 177/200, Iteration 122/250, Loss: 0.0105\n",
      "Epoch 177/200, Iteration 123/250, Loss: 0.0110\n",
      "Epoch 177/200, Iteration 124/250, Loss: 0.0191\n",
      "Epoch 177/200, Iteration 125/250, Loss: 0.0202\n",
      "Epoch 177/200, Iteration 126/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 127/250, Loss: 0.0243\n",
      "Epoch 177/200, Iteration 128/250, Loss: 0.0290\n",
      "Epoch 177/200, Iteration 129/250, Loss: 0.0068\n",
      "Epoch 177/200, Iteration 130/250, Loss: 0.0093\n",
      "Epoch 177/200, Iteration 131/250, Loss: 0.0089\n",
      "Epoch 177/200, Iteration 132/250, Loss: 0.0157\n",
      "Epoch 177/200, Iteration 133/250, Loss: 0.0099\n",
      "Epoch 177/200, Iteration 134/250, Loss: 0.0105\n",
      "Epoch 177/200, Iteration 135/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 136/250, Loss: 0.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 177/200, Iteration 138/250, Loss: 0.0099\n",
      "Epoch 177/200, Iteration 139/250, Loss: 0.0062\n",
      "Epoch 177/200, Iteration 140/250, Loss: 0.0181\n",
      "Epoch 177/200, Iteration 141/250, Loss: 0.0101\n",
      "Epoch 177/200, Iteration 142/250, Loss: 0.0166\n",
      "Epoch 177/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 177/200, Iteration 144/250, Loss: 0.0213\n",
      "Epoch 177/200, Iteration 145/250, Loss: 0.0093\n",
      "Epoch 177/200, Iteration 146/250, Loss: 0.0083\n",
      "Epoch 177/200, Iteration 147/250, Loss: 0.0156\n",
      "Epoch 177/200, Iteration 148/250, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 149/250, Loss: 0.0196\n",
      "Epoch 177/200, Iteration 150/250, Loss: 0.0230\n",
      "Epoch 177/200, Iteration 151/250, Loss: 0.0204\n",
      "Epoch 177/200, Iteration 152/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 153/250, Loss: 0.0095\n",
      "Epoch 177/200, Iteration 154/250, Loss: 0.0252\n",
      "Epoch 177/200, Iteration 155/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 156/250, Loss: 0.0103\n",
      "Epoch 177/200, Iteration 157/250, Loss: 0.0274\n",
      "Epoch 177/200, Iteration 158/250, Loss: 0.0177\n",
      "Epoch 177/200, Iteration 159/250, Loss: 0.0200\n",
      "Epoch 177/200, Iteration 160/250, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 161/250, Loss: 0.0251\n",
      "Epoch 177/200, Iteration 162/250, Loss: 0.0272\n",
      "Epoch 177/200, Iteration 163/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 164/250, Loss: 0.0198\n",
      "Epoch 177/200, Iteration 165/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 166/250, Loss: 0.0146\n",
      "Epoch 177/200, Iteration 167/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 168/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 169/250, Loss: 0.0208\n",
      "Epoch 177/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 177/200, Iteration 171/250, Loss: 0.0297\n",
      "Epoch 177/200, Iteration 172/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 173/250, Loss: 0.0253\n",
      "Epoch 177/200, Iteration 174/250, Loss: 0.0266\n",
      "Epoch 177/200, Iteration 175/250, Loss: 0.0218\n",
      "Epoch 177/200, Iteration 176/250, Loss: 0.0108\n",
      "Epoch 177/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 178/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 179/250, Loss: 0.0164\n",
      "Epoch 177/200, Iteration 180/250, Loss: 0.0075\n",
      "Epoch 177/200, Iteration 181/250, Loss: 0.0250\n",
      "Epoch 177/200, Iteration 182/250, Loss: 0.0095\n",
      "Epoch 177/200, Iteration 183/250, Loss: 0.0064\n",
      "Epoch 177/200, Iteration 184/250, Loss: 0.0312\n",
      "Epoch 177/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 177/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 177/200, Iteration 187/250, Loss: 0.0204\n",
      "Epoch 177/200, Iteration 188/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 189/250, Loss: 0.0149\n",
      "Epoch 177/200, Iteration 190/250, Loss: 0.0133\n",
      "Epoch 177/200, Iteration 191/250, Loss: 0.0202\n",
      "Epoch 177/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 177/200, Iteration 193/250, Loss: 0.0179\n",
      "Epoch 177/200, Iteration 194/250, Loss: 0.0104\n",
      "Epoch 177/200, Iteration 195/250, Loss: 0.0168\n",
      "Epoch 177/200, Iteration 196/250, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 197/250, Loss: 0.0071\n",
      "Epoch 177/200, Iteration 198/250, Loss: 0.0114\n",
      "Epoch 177/200, Iteration 199/250, Loss: 0.0126\n",
      "Epoch 177/200, Iteration 200/250, Loss: 0.0247\n",
      "Epoch 177/200, Iteration 201/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 202/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 203/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 204/250, Loss: 0.0188\n",
      "Epoch 177/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 206/250, Loss: 0.0184\n",
      "Epoch 177/200, Iteration 207/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 208/250, Loss: 0.0205\n",
      "Epoch 177/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 177/200, Iteration 210/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 177/200, Iteration 212/250, Loss: 0.0399\n",
      "Epoch 177/200, Iteration 213/250, Loss: 0.0235\n",
      "Epoch 177/200, Iteration 214/250, Loss: 0.0232\n",
      "Epoch 177/200, Iteration 215/250, Loss: 0.0157\n",
      "Epoch 177/200, Iteration 216/250, Loss: 0.0072\n",
      "Epoch 177/200, Iteration 217/250, Loss: 0.0396\n",
      "Epoch 177/200, Iteration 218/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 219/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 220/250, Loss: 0.0258\n",
      "Epoch 177/200, Iteration 221/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 222/250, Loss: 0.0258\n",
      "Epoch 177/200, Iteration 223/250, Loss: 0.0131\n",
      "Epoch 177/200, Iteration 224/250, Loss: 0.0115\n",
      "Epoch 177/200, Iteration 225/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 226/250, Loss: 0.0072\n",
      "Epoch 177/200, Iteration 227/250, Loss: 0.0184\n",
      "Epoch 177/200, Iteration 228/250, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 230/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 231/250, Loss: 0.0253\n",
      "Epoch 177/200, Iteration 232/250, Loss: 0.0269\n",
      "Epoch 177/200, Iteration 233/250, Loss: 0.0238\n",
      "Epoch 177/200, Iteration 234/250, Loss: 0.0136\n",
      "Epoch 177/200, Iteration 235/250, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 236/250, Loss: 0.0475\n",
      "Epoch 177/200, Iteration 237/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 238/250, Loss: 0.0144\n",
      "Epoch 177/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 177/200, Iteration 240/250, Loss: 0.0344\n",
      "Epoch 177/200, Iteration 241/250, Loss: 0.0180\n",
      "Epoch 177/200, Iteration 242/250, Loss: 0.0083\n",
      "Epoch 177/200, Iteration 243/250, Loss: 0.0143\n",
      "Epoch 177/200, Iteration 244/250, Loss: 0.0090\n",
      "Epoch 177/200, Iteration 245/250, Loss: 0.0186\n",
      "Epoch 177/200, Iteration 246/250, Loss: 0.0170\n",
      "Epoch 177/200, Iteration 247/250, Loss: 0.0149\n",
      "Epoch 177/200, Iteration 248/250, Loss: 0.0218\n",
      "Epoch 177/200, Iteration 249/250, Loss: 0.0082\n",
      "Epoch 177/200, Iteration 250/250, Loss: 0.0205\n",
      "Train Error: \n",
      " Accuracy: 88.83%, Avg loss: 0.006206, MRE: 0.601080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.006257, MRE: 0.884636 \n",
      "\n",
      "Epoch 178/200, Iteration 1/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 2/250, Loss: 0.0075\n",
      "Epoch 178/200, Iteration 3/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 4/250, Loss: 0.0117\n",
      "Epoch 178/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 178/200, Iteration 6/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 7/250, Loss: 0.0244\n",
      "Epoch 178/200, Iteration 8/250, Loss: 0.0099\n",
      "Epoch 178/200, Iteration 9/250, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 10/250, Loss: 0.0081\n",
      "Epoch 178/200, Iteration 11/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 12/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 13/250, Loss: 0.0272\n",
      "Epoch 178/200, Iteration 14/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 15/250, Loss: 0.0155\n",
      "Epoch 178/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 18/250, Loss: 0.0184\n",
      "Epoch 178/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 178/200, Iteration 20/250, Loss: 0.0087\n",
      "Epoch 178/200, Iteration 21/250, Loss: 0.0148\n",
      "Epoch 178/200, Iteration 22/250, Loss: 0.0110\n",
      "Epoch 178/200, Iteration 23/250, Loss: 0.0057\n",
      "Epoch 178/200, Iteration 24/250, Loss: 0.0160\n",
      "Epoch 178/200, Iteration 25/250, Loss: 0.0213\n",
      "Epoch 178/200, Iteration 26/250, Loss: 0.0208\n",
      "Epoch 178/200, Iteration 27/250, Loss: 0.0244\n",
      "Epoch 178/200, Iteration 28/250, Loss: 0.0149\n",
      "Epoch 178/200, Iteration 29/250, Loss: 0.0138\n",
      "Epoch 178/200, Iteration 30/250, Loss: 0.0172\n",
      "Epoch 178/200, Iteration 31/250, Loss: 0.0122\n",
      "Epoch 178/200, Iteration 32/250, Loss: 0.0370\n",
      "Epoch 178/200, Iteration 33/250, Loss: 0.0122\n",
      "Epoch 178/200, Iteration 34/250, Loss: 0.0136\n",
      "Epoch 178/200, Iteration 35/250, Loss: 0.0180\n",
      "Epoch 178/200, Iteration 36/250, Loss: 0.0243\n",
      "Epoch 178/200, Iteration 37/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 178/200, Iteration 39/250, Loss: 0.0120\n",
      "Epoch 178/200, Iteration 40/250, Loss: 0.0144\n",
      "Epoch 178/200, Iteration 41/250, Loss: 0.0371\n",
      "Epoch 178/200, Iteration 42/250, Loss: 0.0134\n",
      "Epoch 178/200, Iteration 43/250, Loss: 0.0174\n",
      "Epoch 178/200, Iteration 44/250, Loss: 0.0120\n",
      "Epoch 178/200, Iteration 45/250, Loss: 0.0086\n",
      "Epoch 178/200, Iteration 46/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 47/250, Loss: 0.0111\n",
      "Epoch 178/200, Iteration 48/250, Loss: 0.0462\n",
      "Epoch 178/200, Iteration 49/250, Loss: 0.0137\n",
      "Epoch 178/200, Iteration 50/250, Loss: 0.0134\n",
      "Epoch 178/200, Iteration 51/250, Loss: 0.0312\n",
      "Epoch 178/200, Iteration 52/250, Loss: 0.0260\n",
      "Epoch 178/200, Iteration 53/250, Loss: 0.0135\n",
      "Epoch 178/200, Iteration 54/250, Loss: 0.0169\n",
      "Epoch 178/200, Iteration 55/250, Loss: 0.0169\n",
      "Epoch 178/200, Iteration 56/250, Loss: 0.0159\n",
      "Epoch 178/200, Iteration 57/250, Loss: 0.0279\n",
      "Epoch 178/200, Iteration 58/250, Loss: 0.0264\n",
      "Epoch 178/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 178/200, Iteration 60/250, Loss: 0.0165\n",
      "Epoch 178/200, Iteration 61/250, Loss: 0.0147\n",
      "Epoch 178/200, Iteration 62/250, Loss: 0.0199\n",
      "Epoch 178/200, Iteration 63/250, Loss: 0.0097\n",
      "Epoch 178/200, Iteration 64/250, Loss: 0.0212\n",
      "Epoch 178/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 66/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 67/250, Loss: 0.0113\n",
      "Epoch 178/200, Iteration 68/250, Loss: 0.0071\n",
      "Epoch 178/200, Iteration 69/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 70/250, Loss: 0.0069\n",
      "Epoch 178/200, Iteration 71/250, Loss: 0.0114\n",
      "Epoch 178/200, Iteration 72/250, Loss: 0.0244\n",
      "Epoch 178/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 178/200, Iteration 74/250, Loss: 0.0189\n",
      "Epoch 178/200, Iteration 75/250, Loss: 0.0339\n",
      "Epoch 178/200, Iteration 76/250, Loss: 0.0159\n",
      "Epoch 178/200, Iteration 77/250, Loss: 0.0250\n",
      "Epoch 178/200, Iteration 78/250, Loss: 0.0150\n",
      "Epoch 178/200, Iteration 79/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 80/250, Loss: 0.0112\n",
      "Epoch 178/200, Iteration 81/250, Loss: 0.0134\n",
      "Epoch 178/200, Iteration 82/250, Loss: 0.0099\n",
      "Epoch 178/200, Iteration 83/250, Loss: 0.0067\n",
      "Epoch 178/200, Iteration 84/250, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 85/250, Loss: 0.0301\n",
      "Epoch 178/200, Iteration 86/250, Loss: 0.0156\n",
      "Epoch 178/200, Iteration 87/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 88/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 89/250, Loss: 0.0110\n",
      "Epoch 178/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 178/200, Iteration 91/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 92/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 93/250, Loss: 0.0172\n",
      "Epoch 178/200, Iteration 94/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 95/250, Loss: 0.0112\n",
      "Epoch 178/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 97/250, Loss: 0.0226\n",
      "Epoch 178/200, Iteration 98/250, Loss: 0.0077\n",
      "Epoch 178/200, Iteration 99/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 100/250, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200, Iteration 101/250, Loss: 0.0109\n",
      "Epoch 178/200, Iteration 102/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 103/250, Loss: 0.0193\n",
      "Epoch 178/200, Iteration 104/250, Loss: 0.0060\n",
      "Epoch 178/200, Iteration 105/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 106/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 107/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 108/250, Loss: 0.0186\n",
      "Epoch 178/200, Iteration 109/250, Loss: 0.0133\n",
      "Epoch 178/200, Iteration 110/250, Loss: 0.0332\n",
      "Epoch 178/200, Iteration 111/250, Loss: 0.0109\n",
      "Epoch 178/200, Iteration 112/250, Loss: 0.0078\n",
      "Epoch 178/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 178/200, Iteration 114/250, Loss: 0.0104\n",
      "Epoch 178/200, Iteration 115/250, Loss: 0.0243\n",
      "Epoch 178/200, Iteration 116/250, Loss: 0.0202\n",
      "Epoch 178/200, Iteration 117/250, Loss: 0.0072\n",
      "Epoch 178/200, Iteration 118/250, Loss: 0.0234\n",
      "Epoch 178/200, Iteration 119/250, Loss: 0.0213\n",
      "Epoch 178/200, Iteration 120/250, Loss: 0.0135\n",
      "Epoch 178/200, Iteration 121/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 122/250, Loss: 0.0210\n",
      "Epoch 178/200, Iteration 123/250, Loss: 0.0052\n",
      "Epoch 178/200, Iteration 124/250, Loss: 0.0315\n",
      "Epoch 178/200, Iteration 125/250, Loss: 0.0049\n",
      "Epoch 178/200, Iteration 126/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 127/250, Loss: 0.0182\n",
      "Epoch 178/200, Iteration 128/250, Loss: 0.0157\n",
      "Epoch 178/200, Iteration 129/250, Loss: 0.0090\n",
      "Epoch 178/200, Iteration 130/250, Loss: 0.0155\n",
      "Epoch 178/200, Iteration 131/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 132/250, Loss: 0.0098\n",
      "Epoch 178/200, Iteration 133/250, Loss: 0.0102\n",
      "Epoch 178/200, Iteration 134/250, Loss: 0.0281\n",
      "Epoch 178/200, Iteration 135/250, Loss: 0.0123\n",
      "Epoch 178/200, Iteration 136/250, Loss: 0.0125\n",
      "Epoch 178/200, Iteration 137/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 138/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 139/250, Loss: 0.0134\n",
      "Epoch 178/200, Iteration 140/250, Loss: 0.0269\n",
      "Epoch 178/200, Iteration 141/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 142/250, Loss: 0.0119\n",
      "Epoch 178/200, Iteration 143/250, Loss: 0.0100\n",
      "Epoch 178/200, Iteration 144/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 145/250, Loss: 0.0147\n",
      "Epoch 178/200, Iteration 146/250, Loss: 0.0111\n",
      "Epoch 178/200, Iteration 147/250, Loss: 0.0186\n",
      "Epoch 178/200, Iteration 148/250, Loss: 0.0234\n",
      "Epoch 178/200, Iteration 149/250, Loss: 0.0100\n",
      "Epoch 178/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 178/200, Iteration 151/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 152/250, Loss: 0.0216\n",
      "Epoch 178/200, Iteration 153/250, Loss: 0.0162\n",
      "Epoch 178/200, Iteration 154/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 155/250, Loss: 0.0083\n",
      "Epoch 178/200, Iteration 156/250, Loss: 0.0055\n",
      "Epoch 178/200, Iteration 157/250, Loss: 0.0074\n",
      "Epoch 178/200, Iteration 158/250, Loss: 0.0222\n",
      "Epoch 178/200, Iteration 159/250, Loss: 0.0070\n",
      "Epoch 178/200, Iteration 160/250, Loss: 0.0137\n",
      "Epoch 178/200, Iteration 161/250, Loss: 0.0114\n",
      "Epoch 178/200, Iteration 162/250, Loss: 0.0075\n",
      "Epoch 178/200, Iteration 163/250, Loss: 0.0193\n",
      "Epoch 178/200, Iteration 164/250, Loss: 0.0101\n",
      "Epoch 178/200, Iteration 165/250, Loss: 0.0087\n",
      "Epoch 178/200, Iteration 166/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 167/250, Loss: 0.0205\n",
      "Epoch 178/200, Iteration 168/250, Loss: 0.0278\n",
      "Epoch 178/200, Iteration 169/250, Loss: 0.0217\n",
      "Epoch 178/200, Iteration 170/250, Loss: 0.0104\n",
      "Epoch 178/200, Iteration 171/250, Loss: 0.0237\n",
      "Epoch 178/200, Iteration 172/250, Loss: 0.0266\n",
      "Epoch 178/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 178/200, Iteration 174/250, Loss: 0.0232\n",
      "Epoch 178/200, Iteration 175/250, Loss: 0.0185\n",
      "Epoch 178/200, Iteration 176/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 177/250, Loss: 0.0120\n",
      "Epoch 178/200, Iteration 178/250, Loss: 0.0223\n",
      "Epoch 178/200, Iteration 179/250, Loss: 0.0122\n",
      "Epoch 178/200, Iteration 180/250, Loss: 0.0369\n",
      "Epoch 178/200, Iteration 181/250, Loss: 0.0142\n",
      "Epoch 178/200, Iteration 182/250, Loss: 0.0100\n",
      "Epoch 178/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 184/250, Loss: 0.0075\n",
      "Epoch 178/200, Iteration 185/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 186/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 187/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 188/250, Loss: 0.0242\n",
      "Epoch 178/200, Iteration 189/250, Loss: 0.0351\n",
      "Epoch 178/200, Iteration 190/250, Loss: 0.0253\n",
      "Epoch 178/200, Iteration 191/250, Loss: 0.0051\n",
      "Epoch 178/200, Iteration 192/250, Loss: 0.0137\n",
      "Epoch 178/200, Iteration 193/250, Loss: 0.0065\n",
      "Epoch 178/200, Iteration 194/250, Loss: 0.0234\n",
      "Epoch 178/200, Iteration 195/250, Loss: 0.0062\n",
      "Epoch 178/200, Iteration 196/250, Loss: 0.0188\n",
      "Epoch 178/200, Iteration 197/250, Loss: 0.0133\n",
      "Epoch 178/200, Iteration 198/250, Loss: 0.0135\n",
      "Epoch 178/200, Iteration 199/250, Loss: 0.0190\n",
      "Epoch 178/200, Iteration 200/250, Loss: 0.0061\n",
      "Epoch 178/200, Iteration 201/250, Loss: 0.0071\n",
      "Epoch 178/200, Iteration 202/250, Loss: 0.0119\n",
      "Epoch 178/200, Iteration 203/250, Loss: 0.0222\n",
      "Epoch 178/200, Iteration 204/250, Loss: 0.0100\n",
      "Epoch 178/200, Iteration 205/250, Loss: 0.0190\n",
      "Epoch 178/200, Iteration 206/250, Loss: 0.0268\n",
      "Epoch 178/200, Iteration 207/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 208/250, Loss: 0.0091\n",
      "Epoch 178/200, Iteration 209/250, Loss: 0.0209\n",
      "Epoch 178/200, Iteration 210/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 211/250, Loss: 0.0233\n",
      "Epoch 178/200, Iteration 212/250, Loss: 0.0082\n",
      "Epoch 178/200, Iteration 213/250, Loss: 0.0150\n",
      "Epoch 178/200, Iteration 214/250, Loss: 0.0172\n",
      "Epoch 178/200, Iteration 215/250, Loss: 0.0082\n",
      "Epoch 178/200, Iteration 216/250, Loss: 0.0233\n",
      "Epoch 178/200, Iteration 217/250, Loss: 0.0099\n",
      "Epoch 178/200, Iteration 218/250, Loss: 0.0161\n",
      "Epoch 178/200, Iteration 219/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 220/250, Loss: 0.0197\n",
      "Epoch 178/200, Iteration 221/250, Loss: 0.0258\n",
      "Epoch 178/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 224/250, Loss: 0.0114\n",
      "Epoch 178/200, Iteration 225/250, Loss: 0.0241\n",
      "Epoch 178/200, Iteration 226/250, Loss: 0.0083\n",
      "Epoch 178/200, Iteration 227/250, Loss: 0.0210\n",
      "Epoch 178/200, Iteration 228/250, Loss: 0.0122\n",
      "Epoch 178/200, Iteration 229/250, Loss: 0.0178\n",
      "Epoch 178/200, Iteration 230/250, Loss: 0.0170\n",
      "Epoch 178/200, Iteration 231/250, Loss: 0.0098\n",
      "Epoch 178/200, Iteration 232/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 233/250, Loss: 0.0176\n",
      "Epoch 178/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 178/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 236/250, Loss: 0.0289\n",
      "Epoch 178/200, Iteration 237/250, Loss: 0.0103\n",
      "Epoch 178/200, Iteration 238/250, Loss: 0.0215\n",
      "Epoch 178/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 178/200, Iteration 240/250, Loss: 0.0176\n",
      "Epoch 178/200, Iteration 241/250, Loss: 0.0313\n",
      "Epoch 178/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 178/200, Iteration 243/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 244/250, Loss: 0.0091\n",
      "Epoch 178/200, Iteration 245/250, Loss: 0.0212\n",
      "Epoch 178/200, Iteration 246/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 247/250, Loss: 0.0265\n",
      "Epoch 178/200, Iteration 248/250, Loss: 0.0438\n",
      "Epoch 178/200, Iteration 249/250, Loss: 0.0169\n",
      "Epoch 178/200, Iteration 250/250, Loss: 0.0153\n",
      "Train Error: \n",
      " Accuracy: 92.29%, Avg loss: 0.005954, MRE: 0.591902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.006031, MRE: 0.961160 \n",
      "\n",
      "Epoch 179/200, Iteration 1/250, Loss: 0.0142\n",
      "Epoch 179/200, Iteration 2/250, Loss: 0.0169\n",
      "Epoch 179/200, Iteration 3/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 4/250, Loss: 0.0068\n",
      "Epoch 179/200, Iteration 5/250, Loss: 0.0150\n",
      "Epoch 179/200, Iteration 6/250, Loss: 0.0177\n",
      "Epoch 179/200, Iteration 7/250, Loss: 0.0184\n",
      "Epoch 179/200, Iteration 8/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 9/250, Loss: 0.0243\n",
      "Epoch 179/200, Iteration 10/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 11/250, Loss: 0.0159\n",
      "Epoch 179/200, Iteration 12/250, Loss: 0.0176\n",
      "Epoch 179/200, Iteration 13/250, Loss: 0.0152\n",
      "Epoch 179/200, Iteration 14/250, Loss: 0.0140\n",
      "Epoch 179/200, Iteration 15/250, Loss: 0.0064\n",
      "Epoch 179/200, Iteration 16/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 17/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 18/250, Loss: 0.0084\n",
      "Epoch 179/200, Iteration 19/250, Loss: 0.0147\n",
      "Epoch 179/200, Iteration 20/250, Loss: 0.0071\n",
      "Epoch 179/200, Iteration 21/250, Loss: 0.0087\n",
      "Epoch 179/200, Iteration 22/250, Loss: 0.0241\n",
      "Epoch 179/200, Iteration 23/250, Loss: 0.0136\n",
      "Epoch 179/200, Iteration 24/250, Loss: 0.0262\n",
      "Epoch 179/200, Iteration 25/250, Loss: 0.0101\n",
      "Epoch 179/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 179/200, Iteration 27/250, Loss: 0.0237\n",
      "Epoch 179/200, Iteration 28/250, Loss: 0.0103\n",
      "Epoch 179/200, Iteration 29/250, Loss: 0.0150\n",
      "Epoch 179/200, Iteration 30/250, Loss: 0.0327\n",
      "Epoch 179/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 179/200, Iteration 32/250, Loss: 0.0110\n",
      "Epoch 179/200, Iteration 33/250, Loss: 0.0053\n",
      "Epoch 179/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 35/250, Loss: 0.0189\n",
      "Epoch 179/200, Iteration 36/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 37/250, Loss: 0.0097\n",
      "Epoch 179/200, Iteration 38/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 179/200, Iteration 40/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 41/250, Loss: 0.0267\n",
      "Epoch 179/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 43/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 44/250, Loss: 0.0154\n",
      "Epoch 179/200, Iteration 45/250, Loss: 0.0279\n",
      "Epoch 179/200, Iteration 46/250, Loss: 0.0206\n",
      "Epoch 179/200, Iteration 47/250, Loss: 0.0178\n",
      "Epoch 179/200, Iteration 48/250, Loss: 0.0082\n",
      "Epoch 179/200, Iteration 49/250, Loss: 0.0209\n",
      "Epoch 179/200, Iteration 50/250, Loss: 0.0216\n",
      "Epoch 179/200, Iteration 51/250, Loss: 0.0228\n",
      "Epoch 179/200, Iteration 52/250, Loss: 0.0218\n",
      "Epoch 179/200, Iteration 53/250, Loss: 0.0153\n",
      "Epoch 179/200, Iteration 54/250, Loss: 0.0094\n",
      "Epoch 179/200, Iteration 55/250, Loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200, Iteration 56/250, Loss: 0.0085\n",
      "Epoch 179/200, Iteration 57/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 58/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 59/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 60/250, Loss: 0.0165\n",
      "Epoch 179/200, Iteration 61/250, Loss: 0.0079\n",
      "Epoch 179/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 179/200, Iteration 63/250, Loss: 0.0268\n",
      "Epoch 179/200, Iteration 64/250, Loss: 0.0064\n",
      "Epoch 179/200, Iteration 65/250, Loss: 0.0123\n",
      "Epoch 179/200, Iteration 66/250, Loss: 0.0155\n",
      "Epoch 179/200, Iteration 67/250, Loss: 0.0082\n",
      "Epoch 179/200, Iteration 68/250, Loss: 0.0179\n",
      "Epoch 179/200, Iteration 69/250, Loss: 0.0166\n",
      "Epoch 179/200, Iteration 70/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 71/250, Loss: 0.0111\n",
      "Epoch 179/200, Iteration 72/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 179/200, Iteration 74/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 75/250, Loss: 0.0212\n",
      "Epoch 179/200, Iteration 76/250, Loss: 0.0177\n",
      "Epoch 179/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 78/250, Loss: 0.0135\n",
      "Epoch 179/200, Iteration 79/250, Loss: 0.0136\n",
      "Epoch 179/200, Iteration 80/250, Loss: 0.0163\n",
      "Epoch 179/200, Iteration 81/250, Loss: 0.0248\n",
      "Epoch 179/200, Iteration 82/250, Loss: 0.0150\n",
      "Epoch 179/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 84/250, Loss: 0.0159\n",
      "Epoch 179/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 179/200, Iteration 86/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 87/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 88/250, Loss: 0.0143\n",
      "Epoch 179/200, Iteration 89/250, Loss: 0.0235\n",
      "Epoch 179/200, Iteration 90/250, Loss: 0.0076\n",
      "Epoch 179/200, Iteration 91/250, Loss: 0.0097\n",
      "Epoch 179/200, Iteration 92/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 93/250, Loss: 0.0188\n",
      "Epoch 179/200, Iteration 94/250, Loss: 0.0304\n",
      "Epoch 179/200, Iteration 95/250, Loss: 0.0128\n",
      "Epoch 179/200, Iteration 96/250, Loss: 0.0164\n",
      "Epoch 179/200, Iteration 97/250, Loss: 0.0220\n",
      "Epoch 179/200, Iteration 98/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 99/250, Loss: 0.0095\n",
      "Epoch 179/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 179/200, Iteration 101/250, Loss: 0.0157\n",
      "Epoch 179/200, Iteration 102/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 103/250, Loss: 0.0180\n",
      "Epoch 179/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 179/200, Iteration 105/250, Loss: 0.0052\n",
      "Epoch 179/200, Iteration 106/250, Loss: 0.0081\n",
      "Epoch 179/200, Iteration 107/250, Loss: 0.0118\n",
      "Epoch 179/200, Iteration 108/250, Loss: 0.0076\n",
      "Epoch 179/200, Iteration 109/250, Loss: 0.0281\n",
      "Epoch 179/200, Iteration 110/250, Loss: 0.0077\n",
      "Epoch 179/200, Iteration 111/250, Loss: 0.0312\n",
      "Epoch 179/200, Iteration 112/250, Loss: 0.0353\n",
      "Epoch 179/200, Iteration 113/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 114/250, Loss: 0.0219\n",
      "Epoch 179/200, Iteration 115/250, Loss: 0.0085\n",
      "Epoch 179/200, Iteration 116/250, Loss: 0.0259\n",
      "Epoch 179/200, Iteration 117/250, Loss: 0.0142\n",
      "Epoch 179/200, Iteration 118/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 119/250, Loss: 0.0115\n",
      "Epoch 179/200, Iteration 120/250, Loss: 0.0132\n",
      "Epoch 179/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 179/200, Iteration 122/250, Loss: 0.0153\n",
      "Epoch 179/200, Iteration 123/250, Loss: 0.0127\n",
      "Epoch 179/200, Iteration 124/250, Loss: 0.0072\n",
      "Epoch 179/200, Iteration 125/250, Loss: 0.0126\n",
      "Epoch 179/200, Iteration 126/250, Loss: 0.0210\n",
      "Epoch 179/200, Iteration 127/250, Loss: 0.0247\n",
      "Epoch 179/200, Iteration 128/250, Loss: 0.0176\n",
      "Epoch 179/200, Iteration 129/250, Loss: 0.0141\n",
      "Epoch 179/200, Iteration 130/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 131/250, Loss: 0.0120\n",
      "Epoch 179/200, Iteration 132/250, Loss: 0.0192\n",
      "Epoch 179/200, Iteration 133/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 134/250, Loss: 0.0125\n",
      "Epoch 179/200, Iteration 135/250, Loss: 0.0370\n",
      "Epoch 179/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 179/200, Iteration 137/250, Loss: 0.0341\n",
      "Epoch 179/200, Iteration 138/250, Loss: 0.0145\n",
      "Epoch 179/200, Iteration 139/250, Loss: 0.0139\n",
      "Epoch 179/200, Iteration 140/250, Loss: 0.0231\n",
      "Epoch 179/200, Iteration 141/250, Loss: 0.0092\n",
      "Epoch 179/200, Iteration 142/250, Loss: 0.0049\n",
      "Epoch 179/200, Iteration 143/250, Loss: 0.0144\n",
      "Epoch 179/200, Iteration 144/250, Loss: 0.0110\n",
      "Epoch 179/200, Iteration 145/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 146/250, Loss: 0.0078\n",
      "Epoch 179/200, Iteration 147/250, Loss: 0.0176\n",
      "Epoch 179/200, Iteration 148/250, Loss: 0.0145\n",
      "Epoch 179/200, Iteration 149/250, Loss: 0.0178\n",
      "Epoch 179/200, Iteration 150/250, Loss: 0.0341\n",
      "Epoch 179/200, Iteration 151/250, Loss: 0.0215\n",
      "Epoch 179/200, Iteration 152/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 153/250, Loss: 0.0203\n",
      "Epoch 179/200, Iteration 154/250, Loss: 0.0160\n",
      "Epoch 179/200, Iteration 155/250, Loss: 0.0323\n",
      "Epoch 179/200, Iteration 156/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 157/250, Loss: 0.0073\n",
      "Epoch 179/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 179/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 179/200, Iteration 160/250, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 161/250, Loss: 0.0099\n",
      "Epoch 179/200, Iteration 162/250, Loss: 0.0077\n",
      "Epoch 179/200, Iteration 163/250, Loss: 0.0103\n",
      "Epoch 179/200, Iteration 164/250, Loss: 0.0082\n",
      "Epoch 179/200, Iteration 165/250, Loss: 0.0261\n",
      "Epoch 179/200, Iteration 166/250, Loss: 0.0117\n",
      "Epoch 179/200, Iteration 167/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 168/250, Loss: 0.0143\n",
      "Epoch 179/200, Iteration 169/250, Loss: 0.0280\n",
      "Epoch 179/200, Iteration 170/250, Loss: 0.0148\n",
      "Epoch 179/200, Iteration 171/250, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 179/200, Iteration 173/250, Loss: 0.0234\n",
      "Epoch 179/200, Iteration 174/250, Loss: 0.0350\n",
      "Epoch 179/200, Iteration 175/250, Loss: 0.0331\n",
      "Epoch 179/200, Iteration 176/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 177/250, Loss: 0.0128\n",
      "Epoch 179/200, Iteration 178/250, Loss: 0.0114\n",
      "Epoch 179/200, Iteration 179/250, Loss: 0.0204\n",
      "Epoch 179/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 179/200, Iteration 181/250, Loss: 0.0126\n",
      "Epoch 179/200, Iteration 182/250, Loss: 0.0234\n",
      "Epoch 179/200, Iteration 183/250, Loss: 0.0234\n",
      "Epoch 179/200, Iteration 184/250, Loss: 0.0073\n",
      "Epoch 179/200, Iteration 185/250, Loss: 0.0202\n",
      "Epoch 179/200, Iteration 186/250, Loss: 0.0083\n",
      "Epoch 179/200, Iteration 187/250, Loss: 0.0221\n",
      "Epoch 179/200, Iteration 188/250, Loss: 0.0224\n",
      "Epoch 179/200, Iteration 189/250, Loss: 0.0085\n",
      "Epoch 179/200, Iteration 190/250, Loss: 0.0198\n",
      "Epoch 179/200, Iteration 191/250, Loss: 0.0113\n",
      "Epoch 179/200, Iteration 192/250, Loss: 0.0092\n",
      "Epoch 179/200, Iteration 193/250, Loss: 0.0132\n",
      "Epoch 179/200, Iteration 194/250, Loss: 0.0112\n",
      "Epoch 179/200, Iteration 195/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 196/250, Loss: 0.0143\n",
      "Epoch 179/200, Iteration 197/250, Loss: 0.0107\n",
      "Epoch 179/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 179/200, Iteration 199/250, Loss: 0.0265\n",
      "Epoch 179/200, Iteration 200/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 201/250, Loss: 0.0162\n",
      "Epoch 179/200, Iteration 202/250, Loss: 0.0282\n",
      "Epoch 179/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 179/200, Iteration 204/250, Loss: 0.0181\n",
      "Epoch 179/200, Iteration 205/250, Loss: 0.0104\n",
      "Epoch 179/200, Iteration 206/250, Loss: 0.0225\n",
      "Epoch 179/200, Iteration 207/250, Loss: 0.0219\n",
      "Epoch 179/200, Iteration 208/250, Loss: 0.0201\n",
      "Epoch 179/200, Iteration 209/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 210/250, Loss: 0.0103\n",
      "Epoch 179/200, Iteration 211/250, Loss: 0.0205\n",
      "Epoch 179/200, Iteration 212/250, Loss: 0.0135\n",
      "Epoch 179/200, Iteration 213/250, Loss: 0.0345\n",
      "Epoch 179/200, Iteration 214/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 215/250, Loss: 0.0056\n",
      "Epoch 179/200, Iteration 216/250, Loss: 0.0169\n",
      "Epoch 179/200, Iteration 217/250, Loss: 0.0143\n",
      "Epoch 179/200, Iteration 218/250, Loss: 0.0174\n",
      "Epoch 179/200, Iteration 219/250, Loss: 0.0296\n",
      "Epoch 179/200, Iteration 220/250, Loss: 0.0128\n",
      "Epoch 179/200, Iteration 221/250, Loss: 0.0081\n",
      "Epoch 179/200, Iteration 222/250, Loss: 0.0125\n",
      "Epoch 179/200, Iteration 223/250, Loss: 0.0207\n",
      "Epoch 179/200, Iteration 224/250, Loss: 0.0082\n",
      "Epoch 179/200, Iteration 225/250, Loss: 0.0158\n",
      "Epoch 179/200, Iteration 226/250, Loss: 0.0230\n",
      "Epoch 179/200, Iteration 227/250, Loss: 0.0132\n",
      "Epoch 179/200, Iteration 228/250, Loss: 0.0133\n",
      "Epoch 179/200, Iteration 229/250, Loss: 0.0052\n",
      "Epoch 179/200, Iteration 230/250, Loss: 0.0094\n",
      "Epoch 179/200, Iteration 231/250, Loss: 0.0081\n",
      "Epoch 179/200, Iteration 232/250, Loss: 0.0081\n",
      "Epoch 179/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 179/200, Iteration 234/250, Loss: 0.0205\n",
      "Epoch 179/200, Iteration 235/250, Loss: 0.0069\n",
      "Epoch 179/200, Iteration 236/250, Loss: 0.0053\n",
      "Epoch 179/200, Iteration 237/250, Loss: 0.0180\n",
      "Epoch 179/200, Iteration 238/250, Loss: 0.0082\n",
      "Epoch 179/200, Iteration 239/250, Loss: 0.0087\n",
      "Epoch 179/200, Iteration 240/250, Loss: 0.0399\n",
      "Epoch 179/200, Iteration 241/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 242/250, Loss: 0.0307\n",
      "Epoch 179/200, Iteration 243/250, Loss: 0.0237\n",
      "Epoch 179/200, Iteration 244/250, Loss: 0.0072\n",
      "Epoch 179/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 246/250, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 247/250, Loss: 0.0261\n",
      "Epoch 179/200, Iteration 248/250, Loss: 0.0185\n",
      "Epoch 179/200, Iteration 249/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 250/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.11%, Avg loss: 0.005863, MRE: 0.602313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.005901, MRE: 0.990872 \n",
      "\n",
      "Epoch 180/200, Iteration 1/250, Loss: 0.0099\n",
      "Epoch 180/200, Iteration 2/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 3/250, Loss: 0.0108\n",
      "Epoch 180/200, Iteration 4/250, Loss: 0.0166\n",
      "Epoch 180/200, Iteration 5/250, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 6/250, Loss: 0.0067\n",
      "Epoch 180/200, Iteration 7/250, Loss: 0.0199\n",
      "Epoch 180/200, Iteration 8/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 9/250, Loss: 0.0126\n",
      "Epoch 180/200, Iteration 10/250, Loss: 0.0125\n",
      "Epoch 180/200, Iteration 11/250, Loss: 0.0134\n",
      "Epoch 180/200, Iteration 12/250, Loss: 0.0066\n",
      "Epoch 180/200, Iteration 13/250, Loss: 0.0156\n",
      "Epoch 180/200, Iteration 14/250, Loss: 0.0207\n",
      "Epoch 180/200, Iteration 15/250, Loss: 0.0143\n",
      "Epoch 180/200, Iteration 16/250, Loss: 0.0097\n",
      "Epoch 180/200, Iteration 17/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 18/250, Loss: 0.0055\n",
      "Epoch 180/200, Iteration 19/250, Loss: 0.0237\n",
      "Epoch 180/200, Iteration 20/250, Loss: 0.0081\n",
      "Epoch 180/200, Iteration 21/250, Loss: 0.0087\n",
      "Epoch 180/200, Iteration 22/250, Loss: 0.0112\n",
      "Epoch 180/200, Iteration 23/250, Loss: 0.0080\n",
      "Epoch 180/200, Iteration 24/250, Loss: 0.0149\n",
      "Epoch 180/200, Iteration 25/250, Loss: 0.0089\n",
      "Epoch 180/200, Iteration 26/250, Loss: 0.0162\n",
      "Epoch 180/200, Iteration 27/250, Loss: 0.0132\n",
      "Epoch 180/200, Iteration 28/250, Loss: 0.0098\n",
      "Epoch 180/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 180/200, Iteration 30/250, Loss: 0.0059\n",
      "Epoch 180/200, Iteration 31/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 32/250, Loss: 0.0064\n",
      "Epoch 180/200, Iteration 33/250, Loss: 0.0171\n",
      "Epoch 180/200, Iteration 34/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 35/250, Loss: 0.0173\n",
      "Epoch 180/200, Iteration 36/250, Loss: 0.0227\n",
      "Epoch 180/200, Iteration 37/250, Loss: 0.0295\n",
      "Epoch 180/200, Iteration 38/250, Loss: 0.0191\n",
      "Epoch 180/200, Iteration 39/250, Loss: 0.0235\n",
      "Epoch 180/200, Iteration 40/250, Loss: 0.0174\n",
      "Epoch 180/200, Iteration 41/250, Loss: 0.0133\n",
      "Epoch 180/200, Iteration 42/250, Loss: 0.0156\n",
      "Epoch 180/200, Iteration 43/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 44/250, Loss: 0.0108\n",
      "Epoch 180/200, Iteration 45/250, Loss: 0.0364\n",
      "Epoch 180/200, Iteration 46/250, Loss: 0.0288\n",
      "Epoch 180/200, Iteration 47/250, Loss: 0.0246\n",
      "Epoch 180/200, Iteration 48/250, Loss: 0.0070\n",
      "Epoch 180/200, Iteration 49/250, Loss: 0.0127\n",
      "Epoch 180/200, Iteration 50/250, Loss: 0.0163\n",
      "Epoch 180/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 180/200, Iteration 52/250, Loss: 0.0247\n",
      "Epoch 180/200, Iteration 53/250, Loss: 0.0208\n",
      "Epoch 180/200, Iteration 54/250, Loss: 0.0275\n",
      "Epoch 180/200, Iteration 55/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 56/250, Loss: 0.0191\n",
      "Epoch 180/200, Iteration 57/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 58/250, Loss: 0.0176\n",
      "Epoch 180/200, Iteration 59/250, Loss: 0.0127\n",
      "Epoch 180/200, Iteration 60/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 61/250, Loss: 0.0171\n",
      "Epoch 180/200, Iteration 62/250, Loss: 0.0111\n",
      "Epoch 180/200, Iteration 63/250, Loss: 0.0163\n",
      "Epoch 180/200, Iteration 64/250, Loss: 0.0065\n",
      "Epoch 180/200, Iteration 65/250, Loss: 0.0127\n",
      "Epoch 180/200, Iteration 66/250, Loss: 0.0183\n",
      "Epoch 180/200, Iteration 67/250, Loss: 0.0110\n",
      "Epoch 180/200, Iteration 68/250, Loss: 0.0115\n",
      "Epoch 180/200, Iteration 69/250, Loss: 0.0153\n",
      "Epoch 180/200, Iteration 70/250, Loss: 0.0235\n",
      "Epoch 180/200, Iteration 71/250, Loss: 0.0171\n",
      "Epoch 180/200, Iteration 72/250, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 73/250, Loss: 0.0112\n",
      "Epoch 180/200, Iteration 74/250, Loss: 0.0099\n",
      "Epoch 180/200, Iteration 75/250, Loss: 0.0161\n",
      "Epoch 180/200, Iteration 76/250, Loss: 0.0103\n",
      "Epoch 180/200, Iteration 77/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 78/250, Loss: 0.0265\n",
      "Epoch 180/200, Iteration 79/250, Loss: 0.0212\n",
      "Epoch 180/200, Iteration 80/250, Loss: 0.0447\n",
      "Epoch 180/200, Iteration 81/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 180/200, Iteration 83/250, Loss: 0.0232\n",
      "Epoch 180/200, Iteration 84/250, Loss: 0.0356\n",
      "Epoch 180/200, Iteration 85/250, Loss: 0.0213\n",
      "Epoch 180/200, Iteration 86/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 87/250, Loss: 0.0240\n",
      "Epoch 180/200, Iteration 88/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 89/250, Loss: 0.0080\n",
      "Epoch 180/200, Iteration 90/250, Loss: 0.0200\n",
      "Epoch 180/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 92/250, Loss: 0.0091\n",
      "Epoch 180/200, Iteration 93/250, Loss: 0.0087\n",
      "Epoch 180/200, Iteration 94/250, Loss: 0.0157\n",
      "Epoch 180/200, Iteration 95/250, Loss: 0.0098\n",
      "Epoch 180/200, Iteration 96/250, Loss: 0.0179\n",
      "Epoch 180/200, Iteration 97/250, Loss: 0.0078\n",
      "Epoch 180/200, Iteration 98/250, Loss: 0.0143\n",
      "Epoch 180/200, Iteration 99/250, Loss: 0.0192\n",
      "Epoch 180/200, Iteration 100/250, Loss: 0.0173\n",
      "Epoch 180/200, Iteration 101/250, Loss: 0.0249\n",
      "Epoch 180/200, Iteration 102/250, Loss: 0.0105\n",
      "Epoch 180/200, Iteration 103/250, Loss: 0.0176\n",
      "Epoch 180/200, Iteration 104/250, Loss: 0.0435\n",
      "Epoch 180/200, Iteration 105/250, Loss: 0.0161\n",
      "Epoch 180/200, Iteration 106/250, Loss: 0.0208\n",
      "Epoch 180/200, Iteration 107/250, Loss: 0.0080\n",
      "Epoch 180/200, Iteration 108/250, Loss: 0.0094\n",
      "Epoch 180/200, Iteration 109/250, Loss: 0.0096\n",
      "Epoch 180/200, Iteration 110/250, Loss: 0.0101\n",
      "Epoch 180/200, Iteration 111/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 112/250, Loss: 0.0332\n",
      "Epoch 180/200, Iteration 113/250, Loss: 0.0060\n",
      "Epoch 180/200, Iteration 114/250, Loss: 0.0087\n",
      "Epoch 180/200, Iteration 115/250, Loss: 0.0083\n",
      "Epoch 180/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 117/250, Loss: 0.0231\n",
      "Epoch 180/200, Iteration 118/250, Loss: 0.0298\n",
      "Epoch 180/200, Iteration 119/250, Loss: 0.0102\n",
      "Epoch 180/200, Iteration 120/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 121/250, Loss: 0.0197\n",
      "Epoch 180/200, Iteration 122/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 123/250, Loss: 0.0115\n",
      "Epoch 180/200, Iteration 124/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 125/250, Loss: 0.0078\n",
      "Epoch 180/200, Iteration 126/250, Loss: 0.0105\n",
      "Epoch 180/200, Iteration 127/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 128/250, Loss: 0.0123\n",
      "Epoch 180/200, Iteration 129/250, Loss: 0.0296\n",
      "Epoch 180/200, Iteration 130/250, Loss: 0.0091\n",
      "Epoch 180/200, Iteration 131/250, Loss: 0.0076\n",
      "Epoch 180/200, Iteration 132/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 133/250, Loss: 0.0068\n",
      "Epoch 180/200, Iteration 134/250, Loss: 0.0211\n",
      "Epoch 180/200, Iteration 135/250, Loss: 0.0084\n",
      "Epoch 180/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 180/200, Iteration 137/250, Loss: 0.0191\n",
      "Epoch 180/200, Iteration 138/250, Loss: 0.0085\n",
      "Epoch 180/200, Iteration 139/250, Loss: 0.0136\n",
      "Epoch 180/200, Iteration 140/250, Loss: 0.0159\n",
      "Epoch 180/200, Iteration 141/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 142/250, Loss: 0.0249\n",
      "Epoch 180/200, Iteration 143/250, Loss: 0.0221\n",
      "Epoch 180/200, Iteration 144/250, Loss: 0.0217\n",
      "Epoch 180/200, Iteration 145/250, Loss: 0.0088\n",
      "Epoch 180/200, Iteration 146/250, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 147/250, Loss: 0.0066\n",
      "Epoch 180/200, Iteration 148/250, Loss: 0.0135\n",
      "Epoch 180/200, Iteration 149/250, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 150/250, Loss: 0.0203\n",
      "Epoch 180/200, Iteration 151/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 152/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 153/250, Loss: 0.0067\n",
      "Epoch 180/200, Iteration 154/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 155/250, Loss: 0.0051\n",
      "Epoch 180/200, Iteration 156/250, Loss: 0.0199\n",
      "Epoch 180/200, Iteration 157/250, Loss: 0.0083\n",
      "Epoch 180/200, Iteration 158/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 159/250, Loss: 0.0130\n",
      "Epoch 180/200, Iteration 160/250, Loss: 0.0166\n",
      "Epoch 180/200, Iteration 161/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 162/250, Loss: 0.0112\n",
      "Epoch 180/200, Iteration 163/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 180/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 166/250, Loss: 0.0143\n",
      "Epoch 180/200, Iteration 167/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 169/250, Loss: 0.0271\n",
      "Epoch 180/200, Iteration 170/250, Loss: 0.0386\n",
      "Epoch 180/200, Iteration 171/250, Loss: 0.0405\n",
      "Epoch 180/200, Iteration 172/250, Loss: 0.0196\n",
      "Epoch 180/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 180/200, Iteration 174/250, Loss: 0.0072\n",
      "Epoch 180/200, Iteration 175/250, Loss: 0.0146\n",
      "Epoch 180/200, Iteration 176/250, Loss: 0.0099\n",
      "Epoch 180/200, Iteration 177/250, Loss: 0.0154\n",
      "Epoch 180/200, Iteration 178/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 179/250, Loss: 0.0294\n",
      "Epoch 180/200, Iteration 180/250, Loss: 0.0183\n",
      "Epoch 180/200, Iteration 181/250, Loss: 0.0129\n",
      "Epoch 180/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 180/200, Iteration 183/250, Loss: 0.0223\n",
      "Epoch 180/200, Iteration 184/250, Loss: 0.0245\n",
      "Epoch 180/200, Iteration 185/250, Loss: 0.0222\n",
      "Epoch 180/200, Iteration 186/250, Loss: 0.0097\n",
      "Epoch 180/200, Iteration 187/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 188/250, Loss: 0.0069\n",
      "Epoch 180/200, Iteration 189/250, Loss: 0.0067\n",
      "Epoch 180/200, Iteration 190/250, Loss: 0.0204\n",
      "Epoch 180/200, Iteration 191/250, Loss: 0.0237\n",
      "Epoch 180/200, Iteration 192/250, Loss: 0.0262\n",
      "Epoch 180/200, Iteration 193/250, Loss: 0.0235\n",
      "Epoch 180/200, Iteration 194/250, Loss: 0.0212\n",
      "Epoch 180/200, Iteration 195/250, Loss: 0.0129\n",
      "Epoch 180/200, Iteration 196/250, Loss: 0.0257\n",
      "Epoch 180/200, Iteration 197/250, Loss: 0.0125\n",
      "Epoch 180/200, Iteration 198/250, Loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Iteration 199/250, Loss: 0.0096\n",
      "Epoch 180/200, Iteration 200/250, Loss: 0.0257\n",
      "Epoch 180/200, Iteration 201/250, Loss: 0.0248\n",
      "Epoch 180/200, Iteration 202/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 203/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 204/250, Loss: 0.0151\n",
      "Epoch 180/200, Iteration 205/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 206/250, Loss: 0.0051\n",
      "Epoch 180/200, Iteration 207/250, Loss: 0.0204\n",
      "Epoch 180/200, Iteration 208/250, Loss: 0.0139\n",
      "Epoch 180/200, Iteration 209/250, Loss: 0.0121\n",
      "Epoch 180/200, Iteration 210/250, Loss: 0.0234\n",
      "Epoch 180/200, Iteration 211/250, Loss: 0.0170\n",
      "Epoch 180/200, Iteration 212/250, Loss: 0.0053\n",
      "Epoch 180/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 180/200, Iteration 214/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 215/250, Loss: 0.0238\n",
      "Epoch 180/200, Iteration 216/250, Loss: 0.0171\n",
      "Epoch 180/200, Iteration 217/250, Loss: 0.0078\n",
      "Epoch 180/200, Iteration 218/250, Loss: 0.0120\n",
      "Epoch 180/200, Iteration 219/250, Loss: 0.0144\n",
      "Epoch 180/200, Iteration 220/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 221/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 222/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 223/250, Loss: 0.0083\n",
      "Epoch 180/200, Iteration 224/250, Loss: 0.0139\n",
      "Epoch 180/200, Iteration 225/250, Loss: 0.0164\n",
      "Epoch 180/200, Iteration 226/250, Loss: 0.0351\n",
      "Epoch 180/200, Iteration 227/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 228/250, Loss: 0.0210\n",
      "Epoch 180/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 180/200, Iteration 230/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 231/250, Loss: 0.0139\n",
      "Epoch 180/200, Iteration 232/250, Loss: 0.0073\n",
      "Epoch 180/200, Iteration 233/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 234/250, Loss: 0.0190\n",
      "Epoch 180/200, Iteration 235/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 236/250, Loss: 0.0098\n",
      "Epoch 180/200, Iteration 237/250, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 180/200, Iteration 239/250, Loss: 0.0191\n",
      "Epoch 180/200, Iteration 240/250, Loss: 0.0133\n",
      "Epoch 180/200, Iteration 241/250, Loss: 0.0094\n",
      "Epoch 180/200, Iteration 242/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 243/250, Loss: 0.0159\n",
      "Epoch 180/200, Iteration 244/250, Loss: 0.0058\n",
      "Epoch 180/200, Iteration 245/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 246/250, Loss: 0.0089\n",
      "Epoch 180/200, Iteration 247/250, Loss: 0.0132\n",
      "Epoch 180/200, Iteration 248/250, Loss: 0.0154\n",
      "Epoch 180/200, Iteration 249/250, Loss: 0.0071\n",
      "Epoch 180/200, Iteration 250/250, Loss: 0.0138\n",
      "Train Error: \n",
      " Accuracy: 86.17%, Avg loss: 0.006522, MRE: 0.625888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.05%, Avg loss: 0.006622, MRE: 0.943733 \n",
      "\n",
      "Epoch 181/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 181/200, Iteration 2/250, Loss: 0.0054\n",
      "Epoch 181/200, Iteration 3/250, Loss: 0.0097\n",
      "Epoch 181/200, Iteration 4/250, Loss: 0.0158\n",
      "Epoch 181/200, Iteration 5/250, Loss: 0.0088\n",
      "Epoch 181/200, Iteration 6/250, Loss: 0.0116\n",
      "Epoch 181/200, Iteration 7/250, Loss: 0.0158\n",
      "Epoch 181/200, Iteration 8/250, Loss: 0.0242\n",
      "Epoch 181/200, Iteration 9/250, Loss: 0.0224\n",
      "Epoch 181/200, Iteration 10/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 11/250, Loss: 0.0077\n",
      "Epoch 181/200, Iteration 12/250, Loss: 0.0156\n",
      "Epoch 181/200, Iteration 13/250, Loss: 0.0118\n",
      "Epoch 181/200, Iteration 14/250, Loss: 0.0204\n",
      "Epoch 181/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 16/250, Loss: 0.0109\n",
      "Epoch 181/200, Iteration 17/250, Loss: 0.0132\n",
      "Epoch 181/200, Iteration 18/250, Loss: 0.0102\n",
      "Epoch 181/200, Iteration 19/250, Loss: 0.0164\n",
      "Epoch 181/200, Iteration 20/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 181/200, Iteration 22/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 23/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 24/250, Loss: 0.0091\n",
      "Epoch 181/200, Iteration 25/250, Loss: 0.0125\n",
      "Epoch 181/200, Iteration 26/250, Loss: 0.0124\n",
      "Epoch 181/200, Iteration 27/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 28/250, Loss: 0.0068\n",
      "Epoch 181/200, Iteration 29/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 30/250, Loss: 0.0203\n",
      "Epoch 181/200, Iteration 31/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 181/200, Iteration 33/250, Loss: 0.0062\n",
      "Epoch 181/200, Iteration 34/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 35/250, Loss: 0.0192\n",
      "Epoch 181/200, Iteration 36/250, Loss: 0.0168\n",
      "Epoch 181/200, Iteration 37/250, Loss: 0.0260\n",
      "Epoch 181/200, Iteration 38/250, Loss: 0.0136\n",
      "Epoch 181/200, Iteration 39/250, Loss: 0.0133\n",
      "Epoch 181/200, Iteration 40/250, Loss: 0.0093\n",
      "Epoch 181/200, Iteration 41/250, Loss: 0.0220\n",
      "Epoch 181/200, Iteration 42/250, Loss: 0.0240\n",
      "Epoch 181/200, Iteration 43/250, Loss: 0.0124\n",
      "Epoch 181/200, Iteration 44/250, Loss: 0.0100\n",
      "Epoch 181/200, Iteration 45/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 46/250, Loss: 0.0262\n",
      "Epoch 181/200, Iteration 47/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 48/250, Loss: 0.0098\n",
      "Epoch 181/200, Iteration 49/250, Loss: 0.0103\n",
      "Epoch 181/200, Iteration 50/250, Loss: 0.0208\n",
      "Epoch 181/200, Iteration 51/250, Loss: 0.0283\n",
      "Epoch 181/200, Iteration 52/250, Loss: 0.0239\n",
      "Epoch 181/200, Iteration 53/250, Loss: 0.0054\n",
      "Epoch 181/200, Iteration 54/250, Loss: 0.0195\n",
      "Epoch 181/200, Iteration 55/250, Loss: 0.0115\n",
      "Epoch 181/200, Iteration 56/250, Loss: 0.0257\n",
      "Epoch 181/200, Iteration 57/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 58/250, Loss: 0.0162\n",
      "Epoch 181/200, Iteration 59/250, Loss: 0.0138\n",
      "Epoch 181/200, Iteration 60/250, Loss: 0.0160\n",
      "Epoch 181/200, Iteration 61/250, Loss: 0.0098\n",
      "Epoch 181/200, Iteration 62/250, Loss: 0.0144\n",
      "Epoch 181/200, Iteration 63/250, Loss: 0.0075\n",
      "Epoch 181/200, Iteration 64/250, Loss: 0.0164\n",
      "Epoch 181/200, Iteration 65/250, Loss: 0.0151\n",
      "Epoch 181/200, Iteration 66/250, Loss: 0.0179\n",
      "Epoch 181/200, Iteration 67/250, Loss: 0.0207\n",
      "Epoch 181/200, Iteration 68/250, Loss: 0.0096\n",
      "Epoch 181/200, Iteration 69/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 70/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 71/250, Loss: 0.0102\n",
      "Epoch 181/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 181/200, Iteration 73/250, Loss: 0.0144\n",
      "Epoch 181/200, Iteration 74/250, Loss: 0.0329\n",
      "Epoch 181/200, Iteration 75/250, Loss: 0.0086\n",
      "Epoch 181/200, Iteration 76/250, Loss: 0.0139\n",
      "Epoch 181/200, Iteration 77/250, Loss: 0.0160\n",
      "Epoch 181/200, Iteration 78/250, Loss: 0.0170\n",
      "Epoch 181/200, Iteration 79/250, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 80/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 81/250, Loss: 0.0103\n",
      "Epoch 181/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 83/250, Loss: 0.0277\n",
      "Epoch 181/200, Iteration 84/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 86/250, Loss: 0.0130\n",
      "Epoch 181/200, Iteration 87/250, Loss: 0.0080\n",
      "Epoch 181/200, Iteration 88/250, Loss: 0.0092\n",
      "Epoch 181/200, Iteration 89/250, Loss: 0.0113\n",
      "Epoch 181/200, Iteration 90/250, Loss: 0.0077\n",
      "Epoch 181/200, Iteration 91/250, Loss: 0.0159\n",
      "Epoch 181/200, Iteration 92/250, Loss: 0.0247\n",
      "Epoch 181/200, Iteration 93/250, Loss: 0.0108\n",
      "Epoch 181/200, Iteration 94/250, Loss: 0.0229\n",
      "Epoch 181/200, Iteration 95/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 96/250, Loss: 0.0165\n",
      "Epoch 181/200, Iteration 97/250, Loss: 0.0358\n",
      "Epoch 181/200, Iteration 98/250, Loss: 0.0210\n",
      "Epoch 181/200, Iteration 99/250, Loss: 0.0058\n",
      "Epoch 181/200, Iteration 100/250, Loss: 0.0187\n",
      "Epoch 181/200, Iteration 101/250, Loss: 0.0209\n",
      "Epoch 181/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 181/200, Iteration 103/250, Loss: 0.0074\n",
      "Epoch 181/200, Iteration 104/250, Loss: 0.0121\n",
      "Epoch 181/200, Iteration 105/250, Loss: 0.0226\n",
      "Epoch 181/200, Iteration 106/250, Loss: 0.0116\n",
      "Epoch 181/200, Iteration 107/250, Loss: 0.0477\n",
      "Epoch 181/200, Iteration 108/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 109/250, Loss: 0.0060\n",
      "Epoch 181/200, Iteration 110/250, Loss: 0.0119\n",
      "Epoch 181/200, Iteration 111/250, Loss: 0.0073\n",
      "Epoch 181/200, Iteration 112/250, Loss: 0.0152\n",
      "Epoch 181/200, Iteration 113/250, Loss: 0.0313\n",
      "Epoch 181/200, Iteration 114/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 115/250, Loss: 0.0139\n",
      "Epoch 181/200, Iteration 116/250, Loss: 0.0110\n",
      "Epoch 181/200, Iteration 117/250, Loss: 0.0177\n",
      "Epoch 181/200, Iteration 118/250, Loss: 0.0141\n",
      "Epoch 181/200, Iteration 119/250, Loss: 0.0220\n",
      "Epoch 181/200, Iteration 120/250, Loss: 0.0219\n",
      "Epoch 181/200, Iteration 121/250, Loss: 0.0456\n",
      "Epoch 181/200, Iteration 122/250, Loss: 0.0155\n",
      "Epoch 181/200, Iteration 123/250, Loss: 0.0167\n",
      "Epoch 181/200, Iteration 124/250, Loss: 0.0201\n",
      "Epoch 181/200, Iteration 125/250, Loss: 0.0097\n",
      "Epoch 181/200, Iteration 126/250, Loss: 0.0154\n",
      "Epoch 181/200, Iteration 127/250, Loss: 0.0164\n",
      "Epoch 181/200, Iteration 128/250, Loss: 0.0233\n",
      "Epoch 181/200, Iteration 129/250, Loss: 0.0197\n",
      "Epoch 181/200, Iteration 130/250, Loss: 0.0119\n",
      "Epoch 181/200, Iteration 131/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 132/250, Loss: 0.0173\n",
      "Epoch 181/200, Iteration 133/250, Loss: 0.0159\n",
      "Epoch 181/200, Iteration 134/250, Loss: 0.0165\n",
      "Epoch 181/200, Iteration 135/250, Loss: 0.0192\n",
      "Epoch 181/200, Iteration 136/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 137/250, Loss: 0.0201\n",
      "Epoch 181/200, Iteration 138/250, Loss: 0.0149\n",
      "Epoch 181/200, Iteration 139/250, Loss: 0.0080\n",
      "Epoch 181/200, Iteration 140/250, Loss: 0.0131\n",
      "Epoch 181/200, Iteration 141/250, Loss: 0.0126\n",
      "Epoch 181/200, Iteration 142/250, Loss: 0.0221\n",
      "Epoch 181/200, Iteration 143/250, Loss: 0.0133\n",
      "Epoch 181/200, Iteration 144/250, Loss: 0.0096\n",
      "Epoch 181/200, Iteration 145/250, Loss: 0.0422\n",
      "Epoch 181/200, Iteration 146/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 147/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 148/250, Loss: 0.0065\n",
      "Epoch 181/200, Iteration 149/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 150/250, Loss: 0.0126\n",
      "Epoch 181/200, Iteration 151/250, Loss: 0.0152\n",
      "Epoch 181/200, Iteration 152/250, Loss: 0.0268\n",
      "Epoch 181/200, Iteration 153/250, Loss: 0.0319\n",
      "Epoch 181/200, Iteration 154/250, Loss: 0.0071\n",
      "Epoch 181/200, Iteration 155/250, Loss: 0.0221\n",
      "Epoch 181/200, Iteration 156/250, Loss: 0.0183\n",
      "Epoch 181/200, Iteration 157/250, Loss: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200, Iteration 158/250, Loss: 0.0077\n",
      "Epoch 181/200, Iteration 159/250, Loss: 0.0172\n",
      "Epoch 181/200, Iteration 160/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 162/250, Loss: 0.0221\n",
      "Epoch 181/200, Iteration 163/250, Loss: 0.0388\n",
      "Epoch 181/200, Iteration 164/250, Loss: 0.0067\n",
      "Epoch 181/200, Iteration 165/250, Loss: 0.0115\n",
      "Epoch 181/200, Iteration 166/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 167/250, Loss: 0.0351\n",
      "Epoch 181/200, Iteration 168/250, Loss: 0.0168\n",
      "Epoch 181/200, Iteration 169/250, Loss: 0.0088\n",
      "Epoch 181/200, Iteration 170/250, Loss: 0.0153\n",
      "Epoch 181/200, Iteration 171/250, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 172/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 173/250, Loss: 0.0460\n",
      "Epoch 181/200, Iteration 174/250, Loss: 0.0162\n",
      "Epoch 181/200, Iteration 175/250, Loss: 0.0250\n",
      "Epoch 181/200, Iteration 176/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 177/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 178/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 179/250, Loss: 0.0280\n",
      "Epoch 181/200, Iteration 180/250, Loss: 0.0079\n",
      "Epoch 181/200, Iteration 181/250, Loss: 0.0182\n",
      "Epoch 181/200, Iteration 182/250, Loss: 0.0216\n",
      "Epoch 181/200, Iteration 183/250, Loss: 0.0315\n",
      "Epoch 181/200, Iteration 184/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 185/250, Loss: 0.0123\n",
      "Epoch 181/200, Iteration 186/250, Loss: 0.0151\n",
      "Epoch 181/200, Iteration 187/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 188/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 189/250, Loss: 0.0112\n",
      "Epoch 181/200, Iteration 190/250, Loss: 0.0158\n",
      "Epoch 181/200, Iteration 191/250, Loss: 0.0204\n",
      "Epoch 181/200, Iteration 192/250, Loss: 0.0140\n",
      "Epoch 181/200, Iteration 193/250, Loss: 0.0077\n",
      "Epoch 181/200, Iteration 194/250, Loss: 0.0198\n",
      "Epoch 181/200, Iteration 195/250, Loss: 0.0160\n",
      "Epoch 181/200, Iteration 196/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 197/250, Loss: 0.0097\n",
      "Epoch 181/200, Iteration 198/250, Loss: 0.0066\n",
      "Epoch 181/200, Iteration 199/250, Loss: 0.0102\n",
      "Epoch 181/200, Iteration 200/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 201/250, Loss: 0.0216\n",
      "Epoch 181/200, Iteration 202/250, Loss: 0.0096\n",
      "Epoch 181/200, Iteration 203/250, Loss: 0.0292\n",
      "Epoch 181/200, Iteration 204/250, Loss: 0.0178\n",
      "Epoch 181/200, Iteration 205/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 206/250, Loss: 0.0163\n",
      "Epoch 181/200, Iteration 207/250, Loss: 0.0119\n",
      "Epoch 181/200, Iteration 208/250, Loss: 0.0293\n",
      "Epoch 181/200, Iteration 209/250, Loss: 0.0151\n",
      "Epoch 181/200, Iteration 210/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 211/250, Loss: 0.0104\n",
      "Epoch 181/200, Iteration 212/250, Loss: 0.0109\n",
      "Epoch 181/200, Iteration 213/250, Loss: 0.0137\n",
      "Epoch 181/200, Iteration 214/250, Loss: 0.0073\n",
      "Epoch 181/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 216/250, Loss: 0.0177\n",
      "Epoch 181/200, Iteration 217/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 218/250, Loss: 0.0106\n",
      "Epoch 181/200, Iteration 219/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 220/250, Loss: 0.0157\n",
      "Epoch 181/200, Iteration 221/250, Loss: 0.0110\n",
      "Epoch 181/200, Iteration 222/250, Loss: 0.0150\n",
      "Epoch 181/200, Iteration 223/250, Loss: 0.0244\n",
      "Epoch 181/200, Iteration 224/250, Loss: 0.0071\n",
      "Epoch 181/200, Iteration 225/250, Loss: 0.0072\n",
      "Epoch 181/200, Iteration 226/250, Loss: 0.0175\n",
      "Epoch 181/200, Iteration 227/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 228/250, Loss: 0.0124\n",
      "Epoch 181/200, Iteration 229/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 230/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 231/250, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 232/250, Loss: 0.0427\n",
      "Epoch 181/200, Iteration 233/250, Loss: 0.0256\n",
      "Epoch 181/200, Iteration 234/250, Loss: 0.0271\n",
      "Epoch 181/200, Iteration 235/250, Loss: 0.0206\n",
      "Epoch 181/200, Iteration 236/250, Loss: 0.0101\n",
      "Epoch 181/200, Iteration 237/250, Loss: 0.0119\n",
      "Epoch 181/200, Iteration 238/250, Loss: 0.0234\n",
      "Epoch 181/200, Iteration 239/250, Loss: 0.0180\n",
      "Epoch 181/200, Iteration 240/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 181/200, Iteration 242/250, Loss: 0.0108\n",
      "Epoch 181/200, Iteration 243/250, Loss: 0.0163\n",
      "Epoch 181/200, Iteration 244/250, Loss: 0.0118\n",
      "Epoch 181/200, Iteration 245/250, Loss: 0.0107\n",
      "Epoch 181/200, Iteration 246/250, Loss: 0.0183\n",
      "Epoch 181/200, Iteration 247/250, Loss: 0.0263\n",
      "Epoch 181/200, Iteration 248/250, Loss: 0.0117\n",
      "Epoch 181/200, Iteration 249/250, Loss: 0.0332\n",
      "Epoch 181/200, Iteration 250/250, Loss: 0.0112\n",
      "Train Error: \n",
      " Accuracy: 91.79%, Avg loss: 0.006181, MRE: 0.625597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.85%, Avg loss: 0.006278, MRE: 1.042685 \n",
      "\n",
      "Epoch 182/200, Iteration 1/250, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 2/250, Loss: 0.0092\n",
      "Epoch 182/200, Iteration 3/250, Loss: 0.0315\n",
      "Epoch 182/200, Iteration 4/250, Loss: 0.0211\n",
      "Epoch 182/200, Iteration 5/250, Loss: 0.0199\n",
      "Epoch 182/200, Iteration 6/250, Loss: 0.0155\n",
      "Epoch 182/200, Iteration 7/250, Loss: 0.0092\n",
      "Epoch 182/200, Iteration 8/250, Loss: 0.0186\n",
      "Epoch 182/200, Iteration 9/250, Loss: 0.0257\n",
      "Epoch 182/200, Iteration 10/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 11/250, Loss: 0.0180\n",
      "Epoch 182/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 182/200, Iteration 13/250, Loss: 0.0275\n",
      "Epoch 182/200, Iteration 14/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 15/250, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 16/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 17/250, Loss: 0.0182\n",
      "Epoch 182/200, Iteration 18/250, Loss: 0.0154\n",
      "Epoch 182/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 182/200, Iteration 20/250, Loss: 0.0050\n",
      "Epoch 182/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 182/200, Iteration 22/250, Loss: 0.0215\n",
      "Epoch 182/200, Iteration 23/250, Loss: 0.0171\n",
      "Epoch 182/200, Iteration 24/250, Loss: 0.0458\n",
      "Epoch 182/200, Iteration 25/250, Loss: 0.0182\n",
      "Epoch 182/200, Iteration 26/250, Loss: 0.0133\n",
      "Epoch 182/200, Iteration 27/250, Loss: 0.0079\n",
      "Epoch 182/200, Iteration 28/250, Loss: 0.0182\n",
      "Epoch 182/200, Iteration 29/250, Loss: 0.0215\n",
      "Epoch 182/200, Iteration 30/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 31/250, Loss: 0.0287\n",
      "Epoch 182/200, Iteration 32/250, Loss: 0.0092\n",
      "Epoch 182/200, Iteration 33/250, Loss: 0.0298\n",
      "Epoch 182/200, Iteration 34/250, Loss: 0.0078\n",
      "Epoch 182/200, Iteration 35/250, Loss: 0.0250\n",
      "Epoch 182/200, Iteration 36/250, Loss: 0.0075\n",
      "Epoch 182/200, Iteration 37/250, Loss: 0.0242\n",
      "Epoch 182/200, Iteration 38/250, Loss: 0.0071\n",
      "Epoch 182/200, Iteration 39/250, Loss: 0.0198\n",
      "Epoch 182/200, Iteration 40/250, Loss: 0.0301\n",
      "Epoch 182/200, Iteration 41/250, Loss: 0.0085\n",
      "Epoch 182/200, Iteration 42/250, Loss: 0.0062\n",
      "Epoch 182/200, Iteration 43/250, Loss: 0.0129\n",
      "Epoch 182/200, Iteration 44/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 45/250, Loss: 0.0083\n",
      "Epoch 182/200, Iteration 46/250, Loss: 0.0155\n",
      "Epoch 182/200, Iteration 47/250, Loss: 0.0377\n",
      "Epoch 182/200, Iteration 48/250, Loss: 0.0122\n",
      "Epoch 182/200, Iteration 49/250, Loss: 0.0370\n",
      "Epoch 182/200, Iteration 50/250, Loss: 0.0306\n",
      "Epoch 182/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 182/200, Iteration 52/250, Loss: 0.0167\n",
      "Epoch 182/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 54/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 182/200, Iteration 56/250, Loss: 0.0107\n",
      "Epoch 182/200, Iteration 57/250, Loss: 0.0090\n",
      "Epoch 182/200, Iteration 58/250, Loss: 0.0101\n",
      "Epoch 182/200, Iteration 59/250, Loss: 0.0116\n",
      "Epoch 182/200, Iteration 60/250, Loss: 0.0123\n",
      "Epoch 182/200, Iteration 61/250, Loss: 0.0050\n",
      "Epoch 182/200, Iteration 62/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 63/250, Loss: 0.0451\n",
      "Epoch 182/200, Iteration 64/250, Loss: 0.0292\n",
      "Epoch 182/200, Iteration 65/250, Loss: 0.0392\n",
      "Epoch 182/200, Iteration 66/250, Loss: 0.0237\n",
      "Epoch 182/200, Iteration 67/250, Loss: 0.0284\n",
      "Epoch 182/200, Iteration 68/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 69/250, Loss: 0.0190\n",
      "Epoch 182/200, Iteration 70/250, Loss: 0.0142\n",
      "Epoch 182/200, Iteration 71/250, Loss: 0.0236\n",
      "Epoch 182/200, Iteration 72/250, Loss: 0.0074\n",
      "Epoch 182/200, Iteration 73/250, Loss: 0.0181\n",
      "Epoch 182/200, Iteration 74/250, Loss: 0.0100\n",
      "Epoch 182/200, Iteration 75/250, Loss: 0.0119\n",
      "Epoch 182/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 182/200, Iteration 77/250, Loss: 0.0142\n",
      "Epoch 182/200, Iteration 78/250, Loss: 0.0239\n",
      "Epoch 182/200, Iteration 79/250, Loss: 0.0097\n",
      "Epoch 182/200, Iteration 80/250, Loss: 0.0174\n",
      "Epoch 182/200, Iteration 81/250, Loss: 0.0216\n",
      "Epoch 182/200, Iteration 82/250, Loss: 0.0227\n",
      "Epoch 182/200, Iteration 83/250, Loss: 0.0099\n",
      "Epoch 182/200, Iteration 84/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 85/250, Loss: 0.0130\n",
      "Epoch 182/200, Iteration 86/250, Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/200, Iteration 87/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 88/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 89/250, Loss: 0.0223\n",
      "Epoch 182/200, Iteration 90/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 91/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 92/250, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 93/250, Loss: 0.0175\n",
      "Epoch 182/200, Iteration 94/250, Loss: 0.0165\n",
      "Epoch 182/200, Iteration 95/250, Loss: 0.0089\n",
      "Epoch 182/200, Iteration 96/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 97/250, Loss: 0.0127\n",
      "Epoch 182/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 182/200, Iteration 99/250, Loss: 0.0139\n",
      "Epoch 182/200, Iteration 100/250, Loss: 0.0075\n",
      "Epoch 182/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 182/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 182/200, Iteration 103/250, Loss: 0.0228\n",
      "Epoch 182/200, Iteration 104/250, Loss: 0.0107\n",
      "Epoch 182/200, Iteration 105/250, Loss: 0.0113\n",
      "Epoch 182/200, Iteration 106/250, Loss: 0.0059\n",
      "Epoch 182/200, Iteration 107/250, Loss: 0.0300\n",
      "Epoch 182/200, Iteration 108/250, Loss: 0.0270\n",
      "Epoch 182/200, Iteration 109/250, Loss: 0.0057\n",
      "Epoch 182/200, Iteration 110/250, Loss: 0.0314\n",
      "Epoch 182/200, Iteration 111/250, Loss: 0.0247\n",
      "Epoch 182/200, Iteration 112/250, Loss: 0.0113\n",
      "Epoch 182/200, Iteration 113/250, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 114/250, Loss: 0.0083\n",
      "Epoch 182/200, Iteration 115/250, Loss: 0.0084\n",
      "Epoch 182/200, Iteration 116/250, Loss: 0.0059\n",
      "Epoch 182/200, Iteration 117/250, Loss: 0.0053\n",
      "Epoch 182/200, Iteration 118/250, Loss: 0.0174\n",
      "Epoch 182/200, Iteration 119/250, Loss: 0.0080\n",
      "Epoch 182/200, Iteration 120/250, Loss: 0.0177\n",
      "Epoch 182/200, Iteration 121/250, Loss: 0.0150\n",
      "Epoch 182/200, Iteration 122/250, Loss: 0.0091\n",
      "Epoch 182/200, Iteration 123/250, Loss: 0.0110\n",
      "Epoch 182/200, Iteration 124/250, Loss: 0.0276\n",
      "Epoch 182/200, Iteration 125/250, Loss: 0.0162\n",
      "Epoch 182/200, Iteration 126/250, Loss: 0.0267\n",
      "Epoch 182/200, Iteration 127/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 128/250, Loss: 0.0149\n",
      "Epoch 182/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 130/250, Loss: 0.0333\n",
      "Epoch 182/200, Iteration 131/250, Loss: 0.0113\n",
      "Epoch 182/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 182/200, Iteration 133/250, Loss: 0.0240\n",
      "Epoch 182/200, Iteration 134/250, Loss: 0.0167\n",
      "Epoch 182/200, Iteration 135/250, Loss: 0.0278\n",
      "Epoch 182/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 182/200, Iteration 137/250, Loss: 0.0262\n",
      "Epoch 182/200, Iteration 138/250, Loss: 0.0318\n",
      "Epoch 182/200, Iteration 139/250, Loss: 0.0258\n",
      "Epoch 182/200, Iteration 140/250, Loss: 0.0150\n",
      "Epoch 182/200, Iteration 141/250, Loss: 0.0160\n",
      "Epoch 182/200, Iteration 142/250, Loss: 0.0135\n",
      "Epoch 182/200, Iteration 143/250, Loss: 0.0149\n",
      "Epoch 182/200, Iteration 144/250, Loss: 0.0193\n",
      "Epoch 182/200, Iteration 145/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 182/200, Iteration 147/250, Loss: 0.0197\n",
      "Epoch 182/200, Iteration 148/250, Loss: 0.0244\n",
      "Epoch 182/200, Iteration 149/250, Loss: 0.0124\n",
      "Epoch 182/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 151/250, Loss: 0.0143\n",
      "Epoch 182/200, Iteration 152/250, Loss: 0.0400\n",
      "Epoch 182/200, Iteration 153/250, Loss: 0.0208\n",
      "Epoch 182/200, Iteration 154/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 155/250, Loss: 0.0147\n",
      "Epoch 182/200, Iteration 156/250, Loss: 0.0201\n",
      "Epoch 182/200, Iteration 157/250, Loss: 0.0086\n",
      "Epoch 182/200, Iteration 158/250, Loss: 0.0108\n",
      "Epoch 182/200, Iteration 159/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 161/250, Loss: 0.0141\n",
      "Epoch 182/200, Iteration 162/250, Loss: 0.0125\n",
      "Epoch 182/200, Iteration 163/250, Loss: 0.0072\n",
      "Epoch 182/200, Iteration 164/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 165/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 166/250, Loss: 0.0469\n",
      "Epoch 182/200, Iteration 167/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 168/250, Loss: 0.0145\n",
      "Epoch 182/200, Iteration 169/250, Loss: 0.0172\n",
      "Epoch 182/200, Iteration 170/250, Loss: 0.0181\n",
      "Epoch 182/200, Iteration 171/250, Loss: 0.0080\n",
      "Epoch 182/200, Iteration 172/250, Loss: 0.0193\n",
      "Epoch 182/200, Iteration 173/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 174/250, Loss: 0.0200\n",
      "Epoch 182/200, Iteration 175/250, Loss: 0.0101\n",
      "Epoch 182/200, Iteration 176/250, Loss: 0.0318\n",
      "Epoch 182/200, Iteration 177/250, Loss: 0.0074\n",
      "Epoch 182/200, Iteration 178/250, Loss: 0.0169\n",
      "Epoch 182/200, Iteration 179/250, Loss: 0.0143\n",
      "Epoch 182/200, Iteration 180/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 181/250, Loss: 0.0694\n",
      "Epoch 182/200, Iteration 182/250, Loss: 0.0106\n",
      "Epoch 182/200, Iteration 183/250, Loss: 0.0283\n",
      "Epoch 182/200, Iteration 184/250, Loss: 0.0428\n",
      "Epoch 182/200, Iteration 185/250, Loss: 0.0069\n",
      "Epoch 182/200, Iteration 186/250, Loss: 0.0243\n",
      "Epoch 182/200, Iteration 187/250, Loss: 0.0195\n",
      "Epoch 182/200, Iteration 188/250, Loss: 0.0300\n",
      "Epoch 182/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 182/200, Iteration 190/250, Loss: 0.0123\n",
      "Epoch 182/200, Iteration 191/250, Loss: 0.0129\n",
      "Epoch 182/200, Iteration 192/250, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 194/250, Loss: 0.0189\n",
      "Epoch 182/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 182/200, Iteration 196/250, Loss: 0.0070\n",
      "Epoch 182/200, Iteration 197/250, Loss: 0.0210\n",
      "Epoch 182/200, Iteration 198/250, Loss: 0.0112\n",
      "Epoch 182/200, Iteration 199/250, Loss: 0.0114\n",
      "Epoch 182/200, Iteration 200/250, Loss: 0.0305\n",
      "Epoch 182/200, Iteration 201/250, Loss: 0.0225\n",
      "Epoch 182/200, Iteration 202/250, Loss: 0.0165\n",
      "Epoch 182/200, Iteration 203/250, Loss: 0.0117\n",
      "Epoch 182/200, Iteration 204/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 182/200, Iteration 206/250, Loss: 0.0105\n",
      "Epoch 182/200, Iteration 207/250, Loss: 0.0113\n",
      "Epoch 182/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 209/250, Loss: 0.0114\n",
      "Epoch 182/200, Iteration 210/250, Loss: 0.0158\n",
      "Epoch 182/200, Iteration 211/250, Loss: 0.0304\n",
      "Epoch 182/200, Iteration 212/250, Loss: 0.0221\n",
      "Epoch 182/200, Iteration 213/250, Loss: 0.0225\n",
      "Epoch 182/200, Iteration 214/250, Loss: 0.0110\n",
      "Epoch 182/200, Iteration 215/250, Loss: 0.0219\n",
      "Epoch 182/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 182/200, Iteration 217/250, Loss: 0.0097\n",
      "Epoch 182/200, Iteration 218/250, Loss: 0.0094\n",
      "Epoch 182/200, Iteration 219/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 220/250, Loss: 0.0079\n",
      "Epoch 182/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 182/200, Iteration 222/250, Loss: 0.0187\n",
      "Epoch 182/200, Iteration 223/250, Loss: 0.0068\n",
      "Epoch 182/200, Iteration 224/250, Loss: 0.0131\n",
      "Epoch 182/200, Iteration 225/250, Loss: 0.0119\n",
      "Epoch 182/200, Iteration 226/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 227/250, Loss: 0.0378\n",
      "Epoch 182/200, Iteration 228/250, Loss: 0.0170\n",
      "Epoch 182/200, Iteration 229/250, Loss: 0.0161\n",
      "Epoch 182/200, Iteration 230/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 231/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 232/250, Loss: 0.0092\n",
      "Epoch 182/200, Iteration 233/250, Loss: 0.0189\n",
      "Epoch 182/200, Iteration 234/250, Loss: 0.0133\n",
      "Epoch 182/200, Iteration 235/250, Loss: 0.0244\n",
      "Epoch 182/200, Iteration 236/250, Loss: 0.0094\n",
      "Epoch 182/200, Iteration 237/250, Loss: 0.0283\n",
      "Epoch 182/200, Iteration 238/250, Loss: 0.0155\n",
      "Epoch 182/200, Iteration 239/250, Loss: 0.0088\n",
      "Epoch 182/200, Iteration 240/250, Loss: 0.0197\n",
      "Epoch 182/200, Iteration 241/250, Loss: 0.0052\n",
      "Epoch 182/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 243/250, Loss: 0.0226\n",
      "Epoch 182/200, Iteration 244/250, Loss: 0.0078\n",
      "Epoch 182/200, Iteration 245/250, Loss: 0.0073\n",
      "Epoch 182/200, Iteration 246/250, Loss: 0.0386\n",
      "Epoch 182/200, Iteration 247/250, Loss: 0.0204\n",
      "Epoch 182/200, Iteration 248/250, Loss: 0.0141\n",
      "Epoch 182/200, Iteration 249/250, Loss: 0.0186\n",
      "Epoch 182/200, Iteration 250/250, Loss: 0.0106\n",
      "Train Error: \n",
      " Accuracy: 94.79%, Avg loss: 0.005822, MRE: 0.616823 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.005840, MRE: 0.954397 \n",
      "\n",
      "Epoch 183/200, Iteration 1/250, Loss: 0.0136\n",
      "Epoch 183/200, Iteration 2/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 3/250, Loss: 0.0103\n",
      "Epoch 183/200, Iteration 4/250, Loss: 0.0102\n",
      "Epoch 183/200, Iteration 5/250, Loss: 0.0153\n",
      "Epoch 183/200, Iteration 6/250, Loss: 0.0059\n",
      "Epoch 183/200, Iteration 7/250, Loss: 0.0162\n",
      "Epoch 183/200, Iteration 8/250, Loss: 0.0221\n",
      "Epoch 183/200, Iteration 9/250, Loss: 0.0060\n",
      "Epoch 183/200, Iteration 10/250, Loss: 0.0182\n",
      "Epoch 183/200, Iteration 11/250, Loss: 0.0190\n",
      "Epoch 183/200, Iteration 12/250, Loss: 0.0164\n",
      "Epoch 183/200, Iteration 13/250, Loss: 0.0049\n",
      "Epoch 183/200, Iteration 14/250, Loss: 0.0112\n",
      "Epoch 183/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 183/200, Iteration 16/250, Loss: 0.0094\n",
      "Epoch 183/200, Iteration 17/250, Loss: 0.0106\n",
      "Epoch 183/200, Iteration 18/250, Loss: 0.0073\n",
      "Epoch 183/200, Iteration 19/250, Loss: 0.0143\n",
      "Epoch 183/200, Iteration 20/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 21/250, Loss: 0.0394\n",
      "Epoch 183/200, Iteration 22/250, Loss: 0.0271\n",
      "Epoch 183/200, Iteration 23/250, Loss: 0.0115\n",
      "Epoch 183/200, Iteration 24/250, Loss: 0.0074\n",
      "Epoch 183/200, Iteration 25/250, Loss: 0.0105\n",
      "Epoch 183/200, Iteration 26/250, Loss: 0.0273\n",
      "Epoch 183/200, Iteration 27/250, Loss: 0.0129\n",
      "Epoch 183/200, Iteration 28/250, Loss: 0.0127\n",
      "Epoch 183/200, Iteration 29/250, Loss: 0.0134\n",
      "Epoch 183/200, Iteration 30/250, Loss: 0.0363\n",
      "Epoch 183/200, Iteration 31/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 183/200, Iteration 33/250, Loss: 0.0120\n",
      "Epoch 183/200, Iteration 34/250, Loss: 0.0069\n",
      "Epoch 183/200, Iteration 35/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 36/250, Loss: 0.0073\n",
      "Epoch 183/200, Iteration 37/250, Loss: 0.0088\n",
      "Epoch 183/200, Iteration 38/250, Loss: 0.0156\n",
      "Epoch 183/200, Iteration 39/250, Loss: 0.0178\n",
      "Epoch 183/200, Iteration 40/250, Loss: 0.0145\n",
      "Epoch 183/200, Iteration 41/250, Loss: 0.0066\n",
      "Epoch 183/200, Iteration 42/250, Loss: 0.0149\n",
      "Epoch 183/200, Iteration 43/250, Loss: 0.0087\n",
      "Epoch 183/200, Iteration 44/250, Loss: 0.0134\n",
      "Epoch 183/200, Iteration 45/250, Loss: 0.0087\n",
      "Epoch 183/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 47/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200, Iteration 48/250, Loss: 0.0216\n",
      "Epoch 183/200, Iteration 49/250, Loss: 0.0121\n",
      "Epoch 183/200, Iteration 50/250, Loss: 0.0137\n",
      "Epoch 183/200, Iteration 51/250, Loss: 0.0076\n",
      "Epoch 183/200, Iteration 52/250, Loss: 0.0121\n",
      "Epoch 183/200, Iteration 53/250, Loss: 0.0109\n",
      "Epoch 183/200, Iteration 54/250, Loss: 0.0100\n",
      "Epoch 183/200, Iteration 55/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 56/250, Loss: 0.0124\n",
      "Epoch 183/200, Iteration 57/250, Loss: 0.0284\n",
      "Epoch 183/200, Iteration 58/250, Loss: 0.0160\n",
      "Epoch 183/200, Iteration 59/250, Loss: 0.0186\n",
      "Epoch 183/200, Iteration 60/250, Loss: 0.0137\n",
      "Epoch 183/200, Iteration 61/250, Loss: 0.0066\n",
      "Epoch 183/200, Iteration 62/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 63/250, Loss: 0.0150\n",
      "Epoch 183/200, Iteration 64/250, Loss: 0.0117\n",
      "Epoch 183/200, Iteration 65/250, Loss: 0.0093\n",
      "Epoch 183/200, Iteration 66/250, Loss: 0.0132\n",
      "Epoch 183/200, Iteration 67/250, Loss: 0.0241\n",
      "Epoch 183/200, Iteration 68/250, Loss: 0.0074\n",
      "Epoch 183/200, Iteration 69/250, Loss: 0.0167\n",
      "Epoch 183/200, Iteration 70/250, Loss: 0.0203\n",
      "Epoch 183/200, Iteration 71/250, Loss: 0.0106\n",
      "Epoch 183/200, Iteration 72/250, Loss: 0.0300\n",
      "Epoch 183/200, Iteration 73/250, Loss: 0.0144\n",
      "Epoch 183/200, Iteration 74/250, Loss: 0.0151\n",
      "Epoch 183/200, Iteration 75/250, Loss: 0.0099\n",
      "Epoch 183/200, Iteration 76/250, Loss: 0.0110\n",
      "Epoch 183/200, Iteration 77/250, Loss: 0.0138\n",
      "Epoch 183/200, Iteration 78/250, Loss: 0.0084\n",
      "Epoch 183/200, Iteration 79/250, Loss: 0.0069\n",
      "Epoch 183/200, Iteration 80/250, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 81/250, Loss: 0.0076\n",
      "Epoch 183/200, Iteration 82/250, Loss: 0.0181\n",
      "Epoch 183/200, Iteration 83/250, Loss: 0.0326\n",
      "Epoch 183/200, Iteration 84/250, Loss: 0.0126\n",
      "Epoch 183/200, Iteration 85/250, Loss: 0.0229\n",
      "Epoch 183/200, Iteration 86/250, Loss: 0.0134\n",
      "Epoch 183/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 183/200, Iteration 88/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 89/250, Loss: 0.0242\n",
      "Epoch 183/200, Iteration 90/250, Loss: 0.0117\n",
      "Epoch 183/200, Iteration 91/250, Loss: 0.0056\n",
      "Epoch 183/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 93/250, Loss: 0.0324\n",
      "Epoch 183/200, Iteration 94/250, Loss: 0.0095\n",
      "Epoch 183/200, Iteration 95/250, Loss: 0.0147\n",
      "Epoch 183/200, Iteration 96/250, Loss: 0.0369\n",
      "Epoch 183/200, Iteration 97/250, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 98/250, Loss: 0.0263\n",
      "Epoch 183/200, Iteration 99/250, Loss: 0.0077\n",
      "Epoch 183/200, Iteration 100/250, Loss: 0.0229\n",
      "Epoch 183/200, Iteration 101/250, Loss: 0.0138\n",
      "Epoch 183/200, Iteration 102/250, Loss: 0.0070\n",
      "Epoch 183/200, Iteration 103/250, Loss: 0.0114\n",
      "Epoch 183/200, Iteration 104/250, Loss: 0.0169\n",
      "Epoch 183/200, Iteration 105/250, Loss: 0.0247\n",
      "Epoch 183/200, Iteration 106/250, Loss: 0.0335\n",
      "Epoch 183/200, Iteration 107/250, Loss: 0.0194\n",
      "Epoch 183/200, Iteration 108/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 109/250, Loss: 0.0170\n",
      "Epoch 183/200, Iteration 110/250, Loss: 0.0207\n",
      "Epoch 183/200, Iteration 111/250, Loss: 0.0136\n",
      "Epoch 183/200, Iteration 112/250, Loss: 0.0161\n",
      "Epoch 183/200, Iteration 113/250, Loss: 0.0194\n",
      "Epoch 183/200, Iteration 114/250, Loss: 0.0164\n",
      "Epoch 183/200, Iteration 115/250, Loss: 0.0193\n",
      "Epoch 183/200, Iteration 116/250, Loss: 0.0114\n",
      "Epoch 183/200, Iteration 117/250, Loss: 0.0173\n",
      "Epoch 183/200, Iteration 118/250, Loss: 0.0148\n",
      "Epoch 183/200, Iteration 119/250, Loss: 0.0069\n",
      "Epoch 183/200, Iteration 120/250, Loss: 0.0081\n",
      "Epoch 183/200, Iteration 121/250, Loss: 0.0170\n",
      "Epoch 183/200, Iteration 122/250, Loss: 0.0179\n",
      "Epoch 183/200, Iteration 123/250, Loss: 0.0303\n",
      "Epoch 183/200, Iteration 124/250, Loss: 0.0149\n",
      "Epoch 183/200, Iteration 125/250, Loss: 0.0096\n",
      "Epoch 183/200, Iteration 126/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 127/250, Loss: 0.0100\n",
      "Epoch 183/200, Iteration 128/250, Loss: 0.0066\n",
      "Epoch 183/200, Iteration 129/250, Loss: 0.0154\n",
      "Epoch 183/200, Iteration 130/250, Loss: 0.0212\n",
      "Epoch 183/200, Iteration 131/250, Loss: 0.0275\n",
      "Epoch 183/200, Iteration 132/250, Loss: 0.0081\n",
      "Epoch 183/200, Iteration 133/250, Loss: 0.0081\n",
      "Epoch 183/200, Iteration 134/250, Loss: 0.0085\n",
      "Epoch 183/200, Iteration 135/250, Loss: 0.0107\n",
      "Epoch 183/200, Iteration 136/250, Loss: 0.0337\n",
      "Epoch 183/200, Iteration 137/250, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 138/250, Loss: 0.0207\n",
      "Epoch 183/200, Iteration 139/250, Loss: 0.0158\n",
      "Epoch 183/200, Iteration 140/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 141/250, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 142/250, Loss: 0.0128\n",
      "Epoch 183/200, Iteration 143/250, Loss: 0.0174\n",
      "Epoch 183/200, Iteration 144/250, Loss: 0.0143\n",
      "Epoch 183/200, Iteration 145/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 146/250, Loss: 0.0167\n",
      "Epoch 183/200, Iteration 147/250, Loss: 0.0193\n",
      "Epoch 183/200, Iteration 148/250, Loss: 0.0260\n",
      "Epoch 183/200, Iteration 149/250, Loss: 0.0280\n",
      "Epoch 183/200, Iteration 150/250, Loss: 0.0089\n",
      "Epoch 183/200, Iteration 151/250, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 152/250, Loss: 0.0165\n",
      "Epoch 183/200, Iteration 153/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 154/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 155/250, Loss: 0.0104\n",
      "Epoch 183/200, Iteration 156/250, Loss: 0.0077\n",
      "Epoch 183/200, Iteration 157/250, Loss: 0.0349\n",
      "Epoch 183/200, Iteration 158/250, Loss: 0.0225\n",
      "Epoch 183/200, Iteration 159/250, Loss: 0.0209\n",
      "Epoch 183/200, Iteration 160/250, Loss: 0.0140\n",
      "Epoch 183/200, Iteration 161/250, Loss: 0.0107\n",
      "Epoch 183/200, Iteration 162/250, Loss: 0.0226\n",
      "Epoch 183/200, Iteration 163/250, Loss: 0.0052\n",
      "Epoch 183/200, Iteration 164/250, Loss: 0.0258\n",
      "Epoch 183/200, Iteration 165/250, Loss: 0.0138\n",
      "Epoch 183/200, Iteration 166/250, Loss: 0.0081\n",
      "Epoch 183/200, Iteration 167/250, Loss: 0.0108\n",
      "Epoch 183/200, Iteration 168/250, Loss: 0.0141\n",
      "Epoch 183/200, Iteration 169/250, Loss: 0.0126\n",
      "Epoch 183/200, Iteration 170/250, Loss: 0.0200\n",
      "Epoch 183/200, Iteration 171/250, Loss: 0.0131\n",
      "Epoch 183/200, Iteration 172/250, Loss: 0.0161\n",
      "Epoch 183/200, Iteration 173/250, Loss: 0.0265\n",
      "Epoch 183/200, Iteration 174/250, Loss: 0.0176\n",
      "Epoch 183/200, Iteration 175/250, Loss: 0.0102\n",
      "Epoch 183/200, Iteration 176/250, Loss: 0.0170\n",
      "Epoch 183/200, Iteration 177/250, Loss: 0.0191\n",
      "Epoch 183/200, Iteration 178/250, Loss: 0.0249\n",
      "Epoch 183/200, Iteration 179/250, Loss: 0.0082\n",
      "Epoch 183/200, Iteration 180/250, Loss: 0.0140\n",
      "Epoch 183/200, Iteration 181/250, Loss: 0.0401\n",
      "Epoch 183/200, Iteration 182/250, Loss: 0.0121\n",
      "Epoch 183/200, Iteration 183/250, Loss: 0.0462\n",
      "Epoch 183/200, Iteration 184/250, Loss: 0.0196\n",
      "Epoch 183/200, Iteration 185/250, Loss: 0.0159\n",
      "Epoch 183/200, Iteration 186/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 187/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 188/250, Loss: 0.0084\n",
      "Epoch 183/200, Iteration 189/250, Loss: 0.0135\n",
      "Epoch 183/200, Iteration 190/250, Loss: 0.0297\n",
      "Epoch 183/200, Iteration 191/250, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 192/250, Loss: 0.0059\n",
      "Epoch 183/200, Iteration 193/250, Loss: 0.0314\n",
      "Epoch 183/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 195/250, Loss: 0.0105\n",
      "Epoch 183/200, Iteration 196/250, Loss: 0.0120\n",
      "Epoch 183/200, Iteration 197/250, Loss: 0.0132\n",
      "Epoch 183/200, Iteration 198/250, Loss: 0.0252\n",
      "Epoch 183/200, Iteration 199/250, Loss: 0.0237\n",
      "Epoch 183/200, Iteration 200/250, Loss: 0.0088\n",
      "Epoch 183/200, Iteration 201/250, Loss: 0.0100\n",
      "Epoch 183/200, Iteration 202/250, Loss: 0.0153\n",
      "Epoch 183/200, Iteration 203/250, Loss: 0.0137\n",
      "Epoch 183/200, Iteration 204/250, Loss: 0.0098\n",
      "Epoch 183/200, Iteration 205/250, Loss: 0.0179\n",
      "Epoch 183/200, Iteration 206/250, Loss: 0.0127\n",
      "Epoch 183/200, Iteration 207/250, Loss: 0.0059\n",
      "Epoch 183/200, Iteration 208/250, Loss: 0.0189\n",
      "Epoch 183/200, Iteration 209/250, Loss: 0.0130\n",
      "Epoch 183/200, Iteration 210/250, Loss: 0.0128\n",
      "Epoch 183/200, Iteration 211/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 212/250, Loss: 0.0132\n",
      "Epoch 183/200, Iteration 213/250, Loss: 0.0320\n",
      "Epoch 183/200, Iteration 214/250, Loss: 0.0115\n",
      "Epoch 183/200, Iteration 215/250, Loss: 0.0077\n",
      "Epoch 183/200, Iteration 216/250, Loss: 0.0326\n",
      "Epoch 183/200, Iteration 217/250, Loss: 0.0273\n",
      "Epoch 183/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 183/200, Iteration 219/250, Loss: 0.0376\n",
      "Epoch 183/200, Iteration 220/250, Loss: 0.0148\n",
      "Epoch 183/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 183/200, Iteration 222/250, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 223/250, Loss: 0.0077\n",
      "Epoch 183/200, Iteration 224/250, Loss: 0.0141\n",
      "Epoch 183/200, Iteration 225/250, Loss: 0.0159\n",
      "Epoch 183/200, Iteration 226/250, Loss: 0.0251\n",
      "Epoch 183/200, Iteration 227/250, Loss: 0.0184\n",
      "Epoch 183/200, Iteration 228/250, Loss: 0.0070\n",
      "Epoch 183/200, Iteration 229/250, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200, Iteration 230/250, Loss: 0.0112\n",
      "Epoch 183/200, Iteration 231/250, Loss: 0.0135\n",
      "Epoch 183/200, Iteration 232/250, Loss: 0.0118\n",
      "Epoch 183/200, Iteration 233/250, Loss: 0.0132\n",
      "Epoch 183/200, Iteration 234/250, Loss: 0.0129\n",
      "Epoch 183/200, Iteration 235/250, Loss: 0.0154\n",
      "Epoch 183/200, Iteration 236/250, Loss: 0.0159\n",
      "Epoch 183/200, Iteration 237/250, Loss: 0.0245\n",
      "Epoch 183/200, Iteration 238/250, Loss: 0.0158\n",
      "Epoch 183/200, Iteration 239/250, Loss: 0.0170\n",
      "Epoch 183/200, Iteration 240/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 241/250, Loss: 0.0184\n",
      "Epoch 183/200, Iteration 242/250, Loss: 0.0199\n",
      "Epoch 183/200, Iteration 243/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 244/250, Loss: 0.0196\n",
      "Epoch 183/200, Iteration 245/250, Loss: 0.0062\n",
      "Epoch 183/200, Iteration 246/250, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 247/250, Loss: 0.0235\n",
      "Epoch 183/200, Iteration 248/250, Loss: 0.0153\n",
      "Epoch 183/200, Iteration 249/250, Loss: 0.0226\n",
      "Epoch 183/200, Iteration 250/250, Loss: 0.0094\n",
      "Train Error: \n",
      " Accuracy: 87.71%, Avg loss: 0.006433, MRE: 0.608347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.006457, MRE: 0.812866 \n",
      "\n",
      "Epoch 184/200, Iteration 1/250, Loss: 0.0150\n",
      "Epoch 184/200, Iteration 2/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 3/250, Loss: 0.0063\n",
      "Epoch 184/200, Iteration 4/250, Loss: 0.0160\n",
      "Epoch 184/200, Iteration 5/250, Loss: 0.0076\n",
      "Epoch 184/200, Iteration 6/250, Loss: 0.0159\n",
      "Epoch 184/200, Iteration 7/250, Loss: 0.0067\n",
      "Epoch 184/200, Iteration 8/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 9/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 10/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 11/250, Loss: 0.0301\n",
      "Epoch 184/200, Iteration 12/250, Loss: 0.0094\n",
      "Epoch 184/200, Iteration 13/250, Loss: 0.0076\n",
      "Epoch 184/200, Iteration 14/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 15/250, Loss: 0.0078\n",
      "Epoch 184/200, Iteration 16/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 17/250, Loss: 0.0110\n",
      "Epoch 184/200, Iteration 18/250, Loss: 0.0127\n",
      "Epoch 184/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 20/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 21/250, Loss: 0.0203\n",
      "Epoch 184/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 184/200, Iteration 23/250, Loss: 0.0069\n",
      "Epoch 184/200, Iteration 24/250, Loss: 0.0201\n",
      "Epoch 184/200, Iteration 25/250, Loss: 0.0138\n",
      "Epoch 184/200, Iteration 26/250, Loss: 0.0102\n",
      "Epoch 184/200, Iteration 27/250, Loss: 0.0234\n",
      "Epoch 184/200, Iteration 28/250, Loss: 0.0113\n",
      "Epoch 184/200, Iteration 29/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 30/250, Loss: 0.0225\n",
      "Epoch 184/200, Iteration 31/250, Loss: 0.0096\n",
      "Epoch 184/200, Iteration 32/250, Loss: 0.0176\n",
      "Epoch 184/200, Iteration 33/250, Loss: 0.0102\n",
      "Epoch 184/200, Iteration 34/250, Loss: 0.0238\n",
      "Epoch 184/200, Iteration 35/250, Loss: 0.0132\n",
      "Epoch 184/200, Iteration 36/250, Loss: 0.0183\n",
      "Epoch 184/200, Iteration 37/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 184/200, Iteration 39/250, Loss: 0.0309\n",
      "Epoch 184/200, Iteration 40/250, Loss: 0.0303\n",
      "Epoch 184/200, Iteration 41/250, Loss: 0.0238\n",
      "Epoch 184/200, Iteration 42/250, Loss: 0.0212\n",
      "Epoch 184/200, Iteration 43/250, Loss: 0.0131\n",
      "Epoch 184/200, Iteration 44/250, Loss: 0.0194\n",
      "Epoch 184/200, Iteration 45/250, Loss: 0.0197\n",
      "Epoch 184/200, Iteration 46/250, Loss: 0.0079\n",
      "Epoch 184/200, Iteration 47/250, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 49/250, Loss: 0.0118\n",
      "Epoch 184/200, Iteration 50/250, Loss: 0.0083\n",
      "Epoch 184/200, Iteration 51/250, Loss: 0.0215\n",
      "Epoch 184/200, Iteration 52/250, Loss: 0.0095\n",
      "Epoch 184/200, Iteration 53/250, Loss: 0.0227\n",
      "Epoch 184/200, Iteration 54/250, Loss: 0.0252\n",
      "Epoch 184/200, Iteration 55/250, Loss: 0.0069\n",
      "Epoch 184/200, Iteration 56/250, Loss: 0.0293\n",
      "Epoch 184/200, Iteration 57/250, Loss: 0.0072\n",
      "Epoch 184/200, Iteration 58/250, Loss: 0.0251\n",
      "Epoch 184/200, Iteration 59/250, Loss: 0.0068\n",
      "Epoch 184/200, Iteration 60/250, Loss: 0.0241\n",
      "Epoch 184/200, Iteration 61/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 62/250, Loss: 0.0145\n",
      "Epoch 184/200, Iteration 63/250, Loss: 0.0285\n",
      "Epoch 184/200, Iteration 64/250, Loss: 0.0087\n",
      "Epoch 184/200, Iteration 65/250, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 184/200, Iteration 67/250, Loss: 0.0112\n",
      "Epoch 184/200, Iteration 68/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 69/250, Loss: 0.0162\n",
      "Epoch 184/200, Iteration 70/250, Loss: 0.0066\n",
      "Epoch 184/200, Iteration 71/250, Loss: 0.0119\n",
      "Epoch 184/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 73/250, Loss: 0.0135\n",
      "Epoch 184/200, Iteration 74/250, Loss: 0.0187\n",
      "Epoch 184/200, Iteration 75/250, Loss: 0.0145\n",
      "Epoch 184/200, Iteration 76/250, Loss: 0.0145\n",
      "Epoch 184/200, Iteration 77/250, Loss: 0.0206\n",
      "Epoch 184/200, Iteration 78/250, Loss: 0.0234\n",
      "Epoch 184/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 80/250, Loss: 0.0208\n",
      "Epoch 184/200, Iteration 81/250, Loss: 0.0188\n",
      "Epoch 184/200, Iteration 82/250, Loss: 0.0354\n",
      "Epoch 184/200, Iteration 83/250, Loss: 0.0154\n",
      "Epoch 184/200, Iteration 84/250, Loss: 0.0224\n",
      "Epoch 184/200, Iteration 85/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 86/250, Loss: 0.0242\n",
      "Epoch 184/200, Iteration 87/250, Loss: 0.0149\n",
      "Epoch 184/200, Iteration 88/250, Loss: 0.0228\n",
      "Epoch 184/200, Iteration 89/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 90/250, Loss: 0.0069\n",
      "Epoch 184/200, Iteration 91/250, Loss: 0.0213\n",
      "Epoch 184/200, Iteration 92/250, Loss: 0.0307\n",
      "Epoch 184/200, Iteration 93/250, Loss: 0.0148\n",
      "Epoch 184/200, Iteration 94/250, Loss: 0.0194\n",
      "Epoch 184/200, Iteration 95/250, Loss: 0.0178\n",
      "Epoch 184/200, Iteration 96/250, Loss: 0.0133\n",
      "Epoch 184/200, Iteration 97/250, Loss: 0.0452\n",
      "Epoch 184/200, Iteration 98/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 99/250, Loss: 0.0122\n",
      "Epoch 184/200, Iteration 100/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 101/250, Loss: 0.0096\n",
      "Epoch 184/200, Iteration 102/250, Loss: 0.0074\n",
      "Epoch 184/200, Iteration 103/250, Loss: 0.0125\n",
      "Epoch 184/200, Iteration 104/250, Loss: 0.0136\n",
      "Epoch 184/200, Iteration 105/250, Loss: 0.0096\n",
      "Epoch 184/200, Iteration 106/250, Loss: 0.0199\n",
      "Epoch 184/200, Iteration 107/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 108/250, Loss: 0.0086\n",
      "Epoch 184/200, Iteration 109/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 110/250, Loss: 0.0214\n",
      "Epoch 184/200, Iteration 111/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 112/250, Loss: 0.0184\n",
      "Epoch 184/200, Iteration 113/250, Loss: 0.0136\n",
      "Epoch 184/200, Iteration 114/250, Loss: 0.0232\n",
      "Epoch 184/200, Iteration 115/250, Loss: 0.0085\n",
      "Epoch 184/200, Iteration 116/250, Loss: 0.0337\n",
      "Epoch 184/200, Iteration 117/250, Loss: 0.0140\n",
      "Epoch 184/200, Iteration 118/250, Loss: 0.0168\n",
      "Epoch 184/200, Iteration 119/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 120/250, Loss: 0.0195\n",
      "Epoch 184/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 184/200, Iteration 122/250, Loss: 0.0094\n",
      "Epoch 184/200, Iteration 123/250, Loss: 0.0154\n",
      "Epoch 184/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 184/200, Iteration 125/250, Loss: 0.0223\n",
      "Epoch 184/200, Iteration 126/250, Loss: 0.0342\n",
      "Epoch 184/200, Iteration 127/250, Loss: 0.0117\n",
      "Epoch 184/200, Iteration 128/250, Loss: 0.0179\n",
      "Epoch 184/200, Iteration 129/250, Loss: 0.0239\n",
      "Epoch 184/200, Iteration 130/250, Loss: 0.0062\n",
      "Epoch 184/200, Iteration 131/250, Loss: 0.0279\n",
      "Epoch 184/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 184/200, Iteration 133/250, Loss: 0.0113\n",
      "Epoch 184/200, Iteration 134/250, Loss: 0.0074\n",
      "Epoch 184/200, Iteration 135/250, Loss: 0.0218\n",
      "Epoch 184/200, Iteration 136/250, Loss: 0.0286\n",
      "Epoch 184/200, Iteration 137/250, Loss: 0.0076\n",
      "Epoch 184/200, Iteration 138/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 139/250, Loss: 0.0087\n",
      "Epoch 184/200, Iteration 140/250, Loss: 0.0345\n",
      "Epoch 184/200, Iteration 141/250, Loss: 0.0197\n",
      "Epoch 184/200, Iteration 142/250, Loss: 0.0065\n",
      "Epoch 184/200, Iteration 143/250, Loss: 0.0063\n",
      "Epoch 184/200, Iteration 144/250, Loss: 0.0145\n",
      "Epoch 184/200, Iteration 145/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 146/250, Loss: 0.0201\n",
      "Epoch 184/200, Iteration 147/250, Loss: 0.0209\n",
      "Epoch 184/200, Iteration 148/250, Loss: 0.0183\n",
      "Epoch 184/200, Iteration 149/250, Loss: 0.0249\n",
      "Epoch 184/200, Iteration 150/250, Loss: 0.0224\n",
      "Epoch 184/200, Iteration 151/250, Loss: 0.0079\n",
      "Epoch 184/200, Iteration 152/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 153/250, Loss: 0.0078\n",
      "Epoch 184/200, Iteration 154/250, Loss: 0.0067\n",
      "Epoch 184/200, Iteration 155/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 156/250, Loss: 0.0148\n",
      "Epoch 184/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 159/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 160/250, Loss: 0.0126\n",
      "Epoch 184/200, Iteration 161/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 162/250, Loss: 0.0066\n",
      "Epoch 184/200, Iteration 163/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 164/250, Loss: 0.0194\n",
      "Epoch 184/200, Iteration 165/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 166/250, Loss: 0.0147\n",
      "Epoch 184/200, Iteration 167/250, Loss: 0.0111\n",
      "Epoch 184/200, Iteration 168/250, Loss: 0.0265\n",
      "Epoch 184/200, Iteration 169/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 170/250, Loss: 0.0180\n",
      "Epoch 184/200, Iteration 171/250, Loss: 0.0286\n",
      "Epoch 184/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 173/250, Loss: 0.0137\n",
      "Epoch 184/200, Iteration 174/250, Loss: 0.0146\n",
      "Epoch 184/200, Iteration 175/250, Loss: 0.0205\n",
      "Epoch 184/200, Iteration 176/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 177/250, Loss: 0.0206\n",
      "Epoch 184/200, Iteration 178/250, Loss: 0.0242\n",
      "Epoch 184/200, Iteration 179/250, Loss: 0.0132\n",
      "Epoch 184/200, Iteration 180/250, Loss: 0.0343\n",
      "Epoch 184/200, Iteration 181/250, Loss: 0.0139\n",
      "Epoch 184/200, Iteration 182/250, Loss: 0.0076\n",
      "Epoch 184/200, Iteration 183/250, Loss: 0.0208\n",
      "Epoch 184/200, Iteration 184/250, Loss: 0.0215\n",
      "Epoch 184/200, Iteration 185/250, Loss: 0.0149\n",
      "Epoch 184/200, Iteration 186/250, Loss: 0.0119\n",
      "Epoch 184/200, Iteration 187/250, Loss: 0.0184\n",
      "Epoch 184/200, Iteration 188/250, Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200, Iteration 189/250, Loss: 0.0251\n",
      "Epoch 184/200, Iteration 190/250, Loss: 0.0152\n",
      "Epoch 184/200, Iteration 191/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 192/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 193/250, Loss: 0.0194\n",
      "Epoch 184/200, Iteration 194/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 195/250, Loss: 0.0185\n",
      "Epoch 184/200, Iteration 196/250, Loss: 0.0089\n",
      "Epoch 184/200, Iteration 197/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 198/250, Loss: 0.0093\n",
      "Epoch 184/200, Iteration 199/250, Loss: 0.0226\n",
      "Epoch 184/200, Iteration 200/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 201/250, Loss: 0.0122\n",
      "Epoch 184/200, Iteration 202/250, Loss: 0.0093\n",
      "Epoch 184/200, Iteration 203/250, Loss: 0.0092\n",
      "Epoch 184/200, Iteration 204/250, Loss: 0.0086\n",
      "Epoch 184/200, Iteration 205/250, Loss: 0.0107\n",
      "Epoch 184/200, Iteration 206/250, Loss: 0.0059\n",
      "Epoch 184/200, Iteration 207/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 208/250, Loss: 0.0110\n",
      "Epoch 184/200, Iteration 209/250, Loss: 0.0102\n",
      "Epoch 184/200, Iteration 210/250, Loss: 0.0165\n",
      "Epoch 184/200, Iteration 211/250, Loss: 0.0148\n",
      "Epoch 184/200, Iteration 212/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 213/250, Loss: 0.0205\n",
      "Epoch 184/200, Iteration 214/250, Loss: 0.0093\n",
      "Epoch 184/200, Iteration 215/250, Loss: 0.0212\n",
      "Epoch 184/200, Iteration 216/250, Loss: 0.0169\n",
      "Epoch 184/200, Iteration 217/250, Loss: 0.0180\n",
      "Epoch 184/200, Iteration 218/250, Loss: 0.0251\n",
      "Epoch 184/200, Iteration 219/250, Loss: 0.0198\n",
      "Epoch 184/200, Iteration 220/250, Loss: 0.0156\n",
      "Epoch 184/200, Iteration 221/250, Loss: 0.0144\n",
      "Epoch 184/200, Iteration 222/250, Loss: 0.0189\n",
      "Epoch 184/200, Iteration 223/250, Loss: 0.0090\n",
      "Epoch 184/200, Iteration 224/250, Loss: 0.0207\n",
      "Epoch 184/200, Iteration 225/250, Loss: 0.0224\n",
      "Epoch 184/200, Iteration 226/250, Loss: 0.0268\n",
      "Epoch 184/200, Iteration 227/250, Loss: 0.0276\n",
      "Epoch 184/200, Iteration 228/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 184/200, Iteration 230/250, Loss: 0.0138\n",
      "Epoch 184/200, Iteration 231/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 232/250, Loss: 0.0279\n",
      "Epoch 184/200, Iteration 233/250, Loss: 0.0149\n",
      "Epoch 184/200, Iteration 234/250, Loss: 0.0239\n",
      "Epoch 184/200, Iteration 235/250, Loss: 0.0072\n",
      "Epoch 184/200, Iteration 236/250, Loss: 0.0124\n",
      "Epoch 184/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 238/250, Loss: 0.0072\n",
      "Epoch 184/200, Iteration 239/250, Loss: 0.0111\n",
      "Epoch 184/200, Iteration 240/250, Loss: 0.0229\n",
      "Epoch 184/200, Iteration 241/250, Loss: 0.0242\n",
      "Epoch 184/200, Iteration 242/250, Loss: 0.0117\n",
      "Epoch 184/200, Iteration 243/250, Loss: 0.0266\n",
      "Epoch 184/200, Iteration 244/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 245/250, Loss: 0.0389\n",
      "Epoch 184/200, Iteration 246/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 247/250, Loss: 0.0131\n",
      "Epoch 184/200, Iteration 248/250, Loss: 0.0170\n",
      "Epoch 184/200, Iteration 249/250, Loss: 0.0179\n",
      "Epoch 184/200, Iteration 250/250, Loss: 0.0151\n",
      "Train Error: \n",
      " Accuracy: 86.15%, Avg loss: 0.006281, MRE: 0.639698 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.006352, MRE: 0.949566 \n",
      "\n",
      "Epoch 185/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 2/250, Loss: 0.0252\n",
      "Epoch 185/200, Iteration 3/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 4/250, Loss: 0.0165\n",
      "Epoch 185/200, Iteration 5/250, Loss: 0.0191\n",
      "Epoch 185/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 7/250, Loss: 0.0118\n",
      "Epoch 185/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 9/250, Loss: 0.0201\n",
      "Epoch 185/200, Iteration 10/250, Loss: 0.0236\n",
      "Epoch 185/200, Iteration 11/250, Loss: 0.0114\n",
      "Epoch 185/200, Iteration 12/250, Loss: 0.0137\n",
      "Epoch 185/200, Iteration 13/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 14/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 15/250, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 16/250, Loss: 0.0067\n",
      "Epoch 185/200, Iteration 17/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 18/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 19/250, Loss: 0.0143\n",
      "Epoch 185/200, Iteration 20/250, Loss: 0.0189\n",
      "Epoch 185/200, Iteration 21/250, Loss: 0.0209\n",
      "Epoch 185/200, Iteration 22/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 185/200, Iteration 24/250, Loss: 0.0075\n",
      "Epoch 185/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 26/250, Loss: 0.0167\n",
      "Epoch 185/200, Iteration 27/250, Loss: 0.0136\n",
      "Epoch 185/200, Iteration 28/250, Loss: 0.0108\n",
      "Epoch 185/200, Iteration 29/250, Loss: 0.0067\n",
      "Epoch 185/200, Iteration 30/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 31/250, Loss: 0.0184\n",
      "Epoch 185/200, Iteration 32/250, Loss: 0.0122\n",
      "Epoch 185/200, Iteration 33/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 34/250, Loss: 0.0079\n",
      "Epoch 185/200, Iteration 35/250, Loss: 0.0124\n",
      "Epoch 185/200, Iteration 36/250, Loss: 0.0223\n",
      "Epoch 185/200, Iteration 37/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 38/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 39/250, Loss: 0.0233\n",
      "Epoch 185/200, Iteration 40/250, Loss: 0.0101\n",
      "Epoch 185/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 42/250, Loss: 0.0075\n",
      "Epoch 185/200, Iteration 43/250, Loss: 0.0185\n",
      "Epoch 185/200, Iteration 44/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 45/250, Loss: 0.0210\n",
      "Epoch 185/200, Iteration 46/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 47/250, Loss: 0.0183\n",
      "Epoch 185/200, Iteration 48/250, Loss: 0.0115\n",
      "Epoch 185/200, Iteration 49/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 50/250, Loss: 0.0075\n",
      "Epoch 185/200, Iteration 51/250, Loss: 0.0110\n",
      "Epoch 185/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 53/250, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 54/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 55/250, Loss: 0.0110\n",
      "Epoch 185/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 58/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 59/250, Loss: 0.0139\n",
      "Epoch 185/200, Iteration 60/250, Loss: 0.0081\n",
      "Epoch 185/200, Iteration 61/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 62/250, Loss: 0.0174\n",
      "Epoch 185/200, Iteration 63/250, Loss: 0.0269\n",
      "Epoch 185/200, Iteration 64/250, Loss: 0.0235\n",
      "Epoch 185/200, Iteration 65/250, Loss: 0.0109\n",
      "Epoch 185/200, Iteration 66/250, Loss: 0.0157\n",
      "Epoch 185/200, Iteration 67/250, Loss: 0.0180\n",
      "Epoch 185/200, Iteration 68/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 69/250, Loss: 0.0235\n",
      "Epoch 185/200, Iteration 70/250, Loss: 0.0102\n",
      "Epoch 185/200, Iteration 71/250, Loss: 0.0128\n",
      "Epoch 185/200, Iteration 72/250, Loss: 0.0176\n",
      "Epoch 185/200, Iteration 73/250, Loss: 0.0079\n",
      "Epoch 185/200, Iteration 74/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 75/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 76/250, Loss: 0.0109\n",
      "Epoch 185/200, Iteration 77/250, Loss: 0.0090\n",
      "Epoch 185/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 185/200, Iteration 79/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 80/250, Loss: 0.0144\n",
      "Epoch 185/200, Iteration 81/250, Loss: 0.0247\n",
      "Epoch 185/200, Iteration 82/250, Loss: 0.0116\n",
      "Epoch 185/200, Iteration 83/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 84/250, Loss: 0.0215\n",
      "Epoch 185/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 86/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 185/200, Iteration 89/250, Loss: 0.0147\n",
      "Epoch 185/200, Iteration 90/250, Loss: 0.0108\n",
      "Epoch 185/200, Iteration 91/250, Loss: 0.0170\n",
      "Epoch 185/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 185/200, Iteration 93/250, Loss: 0.0090\n",
      "Epoch 185/200, Iteration 94/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 95/250, Loss: 0.0261\n",
      "Epoch 185/200, Iteration 96/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 97/250, Loss: 0.0096\n",
      "Epoch 185/200, Iteration 98/250, Loss: 0.0211\n",
      "Epoch 185/200, Iteration 99/250, Loss: 0.0086\n",
      "Epoch 185/200, Iteration 100/250, Loss: 0.0274\n",
      "Epoch 185/200, Iteration 101/250, Loss: 0.0166\n",
      "Epoch 185/200, Iteration 102/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 103/250, Loss: 0.0249\n",
      "Epoch 185/200, Iteration 104/250, Loss: 0.0116\n",
      "Epoch 185/200, Iteration 105/250, Loss: 0.0101\n",
      "Epoch 185/200, Iteration 106/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 107/250, Loss: 0.0156\n",
      "Epoch 185/200, Iteration 108/250, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 109/250, Loss: 0.0114\n",
      "Epoch 185/200, Iteration 110/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 111/250, Loss: 0.0130\n",
      "Epoch 185/200, Iteration 112/250, Loss: 0.0279\n",
      "Epoch 185/200, Iteration 113/250, Loss: 0.0081\n",
      "Epoch 185/200, Iteration 114/250, Loss: 0.0060\n",
      "Epoch 185/200, Iteration 115/250, Loss: 0.0200\n",
      "Epoch 185/200, Iteration 116/250, Loss: 0.0111\n",
      "Epoch 185/200, Iteration 117/250, Loss: 0.0124\n",
      "Epoch 185/200, Iteration 118/250, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200, Iteration 119/250, Loss: 0.0297\n",
      "Epoch 185/200, Iteration 120/250, Loss: 0.0212\n",
      "Epoch 185/200, Iteration 121/250, Loss: 0.0353\n",
      "Epoch 185/200, Iteration 122/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 123/250, Loss: 0.0280\n",
      "Epoch 185/200, Iteration 124/250, Loss: 0.0099\n",
      "Epoch 185/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 126/250, Loss: 0.0143\n",
      "Epoch 185/200, Iteration 127/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 185/200, Iteration 129/250, Loss: 0.0138\n",
      "Epoch 185/200, Iteration 130/250, Loss: 0.0073\n",
      "Epoch 185/200, Iteration 131/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 132/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 133/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 134/250, Loss: 0.0264\n",
      "Epoch 185/200, Iteration 135/250, Loss: 0.0225\n",
      "Epoch 185/200, Iteration 136/250, Loss: 0.0154\n",
      "Epoch 185/200, Iteration 137/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 138/250, Loss: 0.0164\n",
      "Epoch 185/200, Iteration 139/250, Loss: 0.0316\n",
      "Epoch 185/200, Iteration 140/250, Loss: 0.0362\n",
      "Epoch 185/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 142/250, Loss: 0.0109\n",
      "Epoch 185/200, Iteration 143/250, Loss: 0.0317\n",
      "Epoch 185/200, Iteration 144/250, Loss: 0.0429\n",
      "Epoch 185/200, Iteration 145/250, Loss: 0.0141\n",
      "Epoch 185/200, Iteration 146/250, Loss: 0.0184\n",
      "Epoch 185/200, Iteration 147/250, Loss: 0.0222\n",
      "Epoch 185/200, Iteration 148/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 149/250, Loss: 0.0158\n",
      "Epoch 185/200, Iteration 150/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 151/250, Loss: 0.0230\n",
      "Epoch 185/200, Iteration 152/250, Loss: 0.0162\n",
      "Epoch 185/200, Iteration 153/250, Loss: 0.0189\n",
      "Epoch 185/200, Iteration 154/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 155/250, Loss: 0.0131\n",
      "Epoch 185/200, Iteration 156/250, Loss: 0.0075\n",
      "Epoch 185/200, Iteration 157/250, Loss: 0.0206\n",
      "Epoch 185/200, Iteration 158/250, Loss: 0.0130\n",
      "Epoch 185/200, Iteration 159/250, Loss: 0.0087\n",
      "Epoch 185/200, Iteration 160/250, Loss: 0.0195\n",
      "Epoch 185/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 162/250, Loss: 0.0084\n",
      "Epoch 185/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 164/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 165/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 166/250, Loss: 0.0171\n",
      "Epoch 185/200, Iteration 167/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 168/250, Loss: 0.0147\n",
      "Epoch 185/200, Iteration 169/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 170/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 171/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 172/250, Loss: 0.0111\n",
      "Epoch 185/200, Iteration 173/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 174/250, Loss: 0.0121\n",
      "Epoch 185/200, Iteration 175/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 176/250, Loss: 0.0134\n",
      "Epoch 185/200, Iteration 177/250, Loss: 0.0129\n",
      "Epoch 185/200, Iteration 178/250, Loss: 0.0194\n",
      "Epoch 185/200, Iteration 179/250, Loss: 0.0079\n",
      "Epoch 185/200, Iteration 180/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 181/250, Loss: 0.0319\n",
      "Epoch 185/200, Iteration 182/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 183/250, Loss: 0.0118\n",
      "Epoch 185/200, Iteration 184/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 185/250, Loss: 0.0127\n",
      "Epoch 185/200, Iteration 186/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 187/250, Loss: 0.0131\n",
      "Epoch 185/200, Iteration 188/250, Loss: 0.0096\n",
      "Epoch 185/200, Iteration 189/250, Loss: 0.0106\n",
      "Epoch 185/200, Iteration 190/250, Loss: 0.0184\n",
      "Epoch 185/200, Iteration 191/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 192/250, Loss: 0.0297\n",
      "Epoch 185/200, Iteration 193/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 194/250, Loss: 0.0087\n",
      "Epoch 185/200, Iteration 195/250, Loss: 0.0142\n",
      "Epoch 185/200, Iteration 196/250, Loss: 0.0490\n",
      "Epoch 185/200, Iteration 197/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 198/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 199/250, Loss: 0.0224\n",
      "Epoch 185/200, Iteration 200/250, Loss: 0.0113\n",
      "Epoch 185/200, Iteration 201/250, Loss: 0.0137\n",
      "Epoch 185/200, Iteration 202/250, Loss: 0.0070\n",
      "Epoch 185/200, Iteration 203/250, Loss: 0.0137\n",
      "Epoch 185/200, Iteration 204/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 205/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 206/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 207/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 208/250, Loss: 0.0129\n",
      "Epoch 185/200, Iteration 209/250, Loss: 0.0296\n",
      "Epoch 185/200, Iteration 210/250, Loss: 0.0144\n",
      "Epoch 185/200, Iteration 211/250, Loss: 0.0153\n",
      "Epoch 185/200, Iteration 212/250, Loss: 0.0065\n",
      "Epoch 185/200, Iteration 213/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 214/250, Loss: 0.0197\n",
      "Epoch 185/200, Iteration 215/250, Loss: 0.0208\n",
      "Epoch 185/200, Iteration 216/250, Loss: 0.0060\n",
      "Epoch 185/200, Iteration 217/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 218/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 219/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 220/250, Loss: 0.0149\n",
      "Epoch 185/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 185/200, Iteration 222/250, Loss: 0.0201\n",
      "Epoch 185/200, Iteration 223/250, Loss: 0.0126\n",
      "Epoch 185/200, Iteration 224/250, Loss: 0.0250\n",
      "Epoch 185/200, Iteration 225/250, Loss: 0.0280\n",
      "Epoch 185/200, Iteration 226/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 227/250, Loss: 0.0099\n",
      "Epoch 185/200, Iteration 228/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 229/250, Loss: 0.0153\n",
      "Epoch 185/200, Iteration 230/250, Loss: 0.0233\n",
      "Epoch 185/200, Iteration 231/250, Loss: 0.0152\n",
      "Epoch 185/200, Iteration 232/250, Loss: 0.0299\n",
      "Epoch 185/200, Iteration 233/250, Loss: 0.0130\n",
      "Epoch 185/200, Iteration 234/250, Loss: 0.0128\n",
      "Epoch 185/200, Iteration 235/250, Loss: 0.0066\n",
      "Epoch 185/200, Iteration 236/250, Loss: 0.0236\n",
      "Epoch 185/200, Iteration 237/250, Loss: 0.0158\n",
      "Epoch 185/200, Iteration 238/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 239/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 240/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 241/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 242/250, Loss: 0.0190\n",
      "Epoch 185/200, Iteration 243/250, Loss: 0.0138\n",
      "Epoch 185/200, Iteration 244/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 245/250, Loss: 0.0074\n",
      "Epoch 185/200, Iteration 246/250, Loss: 0.0184\n",
      "Epoch 185/200, Iteration 247/250, Loss: 0.0086\n",
      "Epoch 185/200, Iteration 248/250, Loss: 0.0102\n",
      "Epoch 185/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 250/250, Loss: 0.0254\n",
      "Train Error: \n",
      " Accuracy: 97.44%, Avg loss: 0.006363, MRE: 0.660503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.006332, MRE: 1.223539 \n",
      "\n",
      "Epoch 186/200, Iteration 1/250, Loss: 0.0143\n",
      "Epoch 186/200, Iteration 2/250, Loss: 0.0092\n",
      "Epoch 186/200, Iteration 3/250, Loss: 0.0106\n",
      "Epoch 186/200, Iteration 4/250, Loss: 0.0062\n",
      "Epoch 186/200, Iteration 5/250, Loss: 0.0303\n",
      "Epoch 186/200, Iteration 6/250, Loss: 0.0203\n",
      "Epoch 186/200, Iteration 7/250, Loss: 0.0070\n",
      "Epoch 186/200, Iteration 8/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 9/250, Loss: 0.0091\n",
      "Epoch 186/200, Iteration 10/250, Loss: 0.0389\n",
      "Epoch 186/200, Iteration 11/250, Loss: 0.0236\n",
      "Epoch 186/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 186/200, Iteration 13/250, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 14/250, Loss: 0.0197\n",
      "Epoch 186/200, Iteration 15/250, Loss: 0.0117\n",
      "Epoch 186/200, Iteration 16/250, Loss: 0.0055\n",
      "Epoch 186/200, Iteration 17/250, Loss: 0.0107\n",
      "Epoch 186/200, Iteration 18/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 19/250, Loss: 0.0247\n",
      "Epoch 186/200, Iteration 20/250, Loss: 0.0275\n",
      "Epoch 186/200, Iteration 21/250, Loss: 0.0215\n",
      "Epoch 186/200, Iteration 22/250, Loss: 0.0191\n",
      "Epoch 186/200, Iteration 23/250, Loss: 0.0051\n",
      "Epoch 186/200, Iteration 24/250, Loss: 0.0188\n",
      "Epoch 186/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 186/200, Iteration 26/250, Loss: 0.0125\n",
      "Epoch 186/200, Iteration 27/250, Loss: 0.0159\n",
      "Epoch 186/200, Iteration 28/250, Loss: 0.0187\n",
      "Epoch 186/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 186/200, Iteration 30/250, Loss: 0.0289\n",
      "Epoch 186/200, Iteration 31/250, Loss: 0.0140\n",
      "Epoch 186/200, Iteration 32/250, Loss: 0.0309\n",
      "Epoch 186/200, Iteration 33/250, Loss: 0.0367\n",
      "Epoch 186/200, Iteration 34/250, Loss: 0.0114\n",
      "Epoch 186/200, Iteration 35/250, Loss: 0.0149\n",
      "Epoch 186/200, Iteration 36/250, Loss: 0.0148\n",
      "Epoch 186/200, Iteration 37/250, Loss: 0.0145\n",
      "Epoch 186/200, Iteration 38/250, Loss: 0.0182\n",
      "Epoch 186/200, Iteration 39/250, Loss: 0.0097\n",
      "Epoch 186/200, Iteration 40/250, Loss: 0.0100\n",
      "Epoch 186/200, Iteration 41/250, Loss: 0.0219\n",
      "Epoch 186/200, Iteration 42/250, Loss: 0.0165\n",
      "Epoch 186/200, Iteration 43/250, Loss: 0.0223\n",
      "Epoch 186/200, Iteration 44/250, Loss: 0.0223\n",
      "Epoch 186/200, Iteration 45/250, Loss: 0.0149\n",
      "Epoch 186/200, Iteration 46/250, Loss: 0.0082\n",
      "Epoch 186/200, Iteration 47/250, Loss: 0.0198\n",
      "Epoch 186/200, Iteration 48/250, Loss: 0.0220\n",
      "Epoch 186/200, Iteration 49/250, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200, Iteration 50/250, Loss: 0.0108\n",
      "Epoch 186/200, Iteration 51/250, Loss: 0.0086\n",
      "Epoch 186/200, Iteration 52/250, Loss: 0.0216\n",
      "Epoch 186/200, Iteration 53/250, Loss: 0.0223\n",
      "Epoch 186/200, Iteration 54/250, Loss: 0.0070\n",
      "Epoch 186/200, Iteration 55/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 56/250, Loss: 0.0283\n",
      "Epoch 186/200, Iteration 57/250, Loss: 0.0296\n",
      "Epoch 186/200, Iteration 58/250, Loss: 0.0152\n",
      "Epoch 186/200, Iteration 59/250, Loss: 0.0143\n",
      "Epoch 186/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 186/200, Iteration 61/250, Loss: 0.0134\n",
      "Epoch 186/200, Iteration 62/250, Loss: 0.0252\n",
      "Epoch 186/200, Iteration 63/250, Loss: 0.0221\n",
      "Epoch 186/200, Iteration 64/250, Loss: 0.0076\n",
      "Epoch 186/200, Iteration 65/250, Loss: 0.0135\n",
      "Epoch 186/200, Iteration 66/250, Loss: 0.0177\n",
      "Epoch 186/200, Iteration 67/250, Loss: 0.0101\n",
      "Epoch 186/200, Iteration 68/250, Loss: 0.0096\n",
      "Epoch 186/200, Iteration 69/250, Loss: 0.0156\n",
      "Epoch 186/200, Iteration 70/250, Loss: 0.0073\n",
      "Epoch 186/200, Iteration 71/250, Loss: 0.0085\n",
      "Epoch 186/200, Iteration 72/250, Loss: 0.0130\n",
      "Epoch 186/200, Iteration 73/250, Loss: 0.0068\n",
      "Epoch 186/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 75/250, Loss: 0.0200\n",
      "Epoch 186/200, Iteration 76/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 77/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 78/250, Loss: 0.0169\n",
      "Epoch 186/200, Iteration 79/250, Loss: 0.0151\n",
      "Epoch 186/200, Iteration 80/250, Loss: 0.0290\n",
      "Epoch 186/200, Iteration 81/250, Loss: 0.0174\n",
      "Epoch 186/200, Iteration 82/250, Loss: 0.0159\n",
      "Epoch 186/200, Iteration 83/250, Loss: 0.0078\n",
      "Epoch 186/200, Iteration 84/250, Loss: 0.0231\n",
      "Epoch 186/200, Iteration 85/250, Loss: 0.0232\n",
      "Epoch 186/200, Iteration 86/250, Loss: 0.0120\n",
      "Epoch 186/200, Iteration 87/250, Loss: 0.0197\n",
      "Epoch 186/200, Iteration 88/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 89/250, Loss: 0.0117\n",
      "Epoch 186/200, Iteration 90/250, Loss: 0.0117\n",
      "Epoch 186/200, Iteration 91/250, Loss: 0.0222\n",
      "Epoch 186/200, Iteration 92/250, Loss: 0.0167\n",
      "Epoch 186/200, Iteration 93/250, Loss: 0.0088\n",
      "Epoch 186/200, Iteration 94/250, Loss: 0.0382\n",
      "Epoch 186/200, Iteration 95/250, Loss: 0.0097\n",
      "Epoch 186/200, Iteration 96/250, Loss: 0.0115\n",
      "Epoch 186/200, Iteration 97/250, Loss: 0.0252\n",
      "Epoch 186/200, Iteration 98/250, Loss: 0.0060\n",
      "Epoch 186/200, Iteration 99/250, Loss: 0.0192\n",
      "Epoch 186/200, Iteration 100/250, Loss: 0.0108\n",
      "Epoch 186/200, Iteration 101/250, Loss: 0.0171\n",
      "Epoch 186/200, Iteration 102/250, Loss: 0.0148\n",
      "Epoch 186/200, Iteration 103/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 104/250, Loss: 0.0191\n",
      "Epoch 186/200, Iteration 105/250, Loss: 0.0085\n",
      "Epoch 186/200, Iteration 106/250, Loss: 0.0141\n",
      "Epoch 186/200, Iteration 107/250, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 109/250, Loss: 0.0102\n",
      "Epoch 186/200, Iteration 110/250, Loss: 0.0284\n",
      "Epoch 186/200, Iteration 111/250, Loss: 0.0139\n",
      "Epoch 186/200, Iteration 112/250, Loss: 0.0172\n",
      "Epoch 186/200, Iteration 113/250, Loss: 0.0076\n",
      "Epoch 186/200, Iteration 114/250, Loss: 0.0097\n",
      "Epoch 186/200, Iteration 115/250, Loss: 0.0204\n",
      "Epoch 186/200, Iteration 116/250, Loss: 0.0239\n",
      "Epoch 186/200, Iteration 117/250, Loss: 0.0093\n",
      "Epoch 186/200, Iteration 118/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 119/250, Loss: 0.0240\n",
      "Epoch 186/200, Iteration 120/250, Loss: 0.0203\n",
      "Epoch 186/200, Iteration 121/250, Loss: 0.0214\n",
      "Epoch 186/200, Iteration 122/250, Loss: 0.0338\n",
      "Epoch 186/200, Iteration 123/250, Loss: 0.0145\n",
      "Epoch 186/200, Iteration 124/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 126/250, Loss: 0.0160\n",
      "Epoch 186/200, Iteration 127/250, Loss: 0.0117\n",
      "Epoch 186/200, Iteration 128/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 129/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 186/200, Iteration 131/250, Loss: 0.0311\n",
      "Epoch 186/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 133/250, Loss: 0.0151\n",
      "Epoch 186/200, Iteration 134/250, Loss: 0.0184\n",
      "Epoch 186/200, Iteration 135/250, Loss: 0.0066\n",
      "Epoch 186/200, Iteration 136/250, Loss: 0.0142\n",
      "Epoch 186/200, Iteration 137/250, Loss: 0.0140\n",
      "Epoch 186/200, Iteration 138/250, Loss: 0.0133\n",
      "Epoch 186/200, Iteration 139/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 140/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 141/250, Loss: 0.0078\n",
      "Epoch 186/200, Iteration 142/250, Loss: 0.0087\n",
      "Epoch 186/200, Iteration 143/250, Loss: 0.0061\n",
      "Epoch 186/200, Iteration 144/250, Loss: 0.0078\n",
      "Epoch 186/200, Iteration 145/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 146/250, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 147/250, Loss: 0.0302\n",
      "Epoch 186/200, Iteration 148/250, Loss: 0.0255\n",
      "Epoch 186/200, Iteration 149/250, Loss: 0.0144\n",
      "Epoch 186/200, Iteration 150/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 151/250, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 152/250, Loss: 0.0109\n",
      "Epoch 186/200, Iteration 153/250, Loss: 0.0167\n",
      "Epoch 186/200, Iteration 154/250, Loss: 0.0143\n",
      "Epoch 186/200, Iteration 155/250, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 156/250, Loss: 0.0077\n",
      "Epoch 186/200, Iteration 157/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 158/250, Loss: 0.0271\n",
      "Epoch 186/200, Iteration 159/250, Loss: 0.0092\n",
      "Epoch 186/200, Iteration 160/250, Loss: 0.0102\n",
      "Epoch 186/200, Iteration 161/250, Loss: 0.0195\n",
      "Epoch 186/200, Iteration 162/250, Loss: 0.0076\n",
      "Epoch 186/200, Iteration 163/250, Loss: 0.0074\n",
      "Epoch 186/200, Iteration 164/250, Loss: 0.0184\n",
      "Epoch 186/200, Iteration 165/250, Loss: 0.0218\n",
      "Epoch 186/200, Iteration 166/250, Loss: 0.0247\n",
      "Epoch 186/200, Iteration 167/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 168/250, Loss: 0.0134\n",
      "Epoch 186/200, Iteration 169/250, Loss: 0.0166\n",
      "Epoch 186/200, Iteration 170/250, Loss: 0.0264\n",
      "Epoch 186/200, Iteration 171/250, Loss: 0.0150\n",
      "Epoch 186/200, Iteration 172/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 173/250, Loss: 0.0087\n",
      "Epoch 186/200, Iteration 174/250, Loss: 0.0167\n",
      "Epoch 186/200, Iteration 175/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 176/250, Loss: 0.0131\n",
      "Epoch 186/200, Iteration 177/250, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 178/250, Loss: 0.0135\n",
      "Epoch 186/200, Iteration 179/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 180/250, Loss: 0.0141\n",
      "Epoch 186/200, Iteration 181/250, Loss: 0.0136\n",
      "Epoch 186/200, Iteration 182/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 183/250, Loss: 0.0112\n",
      "Epoch 186/200, Iteration 184/250, Loss: 0.0064\n",
      "Epoch 186/200, Iteration 185/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 186/250, Loss: 0.0408\n",
      "Epoch 186/200, Iteration 187/250, Loss: 0.0064\n",
      "Epoch 186/200, Iteration 188/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 189/250, Loss: 0.0102\n",
      "Epoch 186/200, Iteration 190/250, Loss: 0.0089\n",
      "Epoch 186/200, Iteration 191/250, Loss: 0.0155\n",
      "Epoch 186/200, Iteration 192/250, Loss: 0.0283\n",
      "Epoch 186/200, Iteration 193/250, Loss: 0.0091\n",
      "Epoch 186/200, Iteration 194/250, Loss: 0.0139\n",
      "Epoch 186/200, Iteration 195/250, Loss: 0.0216\n",
      "Epoch 186/200, Iteration 196/250, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 197/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 198/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 199/250, Loss: 0.0066\n",
      "Epoch 186/200, Iteration 200/250, Loss: 0.0149\n",
      "Epoch 186/200, Iteration 201/250, Loss: 0.0080\n",
      "Epoch 186/200, Iteration 202/250, Loss: 0.0181\n",
      "Epoch 186/200, Iteration 203/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 204/250, Loss: 0.0163\n",
      "Epoch 186/200, Iteration 205/250, Loss: 0.0109\n",
      "Epoch 186/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 186/200, Iteration 207/250, Loss: 0.0175\n",
      "Epoch 186/200, Iteration 208/250, Loss: 0.0157\n",
      "Epoch 186/200, Iteration 209/250, Loss: 0.0219\n",
      "Epoch 186/200, Iteration 210/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 211/250, Loss: 0.0144\n",
      "Epoch 186/200, Iteration 212/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 213/250, Loss: 0.0150\n",
      "Epoch 186/200, Iteration 214/250, Loss: 0.0095\n",
      "Epoch 186/200, Iteration 215/250, Loss: 0.0126\n",
      "Epoch 186/200, Iteration 216/250, Loss: 0.0176\n",
      "Epoch 186/200, Iteration 217/250, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 218/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 219/250, Loss: 0.0100\n",
      "Epoch 186/200, Iteration 220/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 221/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 222/250, Loss: 0.0263\n",
      "Epoch 186/200, Iteration 223/250, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 224/250, Loss: 0.0114\n",
      "Epoch 186/200, Iteration 225/250, Loss: 0.0153\n",
      "Epoch 186/200, Iteration 226/250, Loss: 0.0188\n",
      "Epoch 186/200, Iteration 227/250, Loss: 0.0133\n",
      "Epoch 186/200, Iteration 228/250, Loss: 0.0248\n",
      "Epoch 186/200, Iteration 229/250, Loss: 0.0213\n",
      "Epoch 186/200, Iteration 230/250, Loss: 0.0123\n",
      "Epoch 186/200, Iteration 231/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 232/250, Loss: 0.0152\n",
      "Epoch 186/200, Iteration 233/250, Loss: 0.0204\n",
      "Epoch 186/200, Iteration 234/250, Loss: 0.0280\n",
      "Epoch 186/200, Iteration 235/250, Loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200, Iteration 236/250, Loss: 0.0075\n",
      "Epoch 186/200, Iteration 237/250, Loss: 0.0189\n",
      "Epoch 186/200, Iteration 238/250, Loss: 0.0150\n",
      "Epoch 186/200, Iteration 239/250, Loss: 0.0391\n",
      "Epoch 186/200, Iteration 240/250, Loss: 0.0079\n",
      "Epoch 186/200, Iteration 241/250, Loss: 0.0059\n",
      "Epoch 186/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 243/250, Loss: 0.0112\n",
      "Epoch 186/200, Iteration 244/250, Loss: 0.0136\n",
      "Epoch 186/200, Iteration 245/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 246/250, Loss: 0.0104\n",
      "Epoch 186/200, Iteration 247/250, Loss: 0.0166\n",
      "Epoch 186/200, Iteration 248/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 249/250, Loss: 0.0289\n",
      "Epoch 186/200, Iteration 250/250, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 91.54%, Avg loss: 0.006065, MRE: 0.597695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.35%, Avg loss: 0.006140, MRE: 0.870730 \n",
      "\n",
      "Epoch 187/200, Iteration 1/250, Loss: 0.0203\n",
      "Epoch 187/200, Iteration 2/250, Loss: 0.0109\n",
      "Epoch 187/200, Iteration 3/250, Loss: 0.0181\n",
      "Epoch 187/200, Iteration 4/250, Loss: 0.0084\n",
      "Epoch 187/200, Iteration 5/250, Loss: 0.0172\n",
      "Epoch 187/200, Iteration 6/250, Loss: 0.0155\n",
      "Epoch 187/200, Iteration 7/250, Loss: 0.0210\n",
      "Epoch 187/200, Iteration 8/250, Loss: 0.0163\n",
      "Epoch 187/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 10/250, Loss: 0.0248\n",
      "Epoch 187/200, Iteration 11/250, Loss: 0.0076\n",
      "Epoch 187/200, Iteration 12/250, Loss: 0.0148\n",
      "Epoch 187/200, Iteration 13/250, Loss: 0.0370\n",
      "Epoch 187/200, Iteration 14/250, Loss: 0.0068\n",
      "Epoch 187/200, Iteration 15/250, Loss: 0.0224\n",
      "Epoch 187/200, Iteration 16/250, Loss: 0.0084\n",
      "Epoch 187/200, Iteration 17/250, Loss: 0.0250\n",
      "Epoch 187/200, Iteration 18/250, Loss: 0.0401\n",
      "Epoch 187/200, Iteration 19/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 20/250, Loss: 0.0180\n",
      "Epoch 187/200, Iteration 21/250, Loss: 0.0173\n",
      "Epoch 187/200, Iteration 22/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 23/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 24/250, Loss: 0.0065\n",
      "Epoch 187/200, Iteration 25/250, Loss: 0.0125\n",
      "Epoch 187/200, Iteration 26/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 27/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 28/250, Loss: 0.0107\n",
      "Epoch 187/200, Iteration 29/250, Loss: 0.0132\n",
      "Epoch 187/200, Iteration 30/250, Loss: 0.0120\n",
      "Epoch 187/200, Iteration 31/250, Loss: 0.0117\n",
      "Epoch 187/200, Iteration 32/250, Loss: 0.0125\n",
      "Epoch 187/200, Iteration 33/250, Loss: 0.0133\n",
      "Epoch 187/200, Iteration 34/250, Loss: 0.0101\n",
      "Epoch 187/200, Iteration 35/250, Loss: 0.0069\n",
      "Epoch 187/200, Iteration 36/250, Loss: 0.0081\n",
      "Epoch 187/200, Iteration 37/250, Loss: 0.0164\n",
      "Epoch 187/200, Iteration 38/250, Loss: 0.0195\n",
      "Epoch 187/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 187/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 187/200, Iteration 41/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 42/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 43/250, Loss: 0.0158\n",
      "Epoch 187/200, Iteration 44/250, Loss: 0.0174\n",
      "Epoch 187/200, Iteration 45/250, Loss: 0.0108\n",
      "Epoch 187/200, Iteration 46/250, Loss: 0.0069\n",
      "Epoch 187/200, Iteration 47/250, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 48/250, Loss: 0.0124\n",
      "Epoch 187/200, Iteration 49/250, Loss: 0.0122\n",
      "Epoch 187/200, Iteration 50/250, Loss: 0.0202\n",
      "Epoch 187/200, Iteration 51/250, Loss: 0.0098\n",
      "Epoch 187/200, Iteration 52/250, Loss: 0.0205\n",
      "Epoch 187/200, Iteration 53/250, Loss: 0.0177\n",
      "Epoch 187/200, Iteration 54/250, Loss: 0.0101\n",
      "Epoch 187/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 187/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 187/200, Iteration 57/250, Loss: 0.0146\n",
      "Epoch 187/200, Iteration 58/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 59/250, Loss: 0.0156\n",
      "Epoch 187/200, Iteration 60/250, Loss: 0.0106\n",
      "Epoch 187/200, Iteration 61/250, Loss: 0.0139\n",
      "Epoch 187/200, Iteration 62/250, Loss: 0.0170\n",
      "Epoch 187/200, Iteration 63/250, Loss: 0.0145\n",
      "Epoch 187/200, Iteration 64/250, Loss: 0.0159\n",
      "Epoch 187/200, Iteration 65/250, Loss: 0.0064\n",
      "Epoch 187/200, Iteration 66/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 67/250, Loss: 0.0169\n",
      "Epoch 187/200, Iteration 68/250, Loss: 0.0180\n",
      "Epoch 187/200, Iteration 69/250, Loss: 0.0204\n",
      "Epoch 187/200, Iteration 70/250, Loss: 0.0209\n",
      "Epoch 187/200, Iteration 71/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 72/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 187/200, Iteration 74/250, Loss: 0.0093\n",
      "Epoch 187/200, Iteration 75/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 76/250, Loss: 0.0070\n",
      "Epoch 187/200, Iteration 77/250, Loss: 0.0058\n",
      "Epoch 187/200, Iteration 78/250, Loss: 0.0160\n",
      "Epoch 187/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 187/200, Iteration 80/250, Loss: 0.0078\n",
      "Epoch 187/200, Iteration 81/250, Loss: 0.0067\n",
      "Epoch 187/200, Iteration 82/250, Loss: 0.0261\n",
      "Epoch 187/200, Iteration 83/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 84/250, Loss: 0.0280\n",
      "Epoch 187/200, Iteration 85/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 86/250, Loss: 0.0198\n",
      "Epoch 187/200, Iteration 87/250, Loss: 0.0256\n",
      "Epoch 187/200, Iteration 88/250, Loss: 0.0139\n",
      "Epoch 187/200, Iteration 89/250, Loss: 0.0192\n",
      "Epoch 187/200, Iteration 90/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 91/250, Loss: 0.0326\n",
      "Epoch 187/200, Iteration 92/250, Loss: 0.0072\n",
      "Epoch 187/200, Iteration 93/250, Loss: 0.0134\n",
      "Epoch 187/200, Iteration 94/250, Loss: 0.0081\n",
      "Epoch 187/200, Iteration 95/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 96/250, Loss: 0.0071\n",
      "Epoch 187/200, Iteration 97/250, Loss: 0.0245\n",
      "Epoch 187/200, Iteration 98/250, Loss: 0.0204\n",
      "Epoch 187/200, Iteration 99/250, Loss: 0.0189\n",
      "Epoch 187/200, Iteration 100/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 101/250, Loss: 0.0087\n",
      "Epoch 187/200, Iteration 102/250, Loss: 0.0163\n",
      "Epoch 187/200, Iteration 103/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 104/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 105/250, Loss: 0.0206\n",
      "Epoch 187/200, Iteration 106/250, Loss: 0.0126\n",
      "Epoch 187/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 187/200, Iteration 109/250, Loss: 0.0170\n",
      "Epoch 187/200, Iteration 110/250, Loss: 0.0177\n",
      "Epoch 187/200, Iteration 111/250, Loss: 0.0197\n",
      "Epoch 187/200, Iteration 112/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 113/250, Loss: 0.0083\n",
      "Epoch 187/200, Iteration 114/250, Loss: 0.0214\n",
      "Epoch 187/200, Iteration 115/250, Loss: 0.0102\n",
      "Epoch 187/200, Iteration 116/250, Loss: 0.0269\n",
      "Epoch 187/200, Iteration 117/250, Loss: 0.0174\n",
      "Epoch 187/200, Iteration 118/250, Loss: 0.0329\n",
      "Epoch 187/200, Iteration 119/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 120/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 121/250, Loss: 0.0097\n",
      "Epoch 187/200, Iteration 122/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 123/250, Loss: 0.0152\n",
      "Epoch 187/200, Iteration 124/250, Loss: 0.0157\n",
      "Epoch 187/200, Iteration 125/250, Loss: 0.0257\n",
      "Epoch 187/200, Iteration 126/250, Loss: 0.0278\n",
      "Epoch 187/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 187/200, Iteration 128/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 129/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 130/250, Loss: 0.0110\n",
      "Epoch 187/200, Iteration 131/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 132/250, Loss: 0.0138\n",
      "Epoch 187/200, Iteration 133/250, Loss: 0.0302\n",
      "Epoch 187/200, Iteration 134/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 135/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 136/250, Loss: 0.0207\n",
      "Epoch 187/200, Iteration 137/250, Loss: 0.0161\n",
      "Epoch 187/200, Iteration 138/250, Loss: 0.0150\n",
      "Epoch 187/200, Iteration 139/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 140/250, Loss: 0.0220\n",
      "Epoch 187/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 187/200, Iteration 142/250, Loss: 0.0181\n",
      "Epoch 187/200, Iteration 143/250, Loss: 0.0352\n",
      "Epoch 187/200, Iteration 144/250, Loss: 0.0128\n",
      "Epoch 187/200, Iteration 145/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 146/250, Loss: 0.0288\n",
      "Epoch 187/200, Iteration 147/250, Loss: 0.0156\n",
      "Epoch 187/200, Iteration 148/250, Loss: 0.0114\n",
      "Epoch 187/200, Iteration 149/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 150/250, Loss: 0.0157\n",
      "Epoch 187/200, Iteration 151/250, Loss: 0.0084\n",
      "Epoch 187/200, Iteration 152/250, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 153/250, Loss: 0.0079\n",
      "Epoch 187/200, Iteration 154/250, Loss: 0.0151\n",
      "Epoch 187/200, Iteration 155/250, Loss: 0.0123\n",
      "Epoch 187/200, Iteration 156/250, Loss: 0.0226\n",
      "Epoch 187/200, Iteration 157/250, Loss: 0.0331\n",
      "Epoch 187/200, Iteration 158/250, Loss: 0.0067\n",
      "Epoch 187/200, Iteration 159/250, Loss: 0.0066\n",
      "Epoch 187/200, Iteration 160/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 161/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 162/250, Loss: 0.0288\n",
      "Epoch 187/200, Iteration 163/250, Loss: 0.0149\n",
      "Epoch 187/200, Iteration 164/250, Loss: 0.0094\n",
      "Epoch 187/200, Iteration 165/250, Loss: 0.0318\n",
      "Epoch 187/200, Iteration 166/250, Loss: 0.0120\n",
      "Epoch 187/200, Iteration 167/250, Loss: 0.0077\n",
      "Epoch 187/200, Iteration 168/250, Loss: 0.0164\n",
      "Epoch 187/200, Iteration 169/250, Loss: 0.0106\n",
      "Epoch 187/200, Iteration 170/250, Loss: 0.0164\n",
      "Epoch 187/200, Iteration 171/250, Loss: 0.0145\n",
      "Epoch 187/200, Iteration 172/250, Loss: 0.0062\n",
      "Epoch 187/200, Iteration 173/250, Loss: 0.0183\n",
      "Epoch 187/200, Iteration 174/250, Loss: 0.0183\n",
      "Epoch 187/200, Iteration 175/250, Loss: 0.0110\n",
      "Epoch 187/200, Iteration 176/250, Loss: 0.0196\n",
      "Epoch 187/200, Iteration 177/250, Loss: 0.0134\n",
      "Epoch 187/200, Iteration 178/250, Loss: 0.0264\n",
      "Epoch 187/200, Iteration 179/250, Loss: 0.0111\n",
      "Epoch 187/200, Iteration 180/250, Loss: 0.0137\n",
      "Epoch 187/200, Iteration 181/250, Loss: 0.0381\n",
      "Epoch 187/200, Iteration 182/250, Loss: 0.0354\n",
      "Epoch 187/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 184/250, Loss: 0.0076\n",
      "Epoch 187/200, Iteration 185/250, Loss: 0.0277\n",
      "Epoch 187/200, Iteration 186/250, Loss: 0.0149\n",
      "Epoch 187/200, Iteration 187/250, Loss: 0.0208\n",
      "Epoch 187/200, Iteration 188/250, Loss: 0.0125\n",
      "Epoch 187/200, Iteration 189/250, Loss: 0.0111\n",
      "Epoch 187/200, Iteration 190/250, Loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200, Iteration 191/250, Loss: 0.0059\n",
      "Epoch 187/200, Iteration 192/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 193/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 194/250, Loss: 0.0146\n",
      "Epoch 187/200, Iteration 195/250, Loss: 0.0117\n",
      "Epoch 187/200, Iteration 196/250, Loss: 0.0167\n",
      "Epoch 187/200, Iteration 197/250, Loss: 0.0145\n",
      "Epoch 187/200, Iteration 198/250, Loss: 0.0117\n",
      "Epoch 187/200, Iteration 199/250, Loss: 0.0092\n",
      "Epoch 187/200, Iteration 200/250, Loss: 0.0228\n",
      "Epoch 187/200, Iteration 201/250, Loss: 0.0178\n",
      "Epoch 187/200, Iteration 202/250, Loss: 0.0118\n",
      "Epoch 187/200, Iteration 203/250, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 204/250, Loss: 0.0093\n",
      "Epoch 187/200, Iteration 205/250, Loss: 0.0159\n",
      "Epoch 187/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 187/200, Iteration 207/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 208/250, Loss: 0.0092\n",
      "Epoch 187/200, Iteration 209/250, Loss: 0.0310\n",
      "Epoch 187/200, Iteration 210/250, Loss: 0.0145\n",
      "Epoch 187/200, Iteration 211/250, Loss: 0.0351\n",
      "Epoch 187/200, Iteration 212/250, Loss: 0.0092\n",
      "Epoch 187/200, Iteration 213/250, Loss: 0.0130\n",
      "Epoch 187/200, Iteration 214/250, Loss: 0.0295\n",
      "Epoch 187/200, Iteration 215/250, Loss: 0.0271\n",
      "Epoch 187/200, Iteration 216/250, Loss: 0.0155\n",
      "Epoch 187/200, Iteration 217/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 219/250, Loss: 0.0108\n",
      "Epoch 187/200, Iteration 220/250, Loss: 0.0162\n",
      "Epoch 187/200, Iteration 221/250, Loss: 0.0260\n",
      "Epoch 187/200, Iteration 222/250, Loss: 0.0205\n",
      "Epoch 187/200, Iteration 223/250, Loss: 0.0125\n",
      "Epoch 187/200, Iteration 224/250, Loss: 0.0138\n",
      "Epoch 187/200, Iteration 225/250, Loss: 0.0198\n",
      "Epoch 187/200, Iteration 226/250, Loss: 0.0070\n",
      "Epoch 187/200, Iteration 227/250, Loss: 0.0162\n",
      "Epoch 187/200, Iteration 228/250, Loss: 0.0232\n",
      "Epoch 187/200, Iteration 229/250, Loss: 0.0147\n",
      "Epoch 187/200, Iteration 230/250, Loss: 0.0134\n",
      "Epoch 187/200, Iteration 231/250, Loss: 0.0137\n",
      "Epoch 187/200, Iteration 232/250, Loss: 0.0079\n",
      "Epoch 187/200, Iteration 233/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 234/250, Loss: 0.0205\n",
      "Epoch 187/200, Iteration 235/250, Loss: 0.0059\n",
      "Epoch 187/200, Iteration 236/250, Loss: 0.0124\n",
      "Epoch 187/200, Iteration 237/250, Loss: 0.0107\n",
      "Epoch 187/200, Iteration 238/250, Loss: 0.0167\n",
      "Epoch 187/200, Iteration 239/250, Loss: 0.0110\n",
      "Epoch 187/200, Iteration 240/250, Loss: 0.0339\n",
      "Epoch 187/200, Iteration 241/250, Loss: 0.0167\n",
      "Epoch 187/200, Iteration 242/250, Loss: 0.0097\n",
      "Epoch 187/200, Iteration 243/250, Loss: 0.0074\n",
      "Epoch 187/200, Iteration 244/250, Loss: 0.0111\n",
      "Epoch 187/200, Iteration 245/250, Loss: 0.0087\n",
      "Epoch 187/200, Iteration 246/250, Loss: 0.0118\n",
      "Epoch 187/200, Iteration 247/250, Loss: 0.0125\n",
      "Epoch 187/200, Iteration 248/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 249/250, Loss: 0.0304\n",
      "Epoch 187/200, Iteration 250/250, Loss: 0.0154\n",
      "Train Error: \n",
      " Accuracy: 90.45%, Avg loss: 0.006143, MRE: 0.589899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.006180, MRE: 0.819514 \n",
      "\n",
      "Epoch 188/200, Iteration 1/250, Loss: 0.0142\n",
      "Epoch 188/200, Iteration 2/250, Loss: 0.0222\n",
      "Epoch 188/200, Iteration 3/250, Loss: 0.0077\n",
      "Epoch 188/200, Iteration 4/250, Loss: 0.0215\n",
      "Epoch 188/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 6/250, Loss: 0.0302\n",
      "Epoch 188/200, Iteration 7/250, Loss: 0.0155\n",
      "Epoch 188/200, Iteration 8/250, Loss: 0.0127\n",
      "Epoch 188/200, Iteration 9/250, Loss: 0.0092\n",
      "Epoch 188/200, Iteration 10/250, Loss: 0.0133\n",
      "Epoch 188/200, Iteration 11/250, Loss: 0.0253\n",
      "Epoch 188/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 188/200, Iteration 13/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 14/250, Loss: 0.0199\n",
      "Epoch 188/200, Iteration 15/250, Loss: 0.0154\n",
      "Epoch 188/200, Iteration 16/250, Loss: 0.0280\n",
      "Epoch 188/200, Iteration 17/250, Loss: 0.0165\n",
      "Epoch 188/200, Iteration 18/250, Loss: 0.0181\n",
      "Epoch 188/200, Iteration 19/250, Loss: 0.0252\n",
      "Epoch 188/200, Iteration 20/250, Loss: 0.0252\n",
      "Epoch 188/200, Iteration 21/250, Loss: 0.0159\n",
      "Epoch 188/200, Iteration 22/250, Loss: 0.0111\n",
      "Epoch 188/200, Iteration 23/250, Loss: 0.0237\n",
      "Epoch 188/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 188/200, Iteration 25/250, Loss: 0.0161\n",
      "Epoch 188/200, Iteration 26/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 27/250, Loss: 0.0198\n",
      "Epoch 188/200, Iteration 28/250, Loss: 0.0137\n",
      "Epoch 188/200, Iteration 29/250, Loss: 0.0102\n",
      "Epoch 188/200, Iteration 30/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 31/250, Loss: 0.0090\n",
      "Epoch 188/200, Iteration 32/250, Loss: 0.0171\n",
      "Epoch 188/200, Iteration 33/250, Loss: 0.0137\n",
      "Epoch 188/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 35/250, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 36/250, Loss: 0.0280\n",
      "Epoch 188/200, Iteration 37/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 38/250, Loss: 0.0179\n",
      "Epoch 188/200, Iteration 39/250, Loss: 0.0136\n",
      "Epoch 188/200, Iteration 40/250, Loss: 0.0081\n",
      "Epoch 188/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 188/200, Iteration 42/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 43/250, Loss: 0.0223\n",
      "Epoch 188/200, Iteration 44/250, Loss: 0.0162\n",
      "Epoch 188/200, Iteration 45/250, Loss: 0.0222\n",
      "Epoch 188/200, Iteration 46/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 47/250, Loss: 0.0343\n",
      "Epoch 188/200, Iteration 48/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 49/250, Loss: 0.0315\n",
      "Epoch 188/200, Iteration 50/250, Loss: 0.0197\n",
      "Epoch 188/200, Iteration 51/250, Loss: 0.0190\n",
      "Epoch 188/200, Iteration 52/250, Loss: 0.0169\n",
      "Epoch 188/200, Iteration 53/250, Loss: 0.0167\n",
      "Epoch 188/200, Iteration 54/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 55/250, Loss: 0.0160\n",
      "Epoch 188/200, Iteration 56/250, Loss: 0.0071\n",
      "Epoch 188/200, Iteration 57/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 58/250, Loss: 0.0058\n",
      "Epoch 188/200, Iteration 59/250, Loss: 0.0143\n",
      "Epoch 188/200, Iteration 60/250, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 61/250, Loss: 0.0106\n",
      "Epoch 188/200, Iteration 62/250, Loss: 0.0098\n",
      "Epoch 188/200, Iteration 63/250, Loss: 0.0279\n",
      "Epoch 188/200, Iteration 64/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 65/250, Loss: 0.0096\n",
      "Epoch 188/200, Iteration 66/250, Loss: 0.0159\n",
      "Epoch 188/200, Iteration 67/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 68/250, Loss: 0.0121\n",
      "Epoch 188/200, Iteration 69/250, Loss: 0.0083\n",
      "Epoch 188/200, Iteration 70/250, Loss: 0.0160\n",
      "Epoch 188/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 188/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 73/250, Loss: 0.0070\n",
      "Epoch 188/200, Iteration 74/250, Loss: 0.0125\n",
      "Epoch 188/200, Iteration 75/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 76/250, Loss: 0.0240\n",
      "Epoch 188/200, Iteration 77/250, Loss: 0.0124\n",
      "Epoch 188/200, Iteration 78/250, Loss: 0.0361\n",
      "Epoch 188/200, Iteration 79/250, Loss: 0.0146\n",
      "Epoch 188/200, Iteration 80/250, Loss: 0.0128\n",
      "Epoch 188/200, Iteration 81/250, Loss: 0.0238\n",
      "Epoch 188/200, Iteration 82/250, Loss: 0.0148\n",
      "Epoch 188/200, Iteration 83/250, Loss: 0.0117\n",
      "Epoch 188/200, Iteration 84/250, Loss: 0.0139\n",
      "Epoch 188/200, Iteration 85/250, Loss: 0.0070\n",
      "Epoch 188/200, Iteration 86/250, Loss: 0.0157\n",
      "Epoch 188/200, Iteration 87/250, Loss: 0.0117\n",
      "Epoch 188/200, Iteration 88/250, Loss: 0.0194\n",
      "Epoch 188/200, Iteration 89/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 90/250, Loss: 0.0142\n",
      "Epoch 188/200, Iteration 91/250, Loss: 0.0338\n",
      "Epoch 188/200, Iteration 92/250, Loss: 0.0292\n",
      "Epoch 188/200, Iteration 93/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 94/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 95/250, Loss: 0.0231\n",
      "Epoch 188/200, Iteration 96/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 97/250, Loss: 0.0159\n",
      "Epoch 188/200, Iteration 98/250, Loss: 0.0212\n",
      "Epoch 188/200, Iteration 99/250, Loss: 0.0158\n",
      "Epoch 188/200, Iteration 100/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 101/250, Loss: 0.0195\n",
      "Epoch 188/200, Iteration 102/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 103/250, Loss: 0.0313\n",
      "Epoch 188/200, Iteration 104/250, Loss: 0.0140\n",
      "Epoch 188/200, Iteration 105/250, Loss: 0.0204\n",
      "Epoch 188/200, Iteration 106/250, Loss: 0.0191\n",
      "Epoch 188/200, Iteration 107/250, Loss: 0.0077\n",
      "Epoch 188/200, Iteration 108/250, Loss: 0.0159\n",
      "Epoch 188/200, Iteration 109/250, Loss: 0.0138\n",
      "Epoch 188/200, Iteration 110/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 111/250, Loss: 0.0280\n",
      "Epoch 188/200, Iteration 112/250, Loss: 0.0173\n",
      "Epoch 188/200, Iteration 113/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 114/250, Loss: 0.0201\n",
      "Epoch 188/200, Iteration 115/250, Loss: 0.0120\n",
      "Epoch 188/200, Iteration 116/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 117/250, Loss: 0.0067\n",
      "Epoch 188/200, Iteration 118/250, Loss: 0.0150\n",
      "Epoch 188/200, Iteration 119/250, Loss: 0.0084\n",
      "Epoch 188/200, Iteration 120/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200, Iteration 121/250, Loss: 0.0133\n",
      "Epoch 188/200, Iteration 122/250, Loss: 0.0072\n",
      "Epoch 188/200, Iteration 123/250, Loss: 0.0120\n",
      "Epoch 188/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 188/200, Iteration 125/250, Loss: 0.0124\n",
      "Epoch 188/200, Iteration 126/250, Loss: 0.0356\n",
      "Epoch 188/200, Iteration 127/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 128/250, Loss: 0.0160\n",
      "Epoch 188/200, Iteration 129/250, Loss: 0.0104\n",
      "Epoch 188/200, Iteration 130/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 131/250, Loss: 0.0112\n",
      "Epoch 188/200, Iteration 132/250, Loss: 0.0278\n",
      "Epoch 188/200, Iteration 133/250, Loss: 0.0171\n",
      "Epoch 188/200, Iteration 134/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 135/250, Loss: 0.0203\n",
      "Epoch 188/200, Iteration 136/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 137/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 138/250, Loss: 0.0137\n",
      "Epoch 188/200, Iteration 139/250, Loss: 0.0221\n",
      "Epoch 188/200, Iteration 140/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 141/250, Loss: 0.0079\n",
      "Epoch 188/200, Iteration 142/250, Loss: 0.0114\n",
      "Epoch 188/200, Iteration 143/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 144/250, Loss: 0.0304\n",
      "Epoch 188/200, Iteration 145/250, Loss: 0.0195\n",
      "Epoch 188/200, Iteration 146/250, Loss: 0.0162\n",
      "Epoch 188/200, Iteration 147/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 148/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 149/250, Loss: 0.0145\n",
      "Epoch 188/200, Iteration 150/250, Loss: 0.0093\n",
      "Epoch 188/200, Iteration 151/250, Loss: 0.0069\n",
      "Epoch 188/200, Iteration 152/250, Loss: 0.0099\n",
      "Epoch 188/200, Iteration 153/250, Loss: 0.0052\n",
      "Epoch 188/200, Iteration 154/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 155/250, Loss: 0.0123\n",
      "Epoch 188/200, Iteration 156/250, Loss: 0.0133\n",
      "Epoch 188/200, Iteration 157/250, Loss: 0.0276\n",
      "Epoch 188/200, Iteration 158/250, Loss: 0.0273\n",
      "Epoch 188/200, Iteration 159/250, Loss: 0.0192\n",
      "Epoch 188/200, Iteration 160/250, Loss: 0.0200\n",
      "Epoch 188/200, Iteration 161/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 162/250, Loss: 0.0059\n",
      "Epoch 188/200, Iteration 163/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 164/250, Loss: 0.0360\n",
      "Epoch 188/200, Iteration 165/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 166/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 167/250, Loss: 0.0098\n",
      "Epoch 188/200, Iteration 168/250, Loss: 0.0089\n",
      "Epoch 188/200, Iteration 169/250, Loss: 0.0125\n",
      "Epoch 188/200, Iteration 170/250, Loss: 0.0118\n",
      "Epoch 188/200, Iteration 171/250, Loss: 0.0084\n",
      "Epoch 188/200, Iteration 172/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 173/250, Loss: 0.0139\n",
      "Epoch 188/200, Iteration 174/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 175/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 176/250, Loss: 0.0243\n",
      "Epoch 188/200, Iteration 177/250, Loss: 0.0204\n",
      "Epoch 188/200, Iteration 178/250, Loss: 0.0088\n",
      "Epoch 188/200, Iteration 179/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 188/200, Iteration 181/250, Loss: 0.0122\n",
      "Epoch 188/200, Iteration 182/250, Loss: 0.0117\n",
      "Epoch 188/200, Iteration 183/250, Loss: 0.0139\n",
      "Epoch 188/200, Iteration 184/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 185/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 186/250, Loss: 0.0071\n",
      "Epoch 188/200, Iteration 187/250, Loss: 0.0063\n",
      "Epoch 188/200, Iteration 188/250, Loss: 0.0217\n",
      "Epoch 188/200, Iteration 189/250, Loss: 0.0144\n",
      "Epoch 188/200, Iteration 190/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 191/250, Loss: 0.0205\n",
      "Epoch 188/200, Iteration 192/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 193/250, Loss: 0.0187\n",
      "Epoch 188/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 188/200, Iteration 195/250, Loss: 0.0121\n",
      "Epoch 188/200, Iteration 196/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 197/250, Loss: 0.0241\n",
      "Epoch 188/200, Iteration 198/250, Loss: 0.0273\n",
      "Epoch 188/200, Iteration 199/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 200/250, Loss: 0.0107\n",
      "Epoch 188/200, Iteration 201/250, Loss: 0.0166\n",
      "Epoch 188/200, Iteration 202/250, Loss: 0.0112\n",
      "Epoch 188/200, Iteration 203/250, Loss: 0.0146\n",
      "Epoch 188/200, Iteration 204/250, Loss: 0.0161\n",
      "Epoch 188/200, Iteration 205/250, Loss: 0.0303\n",
      "Epoch 188/200, Iteration 206/250, Loss: 0.0154\n",
      "Epoch 188/200, Iteration 207/250, Loss: 0.0350\n",
      "Epoch 188/200, Iteration 208/250, Loss: 0.0135\n",
      "Epoch 188/200, Iteration 209/250, Loss: 0.0266\n",
      "Epoch 188/200, Iteration 210/250, Loss: 0.0135\n",
      "Epoch 188/200, Iteration 211/250, Loss: 0.0083\n",
      "Epoch 188/200, Iteration 212/250, Loss: 0.0081\n",
      "Epoch 188/200, Iteration 213/250, Loss: 0.0135\n",
      "Epoch 188/200, Iteration 214/250, Loss: 0.0117\n",
      "Epoch 188/200, Iteration 215/250, Loss: 0.0149\n",
      "Epoch 188/200, Iteration 216/250, Loss: 0.0136\n",
      "Epoch 188/200, Iteration 217/250, Loss: 0.0209\n",
      "Epoch 188/200, Iteration 218/250, Loss: 0.0104\n",
      "Epoch 188/200, Iteration 219/250, Loss: 0.0062\n",
      "Epoch 188/200, Iteration 220/250, Loss: 0.0200\n",
      "Epoch 188/200, Iteration 221/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 222/250, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 223/250, Loss: 0.0187\n",
      "Epoch 188/200, Iteration 224/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 225/250, Loss: 0.0121\n",
      "Epoch 188/200, Iteration 226/250, Loss: 0.0077\n",
      "Epoch 188/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 188/200, Iteration 229/250, Loss: 0.0120\n",
      "Epoch 188/200, Iteration 230/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 231/250, Loss: 0.0083\n",
      "Epoch 188/200, Iteration 232/250, Loss: 0.0092\n",
      "Epoch 188/200, Iteration 233/250, Loss: 0.0307\n",
      "Epoch 188/200, Iteration 234/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 235/250, Loss: 0.0242\n",
      "Epoch 188/200, Iteration 236/250, Loss: 0.0166\n",
      "Epoch 188/200, Iteration 237/250, Loss: 0.0093\n",
      "Epoch 188/200, Iteration 238/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 239/250, Loss: 0.0266\n",
      "Epoch 188/200, Iteration 240/250, Loss: 0.0195\n",
      "Epoch 188/200, Iteration 241/250, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 242/250, Loss: 0.0071\n",
      "Epoch 188/200, Iteration 243/250, Loss: 0.0184\n",
      "Epoch 188/200, Iteration 244/250, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 245/250, Loss: 0.0213\n",
      "Epoch 188/200, Iteration 246/250, Loss: 0.0076\n",
      "Epoch 188/200, Iteration 247/250, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 248/250, Loss: 0.0123\n",
      "Epoch 188/200, Iteration 249/250, Loss: 0.0158\n",
      "Epoch 188/200, Iteration 250/250, Loss: 0.0323\n",
      "Train Error: \n",
      " Accuracy: 80.75%, Avg loss: 0.007423, MRE: 0.582686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.007539, MRE: 0.890577 \n",
      "\n",
      "Epoch 189/200, Iteration 1/250, Loss: 0.0191\n",
      "Epoch 189/200, Iteration 2/250, Loss: 0.0150\n",
      "Epoch 189/200, Iteration 3/250, Loss: 0.0150\n",
      "Epoch 189/200, Iteration 4/250, Loss: 0.0165\n",
      "Epoch 189/200, Iteration 5/250, Loss: 0.0119\n",
      "Epoch 189/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 7/250, Loss: 0.0204\n",
      "Epoch 189/200, Iteration 8/250, Loss: 0.0178\n",
      "Epoch 189/200, Iteration 9/250, Loss: 0.0061\n",
      "Epoch 189/200, Iteration 10/250, Loss: 0.0135\n",
      "Epoch 189/200, Iteration 11/250, Loss: 0.0189\n",
      "Epoch 189/200, Iteration 12/250, Loss: 0.0194\n",
      "Epoch 189/200, Iteration 13/250, Loss: 0.0239\n",
      "Epoch 189/200, Iteration 14/250, Loss: 0.0116\n",
      "Epoch 189/200, Iteration 15/250, Loss: 0.0282\n",
      "Epoch 189/200, Iteration 16/250, Loss: 0.0106\n",
      "Epoch 189/200, Iteration 17/250, Loss: 0.0082\n",
      "Epoch 189/200, Iteration 18/250, Loss: 0.0083\n",
      "Epoch 189/200, Iteration 19/250, Loss: 0.0121\n",
      "Epoch 189/200, Iteration 20/250, Loss: 0.0061\n",
      "Epoch 189/200, Iteration 21/250, Loss: 0.0210\n",
      "Epoch 189/200, Iteration 22/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 23/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 24/250, Loss: 0.0197\n",
      "Epoch 189/200, Iteration 25/250, Loss: 0.0085\n",
      "Epoch 189/200, Iteration 26/250, Loss: 0.0266\n",
      "Epoch 189/200, Iteration 27/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 28/250, Loss: 0.0255\n",
      "Epoch 189/200, Iteration 29/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 30/250, Loss: 0.0133\n",
      "Epoch 189/200, Iteration 31/250, Loss: 0.0092\n",
      "Epoch 189/200, Iteration 32/250, Loss: 0.0269\n",
      "Epoch 189/200, Iteration 33/250, Loss: 0.0214\n",
      "Epoch 189/200, Iteration 34/250, Loss: 0.0073\n",
      "Epoch 189/200, Iteration 35/250, Loss: 0.0212\n",
      "Epoch 189/200, Iteration 36/250, Loss: 0.0126\n",
      "Epoch 189/200, Iteration 37/250, Loss: 0.0155\n",
      "Epoch 189/200, Iteration 38/250, Loss: 0.0086\n",
      "Epoch 189/200, Iteration 39/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 40/250, Loss: 0.0131\n",
      "Epoch 189/200, Iteration 41/250, Loss: 0.0215\n",
      "Epoch 189/200, Iteration 42/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 43/250, Loss: 0.0108\n",
      "Epoch 189/200, Iteration 44/250, Loss: 0.0162\n",
      "Epoch 189/200, Iteration 45/250, Loss: 0.0145\n",
      "Epoch 189/200, Iteration 46/250, Loss: 0.0126\n",
      "Epoch 189/200, Iteration 47/250, Loss: 0.0284\n",
      "Epoch 189/200, Iteration 48/250, Loss: 0.0084\n",
      "Epoch 189/200, Iteration 49/250, Loss: 0.0184\n",
      "Epoch 189/200, Iteration 50/250, Loss: 0.0108\n",
      "Epoch 189/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 189/200, Iteration 52/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 53/250, Loss: 0.0141\n",
      "Epoch 189/200, Iteration 54/250, Loss: 0.0250\n",
      "Epoch 189/200, Iteration 55/250, Loss: 0.0123\n",
      "Epoch 189/200, Iteration 56/250, Loss: 0.0215\n",
      "Epoch 189/200, Iteration 57/250, Loss: 0.0244\n",
      "Epoch 189/200, Iteration 58/250, Loss: 0.0259\n",
      "Epoch 189/200, Iteration 59/250, Loss: 0.0300\n",
      "Epoch 189/200, Iteration 60/250, Loss: 0.0181\n",
      "Epoch 189/200, Iteration 61/250, Loss: 0.0162\n",
      "Epoch 189/200, Iteration 62/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 63/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 64/250, Loss: 0.0157\n",
      "Epoch 189/200, Iteration 65/250, Loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200, Iteration 66/250, Loss: 0.0078\n",
      "Epoch 189/200, Iteration 67/250, Loss: 0.0255\n",
      "Epoch 189/200, Iteration 68/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 69/250, Loss: 0.0067\n",
      "Epoch 189/200, Iteration 70/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 71/250, Loss: 0.0124\n",
      "Epoch 189/200, Iteration 72/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 73/250, Loss: 0.0189\n",
      "Epoch 189/200, Iteration 74/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 75/250, Loss: 0.0116\n",
      "Epoch 189/200, Iteration 76/250, Loss: 0.0119\n",
      "Epoch 189/200, Iteration 77/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 78/250, Loss: 0.0173\n",
      "Epoch 189/200, Iteration 79/250, Loss: 0.0196\n",
      "Epoch 189/200, Iteration 80/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 81/250, Loss: 0.0283\n",
      "Epoch 189/200, Iteration 82/250, Loss: 0.0234\n",
      "Epoch 189/200, Iteration 83/250, Loss: 0.0135\n",
      "Epoch 189/200, Iteration 84/250, Loss: 0.0135\n",
      "Epoch 189/200, Iteration 85/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 86/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 87/250, Loss: 0.0157\n",
      "Epoch 189/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 89/250, Loss: 0.0142\n",
      "Epoch 189/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 189/200, Iteration 91/250, Loss: 0.0154\n",
      "Epoch 189/200, Iteration 92/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 93/250, Loss: 0.0164\n",
      "Epoch 189/200, Iteration 94/250, Loss: 0.0075\n",
      "Epoch 189/200, Iteration 95/250, Loss: 0.0281\n",
      "Epoch 189/200, Iteration 96/250, Loss: 0.0085\n",
      "Epoch 189/200, Iteration 97/250, Loss: 0.0139\n",
      "Epoch 189/200, Iteration 98/250, Loss: 0.0177\n",
      "Epoch 189/200, Iteration 99/250, Loss: 0.0252\n",
      "Epoch 189/200, Iteration 100/250, Loss: 0.0058\n",
      "Epoch 189/200, Iteration 101/250, Loss: 0.0084\n",
      "Epoch 189/200, Iteration 102/250, Loss: 0.0225\n",
      "Epoch 189/200, Iteration 103/250, Loss: 0.0216\n",
      "Epoch 189/200, Iteration 104/250, Loss: 0.0290\n",
      "Epoch 189/200, Iteration 105/250, Loss: 0.0115\n",
      "Epoch 189/200, Iteration 106/250, Loss: 0.0214\n",
      "Epoch 189/200, Iteration 107/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 108/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 109/250, Loss: 0.0098\n",
      "Epoch 189/200, Iteration 110/250, Loss: 0.0126\n",
      "Epoch 189/200, Iteration 111/250, Loss: 0.0148\n",
      "Epoch 189/200, Iteration 112/250, Loss: 0.0079\n",
      "Epoch 189/200, Iteration 113/250, Loss: 0.0211\n",
      "Epoch 189/200, Iteration 114/250, Loss: 0.0218\n",
      "Epoch 189/200, Iteration 115/250, Loss: 0.0136\n",
      "Epoch 189/200, Iteration 116/250, Loss: 0.0168\n",
      "Epoch 189/200, Iteration 117/250, Loss: 0.0104\n",
      "Epoch 189/200, Iteration 118/250, Loss: 0.0086\n",
      "Epoch 189/200, Iteration 119/250, Loss: 0.0069\n",
      "Epoch 189/200, Iteration 120/250, Loss: 0.0236\n",
      "Epoch 189/200, Iteration 121/250, Loss: 0.0124\n",
      "Epoch 189/200, Iteration 122/250, Loss: 0.0086\n",
      "Epoch 189/200, Iteration 123/250, Loss: 0.0232\n",
      "Epoch 189/200, Iteration 124/250, Loss: 0.0227\n",
      "Epoch 189/200, Iteration 125/250, Loss: 0.0520\n",
      "Epoch 189/200, Iteration 126/250, Loss: 0.0109\n",
      "Epoch 189/200, Iteration 127/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 128/250, Loss: 0.0078\n",
      "Epoch 189/200, Iteration 129/250, Loss: 0.0051\n",
      "Epoch 189/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 189/200, Iteration 131/250, Loss: 0.0202\n",
      "Epoch 189/200, Iteration 132/250, Loss: 0.0210\n",
      "Epoch 189/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 134/250, Loss: 0.0092\n",
      "Epoch 189/200, Iteration 135/250, Loss: 0.0191\n",
      "Epoch 189/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 189/200, Iteration 137/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 138/250, Loss: 0.0126\n",
      "Epoch 189/200, Iteration 139/250, Loss: 0.0148\n",
      "Epoch 189/200, Iteration 140/250, Loss: 0.0103\n",
      "Epoch 189/200, Iteration 141/250, Loss: 0.0119\n",
      "Epoch 189/200, Iteration 142/250, Loss: 0.0106\n",
      "Epoch 189/200, Iteration 143/250, Loss: 0.0128\n",
      "Epoch 189/200, Iteration 144/250, Loss: 0.0057\n",
      "Epoch 189/200, Iteration 145/250, Loss: 0.0060\n",
      "Epoch 189/200, Iteration 146/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 189/200, Iteration 148/250, Loss: 0.0155\n",
      "Epoch 189/200, Iteration 149/250, Loss: 0.0072\n",
      "Epoch 189/200, Iteration 150/250, Loss: 0.0082\n",
      "Epoch 189/200, Iteration 151/250, Loss: 0.0194\n",
      "Epoch 189/200, Iteration 152/250, Loss: 0.0136\n",
      "Epoch 189/200, Iteration 153/250, Loss: 0.0357\n",
      "Epoch 189/200, Iteration 154/250, Loss: 0.0275\n",
      "Epoch 189/200, Iteration 155/250, Loss: 0.0350\n",
      "Epoch 189/200, Iteration 156/250, Loss: 0.0141\n",
      "Epoch 189/200, Iteration 157/250, Loss: 0.0169\n",
      "Epoch 189/200, Iteration 158/250, Loss: 0.0082\n",
      "Epoch 189/200, Iteration 159/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 160/250, Loss: 0.0104\n",
      "Epoch 189/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 189/200, Iteration 162/250, Loss: 0.0187\n",
      "Epoch 189/200, Iteration 163/250, Loss: 0.0129\n",
      "Epoch 189/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 165/250, Loss: 0.0290\n",
      "Epoch 189/200, Iteration 166/250, Loss: 0.0209\n",
      "Epoch 189/200, Iteration 167/250, Loss: 0.0240\n",
      "Epoch 189/200, Iteration 168/250, Loss: 0.0293\n",
      "Epoch 189/200, Iteration 169/250, Loss: 0.0170\n",
      "Epoch 189/200, Iteration 170/250, Loss: 0.0174\n",
      "Epoch 189/200, Iteration 171/250, Loss: 0.0061\n",
      "Epoch 189/200, Iteration 172/250, Loss: 0.0153\n",
      "Epoch 189/200, Iteration 173/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 174/250, Loss: 0.0080\n",
      "Epoch 189/200, Iteration 175/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 176/250, Loss: 0.0133\n",
      "Epoch 189/200, Iteration 177/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 178/250, Loss: 0.0189\n",
      "Epoch 189/200, Iteration 179/250, Loss: 0.0145\n",
      "Epoch 189/200, Iteration 180/250, Loss: 0.0088\n",
      "Epoch 189/200, Iteration 181/250, Loss: 0.0063\n",
      "Epoch 189/200, Iteration 182/250, Loss: 0.0125\n",
      "Epoch 189/200, Iteration 183/250, Loss: 0.0075\n",
      "Epoch 189/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 189/200, Iteration 185/250, Loss: 0.0294\n",
      "Epoch 189/200, Iteration 186/250, Loss: 0.0174\n",
      "Epoch 189/200, Iteration 187/250, Loss: 0.0193\n",
      "Epoch 189/200, Iteration 188/250, Loss: 0.0144\n",
      "Epoch 189/200, Iteration 189/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 190/250, Loss: 0.0221\n",
      "Epoch 189/200, Iteration 191/250, Loss: 0.0086\n",
      "Epoch 189/200, Iteration 192/250, Loss: 0.0061\n",
      "Epoch 189/200, Iteration 193/250, Loss: 0.0206\n",
      "Epoch 189/200, Iteration 194/250, Loss: 0.0114\n",
      "Epoch 189/200, Iteration 195/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 196/250, Loss: 0.0137\n",
      "Epoch 189/200, Iteration 197/250, Loss: 0.0178\n",
      "Epoch 189/200, Iteration 198/250, Loss: 0.0123\n",
      "Epoch 189/200, Iteration 199/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 189/200, Iteration 201/250, Loss: 0.0245\n",
      "Epoch 189/200, Iteration 202/250, Loss: 0.0235\n",
      "Epoch 189/200, Iteration 203/250, Loss: 0.0232\n",
      "Epoch 189/200, Iteration 204/250, Loss: 0.0236\n",
      "Epoch 189/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 206/250, Loss: 0.0264\n",
      "Epoch 189/200, Iteration 207/250, Loss: 0.0108\n",
      "Epoch 189/200, Iteration 208/250, Loss: 0.0135\n",
      "Epoch 189/200, Iteration 209/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 210/250, Loss: 0.0223\n",
      "Epoch 189/200, Iteration 211/250, Loss: 0.0156\n",
      "Epoch 189/200, Iteration 212/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 213/250, Loss: 0.0072\n",
      "Epoch 189/200, Iteration 214/250, Loss: 0.0084\n",
      "Epoch 189/200, Iteration 215/250, Loss: 0.0192\n",
      "Epoch 189/200, Iteration 216/250, Loss: 0.0159\n",
      "Epoch 189/200, Iteration 217/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 218/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 219/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 220/250, Loss: 0.0097\n",
      "Epoch 189/200, Iteration 221/250, Loss: 0.0156\n",
      "Epoch 189/200, Iteration 222/250, Loss: 0.0117\n",
      "Epoch 189/200, Iteration 223/250, Loss: 0.0225\n",
      "Epoch 189/200, Iteration 224/250, Loss: 0.0133\n",
      "Epoch 189/200, Iteration 225/250, Loss: 0.0091\n",
      "Epoch 189/200, Iteration 226/250, Loss: 0.0075\n",
      "Epoch 189/200, Iteration 227/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 228/250, Loss: 0.0366\n",
      "Epoch 189/200, Iteration 229/250, Loss: 0.0072\n",
      "Epoch 189/200, Iteration 230/250, Loss: 0.0206\n",
      "Epoch 189/200, Iteration 231/250, Loss: 0.0187\n",
      "Epoch 189/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 189/200, Iteration 233/250, Loss: 0.0099\n",
      "Epoch 189/200, Iteration 234/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 235/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 236/250, Loss: 0.0146\n",
      "Epoch 189/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 189/200, Iteration 238/250, Loss: 0.0260\n",
      "Epoch 189/200, Iteration 239/250, Loss: 0.0099\n",
      "Epoch 189/200, Iteration 240/250, Loss: 0.0156\n",
      "Epoch 189/200, Iteration 241/250, Loss: 0.0109\n",
      "Epoch 189/200, Iteration 242/250, Loss: 0.0221\n",
      "Epoch 189/200, Iteration 243/250, Loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200, Iteration 244/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 245/250, Loss: 0.0124\n",
      "Epoch 189/200, Iteration 246/250, Loss: 0.0173\n",
      "Epoch 189/200, Iteration 247/250, Loss: 0.0125\n",
      "Epoch 189/200, Iteration 248/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 249/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 250/250, Loss: 0.0208\n",
      "Train Error: \n",
      " Accuracy: 91.47%, Avg loss: 0.005816, MRE: 0.596606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.005877, MRE: 0.903695 \n",
      "\n",
      "Epoch 190/200, Iteration 1/250, Loss: 0.0079\n",
      "Epoch 190/200, Iteration 2/250, Loss: 0.0064\n",
      "Epoch 190/200, Iteration 3/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 4/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 190/200, Iteration 6/250, Loss: 0.0113\n",
      "Epoch 190/200, Iteration 7/250, Loss: 0.0247\n",
      "Epoch 190/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 9/250, Loss: 0.0320\n",
      "Epoch 190/200, Iteration 10/250, Loss: 0.0139\n",
      "Epoch 190/200, Iteration 11/250, Loss: 0.0127\n",
      "Epoch 190/200, Iteration 12/250, Loss: 0.0113\n",
      "Epoch 190/200, Iteration 13/250, Loss: 0.0105\n",
      "Epoch 190/200, Iteration 14/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 15/250, Loss: 0.0077\n",
      "Epoch 190/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 190/200, Iteration 17/250, Loss: 0.0096\n",
      "Epoch 190/200, Iteration 18/250, Loss: 0.0315\n",
      "Epoch 190/200, Iteration 19/250, Loss: 0.0178\n",
      "Epoch 190/200, Iteration 20/250, Loss: 0.0103\n",
      "Epoch 190/200, Iteration 21/250, Loss: 0.0160\n",
      "Epoch 190/200, Iteration 22/250, Loss: 0.0069\n",
      "Epoch 190/200, Iteration 23/250, Loss: 0.0122\n",
      "Epoch 190/200, Iteration 24/250, Loss: 0.0135\n",
      "Epoch 190/200, Iteration 25/250, Loss: 0.0152\n",
      "Epoch 190/200, Iteration 26/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 190/200, Iteration 28/250, Loss: 0.0113\n",
      "Epoch 190/200, Iteration 29/250, Loss: 0.0180\n",
      "Epoch 190/200, Iteration 30/250, Loss: 0.0098\n",
      "Epoch 190/200, Iteration 31/250, Loss: 0.0138\n",
      "Epoch 190/200, Iteration 32/250, Loss: 0.0195\n",
      "Epoch 190/200, Iteration 33/250, Loss: 0.0104\n",
      "Epoch 190/200, Iteration 34/250, Loss: 0.0196\n",
      "Epoch 190/200, Iteration 35/250, Loss: 0.0131\n",
      "Epoch 190/200, Iteration 36/250, Loss: 0.0081\n",
      "Epoch 190/200, Iteration 37/250, Loss: 0.0273\n",
      "Epoch 190/200, Iteration 38/250, Loss: 0.0176\n",
      "Epoch 190/200, Iteration 39/250, Loss: 0.0122\n",
      "Epoch 190/200, Iteration 40/250, Loss: 0.0191\n",
      "Epoch 190/200, Iteration 41/250, Loss: 0.0228\n",
      "Epoch 190/200, Iteration 42/250, Loss: 0.0197\n",
      "Epoch 190/200, Iteration 43/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 44/250, Loss: 0.0112\n",
      "Epoch 190/200, Iteration 45/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 46/250, Loss: 0.0256\n",
      "Epoch 190/200, Iteration 47/250, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 48/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 50/250, Loss: 0.0055\n",
      "Epoch 190/200, Iteration 51/250, Loss: 0.0102\n",
      "Epoch 190/200, Iteration 52/250, Loss: 0.0175\n",
      "Epoch 190/200, Iteration 53/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 54/250, Loss: 0.0180\n",
      "Epoch 190/200, Iteration 55/250, Loss: 0.0058\n",
      "Epoch 190/200, Iteration 56/250, Loss: 0.0079\n",
      "Epoch 190/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 190/200, Iteration 58/250, Loss: 0.0169\n",
      "Epoch 190/200, Iteration 59/250, Loss: 0.0248\n",
      "Epoch 190/200, Iteration 60/250, Loss: 0.0145\n",
      "Epoch 190/200, Iteration 61/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 62/250, Loss: 0.0282\n",
      "Epoch 190/200, Iteration 63/250, Loss: 0.0321\n",
      "Epoch 190/200, Iteration 64/250, Loss: 0.0205\n",
      "Epoch 190/200, Iteration 65/250, Loss: 0.0377\n",
      "Epoch 190/200, Iteration 66/250, Loss: 0.0192\n",
      "Epoch 190/200, Iteration 67/250, Loss: 0.0336\n",
      "Epoch 190/200, Iteration 68/250, Loss: 0.0185\n",
      "Epoch 190/200, Iteration 69/250, Loss: 0.0170\n",
      "Epoch 190/200, Iteration 70/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 71/250, Loss: 0.0098\n",
      "Epoch 190/200, Iteration 72/250, Loss: 0.0173\n",
      "Epoch 190/200, Iteration 73/250, Loss: 0.0086\n",
      "Epoch 190/200, Iteration 74/250, Loss: 0.0129\n",
      "Epoch 190/200, Iteration 75/250, Loss: 0.0069\n",
      "Epoch 190/200, Iteration 76/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 78/250, Loss: 0.0130\n",
      "Epoch 190/200, Iteration 79/250, Loss: 0.0064\n",
      "Epoch 190/200, Iteration 80/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 81/250, Loss: 0.0161\n",
      "Epoch 190/200, Iteration 82/250, Loss: 0.0137\n",
      "Epoch 190/200, Iteration 83/250, Loss: 0.0190\n",
      "Epoch 190/200, Iteration 84/250, Loss: 0.0331\n",
      "Epoch 190/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 86/250, Loss: 0.0153\n",
      "Epoch 190/200, Iteration 87/250, Loss: 0.0071\n",
      "Epoch 190/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 89/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 90/250, Loss: 0.0206\n",
      "Epoch 190/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 190/200, Iteration 92/250, Loss: 0.0215\n",
      "Epoch 190/200, Iteration 93/250, Loss: 0.0075\n",
      "Epoch 190/200, Iteration 94/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 95/250, Loss: 0.0270\n",
      "Epoch 190/200, Iteration 96/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 97/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 98/250, Loss: 0.0166\n",
      "Epoch 190/200, Iteration 99/250, Loss: 0.0142\n",
      "Epoch 190/200, Iteration 100/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 101/250, Loss: 0.0104\n",
      "Epoch 190/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 190/200, Iteration 103/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 104/250, Loss: 0.0118\n",
      "Epoch 190/200, Iteration 105/250, Loss: 0.0096\n",
      "Epoch 190/200, Iteration 106/250, Loss: 0.0101\n",
      "Epoch 190/200, Iteration 107/250, Loss: 0.0107\n",
      "Epoch 190/200, Iteration 108/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 109/250, Loss: 0.0144\n",
      "Epoch 190/200, Iteration 110/250, Loss: 0.0063\n",
      "Epoch 190/200, Iteration 111/250, Loss: 0.0165\n",
      "Epoch 190/200, Iteration 112/250, Loss: 0.0204\n",
      "Epoch 190/200, Iteration 113/250, Loss: 0.0095\n",
      "Epoch 190/200, Iteration 114/250, Loss: 0.0286\n",
      "Epoch 190/200, Iteration 115/250, Loss: 0.0422\n",
      "Epoch 190/200, Iteration 116/250, Loss: 0.0154\n",
      "Epoch 190/200, Iteration 117/250, Loss: 0.0069\n",
      "Epoch 190/200, Iteration 118/250, Loss: 0.0186\n",
      "Epoch 190/200, Iteration 119/250, Loss: 0.0110\n",
      "Epoch 190/200, Iteration 120/250, Loss: 0.0087\n",
      "Epoch 190/200, Iteration 121/250, Loss: 0.0097\n",
      "Epoch 190/200, Iteration 122/250, Loss: 0.0130\n",
      "Epoch 190/200, Iteration 123/250, Loss: 0.0163\n",
      "Epoch 190/200, Iteration 124/250, Loss: 0.0236\n",
      "Epoch 190/200, Iteration 125/250, Loss: 0.0086\n",
      "Epoch 190/200, Iteration 126/250, Loss: 0.0100\n",
      "Epoch 190/200, Iteration 127/250, Loss: 0.0269\n",
      "Epoch 190/200, Iteration 128/250, Loss: 0.0129\n",
      "Epoch 190/200, Iteration 129/250, Loss: 0.0209\n",
      "Epoch 190/200, Iteration 130/250, Loss: 0.0087\n",
      "Epoch 190/200, Iteration 131/250, Loss: 0.0185\n",
      "Epoch 190/200, Iteration 132/250, Loss: 0.0182\n",
      "Epoch 190/200, Iteration 133/250, Loss: 0.0109\n",
      "Epoch 190/200, Iteration 134/250, Loss: 0.0141\n",
      "Epoch 190/200, Iteration 135/250, Loss: 0.0170\n",
      "Epoch 190/200, Iteration 136/250, Loss: 0.0165\n",
      "Epoch 190/200, Iteration 137/250, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 138/250, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 139/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 140/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 141/250, Loss: 0.0097\n",
      "Epoch 190/200, Iteration 142/250, Loss: 0.0128\n",
      "Epoch 190/200, Iteration 143/250, Loss: 0.0152\n",
      "Epoch 190/200, Iteration 144/250, Loss: 0.0071\n",
      "Epoch 190/200, Iteration 145/250, Loss: 0.0238\n",
      "Epoch 190/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 190/200, Iteration 147/250, Loss: 0.0095\n",
      "Epoch 190/200, Iteration 148/250, Loss: 0.0300\n",
      "Epoch 190/200, Iteration 149/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 150/250, Loss: 0.0107\n",
      "Epoch 190/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 152/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 153/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 154/250, Loss: 0.0225\n",
      "Epoch 190/200, Iteration 155/250, Loss: 0.0125\n",
      "Epoch 190/200, Iteration 156/250, Loss: 0.0098\n",
      "Epoch 190/200, Iteration 157/250, Loss: 0.0118\n",
      "Epoch 190/200, Iteration 158/250, Loss: 0.0112\n",
      "Epoch 190/200, Iteration 159/250, Loss: 0.0104\n",
      "Epoch 190/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 190/200, Iteration 161/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 162/250, Loss: 0.0252\n",
      "Epoch 190/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 164/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 165/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 166/250, Loss: 0.0133\n",
      "Epoch 190/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 168/250, Loss: 0.0234\n",
      "Epoch 190/200, Iteration 169/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 170/250, Loss: 0.0165\n",
      "Epoch 190/200, Iteration 171/250, Loss: 0.0073\n",
      "Epoch 190/200, Iteration 172/250, Loss: 0.0186\n",
      "Epoch 190/200, Iteration 173/250, Loss: 0.0098\n",
      "Epoch 190/200, Iteration 174/250, Loss: 0.0077\n",
      "Epoch 190/200, Iteration 175/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 176/250, Loss: 0.0144\n",
      "Epoch 190/200, Iteration 177/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 178/250, Loss: 0.0138\n",
      "Epoch 190/200, Iteration 179/250, Loss: 0.0144\n",
      "Epoch 190/200, Iteration 180/250, Loss: 0.0107\n",
      "Epoch 190/200, Iteration 181/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 182/250, Loss: 0.0164\n",
      "Epoch 190/200, Iteration 183/250, Loss: 0.0062\n",
      "Epoch 190/200, Iteration 184/250, Loss: 0.0060\n",
      "Epoch 190/200, Iteration 185/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 186/250, Loss: 0.0138\n",
      "Epoch 190/200, Iteration 187/250, Loss: 0.0214\n",
      "Epoch 190/200, Iteration 188/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 189/250, Loss: 0.0298\n",
      "Epoch 190/200, Iteration 190/250, Loss: 0.0125\n",
      "Epoch 190/200, Iteration 191/250, Loss: 0.0246\n",
      "Epoch 190/200, Iteration 192/250, Loss: 0.0282\n",
      "Epoch 190/200, Iteration 193/250, Loss: 0.0159\n",
      "Epoch 190/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 190/200, Iteration 195/250, Loss: 0.0067\n",
      "Epoch 190/200, Iteration 196/250, Loss: 0.0090\n",
      "Epoch 190/200, Iteration 197/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 198/250, Loss: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 190/200, Iteration 200/250, Loss: 0.0142\n",
      "Epoch 190/200, Iteration 201/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 202/250, Loss: 0.0192\n",
      "Epoch 190/200, Iteration 203/250, Loss: 0.0426\n",
      "Epoch 190/200, Iteration 204/250, Loss: 0.0077\n",
      "Epoch 190/200, Iteration 205/250, Loss: 0.0259\n",
      "Epoch 190/200, Iteration 206/250, Loss: 0.0156\n",
      "Epoch 190/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 190/200, Iteration 208/250, Loss: 0.0164\n",
      "Epoch 190/200, Iteration 209/250, Loss: 0.0072\n",
      "Epoch 190/200, Iteration 210/250, Loss: 0.0104\n",
      "Epoch 190/200, Iteration 211/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 190/200, Iteration 213/250, Loss: 0.0160\n",
      "Epoch 190/200, Iteration 214/250, Loss: 0.0089\n",
      "Epoch 190/200, Iteration 215/250, Loss: 0.0255\n",
      "Epoch 190/200, Iteration 216/250, Loss: 0.0098\n",
      "Epoch 190/200, Iteration 217/250, Loss: 0.0071\n",
      "Epoch 190/200, Iteration 218/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 219/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 220/250, Loss: 0.0234\n",
      "Epoch 190/200, Iteration 221/250, Loss: 0.0230\n",
      "Epoch 190/200, Iteration 222/250, Loss: 0.0133\n",
      "Epoch 190/200, Iteration 223/250, Loss: 0.0142\n",
      "Epoch 190/200, Iteration 224/250, Loss: 0.0170\n",
      "Epoch 190/200, Iteration 225/250, Loss: 0.0115\n",
      "Epoch 190/200, Iteration 226/250, Loss: 0.0247\n",
      "Epoch 190/200, Iteration 227/250, Loss: 0.0332\n",
      "Epoch 190/200, Iteration 228/250, Loss: 0.0118\n",
      "Epoch 190/200, Iteration 229/250, Loss: 0.0262\n",
      "Epoch 190/200, Iteration 230/250, Loss: 0.0086\n",
      "Epoch 190/200, Iteration 231/250, Loss: 0.0231\n",
      "Epoch 190/200, Iteration 232/250, Loss: 0.0226\n",
      "Epoch 190/200, Iteration 233/250, Loss: 0.0248\n",
      "Epoch 190/200, Iteration 234/250, Loss: 0.0079\n",
      "Epoch 190/200, Iteration 235/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 236/250, Loss: 0.0163\n",
      "Epoch 190/200, Iteration 237/250, Loss: 0.0078\n",
      "Epoch 190/200, Iteration 238/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 239/250, Loss: 0.0222\n",
      "Epoch 190/200, Iteration 240/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 241/250, Loss: 0.0305\n",
      "Epoch 190/200, Iteration 242/250, Loss: 0.0142\n",
      "Epoch 190/200, Iteration 243/250, Loss: 0.0119\n",
      "Epoch 190/200, Iteration 244/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 246/250, Loss: 0.0114\n",
      "Epoch 190/200, Iteration 247/250, Loss: 0.0095\n",
      "Epoch 190/200, Iteration 248/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 249/250, Loss: 0.0052\n",
      "Epoch 190/200, Iteration 250/250, Loss: 0.0212\n",
      "Train Error: \n",
      " Accuracy: 96.35%, Avg loss: 0.005809, MRE: 0.606364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.95%, Avg loss: 0.005811, MRE: 1.010652 \n",
      "\n",
      "Epoch 191/200, Iteration 1/250, Loss: 0.0094\n",
      "Epoch 191/200, Iteration 2/250, Loss: 0.0104\n",
      "Epoch 191/200, Iteration 3/250, Loss: 0.0092\n",
      "Epoch 191/200, Iteration 4/250, Loss: 0.0173\n",
      "Epoch 191/200, Iteration 5/250, Loss: 0.0110\n",
      "Epoch 191/200, Iteration 6/250, Loss: 0.0161\n",
      "Epoch 191/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 191/200, Iteration 8/250, Loss: 0.0293\n",
      "Epoch 191/200, Iteration 9/250, Loss: 0.0180\n",
      "Epoch 191/200, Iteration 10/250, Loss: 0.0144\n",
      "Epoch 191/200, Iteration 11/250, Loss: 0.0134\n",
      "Epoch 191/200, Iteration 12/250, Loss: 0.0076\n",
      "Epoch 191/200, Iteration 13/250, Loss: 0.0232\n",
      "Epoch 191/200, Iteration 14/250, Loss: 0.0081\n",
      "Epoch 191/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 16/250, Loss: 0.0173\n",
      "Epoch 191/200, Iteration 17/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 18/250, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 191/200, Iteration 20/250, Loss: 0.0096\n",
      "Epoch 191/200, Iteration 21/250, Loss: 0.0134\n",
      "Epoch 191/200, Iteration 22/250, Loss: 0.0091\n",
      "Epoch 191/200, Iteration 23/250, Loss: 0.0246\n",
      "Epoch 191/200, Iteration 24/250, Loss: 0.0067\n",
      "Epoch 191/200, Iteration 25/250, Loss: 0.0190\n",
      "Epoch 191/200, Iteration 26/250, Loss: 0.0064\n",
      "Epoch 191/200, Iteration 27/250, Loss: 0.0138\n",
      "Epoch 191/200, Iteration 28/250, Loss: 0.0237\n",
      "Epoch 191/200, Iteration 29/250, Loss: 0.0162\n",
      "Epoch 191/200, Iteration 30/250, Loss: 0.0131\n",
      "Epoch 191/200, Iteration 31/250, Loss: 0.0070\n",
      "Epoch 191/200, Iteration 32/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 33/250, Loss: 0.0162\n",
      "Epoch 191/200, Iteration 34/250, Loss: 0.0067\n",
      "Epoch 191/200, Iteration 35/250, Loss: 0.0115\n",
      "Epoch 191/200, Iteration 36/250, Loss: 0.0084\n",
      "Epoch 191/200, Iteration 37/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 38/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 39/250, Loss: 0.0107\n",
      "Epoch 191/200, Iteration 40/250, Loss: 0.0227\n",
      "Epoch 191/200, Iteration 41/250, Loss: 0.0069\n",
      "Epoch 191/200, Iteration 42/250, Loss: 0.0275\n",
      "Epoch 191/200, Iteration 43/250, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 44/250, Loss: 0.0235\n",
      "Epoch 191/200, Iteration 45/250, Loss: 0.0255\n",
      "Epoch 191/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 47/250, Loss: 0.0332\n",
      "Epoch 191/200, Iteration 48/250, Loss: 0.0194\n",
      "Epoch 191/200, Iteration 49/250, Loss: 0.0226\n",
      "Epoch 191/200, Iteration 50/250, Loss: 0.0155\n",
      "Epoch 191/200, Iteration 51/250, Loss: 0.0130\n",
      "Epoch 191/200, Iteration 52/250, Loss: 0.0210\n",
      "Epoch 191/200, Iteration 53/250, Loss: 0.0129\n",
      "Epoch 191/200, Iteration 54/250, Loss: 0.0130\n",
      "Epoch 191/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 191/200, Iteration 56/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 57/250, Loss: 0.0111\n",
      "Epoch 191/200, Iteration 58/250, Loss: 0.0187\n",
      "Epoch 191/200, Iteration 59/250, Loss: 0.0196\n",
      "Epoch 191/200, Iteration 60/250, Loss: 0.0262\n",
      "Epoch 191/200, Iteration 61/250, Loss: 0.0193\n",
      "Epoch 191/200, Iteration 62/250, Loss: 0.0070\n",
      "Epoch 191/200, Iteration 63/250, Loss: 0.0077\n",
      "Epoch 191/200, Iteration 64/250, Loss: 0.0263\n",
      "Epoch 191/200, Iteration 65/250, Loss: 0.0227\n",
      "Epoch 191/200, Iteration 66/250, Loss: 0.0242\n",
      "Epoch 191/200, Iteration 67/250, Loss: 0.0123\n",
      "Epoch 191/200, Iteration 68/250, Loss: 0.0120\n",
      "Epoch 191/200, Iteration 69/250, Loss: 0.0139\n",
      "Epoch 191/200, Iteration 70/250, Loss: 0.0165\n",
      "Epoch 191/200, Iteration 71/250, Loss: 0.0144\n",
      "Epoch 191/200, Iteration 72/250, Loss: 0.0120\n",
      "Epoch 191/200, Iteration 73/250, Loss: 0.0389\n",
      "Epoch 191/200, Iteration 74/250, Loss: 0.0459\n",
      "Epoch 191/200, Iteration 75/250, Loss: 0.0081\n",
      "Epoch 191/200, Iteration 76/250, Loss: 0.0172\n",
      "Epoch 191/200, Iteration 77/250, Loss: 0.0271\n",
      "Epoch 191/200, Iteration 78/250, Loss: 0.0134\n",
      "Epoch 191/200, Iteration 79/250, Loss: 0.0160\n",
      "Epoch 191/200, Iteration 80/250, Loss: 0.0124\n",
      "Epoch 191/200, Iteration 81/250, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 82/250, Loss: 0.0082\n",
      "Epoch 191/200, Iteration 83/250, Loss: 0.0376\n",
      "Epoch 191/200, Iteration 84/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 85/250, Loss: 0.0123\n",
      "Epoch 191/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 87/250, Loss: 0.0087\n",
      "Epoch 191/200, Iteration 88/250, Loss: 0.0286\n",
      "Epoch 191/200, Iteration 89/250, Loss: 0.0161\n",
      "Epoch 191/200, Iteration 90/250, Loss: 0.0062\n",
      "Epoch 191/200, Iteration 91/250, Loss: 0.0101\n",
      "Epoch 191/200, Iteration 92/250, Loss: 0.0085\n",
      "Epoch 191/200, Iteration 93/250, Loss: 0.0110\n",
      "Epoch 191/200, Iteration 94/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 95/250, Loss: 0.0141\n",
      "Epoch 191/200, Iteration 96/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 97/250, Loss: 0.0089\n",
      "Epoch 191/200, Iteration 98/250, Loss: 0.0222\n",
      "Epoch 191/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 102/250, Loss: 0.0195\n",
      "Epoch 191/200, Iteration 103/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 104/250, Loss: 0.0201\n",
      "Epoch 191/200, Iteration 105/250, Loss: 0.0207\n",
      "Epoch 191/200, Iteration 106/250, Loss: 0.0079\n",
      "Epoch 191/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 191/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 109/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 110/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 112/250, Loss: 0.0090\n",
      "Epoch 191/200, Iteration 113/250, Loss: 0.0138\n",
      "Epoch 191/200, Iteration 114/250, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 116/250, Loss: 0.0181\n",
      "Epoch 191/200, Iteration 117/250, Loss: 0.0186\n",
      "Epoch 191/200, Iteration 118/250, Loss: 0.0170\n",
      "Epoch 191/200, Iteration 119/250, Loss: 0.0152\n",
      "Epoch 191/200, Iteration 120/250, Loss: 0.0158\n",
      "Epoch 191/200, Iteration 121/250, Loss: 0.0134\n",
      "Epoch 191/200, Iteration 122/250, Loss: 0.0139\n",
      "Epoch 191/200, Iteration 123/250, Loss: 0.0147\n",
      "Epoch 191/200, Iteration 124/250, Loss: 0.0102\n",
      "Epoch 191/200, Iteration 125/250, Loss: 0.0184\n",
      "Epoch 191/200, Iteration 126/250, Loss: 0.0124\n",
      "Epoch 191/200, Iteration 127/250, Loss: 0.0061\n",
      "Epoch 191/200, Iteration 128/250, Loss: 0.0306\n",
      "Epoch 191/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 130/250, Loss: 0.0174\n",
      "Epoch 191/200, Iteration 131/250, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 132/250, Loss: 0.0265\n",
      "Epoch 191/200, Iteration 133/250, Loss: 0.0275\n",
      "Epoch 191/200, Iteration 134/250, Loss: 0.0102\n",
      "Epoch 191/200, Iteration 135/250, Loss: 0.0266\n",
      "Epoch 191/200, Iteration 136/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 137/250, Loss: 0.0132\n",
      "Epoch 191/200, Iteration 138/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 139/250, Loss: 0.0135\n",
      "Epoch 191/200, Iteration 140/250, Loss: 0.0212\n",
      "Epoch 191/200, Iteration 141/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 142/250, Loss: 0.0121\n",
      "Epoch 191/200, Iteration 143/250, Loss: 0.0077\n",
      "Epoch 191/200, Iteration 144/250, Loss: 0.0297\n",
      "Epoch 191/200, Iteration 145/250, Loss: 0.0526\n",
      "Epoch 191/200, Iteration 146/250, Loss: 0.0107\n",
      "Epoch 191/200, Iteration 147/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 148/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 191/200, Iteration 150/250, Loss: 0.0127\n",
      "Epoch 191/200, Iteration 151/250, Loss: 0.0148\n",
      "Epoch 191/200, Iteration 152/250, Loss: 0.0106\n",
      "Epoch 191/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 191/200, Iteration 154/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 155/250, Loss: 0.0196\n",
      "Epoch 191/200, Iteration 156/250, Loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200, Iteration 157/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 158/250, Loss: 0.0065\n",
      "Epoch 191/200, Iteration 159/250, Loss: 0.0135\n",
      "Epoch 191/200, Iteration 160/250, Loss: 0.0220\n",
      "Epoch 191/200, Iteration 161/250, Loss: 0.0292\n",
      "Epoch 191/200, Iteration 162/250, Loss: 0.0080\n",
      "Epoch 191/200, Iteration 163/250, Loss: 0.0466\n",
      "Epoch 191/200, Iteration 164/250, Loss: 0.0080\n",
      "Epoch 191/200, Iteration 165/250, Loss: 0.0118\n",
      "Epoch 191/200, Iteration 166/250, Loss: 0.0148\n",
      "Epoch 191/200, Iteration 167/250, Loss: 0.0077\n",
      "Epoch 191/200, Iteration 168/250, Loss: 0.0097\n",
      "Epoch 191/200, Iteration 169/250, Loss: 0.0125\n",
      "Epoch 191/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 191/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 191/200, Iteration 173/250, Loss: 0.0159\n",
      "Epoch 191/200, Iteration 174/250, Loss: 0.0213\n",
      "Epoch 191/200, Iteration 175/250, Loss: 0.0072\n",
      "Epoch 191/200, Iteration 176/250, Loss: 0.0158\n",
      "Epoch 191/200, Iteration 177/250, Loss: 0.0082\n",
      "Epoch 191/200, Iteration 178/250, Loss: 0.0160\n",
      "Epoch 191/200, Iteration 179/250, Loss: 0.0181\n",
      "Epoch 191/200, Iteration 180/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 181/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 182/250, Loss: 0.0113\n",
      "Epoch 191/200, Iteration 183/250, Loss: 0.0206\n",
      "Epoch 191/200, Iteration 184/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 185/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 186/250, Loss: 0.0183\n",
      "Epoch 191/200, Iteration 187/250, Loss: 0.0098\n",
      "Epoch 191/200, Iteration 188/250, Loss: 0.0143\n",
      "Epoch 191/200, Iteration 189/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 190/250, Loss: 0.0169\n",
      "Epoch 191/200, Iteration 191/250, Loss: 0.0187\n",
      "Epoch 191/200, Iteration 192/250, Loss: 0.0080\n",
      "Epoch 191/200, Iteration 193/250, Loss: 0.0163\n",
      "Epoch 191/200, Iteration 194/250, Loss: 0.0232\n",
      "Epoch 191/200, Iteration 195/250, Loss: 0.0125\n",
      "Epoch 191/200, Iteration 196/250, Loss: 0.0101\n",
      "Epoch 191/200, Iteration 197/250, Loss: 0.0074\n",
      "Epoch 191/200, Iteration 198/250, Loss: 0.0173\n",
      "Epoch 191/200, Iteration 199/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 200/250, Loss: 0.0312\n",
      "Epoch 191/200, Iteration 201/250, Loss: 0.0141\n",
      "Epoch 191/200, Iteration 202/250, Loss: 0.0066\n",
      "Epoch 191/200, Iteration 203/250, Loss: 0.0305\n",
      "Epoch 191/200, Iteration 204/250, Loss: 0.0144\n",
      "Epoch 191/200, Iteration 205/250, Loss: 0.0128\n",
      "Epoch 191/200, Iteration 206/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 207/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 191/200, Iteration 209/250, Loss: 0.0110\n",
      "Epoch 191/200, Iteration 210/250, Loss: 0.0121\n",
      "Epoch 191/200, Iteration 211/250, Loss: 0.0086\n",
      "Epoch 191/200, Iteration 212/250, Loss: 0.0145\n",
      "Epoch 191/200, Iteration 213/250, Loss: 0.0353\n",
      "Epoch 191/200, Iteration 214/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 215/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 216/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 217/250, Loss: 0.0244\n",
      "Epoch 191/200, Iteration 218/250, Loss: 0.0176\n",
      "Epoch 191/200, Iteration 219/250, Loss: 0.0068\n",
      "Epoch 191/200, Iteration 220/250, Loss: 0.0168\n",
      "Epoch 191/200, Iteration 221/250, Loss: 0.0106\n",
      "Epoch 191/200, Iteration 222/250, Loss: 0.0275\n",
      "Epoch 191/200, Iteration 223/250, Loss: 0.0170\n",
      "Epoch 191/200, Iteration 224/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 225/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 226/250, Loss: 0.0065\n",
      "Epoch 191/200, Iteration 227/250, Loss: 0.0082\n",
      "Epoch 191/200, Iteration 228/250, Loss: 0.0113\n",
      "Epoch 191/200, Iteration 229/250, Loss: 0.0142\n",
      "Epoch 191/200, Iteration 230/250, Loss: 0.0275\n",
      "Epoch 191/200, Iteration 231/250, Loss: 0.0181\n",
      "Epoch 191/200, Iteration 232/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 233/250, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 234/250, Loss: 0.0143\n",
      "Epoch 191/200, Iteration 235/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 236/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 237/250, Loss: 0.0187\n",
      "Epoch 191/200, Iteration 238/250, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 239/250, Loss: 0.0110\n",
      "Epoch 191/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 191/200, Iteration 241/250, Loss: 0.0184\n",
      "Epoch 191/200, Iteration 242/250, Loss: 0.0321\n",
      "Epoch 191/200, Iteration 243/250, Loss: 0.0063\n",
      "Epoch 191/200, Iteration 244/250, Loss: 0.0149\n",
      "Epoch 191/200, Iteration 245/250, Loss: 0.0200\n",
      "Epoch 191/200, Iteration 246/250, Loss: 0.0159\n",
      "Epoch 191/200, Iteration 247/250, Loss: 0.0183\n",
      "Epoch 191/200, Iteration 248/250, Loss: 0.0155\n",
      "Epoch 191/200, Iteration 249/250, Loss: 0.0091\n",
      "Epoch 191/200, Iteration 250/250, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 92.85%, Avg loss: 0.005686, MRE: 0.589929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.005742, MRE: 0.982690 \n",
      "\n",
      "Epoch 192/200, Iteration 1/250, Loss: 0.0207\n",
      "Epoch 192/200, Iteration 2/250, Loss: 0.0099\n",
      "Epoch 192/200, Iteration 3/250, Loss: 0.0134\n",
      "Epoch 192/200, Iteration 4/250, Loss: 0.0102\n",
      "Epoch 192/200, Iteration 5/250, Loss: 0.0203\n",
      "Epoch 192/200, Iteration 6/250, Loss: 0.0063\n",
      "Epoch 192/200, Iteration 7/250, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 8/250, Loss: 0.0081\n",
      "Epoch 192/200, Iteration 9/250, Loss: 0.0075\n",
      "Epoch 192/200, Iteration 10/250, Loss: 0.0073\n",
      "Epoch 192/200, Iteration 11/250, Loss: 0.0119\n",
      "Epoch 192/200, Iteration 12/250, Loss: 0.0171\n",
      "Epoch 192/200, Iteration 13/250, Loss: 0.0129\n",
      "Epoch 192/200, Iteration 14/250, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 15/250, Loss: 0.0304\n",
      "Epoch 192/200, Iteration 16/250, Loss: 0.0197\n",
      "Epoch 192/200, Iteration 17/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 18/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 19/250, Loss: 0.0077\n",
      "Epoch 192/200, Iteration 20/250, Loss: 0.0148\n",
      "Epoch 192/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 192/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 192/200, Iteration 23/250, Loss: 0.0154\n",
      "Epoch 192/200, Iteration 24/250, Loss: 0.0204\n",
      "Epoch 192/200, Iteration 25/250, Loss: 0.0205\n",
      "Epoch 192/200, Iteration 26/250, Loss: 0.0238\n",
      "Epoch 192/200, Iteration 27/250, Loss: 0.0102\n",
      "Epoch 192/200, Iteration 28/250, Loss: 0.0115\n",
      "Epoch 192/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 192/200, Iteration 30/250, Loss: 0.0257\n",
      "Epoch 192/200, Iteration 31/250, Loss: 0.0342\n",
      "Epoch 192/200, Iteration 32/250, Loss: 0.0059\n",
      "Epoch 192/200, Iteration 33/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 34/250, Loss: 0.0067\n",
      "Epoch 192/200, Iteration 35/250, Loss: 0.0167\n",
      "Epoch 192/200, Iteration 36/250, Loss: 0.0121\n",
      "Epoch 192/200, Iteration 37/250, Loss: 0.0061\n",
      "Epoch 192/200, Iteration 38/250, Loss: 0.0133\n",
      "Epoch 192/200, Iteration 39/250, Loss: 0.0121\n",
      "Epoch 192/200, Iteration 40/250, Loss: 0.0392\n",
      "Epoch 192/200, Iteration 41/250, Loss: 0.0070\n",
      "Epoch 192/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 192/200, Iteration 43/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 44/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 45/250, Loss: 0.0240\n",
      "Epoch 192/200, Iteration 46/250, Loss: 0.0125\n",
      "Epoch 192/200, Iteration 47/250, Loss: 0.0192\n",
      "Epoch 192/200, Iteration 48/250, Loss: 0.0224\n",
      "Epoch 192/200, Iteration 49/250, Loss: 0.0083\n",
      "Epoch 192/200, Iteration 50/250, Loss: 0.0083\n",
      "Epoch 192/200, Iteration 51/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 52/250, Loss: 0.0271\n",
      "Epoch 192/200, Iteration 53/250, Loss: 0.0198\n",
      "Epoch 192/200, Iteration 54/250, Loss: 0.0225\n",
      "Epoch 192/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 56/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 58/250, Loss: 0.0086\n",
      "Epoch 192/200, Iteration 59/250, Loss: 0.0108\n",
      "Epoch 192/200, Iteration 60/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 192/200, Iteration 62/250, Loss: 0.0138\n",
      "Epoch 192/200, Iteration 63/250, Loss: 0.0184\n",
      "Epoch 192/200, Iteration 64/250, Loss: 0.0075\n",
      "Epoch 192/200, Iteration 65/250, Loss: 0.0184\n",
      "Epoch 192/200, Iteration 66/250, Loss: 0.0108\n",
      "Epoch 192/200, Iteration 67/250, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 68/250, Loss: 0.0105\n",
      "Epoch 192/200, Iteration 69/250, Loss: 0.0100\n",
      "Epoch 192/200, Iteration 70/250, Loss: 0.0115\n",
      "Epoch 192/200, Iteration 71/250, Loss: 0.0147\n",
      "Epoch 192/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 192/200, Iteration 73/250, Loss: 0.0117\n",
      "Epoch 192/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 75/250, Loss: 0.0203\n",
      "Epoch 192/200, Iteration 76/250, Loss: 0.0170\n",
      "Epoch 192/200, Iteration 77/250, Loss: 0.0115\n",
      "Epoch 192/200, Iteration 78/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 79/250, Loss: 0.0075\n",
      "Epoch 192/200, Iteration 80/250, Loss: 0.0160\n",
      "Epoch 192/200, Iteration 81/250, Loss: 0.0080\n",
      "Epoch 192/200, Iteration 82/250, Loss: 0.0134\n",
      "Epoch 192/200, Iteration 83/250, Loss: 0.0223\n",
      "Epoch 192/200, Iteration 84/250, Loss: 0.0105\n",
      "Epoch 192/200, Iteration 85/250, Loss: 0.0076\n",
      "Epoch 192/200, Iteration 86/250, Loss: 0.0368\n",
      "Epoch 192/200, Iteration 87/250, Loss: 0.0222\n",
      "Epoch 192/200, Iteration 88/250, Loss: 0.0250\n",
      "Epoch 192/200, Iteration 89/250, Loss: 0.0318\n",
      "Epoch 192/200, Iteration 90/250, Loss: 0.0185\n",
      "Epoch 192/200, Iteration 91/250, Loss: 0.0108\n",
      "Epoch 192/200, Iteration 92/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 93/250, Loss: 0.0362\n",
      "Epoch 192/200, Iteration 94/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 95/250, Loss: 0.0148\n",
      "Epoch 192/200, Iteration 96/250, Loss: 0.0201\n",
      "Epoch 192/200, Iteration 97/250, Loss: 0.0062\n",
      "Epoch 192/200, Iteration 98/250, Loss: 0.0127\n",
      "Epoch 192/200, Iteration 99/250, Loss: 0.0073\n",
      "Epoch 192/200, Iteration 100/250, Loss: 0.0132\n",
      "Epoch 192/200, Iteration 101/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 102/250, Loss: 0.0146\n",
      "Epoch 192/200, Iteration 103/250, Loss: 0.0113\n",
      "Epoch 192/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 105/250, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 106/250, Loss: 0.0074\n",
      "Epoch 192/200, Iteration 107/250, Loss: 0.0186\n",
      "Epoch 192/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 192/200, Iteration 109/250, Loss: 0.0214\n",
      "Epoch 192/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 192/200, Iteration 111/250, Loss: 0.0107\n",
      "Epoch 192/200, Iteration 112/250, Loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200, Iteration 113/250, Loss: 0.0081\n",
      "Epoch 192/200, Iteration 114/250, Loss: 0.0289\n",
      "Epoch 192/200, Iteration 115/250, Loss: 0.0249\n",
      "Epoch 192/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 117/250, Loss: 0.0103\n",
      "Epoch 192/200, Iteration 118/250, Loss: 0.0079\n",
      "Epoch 192/200, Iteration 119/250, Loss: 0.0251\n",
      "Epoch 192/200, Iteration 120/250, Loss: 0.0077\n",
      "Epoch 192/200, Iteration 121/250, Loss: 0.0088\n",
      "Epoch 192/200, Iteration 122/250, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 123/250, Loss: 0.0135\n",
      "Epoch 192/200, Iteration 124/250, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 125/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 126/250, Loss: 0.0100\n",
      "Epoch 192/200, Iteration 127/250, Loss: 0.0080\n",
      "Epoch 192/200, Iteration 128/250, Loss: 0.0222\n",
      "Epoch 192/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 130/250, Loss: 0.0256\n",
      "Epoch 192/200, Iteration 131/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 192/200, Iteration 133/250, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 134/250, Loss: 0.0217\n",
      "Epoch 192/200, Iteration 135/250, Loss: 0.0081\n",
      "Epoch 192/200, Iteration 136/250, Loss: 0.0155\n",
      "Epoch 192/200, Iteration 137/250, Loss: 0.0076\n",
      "Epoch 192/200, Iteration 138/250, Loss: 0.0067\n",
      "Epoch 192/200, Iteration 139/250, Loss: 0.0198\n",
      "Epoch 192/200, Iteration 140/250, Loss: 0.0229\n",
      "Epoch 192/200, Iteration 141/250, Loss: 0.0100\n",
      "Epoch 192/200, Iteration 142/250, Loss: 0.0145\n",
      "Epoch 192/200, Iteration 143/250, Loss: 0.0246\n",
      "Epoch 192/200, Iteration 144/250, Loss: 0.0181\n",
      "Epoch 192/200, Iteration 145/250, Loss: 0.0335\n",
      "Epoch 192/200, Iteration 146/250, Loss: 0.0068\n",
      "Epoch 192/200, Iteration 147/250, Loss: 0.0555\n",
      "Epoch 192/200, Iteration 148/250, Loss: 0.0154\n",
      "Epoch 192/200, Iteration 149/250, Loss: 0.0279\n",
      "Epoch 192/200, Iteration 150/250, Loss: 0.0163\n",
      "Epoch 192/200, Iteration 151/250, Loss: 0.0099\n",
      "Epoch 192/200, Iteration 152/250, Loss: 0.0100\n",
      "Epoch 192/200, Iteration 153/250, Loss: 0.0270\n",
      "Epoch 192/200, Iteration 154/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 155/250, Loss: 0.0088\n",
      "Epoch 192/200, Iteration 156/250, Loss: 0.0239\n",
      "Epoch 192/200, Iteration 157/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 158/250, Loss: 0.0084\n",
      "Epoch 192/200, Iteration 159/250, Loss: 0.0126\n",
      "Epoch 192/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 192/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 192/200, Iteration 162/250, Loss: 0.0093\n",
      "Epoch 192/200, Iteration 163/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 164/250, Loss: 0.0145\n",
      "Epoch 192/200, Iteration 165/250, Loss: 0.0183\n",
      "Epoch 192/200, Iteration 166/250, Loss: 0.0168\n",
      "Epoch 192/200, Iteration 167/250, Loss: 0.0164\n",
      "Epoch 192/200, Iteration 168/250, Loss: 0.0131\n",
      "Epoch 192/200, Iteration 169/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 170/250, Loss: 0.0212\n",
      "Epoch 192/200, Iteration 171/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 172/250, Loss: 0.0140\n",
      "Epoch 192/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 192/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 192/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 192/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 178/250, Loss: 0.0146\n",
      "Epoch 192/200, Iteration 179/250, Loss: 0.0162\n",
      "Epoch 192/200, Iteration 180/250, Loss: 0.0305\n",
      "Epoch 192/200, Iteration 181/250, Loss: 0.0223\n",
      "Epoch 192/200, Iteration 182/250, Loss: 0.0116\n",
      "Epoch 192/200, Iteration 183/250, Loss: 0.0132\n",
      "Epoch 192/200, Iteration 184/250, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 185/250, Loss: 0.0351\n",
      "Epoch 192/200, Iteration 186/250, Loss: 0.0267\n",
      "Epoch 192/200, Iteration 187/250, Loss: 0.0165\n",
      "Epoch 192/200, Iteration 188/250, Loss: 0.0077\n",
      "Epoch 192/200, Iteration 189/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 190/250, Loss: 0.0097\n",
      "Epoch 192/200, Iteration 191/250, Loss: 0.0161\n",
      "Epoch 192/200, Iteration 192/250, Loss: 0.0051\n",
      "Epoch 192/200, Iteration 193/250, Loss: 0.0156\n",
      "Epoch 192/200, Iteration 194/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 195/250, Loss: 0.0198\n",
      "Epoch 192/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 197/250, Loss: 0.0267\n",
      "Epoch 192/200, Iteration 198/250, Loss: 0.0163\n",
      "Epoch 192/200, Iteration 199/250, Loss: 0.0070\n",
      "Epoch 192/200, Iteration 200/250, Loss: 0.0211\n",
      "Epoch 192/200, Iteration 201/250, Loss: 0.0193\n",
      "Epoch 192/200, Iteration 202/250, Loss: 0.0142\n",
      "Epoch 192/200, Iteration 203/250, Loss: 0.0347\n",
      "Epoch 192/200, Iteration 204/250, Loss: 0.0165\n",
      "Epoch 192/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 192/200, Iteration 206/250, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 207/250, Loss: 0.0121\n",
      "Epoch 192/200, Iteration 208/250, Loss: 0.0083\n",
      "Epoch 192/200, Iteration 209/250, Loss: 0.0346\n",
      "Epoch 192/200, Iteration 210/250, Loss: 0.0182\n",
      "Epoch 192/200, Iteration 211/250, Loss: 0.0171\n",
      "Epoch 192/200, Iteration 212/250, Loss: 0.0190\n",
      "Epoch 192/200, Iteration 213/250, Loss: 0.0202\n",
      "Epoch 192/200, Iteration 214/250, Loss: 0.0124\n",
      "Epoch 192/200, Iteration 215/250, Loss: 0.0081\n",
      "Epoch 192/200, Iteration 216/250, Loss: 0.0183\n",
      "Epoch 192/200, Iteration 217/250, Loss: 0.0121\n",
      "Epoch 192/200, Iteration 218/250, Loss: 0.0062\n",
      "Epoch 192/200, Iteration 219/250, Loss: 0.0202\n",
      "Epoch 192/200, Iteration 220/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 221/250, Loss: 0.0113\n",
      "Epoch 192/200, Iteration 222/250, Loss: 0.0154\n",
      "Epoch 192/200, Iteration 223/250, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 224/250, Loss: 0.0163\n",
      "Epoch 192/200, Iteration 225/250, Loss: 0.0071\n",
      "Epoch 192/200, Iteration 226/250, Loss: 0.0290\n",
      "Epoch 192/200, Iteration 227/250, Loss: 0.0164\n",
      "Epoch 192/200, Iteration 228/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 229/250, Loss: 0.0123\n",
      "Epoch 192/200, Iteration 230/250, Loss: 0.0116\n",
      "Epoch 192/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 192/200, Iteration 232/250, Loss: 0.0129\n",
      "Epoch 192/200, Iteration 233/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 234/250, Loss: 0.0129\n",
      "Epoch 192/200, Iteration 235/250, Loss: 0.0068\n",
      "Epoch 192/200, Iteration 236/250, Loss: 0.0153\n",
      "Epoch 192/200, Iteration 237/250, Loss: 0.0119\n",
      "Epoch 192/200, Iteration 238/250, Loss: 0.0268\n",
      "Epoch 192/200, Iteration 239/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 240/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 241/250, Loss: 0.0125\n",
      "Epoch 192/200, Iteration 242/250, Loss: 0.0157\n",
      "Epoch 192/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 244/250, Loss: 0.0084\n",
      "Epoch 192/200, Iteration 245/250, Loss: 0.0107\n",
      "Epoch 192/200, Iteration 246/250, Loss: 0.0194\n",
      "Epoch 192/200, Iteration 247/250, Loss: 0.0212\n",
      "Epoch 192/200, Iteration 248/250, Loss: 0.0074\n",
      "Epoch 192/200, Iteration 249/250, Loss: 0.0230\n",
      "Epoch 192/200, Iteration 250/250, Loss: 0.0291\n",
      "Train Error: \n",
      " Accuracy: 77.38%, Avg loss: 0.007258, MRE: 0.634506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.15%, Avg loss: 0.007348, MRE: 0.812420 \n",
      "\n",
      "Epoch 193/200, Iteration 1/250, Loss: 0.0292\n",
      "Epoch 193/200, Iteration 2/250, Loss: 0.0088\n",
      "Epoch 193/200, Iteration 3/250, Loss: 0.0128\n",
      "Epoch 193/200, Iteration 4/250, Loss: 0.0220\n",
      "Epoch 193/200, Iteration 5/250, Loss: 0.0104\n",
      "Epoch 193/200, Iteration 6/250, Loss: 0.0194\n",
      "Epoch 193/200, Iteration 7/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 8/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 9/250, Loss: 0.0114\n",
      "Epoch 193/200, Iteration 10/250, Loss: 0.0205\n",
      "Epoch 193/200, Iteration 11/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 12/250, Loss: 0.0147\n",
      "Epoch 193/200, Iteration 13/250, Loss: 0.0194\n",
      "Epoch 193/200, Iteration 14/250, Loss: 0.0085\n",
      "Epoch 193/200, Iteration 15/250, Loss: 0.0114\n",
      "Epoch 193/200, Iteration 16/250, Loss: 0.0128\n",
      "Epoch 193/200, Iteration 17/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 18/250, Loss: 0.0114\n",
      "Epoch 193/200, Iteration 19/250, Loss: 0.0061\n",
      "Epoch 193/200, Iteration 20/250, Loss: 0.0330\n",
      "Epoch 193/200, Iteration 21/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 22/250, Loss: 0.0131\n",
      "Epoch 193/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 193/200, Iteration 24/250, Loss: 0.0286\n",
      "Epoch 193/200, Iteration 25/250, Loss: 0.0129\n",
      "Epoch 193/200, Iteration 26/250, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 27/250, Loss: 0.0080\n",
      "Epoch 193/200, Iteration 28/250, Loss: 0.0091\n",
      "Epoch 193/200, Iteration 29/250, Loss: 0.0087\n",
      "Epoch 193/200, Iteration 30/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 31/250, Loss: 0.0226\n",
      "Epoch 193/200, Iteration 32/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 33/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 34/250, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 35/250, Loss: 0.0351\n",
      "Epoch 193/200, Iteration 36/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 37/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 38/250, Loss: 0.0100\n",
      "Epoch 193/200, Iteration 39/250, Loss: 0.0113\n",
      "Epoch 193/200, Iteration 40/250, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 41/250, Loss: 0.0135\n",
      "Epoch 193/200, Iteration 42/250, Loss: 0.0253\n",
      "Epoch 193/200, Iteration 43/250, Loss: 0.0168\n",
      "Epoch 193/200, Iteration 44/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 45/250, Loss: 0.0111\n",
      "Epoch 193/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 47/250, Loss: 0.0066\n",
      "Epoch 193/200, Iteration 48/250, Loss: 0.0127\n",
      "Epoch 193/200, Iteration 49/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 50/250, Loss: 0.0177\n",
      "Epoch 193/200, Iteration 51/250, Loss: 0.0104\n",
      "Epoch 193/200, Iteration 52/250, Loss: 0.0172\n",
      "Epoch 193/200, Iteration 53/250, Loss: 0.0199\n",
      "Epoch 193/200, Iteration 54/250, Loss: 0.0457\n",
      "Epoch 193/200, Iteration 55/250, Loss: 0.0289\n",
      "Epoch 193/200, Iteration 56/250, Loss: 0.0339\n",
      "Epoch 193/200, Iteration 57/250, Loss: 0.0158\n",
      "Epoch 193/200, Iteration 58/250, Loss: 0.0062\n",
      "Epoch 193/200, Iteration 59/250, Loss: 0.0133\n",
      "Epoch 193/200, Iteration 60/250, Loss: 0.0114\n",
      "Epoch 193/200, Iteration 61/250, Loss: 0.0107\n",
      "Epoch 193/200, Iteration 62/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 63/250, Loss: 0.0160\n",
      "Epoch 193/200, Iteration 64/250, Loss: 0.0080\n",
      "Epoch 193/200, Iteration 65/250, Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200, Iteration 66/250, Loss: 0.0150\n",
      "Epoch 193/200, Iteration 67/250, Loss: 0.0249\n",
      "Epoch 193/200, Iteration 68/250, Loss: 0.0241\n",
      "Epoch 193/200, Iteration 69/250, Loss: 0.0403\n",
      "Epoch 193/200, Iteration 70/250, Loss: 0.0109\n",
      "Epoch 193/200, Iteration 71/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 72/250, Loss: 0.0170\n",
      "Epoch 193/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 193/200, Iteration 74/250, Loss: 0.0170\n",
      "Epoch 193/200, Iteration 75/250, Loss: 0.0123\n",
      "Epoch 193/200, Iteration 76/250, Loss: 0.0170\n",
      "Epoch 193/200, Iteration 77/250, Loss: 0.0062\n",
      "Epoch 193/200, Iteration 78/250, Loss: 0.0086\n",
      "Epoch 193/200, Iteration 79/250, Loss: 0.0218\n",
      "Epoch 193/200, Iteration 80/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 81/250, Loss: 0.0080\n",
      "Epoch 193/200, Iteration 82/250, Loss: 0.0078\n",
      "Epoch 193/200, Iteration 83/250, Loss: 0.0260\n",
      "Epoch 193/200, Iteration 84/250, Loss: 0.0140\n",
      "Epoch 193/200, Iteration 85/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 86/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 87/250, Loss: 0.0127\n",
      "Epoch 193/200, Iteration 88/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 89/250, Loss: 0.0147\n",
      "Epoch 193/200, Iteration 90/250, Loss: 0.0164\n",
      "Epoch 193/200, Iteration 91/250, Loss: 0.0156\n",
      "Epoch 193/200, Iteration 92/250, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 93/250, Loss: 0.0126\n",
      "Epoch 193/200, Iteration 94/250, Loss: 0.0258\n",
      "Epoch 193/200, Iteration 95/250, Loss: 0.0202\n",
      "Epoch 193/200, Iteration 96/250, Loss: 0.0071\n",
      "Epoch 193/200, Iteration 97/250, Loss: 0.0105\n",
      "Epoch 193/200, Iteration 98/250, Loss: 0.0202\n",
      "Epoch 193/200, Iteration 99/250, Loss: 0.0141\n",
      "Epoch 193/200, Iteration 100/250, Loss: 0.0064\n",
      "Epoch 193/200, Iteration 101/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 102/250, Loss: 0.0098\n",
      "Epoch 193/200, Iteration 103/250, Loss: 0.0094\n",
      "Epoch 193/200, Iteration 104/250, Loss: 0.0312\n",
      "Epoch 193/200, Iteration 105/250, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 106/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 107/250, Loss: 0.0061\n",
      "Epoch 193/200, Iteration 108/250, Loss: 0.0109\n",
      "Epoch 193/200, Iteration 109/250, Loss: 0.0094\n",
      "Epoch 193/200, Iteration 110/250, Loss: 0.0220\n",
      "Epoch 193/200, Iteration 111/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 112/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 113/250, Loss: 0.0280\n",
      "Epoch 193/200, Iteration 114/250, Loss: 0.0125\n",
      "Epoch 193/200, Iteration 115/250, Loss: 0.0086\n",
      "Epoch 193/200, Iteration 116/250, Loss: 0.0127\n",
      "Epoch 193/200, Iteration 117/250, Loss: 0.0132\n",
      "Epoch 193/200, Iteration 118/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 119/250, Loss: 0.0089\n",
      "Epoch 193/200, Iteration 120/250, Loss: 0.0187\n",
      "Epoch 193/200, Iteration 121/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 122/250, Loss: 0.0153\n",
      "Epoch 193/200, Iteration 123/250, Loss: 0.0067\n",
      "Epoch 193/200, Iteration 124/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 125/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 126/250, Loss: 0.0203\n",
      "Epoch 193/200, Iteration 127/250, Loss: 0.0177\n",
      "Epoch 193/200, Iteration 128/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 129/250, Loss: 0.0194\n",
      "Epoch 193/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 131/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 132/250, Loss: 0.0376\n",
      "Epoch 193/200, Iteration 133/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 134/250, Loss: 0.0202\n",
      "Epoch 193/200, Iteration 135/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 136/250, Loss: 0.0082\n",
      "Epoch 193/200, Iteration 137/250, Loss: 0.0194\n",
      "Epoch 193/200, Iteration 138/250, Loss: 0.0283\n",
      "Epoch 193/200, Iteration 139/250, Loss: 0.0085\n",
      "Epoch 193/200, Iteration 140/250, Loss: 0.0089\n",
      "Epoch 193/200, Iteration 141/250, Loss: 0.0268\n",
      "Epoch 193/200, Iteration 142/250, Loss: 0.0070\n",
      "Epoch 193/200, Iteration 143/250, Loss: 0.0162\n",
      "Epoch 193/200, Iteration 144/250, Loss: 0.0113\n",
      "Epoch 193/200, Iteration 145/250, Loss: 0.0178\n",
      "Epoch 193/200, Iteration 146/250, Loss: 0.0086\n",
      "Epoch 193/200, Iteration 147/250, Loss: 0.0115\n",
      "Epoch 193/200, Iteration 148/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 149/250, Loss: 0.0136\n",
      "Epoch 193/200, Iteration 150/250, Loss: 0.0094\n",
      "Epoch 193/200, Iteration 151/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 152/250, Loss: 0.0151\n",
      "Epoch 193/200, Iteration 153/250, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 193/200, Iteration 155/250, Loss: 0.0138\n",
      "Epoch 193/200, Iteration 156/250, Loss: 0.0104\n",
      "Epoch 193/200, Iteration 157/250, Loss: 0.0171\n",
      "Epoch 193/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 193/200, Iteration 159/250, Loss: 0.0187\n",
      "Epoch 193/200, Iteration 160/250, Loss: 0.0152\n",
      "Epoch 193/200, Iteration 161/250, Loss: 0.0237\n",
      "Epoch 193/200, Iteration 162/250, Loss: 0.0069\n",
      "Epoch 193/200, Iteration 163/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 164/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 165/250, Loss: 0.0132\n",
      "Epoch 193/200, Iteration 166/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 168/250, Loss: 0.0178\n",
      "Epoch 193/200, Iteration 169/250, Loss: 0.0126\n",
      "Epoch 193/200, Iteration 170/250, Loss: 0.0138\n",
      "Epoch 193/200, Iteration 171/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 172/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 173/250, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 193/200, Iteration 175/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 176/250, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 177/250, Loss: 0.0139\n",
      "Epoch 193/200, Iteration 178/250, Loss: 0.0131\n",
      "Epoch 193/200, Iteration 179/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 180/250, Loss: 0.0209\n",
      "Epoch 193/200, Iteration 181/250, Loss: 0.0138\n",
      "Epoch 193/200, Iteration 182/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 183/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 184/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 185/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 186/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 188/250, Loss: 0.0248\n",
      "Epoch 193/200, Iteration 189/250, Loss: 0.0071\n",
      "Epoch 193/200, Iteration 190/250, Loss: 0.0251\n",
      "Epoch 193/200, Iteration 191/250, Loss: 0.0141\n",
      "Epoch 193/200, Iteration 192/250, Loss: 0.0157\n",
      "Epoch 193/200, Iteration 193/250, Loss: 0.0179\n",
      "Epoch 193/200, Iteration 194/250, Loss: 0.0141\n",
      "Epoch 193/200, Iteration 195/250, Loss: 0.0183\n",
      "Epoch 193/200, Iteration 196/250, Loss: 0.0071\n",
      "Epoch 193/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 198/250, Loss: 0.0353\n",
      "Epoch 193/200, Iteration 199/250, Loss: 0.0143\n",
      "Epoch 193/200, Iteration 200/250, Loss: 0.0333\n",
      "Epoch 193/200, Iteration 201/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 202/250, Loss: 0.0250\n",
      "Epoch 193/200, Iteration 203/250, Loss: 0.0172\n",
      "Epoch 193/200, Iteration 204/250, Loss: 0.0217\n",
      "Epoch 193/200, Iteration 205/250, Loss: 0.0214\n",
      "Epoch 193/200, Iteration 206/250, Loss: 0.0139\n",
      "Epoch 193/200, Iteration 207/250, Loss: 0.0315\n",
      "Epoch 193/200, Iteration 208/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 209/250, Loss: 0.0166\n",
      "Epoch 193/200, Iteration 210/250, Loss: 0.0290\n",
      "Epoch 193/200, Iteration 211/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 212/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 213/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 214/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 215/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 216/250, Loss: 0.0068\n",
      "Epoch 193/200, Iteration 217/250, Loss: 0.0070\n",
      "Epoch 193/200, Iteration 218/250, Loss: 0.0143\n",
      "Epoch 193/200, Iteration 219/250, Loss: 0.0170\n",
      "Epoch 193/200, Iteration 220/250, Loss: 0.0209\n",
      "Epoch 193/200, Iteration 221/250, Loss: 0.0118\n",
      "Epoch 193/200, Iteration 222/250, Loss: 0.0091\n",
      "Epoch 193/200, Iteration 223/250, Loss: 0.0270\n",
      "Epoch 193/200, Iteration 224/250, Loss: 0.0196\n",
      "Epoch 193/200, Iteration 225/250, Loss: 0.0130\n",
      "Epoch 193/200, Iteration 226/250, Loss: 0.0250\n",
      "Epoch 193/200, Iteration 227/250, Loss: 0.0134\n",
      "Epoch 193/200, Iteration 228/250, Loss: 0.0133\n",
      "Epoch 193/200, Iteration 229/250, Loss: 0.0260\n",
      "Epoch 193/200, Iteration 230/250, Loss: 0.0091\n",
      "Epoch 193/200, Iteration 231/250, Loss: 0.0205\n",
      "Epoch 193/200, Iteration 232/250, Loss: 0.0177\n",
      "Epoch 193/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 234/250, Loss: 0.0214\n",
      "Epoch 193/200, Iteration 235/250, Loss: 0.0167\n",
      "Epoch 193/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 237/250, Loss: 0.0176\n",
      "Epoch 193/200, Iteration 238/250, Loss: 0.0069\n",
      "Epoch 193/200, Iteration 239/250, Loss: 0.0084\n",
      "Epoch 193/200, Iteration 240/250, Loss: 0.0141\n",
      "Epoch 193/200, Iteration 241/250, Loss: 0.0290\n",
      "Epoch 193/200, Iteration 242/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 243/250, Loss: 0.0162\n",
      "Epoch 193/200, Iteration 244/250, Loss: 0.0128\n",
      "Epoch 193/200, Iteration 245/250, Loss: 0.0169\n",
      "Epoch 193/200, Iteration 246/250, Loss: 0.0168\n",
      "Epoch 193/200, Iteration 247/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 248/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 193/200, Iteration 250/250, Loss: 0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 92.24%, Avg loss: 0.006125, MRE: 0.595783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.006202, MRE: 0.980039 \n",
      "\n",
      "Epoch 194/200, Iteration 1/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 2/250, Loss: 0.0058\n",
      "Epoch 194/200, Iteration 3/250, Loss: 0.0181\n",
      "Epoch 194/200, Iteration 4/250, Loss: 0.0206\n",
      "Epoch 194/200, Iteration 5/250, Loss: 0.0237\n",
      "Epoch 194/200, Iteration 6/250, Loss: 0.0079\n",
      "Epoch 194/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 194/200, Iteration 8/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 9/250, Loss: 0.0167\n",
      "Epoch 194/200, Iteration 10/250, Loss: 0.0149\n",
      "Epoch 194/200, Iteration 11/250, Loss: 0.0118\n",
      "Epoch 194/200, Iteration 12/250, Loss: 0.0132\n",
      "Epoch 194/200, Iteration 13/250, Loss: 0.0264\n",
      "Epoch 194/200, Iteration 14/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 15/250, Loss: 0.0186\n",
      "Epoch 194/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 194/200, Iteration 17/250, Loss: 0.0064\n",
      "Epoch 194/200, Iteration 18/250, Loss: 0.0165\n",
      "Epoch 194/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 194/200, Iteration 20/250, Loss: 0.0100\n",
      "Epoch 194/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 194/200, Iteration 22/250, Loss: 0.0233\n",
      "Epoch 194/200, Iteration 23/250, Loss: 0.0209\n",
      "Epoch 194/200, Iteration 24/250, Loss: 0.0191\n",
      "Epoch 194/200, Iteration 25/250, Loss: 0.0109\n",
      "Epoch 194/200, Iteration 26/250, Loss: 0.0103\n",
      "Epoch 194/200, Iteration 27/250, Loss: 0.0151\n",
      "Epoch 194/200, Iteration 28/250, Loss: 0.0099\n",
      "Epoch 194/200, Iteration 29/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 30/250, Loss: 0.0172\n",
      "Epoch 194/200, Iteration 31/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 32/250, Loss: 0.0128\n",
      "Epoch 194/200, Iteration 33/250, Loss: 0.0191\n",
      "Epoch 194/200, Iteration 34/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 35/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 36/250, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 37/250, Loss: 0.0088\n",
      "Epoch 194/200, Iteration 38/250, Loss: 0.0162\n",
      "Epoch 194/200, Iteration 39/250, Loss: 0.0065\n",
      "Epoch 194/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 194/200, Iteration 41/250, Loss: 0.0293\n",
      "Epoch 194/200, Iteration 42/250, Loss: 0.0236\n",
      "Epoch 194/200, Iteration 43/250, Loss: 0.0185\n",
      "Epoch 194/200, Iteration 44/250, Loss: 0.0199\n",
      "Epoch 194/200, Iteration 45/250, Loss: 0.0195\n",
      "Epoch 194/200, Iteration 46/250, Loss: 0.0067\n",
      "Epoch 194/200, Iteration 47/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 48/250, Loss: 0.0081\n",
      "Epoch 194/200, Iteration 49/250, Loss: 0.0244\n",
      "Epoch 194/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 194/200, Iteration 51/250, Loss: 0.0171\n",
      "Epoch 194/200, Iteration 52/250, Loss: 0.0350\n",
      "Epoch 194/200, Iteration 53/250, Loss: 0.0111\n",
      "Epoch 194/200, Iteration 54/250, Loss: 0.0233\n",
      "Epoch 194/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 194/200, Iteration 56/250, Loss: 0.0146\n",
      "Epoch 194/200, Iteration 57/250, Loss: 0.0115\n",
      "Epoch 194/200, Iteration 58/250, Loss: 0.0255\n",
      "Epoch 194/200, Iteration 59/250, Loss: 0.0221\n",
      "Epoch 194/200, Iteration 60/250, Loss: 0.0162\n",
      "Epoch 194/200, Iteration 61/250, Loss: 0.0244\n",
      "Epoch 194/200, Iteration 62/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 63/250, Loss: 0.0067\n",
      "Epoch 194/200, Iteration 64/250, Loss: 0.0102\n",
      "Epoch 194/200, Iteration 65/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 66/250, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 67/250, Loss: 0.0114\n",
      "Epoch 194/200, Iteration 68/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 69/250, Loss: 0.0118\n",
      "Epoch 194/200, Iteration 70/250, Loss: 0.0168\n",
      "Epoch 194/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 194/200, Iteration 72/250, Loss: 0.0128\n",
      "Epoch 194/200, Iteration 73/250, Loss: 0.0148\n",
      "Epoch 194/200, Iteration 74/250, Loss: 0.0077\n",
      "Epoch 194/200, Iteration 75/250, Loss: 0.0259\n",
      "Epoch 194/200, Iteration 76/250, Loss: 0.0205\n",
      "Epoch 194/200, Iteration 77/250, Loss: 0.0503\n",
      "Epoch 194/200, Iteration 78/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 79/250, Loss: 0.0111\n",
      "Epoch 194/200, Iteration 80/250, Loss: 0.0196\n",
      "Epoch 194/200, Iteration 81/250, Loss: 0.0262\n",
      "Epoch 194/200, Iteration 82/250, Loss: 0.0145\n",
      "Epoch 194/200, Iteration 83/250, Loss: 0.0151\n",
      "Epoch 194/200, Iteration 84/250, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 85/250, Loss: 0.0112\n",
      "Epoch 194/200, Iteration 86/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 87/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 88/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 89/250, Loss: 0.0109\n",
      "Epoch 194/200, Iteration 90/250, Loss: 0.0245\n",
      "Epoch 194/200, Iteration 91/250, Loss: 0.0076\n",
      "Epoch 194/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 93/250, Loss: 0.0282\n",
      "Epoch 194/200, Iteration 94/250, Loss: 0.0139\n",
      "Epoch 194/200, Iteration 95/250, Loss: 0.0112\n",
      "Epoch 194/200, Iteration 96/250, Loss: 0.0141\n",
      "Epoch 194/200, Iteration 97/250, Loss: 0.0174\n",
      "Epoch 194/200, Iteration 98/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 99/250, Loss: 0.0132\n",
      "Epoch 194/200, Iteration 100/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 101/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 102/250, Loss: 0.0110\n",
      "Epoch 194/200, Iteration 103/250, Loss: 0.0112\n",
      "Epoch 194/200, Iteration 104/250, Loss: 0.0115\n",
      "Epoch 194/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 106/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 107/250, Loss: 0.0166\n",
      "Epoch 194/200, Iteration 108/250, Loss: 0.0180\n",
      "Epoch 194/200, Iteration 109/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 110/250, Loss: 0.0195\n",
      "Epoch 194/200, Iteration 111/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 112/250, Loss: 0.0131\n",
      "Epoch 194/200, Iteration 113/250, Loss: 0.0222\n",
      "Epoch 194/200, Iteration 114/250, Loss: 0.0231\n",
      "Epoch 194/200, Iteration 115/250, Loss: 0.0364\n",
      "Epoch 194/200, Iteration 116/250, Loss: 0.0124\n",
      "Epoch 194/200, Iteration 117/250, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 118/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 194/200, Iteration 120/250, Loss: 0.0104\n",
      "Epoch 194/200, Iteration 121/250, Loss: 0.0260\n",
      "Epoch 194/200, Iteration 122/250, Loss: 0.0092\n",
      "Epoch 194/200, Iteration 123/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 124/250, Loss: 0.0334\n",
      "Epoch 194/200, Iteration 125/250, Loss: 0.0222\n",
      "Epoch 194/200, Iteration 126/250, Loss: 0.0068\n",
      "Epoch 194/200, Iteration 127/250, Loss: 0.0131\n",
      "Epoch 194/200, Iteration 128/250, Loss: 0.0073\n",
      "Epoch 194/200, Iteration 129/250, Loss: 0.0086\n",
      "Epoch 194/200, Iteration 130/250, Loss: 0.0096\n",
      "Epoch 194/200, Iteration 131/250, Loss: 0.0169\n",
      "Epoch 194/200, Iteration 132/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 133/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 134/250, Loss: 0.0067\n",
      "Epoch 194/200, Iteration 135/250, Loss: 0.0097\n",
      "Epoch 194/200, Iteration 136/250, Loss: 0.0221\n",
      "Epoch 194/200, Iteration 137/250, Loss: 0.0198\n",
      "Epoch 194/200, Iteration 138/250, Loss: 0.0192\n",
      "Epoch 194/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 140/250, Loss: 0.0139\n",
      "Epoch 194/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 194/200, Iteration 142/250, Loss: 0.0081\n",
      "Epoch 194/200, Iteration 143/250, Loss: 0.0136\n",
      "Epoch 194/200, Iteration 144/250, Loss: 0.0143\n",
      "Epoch 194/200, Iteration 145/250, Loss: 0.0151\n",
      "Epoch 194/200, Iteration 146/250, Loss: 0.0149\n",
      "Epoch 194/200, Iteration 147/250, Loss: 0.0139\n",
      "Epoch 194/200, Iteration 148/250, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 149/250, Loss: 0.0144\n",
      "Epoch 194/200, Iteration 150/250, Loss: 0.0270\n",
      "Epoch 194/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 194/200, Iteration 152/250, Loss: 0.0079\n",
      "Epoch 194/200, Iteration 153/250, Loss: 0.0207\n",
      "Epoch 194/200, Iteration 154/250, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 155/250, Loss: 0.0151\n",
      "Epoch 194/200, Iteration 156/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 157/250, Loss: 0.0072\n",
      "Epoch 194/200, Iteration 158/250, Loss: 0.0167\n",
      "Epoch 194/200, Iteration 159/250, Loss: 0.0214\n",
      "Epoch 194/200, Iteration 160/250, Loss: 0.0206\n",
      "Epoch 194/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 162/250, Loss: 0.0282\n",
      "Epoch 194/200, Iteration 163/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 164/250, Loss: 0.0107\n",
      "Epoch 194/200, Iteration 165/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 166/250, Loss: 0.0078\n",
      "Epoch 194/200, Iteration 167/250, Loss: 0.0069\n",
      "Epoch 194/200, Iteration 168/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 169/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 170/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 171/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 172/250, Loss: 0.0261\n",
      "Epoch 194/200, Iteration 173/250, Loss: 0.0172\n",
      "Epoch 194/200, Iteration 174/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 175/250, Loss: 0.0114\n",
      "Epoch 194/200, Iteration 176/250, Loss: 0.0184\n",
      "Epoch 194/200, Iteration 177/250, Loss: 0.0441\n",
      "Epoch 194/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 179/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 180/250, Loss: 0.0202\n",
      "Epoch 194/200, Iteration 181/250, Loss: 0.0233\n",
      "Epoch 194/200, Iteration 182/250, Loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200, Iteration 183/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 184/250, Loss: 0.0060\n",
      "Epoch 194/200, Iteration 185/250, Loss: 0.0246\n",
      "Epoch 194/200, Iteration 186/250, Loss: 0.0061\n",
      "Epoch 194/200, Iteration 187/250, Loss: 0.0210\n",
      "Epoch 194/200, Iteration 188/250, Loss: 0.0106\n",
      "Epoch 194/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 194/200, Iteration 190/250, Loss: 0.0248\n",
      "Epoch 194/200, Iteration 191/250, Loss: 0.0215\n",
      "Epoch 194/200, Iteration 192/250, Loss: 0.0163\n",
      "Epoch 194/200, Iteration 193/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 194/250, Loss: 0.0283\n",
      "Epoch 194/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 194/200, Iteration 196/250, Loss: 0.0240\n",
      "Epoch 194/200, Iteration 197/250, Loss: 0.0250\n",
      "Epoch 194/200, Iteration 198/250, Loss: 0.0167\n",
      "Epoch 194/200, Iteration 199/250, Loss: 0.0115\n",
      "Epoch 194/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 194/200, Iteration 201/250, Loss: 0.0245\n",
      "Epoch 194/200, Iteration 202/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 203/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 204/250, Loss: 0.0073\n",
      "Epoch 194/200, Iteration 205/250, Loss: 0.0279\n",
      "Epoch 194/200, Iteration 206/250, Loss: 0.0216\n",
      "Epoch 194/200, Iteration 207/250, Loss: 0.0139\n",
      "Epoch 194/200, Iteration 208/250, Loss: 0.0196\n",
      "Epoch 194/200, Iteration 209/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 210/250, Loss: 0.0137\n",
      "Epoch 194/200, Iteration 211/250, Loss: 0.0210\n",
      "Epoch 194/200, Iteration 212/250, Loss: 0.0131\n",
      "Epoch 194/200, Iteration 213/250, Loss: 0.0071\n",
      "Epoch 194/200, Iteration 214/250, Loss: 0.0171\n",
      "Epoch 194/200, Iteration 215/250, Loss: 0.0210\n",
      "Epoch 194/200, Iteration 216/250, Loss: 0.0082\n",
      "Epoch 194/200, Iteration 217/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 218/250, Loss: 0.0100\n",
      "Epoch 194/200, Iteration 219/250, Loss: 0.0161\n",
      "Epoch 194/200, Iteration 220/250, Loss: 0.0256\n",
      "Epoch 194/200, Iteration 221/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 222/250, Loss: 0.0088\n",
      "Epoch 194/200, Iteration 223/250, Loss: 0.0212\n",
      "Epoch 194/200, Iteration 224/250, Loss: 0.0077\n",
      "Epoch 194/200, Iteration 225/250, Loss: 0.0260\n",
      "Epoch 194/200, Iteration 226/250, Loss: 0.0248\n",
      "Epoch 194/200, Iteration 227/250, Loss: 0.0170\n",
      "Epoch 194/200, Iteration 228/250, Loss: 0.0101\n",
      "Epoch 194/200, Iteration 229/250, Loss: 0.0186\n",
      "Epoch 194/200, Iteration 230/250, Loss: 0.0082\n",
      "Epoch 194/200, Iteration 231/250, Loss: 0.0076\n",
      "Epoch 194/200, Iteration 232/250, Loss: 0.0145\n",
      "Epoch 194/200, Iteration 233/250, Loss: 0.0082\n",
      "Epoch 194/200, Iteration 234/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 235/250, Loss: 0.0341\n",
      "Epoch 194/200, Iteration 236/250, Loss: 0.0170\n",
      "Epoch 194/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 238/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 239/250, Loss: 0.0111\n",
      "Epoch 194/200, Iteration 240/250, Loss: 0.0047\n",
      "Epoch 194/200, Iteration 241/250, Loss: 0.0211\n",
      "Epoch 194/200, Iteration 242/250, Loss: 0.0128\n",
      "Epoch 194/200, Iteration 243/250, Loss: 0.0153\n",
      "Epoch 194/200, Iteration 244/250, Loss: 0.0077\n",
      "Epoch 194/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 194/200, Iteration 246/250, Loss: 0.0070\n",
      "Epoch 194/200, Iteration 247/250, Loss: 0.0148\n",
      "Epoch 194/200, Iteration 248/250, Loss: 0.0130\n",
      "Epoch 194/200, Iteration 249/250, Loss: 0.0129\n",
      "Epoch 194/200, Iteration 250/250, Loss: 0.0211\n",
      "Train Error: \n",
      " Accuracy: 96.49%, Avg loss: 0.005507, MRE: 0.605849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.005545, MRE: 0.952822 \n",
      "\n",
      "Epoch 195/200, Iteration 1/250, Loss: 0.0256\n",
      "Epoch 195/200, Iteration 2/250, Loss: 0.0074\n",
      "Epoch 195/200, Iteration 3/250, Loss: 0.0274\n",
      "Epoch 195/200, Iteration 4/250, Loss: 0.0071\n",
      "Epoch 195/200, Iteration 5/250, Loss: 0.0086\n",
      "Epoch 195/200, Iteration 6/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 7/250, Loss: 0.0086\n",
      "Epoch 195/200, Iteration 8/250, Loss: 0.0151\n",
      "Epoch 195/200, Iteration 9/250, Loss: 0.0438\n",
      "Epoch 195/200, Iteration 10/250, Loss: 0.0082\n",
      "Epoch 195/200, Iteration 11/250, Loss: 0.0147\n",
      "Epoch 195/200, Iteration 12/250, Loss: 0.0112\n",
      "Epoch 195/200, Iteration 13/250, Loss: 0.0161\n",
      "Epoch 195/200, Iteration 14/250, Loss: 0.0075\n",
      "Epoch 195/200, Iteration 15/250, Loss: 0.0127\n",
      "Epoch 195/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 195/200, Iteration 17/250, Loss: 0.0126\n",
      "Epoch 195/200, Iteration 18/250, Loss: 0.0065\n",
      "Epoch 195/200, Iteration 19/250, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 20/250, Loss: 0.0106\n",
      "Epoch 195/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 22/250, Loss: 0.0163\n",
      "Epoch 195/200, Iteration 23/250, Loss: 0.0191\n",
      "Epoch 195/200, Iteration 24/250, Loss: 0.0165\n",
      "Epoch 195/200, Iteration 25/250, Loss: 0.0074\n",
      "Epoch 195/200, Iteration 26/250, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 27/250, Loss: 0.0172\n",
      "Epoch 195/200, Iteration 28/250, Loss: 0.0128\n",
      "Epoch 195/200, Iteration 29/250, Loss: 0.0138\n",
      "Epoch 195/200, Iteration 30/250, Loss: 0.0130\n",
      "Epoch 195/200, Iteration 31/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 32/250, Loss: 0.0151\n",
      "Epoch 195/200, Iteration 33/250, Loss: 0.0100\n",
      "Epoch 195/200, Iteration 34/250, Loss: 0.0140\n",
      "Epoch 195/200, Iteration 35/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 36/250, Loss: 0.0076\n",
      "Epoch 195/200, Iteration 37/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 38/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 195/200, Iteration 40/250, Loss: 0.0277\n",
      "Epoch 195/200, Iteration 41/250, Loss: 0.0115\n",
      "Epoch 195/200, Iteration 42/250, Loss: 0.0378\n",
      "Epoch 195/200, Iteration 43/250, Loss: 0.0183\n",
      "Epoch 195/200, Iteration 44/250, Loss: 0.0090\n",
      "Epoch 195/200, Iteration 45/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 46/250, Loss: 0.0134\n",
      "Epoch 195/200, Iteration 47/250, Loss: 0.0196\n",
      "Epoch 195/200, Iteration 48/250, Loss: 0.0121\n",
      "Epoch 195/200, Iteration 49/250, Loss: 0.0153\n",
      "Epoch 195/200, Iteration 50/250, Loss: 0.0068\n",
      "Epoch 195/200, Iteration 51/250, Loss: 0.0221\n",
      "Epoch 195/200, Iteration 52/250, Loss: 0.0168\n",
      "Epoch 195/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 195/200, Iteration 54/250, Loss: 0.0127\n",
      "Epoch 195/200, Iteration 55/250, Loss: 0.0164\n",
      "Epoch 195/200, Iteration 56/250, Loss: 0.0124\n",
      "Epoch 195/200, Iteration 57/250, Loss: 0.0123\n",
      "Epoch 195/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 195/200, Iteration 59/250, Loss: 0.0301\n",
      "Epoch 195/200, Iteration 60/250, Loss: 0.0263\n",
      "Epoch 195/200, Iteration 61/250, Loss: 0.0141\n",
      "Epoch 195/200, Iteration 62/250, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 63/250, Loss: 0.0317\n",
      "Epoch 195/200, Iteration 64/250, Loss: 0.0166\n",
      "Epoch 195/200, Iteration 65/250, Loss: 0.0098\n",
      "Epoch 195/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 195/200, Iteration 67/250, Loss: 0.0310\n",
      "Epoch 195/200, Iteration 68/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 69/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 70/250, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 71/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 72/250, Loss: 0.0331\n",
      "Epoch 195/200, Iteration 73/250, Loss: 0.0156\n",
      "Epoch 195/200, Iteration 74/250, Loss: 0.0251\n",
      "Epoch 195/200, Iteration 75/250, Loss: 0.0115\n",
      "Epoch 195/200, Iteration 76/250, Loss: 0.0103\n",
      "Epoch 195/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 78/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 79/250, Loss: 0.0284\n",
      "Epoch 195/200, Iteration 80/250, Loss: 0.0138\n",
      "Epoch 195/200, Iteration 81/250, Loss: 0.0126\n",
      "Epoch 195/200, Iteration 82/250, Loss: 0.0205\n",
      "Epoch 195/200, Iteration 83/250, Loss: 0.0167\n",
      "Epoch 195/200, Iteration 84/250, Loss: 0.0089\n",
      "Epoch 195/200, Iteration 85/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 86/250, Loss: 0.0289\n",
      "Epoch 195/200, Iteration 87/250, Loss: 0.0230\n",
      "Epoch 195/200, Iteration 88/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 89/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 90/250, Loss: 0.0146\n",
      "Epoch 195/200, Iteration 91/250, Loss: 0.0119\n",
      "Epoch 195/200, Iteration 92/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 93/250, Loss: 0.0108\n",
      "Epoch 195/200, Iteration 94/250, Loss: 0.0164\n",
      "Epoch 195/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 195/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 195/200, Iteration 97/250, Loss: 0.0296\n",
      "Epoch 195/200, Iteration 98/250, Loss: 0.0151\n",
      "Epoch 195/200, Iteration 99/250, Loss: 0.0097\n",
      "Epoch 195/200, Iteration 100/250, Loss: 0.0104\n",
      "Epoch 195/200, Iteration 101/250, Loss: 0.0190\n",
      "Epoch 195/200, Iteration 102/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 103/250, Loss: 0.0190\n",
      "Epoch 195/200, Iteration 104/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 105/250, Loss: 0.0237\n",
      "Epoch 195/200, Iteration 106/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 107/250, Loss: 0.0088\n",
      "Epoch 195/200, Iteration 108/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 109/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 110/250, Loss: 0.0220\n",
      "Epoch 195/200, Iteration 111/250, Loss: 0.0096\n",
      "Epoch 195/200, Iteration 112/250, Loss: 0.0235\n",
      "Epoch 195/200, Iteration 113/250, Loss: 0.0058\n",
      "Epoch 195/200, Iteration 114/250, Loss: 0.0251\n",
      "Epoch 195/200, Iteration 115/250, Loss: 0.0105\n",
      "Epoch 195/200, Iteration 116/250, Loss: 0.0303\n",
      "Epoch 195/200, Iteration 117/250, Loss: 0.0056\n",
      "Epoch 195/200, Iteration 118/250, Loss: 0.0125\n",
      "Epoch 195/200, Iteration 119/250, Loss: 0.0146\n",
      "Epoch 195/200, Iteration 120/250, Loss: 0.0113\n",
      "Epoch 195/200, Iteration 121/250, Loss: 0.0215\n",
      "Epoch 195/200, Iteration 122/250, Loss: 0.0129\n",
      "Epoch 195/200, Iteration 123/250, Loss: 0.0119\n",
      "Epoch 195/200, Iteration 124/250, Loss: 0.0105\n",
      "Epoch 195/200, Iteration 125/250, Loss: 0.0052\n",
      "Epoch 195/200, Iteration 126/250, Loss: 0.0141\n",
      "Epoch 195/200, Iteration 127/250, Loss: 0.0315\n",
      "Epoch 195/200, Iteration 128/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 129/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 130/250, Loss: 0.0355\n",
      "Epoch 195/200, Iteration 131/250, Loss: 0.0239\n",
      "Epoch 195/200, Iteration 132/250, Loss: 0.0072\n",
      "Epoch 195/200, Iteration 133/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 134/250, Loss: 0.0183\n",
      "Epoch 195/200, Iteration 135/250, Loss: 0.0098\n",
      "Epoch 195/200, Iteration 136/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 195/200, Iteration 138/250, Loss: 0.0266\n",
      "Epoch 195/200, Iteration 139/250, Loss: 0.0121\n",
      "Epoch 195/200, Iteration 140/250, Loss: 0.0185\n",
      "Epoch 195/200, Iteration 141/250, Loss: 0.0088\n",
      "Epoch 195/200, Iteration 142/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200, Iteration 143/250, Loss: 0.0106\n",
      "Epoch 195/200, Iteration 144/250, Loss: 0.0241\n",
      "Epoch 195/200, Iteration 145/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 146/250, Loss: 0.0149\n",
      "Epoch 195/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 148/250, Loss: 0.0173\n",
      "Epoch 195/200, Iteration 149/250, Loss: 0.0117\n",
      "Epoch 195/200, Iteration 150/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 151/250, Loss: 0.0110\n",
      "Epoch 195/200, Iteration 152/250, Loss: 0.0131\n",
      "Epoch 195/200, Iteration 153/250, Loss: 0.0143\n",
      "Epoch 195/200, Iteration 154/250, Loss: 0.0169\n",
      "Epoch 195/200, Iteration 155/250, Loss: 0.0278\n",
      "Epoch 195/200, Iteration 156/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 157/250, Loss: 0.0184\n",
      "Epoch 195/200, Iteration 158/250, Loss: 0.0207\n",
      "Epoch 195/200, Iteration 159/250, Loss: 0.0055\n",
      "Epoch 195/200, Iteration 160/250, Loss: 0.0105\n",
      "Epoch 195/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 195/200, Iteration 162/250, Loss: 0.0137\n",
      "Epoch 195/200, Iteration 163/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 164/250, Loss: 0.0130\n",
      "Epoch 195/200, Iteration 165/250, Loss: 0.0130\n",
      "Epoch 195/200, Iteration 166/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 167/250, Loss: 0.0089\n",
      "Epoch 195/200, Iteration 168/250, Loss: 0.0088\n",
      "Epoch 195/200, Iteration 169/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 170/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 195/200, Iteration 172/250, Loss: 0.0143\n",
      "Epoch 195/200, Iteration 173/250, Loss: 0.0338\n",
      "Epoch 195/200, Iteration 174/250, Loss: 0.0239\n",
      "Epoch 195/200, Iteration 175/250, Loss: 0.0196\n",
      "Epoch 195/200, Iteration 176/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 195/200, Iteration 178/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 179/250, Loss: 0.0201\n",
      "Epoch 195/200, Iteration 180/250, Loss: 0.0143\n",
      "Epoch 195/200, Iteration 181/250, Loss: 0.0222\n",
      "Epoch 195/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 195/200, Iteration 183/250, Loss: 0.0073\n",
      "Epoch 195/200, Iteration 184/250, Loss: 0.0210\n",
      "Epoch 195/200, Iteration 185/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 186/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 187/250, Loss: 0.0127\n",
      "Epoch 195/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 195/200, Iteration 189/250, Loss: 0.0097\n",
      "Epoch 195/200, Iteration 190/250, Loss: 0.0111\n",
      "Epoch 195/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 195/200, Iteration 192/250, Loss: 0.0160\n",
      "Epoch 195/200, Iteration 193/250, Loss: 0.0199\n",
      "Epoch 195/200, Iteration 194/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 195/200, Iteration 196/250, Loss: 0.0180\n",
      "Epoch 195/200, Iteration 197/250, Loss: 0.0182\n",
      "Epoch 195/200, Iteration 198/250, Loss: 0.0158\n",
      "Epoch 195/200, Iteration 199/250, Loss: 0.0069\n",
      "Epoch 195/200, Iteration 200/250, Loss: 0.0187\n",
      "Epoch 195/200, Iteration 201/250, Loss: 0.0252\n",
      "Epoch 195/200, Iteration 202/250, Loss: 0.0145\n",
      "Epoch 195/200, Iteration 203/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 204/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 205/250, Loss: 0.0082\n",
      "Epoch 195/200, Iteration 206/250, Loss: 0.0116\n",
      "Epoch 195/200, Iteration 207/250, Loss: 0.0229\n",
      "Epoch 195/200, Iteration 208/250, Loss: 0.0282\n",
      "Epoch 195/200, Iteration 209/250, Loss: 0.0160\n",
      "Epoch 195/200, Iteration 210/250, Loss: 0.0213\n",
      "Epoch 195/200, Iteration 211/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 212/250, Loss: 0.0137\n",
      "Epoch 195/200, Iteration 213/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 214/250, Loss: 0.0151\n",
      "Epoch 195/200, Iteration 215/250, Loss: 0.0151\n",
      "Epoch 195/200, Iteration 216/250, Loss: 0.0250\n",
      "Epoch 195/200, Iteration 217/250, Loss: 0.0130\n",
      "Epoch 195/200, Iteration 218/250, Loss: 0.0197\n",
      "Epoch 195/200, Iteration 219/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 220/250, Loss: 0.0131\n",
      "Epoch 195/200, Iteration 221/250, Loss: 0.0158\n",
      "Epoch 195/200, Iteration 222/250, Loss: 0.0158\n",
      "Epoch 195/200, Iteration 223/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 224/250, Loss: 0.0201\n",
      "Epoch 195/200, Iteration 225/250, Loss: 0.0431\n",
      "Epoch 195/200, Iteration 226/250, Loss: 0.0196\n",
      "Epoch 195/200, Iteration 227/250, Loss: 0.0073\n",
      "Epoch 195/200, Iteration 228/250, Loss: 0.0086\n",
      "Epoch 195/200, Iteration 229/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 230/250, Loss: 0.0184\n",
      "Epoch 195/200, Iteration 231/250, Loss: 0.0127\n",
      "Epoch 195/200, Iteration 232/250, Loss: 0.0226\n",
      "Epoch 195/200, Iteration 233/250, Loss: 0.0306\n",
      "Epoch 195/200, Iteration 234/250, Loss: 0.0125\n",
      "Epoch 195/200, Iteration 235/250, Loss: 0.0228\n",
      "Epoch 195/200, Iteration 236/250, Loss: 0.0294\n",
      "Epoch 195/200, Iteration 237/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 238/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 239/250, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 240/250, Loss: 0.0193\n",
      "Epoch 195/200, Iteration 241/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 242/250, Loss: 0.0070\n",
      "Epoch 195/200, Iteration 243/250, Loss: 0.0054\n",
      "Epoch 195/200, Iteration 244/250, Loss: 0.0125\n",
      "Epoch 195/200, Iteration 245/250, Loss: 0.0153\n",
      "Epoch 195/200, Iteration 246/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 247/250, Loss: 0.0194\n",
      "Epoch 195/200, Iteration 248/250, Loss: 0.0116\n",
      "Epoch 195/200, Iteration 249/250, Loss: 0.0103\n",
      "Epoch 195/200, Iteration 250/250, Loss: 0.0130\n",
      "Train Error: \n",
      " Accuracy: 92.91%, Avg loss: 0.005839, MRE: 0.604115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.005922, MRE: 0.896100 \n",
      "\n",
      "Epoch 196/200, Iteration 1/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 2/250, Loss: 0.0172\n",
      "Epoch 196/200, Iteration 3/250, Loss: 0.0078\n",
      "Epoch 196/200, Iteration 4/250, Loss: 0.0051\n",
      "Epoch 196/200, Iteration 5/250, Loss: 0.0113\n",
      "Epoch 196/200, Iteration 6/250, Loss: 0.0101\n",
      "Epoch 196/200, Iteration 7/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 8/250, Loss: 0.0151\n",
      "Epoch 196/200, Iteration 9/250, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 10/250, Loss: 0.0232\n",
      "Epoch 196/200, Iteration 11/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 12/250, Loss: 0.0193\n",
      "Epoch 196/200, Iteration 13/250, Loss: 0.0104\n",
      "Epoch 196/200, Iteration 14/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 15/250, Loss: 0.0074\n",
      "Epoch 196/200, Iteration 16/250, Loss: 0.0061\n",
      "Epoch 196/200, Iteration 17/250, Loss: 0.0154\n",
      "Epoch 196/200, Iteration 18/250, Loss: 0.0140\n",
      "Epoch 196/200, Iteration 19/250, Loss: 0.0169\n",
      "Epoch 196/200, Iteration 20/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 21/250, Loss: 0.0062\n",
      "Epoch 196/200, Iteration 22/250, Loss: 0.0103\n",
      "Epoch 196/200, Iteration 23/250, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 24/250, Loss: 0.0191\n",
      "Epoch 196/200, Iteration 25/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 196/200, Iteration 27/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 196/200, Iteration 29/250, Loss: 0.0152\n",
      "Epoch 196/200, Iteration 30/250, Loss: 0.0167\n",
      "Epoch 196/200, Iteration 31/250, Loss: 0.0100\n",
      "Epoch 196/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 196/200, Iteration 33/250, Loss: 0.0146\n",
      "Epoch 196/200, Iteration 34/250, Loss: 0.0073\n",
      "Epoch 196/200, Iteration 35/250, Loss: 0.0162\n",
      "Epoch 196/200, Iteration 36/250, Loss: 0.0089\n",
      "Epoch 196/200, Iteration 37/250, Loss: 0.0210\n",
      "Epoch 196/200, Iteration 38/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 39/250, Loss: 0.0140\n",
      "Epoch 196/200, Iteration 40/250, Loss: 0.0138\n",
      "Epoch 196/200, Iteration 41/250, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 42/250, Loss: 0.0096\n",
      "Epoch 196/200, Iteration 43/250, Loss: 0.0355\n",
      "Epoch 196/200, Iteration 44/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 45/250, Loss: 0.0221\n",
      "Epoch 196/200, Iteration 46/250, Loss: 0.0223\n",
      "Epoch 196/200, Iteration 47/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 48/250, Loss: 0.0169\n",
      "Epoch 196/200, Iteration 49/250, Loss: 0.0224\n",
      "Epoch 196/200, Iteration 50/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 51/250, Loss: 0.0128\n",
      "Epoch 196/200, Iteration 52/250, Loss: 0.0089\n",
      "Epoch 196/200, Iteration 53/250, Loss: 0.0107\n",
      "Epoch 196/200, Iteration 54/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 55/250, Loss: 0.0184\n",
      "Epoch 196/200, Iteration 56/250, Loss: 0.0148\n",
      "Epoch 196/200, Iteration 57/250, Loss: 0.0070\n",
      "Epoch 196/200, Iteration 58/250, Loss: 0.0268\n",
      "Epoch 196/200, Iteration 59/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 60/250, Loss: 0.0078\n",
      "Epoch 196/200, Iteration 61/250, Loss: 0.0329\n",
      "Epoch 196/200, Iteration 62/250, Loss: 0.0245\n",
      "Epoch 196/200, Iteration 63/250, Loss: 0.0146\n",
      "Epoch 196/200, Iteration 64/250, Loss: 0.0104\n",
      "Epoch 196/200, Iteration 65/250, Loss: 0.0120\n",
      "Epoch 196/200, Iteration 66/250, Loss: 0.0129\n",
      "Epoch 196/200, Iteration 67/250, Loss: 0.0308\n",
      "Epoch 196/200, Iteration 68/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 69/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 196/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 72/250, Loss: 0.0209\n",
      "Epoch 196/200, Iteration 73/250, Loss: 0.0096\n",
      "Epoch 196/200, Iteration 74/250, Loss: 0.0065\n",
      "Epoch 196/200, Iteration 75/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 76/250, Loss: 0.0143\n",
      "Epoch 196/200, Iteration 77/250, Loss: 0.0082\n",
      "Epoch 196/200, Iteration 78/250, Loss: 0.0143\n",
      "Epoch 196/200, Iteration 79/250, Loss: 0.0179\n",
      "Epoch 196/200, Iteration 80/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 82/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 83/250, Loss: 0.0101\n",
      "Epoch 196/200, Iteration 84/250, Loss: 0.0076\n",
      "Epoch 196/200, Iteration 85/250, Loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200, Iteration 86/250, Loss: 0.0161\n",
      "Epoch 196/200, Iteration 87/250, Loss: 0.0181\n",
      "Epoch 196/200, Iteration 88/250, Loss: 0.0188\n",
      "Epoch 196/200, Iteration 89/250, Loss: 0.0064\n",
      "Epoch 196/200, Iteration 90/250, Loss: 0.0323\n",
      "Epoch 196/200, Iteration 91/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 92/250, Loss: 0.0122\n",
      "Epoch 196/200, Iteration 93/250, Loss: 0.0224\n",
      "Epoch 196/200, Iteration 94/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 95/250, Loss: 0.0069\n",
      "Epoch 196/200, Iteration 96/250, Loss: 0.0077\n",
      "Epoch 196/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 98/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 99/250, Loss: 0.0082\n",
      "Epoch 196/200, Iteration 100/250, Loss: 0.0130\n",
      "Epoch 196/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 196/200, Iteration 102/250, Loss: 0.0222\n",
      "Epoch 196/200, Iteration 103/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 196/200, Iteration 105/250, Loss: 0.0065\n",
      "Epoch 196/200, Iteration 106/250, Loss: 0.0188\n",
      "Epoch 196/200, Iteration 107/250, Loss: 0.0102\n",
      "Epoch 196/200, Iteration 108/250, Loss: 0.0094\n",
      "Epoch 196/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 196/200, Iteration 110/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 196/200, Iteration 112/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 113/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 114/250, Loss: 0.0210\n",
      "Epoch 196/200, Iteration 115/250, Loss: 0.0090\n",
      "Epoch 196/200, Iteration 116/250, Loss: 0.0251\n",
      "Epoch 196/200, Iteration 117/250, Loss: 0.0148\n",
      "Epoch 196/200, Iteration 118/250, Loss: 0.0160\n",
      "Epoch 196/200, Iteration 119/250, Loss: 0.0232\n",
      "Epoch 196/200, Iteration 120/250, Loss: 0.0173\n",
      "Epoch 196/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 122/250, Loss: 0.0276\n",
      "Epoch 196/200, Iteration 123/250, Loss: 0.0091\n",
      "Epoch 196/200, Iteration 124/250, Loss: 0.0194\n",
      "Epoch 196/200, Iteration 125/250, Loss: 0.0098\n",
      "Epoch 196/200, Iteration 126/250, Loss: 0.0062\n",
      "Epoch 196/200, Iteration 127/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 128/250, Loss: 0.0130\n",
      "Epoch 196/200, Iteration 129/250, Loss: 0.0170\n",
      "Epoch 196/200, Iteration 130/250, Loss: 0.0217\n",
      "Epoch 196/200, Iteration 131/250, Loss: 0.0089\n",
      "Epoch 196/200, Iteration 132/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 133/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 134/250, Loss: 0.0067\n",
      "Epoch 196/200, Iteration 135/250, Loss: 0.0142\n",
      "Epoch 196/200, Iteration 136/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 137/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 138/250, Loss: 0.0163\n",
      "Epoch 196/200, Iteration 139/250, Loss: 0.0160\n",
      "Epoch 196/200, Iteration 140/250, Loss: 0.0148\n",
      "Epoch 196/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 196/200, Iteration 142/250, Loss: 0.0175\n",
      "Epoch 196/200, Iteration 143/250, Loss: 0.0100\n",
      "Epoch 196/200, Iteration 144/250, Loss: 0.0170\n",
      "Epoch 196/200, Iteration 145/250, Loss: 0.0170\n",
      "Epoch 196/200, Iteration 146/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 147/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 148/250, Loss: 0.0276\n",
      "Epoch 196/200, Iteration 149/250, Loss: 0.0208\n",
      "Epoch 196/200, Iteration 150/250, Loss: 0.0078\n",
      "Epoch 196/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 196/200, Iteration 152/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 153/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 154/250, Loss: 0.0113\n",
      "Epoch 196/200, Iteration 155/250, Loss: 0.0281\n",
      "Epoch 196/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 196/200, Iteration 157/250, Loss: 0.0309\n",
      "Epoch 196/200, Iteration 158/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 159/250, Loss: 0.0294\n",
      "Epoch 196/200, Iteration 160/250, Loss: 0.0156\n",
      "Epoch 196/200, Iteration 161/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 162/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 163/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 164/250, Loss: 0.0150\n",
      "Epoch 196/200, Iteration 165/250, Loss: 0.0110\n",
      "Epoch 196/200, Iteration 166/250, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 167/250, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 168/250, Loss: 0.0263\n",
      "Epoch 196/200, Iteration 169/250, Loss: 0.0108\n",
      "Epoch 196/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 196/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 196/200, Iteration 172/250, Loss: 0.0156\n",
      "Epoch 196/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 196/200, Iteration 174/250, Loss: 0.0103\n",
      "Epoch 196/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 176/250, Loss: 0.0202\n",
      "Epoch 196/200, Iteration 177/250, Loss: 0.0172\n",
      "Epoch 196/200, Iteration 178/250, Loss: 0.0112\n",
      "Epoch 196/200, Iteration 179/250, Loss: 0.0230\n",
      "Epoch 196/200, Iteration 180/250, Loss: 0.0154\n",
      "Epoch 196/200, Iteration 181/250, Loss: 0.0078\n",
      "Epoch 196/200, Iteration 182/250, Loss: 0.0085\n",
      "Epoch 196/200, Iteration 183/250, Loss: 0.0060\n",
      "Epoch 196/200, Iteration 184/250, Loss: 0.0174\n",
      "Epoch 196/200, Iteration 185/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 186/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 187/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 188/250, Loss: 0.0134\n",
      "Epoch 196/200, Iteration 189/250, Loss: 0.0278\n",
      "Epoch 196/200, Iteration 190/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 191/250, Loss: 0.0293\n",
      "Epoch 196/200, Iteration 192/250, Loss: 0.0284\n",
      "Epoch 196/200, Iteration 193/250, Loss: 0.0182\n",
      "Epoch 196/200, Iteration 194/250, Loss: 0.0232\n",
      "Epoch 196/200, Iteration 195/250, Loss: 0.0088\n",
      "Epoch 196/200, Iteration 196/250, Loss: 0.0103\n",
      "Epoch 196/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 198/250, Loss: 0.0181\n",
      "Epoch 196/200, Iteration 199/250, Loss: 0.0086\n",
      "Epoch 196/200, Iteration 200/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 201/250, Loss: 0.0071\n",
      "Epoch 196/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 196/200, Iteration 203/250, Loss: 0.0217\n",
      "Epoch 196/200, Iteration 204/250, Loss: 0.0185\n",
      "Epoch 196/200, Iteration 205/250, Loss: 0.0091\n",
      "Epoch 196/200, Iteration 206/250, Loss: 0.0248\n",
      "Epoch 196/200, Iteration 207/250, Loss: 0.0098\n",
      "Epoch 196/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 209/250, Loss: 0.0086\n",
      "Epoch 196/200, Iteration 210/250, Loss: 0.0236\n",
      "Epoch 196/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 196/200, Iteration 212/250, Loss: 0.0080\n",
      "Epoch 196/200, Iteration 213/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 214/250, Loss: 0.0110\n",
      "Epoch 196/200, Iteration 215/250, Loss: 0.0173\n",
      "Epoch 196/200, Iteration 216/250, Loss: 0.0157\n",
      "Epoch 196/200, Iteration 217/250, Loss: 0.0231\n",
      "Epoch 196/200, Iteration 218/250, Loss: 0.0148\n",
      "Epoch 196/200, Iteration 219/250, Loss: 0.0189\n",
      "Epoch 196/200, Iteration 220/250, Loss: 0.0086\n",
      "Epoch 196/200, Iteration 221/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 222/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 224/250, Loss: 0.0216\n",
      "Epoch 196/200, Iteration 225/250, Loss: 0.0060\n",
      "Epoch 196/200, Iteration 226/250, Loss: 0.0112\n",
      "Epoch 196/200, Iteration 227/250, Loss: 0.0415\n",
      "Epoch 196/200, Iteration 228/250, Loss: 0.0086\n",
      "Epoch 196/200, Iteration 229/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 230/250, Loss: 0.0139\n",
      "Epoch 196/200, Iteration 231/250, Loss: 0.0178\n",
      "Epoch 196/200, Iteration 232/250, Loss: 0.0242\n",
      "Epoch 196/200, Iteration 233/250, Loss: 0.0152\n",
      "Epoch 196/200, Iteration 234/250, Loss: 0.0169\n",
      "Epoch 196/200, Iteration 235/250, Loss: 0.0165\n",
      "Epoch 196/200, Iteration 236/250, Loss: 0.0127\n",
      "Epoch 196/200, Iteration 237/250, Loss: 0.0102\n",
      "Epoch 196/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 196/200, Iteration 239/250, Loss: 0.0226\n",
      "Epoch 196/200, Iteration 240/250, Loss: 0.0067\n",
      "Epoch 196/200, Iteration 241/250, Loss: 0.0143\n",
      "Epoch 196/200, Iteration 242/250, Loss: 0.0174\n",
      "Epoch 196/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 244/250, Loss: 0.0089\n",
      "Epoch 196/200, Iteration 245/250, Loss: 0.0130\n",
      "Epoch 196/200, Iteration 246/250, Loss: 0.0198\n",
      "Epoch 196/200, Iteration 247/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 248/250, Loss: 0.0122\n",
      "Epoch 196/200, Iteration 249/250, Loss: 0.0108\n",
      "Epoch 196/200, Iteration 250/250, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.005535, MRE: 0.601815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.005567, MRE: 0.978596 \n",
      "\n",
      "Epoch 197/200, Iteration 1/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 2/250, Loss: 0.0129\n",
      "Epoch 197/200, Iteration 3/250, Loss: 0.0140\n",
      "Epoch 197/200, Iteration 4/250, Loss: 0.0168\n",
      "Epoch 197/200, Iteration 5/250, Loss: 0.0166\n",
      "Epoch 197/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 197/200, Iteration 7/250, Loss: 0.0111\n",
      "Epoch 197/200, Iteration 8/250, Loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200, Iteration 9/250, Loss: 0.0124\n",
      "Epoch 197/200, Iteration 10/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 11/250, Loss: 0.0220\n",
      "Epoch 197/200, Iteration 12/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 13/250, Loss: 0.0161\n",
      "Epoch 197/200, Iteration 14/250, Loss: 0.0145\n",
      "Epoch 197/200, Iteration 15/250, Loss: 0.0124\n",
      "Epoch 197/200, Iteration 16/250, Loss: 0.0223\n",
      "Epoch 197/200, Iteration 17/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 18/250, Loss: 0.0128\n",
      "Epoch 197/200, Iteration 19/250, Loss: 0.0143\n",
      "Epoch 197/200, Iteration 20/250, Loss: 0.0114\n",
      "Epoch 197/200, Iteration 21/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 22/250, Loss: 0.0275\n",
      "Epoch 197/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 24/250, Loss: 0.0100\n",
      "Epoch 197/200, Iteration 25/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 26/250, Loss: 0.0120\n",
      "Epoch 197/200, Iteration 27/250, Loss: 0.0083\n",
      "Epoch 197/200, Iteration 28/250, Loss: 0.0138\n",
      "Epoch 197/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 30/250, Loss: 0.0090\n",
      "Epoch 197/200, Iteration 31/250, Loss: 0.0085\n",
      "Epoch 197/200, Iteration 32/250, Loss: 0.0237\n",
      "Epoch 197/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 34/250, Loss: 0.0119\n",
      "Epoch 197/200, Iteration 35/250, Loss: 0.0103\n",
      "Epoch 197/200, Iteration 36/250, Loss: 0.0083\n",
      "Epoch 197/200, Iteration 37/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 39/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 40/250, Loss: 0.0182\n",
      "Epoch 197/200, Iteration 41/250, Loss: 0.0117\n",
      "Epoch 197/200, Iteration 42/250, Loss: 0.0183\n",
      "Epoch 197/200, Iteration 43/250, Loss: 0.0159\n",
      "Epoch 197/200, Iteration 44/250, Loss: 0.0146\n",
      "Epoch 197/200, Iteration 45/250, Loss: 0.0170\n",
      "Epoch 197/200, Iteration 46/250, Loss: 0.0348\n",
      "Epoch 197/200, Iteration 47/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 48/250, Loss: 0.0242\n",
      "Epoch 197/200, Iteration 49/250, Loss: 0.0218\n",
      "Epoch 197/200, Iteration 50/250, Loss: 0.0234\n",
      "Epoch 197/200, Iteration 51/250, Loss: 0.0164\n",
      "Epoch 197/200, Iteration 52/250, Loss: 0.0094\n",
      "Epoch 197/200, Iteration 53/250, Loss: 0.0188\n",
      "Epoch 197/200, Iteration 54/250, Loss: 0.0218\n",
      "Epoch 197/200, Iteration 55/250, Loss: 0.0150\n",
      "Epoch 197/200, Iteration 56/250, Loss: 0.0093\n",
      "Epoch 197/200, Iteration 57/250, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 58/250, Loss: 0.0111\n",
      "Epoch 197/200, Iteration 59/250, Loss: 0.0066\n",
      "Epoch 197/200, Iteration 60/250, Loss: 0.0085\n",
      "Epoch 197/200, Iteration 61/250, Loss: 0.0260\n",
      "Epoch 197/200, Iteration 62/250, Loss: 0.0181\n",
      "Epoch 197/200, Iteration 63/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 64/250, Loss: 0.0149\n",
      "Epoch 197/200, Iteration 65/250, Loss: 0.0076\n",
      "Epoch 197/200, Iteration 66/250, Loss: 0.0085\n",
      "Epoch 197/200, Iteration 67/250, Loss: 0.0096\n",
      "Epoch 197/200, Iteration 68/250, Loss: 0.0159\n",
      "Epoch 197/200, Iteration 69/250, Loss: 0.0155\n",
      "Epoch 197/200, Iteration 70/250, Loss: 0.0164\n",
      "Epoch 197/200, Iteration 71/250, Loss: 0.0187\n",
      "Epoch 197/200, Iteration 72/250, Loss: 0.0158\n",
      "Epoch 197/200, Iteration 73/250, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 74/250, Loss: 0.0313\n",
      "Epoch 197/200, Iteration 75/250, Loss: 0.0302\n",
      "Epoch 197/200, Iteration 76/250, Loss: 0.0294\n",
      "Epoch 197/200, Iteration 77/250, Loss: 0.0068\n",
      "Epoch 197/200, Iteration 78/250, Loss: 0.0115\n",
      "Epoch 197/200, Iteration 79/250, Loss: 0.0082\n",
      "Epoch 197/200, Iteration 80/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 81/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 82/250, Loss: 0.0103\n",
      "Epoch 197/200, Iteration 83/250, Loss: 0.0080\n",
      "Epoch 197/200, Iteration 84/250, Loss: 0.0340\n",
      "Epoch 197/200, Iteration 85/250, Loss: 0.0084\n",
      "Epoch 197/200, Iteration 86/250, Loss: 0.0185\n",
      "Epoch 197/200, Iteration 87/250, Loss: 0.0064\n",
      "Epoch 197/200, Iteration 88/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 89/250, Loss: 0.0193\n",
      "Epoch 197/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 197/200, Iteration 91/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 93/250, Loss: 0.0077\n",
      "Epoch 197/200, Iteration 94/250, Loss: 0.0094\n",
      "Epoch 197/200, Iteration 95/250, Loss: 0.0241\n",
      "Epoch 197/200, Iteration 96/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 97/250, Loss: 0.0151\n",
      "Epoch 197/200, Iteration 98/250, Loss: 0.0110\n",
      "Epoch 197/200, Iteration 99/250, Loss: 0.0138\n",
      "Epoch 197/200, Iteration 100/250, Loss: 0.0144\n",
      "Epoch 197/200, Iteration 101/250, Loss: 0.0248\n",
      "Epoch 197/200, Iteration 102/250, Loss: 0.0183\n",
      "Epoch 197/200, Iteration 103/250, Loss: 0.0131\n",
      "Epoch 197/200, Iteration 104/250, Loss: 0.0082\n",
      "Epoch 197/200, Iteration 105/250, Loss: 0.0108\n",
      "Epoch 197/200, Iteration 106/250, Loss: 0.0258\n",
      "Epoch 197/200, Iteration 107/250, Loss: 0.0335\n",
      "Epoch 197/200, Iteration 108/250, Loss: 0.0123\n",
      "Epoch 197/200, Iteration 109/250, Loss: 0.0157\n",
      "Epoch 197/200, Iteration 110/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 111/250, Loss: 0.0090\n",
      "Epoch 197/200, Iteration 112/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 113/250, Loss: 0.0084\n",
      "Epoch 197/200, Iteration 114/250, Loss: 0.0058\n",
      "Epoch 197/200, Iteration 115/250, Loss: 0.0070\n",
      "Epoch 197/200, Iteration 116/250, Loss: 0.0137\n",
      "Epoch 197/200, Iteration 117/250, Loss: 0.0316\n",
      "Epoch 197/200, Iteration 118/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 119/250, Loss: 0.0148\n",
      "Epoch 197/200, Iteration 120/250, Loss: 0.0441\n",
      "Epoch 197/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 122/250, Loss: 0.0069\n",
      "Epoch 197/200, Iteration 123/250, Loss: 0.0292\n",
      "Epoch 197/200, Iteration 124/250, Loss: 0.0235\n",
      "Epoch 197/200, Iteration 125/250, Loss: 0.0106\n",
      "Epoch 197/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 127/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 128/250, Loss: 0.0102\n",
      "Epoch 197/200, Iteration 129/250, Loss: 0.0233\n",
      "Epoch 197/200, Iteration 130/250, Loss: 0.0099\n",
      "Epoch 197/200, Iteration 131/250, Loss: 0.0179\n",
      "Epoch 197/200, Iteration 132/250, Loss: 0.0227\n",
      "Epoch 197/200, Iteration 133/250, Loss: 0.0110\n",
      "Epoch 197/200, Iteration 134/250, Loss: 0.0103\n",
      "Epoch 197/200, Iteration 135/250, Loss: 0.0072\n",
      "Epoch 197/200, Iteration 136/250, Loss: 0.0176\n",
      "Epoch 197/200, Iteration 137/250, Loss: 0.0094\n",
      "Epoch 197/200, Iteration 138/250, Loss: 0.0080\n",
      "Epoch 197/200, Iteration 139/250, Loss: 0.0140\n",
      "Epoch 197/200, Iteration 140/250, Loss: 0.0175\n",
      "Epoch 197/200, Iteration 141/250, Loss: 0.0297\n",
      "Epoch 197/200, Iteration 142/250, Loss: 0.0158\n",
      "Epoch 197/200, Iteration 143/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 144/250, Loss: 0.0166\n",
      "Epoch 197/200, Iteration 145/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 146/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 147/250, Loss: 0.0220\n",
      "Epoch 197/200, Iteration 148/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 150/250, Loss: 0.0049\n",
      "Epoch 197/200, Iteration 151/250, Loss: 0.0075\n",
      "Epoch 197/200, Iteration 152/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 153/250, Loss: 0.0103\n",
      "Epoch 197/200, Iteration 154/250, Loss: 0.0081\n",
      "Epoch 197/200, Iteration 155/250, Loss: 0.0124\n",
      "Epoch 197/200, Iteration 156/250, Loss: 0.0225\n",
      "Epoch 197/200, Iteration 157/250, Loss: 0.0169\n",
      "Epoch 197/200, Iteration 158/250, Loss: 0.0198\n",
      "Epoch 197/200, Iteration 159/250, Loss: 0.0135\n",
      "Epoch 197/200, Iteration 160/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 161/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 162/250, Loss: 0.0149\n",
      "Epoch 197/200, Iteration 163/250, Loss: 0.0149\n",
      "Epoch 197/200, Iteration 164/250, Loss: 0.0141\n",
      "Epoch 197/200, Iteration 165/250, Loss: 0.0195\n",
      "Epoch 197/200, Iteration 166/250, Loss: 0.0139\n",
      "Epoch 197/200, Iteration 167/250, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 168/250, Loss: 0.0134\n",
      "Epoch 197/200, Iteration 169/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 170/250, Loss: 0.0210\n",
      "Epoch 197/200, Iteration 171/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 197/200, Iteration 173/250, Loss: 0.0210\n",
      "Epoch 197/200, Iteration 174/250, Loss: 0.0241\n",
      "Epoch 197/200, Iteration 175/250, Loss: 0.0146\n",
      "Epoch 197/200, Iteration 176/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 178/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 180/250, Loss: 0.0059\n",
      "Epoch 197/200, Iteration 181/250, Loss: 0.0073\n",
      "Epoch 197/200, Iteration 182/250, Loss: 0.0086\n",
      "Epoch 197/200, Iteration 183/250, Loss: 0.0183\n",
      "Epoch 197/200, Iteration 184/250, Loss: 0.0099\n",
      "Epoch 197/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 197/200, Iteration 186/250, Loss: 0.0257\n",
      "Epoch 197/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 197/200, Iteration 188/250, Loss: 0.0173\n",
      "Epoch 197/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 197/200, Iteration 190/250, Loss: 0.0115\n",
      "Epoch 197/200, Iteration 191/250, Loss: 0.0074\n",
      "Epoch 197/200, Iteration 192/250, Loss: 0.0119\n",
      "Epoch 197/200, Iteration 193/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 194/250, Loss: 0.0463\n",
      "Epoch 197/200, Iteration 195/250, Loss: 0.0096\n",
      "Epoch 197/200, Iteration 196/250, Loss: 0.0198\n",
      "Epoch 197/200, Iteration 197/250, Loss: 0.0070\n",
      "Epoch 197/200, Iteration 198/250, Loss: 0.0285\n",
      "Epoch 197/200, Iteration 199/250, Loss: 0.0106\n",
      "Epoch 197/200, Iteration 200/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 201/250, Loss: 0.0205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200, Iteration 202/250, Loss: 0.0199\n",
      "Epoch 197/200, Iteration 203/250, Loss: 0.0083\n",
      "Epoch 197/200, Iteration 204/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 205/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 206/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 207/250, Loss: 0.0217\n",
      "Epoch 197/200, Iteration 208/250, Loss: 0.0181\n",
      "Epoch 197/200, Iteration 209/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 210/250, Loss: 0.0172\n",
      "Epoch 197/200, Iteration 211/250, Loss: 0.0130\n",
      "Epoch 197/200, Iteration 212/250, Loss: 0.0146\n",
      "Epoch 197/200, Iteration 213/250, Loss: 0.0188\n",
      "Epoch 197/200, Iteration 214/250, Loss: 0.0160\n",
      "Epoch 197/200, Iteration 215/250, Loss: 0.0119\n",
      "Epoch 197/200, Iteration 216/250, Loss: 0.0134\n",
      "Epoch 197/200, Iteration 217/250, Loss: 0.0078\n",
      "Epoch 197/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 220/250, Loss: 0.0120\n",
      "Epoch 197/200, Iteration 221/250, Loss: 0.0165\n",
      "Epoch 197/200, Iteration 222/250, Loss: 0.0068\n",
      "Epoch 197/200, Iteration 223/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 224/250, Loss: 0.0132\n",
      "Epoch 197/200, Iteration 225/250, Loss: 0.0102\n",
      "Epoch 197/200, Iteration 226/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 197/200, Iteration 229/250, Loss: 0.0228\n",
      "Epoch 197/200, Iteration 230/250, Loss: 0.0319\n",
      "Epoch 197/200, Iteration 231/250, Loss: 0.0194\n",
      "Epoch 197/200, Iteration 232/250, Loss: 0.0224\n",
      "Epoch 197/200, Iteration 233/250, Loss: 0.0120\n",
      "Epoch 197/200, Iteration 234/250, Loss: 0.0115\n",
      "Epoch 197/200, Iteration 235/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 236/250, Loss: 0.0290\n",
      "Epoch 197/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 197/200, Iteration 238/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 239/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 240/250, Loss: 0.0113\n",
      "Epoch 197/200, Iteration 241/250, Loss: 0.0082\n",
      "Epoch 197/200, Iteration 242/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 243/250, Loss: 0.0081\n",
      "Epoch 197/200, Iteration 244/250, Loss: 0.0186\n",
      "Epoch 197/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 197/200, Iteration 246/250, Loss: 0.0141\n",
      "Epoch 197/200, Iteration 247/250, Loss: 0.0078\n",
      "Epoch 197/200, Iteration 248/250, Loss: 0.0184\n",
      "Epoch 197/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 197/200, Iteration 250/250, Loss: 0.0183\n",
      "Train Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.006146, MRE: 0.610458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.006175, MRE: 0.883874 \n",
      "\n",
      "Epoch 198/200, Iteration 1/250, Loss: 0.0128\n",
      "Epoch 198/200, Iteration 2/250, Loss: 0.0176\n",
      "Epoch 198/200, Iteration 3/250, Loss: 0.0118\n",
      "Epoch 198/200, Iteration 4/250, Loss: 0.0142\n",
      "Epoch 198/200, Iteration 5/250, Loss: 0.0064\n",
      "Epoch 198/200, Iteration 6/250, Loss: 0.0339\n",
      "Epoch 198/200, Iteration 7/250, Loss: 0.0197\n",
      "Epoch 198/200, Iteration 8/250, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 9/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 10/250, Loss: 0.0155\n",
      "Epoch 198/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 198/200, Iteration 12/250, Loss: 0.0277\n",
      "Epoch 198/200, Iteration 13/250, Loss: 0.0142\n",
      "Epoch 198/200, Iteration 14/250, Loss: 0.0119\n",
      "Epoch 198/200, Iteration 15/250, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 16/250, Loss: 0.0204\n",
      "Epoch 198/200, Iteration 17/250, Loss: 0.0308\n",
      "Epoch 198/200, Iteration 18/250, Loss: 0.0234\n",
      "Epoch 198/200, Iteration 19/250, Loss: 0.0108\n",
      "Epoch 198/200, Iteration 20/250, Loss: 0.0191\n",
      "Epoch 198/200, Iteration 21/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 22/250, Loss: 0.0095\n",
      "Epoch 198/200, Iteration 23/250, Loss: 0.0100\n",
      "Epoch 198/200, Iteration 24/250, Loss: 0.0127\n",
      "Epoch 198/200, Iteration 25/250, Loss: 0.0179\n",
      "Epoch 198/200, Iteration 26/250, Loss: 0.0166\n",
      "Epoch 198/200, Iteration 27/250, Loss: 0.0197\n",
      "Epoch 198/200, Iteration 28/250, Loss: 0.0130\n",
      "Epoch 198/200, Iteration 29/250, Loss: 0.0227\n",
      "Epoch 198/200, Iteration 30/250, Loss: 0.0059\n",
      "Epoch 198/200, Iteration 31/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 32/250, Loss: 0.0381\n",
      "Epoch 198/200, Iteration 33/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 34/250, Loss: 0.0062\n",
      "Epoch 198/200, Iteration 35/250, Loss: 0.0141\n",
      "Epoch 198/200, Iteration 36/250, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 37/250, Loss: 0.0112\n",
      "Epoch 198/200, Iteration 38/250, Loss: 0.0105\n",
      "Epoch 198/200, Iteration 39/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 40/250, Loss: 0.0144\n",
      "Epoch 198/200, Iteration 41/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 42/250, Loss: 0.0198\n",
      "Epoch 198/200, Iteration 43/250, Loss: 0.0112\n",
      "Epoch 198/200, Iteration 44/250, Loss: 0.0169\n",
      "Epoch 198/200, Iteration 45/250, Loss: 0.0069\n",
      "Epoch 198/200, Iteration 46/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 47/250, Loss: 0.0106\n",
      "Epoch 198/200, Iteration 48/250, Loss: 0.0207\n",
      "Epoch 198/200, Iteration 49/250, Loss: 0.0069\n",
      "Epoch 198/200, Iteration 50/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 51/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 52/250, Loss: 0.0312\n",
      "Epoch 198/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 198/200, Iteration 54/250, Loss: 0.0179\n",
      "Epoch 198/200, Iteration 55/250, Loss: 0.0085\n",
      "Epoch 198/200, Iteration 56/250, Loss: 0.0201\n",
      "Epoch 198/200, Iteration 57/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 58/250, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 59/250, Loss: 0.0127\n",
      "Epoch 198/200, Iteration 60/250, Loss: 0.0193\n",
      "Epoch 198/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 198/200, Iteration 62/250, Loss: 0.0127\n",
      "Epoch 198/200, Iteration 63/250, Loss: 0.0074\n",
      "Epoch 198/200, Iteration 64/250, Loss: 0.0092\n",
      "Epoch 198/200, Iteration 65/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 66/250, Loss: 0.0053\n",
      "Epoch 198/200, Iteration 67/250, Loss: 0.0097\n",
      "Epoch 198/200, Iteration 68/250, Loss: 0.0217\n",
      "Epoch 198/200, Iteration 69/250, Loss: 0.0078\n",
      "Epoch 198/200, Iteration 70/250, Loss: 0.0121\n",
      "Epoch 198/200, Iteration 71/250, Loss: 0.0103\n",
      "Epoch 198/200, Iteration 72/250, Loss: 0.0176\n",
      "Epoch 198/200, Iteration 73/250, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 74/250, Loss: 0.0132\n",
      "Epoch 198/200, Iteration 75/250, Loss: 0.0051\n",
      "Epoch 198/200, Iteration 76/250, Loss: 0.0118\n",
      "Epoch 198/200, Iteration 77/250, Loss: 0.0065\n",
      "Epoch 198/200, Iteration 78/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 79/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 80/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 81/250, Loss: 0.0109\n",
      "Epoch 198/200, Iteration 82/250, Loss: 0.0158\n",
      "Epoch 198/200, Iteration 83/250, Loss: 0.0171\n",
      "Epoch 198/200, Iteration 84/250, Loss: 0.0141\n",
      "Epoch 198/200, Iteration 85/250, Loss: 0.0113\n",
      "Epoch 198/200, Iteration 86/250, Loss: 0.0104\n",
      "Epoch 198/200, Iteration 87/250, Loss: 0.0357\n",
      "Epoch 198/200, Iteration 88/250, Loss: 0.0077\n",
      "Epoch 198/200, Iteration 89/250, Loss: 0.0135\n",
      "Epoch 198/200, Iteration 90/250, Loss: 0.0155\n",
      "Epoch 198/200, Iteration 91/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 92/250, Loss: 0.0090\n",
      "Epoch 198/200, Iteration 93/250, Loss: 0.0135\n",
      "Epoch 198/200, Iteration 94/250, Loss: 0.0057\n",
      "Epoch 198/200, Iteration 95/250, Loss: 0.0322\n",
      "Epoch 198/200, Iteration 96/250, Loss: 0.0125\n",
      "Epoch 198/200, Iteration 97/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 98/250, Loss: 0.0054\n",
      "Epoch 198/200, Iteration 99/250, Loss: 0.0177\n",
      "Epoch 198/200, Iteration 100/250, Loss: 0.0057\n",
      "Epoch 198/200, Iteration 101/250, Loss: 0.0149\n",
      "Epoch 198/200, Iteration 102/250, Loss: 0.0091\n",
      "Epoch 198/200, Iteration 103/250, Loss: 0.0340\n",
      "Epoch 198/200, Iteration 104/250, Loss: 0.0137\n",
      "Epoch 198/200, Iteration 105/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 106/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 107/250, Loss: 0.0153\n",
      "Epoch 198/200, Iteration 108/250, Loss: 0.0269\n",
      "Epoch 198/200, Iteration 109/250, Loss: 0.0076\n",
      "Epoch 198/200, Iteration 110/250, Loss: 0.0070\n",
      "Epoch 198/200, Iteration 111/250, Loss: 0.0239\n",
      "Epoch 198/200, Iteration 112/250, Loss: 0.0075\n",
      "Epoch 198/200, Iteration 113/250, Loss: 0.0066\n",
      "Epoch 198/200, Iteration 114/250, Loss: 0.0128\n",
      "Epoch 198/200, Iteration 115/250, Loss: 0.0259\n",
      "Epoch 198/200, Iteration 116/250, Loss: 0.0157\n",
      "Epoch 198/200, Iteration 117/250, Loss: 0.0132\n",
      "Epoch 198/200, Iteration 118/250, Loss: 0.0110\n",
      "Epoch 198/200, Iteration 119/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 120/250, Loss: 0.0221\n",
      "Epoch 198/200, Iteration 121/250, Loss: 0.0245\n",
      "Epoch 198/200, Iteration 122/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 123/250, Loss: 0.0093\n",
      "Epoch 198/200, Iteration 124/250, Loss: 0.0074\n",
      "Epoch 198/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 198/200, Iteration 126/250, Loss: 0.0145\n",
      "Epoch 198/200, Iteration 127/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 128/250, Loss: 0.0049\n",
      "Epoch 198/200, Iteration 129/250, Loss: 0.0105\n",
      "Epoch 198/200, Iteration 130/250, Loss: 0.0090\n",
      "Epoch 198/200, Iteration 131/250, Loss: 0.0269\n",
      "Epoch 198/200, Iteration 132/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 133/250, Loss: 0.0084\n",
      "Epoch 198/200, Iteration 134/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 135/250, Loss: 0.0177\n",
      "Epoch 198/200, Iteration 136/250, Loss: 0.0188\n",
      "Epoch 198/200, Iteration 137/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 138/250, Loss: 0.0132\n",
      "Epoch 198/200, Iteration 139/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 198/200, Iteration 141/250, Loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200, Iteration 142/250, Loss: 0.0117\n",
      "Epoch 198/200, Iteration 143/250, Loss: 0.0078\n",
      "Epoch 198/200, Iteration 144/250, Loss: 0.0107\n",
      "Epoch 198/200, Iteration 145/250, Loss: 0.0073\n",
      "Epoch 198/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 198/200, Iteration 147/250, Loss: 0.0104\n",
      "Epoch 198/200, Iteration 148/250, Loss: 0.0256\n",
      "Epoch 198/200, Iteration 149/250, Loss: 0.0353\n",
      "Epoch 198/200, Iteration 150/250, Loss: 0.0186\n",
      "Epoch 198/200, Iteration 151/250, Loss: 0.0065\n",
      "Epoch 198/200, Iteration 152/250, Loss: 0.0105\n",
      "Epoch 198/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 154/250, Loss: 0.0237\n",
      "Epoch 198/200, Iteration 155/250, Loss: 0.0095\n",
      "Epoch 198/200, Iteration 156/250, Loss: 0.0165\n",
      "Epoch 198/200, Iteration 157/250, Loss: 0.0129\n",
      "Epoch 198/200, Iteration 158/250, Loss: 0.0104\n",
      "Epoch 198/200, Iteration 159/250, Loss: 0.0204\n",
      "Epoch 198/200, Iteration 160/250, Loss: 0.0056\n",
      "Epoch 198/200, Iteration 161/250, Loss: 0.0051\n",
      "Epoch 198/200, Iteration 162/250, Loss: 0.0119\n",
      "Epoch 198/200, Iteration 163/250, Loss: 0.0076\n",
      "Epoch 198/200, Iteration 164/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 165/250, Loss: 0.0079\n",
      "Epoch 198/200, Iteration 166/250, Loss: 0.0208\n",
      "Epoch 198/200, Iteration 167/250, Loss: 0.0138\n",
      "Epoch 198/200, Iteration 168/250, Loss: 0.0137\n",
      "Epoch 198/200, Iteration 169/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 170/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 171/250, Loss: 0.0251\n",
      "Epoch 198/200, Iteration 172/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 174/250, Loss: 0.0184\n",
      "Epoch 198/200, Iteration 175/250, Loss: 0.0118\n",
      "Epoch 198/200, Iteration 176/250, Loss: 0.0095\n",
      "Epoch 198/200, Iteration 177/250, Loss: 0.0129\n",
      "Epoch 198/200, Iteration 178/250, Loss: 0.0245\n",
      "Epoch 198/200, Iteration 179/250, Loss: 0.0135\n",
      "Epoch 198/200, Iteration 180/250, Loss: 0.0211\n",
      "Epoch 198/200, Iteration 181/250, Loss: 0.0146\n",
      "Epoch 198/200, Iteration 182/250, Loss: 0.0089\n",
      "Epoch 198/200, Iteration 183/250, Loss: 0.0293\n",
      "Epoch 198/200, Iteration 184/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 185/250, Loss: 0.0165\n",
      "Epoch 198/200, Iteration 186/250, Loss: 0.0110\n",
      "Epoch 198/200, Iteration 187/250, Loss: 0.0606\n",
      "Epoch 198/200, Iteration 188/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 198/200, Iteration 190/250, Loss: 0.0130\n",
      "Epoch 198/200, Iteration 191/250, Loss: 0.0141\n",
      "Epoch 198/200, Iteration 192/250, Loss: 0.0139\n",
      "Epoch 198/200, Iteration 193/250, Loss: 0.0230\n",
      "Epoch 198/200, Iteration 194/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 195/250, Loss: 0.0086\n",
      "Epoch 198/200, Iteration 196/250, Loss: 0.0100\n",
      "Epoch 198/200, Iteration 197/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 198/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 199/250, Loss: 0.0123\n",
      "Epoch 198/200, Iteration 200/250, Loss: 0.0076\n",
      "Epoch 198/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 198/200, Iteration 202/250, Loss: 0.0178\n",
      "Epoch 198/200, Iteration 203/250, Loss: 0.0091\n",
      "Epoch 198/200, Iteration 204/250, Loss: 0.0323\n",
      "Epoch 198/200, Iteration 205/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 206/250, Loss: 0.0092\n",
      "Epoch 198/200, Iteration 207/250, Loss: 0.0223\n",
      "Epoch 198/200, Iteration 208/250, Loss: 0.0093\n",
      "Epoch 198/200, Iteration 209/250, Loss: 0.0267\n",
      "Epoch 198/200, Iteration 210/250, Loss: 0.0158\n",
      "Epoch 198/200, Iteration 211/250, Loss: 0.0168\n",
      "Epoch 198/200, Iteration 212/250, Loss: 0.0128\n",
      "Epoch 198/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 198/200, Iteration 214/250, Loss: 0.0152\n",
      "Epoch 198/200, Iteration 215/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 198/200, Iteration 217/250, Loss: 0.0236\n",
      "Epoch 198/200, Iteration 218/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 198/200, Iteration 220/250, Loss: 0.0197\n",
      "Epoch 198/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 198/200, Iteration 222/250, Loss: 0.0249\n",
      "Epoch 198/200, Iteration 223/250, Loss: 0.0291\n",
      "Epoch 198/200, Iteration 224/250, Loss: 0.0219\n",
      "Epoch 198/200, Iteration 225/250, Loss: 0.0315\n",
      "Epoch 198/200, Iteration 226/250, Loss: 0.0271\n",
      "Epoch 198/200, Iteration 227/250, Loss: 0.0127\n",
      "Epoch 198/200, Iteration 228/250, Loss: 0.0107\n",
      "Epoch 198/200, Iteration 229/250, Loss: 0.0114\n",
      "Epoch 198/200, Iteration 230/250, Loss: 0.0124\n",
      "Epoch 198/200, Iteration 231/250, Loss: 0.0167\n",
      "Epoch 198/200, Iteration 232/250, Loss: 0.0121\n",
      "Epoch 198/200, Iteration 233/250, Loss: 0.0146\n",
      "Epoch 198/200, Iteration 234/250, Loss: 0.0168\n",
      "Epoch 198/200, Iteration 235/250, Loss: 0.0119\n",
      "Epoch 198/200, Iteration 236/250, Loss: 0.0316\n",
      "Epoch 198/200, Iteration 237/250, Loss: 0.0072\n",
      "Epoch 198/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 198/200, Iteration 239/250, Loss: 0.0256\n",
      "Epoch 198/200, Iteration 240/250, Loss: 0.0132\n",
      "Epoch 198/200, Iteration 241/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 242/250, Loss: 0.0181\n",
      "Epoch 198/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 198/200, Iteration 244/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 245/250, Loss: 0.0245\n",
      "Epoch 198/200, Iteration 246/250, Loss: 0.0146\n",
      "Epoch 198/200, Iteration 247/250, Loss: 0.0065\n",
      "Epoch 198/200, Iteration 248/250, Loss: 0.0078\n",
      "Epoch 198/200, Iteration 249/250, Loss: 0.0102\n",
      "Epoch 198/200, Iteration 250/250, Loss: 0.0142\n",
      "Train Error: \n",
      " Accuracy: 88.98%, Avg loss: 0.005999, MRE: 0.581515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.006074, MRE: 0.912032 \n",
      "\n",
      "Epoch 199/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 199/200, Iteration 2/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 3/250, Loss: 0.0088\n",
      "Epoch 199/200, Iteration 4/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 5/250, Loss: 0.0189\n",
      "Epoch 199/200, Iteration 6/250, Loss: 0.0132\n",
      "Epoch 199/200, Iteration 7/250, Loss: 0.0296\n",
      "Epoch 199/200, Iteration 8/250, Loss: 0.0202\n",
      "Epoch 199/200, Iteration 9/250, Loss: 0.0179\n",
      "Epoch 199/200, Iteration 10/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 11/250, Loss: 0.0063\n",
      "Epoch 199/200, Iteration 12/250, Loss: 0.0201\n",
      "Epoch 199/200, Iteration 13/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 14/250, Loss: 0.0096\n",
      "Epoch 199/200, Iteration 15/250, Loss: 0.0115\n",
      "Epoch 199/200, Iteration 16/250, Loss: 0.0065\n",
      "Epoch 199/200, Iteration 17/250, Loss: 0.0112\n",
      "Epoch 199/200, Iteration 18/250, Loss: 0.0226\n",
      "Epoch 199/200, Iteration 19/250, Loss: 0.0141\n",
      "Epoch 199/200, Iteration 20/250, Loss: 0.0222\n",
      "Epoch 199/200, Iteration 21/250, Loss: 0.0098\n",
      "Epoch 199/200, Iteration 22/250, Loss: 0.0144\n",
      "Epoch 199/200, Iteration 23/250, Loss: 0.0064\n",
      "Epoch 199/200, Iteration 24/250, Loss: 0.0149\n",
      "Epoch 199/200, Iteration 25/250, Loss: 0.0177\n",
      "Epoch 199/200, Iteration 26/250, Loss: 0.0091\n",
      "Epoch 199/200, Iteration 27/250, Loss: 0.0128\n",
      "Epoch 199/200, Iteration 28/250, Loss: 0.0143\n",
      "Epoch 199/200, Iteration 29/250, Loss: 0.0532\n",
      "Epoch 199/200, Iteration 30/250, Loss: 0.0059\n",
      "Epoch 199/200, Iteration 31/250, Loss: 0.0114\n",
      "Epoch 199/200, Iteration 32/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 33/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 34/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 35/250, Loss: 0.0128\n",
      "Epoch 199/200, Iteration 36/250, Loss: 0.0080\n",
      "Epoch 199/200, Iteration 37/250, Loss: 0.0156\n",
      "Epoch 199/200, Iteration 38/250, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 39/250, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 199/200, Iteration 41/250, Loss: 0.0148\n",
      "Epoch 199/200, Iteration 42/250, Loss: 0.0142\n",
      "Epoch 199/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 199/200, Iteration 44/250, Loss: 0.0227\n",
      "Epoch 199/200, Iteration 45/250, Loss: 0.0217\n",
      "Epoch 199/200, Iteration 46/250, Loss: 0.0131\n",
      "Epoch 199/200, Iteration 47/250, Loss: 0.0133\n",
      "Epoch 199/200, Iteration 48/250, Loss: 0.0096\n",
      "Epoch 199/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 199/200, Iteration 50/250, Loss: 0.0093\n",
      "Epoch 199/200, Iteration 51/250, Loss: 0.0124\n",
      "Epoch 199/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 53/250, Loss: 0.0100\n",
      "Epoch 199/200, Iteration 54/250, Loss: 0.0139\n",
      "Epoch 199/200, Iteration 55/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 56/250, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 57/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 58/250, Loss: 0.0145\n",
      "Epoch 199/200, Iteration 59/250, Loss: 0.0219\n",
      "Epoch 199/200, Iteration 60/250, Loss: 0.0239\n",
      "Epoch 199/200, Iteration 61/250, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 62/250, Loss: 0.0082\n",
      "Epoch 199/200, Iteration 63/250, Loss: 0.0073\n",
      "Epoch 199/200, Iteration 64/250, Loss: 0.0128\n",
      "Epoch 199/200, Iteration 65/250, Loss: 0.0279\n",
      "Epoch 199/200, Iteration 66/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 67/250, Loss: 0.0127\n",
      "Epoch 199/200, Iteration 68/250, Loss: 0.0192\n",
      "Epoch 199/200, Iteration 69/250, Loss: 0.0249\n",
      "Epoch 199/200, Iteration 70/250, Loss: 0.0253\n",
      "Epoch 199/200, Iteration 71/250, Loss: 0.0155\n",
      "Epoch 199/200, Iteration 72/250, Loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200, Iteration 73/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 74/250, Loss: 0.0168\n",
      "Epoch 199/200, Iteration 75/250, Loss: 0.0175\n",
      "Epoch 199/200, Iteration 76/250, Loss: 0.0216\n",
      "Epoch 199/200, Iteration 77/250, Loss: 0.0187\n",
      "Epoch 199/200, Iteration 78/250, Loss: 0.0212\n",
      "Epoch 199/200, Iteration 79/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 80/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 81/250, Loss: 0.0112\n",
      "Epoch 199/200, Iteration 82/250, Loss: 0.0055\n",
      "Epoch 199/200, Iteration 83/250, Loss: 0.0204\n",
      "Epoch 199/200, Iteration 84/250, Loss: 0.0122\n",
      "Epoch 199/200, Iteration 85/250, Loss: 0.0195\n",
      "Epoch 199/200, Iteration 86/250, Loss: 0.0173\n",
      "Epoch 199/200, Iteration 87/250, Loss: 0.0207\n",
      "Epoch 199/200, Iteration 88/250, Loss: 0.0062\n",
      "Epoch 199/200, Iteration 89/250, Loss: 0.0091\n",
      "Epoch 199/200, Iteration 90/250, Loss: 0.0070\n",
      "Epoch 199/200, Iteration 91/250, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 92/250, Loss: 0.0100\n",
      "Epoch 199/200, Iteration 93/250, Loss: 0.0098\n",
      "Epoch 199/200, Iteration 94/250, Loss: 0.0148\n",
      "Epoch 199/200, Iteration 95/250, Loss: 0.0262\n",
      "Epoch 199/200, Iteration 96/250, Loss: 0.0187\n",
      "Epoch 199/200, Iteration 97/250, Loss: 0.0072\n",
      "Epoch 199/200, Iteration 98/250, Loss: 0.0074\n",
      "Epoch 199/200, Iteration 99/250, Loss: 0.0186\n",
      "Epoch 199/200, Iteration 100/250, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 101/250, Loss: 0.0072\n",
      "Epoch 199/200, Iteration 102/250, Loss: 0.0072\n",
      "Epoch 199/200, Iteration 103/250, Loss: 0.0179\n",
      "Epoch 199/200, Iteration 104/250, Loss: 0.0057\n",
      "Epoch 199/200, Iteration 105/250, Loss: 0.0086\n",
      "Epoch 199/200, Iteration 106/250, Loss: 0.0296\n",
      "Epoch 199/200, Iteration 107/250, Loss: 0.0082\n",
      "Epoch 199/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 199/200, Iteration 109/250, Loss: 0.0181\n",
      "Epoch 199/200, Iteration 110/250, Loss: 0.0086\n",
      "Epoch 199/200, Iteration 111/250, Loss: 0.0165\n",
      "Epoch 199/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 113/250, Loss: 0.0133\n",
      "Epoch 199/200, Iteration 114/250, Loss: 0.0284\n",
      "Epoch 199/200, Iteration 115/250, Loss: 0.0078\n",
      "Epoch 199/200, Iteration 116/250, Loss: 0.0149\n",
      "Epoch 199/200, Iteration 117/250, Loss: 0.0257\n",
      "Epoch 199/200, Iteration 118/250, Loss: 0.0087\n",
      "Epoch 199/200, Iteration 119/250, Loss: 0.0194\n",
      "Epoch 199/200, Iteration 120/250, Loss: 0.0364\n",
      "Epoch 199/200, Iteration 121/250, Loss: 0.0141\n",
      "Epoch 199/200, Iteration 122/250, Loss: 0.0148\n",
      "Epoch 199/200, Iteration 123/250, Loss: 0.0165\n",
      "Epoch 199/200, Iteration 124/250, Loss: 0.0350\n",
      "Epoch 199/200, Iteration 125/250, Loss: 0.0172\n",
      "Epoch 199/200, Iteration 126/250, Loss: 0.0078\n",
      "Epoch 199/200, Iteration 127/250, Loss: 0.0160\n",
      "Epoch 199/200, Iteration 128/250, Loss: 0.0150\n",
      "Epoch 199/200, Iteration 129/250, Loss: 0.0279\n",
      "Epoch 199/200, Iteration 130/250, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 131/250, Loss: 0.0142\n",
      "Epoch 199/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 133/250, Loss: 0.0192\n",
      "Epoch 199/200, Iteration 134/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 199/200, Iteration 137/250, Loss: 0.0197\n",
      "Epoch 199/200, Iteration 138/250, Loss: 0.0257\n",
      "Epoch 199/200, Iteration 139/250, Loss: 0.0111\n",
      "Epoch 199/200, Iteration 140/250, Loss: 0.0165\n",
      "Epoch 199/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 142/250, Loss: 0.0181\n",
      "Epoch 199/200, Iteration 143/250, Loss: 0.0102\n",
      "Epoch 199/200, Iteration 144/250, Loss: 0.0201\n",
      "Epoch 199/200, Iteration 145/250, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 146/250, Loss: 0.0073\n",
      "Epoch 199/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 148/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 149/250, Loss: 0.0132\n",
      "Epoch 199/200, Iteration 150/250, Loss: 0.0088\n",
      "Epoch 199/200, Iteration 151/250, Loss: 0.0363\n",
      "Epoch 199/200, Iteration 152/250, Loss: 0.0115\n",
      "Epoch 199/200, Iteration 153/250, Loss: 0.0088\n",
      "Epoch 199/200, Iteration 154/250, Loss: 0.0217\n",
      "Epoch 199/200, Iteration 155/250, Loss: 0.0089\n",
      "Epoch 199/200, Iteration 156/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 157/250, Loss: 0.0200\n",
      "Epoch 199/200, Iteration 158/250, Loss: 0.0163\n",
      "Epoch 199/200, Iteration 159/250, Loss: 0.0207\n",
      "Epoch 199/200, Iteration 160/250, Loss: 0.0088\n",
      "Epoch 199/200, Iteration 161/250, Loss: 0.0222\n",
      "Epoch 199/200, Iteration 162/250, Loss: 0.0054\n",
      "Epoch 199/200, Iteration 163/250, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 164/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 165/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 166/250, Loss: 0.0181\n",
      "Epoch 199/200, Iteration 167/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 168/250, Loss: 0.0260\n",
      "Epoch 199/200, Iteration 169/250, Loss: 0.0279\n",
      "Epoch 199/200, Iteration 170/250, Loss: 0.0163\n",
      "Epoch 199/200, Iteration 171/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 172/250, Loss: 0.0153\n",
      "Epoch 199/200, Iteration 173/250, Loss: 0.0194\n",
      "Epoch 199/200, Iteration 174/250, Loss: 0.0298\n",
      "Epoch 199/200, Iteration 175/250, Loss: 0.0065\n",
      "Epoch 199/200, Iteration 176/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 177/250, Loss: 0.0083\n",
      "Epoch 199/200, Iteration 178/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 179/250, Loss: 0.0205\n",
      "Epoch 199/200, Iteration 180/250, Loss: 0.0154\n",
      "Epoch 199/200, Iteration 181/250, Loss: 0.0109\n",
      "Epoch 199/200, Iteration 182/250, Loss: 0.0089\n",
      "Epoch 199/200, Iteration 183/250, Loss: 0.0159\n",
      "Epoch 199/200, Iteration 184/250, Loss: 0.0095\n",
      "Epoch 199/200, Iteration 185/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 186/250, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 187/250, Loss: 0.0166\n",
      "Epoch 199/200, Iteration 188/250, Loss: 0.0302\n",
      "Epoch 199/200, Iteration 189/250, Loss: 0.0220\n",
      "Epoch 199/200, Iteration 190/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 191/250, Loss: 0.0178\n",
      "Epoch 199/200, Iteration 192/250, Loss: 0.0158\n",
      "Epoch 199/200, Iteration 193/250, Loss: 0.0143\n",
      "Epoch 199/200, Iteration 194/250, Loss: 0.0112\n",
      "Epoch 199/200, Iteration 195/250, Loss: 0.0386\n",
      "Epoch 199/200, Iteration 196/250, Loss: 0.0170\n",
      "Epoch 199/200, Iteration 197/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 198/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 199/250, Loss: 0.0217\n",
      "Epoch 199/200, Iteration 200/250, Loss: 0.0146\n",
      "Epoch 199/200, Iteration 201/250, Loss: 0.0060\n",
      "Epoch 199/200, Iteration 202/250, Loss: 0.0127\n",
      "Epoch 199/200, Iteration 203/250, Loss: 0.0068\n",
      "Epoch 199/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 206/250, Loss: 0.0098\n",
      "Epoch 199/200, Iteration 207/250, Loss: 0.0135\n",
      "Epoch 199/200, Iteration 208/250, Loss: 0.0112\n",
      "Epoch 199/200, Iteration 209/250, Loss: 0.0120\n",
      "Epoch 199/200, Iteration 210/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 211/250, Loss: 0.0203\n",
      "Epoch 199/200, Iteration 212/250, Loss: 0.0125\n",
      "Epoch 199/200, Iteration 213/250, Loss: 0.0237\n",
      "Epoch 199/200, Iteration 214/250, Loss: 0.0184\n",
      "Epoch 199/200, Iteration 215/250, Loss: 0.0155\n",
      "Epoch 199/200, Iteration 216/250, Loss: 0.0100\n",
      "Epoch 199/200, Iteration 217/250, Loss: 0.0056\n",
      "Epoch 199/200, Iteration 218/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 219/250, Loss: 0.0282\n",
      "Epoch 199/200, Iteration 220/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 221/250, Loss: 0.0161\n",
      "Epoch 199/200, Iteration 222/250, Loss: 0.0110\n",
      "Epoch 199/200, Iteration 223/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 224/250, Loss: 0.0164\n",
      "Epoch 199/200, Iteration 225/250, Loss: 0.0097\n",
      "Epoch 199/200, Iteration 226/250, Loss: 0.0093\n",
      "Epoch 199/200, Iteration 227/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 228/250, Loss: 0.0095\n",
      "Epoch 199/200, Iteration 229/250, Loss: 0.0320\n",
      "Epoch 199/200, Iteration 230/250, Loss: 0.0073\n",
      "Epoch 199/200, Iteration 231/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 232/250, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 233/250, Loss: 0.0100\n",
      "Epoch 199/200, Iteration 234/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 235/250, Loss: 0.0154\n",
      "Epoch 199/200, Iteration 236/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 237/250, Loss: 0.0245\n",
      "Epoch 199/200, Iteration 238/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 239/250, Loss: 0.0136\n",
      "Epoch 199/200, Iteration 240/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 241/250, Loss: 0.0195\n",
      "Epoch 199/200, Iteration 242/250, Loss: 0.0143\n",
      "Epoch 199/200, Iteration 243/250, Loss: 0.0084\n",
      "Epoch 199/200, Iteration 244/250, Loss: 0.0122\n",
      "Epoch 199/200, Iteration 245/250, Loss: 0.0224\n",
      "Epoch 199/200, Iteration 246/250, Loss: 0.0079\n",
      "Epoch 199/200, Iteration 247/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 248/250, Loss: 0.0226\n",
      "Epoch 199/200, Iteration 249/250, Loss: 0.0125\n",
      "Epoch 199/200, Iteration 250/250, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.006126, MRE: 0.673692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.006059, MRE: 1.126019 \n",
      "\n",
      "Epoch 200/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 200/200, Iteration 2/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 3/250, Loss: 0.0131\n",
      "Epoch 200/200, Iteration 4/250, Loss: 0.0218\n",
      "Epoch 200/200, Iteration 5/250, Loss: 0.0342\n",
      "Epoch 200/200, Iteration 6/250, Loss: 0.0125\n",
      "Epoch 200/200, Iteration 7/250, Loss: 0.0308\n",
      "Epoch 200/200, Iteration 8/250, Loss: 0.0190\n",
      "Epoch 200/200, Iteration 9/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 10/250, Loss: 0.0115\n",
      "Epoch 200/200, Iteration 11/250, Loss: 0.0218\n",
      "Epoch 200/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 200/200, Iteration 13/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 14/250, Loss: 0.0079\n",
      "Epoch 200/200, Iteration 15/250, Loss: 0.0159\n",
      "Epoch 200/200, Iteration 16/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 17/250, Loss: 0.0061\n",
      "Epoch 200/200, Iteration 18/250, Loss: 0.0135\n",
      "Epoch 200/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 20/250, Loss: 0.0096\n",
      "Epoch 200/200, Iteration 21/250, Loss: 0.0217\n",
      "Epoch 200/200, Iteration 22/250, Loss: 0.0075\n",
      "Epoch 200/200, Iteration 23/250, Loss: 0.0194\n",
      "Epoch 200/200, Iteration 24/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 200/200, Iteration 26/250, Loss: 0.0109\n",
      "Epoch 200/200, Iteration 27/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 28/250, Loss: 0.0110\n",
      "Epoch 200/200, Iteration 29/250, Loss: 0.0074\n",
      "Epoch 200/200, Iteration 30/250, Loss: 0.0207\n",
      "Epoch 200/200, Iteration 31/250, Loss: 0.0212\n",
      "Epoch 200/200, Iteration 32/250, Loss: 0.0241\n",
      "Epoch 200/200, Iteration 33/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 34/250, Loss: 0.0045\n",
      "Epoch 200/200, Iteration 35/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 36/250, Loss: 0.0084\n",
      "Epoch 200/200, Iteration 37/250, Loss: 0.0118\n",
      "Epoch 200/200, Iteration 38/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 39/250, Loss: 0.0177\n",
      "Epoch 200/200, Iteration 40/250, Loss: 0.0141\n",
      "Epoch 200/200, Iteration 41/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 42/250, Loss: 0.0134\n",
      "Epoch 200/200, Iteration 43/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 200/200, Iteration 45/250, Loss: 0.0123\n",
      "Epoch 200/200, Iteration 46/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 47/250, Loss: 0.0083\n",
      "Epoch 200/200, Iteration 48/250, Loss: 0.0235\n",
      "Epoch 200/200, Iteration 49/250, Loss: 0.0057\n",
      "Epoch 200/200, Iteration 50/250, Loss: 0.0116\n",
      "Epoch 200/200, Iteration 51/250, Loss: 0.0162\n",
      "Epoch 200/200, Iteration 52/250, Loss: 0.0247\n",
      "Epoch 200/200, Iteration 53/250, Loss: 0.0236\n",
      "Epoch 200/200, Iteration 54/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 55/250, Loss: 0.0235\n",
      "Epoch 200/200, Iteration 56/250, Loss: 0.0159\n",
      "Epoch 200/200, Iteration 57/250, Loss: 0.0121\n",
      "Epoch 200/200, Iteration 58/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 59/250, Loss: 0.0200\n",
      "Epoch 200/200, Iteration 60/250, Loss: 0.0218\n",
      "Epoch 200/200, Iteration 61/250, Loss: 0.0115\n",
      "Epoch 200/200, Iteration 62/250, Loss: 0.0338\n",
      "Epoch 200/200, Iteration 63/250, Loss: 0.0109\n",
      "Epoch 200/200, Iteration 64/250, Loss: 0.0341\n",
      "Epoch 200/200, Iteration 65/250, Loss: 0.0171\n",
      "Epoch 200/200, Iteration 66/250, Loss: 0.0156\n",
      "Epoch 200/200, Iteration 67/250, Loss: 0.0205\n",
      "Epoch 200/200, Iteration 68/250, Loss: 0.0165\n",
      "Epoch 200/200, Iteration 69/250, Loss: 0.0080\n",
      "Epoch 200/200, Iteration 70/250, Loss: 0.0192\n",
      "Epoch 200/200, Iteration 71/250, Loss: 0.0112\n",
      "Epoch 200/200, Iteration 72/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 73/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 74/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 75/250, Loss: 0.0142\n",
      "Epoch 200/200, Iteration 76/250, Loss: 0.0135\n",
      "Epoch 200/200, Iteration 77/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 78/250, Loss: 0.0105\n",
      "Epoch 200/200, Iteration 79/250, Loss: 0.0121\n",
      "Epoch 200/200, Iteration 80/250, Loss: 0.0131\n",
      "Epoch 200/200, Iteration 81/250, Loss: 0.0147\n",
      "Epoch 200/200, Iteration 82/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 83/250, Loss: 0.0141\n",
      "Epoch 200/200, Iteration 84/250, Loss: 0.0168\n",
      "Epoch 200/200, Iteration 85/250, Loss: 0.0115\n",
      "Epoch 200/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 200/200, Iteration 87/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 88/250, Loss: 0.0221\n",
      "Epoch 200/200, Iteration 89/250, Loss: 0.0275\n",
      "Epoch 200/200, Iteration 90/250, Loss: 0.0257\n",
      "Epoch 200/200, Iteration 91/250, Loss: 0.0178\n",
      "Epoch 200/200, Iteration 92/250, Loss: 0.0140\n",
      "Epoch 200/200, Iteration 93/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 94/250, Loss: 0.0169\n",
      "Epoch 200/200, Iteration 95/250, Loss: 0.0205\n",
      "Epoch 200/200, Iteration 96/250, Loss: 0.0217\n",
      "Epoch 200/200, Iteration 97/250, Loss: 0.0228\n",
      "Epoch 200/200, Iteration 98/250, Loss: 0.0130\n",
      "Epoch 200/200, Iteration 99/250, Loss: 0.0148\n",
      "Epoch 200/200, Iteration 100/250, Loss: 0.0114\n",
      "Epoch 200/200, Iteration 101/250, Loss: 0.0172\n",
      "Epoch 200/200, Iteration 102/250, Loss: 0.0108\n",
      "Epoch 200/200, Iteration 103/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 200/200, Iteration 105/250, Loss: 0.0159\n",
      "Epoch 200/200, Iteration 106/250, Loss: 0.0190\n",
      "Epoch 200/200, Iteration 107/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 108/250, Loss: 0.0215\n",
      "Epoch 200/200, Iteration 109/250, Loss: 0.0204\n",
      "Epoch 200/200, Iteration 110/250, Loss: 0.0082\n",
      "Epoch 200/200, Iteration 111/250, Loss: 0.0178\n",
      "Epoch 200/200, Iteration 112/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 113/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 114/250, Loss: 0.0199\n",
      "Epoch 200/200, Iteration 115/250, Loss: 0.0224\n",
      "Epoch 200/200, Iteration 116/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 117/250, Loss: 0.0117\n",
      "Epoch 200/200, Iteration 118/250, Loss: 0.0097\n",
      "Epoch 200/200, Iteration 119/250, Loss: 0.0130\n",
      "Epoch 200/200, Iteration 120/250, Loss: 0.0252\n",
      "Epoch 200/200, Iteration 121/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 122/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 123/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 124/250, Loss: 0.0180\n",
      "Epoch 200/200, Iteration 125/250, Loss: 0.0247\n",
      "Epoch 200/200, Iteration 126/250, Loss: 0.0310\n",
      "Epoch 200/200, Iteration 127/250, Loss: 0.0059\n",
      "Epoch 200/200, Iteration 128/250, Loss: 0.0169\n",
      "Epoch 200/200, Iteration 129/250, Loss: 0.0131\n",
      "Epoch 200/200, Iteration 130/250, Loss: 0.0284\n",
      "Epoch 200/200, Iteration 131/250, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 132/250, Loss: 0.0066\n",
      "Epoch 200/200, Iteration 133/250, Loss: 0.0202\n",
      "Epoch 200/200, Iteration 134/250, Loss: 0.0430\n",
      "Epoch 200/200, Iteration 135/250, Loss: 0.0076\n",
      "Epoch 200/200, Iteration 136/250, Loss: 0.0124\n",
      "Epoch 200/200, Iteration 137/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 138/250, Loss: 0.0092\n",
      "Epoch 200/200, Iteration 139/250, Loss: 0.0133\n",
      "Epoch 200/200, Iteration 140/250, Loss: 0.0240\n",
      "Epoch 200/200, Iteration 141/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 143/250, Loss: 0.0219\n",
      "Epoch 200/200, Iteration 144/250, Loss: 0.0125\n",
      "Epoch 200/200, Iteration 145/250, Loss: 0.0142\n",
      "Epoch 200/200, Iteration 146/250, Loss: 0.0211\n",
      "Epoch 200/200, Iteration 147/250, Loss: 0.0076\n",
      "Epoch 200/200, Iteration 148/250, Loss: 0.0068\n",
      "Epoch 200/200, Iteration 149/250, Loss: 0.0181\n",
      "Epoch 200/200, Iteration 150/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 151/250, Loss: 0.0070\n",
      "Epoch 200/200, Iteration 152/250, Loss: 0.0107\n",
      "Epoch 200/200, Iteration 153/250, Loss: 0.0171\n",
      "Epoch 200/200, Iteration 154/250, Loss: 0.0160\n",
      "Epoch 200/200, Iteration 155/250, Loss: 0.0218\n",
      "Epoch 200/200, Iteration 156/250, Loss: 0.0104\n",
      "Epoch 200/200, Iteration 157/250, Loss: 0.0122\n",
      "Epoch 200/200, Iteration 158/250, Loss: 0.0181\n",
      "Epoch 200/200, Iteration 159/250, Loss: 0.0088\n",
      "Epoch 200/200, Iteration 160/250, Loss: 0.0123\n",
      "Epoch 200/200, Iteration 161/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 162/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 163/250, Loss: 0.0113\n",
      "Epoch 200/200, Iteration 164/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 165/250, Loss: 0.0091\n",
      "Epoch 200/200, Iteration 166/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 167/250, Loss: 0.0130\n",
      "Epoch 200/200, Iteration 168/250, Loss: 0.0074\n",
      "Epoch 200/200, Iteration 169/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 170/250, Loss: 0.0068\n",
      "Epoch 200/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 200/200, Iteration 172/250, Loss: 0.0242\n",
      "Epoch 200/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 200/200, Iteration 174/250, Loss: 0.0194\n",
      "Epoch 200/200, Iteration 175/250, Loss: 0.0192\n",
      "Epoch 200/200, Iteration 176/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 177/250, Loss: 0.0083\n",
      "Epoch 200/200, Iteration 178/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 179/250, Loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Iteration 180/250, Loss: 0.0276\n",
      "Epoch 200/200, Iteration 181/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 182/250, Loss: 0.0165\n",
      "Epoch 200/200, Iteration 183/250, Loss: 0.0221\n",
      "Epoch 200/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 200/200, Iteration 185/250, Loss: 0.0258\n",
      "Epoch 200/200, Iteration 186/250, Loss: 0.0334\n",
      "Epoch 200/200, Iteration 187/250, Loss: 0.0202\n",
      "Epoch 200/200, Iteration 188/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 200/200, Iteration 190/250, Loss: 0.0075\n",
      "Epoch 200/200, Iteration 191/250, Loss: 0.0171\n",
      "Epoch 200/200, Iteration 192/250, Loss: 0.0152\n",
      "Epoch 200/200, Iteration 193/250, Loss: 0.0090\n",
      "Epoch 200/200, Iteration 194/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 195/250, Loss: 0.0134\n",
      "Epoch 200/200, Iteration 196/250, Loss: 0.0257\n",
      "Epoch 200/200, Iteration 197/250, Loss: 0.0091\n",
      "Epoch 200/200, Iteration 198/250, Loss: 0.0386\n",
      "Epoch 200/200, Iteration 199/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 200/250, Loss: 0.0125\n",
      "Epoch 200/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 202/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 203/250, Loss: 0.0084\n",
      "Epoch 200/200, Iteration 204/250, Loss: 0.0195\n",
      "Epoch 200/200, Iteration 205/250, Loss: 0.0083\n",
      "Epoch 200/200, Iteration 206/250, Loss: 0.0191\n",
      "Epoch 200/200, Iteration 207/250, Loss: 0.0160\n",
      "Epoch 200/200, Iteration 208/250, Loss: 0.0166\n",
      "Epoch 200/200, Iteration 209/250, Loss: 0.0148\n",
      "Epoch 200/200, Iteration 210/250, Loss: 0.0217\n",
      "Epoch 200/200, Iteration 211/250, Loss: 0.0178\n",
      "Epoch 200/200, Iteration 212/250, Loss: 0.0214\n",
      "Epoch 200/200, Iteration 213/250, Loss: 0.0296\n",
      "Epoch 200/200, Iteration 214/250, Loss: 0.0248\n",
      "Epoch 200/200, Iteration 215/250, Loss: 0.0117\n",
      "Epoch 200/200, Iteration 216/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 217/250, Loss: 0.0088\n",
      "Epoch 200/200, Iteration 218/250, Loss: 0.0123\n",
      "Epoch 200/200, Iteration 219/250, Loss: 0.0175\n",
      "Epoch 200/200, Iteration 220/250, Loss: 0.0109\n",
      "Epoch 200/200, Iteration 221/250, Loss: 0.0099\n",
      "Epoch 200/200, Iteration 222/250, Loss: 0.0170\n",
      "Epoch 200/200, Iteration 223/250, Loss: 0.0068\n",
      "Epoch 200/200, Iteration 224/250, Loss: 0.0188\n",
      "Epoch 200/200, Iteration 225/250, Loss: 0.0105\n",
      "Epoch 200/200, Iteration 226/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 200/200, Iteration 228/250, Loss: 0.0156\n",
      "Epoch 200/200, Iteration 229/250, Loss: 0.0067\n",
      "Epoch 200/200, Iteration 230/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 231/250, Loss: 0.0087\n",
      "Epoch 200/200, Iteration 232/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 233/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 234/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 235/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 236/250, Loss: 0.0244\n",
      "Epoch 200/200, Iteration 237/250, Loss: 0.0094\n",
      "Epoch 200/200, Iteration 238/250, Loss: 0.0162\n",
      "Epoch 200/200, Iteration 239/250, Loss: 0.0053\n",
      "Epoch 200/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 200/200, Iteration 241/250, Loss: 0.0130\n",
      "Epoch 200/200, Iteration 242/250, Loss: 0.0075\n",
      "Epoch 200/200, Iteration 243/250, Loss: 0.0239\n",
      "Epoch 200/200, Iteration 244/250, Loss: 0.0205\n",
      "Epoch 200/200, Iteration 245/250, Loss: 0.0288\n",
      "Epoch 200/200, Iteration 246/250, Loss: 0.0138\n",
      "Epoch 200/200, Iteration 247/250, Loss: 0.0204\n",
      "Epoch 200/200, Iteration 248/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 249/250, Loss: 0.0118\n",
      "Epoch 200/200, Iteration 250/250, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 98.17%, Avg loss: 0.008638, MRE: 0.760837 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.05%, Avg loss: 0.008478, MRE: 1.410267 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predictions = torch.max(pred.data, 1)\n",
    "#         train_correct += (predictions == y.data).sum()                \n",
    "#         train_total += predictions.size(0)    \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping\n",
    "    #train_loss.append(loss.item())\n",
    "    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "\n",
    "#     loss = criterion(outputs, Variable(test_classes))\n",
    "#     test_loss.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f9848",
   "metadata": {},
   "source": [
    "#### Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098cfb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xi_real = []\n",
    "xi_pred = []\n",
    "for (X,y) in train_dataloader:\n",
    "    xi_real = np.append(xi_real, y.numpy())\n",
    "    xi_pred = np.append(xi_pred, net(X).detach().numpy())\n",
    "\n",
    "xi_real_test = []\n",
    "xi_pred_test = []\n",
    "for (X,y) in test_dataloader:\n",
    "    xi_real_test = np.append(xi_real_test, y.numpy())\n",
    "    xi_pred_test = np.append(xi_pred_test, net(X).detach().numpy())\n",
    "\n",
    "# find the boundaries of X and Y values\n",
    "bounds = (min(xi_real.min(), xi_pred.min()) - int(0.1 * xi_pred.min()), max(xi_real.max(), xi_pred.max())+ int(0.1 * xi_pred.max()))\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize =(10,10))\n",
    "\n",
    "# # Reset the limits\n",
    "# ax[0] = plt.gca()\n",
    "ax[0].set_xlim(bounds)\n",
    "ax[0].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[0].plot(xi_real, xi_pred, '.')\n",
    "ax[0].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[0].transAxes)\n",
    "ax[0].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0].set_title('Train Data')\n",
    "\n",
    "# Reset the limits\n",
    "#ax[1] = plt.gca()\n",
    "ax[1].set_xlim(bounds)\n",
    "ax[1].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[1].plot(xi_real_test, xi_pred_test, '.')\n",
    "ax[1].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[1].transAxes)\n",
    "ax[1].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1].set_title('Test Data')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#fig.suptitle(\"Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390bab",
   "metadata": {},
   "source": [
    "#### Plot Fehler vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428c9744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbf7c2",
   "metadata": {},
   "source": [
    "#### Plot Loss vs Variable Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a835602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistake = []\n",
    "param_T = []\n",
    "param_p = []\n",
    "param_x_H2 = []\n",
    "param_x_N2 = []\n",
    "param_x_NH3 = []\n",
    "for X,y in train_dataloader:\n",
    "    mistake = np.append(mistake, abs(y - net(X).detach().numpy()))\n",
    "    param_T = np.append(param_T, X[:,0])\n",
    "    param_p = np.append(param_p, X[:,1])\n",
    "    param_x_H2 = np.append(param_x_H2, X[:,2])\n",
    "    param_x_N2 = np.append(param_x_N2, X[:,3])\n",
    "    param_x_NH3 = np.append(param_x_NH3, X[:,4])\n",
    "    \n",
    "# train_parameters, train_xi = next(iter(train_dataloader))\n",
    "# y = abs(train_xi - net(train_parameters).detach().numpy())\n",
    "# #[T, p ,x_H2, x_N2, x_NH3]\n",
    "# x = [train_parameters[:,0], train_parameters[:,1], train_parameters[:,2], train_parameters[:,3], train_parameters[:,4]]\n",
    "\n",
    "# print(param_T[0])\n",
    "# print(param_T)\n",
    "# print(mistake)\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize = (10, 5), gridspec_kw={'width_ratios': [2,2,3]})\n",
    "\n",
    "ax[0].plot(param_T, mistake, '.', markersize = 2)\n",
    "ax[0].set(xlabel = '$T$ / K', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[1].plot(param_p, mistake, '.', markersize = 2)\n",
    "ax[1].set(xlabel = '$p$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[2].plot(param_x_H2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[2].plot(param_x_N2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{N_2}}$')\n",
    "ax[2].plot(param_x_NH3, mistake, '.', markersize = 2, label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[2].set(xlabel = '$x\\mathregular{_{NH_3}}$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[2].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[2].set\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOx9d5hkVZn+e26o3Gl6erqnJzAzpAGGIIoEkaSgKIrruor8WDGtuIZdXBVlVUR3xRVd1oBZEBNmMWACiSLCDDnnyTM93dPd1V35pvP744R77q1b1VXdPdPdw32fZ57pqrp169ate895z/t93/sRSilFjBgxYsSIESNGjAUPba4PIEaMGDFixIgRI8bsICZ2MWLEiBEjRowY+whiYhcjRowYMWLEiLGPICZ2MWLEiBEjRowY+whiYhcjRowYMWLEiLGPICZ2MWLEiBEjRowY+whiYhcjRowYMWLEiLGPICZ2MWLEiBEjRowY+whiYhcjRowYMWLEiLGPICZ2MWLsQyCEtPTv1ltvndHnXHrppSCEzM5B72Vcc801IIRg06ZNka9v2rSp5fPYaB/tYMeOHbj00kvxwAMPtP3e3/72tyCEoLe3F7VabcbHEiNGjIUPY64PIEaMGLOHv//974HH//Vf/4VbbrkFN998c+D5Qw89dEaf8853vhOvfOUrZ7SP+YqlS5fWncf3vOc9mJiYwI9+9KO6bWeKHTt24FOf+hRWrVqFo446qq33XnXVVQCAsbEx/PrXv8ab3vSmGR9PjBgxFjZiYhcjxj6E4447LvC4r68PmqbVPR9GuVxGJpNp+XOWL1+O5cuXT+sY5zuSyWTd+ers7IRlWVOex72JoaEh/OEPf8Bpp52GO++8E1ddddW8JXbtXl8xYsSYPuJQbIwYzzOccsopWLduHW6//XaccMIJyGQyePvb3w4A+OlPf4ozzjgDS5cuRTqdxiGHHIKPfvSjKJVKgX1EhWJXrVqFs846C3/6059w9NFHI51OY+3atbj66qtbOq5PfepTOPbYY7Fo0SJ0dnbi6KOPxlVXXQVK6bQ/56677sJLXvISpFIpDA4O4uKLL4Zt2+2croaYnJzEhz70IaxevRqJRALLli3DhRdeWHeufv7zn+PYY49FV1cXMpkM1qxZI8/3rbfeimOOOQYA8La3vU2GeC+99NIpP/973/seHMfBBz7wAbz+9a/HTTfdhM2bN9dtl8/n8cEPfhBr1qxBMpnEkiVL8KpXvQpPPPGE3KZWq+HTn/40DjnkEKRSKfT29uLUU0/FnXfeCcAPT19zzTV1+w8fr7g27rvvPrzhDW9AT08P9t9/fwDAPffcg3POOQerVq1COp3GqlWr8OY3vznyuLdv3453vetdWLFiBRKJBAYHB/GGN7wBu3btQrFYRHd3Ny644IK6923atAm6ruPzn//8lOcwRox9EbFiFyPG8xA7d+7Eeeedh4suugiXXXYZNI2t8Z5++mm86lWvwoUXXohsNosnnngCn/vc57B+/fq6cG4UHnzwQXzwgx/ERz/6UfT39+M73/kO3vGOd+CAAw7ASSed1PS9mzZtwgUXXICVK1cCYKTs/e9/P7Zv345LLrmk7c957LHH8LKXvQyrVq3CNddcg0wmg6997Wu49tprp3PKAiiXyzj55JOxbds2/Od//ieOOOIIPProo7jkkkvw8MMP4y9/+QsIIfj73/+ON73pTXjTm96ESy+9FKlUCps3b5bn8uijj8Z3v/tdvO1tb8PHP/5xvPrVrwaAltTQq6++GkuXLsWZZ56JdDqNa6+9Ftdccw0++clPym0KhQJOPPFEbNq0CR/5yEdw7LHHolgs4vbbb8fOnTuxdu1aOI6DM888E3/9619x4YUX4rTTToPjOLjrrruwZcsWnHDCCdM6R69//etxzjnn4N3vfrcku5s2bcLBBx+Mc845B4sWLcLOnTvx9a9/Hccccwwee+wxLF68GAAjdccccwxs25bnd3R0FH/+858xPj6O/v5+vP3tb8e3vvUtXH755ejq6pKf+7WvfQ2JREKS5xgxnnegMWLE2Gdx/vnn02w2G3ju5JNPpgDoTTfd1PS9nudR27bpbbfdRgHQBx98UL72yU9+koaHj/3224+mUim6efNm+VylUqGLFi2iF1xwQVvH7boutW2bfvrTn6a9vb3U87y2P+dNb3oTTafTdGhoSD7nOA5du3YtBUA3btzY8vGcfPLJ9LDDDpOPP/vZz1JN0+iGDRsC2/3iF7+gAOgf/vAHSimlX/jCFygAms/nG+57w4YNFAD97ne/2/Lx3H777RQA/ehHP0opZb/V6tWr6X777Rc4V5/+9KcpAHrjjTc23Nf3v/99CoB++9vfbrjNxo0bGx4jAPrJT35SPhbXxiWXXDLl93AchxaLRZrNZumXvvQl+fzb3/52apomfeyxxxq+99lnn6WaptH/+7//k89VKhXa29tL3/a2t0352TFi7KuIQ7ExYjwP0dPTg9NOO63u+eeeew7nnnsuBgYGoOs6TNPEySefDAB4/PHHp9zvUUcdJRU3AEilUjjooIMiQ21h3HzzzXj5y1+Orq4u+dmXXHIJRkdHMTw83Pbn3HLLLXjZy16G/v5++Zyu67OSh3b99ddj3bp1OOqoo+A4jvz3ile8IlB1LMKsb3zjG/Gzn/0M27dvn/FnA37RhFClCCF461vfis2bN+Omm26S2/3xj3/EQQcdhJe//OUN9/XHP/4RqVRq1hWuf/zHf6x7rlgs4iMf+QgOOOAAGIYBwzCQy+VQKpUC19cf//hHnHrqqTjkkEMa7n/NmjU466yz8LWvfU2G66+99lqMjo7ife9736x+lxgxFhJiYhcjxvMQUdWcxWIRL33pS3H33Xfjv//7v3Hrrbdiw4YN+NWvfgUAqFQqU+63t7e37rlkMjnle9evX48zzjgDAPDtb38bf/vb37BhwwZ87GMfi/zsVj5ndHQUAwMDddtFPdcudu3ahYceegimaQb+dXR0gFKK3bt3AwBOOukk/PrXv4bjOHjLW96C5cuXY926dfjxj3887c8uFAr4+c9/jhe/+MXo6+tDPp9HPp/HP/zDP4AQIkkfAIyMjEwZ1h0ZGcHg4KAMx88Woq6xc889F1deeSXe+c534s9//jPWr1+PDRs2oK+vL/DbtXLcAPDv//7vePrpp3HjjTcCAL761a/i+OOPx9FHHz17XyRGjAWGOMcuRoznIaI86G6++Wbs2LEDt956q1TpAJZ8v6fxk5/8BKZp4vrrr0cqlZLP//rXv572Pnt7ezE0NFT3fNRz7WLx4sVIp9MNC0NErhgAnH322Tj77LNRq9Vw11134bOf/SzOPfdcrFq1Cscff3zbn/3jH/8Y5XIZ69evR09PT93r1113HcbHx9HT04O+vj5s27at6f76+vpwxx13wPO8huRO/CZhr7zR0dGG+w1fYxMTE7j++uvxyU9+Eh/96Efl87VaDWNjY3XHNNVxA8Bpp52GdevW4corr0Qul8N9992HH/7wh1O+L0aMfRmxYhcjRgwA/kScTCYDz3/zm9/cK59tGAZ0XZfPVSoV/OAHP5j2Pk899VTcdNNN2LVrl3zOdV389Kc/ndGxAsBZZ52FZ599Fr29vXjRi15U92/VqlV170kmkzj55JPxuc99DgBw//33y+eB1hRRgIVhOzo6cNNNN+GWW24J/Pv85z+PWq0m/fbOPPNMPPXUU00LX84880xUq9XIileB/v5+pFIpPPTQQ4Hnf/Ob37R0zAD7jSmlddfXd77zHbiuW3dMt9xyC5588skp9/tv//Zv+P3vf4+LL74Y/f39+Kd/+qeWjylGjH0RsWIXI0YMAMAJJ5yAnp4evPvd78YnP/lJmKaJH/3oR3jwwQf3+Ge/+tWvxhVXXIFzzz0X73rXuzA6OoovfOELdSSgHXz84x/Hb3/7W5x22mm45JJLkMlk8NWvfrXOjmQ6uPDCC/HLX/4SJ510Ej7wgQ/giCOOgOd52LJlC2644QZ88IMfxLHHHotLLrkE27Ztw8te9jIsX74c+XweX/rSlwK5i/vvvz/S6TR+9KMf4ZBDDkEul8Pg4CAGBwfrPveRRx7B+vXr8a//+q+ROZIveclL8L//+7+46qqr8L73vQ8XXnghfvrTn+Lss8/GRz/6Ubz4xS9GpVLBbbfdhrPOOgunnnoq3vzmN+O73/0u3v3ud+PJJ5/EqaeeCs/zcPfdd+OQQw7BOeecA0IIzjvvPFx99dXYf//9ceSRR2L9+vVtVRh3dnbipJNOwuc//3ksXrwYq1atwm233YarrroK3d3dgW0//elP449//CNOOukk/Od//icOP/xw5PN5/OlPf8J//Md/YO3atXLb8847DxdffDFuv/12fPzjH0cikWj5mGLE2BcRK3YxYsQAwEKXv//975HJZHDeeefh7W9/O3K53KwoXFPhtNNOw9VXX42HH34Yr3nNa/Cxj30Mb3jDGwIhu3axbt06/OUvf0FnZyfOP/98vOtd78IRRxyBT3ziEzM+3mw2i7/+9a9461vfim9961t49atfjTe+8Y348pe/jOXLl0vF7thjj8XQ0BA+8pGP4IwzzsC73vUupNNp3HzzzTjssMMAAJlMBldffTVGR0dxxhln4JhjjsG3vvWtyM8V+XNR/m0AYJom3vrWt+KBBx7Afffdh46ODtxxxx14xzveIY/zX/7lX/Dkk09K4mgYBv7whz/g4osvxnXXXYezzz4bb3nLW3DHHXdgv/32k/v+3//9X5x33nm4/PLLcfbZZ+Pvf/87rr/++rbO27XXXotTTz0VF110EV7/+tfjnnvuwY033hiwKwGAZcuWYf369TjrrLPwP//zP3jlK1+J97///ZiYmMCiRYsC26bTabzmNa+BYRh497vf3dbxxIixL4JQGnL/jBEjRowYMRYILMvCqlWrcOKJJ+JnP/vZXB9OjBhzjjgUGyNGjBgxFhxGRkbw5JNP4rvf/S527do1I3U3Rox9CTGxixEjRowYCw6///3v8ba3vQ1Lly7F1772tdjiJEYMjjgUGyNGjBgxYsSIsY8gLp6IESNGjBgxYsTYRxATuxgxYsSIESNGjH0EMbGLESNGjBgxYsTYR/C8Lp7wPA87duxAR0dHZIulGDFixIgRI0aMuQalFIVCoaW+zs9rYrdjxw6sWLFirg8jRowYMWLEiBFjSmzduhXLly9vus3zmth1dHQAYCeqs7Nzjo8mRowYMWLEiBGjHpOTk1ixYoXkLc3wvCZ2Ivza2dkZE7sYMWLEiBEjxrxGK2ljcfFEjBgxYsSIESPGPoKY2MWIESNGjBgxYuwjiIldjBgxYsSIESPGPoKY2MWIESNGjBgxYuwjiIldjBgxYsSIESPGPoKY2MWIESNGjBgxYuwjiIldjBgxYsSIESPGPoKY2MWIESNGjBgxYuwjmDfE7vbbb8drXvMaDA4OghCCX//614HXKaW49NJLMTg4iHQ6jVNOOQWPPvpoYJtarYb3v//9WLx4MbLZLF772tdi27Zte/FbxIgRI0aMGDFizB3mDbErlUo48sgjceWVV0a+fvnll+OKK67AlVdeiQ0bNmBgYACnn346CoWC3ObCCy/Eddddh5/85Ce44447UCwWcdZZZ8F13b31NWLEiBEjRowYMeYMhFJK5/ogwiCE4LrrrsPrXvc6AEytGxwcxIUXXoiPfOQjAJg619/fj8997nO44IILMDExgb6+PvzgBz/Am970JgDAjh07sGLFCvzhD3/AK17xirrPmZycRFdXFyYmJuKWYjFixIgRI0aMeYl2+Mq8UeyaYePGjRgaGsIZZ5whn0smkzj55JNx5513AgDuvfde2LYd2GZwcBDr1q2T2zTC5ORk4F+tVtszXyRGjBgxYsSIEWMPYkEQu6GhIQBAf39/4Pn+/n752tDQEBKJBHp6ehpu0wgrVqxAV1eX/PfZz352Fo8+RowYMWLEiBFj78CY6wNoB4SQwGNKad1zYbSyzdatWwPSZjKZnP5BxoixkODaAAigL6ihIEaMGDFiNMCCUOwGBgYAoE55Gx4elirewMAALMvC+Ph4w20aobOzM/AvJnYxnhewysCXjwa+e+ZcH0mMGDFixJglLAhit3r1agwMDODGG2+Uz1mWhdtuuw0nnHACAOCFL3whTNMMbLNz50488sgjcpsYMWL4oNvWAxNbgG3rAc+b68OJESNGjBizgHkTfykWi3jmmWfk440bN+KBBx7AokWLsHLlSlx44YW47LLLcOCBB+LAAw/EZZddhkwmg3PPPRcA0NXVhXe84x344Ac/iN7eXixatAgf+tCHcPjhh+PlL3/5XH2tGDHmLXY//lf08b+pUwFJZOf0eGLEiBEjxswxb4jdPffcg1NPPVU+/o//+A8AwPnnn49rrrkGF110ESqVCt7znvdgfHwcxx57LG644QZ0dHTI9/zf//0fDMPAG9/4RlQqFbzsZS/DNddcA13X9/r3iRFjvqO68S75t10tIxETuxgxYsRY8JiXPnZ7C7GPXYznLTwPxf9eiZzHDL4n//UBdPavnuODihEjRowYUdjnfOxixIgxu/B2Py1JHQBYleIcHk0MAKBb7gbdumGuDyPGbOKpG4DRZ6Nfe/ovwLdOAXY+1Pr+7CpQHpuVQ4sxO6CU4qpbHsVocf7438bELkaM5yF2Pnp74LFVjondXMKrFmFd/RpUr34NqDN/JogY04cz9Dhw7T9h/Pv/HPn65G1fBnbcj/wDv215n7Xv/yPcLx0FTGyfYsMCsPNB4PkbkNtr+NNdD+L0W87GNf93Mar2/GhfGhO7GDGehyg+E+zGYlVLc3QkMQBgeNvTSKKGNK1gYnTXXB9OAM/89GI89403zylJqO58EhNP/nXW9rdreAQ3Xvc9FErKdT+xHfjLp6YmTS3iueeeAgCQiS31L3oejB33AACe3bG75X3SrRug1yYwdPfPm2/4u38HvnkSsOXvLe87RvsYHRvDyj+/HSu1EbwjcSNStDrXhwQgJnYxYkwflTycX78f2HTHXB9J28gN3xd4bNdiYjeXyO98Tv5dGGveKWe24bgent5VQKN062WPX4U1Q3/AyJYn9+pxqZj49lnIXvtaFEZ3zMr+nv7FJ3D6g/+Gh67/unzO+vs3gDuugHX3VcGNp0loa2WW6pCjpbp92LseQ8Zj95xnt0YGqF1BCkzNLTz4u+af/Swbk6o7Hmm+012PAb9+DzC+uaVjmFNQCow8xU3V5wE8F9uvPg+H4VlMkA5k334dME8K0GJiFyPGNLF1w+9gPPB9bLzu03N9KG3BK+ex1GYD+Wa6BADgxordnKIyskn+XcoP79XPvurWx3DJl76O//nDo5GvJ6gFACiXCpGv72lUSxPo94ZhEA+7h7bJ5ymlcNzp+S+myzsBANqYYrH1LCOuj23eKZ/bfP9fUPj0cjz+x2+0/RlOlaU3GMSDVZ4IvLbj4Vvl38SNJnY3PrYLv7jX/76Vwqj8e1XxfoyPNVD6qhNIVpjqu3Fzc8JWuuly4IEfobjhR023mw/Yuv43wFePwZM/vHCuDwUAsPEXH8cRxb+hRk0Mv/q7MPsOmOtDkoiJXYwY08SuUdblxC0tjGTm8ZKFkUINWx75KzRQbKH9GDOXAgDcWnlWPqNWLWPXzq2zsq+FjF/euw1v+ubfMTzZmhrjjvvnrLqXiV3vfV/BjxOfwYF3XYybnwiGgV3HgU6Y2uRYlb16XAK7tm2UfzvKAuSDP3sQL77sJgwX2g9/6S77LkbZP9daiX13y7bkczsfugUdtIjyY39q+zPcqp+3OpkfCbxWVlIhSEROpe16GPnJe9Hx6/Oxu8COtTju78MkLu65KTocO7nFV+nc4kjkNgLV59hxPLm1XiWmlOKjv3wIb7l6PSbKc6+S7XiGFZm4U6mQewmZJ34JALhx1Ydw4ItOn+OjCSImdjFiTBOUhwRS3vxXu0aLNbzkczfjnMu+h+f+8CUAwLbcOrh6CsDsEbsHv3oeer9xBJ574v5Z2d98w83Xfh63fOmdsGyn6Xa3/u2vOHTLj/Cju55rup2AUfCVGbs42mTL2UXNcbG2eDcA4A367bj1p1/C0IRPlGxL+XuWrpF2oYap1WN48VOfx8/t9+NvDz3V9j4NTuxSNf9cZyz2N/H8BHjqsd/ZtNtXK92aT+xK+eBv2j3q3x+aW0/shkbGcK52I16h34Px7c/wfQRJmvfEH+B69WHirU/6aRZaqXH+njuxA70OI7NR4eA7nx7G6Q/8Gz6y6Z340PduQs2Z28IAys9n1p4fC+msNwkAOOS4V87xkdQjJnYxYkwTYtDPLABi9+zOUVyNS3FT8sM4DcxSw1l5oiR2njXzSduuTOKoydtgEA9jz+x7th2FYgEvefJzOHX853js7huabvuWiW/gk+YPYN3/s5b2LUKDAOA1mYxnG49t3I5DsEk+/qj3HVxx7W/kY8vySYdbmxvFrrTbVzMdJRf0ZPcu7K/tRO2R5vlmUUhyYtfh+Oe60+GEgSqknZO8pDONMLRC7MoTPrErj+/EUtfPFdQiQrEj2572t+cKbnWS7aOGBADgWOde3PJYfc5hYevD8m+z1niRsPnBW+XfUarho9d/BS/T78dh2ma8ecdn8ZGfP9AwD3OvwGbns8sbn2LDPQ/q2siBXUO57t45Ppp6xMQuRoxpgrpsAshibpSMduDueBDHaY/DhYaRpafg9iM/j2Nf/36f2Nktfge7Ctz7PSBfX+m39b4bkSDsnLiluR98ZxtP3XsrkoSptGPP3N10226XkYSDiuvxzHA9KfjTI0O4d7OvPHTbSihsL/qU7XzkNuiEYrcxgPLylyJDajh/52dQrLLv6SiKnWvPDbFz8z6xU5XlJGVkZPHwnXXvmQoJyr5Lj8uvU7uKDjDSqCp2hJO8tDsNYmf5JLSm5Mc9d9/Ngc10z0IYhSHf+64ywUPEfB9PJNahbHShm5Tw0F1/rntvctxXMNNW42tp7Am/6IuEVMMNjz+LN0x8Vz4+TX8ASx75Nq66YyPmCoQvPrtRgGO1bgnkRaiaYWweLeHjv34YW8daGwfLk/557ehe3PKx7C3ExC5GjGlCKHZJ2KAtVrbNFawJturfkjgQfRf8Bif9w7uQNE24eppv0NqAtnvDL4Df/RsmvvxS/O7Gv2Ck4A+wlcf9ScYr73vErvDELfJvY6ixqSylFDnK1IUTtYfxx4eCqsrOiQr+9Uf34u3X3APPo6CujcWeP/Hr1b0YatrM7DBGF78IqX/6FgDgMG0zbJ7s7yj5ZnOl2OkF//y5PM/P8yhSYMf2QucBbB9rz4cx6bH7tYuUUCmXUMv7iimhSsiRk7wsbV+VJ7b/Hrvo/6aFp/8GAMjTHABA9yJy7EaVvMJJpio6PJe3kujB6NKTAQAHjQcr8ierNgYsv2Ai5waLNlSolfHhcHD++k9iESliKLUGeNUXAAAXGT/Fo3f/peH+9jR02/+N8yOtVUd//dZnceSnb8ATQ5NNt/vFLRuw+J4r8LNb721pv4U8+02KNIV0KtXSe/YmYmIXI8Z04fohm3IxP3fH0QK8Ilv1V5OLAs9Tgw9KLRLTjZvZhNPl5XHCHW/Fe6/4vlzl9g35PmOkmp/hEc8/dA+vl38PVp5saEZaczx0cvWnj0ziiQfvCry+ebSMl5IHsbz6FDaPlZEf2iwLFAAgae0dUkwpRX+e5Xql1pwArWNAvmbV2PVg1/wJ35tlxY5Siot/9RC+8OfmNiqpiq9mipSBmu0iQ9ix9ZAinnqgPcuhJPzvNT68DePDfo4j8dRQLPs7R0vwIipwr7jhSbzyi7djslpfXKArKrhb8X/TrhFGqJ7LHQ0AMCKIHVFUSq/Ecuso34eT6Ea+/1gAwHI7mMP54NObsZT4JLKTTkpyqmJsooDVth/uVYndY/f/DacVr2ff4dWfB455J2oHvw4G8XDmxE+mVawyG9Ad/3zmd7fmNfiXR7ejq7YDtzzRvIjk0M3fx4XGr3Dwph+0tN/yBCd2JAdCSEvv2ZuIiV2MBYX1X3wzNn76CFTnQ6cEZQIoT85vhYoW2UBkpYJhA2pm2B9Oa4odVZS9XlLAN7xL8cc71oOOPosljpI3VGusFCxEDI/lsdZ5Qj5egx14ZGO0ajBRLCNL/Ily+djfsWm3r96M7dqC75qX4weJz+Kx7eMY3RmcnNN2fnYPvgE2D49jHWWT+8DhpwGaBpvqACBDXY5C+D1rdif0J3cV8OP1W/HVW5+B5TS2Lemy/MpVyslltRJU0Kyn2lOSMoqR7OTINhRVokCVYxGqPHFQKNWPOb+8dxueHRrHfZvr73/d8Y/RK+cBAOMTBezvsHNOV50EADAiQrHpsn88hIfmCSd2NNUNJHL8vUFCuelxRhrzOlvAaaCwi/U5m4/cezuSxB+/1HDwxL2/gk4oHs6egL7DXw4QguSJ7wMAvFB7Cn97ujlJ2lMwXH/sKbXoZ3ju6JW4I3kh6Mbm5tbdZaZydhdbK3aqFthvUtJyLW2/txETuxgLCgfnb8NqbzO2PjUPqi4VYlcpzI9KrUYwKmxw9zIhYmewUCxxWlNjqMMmxPt6Xol896FYRIo48v5LsPuB3we2M638DI94fuGJe29FitgYIz0YNxZDIxRbHr0rctvSRDBh/aXaQ/jjI77qVB16GjqhWESKGHn2fpR2MRW0SNlv0Sx8NpvY9NAdSBIbE6QLyYG1AACbGOx/TuJc2yeodJYVu4e2TuCN+i04g6zH7gZ9Nqu2iz7qExOxsKiGehv3D7feYcGxbZkrCQDlsR2ojPtEgSjFE2q+XTFfT5Auqn0J9yTfjdJovYKkEhGtlgcA7Nr8OCOJyCCxbB3bjtYTu66aHxoWoXmd7wOZHugmU9p1GiR2onCiumgtxniod2JkJ8IY5/l1DhiRV8PBIoRc6ljtv2HpkXBIAr2kgCcefaBuf3sDputff7X81CbetuvhIIepwd0j6xtu53kUix22v6XONlSsqat/LR5ar+gdU247F4iJXYwZo5Xk1NmCyQfd6uQ8IFIKsavO81BsglfHkWxf4HliMjKhO76CQSlt+JsSPrlXkn1In3MNqjBxLH0Q6b99HgDwiLcKAJCchj3EfEb5qdsAAEOLXoRCD5uQK5uj83FKk0Fid4z2JG5+ZJN87OaVsN+29bDGWCHKpsT+AIBOunfOXZV3JxjqPgrg4SQbJgDA4YROTVKnTnPFjlLaliXG9mcewuXmt/El86sYnojOYdsxPIxOohBKriDWQsTuUPdxjIy2ZhNTLgfPr5XfCWfSJz+aGrpU8u3ChN31KI6hD6OLlKFH5FwaSrWrzhVsoQyO64thJNm9l6BBUlu2HCylvp9gghdAJCy2DyO7CLqZZH8rpLBsOUjnmRqYXbYOE6QbADA5GiR2nkeR5eHg7dlD2X4UxU4UUlA+NrANEigtPgIAYG/6+5xUxyY9/zpwC1O33ds1WcUgYb/ZotJzDY9512QFK8D2t5IM47nhqaMvwru0ZnROue1cICZ2MWaEj/3qQZx62fXIl+tXnXsCCbAVqrUXvb4aQiF2Vik/d8fRAjLc+8no7A88TxIsFKtxxY5Siguv/Cne/6UfRZI7IiZ3I4XkwMG4dfBdAIAc93S6p+M0AEDKbZ6svJBAKcXi3WzFb655KVIrXwgA6Bx/JLLzQZVXLw5rfXByg0gSB1271svzSSZ9dWdx/iGQCZZPNdnNJtkMqaFc2vPnr2c3I6Z05QnyOUnshGKn2mBEWGKouOQ3j+IFn76x5crC5DZWRJAiNiZ3R4fWxnaEqjD5dWrxUOwkstipDSBBXGy6p7kFjUAt1EGDFnaBFP1wr1o8oap35ZAqX6ja6OK5lE6x3lRaJSIJm/2eVV6kUTJ7YfB7zwwpdtt3jWAR8Ylr2maELumwfZjZXmiS2PmK3UPbJrA/2KIht2IdikY3O+58kNjtyJexzmNKlr3iJWw/KrFT7nEV2QPYtgfWHsPTw3s/FSZJFYJfnJrYDe0eRy9hv/V+dBt2TUZfv0PbtyDFFVyTuBjaPLUvolsW+Y4xsYsxj0A9F6Nbn5h6wynwskc/ij/Y78BzG1vLTZgJPMeBQdhE6swDOw01ydrhOTTtwN14B+jOxtWVs4mcw85Xsiua2Bm8SrBYqeJTu/8D/5P/EMYn68mFIIDgq/nBV34QD3hMaRqm3cgcdAr7PG/uFbuq7eLiXz2E6+7fNvXGTfDs0JicCFcefQZ6D3wxAGAtfQ6P76z/nlaRneuK3gHtgJcBAI6lD2GYVxAnyn4Y6VDncWic6JElh8DiOW753VNPXDPBQ1tGcYj9GACgf92p8nmHh2I9TuLUUCymCMU6T92ID3tX4/5NUx97zXGxsuBXZapedSomdwVtdQTpsHkHihpJYtui4wEAW9f/Gmd+6a94/df+1rTjR7UcvK610q5gB4oGoVirEFxMThYrMpeSRHR4UImd8MFzJrl1SaoXCV5NKRarAqPbngk87nDzAIAMXywlOxdLxc5UiN1ExcZBGrvWyZJDUE30AABqE0HSaU8OYYCMwwVBdekxAILKnyikIKpiB8DY7zgAwIu0p/DXp/ee16JAWiF2IrWkGSaG/EXBGrITzwzlI7fL73g68Liwjc2Lrkdx65PD0UVSFbYvN9E15XHMBWJi9zzFhu9djN6rjsVDN7ZWBdQIB3vPIktqMMZnn9jd8/2Lce833y0fW0rytrcXvb4agSrEzq20p7DUJofhfe9slL/1SumovifR7eUBAJmepYHntSRrWi3CRqXJMXSTEjpIBbViPXkWZqpi0D98xSJc2flBPOrth2+4r8FRB7O8nNw07CFmG9fdvx0/Xr8Vl/+pjeb1lXF4d3wZUKoYn77vNqSIjbzWg+TAWujLXgAA2J/swH3P1JNGseioGR3QDmAK5onaI9g8ys5JruZPtKu1XVhRYxNLqm8VJghTAArje66t2OM7J/Hzq7+ATlJGScuhZ80L/WMnQrGrJ3Zhr7Mw/rnyQ7zN+DOMjbdOeQxP7JjEi8nj8rE1Hq3Y1caCxE4sLERrMYskYR7CnP9f5/wZh+66HvdtyeM7TfzWrFAoNlHdjbTlk7aAYtdElS9O+ORCjyAaKfhEJMMXOoQrTV52CUx+7yVDil1xFxtLq2DkrZNOglKKDm6hk+leDDPBSKGpkEKvnMcA4ddt38GwU8w41y0ESafNv0cRWZAM20ZVDXV5j4dsPFawStwDte2474lnMduglOLKr30RX7nyC3VhU0ppoOClmT+fQFnpv5wkDnZtjhYyqsPB7+LtZord9/++CW/97gZc9Iv6xbcoDqPp7imPYy4QE7vnKbRxdjGXdsxMtdN4BZk3xaDfLhzbwtHPfh0v3PljjA8zRUMldpgHdhrqoE8r7SW8D+/YChMOsrSE4Xt/M/UbZoBqrYZusEmhsy9I7IyQYqfmCobzmABl0OfvI4TguGOPx6utz+Kuvjdh6QDbf4bUUK3MrXHz9esfx1Xm5/Gq0nUtN4t/7tefgfaXT2DTTz4sn/OeYYayI70vYrloHf0oJpdAIxRbH6s3KhYefrbZCSxjpGkN2YEtuwuo2i4We8GJto+wa6drYH8UdaYAVCb2DLF7dqSId3/7Zvwb/SEAwDj5Q4BuyNddrtgJQuc5PnHQpsixE15vXn5qK4pNTz2IJSQvH9NCfYI/AGAiSJzFwsLhRsUWSeHIU9+ITavfBI1QfCHxTbxRvwU/Wb8FZSu67ZsVuq5z1m502Cqx85S/fZLnhlT56qRP5lJWUM0LE5Gcxz5TKE0ktwRmii2OTOLK9oQAYI9tAgAMZQ8GAHSTEorFAnLcCD3X3Qcjwd+rKHYpnl83qvcBqS7QDMunJaXg9eZwP0KbmMp+FGLHCym0kGKHbC9qXWvYudi8ftZbjG0f2oULdn0a7x65DKNjQeJmWbVAwUvOnjoVxx0PLgoqOx+L3nB8U+BhcoItCkTB028f3IHHdgQX7obFHpOY2MWYTxCkJKqVTDvQwImdPbs5dqXCBDTu7SUq4GzFIFWrzr2dRsDItNamYqfYtdTu++lsHVIkJkaHoBEKjxLkuoOhWCPFCFqCD+bVQl6+ZjchdlrCH/TPO24/vOeU/fFfrzsMuc5F8ChLxC9EVBHOBqq2ix/ctblpLtczwwUctfMXeJl+Py7Qf4ddhdau8+oWFh7s3noj4LnwPIoDx28HABhr/Z6QZOlRAABv+314diR4ngTJdxOdQNdyOMREkjgY3/kcdk5Upc/YcG5t4H19y9egYjBiV5vYM5YSX7/1Wfyz9RP0kUm4i/ZH8iXvDbzuENauSvQO9ZzWFbuUIDLFFioWnw3aT+il6PCtWWKEb1RnJEWECV3eWszWUiCahlVv+Sbw4neBgOJy89s43boZv7wvmmDaVfZ7ieu0yx1FD/UV2kAoVrnHaWgxWVVCsxk7qG7XLEvmbQFAJ0qoWg7SFrsnEt0DSPJ7DwAsdWzjOZfl3sPlMQ5t8hfgXT2LYSREGNc/Vq3CrqsJg6lwWo5VwBshw2uHmzxbSPoFHPDHb+GrpyUyCCOxmoW9D6eP45lZzrPb8fjdMIkLk7gohOxMysWgyioiEM2gF4K/v7Y7OncuVWTnezy9HwCgt7oVE2UbuzY/iSvNL+NE7WFccWPwvSJnUs/0THkcc4GY2D1PIVelM1TaJLFz7Cm2bA8VRTkSidxOzV8BG9Y8IHaKQTFpk9hZSuh2cPff9mgbqQKvisuTDhBFnQEAI8XCQQk+KVsl/7xalfpwqhj09URWPpcydVz0yrV44X6LQDQdBcJeK03sGWL313sfxH6//3+4/mffabjNr9Y/h/MNlky/GBPYOTr19UIpxZIKU7K7vTyKz/4dzz39CA7CZjhUw7IX/4PcNrvqRQCAo7RncHUo7Ee4LYWX7AY0HcX0cgCANfwMhsYmpEJX2P8s+Z7d6EJHrgM1nhflRHiPTVTsGVcjarufxPk6Oy/6mZcDRiLwuq/YsYleXbBF9TQV8DyKNEQO4dRqYy8vRqlqjDykK9HELldjz09kVgEADG55IVqLObwlHggBzrwcOJalbnzO/BaevvXHkQVAbpWRhGHCiM8SjMGET+A0qMUTyt88r0rAUrpJdLj5wG9TCRVoGMTD5GQeOU4AMz2DSKX8e6hW9YldtsxUSmPxGkwSZlmS38rUpkmaQSqZhJn0Q7HiOwo7Gldjv2mC59OmQmFLl4+ntpaAKStz/fHbv8dDih0AwsOxL9SebskWpB1Utig5l6FUhEoxeP92kyJK5eYRgRTvv1zT2TnsauBR11VjJNJezdIm9iM78bN7tuKd2u9wln4XrjE/h56nfor7t/jkPSUKWXLzr08sEBO75y3EqpRMEV6ZCgRsUPFmqPyFUVUIhiR2ilmqWDHNKZSVvdruphUI1QAADDiwH/n1bB1VHSrjbHKc1LrrXjOTbGIVfTdtJdykHqPcnods9WT9oC9Q5JNReWLPVC5nt9yCk/SHcfxwtNLpuB4q9/9Uhvo0QjE+tDlyWxXbt2/DYuTl410bfoXRe68DADyVOhyJDmUQX8NaOp2h3YOb7n0MYyUllMXDNEgz9c3qWsWezz+HPC8GsGCi68jXyPeM6kvYsacYsaOl4Ln76+Pb8N///Z/47p+jvfNaxcvyP4dJXOwePA048OV1rwtSIO5nNcUiqvWVQMV2keLELms1VxvLNRuHWixvaWzlKwAAOeU9tDwGWhxGzXGxyOXttHpYCFCQDo/3YRW9jgEwcveKz8I+/M0wiIePVT6Ph+/4Xd3ni/y80cTSutcAQKPRxE7+rhxqP+RFmEBJITqCiDhUgw1GlvNjI1IZ7OxbBtM0ZLGMWERRStFjMcUzN7AGBR6at3YxxahAmG+aIHZJ4sDiIVEqCl40lpuX7madRLJOUE2UpJgkkOTh4CSxAU5MTV4hG0XssJIVUBxJnoXVRr/WVpDa/bD8O5yKUOFV4gVkpIn26HDzkH8XP4/l5ScCAJa7TIlTUbVdDHhsu8yhZwAAlpIx/Oxvj+N0nVWNG8TD581v4alffEq+T+RMpjqDnXzmC2Ji93wFV+ymCq9MBbG69ZzZDcVWixHETlHsUtNpyj3LUAd9k/u2lS0Hl1/1Q/xh/aNN3+uESFPpnp/M/gFyWBNs5Vo06gehRJqRMNFiyVGURBHuUiFycYxktu41gTI37awVpk/sPv6r+3HhteujFSquTAy42yNz5257chhvtH8beK40MjWx2/hY0MS0c9Of0bPlRgDA2IoQCVpxLOjgC5AiNt5Ib8CP7vL3n+AEQOP5N8aSAwEAudJmlHczYjeZWILeVYdjEuw8FpKMZFCe8C7CagLF9T/A581vYf9Hvzzl92iGbptNmMX9XxX5useLJwRJoMqCTW8yVpQqFSQIux+63DHYTXIan3nyIfSTPGowkTridey43FHZN3f3/x6Lwv8ejQ0PPyrD1mTxAQAAkxM7qU6pxA4ANA3m667EY92nIEkcdN7x3/XfkV/XltmJcdTbVajETlPyaI2QNyNVCmx6MYnRgq+6CcWuQlJSwR7auQ2LwK6NrsXLQAiBBUakRZpJvmxjEIzk9i47EGW9m312nudE83tLhGIBoGaJc8JJLyfnHYsYsevygmqXxxfzjpaAqaiGIvxu8kWeGbV46z0QRZJFmljQx/xq0hsf24WPXfcwirXovMZW0F/yw812qOBDRDjKJIO8xshuI4scAKhYLpZ4bFGQOpQtHg4g2/HMcJCcb9s9jgGw3zG76hhJpF9UvAkDZByOkcXk0f8KAHjT5HexfSMrxMryQpZ0Z9Dwfb4gJnb7Kqwyit9+NSq3XBH5siAl4ebP7ULnoVjqzi6xsxRLAhk6UCr0svPATkMtnkjw9kEPbbgdF219L/pueF/T93qc2D3urQQAdA2vByZba5PTLtwCm8yriQhiJ0KxcFhOmULsRIJ6YHsesjWS9fk3AjWDTT7T9RqcKFt48wPn48InzsO23fUhVGGUO0DGsWM4ol3SHb/BIdpWWFpaJqA749F2GoHP3cxUpAeMI1CjBvqsbTioyp7rfsHrghsTAnI8+43/2bgBP77zaWmLkHDYb2tm2fnuWMqOYam7E5NDmwAAldQAiKZjY+oQAICVHQQAaDy0Y9SCxC49yipIO2vBkGWrRSECOW6ZkWowIXm6IHZW4H8guvWVQFWpNO0n4xhpktM48dgtAIBNqUPQsfQA+Z58xcbw1qfR5w6jkxZQuO6D6ODmxG4Ps9QRpEN0oHD1CPKhG6An/DsAIG3XpzhQqfalkdf8HCmHsumwkWInfOQklNCsQTyMj/pkpMbHrwpJo6yx+2Fi+5PQCYUHAj3HcgYtTqStKvs+23ftQg/3sEv27ictSzpLmwAAVW6Im1CInc0XvJSP5Z7OFLvuJeya6iIllJVCJtEaztGSSCb9/Yg8P2GYrEfd45qGosaOwVUWp9fecAe2b/gtvnXrM/XvaQET+XGs9PzxzwuNHWI+qJE0CrxdWnmsQcENgB35EpZyc+L0gafAgYEsqWHnlmAF7MjWZ6ARigpSINnFmOQh/3/RWScdcuDL0fna/8FmbQUAYGzrE6Cugw5e8ZztikOxMfYidjx6O3Lb70Ditv9Cdfsjda9rs0TsCFdU6CwrdgHlSLY3qq8ym0sEBn1+PO4QU+qWOs2904Qatoksx3rvYBbSfrw+bDQrKIk+sfWDUDLj9zqkdhm05k/QXoRiJ6wZ1JV+GJbJVr2iOrRdDO3YisO0zVil7cLubU/Xb6CoSMObgsqo5Xg4avuPAQCTh5yDUjcrUNAmp/ay00cYeUqvPg53Y518/gm6Hw5eu67+DYeeDdq5DH1kEidWb8a9vF9omqvJZo5NymYfIyWryRAKXDl0ckyhG157PjZ5/aCH/yPbtoMRrlSoX2yuzIhpWiEXT+0q4MhP3YAv/SXiHEXAdj3Z1SLTtSRyG48XT0ilTiV2tPFYUVOIXS8msXO88f2Z3LkBADDR92KYXYx89JAiRsbzGN7oh+PO1JiCWtQ6oGXZtZvkip3ogEJDJrryMzIid7T+mCWxMzMomv49sZuw30vkDQNBkpd2g99JD+X5lhSiYVXY+aiRNKp8oeONsHDqJOmUlci1kGI3tp0RjwLpAFKdMjQ/YHNnAH5vEeV727wYQtwXns72metaLMnq+LBf0CKUOVdLIJlIygINi5M/YaFipqIXb6LAxrV8hfK9hS/hmsTlKN35bYyXGs8FNcfF+o1jcEO5j9sev1sWywEAysEFm82vr5qeQZkvUK18Y2I3MrQVSeLAhQZ0rcBYihGz4rbgXFjcyYjoaGIQIESG/Ndo7Hzph7B0iYkEUz+ruzehqHSW6eyOFbsYbWJy8wPY/n+nYvejt7T93rFJNgjp8LDlFxfXvU744KU1WYW3Al+xm93iCbviTxSOyB1Rcjo6SRm2zT7zuvu34cM/fzDaSHIPQq2eS3vc6mGSDQhdtNC01RrlpKmrqwv304MAAIWdrU3Q7UJv0CcWAFJpn6DZ1TJg+eddqCIqRMg20WDQBwAnySYfOgWxa3R+8jv9VfXkcEQIVSF2xR1Bj7oHH38KJ+IBAMCiU94HrZsVLiRLjScBACjVHPRX2ef2H3g0Ni4+Rb72eNdJMPWIoVI3QY5jYZp36n/Adl6lm5FhGk4aehmxW0GGZf6U1rUMAHD6696Cno8+ipecxPJ7Up1Myck4PmnwPIo+PrGLDh8AsGHTGEqWizufba1IZaJio5urQdmeBsRO44odV+DV+7qZYqcSO41QaVEUhY4S+00Tg4cB6R5JbiaGt6G8/fG67SupAbmQSPDrjzj82gxbcnDI3FHUHzPhxI4aGVRT/j0xrrO/A4qdUkiR8YILnXABV0XpXyqIiKWlme0NgFyBFdkUlJQIm5Mkh99rpWGW4D8uQvNpdg318A4K4t6CpslcM6HYiXxpyhU7ounSF3FCrTLlpNjTkjAMHTXebcTiCr1YvCUaqPIOz+HzFPupXo+RnQ/gh/jJX/4W+T7Po3jn9+7BG7/5d/zh4eD9WNgYbM+nhyt5uTpo62nY/Ddr1lasyJXxvN4L6CYqXUwZxkhwvLB3s9+klOHjRP9B/vESAzjwdABAJcN+D3d8q+wZXKIppFLRC4u5Rkzs5jGe/tM3sGziPmy69Xttv1fNeTto/HY8d99NgdfF4NUsb6YVyNXtLIdiaVVRjmxhlhos9Cjk2WDy8z/djPz9v8aNj+1Zt/4w1FBslrJBUS+xwb2DVDBZamzSS3mjbT3VgQy3IBkZbk4+pgvRJxa5+sk8nTBRoWxyqVaK0JTqXqFs+E9QpPlEKRSRKNBkNwCAcBNP2FVgLFiR9uPbH8J/XvqfuPeZ+u9cHvGrTKu7t9S9rhb8eLuDoZ/8hh9DJxSb0odB6zsAqcXMwqDTam7B8eCWMRxEmKrXveooZA5/jVQynIPObPzGo9+CqpbBQdp2eNs2wPN8I9l0B5/AO5fDJgkkiIsXatyMuHel3EVXxpR/Z7rZb9Sh5EUN54tYxvOuOmhR5h3myzYA2vKCJl8oydCmno0OIQm1R4Zilfs6Sv0SCHvDFRt0kgCAxQ77zbuWHQgQwiZfsO4T2ihTtR7texUoP5beZauR5MQuRQWxE4pdNLFLpqPNfwPvNbNwMv49UUiy+1BXK2QVkteBUsC7LRkq4LIn/YR/h49ftp6Cw7sTDFiM0FaT/rkX6pfIH9Ym2PVeTjPij2xwMeal/NCxzcO4clwUZJwTOwAo8By90rh//YtUBhGytTixs2sVUM9Dit/jiXQ0sRMFNup4LHJvc6SKI+67BLsL9UV5P7x7M3Y88yDO0W/Gxp3BxYg+zFIehGqasEIFH/x8OnoGHu93rYX8+VTUxti5LiSZ0qb1M+U+OxkMxeqTbDu3i92P3SsO8fex/HiA58l6HUxZ1gvbZVFYgeQwXxETu3mM5DhbXXjTUMNcO/ieyh8+AVfJxxFhRJ3OTGkTih1m2e7EU0OCfAChocrb4sRueB7FRypfxLcTV2D0gd/P6jFMBXXQz6AKuA4SFX9wnxhtTDSJLRSHDLoXs8HHi7C4mA1kuN2B0VFP7EydoMIVE6tSDFb3hlpIqTl3iVSTQY17O4nG58O//BDw5Rdg8oFfA2Dq2JKb/wP/o30NkxuurXu7q3Qb8CbqlR+14EeYiQrst/16AEDhIGZN0rlkFQCgz9vd1J7h6aceQ45U4cAAeg/AcUccio8678R/2/8PBx5xQsP3IdWFkY7D2N+jz6JQtdHJjWSz3XwC1zQUuOXJoRqbSDr6V9btClAS3mkBNicROzc/KVvpdZESylVOVkafwb3Jd+O1xZ81Pj4FpTybCD0QINWgFRJX7EQIlijEzmwyVogWXwK1Bp0k8hN59PHK44H92CRaSrCJ2s7vQK7Ifs/KqtNAjmcee9rA4TIXNAkL1POkWTKJ8FoDIImgQTxp3SK/Ir/3SCIDkvN9HS2uymgNiF0nSpgo+9deSrQJA1POaMG/90X+maNn4HGVbQ1hhNZJ+2TN5uqXuLeSfPyopNl1YOSCxE5LK8SOV9sKUijvC8MndhUetqzl/bFIFlkIYsfJpW1VYFlVGRJtlG7h8vd5qkuBcm28hDyEu3/1pcB7tmx8Cpk//jtuSFyE/zG/g5XbgsVNfZNMqd3czexUUnZQDZXhcyMLrYOdG7PaeLykebawqPHc1cQAu9aWu8GForCWMRezjjmpAd9bMn342fJvo4fdr+nKTtS4MXVJi4ldjDZBKUV/lU9aXnsJ0oC/0t6iLUMNJg5zHsX9d/xBvi4GLKOJhUErEHYn1JtdYgeF2FGRE2IHj7U8OYqxUg0HcKVl1dbrZvcYpoA66ANArZxHpuYPNsXxxsRO44odElnofPBOWtPLSZsKok9sKmRODLDOETXeusiulGAoxI7Ywcm6WvWJXbqJYidMOxM8VFV9hpnRjv7pcwCA62+/G6fQe9gxRQzORsHPhzOL9QRBzQvtrvoD9fBzD+Ig9xnYVMfKl54HAMj0McVukIxix0TjXqfjmx4EAEzm1gC6iRWLMug4/u3IH3UBDl/e3fB9AOB0LJPHXZjMSxKWzPohN6trdeA9Ga4khtG5iHuPERvjk3kALOlexSQPBfXtXo9eUsDR1j1Nj0+gwk2PiyQHaHrkNkIlkyRBWVSKMHwUwlXe3mS0+iwarE8ii3QXu+6r6SXyPf02m5AXrVwHnHYJ8JbfAC/9IBL8etMJZeTDbU7s1BSDakhN1F1O7JJZGF2K5Ukn+1un0cROJxSFibx8LCwvxhLs9ydKWzHRJtA1MrI7QZpwRU1Rzh1hL8PHOJ3fczTJ8vKSncHFmJZVw7hcabNCxE5R7Kwk295RSCfh587jeXqyMrdaCfjppRoodqLqVozLlFJ5bTy9nC2o1m76kb99aQyd3z8db9Buhc5JY6rk39dWpYgVnHAR3ls554aIHT+fnpmR/nzpULcPFWLcoF1sQUUWs8r05VRRLilFr8Wu09wAD9X2rAbMLEB04GBfqU/zcaTL2iX9C6u8Qnk+IiZ28xQjw0Po42XYBO0TOxGKHU8sxVPpo9hzo344TIRQm+XNTAVKqVTsyCyHYjWFYEhPrRCxq07uxsjoiGzEfbx99x4LZ0aBhIhdeXIcXa4/2JTzjY1adR4O0pJZJPjgHU6Ybxdfu/UZvPKLt2N3UTlPlKKLskEyHeoTK1AjfOVeLcJ0fTInQlYCwmvLojqSiaCxrQozy4hd0pkEPA9LHDbIrq4+hnvuvBHVu66SA7zab1cgU/EH/Wy1nhyrxG7Q3SGtNUb+xvoeP5B8EboWs+9K+MDeScrYNRL9e3gehcYLJ0i/H4r5xFmH4gv/dCR0jTT8rgCg89V8qrJTmjJbMAL5X/ri/YNv6lwWuS8tmUWVT7STXPG1R4K5l0WuvBkVdq01C5GqEC2wynq9xYd/oPx3FYQuEIptvHhzQopdo04S+e2M2O02/GvRyzEFJjn6OBaBkaXBNYcBmgasOQVIZJFK++pItVyWvY2juiMACHR1qIWMtg1+XZNEFulF/u9g9rAE+0DxBIL3eImH4VjvVnaspQ5G2k2V2MkCjSy0TLAa3eCKE+B7zolCBJ1X15Mk+76ZUC6kKK4BAJuHUEXuscZ/K6Iodh5XB1VfRJnKwAmgLfsDV2Dx39GjBAnT348KofQJYud4FElecJF54ZsBAMu9HahZ7Hg2Pngrumkew7QHz/SxnDVTqfre/uS90AnFKLowcCAz/g5btBCLzQfUzMp+1x1O44VwtsrmgQS/N80Mu+bTqMnCjXzJwjKw67R3Bc+tM1PAeb8A/vlXAB87AKBnKSuq6PNG4JTYsdfMJvfRHCMmdvMUW59UkknpNBQ7kSNDTLj8xoUyiUrFLiIHpeXP8KhfyTTbxE7J7xKhg3DlrV0cx+QuP7k+SRzs/Ft9aG9PQadBUlIujGOx5w9Y1mTjHBCdJ39riazMqwqvUtvFdfdtxxNDhUCuIa1NypyZzt5GxI6t3O1qCUmF2IV7g4resTUkQEhjspPkk0/aLaAwsll+PgCM/OkLeJVzo79xhNLbbfnH3+2O1FXQqQU/PaSI7Tu2AZ6Hgc2s5+7uNa9TDiaHIrebmGxgUpyv2FjlbgIAdKw8suH3aoRU3yp+3EOoTLLfv0SyzDCXIzfoJ2VbMIFMA5sEQljVJIDSGDsPen5TYJMKJ3YmD7EnWyR2doERD9G2LAqUkwLCzzFRfp8ksRtGD2iogjpVjSbRouF6MeNPmhpXyg4ss84DQ6QPqWxw0jTNBFxRvVktyd7GWpSJLgBN11CjbNyrKUoz4Hev0FM55HoH5fOZxYwE6A2qYgEWJQCYIXMXuLrWy9SelKq4iwINMysXOgKpbv8+FMTO42kPhhgXOLHLLRoIvDfdUZ+f5/L7VN4XCiHTuK2KoZBO0UZS/Na2UuUqKmOrSIBo0fRA5vDxz61ajmyf1rvfYbCogSSxsWMzy38tbGOLpo2ZdcCqk9j3ULph5J9l1c9bkgfJBVknSqhU/etapq4kc+jsY2R8ER2vGxsARroX2ezeyfBUDKHgpmChynsIlyZH0clzThO9iqK+3wlsQaFg8eAqeJQgRWx4o+wathMxsYvRJiY2+2X/ZBrETuTleZoBSljYxfPUEAPbpzkVsdt+H/CVFwFP/KHuJVfZHyKUl3bguF6gStJwlInCEe2NghOYUxpDaSRoY9Hz9M9ndBztILyan9jxbKBRtd3Ex80Uk0u6AzkefkujWpfX1g4mq+yzhe0G4CdNF2kKPd3dke9T83xSCrETISu5HV/NV0n0Sl5AVIPmaAG7uB1JmYd7z9TuQh/xk85J6Lqp2i4GqE8KlmIUw6FE7HAHhN2bH4O98W/odYYxSdNYftzrA68XEow4V3ZvijzemuPiYMJCgMbSCFuTKdDNV/NL6QjGuMomvMsE0kq13WRiSYD0hVHiJqlVvjDIlYJ5QcL4Oc2JRKvEjpbZ+6xEd8NtCPexE4qdFlqwhQuY5PMhYtdh746seiZ5kazuh6ITPYzkLSeMfIym6sPURNNk9WytUlQ6oDROCagRkTsavI4THidRyRyWrDgQY+jADixBZ2998YQeTrcosHM+UShIMpPkeVkdjlLJqaRapDqCJD67WFErQ+qXye85g+ewitC8gAhfA4BDgoqdKIRTrVBMHg1IKkTKz8Vj2zlKMYTNf0dx7qIgiR3fT7XqXxPJTAeGDEaWR7ewNmgeV5xrXWuQ5DY7WScv3+PuYtsVu9ciw7+fRijyY/44oCqZ3X3seukmJYxO1vuZTlRsDIBdS0JpS3LF1yAeqjwn0S6zhXQFiYbV1fJ7pTIYJd0AgNw4I6peovECaa4RE7v5ihG/7H86xE4oaJ5mghL+Myu9TQUpaZYQDQB45i/A6NPAE/WFCZ4yKZMZ2J04rofXfPEm/NPXbpcVfyqxE8abCClItJKHnWfE7gmyBjbVsaL8eF1J+55CeDVf2flY8PhKTYgdn1zMVBY93b2ytRAtTb+A4m3VH+KO5L9hu9IwvMj7xI6hCykzOq/K1tgA79ZKyFB/EtRD51uYqFpoTuyy3Nupg5YwuY39Fk8kj8Toohf4+xLk0A0Su527huQqGmCD987h4HkMpw+UdjyJsTuuAgDcrJ2Aw1YGJ8Nqhk00Xj7ay86qVWViO5Yc2vS7RSHR6+fxDQ8zYlcxQvk3vX4otpKqz3UMHK/ZzY5rcgSeR7GEW51IzzO+YMi5eQBASgkvNQW3n3F41XIUxKStRSh2AFALhVzl+ziRqfC8oz7ksbtUTzgznKQm+nyFJLt4eWCbSteayM8QCwqrVpIdKJp1QPE94oLHLE220zmkM1lY774Liff+DTpXsAI5dqKzDrhayNuIlXhFvgsNmQGWv9Xl5SWZ1UWBRjKHdKjtVOdiP/wriR2/1xKc2OkppgaZ6Q5Z3AQAuZ4++bfo6yvz8/hYrimKXZJHAzK2v9jTxMKIVxQ7RISDq9JPz0JjYieLM7jypyqixEgjn2Yh7cpOdu+nCywFSOs7CJkeURw0Ic+VUWYLGL17OYhuYgKMhBWU4jNdUTL1TI8sWNm+rb76esfIKBYJk2eey6qG7MXxWjIC0Xw8Exg32LkfrDHFzkv3NNt8ThETu3mK7qJSlj2dUCyfMKlmgGqGeFK+LkhJIsLnKQAxuYdIDAB4Suk/mUGu3lihhG9O/Cv+e/h9KPGWNAlPWWULf6YweazkQSbZpFfuXYdbvaMAAKX135/2sbQDcQ5FiEgfDVpv6KG2UCoSXHEwUx1YlEtiHGxCFAnuAey4H3i2uZeh7Xp4Oe7GcrIbL524XvYuFe7sk1rj1aXwpXJr5QCxE6qI3I5X7lla84Ewx4ldkjhwdjIbg3LHKiw69f0AmD/UU33Mt42EFhbCoDVPOlEmbDAe27kpsI1Q7EYJmzCTww+iexNTlEcOfCO0UE6csCowitHeam5pHCZvh9Uo960p+HvSxILD7VfsMLHrGJQhL6M7SGTCsDjxcou7sWvCtzrZkWaqn1tmLbu6vDwAFl5SbTgaQauyyZ2mG/e3JIYonogmdlY1WlEWobKJFPtu/WQcQxP16t4ii+VPdiw9UD7XtWRFYBtjycGRn2EpRT6SnDUzyhZWIqFQbIovqkQ7vYGB5VjctwQaNw0O2J3wsKzof+xyclzhuZRFZJHjRG0RmUS+ws6XSkSyIRNbs9MPrwpiB07Okvx7JTL+9SNC8wDQqRI7UcTACZa4LzRFfTJ5JXw39dM8dFF4wgmgy/MqPasiz5XdRLETSp9Q/mw+LngggG7C4sScjLN7eXGNka+uFYeig6uiizApIwyZGru+EzxEXeCdLcpKv1jTEYQ3x6rMDaaCbvnLN+sOr8S9L0vI+NXfekKSc5FzKY7bavZdFQjrlG4wQihaBs5HxMRuHmKsZGE/188Hmk7xhDQY1Ux4PBSrJqqLfU5F7Ko8jFGq1q++1VCsNoOqWLswipXaCA7RtiA/zshQSiV2IhwU8tzTahNIcN+4RM9y3NPFEnPdJ2+Y8jPveW4Xntk1OeV2zSBW82KF2aGScQBGrXFyb4ryySWTQyahI897VhbHQn5rlAI/+ifgh/8IFBp7sRWqDjoJO2dn63/D/Zt52I17a0X1iRUQ/TZpdVJW7gERxI6rNU0HfQCpTKc0T+0dZykFZPEBIIeeDbzk36G95v9Q5INkOIRfGmaV4ONmPwtZAijtDubGCcVuOMNUsKN2/w5JWsMzdBnOfOVr6o5HWBWkytHnT1QV1mCyhP12YSSlF1vPJCsOsMNhGk2DvphNeAMrQoUUYXBT2vzundix+SmYxEUNCYzlWC4XKY9jvGxhMQ9pp1FDpYUenSYP3ZJM42tBM4RiZwf+F7BDJEmCJ/8Xskwh6cUkhkLdJ/KlKpbxMHvfSp+8ZXqDRLdrxWGRH1GTKQMVGX5ONCF2Nlei7FBrvJQw2U4HybdustCmoYy3Qr0rcT84ytuIVXk4vKzlJHnqJBWM5RmBMl2fiGQ6/VCsCy2QXyk7Z/DFqz8u+MdWFF50NAVTaSXmyoparl7y+0JXFDsz3cX369/LOt9OEECR50dtRbFrlm7B9y9ycH0l3wQIkb2Rs4XNqBbz6KNsTB9csw6Jzn5+rsoY42HUToenFvDroMxzQGsKsRPhc5P/Zu5x7wEAnJ3/HoZ++6nA4YmK7DFdCYETgipfGAilTlzLFmnNZNjKBRd9RjZW7GYFhUIBF154Ifbbbz+k02mccMIJ2LBhg3ydUopLL70Ug4ODSKfTOOWUU/Doo82bsc9HPPXcc+glfu7AdEKxIjRKNZOVbgOBSVQMWCnYjDw0wHM72U333HA9CVJz9sK5Uu3AUVrTFHklqVhVA0qyL8+1E6TBtPLI8N6ZRs9yZFe/GACQKWysC/GpGMtPYPB7xyH/jTObdoeYCqJ4YpKvMPsttjK1eZgg2aTKVRitJjOdIITI5tN1lbRWESiNMMW0SYh5smKjkydzLyOjGHnkZgC+O3slok+sgOi3SYvBz06EiJ3L3fFF6LYhCJHmnfs5jKhllx7E2iid/mng6LcAPJcrfN3Yo3y1nR5ElXt52WPBcIvIC60tYrlNojjjiaWvw/JF9RO9sCrotnfJUH/gM/lkJqoMpwOxmj/AY9/Xi0is1niYlyxaXfeaiv0OYJW5aybuwv33syKqEXMQXor9hqQ6jnyphh5eQWoQD1WrfuEVRpLbz+i5xv0ticHOgQjFhomd1YDYaVxRqWSXwYUGjVBMjAQV0q1bNyFFbDjQkF68yn8hkUUR/u82sP8RkZ8hiJpTLUli16y1ncwdtYLXsSA5yUyQ2Gk6u281QmWRiCikqPDwOKrsHNrc8qJsdAKpLukpNzHKFg9qrhxRQnYFrStoNSPUL6cGSinSnNipxSMV3kasEMrbFF1ChGuAIUKxCvkzuU1MGlV57YtcPM1M8f34lisev8dF3l0URA6fiNKEw7edy9j1u9jaiu3PsoXdKLqwqLcPSHXD4bSjMLoL1PPQw5XnLl4UUTXZ+XIKfvQiyRf6Zoqdg8Uv/wB+v+RdAICB+64A1n9bbmtX2G9U04M+c+L4RORB5IXaU0QgJDqDCxAz13hMnWssKGL3zne+EzfeeCN+8IMf4OGHH8YZZ5yBl7/85di+nQ0gl19+Oa644gpceeWV2LBhAwYGBnD66aejUJj7hvHtYPiZ+4NPTCsU6xM7KgYStz7EANQb/6oQ1VqeWx/qoWrO3kwUu5o/8JZ5xZ8Y4AAlLMQHpHHCBrqkU0CXw0Ii2b4VWHvwISjTJBvgxoPGtSqKI5sxSMbwIvoINm18qumxfe/OTfjfG6IJlVzN8zBnjhvT7jBYaEltC6XC9SgrlACQ5gN4xegGANTCoViFbHljjb9ToegncwPAkk2/4e9v3CdW7pcP1HrIyT1Jo4md08JAKMw7hadb38pg7hrhYa8wsRM9XZ2O5TKEiskgQRB5oYlBnwDYVMeRr74g8li6BhiR6qejvFtDEKIXsbB9mA5qfDW/P+FWLVFhmpd/EnjFZcDh/9R0X93HnQ+LpHCEthGrn2NV3oXMSqm0GdYEJsdG5LkFgFp56t7JaV51bYZMb1VIxY4vWuoUu1o0sRP2PSSZQ4n3Xy2PBX+38W3sXhvVl0hiLyC7TyCNdM8gouBIolZWOqA0NolVt5fHb1WR4GH3dDak2CnH5PGxTajydpKbbltsgevwXDvL6GCVzFo3+87jTC1KqgpTIitzwsqJ0H2oFCLUHA9ZPi6ksr7iayXYZ5dCxC4cihULHt30iZ2wiUnDQs0OOiEQXlGs5vkJEtyM7BC+f2E75IiFEVfyB1aze32QDmPoaVbpvMtcwSrpNU2mhZTHh1CcHJUFZ739bNy0ufeep+QoCyVTJeOHv+lT+Kr7OgBA4Z4fy+c93o7SNoKkX4bmp0nskkq3GABIdsTEbsaoVCr45S9/icsvvxwnnXQSDjjgAFx66aVYvXo1vv71r4NSii9+8Yv42Mc+hte//vVYt24dvve976FcLuPaa/eeBcZsoLYjqDJq01LseEhNN0GJyLFTFDslj0SsuKL3wyutaL0C5jpKaHcGxM5RKu2qkyNwXQ9Z+MckE7n5d5rkYcWEPYkllN38XUv2w1H7LcIzlE0K1R2NlVqqKI27HvpL4+0oxX///jF85eZn6iozAf8cVkN+RnkeMuvwoolduVqTJCzFJ5car1R0i0Fy5Uz64cOxrU+gEcrczFbgmNLtcCoFZHnispfpi3gXg8eTqBPVMLELEn6PXyeO3ryCDPCT6AGgRk0MrDwg8DrVohW7dImRAb1nJQzuK5aqBEOowgw1s+xQ2eT88c6XYMWKaNPf5CK2n6VkFDvy9cn/otKz1VybKNAu9hmCbJGozg49q4Dj3ws08F6TyPaicuT5AICX6WyR53avgp4V1/0EyiHz63BLryiIPrNqZWUYwgNNhvVCOZCquq5C51XeWiKLaoqFJu1Qk/byLpaqMJmqz2MsJNn1uSuxsmHFsCBqVrkgyUAi3ZjYSSsRhdiVS/4iP9WE2Ll8YSzucY+Hxw1O7CjPnxUh9xJXmUSHh6SqChKCElewa8kgsSM8HKq7VZQqVTkupBVi5/JFWdUIjjPSKJhHMoRiZygWMIIIaYSiynPLROGJIIAyz8+pyXPlNiE7QunTQ4qdWBhlFi1DCSnohEJ/lrWyLOX8e7Ok83M1sQtjQ0yNn0BWmp57PAeUKDnKaXE+c/55WdmbQfKAkwEAk3l/W9G1yDWC95mlCVsn/h35texMFYHgyPWHTMY7G99Hc40FQ+wcx4HrunVNd9PpNO644w5s3LgRQ0NDOOOMM+RryWQSJ598Mu688869fbgzQmqcrWwnZI7ANKpiPVE8YQKiKtaLVuxsq560CIgwaFQ42FOem0lrMkchlnZhN0rlYkCNkCSV/y8UgUXeKHp49VPHkpVY0pHCdoOtqkaee6jh51HFi0vbHN2wGgBqjoeUW0IvJmA59d9fnMOwfYTXx1as3ShEtrGqKJOLKMN3eZhNWFIITOz2zXrtkWAOn4oqr5QskzR2YDE6SAXeV4/HqkmWqlBaFJ23BPj9NjPcyV2EulOoBUKXlCfIu/rUK9ya4pU2pA9A14MVucJWQwtdN128p2u6bxWy3FessxYMoQrFzkh3YCjFBtu+U6LVOraDQXggSBIHu4fqCyjkAD8DxS6xKLia17MzW813veyDAQXRXHIAEtw2I+NMoDYZJHbCimasZOH0K27Dl28Kmho7rodObqib7Q6a3qrQTEYWxO9SR+waKHYypyyZhZvl+y+EzMK54mx31rdTczIs96rSGV0RC/gLCldVctLZRpvL3FFPIaM1fu9ZVEciEZxLRI4dALi8RaIhisa4WprkbcRESNblxK7KlTjR4SEVKoKoGuw+p6F+zaKAgbg1lIv+uKArLfsI7+vrhPI2qR5U7BJCsVNDscp+RAcOQ27HUzAUXzrKIzTNiJ3Yvwjpuvw9UvkiBMMmb6FXZuMP7fWLZSpcgbQLI7KncF7zw9Ua/74GNzG2HI+1bASQygTPwVEHsM8xHcXQXnT9MIPXhi2rf9m1SgWJ1Vsjdj2DqwKPs00WSHONBUPsOjo6cPzxx+O//uu/sGPHDriuix/+8Ie4++67sXPnTgwNsQmhvz9oJdDf3y9fa4TJycnAv1ptZm22ZgLL8TBgsQFwootVwU0rx44raEQ3ZVWsqlSpil2jvBlAKY336gkKVUO7EYpeq1BzYLzSGCrFfOB1We3FV4hWit1QInm8jBRIqhsAUOlmA0g1ZD2iwlNCyMsn7m24Xanm4NeJT+Dm5Afh1eqVHnEOnVRwEjeXHQ6ANcQei/BZqpT4pAAiV+wioVqrBIldcbdPRIyJTQ2PtVZkoaGy1ol7Ol8OAEgUt6KMFD5ovRu1wWMavld4OHXyrhki1J1GDbZCaCmfIL0WBkLVvHM8XT+RE5lj519Djuthiccmxu6lB6CzfxUAYAnGsLvoF3UkRZPyVBrL3vEjWG/4AZa+8KzGB6ObmNTZbzS287m6l0WrOmcGil12SXA1P+PE6o5+lA77f/Jhz/K1SHHj54xbgKu0iAJ8FeL+zaN4yegv8OCGWwOvT5QtdPMczGx3Y/VWqDiGJ4hd8L52Gyh2otDGSGWhdzHVXCsGyWeyyKxO9N76HMNVLziN/X/Mqxoem1xQlH11xmiifrrSI04hdmU2ZlRJqs5k2zBUYse+t8ixM/i5T7m8IpL3QaY85O5wRY+WRmC7PhERylsHP+fLlgVVZU0qdjVU+bjgQPc7gADY/8Q3YCS5HxYf9+bAe6kmKph5KJZ3fzCTiqKu6awoCL6qK0K2RpIXTSl5fiL1phnZEccsCKK/MPKPeZIX0YiCrsyg34PVFqplcQQVXrVfMH2S5LdYzAMAylVfyczkgqplMtsNIJSTLbtUBNVcv/qfj2PW1N9VRe/iZdL0GgA6u2NiNyv4wQ9+AEopli1bhmQyiS9/+cs499xzA2pA+GallDZ1yQeAFStWoKurS/777Gc/u0eOvxVYjouDeO/TUje7GabnY8dX2noC4MRODaeq4V27wWAN+AalYc82AHAVgqTPIBSrNpMmlVFUCsEQpqzQ48ciFQGOcX2xDN8klzJlKpUPKhaBz1O++zI6hPGd0blr5WoN+2s70UXK8JTJRMDg55OmgpN4ZvBQmSA8Obqr7n0iH6qKlDxuLcsGfjNUSVvN+4uSjsrWhoUuIuenanRg90HnYhftxt3eWryy9ln8jpyCI5v1OzXZ5NjFFZ0JbiWgE4qKau7K86hE6LYZ3KSSI9RVP5GLHDt1QbBrdAy9nKwvGtwfJg+hDpJRbM/zQdj15CBvJjMgSw5BYt1rpzyeKm8GvntbveopB/gZELuupUGlKdUx84q57tM/DI8Y8KBhyeojkJH+gAV4xaDfocMXHsmd63Gp+X1cWP5qwNtucmJMWrqEG8ur0LndiQ6hWAXv66mJXQ4di9nvlq6NSPsiAOiuMfU5O3BA3fs7XvIvwIefQ/bYtzQ8No8rdlqV3YsVJJpWMYsFCFUWjqJ7SjXCu0w3DPm3K3PseN9fbvSb8YqglMLgxA783qcZdk6N8gjKVccndpyIiMrYpNJ1AgCIUL+8miSdZaQD4eieNS9E38UPYdlLQsROtn+zQClFAvWhWPW7ipaAZjhka/iqoTBK9pqo8kLpE+F6l+dIqyqf1xOs/O5b5Rt/e8oi1uEVrNWkf02KFovCe69U9Av3jFAls8hFzKAix0bRtYgmQ8ROKrj8dbv18Qxg3UyGNTZOl2gKiWSLRRdzgAVF7Pbff3/cdtttKBaL2Lp1K9avXw/btrF69WoMDLCqtLA6Nzw8XKfihbF161ZMTEzIfxdffPEe+w5TwamV0EVEhRlTOqZjdyJz3jRDqYpVFTuF2DXwpgJ8tSzcFxUIKYAzUOxcZeDVquNy5eofg/DU4qpNiNgVk/7j/v1ZS6gltS2RKiMQVBoBYNsD0Xl2lZI/oHgRVbayT242mDfT078SBe49VRyPInaMQFWVMnuT52uE+8WKqlaAr0obGBh7vBLMNjtwxLrDcWztq3iTdQmOPOIFuOEDJ2HdssY+duFG6iXFGiXQQF0QcGPqFa5Kdo2++oncD8X653X3dqamlZCGlukGOhkZ6yRl7Bxm+X+WUmiTSE6Rq6ZAW8yOwRx5pO41YRfRrBJwKpiLgkpMuNvAtNC1HNr5v4F2zo+AzqXSnLYTZSCkhrlV/jvxHM3VZCd2TajV5uz56hQu+yLMJid//n+ZijBW9FghcsrMdA7pRex36yfjeG6ETaL5soVllB3zYtGXM4xs83MmlCWzlgcwtbGsbyWipHpU6u89AV3T4XFPStdhbgGCDKe7hKVJCcWagyQvjBLKrM5DrGZ1FMVKSaaSiCpOHHo20LUC2P+04GdyksSInTi21oiGCKESx4Llej6xSwa/m+gFbfN7WVhcSXNnSeyq0nbFMxqfW0EIhfLnq3yKMbLSacWhGpasVH7zLCfB1VFQPr6JUDwApEWLRZ4TWuPzgR1SMgEg08HGNQOuPHbRZ5wkw8UmycDxCu9F2sJ4JpA32bGJqv/5igVF7ASy2SyWLl2K8fFx/PnPf8bZZ58tyd2NN/p9KC3Lwm233YYTTjih6f46OzsD/5JzyMQdW1khi/yLaSh2Gs+xI7opy+tJA2LXaLAGFFIVQS49V+2pOH1i5ykdDkwrD6scDF+KY9BlL8QsSvBvxlrGN/w88ODDUKUmkrCQ3xGt2tFQv0v3udsjt6squXCeU//9DNG9Q7GPyNMsujo6lLZQ9T0zrQofsJQBPB3RagcAtFClKh2LzrMT/lpOohMvWrUIP3zHcfjjv78UX3nzC7BqceM8JKC+kXrV7JKWLVWF3BI+QdIWVrgk0y3/7ly2tv51PkBrSvFEYRcjdqNGP1Mskh0oa+zYJ3dtAgDUlByvZKq1CRAAOg85FQBwuP0ghidDHUycesWhbaQ6pYktAGS7Z4HYAcCqE4G1LDyZ62LETiMUmcKmwGYib0jkF+VIFbt2+fmZVe4JJsxfG0F4oAk1Wvxf5tcqbZCP69v3dAAdTJVaSsbwzAi7h57dMYIlJM+2XVJP9FuBUFbE4qc2RWs7OWErEQHhxVjT6q8dTSNSaXddO+AEkOj0SXW+bCPFc+0MbnnRtYQVhJjVUZTViEOC33svPB/4wCNAf7A63A99W3D4uGC1mMwPQyh2NViOhyQndolk8LuJXtBS1eWETIRshX2J5lr+Pd4kPGlI8i+IHSeDysKoZ8Uh8u9d+oAsygEAo4Ody5Q9BrPMrkui5B529DCS10Un4XlULrDVCIdArqPb/568RZjJuxZpIcVOppDwe6Wd8UygnGHXdlmLid2s4c9//jP+9Kc/YePGjbjxxhtx6qmn4uCDD8bb3vY2EEJw4YUX4rLLLsN1112HRx55BG9961uRyWRw7rnnzvWhtwyRtAtArk4I2vdak+qWkZShWLUqNlA8UYserAFfbo9W7Pz9hUM27cBTPLiS9gTscj7wumyVI/IGjURgEvVyvj1CVzaFrTpLqN36ZMg2RmwfqsTsH7sncjtBwADAc4Lfj1Iqc+wSSnXUqLYImkZQ5d5T1mR9WzGbh0TUATzLB7MOOhkItyaqTKETSkKhAVklPJlb+KedeOBiHLK0tSbVeojYOWYOFU6cLaWFlCaUjxZWuGrxwMDq+sINLSIUa3Ej4mLKD1eVuD9cZTfLz1INco1E6yvt1IGM2B1JnsVDzwVbi4nkc+ELNl2I1TwAZDtmP/+GGAkUwSahfivYP1bmgNb8xciEcq1YBXYdlfUpiJ2YtIX6w/8vE0ZQqFM/VliOhxQPPSbTHUAfU2fWkB14boiF07Y8zZTSspYFptuKiV93GW7b0tREF5AtszRXIXbCCiOC2AGAyxc01HHgKPc84eHrDlLBA5t3I+Ox/SQ5sVvCE+uX0mE8s42pUFUkgp51EdC56mxSS6qJlt6iEi0UO89CzbKkSpgIhWLFOONUiqBePQFU7UtEsRyakB0zGbxGosK3S1b593w+E1SzE11srMvZeaRq7Lo0u/0xXHSnyJEqCsWiXOhXIpTMXDqJEleTS5PsWpMegungte7y60ccr+xoNEWf2MA+uK1RXcvAeYYFRewmJibw3ve+F2vXrsVb3vIWnHjiibjhhhtg8mqmiy66CBdeeCHe85734EUvehG2b9+OG264AR0d8/tHUOHYfBVEifR6ispvmwrSh8rwQ7FCsaNKiAEAXLtx8YTBV+JRx+BRVQGcvmKnThYZZ0IOcAKmVOxEL8QESoryoHcH7RMmciy/Y3JrfdiNfSAbAEdpJ1xKsNTdAWusvo+oqhy6oXZmnudBJ4yAZbr8CX3SYBOAzSu/3GJ96NThYTNbsQ3p7GUExoAn1TcAyNosn+gpysjqxI5oTz1N5vy035haC/XbpImcVENEXg7g+1aFQ7dRSHBiV0ESucUr6l6XRrjKNWTyll+VjD/IV3mIJllmuTiipVWVmg1tMSLRvRK7E8tgEA/5x28NvCQG+laqfZuhrBy3lm6NVLeLImFj2X4IVpyKwhZq+b9XbcTPHbV5pwTRh7YRzAaKXVXnxM6uV/crlosMt6BJpnNA936oGZ1IEgeVbcyg1trCFk9juYOn+opNDo5ddx1ea8qWKEwiyvgiVCu7gSIliJ3j2oFFtq50i/jrI88h57F7OM1z5/QBRmRWkV14ZiNTnlsJqQrVzKQWPD4utEzshOegawUsq7TQgkcaNddKcByLGTCD5agCqn1JzT9XzUKx/H1JWHA9KsdvtahKz/Ygz9NR7O5g/mm2my9ivQl02LzrxCL/3klme2Rlfn50CDYfh6NUVl0jrHUYgGqRjYEJSeyC8364y4ffWq11YmcsZbmChXT9mDafsKCI3Rvf+EY8++yzqNVq2LlzJ6688kp0dfkTGSEEl156KXbu3IlqtYrbbrsN69ata7LH+QdBIFxofm5ck84QjSDVLaV4QvR79cKhyCaKnci1ibQ7UUIVxkxCsbav2HV4BbhcKROtuoRqoFPRCieFqrJiSodaEqGPF53sjvZ9E8dd1nJ4krDE/h0P3li3naMQzHCfWtv2qzTVKsMKTwJ2pRdTvWInBnBHGcB7uzpQoGyAqYhWOpSiy2Or0McM9p2c3fVVnQBg2OxYyTT6Fxqp4ERCk51++Kbq59gJrzKSmHogXLP2KADAWM8RkQRMi8ixM/iA7Jj+b1vloY9sjZ0Tv+VR+/lw+f7jAQCZbXcEXxCdTfT29xnYTY5dhwVkplRqposS9wfMEHbMQrkWVjSiIhAA6Pgm/++y8F3rbrp/Uyp2TuB/4eJP7fqxomzZ0jA4kc4BhKC8mFWGp3ezxVVu9wMAAGfwhVN9xYYQhQaiyGeqDijiOlUVO6Fsug3Ik8unRM+xg8VhiZT0RXv86WfQyfuFZoTlRW4JCsYiaITC28pIbCvETs1Xcxv4rzV5M/t+nhXMkw4tUBxOiDyrhJqieCfT7HOI4ksnF29NyE6Cp0AkYbMexeL+CZHBycwqAEDvfocHns/1snt6ESbQ47HrsnOxMoYTIvvjlsZ3wa42VzKFklfhRRaiHWUiZI0iQq4it060RCNm67m6R51+Hv764q9j1blXtPyeucCCInbPB3jcbNIhBjSRGzeN4gkxYRLDDwcIM1g3FFZ0I8IrAiKPIkqxU4snjBkpdj6x60JBEirhUC6NN4ViZyRhK6bAHUuCUn/3SjaQdJc2RraQEsftEQ2bu5gNiPv47+u2U0mNGyqeUM9hZ1c3LL7CtNJcveO+V5pisikgqrJcJdzB+sWySbswxkI5tXJetsuq9r8IAGBOBPumCiREzo+S29YqjHARQrJTTpq2EoqVrYhaUOwyg2uB99yNZe/6ReTrQrFTi25kwY9iFOtk2SSQsxixEwa51jTaf6UPZuHY/Yv3BipG/VDszBQ7nXvZ7cn8m6oRnKzyCZ5fKoidor4nC0q4ll+HTrK76f4NrtglYMNxPUnsbO7DRiLGikqlJFUgYb5sLn8BAGCw/AQmyjbW1Ngiq+fA45t+fjMIm40kYcc0lbGsJCxqj2lOfJ0G5MklIsfODaRfGIYJbfAoAMDrvL/I7hUdPf6irtTN1Mg1VUZmrRaMvIVqlqQWqCCdoY4JjeD39bVg8dxHBxpr3afArwYtB1IZhI+fLixXPKslFctMKMTO9hqqfCv+4VJYh/wjVpx4TuD5bA+7ZnOkKu1QegaCCliBpwxUJobhcmLXyBi9prFzaJXyAJQuFdmQai6IHb8eDE+Yareu2CUSJl76qnMx0L906o3nEDGxm2dweJK+C12W8qv5cKhOADd/BhiOVqMEZNjSSIAIYsfJmRsqBPCaGBQLYkcQEYqdJcUOCrHLkSpsng8kChDMkFmqnkgGzDp7BoJ2GssPYpPKKm8bhibqw8yC2FFocNcyq4xlw7cDShgLALxqY8XOUc5hJpVCkYcDaI4NWjqv8DO5F1Pg8/nneMpKkRAiE9uL46yye5Sb6ZZoCl2rjwIAdFWCfVMFRDK3OQ3/tHAjdS3VIcM3qn+fwS0tWh4Il6yNbq0FQNOFrYZC7FSLHgEeWk7whGhb9KudhmI3cOQrAAAHky3YuHmT8rlCsZsZsVtzIEsYz+xB41LLDBK7UoanIXAlzbD9xUhH1S+e0KtM+aXp5sbJJi8cM+GgZLmS2DnCEyyC2FVLSuU0v6azq9hC5DDyHG544FkcRNh12zUTYhdagDSz5AD83FFd6XksTGkbWVyIUKznBnPsdF0HOe5fAQDn6ayK3qY6dCVB3xxkC8qjNZbbaLdA7BJcLU/AUvzXWlOQREGC7tnS5F30Qw18J05iaa0sW8JVqQlNZ/OLyKs0vJpP7Jrc44ZC7KqO6xO7UHibHPAyJN50dV1OJVF664pjyYTac4kWi9bkiE/sGpDxGlfyrPIkXI8y6xME27IBAEQuIT9ewxXjWeuK3UJBTOzmGUR7GAe6Qsh8Yjd5/6+A2y/H6J8ua7ofobBpuilXcJLYhfPFIsIr7GB8b6SotmaqYmfOQLGDuqIGkORtpUSbLWm8KYidmQLlE74FQ1asCaSW7A8LBjKkhmefrifAKrE75oSXYbO3BCnUMP7AbwPbeQrRC9uduEoo1jBMlHhyudbFVnJmp6j8ytd/X+GjFBqoSqF+sePDLO8vr3WjbwULxXZ4E9L1XkXaY/tM5KZB7EJtmYxMlwzfOAqxE62IjGRrikIzaFKx868h2V5MUex0/lkiIVqkDUyH2OkdfdhssEXA8EN+6F0SuyZ5Ra3APOgM4NCz0fGyD81oP80QVtzKvNCEOLzzg+MvZPqcIalYiwWGlmlO7MSkrROKUqkk80i9BFOTCZ8Mh566B0/f8gMAvn1PTSkWIMvY4upgshVP3HMTdEIxpvdJC5vpQAsRHncK4qRJvzV/fJEWFw3IkyeInWPLe96mOoimAWtfjUpupWxnViTZQJpB1yr2nZeRUX58UxMGMyXy1WxQTuy8RGuKr2YKYmfJtnh2hJItc9/sssxRrSkEUFfCwcJ5QDObqKE8Vy1JbNQs12872ew9KghBnvika0xbVJeuIcZ+p7Ab4GOQ10DJFD1hncoESpaDnPAQVCpm2XcSZtDsHAgrL70N26SFgpjYzTOIVaILHYSHBdSq2Ke2MDVnx1C9P5oKv3jCr4r1Fbug+haVNwMA8Bxpi6JFKHZhYhcV9mwJjhV42MWNTEXjbUnoBMk0kwDvNDGqLa4bFKAb2GUyad/d9Xj9cXOS6hEN/V1p3Js7BQAwcc/Pg9vVlHylulCsf8xE0/GEcTBzJV/KBndpX+JG9IsVk0siOFDVZKsdrliOsfNQNBZh1bIB7KZM0bNCrcUc10OOBpO520Ey1JbJSHfB4YoGVYkdFcRu5gOhrIpVrqtAXqg4Fu4DJgxwhefhdIgdAAwvPhYAoG/+q3xOTEzh3KS2kcwBb/w+sO4fZ7afJvAU9WOCdEgSICqWReI4AAxiN3ZPcvXC5r5ruebXh5nwz2ul6F+7NMmuPXGuaj99Gw687X3Y9tT9sKoR3nDd+6GsdSBJHBw58jsAwGh3MNeqXRghZdmbojpbXKdmgNjxRZUZTRJkVaznyHQLkXcHTYf5kvfKbYsh6xhjMPj9WsmVE5Y9BvGg8wIo0iqxE4odtaRiZ0e0xfP4cRC7DIcvjNQcVdW+RJDgpqq8sgCyahX//mmV2MFfxAJsfAtD9Mel5VElwhH9mzk8TcCrFlAqVyTxToaKJ0TRlwjNJ7zZG8/mG2JiN88g8jpcwleJCKplLidTor1WI0iLEMMEEcRO5JaFFLsoCwMAgFIBF6XYqSqWAReON01iF1LsRFspj7fqSoKbhYpcOzOFNLcYUc2JVYjnw62XAN+gmIIRQnL46wEAg8N/DdhFoJlixx9bVAcIwZ2HfwYv16/CIYewYp1sD/v8LjoJxw2eO51PLiRE7BxOZCn3rhNdJ2qpxejrSGIbWJh399ZgZWyx5shclXRn+z1KkyHFzsx0SzXEU66BBJ09xU50OFBD+ERY5ig5QqKyLcnzYURfyumaCWtrTgEALM9v8J8TvYhnqNjtDRCF2BW0bjlZifCSqbRWMomLYW76nOGGuokpGpcThSypRuGUK3bic/octrAc2fIk7DK371GJHSEY7WKeba/U1rPnlr+ola/YEOEJeKqOAYaoOFWInSYUzUQDYkdEKNYvnhBkDwCMo8+TOZQVPUTAFh8U2NZrIaSaVMiqaKFFWry/fMXOhsMX51H9jqmsDq7A4WOaGrIVbdlMaksXhKZkR7lGatWyn3vbBrGrmP44VUnWt7gTLdyssW1+iLrBb+bx571aMbAYCRsUa4oZNAAkuKn2bIxn8w0xsZtn8JQcOxJVPMErWvUpiR3vdWjW59g5YWJnB4mVhJL7pkUUcFCF7JnEhR1h4tsKtBCxGyC8rRZ3KNcIhefYfqVeIomDTjgLxexKLDnhnyP3KexGaETxAhXVwXwQP/a4k/GstxQJWJh44Df+cdk+sQvn2Lm2r6wCwCfPPhy3ffy1WNLJBjdhstmNIvKV4HuFuqKFBirRaofwY3Z5o3c30wdCCMZTLJ+qsOOpwPsmKw7rRgDAzLQfik2mMtInDwBSuS7ftNNSkvH5oG+2YQzcCLopcuwiFDvDn3RMTuxEQrRQ7JypPMwaoG/NEQCAHte/LuT1twCInaH4A5bMHpnkLsJLSYXYAcDkTpbvleOVpKnO+kk0AM0n1TXFoJtyFUn3LNQqBVmVWx3fAacqqlRD1Zj97FyLQoPFBzc3ip8KYbIxlbGsoXjECeji3mtAXDwlx85zgvc4ACCZw+ja89jn50IdjYwkCjk/37eRKqhCV8hQxmHjnp7qaLR5AIJIGdRurmTz49AcX7FTlT2D388JWFLF0pspdroJjy+KHasq+4m3YxtiJf1xys7UL85XHvFSAMDayr0+WWugZIprE7VJlPm2FgzfwJlDkwouOwcJYdScjoldjD0MT/RDJQYIiSB2nEzpUxgCiypVzUjU5djRkIJE3GjFzlEm9alaigGAXWtONhuBuNHvU3taWlYFCVk8kYK55CDkPvwwul76rsj3ejxUS8rjda/5x80Gp8GejAzHTt7zM7mdpuQr1YViXV9ZldtrPjkSxRM5UsX4xGTgvQafhLVUcKDSRL9J3gtT467sWgcb+KodrPrX3R0MxRaKBRl+mI6PXTphsL6bHKlcNzwxSCtVlqIVUSLVWqioGYTdiVpNLdMHlBw7oSamUQWlVOaDutNU7NJZThRh+b0lhQn3QiB2Sii1luiRip0obBFWDyVuZFwbeQ6uR6VFiFCSG4IQv2k8d/K3qe6rHW4Nk6NDcnNnchdcS3jDBSf2zCpfoXOgoeeAF7fxTeuRCNnyYApFzORqWAL+wlHeew1IgkeE3YnjK3YkOE2uOPsTKBz7Aax5w3/V76BfsddqoDAFoGmwKBufcy4bJ1oldn6XED/HzokidsL2xalGKt7CcDhBbT8q0kyxI0RWpdu1it8ZqA3DcDetKMe5+muy59CXwyIJLCe7sbzC0mnCnSQkhJpsFWHxLhVRZsbh0LxYqCZTMbGLsYchFDuP6CA6Iw1qGFSQkpYVOyMBTQvmM7mhnDY0UOwsxRtJn6IqFgDsRsrfFCANvoupqAu2VZXkxWyhKpNw5UrnfSVVUB4y9lRSto6FYwdG7gQ4aTMcRbELdatQldVIpLpkbs7kWDAcLJ3RQwRJhB9SFiOjySpLwpaNwxczO4WOfLAgpDzBk7WhNVzVNoOpk0BT9ExHNyDyckS3CUqlCW24inY68EOxqmInLHqUnpPcsiCDGmqON2MzYUFKNUJhc+sUSezaCCXNFVJKKNVJ9cqKPlHhl+bhpaEUb8I+vhkTxRJyhD3fORWxA+DwikWpxBEzEMYqjvnEDsVdcLiFRtiOolchcjvM1a0RnSYwwwuKKRSipChMUBQ7UyTON7iGA4pdRCiW7TCHjjMvhbnsyLr35/bznyONiEgINU7GesBIiZlu7X1+bpwjvUCjFjwi5cNwK7J9pEoARc/lJLGRRGuqvFAG7VpF5uXpbdw/JOtfx0ZXhHVIIoPRvuMAAEdozGhbb7CgJJwI63YRtTJvP0bqiamv4NZAKUWKf9ewj+e+gJjYzTN40qDYgBZRPCFMhqdq4SWUEN1Uiidkjl1rip2l9OWMDMWGFbtpEjuRo1ENlepnOhbBoewcqF0gzBZ6+Wo8rJmIqkqlgjz7l/+xL2aDiAkbtRIjVobSPLwux46TY7fRLUQICtyHrzgeLHQRoYAwsUvygos0z4cSXSeyi9jA17GGTZQD1WcDYfJqkW1XJhlpkdMOCPGJXZWayGUy/iqfK3auUmCTmIXQhc67xagLBrEYIYpil5LEroqy5Ua2L2oHwpQVAKq8q4a+gIhdpstf7HiZXllQYHpsshJWD0XuqZYsbpW+iC4lMFoI1YvKSle034IhKwpNr4aKcj2b1d0yud0NhUaN3tWyWfpE7xFtftN6hIt8prKpEAuQFO+QAAAJTxC7aJIgFHjqOcpY3Po9ZSz1v6eZbk15E/luXSjx97XWtUQQOwO2vC+ick998l+Bx4mdGjY3FXUuR3l1/RR5Z4LYOVZFdgYy2vCD0zv8BUaqJ7pSuueos4LvafCb6fx86U4ZtujDHVGR7HsG1lCzXekRmmqRSC8kxMRunkEMJpQ08LHj6t2UxE4QQDMBIvtyCruToEJG3GhCFmhTE2l3EnzOsaZH7IRiMqEHE7tTuS4p+deKefl8Kz1CEzxklbIn617zj9sPnS5b5Hd+KOaZAmYqFYYIETt/NR80A1VR4Wayk2NBYifyoBKZ4IAiwmQd3gSqtoseyghmTx9zZV97yDqM0RxMOChufkC+z+JEtC6Zuw2IFmJFpJEyNRCelyNyt6plv0I4PQvEzhCKXYDY+d6L8jk+wSSIi3Kl7LcvmqaZcDKZlO2Kavw7iX7I2gIIxea6/XtEyy6RVg0JWkXNspEmPCw2wEKCXdUduOu+BwEARa2jJeLvEK7Y8UIiBwZ0XohgUAvW5IjcNmONKsQuNJkSgt09rEq899BT2/uiEQgvKKYidiLEliI2qha7XxN8UVWn/nF4pF6x8xqp8lHo93ukrh7sb7KhD0GShMlzMtMisTOFYmfLFAUvgthJyyCvKj1LXeX+SaZ9QiZaTZpTqFhC8XOtKgyuiIprpBUkOn1i19G3PHKb1KFnBh43IsqCCCfckuxaZEcROxGapxZq1aq08gkvGPYFxMRunkGuEokhLSEC7by4SmZOQexMqdj5xRMiFBtW2hoRO0dpNRYVig2HJ93pKnb8uxSTIWKX9YldlbuKA0CyhQEkyW0/Mm6h7jW/80QwP67I5fsSD22qieh13zUixy4Mh1f1VsZ3BJ5P8XBZIjRQdXJH9g6UMTQ8jMXgyh1vwbO4I4WnDdZgfefjf5Pvs4uM2NX06fdEtvhAXyRZEEJkorEgdjWubtlUR7IFxXQqCB87k7iSaPsWPcrkpCSg18oFqVROV7EjhEgPL9FVw2jFu2ueQO10oHcslhV9Ca8mE8cBoGsVCwn2OTux6sHPAwDKS49t6TNEYr2wunGI6be+8mpwij6x63DGZYFN2JcRAFa/5evA676BwROji5zaQSpM7KZQlaLU2WSDe09AkDjq2spY3Aax6xgAuAl0q4pduOAhFe6Y0ACGyI2DI42j3YgFj64UDXhyO/8zk4lUoHgKAJJTWIAIZdC1KrI4pZUUGYF0j096e5ZEEzt0r0Sx6yD5MNwiTMDkRDjplhQz4/prw1dwa6hW/IVqI5K/kBETu/kGPph4xPexi1LsTDTPsROhWNNM1BHEsEGx3qB4wbamCMWGCiocu/kxNTxWPrFa6eAKN5PrlpOMxa0XHKohYU7dTirNQ1YddLLeX4/WK3YAUOZho0qBhTaTVCF2YVPnqXLsANidrNjBzG+Sz7keRYobaCYzwYF/UV8/nqZskLvnJ59BiucUEiW5ON/DlBjRVB0A3ApPcjenT+xsrthVOLnVZF4OO9YaJ0FVJAJFItOFaF0F+N6NhiR2yu9rJFiFG3iVJp+YZmImXOUTqcW/k64U5cx36GYSRV4YkeoakJNVEjVUeeK4QzX0rWYhwT4ygWPJY6ghiYF/+kJLn+GKikmh2BFDdnEwYQGl3XLbXuRhi9Z7UTlv3SuAo948rRSBMMxECq5CQKbyH1MVvSr/rdPy3mtQYSmKJzxXFky1pdgRAuzHq397VrX0FjuksqVyrRVA+X19bZljF9XvWKR8JLxqZI6qrmuyYEZgKhVLEEjPrkoTe7MNP7glS7nPKDRkehq350of5qt2Pd3RaQSpbDf736tI79FmxC4JCyVe8W1TPWCIvq8gJnbzDJ4kdoZid1KfYydupii4HlUUu6SsihWh2HDRQ9huRO5HUeyic+yCz01XsRNSvtcRvMFTuU6Z72OLCj0YLRELoWx0oYiyFTJkdusVOwCo8lBmrcAUMKGsARHFEwoBbwStj602O0ub5HMV25VFCOnQyjyTNDF86NsBAGdOsurcCkkHks4TK1gT9a6xR/xjq+QBAE6itZV+FERvWNF3UU8Fqy1tvsKtTdMYOAxDIediQaAW/KiociJjVQq+ujwDYmfxfEKh2AnFQW/DrmEusStzIGowseygI2WOXZLWpO9cmaSR6lws29wBwK6j/x2kRaLh8lCs8HF0iSlDcwlqQauMym07SQVeiT/e062ZFLUVaKFjgG6y3qkArEoZoFQWlzQKd3riu6uhWNLmNPm6rwHvuhVYfkxLm7sh657wgq8RRDVrkjjSb9KLIHZm0r9GIFMZgouYcO/l5BShWKH4ObWyUi3fhmLXtwaVF14A59RLZLeSKOgH+8Qu1xFNeEXrsAwty8UIjSgiE6H8JHFQnGT3ymyNZ/MNMbGbZxCrREp0JYQaFYpt7Bln27bMHzDNBLRwKDaUL9bI7NhVzGkjQ7F1BQXTDMVy/zK9y0+itaGDGCmp2InciVabvwsD4yypIV8oBl6jDRS7msEGVKs0DsvxkIFSVBIKX1OuMnlNbqHsskMAAAP2Fng8ebtUteV+w628AOAlr38vaolFyHKfsJJi5AkASw99CQBg0NkCj58Twh3rvWT7VicCoqF6TedKnZgMBLGriVZEs6NqqcTOdkRnEa7YmcGJrsaPza5MgohrTJ/+cYiws82rviWxS85/xQ4A9v/ADTD/4xHkepcpdjC+YlchKYAQDOtMAd9mrsLKV1/U8v5F/pTO+866xICZ9L3OzFrQG7Kbd4oJG27vCVQVEmS2UJ3th93LsK2KHBdTDYgdnWmOHcAshwZfUN8RpwHCBQ+tdp4IhD65UhXV79jMCIufquwpHE5lUDtRqH1kG0Hk8lm1iixCaEexAyFIv+ZyJE/+QPPtlh8DdCxlBYAdA5GbZHjrsAwqMt8zitipZLXM80RrmHlayXxETOzmGUTIz9N8ZSoYiuWEjbjSrDgMR7EzMRJJv32TVOyChEz3Gih2lpJjF1E8ARounpheKFbkC6Z6lsnnKkgDhEgndbfKk2JJ42IFFUSxGymMh7pPCD+/kNomFC+3kkfFcpFW/K8a59g1Pp6elSyRejV2Ypi3diqX/f6bkQO4mULyhAvkw1R3UMU8YM3+2EF7oYFixxN3AQC0Gi8QmYaHnYDDiZLN2/OY3EJAdJtwqqK7wCwpdoriJvruGlKxC5L3muhbWy1BExXcM1HseIcEl+eQiV7ErRTlzAuYaWidbJITBTgpYqPClWZh9VA68GyMaz3QX/fVtsJNHq+iF31nXWJK1ScFG2krSOxWgBUHTZXzNhuwAsRuagIk1dlaCRXFcFn4GYYhFXhPsTtpJ8duGlDDolHGuo2QUBYiusWVqghil0zVK3bhVAa1E0Ur97gghla1zDoDIcJncDagG8Db/wT8y81Agz7H2U4Wok0Q11eTI8ZWovgeWpMsnWC6rQnnO2JiN8/gK3aG9J9TQ7GqUbBjBV3mBWyFYJlmEkRjg7pQ7OqJXTQh85T9t2J3Ipza24XIF9QVPyNhMClvPEHsWlTsoGmsSTeAcn534CVx3DQUYnE5saOVPEo1G1lVsQudM5l/02TQN3pXw4aBDKlh1zZmKlxVbFsa+nod807ZtzTXGyR2hq5ha3otAGD3k4zYGbzyl8yA2IlG4bbJ83HSwhpAKHZskg93F5gudMOQCdvCOiZg0aPAksSuMCuec7YMI3FrB67YGQskFKsipahW1gQjWOJ8HX7Op9DziY1YetiJbe3T5fec8HF0NVP2NAWAboepHWLhtJywx/peIXaK/1oL1Yxie7taQYUrmjVqIpGIHkfEYo+6Tkv3+GxAVc9E2kErUKu4hboalXua4IpdgrjQ+W8aJoBqJ4oaWid2dq0iid0eKz7qWQUsrfcMFFALYTI1di1Gmhlrfi6hU2QE0NIWyGKuTcTEbr5BUexE7oGukCq1jVdNyYFT4ahKm5mEZvD98PeGQ6gGbRSKVfZDqFQL5bGEiN10Q7HS7TzdiTKCuV6uFkzkjmpy3Qgl3qS7WhgJvsCVzjCxAw9lkuoEKuWitB9g74m2O2k66OsmdhksvDy59TF2LFw1sGA2zi3JLmYJ50BkAnaljw1yZOf9AICEzfapT6OdmNwnb8FW5ZXJYjIQ7uzuLBM7AHB4iMupU+yCE4swvvWqRZkPOhNiJ8LOYuGS4ITSWCChWBVqn0uH90W2VKuHFsOBKjx+zwm7H4+YAVPqHo8pg7sMprAnCf/dWjTknQlspR9tuMdx5Pb8enVqZdQ4sSuTxr+zyLGjntvaPT4LUK17qu0QDU2T1j0Jh6ebRCh2KaVQxOCG7dQIfo4aDm5FsRPEkFolGITPSXNlF6QbqHBltsthi/hG3TsEaaVlpjpbsziezSfExG6eQYT8KNGh6aLHq0/m1L9VnzkVosrQowTQdNmiyVfsgoTMbKDYUTtEHMN5ZmHFbprFE34oLC1NfYXBpFAPRCNotw1iVzEYsbMKoX6xNFqxI7ycXrcmZb6SRPi7t5h/k8+sYsc98iQ7Fm76Wo1oeRPAKy4DXvUF4IR/r3spt5oZFS+ZfBQAkHLZuTGz0yd2d/efg0/Z/4yHBt4AAEjyMFcGNbgehcsrpJ1ZXOEKYif67jZS7Bx+LXhWSaYNzEQdcLk6Sa0yPI/6yd9t+HDNG2gaKpTfIyW2gIny8GoHIn8qyduTeZqJZDIhK1LFQnOy44DA+1rtmDAT2AH/tRaIHQ/dOlYZ5TwjvgXSpDiBjwnUcwCe+0vbzbFrE55CssSCtlVYRJBwTuwiyFUqmZJG7wkrDwAgYWJHVGI3NdkRyqBuKeOkMXcLIxHhWQLeb7eBybP4brIfd6zYxdgbkMROM6BJg+LoUKxtNVLseF4UH5DCOXbhfDGzgWIXJnbh94Vz7Lxwq7IW4Lien6ORTKHMyZiYnET1lQg1OK2GYgFYJiNqQnb3D5srdqHLX093AwAMq4BqOUzsgmFmysmwN0XOX61rDQDAHGehWJsTu9pUA0oiC7z4X4BcfdP21UewAoqldBcKY0PIeGyfyVx38302QVfvUnzXPRO9fSzhXqzyk8RGpWbB2xPEjishwjDbhG+qHdiO+6PRWkmmDWgzCJuKfELPrsByHNmk3lyAih3gm0vrFaZWuBFWD+1AKHbCx9HTTCRNPdAZxqGarPoWaKWYYaZwlKKZVAPLEhUif82tlVGZYMS3bDROWVBz7PxQbGt5vdOFGha19Paua9H+Le2yEGtUv2PD0GVnGWnYHl48KYQ5st9s3U65h55dqHtuLiBsmnp5W7ZEg+IYQez0KiOAszmezSfExG6+QcmxI6S+Kla1GHEaEDthOyIKDfxesey9Hlefarz5dCNPPOHy7x9amNyEVaz2c+ws15OhsEQqhZrZDcD3IZJhIUHstNaJnZtk+0IlWrFDSLETilfCKcBWc+HU94iHoqev1nzQJyHLE2EbIvKgpoPexUuwSWM+UA/+9bfIeWxQT3X2NntbU7zzpWtw9VtfhPOOY957qs9XpVwE5WFLdxYHb9G1w3NsUM9Dgof0wsTO4ySOWKVZMRP2FMWupvRDNheiYgef2KV4taprzkyxE15oaeoTO0JIIME+j1xdx4CoKu/ZhvBPcympU3ajIAiLZ1VQ45WQFbOxsk3F/ew5SvRkz06Tal6c06baKnKO05R7jja4Pyv8Gsm4PB83tJ1qWOy0Ep7kx5x0RGqJMStehdOFSD8Q6TOJBibPImdbtJp0ZlBdP58RE7v5BqGKaYYMxTZU7BqEYm2unInVnGbwKjeIHDtGwEQ+W8MuFqGcOTes2NUVT7Sv2FmW7bexSaRhJ7rZZ/EkfhEWMl3hgt96FZOXYgM44T5vEiLXMJQ7k8yx7dNeUYZMBUi4eEIJmTdDZpBbnlhbAPjVpeGG6e0iv/w0AEDlod+ig7BBPdMZXTXWCtIJHaet7UfK5OF/pe9nrVwEtUVYbk+EYi3Yjn9+jdCETfm1QOySb00ygwpWT3w3uxK4hxLt2DXMIwgVIuMwYueZMyNYlC+ehJmveKx6fk2QLnT0Bnt8plr0X5sJRBi9SpIt5Q+6ijrrFpmi6SQb3yfyft6LxRNQ7rUoY91mEDnHWd7jNWwVJCBsPXKUjWskpHirHStaIXaCGGa8Ij+Oua0utfXgeUs2InZ8/ErbzCIqnGu4ryAmdvMNIq9DM0AiesW2Eor17BCx04MN14XSJhJOEw0UOxIidp4TDL3WV8W2T+xqysRqJNLoH2CTxWA/C0GKUErS9Sv0WgXhxQRGbTzwvDzu0Eo8LdqQeUW4wk1fIPxdWxz0+1axThF9GEOtNA5PuPnPkNgdcNI5AIBjnXtk8/BEdvrErg6aJq+PWqUgw/LeHlDsXMcOXMtGIjRJ8LZimlP2+1K20b4oDMrPPXGq8nM9SkAWqAO9sG/pdNh1TmfoJydCgzlB7LiCp3pIFvVuZBcFK7aTLbbQmgnE9deq/5io3qR2BSizlAzawDYD8BU76rmKkfmeDcWq6plntvfbCTuoDrBxtJGSXePXiPDQDG+nKnZRbcnCEMVLnYS3GpxrYhc6bxnejSIMQVqFcunGil2MvQLXV+z0UAgVQKAy1W0YimWTn/BfkgbFoapYcbMb8OrsPNgOQqHYUOsxGsqxo9OwO7HVyl4jiSUveh3QtQL9Lzyb7ZMPOCmRyN1G8YTOiU7Cngi+QKOrYnNdbPsc9XsO+u8Jq5WcgE8x6C/q7cMI7QYA7N70mMxVq2uY3iZya45DwViETlKRiudMfOyiIPJyrEoRxGETBzVmL1wpcuw8x4Jj+9eOGVYdeOWnbpelYmfMIGxK+aREnAocabxsTquCdD5AFBR0U3adt2pw2wiUE9w0Yeda3INqUn3Z7AYJGcbuDR87j5PyWgsJ/mx7Hna3K9CrTNHUsosbv0GMCdRpWZWfKYhyvbdP7HihCxGWI9H3RdjWQwstjFTLFbeFPsyCGApC2U4kZU/ADanUjRQ7QeQ6uXJJF6DFUSuIid08A1FCsSJnQSfRodhGxM5xRPEEr4blhq9GSLGrqWX/EW3Fwq3GPCfUfSKcd9ag52wz2Dx3ywNh33n/04APPAIc8DL2PFcLMlSEAlsfQMwONoCnnFAhRIMcu1y3362iVgzm5ZGQYge3tUGfEILtBsuHm9z2qHSI92ZI7KBpwEF+ux0XWmNfvGlCTOR2pQQiupDMomLnSWJnw1EKdcI5dkT2rS37nnMzUOxET1PN9RW7dmx05htsPlkJIkZmaDtCQm2pBNELVE4mFwHZUGHPXug8IUJnrVRuqtvDriLJlXujozGxkws1z/H9Lpu0vJoNBNSzNtuyOaHrtlHeoR0idnpIsVPz/FpRsbSQYhfunrG3QRNBtZgko9Vj8d26wRfus7hQnU+Iid0c4ImhSfzX9Y9hrBRBhKhfFavr/oAiLUoUlcxpYC8ilDPRFUGXOXbBqtjAKi7Cg46EiJ0bVvXqyM40iB1XTKxGiokkdo17ITaCKCbIuuEK12jFLqXI93RyR/A9tEGO3RTFEwCQT7OCBGfXk6BcsaOz0Fez46jXyb9LJDfripO4PpxqEUSot7O4wpXFE64tvewcqslWegJ6ShC7itJwfPoEU+QXaU4Frnr9LVCELRv0FjoyNEVYseHETrUacVKLgGRHkGDNsGijFQiFpWU/RUOE3StIO3kAQKqrvtJcQlx7nquo8nuY2CljQbtqazg1pVHuaR2xCyneamWu1wqx4wurTvBq+TlW7OrOW4PzKIhdiiucszmezSfExG4O8O3bN+KqOzbi9w/vrHuNCFsN3ZQhVMCvZCVKWNYL+8xxiKpYSexCIV2RO+JqCWlw6XADWhVhxa6ueCIcip2WYscVkwYTq1hJimqndhS7TNcSACxhWPRq5QfK/gsP2LqBInd+T5SGAi8Rb/rErtq9P/t/55PYOswSuBOzkY+0+iQZ0hVdM2YTgtjZtRJ0XiEdTrqeCcT16Tm2TB+wUX8+hdlowqtIxa6tvpQhiO+gu1U4XImc6xyhmcANqQ5aA3PWlhHONRSdOpR7j2YWA4SgnGDpCx7IXjGoJZLYtUjsZdi9hg6Phaqz3Usabi7uZ+I5UpXf0zl2qmLXSGlqBDc0HjYiduGcXiO0sAx0omjhdxSKX46wcWGuc9VUlbqKBGtFFoFwscRsjmfzCTGxmwNUbDZgVKyIvDZB4DQ90JlAqGWqQXEjQ2AvpNiJqlgDHiilkiRCM2SLFSuiwjbcasxzwuQmrNi1n2Pn1KYIhYUUunaIXa6brcx7UEShqhy7yFOMsDEo8zZkuVqwvyyh0wvFAgAWM8uT1eUHcYj3DABg1dImqkGrMFPQDzodANCzqEne0DQhJk+3VpY9WsksVo7KUKxrS/XZiTifoido0ivLlfZMrEmEQqK7NbhTXX8LAOFJ1ZwpsQtN7MQQxM5/Xsux681Kseu4RlJ7JUdR9Pts2X/M8HPsunheVVfvQOPtpd2J27DIarahFgK1q7Z6oQVJoxSFcNGTHla8ld+8lUrRsOIXJph7G1razy8WvZKjED4PZBYiJ/MRMbGbA7hcPbJdWvean2OXCIRipX9dS8ROFE/w3DrReYJQuK4rP4NouiR2UdYpejjHbopQLJkGsXNljlODgSF0I9I2KheTHSwUmyYWJgpKAUWTAbuis4F1kcs8r4QlR1ixQxuKnbn6eGzx+rCYTOIk/WEAs9h+6bDXs/8XrZmd/SlwRSuvWgmGt+cUO+r6il2UAbXB1c2s5xe0zKThuCB2pleVuX1zHUqaCcIFLWaDxPFWQcJN6PniSm19ZXYwQmd0MkPrlhW0GWLZSnadp3tXtLQ94USH1CakupTr6W/8BrGYpq4cJ1q5x2cCtRDIaJOUu3qY2LWm2JlhAqiMs60Qu/D7vRYKLvYkDCUCUmvmERpWt/dRYrdnr9gYkVhb3IDzze/j6dJlAIJteQjP5SK6LjtPAEooVlGOvJCBsHyeh0Q9TXiS+T+z4zi+Ykc0mVsUSexCil1djl2od+x0cuyEyXI4CVggPMnQNnLskOqCAw0GPEyOjwL9XNVq0FIMAGp6B+AAA4QVT5RIFl10sl6xU4tcpsDa/QZxtvMZfCF1FU7x7mZPthlyaYjDXgckfwX0r5ud/SkQkwG1yzA4ydf3iGJnwZXei/WKnQhbd9ECwEWh5AyInWhWb3g1mc7Q6PpbCPBCk1WyQTulVlHXvYDfc2q1ZKqLkaOeJcuBrUCuY3Yrshth2XH/BLoohwNWntDS9hpX+LqsYYCAjQe8w0wkiLKQk1Wxe3aaVBU7s80UDS+UY9eoWryO/Ie2Uy1XWlm8hQkknWNil8j415/VxOQ5/N1mYps0nxETuznA8cU/4zj9MdR23w7g1MBrQhmioRw71xXETulC0bB4gtsUCMXO8G9+17HlZ3iaId3knQhiZ4RajU2l2IXbbrUCQU4bTqx1idxtDCCEoERy6KKTKE8MAziYPS/OYUTYz050ADWgm1d7VfUcupxJ2Y5NOXC2qxYG/WXdafziP87Couw/AE/8DHjyj8DaV7f+PaYCryCebYiwBa2VYVL2O+mzuMKVDdcdR+aFOhHnM8mNb4Xi4lEC05y+wiYmvwSt+sRuITcDD01WjaweWoUeOrcaX1ypqkyWq14kx/LVtL1QEcsOzgA55DWtb54QPURZbusk6cSiJiFjqc5RR1m87dniCZVkJbLtETsaCoE2SlGgocKWcPs3oub5taLYJeeXYpfM+sTObmbyHCZ2e8GiZy4QE7s5gCZCoV69wiUIhKYZsscrAHg8FBsgdhGVrADLWQL8UKyuq4qd7VfYEl02kXasCGIXzrFzQ+SGzkYolk/oDSbWOsPNcJhoCpT0TnQ5k6hNKv1iG9idAPVFCDWDKXj1ip2fp9gKVi3mA8gLzmP/FgCosGRxyjA99jvNZj9QSew8288LjRiSwkSlBhPpGbQvEt8hQWsynWGuc4RmhNCknc7NTD0LK3aELwypksvXsYiHMzmxa9emY29BLET6eXP4stGNZjbeRBZPuL6yv4dDsWohUKJNtTVMqBpWi4eukUQqpNipxK4FFctMNQ7lzgVSyjXfrFdyWLEzZqD8z2fEOXZzAFnZGs7bgl8VS3QzEIoVlaxqVWzDKlSh2PEBSVXsqOvKcK9HdJlbFEXszLBiN0VLMTIdxU50NGjQUSI8ybQr+Vd5w2+rqBI7HkKOWInTZHBStAy2giYhuxOyl1bzcwlhLbF7bFwSu5kYA4ch+uxSx26q2KVDraqsGYZNDUnsLNkPeWETu+Bvkp6hYqeF7jnxWFSoj9Mcejr4hNh/OPt/0f4z+sw9BYMTEOEFWuW9qBtCpK9QV1Hl955il8q2R8rDqSlmA4IdtldKhu5jdQGttdCurz5Hb24Vu3SuW/7tNjF5DhszGwu0jeBUiBW7OYBUfyIULvmabgSUNkmqVIuRBoqd6AUryJIWUuz8ai+dVQPSaLPjMLGjdTl2QbuTmRC7RhNrWLGrS+yeApbZBVQBVyF2pFm1W6h7g1Dw6kOx/Lvu4dX8XGK/gT5gB/CK8vVIwQLI7Cp2IlWAeraiMtefz3BCudqMfjoQhRcp1PxWaQuY2KkdHyo0gVRiZsQ3bHJLJLFj9+I4OrE6wcnOymOB99wN9Kya0WfuKYRTB5xkzxRv8O1OSBt5tDNBLucXUqXbDMWGXQOSqWhSpimKXY2aSJghr0iFzOkt+BHWdbho0MpsbyGlLGZok17J4dCrOVPPx3mKWLGbAwiSUFdpCUDnypCmm7JXLOCHYgMEYwpiJ0MImgaPsrwSz3UCK1GHG4x6EYqd6CHrqu8NflDwe02D2IlwcqOJNdzUmrSp2LlCgauo/WJFjl395a9nugOPPf7+cOcJ0mYodiFi8SEvBdUMZEkNOqGoUhN659Kp39giRHEPXFv2N3aj1Djdt+UBZu45l+DkNAkb4D52C5rYKeSljDTIDG1HwvecJnLuOLEraJ3Bz1iyds4n9kYwQ6E2Lz1FP2UROaDeXsuxUwuBjDZDsbQubN6A2CmEpgoTCT049gUsV1opKGjxc/cWSEo5b00cB8LfLTGLC9X5hH13VprHkHlyEURIKHaErxxdSqATqnjGKe3FItqAAX7nCaqENx1oSMCFG2qV42gJwAW8MEmkVLr8l5BCJyoROXbse7gg0EGnpdiJAhCvQY5duPVNu5K/GMi1qkLsmuTYGSFiR7mCV6fYyQ4hC7eackoceDrIh5/BxNAmfOfP67HZ6cEVg4OztntZeOI6fiV3g2KUClKMiGHmnnOJtD+Y6xbrSjLXyd8zQUCxIzOfYOuLJ/jijyshk0bvjD9jbyFM7Ei2+bETPiYQ6shxmuzhUCySnYw0a2bDjgkNoYw/NtVhNiChajV7DYk68h9Q7FoidmGj3zkm9mpLsWbELhSCTqb3TWK3YBQ7x3Hw8Y9/HKtXr0Y6ncaaNWvw6U9/WipZAEApxaWXXorBwUGk02mccsopePTRR+fwqKNBWlDsCPdrc/lPJCxKVIJBGuXYefXEzuU2Ep5t+/5MRJdu8nWKnWtD4ySyDF4d2UCxE6ExjdZ/n6lAOTltZGOiJ6LzfVoFSbPQi17L+89Jg+L6QTDZEVzRC+NLvS7HThDwfTfHDgCQ7kHX6hfgg+++AF9+3xth6LM3ZIjrk7qOrOSOCsUCQJX4A7LdYp/QRkil/YFfXBdt2ejMM6h5QlVt5jlDRmiSFkRv69IzcI1zBv7Y/eYZf8beQjKkyBgdUxiD8wW15ik5dntalU9kgH++jv1r0DGhEdQc5Ga5pyr5j1oYBU2SW7iGwnmYc03sdAM1Pg/pqcaqpxkKxSbTcSh2TvG5z30O3/jGN3DllVfi8ccfx+WXX47Pf/7z+MpXviK3ufzyy3HFFVfgyiuvxIYNGzAwMIDTTz8dhUKhyZ73PkRrryiFS5A+jRM7KohdhN1JI2InnlfNfD2+EnVd2yclmg6Xh7XqFDvFI6/KiV24eEIci7yhpqHYiXByox6wYcUuHCaaCkaWEbWkHWFQHFFZmQoROyHxawiFYgUB34dDsXsacsJUqmIbKXY1xQB3pmbCqYSJGuUV4zV2XSxkxc5QJqum5qwtIpxjp/NJvKu3H5c6b4Xbf+SMP2NvIWxknepq3E4MUKpiqVsXPdmj2O8EYMUxbb9NJXaN2jICwWskKkdVLYZoqV2fER6X594PjnJv0JVLG//GYQV3X1XsFsys9Pe//x1nn302Xv1q5v+1atUq/PjHP8Y999wDgKl1X/ziF/Gxj30Mr389c+P/3ve+h/7+flx77bW44IIL5uzYw5ASfxuKneg8QdRQbIRdCuDn2Kn5X0Kxo54LqvRKFaajNNR3ljpV4QWLmsjDC4diOUGySQKg9ZWjrYA4QrGLnljD6oHWZvGE2cFMidOOT+xIkxy7bGeQ2Ikq2XAoVttLidX7MiSxc21pbt2oOtrS0hDc2plhPpyhayghgSRsmDwU24rb/nyFWtBi6zOfYMPms3qCne8z1y0FeTPBCfsvnFBsWLHLdjfpOgGfxGnUL57Y0wbFM0FQsWt8X6hFAlE5qmplbkvt+kKKXaMetXsTqUwnUBttWllshBS7+UBI9wQWjGJ34okn4qabbsJTTz0FAHjwwQdxxx134FWvehUAYOPGjRgaGsIZZ5wh35NMJnHyySfjzjvvbLrvycnJwL9aLTp3bbYgveoiiJB8TXhHcXolyJjqp6Y1IHZEhmL9G1gQO9exfQKm6X5uW6iLRa3KQrNVaoJqghRGV8WKAWVaip3IE2wQYg33NGxb8ueh2A5a9J8T4fuIUGy2K9hzlSZFVWxYrRSr+X04x25Pg7Su2KmEZTasSapctUg6jNiFqwsXEhIBYjcLodhQ+oPB782EoeG1Rw5icW7hqJthewvpv9cAvmLn7V3FbpogirraLPfUTKuh2ObErqV2fYTIrkXA7BqXTxvC0SDZOBSr5tdWYUZGbfYFzN8rNoSPfOQjmJiYwNq1a6HrOlzXxWc+8xm8+c0s32NoaAgA0N8fvHH7+/uxefPmpvtesSLYd/CTn/wkLr300tk7+BBkWK9ZVSwndh4JVqSqip3eKBTrBVU/APA4h3cdJ5Bj5zVQ7Oway6yrwZQEqFEoVoTGdNo+sZPh5AYTa7160N6kIuT5DPVzCKViF5ForCvNpC0Y0iNMQ9jahZ+LeTzoz3dQce48V3oyNlLsVMLizkKXCIur0GmXp2ksZMVOyRNy9JmHlszwPddm+sO8QkiREQp+I4icWTUUG7UAnC9Qc46bpSgklVZldsT9EyR2rV1DNkkgwcf8Rj1q9ype+kHg8d8Bq09quEkqrYakk5gHR71HsGBmpZ/+9Kf44Q9/iGuvvRaHHXYYHnjgAVx44YUYHBzE+eefL7cLV/tQSqcs/9+6dSs6O32Wn0zu2YFMECItgtgJ0ie85zxZPMEIndaKYifJUkQo1nUCVh1UF+8JqpRWrQyA5c8Jg07aoPOEoyUBFzCmE4qVil30LZYIG2m2WzzByZtKzEiTqlh1tVclaWi8z64e7rIhVvNxKHb6ECTOs6WnY6NEdVchdrORD2eRJECBjMeU3Hb9EecTVBWimTlrqzBD419YwVtQCI8rmSmqYjUlFLsAFDs157gZsUso5D9K8U4oodpkprWCAockAMpaL84Lo99DX8v+NYFqLVObYRHWfMb8vWJD+PCHP4yPfvSjOOeccwAAhx9+ODZv3ozPfvazOP/88zEwMACAKXdLl/peW8PDw3UqXhidnZ0BYrenIUhGVCjW4IOJzhUsT+bYuYH3Ak0UMqkmKaFYogGUq24KsZG5baHiCafKFDwLpiy8oOHesEKx4yvA6VTFapyE1jUe5wi3yGl3ktH0emInjptEyfC6gTJJI0MrqGlpWcQSLp7QQkUuMaYBTuyIp9idNAizuuaeIXYd4MRuAefaqFW+dDaIXSh8aS5kYkcIakggCQsWEkhMYb5LlPvdV+XnsWKnELtID0iOVEYh/xEEsLO7B7/JvgEUGs5u0STZ1hLSErRhK7N5BkMhsPsysVswAeZyuRxosQUAuq5Lu5PVq1djYGAAN954o3zdsizcdtttOOGEE/bqsU4FTRCLqBw7TiD0cI6dCK9SJRTbQLGTRsGBUCwPp7r+ShSaIXPbiBsOxbKVmEVUxS46FCtWgAamodh5zYldItwCps0cO02swBViJiuLG4RYyhq7+S2F2IUVO00WuSyYtdG8A5V9Oe0prSVk31rMjjWJCEfpPLWh0fW3EJBKpWBz6d1LzJzY6SH1cl6E2WYAkQNcMrqAKaI3miye8EOx2jxW5TVFkWzUbxsA0gkTFcrbR+r1vychBK/90Hdw9oe+1bLBtar8tVRJOx+gm3Ao4xFRIel9BfP3ig3hNa95DT7zmc9g5cqVOOyww3D//ffjiiuuwNvf/nYA7MK88MILcdlll+HAAw/EgQceiMsuuwyZTAbnnnvuHB99EJK8RSl2nByJxtvhUCxRCIrRQLEj/Hm1gtQjOlPsXD/HDpouqwG1UL6eU2NEzyYJablCG4QjhYLS6HiaweA9SBvZmIRDse1OMmKg1lWbGPF3g8TZmt4BuCOw9bT//jq7E7/1W4zpgSjtm0RVLBrk2Km9LmnExNQuHD0FdR0y5z5cM4CpayggARMVkCbmrC3D2IdCsRDqbHHqPrFQQ7GuVOX3uI/dDKDmHLtNzNJTpo48kkjDamgt1W7HEjXXtaWCi3mCGknAQBXOLJh5z1fM3ys2hK985Sv4xCc+gfe85z0YHh7G4OAgLrjgAlxyySVym4suugiVSgXvec97MD4+jmOPPRY33HADOjra7L+3h6E1ybHTqQcQwAgRO6nYKcUTBm2u2EUVT9CwYqcJYhcKxXLDYpskGClE4xw7l+9jOoqdONZGE2vC1FGjBpKE7bvd4ommodgGip1ldgAW4OgZmFOEYvWY2E0fuh+KBVeDaaPQtuLIH26jNB2E1Y05d86fIapIomO2iF1o4k8scMVOVIHaU/WJhZ9aoSlVsdo8vsfVhW6j7j0AoGsEVSQBFGal+AgIKnZ1HYLmMWpIIotqpHK5r2D+XrEhdHR04Itf/CK++MUvNtyGEIJLL710j1a0zgZkgUQTxU6vI3YiL88nKGYDhUzuVw8pdmA5djIpmOiy92q4eMLlPTQdkvBDlnVVsYxkeoZQ7ELErwWIcHIjxU7XCMowkeTnJVyxNxV8xU1R7CAKH6IVO5rsBEosX6mRYqeF/AZjTAMix446kd1SAlBbLc0CsXNDfm/6Ag7FAn6+kJ6chUWspsOFJu8ZsoCtYADA0VKAC9D01P57RC4EfcUO8/geV/3j3Cl+pyq/Rhp5hraLQD7sAspRFfm1zULXCx0LJsduX4JQj8J5W4BPIKSPnbA7kcUTU4didS9IDgE/x46GQrFCqQjn63kWC8W6WgKUiHBwdEsxERoz0H4oVhSANAuF2cr6o90kXZkzE6iKbdxSDACW8UKcFQN98hyqoVxA+Z3m8Wp+vkMmqnuOnwrQYBJVe13CmPkk4oVW69oCV6VKhOXWkXT3rOxPvecWsscfAPR0MbI7sHTZlNsSXQ3FcuupBv1X5wPUnOOpck8tHnr0ZsnaJ1DEtIAWRjYnpO4sjCPzFfGsNAeQVbGh0KXrURicMBg8P46GqmLVUKzZgEhpnCypCeGeUgDhh2JVYhdU7Dzua+doCZhSsQvnmXGywz/HhAvXo9C11nM1TE4omzmXq8ab7St27Nj1CLuTRopdMse6T6SynZJgG3FV7KxDEDtCHUCaZjdoLaeGGGdhYgpPbkYrjc/nMb6f+n84oLAeq5YdOyv7c2AAaE62Fwqy2Q5gN5DsnKJPLPzUCh2u9LuczwVSaih2qtzTGkkBFMAsKXYB5W8B+UDaguDuw6HYWLGbAwj1J6zY2a4HQ5C+FkKxiYahWE5cVMWO+Ll6qgdbQ8XOFopdUip24Rw7QexEAYYJB7YbVLamglAdm+VoqD0QE+0qdpqv2FEqClA4OW60Eu87iP2/aP+GoVg94hzHaA9SHfEcENEGr8Ekqqf8ECOZBcNcL7Rabzd3c76h88iz8O3sBTh85dTkpRWIxZQNY8pK0nkPQTqm8LADgnYn2gKoilUjGFMpdqIKlM5SPlwg13VBKXb8PCwgMtou5u8Vuw/DD8XWK3YpruIZplDshN1JvY9dI8VOj6qKVexO/NwRHTrPjTBCxE50ovD0JKhYuTdoqyXyK0w4KLseUmbroQuD77uZEid60VpUR8Jo75JVFTuPAjpRFLsog2IAeOHbgOUvBvoPgz60Vb5fNbv2jaRjYjddyEmUOkrBT4MOJGmV2M3CgBwa1PUFrth95JVrcdErDm67srERHGIClBG7BX+FH/paYOxZYM0pU26qK8UT2gKofDcDil1zclXROwAH8MxZKLABgvfQAiJJDi/2o3EoNsZsQqg/eigU6zgudMLUJFkVy21KpGKnELsEceG5riQvcv+cgBkKsVP7vRJp0KvLooVwha0kdlpC2pzUKXYiVMFXazqhcGwHSLU+FSSozaqAm0ysYpKxYCLbRpgX8EMrGqGouQ50zfRz7BopdpoOLD2CvZ8TSZPwMLPOid0CqJib7/CJnSv7GzcK+6nO+eH+n9MBDRnVthvin4+YLVIH8HsOIiS7wPHCt7J/LcBfCLoLIt0icN1OQex+33UOHt+Rg95/RtPtWgYf911o0OexqhmGy0koXUAFH+0iDsXOARoVT9iOT64MM2RQTOsVOwCwrKCxMNuv6Der5NjBtyyRFZ2aIXPbzLBi5yiKncixq/OxEzl2/uBiRxxPI1BKperYrCjCUcJC7U5emhqOdkSeoghFT60s6qb/fkcxaParlxfOgDbfoKmKnawyjlbsEhlfsZsNa4Ww6mfOhybm8wiii4FDnl/XtzQkh7cgCqQCqSlThENHMgfis87/A2apwEbjxIg5JyyccH1Hji0SlyzqntsD2YOIid0cQCTyh33fXMcPrRJNELvGxRMAUKs1I3Y+KZHdIwKKnSFDUCZCnni8xRjVk1LZCrcUE/tRk1BtO9pbLwqOR5EQxK6pYsd9qJq0zGkEdSXphrp3NAzFqu9XzqH6++hxKHbGEP1ZA6HYBjmLqUyX/Ht2iF2QyBkLpCXS3oJU7KZxzy1kyN7QC0SxC3TimeK+GOhiry/pnJ1rfXkf8wVcaGkMq484CRQE+62bXx2pZhPzdymyj4JS2lCxc1RSpItQrLAa4e8JKXZ2rVL3GUYoT4/tx6+K1RSDYoN3djBDoVjCFTtqpEDdBlWx/FjUpF3HDlbXNoPleEi2oNgJR3V7Gtk+muGTN9fhhLcdxU4hGo5K7LiRdLj9UozW4XcFcWR7vUaKXVLpXzkbE4kW6mgS7nDyfIfHCZ37PFPsdKWFoE74ODGPe8VC01juMXGnbIv34TMOxskH9eG0tUtm5aNNfs8suIryE94HcvRbgNTe6w+/txErdnsZrkcbKnaeQhzAlSYRihWkioT81Oxque4zDCrChMqNrliWyOIBXZcNvhNwAKUPrTQsNvxQLKkzKPYNPB1+KbVD7GqOxz4X/iARBYdbYExHPVAVO0/kCE7hY6dCzVMUxBCIfexmA0JR1qgLfQrFLqMQO2MWSJgeCr0mUgtsctrDEIup551ip9qdCPeCeazYAX4kY6qiop5sAq/4/+2deZwT9f3/XzOTY7M35y6ryyGsRbkVBakKVUFRDqXFCtZCsVYrUqla1Kp12+qi1FqsVGv9CqWlyM/Wi3pjFbwqrMCiAkXURVDBFeRYdtlNMvP5/ZH5fPKZybFJNptr38/HIw9IMpl8JslmXnm9r0HlcGpJOu3z80sWVcQKcljUASTsUo7OZGFnc+xM4WBAEeFP4bSxCI5dmJw2kf8l5YcZciiWt1RRNWvyrS6FgoWwyxMzVUNDsWZIU9VEkrXfG4dj5/XBaf4qjhZe4x3OEwrFSjlwvMGy6CMYwy9xWbiFC8XKrzERH9yd0xDMsVMjOKBOZ3CIeTKEneoqEP/3MxUuFzmvMobKHbvO9fnmf8/ZkmMHBCMZaqoFFs+tzqKK2M4CCbsUYxhBcWbvjaabxRM6goIjWrsTAPD7wgk7s8mx1O+LD7JmRjB3RFEdVmFnBIULnx2rONwAD8eEFE8EGx3zTvV6HDl23lbJbYwS0uTCTk8gc0CxOHameODrjiHHTlE1GMx8DyTh68iSL/1MJjjVwx/MC43Si6terUQzcyOvW+92P7dDGlreCicccVZb5zpc2BmdTNjxKROawuAETw/I7L9xIexSXdmdzY5djpPZn9gcRDcMqLyliW1SA3eEdKgim0w0BxbtTqzFE7rNIdON4BeSnGMnRIws7DQNLrkxq+4FEHAyhLBz5klVsVZRKZwvRRWiKy5hJ7uNUX71GSIUm4CrIok3HorlBSix5s74ocIFXVTFGgYTotxBOXYJo0hTPbiwi9bw+cD0p7Ht6wP4Xq9e7X5uh+TYeeFEQRZV9aUC8WMqi9pYJAM5p5ZX7GdFKJZFnrfdYZBjl7F0rr/aDEDO03JCh1c3oJm/Ermwk3tH8apY2NqdNDM38pVW+G2hWJ9uwCnChPJIMXOfhl/sQ1Ed1hCU5EjxSRSqMxiKDc2xM4snVC3QFoEBhj/2UKzfrOg1oETt7m5o/CSTwBesosDPVDgUQ7y+fN1qDDl2AHdQdRi+wON9hgEnd10pFJswDotjZ55Eowjls07uA6BPUp7bKeXUeTuZKxULzBR2nc2xk0Uc77GpZnhLI0N1ATpQmF/Q9sbJJL974N+C7ql9XqJNKBSbYnSpF5qqMIvQM4RjJ4ViFWt+G3fsvKZ7pYcVdmEcO14BavhECFXVHHA5NHiZmc8nFT7w2bGKM08UGYTk2Em5eqI9QhzFE7yi1wdn9D5IWjscOwTHsvEcO77uiA2Kbejm8eum8NV1Xbiumf5rPpPhxRMaDFEhnirXQW547AO5rnZ4pbuRyI+pLEb+oSbyfzP8bzzv1Bk4VPwt9Bt2VmqfeMC5wJQlwIS7Uvu8RJtk9k+RHEQWdoDZ4sQTOJkZupljp8g5dqawYwaYFMZtgRtAI3SbkPL5/GIby7gZIc6CScGK5oDTocIHB1zQ4fO1gp9WuWOnuTxiaoViy7FTRT88VbRFsFT2tgEv/PDCiWinc8PsqJ7oSUbnwk63up6qGtvvGi60DVOEy21PHDQrNmG4O+eAHw4e9krR6+nKC7obiRTl5DrMFDPcuesshPt7znTHrvuFtwEX3pb6J9acwClXpP55iTYhxy7FMLuwk6ZNcPcunGMHw4AhOWY+7tjZiifkKln5JCnEmeEXgkxVNbg0VRQ+yH30+OxYzZkXLEAIceyCxRNBYRdHg2JzrW22VGinsDOE68kbFAdHqsUCF4bcsfN7pdeJhF3CcGGnMV04dlrKHDtZ2HUu8RILRQWB1yfP07nyp8JNksl0x44g7JCwSzF2x04uNuCiSG4KKlfF6tKsVq85yDhU2MlNjuXiCTnHjjt2TjhlYScVYvCGxQ63R4Ri7Y4db3eiqg7RFiGeHDu+9raEnWEm5/rbmIUY8fFCmFnn7cYu7ILNnQP7kaqHSdgljCaKJ/wifSBVr2eeVBXb2Xq1xUK/si6WfzsLmlQFz6HKdyLbIGGXYoxwoVjbfYYcipVCqPJjfaawM2yhWN0fOr0CgKUXndzHTVMVybEL7svBeCg2H+DVo/ZQrBTS5MUZehyhWF04dtEdk896nof/6COwoXRSzPu2PI8IxfIcu2D/vdgez3PsTGFnaSRNoiBReA6oS9FFKNaRIscuz+UQffESzd3MacwfhZEmgeQqqqqIZusccuWJbIOEXYqRXTcgmFcHACxcHzteVMAMkfwPAH7VbT7GKuy4OJObHAf2ExBeCtOl3LjA/eGEnUs4dnkRHTtVKkLgFassjlCsEHZt5fF07Ycrfb/A111PiXnfMtyx48UfIlE/RmHHhbbIgeSNpJkiBDMRP7I75xZVsakRdm6HimPg1dadS7zEBG9h0cmEHWD9/gUA1UmOHZFd0Cc2xRiG3bHzh9wXzrED00UoEQD8mvnF67MLu4D48MFhLUhQg6FYMTXBYZ0HKRdiuMQM13whAJWQyRNBgciFYzzCjodt2zqxXjziOBxt9WPKsIqY9215HlH8YLY74b0AEyyekPsNkqxLHIck4lyKWcmdogkQiqKglYRdZE6eAnz2NjD0++leScqxCzty7Ihsg4RdimF+q7CTiw248DAsg7d5jp21eMIwhZ09py3c9AoAUrsTKRRr3uYXzYXNECNjcCOwH6fLExSFkRoUqw5R2MD02HPsDNOxa6s/XYnHibnfGRDzfu3oihrosWfYq2LjcOxYMMeOv2d+RQN95SeOI0wPwGh97JJNqxIQlrpKnfNDKBsEzH4u3atIC7rt55pGOXZElkGGQ4qxO3ZyTlwwx04qnlCCDYqZHirsYBd2wrGznTTVYCg2OAORD/rm+XHmvqTwsNOdJxw7Ps9T7FKEYtWgsLMJ12hwEdjRJ1bRMsZILMcuGIq1Fk8kMuKMCBLOnXOmcCySVzELkChPkpDQFRJ2RHZDwi7F6H77fFgpEV/njl344gm5otZwmJ3zdWvok4dTdftUBSmcKtqdmEURvKJVhGKlfbrceUG3z+bYiQkOmuzYxR6KZTwfsINDYSIUawpjEYrWYvv4G/aqWNGWhv582oMjTBuJcC5eR8GbfBsJVlsTuYkc7dCZAi3G0YMEkSnQmSnFMJtjJwsh7gixMO1OwAyR/K8zRXSGhx7esfPbHTspV084dg6rY2fwx0q98Fxuj8Xtkwm2DVHBuOsRh7CDP/A8Hd0E1bBN7wjm2MX2S1wXjp0pvMP0GyTiR9NU+Jgtn8mVOpHFK8tZJywQICJjSH/XfmhQaI4wkWWQsEsxhh7ZseMizzJ4Ww0KMsMICCkDqmjaq9iEVLAXnvWEqWhcnPmh8Tmn5i9Rw9Zc2Oc1R30xDW6XQ+SiqTZhx/ejKJoQdnE5dmbo1+jgSkjDFoqVGzTHgnBNeag8zIQQIjH8NnHsTGEzWF5ZLtIaCAI2x45+vBFZCAm7FGPPseOD5QNXzPvCjBSDYQSFBVTATDJXbI5dUNiFd+wCOXY8hGo2FebNhU3B4msN7NMHB1yaGgzjRiqe0DQxggh67Dl2MNfa4Y6dbaSYlkjxBABmmLl1vMiFvvTbjSzsWpkDaozh8aQ8t8pbelAolggi/2CjdAsiG6FPbYphUfvYmcJNlYsneChWh246djpUwBHesePFGNbKWgDcsTNkYWfm2JluGw/FBme4OqCpSrDdiX3yBIKTJ3ijXvt6oqKbId+Oduz4F7UtFKvEmDtj2Bw7kWtnf42JuPFLr6HdvetofFpg+gSfbEIQgPRjGuTKE9kJnZlSjG5YJzPI0yS4IyTn2HGnjTFDhBIZFCgRhB3jPdZs+WN83qti+KAqAWHjsDl2PIzKR4v54Ajkl4gwrt2x49W1qphyoRjxF0+oHdzigtmqWjVpYkYs2IWdqI4lx67d6JZ8ptR+Hb3bZRKOHdmP3T3G4zspfWYik9HN9kZA0O0niGyCPrUphulWccQsVbGmcLOIMt7uxBChRB2qEHaaYc+xM/PW7G6SKU5USVgq5sBrwzY1ghdP+EzBp5rr4UKOo8kzV0UxR+yhWF6Fq7k9MT8mEew5dorUfy8WRPNl3kDaH1q9TCSGRdil2AHdVzQEV/tuwLHC3il9XiKzMSjHjshySNilGGab3iAXGwhHTq6K5a6SESyeYIoCxXS5VLuw08M1OQ6GHeXtHZpN2HHHzmeO+jIdlIihWCaFYvlsSSP2WbG8Ktbp6lhhx0RVrFk0knCOHXfsSNglC2soNrXCbsyA7ih0OzCyb+cadE9Ex5pjR3/jRPZBodgUw2yOFhcJgStmKFZ2kpSgYyeEBTSozkBekN2x466bYWu6yqtiHSy4vWo6dvz5mLkWPjPWbzp2IoxrC8VacvVEKDZ2YccbFDs6uCmt3O6EMQZN4Q2KY/tdY6+KFSFZEnbtJp2O3fdOPR7TRhwHVaV2FkQQ+e+acuyIbIQcuxQT6thJQo9XxcrFE5CFXTAUq0YIxbJIjp25T4ckvHiOnahK5RW1PMeOh2JNt0+L1MdO06CY+7I7iNFw+ZsAAM78kpgfkwgMQceNu54AYm48Kub16jbHjn4XtRu5ACUdkzxI1BF25FAsVb4T2QgJuxRjb3ciN/RVwuXYiRmvwRw7BgUad+yY1SETws7WQoQLO0127EwXL9iqxBR2fj69gjt2ZigW9uIJHorVoIhQbOw5dgV6IwDAVdg15sckApMcO12uSo5xVJBwNA1y7JKNJZ+JqoyJDIBJI8Wo3QmRjdCnNsXYQ7FMD9PHzhKKDU6e4EPsDahQzfClI8Sx473hwrc7cUpCkAu24NQIUxTaQ7HcjZMdO8ZEda2qaqJliRpjKLbVr6MYRwEAecXdY3pMogRz5HRLFbIWZ44df3+4ODdifDwRGVnMpToUSxDhkKMd9OONyEayStj17dsXiqKEXObOnQsAYIyhuroaFRUV8Hg8GDduHLZu3ZrmVVsJDcWGE3bB/DgmjQLjyf8MKhymY+ewOXZcnDFbjh0vFODb+5kaFI2iotXMz+MzXG2OnVwVK49GU1QNmpmvp9rXE4HGFj9KldQIO/4aKoZfiGMAsTfD5V/0/Jj9vC0Nfem3F/nEGVLJTRBpgFk+k/Q3TmQfWSXsamtrsXfvXnFZs2YNAGD69OkAgEWLFuH+++/HkiVLUFtbi/LycowfPx6NjY3pXLYFu7BD2Bw76ctEKp4QTpGiQjNnajojCDuEFE8ErjvB88Okt56HYkU7DzMUa4ZzeY6dKhVPyI2WNc0h8vQ0FlsotrHFj2IEcuy0/I6tSuShFcPQrcIuVsdOtQq7cNXLRGKQY0dkGpYfG5RjR2QhWSXsevTogfLycnF57rnn0L9/f4wdOxaMMSxevBi33XYbpk2bhsGDB2P58uVobm7GypUr0710QYhjJzlfKhdF8rxMU5QozACkWbEaD8UivLAzbDM3eY4dF4J6GGHHmwvzxsG8slYx/1WlHDvdLpC0+ITdkaZmFCuBmbTwdLSwC06e0HW5eCJGISGEnZnjKAQ2CZH2Yg17pW5OLEFEghw7Ittpt7Dbv38/nn/+eaxevRp79+5Nxppiwuv1YsWKFZgzZw4URUF9fT327duHCRMmiG3cbjfGjh2Ld955J2Xragt7jh3azLGTHbtg8QQPxdodO9FuxJZjxytAXeDjsIJfWKLwgYdxeRGFKej4Y+VQrC4dh6IFZ9eGhIYjcOzIN8EreR1cFSvl2EEW0jE6dsyWYyfanlCOXbthFmFHQplIPyTsiGynXd+kTz75JK688kqceOKJ8Pl82LFjB/70pz/hRz/6UbLWF5FnnnkGhw4dwuzZswEA+/btAwCUlZVZtisrK8Nnn30WdV9HjhyxXHe73XC7O2Z+aUgoVp4EYUR27MAMEf40FA3uvEBTXy7UBFwoarYxXbx4IkoolovCoGNnCr6woVir88VdvVgdu9bGAwCAZiUf+bE6ZwkiWsYYOnS/JOxibHcSybGjUGz7kUOxRoyTQAiiIzFI2BFZTlyO3dGjRy3Xf/3rX2PDhg3YsGEDNm/ejH/+85+47bbbkrrASDz22GOYOHEiKioqLLcrirUvFWMs5DY7lZWVKCkpEZeFCxcmfb3BBVmFj6KHhmIVS46dVDzBgo6dkzt28IGZEyAAybGziSXe2sSthJlzKqZYmKKPV9ZqPMcueihW0xxi7qpqa4kSCd/RgLBr0opj2r49CGeN6TAkcaooMTYo5u1ezNdHOJvk2LUbuXrb3lSbINIBoxw7IsuJS9ideuqpePbZZ8V1h8OBhoYGcf2rr76Cy9WxA90B4LPPPsOrr76KH//4x+K28vJyAEHnjtPQ0BDi4tnZs2cPDh8+LC633npr8hdtEppjF+rYKbLbJuXYMandidMdEHZuxQ+fX9qnEb54wj4XVXbsFM1teX6I6RXW4glNCsXKbUMUVRUFH/bpFJHwNwVCsS2pEHYiFBt0PXWmBKuC24K/dszu2NGXfnsxKBRLZBjyjw36GyeykbiE3csvv4xHHnkEl1xyCb788ks88MAD+P73v4/y8nJ0794dt9xyCx566KGOWqtg2bJl6NmzJy666CJxW79+/VBeXi4qZYFAHt66deswZsyYqPsrLi62XDoqDAtAhPM48gguPotV0SLl2JnFE4oGlzs4X7W19Zj4P3fdFFsolo8P48iOHXfzeKsShTdN5k4dv19y4+SiD03Vwm4TDdZ8MLB2ZyqEHRfHunAa42o8ykeq8WPmIVlymNqNHH5lasf/KCSItpDFHAk7IhuJ6ydy37598cILL2DlypUYO3Ysrr/+enz88cf4+OOPoes6Bg4ciLy8Dp77aRhYtmwZZs2aBYckVhRFwfz581FTU4OqqipUVVWhpqYG+fn5mDlzZoeuKR6YYRU+SpiqWEUWDLITJhVPuNzB19nX2gIUFln3Z6+KtYVmDSkMqYjxZKbINGe48hMtLzKQc+x4danOFGiaKuau2qdTRIIdOwQA8Ls6tnACQDCcbfiDhQ8JCDvu2IkCDPrSbz/ySZRy7IgMgBw7IttJqCp25syZIq9u3LhxMAwDw4cP73BRBwCvvvoqdu/ejTlz5oTct2DBAsyfPx/XXnstRo4ciS+++AKvvPIKioqKOnxdMWNEqGKFFIqV3TVp8gQPxTIlOCsWAHzeMI6dw+p+aDahZ3HseI6dzbHj++A5dg5Lg+Kg86UoiminotrmyUZCbT0UeHxeaUzbtwt58oQRyEeMz7ELNjgOPDjM6DciIeS8OqaRA0pkANKPXpouQ2QjcZ+ZXnzxRWzbtg3Dhg3DY489hrVr12LmzJm48MIL8Zvf/AYej6ftnbSDCRMmWIoFZBRFQXV1Naqrqzt0De0humNnhmJlx04UT8jtTlRAVeFlDrgUf8Cx45tzcWY7Sao2x06eh6g6zR50wrHjBRimkyfanQTXzpslc+dLDbNNNBymsGMpEHbiWA09mB+HOIa/i1Asd+x4HiN96bcbTXZHSNgR6UeudqfKdyIbicuxW7BgAWbPno3a2lpcffXV+O1vf4tx48Zh8+bNcLvdGD58OF588cWOWmtuYHe05Ea/LIxjx90iGCIHj4dRveaJ0O8NCjtNuH62HDub0JOLJ7j7x59f5Y2KuWPnCM2fM3RrrpoSJlwbDZcv0GJG7eDmxIEnkapiudMYY0UsEGzurPD3h7+H5Ni1G7lgghw7IiOQfrBRuxMiG4lL2C1duhQvvPACVq1ahdraWvz9738HALhcLtx111146qmncPfdd3fIQnMGW/GEPFuVO3ayCFOkqlhePMHzPnwIbBfOsbMLOc3Ws00u49ecvLmwKVx0awEG35cGQ7ilhlShCwSrbmN17PL8prAr6BrT9u1BnjzBpDzFmBHCzpZjR8UT7ceST0qvJ5F+LCkWJOyILCQuYZefn4/6+noAgRYh9py6QYMG4a233kre6nIQe7sTORSrmc2GLWFTNVgVC5so8ZmOnU9y7FRzfw6ntbJXddgcO8mx0hx8HJgpCg2eY2eGYs1fsA7FEDlqolmyuZZ4Q7EePSDsnIUdL+ws4Wydj2WL/QtbCQnFUo5d0lDJsSMyDEulNgk7IvuIS9gtXLgQP/zhD1FRUYGxY8fit7/9bUetK2eRhRwgzYeFlGPXRh87njPmVwLb+Vqag/sw8780u7ALqYoN49jBGorl4VzNKQ1qNwsH7I6dEqdjV2g0AgDcRd1i2r49iAbDLJhjZ8Tj2GnWUCwXzwoJu/Yjfy5J2BGZgKVBPP2NE9lHXJ/ayy+/HBdccAE+/fRTVFVVobS0tIOWlbswWw6aKjt2IhQbGgqwhGJNMeUzhZ3fGxR2XDg6XVZhZx94b1iqYgPbOoRw8VluV6UQGc+tE82SFVvxRAw5dowxFLGjgAJ4ijte2InX0PAHewHG8ZsmpOKXcuyShtwL0N57kSDSgqUFDzl2RPYR95mpW7du6NYtBSfjHIWH81rhhBs+4QIBUo6dFDZV5FAsn3zAc+zUPEAH/FKDYo35AQUhE0A0R2THjodteShYY15zHebtjuC2uu4D4BECjztfongiBseuqdWPEjQBAPJLerS5fbtRg6HYRHLsFFuOnSiiiHXWLBEZOa+ug2cGE0QsWPrY0Y83IgtJqI8d0Q6EsON5baE5dppU0SqKJ2CIVikiFKsGhJfeGnDsGGNwmKLM6bLmP9pz7OR2Jw7T3XPy5zddP5ULPumEq/t4KJaHNE03TOVjx9oWdkcbD8GpBF6HvBQ6doGq2OD0jpgf7rA6dlycU05YErDkk5JjR6QfhRoUE1kOCbtUY4oDHkZVLcKOO3bhQ7GMWXPsdC3QM9AwQ7E+nSEPAWHn8hRantYeipW/sJxmjp0LfoCxoGMnhJ0UiuWixhbSjGekWPPhAwAALxxQnPltbt9eFNFgOLE+dsFQLG93Ygpf+jXfbuSJKPbeiwSRFuTwK/2NE1kICbtUw4Wd2arEIuzM+zQ510jqYwe5QTEA3WwgbPgCodhjPh15Chd2VsEULRRrKbQw/HAwawGGnPPn95s97mzFE1ocwu7Y4f0AgEalKDhZowNhSmgoNq4cO83q2Im8SPrSbz9yjp2DHDsiA5CbZlOOHZGFxCXsfvnLX2LDhg0dtZbOgSksfHwOq9SwmDt2mm0GLsBnxZqiyXTsDEcg3MpMx67Fp8ODwJxXp7vA8rQO20lTnpXqdEvCTveKIgrNaYZz1eC2os2JbnW+eL5ZLKFY79GAY3dUTdGoN6kqNpgbGI+wc4rHW/6lnLB2I7t05NgRGYH0o1ehUCyRhcQl7Pbu3YtJkyahV69e+MlPfoLnn38era2tHbW2nISLAt6qRM6xc4TJsQuKktB2J8xhjm/jjp1Xh8cMxSouq2On2n55yr9Enc5gPp7u98IpHLvgOvzMzOvjgs5WFcsdOw3BXneR8JnC7piWWmEXKECx5inG9HDRysV07MI0kiYSwyLsyLEjMgBLGyNy5YksJC5ht2zZMnz11Vd44oknUFpaihtvvBHdu3fHtGnT8Ne//hX79+/vqHXmDlzYmYUPXNgZBhNul2apig0nSsyh9qZjB3+gQfExrx8eMxQLW+6aveeaNccu+Hw+byscCAg7uQBDN4skGBd2fLyZebs8eUKPMMtX7Kv5IACg1VEcdbtkoVj62LU/FCsmUJCwaz/Sa6iSsCMyAY2EHZHdxJ1jpygKzjrrLCxatAj/+9//sGHDBowePRqPPvoojjvuOJx99tm477778MUXX3TEerMexQynBoWdGZo1DFGVaqlgNcOgKuR2J+bbZgo7xXTsWqVGxXB6rE+sqtBZMJ9NzrFzOjS0ssAXmN/bKtbhkHrh8dmqunDsuMjkkydM5w4G9DYcOxwLCDufqyT6dkkiOMdWD3E9Y4HnGIo+g7yIgr70242cv0kOKJEJkGNHZDvtLp446aSTsGDBArz99tv4/PPPMWvWLLz55pt4/PHHk7G+3IPxIfRmKNYUUbrk2DkkB00VVbEsVNiZrpyqBxw7b8vR4PM4bMIOgC6/3bKw01T4TefN72sNhmIlx447XKKqlE+gsFfFKky0FImEcuxQ4LlcpVG3Sxpyjl0Cjl2w4tfMgeRVsQ760m8vclNi1UmOHZF+FHLsiCwnqZ/aHj164Morr8SVV16ZzN3mFmY41dB4jp3p2OkMeaJ4IsxIMejCJeOiTHUFxJuqBxw737FA018fHHCGSewPhFOtTY4BQFMV+OAA0Aq/t0X0mAsXitX9VsfOLuwA7upFdl+01kOBx+alyLGTqmIhpnfE0e7EdJKCjp35Lw2tbzeyS6dq7ihbEkRqUKT8Y2pCTmQj1O4kxfAwnmGexBwWxy4gGByWUGyoY8ffNtUskND0QAGLryUg7LxK+BOkLo/KsVV7+UyNr0uunzOMY2fYiieYKJ4I7s/wByt9w+HwHg78x9Ml6nZJI5xjF0e1mwjF8uIJ8KpYEnbtRZE+65qTXk8i/ZBjR2Q7JOxSjCIcOz7Gyyym8OtwKIH75CRyVQ1OnhB97HjenenYaWYo1m9OoPCq4YWdHH6092fym8OuW5uPiNuc7jChWN10vCL0sQMAXZp/Gw63L/AcSn7XqNslDTESzJDEceyOnRrJsaNQbLuxOHYOcuyI9CPn2CnUx47IQhISdnv27En2OjoPvJpUC4gmLux8fl9wGzkUIBL/g1WxPDyrmY6dwwg4dv5WMxSrWMeJcXg4NbAPm7AzQ6deSdi53WFCsUZgnfbxZnIolveKi4RHDzyHsyA1ws5aPBH/SDEu4ELbnZCway+yOLb3WiSIdGBx4indgshCEhJ2AwcOxB133IGmpqZkryfn4a0yGA/F8tCszxvcSA1tdxJw7KztThx5AWHnNIWdYTp2fi2SsJMcO7uwMx0737HGwL9Mg1M66fJ+dcF2J9ZZsbJQ5OHaSOTrgedwFaZW2ClyZXEcjh1vPyMaSHOBR6HYdqNS8QSRYaiWMXfk2BHZR0LCbs2aNXjllVdQVVWFZcuWJXtNOQ0PxfJWJQ7u2OmyYyfPipUmT9gcOz5dwsUCoVjdG13YGbJjZwsx6DzHjgs7OKCpUnsUkWNnCiP+Lx8JJu1Pb0PYFbLAc7iLukfdLlnIjp1hE8cxPV6zCTs++s1Jjl170SjHjsgwrO1O6DNJZB8JCbsxY8Zg/fr1uOeee/CrX/0KI0aMwNq1a5O8tNxEjBAz84kcigEwBt0nCTu5Gz/PD0NouxNHHhd25vxWU9jpWmirEyDougX2Ed6x01sCostrK5jmoUvDsDYoZsKxC+47aihW96EAASGaX9ot8nZJRG5QLPIU45hRKxw7U1grpluZ5wovoInYkYsnHE7KsSPSj2LprUg/3ojso13FEz/84Q/x0UcfYfLkybjoootwySWX4OOPP07W2nISMWdUShRnuhe6XwrFSiJJUaTiCS4KTZHlMkOxLhYIxTJvoO2JETEUG8WxUwInWKM1UBXrU6y/VIPFE6YbJ3LVVL5Q0QCZRSme8Dd9I/5fUJwiYacFiydENW8cH31eGOKADp9uBJpFA8jPIyHSXjTp70AjYUdkAJZQLFXFEllIu6tiGWOYMGECfvKTn2D16tUYPHgwbrzxRjQ2NiZjfTkHD8Uq0nxWv88Lwyye8MEhwq+AFEZEaCjWZTp2efAGpj34Ao6dGDVmw1IwYHPsdP4F5g0IO3+IY2cLxRpcZEpOHQ/XGpEdu6bDgTmxR5gHRfmpOZEr0vQOe9FHLPC+ghp0NLX6xWSOPDflhLUXTS6eoBw7IgNQLDl2JOyI7COhT+2f//xn1NbWora2Ftu3b4emaRg6dCjmzp2L4cOH4x//+AdOPvlkPP300xg5cmSy15zViDmjFmHng24KOx2qpbUvH9WlMEOMI+NuW56nMPAvvGjx6YDfdOzCTJ0ArDl2TLULN/NZvbyy1u7YmbNiDauwk1uo6IoKJ/Soodjm5maUAPDChWItNd12LKFYEc5OoI+dwtB4zItSBBxSp6coySvtfKgUiiUyDM3i2FHxBJF9JCTs7r77bowePRqzZs3C6NGjMXLkSLjdwS/lOXPmoKamBrNnz8aHH36YtMXmAgp4rzqplYi/VYRi7U6ZmDIhOXZMOHaBUKxH8WK/1w/VnBkbMifWxOLY2b6wDDPHTvUFhJ1uE3ZcCDFe5MFCixAC4s8XNRTb6vWa+0/dF6ZiJkBbHLs4qmLlhtGNTU2oVMzXOUWTM3IZecoKOXZEJiC3OyHHjshGEvrUxtLH7sorr8Qdd9yRyO5zGlVUVDqhMwWawuD3+USLEHt/NVXjwi5YPMHz7lR3vtiu5VgTFLNRMZ8ha0cunrCHYg1T/GimsPPDLuysYVYWpgiBu3d6FMeOC1g9udPsomLtBZiAYydVvzYf+jp4h7s4OQvsxGiSmHO6yLEj0o9GxRNElpNQLOytt97Cli1bom7Ts2dPvPbaawktKpcRwk5zCHfO7w/m2PlhFRyieIIZwTAuFyVSyLX1WJOYQKG4Igi7KMUTXNg5dLOyVo1QPMHz5+xVsQj2yYvWx04cZyodOy3Yxy6RHDvZsTt2OCDsWuAGqKFuu9EKe6LO6I//6CMsfRMJIl1Yq2Kp3QmRfSQk7ObNm4eNGzeG3P7RRx/h8OHAHFBFUTB27Nj2rS4H4aFYRdXgM0WR4fcJwWN37KzFE4zfGPhXcwgh6G1pgqYHQoRqBGHHLNW24YWd0xR2fnuOnQjF8lmxoQIpRPyFwdBT79hpZj6hxnRJHMdTPBF8LbyN+wEAzWph8hbYiSkpyMNsbSGqi35l6ZtIEOlCo1AskeUkJOx27NgRVrS9/vrrmDFjRrsXlcuovCpWEmW6zysVT1i/SFQxNYEFRYnktrUgEL5qPdYEh+nYRRJ2FtFo+8JiprBzRXDsRI5dSChWzrELdew+bmjEkZZgjz4uYHUlhV+YIpwtjRSLp92JVGjiP2o6dhoJu2SQ59Tw6o3j8Nx1Z6V7KQQBwDrmjhw7IhtJSNgVFxfjm2++Cbn9rLPOwoYNG9q9qFxG9LFTHMFpD/5gwUGoYye16mChLplPCYQDfS1NcBoBYedwRxJ28kQLu2MX2I/bMCtrFWuYkT+nPRQrt2YRY8dM8bT7QDPOu/8NXPP3oLsbyZnsSFSL65mAY6ep8DNz+6ZAu5ZWBwm7ZNG90I2SfDqBEpmB7NipNFKMyEISEnZTpkzBfffdF7ozVYXX6w3zCIKjiqpYTeSZGX4vDLOowFDCO3YqjGAPPEmUeNVAda2/tVnMjI0k7CyhWHuIwXSl8lhA2IXk2HEhxiteozl25n1fHg7s6/ODx4Lb6GkQdpYGxbwXYBwjxRRFNHdWjgV+0Pic1OqEIHIRuWBCpQbFRBaSkLCrqanBm2++ifPOOw/vv/8+AKClpQX33nsvhg4dmtQF5hq8eEJRNSEWdH/kqliECcXKvZV8SiAU629thpNxYVcQ9rlZlHYnzPyV6jHHfTF7KDakj12oe8jEdIrANroRyAn064bYJh2hWN49Xnbs4imeAAC/eWyO1kOB606qiCWIXEQOxcoj7wgiW0hI2HXv3h3//e9/4XK5MHz4cHg8HhQVFeHf//43fve73yV7jTmFKoonHELcGH4vGC8qCHHsAm+RBgOKWTwhixK/GhR2bsYb54YXdrJoDBmVY4Zineage0OzVXyqPMxqOnZhQprBUGxgG79u4EfaizjJv11sw4/T7kx2JKLBcIRwdixwEe7yHgQAGNTqhCByErndiUaV2kQWkvCntk+fPnjhhRewZ88ebN68GU6nE6NGjULXrl2Tub6cQ4RiZcdO9wrHzt5fjed4BMKwoY6d35wL23qsCR5zIgIfNWaHRRkpZm/dYXfsDPOjwh07JUy7k2DxROC+/AMf4k7n3/E/vS+A68z7eCg2lcIumKeohBmFFgu8obLHdyhwAwk7gshJ5Cp4japiiSwkIcdO13U88sgj+PnPf44nnngCBQUFOP300ztc1H3xxRf4wQ9+gG7duiE/Px/Dhw+3tF1hjKG6uhoVFRXweDwYN24ctm7d2qFripdgVawm3Dnm94k2InbBo4jJE0zk2MlhVEMLOHbeY0eRpwTcMJcnfGI/k/Ztz7FjtuovplmbxTLTsRO5dUaoeygKLFjgWBRvYF5wAWsObuNPvbBTpHYniTt2ge0L9EA7H3ho6gRB5CKW4gnqVUlkIQn3sbvjjjvQ0NCAW2+9FRdddBF69uyJ3r17Y8qUKcleIwDg4MGD+Pa3vw2n04kXX3wR27Ztw+9//3uUlpaKbRYtWoT7778fS5YsQW1tLcrLyzF+/Hg0NjZ2yJoSQTh2mjNYFav7xKiuyJMngsUTstuka4Emxa0tzcKxiyXHzj4DUbXn1Gn2qlhrjp0IxapSKJbn4ZmOHf/XCalhcRocO/6rW4UhhGncjp15bEVG4LOkerokb4EEQWQMmpMcOyK7SUjYPfXUU/j73/+Of/zjH3C73Xjvvffwxz/+ES0tLejTp0+y1wgAuPfee1FZWYlly5bh9NNPR9++fXHuueeif//+AAJu3eLFi3Hbbbdh2rRpGDx4MJYvX47m5masXLmyQ9aUCKoZTlU1VYT3mNTuxB4CDbY7CV88YZgzZ/0tzfDArEh25iEcLFqOnf2XqT3HTlTF6pZ/LaFY+9gx04V0SMLOEMeZQsfOFMeaRRzHV5XLRWspjgAAHPmlSVsfQRCZg8MRObJBENlAQsLu6NGjOPnkkwEATqcTmqZh7ty5uPXWW5GXF15UtJfVq1dj5MiRmD59Onr27IkRI0bg0UcfFffX19dj3759mDBhgrjN7XZj7NixeOeddzpkTYmghSmeYLpPOFkhOXaWis5A+FNudwJT2OmtTfAoXNhFaHciCULF3p/JLuQiOHai3YkIC4dWxXLRx0WcAzoYn5rBHbsUCjtNcj1ZglWxXIQXKGYeY0Fp8hZIEETGoGpOGCzQn1OeZUwQ2UJCwu6EE07Al19+CQA47rjj8MUXXwAAJk+ejBUrViRvdRKffvopHn74YVRVVeHll1/GNddcg5/97Gf429/+BgDYt28fAKCsrMzyuLKyMnFfJI4cOWK5tLa2dsgxAMEcO1XTRDjSkHPsVHtVbFCUcLdPzrFjzkAo1uk9HHyQMzhDViaaY6e05djx52TWUGy4PnYiXGsKOyf88OlmTp4QsKksngi4oJHC2bGg22b4ugspFEsQuYhD07BEn4rl/vHQCrqnezkEETcJCbvp06fjpZdeAgCMGzcOS5cuBQBs27YNx44di/bQhDEMA6eccgpqamowYsQIXH311bjqqqvw8MMPW7ZTFOu8ScZYyG12KisrUVJSIi4LFy5M+vo5wapYpzR/NejYwV48Yc7P1BQmXDI5FKs4AiIuz38o+CBHeGEnhx/tjp19dI5d6NknTyhGqECy5+EZetCx8/PtubBLoWMXrt1JvMLOnvuYV0TV3wSRi6iqgiOjb8YHw+5A1wJy7IjsI6Gz6x133CH+/4tf/AKnn346evTogSNHjuDKK69M2uJkevXqJcK/nJNOOglPPvkkAKC8vBxAwLnr1auX2KahoSHExbOzZ88eFBcH21e43e4oW7ePYI5d0LFjui8ohmyCR07eDduqw3TnCvQjgAb44IAzQl6ILKbsHdUVh9t23S7szOkNUfrYifBmiGOno8V07BAhl7Aj4a6nQwkWTzA1sRw7jqeYhB1B5Cq3Tzq57Y0IIkOJ27HTdR1PPvmkqDTt3bs3tm7divvvvx9PPfUUHnrooaQvEgC+/e1vY8eOHZbbPvroI1Gs0a9fP5SXl2PNmjXifq/Xi3Xr1mHMmDFR911cXGy5dKSw4zl2muYQIi7g2Jn5cTbBIbtzGvOZt0kCzRUQdl2UowCAViVKjqMaORSr2Tus24SeyKXjzhtCixCCxROmeDP/VRUGn890JNPo2AUWZwrTOIsndNv2bsqxIwiCIDKQuM+umqbhBz/4AbZu3YqiosC8zG7duuGKK65I+uJkfv7zn2PMmDGoqanBpZdeig0bNuAvf/kL/vKXvwAIhGDnz5+PmpoaVFVVoaqqCjU1NcjPz8fMmTM7dG2xwhiDCrMAwubYiZw1e46d3AVdVMUG9bjqChRKdEFAaPvUKKLUEoq1OXZOu2Nn249iy7EzQtudhIwdM9udAIDf1wogPyis0iTsFBHyTjwU64UDrgh5jARBEASRThI6u55++umor6/HCSeckOz1ROS0007D008/jVtvvRW/+c1v0K9fPyxevBiXX3652GbBggU4duwYrr32Whw8eBCjRo3CK6+8IgRoujFYIN8MADTVIcKRTPfD5w0UbGi2EKiqBvMDVd74VxIlGhd2pmPnUyM7dtaqWLtjZ3veEMfO3N4UZopo9CsVcthCsWL8GAC/13QkDe7YpS4U63BIx20kKOykUOxRFKBrG3mbBEEQBJEOEhJ2P/vZz/DLX/4S//rXv1BZWZnsNUVk0qRJmDRpUsT7FUVBdXU1qqurU7ameNANFpwV63AEm/QaPnhN4eNyWgWPKokxlbtlsouXFxB2JWgCEJwdGxY5hGsvnrAJOc3ZhmMXpgghWDxh3mcEHTvdz4VdGhw7Vc5TbL9j16wWgjLsCIIgiEwkobPr9OnTAQCDBg3ClClTMG7cOIwYMQJDhgyBy0VVRJHQDQanlGMnwq66D15fQPg4XVZBZQnFguesBUWJ051v3hYI8fLZsWGRxIm9eMLerymkfxMXmFy0RSmesLc7AQDdF3AkRShUS51jJ+cPBoVdnMUT0vYtWvjJHgRBEASRbhISdvX19airq8OWLVtQV1eHhQsXYteuXdA0DQMHDsT777+f7HXmBDpj8CiSsFOCws7nDQgOt8seig0KJwfjbldQZDht48MMLUrul8Wxs+Xy2Rw61Ta9grtxCg8HszA99WxNjJnk2PnNGbGKOIYUVsVK7qQqHMP4HDtmEXaZEdonCIIgCDsJCbs+ffqgT58+mDp1qritsbERdXV1JOqioEvFBKpUFQvDHyguUEJbrWiaXBVriipZ2OVZp0zojmhVsVJI0lZ967Dl2Nlz7vj2ouUKnyQRJcdOduwMMxQr2qWkcFSPpYqYJerYBffhc5KwIwiCIDKThM6u33zzDbp2tWYZFRUV4ayzzsJZZ52VlIXlIobpWgFmfzqVT57wBpr5OoA8t11QhYZi5eIJl8fq2LFIzYlha51ia2/isDl2mssmEMXkCTNH0Ajj2MFeOSsVT/iswi5kVm1HoigwmAJVYVATzrEjYUcQBEFkPgmdXbt3747jjz8ew4YNs1yqqqranPLQmdH1oNBRNVWEI1tbW1GsNAMAXJ5i64Ok11MzK2rlilZ3XuzCzlIVa3fsXG0JO/M5ecsVhCmeUO05dkGH0vCbOXbCsUtdKBYAdKhQoUu9AONz7Cyj01zFUbYkCIIgiPSRkLDbtm0b6urqsHnzZtTW1uKRRx7BN998A4/Hg0GDBmH9+vXJXmdOYEihWEUNFk+0er3ohQMAALX0+JDH+ZkKh2LAwXRAsTp2Drc1FAun7bqExf0LceysTqEzQlWsYpsVG9WxY1JVrNmgWLRsSbGwC8yx1aGJBsVx5tjJx+kmYUcQBEFkJgkJu4EDB2LgwIG47LLLAAQa77700kuYN28ezj333KQuMJeQHTuoDuFa+Xyt6KcEhB1KQoWdgYBr50Rojp3isgo5xRnb5Al7uxO7Y+ewOXYix447djwkK+eqqfYcO8mx022h2FQ7dqaQU1mixRPSn0peSbKWRRAEQRBJJe6RYuFQFAUTJ07EihUr8OWXXyZjlzmJIQs7RROOnd/rRQUXdsXHhTyOmW+TQ5ozK7AXS8To2Kk2YWV36OxCj4dihaDjfezUaH3s5OIJ7tilvt0JEAjFAtJYtnY4doqnNGnrIgiCIIhkkpCwM8S8UCujR4/G2rVr27OenMaQHCyomsixK/R/gzzFFDzFFSGP04WwC3Xs7EJOtYdmZTRZ2EV37Jwhjl1gDcJxi9LHTuThScfLzKpY3mRZtc+m7WD45Aiep2ifydsWco6dI780WcsiCIIgiKSSUCi2sLAQgwcPxvDhwzFs2DAMHz4c3/rWt7BhwwYcPXo02WvMGbhrZUCBqijCtarEVwCARkdXFNlHeQFgZihWM5sQW4Sd5oQOFRpvfOyK3DzXMsXCVpVqb4xsF3ZcFArHjk/QkNdiy8NjTGpQrFtz7NQU9rEDeI4d4Eiw3Yk8w9dZUJqsZREEQRBEUklI2D311FPYsmULtmzZgj/96U/YuXMnDMOAoij47W9/m+w15gw8FBuo0IQIbx6vfA0AOOouR7hGGrotbKhaxJQCL1zwoAUAoEVz7CzFEzZhZ+tb53RHyLHjjpcYKRauQXEYx87HHTvT8Uu5Y8dDsdz1TDzHzlXYJXkLIwiCIIgkkpCwu+CCC3DBBReI6y0tLfjkk0/QrVs3lJeXJ21xuYZuCh0uMnjbErcSEBst+eFfO+7YcRTNKkq8qhseIyDsHHlRcuwsoVjb5AlNhZc54DLX4goJxZqOnWErnrCITB6K5Xl4QceO6bZQbFqqYoPh7Pgdu+D2eUUk7AiCIIjMJCFh99Zbb6GoqAjDhg0DAOTl5WHQoEFJXVguEnTsTJFgEzf+wtD8OiBYPMGxN/f1KcEwqsMdWyjW3u4EAHxwwAU/fEyD05aDF3TsrMUTFudLtTp2kHIxDTMUyx2zlOfYKSrA5DzFONNLJccuv6h7MpdGEARBEEkjoeKJefPmYePGjSG3f/TRRzh8+HC7F5WrMD0gdIKOnU3chGl1AgSLJziqTZT41KC75sqLMqBeej4tzEgvv+li+cLofS7sVFu7ExYuFCu2kRw7v13YWUO/HQ1/zZ0swckX5vH7mYqCIupjRxAEQWQmCQm7HTt2YOzYsSG3v/7665gxY0a7F5WrGAYvnuDCzipuHF0qwz4uJBRrq+jU1aBjZx8xZnmcPHfWESpsfDD76ilhhJ0pCkUolU/BCFc8YdjGjgGA4bM8PuV97EyXlLeMQbwTUkwh2Ih85LtSOA6NIAiCIOIgIWFXXFyMb775JuT2s846Cxs2bGj3onIVPnlCCDuba5TXvXf4x4U4djZhp8mOXWHE55crYcM6dqZTxwWeTLBBsTUUa1mLanfs5HYnpmNnhkLDCcuOhLdiCdfkOabHm6/dURRAVWlsHkEQBJGZJCTspkyZgvvuuy90Z6oKr9fb7kXlKjzHzjBFhr0ytLBn3/CPsws7LbKwU12RiydUS/FEqHjzm06dX4ki7GAPxUprCwnFSo6dWTzhMG/TtDSFYpXE+tjx7ZvUKKFugiAIgkgzCQm7mpoavPnmmzjvvPPw/vvvAwhUxt57770YOnRoUheYSzC7YyflmfmYhsKuEYonFHso1up2GfL0Cacn8gLk3nFhhI1uCrrwjl3gOTUu2hDOsTOPK5xjZ1gdO9WZYmFnq4JV4qyK5aHYYyTsCIIgiAwmoXhY9+7d8e677+Kaa67B8OHD4Xa74ff7UVJSgn//+9/JXmPOwMycM57vJbtmXytdUREmPAqEC8VarzOHJOaijBTjTp/BzAbJNnRT7IR17DRrKFYN2+6EV8XycK3s2AWEHc9x01JcPBFaWRzfbxoubFsd4ToNEgRBEERm0K52Jy+88AL27NmDzZs3w+l0YtSoUejatWuy15gzGIY1FCsLu2+0Hgjv14WKEnsPOhajY8cfJxok2+COnR6meILn56mwTp5AuBw7hAo7xeDCjufYpaHdiUS8OXYHigfCz1R8mjcYo5O5MIIgCIJIIu1ud1JZWYkpU6Zg4sSJ2L9/P7U7iQIzhR0TodiggDrkKov4OLsoUe0D7GUxF0XY8QbF9kkWHCHs1FA3jT/W3u5ECSPseDWsanHsTEFnPs6R4lAsgz0UG99Hv6HbKAxp/T+82eOyZC6LIAiCIJIKtTtJIYbfzLFTeCg2KG6a8iILu5AwosMmUkwx54MjalEAd910hN+GO3V6mFAsD+PyNieqyLELVzwRJhRrd+xSLOx0e45dhLB3JL49oDuO69kdk4ZG8lUJgiAIIv1Qu5MUwszmuDxnTp6+0JrfK/LjbH3sVFvxRNfSEgCAX4tSOAHA7XZZnt+OoXLHLpyw446dtd2JPH+Wu2Bc0MmOnWr4wAwdmsIAAFqK+9gxu0MXZx+7k3oV49UbxuKioZHfJ4IgCIJIN9TuJIWIqljTPZJbfhhFx0V8nD0Uq9lcuW6msMvLj9zDDgCO6xq43+0K75YZplNnhBF29pFiItcuXCjWLv4AwPBD9wU/G44Ia+gomM2xs4tjgiAIgsgFqN1JCuFVsTy0qjolARVhnJi8PUex9bGDWRWrRGt1AkBxB0ZhufJLwj+PKXaMMDl2vKGxZgvFyrlqwSbGoY6dovvg90vCLuU5du2riiUIgiCIbCDhdif//e9/8dOf/pTancQBF3Yix04KxTq7hp86AYSGEe3tTuA0q2KjtDoBAHTtB0xaDHTrH/Zu7tSFE3aKvSpWjAaT251EDsUqzA+fzwtev+tIdbuTdlbFEgRBEEQ2kHA8qk+fPtTuJE6YWRnKRYbi6YpW5sAhFKKwtEfEx9lz4kLGgXFB14ZjBwAY+aPIz2MKOhYm/00zBRyvalURyJULN1JMES1RrDl2hjlWDAAcKW53EhqKJceOIAiCyD3anWhUWVmJysrww+sJK6LdiSnsNE8JpnvvxFF4sLggioNlS/S397FD1xMC/3bp1771mY4dC+PYcXfRXhUrO1/2ebKarY+d3xcQdj6mwaGlVljZ8xRBOXYEQRBEDpK0s9vBgwdRV1eHuro6/PznP0/WbnMKxniOnel+qQreZ4GwaJf8yMLOQBtu0/GnAT99p/3CznTqWJg5rjzkqiHy5AkerhWhWNmxY37o/lYAgQbJzjirUttLqGNHoViCIAgi90hI2NXX1wsRxy+ff/45GGMoKCggYRcJPSCGeI6dU3KtukZx7OztTkJCsYoClA1q9/I8eYEMOI8nNKTLn9M+ecLiHtocO1WqilUNH3TTsfMn7/dEzNiFHeXYEQRBELlIXPGwsWPHorS0FP3798ecOXPw6quvory8HF988QUee+wxfPbZZ2hsbOyotWY9wrEzRUZxnhOaqqBLvhP5rshCI1WiZOC3p8CX1w0njZkcch934zQYYIxJodgoVbGSY6cxHX6z3YlfSb2oCnkNUxwKJgiCIIhUEJd18t///he/+MUvcO211+K444J915YuXYrTTz+dcu3agOkBx4rn2JXkO7Fs9mko9jihRAlNMuk+gylQOyiM6TzpQmDgJ2Gb9zq0oLAzWKQcO7ONC0Jz7FTmg66bwi4Njh3sVbFpEJcEQRAE0dHEZVusX78eb775JubOnYuPPvqoo9aUszAjIHhk9+jsE3tgeGVp9MdJb5OeWOvB2IkgGvlcWw0GdIMFq2ItoVieY2dtYgwEWp/oZlVspJFmHUlIjp29FyBBEARB5ABxqYQRI0bgjTfewKWXXorzzz8fc+fORUNDQ0etLffgDYrjHEAvb2/Pt0sVDqlBcUDY8VmxQYHE/8/712mWUKwPBs+xU9KRY9dGL0CCIAiCyAESOrvNnDkTW7duRWlpKQYNGgTDMKDretsP7OzYcuxiRkmhYxcB7sw5FAM6Y8G2J7JAChk7Jgs7vwjF2qt8U0FoniK1OyEIgiByj4RVQn5+Pu6++26sX78ekyZNwrnnnov77rsPx44dS+b6BNXV1VAUxXIpLy8X9zPGUF1djYqKCng8HowbNw5bt27tkLUkihgpFqewkxsU25sVpwrNERRCuq6LticI08dOFX3sgqFYjemiQbGejvw21d7uhBw7giAIIvdo99nthBNOwLPPPot//OMfWLZsGU444YRkrCssgwYNwt69e8Xlgw8+EPctWrQI999/P5YsWYLa2lqUl5dj/PjxmVWlm2AoVnbsjBT3f+PILVZ0vw8KC+TYaZLzpfIcO/BQbFDYORCcPKGnpXiCHDuCIAgi90na2W38+PF4//338eCDDyZrlyE4HA6LS8dhjGHx4sW47bbbMG3aNADA8uXLUVZWhpUrV+Lqq6/usDXFhZg8EZ9jxTLAsVMtws4Ph8L72EVx7GztTgx/IBSrpyXHzl48QY4dQRAEkXsk9eymaRrmz5+fzF1a2LlzJyoqKtCvXz9cdtll+PTTTwEEGibv27cPEyZMENu63W6MHTsW77zzTpv7PXLkiOXS2traMQfA23/EK+wsxRNpEiTSmg1z5i1g62NnijxRWCE5dhr8YlaukQZhB1volRoUEwRBELlI1tgWo0aNwt/+9je8/PLLePTRR7Fv3z6MGTMGBw4cwL59+wAAZWVllseUlZWJ+6JRWVmJkpIScVm4cGGHHIMIxcaZ38UyoHhCzlEz/EHhqzrkUGxw8oRhMDgkx87BdBg6d+zSXzyhkbAjCIIgcpCsSTSaOHGi+P+QIUNwxhlnoH///li+fDlGjx4NACFNfhljURv/cvbs2YPi4mJx3e12J2nVNpLg2KUrFAspJ003J0gAgKaECcVCNytng46dE34Y/jQ6dpRjRxAEQXQCssaxs1NQUIAhQ4Zg586dIu/O7s41NDSEuHjhKC4utlw6TNiJ4ok4RUUG9LGzFHD4go6dIuXecbGkmk2MHZbiCT+Y6dixdIgqe1Us5dgRBEEQOUjWnt1aW1uxfft29OrVC/369UN5eTnWrFkj7vd6vVi3bh3GjBmTxlXa4I5dvK02LFWxaQohKooIAx+VWtpYiie0YPGErutQFSbucyDY7iQTHDuVQrEEQRBEDpI18aibbroJkydPRu/evdHQ0IC77roLR44cwaxZs6AoCubPn4+amhpUVVWhqqoKNTU1yM/Px8yZM9O9dIFiJBiKRQY4dgjk92kw0NjULG6T250EQ7EG/H6/5bFO+EUINz3FE7ZQrCNrPvoEQRAEETNZc3b7/PPPMWPGDOzfvx89evTA6NGj8e6776JPnz4AgAULFuDYsWO49tprcfDgQYwaNQqvvPIKioqK0rxyiQRz7JAJOXYAGDQAfhxtDgo7RQpp8pYoKgzhznEcigG/eVtGhGLT5XwSBEEQRAeSNcJu1apVUe9XFAXV1dWorq5OzYISwQid1hALGVE8wdfBgKNNTeI2uXGxKrU70XV/6ON9gRBuJoRiNY2EHUEQBJF7ZG2OXTai8Fmx8eZ3ycUT8U6tSCJ+1QUAaG0OTvPQwjQo1mBYet2J+30Bpy8djp29b51CI8UIgiCIHITObimEZXO7EwDHnF0AAOxoAwBAZwrkbjLcvQsUT/hCHs+FHdIg7OxiWnYaCYIgCCJXIGGXQlRT2MU99UASgul07FpdXQEAzuavAJjFFJKyk4sndF8Yx84fCMWmxbGzvW7UoJggCILIRUjYpRJeFduOUGw6HTufpxsAwH3sa7EWVRJ2vHhCgwHDnIvrYxr85po1vQUAwFRnytbMCQnFUo4dQRAEkYOQsEshCjOLJ9ozKzaNjp2R3x0AkO/dH7gOFaoqC7ugY2eYoVhdUeEza3TUNDp2sIlJu4NHEARBELkAnd1SiJJwKFbuY5e+t0wp6AkAKPIfABA6t1ZV5XYnfnMbDbop7BxGOh07ad4uU4AYRs0RBEEQRLZBwi6VJKEq1kij06QVBYRdF+NgYC12YSf1sfNLws6PwPE6zFCskgZhJ4e/0xnOJgiCIIiOhM5wKYSHYpW4GxRLxRNpfMtcJQFh1wOHAIQKJE1qd8KbERtQoZt965ymY4c05LcpUviXhB1BEASRq9AZLoWorP3FE+nMscsrLQcAFCuBtiWGbbyZ6jCFncLg9wfGhwUcu4Cocglhl97iCfu6CYIgCCJXIGGXQkSOXbyOlZQPlk63Kb9rL8v1SKFYANJc2KBj52Kt5oYUiiUIgiCIjoDOcClEhGLjrAq15OSl0bFzF5dZrtvz/VRVFnYBEWdAg26Gkt0I3Kak27GjwgmCIAgiRyFhl0oSnDyhZEgoFu4itCIoykJCsZITafgCYVddCVbF5rH0CTtQjh1BEATRCaAzXApRYTp28Y6zUjOjeAKKgsNKibhqIPKYLt3MsQsUTwSEXJ7p2KUjx061hGKpOTFBEASRm5CwSyGJjxTLEMcOQKPWRfw/JMdO6hVn8FCsosHgOXYKzzFMw0gxTXbsKBRLEARB5CYk7FJIUhoUx9sqJck0OYPCjtkEkpw7yPxSjp0tp1BNd44dfewJgiCIHIXOcCkkWDyRnX3sAKDF1VX8P6RZshwyFo6dKhw7QZqFXbpfQ4IgCILoKNIwtLNzUbfnEPZ804yRfbsEc+yyOBTrzesGHA78P8T5UhQYTIGqMDCd59hpMBSrkEu7Y0dzYgmCIIgchc5wHUzN89sx7/HN2PjZQSkUG2/xROYIO93TXfw/XBECnx9r8FCs4gCzHa/icHXgCsOjWhw7yrEjCIIgchMSdh1M96KAiDlw1JtwVaxlBFm63aaCHuK/LEw/OOHimcKOKSqMTMix06jdCUEQBJH70Bmug+lW4AYA7D/aKqpi1XhDsWrmFE+ohT3F/8MJJBHm1M1ZsUqYUKwjvcKOcuwIgiCIXIXOcB1Mt8KAY7ff4thlb46ds1gWdpFDsUHHTgsJxabDsdM0yrEjCIIgch86w3Uw3QoDjt2Bo61QE6yKzaRQbF6X8uCVKKFYxSyeCAg7q5DT0uHYya1YKMeOIAiCyFFI2HUwJzZtwmXaa9CO7IaCxEKxllYdaQ7F5pcG58WGc+xEeNYwq2LDOXZpLp4w0vwaEgRBEERHQe1OOpiTPnoYo5zr8ZvGkqBjF2co0lKkkGbHrqQwHwdZIbooR8OGNMM5dva+dWlx7DRy7AiCIIjchxy7DkYtCuSkuVoOQOOOXZw5dpZWHekWdh4nDrDiwJUooVhVFnb2UKwzzY4dfewJgiCIHIXOcB2MsziQk1akfyMmT6jx9rHLpBw7p4ZvlBIAEUKx5voUI1AVyxQNzNbeJR2OneqQHDsqniAIgiByFDrDdTCukkBOWjccgZJoVawqh2LTnx92RC0FEF4gcbGnGrJjZ3XotLTk2FG7E4IgCCL3oTNcB6OYfd+6K4ehITHHzlLRmQFuU5OjC4DoxROq6dhBDc2xS0cfO9mxo+IJgiAIIldJv0rIdcxJDRZhF6djp8hiLgOE3TFXVwARJk+Y69NEVawjRNg50pxjR8UTBEEQRK6SfpWQ6wjH7ohoUKzGOVJMnjyBeKdWdADNeYHwslf1hNzHHTuNccdODRmh5khHKFbLnJYxBEEQBNFRULuTjsZ07HrgMI4hIGjiFXaZ1KAYAHZ0Pw8PfFWPfcXn4wzbfUHHjhdPOADNlmOXFsdODmeTY0cQBEHkJulXCbmO6di5FR+K0AwgkRw7ORSbfrfJU1CCP/i/hy/cJ4Tcx8y8u6Bjp4X07XOmQdjJI8WoeIIgCILIVegM19E4PfBqBQAATWEAEsixy6A+dgBQ7AkINS2M8cUdOwcL5NhB0aDaHDtHOhoUS8+ZCa8hQRAEQXQEdIZLAa3ubpbrcefYSUIk3jmzHUEJF3ZqqLLjbpiD+QPXVQeQAX3sNEsoNv2vIUEQBEF0BFkr7BYuXAhFUTB//nxxG2MM1dXVqKiogMfjwbhx47B169b0LdJEz+9hua454hN2ltmyGeA2Da8sgaoAJ1eUhNzHW4k45FCswy3u9zHNGlpOEZqDqmIJgiCI3Cf9KiEBamtr8Ze//AVDhw613L5o0SLcf//9WLJkCWpra1FeXo7x48ejsbExTSsNoBRahV3cxRMZJuxO7dMVW+6cgBvGnxhyH3fsnDCFneKAKuXY+cP0vksFmkaOHUEQBJH7pF8lxMnRo0dx+eWX49FHH0WXLl3E7YwxLF68GLfddhumTZuGwYMHY/ny5WhubsbKlSvTuGLAUVxmuR5/jl1mtTsBgKK88OFUnr/mNEOxUDVLQ2J/mkSVLOzCzbglCIIgiFwg64Td3LlzcdFFF+G8886z3F5fX499+/ZhwoQJ4ja3242xY8finXfeSfUyLbhKyi3XtbirYmXHLjOEXSR4KFY4dqoGVepb509Thx2VHDuCIAiiE5BVfexWrVqFTZs2oba2NuS+ffv2AQDKyqzuWFlZGT777LOo+z1y5IjlutvthtvtjrB1/Dhtjp2c7xULVscus7W4cOzAHTuHRdjpaQrFyiFsqoolCIIgcpWsOcPt2bMH119/PVasWIG8vLyI2ym2MBtjLOQ2O5WVlSgpKRGXhQsXJmXNArOXnVhjvI5dhjUojkYwx04WdsFQbPqEnQI/C6yN+tgRBEEQuUrWOHYbN25EQ0MDTj31VHGbrut44403sGTJEuzYsQNAwLnr1auX2KahoSHExbOzZ88eFBcXi+vJdOsAAAVWYRdvOFUOxWZCu5No8DCnS9EBBNaryY6dkr6PXGDcmZHx4pggCIIgEiVrhN25556LDz74wHLbj370IwwcOBA333wzTjjhBJSXl2PNmjUYMWIEAMDr9WLdunW49957o+67uLjYIuySjq0qFnE6dqqWWZMnohES5lQ1qM4MCMUC0E2njnLsCIIgiFwla4RdUVERBg8ebLmtoKAA3bp1E7fPnz8fNTU1qKqqQlVVFWpqapCfn4+ZM2emY8nSQu3CLl7HTq7ozGxREiKaVAc0LUMcOy46qSqWIAiCyFGyRtjFwoIFC3Ds2DFce+21OHjwIEaNGoVXXnkFRUVF6V2YqxA+1Q2n0Rq4Hm8oUBIiaphpD5mEXdgpqgbNmSHCjhw7giAIIsfJamG3du1ay3VFUVBdXY3q6uq0rCciioIWVzc4W76EDgVanI6R3PeOZXyOnVW0KpojY4RdMBRLOXYEQRBEbkJnuBTh93QHABgJ5JhZiicy3G0KEXaqBock7NLplnHHjoonCIIgiFyFznApgpmVsXoCL7mqZF9VrEB1wJEhVbGicCPDxTFBEARBJAoJuxSR3zXQgiURx8oi5jK8QbFdNCmqw+LYGRmQY0eOHUEQBJGr0BkuReSVBsaK5bnCz1iNhjx5IvMdu9AcO4cr2BcwrcJOoRw7giAIIrehM1yqMEOxiQgzTcueHDu7G6Zq1lCsEWcPv2Qi8htJ2BEEQRA5Cp3hUgVvUpyIMMviUCxUa1UsS6Njx526TK8sJgiCIIhEyXCVkEPwsWKJOHaSmFMzXJQwm/BUVYelwTJLq2MXWJtCH3uCIAgiR6EzXKooHwwUVQD9zo77odk0KzakeELTAEWBlwUEXTodO9GgONNfQ4IgCIJIkKxuUJxV5JUAP/8wofwuVXa5siwUq2qBYhG/osEFf1pz7ETRBOXYEQRBEDkKneFSiaolNKfUUhWbRscrFuxumGIWfvjN3xDpDMXyPnYZX4BCEARBEAlCwi4LULMqFGuvijUdO16Rqsbf7iVZiB6CCYhrgiAIgsgGSNhlAfKsWCXrQrEBh86PgKBLa/EEVcUSBEEQOU6GqwQCsIq5TK+KtVf9codRNwUf09Lo2PGqWMqxIwiCIHIUOsNlAZoWdLkyPxRrXZ/mCAg5PiM2nTmCIhSb6a8hQRAEQSQICbssQM2ikWL2ql3h2PHiCS0TqmIz/DUkCIIgiAQhYZcFKHKOnZbhosTu2Gk2xy6NoVhDFE/Qx54gCILITegMlwVokkunZlvxhCMg6Liwy4iq2Ex/DQmCIAgiQegMlwVY251kdh87e/4ar4oVwi6djh0VTxAEQRA5Dp3hsgBVLp7IdFGi2kOxgbWLiRNpFKYOs5DD43albQ0EQRAE0ZFkuEogAFhywtQ0Fh/Egr24QzXFlCFy7NK3/v6VFQCAk/oel7Y1EARBEERHktkqgQigKDCYAlVhULUM1+Ihjl3gutOVB7QAXYoK07EqAEDeeb8Eep8Cx6CpaVsDQRAEQXQkJOyyBAMKVLCMb9Vhn8PK+9j1P3cOWt5qQtXoi9KxrABd+wGjf5q+5ycIgiCIDoaEXZZgIDDfVMv0dichxRMBYecYNh2OYdPTsSKCIAiC6DRkeFyP4PBWHcUed5pXEh17jp3myHAhShAEQRA5BAm7LMFpCqSi/CwTdmlsb0IQBEEQnQ0KxWYJ6uBpwNf/A0p6p3sp0YnQ7oQgCIIgiI6HzrrZwsUPpXsFMWF37NI5QowgCIIgOhsUiiWSil3Y0VxWgiAIgkgddNYlkoos7PxMBRQljashCIIgiM4FCTsiqcjCTgdVxBIEQRBEKiFhRyQXaRasTmFYgiAIgkgpdOYlkgo5dgRBEASRPkjYEUnFKuzo40UQBEEQqYTOvERSkYWdQY4dQRAEQaQUEnZEUlEtwo4+XgRBEASRSrLmzPvwww9j6NChKC4uRnFxMc444wy8+OKL4n7GGKqrq1FRUQGPx4Nx48Zh69ataVxx50TRpFCsQo4dQRAEQaSSrBF2xx9/PO655x689957eO+993DOOedg6tSpQrwtWrQI999/P5YsWYLa2lqUl5dj/PjxaGxsTPPKOxeKXBVLoViCIAiCSClZI+wmT56MCy+8ECeeeCJOPPFE3H333SgsLMS7774LxhgWL16M2267DdOmTcPgwYOxfPlyNDc3Y+XKleleeqdCDsUyandCEARBECklK8+8uq5j1apVaGpqwhlnnIH6+nrs27cPEyZMENu43W6MHTsW77zzTpv7O3LkiOXS2trakcvPaVSNHDuCIAiCSBdZJew++OADFBYWwu1245prrsHTTz+Nk08+Gfv27QMAlJWVWbYvKysT90WjsrISJSUl4rJw4cIOWX9nwFIVS44dQRAEQaQUR9ubZA7f+ta3UFdXh0OHDuHJJ5/ErFmzsG7dOnG/YptLyhgLuS0ce/bsQXFxsbjudruTt+hOhuzYUbsTgiByGcYY/H4/dF1P91KILEfTNDgcjpg0S1tklbBzuVwYMGAAAGDkyJGora3FAw88gJtvvhkAsG/fPvTq1Uts39DQEOLihYNX2hLtR1WDH0qDqmIJgshRvF4v9u7di+bm5nQvhcgR8vPz0atXL7hcrnbtJ6uEnR3GGFpbW9GvXz+Ul5djzZo1GDFiBIDAH926detw7733pnmVnQu5KpaRsCMIIgcxDAP19fXQNA0VFRVwuVxJcVqIzgljDF6vF19//TXq6+tRVVUFVU08lSlrhN0vf/lLTJw4EZWVlWhsbMSqVauwdu1avPTSS1AUBfPnz0dNTQ2qqqpQVVWFmpoa5OfnY+bMmeleeqdC1WjyBEEQuY3X64VhGKisrER+fn66l0PkAB6PB06nE5999hm8Xi/y8vIS3lfWCLuvvvoKV1xxBfbu3YuSkhIMHToUL730EsaPHw8AWLBgAY4dO4Zrr70WBw8exKhRo/DKK6+gqKgozSvvXFhy7MixIwgih2mPq0IQdpL1ecoaYffYY49FvV9RFFRXV6O6ujo1CyLCTKfECgAAI2xJREFUIgs7CsUSBEEQRGqhnxtEUrGEYqndCUEQRE7Tt29fLF68ON3LICSyxrEjsgPVUjxBHy+CIIhMYty4cRg+fHjSxFhtbS0KCgqSsi8iOdCZl0gqCo0UIwiCyGoYY9B1HQ5H2xKhR48eKVhRaonn+DMROvMSSUWzhGKz84+CIAgiF5k9ezbWrVuHBx54AIqiQFEU7Nq1C2vXroWiKHj55ZcxcuRIuN1uvPnmm/jkk08wdepUlJWVobCwEKeddhpeffVVyz7toVhFUfB///d/uOSSS5Cfn4+qqiqsXr066rpWrFiBkSNHoqioCOXl5Zg5cyYaGhos22zduhUXXXQRiouLUVRUhLPOOguffPKJuH/p0qUYNGgQ3G43evXqheuuuw4AsGvXLiiKgrq6OrHtoUOHoCgK1q5dCwDtOv7W1lYsWLAAlZWVcLvdqKqqwmOPPQbGGAYMGID77rvPsv2HH34IVVUta082JOyIpKI6qHiCIIjOB2MMzV5/Wi6MsZjW+MADD+CMM87AVVddhb1792Lv3r2orKwU9y9YsAALFy7E9u3bMXToUBw9ehQXXnghXn31VWzevBnnn38+Jk+ejN27d0d9nl//+te49NJL8f777+PCCy/E5Zdfjm+++Sbi9l6vF7/97W+xZcsWPPPMM6ivr8fs2bPF/V988QXOPvts5OXl4bXXXsPGjRsxZ84c+P1+AMDDDz+MuXPn4ic/+Qk++OADrF69WgwziIdEjv+HP/whVq1ahT/+8Y/Yvn07/vznP6OwsBCKomDOnDlYtmyZ5TmWLl2Ks846C/379497fbFClgqRVCw5dioJO4IgOgfHfDpO/tXLaXnubb85H/mutk/nJSUlcLlcyM/PR3l5ecj9v/nNb0QLMQDo1q0bhg0bJq7fddddePrpp7F69WrhiIVj9uzZmDFjBgCgpqYGDz74IDZs2IALLrgg7PZz5swR/z/hhBPwxz/+EaeffjqOHj2KwsJC/OlPf0JJSQlWrVoFp9MJADjxxBMt67rxxhtx/fXXi9tOO+20tl6OEOI9/o8++ghPPPEE1qxZg/POO0+sn/OjH/0Iv/rVr7Bhwwacfvrp8Pl8WLFiBX73u9/FvbZ4IMeOSCpyKJYcO4IgiOxh5MiRlutNTU1YsGABTj75ZJSWlqKwsBD/+9//2nTshg4dKv5fUFCAoqKikNCqzObNmzF16lT06dMHRUVFGDduHACI56mrq8NZZ50lRJ1MQ0MDvvzyS5x77rmxHmZE4j3+uro6aJqGsWPHht1fr169cNFFF2Hp0qUAgOeeew4tLS2YPn16u9caDXLsiKQi97EDCTuCIDoJHqeGbb85P23PnQzs1a2/+MUv8PLLL+O+++7DgAED4PF48L3vfQ9erzfqfuwCTFEUGIYRdtumpiZMmDABEyZMwIoVK9CjRw/s3r0b559/vngej8cT8bmi3QcEm/7K4Wqfzxd223iPv63nBoAf//jHuOKKK/CHP/wBy5Ytw/e///0On1ZCwo5IKppGoViCIDofiqLEFA5NNy6XC7qux7Ttm2++idmzZ+OSSy4BABw9ehS7du1K6nr+97//Yf/+/bjnnntEvt97771n2Wbo0KFYvnw5fD5fiGgsKipC37598Z///Aff+c53QvbPq3b37t0rZsnLhRTRaOv4hwwZAsMwsG7dOhGKtXPhhReioKAADz/8MF588UW88cYbMT13e6BQLJFUVEsoNvO/5AiCIDoTffv2xfr167Fr1y7s378/opMGAAMGDMBTTz2Furo6bNmyBTNnzoy6fSL07t0bLpcLDz74ID799FOsXr0av/3tby3bXHfddThy5Aguu+wyvPfee9i5cyf+/ve/Y8eOHQCA6upq/P73v8cf//hH7Ny5E5s2bcKDDz4IIOCqjR49Gvfccw+2bduGN954A7fffntMa2vr+Pv27YtZs2Zhzpw5ouhj7dq1eOKJJ8Q2mqZh9uzZuPXWWzFgwACcccYZ7X3J2oSEHZFUFFUOxdLHiyAIIpO46aaboGkaTj75ZBH2jMQf/vAHdOnSBWPGjMHkyZNx/vnn45RTTknqenr06IG//vWv+Oc//4mTTz4Z99xzT0iLkG7duuG1117D0aNHMXbsWJx66ql49NFHhXs3a9YsLF68GA899BAGDRqESZMmYefOneLxS5cuhc/nw8iRI3H99dfjrrvuimltsRz/ww8/jO9973u49tprMXDgQFx11VVoamqybHPllVfC6/VaikQ6EoXFWiedgxw5cgQlJSU4fPgwiouL072cnMG4sxSqwrCh53Scfu3/pXs5BEEQSaWlpQX19fXo168f8vLy0r0cIsN5++23MW7cOHz++ecoKyuLuF20z1U8eoViZUTS0aFChU7FEwRBEESnpbW1FXv27MEdd9yBSy+9NKqoSyYUKyOSjsE/VlQ8QRAEQXRSHn/8cXzrW9/C4cOHsWjRopQ9Lwk7IunoQtiRIUwQBEF0TmbPng1d17Fx40Ycd9xxKXteEnZE0jHMoglqd0IQBEEQqYWEHZF0eChWoRw7giAIgkgpJOyIpMOFHaNQLEEQBEGkFBJ2RNLhOXYKhWIJgiAIIqWQsCOSjkHFEwRBEASRFkjYEUmH2p0QBEEQRHogYUckHV4Vq5BjRxAEQRAphYQdkXQMmE4dCTuCIIiMYty4cZg/f35S9zl79mxcfPHFSd0nkTgk7Iikw3jxhEbCjiAIgshcfD5fupeQdEjYEUmHh2Ipx44gCCJzmD17NtatW4cHHngAiqJAURTs2rULALBt2zZceOGFKCwsRFlZGa644grs379fPPZf//oXhgwZAo/Hg27duuG8885DU1MTqqursXz5cjz77LNin2vXrg37/C+99BLOPPNMlJaWolu3bpg0aRI++eQTyzaff/45LrvsMnTt2hUFBQUYOXIk1q9fL+5fvXo1Ro4ciby8PHTv3h3Tpk0T9ymKgmeeecayv9LSUvz1r38FAOzatQuKouCJJ57AuHHjkJeXhxUrVuDAgQOYMWMGjj/+eOTn52PIkCF4/PHHLfsxDAP33nsvBgwYALfbjd69e+Puu+8GAJxzzjm47rrrLNsfOHAAbrcbr732WpvvS7IhYUckHdGgmEKxBEF0FhgDvE3puTAW0xIfeOABnHHGGbjqqquwd+9e7N27F5WVldi7dy/Gjh2L4cOH47333sNLL72Er776CpdeeikAYO/evZgxYwbmzJmD7du3Y+3atZg2bRoYY7jppptw6aWX4oILLhD7HDNmTNjnb2pqwg033IDa2lr85z//gaqquOSSS2AYBgDg6NGjGDt2LL788kusXr0aW7ZswYIFC8T9zz//PKZNm4aLLroImzdvxn/+8x+MHDky7rfq5ptvxs9+9jNs374d559/PlpaWnDqqafiueeew4cffoif/OQnuOKKKyyC8tZbb8W9996LO+64A9u2bcPKlStRVlYGAPjxj3+MlStXorW1VWz/j3/8AxUVFfjOd74T9/raC515iaQjiicoFEsQRGfB1wzUVKTnuX/5JeAqaHOzkpISuFwu5Ofno7y8XNz+8MMP45RTTkFNTY24benSpaisrMRHH32Eo0ePwu/3Y9q0aejTpw8AYMiQIWJbj8eD1tZWyz7D8d3vftdy/bHHHkPPnj2xbds2DB48GCtXrsTXX3+N2tpadO3aFQAwYMAAsf3dd9+Nyy67DL/+9a/FbcOGDWvzuO3Mnz/f4vQBwE033ST+P2/ePLz00kv45z//iVGjRqGxsREPPPAAlixZglmzZgEA+vfvjzPPPFMc17x58/Dss88KMbxs2TLMnj0biqLEvb72Qo4dkXSYWTxBDYoJgiAyn40bN+L1119HYWGhuAwcOBAA8Mknn2DYsGE499xzMWTIEEyfPh2PPvooDh48GPfzfPLJJ5g5cyZOOOEEFBcXo1+/fgCA3bt3AwDq6uowYsQIIers1NXV4dxzz03wKIPYXT5d13H33Xdj6NCh6NatGwoLC/HKK6+IdW3fvh2tra0Rn9vtduMHP/gBli5dKta5ZcsWzJ49u91rTQSyVIikQ44dQRCdDmd+wDlL13O3A8MwMHnyZNx7770h9/Xq1QuapmHNmjV455138Morr+DBBx/EbbfdhvXr1wtxFguTJ09GZWUlHn30UVRUVMAwDAwePBherxdAwPmLRlv3K4oCZgtLhyuOKCiwupu///3v8Yc//AGLFy/GkCFDUFBQgPnz58e8LiAQjh0+fDg+//xzLF26FOeee65wN1MNOXZE0iktyAMAnNCzOM0rIQiCSBGKEgiHpuMSR7jP5XJB13XLbaeccgq2bt2Kvn37YsCAAZYLF0GKouDb3/42fv3rX2Pz5s1wuVx4+umnI+7TzoEDB7B9+3bcfvvtOPfcc3HSSSeFuH5Dhw5FXV0dvvnmm7D7GDp0KP7zn/9EfI4ePXpg79694vrOnTvR3NwcdV0A8Oabb2Lq1Kn4wQ9+gGHDhuGEE07Azp07xf1VVVXweDxRn3vIkCEYOXIkHn30UaxcuRJz5sxp83k7ChJ2RNLpMWIyUFiO4hNOT/dSCIIgCIm+ffti/fr12LVrF/bv3w/DMDB37lx88803mDFjBjZs2IBPP/0Ur7zyCubMmQNd17F+/XrU1NTgvffew+7du/HUU0/h66+/xkknnST2+f7772PHjh3Yv39/WJesS5cu6NatG/7yl7/g448/xmuvvYYbbrjBss2MGTNQXl6Oiy++GG+//TY+/fRTPPnkk/jvf/8LALjzzjvx+OOP484778T27dvxwQcfYNGiReLx55xzDpYsWYJNmzbhvffewzXXXAOn09nmazJgwADhSG7fvh1XX3019u3bJ+7Py8vDzTffjAULFuBvf/sbPvnkE7z77rt47LHHLPv58Y9/jHvuuQe6ruOSSy6J/U1JNqwTc/jwYQaAHT58ON1LyT0MI90rIAiC6BCOHTvGtm3bxo4dO5bupcTNjh072OjRo5nH42EAWH19PWOMsY8++ohdcsklrLS0lHk8HjZw4EA2f/58ZhgG27ZtGzv//PNZjx49mNvtZieeeCJ78MEHxT4bGhrY+PHjWWFhIQPAXn/99bDPvWbNGnbSSScxt9vNhg4dytauXcsAsKefflpss2vXLvbd736XFRcXs/z8fDZy5Ei2fv16cf+TTz7Jhg8fzlwuF+vevTubNm2auO+LL75gEyZMYAUFBayqqoq98MILrKSkhC1btowxxlh9fT0DwDZv3mxZ14EDB9jUqVNZYWEh69mzJ7v99tvZD3/4QzZ16lSxja7r7K677mJ9+vRhTqeT9e7dm9XU1Fj209jYyPLz89m1114b+xsiEe1zFY9eURiLsU46Bzly5AhKSkpw+PBhFBdT2JAgCIJom5aWFtTX16Nfv37Iy8tL93KIDGHPnj3o27cvamtrccopp8T9+Gifq3j0CmW3EwRBEARBJIjP58PevXtxyy23YPTo0QmJumSSNTl2CxcuxGmnnYaioiL07NkTF198MXbs2GHZhjGG6upqVFRUwOPxYNy4cdi6dWuaVkwQBEEQRK7z9ttvo0+fPti4cSP+/Oc/p3s52SPs1q1bh7lz5+Ldd9/FmjVr4Pf7MWHCBDQ1NYltFi1ahPvvvx9LlixBbW0tysvLMX78eDQ2NqZx5QRBEARB5Crjxo0DYww7duywNG5OF1kTin3ppZcs15ctW4aePXti48aNOPvss8EYw+LFi3HbbbeJjtLLly9HWVkZVq5ciauvvjodyyYIgiAIgkgZWePY2Tl8+DAAiA7V9fX12LdvHyZMmCC2cbvdGDt2LN55552o+zpy5IjlIs97IwiCIAiCyBayUtgxxnDDDTfgzDPPxODBgwFA9JzhQ3k5ZWVlln404aisrERJSYm4LFy4sGMWThAEQeQMnbipBNEBJOvzlDWhWJnrrrsO77//Pt56662Q++wDdxljbQ7h3bNnj6V82O12J2ehBEEQRM7Bm942NzfHNG6KIGKBT8mIpalyNLJO2M2bNw+rV6/GG2+8geOPP17cXl5eDiDg3PXq1Uvc3tDQEOLi2SkuLqY+dgRBEERMaJqG0tJSNDQ0AADy8/PbNBAIIhKMMTQ3N6OhoQGlpaXQNK1d+8saYccYw7x58/D0009j7dq1IYOH+/Xrh/LycqxZswYjRowAAHi9Xqxbty7sYGOCIAiCSBRuJnBxRxDtpbS0VHyu2kPWCLu5c+di5cqVePbZZ1FUVCTy5kpKSuDxeKAoCubPn4+amhpUVVWhqqoKNTU1yM/Px8yZM9O8eoIgCCKXUBQFvXr1Qs+ePcPORiWIeHA6ne126gQJDTRLAwDCXvgMOMYYMwyD3Xnnnay8vJy53W529tlnsw8++CDiPlMxK7alpYXdeeedrKWlpcOeI5PpzMffmY+dsc59/J352Bnr3MffmY+dsc59/B157DQrNkZSMSu2s8+j7czH35mPHejcx9+Zjx3o3MffmY8d6NzH35HHHs++s7LdCUEQBEEQBBEKCTuCIAiCIIgcIWuKJzoCHoU+cuRIhz0H33dHPkcm05mPvzMfO9C5j78zHzvQuY+/Mx870LmPvyOPne8zluy5Tp1j9/nnn6OysjLdyyAIgiAIgmiTPXv2WHr4hqNTCzvDMPDll1+iqKiImksSBEEQBJGRMMbQ2NiIiooKqGr0LLpOLewIgiAIgiByCSqeIAiCIAiCyBFI2BEEQRAEQeQIJOw6mIceegj9+vVDXl4eTj31VLz55pvpXlLSWbhwIU477TQUFRWhZ8+euPjii7Fjxw7LNrNnz4aiKJbL6NGj07Ti5FFdXR1yXPKsP8YYqqurUVFRAY/Hg3HjxmHr1q1pXHFy6du3b8jxK4qCuXPnAsi99/2NN97A5MmTUVFRAUVR8Mwzz1juj+X9bm1txbx589C9e3cUFBRgypQp+Pzzz1N4FIkR7dh9Ph9uvvlmDBkyBAUFBaioqMAPf/hDfPnll5Z9jBs3LuTzcNlll6X4SBKjrfc+ls96Lr73AMJ+ByiKgt/97ndim2x972M5v2Xa3z0Juw7k//2//4f58+fjtttuw+bNm3HWWWdh4sSJ2L17d7qXllTWrVuHuXPn4t1338WaNWvg9/sxYcIENDU1Wba74IILsHfvXnF54YUX0rTi5DJo0CDLcX3wwQfivkWLFuH+++/HkiVLUFtbi/LycowfPx6NjY1pXHHyqK2ttRz7mjVrAADTp08X2+TS+97U1IRhw4ZhyZIlYe+P5f2eP38+nn76aaxatQpvvfUWjh49ikmTJkHX9VQdRkJEO/bm5mZs2rQJd9xxBzZt2oSnnnoKH330EaZMmRKy7VVXXWX5PDzyyCOpWH67aeu9B9r+rOfiew/Acsx79+7F0qVLoSgKvvvd71q2y8b3PpbzW8b93Sd9oBkhOP3009k111xjuW3gwIHslltuSdOKUkNDQwMDwNatWydumzVrFps6dWr6FtVB3HnnnWzYsGFh7zMMg5WXl7N77rlH3NbS0sJKSkrYn//85xStMLVcf/31rH///swwDMZY7r7vjAXmVz/99NPieizv96FDh5jT6WSrVq0S23zxxRdMVVX20ksvpWzt7cV+7OHYsGEDA8A+++wzcdvYsWPZ9ddf37GLSwHhjr+tz3pneu+nTp3KzjnnHMttufLe289vmfh3T45dB+H1erFx40ZMmDDBcvuECRPwzjvvpGlVqeHw4cMAgK5du1puX7t2LXr27IkTTzwRV111FRoaGtKxvKSzc+dOVFRUoF+/frjsssvw6aefAgDq6+uxb98+y2fA7XZj7NixOfkZ8Hq9WLFiBebMmWNpH5Sr77udWN7vjRs3wufzWbapqKjA4MGDc+4zcfjwYSiKgtLSUsvt//jHP9C9e3cMGjQIN910U86410D0z3pnee+/+uorPP/887jyyitD7suF995+fsvEv/tOPXmiI9m/fz90XUdZWZnl9rKyMuzbty9Nq+p4GGO44YYbcOaZZ2Lw4MHi9okTJ2L69Ono06cP6uvrcccdd+Ccc87Bxo0b4Xa707ji9jFq1Cj87W9/w4knnoivvvoKd911F8aMGYOtW7eK9zncZ+Czzz5Lx3I7lGeeeQaHDh3C7NmzxW25+r6HI5b3e9++fXC5XOjSpUvINrn0vdDS0oJbbrkFM2fOtAwsv/zyy9GvXz+Ul5fjww8/xK233ootW7aIEH4209ZnvbO898uXL0dRURGmTZtmuT0X3vtw57dM/LsnYdfB2BsfM8Zyuhnyddddh/fffx9vvfWW5fbvf//74v+DBw/GyJEj0adPHzz//PMhXwDZxMSJE8X/hwwZgjPOOAP9+/fH8uXLReJ0Z/kMPPbYY5g4cSIqKirEbbn6vkcjkfc7lz4TPp8Pl112GQzDwEMPPWS576qrrhL/Hzx4MKqqqjBy5Ehs2rQJp5xySqqXmlQS/azn0nsPAEuXLsXll1+OvLw8y+258N5HOr8BmfV3T6HYDqJ79+7QNC1EjTc0NIQo+1xh3rx5WL16NV5//fU2R5706tULffr0wc6dO1O0utRQUFCAIUOGYOfOnaI6tjN8Bj777DO8+uqr+PGPfxx1u1x93wHE9H6Xl5fD6/Xi4MGDEbfJZnw+Hy699FLU19djzZo1FrcuHKeccgqcTmdOfh7sn/Vcf+8B4M0338SOHTva/B4Asu+9j3R+y8S/exJ2HYTL5cKpp54aYjOvWbMGY8aMSdOqOgbGGK677jo89dRTeO2119CvX782H3PgwAHs2bMHvXr1SsEKU0drayu2b9+OXr16ibCD/Bnwer1Yt25dzn0Gli1bhp49e+Kiiy6Kul2uvu8AYnq/Tz31VDidTss2e/fuxYcffpj1nwku6nbu3IlXX30V3bp1a/MxW7duhc/ny8nPg/2znsvvPeexxx7DqaeeimHDhrW5bba8922d3zLy7z7p5RiEYNWqVczpdLLHHnuMbdu2jc2fP58VFBSwXbt2pXtpSeWnP/0pKykpYWvXrmV79+4Vl+bmZsYYY42NjezGG29k77zzDquvr2evv/46O+OMM9hxxx3Hjhw5kubVt48bb7yRrV27ln366afs3XffZZMmTWJFRUXiPb7nnntYSUkJe+qpp9gHH3zAZsyYwXr16pX1xy2j6zrr3bs3u/nmmy235+L73tjYyDZv3sw2b97MALD777+fbd68WVR+xvJ+X3PNNez4449nr776Ktu0aRM755xz2LBhw5jf70/XYcVEtGP3+XxsypQp7Pjjj2d1dXWW74HW1lbGGGMff/wx+/Wvf81qa2tZfX09e/7559nAgQPZiBEjMv7YGYt+/LF+1nPxveccPnyY5efns4cffjjk8dn83rd1fmMs8/7uSdh1MH/6059Ynz59mMvlYqeccoqlBUiuACDsZdmyZYwxxpqbm9mECRNYjx49mNPpZL1792azZs1iu3fvTu/Ck8D3v/991qtXL+Z0OllFRQWbNm0a27p1q7jfMAx25513svLycuZ2u9nZZ5/NPvjggzSuOPm8/PLLDADbsWOH5fZcfN9ff/31sJ/1WbNmMcZie7+PHTvGrrvuOta1a1fm8XjYpEmTsuI1iXbs9fX1Eb8HXn/9dcYYY7t372Znn30269q1K3O5XKx///7sZz/7GTtw4EB6DyxGoh1/rJ/1XHzvOY888gjzeDzs0KFDIY/P5ve+rfMbY5n3d6+YCycIgiAIgiCyHMqxIwiCIAiCyBFI2BEEQRAEQeQIJOwIgiAIgiByBBJ2BEEQBEEQOQIJO4IgCIIgiByBhB1BEARBEESOQMKOIAiCIAgiRyBhRxAEQRAEkSOQsCMIgiAIgsgRSNgRBEEQBEHkCCTsCIIgksyNN96IyZMnp3sZBEF0QkjYEQSRU5x99tlQFCXkcvnll6dsDXV1dRg2bFjS9zt79mzccsstYe974403MHnyZFRUVEBRFDzzzDNJf36CIDIfEnYEQeQMjDHU1dXhvvvuw969ey2XRx55JGXr2LJlS9KFnWEYeP755zF16tSw9zc1NWHYsGFYsmRJUp+XIIjsgoQdQRA5w86dO9HY2Iizzz4b5eXllkthYSG++uorKIqCBx54ACNGjEBeXh4GDRqEt956y7KfDz/8EBdeeCGKi4tRXl6OG2+8EV6v17LN119/jZ/85CcoKyuDx+PBsGHD8MYbb2DPnj04cOAAVFXF+PHjkZ+fj29961tYv369eKxhGKipqUFVVRXy8vJQVlaGK664Iuqxvf3221BVFaNGjQp7/8SJE3HXXXdh2rRpCb56BEHkAiTsCILIGTZu3AiHw4GhQ4eGvX/z5s0AgIceegh/+MMfsGXLFvTt2xeXX345DMMQ24wZMwannHIKNm3ahP/3//4fHn/8cdx7771iP5999hmGDh2KgwcP4tlnn8X777+PefPmoaioCHV1dQCABx98ELfeeiu2bNmC3r17W0KoCxcuxMqVK/GXv/wFO3bswFNPPYVx48ZFPbbVq1dj8uTJUFX62iYIIjKOdC+AIAgiWWzatAm6rqNbt26W22fMmIFHH30UW7ZsgdPpxEsvvYR+/foBAH7zm99g5MiR+OKLL1BZWYmrrroKV1xxBe666y4AwIABA3DVVVfhueeewx133AEA+OlPf4qBAwfiiSeegKIoAICqqioAwHPPPYcuXbrgiSeeQM+ePQEAF198MR5++GGxnpdffhkXXXQRvvOd7wAA+vTpg29/+9tRj2316tW477772vsSEQSR45CwIwgiZ9i4cSOmT5+Ou+++23J7ly5dAASKGqZNmyZEHQC43W7x///973/YuHEjVqxYYXm8y+VCa2srAGD37t148cUXsWnTJiHqZOrq6jB16lQh6gDg008/xYABA8T1KVOm4Oabb8bmzZsxbdo0XHrppejatWvE49q+fTs+//xznHfeebG8DARBdGLI0ycIImfYvHkzzjzzTAwYMMBy4Q5eXV0dhg8fbnnMpk2b0L17dxx33HHYunUrnE4nTjzxRMs227Ztw5AhQ8RzuFwujBgxIuwa6urqcMYZZ4SsS37em266Cdu3b8d5552HBx98EAMGDEB9fX3E41q9ejXGjx8Pj8cT60tBEEQnhYQdQRA5waeffopDhw5FFFzHjh3Dzp07oeu6uM0wDDzwwAOYNWsWVFVFUVERdF2Hz+cT2+zevRv/+te/MHPmTACA0+mE3+9Hc3NzyHM0Njaivr4+ZA3hBOWJJ56IBQsWYNOmTWhubsa2bdsiHtuzzz6LKVOmtPkaEARBUCiWIIicYOPGjQCAsrIy7Nu3z3Jfz5498cEHH0BRFKxYsQLnnHMOSktL8atf/QqHDh3C7bffDgAYNWoUunbtiltuuQXz5s3Drl27MG/ePEyfPh0TJ04U25SUlOCnP/0pbrnlFjDG8MYbb2DcuHH4+uuvoaqqcPeAQKHFwYMHhbBbtGgRysrKcNppp0HTNPzf//0funTpgjFjxoQ9roaGBtTW1rbZl+7o0aP4+OOPxfX6+nrU1dWha9eu6N27d1yvJUEQ2Qs5dgRB5ASbNm0CEHDCevXqJS69e/eGz+dDXV0dBg4ciNtvvx3f+973MHLkSKiqiv/+978oLS0FAJSUlODZZ5/FW2+9hcGDB4tCiuXLl4vn6datG/79739j586dOO2003DmmWfimWeeQVlZGbZs2YKBAwciLy9PbL9582aUlpaib9++AICWlhbU1NTg1FNPxZlnnomdO3fitddeE3mAdv79739j1KhRlpy9cLz33nsYMWKEcAtvuOEGjBgxAr/61a8SfUkJgshCFMYYS/ciCIIgOpq5c+fi4MGDWLlyZbqXEhdTpkzBmWeeiQULFqR7KQRBZAHk2BEE0Smoq6uL2N8ukznzzDMxY8aMdC+DIIgsgRw7giByHsYYSkpKsGrVKlx44YXpXg5BEESHQcKOIAiCIAgiR6BQLEEQBEEQRI5Awo4gCIIgCCJHIGFHEARBEASRI5CwIwiCIAiCyBFI2BEEQRAEQeQIJOwIgiAIgiByBBJ2BEEQBEEQOQIJO4IgCIIgiByBhB1BEARBEESOQMKOIAiCIAgiRyBhRxAEQRAEkSP8f5OyqcPaOo9hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418caa55",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.8770e+02, 1.9331e+02, 2.5903e-01, 2.8741e-01, 4.5356e-01],\n",
      "        [8.5070e+02, 2.1031e+02, 4.2552e-01, 3.7470e-01, 1.9978e-01],\n",
      "        [7.6725e+02, 1.7563e+02, 1.9704e-01, 2.6091e-01, 5.4205e-01],\n",
      "        [7.1270e+02, 1.7669e+02, 7.6219e-01, 4.1129e-02, 1.9668e-01],\n",
      "        [6.5979e+02, 1.3901e+02, 6.1835e-02, 3.5623e-01, 5.8194e-01],\n",
      "        [7.4421e+02, 1.2740e+02, 2.6441e-01, 6.2881e-01, 1.0678e-01],\n",
      "        [6.7760e+02, 1.9565e+02, 6.6837e-01, 1.1301e-01, 2.1862e-01],\n",
      "        [6.6625e+02, 1.2081e+02, 3.9046e-01, 4.5643e-01, 1.5311e-01],\n",
      "        [6.8138e+02, 1.5340e+02, 7.2753e-01, 1.7601e-01, 9.6464e-02],\n",
      "        [7.4015e+02, 1.4639e+02, 5.7118e-03, 9.1451e-01, 7.9775e-02],\n",
      "        [6.6713e+02, 2.2438e+02, 2.1991e-01, 3.8925e-02, 7.4116e-01],\n",
      "        [6.6775e+02, 1.1047e+02, 1.0550e-01, 5.4677e-01, 3.4773e-01],\n",
      "        [7.0896e+02, 1.5077e+02, 8.0591e-01, 5.0458e-03, 1.8904e-01],\n",
      "        [8.2574e+02, 1.9638e+02, 3.8461e-01, 1.2983e-01, 4.8555e-01],\n",
      "        [7.5665e+02, 1.1050e+02, 3.7467e-01, 1.8706e-01, 4.3828e-01],\n",
      "        [8.1126e+02, 2.0688e+02, 8.8633e-01, 2.5900e-02, 8.7773e-02],\n",
      "        [7.2587e+02, 1.9390e+02, 5.6016e-01, 3.6366e-01, 7.6183e-02],\n",
      "        [7.3547e+02, 2.1165e+02, 6.6340e-02, 3.1125e-01, 6.2241e-01],\n",
      "        [8.0656e+02, 1.8183e+02, 3.2324e-01, 6.5149e-01, 2.5272e-02],\n",
      "        [7.6664e+02, 2.4147e+02, 1.9211e-01, 6.2506e-01, 1.8284e-01],\n",
      "        [8.0536e+02, 2.3865e+02, 1.5926e-01, 5.5413e-01, 2.8661e-01],\n",
      "        [7.1186e+02, 1.8458e+02, 1.4165e-01, 4.1762e-03, 8.5418e-01],\n",
      "        [8.1020e+02, 1.2142e+02, 2.0957e-01, 1.4372e-01, 6.4672e-01],\n",
      "        [8.4917e+02, 1.4747e+02, 8.5546e-02, 6.9857e-01, 2.1588e-01],\n",
      "        [7.5234e+02, 1.3635e+02, 4.6919e-01, 5.1648e-01, 1.4333e-02],\n",
      "        [6.9711e+02, 1.0937e+02, 1.8953e-01, 3.4053e-02, 7.7641e-01],\n",
      "        [6.6515e+02, 1.3349e+02, 2.9291e-01, 1.0756e-01, 5.9953e-01],\n",
      "        [7.1215e+02, 1.1155e+02, 8.9856e-01, 9.1262e-02, 1.0180e-02],\n",
      "        [8.4040e+02, 1.2046e+02, 1.8431e-01, 6.6712e-01, 1.4857e-01],\n",
      "        [8.1371e+02, 2.3844e+02, 5.3921e-01, 9.6449e-03, 4.5114e-01],\n",
      "        [6.9865e+02, 2.4703e+02, 1.8315e-01, 3.0894e-01, 5.0791e-01],\n",
      "        [8.1405e+02, 1.4546e+02, 1.6010e-01, 2.7854e-01, 5.6135e-01]])\n",
      "tensor([[-0.0615],\n",
      "        [-0.0498],\n",
      "        [-0.1659],\n",
      "        [-0.0013],\n",
      "        [-0.1197],\n",
      "        [-0.0099],\n",
      "        [ 0.0392],\n",
      "        [ 0.0282],\n",
      "        [ 0.0746],\n",
      "        [-0.0290],\n",
      "        [-0.1257],\n",
      "        [-0.0728],\n",
      "        [-0.0191],\n",
      "        [-0.1656],\n",
      "        [-0.1375],\n",
      "        [-0.0037],\n",
      "        [ 0.0592],\n",
      "        [-0.1682],\n",
      "        [ 0.0171],\n",
      "        [-0.0315],\n",
      "        [-0.0829],\n",
      "        [-0.2348],\n",
      "        [-0.2568],\n",
      "        [-0.0867],\n",
      "        [ 0.0433],\n",
      "        [-0.2321],\n",
      "        [-0.1106],\n",
      "        [ 0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.1382],\n",
      "        [-0.0799],\n",
      "        [-0.2139]])\n",
      "tensor([[-0.0713],\n",
      "        [-0.0502],\n",
      "        [-0.1614],\n",
      "        [ 0.0058],\n",
      "        [-0.1220],\n",
      "        [-0.0095],\n",
      "        [ 0.0311],\n",
      "        [ 0.0264],\n",
      "        [ 0.0647],\n",
      "        [-0.0261],\n",
      "        [-0.1212],\n",
      "        [-0.0761],\n",
      "        [-0.0016],\n",
      "        [-0.1601],\n",
      "        [-0.1297],\n",
      "        [ 0.0011],\n",
      "        [ 0.0609],\n",
      "        [-0.1564],\n",
      "        [ 0.0006],\n",
      "        [-0.0253],\n",
      "        [-0.0789],\n",
      "        [-0.2308],\n",
      "        [-0.2528],\n",
      "        [-0.0880],\n",
      "        [ 0.0362],\n",
      "        [-0.2223],\n",
      "        [-0.1107],\n",
      "        [ 0.0503],\n",
      "        [-0.0664],\n",
      "        [-0.1253],\n",
      "        [-0.0850],\n",
      "        [-0.2129]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241eab8",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.1575, 0.1226, 0.1731, 0.1604, 0.1699], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0081,  0.0001,  0.0166,  0.0141,  0.0038], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.7705e-03,  4.6765e-02, -1.5921e-02, -1.3772e-01, -2.8893e-01],\n",
       "         [-1.3702e-02, -7.2420e-03, -1.3800e-01, -1.5010e-01, -1.3960e-01],\n",
       "         [ 4.0921e-02, -6.0476e-03,  1.3511e-01,  1.3927e-01,  1.0355e-01],\n",
       "         [-1.9964e-02, -2.4128e-02, -1.1672e-01, -1.5357e-01, -1.2191e-01],\n",
       "         [-1.3525e-02, -1.3791e-02, -1.1524e-01, -1.2758e-01, -1.0388e-01],\n",
       "         [-1.3545e-02, -2.2741e-02,  4.6581e-02,  1.4251e-02,  2.4601e-02],\n",
       "         [ 3.3141e-02, -5.4900e-02,  7.5903e-02,  9.3255e-04, -8.3045e-03],\n",
       "         [ 3.2510e-02, -3.2845e-02,  9.8996e-02,  1.2284e-01,  9.1005e-02],\n",
       "         [-2.8213e-02,  7.1741e-03,  6.3576e-02,  5.0254e-02,  5.3353e-02],\n",
       "         [ 2.1426e-02, -4.8359e-02,  1.3230e-02, -4.3137e-02, -3.9042e-02],\n",
       "         [-3.5743e-02,  2.8726e-02, -1.2977e-01, -1.1396e-01, -9.9350e-02],\n",
       "         [ 8.0413e-02, -5.8733e-02,  8.8585e-02,  7.9239e-02,  3.8787e-02],\n",
       "         [ 4.0580e-02, -2.2045e-02,  1.5187e-01,  1.2436e-01,  1.1037e-01],\n",
       "         [ 1.5669e-02, -1.5925e-02,  7.2765e-02,  8.9807e-02,  5.7887e-02],\n",
       "         [ 5.7838e-02, -2.0686e-02,  1.3720e-01,  1.3776e-01,  8.4187e-02],\n",
       "         [-3.5859e-02,  8.6551e-03, -5.4703e-01, -7.7038e-01, -4.9613e-01],\n",
       "         [ 2.3218e-02, -4.7923e-03,  5.6558e-02,  5.3338e-02,  3.5489e-02],\n",
       "         [ 2.2050e-02, -6.0538e-03, -6.5404e-03, -4.1361e-02, -3.4098e-02],\n",
       "         [ 1.3985e-02, -2.2821e-04,  9.3867e-03,  9.6096e-03, -1.8389e-03],\n",
       "         [-5.3137e-02,  5.1721e-02, -1.0401e-01, -1.2154e-01, -6.8099e-02],\n",
       "         [-3.6746e-03, -3.4172e-02,  7.2107e-02,  4.4769e-02,  4.9421e-02],\n",
       "         [ 1.0381e-02,  1.4350e-02,  7.0481e-02,  1.3228e-01,  1.0351e-01],\n",
       "         [-9.6071e-03, -1.0336e-02, -1.1144e-01, -1.2128e-01, -1.1503e-01],\n",
       "         [-8.0655e-03,  4.0250e-02, -7.4337e-02, -8.8466e-02, -6.7334e-02],\n",
       "         [ 4.1344e-02, -8.0923e-03,  1.3728e-01,  1.4992e-01,  1.1314e-01],\n",
       "         [-4.0404e-02, -8.7520e-03, -9.4523e-02, -1.0785e-01, -6.3866e-02],\n",
       "         [ 2.8371e-02, -3.4696e-03,  8.5457e-02,  1.3712e-01,  9.6787e-02],\n",
       "         [-5.7930e-02,  4.1161e-02, -8.1215e-02, -6.7533e-02, -3.3222e-02],\n",
       "         [ 4.6661e-03, -4.4154e-03,  8.1029e-02,  1.0914e-01,  9.2712e-02],\n",
       "         [-8.1784e-02,  4.4178e-02, -1.4177e-01, -1.3361e-01, -9.2770e-02],\n",
       "         [-2.7068e-02,  1.6400e-02, -1.1652e-01, -1.2353e-01, -1.0095e-01],\n",
       "         [-1.9956e-02,  1.1825e-02, -1.2133e-01, -1.0656e-01, -9.3093e-02],\n",
       "         [ 4.3391e-02, -8.0687e-02,  1.0449e-01,  5.1401e-02,  2.1372e-02],\n",
       "         [-2.8578e-02,  1.9217e-03, -1.9488e-02, -3.3641e-02, -1.9205e-03],\n",
       "         [-7.8430e-02,  3.9775e-02, -7.8152e-02, -6.3801e-02, -1.5008e-02],\n",
       "         [ 8.5641e-03,  1.7016e-02,  2.1791e-02,  7.0645e-02,  4.6380e-02],\n",
       "         [ 9.4343e-03,  7.1866e-03,  1.6713e-01,  1.7026e-01,  1.5892e-01],\n",
       "         [-9.0727e-04, -6.5472e-03,  3.4813e-02,  6.7818e-02,  4.4288e-02],\n",
       "         [-1.1582e-01,  4.5978e-02, -6.2006e-02, -1.6980e-01, -6.7456e-02],\n",
       "         [-2.8241e-02,  5.4671e-03, -3.0076e-02, -6.2811e-02, -2.5559e-02],\n",
       "         [-3.0660e-02, -1.0125e-02,  5.1317e-02,  9.6257e-02,  8.0350e-02],\n",
       "         [ 1.1924e-01, -7.6851e-02,  1.2355e-01,  9.0187e-02,  3.6247e-02],\n",
       "         [ 5.6247e-02, -6.3925e-03,  4.4357e-02,  1.6325e-02,  4.5203e-03],\n",
       "         [ 3.9670e-02, -2.0781e-02, -3.2385e-02, -2.6308e-02, -3.8299e-02],\n",
       "         [-2.8447e-02,  1.5210e-02, -6.9369e-02, -3.9418e-02, -3.1630e-02],\n",
       "         [-1.4198e-03, -4.5090e-04, -6.0260e-02, -8.8061e-02, -7.1217e-02],\n",
       "         [-6.1317e-03,  2.1081e-02,  4.8819e-02,  8.9646e-02,  6.9366e-02],\n",
       "         [-1.7459e-02,  5.1392e-02, -8.3407e-02, -6.4944e-02, -4.3542e-02],\n",
       "         [-1.2979e-02, -2.4157e-02, -1.2775e-02, -1.9271e-02, -3.6543e-03],\n",
       "         [ 4.4254e-02, -5.2296e-02,  7.3159e-02,  4.1684e-02,  2.2036e-02],\n",
       "         [-3.5884e-02,  1.7169e-02, -3.4100e-02, -4.7005e-02, -1.0037e-02],\n",
       "         [-3.7315e-02,  3.8322e-02, -7.4321e-02,  7.7291e-03,  4.6144e-03],\n",
       "         [ 2.9775e-02, -4.6784e-02,  9.4764e-02,  5.3909e-02,  3.1211e-02],\n",
       "         [ 3.7259e-02, -1.4040e-02,  2.4170e-02,  7.4390e-03, -9.2133e-03],\n",
       "         [-4.2351e-02,  2.0773e-02, -7.1413e-02, -6.2571e-02, -2.7659e-02],\n",
       "         [ 1.6346e-02,  6.8657e-03,  7.1690e-02,  7.2903e-02,  5.2747e-02],\n",
       "         [ 4.6986e-03, -4.5059e-02,  4.0995e-02, -1.9329e-02, -1.0080e-02],\n",
       "         [-5.1660e-02, -2.2298e-03, -1.4805e-02,  1.4773e-02,  1.0067e-02],\n",
       "         [-1.3500e-02,  4.0043e-02,  1.8369e-02,  4.6419e-02,  4.2939e-02],\n",
       "         [-2.3519e-02, -1.2806e-02,  5.1455e-02,  3.4799e-02,  3.9739e-02],\n",
       "         [ 2.4642e-03,  1.6460e-02,  2.4207e-02, -3.6219e-02,  9.2901e-03],\n",
       "         [ 7.3346e-03,  7.3974e-03,  6.8821e-02,  5.8322e-02,  6.0943e-02],\n",
       "         [ 1.0581e-02, -8.5159e-03,  3.0830e-02, -1.5961e-02,  3.7555e-03],\n",
       "         [-3.3294e-02,  3.7036e-02, -2.1640e-02, -7.8870e-03,  1.8507e-02],\n",
       "         [ 5.6965e-02, -6.1739e-02,  6.3187e-02,  4.7245e-02,  1.6458e-02],\n",
       "         [ 5.4543e-03,  1.1205e-02, -5.8211e-02, -3.9247e-02, -4.0676e-02],\n",
       "         [-5.0647e-02,  6.7451e-03,  3.2537e-02,  3.8909e-02,  4.8044e-02],\n",
       "         [ 2.7894e-02, -3.5849e-02,  8.7646e-02,  7.7776e-02,  4.2970e-02],\n",
       "         [ 3.7776e-02, -2.7979e-03,  4.9248e-02,  9.6146e-02,  5.8023e-02],\n",
       "         [-2.2439e-02,  5.3013e-03, -8.7326e-02, -1.0660e-01, -7.5174e-02],\n",
       "         [ 1.1724e-02,  2.1451e-03,  2.1165e-03,  4.1038e-02,  1.1426e-02],\n",
       "         [-6.8171e-02,  4.7555e-02, -2.8900e-02, -1.3029e-01, -5.6684e-02],\n",
       "         [ 1.6585e-02,  1.1086e-02, -2.3081e-02, -2.5626e-02, -3.0035e-02],\n",
       "         [-4.3333e-02,  3.5466e-02, -6.1099e-02, -7.6665e-02, -3.1108e-02],\n",
       "         [ 1.7788e-02,  1.1249e-01, -1.4873e-01, -1.5002e-01, -1.7706e-01],\n",
       "         [-3.3848e-02,  2.1908e-02, -1.2142e-01, -1.2969e-01, -9.4551e-02],\n",
       "         [ 5.4772e-03, -1.4824e-02,  1.3083e-02, -3.0186e-02, -2.2614e-02],\n",
       "         [ 9.7245e-03,  4.2357e-02,  6.4519e-02,  1.1095e-01,  1.0265e-01],\n",
       "         [ 4.9687e-02, -2.3260e-02,  1.1967e-01,  1.2110e-01,  8.9714e-02],\n",
       "         [ 2.8268e-03, -2.6539e-03,  2.0353e-01,  2.2035e-01,  2.0280e-01],\n",
       "         [ 5.2842e-02, -1.3344e-02,  8.9158e-02,  7.3274e-02,  4.3996e-02],\n",
       "         [ 2.3586e-03,  3.4475e-02, -3.8993e-02,  1.1252e-02, -7.5727e-03],\n",
       "         [ 6.7972e-03,  1.7649e-02, -2.5041e-02, -4.6634e-03, -1.4103e-02],\n",
       "         [-1.3808e-02,  7.1635e-03,  7.8332e-02,  7.9135e-02,  7.1912e-02],\n",
       "         [ 3.1200e-01, -4.7661e-02, -3.3761e-01,  3.4719e-01, -4.5224e-03],\n",
       "         [ 6.1723e-03,  1.8969e-02,  6.4699e-02,  7.3275e-02,  5.9481e-02],\n",
       "         [ 2.1597e-02, -1.9649e-03,  1.2388e-01,  1.1781e-01,  1.1280e-01],\n",
       "         [-3.8393e-03, -1.2116e-02,  8.5972e-02,  7.5792e-02,  7.1571e-02],\n",
       "         [ 3.8993e-02, -2.6368e-02,  1.1218e-01,  1.0029e-01,  7.4982e-02],\n",
       "         [-2.9980e-02,  9.7150e-03, -7.0753e-02, -7.7615e-02, -4.2165e-02],\n",
       "         [-1.2304e-02, -2.9310e-02,  4.7038e-02,  4.4246e-02,  3.0529e-02],\n",
       "         [-4.1737e-02,  2.3388e-02, -4.8870e-02, -1.9567e-02,  1.7130e-02],\n",
       "         [-3.0419e-02,  9.7294e-03,  2.6678e-02,  1.9882e-02,  3.0676e-02],\n",
       "         [ 4.2916e-02, -4.9642e-02,  1.1008e-01,  7.3310e-02,  4.7341e-02],\n",
       "         [-9.2489e-03, -3.5102e-03,  5.5391e-02,  4.9444e-02,  5.6108e-02],\n",
       "         [ 1.9991e-02, -3.0863e-02, -6.6310e-02, -5.9638e-02, -6.7223e-02],\n",
       "         [-1.5143e-02,  1.7534e-02, -6.8141e-02, -1.0860e-01, -7.7858e-02],\n",
       "         [-5.5222e-03,  1.5192e-02,  7.8840e-02,  1.1145e-01,  9.1678e-02],\n",
       "         [ 3.3616e-02,  1.0177e-02, -2.9741e-02, -5.8864e-02, -4.3045e-02],\n",
       "         [ 5.5025e-02, -1.8503e-02, -3.8218e-04,  1.4937e-01,  5.8373e-02],\n",
       "         [ 2.1997e-02,  2.9689e-03,  1.1407e-01,  1.4100e-01,  1.0069e-01],\n",
       "         [-2.8237e-03, -6.2143e-03,  5.5564e-02,  4.6560e-02,  3.5802e-02],\n",
       "         [-3.9386e-02,  2.0021e-02, -1.1497e-01, -1.2659e-01, -9.0051e-02],\n",
       "         [-4.4762e-04, -1.4162e-02, -6.9243e-02, -9.1370e-02, -7.9212e-02],\n",
       "         [-2.6284e-03, -6.9196e-03,  3.7645e-02,  8.0425e-02,  6.1856e-02],\n",
       "         [ 1.2853e-02,  2.0728e-02,  1.2424e-01,  1.7317e-01,  1.3580e-01],\n",
       "         [-5.7385e-02,  6.0836e-02, -8.3180e-02, -1.1107e-01, -3.6429e-02],\n",
       "         [-7.2848e-02,  4.8225e-02, -9.9352e-02, -7.6548e-02, -3.4472e-02],\n",
       "         [-4.0536e-03,  1.2250e-02,  7.4163e-02,  1.1095e-01,  8.8179e-02],\n",
       "         [-4.4515e-03, -1.0309e-02,  7.6459e-02,  1.0689e-01,  8.7928e-02],\n",
       "         [ 3.8261e-02, -4.6917e-03, -2.6348e-02, -4.9255e-02, -4.9172e-02],\n",
       "         [-4.4196e-02, -3.3372e-02,  7.0248e-03,  3.1839e-02,  2.9156e-02],\n",
       "         [ 2.0119e-03, -2.5387e-03, -4.0046e-02, -8.3285e-02, -6.1593e-02],\n",
       "         [-1.1661e-03, -2.2975e-02, -7.5795e-04, -4.2287e-02, -3.5535e-02],\n",
       "         [ 1.0738e-03,  1.1248e-02, -6.6631e-02, -7.7701e-02, -6.7862e-02],\n",
       "         [-1.1613e-02,  5.0437e-02, -9.2854e-02, -6.2003e-02, -4.7669e-02],\n",
       "         [ 2.6901e-02,  2.0659e-02, -3.7381e-02, -1.5617e-02, -1.7736e-02],\n",
       "         [-6.6820e-02,  2.7365e-02, -8.2215e-02, -6.9625e-02, -2.7271e-02],\n",
       "         [-1.5540e-03, -1.1808e-02, -1.4580e-01, -1.1381e-01, -1.1905e-01],\n",
       "         [-1.1246e-02,  1.9714e-03, -2.1899e-02, -2.6723e-02, -9.0304e-03],\n",
       "         [-4.5300e-03, -8.4207e-04, -8.1200e-02, -9.3848e-02, -8.1549e-02],\n",
       "         [ 2.9541e-02, -1.9495e-02, -5.9150e-02, -9.9428e-02, -8.6540e-02],\n",
       "         [ 8.3467e-02, -3.8253e-02,  1.0494e-01,  6.3172e-02,  3.9378e-02],\n",
       "         [-1.8184e-02, -3.5356e-03, -1.5712e-01, -1.8981e-01, -1.6024e-01],\n",
       "         [ 1.7212e-02, -2.6509e-02, -8.6916e-03, -3.4814e-02, -3.3253e-02],\n",
       "         [ 8.3518e-02, -4.5529e-02,  1.2206e-01,  8.1155e-02,  3.8843e-02],\n",
       "         [-3.2083e-03, -1.4398e-02,  1.0243e-02, -3.5003e-02, -1.6207e-02],\n",
       "         [-1.3193e-02,  6.5255e-03,  6.8274e-02,  5.8192e-02,  5.6039e-02],\n",
       "         [-1.0769e-02, -2.3344e-02,  5.9286e-02,  3.6342e-02,  4.9176e-02],\n",
       "         [-8.1116e-05,  2.1097e-02, -7.1153e-02, -7.7948e-02, -7.0382e-02],\n",
       "         [ 3.1845e-02,  5.5383e-03, -1.8555e-02, -2.6170e-02, -2.5810e-02],\n",
       "         [ 7.3058e-03, -2.8371e-02,  5.7940e-02,  3.6292e-02,  2.8068e-02],\n",
       "         [-3.5826e-02,  1.5816e-02, -1.1072e-01, -1.2139e-01, -8.1479e-02],\n",
       "         [-6.7294e-03, -1.1363e-02, -7.7530e-03, -6.9030e-02, -3.5690e-02],\n",
       "         [-8.5244e-03,  3.2619e-03,  7.9860e-02,  7.8222e-02,  7.7773e-02],\n",
       "         [-3.5598e-02,  1.1203e-02, -1.3088e-01, -1.7100e-01, -1.3461e-01],\n",
       "         [ 1.2179e-02, -2.4276e-02,  7.4261e-02,  4.9515e-02,  3.7176e-02],\n",
       "         [-4.5733e-02,  2.1702e-02, -1.0120e-01, -1.0196e-01, -7.7566e-02],\n",
       "         [-8.4168e-02,  1.0333e-01, -1.9409e-01, -2.5881e-01, -1.9232e-01],\n",
       "         [ 2.7493e-02, -2.6700e-02,  4.2825e-02,  3.5056e-02,  1.3761e-02],\n",
       "         [-1.3446e-02,  3.9989e-02, -1.4634e-02,  3.4517e-02,  2.7543e-02],\n",
       "         [ 3.5113e-02, -1.4694e-02,  5.4383e-01, -6.6076e-02, -1.0094e+00],\n",
       "         [ 9.1370e-03,  1.3394e-02, -5.5638e-02, -4.8652e-02, -3.7042e-02],\n",
       "         [ 2.7390e-02,  4.6295e-02,  3.3229e-02,  4.1454e-02,  2.7402e-02],\n",
       "         [-1.3936e-02,  2.2537e-02, -8.3787e-02, -1.3902e-02, -5.2487e-03],\n",
       "         [-9.1874e-02,  9.6573e-02, -1.1822e-01, -7.0056e-02, -2.1162e-02],\n",
       "         [ 1.0707e-01, -1.0136e-01,  2.9248e-01,  4.1688e-01,  2.4901e-01],\n",
       "         [-2.3085e-02, -3.8094e-03, -9.1301e-02, -1.1753e-01, -8.8374e-02],\n",
       "         [ 4.2702e-02, -1.3640e-02, -7.1724e-02, -6.8796e-02, -7.2593e-02],\n",
       "         [-1.9914e-02,  1.1396e-02, -7.7083e-02, -5.9551e-02, -4.6688e-02],\n",
       "         [ 8.5160e-02, -6.6346e-02,  1.0189e-01,  9.8943e-02,  3.2012e-02],\n",
       "         [-6.0383e-02,  4.0350e-02, -1.3039e-01, -1.2333e-01, -8.1226e-02],\n",
       "         [-1.4817e-02,  2.6518e-02, -7.2135e-02, -8.1391e-02, -5.0915e-02],\n",
       "         [ 2.4977e-02, -2.5311e-02,  1.5586e-02,  8.8589e-02,  3.4421e-02],\n",
       "         [-9.9409e-03, -2.0315e-03, -3.4890e-02, -2.8629e-02, -1.8762e-02],\n",
       "         [-1.9063e-02,  1.6479e-02, -2.1592e-02, -1.3082e-02,  7.5603e-03],\n",
       "         [-2.1985e-02,  1.5748e-02, -4.1720e-02, -3.1374e-02, -1.6382e-02],\n",
       "         [ 6.4861e-03,  5.7948e-03, -6.4496e-02, -1.0296e-01, -8.3797e-02],\n",
       "         [ 7.4710e-04,  3.5972e-04,  3.2046e-02,  4.2218e-02,  3.2603e-02],\n",
       "         [-1.1522e-02,  2.9870e-02, -7.8468e-02, -7.3035e-02, -5.7714e-02],\n",
       "         [ 4.2121e-02, -2.4424e-02,  3.4199e-02,  2.1666e-02, -3.2965e-03],\n",
       "         [ 5.5426e-03, -1.9238e-02,  4.3417e-02,  2.0634e-02,  3.1375e-02],\n",
       "         [-2.6548e-02, -4.1618e-03, -9.6738e-02, -1.0152e-01, -8.7190e-02],\n",
       "         [ 2.0013e-02, -1.2541e-03,  1.0561e-01,  1.1364e-01,  8.1918e-02],\n",
       "         [ 4.6634e-02,  1.0110e-03, -3.1424e-02, -5.4803e-02, -4.6823e-02],\n",
       "         [ 8.0095e-02, -4.6237e-02,  1.2754e-01,  1.2210e-01,  6.9891e-02],\n",
       "         [ 6.7818e-03, -5.9167e-02,  2.0539e-01,  2.0674e-01,  2.0664e-01],\n",
       "         [ 8.5058e-03,  1.0133e-02,  2.0519e-02,  1.2609e-01,  7.8476e-02],\n",
       "         [ 4.7786e-02, -2.2894e-02,  1.2334e-01,  1.7389e-01,  1.1541e-01],\n",
       "         [-3.7148e-01,  2.3889e-01,  9.7215e-01,  3.9862e-01,  3.2342e-01],\n",
       "         [ 3.7824e-02, -1.0387e-03, -3.2261e-02, -2.1028e-02, -2.7106e-02],\n",
       "         [ 2.5280e-02, -2.1560e-02,  1.1047e-01,  1.1144e-01,  9.9751e-02],\n",
       "         [ 3.9029e-02, -9.3043e-03, -3.2435e-02, -4.6668e-02, -4.4141e-02],\n",
       "         [ 1.8928e-02,  2.1968e-02, -3.9752e-02, -3.2565e-02, -4.1209e-02],\n",
       "         [ 1.0849e-02, -3.2910e-02,  1.7794e-01,  2.0315e-01,  1.8504e-01],\n",
       "         [ 1.5208e-02,  4.9424e-03,  1.7724e-01,  1.9842e-01,  1.7648e-01],\n",
       "         [ 3.1228e-03, -2.1607e-02, -5.5505e-02, -8.5118e-02, -7.3730e-02],\n",
       "         [-4.1729e-02, -2.1830e-02, -7.0911e-02, -9.5537e-02, -5.3848e-02],\n",
       "         [-2.9743e-03, -1.2555e-02, -5.7057e-02, -7.8414e-02, -6.7917e-02],\n",
       "         [ 1.6830e-02,  1.1978e-02, -7.7909e-02, -2.2165e-02, -4.0220e-02],\n",
       "         [ 2.2293e-02, -2.9617e-02,  8.7763e-02,  8.3258e-02,  7.1356e-02],\n",
       "         [ 2.5326e-02,  2.1388e-02,  1.4892e-01,  1.5365e-01,  1.3351e-01],\n",
       "         [ 2.8332e-02, -2.2270e-02,  1.4818e-01,  1.6597e-01,  1.4223e-01],\n",
       "         [ 1.3859e-02,  4.1119e-03,  9.5901e-02,  1.1603e-01,  9.0142e-02],\n",
       "         [ 2.3385e-02,  6.1966e-03,  9.0240e-02,  1.2211e-01,  8.5813e-02],\n",
       "         [ 2.6991e-02,  1.5368e-02, -5.4646e-02, -6.2582e-02, -4.9724e-02],\n",
       "         [ 1.8351e-02,  1.7627e-02,  8.9600e-02,  1.2456e-01,  9.5347e-02],\n",
       "         [-3.0533e-02,  3.6844e-03, -7.6853e-04, -1.1691e-03,  4.8425e-03],\n",
       "         [ 1.7793e-02, -1.7250e-02,  3.3234e-02,  3.0974e-02,  2.0418e-02],\n",
       "         [ 2.7152e-02, -3.6728e-02,  5.1480e-02,  8.3257e-02,  4.4211e-02],\n",
       "         [-3.6650e-02,  2.4232e-02,  1.1080e-02,  2.3082e-02,  2.9615e-02],\n",
       "         [ 4.6381e-02, -3.6074e-02,  6.6528e-02,  3.0700e-02,  1.4119e-02],\n",
       "         [-4.7948e-02,  1.4777e-02, -1.3785e-01, -1.5219e-01, -1.2253e-01],\n",
       "         [ 1.3112e-02,  2.2803e-02,  8.2038e-02,  1.2219e-01,  9.9295e-02],\n",
       "         [-2.5947e-03,  2.0589e-02,  1.9969e-03,  4.8468e-02,  5.1739e-02],\n",
       "         [ 8.9330e-01, -3.9518e-01,  1.8604e-01, -7.8641e-01,  3.8323e-01],\n",
       "         [ 3.4287e-03,  1.6979e-02, -3.5902e-02,  1.3280e-03, -1.7754e-02],\n",
       "         [ 8.7098e-02, -9.1012e-02,  1.9123e-01,  3.6710e-01,  2.7422e-01],\n",
       "         [ 1.4038e-02, -2.1594e-02, -1.9333e-02, -4.3075e-02, -5.3800e-02],\n",
       "         [ 2.4163e-02, -5.2233e-03,  1.3451e-01,  1.2535e-01,  1.1565e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 9.3084e-03,  5.4256e-04,  1.0030e-02, -4.1252e-03, -3.4105e-03,\n",
       "         -2.9541e-03,  8.0076e-03,  7.9131e-03, -2.9841e-03,  3.8171e-03,\n",
       "         -2.4510e-03,  1.4152e-02,  2.9348e-03,  6.4627e-03,  1.6906e-02,\n",
       "         -1.0819e-03,  1.7066e-03,  1.4732e-03,  1.9958e-03, -2.0805e-02,\n",
       "         -2.3966e-03,  1.7273e-03,  2.0543e-03, -6.0110e-03,  8.8765e-03,\n",
       "         -1.0350e-02,  8.0070e-03, -1.2434e-02, -4.5066e-04, -1.3431e-02,\n",
       "         -5.2988e-03, -2.3845e-03,  1.2637e-02, -1.0008e-02, -2.1469e-02,\n",
       "          3.3382e-03, -4.0423e-04,  3.6849e-03, -2.5555e-02, -9.6680e-03,\n",
       "         -8.8367e-04,  2.4903e-02,  4.9101e-03,  5.2574e-03, -1.2269e-03,\n",
       "         -2.5809e-03,  3.5803e-04, -4.8413e-03, -2.9885e-03,  7.7584e-03,\n",
       "         -9.5258e-03, -5.3927e-03,  7.2755e-03,  7.2017e-03, -4.8339e-03,\n",
       "          3.6022e-03, -1.6139e-03, -2.6530e-03, -1.9034e-03, -2.5736e-03,\n",
       "         -9.6490e-03, -3.3197e-03, -4.1590e-03, -1.3039e-02,  1.4086e-02,\n",
       "          1.6677e-03, -7.3270e-03,  1.0286e-02,  8.2487e-03, -8.5823e-03,\n",
       "          5.8836e-03, -1.9178e-02,  2.1003e-03, -1.5094e-02,  1.6444e-02,\n",
       "         -1.1268e-02,  1.2591e-03, -3.2059e-03,  7.1118e-03, -4.1647e-04,\n",
       "          5.2723e-03,  3.9711e-03,  2.1134e-03, -1.3933e-03,  1.3893e-03,\n",
       "          2.6562e-03, -1.0449e-03, -1.5091e-03,  8.1963e-03, -1.0421e-02,\n",
       "          1.9793e-03, -1.5471e-02, -4.6920e-03,  8.5659e-03, -4.2599e-03,\n",
       "          4.9555e-03, -6.4156e-03,  1.0975e-03, -5.4373e-04,  1.5687e-02,\n",
       "          8.6522e-03,  2.7779e-03, -8.6153e-03,  8.3543e-04,  1.3984e-03,\n",
       "          4.7348e-03, -2.7045e-02, -1.5371e-02,  2.2268e-03, -1.8808e-04,\n",
       "          4.1197e-03, -2.0045e-03, -2.7655e-03, -5.5918e-04,  7.7165e-04,\n",
       "         -3.5141e-03,  2.6047e-03, -1.2704e-02,  1.1328e-04, -5.3179e-03,\n",
       "          4.5887e-04,  2.0776e-03,  8.1177e-03, -4.5121e-03,  1.8057e-03,\n",
       "          1.3600e-02, -4.6548e-03, -1.4092e-03, -4.9155e-03,  9.5580e-04,\n",
       "          3.4922e-03,  5.9690e-04, -1.1835e-02, -6.2422e-03, -2.4387e-03,\n",
       "         -1.0084e-02,  3.8322e-03, -3.5167e-03, -2.8657e-03,  1.7140e-03,\n",
       "         -8.9639e-04, -8.6506e-03, -2.0680e-03,  2.5617e-03, -2.9179e-03,\n",
       "         -2.2577e-02,  3.5552e-03, -5.1394e-03,  3.8064e-03, -1.6635e-03,\n",
       "          2.4091e-02, -1.7871e-02, -7.9958e-03,  1.5722e-02,  3.8611e-04,\n",
       "         -7.2188e-03, -1.0850e-03,  1.0778e-06,  9.3782e-04, -2.1950e-03,\n",
       "          7.5533e-03, -5.7654e-03, -1.1499e-03,  6.7555e-03,  2.7484e-03,\n",
       "          2.0148e-02, -2.4964e-03,  4.9634e-03,  1.8078e-02,  2.5077e-02,\n",
       "          2.8785e-03,  1.2395e-03,  3.3260e-03,  3.6721e-03,  2.5426e-05,\n",
       "          2.1332e-03, -2.9285e-04, -6.8803e-03,  5.2607e-04,  4.0147e-03,\n",
       "          1.1962e-04,  1.6771e-03,  6.7743e-03,  4.3109e-03,  7.9554e-03,\n",
       "          1.3087e-04,  4.2083e-03, -2.8492e-03,  3.7370e-04,  8.7866e-03,\n",
       "         -5.7576e-03,  7.2898e-03, -7.4433e-03,  2.2488e-03, -4.2825e-03,\n",
       "          3.1165e-02,  5.9356e-03, -7.2037e-03,  6.5278e-03,  7.1258e-04],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0157, -0.0675,  0.0042,  ..., -0.0148,  0.0503, -0.0407],\n",
       "         [ 0.0568,  0.0153, -0.0085,  ...,  0.1138,  0.0047, -0.0536],\n",
       "         [ 0.0114, -0.0010, -0.0087,  ..., -0.1123, -0.0029, -0.0175],\n",
       "         ...,\n",
       "         [-0.0360, -0.0174,  0.0246,  ..., -0.0678, -0.0045, -0.0193],\n",
       "         [ 0.2875, -0.0114,  0.0408,  ..., -0.5442,  0.0430, -0.0191],\n",
       "         [-0.0471,  0.0107, -0.0152,  ...,  0.0194,  0.0716, -0.0018]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.5867e-03,  1.3379e-02, -4.1660e-03,  1.7318e-03,  6.3161e-03,\n",
       "          1.0077e-02, -2.2253e-04,  2.5309e-02, -8.2151e-03,  4.6735e-03,\n",
       "          4.4624e-03, -4.3998e-03, -2.9444e-03,  7.7602e-03, -6.7190e-03,\n",
       "         -3.7971e-03, -1.8701e-04,  1.5226e-03, -1.4436e-02, -3.6492e-03,\n",
       "          2.6458e-03,  3.6485e-03,  4.3539e-04, -1.2557e-02, -5.3752e-03,\n",
       "          2.9728e-02,  5.8308e-03, -1.3756e-02, -1.0921e-02,  1.7285e-02,\n",
       "         -1.0242e-02,  3.0310e-02,  2.4720e-02, -1.4089e-02, -1.3167e-02,\n",
       "         -1.2892e-02,  1.0795e-02,  3.2578e-03, -6.3074e-05,  3.1253e-03,\n",
       "         -3.6995e-03,  8.7199e-04, -8.6386e-03, -2.3797e-02, -2.6025e-03,\n",
       "         -8.4560e-03,  1.0847e-02,  9.0305e-03,  8.8125e-03, -2.0351e-02,\n",
       "          1.0270e-02, -1.5633e-02, -2.7184e-02, -5.2037e-03,  8.8129e-03,\n",
       "         -9.7820e-03,  9.0521e-03, -4.3079e-03,  2.8346e-02, -1.0394e-02,\n",
       "          1.1036e-03,  8.5224e-03, -6.1065e-03, -5.0528e-03,  2.7136e-03,\n",
       "         -2.1427e-02,  1.2949e-02,  7.1512e-03, -1.6449e-03,  4.1316e-03,\n",
       "          3.1093e-03, -4.4572e-03, -2.3363e-02, -4.9942e-03, -8.4184e-03,\n",
       "         -1.4950e-02,  1.3914e-02, -1.9666e-02, -9.1921e-02,  7.4012e-03,\n",
       "         -1.5678e-02,  9.3740e-04, -2.0385e-02, -3.7807e-03,  5.0603e-03,\n",
       "          2.8755e-03,  9.0072e-03,  1.3769e-02,  7.6051e-03, -2.9439e-03,\n",
       "         -4.9020e-03,  2.1854e-02, -1.8434e-02, -4.9370e-03, -2.6245e-03,\n",
       "         -1.4327e-02,  1.0405e-02, -1.9923e-02,  2.0009e-03, -7.0881e-03,\n",
       "          7.4309e-03,  7.9670e-03,  1.0935e-03,  1.6176e-03, -4.8511e-03,\n",
       "         -3.8650e-02, -9.6422e-03, -1.8187e-03,  9.7165e-03, -1.8587e-02,\n",
       "          9.8117e-03, -1.2136e-03, -9.1901e-03, -1.4357e-02,  9.9387e-03,\n",
       "          1.6715e-02, -2.8853e-03, -2.8920e-02,  1.8235e-02,  6.0143e-03,\n",
       "          2.3556e-02,  5.8831e-03,  1.4621e-02,  2.2708e-02,  7.2871e-03,\n",
       "         -1.5801e-02, -1.5087e-03,  8.4131e-03,  6.1649e-03, -8.5873e-03,\n",
       "          3.3914e-03,  1.9485e-02,  2.7079e-03,  1.1639e-03,  5.8818e-04,\n",
       "          2.3424e-03, -7.8740e-03,  1.2818e-02, -1.2806e-02,  6.8720e-03,\n",
       "         -9.5739e-03,  8.4938e-03,  9.1322e-03, -1.2918e-03, -2.0621e-02,\n",
       "          1.3528e-02, -9.2755e-04, -6.0580e-03,  4.1826e-03, -3.9337e-02,\n",
       "         -2.8131e-02,  3.9424e-03,  4.1621e-03,  5.4595e-03, -2.0379e-02,\n",
       "         -6.9596e-03,  3.0168e-03,  9.7031e-04,  3.7593e-04,  1.3861e-02,\n",
       "          1.2955e-02,  5.1135e-03,  6.0063e-03, -1.2704e-01, -1.2496e-02,\n",
       "          1.4646e-02, -1.8008e-03,  1.3425e-03, -2.8364e-03,  2.9549e-03,\n",
       "          1.2492e-02, -4.6088e-03,  1.5698e-02,  4.9276e-03,  9.4380e-03,\n",
       "          8.4063e-03,  7.4766e-03, -4.1074e-05,  2.5191e-03, -5.8981e-03,\n",
       "         -1.3381e-02, -8.4439e-03,  6.3191e-03, -4.6728e-03, -2.7220e-04,\n",
       "         -2.0264e-02, -7.1267e-04,  7.5867e-03, -3.5295e-03,  1.0339e-02,\n",
       "         -1.0503e-02, -1.2675e-02, -2.4809e-03, -7.0960e-03, -5.8433e-03,\n",
       "          1.7638e-02, -1.1935e-02, -5.8529e-03, -1.4440e-01, -1.2763e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0274, -0.0365, -0.0346,  ...,  0.0100, -0.0065,  0.0229],\n",
       "         [ 0.0120, -0.0568,  0.0091,  ..., -0.0305, -0.0068,  0.0457],\n",
       "         [-0.0061,  0.0083, -0.0036,  ..., -0.0023,  0.0036, -0.0240],\n",
       "         ...,\n",
       "         [-0.0265,  0.0149, -0.0356,  ..., -0.0222, -0.0011, -0.0105],\n",
       "         [-0.0285,  0.0316,  0.0135,  ...,  0.0272, -0.0049,  0.0006],\n",
       "         [-0.0407,  0.0288, -0.0163,  ..., -0.0355, -0.0086,  0.0321]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.3055e-02, -3.2838e-03, -6.8787e-03, -3.7385e-03, -3.6478e-03,\n",
       "         -3.7982e-03,  6.5291e-05,  2.0163e-03,  4.4492e-03,  4.1947e-03,\n",
       "          5.8688e-03, -1.8445e-02, -5.7015e-03, -1.1446e-02,  4.0441e-03,\n",
       "         -1.4389e-03, -2.5659e-04, -1.0440e-03,  8.7336e-04,  2.1039e-02,\n",
       "          1.6027e-02, -1.3576e-02, -1.2981e-03, -1.4019e+00, -5.6383e-04,\n",
       "         -1.3274e-02,  3.9097e-03,  5.4057e-03, -9.8957e-03, -1.1827e-02,\n",
       "         -8.1678e-03, -2.5867e-02,  1.3802e-03, -7.8846e-03,  9.1861e-04,\n",
       "          4.4586e-03, -5.0944e-03, -6.4717e-03, -4.0693e-03,  2.9466e-03,\n",
       "         -4.7390e-03,  1.2267e-02,  2.6403e-03,  1.6791e-02, -6.4032e-03,\n",
       "         -4.1666e-03,  2.1655e-02, -4.5913e-04, -9.7801e-03,  9.3617e-03,\n",
       "         -4.7016e-02,  7.7545e-03, -3.0944e-03, -8.4413e-03, -2.1559e-03,\n",
       "         -1.9162e-03,  4.1128e-03, -1.3567e-02,  6.8736e-03,  1.2181e-03,\n",
       "         -4.0818e-03,  7.1736e-03,  6.3327e-03, -6.2942e-03, -2.5455e-03,\n",
       "          8.3940e-03,  4.9137e-03, -7.5309e-03,  7.2861e-03, -1.2682e-02,\n",
       "         -8.0765e-03, -2.2428e-02, -4.4343e-04,  2.3469e-03, -7.9391e-03,\n",
       "          1.8631e-03,  1.3090e-02, -1.1040e-02, -9.3465e-03,  5.7405e-04,\n",
       "         -6.0659e-03,  1.2969e-03,  8.3176e-03, -2.1885e-02, -4.3944e-03,\n",
       "          2.6557e-02,  9.5574e-03,  1.3352e-02, -6.6952e-03,  3.5356e-03,\n",
       "         -1.8735e-02, -6.8315e-03, -5.2640e-03, -1.9052e-02, -5.8412e-05,\n",
       "          6.3327e-03,  1.2933e-02,  4.4759e-03, -9.4868e-04, -1.4075e-02,\n",
       "          1.1257e-02, -5.4552e-03,  4.4472e-03, -7.2102e-03,  5.3993e-03,\n",
       "          1.4680e-02, -1.2149e-02, -1.3745e-02,  1.0009e-02, -1.0367e-02,\n",
       "         -9.5803e-03, -1.6478e-03,  6.2392e-04,  1.2254e-03, -1.2935e-03,\n",
       "         -1.4236e-02,  1.5377e-03, -1.9637e-02, -4.6309e-03, -1.0100e-02,\n",
       "         -1.7197e-02,  3.6306e-03, -9.9582e-03, -2.9927e-04,  8.0655e-06,\n",
       "         -8.7008e-03, -9.0056e-03, -1.6604e-02,  5.8103e-04, -6.2088e-04,\n",
       "         -2.0191e-02, -7.3301e-03, -6.3271e-03,  3.8054e-03, -6.3490e-03,\n",
       "         -2.3799e-03, -1.7857e-03,  1.1035e-02, -8.6382e-03, -4.2143e-03,\n",
       "         -1.6073e-02,  2.2973e-01, -2.7451e-03,  3.5186e-03,  2.6873e-03,\n",
       "          1.6091e-02, -3.6719e-03, -1.7448e-02, -6.2532e-03, -1.3645e-02,\n",
       "          2.7980e-04, -6.7334e-03, -3.5700e-03,  4.0515e-03,  1.4724e-03,\n",
       "          2.7188e-03,  1.0088e-02, -9.5394e-04,  1.2568e-02,  1.1836e-02,\n",
       "          1.2468e-02, -1.3813e-03, -5.2039e-03, -1.0890e-02,  7.7866e-03,\n",
       "         -4.1591e-03, -1.1710e-03, -1.6397e-02,  1.8185e-02,  6.3454e-03,\n",
       "          2.4557e-02,  7.8445e-03, -1.0101e-02, -1.0662e-02, -1.4269e-02,\n",
       "          3.1482e-03, -2.6892e-03, -5.9068e-04,  1.0392e-02, -2.3883e-03,\n",
       "          1.4332e-02,  4.7066e-03, -1.1525e-02,  7.8490e-04,  1.3589e-01,\n",
       "          7.3951e-03,  1.0031e-02,  1.8267e-03,  2.0161e-03, -1.8682e-02,\n",
       "         -1.6037e-02, -4.1848e-03,  6.6322e-03, -1.0777e-02, -3.6464e-03,\n",
       "          4.6504e-03,  1.8364e-03,  5.6430e-03,  5.0415e-03, -2.2217e-03],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.0431e-03,  8.2700e-04,  2.2384e-04, -7.9142e-04,  3.4864e-03,\n",
       "          -5.2756e-04,  6.8827e-04, -1.6071e-03,  1.5657e-03,  2.6501e-03,\n",
       "          -4.2213e-04,  9.2937e-03, -9.2331e-04, -1.0291e-04,  1.2206e-04,\n",
       "           2.0046e-05,  9.5043e-05,  1.6811e-03,  1.3448e-04, -1.4832e-03,\n",
       "          -6.3174e-03,  6.8390e-03,  2.5326e-03, -1.1445e-01,  3.1750e-03,\n",
       "           1.0830e-03, -3.1561e-03, -6.1417e-04,  3.5798e-03,  5.3468e-03,\n",
       "           5.2334e-04,  4.8264e-03,  1.6506e-03,  2.1968e-03,  1.1880e-04,\n",
       "           2.5132e-05, -1.4793e-04, -1.1872e-04, -2.0134e-03, -1.4613e-03,\n",
       "           3.8420e-03, -6.2786e-03, -1.4472e-05, -8.5732e-03,  4.4184e-03,\n",
       "          -4.0691e-04, -6.9739e-03,  2.4239e-03,  1.8914e-03,  1.6756e-04,\n",
       "          -7.0404e-02, -1.5245e-03, -1.2356e-04,  8.6419e-04, -1.1663e-04,\n",
       "           9.9804e-06, -4.8387e-03,  3.4545e-03,  6.3761e-05, -8.2806e-04,\n",
       "           8.3439e-04, -2.0798e-03,  1.1007e-04,  4.2594e-03, -2.9834e-04,\n",
       "          -3.3693e-03, -2.9176e-03,  8.0031e-06, -3.0720e-03,  3.5376e-03,\n",
       "           3.8885e-03,  7.7678e-03,  1.2666e-04, -3.4634e-03, -9.4266e-05,\n",
       "           1.9391e-03, -2.6227e-03,  3.4403e-03,  4.1717e-04, -2.3884e-03,\n",
       "          -1.4894e-04,  6.3768e-06, -1.3969e-03,  7.4063e-03, -2.0570e-03,\n",
       "          -9.5549e-03,  1.0518e-04, -2.9606e-03,  3.9953e-03,  1.1122e-03,\n",
       "           4.7797e-03, -1.0503e-04, -4.0632e-06,  9.0683e-03, -3.6191e-03,\n",
       "          -7.3260e-03, -3.2315e-03,  5.1793e-05,  2.9702e-03,  4.8139e-03,\n",
       "          -3.2225e-03,  1.0857e-03, -3.9385e-03, -3.0010e-05, -7.0943e-03,\n",
       "          -5.2528e-03,  5.3359e-03,  6.7882e-03, -1.0399e-03,  6.9853e-03,\n",
       "           3.5179e-03,  4.4475e-03, -1.0195e-03, -4.9569e-05,  3.1216e-03,\n",
       "           3.1604e-03, -6.9720e-04,  4.7164e-03, -1.0056e-04,  6.2196e-04,\n",
       "           4.3979e-03,  1.0994e-03, -3.7454e-04, -2.6682e-05, -2.5125e-04,\n",
       "           2.7616e-03,  6.0990e-03,  5.8835e-03,  9.1377e-05, -2.1758e-03,\n",
       "           7.1045e-03,  6.0882e-03, -1.2832e-04,  3.0222e-04,  3.5144e-03,\n",
       "          -2.5152e-04,  3.3073e-03, -6.3261e-03,  1.7539e-03, -8.2708e-05,\n",
       "           1.9663e-03, -1.0001e-01,  1.2744e-03, -8.1090e-03,  1.4970e-03,\n",
       "          -3.3967e-03, -8.7028e-05,  5.3088e-03,  1.4165e-03,  1.9243e-03,\n",
       "          -4.0421e-04, -8.7939e-05,  1.0419e-03,  8.8437e-05, -1.5015e-03,\n",
       "          -9.0941e-04, -4.0803e-03, -2.6553e-05, -5.1499e-03,  1.2726e-04,\n",
       "          -6.7496e-03, -3.1512e-05,  9.4965e-04,  3.8633e-03, -4.3822e-03,\n",
       "          -2.7951e-03, -6.4879e-05,  4.5892e-03, -6.6001e-03,  1.4189e-04,\n",
       "          -7.5113e-03, -3.7191e-04,  1.6921e-03,  1.9083e-03,  4.3668e-03,\n",
       "           1.7548e-03,  4.1182e-03, -2.0574e-03, -9.5176e-03, -2.0138e-05,\n",
       "          -2.6453e-03,  1.3408e-04,  3.8899e-03,  3.9511e-03, -7.5118e-02,\n",
       "          -2.8757e-03, -2.5858e-03, -6.0769e-03, -1.4355e-04,  4.9922e-03,\n",
       "           6.3590e-03,  4.3575e-03, -8.3995e-05, -1.1911e-04, -1.2064e-04,\n",
       "          -3.2644e-05, -2.4101e-04, -3.0015e-03, -1.2813e-04,  4.2443e-03]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1377], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5304, 0.5070, 0.2612, 0.1520, 0.8605],\n",
      "        [0.6194, 0.1672, 0.3754, 0.3235, 0.3977]])\n",
      "tensor([[-0.1761],\n",
      "        [-0.0044]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lnorm = nn.LayerNorm(5)\n",
    "Bnorm = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f854e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.7619e+02, 1.8175e+02, 5.4326e-01, 3.3009e-01, 1.2666e-01],\n",
      "        [7.8122e+02, 2.1935e+02, 3.3731e-01, 3.0653e-01, 3.5616e-01],\n",
      "        [6.8710e+02, 2.4448e+02, 2.7587e-01, 6.6545e-01, 5.8671e-02],\n",
      "        [6.6953e+02, 2.4334e+02, 2.4388e-01, 3.2311e-01, 4.3301e-01],\n",
      "        [6.5361e+02, 2.4286e+02, 1.0120e-01, 2.3178e-01, 6.6703e-01],\n",
      "        [8.1118e+02, 1.4268e+02, 4.0387e-02, 4.7464e-01, 4.8498e-01],\n",
      "        [8.3129e+02, 2.1740e+02, 3.4283e-01, 5.6580e-01, 9.1370e-02],\n",
      "        [7.1658e+02, 1.8747e+02, 2.8704e-01, 2.0605e-01, 5.0691e-01],\n",
      "        [6.6310e+02, 1.6943e+02, 1.2187e-01, 1.5450e-01, 7.2364e-01],\n",
      "        [6.9805e+02, 1.0843e+02, 1.5387e-01, 2.2903e-01, 6.1711e-01],\n",
      "        [7.5928e+02, 1.1254e+02, 3.8763e-01, 1.9098e-01, 4.2139e-01],\n",
      "        [6.6805e+02, 1.9806e+02, 2.1331e-01, 7.6601e-01, 2.0682e-02],\n",
      "        [8.0226e+02, 2.1278e+02, 7.2162e-01, 1.5958e-01, 1.1881e-01],\n",
      "        [7.3167e+02, 1.1271e+02, 7.7830e-01, 1.9004e-01, 3.1658e-02],\n",
      "        [6.5514e+02, 1.8019e+02, 6.5692e-01, 4.8884e-02, 2.9420e-01],\n",
      "        [6.7551e+02, 1.7275e+02, 7.4567e-02, 7.2001e-01, 2.0543e-01],\n",
      "        [7.4173e+02, 1.9113e+02, 5.1792e-01, 4.4282e-03, 4.7765e-01],\n",
      "        [8.3114e+02, 1.3822e+02, 1.3954e-01, 2.1819e-01, 6.4227e-01],\n",
      "        [8.0727e+02, 1.6388e+02, 1.1610e-02, 6.2803e-01, 3.6036e-01],\n",
      "        [8.3036e+02, 1.3754e+02, 5.0171e-01, 3.2553e-02, 4.6574e-01],\n",
      "        [8.0275e+02, 1.2790e+02, 2.1633e-01, 1.7681e-01, 6.0686e-01],\n",
      "        [6.5271e+02, 2.2376e+02, 3.8433e-01, 4.3365e-02, 5.7230e-01],\n",
      "        [8.0566e+02, 1.2558e+02, 6.5497e-01, 2.6044e-01, 8.4587e-02],\n",
      "        [6.6010e+02, 1.6923e+02, 2.4080e-01, 9.0453e-02, 6.6875e-01],\n",
      "        [7.7718e+02, 1.3373e+02, 6.8114e-01, 1.3871e-01, 1.8015e-01],\n",
      "        [8.2750e+02, 2.4859e+02, 3.9884e-01, 5.2700e-01, 7.4159e-02],\n",
      "        [7.4132e+02, 1.6480e+02, 3.7684e-01, 5.5277e-01, 7.0383e-02],\n",
      "        [6.9737e+02, 1.6747e+02, 1.4915e-02, 3.3400e-01, 6.5108e-01],\n",
      "        [6.5787e+02, 1.4591e+02, 1.7127e-01, 5.8454e-01, 2.4419e-01],\n",
      "        [7.6271e+02, 2.2813e+02, 5.2186e-01, 2.1511e-02, 4.5663e-01],\n",
      "        [7.5244e+02, 1.4937e+02, 2.2446e-01, 5.2971e-02, 7.2257e-01],\n",
      "        [8.0868e+02, 1.8668e+02, 1.3355e-01, 1.5236e-01, 7.1409e-01]])\n",
      "tensor([ 1.7764e-15,  1.3878e-17, -2.7756e-17,  1.3878e-16, -1.6653e-16],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.9812,  0.1264,  1.0030,  0.1674, -1.0675],\n",
      "        [ 0.6690,  1.0314,  0.0470,  0.0607, -0.0992],\n",
      "        [-0.8097,  1.6362, -0.2382,  1.6870, -1.3543],\n",
      "        [-1.0858,  1.6089, -0.3867,  0.1358,  0.2250],\n",
      "        [-1.3358,  1.5972, -1.0490, -0.2781,  1.2124],\n",
      "        [ 1.1395, -0.8142, -1.3313,  0.8224,  0.4443],\n",
      "        [ 1.4554,  0.9844,  0.0726,  1.2354, -1.2163],\n",
      "        [-0.3467,  0.2641, -0.1863, -0.3946,  0.5368],\n",
      "        [-1.1868, -0.1704, -0.9531, -0.6282,  1.4512],\n",
      "        [-0.6377, -1.6387, -0.8045, -0.2905,  1.0017],\n",
      "        [ 0.3242, -1.5396,  0.2806, -0.4629,  0.1760],\n",
      "        [-1.1090,  0.5188, -0.5286,  2.1426, -1.5146],\n",
      "        [ 0.9994,  0.8731,  1.8309, -0.6052, -1.1006],\n",
      "        [-0.1096, -1.5356,  2.0941, -0.4672, -1.4683],\n",
      "        [-1.3118,  0.0888,  1.5306, -1.1068, -0.3606],\n",
      "        [-0.9918, -0.0905, -1.1727,  1.9341, -0.7351],\n",
      "        [ 0.0485,  0.3520,  0.8854, -1.3082,  0.4134],\n",
      "        [ 1.4531, -0.9215, -0.8710, -0.3396,  1.1079],\n",
      "        [ 1.0781, -0.3039, -1.4649,  1.5174, -0.0815],\n",
      "        [ 1.4409, -0.9379,  0.8101, -1.1808,  0.3631],\n",
      "        [ 1.0071, -1.1699, -0.5146, -0.5271,  0.9585],\n",
      "        [-1.3500,  1.1376,  0.2653, -1.1318,  0.8127],\n",
      "        [ 1.0529, -1.2257,  1.5216, -0.1482, -1.2450],\n",
      "        [-1.2339, -0.1752, -0.4010, -0.9184,  1.2196],\n",
      "        [ 0.6055, -1.0296,  1.6430, -0.6997, -0.8418],\n",
      "        [ 1.3960,  1.7351,  0.3326,  1.0596, -1.2890],\n",
      "        [ 0.0420, -0.2818,  0.2305,  1.1764, -1.3049],\n",
      "        [-0.6484, -0.2174, -1.4496,  0.1851,  1.1451],\n",
      "        [-1.2689, -0.7365, -0.7238,  1.3203, -0.5716],\n",
      "        [ 0.3781,  1.2427,  0.9037, -1.2308,  0.3247],\n",
      "        [ 0.2168, -0.6530, -0.4769, -1.0882,  1.4467],\n",
      "        [ 1.1004,  0.2448, -0.8989, -0.6379,  1.4109]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    #print(y.reshape((-1,1)))\n",
    "    print(Bnorm(X).mean(dim=0))\n",
    "    print(Bnorm(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
