{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz, Output x_H2 und x_NH3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import normalize as norm\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ReduceLROnPlateau\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import max_error\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "# from sklearn.metrics import mean_absolute_error as MAE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden1_size), #Lineare Transformation mit gespeicherten weights und biases\n",
    "            nn.ReLU(), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            nn.Dropout(p = 0.01),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2_size, output_size)\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Dropout(p=0.01, inplace=False)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset_x.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs x[H2,N2,NH3]\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "x = torch.tensor(res['x'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#T = log10(T)\n",
    "# T = T / 850\n",
    "# p = p / 1000\n",
    "\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "y_output = torch.stack((x[:,0], x[:,2]), 1) # [H2, NH3], dritter Stoffmengenanteil ergibt sich den anderen\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Split des Datensatzes in Trainings und Testdaten\n",
    "split = 0.8 # Anteil Trainingsdaten\n",
    "\n",
    "x_input_train = x_input[:int(split * len(x_input)), :]\n",
    "y_output_train = y_output[:int(split * len(y_output)), :]\n",
    "x_input_test = x_input[int(split * len(x_input)):, :]\n",
    "y_output_test = y_output[int(split * len(y_output)):, :]\n",
    "\n",
    "# Preprocessing Normalisierung der Daten\n",
    "mean_in = torch.mean(x_input_train,0) # Mittelwert\n",
    "std_in = torch.std(x_input_train,0) # Standardabweichung\n",
    "mean_out = torch.mean(y_output_train,0)\n",
    "std_out = torch.std(y_output_train,0)\n",
    "\n",
    "x_input_train_norm = (x_input_train - mean_in) / std_in\n",
    "y_output_train_norm = (y_output_train - mean_out) / std_out\n",
    "\n",
    "x_input_test_norm = (x_input_test - mean_in) / std_in\n",
    "y_output_test_norm = (y_output_test - mean_out) / std_out\n",
    "\n",
    "# print(x_input_train_norm)\n",
    "# print(torch.mean(x_input_train_norm[:,0]))\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "train_dataset = TensorDataset(x_input_train_norm, y_output_train_norm)\n",
    "test_dataset = TensorDataset(x_input_test_norm, y_output_test_norm)\n",
    "    \n",
    "# # Split in Trainings und Test Set\n",
    "# train_dataset, test_dataset = random_split(dataset, \n",
    "#                                            [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "#                                            generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 2)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "loss_fn_MSE = nn.MSELoss()\n",
    "loss_fn_L1 = nn.L1Loss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[30, 70, 100], gamma = 0.1)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 10, threshold = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ccc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-6\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    MAE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn_MSE(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred * std_out + mean_out, y * std_out + mean_out)\n",
    "            MAE += loss_fn_L1(pred * std_out + mean_out, y * std_out + mean_out)\n",
    "            \n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if ((pred[i,0] * std_out[0] + mean_out[0]) - (y[i,0] * std_out[0] + mean_out[0]) and (pred[i,1] * std_out[1] + mean_out[1]) - (y[i,1] * std_out[1] + mean_out[1])) <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        MAE /= num_batches\n",
    "\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f}, MAE: {MAE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200, Iteration 1/12, Loss: 1.1526\n",
      "Epoch 1/1200, Iteration 2/12, Loss: 0.9399\n",
      "Epoch 1/1200, Iteration 3/12, Loss: 0.9217\n",
      "Epoch 1/1200, Iteration 4/12, Loss: 0.8670\n",
      "Epoch 1/1200, Iteration 5/12, Loss: 0.8785\n",
      "Epoch 1/1200, Iteration 6/12, Loss: 1.0275\n",
      "Epoch 1/1200, Iteration 7/12, Loss: 0.7393\n",
      "Epoch 1/1200, Iteration 8/12, Loss: 0.7220\n",
      "Epoch 1/1200, Iteration 9/12, Loss: 0.7636\n",
      "Epoch 1/1200, Iteration 10/12, Loss: 0.5999\n",
      "Epoch 1/1200, Iteration 11/12, Loss: 0.7545\n",
      "Epoch 1/1200, Iteration 12/12, Loss: 0.5640\n",
      "Epoch 1/1200, Iteration 13/12, Loss: 0.6209\n",
      "Train Error: \n",
      " Accuracy: 49.62%, Avg loss: 0.610066, MRE: 0.520155, MAE: 0.081696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.566214, MRE: 0.420494, MAE: 0.072968 \n",
      "\n",
      "Epoch 2/1200, Iteration 1/12, Loss: 0.4474\n",
      "Epoch 2/1200, Iteration 2/12, Loss: 0.5450\n",
      "Epoch 2/1200, Iteration 3/12, Loss: 0.7424\n",
      "Epoch 2/1200, Iteration 4/12, Loss: 0.5076\n",
      "Epoch 2/1200, Iteration 5/12, Loss: 0.5474\n",
      "Epoch 2/1200, Iteration 6/12, Loss: 0.5533\n",
      "Epoch 2/1200, Iteration 7/12, Loss: 0.4549\n",
      "Epoch 2/1200, Iteration 8/12, Loss: 0.4652\n",
      "Epoch 2/1200, Iteration 9/12, Loss: 0.4638\n",
      "Epoch 2/1200, Iteration 10/12, Loss: 0.3674\n",
      "Epoch 2/1200, Iteration 11/12, Loss: 0.3845\n",
      "Epoch 2/1200, Iteration 12/12, Loss: 0.3329\n",
      "Epoch 2/1200, Iteration 13/12, Loss: 0.3500\n",
      "Train Error: \n",
      " Accuracy: 51.12%, Avg loss: 0.337876, MRE: 0.354286, MAE: 0.053744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.326577, MRE: 0.280580, MAE: 0.047283 \n",
      "\n",
      "Epoch 3/1200, Iteration 1/12, Loss: 0.2999\n",
      "Epoch 3/1200, Iteration 2/12, Loss: 0.3679\n",
      "Epoch 3/1200, Iteration 3/12, Loss: 0.3963\n",
      "Epoch 3/1200, Iteration 4/12, Loss: 0.3346\n",
      "Epoch 3/1200, Iteration 5/12, Loss: 0.2304\n",
      "Epoch 3/1200, Iteration 6/12, Loss: 0.2791\n",
      "Epoch 3/1200, Iteration 7/12, Loss: 0.2144\n",
      "Epoch 3/1200, Iteration 8/12, Loss: 0.2493\n",
      "Epoch 3/1200, Iteration 9/12, Loss: 0.1737\n",
      "Epoch 3/1200, Iteration 10/12, Loss: 0.1694\n",
      "Epoch 3/1200, Iteration 11/12, Loss: 0.2088\n",
      "Epoch 3/1200, Iteration 12/12, Loss: 0.2466\n",
      "Epoch 3/1200, Iteration 13/12, Loss: 0.2097\n",
      "Train Error: \n",
      " Accuracy: 51.88%, Avg loss: 0.182431, MRE: 0.229153, MAE: 0.034969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.183017, MRE: 0.187375, MAE: 0.031020 \n",
      "\n",
      "Epoch 4/1200, Iteration 1/12, Loss: 0.1795\n",
      "Epoch 4/1200, Iteration 2/12, Loss: 0.1670\n",
      "Epoch 4/1200, Iteration 3/12, Loss: 0.1982\n",
      "Epoch 4/1200, Iteration 4/12, Loss: 0.1478\n",
      "Epoch 4/1200, Iteration 5/12, Loss: 0.2540\n",
      "Epoch 4/1200, Iteration 6/12, Loss: 0.1658\n",
      "Epoch 4/1200, Iteration 7/12, Loss: 0.1120\n",
      "Epoch 4/1200, Iteration 8/12, Loss: 0.1592\n",
      "Epoch 4/1200, Iteration 9/12, Loss: 0.0834\n",
      "Epoch 4/1200, Iteration 10/12, Loss: 0.1345\n",
      "Epoch 4/1200, Iteration 11/12, Loss: 0.0882\n",
      "Epoch 4/1200, Iteration 12/12, Loss: 0.0704\n",
      "Epoch 4/1200, Iteration 13/12, Loss: 0.1575\n",
      "Train Error: \n",
      " Accuracy: 71.38%, Avg loss: 0.113497, MRE: 0.141679, MAE: 0.026215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.112960, MRE: 0.118068, MAE: 0.023613 \n",
      "\n",
      "Epoch 5/1200, Iteration 1/12, Loss: 0.0902\n",
      "Epoch 5/1200, Iteration 2/12, Loss: 0.0992\n",
      "Epoch 5/1200, Iteration 3/12, Loss: 0.1349\n",
      "Epoch 5/1200, Iteration 4/12, Loss: 0.1152\n",
      "Epoch 5/1200, Iteration 5/12, Loss: 0.0803\n",
      "Epoch 5/1200, Iteration 6/12, Loss: 0.1005\n",
      "Epoch 5/1200, Iteration 7/12, Loss: 0.0942\n",
      "Epoch 5/1200, Iteration 8/12, Loss: 0.1072\n",
      "Epoch 5/1200, Iteration 9/12, Loss: 0.1239\n",
      "Epoch 5/1200, Iteration 10/12, Loss: 0.0778\n",
      "Epoch 5/1200, Iteration 11/12, Loss: 0.0894\n",
      "Epoch 5/1200, Iteration 12/12, Loss: 0.0699\n",
      "Epoch 5/1200, Iteration 13/12, Loss: 0.0571\n",
      "Train Error: \n",
      " Accuracy: 77.25%, Avg loss: 0.079822, MRE: 0.114622, MAE: 0.022644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.077797, MRE: 0.105171, MAE: 0.021005 \n",
      "\n",
      "Epoch 6/1200, Iteration 1/12, Loss: 0.0898\n",
      "Epoch 6/1200, Iteration 2/12, Loss: 0.0665\n",
      "Epoch 6/1200, Iteration 3/12, Loss: 0.0592\n",
      "Epoch 6/1200, Iteration 4/12, Loss: 0.0819\n",
      "Epoch 6/1200, Iteration 5/12, Loss: 0.0770\n",
      "Epoch 6/1200, Iteration 6/12, Loss: 0.0708\n",
      "Epoch 6/1200, Iteration 7/12, Loss: 0.0580\n",
      "Epoch 6/1200, Iteration 8/12, Loss: 0.1075\n",
      "Epoch 6/1200, Iteration 9/12, Loss: 0.1044\n",
      "Epoch 6/1200, Iteration 10/12, Loss: 0.0651\n",
      "Epoch 6/1200, Iteration 11/12, Loss: 0.0495\n",
      "Epoch 6/1200, Iteration 12/12, Loss: 0.0635\n",
      "Epoch 6/1200, Iteration 13/12, Loss: 0.0893\n",
      "Train Error: \n",
      " Accuracy: 81.62%, Avg loss: 0.066418, MRE: 0.110597, MAE: 0.021325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.065143, MRE: 0.106687, MAE: 0.020538 \n",
      "\n",
      "Epoch 7/1200, Iteration 1/12, Loss: 0.0747\n",
      "Epoch 7/1200, Iteration 2/12, Loss: 0.0572\n",
      "Epoch 7/1200, Iteration 3/12, Loss: 0.0536\n",
      "Epoch 7/1200, Iteration 4/12, Loss: 0.0807\n",
      "Epoch 7/1200, Iteration 5/12, Loss: 0.0896\n",
      "Epoch 7/1200, Iteration 6/12, Loss: 0.0832\n",
      "Epoch 7/1200, Iteration 7/12, Loss: 0.0673\n",
      "Epoch 7/1200, Iteration 8/12, Loss: 0.0499\n",
      "Epoch 7/1200, Iteration 9/12, Loss: 0.0621\n",
      "Epoch 7/1200, Iteration 10/12, Loss: 0.0668\n",
      "Epoch 7/1200, Iteration 11/12, Loss: 0.0431\n",
      "Epoch 7/1200, Iteration 12/12, Loss: 0.0510\n",
      "Epoch 7/1200, Iteration 13/12, Loss: 0.0471\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.058722, MRE: 0.106667, MAE: 0.019721 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.051541, MRE: 0.099655, MAE: 0.018617 \n",
      "\n",
      "Epoch 8/1200, Iteration 1/12, Loss: 0.0361\n",
      "Epoch 8/1200, Iteration 2/12, Loss: 0.0469\n",
      "Epoch 8/1200, Iteration 3/12, Loss: 0.0499\n",
      "Epoch 8/1200, Iteration 4/12, Loss: 0.0640\n",
      "Epoch 8/1200, Iteration 5/12, Loss: 0.0429\n",
      "Epoch 8/1200, Iteration 6/12, Loss: 0.0831\n",
      "Epoch 8/1200, Iteration 7/12, Loss: 0.0398\n",
      "Epoch 8/1200, Iteration 8/12, Loss: 0.0568\n",
      "Epoch 8/1200, Iteration 9/12, Loss: 0.0705\n",
      "Epoch 8/1200, Iteration 10/12, Loss: 0.0586\n",
      "Epoch 8/1200, Iteration 11/12, Loss: 0.0605\n",
      "Epoch 8/1200, Iteration 12/12, Loss: 0.0476\n",
      "Epoch 8/1200, Iteration 13/12, Loss: 0.0882\n",
      "Train Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.050999, MRE: 0.105513, MAE: 0.018722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.047672, MRE: 0.098490, MAE: 0.018204 \n",
      "\n",
      "Epoch 9/1200, Iteration 1/12, Loss: 0.0566\n",
      "Epoch 9/1200, Iteration 2/12, Loss: 0.0588\n",
      "Epoch 9/1200, Iteration 3/12, Loss: 0.0521\n",
      "Epoch 9/1200, Iteration 4/12, Loss: 0.0365\n",
      "Epoch 9/1200, Iteration 5/12, Loss: 0.0511\n",
      "Epoch 9/1200, Iteration 6/12, Loss: 0.0859\n",
      "Epoch 9/1200, Iteration 7/12, Loss: 0.0430\n",
      "Epoch 9/1200, Iteration 8/12, Loss: 0.0447\n",
      "Epoch 9/1200, Iteration 9/12, Loss: 0.0540\n",
      "Epoch 9/1200, Iteration 10/12, Loss: 0.0451\n",
      "Epoch 9/1200, Iteration 11/12, Loss: 0.0318\n",
      "Epoch 9/1200, Iteration 12/12, Loss: 0.0625\n",
      "Epoch 9/1200, Iteration 13/12, Loss: 0.0307\n",
      "Train Error: \n",
      " Accuracy: 79.62%, Avg loss: 0.046735, MRE: 0.097310, MAE: 0.017529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.039546, MRE: 0.088785, MAE: 0.016576 \n",
      "\n",
      "Epoch 10/1200, Iteration 1/12, Loss: 0.0447\n",
      "Epoch 10/1200, Iteration 2/12, Loss: 0.0373\n",
      "Epoch 10/1200, Iteration 3/12, Loss: 0.0344\n",
      "Epoch 10/1200, Iteration 4/12, Loss: 0.0457\n",
      "Epoch 10/1200, Iteration 5/12, Loss: 0.0756\n",
      "Epoch 10/1200, Iteration 6/12, Loss: 0.0320\n",
      "Epoch 10/1200, Iteration 7/12, Loss: 0.0527\n",
      "Epoch 10/1200, Iteration 8/12, Loss: 0.0752\n",
      "Epoch 10/1200, Iteration 9/12, Loss: 0.0392\n",
      "Epoch 10/1200, Iteration 10/12, Loss: 0.0297\n",
      "Epoch 10/1200, Iteration 11/12, Loss: 0.0746\n",
      "Epoch 10/1200, Iteration 12/12, Loss: 0.0293\n",
      "Epoch 10/1200, Iteration 13/12, Loss: 0.0160\n",
      "Train Error: \n",
      " Accuracy: 82.38%, Avg loss: 0.042141, MRE: 0.093385, MAE: 0.016519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.035621, MRE: 0.083139, MAE: 0.015507 \n",
      "\n",
      "Epoch 11/1200, Iteration 1/12, Loss: 0.0288\n",
      "Epoch 11/1200, Iteration 2/12, Loss: 0.0433\n",
      "Epoch 11/1200, Iteration 3/12, Loss: 0.0430\n",
      "Epoch 11/1200, Iteration 4/12, Loss: 0.0249\n",
      "Epoch 11/1200, Iteration 5/12, Loss: 0.0295\n",
      "Epoch 11/1200, Iteration 6/12, Loss: 0.0329\n",
      "Epoch 11/1200, Iteration 7/12, Loss: 0.0590\n",
      "Epoch 11/1200, Iteration 8/12, Loss: 0.0419\n",
      "Epoch 11/1200, Iteration 9/12, Loss: 0.0583\n",
      "Epoch 11/1200, Iteration 10/12, Loss: 0.0444\n",
      "Epoch 11/1200, Iteration 11/12, Loss: 0.0568\n",
      "Epoch 11/1200, Iteration 12/12, Loss: 0.0578\n",
      "Epoch 11/1200, Iteration 13/12, Loss: 0.0243\n",
      "Train Error: \n",
      " Accuracy: 83.62%, Avg loss: 0.038406, MRE: 0.089420, MAE: 0.015682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.032940, MRE: 0.078485, MAE: 0.014907 \n",
      "\n",
      "Epoch 12/1200, Iteration 1/12, Loss: 0.0399\n",
      "Epoch 12/1200, Iteration 2/12, Loss: 0.0769\n",
      "Epoch 12/1200, Iteration 3/12, Loss: 0.0410\n",
      "Epoch 12/1200, Iteration 4/12, Loss: 0.0475\n",
      "Epoch 12/1200, Iteration 5/12, Loss: 0.0516\n",
      "Epoch 12/1200, Iteration 6/12, Loss: 0.0249\n",
      "Epoch 12/1200, Iteration 7/12, Loss: 0.0297\n",
      "Epoch 12/1200, Iteration 8/12, Loss: 0.0350\n",
      "Epoch 12/1200, Iteration 9/12, Loss: 0.0191\n",
      "Epoch 12/1200, Iteration 10/12, Loss: 0.0353\n",
      "Epoch 12/1200, Iteration 11/12, Loss: 0.0398\n",
      "Epoch 12/1200, Iteration 12/12, Loss: 0.0252\n",
      "Epoch 12/1200, Iteration 13/12, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.036446, MRE: 0.088457, MAE: 0.015077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.030004, MRE: 0.075210, MAE: 0.014157 \n",
      "\n",
      "Epoch 13/1200, Iteration 1/12, Loss: 0.0537\n",
      "Epoch 13/1200, Iteration 2/12, Loss: 0.0461\n",
      "Epoch 13/1200, Iteration 3/12, Loss: 0.0411\n",
      "Epoch 13/1200, Iteration 4/12, Loss: 0.0169\n",
      "Epoch 13/1200, Iteration 5/12, Loss: 0.0621\n",
      "Epoch 13/1200, Iteration 6/12, Loss: 0.0230\n",
      "Epoch 13/1200, Iteration 7/12, Loss: 0.0234\n",
      "Epoch 13/1200, Iteration 8/12, Loss: 0.0504\n",
      "Epoch 13/1200, Iteration 9/12, Loss: 0.0202\n",
      "Epoch 13/1200, Iteration 10/12, Loss: 0.0228\n",
      "Epoch 13/1200, Iteration 11/12, Loss: 0.0380\n",
      "Epoch 13/1200, Iteration 12/12, Loss: 0.0425\n",
      "Epoch 13/1200, Iteration 13/12, Loss: 0.0369\n",
      "Train Error: \n",
      " Accuracy: 84.25%, Avg loss: 0.033321, MRE: 0.083099, MAE: 0.014322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.026941, MRE: 0.070418, MAE: 0.013524 \n",
      "\n",
      "Epoch 14/1200, Iteration 1/12, Loss: 0.0149\n",
      "Epoch 14/1200, Iteration 2/12, Loss: 0.0353\n",
      "Epoch 14/1200, Iteration 3/12, Loss: 0.0629\n",
      "Epoch 14/1200, Iteration 4/12, Loss: 0.0252\n",
      "Epoch 14/1200, Iteration 5/12, Loss: 0.0322\n",
      "Epoch 14/1200, Iteration 6/12, Loss: 0.0495\n",
      "Epoch 14/1200, Iteration 7/12, Loss: 0.0359\n",
      "Epoch 14/1200, Iteration 8/12, Loss: 0.0255\n",
      "Epoch 14/1200, Iteration 9/12, Loss: 0.0391\n",
      "Epoch 14/1200, Iteration 10/12, Loss: 0.0407\n",
      "Epoch 14/1200, Iteration 11/12, Loss: 0.0334\n",
      "Epoch 14/1200, Iteration 12/12, Loss: 0.0175\n",
      "Epoch 14/1200, Iteration 13/12, Loss: 0.0227\n",
      "Train Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.031472, MRE: 0.078940, MAE: 0.013740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.025480, MRE: 0.067566, MAE: 0.013004 \n",
      "\n",
      "Epoch 15/1200, Iteration 1/12, Loss: 0.0344\n",
      "Epoch 15/1200, Iteration 2/12, Loss: 0.0244\n",
      "Epoch 15/1200, Iteration 3/12, Loss: 0.0231\n",
      "Epoch 15/1200, Iteration 4/12, Loss: 0.0440\n",
      "Epoch 15/1200, Iteration 5/12, Loss: 0.0228\n",
      "Epoch 15/1200, Iteration 6/12, Loss: 0.0435\n",
      "Epoch 15/1200, Iteration 7/12, Loss: 0.0146\n",
      "Epoch 15/1200, Iteration 8/12, Loss: 0.0468\n",
      "Epoch 15/1200, Iteration 9/12, Loss: 0.0482\n",
      "Epoch 15/1200, Iteration 10/12, Loss: 0.0309\n",
      "Epoch 15/1200, Iteration 11/12, Loss: 0.0138\n",
      "Epoch 15/1200, Iteration 12/12, Loss: 0.0468\n",
      "Epoch 15/1200, Iteration 13/12, Loss: 0.0175\n",
      "Train Error: \n",
      " Accuracy: 86.38%, Avg loss: 0.029809, MRE: 0.077578, MAE: 0.013320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.023977, MRE: 0.065559, MAE: 0.012670 \n",
      "\n",
      "Epoch 16/1200, Iteration 1/12, Loss: 0.0350\n",
      "Epoch 16/1200, Iteration 2/12, Loss: 0.0252\n",
      "Epoch 16/1200, Iteration 3/12, Loss: 0.0256\n",
      "Epoch 16/1200, Iteration 4/12, Loss: 0.0266\n",
      "Epoch 16/1200, Iteration 5/12, Loss: 0.0279\n",
      "Epoch 16/1200, Iteration 6/12, Loss: 0.0274\n",
      "Epoch 16/1200, Iteration 7/12, Loss: 0.0366\n",
      "Epoch 16/1200, Iteration 8/12, Loss: 0.0344\n",
      "Epoch 16/1200, Iteration 9/12, Loss: 0.0817\n",
      "Epoch 16/1200, Iteration 10/12, Loss: 0.0163\n",
      "Epoch 16/1200, Iteration 11/12, Loss: 0.0255\n",
      "Epoch 16/1200, Iteration 12/12, Loss: 0.0125\n",
      "Epoch 16/1200, Iteration 13/12, Loss: 0.0235\n",
      "Train Error: \n",
      " Accuracy: 84.75%, Avg loss: 0.029218, MRE: 0.074320, MAE: 0.012873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.021860, MRE: 0.062976, MAE: 0.012086 \n",
      "\n",
      "Epoch 17/1200, Iteration 1/12, Loss: 0.0329\n",
      "Epoch 17/1200, Iteration 2/12, Loss: 0.0220\n",
      "Epoch 17/1200, Iteration 3/12, Loss: 0.0278\n",
      "Epoch 17/1200, Iteration 4/12, Loss: 0.0214\n",
      "Epoch 17/1200, Iteration 5/12, Loss: 0.0208\n",
      "Epoch 17/1200, Iteration 6/12, Loss: 0.0197\n",
      "Epoch 17/1200, Iteration 7/12, Loss: 0.0257\n",
      "Epoch 17/1200, Iteration 8/12, Loss: 0.0187\n",
      "Epoch 17/1200, Iteration 9/12, Loss: 0.0427\n",
      "Epoch 17/1200, Iteration 10/12, Loss: 0.0298\n",
      "Epoch 17/1200, Iteration 11/12, Loss: 0.0284\n",
      "Epoch 17/1200, Iteration 12/12, Loss: 0.0423\n",
      "Epoch 17/1200, Iteration 13/12, Loss: 0.0432\n",
      "Train Error: \n",
      " Accuracy: 88.88%, Avg loss: 0.028927, MRE: 0.075934, MAE: 0.012796 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.023325, MRE: 0.063947, MAE: 0.012365 \n",
      "\n",
      "Epoch 18/1200, Iteration 1/12, Loss: 0.0210\n",
      "Epoch 18/1200, Iteration 2/12, Loss: 0.0261\n",
      "Epoch 18/1200, Iteration 3/12, Loss: 0.0141\n",
      "Epoch 18/1200, Iteration 4/12, Loss: 0.0373\n",
      "Epoch 18/1200, Iteration 5/12, Loss: 0.0263\n",
      "Epoch 18/1200, Iteration 6/12, Loss: 0.0403\n",
      "Epoch 18/1200, Iteration 7/12, Loss: 0.0392\n",
      "Epoch 18/1200, Iteration 8/12, Loss: 0.0212\n",
      "Epoch 18/1200, Iteration 9/12, Loss: 0.0303\n",
      "Epoch 18/1200, Iteration 10/12, Loss: 0.0140\n",
      "Epoch 18/1200, Iteration 11/12, Loss: 0.0463\n",
      "Epoch 18/1200, Iteration 12/12, Loss: 0.0208\n",
      "Epoch 18/1200, Iteration 13/12, Loss: 0.0220\n",
      "Train Error: \n",
      " Accuracy: 85.88%, Avg loss: 0.025653, MRE: 0.070501, MAE: 0.012021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.019714, MRE: 0.059732, MAE: 0.011413 \n",
      "\n",
      "Epoch 19/1200, Iteration 1/12, Loss: 0.0107\n",
      "Epoch 19/1200, Iteration 2/12, Loss: 0.0239\n",
      "Epoch 19/1200, Iteration 3/12, Loss: 0.0225\n",
      "Epoch 19/1200, Iteration 4/12, Loss: 0.0233\n",
      "Epoch 19/1200, Iteration 5/12, Loss: 0.0156\n",
      "Epoch 19/1200, Iteration 6/12, Loss: 0.0254\n",
      "Epoch 19/1200, Iteration 7/12, Loss: 0.0612\n",
      "Epoch 19/1200, Iteration 8/12, Loss: 0.0381\n",
      "Epoch 19/1200, Iteration 9/12, Loss: 0.0364\n",
      "Epoch 19/1200, Iteration 10/12, Loss: 0.0194\n",
      "Epoch 19/1200, Iteration 11/12, Loss: 0.0234\n",
      "Epoch 19/1200, Iteration 12/12, Loss: 0.0234\n",
      "Epoch 19/1200, Iteration 13/12, Loss: 0.0170\n",
      "Train Error: \n",
      " Accuracy: 87.88%, Avg loss: 0.025483, MRE: 0.070395, MAE: 0.011691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.018751, MRE: 0.058429, MAE: 0.011016 \n",
      "\n",
      "Epoch 20/1200, Iteration 1/12, Loss: 0.0215\n",
      "Epoch 20/1200, Iteration 2/12, Loss: 0.0244\n",
      "Epoch 20/1200, Iteration 3/12, Loss: 0.0573\n",
      "Epoch 20/1200, Iteration 4/12, Loss: 0.0161\n",
      "Epoch 20/1200, Iteration 5/12, Loss: 0.0255\n",
      "Epoch 20/1200, Iteration 6/12, Loss: 0.0239\n",
      "Epoch 20/1200, Iteration 7/12, Loss: 0.0228\n",
      "Epoch 20/1200, Iteration 8/12, Loss: 0.0156\n",
      "Epoch 20/1200, Iteration 9/12, Loss: 0.0361\n",
      "Epoch 20/1200, Iteration 10/12, Loss: 0.0126\n",
      "Epoch 20/1200, Iteration 11/12, Loss: 0.0268\n",
      "Epoch 20/1200, Iteration 12/12, Loss: 0.0211\n",
      "Epoch 20/1200, Iteration 13/12, Loss: 0.0491\n",
      "Train Error: \n",
      " Accuracy: 87.88%, Avg loss: 0.023749, MRE: 0.069716, MAE: 0.011497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.018465, MRE: 0.057889, MAE: 0.010949 \n",
      "\n",
      "Epoch 21/1200, Iteration 1/12, Loss: 0.0213\n",
      "Epoch 21/1200, Iteration 2/12, Loss: 0.0430\n",
      "Epoch 21/1200, Iteration 3/12, Loss: 0.0345\n",
      "Epoch 21/1200, Iteration 4/12, Loss: 0.0279\n",
      "Epoch 21/1200, Iteration 5/12, Loss: 0.0303\n",
      "Epoch 21/1200, Iteration 6/12, Loss: 0.0190\n",
      "Epoch 21/1200, Iteration 7/12, Loss: 0.0232\n",
      "Epoch 21/1200, Iteration 8/12, Loss: 0.0172\n",
      "Epoch 21/1200, Iteration 9/12, Loss: 0.0294\n",
      "Epoch 21/1200, Iteration 10/12, Loss: 0.0281\n",
      "Epoch 21/1200, Iteration 11/12, Loss: 0.0251\n",
      "Epoch 21/1200, Iteration 12/12, Loss: 0.0128\n",
      "Epoch 21/1200, Iteration 13/12, Loss: 0.0062\n",
      "Train Error: \n",
      " Accuracy: 87.25%, Avg loss: 0.022709, MRE: 0.068573, MAE: 0.011052 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.017501, MRE: 0.056600, MAE: 0.010673 \n",
      "\n",
      "Epoch 22/1200, Iteration 1/12, Loss: 0.0430\n",
      "Epoch 22/1200, Iteration 2/12, Loss: 0.0175\n",
      "Epoch 22/1200, Iteration 3/12, Loss: 0.0229\n",
      "Epoch 22/1200, Iteration 4/12, Loss: 0.0292\n",
      "Epoch 22/1200, Iteration 5/12, Loss: 0.0210\n",
      "Epoch 22/1200, Iteration 6/12, Loss: 0.0265\n",
      "Epoch 22/1200, Iteration 7/12, Loss: 0.0153\n",
      "Epoch 22/1200, Iteration 8/12, Loss: 0.0280\n",
      "Epoch 22/1200, Iteration 9/12, Loss: 0.0247\n",
      "Epoch 22/1200, Iteration 10/12, Loss: 0.0174\n",
      "Epoch 22/1200, Iteration 11/12, Loss: 0.0133\n",
      "Epoch 22/1200, Iteration 12/12, Loss: 0.0293\n",
      "Epoch 22/1200, Iteration 13/12, Loss: 0.0246\n",
      "Train Error: \n",
      " Accuracy: 85.88%, Avg loss: 0.021799, MRE: 0.066835, MAE: 0.010796 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.016510, MRE: 0.055887, MAE: 0.010425 \n",
      "\n",
      "Epoch 23/1200, Iteration 1/12, Loss: 0.0252\n",
      "Epoch 23/1200, Iteration 2/12, Loss: 0.0129\n",
      "Epoch 23/1200, Iteration 3/12, Loss: 0.0361\n",
      "Epoch 23/1200, Iteration 4/12, Loss: 0.0315\n",
      "Epoch 23/1200, Iteration 5/12, Loss: 0.0379\n",
      "Epoch 23/1200, Iteration 6/12, Loss: 0.0122\n",
      "Epoch 23/1200, Iteration 7/12, Loss: 0.0084\n",
      "Epoch 23/1200, Iteration 8/12, Loss: 0.0330\n",
      "Epoch 23/1200, Iteration 9/12, Loss: 0.0285\n",
      "Epoch 23/1200, Iteration 10/12, Loss: 0.0152\n",
      "Epoch 23/1200, Iteration 11/12, Loss: 0.0222\n",
      "Epoch 23/1200, Iteration 12/12, Loss: 0.0127\n",
      "Epoch 23/1200, Iteration 13/12, Loss: 0.0184\n",
      "Train Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.021722, MRE: 0.064813, MAE: 0.010730 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.015643, MRE: 0.055570, MAE: 0.010271 \n",
      "\n",
      "Epoch 24/1200, Iteration 1/12, Loss: 0.0244\n",
      "Epoch 24/1200, Iteration 2/12, Loss: 0.0110\n",
      "Epoch 24/1200, Iteration 3/12, Loss: 0.0129\n",
      "Epoch 24/1200, Iteration 4/12, Loss: 0.0174\n",
      "Epoch 24/1200, Iteration 5/12, Loss: 0.0122\n",
      "Epoch 24/1200, Iteration 6/12, Loss: 0.0265\n",
      "Epoch 24/1200, Iteration 7/12, Loss: 0.0147\n",
      "Epoch 24/1200, Iteration 8/12, Loss: 0.0155\n",
      "Epoch 24/1200, Iteration 9/12, Loss: 0.0405\n",
      "Epoch 24/1200, Iteration 10/12, Loss: 0.0371\n",
      "Epoch 24/1200, Iteration 11/12, Loss: 0.0299\n",
      "Epoch 24/1200, Iteration 12/12, Loss: 0.0357\n",
      "Epoch 24/1200, Iteration 13/12, Loss: 0.0071\n",
      "Train Error: \n",
      " Accuracy: 90.25%, Avg loss: 0.020957, MRE: 0.066568, MAE: 0.010690 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.017294, MRE: 0.055563, MAE: 0.010482 \n",
      "\n",
      "Epoch 25/1200, Iteration 1/12, Loss: 0.0293\n",
      "Epoch 25/1200, Iteration 2/12, Loss: 0.0145\n",
      "Epoch 25/1200, Iteration 3/12, Loss: 0.0180\n",
      "Epoch 25/1200, Iteration 4/12, Loss: 0.0228\n",
      "Epoch 25/1200, Iteration 5/12, Loss: 0.0177\n",
      "Epoch 25/1200, Iteration 6/12, Loss: 0.0163\n",
      "Epoch 25/1200, Iteration 7/12, Loss: 0.0156\n",
      "Epoch 25/1200, Iteration 8/12, Loss: 0.0330\n",
      "Epoch 25/1200, Iteration 9/12, Loss: 0.0396\n",
      "Epoch 25/1200, Iteration 10/12, Loss: 0.0249\n",
      "Epoch 25/1200, Iteration 11/12, Loss: 0.0175\n",
      "Epoch 25/1200, Iteration 12/12, Loss: 0.0188\n",
      "Epoch 25/1200, Iteration 13/12, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 88.38%, Avg loss: 0.022550, MRE: 0.065276, MAE: 0.010581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.016024, MRE: 0.054192, MAE: 0.010111 \n",
      "\n",
      "Epoch 26/1200, Iteration 1/12, Loss: 0.0142\n",
      "Epoch 26/1200, Iteration 2/12, Loss: 0.0236\n",
      "Epoch 26/1200, Iteration 3/12, Loss: 0.0162\n",
      "Epoch 26/1200, Iteration 4/12, Loss: 0.0343\n",
      "Epoch 26/1200, Iteration 5/12, Loss: 0.0211\n",
      "Epoch 26/1200, Iteration 6/12, Loss: 0.0229\n",
      "Epoch 26/1200, Iteration 7/12, Loss: 0.0272\n",
      "Epoch 26/1200, Iteration 8/12, Loss: 0.0262\n",
      "Epoch 26/1200, Iteration 9/12, Loss: 0.0083\n",
      "Epoch 26/1200, Iteration 10/12, Loss: 0.0192\n",
      "Epoch 26/1200, Iteration 11/12, Loss: 0.0128\n",
      "Epoch 26/1200, Iteration 12/12, Loss: 0.0177\n",
      "Epoch 26/1200, Iteration 13/12, Loss: 0.0492\n",
      "Train Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.021598, MRE: 0.066568, MAE: 0.010495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.017239, MRE: 0.054499, MAE: 0.010326 \n",
      "\n",
      "Epoch 27/1200, Iteration 1/12, Loss: 0.0139\n",
      "Epoch 27/1200, Iteration 2/12, Loss: 0.0296\n",
      "Epoch 27/1200, Iteration 3/12, Loss: 0.0247\n",
      "Epoch 27/1200, Iteration 4/12, Loss: 0.0131\n",
      "Epoch 27/1200, Iteration 5/12, Loss: 0.0302\n",
      "Epoch 27/1200, Iteration 6/12, Loss: 0.0164\n",
      "Epoch 27/1200, Iteration 7/12, Loss: 0.0153\n",
      "Epoch 27/1200, Iteration 8/12, Loss: 0.0151\n",
      "Epoch 27/1200, Iteration 9/12, Loss: 0.0320\n",
      "Epoch 27/1200, Iteration 10/12, Loss: 0.0158\n",
      "Epoch 27/1200, Iteration 11/12, Loss: 0.0334\n",
      "Epoch 27/1200, Iteration 12/12, Loss: 0.0176\n",
      "Epoch 27/1200, Iteration 13/12, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 88.75%, Avg loss: 0.019538, MRE: 0.062394, MAE: 0.010127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.015733, MRE: 0.053079, MAE: 0.009971 \n",
      "\n",
      "Epoch 28/1200, Iteration 1/12, Loss: 0.0139\n",
      "Epoch 28/1200, Iteration 2/12, Loss: 0.0339\n",
      "Epoch 28/1200, Iteration 3/12, Loss: 0.0290\n",
      "Epoch 28/1200, Iteration 4/12, Loss: 0.0269\n",
      "Epoch 28/1200, Iteration 5/12, Loss: 0.0165\n",
      "Epoch 28/1200, Iteration 6/12, Loss: 0.0161\n",
      "Epoch 28/1200, Iteration 7/12, Loss: 0.0077\n",
      "Epoch 28/1200, Iteration 8/12, Loss: 0.0127\n",
      "Epoch 28/1200, Iteration 9/12, Loss: 0.0146\n",
      "Epoch 28/1200, Iteration 10/12, Loss: 0.0218\n",
      "Epoch 28/1200, Iteration 11/12, Loss: 0.0256\n",
      "Epoch 28/1200, Iteration 12/12, Loss: 0.0336\n",
      "Epoch 28/1200, Iteration 13/12, Loss: 0.0062\n",
      "Train Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.018997, MRE: 0.073483, MAE: 0.010013 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.015445, MRE: 0.052724, MAE: 0.009890 \n",
      "\n",
      "Epoch 29/1200, Iteration 1/12, Loss: 0.0299\n",
      "Epoch 29/1200, Iteration 2/12, Loss: 0.0289\n",
      "Epoch 29/1200, Iteration 3/12, Loss: 0.0309\n",
      "Epoch 29/1200, Iteration 4/12, Loss: 0.0127\n",
      "Epoch 29/1200, Iteration 5/12, Loss: 0.0181\n",
      "Epoch 29/1200, Iteration 6/12, Loss: 0.0112\n",
      "Epoch 29/1200, Iteration 7/12, Loss: 0.0161\n",
      "Epoch 29/1200, Iteration 8/12, Loss: 0.0207\n",
      "Epoch 29/1200, Iteration 9/12, Loss: 0.0154\n",
      "Epoch 29/1200, Iteration 10/12, Loss: 0.0266\n",
      "Epoch 29/1200, Iteration 11/12, Loss: 0.0203\n",
      "Epoch 29/1200, Iteration 12/12, Loss: 0.0127\n",
      "Epoch 29/1200, Iteration 13/12, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 87.38%, Avg loss: 0.018607, MRE: 0.073635, MAE: 0.009851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.013994, MRE: 0.051813, MAE: 0.009603 \n",
      "\n",
      "Epoch 30/1200, Iteration 1/12, Loss: 0.0466\n",
      "Epoch 30/1200, Iteration 2/12, Loss: 0.0167\n",
      "Epoch 30/1200, Iteration 3/12, Loss: 0.0312\n",
      "Epoch 30/1200, Iteration 4/12, Loss: 0.0139\n",
      "Epoch 30/1200, Iteration 5/12, Loss: 0.0146\n",
      "Epoch 30/1200, Iteration 6/12, Loss: 0.0179\n",
      "Epoch 30/1200, Iteration 7/12, Loss: 0.0099\n",
      "Epoch 30/1200, Iteration 8/12, Loss: 0.0086\n",
      "Epoch 30/1200, Iteration 9/12, Loss: 0.0351\n",
      "Epoch 30/1200, Iteration 10/12, Loss: 0.0184\n",
      "Epoch 30/1200, Iteration 11/12, Loss: 0.0113\n",
      "Epoch 30/1200, Iteration 12/12, Loss: 0.0169\n",
      "Epoch 30/1200, Iteration 13/12, Loss: 0.0149\n",
      "Train Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.018524, MRE: 0.062778, MAE: 0.009741 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.014007, MRE: 0.051388, MAE: 0.009508 \n",
      "\n",
      "Epoch 31/1200, Iteration 1/12, Loss: 0.0108\n",
      "Epoch 31/1200, Iteration 2/12, Loss: 0.0207\n",
      "Epoch 31/1200, Iteration 3/12, Loss: 0.0157\n",
      "Epoch 31/1200, Iteration 4/12, Loss: 0.0123\n",
      "Epoch 31/1200, Iteration 5/12, Loss: 0.0195\n",
      "Epoch 31/1200, Iteration 6/12, Loss: 0.0175\n",
      "Epoch 31/1200, Iteration 7/12, Loss: 0.0078\n",
      "Epoch 31/1200, Iteration 8/12, Loss: 0.0527\n",
      "Epoch 31/1200, Iteration 9/12, Loss: 0.0169\n",
      "Epoch 31/1200, Iteration 10/12, Loss: 0.0088\n",
      "Epoch 31/1200, Iteration 11/12, Loss: 0.0212\n",
      "Epoch 31/1200, Iteration 12/12, Loss: 0.0142\n",
      "Epoch 31/1200, Iteration 13/12, Loss: 0.0491\n",
      "Train Error: \n",
      " Accuracy: 91.38%, Avg loss: 0.017729, MRE: 0.061847, MAE: 0.009685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.015624, MRE: 0.052497, MAE: 0.009877 \n",
      "\n",
      "Epoch 32/1200, Iteration 1/12, Loss: 0.0162\n",
      "Epoch 32/1200, Iteration 2/12, Loss: 0.0355\n",
      "Epoch 32/1200, Iteration 3/12, Loss: 0.0138\n",
      "Epoch 32/1200, Iteration 4/12, Loss: 0.0227\n",
      "Epoch 32/1200, Iteration 5/12, Loss: 0.0079\n",
      "Epoch 32/1200, Iteration 6/12, Loss: 0.0090\n",
      "Epoch 32/1200, Iteration 7/12, Loss: 0.0201\n",
      "Epoch 32/1200, Iteration 8/12, Loss: 0.0191\n",
      "Epoch 32/1200, Iteration 9/12, Loss: 0.0110\n",
      "Epoch 32/1200, Iteration 10/12, Loss: 0.0417\n",
      "Epoch 32/1200, Iteration 11/12, Loss: 0.0178\n",
      "Epoch 32/1200, Iteration 12/12, Loss: 0.0189\n",
      "Epoch 32/1200, Iteration 13/12, Loss: 0.0246\n",
      "Train Error: \n",
      " Accuracy: 88.75%, Avg loss: 0.017282, MRE: 0.060621, MAE: 0.009484 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.013805, MRE: 0.050938, MAE: 0.009471 \n",
      "\n",
      "Epoch 33/1200, Iteration 1/12, Loss: 0.0229\n",
      "Epoch 33/1200, Iteration 2/12, Loss: 0.0199\n",
      "Epoch 33/1200, Iteration 3/12, Loss: 0.0216\n",
      "Epoch 33/1200, Iteration 4/12, Loss: 0.0341\n",
      "Epoch 33/1200, Iteration 5/12, Loss: 0.0156\n",
      "Epoch 33/1200, Iteration 6/12, Loss: 0.0186\n",
      "Epoch 33/1200, Iteration 7/12, Loss: 0.0173\n",
      "Epoch 33/1200, Iteration 8/12, Loss: 0.0140\n",
      "Epoch 33/1200, Iteration 9/12, Loss: 0.0090\n",
      "Epoch 33/1200, Iteration 10/12, Loss: 0.0184\n",
      "Epoch 33/1200, Iteration 11/12, Loss: 0.0147\n",
      "Epoch 33/1200, Iteration 12/12, Loss: 0.0153\n",
      "Epoch 33/1200, Iteration 13/12, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 85.62%, Avg loss: 0.018063, MRE: 0.060532, MAE: 0.009608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.012730, MRE: 0.050250, MAE: 0.009273 \n",
      "\n",
      "Epoch 34/1200, Iteration 1/12, Loss: 0.0204\n",
      "Epoch 34/1200, Iteration 2/12, Loss: 0.0107\n",
      "Epoch 34/1200, Iteration 3/12, Loss: 0.0136\n",
      "Epoch 34/1200, Iteration 4/12, Loss: 0.0085\n",
      "Epoch 34/1200, Iteration 5/12, Loss: 0.0180\n",
      "Epoch 34/1200, Iteration 6/12, Loss: 0.0159\n",
      "Epoch 34/1200, Iteration 7/12, Loss: 0.0167\n",
      "Epoch 34/1200, Iteration 8/12, Loss: 0.0332\n",
      "Epoch 34/1200, Iteration 9/12, Loss: 0.0146\n",
      "Epoch 34/1200, Iteration 10/12, Loss: 0.0098\n",
      "Epoch 34/1200, Iteration 11/12, Loss: 0.0183\n",
      "Epoch 34/1200, Iteration 12/12, Loss: 0.0212\n",
      "Epoch 34/1200, Iteration 13/12, Loss: 0.0576\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.017078, MRE: 0.061341, MAE: 0.009571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.016118, MRE: 0.052410, MAE: 0.010044 \n",
      "\n",
      "Epoch 35/1200, Iteration 1/12, Loss: 0.0107\n",
      "Epoch 35/1200, Iteration 2/12, Loss: 0.0382\n",
      "Epoch 35/1200, Iteration 3/12, Loss: 0.0180\n",
      "Epoch 35/1200, Iteration 4/12, Loss: 0.0151\n",
      "Epoch 35/1200, Iteration 5/12, Loss: 0.0107\n",
      "Epoch 35/1200, Iteration 6/12, Loss: 0.0290\n",
      "Epoch 35/1200, Iteration 7/12, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1200, Iteration 8/12, Loss: 0.0065\n",
      "Epoch 35/1200, Iteration 9/12, Loss: 0.0380\n",
      "Epoch 35/1200, Iteration 10/12, Loss: 0.0192\n",
      "Epoch 35/1200, Iteration 11/12, Loss: 0.0101\n",
      "Epoch 35/1200, Iteration 12/12, Loss: 0.0116\n",
      "Epoch 35/1200, Iteration 13/12, Loss: 0.0289\n",
      "Train Error: \n",
      " Accuracy: 85.62%, Avg loss: 0.016648, MRE: 0.058197, MAE: 0.009281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.013065, MRE: 0.050298, MAE: 0.009293 \n",
      "\n",
      "Epoch 36/1200, Iteration 1/12, Loss: 0.0074\n",
      "Epoch 36/1200, Iteration 2/12, Loss: 0.0311\n",
      "Epoch 36/1200, Iteration 3/12, Loss: 0.0308\n",
      "Epoch 36/1200, Iteration 4/12, Loss: 0.0234\n",
      "Epoch 36/1200, Iteration 5/12, Loss: 0.0134\n",
      "Epoch 36/1200, Iteration 6/12, Loss: 0.0168\n",
      "Epoch 36/1200, Iteration 7/12, Loss: 0.0067\n",
      "Epoch 36/1200, Iteration 8/12, Loss: 0.0210\n",
      "Epoch 36/1200, Iteration 9/12, Loss: 0.0157\n",
      "Epoch 36/1200, Iteration 10/12, Loss: 0.0162\n",
      "Epoch 36/1200, Iteration 11/12, Loss: 0.0167\n",
      "Epoch 36/1200, Iteration 12/12, Loss: 0.0117\n",
      "Epoch 36/1200, Iteration 13/12, Loss: 0.0224\n",
      "Train Error: \n",
      " Accuracy: 88.88%, Avg loss: 0.017158, MRE: 0.059569, MAE: 0.009315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.012947, MRE: 0.049244, MAE: 0.009173 \n",
      "\n",
      "Epoch 37/1200, Iteration 1/12, Loss: 0.0101\n",
      "Epoch 37/1200, Iteration 2/12, Loss: 0.0174\n",
      "Epoch 37/1200, Iteration 3/12, Loss: 0.0192\n",
      "Epoch 37/1200, Iteration 4/12, Loss: 0.0172\n",
      "Epoch 37/1200, Iteration 5/12, Loss: 0.0242\n",
      "Epoch 37/1200, Iteration 6/12, Loss: 0.0148\n",
      "Epoch 37/1200, Iteration 7/12, Loss: 0.0189\n",
      "Epoch 37/1200, Iteration 8/12, Loss: 0.0194\n",
      "Epoch 37/1200, Iteration 9/12, Loss: 0.0107\n",
      "Epoch 37/1200, Iteration 10/12, Loss: 0.0140\n",
      "Epoch 37/1200, Iteration 11/12, Loss: 0.0281\n",
      "Epoch 37/1200, Iteration 12/12, Loss: 0.0171\n",
      "Epoch 37/1200, Iteration 13/12, Loss: 0.0148\n",
      "Train Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.016545, MRE: 0.060885, MAE: 0.009275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.013508, MRE: 0.049352, MAE: 0.009260 \n",
      "\n",
      "Epoch 38/1200, Iteration 1/12, Loss: 0.0107\n",
      "Epoch 38/1200, Iteration 2/12, Loss: 0.0158\n",
      "Epoch 38/1200, Iteration 3/12, Loss: 0.0074\n",
      "Epoch 38/1200, Iteration 4/12, Loss: 0.0284\n",
      "Epoch 38/1200, Iteration 5/12, Loss: 0.0147\n",
      "Epoch 38/1200, Iteration 6/12, Loss: 0.0196\n",
      "Epoch 38/1200, Iteration 7/12, Loss: 0.0303\n",
      "Epoch 38/1200, Iteration 8/12, Loss: 0.0125\n",
      "Epoch 38/1200, Iteration 9/12, Loss: 0.0187\n",
      "Epoch 38/1200, Iteration 10/12, Loss: 0.0278\n",
      "Epoch 38/1200, Iteration 11/12, Loss: 0.0126\n",
      "Epoch 38/1200, Iteration 12/12, Loss: 0.0151\n",
      "Epoch 38/1200, Iteration 13/12, Loss: 0.0068\n",
      "Train Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.015874, MRE: 0.059305, MAE: 0.009117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.014020, MRE: 0.049480, MAE: 0.009369 \n",
      "\n",
      "Epoch 39/1200, Iteration 1/12, Loss: 0.0095\n",
      "Epoch 39/1200, Iteration 2/12, Loss: 0.0091\n",
      "Epoch 39/1200, Iteration 3/12, Loss: 0.0199\n",
      "Epoch 39/1200, Iteration 4/12, Loss: 0.0223\n",
      "Epoch 39/1200, Iteration 5/12, Loss: 0.0340\n",
      "Epoch 39/1200, Iteration 6/12, Loss: 0.0192\n",
      "Epoch 39/1200, Iteration 7/12, Loss: 0.0150\n",
      "Epoch 39/1200, Iteration 8/12, Loss: 0.0159\n",
      "Epoch 39/1200, Iteration 9/12, Loss: 0.0076\n",
      "Epoch 39/1200, Iteration 10/12, Loss: 0.0103\n",
      "Epoch 39/1200, Iteration 11/12, Loss: 0.0122\n",
      "Epoch 39/1200, Iteration 12/12, Loss: 0.0312\n",
      "Epoch 39/1200, Iteration 13/12, Loss: 0.0068\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.016963, MRE: 0.058753, MAE: 0.009172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.012531, MRE: 0.048127, MAE: 0.008950 \n",
      "\n",
      "Epoch 40/1200, Iteration 1/12, Loss: 0.0187\n",
      "Epoch 40/1200, Iteration 2/12, Loss: 0.0099\n",
      "Epoch 40/1200, Iteration 3/12, Loss: 0.0270\n",
      "Epoch 40/1200, Iteration 4/12, Loss: 0.0134\n",
      "Epoch 40/1200, Iteration 5/12, Loss: 0.0104\n",
      "Epoch 40/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 40/1200, Iteration 7/12, Loss: 0.0235\n",
      "Epoch 40/1200, Iteration 8/12, Loss: 0.0247\n",
      "Epoch 40/1200, Iteration 9/12, Loss: 0.0138\n",
      "Epoch 40/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 40/1200, Iteration 11/12, Loss: 0.0164\n",
      "Epoch 40/1200, Iteration 12/12, Loss: 0.0295\n",
      "Epoch 40/1200, Iteration 13/12, Loss: 0.0144\n",
      "Train Error: \n",
      " Accuracy: 88.88%, Avg loss: 0.015228, MRE: 0.056678, MAE: 0.008820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.012451, MRE: 0.047868, MAE: 0.008973 \n",
      "\n",
      "Epoch 41/1200, Iteration 1/12, Loss: 0.0099\n",
      "Epoch 41/1200, Iteration 2/12, Loss: 0.0129\n",
      "Epoch 41/1200, Iteration 3/12, Loss: 0.0267\n",
      "Epoch 41/1200, Iteration 4/12, Loss: 0.0110\n",
      "Epoch 41/1200, Iteration 5/12, Loss: 0.0118\n",
      "Epoch 41/1200, Iteration 6/12, Loss: 0.0115\n",
      "Epoch 41/1200, Iteration 7/12, Loss: 0.0099\n",
      "Epoch 41/1200, Iteration 8/12, Loss: 0.0321\n",
      "Epoch 41/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 41/1200, Iteration 10/12, Loss: 0.0135\n",
      "Epoch 41/1200, Iteration 11/12, Loss: 0.0404\n",
      "Epoch 41/1200, Iteration 12/12, Loss: 0.0216\n",
      "Epoch 41/1200, Iteration 13/12, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 90.12%, Avg loss: 0.015245, MRE: 0.057367, MAE: 0.008867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.012656, MRE: 0.047649, MAE: 0.008937 \n",
      "\n",
      "Epoch 42/1200, Iteration 1/12, Loss: 0.0100\n",
      "Epoch 42/1200, Iteration 2/12, Loss: 0.0200\n",
      "Epoch 42/1200, Iteration 3/12, Loss: 0.0075\n",
      "Epoch 42/1200, Iteration 4/12, Loss: 0.0089\n",
      "Epoch 42/1200, Iteration 5/12, Loss: 0.0377\n",
      "Epoch 42/1200, Iteration 6/12, Loss: 0.0176\n",
      "Epoch 42/1200, Iteration 7/12, Loss: 0.0251\n",
      "Epoch 42/1200, Iteration 8/12, Loss: 0.0061\n",
      "Epoch 42/1200, Iteration 9/12, Loss: 0.0207\n",
      "Epoch 42/1200, Iteration 10/12, Loss: 0.0128\n",
      "Epoch 42/1200, Iteration 11/12, Loss: 0.0100\n",
      "Epoch 42/1200, Iteration 12/12, Loss: 0.0173\n",
      "Epoch 42/1200, Iteration 13/12, Loss: 0.0179\n",
      "Train Error: \n",
      " Accuracy: 90.88%, Avg loss: 0.015331, MRE: 0.056668, MAE: 0.008850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.012806, MRE: 0.047657, MAE: 0.008991 \n",
      "\n",
      "Epoch 43/1200, Iteration 1/12, Loss: 0.0221\n",
      "Epoch 43/1200, Iteration 2/12, Loss: 0.0086\n",
      "Epoch 43/1200, Iteration 3/12, Loss: 0.0148\n",
      "Epoch 43/1200, Iteration 4/12, Loss: 0.0261\n",
      "Epoch 43/1200, Iteration 5/12, Loss: 0.0109\n",
      "Epoch 43/1200, Iteration 6/12, Loss: 0.0105\n",
      "Epoch 43/1200, Iteration 7/12, Loss: 0.0245\n",
      "Epoch 43/1200, Iteration 8/12, Loss: 0.0255\n",
      "Epoch 43/1200, Iteration 9/12, Loss: 0.0133\n",
      "Epoch 43/1200, Iteration 10/12, Loss: 0.0100\n",
      "Epoch 43/1200, Iteration 11/12, Loss: 0.0193\n",
      "Epoch 43/1200, Iteration 12/12, Loss: 0.0148\n",
      "Epoch 43/1200, Iteration 13/12, Loss: 0.0145\n",
      "Train Error: \n",
      " Accuracy: 86.75%, Avg loss: 0.014914, MRE: 0.055785, MAE: 0.008819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.011552, MRE: 0.047116, MAE: 0.008819 \n",
      "\n",
      "Epoch 44/1200, Iteration 1/12, Loss: 0.0176\n",
      "Epoch 44/1200, Iteration 2/12, Loss: 0.0130\n",
      "Epoch 44/1200, Iteration 3/12, Loss: 0.0207\n",
      "Epoch 44/1200, Iteration 4/12, Loss: 0.0124\n",
      "Epoch 44/1200, Iteration 5/12, Loss: 0.0254\n",
      "Epoch 44/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 44/1200, Iteration 7/12, Loss: 0.0330\n",
      "Epoch 44/1200, Iteration 8/12, Loss: 0.0200\n",
      "Epoch 44/1200, Iteration 9/12, Loss: 0.0088\n",
      "Epoch 44/1200, Iteration 10/12, Loss: 0.0210\n",
      "Epoch 44/1200, Iteration 11/12, Loss: 0.0101\n",
      "Epoch 44/1200, Iteration 12/12, Loss: 0.0075\n",
      "Epoch 44/1200, Iteration 13/12, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 88.62%, Avg loss: 0.015054, MRE: 0.055627, MAE: 0.008738 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.011563, MRE: 0.046303, MAE: 0.008660 \n",
      "\n",
      "Epoch 45/1200, Iteration 1/12, Loss: 0.0135\n",
      "Epoch 45/1200, Iteration 2/12, Loss: 0.0216\n",
      "Epoch 45/1200, Iteration 3/12, Loss: 0.0175\n",
      "Epoch 45/1200, Iteration 4/12, Loss: 0.0148\n",
      "Epoch 45/1200, Iteration 5/12, Loss: 0.0063\n",
      "Epoch 45/1200, Iteration 6/12, Loss: 0.0321\n",
      "Epoch 45/1200, Iteration 7/12, Loss: 0.0163\n",
      "Epoch 45/1200, Iteration 8/12, Loss: 0.0123\n",
      "Epoch 45/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 45/1200, Iteration 10/12, Loss: 0.0219\n",
      "Epoch 45/1200, Iteration 11/12, Loss: 0.0161\n",
      "Epoch 45/1200, Iteration 12/12, Loss: 0.0083\n",
      "Epoch 45/1200, Iteration 13/12, Loss: 0.0159\n",
      "Train Error: \n",
      " Accuracy: 88.12%, Avg loss: 0.014570, MRE: 0.054872, MAE: 0.008611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.011220, MRE: 0.045961, MAE: 0.008542 \n",
      "\n",
      "Epoch 46/1200, Iteration 1/12, Loss: 0.0255\n",
      "Epoch 46/1200, Iteration 2/12, Loss: 0.0102\n",
      "Epoch 46/1200, Iteration 3/12, Loss: 0.0129\n",
      "Epoch 46/1200, Iteration 4/12, Loss: 0.0272\n",
      "Epoch 46/1200, Iteration 5/12, Loss: 0.0352\n",
      "Epoch 46/1200, Iteration 6/12, Loss: 0.0147\n",
      "Epoch 46/1200, Iteration 7/12, Loss: 0.0102\n",
      "Epoch 46/1200, Iteration 8/12, Loss: 0.0154\n",
      "Epoch 46/1200, Iteration 9/12, Loss: 0.0103\n",
      "Epoch 46/1200, Iteration 10/12, Loss: 0.0103\n",
      "Epoch 46/1200, Iteration 11/12, Loss: 0.0073\n",
      "Epoch 46/1200, Iteration 12/12, Loss: 0.0097\n",
      "Epoch 46/1200, Iteration 13/12, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 90.38%, Avg loss: 0.014294, MRE: 0.064378, MAE: 0.008595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.011873, MRE: 0.046309, MAE: 0.008685 \n",
      "\n",
      "Epoch 47/1200, Iteration 1/12, Loss: 0.0138\n",
      "Epoch 47/1200, Iteration 2/12, Loss: 0.0233\n",
      "Epoch 47/1200, Iteration 3/12, Loss: 0.0149\n",
      "Epoch 47/1200, Iteration 4/12, Loss: 0.0167\n",
      "Epoch 47/1200, Iteration 5/12, Loss: 0.0126\n",
      "Epoch 47/1200, Iteration 6/12, Loss: 0.0155\n",
      "Epoch 47/1200, Iteration 7/12, Loss: 0.0187\n",
      "Epoch 47/1200, Iteration 8/12, Loss: 0.0148\n",
      "Epoch 47/1200, Iteration 9/12, Loss: 0.0321\n",
      "Epoch 47/1200, Iteration 10/12, Loss: 0.0087\n",
      "Epoch 47/1200, Iteration 11/12, Loss: 0.0078\n",
      "Epoch 47/1200, Iteration 12/12, Loss: 0.0106\n",
      "Epoch 47/1200, Iteration 13/12, Loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.014165, MRE: 0.053918, MAE: 0.008492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.011366, MRE: 0.045856, MAE: 0.008595 \n",
      "\n",
      "Epoch 48/1200, Iteration 1/12, Loss: 0.0144\n",
      "Epoch 48/1200, Iteration 2/12, Loss: 0.0122\n",
      "Epoch 48/1200, Iteration 3/12, Loss: 0.0082\n",
      "Epoch 48/1200, Iteration 4/12, Loss: 0.0134\n",
      "Epoch 48/1200, Iteration 5/12, Loss: 0.0183\n",
      "Epoch 48/1200, Iteration 6/12, Loss: 0.0377\n",
      "Epoch 48/1200, Iteration 7/12, Loss: 0.0124\n",
      "Epoch 48/1200, Iteration 8/12, Loss: 0.0138\n",
      "Epoch 48/1200, Iteration 9/12, Loss: 0.0070\n",
      "Epoch 48/1200, Iteration 10/12, Loss: 0.0153\n",
      "Epoch 48/1200, Iteration 11/12, Loss: 0.0098\n",
      "Epoch 48/1200, Iteration 12/12, Loss: 0.0206\n",
      "Epoch 48/1200, Iteration 13/12, Loss: 0.0208\n",
      "Train Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.013897, MRE: 0.052707, MAE: 0.008451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.012520, MRE: 0.046154, MAE: 0.008826 \n",
      "\n",
      "Epoch 49/1200, Iteration 1/12, Loss: 0.0069\n",
      "Epoch 49/1200, Iteration 2/12, Loss: 0.0132\n",
      "Epoch 49/1200, Iteration 3/12, Loss: 0.0085\n",
      "Epoch 49/1200, Iteration 4/12, Loss: 0.0159\n",
      "Epoch 49/1200, Iteration 5/12, Loss: 0.0090\n",
      "Epoch 49/1200, Iteration 6/12, Loss: 0.0150\n",
      "Epoch 49/1200, Iteration 7/12, Loss: 0.0222\n",
      "Epoch 49/1200, Iteration 8/12, Loss: 0.0120\n",
      "Epoch 49/1200, Iteration 9/12, Loss: 0.0089\n",
      "Epoch 49/1200, Iteration 10/12, Loss: 0.0289\n",
      "Epoch 49/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 49/1200, Iteration 12/12, Loss: 0.0348\n",
      "Epoch 49/1200, Iteration 13/12, Loss: 0.0192\n",
      "Train Error: \n",
      " Accuracy: 91.12%, Avg loss: 0.013633, MRE: 0.053358, MAE: 0.008358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.011995, MRE: 0.045571, MAE: 0.008664 \n",
      "\n",
      "Epoch 50/1200, Iteration 1/12, Loss: 0.0127\n",
      "Epoch 50/1200, Iteration 2/12, Loss: 0.0106\n",
      "Epoch 50/1200, Iteration 3/12, Loss: 0.0126\n",
      "Epoch 50/1200, Iteration 4/12, Loss: 0.0137\n",
      "Epoch 50/1200, Iteration 5/12, Loss: 0.0080\n",
      "Epoch 50/1200, Iteration 6/12, Loss: 0.0069\n",
      "Epoch 50/1200, Iteration 7/12, Loss: 0.0098\n",
      "Epoch 50/1200, Iteration 8/12, Loss: 0.0181\n",
      "Epoch 50/1200, Iteration 9/12, Loss: 0.0106\n",
      "Epoch 50/1200, Iteration 10/12, Loss: 0.0317\n",
      "Epoch 50/1200, Iteration 11/12, Loss: 0.0124\n",
      "Epoch 50/1200, Iteration 12/12, Loss: 0.0291\n",
      "Epoch 50/1200, Iteration 13/12, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 90.62%, Avg loss: 0.013707, MRE: 0.052505, MAE: 0.008354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.012046, MRE: 0.045367, MAE: 0.008652 \n",
      "\n",
      "Epoch 51/1200, Iteration 1/12, Loss: 0.0135\n",
      "Epoch 51/1200, Iteration 2/12, Loss: 0.0188\n",
      "Epoch 51/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 51/1200, Iteration 4/12, Loss: 0.0209\n",
      "Epoch 51/1200, Iteration 5/12, Loss: 0.0366\n",
      "Epoch 51/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 51/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 51/1200, Iteration 8/12, Loss: 0.0167\n",
      "Epoch 51/1200, Iteration 9/12, Loss: 0.0182\n",
      "Epoch 51/1200, Iteration 10/12, Loss: 0.0091\n",
      "Epoch 51/1200, Iteration 11/12, Loss: 0.0082\n",
      "Epoch 51/1200, Iteration 12/12, Loss: 0.0113\n",
      "Epoch 51/1200, Iteration 13/12, Loss: 0.0092\n",
      "Train Error: \n",
      " Accuracy: 88.38%, Avg loss: 0.013539, MRE: 0.051643, MAE: 0.008276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.010851, MRE: 0.045021, MAE: 0.008427 \n",
      "\n",
      "Epoch 52/1200, Iteration 1/12, Loss: 0.0314\n",
      "Epoch 52/1200, Iteration 2/12, Loss: 0.0319\n",
      "Epoch 52/1200, Iteration 3/12, Loss: 0.0149\n",
      "Epoch 52/1200, Iteration 4/12, Loss: 0.0103\n",
      "Epoch 52/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 52/1200, Iteration 6/12, Loss: 0.0117\n",
      "Epoch 52/1200, Iteration 7/12, Loss: 0.0143\n",
      "Epoch 52/1200, Iteration 8/12, Loss: 0.0110\n",
      "Epoch 52/1200, Iteration 9/12, Loss: 0.0155\n",
      "Epoch 52/1200, Iteration 10/12, Loss: 0.0090\n",
      "Epoch 52/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 52/1200, Iteration 12/12, Loss: 0.0164\n",
      "Epoch 52/1200, Iteration 13/12, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 89.12%, Avg loss: 0.013179, MRE: 0.052308, MAE: 0.008173 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.010888, MRE: 0.044088, MAE: 0.008359 \n",
      "\n",
      "Epoch 53/1200, Iteration 1/12, Loss: 0.0100\n",
      "Epoch 53/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 53/1200, Iteration 3/12, Loss: 0.0164\n",
      "Epoch 53/1200, Iteration 4/12, Loss: 0.0086\n",
      "Epoch 53/1200, Iteration 5/12, Loss: 0.0176\n",
      "Epoch 53/1200, Iteration 6/12, Loss: 0.0107\n",
      "Epoch 53/1200, Iteration 7/12, Loss: 0.0150\n",
      "Epoch 53/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 53/1200, Iteration 9/12, Loss: 0.0082\n",
      "Epoch 53/1200, Iteration 10/12, Loss: 0.0113\n",
      "Epoch 53/1200, Iteration 11/12, Loss: 0.0281\n",
      "Epoch 53/1200, Iteration 12/12, Loss: 0.0296\n",
      "Epoch 53/1200, Iteration 13/12, Loss: 0.0122\n",
      "Train Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.014539, MRE: 0.053650, MAE: 0.008330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.011526, MRE: 0.044494, MAE: 0.008514 \n",
      "\n",
      "Epoch 54/1200, Iteration 1/12, Loss: 0.0349\n",
      "Epoch 54/1200, Iteration 2/12, Loss: 0.0227\n",
      "Epoch 54/1200, Iteration 3/12, Loss: 0.0115\n",
      "Epoch 54/1200, Iteration 4/12, Loss: 0.0101\n",
      "Epoch 54/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 54/1200, Iteration 6/12, Loss: 0.0100\n",
      "Epoch 54/1200, Iteration 7/12, Loss: 0.0148\n",
      "Epoch 54/1200, Iteration 8/12, Loss: 0.0081\n",
      "Epoch 54/1200, Iteration 9/12, Loss: 0.0075\n",
      "Epoch 54/1200, Iteration 10/12, Loss: 0.0128\n",
      "Epoch 54/1200, Iteration 11/12, Loss: 0.0098\n",
      "Epoch 54/1200, Iteration 12/12, Loss: 0.0140\n",
      "Epoch 54/1200, Iteration 13/12, Loss: 0.0329\n",
      "Train Error: \n",
      " Accuracy: 91.12%, Avg loss: 0.013238, MRE: 0.051527, MAE: 0.008136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.011128, MRE: 0.043878, MAE: 0.008362 \n",
      "\n",
      "Epoch 55/1200, Iteration 1/12, Loss: 0.0238\n",
      "Epoch 55/1200, Iteration 2/12, Loss: 0.0085\n",
      "Epoch 55/1200, Iteration 3/12, Loss: 0.0222\n",
      "Epoch 55/1200, Iteration 4/12, Loss: 0.0091\n",
      "Epoch 55/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 55/1200, Iteration 6/12, Loss: 0.0197\n",
      "Epoch 55/1200, Iteration 7/12, Loss: 0.0104\n",
      "Epoch 55/1200, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 55/1200, Iteration 9/12, Loss: 0.0211\n",
      "Epoch 55/1200, Iteration 10/12, Loss: 0.0080\n",
      "Epoch 55/1200, Iteration 11/12, Loss: 0.0166\n",
      "Epoch 55/1200, Iteration 12/12, Loss: 0.0234\n",
      "Epoch 55/1200, Iteration 13/12, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 92.25%, Avg loss: 0.012775, MRE: 0.052273, MAE: 0.008038 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.011394, MRE: 0.043909, MAE: 0.008401 \n",
      "\n",
      "Epoch 56/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 56/1200, Iteration 2/12, Loss: 0.0131\n",
      "Epoch 56/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 56/1200, Iteration 4/12, Loss: 0.0106\n",
      "Epoch 56/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 56/1200, Iteration 6/12, Loss: 0.0160\n",
      "Epoch 56/1200, Iteration 7/12, Loss: 0.0191\n",
      "Epoch 56/1200, Iteration 8/12, Loss: 0.0288\n",
      "Epoch 56/1200, Iteration 9/12, Loss: 0.0145\n",
      "Epoch 56/1200, Iteration 10/12, Loss: 0.0168\n",
      "Epoch 56/1200, Iteration 11/12, Loss: 0.0218\n",
      "Epoch 56/1200, Iteration 12/12, Loss: 0.0107\n",
      "Epoch 56/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.012582, MRE: 0.051565, MAE: 0.007911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.010865, MRE: 0.043276, MAE: 0.008212 \n",
      "\n",
      "Epoch 57/1200, Iteration 1/12, Loss: 0.0164\n",
      "Epoch 57/1200, Iteration 2/12, Loss: 0.0139\n",
      "Epoch 57/1200, Iteration 3/12, Loss: 0.0127\n",
      "Epoch 57/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 57/1200, Iteration 5/12, Loss: 0.0104\n",
      "Epoch 57/1200, Iteration 6/12, Loss: 0.0082\n",
      "Epoch 57/1200, Iteration 7/12, Loss: 0.0118\n",
      "Epoch 57/1200, Iteration 8/12, Loss: 0.0185\n",
      "Epoch 57/1200, Iteration 9/12, Loss: 0.0066\n",
      "Epoch 57/1200, Iteration 10/12, Loss: 0.0393\n",
      "Epoch 57/1200, Iteration 11/12, Loss: 0.0112\n",
      "Epoch 57/1200, Iteration 12/12, Loss: 0.0116\n",
      "Epoch 57/1200, Iteration 13/12, Loss: 0.0173\n",
      "Train Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.012576, MRE: 0.050871, MAE: 0.007937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.011018, MRE: 0.043277, MAE: 0.008241 \n",
      "\n",
      "Epoch 58/1200, Iteration 1/12, Loss: 0.0092\n",
      "Epoch 58/1200, Iteration 2/12, Loss: 0.0136\n",
      "Epoch 58/1200, Iteration 3/12, Loss: 0.0093\n",
      "Epoch 58/1200, Iteration 4/12, Loss: 0.0071\n",
      "Epoch 58/1200, Iteration 5/12, Loss: 0.0330\n",
      "Epoch 58/1200, Iteration 6/12, Loss: 0.0164\n",
      "Epoch 58/1200, Iteration 7/12, Loss: 0.0118\n",
      "Epoch 58/1200, Iteration 8/12, Loss: 0.0100\n",
      "Epoch 58/1200, Iteration 9/12, Loss: 0.0199\n",
      "Epoch 58/1200, Iteration 10/12, Loss: 0.0102\n",
      "Epoch 58/1200, Iteration 11/12, Loss: 0.0083\n",
      "Epoch 58/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 58/1200, Iteration 13/12, Loss: 0.0318\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.012834, MRE: 0.051614, MAE: 0.008098 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.012691, MRE: 0.044622, MAE: 0.008665 \n",
      "\n",
      "Epoch 59/1200, Iteration 1/12, Loss: 0.0123\n",
      "Epoch 59/1200, Iteration 2/12, Loss: 0.0071\n",
      "Epoch 59/1200, Iteration 3/12, Loss: 0.0203\n",
      "Epoch 59/1200, Iteration 4/12, Loss: 0.0245\n",
      "Epoch 59/1200, Iteration 5/12, Loss: 0.0086\n",
      "Epoch 59/1200, Iteration 6/12, Loss: 0.0113\n",
      "Epoch 59/1200, Iteration 7/12, Loss: 0.0172\n",
      "Epoch 59/1200, Iteration 8/12, Loss: 0.0227\n",
      "Epoch 59/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 59/1200, Iteration 10/12, Loss: 0.0105\n",
      "Epoch 59/1200, Iteration 11/12, Loss: 0.0131\n",
      "Epoch 59/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 59/1200, Iteration 13/12, Loss: 0.0149\n",
      "Train Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.012196, MRE: 0.048936, MAE: 0.007877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.011008, MRE: 0.043053, MAE: 0.008276 \n",
      "\n",
      "Epoch 60/1200, Iteration 1/12, Loss: 0.0087\n",
      "Epoch 60/1200, Iteration 2/12, Loss: 0.0161\n",
      "Epoch 60/1200, Iteration 3/12, Loss: 0.0105\n",
      "Epoch 60/1200, Iteration 4/12, Loss: 0.0147\n",
      "Epoch 60/1200, Iteration 5/12, Loss: 0.0146\n",
      "Epoch 60/1200, Iteration 6/12, Loss: 0.0100\n",
      "Epoch 60/1200, Iteration 7/12, Loss: 0.0116\n",
      "Epoch 60/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 60/1200, Iteration 9/12, Loss: 0.0152\n",
      "Epoch 60/1200, Iteration 10/12, Loss: 0.0081\n",
      "Epoch 60/1200, Iteration 11/12, Loss: 0.0111\n",
      "Epoch 60/1200, Iteration 12/12, Loss: 0.0216\n",
      "Epoch 60/1200, Iteration 13/12, Loss: 0.0379\n",
      "Train Error: \n",
      " Accuracy: 93.12%, Avg loss: 0.013592, MRE: 0.059155, MAE: 0.008174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.012383, MRE: 0.043997, MAE: 0.008572 \n",
      "\n",
      "Epoch 61/1200, Iteration 1/12, Loss: 0.0231\n",
      "Epoch 61/1200, Iteration 2/12, Loss: 0.0079\n",
      "Epoch 61/1200, Iteration 3/12, Loss: 0.0090\n",
      "Epoch 61/1200, Iteration 4/12, Loss: 0.0151\n",
      "Epoch 61/1200, Iteration 5/12, Loss: 0.0099\n",
      "Epoch 61/1200, Iteration 6/12, Loss: 0.0091\n",
      "Epoch 61/1200, Iteration 7/12, Loss: 0.0170\n",
      "Epoch 61/1200, Iteration 8/12, Loss: 0.0171\n",
      "Epoch 61/1200, Iteration 9/12, Loss: 0.0197\n",
      "Epoch 61/1200, Iteration 10/12, Loss: 0.0214\n",
      "Epoch 61/1200, Iteration 11/12, Loss: 0.0070\n",
      "Epoch 61/1200, Iteration 12/12, Loss: 0.0117\n",
      "Epoch 61/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 90.12%, Avg loss: 0.012914, MRE: 0.049519, MAE: 0.007891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.010252, MRE: 0.042341, MAE: 0.008099 \n",
      "\n",
      "Epoch 62/1200, Iteration 1/12, Loss: 0.0206\n",
      "Epoch 62/1200, Iteration 2/12, Loss: 0.0124\n",
      "Epoch 62/1200, Iteration 3/12, Loss: 0.0094\n",
      "Epoch 62/1200, Iteration 4/12, Loss: 0.0173\n",
      "Epoch 62/1200, Iteration 5/12, Loss: 0.0162\n",
      "Epoch 62/1200, Iteration 6/12, Loss: 0.0072\n",
      "Epoch 62/1200, Iteration 7/12, Loss: 0.0094\n",
      "Epoch 62/1200, Iteration 8/12, Loss: 0.0223\n",
      "Epoch 62/1200, Iteration 9/12, Loss: 0.0083\n",
      "Epoch 62/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 62/1200, Iteration 11/12, Loss: 0.0084\n",
      "Epoch 62/1200, Iteration 12/12, Loss: 0.0216\n",
      "Epoch 62/1200, Iteration 13/12, Loss: 0.0159\n",
      "Train Error: \n",
      " Accuracy: 91.38%, Avg loss: 0.011913, MRE: 0.048662, MAE: 0.007725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.010422, MRE: 0.042217, MAE: 0.008092 \n",
      "\n",
      "Epoch 63/1200, Iteration 1/12, Loss: 0.0098\n",
      "Epoch 63/1200, Iteration 2/12, Loss: 0.0221\n",
      "Epoch 63/1200, Iteration 3/12, Loss: 0.0146\n",
      "Epoch 63/1200, Iteration 4/12, Loss: 0.0178\n",
      "Epoch 63/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 63/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 63/1200, Iteration 7/12, Loss: 0.0074\n",
      "Epoch 63/1200, Iteration 8/12, Loss: 0.0071\n",
      "Epoch 63/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 63/1200, Iteration 10/12, Loss: 0.0240\n",
      "Epoch 63/1200, Iteration 11/12, Loss: 0.0092\n",
      "Epoch 63/1200, Iteration 12/12, Loss: 0.0143\n",
      "Epoch 63/1200, Iteration 13/12, Loss: 0.0321\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.011806, MRE: 0.048720, MAE: 0.007766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.010793, MRE: 0.042159, MAE: 0.008114 \n",
      "\n",
      "Epoch 64/1200, Iteration 1/12, Loss: 0.0059\n",
      "Epoch 64/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 64/1200, Iteration 3/12, Loss: 0.0158\n",
      "Epoch 64/1200, Iteration 4/12, Loss: 0.0088\n",
      "Epoch 64/1200, Iteration 5/12, Loss: 0.0094\n",
      "Epoch 64/1200, Iteration 6/12, Loss: 0.0153\n",
      "Epoch 64/1200, Iteration 7/12, Loss: 0.0228\n",
      "Epoch 64/1200, Iteration 8/12, Loss: 0.0127\n",
      "Epoch 64/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 64/1200, Iteration 10/12, Loss: 0.0212\n",
      "Epoch 64/1200, Iteration 11/12, Loss: 0.0157\n",
      "Epoch 64/1200, Iteration 12/12, Loss: 0.0144\n",
      "Epoch 64/1200, Iteration 13/12, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 91.75%, Avg loss: 0.011625, MRE: 0.047897, MAE: 0.007611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.010243, MRE: 0.041591, MAE: 0.007963 \n",
      "\n",
      "Epoch 65/1200, Iteration 1/12, Loss: 0.0151\n",
      "Epoch 65/1200, Iteration 2/12, Loss: 0.0148\n",
      "Epoch 65/1200, Iteration 3/12, Loss: 0.0111\n",
      "Epoch 65/1200, Iteration 4/12, Loss: 0.0079\n",
      "Epoch 65/1200, Iteration 5/12, Loss: 0.0075\n",
      "Epoch 65/1200, Iteration 6/12, Loss: 0.0090\n",
      "Epoch 65/1200, Iteration 7/12, Loss: 0.0158\n",
      "Epoch 65/1200, Iteration 8/12, Loss: 0.0214\n",
      "Epoch 65/1200, Iteration 9/12, Loss: 0.0068\n",
      "Epoch 65/1200, Iteration 10/12, Loss: 0.0111\n",
      "Epoch 65/1200, Iteration 11/12, Loss: 0.0152\n",
      "Epoch 65/1200, Iteration 12/12, Loss: 0.0161\n",
      "Epoch 65/1200, Iteration 13/12, Loss: 0.0068\n",
      "Train Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.011584, MRE: 0.048580, MAE: 0.007645 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.010727, MRE: 0.041804, MAE: 0.008079 \n",
      "\n",
      "Epoch 66/1200, Iteration 1/12, Loss: 0.0096\n",
      "Epoch 66/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 66/1200, Iteration 3/12, Loss: 0.0140\n",
      "Epoch 66/1200, Iteration 4/12, Loss: 0.0072\n",
      "Epoch 66/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 66/1200, Iteration 6/12, Loss: 0.0400\n",
      "Epoch 66/1200, Iteration 7/12, Loss: 0.0135\n",
      "Epoch 66/1200, Iteration 8/12, Loss: 0.0231\n",
      "Epoch 66/1200, Iteration 9/12, Loss: 0.0107\n",
      "Epoch 66/1200, Iteration 10/12, Loss: 0.0062\n",
      "Epoch 66/1200, Iteration 11/12, Loss: 0.0081\n",
      "Epoch 66/1200, Iteration 12/12, Loss: 0.0122\n",
      "Epoch 66/1200, Iteration 13/12, Loss: 0.0097\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.012205, MRE: 0.048172, MAE: 0.007658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.009976, MRE: 0.041185, MAE: 0.007885 \n",
      "\n",
      "Epoch 67/1200, Iteration 1/12, Loss: 0.0080\n",
      "Epoch 67/1200, Iteration 2/12, Loss: 0.0110\n",
      "Epoch 67/1200, Iteration 3/12, Loss: 0.0317\n",
      "Epoch 67/1200, Iteration 4/12, Loss: 0.0065\n",
      "Epoch 67/1200, Iteration 5/12, Loss: 0.0143\n",
      "Epoch 67/1200, Iteration 6/12, Loss: 0.0100\n",
      "Epoch 67/1200, Iteration 7/12, Loss: 0.0085\n",
      "Epoch 67/1200, Iteration 8/12, Loss: 0.0092\n",
      "Epoch 67/1200, Iteration 9/12, Loss: 0.0079\n",
      "Epoch 67/1200, Iteration 10/12, Loss: 0.0173\n",
      "Epoch 67/1200, Iteration 11/12, Loss: 0.0106\n",
      "Epoch 67/1200, Iteration 12/12, Loss: 0.0148\n",
      "Epoch 67/1200, Iteration 13/12, Loss: 0.0262\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.011693, MRE: 0.047949, MAE: 0.007598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.010659, MRE: 0.041333, MAE: 0.007966 \n",
      "\n",
      "Epoch 68/1200, Iteration 1/12, Loss: 0.0245\n",
      "Epoch 68/1200, Iteration 2/12, Loss: 0.0170\n",
      "Epoch 68/1200, Iteration 3/12, Loss: 0.0175\n",
      "Epoch 68/1200, Iteration 4/12, Loss: 0.0121\n",
      "Epoch 68/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 68/1200, Iteration 6/12, Loss: 0.0071\n",
      "Epoch 68/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 68/1200, Iteration 8/12, Loss: 0.0096\n",
      "Epoch 68/1200, Iteration 9/12, Loss: 0.0184\n",
      "Epoch 68/1200, Iteration 10/12, Loss: 0.0090\n",
      "Epoch 68/1200, Iteration 11/12, Loss: 0.0058\n",
      "Epoch 68/1200, Iteration 12/12, Loss: 0.0160\n",
      "Epoch 68/1200, Iteration 13/12, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.011180, MRE: 0.047227, MAE: 0.007459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.009924, MRE: 0.040922, MAE: 0.007854 \n",
      "\n",
      "Epoch 69/1200, Iteration 1/12, Loss: 0.0139\n",
      "Epoch 69/1200, Iteration 2/12, Loss: 0.0132\n",
      "Epoch 69/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 69/1200, Iteration 4/12, Loss: 0.0080\n",
      "Epoch 69/1200, Iteration 5/12, Loss: 0.0245\n",
      "Epoch 69/1200, Iteration 6/12, Loss: 0.0095\n",
      "Epoch 69/1200, Iteration 7/12, Loss: 0.0095\n",
      "Epoch 69/1200, Iteration 8/12, Loss: 0.0184\n",
      "Epoch 69/1200, Iteration 9/12, Loss: 0.0200\n",
      "Epoch 69/1200, Iteration 10/12, Loss: 0.0075\n",
      "Epoch 69/1200, Iteration 11/12, Loss: 0.0091\n",
      "Epoch 69/1200, Iteration 12/12, Loss: 0.0096\n",
      "Epoch 69/1200, Iteration 13/12, Loss: 0.0125\n",
      "Train Error: \n",
      " Accuracy: 91.12%, Avg loss: 0.011248, MRE: 0.046342, MAE: 0.007516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.009646, MRE: 0.040685, MAE: 0.007791 \n",
      "\n",
      "Epoch 70/1200, Iteration 1/12, Loss: 0.0075\n",
      "Epoch 70/1200, Iteration 2/12, Loss: 0.0084\n",
      "Epoch 70/1200, Iteration 3/12, Loss: 0.0112\n",
      "Epoch 70/1200, Iteration 4/12, Loss: 0.0209\n",
      "Epoch 70/1200, Iteration 5/12, Loss: 0.0136\n",
      "Epoch 70/1200, Iteration 6/12, Loss: 0.0094\n",
      "Epoch 70/1200, Iteration 7/12, Loss: 0.0072\n",
      "Epoch 70/1200, Iteration 8/12, Loss: 0.0195\n",
      "Epoch 70/1200, Iteration 9/12, Loss: 0.0125\n",
      "Epoch 70/1200, Iteration 10/12, Loss: 0.0094\n",
      "Epoch 70/1200, Iteration 11/12, Loss: 0.0213\n",
      "Epoch 70/1200, Iteration 12/12, Loss: 0.0092\n",
      "Epoch 70/1200, Iteration 13/12, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 90.62%, Avg loss: 0.011714, MRE: 0.046553, MAE: 0.007592 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.009479, MRE: 0.040668, MAE: 0.007720 \n",
      "\n",
      "Epoch 71/1200, Iteration 1/12, Loss: 0.0067\n",
      "Epoch 71/1200, Iteration 2/12, Loss: 0.0278\n",
      "Epoch 71/1200, Iteration 3/12, Loss: 0.0117\n",
      "Epoch 71/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 71/1200, Iteration 5/12, Loss: 0.0160\n",
      "Epoch 71/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 71/1200, Iteration 7/12, Loss: 0.0081\n",
      "Epoch 71/1200, Iteration 8/12, Loss: 0.0094\n",
      "Epoch 71/1200, Iteration 9/12, Loss: 0.0148\n",
      "Epoch 71/1200, Iteration 10/12, Loss: 0.0234\n",
      "Epoch 71/1200, Iteration 11/12, Loss: 0.0083\n",
      "Epoch 71/1200, Iteration 12/12, Loss: 0.0089\n",
      "Epoch 71/1200, Iteration 13/12, Loss: 0.0125\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.011120, MRE: 0.046971, MAE: 0.007428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.009658, MRE: 0.040277, MAE: 0.007690 \n",
      "\n",
      "Epoch 72/1200, Iteration 1/12, Loss: 0.0086\n",
      "Epoch 72/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 72/1200, Iteration 3/12, Loss: 0.0115\n",
      "Epoch 72/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 72/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 72/1200, Iteration 6/12, Loss: 0.0085\n",
      "Epoch 72/1200, Iteration 7/12, Loss: 0.0163\n",
      "Epoch 72/1200, Iteration 8/12, Loss: 0.0257\n",
      "Epoch 72/1200, Iteration 9/12, Loss: 0.0188\n",
      "Epoch 72/1200, Iteration 10/12, Loss: 0.0120\n",
      "Epoch 72/1200, Iteration 11/12, Loss: 0.0181\n",
      "Epoch 72/1200, Iteration 12/12, Loss: 0.0119\n",
      "Epoch 72/1200, Iteration 13/12, Loss: 0.0135\n",
      "Train Error: \n",
      " Accuracy: 91.25%, Avg loss: 0.011163, MRE: 0.046749, MAE: 0.007386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.009055, MRE: 0.039743, MAE: 0.007523 \n",
      "\n",
      "Epoch 73/1200, Iteration 1/12, Loss: 0.0109\n",
      "Epoch 73/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 73/1200, Iteration 3/12, Loss: 0.0105\n",
      "Epoch 73/1200, Iteration 4/12, Loss: 0.0075\n",
      "Epoch 73/1200, Iteration 5/12, Loss: 0.0175\n",
      "Epoch 73/1200, Iteration 6/12, Loss: 0.0200\n",
      "Epoch 73/1200, Iteration 7/12, Loss: 0.0079\n",
      "Epoch 73/1200, Iteration 8/12, Loss: 0.0142\n",
      "Epoch 73/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 73/1200, Iteration 10/12, Loss: 0.0164\n",
      "Epoch 73/1200, Iteration 11/12, Loss: 0.0071\n",
      "Epoch 73/1200, Iteration 12/12, Loss: 0.0180\n",
      "Epoch 73/1200, Iteration 13/12, Loss: 0.0077\n",
      "Train Error: \n",
      " Accuracy: 92.25%, Avg loss: 0.010811, MRE: 0.045924, MAE: 0.007282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.008959, MRE: 0.039469, MAE: 0.007504 \n",
      "\n",
      "Epoch 74/1200, Iteration 1/12, Loss: 0.0078\n",
      "Epoch 74/1200, Iteration 2/12, Loss: 0.0138\n",
      "Epoch 74/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 74/1200, Iteration 4/12, Loss: 0.0141\n",
      "Epoch 74/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 74/1200, Iteration 6/12, Loss: 0.0070\n",
      "Epoch 74/1200, Iteration 7/12, Loss: 0.0139\n",
      "Epoch 74/1200, Iteration 8/12, Loss: 0.0110\n",
      "Epoch 74/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 74/1200, Iteration 10/12, Loss: 0.0253\n",
      "Epoch 74/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 74/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 74/1200, Iteration 13/12, Loss: 0.0419\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.010890, MRE: 0.046589, MAE: 0.007343 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.010164, MRE: 0.040295, MAE: 0.007761 \n",
      "\n",
      "Epoch 75/1200, Iteration 1/12, Loss: 0.0123\n",
      "Epoch 75/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 75/1200, Iteration 3/12, Loss: 0.0080\n",
      "Epoch 75/1200, Iteration 4/12, Loss: 0.0116\n",
      "Epoch 75/1200, Iteration 5/12, Loss: 0.0065\n",
      "Epoch 75/1200, Iteration 6/12, Loss: 0.0169\n",
      "Epoch 75/1200, Iteration 7/12, Loss: 0.0156\n",
      "Epoch 75/1200, Iteration 8/12, Loss: 0.0260\n",
      "Epoch 75/1200, Iteration 9/12, Loss: 0.0180\n",
      "Epoch 75/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 75/1200, Iteration 11/12, Loss: 0.0121\n",
      "Epoch 75/1200, Iteration 12/12, Loss: 0.0082\n",
      "Epoch 75/1200, Iteration 13/12, Loss: 0.0055\n",
      "Train Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.011116, MRE: 0.045469, MAE: 0.007340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.009294, MRE: 0.039491, MAE: 0.007548 \n",
      "\n",
      "Epoch 76/1200, Iteration 1/12, Loss: 0.0285\n",
      "Epoch 76/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 76/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 76/1200, Iteration 4/12, Loss: 0.0175\n",
      "Epoch 76/1200, Iteration 5/12, Loss: 0.0100\n",
      "Epoch 76/1200, Iteration 6/12, Loss: 0.0112\n",
      "Epoch 76/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 76/1200, Iteration 8/12, Loss: 0.0111\n",
      "Epoch 76/1200, Iteration 9/12, Loss: 0.0107\n",
      "Epoch 76/1200, Iteration 10/12, Loss: 0.0170\n",
      "Epoch 76/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 76/1200, Iteration 12/12, Loss: 0.0095\n",
      "Epoch 76/1200, Iteration 13/12, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 89.38%, Avg loss: 0.010999, MRE: 0.045624, MAE: 0.007338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.008418, MRE: 0.039275, MAE: 0.007452 \n",
      "\n",
      "Epoch 77/1200, Iteration 1/12, Loss: 0.0099\n",
      "Epoch 77/1200, Iteration 2/12, Loss: 0.0056\n",
      "Epoch 77/1200, Iteration 3/12, Loss: 0.0133\n",
      "Epoch 77/1200, Iteration 4/12, Loss: 0.0078\n",
      "Epoch 77/1200, Iteration 5/12, Loss: 0.0152\n",
      "Epoch 77/1200, Iteration 6/12, Loss: 0.0077\n",
      "Epoch 77/1200, Iteration 7/12, Loss: 0.0186\n",
      "Epoch 77/1200, Iteration 8/12, Loss: 0.0143\n",
      "Epoch 77/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 77/1200, Iteration 10/12, Loss: 0.0071\n",
      "Epoch 77/1200, Iteration 11/12, Loss: 0.0099\n",
      "Epoch 77/1200, Iteration 12/12, Loss: 0.0256\n",
      "Epoch 77/1200, Iteration 13/12, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.010562, MRE: 0.045129, MAE: 0.007169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008987, MRE: 0.038925, MAE: 0.007417 \n",
      "\n",
      "Epoch 78/1200, Iteration 1/12, Loss: 0.0173\n",
      "Epoch 78/1200, Iteration 2/12, Loss: 0.0115\n",
      "Epoch 78/1200, Iteration 3/12, Loss: 0.0090\n",
      "Epoch 78/1200, Iteration 4/12, Loss: 0.0108\n",
      "Epoch 78/1200, Iteration 5/12, Loss: 0.0317\n",
      "Epoch 78/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 78/1200, Iteration 7/12, Loss: 0.0150\n",
      "Epoch 78/1200, Iteration 8/12, Loss: 0.0095\n",
      "Epoch 78/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 78/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 78/1200, Iteration 11/12, Loss: 0.0115\n",
      "Epoch 78/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 78/1200, Iteration 13/12, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.010709, MRE: 0.044521, MAE: 0.007227 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008941, MRE: 0.038580, MAE: 0.007414 \n",
      "\n",
      "Epoch 79/1200, Iteration 1/12, Loss: 0.0093\n",
      "Epoch 79/1200, Iteration 2/12, Loss: 0.0160\n",
      "Epoch 79/1200, Iteration 3/12, Loss: 0.0142\n",
      "Epoch 79/1200, Iteration 4/12, Loss: 0.0164\n",
      "Epoch 79/1200, Iteration 5/12, Loss: 0.0118\n",
      "Epoch 79/1200, Iteration 6/12, Loss: 0.0090\n",
      "Epoch 79/1200, Iteration 7/12, Loss: 0.0079\n",
      "Epoch 79/1200, Iteration 8/12, Loss: 0.0084\n",
      "Epoch 79/1200, Iteration 9/12, Loss: 0.0185\n",
      "Epoch 79/1200, Iteration 10/12, Loss: 0.0215\n",
      "Epoch 79/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 79/1200, Iteration 12/12, Loss: 0.0071\n",
      "Epoch 79/1200, Iteration 13/12, Loss: 0.0053\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.011074, MRE: 0.051635, MAE: 0.007255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008963, MRE: 0.038525, MAE: 0.007409 \n",
      "\n",
      "Epoch 80/1200, Iteration 1/12, Loss: 0.0098\n",
      "Epoch 80/1200, Iteration 2/12, Loss: 0.0168\n",
      "Epoch 80/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 80/1200, Iteration 4/12, Loss: 0.0159\n",
      "Epoch 80/1200, Iteration 5/12, Loss: 0.0216\n",
      "Epoch 80/1200, Iteration 6/12, Loss: 0.0101\n",
      "Epoch 80/1200, Iteration 7/12, Loss: 0.0120\n",
      "Epoch 80/1200, Iteration 8/12, Loss: 0.0067\n",
      "Epoch 80/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 80/1200, Iteration 10/12, Loss: 0.0154\n",
      "Epoch 80/1200, Iteration 11/12, Loss: 0.0113\n",
      "Epoch 80/1200, Iteration 12/12, Loss: 0.0139\n",
      "Epoch 80/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 91.25%, Avg loss: 0.010336, MRE: 0.043375, MAE: 0.007109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.008612, MRE: 0.038736, MAE: 0.007407 \n",
      "\n",
      "Epoch 81/1200, Iteration 1/12, Loss: 0.0096\n",
      "Epoch 81/1200, Iteration 2/12, Loss: 0.0183\n",
      "Epoch 81/1200, Iteration 3/12, Loss: 0.0087\n",
      "Epoch 81/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 81/1200, Iteration 5/12, Loss: 0.0059\n",
      "Epoch 81/1200, Iteration 6/12, Loss: 0.0109\n",
      "Epoch 81/1200, Iteration 7/12, Loss: 0.0084\n",
      "Epoch 81/1200, Iteration 8/12, Loss: 0.0188\n",
      "Epoch 81/1200, Iteration 9/12, Loss: 0.0054\n",
      "Epoch 81/1200, Iteration 10/12, Loss: 0.0080\n",
      "Epoch 81/1200, Iteration 11/12, Loss: 0.0222\n",
      "Epoch 81/1200, Iteration 12/12, Loss: 0.0183\n",
      "Epoch 81/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.010920, MRE: 0.043783, MAE: 0.007144 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008885, MRE: 0.038220, MAE: 0.007341 \n",
      "\n",
      "Epoch 82/1200, Iteration 1/12, Loss: 0.0128\n",
      "Epoch 82/1200, Iteration 2/12, Loss: 0.0104\n",
      "Epoch 82/1200, Iteration 3/12, Loss: 0.0181\n",
      "Epoch 82/1200, Iteration 4/12, Loss: 0.0093\n",
      "Epoch 82/1200, Iteration 5/12, Loss: 0.0208\n",
      "Epoch 82/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 82/1200, Iteration 7/12, Loss: 0.0152\n",
      "Epoch 82/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 82/1200, Iteration 9/12, Loss: 0.0072\n",
      "Epoch 82/1200, Iteration 10/12, Loss: 0.0175\n",
      "Epoch 82/1200, Iteration 11/12, Loss: 0.0113\n",
      "Epoch 82/1200, Iteration 12/12, Loss: 0.0067\n",
      "Epoch 82/1200, Iteration 13/12, Loss: 0.0075\n",
      "Train Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.010761, MRE: 0.043367, MAE: 0.007151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008911, MRE: 0.038423, MAE: 0.007376 \n",
      "\n",
      "Epoch 83/1200, Iteration 1/12, Loss: 0.0216\n",
      "Epoch 83/1200, Iteration 2/12, Loss: 0.0108\n",
      "Epoch 83/1200, Iteration 3/12, Loss: 0.0117\n",
      "Epoch 83/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 83/1200, Iteration 5/12, Loss: 0.0073\n",
      "Epoch 83/1200, Iteration 6/12, Loss: 0.0149\n",
      "Epoch 83/1200, Iteration 7/12, Loss: 0.0100\n",
      "Epoch 83/1200, Iteration 8/12, Loss: 0.0094\n",
      "Epoch 83/1200, Iteration 9/12, Loss: 0.0209\n",
      "Epoch 83/1200, Iteration 10/12, Loss: 0.0140\n",
      "Epoch 83/1200, Iteration 11/12, Loss: 0.0076\n",
      "Epoch 83/1200, Iteration 12/12, Loss: 0.0083\n",
      "Epoch 83/1200, Iteration 13/12, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.010105, MRE: 0.042859, MAE: 0.006993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008540, MRE: 0.037804, MAE: 0.007249 \n",
      "\n",
      "Epoch 84/1200, Iteration 1/12, Loss: 0.0184\n",
      "Epoch 84/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 84/1200, Iteration 3/12, Loss: 0.0058\n",
      "Epoch 84/1200, Iteration 4/12, Loss: 0.0078\n",
      "Epoch 84/1200, Iteration 5/12, Loss: 0.0164\n",
      "Epoch 84/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 84/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 84/1200, Iteration 8/12, Loss: 0.0154\n",
      "Epoch 84/1200, Iteration 9/12, Loss: 0.0104\n",
      "Epoch 84/1200, Iteration 10/12, Loss: 0.0095\n",
      "Epoch 84/1200, Iteration 11/12, Loss: 0.0160\n",
      "Epoch 84/1200, Iteration 12/12, Loss: 0.0213\n",
      "Epoch 84/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.010106, MRE: 0.042561, MAE: 0.006978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008844, MRE: 0.037758, MAE: 0.007307 \n",
      "\n",
      "Epoch 85/1200, Iteration 1/12, Loss: 0.0102\n",
      "Epoch 85/1200, Iteration 2/12, Loss: 0.0297\n",
      "Epoch 85/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 85/1200, Iteration 4/12, Loss: 0.0073\n",
      "Epoch 85/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 85/1200, Iteration 6/12, Loss: 0.0195\n",
      "Epoch 85/1200, Iteration 7/12, Loss: 0.0104\n",
      "Epoch 85/1200, Iteration 8/12, Loss: 0.0135\n",
      "Epoch 85/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 85/1200, Iteration 10/12, Loss: 0.0142\n",
      "Epoch 85/1200, Iteration 11/12, Loss: 0.0083\n",
      "Epoch 85/1200, Iteration 12/12, Loss: 0.0075\n",
      "Epoch 85/1200, Iteration 13/12, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.009887, MRE: 0.041734, MAE: 0.006904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008692, MRE: 0.037552, MAE: 0.007263 \n",
      "\n",
      "Epoch 86/1200, Iteration 1/12, Loss: 0.0161\n",
      "Epoch 86/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 86/1200, Iteration 3/12, Loss: 0.0196\n",
      "Epoch 86/1200, Iteration 4/12, Loss: 0.0117\n",
      "Epoch 86/1200, Iteration 5/12, Loss: 0.0125\n",
      "Epoch 86/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 86/1200, Iteration 7/12, Loss: 0.0120\n",
      "Epoch 86/1200, Iteration 8/12, Loss: 0.0182\n",
      "Epoch 86/1200, Iteration 9/12, Loss: 0.0094\n",
      "Epoch 86/1200, Iteration 10/12, Loss: 0.0109\n",
      "Epoch 86/1200, Iteration 11/12, Loss: 0.0057\n",
      "Epoch 86/1200, Iteration 12/12, Loss: 0.0071\n",
      "Epoch 86/1200, Iteration 13/12, Loss: 0.0070\n",
      "Train Error: \n",
      " Accuracy: 92.25%, Avg loss: 0.009866, MRE: 0.041912, MAE: 0.006884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008329, MRE: 0.037299, MAE: 0.007172 \n",
      "\n",
      "Epoch 87/1200, Iteration 1/12, Loss: 0.0173\n",
      "Epoch 87/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 87/1200, Iteration 3/12, Loss: 0.0200\n",
      "Epoch 87/1200, Iteration 4/12, Loss: 0.0099\n",
      "Epoch 87/1200, Iteration 5/12, Loss: 0.0144\n",
      "Epoch 87/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 87/1200, Iteration 7/12, Loss: 0.0119\n",
      "Epoch 87/1200, Iteration 8/12, Loss: 0.0088\n",
      "Epoch 87/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 87/1200, Iteration 10/12, Loss: 0.0125\n",
      "Epoch 87/1200, Iteration 11/12, Loss: 0.0105\n",
      "Epoch 87/1200, Iteration 12/12, Loss: 0.0072\n",
      "Epoch 87/1200, Iteration 13/12, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 92.88%, Avg loss: 0.009708, MRE: 0.041846, MAE: 0.006826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008596, MRE: 0.037258, MAE: 0.007199 \n",
      "\n",
      "Epoch 88/1200, Iteration 1/12, Loss: 0.0204\n",
      "Epoch 88/1200, Iteration 2/12, Loss: 0.0110\n",
      "Epoch 88/1200, Iteration 3/12, Loss: 0.0104\n",
      "Epoch 88/1200, Iteration 4/12, Loss: 0.0085\n",
      "Epoch 88/1200, Iteration 5/12, Loss: 0.0087\n",
      "Epoch 88/1200, Iteration 6/12, Loss: 0.0152\n",
      "Epoch 88/1200, Iteration 7/12, Loss: 0.0077\n",
      "Epoch 88/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 88/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 88/1200, Iteration 10/12, Loss: 0.0194\n",
      "Epoch 88/1200, Iteration 11/12, Loss: 0.0092\n",
      "Epoch 88/1200, Iteration 12/12, Loss: 0.0092\n",
      "Epoch 88/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 92.12%, Avg loss: 0.009620, MRE: 0.041029, MAE: 0.006787 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008149, MRE: 0.037079, MAE: 0.007100 \n",
      "\n",
      "Epoch 89/1200, Iteration 1/12, Loss: 0.0170\n",
      "Epoch 89/1200, Iteration 2/12, Loss: 0.0141\n",
      "Epoch 89/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 89/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 89/1200, Iteration 5/12, Loss: 0.0105\n",
      "Epoch 89/1200, Iteration 6/12, Loss: 0.0072\n",
      "Epoch 89/1200, Iteration 7/12, Loss: 0.0109\n",
      "Epoch 89/1200, Iteration 8/12, Loss: 0.0100\n",
      "Epoch 89/1200, Iteration 9/12, Loss: 0.0143\n",
      "Epoch 89/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 89/1200, Iteration 11/12, Loss: 0.0104\n",
      "Epoch 89/1200, Iteration 12/12, Loss: 0.0153\n",
      "Epoch 89/1200, Iteration 13/12, Loss: 0.0259\n",
      "Train Error: \n",
      " Accuracy: 92.75%, Avg loss: 0.009669, MRE: 0.041558, MAE: 0.006892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.009005, MRE: 0.037812, MAE: 0.007298 \n",
      "\n",
      "Epoch 90/1200, Iteration 1/12, Loss: 0.0165\n",
      "Epoch 90/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 90/1200, Iteration 3/12, Loss: 0.0219\n",
      "Epoch 90/1200, Iteration 4/12, Loss: 0.0114\n",
      "Epoch 90/1200, Iteration 5/12, Loss: 0.0090\n",
      "Epoch 90/1200, Iteration 6/12, Loss: 0.0120\n",
      "Epoch 90/1200, Iteration 7/12, Loss: 0.0079\n",
      "Epoch 90/1200, Iteration 8/12, Loss: 0.0092\n",
      "Epoch 90/1200, Iteration 9/12, Loss: 0.0105\n",
      "Epoch 90/1200, Iteration 10/12, Loss: 0.0092\n",
      "Epoch 90/1200, Iteration 11/12, Loss: 0.0161\n",
      "Epoch 90/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 90/1200, Iteration 13/12, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 92.38%, Avg loss: 0.009535, MRE: 0.041370, MAE: 0.006795 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008367, MRE: 0.037147, MAE: 0.007140 \n",
      "\n",
      "Epoch 91/1200, Iteration 1/12, Loss: 0.0119\n",
      "Epoch 91/1200, Iteration 2/12, Loss: 0.0106\n",
      "Epoch 91/1200, Iteration 3/12, Loss: 0.0110\n",
      "Epoch 91/1200, Iteration 4/12, Loss: 0.0139\n",
      "Epoch 91/1200, Iteration 5/12, Loss: 0.0073\n",
      "Epoch 91/1200, Iteration 6/12, Loss: 0.0102\n",
      "Epoch 91/1200, Iteration 7/12, Loss: 0.0100\n",
      "Epoch 91/1200, Iteration 8/12, Loss: 0.0122\n",
      "Epoch 91/1200, Iteration 9/12, Loss: 0.0166\n",
      "Epoch 91/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 91/1200, Iteration 11/12, Loss: 0.0076\n",
      "Epoch 91/1200, Iteration 12/12, Loss: 0.0102\n",
      "Epoch 91/1200, Iteration 13/12, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.009385, MRE: 0.040770, MAE: 0.006725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.008734, MRE: 0.037070, MAE: 0.007181 \n",
      "\n",
      "Epoch 92/1200, Iteration 1/12, Loss: 0.0073\n",
      "Epoch 92/1200, Iteration 2/12, Loss: 0.0075\n",
      "Epoch 92/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 92/1200, Iteration 4/12, Loss: 0.0099\n",
      "Epoch 92/1200, Iteration 5/12, Loss: 0.0162\n",
      "Epoch 92/1200, Iteration 6/12, Loss: 0.0310\n",
      "Epoch 92/1200, Iteration 7/12, Loss: 0.0080\n",
      "Epoch 92/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 92/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 92/1200, Iteration 10/12, Loss: 0.0110\n",
      "Epoch 92/1200, Iteration 11/12, Loss: 0.0112\n",
      "Epoch 92/1200, Iteration 12/12, Loss: 0.0114\n",
      "Epoch 92/1200, Iteration 13/12, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.009711, MRE: 0.040844, MAE: 0.006831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007778, MRE: 0.036954, MAE: 0.007020 \n",
      "\n",
      "Epoch 93/1200, Iteration 1/12, Loss: 0.0069\n",
      "Epoch 93/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 93/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 93/1200, Iteration 4/12, Loss: 0.0123\n",
      "Epoch 93/1200, Iteration 5/12, Loss: 0.0142\n",
      "Epoch 93/1200, Iteration 6/12, Loss: 0.0329\n",
      "Epoch 93/1200, Iteration 7/12, Loss: 0.0081\n",
      "Epoch 93/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 93/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 93/1200, Iteration 10/12, Loss: 0.0154\n",
      "Epoch 93/1200, Iteration 11/12, Loss: 0.0094\n",
      "Epoch 93/1200, Iteration 12/12, Loss: 0.0095\n",
      "Epoch 93/1200, Iteration 13/12, Loss: 0.0135\n",
      "Train Error: \n",
      " Accuracy: 92.25%, Avg loss: 0.009872, MRE: 0.041460, MAE: 0.006784 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007917, MRE: 0.036267, MAE: 0.006966 \n",
      "\n",
      "Epoch 94/1200, Iteration 1/12, Loss: 0.0063\n",
      "Epoch 94/1200, Iteration 2/12, Loss: 0.0126\n",
      "Epoch 94/1200, Iteration 3/12, Loss: 0.0072\n",
      "Epoch 94/1200, Iteration 4/12, Loss: 0.0277\n",
      "Epoch 94/1200, Iteration 5/12, Loss: 0.0076\n",
      "Epoch 94/1200, Iteration 6/12, Loss: 0.0135\n",
      "Epoch 94/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 94/1200, Iteration 8/12, Loss: 0.0175\n",
      "Epoch 94/1200, Iteration 9/12, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1200, Iteration 10/12, Loss: 0.0092\n",
      "Epoch 94/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 94/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 94/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.009506, MRE: 0.040352, MAE: 0.006704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007933, MRE: 0.036184, MAE: 0.006973 \n",
      "\n",
      "Epoch 95/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 95/1200, Iteration 2/12, Loss: 0.0174\n",
      "Epoch 95/1200, Iteration 3/12, Loss: 0.0195\n",
      "Epoch 95/1200, Iteration 4/12, Loss: 0.0084\n",
      "Epoch 95/1200, Iteration 5/12, Loss: 0.0211\n",
      "Epoch 95/1200, Iteration 6/12, Loss: 0.0083\n",
      "Epoch 95/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 95/1200, Iteration 8/12, Loss: 0.0095\n",
      "Epoch 95/1200, Iteration 9/12, Loss: 0.0080\n",
      "Epoch 95/1200, Iteration 10/12, Loss: 0.0103\n",
      "Epoch 95/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 95/1200, Iteration 12/12, Loss: 0.0097\n",
      "Epoch 95/1200, Iteration 13/12, Loss: 0.0086\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.009293, MRE: 0.041723, MAE: 0.006666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.008139, MRE: 0.035851, MAE: 0.006923 \n",
      "\n",
      "Epoch 96/1200, Iteration 1/12, Loss: 0.0070\n",
      "Epoch 96/1200, Iteration 2/12, Loss: 0.0104\n",
      "Epoch 96/1200, Iteration 3/12, Loss: 0.0096\n",
      "Epoch 96/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 96/1200, Iteration 5/12, Loss: 0.0170\n",
      "Epoch 96/1200, Iteration 6/12, Loss: 0.0059\n",
      "Epoch 96/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 96/1200, Iteration 8/12, Loss: 0.0247\n",
      "Epoch 96/1200, Iteration 9/12, Loss: 0.0190\n",
      "Epoch 96/1200, Iteration 10/12, Loss: 0.0057\n",
      "Epoch 96/1200, Iteration 11/12, Loss: 0.0114\n",
      "Epoch 96/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 96/1200, Iteration 13/12, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 92.62%, Avg loss: 0.009261, MRE: 0.047082, MAE: 0.006607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007861, MRE: 0.035849, MAE: 0.006895 \n",
      "\n",
      "Epoch 97/1200, Iteration 1/12, Loss: 0.0074\n",
      "Epoch 97/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 97/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 97/1200, Iteration 4/12, Loss: 0.0127\n",
      "Epoch 97/1200, Iteration 5/12, Loss: 0.0080\n",
      "Epoch 97/1200, Iteration 6/12, Loss: 0.0114\n",
      "Epoch 97/1200, Iteration 7/12, Loss: 0.0205\n",
      "Epoch 97/1200, Iteration 8/12, Loss: 0.0096\n",
      "Epoch 97/1200, Iteration 9/12, Loss: 0.0207\n",
      "Epoch 97/1200, Iteration 10/12, Loss: 0.0082\n",
      "Epoch 97/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 97/1200, Iteration 12/12, Loss: 0.0118\n",
      "Epoch 97/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 93.12%, Avg loss: 0.009066, MRE: 0.040062, MAE: 0.006543 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.007886, MRE: 0.035502, MAE: 0.006839 \n",
      "\n",
      "Epoch 98/1200, Iteration 1/12, Loss: 0.0258\n",
      "Epoch 98/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 98/1200, Iteration 3/12, Loss: 0.0065\n",
      "Epoch 98/1200, Iteration 4/12, Loss: 0.0127\n",
      "Epoch 98/1200, Iteration 5/12, Loss: 0.0055\n",
      "Epoch 98/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 98/1200, Iteration 7/12, Loss: 0.0131\n",
      "Epoch 98/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 98/1200, Iteration 9/12, Loss: 0.0133\n",
      "Epoch 98/1200, Iteration 10/12, Loss: 0.0126\n",
      "Epoch 98/1200, Iteration 11/12, Loss: 0.0093\n",
      "Epoch 98/1200, Iteration 12/12, Loss: 0.0135\n",
      "Epoch 98/1200, Iteration 13/12, Loss: 0.0070\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.009121, MRE: 0.040242, MAE: 0.006564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.008139, MRE: 0.035637, MAE: 0.006898 \n",
      "\n",
      "Epoch 99/1200, Iteration 1/12, Loss: 0.0110\n",
      "Epoch 99/1200, Iteration 2/12, Loss: 0.0075\n",
      "Epoch 99/1200, Iteration 3/12, Loss: 0.0152\n",
      "Epoch 99/1200, Iteration 4/12, Loss: 0.0094\n",
      "Epoch 99/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 99/1200, Iteration 6/12, Loss: 0.0223\n",
      "Epoch 99/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 99/1200, Iteration 8/12, Loss: 0.0086\n",
      "Epoch 99/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 99/1200, Iteration 10/12, Loss: 0.0156\n",
      "Epoch 99/1200, Iteration 11/12, Loss: 0.0130\n",
      "Epoch 99/1200, Iteration 12/12, Loss: 0.0101\n",
      "Epoch 99/1200, Iteration 13/12, Loss: 0.0068\n",
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.009775, MRE: 0.040576, MAE: 0.006680 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.008129, MRE: 0.035573, MAE: 0.006894 \n",
      "\n",
      "Epoch 100/1200, Iteration 1/12, Loss: 0.0073\n",
      "Epoch 100/1200, Iteration 2/12, Loss: 0.0250\n",
      "Epoch 100/1200, Iteration 3/12, Loss: 0.0102\n",
      "Epoch 100/1200, Iteration 4/12, Loss: 0.0097\n",
      "Epoch 100/1200, Iteration 5/12, Loss: 0.0159\n",
      "Epoch 100/1200, Iteration 6/12, Loss: 0.0089\n",
      "Epoch 100/1200, Iteration 7/12, Loss: 0.0070\n",
      "Epoch 100/1200, Iteration 8/12, Loss: 0.0073\n",
      "Epoch 100/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 100/1200, Iteration 10/12, Loss: 0.0111\n",
      "Epoch 100/1200, Iteration 11/12, Loss: 0.0094\n",
      "Epoch 100/1200, Iteration 12/12, Loss: 0.0063\n",
      "Epoch 100/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.009004, MRE: 0.039506, MAE: 0.006527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.007572, MRE: 0.035037, MAE: 0.006730 \n",
      "\n",
      "Epoch 101/1200, Iteration 1/12, Loss: 0.0096\n",
      "Epoch 101/1200, Iteration 2/12, Loss: 0.0065\n",
      "Epoch 101/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 101/1200, Iteration 4/12, Loss: 0.0141\n",
      "Epoch 101/1200, Iteration 5/12, Loss: 0.0158\n",
      "Epoch 101/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 101/1200, Iteration 7/12, Loss: 0.0078\n",
      "Epoch 101/1200, Iteration 8/12, Loss: 0.0093\n",
      "Epoch 101/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 101/1200, Iteration 10/12, Loss: 0.0173\n",
      "Epoch 101/1200, Iteration 11/12, Loss: 0.0075\n",
      "Epoch 101/1200, Iteration 12/12, Loss: 0.0168\n",
      "Epoch 101/1200, Iteration 13/12, Loss: 0.0112\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.009047, MRE: 0.039378, MAE: 0.006495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.007455, MRE: 0.034646, MAE: 0.006628 \n",
      "\n",
      "Epoch 102/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 102/1200, Iteration 2/12, Loss: 0.0163\n",
      "Epoch 102/1200, Iteration 3/12, Loss: 0.0113\n",
      "Epoch 102/1200, Iteration 4/12, Loss: 0.0092\n",
      "Epoch 102/1200, Iteration 5/12, Loss: 0.0100\n",
      "Epoch 102/1200, Iteration 6/12, Loss: 0.0211\n",
      "Epoch 102/1200, Iteration 7/12, Loss: 0.0121\n",
      "Epoch 102/1200, Iteration 8/12, Loss: 0.0083\n",
      "Epoch 102/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 102/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 102/1200, Iteration 11/12, Loss: 0.0085\n",
      "Epoch 102/1200, Iteration 12/12, Loss: 0.0080\n",
      "Epoch 102/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.008903, MRE: 0.039590, MAE: 0.006465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007775, MRE: 0.034781, MAE: 0.006705 \n",
      "\n",
      "Epoch 103/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 103/1200, Iteration 2/12, Loss: 0.0098\n",
      "Epoch 103/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 103/1200, Iteration 4/12, Loss: 0.0140\n",
      "Epoch 103/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 103/1200, Iteration 6/12, Loss: 0.0119\n",
      "Epoch 103/1200, Iteration 7/12, Loss: 0.0120\n",
      "Epoch 103/1200, Iteration 8/12, Loss: 0.0093\n",
      "Epoch 103/1200, Iteration 9/12, Loss: 0.0173\n",
      "Epoch 103/1200, Iteration 10/12, Loss: 0.0142\n",
      "Epoch 103/1200, Iteration 11/12, Loss: 0.0087\n",
      "Epoch 103/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 103/1200, Iteration 13/12, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.009258, MRE: 0.039081, MAE: 0.006591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.008153, MRE: 0.035116, MAE: 0.006856 \n",
      "\n",
      "Epoch 104/1200, Iteration 1/12, Loss: 0.0108\n",
      "Epoch 104/1200, Iteration 2/12, Loss: 0.0078\n",
      "Epoch 104/1200, Iteration 3/12, Loss: 0.0092\n",
      "Epoch 104/1200, Iteration 4/12, Loss: 0.0165\n",
      "Epoch 104/1200, Iteration 5/12, Loss: 0.0085\n",
      "Epoch 104/1200, Iteration 6/12, Loss: 0.0088\n",
      "Epoch 104/1200, Iteration 7/12, Loss: 0.0187\n",
      "Epoch 104/1200, Iteration 8/12, Loss: 0.0101\n",
      "Epoch 104/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 104/1200, Iteration 10/12, Loss: 0.0091\n",
      "Epoch 104/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 104/1200, Iteration 12/12, Loss: 0.0104\n",
      "Epoch 104/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.009014, MRE: 0.038488, MAE: 0.006505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.008184, MRE: 0.034914, MAE: 0.006905 \n",
      "\n",
      "Epoch 105/1200, Iteration 1/12, Loss: 0.0113\n",
      "Epoch 105/1200, Iteration 2/12, Loss: 0.0062\n",
      "Epoch 105/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 105/1200, Iteration 4/12, Loss: 0.0219\n",
      "Epoch 105/1200, Iteration 5/12, Loss: 0.0097\n",
      "Epoch 105/1200, Iteration 6/12, Loss: 0.0080\n",
      "Epoch 105/1200, Iteration 7/12, Loss: 0.0093\n",
      "Epoch 105/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 105/1200, Iteration 9/12, Loss: 0.0093\n",
      "Epoch 105/1200, Iteration 10/12, Loss: 0.0162\n",
      "Epoch 105/1200, Iteration 11/12, Loss: 0.0071\n",
      "Epoch 105/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 105/1200, Iteration 13/12, Loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.008613, MRE: 0.039486, MAE: 0.006381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007712, MRE: 0.034463, MAE: 0.006716 \n",
      "\n",
      "Epoch 106/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 106/1200, Iteration 2/12, Loss: 0.0113\n",
      "Epoch 106/1200, Iteration 3/12, Loss: 0.0150\n",
      "Epoch 106/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 106/1200, Iteration 5/12, Loss: 0.0102\n",
      "Epoch 106/1200, Iteration 6/12, Loss: 0.0140\n",
      "Epoch 106/1200, Iteration 7/12, Loss: 0.0130\n",
      "Epoch 106/1200, Iteration 8/12, Loss: 0.0061\n",
      "Epoch 106/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 106/1200, Iteration 10/12, Loss: 0.0106\n",
      "Epoch 106/1200, Iteration 11/12, Loss: 0.0104\n",
      "Epoch 106/1200, Iteration 12/12, Loss: 0.0122\n",
      "Epoch 106/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.008769, MRE: 0.037635, MAE: 0.006391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007476, MRE: 0.034679, MAE: 0.006699 \n",
      "\n",
      "Epoch 107/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 107/1200, Iteration 2/12, Loss: 0.0087\n",
      "Epoch 107/1200, Iteration 3/12, Loss: 0.0071\n",
      "Epoch 107/1200, Iteration 4/12, Loss: 0.0196\n",
      "Epoch 107/1200, Iteration 5/12, Loss: 0.0111\n",
      "Epoch 107/1200, Iteration 6/12, Loss: 0.0072\n",
      "Epoch 107/1200, Iteration 7/12, Loss: 0.0086\n",
      "Epoch 107/1200, Iteration 8/12, Loss: 0.0090\n",
      "Epoch 107/1200, Iteration 9/12, Loss: 0.0216\n",
      "Epoch 107/1200, Iteration 10/12, Loss: 0.0123\n",
      "Epoch 107/1200, Iteration 11/12, Loss: 0.0091\n",
      "Epoch 107/1200, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 107/1200, Iteration 13/12, Loss: 0.0055\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.008739, MRE: 0.038080, MAE: 0.006414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.007300, MRE: 0.034175, MAE: 0.006608 \n",
      "\n",
      "Epoch 108/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 108/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 108/1200, Iteration 3/12, Loss: 0.0281\n",
      "Epoch 108/1200, Iteration 4/12, Loss: 0.0151\n",
      "Epoch 108/1200, Iteration 5/12, Loss: 0.0135\n",
      "Epoch 108/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 108/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 108/1200, Iteration 8/12, Loss: 0.0068\n",
      "Epoch 108/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 108/1200, Iteration 10/12, Loss: 0.0094\n",
      "Epoch 108/1200, Iteration 11/12, Loss: 0.0071\n",
      "Epoch 108/1200, Iteration 12/12, Loss: 0.0148\n",
      "Epoch 108/1200, Iteration 13/12, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.008446, MRE: 0.038386, MAE: 0.006310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.007023, MRE: 0.033906, MAE: 0.006515 \n",
      "\n",
      "Epoch 109/1200, Iteration 1/12, Loss: 0.0119\n",
      "Epoch 109/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 109/1200, Iteration 3/12, Loss: 0.0157\n",
      "Epoch 109/1200, Iteration 4/12, Loss: 0.0149\n",
      "Epoch 109/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 109/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 109/1200, Iteration 7/12, Loss: 0.0147\n",
      "Epoch 109/1200, Iteration 8/12, Loss: 0.0088\n",
      "Epoch 109/1200, Iteration 9/12, Loss: 0.0121\n",
      "Epoch 109/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 109/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 109/1200, Iteration 12/12, Loss: 0.0101\n",
      "Epoch 109/1200, Iteration 13/12, Loss: 0.0145\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.008741, MRE: 0.038647, MAE: 0.006443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007969, MRE: 0.034547, MAE: 0.006740 \n",
      "\n",
      "Epoch 110/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 110/1200, Iteration 2/12, Loss: 0.0081\n",
      "Epoch 110/1200, Iteration 3/12, Loss: 0.0079\n",
      "Epoch 110/1200, Iteration 4/12, Loss: 0.0070\n",
      "Epoch 110/1200, Iteration 5/12, Loss: 0.0147\n",
      "Epoch 110/1200, Iteration 6/12, Loss: 0.0119\n",
      "Epoch 110/1200, Iteration 7/12, Loss: 0.0078\n",
      "Epoch 110/1200, Iteration 8/12, Loss: 0.0074\n",
      "Epoch 110/1200, Iteration 9/12, Loss: 0.0105\n",
      "Epoch 110/1200, Iteration 10/12, Loss: 0.0057\n",
      "Epoch 110/1200, Iteration 11/12, Loss: 0.0151\n",
      "Epoch 110/1200, Iteration 12/12, Loss: 0.0099\n",
      "Epoch 110/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.008480, MRE: 0.037520, MAE: 0.006298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007385, MRE: 0.033893, MAE: 0.006584 \n",
      "\n",
      "Epoch 111/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 111/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 111/1200, Iteration 3/12, Loss: 0.0096\n",
      "Epoch 111/1200, Iteration 4/12, Loss: 0.0144\n",
      "Epoch 111/1200, Iteration 5/12, Loss: 0.0134\n",
      "Epoch 111/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 111/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 111/1200, Iteration 8/12, Loss: 0.0173\n",
      "Epoch 111/1200, Iteration 9/12, Loss: 0.0095\n",
      "Epoch 111/1200, Iteration 10/12, Loss: 0.0074\n",
      "Epoch 111/1200, Iteration 11/12, Loss: 0.0074\n",
      "Epoch 111/1200, Iteration 12/12, Loss: 0.0101\n",
      "Epoch 111/1200, Iteration 13/12, Loss: 0.0190\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.008704, MRE: 0.039760, MAE: 0.006503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.008463, MRE: 0.035019, MAE: 0.006914 \n",
      "\n",
      "Epoch 112/1200, Iteration 1/12, Loss: 0.0136\n",
      "Epoch 112/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 112/1200, Iteration 3/12, Loss: 0.0063\n",
      "Epoch 112/1200, Iteration 4/12, Loss: 0.0134\n",
      "Epoch 112/1200, Iteration 5/12, Loss: 0.0078\n",
      "Epoch 112/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 112/1200, Iteration 7/12, Loss: 0.0126\n",
      "Epoch 112/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 112/1200, Iteration 9/12, Loss: 0.0108\n",
      "Epoch 112/1200, Iteration 10/12, Loss: 0.0085\n",
      "Epoch 112/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 112/1200, Iteration 12/12, Loss: 0.0214\n",
      "Epoch 112/1200, Iteration 13/12, Loss: 0.0069\n",
      "Train Error: \n",
      " Accuracy: 94.62%, Avg loss: 0.008277, MRE: 0.038047, MAE: 0.006224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007565, MRE: 0.033865, MAE: 0.006623 \n",
      "\n",
      "Epoch 113/1200, Iteration 1/12, Loss: 0.0170\n",
      "Epoch 113/1200, Iteration 2/12, Loss: 0.0132\n",
      "Epoch 113/1200, Iteration 3/12, Loss: 0.0077\n",
      "Epoch 113/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 113/1200, Iteration 5/12, Loss: 0.0106\n",
      "Epoch 113/1200, Iteration 6/12, Loss: 0.0153\n",
      "Epoch 113/1200, Iteration 7/12, Loss: 0.0105\n",
      "Epoch 113/1200, Iteration 8/12, Loss: 0.0090\n",
      "Epoch 113/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 113/1200, Iteration 10/12, Loss: 0.0069\n",
      "Epoch 113/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 113/1200, Iteration 12/12, Loss: 0.0101\n",
      "Epoch 113/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.008278, MRE: 0.037373, MAE: 0.006226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.006934, MRE: 0.033474, MAE: 0.006462 \n",
      "\n",
      "Epoch 114/1200, Iteration 1/12, Loss: 0.0082\n",
      "Epoch 114/1200, Iteration 2/12, Loss: 0.0077\n",
      "Epoch 114/1200, Iteration 3/12, Loss: 0.0063\n",
      "Epoch 114/1200, Iteration 4/12, Loss: 0.0110\n",
      "Epoch 114/1200, Iteration 5/12, Loss: 0.0171\n",
      "Epoch 114/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 114/1200, Iteration 7/12, Loss: 0.0066\n",
      "Epoch 114/1200, Iteration 8/12, Loss: 0.0105\n",
      "Epoch 114/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 114/1200, Iteration 10/12, Loss: 0.0091\n",
      "Epoch 114/1200, Iteration 11/12, Loss: 0.0156\n",
      "Epoch 114/1200, Iteration 12/12, Loss: 0.0072\n",
      "Epoch 114/1200, Iteration 13/12, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.008275, MRE: 0.036834, MAE: 0.006230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.007366, MRE: 0.033687, MAE: 0.006556 \n",
      "\n",
      "Epoch 115/1200, Iteration 1/12, Loss: 0.0146\n",
      "Epoch 115/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 115/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 115/1200, Iteration 4/12, Loss: 0.0068\n",
      "Epoch 115/1200, Iteration 5/12, Loss: 0.0102\n",
      "Epoch 115/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 115/1200, Iteration 7/12, Loss: 0.0199\n",
      "Epoch 115/1200, Iteration 8/12, Loss: 0.0061\n",
      "Epoch 115/1200, Iteration 9/12, Loss: 0.0207\n",
      "Epoch 115/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 115/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 115/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 115/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 93.62%, Avg loss: 0.008203, MRE: 0.036655, MAE: 0.006150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.006956, MRE: 0.033154, MAE: 0.006398 \n",
      "\n",
      "Epoch 116/1200, Iteration 1/12, Loss: 0.0088\n",
      "Epoch 116/1200, Iteration 2/12, Loss: 0.0087\n",
      "Epoch 116/1200, Iteration 3/12, Loss: 0.0076\n",
      "Epoch 116/1200, Iteration 4/12, Loss: 0.0088\n",
      "Epoch 116/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 116/1200, Iteration 6/12, Loss: 0.0103\n",
      "Epoch 116/1200, Iteration 7/12, Loss: 0.0114\n",
      "Epoch 116/1200, Iteration 8/12, Loss: 0.0068\n",
      "Epoch 116/1200, Iteration 9/12, Loss: 0.0180\n",
      "Epoch 116/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 116/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 116/1200, Iteration 12/12, Loss: 0.0099\n",
      "Epoch 116/1200, Iteration 13/12, Loss: 0.0160\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.008264, MRE: 0.037656, MAE: 0.006314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.008023, MRE: 0.034259, MAE: 0.006701 \n",
      "\n",
      "Epoch 117/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 117/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 117/1200, Iteration 3/12, Loss: 0.0131\n",
      "Epoch 117/1200, Iteration 4/12, Loss: 0.0081\n",
      "Epoch 117/1200, Iteration 5/12, Loss: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 117/1200, Iteration 7/12, Loss: 0.0080\n",
      "Epoch 117/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 117/1200, Iteration 9/12, Loss: 0.0108\n",
      "Epoch 117/1200, Iteration 10/12, Loss: 0.0089\n",
      "Epoch 117/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 117/1200, Iteration 12/12, Loss: 0.0099\n",
      "Epoch 117/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 93.12%, Avg loss: 0.008313, MRE: 0.036555, MAE: 0.006186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.006785, MRE: 0.033270, MAE: 0.006390 \n",
      "\n",
      "Epoch 118/1200, Iteration 1/12, Loss: 0.0167\n",
      "Epoch 118/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 118/1200, Iteration 3/12, Loss: 0.0080\n",
      "Epoch 118/1200, Iteration 4/12, Loss: 0.0071\n",
      "Epoch 118/1200, Iteration 5/12, Loss: 0.0078\n",
      "Epoch 118/1200, Iteration 6/12, Loss: 0.0096\n",
      "Epoch 118/1200, Iteration 7/12, Loss: 0.0094\n",
      "Epoch 118/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 118/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 118/1200, Iteration 10/12, Loss: 0.0099\n",
      "Epoch 118/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 118/1200, Iteration 12/12, Loss: 0.0224\n",
      "Epoch 118/1200, Iteration 13/12, Loss: 0.0097\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.007945, MRE: 0.036457, MAE: 0.006062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006742, MRE: 0.032618, MAE: 0.006306 \n",
      "\n",
      "Epoch 119/1200, Iteration 1/12, Loss: 0.0136\n",
      "Epoch 119/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 119/1200, Iteration 3/12, Loss: 0.0075\n",
      "Epoch 119/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 119/1200, Iteration 5/12, Loss: 0.0075\n",
      "Epoch 119/1200, Iteration 6/12, Loss: 0.0095\n",
      "Epoch 119/1200, Iteration 7/12, Loss: 0.0097\n",
      "Epoch 119/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 119/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 119/1200, Iteration 10/12, Loss: 0.0104\n",
      "Epoch 119/1200, Iteration 11/12, Loss: 0.0109\n",
      "Epoch 119/1200, Iteration 12/12, Loss: 0.0167\n",
      "Epoch 119/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.007924, MRE: 0.036392, MAE: 0.006047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006792, MRE: 0.032399, MAE: 0.006262 \n",
      "\n",
      "Epoch 120/1200, Iteration 1/12, Loss: 0.0060\n",
      "Epoch 120/1200, Iteration 2/12, Loss: 0.0100\n",
      "Epoch 120/1200, Iteration 3/12, Loss: 0.0153\n",
      "Epoch 120/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 120/1200, Iteration 5/12, Loss: 0.0157\n",
      "Epoch 120/1200, Iteration 6/12, Loss: 0.0104\n",
      "Epoch 120/1200, Iteration 7/12, Loss: 0.0114\n",
      "Epoch 120/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 120/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 120/1200, Iteration 10/12, Loss: 0.0075\n",
      "Epoch 120/1200, Iteration 11/12, Loss: 0.0071\n",
      "Epoch 120/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 120/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.007915, MRE: 0.035730, MAE: 0.006055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006903, MRE: 0.032607, MAE: 0.006321 \n",
      "\n",
      "Epoch 121/1200, Iteration 1/12, Loss: 0.0073\n",
      "Epoch 121/1200, Iteration 2/12, Loss: 0.0154\n",
      "Epoch 121/1200, Iteration 3/12, Loss: 0.0052\n",
      "Epoch 121/1200, Iteration 4/12, Loss: 0.0099\n",
      "Epoch 121/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 121/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 121/1200, Iteration 7/12, Loss: 0.0108\n",
      "Epoch 121/1200, Iteration 8/12, Loss: 0.0192\n",
      "Epoch 121/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 121/1200, Iteration 10/12, Loss: 0.0068\n",
      "Epoch 121/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 121/1200, Iteration 12/12, Loss: 0.0203\n",
      "Epoch 121/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.008507, MRE: 0.037709, MAE: 0.006174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007132, MRE: 0.032975, MAE: 0.006360 \n",
      "\n",
      "Epoch 122/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 122/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 122/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 122/1200, Iteration 4/12, Loss: 0.0090\n",
      "Epoch 122/1200, Iteration 5/12, Loss: 0.0064\n",
      "Epoch 122/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 122/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 122/1200, Iteration 8/12, Loss: 0.0162\n",
      "Epoch 122/1200, Iteration 9/12, Loss: 0.0099\n",
      "Epoch 122/1200, Iteration 10/12, Loss: 0.0184\n",
      "Epoch 122/1200, Iteration 11/12, Loss: 0.0178\n",
      "Epoch 122/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 122/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.007785, MRE: 0.035389, MAE: 0.005985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006811, MRE: 0.032505, MAE: 0.006317 \n",
      "\n",
      "Epoch 123/1200, Iteration 1/12, Loss: 0.0114\n",
      "Epoch 123/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 123/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 123/1200, Iteration 4/12, Loss: 0.0055\n",
      "Epoch 123/1200, Iteration 5/12, Loss: 0.0091\n",
      "Epoch 123/1200, Iteration 6/12, Loss: 0.0129\n",
      "Epoch 123/1200, Iteration 7/12, Loss: 0.0130\n",
      "Epoch 123/1200, Iteration 8/12, Loss: 0.0063\n",
      "Epoch 123/1200, Iteration 9/12, Loss: 0.0057\n",
      "Epoch 123/1200, Iteration 10/12, Loss: 0.0127\n",
      "Epoch 123/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 123/1200, Iteration 12/12, Loss: 0.0110\n",
      "Epoch 123/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.007782, MRE: 0.036088, MAE: 0.006007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006864, MRE: 0.032422, MAE: 0.006295 \n",
      "\n",
      "Epoch 124/1200, Iteration 1/12, Loss: 0.0140\n",
      "Epoch 124/1200, Iteration 2/12, Loss: 0.0084\n",
      "Epoch 124/1200, Iteration 3/12, Loss: 0.0075\n",
      "Epoch 124/1200, Iteration 4/12, Loss: 0.0057\n",
      "Epoch 124/1200, Iteration 5/12, Loss: 0.0088\n",
      "Epoch 124/1200, Iteration 6/12, Loss: 0.0086\n",
      "Epoch 124/1200, Iteration 7/12, Loss: 0.0068\n",
      "Epoch 124/1200, Iteration 8/12, Loss: 0.0133\n",
      "Epoch 124/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 124/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 124/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 124/1200, Iteration 12/12, Loss: 0.0060\n",
      "Epoch 124/1200, Iteration 13/12, Loss: 0.0200\n",
      "Train Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.007758, MRE: 0.035991, MAE: 0.006012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007326, MRE: 0.032621, MAE: 0.006353 \n",
      "\n",
      "Epoch 125/1200, Iteration 1/12, Loss: 0.0150\n",
      "Epoch 125/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 125/1200, Iteration 3/12, Loss: 0.0135\n",
      "Epoch 125/1200, Iteration 4/12, Loss: 0.0077\n",
      "Epoch 125/1200, Iteration 5/12, Loss: 0.0080\n",
      "Epoch 125/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 125/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 125/1200, Iteration 8/12, Loss: 0.0096\n",
      "Epoch 125/1200, Iteration 9/12, Loss: 0.0094\n",
      "Epoch 125/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 125/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 125/1200, Iteration 12/12, Loss: 0.0105\n",
      "Epoch 125/1200, Iteration 13/12, Loss: 0.0211\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.007974, MRE: 0.035458, MAE: 0.006000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006977, MRE: 0.032613, MAE: 0.006290 \n",
      "\n",
      "Epoch 126/1200, Iteration 1/12, Loss: 0.0120\n",
      "Epoch 126/1200, Iteration 2/12, Loss: 0.0089\n",
      "Epoch 126/1200, Iteration 3/12, Loss: 0.0103\n",
      "Epoch 126/1200, Iteration 4/12, Loss: 0.0066\n",
      "Epoch 126/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 126/1200, Iteration 6/12, Loss: 0.0074\n",
      "Epoch 126/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 126/1200, Iteration 8/12, Loss: 0.0168\n",
      "Epoch 126/1200, Iteration 9/12, Loss: 0.0085\n",
      "Epoch 126/1200, Iteration 10/12, Loss: 0.0104\n",
      "Epoch 126/1200, Iteration 11/12, Loss: 0.0081\n",
      "Epoch 126/1200, Iteration 12/12, Loss: 0.0061\n",
      "Epoch 126/1200, Iteration 13/12, Loss: 0.0086\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.008427, MRE: 0.035884, MAE: 0.006016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.006498, MRE: 0.031795, MAE: 0.006126 \n",
      "\n",
      "Epoch 127/1200, Iteration 1/12, Loss: 0.0100\n",
      "Epoch 127/1200, Iteration 2/12, Loss: 0.0123\n",
      "Epoch 127/1200, Iteration 3/12, Loss: 0.0125\n",
      "Epoch 127/1200, Iteration 4/12, Loss: 0.0095\n",
      "Epoch 127/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 127/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 127/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 127/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 127/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 127/1200, Iteration 10/12, Loss: 0.0066\n",
      "Epoch 127/1200, Iteration 11/12, Loss: 0.0077\n",
      "Epoch 127/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 127/1200, Iteration 13/12, Loss: 0.0288\n",
      "Train Error: \n",
      " Accuracy: 94.62%, Avg loss: 0.007758, MRE: 0.035590, MAE: 0.005967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006900, MRE: 0.032076, MAE: 0.006214 \n",
      "\n",
      "Epoch 128/1200, Iteration 1/12, Loss: 0.0090\n",
      "Epoch 128/1200, Iteration 2/12, Loss: 0.0136\n",
      "Epoch 128/1200, Iteration 3/12, Loss: 0.0059\n",
      "Epoch 128/1200, Iteration 4/12, Loss: 0.0113\n",
      "Epoch 128/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 128/1200, Iteration 6/12, Loss: 0.0096\n",
      "Epoch 128/1200, Iteration 7/12, Loss: 0.0099\n",
      "Epoch 128/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 128/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 128/1200, Iteration 10/12, Loss: 0.0085\n",
      "Epoch 128/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 128/1200, Iteration 12/12, Loss: 0.0175\n",
      "Epoch 128/1200, Iteration 13/12, Loss: 0.0120\n",
      "Train Error: \n",
      " Accuracy: 92.88%, Avg loss: 0.007887, MRE: 0.035340, MAE: 0.005981 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.005994, MRE: 0.031863, MAE: 0.006052 \n",
      "\n",
      "Epoch 129/1200, Iteration 1/12, Loss: 0.0168\n",
      "Epoch 129/1200, Iteration 2/12, Loss: 0.0101\n",
      "Epoch 129/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 129/1200, Iteration 4/12, Loss: 0.0068\n",
      "Epoch 129/1200, Iteration 5/12, Loss: 0.0074\n",
      "Epoch 129/1200, Iteration 6/12, Loss: 0.0101\n",
      "Epoch 129/1200, Iteration 7/12, Loss: 0.0066\n",
      "Epoch 129/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 129/1200, Iteration 9/12, Loss: 0.0112\n",
      "Epoch 129/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 129/1200, Iteration 11/12, Loss: 0.0070\n",
      "Epoch 129/1200, Iteration 12/12, Loss: 0.0236\n",
      "Epoch 129/1200, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.12%, Avg loss: 0.007682, MRE: 0.034825, MAE: 0.005899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.006071, MRE: 0.031687, MAE: 0.006057 \n",
      "\n",
      "Epoch 130/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 130/1200, Iteration 2/12, Loss: 0.0196\n",
      "Epoch 130/1200, Iteration 3/12, Loss: 0.0064\n",
      "Epoch 130/1200, Iteration 4/12, Loss: 0.0061\n",
      "Epoch 130/1200, Iteration 5/12, Loss: 0.0068\n",
      "Epoch 130/1200, Iteration 6/12, Loss: 0.0109\n",
      "Epoch 130/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 130/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 130/1200, Iteration 9/12, Loss: 0.0204\n",
      "Epoch 130/1200, Iteration 10/12, Loss: 0.0064\n",
      "Epoch 130/1200, Iteration 11/12, Loss: 0.0062\n",
      "Epoch 130/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 130/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007531, MRE: 0.034557, MAE: 0.005893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006443, MRE: 0.031567, MAE: 0.006096 \n",
      "\n",
      "Epoch 131/1200, Iteration 1/12, Loss: 0.0100\n",
      "Epoch 131/1200, Iteration 2/12, Loss: 0.0062\n",
      "Epoch 131/1200, Iteration 3/12, Loss: 0.0180\n",
      "Epoch 131/1200, Iteration 4/12, Loss: 0.0090\n",
      "Epoch 131/1200, Iteration 5/12, Loss: 0.0083\n",
      "Epoch 131/1200, Iteration 6/12, Loss: 0.0120\n",
      "Epoch 131/1200, Iteration 7/12, Loss: 0.0069\n",
      "Epoch 131/1200, Iteration 8/12, Loss: 0.0140\n",
      "Epoch 131/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 131/1200, Iteration 10/12, Loss: 0.0062\n",
      "Epoch 131/1200, Iteration 11/12, Loss: 0.0082\n",
      "Epoch 131/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 131/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.007572, MRE: 0.034538, MAE: 0.005854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.006137, MRE: 0.031290, MAE: 0.005976 \n",
      "\n",
      "Epoch 132/1200, Iteration 1/12, Loss: 0.0087\n",
      "Epoch 132/1200, Iteration 2/12, Loss: 0.0183\n",
      "Epoch 132/1200, Iteration 3/12, Loss: 0.0071\n",
      "Epoch 132/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 132/1200, Iteration 5/12, Loss: 0.0152\n",
      "Epoch 132/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 132/1200, Iteration 7/12, Loss: 0.0051\n",
      "Epoch 132/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 132/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 132/1200, Iteration 10/12, Loss: 0.0131\n",
      "Epoch 132/1200, Iteration 11/12, Loss: 0.0063\n",
      "Epoch 132/1200, Iteration 12/12, Loss: 0.0102\n",
      "Epoch 132/1200, Iteration 13/12, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.007595, MRE: 0.035919, MAE: 0.006071 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.007648, MRE: 0.032690, MAE: 0.006535 \n",
      "\n",
      "Epoch 133/1200, Iteration 1/12, Loss: 0.0121\n",
      "Epoch 133/1200, Iteration 2/12, Loss: 0.0132\n",
      "Epoch 133/1200, Iteration 3/12, Loss: 0.0072\n",
      "Epoch 133/1200, Iteration 4/12, Loss: 0.0069\n",
      "Epoch 133/1200, Iteration 5/12, Loss: 0.0065\n",
      "Epoch 133/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 133/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 133/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 133/1200, Iteration 9/12, Loss: 0.0082\n",
      "Epoch 133/1200, Iteration 10/12, Loss: 0.0094\n",
      "Epoch 133/1200, Iteration 11/12, Loss: 0.0134\n",
      "Epoch 133/1200, Iteration 12/12, Loss: 0.0094\n",
      "Epoch 133/1200, Iteration 13/12, Loss: 0.0064\n",
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.007439, MRE: 0.033914, MAE: 0.005822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.006311, MRE: 0.031560, MAE: 0.006036 \n",
      "\n",
      "Epoch 134/1200, Iteration 1/12, Loss: 0.0070\n",
      "Epoch 134/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 134/1200, Iteration 3/12, Loss: 0.0153\n",
      "Epoch 134/1200, Iteration 4/12, Loss: 0.0080\n",
      "Epoch 134/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 134/1200, Iteration 6/12, Loss: 0.0079\n",
      "Epoch 134/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 134/1200, Iteration 8/12, Loss: 0.0113\n",
      "Epoch 134/1200, Iteration 9/12, Loss: 0.0107\n",
      "Epoch 134/1200, Iteration 10/12, Loss: 0.0098\n",
      "Epoch 134/1200, Iteration 11/12, Loss: 0.0117\n",
      "Epoch 134/1200, Iteration 12/12, Loss: 0.0094\n",
      "Epoch 134/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.007476, MRE: 0.034746, MAE: 0.005873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006733, MRE: 0.031382, MAE: 0.006081 \n",
      "\n",
      "Epoch 135/1200, Iteration 1/12, Loss: 0.0121\n",
      "Epoch 135/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 135/1200, Iteration 3/12, Loss: 0.0068\n",
      "Epoch 135/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 135/1200, Iteration 5/12, Loss: 0.0108\n",
      "Epoch 135/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 135/1200, Iteration 7/12, Loss: 0.0171\n",
      "Epoch 135/1200, Iteration 8/12, Loss: 0.0068\n",
      "Epoch 135/1200, Iteration 9/12, Loss: 0.0133\n",
      "Epoch 135/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 135/1200, Iteration 11/12, Loss: 0.0097\n",
      "Epoch 135/1200, Iteration 12/12, Loss: 0.0078\n",
      "Epoch 135/1200, Iteration 13/12, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.007354, MRE: 0.033952, MAE: 0.005813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006976, MRE: 0.031546, MAE: 0.006152 \n",
      "\n",
      "Epoch 136/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 136/1200, Iteration 2/12, Loss: 0.0097\n",
      "Epoch 136/1200, Iteration 3/12, Loss: 0.0166\n",
      "Epoch 136/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 136/1200, Iteration 5/12, Loss: 0.0105\n",
      "Epoch 136/1200, Iteration 6/12, Loss: 0.0130\n",
      "Epoch 136/1200, Iteration 7/12, Loss: 0.0108\n",
      "Epoch 136/1200, Iteration 8/12, Loss: 0.0068\n",
      "Epoch 136/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 136/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 136/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 136/1200, Iteration 12/12, Loss: 0.0118\n",
      "Epoch 136/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.008264, MRE: 0.034256, MAE: 0.005930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006487, MRE: 0.031323, MAE: 0.006046 \n",
      "\n",
      "Epoch 137/1200, Iteration 1/12, Loss: 0.0063\n",
      "Epoch 137/1200, Iteration 2/12, Loss: 0.0131\n",
      "Epoch 137/1200, Iteration 3/12, Loss: 0.0072\n",
      "Epoch 137/1200, Iteration 4/12, Loss: 0.0068\n",
      "Epoch 137/1200, Iteration 5/12, Loss: 0.0132\n",
      "Epoch 137/1200, Iteration 6/12, Loss: 0.0103\n",
      "Epoch 137/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 137/1200, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 137/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 137/1200, Iteration 10/12, Loss: 0.0120\n",
      "Epoch 137/1200, Iteration 11/12, Loss: 0.0084\n",
      "Epoch 137/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 137/1200, Iteration 13/12, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.007500, MRE: 0.034952, MAE: 0.005805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006202, MRE: 0.030994, MAE: 0.005954 \n",
      "\n",
      "Epoch 138/1200, Iteration 1/12, Loss: 0.0126\n",
      "Epoch 138/1200, Iteration 2/12, Loss: 0.0073\n",
      "Epoch 138/1200, Iteration 3/12, Loss: 0.0076\n",
      "Epoch 138/1200, Iteration 4/12, Loss: 0.0114\n",
      "Epoch 138/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 138/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 138/1200, Iteration 7/12, Loss: 0.0115\n",
      "Epoch 138/1200, Iteration 8/12, Loss: 0.0079\n",
      "Epoch 138/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 138/1200, Iteration 10/12, Loss: 0.0144\n",
      "Epoch 138/1200, Iteration 11/12, Loss: 0.0070\n",
      "Epoch 138/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 138/1200, Iteration 13/12, Loss: 0.0104\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.007271, MRE: 0.034657, MAE: 0.005845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006928, MRE: 0.031514, MAE: 0.006160 \n",
      "\n",
      "Epoch 139/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 139/1200, Iteration 2/12, Loss: 0.0107\n",
      "Epoch 139/1200, Iteration 3/12, Loss: 0.0102\n",
      "Epoch 139/1200, Iteration 4/12, Loss: 0.0092\n",
      "Epoch 139/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 139/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 139/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 139/1200, Iteration 8/12, Loss: 0.0158\n",
      "Epoch 139/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 139/1200, Iteration 10/12, Loss: 0.0122\n",
      "Epoch 139/1200, Iteration 11/12, Loss: 0.0095\n",
      "Epoch 139/1200, Iteration 12/12, Loss: 0.0105\n",
      "Epoch 139/1200, Iteration 13/12, Loss: 0.0055\n",
      "Train Error: \n",
      " Accuracy: 94.62%, Avg loss: 0.007104, MRE: 0.033385, MAE: 0.005708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006693, MRE: 0.031229, MAE: 0.006063 \n",
      "\n",
      "Epoch 140/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 140/1200, Iteration 2/12, Loss: 0.0121\n",
      "Epoch 140/1200, Iteration 3/12, Loss: 0.0108\n",
      "Epoch 140/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 140/1200, Iteration 5/12, Loss: 0.0222\n",
      "Epoch 140/1200, Iteration 6/12, Loss: 0.0078\n",
      "Epoch 140/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 140/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 140/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 140/1200, Iteration 10/12, Loss: 0.0096\n",
      "Epoch 140/1200, Iteration 11/12, Loss: 0.0084\n",
      "Epoch 140/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 140/1200, Iteration 13/12, Loss: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.007806, MRE: 0.038590, MAE: 0.005783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006242, MRE: 0.030782, MAE: 0.005919 \n",
      "\n",
      "Epoch 141/1200, Iteration 1/12, Loss: 0.0127\n",
      "Epoch 141/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 141/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 141/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 141/1200, Iteration 5/12, Loss: 0.0080\n",
      "Epoch 141/1200, Iteration 6/12, Loss: 0.0054\n",
      "Epoch 141/1200, Iteration 7/12, Loss: 0.0083\n",
      "Epoch 141/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 141/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 141/1200, Iteration 10/12, Loss: 0.0071\n",
      "Epoch 141/1200, Iteration 11/12, Loss: 0.0135\n",
      "Epoch 141/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 141/1200, Iteration 13/12, Loss: 0.0285\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.007609, MRE: 0.035466, MAE: 0.006034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.007747, MRE: 0.032464, MAE: 0.006419 \n",
      "\n",
      "Epoch 142/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 142/1200, Iteration 2/12, Loss: 0.0137\n",
      "Epoch 142/1200, Iteration 3/12, Loss: 0.0135\n",
      "Epoch 142/1200, Iteration 4/12, Loss: 0.0145\n",
      "Epoch 142/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 142/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 142/1200, Iteration 7/12, Loss: 0.0085\n",
      "Epoch 142/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 142/1200, Iteration 9/12, Loss: 0.0066\n",
      "Epoch 142/1200, Iteration 10/12, Loss: 0.0087\n",
      "Epoch 142/1200, Iteration 11/12, Loss: 0.0075\n",
      "Epoch 142/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 142/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.007591, MRE: 0.033220, MAE: 0.005719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006158, MRE: 0.030634, MAE: 0.005892 \n",
      "\n",
      "Epoch 143/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 143/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 143/1200, Iteration 3/12, Loss: 0.0121\n",
      "Epoch 143/1200, Iteration 4/12, Loss: 0.0061\n",
      "Epoch 143/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 143/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 143/1200, Iteration 7/12, Loss: 0.0144\n",
      "Epoch 143/1200, Iteration 8/12, Loss: 0.0128\n",
      "Epoch 143/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 143/1200, Iteration 10/12, Loss: 0.0066\n",
      "Epoch 143/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 143/1200, Iteration 12/12, Loss: 0.0122\n",
      "Epoch 143/1200, Iteration 13/12, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007161, MRE: 0.033313, MAE: 0.005726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.005914, MRE: 0.030769, MAE: 0.005860 \n",
      "\n",
      "Epoch 144/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 144/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 144/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 144/1200, Iteration 4/12, Loss: 0.0144\n",
      "Epoch 144/1200, Iteration 5/12, Loss: 0.0095\n",
      "Epoch 144/1200, Iteration 6/12, Loss: 0.0132\n",
      "Epoch 144/1200, Iteration 7/12, Loss: 0.0131\n",
      "Epoch 144/1200, Iteration 8/12, Loss: 0.0102\n",
      "Epoch 144/1200, Iteration 9/12, Loss: 0.0102\n",
      "Epoch 144/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 144/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 144/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 144/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.007104, MRE: 0.037103, MAE: 0.005650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.005987, MRE: 0.030647, MAE: 0.005810 \n",
      "\n",
      "Epoch 145/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 145/1200, Iteration 2/12, Loss: 0.0153\n",
      "Epoch 145/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 145/1200, Iteration 4/12, Loss: 0.0121\n",
      "Epoch 145/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 145/1200, Iteration 6/12, Loss: 0.0155\n",
      "Epoch 145/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 145/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 145/1200, Iteration 9/12, Loss: 0.0089\n",
      "Epoch 145/1200, Iteration 10/12, Loss: 0.0097\n",
      "Epoch 145/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 145/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 145/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.007214, MRE: 0.033902, MAE: 0.005743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006487, MRE: 0.030602, MAE: 0.005938 \n",
      "\n",
      "Epoch 146/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 146/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 146/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 146/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 146/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 146/1200, Iteration 6/12, Loss: 0.0156\n",
      "Epoch 146/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 146/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 146/1200, Iteration 9/12, Loss: 0.0124\n",
      "Epoch 146/1200, Iteration 10/12, Loss: 0.0168\n",
      "Epoch 146/1200, Iteration 11/12, Loss: 0.0073\n",
      "Epoch 146/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 146/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.007077, MRE: 0.033413, MAE: 0.005631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006305, MRE: 0.030332, MAE: 0.005880 \n",
      "\n",
      "Epoch 147/1200, Iteration 1/12, Loss: 0.0108\n",
      "Epoch 147/1200, Iteration 2/12, Loss: 0.0075\n",
      "Epoch 147/1200, Iteration 3/12, Loss: 0.0170\n",
      "Epoch 147/1200, Iteration 4/12, Loss: 0.0116\n",
      "Epoch 147/1200, Iteration 5/12, Loss: 0.0085\n",
      "Epoch 147/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 147/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 147/1200, Iteration 8/12, Loss: 0.0080\n",
      "Epoch 147/1200, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 147/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 147/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 147/1200, Iteration 12/12, Loss: 0.0110\n",
      "Epoch 147/1200, Iteration 13/12, Loss: 0.0073\n",
      "Train Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.006949, MRE: 0.032509, MAE: 0.005590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.005841, MRE: 0.030478, MAE: 0.005784 \n",
      "\n",
      "Epoch 148/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 148/1200, Iteration 2/12, Loss: 0.0162\n",
      "Epoch 148/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 148/1200, Iteration 4/12, Loss: 0.0079\n",
      "Epoch 148/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 148/1200, Iteration 6/12, Loss: 0.0091\n",
      "Epoch 148/1200, Iteration 7/12, Loss: 0.0109\n",
      "Epoch 148/1200, Iteration 8/12, Loss: 0.0065\n",
      "Epoch 148/1200, Iteration 9/12, Loss: 0.0119\n",
      "Epoch 148/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 148/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 148/1200, Iteration 12/12, Loss: 0.0088\n",
      "Epoch 148/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 93.62%, Avg loss: 0.006934, MRE: 0.032220, MAE: 0.005611 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005816, MRE: 0.030438, MAE: 0.005775 \n",
      "\n",
      "Epoch 149/1200, Iteration 1/12, Loss: 0.0127\n",
      "Epoch 149/1200, Iteration 2/12, Loss: 0.0117\n",
      "Epoch 149/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 149/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 149/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 149/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 149/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 149/1200, Iteration 8/12, Loss: 0.0102\n",
      "Epoch 149/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 149/1200, Iteration 10/12, Loss: 0.0093\n",
      "Epoch 149/1200, Iteration 11/12, Loss: 0.0092\n",
      "Epoch 149/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 149/1200, Iteration 13/12, Loss: 0.0198\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.006872, MRE: 0.033801, MAE: 0.005609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006304, MRE: 0.030085, MAE: 0.005820 \n",
      "\n",
      "Epoch 150/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 150/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 150/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 150/1200, Iteration 4/12, Loss: 0.0055\n",
      "Epoch 150/1200, Iteration 5/12, Loss: 0.0102\n",
      "Epoch 150/1200, Iteration 6/12, Loss: 0.0122\n",
      "Epoch 150/1200, Iteration 7/12, Loss: 0.0069\n",
      "Epoch 150/1200, Iteration 8/12, Loss: 0.0133\n",
      "Epoch 150/1200, Iteration 9/12, Loss: 0.0142\n",
      "Epoch 150/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 150/1200, Iteration 11/12, Loss: 0.0101\n",
      "Epoch 150/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 150/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.007132, MRE: 0.033005, MAE: 0.005652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.005668, MRE: 0.030755, MAE: 0.005812 \n",
      "\n",
      "Epoch 151/1200, Iteration 1/12, Loss: 0.0169\n",
      "Epoch 151/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 151/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 151/1200, Iteration 4/12, Loss: 0.0142\n",
      "Epoch 151/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 151/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 151/1200, Iteration 7/12, Loss: 0.0132\n",
      "Epoch 151/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 151/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 151/1200, Iteration 10/12, Loss: 0.0075\n",
      "Epoch 151/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 151/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 151/1200, Iteration 13/12, Loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.75%, Avg loss: 0.006995, MRE: 0.032791, MAE: 0.005576 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005435, MRE: 0.029530, MAE: 0.005651 \n",
      "\n",
      "Epoch 152/1200, Iteration 1/12, Loss: 0.0175\n",
      "Epoch 152/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 152/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 152/1200, Iteration 4/12, Loss: 0.0126\n",
      "Epoch 152/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 152/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 152/1200, Iteration 7/12, Loss: 0.0104\n",
      "Epoch 152/1200, Iteration 8/12, Loss: 0.0145\n",
      "Epoch 152/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 152/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 152/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 152/1200, Iteration 12/12, Loss: 0.0067\n",
      "Epoch 152/1200, Iteration 13/12, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.006859, MRE: 0.032950, MAE: 0.005661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006252, MRE: 0.030360, MAE: 0.005864 \n",
      "\n",
      "Epoch 153/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 153/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 153/1200, Iteration 3/12, Loss: 0.0104\n",
      "Epoch 153/1200, Iteration 4/12, Loss: 0.0056\n",
      "Epoch 153/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 153/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 153/1200, Iteration 7/12, Loss: 0.0083\n",
      "Epoch 153/1200, Iteration 8/12, Loss: 0.0137\n",
      "Epoch 153/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 153/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 153/1200, Iteration 11/12, Loss: 0.0105\n",
      "Epoch 153/1200, Iteration 12/12, Loss: 0.0088\n",
      "Epoch 153/1200, Iteration 13/12, Loss: 0.0129\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.006768, MRE: 0.036674, MAE: 0.005520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005588, MRE: 0.029487, MAE: 0.005660 \n",
      "\n",
      "Epoch 154/1200, Iteration 1/12, Loss: 0.0163\n",
      "Epoch 154/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 154/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 154/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 154/1200, Iteration 5/12, Loss: 0.0094\n",
      "Epoch 154/1200, Iteration 6/12, Loss: 0.0103\n",
      "Epoch 154/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 154/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 154/1200, Iteration 9/12, Loss: 0.0173\n",
      "Epoch 154/1200, Iteration 10/12, Loss: 0.0077\n",
      "Epoch 154/1200, Iteration 11/12, Loss: 0.0125\n",
      "Epoch 154/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 154/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.006599, MRE: 0.031369, MAE: 0.005450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005719, MRE: 0.029657, MAE: 0.005682 \n",
      "\n",
      "Epoch 155/1200, Iteration 1/12, Loss: 0.0179\n",
      "Epoch 155/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 155/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 155/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 155/1200, Iteration 5/12, Loss: 0.0153\n",
      "Epoch 155/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 155/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 155/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 155/1200, Iteration 9/12, Loss: 0.0106\n",
      "Epoch 155/1200, Iteration 10/12, Loss: 0.0086\n",
      "Epoch 155/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 155/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 155/1200, Iteration 13/12, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.006595, MRE: 0.031737, MAE: 0.005487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005981, MRE: 0.029837, MAE: 0.005758 \n",
      "\n",
      "Epoch 156/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 156/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 156/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 156/1200, Iteration 4/12, Loss: 0.0170\n",
      "Epoch 156/1200, Iteration 5/12, Loss: 0.0060\n",
      "Epoch 156/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 156/1200, Iteration 7/12, Loss: 0.0067\n",
      "Epoch 156/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 156/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 156/1200, Iteration 10/12, Loss: 0.0184\n",
      "Epoch 156/1200, Iteration 11/12, Loss: 0.0057\n",
      "Epoch 156/1200, Iteration 12/12, Loss: 0.0110\n",
      "Epoch 156/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.007342, MRE: 0.032186, MAE: 0.005604 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006115, MRE: 0.029833, MAE: 0.005780 \n",
      "\n",
      "Epoch 157/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 157/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 157/1200, Iteration 3/12, Loss: 0.0095\n",
      "Epoch 157/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 157/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 157/1200, Iteration 6/12, Loss: 0.0075\n",
      "Epoch 157/1200, Iteration 7/12, Loss: 0.0111\n",
      "Epoch 157/1200, Iteration 8/12, Loss: 0.0129\n",
      "Epoch 157/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 157/1200, Iteration 10/12, Loss: 0.0153\n",
      "Epoch 157/1200, Iteration 11/12, Loss: 0.0108\n",
      "Epoch 157/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 157/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.006757, MRE: 0.031320, MAE: 0.005492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005864, MRE: 0.029523, MAE: 0.005696 \n",
      "\n",
      "Epoch 158/1200, Iteration 1/12, Loss: 0.0122\n",
      "Epoch 158/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 158/1200, Iteration 3/12, Loss: 0.0091\n",
      "Epoch 158/1200, Iteration 4/12, Loss: 0.0128\n",
      "Epoch 158/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 158/1200, Iteration 6/12, Loss: 0.0093\n",
      "Epoch 158/1200, Iteration 7/12, Loss: 0.0118\n",
      "Epoch 158/1200, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 158/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 158/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 158/1200, Iteration 11/12, Loss: 0.0090\n",
      "Epoch 158/1200, Iteration 12/12, Loss: 0.0070\n",
      "Epoch 158/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 93.88%, Avg loss: 0.006604, MRE: 0.031224, MAE: 0.005426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005632, MRE: 0.029241, MAE: 0.005619 \n",
      "\n",
      "Epoch 159/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 159/1200, Iteration 2/12, Loss: 0.0166\n",
      "Epoch 159/1200, Iteration 3/12, Loss: 0.0125\n",
      "Epoch 159/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 159/1200, Iteration 5/12, Loss: 0.0057\n",
      "Epoch 159/1200, Iteration 6/12, Loss: 0.0088\n",
      "Epoch 159/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 159/1200, Iteration 8/12, Loss: 0.0074\n",
      "Epoch 159/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 159/1200, Iteration 10/12, Loss: 0.0057\n",
      "Epoch 159/1200, Iteration 11/12, Loss: 0.0091\n",
      "Epoch 159/1200, Iteration 12/12, Loss: 0.0102\n",
      "Epoch 159/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.006601, MRE: 0.031339, MAE: 0.005454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005721, MRE: 0.029367, MAE: 0.005638 \n",
      "\n",
      "Epoch 160/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 160/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 160/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 160/1200, Iteration 4/12, Loss: 0.0104\n",
      "Epoch 160/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 160/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 160/1200, Iteration 7/12, Loss: 0.0082\n",
      "Epoch 160/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 160/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 160/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 160/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 160/1200, Iteration 12/12, Loss: 0.0184\n",
      "Epoch 160/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.006963, MRE: 0.032097, MAE: 0.005466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006056, MRE: 0.029172, MAE: 0.005684 \n",
      "\n",
      "Epoch 161/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 161/1200, Iteration 2/12, Loss: 0.0098\n",
      "Epoch 161/1200, Iteration 3/12, Loss: 0.0067\n",
      "Epoch 161/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 161/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 161/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 161/1200, Iteration 7/12, Loss: 0.0190\n",
      "Epoch 161/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 161/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 161/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 161/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 161/1200, Iteration 12/12, Loss: 0.0132\n",
      "Epoch 161/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006747, MRE: 0.032146, MAE: 0.005546 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006409, MRE: 0.029719, MAE: 0.005828 \n",
      "\n",
      "Epoch 162/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 162/1200, Iteration 2/12, Loss: 0.0136\n",
      "Epoch 162/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 162/1200, Iteration 4/12, Loss: 0.0079\n",
      "Epoch 162/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 162/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 162/1200, Iteration 7/12, Loss: 0.0104\n",
      "Epoch 162/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 162/1200, Iteration 9/12, Loss: 0.0141\n",
      "Epoch 162/1200, Iteration 10/12, Loss: 0.0077\n",
      "Epoch 162/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 162/1200, Iteration 12/12, Loss: 0.0061\n",
      "Epoch 162/1200, Iteration 13/12, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.006482, MRE: 0.031665, MAE: 0.005400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005946, MRE: 0.029255, MAE: 0.005640 \n",
      "\n",
      "Epoch 163/1200, Iteration 1/12, Loss: 0.0077\n",
      "Epoch 163/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 163/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 163/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 163/1200, Iteration 5/12, Loss: 0.0078\n",
      "Epoch 163/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 163/1200, Iteration 7/12, Loss: 0.0122\n",
      "Epoch 163/1200, Iteration 8/12, Loss: 0.0101\n",
      "Epoch 163/1200, Iteration 9/12, Loss: 0.0079\n",
      "Epoch 163/1200, Iteration 10/12, Loss: 0.0101\n",
      "Epoch 163/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 163/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 163/1200, Iteration 13/12, Loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006673, MRE: 0.033183, MAE: 0.005605 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006591, MRE: 0.030425, MAE: 0.005912 \n",
      "\n",
      "Epoch 164/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 164/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 164/1200, Iteration 3/12, Loss: 0.0106\n",
      "Epoch 164/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 164/1200, Iteration 5/12, Loss: 0.0059\n",
      "Epoch 164/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 164/1200, Iteration 7/12, Loss: 0.0120\n",
      "Epoch 164/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 164/1200, Iteration 9/12, Loss: 0.0095\n",
      "Epoch 164/1200, Iteration 10/12, Loss: 0.0102\n",
      "Epoch 164/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 164/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 164/1200, Iteration 13/12, Loss: 0.0202\n",
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.007044, MRE: 0.032135, MAE: 0.005554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006505, MRE: 0.029944, MAE: 0.005834 \n",
      "\n",
      "Epoch 165/1200, Iteration 1/12, Loss: 0.0074\n",
      "Epoch 165/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 165/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 165/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 165/1200, Iteration 5/12, Loss: 0.0095\n",
      "Epoch 165/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 165/1200, Iteration 7/12, Loss: 0.0102\n",
      "Epoch 165/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 165/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 165/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 165/1200, Iteration 11/12, Loss: 0.0157\n",
      "Epoch 165/1200, Iteration 12/12, Loss: 0.0141\n",
      "Epoch 165/1200, Iteration 13/12, Loss: 0.0075\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.006419, MRE: 0.031354, MAE: 0.005389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005558, MRE: 0.029043, MAE: 0.005539 \n",
      "\n",
      "Epoch 166/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 166/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 166/1200, Iteration 3/12, Loss: 0.0085\n",
      "Epoch 166/1200, Iteration 4/12, Loss: 0.0099\n",
      "Epoch 166/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 166/1200, Iteration 6/12, Loss: 0.0073\n",
      "Epoch 166/1200, Iteration 7/12, Loss: 0.0062\n",
      "Epoch 166/1200, Iteration 8/12, Loss: 0.0081\n",
      "Epoch 166/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 166/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 166/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 166/1200, Iteration 12/12, Loss: 0.0196\n",
      "Epoch 166/1200, Iteration 13/12, Loss: 0.0077\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.006936, MRE: 0.031368, MAE: 0.005408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005588, MRE: 0.028893, MAE: 0.005528 \n",
      "\n",
      "Epoch 167/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 167/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 167/1200, Iteration 3/12, Loss: 0.0132\n",
      "Epoch 167/1200, Iteration 4/12, Loss: 0.0092\n",
      "Epoch 167/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 167/1200, Iteration 6/12, Loss: 0.0139\n",
      "Epoch 167/1200, Iteration 7/12, Loss: 0.0069\n",
      "Epoch 167/1200, Iteration 8/12, Loss: 0.0089\n",
      "Epoch 167/1200, Iteration 9/12, Loss: 0.0058\n",
      "Epoch 167/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 167/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 167/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 167/1200, Iteration 13/12, Loss: 0.0064\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.006317, MRE: 0.031116, MAE: 0.005330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005182, MRE: 0.028836, MAE: 0.005477 \n",
      "\n",
      "Epoch 168/1200, Iteration 1/12, Loss: 0.0094\n",
      "Epoch 168/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 168/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 168/1200, Iteration 4/12, Loss: 0.0141\n",
      "Epoch 168/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 168/1200, Iteration 6/12, Loss: 0.0086\n",
      "Epoch 168/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 168/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 168/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 168/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 168/1200, Iteration 11/12, Loss: 0.0152\n",
      "Epoch 168/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 168/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.006304, MRE: 0.034825, MAE: 0.005283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005219, MRE: 0.028533, MAE: 0.005384 \n",
      "\n",
      "Epoch 169/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 169/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 169/1200, Iteration 3/12, Loss: 0.0116\n",
      "Epoch 169/1200, Iteration 4/12, Loss: 0.0056\n",
      "Epoch 169/1200, Iteration 5/12, Loss: 0.0119\n",
      "Epoch 169/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 169/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 169/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 169/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 169/1200, Iteration 10/12, Loss: 0.0092\n",
      "Epoch 169/1200, Iteration 11/12, Loss: 0.0110\n",
      "Epoch 169/1200, Iteration 12/12, Loss: 0.0072\n",
      "Epoch 169/1200, Iteration 13/12, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.006440, MRE: 0.031043, MAE: 0.005257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005186, MRE: 0.028325, MAE: 0.005347 \n",
      "\n",
      "Epoch 170/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 170/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 170/1200, Iteration 3/12, Loss: 0.0077\n",
      "Epoch 170/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 170/1200, Iteration 5/12, Loss: 0.0231\n",
      "Epoch 170/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 170/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 170/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 170/1200, Iteration 9/12, Loss: 0.0059\n",
      "Epoch 170/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 170/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 170/1200, Iteration 12/12, Loss: 0.0111\n",
      "Epoch 170/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.006172, MRE: 0.030835, MAE: 0.005271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005675, MRE: 0.028541, MAE: 0.005466 \n",
      "\n",
      "Epoch 171/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 171/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 171/1200, Iteration 3/12, Loss: 0.0068\n",
      "Epoch 171/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 171/1200, Iteration 5/12, Loss: 0.0091\n",
      "Epoch 171/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 171/1200, Iteration 7/12, Loss: 0.0130\n",
      "Epoch 171/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 171/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 171/1200, Iteration 10/12, Loss: 0.0165\n",
      "Epoch 171/1200, Iteration 11/12, Loss: 0.0091\n",
      "Epoch 171/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 171/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.006332, MRE: 0.030641, MAE: 0.005270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005674, MRE: 0.028781, MAE: 0.005514 \n",
      "\n",
      "Epoch 172/1200, Iteration 1/12, Loss: 0.0084\n",
      "Epoch 172/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 172/1200, Iteration 3/12, Loss: 0.0129\n",
      "Epoch 172/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 172/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 172/1200, Iteration 6/12, Loss: 0.0126\n",
      "Epoch 172/1200, Iteration 7/12, Loss: 0.0086\n",
      "Epoch 172/1200, Iteration 8/12, Loss: 0.0143\n",
      "Epoch 172/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 172/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 172/1200, Iteration 11/12, Loss: 0.0060\n",
      "Epoch 172/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 172/1200, Iteration 13/12, Loss: 0.0062\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.006250, MRE: 0.031274, MAE: 0.005349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.006033, MRE: 0.029232, MAE: 0.005632 \n",
      "\n",
      "Epoch 173/1200, Iteration 1/12, Loss: 0.0106\n",
      "Epoch 173/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 173/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 173/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 173/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 173/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 173/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 173/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 173/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 173/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 173/1200, Iteration 11/12, Loss: 0.0069\n",
      "Epoch 173/1200, Iteration 12/12, Loss: 0.0123\n",
      "Epoch 173/1200, Iteration 13/12, Loss: 0.0219\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.006227, MRE: 0.031866, MAE: 0.005319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005940, MRE: 0.029069, MAE: 0.005580 \n",
      "\n",
      "Epoch 174/1200, Iteration 1/12, Loss: 0.0120\n",
      "Epoch 174/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 174/1200, Iteration 3/12, Loss: 0.0047\n",
      "Epoch 174/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 174/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 174/1200, Iteration 6/12, Loss: 0.0081\n",
      "Epoch 174/1200, Iteration 7/12, Loss: 0.0078\n",
      "Epoch 174/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 174/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 174/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 174/1200, Iteration 11/12, Loss: 0.0141\n",
      "Epoch 174/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 174/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.006282, MRE: 0.031216, MAE: 0.005334 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005391, MRE: 0.028541, MAE: 0.005464 \n",
      "\n",
      "Epoch 175/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 175/1200, Iteration 2/12, Loss: 0.0056\n",
      "Epoch 175/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 175/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 175/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 175/1200, Iteration 6/12, Loss: 0.0141\n",
      "Epoch 175/1200, Iteration 7/12, Loss: 0.0132\n",
      "Epoch 175/1200, Iteration 8/12, Loss: 0.0152\n",
      "Epoch 175/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 175/1200, Iteration 10/12, Loss: 0.0073\n",
      "Epoch 175/1200, Iteration 11/12, Loss: 0.0054\n",
      "Epoch 175/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 175/1200, Iteration 13/12, Loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.006131, MRE: 0.030489, MAE: 0.005237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005388, MRE: 0.028509, MAE: 0.005410 \n",
      "\n",
      "Epoch 176/1200, Iteration 1/12, Loss: 0.0086\n",
      "Epoch 176/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 176/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 176/1200, Iteration 4/12, Loss: 0.0080\n",
      "Epoch 176/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 176/1200, Iteration 6/12, Loss: 0.0183\n",
      "Epoch 176/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 176/1200, Iteration 8/12, Loss: 0.0090\n",
      "Epoch 176/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 176/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 176/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 176/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 176/1200, Iteration 13/12, Loss: 0.0217\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.006019, MRE: 0.030288, MAE: 0.005193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005488, MRE: 0.028468, MAE: 0.005417 \n",
      "\n",
      "Epoch 177/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 177/1200, Iteration 2/12, Loss: 0.0219\n",
      "Epoch 177/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 177/1200, Iteration 4/12, Loss: 0.0075\n",
      "Epoch 177/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 177/1200, Iteration 6/12, Loss: 0.0085\n",
      "Epoch 177/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 177/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 177/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 177/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 177/1200, Iteration 11/12, Loss: 0.0097\n",
      "Epoch 177/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 177/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.006327, MRE: 0.030813, MAE: 0.005219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005185, MRE: 0.028205, MAE: 0.005344 \n",
      "\n",
      "Epoch 178/1200, Iteration 1/12, Loss: 0.0130\n",
      "Epoch 178/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 178/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 178/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 178/1200, Iteration 5/12, Loss: 0.0103\n",
      "Epoch 178/1200, Iteration 6/12, Loss: 0.0070\n",
      "Epoch 178/1200, Iteration 7/12, Loss: 0.0086\n",
      "Epoch 178/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 178/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 178/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 178/1200, Iteration 11/12, Loss: 0.0103\n",
      "Epoch 178/1200, Iteration 12/12, Loss: 0.0078\n",
      "Epoch 178/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 94.38%, Avg loss: 0.006044, MRE: 0.029911, MAE: 0.005178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005260, MRE: 0.028410, MAE: 0.005373 \n",
      "\n",
      "Epoch 179/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 179/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 179/1200, Iteration 3/12, Loss: 0.0115\n",
      "Epoch 179/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 179/1200, Iteration 5/12, Loss: 0.0055\n",
      "Epoch 179/1200, Iteration 6/12, Loss: 0.0072\n",
      "Epoch 179/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 179/1200, Iteration 8/12, Loss: 0.0075\n",
      "Epoch 179/1200, Iteration 9/12, Loss: 0.0102\n",
      "Epoch 179/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 179/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 179/1200, Iteration 12/12, Loss: 0.0112\n",
      "Epoch 179/1200, Iteration 13/12, Loss: 0.0104\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.006067, MRE: 0.030927, MAE: 0.005238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005466, MRE: 0.028132, MAE: 0.005402 \n",
      "\n",
      "Epoch 180/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 180/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 180/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 180/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 180/1200, Iteration 5/12, Loss: 0.0154\n",
      "Epoch 180/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 180/1200, Iteration 7/12, Loss: 0.0084\n",
      "Epoch 180/1200, Iteration 8/12, Loss: 0.0087\n",
      "Epoch 180/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 180/1200, Iteration 10/12, Loss: 0.0083\n",
      "Epoch 180/1200, Iteration 11/12, Loss: 0.0077\n",
      "Epoch 180/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 180/1200, Iteration 13/12, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005963, MRE: 0.030107, MAE: 0.005145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005454, MRE: 0.027933, MAE: 0.005350 \n",
      "\n",
      "Epoch 181/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 181/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 181/1200, Iteration 3/12, Loss: 0.0065\n",
      "Epoch 181/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 181/1200, Iteration 5/12, Loss: 0.0128\n",
      "Epoch 181/1200, Iteration 6/12, Loss: 0.0105\n",
      "Epoch 181/1200, Iteration 7/12, Loss: 0.0074\n",
      "Epoch 181/1200, Iteration 8/12, Loss: 0.0107\n",
      "Epoch 181/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 181/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 181/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 181/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 181/1200, Iteration 13/12, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.005994, MRE: 0.030050, MAE: 0.005178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005780, MRE: 0.028353, MAE: 0.005452 \n",
      "\n",
      "Epoch 182/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 182/1200, Iteration 2/12, Loss: 0.0076\n",
      "Epoch 182/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 182/1200, Iteration 4/12, Loss: 0.0096\n",
      "Epoch 182/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 182/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 182/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 182/1200, Iteration 8/12, Loss: 0.0139\n",
      "Epoch 182/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 182/1200, Iteration 10/12, Loss: 0.0097\n",
      "Epoch 182/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 182/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 182/1200, Iteration 13/12, Loss: 0.0160\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.005889, MRE: 0.029695, MAE: 0.005121 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005733, MRE: 0.028309, MAE: 0.005424 \n",
      "\n",
      "Epoch 183/1200, Iteration 1/12, Loss: 0.0137\n",
      "Epoch 183/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 183/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 183/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 183/1200, Iteration 5/12, Loss: 0.0141\n",
      "Epoch 183/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 183/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 183/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 183/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 183/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 183/1200, Iteration 11/12, Loss: 0.0071\n",
      "Epoch 183/1200, Iteration 12/12, Loss: 0.0070\n",
      "Epoch 183/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.005904, MRE: 0.030107, MAE: 0.005176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005782, MRE: 0.028360, MAE: 0.005437 \n",
      "\n",
      "Epoch 184/1200, Iteration 1/12, Loss: 0.0078\n",
      "Epoch 184/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 184/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 184/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 184/1200, Iteration 5/12, Loss: 0.0057\n",
      "Epoch 184/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 184/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 184/1200, Iteration 8/12, Loss: 0.0113\n",
      "Epoch 184/1200, Iteration 9/12, Loss: 0.0129\n",
      "Epoch 184/1200, Iteration 10/12, Loss: 0.0056\n",
      "Epoch 184/1200, Iteration 11/12, Loss: 0.0087\n",
      "Epoch 184/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 184/1200, Iteration 13/12, Loss: 0.0170\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005941, MRE: 0.029976, MAE: 0.005167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005841, MRE: 0.027854, MAE: 0.005414 \n",
      "\n",
      "Epoch 185/1200, Iteration 1/12, Loss: 0.0077\n",
      "Epoch 185/1200, Iteration 2/12, Loss: 0.0087\n",
      "Epoch 185/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 185/1200, Iteration 4/12, Loss: 0.0064\n",
      "Epoch 185/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 185/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 185/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 185/1200, Iteration 8/12, Loss: 0.0160\n",
      "Epoch 185/1200, Iteration 9/12, Loss: 0.0068\n",
      "Epoch 185/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 185/1200, Iteration 11/12, Loss: 0.0109\n",
      "Epoch 185/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 185/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.006422, MRE: 0.030549, MAE: 0.005212 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005528, MRE: 0.027877, MAE: 0.005347 \n",
      "\n",
      "Epoch 186/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 186/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 186/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 186/1200, Iteration 4/12, Loss: 0.0086\n",
      "Epoch 186/1200, Iteration 5/12, Loss: 0.0084\n",
      "Epoch 186/1200, Iteration 6/12, Loss: 0.0119\n",
      "Epoch 186/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 186/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 186/1200, Iteration 9/12, Loss: 0.0129\n",
      "Epoch 186/1200, Iteration 10/12, Loss: 0.0109\n",
      "Epoch 186/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 186/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 186/1200, Iteration 13/12, Loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005798, MRE: 0.029620, MAE: 0.005084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005427, MRE: 0.027676, MAE: 0.005323 \n",
      "\n",
      "Epoch 187/1200, Iteration 1/12, Loss: 0.0103\n",
      "Epoch 187/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 187/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 187/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 187/1200, Iteration 5/12, Loss: 0.0162\n",
      "Epoch 187/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 187/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 187/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 187/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 187/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 187/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 187/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 187/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.005783, MRE: 0.029743, MAE: 0.005053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005207, MRE: 0.027406, MAE: 0.005258 \n",
      "\n",
      "Epoch 188/1200, Iteration 1/12, Loss: 0.0126\n",
      "Epoch 188/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 188/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 188/1200, Iteration 4/12, Loss: 0.0116\n",
      "Epoch 188/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 188/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 188/1200, Iteration 7/12, Loss: 0.0070\n",
      "Epoch 188/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 188/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 188/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 188/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 188/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 188/1200, Iteration 13/12, Loss: 0.0232\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.006511, MRE: 0.032077, MAE: 0.005526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.006623, MRE: 0.029433, MAE: 0.005778 \n",
      "\n",
      "Epoch 189/1200, Iteration 1/12, Loss: 0.0141\n",
      "Epoch 189/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 189/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 189/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 189/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 189/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 189/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 189/1200, Iteration 8/12, Loss: 0.0138\n",
      "Epoch 189/1200, Iteration 9/12, Loss: 0.0075\n",
      "Epoch 189/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 189/1200, Iteration 11/12, Loss: 0.0104\n",
      "Epoch 189/1200, Iteration 12/12, Loss: 0.0127\n",
      "Epoch 189/1200, Iteration 13/12, Loss: 0.0075\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.006005, MRE: 0.030690, MAE: 0.005230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.006232, MRE: 0.028417, MAE: 0.005567 \n",
      "\n",
      "Epoch 190/1200, Iteration 1/12, Loss: 0.0082\n",
      "Epoch 190/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 190/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 190/1200, Iteration 4/12, Loss: 0.0069\n",
      "Epoch 190/1200, Iteration 5/12, Loss: 0.0086\n",
      "Epoch 190/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 190/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 190/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 190/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 190/1200, Iteration 10/12, Loss: 0.0109\n",
      "Epoch 190/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 190/1200, Iteration 12/12, Loss: 0.0122\n",
      "Epoch 190/1200, Iteration 13/12, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.005765, MRE: 0.029286, MAE: 0.005109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005895, MRE: 0.028022, MAE: 0.005451 \n",
      "\n",
      "Epoch 191/1200, Iteration 1/12, Loss: 0.0057\n",
      "Epoch 191/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 191/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 191/1200, Iteration 4/12, Loss: 0.0065\n",
      "Epoch 191/1200, Iteration 5/12, Loss: 0.0136\n",
      "Epoch 191/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 191/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 191/1200, Iteration 8/12, Loss: 0.0138\n",
      "Epoch 191/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 191/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 191/1200, Iteration 11/12, Loss: 0.0062\n",
      "Epoch 191/1200, Iteration 12/12, Loss: 0.0144\n",
      "Epoch 191/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005715, MRE: 0.029749, MAE: 0.005082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005479, MRE: 0.027653, MAE: 0.005354 \n",
      "\n",
      "Epoch 192/1200, Iteration 1/12, Loss: 0.0076\n",
      "Epoch 192/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 192/1200, Iteration 3/12, Loss: 0.0086\n",
      "Epoch 192/1200, Iteration 4/12, Loss: 0.0101\n",
      "Epoch 192/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 192/1200, Iteration 6/12, Loss: 0.0052\n",
      "Epoch 192/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 192/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 192/1200, Iteration 9/12, Loss: 0.0087\n",
      "Epoch 192/1200, Iteration 10/12, Loss: 0.0105\n",
      "Epoch 192/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 192/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 192/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.005741, MRE: 0.029530, MAE: 0.005086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005146, MRE: 0.027550, MAE: 0.005274 \n",
      "\n",
      "Epoch 193/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 193/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 193/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 193/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 193/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 193/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 193/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 193/1200, Iteration 8/12, Loss: 0.0098\n",
      "Epoch 193/1200, Iteration 9/12, Loss: 0.0099\n",
      "Epoch 193/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 193/1200, Iteration 11/12, Loss: 0.0053\n",
      "Epoch 193/1200, Iteration 12/12, Loss: 0.0129\n",
      "Epoch 193/1200, Iteration 13/12, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.005792, MRE: 0.029498, MAE: 0.005182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005908, MRE: 0.028380, MAE: 0.005498 \n",
      "\n",
      "Epoch 194/1200, Iteration 1/12, Loss: 0.0080\n",
      "Epoch 194/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 194/1200, Iteration 3/12, Loss: 0.0092\n",
      "Epoch 194/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 194/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 194/1200, Iteration 6/12, Loss: 0.0092\n",
      "Epoch 194/1200, Iteration 7/12, Loss: 0.0093\n",
      "Epoch 194/1200, Iteration 8/12, Loss: 0.0061\n",
      "Epoch 194/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 194/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 194/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 194/1200, Iteration 12/12, Loss: 0.0150\n",
      "Epoch 194/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.005945, MRE: 0.028985, MAE: 0.005063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005210, MRE: 0.027537, MAE: 0.005253 \n",
      "\n",
      "Epoch 195/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 195/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 195/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 195/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 195/1200, Iteration 5/12, Loss: 0.0085\n",
      "Epoch 195/1200, Iteration 6/12, Loss: 0.0100\n",
      "Epoch 195/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 195/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 195/1200, Iteration 9/12, Loss: 0.0114\n",
      "Epoch 195/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 195/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 195/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 195/1200, Iteration 13/12, Loss: 0.0196\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005741, MRE: 0.030368, MAE: 0.005126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.005879, MRE: 0.028017, MAE: 0.005431 \n",
      "\n",
      "Epoch 196/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 196/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 196/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 196/1200, Iteration 4/12, Loss: 0.0112\n",
      "Epoch 196/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 196/1200, Iteration 6/12, Loss: 0.0079\n",
      "Epoch 196/1200, Iteration 7/12, Loss: 0.0063\n",
      "Epoch 196/1200, Iteration 8/12, Loss: 0.0071\n",
      "Epoch 196/1200, Iteration 9/12, Loss: 0.0093\n",
      "Epoch 196/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 196/1200, Iteration 11/12, Loss: 0.0060\n",
      "Epoch 196/1200, Iteration 12/12, Loss: 0.0096\n",
      "Epoch 196/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.005596, MRE: 0.028767, MAE: 0.005005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005264, MRE: 0.027491, MAE: 0.005251 \n",
      "\n",
      "Epoch 197/1200, Iteration 1/12, Loss: 0.0085\n",
      "Epoch 197/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 197/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 197/1200, Iteration 4/12, Loss: 0.0158\n",
      "Epoch 197/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 197/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 197/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 197/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 197/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 197/1200, Iteration 10/12, Loss: 0.0058\n",
      "Epoch 197/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 197/1200, Iteration 12/12, Loss: 0.0063\n",
      "Epoch 197/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.005660, MRE: 0.029225, MAE: 0.004987 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004921, MRE: 0.027276, MAE: 0.005172 \n",
      "\n",
      "Epoch 198/1200, Iteration 1/12, Loss: 0.0092\n",
      "Epoch 198/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 198/1200, Iteration 3/12, Loss: 0.0077\n",
      "Epoch 198/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 198/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 198/1200, Iteration 6/12, Loss: 0.0119\n",
      "Epoch 198/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 198/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 198/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 198/1200, Iteration 10/12, Loss: 0.0131\n",
      "Epoch 198/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 198/1200, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 198/1200, Iteration 13/12, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.62%, Avg loss: 0.005672, MRE: 0.028810, MAE: 0.005015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004909, MRE: 0.027240, MAE: 0.005184 \n",
      "\n",
      "Epoch 199/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 199/1200, Iteration 2/12, Loss: 0.0066\n",
      "Epoch 199/1200, Iteration 3/12, Loss: 0.0086\n",
      "Epoch 199/1200, Iteration 4/12, Loss: 0.0084\n",
      "Epoch 199/1200, Iteration 5/12, Loss: 0.0075\n",
      "Epoch 199/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 199/1200, Iteration 7/12, Loss: 0.0104\n",
      "Epoch 199/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 199/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 199/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 199/1200, Iteration 11/12, Loss: 0.0089\n",
      "Epoch 199/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 199/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005476, MRE: 0.028866, MAE: 0.004912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004932, MRE: 0.026772, MAE: 0.005158 \n",
      "\n",
      "Epoch 200/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 200/1200, Iteration 2/12, Loss: 0.0095\n",
      "Epoch 200/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 200/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 200/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 200/1200, Iteration 6/12, Loss: 0.0120\n",
      "Epoch 200/1200, Iteration 7/12, Loss: 0.0094\n",
      "Epoch 200/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 200/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 200/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 200/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 200/1200, Iteration 12/12, Loss: 0.0101\n",
      "Epoch 200/1200, Iteration 13/12, Loss: 0.0074\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005651, MRE: 0.029766, MAE: 0.005086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.005568, MRE: 0.027500, MAE: 0.005306 \n",
      "\n",
      "Epoch 201/1200, Iteration 1/12, Loss: 0.0067\n",
      "Epoch 201/1200, Iteration 2/12, Loss: 0.0094\n",
      "Epoch 201/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 201/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 201/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 201/1200, Iteration 6/12, Loss: 0.0109\n",
      "Epoch 201/1200, Iteration 7/12, Loss: 0.0062\n",
      "Epoch 201/1200, Iteration 8/12, Loss: 0.0058\n",
      "Epoch 201/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 201/1200, Iteration 10/12, Loss: 0.0109\n",
      "Epoch 201/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 201/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 201/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.005520, MRE: 0.028983, MAE: 0.004988 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005029, MRE: 0.026866, MAE: 0.005201 \n",
      "\n",
      "Epoch 202/1200, Iteration 1/12, Loss: 0.0063\n",
      "Epoch 202/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 202/1200, Iteration 3/12, Loss: 0.0097\n",
      "Epoch 202/1200, Iteration 4/12, Loss: 0.0134\n",
      "Epoch 202/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 202/1200, Iteration 6/12, Loss: 0.0052\n",
      "Epoch 202/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 202/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 202/1200, Iteration 9/12, Loss: 0.0075\n",
      "Epoch 202/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 202/1200, Iteration 11/12, Loss: 0.0063\n",
      "Epoch 202/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 202/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.005499, MRE: 0.028738, MAE: 0.004975 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004699, MRE: 0.027060, MAE: 0.005187 \n",
      "\n",
      "Epoch 203/1200, Iteration 1/12, Loss: 0.0134\n",
      "Epoch 203/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 203/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 203/1200, Iteration 4/12, Loss: 0.0123\n",
      "Epoch 203/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 203/1200, Iteration 6/12, Loss: 0.0099\n",
      "Epoch 203/1200, Iteration 7/12, Loss: 0.0090\n",
      "Epoch 203/1200, Iteration 8/12, Loss: 0.0071\n",
      "Epoch 203/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 203/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 203/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 203/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 203/1200, Iteration 13/12, Loss: 0.0074\n",
      "Train Error: \n",
      " Accuracy: 94.25%, Avg loss: 0.005550, MRE: 0.029304, MAE: 0.004972 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004498, MRE: 0.026887, MAE: 0.005072 \n",
      "\n",
      "Epoch 204/1200, Iteration 1/12, Loss: 0.0069\n",
      "Epoch 204/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 204/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 204/1200, Iteration 4/12, Loss: 0.0100\n",
      "Epoch 204/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 204/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 204/1200, Iteration 7/12, Loss: 0.0103\n",
      "Epoch 204/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 204/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 204/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 204/1200, Iteration 11/12, Loss: 0.0058\n",
      "Epoch 204/1200, Iteration 12/12, Loss: 0.0082\n",
      "Epoch 204/1200, Iteration 13/12, Loss: 0.0129\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.005574, MRE: 0.029137, MAE: 0.004996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005211, MRE: 0.026900, MAE: 0.005190 \n",
      "\n",
      "Epoch 205/1200, Iteration 1/12, Loss: 0.0080\n",
      "Epoch 205/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 205/1200, Iteration 3/12, Loss: 0.0068\n",
      "Epoch 205/1200, Iteration 4/12, Loss: 0.0076\n",
      "Epoch 205/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 205/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 205/1200, Iteration 7/12, Loss: 0.0100\n",
      "Epoch 205/1200, Iteration 8/12, Loss: 0.0067\n",
      "Epoch 205/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 205/1200, Iteration 10/12, Loss: 0.0111\n",
      "Epoch 205/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 205/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 205/1200, Iteration 13/12, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005379, MRE: 0.028625, MAE: 0.004915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005055, MRE: 0.026583, MAE: 0.005122 \n",
      "\n",
      "Epoch 206/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 206/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 206/1200, Iteration 3/12, Loss: 0.0105\n",
      "Epoch 206/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 206/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 206/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 206/1200, Iteration 7/12, Loss: 0.0070\n",
      "Epoch 206/1200, Iteration 8/12, Loss: 0.0057\n",
      "Epoch 206/1200, Iteration 9/12, Loss: 0.0091\n",
      "Epoch 206/1200, Iteration 10/12, Loss: 0.0092\n",
      "Epoch 206/1200, Iteration 11/12, Loss: 0.0073\n",
      "Epoch 206/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 206/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 94.12%, Avg loss: 0.005537, MRE: 0.028872, MAE: 0.004912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004538, MRE: 0.026781, MAE: 0.005045 \n",
      "\n",
      "Epoch 207/1200, Iteration 1/12, Loss: 0.0102\n",
      "Epoch 207/1200, Iteration 2/12, Loss: 0.0158\n",
      "Epoch 207/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 207/1200, Iteration 4/12, Loss: 0.0076\n",
      "Epoch 207/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 207/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 207/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 207/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 207/1200, Iteration 9/12, Loss: 0.0069\n",
      "Epoch 207/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 207/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 207/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 207/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 95.12%, Avg loss: 0.005497, MRE: 0.029815, MAE: 0.004976 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004605, MRE: 0.026599, MAE: 0.005141 \n",
      "\n",
      "Epoch 208/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 208/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 208/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 208/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 208/1200, Iteration 5/12, Loss: 0.0083\n",
      "Epoch 208/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 208/1200, Iteration 7/12, Loss: 0.0121\n",
      "Epoch 208/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 208/1200, Iteration 9/12, Loss: 0.0147\n",
      "Epoch 208/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 208/1200, Iteration 11/12, Loss: 0.0053\n",
      "Epoch 208/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 208/1200, Iteration 13/12, Loss: 0.0053\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.005444, MRE: 0.028672, MAE: 0.004905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004614, MRE: 0.026413, MAE: 0.005071 \n",
      "\n",
      "Epoch 209/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 209/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 209/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 209/1200, Iteration 4/12, Loss: 0.0105\n",
      "Epoch 209/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 209/1200, Iteration 6/12, Loss: 0.0078\n",
      "Epoch 209/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 209/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 209/1200, Iteration 9/12, Loss: 0.0152\n",
      "Epoch 209/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 209/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 209/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 209/1200, Iteration 13/12, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.005296, MRE: 0.028380, MAE: 0.004896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004926, MRE: 0.026836, MAE: 0.005156 \n",
      "\n",
      "Epoch 210/1200, Iteration 1/12, Loss: 0.0130\n",
      "Epoch 210/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 210/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 210/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 210/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 210/1200, Iteration 6/12, Loss: 0.0114\n",
      "Epoch 210/1200, Iteration 7/12, Loss: 0.0065\n",
      "Epoch 210/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 210/1200, Iteration 9/12, Loss: 0.0079\n",
      "Epoch 210/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 210/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 210/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 210/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.005684, MRE: 0.029792, MAE: 0.004970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005044, MRE: 0.026640, MAE: 0.005113 \n",
      "\n",
      "Epoch 211/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 211/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 211/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 211/1200, Iteration 4/12, Loss: 0.0103\n",
      "Epoch 211/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 211/1200, Iteration 6/12, Loss: 0.0110\n",
      "Epoch 211/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 211/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 211/1200, Iteration 9/12, Loss: 0.0094\n",
      "Epoch 211/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 211/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 211/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 211/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.005276, MRE: 0.028762, MAE: 0.004816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004680, MRE: 0.026464, MAE: 0.005012 \n",
      "\n",
      "Epoch 212/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 212/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 212/1200, Iteration 3/12, Loss: 0.0103\n",
      "Epoch 212/1200, Iteration 4/12, Loss: 0.0067\n",
      "Epoch 212/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 212/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 212/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 212/1200, Iteration 8/12, Loss: 0.0089\n",
      "Epoch 212/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 212/1200, Iteration 10/12, Loss: 0.0112\n",
      "Epoch 212/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 212/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 212/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005214, MRE: 0.028235, MAE: 0.004806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004811, MRE: 0.026387, MAE: 0.005083 \n",
      "\n",
      "Epoch 213/1200, Iteration 1/12, Loss: 0.0136\n",
      "Epoch 213/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 213/1200, Iteration 3/12, Loss: 0.0071\n",
      "Epoch 213/1200, Iteration 4/12, Loss: 0.0067\n",
      "Epoch 213/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 213/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 213/1200, Iteration 7/12, Loss: 0.0051\n",
      "Epoch 213/1200, Iteration 8/12, Loss: 0.0098\n",
      "Epoch 213/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 213/1200, Iteration 10/12, Loss: 0.0077\n",
      "Epoch 213/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 213/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 213/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005211, MRE: 0.027908, MAE: 0.004817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004854, MRE: 0.026452, MAE: 0.005117 \n",
      "\n",
      "Epoch 214/1200, Iteration 1/12, Loss: 0.0076\n",
      "Epoch 214/1200, Iteration 2/12, Loss: 0.0084\n",
      "Epoch 214/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 214/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 214/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 214/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 214/1200, Iteration 7/12, Loss: 0.0098\n",
      "Epoch 214/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 214/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 214/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 214/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 214/1200, Iteration 12/12, Loss: 0.0102\n",
      "Epoch 214/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.005354, MRE: 0.028943, MAE: 0.004892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004848, MRE: 0.026186, MAE: 0.005090 \n",
      "\n",
      "Epoch 215/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 215/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 215/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 215/1200, Iteration 4/12, Loss: 0.0108\n",
      "Epoch 215/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 215/1200, Iteration 6/12, Loss: 0.0082\n",
      "Epoch 215/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 215/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 215/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 215/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 215/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 215/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 215/1200, Iteration 13/12, Loss: 0.0130\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.005725, MRE: 0.028659, MAE: 0.004943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.005093, MRE: 0.026395, MAE: 0.005098 \n",
      "\n",
      "Epoch 216/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 216/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 216/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 216/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 216/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 216/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 216/1200, Iteration 7/12, Loss: 0.0071\n",
      "Epoch 216/1200, Iteration 8/12, Loss: 0.0128\n",
      "Epoch 216/1200, Iteration 9/12, Loss: 0.0094\n",
      "Epoch 216/1200, Iteration 10/12, Loss: 0.0089\n",
      "Epoch 216/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 216/1200, Iteration 12/12, Loss: 0.0115\n",
      "Epoch 216/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.005612, MRE: 0.028391, MAE: 0.004880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004931, MRE: 0.026311, MAE: 0.005085 \n",
      "\n",
      "Epoch 217/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 217/1200, Iteration 2/12, Loss: 0.0093\n",
      "Epoch 217/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 217/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 217/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 217/1200, Iteration 6/12, Loss: 0.0141\n",
      "Epoch 217/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 217/1200, Iteration 8/12, Loss: 0.0118\n",
      "Epoch 217/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 217/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 217/1200, Iteration 11/12, Loss: 0.0069\n",
      "Epoch 217/1200, Iteration 12/12, Loss: 0.0075\n",
      "Epoch 217/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005303, MRE: 0.029486, MAE: 0.004883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004834, MRE: 0.026269, MAE: 0.005059 \n",
      "\n",
      "Epoch 218/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 218/1200, Iteration 2/12, Loss: 0.0076\n",
      "Epoch 218/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 218/1200, Iteration 4/12, Loss: 0.0083\n",
      "Epoch 218/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 218/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 218/1200, Iteration 7/12, Loss: 0.0111\n",
      "Epoch 218/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 218/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 218/1200, Iteration 10/12, Loss: 0.0107\n",
      "Epoch 218/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 218/1200, Iteration 12/12, Loss: 0.0075\n",
      "Epoch 218/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.005148, MRE: 0.028381, MAE: 0.004817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004978, MRE: 0.026600, MAE: 0.005168 \n",
      "\n",
      "Epoch 219/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 219/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 219/1200, Iteration 3/12, Loss: 0.0075\n",
      "Epoch 219/1200, Iteration 4/12, Loss: 0.0069\n",
      "Epoch 219/1200, Iteration 5/12, Loss: 0.0075\n",
      "Epoch 219/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 219/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 219/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 219/1200, Iteration 9/12, Loss: 0.0090\n",
      "Epoch 219/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 219/1200, Iteration 11/12, Loss: 0.0124\n",
      "Epoch 219/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 219/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005113, MRE: 0.027782, MAE: 0.004770 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004862, MRE: 0.026431, MAE: 0.005075 \n",
      "\n",
      "Epoch 220/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 220/1200, Iteration 2/12, Loss: 0.0111\n",
      "Epoch 220/1200, Iteration 3/12, Loss: 0.0179\n",
      "Epoch 220/1200, Iteration 4/12, Loss: 0.0072\n",
      "Epoch 220/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 220/1200, Iteration 6/12, Loss: 0.0100\n",
      "Epoch 220/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 220/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 220/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 220/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 220/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 220/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 220/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.005137, MRE: 0.028409, MAE: 0.004767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004644, MRE: 0.025940, MAE: 0.004996 \n",
      "\n",
      "Epoch 221/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 221/1200, Iteration 2/12, Loss: 0.0077\n",
      "Epoch 221/1200, Iteration 3/12, Loss: 0.0054\n",
      "Epoch 221/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 221/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 221/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 221/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 221/1200, Iteration 8/12, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 221/1200, Iteration 10/12, Loss: 0.0100\n",
      "Epoch 221/1200, Iteration 11/12, Loss: 0.0077\n",
      "Epoch 221/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 221/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.005228, MRE: 0.027891, MAE: 0.004802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004693, MRE: 0.025949, MAE: 0.004978 \n",
      "\n",
      "Epoch 222/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 222/1200, Iteration 2/12, Loss: 0.0057\n",
      "Epoch 222/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 222/1200, Iteration 4/12, Loss: 0.0107\n",
      "Epoch 222/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 222/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 222/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 222/1200, Iteration 8/12, Loss: 0.0073\n",
      "Epoch 222/1200, Iteration 9/12, Loss: 0.0092\n",
      "Epoch 222/1200, Iteration 10/12, Loss: 0.0100\n",
      "Epoch 222/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 222/1200, Iteration 12/12, Loss: 0.0061\n",
      "Epoch 222/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.005348, MRE: 0.028164, MAE: 0.004857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.005053, MRE: 0.026295, MAE: 0.005085 \n",
      "\n",
      "Epoch 223/1200, Iteration 1/12, Loss: 0.0076\n",
      "Epoch 223/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 223/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 223/1200, Iteration 4/12, Loss: 0.0093\n",
      "Epoch 223/1200, Iteration 5/12, Loss: 0.0084\n",
      "Epoch 223/1200, Iteration 6/12, Loss: 0.0071\n",
      "Epoch 223/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 223/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 223/1200, Iteration 9/12, Loss: 0.0059\n",
      "Epoch 223/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 223/1200, Iteration 11/12, Loss: 0.0097\n",
      "Epoch 223/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 223/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.005105, MRE: 0.028118, MAE: 0.004733 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004700, MRE: 0.025825, MAE: 0.004970 \n",
      "\n",
      "Epoch 224/1200, Iteration 1/12, Loss: 0.0079\n",
      "Epoch 224/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 224/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 224/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 224/1200, Iteration 5/12, Loss: 0.0072\n",
      "Epoch 224/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 224/1200, Iteration 7/12, Loss: 0.0176\n",
      "Epoch 224/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 224/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 224/1200, Iteration 10/12, Loss: 0.0074\n",
      "Epoch 224/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 224/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 224/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 94.75%, Avg loss: 0.005199, MRE: 0.027681, MAE: 0.004776 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004544, MRE: 0.026348, MAE: 0.004966 \n",
      "\n",
      "Epoch 225/1200, Iteration 1/12, Loss: 0.0109\n",
      "Epoch 225/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 225/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 225/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 225/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 225/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 225/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 225/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 225/1200, Iteration 9/12, Loss: 0.0090\n",
      "Epoch 225/1200, Iteration 10/12, Loss: 0.0103\n",
      "Epoch 225/1200, Iteration 11/12, Loss: 0.0073\n",
      "Epoch 225/1200, Iteration 12/12, Loss: 0.0070\n",
      "Epoch 225/1200, Iteration 13/12, Loss: 0.0062\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.005335, MRE: 0.027844, MAE: 0.004793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004514, MRE: 0.025812, MAE: 0.004913 \n",
      "\n",
      "Epoch 226/1200, Iteration 1/12, Loss: 0.0142\n",
      "Epoch 226/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 226/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 226/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 226/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 226/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 226/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 226/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 226/1200, Iteration 9/12, Loss: 0.0120\n",
      "Epoch 226/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 226/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 226/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 226/1200, Iteration 13/12, Loss: 0.0070\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005289, MRE: 0.028867, MAE: 0.004845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004658, MRE: 0.025740, MAE: 0.004973 \n",
      "\n",
      "Epoch 227/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 227/1200, Iteration 2/12, Loss: 0.0118\n",
      "Epoch 227/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 227/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 227/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 227/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 227/1200, Iteration 7/12, Loss: 0.0051\n",
      "Epoch 227/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 227/1200, Iteration 9/12, Loss: 0.0095\n",
      "Epoch 227/1200, Iteration 10/12, Loss: 0.0074\n",
      "Epoch 227/1200, Iteration 11/12, Loss: 0.0086\n",
      "Epoch 227/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 227/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 95.25%, Avg loss: 0.005028, MRE: 0.027530, MAE: 0.004709 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004370, MRE: 0.025818, MAE: 0.004897 \n",
      "\n",
      "Epoch 228/1200, Iteration 1/12, Loss: 0.0087\n",
      "Epoch 228/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 228/1200, Iteration 3/12, Loss: 0.0058\n",
      "Epoch 228/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 228/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 228/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 228/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 228/1200, Iteration 8/12, Loss: 0.0078\n",
      "Epoch 228/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 228/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 228/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 228/1200, Iteration 12/12, Loss: 0.0087\n",
      "Epoch 228/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004974, MRE: 0.027402, MAE: 0.004671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004353, MRE: 0.025687, MAE: 0.004879 \n",
      "\n",
      "Epoch 229/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 229/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 229/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 229/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 229/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 229/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 229/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 229/1200, Iteration 8/12, Loss: 0.0093\n",
      "Epoch 229/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 229/1200, Iteration 10/12, Loss: 0.0074\n",
      "Epoch 229/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 229/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 229/1200, Iteration 13/12, Loss: 0.0119\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.004956, MRE: 0.027336, MAE: 0.004688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004369, MRE: 0.025746, MAE: 0.004927 \n",
      "\n",
      "Epoch 230/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 230/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 230/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 230/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 230/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 230/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 230/1200, Iteration 7/12, Loss: 0.0055\n",
      "Epoch 230/1200, Iteration 8/12, Loss: 0.0095\n",
      "Epoch 230/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 230/1200, Iteration 10/12, Loss: 0.0071\n",
      "Epoch 230/1200, Iteration 11/12, Loss: 0.0125\n",
      "Epoch 230/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 230/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.005199, MRE: 0.028186, MAE: 0.004781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004508, MRE: 0.025411, MAE: 0.004885 \n",
      "\n",
      "Epoch 231/1200, Iteration 1/12, Loss: 0.0107\n",
      "Epoch 231/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 231/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 231/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 231/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 231/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 231/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 231/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 231/1200, Iteration 9/12, Loss: 0.0134\n",
      "Epoch 231/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 231/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 231/1200, Iteration 12/12, Loss: 0.0067\n",
      "Epoch 231/1200, Iteration 13/12, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004944, MRE: 0.027302, MAE: 0.004673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004519, MRE: 0.025498, MAE: 0.004897 \n",
      "\n",
      "Epoch 232/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 232/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 232/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 232/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 232/1200, Iteration 5/12, Loss: 0.0070\n",
      "Epoch 232/1200, Iteration 6/12, Loss: 0.0098\n",
      "Epoch 232/1200, Iteration 7/12, Loss: 0.0066\n",
      "Epoch 232/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 232/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 232/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 232/1200, Iteration 11/12, Loss: 0.0060\n",
      "Epoch 232/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 232/1200, Iteration 13/12, Loss: 0.0136\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.005096, MRE: 0.028245, MAE: 0.004821 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.005039, MRE: 0.025789, MAE: 0.005050 \n",
      "\n",
      "Epoch 233/1200, Iteration 1/12, Loss: 0.0101\n",
      "Epoch 233/1200, Iteration 2/12, Loss: 0.0119\n",
      "Epoch 233/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 233/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 233/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 233/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 233/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 233/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 233/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 233/1200, Iteration 10/12, Loss: 0.0079\n",
      "Epoch 233/1200, Iteration 11/12, Loss: 0.0103\n",
      "Epoch 233/1200, Iteration 12/12, Loss: 0.0071\n",
      "Epoch 233/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.005030, MRE: 0.027911, MAE: 0.004715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004745, MRE: 0.025705, MAE: 0.004979 \n",
      "\n",
      "Epoch 234/1200, Iteration 1/12, Loss: 0.0092\n",
      "Epoch 234/1200, Iteration 2/12, Loss: 0.0059\n",
      "Epoch 234/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 234/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 234/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 234/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 234/1200, Iteration 7/12, Loss: 0.0089\n",
      "Epoch 234/1200, Iteration 8/12, Loss: 0.0058\n",
      "Epoch 234/1200, Iteration 9/12, Loss: 0.0087\n",
      "Epoch 234/1200, Iteration 10/12, Loss: 0.0061\n",
      "Epoch 234/1200, Iteration 11/12, Loss: 0.0090\n",
      "Epoch 234/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 234/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004935, MRE: 0.027160, MAE: 0.004655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004528, MRE: 0.025714, MAE: 0.004878 \n",
      "\n",
      "Epoch 235/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 235/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 235/1200, Iteration 3/12, Loss: 0.0093\n",
      "Epoch 235/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 235/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 235/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 235/1200, Iteration 7/12, Loss: 0.0091\n",
      "Epoch 235/1200, Iteration 8/12, Loss: 0.0086\n",
      "Epoch 235/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 235/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 235/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 235/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 235/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.004836, MRE: 0.027304, MAE: 0.004651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004582, MRE: 0.025557, MAE: 0.004931 \n",
      "\n",
      "Epoch 236/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 236/1200, Iteration 2/12, Loss: 0.0082\n",
      "Epoch 236/1200, Iteration 3/12, Loss: 0.0155\n",
      "Epoch 236/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 236/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 236/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 236/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 236/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 236/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 236/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 236/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 236/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 236/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004853, MRE: 0.027679, MAE: 0.004654 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004546, MRE: 0.025620, MAE: 0.004934 \n",
      "\n",
      "Epoch 237/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 237/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 237/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 237/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 237/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 237/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 237/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 237/1200, Iteration 8/12, Loss: 0.0105\n",
      "Epoch 237/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 237/1200, Iteration 10/12, Loss: 0.0085\n",
      "Epoch 237/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 237/1200, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 237/1200, Iteration 13/12, Loss: 0.0061\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.005001, MRE: 0.027264, MAE: 0.004680 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004394, MRE: 0.025818, MAE: 0.004961 \n",
      "\n",
      "Epoch 238/1200, Iteration 1/12, Loss: 0.0062\n",
      "Epoch 238/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 238/1200, Iteration 3/12, Loss: 0.0060\n",
      "Epoch 238/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 238/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 238/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 238/1200, Iteration 7/12, Loss: 0.0100\n",
      "Epoch 238/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 238/1200, Iteration 9/12, Loss: 0.0123\n",
      "Epoch 238/1200, Iteration 10/12, Loss: 0.0102\n",
      "Epoch 238/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 238/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 238/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.005457, MRE: 0.028858, MAE: 0.004801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004431, MRE: 0.025978, MAE: 0.004971 \n",
      "\n",
      "Epoch 239/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 239/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 239/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 239/1200, Iteration 4/12, Loss: 0.0056\n",
      "Epoch 239/1200, Iteration 5/12, Loss: 0.0114\n",
      "Epoch 239/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 239/1200, Iteration 7/12, Loss: 0.0127\n",
      "Epoch 239/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 239/1200, Iteration 9/12, Loss: 0.0062\n",
      "Epoch 239/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 239/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 239/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 239/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.005017, MRE: 0.027046, MAE: 0.004655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004505, MRE: 0.025436, MAE: 0.004941 \n",
      "\n",
      "Epoch 240/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 240/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 240/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 240/1200, Iteration 4/12, Loss: 0.0086\n",
      "Epoch 240/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 240/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 240/1200, Iteration 7/12, Loss: 0.0088\n",
      "Epoch 240/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 240/1200, Iteration 9/12, Loss: 0.0059\n",
      "Epoch 240/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 240/1200, Iteration 11/12, Loss: 0.0053\n",
      "Epoch 240/1200, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 240/1200, Iteration 13/12, Loss: 0.0162\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004881, MRE: 0.028247, MAE: 0.004722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004839, MRE: 0.025499, MAE: 0.004995 \n",
      "\n",
      "Epoch 241/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 241/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 241/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 241/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 241/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 241/1200, Iteration 6/12, Loss: 0.0071\n",
      "Epoch 241/1200, Iteration 7/12, Loss: 0.0088\n",
      "Epoch 241/1200, Iteration 8/12, Loss: 0.0050\n",
      "Epoch 241/1200, Iteration 9/12, Loss: 0.0072\n",
      "Epoch 241/1200, Iteration 10/12, Loss: 0.0101\n",
      "Epoch 241/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 241/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 241/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.004809, MRE: 0.026859, MAE: 0.004664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004633, MRE: 0.025800, MAE: 0.005000 \n",
      "\n",
      "Epoch 242/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 242/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 242/1200, Iteration 3/12, Loss: 0.0098\n",
      "Epoch 242/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 242/1200, Iteration 5/12, Loss: 0.0070\n",
      "Epoch 242/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 242/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 242/1200, Iteration 8/12, Loss: 0.0123\n",
      "Epoch 242/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 242/1200, Iteration 10/12, Loss: 0.0062\n",
      "Epoch 242/1200, Iteration 11/12, Loss: 0.0097\n",
      "Epoch 242/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 242/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.005147, MRE: 0.026970, MAE: 0.004644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004581, MRE: 0.025525, MAE: 0.004913 \n",
      "\n",
      "Epoch 243/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 243/1200, Iteration 2/12, Loss: 0.0057\n",
      "Epoch 243/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 243/1200, Iteration 4/12, Loss: 0.0078\n",
      "Epoch 243/1200, Iteration 5/12, Loss: 0.0076\n",
      "Epoch 243/1200, Iteration 6/12, Loss: 0.0065\n",
      "Epoch 243/1200, Iteration 7/12, Loss: 0.0075\n",
      "Epoch 243/1200, Iteration 8/12, Loss: 0.0102\n",
      "Epoch 243/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 243/1200, Iteration 10/12, Loss: 0.0066\n",
      "Epoch 243/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 243/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 243/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004767, MRE: 0.026770, MAE: 0.004598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004427, MRE: 0.025332, MAE: 0.004844 \n",
      "\n",
      "Epoch 244/1200, Iteration 1/12, Loss: 0.0088\n",
      "Epoch 244/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 244/1200, Iteration 3/12, Loss: 0.0071\n",
      "Epoch 244/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 244/1200, Iteration 5/12, Loss: 0.0065\n",
      "Epoch 244/1200, Iteration 6/12, Loss: 0.0138\n",
      "Epoch 244/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 244/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 244/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 244/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 244/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 244/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 244/1200, Iteration 13/12, Loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.004846, MRE: 0.027068, MAE: 0.004613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004249, MRE: 0.025598, MAE: 0.004853 \n",
      "\n",
      "Epoch 245/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 245/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 245/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 245/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 245/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 245/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 245/1200, Iteration 7/12, Loss: 0.0085\n",
      "Epoch 245/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 245/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 245/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 245/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 245/1200, Iteration 12/12, Loss: 0.0122\n",
      "Epoch 245/1200, Iteration 13/12, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004790, MRE: 0.027389, MAE: 0.004692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004864, MRE: 0.025462, MAE: 0.004957 \n",
      "\n",
      "Epoch 246/1200, Iteration 1/12, Loss: 0.0090\n",
      "Epoch 246/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 246/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 246/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 246/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 246/1200, Iteration 6/12, Loss: 0.0074\n",
      "Epoch 246/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 246/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 246/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 246/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 246/1200, Iteration 11/12, Loss: 0.0057\n",
      "Epoch 246/1200, Iteration 12/12, Loss: 0.0080\n",
      "Epoch 246/1200, Iteration 13/12, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004848, MRE: 0.027469, MAE: 0.004694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004989, MRE: 0.025561, MAE: 0.005007 \n",
      "\n",
      "Epoch 247/1200, Iteration 1/12, Loss: 0.0076\n",
      "Epoch 247/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 247/1200, Iteration 3/12, Loss: 0.0073\n",
      "Epoch 247/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 247/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 247/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 247/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 247/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 247/1200, Iteration 9/12, Loss: 0.0060\n",
      "Epoch 247/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 247/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 247/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 247/1200, Iteration 13/12, Loss: 0.0117\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004862, MRE: 0.027175, MAE: 0.004612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004563, MRE: 0.025216, MAE: 0.004900 \n",
      "\n",
      "Epoch 248/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 248/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 248/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 248/1200, Iteration 4/12, Loss: 0.0145\n",
      "Epoch 248/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 248/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 248/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 248/1200, Iteration 8/12, Loss: 0.0091\n",
      "Epoch 248/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 248/1200, Iteration 10/12, Loss: 0.0058\n",
      "Epoch 248/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 248/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 248/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004783, MRE: 0.030589, MAE: 0.004618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004559, MRE: 0.025329, MAE: 0.004908 \n",
      "\n",
      "Epoch 249/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 249/1200, Iteration 2/12, Loss: 0.0077\n",
      "Epoch 249/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 249/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 249/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 249/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 249/1200, Iteration 7/12, Loss: 0.0098\n",
      "Epoch 249/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 249/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 249/1200, Iteration 10/12, Loss: 0.0084\n",
      "Epoch 249/1200, Iteration 11/12, Loss: 0.0107\n",
      "Epoch 249/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 249/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004635, MRE: 0.026661, MAE: 0.004522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004449, MRE: 0.025284, MAE: 0.004876 \n",
      "\n",
      "Epoch 250/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 250/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 250/1200, Iteration 3/12, Loss: 0.0102\n",
      "Epoch 250/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 250/1200, Iteration 5/12, Loss: 0.0081\n",
      "Epoch 250/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 250/1200, Iteration 7/12, Loss: 0.0081\n",
      "Epoch 250/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 250/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 250/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 250/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 250/1200, Iteration 12/12, Loss: 0.0078\n",
      "Epoch 250/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004649, MRE: 0.026794, MAE: 0.004547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004461, MRE: 0.025366, MAE: 0.004904 \n",
      "\n",
      "Epoch 251/1200, Iteration 1/12, Loss: 0.0089\n",
      "Epoch 251/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 251/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 251/1200, Iteration 4/12, Loss: 0.0076\n",
      "Epoch 251/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 251/1200, Iteration 6/12, Loss: 0.0101\n",
      "Epoch 251/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 251/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 251/1200, Iteration 9/12, Loss: 0.0066\n",
      "Epoch 251/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 251/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 251/1200, Iteration 12/12, Loss: 0.0078\n",
      "Epoch 251/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004856, MRE: 0.027170, MAE: 0.004606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004133, MRE: 0.024927, MAE: 0.004820 \n",
      "\n",
      "Epoch 252/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 252/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 252/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 252/1200, Iteration 4/12, Loss: 0.0120\n",
      "Epoch 252/1200, Iteration 5/12, Loss: 0.0082\n",
      "Epoch 252/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 252/1200, Iteration 7/12, Loss: 0.0082\n",
      "Epoch 252/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 252/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 252/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 252/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 252/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 252/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004672, MRE: 0.026691, MAE: 0.004528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004162, MRE: 0.024737, MAE: 0.004770 \n",
      "\n",
      "Epoch 253/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 253/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 253/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 253/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 253/1200, Iteration 5/12, Loss: 0.0086\n",
      "Epoch 253/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 253/1200, Iteration 7/12, Loss: 0.0144\n",
      "Epoch 253/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 253/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 253/1200, Iteration 10/12, Loss: 0.0073\n",
      "Epoch 253/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 253/1200, Iteration 12/12, Loss: 0.0085\n",
      "Epoch 253/1200, Iteration 13/12, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.004628, MRE: 0.030860, MAE: 0.004551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004462, MRE: 0.024879, MAE: 0.004886 \n",
      "\n",
      "Epoch 254/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 254/1200, Iteration 2/12, Loss: 0.0065\n",
      "Epoch 254/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 254/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 254/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 254/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 254/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 254/1200, Iteration 8/12, Loss: 0.0098\n",
      "Epoch 254/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 254/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 254/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 254/1200, Iteration 12/12, Loss: 0.0091\n",
      "Epoch 254/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004651, MRE: 0.026911, MAE: 0.004510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004130, MRE: 0.024869, MAE: 0.004778 \n",
      "\n",
      "Epoch 255/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 255/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 255/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 255/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 255/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 255/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 255/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 255/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 255/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 255/1200, Iteration 10/12, Loss: 0.0084\n",
      "Epoch 255/1200, Iteration 11/12, Loss: 0.0075\n",
      "Epoch 255/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 255/1200, Iteration 13/12, Loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004581, MRE: 0.026804, MAE: 0.004509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004330, MRE: 0.024710, MAE: 0.004815 \n",
      "\n",
      "Epoch 256/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 256/1200, Iteration 2/12, Loss: 0.0083\n",
      "Epoch 256/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 256/1200, Iteration 4/12, Loss: 0.0075\n",
      "Epoch 256/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 256/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 256/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 256/1200, Iteration 8/12, Loss: 0.0101\n",
      "Epoch 256/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 256/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 256/1200, Iteration 11/12, Loss: 0.0054\n",
      "Epoch 256/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 256/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004545, MRE: 0.026806, MAE: 0.004496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004303, MRE: 0.024657, MAE: 0.004801 \n",
      "\n",
      "Epoch 257/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 257/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 257/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 257/1200, Iteration 4/12, Loss: 0.0079\n",
      "Epoch 257/1200, Iteration 5/12, Loss: 0.0109\n",
      "Epoch 257/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 257/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 257/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 257/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 257/1200, Iteration 10/12, Loss: 0.0080\n",
      "Epoch 257/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 257/1200, Iteration 12/12, Loss: 0.0075\n",
      "Epoch 257/1200, Iteration 13/12, Loss: 0.0065\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004649, MRE: 0.027148, MAE: 0.004629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004804, MRE: 0.024975, MAE: 0.004918 \n",
      "\n",
      "Epoch 258/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 258/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 258/1200, Iteration 3/12, Loss: 0.0054\n",
      "Epoch 258/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 258/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 258/1200, Iteration 6/12, Loss: 0.0069\n",
      "Epoch 258/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 258/1200, Iteration 8/12, Loss: 0.0094\n",
      "Epoch 258/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 258/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 258/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 258/1200, Iteration 12/12, Loss: 0.0103\n",
      "Epoch 258/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004667, MRE: 0.027126, MAE: 0.004577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004721, MRE: 0.024794, MAE: 0.004903 \n",
      "\n",
      "Epoch 259/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 259/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 259/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 259/1200, Iteration 4/12, Loss: 0.0091\n",
      "Epoch 259/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 259/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 259/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 259/1200, Iteration 8/12, Loss: 0.0061\n",
      "Epoch 259/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 259/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 259/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 259/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 259/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.004570, MRE: 0.026592, MAE: 0.004539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004208, MRE: 0.025005, MAE: 0.004825 \n",
      "\n",
      "Epoch 260/1200, Iteration 1/12, Loss: 0.0079\n",
      "Epoch 260/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 260/1200, Iteration 3/12, Loss: 0.0097\n",
      "Epoch 260/1200, Iteration 4/12, Loss: 0.0088\n",
      "Epoch 260/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 260/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 260/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 260/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 260/1200, Iteration 9/12, Loss: 0.0087\n",
      "Epoch 260/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 260/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 260/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 260/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.004576, MRE: 0.026384, MAE: 0.004485 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004192, MRE: 0.024672, MAE: 0.004752 \n",
      "\n",
      "Epoch 261/1200, Iteration 1/12, Loss: 0.0111\n",
      "Epoch 261/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 261/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 261/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 261/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 261/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 261/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 261/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 261/1200, Iteration 9/12, Loss: 0.0096\n",
      "Epoch 261/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 261/1200, Iteration 11/12, Loss: 0.0083\n",
      "Epoch 261/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 261/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 95.62%, Avg loss: 0.004537, MRE: 0.026261, MAE: 0.004488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004123, MRE: 0.024416, MAE: 0.004735 \n",
      "\n",
      "Epoch 262/1200, Iteration 1/12, Loss: 0.0088\n",
      "Epoch 262/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 262/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 262/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 262/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 262/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 262/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 262/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 262/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 262/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 262/1200, Iteration 11/12, Loss: 0.0094\n",
      "Epoch 262/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 262/1200, Iteration 13/12, Loss: 0.0092\n",
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004566, MRE: 0.026562, MAE: 0.004495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004269, MRE: 0.024669, MAE: 0.004811 \n",
      "\n",
      "Epoch 263/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 263/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 263/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 263/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 263/1200, Iteration 5/12, Loss: 0.0092\n",
      "Epoch 263/1200, Iteration 6/12, Loss: 0.0143\n",
      "Epoch 263/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 263/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 263/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 263/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 263/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 263/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 263/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004642, MRE: 0.026760, MAE: 0.004521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004314, MRE: 0.024302, MAE: 0.004819 \n",
      "\n",
      "Epoch 264/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 264/1200, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 264/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 264/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 264/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 264/1200, Iteration 6/12, Loss: 0.0115\n",
      "Epoch 264/1200, Iteration 7/12, Loss: 0.0086\n",
      "Epoch 264/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 264/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 264/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 264/1200, Iteration 11/12, Loss: 0.0070\n",
      "Epoch 264/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 264/1200, Iteration 13/12, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.004677, MRE: 0.027079, MAE: 0.004633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004929, MRE: 0.024802, MAE: 0.004969 \n",
      "\n",
      "Epoch 265/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 265/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 265/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 265/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 265/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 265/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 265/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 265/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 265/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 265/1200, Iteration 10/12, Loss: 0.0089\n",
      "Epoch 265/1200, Iteration 11/12, Loss: 0.0060\n",
      "Epoch 265/1200, Iteration 12/12, Loss: 0.0066\n",
      "Epoch 265/1200, Iteration 13/12, Loss: 0.0119\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004736, MRE: 0.027279, MAE: 0.004665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.005024, MRE: 0.024937, MAE: 0.004961 \n",
      "\n",
      "Epoch 266/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 266/1200, Iteration 2/12, Loss: 0.0119\n",
      "Epoch 266/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 266/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 266/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 266/1200, Iteration 6/12, Loss: 0.0105\n",
      "Epoch 266/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 266/1200, Iteration 8/12, Loss: 0.0074\n",
      "Epoch 266/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 266/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 266/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 266/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 266/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 95.75%, Avg loss: 0.004601, MRE: 0.026357, MAE: 0.004500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.004205, MRE: 0.024661, MAE: 0.004799 \n",
      "\n",
      "Epoch 267/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 267/1200, Iteration 2/12, Loss: 0.0119\n",
      "Epoch 267/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 267/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 267/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 267/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 267/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 267/1200, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 267/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 267/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 267/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 267/1200, Iteration 12/12, Loss: 0.0082\n",
      "Epoch 267/1200, Iteration 13/12, Loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004516, MRE: 0.027104, MAE: 0.004478 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004233, MRE: 0.024173, MAE: 0.004747 \n",
      "\n",
      "Epoch 268/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 268/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 268/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 268/1200, Iteration 4/12, Loss: 0.0052\n",
      "Epoch 268/1200, Iteration 5/12, Loss: 0.0084\n",
      "Epoch 268/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 268/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 268/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 268/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 268/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 268/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 268/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 268/1200, Iteration 13/12, Loss: 0.0130\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004456, MRE: 0.026436, MAE: 0.004510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004401, MRE: 0.024500, MAE: 0.004740 \n",
      "\n",
      "Epoch 269/1200, Iteration 1/12, Loss: 0.0083\n",
      "Epoch 269/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 269/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 269/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 269/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 269/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 269/1200, Iteration 7/12, Loss: 0.0050\n",
      "Epoch 269/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 269/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 269/1200, Iteration 10/12, Loss: 0.0119\n",
      "Epoch 269/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 269/1200, Iteration 12/12, Loss: 0.0103\n",
      "Epoch 269/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004987, MRE: 0.026990, MAE: 0.004573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004455, MRE: 0.024219, MAE: 0.004815 \n",
      "\n",
      "Epoch 270/1200, Iteration 1/12, Loss: 0.0068\n",
      "Epoch 270/1200, Iteration 2/12, Loss: 0.0073\n",
      "Epoch 270/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 270/1200, Iteration 4/12, Loss: 0.0078\n",
      "Epoch 270/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 270/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 270/1200, Iteration 7/12, Loss: 0.0082\n",
      "Epoch 270/1200, Iteration 8/12, Loss: 0.0063\n",
      "Epoch 270/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 270/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 270/1200, Iteration 11/12, Loss: 0.0082\n",
      "Epoch 270/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 270/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004647, MRE: 0.029508, MAE: 0.004496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004255, MRE: 0.024369, MAE: 0.004774 \n",
      "\n",
      "Epoch 271/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 271/1200, Iteration 2/12, Loss: 0.0097\n",
      "Epoch 271/1200, Iteration 3/12, Loss: 0.0086\n",
      "Epoch 271/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 271/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 271/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 271/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 271/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 271/1200, Iteration 9/12, Loss: 0.0085\n",
      "Epoch 271/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 271/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 271/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 271/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004480, MRE: 0.027149, MAE: 0.004486 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004302, MRE: 0.024234, MAE: 0.004749 \n",
      "\n",
      "Epoch 272/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 272/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 272/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 272/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 272/1200, Iteration 5/12, Loss: 0.0144\n",
      "Epoch 272/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 272/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 272/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 272/1200, Iteration 9/12, Loss: 0.0069\n",
      "Epoch 272/1200, Iteration 10/12, Loss: 0.0081\n",
      "Epoch 272/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 272/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 272/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004451, MRE: 0.025945, MAE: 0.004451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004371, MRE: 0.024173, MAE: 0.004768 \n",
      "\n",
      "Epoch 273/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 273/1200, Iteration 2/12, Loss: 0.0078\n",
      "Epoch 273/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 273/1200, Iteration 4/12, Loss: 0.0119\n",
      "Epoch 273/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 273/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 273/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 273/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 273/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 273/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 273/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 273/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 273/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004389, MRE: 0.026070, MAE: 0.004423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004116, MRE: 0.024057, MAE: 0.004760 \n",
      "\n",
      "Epoch 274/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 274/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 274/1200, Iteration 3/12, Loss: 0.0052\n",
      "Epoch 274/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 274/1200, Iteration 5/12, Loss: 0.0120\n",
      "Epoch 274/1200, Iteration 6/12, Loss: 0.0128\n",
      "Epoch 274/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 274/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 274/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 274/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 274/1200, Iteration 11/12, Loss: 0.0058\n",
      "Epoch 274/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 274/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004379, MRE: 0.025832, MAE: 0.004445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004193, MRE: 0.024417, MAE: 0.004749 \n",
      "\n",
      "Epoch 275/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 275/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 275/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 275/1200, Iteration 4/12, Loss: 0.0052\n",
      "Epoch 275/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 275/1200, Iteration 6/12, Loss: 0.0104\n",
      "Epoch 275/1200, Iteration 7/12, Loss: 0.0068\n",
      "Epoch 275/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 275/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 275/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 275/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 275/1200, Iteration 12/12, Loss: 0.0082\n",
      "Epoch 275/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004370, MRE: 0.026875, MAE: 0.004462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004315, MRE: 0.024028, MAE: 0.004747 \n",
      "\n",
      "Epoch 276/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 276/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 276/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 276/1200, Iteration 4/12, Loss: 0.0093\n",
      "Epoch 276/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 276/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 276/1200, Iteration 7/12, Loss: 0.0081\n",
      "Epoch 276/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 276/1200, Iteration 9/12, Loss: 0.0097\n",
      "Epoch 276/1200, Iteration 10/12, Loss: 0.0066\n",
      "Epoch 276/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 276/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 276/1200, Iteration 13/12, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004382, MRE: 0.026062, MAE: 0.004456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004403, MRE: 0.024420, MAE: 0.004849 \n",
      "\n",
      "Epoch 277/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 277/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 277/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 277/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 277/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 277/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 277/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 277/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 277/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 277/1200, Iteration 10/12, Loss: 0.0098\n",
      "Epoch 277/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 277/1200, Iteration 12/12, Loss: 0.0078\n",
      "Epoch 277/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004275, MRE: 0.025739, MAE: 0.004369 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004308, MRE: 0.024263, MAE: 0.004777 \n",
      "\n",
      "Epoch 278/1200, Iteration 1/12, Loss: 0.0096\n",
      "Epoch 278/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 278/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 278/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 278/1200, Iteration 5/12, Loss: 0.0131\n",
      "Epoch 278/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 278/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 278/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 278/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 278/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 278/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 278/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 278/1200, Iteration 13/12, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 95.88%, Avg loss: 0.004281, MRE: 0.025881, MAE: 0.004386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003971, MRE: 0.024236, MAE: 0.004791 \n",
      "\n",
      "Epoch 279/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 279/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 279/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 279/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 279/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 279/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 279/1200, Iteration 7/12, Loss: 0.0062\n",
      "Epoch 279/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 279/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 279/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 279/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 279/1200, Iteration 12/12, Loss: 0.0135\n",
      "Epoch 279/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004411, MRE: 0.027021, MAE: 0.004490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004487, MRE: 0.024386, MAE: 0.004821 \n",
      "\n",
      "Epoch 280/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 280/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 280/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 280/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 280/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 280/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 280/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 280/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 280/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 280/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 280/1200, Iteration 11/12, Loss: 0.0072\n",
      "Epoch 280/1200, Iteration 12/12, Loss: 0.0070\n",
      "Epoch 280/1200, Iteration 13/12, Loss: 0.0153\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004296, MRE: 0.026222, MAE: 0.004395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004283, MRE: 0.024142, MAE: 0.004776 \n",
      "\n",
      "Epoch 281/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 281/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 281/1200, Iteration 3/12, Loss: 0.0089\n",
      "Epoch 281/1200, Iteration 4/12, Loss: 0.0082\n",
      "Epoch 281/1200, Iteration 5/12, Loss: 0.0055\n",
      "Epoch 281/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 281/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 281/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 281/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 281/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 281/1200, Iteration 11/12, Loss: 0.0082\n",
      "Epoch 281/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 281/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004636, MRE: 0.026594, MAE: 0.004419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004027, MRE: 0.023950, MAE: 0.004730 \n",
      "\n",
      "Epoch 282/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 282/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 282/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 282/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 282/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 282/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 282/1200, Iteration 7/12, Loss: 0.0070\n",
      "Epoch 282/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 282/1200, Iteration 9/12, Loss: 0.0093\n",
      "Epoch 282/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 282/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 282/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 282/1200, Iteration 13/12, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.004634, MRE: 0.026147, MAE: 0.004420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.003837, MRE: 0.024174, MAE: 0.004722 \n",
      "\n",
      "Epoch 283/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 283/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 283/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 283/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 283/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 283/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 283/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 283/1200, Iteration 8/12, Loss: 0.0113\n",
      "Epoch 283/1200, Iteration 9/12, Loss: 0.0107\n",
      "Epoch 283/1200, Iteration 10/12, Loss: 0.0057\n",
      "Epoch 283/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 283/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 283/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004357, MRE: 0.026868, MAE: 0.004459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004239, MRE: 0.023802, MAE: 0.004683 \n",
      "\n",
      "Epoch 284/1200, Iteration 1/12, Loss: 0.0074\n",
      "Epoch 284/1200, Iteration 2/12, Loss: 0.0066\n",
      "Epoch 284/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 284/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 284/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 284/1200, Iteration 6/12, Loss: 0.0118\n",
      "Epoch 284/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 284/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 284/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 284/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 284/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 284/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 284/1200, Iteration 13/12, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004288, MRE: 0.025763, MAE: 0.004399 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004355, MRE: 0.023994, MAE: 0.004720 \n",
      "\n",
      "Epoch 285/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 285/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 285/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 285/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 285/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 285/1200, Iteration 6/12, Loss: 0.0091\n",
      "Epoch 285/1200, Iteration 7/12, Loss: 0.0063\n",
      "Epoch 285/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 285/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 285/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 285/1200, Iteration 11/12, Loss: 0.0085\n",
      "Epoch 285/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 285/1200, Iteration 13/12, Loss: 0.0085\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004242, MRE: 0.026168, MAE: 0.004367 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004329, MRE: 0.023913, MAE: 0.004723 \n",
      "\n",
      "Epoch 286/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 286/1200, Iteration 2/12, Loss: 0.0096\n",
      "Epoch 286/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 286/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 286/1200, Iteration 5/12, Loss: 0.0060\n",
      "Epoch 286/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 286/1200, Iteration 7/12, Loss: 0.0051\n",
      "Epoch 286/1200, Iteration 8/12, Loss: 0.0075\n",
      "Epoch 286/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 286/1200, Iteration 10/12, Loss: 0.0129\n",
      "Epoch 286/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 286/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 286/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004321, MRE: 0.025565, MAE: 0.004385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004244, MRE: 0.023904, MAE: 0.004763 \n",
      "\n",
      "Epoch 287/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 287/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 287/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 287/1200, Iteration 4/12, Loss: 0.0073\n",
      "Epoch 287/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 287/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 287/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 287/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 287/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 287/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 287/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 287/1200, Iteration 12/12, Loss: 0.0106\n",
      "Epoch 287/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.004155, MRE: 0.025553, MAE: 0.004316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004128, MRE: 0.023748, MAE: 0.004704 \n",
      "\n",
      "Epoch 288/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 288/1200, Iteration 2/12, Loss: 0.0067\n",
      "Epoch 288/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 288/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 288/1200, Iteration 5/12, Loss: 0.0090\n",
      "Epoch 288/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 288/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 288/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 288/1200, Iteration 9/12, Loss: 0.0097\n",
      "Epoch 288/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 288/1200, Iteration 11/12, Loss: 0.0088\n",
      "Epoch 288/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 288/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 96.12%, Avg loss: 0.004197, MRE: 0.025752, MAE: 0.004339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004055, MRE: 0.023935, MAE: 0.004671 \n",
      "\n",
      "Epoch 289/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 289/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 289/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 289/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 289/1200, Iteration 5/12, Loss: 0.0097\n",
      "Epoch 289/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 289/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 289/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 289/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 289/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 289/1200, Iteration 11/12, Loss: 0.0086\n",
      "Epoch 289/1200, Iteration 12/12, Loss: 0.0063\n",
      "Epoch 289/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004150, MRE: 0.025440, MAE: 0.004307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004123, MRE: 0.023729, MAE: 0.004694 \n",
      "\n",
      "Epoch 290/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 290/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 290/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 290/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 290/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 290/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 290/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 290/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 290/1200, Iteration 9/12, Loss: 0.0084\n",
      "Epoch 290/1200, Iteration 10/12, Loss: 0.0072\n",
      "Epoch 290/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 290/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 290/1200, Iteration 13/12, Loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004170, MRE: 0.026373, MAE: 0.004316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004056, MRE: 0.023482, MAE: 0.004633 \n",
      "\n",
      "Epoch 291/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 291/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 291/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 291/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 291/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 291/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 291/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 291/1200, Iteration 8/12, Loss: 0.0091\n",
      "Epoch 291/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 291/1200, Iteration 10/12, Loss: 0.0108\n",
      "Epoch 291/1200, Iteration 11/12, Loss: 0.0076\n",
      "Epoch 291/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 291/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004159, MRE: 0.025994, MAE: 0.004328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004157, MRE: 0.023604, MAE: 0.004689 \n",
      "\n",
      "Epoch 292/1200, Iteration 1/12, Loss: 0.0080\n",
      "Epoch 292/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 292/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 292/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 292/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 292/1200, Iteration 6/12, Loss: 0.0092\n",
      "Epoch 292/1200, Iteration 7/12, Loss: 0.0063\n",
      "Epoch 292/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 292/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 292/1200, Iteration 10/12, Loss: 0.0093\n",
      "Epoch 292/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 292/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 292/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004124, MRE: 0.025856, MAE: 0.004273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003906, MRE: 0.023396, MAE: 0.004613 \n",
      "\n",
      "Epoch 293/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 293/1200, Iteration 2/12, Loss: 0.0097\n",
      "Epoch 293/1200, Iteration 3/12, Loss: 0.0076\n",
      "Epoch 293/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 293/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 293/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 293/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 293/1200, Iteration 8/12, Loss: 0.0075\n",
      "Epoch 293/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 293/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 293/1200, Iteration 11/12, Loss: 0.0108\n",
      "Epoch 293/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 293/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004115, MRE: 0.025731, MAE: 0.004298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003955, MRE: 0.023318, MAE: 0.004605 \n",
      "\n",
      "Epoch 294/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 294/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 294/1200, Iteration 3/12, Loss: 0.0094\n",
      "Epoch 294/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 294/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 294/1200, Iteration 6/12, Loss: 0.0089\n",
      "Epoch 294/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 294/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 294/1200, Iteration 9/12, Loss: 0.0090\n",
      "Epoch 294/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 294/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 294/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 294/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004187, MRE: 0.025469, MAE: 0.004313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004069, MRE: 0.023544, MAE: 0.004671 \n",
      "\n",
      "Epoch 295/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 295/1200, Iteration 2/12, Loss: 0.0076\n",
      "Epoch 295/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 295/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 295/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 295/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 295/1200, Iteration 7/12, Loss: 0.0068\n",
      "Epoch 295/1200, Iteration 8/12, Loss: 0.0111\n",
      "Epoch 295/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 295/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 295/1200, Iteration 11/12, Loss: 0.0082\n",
      "Epoch 295/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 295/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004130, MRE: 0.025588, MAE: 0.004304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004046, MRE: 0.023490, MAE: 0.004650 \n",
      "\n",
      "Epoch 296/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 296/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 296/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 296/1200, Iteration 4/12, Loss: 0.0089\n",
      "Epoch 296/1200, Iteration 5/12, Loss: 0.0131\n",
      "Epoch 296/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 296/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 296/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 296/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 296/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 296/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 296/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 296/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004075, MRE: 0.025248, MAE: 0.004284 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003943, MRE: 0.023464, MAE: 0.004635 \n",
      "\n",
      "Epoch 297/1200, Iteration 1/12, Loss: 0.0102\n",
      "Epoch 297/1200, Iteration 2/12, Loss: 0.0097\n",
      "Epoch 297/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 297/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 297/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 297/1200, Iteration 6/12, Loss: 0.0074\n",
      "Epoch 297/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 297/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 297/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 297/1200, Iteration 10/12, Loss: 0.0062\n",
      "Epoch 297/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 297/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 297/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004645, MRE: 0.025748, MAE: 0.004404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003864, MRE: 0.023427, MAE: 0.004637 \n",
      "\n",
      "Epoch 298/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 298/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 298/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 298/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 298/1200, Iteration 5/12, Loss: 0.0065\n",
      "Epoch 298/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 298/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 298/1200, Iteration 8/12, Loss: 0.0091\n",
      "Epoch 298/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 298/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 298/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 298/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 298/1200, Iteration 13/12, Loss: 0.0151\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004116, MRE: 0.025698, MAE: 0.004309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004027, MRE: 0.023369, MAE: 0.004581 \n",
      "\n",
      "Epoch 299/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 299/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 299/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 299/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 299/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 299/1200, Iteration 6/12, Loss: 0.0083\n",
      "Epoch 299/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 299/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 299/1200, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 299/1200, Iteration 10/12, Loss: 0.0058\n",
      "Epoch 299/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 299/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 299/1200, Iteration 13/12, Loss: 0.0106\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004142, MRE: 0.025363, MAE: 0.004297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003879, MRE: 0.023498, MAE: 0.004552 \n",
      "\n",
      "Epoch 300/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 300/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 300/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 300/1200, Iteration 4/12, Loss: 0.0064\n",
      "Epoch 300/1200, Iteration 5/12, Loss: 0.0074\n",
      "Epoch 300/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 300/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 300/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 300/1200, Iteration 9/12, Loss: 0.0085\n",
      "Epoch 300/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 300/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 300/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 300/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.004050, MRE: 0.025230, MAE: 0.004240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003824, MRE: 0.023163, MAE: 0.004548 \n",
      "\n",
      "Epoch 301/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 301/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 301/1200, Iteration 3/12, Loss: 0.0067\n",
      "Epoch 301/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 301/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 301/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 301/1200, Iteration 7/12, Loss: 0.0071\n",
      "Epoch 301/1200, Iteration 8/12, Loss: 0.0128\n",
      "Epoch 301/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 301/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 301/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 301/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 301/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004132, MRE: 0.025771, MAE: 0.004313 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004103, MRE: 0.023381, MAE: 0.004631 \n",
      "\n",
      "Epoch 302/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 302/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 302/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 302/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 302/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 302/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 302/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 302/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 302/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 302/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 302/1200, Iteration 11/12, Loss: 0.0141\n",
      "Epoch 302/1200, Iteration 12/12, Loss: 0.0083\n",
      "Epoch 302/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.004071, MRE: 0.025731, MAE: 0.004315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004291, MRE: 0.023359, MAE: 0.004683 \n",
      "\n",
      "Epoch 303/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 303/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 303/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 303/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 303/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 303/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 303/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 303/1200, Iteration 8/12, Loss: 0.0063\n",
      "Epoch 303/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 303/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 303/1200, Iteration 11/12, Loss: 0.0072\n",
      "Epoch 303/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 303/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.003994, MRE: 0.024948, MAE: 0.004242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003934, MRE: 0.023345, MAE: 0.004648 \n",
      "\n",
      "Epoch 304/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 304/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 304/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 304/1200, Iteration 4/12, Loss: 0.0082\n",
      "Epoch 304/1200, Iteration 5/12, Loss: 0.0075\n",
      "Epoch 304/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 304/1200, Iteration 7/12, Loss: 0.0055\n",
      "Epoch 304/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 304/1200, Iteration 9/12, Loss: 0.0068\n",
      "Epoch 304/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 304/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 304/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 304/1200, Iteration 13/12, Loss: 0.0055\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004052, MRE: 0.025125, MAE: 0.004230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003895, MRE: 0.023115, MAE: 0.004608 \n",
      "\n",
      "Epoch 305/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 305/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 305/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 305/1200, Iteration 4/12, Loss: 0.0085\n",
      "Epoch 305/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 305/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 305/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 305/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 305/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 305/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 305/1200, Iteration 11/12, Loss: 0.0072\n",
      "Epoch 305/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 305/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004025, MRE: 0.025116, MAE: 0.004249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.004027, MRE: 0.023339, MAE: 0.004622 \n",
      "\n",
      "Epoch 306/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 306/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 306/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 306/1200, Iteration 4/12, Loss: 0.0072\n",
      "Epoch 306/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 306/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 306/1200, Iteration 7/12, Loss: 0.0121\n",
      "Epoch 306/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 306/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 306/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 306/1200, Iteration 11/12, Loss: 0.0089\n",
      "Epoch 306/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 306/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004061, MRE: 0.025228, MAE: 0.004234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003820, MRE: 0.023116, MAE: 0.004573 \n",
      "\n",
      "Epoch 307/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 307/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 307/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 307/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 307/1200, Iteration 5/12, Loss: 0.0079\n",
      "Epoch 307/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 307/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 307/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 307/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 307/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 307/1200, Iteration 11/12, Loss: 0.0107\n",
      "Epoch 307/1200, Iteration 12/12, Loss: 0.0079\n",
      "Epoch 307/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003987, MRE: 0.025286, MAE: 0.004202 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003956, MRE: 0.022990, MAE: 0.004550 \n",
      "\n",
      "Epoch 308/1200, Iteration 1/12, Loss: 0.0079\n",
      "Epoch 308/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 308/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 308/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 308/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 308/1200, Iteration 6/12, Loss: 0.0083\n",
      "Epoch 308/1200, Iteration 7/12, Loss: 0.0098\n",
      "Epoch 308/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 308/1200, Iteration 9/12, Loss: 0.0057\n",
      "Epoch 308/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 308/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 308/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 308/1200, Iteration 13/12, Loss: 0.0074\n",
      "Train Error: \n",
      " Accuracy: 94.88%, Avg loss: 0.004240, MRE: 0.025683, MAE: 0.004326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.003640, MRE: 0.024138, MAE: 0.004598 \n",
      "\n",
      "Epoch 309/1200, Iteration 1/12, Loss: 0.0116\n",
      "Epoch 309/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 309/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 309/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 309/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 309/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 309/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 309/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 309/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 309/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 309/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 309/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 309/1200, Iteration 13/12, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.004080, MRE: 0.025618, MAE: 0.004337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004313, MRE: 0.023467, MAE: 0.004653 \n",
      "\n",
      "Epoch 310/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 310/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 310/1200, Iteration 3/12, Loss: 0.0090\n",
      "Epoch 310/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 310/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 310/1200, Iteration 6/12, Loss: 0.0099\n",
      "Epoch 310/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 310/1200, Iteration 8/12, Loss: 0.0073\n",
      "Epoch 310/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 310/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 310/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 310/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 310/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 96.25%, Avg loss: 0.004233, MRE: 0.025243, MAE: 0.004290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003840, MRE: 0.023673, MAE: 0.004612 \n",
      "\n",
      "Epoch 311/1200, Iteration 1/12, Loss: 0.0092\n",
      "Epoch 311/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 311/1200, Iteration 3/12, Loss: 0.0068\n",
      "Epoch 311/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 311/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 311/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 311/1200, Iteration 7/12, Loss: 0.0079\n",
      "Epoch 311/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 311/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 311/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 311/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 311/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 311/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.004013, MRE: 0.024931, MAE: 0.004220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003881, MRE: 0.023037, MAE: 0.004530 \n",
      "\n",
      "Epoch 312/1200, Iteration 1/12, Loss: 0.0088\n",
      "Epoch 312/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 312/1200, Iteration 3/12, Loss: 0.0101\n",
      "Epoch 312/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 312/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 312/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 312/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 312/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 312/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 312/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 312/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 312/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 312/1200, Iteration 13/12, Loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.004030, MRE: 0.026419, MAE: 0.004282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003681, MRE: 0.023774, MAE: 0.004657 \n",
      "\n",
      "Epoch 313/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 313/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 313/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 313/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 313/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 313/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 313/1200, Iteration 7/12, Loss: 0.0109\n",
      "Epoch 313/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 313/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 313/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 313/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 313/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 313/1200, Iteration 13/12, Loss: 0.0051\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.003932, MRE: 0.024926, MAE: 0.004171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003644, MRE: 0.022921, MAE: 0.004480 \n",
      "\n",
      "Epoch 314/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 314/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 314/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 314/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 314/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 314/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 314/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 314/1200, Iteration 8/12, Loss: 0.0090\n",
      "Epoch 314/1200, Iteration 9/12, Loss: 0.0062\n",
      "Epoch 314/1200, Iteration 10/12, Loss: 0.0063\n",
      "Epoch 314/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 314/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 314/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.004364, MRE: 0.025205, MAE: 0.004264 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003743, MRE: 0.022922, MAE: 0.004539 \n",
      "\n",
      "Epoch 315/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 315/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 315/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 315/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 315/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 315/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 315/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 315/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 315/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 315/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 315/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 315/1200, Iteration 12/12, Loss: 0.0124\n",
      "Epoch 315/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003912, MRE: 0.025790, MAE: 0.004192 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003797, MRE: 0.022781, MAE: 0.004548 \n",
      "\n",
      "Epoch 316/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 316/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 316/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 316/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 316/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 316/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 316/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 316/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 316/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 316/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 316/1200, Iteration 11/12, Loss: 0.0106\n",
      "Epoch 316/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 316/1200, Iteration 13/12, Loss: 0.0180\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.003970, MRE: 0.024913, MAE: 0.004185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003784, MRE: 0.022789, MAE: 0.004528 \n",
      "\n",
      "Epoch 317/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 317/1200, Iteration 2/12, Loss: 0.0086\n",
      "Epoch 317/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 317/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 317/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 317/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 317/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 317/1200, Iteration 8/12, Loss: 0.0075\n",
      "Epoch 317/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 317/1200, Iteration 10/12, Loss: 0.0072\n",
      "Epoch 317/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 317/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 317/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004188, MRE: 0.024948, MAE: 0.004181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003765, MRE: 0.022534, MAE: 0.004487 \n",
      "\n",
      "Epoch 318/1200, Iteration 1/12, Loss: 0.0074\n",
      "Epoch 318/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 318/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 318/1200, Iteration 4/12, Loss: 0.0065\n",
      "Epoch 318/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 318/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 318/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 318/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 318/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 318/1200, Iteration 10/12, Loss: 0.0063\n",
      "Epoch 318/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 318/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 318/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003903, MRE: 0.024823, MAE: 0.004208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003789, MRE: 0.023221, MAE: 0.004606 \n",
      "\n",
      "Epoch 319/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 319/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 319/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 319/1200, Iteration 4/12, Loss: 0.0083\n",
      "Epoch 319/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 319/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 319/1200, Iteration 7/12, Loss: 0.0051\n",
      "Epoch 319/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 319/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 319/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 319/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 319/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 319/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.004023, MRE: 0.025499, MAE: 0.004243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003870, MRE: 0.022377, MAE: 0.004470 \n",
      "\n",
      "Epoch 320/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 320/1200, Iteration 2/12, Loss: 0.0079\n",
      "Epoch 320/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 320/1200, Iteration 4/12, Loss: 0.0068\n",
      "Epoch 320/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 320/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 320/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 320/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 320/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 320/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 320/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 320/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 320/1200, Iteration 13/12, Loss: 0.0057\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003859, MRE: 0.029025, MAE: 0.004198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003785, MRE: 0.022406, MAE: 0.004447 \n",
      "\n",
      "Epoch 321/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 321/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 321/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 321/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 321/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 321/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 321/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 321/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 321/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 321/1200, Iteration 10/12, Loss: 0.0078\n",
      "Epoch 321/1200, Iteration 11/12, Loss: 0.0093\n",
      "Epoch 321/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 321/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003922, MRE: 0.024893, MAE: 0.004176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003772, MRE: 0.022289, MAE: 0.004438 \n",
      "\n",
      "Epoch 322/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 322/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 322/1200, Iteration 3/12, Loss: 0.0076\n",
      "Epoch 322/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 322/1200, Iteration 5/12, Loss: 0.0060\n",
      "Epoch 322/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 322/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 322/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 322/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 322/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 322/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 322/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 322/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 96.38%, Avg loss: 0.003824, MRE: 0.024555, MAE: 0.004123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003664, MRE: 0.022728, MAE: 0.004461 \n",
      "\n",
      "Epoch 323/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 323/1200, Iteration 2/12, Loss: 0.0077\n",
      "Epoch 323/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 323/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 323/1200, Iteration 5/12, Loss: 0.0072\n",
      "Epoch 323/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 323/1200, Iteration 7/12, Loss: 0.0099\n",
      "Epoch 323/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 323/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 323/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 323/1200, Iteration 11/12, Loss: 0.0053\n",
      "Epoch 323/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 323/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.003843, MRE: 0.025186, MAE: 0.004131 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003571, MRE: 0.022655, MAE: 0.004473 \n",
      "\n",
      "Epoch 324/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 324/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 324/1200, Iteration 3/12, Loss: 0.0095\n",
      "Epoch 324/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 324/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 324/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 324/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 324/1200, Iteration 8/12, Loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 324/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 324/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 324/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 324/1200, Iteration 13/12, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003977, MRE: 0.025979, MAE: 0.004289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.004079, MRE: 0.022767, MAE: 0.004552 \n",
      "\n",
      "Epoch 325/1200, Iteration 1/12, Loss: 0.0079\n",
      "Epoch 325/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 325/1200, Iteration 3/12, Loss: 0.0064\n",
      "Epoch 325/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 325/1200, Iteration 5/12, Loss: 0.0064\n",
      "Epoch 325/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 325/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 325/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 325/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 325/1200, Iteration 10/12, Loss: 0.0084\n",
      "Epoch 325/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 325/1200, Iteration 12/12, Loss: 0.0066\n",
      "Epoch 325/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003793, MRE: 0.024566, MAE: 0.004118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003901, MRE: 0.022481, MAE: 0.004494 \n",
      "\n",
      "Epoch 326/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 326/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 326/1200, Iteration 3/12, Loss: 0.0085\n",
      "Epoch 326/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 326/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 326/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 326/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 326/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 326/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 326/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 326/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 326/1200, Iteration 12/12, Loss: 0.0091\n",
      "Epoch 326/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003989, MRE: 0.025525, MAE: 0.004250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.004015, MRE: 0.022554, MAE: 0.004502 \n",
      "\n",
      "Epoch 327/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 327/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 327/1200, Iteration 3/12, Loss: 0.0083\n",
      "Epoch 327/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 327/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 327/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 327/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 327/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 327/1200, Iteration 9/12, Loss: 0.0106\n",
      "Epoch 327/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 327/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 327/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 327/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003791, MRE: 0.025052, MAE: 0.004150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003770, MRE: 0.022716, MAE: 0.004539 \n",
      "\n",
      "Epoch 328/1200, Iteration 1/12, Loss: 0.0070\n",
      "Epoch 328/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 328/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 328/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 328/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 328/1200, Iteration 6/12, Loss: 0.0054\n",
      "Epoch 328/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 328/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 328/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 328/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 328/1200, Iteration 11/12, Loss: 0.0069\n",
      "Epoch 328/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 328/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003949, MRE: 0.024832, MAE: 0.004169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003733, MRE: 0.022672, MAE: 0.004495 \n",
      "\n",
      "Epoch 329/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 329/1200, Iteration 2/12, Loss: 0.0085\n",
      "Epoch 329/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 329/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 329/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 329/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 329/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 329/1200, Iteration 8/12, Loss: 0.0111\n",
      "Epoch 329/1200, Iteration 9/12, Loss: 0.0075\n",
      "Epoch 329/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 329/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 329/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 329/1200, Iteration 13/12, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003829, MRE: 0.025272, MAE: 0.004172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003975, MRE: 0.022407, MAE: 0.004518 \n",
      "\n",
      "Epoch 330/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 330/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 330/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 330/1200, Iteration 4/12, Loss: 0.0077\n",
      "Epoch 330/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 330/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 330/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 330/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 330/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 330/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 330/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 330/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 330/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003749, MRE: 0.025214, MAE: 0.004118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003853, MRE: 0.022284, MAE: 0.004459 \n",
      "\n",
      "Epoch 331/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 331/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 331/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 331/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 331/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 331/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 331/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 331/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 331/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 331/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 331/1200, Iteration 11/12, Loss: 0.0101\n",
      "Epoch 331/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 331/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003733, MRE: 0.024887, MAE: 0.004127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003908, MRE: 0.022439, MAE: 0.004507 \n",
      "\n",
      "Epoch 332/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 332/1200, Iteration 2/12, Loss: 0.0067\n",
      "Epoch 332/1200, Iteration 3/12, Loss: 0.0089\n",
      "Epoch 332/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 332/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 332/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 332/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 332/1200, Iteration 8/12, Loss: 0.0087\n",
      "Epoch 332/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 332/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 332/1200, Iteration 11/12, Loss: 0.0062\n",
      "Epoch 332/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 332/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.003940, MRE: 0.025097, MAE: 0.004221 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003596, MRE: 0.022733, MAE: 0.004578 \n",
      "\n",
      "Epoch 333/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 333/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 333/1200, Iteration 3/12, Loss: 0.0099\n",
      "Epoch 333/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 333/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 333/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 333/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 333/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 333/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 333/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 333/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 333/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 333/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003900, MRE: 0.024588, MAE: 0.004162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003774, MRE: 0.022306, MAE: 0.004479 \n",
      "\n",
      "Epoch 334/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 334/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 334/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 334/1200, Iteration 4/12, Loss: 0.0117\n",
      "Epoch 334/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 334/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 334/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 334/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 334/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 334/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 334/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 334/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 334/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003797, MRE: 0.024599, MAE: 0.004110 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003584, MRE: 0.022325, MAE: 0.004446 \n",
      "\n",
      "Epoch 335/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 335/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 335/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 335/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 335/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 335/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 335/1200, Iteration 7/12, Loss: 0.0083\n",
      "Epoch 335/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 335/1200, Iteration 9/12, Loss: 0.0103\n",
      "Epoch 335/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 335/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 335/1200, Iteration 12/12, Loss: 0.0077\n",
      "Epoch 335/1200, Iteration 13/12, Loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003889, MRE: 0.024669, MAE: 0.004127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003639, MRE: 0.022266, MAE: 0.004452 \n",
      "\n",
      "Epoch 336/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 336/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 336/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 336/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 336/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 336/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 336/1200, Iteration 7/12, Loss: 0.0101\n",
      "Epoch 336/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 336/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 336/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 336/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 336/1200, Iteration 12/12, Loss: 0.0066\n",
      "Epoch 336/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.004194, MRE: 0.024800, MAE: 0.004163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003664, MRE: 0.022159, MAE: 0.004428 \n",
      "\n",
      "Epoch 337/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 337/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 337/1200, Iteration 3/12, Loss: 0.0068\n",
      "Epoch 337/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 337/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 337/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 337/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 337/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 337/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 337/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 337/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 337/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 337/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003961, MRE: 0.025033, MAE: 0.004142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003596, MRE: 0.022108, MAE: 0.004396 \n",
      "\n",
      "Epoch 338/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 338/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 338/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 338/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 338/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 338/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 338/1200, Iteration 7/12, Loss: 0.0077\n",
      "Epoch 338/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 338/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 338/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 338/1200, Iteration 11/12, Loss: 0.0078\n",
      "Epoch 338/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 338/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003723, MRE: 0.024782, MAE: 0.004127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003934, MRE: 0.022092, MAE: 0.004475 \n",
      "\n",
      "Epoch 339/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 339/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 339/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 339/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 339/1200, Iteration 5/12, Loss: 0.0067\n",
      "Epoch 339/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 339/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 339/1200, Iteration 8/12, Loss: 0.0126\n",
      "Epoch 339/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 339/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 339/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 339/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 339/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003658, MRE: 0.024141, MAE: 0.004065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003701, MRE: 0.022544, MAE: 0.004509 \n",
      "\n",
      "Epoch 340/1200, Iteration 1/12, Loss: 0.0063\n",
      "Epoch 340/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 340/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 340/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 340/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 340/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 340/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 340/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 340/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 340/1200, Iteration 10/12, Loss: 0.0070\n",
      "Epoch 340/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 340/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 340/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003712, MRE: 0.024202, MAE: 0.004040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003644, MRE: 0.022295, MAE: 0.004405 \n",
      "\n",
      "Epoch 341/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 341/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 341/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 341/1200, Iteration 4/12, Loss: 0.0052\n",
      "Epoch 341/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 341/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 341/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 341/1200, Iteration 8/12, Loss: 0.0077\n",
      "Epoch 341/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 341/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 341/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 341/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 341/1200, Iteration 13/12, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003676, MRE: 0.024236, MAE: 0.004067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003919, MRE: 0.022007, MAE: 0.004425 \n",
      "\n",
      "Epoch 342/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 342/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 342/1200, Iteration 3/12, Loss: 0.0080\n",
      "Epoch 342/1200, Iteration 4/12, Loss: 0.0073\n",
      "Epoch 342/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 342/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 342/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 342/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 342/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 342/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 342/1200, Iteration 11/12, Loss: 0.0070\n",
      "Epoch 342/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 342/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003823, MRE: 0.024309, MAE: 0.004100 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003699, MRE: 0.022592, MAE: 0.004461 \n",
      "\n",
      "Epoch 343/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 343/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 343/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 343/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 343/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 343/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 343/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 343/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 343/1200, Iteration 9/12, Loss: 0.0105\n",
      "Epoch 343/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 343/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 343/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 343/1200, Iteration 13/12, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003852, MRE: 0.025141, MAE: 0.004178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.004116, MRE: 0.022160, MAE: 0.004493 \n",
      "\n",
      "Epoch 344/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 344/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 344/1200, Iteration 3/12, Loss: 0.0065\n",
      "Epoch 344/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 344/1200, Iteration 5/12, Loss: 0.0064\n",
      "Epoch 344/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 344/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 344/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 344/1200, Iteration 9/12, Loss: 0.0084\n",
      "Epoch 344/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 344/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 344/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 344/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003718, MRE: 0.024357, MAE: 0.004060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003590, MRE: 0.022242, MAE: 0.004407 \n",
      "\n",
      "Epoch 345/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 345/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 345/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 345/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 345/1200, Iteration 5/12, Loss: 0.0059\n",
      "Epoch 345/1200, Iteration 6/12, Loss: 0.0097\n",
      "Epoch 345/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 345/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 345/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 345/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 345/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 345/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 345/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003608, MRE: 0.024472, MAE: 0.004035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003657, MRE: 0.021862, MAE: 0.004372 \n",
      "\n",
      "Epoch 346/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 346/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 346/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 346/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 346/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 346/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 346/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 346/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 346/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 346/1200, Iteration 10/12, Loss: 0.0077\n",
      "Epoch 346/1200, Iteration 11/12, Loss: 0.0057\n",
      "Epoch 346/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 346/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003681, MRE: 0.024179, MAE: 0.004065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003637, MRE: 0.022062, MAE: 0.004413 \n",
      "\n",
      "Epoch 347/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 347/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 347/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 347/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 347/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 347/1200, Iteration 6/12, Loss: 0.0095\n",
      "Epoch 347/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 347/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 347/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 347/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 347/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 347/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 347/1200, Iteration 13/12, Loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.004035, MRE: 0.024520, MAE: 0.004098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003461, MRE: 0.021871, MAE: 0.004343 \n",
      "\n",
      "Epoch 348/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 348/1200, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 348/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 348/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 348/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 348/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 348/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 348/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 348/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 348/1200, Iteration 10/12, Loss: 0.0049\n",
      "Epoch 348/1200, Iteration 11/12, Loss: 0.0095\n",
      "Epoch 348/1200, Iteration 12/12, Loss: 0.0080\n",
      "Epoch 348/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003598, MRE: 0.024238, MAE: 0.004010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003619, MRE: 0.021703, MAE: 0.004374 \n",
      "\n",
      "Epoch 349/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 349/1200, Iteration 2/12, Loss: 0.0070\n",
      "Epoch 349/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 349/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 349/1200, Iteration 5/12, Loss: 0.0127\n",
      "Epoch 349/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 349/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 349/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 349/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 349/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 349/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 349/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 349/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003612, MRE: 0.024719, MAE: 0.004048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003557, MRE: 0.022688, MAE: 0.004493 \n",
      "\n",
      "Epoch 350/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 350/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 350/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 350/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 350/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 350/1200, Iteration 6/12, Loss: 0.0073\n",
      "Epoch 350/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 350/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 350/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 350/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 350/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 350/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 350/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003655, MRE: 0.024725, MAE: 0.004044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003492, MRE: 0.022266, MAE: 0.004411 \n",
      "\n",
      "Epoch 351/1200, Iteration 1/12, Loss: 0.0061\n",
      "Epoch 351/1200, Iteration 2/12, Loss: 0.0056\n",
      "Epoch 351/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 351/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 351/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 351/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 351/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 351/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 351/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 351/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 351/1200, Iteration 11/12, Loss: 0.0114\n",
      "Epoch 351/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 351/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003626, MRE: 0.024534, MAE: 0.004055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003802, MRE: 0.021610, MAE: 0.004383 \n",
      "\n",
      "Epoch 352/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 352/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 352/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 352/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 352/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 352/1200, Iteration 6/12, Loss: 0.0091\n",
      "Epoch 352/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 352/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 352/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 352/1200, Iteration 10/12, Loss: 0.0068\n",
      "Epoch 352/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 352/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 352/1200, Iteration 13/12, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003642, MRE: 0.024474, MAE: 0.004084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003829, MRE: 0.021893, MAE: 0.004454 \n",
      "\n",
      "Epoch 353/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 353/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 353/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 353/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 353/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 353/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 353/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 353/1200, Iteration 8/12, Loss: 0.0077\n",
      "Epoch 353/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 353/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 353/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 353/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 353/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.003571, MRE: 0.024165, MAE: 0.004034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003641, MRE: 0.022813, MAE: 0.004498 \n",
      "\n",
      "Epoch 354/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 354/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 354/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 354/1200, Iteration 4/12, Loss: 0.0075\n",
      "Epoch 354/1200, Iteration 5/12, Loss: 0.0072\n",
      "Epoch 354/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 354/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 354/1200, Iteration 8/12, Loss: 0.0063\n",
      "Epoch 354/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 354/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 354/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 354/1200, Iteration 12/12, Loss: 0.0081\n",
      "Epoch 354/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003526, MRE: 0.024301, MAE: 0.003963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003484, MRE: 0.021793, MAE: 0.004373 \n",
      "\n",
      "Epoch 355/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 355/1200, Iteration 2/12, Loss: 0.0059\n",
      "Epoch 355/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 355/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 355/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 355/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 355/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 355/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 355/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 355/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 355/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 355/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 355/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003596, MRE: 0.024131, MAE: 0.003991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003606, MRE: 0.021752, MAE: 0.004401 \n",
      "\n",
      "Epoch 356/1200, Iteration 1/12, Loss: 0.0071\n",
      "Epoch 356/1200, Iteration 2/12, Loss: 0.0081\n",
      "Epoch 356/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 356/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 356/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 356/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 356/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 356/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 356/1200, Iteration 9/12, Loss: 0.0076\n",
      "Epoch 356/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 356/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 356/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 356/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003530, MRE: 0.024086, MAE: 0.003997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003666, MRE: 0.021770, MAE: 0.004398 \n",
      "\n",
      "Epoch 357/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 357/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 357/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 357/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 357/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 357/1200, Iteration 6/12, Loss: 0.0070\n",
      "Epoch 357/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 357/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 357/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 357/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 357/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 357/1200, Iteration 12/12, Loss: 0.0083\n",
      "Epoch 357/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003772, MRE: 0.025383, MAE: 0.004172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003878, MRE: 0.021640, MAE: 0.004422 \n",
      "\n",
      "Epoch 358/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 358/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 358/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 358/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 358/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 358/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 358/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 358/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 358/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 358/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 358/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 358/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 358/1200, Iteration 13/12, Loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003655, MRE: 0.024286, MAE: 0.004053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003445, MRE: 0.022004, MAE: 0.004423 \n",
      "\n",
      "Epoch 359/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 359/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 359/1200, Iteration 3/12, Loss: 0.0059\n",
      "Epoch 359/1200, Iteration 4/12, Loss: 0.0083\n",
      "Epoch 359/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 359/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 359/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 359/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 359/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 359/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 359/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 359/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 359/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003873, MRE: 0.024888, MAE: 0.004048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003532, MRE: 0.021485, MAE: 0.004328 \n",
      "\n",
      "Epoch 360/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 360/1200, Iteration 2/12, Loss: 0.0102\n",
      "Epoch 360/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 360/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 360/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 360/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 360/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 360/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 360/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 360/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 360/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 360/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 360/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003670, MRE: 0.023788, MAE: 0.004011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003515, MRE: 0.021873, MAE: 0.004394 \n",
      "\n",
      "Epoch 361/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 361/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 361/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 361/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 361/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 361/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 361/1200, Iteration 7/12, Loss: 0.0075\n",
      "Epoch 361/1200, Iteration 8/12, Loss: 0.0058\n",
      "Epoch 361/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 361/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 361/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 361/1200, Iteration 12/12, Loss: 0.0071\n",
      "Epoch 361/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003571, MRE: 0.028180, MAE: 0.004017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003548, MRE: 0.021481, MAE: 0.004332 \n",
      "\n",
      "Epoch 362/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 362/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 362/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 362/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 362/1200, Iteration 5/12, Loss: 0.0083\n",
      "Epoch 362/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 362/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 362/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 362/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 362/1200, Iteration 10/12, Loss: 0.0082\n",
      "Epoch 362/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 362/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 362/1200, Iteration 13/12, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003512, MRE: 0.024865, MAE: 0.004005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003640, MRE: 0.021419, MAE: 0.004328 \n",
      "\n",
      "Epoch 363/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 363/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 363/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 363/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 363/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 363/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 363/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 363/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 363/1200, Iteration 9/12, Loss: 0.0059\n",
      "Epoch 363/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 363/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 363/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 363/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003468, MRE: 0.023623, MAE: 0.003961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003512, MRE: 0.021673, MAE: 0.004338 \n",
      "\n",
      "Epoch 364/1200, Iteration 1/12, Loss: 0.0104\n",
      "Epoch 364/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 364/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 364/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 364/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 364/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 364/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 364/1200, Iteration 8/12, Loss: 0.0058\n",
      "Epoch 364/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 364/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 364/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 364/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 364/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003482, MRE: 0.024307, MAE: 0.003997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003666, MRE: 0.021259, MAE: 0.004337 \n",
      "\n",
      "Epoch 365/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 365/1200, Iteration 2/12, Loss: 0.0062\n",
      "Epoch 365/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 365/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 365/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 365/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 365/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 365/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 365/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 365/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 365/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 365/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 365/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003497, MRE: 0.024324, MAE: 0.003982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003611, MRE: 0.021350, MAE: 0.004338 \n",
      "\n",
      "Epoch 366/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 366/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 366/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 366/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 366/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 366/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 366/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 366/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 366/1200, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 366/1200, Iteration 10/12, Loss: 0.0084\n",
      "Epoch 366/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 366/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 366/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003782, MRE: 0.024123, MAE: 0.004004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003403, MRE: 0.021881, MAE: 0.004365 \n",
      "\n",
      "Epoch 367/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 367/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 367/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 367/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 367/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 367/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 367/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 367/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 367/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 367/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 367/1200, Iteration 11/12, Loss: 0.0101\n",
      "Epoch 367/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 367/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003436, MRE: 0.023746, MAE: 0.003974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003589, MRE: 0.021292, MAE: 0.004323 \n",
      "\n",
      "Epoch 368/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 368/1200, Iteration 2/12, Loss: 0.0082\n",
      "Epoch 368/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 368/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 368/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 368/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 368/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 368/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 368/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 368/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 368/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 368/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 368/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003425, MRE: 0.023626, MAE: 0.003937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003524, MRE: 0.021394, MAE: 0.004325 \n",
      "\n",
      "Epoch 369/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 369/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 369/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 369/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 369/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 369/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 369/1200, Iteration 7/12, Loss: 0.0074\n",
      "Epoch 369/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 369/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 369/1200, Iteration 10/12, Loss: 0.0056\n",
      "Epoch 369/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 369/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 369/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 96.88%, Avg loss: 0.003418, MRE: 0.023738, MAE: 0.003938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003473, MRE: 0.021943, MAE: 0.004380 \n",
      "\n",
      "Epoch 370/1200, Iteration 1/12, Loss: 0.0091\n",
      "Epoch 370/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 370/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 370/1200, Iteration 4/12, Loss: 0.0110\n",
      "Epoch 370/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 370/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 370/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 370/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 370/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 370/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 370/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 370/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 370/1200, Iteration 13/12, Loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003597, MRE: 0.024016, MAE: 0.004061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003460, MRE: 0.022072, MAE: 0.004454 \n",
      "\n",
      "Epoch 371/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 371/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 371/1200, Iteration 3/12, Loss: 0.0088\n",
      "Epoch 371/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 371/1200, Iteration 5/12, Loss: 0.0065\n",
      "Epoch 371/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 371/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 371/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 371/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 371/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 371/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 371/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 371/1200, Iteration 13/12, Loss: 0.0116\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003391, MRE: 0.023613, MAE: 0.003900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003434, MRE: 0.021365, MAE: 0.004283 \n",
      "\n",
      "Epoch 372/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 372/1200, Iteration 2/12, Loss: 0.0080\n",
      "Epoch 372/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 372/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 372/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 372/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 372/1200, Iteration 7/12, Loss: 0.0087\n",
      "Epoch 372/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 372/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 372/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 372/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 372/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 372/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003375, MRE: 0.023670, MAE: 0.003903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003404, MRE: 0.021463, MAE: 0.004239 \n",
      "\n",
      "Epoch 373/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 373/1200, Iteration 2/12, Loss: 0.0073\n",
      "Epoch 373/1200, Iteration 3/12, Loss: 0.0113\n",
      "Epoch 373/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 373/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 373/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 373/1200, Iteration 7/12, Loss: 0.0050\n",
      "Epoch 373/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 373/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 373/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 373/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 373/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 373/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003454, MRE: 0.023804, MAE: 0.003936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003332, MRE: 0.021457, MAE: 0.004256 \n",
      "\n",
      "Epoch 374/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 374/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 374/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 374/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 374/1200, Iteration 5/12, Loss: 0.0071\n",
      "Epoch 374/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 374/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 374/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 374/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 374/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 374/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 374/1200, Iteration 12/12, Loss: 0.0098\n",
      "Epoch 374/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003452, MRE: 0.023910, MAE: 0.003938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003287, MRE: 0.021760, MAE: 0.004291 \n",
      "\n",
      "Epoch 375/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 375/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 375/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 375/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 375/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 375/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 375/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 375/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 375/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 375/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 375/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 375/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 375/1200, Iteration 13/12, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003577, MRE: 0.025055, MAE: 0.004065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003793, MRE: 0.021339, MAE: 0.004358 \n",
      "\n",
      "Epoch 376/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 376/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 376/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 376/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 376/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 376/1200, Iteration 6/12, Loss: 0.0054\n",
      "Epoch 376/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 376/1200, Iteration 8/12, Loss: 0.0091\n",
      "Epoch 376/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 376/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 376/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 376/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 376/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003441, MRE: 0.023581, MAE: 0.003942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003605, MRE: 0.021670, MAE: 0.004354 \n",
      "\n",
      "Epoch 377/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 377/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 377/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 377/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 377/1200, Iteration 5/12, Loss: 0.0058\n",
      "Epoch 377/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 377/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 377/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 377/1200, Iteration 9/12, Loss: 0.0093\n",
      "Epoch 377/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 377/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 377/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 377/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003394, MRE: 0.023862, MAE: 0.003911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003395, MRE: 0.021568, MAE: 0.004325 \n",
      "\n",
      "Epoch 378/1200, Iteration 1/12, Loss: 0.0077\n",
      "Epoch 378/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 378/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 378/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 378/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 378/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 378/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 378/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 378/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 378/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 378/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 378/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 378/1200, Iteration 13/12, Loss: 0.0078\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003379, MRE: 0.023501, MAE: 0.003943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003608, MRE: 0.021037, MAE: 0.004264 \n",
      "\n",
      "Epoch 379/1200, Iteration 1/12, Loss: 0.0060\n",
      "Epoch 379/1200, Iteration 2/12, Loss: 0.0101\n",
      "Epoch 379/1200, Iteration 3/12, Loss: 0.0059\n",
      "Epoch 379/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 379/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 379/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 379/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 379/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 379/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 379/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 379/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 379/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 379/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003694, MRE: 0.028537, MAE: 0.003983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003441, MRE: 0.021176, MAE: 0.004277 \n",
      "\n",
      "Epoch 380/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 380/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 380/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 380/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 380/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 380/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 380/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 380/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 380/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 380/1200, Iteration 10/12, Loss: 0.0073\n",
      "Epoch 380/1200, Iteration 11/12, Loss: 0.0063\n",
      "Epoch 380/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 380/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003394, MRE: 0.023640, MAE: 0.003943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003377, MRE: 0.021940, MAE: 0.004354 \n",
      "\n",
      "Epoch 381/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 381/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 381/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 381/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 381/1200, Iteration 5/12, Loss: 0.0063\n",
      "Epoch 381/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 381/1200, Iteration 7/12, Loss: 0.0067\n",
      "Epoch 381/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 381/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 381/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 381/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 381/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 381/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003459, MRE: 0.024512, MAE: 0.004003 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003696, MRE: 0.021092, MAE: 0.004279 \n",
      "\n",
      "Epoch 382/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 382/1200, Iteration 2/12, Loss: 0.0113\n",
      "Epoch 382/1200, Iteration 3/12, Loss: 0.0073\n",
      "Epoch 382/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 382/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 382/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 382/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 382/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 382/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 382/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 382/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 382/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 382/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003405, MRE: 0.023552, MAE: 0.003971 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003304, MRE: 0.021642, MAE: 0.004390 \n",
      "\n",
      "Epoch 383/1200, Iteration 1/12, Loss: 0.0067\n",
      "Epoch 383/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 383/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 383/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 383/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 383/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 383/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 383/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 383/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 383/1200, Iteration 10/12, Loss: 0.0064\n",
      "Epoch 383/1200, Iteration 11/12, Loss: 0.0118\n",
      "Epoch 383/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 383/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003394, MRE: 0.024001, MAE: 0.003885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003280, MRE: 0.020707, MAE: 0.004151 \n",
      "\n",
      "Epoch 384/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 384/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 384/1200, Iteration 3/12, Loss: 0.0073\n",
      "Epoch 384/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 384/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 384/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 384/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 384/1200, Iteration 8/12, Loss: 0.0090\n",
      "Epoch 384/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 384/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 384/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 384/1200, Iteration 12/12, Loss: 0.0077\n",
      "Epoch 384/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003295, MRE: 0.023202, MAE: 0.003858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003397, MRE: 0.020880, MAE: 0.004264 \n",
      "\n",
      "Epoch 385/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 385/1200, Iteration 2/12, Loss: 0.0093\n",
      "Epoch 385/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 385/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 385/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 385/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 385/1200, Iteration 7/12, Loss: 0.0074\n",
      "Epoch 385/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 385/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 385/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 385/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 385/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 385/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.003287, MRE: 0.023328, MAE: 0.003850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003292, MRE: 0.020795, MAE: 0.004178 \n",
      "\n",
      "Epoch 386/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 386/1200, Iteration 2/12, Loss: 0.0084\n",
      "Epoch 386/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 386/1200, Iteration 4/12, Loss: 0.0046\n",
      "Epoch 386/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 386/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 386/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 386/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 386/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 386/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 386/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 386/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 386/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 97.12%, Avg loss: 0.003330, MRE: 0.023108, MAE: 0.003862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003229, MRE: 0.020925, MAE: 0.004179 \n",
      "\n",
      "Epoch 387/1200, Iteration 1/12, Loss: 0.0081\n",
      "Epoch 387/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 387/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 387/1200, Iteration 4/12, Loss: 0.0068\n",
      "Epoch 387/1200, Iteration 5/12, Loss: 0.0063\n",
      "Epoch 387/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 387/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 387/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 387/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 387/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 387/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 387/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 387/1200, Iteration 13/12, Loss: 0.0073\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003416, MRE: 0.023774, MAE: 0.003896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003386, MRE: 0.020795, MAE: 0.004226 \n",
      "\n",
      "Epoch 388/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 388/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 388/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 388/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 388/1200, Iteration 5/12, Loss: 0.0079\n",
      "Epoch 388/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 388/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 388/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 388/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 388/1200, Iteration 10/12, Loss: 0.0116\n",
      "Epoch 388/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 388/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 388/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 96.75%, Avg loss: 0.003372, MRE: 0.023604, MAE: 0.003920 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.003295, MRE: 0.022306, MAE: 0.004373 \n",
      "\n",
      "Epoch 389/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 389/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 389/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 389/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 389/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 389/1200, Iteration 6/12, Loss: 0.0091\n",
      "Epoch 389/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 389/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 389/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 389/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 389/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 389/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 389/1200, Iteration 13/12, Loss: 0.0104\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003289, MRE: 0.023149, MAE: 0.003875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003631, MRE: 0.020682, MAE: 0.004279 \n",
      "\n",
      "Epoch 390/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 390/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 390/1200, Iteration 3/12, Loss: 0.0095\n",
      "Epoch 390/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 390/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 390/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 390/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 390/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 390/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 390/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 390/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 390/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 390/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003307, MRE: 0.023720, MAE: 0.003891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003403, MRE: 0.020645, MAE: 0.004238 \n",
      "\n",
      "Epoch 391/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 391/1200, Iteration 2/12, Loss: 0.0074\n",
      "Epoch 391/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 391/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 391/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 391/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 391/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 391/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 391/1200, Iteration 9/12, Loss: 0.0087\n",
      "Epoch 391/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 391/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 391/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 391/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003521, MRE: 0.023121, MAE: 0.003871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003448, MRE: 0.020646, MAE: 0.004228 \n",
      "\n",
      "Epoch 392/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 392/1200, Iteration 2/12, Loss: 0.0075\n",
      "Epoch 392/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 392/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 392/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 392/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 392/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 392/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 392/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 392/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 392/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 392/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 392/1200, Iteration 13/12, Loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003250, MRE: 0.023197, MAE: 0.003834 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003269, MRE: 0.021004, MAE: 0.004238 \n",
      "\n",
      "Epoch 393/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 393/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 393/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 393/1200, Iteration 4/12, Loss: 0.0073\n",
      "Epoch 393/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 393/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 393/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 393/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 393/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 393/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 393/1200, Iteration 11/12, Loss: 0.0065\n",
      "Epoch 393/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 393/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003262, MRE: 0.023059, MAE: 0.003835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003319, MRE: 0.020679, MAE: 0.004175 \n",
      "\n",
      "Epoch 394/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 394/1200, Iteration 2/12, Loss: 0.0075\n",
      "Epoch 394/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 394/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 394/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 394/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 394/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 394/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 394/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 394/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 394/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 394/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 394/1200, Iteration 13/12, Loss: 0.0125\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003507, MRE: 0.024660, MAE: 0.004128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003938, MRE: 0.020970, MAE: 0.004352 \n",
      "\n",
      "Epoch 395/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 395/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 395/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 395/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 395/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 395/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 395/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 395/1200, Iteration 8/12, Loss: 0.0072\n",
      "Epoch 395/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 395/1200, Iteration 10/12, Loss: 0.0096\n",
      "Epoch 395/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 395/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 395/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003270, MRE: 0.023501, MAE: 0.003891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003587, MRE: 0.020601, MAE: 0.004239 \n",
      "\n",
      "Epoch 396/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 396/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 396/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 396/1200, Iteration 4/12, Loss: 0.0077\n",
      "Epoch 396/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 396/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 396/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 396/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 396/1200, Iteration 9/12, Loss: 0.0077\n",
      "Epoch 396/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 396/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 396/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 396/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003347, MRE: 0.023578, MAE: 0.003977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003552, MRE: 0.020604, MAE: 0.004231 \n",
      "\n",
      "Epoch 397/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 397/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 397/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 397/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 397/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 397/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 397/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 397/1200, Iteration 8/12, Loss: 0.0092\n",
      "Epoch 397/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 397/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 397/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 397/1200, Iteration 12/12, Loss: 0.0082\n",
      "Epoch 397/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003256, MRE: 0.023198, MAE: 0.003836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003313, MRE: 0.020734, MAE: 0.004209 \n",
      "\n",
      "Epoch 398/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 398/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 398/1200, Iteration 3/12, Loss: 0.0091\n",
      "Epoch 398/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 398/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 398/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 398/1200, Iteration 7/12, Loss: 0.0087\n",
      "Epoch 398/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 398/1200, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 398/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 398/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 398/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 398/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003230, MRE: 0.026856, MAE: 0.003869 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003384, MRE: 0.020483, MAE: 0.004187 \n",
      "\n",
      "Epoch 399/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 399/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 399/1200, Iteration 3/12, Loss: 0.0082\n",
      "Epoch 399/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 399/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 399/1200, Iteration 6/12, Loss: 0.0074\n",
      "Epoch 399/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 399/1200, Iteration 8/12, Loss: 0.0070\n",
      "Epoch 399/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 399/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 399/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 399/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 399/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003273, MRE: 0.023252, MAE: 0.003843 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003242, MRE: 0.020582, MAE: 0.004131 \n",
      "\n",
      "Epoch 400/1200, Iteration 1/12, Loss: 0.0057\n",
      "Epoch 400/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 400/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 400/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 400/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 400/1200, Iteration 6/12, Loss: 0.0073\n",
      "Epoch 400/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 400/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 400/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 400/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 400/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 400/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 400/1200, Iteration 13/12, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003367, MRE: 0.023220, MAE: 0.003867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003245, MRE: 0.020833, MAE: 0.004148 \n",
      "\n",
      "Epoch 401/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 401/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 401/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 401/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 401/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 401/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 401/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 401/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 401/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 401/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 401/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 401/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 401/1200, Iteration 13/12, Loss: 0.0093\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003434, MRE: 0.025489, MAE: 0.004076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003857, MRE: 0.021176, MAE: 0.004313 \n",
      "\n",
      "Epoch 402/1200, Iteration 1/12, Loss: 0.0073\n",
      "Epoch 402/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 402/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 402/1200, Iteration 4/12, Loss: 0.0117\n",
      "Epoch 402/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 402/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 402/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 402/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 402/1200, Iteration 9/12, Loss: 0.0061\n",
      "Epoch 402/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 402/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 402/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 402/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003189, MRE: 0.022744, MAE: 0.003811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003324, MRE: 0.020711, MAE: 0.004157 \n",
      "\n",
      "Epoch 403/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 403/1200, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 403/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 403/1200, Iteration 4/12, Loss: 0.0055\n",
      "Epoch 403/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 403/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 403/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 403/1200, Iteration 8/12, Loss: 0.0085\n",
      "Epoch 403/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 403/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 403/1200, Iteration 11/12, Loss: 0.0097\n",
      "Epoch 403/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 403/1200, Iteration 13/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003178, MRE: 0.022908, MAE: 0.003786 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003310, MRE: 0.020988, MAE: 0.004195 \n",
      "\n",
      "Epoch 404/1200, Iteration 1/12, Loss: 0.0081\n",
      "Epoch 404/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 404/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 404/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 404/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 404/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 404/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 404/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 404/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 404/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 404/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 404/1200, Iteration 12/12, Loss: 0.0084\n",
      "Epoch 404/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003241, MRE: 0.023568, MAE: 0.003855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003212, MRE: 0.020963, MAE: 0.004261 \n",
      "\n",
      "Epoch 405/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 405/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 405/1200, Iteration 3/12, Loss: 0.0079\n",
      "Epoch 405/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 405/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 405/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 405/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 405/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 405/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 405/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 405/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 405/1200, Iteration 12/12, Loss: 0.0060\n",
      "Epoch 405/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003165, MRE: 0.022837, MAE: 0.003801 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003244, MRE: 0.020934, MAE: 0.004148 \n",
      "\n",
      "Epoch 406/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 406/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 406/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 406/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 406/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 406/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 406/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 406/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 406/1200, Iteration 9/12, Loss: 0.0062\n",
      "Epoch 406/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 406/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 406/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 406/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003147, MRE: 0.022840, MAE: 0.003797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003233, MRE: 0.020617, MAE: 0.004092 \n",
      "\n",
      "Epoch 407/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 407/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 407/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 407/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 407/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 407/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 407/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 407/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 407/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 407/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 407/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 407/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 407/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003418, MRE: 0.023655, MAE: 0.003866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003073, MRE: 0.020826, MAE: 0.004171 \n",
      "\n",
      "Epoch 408/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 408/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 408/1200, Iteration 3/12, Loss: 0.0085\n",
      "Epoch 408/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 408/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 408/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 408/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 408/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 408/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 408/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 408/1200, Iteration 11/12, Loss: 0.0058\n",
      "Epoch 408/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 408/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003531, MRE: 0.024476, MAE: 0.003990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003487, MRE: 0.020386, MAE: 0.004167 \n",
      "\n",
      "Epoch 409/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 409/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 409/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 409/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 409/1200, Iteration 5/12, Loss: 0.0074\n",
      "Epoch 409/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 409/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 409/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 409/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 409/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 409/1200, Iteration 11/12, Loss: 0.0057\n",
      "Epoch 409/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 409/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003177, MRE: 0.023029, MAE: 0.003811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003429, MRE: 0.020378, MAE: 0.004164 \n",
      "\n",
      "Epoch 410/1200, Iteration 1/12, Loss: 0.0066\n",
      "Epoch 410/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 410/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 410/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 410/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 410/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 410/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 410/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 410/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 410/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 410/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 410/1200, Iteration 12/12, Loss: 0.0084\n",
      "Epoch 410/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003156, MRE: 0.022991, MAE: 0.003802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003222, MRE: 0.020722, MAE: 0.004237 \n",
      "\n",
      "Epoch 411/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 411/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 411/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 411/1200, Iteration 4/12, Loss: 0.0076\n",
      "Epoch 411/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 411/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 411/1200, Iteration 7/12, Loss: 0.0072\n",
      "Epoch 411/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 411/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 411/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 411/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 411/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 411/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003111, MRE: 0.022983, MAE: 0.003789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003187, MRE: 0.020676, MAE: 0.004229 \n",
      "\n",
      "Epoch 412/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 412/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 412/1200, Iteration 3/12, Loss: 0.0064\n",
      "Epoch 412/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 412/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 412/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 412/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 412/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 412/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 412/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 412/1200, Iteration 11/12, Loss: 0.0083\n",
      "Epoch 412/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 412/1200, Iteration 13/12, Loss: 0.0072\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003303, MRE: 0.023368, MAE: 0.003867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003508, MRE: 0.020286, MAE: 0.004153 \n",
      "\n",
      "Epoch 413/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 413/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 413/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 413/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 413/1200, Iteration 5/12, Loss: 0.0066\n",
      "Epoch 413/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 413/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 413/1200, Iteration 8/12, Loss: 0.0101\n",
      "Epoch 413/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 413/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 413/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 413/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 413/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003157, MRE: 0.022598, MAE: 0.003777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003253, MRE: 0.020818, MAE: 0.004208 \n",
      "\n",
      "Epoch 414/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 414/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 414/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 414/1200, Iteration 4/12, Loss: 0.0057\n",
      "Epoch 414/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 414/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 414/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 414/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 414/1200, Iteration 9/12, Loss: 0.0072\n",
      "Epoch 414/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 414/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 414/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 414/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003136, MRE: 0.022935, MAE: 0.003778 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003262, MRE: 0.020685, MAE: 0.004203 \n",
      "\n",
      "Epoch 415/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 415/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 415/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 415/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 415/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 415/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 415/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 415/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 415/1200, Iteration 9/12, Loss: 0.0081\n",
      "Epoch 415/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 415/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 415/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 415/1200, Iteration 13/12, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003135, MRE: 0.022751, MAE: 0.003782 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003312, MRE: 0.020339, MAE: 0.004106 \n",
      "\n",
      "Epoch 416/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 416/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 416/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 416/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 416/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 416/1200, Iteration 6/12, Loss: 0.0096\n",
      "Epoch 416/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 416/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 416/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 416/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 416/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 416/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 416/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003290, MRE: 0.022732, MAE: 0.003795 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003303, MRE: 0.020269, MAE: 0.004113 \n",
      "\n",
      "Epoch 417/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 417/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 417/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 417/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 417/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 417/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 417/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 417/1200, Iteration 8/12, Loss: 0.0077\n",
      "Epoch 417/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 417/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 417/1200, Iteration 11/12, Loss: 0.0067\n",
      "Epoch 417/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 417/1200, Iteration 13/12, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003189, MRE: 0.023440, MAE: 0.003845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003563, MRE: 0.020345, MAE: 0.004195 \n",
      "\n",
      "Epoch 418/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 418/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 418/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 418/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 418/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 418/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 418/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 418/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 418/1200, Iteration 9/12, Loss: 0.0065\n",
      "Epoch 418/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 418/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 418/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 418/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003194, MRE: 0.022889, MAE: 0.003815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003247, MRE: 0.020939, MAE: 0.004206 \n",
      "\n",
      "Epoch 419/1200, Iteration 1/12, Loss: 0.0078\n",
      "Epoch 419/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 419/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 419/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 419/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 419/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 419/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 419/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 419/1200, Iteration 9/12, Loss: 0.0078\n",
      "Epoch 419/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 419/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 419/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 419/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003096, MRE: 0.023746, MAE: 0.003800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003415, MRE: 0.020391, MAE: 0.004138 \n",
      "\n",
      "Epoch 420/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 420/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 420/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 420/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 420/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 420/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 420/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 420/1200, Iteration 8/12, Loss: 0.0067\n",
      "Epoch 420/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 420/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 420/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 420/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 420/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.003485, MRE: 0.023894, MAE: 0.003960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003140, MRE: 0.021265, MAE: 0.004342 \n",
      "\n",
      "Epoch 421/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 421/1200, Iteration 2/12, Loss: 0.0102\n",
      "Epoch 421/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 421/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 421/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 421/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 421/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 421/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 421/1200, Iteration 9/12, Loss: 0.0068\n",
      "Epoch 421/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 421/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 421/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 421/1200, Iteration 13/12, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003134, MRE: 0.024103, MAE: 0.003851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003484, MRE: 0.020317, MAE: 0.004111 \n",
      "\n",
      "Epoch 422/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 422/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 422/1200, Iteration 3/12, Loss: 0.0054\n",
      "Epoch 422/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 422/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 422/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 422/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 422/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 422/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 422/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 422/1200, Iteration 11/12, Loss: 0.0080\n",
      "Epoch 422/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 422/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003115, MRE: 0.023089, MAE: 0.003789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003404, MRE: 0.020384, MAE: 0.004140 \n",
      "\n",
      "Epoch 423/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 423/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 423/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 423/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 423/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 423/1200, Iteration 6/12, Loss: 0.0082\n",
      "Epoch 423/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 423/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 423/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 423/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 423/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 423/1200, Iteration 12/12, Loss: 0.0083\n",
      "Epoch 423/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003091, MRE: 0.022826, MAE: 0.003770 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003297, MRE: 0.020362, MAE: 0.004078 \n",
      "\n",
      "Epoch 424/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 424/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 424/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 424/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 424/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 424/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 424/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 424/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 424/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 424/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 424/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 424/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 424/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003024, MRE: 0.022996, MAE: 0.003740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003175, MRE: 0.020412, MAE: 0.004140 \n",
      "\n",
      "Epoch 425/1200, Iteration 1/12, Loss: 0.0075\n",
      "Epoch 425/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 425/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 425/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 425/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 425/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 425/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 425/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 425/1200, Iteration 9/12, Loss: 0.0059\n",
      "Epoch 425/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 425/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 425/1200, Iteration 12/12, Loss: 0.0064\n",
      "Epoch 425/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003121, MRE: 0.023742, MAE: 0.003770 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003291, MRE: 0.020349, MAE: 0.004130 \n",
      "\n",
      "Epoch 426/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 426/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 426/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 426/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 426/1200, Iteration 5/12, Loss: 0.0085\n",
      "Epoch 426/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 426/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 426/1200, Iteration 8/12, Loss: 0.0067\n",
      "Epoch 426/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 426/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 426/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 426/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 426/1200, Iteration 13/12, Loss: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003414, MRE: 0.022932, MAE: 0.003828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003249, MRE: 0.020553, MAE: 0.004183 \n",
      "\n",
      "Epoch 427/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 427/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 427/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 427/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 427/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 427/1200, Iteration 6/12, Loss: 0.0054\n",
      "Epoch 427/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 427/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 427/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 427/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 427/1200, Iteration 11/12, Loss: 0.0108\n",
      "Epoch 427/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 427/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003027, MRE: 0.022529, MAE: 0.003744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003399, MRE: 0.020144, MAE: 0.004109 \n",
      "\n",
      "Epoch 428/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 428/1200, Iteration 2/12, Loss: 0.0086\n",
      "Epoch 428/1200, Iteration 3/12, Loss: 0.0086\n",
      "Epoch 428/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 428/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 428/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 428/1200, Iteration 7/12, Loss: 0.0066\n",
      "Epoch 428/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 428/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 428/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 428/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 428/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 428/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003083, MRE: 0.023034, MAE: 0.003760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003233, MRE: 0.020126, MAE: 0.004060 \n",
      "\n",
      "Epoch 429/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 429/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 429/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 429/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 429/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 429/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 429/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 429/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 429/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 429/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 429/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 429/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 429/1200, Iteration 13/12, Loss: 0.0169\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.003306, MRE: 0.023182, MAE: 0.003914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003845, MRE: 0.020434, MAE: 0.004229 \n",
      "\n",
      "Epoch 430/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 430/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 430/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 430/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 430/1200, Iteration 5/12, Loss: 0.0079\n",
      "Epoch 430/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 430/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 430/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 430/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 430/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 430/1200, Iteration 11/12, Loss: 0.0063\n",
      "Epoch 430/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 430/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003230, MRE: 0.023003, MAE: 0.003783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003258, MRE: 0.020450, MAE: 0.004081 \n",
      "\n",
      "Epoch 431/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 431/1200, Iteration 2/12, Loss: 0.0084\n",
      "Epoch 431/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 431/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 431/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 431/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 431/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 431/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 431/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 431/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 431/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 431/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 431/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002975, MRE: 0.022312, MAE: 0.003682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003150, MRE: 0.020531, MAE: 0.004125 \n",
      "\n",
      "Epoch 432/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 432/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 432/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 432/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 432/1200, Iteration 5/12, Loss: 0.0084\n",
      "Epoch 432/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 432/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 432/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 432/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 432/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 432/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 432/1200, Iteration 12/12, Loss: 0.0065\n",
      "Epoch 432/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003359, MRE: 0.023474, MAE: 0.003800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003172, MRE: 0.020425, MAE: 0.004126 \n",
      "\n",
      "Epoch 433/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 433/1200, Iteration 2/12, Loss: 0.0077\n",
      "Epoch 433/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 433/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 433/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 433/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 433/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 433/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 433/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 433/1200, Iteration 10/12, Loss: 0.0069\n",
      "Epoch 433/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 433/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 433/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.003011, MRE: 0.022908, MAE: 0.003756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003099, MRE: 0.020493, MAE: 0.004140 \n",
      "\n",
      "Epoch 434/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 434/1200, Iteration 2/12, Loss: 0.0057\n",
      "Epoch 434/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 434/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 434/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 434/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 434/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 434/1200, Iteration 8/12, Loss: 0.0089\n",
      "Epoch 434/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 434/1200, Iteration 10/12, Loss: 0.0068\n",
      "Epoch 434/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 434/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 434/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002974, MRE: 0.022546, MAE: 0.003707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003216, MRE: 0.020212, MAE: 0.004058 \n",
      "\n",
      "Epoch 435/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 435/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 435/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 435/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 435/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 435/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 435/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 435/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 435/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 435/1200, Iteration 10/12, Loss: 0.0069\n",
      "Epoch 435/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 435/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 435/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 97.38%, Avg loss: 0.003136, MRE: 0.022811, MAE: 0.003797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003065, MRE: 0.020911, MAE: 0.004157 \n",
      "\n",
      "Epoch 436/1200, Iteration 1/12, Loss: 0.0069\n",
      "Epoch 436/1200, Iteration 2/12, Loss: 0.0074\n",
      "Epoch 436/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 436/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 436/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 436/1200, Iteration 6/12, Loss: 0.0088\n",
      "Epoch 436/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 436/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 436/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 436/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 436/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 436/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 436/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002973, MRE: 0.022291, MAE: 0.003707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003260, MRE: 0.019986, MAE: 0.004051 \n",
      "\n",
      "Epoch 437/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 437/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 437/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 437/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 437/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 437/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 437/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 437/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 437/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 437/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 437/1200, Iteration 11/12, Loss: 0.0086\n",
      "Epoch 437/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 437/1200, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002978, MRE: 0.022932, MAE: 0.003743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003189, MRE: 0.019851, MAE: 0.004016 \n",
      "\n",
      "Epoch 438/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 438/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 438/1200, Iteration 3/12, Loss: 0.0063\n",
      "Epoch 438/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 438/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 438/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 438/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 438/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 438/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 438/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 438/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 438/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 438/1200, Iteration 13/12, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003049, MRE: 0.026380, MAE: 0.003760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003368, MRE: 0.020016, MAE: 0.004126 \n",
      "\n",
      "Epoch 439/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 439/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 439/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 439/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 439/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 439/1200, Iteration 6/12, Loss: 0.0066\n",
      "Epoch 439/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 439/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 439/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 439/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 439/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 439/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 439/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002987, MRE: 0.022698, MAE: 0.003720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003147, MRE: 0.020223, MAE: 0.004083 \n",
      "\n",
      "Epoch 440/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 440/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 440/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 440/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 440/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 440/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 440/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 440/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 440/1200, Iteration 9/12, Loss: 0.0054\n",
      "Epoch 440/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 440/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 440/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 440/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002966, MRE: 0.022338, MAE: 0.003713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.003119, MRE: 0.020840, MAE: 0.004153 \n",
      "\n",
      "Epoch 441/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 441/1200, Iteration 2/12, Loss: 0.0078\n",
      "Epoch 441/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 441/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 441/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 441/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 441/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 441/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 441/1200, Iteration 9/12, Loss: 0.0062\n",
      "Epoch 441/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 441/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 441/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 441/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002913, MRE: 0.022225, MAE: 0.003663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003129, MRE: 0.020205, MAE: 0.004068 \n",
      "\n",
      "Epoch 442/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 442/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 442/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 442/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 442/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 442/1200, Iteration 6/12, Loss: 0.0074\n",
      "Epoch 442/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 442/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 442/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 442/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 442/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 442/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 442/1200, Iteration 13/12, Loss: 0.0149\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.003212, MRE: 0.024476, MAE: 0.003969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003763, MRE: 0.020377, MAE: 0.004182 \n",
      "\n",
      "Epoch 443/1200, Iteration 1/12, Loss: 0.0064\n",
      "Epoch 443/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 443/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 443/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 443/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 443/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 443/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 443/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 443/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 443/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 443/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 443/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 443/1200, Iteration 13/12, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003007, MRE: 0.023170, MAE: 0.003720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003434, MRE: 0.020012, MAE: 0.004120 \n",
      "\n",
      "Epoch 444/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 444/1200, Iteration 2/12, Loss: 0.0060\n",
      "Epoch 444/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 444/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 444/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 444/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 444/1200, Iteration 7/12, Loss: 0.0074\n",
      "Epoch 444/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 444/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 444/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 444/1200, Iteration 11/12, Loss: 0.0076\n",
      "Epoch 444/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 444/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002967, MRE: 0.022390, MAE: 0.003689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003179, MRE: 0.020091, MAE: 0.004058 \n",
      "\n",
      "Epoch 445/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 445/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 445/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 445/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 445/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 445/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 445/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 445/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 445/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 445/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 445/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 445/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 445/1200, Iteration 13/12, Loss: 0.0141\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.003173, MRE: 0.023115, MAE: 0.003737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003363, MRE: 0.020063, MAE: 0.004064 \n",
      "\n",
      "Epoch 446/1200, Iteration 1/12, Loss: 0.0059\n",
      "Epoch 446/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 446/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 446/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 446/1200, Iteration 5/12, Loss: 0.0069\n",
      "Epoch 446/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 446/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 446/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 446/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 446/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 446/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 446/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 446/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002993, MRE: 0.023035, MAE: 0.003747 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003507, MRE: 0.019912, MAE: 0.004093 \n",
      "\n",
      "Epoch 447/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 447/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 447/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 447/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 447/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 447/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 447/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 447/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 447/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 447/1200, Iteration 10/12, Loss: 0.0084\n",
      "Epoch 447/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 447/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 447/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003086, MRE: 0.022883, MAE: 0.003699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003140, MRE: 0.020123, MAE: 0.004059 \n",
      "\n",
      "Epoch 448/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 448/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 448/1200, Iteration 3/12, Loss: 0.0059\n",
      "Epoch 448/1200, Iteration 4/12, Loss: 0.0069\n",
      "Epoch 448/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 448/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 448/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 448/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 448/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 448/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 448/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 448/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 448/1200, Iteration 13/12, Loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002882, MRE: 0.022428, MAE: 0.003646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003026, MRE: 0.020244, MAE: 0.004038 \n",
      "\n",
      "Epoch 449/1200, Iteration 1/12, Loss: 0.0062\n",
      "Epoch 449/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 449/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 449/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 449/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 449/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 449/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 449/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 449/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 449/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 449/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 449/1200, Iteration 12/12, Loss: 0.0068\n",
      "Epoch 449/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002969, MRE: 0.022665, MAE: 0.003734 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003263, MRE: 0.019857, MAE: 0.004007 \n",
      "\n",
      "Epoch 450/1200, Iteration 1/12, Loss: 0.0062\n",
      "Epoch 450/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 450/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 450/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 450/1200, Iteration 5/12, Loss: 0.0070\n",
      "Epoch 450/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 450/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 450/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 450/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 450/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 450/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 450/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 450/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002878, MRE: 0.022079, MAE: 0.003654 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003155, MRE: 0.020317, MAE: 0.004060 \n",
      "\n",
      "Epoch 451/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 451/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 451/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 451/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 451/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 451/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 451/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 451/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 451/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 451/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 451/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 451/1200, Iteration 12/12, Loss: 0.0074\n",
      "Epoch 451/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003048, MRE: 0.022558, MAE: 0.003686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003124, MRE: 0.019838, MAE: 0.004015 \n",
      "\n",
      "Epoch 452/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 452/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 452/1200, Iteration 3/12, Loss: 0.0074\n",
      "Epoch 452/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 452/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 452/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 452/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 452/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 452/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 452/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 452/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 452/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 452/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002824, MRE: 0.022147, MAE: 0.003607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003050, MRE: 0.019946, MAE: 0.004005 \n",
      "\n",
      "Epoch 453/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 453/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 453/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 453/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 453/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 453/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 453/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 453/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 453/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 453/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 453/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 453/1200, Iteration 12/12, Loss: 0.0087\n",
      "Epoch 453/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002846, MRE: 0.021951, MAE: 0.003635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003206, MRE: 0.020243, MAE: 0.004088 \n",
      "\n",
      "Epoch 454/1200, Iteration 1/12, Loss: 0.0081\n",
      "Epoch 454/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 454/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 454/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 454/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 454/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 454/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 454/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 454/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 454/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 454/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 454/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 454/1200, Iteration 13/12, Loss: 0.0120\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002957, MRE: 0.026491, MAE: 0.003729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003475, MRE: 0.019817, MAE: 0.004092 \n",
      "\n",
      "Epoch 455/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 455/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 455/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 455/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 455/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 455/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 455/1200, Iteration 7/12, Loss: 0.0083\n",
      "Epoch 455/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 455/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 455/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 455/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 455/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 455/1200, Iteration 13/12, Loss: 0.0066\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002837, MRE: 0.022332, MAE: 0.003650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003045, MRE: 0.020179, MAE: 0.004093 \n",
      "\n",
      "Epoch 456/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 456/1200, Iteration 2/12, Loss: 0.0062\n",
      "Epoch 456/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 456/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 456/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 456/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 456/1200, Iteration 7/12, Loss: 0.0055\n",
      "Epoch 456/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 456/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 456/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 456/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 456/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 456/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002883, MRE: 0.022335, MAE: 0.003650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003072, MRE: 0.019959, MAE: 0.004040 \n",
      "\n",
      "Epoch 457/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 457/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 457/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 457/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 457/1200, Iteration 5/12, Loss: 0.0057\n",
      "Epoch 457/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 457/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 457/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 457/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 457/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 457/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 457/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 457/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002867, MRE: 0.022275, MAE: 0.003671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003178, MRE: 0.019633, MAE: 0.003961 \n",
      "\n",
      "Epoch 458/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 458/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 458/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 458/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 458/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 458/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 458/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 458/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 458/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 458/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 458/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 458/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 458/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002895, MRE: 0.022104, MAE: 0.003647 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003072, MRE: 0.020035, MAE: 0.004014 \n",
      "\n",
      "Epoch 459/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 459/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 459/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 459/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 459/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 459/1200, Iteration 6/12, Loss: 0.0084\n",
      "Epoch 459/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 459/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 459/1200, Iteration 9/12, Loss: 0.0073\n",
      "Epoch 459/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 459/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 459/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 459/1200, Iteration 13/12, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002809, MRE: 0.021938, MAE: 0.003616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003080, MRE: 0.020029, MAE: 0.004012 \n",
      "\n",
      "Epoch 460/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 460/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 460/1200, Iteration 3/12, Loss: 0.0064\n",
      "Epoch 460/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 460/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 460/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 460/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 460/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 460/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 460/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 460/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 460/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 460/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002967, MRE: 0.022348, MAE: 0.003656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002958, MRE: 0.020065, MAE: 0.004045 \n",
      "\n",
      "Epoch 461/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 461/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 461/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 461/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 461/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 461/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 461/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 461/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 461/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 461/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 461/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 461/1200, Iteration 12/12, Loss: 0.0066\n",
      "Epoch 461/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002902, MRE: 0.022383, MAE: 0.003633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003060, MRE: 0.020071, MAE: 0.004070 \n",
      "\n",
      "Epoch 462/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 462/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 462/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 462/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 462/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 462/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 462/1200, Iteration 7/12, Loss: 0.0069\n",
      "Epoch 462/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 462/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 462/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 462/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 462/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 462/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002822, MRE: 0.022027, MAE: 0.003640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003295, MRE: 0.019646, MAE: 0.004052 \n",
      "\n",
      "Epoch 463/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 463/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 463/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 463/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 463/1200, Iteration 5/12, Loss: 0.0048\n",
      "Epoch 463/1200, Iteration 6/12, Loss: 0.0099\n",
      "Epoch 463/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 463/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 463/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 463/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 463/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 463/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 463/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.003032, MRE: 0.022032, MAE: 0.003638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003146, MRE: 0.019723, MAE: 0.004028 \n",
      "\n",
      "Epoch 464/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 464/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 464/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 464/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 464/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 464/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 464/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 464/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 464/1200, Iteration 9/12, Loss: 0.0060\n",
      "Epoch 464/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 464/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 464/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 464/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.003070, MRE: 0.022061, MAE: 0.003630 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002976, MRE: 0.019683, MAE: 0.003946 \n",
      "\n",
      "Epoch 465/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 465/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 465/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 465/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 465/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 465/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 465/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 465/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 465/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 465/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 465/1200, Iteration 11/12, Loss: 0.0102\n",
      "Epoch 465/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 465/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002810, MRE: 0.022332, MAE: 0.003595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003016, MRE: 0.019460, MAE: 0.003926 \n",
      "\n",
      "Epoch 466/1200, Iteration 1/12, Loss: 0.0084\n",
      "Epoch 466/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 466/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 466/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 466/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 466/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 466/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 466/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 466/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 466/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 466/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 466/1200, Iteration 12/12, Loss: 0.0063\n",
      "Epoch 466/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.003079, MRE: 0.022277, MAE: 0.003691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003187, MRE: 0.019434, MAE: 0.003954 \n",
      "\n",
      "Epoch 467/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 467/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 467/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 467/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 467/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 467/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 467/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 467/1200, Iteration 8/12, Loss: 0.0081\n",
      "Epoch 467/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 467/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 467/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 467/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 467/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002921, MRE: 0.022257, MAE: 0.003642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003124, MRE: 0.019393, MAE: 0.003945 \n",
      "\n",
      "Epoch 468/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 468/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 468/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 468/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 468/1200, Iteration 5/12, Loss: 0.0071\n",
      "Epoch 468/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 468/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 468/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 468/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 468/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 468/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 468/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 468/1200, Iteration 13/12, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002864, MRE: 0.022626, MAE: 0.003661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003320, MRE: 0.019636, MAE: 0.004045 \n",
      "\n",
      "Epoch 469/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 469/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 469/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 469/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 469/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 469/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 469/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 469/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 469/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 469/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 469/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 469/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 469/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002897, MRE: 0.021995, MAE: 0.003626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003139, MRE: 0.019687, MAE: 0.004023 \n",
      "\n",
      "Epoch 470/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 470/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 470/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 470/1200, Iteration 4/12, Loss: 0.0061\n",
      "Epoch 470/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 470/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 470/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 470/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 470/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 470/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 470/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 470/1200, Iteration 12/12, Loss: 0.0076\n",
      "Epoch 470/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002786, MRE: 0.022015, MAE: 0.003626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002932, MRE: 0.019869, MAE: 0.004027 \n",
      "\n",
      "Epoch 471/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 471/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 471/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 471/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 471/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 471/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 471/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 471/1200, Iteration 8/12, Loss: 0.0050\n",
      "Epoch 471/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 471/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 471/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 471/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 471/1200, Iteration 13/12, Loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002801, MRE: 0.022010, MAE: 0.003603 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002858, MRE: 0.019570, MAE: 0.003889 \n",
      "\n",
      "Epoch 472/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 472/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 472/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 472/1200, Iteration 4/12, Loss: 0.0084\n",
      "Epoch 472/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 472/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 472/1200, Iteration 7/12, Loss: 0.0060\n",
      "Epoch 472/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 472/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 472/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 472/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 472/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 472/1200, Iteration 13/12, Loss: 0.0077\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002843, MRE: 0.022169, MAE: 0.003621 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002796, MRE: 0.019496, MAE: 0.003909 \n",
      "\n",
      "Epoch 473/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 473/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 473/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 473/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 473/1200, Iteration 5/12, Loss: 0.0062\n",
      "Epoch 473/1200, Iteration 6/12, Loss: 0.0072\n",
      "Epoch 473/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 473/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 473/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 473/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 473/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 473/1200, Iteration 12/12, Loss: 0.0062\n",
      "Epoch 473/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.002746, MRE: 0.021795, MAE: 0.003563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002953, MRE: 0.019743, MAE: 0.003901 \n",
      "\n",
      "Epoch 474/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 474/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 474/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 474/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 474/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 474/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 474/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 474/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 474/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 474/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 474/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 474/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 474/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002872, MRE: 0.021998, MAE: 0.003595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002905, MRE: 0.019319, MAE: 0.003897 \n",
      "\n",
      "Epoch 475/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 475/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 475/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 475/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 475/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 475/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 475/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 475/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 475/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 475/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 475/1200, Iteration 11/12, Loss: 0.0062\n",
      "Epoch 475/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 475/1200, Iteration 13/12, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002762, MRE: 0.021938, MAE: 0.003596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003057, MRE: 0.019475, MAE: 0.003973 \n",
      "\n",
      "Epoch 476/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 476/1200, Iteration 2/12, Loss: 0.0056\n",
      "Epoch 476/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 476/1200, Iteration 4/12, Loss: 0.0086\n",
      "Epoch 476/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 476/1200, Iteration 6/12, Loss: 0.0056\n",
      "Epoch 476/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 476/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 476/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 476/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 476/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 476/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 476/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002947, MRE: 0.022555, MAE: 0.003659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003020, MRE: 0.019249, MAE: 0.003889 \n",
      "\n",
      "Epoch 477/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 477/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 477/1200, Iteration 3/12, Loss: 0.0075\n",
      "Epoch 477/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 477/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 477/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 477/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 477/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 477/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 477/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 477/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 477/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 477/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002751, MRE: 0.022208, MAE: 0.003569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002867, MRE: 0.019768, MAE: 0.003949 \n",
      "\n",
      "Epoch 478/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 478/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 478/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 478/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 478/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 478/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 478/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 478/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 478/1200, Iteration 9/12, Loss: 0.0070\n",
      "Epoch 478/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 478/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 478/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 478/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002851, MRE: 0.022539, MAE: 0.003635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002908, MRE: 0.019812, MAE: 0.004000 \n",
      "\n",
      "Epoch 479/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 479/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 479/1200, Iteration 3/12, Loss: 0.0047\n",
      "Epoch 479/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 479/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 479/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 479/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 479/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 479/1200, Iteration 9/12, Loss: 0.0076\n",
      "Epoch 479/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 479/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 479/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 479/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002910, MRE: 0.021915, MAE: 0.003592 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002907, MRE: 0.019843, MAE: 0.003977 \n",
      "\n",
      "Epoch 480/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 480/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 480/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 480/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 480/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 480/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 480/1200, Iteration 7/12, Loss: 0.0064\n",
      "Epoch 480/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 480/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 480/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 480/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 480/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 480/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002737, MRE: 0.022204, MAE: 0.003569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002800, MRE: 0.019873, MAE: 0.003965 \n",
      "\n",
      "Epoch 481/1200, Iteration 1/12, Loss: 0.0054\n",
      "Epoch 481/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 481/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 481/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 481/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 481/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 481/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 481/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 481/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 481/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 481/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 481/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 481/1200, Iteration 13/12, Loss: 0.0057\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002796, MRE: 0.022163, MAE: 0.003589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002905, MRE: 0.019399, MAE: 0.003938 \n",
      "\n",
      "Epoch 482/1200, Iteration 1/12, Loss: 0.0072\n",
      "Epoch 482/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 482/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 482/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 482/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 482/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 482/1200, Iteration 7/12, Loss: 0.0057\n",
      "Epoch 482/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 482/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 482/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 482/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 482/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 482/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.25%, Avg loss: 0.002883, MRE: 0.021945, MAE: 0.003626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002842, MRE: 0.020235, MAE: 0.003989 \n",
      "\n",
      "Epoch 483/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 483/1200, Iteration 2/12, Loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 483/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 483/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 483/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 483/1200, Iteration 7/12, Loss: 0.0087\n",
      "Epoch 483/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 483/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 483/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 483/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 483/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 483/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002695, MRE: 0.021670, MAE: 0.003542 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002889, MRE: 0.019521, MAE: 0.003906 \n",
      "\n",
      "Epoch 484/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 484/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 484/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 484/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 484/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 484/1200, Iteration 6/12, Loss: 0.0087\n",
      "Epoch 484/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 484/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 484/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 484/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 484/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 484/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 484/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002724, MRE: 0.022070, MAE: 0.003552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002800, MRE: 0.019462, MAE: 0.003931 \n",
      "\n",
      "Epoch 485/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 485/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 485/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 485/1200, Iteration 4/12, Loss: 0.0074\n",
      "Epoch 485/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 485/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 485/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 485/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 485/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 485/1200, Iteration 10/12, Loss: 0.0090\n",
      "Epoch 485/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 485/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 485/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002753, MRE: 0.021466, MAE: 0.003570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002930, MRE: 0.019572, MAE: 0.003866 \n",
      "\n",
      "Epoch 486/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 486/1200, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 486/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 486/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 486/1200, Iteration 5/12, Loss: 0.0070\n",
      "Epoch 486/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 486/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 486/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 486/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 486/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 486/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 486/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 486/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002880, MRE: 0.021764, MAE: 0.003605 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002839, MRE: 0.019277, MAE: 0.003851 \n",
      "\n",
      "Epoch 487/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 487/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 487/1200, Iteration 3/12, Loss: 0.0061\n",
      "Epoch 487/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 487/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 487/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 487/1200, Iteration 7/12, Loss: 0.0076\n",
      "Epoch 487/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 487/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 487/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 487/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 487/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 487/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002708, MRE: 0.021536, MAE: 0.003538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002847, MRE: 0.019255, MAE: 0.003859 \n",
      "\n",
      "Epoch 488/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 488/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 488/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 488/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 488/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 488/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 488/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 488/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 488/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 488/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 488/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 488/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 488/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002655, MRE: 0.021642, MAE: 0.003519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002852, MRE: 0.019405, MAE: 0.003880 \n",
      "\n",
      "Epoch 489/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 489/1200, Iteration 2/12, Loss: 0.0057\n",
      "Epoch 489/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 489/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 489/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 489/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 489/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 489/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 489/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 489/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 489/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 489/1200, Iteration 12/12, Loss: 0.0068\n",
      "Epoch 489/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002726, MRE: 0.021824, MAE: 0.003551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002839, MRE: 0.019370, MAE: 0.003906 \n",
      "\n",
      "Epoch 490/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 490/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 490/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 490/1200, Iteration 4/12, Loss: 0.0050\n",
      "Epoch 490/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 490/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 490/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 490/1200, Iteration 8/12, Loss: 0.0080\n",
      "Epoch 490/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 490/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 490/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 490/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 490/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002654, MRE: 0.025523, MAE: 0.003566 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002951, MRE: 0.019019, MAE: 0.003844 \n",
      "\n",
      "Epoch 491/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 491/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 491/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 491/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 491/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 491/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 491/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 491/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 491/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 491/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 491/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 491/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 491/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002703, MRE: 0.021575, MAE: 0.003555 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003008, MRE: 0.019240, MAE: 0.003906 \n",
      "\n",
      "Epoch 492/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 492/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 492/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 492/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 492/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 492/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 492/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 492/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 492/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 492/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 492/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 492/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 492/1200, Iteration 13/12, Loss: 0.0061\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002643, MRE: 0.021462, MAE: 0.003521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003061, MRE: 0.019022, MAE: 0.003879 \n",
      "\n",
      "Epoch 493/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 493/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 493/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 493/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 493/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 493/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 493/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 493/1200, Iteration 8/12, Loss: 0.0057\n",
      "Epoch 493/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 493/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 493/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 493/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 493/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002622, MRE: 0.021309, MAE: 0.003515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002978, MRE: 0.019217, MAE: 0.003907 \n",
      "\n",
      "Epoch 494/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 494/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 494/1200, Iteration 3/12, Loss: 0.0069\n",
      "Epoch 494/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 494/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 494/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 494/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 494/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 494/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 494/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 494/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 494/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 494/1200, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002645, MRE: 0.022046, MAE: 0.003538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002788, MRE: 0.019457, MAE: 0.003930 \n",
      "\n",
      "Epoch 495/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 495/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 495/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 495/1200, Iteration 4/12, Loss: 0.0052\n",
      "Epoch 495/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 495/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 495/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 495/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 495/1200, Iteration 9/12, Loss: 0.0054\n",
      "Epoch 495/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 495/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 495/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 495/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002651, MRE: 0.021539, MAE: 0.003525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002760, MRE: 0.019430, MAE: 0.003911 \n",
      "\n",
      "Epoch 496/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 496/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 496/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 496/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 496/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 496/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 496/1200, Iteration 7/12, Loss: 0.0065\n",
      "Epoch 496/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 496/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 496/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 496/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 496/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 496/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002683, MRE: 0.021705, MAE: 0.003513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002857, MRE: 0.018990, MAE: 0.003796 \n",
      "\n",
      "Epoch 497/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 497/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 497/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 497/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 497/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 497/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 497/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 497/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 497/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 497/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 497/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 497/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 497/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002647, MRE: 0.021505, MAE: 0.003513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002792, MRE: 0.019614, MAE: 0.003905 \n",
      "\n",
      "Epoch 498/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 498/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 498/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 498/1200, Iteration 4/12, Loss: 0.0056\n",
      "Epoch 498/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 498/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 498/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 498/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 498/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 498/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 498/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 498/1200, Iteration 12/12, Loss: 0.0076\n",
      "Epoch 498/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002593, MRE: 0.021547, MAE: 0.003481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002887, MRE: 0.018864, MAE: 0.003783 \n",
      "\n",
      "Epoch 499/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 499/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 499/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 499/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 499/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 499/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 499/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 499/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 499/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 499/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 499/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 499/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 499/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002646, MRE: 0.021980, MAE: 0.003538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003041, MRE: 0.018930, MAE: 0.003851 \n",
      "\n",
      "Epoch 500/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 500/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 500/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 500/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 500/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 500/1200, Iteration 6/12, Loss: 0.0089\n",
      "Epoch 500/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 500/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 500/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 500/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 500/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 500/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 500/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002769, MRE: 0.021424, MAE: 0.003531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002970, MRE: 0.019422, MAE: 0.003874 \n",
      "\n",
      "Epoch 501/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 501/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 501/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 501/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 501/1200, Iteration 5/12, Loss: 0.0077\n",
      "Epoch 501/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 501/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 501/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 501/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 501/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 501/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 501/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 501/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002634, MRE: 0.021378, MAE: 0.003512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002889, MRE: 0.019340, MAE: 0.003871 \n",
      "\n",
      "Epoch 502/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 502/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 502/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 502/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 502/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 502/1200, Iteration 6/12, Loss: 0.0075\n",
      "Epoch 502/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 502/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 502/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 502/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 502/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 502/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 502/1200, Iteration 13/12, Loss: 0.0097\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002690, MRE: 0.021987, MAE: 0.003564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003061, MRE: 0.018959, MAE: 0.003828 \n",
      "\n",
      "Epoch 503/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 503/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 503/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 503/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 503/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 503/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 503/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 503/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 503/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 503/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 503/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 503/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 503/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002605, MRE: 0.021758, MAE: 0.003494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003020, MRE: 0.019040, MAE: 0.003866 \n",
      "\n",
      "Epoch 504/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 504/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 504/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 504/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 504/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 504/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 504/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 504/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 504/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 504/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 504/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 504/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 504/1200, Iteration 13/12, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002692, MRE: 0.021702, MAE: 0.003605 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003137, MRE: 0.018917, MAE: 0.003833 \n",
      "\n",
      "Epoch 505/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 505/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 505/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 505/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 505/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 505/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 505/1200, Iteration 7/12, Loss: 0.0075\n",
      "Epoch 505/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 505/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 505/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 505/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 505/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 505/1200, Iteration 13/12, Loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002722, MRE: 0.021448, MAE: 0.003574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002915, MRE: 0.019499, MAE: 0.003863 \n",
      "\n",
      "Epoch 506/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 506/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 506/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 506/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 506/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 506/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 506/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 506/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 506/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 506/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 506/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 506/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 506/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002648, MRE: 0.021394, MAE: 0.003519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002777, MRE: 0.019373, MAE: 0.003915 \n",
      "\n",
      "Epoch 507/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 507/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 507/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 507/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 507/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 507/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 507/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 507/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 507/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 507/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 507/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 507/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 507/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.002686, MRE: 0.021810, MAE: 0.003554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002798, MRE: 0.020062, MAE: 0.003953 \n",
      "\n",
      "Epoch 508/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 508/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 508/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 508/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 508/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 508/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 508/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 508/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 508/1200, Iteration 9/12, Loss: 0.0063\n",
      "Epoch 508/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 508/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 508/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 508/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002537, MRE: 0.021483, MAE: 0.003441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002767, MRE: 0.019023, MAE: 0.003849 \n",
      "\n",
      "Epoch 509/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 509/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 509/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 509/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 509/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 509/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 509/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 509/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 509/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 509/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 509/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 509/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 509/1200, Iteration 13/12, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 97.62%, Avg loss: 0.002661, MRE: 0.022100, MAE: 0.003555 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002730, MRE: 0.019903, MAE: 0.003966 \n",
      "\n",
      "Epoch 510/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 510/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 510/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 510/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 510/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 510/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 510/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 510/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 510/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 510/1200, Iteration 10/12, Loss: 0.0068\n",
      "Epoch 510/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 510/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 510/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002970, MRE: 0.021664, MAE: 0.003525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002698, MRE: 0.019178, MAE: 0.003833 \n",
      "\n",
      "Epoch 511/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 511/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 511/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 511/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 511/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 511/1200, Iteration 6/12, Loss: 0.0103\n",
      "Epoch 511/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 511/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 511/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 511/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 511/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 511/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 511/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002574, MRE: 0.021335, MAE: 0.003480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002805, MRE: 0.019420, MAE: 0.003865 \n",
      "\n",
      "Epoch 512/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 512/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 512/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 512/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 512/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 512/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 512/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 512/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 512/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 512/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 512/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 512/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 512/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002520, MRE: 0.021233, MAE: 0.003434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002870, MRE: 0.018741, MAE: 0.003803 \n",
      "\n",
      "Epoch 513/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 513/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 513/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 513/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 513/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 513/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 513/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 513/1200, Iteration 8/12, Loss: 0.0063\n",
      "Epoch 513/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 513/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 513/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 513/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 513/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002507, MRE: 0.021040, MAE: 0.003414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002840, MRE: 0.018782, MAE: 0.003762 \n",
      "\n",
      "Epoch 514/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 514/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 514/1200, Iteration 3/12, Loss: 0.0047\n",
      "Epoch 514/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 514/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 514/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 514/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 514/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 514/1200, Iteration 9/12, Loss: 0.0080\n",
      "Epoch 514/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 514/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 514/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 514/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002584, MRE: 0.024597, MAE: 0.003517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002805, MRE: 0.019201, MAE: 0.003894 \n",
      "\n",
      "Epoch 515/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 515/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 515/1200, Iteration 3/12, Loss: 0.0067\n",
      "Epoch 515/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 515/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 515/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 515/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 515/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 515/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 515/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 515/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 515/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 515/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002809, MRE: 0.022132, MAE: 0.003579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002935, MRE: 0.018634, MAE: 0.003755 \n",
      "\n",
      "Epoch 516/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 516/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 516/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 516/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 516/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 516/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 516/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 516/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 516/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 516/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 516/1200, Iteration 11/12, Loss: 0.0063\n",
      "Epoch 516/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 516/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002552, MRE: 0.021299, MAE: 0.003449 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002722, MRE: 0.018605, MAE: 0.003734 \n",
      "\n",
      "Epoch 517/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 517/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 517/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 517/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 517/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 517/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 517/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 517/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 517/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 517/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 517/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 517/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 517/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002516, MRE: 0.021086, MAE: 0.003446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002797, MRE: 0.018906, MAE: 0.003828 \n",
      "\n",
      "Epoch 518/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 518/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 518/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 518/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 518/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 518/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 518/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 518/1200, Iteration 8/12, Loss: 0.0076\n",
      "Epoch 518/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 518/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 518/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 518/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 518/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002501, MRE: 0.020846, MAE: 0.003413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002721, MRE: 0.018984, MAE: 0.003804 \n",
      "\n",
      "Epoch 519/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 519/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 519/1200, Iteration 3/12, Loss: 0.0065\n",
      "Epoch 519/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 519/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 519/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 519/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 519/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 519/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 519/1200, Iteration 10/12, Loss: 0.0056\n",
      "Epoch 519/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 519/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 519/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002589, MRE: 0.021314, MAE: 0.003471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002723, MRE: 0.019535, MAE: 0.003871 \n",
      "\n",
      "Epoch 520/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 520/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 520/1200, Iteration 3/12, Loss: 0.0073\n",
      "Epoch 520/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 520/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 520/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 520/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 520/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 520/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 520/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 520/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 520/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 520/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002548, MRE: 0.021035, MAE: 0.003452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002783, MRE: 0.019011, MAE: 0.003780 \n",
      "\n",
      "Epoch 521/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 521/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 521/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 521/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 521/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 521/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 521/1200, Iteration 7/12, Loss: 0.0066\n",
      "Epoch 521/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 521/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 521/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 521/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 521/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 521/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002481, MRE: 0.021325, MAE: 0.003418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002809, MRE: 0.019071, MAE: 0.003855 \n",
      "\n",
      "Epoch 522/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 522/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 522/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 522/1200, Iteration 4/12, Loss: 0.0052\n",
      "Epoch 522/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 522/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 522/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 522/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 522/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 522/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 522/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 522/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 522/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002547, MRE: 0.020889, MAE: 0.003432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002659, MRE: 0.018956, MAE: 0.003772 \n",
      "\n",
      "Epoch 523/1200, Iteration 1/12, Loss: 0.0052\n",
      "Epoch 523/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 523/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 523/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 523/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 523/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 523/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 523/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 523/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 523/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 523/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 523/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 523/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002529, MRE: 0.022151, MAE: 0.003460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002608, MRE: 0.018944, MAE: 0.003800 \n",
      "\n",
      "Epoch 524/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 524/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 524/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 524/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 524/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 524/1200, Iteration 6/12, Loss: 0.0068\n",
      "Epoch 524/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 524/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 524/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 524/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 524/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 524/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 524/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002550, MRE: 0.021111, MAE: 0.003456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002709, MRE: 0.019280, MAE: 0.003827 \n",
      "\n",
      "Epoch 525/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 525/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 525/1200, Iteration 3/12, Loss: 0.0063\n",
      "Epoch 525/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 525/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 525/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 525/1200, Iteration 7/12, Loss: 0.0097\n",
      "Epoch 525/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 525/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 525/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 525/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 525/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 525/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002463, MRE: 0.020780, MAE: 0.003403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002812, MRE: 0.018958, MAE: 0.003838 \n",
      "\n",
      "Epoch 526/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 526/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 526/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 526/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 526/1200, Iteration 5/12, Loss: 0.0097\n",
      "Epoch 526/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 526/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 526/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 526/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 526/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 526/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 526/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 526/1200, Iteration 13/12, Loss: 0.0086\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002543, MRE: 0.022379, MAE: 0.003499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002993, MRE: 0.018865, MAE: 0.003829 \n",
      "\n",
      "Epoch 527/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 527/1200, Iteration 2/12, Loss: 0.0057\n",
      "Epoch 527/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 527/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 527/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 527/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 527/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 527/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 527/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 527/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 527/1200, Iteration 11/12, Loss: 0.0072\n",
      "Epoch 527/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 527/1200, Iteration 13/12, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002653, MRE: 0.022010, MAE: 0.003529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003062, MRE: 0.018730, MAE: 0.003813 \n",
      "\n",
      "Epoch 528/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 528/1200, Iteration 2/12, Loss: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 528/1200, Iteration 4/12, Loss: 0.0060\n",
      "Epoch 528/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 528/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 528/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 528/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 528/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 528/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 528/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 528/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 528/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002654, MRE: 0.021672, MAE: 0.003501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002970, MRE: 0.018704, MAE: 0.003798 \n",
      "\n",
      "Epoch 529/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 529/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 529/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 529/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 529/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 529/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 529/1200, Iteration 7/12, Loss: 0.0075\n",
      "Epoch 529/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 529/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 529/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 529/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 529/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 529/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002508, MRE: 0.021296, MAE: 0.003460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002701, MRE: 0.019460, MAE: 0.003903 \n",
      "\n",
      "Epoch 530/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 530/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 530/1200, Iteration 3/12, Loss: 0.0076\n",
      "Epoch 530/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 530/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 530/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 530/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 530/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 530/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 530/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 530/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 530/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 530/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 97.75%, Avg loss: 0.002532, MRE: 0.021011, MAE: 0.003463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002692, MRE: 0.019595, MAE: 0.003874 \n",
      "\n",
      "Epoch 531/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 531/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 531/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 531/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 531/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 531/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 531/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 531/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 531/1200, Iteration 9/12, Loss: 0.0067\n",
      "Epoch 531/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 531/1200, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 531/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 531/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002473, MRE: 0.021055, MAE: 0.003403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002768, MRE: 0.018605, MAE: 0.003756 \n",
      "\n",
      "Epoch 532/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 532/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 532/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 532/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 532/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 532/1200, Iteration 6/12, Loss: 0.0059\n",
      "Epoch 532/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 532/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 532/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 532/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 532/1200, Iteration 11/12, Loss: 0.0058\n",
      "Epoch 532/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 532/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002676, MRE: 0.021283, MAE: 0.003470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002797, MRE: 0.018619, MAE: 0.003777 \n",
      "\n",
      "Epoch 533/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 533/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 533/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 533/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 533/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 533/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 533/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 533/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 533/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 533/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 533/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 533/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 533/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002435, MRE: 0.021043, MAE: 0.003394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002817, MRE: 0.018553, MAE: 0.003811 \n",
      "\n",
      "Epoch 534/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 534/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 534/1200, Iteration 3/12, Loss: 0.0054\n",
      "Epoch 534/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 534/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 534/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 534/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 534/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 534/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 534/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 534/1200, Iteration 11/12, Loss: 0.0069\n",
      "Epoch 534/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 534/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002422, MRE: 0.020744, MAE: 0.003403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002794, MRE: 0.018861, MAE: 0.003818 \n",
      "\n",
      "Epoch 535/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 535/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 535/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 535/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 535/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 535/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 535/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 535/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 535/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 535/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 535/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 535/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 535/1200, Iteration 13/12, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002538, MRE: 0.021473, MAE: 0.003463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002945, MRE: 0.018495, MAE: 0.003752 \n",
      "\n",
      "Epoch 536/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 536/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 536/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 536/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 536/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 536/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 536/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 536/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 536/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 536/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 536/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 536/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 536/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002426, MRE: 0.021263, MAE: 0.003415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002825, MRE: 0.018656, MAE: 0.003787 \n",
      "\n",
      "Epoch 537/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 537/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 537/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 537/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 537/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 537/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 537/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 537/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 537/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 537/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 537/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 537/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 537/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002471, MRE: 0.020935, MAE: 0.003415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002815, MRE: 0.018568, MAE: 0.003777 \n",
      "\n",
      "Epoch 538/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 538/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 538/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 538/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 538/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 538/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 538/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 538/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 538/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 538/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 538/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 538/1200, Iteration 12/12, Loss: 0.0070\n",
      "Epoch 538/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002441, MRE: 0.020840, MAE: 0.003392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002900, MRE: 0.018436, MAE: 0.003773 \n",
      "\n",
      "Epoch 539/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 539/1200, Iteration 2/12, Loss: 0.0062\n",
      "Epoch 539/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 539/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 539/1200, Iteration 5/12, Loss: 0.0056\n",
      "Epoch 539/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 539/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 539/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 539/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 539/1200, Iteration 10/12, Loss: 0.0058\n",
      "Epoch 539/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 539/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 539/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002474, MRE: 0.020806, MAE: 0.003384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002648, MRE: 0.018515, MAE: 0.003712 \n",
      "\n",
      "Epoch 540/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 540/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 540/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 540/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 540/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 540/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 540/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 540/1200, Iteration 8/12, Loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 540/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 540/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 540/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 540/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002408, MRE: 0.021119, MAE: 0.003377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002679, MRE: 0.018561, MAE: 0.003729 \n",
      "\n",
      "Epoch 541/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 541/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 541/1200, Iteration 3/12, Loss: 0.0066\n",
      "Epoch 541/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 541/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 541/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 541/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 541/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 541/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 541/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 541/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 541/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 541/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002474, MRE: 0.024538, MAE: 0.003452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002678, MRE: 0.018863, MAE: 0.003808 \n",
      "\n",
      "Epoch 542/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 542/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 542/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 542/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 542/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 542/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 542/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 542/1200, Iteration 8/12, Loss: 0.0055\n",
      "Epoch 542/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 542/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 542/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 542/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 542/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002425, MRE: 0.020916, MAE: 0.003392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002809, MRE: 0.018349, MAE: 0.003744 \n",
      "\n",
      "Epoch 543/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 543/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 543/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 543/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 543/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 543/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 543/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 543/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 543/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 543/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 543/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 543/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 543/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002422, MRE: 0.021351, MAE: 0.003395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002699, MRE: 0.018557, MAE: 0.003728 \n",
      "\n",
      "Epoch 544/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 544/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 544/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 544/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 544/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 544/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 544/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 544/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 544/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 544/1200, Iteration 10/12, Loss: 0.0075\n",
      "Epoch 544/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 544/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 544/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002383, MRE: 0.020838, MAE: 0.003370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002741, MRE: 0.018873, MAE: 0.003787 \n",
      "\n",
      "Epoch 545/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 545/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 545/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 545/1200, Iteration 4/12, Loss: 0.0061\n",
      "Epoch 545/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 545/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 545/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 545/1200, Iteration 8/12, Loss: 0.0058\n",
      "Epoch 545/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 545/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 545/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 545/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 545/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002400, MRE: 0.021683, MAE: 0.003381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002711, MRE: 0.018647, MAE: 0.003750 \n",
      "\n",
      "Epoch 546/1200, Iteration 1/12, Loss: 0.0043\n",
      "Epoch 546/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 546/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 546/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 546/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 546/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 546/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 546/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 546/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 546/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 546/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 546/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 546/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002352, MRE: 0.020987, MAE: 0.003322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002700, MRE: 0.018394, MAE: 0.003714 \n",
      "\n",
      "Epoch 547/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 547/1200, Iteration 2/12, Loss: 0.0068\n",
      "Epoch 547/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 547/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 547/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 547/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 547/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 547/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 547/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 547/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 547/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 547/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 547/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002364, MRE: 0.020702, MAE: 0.003333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002611, MRE: 0.018234, MAE: 0.003664 \n",
      "\n",
      "Epoch 548/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 548/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 548/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 548/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 548/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 548/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 548/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 548/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 548/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 548/1200, Iteration 10/12, Loss: 0.0073\n",
      "Epoch 548/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 548/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 548/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002385, MRE: 0.020693, MAE: 0.003346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002713, MRE: 0.018353, MAE: 0.003732 \n",
      "\n",
      "Epoch 549/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 549/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 549/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 549/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 549/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 549/1200, Iteration 6/12, Loss: 0.0076\n",
      "Epoch 549/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 549/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 549/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 549/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 549/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 549/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 549/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002460, MRE: 0.020832, MAE: 0.003383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002691, MRE: 0.018283, MAE: 0.003690 \n",
      "\n",
      "Epoch 550/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 550/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 550/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 550/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 550/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 550/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 550/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 550/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 550/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 550/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 550/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 550/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 550/1200, Iteration 13/12, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002461, MRE: 0.020667, MAE: 0.003378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002845, MRE: 0.018302, MAE: 0.003758 \n",
      "\n",
      "Epoch 551/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 551/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 551/1200, Iteration 3/12, Loss: 0.0054\n",
      "Epoch 551/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 551/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 551/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 551/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 551/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 551/1200, Iteration 9/12, Loss: 0.0093\n",
      "Epoch 551/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 551/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 551/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 551/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002346, MRE: 0.020666, MAE: 0.003344 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002703, MRE: 0.018479, MAE: 0.003718 \n",
      "\n",
      "Epoch 552/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 552/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 552/1200, Iteration 3/12, Loss: 0.0047\n",
      "Epoch 552/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 552/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 552/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 552/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 552/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 552/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 552/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 552/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 552/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 552/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002640, MRE: 0.020881, MAE: 0.003427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002646, MRE: 0.019238, MAE: 0.003777 \n",
      "\n",
      "Epoch 553/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 553/1200, Iteration 2/12, Loss: 0.0067\n",
      "Epoch 553/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 553/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 553/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 553/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 553/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 553/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 553/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 553/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 553/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 553/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 553/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002364, MRE: 0.020530, MAE: 0.003366 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002665, MRE: 0.019152, MAE: 0.003799 \n",
      "\n",
      "Epoch 554/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 554/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 554/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 554/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 554/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 554/1200, Iteration 6/12, Loss: 0.0058\n",
      "Epoch 554/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 554/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 554/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 554/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 554/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 554/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 554/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002359, MRE: 0.020650, MAE: 0.003347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002578, MRE: 0.018615, MAE: 0.003719 \n",
      "\n",
      "Epoch 555/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 555/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 555/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 555/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 555/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 555/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 555/1200, Iteration 7/12, Loss: 0.0050\n",
      "Epoch 555/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 555/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 555/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 555/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 555/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 555/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002388, MRE: 0.020700, MAE: 0.003346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002576, MRE: 0.018684, MAE: 0.003753 \n",
      "\n",
      "Epoch 556/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 556/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 556/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 556/1200, Iteration 4/12, Loss: 0.0075\n",
      "Epoch 556/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 556/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 556/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 556/1200, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 556/1200, Iteration 9/12, Loss: 0.0049\n",
      "Epoch 556/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 556/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 556/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 556/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002330, MRE: 0.020552, MAE: 0.003307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002557, MRE: 0.018528, MAE: 0.003723 \n",
      "\n",
      "Epoch 557/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 557/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 557/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 557/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 557/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 557/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 557/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 557/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 557/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 557/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 557/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 557/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 557/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002358, MRE: 0.021767, MAE: 0.003367 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002714, MRE: 0.018298, MAE: 0.003693 \n",
      "\n",
      "Epoch 558/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 558/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 558/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 558/1200, Iteration 4/12, Loss: 0.0055\n",
      "Epoch 558/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 558/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 558/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 558/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 558/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 558/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 558/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 558/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 558/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002318, MRE: 0.021035, MAE: 0.003332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002697, MRE: 0.018390, MAE: 0.003718 \n",
      "\n",
      "Epoch 559/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 559/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 559/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 559/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 559/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 559/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 559/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 559/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 559/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 559/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 559/1200, Iteration 11/12, Loss: 0.0074\n",
      "Epoch 559/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 559/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002421, MRE: 0.020982, MAE: 0.003347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002602, MRE: 0.018259, MAE: 0.003717 \n",
      "\n",
      "Epoch 560/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 560/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 560/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 560/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 560/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 560/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 560/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 560/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 560/1200, Iteration 9/12, Loss: 0.0089\n",
      "Epoch 560/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 560/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 560/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 560/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002344, MRE: 0.020416, MAE: 0.003332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002701, MRE: 0.018404, MAE: 0.003791 \n",
      "\n",
      "Epoch 561/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 561/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 561/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 561/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 561/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 561/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 561/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 561/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 561/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 561/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 561/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 561/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 561/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002315, MRE: 0.020542, MAE: 0.003313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002660, MRE: 0.018180, MAE: 0.003685 \n",
      "\n",
      "Epoch 562/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 562/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 562/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 562/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 562/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 562/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 562/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 562/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 562/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 562/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 562/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 562/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 562/1200, Iteration 13/12, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 97.88%, Avg loss: 0.002388, MRE: 0.021044, MAE: 0.003383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002493, MRE: 0.018883, MAE: 0.003828 \n",
      "\n",
      "Epoch 563/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 563/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 563/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 563/1200, Iteration 4/12, Loss: 0.0063\n",
      "Epoch 563/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 563/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 563/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 563/1200, Iteration 8/12, Loss: 0.0069\n",
      "Epoch 563/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 563/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 563/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 563/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 563/1200, Iteration 13/12, Loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002317, MRE: 0.021184, MAE: 0.003332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002523, MRE: 0.018245, MAE: 0.003642 \n",
      "\n",
      "Epoch 564/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 564/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 564/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 564/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 564/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 564/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 564/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 564/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 564/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 564/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 564/1200, Iteration 11/12, Loss: 0.0079\n",
      "Epoch 564/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 564/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002379, MRE: 0.024361, MAE: 0.003364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002567, MRE: 0.018111, MAE: 0.003709 \n",
      "\n",
      "Epoch 565/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 565/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 565/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 565/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 565/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 565/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 565/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 565/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 565/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 565/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 565/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 565/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 565/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002376, MRE: 0.020768, MAE: 0.003352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002651, MRE: 0.017906, MAE: 0.003663 \n",
      "\n",
      "Epoch 566/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 566/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 566/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 566/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 566/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 566/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 566/1200, Iteration 7/12, Loss: 0.0050\n",
      "Epoch 566/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 566/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 566/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 566/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 566/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 566/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002314, MRE: 0.020498, MAE: 0.003302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002535, MRE: 0.017900, MAE: 0.003627 \n",
      "\n",
      "Epoch 567/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 567/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 567/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 567/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 567/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 567/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 567/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 567/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 567/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 567/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 567/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 567/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 567/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002279, MRE: 0.020029, MAE: 0.003282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002538, MRE: 0.018111, MAE: 0.003617 \n",
      "\n",
      "Epoch 568/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 568/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 568/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 568/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 568/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 568/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 568/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 568/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 568/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 568/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 568/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 568/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 568/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002558, MRE: 0.020559, MAE: 0.003357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002481, MRE: 0.018385, MAE: 0.003689 \n",
      "\n",
      "Epoch 569/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 569/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 569/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 569/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 569/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 569/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 569/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 569/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 569/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 569/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 569/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 569/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 569/1200, Iteration 13/12, Loss: 0.0066\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002370, MRE: 0.020985, MAE: 0.003394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002839, MRE: 0.017880, MAE: 0.003633 \n",
      "\n",
      "Epoch 570/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 570/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 570/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 570/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 570/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 570/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 570/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 570/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 570/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 570/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 570/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 570/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 570/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002293, MRE: 0.020675, MAE: 0.003303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002679, MRE: 0.018078, MAE: 0.003681 \n",
      "\n",
      "Epoch 571/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 571/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 571/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 571/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 571/1200, Iteration 5/12, Loss: 0.0073\n",
      "Epoch 571/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 571/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 571/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 571/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 571/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 571/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 571/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 571/1200, Iteration 13/12, Loss: 0.0083\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002429, MRE: 0.020753, MAE: 0.003382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002516, MRE: 0.018521, MAE: 0.003755 \n",
      "\n",
      "Epoch 572/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 572/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 572/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 572/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 572/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 572/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 572/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 572/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 572/1200, Iteration 9/12, Loss: 0.0057\n",
      "Epoch 572/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 572/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 572/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 572/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002267, MRE: 0.020817, MAE: 0.003295 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002598, MRE: 0.017955, MAE: 0.003702 \n",
      "\n",
      "Epoch 573/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 573/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 573/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 573/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 573/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 573/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 573/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 573/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 573/1200, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 573/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 573/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 573/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 573/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002236, MRE: 0.020280, MAE: 0.003250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002595, MRE: 0.017756, MAE: 0.003601 \n",
      "\n",
      "Epoch 574/1200, Iteration 1/12, Loss: 0.0090\n",
      "Epoch 574/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 574/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 574/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 574/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 574/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 574/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 574/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 574/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 574/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 574/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 574/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 574/1200, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002255, MRE: 0.020249, MAE: 0.003269 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002590, MRE: 0.017992, MAE: 0.003671 \n",
      "\n",
      "Epoch 575/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 575/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 575/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 575/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 575/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 575/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 575/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 575/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 575/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 575/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 575/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 575/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 575/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002281, MRE: 0.020452, MAE: 0.003293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002491, MRE: 0.018354, MAE: 0.003686 \n",
      "\n",
      "Epoch 576/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 576/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 576/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 576/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 576/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 576/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 576/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 576/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 576/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 576/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 576/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 576/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 576/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002270, MRE: 0.021019, MAE: 0.003309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002628, MRE: 0.017820, MAE: 0.003668 \n",
      "\n",
      "Epoch 577/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 577/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 577/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 577/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 577/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 577/1200, Iteration 6/12, Loss: 0.0062\n",
      "Epoch 577/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 577/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 577/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 577/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 577/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 577/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 577/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002325, MRE: 0.020389, MAE: 0.003320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002500, MRE: 0.018326, MAE: 0.003732 \n",
      "\n",
      "Epoch 578/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 578/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 578/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 578/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 578/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 578/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 578/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 578/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 578/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 578/1200, Iteration 10/12, Loss: 0.0065\n",
      "Epoch 578/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 578/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 578/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002223, MRE: 0.020529, MAE: 0.003244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002499, MRE: 0.017734, MAE: 0.003582 \n",
      "\n",
      "Epoch 579/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 579/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 579/1200, Iteration 3/12, Loss: 0.0080\n",
      "Epoch 579/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 579/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 579/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 579/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 579/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 579/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 579/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 579/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 579/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 579/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002216, MRE: 0.020501, MAE: 0.003251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002536, MRE: 0.017741, MAE: 0.003573 \n",
      "\n",
      "Epoch 580/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 580/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 580/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 580/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 580/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 580/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 580/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 580/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 580/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 580/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 580/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 580/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 580/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002247, MRE: 0.020102, MAE: 0.003259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002493, MRE: 0.017846, MAE: 0.003608 \n",
      "\n",
      "Epoch 581/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 581/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 581/1200, Iteration 3/12, Loss: 0.0064\n",
      "Epoch 581/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 581/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 581/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 581/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 581/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 581/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 581/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 581/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 581/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 581/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002228, MRE: 0.020278, MAE: 0.003270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002547, MRE: 0.018028, MAE: 0.003722 \n",
      "\n",
      "Epoch 582/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 582/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 582/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 582/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 582/1200, Iteration 5/12, Loss: 0.0057\n",
      "Epoch 582/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 582/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 582/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 582/1200, Iteration 9/12, Loss: 0.0060\n",
      "Epoch 582/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 582/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 582/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 582/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002422, MRE: 0.020461, MAE: 0.003316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002534, MRE: 0.017885, MAE: 0.003673 \n",
      "\n",
      "Epoch 583/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 583/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 583/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 583/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 583/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 583/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 583/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 583/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 583/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 583/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 583/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 583/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 583/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002240, MRE: 0.019773, MAE: 0.003272 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002566, MRE: 0.018028, MAE: 0.003720 \n",
      "\n",
      "Epoch 584/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 584/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 584/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 584/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 584/1200, Iteration 5/12, Loss: 0.0059\n",
      "Epoch 584/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 584/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 584/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 584/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 584/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 584/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 584/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 584/1200, Iteration 13/12, Loss: 0.0142\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002365, MRE: 0.021101, MAE: 0.003463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003023, MRE: 0.018114, MAE: 0.003773 \n",
      "\n",
      "Epoch 585/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 585/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 585/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 585/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 585/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 585/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 585/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 585/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 585/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 585/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 585/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 585/1200, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 585/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002226, MRE: 0.020242, MAE: 0.003291 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002535, MRE: 0.018491, MAE: 0.003758 \n",
      "\n",
      "Epoch 586/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 586/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 586/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 586/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 586/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 586/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 586/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 586/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 586/1200, Iteration 9/12, Loss: 0.0054\n",
      "Epoch 586/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 586/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 586/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 586/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002239, MRE: 0.020120, MAE: 0.003271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002640, MRE: 0.017969, MAE: 0.003692 \n",
      "\n",
      "Epoch 587/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 587/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 587/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 587/1200, Iteration 4/12, Loss: 0.0055\n",
      "Epoch 587/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 587/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 587/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 587/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 587/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 587/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 587/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 587/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 587/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002250, MRE: 0.020576, MAE: 0.003297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002528, MRE: 0.018035, MAE: 0.003723 \n",
      "\n",
      "Epoch 588/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 588/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 588/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 588/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 588/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 588/1200, Iteration 6/12, Loss: 0.0059\n",
      "Epoch 588/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 588/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 588/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 588/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 588/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 588/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 588/1200, Iteration 13/12, Loss: 0.0049\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002181, MRE: 0.019763, MAE: 0.003233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002605, MRE: 0.017962, MAE: 0.003680 \n",
      "\n",
      "Epoch 589/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 589/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 589/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 589/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 589/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 589/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 589/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 589/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 589/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 589/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 589/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 589/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 589/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002278, MRE: 0.020067, MAE: 0.003280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002503, MRE: 0.018103, MAE: 0.003717 \n",
      "\n",
      "Epoch 590/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 590/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 590/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 590/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 590/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 590/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 590/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 590/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 590/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 590/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 590/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 590/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 590/1200, Iteration 13/12, Loss: 0.0061\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002348, MRE: 0.020603, MAE: 0.003263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002418, MRE: 0.018088, MAE: 0.003616 \n",
      "\n",
      "Epoch 591/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 591/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 591/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 591/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 591/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 591/1200, Iteration 6/12, Loss: 0.0052\n",
      "Epoch 591/1200, Iteration 7/12, Loss: 0.0056\n",
      "Epoch 591/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 591/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 591/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 591/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 591/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 591/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002176, MRE: 0.019925, MAE: 0.003231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002503, MRE: 0.018316, MAE: 0.003656 \n",
      "\n",
      "Epoch 592/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 592/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 592/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 592/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 592/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 592/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 592/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 592/1200, Iteration 8/12, Loss: 0.0051\n",
      "Epoch 592/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 592/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 592/1200, Iteration 11/12, Loss: 0.0036\n",
      "Epoch 592/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 592/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002193, MRE: 0.020377, MAE: 0.003265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002581, MRE: 0.017531, MAE: 0.003544 \n",
      "\n",
      "Epoch 593/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 593/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 593/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 593/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 593/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 593/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 593/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 593/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 593/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 593/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 593/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 593/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 593/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002249, MRE: 0.020228, MAE: 0.003304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002602, MRE: 0.017712, MAE: 0.003578 \n",
      "\n",
      "Epoch 594/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 594/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 594/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 594/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 594/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 594/1200, Iteration 6/12, Loss: 0.0059\n",
      "Epoch 594/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 594/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 594/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 594/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 594/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 594/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 594/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002178, MRE: 0.019927, MAE: 0.003241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002542, MRE: 0.018000, MAE: 0.003671 \n",
      "\n",
      "Epoch 595/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 595/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 595/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 595/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 595/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 595/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 595/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 595/1200, Iteration 8/12, Loss: 0.0052\n",
      "Epoch 595/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 595/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 595/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 595/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 595/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002153, MRE: 0.019644, MAE: 0.003213 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002549, MRE: 0.017693, MAE: 0.003616 \n",
      "\n",
      "Epoch 596/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 596/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 596/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 596/1200, Iteration 4/12, Loss: 0.0059\n",
      "Epoch 596/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 596/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 596/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 596/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 596/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 596/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 596/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 596/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 596/1200, Iteration 13/12, Loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002197, MRE: 0.020533, MAE: 0.003233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002371, MRE: 0.017727, MAE: 0.003575 \n",
      "\n",
      "Epoch 597/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 597/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 597/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 597/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 597/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 597/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 597/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 597/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 597/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 597/1200, Iteration 10/12, Loss: 0.0049\n",
      "Epoch 597/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 597/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 597/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002404, MRE: 0.019993, MAE: 0.003268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002541, MRE: 0.017695, MAE: 0.003598 \n",
      "\n",
      "Epoch 598/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 598/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 598/1200, Iteration 3/12, Loss: 0.0078\n",
      "Epoch 598/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 598/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 598/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 598/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 598/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 598/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 598/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 598/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 598/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 598/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002356, MRE: 0.019897, MAE: 0.003281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002655, MRE: 0.017615, MAE: 0.003578 \n",
      "\n",
      "Epoch 599/1200, Iteration 1/12, Loss: 0.0069\n",
      "Epoch 599/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 599/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 599/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 599/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 599/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 599/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 599/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 599/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 599/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 599/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 599/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 599/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002150, MRE: 0.020334, MAE: 0.003199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002410, MRE: 0.017724, MAE: 0.003592 \n",
      "\n",
      "Epoch 600/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 600/1200, Iteration 2/12, Loss: 0.0053\n",
      "Epoch 600/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 600/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 600/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 600/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 600/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 600/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 600/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 600/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 600/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 600/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 600/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002180, MRE: 0.019642, MAE: 0.003229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002544, MRE: 0.017605, MAE: 0.003536 \n",
      "\n",
      "Epoch 601/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 601/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 601/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 601/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 601/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 601/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 601/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 601/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 601/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 601/1200, Iteration 10/12, Loss: 0.0079\n",
      "Epoch 601/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 601/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 601/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002146, MRE: 0.019812, MAE: 0.003199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002517, MRE: 0.017694, MAE: 0.003613 \n",
      "\n",
      "Epoch 602/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 602/1200, Iteration 2/12, Loss: 0.0047\n",
      "Epoch 602/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 602/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 602/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 602/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 602/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 602/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 602/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 602/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 602/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 602/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 602/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002207, MRE: 0.019881, MAE: 0.003261 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002476, MRE: 0.018340, MAE: 0.003713 \n",
      "\n",
      "Epoch 603/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 603/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 603/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 603/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 603/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 603/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 603/1200, Iteration 7/12, Loss: 0.0063\n",
      "Epoch 603/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 603/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 603/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 603/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 603/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 603/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002143, MRE: 0.019698, MAE: 0.003227 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002636, MRE: 0.017460, MAE: 0.003548 \n",
      "\n",
      "Epoch 604/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 604/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 604/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 604/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 604/1200, Iteration 5/12, Loss: 0.0054\n",
      "Epoch 604/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 604/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 604/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 604/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 604/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 604/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 604/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 604/1200, Iteration 13/12, Loss: 0.0072\n",
      "Train Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002308, MRE: 0.020560, MAE: 0.003368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002510, MRE: 0.019136, MAE: 0.003738 \n",
      "\n",
      "Epoch 605/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 605/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 605/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 605/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 605/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 605/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 605/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 605/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 605/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 605/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 605/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 605/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 605/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002137, MRE: 0.019623, MAE: 0.003189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002418, MRE: 0.017695, MAE: 0.003558 \n",
      "\n",
      "Epoch 606/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 606/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 606/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 606/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 606/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 606/1200, Iteration 6/12, Loss: 0.0067\n",
      "Epoch 606/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 606/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 606/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 606/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 606/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 606/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 606/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002186, MRE: 0.019902, MAE: 0.003226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002461, MRE: 0.017706, MAE: 0.003615 \n",
      "\n",
      "Epoch 607/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 607/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 607/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 607/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 607/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 607/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 607/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 607/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 607/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 607/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 607/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 607/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 607/1200, Iteration 13/12, Loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002243, MRE: 0.019770, MAE: 0.003247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002441, MRE: 0.018096, MAE: 0.003699 \n",
      "\n",
      "Epoch 608/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 608/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 608/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 608/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 608/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 608/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 608/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 608/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 608/1200, Iteration 9/12, Loss: 0.0058\n",
      "Epoch 608/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 608/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 608/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 608/1200, Iteration 13/12, Loss: 0.0064\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002157, MRE: 0.019621, MAE: 0.003246 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002612, MRE: 0.017635, MAE: 0.003575 \n",
      "\n",
      "Epoch 609/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 609/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 609/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 609/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 609/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 609/1200, Iteration 6/12, Loss: 0.0065\n",
      "Epoch 609/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 609/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 609/1200, Iteration 9/12, Loss: 0.0057\n",
      "Epoch 609/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 609/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 609/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 609/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002126, MRE: 0.019447, MAE: 0.003188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002479, MRE: 0.017793, MAE: 0.003585 \n",
      "\n",
      "Epoch 610/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 610/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 610/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 610/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 610/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 610/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 610/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 610/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 610/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 610/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 610/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 610/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 610/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002365, MRE: 0.020516, MAE: 0.003291 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002630, MRE: 0.017491, MAE: 0.003556 \n",
      "\n",
      "Epoch 611/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 611/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 611/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 611/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 611/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 611/1200, Iteration 6/12, Loss: 0.0073\n",
      "Epoch 611/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 611/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 611/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 611/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 611/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 611/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 611/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002198, MRE: 0.023115, MAE: 0.003234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002434, MRE: 0.018030, MAE: 0.003638 \n",
      "\n",
      "Epoch 612/1200, Iteration 1/12, Loss: 0.0048\n",
      "Epoch 612/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 612/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 612/1200, Iteration 4/12, Loss: 0.0073\n",
      "Epoch 612/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 612/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 612/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 612/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 612/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 612/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 612/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 612/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 612/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002104, MRE: 0.019424, MAE: 0.003157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002437, MRE: 0.017566, MAE: 0.003549 \n",
      "\n",
      "Epoch 613/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 613/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 613/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 613/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 613/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 613/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 613/1200, Iteration 7/12, Loss: 0.0058\n",
      "Epoch 613/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 613/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 613/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 613/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 613/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 613/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002145, MRE: 0.020075, MAE: 0.003213 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002454, MRE: 0.018447, MAE: 0.003656 \n",
      "\n",
      "Epoch 614/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 614/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 614/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 614/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 614/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 614/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 614/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 614/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 614/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 614/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 614/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 614/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 614/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002151, MRE: 0.019641, MAE: 0.003187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002474, MRE: 0.017582, MAE: 0.003595 \n",
      "\n",
      "Epoch 615/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 615/1200, Iteration 2/12, Loss: 0.0069\n",
      "Epoch 615/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 615/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 615/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 615/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 615/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 615/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 615/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 615/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 615/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 615/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 615/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002079, MRE: 0.019714, MAE: 0.003150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002464, MRE: 0.017611, MAE: 0.003584 \n",
      "\n",
      "Epoch 616/1200, Iteration 1/12, Loss: 0.0079\n",
      "Epoch 616/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 616/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 616/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 616/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 616/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 616/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 616/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 616/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 616/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 616/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 616/1200, Iteration 12/12, Loss: 0.0054\n",
      "Epoch 616/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002083, MRE: 0.020009, MAE: 0.003156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002502, MRE: 0.017568, MAE: 0.003544 \n",
      "\n",
      "Epoch 617/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 617/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 617/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 617/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 617/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 617/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 617/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 617/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 617/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 617/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 617/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 617/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 617/1200, Iteration 13/12, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.002452, MRE: 0.021469, MAE: 0.003456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.003144, MRE: 0.018247, MAE: 0.003786 \n",
      "\n",
      "Epoch 618/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 618/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 618/1200, Iteration 3/12, Loss: 0.0058\n",
      "Epoch 618/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 618/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 618/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 618/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 618/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 618/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 618/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 618/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 618/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 618/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002265, MRE: 0.019517, MAE: 0.003232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002547, MRE: 0.018077, MAE: 0.003635 \n",
      "\n",
      "Epoch 619/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 619/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 619/1200, Iteration 3/12, Loss: 0.0058\n",
      "Epoch 619/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 619/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 619/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 619/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 619/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 619/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 619/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 619/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 619/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 619/1200, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002131, MRE: 0.019755, MAE: 0.003191 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002442, MRE: 0.017557, MAE: 0.003592 \n",
      "\n",
      "Epoch 620/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 620/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 620/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 620/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 620/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 620/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 620/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 620/1200, Iteration 8/12, Loss: 0.0062\n",
      "Epoch 620/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 620/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 620/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 620/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 620/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002091, MRE: 0.019711, MAE: 0.003176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002450, MRE: 0.017353, MAE: 0.003511 \n",
      "\n",
      "Epoch 621/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 621/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 621/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 621/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 621/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 621/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 621/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 621/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 621/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 621/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 621/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 621/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 621/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002076, MRE: 0.019346, MAE: 0.003169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002449, MRE: 0.017607, MAE: 0.003582 \n",
      "\n",
      "Epoch 622/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 622/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 622/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 622/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 622/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 622/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 622/1200, Iteration 7/12, Loss: 0.0059\n",
      "Epoch 622/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 622/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 622/1200, Iteration 10/12, Loss: 0.0065\n",
      "Epoch 622/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 622/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 622/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002054, MRE: 0.019313, MAE: 0.003140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002473, MRE: 0.017443, MAE: 0.003541 \n",
      "\n",
      "Epoch 623/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 623/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 623/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 623/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 623/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 623/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 623/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 623/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 623/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 623/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 623/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 623/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 623/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002094, MRE: 0.020024, MAE: 0.003188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002513, MRE: 0.017147, MAE: 0.003488 \n",
      "\n",
      "Epoch 624/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 624/1200, Iteration 2/12, Loss: 0.0063\n",
      "Epoch 624/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 624/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 624/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 624/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 624/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 624/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 624/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 624/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 624/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 624/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 624/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002147, MRE: 0.019524, MAE: 0.003204 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002424, MRE: 0.018063, MAE: 0.003564 \n",
      "\n",
      "Epoch 625/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 625/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 625/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 625/1200, Iteration 4/12, Loss: 0.0056\n",
      "Epoch 625/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 625/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 625/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 625/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 625/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 625/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 625/1200, Iteration 11/12, Loss: 0.0064\n",
      "Epoch 625/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 625/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.12%, Avg loss: 0.002172, MRE: 0.019585, MAE: 0.003193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002287, MRE: 0.017429, MAE: 0.003528 \n",
      "\n",
      "Epoch 626/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 626/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 626/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 626/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 626/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 626/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 626/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 626/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 626/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 626/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 626/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 626/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 626/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002061, MRE: 0.019408, MAE: 0.003168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002512, MRE: 0.017207, MAE: 0.003506 \n",
      "\n",
      "Epoch 627/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 627/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 627/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 627/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 627/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 627/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 627/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 627/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 627/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 627/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 627/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 627/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 627/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.002132, MRE: 0.020080, MAE: 0.003199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002531, MRE: 0.017229, MAE: 0.003489 \n",
      "\n",
      "Epoch 628/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 628/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 628/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 628/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 628/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 628/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 628/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 628/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 628/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 628/1200, Iteration 10/12, Loss: 0.0059\n",
      "Epoch 628/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 628/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 628/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002049, MRE: 0.019640, MAE: 0.003159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002444, MRE: 0.017662, MAE: 0.003599 \n",
      "\n",
      "Epoch 629/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 629/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 629/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 629/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 629/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 629/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 629/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 629/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 629/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 629/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 629/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 629/1200, Iteration 12/12, Loss: 0.0061\n",
      "Epoch 629/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.002159, MRE: 0.019851, MAE: 0.003198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002547, MRE: 0.017277, MAE: 0.003540 \n",
      "\n",
      "Epoch 630/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 630/1200, Iteration 2/12, Loss: 0.0050\n",
      "Epoch 630/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 630/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 630/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 630/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 630/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 630/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 630/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 630/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 630/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 630/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 630/1200, Iteration 13/12, Loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002062, MRE: 0.019290, MAE: 0.003130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002575, MRE: 0.017327, MAE: 0.003530 \n",
      "\n",
      "Epoch 631/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 631/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 631/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 631/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 631/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 631/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 631/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 631/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 631/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 631/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 631/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 631/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 631/1200, Iteration 13/12, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002033, MRE: 0.019789, MAE: 0.003124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002425, MRE: 0.017356, MAE: 0.003474 \n",
      "\n",
      "Epoch 632/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 632/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 632/1200, Iteration 3/12, Loss: 0.0057\n",
      "Epoch 632/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 632/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 632/1200, Iteration 6/12, Loss: 0.0063\n",
      "Epoch 632/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 632/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 632/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 632/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 632/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 632/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 632/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002036, MRE: 0.019741, MAE: 0.003127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002411, MRE: 0.017325, MAE: 0.003484 \n",
      "\n",
      "Epoch 633/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 633/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 633/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 633/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 633/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 633/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 633/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 633/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 633/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 633/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 633/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 633/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 633/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002216, MRE: 0.020079, MAE: 0.003196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002440, MRE: 0.017338, MAE: 0.003498 \n",
      "\n",
      "Epoch 634/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 634/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 634/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 634/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 634/1200, Iteration 5/12, Loss: 0.0052\n",
      "Epoch 634/1200, Iteration 6/12, Loss: 0.0061\n",
      "Epoch 634/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 634/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 634/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 634/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 634/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 634/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 634/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002067, MRE: 0.020024, MAE: 0.003155 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002598, MRE: 0.017300, MAE: 0.003525 \n",
      "\n",
      "Epoch 635/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 635/1200, Iteration 2/12, Loss: 0.0061\n",
      "Epoch 635/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 635/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 635/1200, Iteration 5/12, Loss: 0.0070\n",
      "Epoch 635/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 635/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 635/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 635/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 635/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 635/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 635/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 635/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002195, MRE: 0.019296, MAE: 0.003171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002443, MRE: 0.017586, MAE: 0.003537 \n",
      "\n",
      "Epoch 636/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 636/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 636/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 636/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 636/1200, Iteration 5/12, Loss: 0.0061\n",
      "Epoch 636/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 636/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 636/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 636/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 636/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 636/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 636/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 636/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002312, MRE: 0.019468, MAE: 0.003228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002478, MRE: 0.017438, MAE: 0.003535 \n",
      "\n",
      "Epoch 637/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 637/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 637/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 637/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 637/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 637/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 637/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 637/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 637/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 637/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 637/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 637/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 637/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002054, MRE: 0.019243, MAE: 0.003135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002547, MRE: 0.017375, MAE: 0.003528 \n",
      "\n",
      "Epoch 638/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 638/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 638/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 638/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 638/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 638/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 638/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 638/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 638/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 638/1200, Iteration 10/12, Loss: 0.0076\n",
      "Epoch 638/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 638/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 638/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002013, MRE: 0.019447, MAE: 0.003122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002401, MRE: 0.017663, MAE: 0.003547 \n",
      "\n",
      "Epoch 639/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 639/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 639/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 639/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 639/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 639/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 639/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 639/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 639/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 639/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 639/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 639/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 639/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001996, MRE: 0.019412, MAE: 0.003090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002401, MRE: 0.017442, MAE: 0.003514 \n",
      "\n",
      "Epoch 640/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 640/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 640/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 640/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 640/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 640/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 640/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 640/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 640/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 640/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 640/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 640/1200, Iteration 12/12, Loss: 0.0050\n",
      "Epoch 640/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.002047, MRE: 0.019417, MAE: 0.003120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002478, MRE: 0.017394, MAE: 0.003558 \n",
      "\n",
      "Epoch 641/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 641/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 641/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 641/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 641/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 641/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 641/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 641/1200, Iteration 8/12, Loss: 0.0050\n",
      "Epoch 641/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 641/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 641/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 641/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 641/1200, Iteration 13/12, Loss: 0.0051\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002223, MRE: 0.019264, MAE: 0.003149 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002404, MRE: 0.017798, MAE: 0.003591 \n",
      "\n",
      "Epoch 642/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 642/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 642/1200, Iteration 3/12, Loss: 0.0052\n",
      "Epoch 642/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 642/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 642/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 642/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 642/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 642/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 642/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 642/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 642/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 642/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002011, MRE: 0.019134, MAE: 0.003128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002419, MRE: 0.017482, MAE: 0.003547 \n",
      "\n",
      "Epoch 643/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 643/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 643/1200, Iteration 3/12, Loss: 0.0070\n",
      "Epoch 643/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 643/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 643/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 643/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 643/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 643/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 643/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 643/1200, Iteration 11/12, Loss: 0.0051\n",
      "Epoch 643/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 643/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002033, MRE: 0.019256, MAE: 0.003116 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002382, MRE: 0.017611, MAE: 0.003557 \n",
      "\n",
      "Epoch 644/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 644/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 644/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 644/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 644/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 644/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 644/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 644/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 644/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 644/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 644/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 644/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 644/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001993, MRE: 0.019536, MAE: 0.003090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002504, MRE: 0.017088, MAE: 0.003481 \n",
      "\n",
      "Epoch 645/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 645/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 645/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 645/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 645/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 645/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 645/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 645/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 645/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 645/1200, Iteration 10/12, Loss: 0.0055\n",
      "Epoch 645/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 645/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 645/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001995, MRE: 0.019437, MAE: 0.003117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002414, MRE: 0.017348, MAE: 0.003563 \n",
      "\n",
      "Epoch 646/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 646/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 646/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 646/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 646/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 646/1200, Iteration 6/12, Loss: 0.0060\n",
      "Epoch 646/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 646/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 646/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 646/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 646/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 646/1200, Iteration 12/12, Loss: 0.0055\n",
      "Epoch 646/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002070, MRE: 0.019743, MAE: 0.003133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002408, MRE: 0.017314, MAE: 0.003572 \n",
      "\n",
      "Epoch 647/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 647/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 647/1200, Iteration 3/12, Loss: 0.0074\n",
      "Epoch 647/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 647/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 647/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 647/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 647/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 647/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 647/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 647/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 647/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 647/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002032, MRE: 0.019553, MAE: 0.003123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002363, MRE: 0.017046, MAE: 0.003442 \n",
      "\n",
      "Epoch 648/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 648/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 648/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 648/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 648/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 648/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 648/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 648/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 648/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 648/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 648/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 648/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 648/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001995, MRE: 0.019413, MAE: 0.003093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002333, MRE: 0.017099, MAE: 0.003471 \n",
      "\n",
      "Epoch 649/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 649/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 649/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 649/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 649/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 649/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 649/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 649/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 649/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 649/1200, Iteration 10/12, Loss: 0.0063\n",
      "Epoch 649/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 649/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 649/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002070, MRE: 0.019397, MAE: 0.003146 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002348, MRE: 0.017539, MAE: 0.003582 \n",
      "\n",
      "Epoch 650/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 650/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 650/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 650/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 650/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 650/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 650/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 650/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 650/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 650/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 650/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 650/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 650/1200, Iteration 13/12, Loss: 0.0104\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.002069, MRE: 0.019694, MAE: 0.003196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002674, MRE: 0.017070, MAE: 0.003507 \n",
      "\n",
      "Epoch 651/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 651/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 651/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 651/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 651/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 651/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 651/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 651/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 651/1200, Iteration 9/12, Loss: 0.0050\n",
      "Epoch 651/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 651/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 651/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 651/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001967, MRE: 0.018898, MAE: 0.003059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002430, MRE: 0.017319, MAE: 0.003523 \n",
      "\n",
      "Epoch 652/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 652/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 652/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 652/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 652/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 652/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 652/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 652/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 652/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 652/1200, Iteration 10/12, Loss: 0.0067\n",
      "Epoch 652/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 652/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 652/1200, Iteration 13/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002201, MRE: 0.019394, MAE: 0.003120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002408, MRE: 0.017288, MAE: 0.003553 \n",
      "\n",
      "Epoch 653/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 653/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 653/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 653/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 653/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 653/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 653/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 653/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 653/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 653/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 653/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 653/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 653/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001975, MRE: 0.019602, MAE: 0.003082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002322, MRE: 0.017464, MAE: 0.003553 \n",
      "\n",
      "Epoch 654/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 654/1200, Iteration 2/12, Loss: 0.0065\n",
      "Epoch 654/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 654/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 654/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 654/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 654/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 654/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 654/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 654/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 654/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 654/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 654/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002004, MRE: 0.019040, MAE: 0.003089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002345, MRE: 0.017447, MAE: 0.003523 \n",
      "\n",
      "Epoch 655/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 655/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 655/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 655/1200, Iteration 4/12, Loss: 0.0047\n",
      "Epoch 655/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 655/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 655/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 655/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 655/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 655/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 655/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 655/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 655/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002047, MRE: 0.019091, MAE: 0.003096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002402, MRE: 0.017381, MAE: 0.003556 \n",
      "\n",
      "Epoch 656/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 656/1200, Iteration 2/12, Loss: 0.0059\n",
      "Epoch 656/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 656/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 656/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 656/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 656/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 656/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 656/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 656/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 656/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 656/1200, Iteration 12/12, Loss: 0.0069\n",
      "Epoch 656/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002032, MRE: 0.019152, MAE: 0.003127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002314, MRE: 0.017552, MAE: 0.003542 \n",
      "\n",
      "Epoch 657/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 657/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 657/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 657/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 657/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 657/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 657/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 657/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 657/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 657/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 657/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 657/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 657/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001990, MRE: 0.018818, MAE: 0.003107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002556, MRE: 0.017378, MAE: 0.003506 \n",
      "\n",
      "Epoch 658/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 658/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 658/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 658/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 658/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 658/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 658/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 658/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 658/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 658/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 658/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 658/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 658/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002041, MRE: 0.019222, MAE: 0.003120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002386, MRE: 0.017521, MAE: 0.003566 \n",
      "\n",
      "Epoch 659/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 659/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 659/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 659/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 659/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 659/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 659/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 659/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 659/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 659/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 659/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 659/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 659/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001962, MRE: 0.018853, MAE: 0.003077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002338, MRE: 0.017594, MAE: 0.003557 \n",
      "\n",
      "Epoch 660/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 660/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 660/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 660/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 660/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 660/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 660/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 660/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 660/1200, Iteration 9/12, Loss: 0.0074\n",
      "Epoch 660/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 660/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 660/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 660/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001954, MRE: 0.019132, MAE: 0.003068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002379, MRE: 0.016818, MAE: 0.003477 \n",
      "\n",
      "Epoch 661/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 661/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 661/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 661/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 661/1200, Iteration 5/12, Loss: 0.0074\n",
      "Epoch 661/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 661/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 661/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 661/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 661/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 661/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 661/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 661/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001948, MRE: 0.019188, MAE: 0.003071 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002430, MRE: 0.016772, MAE: 0.003442 \n",
      "\n",
      "Epoch 662/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 662/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 662/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 662/1200, Iteration 4/12, Loss: 0.0061\n",
      "Epoch 662/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 662/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 662/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 662/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 662/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 662/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 662/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 662/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 662/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.002011, MRE: 0.019397, MAE: 0.003142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002271, MRE: 0.017861, MAE: 0.003581 \n",
      "\n",
      "Epoch 663/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 663/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 663/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 663/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 663/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 663/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 663/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 663/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 663/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 663/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 663/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 663/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 663/1200, Iteration 13/12, Loss: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002066, MRE: 0.019031, MAE: 0.003094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002322, MRE: 0.016873, MAE: 0.003396 \n",
      "\n",
      "Epoch 664/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 664/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 664/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 664/1200, Iteration 4/12, Loss: 0.0057\n",
      "Epoch 664/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 664/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 664/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 664/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 664/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 664/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 664/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 664/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 664/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001983, MRE: 0.019022, MAE: 0.003062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002311, MRE: 0.016764, MAE: 0.003465 \n",
      "\n",
      "Epoch 665/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 665/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 665/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 665/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 665/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 665/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 665/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 665/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 665/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 665/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 665/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 665/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 665/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001971, MRE: 0.018819, MAE: 0.003076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002420, MRE: 0.016748, MAE: 0.003407 \n",
      "\n",
      "Epoch 666/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 666/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 666/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 666/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 666/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 666/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 666/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 666/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 666/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 666/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 666/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 666/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 666/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.001976, MRE: 0.019152, MAE: 0.003098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002263, MRE: 0.017250, MAE: 0.003514 \n",
      "\n",
      "Epoch 667/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 667/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 667/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 667/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 667/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 667/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 667/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 667/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 667/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 667/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 667/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 667/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 667/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001986, MRE: 0.018764, MAE: 0.003054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002283, MRE: 0.016906, MAE: 0.003464 \n",
      "\n",
      "Epoch 668/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 668/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 668/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 668/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 668/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 668/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 668/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 668/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 668/1200, Iteration 9/12, Loss: 0.0081\n",
      "Epoch 668/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 668/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 668/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 668/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001982, MRE: 0.018921, MAE: 0.003073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002298, MRE: 0.016774, MAE: 0.003402 \n",
      "\n",
      "Epoch 669/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 669/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 669/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 669/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 669/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 669/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 669/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 669/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 669/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 669/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 669/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 669/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 669/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001923, MRE: 0.018722, MAE: 0.003050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002316, MRE: 0.016833, MAE: 0.003420 \n",
      "\n",
      "Epoch 670/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 670/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 670/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 670/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 670/1200, Iteration 5/12, Loss: 0.0059\n",
      "Epoch 670/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 670/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 670/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 670/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 670/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 670/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 670/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 670/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002054, MRE: 0.019286, MAE: 0.003099 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002400, MRE: 0.016742, MAE: 0.003473 \n",
      "\n",
      "Epoch 671/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 671/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 671/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 671/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 671/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 671/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 671/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 671/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 671/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 671/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 671/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 671/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 671/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001945, MRE: 0.022715, MAE: 0.003063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002341, MRE: 0.016666, MAE: 0.003425 \n",
      "\n",
      "Epoch 672/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 672/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 672/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 672/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 672/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 672/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 672/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 672/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 672/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 672/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 672/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 672/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 672/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001925, MRE: 0.018844, MAE: 0.003070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002307, MRE: 0.017234, MAE: 0.003477 \n",
      "\n",
      "Epoch 673/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 673/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 673/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 673/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 673/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 673/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 673/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 673/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 673/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 673/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 673/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 673/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 673/1200, Iteration 13/12, Loss: 0.0066\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.002032, MRE: 0.019068, MAE: 0.003117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002560, MRE: 0.016676, MAE: 0.003440 \n",
      "\n",
      "Epoch 674/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 674/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 674/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 674/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 674/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 674/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 674/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 674/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 674/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 674/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 674/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 674/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 674/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001978, MRE: 0.019011, MAE: 0.003117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002305, MRE: 0.017110, MAE: 0.003553 \n",
      "\n",
      "Epoch 675/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 675/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 675/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 675/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 675/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 675/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 675/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 675/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 675/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 675/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 675/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 675/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 675/1200, Iteration 13/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001876, MRE: 0.018733, MAE: 0.002998 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002279, MRE: 0.016778, MAE: 0.003401 \n",
      "\n",
      "Epoch 676/1200, Iteration 1/12, Loss: 0.0070\n",
      "Epoch 676/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 676/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 676/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 676/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 676/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 676/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 676/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 676/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 676/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 676/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 676/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 676/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001880, MRE: 0.018510, MAE: 0.003019 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002364, MRE: 0.017013, MAE: 0.003470 \n",
      "\n",
      "Epoch 677/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 677/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 677/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 677/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 677/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 677/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 677/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 677/1200, Iteration 8/12, Loss: 0.0067\n",
      "Epoch 677/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 677/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 677/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 677/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 677/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002113, MRE: 0.018843, MAE: 0.003087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002320, MRE: 0.017529, MAE: 0.003442 \n",
      "\n",
      "Epoch 678/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 678/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 678/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 678/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 678/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 678/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 678/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 678/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 678/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 678/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 678/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 678/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 678/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001886, MRE: 0.018752, MAE: 0.003013 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002327, MRE: 0.016677, MAE: 0.003425 \n",
      "\n",
      "Epoch 679/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 679/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 679/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 679/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 679/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 679/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 679/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 679/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 679/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 679/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 679/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 679/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 679/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.001936, MRE: 0.018710, MAE: 0.003052 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002191, MRE: 0.017270, MAE: 0.003456 \n",
      "\n",
      "Epoch 680/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 680/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 680/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 680/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 680/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 680/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 680/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 680/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 680/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 680/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 680/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 680/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 680/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001927, MRE: 0.018577, MAE: 0.003051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002326, MRE: 0.016661, MAE: 0.003380 \n",
      "\n",
      "Epoch 681/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 681/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 681/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 681/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 681/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 681/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 681/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 681/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 681/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 681/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 681/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 681/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 681/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001935, MRE: 0.018996, MAE: 0.003066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002223, MRE: 0.016663, MAE: 0.003447 \n",
      "\n",
      "Epoch 682/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 682/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 682/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 682/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 682/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 682/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 682/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 682/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 682/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 682/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 682/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 682/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 682/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001928, MRE: 0.018691, MAE: 0.003026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002157, MRE: 0.017008, MAE: 0.003398 \n",
      "\n",
      "Epoch 683/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 683/1200, Iteration 2/12, Loss: 0.0064\n",
      "Epoch 683/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 683/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 683/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 683/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 683/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 683/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 683/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 683/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 683/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 683/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 683/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001930, MRE: 0.018630, MAE: 0.003038 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002205, MRE: 0.016606, MAE: 0.003401 \n",
      "\n",
      "Epoch 684/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 684/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 684/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 684/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 684/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 684/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 684/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 684/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 684/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 684/1200, Iteration 10/12, Loss: 0.0050\n",
      "Epoch 684/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 684/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 684/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001906, MRE: 0.018758, MAE: 0.003041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002513, MRE: 0.016628, MAE: 0.003441 \n",
      "\n",
      "Epoch 685/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 685/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 685/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 685/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 685/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 685/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 685/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 685/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 685/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 685/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 685/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 685/1200, Iteration 12/12, Loss: 0.0053\n",
      "Epoch 685/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001876, MRE: 0.018735, MAE: 0.003019 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002227, MRE: 0.017155, MAE: 0.003477 \n",
      "\n",
      "Epoch 686/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 686/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 686/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 686/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 686/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 686/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 686/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 686/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 686/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 686/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 686/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 686/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 686/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001956, MRE: 0.018392, MAE: 0.003014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002312, MRE: 0.016826, MAE: 0.003400 \n",
      "\n",
      "Epoch 687/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 687/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 687/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 687/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 687/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 687/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 687/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 687/1200, Iteration 8/12, Loss: 0.0047\n",
      "Epoch 687/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 687/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 687/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 687/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 687/1200, Iteration 13/12, Loss: 0.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001865, MRE: 0.018577, MAE: 0.002996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002226, MRE: 0.017025, MAE: 0.003388 \n",
      "\n",
      "Epoch 688/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 688/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 688/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 688/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 688/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 688/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 688/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 688/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 688/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 688/1200, Iteration 10/12, Loss: 0.0056\n",
      "Epoch 688/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 688/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 688/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001906, MRE: 0.018690, MAE: 0.003060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002521, MRE: 0.016767, MAE: 0.003448 \n",
      "\n",
      "Epoch 689/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 689/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 689/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 689/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 689/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 689/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 689/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 689/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 689/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 689/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 689/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 689/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 689/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001914, MRE: 0.018295, MAE: 0.003027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002428, MRE: 0.016882, MAE: 0.003448 \n",
      "\n",
      "Epoch 690/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 690/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 690/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 690/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 690/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 690/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 690/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 690/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 690/1200, Iteration 9/12, Loss: 0.0056\n",
      "Epoch 690/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 690/1200, Iteration 11/12, Loss: 0.0056\n",
      "Epoch 690/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 690/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001961, MRE: 0.018459, MAE: 0.003045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002414, MRE: 0.016677, MAE: 0.003434 \n",
      "\n",
      "Epoch 691/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 691/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 691/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 691/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 691/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 691/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 691/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 691/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 691/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 691/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 691/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 691/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 691/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001852, MRE: 0.018679, MAE: 0.003006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002315, MRE: 0.016782, MAE: 0.003437 \n",
      "\n",
      "Epoch 692/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 692/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 692/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 692/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 692/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 692/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 692/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 692/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 692/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 692/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 692/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 692/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 692/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.002007, MRE: 0.018740, MAE: 0.003075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002231, MRE: 0.017215, MAE: 0.003498 \n",
      "\n",
      "Epoch 693/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 693/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 693/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 693/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 693/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 693/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 693/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 693/1200, Iteration 8/12, Loss: 0.0060\n",
      "Epoch 693/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 693/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 693/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 693/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 693/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001881, MRE: 0.018313, MAE: 0.003022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002239, MRE: 0.016991, MAE: 0.003439 \n",
      "\n",
      "Epoch 694/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 694/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 694/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 694/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 694/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 694/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 694/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 694/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 694/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 694/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 694/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 694/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 694/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001853, MRE: 0.018314, MAE: 0.002993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002389, MRE: 0.016590, MAE: 0.003395 \n",
      "\n",
      "Epoch 695/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 695/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 695/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 695/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 695/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 695/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 695/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 695/1200, Iteration 8/12, Loss: 0.0054\n",
      "Epoch 695/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 695/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 695/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 695/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 695/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001857, MRE: 0.018411, MAE: 0.002996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002285, MRE: 0.016720, MAE: 0.003420 \n",
      "\n",
      "Epoch 696/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 696/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 696/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 696/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 696/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 696/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 696/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 696/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 696/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 696/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 696/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 696/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 696/1200, Iteration 13/12, Loss: 0.0041\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.001926, MRE: 0.018687, MAE: 0.003058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002187, MRE: 0.017689, MAE: 0.003491 \n",
      "\n",
      "Epoch 697/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 697/1200, Iteration 2/12, Loss: 0.0074\n",
      "Epoch 697/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 697/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 697/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 697/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 697/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 697/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 697/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 697/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 697/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 697/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 697/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001829, MRE: 0.018411, MAE: 0.002978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002182, MRE: 0.016537, MAE: 0.003337 \n",
      "\n",
      "Epoch 698/1200, Iteration 1/12, Loss: 0.0068\n",
      "Epoch 698/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 698/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 698/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 698/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 698/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 698/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 698/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 698/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 698/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 698/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 698/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 698/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001860, MRE: 0.018648, MAE: 0.002974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002091, MRE: 0.016691, MAE: 0.003385 \n",
      "\n",
      "Epoch 699/1200, Iteration 1/12, Loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 699/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 699/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 699/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 699/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 699/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 699/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 699/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 699/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 699/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 699/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 699/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001956, MRE: 0.018363, MAE: 0.002960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002131, MRE: 0.016557, MAE: 0.003332 \n",
      "\n",
      "Epoch 700/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 700/1200, Iteration 2/12, Loss: 0.0065\n",
      "Epoch 700/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 700/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 700/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 700/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 700/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 700/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 700/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 700/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 700/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 700/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 700/1200, Iteration 13/12, Loss: 0.0072\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.002066, MRE: 0.018633, MAE: 0.003055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002338, MRE: 0.016456, MAE: 0.003371 \n",
      "\n",
      "Epoch 701/1200, Iteration 1/12, Loss: 0.0056\n",
      "Epoch 701/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 701/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 701/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 701/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 701/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 701/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 701/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 701/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 701/1200, Iteration 10/12, Loss: 0.0073\n",
      "Epoch 701/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 701/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 701/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001870, MRE: 0.018385, MAE: 0.002990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002277, MRE: 0.016519, MAE: 0.003390 \n",
      "\n",
      "Epoch 702/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 702/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 702/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 702/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 702/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 702/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 702/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 702/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 702/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 702/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 702/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 702/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 702/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001975, MRE: 0.018443, MAE: 0.003008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002272, MRE: 0.016768, MAE: 0.003411 \n",
      "\n",
      "Epoch 703/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 703/1200, Iteration 2/12, Loss: 0.0056\n",
      "Epoch 703/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 703/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 703/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 703/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 703/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 703/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 703/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 703/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 703/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 703/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 703/1200, Iteration 13/12, Loss: 0.0040\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001824, MRE: 0.018652, MAE: 0.002959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002142, MRE: 0.016596, MAE: 0.003348 \n",
      "\n",
      "Epoch 704/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 704/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 704/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 704/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 704/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 704/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 704/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 704/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 704/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 704/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 704/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 704/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 704/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001873, MRE: 0.018639, MAE: 0.003000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002187, MRE: 0.016641, MAE: 0.003377 \n",
      "\n",
      "Epoch 705/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 705/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 705/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 705/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 705/1200, Iteration 5/12, Loss: 0.0081\n",
      "Epoch 705/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 705/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 705/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 705/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 705/1200, Iteration 10/12, Loss: 0.0053\n",
      "Epoch 705/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 705/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 705/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001805, MRE: 0.018246, MAE: 0.002944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002227, MRE: 0.016691, MAE: 0.003366 \n",
      "\n",
      "Epoch 706/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 706/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 706/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 706/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 706/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 706/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 706/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 706/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 706/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 706/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 706/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 706/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 706/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001869, MRE: 0.019034, MAE: 0.003016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002481, MRE: 0.016584, MAE: 0.003420 \n",
      "\n",
      "Epoch 707/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 707/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 707/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 707/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 707/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 707/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 707/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 707/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 707/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 707/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 707/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 707/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 707/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.25%, Avg loss: 0.001859, MRE: 0.018585, MAE: 0.003000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002184, MRE: 0.017284, MAE: 0.003409 \n",
      "\n",
      "Epoch 708/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 708/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 708/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 708/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 708/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 708/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 708/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 708/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 708/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 708/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 708/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 708/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 708/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001806, MRE: 0.018284, MAE: 0.002958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002225, MRE: 0.016989, MAE: 0.003371 \n",
      "\n",
      "Epoch 709/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 709/1200, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 709/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 709/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 709/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 709/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 709/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 709/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 709/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 709/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 709/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 709/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 709/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001823, MRE: 0.018439, MAE: 0.002985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002216, MRE: 0.017119, MAE: 0.003411 \n",
      "\n",
      "Epoch 710/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 710/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 710/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 710/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 710/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 710/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 710/1200, Iteration 7/12, Loss: 0.0040\n",
      "Epoch 710/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 710/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 710/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 710/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 710/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 710/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001827, MRE: 0.018637, MAE: 0.002987 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002344, MRE: 0.016602, MAE: 0.003367 \n",
      "\n",
      "Epoch 711/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 711/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 711/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 711/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 711/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 711/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 711/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 711/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 711/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 711/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 711/1200, Iteration 11/12, Loss: 0.0068\n",
      "Epoch 711/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 711/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001867, MRE: 0.018928, MAE: 0.003016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002506, MRE: 0.016757, MAE: 0.003477 \n",
      "\n",
      "Epoch 712/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 712/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 712/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 712/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 712/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 712/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 712/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 712/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 712/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 712/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 712/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 712/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 712/1200, Iteration 13/12, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001898, MRE: 0.018614, MAE: 0.003027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002461, MRE: 0.016685, MAE: 0.003462 \n",
      "\n",
      "Epoch 713/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 713/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 713/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 713/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 713/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 713/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 713/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 713/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 713/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 713/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 713/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 713/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 713/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001872, MRE: 0.018220, MAE: 0.002969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002360, MRE: 0.016714, MAE: 0.003405 \n",
      "\n",
      "Epoch 714/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 714/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 714/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 714/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 714/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 714/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 714/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 714/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 714/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 714/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 714/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 714/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 714/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001927, MRE: 0.018900, MAE: 0.002973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002161, MRE: 0.016674, MAE: 0.003381 \n",
      "\n",
      "Epoch 715/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 715/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 715/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 715/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 715/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 715/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 715/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 715/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 715/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 715/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 715/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 715/1200, Iteration 12/12, Loss: 0.0057\n",
      "Epoch 715/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001849, MRE: 0.018793, MAE: 0.002994 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002297, MRE: 0.016409, MAE: 0.003338 \n",
      "\n",
      "Epoch 716/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 716/1200, Iteration 2/12, Loss: 0.0052\n",
      "Epoch 716/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 716/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 716/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 716/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 716/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 716/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 716/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 716/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 716/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 716/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 716/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001876, MRE: 0.018483, MAE: 0.003002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002207, MRE: 0.017126, MAE: 0.003438 \n",
      "\n",
      "Epoch 717/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 717/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 717/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 717/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 717/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 717/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 717/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 717/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 717/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 717/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 717/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 717/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 717/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001779, MRE: 0.018523, MAE: 0.002936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002188, MRE: 0.016339, MAE: 0.003335 \n",
      "\n",
      "Epoch 718/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 718/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 718/1200, Iteration 3/12, Loss: 0.0052\n",
      "Epoch 718/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 718/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 718/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 718/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 718/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 718/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 718/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 718/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 718/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 718/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001803, MRE: 0.018415, MAE: 0.002938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002252, MRE: 0.016280, MAE: 0.003313 \n",
      "\n",
      "Epoch 719/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 719/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 719/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 719/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 719/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 719/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 719/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 719/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 719/1200, Iteration 9/12, Loss: 0.0051\n",
      "Epoch 719/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 719/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 719/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 719/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001775, MRE: 0.017992, MAE: 0.002943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002218, MRE: 0.016821, MAE: 0.003373 \n",
      "\n",
      "Epoch 720/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 720/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 720/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 720/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 720/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 720/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 720/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 720/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 720/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 720/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 720/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 720/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 720/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001764, MRE: 0.018227, MAE: 0.002934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002250, MRE: 0.016186, MAE: 0.003307 \n",
      "\n",
      "Epoch 721/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 721/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 721/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 721/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 721/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 721/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 721/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 721/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 721/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 721/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 721/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 721/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 721/1200, Iteration 13/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001818, MRE: 0.018486, MAE: 0.002969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002237, MRE: 0.016484, MAE: 0.003340 \n",
      "\n",
      "Epoch 722/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 722/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 722/1200, Iteration 3/12, Loss: 0.0055\n",
      "Epoch 722/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 722/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 722/1200, Iteration 6/12, Loss: 0.0065\n",
      "Epoch 722/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 722/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 722/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 722/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 722/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 722/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 722/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001921, MRE: 0.018329, MAE: 0.002995 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002225, MRE: 0.016296, MAE: 0.003308 \n",
      "\n",
      "Epoch 723/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 723/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 723/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 723/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 723/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 723/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 723/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 723/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 723/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 723/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 723/1200, Iteration 11/12, Loss: 0.0066\n",
      "Epoch 723/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 723/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001813, MRE: 0.018724, MAE: 0.002957 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002260, MRE: 0.016466, MAE: 0.003342 \n",
      "\n",
      "Epoch 724/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 724/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 724/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 724/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 724/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 724/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 724/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 724/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 724/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 724/1200, Iteration 10/12, Loss: 0.0043\n",
      "Epoch 724/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 724/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 724/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001755, MRE: 0.018473, MAE: 0.002929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002229, MRE: 0.016462, MAE: 0.003392 \n",
      "\n",
      "Epoch 725/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 725/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 725/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 725/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 725/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 725/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 725/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 725/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 725/1200, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 725/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 725/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 725/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 725/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001915, MRE: 0.018231, MAE: 0.002965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002243, MRE: 0.016715, MAE: 0.003388 \n",
      "\n",
      "Epoch 726/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 726/1200, Iteration 2/12, Loss: 0.0051\n",
      "Epoch 726/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 726/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 726/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 726/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 726/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 726/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 726/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 726/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 726/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 726/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 726/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001771, MRE: 0.018255, MAE: 0.002956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002275, MRE: 0.016424, MAE: 0.003335 \n",
      "\n",
      "Epoch 727/1200, Iteration 1/12, Loss: 0.0053\n",
      "Epoch 727/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 727/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 727/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 727/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 727/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 727/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 727/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 727/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 727/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 727/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 727/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 727/1200, Iteration 13/12, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.002111, MRE: 0.023177, MAE: 0.003222 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002766, MRE: 0.017166, MAE: 0.003577 \n",
      "\n",
      "Epoch 728/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 728/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 728/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 728/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 728/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 728/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 728/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 728/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 728/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 728/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 728/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 728/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 728/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001748, MRE: 0.017959, MAE: 0.002922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002217, MRE: 0.016606, MAE: 0.003394 \n",
      "\n",
      "Epoch 729/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 729/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 729/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 729/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 729/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 729/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 729/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 729/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 729/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 729/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 729/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 729/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 729/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001747, MRE: 0.017903, MAE: 0.002911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002309, MRE: 0.016444, MAE: 0.003386 \n",
      "\n",
      "Epoch 730/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 730/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 730/1200, Iteration 3/12, Loss: 0.0045\n",
      "Epoch 730/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 730/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 730/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 730/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 730/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 730/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 730/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 730/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 730/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 730/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001802, MRE: 0.018321, MAE: 0.002969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002116, MRE: 0.016965, MAE: 0.003443 \n",
      "\n",
      "Epoch 731/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 731/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 731/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 731/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 731/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 731/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 731/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 731/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 731/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 731/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 731/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 731/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 731/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001992, MRE: 0.018356, MAE: 0.003011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002260, MRE: 0.016253, MAE: 0.003319 \n",
      "\n",
      "Epoch 732/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 732/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 732/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 732/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 732/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 732/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 732/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 732/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 732/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 732/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 732/1200, Iteration 11/12, Loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 732/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 732/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001961, MRE: 0.018038, MAE: 0.002954 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002171, MRE: 0.016364, MAE: 0.003313 \n",
      "\n",
      "Epoch 733/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 733/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 733/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 733/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 733/1200, Iteration 5/12, Loss: 0.0049\n",
      "Epoch 733/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 733/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 733/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 733/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 733/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 733/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 733/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 733/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001742, MRE: 0.018227, MAE: 0.002900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002120, MRE: 0.016144, MAE: 0.003290 \n",
      "\n",
      "Epoch 734/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 734/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 734/1200, Iteration 3/12, Loss: 0.0067\n",
      "Epoch 734/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 734/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 734/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 734/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 734/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 734/1200, Iteration 9/12, Loss: 0.0042\n",
      "Epoch 734/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 734/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 734/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 734/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001721, MRE: 0.018361, MAE: 0.002874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002150, MRE: 0.016196, MAE: 0.003303 \n",
      "\n",
      "Epoch 735/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 735/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 735/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 735/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 735/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 735/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 735/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 735/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 735/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 735/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 735/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 735/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 735/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001784, MRE: 0.022394, MAE: 0.002977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002252, MRE: 0.016257, MAE: 0.003320 \n",
      "\n",
      "Epoch 736/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 736/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 736/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 736/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 736/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 736/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 736/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 736/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 736/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 736/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 736/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 736/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 736/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001731, MRE: 0.017906, MAE: 0.002916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002088, MRE: 0.016388, MAE: 0.003350 \n",
      "\n",
      "Epoch 737/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 737/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 737/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 737/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 737/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 737/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 737/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 737/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 737/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 737/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 737/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 737/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 737/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001748, MRE: 0.018240, MAE: 0.002937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002241, MRE: 0.016212, MAE: 0.003327 \n",
      "\n",
      "Epoch 738/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 738/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 738/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 738/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 738/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 738/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 738/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 738/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 738/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 738/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 738/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 738/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 738/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001730, MRE: 0.017928, MAE: 0.002918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002128, MRE: 0.016663, MAE: 0.003402 \n",
      "\n",
      "Epoch 739/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 739/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 739/1200, Iteration 3/12, Loss: 0.0056\n",
      "Epoch 739/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 739/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 739/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 739/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 739/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 739/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 739/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 739/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 739/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 739/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001742, MRE: 0.017875, MAE: 0.002899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002096, MRE: 0.016689, MAE: 0.003316 \n",
      "\n",
      "Epoch 740/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 740/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 740/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 740/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 740/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 740/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 740/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 740/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 740/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 740/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 740/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 740/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 740/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001691, MRE: 0.017669, MAE: 0.002856 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002133, MRE: 0.016300, MAE: 0.003349 \n",
      "\n",
      "Epoch 741/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 741/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 741/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 741/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 741/1200, Iteration 5/12, Loss: 0.0050\n",
      "Epoch 741/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 741/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 741/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 741/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 741/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 741/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 741/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 741/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001717, MRE: 0.018019, MAE: 0.002911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002131, MRE: 0.016314, MAE: 0.003360 \n",
      "\n",
      "Epoch 742/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 742/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 742/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 742/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 742/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 742/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 742/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 742/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 742/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 742/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 742/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 742/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 742/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001764, MRE: 0.018594, MAE: 0.002942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002195, MRE: 0.016171, MAE: 0.003337 \n",
      "\n",
      "Epoch 743/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 743/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 743/1200, Iteration 3/12, Loss: 0.0044\n",
      "Epoch 743/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 743/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 743/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 743/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 743/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 743/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 743/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 743/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 743/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 743/1200, Iteration 13/12, Loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001722, MRE: 0.018675, MAE: 0.002896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002048, MRE: 0.016191, MAE: 0.003309 \n",
      "\n",
      "Epoch 744/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 744/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 744/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 744/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 744/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 744/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 744/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 744/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 744/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 744/1200, Iteration 10/12, Loss: 0.0063\n",
      "Epoch 744/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 744/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 744/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001714, MRE: 0.017975, MAE: 0.002876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002109, MRE: 0.016101, MAE: 0.003290 \n",
      "\n",
      "Epoch 745/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 745/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 745/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 745/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 745/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 745/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 745/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 745/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 745/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 745/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 745/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 745/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 745/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001734, MRE: 0.017911, MAE: 0.002905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002153, MRE: 0.016157, MAE: 0.003326 \n",
      "\n",
      "Epoch 746/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 746/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 746/1200, Iteration 3/12, Loss: 0.0046\n",
      "Epoch 746/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 746/1200, Iteration 5/12, Loss: 0.0046\n",
      "Epoch 746/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 746/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 746/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 746/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 746/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 746/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 746/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 746/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001715, MRE: 0.017996, MAE: 0.002896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002053, MRE: 0.016418, MAE: 0.003370 \n",
      "\n",
      "Epoch 747/1200, Iteration 1/12, Loss: 0.0058\n",
      "Epoch 747/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 747/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 747/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 747/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 747/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 747/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 747/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 747/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 747/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 747/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 747/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 747/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001850, MRE: 0.018013, MAE: 0.002914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002072, MRE: 0.016339, MAE: 0.003298 \n",
      "\n",
      "Epoch 748/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 748/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 748/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 748/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 748/1200, Iteration 5/12, Loss: 0.0008\n",
      "Epoch 748/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 748/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 748/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 748/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 748/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 748/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 748/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 748/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001735, MRE: 0.018246, MAE: 0.002918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002145, MRE: 0.016004, MAE: 0.003270 \n",
      "\n",
      "Epoch 749/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 749/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 749/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 749/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 749/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 749/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 749/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 749/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 749/1200, Iteration 9/12, Loss: 0.0055\n",
      "Epoch 749/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 749/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 749/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 749/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001676, MRE: 0.018120, MAE: 0.002862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002124, MRE: 0.015967, MAE: 0.003302 \n",
      "\n",
      "Epoch 750/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 750/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 750/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 750/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 750/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 750/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 750/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 750/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 750/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 750/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 750/1200, Iteration 11/12, Loss: 0.0054\n",
      "Epoch 750/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 750/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001732, MRE: 0.017747, MAE: 0.002897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002186, MRE: 0.016045, MAE: 0.003308 \n",
      "\n",
      "Epoch 751/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 751/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 751/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 751/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 751/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 751/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 751/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 751/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 751/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 751/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 751/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 751/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 751/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001693, MRE: 0.021013, MAE: 0.002881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002108, MRE: 0.016045, MAE: 0.003288 \n",
      "\n",
      "Epoch 752/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 752/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 752/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 752/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 752/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 752/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 752/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 752/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 752/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 752/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 752/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 752/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 752/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001805, MRE: 0.017777, MAE: 0.002881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002087, MRE: 0.015888, MAE: 0.003257 \n",
      "\n",
      "Epoch 753/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 753/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 753/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 753/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 753/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 753/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 753/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 753/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 753/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 753/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 753/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 753/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 753/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001681, MRE: 0.017519, MAE: 0.002871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002124, MRE: 0.016512, MAE: 0.003327 \n",
      "\n",
      "Epoch 754/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 754/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 754/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 754/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 754/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 754/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 754/1200, Iteration 7/12, Loss: 0.0061\n",
      "Epoch 754/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 754/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 754/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 754/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 754/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 754/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001842, MRE: 0.018417, MAE: 0.002959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002163, MRE: 0.016047, MAE: 0.003259 \n",
      "\n",
      "Epoch 755/1200, Iteration 1/12, Loss: 0.0041\n",
      "Epoch 755/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 755/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 755/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 755/1200, Iteration 5/12, Loss: 0.0053\n",
      "Epoch 755/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 755/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 755/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 755/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 755/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 755/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 755/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 755/1200, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001705, MRE: 0.017814, MAE: 0.002904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002123, MRE: 0.016372, MAE: 0.003338 \n",
      "\n",
      "Epoch 756/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 756/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 756/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 756/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 756/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 756/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 756/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 756/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 756/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 756/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 756/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 756/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 756/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001654, MRE: 0.017412, MAE: 0.002826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002056, MRE: 0.016023, MAE: 0.003272 \n",
      "\n",
      "Epoch 757/1200, Iteration 1/12, Loss: 0.0051\n",
      "Epoch 757/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 757/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 757/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 757/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 757/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 757/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 757/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 757/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 757/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 757/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 757/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 757/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001725, MRE: 0.018323, MAE: 0.002858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002029, MRE: 0.015944, MAE: 0.003264 \n",
      "\n",
      "Epoch 758/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 758/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 758/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 758/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 758/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 758/1200, Iteration 6/12, Loss: 0.0048\n",
      "Epoch 758/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 758/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 758/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 758/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 758/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 758/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 758/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001691, MRE: 0.017535, MAE: 0.002859 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002097, MRE: 0.015974, MAE: 0.003262 \n",
      "\n",
      "Epoch 759/1200, Iteration 1/12, Loss: 0.0068\n",
      "Epoch 759/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 759/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 759/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 759/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 759/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 759/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 759/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 759/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 759/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 759/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 759/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 759/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001666, MRE: 0.017924, MAE: 0.002852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002193, MRE: 0.016040, MAE: 0.003326 \n",
      "\n",
      "Epoch 760/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 760/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 760/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 760/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 760/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 760/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 760/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 760/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 760/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 760/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 760/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 760/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 760/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001716, MRE: 0.017844, MAE: 0.002882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002143, MRE: 0.016137, MAE: 0.003289 \n",
      "\n",
      "Epoch 761/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 761/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 761/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 761/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 761/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 761/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 761/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 761/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 761/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 761/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 761/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 761/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 761/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001728, MRE: 0.018130, MAE: 0.002894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002049, MRE: 0.016817, MAE: 0.003371 \n",
      "\n",
      "Epoch 762/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 762/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 762/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 762/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 762/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 762/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 762/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 762/1200, Iteration 8/12, Loss: 0.0064\n",
      "Epoch 762/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 762/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 762/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 762/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 762/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001664, MRE: 0.020738, MAE: 0.002853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002115, MRE: 0.015988, MAE: 0.003257 \n",
      "\n",
      "Epoch 763/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 763/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 763/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 763/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 763/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 763/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 763/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 763/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 763/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 763/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 763/1200, Iteration 11/12, Loss: 0.0059\n",
      "Epoch 763/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 763/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001735, MRE: 0.017782, MAE: 0.002886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002079, MRE: 0.016430, MAE: 0.003324 \n",
      "\n",
      "Epoch 764/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 764/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 764/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 764/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 764/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 764/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 764/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 764/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 764/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 764/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 764/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 764/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 764/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001682, MRE: 0.017808, MAE: 0.002890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002065, MRE: 0.017080, MAE: 0.003375 \n",
      "\n",
      "Epoch 765/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 765/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 765/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 765/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 765/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 765/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 765/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 765/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 765/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 765/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 765/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 765/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 765/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001668, MRE: 0.017693, MAE: 0.002852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002063, MRE: 0.016013, MAE: 0.003253 \n",
      "\n",
      "Epoch 766/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 766/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 766/1200, Iteration 3/12, Loss: 0.0062\n",
      "Epoch 766/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 766/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 766/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 766/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 766/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 766/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 766/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 766/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 766/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 766/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001635, MRE: 0.017313, MAE: 0.002820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002122, MRE: 0.016017, MAE: 0.003268 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 767/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 767/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 767/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 767/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 767/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 767/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 767/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 767/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 767/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 767/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 767/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 767/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001723, MRE: 0.018073, MAE: 0.002926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002064, MRE: 0.017267, MAE: 0.003375 \n",
      "\n",
      "Epoch 768/1200, Iteration 1/12, Loss: 0.0037\n",
      "Epoch 768/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 768/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 768/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 768/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 768/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 768/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 768/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 768/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 768/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 768/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 768/1200, Iteration 12/12, Loss: 0.0060\n",
      "Epoch 768/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001700, MRE: 0.018410, MAE: 0.002913 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002234, MRE: 0.015890, MAE: 0.003273 \n",
      "\n",
      "Epoch 769/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 769/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 769/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 769/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 769/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 769/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 769/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 769/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 769/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 769/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 769/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 769/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 769/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001632, MRE: 0.017359, MAE: 0.002816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002079, MRE: 0.016180, MAE: 0.003292 \n",
      "\n",
      "Epoch 770/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 770/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 770/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 770/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 770/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 770/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 770/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 770/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 770/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 770/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 770/1200, Iteration 11/12, Loss: 0.0046\n",
      "Epoch 770/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 770/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001643, MRE: 0.017217, MAE: 0.002825 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002145, MRE: 0.015953, MAE: 0.003297 \n",
      "\n",
      "Epoch 771/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 771/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 771/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 771/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 771/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 771/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 771/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 771/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 771/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 771/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 771/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 771/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 771/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001626, MRE: 0.017052, MAE: 0.002819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002185, MRE: 0.015869, MAE: 0.003283 \n",
      "\n",
      "Epoch 772/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 772/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 772/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 772/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 772/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 772/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 772/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 772/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 772/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 772/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 772/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 772/1200, Iteration 12/12, Loss: 0.0046\n",
      "Epoch 772/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001631, MRE: 0.017187, MAE: 0.002815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002112, MRE: 0.015869, MAE: 0.003277 \n",
      "\n",
      "Epoch 773/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 773/1200, Iteration 2/12, Loss: 0.0048\n",
      "Epoch 773/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 773/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 773/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 773/1200, Iteration 6/12, Loss: 0.0047\n",
      "Epoch 773/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 773/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 773/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 773/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 773/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 773/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 773/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001646, MRE: 0.018003, MAE: 0.002855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002173, MRE: 0.015935, MAE: 0.003279 \n",
      "\n",
      "Epoch 774/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 774/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 774/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 774/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 774/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 774/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 774/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 774/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 774/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 774/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 774/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 774/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 774/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001617, MRE: 0.017380, MAE: 0.002809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002095, MRE: 0.015683, MAE: 0.003240 \n",
      "\n",
      "Epoch 775/1200, Iteration 1/12, Loss: 0.0065\n",
      "Epoch 775/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 775/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 775/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 775/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 775/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 775/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 775/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 775/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 775/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 775/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 775/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 775/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001754, MRE: 0.017505, MAE: 0.002851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002038, MRE: 0.016073, MAE: 0.003260 \n",
      "\n",
      "Epoch 776/1200, Iteration 1/12, Loss: 0.0039\n",
      "Epoch 776/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 776/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 776/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 776/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 776/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 776/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 776/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 776/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 776/1200, Iteration 10/12, Loss: 0.0058\n",
      "Epoch 776/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 776/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 776/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001620, MRE: 0.017231, MAE: 0.002819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002164, MRE: 0.015802, MAE: 0.003260 \n",
      "\n",
      "Epoch 777/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 777/1200, Iteration 2/12, Loss: 0.0058\n",
      "Epoch 777/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 777/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 777/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 777/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 777/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 777/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 777/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 777/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 777/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 777/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 777/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001619, MRE: 0.017370, MAE: 0.002803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001960, MRE: 0.015860, MAE: 0.003232 \n",
      "\n",
      "Epoch 778/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 778/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 778/1200, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 778/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 778/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 778/1200, Iteration 6/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 778/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 778/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 778/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 778/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 778/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 778/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001707, MRE: 0.017447, MAE: 0.002853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001993, MRE: 0.016152, MAE: 0.003261 \n",
      "\n",
      "Epoch 779/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 779/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 779/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 779/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 779/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 779/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 779/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 779/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 779/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 779/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 779/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 779/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 779/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001601, MRE: 0.017233, MAE: 0.002791 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002066, MRE: 0.015915, MAE: 0.003272 \n",
      "\n",
      "Epoch 780/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 780/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 780/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 780/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 780/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 780/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 780/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 780/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 780/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 780/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 780/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 780/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 780/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001772, MRE: 0.017539, MAE: 0.002862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002053, MRE: 0.015816, MAE: 0.003228 \n",
      "\n",
      "Epoch 781/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 781/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 781/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 781/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 781/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 781/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 781/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 781/1200, Iteration 8/12, Loss: 0.0044\n",
      "Epoch 781/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 781/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 781/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 781/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 781/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001594, MRE: 0.017274, MAE: 0.002784 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002060, MRE: 0.015800, MAE: 0.003239 \n",
      "\n",
      "Epoch 782/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 782/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 782/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 782/1200, Iteration 4/12, Loss: 0.0062\n",
      "Epoch 782/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 782/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 782/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 782/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 782/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 782/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 782/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 782/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 782/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001627, MRE: 0.017998, MAE: 0.002826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002101, MRE: 0.015903, MAE: 0.003297 \n",
      "\n",
      "Epoch 783/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 783/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 783/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 783/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 783/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 783/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 783/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 783/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 783/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 783/1200, Iteration 10/12, Loss: 0.0056\n",
      "Epoch 783/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 783/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 783/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001596, MRE: 0.017545, MAE: 0.002797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002073, MRE: 0.015822, MAE: 0.003274 \n",
      "\n",
      "Epoch 784/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 784/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 784/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 784/1200, Iteration 4/12, Loss: 0.0048\n",
      "Epoch 784/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 784/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 784/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 784/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 784/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 784/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 784/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 784/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 784/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001595, MRE: 0.017295, MAE: 0.002802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002088, MRE: 0.015616, MAE: 0.003230 \n",
      "\n",
      "Epoch 785/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 785/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 785/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 785/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 785/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 785/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 785/1200, Iteration 7/12, Loss: 0.0055\n",
      "Epoch 785/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 785/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 785/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 785/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 785/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 785/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001772, MRE: 0.017643, MAE: 0.002911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001965, MRE: 0.016619, MAE: 0.003336 \n",
      "\n",
      "Epoch 786/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 786/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 786/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 786/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 786/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 786/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 786/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 786/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 786/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 786/1200, Iteration 10/12, Loss: 0.0054\n",
      "Epoch 786/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 786/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 786/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001700, MRE: 0.021877, MAE: 0.002893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002198, MRE: 0.015902, MAE: 0.003258 \n",
      "\n",
      "Epoch 787/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 787/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 787/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 787/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 787/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 787/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 787/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 787/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 787/1200, Iteration 9/12, Loss: 0.0116\n",
      "Epoch 787/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 787/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 787/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 787/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001679, MRE: 0.017748, MAE: 0.002836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002180, MRE: 0.015808, MAE: 0.003271 \n",
      "\n",
      "Epoch 788/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 788/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 788/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 788/1200, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 788/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 788/1200, Iteration 6/12, Loss: 0.0046\n",
      "Epoch 788/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 788/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 788/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 788/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 788/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 788/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 788/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001595, MRE: 0.017442, MAE: 0.002805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002075, MRE: 0.015734, MAE: 0.003227 \n",
      "\n",
      "Epoch 789/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 789/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 789/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 789/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 789/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 789/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 789/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 789/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 789/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 789/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 789/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 789/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 789/1200, Iteration 13/12, Loss: 0.0053\n",
      "Train Error: \n",
      " Accuracy: 98.38%, Avg loss: 0.001701, MRE: 0.017685, MAE: 0.002952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001994, MRE: 0.016919, MAE: 0.003476 \n",
      "\n",
      "Epoch 790/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 790/1200, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 790/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 790/1200, Iteration 4/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 790/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 790/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 790/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 790/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 790/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 790/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 790/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 790/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001609, MRE: 0.016974, MAE: 0.002798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002063, MRE: 0.015743, MAE: 0.003234 \n",
      "\n",
      "Epoch 791/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 791/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 791/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 791/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 791/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 791/1200, Iteration 6/12, Loss: 0.0053\n",
      "Epoch 791/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 791/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 791/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 791/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 791/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 791/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 791/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001580, MRE: 0.016949, MAE: 0.002786 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002142, MRE: 0.015860, MAE: 0.003288 \n",
      "\n",
      "Epoch 792/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 792/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 792/1200, Iteration 3/12, Loss: 0.0073\n",
      "Epoch 792/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 792/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 792/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 792/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 792/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 792/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 792/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 792/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 792/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 792/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001583, MRE: 0.017321, MAE: 0.002783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001988, MRE: 0.015687, MAE: 0.003223 \n",
      "\n",
      "Epoch 793/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 793/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 793/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 793/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 793/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 793/1200, Iteration 6/12, Loss: 0.0038\n",
      "Epoch 793/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 793/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 793/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 793/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 793/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 793/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 793/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001601, MRE: 0.017322, MAE: 0.002794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001938, MRE: 0.015991, MAE: 0.003270 \n",
      "\n",
      "Epoch 794/1200, Iteration 1/12, Loss: 0.0036\n",
      "Epoch 794/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 794/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 794/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 794/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 794/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 794/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 794/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 794/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 794/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 794/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 794/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 794/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001634, MRE: 0.017265, MAE: 0.002813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002179, MRE: 0.015773, MAE: 0.003262 \n",
      "\n",
      "Epoch 795/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 795/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 795/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 795/1200, Iteration 4/12, Loss: 0.0054\n",
      "Epoch 795/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 795/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 795/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 795/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 795/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 795/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 795/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 795/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 795/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001563, MRE: 0.017223, MAE: 0.002769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002023, MRE: 0.015855, MAE: 0.003234 \n",
      "\n",
      "Epoch 796/1200, Iteration 1/12, Loss: 0.0055\n",
      "Epoch 796/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 796/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 796/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 796/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 796/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 796/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 796/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 796/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 796/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 796/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 796/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 796/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001584, MRE: 0.017364, MAE: 0.002803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002094, MRE: 0.015631, MAE: 0.003210 \n",
      "\n",
      "Epoch 797/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 797/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 797/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 797/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 797/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 797/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 797/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 797/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 797/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 797/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 797/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 797/1200, Iteration 12/12, Loss: 0.0059\n",
      "Epoch 797/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001623, MRE: 0.017041, MAE: 0.002775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002015, MRE: 0.015961, MAE: 0.003297 \n",
      "\n",
      "Epoch 798/1200, Iteration 1/12, Loss: 0.0075\n",
      "Epoch 798/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 798/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 798/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 798/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 798/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 798/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 798/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 798/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 798/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 798/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 798/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 798/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001593, MRE: 0.016952, MAE: 0.002782 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002066, MRE: 0.015743, MAE: 0.003250 \n",
      "\n",
      "Epoch 799/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 799/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 799/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 799/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 799/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 799/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 799/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 799/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 799/1200, Iteration 9/12, Loss: 0.0045\n",
      "Epoch 799/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 799/1200, Iteration 11/12, Loss: 0.0049\n",
      "Epoch 799/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 799/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001551, MRE: 0.017051, MAE: 0.002750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002080, MRE: 0.015691, MAE: 0.003242 \n",
      "\n",
      "Epoch 800/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 800/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 800/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 800/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 800/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 800/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 800/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 800/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 800/1200, Iteration 9/12, Loss: 0.0053\n",
      "Epoch 800/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 800/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 800/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 800/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001554, MRE: 0.017037, MAE: 0.002763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002047, MRE: 0.015935, MAE: 0.003284 \n",
      "\n",
      "Epoch 801/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 801/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 801/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 801/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 801/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 801/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 801/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 801/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 801/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 801/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 801/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 801/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 801/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001622, MRE: 0.017092, MAE: 0.002805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001998, MRE: 0.015854, MAE: 0.003289 \n",
      "\n",
      "Epoch 802/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 802/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 802/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 802/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 802/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 802/1200, Iteration 6/12, Loss: 0.0063\n",
      "Epoch 802/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 802/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 802/1200, Iteration 9/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 802/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 802/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 802/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001564, MRE: 0.017466, MAE: 0.002796 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001963, MRE: 0.015802, MAE: 0.003305 \n",
      "\n",
      "Epoch 803/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 803/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 803/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 803/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 803/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 803/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 803/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 803/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 803/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 803/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 803/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 803/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 803/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001716, MRE: 0.017026, MAE: 0.002800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002013, MRE: 0.015596, MAE: 0.003241 \n",
      "\n",
      "Epoch 804/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 804/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 804/1200, Iteration 3/12, Loss: 0.0048\n",
      "Epoch 804/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 804/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 804/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 804/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 804/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 804/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 804/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 804/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 804/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 804/1200, Iteration 13/12, Loss: 0.0051\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001580, MRE: 0.019449, MAE: 0.002790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002187, MRE: 0.016079, MAE: 0.003319 \n",
      "\n",
      "Epoch 805/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 805/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 805/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 805/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 805/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 805/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 805/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 805/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 805/1200, Iteration 9/12, Loss: 0.0058\n",
      "Epoch 805/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 805/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 805/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 805/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001570, MRE: 0.016821, MAE: 0.002782 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002123, MRE: 0.015660, MAE: 0.003255 \n",
      "\n",
      "Epoch 806/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 806/1200, Iteration 2/12, Loss: 0.0041\n",
      "Epoch 806/1200, Iteration 3/12, Loss: 0.0060\n",
      "Epoch 806/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 806/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 806/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 806/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 806/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 806/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 806/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 806/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 806/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 806/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001534, MRE: 0.016947, MAE: 0.002735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001982, MRE: 0.015564, MAE: 0.003205 \n",
      "\n",
      "Epoch 807/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 807/1200, Iteration 2/12, Loss: 0.0049\n",
      "Epoch 807/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 807/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 807/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 807/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 807/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 807/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 807/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 807/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 807/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 807/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 807/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001536, MRE: 0.016649, MAE: 0.002742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002060, MRE: 0.015666, MAE: 0.003241 \n",
      "\n",
      "Epoch 808/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 808/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 808/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 808/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 808/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 808/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 808/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 808/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 808/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 808/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 808/1200, Iteration 11/12, Loss: 0.0062\n",
      "Epoch 808/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 808/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001538, MRE: 0.016700, MAE: 0.002755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002023, MRE: 0.015928, MAE: 0.003256 \n",
      "\n",
      "Epoch 809/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 809/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 809/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 809/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 809/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 809/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 809/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 809/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 809/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 809/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 809/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 809/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 809/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001652, MRE: 0.017258, MAE: 0.002826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002108, MRE: 0.015619, MAE: 0.003239 \n",
      "\n",
      "Epoch 810/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 810/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 810/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 810/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 810/1200, Iteration 5/12, Loss: 0.0045\n",
      "Epoch 810/1200, Iteration 6/12, Loss: 0.0051\n",
      "Epoch 810/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 810/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 810/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 810/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 810/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 810/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 810/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001646, MRE: 0.019781, MAE: 0.002818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002072, MRE: 0.015882, MAE: 0.003276 \n",
      "\n",
      "Epoch 811/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 811/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 811/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 811/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 811/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 811/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 811/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 811/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 811/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 811/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 811/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 811/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 811/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001558, MRE: 0.020007, MAE: 0.002758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002034, MRE: 0.015729, MAE: 0.003209 \n",
      "\n",
      "Epoch 812/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 812/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 812/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 812/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 812/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 812/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 812/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 812/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 812/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 812/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 812/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 812/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 812/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001524, MRE: 0.016423, MAE: 0.002717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002003, MRE: 0.015719, MAE: 0.003253 \n",
      "\n",
      "Epoch 813/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 813/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 813/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 813/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 813/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 813/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 813/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 813/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 813/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 813/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 813/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 813/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 813/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001546, MRE: 0.016795, MAE: 0.002762 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002020, MRE: 0.015593, MAE: 0.003251 \n",
      "\n",
      "Epoch 814/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 814/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 814/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 814/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 814/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 814/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 814/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 814/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 814/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 814/1200, Iteration 10/12, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 814/1200, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 814/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001528, MRE: 0.016747, MAE: 0.002736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002034, MRE: 0.015451, MAE: 0.003220 \n",
      "\n",
      "Epoch 815/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 815/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 815/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 815/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 815/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 815/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 815/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 815/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 815/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 815/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 815/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 815/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 815/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001520, MRE: 0.016554, MAE: 0.002724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001952, MRE: 0.015537, MAE: 0.003215 \n",
      "\n",
      "Epoch 816/1200, Iteration 1/12, Loss: 0.0044\n",
      "Epoch 816/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 816/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 816/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 816/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 816/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 816/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 816/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 816/1200, Iteration 9/12, Loss: 0.0052\n",
      "Epoch 816/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 816/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 816/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 816/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001603, MRE: 0.016746, MAE: 0.002780 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001967, MRE: 0.015913, MAE: 0.003199 \n",
      "\n",
      "Epoch 817/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 817/1200, Iteration 2/12, Loss: 0.0032\n",
      "Epoch 817/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 817/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 817/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 817/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 817/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 817/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 817/1200, Iteration 9/12, Loss: 0.0047\n",
      "Epoch 817/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 817/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 817/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 817/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001539, MRE: 0.016721, MAE: 0.002743 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001933, MRE: 0.015617, MAE: 0.003217 \n",
      "\n",
      "Epoch 818/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 818/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 818/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 818/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 818/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 818/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 818/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 818/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 818/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 818/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 818/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 818/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 818/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001532, MRE: 0.016668, MAE: 0.002756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001914, MRE: 0.015678, MAE: 0.003248 \n",
      "\n",
      "Epoch 819/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 819/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 819/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 819/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 819/1200, Iteration 5/12, Loss: 0.0055\n",
      "Epoch 819/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 819/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 819/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 819/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 819/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 819/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 819/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 819/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.001604, MRE: 0.017226, MAE: 0.002820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001968, MRE: 0.016730, MAE: 0.003360 \n",
      "\n",
      "Epoch 820/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 820/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 820/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 820/1200, Iteration 4/12, Loss: 0.0069\n",
      "Epoch 820/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 820/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 820/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 820/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 820/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 820/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 820/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 820/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 820/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001509, MRE: 0.016731, MAE: 0.002731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001975, MRE: 0.015519, MAE: 0.003206 \n",
      "\n",
      "Epoch 821/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 821/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 821/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 821/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 821/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 821/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 821/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 821/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 821/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 821/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 821/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 821/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 821/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001511, MRE: 0.016673, MAE: 0.002720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001942, MRE: 0.015458, MAE: 0.003167 \n",
      "\n",
      "Epoch 822/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 822/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 822/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 822/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 822/1200, Iteration 5/12, Loss: 0.0044\n",
      "Epoch 822/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 822/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 822/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 822/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 822/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 822/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 822/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 822/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001544, MRE: 0.017198, MAE: 0.002759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001922, MRE: 0.015452, MAE: 0.003188 \n",
      "\n",
      "Epoch 823/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 823/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 823/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 823/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 823/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 823/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 823/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 823/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 823/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 823/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 823/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 823/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 823/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001504, MRE: 0.016705, MAE: 0.002724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001961, MRE: 0.015385, MAE: 0.003212 \n",
      "\n",
      "Epoch 824/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 824/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 824/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 824/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 824/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 824/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 824/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 824/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 824/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 824/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 824/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 824/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 824/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001663, MRE: 0.017727, MAE: 0.002799 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001974, MRE: 0.015516, MAE: 0.003258 \n",
      "\n",
      "Epoch 825/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 825/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 825/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 825/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 825/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 825/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 825/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 825/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 825/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 825/1200, Iteration 10/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1200, Iteration 11/12, Loss: 0.0048\n",
      "Epoch 825/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 825/1200, Iteration 13/12, Loss: 0.0056\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001560, MRE: 0.017561, MAE: 0.002774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002138, MRE: 0.015569, MAE: 0.003247 \n",
      "\n",
      "Epoch 826/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 826/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 826/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 826/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 826/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 826/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 826/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 826/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 826/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 826/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 826/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 826/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 826/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001502, MRE: 0.017061, MAE: 0.002723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001955, MRE: 0.015388, MAE: 0.003207 \n",
      "\n",
      "Epoch 827/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 827/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 827/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 827/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 827/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 827/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 827/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 827/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 827/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 827/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 827/1200, Iteration 11/12, Loss: 0.0061\n",
      "Epoch 827/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 827/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001537, MRE: 0.016747, MAE: 0.002727 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001864, MRE: 0.015767, MAE: 0.003250 \n",
      "\n",
      "Epoch 828/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 828/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 828/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 828/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 828/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 828/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 828/1200, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 828/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 828/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 828/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 828/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 828/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 828/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001510, MRE: 0.016735, MAE: 0.002735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001935, MRE: 0.015422, MAE: 0.003186 \n",
      "\n",
      "Epoch 829/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 829/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 829/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 829/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 829/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 829/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 829/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 829/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 829/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 829/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 829/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 829/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 829/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001715, MRE: 0.016910, MAE: 0.002784 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002041, MRE: 0.015495, MAE: 0.003281 \n",
      "\n",
      "Epoch 830/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 830/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 830/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 830/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 830/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 830/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 830/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 830/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 830/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 830/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 830/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 830/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 830/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001476, MRE: 0.016571, MAE: 0.002690 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001967, MRE: 0.015590, MAE: 0.003202 \n",
      "\n",
      "Epoch 831/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 831/1200, Iteration 2/12, Loss: 0.0054\n",
      "Epoch 831/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 831/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 831/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 831/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 831/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 831/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 831/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 831/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 831/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 831/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 831/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001478, MRE: 0.016755, MAE: 0.002684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001939, MRE: 0.015439, MAE: 0.003188 \n",
      "\n",
      "Epoch 832/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 832/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 832/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 832/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 832/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 832/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 832/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 832/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 832/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 832/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 832/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 832/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 832/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001555, MRE: 0.017109, MAE: 0.002757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001823, MRE: 0.015865, MAE: 0.003249 \n",
      "\n",
      "Epoch 833/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 833/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 833/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 833/1200, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 833/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 833/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 833/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 833/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 833/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 833/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 833/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 833/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 833/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001486, MRE: 0.016915, MAE: 0.002683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001845, MRE: 0.015438, MAE: 0.003165 \n",
      "\n",
      "Epoch 834/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 834/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 834/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 834/1200, Iteration 4/12, Loss: 0.0053\n",
      "Epoch 834/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 834/1200, Iteration 6/12, Loss: 0.0042\n",
      "Epoch 834/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 834/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 834/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 834/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 834/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 834/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 834/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001488, MRE: 0.016710, MAE: 0.002684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001870, MRE: 0.015331, MAE: 0.003147 \n",
      "\n",
      "Epoch 835/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 835/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 835/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 835/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 835/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 835/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 835/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 835/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 835/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 835/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 835/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 835/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 835/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001520, MRE: 0.016897, MAE: 0.002728 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001871, MRE: 0.015622, MAE: 0.003202 \n",
      "\n",
      "Epoch 836/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 836/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 836/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 836/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 836/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 836/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 836/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 836/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 836/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 836/1200, Iteration 10/12, Loss: 0.0064\n",
      "Epoch 836/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 836/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 836/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001483, MRE: 0.016668, MAE: 0.002704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001921, MRE: 0.015366, MAE: 0.003186 \n",
      "\n",
      "Epoch 837/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 837/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 837/1200, Iteration 3/12, Loss: 0.0042\n",
      "Epoch 837/1200, Iteration 4/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 837/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 837/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 837/1200, Iteration 8/12, Loss: 0.0036\n",
      "Epoch 837/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 837/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 837/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 837/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 837/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001496, MRE: 0.016706, MAE: 0.002724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001941, MRE: 0.015712, MAE: 0.003175 \n",
      "\n",
      "Epoch 838/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 838/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 838/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 838/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 838/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 838/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 838/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 838/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 838/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 838/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 838/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 838/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 838/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001580, MRE: 0.016574, MAE: 0.002736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001917, MRE: 0.015685, MAE: 0.003194 \n",
      "\n",
      "Epoch 839/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 839/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 839/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 839/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 839/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 839/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 839/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 839/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 839/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 839/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 839/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 839/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 839/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001500, MRE: 0.016784, MAE: 0.002730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002057, MRE: 0.015451, MAE: 0.003215 \n",
      "\n",
      "Epoch 840/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 840/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 840/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 840/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 840/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 840/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 840/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 840/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 840/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 840/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 840/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 840/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 840/1200, Iteration 13/12, Loss: 0.0061\n",
      "Train Error: \n",
      " Accuracy: 98.75%, Avg loss: 0.001514, MRE: 0.016515, MAE: 0.002723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001843, MRE: 0.015794, MAE: 0.003216 \n",
      "\n",
      "Epoch 841/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 841/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 841/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 841/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 841/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 841/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 841/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 841/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 841/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 841/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 841/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 841/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 841/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001501, MRE: 0.016782, MAE: 0.002718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001960, MRE: 0.015282, MAE: 0.003192 \n",
      "\n",
      "Epoch 842/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 842/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 842/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 842/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 842/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 842/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 842/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 842/1200, Iteration 8/12, Loss: 0.0040\n",
      "Epoch 842/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 842/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 842/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 842/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 842/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001463, MRE: 0.016525, MAE: 0.002691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001944, MRE: 0.015349, MAE: 0.003224 \n",
      "\n",
      "Epoch 843/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 843/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 843/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 843/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 843/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 843/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 843/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 843/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 843/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 843/1200, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 843/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 843/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 843/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001624, MRE: 0.016695, MAE: 0.002733 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001952, MRE: 0.015230, MAE: 0.003173 \n",
      "\n",
      "Epoch 844/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 844/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 844/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 844/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 844/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 844/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 844/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 844/1200, Iteration 8/12, Loss: 0.0056\n",
      "Epoch 844/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 844/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 844/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 844/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 844/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001488, MRE: 0.016538, MAE: 0.002732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001874, MRE: 0.015611, MAE: 0.003246 \n",
      "\n",
      "Epoch 845/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 845/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 845/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 845/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 845/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 845/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 845/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 845/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 845/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 845/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 845/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 845/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 845/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001472, MRE: 0.019681, MAE: 0.002710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001945, MRE: 0.015381, MAE: 0.003189 \n",
      "\n",
      "Epoch 846/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 846/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 846/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 846/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 846/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 846/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 846/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 846/1200, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 846/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 846/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 846/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 846/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 846/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001517, MRE: 0.016656, MAE: 0.002735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001817, MRE: 0.015700, MAE: 0.003193 \n",
      "\n",
      "Epoch 847/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 847/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 847/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 847/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 847/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 847/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 847/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 847/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 847/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 847/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 847/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 847/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 847/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001456, MRE: 0.016320, MAE: 0.002676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001915, MRE: 0.015269, MAE: 0.003146 \n",
      "\n",
      "Epoch 848/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 848/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 848/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 848/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 848/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 848/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 848/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 848/1200, Iteration 8/12, Loss: 0.0041\n",
      "Epoch 848/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 848/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 848/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 848/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 848/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001454, MRE: 0.016494, MAE: 0.002664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001887, MRE: 0.015183, MAE: 0.003142 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 849/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 849/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 849/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 849/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 849/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 849/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 849/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 849/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 849/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 849/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 849/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 849/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001599, MRE: 0.017388, MAE: 0.002890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002258, MRE: 0.015681, MAE: 0.003281 \n",
      "\n",
      "Epoch 850/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 850/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 850/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 850/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 850/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 850/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 850/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 850/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 850/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 850/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 850/1200, Iteration 11/12, Loss: 0.0044\n",
      "Epoch 850/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 850/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001552, MRE: 0.016693, MAE: 0.002742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001895, MRE: 0.016049, MAE: 0.003247 \n",
      "\n",
      "Epoch 851/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 851/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 851/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 851/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 851/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 851/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 851/1200, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 851/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 851/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 851/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 851/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 851/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 851/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001468, MRE: 0.016397, MAE: 0.002659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001895, MRE: 0.015553, MAE: 0.003183 \n",
      "\n",
      "Epoch 852/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 852/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 852/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 852/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 852/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 852/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 852/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 852/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 852/1200, Iteration 9/12, Loss: 0.0044\n",
      "Epoch 852/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 852/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 852/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 852/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001527, MRE: 0.016628, MAE: 0.002702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001922, MRE: 0.015511, MAE: 0.003187 \n",
      "\n",
      "Epoch 853/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 853/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 853/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 853/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 853/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 853/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 853/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 853/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 853/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 853/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 853/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 853/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 853/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001500, MRE: 0.016980, MAE: 0.002731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002061, MRE: 0.015383, MAE: 0.003198 \n",
      "\n",
      "Epoch 854/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 854/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 854/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 854/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 854/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 854/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 854/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 854/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 854/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 854/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 854/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 854/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 854/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001436, MRE: 0.016356, MAE: 0.002648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001921, MRE: 0.015294, MAE: 0.003146 \n",
      "\n",
      "Epoch 855/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 855/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 855/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 855/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 855/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 855/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 855/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 855/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 855/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 855/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 855/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 855/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 855/1200, Iteration 13/12, Loss: 0.0054\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001450, MRE: 0.016888, MAE: 0.002688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001944, MRE: 0.015246, MAE: 0.003181 \n",
      "\n",
      "Epoch 856/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 856/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 856/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 856/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 856/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 856/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 856/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 856/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 856/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 856/1200, Iteration 10/12, Loss: 0.0046\n",
      "Epoch 856/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 856/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 856/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001469, MRE: 0.016227, MAE: 0.002675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001837, MRE: 0.015456, MAE: 0.003189 \n",
      "\n",
      "Epoch 857/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 857/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 857/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 857/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 857/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 857/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 857/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 857/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 857/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 857/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 857/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 857/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 857/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001437, MRE: 0.016261, MAE: 0.002665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001963, MRE: 0.015211, MAE: 0.003178 \n",
      "\n",
      "Epoch 858/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 858/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 858/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 858/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 858/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 858/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 858/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 858/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 858/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 858/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 858/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 858/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 858/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001565, MRE: 0.016282, MAE: 0.002678 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001945, MRE: 0.015242, MAE: 0.003155 \n",
      "\n",
      "Epoch 859/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 859/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 859/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 859/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 859/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 859/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 859/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 859/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 859/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 859/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 859/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 859/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 859/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001503, MRE: 0.017745, MAE: 0.002722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001945, MRE: 0.015315, MAE: 0.003170 \n",
      "\n",
      "Epoch 860/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 860/1200, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 860/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 860/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 860/1200, Iteration 5/12, Loss: 0.0008\n",
      "Epoch 860/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 860/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 860/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 860/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 860/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 860/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 860/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 860/1200, Iteration 13/12, Loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001438, MRE: 0.016408, MAE: 0.002685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001857, MRE: 0.015590, MAE: 0.003224 \n",
      "\n",
      "Epoch 861/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 861/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 861/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 861/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 861/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 861/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 861/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 861/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 861/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 861/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 861/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 861/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 861/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001596, MRE: 0.017058, MAE: 0.002721 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001962, MRE: 0.015360, MAE: 0.003194 \n",
      "\n",
      "Epoch 862/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 862/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 862/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 862/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 862/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 862/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 862/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 862/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 862/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 862/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 862/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 862/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 862/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001467, MRE: 0.016760, MAE: 0.002688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001833, MRE: 0.015540, MAE: 0.003185 \n",
      "\n",
      "Epoch 863/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 863/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 863/1200, Iteration 3/12, Loss: 0.0036\n",
      "Epoch 863/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 863/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 863/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 863/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 863/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 863/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 863/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 863/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 863/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 863/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001435, MRE: 0.016330, MAE: 0.002658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001907, MRE: 0.015397, MAE: 0.003181 \n",
      "\n",
      "Epoch 864/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 864/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 864/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 864/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 864/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 864/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 864/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 864/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 864/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 864/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 864/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 864/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 864/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001434, MRE: 0.016468, MAE: 0.002672 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001927, MRE: 0.015887, MAE: 0.003220 \n",
      "\n",
      "Epoch 865/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 865/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 865/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 865/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 865/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 865/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 865/1200, Iteration 7/12, Loss: 0.0050\n",
      "Epoch 865/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 865/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 865/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 865/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 865/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 865/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001431, MRE: 0.016547, MAE: 0.002673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001825, MRE: 0.015483, MAE: 0.003216 \n",
      "\n",
      "Epoch 866/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 866/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 866/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 866/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 866/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 866/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 866/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 866/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 866/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 866/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 866/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 866/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 866/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 98.88%, Avg loss: 0.001457, MRE: 0.016418, MAE: 0.002690 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001831, MRE: 0.015904, MAE: 0.003220 \n",
      "\n",
      "Epoch 867/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 867/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 867/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 867/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 867/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 867/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 867/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 867/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 867/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 867/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 867/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 867/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 867/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001418, MRE: 0.016519, MAE: 0.002656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001901, MRE: 0.015306, MAE: 0.003129 \n",
      "\n",
      "Epoch 868/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 868/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 868/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 868/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 868/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 868/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 868/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 868/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 868/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 868/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 868/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 868/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 868/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001402, MRE: 0.016140, MAE: 0.002623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001818, MRE: 0.015226, MAE: 0.003126 \n",
      "\n",
      "Epoch 869/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 869/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 869/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 869/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 869/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 869/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 869/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 869/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 869/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 869/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 869/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 869/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 869/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001502, MRE: 0.016630, MAE: 0.002696 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001839, MRE: 0.015352, MAE: 0.003193 \n",
      "\n",
      "Epoch 870/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 870/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 870/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 870/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 870/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 870/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 870/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 870/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 870/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 870/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 870/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 870/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 870/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001411, MRE: 0.016371, MAE: 0.002652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001868, MRE: 0.015546, MAE: 0.003155 \n",
      "\n",
      "Epoch 871/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 871/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 871/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 871/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 871/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 871/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 871/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 871/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 871/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 871/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 871/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 871/1200, Iteration 12/12, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001462, MRE: 0.016069, MAE: 0.002667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001887, MRE: 0.015407, MAE: 0.003205 \n",
      "\n",
      "Epoch 872/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 872/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 872/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 872/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 872/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 872/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 872/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 872/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 872/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 872/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 872/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 872/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 872/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001522, MRE: 0.016494, MAE: 0.002715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001868, MRE: 0.015782, MAE: 0.003267 \n",
      "\n",
      "Epoch 873/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 873/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 873/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 873/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 873/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 873/1200, Iteration 6/12, Loss: 0.0055\n",
      "Epoch 873/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 873/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 873/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 873/1200, Iteration 10/12, Loss: 0.0047\n",
      "Epoch 873/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 873/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 873/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001425, MRE: 0.016321, MAE: 0.002663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001813, MRE: 0.015327, MAE: 0.003199 \n",
      "\n",
      "Epoch 874/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 874/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 874/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 874/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 874/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 874/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 874/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 874/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 874/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 874/1200, Iteration 10/12, Loss: 0.0045\n",
      "Epoch 874/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 874/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 874/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001397, MRE: 0.016256, MAE: 0.002626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001918, MRE: 0.015274, MAE: 0.003186 \n",
      "\n",
      "Epoch 875/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 875/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 875/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 875/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 875/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 875/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 875/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 875/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 875/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 875/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 875/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 875/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 875/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001409, MRE: 0.016599, MAE: 0.002639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001817, MRE: 0.015356, MAE: 0.003153 \n",
      "\n",
      "Epoch 876/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 876/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 876/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 876/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 876/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 876/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 876/1200, Iteration 7/12, Loss: 0.0037\n",
      "Epoch 876/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 876/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 876/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 876/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 876/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 876/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001431, MRE: 0.016598, MAE: 0.002669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001845, MRE: 0.015262, MAE: 0.003188 \n",
      "\n",
      "Epoch 877/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 877/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 877/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 877/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 877/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 877/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 877/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 877/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 877/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 877/1200, Iteration 10/12, Loss: 0.0049\n",
      "Epoch 877/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 877/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 877/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001396, MRE: 0.016236, MAE: 0.002625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001860, MRE: 0.015325, MAE: 0.003165 \n",
      "\n",
      "Epoch 878/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 878/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 878/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 878/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 878/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 878/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 878/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 878/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 878/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 878/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 878/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 878/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 878/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001431, MRE: 0.016345, MAE: 0.002652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001854, MRE: 0.015170, MAE: 0.003144 \n",
      "\n",
      "Epoch 879/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 879/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 879/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 879/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 879/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 879/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 879/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 879/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 879/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 879/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 879/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 879/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 879/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001411, MRE: 0.016881, MAE: 0.002640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001936, MRE: 0.015166, MAE: 0.003167 \n",
      "\n",
      "Epoch 880/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 880/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 880/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 880/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 880/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 880/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 880/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 880/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 880/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 880/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 880/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 880/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 880/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001415, MRE: 0.016244, MAE: 0.002670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001928, MRE: 0.015295, MAE: 0.003166 \n",
      "\n",
      "Epoch 881/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 881/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 881/1200, Iteration 3/12, Loss: 0.0047\n",
      "Epoch 881/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 881/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 881/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 881/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 881/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 881/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 881/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 881/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 881/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 881/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001398, MRE: 0.016126, MAE: 0.002629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001856, MRE: 0.015524, MAE: 0.003205 \n",
      "\n",
      "Epoch 882/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 882/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 882/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 882/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 882/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 882/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 882/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 882/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 882/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 882/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 882/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 882/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 882/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001488, MRE: 0.016596, MAE: 0.002666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001940, MRE: 0.015233, MAE: 0.003158 \n",
      "\n",
      "Epoch 883/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 883/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 883/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 883/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 883/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 883/1200, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 883/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 883/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 883/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 883/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 883/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 883/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 883/1200, Iteration 13/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001403, MRE: 0.016135, MAE: 0.002639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001854, MRE: 0.015096, MAE: 0.003121 \n",
      "\n",
      "Epoch 884/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 884/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 884/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 884/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 884/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 884/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 884/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 884/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 884/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 884/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 884/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 884/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 884/1200, Iteration 13/12, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001389, MRE: 0.016173, MAE: 0.002606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001788, MRE: 0.015180, MAE: 0.003123 \n",
      "\n",
      "Epoch 885/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 885/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 885/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 885/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 885/1200, Iteration 5/12, Loss: 0.0047\n",
      "Epoch 885/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 885/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 885/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 885/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 885/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 885/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 885/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 885/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001394, MRE: 0.016203, MAE: 0.002624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001838, MRE: 0.015283, MAE: 0.003153 \n",
      "\n",
      "Epoch 886/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 886/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 886/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 886/1200, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 886/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 886/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 886/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 886/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 886/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 886/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 886/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 886/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 886/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001494, MRE: 0.015968, MAE: 0.002625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001814, MRE: 0.015301, MAE: 0.003147 \n",
      "\n",
      "Epoch 887/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 887/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 887/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 887/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 887/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 887/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 887/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 887/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 887/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 887/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 887/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 887/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 887/1200, Iteration 13/12, Loss: 0.0066\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001432, MRE: 0.017070, MAE: 0.002701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001962, MRE: 0.015217, MAE: 0.003160 \n",
      "\n",
      "Epoch 888/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 888/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 888/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 888/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 888/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 888/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 888/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 888/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 888/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 888/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 888/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 888/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 888/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001465, MRE: 0.016179, MAE: 0.002668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001812, MRE: 0.015483, MAE: 0.003225 \n",
      "\n",
      "Epoch 889/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 889/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 889/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 889/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 889/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 889/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 889/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 889/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 889/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 889/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 889/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 889/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 889/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001403, MRE: 0.016340, MAE: 0.002649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001886, MRE: 0.015179, MAE: 0.003129 \n",
      "\n",
      "Epoch 890/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 890/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 890/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 890/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 890/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 890/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 890/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 890/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 890/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 890/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 890/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 890/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 890/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001378, MRE: 0.016372, MAE: 0.002622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001889, MRE: 0.015146, MAE: 0.003130 \n",
      "\n",
      "Epoch 891/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 891/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 891/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 891/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 891/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 891/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 891/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 891/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 891/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 891/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 891/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 891/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 891/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001393, MRE: 0.016721, MAE: 0.002641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001848, MRE: 0.015215, MAE: 0.003178 \n",
      "\n",
      "Epoch 892/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 892/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 892/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 892/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 892/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 892/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 892/1200, Iteration 7/12, Loss: 0.0042\n",
      "Epoch 892/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 892/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 892/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 892/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 892/1200, Iteration 12/12, Loss: 0.0048\n",
      "Epoch 892/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001395, MRE: 0.016190, MAE: 0.002636 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001821, MRE: 0.015590, MAE: 0.003204 \n",
      "\n",
      "Epoch 893/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 893/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 893/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 893/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 893/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 893/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 893/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 893/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 893/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 893/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 893/1200, Iteration 11/12, Loss: 0.0052\n",
      "Epoch 893/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 893/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001397, MRE: 0.016079, MAE: 0.002622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001957, MRE: 0.015345, MAE: 0.003177 \n",
      "\n",
      "Epoch 894/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 894/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 894/1200, Iteration 3/12, Loss: 0.0041\n",
      "Epoch 894/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 894/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 894/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 894/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 894/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 894/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 894/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 894/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 894/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 894/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001372, MRE: 0.016615, MAE: 0.002616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001848, MRE: 0.015264, MAE: 0.003148 \n",
      "\n",
      "Epoch 895/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 895/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 895/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 895/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 895/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 895/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 895/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 895/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 895/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 895/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 895/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 895/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 895/1200, Iteration 13/12, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001519, MRE: 0.016147, MAE: 0.002619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001820, MRE: 0.015227, MAE: 0.003152 \n",
      "\n",
      "Epoch 896/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 896/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 896/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 896/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 896/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 896/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 896/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 896/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 896/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 896/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 896/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 896/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 896/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 98.62%, Avg loss: 0.001500, MRE: 0.016881, MAE: 0.002731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001824, MRE: 0.016501, MAE: 0.003308 \n",
      "\n",
      "Epoch 897/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 897/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 897/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 897/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 897/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 897/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 897/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 897/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 897/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 897/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 897/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 897/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 897/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001381, MRE: 0.016895, MAE: 0.002638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001912, MRE: 0.015197, MAE: 0.003178 \n",
      "\n",
      "Epoch 898/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 898/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 898/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 898/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 898/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 898/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 898/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 898/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 898/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 898/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 898/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 898/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 898/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001368, MRE: 0.016104, MAE: 0.002599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001896, MRE: 0.015156, MAE: 0.003183 \n",
      "\n",
      "Epoch 899/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 899/1200, Iteration 2/12, Loss: 0.0037\n",
      "Epoch 899/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 899/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 899/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 899/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 899/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 899/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 899/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 899/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 899/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 899/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 899/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001553, MRE: 0.016272, MAE: 0.002637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001833, MRE: 0.015001, MAE: 0.003118 \n",
      "\n",
      "Epoch 900/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 900/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 900/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 900/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 900/1200, Iteration 5/12, Loss: 0.0051\n",
      "Epoch 900/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 900/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 900/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 900/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 900/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 900/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 900/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 900/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001408, MRE: 0.016233, MAE: 0.002658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002014, MRE: 0.015177, MAE: 0.003188 \n",
      "\n",
      "Epoch 901/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 901/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 901/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 901/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 901/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 901/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 901/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 901/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 901/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 901/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 901/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 901/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 901/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001430, MRE: 0.015900, MAE: 0.002598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001894, MRE: 0.015161, MAE: 0.003141 \n",
      "\n",
      "Epoch 902/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 902/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 902/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 902/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 902/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 902/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 902/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 902/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 902/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 902/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 902/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 902/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 902/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001427, MRE: 0.016287, MAE: 0.002659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001978, MRE: 0.015180, MAE: 0.003207 \n",
      "\n",
      "Epoch 903/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 903/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 903/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 903/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 903/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 903/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 903/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 903/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 903/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 903/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 903/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 903/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 903/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001410, MRE: 0.016426, MAE: 0.002650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001987, MRE: 0.015211, MAE: 0.003177 \n",
      "\n",
      "Epoch 904/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 904/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 904/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 904/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 904/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 904/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 904/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 904/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 904/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 904/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 904/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 904/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 904/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001352, MRE: 0.015759, MAE: 0.002589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001845, MRE: 0.015350, MAE: 0.003169 \n",
      "\n",
      "Epoch 905/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 905/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 905/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 905/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 905/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 905/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 905/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 905/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 905/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 905/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 905/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 905/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 905/1200, Iteration 13/12, Loss: 0.0066\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001343, MRE: 0.015863, MAE: 0.002591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001919, MRE: 0.015195, MAE: 0.003155 \n",
      "\n",
      "Epoch 906/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 906/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 906/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 906/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 906/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 906/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 906/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 906/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 906/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 906/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 906/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 906/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 906/1200, Iteration 13/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001345, MRE: 0.015921, MAE: 0.002575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001783, MRE: 0.015397, MAE: 0.003189 \n",
      "\n",
      "Epoch 907/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 907/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 907/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 907/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 907/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 907/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 907/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 907/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 907/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 907/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 907/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 907/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 907/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001338, MRE: 0.015729, MAE: 0.002573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001854, MRE: 0.015218, MAE: 0.003169 \n",
      "\n",
      "Epoch 908/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 908/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 908/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 908/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 908/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 908/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 908/1200, Iteration 7/12, Loss: 0.0048\n",
      "Epoch 908/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 908/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 908/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 908/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 908/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 908/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001403, MRE: 0.016398, MAE: 0.002614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001854, MRE: 0.015097, MAE: 0.003133 \n",
      "\n",
      "Epoch 909/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 909/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 909/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 909/1200, Iteration 4/12, Loss: 0.0040\n",
      "Epoch 909/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 909/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 909/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 909/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 909/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 909/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 909/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 909/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 909/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001364, MRE: 0.016085, MAE: 0.002609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001847, MRE: 0.015639, MAE: 0.003195 \n",
      "\n",
      "Epoch 910/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 910/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 910/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 910/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 910/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 910/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 910/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 910/1200, Iteration 8/12, Loss: 0.0048\n",
      "Epoch 910/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 910/1200, Iteration 10/12, Loss: 0.0042\n",
      "Epoch 910/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 910/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 910/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001331, MRE: 0.015608, MAE: 0.002566 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001882, MRE: 0.015267, MAE: 0.003158 \n",
      "\n",
      "Epoch 911/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 911/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 911/1200, Iteration 3/12, Loss: 0.0051\n",
      "Epoch 911/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 911/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 911/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 911/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 911/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 911/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 911/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 911/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 911/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 911/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001329, MRE: 0.015880, MAE: 0.002586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001880, MRE: 0.015228, MAE: 0.003220 \n",
      "\n",
      "Epoch 912/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 912/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 912/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 912/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 912/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 912/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 912/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 912/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 912/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 912/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 912/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 912/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 912/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001337, MRE: 0.015913, MAE: 0.002601 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001936, MRE: 0.015239, MAE: 0.003224 \n",
      "\n",
      "Epoch 913/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 913/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 913/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 913/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 913/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 913/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 913/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 913/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 913/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 913/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 913/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 913/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 913/1200, Iteration 13/12, Loss: 0.0072\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001323, MRE: 0.015644, MAE: 0.002553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001854, MRE: 0.015254, MAE: 0.003150 \n",
      "\n",
      "Epoch 914/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 914/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 914/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 914/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 914/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 914/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 914/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 914/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 914/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 914/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 914/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 914/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 914/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001367, MRE: 0.015742, MAE: 0.002589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001888, MRE: 0.015239, MAE: 0.003142 \n",
      "\n",
      "Epoch 915/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 915/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 915/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 915/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 915/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 915/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 915/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 915/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 915/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 915/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 915/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 915/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 915/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001400, MRE: 0.016991, MAE: 0.002613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001796, MRE: 0.015188, MAE: 0.003135 \n",
      "\n",
      "Epoch 916/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 916/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 916/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 916/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 916/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 916/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 916/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 916/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 916/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 916/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 916/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 916/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 916/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001340, MRE: 0.016155, MAE: 0.002588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001891, MRE: 0.015136, MAE: 0.003139 \n",
      "\n",
      "Epoch 917/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 917/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 917/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 917/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 917/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 917/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 917/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 917/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 917/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 917/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 917/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 917/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 917/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001325, MRE: 0.015932, MAE: 0.002576 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001774, MRE: 0.015406, MAE: 0.003190 \n",
      "\n",
      "Epoch 918/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 918/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 918/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 918/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 918/1200, Iteration 5/12, Loss: 0.0008\n",
      "Epoch 918/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 918/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 918/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 918/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 918/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 918/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 918/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 918/1200, Iteration 13/12, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001535, MRE: 0.016275, MAE: 0.002636 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001818, MRE: 0.015065, MAE: 0.003119 \n",
      "\n",
      "Epoch 919/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 919/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 919/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 919/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 919/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 919/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 919/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 919/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 919/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 919/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 919/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 919/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 919/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001349, MRE: 0.015609, MAE: 0.002593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001803, MRE: 0.015506, MAE: 0.003176 \n",
      "\n",
      "Epoch 920/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 920/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 920/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 920/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 920/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 920/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 920/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 920/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 920/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 920/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 920/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 920/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 920/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001380, MRE: 0.016368, MAE: 0.002625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001847, MRE: 0.015093, MAE: 0.003108 \n",
      "\n",
      "Epoch 921/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 921/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 921/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 921/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 921/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 921/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 921/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 921/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 921/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 921/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 921/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 921/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 921/1200, Iteration 13/12, Loss: 0.0042\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001380, MRE: 0.016162, MAE: 0.002685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002019, MRE: 0.015139, MAE: 0.003177 \n",
      "\n",
      "Epoch 922/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 922/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 922/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 922/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 922/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 922/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 922/1200, Iteration 7/12, Loss: 0.0053\n",
      "Epoch 922/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 922/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 922/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 922/1200, Iteration 11/12, Loss: 0.0040\n",
      "Epoch 922/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 922/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001428, MRE: 0.016150, MAE: 0.002665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002034, MRE: 0.015231, MAE: 0.003225 \n",
      "\n",
      "Epoch 923/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 923/1200, Iteration 2/12, Loss: 0.0038\n",
      "Epoch 923/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 923/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 923/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 923/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 923/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 923/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 923/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 923/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 923/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 923/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 923/1200, Iteration 13/12, Loss: 0.0051\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001388, MRE: 0.016008, MAE: 0.002640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002078, MRE: 0.015244, MAE: 0.003225 \n",
      "\n",
      "Epoch 924/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 924/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 924/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 924/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 924/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 924/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 924/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 924/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 924/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 924/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 924/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 924/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 924/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001420, MRE: 0.016387, MAE: 0.002708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002139, MRE: 0.015479, MAE: 0.003223 \n",
      "\n",
      "Epoch 925/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 925/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 925/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 925/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 925/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 925/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 925/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 925/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 925/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 925/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 925/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 925/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 925/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001312, MRE: 0.015908, MAE: 0.002580 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001849, MRE: 0.015589, MAE: 0.003256 \n",
      "\n",
      "Epoch 926/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 926/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 926/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 926/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 926/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 926/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 926/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 926/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 926/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 926/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 926/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 926/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 926/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001327, MRE: 0.015965, MAE: 0.002565 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001794, MRE: 0.015348, MAE: 0.003143 \n",
      "\n",
      "Epoch 927/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 927/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 927/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 927/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 927/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 927/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 927/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 927/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 927/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 927/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 927/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 927/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 927/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001326, MRE: 0.016201, MAE: 0.002572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001844, MRE: 0.015165, MAE: 0.003119 \n",
      "\n",
      "Epoch 928/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 928/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 928/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 928/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 928/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 928/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 928/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 928/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 928/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 928/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 928/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 928/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 928/1200, Iteration 13/12, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001318, MRE: 0.015754, MAE: 0.002567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001828, MRE: 0.015186, MAE: 0.003128 \n",
      "\n",
      "Epoch 929/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 929/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 929/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 929/1200, Iteration 4/12, Loss: 0.0039\n",
      "Epoch 929/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 929/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 929/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 929/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 929/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 929/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 929/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 929/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 929/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001299, MRE: 0.015690, MAE: 0.002564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001784, MRE: 0.015421, MAE: 0.003251 \n",
      "\n",
      "Epoch 930/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 930/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 930/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 930/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 930/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 930/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 930/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 930/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 930/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 930/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 930/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 930/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 930/1200, Iteration 13/12, Loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001323, MRE: 0.015824, MAE: 0.002585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001707, MRE: 0.015235, MAE: 0.003189 \n",
      "\n",
      "Epoch 931/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 931/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 931/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 931/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 931/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 931/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 931/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 931/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 931/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 931/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 931/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 931/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 931/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001323, MRE: 0.015887, MAE: 0.002571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001744, MRE: 0.014930, MAE: 0.003097 \n",
      "\n",
      "Epoch 932/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 932/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 932/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 932/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 932/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 932/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 932/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 932/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 932/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 932/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 932/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 932/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 932/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001379, MRE: 0.015714, MAE: 0.002568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001743, MRE: 0.015316, MAE: 0.003198 \n",
      "\n",
      "Epoch 933/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 933/1200, Iteration 2/12, Loss: 0.0007\n",
      "Epoch 933/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 933/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 933/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 933/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 933/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 933/1200, Iteration 8/12, Loss: 0.0043\n",
      "Epoch 933/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 933/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 933/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 933/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 933/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001297, MRE: 0.016017, MAE: 0.002559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001784, MRE: 0.015037, MAE: 0.003161 \n",
      "\n",
      "Epoch 934/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 934/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 934/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 934/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 934/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 934/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 934/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 934/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 934/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 934/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 934/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 934/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 934/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001288, MRE: 0.015806, MAE: 0.002556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001769, MRE: 0.015238, MAE: 0.003212 \n",
      "\n",
      "Epoch 935/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 935/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 935/1200, Iteration 3/12, Loss: 0.0050\n",
      "Epoch 935/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 935/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 935/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 935/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 935/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 935/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 935/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 935/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 935/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 935/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001434, MRE: 0.015692, MAE: 0.002596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001755, MRE: 0.015697, MAE: 0.003166 \n",
      "\n",
      "Epoch 936/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 936/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 936/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 936/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 936/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 936/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 936/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 936/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 936/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 936/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 936/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 936/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 936/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001403, MRE: 0.015862, MAE: 0.002575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001750, MRE: 0.015064, MAE: 0.003129 \n",
      "\n",
      "Epoch 937/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 937/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 937/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 937/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 937/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 937/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 937/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 937/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 937/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 937/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 937/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 937/1200, Iteration 12/12, Loss: 0.0058\n",
      "Epoch 937/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001312, MRE: 0.015699, MAE: 0.002575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001848, MRE: 0.015157, MAE: 0.003145 \n",
      "\n",
      "Epoch 938/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 938/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 938/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 938/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 938/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 938/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 938/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 938/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 938/1200, Iteration 9/12, Loss: 0.0039\n",
      "Epoch 938/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 938/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 938/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 938/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001329, MRE: 0.015956, MAE: 0.002585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001906, MRE: 0.015154, MAE: 0.003123 \n",
      "\n",
      "Epoch 939/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 939/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 939/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 939/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 939/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 939/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 939/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 939/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 939/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 939/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 939/1200, Iteration 11/12, Loss: 0.0030\n",
      "Epoch 939/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 939/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001316, MRE: 0.015591, MAE: 0.002567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001738, MRE: 0.015291, MAE: 0.003187 \n",
      "\n",
      "Epoch 940/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 940/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 940/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 940/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 940/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 940/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 940/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 940/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 940/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 940/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 940/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 940/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 940/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001367, MRE: 0.016247, MAE: 0.002593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001804, MRE: 0.014997, MAE: 0.003128 \n",
      "\n",
      "Epoch 941/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 941/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 941/1200, Iteration 3/12, Loss: 0.0037\n",
      "Epoch 941/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 941/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 941/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 941/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 941/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 941/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 941/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 941/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 941/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 941/1200, Iteration 13/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001303, MRE: 0.015678, MAE: 0.002548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001803, MRE: 0.014920, MAE: 0.003089 \n",
      "\n",
      "Epoch 942/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 942/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 942/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 942/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 942/1200, Iteration 5/12, Loss: 0.0034\n",
      "Epoch 942/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 942/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 942/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 942/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 942/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 942/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 942/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 942/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001292, MRE: 0.016008, MAE: 0.002550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001836, MRE: 0.014897, MAE: 0.003127 \n",
      "\n",
      "Epoch 943/1200, Iteration 1/12, Loss: 0.0042\n",
      "Epoch 943/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 943/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 943/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 943/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 943/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 943/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 943/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 943/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 943/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 943/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 943/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 943/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001294, MRE: 0.015912, MAE: 0.002563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001803, MRE: 0.015807, MAE: 0.003250 \n",
      "\n",
      "Epoch 944/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 944/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 944/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 944/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 944/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 944/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 944/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 944/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 944/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 944/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 944/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 944/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 944/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001290, MRE: 0.015583, MAE: 0.002531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001899, MRE: 0.015173, MAE: 0.003147 \n",
      "\n",
      "Epoch 945/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 945/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 945/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 945/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 945/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 945/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 945/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 945/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 945/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 945/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 945/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 945/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 945/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001424, MRE: 0.015707, MAE: 0.002588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001954, MRE: 0.015163, MAE: 0.003189 \n",
      "\n",
      "Epoch 946/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 946/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 946/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 946/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 946/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 946/1200, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 946/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 946/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 946/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 946/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 946/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 946/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 946/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001289, MRE: 0.015924, MAE: 0.002562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001901, MRE: 0.015258, MAE: 0.003212 \n",
      "\n",
      "Epoch 947/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 947/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 947/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 947/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 947/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 947/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 947/1200, Iteration 7/12, Loss: 0.0052\n",
      "Epoch 947/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 947/1200, Iteration 9/12, Loss: 0.0034\n",
      "Epoch 947/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 947/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 947/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 947/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001483, MRE: 0.018848, MAE: 0.002623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001768, MRE: 0.015452, MAE: 0.003192 \n",
      "\n",
      "Epoch 948/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 948/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 948/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 948/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 948/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 948/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 948/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 948/1200, Iteration 8/12, Loss: 0.0049\n",
      "Epoch 948/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 948/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 948/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 948/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 948/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001347, MRE: 0.015799, MAE: 0.002563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001829, MRE: 0.015026, MAE: 0.003130 \n",
      "\n",
      "Epoch 949/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 949/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 949/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 949/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 949/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 949/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 949/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 949/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 949/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 949/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 949/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 949/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 949/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001296, MRE: 0.015819, MAE: 0.002590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001877, MRE: 0.015036, MAE: 0.003129 \n",
      "\n",
      "Epoch 950/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 950/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 950/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 950/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 950/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 950/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 950/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 950/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 950/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 950/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 950/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 950/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 950/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001268, MRE: 0.015282, MAE: 0.002530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001866, MRE: 0.015264, MAE: 0.003178 \n",
      "\n",
      "Epoch 951/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 951/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 951/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 951/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 951/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 951/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 951/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 951/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 951/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 951/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 951/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 951/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 951/1200, Iteration 13/12, Loss: 0.0046\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001317, MRE: 0.015493, MAE: 0.002557 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001877, MRE: 0.015092, MAE: 0.003127 \n",
      "\n",
      "Epoch 952/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 952/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 952/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 952/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 952/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 952/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 952/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 952/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 952/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 952/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 952/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 952/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 952/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001299, MRE: 0.015506, MAE: 0.002541 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001826, MRE: 0.015143, MAE: 0.003129 \n",
      "\n",
      "Epoch 953/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 953/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 953/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 953/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 953/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 953/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 953/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 953/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 953/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 953/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 953/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 953/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 953/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001424, MRE: 0.016057, MAE: 0.002586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001770, MRE: 0.015004, MAE: 0.003143 \n",
      "\n",
      "Epoch 954/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 954/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 954/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 954/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 954/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 954/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 954/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 954/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 954/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 954/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 954/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 954/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 954/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001411, MRE: 0.015781, MAE: 0.002564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001865, MRE: 0.015131, MAE: 0.003150 \n",
      "\n",
      "Epoch 955/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 955/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 955/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 955/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 955/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 955/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 955/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 955/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 955/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 955/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 955/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 955/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 955/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001287, MRE: 0.015332, MAE: 0.002533 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001810, MRE: 0.015446, MAE: 0.003183 \n",
      "\n",
      "Epoch 956/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 956/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 956/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 956/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 956/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 956/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 956/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 956/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 956/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 956/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 956/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 956/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 956/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001285, MRE: 0.015327, MAE: 0.002552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001783, MRE: 0.015498, MAE: 0.003201 \n",
      "\n",
      "Epoch 957/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 957/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 957/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 957/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 957/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 957/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 957/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 957/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 957/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 957/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 957/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 957/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 957/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001260, MRE: 0.015573, MAE: 0.002526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001754, MRE: 0.014959, MAE: 0.003097 \n",
      "\n",
      "Epoch 958/1200, Iteration 1/12, Loss: 0.0049\n",
      "Epoch 958/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 958/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 958/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 958/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 958/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 958/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 958/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 958/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 958/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 958/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 958/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 958/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001267, MRE: 0.018318, MAE: 0.002527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001766, MRE: 0.015219, MAE: 0.003127 \n",
      "\n",
      "Epoch 959/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 959/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 959/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 959/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 959/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 959/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 959/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 959/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 959/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 959/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 959/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 959/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 959/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001255, MRE: 0.015555, MAE: 0.002516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001796, MRE: 0.014911, MAE: 0.003092 \n",
      "\n",
      "Epoch 960/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 960/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 960/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 960/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 960/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 960/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 960/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 960/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 960/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 960/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 960/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 960/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 960/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001341, MRE: 0.015516, MAE: 0.002537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001742, MRE: 0.014897, MAE: 0.003084 \n",
      "\n",
      "Epoch 961/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 961/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 961/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 961/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 961/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 961/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 961/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 961/1200, Iteration 8/12, Loss: 0.0042\n",
      "Epoch 961/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 961/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 961/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 961/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 961/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001244, MRE: 0.015498, MAE: 0.002499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001733, MRE: 0.014913, MAE: 0.003091 \n",
      "\n",
      "Epoch 962/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 962/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 962/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 962/1200, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 962/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 962/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 962/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 962/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 962/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 962/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 962/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 962/1200, Iteration 12/12, Loss: 0.0043\n",
      "Epoch 962/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001367, MRE: 0.015304, MAE: 0.002548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001722, MRE: 0.015261, MAE: 0.003123 \n",
      "\n",
      "Epoch 963/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 963/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 963/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 963/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 963/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 963/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 963/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 963/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 963/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 963/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 963/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 963/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 963/1200, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001255, MRE: 0.015637, MAE: 0.002512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001739, MRE: 0.014909, MAE: 0.003109 \n",
      "\n",
      "Epoch 964/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 964/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 964/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 964/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 964/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 964/1200, Iteration 6/12, Loss: 0.0059\n",
      "Epoch 964/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 964/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 964/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 964/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 964/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 964/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 964/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001281, MRE: 0.015472, MAE: 0.002550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001702, MRE: 0.015346, MAE: 0.003203 \n",
      "\n",
      "Epoch 965/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 965/1200, Iteration 2/12, Loss: 0.0033\n",
      "Epoch 965/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 965/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 965/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 965/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 965/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 965/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 965/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 965/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 965/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 965/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 965/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001245, MRE: 0.015281, MAE: 0.002513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001822, MRE: 0.014954, MAE: 0.003131 \n",
      "\n",
      "Epoch 966/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 966/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 966/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 966/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 966/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 966/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 966/1200, Iteration 7/12, Loss: 0.0043\n",
      "Epoch 966/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 966/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 966/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 966/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 966/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 966/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001249, MRE: 0.015136, MAE: 0.002506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001796, MRE: 0.015147, MAE: 0.003139 \n",
      "\n",
      "Epoch 967/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 967/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 967/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 967/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 967/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 967/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 967/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 967/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 967/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 967/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 967/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 967/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 967/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001312, MRE: 0.015759, MAE: 0.002593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001714, MRE: 0.015749, MAE: 0.003247 \n",
      "\n",
      "Epoch 968/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 968/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 968/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 968/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 968/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 968/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 968/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 968/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 968/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 968/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 968/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 968/1200, Iteration 12/12, Loss: 0.0045\n",
      "Epoch 968/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001257, MRE: 0.015382, MAE: 0.002506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001801, MRE: 0.014980, MAE: 0.003116 \n",
      "\n",
      "Epoch 969/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 969/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 969/1200, Iteration 3/12, Loss: 0.0040\n",
      "Epoch 969/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 969/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 969/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 969/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 969/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 969/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 969/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 969/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 969/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 969/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001250, MRE: 0.015332, MAE: 0.002502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001781, MRE: 0.014929, MAE: 0.003114 \n",
      "\n",
      "Epoch 970/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 970/1200, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 970/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 970/1200, Iteration 4/12, Loss: 0.0033\n",
      "Epoch 970/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 970/1200, Iteration 6/12, Loss: 0.0049\n",
      "Epoch 970/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 970/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 970/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 970/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 970/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 970/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 970/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001242, MRE: 0.015308, MAE: 0.002509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001815, MRE: 0.015181, MAE: 0.003115 \n",
      "\n",
      "Epoch 971/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 971/1200, Iteration 2/12, Loss: 0.0006\n",
      "Epoch 971/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 971/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 971/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 971/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 971/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 971/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 971/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 971/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 971/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 971/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 971/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001221, MRE: 0.015243, MAE: 0.002470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001752, MRE: 0.014890, MAE: 0.003093 \n",
      "\n",
      "Epoch 972/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 972/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 972/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 972/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 972/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 972/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 972/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 972/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 972/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 972/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 972/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 972/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 972/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001250, MRE: 0.015338, MAE: 0.002522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001726, MRE: 0.015275, MAE: 0.003153 \n",
      "\n",
      "Epoch 973/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 973/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 973/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 973/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 973/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 973/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 973/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 973/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 973/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 973/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 973/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 973/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 973/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001248, MRE: 0.015453, MAE: 0.002495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001660, MRE: 0.014920, MAE: 0.003098 \n",
      "\n",
      "Epoch 974/1200, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 974/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 974/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 974/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 974/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 974/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 974/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 974/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 974/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 974/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 974/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 974/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 974/1200, Iteration 13/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001234, MRE: 0.015302, MAE: 0.002488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001702, MRE: 0.014889, MAE: 0.003087 \n",
      "\n",
      "Epoch 975/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 975/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 975/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 975/1200, Iteration 4/12, Loss: 0.0036\n",
      "Epoch 975/1200, Iteration 5/12, Loss: 0.0039\n",
      "Epoch 975/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 975/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 975/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 975/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 975/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 975/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 975/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 975/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001273, MRE: 0.015335, MAE: 0.002532 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001694, MRE: 0.015258, MAE: 0.003135 \n",
      "\n",
      "Epoch 976/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 976/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 976/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 976/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 976/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 976/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 976/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 976/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 976/1200, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 976/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 976/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 976/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 976/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001229, MRE: 0.015468, MAE: 0.002487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001768, MRE: 0.014987, MAE: 0.003090 \n",
      "\n",
      "Epoch 977/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 977/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 977/1200, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 977/1200, Iteration 4/12, Loss: 0.0042\n",
      "Epoch 977/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 977/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 977/1200, Iteration 7/12, Loss: 0.0046\n",
      "Epoch 977/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 977/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 977/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 977/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 977/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 977/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001212, MRE: 0.015191, MAE: 0.002467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001743, MRE: 0.015119, MAE: 0.003105 \n",
      "\n",
      "Epoch 978/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 978/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 978/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 978/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 978/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 978/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 978/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 978/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 978/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 978/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 978/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 978/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 978/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001288, MRE: 0.015454, MAE: 0.002543 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001925, MRE: 0.015112, MAE: 0.003152 \n",
      "\n",
      "Epoch 979/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 979/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 979/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 979/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 979/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 979/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 979/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 979/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 979/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 979/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 979/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 979/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 979/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001269, MRE: 0.015330, MAE: 0.002524 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001848, MRE: 0.015274, MAE: 0.003150 \n",
      "\n",
      "Epoch 980/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 980/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 980/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 980/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 980/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 980/1200, Iteration 6/12, Loss: 0.0040\n",
      "Epoch 980/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 980/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 980/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 980/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 980/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 980/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 980/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.001407, MRE: 0.015635, MAE: 0.002599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001695, MRE: 0.015698, MAE: 0.003178 \n",
      "\n",
      "Epoch 981/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 981/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 981/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 981/1200, Iteration 4/12, Loss: 0.0051\n",
      "Epoch 981/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 981/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 981/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 981/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 981/1200, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 981/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 981/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 981/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 981/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001207, MRE: 0.015103, MAE: 0.002471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001707, MRE: 0.014940, MAE: 0.003096 \n",
      "\n",
      "Epoch 982/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 982/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 982/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 982/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 982/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 982/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 982/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 982/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 982/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 982/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 982/1200, Iteration 11/12, Loss: 0.0047\n",
      "Epoch 982/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 982/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001234, MRE: 0.015239, MAE: 0.002507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001754, MRE: 0.015095, MAE: 0.003079 \n",
      "\n",
      "Epoch 983/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 983/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 983/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 983/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 983/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 983/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 983/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 983/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 983/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 983/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 983/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 983/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 983/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001240, MRE: 0.015372, MAE: 0.002559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001749, MRE: 0.015671, MAE: 0.003284 \n",
      "\n",
      "Epoch 984/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 984/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 984/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 984/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 984/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 984/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 984/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 984/1200, Iteration 8/12, Loss: 0.0037\n",
      "Epoch 984/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 984/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 984/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 984/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 984/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001208, MRE: 0.015096, MAE: 0.002459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001727, MRE: 0.015106, MAE: 0.003135 \n",
      "\n",
      "Epoch 985/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 985/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 985/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 985/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 985/1200, Iteration 5/12, Loss: 0.0042\n",
      "Epoch 985/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 985/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 985/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 985/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 985/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 985/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 985/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 985/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001215, MRE: 0.015358, MAE: 0.002485 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001736, MRE: 0.015271, MAE: 0.003158 \n",
      "\n",
      "Epoch 986/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 986/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 986/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 986/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 986/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 986/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 986/1200, Iteration 7/12, Loss: 0.0055\n",
      "Epoch 986/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 986/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 986/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 986/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 986/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 986/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001235, MRE: 0.015103, MAE: 0.002485 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001763, MRE: 0.015161, MAE: 0.003122 \n",
      "\n",
      "Epoch 987/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 987/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 987/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 987/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 987/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 987/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 987/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 987/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 987/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 987/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 987/1200, Iteration 11/12, Loss: 0.0055\n",
      "Epoch 987/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 987/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001222, MRE: 0.015235, MAE: 0.002484 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001812, MRE: 0.014908, MAE: 0.003126 \n",
      "\n",
      "Epoch 988/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 988/1200, Iteration 2/12, Loss: 0.0042\n",
      "Epoch 988/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 988/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 988/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 988/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 988/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 988/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 988/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 988/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 988/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 988/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 988/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001222, MRE: 0.015421, MAE: 0.002516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001793, MRE: 0.014920, MAE: 0.003106 \n",
      "\n",
      "Epoch 989/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 989/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 989/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 989/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 989/1200, Iteration 5/12, Loss: 0.0031\n",
      "Epoch 989/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 989/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 989/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 989/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 989/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 989/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 989/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 989/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001214, MRE: 0.015391, MAE: 0.002490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001656, MRE: 0.014969, MAE: 0.003091 \n",
      "\n",
      "Epoch 990/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 990/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 990/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 990/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 990/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 990/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 990/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 990/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 990/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 990/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 990/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 990/1200, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 990/1200, Iteration 13/12, Loss: 0.0036\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001226, MRE: 0.015375, MAE: 0.002491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001708, MRE: 0.015384, MAE: 0.003151 \n",
      "\n",
      "Epoch 991/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 991/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 991/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 991/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 991/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 991/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 991/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 991/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 991/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 991/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 991/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 991/1200, Iteration 12/12, Loss: 0.0006\n",
      "Epoch 991/1200, Iteration 13/12, Loss: 0.0052\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001241, MRE: 0.015377, MAE: 0.002508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001836, MRE: 0.015021, MAE: 0.003149 \n",
      "\n",
      "Epoch 992/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 992/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 992/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 992/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 992/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 992/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 992/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 992/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 992/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 992/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 992/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 992/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 992/1200, Iteration 13/12, Loss: 0.0065\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001267, MRE: 0.015430, MAE: 0.002533 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001887, MRE: 0.015078, MAE: 0.003185 \n",
      "\n",
      "Epoch 993/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 993/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 993/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 993/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 993/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 993/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 993/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 993/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 993/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 993/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 993/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 993/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 993/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001287, MRE: 0.018728, MAE: 0.002527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001776, MRE: 0.015009, MAE: 0.003115 \n",
      "\n",
      "Epoch 994/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 994/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 994/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 994/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 994/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 994/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 994/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 994/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 994/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 994/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 994/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 994/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 994/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001340, MRE: 0.015591, MAE: 0.002522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001806, MRE: 0.014955, MAE: 0.003143 \n",
      "\n",
      "Epoch 995/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 995/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 995/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 995/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 995/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 995/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 995/1200, Iteration 7/12, Loss: 0.0073\n",
      "Epoch 995/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 995/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 995/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 995/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 995/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 995/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001268, MRE: 0.015276, MAE: 0.002517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001833, MRE: 0.015062, MAE: 0.003168 \n",
      "\n",
      "Epoch 996/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 996/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 996/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 996/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 996/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 996/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 996/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 996/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 996/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 996/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 996/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 996/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 996/1200, Iteration 13/12, Loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001190, MRE: 0.015094, MAE: 0.002463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001700, MRE: 0.015024, MAE: 0.003109 \n",
      "\n",
      "Epoch 997/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 997/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 997/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 997/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 997/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 997/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 997/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 997/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 997/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 997/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 997/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 997/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 997/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001292, MRE: 0.015249, MAE: 0.002546 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001794, MRE: 0.015061, MAE: 0.003120 \n",
      "\n",
      "Epoch 998/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 998/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 998/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 998/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 998/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 998/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 998/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 998/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 998/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 998/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 998/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 998/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 998/1200, Iteration 13/12, Loss: 0.0048\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001221, MRE: 0.015174, MAE: 0.002480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001657, MRE: 0.015186, MAE: 0.003148 \n",
      "\n",
      "Epoch 999/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 999/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 999/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 999/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 999/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 999/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 999/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 999/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 999/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 999/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 999/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 999/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 999/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001217, MRE: 0.015015, MAE: 0.002475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001673, MRE: 0.014951, MAE: 0.003083 \n",
      "\n",
      "Epoch 1000/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1000/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 1000/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 1000/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1000/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 1000/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1000/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1000/1200, Iteration 8/12, Loss: 0.0046\n",
      "Epoch 1000/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1000/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 1000/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1000/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1000/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001186, MRE: 0.014957, MAE: 0.002453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001690, MRE: 0.014963, MAE: 0.003114 \n",
      "\n",
      "Epoch 1001/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1001/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1001/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1001/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 1001/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1001/1200, Iteration 6/12, Loss: 0.0044\n",
      "Epoch 1001/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1001/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1001/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1001/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 1001/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1001/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1001/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001189, MRE: 0.014814, MAE: 0.002446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001661, MRE: 0.015168, MAE: 0.003138 \n",
      "\n",
      "Epoch 1002/1200, Iteration 1/12, Loss: 0.0046\n",
      "Epoch 1002/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1002/1200, Iteration 3/12, Loss: 0.0033\n",
      "Epoch 1002/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1002/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 1002/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 1002/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1002/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1002/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1002/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1002/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1002/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 1002/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001180, MRE: 0.015238, MAE: 0.002438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001706, MRE: 0.015072, MAE: 0.003138 \n",
      "\n",
      "Epoch 1003/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 1003/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1003/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1003/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 1003/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 1003/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1003/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 1003/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1003/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1003/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 1003/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1003/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1003/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001215, MRE: 0.015183, MAE: 0.002471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001708, MRE: 0.015215, MAE: 0.003144 \n",
      "\n",
      "Epoch 1004/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1004/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1004/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1004/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1004/1200, Iteration 5/12, Loss: 0.0029\n",
      "Epoch 1004/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1004/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1004/1200, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 1004/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1004/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1004/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1004/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 1004/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001191, MRE: 0.015138, MAE: 0.002449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001653, MRE: 0.015196, MAE: 0.003140 \n",
      "\n",
      "Epoch 1005/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1005/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 1005/1200, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 1005/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1005/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1005/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1005/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1005/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1005/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1005/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1005/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1005/1200, Iteration 12/12, Loss: 0.0032\n",
      "Epoch 1005/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001171, MRE: 0.014942, MAE: 0.002427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001696, MRE: 0.014933, MAE: 0.003109 \n",
      "\n",
      "Epoch 1006/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1006/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 1006/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1006/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 1006/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1006/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1006/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1006/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1006/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1006/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 1006/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1006/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1006/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001231, MRE: 0.015289, MAE: 0.002521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001788, MRE: 0.014913, MAE: 0.003106 \n",
      "\n",
      "Epoch 1007/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1007/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1007/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 1007/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1007/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1007/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 1007/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 1007/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 1007/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1007/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 1007/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1007/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 1007/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001343, MRE: 0.015061, MAE: 0.002500 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001698, MRE: 0.015021, MAE: 0.003130 \n",
      "\n",
      "Epoch 1008/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1008/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1008/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 1008/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1008/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1008/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1008/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1008/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 1008/1200, Iteration 9/12, Loss: 0.0028\n",
      "Epoch 1008/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1008/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1008/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1008/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001295, MRE: 0.015199, MAE: 0.002501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001671, MRE: 0.014879, MAE: 0.003094 \n",
      "\n",
      "Epoch 1009/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1009/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 1009/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1009/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1009/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1009/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1009/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 1009/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1009/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1009/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1009/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 1009/1200, Iteration 12/12, Loss: 0.0040\n",
      "Epoch 1009/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001371, MRE: 0.015221, MAE: 0.002517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001699, MRE: 0.014883, MAE: 0.003091 \n",
      "\n",
      "Epoch 1010/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1010/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1010/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1010/1200, Iteration 4/12, Loss: 0.0058\n",
      "Epoch 1010/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 1010/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 1010/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1010/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 1010/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1010/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1010/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1010/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1010/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001234, MRE: 0.014918, MAE: 0.002470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001696, MRE: 0.014714, MAE: 0.003105 \n",
      "\n",
      "Epoch 1011/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1011/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 1011/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1011/1200, Iteration 4/12, Loss: 0.0038\n",
      "Epoch 1011/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1011/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 1011/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1011/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1011/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1011/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1011/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1011/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 1011/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001179, MRE: 0.014974, MAE: 0.002443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001728, MRE: 0.014885, MAE: 0.003091 \n",
      "\n",
      "Epoch 1012/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1012/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 1012/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1012/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1012/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 1012/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1012/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 1012/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1012/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1012/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1012/1200, Iteration 11/12, Loss: 0.0037\n",
      "Epoch 1012/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1012/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001177, MRE: 0.015165, MAE: 0.002450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001694, MRE: 0.014822, MAE: 0.003089 \n",
      "\n",
      "Epoch 1013/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1013/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1013/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1013/1200, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 1013/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 1013/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1013/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1013/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 1013/1200, Iteration 9/12, Loss: 0.0043\n",
      "Epoch 1013/1200, Iteration 10/12, Loss: 0.0041\n",
      "Epoch 1013/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 1013/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1013/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001211, MRE: 0.015481, MAE: 0.002490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001856, MRE: 0.014966, MAE: 0.003180 \n",
      "\n",
      "Epoch 1014/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1014/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 1014/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1014/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1014/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1014/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1014/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1014/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1014/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1014/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 1014/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 1014/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1014/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001233, MRE: 0.015228, MAE: 0.002453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001746, MRE: 0.014941, MAE: 0.003104 \n",
      "\n",
      "Epoch 1015/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1015/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1015/1200, Iteration 3/12, Loss: 0.0038\n",
      "Epoch 1015/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1015/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1015/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1015/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1015/1200, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 1015/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1015/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1015/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1015/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1015/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001215, MRE: 0.015074, MAE: 0.002449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001691, MRE: 0.014966, MAE: 0.003110 \n",
      "\n",
      "Epoch 1016/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1016/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1016/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1016/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1016/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1016/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1016/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1016/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 1016/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 1016/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1016/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1016/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1016/1200, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001273, MRE: 0.015691, MAE: 0.002553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001908, MRE: 0.015189, MAE: 0.003164 \n",
      "\n",
      "Epoch 1017/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1017/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1017/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1017/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1017/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1017/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1017/1200, Iteration 7/12, Loss: 0.0045\n",
      "Epoch 1017/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1017/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1017/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1017/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1017/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1017/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001171, MRE: 0.015257, MAE: 0.002461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001716, MRE: 0.015303, MAE: 0.003155 \n",
      "\n",
      "Epoch 1018/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1018/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1018/1200, Iteration 3/12, Loss: 0.0007\n",
      "Epoch 1018/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1018/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 1018/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1018/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1018/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 1018/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1018/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1018/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 1018/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 1018/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001162, MRE: 0.015234, MAE: 0.002429 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001658, MRE: 0.015106, MAE: 0.003122 \n",
      "\n",
      "Epoch 1019/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1019/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1019/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1019/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 1019/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1019/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1019/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1019/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1019/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1019/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1019/1200, Iteration 11/12, Loss: 0.0035\n",
      "Epoch 1019/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 1019/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001168, MRE: 0.014966, MAE: 0.002419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001684, MRE: 0.014771, MAE: 0.003068 \n",
      "\n",
      "Epoch 1020/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1020/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 1020/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 1020/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 1020/1200, Iteration 5/12, Loss: 0.0060\n",
      "Epoch 1020/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1020/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1020/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1020/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1020/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1020/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1020/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1020/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001157, MRE: 0.015203, MAE: 0.002417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001668, MRE: 0.014918, MAE: 0.003100 \n",
      "\n",
      "Epoch 1021/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1021/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1021/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1021/1200, Iteration 4/12, Loss: 0.0037\n",
      "Epoch 1021/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 1021/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1021/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1021/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1021/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1021/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1021/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1021/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1021/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001221, MRE: 0.014926, MAE: 0.002433 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001690, MRE: 0.014812, MAE: 0.003085 \n",
      "\n",
      "Epoch 1022/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1022/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1022/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1022/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1022/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1022/1200, Iteration 6/12, Loss: 0.0050\n",
      "Epoch 1022/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1022/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1022/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1022/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1022/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1022/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1022/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001164, MRE: 0.014865, MAE: 0.002432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001676, MRE: 0.014998, MAE: 0.003119 \n",
      "\n",
      "Epoch 1023/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1023/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 1023/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 1023/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1023/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1023/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 1023/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1023/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1023/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1023/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 1023/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1023/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 1023/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001169, MRE: 0.015024, MAE: 0.002438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001678, MRE: 0.014760, MAE: 0.003081 \n",
      "\n",
      "Epoch 1024/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1024/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1024/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1024/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1024/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1024/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 1024/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1024/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1024/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1024/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1024/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1024/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1024/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001177, MRE: 0.017749, MAE: 0.002466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001692, MRE: 0.015459, MAE: 0.003166 \n",
      "\n",
      "Epoch 1025/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1025/1200, Iteration 2/12, Loss: 0.0046\n",
      "Epoch 1025/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1025/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1025/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1025/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1025/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1025/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 1025/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1025/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1025/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 1025/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1025/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001163, MRE: 0.014842, MAE: 0.002428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001685, MRE: 0.015211, MAE: 0.003120 \n",
      "\n",
      "Epoch 1026/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1026/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 1026/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 1026/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1026/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 1026/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1026/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1026/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1026/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1026/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1026/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1026/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 1026/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001158, MRE: 0.015593, MAE: 0.002440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001643, MRE: 0.014865, MAE: 0.003089 \n",
      "\n",
      "Epoch 1027/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 1027/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1027/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1027/1200, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 1027/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1027/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1027/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 1027/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 1027/1200, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 1027/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1027/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1027/1200, Iteration 12/12, Loss: 0.0042\n",
      "Epoch 1027/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001188, MRE: 0.015243, MAE: 0.002454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001625, MRE: 0.015576, MAE: 0.003172 \n",
      "\n",
      "Epoch 1028/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1028/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1028/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1028/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1028/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1028/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1028/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 1028/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1028/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1028/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1028/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1028/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1028/1200, Iteration 13/12, Loss: 0.0053\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001212, MRE: 0.015172, MAE: 0.002456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001756, MRE: 0.014883, MAE: 0.003102 \n",
      "\n",
      "Epoch 1029/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1029/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1029/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1029/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1029/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1029/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 1029/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1029/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1029/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1029/1200, Iteration 10/12, Loss: 0.0048\n",
      "Epoch 1029/1200, Iteration 11/12, Loss: 0.0054\n",
      "Epoch 1029/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1029/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001137, MRE: 0.014699, MAE: 0.002399 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001682, MRE: 0.014813, MAE: 0.003075 \n",
      "\n",
      "Epoch 1030/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1030/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 1030/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 1030/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1030/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1030/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 1030/1200, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 1030/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1030/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1030/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1030/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1030/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 1030/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001145, MRE: 0.014847, MAE: 0.002413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001657, MRE: 0.014978, MAE: 0.003082 \n",
      "\n",
      "Epoch 1031/1200, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 1031/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 1031/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 1031/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1031/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1031/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1031/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1031/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1031/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1031/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1031/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1031/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1031/1200, Iteration 13/12, Loss: 0.0044\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001242, MRE: 0.015320, MAE: 0.002485 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001608, MRE: 0.015095, MAE: 0.003112 \n",
      "\n",
      "Epoch 1032/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1032/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1032/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1032/1200, Iteration 4/12, Loss: 0.0041\n",
      "Epoch 1032/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1032/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1032/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1032/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1032/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 1032/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1032/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1032/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1032/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001138, MRE: 0.015020, MAE: 0.002425 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001679, MRE: 0.014755, MAE: 0.003055 \n",
      "\n",
      "Epoch 1033/1200, Iteration 1/12, Loss: 0.0008\n",
      "Epoch 1033/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 1033/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 1033/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1033/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1033/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1033/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1033/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1033/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 1033/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 1033/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 1033/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 1033/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001146, MRE: 0.015006, MAE: 0.002420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001671, MRE: 0.014786, MAE: 0.003055 \n",
      "\n",
      "Epoch 1034/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1034/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1034/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1034/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 1034/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1034/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 1034/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1034/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1034/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 1034/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1034/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1034/1200, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 1034/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001135, MRE: 0.014788, MAE: 0.002402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001663, MRE: 0.014852, MAE: 0.003052 \n",
      "\n",
      "Epoch 1035/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1035/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 1035/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 1035/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1035/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1035/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 1035/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1035/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1035/1200, Iteration 9/12, Loss: 0.0041\n",
      "Epoch 1035/1200, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 1035/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 1035/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1035/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001142, MRE: 0.015131, MAE: 0.002415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001668, MRE: 0.014838, MAE: 0.003068 \n",
      "\n",
      "Epoch 1036/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1036/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1036/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1036/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 1036/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1036/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1036/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1036/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1036/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1036/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1036/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1036/1200, Iteration 12/12, Loss: 0.0034\n",
      "Epoch 1036/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001134, MRE: 0.014810, MAE: 0.002403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001628, MRE: 0.014825, MAE: 0.003082 \n",
      "\n",
      "Epoch 1037/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1037/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1037/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1037/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1037/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1037/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1037/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1037/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 1037/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1037/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1037/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1037/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1037/1200, Iteration 13/12, Loss: 0.0059\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001223, MRE: 0.015549, MAE: 0.002520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001871, MRE: 0.014934, MAE: 0.003114 \n",
      "\n",
      "Epoch 1038/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1038/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 1038/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1038/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 1038/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1038/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 1038/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1038/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1038/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1038/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1038/1200, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 1038/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1038/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001185, MRE: 0.014682, MAE: 0.002449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001798, MRE: 0.015181, MAE: 0.003171 \n",
      "\n",
      "Epoch 1039/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1039/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 1039/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 1039/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1039/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1039/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 1039/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1039/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1039/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1039/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1039/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1039/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1039/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001185, MRE: 0.015098, MAE: 0.002455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001734, MRE: 0.014805, MAE: 0.003096 \n",
      "\n",
      "Epoch 1040/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 1040/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 1040/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1040/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 1040/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1040/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1040/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1040/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1040/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1040/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 1040/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1040/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 1040/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001191, MRE: 0.014742, MAE: 0.002423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001720, MRE: 0.014730, MAE: 0.003106 \n",
      "\n",
      "Epoch 1041/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1041/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 1041/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1041/1200, Iteration 4/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 1041/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 1041/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1041/1200, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 1041/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 1041/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1041/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1041/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1041/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001187, MRE: 0.014832, MAE: 0.002463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001619, MRE: 0.015202, MAE: 0.003125 \n",
      "\n",
      "Epoch 1042/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1042/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 1042/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1042/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1042/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1042/1200, Iteration 6/12, Loss: 0.0064\n",
      "Epoch 1042/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1042/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1042/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1042/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1042/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 1042/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1042/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001174, MRE: 0.014680, MAE: 0.002429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001698, MRE: 0.014736, MAE: 0.003061 \n",
      "\n",
      "Epoch 1043/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1043/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1043/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1043/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1043/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1043/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1043/1200, Iteration 7/12, Loss: 0.0054\n",
      "Epoch 1043/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1043/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1043/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 1043/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1043/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1043/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001140, MRE: 0.014794, MAE: 0.002436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001697, MRE: 0.014696, MAE: 0.003085 \n",
      "\n",
      "Epoch 1044/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1044/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1044/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1044/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 1044/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1044/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 1044/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1044/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1044/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1044/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1044/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1044/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1044/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001133, MRE: 0.014431, MAE: 0.002400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001710, MRE: 0.014980, MAE: 0.003118 \n",
      "\n",
      "Epoch 1045/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1045/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1045/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 1045/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1045/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1045/1200, Iteration 6/12, Loss: 0.0033\n",
      "Epoch 1045/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1045/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1045/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 1045/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1045/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1045/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1045/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001148, MRE: 0.014711, MAE: 0.002428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001620, MRE: 0.015189, MAE: 0.003106 \n",
      "\n",
      "Epoch 1046/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1046/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1046/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1046/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 1046/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1046/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 1046/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1046/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 1046/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1046/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1046/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1046/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1046/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001181, MRE: 0.015285, MAE: 0.002475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001768, MRE: 0.014801, MAE: 0.003088 \n",
      "\n",
      "Epoch 1047/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1047/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 1047/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1047/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1047/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 1047/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1047/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1047/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 1047/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1047/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1047/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1047/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1047/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001188, MRE: 0.014610, MAE: 0.002431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001720, MRE: 0.014945, MAE: 0.003131 \n",
      "\n",
      "Epoch 1048/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1048/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1048/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1048/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1048/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1048/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1048/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 1048/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 1048/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1048/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1048/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 1048/1200, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 1048/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001167, MRE: 0.014814, MAE: 0.002451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001620, MRE: 0.015383, MAE: 0.003154 \n",
      "\n",
      "Epoch 1049/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 1049/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1049/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1049/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1049/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1049/1200, Iteration 6/12, Loss: 0.0032\n",
      "Epoch 1049/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 1049/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1049/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1049/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1049/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1049/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 1049/1200, Iteration 13/12, Loss: 0.0030\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001166, MRE: 0.014832, MAE: 0.002429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001563, MRE: 0.014935, MAE: 0.003067 \n",
      "\n",
      "Epoch 1050/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 1050/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 1050/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1050/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1050/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1050/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 1050/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1050/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1050/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 1050/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 1050/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1050/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1050/1200, Iteration 13/12, Loss: 0.0097\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001239, MRE: 0.016138, MAE: 0.002568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001857, MRE: 0.015167, MAE: 0.003149 \n",
      "\n",
      "Epoch 1051/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1051/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1051/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1051/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1051/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 1051/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1051/1200, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 1051/1200, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 1051/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1051/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1051/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1051/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1051/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001163, MRE: 0.014755, MAE: 0.002441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001644, MRE: 0.015240, MAE: 0.003155 \n",
      "\n",
      "Epoch 1052/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1052/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1052/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1052/1200, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 1052/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1052/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1052/1200, Iteration 7/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1052/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1052/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1052/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 1052/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1052/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1052/1200, Iteration 13/12, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001114, MRE: 0.014606, MAE: 0.002392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001662, MRE: 0.014850, MAE: 0.003077 \n",
      "\n",
      "Epoch 1053/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1053/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1053/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1053/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1053/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1053/1200, Iteration 6/12, Loss: 0.0043\n",
      "Epoch 1053/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1053/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1053/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1053/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1053/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 1053/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1053/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001126, MRE: 0.014759, MAE: 0.002405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001653, MRE: 0.014625, MAE: 0.003042 \n",
      "\n",
      "Epoch 1054/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1054/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1054/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1054/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1054/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 1054/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1054/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1054/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1054/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1054/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 1054/1200, Iteration 11/12, Loss: 0.0041\n",
      "Epoch 1054/1200, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 1054/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001135, MRE: 0.014571, MAE: 0.002401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001668, MRE: 0.014913, MAE: 0.003078 \n",
      "\n",
      "Epoch 1055/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1055/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1055/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1055/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1055/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1055/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 1055/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1055/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1055/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1055/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1055/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1055/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 1055/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001128, MRE: 0.014912, MAE: 0.002385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001629, MRE: 0.014767, MAE: 0.003085 \n",
      "\n",
      "Epoch 1056/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1056/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1056/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1056/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1056/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1056/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1056/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 1056/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 1056/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1056/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1056/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 1056/1200, Iteration 12/12, Loss: 0.0052\n",
      "Epoch 1056/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001114, MRE: 0.014620, MAE: 0.002391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001724, MRE: 0.014807, MAE: 0.003079 \n",
      "\n",
      "Epoch 1057/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1057/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1057/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1057/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 1057/1200, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 1057/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1057/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 1057/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 1057/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1057/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1057/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 1057/1200, Iteration 12/12, Loss: 0.0037\n",
      "Epoch 1057/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001130, MRE: 0.014398, MAE: 0.002408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001793, MRE: 0.014933, MAE: 0.003122 \n",
      "\n",
      "Epoch 1058/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1058/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1058/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 1058/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1058/1200, Iteration 5/12, Loss: 0.0030\n",
      "Epoch 1058/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 1058/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 1058/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1058/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1058/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1058/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1058/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1058/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001160, MRE: 0.014794, MAE: 0.002446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001701, MRE: 0.014796, MAE: 0.003087 \n",
      "\n",
      "Epoch 1059/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1059/1200, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 1059/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1059/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1059/1200, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 1059/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1059/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1059/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1059/1200, Iteration 9/12, Loss: 0.0046\n",
      "Epoch 1059/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1059/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1059/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1059/1200, Iteration 13/12, Loss: 0.0058\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001143, MRE: 0.014663, MAE: 0.002438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001783, MRE: 0.014821, MAE: 0.003106 \n",
      "\n",
      "Epoch 1060/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 1060/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1060/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1060/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1060/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1060/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1060/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1060/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 1060/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1060/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1060/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1060/1200, Iteration 12/12, Loss: 0.0039\n",
      "Epoch 1060/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001109, MRE: 0.014855, MAE: 0.002391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001668, MRE: 0.014863, MAE: 0.003084 \n",
      "\n",
      "Epoch 1061/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1061/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1061/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1061/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1061/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 1061/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1061/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 1061/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 1061/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 1061/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1061/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 1061/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1061/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001100, MRE: 0.014519, MAE: 0.002395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001663, MRE: 0.014988, MAE: 0.003080 \n",
      "\n",
      "Epoch 1062/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1062/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1062/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1062/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1062/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 1062/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1062/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1062/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 1062/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1062/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1062/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1062/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1062/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001118, MRE: 0.017504, MAE: 0.002408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001728, MRE: 0.015069, MAE: 0.003117 \n",
      "\n",
      "Epoch 1063/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1063/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1063/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1063/1200, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 1063/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1063/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1063/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1063/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1063/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1063/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 1063/1200, Iteration 11/12, Loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1063/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1063/1200, Iteration 13/12, Loss: 0.0038\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001166, MRE: 0.014801, MAE: 0.002419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001722, MRE: 0.014885, MAE: 0.003110 \n",
      "\n",
      "Epoch 1064/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1064/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1064/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 1064/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1064/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1064/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1064/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1064/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1064/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1064/1200, Iteration 10/12, Loss: 0.0060\n",
      "Epoch 1064/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1064/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 1064/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001120, MRE: 0.014735, MAE: 0.002426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001724, MRE: 0.014707, MAE: 0.003095 \n",
      "\n",
      "Epoch 1065/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1065/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 1065/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1065/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1065/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1065/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1065/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1065/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 1065/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 1065/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1065/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1065/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1065/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001094, MRE: 0.014424, MAE: 0.002372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001686, MRE: 0.014956, MAE: 0.003126 \n",
      "\n",
      "Epoch 1066/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1066/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1066/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1066/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1066/1200, Iteration 5/12, Loss: 0.0007\n",
      "Epoch 1066/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 1066/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1066/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1066/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 1066/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1066/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 1066/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1066/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001188, MRE: 0.015426, MAE: 0.002478 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001835, MRE: 0.014919, MAE: 0.003112 \n",
      "\n",
      "Epoch 1067/1200, Iteration 1/12, Loss: 0.0050\n",
      "Epoch 1067/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1067/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1067/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1067/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1067/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1067/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1067/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1067/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1067/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1067/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1067/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1067/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001105, MRE: 0.014606, MAE: 0.002387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001663, MRE: 0.015016, MAE: 0.003095 \n",
      "\n",
      "Epoch 1068/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1068/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1068/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 1068/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1068/1200, Iteration 5/12, Loss: 0.0035\n",
      "Epoch 1068/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1068/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 1068/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 1068/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1068/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1068/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1068/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1068/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001131, MRE: 0.014715, MAE: 0.002403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001663, MRE: 0.014876, MAE: 0.003086 \n",
      "\n",
      "Epoch 1069/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1069/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 1069/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1069/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 1069/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 1069/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 1069/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1069/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1069/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1069/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1069/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1069/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1069/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001086, MRE: 0.014495, MAE: 0.002361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001665, MRE: 0.014842, MAE: 0.003090 \n",
      "\n",
      "Epoch 1070/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1070/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1070/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1070/1200, Iteration 4/12, Loss: 0.0007\n",
      "Epoch 1070/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1070/1200, Iteration 6/12, Loss: 0.0030\n",
      "Epoch 1070/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1070/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 1070/1200, Iteration 9/12, Loss: 0.0031\n",
      "Epoch 1070/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1070/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1070/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 1070/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001213, MRE: 0.014822, MAE: 0.002420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001724, MRE: 0.014822, MAE: 0.003108 \n",
      "\n",
      "Epoch 1071/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 1071/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1071/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1071/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1071/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1071/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1071/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1071/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1071/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 1071/1200, Iteration 10/12, Loss: 0.0052\n",
      "Epoch 1071/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1071/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 1071/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001096, MRE: 0.014483, MAE: 0.002392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001716, MRE: 0.015115, MAE: 0.003133 \n",
      "\n",
      "Epoch 1072/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1072/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1072/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1072/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1072/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1072/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1072/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1072/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 1072/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 1072/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1072/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1072/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1072/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001134, MRE: 0.014810, MAE: 0.002439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001644, MRE: 0.015569, MAE: 0.003191 \n",
      "\n",
      "Epoch 1073/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1073/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 1073/1200, Iteration 3/12, Loss: 0.0035\n",
      "Epoch 1073/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1073/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1073/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 1073/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1073/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1073/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1073/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 1073/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1073/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 1073/1200, Iteration 13/12, Loss: 0.0005\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001114, MRE: 0.014819, MAE: 0.002383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001605, MRE: 0.014874, MAE: 0.003090 \n",
      "\n",
      "Epoch 1074/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1074/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 1074/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1074/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1074/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1074/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1074/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1074/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1074/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1074/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1074/1200, Iteration 11/12, Loss: 0.0050\n",
      "Epoch 1074/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 1074/1200, Iteration 13/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001123, MRE: 0.015086, MAE: 0.002464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001722, MRE: 0.014836, MAE: 0.003064 \n",
      "\n",
      "Epoch 1075/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1075/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1075/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1075/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1075/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1075/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1075/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1075/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1075/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1075/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 1075/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 1075/1200, Iteration 12/12, Loss: 0.0049\n",
      "Epoch 1075/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001116, MRE: 0.014776, MAE: 0.002419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001688, MRE: 0.014775, MAE: 0.003082 \n",
      "\n",
      "Epoch 1076/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1076/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 1076/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1076/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1076/1200, Iteration 5/12, Loss: 0.0036\n",
      "Epoch 1076/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1076/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1076/1200, Iteration 8/12, Loss: 0.0034\n",
      "Epoch 1076/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1076/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1076/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1076/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1076/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001214, MRE: 0.014598, MAE: 0.002407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001590, MRE: 0.014832, MAE: 0.003122 \n",
      "\n",
      "Epoch 1077/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1077/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 1077/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 1077/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1077/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 1077/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1077/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 1077/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1077/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1077/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1077/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1077/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 1077/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001204, MRE: 0.014450, MAE: 0.002396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001620, MRE: 0.014896, MAE: 0.003128 \n",
      "\n",
      "Epoch 1078/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1078/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1078/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 1078/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1078/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1078/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1078/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1078/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1078/1200, Iteration 9/12, Loss: 0.0040\n",
      "Epoch 1078/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 1078/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1078/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1078/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001201, MRE: 0.014505, MAE: 0.002403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001663, MRE: 0.014609, MAE: 0.003077 \n",
      "\n",
      "Epoch 1079/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1079/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 1079/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1079/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1079/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1079/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1079/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1079/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1079/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1079/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1079/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1079/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1079/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001094, MRE: 0.014338, MAE: 0.002384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001632, MRE: 0.015032, MAE: 0.003098 \n",
      "\n",
      "Epoch 1080/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 1080/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1080/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1080/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1080/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1080/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1080/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 1080/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 1080/1200, Iteration 9/12, Loss: 0.0026\n",
      "Epoch 1080/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1080/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1080/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1080/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001080, MRE: 0.014319, MAE: 0.002377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001644, MRE: 0.014739, MAE: 0.003050 \n",
      "\n",
      "Epoch 1081/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1081/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1081/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 1081/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1081/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1081/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1081/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1081/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1081/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1081/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1081/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1081/1200, Iteration 12/12, Loss: 0.0041\n",
      "Epoch 1081/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001194, MRE: 0.017327, MAE: 0.002405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001652, MRE: 0.014664, MAE: 0.003067 \n",
      "\n",
      "Epoch 1082/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1082/1200, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 1082/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1082/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 1082/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1082/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1082/1200, Iteration 7/12, Loss: 0.0047\n",
      "Epoch 1082/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1082/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1082/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1082/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1082/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1082/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001144, MRE: 0.014439, MAE: 0.002401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001623, MRE: 0.014976, MAE: 0.003093 \n",
      "\n",
      "Epoch 1083/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1083/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1083/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1083/1200, Iteration 4/12, Loss: 0.0031\n",
      "Epoch 1083/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1083/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1083/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 1083/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 1083/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1083/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1083/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1083/1200, Iteration 12/12, Loss: 0.0044\n",
      "Epoch 1083/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001076, MRE: 0.014507, MAE: 0.002355 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001601, MRE: 0.014942, MAE: 0.003062 \n",
      "\n",
      "Epoch 1084/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1084/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1084/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 1084/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1084/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1084/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1084/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1084/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1084/1200, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 1084/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1084/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1084/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1084/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001072, MRE: 0.014308, MAE: 0.002363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001611, MRE: 0.014695, MAE: 0.003052 \n",
      "\n",
      "Epoch 1085/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1085/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1085/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1085/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1085/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1085/1200, Iteration 6/12, Loss: 0.0031\n",
      "Epoch 1085/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1085/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1085/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1085/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1085/1200, Iteration 11/12, Loss: 0.0042\n",
      "Epoch 1085/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1085/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001069, MRE: 0.014281, MAE: 0.002358 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001647, MRE: 0.014988, MAE: 0.003076 \n",
      "\n",
      "Epoch 1086/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 1086/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1086/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1086/1200, Iteration 4/12, Loss: 0.0044\n",
      "Epoch 1086/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1086/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1086/1200, Iteration 7/12, Loss: 0.0036\n",
      "Epoch 1086/1200, Iteration 8/12, Loss: 0.0059\n",
      "Epoch 1086/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1086/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1086/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1086/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1086/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001072, MRE: 0.014214, MAE: 0.002353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001654, MRE: 0.014709, MAE: 0.003084 \n",
      "\n",
      "Epoch 1087/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1087/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1087/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1087/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1087/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1087/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1087/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1087/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1087/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1087/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1087/1200, Iteration 11/12, Loss: 0.0032\n",
      "Epoch 1087/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1087/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001087, MRE: 0.014340, MAE: 0.002366 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001644, MRE: 0.014918, MAE: 0.003087 \n",
      "\n",
      "Epoch 1088/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1088/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1088/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1088/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1088/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 1088/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 1088/1200, Iteration 7/12, Loss: 0.0007\n",
      "Epoch 1088/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1088/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1088/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 1088/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1088/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 1088/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001087, MRE: 0.014807, MAE: 0.002385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001651, MRE: 0.014682, MAE: 0.003040 \n",
      "\n",
      "Epoch 1089/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1089/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1089/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 1089/1200, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 1089/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1089/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1089/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1089/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1089/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1089/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1089/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1089/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 1089/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001076, MRE: 0.014545, MAE: 0.002370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001601, MRE: 0.014869, MAE: 0.003136 \n",
      "\n",
      "Epoch 1090/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1090/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 1090/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 1090/1200, Iteration 4/12, Loss: 0.0007\n",
      "Epoch 1090/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1090/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1090/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1090/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1090/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1090/1200, Iteration 10/12, Loss: 0.0028\n",
      "Epoch 1090/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1090/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1090/1200, Iteration 13/12, Loss: 0.0005\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001067, MRE: 0.014149, MAE: 0.002360 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001666, MRE: 0.014807, MAE: 0.003115 \n",
      "\n",
      "Epoch 1091/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1091/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1091/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1091/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1091/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1091/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1091/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1091/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1091/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1091/1200, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 1091/1200, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 1091/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1091/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001246, MRE: 0.014732, MAE: 0.002401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001642, MRE: 0.014627, MAE: 0.003065 \n",
      "\n",
      "Epoch 1092/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1092/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 1092/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1092/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1092/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1092/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1092/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1092/1200, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 1092/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1092/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1092/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1092/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1092/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001202, MRE: 0.014533, MAE: 0.002414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001676, MRE: 0.015119, MAE: 0.003088 \n",
      "\n",
      "Epoch 1093/1200, Iteration 1/12, Loss: 0.0030\n",
      "Epoch 1093/1200, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 1093/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1093/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1093/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1093/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1093/1200, Iteration 7/12, Loss: 0.0006\n",
      "Epoch 1093/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1093/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1093/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1093/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1093/1200, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 1093/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001066, MRE: 0.014345, MAE: 0.002355 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001612, MRE: 0.015138, MAE: 0.003087 \n",
      "\n",
      "Epoch 1094/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 1094/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1094/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1094/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1094/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1094/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 1094/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 1094/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1094/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1094/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1094/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1094/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1094/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001058, MRE: 0.014436, MAE: 0.002339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001605, MRE: 0.014764, MAE: 0.003047 \n",
      "\n",
      "Epoch 1095/1200, Iteration 1/12, Loss: 0.0034\n",
      "Epoch 1095/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1095/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 1095/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1095/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1095/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1095/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 1095/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 1095/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1095/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1095/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1095/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1095/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001053, MRE: 0.014177, MAE: 0.002316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001642, MRE: 0.014724, MAE: 0.003071 \n",
      "\n",
      "Epoch 1096/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1096/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 1096/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1096/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1096/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1096/1200, Iteration 6/12, Loss: 0.0045\n",
      "Epoch 1096/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 1096/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1096/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1096/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1096/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1096/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1096/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001068, MRE: 0.014475, MAE: 0.002353 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001639, MRE: 0.014704, MAE: 0.003059 \n",
      "\n",
      "Epoch 1097/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1097/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1097/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1097/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1097/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1097/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1097/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 1097/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1097/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1097/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1097/1200, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 1097/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1097/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001110, MRE: 0.014428, MAE: 0.002357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001594, MRE: 0.014552, MAE: 0.003037 \n",
      "\n",
      "Epoch 1098/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 1098/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1098/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1098/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1098/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1098/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1098/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1098/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 1098/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1098/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1098/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1098/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 1098/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001207, MRE: 0.014487, MAE: 0.002440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001630, MRE: 0.015049, MAE: 0.003077 \n",
      "\n",
      "Epoch 1099/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1099/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1099/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1099/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1099/1200, Iteration 5/12, Loss: 0.0008\n",
      "Epoch 1099/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1099/1200, Iteration 7/12, Loss: 0.0039\n",
      "Epoch 1099/1200, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 1099/1200, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 1099/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1099/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1099/1200, Iteration 12/12, Loss: 0.0029\n",
      "Epoch 1099/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001063, MRE: 0.014074, MAE: 0.002346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001600, MRE: 0.014782, MAE: 0.003099 \n",
      "\n",
      "Epoch 1100/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1100/1200, Iteration 2/12, Loss: 0.0039\n",
      "Epoch 1100/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1100/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1100/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1100/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1100/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1100/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1100/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1100/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 1100/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1100/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 1100/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001105, MRE: 0.014374, MAE: 0.002349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001630, MRE: 0.014515, MAE: 0.003072 \n",
      "\n",
      "Epoch 1101/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1101/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1101/1200, Iteration 3/12, Loss: 0.0049\n",
      "Epoch 1101/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1101/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1101/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1101/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 1101/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1101/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1101/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1101/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1101/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1101/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001110, MRE: 0.014161, MAE: 0.002359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001599, MRE: 0.014598, MAE: 0.003066 \n",
      "\n",
      "Epoch 1102/1200, Iteration 1/12, Loss: 0.0032\n",
      "Epoch 1102/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1102/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1102/1200, Iteration 4/12, Loss: 0.0035\n",
      "Epoch 1102/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1102/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 1102/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 1102/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1102/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1102/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 1102/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1102/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1102/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001045, MRE: 0.013971, MAE: 0.002312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001588, MRE: 0.014653, MAE: 0.003059 \n",
      "\n",
      "Epoch 1103/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1103/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 1103/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 1103/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1103/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1103/1200, Iteration 6/12, Loss: 0.0029\n",
      "Epoch 1103/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1103/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1103/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1103/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1103/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1103/1200, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 1103/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001071, MRE: 0.013989, MAE: 0.002341 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001612, MRE: 0.014620, MAE: 0.003065 \n",
      "\n",
      "Epoch 1104/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 1104/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1104/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 1104/1200, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 1104/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1104/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1104/1200, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 1104/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1104/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1104/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1104/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1104/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 1104/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001073, MRE: 0.014294, MAE: 0.002349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001589, MRE: 0.014609, MAE: 0.003052 \n",
      "\n",
      "Epoch 1105/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 1105/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1105/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1105/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1105/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1105/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1105/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 1105/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 1105/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1105/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1105/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1105/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1105/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001062, MRE: 0.014022, MAE: 0.002345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001645, MRE: 0.014829, MAE: 0.003059 \n",
      "\n",
      "Epoch 1106/1200, Iteration 1/12, Loss: 0.0045\n",
      "Epoch 1106/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 1106/1200, Iteration 3/12, Loss: 0.0028\n",
      "Epoch 1106/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1106/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1106/1200, Iteration 6/12, Loss: 0.0041\n",
      "Epoch 1106/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1106/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 1106/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1106/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 1106/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1106/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1106/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001107, MRE: 0.014144, MAE: 0.002354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001592, MRE: 0.014835, MAE: 0.003077 \n",
      "\n",
      "Epoch 1107/1200, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 1107/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1107/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1107/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1107/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1107/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1107/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1107/1200, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 1107/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1107/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1107/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1107/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 1107/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001081, MRE: 0.014578, MAE: 0.002384 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001730, MRE: 0.014677, MAE: 0.003114 \n",
      "\n",
      "Epoch 1108/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1108/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 1108/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 1108/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1108/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1108/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1108/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1108/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1108/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1108/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1108/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1108/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1108/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001170, MRE: 0.014564, MAE: 0.002404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001682, MRE: 0.014994, MAE: 0.003150 \n",
      "\n",
      "Epoch 1109/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 1109/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1109/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1109/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1109/1200, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 1109/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1109/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1109/1200, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 1109/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1109/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1109/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1109/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 1109/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001114, MRE: 0.014702, MAE: 0.002406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001747, MRE: 0.014997, MAE: 0.003104 \n",
      "\n",
      "Epoch 1110/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1110/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1110/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 1110/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1110/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1110/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1110/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1110/1200, Iteration 8/12, Loss: 0.0053\n",
      "Epoch 1110/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1110/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1110/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1110/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1110/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001046, MRE: 0.014456, MAE: 0.002333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001603, MRE: 0.014879, MAE: 0.003118 \n",
      "\n",
      "Epoch 1111/1200, Iteration 1/12, Loss: 0.0035\n",
      "Epoch 1111/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1111/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1111/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1111/1200, Iteration 5/12, Loss: 0.0037\n",
      "Epoch 1111/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1111/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1111/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1111/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1111/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1111/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1111/1200, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 1111/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001052, MRE: 0.014414, MAE: 0.002318 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001636, MRE: 0.014712, MAE: 0.003066 \n",
      "\n",
      "Epoch 1112/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1112/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 1112/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1112/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1112/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1112/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1112/1200, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 1112/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1112/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1112/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1112/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1112/1200, Iteration 12/12, Loss: 0.0047\n",
      "Epoch 1112/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001051, MRE: 0.014266, MAE: 0.002332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001615, MRE: 0.014755, MAE: 0.003062 \n",
      "\n",
      "Epoch 1113/1200, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 1113/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 1113/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1113/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1113/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1113/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1113/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1113/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1113/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1113/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1113/1200, Iteration 11/12, Loss: 0.0006\n",
      "Epoch 1113/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1113/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001040, MRE: 0.014204, MAE: 0.002327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001615, MRE: 0.014734, MAE: 0.003079 \n",
      "\n",
      "Epoch 1114/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1114/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1114/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 1114/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1114/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1114/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1114/1200, Iteration 7/12, Loss: 0.0027\n",
      "Epoch 1114/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1114/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1114/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 1114/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1114/1200, Iteration 12/12, Loss: 0.0007\n",
      "Epoch 1114/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001040, MRE: 0.013991, MAE: 0.002339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001644, MRE: 0.014532, MAE: 0.003020 \n",
      "\n",
      "Epoch 1115/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1115/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1115/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1115/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1115/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1115/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1115/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1115/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1115/1200, Iteration 9/12, Loss: 0.0030\n",
      "Epoch 1115/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1115/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1115/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1115/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001116, MRE: 0.014320, MAE: 0.002430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001767, MRE: 0.014700, MAE: 0.003078 \n",
      "\n",
      "Epoch 1116/1200, Iteration 1/12, Loss: 0.0031\n",
      "Epoch 1116/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1116/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1116/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1116/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1116/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1116/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1116/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1116/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1116/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 1116/1200, Iteration 11/12, Loss: 0.0029\n",
      "Epoch 1116/1200, Iteration 12/12, Loss: 0.0027\n",
      "Epoch 1116/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001069, MRE: 0.014181, MAE: 0.002350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001570, MRE: 0.015041, MAE: 0.003044 \n",
      "\n",
      "Epoch 1117/1200, Iteration 1/12, Loss: 0.0007\n",
      "Epoch 1117/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 1117/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1117/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1117/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 1117/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1117/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1117/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1117/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1117/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1117/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1117/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1117/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001106, MRE: 0.015771, MAE: 0.002447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001722, MRE: 0.014745, MAE: 0.003079 \n",
      "\n",
      "Epoch 1118/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1118/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1118/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1118/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1118/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1118/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1118/1200, Iteration 7/12, Loss: 0.0065\n",
      "Epoch 1118/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1118/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1118/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 1118/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1118/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1118/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001037, MRE: 0.014370, MAE: 0.002322 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001594, MRE: 0.014740, MAE: 0.003066 \n",
      "\n",
      "Epoch 1119/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1119/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1119/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1119/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 1119/1200, Iteration 5/12, Loss: 0.0027\n",
      "Epoch 1119/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1119/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1119/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 1119/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1119/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1119/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1119/1200, Iteration 12/12, Loss: 0.0035\n",
      "Epoch 1119/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001063, MRE: 0.014248, MAE: 0.002381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001670, MRE: 0.014609, MAE: 0.003021 \n",
      "\n",
      "Epoch 1120/1200, Iteration 1/12, Loss: 0.0040\n",
      "Epoch 1120/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1120/1200, Iteration 3/12, Loss: 0.0027\n",
      "Epoch 1120/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1120/1200, Iteration 5/12, Loss: 0.0033\n",
      "Epoch 1120/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1120/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1120/1200, Iteration 8/12, Loss: 0.0030\n",
      "Epoch 1120/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1120/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 1120/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1120/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1120/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001065, MRE: 0.014404, MAE: 0.002405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001698, MRE: 0.014600, MAE: 0.003039 \n",
      "\n",
      "Epoch 1121/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 1121/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1121/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1121/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1121/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1121/1200, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 1121/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 1121/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1121/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1121/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1121/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1121/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 1121/1200, Iteration 13/12, Loss: 0.0006\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001031, MRE: 0.014124, MAE: 0.002333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001616, MRE: 0.014938, MAE: 0.003102 \n",
      "\n",
      "Epoch 1122/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1122/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1122/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 1122/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1122/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1122/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1122/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1122/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1122/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1122/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1122/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1122/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1122/1200, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001070, MRE: 0.014603, MAE: 0.002385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001710, MRE: 0.014595, MAE: 0.003055 \n",
      "\n",
      "Epoch 1123/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 1123/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1123/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1123/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1123/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1123/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1123/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 1123/1200, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 1123/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1123/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1123/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1123/1200, Iteration 12/12, Loss: 0.0038\n",
      "Epoch 1123/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001067, MRE: 0.014237, MAE: 0.002332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001611, MRE: 0.014549, MAE: 0.003040 \n",
      "\n",
      "Epoch 1124/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1124/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1124/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1124/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1124/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1124/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1124/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1124/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1124/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1124/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1124/1200, Iteration 11/12, Loss: 0.0031\n",
      "Epoch 1124/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 1124/1200, Iteration 13/12, Loss: 0.0039\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001032, MRE: 0.014014, MAE: 0.002305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001558, MRE: 0.014796, MAE: 0.003042 \n",
      "\n",
      "Epoch 1125/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1125/1200, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 1125/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1125/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1125/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 1125/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1125/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1125/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 1125/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1125/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1125/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1125/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 1125/1200, Iteration 13/12, Loss: 0.0029\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001058, MRE: 0.014203, MAE: 0.002334 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001649, MRE: 0.014555, MAE: 0.003054 \n",
      "\n",
      "Epoch 1126/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1126/1200, Iteration 2/12, Loss: 0.0043\n",
      "Epoch 1126/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1126/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1126/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1126/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1126/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1126/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1126/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1126/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1126/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1126/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1126/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001040, MRE: 0.014031, MAE: 0.002336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001564, MRE: 0.014903, MAE: 0.003071 \n",
      "\n",
      "Epoch 1127/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1127/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1127/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1127/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1127/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1127/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1127/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1127/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1127/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 1127/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1127/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1127/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 1127/1200, Iteration 13/12, Loss: 0.0032\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001084, MRE: 0.014230, MAE: 0.002392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001558, MRE: 0.015076, MAE: 0.003153 \n",
      "\n",
      "Epoch 1128/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1128/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1128/1200, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 1128/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1128/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1128/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1128/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1128/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1128/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1128/1200, Iteration 10/12, Loss: 0.0032\n",
      "Epoch 1128/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1128/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1128/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001075, MRE: 0.014094, MAE: 0.002326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001556, MRE: 0.014381, MAE: 0.003013 \n",
      "\n",
      "Epoch 1129/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1129/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1129/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1129/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1129/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1129/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1129/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 1129/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1129/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1129/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 1129/1200, Iteration 11/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1129/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1129/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001023, MRE: 0.014195, MAE: 0.002333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001602, MRE: 0.014656, MAE: 0.003016 \n",
      "\n",
      "Epoch 1130/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1130/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1130/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1130/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1130/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1130/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1130/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1130/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1130/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1130/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1130/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 1130/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1130/1200, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001018, MRE: 0.014040, MAE: 0.002312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001580, MRE: 0.014762, MAE: 0.003056 \n",
      "\n",
      "Epoch 1131/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1131/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 1131/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1131/1200, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 1131/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1131/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1131/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1131/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1131/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1131/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 1131/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1131/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1131/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001123, MRE: 0.014481, MAE: 0.002391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001512, MRE: 0.015017, MAE: 0.003106 \n",
      "\n",
      "Epoch 1132/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1132/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1132/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 1132/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1132/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1132/1200, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 1132/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1132/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1132/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1132/1200, Iteration 10/12, Loss: 0.0034\n",
      "Epoch 1132/1200, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 1132/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1132/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001022, MRE: 0.014555, MAE: 0.002313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001544, MRE: 0.014349, MAE: 0.003009 \n",
      "\n",
      "Epoch 1133/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1133/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1133/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 1133/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1133/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1133/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1133/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1133/1200, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 1133/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1133/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1133/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1133/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1133/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001024, MRE: 0.016927, MAE: 0.002307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001556, MRE: 0.014337, MAE: 0.003010 \n",
      "\n",
      "Epoch 1134/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1134/1200, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 1134/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1134/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1134/1200, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 1134/1200, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 1134/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 1134/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1134/1200, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 1134/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1134/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1134/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 1134/1200, Iteration 13/12, Loss: 0.0031\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001051, MRE: 0.014407, MAE: 0.002347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001494, MRE: 0.014715, MAE: 0.003061 \n",
      "\n",
      "Epoch 1135/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1135/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1135/1200, Iteration 3/12, Loss: 0.0030\n",
      "Epoch 1135/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1135/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1135/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1135/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 1135/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1135/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1135/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1135/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1135/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1135/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001024, MRE: 0.014176, MAE: 0.002321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001521, MRE: 0.014486, MAE: 0.003027 \n",
      "\n",
      "Epoch 1136/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1136/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1136/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1136/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1136/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 1136/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1136/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1136/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1136/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1136/1200, Iteration 10/12, Loss: 0.0030\n",
      "Epoch 1136/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1136/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1136/1200, Iteration 13/12, Loss: 0.0027\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001033, MRE: 0.014117, MAE: 0.002330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001599, MRE: 0.014549, MAE: 0.003031 \n",
      "\n",
      "Epoch 1137/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1137/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 1137/1200, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 1137/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 1137/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1137/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1137/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1137/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1137/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1137/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1137/1200, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 1137/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1137/1200, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001052, MRE: 0.014594, MAE: 0.002335 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001496, MRE: 0.014675, MAE: 0.003068 \n",
      "\n",
      "Epoch 1138/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1138/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1138/1200, Iteration 3/12, Loss: 0.0007\n",
      "Epoch 1138/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1138/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1138/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1138/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1138/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 1138/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1138/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 1138/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1138/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 1138/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001035, MRE: 0.014381, MAE: 0.002350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001562, MRE: 0.014534, MAE: 0.002999 \n",
      "\n",
      "Epoch 1139/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 1139/1200, Iteration 2/12, Loss: 0.0036\n",
      "Epoch 1139/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1139/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1139/1200, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 1139/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1139/1200, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 1139/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1139/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1139/1200, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 1139/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1139/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1139/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001071, MRE: 0.014166, MAE: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001550, MRE: 0.014503, MAE: 0.003023 \n",
      "\n",
      "Epoch 1140/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1140/1200, Iteration 2/12, Loss: 0.0031\n",
      "Epoch 1140/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1140/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1140/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1140/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1140/1200, Iteration 7/12, Loss: 0.0035\n",
      "Epoch 1140/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1140/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1140/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 1140/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1140/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1140/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001016, MRE: 0.013717, MAE: 0.002310 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001609, MRE: 0.014872, MAE: 0.003104 \n",
      "\n",
      "Epoch 1141/1200, Iteration 1/12, Loss: 0.0028\n",
      "Epoch 1141/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1141/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1141/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1141/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1141/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1141/1200, Iteration 7/12, Loss: 0.0031\n",
      "Epoch 1141/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1141/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1141/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1141/1200, Iteration 11/12, Loss: 0.0043\n",
      "Epoch 1141/1200, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 1141/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001162, MRE: 0.014791, MAE: 0.002427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001650, MRE: 0.014423, MAE: 0.003040 \n",
      "\n",
      "Epoch 1142/1200, Iteration 1/12, Loss: 0.0029\n",
      "Epoch 1142/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1142/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1142/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1142/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1142/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1142/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 1142/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1142/1200, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 1142/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1142/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1142/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1142/1200, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001021, MRE: 0.014043, MAE: 0.002319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001654, MRE: 0.014560, MAE: 0.003065 \n",
      "\n",
      "Epoch 1143/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1143/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1143/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1143/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1143/1200, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 1143/1200, Iteration 6/12, Loss: 0.0028\n",
      "Epoch 1143/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1143/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 1143/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1143/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1143/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1143/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1143/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001076, MRE: 0.013954, MAE: 0.002309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001545, MRE: 0.014665, MAE: 0.003041 \n",
      "\n",
      "Epoch 1144/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1144/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1144/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1144/1200, Iteration 4/12, Loss: 0.0049\n",
      "Epoch 1144/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 1144/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1144/1200, Iteration 7/12, Loss: 0.0006\n",
      "Epoch 1144/1200, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 1144/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1144/1200, Iteration 10/12, Loss: 0.0023\n",
      "Epoch 1144/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1144/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1144/1200, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001018, MRE: 0.014174, MAE: 0.002305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001552, MRE: 0.014698, MAE: 0.003053 \n",
      "\n",
      "Epoch 1145/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1145/1200, Iteration 2/12, Loss: 0.0005\n",
      "Epoch 1145/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1145/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 1145/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1145/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1145/1200, Iteration 7/12, Loss: 0.0032\n",
      "Epoch 1145/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1145/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1145/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1145/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1145/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1145/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001019, MRE: 0.014087, MAE: 0.002307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001590, MRE: 0.014661, MAE: 0.003037 \n",
      "\n",
      "Epoch 1146/1200, Iteration 1/12, Loss: 0.0008\n",
      "Epoch 1146/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1146/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1146/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1146/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1146/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1146/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1146/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1146/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1146/1200, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 1146/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1146/1200, Iteration 12/12, Loss: 0.0033\n",
      "Epoch 1146/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001005, MRE: 0.013767, MAE: 0.002297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001557, MRE: 0.014802, MAE: 0.003050 \n",
      "\n",
      "Epoch 1147/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 1147/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1147/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1147/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1147/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1147/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1147/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1147/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1147/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1147/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1147/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1147/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1147/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001042, MRE: 0.014219, MAE: 0.002362 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001682, MRE: 0.014772, MAE: 0.003027 \n",
      "\n",
      "Epoch 1148/1200, Iteration 1/12, Loss: 0.0007\n",
      "Epoch 1148/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1148/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1148/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1148/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1148/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1148/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1148/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1148/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1148/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1148/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1148/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 1148/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001026, MRE: 0.013904, MAE: 0.002328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001621, MRE: 0.014860, MAE: 0.003057 \n",
      "\n",
      "Epoch 1149/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1149/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1149/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 1149/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1149/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1149/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1149/1200, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 1149/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1149/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1149/1200, Iteration 10/12, Loss: 0.0039\n",
      "Epoch 1149/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1149/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1149/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001063, MRE: 0.013904, MAE: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001541, MRE: 0.014536, MAE: 0.002981 \n",
      "\n",
      "Epoch 1150/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1150/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1150/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 1150/1200, Iteration 4/12, Loss: 0.0026\n",
      "Epoch 1150/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1150/1200, Iteration 6/12, Loss: 0.0025\n",
      "Epoch 1150/1200, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 1150/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 1150/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1150/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1150/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1150/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1150/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001008, MRE: 0.016314, MAE: 0.002287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001555, MRE: 0.014514, MAE: 0.002997 \n",
      "\n",
      "Epoch 1151/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1151/1200, Iteration 2/12, Loss: 0.0055\n",
      "Epoch 1151/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1151/1200, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 1151/1200, Iteration 5/12, Loss: 0.0041\n",
      "Epoch 1151/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1151/1200, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 1151/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1151/1200, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 1151/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1151/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1151/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1151/1200, Iteration 13/12, Loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001007, MRE: 0.013936, MAE: 0.002322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001539, MRE: 0.014752, MAE: 0.003067 \n",
      "\n",
      "Epoch 1152/1200, Iteration 1/12, Loss: 0.0038\n",
      "Epoch 1152/1200, Iteration 2/12, Loss: 0.0045\n",
      "Epoch 1152/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 1152/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1152/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1152/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1152/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1152/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1152/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1152/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1152/1200, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 1152/1200, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 1152/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001003, MRE: 0.013684, MAE: 0.002304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001618, MRE: 0.014613, MAE: 0.003037 \n",
      "\n",
      "Epoch 1153/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1153/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1153/1200, Iteration 3/12, Loss: 0.0025\n",
      "Epoch 1153/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1153/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1153/1200, Iteration 6/12, Loss: 0.0007\n",
      "Epoch 1153/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1153/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1153/1200, Iteration 9/12, Loss: 0.0025\n",
      "Epoch 1153/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1153/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1153/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1153/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001024, MRE: 0.016412, MAE: 0.002298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001532, MRE: 0.014605, MAE: 0.003025 \n",
      "\n",
      "Epoch 1154/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1154/1200, Iteration 2/12, Loss: 0.0025\n",
      "Epoch 1154/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 1154/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1154/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 1154/1200, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 1154/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1154/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1154/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1154/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1154/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1154/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1154/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001004, MRE: 0.013668, MAE: 0.002279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001516, MRE: 0.014499, MAE: 0.003008 \n",
      "\n",
      "Epoch 1155/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1155/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1155/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1155/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1155/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1155/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1155/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1155/1200, Iteration 8/12, Loss: 0.0035\n",
      "Epoch 1155/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1155/1200, Iteration 10/12, Loss: 0.0036\n",
      "Epoch 1155/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1155/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1155/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001013, MRE: 0.014013, MAE: 0.002305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001553, MRE: 0.014946, MAE: 0.003035 \n",
      "\n",
      "Epoch 1156/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1156/1200, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 1156/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1156/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1156/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1156/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1156/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1156/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1156/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1156/1200, Iteration 10/12, Loss: 0.0038\n",
      "Epoch 1156/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1156/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1156/1200, Iteration 13/12, Loss: 0.0033\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001001, MRE: 0.014066, MAE: 0.002302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001490, MRE: 0.014507, MAE: 0.003010 \n",
      "\n",
      "Epoch 1157/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1157/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1157/1200, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 1157/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1157/1200, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 1157/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1157/1200, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 1157/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1157/1200, Iteration 9/12, Loss: 0.0024\n",
      "Epoch 1157/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1157/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1157/1200, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 1157/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000989, MRE: 0.013881, MAE: 0.002283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001525, MRE: 0.014359, MAE: 0.002993 \n",
      "\n",
      "Epoch 1158/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1158/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1158/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1158/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 1158/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1158/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1158/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1158/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1158/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1158/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1158/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1158/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1158/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001020, MRE: 0.014237, MAE: 0.002344 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001618, MRE: 0.014388, MAE: 0.002999 \n",
      "\n",
      "Epoch 1159/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1159/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1159/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 1159/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1159/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1159/1200, Iteration 6/12, Loss: 0.0036\n",
      "Epoch 1159/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1159/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1159/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1159/1200, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 1159/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1159/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1159/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001005, MRE: 0.014637, MAE: 0.002310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001579, MRE: 0.014281, MAE: 0.003005 \n",
      "\n",
      "Epoch 1160/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1160/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1160/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1160/1200, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 1160/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1160/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1160/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1160/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1160/1200, Iteration 9/12, Loss: 0.0048\n",
      "Epoch 1160/1200, Iteration 10/12, Loss: 0.0007\n",
      "Epoch 1160/1200, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 1160/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1160/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001148, MRE: 0.013914, MAE: 0.002336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001505, MRE: 0.014521, MAE: 0.002983 \n",
      "\n",
      "Epoch 1161/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1161/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1161/1200, Iteration 3/12, Loss: 0.0006\n",
      "Epoch 1161/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1161/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1161/1200, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 1161/1200, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 1161/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1161/1200, Iteration 9/12, Loss: 0.0036\n",
      "Epoch 1161/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1161/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1161/1200, Iteration 12/12, Loss: 0.0028\n",
      "Epoch 1161/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001018, MRE: 0.014053, MAE: 0.002345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001519, MRE: 0.014866, MAE: 0.003096 \n",
      "\n",
      "Epoch 1162/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1162/1200, Iteration 2/12, Loss: 0.0029\n",
      "Epoch 1162/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1162/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1162/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 1162/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1162/1200, Iteration 7/12, Loss: 0.0028\n",
      "Epoch 1162/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1162/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1162/1200, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 1162/1200, Iteration 11/12, Loss: 0.0028\n",
      "Epoch 1162/1200, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 1162/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001049, MRE: 0.014022, MAE: 0.002301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001530, MRE: 0.014413, MAE: 0.003006 \n",
      "\n",
      "Epoch 1163/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1163/1200, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 1163/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1163/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1163/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1163/1200, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 1163/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1163/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1163/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1163/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1163/1200, Iteration 11/12, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1163/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1163/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000996, MRE: 0.013857, MAE: 0.002286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001502, MRE: 0.014491, MAE: 0.003010 \n",
      "\n",
      "Epoch 1164/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1164/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 1164/1200, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 1164/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1164/1200, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 1164/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1164/1200, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 1164/1200, Iteration 8/12, Loss: 0.0038\n",
      "Epoch 1164/1200, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 1164/1200, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 1164/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1164/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1164/1200, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001036, MRE: 0.013800, MAE: 0.002322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001618, MRE: 0.014523, MAE: 0.002997 \n",
      "\n",
      "Epoch 1165/1200, Iteration 1/12, Loss: 0.0026\n",
      "Epoch 1165/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1165/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1165/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1165/1200, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 1165/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 1165/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1165/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1165/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1165/1200, Iteration 10/12, Loss: 0.0022\n",
      "Epoch 1165/1200, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 1165/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 1165/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000992, MRE: 0.013907, MAE: 0.002298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001550, MRE: 0.014738, MAE: 0.003007 \n",
      "\n",
      "Epoch 1166/1200, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 1166/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1166/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 1166/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1166/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1166/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 1166/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1166/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1166/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1166/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1166/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1166/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 1166/1200, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000997, MRE: 0.013602, MAE: 0.002286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001544, MRE: 0.014481, MAE: 0.002980 \n",
      "\n",
      "Epoch 1167/1200, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 1167/1200, Iteration 2/12, Loss: 0.0040\n",
      "Epoch 1167/1200, Iteration 3/12, Loss: 0.0007\n",
      "Epoch 1167/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1167/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1167/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1167/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1167/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1167/1200, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 1167/1200, Iteration 10/12, Loss: 0.0024\n",
      "Epoch 1167/1200, Iteration 11/12, Loss: 0.0034\n",
      "Epoch 1167/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1167/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000984, MRE: 0.013665, MAE: 0.002277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001524, MRE: 0.014578, MAE: 0.002989 \n",
      "\n",
      "Epoch 1168/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1168/1200, Iteration 2/12, Loss: 0.0027\n",
      "Epoch 1168/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1168/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1168/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1168/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1168/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 1168/1200, Iteration 8/12, Loss: 0.0033\n",
      "Epoch 1168/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1168/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1168/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1168/1200, Iteration 12/12, Loss: 0.0007\n",
      "Epoch 1168/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001004, MRE: 0.013909, MAE: 0.002296 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001533, MRE: 0.014275, MAE: 0.002984 \n",
      "\n",
      "Epoch 1169/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1169/1200, Iteration 2/12, Loss: 0.0023\n",
      "Epoch 1169/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1169/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1169/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1169/1200, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 1169/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1169/1200, Iteration 8/12, Loss: 0.0026\n",
      "Epoch 1169/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1169/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1169/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1169/1200, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 1169/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000985, MRE: 0.013678, MAE: 0.002277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001501, MRE: 0.014651, MAE: 0.003036 \n",
      "\n",
      "Epoch 1170/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1170/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1170/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1170/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1170/1200, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 1170/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1170/1200, Iteration 7/12, Loss: 0.0033\n",
      "Epoch 1170/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1170/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1170/1200, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 1170/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1170/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1170/1200, Iteration 13/12, Loss: 0.0045\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001048, MRE: 0.014342, MAE: 0.002373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001645, MRE: 0.014486, MAE: 0.003037 \n",
      "\n",
      "Epoch 1171/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1171/1200, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 1171/1200, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 1171/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1171/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1171/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 1171/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1171/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1171/1200, Iteration 9/12, Loss: 0.0035\n",
      "Epoch 1171/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1171/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1171/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1171/1200, Iteration 13/12, Loss: 0.0028\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001053, MRE: 0.013803, MAE: 0.002301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001533, MRE: 0.014273, MAE: 0.002969 \n",
      "\n",
      "Epoch 1172/1200, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 1172/1200, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 1172/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1172/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1172/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1172/1200, Iteration 6/12, Loss: 0.0039\n",
      "Epoch 1172/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1172/1200, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 1172/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1172/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1172/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1172/1200, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 1172/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001015, MRE: 0.013866, MAE: 0.002316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001590, MRE: 0.014232, MAE: 0.002982 \n",
      "\n",
      "Epoch 1173/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1173/1200, Iteration 2/12, Loss: 0.0006\n",
      "Epoch 1173/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1173/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1173/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1173/1200, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 1173/1200, Iteration 7/12, Loss: 0.0026\n",
      "Epoch 1173/1200, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 1173/1200, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 1173/1200, Iteration 10/12, Loss: 0.0035\n",
      "Epoch 1173/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1173/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 1173/1200, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000966, MRE: 0.013508, MAE: 0.002247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001545, MRE: 0.014545, MAE: 0.003009 \n",
      "\n",
      "Epoch 1174/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1174/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1174/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1174/1200, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 1174/1200, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 1174/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1174/1200, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 1174/1200, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 1174/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1174/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1174/1200, Iteration 11/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1174/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1174/1200, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000985, MRE: 0.013625, MAE: 0.002249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001482, MRE: 0.014546, MAE: 0.002992 \n",
      "\n",
      "Epoch 1175/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1175/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1175/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 1175/1200, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 1175/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1175/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1175/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1175/1200, Iteration 8/12, Loss: 0.0025\n",
      "Epoch 1175/1200, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 1175/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1175/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1175/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1175/1200, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000967, MRE: 0.013617, MAE: 0.002264 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001541, MRE: 0.014518, MAE: 0.002974 \n",
      "\n",
      "Epoch 1176/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1176/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1176/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1176/1200, Iteration 4/12, Loss: 0.0027\n",
      "Epoch 1176/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1176/1200, Iteration 6/12, Loss: 0.0027\n",
      "Epoch 1176/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1176/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1176/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1176/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1176/1200, Iteration 11/12, Loss: 0.0023\n",
      "Epoch 1176/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1176/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000998, MRE: 0.013631, MAE: 0.002273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001492, MRE: 0.014648, MAE: 0.003011 \n",
      "\n",
      "Epoch 1177/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1177/1200, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 1177/1200, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 1177/1200, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 1177/1200, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 1177/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1177/1200, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 1177/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 1177/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1177/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1177/1200, Iteration 11/12, Loss: 0.0007\n",
      "Epoch 1177/1200, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 1177/1200, Iteration 13/12, Loss: 0.0004\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000980, MRE: 0.013736, MAE: 0.002267 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001531, MRE: 0.014588, MAE: 0.002990 \n",
      "\n",
      "Epoch 1178/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1178/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1178/1200, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 1178/1200, Iteration 4/12, Loss: 0.0034\n",
      "Epoch 1178/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1178/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1178/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1178/1200, Iteration 8/12, Loss: 0.0027\n",
      "Epoch 1178/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1178/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1178/1200, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 1178/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1178/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000987, MRE: 0.014036, MAE: 0.002281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001527, MRE: 0.014281, MAE: 0.003005 \n",
      "\n",
      "Epoch 1179/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1179/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1179/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1179/1200, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 1179/1200, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 1179/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1179/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1179/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1179/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1179/1200, Iteration 10/12, Loss: 0.0033\n",
      "Epoch 1179/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1179/1200, Iteration 12/12, Loss: 0.0056\n",
      "Epoch 1179/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001045, MRE: 0.013875, MAE: 0.002291 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001492, MRE: 0.014188, MAE: 0.002961 \n",
      "\n",
      "Epoch 1180/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1180/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 1180/1200, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 1180/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1180/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1180/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1180/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1180/1200, Iteration 8/12, Loss: 0.0032\n",
      "Epoch 1180/1200, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 1180/1200, Iteration 10/12, Loss: 0.0007\n",
      "Epoch 1180/1200, Iteration 11/12, Loss: 0.0039\n",
      "Epoch 1180/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1180/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001086, MRE: 0.014016, MAE: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001491, MRE: 0.014627, MAE: 0.003046 \n",
      "\n",
      "Epoch 1181/1200, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 1181/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1181/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1181/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1181/1200, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 1181/1200, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 1181/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1181/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1181/1200, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 1181/1200, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 1181/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1181/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1181/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000987, MRE: 0.013766, MAE: 0.002277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001477, MRE: 0.014632, MAE: 0.003028 \n",
      "\n",
      "Epoch 1182/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1182/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1182/1200, Iteration 3/12, Loss: 0.0029\n",
      "Epoch 1182/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1182/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1182/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1182/1200, Iteration 7/12, Loss: 0.0034\n",
      "Epoch 1182/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1182/1200, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 1182/1200, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 1182/1200, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 1182/1200, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 1182/1200, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001028, MRE: 0.014358, MAE: 0.002352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001652, MRE: 0.014309, MAE: 0.003021 \n",
      "\n",
      "Epoch 1183/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1183/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1183/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1183/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1183/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1183/1200, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 1183/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1183/1200, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 1183/1200, Iteration 9/12, Loss: 0.0032\n",
      "Epoch 1183/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1183/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1183/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1183/1200, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000965, MRE: 0.013750, MAE: 0.002255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001530, MRE: 0.014435, MAE: 0.003039 \n",
      "\n",
      "Epoch 1184/1200, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 1184/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1184/1200, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 1184/1200, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 1184/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1184/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1184/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1184/1200, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 1184/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1184/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1184/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1184/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1184/1200, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000991, MRE: 0.013950, MAE: 0.002308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001511, MRE: 0.014740, MAE: 0.003087 \n",
      "\n",
      "Epoch 1185/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1185/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1185/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1185/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 1185/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1185/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1185/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1185/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1185/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1185/1200, Iteration 10/12, Loss: 0.0037\n",
      "Epoch 1185/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1185/1200, Iteration 12/12, Loss: 0.0025\n",
      "Epoch 1185/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000960, MRE: 0.013770, MAE: 0.002250 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001505, MRE: 0.014322, MAE: 0.002993 \n",
      "\n",
      "Epoch 1186/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1186/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1186/1200, Iteration 3/12, Loss: 0.0032\n",
      "Epoch 1186/1200, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 1186/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1186/1200, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 1186/1200, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 1186/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1186/1200, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 1186/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1186/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1186/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1186/1200, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000965, MRE: 0.013852, MAE: 0.002256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001474, MRE: 0.014170, MAE: 0.002984 \n",
      "\n",
      "Epoch 1187/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1187/1200, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 1187/1200, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 1187/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1187/1200, Iteration 5/12, Loss: 0.0032\n",
      "Epoch 1187/1200, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 1187/1200, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 1187/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1187/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1187/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1187/1200, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 1187/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1187/1200, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.001002, MRE: 0.013837, MAE: 0.002290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001423, MRE: 0.014496, MAE: 0.002997 \n",
      "\n",
      "Epoch 1188/1200, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 1188/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1188/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1188/1200, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 1188/1200, Iteration 5/12, Loss: 0.0025\n",
      "Epoch 1188/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1188/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1188/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1188/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1188/1200, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 1188/1200, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 1188/1200, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 1188/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000977, MRE: 0.013743, MAE: 0.002278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001472, MRE: 0.014408, MAE: 0.003023 \n",
      "\n",
      "Epoch 1189/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1189/1200, Iteration 2/12, Loss: 0.0030\n",
      "Epoch 1189/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1189/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1189/1200, Iteration 5/12, Loss: 0.0008\n",
      "Epoch 1189/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1189/1200, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 1189/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1189/1200, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 1189/1200, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 1189/1200, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 1189/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1189/1200, Iteration 13/12, Loss: 0.0047\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.000994, MRE: 0.013931, MAE: 0.002294 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001615, MRE: 0.014270, MAE: 0.003008 \n",
      "\n",
      "Epoch 1190/1200, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 1190/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1190/1200, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 1190/1200, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 1190/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1190/1200, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 1190/1200, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 1190/1200, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 1190/1200, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 1190/1200, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 1190/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1190/1200, Iteration 12/12, Loss: 0.0026\n",
      "Epoch 1190/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000958, MRE: 0.013691, MAE: 0.002261 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001511, MRE: 0.014306, MAE: 0.003022 \n",
      "\n",
      "Epoch 1191/1200, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 1191/1200, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 1191/1200, Iteration 3/12, Loss: 0.0024\n",
      "Epoch 1191/1200, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 1191/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1191/1200, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 1191/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1191/1200, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 1191/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1191/1200, Iteration 10/12, Loss: 0.0040\n",
      "Epoch 1191/1200, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 1191/1200, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 1191/1200, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000976, MRE: 0.013701, MAE: 0.002256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001497, MRE: 0.014624, MAE: 0.003008 \n",
      "\n",
      "Epoch 1192/1200, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 1192/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1192/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1192/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1192/1200, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 1192/1200, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 1192/1200, Iteration 7/12, Loss: 0.0029\n",
      "Epoch 1192/1200, Iteration 8/12, Loss: 0.0028\n",
      "Epoch 1192/1200, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 1192/1200, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 1192/1200, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 1192/1200, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 1192/1200, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000968, MRE: 0.013662, MAE: 0.002278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001562, MRE: 0.014541, MAE: 0.003010 \n",
      "\n",
      "Epoch 1193/1200, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 1193/1200, Iteration 2/12, Loss: 0.0034\n",
      "Epoch 1193/1200, Iteration 3/12, Loss: 0.0031\n",
      "Epoch 1193/1200, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 1193/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1193/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1193/1200, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 1193/1200, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 1193/1200, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 1193/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1193/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1193/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1193/1200, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000955, MRE: 0.013768, MAE: 0.002249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001529, MRE: 0.014299, MAE: 0.002955 \n",
      "\n",
      "Epoch 1194/1200, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 1194/1200, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 1194/1200, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 1194/1200, Iteration 4/12, Loss: 0.0030\n",
      "Epoch 1194/1200, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 1194/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1194/1200, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 1194/1200, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 1194/1200, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 1194/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1194/1200, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 1194/1200, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 1194/1200, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000953, MRE: 0.013550, MAE: 0.002240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001497, MRE: 0.014367, MAE: 0.002980 \n",
      "\n",
      "Epoch 1195/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1195/1200, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 1195/1200, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 1195/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1195/1200, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 1195/1200, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 1195/1200, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 1195/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1195/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1195/1200, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 1195/1200, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 1195/1200, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 1195/1200, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.000973, MRE: 0.014190, MAE: 0.002314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001503, MRE: 0.014247, MAE: 0.002932 \n",
      "\n",
      "Epoch 1196/1200, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 1196/1200, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 1196/1200, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 1196/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1196/1200, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 1196/1200, Iteration 6/12, Loss: 0.0034\n",
      "Epoch 1196/1200, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 1196/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1196/1200, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 1196/1200, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 1196/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1196/1200, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 1196/1200, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000966, MRE: 0.013867, MAE: 0.002276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001497, MRE: 0.014223, MAE: 0.002994 \n",
      "\n",
      "Epoch 1197/1200, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 1197/1200, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 1197/1200, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 1197/1200, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 1197/1200, Iteration 5/12, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1197/1200, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 1197/1200, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 1197/1200, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 1197/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1197/1200, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 1197/1200, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 1197/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1197/1200, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000970, MRE: 0.016500, MAE: 0.002249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001465, MRE: 0.014296, MAE: 0.002973 \n",
      "\n",
      "Epoch 1198/1200, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 1198/1200, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 1198/1200, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 1198/1200, Iteration 4/12, Loss: 0.0029\n",
      "Epoch 1198/1200, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 1198/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1198/1200, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 1198/1200, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 1198/1200, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 1198/1200, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 1198/1200, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 1198/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1198/1200, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000971, MRE: 0.016301, MAE: 0.002285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001461, MRE: 0.014488, MAE: 0.003004 \n",
      "\n",
      "Epoch 1199/1200, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 1199/1200, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 1199/1200, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 1199/1200, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 1199/1200, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 1199/1200, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 1199/1200, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 1199/1200, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 1199/1200, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 1199/1200, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 1199/1200, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 1199/1200, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 1199/1200, Iteration 13/12, Loss: 0.0035\n",
      "Train Error: \n",
      " Accuracy: 99.25%, Avg loss: 0.001012, MRE: 0.014190, MAE: 0.002332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001622, MRE: 0.014138, MAE: 0.003010 \n",
      "\n",
      "Epoch 1200/1200, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 1200/1200, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 1200/1200, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 1200/1200, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 1200/1200, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 1200/1200, Iteration 6/12, Loss: 0.0035\n",
      "Epoch 1200/1200, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 1200/1200, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 1200/1200, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 1200/1200, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 1200/1200, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 1200/1200, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 1200/1200, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 99.12%, Avg loss: 0.000959, MRE: 0.013508, MAE: 0.002271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.001531, MRE: 0.014546, MAE: 0.003019 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1200 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "train_MAE = []\n",
    "test_MAE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn_MSE(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients  \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    #scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE, tr_MAE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    train_MAE.append(tr_MAE)\n",
    "    \n",
    "    #scheduler.step(tr_loss) # LR scheduler step für reduceonPlateau\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE, t_MAE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "    test_MAE.append(t_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = 'Loss / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f9848",
   "metadata": {},
   "source": [
    "#### Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098cfb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: R^2(H2) = 0.9990640324964386 , R^2(NH3) = 0.9976344814148526\n",
      "Test Dataset: R^2(H2) = 0.9986707974707992 , R^2(NH3) = 0.9973018431193431\n",
      "Max Error Training: |x_H2 - x_H2,pred| = 0.03316896354760307 , |x_NH3 - x_NH3,pred| = 0.03097898773042651\n",
      "Max Error Test: |x_H2 - x_H2,pred| = 0.026011980679625957 , |x_NH3 - x_NH3,pred| = 0.033002898248807866\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_H2_real_norm = []\n",
    "x_H2_pred_norm = []\n",
    "x_NH3_real_norm = []\n",
    "x_NH3_pred_norm = []\n",
    "for (X,y) in train_dataloader:\n",
    "    x_H2_real_norm = np.append(x_H2_real_norm, y[:,0].numpy())\n",
    "    x_NH3_real_norm = np.append(x_NH3_real_norm, y[:,1].numpy())\n",
    "    help_x_H2,help_x_NH3 = (net(X).detach().numpy()).T\n",
    "    x_H2_pred_norm = np.append(x_H2_pred_norm, help_x_H2)\n",
    "    x_NH3_pred_norm = np.append(x_NH3_pred_norm, help_x_NH3)\n",
    "\n",
    "x_H2_real_test_norm = []\n",
    "x_H2_pred_test_norm = []\n",
    "x_NH3_real_test_norm = []\n",
    "x_NH3_pred_test_norm = []\n",
    "for (X,y) in test_dataloader:\n",
    "    x_H2_real_test_norm = np.append(x_H2_real_test_norm, y[:,0].numpy())\n",
    "    x_NH3_real_test_norm = np.append(x_NH3_real_test_norm, y[:,1].numpy())\n",
    "    help_x_H2,help_x_NH3 = (net(X).detach().numpy()).T\n",
    "    x_H2_pred_test_norm = np.append(x_H2_pred_test_norm, help_x_H2)\n",
    "    x_NH3_pred_test_norm = np.append(x_NH3_pred_test_norm, help_x_NH3)\n",
    "\n",
    "x_H2_real = x_H2_real_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_H2_pred = x_H2_pred_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_NH3_real = x_NH3_real_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "x_NH3_pred = x_NH3_pred_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "\n",
    "x_H2_real_test = x_H2_real_test_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_H2_pred_test = x_H2_pred_test_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_NH3_real_test = x_NH3_real_test_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "x_NH3_pred_test = x_NH3_pred_test_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "\n",
    "print('Training Dataset: R^2(H2) =', r2(x_H2_real,x_H2_pred), ', R^2(NH3) =', r2(x_NH3_real,x_NH3_pred))\n",
    "print('Test Dataset: R^2(H2) =', r2(x_H2_real_test,x_H2_pred_test), ', R^2(NH3) =', r2(x_NH3_real_test,x_NH3_pred_test))\n",
    "print('Max Error Training: |x_H2 - x_H2,pred| =', max_error(x_H2_real, x_H2_pred), ', |x_NH3 - x_NH3,pred| =', max_error(x_NH3_real, x_NH3_pred))\n",
    "print('Max Error Test: |x_H2 - x_H2,pred| =', max_error(x_H2_real_test, x_H2_pred_test), ', |x_NH3 - x_NH3,pred| =', max_error(x_NH3_real_test, x_NH3_pred_test))\n",
    "\n",
    "# find the boundaries of X and Y values\n",
    "bounds = (0,1)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize =(10,10))\n",
    "\n",
    "# # Reset the limits\n",
    "# ax[0] = plt.gca()\n",
    "ax[0].set_xlim(bounds)\n",
    "ax[0].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[0].plot(x_H2_real, x_H2_pred, '.', color ='rebeccapurple', label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[0].plot(x_NH3_real, x_NH3_pred, '.', color ='cornflowerblue', label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[0].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[0].transAxes)\n",
    "ax[0].plot([bounds[0],bounds[1]], [bounds[0] * 1.1, bounds[1] * 1.1], \"k--\") # Error line\n",
    "ax[0].plot([bounds[0],bounds[1]], [bounds[0] * 0.9, bounds[1] * 0.9], \"k--\") # Error line\n",
    "ax[0].text(0.7, 0.9, '+10%')\n",
    "ax[0].text(0.8, 0.65, '-10%')\n",
    "ax[0].set(xlabel = '$x$ / 1', ylabel = '$x\\mathregular{_{pred}}$ / 1')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0].set_title('Train Data')\n",
    "ax[0].legend()\n",
    "#ax[0].legend(['$\\\\mathregular{R^2}$ = ', r2(xi_real,xi_pred)], markerscale=0)\n",
    "\n",
    "# Reset the limits\n",
    "#ax[1] = plt.gca()\n",
    "ax[1].set_xlim(bounds)\n",
    "ax[1].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[1].plot(x_H2_real_test, x_H2_pred_test, '.', color ='rebeccapurple', label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[1].plot(x_NH3_real_test, x_NH3_pred_test, '.', color ='cornflowerblue', label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[1].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[1].transAxes)\n",
    "ax[1].plot([bounds[0],bounds[1]], [bounds[0] * 1.1, bounds[1] * 1.1], \"k--\") # Error line\n",
    "ax[1].plot([bounds[0],bounds[1]], [bounds[0] * 0.9, bounds[1] * 0.9], \"k--\") # Error line\n",
    "ax[1].text(0.7, 0.9, '+10%')\n",
    "ax[1].text(0.8, 0.65, '-10%')\n",
    "ax[1].set(xlabel = '$x$ / 1', ylabel = '$x\\mathregular{_{pred}}$ / 1')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1].set_title('Test Data')\n",
    "ax[1].legend()\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#fig.suptitle(\"Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86fc9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.semilogy(x_H2_real, abs((x_H2_pred - x_H2_real) / x_H2_real), '.', label = 'MRE')\n",
    "ax.semilogy(x_H2_real, abs(x_H2_real-x_H2_pred), '.', label = 'MAE')\n",
    "ax.set(xlabel = '$x \\mathregular{_{H_2}}$ / 1', ylabel = 'Mistake')\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390bab",
   "metadata": {},
   "source": [
    "#### Plot Fehler vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428c9744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(2)\n",
    "#fig.figsize=(12, 8)\n",
    "ax[0].semilogy(train_MRE, label='train MRE')\n",
    "ax[0].semilogy(test_MRE, label='test MRE')\n",
    "ax[0].set_title(\"Mean Relative Error\")\n",
    "ax[0].set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].semilogy(train_MAE, label='train MAE')\n",
    "ax[1].semilogy(test_MAE, label='test MAE')\n",
    "ax[1].set_title(\"Mean Absolute Error\")\n",
    "ax[1].set(xlabel = '$Epochs$ / 1', ylabel = '$MAE$ / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbf7c2",
   "metadata": {},
   "source": [
    "#### Plot Loss vs Variable Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a835602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mistake_H2 = []\n",
    "# mistake_NH3 = []\n",
    "x_H2_pred_norm = []\n",
    "x_NH3_pred_norm = []\n",
    "x_H2_real_norm = []\n",
    "x_NH3_real_norm = []\n",
    "param_T_norm = []\n",
    "param_p_norm = []\n",
    "param_x_H2_0_norm = []\n",
    "param_x_N2_0_norm = []\n",
    "param_x_NH3_0_norm = []\n",
    "for X,y in train_dataloader:\n",
    "#     help_mistake_H2, help_mistake_NH3 = (abs(y - net(X).detach().numpy())).T\n",
    "#     mistake_H2 = np.append(mistake_H2, help_mistake_H2)\n",
    "#     mistake_NH3 = np.append(mistake_NH3, help_mistake_NH3\n",
    "    help_pred = net(X).detach().numpy()\n",
    "    x_H2_pred_norm = np.append(x_H2_pred_norm, help_pred[:,0])\n",
    "    x_NH3_pred_norm = np.append(x_NH3_pred_norm, help_pred[:,1])\n",
    "    help_real = y.detach().numpy()\n",
    "    x_H2_real_norm = np.append(x_H2_real_norm, help_real[:,0])\n",
    "    x_NH3_real_norm = np.append(x_NH3_real_norm, help_real[:,1])\n",
    "    param_T_norm = np.append(param_T_norm, X[:,0])\n",
    "    param_p_norm = np.append(param_p_norm, X[:,1])\n",
    "    param_x_H2_0_norm = np.append(param_x_H2_0_norm, X[:,2])\n",
    "    param_x_N2_0_norm = np.append(param_x_N2_0_norm, X[:,3])\n",
    "    param_x_NH3_0_norm = np.append(param_x_NH3_0_norm, X[:,4])\n",
    "\n",
    "# print('x_H2:', x_H2_real_norm) #, x_H2_real_norm.dtype())\n",
    "# print('x_H2_pred:', x_H2_pred_norm)\n",
    "x_H2_pred = x_H2_pred_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_H2_real = x_H2_real_norm * std_out[0].numpy() + mean_out[0].numpy()\n",
    "x_NH3_pred = x_NH3_pred_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "x_NH3_real = x_NH3_real_norm * std_out[1].numpy() + mean_out[1].numpy()\n",
    "\n",
    "mistake_H2 = abs(x_H2_real - x_H2_pred)\n",
    "mistake_NH3 = abs(x_NH3_real - x_NH3_pred)\n",
    "\n",
    "param_T = param_T_norm * std_in[0].numpy() + mean_in[0].numpy()\n",
    "param_p = param_p_norm * std_in[1].numpy() + mean_in[1].numpy()\n",
    "param_x_H2_0 = param_x_H2_0_norm * std_in[2].numpy() + mean_in[2].numpy()\n",
    "param_x_N2_0 = param_x_N2_0_norm * std_in[3].numpy() + mean_in[3].numpy()\n",
    "param_x_NH3_0 = param_x_NH3_0_norm * std_in[4].numpy() + mean_in[4].numpy()\n",
    "\n",
    "# print('T:', param_T[0])\n",
    "# print(len(param_T))\n",
    "# print(param_T[0])\n",
    "\n",
    "fig,ax = plt.subplots(2,2, figsize = (10, 7)) #gridspec_kw={'width_ratios': [1,1,1,1]})\n",
    "\n",
    "ax[0,0].semilogy(param_T, mistake_H2, '.', markersize = 2, label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[0,0].semilogy(param_T, mistake_NH3, '.', markersize = 2, label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[0,0].set(xlabel = '$T$ / K', ylabel = '|$x\\mathregular{_i} - x\\mathregular{_{i,pred}}$| / mol')\n",
    "ax[0,0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0,0].legend()\n",
    "\n",
    "ax[0,1].semilogy(param_p, mistake_H2, '.', markersize = 2, label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[0,1].semilogy(param_p, mistake_NH3, '.', markersize = 2, label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[0,1].set(xlabel = '$p$ / bar', ylabel = '|$x\\mathregular{_i} - x\\mathregular{_{i,pred}}$| / mol')\n",
    "ax[0,1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0,1].legend()\n",
    "\n",
    "ax[1,0].semilogy(param_x_H2_0, mistake_H2, '.', markersize = 2, label = '$x\\mathregular{_{H_2, 0}}$')\n",
    "ax[1,0].semilogy(param_x_N2_0, mistake_H2, '.', markersize = 2, label = '$x\\mathregular{_{N_2, 0}}$')\n",
    "ax[1,0].semilogy(param_x_NH3_0, mistake_H2, '.', markersize = 2, label = '$x\\mathregular{_{NH_3, 0}}$')\n",
    "ax[1,0].set(xlabel = '$x\\mathregular{_{i,0}}$ / 1', ylabel = '|$x\\mathregular{_{H_2}} - x\\mathregular{_{H_2,pred}}$| / mol')\n",
    "ax[1,0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1,0].set(xlim = (0,1))\n",
    "ax[1,0].legend()\n",
    "\n",
    "ax[1,1].semilogy(param_x_H2_0, mistake_NH3, '.', markersize = 2, label = '$x\\mathregular{_{H_2, 0}}$')\n",
    "ax[1,1].semilogy(param_x_N2_0, mistake_NH3, '.', markersize = 2, label = '$x\\mathregular{_{N_2, 0}}$')\n",
    "ax[1,1].semilogy(param_x_NH3_0, mistake_NH3, '.', markersize = 2, label = '$x\\mathregular{_{NH_3, 0}}$')\n",
    "ax[1,1].set(xlabel = '$x\\mathregular{_{i,0}}$ / 1', ylabel = '|$x\\mathregular{_{NH_3}} - x\\mathregular{_{NH_3,pred}}$| / mol')\n",
    "ax[1,1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1,1].set(xlim = (0,1))\n",
    "ax[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418caa55",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4926e+00, -6.4122e-01, -3.3851e-01, -1.5372e-01,  4.8932e-01],\n",
      "        [ 1.4029e+00,  1.3636e+00,  1.1425e-01, -1.0628e+00,  9.7412e-01],\n",
      "        [-1.1767e+00,  9.6198e-01,  1.4423e+00, -1.2923e+00, -9.4698e-02],\n",
      "        [-1.3352e-01,  9.9868e-01, -1.2047e+00,  2.2949e+00, -1.1633e+00],\n",
      "        [-8.6655e-01,  6.9624e-01, -3.9661e-01,  2.9290e-02,  3.5929e-01],\n",
      "        [-1.4867e+00, -1.1825e-01,  8.6734e-01,  1.8646e-01, -1.0418e+00],\n",
      "        [-1.0993e+00, -1.2398e+00, -1.1145e-01,  3.1370e-01, -2.1125e-01],\n",
      "        [-1.8091e-01, -1.4866e+00, -6.5910e-01,  1.1967e+00, -5.7630e-01],\n",
      "        [-5.1265e-01,  9.0194e-01,  1.2347e-01, -1.4353e-01,  2.5528e-02],\n",
      "        [-1.0719e+00,  1.2129e+00,  6.9923e-01, -4.7566e-01, -2.0005e-01],\n",
      "        [-9.0842e-01, -1.2030e+00,  1.6249e+00, -5.6415e-01, -1.0180e+00],\n",
      "        [-1.3018e+00,  7.0996e-01, -1.1304e+00,  1.7055e+00, -6.3378e-01],\n",
      "        [ 1.5639e-01,  4.6021e-03, -5.6245e-01, -1.2557e+00,  1.8354e+00],\n",
      "        [ 1.0665e+00,  1.3337e+00, -1.3049e+00, -1.0487e+00,  2.3525e+00],\n",
      "        [-1.6864e+00, -1.0646e+00,  1.2640e-01, -6.0899e-01,  4.9839e-01],\n",
      "        [ 2.2979e-01,  1.0088e+00,  2.0413e+00, -6.2863e-01, -1.3608e+00],\n",
      "        [ 7.1847e-01,  6.7268e-01,  4.2490e-02, -1.2499e+00,  1.2358e+00],\n",
      "        [-1.0305e+00, -1.4174e+00,  4.7175e-01,  1.7148e-03, -4.6472e-01],\n",
      "        [ 8.8061e-01,  2.2426e-01,  5.6420e-01,  8.1545e-02, -6.3704e-01],\n",
      "        [-1.7403e+00, -2.0467e-01, -7.5283e-01, -5.4417e-01,  1.2950e+00],\n",
      "        [-1.5794e+00, -1.6658e+00, -3.3551e-01,  1.6491e+00, -1.3562e+00],\n",
      "        [-1.6445e+00,  1.6613e+00, -1.3740e+00,  8.7880e-01,  4.5018e-01],\n",
      "        [-1.1053e+00, -1.5090e+00, -1.0574e+00, -1.3562e+00,  2.4239e+00],\n",
      "        [-1.0849e+00, -1.4037e+00,  2.2055e-01,  4.6251e-02, -2.6372e-01],\n",
      "        [ 1.1035e+00,  3.8386e-01,  2.5076e-01, -1.2986e+00,  1.0812e+00],\n",
      "        [ 6.4162e-01,  9.0515e-02, -4.1377e-01,  2.1817e-01,  1.8308e-01],\n",
      "        [-1.1546e+00, -1.0749e+00,  1.0006e+00,  2.3159e-01, -1.2187e+00],\n",
      "        [ 1.8107e-01,  6.4807e-01, -3.6535e-01,  4.7480e-01, -1.2673e-01],\n",
      "        [-1.4725e-01,  3.5406e-03,  7.8259e-01,  4.9823e-01, -1.2772e+00],\n",
      "        [ 1.1426e+00, -1.6349e+00, -6.0805e-01,  8.7061e-01, -2.9310e-01],\n",
      "        [-1.1637e+00, -9.0495e-01,  6.9587e-01, -1.3622e+00,  7.0937e-01],\n",
      "        [ 1.4755e+00, -1.5753e+00,  2.4516e+00, -1.0261e+00, -1.3571e+00],\n",
      "        [ 9.9968e-01, -5.1435e-01, -5.6521e-01, -1.0836e-01,  6.6544e-01],\n",
      "        [ 9.9438e-01,  1.4025e+00,  1.3257e+00, -7.6355e-01, -5.2059e-01],\n",
      "        [-3.1635e-01,  1.6484e+00, -1.2782e+00,  1.1253e+00,  1.0428e-01],\n",
      "        [ 1.0531e+00, -6.7937e-01,  7.9734e-02, -3.3668e-01,  2.6586e-01],\n",
      "        [-4.2732e-01, -8.7746e-01,  7.8443e-01, -2.2229e-01, -5.4263e-01],\n",
      "        [ 7.8205e-01, -9.3866e-01, -3.6143e-01, -2.1919e-03,  3.5694e-01],\n",
      "        [ 2.1080e-02,  1.6799e+00, -1.4390e+00,  7.1952e-01,  6.7682e-01],\n",
      "        [ 1.2845e+00, -1.6850e+00,  7.3213e-01, -1.1466e+00,  4.5340e-01],\n",
      "        [-3.0125e-01, -1.6028e+00, -5.5705e-01,  1.3713e+00, -8.5485e-01],\n",
      "        [ 1.1556e+00, -8.4904e-01, -2.9665e-01,  8.4680e-01, -5.7436e-01],\n",
      "        [ 5.2479e-01,  1.6455e+00,  2.4220e+00, -1.3302e+00, -1.0174e+00],\n",
      "        [-8.3779e-01, -1.4711e+00, -1.1141e+00, -9.8002e-01,  2.0950e+00],\n",
      "        [-9.1077e-01,  1.2135e+00, -1.2131e-01,  7.4738e-01, -6.4483e-01],\n",
      "        [-1.7006e+00,  5.7091e-01, -9.8697e-01,  1.1048e+00, -1.6058e-01],\n",
      "        [ 2.3369e-01,  5.3065e-01, -5.6861e-01,  1.6161e+00, -1.0938e+00],\n",
      "        [-1.1193e+00, -8.0417e-01, -7.0598e-01,  1.2467e+00, -5.8139e-01],\n",
      "        [-1.6716e+00,  3.0497e-01,  2.2128e+00, -1.0556e+00, -1.0926e+00],\n",
      "        [-9.5278e-01, -1.3571e+00, -2.6010e-01, -7.5914e-01,  1.0312e+00],\n",
      "        [ 1.2629e+00, -1.3835e+00, -4.1635e-01, -9.2139e-02,  5.0278e-01],\n",
      "        [ 3.9789e-01,  2.0244e-01,  2.0372e+00, -1.2713e+00, -6.9996e-01],\n",
      "        [-1.7468e+00, -1.6659e+00,  1.1990e-01,  7.4597e-01, -8.8010e-01],\n",
      "        [-1.3139e+00, -1.1382e+00,  8.9288e-02, -6.8692e-01,  6.1445e-01],\n",
      "        [-1.4236e+00, -5.0433e-01, -3.5978e-01,  8.0920e-01, -4.7398e-01],\n",
      "        [ 1.4913e+00,  1.4584e+00, -1.1342e+00,  1.6930e+00, -6.1719e-01],\n",
      "        [ 1.3861e+00,  1.1673e+00, -1.3147e+00,  3.0636e-01,  9.7715e-01],\n",
      "        [-4.2120e-01,  1.5532e-01, -1.1526e+00, -1.1303e+00,  2.2864e+00],\n",
      "        [ 9.8009e-01,  6.0436e-01, -8.8164e-01,  1.5503e+00, -7.1933e-01],\n",
      "        [-6.3324e-01,  3.4146e-01, -5.1085e-01,  6.8952e-01, -2.0341e-01],\n",
      "        [ 2.2628e-01,  1.6550e-01,  6.7760e-01,  7.0050e-02, -7.3658e-01],\n",
      "        [-1.7799e-01, -1.2922e+00, -9.2278e-01, -1.6513e-01,  1.0744e+00],\n",
      "        [ 1.5115e+00, -6.7851e-01, -6.9327e-01, -1.1582e+00,  1.8642e+00],\n",
      "        [-9.2755e-01,  4.7059e-01, -9.4356e-01,  9.3635e-02,  8.3029e-01]])\n",
      "tensor([[ 0.5064, -0.9387],\n",
      "        [ 1.0683, -0.3978],\n",
      "        [ 1.1273,  1.3280],\n",
      "        [-2.0590, -1.4615],\n",
      "        [-0.5173,  1.1835],\n",
      "        [-0.7111,  1.6454],\n",
      "        [-0.4987,  0.4849],\n",
      "        [-0.9093, -0.8805],\n",
      "        [-0.1952,  1.0037],\n",
      "        [-0.1218,  2.0613],\n",
      "        [ 0.7295,  0.7346],\n",
      "        [-1.7759, -0.4017],\n",
      "        [ 0.8517,  0.1621],\n",
      "        [ 0.7065, -0.1906],\n",
      "        [-0.0883,  1.9165],\n",
      "        [ 1.0968,  0.3378],\n",
      "        [ 1.0798, -0.1132],\n",
      "        [-0.1155,  0.5609],\n",
      "        [ 0.2183, -0.4562],\n",
      "        [-0.4959,  2.3623],\n",
      "        [-1.6935, -0.7763],\n",
      "        [-1.5026,  1.2314],\n",
      "        [ 0.5917,  0.8069],\n",
      "        [-0.2115,  0.5850],\n",
      "        [ 1.2763, -0.4608],\n",
      "        [-0.0395, -0.4256],\n",
      "        [-0.3951,  0.7739],\n",
      "        [-0.4369, -0.1024],\n",
      "        [-0.4478, -0.0102],\n",
      "        [-0.3475, -1.2464],\n",
      "        [ 0.9831,  1.0321],\n",
      "        [ 2.1252, -1.2627],\n",
      "        [ 0.3464, -0.6987],\n",
      "        [ 1.0965, -0.1353],\n",
      "        [-1.1669, -0.0698],\n",
      "        [ 0.6335, -0.7166],\n",
      "        [ 0.2794,  0.3078],\n",
      "        [ 0.2871, -0.7170],\n",
      "        [-0.7820,  0.0579],\n",
      "        [ 1.5072, -1.0845],\n",
      "        [-1.1029, -0.9839],\n",
      "        [-0.4033, -1.0947],\n",
      "        [ 2.2095, -0.7807],\n",
      "        [ 0.4529,  0.4908],\n",
      "        [-1.1036,  0.6570],\n",
      "        [-1.5507,  0.7083],\n",
      "        [-1.4327, -1.0319],\n",
      "        [-1.2984, -0.2318],\n",
      "        [ 1.3993,  0.9993],\n",
      "        [ 0.3872,  0.6972],\n",
      "        [ 0.4847, -1.0352],\n",
      "        [ 1.8890, -0.4694],\n",
      "        [-1.0385,  0.5123],\n",
      "        [ 0.1862,  1.3163],\n",
      "        [-1.1474,  0.5883],\n",
      "        [-1.2786, -1.2683],\n",
      "        [-0.0786, -0.6583],\n",
      "        [ 0.4297,  0.8119],\n",
      "        [-1.1985, -1.1559],\n",
      "        [-0.8556,  0.2827],\n",
      "        [ 0.0679, -0.0068],\n",
      "        [ 0.1534, -0.2027],\n",
      "        [ 1.1268, -0.8985],\n",
      "        [-0.5992,  1.0866]])\n",
      "tensor([[ 0.5097, -0.9652],\n",
      "        [ 1.0554, -0.4017],\n",
      "        [ 1.1807,  1.3003],\n",
      "        [-2.0083, -1.3573],\n",
      "        [-0.5516,  1.2423],\n",
      "        [-0.6532,  1.6526],\n",
      "        [-0.5198,  0.4991],\n",
      "        [-0.9020, -0.8609],\n",
      "        [-0.2175,  1.0340],\n",
      "        [-0.1363,  2.1183],\n",
      "        [ 0.7628,  0.7382],\n",
      "        [-1.7883, -0.3964],\n",
      "        [ 0.8566,  0.1748],\n",
      "        [ 0.7094, -0.1925],\n",
      "        [-0.1154,  1.9108],\n",
      "        [ 1.1005,  0.3090],\n",
      "        [ 1.0549, -0.1187],\n",
      "        [-0.1141,  0.5605],\n",
      "        [ 0.2250, -0.3984],\n",
      "        [-0.4706,  2.2685],\n",
      "        [-1.6624, -0.7552],\n",
      "        [-1.4507,  1.2012],\n",
      "        [ 0.6048,  0.7935],\n",
      "        [-0.2096,  0.5509],\n",
      "        [ 1.2200, -0.3936],\n",
      "        [-0.0326, -0.4488],\n",
      "        [-0.4146,  0.7649],\n",
      "        [-0.4335, -0.0926],\n",
      "        [-0.4401,  0.0332],\n",
      "        [-0.3218, -1.1727],\n",
      "        [ 0.9741,  1.0378],\n",
      "        [ 2.1459, -1.3183],\n",
      "        [ 0.3422, -0.7117],\n",
      "        [ 1.1308, -0.1579],\n",
      "        [-1.1631, -0.1328],\n",
      "        [ 0.6300, -0.7192],\n",
      "        [ 0.3096,  0.3337],\n",
      "        [ 0.2947, -0.7451],\n",
      "        [-0.8126,  0.0404],\n",
      "        [ 1.5143, -1.0803],\n",
      "        [-1.1386, -0.9393],\n",
      "        [-0.4384, -1.0336],\n",
      "        [ 2.1784, -0.6487],\n",
      "        [ 0.4162,  0.5227],\n",
      "        [-1.0970,  0.6019],\n",
      "        [-1.5728,  0.7170],\n",
      "        [-1.4632, -1.0440],\n",
      "        [-1.2983, -0.2428],\n",
      "        [ 1.3270,  1.1667],\n",
      "        [ 0.4000,  0.6990],\n",
      "        [ 0.4820, -1.0559],\n",
      "        [ 1.9174, -0.4968],\n",
      "        [-1.0475,  0.5666],\n",
      "        [ 0.1871,  1.3397],\n",
      "        [-1.1423,  0.5384],\n",
      "        [-1.2448, -1.1825],\n",
      "        [-0.0978, -0.6707],\n",
      "        [ 0.4178,  0.8474],\n",
      "        [-1.2391, -1.1512],\n",
      "        [-0.8270,  0.2321],\n",
      "        [ 0.0692,  0.0201],\n",
      "        [ 0.1669, -0.2150],\n",
      "        [ 1.1543, -0.9161],\n",
      "        [-0.6099,  1.1248]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241eab8",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 8.0333e-02, -1.6383e-01, -2.3139e-01, -2.1148e-01,  5.8986e-02],\n",
       "         [ 3.9455e-01,  4.3300e-01, -7.3945e-03,  4.2235e-01,  2.2645e-02],\n",
       "         [-4.2834e-01,  6.9931e-02, -8.1977e-03, -2.5549e-01, -2.6191e-01],\n",
       "         [-2.7258e-01,  6.3698e-02,  5.4578e-02,  8.5723e-02, -3.5292e-01],\n",
       "         [ 1.5673e-01, -2.3347e-01,  2.1897e-01, -2.8647e-01,  2.5850e-01],\n",
       "         [ 4.0717e-01,  3.7057e-01,  1.5369e-01,  8.6827e-02, -1.2993e-01],\n",
       "         [ 1.1326e-01, -3.9833e-01, -1.9031e-01,  4.0127e-01,  3.9132e-01],\n",
       "         [-2.2104e-01,  2.2923e-01,  5.9663e-02,  3.1093e-01,  7.4933e-02],\n",
       "         [ 1.9572e-01, -1.3785e-01, -1.0397e-01, -1.6973e-01,  1.5169e-01],\n",
       "         [ 1.7382e-01, -2.8682e-01,  3.7889e-01,  2.8800e-01, -4.3283e-01],\n",
       "         [ 5.8503e-02,  3.1362e-01,  2.4849e-01, -3.8413e-02, -8.1772e-02],\n",
       "         [ 2.0108e-02, -2.9855e-01, -3.6623e-01, -3.9773e-01, -3.6204e-01],\n",
       "         [ 1.3500e-01,  2.1200e-01,  3.4701e-01, -1.2217e-01, -3.2905e-01],\n",
       "         [-1.2564e-01, -4.1835e-01, -3.5618e-01, -1.7275e-01, -4.6960e-01],\n",
       "         [ 3.9096e-01, -2.4069e-01,  2.5167e-01, -4.4453e-01,  3.7974e-01],\n",
       "         [ 1.2104e-01, -1.6794e-02, -3.9580e-01,  2.4108e-01, -3.7253e-01],\n",
       "         [ 2.7009e-01, -1.5829e-01,  3.8445e-01,  2.4117e-01,  1.1228e-02],\n",
       "         [-1.0373e-01,  2.2508e-01,  1.6399e-01, -9.4415e-02,  6.3012e-03],\n",
       "         [ 1.2501e-01,  1.8123e-01,  1.0413e-01,  3.7100e-01,  3.8983e-01],\n",
       "         [-1.9468e-01, -1.8573e-01, -1.0363e-01, -2.9829e-01,  2.6970e-01],\n",
       "         [-4.7007e-02,  1.4863e-01, -1.6653e-01, -2.4728e-01,  2.7109e-01],\n",
       "         [-3.2503e-01, -3.2420e-01, -3.6623e-01, -1.8493e-01,  6.2559e-02],\n",
       "         [-2.4944e-01,  1.5158e-01,  8.9187e-02,  3.9873e-03,  4.6636e-02],\n",
       "         [-1.3434e-01,  7.9656e-02, -2.0484e-01, -4.1612e-01, -2.2882e-01],\n",
       "         [-2.7529e-02, -1.4212e-01,  2.2252e-03, -3.2463e-01,  3.1123e-01],\n",
       "         [ 4.8311e-03,  8.7292e-04, -2.8989e-01, -3.7507e-01,  3.3389e-01],\n",
       "         [ 4.4426e-01, -1.2704e-01, -4.1602e-01,  1.1606e-01,  1.8969e-01],\n",
       "         [-9.9248e-03,  4.4293e-01, -2.0379e-01,  3.8960e-01, -2.4931e-01],\n",
       "         [-4.1944e-01, -4.2775e-01,  5.9747e-02,  3.6240e-01,  4.3934e-01],\n",
       "         [-3.9549e-01, -3.3118e-01, -9.1940e-02,  2.2695e-01,  8.6135e-02],\n",
       "         [ 8.4588e-02,  2.0507e-01, -3.4576e-01, -1.7760e-01,  3.0180e-03],\n",
       "         [-1.4121e-01, -4.4488e-01,  3.1284e-01,  1.9392e-02,  1.0829e-01],\n",
       "         [-1.2990e-01, -1.0868e-01, -4.2771e-01, -4.0238e-01,  2.4469e-01],\n",
       "         [ 1.8664e-01,  2.8356e-01, -4.1408e-01, -3.7937e-02, -1.8014e-01],\n",
       "         [ 3.5846e-01, -1.3437e-01,  1.3201e-01, -4.0120e-01,  9.0196e-02],\n",
       "         [ 7.9178e-02, -9.3685e-03,  3.3976e-01,  4.5244e-01, -2.1591e-01],\n",
       "         [ 2.9591e-01,  4.4329e-01,  2.2075e-01, -3.3593e-01,  1.5493e-01],\n",
       "         [ 3.1184e-01,  9.4203e-02, -3.3137e-01,  2.6329e-01, -1.5323e-01],\n",
       "         [-2.4942e-01,  4.4065e-01, -1.6514e-02, -3.3432e-01,  2.9958e-02],\n",
       "         [-3.5145e-01, -2.0525e-01,  1.3545e-01, -3.4534e-01, -7.9170e-02],\n",
       "         [-1.7381e-01,  1.2148e-01,  3.7489e-01, -3.8676e-01, -2.3951e-02],\n",
       "         [ 3.3989e-01,  2.4699e-01,  3.0023e-01, -2.6217e-01, -1.1885e-01],\n",
       "         [ 1.2773e-01, -1.2611e-01, -2.4483e-01, -1.8198e-02, -8.8589e-03],\n",
       "         [ 3.7872e-01,  3.2078e-01, -2.0256e-01, -1.6015e-01, -5.9246e-02],\n",
       "         [ 2.1568e-01, -3.2024e-01,  2.5071e-01,  4.3776e-02,  3.1524e-01],\n",
       "         [ 1.8330e-01, -8.8677e-02, -7.7534e-02, -3.5459e-01, -3.7522e-01],\n",
       "         [ 3.7046e-01, -3.1948e-01, -3.7997e-01, -2.2831e-01, -4.2745e-01],\n",
       "         [ 2.6258e-01,  7.7161e-02,  1.5333e-02,  3.7452e-01, -4.5778e-01],\n",
       "         [ 4.2020e-01, -2.7031e-01, -2.9073e-01,  1.7935e-01, -2.7136e-01],\n",
       "         [-1.6430e-01,  3.4767e-01,  4.4749e-01,  8.6461e-02, -2.9768e-01],\n",
       "         [-4.6242e-01, -4.0861e-01, -1.5979e-01,  4.0198e-01,  1.7139e-01],\n",
       "         [-3.7590e-01, -2.2277e-01, -4.2057e-01, -3.4298e-01, -2.6066e-01],\n",
       "         [ 3.7725e-01, -8.5769e-02,  1.5042e-01,  1.2105e-01,  1.1455e-01],\n",
       "         [-3.8276e-01, -3.1370e-01, -1.5210e-01,  4.3802e-01, -2.8685e-02],\n",
       "         [ 2.3321e-01, -3.4625e-01,  4.5614e-01, -3.8962e-01,  3.1949e-01],\n",
       "         [-8.6127e-02, -1.9375e-01,  3.6651e-01,  7.4553e-02,  3.9934e-01],\n",
       "         [ 2.9476e-01,  7.8146e-02,  2.7089e-01, -3.9207e-01,  2.6605e-03],\n",
       "         [-4.4592e-01,  2.5260e-01,  4.4116e-01, -3.8942e-01,  3.8295e-01],\n",
       "         [-1.0263e-01, -3.7222e-02, -7.0939e-02,  1.7182e-01, -1.1355e-01],\n",
       "         [-9.2108e-02, -7.3464e-02, -3.3459e-01, -4.2113e-01, -2.5112e-01],\n",
       "         [-1.6269e-01,  3.4823e-01,  4.3183e-01,  5.3465e-02, -8.3621e-02],\n",
       "         [ 5.1550e-03, -4.1236e-01, -1.1002e-02,  2.8992e-01,  8.4992e-02],\n",
       "         [-1.5835e-01,  3.3811e-01,  1.8444e-01,  1.8380e-02, -2.7382e-01],\n",
       "         [-1.2908e-01,  3.4562e-02, -9.1839e-02,  3.5750e-02, -2.5322e-02],\n",
       "         [ 3.1688e-01,  1.0824e-01,  2.9879e-01, -3.6079e-01,  1.5202e-01],\n",
       "         [-1.2793e-01,  3.6706e-01,  3.0098e-01,  4.0490e-01, -1.5714e-02],\n",
       "         [-7.9578e-02,  1.3804e-01, -3.3423e-01,  1.5697e-01,  3.3628e-01],\n",
       "         [-1.1955e-01,  2.8952e-02,  4.5172e-01,  1.5057e-01, -2.1160e-01],\n",
       "         [ 2.8586e-01, -1.8453e-01,  3.6706e-01, -3.4463e-01,  2.9132e-01],\n",
       "         [-1.4264e-02,  2.3824e-01, -1.2454e-01,  3.7024e-01,  3.5379e-01],\n",
       "         [-2.8696e-01,  4.2314e-01,  2.1293e-01, -2.6345e-01,  4.0514e-01],\n",
       "         [-4.3405e-01,  1.0441e-01, -2.9030e-01,  5.9681e-02,  7.3204e-02],\n",
       "         [-4.1816e-02, -3.0808e-01, -1.0664e-01, -4.4582e-02, -1.2446e-01],\n",
       "         [ 3.4072e-02,  2.6383e-03,  3.1713e-01, -2.3315e-01,  4.0952e-01],\n",
       "         [-3.0792e-01, -8.8122e-02, -2.5669e-01, -4.0127e-01,  2.6690e-01],\n",
       "         [-2.0908e-01, -3.3108e-01, -1.4811e-01, -3.0127e-01,  1.3036e-01],\n",
       "         [ 7.1286e-02,  1.2380e-03, -2.7234e-01, -9.7232e-02, -1.3134e-01],\n",
       "         [ 1.3349e-01, -2.2068e-01, -3.3669e-02, -3.5357e-01,  2.1886e-01],\n",
       "         [-5.5080e-03,  3.6488e-01, -1.7144e-01,  4.9002e-02,  1.7295e-01],\n",
       "         [-2.0944e-01,  3.5306e-01, -2.2120e-01, -3.4650e-01, -3.7627e-01],\n",
       "         [-1.4893e-01,  3.2772e-01, -3.4230e-01,  1.0548e-01,  1.1733e-01],\n",
       "         [ 4.0574e-01,  2.8385e-01, -4.0305e-01, -2.1674e-01, -1.6148e-01],\n",
       "         [-4.2985e-02,  2.0577e-01, -4.4426e-01, -1.7324e-01,  7.4252e-02],\n",
       "         [ 3.9589e-01, -3.6240e-01,  2.7929e-01,  1.4297e-01,  4.2484e-01],\n",
       "         [ 1.5203e-01,  5.2511e-02,  3.7182e-02,  1.0462e-01,  1.0209e-01],\n",
       "         [-1.1711e-01,  2.5944e-01, -3.9829e-01, -2.0750e-02, -1.7219e-01],\n",
       "         [-4.4499e-01, -6.3671e-02,  2.9025e-01,  3.5399e-02,  5.7065e-02],\n",
       "         [-2.0610e-02,  5.0647e-02,  2.1720e-01, -4.1758e-01, -1.4120e-01],\n",
       "         [-8.0249e-02, -1.5753e-01, -3.2350e-01, -2.3898e-01, -8.2320e-02],\n",
       "         [-1.4677e-01,  2.3873e-01, -6.7278e-02, -2.9138e-01,  1.3275e-01],\n",
       "         [ 1.9789e-01,  3.3724e-02,  4.1793e-02,  9.9720e-02,  3.6242e-01],\n",
       "         [ 2.9904e-01, -1.9126e-01, -1.8775e-01,  1.1490e-02, -2.1341e-01],\n",
       "         [ 2.4638e-01, -2.6607e-01,  4.1128e-01, -1.5256e-01, -6.6309e-02],\n",
       "         [-2.6848e-01,  3.1018e-01,  3.9608e-01,  2.7567e-01, -3.3120e-01],\n",
       "         [-1.4424e-01,  2.5619e-02, -2.5280e-01,  3.1746e-01, -2.6359e-01],\n",
       "         [-1.3415e-01, -1.2354e-01, -1.2567e-01, -1.1214e-01, -3.1888e-01],\n",
       "         [-3.4990e-02, -5.8431e-02, -2.5197e-01, -1.7618e-01, -2.0445e-01],\n",
       "         [-1.5024e-01, -1.2562e-01,  1.3013e-01, -1.3032e-01, -1.9585e-01],\n",
       "         [ 1.5957e-01,  7.7864e-02, -1.6328e-01, -9.7555e-02, -2.5258e-01],\n",
       "         [ 1.5716e-01,  1.5627e-01, -1.9084e-01,  1.8621e-01,  3.4278e-01],\n",
       "         [ 2.0683e-01,  4.2348e-02,  2.7119e-01, -2.9999e-01,  8.3874e-05],\n",
       "         [-2.6280e-01,  4.0291e-01,  1.0367e-01, -2.3039e-01, -2.5573e-01],\n",
       "         [ 9.7494e-02, -8.2671e-02, -4.1476e-01, -3.7020e-01, -6.4585e-02],\n",
       "         [-1.4133e-01, -1.1157e-01,  4.3175e-01, -6.6761e-04, -5.1944e-03],\n",
       "         [ 7.3526e-02,  5.7434e-02,  3.8782e-01, -2.3434e-01, -2.7841e-01],\n",
       "         [-1.7414e-01,  1.0563e-01,  1.0262e-01,  1.9036e-01,  2.7183e-02],\n",
       "         [-4.8000e-01,  2.3112e-01, -2.3357e-01, -4.3061e-01, -1.2719e-01],\n",
       "         [-1.1876e-01, -4.0251e-01,  3.2323e-01,  4.3115e-01, -4.5238e-01],\n",
       "         [ 1.7024e-01,  2.6582e-01,  2.8769e-01, -4.0859e-01,  2.2151e-01],\n",
       "         [-2.6244e-02, -2.2068e-01,  5.7709e-02,  3.7486e-01,  8.8218e-02],\n",
       "         [-3.7014e-01, -1.1108e-02, -9.5187e-02,  3.0573e-01, -2.2125e-01],\n",
       "         [ 2.9568e-01, -2.4089e-02,  3.1103e-01,  2.8924e-01, -3.7514e-01],\n",
       "         [ 2.5739e-01, -4.1968e-01, -4.0981e-01, -2.8005e-01, -3.5783e-01],\n",
       "         [ 2.2414e-02,  3.5314e-01, -1.8557e-01,  1.1026e-01,  1.1663e-04],\n",
       "         [ 9.1663e-02,  3.0078e-01,  1.1054e-01,  3.9826e-01, -4.1780e-01],\n",
       "         [ 3.8376e-01, -2.1553e-01,  1.6157e-01, -1.0702e-01, -2.4981e-01],\n",
       "         [-2.4502e-01, -3.7939e-01,  3.2232e-01,  2.6138e-01, -1.0484e-01],\n",
       "         [ 4.0942e-01,  4.2051e-01,  4.3923e-01,  3.5368e-01, -1.5961e-01],\n",
       "         [ 4.0969e-01,  2.7730e-01, -4.3669e-01,  2.3848e-01,  3.2288e-02],\n",
       "         [ 4.3809e-01, -1.6324e-01,  3.6361e-01,  1.4497e-01,  3.9630e-01],\n",
       "         [ 2.6838e-01,  4.4369e-01, -4.2903e-01,  1.3532e-01, -2.5985e-01],\n",
       "         [-1.5458e-02, -2.6543e-01,  2.1511e-01,  1.0269e-01, -2.9701e-01],\n",
       "         [-2.4838e-01,  5.5512e-02, -4.0056e-01,  3.5151e-01,  1.5389e-01],\n",
       "         [-1.2705e-01, -1.9513e-02, -3.1980e-01,  2.7041e-01,  9.8709e-02],\n",
       "         [ 3.7610e-01, -7.5590e-02, -2.4018e-01,  4.3964e-01, -2.6588e-01],\n",
       "         [ 3.2002e-01,  5.9593e-02,  1.0737e-01,  1.0298e-01, -4.2787e-01],\n",
       "         [ 3.9440e-01, -8.3572e-02,  4.1511e-01, -4.1982e-01,  3.3710e-01],\n",
       "         [ 4.2531e-01,  7.9139e-02, -4.2465e-01,  1.3161e-01,  3.2244e-01],\n",
       "         [-2.7455e-01,  7.5763e-02, -2.6762e-01, -3.2713e-01,  1.8071e-01],\n",
       "         [ 3.6829e-01, -1.1723e-01,  1.6380e-02, -2.2610e-01,  3.4065e-01],\n",
       "         [ 2.6533e-01,  3.5619e-01, -2.8858e-01,  1.1624e-01,  2.5552e-01],\n",
       "         [-3.7421e-01,  1.0881e-01,  2.7720e-01, -4.4026e-01, -4.1055e-01],\n",
       "         [ 3.0941e-01,  1.1137e-02,  4.2075e-01, -3.5845e-01,  1.5661e-01],\n",
       "         [ 1.9331e-01,  2.0055e-02,  1.2906e-01, -3.5170e-01,  9.0486e-02],\n",
       "         [ 1.4045e-01,  2.9026e-02,  2.1872e-01, -3.5200e-01, -2.8175e-01],\n",
       "         [-1.6076e-01,  1.4631e-01,  1.6948e-01, -1.5255e-01,  5.4884e-02],\n",
       "         [ 3.0074e-01,  5.0490e-04,  8.6888e-02,  2.6907e-01,  9.5393e-02],\n",
       "         [-2.3231e-02, -8.0506e-03,  5.2819e-02, -3.8852e-01, -4.3974e-01],\n",
       "         [-3.3716e-02, -3.0532e-01,  4.0250e-01,  3.5199e-01,  3.0358e-01],\n",
       "         [-4.3256e-01,  5.7750e-02, -1.3079e-01,  1.6255e-02,  1.9233e-01],\n",
       "         [ 1.0436e-01,  8.3858e-02,  1.8949e-01, -2.4473e-01, -7.0951e-02],\n",
       "         [-1.5134e-01,  2.6561e-01,  3.8673e-01, -1.0642e-01,  2.8351e-01],\n",
       "         [-1.4701e-01,  2.1023e-01, -2.4901e-03,  2.7087e-01, -3.7021e-01],\n",
       "         [ 3.7368e-01, -4.2345e-02,  3.0007e-01,  2.5715e-01,  2.9601e-01],\n",
       "         [-1.4183e-01, -1.9169e-01, -3.1910e-01, -2.1262e-01,  4.3017e-01],\n",
       "         [ 8.3460e-02,  4.1288e-01,  3.8932e-01,  1.6188e-01, -7.0119e-02],\n",
       "         [-2.6314e-02, -3.4355e-01, -3.3135e-01, -1.0890e-01,  1.6165e-01],\n",
       "         [-2.5406e-01, -3.9633e-01,  1.0868e-01,  2.6502e-01, -3.5573e-02],\n",
       "         [ 4.4999e-01, -3.0043e-01, -4.1264e-01, -4.3373e-02,  8.8983e-02],\n",
       "         [-3.5553e-01,  2.4012e-01, -9.1337e-02,  3.8662e-01,  2.7309e-01],\n",
       "         [-3.8624e-01, -6.5714e-02, -4.9329e-02,  1.7276e-01,  3.2575e-01],\n",
       "         [-3.6930e-01, -3.3560e-01, -3.9861e-01,  1.4707e-02,  1.9448e-01],\n",
       "         [ 1.2595e-01, -2.9447e-01,  1.8335e-01, -3.9391e-01, -5.0266e-02],\n",
       "         [-3.7061e-01,  9.2537e-02, -3.7543e-01, -6.6923e-02, -2.1937e-01],\n",
       "         [ 2.1719e-02, -6.7133e-02,  2.8583e-01, -4.6535e-01,  3.7091e-01],\n",
       "         [-6.2717e-02, -1.3911e-02,  3.6688e-01,  6.0490e-02,  1.9775e-01],\n",
       "         [ 2.9767e-01, -2.3054e-01,  3.9564e-01, -1.9487e-01, -4.7961e-03],\n",
       "         [ 1.2597e-01, -2.8812e-01,  1.7305e-01,  2.6667e-01, -9.7795e-02],\n",
       "         [-4.4540e-01, -4.2346e-02, -2.4592e-01,  1.3272e-01, -3.1667e-01],\n",
       "         [ 2.3441e-01,  6.0975e-02,  1.1586e-01,  1.1354e-01, -7.4894e-02],\n",
       "         [-2.3211e-01, -3.5139e-01, -3.7982e-01,  4.3407e-01, -2.1292e-01],\n",
       "         [-9.8057e-02, -1.5603e-01, -2.0895e-01, -1.2583e-01,  3.7050e-01],\n",
       "         [-1.9803e-01,  4.1457e-01,  2.8238e-01, -2.7672e-02, -2.0382e-01],\n",
       "         [-5.7179e-03, -8.1522e-02,  1.7336e-01, -1.6975e-01,  7.7689e-02],\n",
       "         [ 4.2083e-03, -8.0369e-02, -9.9353e-02, -2.3456e-01, -4.2025e-03],\n",
       "         [-2.1401e-01, -2.0833e-01,  2.3433e-01,  1.6511e-01,  1.2398e-01],\n",
       "         [-3.8803e-02,  1.2482e-01, -4.4012e-01,  2.2515e-01,  3.9198e-01],\n",
       "         [ 3.5024e-01, -4.1468e-01,  1.6571e-01, -3.0420e-01, -4.2905e-01],\n",
       "         [ 1.4328e-01,  3.0581e-01, -8.6930e-02, -4.1581e-01, -1.3403e-01],\n",
       "         [-2.9296e-01, -1.5481e-01,  4.1078e-01,  3.6576e-01, -1.2777e-01],\n",
       "         [-3.1069e-01, -3.7733e-01, -1.5045e-01, -3.0712e-01, -4.3106e-01],\n",
       "         [-1.6997e-01,  3.8440e-01, -1.0432e-01,  9.0461e-03, -2.5325e-02],\n",
       "         [ 3.4881e-01,  9.2057e-02,  2.2654e-01,  7.1740e-02, -6.1468e-02],\n",
       "         [ 2.0158e-01,  1.9916e-01, -1.3078e-01,  3.3686e-01, -1.2499e-01],\n",
       "         [-2.5718e-01,  2.4543e-02, -3.9435e-01,  4.5279e-01,  7.7701e-03],\n",
       "         [ 2.2483e-01,  1.6531e-01, -5.9542e-02, -3.6292e-01,  5.7659e-02],\n",
       "         [-2.3809e-01, -2.3910e-01,  1.2623e-01, -4.5468e-01, -2.1639e-02],\n",
       "         [ 5.6443e-03, -2.3446e-01, -4.9521e-02,  1.2071e-01,  1.1041e-01],\n",
       "         [ 4.4162e-02, -3.3022e-01,  6.5383e-02, -8.2215e-04,  1.1870e-01],\n",
       "         [-1.5037e-01, -9.4552e-02,  2.5556e-01, -3.0226e-01,  3.0162e-01],\n",
       "         [-3.4409e-01, -7.2997e-02,  1.2939e-01, -3.4350e-01,  3.2847e-01],\n",
       "         [ 3.5952e-01,  4.1033e-01, -9.3858e-02, -2.5991e-01,  3.0455e-01],\n",
       "         [-2.8817e-01,  7.3349e-02, -2.0098e-01, -1.6898e-01, -3.0008e-01],\n",
       "         [-2.5943e-01,  2.2659e-01, -7.5916e-02, -1.9689e-01, -1.8911e-01],\n",
       "         [ 4.3324e-01,  1.3792e-01,  7.5372e-02,  2.5135e-01,  4.3529e-01],\n",
       "         [-4.4417e-02, -3.8042e-01, -3.2591e-01,  1.2513e-01,  2.7342e-01],\n",
       "         [-3.1596e-01, -7.1197e-02, -4.2224e-01, -1.7659e-01,  2.0951e-01],\n",
       "         [ 1.9489e-01, -1.1299e-01, -2.4830e-02,  4.7690e-01,  1.0609e-04],\n",
       "         [-7.0337e-02, -6.5347e-02, -1.9762e-01, -3.2940e-01,  1.4135e-01],\n",
       "         [ 1.7451e-01, -2.9654e-01, -4.4810e-02, -3.0660e-01, -2.1201e-01],\n",
       "         [ 1.9286e-01,  9.7901e-02,  1.1752e-01, -2.8036e-01, -2.6431e-01],\n",
       "         [ 1.1077e-01, -2.8841e-01,  1.9255e-01,  2.8712e-02, -1.2216e-01],\n",
       "         [-9.2789e-02, -2.9969e-01, -5.9751e-03, -1.3352e-01,  4.3518e-01],\n",
       "         [-4.6899e-01,  1.4436e-01, -2.1245e-01,  1.1672e-01,  1.5293e-01],\n",
       "         [ 3.3512e-01,  4.3248e-01, -1.1797e-01,  4.7103e-02,  4.1530e-01],\n",
       "         [-2.3090e-01, -1.5805e-01, -1.4231e-01,  3.6452e-01,  3.8161e-01],\n",
       "         [ 7.5428e-02, -2.3521e-01,  3.7790e-01,  2.0688e-01,  1.6864e-01],\n",
       "         [-4.3223e-01,  2.9355e-01,  1.5592e-01,  7.4028e-02, -1.7409e-01],\n",
       "         [ 3.6278e-02,  1.1051e-01,  1.6308e-01,  4.6431e-01,  1.2997e-02],\n",
       "         [-6.0628e-02, -1.9653e-01, -3.0526e-01, -6.7328e-02,  1.1991e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2238, -0.1195,  0.3114,  0.3493,  0.4017,  0.1228,  0.4847,  0.2288,\n",
       "         -0.1463, -0.0007, -0.0856,  0.4106,  0.1262,  0.2639,  0.0916, -0.2572,\n",
       "          0.3620,  0.0020, -0.3385, -0.0048, -0.0247, -0.0921,  0.0747, -0.0721,\n",
       "          0.0660, -0.3902,  0.0010, -0.2651, -0.2714, -0.3707, -0.1099, -0.2014,\n",
       "          0.2106,  0.3471, -0.3601, -0.0480, -0.1319,  0.2894,  0.0515, -0.3746,\n",
       "         -0.3344, -0.2350,  0.3767, -0.1819, -0.0328,  0.1110,  0.1815, -0.3513,\n",
       "          0.2796, -0.1683, -0.2243,  0.4051,  0.0189, -0.3835,  0.1086, -0.0391,\n",
       "          0.3821, -0.1235,  0.2448,  0.3258, -0.4522, -0.0595,  0.2813, -0.2818,\n",
       "         -0.3671, -0.3414, -0.0151, -0.1668,  0.2687, -0.1811, -0.2853, -0.3674,\n",
       "         -0.2845,  0.1937, -0.0073,  0.2165, -0.4200, -0.0714,  0.0723, -0.1525,\n",
       "          0.2785, -0.2297, -0.0729,  0.1485,  0.0611,  0.4605,  0.4350, -0.3714,\n",
       "         -0.3070, -0.0501,  0.0786, -0.0660, -0.1812, -0.3991,  0.1329, -0.0616,\n",
       "         -0.3674,  0.0164,  0.1252, -0.4442,  0.2060, -0.1211, -0.0056,  0.1812,\n",
       "          0.1589,  0.0343, -0.1867, -0.3235, -0.0939,  0.1208, -0.2110, -0.3688,\n",
       "         -0.3616,  0.1846,  0.0921, -0.0499, -0.0364,  0.2178, -0.4418, -0.0331,\n",
       "         -0.1808,  0.2498,  0.2582, -0.3069, -0.2996,  0.3679,  0.1822,  0.2902,\n",
       "          0.4104,  0.0243,  0.3000,  0.3390, -0.2118, -0.1225, -0.5223,  0.3488,\n",
       "         -0.2906, -0.1046,  0.0466,  0.2753, -0.4711,  0.0931,  0.2399,  0.3223,\n",
       "          0.0731, -0.3699,  0.3517, -0.0540,  0.2408,  0.3478, -0.3862, -0.3426,\n",
       "         -0.1516,  0.0408, -0.0378, -0.4267,  0.4246,  0.2753, -0.0375,  0.4355,\n",
       "         -0.4188,  0.0686, -0.4025, -0.2599, -0.3911, -0.2663, -0.2683,  0.0042,\n",
       "         -0.3949,  0.3944,  0.1540, -0.3583, -0.0445, -0.0303, -0.0325,  0.1771,\n",
       "         -0.3438, -0.4200, -0.0756, -0.0753,  0.1969, -0.2443, -0.1540,  0.4123,\n",
       "         -0.2159, -0.4464,  0.0474,  0.1695, -0.1842,  0.3398,  0.1224,  0.1815,\n",
       "          0.0350,  0.0095, -0.1167,  0.0292,  0.2683,  0.2807, -0.2689,  0.1311],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0241, -0.0122, -0.0537,  ...,  0.0011, -0.0713,  0.0578],\n",
       "         [ 0.0301, -0.0613, -0.0481,  ..., -0.0137, -0.0701,  0.0377],\n",
       "         [-0.0699,  0.0036,  0.0254,  ..., -0.0311,  0.0295,  0.0451],\n",
       "         ...,\n",
       "         [-0.0262,  0.0688,  0.0133,  ..., -0.0391, -0.0341, -0.0649],\n",
       "         [ 0.0248, -0.0376, -0.0398,  ..., -0.0373, -0.0040,  0.0057],\n",
       "         [ 0.0504,  0.0013, -0.0565,  ..., -0.0387, -0.0491, -0.0318]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0030, -0.0538,  0.0081,  0.0031, -0.0372,  0.0123, -0.0655, -0.0209,\n",
       "         -0.0120,  0.0032,  0.0749,  0.0636, -0.1013, -0.0168, -0.0595, -0.0185,\n",
       "          0.0541,  0.0394, -0.0921, -0.0269, -0.1869, -0.0688,  0.0052, -0.0588,\n",
       "          0.0003,  0.0688, -0.0233, -0.0158, -0.0247, -0.0998, -0.0353,  0.0525,\n",
       "          0.0307, -0.0340, -0.0069,  0.0765, -0.0922, -0.0376,  0.0246, -0.0497,\n",
       "         -0.0181, -0.0210,  0.0408,  0.0671,  0.0732,  0.0655,  0.0526,  0.0172,\n",
       "          0.0193, -0.0334, -0.0155,  0.0190, -0.0357,  0.0628, -0.0427,  0.0478,\n",
       "         -0.0193, -0.0478,  0.0549,  0.0504, -0.0003,  0.0362,  0.0617, -0.0291,\n",
       "          0.0049,  0.0533,  0.0315,  0.0290,  0.0062, -0.0472, -0.0671,  0.0297,\n",
       "         -0.0552, -0.0301,  0.0318, -0.0591,  0.0093, -0.0030, -0.0725,  0.0110,\n",
       "          0.0542,  0.0513,  0.0074, -0.0443, -0.0682,  0.0159, -0.0335,  0.0494,\n",
       "         -0.0661, -0.0442, -0.0293, -0.0366,  0.0128, -0.0623, -0.0300,  0.0735,\n",
       "          0.0231,  0.0178,  0.0115, -0.0075,  0.0072,  0.0781, -0.0492, -0.0421,\n",
       "          0.0414, -0.0379, -0.0076,  0.0671,  0.0511,  0.0816, -0.0065, -0.0533,\n",
       "          0.0217, -0.0043,  0.0207,  0.0193,  0.0028, -0.0633,  0.0309,  0.0062,\n",
       "          0.0350,  0.0247, -0.0804,  0.0594,  0.0157,  0.0747, -0.0177,  0.0573,\n",
       "          0.0312, -0.0563, -0.0323, -0.0385,  0.0180, -0.0337, -0.0317,  0.0631,\n",
       "          0.1137, -0.0471,  0.0145,  0.0435, -0.0624, -0.0416, -0.0230, -0.1062,\n",
       "          0.0091,  0.0478, -0.0545,  0.0415,  0.0911,  0.0453,  0.0407,  0.0895,\n",
       "          0.0050, -0.0409,  0.0184,  0.0168,  0.0236,  0.0198, -0.0368,  0.0465,\n",
       "         -0.0075,  0.0516, -0.0437,  0.0115, -0.0615,  0.0151, -0.0522,  0.0353,\n",
       "          0.0070,  0.0081, -0.0034,  0.0418,  0.0641, -0.0706, -0.0630, -0.0286,\n",
       "          0.0313,  0.0559, -0.0630, -0.0341, -0.0092, -0.0586, -0.0489, -0.0268,\n",
       "         -0.0199, -0.0097,  0.0579,  0.0458, -0.0067, -0.0579, -0.0655,  0.0211,\n",
       "          0.0339,  0.0869, -0.0969,  0.0267, -0.0187, -0.0064, -0.0499,  0.0666],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.4090e-02,  6.9565e-02, -3.5155e-02,  5.5612e-02,  5.3860e-02,\n",
       "          -4.1337e-02,  3.5834e-04,  3.7169e-02, -6.0709e-02, -8.5313e-02,\n",
       "          -6.0081e-02,  2.7807e-02,  1.1879e-01,  4.2109e-02,  4.0483e-02,\n",
       "           8.8495e-02, -3.8957e-02, -3.2006e-03,  1.1152e-01, -1.2592e-01,\n",
       "           2.3450e-01, -2.6364e-02,  6.3550e-02,  5.5842e-03, -3.9718e-02,\n",
       "           8.4890e-02,  2.5143e-02,  1.7254e-01,  3.8818e-02, -3.9532e-02,\n",
       "           5.8330e-02, -5.5171e-03,  5.5141e-02,  5.2298e-02,  1.1099e-01,\n",
       "          -8.9969e-02,  7.8419e-02,  4.5299e-02, -6.5000e-02, -3.2117e-02,\n",
       "          -4.1099e-02,  9.8845e-02, -6.1753e-02,  1.5554e-02, -1.0087e-01,\n",
       "           1.2362e-01,  4.2198e-02, -2.2892e-02,  5.2504e-02, -8.4065e-02,\n",
       "          -7.8466e-02,  4.2878e-02, -1.3694e-04,  1.2543e-02,  2.6602e-02,\n",
       "           1.0763e-02,  3.5303e-02, -1.8495e-02, -4.0041e-02,  1.3350e-01,\n",
       "          -2.0601e-02, -5.7641e-02, -8.5344e-02, -2.2561e-03, -5.9076e-02,\n",
       "          -1.0543e-01, -1.0828e-01,  8.6927e-02, -2.2099e-02, -8.0739e-03,\n",
       "          -2.5372e-02,  7.1726e-03, -1.1923e-01,  1.0359e-02, -5.1938e-02,\n",
       "          -3.9619e-02,  6.6883e-02,  1.1000e-01,  1.6874e-02,  1.6325e-02,\n",
       "           1.1502e-01, -7.8796e-02, -3.5110e-04, -7.6488e-02,  5.1980e-02,\n",
       "          -5.6062e-02,  1.0260e-02, -4.5081e-02, -8.8042e-02,  1.0751e-01,\n",
       "           6.8655e-02,  1.1500e-01,  2.5798e-02,  5.2334e-02, -2.5429e-03,\n",
       "          -5.6267e-02, -4.2473e-02,  9.3580e-02, -1.0898e-01, -2.9392e-02,\n",
       "           6.7912e-04,  2.9322e-02, -2.9297e-02,  4.0222e-02,  1.6834e-02,\n",
       "           1.0913e-01,  7.8026e-02, -1.7227e-02,  9.2528e-02, -6.4047e-02,\n",
       "          -4.1455e-02, -6.4682e-02, -2.9402e-02, -7.2620e-02, -2.4168e-02,\n",
       "           8.4882e-03, -7.0883e-02, -1.5464e-01, -2.7444e-02,  7.6772e-02,\n",
       "           5.5740e-03, -8.0880e-03,  8.4834e-02,  4.9000e-02, -9.0769e-02,\n",
       "           4.3266e-02, -7.7761e-03,  5.5733e-03, -5.6174e-02, -3.7735e-02,\n",
       "           5.8852e-02,  1.3540e-01,  4.7268e-02, -6.4088e-02,  5.7190e-02,\n",
       "          -2.2886e-02,  2.5773e-02,  1.7621e-03, -1.5433e-01, -6.6745e-02,\n",
       "           1.1522e-01,  1.5705e-01, -7.3196e-03,  1.5338e-01,  5.4097e-03,\n",
       "          -3.2571e-02, -8.2287e-02,  5.1264e-02,  9.2003e-03, -6.4360e-02,\n",
       "           2.0385e-02, -3.0545e-02, -6.9155e-02, -4.5868e-02,  5.9196e-02,\n",
       "           7.0005e-02,  1.4954e-02, -2.5316e-02, -6.4019e-02,  8.8729e-02,\n",
       "          -3.3755e-02, -1.2174e-01,  7.6336e-02,  3.5521e-03,  1.0624e-01,\n",
       "          -6.8602e-03, -8.0241e-03,  1.6893e-03, -6.1401e-02,  4.9035e-02,\n",
       "          -1.2460e-01, -6.7994e-02, -6.7066e-02,  3.3210e-02, -9.2354e-02,\n",
       "           6.1075e-02, -2.5647e-02,  8.7386e-02, -1.2051e-01, -6.0630e-02,\n",
       "           4.6389e-02,  3.5998e-02, -2.0005e-02,  5.6358e-02,  5.3410e-02,\n",
       "           9.0332e-02,  2.4395e-02, -6.0888e-03,  1.7521e-02,  1.0745e-01,\n",
       "           1.6095e-02, -5.6365e-02,  3.7151e-02, -4.5484e-02, -4.5458e-02,\n",
       "          -1.0730e-01,  3.7370e-02, -3.3387e-02, -1.8438e-02,  4.1773e-02],\n",
       "         [ 5.1393e-02,  4.1816e-02,  5.8070e-02, -5.1592e-02, -2.7406e-04,\n",
       "          -4.9235e-02, -3.7931e-02,  4.5062e-02, -5.2186e-02,  1.2924e-01,\n",
       "          -1.2785e-01,  1.0541e-01, -1.9589e-01,  6.6582e-02, -3.6593e-02,\n",
       "          -4.1712e-02, -1.2183e-01,  5.2140e-02, -1.8831e-01,  2.2634e-02,\n",
       "          -4.6194e-01,  3.7174e-02,  7.2761e-02, -8.6222e-02, -5.4842e-02,\n",
       "          -1.3317e-02,  2.4646e-02, -5.7903e-02,  1.1182e-01,  3.0380e-01,\n",
       "          -4.4085e-02, -7.7520e-02, -7.0107e-02,  1.4300e-01, -9.9611e-02,\n",
       "           1.8258e-01, -2.2056e-01,  5.9995e-02, -1.6059e-01, -4.6075e-02,\n",
       "           1.6655e-01,  1.2393e-02,  1.3093e-01,  3.6467e-02, -1.3634e-01,\n",
       "          -2.9592e-02,  1.6509e-01, -1.4018e-01,  2.6554e-02, -1.2528e-01,\n",
       "          -6.5688e-03, -1.3418e-01,  1.0286e-02,  4.1000e-02, -3.3844e-02,\n",
       "           4.5193e-05,  1.9290e-02,  2.8841e-01,  1.5955e-01, -2.4874e-02,\n",
       "          -5.0523e-02, -1.5217e-01,  8.8954e-02,  1.1123e-01, -3.3112e-02,\n",
       "           1.1415e-01, -3.5766e-02, -2.9296e-02,  3.5182e-02,  1.1403e-02,\n",
       "           2.3593e-01, -3.4789e-02, -1.1845e-01, -1.2312e-02, -4.0624e-02,\n",
       "           7.2255e-02,  7.3120e-03, -1.3574e-01, -2.5847e-01,  9.4771e-02,\n",
       "           8.6294e-02,  1.8969e-01,  4.7112e-02,  5.8300e-02,  4.8253e-02,\n",
       "           2.7570e-02,  1.0024e-03, -6.9328e-02,  1.8781e-01, -1.3503e-01,\n",
       "           8.0034e-02, -1.6802e-01, -3.0823e-02,  3.9714e-02, -6.3968e-02,\n",
       "          -1.2343e-01,  1.8881e-03, -1.0268e-01, -1.1256e-01,  1.6285e-01,\n",
       "           1.3945e-01, -7.3003e-02,  2.6335e-02, -3.9244e-02,  3.9956e-02,\n",
       "          -1.8696e-02,  2.3342e-02,  1.6685e-03, -2.5712e-03,  1.7102e-01,\n",
       "           9.6039e-02,  1.5658e-02, -1.0327e-01,  1.2220e-01,  1.3166e-01,\n",
       "          -1.0065e-02,  9.8939e-03,  1.1929e-01,  2.1933e-02, -9.1318e-02,\n",
       "          -3.9081e-02,  9.6818e-05,  1.1671e-02,  3.3077e-03, -1.0649e-01,\n",
       "          -9.7867e-02,  1.2378e-01,  1.2790e-01,  8.5702e-03, -4.6017e-02,\n",
       "           4.2153e-02, -1.4716e-01, -4.9269e-02, -1.3573e-01,  2.4904e-02,\n",
       "           6.6897e-02, -1.8934e-01, -1.8823e-02,  1.3307e-01,  8.3504e-02,\n",
       "          -7.3242e-02, -2.1798e-01,  7.1859e-02, -1.3589e-01,  1.3158e-01,\n",
       "           1.0607e-01,  3.9916e-02,  1.1572e-01, -1.1218e-01, -7.9377e-02,\n",
       "           2.6187e-02,  1.4297e-01,  8.1519e-02,  1.3488e-01,  6.7198e-02,\n",
       "           4.5175e-02, -5.9759e-02, -9.3139e-02,  1.8720e-01,  1.2975e-01,\n",
       "           3.5193e-02,  2.4946e-02, -6.2290e-02,  1.4817e-02, -4.6539e-02,\n",
       "          -1.0385e-01, -2.2876e-02, -6.2560e-02,  3.8240e-02, -2.6265e-02,\n",
       "           1.1988e-01,  5.5625e-02,  6.5548e-02,  3.7220e-03,  1.7815e-02,\n",
       "          -6.5596e-02,  2.1037e-02, -6.3541e-03,  2.6151e-02, -5.4592e-02,\n",
       "           1.5133e-01, -7.9556e-02,  6.4233e-02,  5.2177e-03,  3.3940e-02,\n",
       "          -8.0343e-02, -9.0897e-02, -2.4677e-02, -9.2971e-02,  4.7163e-02,\n",
       "          -1.7472e-01,  5.0219e-02,  1.3372e-01, -9.7566e-02, -1.4677e-01,\n",
       "           8.5207e-03, -4.6670e-02,  9.1855e-02, -1.1418e-01,  2.8437e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0010,  0.1402], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6837, 0.3785, 0.6648, 0.0171, 0.2151],\n",
      "        [0.4980, 0.2629, 0.8750, 0.3264, 0.6148]])\n",
      "tensor([[ 0.4816, -0.2646],\n",
      "        [ 0.4714, -0.2921]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3da3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lnorm = nn.LayerNorm(5)\n",
    "Bnorm = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f854e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1849e-01,  1.3309e-01, -1.0097e-02,  1.1138e+00, -1.1284e+00],\n",
      "        [-1.3124e+00, -4.5486e-01, -6.9774e-01,  7.1873e-01, -4.9840e-02],\n",
      "        [-1.0751e+00, -5.4105e-01, -7.6198e-01, -8.0966e-01,  1.5753e+00],\n",
      "        [-1.4601e+00,  4.0222e-01,  8.9972e-01, -7.6124e-01, -1.0493e-01],\n",
      "        [ 3.9241e-01, -1.5774e+00,  1.3533e-01, -6.1199e-01,  4.9269e-01],\n",
      "        [-1.5800e+00, -3.8601e-01,  4.7212e-03,  9.0382e-01, -9.2840e-01],\n",
      "        [ 1.2295e+00, -1.2447e+00, -2.8283e-01, -1.2922e+00,  1.5983e+00],\n",
      "        [-4.2120e-01,  1.5532e-01, -1.1526e+00, -1.1303e+00,  2.2864e+00],\n",
      "        [ 5.3817e-01,  1.4841e+00,  4.3640e-01, -1.4327e-01, -2.8184e-01],\n",
      "        [ 1.4035e+00,  5.9408e-01, -6.3031e-01, -9.4790e-01,  1.5874e+00],\n",
      "        [ 1.6121e+00,  5.5167e-01, -1.2638e-01, -6.5691e-01,  7.9544e-01],\n",
      "        [-1.0078e+00, -2.4737e-01, -2.4922e-01, -3.9616e-01,  6.4948e-01],\n",
      "        [-9.8495e-01,  1.4651e+00,  5.7657e-01, -5.5475e-01,  1.1575e-03],\n",
      "        [-1.5295e+00, -1.0960e+00, -1.8324e-02, -6.1725e-01,  6.4886e-01],\n",
      "        [ 1.4392e+00,  1.3400e+00,  1.0232e+00, -1.1805e+00,  2.0236e-01],\n",
      "        [-7.0648e-02,  5.1633e-01, -1.1562e+00,  1.7878e+00, -6.9257e-01],\n",
      "        [ 1.3046e+00, -1.4648e+00, -1.0305e+00,  2.0939e+00, -1.1288e+00],\n",
      "        [-1.4028e+00, -7.5049e-01,  1.4111e+00, -6.2756e-01, -7.4338e-01],\n",
      "        [-8.1115e-01, -9.4013e-01,  6.9493e-01, -6.0763e-01, -6.0950e-02],\n",
      "        [-2.5617e-01, -1.2344e-01, -9.3568e-02,  9.2276e-01, -8.5130e-01],\n",
      "        [ 8.3027e-01, -3.1979e-01,  1.1492e+00, -1.9604e-01, -9.2745e-01],\n",
      "        [-3.6225e-01,  1.6103e+00, -6.8104e-01, -5.9348e-01,  1.2749e+00],\n",
      "        [-1.7547e+00, -1.2613e+00,  7.0373e-01, -5.8766e-01, -8.9998e-02],\n",
      "        [ 1.3152e+00,  1.4590e+00,  2.0306e+00, -6.0776e-01, -1.3716e+00],\n",
      "        [ 1.3108e+00,  6.2988e-01,  1.2637e-01,  3.6792e-01, -5.0006e-01],\n",
      "        [-1.2812e+00, -1.4891e+00,  1.7154e+00, -1.1615e+00, -4.9629e-01],\n",
      "        [-7.4183e-01,  1.1734e+00,  1.3456e-01, -1.0353e+00,  9.2615e-01],\n",
      "        [-2.9450e-01,  1.4504e+00, -8.8758e-01,  3.2059e-01,  5.4339e-01],\n",
      "        [ 1.2291e-01,  1.0749e+00, -4.3597e-01,  1.6668e+00, -1.2758e+00],\n",
      "        [ 9.6669e-01, -1.3365e+00,  1.5060e+00, -1.0696e+00, -3.8480e-01],\n",
      "        [ 5.4929e-01,  1.1143e-01, -9.6741e-01, -1.2566e+00,  2.2338e+00],\n",
      "        [ 1.5312e+00,  1.1676e+00,  7.1824e-01, -1.0581e+00,  3.7663e-01],\n",
      "        [-8.3855e-01,  1.3055e+00, -3.8536e-02, -6.6298e-01,  7.1543e-01],\n",
      "        [-4.6276e-01,  7.1749e-01, -2.9994e-01, -6.6325e-01,  9.7225e-01],\n",
      "        [-1.9058e-01, -8.9069e-01, -4.6595e-01, -1.1702e+00,  1.6533e+00],\n",
      "        [ 1.5685e+00,  2.5778e-01,  5.0059e-01, -5.6895e-01,  9.0238e-02],\n",
      "        [ 1.1170e+00,  1.2613e-01,  1.8675e+00, -1.1061e+00, -7.0226e-01],\n",
      "        [ 7.3327e-01,  1.2197e+00, -1.0070e+00,  2.1183e-01,  7.7170e-01],\n",
      "        [-1.6567e+00,  3.3916e-01, -2.7547e-02,  9.2913e-02, -6.7929e-02],\n",
      "        [ 1.5639e-01,  4.6021e-03, -5.6245e-01, -1.2557e+00,  1.8354e+00],\n",
      "        [ 2.8346e-01, -1.2069e+00,  2.1403e-03, -2.5448e-01,  2.5799e-01],\n",
      "        [-6.7233e-01,  9.3719e-01,  2.1455e-01,  5.1228e-01, -7.3414e-01],\n",
      "        [ 1.4988e+00,  7.6228e-02,  1.8619e+00, -1.0607e+00, -7.4312e-01],\n",
      "        [-5.4861e-01,  5.7522e-01,  6.5008e-02, -1.2773e+00,  1.2417e+00],\n",
      "        [-9.1929e-01, -9.3665e-01, -1.0869e+00, -4.7171e-01,  1.5488e+00],\n",
      "        [ 8.0753e-01,  8.2430e-01,  4.5165e-01, -9.2479e-01,  5.0196e-01],\n",
      "        [ 1.0932e-01, -2.4943e-01,  1.4727e+00, -1.2349e-01, -1.3191e+00],\n",
      "        [-1.5536e+00, -9.1581e-01, -1.1906e+00, -1.0884e+00,  2.2808e+00],\n",
      "        [-1.6415e+00, -7.2668e-01, -5.0998e-01, -2.6546e-01,  7.7180e-01],\n",
      "        [ 9.2303e-01, -1.1778e-01, -1.1215e+00,  9.6405e-01,  1.1525e-01],\n",
      "        [ 1.4029e+00,  1.3636e+00,  1.1425e-01, -1.0628e+00,  9.7412e-01],\n",
      "        [ 3.1401e-01,  9.6992e-01, -1.0414e+00, -7.6595e-01,  1.8049e+00],\n",
      "        [ 1.5099e+00,  1.4525e+00,  4.0396e-01,  4.7049e-01, -8.7732e-01],\n",
      "        [ 9.8009e-01,  6.0436e-01, -8.8164e-01,  1.5503e+00, -7.1933e-01],\n",
      "        [-1.3154e+00, -1.2227e+00,  5.9243e-01, -1.0401e+00,  4.8162e-01],\n",
      "        [ 1.0444e+00,  6.7814e-02,  5.2521e-01,  9.7191e-02, -6.1477e-01],\n",
      "        [ 1.3609e+00,  6.3869e-01, -4.3838e-01,  3.8090e-01,  4.0909e-02],\n",
      "        [-5.4461e-01,  4.8240e-01, -2.0080e-01, -7.7678e-01,  9.9099e-01],\n",
      "        [ 2.7089e-01, -1.6156e+00, -8.6075e-01,  2.2373e-01,  6.1606e-01],\n",
      "        [-1.0900e+00,  5.4445e-01, -2.7218e-01,  4.7105e-01, -2.1433e-01],\n",
      "        [ 1.1288e+00,  8.8812e-01,  5.0622e-01, -5.8226e-01,  9.8313e-02],\n",
      "        [-8.9649e-02, -5.0450e-01, -6.9228e-01,  4.9430e-01,  1.7418e-01],\n",
      "        [-1.6180e+00,  1.4353e+00,  1.9329e+00, -8.9135e-01, -9.8587e-01],\n",
      "        [-1.9339e-01, -1.0697e+00, -1.2763e+00, -1.2917e+00,  2.5728e+00]])\n",
      "tensor([ 1.3878e-17,  6.2450e-17,  1.3878e-17, -6.9389e-18,  1.3878e-17],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.2035,  0.0174, -0.0581,  1.6898, -1.3992],\n",
      "        [-1.2329, -0.6017, -0.8408,  1.2210, -0.3251],\n",
      "        [-1.0096, -0.6924, -0.9139, -0.5930,  1.2931],\n",
      "        [-1.3720,  0.3008,  0.9775, -0.5355, -0.3800],\n",
      "        [ 0.3714, -1.7836,  0.1074, -0.3584,  0.2151],\n",
      "        [-1.4847, -0.5292, -0.0412,  1.4406, -1.2000],\n",
      "        [ 1.1592, -1.4334, -0.3686, -1.1657,  1.3160],\n",
      "        [-0.3943,  0.0408, -1.3585, -0.9735,  2.0012],\n",
      "        [ 0.5086,  1.4399,  0.4501,  0.1979, -0.5562],\n",
      "        [ 1.3229,  0.5028, -0.7641, -0.7570,  1.3052],\n",
      "        [ 1.5192,  0.4581, -0.1905, -0.4117,  0.5166],\n",
      "        [-0.9463, -0.3832, -0.3303, -0.1022,  0.3712],\n",
      "        [-0.9248,  1.4200,  0.6097, -0.2904, -0.2744],\n",
      "        [-1.4373, -1.2767, -0.0675, -0.3646,  0.3706],\n",
      "        [ 1.3565,  1.2883,  1.1180, -1.0330, -0.0740],\n",
      "        [-0.0644,  0.4209, -1.3626,  2.4897, -0.9652],\n",
      "        [ 1.2299, -1.6651, -1.2195,  2.8531, -1.3996],\n",
      "        [-1.3180, -0.9130,  1.5595, -0.3768, -1.0158],\n",
      "        [-0.7612, -1.1126,  0.7444, -0.3532, -0.3362],\n",
      "        [-0.2389, -0.2527, -0.1531,  1.4631, -1.1232],\n",
      "        [ 0.7835, -0.4595,  1.2615,  0.1353, -1.1990],\n",
      "        [-0.3388,  1.5728, -0.8218, -0.3364,  0.9940],\n",
      "        [-1.6492, -1.4509,  0.7544, -0.3295, -0.3651],\n",
      "        [ 1.2398,  1.4135,  2.2647, -0.3533, -1.6413],\n",
      "        [ 1.2357,  0.5405,  0.0972,  0.8046, -0.7735],\n",
      "        [-1.2035, -1.6906,  1.9059, -1.0105, -0.7697],\n",
      "        [-0.6960,  1.1128,  0.1065, -0.8608,  0.6467],\n",
      "        [-0.2750,  1.4044, -1.0569,  0.7484,  0.2656],\n",
      "        [ 0.1178,  1.0091, -0.5429,  2.3462, -1.5459],\n",
      "        [ 0.9119, -1.5300,  1.6676, -0.9014, -0.6587],\n",
      "        [ 0.5191, -0.0054, -1.1478, -1.1235,  1.9488],\n",
      "        [ 1.4431,  1.1067,  0.7709, -0.8879,  0.0995],\n",
      "        [-0.7870,  1.2519, -0.0905, -0.4189,  0.4369],\n",
      "        [-0.4334,  0.6327, -0.3880, -0.4192,  0.6926],\n",
      "        [-0.1772, -1.0606, -0.5770, -1.0209,  1.3708],\n",
      "        [ 1.4782,  0.1487,  0.5232, -0.3073, -0.1857],\n",
      "        [ 1.0533,  0.0101,  2.0790, -0.9447, -0.9748],\n",
      "        [ 0.6922,  1.1615, -1.1928,  0.6194,  0.4929],\n",
      "        [-1.5569,  0.2344, -0.0780,  0.4782, -0.3432],\n",
      "        [ 0.1493, -0.1179, -0.6868, -1.1223,  1.5521],\n",
      "        [ 0.2689, -1.3936, -0.0442,  0.0659, -0.0186],\n",
      "        [-0.6306,  0.8641,  0.1976,  0.9759, -1.0065],\n",
      "        [ 1.4126, -0.0425,  2.0726, -0.8909, -1.0155],\n",
      "        [-0.5142,  0.4830,  0.0274, -1.1480,  0.9609],\n",
      "        [-0.8630, -1.1090, -1.2837, -0.1919,  1.2667],\n",
      "        [ 0.7621,  0.7452,  0.4675, -0.7296,  0.2243],\n",
      "        [ 0.1050, -0.3854,  1.6297,  0.2214, -1.5891],\n",
      "        [-1.4599, -1.0870, -1.4018, -0.9237,  1.9956],\n",
      "        [-1.5426, -0.8879, -0.6271,  0.0529,  0.4930],\n",
      "        [ 0.8708, -0.2467, -1.3231,  1.5121, -0.1608],\n",
      "        [ 1.3224,  1.3130,  0.0834, -0.8934,  0.6945],\n",
      "        [ 0.2976,  0.8985, -1.2320, -0.5411,  1.5217],\n",
      "        [ 1.4231,  1.4067,  0.4132,  0.9264, -1.1491],\n",
      "        [ 0.9245,  0.5136, -1.0501,  2.2080, -0.9918],\n",
      "        [-1.2357, -1.4102,  0.6277, -0.8664,  0.2041],\n",
      "        [ 0.9850, -0.0513,  0.5512,  0.4833, -0.8877],\n",
      "        [ 1.2828,  0.5498, -0.5456,  0.8200, -0.2348],\n",
      "        [-0.5104,  0.3852, -0.2752, -0.5539,  0.7113],\n",
      "        [ 0.2571, -1.8239, -1.0264,  0.6335,  0.3379],\n",
      "        [-1.0236,  0.4505, -0.3564,  0.9270, -0.4889],\n",
      "        [ 1.0644,  0.8124,  0.5296, -0.3231, -0.1776],\n",
      "        [-0.0822, -0.6539, -0.8346,  0.9546, -0.1021],\n",
      "        [-1.5206,  1.3885,  2.1535, -0.6899, -1.2572],\n",
      "        [-0.1799, -1.2491, -1.4994, -1.1651,  2.2864]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([[-2.7365e-01,  2.1608e-01,  1.6627e-02,  1.5821e+00, -1.5411e+00],\n",
      "        [-1.4084e+00, -1.4131e-01, -5.0021e-01,  1.5928e+00,  4.5715e-01],\n",
      "        [-7.8073e-01, -2.2672e-01, -4.5589e-01, -5.0536e-01,  1.9687e+00],\n",
      "        [-1.5038e+00,  7.2729e-01,  1.3233e+00, -6.6651e-01,  1.1973e-01],\n",
      "        [ 8.0782e-01, -1.7333e+00,  4.7618e-01, -4.8790e-01,  9.3718e-01],\n",
      "        [-1.4066e+00,  1.3266e-02,  4.7793e-01,  1.5472e+00, -6.3176e-01],\n",
      "        [ 1.0117e+00, -1.0269e+00, -2.3435e-01, -1.0660e+00,  1.3156e+00],\n",
      "        [-2.9111e-01,  1.6406e-01, -8.6854e-01, -8.5097e-01,  1.8466e+00],\n",
      "        [ 2.1022e-01,  1.7227e+00,  4.7487e-02, -8.7944e-01, -1.1010e+00],\n",
      "        [ 9.7033e-01,  1.8662e-01, -9.9894e-01, -1.3064e+00,  1.1484e+00],\n",
      "        [ 1.5102e+00,  1.4948e-01, -7.2060e-01, -1.4014e+00,  4.6229e-01],\n",
      "        [-1.4293e+00,  5.3600e-03,  1.8638e-03, -2.7536e-01,  1.6974e+00],\n",
      "        [-1.2609e+00,  1.5848e+00,  5.5280e-01, -7.6122e-01, -1.1554e-01],\n",
      "        [-1.3049e+00, -7.4312e-01,  6.5318e-01, -1.2285e-01,  1.5177e+00],\n",
      "        [ 8.9674e-01,  7.9507e-01,  4.7009e-01, -1.7901e+00, -3.7181e-01],\n",
      "        [-1.4397e-01,  4.2861e-01, -1.2029e+00,  1.6689e+00, -7.5063e-01],\n",
      "        [ 9.2883e-01, -9.7698e-01, -6.7808e-01,  1.4720e+00, -7.4577e-01],\n",
      "        [-1.0246e+00, -3.4272e-01,  1.9168e+00, -2.1421e-01, -3.3529e-01],\n",
      "        [-7.7638e-01, -9.9118e-01,  1.7319e+00, -4.3742e-01,  4.7305e-01],\n",
      "        [-3.0761e-01, -7.5393e-02, -2.3136e-02,  1.7549e+00, -1.3488e+00],\n",
      "        [ 9.4076e-01, -5.5562e-01,  1.3557e+00, -3.9461e-01, -1.3463e+00],\n",
      "        [-6.2108e-01,  1.3809e+00, -9.4461e-01, -8.5575e-01,  1.0405e+00],\n",
      "        [-1.3391e+00, -7.6796e-01,  1.5070e+00,  1.1955e-02,  5.8810e-01],\n",
      "        [ 5.7075e-01,  6.8020e-01,  1.1151e+00, -8.9242e-01, -1.4736e+00],\n",
      "        [ 1.5538e+00,  4.0851e-01, -4.3831e-01, -3.2080e-02, -1.4919e+00],\n",
      "        [-6.2763e-01, -8.0429e-01,  1.9186e+00, -5.2596e-01,  3.9292e-02],\n",
      "        [-9.5161e-01,  1.2357e+00,  4.9309e-02, -1.2868e+00,  9.5338e-01],\n",
      "        [-6.5951e-01,  1.5494e+00, -1.4103e+00,  1.1917e-01,  4.0123e-01],\n",
      "        [-1.0266e-01,  8.0500e-01, -6.3549e-01,  1.3693e+00, -1.4362e+00],\n",
      "        [ 9.2076e-01, -1.1375e+00,  1.4027e+00, -8.9898e-01, -2.8702e-01],\n",
      "        [ 3.3395e-01, -1.8227e-02, -8.8594e-01, -1.1186e+00,  1.6888e+00],\n",
      "        [ 1.1018e+00,  6.9473e-01,  1.9161e-01, -1.7973e+00, -1.9087e-01],\n",
      "        [-1.1481e+00,  1.4854e+00, -1.6546e-01, -9.3245e-01,  7.6062e-01],\n",
      "        [-7.7890e-01,  1.0044e+00, -5.3291e-01, -1.0818e+00,  1.3893e+00],\n",
      "        [ 2.2416e-02, -6.8312e-01, -2.5509e-01, -9.6484e-01,  1.8806e+00],\n",
      "        [ 1.7211e+00, -1.6057e-01,  1.8801e-01, -1.3475e+00, -4.0110e-01],\n",
      "        [ 7.7368e-01, -1.2134e-01,  1.4515e+00, -1.2343e+00, -8.6957e-01],\n",
      "        [ 4.5338e-01,  1.0882e+00, -1.8180e+00, -2.2719e-01,  5.0355e-01],\n",
      "        [-1.9597e+00,  8.4876e-01,  3.3275e-01,  5.0225e-01,  2.7592e-01],\n",
      "        [ 1.1749e-01, -3.0211e-02, -5.8202e-01, -1.2566e+00,  1.7514e+00],\n",
      "        [ 8.5269e-01, -1.8684e+00,  3.3905e-01, -1.2948e-01,  8.0619e-01],\n",
      "        [-1.1001e+00,  1.3461e+00,  2.4779e-01,  7.0030e-01, -1.1941e+00],\n",
      "        [ 1.0005e+00, -2.1373e-01,  1.3104e+00, -1.1842e+00, -9.1309e-01],\n",
      "        [-6.4141e-01,  6.4623e-01,  6.1648e-02, -1.4763e+00,  1.4098e+00],\n",
      "        [-5.5574e-01, -5.7340e-01, -7.2627e-01, -1.0029e-01,  1.9557e+00],\n",
      "        [ 7.3508e-01,  7.6102e-01,  1.8481e-01, -1.9435e+00,  2.6260e-01],\n",
      "        [ 1.4688e-01, -2.5440e-01,  1.6720e+00, -1.1353e-01, -1.4509e+00],\n",
      "        [-7.5571e-01, -3.0105e-01, -4.9693e-01, -4.2406e-01,  1.9777e+00],\n",
      "        [-1.5008e+00, -3.2446e-01, -4.5800e-02,  2.6863e-01,  1.6025e+00],\n",
      "        [ 1.0030e+00, -3.5204e-01, -1.6588e+00,  1.0564e+00, -4.8651e-02],\n",
      "        [ 9.0438e-01,  8.6223e-01, -4.7566e-01, -1.7361e+00,  4.4518e-01],\n",
      "        [ 5.4345e-02,  6.7194e-01, -1.2219e+00, -9.6253e-01,  1.4581e+00],\n",
      "        [ 1.0541e+00,  9.8819e-01, -2.1581e-01, -1.3942e-01, -1.6871e+00],\n",
      "        [ 7.0555e-01,  3.1184e-01, -1.2453e+00,  1.3031e+00, -1.0752e+00],\n",
      "        [-9.5520e-01, -8.4655e-01,  1.2820e+00, -6.3238e-01,  1.1521e+00],\n",
      "        [ 1.4940e+00, -2.8435e-01,  5.4857e-01, -2.3086e-01, -1.5273e+00],\n",
      "        [ 1.6016e+00,  4.0210e-01, -1.3868e+00, -2.6078e-02, -5.9078e-01],\n",
      "        [-8.1475e-01,  7.4973e-01, -2.9102e-01, -1.1684e+00,  1.5245e+00],\n",
      "        [ 6.5200e-01, -1.6089e+00, -7.0423e-01,  5.9548e-01,  1.0657e+00],\n",
      "        [-1.6464e+00,  1.1057e+00, -2.6938e-01,  9.8209e-01, -1.7197e-01],\n",
      "        [ 1.1897e+00,  7.9250e-01,  1.6233e-01, -1.6338e+00, -5.1076e-01],\n",
      "        [ 7.8274e-02, -8.7844e-01, -1.3115e+00,  1.4249e+00,  6.8670e-01],\n",
      "        [-1.1163e+00,  1.0238e+00,  1.3726e+00, -6.0695e-01, -6.7320e-01],\n",
      "        [ 3.9691e-02, -5.5709e-01, -6.9777e-01, -7.0825e-01,  1.9234e+00]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(Bnorm(X))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(Lnorm(X))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m((Lnorm(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(Lnorm(X)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(Lnorm(X)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    #print(y.reshape((-1,1)))\n",
    "    print(Bnorm(X).mean(dim=0))\n",
    "    print(Bnorm(X))\n",
    "    print(Lnorm(X))\n",
    "    print((Lnorm(X.permute(0,2,1))).permute(0,2,1))\n",
    "    print(Lnorm(X).mean(dim=0))\n",
    "    print(Lnorm(X).mean(dim=1))\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b867dae",
   "metadata": {},
   "source": [
    "#### Histogramme Verteilung von $xi$ und $x{_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(xi)\n",
    "plt.hist(x_0[:,0],bins=100)\n",
    "plt.hist(x_0[:,1],bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332126b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
