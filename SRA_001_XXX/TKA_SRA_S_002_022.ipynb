{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ReduceLROnPlateau\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import max_error\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "# from sklearn.metrics import mean_absolute_error as MAE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.Linear(input_size, hidden1_size), #Lineare Transformation mit gespeicherten weights und biases\n",
    "            #nn.LayerNorm(hidden1_size),\n",
    "            nn.Tanh(), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden\n",
    "            #nn.SELU(),\n",
    "            nn.BatchNorm1d(hidden1_size),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            #nn.LayerNorm(hidden2_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.BatchNorm1d(hidden2_size),\n",
    "            nn.Linear(hidden2_size, hidden3_size),\n",
    "            #nn.LayerNorm(hidden3_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.BatchNorm1d(hidden3_size),\n",
    "            nn.Linear(hidden3_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (8): Tanh()\n",
      "    (9): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#T = log10(T)\n",
    "# T = T / 850\n",
    "# p = p / 1000\n",
    "\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[30, 70, 100], gamma = 0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 10, threshold = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ccc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-3\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 1/25, Loss: 0.3538\n",
      "Epoch 1/200, Iteration 2/25, Loss: 4.3141\n",
      "Epoch 1/200, Iteration 3/25, Loss: 1.6414\n",
      "Epoch 1/200, Iteration 4/25, Loss: 0.4782\n",
      "Epoch 1/200, Iteration 5/25, Loss: 0.7025\n",
      "Epoch 1/200, Iteration 6/25, Loss: 0.6295\n",
      "Epoch 1/200, Iteration 7/25, Loss: 0.4898\n",
      "Epoch 1/200, Iteration 8/25, Loss: 0.2715\n",
      "Epoch 1/200, Iteration 9/25, Loss: 0.2758\n",
      "Epoch 1/200, Iteration 10/25, Loss: 0.2750\n",
      "Epoch 1/200, Iteration 11/25, Loss: 0.2792\n",
      "Epoch 1/200, Iteration 12/25, Loss: 0.2454\n",
      "Epoch 1/200, Iteration 13/25, Loss: 0.1645\n",
      "Epoch 1/200, Iteration 14/25, Loss: 0.1991\n",
      "Epoch 1/200, Iteration 15/25, Loss: 0.2268\n",
      "Epoch 1/200, Iteration 16/25, Loss: 0.1952\n",
      "Epoch 1/200, Iteration 17/25, Loss: 0.1317\n",
      "Epoch 1/200, Iteration 18/25, Loss: 0.1559\n",
      "Epoch 1/200, Iteration 19/25, Loss: 0.1445\n",
      "Epoch 1/200, Iteration 20/25, Loss: 0.1496\n",
      "Epoch 1/200, Iteration 21/25, Loss: 0.1763\n",
      "Epoch 1/200, Iteration 22/25, Loss: 0.1314\n",
      "Epoch 1/200, Iteration 23/25, Loss: 0.1103\n",
      "Epoch 1/200, Iteration 24/25, Loss: 0.1252\n",
      "Epoch 1/200, Iteration 25/25, Loss: 0.1081\n",
      "Train Error: \n",
      " Accuracy: 43.12%, Avg loss: 0.075293, MRE: 4.289723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 0.068798, MRE: 4.010273 \n",
      "\n",
      "Epoch 2/200, Iteration 1/25, Loss: 0.0612\n",
      "Epoch 2/200, Iteration 2/25, Loss: 0.0669\n",
      "Epoch 2/200, Iteration 3/25, Loss: 0.1244\n",
      "Epoch 2/200, Iteration 4/25, Loss: 0.0793\n",
      "Epoch 2/200, Iteration 5/25, Loss: 0.1332\n",
      "Epoch 2/200, Iteration 6/25, Loss: 0.1284\n",
      "Epoch 2/200, Iteration 7/25, Loss: 0.0999\n",
      "Epoch 2/200, Iteration 8/25, Loss: 0.1422\n",
      "Epoch 2/200, Iteration 9/25, Loss: 0.1332\n",
      "Epoch 2/200, Iteration 10/25, Loss: 0.0751\n",
      "Epoch 2/200, Iteration 11/25, Loss: 0.1048\n",
      "Epoch 2/200, Iteration 12/25, Loss: 0.1126\n",
      "Epoch 2/200, Iteration 13/25, Loss: 0.0725\n",
      "Epoch 2/200, Iteration 14/25, Loss: 0.0821\n",
      "Epoch 2/200, Iteration 15/25, Loss: 0.1251\n",
      "Epoch 2/200, Iteration 16/25, Loss: 0.0752\n",
      "Epoch 2/200, Iteration 17/25, Loss: 0.1309\n",
      "Epoch 2/200, Iteration 18/25, Loss: 0.1254\n",
      "Epoch 2/200, Iteration 19/25, Loss: 0.0803\n",
      "Epoch 2/200, Iteration 20/25, Loss: 0.1688\n",
      "Epoch 2/200, Iteration 21/25, Loss: 0.1459\n",
      "Epoch 2/200, Iteration 22/25, Loss: 0.1417\n",
      "Epoch 2/200, Iteration 23/25, Loss: 0.0841\n",
      "Epoch 2/200, Iteration 24/25, Loss: 0.1715\n",
      "Epoch 2/200, Iteration 25/25, Loss: 0.1832\n",
      "Train Error: \n",
      " Accuracy: 52.88%, Avg loss: 0.115392, MRE: 5.222447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.119040, MRE: 15.803632 \n",
      "\n",
      "Epoch 3/200, Iteration 1/25, Loss: 0.1094\n",
      "Epoch 3/200, Iteration 2/25, Loss: 0.1401\n",
      "Epoch 3/200, Iteration 3/25, Loss: 0.1222\n",
      "Epoch 3/200, Iteration 4/25, Loss: 0.2106\n",
      "Epoch 3/200, Iteration 5/25, Loss: 0.1432\n",
      "Epoch 3/200, Iteration 6/25, Loss: 0.0661\n",
      "Epoch 3/200, Iteration 7/25, Loss: 0.1220\n",
      "Epoch 3/200, Iteration 8/25, Loss: 0.1561\n",
      "Epoch 3/200, Iteration 9/25, Loss: 0.1228\n",
      "Epoch 3/200, Iteration 10/25, Loss: 0.0663\n",
      "Epoch 3/200, Iteration 11/25, Loss: 0.1190\n",
      "Epoch 3/200, Iteration 12/25, Loss: 0.1367\n",
      "Epoch 3/200, Iteration 13/25, Loss: 0.1358\n",
      "Epoch 3/200, Iteration 14/25, Loss: 0.0863\n",
      "Epoch 3/200, Iteration 15/25, Loss: 0.0895\n",
      "Epoch 3/200, Iteration 16/25, Loss: 0.1220\n",
      "Epoch 3/200, Iteration 17/25, Loss: 0.1671\n",
      "Epoch 3/200, Iteration 18/25, Loss: 0.0763\n",
      "Epoch 3/200, Iteration 19/25, Loss: 0.1904\n",
      "Epoch 3/200, Iteration 20/25, Loss: 0.1922\n",
      "Epoch 3/200, Iteration 21/25, Loss: 0.1145\n",
      "Epoch 3/200, Iteration 22/25, Loss: 0.2172\n",
      "Epoch 3/200, Iteration 23/25, Loss: 0.2442\n",
      "Epoch 3/200, Iteration 24/25, Loss: 0.0801\n",
      "Epoch 3/200, Iteration 25/25, Loss: 0.1825\n",
      "Train Error: \n",
      " Accuracy: 46.75%, Avg loss: 0.241265, MRE: 16.497091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.229032, MRE: 32.317204 \n",
      "\n",
      "Epoch 4/200, Iteration 1/25, Loss: 0.2847\n",
      "Epoch 4/200, Iteration 2/25, Loss: 0.1196\n",
      "Epoch 4/200, Iteration 3/25, Loss: 0.1691\n",
      "Epoch 4/200, Iteration 4/25, Loss: 0.1952\n",
      "Epoch 4/200, Iteration 5/25, Loss: 0.0618\n",
      "Epoch 4/200, Iteration 6/25, Loss: 0.1584\n",
      "Epoch 4/200, Iteration 7/25, Loss: 0.2113\n",
      "Epoch 4/200, Iteration 8/25, Loss: 0.1530\n",
      "Epoch 4/200, Iteration 9/25, Loss: 0.1567\n",
      "Epoch 4/200, Iteration 10/25, Loss: 0.2727\n",
      "Epoch 4/200, Iteration 11/25, Loss: 0.1724\n",
      "Epoch 4/200, Iteration 12/25, Loss: 0.0930\n",
      "Epoch 4/200, Iteration 13/25, Loss: 0.1460\n",
      "Epoch 4/200, Iteration 14/25, Loss: 0.1823\n",
      "Epoch 4/200, Iteration 15/25, Loss: 0.1002\n",
      "Epoch 4/200, Iteration 16/25, Loss: 0.1426\n",
      "Epoch 4/200, Iteration 17/25, Loss: 0.1653\n",
      "Epoch 4/200, Iteration 18/25, Loss: 0.1403\n",
      "Epoch 4/200, Iteration 19/25, Loss: 0.0884\n",
      "Epoch 4/200, Iteration 20/25, Loss: 0.1309\n",
      "Epoch 4/200, Iteration 21/25, Loss: 0.1105\n",
      "Epoch 4/200, Iteration 22/25, Loss: 0.0598\n",
      "Epoch 4/200, Iteration 23/25, Loss: 0.1332\n",
      "Epoch 4/200, Iteration 24/25, Loss: 0.1095\n",
      "Epoch 4/200, Iteration 25/25, Loss: 0.0625\n",
      "Train Error: \n",
      " Accuracy: 56.25%, Avg loss: 0.118120, MRE: 7.300960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.119756, MRE: 7.883765 \n",
      "\n",
      "Epoch 5/200, Iteration 1/25, Loss: 0.1033\n",
      "Epoch 5/200, Iteration 2/25, Loss: 0.0680\n",
      "Epoch 5/200, Iteration 3/25, Loss: 0.0432\n",
      "Epoch 5/200, Iteration 4/25, Loss: 0.0570\n",
      "Epoch 5/200, Iteration 5/25, Loss: 0.0527\n",
      "Epoch 5/200, Iteration 6/25, Loss: 0.0584\n",
      "Epoch 5/200, Iteration 7/25, Loss: 0.0552\n",
      "Epoch 5/200, Iteration 8/25, Loss: 0.0594\n",
      "Epoch 5/200, Iteration 9/25, Loss: 0.0549\n",
      "Epoch 5/200, Iteration 10/25, Loss: 0.0572\n",
      "Epoch 5/200, Iteration 11/25, Loss: 0.0504\n",
      "Epoch 5/200, Iteration 12/25, Loss: 0.0789\n",
      "Epoch 5/200, Iteration 13/25, Loss: 0.0384\n",
      "Epoch 5/200, Iteration 14/25, Loss: 0.0600\n",
      "Epoch 5/200, Iteration 15/25, Loss: 0.0627\n",
      "Epoch 5/200, Iteration 16/25, Loss: 0.0370\n",
      "Epoch 5/200, Iteration 17/25, Loss: 0.0820\n",
      "Epoch 5/200, Iteration 18/25, Loss: 0.0950\n",
      "Epoch 5/200, Iteration 19/25, Loss: 0.0498\n",
      "Epoch 5/200, Iteration 20/25, Loss: 0.0840\n",
      "Epoch 5/200, Iteration 21/25, Loss: 0.0948\n",
      "Epoch 5/200, Iteration 22/25, Loss: 0.0692\n",
      "Epoch 5/200, Iteration 23/25, Loss: 0.0897\n",
      "Epoch 5/200, Iteration 24/25, Loss: 0.0887\n",
      "Epoch 5/200, Iteration 25/25, Loss: 0.0467\n",
      "Train Error: \n",
      " Accuracy: 51.88%, Avg loss: 0.088090, MRE: 5.994405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 0.091122, MRE: 10.875279 \n",
      "\n",
      "Epoch 6/200, Iteration 1/25, Loss: 0.0922\n",
      "Epoch 6/200, Iteration 2/25, Loss: 0.0811\n",
      "Epoch 6/200, Iteration 3/25, Loss: 0.0489\n",
      "Epoch 6/200, Iteration 4/25, Loss: 0.0676\n",
      "Epoch 6/200, Iteration 5/25, Loss: 0.0581\n",
      "Epoch 6/200, Iteration 6/25, Loss: 0.0772\n",
      "Epoch 6/200, Iteration 7/25, Loss: 0.0694\n",
      "Epoch 6/200, Iteration 8/25, Loss: 0.0633\n",
      "Epoch 6/200, Iteration 9/25, Loss: 0.0629\n",
      "Epoch 6/200, Iteration 10/25, Loss: 0.0580\n",
      "Epoch 6/200, Iteration 11/25, Loss: 0.0614\n",
      "Epoch 6/200, Iteration 12/25, Loss: 0.0483\n",
      "Epoch 6/200, Iteration 13/25, Loss: 0.0740\n",
      "Epoch 6/200, Iteration 14/25, Loss: 0.0520\n",
      "Epoch 6/200, Iteration 15/25, Loss: 0.0400\n",
      "Epoch 6/200, Iteration 16/25, Loss: 0.0740\n",
      "Epoch 6/200, Iteration 17/25, Loss: 0.0392\n",
      "Epoch 6/200, Iteration 18/25, Loss: 0.0545\n",
      "Epoch 6/200, Iteration 19/25, Loss: 0.0542\n",
      "Epoch 6/200, Iteration 20/25, Loss: 0.0507\n",
      "Epoch 6/200, Iteration 21/25, Loss: 0.0908\n",
      "Epoch 6/200, Iteration 22/25, Loss: 0.1324\n",
      "Epoch 6/200, Iteration 23/25, Loss: 0.0818\n",
      "Epoch 6/200, Iteration 24/25, Loss: 0.0353\n",
      "Epoch 6/200, Iteration 25/25, Loss: 0.0928\n",
      "Train Error: \n",
      " Accuracy: 50.75%, Avg loss: 0.097500, MRE: 5.641391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.099726, MRE: 17.165851 \n",
      "\n",
      "Epoch 7/200, Iteration 1/25, Loss: 0.0953\n",
      "Epoch 7/200, Iteration 2/25, Loss: 0.0959\n",
      "Epoch 7/200, Iteration 3/25, Loss: 0.0799\n",
      "Epoch 7/200, Iteration 4/25, Loss: 0.0669\n",
      "Epoch 7/200, Iteration 5/25, Loss: 0.0816\n",
      "Epoch 7/200, Iteration 6/25, Loss: 0.0915\n",
      "Epoch 7/200, Iteration 7/25, Loss: 0.0609\n",
      "Epoch 7/200, Iteration 8/25, Loss: 0.0454\n",
      "Epoch 7/200, Iteration 9/25, Loss: 0.0753\n",
      "Epoch 7/200, Iteration 10/25, Loss: 0.0758\n",
      "Epoch 7/200, Iteration 11/25, Loss: 0.0522\n",
      "Epoch 7/200, Iteration 12/25, Loss: 0.0376\n",
      "Epoch 7/200, Iteration 13/25, Loss: 0.0628\n",
      "Epoch 7/200, Iteration 14/25, Loss: 0.0640\n",
      "Epoch 7/200, Iteration 15/25, Loss: 0.0564\n",
      "Epoch 7/200, Iteration 16/25, Loss: 0.0730\n",
      "Epoch 7/200, Iteration 17/25, Loss: 0.0633\n",
      "Epoch 7/200, Iteration 18/25, Loss: 0.0889\n",
      "Epoch 7/200, Iteration 19/25, Loss: 0.0522\n",
      "Epoch 7/200, Iteration 20/25, Loss: 0.0630\n",
      "Epoch 7/200, Iteration 21/25, Loss: 0.0672\n",
      "Epoch 7/200, Iteration 22/25, Loss: 0.0853\n",
      "Epoch 7/200, Iteration 23/25, Loss: 0.0460\n",
      "Epoch 7/200, Iteration 24/25, Loss: 0.0511\n",
      "Epoch 7/200, Iteration 25/25, Loss: 0.0695\n",
      "Train Error: \n",
      " Accuracy: 63.12%, Avg loss: 0.045426, MRE: 2.255871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.047693, MRE: 5.777229 \n",
      "\n",
      "Epoch 8/200, Iteration 1/25, Loss: 0.0444\n",
      "Epoch 8/200, Iteration 2/25, Loss: 0.0529\n",
      "Epoch 8/200, Iteration 3/25, Loss: 0.0568\n",
      "Epoch 8/200, Iteration 4/25, Loss: 0.0479\n",
      "Epoch 8/200, Iteration 5/25, Loss: 0.0340\n",
      "Epoch 8/200, Iteration 6/25, Loss: 0.0613\n",
      "Epoch 8/200, Iteration 7/25, Loss: 0.0515\n",
      "Epoch 8/200, Iteration 8/25, Loss: 0.0466\n",
      "Epoch 8/200, Iteration 9/25, Loss: 0.0563\n",
      "Epoch 8/200, Iteration 10/25, Loss: 0.0543\n",
      "Epoch 8/200, Iteration 11/25, Loss: 0.0716\n",
      "Epoch 8/200, Iteration 12/25, Loss: 0.0794\n",
      "Epoch 8/200, Iteration 13/25, Loss: 0.0299\n",
      "Epoch 8/200, Iteration 14/25, Loss: 0.0664\n",
      "Epoch 8/200, Iteration 15/25, Loss: 0.0420\n",
      "Epoch 8/200, Iteration 16/25, Loss: 0.0499\n",
      "Epoch 8/200, Iteration 17/25, Loss: 0.0556\n",
      "Epoch 8/200, Iteration 18/25, Loss: 0.0583\n",
      "Epoch 8/200, Iteration 19/25, Loss: 0.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 20/25, Loss: 0.0359\n",
      "Epoch 8/200, Iteration 21/25, Loss: 0.0343\n",
      "Epoch 8/200, Iteration 22/25, Loss: 0.0369\n",
      "Epoch 8/200, Iteration 23/25, Loss: 0.0347\n",
      "Epoch 8/200, Iteration 24/25, Loss: 0.0378\n",
      "Epoch 8/200, Iteration 25/25, Loss: 0.0379\n",
      "Train Error: \n",
      " Accuracy: 68.25%, Avg loss: 0.032861, MRE: 2.275302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.034505, MRE: 6.741541 \n",
      "\n",
      "Epoch 9/200, Iteration 1/25, Loss: 0.0353\n",
      "Epoch 9/200, Iteration 2/25, Loss: 0.0283\n",
      "Epoch 9/200, Iteration 3/25, Loss: 0.0507\n",
      "Epoch 9/200, Iteration 4/25, Loss: 0.0583\n",
      "Epoch 9/200, Iteration 5/25, Loss: 0.0414\n",
      "Epoch 9/200, Iteration 6/25, Loss: 0.0648\n",
      "Epoch 9/200, Iteration 7/25, Loss: 0.0491\n",
      "Epoch 9/200, Iteration 8/25, Loss: 0.0688\n",
      "Epoch 9/200, Iteration 9/25, Loss: 0.0765\n",
      "Epoch 9/200, Iteration 10/25, Loss: 0.0614\n",
      "Epoch 9/200, Iteration 11/25, Loss: 0.0579\n",
      "Epoch 9/200, Iteration 12/25, Loss: 0.0518\n",
      "Epoch 9/200, Iteration 13/25, Loss: 0.0509\n",
      "Epoch 9/200, Iteration 14/25, Loss: 0.0730\n",
      "Epoch 9/200, Iteration 15/25, Loss: 0.0644\n",
      "Epoch 9/200, Iteration 16/25, Loss: 0.0582\n",
      "Epoch 9/200, Iteration 17/25, Loss: 0.0778\n",
      "Epoch 9/200, Iteration 18/25, Loss: 0.0714\n",
      "Epoch 9/200, Iteration 19/25, Loss: 0.0304\n",
      "Epoch 9/200, Iteration 20/25, Loss: 0.0730\n",
      "Epoch 9/200, Iteration 21/25, Loss: 0.0523\n",
      "Epoch 9/200, Iteration 22/25, Loss: 0.0305\n",
      "Epoch 9/200, Iteration 23/25, Loss: 0.0578\n",
      "Epoch 9/200, Iteration 24/25, Loss: 0.0567\n",
      "Epoch 9/200, Iteration 25/25, Loss: 0.0263\n",
      "Train Error: \n",
      " Accuracy: 75.75%, Avg loss: 0.047559, MRE: 3.184934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.049274, MRE: 9.582183 \n",
      "\n",
      "Epoch 10/200, Iteration 1/25, Loss: 0.0474\n",
      "Epoch 10/200, Iteration 2/25, Loss: 0.0487\n",
      "Epoch 10/200, Iteration 3/25, Loss: 0.0710\n",
      "Epoch 10/200, Iteration 4/25, Loss: 0.0497\n",
      "Epoch 10/200, Iteration 5/25, Loss: 0.0770\n",
      "Epoch 10/200, Iteration 6/25, Loss: 0.0622\n",
      "Epoch 10/200, Iteration 7/25, Loss: 0.0647\n",
      "Epoch 10/200, Iteration 8/25, Loss: 0.0772\n",
      "Epoch 10/200, Iteration 9/25, Loss: 0.0394\n",
      "Epoch 10/200, Iteration 10/25, Loss: 0.0788\n",
      "Epoch 10/200, Iteration 11/25, Loss: 0.0762\n",
      "Epoch 10/200, Iteration 12/25, Loss: 0.0313\n",
      "Epoch 10/200, Iteration 13/25, Loss: 0.0379\n",
      "Epoch 10/200, Iteration 14/25, Loss: 0.0442\n",
      "Epoch 10/200, Iteration 15/25, Loss: 0.0331\n",
      "Epoch 10/200, Iteration 16/25, Loss: 0.0421\n",
      "Epoch 10/200, Iteration 17/25, Loss: 0.0296\n",
      "Epoch 10/200, Iteration 18/25, Loss: 0.0273\n",
      "Epoch 10/200, Iteration 19/25, Loss: 0.0552\n",
      "Epoch 10/200, Iteration 20/25, Loss: 0.0407\n",
      "Epoch 10/200, Iteration 21/25, Loss: 0.0621\n",
      "Epoch 10/200, Iteration 22/25, Loss: 0.0509\n",
      "Epoch 10/200, Iteration 23/25, Loss: 0.0528\n",
      "Epoch 10/200, Iteration 24/25, Loss: 0.0513\n",
      "Epoch 10/200, Iteration 25/25, Loss: 0.0470\n",
      "Train Error: \n",
      " Accuracy: 62.12%, Avg loss: 0.037390, MRE: 2.123023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.039769, MRE: 2.165040 \n",
      "\n",
      "Epoch 11/200, Iteration 1/25, Loss: 0.0367\n",
      "Epoch 11/200, Iteration 2/25, Loss: 0.0353\n",
      "Epoch 11/200, Iteration 3/25, Loss: 0.0473\n",
      "Epoch 11/200, Iteration 4/25, Loss: 0.0421\n",
      "Epoch 11/200, Iteration 5/25, Loss: 0.0483\n",
      "Epoch 11/200, Iteration 6/25, Loss: 0.0472\n",
      "Epoch 11/200, Iteration 7/25, Loss: 0.0446\n",
      "Epoch 11/200, Iteration 8/25, Loss: 0.0466\n",
      "Epoch 11/200, Iteration 9/25, Loss: 0.0481\n",
      "Epoch 11/200, Iteration 10/25, Loss: 0.0611\n",
      "Epoch 11/200, Iteration 11/25, Loss: 0.0406\n",
      "Epoch 11/200, Iteration 12/25, Loss: 0.0545\n",
      "Epoch 11/200, Iteration 13/25, Loss: 0.0364\n",
      "Epoch 11/200, Iteration 14/25, Loss: 0.0384\n",
      "Epoch 11/200, Iteration 15/25, Loss: 0.0554\n",
      "Epoch 11/200, Iteration 16/25, Loss: 0.0399\n",
      "Epoch 11/200, Iteration 17/25, Loss: 0.0526\n",
      "Epoch 11/200, Iteration 18/25, Loss: 0.0632\n",
      "Epoch 11/200, Iteration 19/25, Loss: 0.0527\n",
      "Epoch 11/200, Iteration 20/25, Loss: 0.0541\n",
      "Epoch 11/200, Iteration 21/25, Loss: 0.0600\n",
      "Epoch 11/200, Iteration 22/25, Loss: 0.0479\n",
      "Epoch 11/200, Iteration 23/25, Loss: 0.0584\n",
      "Epoch 11/200, Iteration 24/25, Loss: 0.0807\n",
      "Epoch 11/200, Iteration 25/25, Loss: 0.0656\n",
      "Train Error: \n",
      " Accuracy: 65.88%, Avg loss: 0.028606, MRE: 1.774723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.029745, MRE: 5.383109 \n",
      "\n",
      "Epoch 12/200, Iteration 1/25, Loss: 0.0334\n",
      "Epoch 12/200, Iteration 2/25, Loss: 0.0504\n",
      "Epoch 12/200, Iteration 3/25, Loss: 0.0565\n",
      "Epoch 12/200, Iteration 4/25, Loss: 0.0830\n",
      "Epoch 12/200, Iteration 5/25, Loss: 0.0512\n",
      "Epoch 12/200, Iteration 6/25, Loss: 0.0734\n",
      "Epoch 12/200, Iteration 7/25, Loss: 0.0556\n",
      "Epoch 12/200, Iteration 8/25, Loss: 0.0750\n",
      "Epoch 12/200, Iteration 9/25, Loss: 0.1011\n",
      "Epoch 12/200, Iteration 10/25, Loss: 0.0605\n",
      "Epoch 12/200, Iteration 11/25, Loss: 0.1003\n",
      "Epoch 12/200, Iteration 12/25, Loss: 0.0895\n",
      "Epoch 12/200, Iteration 13/25, Loss: 0.0583\n",
      "Epoch 12/200, Iteration 14/25, Loss: 0.0997\n",
      "Epoch 12/200, Iteration 15/25, Loss: 0.0646\n",
      "Epoch 12/200, Iteration 16/25, Loss: 0.0910\n",
      "Epoch 12/200, Iteration 17/25, Loss: 0.0993\n",
      "Epoch 12/200, Iteration 18/25, Loss: 0.0512\n",
      "Epoch 12/200, Iteration 19/25, Loss: 0.0945\n",
      "Epoch 12/200, Iteration 20/25, Loss: 0.0915\n",
      "Epoch 12/200, Iteration 21/25, Loss: 0.0357\n",
      "Epoch 12/200, Iteration 22/25, Loss: 0.0712\n",
      "Epoch 12/200, Iteration 23/25, Loss: 0.0609\n",
      "Epoch 12/200, Iteration 24/25, Loss: 0.0962\n",
      "Epoch 12/200, Iteration 25/25, Loss: 0.1587\n",
      "Train Error: \n",
      " Accuracy: 49.38%, Avg loss: 0.084203, MRE: 4.633344 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.082189, MRE: 19.224730 \n",
      "\n",
      "Epoch 13/200, Iteration 1/25, Loss: 0.0871\n",
      "Epoch 13/200, Iteration 2/25, Loss: 0.0831\n",
      "Epoch 13/200, Iteration 3/25, Loss: 0.1482\n",
      "Epoch 13/200, Iteration 4/25, Loss: 0.0906\n",
      "Epoch 13/200, Iteration 5/25, Loss: 0.0692\n",
      "Epoch 13/200, Iteration 6/25, Loss: 0.1093\n",
      "Epoch 13/200, Iteration 7/25, Loss: 0.1476\n",
      "Epoch 13/200, Iteration 8/25, Loss: 0.0867\n",
      "Epoch 13/200, Iteration 9/25, Loss: 0.0732\n",
      "Epoch 13/200, Iteration 10/25, Loss: 0.0840\n",
      "Epoch 13/200, Iteration 11/25, Loss: 0.0882\n",
      "Epoch 13/200, Iteration 12/25, Loss: 0.1170\n",
      "Epoch 13/200, Iteration 13/25, Loss: 0.0926\n",
      "Epoch 13/200, Iteration 14/25, Loss: 0.1002\n",
      "Epoch 13/200, Iteration 15/25, Loss: 0.1058\n",
      "Epoch 13/200, Iteration 16/25, Loss: 0.0794\n",
      "Epoch 13/200, Iteration 17/25, Loss: 0.0856\n",
      "Epoch 13/200, Iteration 18/25, Loss: 0.0882\n",
      "Epoch 13/200, Iteration 19/25, Loss: 0.1049\n",
      "Epoch 13/200, Iteration 20/25, Loss: 0.0737\n",
      "Epoch 13/200, Iteration 21/25, Loss: 0.0891\n",
      "Epoch 13/200, Iteration 22/25, Loss: 0.0753\n",
      "Epoch 13/200, Iteration 23/25, Loss: 0.0551\n",
      "Epoch 13/200, Iteration 24/25, Loss: 0.0623\n",
      "Epoch 13/200, Iteration 25/25, Loss: 0.0552\n",
      "Train Error: \n",
      " Accuracy: 62.38%, Avg loss: 0.061420, MRE: 3.646552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.056448, MRE: 6.754800 \n",
      "\n",
      "Epoch 14/200, Iteration 1/25, Loss: 0.0479\n",
      "Epoch 14/200, Iteration 2/25, Loss: 0.0684\n",
      "Epoch 14/200, Iteration 3/25, Loss: 0.0659\n",
      "Epoch 14/200, Iteration 4/25, Loss: 0.0685\n",
      "Epoch 14/200, Iteration 5/25, Loss: 0.0504\n",
      "Epoch 14/200, Iteration 6/25, Loss: 0.0481\n",
      "Epoch 14/200, Iteration 7/25, Loss: 0.0373\n",
      "Epoch 14/200, Iteration 8/25, Loss: 0.0341\n",
      "Epoch 14/200, Iteration 9/25, Loss: 0.0560\n",
      "Epoch 14/200, Iteration 10/25, Loss: 0.0468\n",
      "Epoch 14/200, Iteration 11/25, Loss: 0.0226\n",
      "Epoch 14/200, Iteration 12/25, Loss: 0.0483\n",
      "Epoch 14/200, Iteration 13/25, Loss: 0.0419\n",
      "Epoch 14/200, Iteration 14/25, Loss: 0.0353\n",
      "Epoch 14/200, Iteration 15/25, Loss: 0.0455\n",
      "Epoch 14/200, Iteration 16/25, Loss: 0.0463\n",
      "Epoch 14/200, Iteration 17/25, Loss: 0.0437\n",
      "Epoch 14/200, Iteration 18/25, Loss: 0.0675\n",
      "Epoch 14/200, Iteration 19/25, Loss: 0.0498\n",
      "Epoch 14/200, Iteration 20/25, Loss: 0.0257\n",
      "Epoch 14/200, Iteration 21/25, Loss: 0.0489\n",
      "Epoch 14/200, Iteration 22/25, Loss: 0.0357\n",
      "Epoch 14/200, Iteration 23/25, Loss: 0.0565\n",
      "Epoch 14/200, Iteration 24/25, Loss: 0.0684\n",
      "Epoch 14/200, Iteration 25/25, Loss: 0.0581\n",
      "Train Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.046201, MRE: 1.958128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.044056, MRE: 2.200982 \n",
      "\n",
      "Epoch 15/200, Iteration 1/25, Loss: 0.0440\n",
      "Epoch 15/200, Iteration 2/25, Loss: 0.0370\n",
      "Epoch 15/200, Iteration 3/25, Loss: 0.0477\n",
      "Epoch 15/200, Iteration 4/25, Loss: 0.0381\n",
      "Epoch 15/200, Iteration 5/25, Loss: 0.0345\n",
      "Epoch 15/200, Iteration 6/25, Loss: 0.0514\n",
      "Epoch 15/200, Iteration 7/25, Loss: 0.0324\n",
      "Epoch 15/200, Iteration 8/25, Loss: 0.0522\n",
      "Epoch 15/200, Iteration 9/25, Loss: 0.0549\n",
      "Epoch 15/200, Iteration 10/25, Loss: 0.0363\n",
      "Epoch 15/200, Iteration 11/25, Loss: 0.0598\n",
      "Epoch 15/200, Iteration 12/25, Loss: 0.0974\n",
      "Epoch 15/200, Iteration 13/25, Loss: 0.0373\n",
      "Epoch 15/200, Iteration 14/25, Loss: 0.0358\n",
      "Epoch 15/200, Iteration 15/25, Loss: 0.0910\n",
      "Epoch 15/200, Iteration 16/25, Loss: 0.0880\n",
      "Epoch 15/200, Iteration 17/25, Loss: 0.0481\n",
      "Epoch 15/200, Iteration 18/25, Loss: 0.0504\n",
      "Epoch 15/200, Iteration 19/25, Loss: 0.0449\n",
      "Epoch 15/200, Iteration 20/25, Loss: 0.0479\n",
      "Epoch 15/200, Iteration 21/25, Loss: 0.0500\n",
      "Epoch 15/200, Iteration 22/25, Loss: 0.0463\n",
      "Epoch 15/200, Iteration 23/25, Loss: 0.0577\n",
      "Epoch 15/200, Iteration 24/25, Loss: 0.0342\n",
      "Epoch 15/200, Iteration 25/25, Loss: 0.0480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.035495, MRE: 1.788489 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.039538, MRE: 3.434883 \n",
      "\n",
      "Epoch 16/200, Iteration 1/25, Loss: 0.0245\n",
      "Epoch 16/200, Iteration 2/25, Loss: 0.0455\n",
      "Epoch 16/200, Iteration 3/25, Loss: 0.0592\n",
      "Epoch 16/200, Iteration 4/25, Loss: 0.0579\n",
      "Epoch 16/200, Iteration 5/25, Loss: 0.0448\n",
      "Epoch 16/200, Iteration 6/25, Loss: 0.0352\n",
      "Epoch 16/200, Iteration 7/25, Loss: 0.0453\n",
      "Epoch 16/200, Iteration 8/25, Loss: 0.0635\n",
      "Epoch 16/200, Iteration 9/25, Loss: 0.0533\n",
      "Epoch 16/200, Iteration 10/25, Loss: 0.0335\n",
      "Epoch 16/200, Iteration 11/25, Loss: 0.0571\n",
      "Epoch 16/200, Iteration 12/25, Loss: 0.0440\n",
      "Epoch 16/200, Iteration 13/25, Loss: 0.0373\n",
      "Epoch 16/200, Iteration 14/25, Loss: 0.0476\n",
      "Epoch 16/200, Iteration 15/25, Loss: 0.0333\n",
      "Epoch 16/200, Iteration 16/25, Loss: 0.0410\n",
      "Epoch 16/200, Iteration 17/25, Loss: 0.0451\n",
      "Epoch 16/200, Iteration 18/25, Loss: 0.0504\n",
      "Epoch 16/200, Iteration 19/25, Loss: 0.0471\n",
      "Epoch 16/200, Iteration 20/25, Loss: 0.0413\n",
      "Epoch 16/200, Iteration 21/25, Loss: 0.0355\n",
      "Epoch 16/200, Iteration 22/25, Loss: 0.0289\n",
      "Epoch 16/200, Iteration 23/25, Loss: 0.0378\n",
      "Epoch 16/200, Iteration 24/25, Loss: 0.0373\n",
      "Epoch 16/200, Iteration 25/25, Loss: 0.0333\n",
      "Train Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.055689, MRE: 2.270095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 0.057581, MRE: 6.818604 \n",
      "\n",
      "Epoch 17/200, Iteration 1/25, Loss: 0.0513\n",
      "Epoch 17/200, Iteration 2/25, Loss: 0.0245\n",
      "Epoch 17/200, Iteration 3/25, Loss: 0.0640\n",
      "Epoch 17/200, Iteration 4/25, Loss: 0.0528\n",
      "Epoch 17/200, Iteration 5/25, Loss: 0.0483\n",
      "Epoch 17/200, Iteration 6/25, Loss: 0.0382\n",
      "Epoch 17/200, Iteration 7/25, Loss: 0.0528\n",
      "Epoch 17/200, Iteration 8/25, Loss: 0.0495\n",
      "Epoch 17/200, Iteration 9/25, Loss: 0.0533\n",
      "Epoch 17/200, Iteration 10/25, Loss: 0.0526\n",
      "Epoch 17/200, Iteration 11/25, Loss: 0.0385\n",
      "Epoch 17/200, Iteration 12/25, Loss: 0.0491\n",
      "Epoch 17/200, Iteration 13/25, Loss: 0.0563\n",
      "Epoch 17/200, Iteration 14/25, Loss: 0.0394\n",
      "Epoch 17/200, Iteration 15/25, Loss: 0.0479\n",
      "Epoch 17/200, Iteration 16/25, Loss: 0.0551\n",
      "Epoch 17/200, Iteration 17/25, Loss: 0.0403\n",
      "Epoch 17/200, Iteration 18/25, Loss: 0.0576\n",
      "Epoch 17/200, Iteration 19/25, Loss: 0.0715\n",
      "Epoch 17/200, Iteration 20/25, Loss: 0.0550\n",
      "Epoch 17/200, Iteration 21/25, Loss: 0.0584\n",
      "Epoch 17/200, Iteration 22/25, Loss: 0.0607\n",
      "Epoch 17/200, Iteration 23/25, Loss: 0.0558\n",
      "Epoch 17/200, Iteration 24/25, Loss: 0.0478\n",
      "Epoch 17/200, Iteration 25/25, Loss: 0.0479\n",
      "Train Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.034181, MRE: 1.999481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 0.036310, MRE: 3.109990 \n",
      "\n",
      "Epoch 18/200, Iteration 1/25, Loss: 0.0454\n",
      "Epoch 18/200, Iteration 2/25, Loss: 0.0408\n",
      "Epoch 18/200, Iteration 3/25, Loss: 0.0479\n",
      "Epoch 18/200, Iteration 4/25, Loss: 0.0710\n",
      "Epoch 18/200, Iteration 5/25, Loss: 0.0499\n",
      "Epoch 18/200, Iteration 6/25, Loss: 0.0557\n",
      "Epoch 18/200, Iteration 7/25, Loss: 0.0452\n",
      "Epoch 18/200, Iteration 8/25, Loss: 0.0705\n",
      "Epoch 18/200, Iteration 9/25, Loss: 0.0541\n",
      "Epoch 18/200, Iteration 10/25, Loss: 0.0483\n",
      "Epoch 18/200, Iteration 11/25, Loss: 0.0882\n",
      "Epoch 18/200, Iteration 12/25, Loss: 0.0743\n",
      "Epoch 18/200, Iteration 13/25, Loss: 0.0769\n",
      "Epoch 18/200, Iteration 14/25, Loss: 0.0362\n",
      "Epoch 18/200, Iteration 15/25, Loss: 0.0626\n",
      "Epoch 18/200, Iteration 16/25, Loss: 0.1021\n",
      "Epoch 18/200, Iteration 17/25, Loss: 0.0774\n",
      "Epoch 18/200, Iteration 18/25, Loss: 0.0492\n",
      "Epoch 18/200, Iteration 19/25, Loss: 0.0553\n",
      "Epoch 18/200, Iteration 20/25, Loss: 0.0638\n",
      "Epoch 18/200, Iteration 21/25, Loss: 0.0651\n",
      "Epoch 18/200, Iteration 22/25, Loss: 0.0435\n",
      "Epoch 18/200, Iteration 23/25, Loss: 0.0551\n",
      "Epoch 18/200, Iteration 24/25, Loss: 0.0716\n",
      "Epoch 18/200, Iteration 25/25, Loss: 0.0623\n",
      "Train Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.034979, MRE: 1.729816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.038838, MRE: 1.300507 \n",
      "\n",
      "Epoch 19/200, Iteration 1/25, Loss: 0.0282\n",
      "Epoch 19/200, Iteration 2/25, Loss: 0.0391\n",
      "Epoch 19/200, Iteration 3/25, Loss: 0.0556\n",
      "Epoch 19/200, Iteration 4/25, Loss: 0.0225\n",
      "Epoch 19/200, Iteration 5/25, Loss: 0.0297\n",
      "Epoch 19/200, Iteration 6/25, Loss: 0.0438\n",
      "Epoch 19/200, Iteration 7/25, Loss: 0.0471\n",
      "Epoch 19/200, Iteration 8/25, Loss: 0.0357\n",
      "Epoch 19/200, Iteration 9/25, Loss: 0.0249\n",
      "Epoch 19/200, Iteration 10/25, Loss: 0.0303\n",
      "Epoch 19/200, Iteration 11/25, Loss: 0.0484\n",
      "Epoch 19/200, Iteration 12/25, Loss: 0.0348\n",
      "Epoch 19/200, Iteration 13/25, Loss: 0.0438\n",
      "Epoch 19/200, Iteration 14/25, Loss: 0.0386\n",
      "Epoch 19/200, Iteration 15/25, Loss: 0.0383\n",
      "Epoch 19/200, Iteration 16/25, Loss: 0.0495\n",
      "Epoch 19/200, Iteration 17/25, Loss: 0.0502\n",
      "Epoch 19/200, Iteration 18/25, Loss: 0.0489\n",
      "Epoch 19/200, Iteration 19/25, Loss: 0.0429\n",
      "Epoch 19/200, Iteration 20/25, Loss: 0.0584\n",
      "Epoch 19/200, Iteration 21/25, Loss: 0.0580\n",
      "Epoch 19/200, Iteration 22/25, Loss: 0.0530\n",
      "Epoch 19/200, Iteration 23/25, Loss: 0.0711\n",
      "Epoch 19/200, Iteration 24/25, Loss: 0.0672\n",
      "Epoch 19/200, Iteration 25/25, Loss: 0.0390\n",
      "Train Error: \n",
      " Accuracy: 79.88%, Avg loss: 0.034382, MRE: 2.411558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.036094, MRE: 7.600893 \n",
      "\n",
      "Epoch 20/200, Iteration 1/25, Loss: 0.0400\n",
      "Epoch 20/200, Iteration 2/25, Loss: 0.0265\n",
      "Epoch 20/200, Iteration 3/25, Loss: 0.0288\n",
      "Epoch 20/200, Iteration 4/25, Loss: 0.0323\n",
      "Epoch 20/200, Iteration 5/25, Loss: 0.0375\n",
      "Epoch 20/200, Iteration 6/25, Loss: 0.0447\n",
      "Epoch 20/200, Iteration 7/25, Loss: 0.0383\n",
      "Epoch 20/200, Iteration 8/25, Loss: 0.0287\n",
      "Epoch 20/200, Iteration 9/25, Loss: 0.0533\n",
      "Epoch 20/200, Iteration 10/25, Loss: 0.0443\n",
      "Epoch 20/200, Iteration 11/25, Loss: 0.0261\n",
      "Epoch 20/200, Iteration 12/25, Loss: 0.0310\n",
      "Epoch 20/200, Iteration 13/25, Loss: 0.0306\n",
      "Epoch 20/200, Iteration 14/25, Loss: 0.0290\n",
      "Epoch 20/200, Iteration 15/25, Loss: 0.0251\n",
      "Epoch 20/200, Iteration 16/25, Loss: 0.0480\n",
      "Epoch 20/200, Iteration 17/25, Loss: 0.0352\n",
      "Epoch 20/200, Iteration 18/25, Loss: 0.0319\n",
      "Epoch 20/200, Iteration 19/25, Loss: 0.0296\n",
      "Epoch 20/200, Iteration 20/25, Loss: 0.0517\n",
      "Epoch 20/200, Iteration 21/25, Loss: 0.0368\n",
      "Epoch 20/200, Iteration 22/25, Loss: 0.0490\n",
      "Epoch 20/200, Iteration 23/25, Loss: 0.0331\n",
      "Epoch 20/200, Iteration 24/25, Loss: 0.0324\n",
      "Epoch 20/200, Iteration 25/25, Loss: 0.0627\n",
      "Train Error: \n",
      " Accuracy: 47.88%, Avg loss: 0.067046, MRE: 4.066586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.067981, MRE: 4.179776 \n",
      "\n",
      "Epoch 21/200, Iteration 1/25, Loss: 0.0667\n",
      "Epoch 21/200, Iteration 2/25, Loss: 0.0832\n",
      "Epoch 21/200, Iteration 3/25, Loss: 0.0607\n",
      "Epoch 21/200, Iteration 4/25, Loss: 0.0442\n",
      "Epoch 21/200, Iteration 5/25, Loss: 0.0443\n",
      "Epoch 21/200, Iteration 6/25, Loss: 0.0242\n",
      "Epoch 21/200, Iteration 7/25, Loss: 0.0349\n",
      "Epoch 21/200, Iteration 8/25, Loss: 0.0456\n",
      "Epoch 21/200, Iteration 9/25, Loss: 0.0194\n",
      "Epoch 21/200, Iteration 10/25, Loss: 0.0376\n",
      "Epoch 21/200, Iteration 11/25, Loss: 0.0321\n",
      "Epoch 21/200, Iteration 12/25, Loss: 0.0354\n",
      "Epoch 21/200, Iteration 13/25, Loss: 0.0425\n",
      "Epoch 21/200, Iteration 14/25, Loss: 0.0380\n",
      "Epoch 21/200, Iteration 15/25, Loss: 0.0328\n",
      "Epoch 21/200, Iteration 16/25, Loss: 0.0315\n",
      "Epoch 21/200, Iteration 17/25, Loss: 0.0254\n",
      "Epoch 21/200, Iteration 18/25, Loss: 0.0281\n",
      "Epoch 21/200, Iteration 19/25, Loss: 0.0355\n",
      "Epoch 21/200, Iteration 20/25, Loss: 0.0325\n",
      "Epoch 21/200, Iteration 21/25, Loss: 0.0364\n",
      "Epoch 21/200, Iteration 22/25, Loss: 0.0365\n",
      "Epoch 21/200, Iteration 23/25, Loss: 0.0313\n",
      "Epoch 21/200, Iteration 24/25, Loss: 0.0282\n",
      "Epoch 21/200, Iteration 25/25, Loss: 0.0317\n",
      "Train Error: \n",
      " Accuracy: 50.12%, Avg loss: 0.028233, MRE: 2.218226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.033101, MRE: 7.539263 \n",
      "\n",
      "Epoch 22/200, Iteration 1/25, Loss: 0.0366\n",
      "Epoch 22/200, Iteration 2/25, Loss: 0.0250\n",
      "Epoch 22/200, Iteration 3/25, Loss: 0.0287\n",
      "Epoch 22/200, Iteration 4/25, Loss: 0.0233\n",
      "Epoch 22/200, Iteration 5/25, Loss: 0.0276\n",
      "Epoch 22/200, Iteration 6/25, Loss: 0.0315\n",
      "Epoch 22/200, Iteration 7/25, Loss: 0.0247\n",
      "Epoch 22/200, Iteration 8/25, Loss: 0.0236\n",
      "Epoch 22/200, Iteration 9/25, Loss: 0.0265\n",
      "Epoch 22/200, Iteration 10/25, Loss: 0.0390\n",
      "Epoch 22/200, Iteration 11/25, Loss: 0.0410\n",
      "Epoch 22/200, Iteration 12/25, Loss: 0.0375\n",
      "Epoch 22/200, Iteration 13/25, Loss: 0.0427\n",
      "Epoch 22/200, Iteration 14/25, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 15/25, Loss: 0.0254\n",
      "Epoch 22/200, Iteration 16/25, Loss: 0.0355\n",
      "Epoch 22/200, Iteration 17/25, Loss: 0.0289\n",
      "Epoch 22/200, Iteration 18/25, Loss: 0.0306\n",
      "Epoch 22/200, Iteration 19/25, Loss: 0.0437\n",
      "Epoch 22/200, Iteration 20/25, Loss: 0.0354\n",
      "Epoch 22/200, Iteration 21/25, Loss: 0.0274\n",
      "Epoch 22/200, Iteration 22/25, Loss: 0.0206\n",
      "Epoch 22/200, Iteration 23/25, Loss: 0.0300\n",
      "Epoch 22/200, Iteration 24/25, Loss: 0.0304\n",
      "Epoch 22/200, Iteration 25/25, Loss: 0.0271\n",
      "Train Error: \n",
      " Accuracy: 66.25%, Avg loss: 0.037017, MRE: 1.727583 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.038434, MRE: 7.611524 \n",
      "\n",
      "Epoch 23/200, Iteration 1/25, Loss: 0.0437\n",
      "Epoch 23/200, Iteration 2/25, Loss: 0.0378\n",
      "Epoch 23/200, Iteration 3/25, Loss: 0.0352\n",
      "Epoch 23/200, Iteration 4/25, Loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Iteration 5/25, Loss: 0.0430\n",
      "Epoch 23/200, Iteration 6/25, Loss: 0.0314\n",
      "Epoch 23/200, Iteration 7/25, Loss: 0.0397\n",
      "Epoch 23/200, Iteration 8/25, Loss: 0.0418\n",
      "Epoch 23/200, Iteration 9/25, Loss: 0.0420\n",
      "Epoch 23/200, Iteration 10/25, Loss: 0.0450\n",
      "Epoch 23/200, Iteration 11/25, Loss: 0.0311\n",
      "Epoch 23/200, Iteration 12/25, Loss: 0.0473\n",
      "Epoch 23/200, Iteration 13/25, Loss: 0.0647\n",
      "Epoch 23/200, Iteration 14/25, Loss: 0.0504\n",
      "Epoch 23/200, Iteration 15/25, Loss: 0.0250\n",
      "Epoch 23/200, Iteration 16/25, Loss: 0.0307\n",
      "Epoch 23/200, Iteration 17/25, Loss: 0.0395\n",
      "Epoch 23/200, Iteration 18/25, Loss: 0.0387\n",
      "Epoch 23/200, Iteration 19/25, Loss: 0.0361\n",
      "Epoch 23/200, Iteration 20/25, Loss: 0.0194\n",
      "Epoch 23/200, Iteration 21/25, Loss: 0.0262\n",
      "Epoch 23/200, Iteration 22/25, Loss: 0.0326\n",
      "Epoch 23/200, Iteration 23/25, Loss: 0.0316\n",
      "Epoch 23/200, Iteration 24/25, Loss: 0.0248\n",
      "Epoch 23/200, Iteration 25/25, Loss: 0.0540\n",
      "Train Error: \n",
      " Accuracy: 69.38%, Avg loss: 0.041289, MRE: 2.315426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.039952, MRE: 3.849005 \n",
      "\n",
      "Epoch 24/200, Iteration 1/25, Loss: 0.0450\n",
      "Epoch 24/200, Iteration 2/25, Loss: 0.0318\n",
      "Epoch 24/200, Iteration 3/25, Loss: 0.0520\n",
      "Epoch 24/200, Iteration 4/25, Loss: 0.0608\n",
      "Epoch 24/200, Iteration 5/25, Loss: 0.0270\n",
      "Epoch 24/200, Iteration 6/25, Loss: 0.0305\n",
      "Epoch 24/200, Iteration 7/25, Loss: 0.0337\n",
      "Epoch 24/200, Iteration 8/25, Loss: 0.0396\n",
      "Epoch 24/200, Iteration 9/25, Loss: 0.0471\n",
      "Epoch 24/200, Iteration 10/25, Loss: 0.0356\n",
      "Epoch 24/200, Iteration 11/25, Loss: 0.0399\n",
      "Epoch 24/200, Iteration 12/25, Loss: 0.0569\n",
      "Epoch 24/200, Iteration 13/25, Loss: 0.0501\n",
      "Epoch 24/200, Iteration 14/25, Loss: 0.0315\n",
      "Epoch 24/200, Iteration 15/25, Loss: 0.0391\n",
      "Epoch 24/200, Iteration 16/25, Loss: 0.0359\n",
      "Epoch 24/200, Iteration 17/25, Loss: 0.0429\n",
      "Epoch 24/200, Iteration 18/25, Loss: 0.0433\n",
      "Epoch 24/200, Iteration 19/25, Loss: 0.0315\n",
      "Epoch 24/200, Iteration 20/25, Loss: 0.0406\n",
      "Epoch 24/200, Iteration 21/25, Loss: 0.0385\n",
      "Epoch 24/200, Iteration 22/25, Loss: 0.0407\n",
      "Epoch 24/200, Iteration 23/25, Loss: 0.0240\n",
      "Epoch 24/200, Iteration 24/25, Loss: 0.0348\n",
      "Epoch 24/200, Iteration 25/25, Loss: 0.0280\n",
      "Train Error: \n",
      " Accuracy: 53.37%, Avg loss: 0.026269, MRE: 1.284808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.030187, MRE: 3.209682 \n",
      "\n",
      "Epoch 25/200, Iteration 1/25, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 2/25, Loss: 0.0386\n",
      "Epoch 25/200, Iteration 3/25, Loss: 0.0433\n",
      "Epoch 25/200, Iteration 4/25, Loss: 0.0402\n",
      "Epoch 25/200, Iteration 5/25, Loss: 0.0362\n",
      "Epoch 25/200, Iteration 6/25, Loss: 0.0445\n",
      "Epoch 25/200, Iteration 7/25, Loss: 0.0458\n",
      "Epoch 25/200, Iteration 8/25, Loss: 0.0343\n",
      "Epoch 25/200, Iteration 9/25, Loss: 0.0221\n",
      "Epoch 25/200, Iteration 10/25, Loss: 0.0606\n",
      "Epoch 25/200, Iteration 11/25, Loss: 0.0734\n",
      "Epoch 25/200, Iteration 12/25, Loss: 0.0632\n",
      "Epoch 25/200, Iteration 13/25, Loss: 0.0513\n",
      "Epoch 25/200, Iteration 14/25, Loss: 0.0235\n",
      "Epoch 25/200, Iteration 15/25, Loss: 0.0396\n",
      "Epoch 25/200, Iteration 16/25, Loss: 0.0460\n",
      "Epoch 25/200, Iteration 17/25, Loss: 0.0494\n",
      "Epoch 25/200, Iteration 18/25, Loss: 0.0345\n",
      "Epoch 25/200, Iteration 19/25, Loss: 0.0400\n",
      "Epoch 25/200, Iteration 20/25, Loss: 0.0203\n",
      "Epoch 25/200, Iteration 21/25, Loss: 0.0743\n",
      "Epoch 25/200, Iteration 22/25, Loss: 0.0439\n",
      "Epoch 25/200, Iteration 23/25, Loss: 0.0265\n",
      "Epoch 25/200, Iteration 24/25, Loss: 0.0337\n",
      "Epoch 25/200, Iteration 25/25, Loss: 0.0288\n",
      "Train Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.025625, MRE: 1.849307 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.027806, MRE: 2.093611 \n",
      "\n",
      "Epoch 26/200, Iteration 1/25, Loss: 0.0354\n",
      "Epoch 26/200, Iteration 2/25, Loss: 0.0306\n",
      "Epoch 26/200, Iteration 3/25, Loss: 0.0407\n",
      "Epoch 26/200, Iteration 4/25, Loss: 0.0201\n",
      "Epoch 26/200, Iteration 5/25, Loss: 0.0294\n",
      "Epoch 26/200, Iteration 6/25, Loss: 0.0390\n",
      "Epoch 26/200, Iteration 7/25, Loss: 0.0362\n",
      "Epoch 26/200, Iteration 8/25, Loss: 0.0350\n",
      "Epoch 26/200, Iteration 9/25, Loss: 0.0587\n",
      "Epoch 26/200, Iteration 10/25, Loss: 0.0400\n",
      "Epoch 26/200, Iteration 11/25, Loss: 0.0403\n",
      "Epoch 26/200, Iteration 12/25, Loss: 0.0328\n",
      "Epoch 26/200, Iteration 13/25, Loss: 0.0391\n",
      "Epoch 26/200, Iteration 14/25, Loss: 0.0557\n",
      "Epoch 26/200, Iteration 15/25, Loss: 0.0552\n",
      "Epoch 26/200, Iteration 16/25, Loss: 0.0574\n",
      "Epoch 26/200, Iteration 17/25, Loss: 0.0181\n",
      "Epoch 26/200, Iteration 18/25, Loss: 0.0318\n",
      "Epoch 26/200, Iteration 19/25, Loss: 0.0354\n",
      "Epoch 26/200, Iteration 20/25, Loss: 0.0318\n",
      "Epoch 26/200, Iteration 21/25, Loss: 0.0252\n",
      "Epoch 26/200, Iteration 22/25, Loss: 0.0250\n",
      "Epoch 26/200, Iteration 23/25, Loss: 0.0267\n",
      "Epoch 26/200, Iteration 24/25, Loss: 0.0369\n",
      "Epoch 26/200, Iteration 25/25, Loss: 0.0307\n",
      "Train Error: \n",
      " Accuracy: 81.38%, Avg loss: 0.025327, MRE: 1.774069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.025616, MRE: 4.014807 \n",
      "\n",
      "Epoch 27/200, Iteration 1/25, Loss: 0.0531\n",
      "Epoch 27/200, Iteration 2/25, Loss: 0.0246\n",
      "Epoch 27/200, Iteration 3/25, Loss: 0.0225\n",
      "Epoch 27/200, Iteration 4/25, Loss: 0.0215\n",
      "Epoch 27/200, Iteration 5/25, Loss: 0.0207\n",
      "Epoch 27/200, Iteration 6/25, Loss: 0.0319\n",
      "Epoch 27/200, Iteration 7/25, Loss: 0.0324\n",
      "Epoch 27/200, Iteration 8/25, Loss: 0.0387\n",
      "Epoch 27/200, Iteration 9/25, Loss: 0.0187\n",
      "Epoch 27/200, Iteration 10/25, Loss: 0.0422\n",
      "Epoch 27/200, Iteration 11/25, Loss: 0.0272\n",
      "Epoch 27/200, Iteration 12/25, Loss: 0.0271\n",
      "Epoch 27/200, Iteration 13/25, Loss: 0.0339\n",
      "Epoch 27/200, Iteration 14/25, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 15/25, Loss: 0.0239\n",
      "Epoch 27/200, Iteration 16/25, Loss: 0.0327\n",
      "Epoch 27/200, Iteration 17/25, Loss: 0.0500\n",
      "Epoch 27/200, Iteration 18/25, Loss: 0.0363\n",
      "Epoch 27/200, Iteration 19/25, Loss: 0.0298\n",
      "Epoch 27/200, Iteration 20/25, Loss: 0.0418\n",
      "Epoch 27/200, Iteration 21/25, Loss: 0.0407\n",
      "Epoch 27/200, Iteration 22/25, Loss: 0.0401\n",
      "Epoch 27/200, Iteration 23/25, Loss: 0.0177\n",
      "Epoch 27/200, Iteration 24/25, Loss: 0.0352\n",
      "Epoch 27/200, Iteration 25/25, Loss: 0.0265\n",
      "Train Error: \n",
      " Accuracy: 47.88%, Avg loss: 0.018834, MRE: 1.185170 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.023012, MRE: 3.255317 \n",
      "\n",
      "Epoch 28/200, Iteration 1/25, Loss: 0.0255\n",
      "Epoch 28/200, Iteration 2/25, Loss: 0.0498\n",
      "Epoch 28/200, Iteration 3/25, Loss: 0.0450\n",
      "Epoch 28/200, Iteration 4/25, Loss: 0.0393\n",
      "Epoch 28/200, Iteration 5/25, Loss: 0.0258\n",
      "Epoch 28/200, Iteration 6/25, Loss: 0.0327\n",
      "Epoch 28/200, Iteration 7/25, Loss: 0.0343\n",
      "Epoch 28/200, Iteration 8/25, Loss: 0.0374\n",
      "Epoch 28/200, Iteration 9/25, Loss: 0.0297\n",
      "Epoch 28/200, Iteration 10/25, Loss: 0.0237\n",
      "Epoch 28/200, Iteration 11/25, Loss: 0.0299\n",
      "Epoch 28/200, Iteration 12/25, Loss: 0.0321\n",
      "Epoch 28/200, Iteration 13/25, Loss: 0.0328\n",
      "Epoch 28/200, Iteration 14/25, Loss: 0.0344\n",
      "Epoch 28/200, Iteration 15/25, Loss: 0.0364\n",
      "Epoch 28/200, Iteration 16/25, Loss: 0.0404\n",
      "Epoch 28/200, Iteration 17/25, Loss: 0.0504\n",
      "Epoch 28/200, Iteration 18/25, Loss: 0.0442\n",
      "Epoch 28/200, Iteration 19/25, Loss: 0.0416\n",
      "Epoch 28/200, Iteration 20/25, Loss: 0.0341\n",
      "Epoch 28/200, Iteration 21/25, Loss: 0.0340\n",
      "Epoch 28/200, Iteration 22/25, Loss: 0.0568\n",
      "Epoch 28/200, Iteration 23/25, Loss: 0.0332\n",
      "Epoch 28/200, Iteration 24/25, Loss: 0.0333\n",
      "Epoch 28/200, Iteration 25/25, Loss: 0.0356\n",
      "Train Error: \n",
      " Accuracy: 52.25%, Avg loss: 0.035600, MRE: 2.025728 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 0.036310, MRE: 7.378266 \n",
      "\n",
      "Epoch 29/200, Iteration 1/25, Loss: 0.0320\n",
      "Epoch 29/200, Iteration 2/25, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 3/25, Loss: 0.0387\n",
      "Epoch 29/200, Iteration 4/25, Loss: 0.0470\n",
      "Epoch 29/200, Iteration 5/25, Loss: 0.0341\n",
      "Epoch 29/200, Iteration 6/25, Loss: 0.0326\n",
      "Epoch 29/200, Iteration 7/25, Loss: 0.0478\n",
      "Epoch 29/200, Iteration 8/25, Loss: 0.0466\n",
      "Epoch 29/200, Iteration 9/25, Loss: 0.0357\n",
      "Epoch 29/200, Iteration 10/25, Loss: 0.0499\n",
      "Epoch 29/200, Iteration 11/25, Loss: 0.0439\n",
      "Epoch 29/200, Iteration 12/25, Loss: 0.0426\n",
      "Epoch 29/200, Iteration 13/25, Loss: 0.0318\n",
      "Epoch 29/200, Iteration 14/25, Loss: 0.0408\n",
      "Epoch 29/200, Iteration 15/25, Loss: 0.0442\n",
      "Epoch 29/200, Iteration 16/25, Loss: 0.0272\n",
      "Epoch 29/200, Iteration 17/25, Loss: 0.0367\n",
      "Epoch 29/200, Iteration 18/25, Loss: 0.0329\n",
      "Epoch 29/200, Iteration 19/25, Loss: 0.0481\n",
      "Epoch 29/200, Iteration 20/25, Loss: 0.0309\n",
      "Epoch 29/200, Iteration 21/25, Loss: 0.0440\n",
      "Epoch 29/200, Iteration 22/25, Loss: 0.0305\n",
      "Epoch 29/200, Iteration 23/25, Loss: 0.0554\n",
      "Epoch 29/200, Iteration 24/25, Loss: 0.0524\n",
      "Epoch 29/200, Iteration 25/25, Loss: 0.0578\n",
      "Train Error: \n",
      " Accuracy: 51.12%, Avg loss: 0.041363, MRE: 2.206949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 0.042744, MRE: 4.104592 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Iteration 1/25, Loss: 0.0347\n",
      "Epoch 30/200, Iteration 2/25, Loss: 0.0250\n",
      "Epoch 30/200, Iteration 3/25, Loss: 0.0261\n",
      "Epoch 30/200, Iteration 4/25, Loss: 0.0318\n",
      "Epoch 30/200, Iteration 5/25, Loss: 0.0383\n",
      "Epoch 30/200, Iteration 6/25, Loss: 0.0359\n",
      "Epoch 30/200, Iteration 7/25, Loss: 0.0403\n",
      "Epoch 30/200, Iteration 8/25, Loss: 0.0283\n",
      "Epoch 30/200, Iteration 9/25, Loss: 0.0286\n",
      "Epoch 30/200, Iteration 10/25, Loss: 0.0213\n",
      "Epoch 30/200, Iteration 11/25, Loss: 0.0344\n",
      "Epoch 30/200, Iteration 12/25, Loss: 0.0517\n",
      "Epoch 30/200, Iteration 13/25, Loss: 0.0267\n",
      "Epoch 30/200, Iteration 14/25, Loss: 0.0285\n",
      "Epoch 30/200, Iteration 15/25, Loss: 0.0301\n",
      "Epoch 30/200, Iteration 16/25, Loss: 0.0266\n",
      "Epoch 30/200, Iteration 17/25, Loss: 0.0200\n",
      "Epoch 30/200, Iteration 18/25, Loss: 0.0215\n",
      "Epoch 30/200, Iteration 19/25, Loss: 0.0293\n",
      "Epoch 30/200, Iteration 20/25, Loss: 0.0265\n",
      "Epoch 30/200, Iteration 21/25, Loss: 0.0339\n",
      "Epoch 30/200, Iteration 22/25, Loss: 0.0314\n",
      "Epoch 30/200, Iteration 23/25, Loss: 0.0331\n",
      "Epoch 30/200, Iteration 24/25, Loss: 0.0351\n",
      "Epoch 30/200, Iteration 25/25, Loss: 0.0264\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.030494, MRE: 1.319058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.032212, MRE: 3.889595 \n",
      "\n",
      "Epoch 31/200, Iteration 1/25, Loss: 0.0462\n",
      "Epoch 31/200, Iteration 2/25, Loss: 0.0360\n",
      "Epoch 31/200, Iteration 3/25, Loss: 0.0301\n",
      "Epoch 31/200, Iteration 4/25, Loss: 0.0204\n",
      "Epoch 31/200, Iteration 5/25, Loss: 0.0237\n",
      "Epoch 31/200, Iteration 6/25, Loss: 0.0585\n",
      "Epoch 31/200, Iteration 7/25, Loss: 0.0363\n",
      "Epoch 31/200, Iteration 8/25, Loss: 0.0308\n",
      "Epoch 31/200, Iteration 9/25, Loss: 0.0453\n",
      "Epoch 31/200, Iteration 10/25, Loss: 0.0271\n",
      "Epoch 31/200, Iteration 11/25, Loss: 0.0250\n",
      "Epoch 31/200, Iteration 12/25, Loss: 0.0352\n",
      "Epoch 31/200, Iteration 13/25, Loss: 0.0216\n",
      "Epoch 31/200, Iteration 14/25, Loss: 0.0226\n",
      "Epoch 31/200, Iteration 15/25, Loss: 0.0253\n",
      "Epoch 31/200, Iteration 16/25, Loss: 0.0226\n",
      "Epoch 31/200, Iteration 17/25, Loss: 0.0275\n",
      "Epoch 31/200, Iteration 18/25, Loss: 0.0215\n",
      "Epoch 31/200, Iteration 19/25, Loss: 0.0250\n",
      "Epoch 31/200, Iteration 20/25, Loss: 0.0287\n",
      "Epoch 31/200, Iteration 21/25, Loss: 0.0279\n",
      "Epoch 31/200, Iteration 22/25, Loss: 0.0241\n",
      "Epoch 31/200, Iteration 23/25, Loss: 0.0281\n",
      "Epoch 31/200, Iteration 24/25, Loss: 0.0157\n",
      "Epoch 31/200, Iteration 25/25, Loss: 0.0260\n",
      "Train Error: \n",
      " Accuracy: 81.88%, Avg loss: 0.018621, MRE: 0.991484 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.022837, MRE: 2.192236 \n",
      "\n",
      "Epoch 32/200, Iteration 1/25, Loss: 0.0291\n",
      "Epoch 32/200, Iteration 2/25, Loss: 0.0239\n",
      "Epoch 32/200, Iteration 3/25, Loss: 0.0317\n",
      "Epoch 32/200, Iteration 4/25, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 5/25, Loss: 0.0283\n",
      "Epoch 32/200, Iteration 6/25, Loss: 0.0333\n",
      "Epoch 32/200, Iteration 7/25, Loss: 0.0207\n",
      "Epoch 32/200, Iteration 8/25, Loss: 0.0327\n",
      "Epoch 32/200, Iteration 9/25, Loss: 0.0205\n",
      "Epoch 32/200, Iteration 10/25, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 11/25, Loss: 0.0329\n",
      "Epoch 32/200, Iteration 12/25, Loss: 0.0193\n",
      "Epoch 32/200, Iteration 13/25, Loss: 0.0165\n",
      "Epoch 32/200, Iteration 14/25, Loss: 0.0277\n",
      "Epoch 32/200, Iteration 15/25, Loss: 0.0206\n",
      "Epoch 32/200, Iteration 16/25, Loss: 0.0264\n",
      "Epoch 32/200, Iteration 17/25, Loss: 0.0204\n",
      "Epoch 32/200, Iteration 18/25, Loss: 0.0238\n",
      "Epoch 32/200, Iteration 19/25, Loss: 0.0184\n",
      "Epoch 32/200, Iteration 20/25, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 21/25, Loss: 0.0346\n",
      "Epoch 32/200, Iteration 22/25, Loss: 0.0419\n",
      "Epoch 32/200, Iteration 23/25, Loss: 0.0416\n",
      "Epoch 32/200, Iteration 24/25, Loss: 0.0407\n",
      "Epoch 32/200, Iteration 25/25, Loss: 0.0447\n",
      "Train Error: \n",
      " Accuracy: 47.62%, Avg loss: 0.028206, MRE: 1.225852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.030900, MRE: 4.857045 \n",
      "\n",
      "Epoch 33/200, Iteration 1/25, Loss: 0.0303\n",
      "Epoch 33/200, Iteration 2/25, Loss: 0.0279\n",
      "Epoch 33/200, Iteration 3/25, Loss: 0.0238\n",
      "Epoch 33/200, Iteration 4/25, Loss: 0.0208\n",
      "Epoch 33/200, Iteration 5/25, Loss: 0.0221\n",
      "Epoch 33/200, Iteration 6/25, Loss: 0.0251\n",
      "Epoch 33/200, Iteration 7/25, Loss: 0.0353\n",
      "Epoch 33/200, Iteration 8/25, Loss: 0.0213\n",
      "Epoch 33/200, Iteration 9/25, Loss: 0.0311\n",
      "Epoch 33/200, Iteration 10/25, Loss: 0.0139\n",
      "Epoch 33/200, Iteration 11/25, Loss: 0.0281\n",
      "Epoch 33/200, Iteration 12/25, Loss: 0.0298\n",
      "Epoch 33/200, Iteration 13/25, Loss: 0.0324\n",
      "Epoch 33/200, Iteration 14/25, Loss: 0.0368\n",
      "Epoch 33/200, Iteration 15/25, Loss: 0.0263\n",
      "Epoch 33/200, Iteration 16/25, Loss: 0.0250\n",
      "Epoch 33/200, Iteration 17/25, Loss: 0.0326\n",
      "Epoch 33/200, Iteration 18/25, Loss: 0.0420\n",
      "Epoch 33/200, Iteration 19/25, Loss: 0.0376\n",
      "Epoch 33/200, Iteration 20/25, Loss: 0.0408\n",
      "Epoch 33/200, Iteration 21/25, Loss: 0.0254\n",
      "Epoch 33/200, Iteration 22/25, Loss: 0.0482\n",
      "Epoch 33/200, Iteration 23/25, Loss: 0.0362\n",
      "Epoch 33/200, Iteration 24/25, Loss: 0.0237\n",
      "Epoch 33/200, Iteration 25/25, Loss: 0.0234\n",
      "Train Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.031924, MRE: 1.526610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.033635, MRE: 2.866763 \n",
      "\n",
      "Epoch 34/200, Iteration 1/25, Loss: 0.0324\n",
      "Epoch 34/200, Iteration 2/25, Loss: 0.0335\n",
      "Epoch 34/200, Iteration 3/25, Loss: 0.0259\n",
      "Epoch 34/200, Iteration 4/25, Loss: 0.0204\n",
      "Epoch 34/200, Iteration 5/25, Loss: 0.0267\n",
      "Epoch 34/200, Iteration 6/25, Loss: 0.0353\n",
      "Epoch 34/200, Iteration 7/25, Loss: 0.0186\n",
      "Epoch 34/200, Iteration 8/25, Loss: 0.0237\n",
      "Epoch 34/200, Iteration 9/25, Loss: 0.0246\n",
      "Epoch 34/200, Iteration 10/25, Loss: 0.0236\n",
      "Epoch 34/200, Iteration 11/25, Loss: 0.0214\n",
      "Epoch 34/200, Iteration 12/25, Loss: 0.0330\n",
      "Epoch 34/200, Iteration 13/25, Loss: 0.0281\n",
      "Epoch 34/200, Iteration 14/25, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 15/25, Loss: 0.0325\n",
      "Epoch 34/200, Iteration 16/25, Loss: 0.0278\n",
      "Epoch 34/200, Iteration 17/25, Loss: 0.0352\n",
      "Epoch 34/200, Iteration 18/25, Loss: 0.0258\n",
      "Epoch 34/200, Iteration 19/25, Loss: 0.0326\n",
      "Epoch 34/200, Iteration 20/25, Loss: 0.0448\n",
      "Epoch 34/200, Iteration 21/25, Loss: 0.0348\n",
      "Epoch 34/200, Iteration 22/25, Loss: 0.0240\n",
      "Epoch 34/200, Iteration 23/25, Loss: 0.0247\n",
      "Epoch 34/200, Iteration 24/25, Loss: 0.0191\n",
      "Epoch 34/200, Iteration 25/25, Loss: 0.0284\n",
      "Train Error: \n",
      " Accuracy: 61.38%, Avg loss: 0.018439, MRE: 0.914499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.020960, MRE: 0.987360 \n",
      "\n",
      "Epoch 35/200, Iteration 1/25, Loss: 0.0206\n",
      "Epoch 35/200, Iteration 2/25, Loss: 0.0228\n",
      "Epoch 35/200, Iteration 3/25, Loss: 0.0251\n",
      "Epoch 35/200, Iteration 4/25, Loss: 0.0206\n",
      "Epoch 35/200, Iteration 5/25, Loss: 0.0230\n",
      "Epoch 35/200, Iteration 6/25, Loss: 0.0257\n",
      "Epoch 35/200, Iteration 7/25, Loss: 0.0218\n",
      "Epoch 35/200, Iteration 8/25, Loss: 0.0585\n",
      "Epoch 35/200, Iteration 9/25, Loss: 0.0264\n",
      "Epoch 35/200, Iteration 10/25, Loss: 0.0255\n",
      "Epoch 35/200, Iteration 11/25, Loss: 0.0330\n",
      "Epoch 35/200, Iteration 12/25, Loss: 0.0509\n",
      "Epoch 35/200, Iteration 13/25, Loss: 0.0290\n",
      "Epoch 35/200, Iteration 14/25, Loss: 0.0201\n",
      "Epoch 35/200, Iteration 15/25, Loss: 0.0341\n",
      "Epoch 35/200, Iteration 16/25, Loss: 0.0268\n",
      "Epoch 35/200, Iteration 17/25, Loss: 0.0351\n",
      "Epoch 35/200, Iteration 18/25, Loss: 0.0203\n",
      "Epoch 35/200, Iteration 19/25, Loss: 0.0403\n",
      "Epoch 35/200, Iteration 20/25, Loss: 0.0384\n",
      "Epoch 35/200, Iteration 21/25, Loss: 0.0235\n",
      "Epoch 35/200, Iteration 22/25, Loss: 0.0306\n",
      "Epoch 35/200, Iteration 23/25, Loss: 0.0249\n",
      "Epoch 35/200, Iteration 24/25, Loss: 0.0353\n",
      "Epoch 35/200, Iteration 25/25, Loss: 0.0355\n",
      "Train Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.018820, MRE: 0.840162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.021493, MRE: 2.510852 \n",
      "\n",
      "Epoch 36/200, Iteration 1/25, Loss: 0.0257\n",
      "Epoch 36/200, Iteration 2/25, Loss: 0.0226\n",
      "Epoch 36/200, Iteration 3/25, Loss: 0.0361\n",
      "Epoch 36/200, Iteration 4/25, Loss: 0.0368\n",
      "Epoch 36/200, Iteration 5/25, Loss: 0.0214\n",
      "Epoch 36/200, Iteration 6/25, Loss: 0.0223\n",
      "Epoch 36/200, Iteration 7/25, Loss: 0.0297\n",
      "Epoch 36/200, Iteration 8/25, Loss: 0.0304\n",
      "Epoch 36/200, Iteration 9/25, Loss: 0.0372\n",
      "Epoch 36/200, Iteration 10/25, Loss: 0.0321\n",
      "Epoch 36/200, Iteration 11/25, Loss: 0.0305\n",
      "Epoch 36/200, Iteration 12/25, Loss: 0.0258\n",
      "Epoch 36/200, Iteration 13/25, Loss: 0.0350\n",
      "Epoch 36/200, Iteration 14/25, Loss: 0.0281\n",
      "Epoch 36/200, Iteration 15/25, Loss: 0.0466\n",
      "Epoch 36/200, Iteration 16/25, Loss: 0.0279\n",
      "Epoch 36/200, Iteration 17/25, Loss: 0.0258\n",
      "Epoch 36/200, Iteration 18/25, Loss: 0.0220\n",
      "Epoch 36/200, Iteration 19/25, Loss: 0.0161\n",
      "Epoch 36/200, Iteration 20/25, Loss: 0.0254\n",
      "Epoch 36/200, Iteration 21/25, Loss: 0.0291\n",
      "Epoch 36/200, Iteration 22/25, Loss: 0.0223\n",
      "Epoch 36/200, Iteration 23/25, Loss: 0.0261\n",
      "Epoch 36/200, Iteration 24/25, Loss: 0.0308\n",
      "Epoch 36/200, Iteration 25/25, Loss: 0.0345\n",
      "Train Error: \n",
      " Accuracy: 70.25%, Avg loss: 0.016142, MRE: 0.768330 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.018788, MRE: 0.897981 \n",
      "\n",
      "Epoch 37/200, Iteration 1/25, Loss: 0.0262\n",
      "Epoch 37/200, Iteration 2/25, Loss: 0.0162\n",
      "Epoch 37/200, Iteration 3/25, Loss: 0.0242\n",
      "Epoch 37/200, Iteration 4/25, Loss: 0.0241\n",
      "Epoch 37/200, Iteration 5/25, Loss: 0.0296\n",
      "Epoch 37/200, Iteration 6/25, Loss: 0.0206\n",
      "Epoch 37/200, Iteration 7/25, Loss: 0.0350\n",
      "Epoch 37/200, Iteration 8/25, Loss: 0.0239\n",
      "Epoch 37/200, Iteration 9/25, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 10/25, Loss: 0.0244\n",
      "Epoch 37/200, Iteration 11/25, Loss: 0.0176\n",
      "Epoch 37/200, Iteration 12/25, Loss: 0.0124\n",
      "Epoch 37/200, Iteration 13/25, Loss: 0.0158\n",
      "Epoch 37/200, Iteration 14/25, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 15/25, Loss: 0.0225\n",
      "Epoch 37/200, Iteration 16/25, Loss: 0.0286\n",
      "Epoch 37/200, Iteration 17/25, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 18/25, Loss: 0.0258\n",
      "Epoch 37/200, Iteration 19/25, Loss: 0.0262\n",
      "Epoch 37/200, Iteration 20/25, Loss: 0.0470\n",
      "Epoch 37/200, Iteration 21/25, Loss: 0.0258\n",
      "Epoch 37/200, Iteration 22/25, Loss: 0.0259\n",
      "Epoch 37/200, Iteration 23/25, Loss: 0.0146\n",
      "Epoch 37/200, Iteration 24/25, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 25/25, Loss: 0.0146\n",
      "Train Error: \n",
      " Accuracy: 63.75%, Avg loss: 0.018181, MRE: 1.079395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.021351, MRE: 3.329705 \n",
      "\n",
      "Epoch 38/200, Iteration 1/25, Loss: 0.0247\n",
      "Epoch 38/200, Iteration 2/25, Loss: 0.0255\n",
      "Epoch 38/200, Iteration 3/25, Loss: 0.0192\n",
      "Epoch 38/200, Iteration 4/25, Loss: 0.0173\n",
      "Epoch 38/200, Iteration 5/25, Loss: 0.0241\n",
      "Epoch 38/200, Iteration 6/25, Loss: 0.0245\n",
      "Epoch 38/200, Iteration 7/25, Loss: 0.0336\n",
      "Epoch 38/200, Iteration 8/25, Loss: 0.0253\n",
      "Epoch 38/200, Iteration 9/25, Loss: 0.0313\n",
      "Epoch 38/200, Iteration 10/25, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 11/25, Loss: 0.0304\n",
      "Epoch 38/200, Iteration 12/25, Loss: 0.0303\n",
      "Epoch 38/200, Iteration 13/25, Loss: 0.0206\n",
      "Epoch 38/200, Iteration 14/25, Loss: 0.0316\n",
      "Epoch 38/200, Iteration 15/25, Loss: 0.0342\n",
      "Epoch 38/200, Iteration 16/25, Loss: 0.0404\n",
      "Epoch 38/200, Iteration 17/25, Loss: 0.0279\n",
      "Epoch 38/200, Iteration 18/25, Loss: 0.0526\n",
      "Epoch 38/200, Iteration 19/25, Loss: 0.0338\n",
      "Epoch 38/200, Iteration 20/25, Loss: 0.0337\n",
      "Epoch 38/200, Iteration 21/25, Loss: 0.0337\n",
      "Epoch 38/200, Iteration 22/25, Loss: 0.0346\n",
      "Epoch 38/200, Iteration 23/25, Loss: 0.0265\n",
      "Epoch 38/200, Iteration 24/25, Loss: 0.0426\n",
      "Epoch 38/200, Iteration 25/25, Loss: 0.0411\n",
      "Train Error: \n",
      " Accuracy: 40.62%, Avg loss: 0.031382, MRE: 1.146187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.036511, MRE: 1.999986 \n",
      "\n",
      "Epoch 39/200, Iteration 1/25, Loss: 0.0275\n",
      "Epoch 39/200, Iteration 2/25, Loss: 0.0249\n",
      "Epoch 39/200, Iteration 3/25, Loss: 0.0269\n",
      "Epoch 39/200, Iteration 4/25, Loss: 0.0245\n",
      "Epoch 39/200, Iteration 5/25, Loss: 0.0279\n",
      "Epoch 39/200, Iteration 6/25, Loss: 0.0227\n",
      "Epoch 39/200, Iteration 7/25, Loss: 0.0233\n",
      "Epoch 39/200, Iteration 8/25, Loss: 0.0271\n",
      "Epoch 39/200, Iteration 9/25, Loss: 0.0256\n",
      "Epoch 39/200, Iteration 10/25, Loss: 0.0237\n",
      "Epoch 39/200, Iteration 11/25, Loss: 0.0208\n",
      "Epoch 39/200, Iteration 12/25, Loss: 0.0375\n",
      "Epoch 39/200, Iteration 13/25, Loss: 0.0351\n",
      "Epoch 39/200, Iteration 14/25, Loss: 0.0370\n",
      "Epoch 39/200, Iteration 15/25, Loss: 0.0345\n",
      "Epoch 39/200, Iteration 16/25, Loss: 0.0316\n",
      "Epoch 39/200, Iteration 17/25, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 18/25, Loss: 0.0179\n",
      "Epoch 39/200, Iteration 19/25, Loss: 0.0417\n",
      "Epoch 39/200, Iteration 20/25, Loss: 0.0264\n",
      "Epoch 39/200, Iteration 21/25, Loss: 0.0350\n",
      "Epoch 39/200, Iteration 22/25, Loss: 0.0267\n",
      "Epoch 39/200, Iteration 23/25, Loss: 0.0221\n",
      "Epoch 39/200, Iteration 24/25, Loss: 0.0135\n",
      "Epoch 39/200, Iteration 25/25, Loss: 0.0469\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.028112, MRE: 1.275299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.030327, MRE: 3.500794 \n",
      "\n",
      "Epoch 40/200, Iteration 1/25, Loss: 0.0211\n",
      "Epoch 40/200, Iteration 2/25, Loss: 0.0261\n",
      "Epoch 40/200, Iteration 3/25, Loss: 0.0294\n",
      "Epoch 40/200, Iteration 4/25, Loss: 0.0317\n",
      "Epoch 40/200, Iteration 5/25, Loss: 0.0292\n",
      "Epoch 40/200, Iteration 6/25, Loss: 0.0227\n",
      "Epoch 40/200, Iteration 7/25, Loss: 0.0269\n",
      "Epoch 40/200, Iteration 8/25, Loss: 0.0201\n",
      "Epoch 40/200, Iteration 9/25, Loss: 0.0288\n",
      "Epoch 40/200, Iteration 10/25, Loss: 0.0261\n",
      "Epoch 40/200, Iteration 11/25, Loss: 0.0235\n",
      "Epoch 40/200, Iteration 12/25, Loss: 0.0288\n",
      "Epoch 40/200, Iteration 13/25, Loss: 0.0204\n",
      "Epoch 40/200, Iteration 14/25, Loss: 0.0249\n",
      "Epoch 40/200, Iteration 15/25, Loss: 0.0230\n",
      "Epoch 40/200, Iteration 16/25, Loss: 0.0288\n",
      "Epoch 40/200, Iteration 17/25, Loss: 0.0311\n",
      "Epoch 40/200, Iteration 18/25, Loss: 0.0234\n",
      "Epoch 40/200, Iteration 19/25, Loss: 0.0245\n",
      "Epoch 40/200, Iteration 20/25, Loss: 0.0232\n",
      "Epoch 40/200, Iteration 21/25, Loss: 0.0250\n",
      "Epoch 40/200, Iteration 22/25, Loss: 0.0165\n",
      "Epoch 40/200, Iteration 23/25, Loss: 0.0179\n",
      "Epoch 40/200, Iteration 24/25, Loss: 0.0365\n",
      "Epoch 40/200, Iteration 25/25, Loss: 0.0187\n",
      "Train Error: \n",
      " Accuracy: 61.62%, Avg loss: 0.020093, MRE: 0.792302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.022772, MRE: 2.112859 \n",
      "\n",
      "Epoch 41/200, Iteration 1/25, Loss: 0.0322\n",
      "Epoch 41/200, Iteration 2/25, Loss: 0.0214\n",
      "Epoch 41/200, Iteration 3/25, Loss: 0.0183\n",
      "Epoch 41/200, Iteration 4/25, Loss: 0.0189\n",
      "Epoch 41/200, Iteration 5/25, Loss: 0.0301\n",
      "Epoch 41/200, Iteration 6/25, Loss: 0.0297\n",
      "Epoch 41/200, Iteration 7/25, Loss: 0.0307\n",
      "Epoch 41/200, Iteration 8/25, Loss: 0.0236\n",
      "Epoch 41/200, Iteration 9/25, Loss: 0.0254\n",
      "Epoch 41/200, Iteration 10/25, Loss: 0.0206\n",
      "Epoch 41/200, Iteration 11/25, Loss: 0.0255\n",
      "Epoch 41/200, Iteration 12/25, Loss: 0.0209\n",
      "Epoch 41/200, Iteration 13/25, Loss: 0.0144\n",
      "Epoch 41/200, Iteration 14/25, Loss: 0.0201\n",
      "Epoch 41/200, Iteration 15/25, Loss: 0.0322\n",
      "Epoch 41/200, Iteration 16/25, Loss: 0.0237\n",
      "Epoch 41/200, Iteration 17/25, Loss: 0.0283\n",
      "Epoch 41/200, Iteration 18/25, Loss: 0.0213\n",
      "Epoch 41/200, Iteration 19/25, Loss: 0.0263\n",
      "Epoch 41/200, Iteration 20/25, Loss: 0.0244\n",
      "Epoch 41/200, Iteration 21/25, Loss: 0.0164\n",
      "Epoch 41/200, Iteration 22/25, Loss: 0.0228\n",
      "Epoch 41/200, Iteration 23/25, Loss: 0.0338\n",
      "Epoch 41/200, Iteration 24/25, Loss: 0.0252\n",
      "Epoch 41/200, Iteration 25/25, Loss: 0.0159\n",
      "Train Error: \n",
      " Accuracy: 76.88%, Avg loss: 0.017039, MRE: 1.048675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.019056, MRE: 2.610551 \n",
      "\n",
      "Epoch 42/200, Iteration 1/25, Loss: 0.0199\n",
      "Epoch 42/200, Iteration 2/25, Loss: 0.0201\n",
      "Epoch 42/200, Iteration 3/25, Loss: 0.0352\n",
      "Epoch 42/200, Iteration 4/25, Loss: 0.0253\n",
      "Epoch 42/200, Iteration 5/25, Loss: 0.0261\n",
      "Epoch 42/200, Iteration 6/25, Loss: 0.0214\n",
      "Epoch 42/200, Iteration 7/25, Loss: 0.0302\n",
      "Epoch 42/200, Iteration 8/25, Loss: 0.0347\n",
      "Epoch 42/200, Iteration 9/25, Loss: 0.0241\n",
      "Epoch 42/200, Iteration 10/25, Loss: 0.0309\n",
      "Epoch 42/200, Iteration 11/25, Loss: 0.0205\n",
      "Epoch 42/200, Iteration 12/25, Loss: 0.0229\n",
      "Epoch 42/200, Iteration 13/25, Loss: 0.0243\n",
      "Epoch 42/200, Iteration 14/25, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 15/25, Loss: 0.0255\n",
      "Epoch 42/200, Iteration 16/25, Loss: 0.0359\n",
      "Epoch 42/200, Iteration 17/25, Loss: 0.0293\n",
      "Epoch 42/200, Iteration 18/25, Loss: 0.0216\n",
      "Epoch 42/200, Iteration 19/25, Loss: 0.0291\n",
      "Epoch 42/200, Iteration 20/25, Loss: 0.0224\n",
      "Epoch 42/200, Iteration 21/25, Loss: 0.0206\n",
      "Epoch 42/200, Iteration 22/25, Loss: 0.0319\n",
      "Epoch 42/200, Iteration 23/25, Loss: 0.0211\n",
      "Epoch 42/200, Iteration 24/25, Loss: 0.0206\n",
      "Epoch 42/200, Iteration 25/25, Loss: 0.0358\n",
      "Train Error: \n",
      " Accuracy: 36.88%, Avg loss: 0.024198, MRE: 1.092375 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.028739, MRE: 3.050070 \n",
      "\n",
      "Epoch 43/200, Iteration 1/25, Loss: 0.0144\n",
      "Epoch 43/200, Iteration 2/25, Loss: 0.0244\n",
      "Epoch 43/200, Iteration 3/25, Loss: 0.0311\n",
      "Epoch 43/200, Iteration 4/25, Loss: 0.0181\n",
      "Epoch 43/200, Iteration 5/25, Loss: 0.0260\n",
      "Epoch 43/200, Iteration 6/25, Loss: 0.0270\n",
      "Epoch 43/200, Iteration 7/25, Loss: 0.0174\n",
      "Epoch 43/200, Iteration 8/25, Loss: 0.0498\n",
      "Epoch 43/200, Iteration 9/25, Loss: 0.0377\n",
      "Epoch 43/200, Iteration 10/25, Loss: 0.0293\n",
      "Epoch 43/200, Iteration 11/25, Loss: 0.0237\n",
      "Epoch 43/200, Iteration 12/25, Loss: 0.0282\n",
      "Epoch 43/200, Iteration 13/25, Loss: 0.0263\n",
      "Epoch 43/200, Iteration 14/25, Loss: 0.0488\n",
      "Epoch 43/200, Iteration 15/25, Loss: 0.0234\n",
      "Epoch 43/200, Iteration 16/25, Loss: 0.0209\n",
      "Epoch 43/200, Iteration 17/25, Loss: 0.0250\n",
      "Epoch 43/200, Iteration 18/25, Loss: 0.0259\n",
      "Epoch 43/200, Iteration 19/25, Loss: 0.0355\n",
      "Epoch 43/200, Iteration 20/25, Loss: 0.0205\n",
      "Epoch 43/200, Iteration 21/25, Loss: 0.0188\n",
      "Epoch 43/200, Iteration 22/25, Loss: 0.0259\n",
      "Epoch 43/200, Iteration 23/25, Loss: 0.0234\n",
      "Epoch 43/200, Iteration 24/25, Loss: 0.0439\n",
      "Epoch 43/200, Iteration 25/25, Loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.018801, MRE: 0.898628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.020273, MRE: 3.019184 \n",
      "\n",
      "Epoch 44/200, Iteration 1/25, Loss: 0.0322\n",
      "Epoch 44/200, Iteration 2/25, Loss: 0.0237\n",
      "Epoch 44/200, Iteration 3/25, Loss: 0.0224\n",
      "Epoch 44/200, Iteration 4/25, Loss: 0.0233\n",
      "Epoch 44/200, Iteration 5/25, Loss: 0.0322\n",
      "Epoch 44/200, Iteration 6/25, Loss: 0.0202\n",
      "Epoch 44/200, Iteration 7/25, Loss: 0.0496\n",
      "Epoch 44/200, Iteration 8/25, Loss: 0.0350\n",
      "Epoch 44/200, Iteration 9/25, Loss: 0.0381\n",
      "Epoch 44/200, Iteration 10/25, Loss: 0.0256\n",
      "Epoch 44/200, Iteration 11/25, Loss: 0.0216\n",
      "Epoch 44/200, Iteration 12/25, Loss: 0.0149\n",
      "Epoch 44/200, Iteration 13/25, Loss: 0.0153\n",
      "Epoch 44/200, Iteration 14/25, Loss: 0.0150\n",
      "Epoch 44/200, Iteration 15/25, Loss: 0.0299\n",
      "Epoch 44/200, Iteration 16/25, Loss: 0.0367\n",
      "Epoch 44/200, Iteration 17/25, Loss: 0.0341\n",
      "Epoch 44/200, Iteration 18/25, Loss: 0.0179\n",
      "Epoch 44/200, Iteration 19/25, Loss: 0.0244\n",
      "Epoch 44/200, Iteration 20/25, Loss: 0.0280\n",
      "Epoch 44/200, Iteration 21/25, Loss: 0.0183\n",
      "Epoch 44/200, Iteration 22/25, Loss: 0.0174\n",
      "Epoch 44/200, Iteration 23/25, Loss: 0.0243\n",
      "Epoch 44/200, Iteration 24/25, Loss: 0.0259\n",
      "Epoch 44/200, Iteration 25/25, Loss: 0.0169\n",
      "Train Error: \n",
      " Accuracy: 71.62%, Avg loss: 0.021665, MRE: 1.471528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.022727, MRE: 4.886389 \n",
      "\n",
      "Epoch 45/200, Iteration 1/25, Loss: 0.0121\n",
      "Epoch 45/200, Iteration 2/25, Loss: 0.0234\n",
      "Epoch 45/200, Iteration 3/25, Loss: 0.0308\n",
      "Epoch 45/200, Iteration 4/25, Loss: 0.0320\n",
      "Epoch 45/200, Iteration 5/25, Loss: 0.0243\n",
      "Epoch 45/200, Iteration 6/25, Loss: 0.0430\n",
      "Epoch 45/200, Iteration 7/25, Loss: 0.0385\n",
      "Epoch 45/200, Iteration 8/25, Loss: 0.0217\n",
      "Epoch 45/200, Iteration 9/25, Loss: 0.0284\n",
      "Epoch 45/200, Iteration 10/25, Loss: 0.0188\n",
      "Epoch 45/200, Iteration 11/25, Loss: 0.0213\n",
      "Epoch 45/200, Iteration 12/25, Loss: 0.0152\n",
      "Epoch 45/200, Iteration 13/25, Loss: 0.0188\n",
      "Epoch 45/200, Iteration 14/25, Loss: 0.0223\n",
      "Epoch 45/200, Iteration 15/25, Loss: 0.0564\n",
      "Epoch 45/200, Iteration 16/25, Loss: 0.0232\n",
      "Epoch 45/200, Iteration 17/25, Loss: 0.0233\n",
      "Epoch 45/200, Iteration 18/25, Loss: 0.0193\n",
      "Epoch 45/200, Iteration 19/25, Loss: 0.0143\n",
      "Epoch 45/200, Iteration 20/25, Loss: 0.0141\n",
      "Epoch 45/200, Iteration 21/25, Loss: 0.0215\n",
      "Epoch 45/200, Iteration 22/25, Loss: 0.0187\n",
      "Epoch 45/200, Iteration 23/25, Loss: 0.0277\n",
      "Epoch 45/200, Iteration 24/25, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 25/25, Loss: 0.0455\n",
      "Train Error: \n",
      " Accuracy: 87.12%, Avg loss: 0.021483, MRE: 0.992994 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.021127, MRE: 1.735850 \n",
      "\n",
      "Epoch 46/200, Iteration 1/25, Loss: 0.0452\n",
      "Epoch 46/200, Iteration 2/25, Loss: 0.0181\n",
      "Epoch 46/200, Iteration 3/25, Loss: 0.0215\n",
      "Epoch 46/200, Iteration 4/25, Loss: 0.0467\n",
      "Epoch 46/200, Iteration 5/25, Loss: 0.0222\n",
      "Epoch 46/200, Iteration 6/25, Loss: 0.0197\n",
      "Epoch 46/200, Iteration 7/25, Loss: 0.0169\n",
      "Epoch 46/200, Iteration 8/25, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 9/25, Loss: 0.0271\n",
      "Epoch 46/200, Iteration 10/25, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 11/25, Loss: 0.0249\n",
      "Epoch 46/200, Iteration 12/25, Loss: 0.0209\n",
      "Epoch 46/200, Iteration 13/25, Loss: 0.0207\n",
      "Epoch 46/200, Iteration 14/25, Loss: 0.0264\n",
      "Epoch 46/200, Iteration 15/25, Loss: 0.0252\n",
      "Epoch 46/200, Iteration 16/25, Loss: 0.0260\n",
      "Epoch 46/200, Iteration 17/25, Loss: 0.0214\n",
      "Epoch 46/200, Iteration 18/25, Loss: 0.0362\n",
      "Epoch 46/200, Iteration 19/25, Loss: 0.0136\n",
      "Epoch 46/200, Iteration 20/25, Loss: 0.0209\n",
      "Epoch 46/200, Iteration 21/25, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 22/25, Loss: 0.0213\n",
      "Epoch 46/200, Iteration 23/25, Loss: 0.0219\n",
      "Epoch 46/200, Iteration 24/25, Loss: 0.0384\n",
      "Epoch 46/200, Iteration 25/25, Loss: 0.0300\n",
      "Train Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.014604, MRE: 0.694997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.015777, MRE: 2.082628 \n",
      "\n",
      "Epoch 47/200, Iteration 1/25, Loss: 0.0259\n",
      "Epoch 47/200, Iteration 2/25, Loss: 0.0310\n",
      "Epoch 47/200, Iteration 3/25, Loss: 0.0185\n",
      "Epoch 47/200, Iteration 4/25, Loss: 0.0191\n",
      "Epoch 47/200, Iteration 5/25, Loss: 0.0276\n",
      "Epoch 47/200, Iteration 6/25, Loss: 0.0360\n",
      "Epoch 47/200, Iteration 7/25, Loss: 0.0493\n",
      "Epoch 47/200, Iteration 8/25, Loss: 0.0239\n",
      "Epoch 47/200, Iteration 9/25, Loss: 0.0260\n",
      "Epoch 47/200, Iteration 10/25, Loss: 0.0271\n",
      "Epoch 47/200, Iteration 11/25, Loss: 0.0154\n",
      "Epoch 47/200, Iteration 12/25, Loss: 0.0182\n",
      "Epoch 47/200, Iteration 13/25, Loss: 0.0373\n",
      "Epoch 47/200, Iteration 14/25, Loss: 0.0335\n",
      "Epoch 47/200, Iteration 15/25, Loss: 0.0271\n",
      "Epoch 47/200, Iteration 16/25, Loss: 0.0181\n",
      "Epoch 47/200, Iteration 17/25, Loss: 0.0145\n",
      "Epoch 47/200, Iteration 18/25, Loss: 0.0286\n",
      "Epoch 47/200, Iteration 19/25, Loss: 0.0520\n",
      "Epoch 47/200, Iteration 20/25, Loss: 0.0289\n",
      "Epoch 47/200, Iteration 21/25, Loss: 0.0227\n",
      "Epoch 47/200, Iteration 22/25, Loss: 0.0301\n",
      "Epoch 47/200, Iteration 23/25, Loss: 0.0220\n",
      "Epoch 47/200, Iteration 24/25, Loss: 0.0195\n",
      "Epoch 47/200, Iteration 25/25, Loss: 0.0195\n",
      "Train Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.014287, MRE: 0.860428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.015732, MRE: 2.062600 \n",
      "\n",
      "Epoch 48/200, Iteration 1/25, Loss: 0.0191\n",
      "Epoch 48/200, Iteration 2/25, Loss: 0.0228\n",
      "Epoch 48/200, Iteration 3/25, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 4/25, Loss: 0.0310\n",
      "Epoch 48/200, Iteration 5/25, Loss: 0.0307\n",
      "Epoch 48/200, Iteration 6/25, Loss: 0.0166\n",
      "Epoch 48/200, Iteration 7/25, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 8/25, Loss: 0.0191\n",
      "Epoch 48/200, Iteration 9/25, Loss: 0.0206\n",
      "Epoch 48/200, Iteration 10/25, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 11/25, Loss: 0.0227\n",
      "Epoch 48/200, Iteration 12/25, Loss: 0.0213\n",
      "Epoch 48/200, Iteration 13/25, Loss: 0.0184\n",
      "Epoch 48/200, Iteration 14/25, Loss: 0.0260\n",
      "Epoch 48/200, Iteration 15/25, Loss: 0.0199\n",
      "Epoch 48/200, Iteration 16/25, Loss: 0.0268\n",
      "Epoch 48/200, Iteration 17/25, Loss: 0.0227\n",
      "Epoch 48/200, Iteration 18/25, Loss: 0.0155\n",
      "Epoch 48/200, Iteration 19/25, Loss: 0.0218\n",
      "Epoch 48/200, Iteration 20/25, Loss: 0.0236\n",
      "Epoch 48/200, Iteration 21/25, Loss: 0.0194\n",
      "Epoch 48/200, Iteration 22/25, Loss: 0.0179\n",
      "Epoch 48/200, Iteration 23/25, Loss: 0.0351\n",
      "Epoch 48/200, Iteration 24/25, Loss: 0.0378\n",
      "Epoch 48/200, Iteration 25/25, Loss: 0.0167\n",
      "Train Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.016821, MRE: 0.625182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.019288, MRE: 3.002423 \n",
      "\n",
      "Epoch 49/200, Iteration 1/25, Loss: 0.0218\n",
      "Epoch 49/200, Iteration 2/25, Loss: 0.0148\n",
      "Epoch 49/200, Iteration 3/25, Loss: 0.0430\n",
      "Epoch 49/200, Iteration 4/25, Loss: 0.0544\n",
      "Epoch 49/200, Iteration 5/25, Loss: 0.0372\n",
      "Epoch 49/200, Iteration 6/25, Loss: 0.0296\n",
      "Epoch 49/200, Iteration 7/25, Loss: 0.0305\n",
      "Epoch 49/200, Iteration 8/25, Loss: 0.0162\n",
      "Epoch 49/200, Iteration 9/25, Loss: 0.0196\n",
      "Epoch 49/200, Iteration 10/25, Loss: 0.0191\n",
      "Epoch 49/200, Iteration 11/25, Loss: 0.0290\n",
      "Epoch 49/200, Iteration 12/25, Loss: 0.0240\n",
      "Epoch 49/200, Iteration 13/25, Loss: 0.0254\n",
      "Epoch 49/200, Iteration 14/25, Loss: 0.0148\n",
      "Epoch 49/200, Iteration 15/25, Loss: 0.0205\n",
      "Epoch 49/200, Iteration 16/25, Loss: 0.0243\n",
      "Epoch 49/200, Iteration 17/25, Loss: 0.0384\n",
      "Epoch 49/200, Iteration 18/25, Loss: 0.0304\n",
      "Epoch 49/200, Iteration 19/25, Loss: 0.0213\n",
      "Epoch 49/200, Iteration 20/25, Loss: 0.0173\n",
      "Epoch 49/200, Iteration 21/25, Loss: 0.0190\n",
      "Epoch 49/200, Iteration 22/25, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 23/25, Loss: 0.0219\n",
      "Epoch 49/200, Iteration 24/25, Loss: 0.0163\n",
      "Epoch 49/200, Iteration 25/25, Loss: 0.0154\n",
      "Train Error: \n",
      " Accuracy: 63.75%, Avg loss: 0.012892, MRE: 1.001420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.014594, MRE: 0.944764 \n",
      "\n",
      "Epoch 50/200, Iteration 1/25, Loss: 0.0213\n",
      "Epoch 50/200, Iteration 2/25, Loss: 0.0157\n",
      "Epoch 50/200, Iteration 3/25, Loss: 0.0228\n",
      "Epoch 50/200, Iteration 4/25, Loss: 0.0274\n",
      "Epoch 50/200, Iteration 5/25, Loss: 0.0348\n",
      "Epoch 50/200, Iteration 6/25, Loss: 0.0243\n",
      "Epoch 50/200, Iteration 7/25, Loss: 0.0289\n",
      "Epoch 50/200, Iteration 8/25, Loss: 0.0209\n",
      "Epoch 50/200, Iteration 9/25, Loss: 0.0430\n",
      "Epoch 50/200, Iteration 10/25, Loss: 0.0207\n",
      "Epoch 50/200, Iteration 11/25, Loss: 0.0277\n",
      "Epoch 50/200, Iteration 12/25, Loss: 0.0263\n",
      "Epoch 50/200, Iteration 13/25, Loss: 0.0232\n",
      "Epoch 50/200, Iteration 14/25, Loss: 0.0172\n",
      "Epoch 50/200, Iteration 15/25, Loss: 0.0170\n",
      "Epoch 50/200, Iteration 16/25, Loss: 0.0626\n",
      "Epoch 50/200, Iteration 17/25, Loss: 0.0167\n",
      "Epoch 50/200, Iteration 18/25, Loss: 0.0202\n",
      "Epoch 50/200, Iteration 19/25, Loss: 0.0231\n",
      "Epoch 50/200, Iteration 20/25, Loss: 0.0147\n",
      "Epoch 50/200, Iteration 21/25, Loss: 0.0285\n",
      "Epoch 50/200, Iteration 22/25, Loss: 0.0168\n",
      "Epoch 50/200, Iteration 23/25, Loss: 0.0342\n",
      "Epoch 50/200, Iteration 24/25, Loss: 0.0267\n",
      "Epoch 50/200, Iteration 25/25, Loss: 0.0198\n",
      "Train Error: \n",
      " Accuracy: 53.37%, Avg loss: 0.022033, MRE: 0.688045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.024232, MRE: 3.354548 \n",
      "\n",
      "Epoch 51/200, Iteration 1/25, Loss: 0.0189\n",
      "Epoch 51/200, Iteration 2/25, Loss: 0.0201\n",
      "Epoch 51/200, Iteration 3/25, Loss: 0.0208\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients  \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    #scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    scheduler.step(tr_loss) # LR scheduler step für reduceonPlateau\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f9848",
   "metadata": {},
   "source": [
    "#### Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_real = []\n",
    "xi_pred = []\n",
    "for (X,y) in train_dataloader:\n",
    "    xi_real = np.append(xi_real, y.numpy())\n",
    "    xi_pred = np.append(xi_pred, net(X).detach().numpy())\n",
    "\n",
    "xi_real_test = []\n",
    "xi_pred_test = []\n",
    "for (X,y) in test_dataloader:\n",
    "    xi_real_test = np.append(xi_real_test, y.numpy())\n",
    "    xi_pred_test = np.append(xi_pred_test, net(X).detach().numpy())\n",
    "\n",
    "print('Training Dataset: R^2 =', r2(xi_real,xi_pred))\n",
    "print('Test Dataset: R^2 =', r2(xi_real_test,xi_pred_test))\n",
    "print('Max Error Training: |xi - xi_pred| =', max_error(xi_real, xi_pred))\n",
    "print('Max Error Test: |xi - xi_pred| =', max_error(xi_real_test, xi_pred_test))\n",
    "\n",
    "# find the boundaries of X and Y values\n",
    "bounds = (min(xi_real.min(), xi_pred.min()) - int(0.1 * xi_pred.min()), max(xi_real.max(), xi_pred.max())+ int(0.1 * xi_pred.max()))\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize =(10,10))\n",
    "\n",
    "# # Reset the limits\n",
    "# ax[0] = plt.gca()\n",
    "ax[0].set_xlim(bounds)\n",
    "ax[0].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[0].plot(xi_real, xi_pred, '.')\n",
    "ax[0].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[0].transAxes)\n",
    "ax[0].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0].set_title('Train Data')\n",
    "#ax[0].legend(['$\\\\mathregular{R^2}$ = ', r2(xi_real,xi_pred)], markerscale=0)\n",
    "\n",
    "# Reset the limits\n",
    "#ax[1] = plt.gca()\n",
    "ax[1].set_xlim(bounds)\n",
    "ax[1].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[1].plot(xi_real_test, xi_pred_test, '.')\n",
    "ax[1].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[1].transAxes)\n",
    "ax[1].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1].set_title('Test Data')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#fig.suptitle(\"Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390bab",
   "metadata": {},
   "source": [
    "#### Plot Fehler vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbf7c2",
   "metadata": {},
   "source": [
    "#### Plot Loss vs Variable Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake = []\n",
    "param_T = []\n",
    "param_p = []\n",
    "param_x_H2 = []\n",
    "param_x_N2 = []\n",
    "param_x_NH3 = []\n",
    "for X,y in train_dataloader:\n",
    "    mistake = np.append(mistake, abs(y - net(X).detach().numpy()))\n",
    "    param_T = np.append(param_T, X[:,0])\n",
    "    param_p = np.append(param_p, X[:,1])\n",
    "    param_x_H2 = np.append(param_x_H2, X[:,2])\n",
    "    param_x_N2 = np.append(param_x_N2, X[:,3])\n",
    "    param_x_NH3 = np.append(param_x_NH3, X[:,4])\n",
    "    \n",
    "# train_parameters, train_xi = next(iter(train_dataloader))\n",
    "# y = abs(train_xi - net(train_parameters).detach().numpy())\n",
    "# #[T, p ,x_H2, x_N2, x_NH3]\n",
    "# x = [train_parameters[:,0], train_parameters[:,1], train_parameters[:,2], train_parameters[:,3], train_parameters[:,4]]\n",
    "\n",
    "# print(param_T[0])\n",
    "# print(param_T)\n",
    "# print(mistake)\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize = (10, 5), gridspec_kw={'width_ratios': [2,2,3]})\n",
    "\n",
    "ax[0].plot(param_T, mistake, '.', markersize = 2)\n",
    "ax[0].set(xlabel = '$T$ / K', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[1].plot(param_p, mistake, '.', markersize = 2)\n",
    "ax[1].set(xlabel = '$p$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[2].plot(param_x_H2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[2].plot(param_x_N2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{N_2}}$')\n",
    "ax[2].plot(param_x_NH3, mistake, '.', markersize = 2, label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[2].set(xlabel = '$x\\mathregular{_{NH_3}}$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[2].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[2].set\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418caa55",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241eab8",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b043958",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lnorm = nn.LayerNorm(5)\n",
    "Bnorm = nn.BatchNorm1d(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    #print(y.reshape((-1,1)))\n",
    "    print(Bnorm(X).mean(dim=0))\n",
    "    print(Bnorm(X))\n",
    "    print(Lnorm(X))\n",
    "    print((Lnorm(X.permute(0,2,1))).permute(0,2,1))\n",
    "    print(Lnorm(X).mean(dim=0))\n",
    "    print(Lnorm(X).mean(dim=1))\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b867dae",
   "metadata": {},
   "source": [
    "#### Histogramme Verteilung von $xi$ und $x{_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(xi)\n",
    "plt.hist(x_0[:,0],bins=100)\n",
    "plt.hist(x_0[:,1],bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332126b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
