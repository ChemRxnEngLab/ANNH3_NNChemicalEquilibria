{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ReduceLROnPlateau\n",
    "from sklearn.metrics import r2_score as r2\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "# from sklearn.metrics import mean_absolute_error as MAE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.Linear(input_size, hidden1_size), #Lineare Transformation mit gespeicherten weights und biases\n",
    "            #nn.LayerNorm(hidden1_size),\n",
    "            nn.Tanh(), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            #nn.LayerNorm(hidden2_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden2_size, hidden3_size),\n",
    "            #nn.LayerNorm(hidden3_size),\n",
    "            nn.Tanh(),\n",
    "            #nn.SELU(),\n",
    "            nn.Linear(hidden3_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (6): Tanh()\n",
      "    (7): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset_10000.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#T = log10(T)\n",
    "# T = T / 850\n",
    "# p = p / 1000\n",
    "\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[30, 70, 100], gamma = 0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 10, threshold = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 1/250, Loss: 0.1269\n",
      "Epoch 1/200, Iteration 2/250, Loss: 1.6751\n",
      "Epoch 1/200, Iteration 3/250, Loss: 1.8769\n",
      "Epoch 1/200, Iteration 4/250, Loss: 1.9910\n",
      "Epoch 1/200, Iteration 5/250, Loss: 0.6608\n",
      "Epoch 1/200, Iteration 6/250, Loss: 0.5706\n",
      "Epoch 1/200, Iteration 7/250, Loss: 0.7919\n",
      "Epoch 1/200, Iteration 8/250, Loss: 0.7496\n",
      "Epoch 1/200, Iteration 9/250, Loss: 0.6037\n",
      "Epoch 1/200, Iteration 10/250, Loss: 0.3833\n",
      "Epoch 1/200, Iteration 11/250, Loss: 0.3807\n",
      "Epoch 1/200, Iteration 12/250, Loss: 0.5423\n",
      "Epoch 1/200, Iteration 13/250, Loss: 0.3958\n",
      "Epoch 1/200, Iteration 14/250, Loss: 0.2758\n",
      "Epoch 1/200, Iteration 15/250, Loss: 0.2558\n",
      "Epoch 1/200, Iteration 16/250, Loss: 0.1061\n",
      "Epoch 1/200, Iteration 17/250, Loss: 0.2872\n",
      "Epoch 1/200, Iteration 18/250, Loss: 0.2183\n",
      "Epoch 1/200, Iteration 19/250, Loss: 0.2331\n",
      "Epoch 1/200, Iteration 20/250, Loss: 0.2346\n",
      "Epoch 1/200, Iteration 21/250, Loss: 0.1141\n",
      "Epoch 1/200, Iteration 22/250, Loss: 0.1444\n",
      "Epoch 1/200, Iteration 23/250, Loss: 0.1088\n",
      "Epoch 1/200, Iteration 24/250, Loss: 0.1496\n",
      "Epoch 1/200, Iteration 25/250, Loss: 0.1412\n",
      "Epoch 1/200, Iteration 26/250, Loss: 0.1069\n",
      "Epoch 1/200, Iteration 27/250, Loss: 0.0746\n",
      "Epoch 1/200, Iteration 28/250, Loss: 0.0552\n",
      "Epoch 1/200, Iteration 29/250, Loss: 0.0758\n",
      "Epoch 1/200, Iteration 30/250, Loss: 0.1021\n",
      "Epoch 1/200, Iteration 31/250, Loss: 0.0861\n",
      "Epoch 1/200, Iteration 32/250, Loss: 0.0885\n",
      "Epoch 1/200, Iteration 33/250, Loss: 0.0725\n",
      "Epoch 1/200, Iteration 34/250, Loss: 0.1787\n",
      "Epoch 1/200, Iteration 35/250, Loss: 0.1200\n",
      "Epoch 1/200, Iteration 36/250, Loss: 0.1028\n",
      "Epoch 1/200, Iteration 37/250, Loss: 0.0968\n",
      "Epoch 1/200, Iteration 38/250, Loss: 0.1384\n",
      "Epoch 1/200, Iteration 39/250, Loss: 0.1535\n",
      "Epoch 1/200, Iteration 40/250, Loss: 0.0668\n",
      "Epoch 1/200, Iteration 41/250, Loss: 0.0843\n",
      "Epoch 1/200, Iteration 42/250, Loss: 0.0708\n",
      "Epoch 1/200, Iteration 43/250, Loss: 0.0826\n",
      "Epoch 1/200, Iteration 44/250, Loss: 0.0819\n",
      "Epoch 1/200, Iteration 45/250, Loss: 0.1116\n",
      "Epoch 1/200, Iteration 46/250, Loss: 0.1235\n",
      "Epoch 1/200, Iteration 47/250, Loss: 0.0545\n",
      "Epoch 1/200, Iteration 48/250, Loss: 0.1302\n",
      "Epoch 1/200, Iteration 49/250, Loss: 0.0543\n",
      "Epoch 1/200, Iteration 50/250, Loss: 0.1031\n",
      "Epoch 1/200, Iteration 51/250, Loss: 0.0933\n",
      "Epoch 1/200, Iteration 52/250, Loss: 0.0530\n",
      "Epoch 1/200, Iteration 53/250, Loss: 0.0708\n",
      "Epoch 1/200, Iteration 54/250, Loss: 0.0408\n",
      "Epoch 1/200, Iteration 55/250, Loss: 0.0909\n",
      "Epoch 1/200, Iteration 56/250, Loss: 0.0598\n",
      "Epoch 1/200, Iteration 57/250, Loss: 0.0831\n",
      "Epoch 1/200, Iteration 58/250, Loss: 0.0931\n",
      "Epoch 1/200, Iteration 59/250, Loss: 0.0614\n",
      "Epoch 1/200, Iteration 60/250, Loss: 0.1009\n",
      "Epoch 1/200, Iteration 61/250, Loss: 0.0739\n",
      "Epoch 1/200, Iteration 62/250, Loss: 0.0985\n",
      "Epoch 1/200, Iteration 63/250, Loss: 0.1083\n",
      "Epoch 1/200, Iteration 64/250, Loss: 0.1223\n",
      "Epoch 1/200, Iteration 65/250, Loss: 0.0359\n",
      "Epoch 1/200, Iteration 66/250, Loss: 0.1052\n",
      "Epoch 1/200, Iteration 67/250, Loss: 0.1114\n",
      "Epoch 1/200, Iteration 68/250, Loss: 0.0968\n",
      "Epoch 1/200, Iteration 69/250, Loss: 0.0675\n",
      "Epoch 1/200, Iteration 70/250, Loss: 0.0726\n",
      "Epoch 1/200, Iteration 71/250, Loss: 0.0490\n",
      "Epoch 1/200, Iteration 72/250, Loss: 0.0657\n",
      "Epoch 1/200, Iteration 73/250, Loss: 0.1094\n",
      "Epoch 1/200, Iteration 74/250, Loss: 0.0604\n",
      "Epoch 1/200, Iteration 75/250, Loss: 0.0462\n",
      "Epoch 1/200, Iteration 76/250, Loss: 0.1234\n",
      "Epoch 1/200, Iteration 77/250, Loss: 0.1197\n",
      "Epoch 1/200, Iteration 78/250, Loss: 0.0756\n",
      "Epoch 1/200, Iteration 79/250, Loss: 0.1048\n",
      "Epoch 1/200, Iteration 80/250, Loss: 0.0900\n",
      "Epoch 1/200, Iteration 81/250, Loss: 0.1215\n",
      "Epoch 1/200, Iteration 82/250, Loss: 0.0517\n",
      "Epoch 1/200, Iteration 83/250, Loss: 0.0429\n",
      "Epoch 1/200, Iteration 84/250, Loss: 0.0664\n",
      "Epoch 1/200, Iteration 85/250, Loss: 0.0442\n",
      "Epoch 1/200, Iteration 86/250, Loss: 0.0986\n",
      "Epoch 1/200, Iteration 87/250, Loss: 0.0588\n",
      "Epoch 1/200, Iteration 88/250, Loss: 0.1230\n",
      "Epoch 1/200, Iteration 89/250, Loss: 0.1455\n",
      "Epoch 1/200, Iteration 90/250, Loss: 0.0625\n",
      "Epoch 1/200, Iteration 91/250, Loss: 0.1469\n",
      "Epoch 1/200, Iteration 92/250, Loss: 0.1675\n",
      "Epoch 1/200, Iteration 93/250, Loss: 0.0443\n",
      "Epoch 1/200, Iteration 94/250, Loss: 0.0935\n",
      "Epoch 1/200, Iteration 95/250, Loss: 0.0592\n",
      "Epoch 1/200, Iteration 96/250, Loss: 0.0899\n",
      "Epoch 1/200, Iteration 97/250, Loss: 0.0745\n",
      "Epoch 1/200, Iteration 98/250, Loss: 0.0652\n",
      "Epoch 1/200, Iteration 99/250, Loss: 0.0495\n",
      "Epoch 1/200, Iteration 100/250, Loss: 0.0587\n",
      "Epoch 1/200, Iteration 101/250, Loss: 0.0918\n",
      "Epoch 1/200, Iteration 102/250, Loss: 0.0771\n",
      "Epoch 1/200, Iteration 103/250, Loss: 0.0371\n",
      "Epoch 1/200, Iteration 104/250, Loss: 0.1078\n",
      "Epoch 1/200, Iteration 105/250, Loss: 0.0448\n",
      "Epoch 1/200, Iteration 106/250, Loss: 0.0366\n",
      "Epoch 1/200, Iteration 107/250, Loss: 0.0613\n",
      "Epoch 1/200, Iteration 108/250, Loss: 0.0653\n",
      "Epoch 1/200, Iteration 109/250, Loss: 0.0448\n",
      "Epoch 1/200, Iteration 110/250, Loss: 0.0697\n",
      "Epoch 1/200, Iteration 111/250, Loss: 0.1120\n",
      "Epoch 1/200, Iteration 112/250, Loss: 0.0613\n",
      "Epoch 1/200, Iteration 113/250, Loss: 0.0296\n",
      "Epoch 1/200, Iteration 114/250, Loss: 0.0523\n",
      "Epoch 1/200, Iteration 115/250, Loss: 0.0422\n",
      "Epoch 1/200, Iteration 116/250, Loss: 0.0789\n",
      "Epoch 1/200, Iteration 117/250, Loss: 0.0554\n",
      "Epoch 1/200, Iteration 118/250, Loss: 0.0383\n",
      "Epoch 1/200, Iteration 119/250, Loss: 0.0408\n",
      "Epoch 1/200, Iteration 120/250, Loss: 0.0713\n",
      "Epoch 1/200, Iteration 121/250, Loss: 0.0405\n",
      "Epoch 1/200, Iteration 122/250, Loss: 0.0585\n",
      "Epoch 1/200, Iteration 123/250, Loss: 0.0428\n",
      "Epoch 1/200, Iteration 124/250, Loss: 0.0743\n",
      "Epoch 1/200, Iteration 125/250, Loss: 0.0666\n",
      "Epoch 1/200, Iteration 126/250, Loss: 0.0577\n",
      "Epoch 1/200, Iteration 127/250, Loss: 0.0945\n",
      "Epoch 1/200, Iteration 128/250, Loss: 0.0371\n",
      "Epoch 1/200, Iteration 129/250, Loss: 0.0724\n",
      "Epoch 1/200, Iteration 130/250, Loss: 0.0786\n",
      "Epoch 1/200, Iteration 131/250, Loss: 0.0579\n",
      "Epoch 1/200, Iteration 132/250, Loss: 0.0858\n",
      "Epoch 1/200, Iteration 133/250, Loss: 0.1094\n",
      "Epoch 1/200, Iteration 134/250, Loss: 0.0640\n",
      "Epoch 1/200, Iteration 135/250, Loss: 0.0900\n",
      "Epoch 1/200, Iteration 136/250, Loss: 0.0994\n",
      "Epoch 1/200, Iteration 137/250, Loss: 0.0489\n",
      "Epoch 1/200, Iteration 138/250, Loss: 0.0543\n",
      "Epoch 1/200, Iteration 139/250, Loss: 0.0603\n",
      "Epoch 1/200, Iteration 140/250, Loss: 0.0615\n",
      "Epoch 1/200, Iteration 141/250, Loss: 0.0427\n",
      "Epoch 1/200, Iteration 142/250, Loss: 0.0568\n",
      "Epoch 1/200, Iteration 143/250, Loss: 0.0512\n",
      "Epoch 1/200, Iteration 144/250, Loss: 0.0279\n",
      "Epoch 1/200, Iteration 145/250, Loss: 0.0535\n",
      "Epoch 1/200, Iteration 146/250, Loss: 0.0584\n",
      "Epoch 1/200, Iteration 147/250, Loss: 0.0388\n",
      "Epoch 1/200, Iteration 148/250, Loss: 0.0497\n",
      "Epoch 1/200, Iteration 149/250, Loss: 0.0489\n",
      "Epoch 1/200, Iteration 150/250, Loss: 0.0567\n",
      "Epoch 1/200, Iteration 151/250, Loss: 0.0663\n",
      "Epoch 1/200, Iteration 152/250, Loss: 0.0543\n",
      "Epoch 1/200, Iteration 153/250, Loss: 0.0444\n",
      "Epoch 1/200, Iteration 154/250, Loss: 0.0401\n",
      "Epoch 1/200, Iteration 155/250, Loss: 0.0507\n",
      "Epoch 1/200, Iteration 156/250, Loss: 0.0429\n",
      "Epoch 1/200, Iteration 157/250, Loss: 0.0420\n",
      "Epoch 1/200, Iteration 158/250, Loss: 0.0411\n",
      "Epoch 1/200, Iteration 159/250, Loss: 0.0384\n",
      "Epoch 1/200, Iteration 160/250, Loss: 0.0501\n",
      "Epoch 1/200, Iteration 161/250, Loss: 0.0468\n",
      "Epoch 1/200, Iteration 162/250, Loss: 0.0650\n",
      "Epoch 1/200, Iteration 163/250, Loss: 0.0324\n",
      "Epoch 1/200, Iteration 164/250, Loss: 0.0359\n",
      "Epoch 1/200, Iteration 165/250, Loss: 0.0547\n",
      "Epoch 1/200, Iteration 166/250, Loss: 0.0362\n",
      "Epoch 1/200, Iteration 167/250, Loss: 0.0396\n",
      "Epoch 1/200, Iteration 168/250, Loss: 0.0344\n",
      "Epoch 1/200, Iteration 169/250, Loss: 0.0564\n",
      "Epoch 1/200, Iteration 170/250, Loss: 0.0458\n",
      "Epoch 1/200, Iteration 171/250, Loss: 0.0657\n",
      "Epoch 1/200, Iteration 172/250, Loss: 0.0330\n",
      "Epoch 1/200, Iteration 173/250, Loss: 0.0733\n",
      "Epoch 1/200, Iteration 174/250, Loss: 0.0320\n",
      "Epoch 1/200, Iteration 175/250, Loss: 0.0934\n",
      "Epoch 1/200, Iteration 176/250, Loss: 0.0781\n",
      "Epoch 1/200, Iteration 177/250, Loss: 0.0499\n",
      "Epoch 1/200, Iteration 178/250, Loss: 0.0491\n",
      "Epoch 1/200, Iteration 179/250, Loss: 0.0297\n",
      "Epoch 1/200, Iteration 180/250, Loss: 0.0428\n",
      "Epoch 1/200, Iteration 181/250, Loss: 0.0384\n",
      "Epoch 1/200, Iteration 182/250, Loss: 0.0717\n",
      "Epoch 1/200, Iteration 183/250, Loss: 0.0480\n",
      "Epoch 1/200, Iteration 184/250, Loss: 0.0740\n",
      "Epoch 1/200, Iteration 185/250, Loss: 0.1231\n",
      "Epoch 1/200, Iteration 186/250, Loss: 0.0539\n",
      "Epoch 1/200, Iteration 187/250, Loss: 0.0561\n",
      "Epoch 1/200, Iteration 188/250, Loss: 0.0459\n",
      "Epoch 1/200, Iteration 189/250, Loss: 0.0634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Iteration 190/250, Loss: 0.0702\n",
      "Epoch 1/200, Iteration 191/250, Loss: 0.0371\n",
      "Epoch 1/200, Iteration 192/250, Loss: 0.0361\n",
      "Epoch 1/200, Iteration 193/250, Loss: 0.0476\n",
      "Epoch 1/200, Iteration 194/250, Loss: 0.0436\n",
      "Epoch 1/200, Iteration 195/250, Loss: 0.0419\n",
      "Epoch 1/200, Iteration 196/250, Loss: 0.0431\n",
      "Epoch 1/200, Iteration 197/250, Loss: 0.0649\n",
      "Epoch 1/200, Iteration 198/250, Loss: 0.0620\n",
      "Epoch 1/200, Iteration 199/250, Loss: 0.0799\n",
      "Epoch 1/200, Iteration 200/250, Loss: 0.0581\n",
      "Epoch 1/200, Iteration 201/250, Loss: 0.0762\n",
      "Epoch 1/200, Iteration 202/250, Loss: 0.0763\n",
      "Epoch 1/200, Iteration 203/250, Loss: 0.0750\n",
      "Epoch 1/200, Iteration 204/250, Loss: 0.0504\n",
      "Epoch 1/200, Iteration 205/250, Loss: 0.0686\n",
      "Epoch 1/200, Iteration 206/250, Loss: 0.0843\n",
      "Epoch 1/200, Iteration 207/250, Loss: 0.0361\n",
      "Epoch 1/200, Iteration 208/250, Loss: 0.0721\n",
      "Epoch 1/200, Iteration 209/250, Loss: 0.0420\n",
      "Epoch 1/200, Iteration 210/250, Loss: 0.0401\n",
      "Epoch 1/200, Iteration 211/250, Loss: 0.0676\n",
      "Epoch 1/200, Iteration 212/250, Loss: 0.0508\n",
      "Epoch 1/200, Iteration 213/250, Loss: 0.0518\n",
      "Epoch 1/200, Iteration 214/250, Loss: 0.0484\n",
      "Epoch 1/200, Iteration 215/250, Loss: 0.0374\n",
      "Epoch 1/200, Iteration 216/250, Loss: 0.0390\n",
      "Epoch 1/200, Iteration 217/250, Loss: 0.0480\n",
      "Epoch 1/200, Iteration 218/250, Loss: 0.0508\n",
      "Epoch 1/200, Iteration 219/250, Loss: 0.0467\n",
      "Epoch 1/200, Iteration 220/250, Loss: 0.0383\n",
      "Epoch 1/200, Iteration 221/250, Loss: 0.0551\n",
      "Epoch 1/200, Iteration 222/250, Loss: 0.0582\n",
      "Epoch 1/200, Iteration 223/250, Loss: 0.0546\n",
      "Epoch 1/200, Iteration 224/250, Loss: 0.0328\n",
      "Epoch 1/200, Iteration 225/250, Loss: 0.0324\n",
      "Epoch 1/200, Iteration 226/250, Loss: 0.0375\n",
      "Epoch 1/200, Iteration 227/250, Loss: 0.0603\n",
      "Epoch 1/200, Iteration 228/250, Loss: 0.0553\n",
      "Epoch 1/200, Iteration 229/250, Loss: 0.0474\n",
      "Epoch 1/200, Iteration 230/250, Loss: 0.0381\n",
      "Epoch 1/200, Iteration 231/250, Loss: 0.0673\n",
      "Epoch 1/200, Iteration 232/250, Loss: 0.0886\n",
      "Epoch 1/200, Iteration 233/250, Loss: 0.0517\n",
      "Epoch 1/200, Iteration 234/250, Loss: 0.0818\n",
      "Epoch 1/200, Iteration 235/250, Loss: 0.0445\n",
      "Epoch 1/200, Iteration 236/250, Loss: 0.0793\n",
      "Epoch 1/200, Iteration 237/250, Loss: 0.0573\n",
      "Epoch 1/200, Iteration 238/250, Loss: 0.0338\n",
      "Epoch 1/200, Iteration 239/250, Loss: 0.0617\n",
      "Epoch 1/200, Iteration 240/250, Loss: 0.0607\n",
      "Epoch 1/200, Iteration 241/250, Loss: 0.0669\n",
      "Epoch 1/200, Iteration 242/250, Loss: 0.0719\n",
      "Epoch 1/200, Iteration 243/250, Loss: 0.0784\n",
      "Epoch 1/200, Iteration 244/250, Loss: 0.0365\n",
      "Epoch 1/200, Iteration 245/250, Loss: 0.0702\n",
      "Epoch 1/200, Iteration 246/250, Loss: 0.0343\n",
      "Epoch 1/200, Iteration 247/250, Loss: 0.0617\n",
      "Epoch 1/200, Iteration 248/250, Loss: 0.0679\n",
      "Epoch 1/200, Iteration 249/250, Loss: 0.0549\n",
      "Epoch 1/200, Iteration 250/250, Loss: 0.0563\n",
      "Train Error: \n",
      " Accuracy: 31.21%, Avg loss: 0.080495, MRE: 6.828295 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 30.35%, Avg loss: 0.080232, MRE: 10.511249 \n",
      "\n",
      "Epoch 2/200, Iteration 1/250, Loss: 0.0778\n",
      "Epoch 2/200, Iteration 2/250, Loss: 0.0753\n",
      "Epoch 2/200, Iteration 3/250, Loss: 0.0288\n",
      "Epoch 2/200, Iteration 4/250, Loss: 0.0764\n",
      "Epoch 2/200, Iteration 5/250, Loss: 0.0665\n",
      "Epoch 2/200, Iteration 6/250, Loss: 0.0304\n",
      "Epoch 2/200, Iteration 7/250, Loss: 0.0357\n",
      "Epoch 2/200, Iteration 8/250, Loss: 0.0483\n",
      "Epoch 2/200, Iteration 9/250, Loss: 0.0532\n",
      "Epoch 2/200, Iteration 10/250, Loss: 0.0493\n",
      "Epoch 2/200, Iteration 11/250, Loss: 0.0464\n",
      "Epoch 2/200, Iteration 12/250, Loss: 0.0405\n",
      "Epoch 2/200, Iteration 13/250, Loss: 0.0234\n",
      "Epoch 2/200, Iteration 14/250, Loss: 0.0304\n",
      "Epoch 2/200, Iteration 15/250, Loss: 0.0391\n",
      "Epoch 2/200, Iteration 16/250, Loss: 0.0374\n",
      "Epoch 2/200, Iteration 17/250, Loss: 0.0344\n",
      "Epoch 2/200, Iteration 18/250, Loss: 0.0589\n",
      "Epoch 2/200, Iteration 19/250, Loss: 0.0585\n",
      "Epoch 2/200, Iteration 20/250, Loss: 0.0254\n",
      "Epoch 2/200, Iteration 21/250, Loss: 0.0477\n",
      "Epoch 2/200, Iteration 22/250, Loss: 0.0536\n",
      "Epoch 2/200, Iteration 23/250, Loss: 0.0455\n",
      "Epoch 2/200, Iteration 24/250, Loss: 0.0324\n",
      "Epoch 2/200, Iteration 25/250, Loss: 0.0441\n",
      "Epoch 2/200, Iteration 26/250, Loss: 0.0433\n",
      "Epoch 2/200, Iteration 27/250, Loss: 0.0361\n",
      "Epoch 2/200, Iteration 28/250, Loss: 0.0396\n",
      "Epoch 2/200, Iteration 29/250, Loss: 0.0275\n",
      "Epoch 2/200, Iteration 30/250, Loss: 0.0305\n",
      "Epoch 2/200, Iteration 31/250, Loss: 0.0622\n",
      "Epoch 2/200, Iteration 32/250, Loss: 0.0425\n",
      "Epoch 2/200, Iteration 33/250, Loss: 0.0287\n",
      "Epoch 2/200, Iteration 34/250, Loss: 0.0517\n",
      "Epoch 2/200, Iteration 35/250, Loss: 0.0654\n",
      "Epoch 2/200, Iteration 36/250, Loss: 0.0500\n",
      "Epoch 2/200, Iteration 37/250, Loss: 0.1204\n",
      "Epoch 2/200, Iteration 38/250, Loss: 0.1157\n",
      "Epoch 2/200, Iteration 39/250, Loss: 0.0252\n",
      "Epoch 2/200, Iteration 40/250, Loss: 0.0545\n",
      "Epoch 2/200, Iteration 41/250, Loss: 0.0269\n",
      "Epoch 2/200, Iteration 42/250, Loss: 0.0449\n",
      "Epoch 2/200, Iteration 43/250, Loss: 0.0376\n",
      "Epoch 2/200, Iteration 44/250, Loss: 0.0487\n",
      "Epoch 2/200, Iteration 45/250, Loss: 0.0341\n",
      "Epoch 2/200, Iteration 46/250, Loss: 0.0348\n",
      "Epoch 2/200, Iteration 47/250, Loss: 0.0460\n",
      "Epoch 2/200, Iteration 48/250, Loss: 0.0344\n",
      "Epoch 2/200, Iteration 49/250, Loss: 0.0265\n",
      "Epoch 2/200, Iteration 50/250, Loss: 0.0397\n",
      "Epoch 2/200, Iteration 51/250, Loss: 0.0448\n",
      "Epoch 2/200, Iteration 52/250, Loss: 0.0332\n",
      "Epoch 2/200, Iteration 53/250, Loss: 0.0299\n",
      "Epoch 2/200, Iteration 54/250, Loss: 0.0496\n",
      "Epoch 2/200, Iteration 55/250, Loss: 0.0526\n",
      "Epoch 2/200, Iteration 56/250, Loss: 0.0252\n",
      "Epoch 2/200, Iteration 57/250, Loss: 0.0384\n",
      "Epoch 2/200, Iteration 58/250, Loss: 0.0479\n",
      "Epoch 2/200, Iteration 59/250, Loss: 0.0349\n",
      "Epoch 2/200, Iteration 60/250, Loss: 0.0438\n",
      "Epoch 2/200, Iteration 61/250, Loss: 0.0451\n",
      "Epoch 2/200, Iteration 62/250, Loss: 0.0598\n",
      "Epoch 2/200, Iteration 63/250, Loss: 0.0234\n",
      "Epoch 2/200, Iteration 64/250, Loss: 0.0563\n",
      "Epoch 2/200, Iteration 65/250, Loss: 0.0666\n",
      "Epoch 2/200, Iteration 66/250, Loss: 0.0398\n",
      "Epoch 2/200, Iteration 67/250, Loss: 0.0581\n",
      "Epoch 2/200, Iteration 68/250, Loss: 0.0373\n",
      "Epoch 2/200, Iteration 69/250, Loss: 0.0401\n",
      "Epoch 2/200, Iteration 70/250, Loss: 0.0954\n",
      "Epoch 2/200, Iteration 71/250, Loss: 0.0712\n",
      "Epoch 2/200, Iteration 72/250, Loss: 0.0331\n",
      "Epoch 2/200, Iteration 73/250, Loss: 0.0811\n",
      "Epoch 2/200, Iteration 74/250, Loss: 0.0923\n",
      "Epoch 2/200, Iteration 75/250, Loss: 0.0575\n",
      "Epoch 2/200, Iteration 76/250, Loss: 0.0519\n",
      "Epoch 2/200, Iteration 77/250, Loss: 0.0427\n",
      "Epoch 2/200, Iteration 78/250, Loss: 0.0982\n",
      "Epoch 2/200, Iteration 79/250, Loss: 0.1119\n",
      "Epoch 2/200, Iteration 80/250, Loss: 0.0476\n",
      "Epoch 2/200, Iteration 81/250, Loss: 0.0817\n",
      "Epoch 2/200, Iteration 82/250, Loss: 0.0825\n",
      "Epoch 2/200, Iteration 83/250, Loss: 0.0517\n",
      "Epoch 2/200, Iteration 84/250, Loss: 0.0616\n",
      "Epoch 2/200, Iteration 85/250, Loss: 0.0745\n",
      "Epoch 2/200, Iteration 86/250, Loss: 0.0422\n",
      "Epoch 2/200, Iteration 87/250, Loss: 0.0560\n",
      "Epoch 2/200, Iteration 88/250, Loss: 0.0871\n",
      "Epoch 2/200, Iteration 89/250, Loss: 0.0731\n",
      "Epoch 2/200, Iteration 90/250, Loss: 0.0778\n",
      "Epoch 2/200, Iteration 91/250, Loss: 0.0420\n",
      "Epoch 2/200, Iteration 92/250, Loss: 0.0581\n",
      "Epoch 2/200, Iteration 93/250, Loss: 0.0824\n",
      "Epoch 2/200, Iteration 94/250, Loss: 0.0498\n",
      "Epoch 2/200, Iteration 95/250, Loss: 0.1192\n",
      "Epoch 2/200, Iteration 96/250, Loss: 0.0557\n",
      "Epoch 2/200, Iteration 97/250, Loss: 0.0966\n",
      "Epoch 2/200, Iteration 98/250, Loss: 0.1565\n",
      "Epoch 2/200, Iteration 99/250, Loss: 0.0453\n",
      "Epoch 2/200, Iteration 100/250, Loss: 0.0836\n",
      "Epoch 2/200, Iteration 101/250, Loss: 0.0905\n",
      "Epoch 2/200, Iteration 102/250, Loss: 0.0293\n",
      "Epoch 2/200, Iteration 103/250, Loss: 0.0512\n",
      "Epoch 2/200, Iteration 104/250, Loss: 0.0900\n",
      "Epoch 2/200, Iteration 105/250, Loss: 0.0539\n",
      "Epoch 2/200, Iteration 106/250, Loss: 0.0706\n",
      "Epoch 2/200, Iteration 107/250, Loss: 0.0531\n",
      "Epoch 2/200, Iteration 108/250, Loss: 0.0807\n",
      "Epoch 2/200, Iteration 109/250, Loss: 0.0810\n",
      "Epoch 2/200, Iteration 110/250, Loss: 0.0530\n",
      "Epoch 2/200, Iteration 111/250, Loss: 0.0548\n",
      "Epoch 2/200, Iteration 112/250, Loss: 0.0296\n",
      "Epoch 2/200, Iteration 113/250, Loss: 0.0249\n",
      "Epoch 2/200, Iteration 114/250, Loss: 0.0548\n",
      "Epoch 2/200, Iteration 115/250, Loss: 0.0579\n",
      "Epoch 2/200, Iteration 116/250, Loss: 0.0485\n",
      "Epoch 2/200, Iteration 117/250, Loss: 0.0525\n",
      "Epoch 2/200, Iteration 118/250, Loss: 0.0394\n",
      "Epoch 2/200, Iteration 119/250, Loss: 0.0802\n",
      "Epoch 2/200, Iteration 120/250, Loss: 0.0817\n",
      "Epoch 2/200, Iteration 121/250, Loss: 0.0431\n",
      "Epoch 2/200, Iteration 122/250, Loss: 0.0886\n",
      "Epoch 2/200, Iteration 123/250, Loss: 0.0577\n",
      "Epoch 2/200, Iteration 124/250, Loss: 0.0605\n",
      "Epoch 2/200, Iteration 125/250, Loss: 0.0710\n",
      "Epoch 2/200, Iteration 126/250, Loss: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Iteration 127/250, Loss: 0.0402\n",
      "Epoch 2/200, Iteration 128/250, Loss: 0.0916\n",
      "Epoch 2/200, Iteration 129/250, Loss: 0.0317\n",
      "Epoch 2/200, Iteration 130/250, Loss: 0.0473\n",
      "Epoch 2/200, Iteration 131/250, Loss: 0.0345\n",
      "Epoch 2/200, Iteration 132/250, Loss: 0.0502\n",
      "Epoch 2/200, Iteration 133/250, Loss: 0.0504\n",
      "Epoch 2/200, Iteration 134/250, Loss: 0.0481\n",
      "Epoch 2/200, Iteration 135/250, Loss: 0.1064\n",
      "Epoch 2/200, Iteration 136/250, Loss: 0.0860\n",
      "Epoch 2/200, Iteration 137/250, Loss: 0.0339\n",
      "Epoch 2/200, Iteration 138/250, Loss: 0.1261\n",
      "Epoch 2/200, Iteration 139/250, Loss: 0.1128\n",
      "Epoch 2/200, Iteration 140/250, Loss: 0.0569\n",
      "Epoch 2/200, Iteration 141/250, Loss: 0.0765\n",
      "Epoch 2/200, Iteration 142/250, Loss: 0.0785\n",
      "Epoch 2/200, Iteration 143/250, Loss: 0.0618\n",
      "Epoch 2/200, Iteration 144/250, Loss: 0.0470\n",
      "Epoch 2/200, Iteration 145/250, Loss: 0.0655\n",
      "Epoch 2/200, Iteration 146/250, Loss: 0.0491\n",
      "Epoch 2/200, Iteration 147/250, Loss: 0.0379\n",
      "Epoch 2/200, Iteration 148/250, Loss: 0.0596\n",
      "Epoch 2/200, Iteration 149/250, Loss: 0.0415\n",
      "Epoch 2/200, Iteration 150/250, Loss: 0.0564\n",
      "Epoch 2/200, Iteration 151/250, Loss: 0.0518\n",
      "Epoch 2/200, Iteration 152/250, Loss: 0.0955\n",
      "Epoch 2/200, Iteration 153/250, Loss: 0.0864\n",
      "Epoch 2/200, Iteration 154/250, Loss: 0.0447\n",
      "Epoch 2/200, Iteration 155/250, Loss: 0.0932\n",
      "Epoch 2/200, Iteration 156/250, Loss: 0.0689\n",
      "Epoch 2/200, Iteration 157/250, Loss: 0.0644\n",
      "Epoch 2/200, Iteration 158/250, Loss: 0.0234\n",
      "Epoch 2/200, Iteration 159/250, Loss: 0.0690\n",
      "Epoch 2/200, Iteration 160/250, Loss: 0.0830\n",
      "Epoch 2/200, Iteration 161/250, Loss: 0.0638\n",
      "Epoch 2/200, Iteration 162/250, Loss: 0.0471\n",
      "Epoch 2/200, Iteration 163/250, Loss: 0.0599\n",
      "Epoch 2/200, Iteration 164/250, Loss: 0.0596\n",
      "Epoch 2/200, Iteration 165/250, Loss: 0.1033\n",
      "Epoch 2/200, Iteration 166/250, Loss: 0.0703\n",
      "Epoch 2/200, Iteration 167/250, Loss: 0.0715\n",
      "Epoch 2/200, Iteration 168/250, Loss: 0.0746\n",
      "Epoch 2/200, Iteration 169/250, Loss: 0.0730\n",
      "Epoch 2/200, Iteration 170/250, Loss: 0.0824\n",
      "Epoch 2/200, Iteration 171/250, Loss: 0.0567\n",
      "Epoch 2/200, Iteration 172/250, Loss: 0.0508\n",
      "Epoch 2/200, Iteration 173/250, Loss: 0.0587\n",
      "Epoch 2/200, Iteration 174/250, Loss: 0.0358\n",
      "Epoch 2/200, Iteration 175/250, Loss: 0.0527\n",
      "Epoch 2/200, Iteration 176/250, Loss: 0.0436\n",
      "Epoch 2/200, Iteration 177/250, Loss: 0.0869\n",
      "Epoch 2/200, Iteration 178/250, Loss: 0.0623\n",
      "Epoch 2/200, Iteration 179/250, Loss: 0.0819\n",
      "Epoch 2/200, Iteration 180/250, Loss: 0.0859\n",
      "Epoch 2/200, Iteration 181/250, Loss: 0.0794\n",
      "Epoch 2/200, Iteration 182/250, Loss: 0.0979\n",
      "Epoch 2/200, Iteration 183/250, Loss: 0.0553\n",
      "Epoch 2/200, Iteration 184/250, Loss: 0.0727\n",
      "Epoch 2/200, Iteration 185/250, Loss: 0.0762\n",
      "Epoch 2/200, Iteration 186/250, Loss: 0.0710\n",
      "Epoch 2/200, Iteration 187/250, Loss: 0.0699\n",
      "Epoch 2/200, Iteration 188/250, Loss: 0.0479\n",
      "Epoch 2/200, Iteration 189/250, Loss: 0.0485\n",
      "Epoch 2/200, Iteration 190/250, Loss: 0.0442\n",
      "Epoch 2/200, Iteration 191/250, Loss: 0.0624\n",
      "Epoch 2/200, Iteration 192/250, Loss: 0.0530\n",
      "Epoch 2/200, Iteration 193/250, Loss: 0.0403\n",
      "Epoch 2/200, Iteration 194/250, Loss: 0.0666\n",
      "Epoch 2/200, Iteration 195/250, Loss: 0.0430\n",
      "Epoch 2/200, Iteration 196/250, Loss: 0.0586\n",
      "Epoch 2/200, Iteration 197/250, Loss: 0.0476\n",
      "Epoch 2/200, Iteration 198/250, Loss: 0.0629\n",
      "Epoch 2/200, Iteration 199/250, Loss: 0.0299\n",
      "Epoch 2/200, Iteration 200/250, Loss: 0.1183\n",
      "Epoch 2/200, Iteration 201/250, Loss: 0.0527\n",
      "Epoch 2/200, Iteration 202/250, Loss: 0.1858\n",
      "Epoch 2/200, Iteration 203/250, Loss: 0.2213\n",
      "Epoch 2/200, Iteration 204/250, Loss: 0.0765\n",
      "Epoch 2/200, Iteration 205/250, Loss: 0.1752\n",
      "Epoch 2/200, Iteration 206/250, Loss: 0.2509\n",
      "Epoch 2/200, Iteration 207/250, Loss: 0.1462\n",
      "Epoch 2/200, Iteration 208/250, Loss: 0.1110\n",
      "Epoch 2/200, Iteration 209/250, Loss: 0.1740\n",
      "Epoch 2/200, Iteration 210/250, Loss: 0.1433\n",
      "Epoch 2/200, Iteration 211/250, Loss: 0.0473\n",
      "Epoch 2/200, Iteration 212/250, Loss: 0.0834\n",
      "Epoch 2/200, Iteration 213/250, Loss: 0.1161\n",
      "Epoch 2/200, Iteration 214/250, Loss: 0.1468\n",
      "Epoch 2/200, Iteration 215/250, Loss: 0.0559\n",
      "Epoch 2/200, Iteration 216/250, Loss: 0.1293\n",
      "Epoch 2/200, Iteration 217/250, Loss: 0.1181\n",
      "Epoch 2/200, Iteration 218/250, Loss: 0.1067\n",
      "Epoch 2/200, Iteration 219/250, Loss: 0.1319\n",
      "Epoch 2/200, Iteration 220/250, Loss: 0.1073\n",
      "Epoch 2/200, Iteration 221/250, Loss: 0.1244\n",
      "Epoch 2/200, Iteration 222/250, Loss: 0.1081\n",
      "Epoch 2/200, Iteration 223/250, Loss: 0.0850\n",
      "Epoch 2/200, Iteration 224/250, Loss: 0.0958\n",
      "Epoch 2/200, Iteration 225/250, Loss: 0.0508\n",
      "Epoch 2/200, Iteration 226/250, Loss: 0.0794\n",
      "Epoch 2/200, Iteration 227/250, Loss: 0.0651\n",
      "Epoch 2/200, Iteration 228/250, Loss: 0.0661\n",
      "Epoch 2/200, Iteration 229/250, Loss: 0.1296\n",
      "Epoch 2/200, Iteration 230/250, Loss: 0.0793\n",
      "Epoch 2/200, Iteration 231/250, Loss: 0.1377\n",
      "Epoch 2/200, Iteration 232/250, Loss: 0.0652\n",
      "Epoch 2/200, Iteration 233/250, Loss: 0.1499\n",
      "Epoch 2/200, Iteration 234/250, Loss: 0.0750\n",
      "Epoch 2/200, Iteration 235/250, Loss: 0.1561\n",
      "Epoch 2/200, Iteration 236/250, Loss: 0.0493\n",
      "Epoch 2/200, Iteration 237/250, Loss: 0.0742\n",
      "Epoch 2/200, Iteration 238/250, Loss: 0.0566\n",
      "Epoch 2/200, Iteration 239/250, Loss: 0.0802\n",
      "Epoch 2/200, Iteration 240/250, Loss: 0.0383\n",
      "Epoch 2/200, Iteration 241/250, Loss: 0.0415\n",
      "Epoch 2/200, Iteration 242/250, Loss: 0.1140\n",
      "Epoch 2/200, Iteration 243/250, Loss: 0.0409\n",
      "Epoch 2/200, Iteration 244/250, Loss: 0.1276\n",
      "Epoch 2/200, Iteration 245/250, Loss: 0.0811\n",
      "Epoch 2/200, Iteration 246/250, Loss: 0.1424\n",
      "Epoch 2/200, Iteration 247/250, Loss: 0.0967\n",
      "Epoch 2/200, Iteration 248/250, Loss: 0.1427\n",
      "Epoch 2/200, Iteration 249/250, Loss: 0.1422\n",
      "Epoch 2/200, Iteration 250/250, Loss: 0.0518\n",
      "Train Error: \n",
      " Accuracy: 63.76%, Avg loss: 0.073733, MRE: 6.108930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.074829, MRE: 10.302530 \n",
      "\n",
      "Epoch 3/200, Iteration 1/250, Loss: 0.0799\n",
      "Epoch 3/200, Iteration 2/250, Loss: 0.0426\n",
      "Epoch 3/200, Iteration 3/250, Loss: 0.0510\n",
      "Epoch 3/200, Iteration 4/250, Loss: 0.0339\n",
      "Epoch 3/200, Iteration 5/250, Loss: 0.0408\n",
      "Epoch 3/200, Iteration 6/250, Loss: 0.0527\n",
      "Epoch 3/200, Iteration 7/250, Loss: 0.0616\n",
      "Epoch 3/200, Iteration 8/250, Loss: 0.0591\n",
      "Epoch 3/200, Iteration 9/250, Loss: 0.1074\n",
      "Epoch 3/200, Iteration 10/250, Loss: 0.0957\n",
      "Epoch 3/200, Iteration 11/250, Loss: 0.1073\n",
      "Epoch 3/200, Iteration 12/250, Loss: 0.1248\n",
      "Epoch 3/200, Iteration 13/250, Loss: 0.0613\n",
      "Epoch 3/200, Iteration 14/250, Loss: 0.0522\n",
      "Epoch 3/200, Iteration 15/250, Loss: 0.0524\n",
      "Epoch 3/200, Iteration 16/250, Loss: 0.0652\n",
      "Epoch 3/200, Iteration 17/250, Loss: 0.0265\n",
      "Epoch 3/200, Iteration 18/250, Loss: 0.0737\n",
      "Epoch 3/200, Iteration 19/250, Loss: 0.0417\n",
      "Epoch 3/200, Iteration 20/250, Loss: 0.0553\n",
      "Epoch 3/200, Iteration 21/250, Loss: 0.0917\n",
      "Epoch 3/200, Iteration 22/250, Loss: 0.0850\n",
      "Epoch 3/200, Iteration 23/250, Loss: 0.0622\n",
      "Epoch 3/200, Iteration 24/250, Loss: 0.0732\n",
      "Epoch 3/200, Iteration 25/250, Loss: 0.0758\n",
      "Epoch 3/200, Iteration 26/250, Loss: 0.0881\n",
      "Epoch 3/200, Iteration 27/250, Loss: 0.1103\n",
      "Epoch 3/200, Iteration 28/250, Loss: 0.0453\n",
      "Epoch 3/200, Iteration 29/250, Loss: 0.0656\n",
      "Epoch 3/200, Iteration 30/250, Loss: 0.1208\n",
      "Epoch 3/200, Iteration 31/250, Loss: 0.0815\n",
      "Epoch 3/200, Iteration 32/250, Loss: 0.0732\n",
      "Epoch 3/200, Iteration 33/250, Loss: 0.0336\n",
      "Epoch 3/200, Iteration 34/250, Loss: 0.0592\n",
      "Epoch 3/200, Iteration 35/250, Loss: 0.0768\n",
      "Epoch 3/200, Iteration 36/250, Loss: 0.0998\n",
      "Epoch 3/200, Iteration 37/250, Loss: 0.1284\n",
      "Epoch 3/200, Iteration 38/250, Loss: 0.0667\n",
      "Epoch 3/200, Iteration 39/250, Loss: 0.1004\n",
      "Epoch 3/200, Iteration 40/250, Loss: 0.1264\n",
      "Epoch 3/200, Iteration 41/250, Loss: 0.0772\n",
      "Epoch 3/200, Iteration 42/250, Loss: 0.1061\n",
      "Epoch 3/200, Iteration 43/250, Loss: 0.1724\n",
      "Epoch 3/200, Iteration 44/250, Loss: 0.1047\n",
      "Epoch 3/200, Iteration 45/250, Loss: 0.2102\n",
      "Epoch 3/200, Iteration 46/250, Loss: 0.1634\n",
      "Epoch 3/200, Iteration 47/250, Loss: 0.0992\n",
      "Epoch 3/200, Iteration 48/250, Loss: 0.2127\n",
      "Epoch 3/200, Iteration 49/250, Loss: 0.1512\n",
      "Epoch 3/200, Iteration 50/250, Loss: 0.0668\n",
      "Epoch 3/200, Iteration 51/250, Loss: 0.1832\n",
      "Epoch 3/200, Iteration 52/250, Loss: 0.1820\n",
      "Epoch 3/200, Iteration 53/250, Loss: 0.1718\n",
      "Epoch 3/200, Iteration 54/250, Loss: 0.2114\n",
      "Epoch 3/200, Iteration 55/250, Loss: 0.1862\n",
      "Epoch 3/200, Iteration 56/250, Loss: 0.1341\n",
      "Epoch 3/200, Iteration 57/250, Loss: 0.1375\n",
      "Epoch 3/200, Iteration 58/250, Loss: 0.1159\n",
      "Epoch 3/200, Iteration 59/250, Loss: 0.1345\n",
      "Epoch 3/200, Iteration 60/250, Loss: 0.1394\n",
      "Epoch 3/200, Iteration 61/250, Loss: 0.0735\n",
      "Epoch 3/200, Iteration 62/250, Loss: 0.1089\n",
      "Epoch 3/200, Iteration 63/250, Loss: 0.0527\n",
      "Epoch 3/200, Iteration 64/250, Loss: 0.0734\n",
      "Epoch 3/200, Iteration 65/250, Loss: 0.1292\n",
      "Epoch 3/200, Iteration 66/250, Loss: 0.0446\n",
      "Epoch 3/200, Iteration 67/250, Loss: 0.0985\n",
      "Epoch 3/200, Iteration 68/250, Loss: 0.1037\n",
      "Epoch 3/200, Iteration 69/250, Loss: 0.0704\n",
      "Epoch 3/200, Iteration 70/250, Loss: 0.0846\n",
      "Epoch 3/200, Iteration 71/250, Loss: 0.0805\n",
      "Epoch 3/200, Iteration 72/250, Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Iteration 73/250, Loss: 0.0530\n",
      "Epoch 3/200, Iteration 74/250, Loss: 0.0687\n",
      "Epoch 3/200, Iteration 75/250, Loss: 0.1240\n",
      "Epoch 3/200, Iteration 76/250, Loss: 0.1203\n",
      "Epoch 3/200, Iteration 77/250, Loss: 0.0743\n",
      "Epoch 3/200, Iteration 78/250, Loss: 0.1226\n",
      "Epoch 3/200, Iteration 79/250, Loss: 0.1227\n",
      "Epoch 3/200, Iteration 80/250, Loss: 0.1072\n",
      "Epoch 3/200, Iteration 81/250, Loss: 0.0608\n",
      "Epoch 3/200, Iteration 82/250, Loss: 0.0774\n",
      "Epoch 3/200, Iteration 83/250, Loss: 0.1144\n",
      "Epoch 3/200, Iteration 84/250, Loss: 0.1040\n",
      "Epoch 3/200, Iteration 85/250, Loss: 0.0590\n",
      "Epoch 3/200, Iteration 86/250, Loss: 0.0678\n",
      "Epoch 3/200, Iteration 87/250, Loss: 0.1338\n",
      "Epoch 3/200, Iteration 88/250, Loss: 0.1115\n",
      "Epoch 3/200, Iteration 89/250, Loss: 0.0932\n",
      "Epoch 3/200, Iteration 90/250, Loss: 0.0756\n",
      "Epoch 3/200, Iteration 91/250, Loss: 0.1211\n",
      "Epoch 3/200, Iteration 92/250, Loss: 0.0639\n",
      "Epoch 3/200, Iteration 93/250, Loss: 0.1523\n",
      "Epoch 3/200, Iteration 94/250, Loss: 0.0637\n",
      "Epoch 3/200, Iteration 95/250, Loss: 0.1441\n",
      "Epoch 3/200, Iteration 96/250, Loss: 0.1362\n",
      "Epoch 3/200, Iteration 97/250, Loss: 0.0684\n",
      "Epoch 3/200, Iteration 98/250, Loss: 0.1930\n",
      "Epoch 3/200, Iteration 99/250, Loss: 0.2108\n",
      "Epoch 3/200, Iteration 100/250, Loss: 0.1374\n",
      "Epoch 3/200, Iteration 101/250, Loss: 0.2238\n",
      "Epoch 3/200, Iteration 102/250, Loss: 0.2394\n",
      "Epoch 3/200, Iteration 103/250, Loss: 0.0987\n",
      "Epoch 3/200, Iteration 104/250, Loss: 0.2015\n",
      "Epoch 3/200, Iteration 105/250, Loss: 0.2502\n",
      "Epoch 3/200, Iteration 106/250, Loss: 0.1740\n",
      "Epoch 3/200, Iteration 107/250, Loss: 0.0547\n",
      "Epoch 3/200, Iteration 108/250, Loss: 0.1972\n",
      "Epoch 3/200, Iteration 109/250, Loss: 0.2082\n",
      "Epoch 3/200, Iteration 110/250, Loss: 0.1135\n",
      "Epoch 3/200, Iteration 111/250, Loss: 0.1851\n",
      "Epoch 3/200, Iteration 112/250, Loss: 0.0861\n",
      "Epoch 3/200, Iteration 113/250, Loss: 0.3181\n",
      "Epoch 3/200, Iteration 114/250, Loss: 0.2394\n",
      "Epoch 3/200, Iteration 115/250, Loss: 0.2764\n",
      "Epoch 3/200, Iteration 116/250, Loss: 0.3881\n",
      "Epoch 3/200, Iteration 117/250, Loss: 0.0778\n",
      "Epoch 3/200, Iteration 118/250, Loss: 0.2090\n",
      "Epoch 3/200, Iteration 119/250, Loss: 0.0644\n",
      "Epoch 3/200, Iteration 120/250, Loss: 0.2804\n",
      "Epoch 3/200, Iteration 121/250, Loss: 0.1228\n",
      "Epoch 3/200, Iteration 122/250, Loss: 0.3797\n",
      "Epoch 3/200, Iteration 123/250, Loss: 0.4987\n",
      "Epoch 3/200, Iteration 124/250, Loss: 0.2202\n",
      "Epoch 3/200, Iteration 125/250, Loss: 0.3313\n",
      "Epoch 3/200, Iteration 126/250, Loss: 0.3820\n",
      "Epoch 3/200, Iteration 127/250, Loss: 0.1316\n",
      "Epoch 3/200, Iteration 128/250, Loss: 0.3688\n",
      "Epoch 3/200, Iteration 129/250, Loss: 0.5288\n",
      "Epoch 3/200, Iteration 130/250, Loss: 0.3528\n",
      "Epoch 3/200, Iteration 131/250, Loss: 0.0930\n",
      "Epoch 3/200, Iteration 132/250, Loss: 0.2088\n",
      "Epoch 3/200, Iteration 133/250, Loss: 0.0791\n",
      "Epoch 3/200, Iteration 134/250, Loss: 0.2045\n",
      "Epoch 3/200, Iteration 135/250, Loss: 0.2131\n",
      "Epoch 3/200, Iteration 136/250, Loss: 0.0927\n",
      "Epoch 3/200, Iteration 137/250, Loss: 0.2296\n",
      "Epoch 3/200, Iteration 138/250, Loss: 0.2215\n",
      "Epoch 3/200, Iteration 139/250, Loss: 0.1455\n",
      "Epoch 3/200, Iteration 140/250, Loss: 0.1471\n",
      "Epoch 3/200, Iteration 141/250, Loss: 0.1238\n",
      "Epoch 3/200, Iteration 142/250, Loss: 0.1285\n",
      "Epoch 3/200, Iteration 143/250, Loss: 0.0723\n",
      "Epoch 3/200, Iteration 144/250, Loss: 0.1525\n",
      "Epoch 3/200, Iteration 145/250, Loss: 0.0949\n",
      "Epoch 3/200, Iteration 146/250, Loss: 0.0944\n",
      "Epoch 3/200, Iteration 147/250, Loss: 0.1011\n",
      "Epoch 3/200, Iteration 148/250, Loss: 0.0748\n",
      "Epoch 3/200, Iteration 149/250, Loss: 0.0743\n",
      "Epoch 3/200, Iteration 150/250, Loss: 0.0707\n",
      "Epoch 3/200, Iteration 151/250, Loss: 0.0837\n",
      "Epoch 3/200, Iteration 152/250, Loss: 0.0642\n",
      "Epoch 3/200, Iteration 153/250, Loss: 0.0787\n",
      "Epoch 3/200, Iteration 154/250, Loss: 0.0550\n",
      "Epoch 3/200, Iteration 155/250, Loss: 0.0443\n",
      "Epoch 3/200, Iteration 156/250, Loss: 0.0641\n",
      "Epoch 3/200, Iteration 157/250, Loss: 0.0506\n",
      "Epoch 3/200, Iteration 158/250, Loss: 0.0646\n",
      "Epoch 3/200, Iteration 159/250, Loss: 0.0457\n",
      "Epoch 3/200, Iteration 160/250, Loss: 0.0574\n",
      "Epoch 3/200, Iteration 161/250, Loss: 0.0356\n",
      "Epoch 3/200, Iteration 162/250, Loss: 0.0640\n",
      "Epoch 3/200, Iteration 163/250, Loss: 0.0541\n",
      "Epoch 3/200, Iteration 164/250, Loss: 0.0721\n",
      "Epoch 3/200, Iteration 165/250, Loss: 0.0893\n",
      "Epoch 3/200, Iteration 166/250, Loss: 0.0873\n",
      "Epoch 3/200, Iteration 167/250, Loss: 0.0867\n",
      "Epoch 3/200, Iteration 168/250, Loss: 0.0897\n",
      "Epoch 3/200, Iteration 169/250, Loss: 0.0818\n",
      "Epoch 3/200, Iteration 170/250, Loss: 0.1441\n",
      "Epoch 3/200, Iteration 171/250, Loss: 0.0893\n",
      "Epoch 3/200, Iteration 172/250, Loss: 0.0924\n",
      "Epoch 3/200, Iteration 173/250, Loss: 0.1488\n",
      "Epoch 3/200, Iteration 174/250, Loss: 0.1377\n",
      "Epoch 3/200, Iteration 175/250, Loss: 0.1284\n",
      "Epoch 3/200, Iteration 176/250, Loss: 0.1367\n",
      "Epoch 3/200, Iteration 177/250, Loss: 0.1006\n",
      "Epoch 3/200, Iteration 178/250, Loss: 0.0770\n",
      "Epoch 3/200, Iteration 179/250, Loss: 0.1071\n",
      "Epoch 3/200, Iteration 180/250, Loss: 0.1007\n",
      "Epoch 3/200, Iteration 181/250, Loss: 0.0580\n",
      "Epoch 3/200, Iteration 182/250, Loss: 0.0894\n",
      "Epoch 3/200, Iteration 183/250, Loss: 0.0585\n",
      "Epoch 3/200, Iteration 184/250, Loss: 0.0523\n",
      "Epoch 3/200, Iteration 185/250, Loss: 0.0828\n",
      "Epoch 3/200, Iteration 186/250, Loss: 0.0449\n",
      "Epoch 3/200, Iteration 187/250, Loss: 0.0960\n",
      "Epoch 3/200, Iteration 188/250, Loss: 0.0683\n",
      "Epoch 3/200, Iteration 189/250, Loss: 0.1131\n",
      "Epoch 3/200, Iteration 190/250, Loss: 0.0549\n",
      "Epoch 3/200, Iteration 191/250, Loss: 0.1161\n",
      "Epoch 3/200, Iteration 192/250, Loss: 0.0454\n",
      "Epoch 3/200, Iteration 193/250, Loss: 0.0760\n",
      "Epoch 3/200, Iteration 194/250, Loss: 0.0749\n",
      "Epoch 3/200, Iteration 195/250, Loss: 0.0461\n",
      "Epoch 3/200, Iteration 196/250, Loss: 0.0853\n",
      "Epoch 3/200, Iteration 197/250, Loss: 0.0398\n",
      "Epoch 3/200, Iteration 198/250, Loss: 0.0351\n",
      "Epoch 3/200, Iteration 199/250, Loss: 0.0941\n",
      "Epoch 3/200, Iteration 200/250, Loss: 0.0686\n",
      "Epoch 3/200, Iteration 201/250, Loss: 0.0791\n",
      "Epoch 3/200, Iteration 202/250, Loss: 0.0614\n",
      "Epoch 3/200, Iteration 203/250, Loss: 0.0748\n",
      "Epoch 3/200, Iteration 204/250, Loss: 0.0814\n",
      "Epoch 3/200, Iteration 205/250, Loss: 0.0987\n",
      "Epoch 3/200, Iteration 206/250, Loss: 0.0649\n",
      "Epoch 3/200, Iteration 207/250, Loss: 0.1222\n",
      "Epoch 3/200, Iteration 208/250, Loss: 0.0663\n",
      "Epoch 3/200, Iteration 209/250, Loss: 0.0814\n",
      "Epoch 3/200, Iteration 210/250, Loss: 0.0588\n",
      "Epoch 3/200, Iteration 211/250, Loss: 0.0541\n",
      "Epoch 3/200, Iteration 212/250, Loss: 0.0593\n",
      "Epoch 3/200, Iteration 213/250, Loss: 0.0737\n",
      "Epoch 3/200, Iteration 214/250, Loss: 0.0809\n",
      "Epoch 3/200, Iteration 215/250, Loss: 0.0722\n",
      "Epoch 3/200, Iteration 216/250, Loss: 0.0445\n",
      "Epoch 3/200, Iteration 217/250, Loss: 0.0738\n",
      "Epoch 3/200, Iteration 218/250, Loss: 0.0510\n",
      "Epoch 3/200, Iteration 219/250, Loss: 0.0391\n",
      "Epoch 3/200, Iteration 220/250, Loss: 0.0501\n",
      "Epoch 3/200, Iteration 221/250, Loss: 0.0549\n",
      "Epoch 3/200, Iteration 222/250, Loss: 0.0454\n",
      "Epoch 3/200, Iteration 223/250, Loss: 0.0996\n",
      "Epoch 3/200, Iteration 224/250, Loss: 0.0611\n",
      "Epoch 3/200, Iteration 225/250, Loss: 0.0631\n",
      "Epoch 3/200, Iteration 226/250, Loss: 0.1095\n",
      "Epoch 3/200, Iteration 227/250, Loss: 0.0552\n",
      "Epoch 3/200, Iteration 228/250, Loss: 0.0355\n",
      "Epoch 3/200, Iteration 229/250, Loss: 0.0932\n",
      "Epoch 3/200, Iteration 230/250, Loss: 0.1143\n",
      "Epoch 3/200, Iteration 231/250, Loss: 0.0566\n",
      "Epoch 3/200, Iteration 232/250, Loss: 0.1435\n",
      "Epoch 3/200, Iteration 233/250, Loss: 0.1112\n",
      "Epoch 3/200, Iteration 234/250, Loss: 0.2137\n",
      "Epoch 3/200, Iteration 235/250, Loss: 0.2154\n",
      "Epoch 3/200, Iteration 236/250, Loss: 0.0531\n",
      "Epoch 3/200, Iteration 237/250, Loss: 0.2531\n",
      "Epoch 3/200, Iteration 238/250, Loss: 0.2894\n",
      "Epoch 3/200, Iteration 239/250, Loss: 0.1351\n",
      "Epoch 3/200, Iteration 240/250, Loss: 0.2011\n",
      "Epoch 3/200, Iteration 241/250, Loss: 0.2813\n",
      "Epoch 3/200, Iteration 242/250, Loss: 0.1871\n",
      "Epoch 3/200, Iteration 243/250, Loss: 0.1010\n",
      "Epoch 3/200, Iteration 244/250, Loss: 0.1594\n",
      "Epoch 3/200, Iteration 245/250, Loss: 0.1806\n",
      "Epoch 3/200, Iteration 246/250, Loss: 0.0727\n",
      "Epoch 3/200, Iteration 247/250, Loss: 0.0588\n",
      "Epoch 3/200, Iteration 248/250, Loss: 0.1264\n",
      "Epoch 3/200, Iteration 249/250, Loss: 0.1583\n",
      "Epoch 3/200, Iteration 250/250, Loss: 0.0985\n",
      "Train Error: \n",
      " Accuracy: 37.38%, Avg loss: 0.094761, MRE: 7.089718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 35.35%, Avg loss: 0.094882, MRE: 8.156825 \n",
      "\n",
      "Epoch 4/200, Iteration 1/250, Loss: 0.0752\n",
      "Epoch 4/200, Iteration 2/250, Loss: 0.1131\n",
      "Epoch 4/200, Iteration 3/250, Loss: 0.1341\n",
      "Epoch 4/200, Iteration 4/250, Loss: 0.1214\n",
      "Epoch 4/200, Iteration 5/250, Loss: 0.1834\n",
      "Epoch 4/200, Iteration 6/250, Loss: 0.1345\n",
      "Epoch 4/200, Iteration 7/250, Loss: 0.1872\n",
      "Epoch 4/200, Iteration 8/250, Loss: 0.0583\n",
      "Epoch 4/200, Iteration 9/250, Loss: 0.1903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Iteration 10/250, Loss: 0.1171\n",
      "Epoch 4/200, Iteration 11/250, Loss: 0.2176\n",
      "Epoch 4/200, Iteration 12/250, Loss: 0.1624\n",
      "Epoch 4/200, Iteration 13/250, Loss: 0.0560\n",
      "Epoch 4/200, Iteration 14/250, Loss: 0.2325\n",
      "Epoch 4/200, Iteration 15/250, Loss: 0.1989\n",
      "Epoch 4/200, Iteration 16/250, Loss: 0.1282\n",
      "Epoch 4/200, Iteration 17/250, Loss: 0.1541\n",
      "Epoch 4/200, Iteration 18/250, Loss: 0.1158\n",
      "Epoch 4/200, Iteration 19/250, Loss: 0.1132\n",
      "Epoch 4/200, Iteration 20/250, Loss: 0.0648\n",
      "Epoch 4/200, Iteration 21/250, Loss: 0.1194\n",
      "Epoch 4/200, Iteration 22/250, Loss: 0.0913\n",
      "Epoch 4/200, Iteration 23/250, Loss: 0.1021\n",
      "Epoch 4/200, Iteration 24/250, Loss: 0.0671\n",
      "Epoch 4/200, Iteration 25/250, Loss: 0.0587\n",
      "Epoch 4/200, Iteration 26/250, Loss: 0.0875\n",
      "Epoch 4/200, Iteration 27/250, Loss: 0.0863\n",
      "Epoch 4/200, Iteration 28/250, Loss: 0.1275\n",
      "Epoch 4/200, Iteration 29/250, Loss: 0.0997\n",
      "Epoch 4/200, Iteration 30/250, Loss: 0.1865\n",
      "Epoch 4/200, Iteration 31/250, Loss: 0.1947\n",
      "Epoch 4/200, Iteration 32/250, Loss: 0.1416\n",
      "Epoch 4/200, Iteration 33/250, Loss: 0.1051\n",
      "Epoch 4/200, Iteration 34/250, Loss: 0.1051\n",
      "Epoch 4/200, Iteration 35/250, Loss: 0.0993\n",
      "Epoch 4/200, Iteration 36/250, Loss: 0.0774\n",
      "Epoch 4/200, Iteration 37/250, Loss: 0.0978\n",
      "Epoch 4/200, Iteration 38/250, Loss: 0.1049\n",
      "Epoch 4/200, Iteration 39/250, Loss: 0.0977\n",
      "Epoch 4/200, Iteration 40/250, Loss: 0.1235\n",
      "Epoch 4/200, Iteration 41/250, Loss: 0.1106\n",
      "Epoch 4/200, Iteration 42/250, Loss: 0.1097\n",
      "Epoch 4/200, Iteration 43/250, Loss: 0.0978\n",
      "Epoch 4/200, Iteration 44/250, Loss: 0.0875\n",
      "Epoch 4/200, Iteration 45/250, Loss: 0.0948\n",
      "Epoch 4/200, Iteration 46/250, Loss: 0.0750\n",
      "Epoch 4/200, Iteration 47/250, Loss: 0.0835\n",
      "Epoch 4/200, Iteration 48/250, Loss: 0.0538\n",
      "Epoch 4/200, Iteration 49/250, Loss: 0.0819\n",
      "Epoch 4/200, Iteration 50/250, Loss: 0.0731\n",
      "Epoch 4/200, Iteration 51/250, Loss: 0.0956\n",
      "Epoch 4/200, Iteration 52/250, Loss: 0.0681\n",
      "Epoch 4/200, Iteration 53/250, Loss: 0.0666\n",
      "Epoch 4/200, Iteration 54/250, Loss: 0.0726\n",
      "Epoch 4/200, Iteration 55/250, Loss: 0.0634\n",
      "Epoch 4/200, Iteration 56/250, Loss: 0.0390\n",
      "Epoch 4/200, Iteration 57/250, Loss: 0.0603\n",
      "Epoch 4/200, Iteration 58/250, Loss: 0.0439\n",
      "Epoch 4/200, Iteration 59/250, Loss: 0.1213\n",
      "Epoch 4/200, Iteration 60/250, Loss: 0.1022\n",
      "Epoch 4/200, Iteration 61/250, Loss: 0.0760\n",
      "Epoch 4/200, Iteration 62/250, Loss: 0.1043\n",
      "Epoch 4/200, Iteration 63/250, Loss: 0.0942\n",
      "Epoch 4/200, Iteration 64/250, Loss: 0.0361\n",
      "Epoch 4/200, Iteration 65/250, Loss: 0.1149\n",
      "Epoch 4/200, Iteration 66/250, Loss: 0.0925\n",
      "Epoch 4/200, Iteration 67/250, Loss: 0.0733\n",
      "Epoch 4/200, Iteration 68/250, Loss: 0.1230\n",
      "Epoch 4/200, Iteration 69/250, Loss: 0.0998\n",
      "Epoch 4/200, Iteration 70/250, Loss: 0.1265\n",
      "Epoch 4/200, Iteration 71/250, Loss: 0.1089\n",
      "Epoch 4/200, Iteration 72/250, Loss: 0.1224\n",
      "Epoch 4/200, Iteration 73/250, Loss: 0.1338\n",
      "Epoch 4/200, Iteration 74/250, Loss: 0.0554\n",
      "Epoch 4/200, Iteration 75/250, Loss: 0.1034\n",
      "Epoch 4/200, Iteration 76/250, Loss: 0.0611\n",
      "Epoch 4/200, Iteration 77/250, Loss: 0.1095\n",
      "Epoch 4/200, Iteration 78/250, Loss: 0.0689\n",
      "Epoch 4/200, Iteration 79/250, Loss: 0.0966\n",
      "Epoch 4/200, Iteration 80/250, Loss: 0.0464\n",
      "Epoch 4/200, Iteration 81/250, Loss: 0.1283\n",
      "Epoch 4/200, Iteration 82/250, Loss: 0.0610\n",
      "Epoch 4/200, Iteration 83/250, Loss: 0.1433\n",
      "Epoch 4/200, Iteration 84/250, Loss: 0.0749\n",
      "Epoch 4/200, Iteration 85/250, Loss: 0.2002\n",
      "Epoch 4/200, Iteration 86/250, Loss: 0.1828\n",
      "Epoch 4/200, Iteration 87/250, Loss: 0.0923\n",
      "Epoch 4/200, Iteration 88/250, Loss: 0.1014\n",
      "Epoch 4/200, Iteration 89/250, Loss: 0.0722\n",
      "Epoch 4/200, Iteration 90/250, Loss: 0.0793\n",
      "Epoch 4/200, Iteration 91/250, Loss: 0.1166\n",
      "Epoch 4/200, Iteration 92/250, Loss: 0.0479\n",
      "Epoch 4/200, Iteration 93/250, Loss: 0.0896\n",
      "Epoch 4/200, Iteration 94/250, Loss: 0.0679\n",
      "Epoch 4/200, Iteration 95/250, Loss: 0.0880\n",
      "Epoch 4/200, Iteration 96/250, Loss: 0.0494\n",
      "Epoch 4/200, Iteration 97/250, Loss: 0.0592\n",
      "Epoch 4/200, Iteration 98/250, Loss: 0.1027\n",
      "Epoch 4/200, Iteration 99/250, Loss: 0.0974\n",
      "Epoch 4/200, Iteration 100/250, Loss: 0.0511\n",
      "Epoch 4/200, Iteration 101/250, Loss: 0.0492\n",
      "Epoch 4/200, Iteration 102/250, Loss: 0.0587\n",
      "Epoch 4/200, Iteration 103/250, Loss: 0.0473\n",
      "Epoch 4/200, Iteration 104/250, Loss: 0.0499\n",
      "Epoch 4/200, Iteration 105/250, Loss: 0.0751\n",
      "Epoch 4/200, Iteration 106/250, Loss: 0.0505\n",
      "Epoch 4/200, Iteration 107/250, Loss: 0.0554\n",
      "Epoch 4/200, Iteration 108/250, Loss: 0.0507\n",
      "Epoch 4/200, Iteration 109/250, Loss: 0.0434\n",
      "Epoch 4/200, Iteration 110/250, Loss: 0.0863\n",
      "Epoch 4/200, Iteration 111/250, Loss: 0.0543\n",
      "Epoch 4/200, Iteration 112/250, Loss: 0.0962\n",
      "Epoch 4/200, Iteration 113/250, Loss: 0.0945\n",
      "Epoch 4/200, Iteration 114/250, Loss: 0.1030\n",
      "Epoch 4/200, Iteration 115/250, Loss: 0.1322\n",
      "Epoch 4/200, Iteration 116/250, Loss: 0.0758\n",
      "Epoch 4/200, Iteration 117/250, Loss: 0.1233\n",
      "Epoch 4/200, Iteration 118/250, Loss: 0.1525\n",
      "Epoch 4/200, Iteration 119/250, Loss: 0.0755\n",
      "Epoch 4/200, Iteration 120/250, Loss: 0.1341\n",
      "Epoch 4/200, Iteration 121/250, Loss: 0.1527\n",
      "Epoch 4/200, Iteration 122/250, Loss: 0.0739\n",
      "Epoch 4/200, Iteration 123/250, Loss: 0.0611\n",
      "Epoch 4/200, Iteration 124/250, Loss: 0.1080\n",
      "Epoch 4/200, Iteration 125/250, Loss: 0.0904\n",
      "Epoch 4/200, Iteration 126/250, Loss: 0.0496\n",
      "Epoch 4/200, Iteration 127/250, Loss: 0.1247\n",
      "Epoch 4/200, Iteration 128/250, Loss: 0.1124\n",
      "Epoch 4/200, Iteration 129/250, Loss: 0.1122\n",
      "Epoch 4/200, Iteration 130/250, Loss: 0.0909\n",
      "Epoch 4/200, Iteration 131/250, Loss: 0.0922\n",
      "Epoch 4/200, Iteration 132/250, Loss: 0.0811\n",
      "Epoch 4/200, Iteration 133/250, Loss: 0.1152\n",
      "Epoch 4/200, Iteration 134/250, Loss: 0.0930\n",
      "Epoch 4/200, Iteration 135/250, Loss: 0.1019\n",
      "Epoch 4/200, Iteration 136/250, Loss: 0.0718\n",
      "Epoch 4/200, Iteration 137/250, Loss: 0.0700\n",
      "Epoch 4/200, Iteration 138/250, Loss: 0.0756\n",
      "Epoch 4/200, Iteration 139/250, Loss: 0.0759\n",
      "Epoch 4/200, Iteration 140/250, Loss: 0.0778\n",
      "Epoch 4/200, Iteration 141/250, Loss: 0.0761\n",
      "Epoch 4/200, Iteration 142/250, Loss: 0.0832\n",
      "Epoch 4/200, Iteration 143/250, Loss: 0.0860\n",
      "Epoch 4/200, Iteration 144/250, Loss: 0.0462\n",
      "Epoch 4/200, Iteration 145/250, Loss: 0.0585\n",
      "Epoch 4/200, Iteration 146/250, Loss: 0.0372\n",
      "Epoch 4/200, Iteration 147/250, Loss: 0.1062\n",
      "Epoch 4/200, Iteration 148/250, Loss: 0.0875\n",
      "Epoch 4/200, Iteration 149/250, Loss: 0.0784\n",
      "Epoch 4/200, Iteration 150/250, Loss: 0.1172\n",
      "Epoch 4/200, Iteration 151/250, Loss: 0.1000\n",
      "Epoch 4/200, Iteration 152/250, Loss: 0.0521\n",
      "Epoch 4/200, Iteration 153/250, Loss: 0.1248\n",
      "Epoch 4/200, Iteration 154/250, Loss: 0.1381\n",
      "Epoch 4/200, Iteration 155/250, Loss: 0.0601\n",
      "Epoch 4/200, Iteration 156/250, Loss: 0.1334\n",
      "Epoch 4/200, Iteration 157/250, Loss: 0.1700\n",
      "Epoch 4/200, Iteration 158/250, Loss: 0.1345\n",
      "Epoch 4/200, Iteration 159/250, Loss: 0.0968\n",
      "Epoch 4/200, Iteration 160/250, Loss: 0.1458\n",
      "Epoch 4/200, Iteration 161/250, Loss: 0.1629\n",
      "Epoch 4/200, Iteration 162/250, Loss: 0.1086\n",
      "Epoch 4/200, Iteration 163/250, Loss: 0.0667\n",
      "Epoch 4/200, Iteration 164/250, Loss: 0.1335\n",
      "Epoch 4/200, Iteration 165/250, Loss: 0.1366\n",
      "Epoch 4/200, Iteration 166/250, Loss: 0.1653\n",
      "Epoch 4/200, Iteration 167/250, Loss: 0.1050\n",
      "Epoch 4/200, Iteration 168/250, Loss: 0.1875\n",
      "Epoch 4/200, Iteration 169/250, Loss: 0.2262\n",
      "Epoch 4/200, Iteration 170/250, Loss: 0.1161\n",
      "Epoch 4/200, Iteration 171/250, Loss: 0.1571\n",
      "Epoch 4/200, Iteration 172/250, Loss: 0.1091\n",
      "Epoch 4/200, Iteration 173/250, Loss: 0.1273\n",
      "Epoch 4/200, Iteration 174/250, Loss: 0.1551\n",
      "Epoch 4/200, Iteration 175/250, Loss: 0.0530\n",
      "Epoch 4/200, Iteration 176/250, Loss: 0.2617\n",
      "Epoch 4/200, Iteration 177/250, Loss: 0.1891\n",
      "Epoch 4/200, Iteration 178/250, Loss: 0.2356\n",
      "Epoch 4/200, Iteration 179/250, Loss: 0.2811\n",
      "Epoch 4/200, Iteration 180/250, Loss: 0.0648\n",
      "Epoch 4/200, Iteration 181/250, Loss: 0.2728\n",
      "Epoch 4/200, Iteration 182/250, Loss: 0.3908\n",
      "Epoch 4/200, Iteration 183/250, Loss: 0.1446\n",
      "Epoch 4/200, Iteration 184/250, Loss: 0.2802\n",
      "Epoch 4/200, Iteration 185/250, Loss: 0.4114\n",
      "Epoch 4/200, Iteration 186/250, Loss: 0.3535\n",
      "Epoch 4/200, Iteration 187/250, Loss: 0.0372\n",
      "Epoch 4/200, Iteration 188/250, Loss: 0.3018\n",
      "Epoch 4/200, Iteration 189/250, Loss: 0.2715\n",
      "Epoch 4/200, Iteration 190/250, Loss: 0.0690\n",
      "Epoch 4/200, Iteration 191/250, Loss: 0.3012\n",
      "Epoch 4/200, Iteration 192/250, Loss: 0.3494\n",
      "Epoch 4/200, Iteration 193/250, Loss: 0.2405\n",
      "Epoch 4/200, Iteration 194/250, Loss: 0.1326\n",
      "Epoch 4/200, Iteration 195/250, Loss: 0.2251\n",
      "Epoch 4/200, Iteration 196/250, Loss: 0.2487\n",
      "Epoch 4/200, Iteration 197/250, Loss: 0.1944\n",
      "Epoch 4/200, Iteration 198/250, Loss: 0.1255\n",
      "Epoch 4/200, Iteration 199/250, Loss: 0.1400\n",
      "Epoch 4/200, Iteration 200/250, Loss: 0.1303\n",
      "Epoch 4/200, Iteration 201/250, Loss: 0.1009\n",
      "Epoch 4/200, Iteration 202/250, Loss: 0.1195\n",
      "Epoch 4/200, Iteration 203/250, Loss: 0.1459\n",
      "Epoch 4/200, Iteration 204/250, Loss: 0.0870\n",
      "Epoch 4/200, Iteration 205/250, Loss: 0.0588\n",
      "Epoch 4/200, Iteration 206/250, Loss: 0.1118\n",
      "Epoch 4/200, Iteration 207/250, Loss: 0.1159\n",
      "Epoch 4/200, Iteration 208/250, Loss: 0.1384\n",
      "Epoch 4/200, Iteration 209/250, Loss: 0.0494\n",
      "Epoch 4/200, Iteration 210/250, Loss: 0.0754\n",
      "Epoch 4/200, Iteration 211/250, Loss: 0.1192\n",
      "Epoch 4/200, Iteration 212/250, Loss: 0.1077\n",
      "Epoch 4/200, Iteration 213/250, Loss: 0.1118\n",
      "Epoch 4/200, Iteration 214/250, Loss: 0.0966\n",
      "Epoch 4/200, Iteration 215/250, Loss: 0.1122\n",
      "Epoch 4/200, Iteration 216/250, Loss: 0.0678\n",
      "Epoch 4/200, Iteration 217/250, Loss: 0.1309\n",
      "Epoch 4/200, Iteration 218/250, Loss: 0.0936\n",
      "Epoch 4/200, Iteration 219/250, Loss: 0.1363\n",
      "Epoch 4/200, Iteration 220/250, Loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Iteration 221/250, Loss: 0.1074\n",
      "Epoch 4/200, Iteration 222/250, Loss: 0.1102\n",
      "Epoch 4/200, Iteration 223/250, Loss: 0.1519\n",
      "Epoch 4/200, Iteration 224/250, Loss: 0.0957\n",
      "Epoch 4/200, Iteration 225/250, Loss: 0.1465\n",
      "Epoch 4/200, Iteration 226/250, Loss: 0.1321\n",
      "Epoch 4/200, Iteration 227/250, Loss: 0.0889\n",
      "Epoch 4/200, Iteration 228/250, Loss: 0.0758\n",
      "Epoch 4/200, Iteration 229/250, Loss: 0.1430\n",
      "Epoch 4/200, Iteration 230/250, Loss: 0.1926\n",
      "Epoch 4/200, Iteration 231/250, Loss: 0.1018\n",
      "Epoch 4/200, Iteration 232/250, Loss: 0.1282\n",
      "Epoch 4/200, Iteration 233/250, Loss: 0.1685\n",
      "Epoch 4/200, Iteration 234/250, Loss: 0.0728\n",
      "Epoch 4/200, Iteration 235/250, Loss: 0.1847\n",
      "Epoch 4/200, Iteration 236/250, Loss: 0.2102\n",
      "Epoch 4/200, Iteration 237/250, Loss: 0.1174\n",
      "Epoch 4/200, Iteration 238/250, Loss: 0.1114\n",
      "Epoch 4/200, Iteration 239/250, Loss: 0.2049\n",
      "Epoch 4/200, Iteration 240/250, Loss: 0.1614\n",
      "Epoch 4/200, Iteration 241/250, Loss: 0.0934\n",
      "Epoch 4/200, Iteration 242/250, Loss: 0.1165\n",
      "Epoch 4/200, Iteration 243/250, Loss: 0.0887\n",
      "Epoch 4/200, Iteration 244/250, Loss: 0.1300\n",
      "Epoch 4/200, Iteration 245/250, Loss: 0.1096\n",
      "Epoch 4/200, Iteration 246/250, Loss: 0.1066\n",
      "Epoch 4/200, Iteration 247/250, Loss: 0.1022\n",
      "Epoch 4/200, Iteration 248/250, Loss: 0.0994\n",
      "Epoch 4/200, Iteration 249/250, Loss: 0.0956\n",
      "Epoch 4/200, Iteration 250/250, Loss: 0.0738\n",
      "Train Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.045637, MRE: 4.152368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.05%, Avg loss: 0.046515, MRE: 6.526335 \n",
      "\n",
      "Epoch 5/200, Iteration 1/250, Loss: 0.0417\n",
      "Epoch 5/200, Iteration 2/250, Loss: 0.1050\n",
      "Epoch 5/200, Iteration 3/250, Loss: 0.0837\n",
      "Epoch 5/200, Iteration 4/250, Loss: 0.0658\n",
      "Epoch 5/200, Iteration 5/250, Loss: 0.0665\n",
      "Epoch 5/200, Iteration 6/250, Loss: 0.0757\n",
      "Epoch 5/200, Iteration 7/250, Loss: 0.1024\n",
      "Epoch 5/200, Iteration 8/250, Loss: 0.1200\n",
      "Epoch 5/200, Iteration 9/250, Loss: 0.0407\n",
      "Epoch 5/200, Iteration 10/250, Loss: 0.1284\n",
      "Epoch 5/200, Iteration 11/250, Loss: 0.0928\n",
      "Epoch 5/200, Iteration 12/250, Loss: 0.0691\n",
      "Epoch 5/200, Iteration 13/250, Loss: 0.0905\n",
      "Epoch 5/200, Iteration 14/250, Loss: 0.0560\n",
      "Epoch 5/200, Iteration 15/250, Loss: 0.1420\n",
      "Epoch 5/200, Iteration 16/250, Loss: 0.1578\n",
      "Epoch 5/200, Iteration 17/250, Loss: 0.0846\n",
      "Epoch 5/200, Iteration 18/250, Loss: 0.0918\n",
      "Epoch 5/200, Iteration 19/250, Loss: 0.1185\n",
      "Epoch 5/200, Iteration 20/250, Loss: 0.1331\n",
      "Epoch 5/200, Iteration 21/250, Loss: 0.0941\n",
      "Epoch 5/200, Iteration 22/250, Loss: 0.0596\n",
      "Epoch 5/200, Iteration 23/250, Loss: 0.0902\n",
      "Epoch 5/200, Iteration 24/250, Loss: 0.0822\n",
      "Epoch 5/200, Iteration 25/250, Loss: 0.0768\n",
      "Epoch 5/200, Iteration 26/250, Loss: 0.0726\n",
      "Epoch 5/200, Iteration 27/250, Loss: 0.1064\n",
      "Epoch 5/200, Iteration 28/250, Loss: 0.0685\n",
      "Epoch 5/200, Iteration 29/250, Loss: 0.1483\n",
      "Epoch 5/200, Iteration 30/250, Loss: 0.1554\n",
      "Epoch 5/200, Iteration 31/250, Loss: 0.0936\n",
      "Epoch 5/200, Iteration 32/250, Loss: 0.1488\n",
      "Epoch 5/200, Iteration 33/250, Loss: 0.0992\n",
      "Epoch 5/200, Iteration 34/250, Loss: 0.0746\n",
      "Epoch 5/200, Iteration 35/250, Loss: 0.0843\n",
      "Epoch 5/200, Iteration 36/250, Loss: 0.0459\n",
      "Epoch 5/200, Iteration 37/250, Loss: 0.1326\n",
      "Epoch 5/200, Iteration 38/250, Loss: 0.1103\n",
      "Epoch 5/200, Iteration 39/250, Loss: 0.0456\n",
      "Epoch 5/200, Iteration 40/250, Loss: 0.0669\n",
      "Epoch 5/200, Iteration 41/250, Loss: 0.0537\n",
      "Epoch 5/200, Iteration 42/250, Loss: 0.0600\n",
      "Epoch 5/200, Iteration 43/250, Loss: 0.0628\n",
      "Epoch 5/200, Iteration 44/250, Loss: 0.0520\n",
      "Epoch 5/200, Iteration 45/250, Loss: 0.0872\n",
      "Epoch 5/200, Iteration 46/250, Loss: 0.0607\n",
      "Epoch 5/200, Iteration 47/250, Loss: 0.0511\n",
      "Epoch 5/200, Iteration 48/250, Loss: 0.0932\n",
      "Epoch 5/200, Iteration 49/250, Loss: 0.1004\n",
      "Epoch 5/200, Iteration 50/250, Loss: 0.0531\n",
      "Epoch 5/200, Iteration 51/250, Loss: 0.0688\n",
      "Epoch 5/200, Iteration 52/250, Loss: 0.0934\n",
      "Epoch 5/200, Iteration 53/250, Loss: 0.0620\n",
      "Epoch 5/200, Iteration 54/250, Loss: 0.0434\n",
      "Epoch 5/200, Iteration 55/250, Loss: 0.0644\n",
      "Epoch 5/200, Iteration 56/250, Loss: 0.0743\n",
      "Epoch 5/200, Iteration 57/250, Loss: 0.0843\n",
      "Epoch 5/200, Iteration 58/250, Loss: 0.0696\n",
      "Epoch 5/200, Iteration 59/250, Loss: 0.0747\n",
      "Epoch 5/200, Iteration 60/250, Loss: 0.0424\n",
      "Epoch 5/200, Iteration 61/250, Loss: 0.0637\n",
      "Epoch 5/200, Iteration 62/250, Loss: 0.0845\n",
      "Epoch 5/200, Iteration 63/250, Loss: 0.0709\n",
      "Epoch 5/200, Iteration 64/250, Loss: 0.0480\n",
      "Epoch 5/200, Iteration 65/250, Loss: 0.0655\n",
      "Epoch 5/200, Iteration 66/250, Loss: 0.0629\n",
      "Epoch 5/200, Iteration 67/250, Loss: 0.0780\n",
      "Epoch 5/200, Iteration 68/250, Loss: 0.0600\n",
      "Epoch 5/200, Iteration 69/250, Loss: 0.0925\n",
      "Epoch 5/200, Iteration 70/250, Loss: 0.1094\n",
      "Epoch 5/200, Iteration 71/250, Loss: 0.0996\n",
      "Epoch 5/200, Iteration 72/250, Loss: 0.0706\n",
      "Epoch 5/200, Iteration 73/250, Loss: 0.0760\n",
      "Epoch 5/200, Iteration 74/250, Loss: 0.1213\n",
      "Epoch 5/200, Iteration 75/250, Loss: 0.0890\n",
      "Epoch 5/200, Iteration 76/250, Loss: 0.0439\n",
      "Epoch 5/200, Iteration 77/250, Loss: 0.0702\n",
      "Epoch 5/200, Iteration 78/250, Loss: 0.0865\n",
      "Epoch 5/200, Iteration 79/250, Loss: 0.0695\n",
      "Epoch 5/200, Iteration 80/250, Loss: 0.0580\n",
      "Epoch 5/200, Iteration 81/250, Loss: 0.0723\n",
      "Epoch 5/200, Iteration 82/250, Loss: 0.0606\n",
      "Epoch 5/200, Iteration 83/250, Loss: 0.0712\n",
      "Epoch 5/200, Iteration 84/250, Loss: 0.0774\n",
      "Epoch 5/200, Iteration 85/250, Loss: 0.0756\n",
      "Epoch 5/200, Iteration 86/250, Loss: 0.1264\n",
      "Epoch 5/200, Iteration 87/250, Loss: 0.1284\n",
      "Epoch 5/200, Iteration 88/250, Loss: 0.0705\n",
      "Epoch 5/200, Iteration 89/250, Loss: 0.0856\n",
      "Epoch 5/200, Iteration 90/250, Loss: 0.0860\n",
      "Epoch 5/200, Iteration 91/250, Loss: 0.0939\n",
      "Epoch 5/200, Iteration 92/250, Loss: 0.0374\n",
      "Epoch 5/200, Iteration 93/250, Loss: 0.0810\n",
      "Epoch 5/200, Iteration 94/250, Loss: 0.0645\n",
      "Epoch 5/200, Iteration 95/250, Loss: 0.0735\n",
      "Epoch 5/200, Iteration 96/250, Loss: 0.0662\n",
      "Epoch 5/200, Iteration 97/250, Loss: 0.0843\n",
      "Epoch 5/200, Iteration 98/250, Loss: 0.0871\n",
      "Epoch 5/200, Iteration 99/250, Loss: 0.0767\n",
      "Epoch 5/200, Iteration 100/250, Loss: 0.0545\n",
      "Epoch 5/200, Iteration 101/250, Loss: 0.1086\n",
      "Epoch 5/200, Iteration 102/250, Loss: 0.1199\n",
      "Epoch 5/200, Iteration 103/250, Loss: 0.0709\n",
      "Epoch 5/200, Iteration 104/250, Loss: 0.1382\n",
      "Epoch 5/200, Iteration 105/250, Loss: 0.0339\n",
      "Epoch 5/200, Iteration 106/250, Loss: 0.1317\n",
      "Epoch 5/200, Iteration 107/250, Loss: 0.0885\n",
      "Epoch 5/200, Iteration 108/250, Loss: 0.1392\n",
      "Epoch 5/200, Iteration 109/250, Loss: 0.1442\n",
      "Epoch 5/200, Iteration 110/250, Loss: 0.0877\n",
      "Epoch 5/200, Iteration 111/250, Loss: 0.0810\n",
      "Epoch 5/200, Iteration 112/250, Loss: 0.1330\n",
      "Epoch 5/200, Iteration 113/250, Loss: 0.0932\n",
      "Epoch 5/200, Iteration 114/250, Loss: 0.1388\n",
      "Epoch 5/200, Iteration 115/250, Loss: 0.1492\n",
      "Epoch 5/200, Iteration 116/250, Loss: 0.0872\n",
      "Epoch 5/200, Iteration 117/250, Loss: 0.1459\n",
      "Epoch 5/200, Iteration 118/250, Loss: 0.0658\n",
      "Epoch 5/200, Iteration 119/250, Loss: 0.1124\n",
      "Epoch 5/200, Iteration 120/250, Loss: 0.0666\n",
      "Epoch 5/200, Iteration 121/250, Loss: 0.1095\n",
      "Epoch 5/200, Iteration 122/250, Loss: 0.1410\n",
      "Epoch 5/200, Iteration 123/250, Loss: 0.0738\n",
      "Epoch 5/200, Iteration 124/250, Loss: 0.0442\n",
      "Epoch 5/200, Iteration 125/250, Loss: 0.0998\n",
      "Epoch 5/200, Iteration 126/250, Loss: 0.0784\n",
      "Epoch 5/200, Iteration 127/250, Loss: 0.0652\n",
      "Epoch 5/200, Iteration 128/250, Loss: 0.0754\n",
      "Epoch 5/200, Iteration 129/250, Loss: 0.0582\n",
      "Epoch 5/200, Iteration 130/250, Loss: 0.0597\n",
      "Epoch 5/200, Iteration 131/250, Loss: 0.0889\n",
      "Epoch 5/200, Iteration 132/250, Loss: 0.0567\n",
      "Epoch 5/200, Iteration 133/250, Loss: 0.1147\n",
      "Epoch 5/200, Iteration 134/250, Loss: 0.0946\n",
      "Epoch 5/200, Iteration 135/250, Loss: 0.0429\n",
      "Epoch 5/200, Iteration 136/250, Loss: 0.1014\n",
      "Epoch 5/200, Iteration 137/250, Loss: 0.0882\n",
      "Epoch 5/200, Iteration 138/250, Loss: 0.0566\n",
      "Epoch 5/200, Iteration 139/250, Loss: 0.0804\n",
      "Epoch 5/200, Iteration 140/250, Loss: 0.0997\n",
      "Epoch 5/200, Iteration 141/250, Loss: 0.0709\n",
      "Epoch 5/200, Iteration 142/250, Loss: 0.0577\n",
      "Epoch 5/200, Iteration 143/250, Loss: 0.0778\n",
      "Epoch 5/200, Iteration 144/250, Loss: 0.0797\n",
      "Epoch 5/200, Iteration 145/250, Loss: 0.0590\n",
      "Epoch 5/200, Iteration 146/250, Loss: 0.1552\n",
      "Epoch 5/200, Iteration 147/250, Loss: 0.1948\n",
      "Epoch 5/200, Iteration 148/250, Loss: 0.0761\n",
      "Epoch 5/200, Iteration 149/250, Loss: 0.1059\n",
      "Epoch 5/200, Iteration 150/250, Loss: 0.0666\n",
      "Epoch 5/200, Iteration 151/250, Loss: 0.0708\n",
      "Epoch 5/200, Iteration 152/250, Loss: 0.0452\n",
      "Epoch 5/200, Iteration 153/250, Loss: 0.1080\n",
      "Epoch 5/200, Iteration 154/250, Loss: 0.0845\n",
      "Epoch 5/200, Iteration 155/250, Loss: 0.1137\n",
      "Epoch 5/200, Iteration 156/250, Loss: 0.0545\n",
      "Epoch 5/200, Iteration 157/250, Loss: 0.1021\n",
      "Epoch 5/200, Iteration 158/250, Loss: 0.1134\n",
      "Epoch 5/200, Iteration 159/250, Loss: 0.1173\n",
      "Epoch 5/200, Iteration 160/250, Loss: 0.1731\n",
      "Epoch 5/200, Iteration 161/250, Loss: 0.0785\n",
      "Epoch 5/200, Iteration 162/250, Loss: 0.1872\n",
      "Epoch 5/200, Iteration 163/250, Loss: 0.1820\n",
      "Epoch 5/200, Iteration 164/250, Loss: 0.0772\n",
      "Epoch 5/200, Iteration 165/250, Loss: 0.1805\n",
      "Epoch 5/200, Iteration 166/250, Loss: 0.2232\n",
      "Epoch 5/200, Iteration 167/250, Loss: 0.1106\n",
      "Epoch 5/200, Iteration 168/250, Loss: 0.0908\n",
      "Epoch 5/200, Iteration 169/250, Loss: 0.1861\n",
      "Epoch 5/200, Iteration 170/250, Loss: 0.1589\n",
      "Epoch 5/200, Iteration 171/250, Loss: 0.0871\n",
      "Epoch 5/200, Iteration 172/250, Loss: 0.1245\n",
      "Epoch 5/200, Iteration 173/250, Loss: 0.0958\n",
      "Epoch 5/200, Iteration 174/250, Loss: 0.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Iteration 175/250, Loss: 0.1602\n",
      "Epoch 5/200, Iteration 176/250, Loss: 0.1406\n",
      "Epoch 5/200, Iteration 177/250, Loss: 0.1228\n",
      "Epoch 5/200, Iteration 178/250, Loss: 0.0925\n",
      "Epoch 5/200, Iteration 179/250, Loss: 0.0640\n",
      "Epoch 5/200, Iteration 180/250, Loss: 0.0610\n",
      "Epoch 5/200, Iteration 181/250, Loss: 0.1182\n",
      "Epoch 5/200, Iteration 182/250, Loss: 0.0908\n",
      "Epoch 5/200, Iteration 183/250, Loss: 0.1016\n",
      "Epoch 5/200, Iteration 184/250, Loss: 0.0789\n",
      "Epoch 5/200, Iteration 185/250, Loss: 0.0765\n",
      "Epoch 5/200, Iteration 186/250, Loss: 0.0814\n",
      "Epoch 5/200, Iteration 187/250, Loss: 0.0678\n",
      "Epoch 5/200, Iteration 188/250, Loss: 0.0596\n",
      "Epoch 5/200, Iteration 189/250, Loss: 0.1027\n",
      "Epoch 5/200, Iteration 190/250, Loss: 0.0378\n",
      "Epoch 5/200, Iteration 191/250, Loss: 0.0517\n",
      "Epoch 5/200, Iteration 192/250, Loss: 0.0531\n",
      "Epoch 5/200, Iteration 193/250, Loss: 0.0576\n",
      "Epoch 5/200, Iteration 194/250, Loss: 0.0590\n",
      "Epoch 5/200, Iteration 195/250, Loss: 0.0762\n",
      "Epoch 5/200, Iteration 196/250, Loss: 0.0530\n",
      "Epoch 5/200, Iteration 197/250, Loss: 0.0587\n",
      "Epoch 5/200, Iteration 198/250, Loss: 0.0796\n",
      "Epoch 5/200, Iteration 199/250, Loss: 0.0484\n",
      "Epoch 5/200, Iteration 200/250, Loss: 0.0901\n",
      "Epoch 5/200, Iteration 201/250, Loss: 0.0433\n",
      "Epoch 5/200, Iteration 202/250, Loss: 0.1118\n",
      "Epoch 5/200, Iteration 203/250, Loss: 0.0864\n",
      "Epoch 5/200, Iteration 204/250, Loss: 0.0862\n",
      "Epoch 5/200, Iteration 205/250, Loss: 0.1041\n",
      "Epoch 5/200, Iteration 206/250, Loss: 0.0906\n",
      "Epoch 5/200, Iteration 207/250, Loss: 0.1173\n",
      "Epoch 5/200, Iteration 208/250, Loss: 0.0910\n",
      "Epoch 5/200, Iteration 209/250, Loss: 0.0424\n",
      "Epoch 5/200, Iteration 210/250, Loss: 0.1046\n",
      "Epoch 5/200, Iteration 211/250, Loss: 0.1056\n",
      "Epoch 5/200, Iteration 212/250, Loss: 0.1260\n",
      "Epoch 5/200, Iteration 213/250, Loss: 0.0486\n",
      "Epoch 5/200, Iteration 214/250, Loss: 0.0882\n",
      "Epoch 5/200, Iteration 215/250, Loss: 0.1406\n",
      "Epoch 5/200, Iteration 216/250, Loss: 0.0800\n",
      "Epoch 5/200, Iteration 217/250, Loss: 0.0801\n",
      "Epoch 5/200, Iteration 218/250, Loss: 0.0682\n",
      "Epoch 5/200, Iteration 219/250, Loss: 0.0831\n",
      "Epoch 5/200, Iteration 220/250, Loss: 0.0757\n",
      "Epoch 5/200, Iteration 221/250, Loss: 0.1009\n",
      "Epoch 5/200, Iteration 222/250, Loss: 0.0646\n",
      "Epoch 5/200, Iteration 223/250, Loss: 0.1008\n",
      "Epoch 5/200, Iteration 224/250, Loss: 0.0756\n",
      "Epoch 5/200, Iteration 225/250, Loss: 0.0754\n",
      "Epoch 5/200, Iteration 226/250, Loss: 0.0730\n",
      "Epoch 5/200, Iteration 227/250, Loss: 0.0573\n",
      "Epoch 5/200, Iteration 228/250, Loss: 0.0496\n",
      "Epoch 5/200, Iteration 229/250, Loss: 0.0784\n",
      "Epoch 5/200, Iteration 230/250, Loss: 0.0695\n",
      "Epoch 5/200, Iteration 231/250, Loss: 0.0954\n",
      "Epoch 5/200, Iteration 232/250, Loss: 0.0708\n",
      "Epoch 5/200, Iteration 233/250, Loss: 0.0704\n",
      "Epoch 5/200, Iteration 234/250, Loss: 0.0986\n",
      "Epoch 5/200, Iteration 235/250, Loss: 0.0578\n",
      "Epoch 5/200, Iteration 236/250, Loss: 0.0616\n",
      "Epoch 5/200, Iteration 237/250, Loss: 0.0691\n",
      "Epoch 5/200, Iteration 238/250, Loss: 0.0755\n",
      "Epoch 5/200, Iteration 239/250, Loss: 0.0816\n",
      "Epoch 5/200, Iteration 240/250, Loss: 0.0707\n",
      "Epoch 5/200, Iteration 241/250, Loss: 0.0887\n",
      "Epoch 5/200, Iteration 242/250, Loss: 0.0675\n",
      "Epoch 5/200, Iteration 243/250, Loss: 0.0422\n",
      "Epoch 5/200, Iteration 244/250, Loss: 0.0896\n",
      "Epoch 5/200, Iteration 245/250, Loss: 0.0892\n",
      "Epoch 5/200, Iteration 246/250, Loss: 0.0876\n",
      "Epoch 5/200, Iteration 247/250, Loss: 0.1001\n",
      "Epoch 5/200, Iteration 248/250, Loss: 0.0856\n",
      "Epoch 5/200, Iteration 249/250, Loss: 0.0777\n",
      "Epoch 5/200, Iteration 250/250, Loss: 0.0588\n",
      "Train Error: \n",
      " Accuracy: 54.65%, Avg loss: 0.112866, MRE: 11.464850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.15%, Avg loss: 0.112100, MRE: 14.475785 \n",
      "\n",
      "Epoch 6/200, Iteration 1/250, Loss: 0.1090\n",
      "Epoch 6/200, Iteration 2/250, Loss: 0.1039\n",
      "Epoch 6/200, Iteration 3/250, Loss: 0.0885\n",
      "Epoch 6/200, Iteration 4/250, Loss: 0.0892\n",
      "Epoch 6/200, Iteration 5/250, Loss: 0.1040\n",
      "Epoch 6/200, Iteration 6/250, Loss: 0.0523\n",
      "Epoch 6/200, Iteration 7/250, Loss: 0.0956\n",
      "Epoch 6/200, Iteration 8/250, Loss: 0.0493\n",
      "Epoch 6/200, Iteration 9/250, Loss: 0.0650\n",
      "Epoch 6/200, Iteration 10/250, Loss: 0.0776\n",
      "Epoch 6/200, Iteration 11/250, Loss: 0.0730\n",
      "Epoch 6/200, Iteration 12/250, Loss: 0.0715\n",
      "Epoch 6/200, Iteration 13/250, Loss: 0.0576\n",
      "Epoch 6/200, Iteration 14/250, Loss: 0.0642\n",
      "Epoch 6/200, Iteration 15/250, Loss: 0.0760\n",
      "Epoch 6/200, Iteration 16/250, Loss: 0.0544\n",
      "Epoch 6/200, Iteration 17/250, Loss: 0.0641\n",
      "Epoch 6/200, Iteration 18/250, Loss: 0.0778\n",
      "Epoch 6/200, Iteration 19/250, Loss: 0.0657\n",
      "Epoch 6/200, Iteration 20/250, Loss: 0.0296\n",
      "Epoch 6/200, Iteration 21/250, Loss: 0.0429\n",
      "Epoch 6/200, Iteration 22/250, Loss: 0.0787\n",
      "Epoch 6/200, Iteration 23/250, Loss: 0.0464\n",
      "Epoch 6/200, Iteration 24/250, Loss: 0.0596\n",
      "Epoch 6/200, Iteration 25/250, Loss: 0.0391\n",
      "Epoch 6/200, Iteration 26/250, Loss: 0.0466\n",
      "Epoch 6/200, Iteration 27/250, Loss: 0.0354\n",
      "Epoch 6/200, Iteration 28/250, Loss: 0.0802\n",
      "Epoch 6/200, Iteration 29/250, Loss: 0.0681\n",
      "Epoch 6/200, Iteration 30/250, Loss: 0.0918\n",
      "Epoch 6/200, Iteration 31/250, Loss: 0.0471\n",
      "Epoch 6/200, Iteration 32/250, Loss: 0.1157\n",
      "Epoch 6/200, Iteration 33/250, Loss: 0.0830\n",
      "Epoch 6/200, Iteration 34/250, Loss: 0.0801\n",
      "Epoch 6/200, Iteration 35/250, Loss: 0.0618\n",
      "Epoch 6/200, Iteration 36/250, Loss: 0.0732\n",
      "Epoch 6/200, Iteration 37/250, Loss: 0.1090\n",
      "Epoch 6/200, Iteration 38/250, Loss: 0.0602\n",
      "Epoch 6/200, Iteration 39/250, Loss: 0.0914\n",
      "Epoch 6/200, Iteration 40/250, Loss: 0.1132\n",
      "Epoch 6/200, Iteration 41/250, Loss: 0.1118\n",
      "Epoch 6/200, Iteration 42/250, Loss: 0.0932\n",
      "Epoch 6/200, Iteration 43/250, Loss: 0.0941\n",
      "Epoch 6/200, Iteration 44/250, Loss: 0.0791\n",
      "Epoch 6/200, Iteration 45/250, Loss: 0.1128\n",
      "Epoch 6/200, Iteration 46/250, Loss: 0.0983\n",
      "Epoch 6/200, Iteration 47/250, Loss: 0.0673\n",
      "Epoch 6/200, Iteration 48/250, Loss: 0.0730\n",
      "Epoch 6/200, Iteration 49/250, Loss: 0.0736\n",
      "Epoch 6/200, Iteration 50/250, Loss: 0.0617\n",
      "Epoch 6/200, Iteration 51/250, Loss: 0.0584\n",
      "Epoch 6/200, Iteration 52/250, Loss: 0.0443\n",
      "Epoch 6/200, Iteration 53/250, Loss: 0.0859\n",
      "Epoch 6/200, Iteration 54/250, Loss: 0.0736\n",
      "Epoch 6/200, Iteration 55/250, Loss: 0.0710\n",
      "Epoch 6/200, Iteration 56/250, Loss: 0.0477\n",
      "Epoch 6/200, Iteration 57/250, Loss: 0.0537\n",
      "Epoch 6/200, Iteration 58/250, Loss: 0.0791\n",
      "Epoch 6/200, Iteration 59/250, Loss: 0.0821\n",
      "Epoch 6/200, Iteration 60/250, Loss: 0.0387\n",
      "Epoch 6/200, Iteration 61/250, Loss: 0.0465\n",
      "Epoch 6/200, Iteration 62/250, Loss: 0.0725\n",
      "Epoch 6/200, Iteration 63/250, Loss: 0.0839\n",
      "Epoch 6/200, Iteration 64/250, Loss: 0.1029\n",
      "Epoch 6/200, Iteration 65/250, Loss: 0.0769\n",
      "Epoch 6/200, Iteration 66/250, Loss: 0.1328\n",
      "Epoch 6/200, Iteration 67/250, Loss: 0.0614\n",
      "Epoch 6/200, Iteration 68/250, Loss: 0.1051\n",
      "Epoch 6/200, Iteration 69/250, Loss: 0.1606\n",
      "Epoch 6/200, Iteration 70/250, Loss: 0.1119\n",
      "Epoch 6/200, Iteration 71/250, Loss: 0.1296\n",
      "Epoch 6/200, Iteration 72/250, Loss: 0.2038\n",
      "Epoch 6/200, Iteration 73/250, Loss: 0.1463\n",
      "Epoch 6/200, Iteration 74/250, Loss: 0.0648\n",
      "Epoch 6/200, Iteration 75/250, Loss: 0.1008\n",
      "Epoch 6/200, Iteration 76/250, Loss: 0.1140\n",
      "Epoch 6/200, Iteration 77/250, Loss: 0.0516\n",
      "Epoch 6/200, Iteration 78/250, Loss: 0.1052\n",
      "Epoch 6/200, Iteration 79/250, Loss: 0.1014\n",
      "Epoch 6/200, Iteration 80/250, Loss: 0.0560\n",
      "Epoch 6/200, Iteration 81/250, Loss: 0.1194\n",
      "Epoch 6/200, Iteration 82/250, Loss: 0.1631\n",
      "Epoch 6/200, Iteration 83/250, Loss: 0.0554\n",
      "Epoch 6/200, Iteration 84/250, Loss: 0.1421\n",
      "Epoch 6/200, Iteration 85/250, Loss: 0.1491\n",
      "Epoch 6/200, Iteration 86/250, Loss: 0.1158\n",
      "Epoch 6/200, Iteration 87/250, Loss: 0.1518\n",
      "Epoch 6/200, Iteration 88/250, Loss: 0.1380\n",
      "Epoch 6/200, Iteration 89/250, Loss: 0.0892\n",
      "Epoch 6/200, Iteration 90/250, Loss: 0.1465\n",
      "Epoch 6/200, Iteration 91/250, Loss: 0.0986\n",
      "Epoch 6/200, Iteration 92/250, Loss: 0.1231\n",
      "Epoch 6/200, Iteration 93/250, Loss: 0.1549\n",
      "Epoch 6/200, Iteration 94/250, Loss: 0.1050\n",
      "Epoch 6/200, Iteration 95/250, Loss: 0.1243\n",
      "Epoch 6/200, Iteration 96/250, Loss: 0.0932\n",
      "Epoch 6/200, Iteration 97/250, Loss: 0.0586\n",
      "Epoch 6/200, Iteration 98/250, Loss: 0.0552\n",
      "Epoch 6/200, Iteration 99/250, Loss: 0.0598\n",
      "Epoch 6/200, Iteration 100/250, Loss: 0.0555\n",
      "Epoch 6/200, Iteration 101/250, Loss: 0.0696\n",
      "Epoch 6/200, Iteration 102/250, Loss: 0.0650\n",
      "Epoch 6/200, Iteration 103/250, Loss: 0.0592\n",
      "Epoch 6/200, Iteration 104/250, Loss: 0.0437\n",
      "Epoch 6/200, Iteration 105/250, Loss: 0.0612\n",
      "Epoch 6/200, Iteration 106/250, Loss: 0.0409\n",
      "Epoch 6/200, Iteration 107/250, Loss: 0.0571\n",
      "Epoch 6/200, Iteration 108/250, Loss: 0.0722\n",
      "Epoch 6/200, Iteration 109/250, Loss: 0.0544\n",
      "Epoch 6/200, Iteration 110/250, Loss: 0.0435\n",
      "Epoch 6/200, Iteration 111/250, Loss: 0.0628\n",
      "Epoch 6/200, Iteration 112/250, Loss: 0.0713\n",
      "Epoch 6/200, Iteration 113/250, Loss: 0.0427\n",
      "Epoch 6/200, Iteration 114/250, Loss: 0.0604\n",
      "Epoch 6/200, Iteration 115/250, Loss: 0.0648\n",
      "Epoch 6/200, Iteration 116/250, Loss: 0.0520\n",
      "Epoch 6/200, Iteration 117/250, Loss: 0.0276\n",
      "Epoch 6/200, Iteration 118/250, Loss: 0.0514\n",
      "Epoch 6/200, Iteration 119/250, Loss: 0.0631\n",
      "Epoch 6/200, Iteration 120/250, Loss: 0.0449\n",
      "Epoch 6/200, Iteration 121/250, Loss: 0.0987\n",
      "Epoch 6/200, Iteration 122/250, Loss: 0.0893\n",
      "Epoch 6/200, Iteration 123/250, Loss: 0.0517\n",
      "Epoch 6/200, Iteration 124/250, Loss: 0.0821\n",
      "Epoch 6/200, Iteration 125/250, Loss: 0.0346\n",
      "Epoch 6/200, Iteration 126/250, Loss: 0.0476\n",
      "Epoch 6/200, Iteration 127/250, Loss: 0.0592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Iteration 128/250, Loss: 0.0515\n",
      "Epoch 6/200, Iteration 129/250, Loss: 0.0521\n",
      "Epoch 6/200, Iteration 130/250, Loss: 0.0452\n",
      "Epoch 6/200, Iteration 131/250, Loss: 0.0547\n",
      "Epoch 6/200, Iteration 132/250, Loss: 0.0738\n",
      "Epoch 6/200, Iteration 133/250, Loss: 0.0738\n",
      "Epoch 6/200, Iteration 134/250, Loss: 0.0581\n",
      "Epoch 6/200, Iteration 135/250, Loss: 0.0688\n",
      "Epoch 6/200, Iteration 136/250, Loss: 0.0572\n",
      "Epoch 6/200, Iteration 137/250, Loss: 0.0500\n",
      "Epoch 6/200, Iteration 138/250, Loss: 0.0426\n",
      "Epoch 6/200, Iteration 139/250, Loss: 0.0899\n",
      "Epoch 6/200, Iteration 140/250, Loss: 0.0652\n",
      "Epoch 6/200, Iteration 141/250, Loss: 0.0332\n",
      "Epoch 6/200, Iteration 142/250, Loss: 0.0536\n",
      "Epoch 6/200, Iteration 143/250, Loss: 0.0511\n",
      "Epoch 6/200, Iteration 144/250, Loss: 0.0929\n",
      "Epoch 6/200, Iteration 145/250, Loss: 0.0561\n",
      "Epoch 6/200, Iteration 146/250, Loss: 0.0835\n",
      "Epoch 6/200, Iteration 147/250, Loss: 0.0573\n",
      "Epoch 6/200, Iteration 148/250, Loss: 0.0916\n",
      "Epoch 6/200, Iteration 149/250, Loss: 0.0952\n",
      "Epoch 6/200, Iteration 150/250, Loss: 0.0847\n",
      "Epoch 6/200, Iteration 151/250, Loss: 0.0748\n",
      "Epoch 6/200, Iteration 152/250, Loss: 0.0694\n",
      "Epoch 6/200, Iteration 153/250, Loss: 0.0654\n",
      "Epoch 6/200, Iteration 154/250, Loss: 0.0411\n",
      "Epoch 6/200, Iteration 155/250, Loss: 0.0621\n",
      "Epoch 6/200, Iteration 156/250, Loss: 0.0692\n",
      "Epoch 6/200, Iteration 157/250, Loss: 0.0574\n",
      "Epoch 6/200, Iteration 158/250, Loss: 0.0392\n",
      "Epoch 6/200, Iteration 159/250, Loss: 0.0762\n",
      "Epoch 6/200, Iteration 160/250, Loss: 0.0685\n",
      "Epoch 6/200, Iteration 161/250, Loss: 0.0288\n",
      "Epoch 6/200, Iteration 162/250, Loss: 0.0879\n",
      "Epoch 6/200, Iteration 163/250, Loss: 0.0769\n",
      "Epoch 6/200, Iteration 164/250, Loss: 0.0670\n",
      "Epoch 6/200, Iteration 165/250, Loss: 0.0596\n",
      "Epoch 6/200, Iteration 166/250, Loss: 0.1041\n",
      "Epoch 6/200, Iteration 167/250, Loss: 0.0624\n",
      "Epoch 6/200, Iteration 168/250, Loss: 0.0387\n",
      "Epoch 6/200, Iteration 169/250, Loss: 0.0822\n",
      "Epoch 6/200, Iteration 170/250, Loss: 0.0633\n",
      "Epoch 6/200, Iteration 171/250, Loss: 0.0791\n",
      "Epoch 6/200, Iteration 172/250, Loss: 0.0669\n",
      "Epoch 6/200, Iteration 173/250, Loss: 0.0544\n",
      "Epoch 6/200, Iteration 174/250, Loss: 0.0633\n",
      "Epoch 6/200, Iteration 175/250, Loss: 0.0840\n",
      "Epoch 6/200, Iteration 176/250, Loss: 0.0416\n",
      "Epoch 6/200, Iteration 177/250, Loss: 0.0899\n",
      "Epoch 6/200, Iteration 178/250, Loss: 0.0594\n",
      "Epoch 6/200, Iteration 179/250, Loss: 0.0985\n",
      "Epoch 6/200, Iteration 180/250, Loss: 0.1052\n",
      "Epoch 6/200, Iteration 181/250, Loss: 0.1047\n",
      "Epoch 6/200, Iteration 182/250, Loss: 0.0979\n",
      "Epoch 6/200, Iteration 183/250, Loss: 0.0906\n",
      "Epoch 6/200, Iteration 184/250, Loss: 0.0843\n",
      "Epoch 6/200, Iteration 185/250, Loss: 0.0630\n",
      "Epoch 6/200, Iteration 186/250, Loss: 0.0640\n",
      "Epoch 6/200, Iteration 187/250, Loss: 0.0492\n",
      "Epoch 6/200, Iteration 188/250, Loss: 0.0376\n",
      "Epoch 6/200, Iteration 189/250, Loss: 0.0477\n",
      "Epoch 6/200, Iteration 190/250, Loss: 0.0866\n",
      "Epoch 6/200, Iteration 191/250, Loss: 0.0438\n",
      "Epoch 6/200, Iteration 192/250, Loss: 0.1078\n",
      "Epoch 6/200, Iteration 193/250, Loss: 0.0704\n",
      "Epoch 6/200, Iteration 194/250, Loss: 0.1441\n",
      "Epoch 6/200, Iteration 195/250, Loss: 0.1386\n",
      "Epoch 6/200, Iteration 196/250, Loss: 0.0477\n",
      "Epoch 6/200, Iteration 197/250, Loss: 0.1167\n",
      "Epoch 6/200, Iteration 198/250, Loss: 0.0438\n",
      "Epoch 6/200, Iteration 199/250, Loss: 0.0896\n",
      "Epoch 6/200, Iteration 200/250, Loss: 0.0758\n",
      "Epoch 6/200, Iteration 201/250, Loss: 0.1187\n",
      "Epoch 6/200, Iteration 202/250, Loss: 0.1154\n",
      "Epoch 6/200, Iteration 203/250, Loss: 0.0568\n",
      "Epoch 6/200, Iteration 204/250, Loss: 0.0848\n",
      "Epoch 6/200, Iteration 205/250, Loss: 0.0807\n",
      "Epoch 6/200, Iteration 206/250, Loss: 0.0854\n",
      "Epoch 6/200, Iteration 207/250, Loss: 0.1093\n",
      "Epoch 6/200, Iteration 208/250, Loss: 0.0534\n",
      "Epoch 6/200, Iteration 209/250, Loss: 0.0703\n",
      "Epoch 6/200, Iteration 210/250, Loss: 0.0664\n",
      "Epoch 6/200, Iteration 211/250, Loss: 0.0756\n",
      "Epoch 6/200, Iteration 212/250, Loss: 0.0908\n",
      "Epoch 6/200, Iteration 213/250, Loss: 0.0746\n",
      "Epoch 6/200, Iteration 214/250, Loss: 0.0668\n",
      "Epoch 6/200, Iteration 215/250, Loss: 0.0558\n",
      "Epoch 6/200, Iteration 216/250, Loss: 0.0498\n",
      "Epoch 6/200, Iteration 217/250, Loss: 0.0413\n",
      "Epoch 6/200, Iteration 218/250, Loss: 0.0467\n",
      "Epoch 6/200, Iteration 219/250, Loss: 0.0659\n",
      "Epoch 6/200, Iteration 220/250, Loss: 0.0603\n",
      "Epoch 6/200, Iteration 221/250, Loss: 0.0463\n",
      "Epoch 6/200, Iteration 222/250, Loss: 0.0477\n",
      "Epoch 6/200, Iteration 223/250, Loss: 0.0345\n",
      "Epoch 6/200, Iteration 224/250, Loss: 0.0436\n",
      "Epoch 6/200, Iteration 225/250, Loss: 0.0551\n",
      "Epoch 6/200, Iteration 226/250, Loss: 0.0705\n",
      "Epoch 6/200, Iteration 227/250, Loss: 0.0761\n",
      "Epoch 6/200, Iteration 228/250, Loss: 0.0728\n",
      "Epoch 6/200, Iteration 229/250, Loss: 0.0731\n",
      "Epoch 6/200, Iteration 230/250, Loss: 0.0459\n",
      "Epoch 6/200, Iteration 231/250, Loss: 0.0557\n",
      "Epoch 6/200, Iteration 232/250, Loss: 0.0512\n",
      "Epoch 6/200, Iteration 233/250, Loss: 0.0290\n",
      "Epoch 6/200, Iteration 234/250, Loss: 0.0825\n",
      "Epoch 6/200, Iteration 235/250, Loss: 0.0624\n",
      "Epoch 6/200, Iteration 236/250, Loss: 0.0462\n",
      "Epoch 6/200, Iteration 237/250, Loss: 0.0848\n",
      "Epoch 6/200, Iteration 238/250, Loss: 0.0507\n",
      "Epoch 6/200, Iteration 239/250, Loss: 0.0389\n",
      "Epoch 6/200, Iteration 240/250, Loss: 0.0473\n",
      "Epoch 6/200, Iteration 241/250, Loss: 0.0628\n",
      "Epoch 6/200, Iteration 242/250, Loss: 0.0491\n",
      "Epoch 6/200, Iteration 243/250, Loss: 0.0579\n",
      "Epoch 6/200, Iteration 244/250, Loss: 0.0507\n",
      "Epoch 6/200, Iteration 245/250, Loss: 0.0324\n",
      "Epoch 6/200, Iteration 246/250, Loss: 0.0393\n",
      "Epoch 6/200, Iteration 247/250, Loss: 0.0544\n",
      "Epoch 6/200, Iteration 248/250, Loss: 0.0522\n",
      "Epoch 6/200, Iteration 249/250, Loss: 0.0554\n",
      "Epoch 6/200, Iteration 250/250, Loss: 0.0375\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.052205, MRE: 3.902559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.45%, Avg loss: 0.052931, MRE: 5.090322 \n",
      "\n",
      "Epoch 7/200, Iteration 1/250, Loss: 0.0517\n",
      "Epoch 7/200, Iteration 2/250, Loss: 0.0848\n",
      "Epoch 7/200, Iteration 3/250, Loss: 0.0422\n",
      "Epoch 7/200, Iteration 4/250, Loss: 0.0555\n",
      "Epoch 7/200, Iteration 5/250, Loss: 0.0819\n",
      "Epoch 7/200, Iteration 6/250, Loss: 0.0593\n",
      "Epoch 7/200, Iteration 7/250, Loss: 0.1215\n",
      "Epoch 7/200, Iteration 8/250, Loss: 0.0518\n",
      "Epoch 7/200, Iteration 9/250, Loss: 0.1074\n",
      "Epoch 7/200, Iteration 10/250, Loss: 0.0527\n",
      "Epoch 7/200, Iteration 11/250, Loss: 0.1146\n",
      "Epoch 7/200, Iteration 12/250, Loss: 0.0555\n",
      "Epoch 7/200, Iteration 13/250, Loss: 0.0826\n",
      "Epoch 7/200, Iteration 14/250, Loss: 0.0747\n",
      "Epoch 7/200, Iteration 15/250, Loss: 0.0462\n",
      "Epoch 7/200, Iteration 16/250, Loss: 0.0505\n",
      "Epoch 7/200, Iteration 17/250, Loss: 0.0630\n",
      "Epoch 7/200, Iteration 18/250, Loss: 0.0793\n",
      "Epoch 7/200, Iteration 19/250, Loss: 0.0537\n",
      "Epoch 7/200, Iteration 20/250, Loss: 0.1301\n",
      "Epoch 7/200, Iteration 21/250, Loss: 0.1023\n",
      "Epoch 7/200, Iteration 22/250, Loss: 0.0869\n",
      "Epoch 7/200, Iteration 23/250, Loss: 0.0775\n",
      "Epoch 7/200, Iteration 24/250, Loss: 0.0484\n",
      "Epoch 7/200, Iteration 25/250, Loss: 0.0964\n",
      "Epoch 7/200, Iteration 26/250, Loss: 0.0384\n",
      "Epoch 7/200, Iteration 27/250, Loss: 0.1124\n",
      "Epoch 7/200, Iteration 28/250, Loss: 0.0826\n",
      "Epoch 7/200, Iteration 29/250, Loss: 0.1090\n",
      "Epoch 7/200, Iteration 30/250, Loss: 0.0720\n",
      "Epoch 7/200, Iteration 31/250, Loss: 0.0872\n",
      "Epoch 7/200, Iteration 32/250, Loss: 0.0563\n",
      "Epoch 7/200, Iteration 33/250, Loss: 0.0489\n",
      "Epoch 7/200, Iteration 34/250, Loss: 0.1164\n",
      "Epoch 7/200, Iteration 35/250, Loss: 0.0581\n",
      "Epoch 7/200, Iteration 36/250, Loss: 0.0444\n",
      "Epoch 7/200, Iteration 37/250, Loss: 0.0507\n",
      "Epoch 7/200, Iteration 38/250, Loss: 0.0793\n",
      "Epoch 7/200, Iteration 39/250, Loss: 0.1160\n",
      "Epoch 7/200, Iteration 40/250, Loss: 0.0704\n",
      "Epoch 7/200, Iteration 41/250, Loss: 0.2035\n",
      "Epoch 7/200, Iteration 42/250, Loss: 0.2559\n",
      "Epoch 7/200, Iteration 43/250, Loss: 0.1114\n",
      "Epoch 7/200, Iteration 44/250, Loss: 0.2665\n",
      "Epoch 7/200, Iteration 45/250, Loss: 0.2672\n",
      "Epoch 7/200, Iteration 46/250, Loss: 0.0564\n",
      "Epoch 7/200, Iteration 47/250, Loss: 0.3282\n",
      "Epoch 7/200, Iteration 48/250, Loss: 0.3584\n",
      "Epoch 7/200, Iteration 49/250, Loss: 0.2242\n",
      "Epoch 7/200, Iteration 50/250, Loss: 0.1614\n",
      "Epoch 7/200, Iteration 51/250, Loss: 0.3461\n",
      "Epoch 7/200, Iteration 52/250, Loss: 0.2105\n",
      "Epoch 7/200, Iteration 53/250, Loss: 0.0825\n",
      "Epoch 7/200, Iteration 54/250, Loss: 0.1882\n",
      "Epoch 7/200, Iteration 55/250, Loss: 0.1449\n",
      "Epoch 7/200, Iteration 56/250, Loss: 0.1580\n",
      "Epoch 7/200, Iteration 57/250, Loss: 0.1539\n",
      "Epoch 7/200, Iteration 58/250, Loss: 0.0915\n",
      "Epoch 7/200, Iteration 59/250, Loss: 0.1125\n",
      "Epoch 7/200, Iteration 60/250, Loss: 0.1211\n",
      "Epoch 7/200, Iteration 61/250, Loss: 0.1046\n",
      "Epoch 7/200, Iteration 62/250, Loss: 0.0750\n",
      "Epoch 7/200, Iteration 63/250, Loss: 0.0847\n",
      "Epoch 7/200, Iteration 64/250, Loss: 0.0858\n",
      "Epoch 7/200, Iteration 65/250, Loss: 0.0694\n",
      "Epoch 7/200, Iteration 66/250, Loss: 0.0489\n",
      "Epoch 7/200, Iteration 67/250, Loss: 0.0646\n",
      "Epoch 7/200, Iteration 68/250, Loss: 0.0592\n",
      "Epoch 7/200, Iteration 69/250, Loss: 0.0852\n",
      "Epoch 7/200, Iteration 70/250, Loss: 0.0609\n",
      "Epoch 7/200, Iteration 71/250, Loss: 0.0519\n",
      "Epoch 7/200, Iteration 72/250, Loss: 0.0547\n",
      "Epoch 7/200, Iteration 73/250, Loss: 0.0575\n",
      "Epoch 7/200, Iteration 74/250, Loss: 0.0581\n",
      "Epoch 7/200, Iteration 75/250, Loss: 0.0381\n",
      "Epoch 7/200, Iteration 76/250, Loss: 0.0489\n",
      "Epoch 7/200, Iteration 77/250, Loss: 0.0488\n",
      "Epoch 7/200, Iteration 78/250, Loss: 0.0531\n",
      "Epoch 7/200, Iteration 79/250, Loss: 0.0642\n",
      "Epoch 7/200, Iteration 80/250, Loss: 0.0618\n",
      "Epoch 7/200, Iteration 81/250, Loss: 0.0361\n",
      "Epoch 7/200, Iteration 82/250, Loss: 0.0983\n",
      "Epoch 7/200, Iteration 83/250, Loss: 0.1131\n",
      "Epoch 7/200, Iteration 84/250, Loss: 0.0705\n",
      "Epoch 7/200, Iteration 85/250, Loss: 0.0735\n",
      "Epoch 7/200, Iteration 86/250, Loss: 0.0534\n",
      "Epoch 7/200, Iteration 87/250, Loss: 0.0597\n",
      "Epoch 7/200, Iteration 88/250, Loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Iteration 89/250, Loss: 0.0829\n",
      "Epoch 7/200, Iteration 90/250, Loss: 0.0923\n",
      "Epoch 7/200, Iteration 91/250, Loss: 0.0710\n",
      "Epoch 7/200, Iteration 92/250, Loss: 0.0522\n",
      "Epoch 7/200, Iteration 93/250, Loss: 0.0541\n",
      "Epoch 7/200, Iteration 94/250, Loss: 0.0366\n",
      "Epoch 7/200, Iteration 95/250, Loss: 0.0412\n",
      "Epoch 7/200, Iteration 96/250, Loss: 0.0622\n",
      "Epoch 7/200, Iteration 97/250, Loss: 0.1003\n",
      "Epoch 7/200, Iteration 98/250, Loss: 0.0745\n",
      "Epoch 7/200, Iteration 99/250, Loss: 0.0650\n",
      "Epoch 7/200, Iteration 100/250, Loss: 0.0968\n",
      "Epoch 7/200, Iteration 101/250, Loss: 0.0593\n",
      "Epoch 7/200, Iteration 102/250, Loss: 0.0639\n",
      "Epoch 7/200, Iteration 103/250, Loss: 0.0644\n",
      "Epoch 7/200, Iteration 104/250, Loss: 0.0640\n",
      "Epoch 7/200, Iteration 105/250, Loss: 0.0709\n",
      "Epoch 7/200, Iteration 106/250, Loss: 0.0678\n",
      "Epoch 7/200, Iteration 107/250, Loss: 0.0838\n",
      "Epoch 7/200, Iteration 108/250, Loss: 0.0591\n",
      "Epoch 7/200, Iteration 109/250, Loss: 0.0602\n",
      "Epoch 7/200, Iteration 110/250, Loss: 0.0913\n",
      "Epoch 7/200, Iteration 111/250, Loss: 0.0876\n",
      "Epoch 7/200, Iteration 112/250, Loss: 0.0536\n",
      "Epoch 7/200, Iteration 113/250, Loss: 0.0909\n",
      "Epoch 7/200, Iteration 114/250, Loss: 0.0671\n",
      "Epoch 7/200, Iteration 115/250, Loss: 0.0818\n",
      "Epoch 7/200, Iteration 116/250, Loss: 0.0799\n",
      "Epoch 7/200, Iteration 117/250, Loss: 0.0427\n",
      "Epoch 7/200, Iteration 118/250, Loss: 0.0622\n",
      "Epoch 7/200, Iteration 119/250, Loss: 0.0743\n",
      "Epoch 7/200, Iteration 120/250, Loss: 0.0436\n",
      "Epoch 7/200, Iteration 121/250, Loss: 0.1326\n",
      "Epoch 7/200, Iteration 122/250, Loss: 0.0710\n",
      "Epoch 7/200, Iteration 123/250, Loss: 0.0807\n",
      "Epoch 7/200, Iteration 124/250, Loss: 0.1198\n",
      "Epoch 7/200, Iteration 125/250, Loss: 0.1121\n",
      "Epoch 7/200, Iteration 126/250, Loss: 0.1505\n",
      "Epoch 7/200, Iteration 127/250, Loss: 0.0521\n",
      "Epoch 7/200, Iteration 128/250, Loss: 0.0954\n",
      "Epoch 7/200, Iteration 129/250, Loss: 0.0770\n",
      "Epoch 7/200, Iteration 130/250, Loss: 0.0857\n",
      "Epoch 7/200, Iteration 131/250, Loss: 0.1142\n",
      "Epoch 7/200, Iteration 132/250, Loss: 0.0844\n",
      "Epoch 7/200, Iteration 133/250, Loss: 0.1538\n",
      "Epoch 7/200, Iteration 134/250, Loss: 0.1177\n",
      "Epoch 7/200, Iteration 135/250, Loss: 0.1328\n",
      "Epoch 7/200, Iteration 136/250, Loss: 0.1885\n",
      "Epoch 7/200, Iteration 137/250, Loss: 0.1218\n",
      "Epoch 7/200, Iteration 138/250, Loss: 0.0953\n",
      "Epoch 7/200, Iteration 139/250, Loss: 0.1438\n",
      "Epoch 7/200, Iteration 140/250, Loss: 0.0810\n",
      "Epoch 7/200, Iteration 141/250, Loss: 0.0855\n",
      "Epoch 7/200, Iteration 142/250, Loss: 0.0877\n",
      "Epoch 7/200, Iteration 143/250, Loss: 0.0965\n",
      "Epoch 7/200, Iteration 144/250, Loss: 0.0716\n",
      "Epoch 7/200, Iteration 145/250, Loss: 0.1146\n",
      "Epoch 7/200, Iteration 146/250, Loss: 0.1231\n",
      "Epoch 7/200, Iteration 147/250, Loss: 0.1346\n",
      "Epoch 7/200, Iteration 148/250, Loss: 0.0475\n",
      "Epoch 7/200, Iteration 149/250, Loss: 0.0934\n",
      "Epoch 7/200, Iteration 150/250, Loss: 0.1066\n",
      "Epoch 7/200, Iteration 151/250, Loss: 0.0598\n",
      "Epoch 7/200, Iteration 152/250, Loss: 0.0671\n",
      "Epoch 7/200, Iteration 153/250, Loss: 0.0834\n",
      "Epoch 7/200, Iteration 154/250, Loss: 0.0860\n",
      "Epoch 7/200, Iteration 155/250, Loss: 0.0656\n",
      "Epoch 7/200, Iteration 156/250, Loss: 0.0698\n",
      "Epoch 7/200, Iteration 157/250, Loss: 0.1014\n",
      "Epoch 7/200, Iteration 158/250, Loss: 0.0794\n",
      "Epoch 7/200, Iteration 159/250, Loss: 0.1064\n",
      "Epoch 7/200, Iteration 160/250, Loss: 0.1258\n",
      "Epoch 7/200, Iteration 161/250, Loss: 0.0889\n",
      "Epoch 7/200, Iteration 162/250, Loss: 0.0919\n",
      "Epoch 7/200, Iteration 163/250, Loss: 0.1733\n",
      "Epoch 7/200, Iteration 164/250, Loss: 0.1232\n",
      "Epoch 7/200, Iteration 165/250, Loss: 0.0819\n",
      "Epoch 7/200, Iteration 166/250, Loss: 0.0671\n",
      "Epoch 7/200, Iteration 167/250, Loss: 0.0613\n",
      "Epoch 7/200, Iteration 168/250, Loss: 0.0681\n",
      "Epoch 7/200, Iteration 169/250, Loss: 0.0995\n",
      "Epoch 7/200, Iteration 170/250, Loss: 0.0663\n",
      "Epoch 7/200, Iteration 171/250, Loss: 0.0388\n",
      "Epoch 7/200, Iteration 172/250, Loss: 0.0957\n",
      "Epoch 7/200, Iteration 173/250, Loss: 0.0642\n",
      "Epoch 7/200, Iteration 174/250, Loss: 0.0731\n",
      "Epoch 7/200, Iteration 175/250, Loss: 0.0389\n",
      "Epoch 7/200, Iteration 176/250, Loss: 0.0690\n",
      "Epoch 7/200, Iteration 177/250, Loss: 0.0905\n",
      "Epoch 7/200, Iteration 178/250, Loss: 0.1077\n",
      "Epoch 7/200, Iteration 179/250, Loss: 0.0886\n",
      "Epoch 7/200, Iteration 180/250, Loss: 0.0791\n",
      "Epoch 7/200, Iteration 181/250, Loss: 0.0550\n",
      "Epoch 7/200, Iteration 182/250, Loss: 0.0429\n",
      "Epoch 7/200, Iteration 183/250, Loss: 0.0672\n",
      "Epoch 7/200, Iteration 184/250, Loss: 0.0497\n",
      "Epoch 7/200, Iteration 185/250, Loss: 0.0567\n",
      "Epoch 7/200, Iteration 186/250, Loss: 0.0565\n",
      "Epoch 7/200, Iteration 187/250, Loss: 0.0539\n",
      "Epoch 7/200, Iteration 188/250, Loss: 0.0594\n",
      "Epoch 7/200, Iteration 189/250, Loss: 0.0691\n",
      "Epoch 7/200, Iteration 190/250, Loss: 0.1048\n",
      "Epoch 7/200, Iteration 191/250, Loss: 0.0770\n",
      "Epoch 7/200, Iteration 192/250, Loss: 0.1275\n",
      "Epoch 7/200, Iteration 193/250, Loss: 0.1272\n",
      "Epoch 7/200, Iteration 194/250, Loss: 0.0483\n",
      "Epoch 7/200, Iteration 195/250, Loss: 0.1344\n",
      "Epoch 7/200, Iteration 196/250, Loss: 0.1070\n",
      "Epoch 7/200, Iteration 197/250, Loss: 0.1456\n",
      "Epoch 7/200, Iteration 198/250, Loss: 0.1537\n",
      "Epoch 7/200, Iteration 199/250, Loss: 0.1296\n",
      "Epoch 7/200, Iteration 200/250, Loss: 0.1014\n",
      "Epoch 7/200, Iteration 201/250, Loss: 0.1489\n",
      "Epoch 7/200, Iteration 202/250, Loss: 0.1192\n",
      "Epoch 7/200, Iteration 203/250, Loss: 0.0740\n",
      "Epoch 7/200, Iteration 204/250, Loss: 0.1176\n",
      "Epoch 7/200, Iteration 205/250, Loss: 0.0971\n",
      "Epoch 7/200, Iteration 206/250, Loss: 0.0668\n",
      "Epoch 7/200, Iteration 207/250, Loss: 0.0740\n",
      "Epoch 7/200, Iteration 208/250, Loss: 0.0698\n",
      "Epoch 7/200, Iteration 209/250, Loss: 0.0781\n",
      "Epoch 7/200, Iteration 210/250, Loss: 0.1097\n",
      "Epoch 7/200, Iteration 211/250, Loss: 0.0778\n",
      "Epoch 7/200, Iteration 212/250, Loss: 0.0571\n",
      "Epoch 7/200, Iteration 213/250, Loss: 0.1083\n",
      "Epoch 7/200, Iteration 214/250, Loss: 0.0994\n",
      "Epoch 7/200, Iteration 215/250, Loss: 0.0772\n",
      "Epoch 7/200, Iteration 216/250, Loss: 0.0576\n",
      "Epoch 7/200, Iteration 217/250, Loss: 0.1317\n",
      "Epoch 7/200, Iteration 218/250, Loss: 0.1181\n",
      "Epoch 7/200, Iteration 219/250, Loss: 0.0888\n",
      "Epoch 7/200, Iteration 220/250, Loss: 0.0791\n",
      "Epoch 7/200, Iteration 221/250, Loss: 0.0838\n",
      "Epoch 7/200, Iteration 222/250, Loss: 0.0804\n",
      "Epoch 7/200, Iteration 223/250, Loss: 0.1279\n",
      "Epoch 7/200, Iteration 224/250, Loss: 0.0650\n",
      "Epoch 7/200, Iteration 225/250, Loss: 0.0645\n",
      "Epoch 7/200, Iteration 226/250, Loss: 0.0358\n",
      "Epoch 7/200, Iteration 227/250, Loss: 0.0656\n",
      "Epoch 7/200, Iteration 228/250, Loss: 0.0720\n",
      "Epoch 7/200, Iteration 229/250, Loss: 0.0574\n",
      "Epoch 7/200, Iteration 230/250, Loss: 0.0880\n",
      "Epoch 7/200, Iteration 231/250, Loss: 0.0911\n",
      "Epoch 7/200, Iteration 232/250, Loss: 0.0515\n",
      "Epoch 7/200, Iteration 233/250, Loss: 0.0568\n",
      "Epoch 7/200, Iteration 234/250, Loss: 0.0651\n",
      "Epoch 7/200, Iteration 235/250, Loss: 0.0703\n",
      "Epoch 7/200, Iteration 236/250, Loss: 0.0592\n",
      "Epoch 7/200, Iteration 237/250, Loss: 0.0811\n",
      "Epoch 7/200, Iteration 238/250, Loss: 0.0723\n",
      "Epoch 7/200, Iteration 239/250, Loss: 0.0971\n",
      "Epoch 7/200, Iteration 240/250, Loss: 0.0821\n",
      "Epoch 7/200, Iteration 241/250, Loss: 0.1191\n",
      "Epoch 7/200, Iteration 242/250, Loss: 0.1023\n",
      "Epoch 7/200, Iteration 243/250, Loss: 0.1606\n",
      "Epoch 7/200, Iteration 244/250, Loss: 0.1191\n",
      "Epoch 7/200, Iteration 245/250, Loss: 0.0961\n",
      "Epoch 7/200, Iteration 246/250, Loss: 0.0692\n",
      "Epoch 7/200, Iteration 247/250, Loss: 0.0808\n",
      "Epoch 7/200, Iteration 248/250, Loss: 0.0735\n",
      "Epoch 7/200, Iteration 249/250, Loss: 0.0453\n",
      "Epoch 7/200, Iteration 250/250, Loss: 0.1204\n",
      "Train Error: \n",
      " Accuracy: 48.44%, Avg loss: 0.052575, MRE: 3.574315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 0.052426, MRE: 3.529972 \n",
      "\n",
      "Epoch 8/200, Iteration 1/250, Loss: 0.0480\n",
      "Epoch 8/200, Iteration 2/250, Loss: 0.0782\n",
      "Epoch 8/200, Iteration 3/250, Loss: 0.0722\n",
      "Epoch 8/200, Iteration 4/250, Loss: 0.0504\n",
      "Epoch 8/200, Iteration 5/250, Loss: 0.0693\n",
      "Epoch 8/200, Iteration 6/250, Loss: 0.1157\n",
      "Epoch 8/200, Iteration 7/250, Loss: 0.0960\n",
      "Epoch 8/200, Iteration 8/250, Loss: 0.1036\n",
      "Epoch 8/200, Iteration 9/250, Loss: 0.0862\n",
      "Epoch 8/200, Iteration 10/250, Loss: 0.0700\n",
      "Epoch 8/200, Iteration 11/250, Loss: 0.1226\n",
      "Epoch 8/200, Iteration 12/250, Loss: 0.1605\n",
      "Epoch 8/200, Iteration 13/250, Loss: 0.0927\n",
      "Epoch 8/200, Iteration 14/250, Loss: 0.1355\n",
      "Epoch 8/200, Iteration 15/250, Loss: 0.1430\n",
      "Epoch 8/200, Iteration 16/250, Loss: 0.1033\n",
      "Epoch 8/200, Iteration 17/250, Loss: 0.0977\n",
      "Epoch 8/200, Iteration 18/250, Loss: 0.0878\n",
      "Epoch 8/200, Iteration 19/250, Loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 20/250, Loss: 0.1040\n",
      "Epoch 8/200, Iteration 21/250, Loss: 0.0395\n",
      "Epoch 8/200, Iteration 22/250, Loss: 0.1123\n",
      "Epoch 8/200, Iteration 23/250, Loss: 0.1256\n",
      "Epoch 8/200, Iteration 24/250, Loss: 0.0880\n",
      "Epoch 8/200, Iteration 25/250, Loss: 0.1154\n",
      "Epoch 8/200, Iteration 26/250, Loss: 0.1242\n",
      "Epoch 8/200, Iteration 27/250, Loss: 0.0971\n",
      "Epoch 8/200, Iteration 28/250, Loss: 0.1142\n",
      "Epoch 8/200, Iteration 29/250, Loss: 0.1284\n",
      "Epoch 8/200, Iteration 30/250, Loss: 0.0706\n",
      "Epoch 8/200, Iteration 31/250, Loss: 0.1372\n",
      "Epoch 8/200, Iteration 32/250, Loss: 0.1797\n",
      "Epoch 8/200, Iteration 33/250, Loss: 0.1730\n",
      "Epoch 8/200, Iteration 34/250, Loss: 0.1272\n",
      "Epoch 8/200, Iteration 35/250, Loss: 0.1462\n",
      "Epoch 8/200, Iteration 36/250, Loss: 0.1337\n",
      "Epoch 8/200, Iteration 37/250, Loss: 0.1014\n",
      "Epoch 8/200, Iteration 38/250, Loss: 0.1446\n",
      "Epoch 8/200, Iteration 39/250, Loss: 0.1611\n",
      "Epoch 8/200, Iteration 40/250, Loss: 0.1052\n",
      "Epoch 8/200, Iteration 41/250, Loss: 0.0764\n",
      "Epoch 8/200, Iteration 42/250, Loss: 0.1109\n",
      "Epoch 8/200, Iteration 43/250, Loss: 0.1043\n",
      "Epoch 8/200, Iteration 44/250, Loss: 0.1162\n",
      "Epoch 8/200, Iteration 45/250, Loss: 0.1279\n",
      "Epoch 8/200, Iteration 46/250, Loss: 0.0819\n",
      "Epoch 8/200, Iteration 47/250, Loss: 0.0755\n",
      "Epoch 8/200, Iteration 48/250, Loss: 0.1090\n",
      "Epoch 8/200, Iteration 49/250, Loss: 0.1326\n",
      "Epoch 8/200, Iteration 50/250, Loss: 0.1404\n",
      "Epoch 8/200, Iteration 51/250, Loss: 0.1196\n",
      "Epoch 8/200, Iteration 52/250, Loss: 0.1323\n",
      "Epoch 8/200, Iteration 53/250, Loss: 0.0631\n",
      "Epoch 8/200, Iteration 54/250, Loss: 0.0950\n",
      "Epoch 8/200, Iteration 55/250, Loss: 0.0846\n",
      "Epoch 8/200, Iteration 56/250, Loss: 0.1519\n",
      "Epoch 8/200, Iteration 57/250, Loss: 0.0930\n",
      "Epoch 8/200, Iteration 58/250, Loss: 0.1813\n",
      "Epoch 8/200, Iteration 59/250, Loss: 0.1210\n",
      "Epoch 8/200, Iteration 60/250, Loss: 0.1192\n",
      "Epoch 8/200, Iteration 61/250, Loss: 0.1418\n",
      "Epoch 8/200, Iteration 62/250, Loss: 0.1218\n",
      "Epoch 8/200, Iteration 63/250, Loss: 0.1245\n",
      "Epoch 8/200, Iteration 64/250, Loss: 0.1081\n",
      "Epoch 8/200, Iteration 65/250, Loss: 0.0947\n",
      "Epoch 8/200, Iteration 66/250, Loss: 0.0488\n",
      "Epoch 8/200, Iteration 67/250, Loss: 0.1775\n",
      "Epoch 8/200, Iteration 68/250, Loss: 0.1568\n",
      "Epoch 8/200, Iteration 69/250, Loss: 0.1079\n",
      "Epoch 8/200, Iteration 70/250, Loss: 0.1827\n",
      "Epoch 8/200, Iteration 71/250, Loss: 0.0791\n",
      "Epoch 8/200, Iteration 72/250, Loss: 0.1419\n",
      "Epoch 8/200, Iteration 73/250, Loss: 0.1123\n",
      "Epoch 8/200, Iteration 74/250, Loss: 0.1000\n",
      "Epoch 8/200, Iteration 75/250, Loss: 0.1152\n",
      "Epoch 8/200, Iteration 76/250, Loss: 0.0785\n",
      "Epoch 8/200, Iteration 77/250, Loss: 0.0932\n",
      "Epoch 8/200, Iteration 78/250, Loss: 0.0532\n",
      "Epoch 8/200, Iteration 79/250, Loss: 0.1002\n",
      "Epoch 8/200, Iteration 80/250, Loss: 0.0890\n",
      "Epoch 8/200, Iteration 81/250, Loss: 0.0726\n",
      "Epoch 8/200, Iteration 82/250, Loss: 0.0521\n",
      "Epoch 8/200, Iteration 83/250, Loss: 0.0651\n",
      "Epoch 8/200, Iteration 84/250, Loss: 0.0532\n",
      "Epoch 8/200, Iteration 85/250, Loss: 0.0682\n",
      "Epoch 8/200, Iteration 86/250, Loss: 0.0782\n",
      "Epoch 8/200, Iteration 87/250, Loss: 0.0852\n",
      "Epoch 8/200, Iteration 88/250, Loss: 0.0635\n",
      "Epoch 8/200, Iteration 89/250, Loss: 0.0601\n",
      "Epoch 8/200, Iteration 90/250, Loss: 0.0776\n",
      "Epoch 8/200, Iteration 91/250, Loss: 0.0686\n",
      "Epoch 8/200, Iteration 92/250, Loss: 0.0446\n",
      "Epoch 8/200, Iteration 93/250, Loss: 0.0608\n",
      "Epoch 8/200, Iteration 94/250, Loss: 0.0591\n",
      "Epoch 8/200, Iteration 95/250, Loss: 0.0585\n",
      "Epoch 8/200, Iteration 96/250, Loss: 0.0568\n",
      "Epoch 8/200, Iteration 97/250, Loss: 0.0895\n",
      "Epoch 8/200, Iteration 98/250, Loss: 0.0425\n",
      "Epoch 8/200, Iteration 99/250, Loss: 0.1657\n",
      "Epoch 8/200, Iteration 100/250, Loss: 0.1597\n",
      "Epoch 8/200, Iteration 101/250, Loss: 0.0512\n",
      "Epoch 8/200, Iteration 102/250, Loss: 0.1877\n",
      "Epoch 8/200, Iteration 103/250, Loss: 0.1133\n",
      "Epoch 8/200, Iteration 104/250, Loss: 0.1643\n",
      "Epoch 8/200, Iteration 105/250, Loss: 0.1656\n",
      "Epoch 8/200, Iteration 106/250, Loss: 0.0885\n",
      "Epoch 8/200, Iteration 107/250, Loss: 0.1032\n",
      "Epoch 8/200, Iteration 108/250, Loss: 0.0528\n",
      "Epoch 8/200, Iteration 109/250, Loss: 0.1375\n",
      "Epoch 8/200, Iteration 110/250, Loss: 0.0783\n",
      "Epoch 8/200, Iteration 111/250, Loss: 0.1367\n",
      "Epoch 8/200, Iteration 112/250, Loss: 0.0785\n",
      "Epoch 8/200, Iteration 113/250, Loss: 0.1122\n",
      "Epoch 8/200, Iteration 114/250, Loss: 0.1109\n",
      "Epoch 8/200, Iteration 115/250, Loss: 0.0920\n",
      "Epoch 8/200, Iteration 116/250, Loss: 0.1209\n",
      "Epoch 8/200, Iteration 117/250, Loss: 0.0528\n",
      "Epoch 8/200, Iteration 118/250, Loss: 0.1048\n",
      "Epoch 8/200, Iteration 119/250, Loss: 0.1030\n",
      "Epoch 8/200, Iteration 120/250, Loss: 0.0790\n",
      "Epoch 8/200, Iteration 121/250, Loss: 0.0580\n",
      "Epoch 8/200, Iteration 122/250, Loss: 0.0738\n",
      "Epoch 8/200, Iteration 123/250, Loss: 0.0574\n",
      "Epoch 8/200, Iteration 124/250, Loss: 0.1030\n",
      "Epoch 8/200, Iteration 125/250, Loss: 0.1323\n",
      "Epoch 8/200, Iteration 126/250, Loss: 0.0572\n",
      "Epoch 8/200, Iteration 127/250, Loss: 0.1173\n",
      "Epoch 8/200, Iteration 128/250, Loss: 0.1056\n",
      "Epoch 8/200, Iteration 129/250, Loss: 0.0833\n",
      "Epoch 8/200, Iteration 130/250, Loss: 0.0455\n",
      "Epoch 8/200, Iteration 131/250, Loss: 0.1388\n",
      "Epoch 8/200, Iteration 132/250, Loss: 0.1490\n",
      "Epoch 8/200, Iteration 133/250, Loss: 0.1152\n",
      "Epoch 8/200, Iteration 134/250, Loss: 0.1407\n",
      "Epoch 8/200, Iteration 135/250, Loss: 0.1777\n",
      "Epoch 8/200, Iteration 136/250, Loss: 0.1109\n",
      "Epoch 8/200, Iteration 137/250, Loss: 0.1709\n",
      "Epoch 8/200, Iteration 138/250, Loss: 0.1699\n",
      "Epoch 8/200, Iteration 139/250, Loss: 0.1286\n",
      "Epoch 8/200, Iteration 140/250, Loss: 0.2143\n",
      "Epoch 8/200, Iteration 141/250, Loss: 0.1789\n",
      "Epoch 8/200, Iteration 142/250, Loss: 0.0656\n",
      "Epoch 8/200, Iteration 143/250, Loss: 0.1108\n",
      "Epoch 8/200, Iteration 144/250, Loss: 0.1070\n",
      "Epoch 8/200, Iteration 145/250, Loss: 0.2490\n",
      "Epoch 8/200, Iteration 146/250, Loss: 0.2047\n",
      "Epoch 8/200, Iteration 147/250, Loss: 0.1176\n",
      "Epoch 8/200, Iteration 148/250, Loss: 0.2114\n",
      "Epoch 8/200, Iteration 149/250, Loss: 0.1696\n",
      "Epoch 8/200, Iteration 150/250, Loss: 0.0747\n",
      "Epoch 8/200, Iteration 151/250, Loss: 0.1627\n",
      "Epoch 8/200, Iteration 152/250, Loss: 0.1557\n",
      "Epoch 8/200, Iteration 153/250, Loss: 0.1577\n",
      "Epoch 8/200, Iteration 154/250, Loss: 0.1362\n",
      "Epoch 8/200, Iteration 155/250, Loss: 0.0447\n",
      "Epoch 8/200, Iteration 156/250, Loss: 0.0941\n",
      "Epoch 8/200, Iteration 157/250, Loss: 0.0972\n",
      "Epoch 8/200, Iteration 158/250, Loss: 0.0659\n",
      "Epoch 8/200, Iteration 159/250, Loss: 0.1075\n",
      "Epoch 8/200, Iteration 160/250, Loss: 0.1042\n",
      "Epoch 8/200, Iteration 161/250, Loss: 0.0670\n",
      "Epoch 8/200, Iteration 162/250, Loss: 0.0848\n",
      "Epoch 8/200, Iteration 163/250, Loss: 0.1700\n",
      "Epoch 8/200, Iteration 164/250, Loss: 0.1472\n",
      "Epoch 8/200, Iteration 165/250, Loss: 0.0795\n",
      "Epoch 8/200, Iteration 166/250, Loss: 0.0736\n",
      "Epoch 8/200, Iteration 167/250, Loss: 0.0611\n",
      "Epoch 8/200, Iteration 168/250, Loss: 0.1384\n",
      "Epoch 8/200, Iteration 169/250, Loss: 0.0994\n",
      "Epoch 8/200, Iteration 170/250, Loss: 0.0970\n",
      "Epoch 8/200, Iteration 171/250, Loss: 0.1167\n",
      "Epoch 8/200, Iteration 172/250, Loss: 0.1184\n",
      "Epoch 8/200, Iteration 173/250, Loss: 0.1395\n",
      "Epoch 8/200, Iteration 174/250, Loss: 0.0882\n",
      "Epoch 8/200, Iteration 175/250, Loss: 0.0972\n",
      "Epoch 8/200, Iteration 176/250, Loss: 0.1009\n",
      "Epoch 8/200, Iteration 177/250, Loss: 0.1359\n",
      "Epoch 8/200, Iteration 178/250, Loss: 0.1880\n",
      "Epoch 8/200, Iteration 179/250, Loss: 0.0702\n",
      "Epoch 8/200, Iteration 180/250, Loss: 0.1316\n",
      "Epoch 8/200, Iteration 181/250, Loss: 0.1918\n",
      "Epoch 8/200, Iteration 182/250, Loss: 0.1492\n",
      "Epoch 8/200, Iteration 183/250, Loss: 0.1448\n",
      "Epoch 8/200, Iteration 184/250, Loss: 0.1678\n",
      "Epoch 8/200, Iteration 185/250, Loss: 0.0978\n",
      "Epoch 8/200, Iteration 186/250, Loss: 0.1296\n",
      "Epoch 8/200, Iteration 187/250, Loss: 0.1106\n",
      "Epoch 8/200, Iteration 188/250, Loss: 0.1073\n",
      "Epoch 8/200, Iteration 189/250, Loss: 0.1239\n",
      "Epoch 8/200, Iteration 190/250, Loss: 0.1198\n",
      "Epoch 8/200, Iteration 191/250, Loss: 0.0947\n",
      "Epoch 8/200, Iteration 192/250, Loss: 0.0941\n",
      "Epoch 8/200, Iteration 193/250, Loss: 0.1262\n",
      "Epoch 8/200, Iteration 194/250, Loss: 0.1087\n",
      "Epoch 8/200, Iteration 195/250, Loss: 0.1486\n",
      "Epoch 8/200, Iteration 196/250, Loss: 0.0827\n",
      "Epoch 8/200, Iteration 197/250, Loss: 0.1100\n",
      "Epoch 8/200, Iteration 198/250, Loss: 0.0813\n",
      "Epoch 8/200, Iteration 199/250, Loss: 0.1162\n",
      "Epoch 8/200, Iteration 200/250, Loss: 0.0998\n",
      "Epoch 8/200, Iteration 201/250, Loss: 0.0506\n",
      "Epoch 8/200, Iteration 202/250, Loss: 0.0508\n",
      "Epoch 8/200, Iteration 203/250, Loss: 0.0676\n",
      "Epoch 8/200, Iteration 204/250, Loss: 0.0666\n",
      "Epoch 8/200, Iteration 205/250, Loss: 0.1084\n",
      "Epoch 8/200, Iteration 206/250, Loss: 0.0737\n",
      "Epoch 8/200, Iteration 207/250, Loss: 0.0645\n",
      "Epoch 8/200, Iteration 208/250, Loss: 0.1071\n",
      "Epoch 8/200, Iteration 209/250, Loss: 0.0641\n",
      "Epoch 8/200, Iteration 210/250, Loss: 0.1000\n",
      "Epoch 8/200, Iteration 211/250, Loss: 0.0586\n",
      "Epoch 8/200, Iteration 212/250, Loss: 0.0470\n",
      "Epoch 8/200, Iteration 213/250, Loss: 0.0596\n",
      "Epoch 8/200, Iteration 214/250, Loss: 0.0379\n",
      "Epoch 8/200, Iteration 215/250, Loss: 0.0556\n",
      "Epoch 8/200, Iteration 216/250, Loss: 0.0404\n",
      "Epoch 8/200, Iteration 217/250, Loss: 0.1010\n",
      "Epoch 8/200, Iteration 218/250, Loss: 0.1036\n",
      "Epoch 8/200, Iteration 219/250, Loss: 0.0892\n",
      "Epoch 8/200, Iteration 220/250, Loss: 0.0589\n",
      "Epoch 8/200, Iteration 221/250, Loss: 0.0600\n",
      "Epoch 8/200, Iteration 222/250, Loss: 0.0686\n",
      "Epoch 8/200, Iteration 223/250, Loss: 0.1215\n",
      "Epoch 8/200, Iteration 224/250, Loss: 0.1020\n",
      "Epoch 8/200, Iteration 225/250, Loss: 0.0950\n",
      "Epoch 8/200, Iteration 226/250, Loss: 0.2033\n",
      "Epoch 8/200, Iteration 227/250, Loss: 0.1754\n",
      "Epoch 8/200, Iteration 228/250, Loss: 0.1003\n",
      "Epoch 8/200, Iteration 229/250, Loss: 0.1292\n",
      "Epoch 8/200, Iteration 230/250, Loss: 0.1639\n",
      "Epoch 8/200, Iteration 231/250, Loss: 0.0989\n",
      "Epoch 8/200, Iteration 232/250, Loss: 0.1004\n",
      "Epoch 8/200, Iteration 233/250, Loss: 0.1701\n",
      "Epoch 8/200, Iteration 234/250, Loss: 0.1728\n",
      "Epoch 8/200, Iteration 235/250, Loss: 0.0501\n",
      "Epoch 8/200, Iteration 236/250, Loss: 0.1304\n",
      "Epoch 8/200, Iteration 237/250, Loss: 0.1756\n",
      "Epoch 8/200, Iteration 238/250, Loss: 0.0626\n",
      "Epoch 8/200, Iteration 239/250, Loss: 0.0907\n",
      "Epoch 8/200, Iteration 240/250, Loss: 0.1641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Iteration 241/250, Loss: 0.0919\n",
      "Epoch 8/200, Iteration 242/250, Loss: 0.0448\n",
      "Epoch 8/200, Iteration 243/250, Loss: 0.0837\n",
      "Epoch 8/200, Iteration 244/250, Loss: 0.0928\n",
      "Epoch 8/200, Iteration 245/250, Loss: 0.0551\n",
      "Epoch 8/200, Iteration 246/250, Loss: 0.1419\n",
      "Epoch 8/200, Iteration 247/250, Loss: 0.0830\n",
      "Epoch 8/200, Iteration 248/250, Loss: 0.1320\n",
      "Epoch 8/200, Iteration 249/250, Loss: 0.1197\n",
      "Epoch 8/200, Iteration 250/250, Loss: 0.0804\n",
      "Train Error: \n",
      " Accuracy: 33.31%, Avg loss: 0.143192, MRE: 13.634797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.7%, Avg loss: 0.142919, MRE: 18.310923 \n",
      "\n",
      "Epoch 9/200, Iteration 1/250, Loss: 0.1253\n",
      "Epoch 9/200, Iteration 2/250, Loss: 0.0542\n",
      "Epoch 9/200, Iteration 3/250, Loss: 0.0571\n",
      "Epoch 9/200, Iteration 4/250, Loss: 0.0479\n",
      "Epoch 9/200, Iteration 5/250, Loss: 0.0408\n",
      "Epoch 9/200, Iteration 6/250, Loss: 0.0457\n",
      "Epoch 9/200, Iteration 7/250, Loss: 0.0708\n",
      "Epoch 9/200, Iteration 8/250, Loss: 0.1553\n",
      "Epoch 9/200, Iteration 9/250, Loss: 0.0959\n",
      "Epoch 9/200, Iteration 10/250, Loss: 0.1428\n",
      "Epoch 9/200, Iteration 11/250, Loss: 0.1412\n",
      "Epoch 9/200, Iteration 12/250, Loss: 0.0737\n",
      "Epoch 9/200, Iteration 13/250, Loss: 0.1264\n",
      "Epoch 9/200, Iteration 14/250, Loss: 0.0763\n",
      "Epoch 9/200, Iteration 15/250, Loss: 0.0863\n",
      "Epoch 9/200, Iteration 16/250, Loss: 0.0621\n",
      "Epoch 9/200, Iteration 17/250, Loss: 0.0441\n",
      "Epoch 9/200, Iteration 18/250, Loss: 0.0437\n",
      "Epoch 9/200, Iteration 19/250, Loss: 0.1158\n",
      "Epoch 9/200, Iteration 20/250, Loss: 0.0861\n",
      "Epoch 9/200, Iteration 21/250, Loss: 0.1336\n",
      "Epoch 9/200, Iteration 22/250, Loss: 0.1542\n",
      "Epoch 9/200, Iteration 23/250, Loss: 0.0726\n",
      "Epoch 9/200, Iteration 24/250, Loss: 0.0693\n",
      "Epoch 9/200, Iteration 25/250, Loss: 0.1127\n",
      "Epoch 9/200, Iteration 26/250, Loss: 0.0595\n",
      "Epoch 9/200, Iteration 27/250, Loss: 0.1280\n",
      "Epoch 9/200, Iteration 28/250, Loss: 0.0803\n",
      "Epoch 9/200, Iteration 29/250, Loss: 0.1567\n",
      "Epoch 9/200, Iteration 30/250, Loss: 0.1025\n",
      "Epoch 9/200, Iteration 31/250, Loss: 0.1510\n",
      "Epoch 9/200, Iteration 32/250, Loss: 0.1105\n",
      "Epoch 9/200, Iteration 33/250, Loss: 0.0373\n",
      "Epoch 9/200, Iteration 34/250, Loss: 0.1010\n",
      "Epoch 9/200, Iteration 35/250, Loss: 0.0731\n",
      "Epoch 9/200, Iteration 36/250, Loss: 0.0645\n",
      "Epoch 9/200, Iteration 37/250, Loss: 0.1207\n",
      "Epoch 9/200, Iteration 38/250, Loss: 0.1110\n",
      "Epoch 9/200, Iteration 39/250, Loss: 0.0815\n",
      "Epoch 9/200, Iteration 40/250, Loss: 0.0793\n",
      "Epoch 9/200, Iteration 41/250, Loss: 0.1304\n",
      "Epoch 9/200, Iteration 42/250, Loss: 0.0866\n",
      "Epoch 9/200, Iteration 43/250, Loss: 0.0693\n",
      "Epoch 9/200, Iteration 44/250, Loss: 0.0745\n",
      "Epoch 9/200, Iteration 45/250, Loss: 0.0994\n",
      "Epoch 9/200, Iteration 46/250, Loss: 0.1005\n",
      "Epoch 9/200, Iteration 47/250, Loss: 0.1132\n",
      "Epoch 9/200, Iteration 48/250, Loss: 0.0648\n",
      "Epoch 9/200, Iteration 49/250, Loss: 0.1804\n",
      "Epoch 9/200, Iteration 50/250, Loss: 0.2404\n",
      "Epoch 9/200, Iteration 51/250, Loss: 0.1003\n",
      "Epoch 9/200, Iteration 52/250, Loss: 0.1654\n",
      "Epoch 9/200, Iteration 53/250, Loss: 0.1779\n",
      "Epoch 9/200, Iteration 54/250, Loss: 0.1162\n",
      "Epoch 9/200, Iteration 55/250, Loss: 0.1641\n",
      "Epoch 9/200, Iteration 56/250, Loss: 0.0663\n",
      "Epoch 9/200, Iteration 57/250, Loss: 0.0886\n",
      "Epoch 9/200, Iteration 58/250, Loss: 0.1020\n",
      "Epoch 9/200, Iteration 59/250, Loss: 0.1010\n",
      "Epoch 9/200, Iteration 60/250, Loss: 0.0914\n",
      "Epoch 9/200, Iteration 61/250, Loss: 0.1172\n",
      "Epoch 9/200, Iteration 62/250, Loss: 0.1182\n",
      "Epoch 9/200, Iteration 63/250, Loss: 0.0724\n",
      "Epoch 9/200, Iteration 64/250, Loss: 0.0946\n",
      "Epoch 9/200, Iteration 65/250, Loss: 0.0960\n",
      "Epoch 9/200, Iteration 66/250, Loss: 0.1218\n",
      "Epoch 9/200, Iteration 67/250, Loss: 0.0760\n",
      "Epoch 9/200, Iteration 68/250, Loss: 0.0801\n",
      "Epoch 9/200, Iteration 69/250, Loss: 0.0774\n",
      "Epoch 9/200, Iteration 70/250, Loss: 0.1535\n",
      "Epoch 9/200, Iteration 71/250, Loss: 0.0990\n",
      "Epoch 9/200, Iteration 72/250, Loss: 0.1028\n",
      "Epoch 9/200, Iteration 73/250, Loss: 0.0843\n",
      "Epoch 9/200, Iteration 74/250, Loss: 0.1854\n",
      "Epoch 9/200, Iteration 75/250, Loss: 0.1558\n",
      "Epoch 9/200, Iteration 76/250, Loss: 0.0845\n",
      "Epoch 9/200, Iteration 77/250, Loss: 0.0520\n",
      "Epoch 9/200, Iteration 78/250, Loss: 0.0627\n",
      "Epoch 9/200, Iteration 79/250, Loss: 0.0645\n",
      "Epoch 9/200, Iteration 80/250, Loss: 0.0453\n",
      "Epoch 9/200, Iteration 81/250, Loss: 0.0402\n",
      "Epoch 9/200, Iteration 82/250, Loss: 0.0767\n",
      "Epoch 9/200, Iteration 83/250, Loss: 0.0791\n",
      "Epoch 9/200, Iteration 84/250, Loss: 0.0672\n",
      "Epoch 9/200, Iteration 85/250, Loss: 0.0737\n",
      "Epoch 9/200, Iteration 86/250, Loss: 0.0632\n",
      "Epoch 9/200, Iteration 87/250, Loss: 0.0620\n",
      "Epoch 9/200, Iteration 88/250, Loss: 0.0829\n",
      "Epoch 9/200, Iteration 89/250, Loss: 0.0612\n",
      "Epoch 9/200, Iteration 90/250, Loss: 0.0955\n",
      "Epoch 9/200, Iteration 91/250, Loss: 0.0461\n",
      "Epoch 9/200, Iteration 92/250, Loss: 0.1462\n",
      "Epoch 9/200, Iteration 93/250, Loss: 0.0542\n",
      "Epoch 9/200, Iteration 94/250, Loss: 0.1176\n",
      "Epoch 9/200, Iteration 95/250, Loss: 0.0669\n",
      "Epoch 9/200, Iteration 96/250, Loss: 0.0715\n",
      "Epoch 9/200, Iteration 97/250, Loss: 0.0658\n",
      "Epoch 9/200, Iteration 98/250, Loss: 0.0907\n",
      "Epoch 9/200, Iteration 99/250, Loss: 0.0779\n",
      "Epoch 9/200, Iteration 100/250, Loss: 0.0528\n",
      "Epoch 9/200, Iteration 101/250, Loss: 0.0458\n",
      "Epoch 9/200, Iteration 102/250, Loss: 0.0903\n",
      "Epoch 9/200, Iteration 103/250, Loss: 0.0636\n",
      "Epoch 9/200, Iteration 104/250, Loss: 0.1098\n",
      "Epoch 9/200, Iteration 105/250, Loss: 0.0845\n",
      "Epoch 9/200, Iteration 106/250, Loss: 0.1478\n",
      "Epoch 9/200, Iteration 107/250, Loss: 0.0427\n",
      "Epoch 9/200, Iteration 108/250, Loss: 0.1429\n",
      "Epoch 9/200, Iteration 109/250, Loss: 0.1305\n",
      "Epoch 9/200, Iteration 110/250, Loss: 0.0849\n",
      "Epoch 9/200, Iteration 111/250, Loss: 0.1280\n",
      "Epoch 9/200, Iteration 112/250, Loss: 0.0662\n",
      "Epoch 9/200, Iteration 113/250, Loss: 0.0597\n",
      "Epoch 9/200, Iteration 114/250, Loss: 0.1807\n",
      "Epoch 9/200, Iteration 115/250, Loss: 0.1608\n",
      "Epoch 9/200, Iteration 116/250, Loss: 0.0773\n",
      "Epoch 9/200, Iteration 117/250, Loss: 0.1155\n",
      "Epoch 9/200, Iteration 118/250, Loss: 0.0584\n",
      "Epoch 9/200, Iteration 119/250, Loss: 0.1278\n",
      "Epoch 9/200, Iteration 120/250, Loss: 0.0438\n",
      "Epoch 9/200, Iteration 121/250, Loss: 0.1228\n",
      "Epoch 9/200, Iteration 122/250, Loss: 0.0732\n",
      "Epoch 9/200, Iteration 123/250, Loss: 0.1722\n",
      "Epoch 9/200, Iteration 124/250, Loss: 0.1773\n",
      "Epoch 9/200, Iteration 125/250, Loss: 0.0538\n",
      "Epoch 9/200, Iteration 126/250, Loss: 0.2020\n",
      "Epoch 9/200, Iteration 127/250, Loss: 0.1886\n",
      "Epoch 9/200, Iteration 128/250, Loss: 0.0583\n",
      "Epoch 9/200, Iteration 129/250, Loss: 0.1685\n",
      "Epoch 9/200, Iteration 130/250, Loss: 0.1133\n",
      "Epoch 9/200, Iteration 131/250, Loss: 0.0511\n",
      "Epoch 9/200, Iteration 132/250, Loss: 0.1419\n",
      "Epoch 9/200, Iteration 133/250, Loss: 0.0802\n",
      "Epoch 9/200, Iteration 134/250, Loss: 0.1270\n",
      "Epoch 9/200, Iteration 135/250, Loss: 0.0768\n",
      "Epoch 9/200, Iteration 136/250, Loss: 0.0542\n",
      "Epoch 9/200, Iteration 137/250, Loss: 0.0481\n",
      "Epoch 9/200, Iteration 138/250, Loss: 0.0669\n",
      "Epoch 9/200, Iteration 139/250, Loss: 0.0778\n",
      "Epoch 9/200, Iteration 140/250, Loss: 0.0622\n",
      "Epoch 9/200, Iteration 141/250, Loss: 0.0574\n",
      "Epoch 9/200, Iteration 142/250, Loss: 0.0763\n",
      "Epoch 9/200, Iteration 143/250, Loss: 0.0608\n",
      "Epoch 9/200, Iteration 144/250, Loss: 0.1070\n",
      "Epoch 9/200, Iteration 145/250, Loss: 0.0891\n",
      "Epoch 9/200, Iteration 146/250, Loss: 0.0613\n",
      "Epoch 9/200, Iteration 147/250, Loss: 0.0627\n",
      "Epoch 9/200, Iteration 148/250, Loss: 0.0932\n",
      "Epoch 9/200, Iteration 149/250, Loss: 0.0843\n",
      "Epoch 9/200, Iteration 150/250, Loss: 0.0824\n",
      "Epoch 9/200, Iteration 151/250, Loss: 0.0562\n",
      "Epoch 9/200, Iteration 152/250, Loss: 0.1425\n",
      "Epoch 9/200, Iteration 153/250, Loss: 0.1039\n",
      "Epoch 9/200, Iteration 154/250, Loss: 0.1213\n",
      "Epoch 9/200, Iteration 155/250, Loss: 0.1092\n",
      "Epoch 9/200, Iteration 156/250, Loss: 0.0857\n",
      "Epoch 9/200, Iteration 157/250, Loss: 0.0657\n",
      "Epoch 9/200, Iteration 158/250, Loss: 0.0724\n",
      "Epoch 9/200, Iteration 159/250, Loss: 0.0623\n",
      "Epoch 9/200, Iteration 160/250, Loss: 0.0889\n",
      "Epoch 9/200, Iteration 161/250, Loss: 0.0525\n",
      "Epoch 9/200, Iteration 162/250, Loss: 0.0602\n",
      "Epoch 9/200, Iteration 163/250, Loss: 0.0787\n",
      "Epoch 9/200, Iteration 164/250, Loss: 0.0549\n",
      "Epoch 9/200, Iteration 165/250, Loss: 0.0808\n",
      "Epoch 9/200, Iteration 166/250, Loss: 0.0771\n",
      "Epoch 9/200, Iteration 167/250, Loss: 0.0812\n",
      "Epoch 9/200, Iteration 168/250, Loss: 0.1070\n",
      "Epoch 9/200, Iteration 169/250, Loss: 0.1040\n",
      "Epoch 9/200, Iteration 170/250, Loss: 0.0917\n",
      "Epoch 9/200, Iteration 171/250, Loss: 0.1006\n",
      "Epoch 9/200, Iteration 172/250, Loss: 0.1412\n",
      "Epoch 9/200, Iteration 173/250, Loss: 0.1396\n",
      "Epoch 9/200, Iteration 174/250, Loss: 0.0933\n",
      "Epoch 9/200, Iteration 175/250, Loss: 0.1277\n",
      "Epoch 9/200, Iteration 176/250, Loss: 0.1040\n",
      "Epoch 9/200, Iteration 177/250, Loss: 0.0559\n",
      "Epoch 9/200, Iteration 178/250, Loss: 0.0957\n",
      "Epoch 9/200, Iteration 179/250, Loss: 0.1125\n",
      "Epoch 9/200, Iteration 180/250, Loss: 0.0915\n",
      "Epoch 9/200, Iteration 181/250, Loss: 0.0803\n",
      "Epoch 9/200, Iteration 182/250, Loss: 0.0966\n",
      "Epoch 9/200, Iteration 183/250, Loss: 0.0609\n",
      "Epoch 9/200, Iteration 184/250, Loss: 0.0602\n",
      "Epoch 9/200, Iteration 185/250, Loss: 0.0563\n",
      "Epoch 9/200, Iteration 186/250, Loss: 0.0441\n",
      "Epoch 9/200, Iteration 187/250, Loss: 0.0487\n",
      "Epoch 9/200, Iteration 188/250, Loss: 0.0464\n",
      "Epoch 9/200, Iteration 189/250, Loss: 0.0609\n",
      "Epoch 9/200, Iteration 190/250, Loss: 0.1744\n",
      "Epoch 9/200, Iteration 191/250, Loss: 0.1244\n",
      "Epoch 9/200, Iteration 192/250, Loss: 0.1252\n",
      "Epoch 9/200, Iteration 193/250, Loss: 0.1036\n",
      "Epoch 9/200, Iteration 194/250, Loss: 0.1616\n",
      "Epoch 9/200, Iteration 195/250, Loss: 0.1333\n",
      "Epoch 9/200, Iteration 196/250, Loss: 0.0606\n",
      "Epoch 9/200, Iteration 197/250, Loss: 0.0648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Iteration 198/250, Loss: 0.1488\n",
      "Epoch 9/200, Iteration 199/250, Loss: 0.0980\n",
      "Epoch 9/200, Iteration 200/250, Loss: 0.0719\n",
      "Epoch 9/200, Iteration 201/250, Loss: 0.0878\n",
      "Epoch 9/200, Iteration 202/250, Loss: 0.1040\n",
      "Epoch 9/200, Iteration 203/250, Loss: 0.0521\n",
      "Epoch 9/200, Iteration 204/250, Loss: 0.0519\n",
      "Epoch 9/200, Iteration 205/250, Loss: 0.1264\n",
      "Epoch 9/200, Iteration 206/250, Loss: 0.1211\n",
      "Epoch 9/200, Iteration 207/250, Loss: 0.1354\n",
      "Epoch 9/200, Iteration 208/250, Loss: 0.0724\n",
      "Epoch 9/200, Iteration 209/250, Loss: 0.1761\n",
      "Epoch 9/200, Iteration 210/250, Loss: 0.1022\n",
      "Epoch 9/200, Iteration 211/250, Loss: 0.1326\n",
      "Epoch 9/200, Iteration 212/250, Loss: 0.1742\n",
      "Epoch 9/200, Iteration 213/250, Loss: 0.0736\n",
      "Epoch 9/200, Iteration 214/250, Loss: 0.0872\n",
      "Epoch 9/200, Iteration 215/250, Loss: 0.0943\n",
      "Epoch 9/200, Iteration 216/250, Loss: 0.1078\n",
      "Epoch 9/200, Iteration 217/250, Loss: 0.0864\n",
      "Epoch 9/200, Iteration 218/250, Loss: 0.0769\n",
      "Epoch 9/200, Iteration 219/250, Loss: 0.0507\n",
      "Epoch 9/200, Iteration 220/250, Loss: 0.0510\n",
      "Epoch 9/200, Iteration 221/250, Loss: 0.0977\n",
      "Epoch 9/200, Iteration 222/250, Loss: 0.0649\n",
      "Epoch 9/200, Iteration 223/250, Loss: 0.0442\n",
      "Epoch 9/200, Iteration 224/250, Loss: 0.0728\n",
      "Epoch 9/200, Iteration 225/250, Loss: 0.0747\n",
      "Epoch 9/200, Iteration 226/250, Loss: 0.0647\n",
      "Epoch 9/200, Iteration 227/250, Loss: 0.0895\n",
      "Epoch 9/200, Iteration 228/250, Loss: 0.0898\n",
      "Epoch 9/200, Iteration 229/250, Loss: 0.0968\n",
      "Epoch 9/200, Iteration 230/250, Loss: 0.0693\n",
      "Epoch 9/200, Iteration 231/250, Loss: 0.0801\n",
      "Epoch 9/200, Iteration 232/250, Loss: 0.1181\n",
      "Epoch 9/200, Iteration 233/250, Loss: 0.0697\n",
      "Epoch 9/200, Iteration 234/250, Loss: 0.2037\n",
      "Epoch 9/200, Iteration 235/250, Loss: 0.2031\n",
      "Epoch 9/200, Iteration 236/250, Loss: 0.0811\n",
      "Epoch 9/200, Iteration 237/250, Loss: 0.2202\n",
      "Epoch 9/200, Iteration 238/250, Loss: 0.1418\n",
      "Epoch 9/200, Iteration 239/250, Loss: 0.1794\n",
      "Epoch 9/200, Iteration 240/250, Loss: 0.1827\n",
      "Epoch 9/200, Iteration 241/250, Loss: 0.0654\n",
      "Epoch 9/200, Iteration 242/250, Loss: 0.2030\n",
      "Epoch 9/200, Iteration 243/250, Loss: 0.1572\n",
      "Epoch 9/200, Iteration 244/250, Loss: 0.1256\n",
      "Epoch 9/200, Iteration 245/250, Loss: 0.1754\n",
      "Epoch 9/200, Iteration 246/250, Loss: 0.0650\n",
      "Epoch 9/200, Iteration 247/250, Loss: 0.1440\n",
      "Epoch 9/200, Iteration 248/250, Loss: 0.1798\n",
      "Epoch 9/200, Iteration 249/250, Loss: 0.0600\n",
      "Epoch 9/200, Iteration 250/250, Loss: 0.2145\n",
      "Train Error: \n",
      " Accuracy: 26.09%, Avg loss: 0.172981, MRE: 16.537918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 25.8%, Avg loss: 0.170790, MRE: 19.507256 \n",
      "\n",
      "Epoch 10/200, Iteration 1/250, Loss: 0.1652\n",
      "Epoch 10/200, Iteration 2/250, Loss: 0.0828\n",
      "Epoch 10/200, Iteration 3/250, Loss: 0.1395\n",
      "Epoch 10/200, Iteration 4/250, Loss: 0.0619\n",
      "Epoch 10/200, Iteration 5/250, Loss: 0.1422\n",
      "Epoch 10/200, Iteration 6/250, Loss: 0.0986\n",
      "Epoch 10/200, Iteration 7/250, Loss: 0.0492\n",
      "Epoch 10/200, Iteration 8/250, Loss: 0.1396\n",
      "Epoch 10/200, Iteration 9/250, Loss: 0.0929\n",
      "Epoch 10/200, Iteration 10/250, Loss: 0.1523\n",
      "Epoch 10/200, Iteration 11/250, Loss: 0.1253\n",
      "Epoch 10/200, Iteration 12/250, Loss: 0.0806\n",
      "Epoch 10/200, Iteration 13/250, Loss: 0.0953\n",
      "Epoch 10/200, Iteration 14/250, Loss: 0.0860\n",
      "Epoch 10/200, Iteration 15/250, Loss: 0.1360\n",
      "Epoch 10/200, Iteration 16/250, Loss: 0.0797\n",
      "Epoch 10/200, Iteration 17/250, Loss: 0.1220\n",
      "Epoch 10/200, Iteration 18/250, Loss: 0.1157\n",
      "Epoch 10/200, Iteration 19/250, Loss: 0.0634\n",
      "Epoch 10/200, Iteration 20/250, Loss: 0.1666\n",
      "Epoch 10/200, Iteration 21/250, Loss: 0.1633\n",
      "Epoch 10/200, Iteration 22/250, Loss: 0.1183\n",
      "Epoch 10/200, Iteration 23/250, Loss: 0.1219\n",
      "Epoch 10/200, Iteration 24/250, Loss: 0.0656\n",
      "Epoch 10/200, Iteration 25/250, Loss: 0.0710\n",
      "Epoch 10/200, Iteration 26/250, Loss: 0.0594\n",
      "Epoch 10/200, Iteration 27/250, Loss: 0.0774\n",
      "Epoch 10/200, Iteration 28/250, Loss: 0.1049\n",
      "Epoch 10/200, Iteration 29/250, Loss: 0.0711\n",
      "Epoch 10/200, Iteration 30/250, Loss: 0.0727\n",
      "Epoch 10/200, Iteration 31/250, Loss: 0.0801\n",
      "Epoch 10/200, Iteration 32/250, Loss: 0.0427\n",
      "Epoch 10/200, Iteration 33/250, Loss: 0.0961\n",
      "Epoch 10/200, Iteration 34/250, Loss: 0.0731\n",
      "Epoch 10/200, Iteration 35/250, Loss: 0.0828\n",
      "Epoch 10/200, Iteration 36/250, Loss: 0.0824\n",
      "Epoch 10/200, Iteration 37/250, Loss: 0.1083\n",
      "Epoch 10/200, Iteration 38/250, Loss: 0.1242\n",
      "Epoch 10/200, Iteration 39/250, Loss: 0.1167\n",
      "Epoch 10/200, Iteration 40/250, Loss: 0.1264\n",
      "Epoch 10/200, Iteration 41/250, Loss: 0.0719\n",
      "Epoch 10/200, Iteration 42/250, Loss: 0.0879\n",
      "Epoch 10/200, Iteration 43/250, Loss: 0.0940\n",
      "Epoch 10/200, Iteration 44/250, Loss: 0.1198\n",
      "Epoch 10/200, Iteration 45/250, Loss: 0.1754\n",
      "Epoch 10/200, Iteration 46/250, Loss: 0.0811\n",
      "Epoch 10/200, Iteration 47/250, Loss: 0.1294\n",
      "Epoch 10/200, Iteration 48/250, Loss: 0.1459\n",
      "Epoch 10/200, Iteration 49/250, Loss: 0.0541\n",
      "Epoch 10/200, Iteration 50/250, Loss: 0.1213\n",
      "Epoch 10/200, Iteration 51/250, Loss: 0.0963\n",
      "Epoch 10/200, Iteration 52/250, Loss: 0.0720\n",
      "Epoch 10/200, Iteration 53/250, Loss: 0.1008\n",
      "Epoch 10/200, Iteration 54/250, Loss: 0.0589\n",
      "Epoch 10/200, Iteration 55/250, Loss: 0.0536\n",
      "Epoch 10/200, Iteration 56/250, Loss: 0.0790\n",
      "Epoch 10/200, Iteration 57/250, Loss: 0.0535\n",
      "Epoch 10/200, Iteration 58/250, Loss: 0.0657\n",
      "Epoch 10/200, Iteration 59/250, Loss: 0.0515\n",
      "Epoch 10/200, Iteration 60/250, Loss: 0.0430\n",
      "Epoch 10/200, Iteration 61/250, Loss: 0.1056\n",
      "Epoch 10/200, Iteration 62/250, Loss: 0.0861\n",
      "Epoch 10/200, Iteration 63/250, Loss: 0.0459\n",
      "Epoch 10/200, Iteration 64/250, Loss: 0.0762\n",
      "Epoch 10/200, Iteration 65/250, Loss: 0.0447\n",
      "Epoch 10/200, Iteration 66/250, Loss: 0.1041\n",
      "Epoch 10/200, Iteration 67/250, Loss: 0.0929\n",
      "Epoch 10/200, Iteration 68/250, Loss: 0.1013\n",
      "Epoch 10/200, Iteration 69/250, Loss: 0.0819\n",
      "Epoch 10/200, Iteration 70/250, Loss: 0.0662\n",
      "Epoch 10/200, Iteration 71/250, Loss: 0.0938\n",
      "Epoch 10/200, Iteration 72/250, Loss: 0.0642\n",
      "Epoch 10/200, Iteration 73/250, Loss: 0.0998\n",
      "Epoch 10/200, Iteration 74/250, Loss: 0.0729\n",
      "Epoch 10/200, Iteration 75/250, Loss: 0.1002\n",
      "Epoch 10/200, Iteration 76/250, Loss: 0.0617\n",
      "Epoch 10/200, Iteration 77/250, Loss: 0.0603\n",
      "Epoch 10/200, Iteration 78/250, Loss: 0.0875\n",
      "Epoch 10/200, Iteration 79/250, Loss: 0.0573\n",
      "Epoch 10/200, Iteration 80/250, Loss: 0.0604\n",
      "Epoch 10/200, Iteration 81/250, Loss: 0.0582\n",
      "Epoch 10/200, Iteration 82/250, Loss: 0.0703\n",
      "Epoch 10/200, Iteration 83/250, Loss: 0.0638\n",
      "Epoch 10/200, Iteration 84/250, Loss: 0.0735\n",
      "Epoch 10/200, Iteration 85/250, Loss: 0.0601\n",
      "Epoch 10/200, Iteration 86/250, Loss: 0.0432\n",
      "Epoch 10/200, Iteration 87/250, Loss: 0.0801\n",
      "Epoch 10/200, Iteration 88/250, Loss: 0.0458\n",
      "Epoch 10/200, Iteration 89/250, Loss: 0.0825\n",
      "Epoch 10/200, Iteration 90/250, Loss: 0.0827\n",
      "Epoch 10/200, Iteration 91/250, Loss: 0.0835\n",
      "Epoch 10/200, Iteration 92/250, Loss: 0.0491\n",
      "Epoch 10/200, Iteration 93/250, Loss: 0.0729\n",
      "Epoch 10/200, Iteration 94/250, Loss: 0.0744\n",
      "Epoch 10/200, Iteration 95/250, Loss: 0.0851\n",
      "Epoch 10/200, Iteration 96/250, Loss: 0.0681\n",
      "Epoch 10/200, Iteration 97/250, Loss: 0.0676\n",
      "Epoch 10/200, Iteration 98/250, Loss: 0.0730\n",
      "Epoch 10/200, Iteration 99/250, Loss: 0.0614\n",
      "Epoch 10/200, Iteration 100/250, Loss: 0.0581\n",
      "Epoch 10/200, Iteration 101/250, Loss: 0.0673\n",
      "Epoch 10/200, Iteration 102/250, Loss: 0.0471\n",
      "Epoch 10/200, Iteration 103/250, Loss: 0.0818\n",
      "Epoch 10/200, Iteration 104/250, Loss: 0.0617\n",
      "Epoch 10/200, Iteration 105/250, Loss: 0.0887\n",
      "Epoch 10/200, Iteration 106/250, Loss: 0.0790\n",
      "Epoch 10/200, Iteration 107/250, Loss: 0.0567\n",
      "Epoch 10/200, Iteration 108/250, Loss: 0.0910\n",
      "Epoch 10/200, Iteration 109/250, Loss: 0.0799\n",
      "Epoch 10/200, Iteration 110/250, Loss: 0.0603\n",
      "Epoch 10/200, Iteration 111/250, Loss: 0.0698\n",
      "Epoch 10/200, Iteration 112/250, Loss: 0.0895\n",
      "Epoch 10/200, Iteration 113/250, Loss: 0.0677\n",
      "Epoch 10/200, Iteration 114/250, Loss: 0.0724\n",
      "Epoch 10/200, Iteration 115/250, Loss: 0.0860\n",
      "Epoch 10/200, Iteration 116/250, Loss: 0.0787\n",
      "Epoch 10/200, Iteration 117/250, Loss: 0.0547\n",
      "Epoch 10/200, Iteration 118/250, Loss: 0.1300\n",
      "Epoch 10/200, Iteration 119/250, Loss: 0.1447\n",
      "Epoch 10/200, Iteration 120/250, Loss: 0.0814\n",
      "Epoch 10/200, Iteration 121/250, Loss: 0.0984\n",
      "Epoch 10/200, Iteration 122/250, Loss: 0.0935\n",
      "Epoch 10/200, Iteration 123/250, Loss: 0.0911\n",
      "Epoch 10/200, Iteration 124/250, Loss: 0.0956\n",
      "Epoch 10/200, Iteration 125/250, Loss: 0.0860\n",
      "Epoch 10/200, Iteration 126/250, Loss: 0.1046\n",
      "Epoch 10/200, Iteration 127/250, Loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Iteration 128/250, Loss: 0.0938\n",
      "Epoch 10/200, Iteration 129/250, Loss: 0.0459\n",
      "Epoch 10/200, Iteration 130/250, Loss: 0.0778\n",
      "Epoch 10/200, Iteration 131/250, Loss: 0.0540\n",
      "Epoch 10/200, Iteration 132/250, Loss: 0.0727\n",
      "Epoch 10/200, Iteration 133/250, Loss: 0.0671\n",
      "Epoch 10/200, Iteration 134/250, Loss: 0.0484\n",
      "Epoch 10/200, Iteration 135/250, Loss: 0.0513\n",
      "Epoch 10/200, Iteration 136/250, Loss: 0.0625\n",
      "Epoch 10/200, Iteration 137/250, Loss: 0.0732\n",
      "Epoch 10/200, Iteration 138/250, Loss: 0.0594\n",
      "Epoch 10/200, Iteration 139/250, Loss: 0.0686\n",
      "Epoch 10/200, Iteration 140/250, Loss: 0.0493\n",
      "Epoch 10/200, Iteration 141/250, Loss: 0.0583\n",
      "Epoch 10/200, Iteration 142/250, Loss: 0.0775\n",
      "Epoch 10/200, Iteration 143/250, Loss: 0.0883\n",
      "Epoch 10/200, Iteration 144/250, Loss: 0.0877\n",
      "Epoch 10/200, Iteration 145/250, Loss: 0.0739\n",
      "Epoch 10/200, Iteration 146/250, Loss: 0.0734\n",
      "Epoch 10/200, Iteration 147/250, Loss: 0.0668\n",
      "Epoch 10/200, Iteration 148/250, Loss: 0.0363\n",
      "Epoch 10/200, Iteration 149/250, Loss: 0.1014\n",
      "Epoch 10/200, Iteration 150/250, Loss: 0.0822\n",
      "Epoch 10/200, Iteration 151/250, Loss: 0.0649\n",
      "Epoch 10/200, Iteration 152/250, Loss: 0.0804\n",
      "Epoch 10/200, Iteration 153/250, Loss: 0.0651\n",
      "Epoch 10/200, Iteration 154/250, Loss: 0.0991\n",
      "Epoch 10/200, Iteration 155/250, Loss: 0.0826\n",
      "Epoch 10/200, Iteration 156/250, Loss: 0.0668\n",
      "Epoch 10/200, Iteration 157/250, Loss: 0.0509\n",
      "Epoch 10/200, Iteration 158/250, Loss: 0.0804\n",
      "Epoch 10/200, Iteration 159/250, Loss: 0.0477\n",
      "Epoch 10/200, Iteration 160/250, Loss: 0.0804\n",
      "Epoch 10/200, Iteration 161/250, Loss: 0.0868\n",
      "Epoch 10/200, Iteration 162/250, Loss: 0.0802\n",
      "Epoch 10/200, Iteration 163/250, Loss: 0.0621\n",
      "Epoch 10/200, Iteration 164/250, Loss: 0.0726\n",
      "Epoch 10/200, Iteration 165/250, Loss: 0.0577\n",
      "Epoch 10/200, Iteration 166/250, Loss: 0.0545\n",
      "Epoch 10/200, Iteration 167/250, Loss: 0.0517\n",
      "Epoch 10/200, Iteration 168/250, Loss: 0.0947\n",
      "Epoch 10/200, Iteration 169/250, Loss: 0.0776\n",
      "Epoch 10/200, Iteration 170/250, Loss: 0.1003\n",
      "Epoch 10/200, Iteration 171/250, Loss: 0.1150\n",
      "Epoch 10/200, Iteration 172/250, Loss: 0.1011\n",
      "Epoch 10/200, Iteration 173/250, Loss: 0.0503\n",
      "Epoch 10/200, Iteration 174/250, Loss: 0.0753\n",
      "Epoch 10/200, Iteration 175/250, Loss: 0.0822\n",
      "Epoch 10/200, Iteration 176/250, Loss: 0.1090\n",
      "Epoch 10/200, Iteration 177/250, Loss: 0.0530\n",
      "Epoch 10/200, Iteration 178/250, Loss: 0.0869\n",
      "Epoch 10/200, Iteration 179/250, Loss: 0.0837\n",
      "Epoch 10/200, Iteration 180/250, Loss: 0.0565\n",
      "Epoch 10/200, Iteration 181/250, Loss: 0.0764\n",
      "Epoch 10/200, Iteration 182/250, Loss: 0.0355\n",
      "Epoch 10/200, Iteration 183/250, Loss: 0.0590\n",
      "Epoch 10/200, Iteration 184/250, Loss: 0.0530\n",
      "Epoch 10/200, Iteration 185/250, Loss: 0.0445\n",
      "Epoch 10/200, Iteration 186/250, Loss: 0.0603\n",
      "Epoch 10/200, Iteration 187/250, Loss: 0.0559\n",
      "Epoch 10/200, Iteration 188/250, Loss: 0.0307\n",
      "Epoch 10/200, Iteration 189/250, Loss: 0.0401\n",
      "Epoch 10/200, Iteration 190/250, Loss: 0.0614\n",
      "Epoch 10/200, Iteration 191/250, Loss: 0.1061\n",
      "Epoch 10/200, Iteration 192/250, Loss: 0.0787\n",
      "Epoch 10/200, Iteration 193/250, Loss: 0.1716\n",
      "Epoch 10/200, Iteration 194/250, Loss: 0.1654\n",
      "Epoch 10/200, Iteration 195/250, Loss: 0.0682\n",
      "Epoch 10/200, Iteration 196/250, Loss: 0.1202\n",
      "Epoch 10/200, Iteration 197/250, Loss: 0.0385\n",
      "Epoch 10/200, Iteration 198/250, Loss: 0.1097\n",
      "Epoch 10/200, Iteration 199/250, Loss: 0.1048\n",
      "Epoch 10/200, Iteration 200/250, Loss: 0.1026\n",
      "Epoch 10/200, Iteration 201/250, Loss: 0.0677\n",
      "Epoch 10/200, Iteration 202/250, Loss: 0.1304\n",
      "Epoch 10/200, Iteration 203/250, Loss: 0.1251\n",
      "Epoch 10/200, Iteration 204/250, Loss: 0.0938\n",
      "Epoch 10/200, Iteration 205/250, Loss: 0.1032\n",
      "Epoch 10/200, Iteration 206/250, Loss: 0.1016\n",
      "Epoch 10/200, Iteration 207/250, Loss: 0.0647\n",
      "Epoch 10/200, Iteration 208/250, Loss: 0.0728\n",
      "Epoch 10/200, Iteration 209/250, Loss: 0.0874\n",
      "Epoch 10/200, Iteration 210/250, Loss: 0.1132\n",
      "Epoch 10/200, Iteration 211/250, Loss: 0.0898\n",
      "Epoch 10/200, Iteration 212/250, Loss: 0.0419\n",
      "Epoch 10/200, Iteration 213/250, Loss: 0.0982\n",
      "Epoch 10/200, Iteration 214/250, Loss: 0.0725\n",
      "Epoch 10/200, Iteration 215/250, Loss: 0.0955\n",
      "Epoch 10/200, Iteration 216/250, Loss: 0.0739\n",
      "Epoch 10/200, Iteration 217/250, Loss: 0.0959\n",
      "Epoch 10/200, Iteration 218/250, Loss: 0.0650\n",
      "Epoch 10/200, Iteration 219/250, Loss: 0.0623\n",
      "Epoch 10/200, Iteration 220/250, Loss: 0.0635\n",
      "Epoch 10/200, Iteration 221/250, Loss: 0.0735\n",
      "Epoch 10/200, Iteration 222/250, Loss: 0.0838\n",
      "Epoch 10/200, Iteration 223/250, Loss: 0.0677\n",
      "Epoch 10/200, Iteration 224/250, Loss: 0.0470\n",
      "Epoch 10/200, Iteration 225/250, Loss: 0.0703\n",
      "Epoch 10/200, Iteration 226/250, Loss: 0.1095\n",
      "Epoch 10/200, Iteration 227/250, Loss: 0.1024\n",
      "Epoch 10/200, Iteration 228/250, Loss: 0.1008\n",
      "Epoch 10/200, Iteration 229/250, Loss: 0.0526\n",
      "Epoch 10/200, Iteration 230/250, Loss: 0.1501\n",
      "Epoch 10/200, Iteration 231/250, Loss: 0.1110\n",
      "Epoch 10/200, Iteration 232/250, Loss: 0.0932\n",
      "Epoch 10/200, Iteration 233/250, Loss: 0.0960\n",
      "Epoch 10/200, Iteration 234/250, Loss: 0.0566\n",
      "Epoch 10/200, Iteration 235/250, Loss: 0.0779\n",
      "Epoch 10/200, Iteration 236/250, Loss: 0.1069\n",
      "Epoch 10/200, Iteration 237/250, Loss: 0.0518\n",
      "Epoch 10/200, Iteration 238/250, Loss: 0.0735\n",
      "Epoch 10/200, Iteration 239/250, Loss: 0.0705\n",
      "Epoch 10/200, Iteration 240/250, Loss: 0.0753\n",
      "Epoch 10/200, Iteration 241/250, Loss: 0.0515\n",
      "Epoch 10/200, Iteration 242/250, Loss: 0.0448\n",
      "Epoch 10/200, Iteration 243/250, Loss: 0.0624\n",
      "Epoch 10/200, Iteration 244/250, Loss: 0.0476\n",
      "Epoch 10/200, Iteration 245/250, Loss: 0.0662\n",
      "Epoch 10/200, Iteration 246/250, Loss: 0.0484\n",
      "Epoch 10/200, Iteration 247/250, Loss: 0.0558\n",
      "Epoch 10/200, Iteration 248/250, Loss: 0.0628\n",
      "Epoch 10/200, Iteration 249/250, Loss: 0.0506\n",
      "Epoch 10/200, Iteration 250/250, Loss: 0.0443\n",
      "Train Error: \n",
      " Accuracy: 69.89%, Avg loss: 0.056516, MRE: 4.616964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.055705, MRE: 4.038333 \n",
      "\n",
      "Epoch 11/200, Iteration 1/250, Loss: 0.0523\n",
      "Epoch 11/200, Iteration 2/250, Loss: 0.0586\n",
      "Epoch 11/200, Iteration 3/250, Loss: 0.0502\n",
      "Epoch 11/200, Iteration 4/250, Loss: 0.0856\n",
      "Epoch 11/200, Iteration 5/250, Loss: 0.0528\n",
      "Epoch 11/200, Iteration 6/250, Loss: 0.0870\n",
      "Epoch 11/200, Iteration 7/250, Loss: 0.0646\n",
      "Epoch 11/200, Iteration 8/250, Loss: 0.0508\n",
      "Epoch 11/200, Iteration 9/250, Loss: 0.0449\n",
      "Epoch 11/200, Iteration 10/250, Loss: 0.0859\n",
      "Epoch 11/200, Iteration 11/250, Loss: 0.0750\n",
      "Epoch 11/200, Iteration 12/250, Loss: 0.1179\n",
      "Epoch 11/200, Iteration 13/250, Loss: 0.0805\n",
      "Epoch 11/200, Iteration 14/250, Loss: 0.1179\n",
      "Epoch 11/200, Iteration 15/250, Loss: 0.0872\n",
      "Epoch 11/200, Iteration 16/250, Loss: 0.1268\n",
      "Epoch 11/200, Iteration 17/250, Loss: 0.1385\n",
      "Epoch 11/200, Iteration 18/250, Loss: 0.0643\n",
      "Epoch 11/200, Iteration 19/250, Loss: 0.1262\n",
      "Epoch 11/200, Iteration 20/250, Loss: 0.1093\n",
      "Epoch 11/200, Iteration 21/250, Loss: 0.1034\n",
      "Epoch 11/200, Iteration 22/250, Loss: 0.1504\n",
      "Epoch 11/200, Iteration 23/250, Loss: 0.1200\n",
      "Epoch 11/200, Iteration 24/250, Loss: 0.1094\n",
      "Epoch 11/200, Iteration 25/250, Loss: 0.1803\n",
      "Epoch 11/200, Iteration 26/250, Loss: 0.1239\n",
      "Epoch 11/200, Iteration 27/250, Loss: 0.0675\n",
      "Epoch 11/200, Iteration 28/250, Loss: 0.0772\n",
      "Epoch 11/200, Iteration 29/250, Loss: 0.0658\n",
      "Epoch 11/200, Iteration 30/250, Loss: 0.0694\n",
      "Epoch 11/200, Iteration 31/250, Loss: 0.0441\n",
      "Epoch 11/200, Iteration 32/250, Loss: 0.0386\n",
      "Epoch 11/200, Iteration 33/250, Loss: 0.0680\n",
      "Epoch 11/200, Iteration 34/250, Loss: 0.0723\n",
      "Epoch 11/200, Iteration 35/250, Loss: 0.0413\n",
      "Epoch 11/200, Iteration 36/250, Loss: 0.0880\n",
      "Epoch 11/200, Iteration 37/250, Loss: 0.0637\n",
      "Epoch 11/200, Iteration 38/250, Loss: 0.0955\n",
      "Epoch 11/200, Iteration 39/250, Loss: 0.0703\n",
      "Epoch 11/200, Iteration 40/250, Loss: 0.0479\n",
      "Epoch 11/200, Iteration 41/250, Loss: 0.0854\n",
      "Epoch 11/200, Iteration 42/250, Loss: 0.0846\n",
      "Epoch 11/200, Iteration 43/250, Loss: 0.0389\n",
      "Epoch 11/200, Iteration 44/250, Loss: 0.0924\n",
      "Epoch 11/200, Iteration 45/250, Loss: 0.0848\n",
      "Epoch 11/200, Iteration 46/250, Loss: 0.0806\n",
      "Epoch 11/200, Iteration 47/250, Loss: 0.0806\n",
      "Epoch 11/200, Iteration 48/250, Loss: 0.0861\n",
      "Epoch 11/200, Iteration 49/250, Loss: 0.1212\n",
      "Epoch 11/200, Iteration 50/250, Loss: 0.0605\n",
      "Epoch 11/200, Iteration 51/250, Loss: 0.0518\n",
      "Epoch 11/200, Iteration 52/250, Loss: 0.0885\n",
      "Epoch 11/200, Iteration 53/250, Loss: 0.0877\n",
      "Epoch 11/200, Iteration 54/250, Loss: 0.1075\n",
      "Epoch 11/200, Iteration 55/250, Loss: 0.0896\n",
      "Epoch 11/200, Iteration 56/250, Loss: 0.0657\n",
      "Epoch 11/200, Iteration 57/250, Loss: 0.0725\n",
      "Epoch 11/200, Iteration 58/250, Loss: 0.0893\n",
      "Epoch 11/200, Iteration 59/250, Loss: 0.0777\n",
      "Epoch 11/200, Iteration 60/250, Loss: 0.0772\n",
      "Epoch 11/200, Iteration 61/250, Loss: 0.0990\n",
      "Epoch 11/200, Iteration 62/250, Loss: 0.1258\n",
      "Epoch 11/200, Iteration 63/250, Loss: 0.1285\n",
      "Epoch 11/200, Iteration 64/250, Loss: 0.1305\n",
      "Epoch 11/200, Iteration 65/250, Loss: 0.0956\n",
      "Epoch 11/200, Iteration 66/250, Loss: 0.1011\n",
      "Epoch 11/200, Iteration 67/250, Loss: 0.1332\n",
      "Epoch 11/200, Iteration 68/250, Loss: 0.1449\n",
      "Epoch 11/200, Iteration 69/250, Loss: 0.0894\n",
      "Epoch 11/200, Iteration 70/250, Loss: 0.0968\n",
      "Epoch 11/200, Iteration 71/250, Loss: 0.1028\n",
      "Epoch 11/200, Iteration 72/250, Loss: 0.0719\n",
      "Epoch 11/200, Iteration 73/250, Loss: 0.1077\n",
      "Epoch 11/200, Iteration 74/250, Loss: 0.0737\n",
      "Epoch 11/200, Iteration 75/250, Loss: 0.0997\n",
      "Epoch 11/200, Iteration 76/250, Loss: 0.0889\n",
      "Epoch 11/200, Iteration 77/250, Loss: 0.0676\n",
      "Epoch 11/200, Iteration 78/250, Loss: 0.0778\n",
      "Epoch 11/200, Iteration 79/250, Loss: 0.1019\n",
      "Epoch 11/200, Iteration 80/250, Loss: 0.0613\n",
      "Epoch 11/200, Iteration 81/250, Loss: 0.1068\n",
      "Epoch 11/200, Iteration 82/250, Loss: 0.1301\n",
      "Epoch 11/200, Iteration 83/250, Loss: 0.0916\n",
      "Epoch 11/200, Iteration 84/250, Loss: 0.1227\n",
      "Epoch 11/200, Iteration 85/250, Loss: 0.1224\n",
      "Epoch 11/200, Iteration 86/250, Loss: 0.0793\n",
      "Epoch 11/200, Iteration 87/250, Loss: 0.1255\n",
      "Epoch 11/200, Iteration 88/250, Loss: 0.1512\n",
      "Epoch 11/200, Iteration 89/250, Loss: 0.1209\n",
      "Epoch 11/200, Iteration 90/250, Loss: 0.0903\n",
      "Epoch 11/200, Iteration 91/250, Loss: 0.1041\n",
      "Epoch 11/200, Iteration 92/250, Loss: 0.1714\n",
      "Epoch 11/200, Iteration 93/250, Loss: 0.1499\n",
      "Epoch 11/200, Iteration 94/250, Loss: 0.1164\n",
      "Epoch 11/200, Iteration 95/250, Loss: 0.0875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Iteration 96/250, Loss: 0.1527\n",
      "Epoch 11/200, Iteration 97/250, Loss: 0.1019\n",
      "Epoch 11/200, Iteration 98/250, Loss: 0.0948\n",
      "Epoch 11/200, Iteration 99/250, Loss: 0.1114\n",
      "Epoch 11/200, Iteration 100/250, Loss: 0.0748\n",
      "Epoch 11/200, Iteration 101/250, Loss: 0.0653\n",
      "Epoch 11/200, Iteration 102/250, Loss: 0.0769\n",
      "Epoch 11/200, Iteration 103/250, Loss: 0.0924\n",
      "Epoch 11/200, Iteration 104/250, Loss: 0.0715\n",
      "Epoch 11/200, Iteration 105/250, Loss: 0.1134\n",
      "Epoch 11/200, Iteration 106/250, Loss: 0.0683\n",
      "Epoch 11/200, Iteration 107/250, Loss: 0.0491\n",
      "Epoch 11/200, Iteration 108/250, Loss: 0.0759\n",
      "Epoch 11/200, Iteration 109/250, Loss: 0.1067\n",
      "Epoch 11/200, Iteration 110/250, Loss: 0.0598\n",
      "Epoch 11/200, Iteration 111/250, Loss: 0.0750\n",
      "Epoch 11/200, Iteration 112/250, Loss: 0.0763\n",
      "Epoch 11/200, Iteration 113/250, Loss: 0.0558\n",
      "Epoch 11/200, Iteration 114/250, Loss: 0.0716\n",
      "Epoch 11/200, Iteration 115/250, Loss: 0.0922\n",
      "Epoch 11/200, Iteration 116/250, Loss: 0.0540\n",
      "Epoch 11/200, Iteration 117/250, Loss: 0.0457\n",
      "Epoch 11/200, Iteration 118/250, Loss: 0.1019\n",
      "Epoch 11/200, Iteration 119/250, Loss: 0.0693\n",
      "Epoch 11/200, Iteration 120/250, Loss: 0.0936\n",
      "Epoch 11/200, Iteration 121/250, Loss: 0.0703\n",
      "Epoch 11/200, Iteration 122/250, Loss: 0.1105\n",
      "Epoch 11/200, Iteration 123/250, Loss: 0.1299\n",
      "Epoch 11/200, Iteration 124/250, Loss: 0.0609\n",
      "Epoch 11/200, Iteration 125/250, Loss: 0.1609\n",
      "Epoch 11/200, Iteration 126/250, Loss: 0.1957\n",
      "Epoch 11/200, Iteration 127/250, Loss: 0.1107\n",
      "Epoch 11/200, Iteration 128/250, Loss: 0.1063\n",
      "Epoch 11/200, Iteration 129/250, Loss: 0.1380\n",
      "Epoch 11/200, Iteration 130/250, Loss: 0.0699\n",
      "Epoch 11/200, Iteration 131/250, Loss: 0.0878\n",
      "Epoch 11/200, Iteration 132/250, Loss: 0.1434\n",
      "Epoch 11/200, Iteration 133/250, Loss: 0.0701\n",
      "Epoch 11/200, Iteration 134/250, Loss: 0.1223\n",
      "Epoch 11/200, Iteration 135/250, Loss: 0.1475\n",
      "Epoch 11/200, Iteration 136/250, Loss: 0.0684\n",
      "Epoch 11/200, Iteration 137/250, Loss: 0.0727\n",
      "Epoch 11/200, Iteration 138/250, Loss: 0.1103\n",
      "Epoch 11/200, Iteration 139/250, Loss: 0.1038\n",
      "Epoch 11/200, Iteration 140/250, Loss: 0.0519\n",
      "Epoch 11/200, Iteration 141/250, Loss: 0.0705\n",
      "Epoch 11/200, Iteration 142/250, Loss: 0.0988\n",
      "Epoch 11/200, Iteration 143/250, Loss: 0.0835\n",
      "Epoch 11/200, Iteration 144/250, Loss: 0.0852\n",
      "Epoch 11/200, Iteration 145/250, Loss: 0.0779\n",
      "Epoch 11/200, Iteration 146/250, Loss: 0.1019\n",
      "Epoch 11/200, Iteration 147/250, Loss: 0.0635\n",
      "Epoch 11/200, Iteration 148/250, Loss: 0.0780\n",
      "Epoch 11/200, Iteration 149/250, Loss: 0.0469\n",
      "Epoch 11/200, Iteration 150/250, Loss: 0.0702\n",
      "Epoch 11/200, Iteration 151/250, Loss: 0.0919\n",
      "Epoch 11/200, Iteration 152/250, Loss: 0.0576\n",
      "Epoch 11/200, Iteration 153/250, Loss: 0.0608\n",
      "Epoch 11/200, Iteration 154/250, Loss: 0.0538\n",
      "Epoch 11/200, Iteration 155/250, Loss: 0.0651\n",
      "Epoch 11/200, Iteration 156/250, Loss: 0.0757\n",
      "Epoch 11/200, Iteration 157/250, Loss: 0.0501\n",
      "Epoch 11/200, Iteration 158/250, Loss: 0.1171\n",
      "Epoch 11/200, Iteration 159/250, Loss: 0.0471\n",
      "Epoch 11/200, Iteration 160/250, Loss: 0.1036\n",
      "Epoch 11/200, Iteration 161/250, Loss: 0.0942\n",
      "Epoch 11/200, Iteration 162/250, Loss: 0.0722\n",
      "Epoch 11/200, Iteration 163/250, Loss: 0.1115\n",
      "Epoch 11/200, Iteration 164/250, Loss: 0.0497\n",
      "Epoch 11/200, Iteration 165/250, Loss: 0.0489\n",
      "Epoch 11/200, Iteration 166/250, Loss: 0.0712\n",
      "Epoch 11/200, Iteration 167/250, Loss: 0.0455\n",
      "Epoch 11/200, Iteration 168/250, Loss: 0.0855\n",
      "Epoch 11/200, Iteration 169/250, Loss: 0.0452\n",
      "Epoch 11/200, Iteration 170/250, Loss: 0.0608\n",
      "Epoch 11/200, Iteration 171/250, Loss: 0.0871\n",
      "Epoch 11/200, Iteration 172/250, Loss: 0.0573\n",
      "Epoch 11/200, Iteration 173/250, Loss: 0.0494\n",
      "Epoch 11/200, Iteration 174/250, Loss: 0.0373\n",
      "Epoch 11/200, Iteration 175/250, Loss: 0.0594\n",
      "Epoch 11/200, Iteration 176/250, Loss: 0.0913\n",
      "Epoch 11/200, Iteration 177/250, Loss: 0.0616\n",
      "Epoch 11/200, Iteration 178/250, Loss: 0.0676\n",
      "Epoch 11/200, Iteration 179/250, Loss: 0.0438\n",
      "Epoch 11/200, Iteration 180/250, Loss: 0.0614\n",
      "Epoch 11/200, Iteration 181/250, Loss: 0.0417\n",
      "Epoch 11/200, Iteration 182/250, Loss: 0.0645\n",
      "Epoch 11/200, Iteration 183/250, Loss: 0.0459\n",
      "Epoch 11/200, Iteration 184/250, Loss: 0.1052\n",
      "Epoch 11/200, Iteration 185/250, Loss: 0.0866\n",
      "Epoch 11/200, Iteration 186/250, Loss: 0.0729\n",
      "Epoch 11/200, Iteration 187/250, Loss: 0.1614\n",
      "Epoch 11/200, Iteration 188/250, Loss: 0.1468\n",
      "Epoch 11/200, Iteration 189/250, Loss: 0.0847\n",
      "Epoch 11/200, Iteration 190/250, Loss: 0.1068\n",
      "Epoch 11/200, Iteration 191/250, Loss: 0.0820\n",
      "Epoch 11/200, Iteration 192/250, Loss: 0.1027\n",
      "Epoch 11/200, Iteration 193/250, Loss: 0.0756\n",
      "Epoch 11/200, Iteration 194/250, Loss: 0.0485\n",
      "Epoch 11/200, Iteration 195/250, Loss: 0.1163\n",
      "Epoch 11/200, Iteration 196/250, Loss: 0.0647\n",
      "Epoch 11/200, Iteration 197/250, Loss: 0.1330\n",
      "Epoch 11/200, Iteration 198/250, Loss: 0.0968\n",
      "Epoch 11/200, Iteration 199/250, Loss: 0.0566\n",
      "Epoch 11/200, Iteration 200/250, Loss: 0.1305\n",
      "Epoch 11/200, Iteration 201/250, Loss: 0.0634\n",
      "Epoch 11/200, Iteration 202/250, Loss: 0.1486\n",
      "Epoch 11/200, Iteration 203/250, Loss: 0.0844\n",
      "Epoch 11/200, Iteration 204/250, Loss: 0.2062\n",
      "Epoch 11/200, Iteration 205/250, Loss: 0.1824\n",
      "Epoch 11/200, Iteration 206/250, Loss: 0.0507\n",
      "Epoch 11/200, Iteration 207/250, Loss: 0.2718\n",
      "Epoch 11/200, Iteration 208/250, Loss: 0.2527\n",
      "Epoch 11/200, Iteration 209/250, Loss: 0.1325\n",
      "Epoch 11/200, Iteration 210/250, Loss: 0.2013\n",
      "Epoch 11/200, Iteration 211/250, Loss: 0.2845\n",
      "Epoch 11/200, Iteration 212/250, Loss: 0.2129\n",
      "Epoch 11/200, Iteration 213/250, Loss: 0.1082\n",
      "Epoch 11/200, Iteration 214/250, Loss: 0.2074\n",
      "Epoch 11/200, Iteration 215/250, Loss: 0.3019\n",
      "Epoch 11/200, Iteration 216/250, Loss: 0.2206\n",
      "Epoch 11/200, Iteration 217/250, Loss: 0.0703\n",
      "Epoch 11/200, Iteration 218/250, Loss: 0.2285\n",
      "Epoch 11/200, Iteration 219/250, Loss: 0.2713\n",
      "Epoch 11/200, Iteration 220/250, Loss: 0.1398\n",
      "Epoch 11/200, Iteration 221/250, Loss: 0.0466\n",
      "Epoch 11/200, Iteration 222/250, Loss: 0.1793\n",
      "Epoch 11/200, Iteration 223/250, Loss: 0.1559\n",
      "Epoch 11/200, Iteration 224/250, Loss: 0.0843\n",
      "Epoch 11/200, Iteration 225/250, Loss: 0.1695\n",
      "Epoch 11/200, Iteration 226/250, Loss: 0.1993\n",
      "Epoch 11/200, Iteration 227/250, Loss: 0.1829\n",
      "Epoch 11/200, Iteration 228/250, Loss: 0.1370\n",
      "Epoch 11/200, Iteration 229/250, Loss: 0.1185\n",
      "Epoch 11/200, Iteration 230/250, Loss: 0.1656\n",
      "Epoch 11/200, Iteration 231/250, Loss: 0.1086\n",
      "Epoch 11/200, Iteration 232/250, Loss: 0.0875\n",
      "Epoch 11/200, Iteration 233/250, Loss: 0.1385\n",
      "Epoch 11/200, Iteration 234/250, Loss: 0.1483\n",
      "Epoch 11/200, Iteration 235/250, Loss: 0.0579\n",
      "Epoch 11/200, Iteration 236/250, Loss: 0.0802\n",
      "Epoch 11/200, Iteration 237/250, Loss: 0.1330\n",
      "Epoch 11/200, Iteration 238/250, Loss: 0.0992\n",
      "Epoch 11/200, Iteration 239/250, Loss: 0.0851\n",
      "Epoch 11/200, Iteration 240/250, Loss: 0.0665\n",
      "Epoch 11/200, Iteration 241/250, Loss: 0.0862\n",
      "Epoch 11/200, Iteration 242/250, Loss: 0.0823\n",
      "Epoch 11/200, Iteration 243/250, Loss: 0.0605\n",
      "Epoch 11/200, Iteration 244/250, Loss: 0.1207\n",
      "Epoch 11/200, Iteration 245/250, Loss: 0.0688\n",
      "Epoch 11/200, Iteration 246/250, Loss: 0.0556\n",
      "Epoch 11/200, Iteration 247/250, Loss: 0.1392\n",
      "Epoch 11/200, Iteration 248/250, Loss: 0.0897\n",
      "Epoch 11/200, Iteration 249/250, Loss: 0.0675\n",
      "Epoch 11/200, Iteration 250/250, Loss: 0.0513\n",
      "Train Error: \n",
      " Accuracy: 48.54%, Avg loss: 0.104917, MRE: 8.027301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.95%, Avg loss: 0.106076, MRE: 10.885424 \n",
      "\n",
      "Epoch 12/200, Iteration 1/250, Loss: 0.1003\n",
      "Epoch 12/200, Iteration 2/250, Loss: 0.0787\n",
      "Epoch 12/200, Iteration 3/250, Loss: 0.1273\n",
      "Epoch 12/200, Iteration 4/250, Loss: 0.0947\n",
      "Epoch 12/200, Iteration 5/250, Loss: 0.0962\n",
      "Epoch 12/200, Iteration 6/250, Loss: 0.1472\n",
      "Epoch 12/200, Iteration 7/250, Loss: 0.1044\n",
      "Epoch 12/200, Iteration 8/250, Loss: 0.1064\n",
      "Epoch 12/200, Iteration 9/250, Loss: 0.1093\n",
      "Epoch 12/200, Iteration 10/250, Loss: 0.0610\n",
      "Epoch 12/200, Iteration 11/250, Loss: 0.1177\n",
      "Epoch 12/200, Iteration 12/250, Loss: 0.0731\n",
      "Epoch 12/200, Iteration 13/250, Loss: 0.0958\n",
      "Epoch 12/200, Iteration 14/250, Loss: 0.1228\n",
      "Epoch 12/200, Iteration 15/250, Loss: 0.0895\n",
      "Epoch 12/200, Iteration 16/250, Loss: 0.0638\n",
      "Epoch 12/200, Iteration 17/250, Loss: 0.0594\n",
      "Epoch 12/200, Iteration 18/250, Loss: 0.1022\n",
      "Epoch 12/200, Iteration 19/250, Loss: 0.0860\n",
      "Epoch 12/200, Iteration 20/250, Loss: 0.0905\n",
      "Epoch 12/200, Iteration 21/250, Loss: 0.0457\n",
      "Epoch 12/200, Iteration 22/250, Loss: 0.0585\n",
      "Epoch 12/200, Iteration 23/250, Loss: 0.1086\n",
      "Epoch 12/200, Iteration 24/250, Loss: 0.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Iteration 25/250, Loss: 0.0594\n",
      "Epoch 12/200, Iteration 26/250, Loss: 0.0530\n",
      "Epoch 12/200, Iteration 27/250, Loss: 0.0706\n",
      "Epoch 12/200, Iteration 28/250, Loss: 0.0886\n",
      "Epoch 12/200, Iteration 29/250, Loss: 0.0694\n",
      "Epoch 12/200, Iteration 30/250, Loss: 0.0358\n",
      "Epoch 12/200, Iteration 31/250, Loss: 0.0679\n",
      "Epoch 12/200, Iteration 32/250, Loss: 0.0572\n",
      "Epoch 12/200, Iteration 33/250, Loss: 0.0544\n",
      "Epoch 12/200, Iteration 34/250, Loss: 0.0585\n",
      "Epoch 12/200, Iteration 35/250, Loss: 0.0589\n",
      "Epoch 12/200, Iteration 36/250, Loss: 0.0478\n",
      "Epoch 12/200, Iteration 37/250, Loss: 0.0704\n",
      "Epoch 12/200, Iteration 38/250, Loss: 0.0510\n",
      "Epoch 12/200, Iteration 39/250, Loss: 0.0741\n",
      "Epoch 12/200, Iteration 40/250, Loss: 0.0755\n",
      "Epoch 12/200, Iteration 41/250, Loss: 0.0595\n",
      "Epoch 12/200, Iteration 42/250, Loss: 0.0554\n",
      "Epoch 12/200, Iteration 43/250, Loss: 0.1096\n",
      "Epoch 12/200, Iteration 44/250, Loss: 0.0599\n",
      "Epoch 12/200, Iteration 45/250, Loss: 0.0895\n",
      "Epoch 12/200, Iteration 46/250, Loss: 0.0953\n",
      "Epoch 12/200, Iteration 47/250, Loss: 0.1129\n",
      "Epoch 12/200, Iteration 48/250, Loss: 0.0525\n",
      "Epoch 12/200, Iteration 49/250, Loss: 0.0689\n",
      "Epoch 12/200, Iteration 50/250, Loss: 0.0681\n",
      "Epoch 12/200, Iteration 51/250, Loss: 0.0506\n",
      "Epoch 12/200, Iteration 52/250, Loss: 0.0524\n",
      "Epoch 12/200, Iteration 53/250, Loss: 0.0883\n",
      "Epoch 12/200, Iteration 54/250, Loss: 0.0708\n",
      "Epoch 12/200, Iteration 55/250, Loss: 0.0512\n",
      "Epoch 12/200, Iteration 56/250, Loss: 0.1195\n",
      "Epoch 12/200, Iteration 57/250, Loss: 0.1097\n",
      "Epoch 12/200, Iteration 58/250, Loss: 0.0963\n",
      "Epoch 12/200, Iteration 59/250, Loss: 0.0730\n",
      "Epoch 12/200, Iteration 60/250, Loss: 0.0526\n",
      "Epoch 12/200, Iteration 61/250, Loss: 0.1286\n",
      "Epoch 12/200, Iteration 62/250, Loss: 0.1124\n",
      "Epoch 12/200, Iteration 63/250, Loss: 0.1471\n",
      "Epoch 12/200, Iteration 64/250, Loss: 0.0623\n",
      "Epoch 12/200, Iteration 65/250, Loss: 0.0952\n",
      "Epoch 12/200, Iteration 66/250, Loss: 0.1363\n",
      "Epoch 12/200, Iteration 67/250, Loss: 0.0568\n",
      "Epoch 12/200, Iteration 68/250, Loss: 0.1243\n",
      "Epoch 12/200, Iteration 69/250, Loss: 0.0950\n",
      "Epoch 12/200, Iteration 70/250, Loss: 0.0813\n",
      "Epoch 12/200, Iteration 71/250, Loss: 0.0991\n",
      "Epoch 12/200, Iteration 72/250, Loss: 0.0629\n",
      "Epoch 12/200, Iteration 73/250, Loss: 0.1135\n",
      "Epoch 12/200, Iteration 74/250, Loss: 0.0644\n",
      "Epoch 12/200, Iteration 75/250, Loss: 0.1426\n",
      "Epoch 12/200, Iteration 76/250, Loss: 0.1169\n",
      "Epoch 12/200, Iteration 77/250, Loss: 0.0790\n",
      "Epoch 12/200, Iteration 78/250, Loss: 0.1425\n",
      "Epoch 12/200, Iteration 79/250, Loss: 0.0877\n",
      "Epoch 12/200, Iteration 80/250, Loss: 0.1542\n",
      "Epoch 12/200, Iteration 81/250, Loss: 0.1985\n",
      "Epoch 12/200, Iteration 82/250, Loss: 0.1202\n",
      "Epoch 12/200, Iteration 83/250, Loss: 0.1317\n",
      "Epoch 12/200, Iteration 84/250, Loss: 0.1408\n",
      "Epoch 12/200, Iteration 85/250, Loss: 0.1310\n",
      "Epoch 12/200, Iteration 86/250, Loss: 0.0894\n",
      "Epoch 12/200, Iteration 87/250, Loss: 0.1132\n",
      "Epoch 12/200, Iteration 88/250, Loss: 0.0608\n",
      "Epoch 12/200, Iteration 89/250, Loss: 0.0977\n",
      "Epoch 12/200, Iteration 90/250, Loss: 0.0710\n",
      "Epoch 12/200, Iteration 91/250, Loss: 0.0941\n",
      "Epoch 12/200, Iteration 92/250, Loss: 0.0735\n",
      "Epoch 12/200, Iteration 93/250, Loss: 0.0423\n",
      "Epoch 12/200, Iteration 94/250, Loss: 0.0959\n",
      "Epoch 12/200, Iteration 95/250, Loss: 0.0689\n",
      "Epoch 12/200, Iteration 96/250, Loss: 0.1072\n",
      "Epoch 12/200, Iteration 97/250, Loss: 0.0795\n",
      "Epoch 12/200, Iteration 98/250, Loss: 0.0824\n",
      "Epoch 12/200, Iteration 99/250, Loss: 0.0608\n",
      "Epoch 12/200, Iteration 100/250, Loss: 0.0835\n",
      "Epoch 12/200, Iteration 101/250, Loss: 0.0992\n",
      "Epoch 12/200, Iteration 102/250, Loss: 0.0617\n",
      "Epoch 12/200, Iteration 103/250, Loss: 0.0933\n",
      "Epoch 12/200, Iteration 104/250, Loss: 0.0651\n",
      "Epoch 12/200, Iteration 105/250, Loss: 0.0861\n",
      "Epoch 12/200, Iteration 106/250, Loss: 0.0952\n",
      "Epoch 12/200, Iteration 107/250, Loss: 0.0530\n",
      "Epoch 12/200, Iteration 108/250, Loss: 0.0539\n",
      "Epoch 12/200, Iteration 109/250, Loss: 0.0404\n",
      "Epoch 12/200, Iteration 110/250, Loss: 0.0888\n",
      "Epoch 12/200, Iteration 111/250, Loss: 0.0629\n",
      "Epoch 12/200, Iteration 112/250, Loss: 0.0878\n",
      "Epoch 12/200, Iteration 113/250, Loss: 0.0712\n",
      "Epoch 12/200, Iteration 114/250, Loss: 0.0985\n",
      "Epoch 12/200, Iteration 115/250, Loss: 0.1406\n",
      "Epoch 12/200, Iteration 116/250, Loss: 0.0908\n",
      "Epoch 12/200, Iteration 117/250, Loss: 0.1199\n",
      "Epoch 12/200, Iteration 118/250, Loss: 0.1578\n",
      "Epoch 12/200, Iteration 119/250, Loss: 0.1515\n",
      "Epoch 12/200, Iteration 120/250, Loss: 0.1118\n",
      "Epoch 12/200, Iteration 121/250, Loss: 0.1150\n",
      "Epoch 12/200, Iteration 122/250, Loss: 0.1077\n",
      "Epoch 12/200, Iteration 123/250, Loss: 0.0937\n",
      "Epoch 12/200, Iteration 124/250, Loss: 0.1234\n",
      "Epoch 12/200, Iteration 125/250, Loss: 0.1030\n",
      "Epoch 12/200, Iteration 126/250, Loss: 0.1066\n",
      "Epoch 12/200, Iteration 127/250, Loss: 0.0721\n",
      "Epoch 12/200, Iteration 128/250, Loss: 0.0900\n",
      "Epoch 12/200, Iteration 129/250, Loss: 0.0869\n",
      "Epoch 12/200, Iteration 130/250, Loss: 0.0698\n",
      "Epoch 12/200, Iteration 131/250, Loss: 0.0716\n",
      "Epoch 12/200, Iteration 132/250, Loss: 0.0938\n",
      "Epoch 12/200, Iteration 133/250, Loss: 0.0542\n",
      "Epoch 12/200, Iteration 134/250, Loss: 0.0935\n",
      "Epoch 12/200, Iteration 135/250, Loss: 0.1144\n",
      "Epoch 12/200, Iteration 136/250, Loss: 0.0839\n",
      "Epoch 12/200, Iteration 137/250, Loss: 0.0838\n",
      "Epoch 12/200, Iteration 138/250, Loss: 0.0729\n",
      "Epoch 12/200, Iteration 139/250, Loss: 0.0985\n",
      "Epoch 12/200, Iteration 140/250, Loss: 0.1027\n",
      "Epoch 12/200, Iteration 141/250, Loss: 0.0926\n",
      "Epoch 12/200, Iteration 142/250, Loss: 0.1071\n",
      "Epoch 12/200, Iteration 143/250, Loss: 0.1101\n",
      "Epoch 12/200, Iteration 144/250, Loss: 0.0529\n",
      "Epoch 12/200, Iteration 145/250, Loss: 0.0987\n",
      "Epoch 12/200, Iteration 146/250, Loss: 0.0751\n",
      "Epoch 12/200, Iteration 147/250, Loss: 0.0914\n",
      "Epoch 12/200, Iteration 148/250, Loss: 0.0702\n",
      "Epoch 12/200, Iteration 149/250, Loss: 0.1133\n",
      "Epoch 12/200, Iteration 150/250, Loss: 0.0921\n",
      "Epoch 12/200, Iteration 151/250, Loss: 0.0714\n",
      "Epoch 12/200, Iteration 152/250, Loss: 0.0702\n",
      "Epoch 12/200, Iteration 153/250, Loss: 0.1190\n",
      "Epoch 12/200, Iteration 154/250, Loss: 0.1078\n",
      "Epoch 12/200, Iteration 155/250, Loss: 0.0643\n",
      "Epoch 12/200, Iteration 156/250, Loss: 0.0817\n",
      "Epoch 12/200, Iteration 157/250, Loss: 0.0857\n",
      "Epoch 12/200, Iteration 158/250, Loss: 0.1006\n",
      "Epoch 12/200, Iteration 159/250, Loss: 0.0538\n",
      "Epoch 12/200, Iteration 160/250, Loss: 0.1136\n",
      "Epoch 12/200, Iteration 161/250, Loss: 0.1143\n",
      "Epoch 12/200, Iteration 162/250, Loss: 0.0489\n",
      "Epoch 12/200, Iteration 163/250, Loss: 0.0498\n",
      "Epoch 12/200, Iteration 164/250, Loss: 0.0619\n",
      "Epoch 12/200, Iteration 165/250, Loss: 0.0730\n",
      "Epoch 12/200, Iteration 166/250, Loss: 0.0579\n",
      "Epoch 12/200, Iteration 167/250, Loss: 0.0515\n",
      "Epoch 12/200, Iteration 168/250, Loss: 0.0604\n",
      "Epoch 12/200, Iteration 169/250, Loss: 0.0597\n",
      "Epoch 12/200, Iteration 170/250, Loss: 0.0681\n",
      "Epoch 12/200, Iteration 171/250, Loss: 0.0395\n",
      "Epoch 12/200, Iteration 172/250, Loss: 0.0799\n",
      "Epoch 12/200, Iteration 173/250, Loss: 0.0714\n",
      "Epoch 12/200, Iteration 174/250, Loss: 0.0769\n",
      "Epoch 12/200, Iteration 175/250, Loss: 0.0628\n",
      "Epoch 12/200, Iteration 176/250, Loss: 0.0320\n",
      "Epoch 12/200, Iteration 177/250, Loss: 0.0717\n",
      "Epoch 12/200, Iteration 178/250, Loss: 0.0913\n",
      "Epoch 12/200, Iteration 179/250, Loss: 0.0585\n",
      "Epoch 12/200, Iteration 180/250, Loss: 0.0899\n",
      "Epoch 12/200, Iteration 181/250, Loss: 0.1096\n",
      "Epoch 12/200, Iteration 182/250, Loss: 0.0922\n",
      "Epoch 12/200, Iteration 183/250, Loss: 0.0949\n",
      "Epoch 12/200, Iteration 184/250, Loss: 0.0520\n",
      "Epoch 12/200, Iteration 185/250, Loss: 0.0867\n",
      "Epoch 12/200, Iteration 186/250, Loss: 0.0570\n",
      "Epoch 12/200, Iteration 187/250, Loss: 0.1139\n",
      "Epoch 12/200, Iteration 188/250, Loss: 0.1126\n",
      "Epoch 12/200, Iteration 189/250, Loss: 0.1001\n",
      "Epoch 12/200, Iteration 190/250, Loss: 0.0934\n",
      "Epoch 12/200, Iteration 191/250, Loss: 0.0740\n",
      "Epoch 12/200, Iteration 192/250, Loss: 0.0762\n",
      "Epoch 12/200, Iteration 193/250, Loss: 0.0974\n",
      "Epoch 12/200, Iteration 194/250, Loss: 0.0665\n",
      "Epoch 12/200, Iteration 195/250, Loss: 0.0742\n",
      "Epoch 12/200, Iteration 196/250, Loss: 0.0984\n",
      "Epoch 12/200, Iteration 197/250, Loss: 0.0655\n",
      "Epoch 12/200, Iteration 198/250, Loss: 0.0595\n",
      "Epoch 12/200, Iteration 199/250, Loss: 0.0612\n",
      "Epoch 12/200, Iteration 200/250, Loss: 0.0777\n",
      "Epoch 12/200, Iteration 201/250, Loss: 0.0567\n",
      "Epoch 12/200, Iteration 202/250, Loss: 0.0722\n",
      "Epoch 12/200, Iteration 203/250, Loss: 0.0662\n",
      "Epoch 12/200, Iteration 204/250, Loss: 0.0554\n",
      "Epoch 12/200, Iteration 205/250, Loss: 0.0581\n",
      "Epoch 12/200, Iteration 206/250, Loss: 0.0344\n",
      "Epoch 12/200, Iteration 207/250, Loss: 0.0465\n",
      "Epoch 12/200, Iteration 208/250, Loss: 0.0697\n",
      "Epoch 12/200, Iteration 209/250, Loss: 0.0734\n",
      "Epoch 12/200, Iteration 210/250, Loss: 0.0839\n",
      "Epoch 12/200, Iteration 211/250, Loss: 0.0692\n",
      "Epoch 12/200, Iteration 212/250, Loss: 0.0556\n",
      "Epoch 12/200, Iteration 213/250, Loss: 0.0550\n",
      "Epoch 12/200, Iteration 214/250, Loss: 0.0491\n",
      "Epoch 12/200, Iteration 215/250, Loss: 0.0551\n",
      "Epoch 12/200, Iteration 216/250, Loss: 0.0465\n",
      "Epoch 12/200, Iteration 217/250, Loss: 0.0474\n",
      "Epoch 12/200, Iteration 218/250, Loss: 0.0390\n",
      "Epoch 12/200, Iteration 219/250, Loss: 0.0772\n",
      "Epoch 12/200, Iteration 220/250, Loss: 0.0523\n",
      "Epoch 12/200, Iteration 221/250, Loss: 0.0510\n",
      "Epoch 12/200, Iteration 222/250, Loss: 0.0675\n",
      "Epoch 12/200, Iteration 223/250, Loss: 0.0544\n",
      "Epoch 12/200, Iteration 224/250, Loss: 0.0592\n",
      "Epoch 12/200, Iteration 225/250, Loss: 0.0650\n",
      "Epoch 12/200, Iteration 226/250, Loss: 0.0465\n",
      "Epoch 12/200, Iteration 227/250, Loss: 0.0415\n",
      "Epoch 12/200, Iteration 228/250, Loss: 0.0374\n",
      "Epoch 12/200, Iteration 229/250, Loss: 0.0416\n",
      "Epoch 12/200, Iteration 230/250, Loss: 0.0600\n",
      "Epoch 12/200, Iteration 231/250, Loss: 0.0560\n",
      "Epoch 12/200, Iteration 232/250, Loss: 0.0980\n",
      "Epoch 12/200, Iteration 233/250, Loss: 0.0584\n",
      "Epoch 12/200, Iteration 234/250, Loss: 0.0849\n",
      "Epoch 12/200, Iteration 235/250, Loss: 0.0742\n",
      "Epoch 12/200, Iteration 236/250, Loss: 0.0519\n",
      "Epoch 12/200, Iteration 237/250, Loss: 0.0954\n",
      "Epoch 12/200, Iteration 238/250, Loss: 0.0773\n",
      "Epoch 12/200, Iteration 239/250, Loss: 0.0843\n",
      "Epoch 12/200, Iteration 240/250, Loss: 0.1020\n",
      "Epoch 12/200, Iteration 241/250, Loss: 0.0756\n",
      "Epoch 12/200, Iteration 242/250, Loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Iteration 243/250, Loss: 0.0816\n",
      "Epoch 12/200, Iteration 244/250, Loss: 0.0748\n",
      "Epoch 12/200, Iteration 245/250, Loss: 0.0923\n",
      "Epoch 12/200, Iteration 246/250, Loss: 0.0590\n",
      "Epoch 12/200, Iteration 247/250, Loss: 0.0737\n",
      "Epoch 12/200, Iteration 248/250, Loss: 0.0895\n",
      "Epoch 12/200, Iteration 249/250, Loss: 0.0726\n",
      "Epoch 12/200, Iteration 250/250, Loss: 0.0635\n",
      "Train Error: \n",
      " Accuracy: 45.49%, Avg loss: 0.088121, MRE: 6.119217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.45%, Avg loss: 0.086766, MRE: 5.354450 \n",
      "\n",
      "Epoch 13/200, Iteration 1/250, Loss: 0.0881\n",
      "Epoch 13/200, Iteration 2/250, Loss: 0.0457\n",
      "Epoch 13/200, Iteration 3/250, Loss: 0.0850\n",
      "Epoch 13/200, Iteration 4/250, Loss: 0.1088\n",
      "Epoch 13/200, Iteration 5/250, Loss: 0.0930\n",
      "Epoch 13/200, Iteration 6/250, Loss: 0.0526\n",
      "Epoch 13/200, Iteration 7/250, Loss: 0.0915\n",
      "Epoch 13/200, Iteration 8/250, Loss: 0.0963\n",
      "Epoch 13/200, Iteration 9/250, Loss: 0.1058\n",
      "Epoch 13/200, Iteration 10/250, Loss: 0.0910\n",
      "Epoch 13/200, Iteration 11/250, Loss: 0.0531\n",
      "Epoch 13/200, Iteration 12/250, Loss: 0.0983\n",
      "Epoch 13/200, Iteration 13/250, Loss: 0.1213\n",
      "Epoch 13/200, Iteration 14/250, Loss: 0.0997\n",
      "Epoch 13/200, Iteration 15/250, Loss: 0.0822\n",
      "Epoch 13/200, Iteration 16/250, Loss: 0.0963\n",
      "Epoch 13/200, Iteration 17/250, Loss: 0.0927\n",
      "Epoch 13/200, Iteration 18/250, Loss: 0.0718\n",
      "Epoch 13/200, Iteration 19/250, Loss: 0.0725\n",
      "Epoch 13/200, Iteration 20/250, Loss: 0.1007\n",
      "Epoch 13/200, Iteration 21/250, Loss: 0.0762\n",
      "Epoch 13/200, Iteration 22/250, Loss: 0.1114\n",
      "Epoch 13/200, Iteration 23/250, Loss: 0.0818\n",
      "Epoch 13/200, Iteration 24/250, Loss: 0.0835\n",
      "Epoch 13/200, Iteration 25/250, Loss: 0.0842\n",
      "Epoch 13/200, Iteration 26/250, Loss: 0.0472\n",
      "Epoch 13/200, Iteration 27/250, Loss: 0.0825\n",
      "Epoch 13/200, Iteration 28/250, Loss: 0.0612\n",
      "Epoch 13/200, Iteration 29/250, Loss: 0.0490\n",
      "Epoch 13/200, Iteration 30/250, Loss: 0.0781\n",
      "Epoch 13/200, Iteration 31/250, Loss: 0.0587\n",
      "Epoch 13/200, Iteration 32/250, Loss: 0.0934\n",
      "Epoch 13/200, Iteration 33/250, Loss: 0.0631\n",
      "Epoch 13/200, Iteration 34/250, Loss: 0.0916\n",
      "Epoch 13/200, Iteration 35/250, Loss: 0.1093\n",
      "Epoch 13/200, Iteration 36/250, Loss: 0.0831\n",
      "Epoch 13/200, Iteration 37/250, Loss: 0.0599\n",
      "Epoch 13/200, Iteration 38/250, Loss: 0.0961\n",
      "Epoch 13/200, Iteration 39/250, Loss: 0.0801\n",
      "Epoch 13/200, Iteration 40/250, Loss: 0.0406\n",
      "Epoch 13/200, Iteration 41/250, Loss: 0.1340\n",
      "Epoch 13/200, Iteration 42/250, Loss: 0.1877\n",
      "Epoch 13/200, Iteration 43/250, Loss: 0.1418\n",
      "Epoch 13/200, Iteration 44/250, Loss: 0.1220\n",
      "Epoch 13/200, Iteration 45/250, Loss: 0.1205\n",
      "Epoch 13/200, Iteration 46/250, Loss: 0.0788\n",
      "Epoch 13/200, Iteration 47/250, Loss: 0.1353\n",
      "Epoch 13/200, Iteration 48/250, Loss: 0.1116\n",
      "Epoch 13/200, Iteration 49/250, Loss: 0.0987\n",
      "Epoch 13/200, Iteration 50/250, Loss: 0.1169\n",
      "Epoch 13/200, Iteration 51/250, Loss: 0.1255\n",
      "Epoch 13/200, Iteration 52/250, Loss: 0.0906\n",
      "Epoch 13/200, Iteration 53/250, Loss: 0.1036\n",
      "Epoch 13/200, Iteration 54/250, Loss: 0.1319\n",
      "Epoch 13/200, Iteration 55/250, Loss: 0.0736\n",
      "Epoch 13/200, Iteration 56/250, Loss: 0.1522\n",
      "Epoch 13/200, Iteration 57/250, Loss: 0.1047\n",
      "Epoch 13/200, Iteration 58/250, Loss: 0.0612\n",
      "Epoch 13/200, Iteration 59/250, Loss: 0.1139\n",
      "Epoch 13/200, Iteration 60/250, Loss: 0.1131\n",
      "Epoch 13/200, Iteration 61/250, Loss: 0.0551\n",
      "Epoch 13/200, Iteration 62/250, Loss: 0.0850\n",
      "Epoch 13/200, Iteration 63/250, Loss: 0.0654\n",
      "Epoch 13/200, Iteration 64/250, Loss: 0.0790\n",
      "Epoch 13/200, Iteration 65/250, Loss: 0.0696\n",
      "Epoch 13/200, Iteration 66/250, Loss: 0.0686\n",
      "Epoch 13/200, Iteration 67/250, Loss: 0.0669\n",
      "Epoch 13/200, Iteration 68/250, Loss: 0.0987\n",
      "Epoch 13/200, Iteration 69/250, Loss: 0.0712\n",
      "Epoch 13/200, Iteration 70/250, Loss: 0.0979\n",
      "Epoch 13/200, Iteration 71/250, Loss: 0.1010\n",
      "Epoch 13/200, Iteration 72/250, Loss: 0.0856\n",
      "Epoch 13/200, Iteration 73/250, Loss: 0.0492\n",
      "Epoch 13/200, Iteration 74/250, Loss: 0.0710\n",
      "Epoch 13/200, Iteration 75/250, Loss: 0.0763\n",
      "Epoch 13/200, Iteration 76/250, Loss: 0.0548\n",
      "Epoch 13/200, Iteration 77/250, Loss: 0.0554\n",
      "Epoch 13/200, Iteration 78/250, Loss: 0.0591\n",
      "Epoch 13/200, Iteration 79/250, Loss: 0.0657\n",
      "Epoch 13/200, Iteration 80/250, Loss: 0.0617\n",
      "Epoch 13/200, Iteration 81/250, Loss: 0.0375\n",
      "Epoch 13/200, Iteration 82/250, Loss: 0.0690\n",
      "Epoch 13/200, Iteration 83/250, Loss: 0.1124\n",
      "Epoch 13/200, Iteration 84/250, Loss: 0.0971\n",
      "Epoch 13/200, Iteration 85/250, Loss: 0.0540\n",
      "Epoch 13/200, Iteration 86/250, Loss: 0.0923\n",
      "Epoch 13/200, Iteration 87/250, Loss: 0.1153\n",
      "Epoch 13/200, Iteration 88/250, Loss: 0.1213\n",
      "Epoch 13/200, Iteration 89/250, Loss: 0.1273\n",
      "Epoch 13/200, Iteration 90/250, Loss: 0.0938\n",
      "Epoch 13/200, Iteration 91/250, Loss: 0.0829\n",
      "Epoch 13/200, Iteration 92/250, Loss: 0.1115\n",
      "Epoch 13/200, Iteration 93/250, Loss: 0.0511\n",
      "Epoch 13/200, Iteration 94/250, Loss: 0.0713\n",
      "Epoch 13/200, Iteration 95/250, Loss: 0.0740\n",
      "Epoch 13/200, Iteration 96/250, Loss: 0.1120\n",
      "Epoch 13/200, Iteration 97/250, Loss: 0.0760\n",
      "Epoch 13/200, Iteration 98/250, Loss: 0.0551\n",
      "Epoch 13/200, Iteration 99/250, Loss: 0.0674\n",
      "Epoch 13/200, Iteration 100/250, Loss: 0.0776\n",
      "Epoch 13/200, Iteration 101/250, Loss: 0.0952\n",
      "Epoch 13/200, Iteration 102/250, Loss: 0.0607\n",
      "Epoch 13/200, Iteration 103/250, Loss: 0.0841\n",
      "Epoch 13/200, Iteration 104/250, Loss: 0.0965\n",
      "Epoch 13/200, Iteration 105/250, Loss: 0.0542\n",
      "Epoch 13/200, Iteration 106/250, Loss: 0.0850\n",
      "Epoch 13/200, Iteration 107/250, Loss: 0.1053\n",
      "Epoch 13/200, Iteration 108/250, Loss: 0.1294\n",
      "Epoch 13/200, Iteration 109/250, Loss: 0.1145\n",
      "Epoch 13/200, Iteration 110/250, Loss: 0.1109\n",
      "Epoch 13/200, Iteration 111/250, Loss: 0.1555\n",
      "Epoch 13/200, Iteration 112/250, Loss: 0.0961\n",
      "Epoch 13/200, Iteration 113/250, Loss: 0.1085\n",
      "Epoch 13/200, Iteration 114/250, Loss: 0.1613\n",
      "Epoch 13/200, Iteration 115/250, Loss: 0.1208\n",
      "Epoch 13/200, Iteration 116/250, Loss: 0.1002\n",
      "Epoch 13/200, Iteration 117/250, Loss: 0.1652\n",
      "Epoch 13/200, Iteration 118/250, Loss: 0.1572\n",
      "Epoch 13/200, Iteration 119/250, Loss: 0.0799\n",
      "Epoch 13/200, Iteration 120/250, Loss: 0.1299\n",
      "Epoch 13/200, Iteration 121/250, Loss: 0.1445\n",
      "Epoch 13/200, Iteration 122/250, Loss: 0.0862\n",
      "Epoch 13/200, Iteration 123/250, Loss: 0.0919\n",
      "Epoch 13/200, Iteration 124/250, Loss: 0.0894\n",
      "Epoch 13/200, Iteration 125/250, Loss: 0.0823\n",
      "Epoch 13/200, Iteration 126/250, Loss: 0.0772\n",
      "Epoch 13/200, Iteration 127/250, Loss: 0.1318\n",
      "Epoch 13/200, Iteration 128/250, Loss: 0.0812\n",
      "Epoch 13/200, Iteration 129/250, Loss: 0.0618\n",
      "Epoch 13/200, Iteration 130/250, Loss: 0.0901\n",
      "Epoch 13/200, Iteration 131/250, Loss: 0.0816\n",
      "Epoch 13/200, Iteration 132/250, Loss: 0.0580\n",
      "Epoch 13/200, Iteration 133/250, Loss: 0.0894\n",
      "Epoch 13/200, Iteration 134/250, Loss: 0.1080\n",
      "Epoch 13/200, Iteration 135/250, Loss: 0.0667\n",
      "Epoch 13/200, Iteration 136/250, Loss: 0.0810\n",
      "Epoch 13/200, Iteration 137/250, Loss: 0.1133\n",
      "Epoch 13/200, Iteration 138/250, Loss: 0.0817\n",
      "Epoch 13/200, Iteration 139/250, Loss: 0.0445\n",
      "Epoch 13/200, Iteration 140/250, Loss: 0.0703\n",
      "Epoch 13/200, Iteration 141/250, Loss: 0.0465\n",
      "Epoch 13/200, Iteration 142/250, Loss: 0.0567\n",
      "Epoch 13/200, Iteration 143/250, Loss: 0.0471\n",
      "Epoch 13/200, Iteration 144/250, Loss: 0.0747\n",
      "Epoch 13/200, Iteration 145/250, Loss: 0.0808\n",
      "Epoch 13/200, Iteration 146/250, Loss: 0.0587\n",
      "Epoch 13/200, Iteration 147/250, Loss: 0.0429\n",
      "Epoch 13/200, Iteration 148/250, Loss: 0.0417\n",
      "Epoch 13/200, Iteration 149/250, Loss: 0.0414\n",
      "Epoch 13/200, Iteration 150/250, Loss: 0.0473\n",
      "Epoch 13/200, Iteration 151/250, Loss: 0.0565\n",
      "Epoch 13/200, Iteration 152/250, Loss: 0.0641\n",
      "Epoch 13/200, Iteration 153/250, Loss: 0.0400\n",
      "Epoch 13/200, Iteration 154/250, Loss: 0.0615\n",
      "Epoch 13/200, Iteration 155/250, Loss: 0.0913\n",
      "Epoch 13/200, Iteration 156/250, Loss: 0.0434\n",
      "Epoch 13/200, Iteration 157/250, Loss: 0.0664\n",
      "Epoch 13/200, Iteration 158/250, Loss: 0.0374\n",
      "Epoch 13/200, Iteration 159/250, Loss: 0.0587\n",
      "Epoch 13/200, Iteration 160/250, Loss: 0.0435\n",
      "Epoch 13/200, Iteration 161/250, Loss: 0.0557\n",
      "Epoch 13/200, Iteration 162/250, Loss: 0.0750\n",
      "Epoch 13/200, Iteration 163/250, Loss: 0.0956\n",
      "Epoch 13/200, Iteration 164/250, Loss: 0.0647\n",
      "Epoch 13/200, Iteration 165/250, Loss: 0.1234\n",
      "Epoch 13/200, Iteration 166/250, Loss: 0.0916\n",
      "Epoch 13/200, Iteration 167/250, Loss: 0.0940\n",
      "Epoch 13/200, Iteration 168/250, Loss: 0.0999\n",
      "Epoch 13/200, Iteration 169/250, Loss: 0.0774\n",
      "Epoch 13/200, Iteration 170/250, Loss: 0.1325\n",
      "Epoch 13/200, Iteration 171/250, Loss: 0.1745\n",
      "Epoch 13/200, Iteration 172/250, Loss: 0.1006\n",
      "Epoch 13/200, Iteration 173/250, Loss: 0.1313\n",
      "Epoch 13/200, Iteration 174/250, Loss: 0.1287\n",
      "Epoch 13/200, Iteration 175/250, Loss: 0.1217\n",
      "Epoch 13/200, Iteration 176/250, Loss: 0.1115\n",
      "Epoch 13/200, Iteration 177/250, Loss: 0.1374\n",
      "Epoch 13/200, Iteration 178/250, Loss: 0.1583\n",
      "Epoch 13/200, Iteration 179/250, Loss: 0.0903\n",
      "Epoch 13/200, Iteration 180/250, Loss: 0.1325\n",
      "Epoch 13/200, Iteration 181/250, Loss: 0.1498\n",
      "Epoch 13/200, Iteration 182/250, Loss: 0.1520\n",
      "Epoch 13/200, Iteration 183/250, Loss: 0.1157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Iteration 184/250, Loss: 0.1029\n",
      "Epoch 13/200, Iteration 185/250, Loss: 0.1619\n",
      "Epoch 13/200, Iteration 186/250, Loss: 0.1367\n",
      "Epoch 13/200, Iteration 187/250, Loss: 0.0661\n",
      "Epoch 13/200, Iteration 188/250, Loss: 0.0878\n",
      "Epoch 13/200, Iteration 189/250, Loss: 0.1045\n",
      "Epoch 13/200, Iteration 190/250, Loss: 0.1087\n",
      "Epoch 13/200, Iteration 191/250, Loss: 0.0713\n",
      "Epoch 13/200, Iteration 192/250, Loss: 0.0673\n",
      "Epoch 13/200, Iteration 193/250, Loss: 0.0828\n",
      "Epoch 13/200, Iteration 194/250, Loss: 0.1346\n",
      "Epoch 13/200, Iteration 195/250, Loss: 0.1255\n",
      "Epoch 13/200, Iteration 196/250, Loss: 0.0440\n",
      "Epoch 13/200, Iteration 197/250, Loss: 0.1047\n",
      "Epoch 13/200, Iteration 198/250, Loss: 0.0998\n",
      "Epoch 13/200, Iteration 199/250, Loss: 0.0739\n",
      "Epoch 13/200, Iteration 200/250, Loss: 0.1088\n",
      "Epoch 13/200, Iteration 201/250, Loss: 0.0677\n",
      "Epoch 13/200, Iteration 202/250, Loss: 0.1176\n",
      "Epoch 13/200, Iteration 203/250, Loss: 0.1765\n",
      "Epoch 13/200, Iteration 204/250, Loss: 0.0911\n",
      "Epoch 13/200, Iteration 205/250, Loss: 0.1373\n",
      "Epoch 13/200, Iteration 206/250, Loss: 0.1866\n",
      "Epoch 13/200, Iteration 207/250, Loss: 0.1055\n",
      "Epoch 13/200, Iteration 208/250, Loss: 0.1306\n",
      "Epoch 13/200, Iteration 209/250, Loss: 0.1924\n",
      "Epoch 13/200, Iteration 210/250, Loss: 0.1376\n",
      "Epoch 13/200, Iteration 211/250, Loss: 0.1046\n",
      "Epoch 13/200, Iteration 212/250, Loss: 0.1693\n",
      "Epoch 13/200, Iteration 213/250, Loss: 0.1227\n",
      "Epoch 13/200, Iteration 214/250, Loss: 0.0697\n",
      "Epoch 13/200, Iteration 215/250, Loss: 0.1204\n",
      "Epoch 13/200, Iteration 216/250, Loss: 0.1382\n",
      "Epoch 13/200, Iteration 217/250, Loss: 0.1150\n",
      "Epoch 13/200, Iteration 218/250, Loss: 0.0672\n",
      "Epoch 13/200, Iteration 219/250, Loss: 0.0875\n",
      "Epoch 13/200, Iteration 220/250, Loss: 0.0990\n",
      "Epoch 13/200, Iteration 221/250, Loss: 0.1085\n",
      "Epoch 13/200, Iteration 222/250, Loss: 0.1373\n",
      "Epoch 13/200, Iteration 223/250, Loss: 0.1136\n",
      "Epoch 13/200, Iteration 224/250, Loss: 0.0922\n",
      "Epoch 13/200, Iteration 225/250, Loss: 0.1043\n",
      "Epoch 13/200, Iteration 226/250, Loss: 0.1713\n",
      "Epoch 13/200, Iteration 227/250, Loss: 0.2027\n",
      "Epoch 13/200, Iteration 228/250, Loss: 0.1170\n",
      "Epoch 13/200, Iteration 229/250, Loss: 0.0778\n",
      "Epoch 13/200, Iteration 230/250, Loss: 0.1404\n",
      "Epoch 13/200, Iteration 231/250, Loss: 0.0970\n",
      "Epoch 13/200, Iteration 232/250, Loss: 0.1067\n",
      "Epoch 13/200, Iteration 233/250, Loss: 0.1131\n",
      "Epoch 13/200, Iteration 234/250, Loss: 0.0595\n",
      "Epoch 13/200, Iteration 235/250, Loss: 0.0618\n",
      "Epoch 13/200, Iteration 236/250, Loss: 0.1011\n",
      "Epoch 13/200, Iteration 237/250, Loss: 0.1450\n",
      "Epoch 13/200, Iteration 238/250, Loss: 0.0962\n",
      "Epoch 13/200, Iteration 239/250, Loss: 0.0707\n",
      "Epoch 13/200, Iteration 240/250, Loss: 0.0524\n",
      "Epoch 13/200, Iteration 241/250, Loss: 0.1094\n",
      "Epoch 13/200, Iteration 242/250, Loss: 0.0674\n",
      "Epoch 13/200, Iteration 243/250, Loss: 0.0692\n",
      "Epoch 13/200, Iteration 244/250, Loss: 0.0585\n",
      "Epoch 13/200, Iteration 245/250, Loss: 0.0981\n",
      "Epoch 13/200, Iteration 246/250, Loss: 0.0937\n",
      "Epoch 13/200, Iteration 247/250, Loss: 0.0690\n",
      "Epoch 13/200, Iteration 248/250, Loss: 0.0941\n",
      "Epoch 13/200, Iteration 249/250, Loss: 0.0607\n",
      "Epoch 13/200, Iteration 250/250, Loss: 0.0614\n",
      "Train Error: \n",
      " Accuracy: 43.68%, Avg loss: 0.084822, MRE: 6.309483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 0.085863, MRE: 7.771152 \n",
      "\n",
      "Epoch 14/200, Iteration 1/250, Loss: 0.0849\n",
      "Epoch 14/200, Iteration 2/250, Loss: 0.0746\n",
      "Epoch 14/200, Iteration 3/250, Loss: 0.0811\n",
      "Epoch 14/200, Iteration 4/250, Loss: 0.0903\n",
      "Epoch 14/200, Iteration 5/250, Loss: 0.1051\n",
      "Epoch 14/200, Iteration 6/250, Loss: 0.0694\n",
      "Epoch 14/200, Iteration 7/250, Loss: 0.0912\n",
      "Epoch 14/200, Iteration 8/250, Loss: 0.1294\n",
      "Epoch 14/200, Iteration 9/250, Loss: 0.0672\n",
      "Epoch 14/200, Iteration 10/250, Loss: 0.0680\n",
      "Epoch 14/200, Iteration 11/250, Loss: 0.1041\n",
      "Epoch 14/200, Iteration 12/250, Loss: 0.0701\n",
      "Epoch 14/200, Iteration 13/250, Loss: 0.0773\n",
      "Epoch 14/200, Iteration 14/250, Loss: 0.0672\n",
      "Epoch 14/200, Iteration 15/250, Loss: 0.0855\n",
      "Epoch 14/200, Iteration 16/250, Loss: 0.0439\n",
      "Epoch 14/200, Iteration 17/250, Loss: 0.0809\n",
      "Epoch 14/200, Iteration 18/250, Loss: 0.0763\n",
      "Epoch 14/200, Iteration 19/250, Loss: 0.0597\n",
      "Epoch 14/200, Iteration 20/250, Loss: 0.0638\n",
      "Epoch 14/200, Iteration 21/250, Loss: 0.0655\n",
      "Epoch 14/200, Iteration 22/250, Loss: 0.0663\n",
      "Epoch 14/200, Iteration 23/250, Loss: 0.0502\n",
      "Epoch 14/200, Iteration 24/250, Loss: 0.0627\n",
      "Epoch 14/200, Iteration 25/250, Loss: 0.0474\n",
      "Epoch 14/200, Iteration 26/250, Loss: 0.0901\n",
      "Epoch 14/200, Iteration 27/250, Loss: 0.0554\n",
      "Epoch 14/200, Iteration 28/250, Loss: 0.0540\n",
      "Epoch 14/200, Iteration 29/250, Loss: 0.0420\n",
      "Epoch 14/200, Iteration 30/250, Loss: 0.0479\n",
      "Epoch 14/200, Iteration 31/250, Loss: 0.0650\n",
      "Epoch 14/200, Iteration 32/250, Loss: 0.0444\n",
      "Epoch 14/200, Iteration 33/250, Loss: 0.0470\n",
      "Epoch 14/200, Iteration 34/250, Loss: 0.0369\n",
      "Epoch 14/200, Iteration 35/250, Loss: 0.0584\n",
      "Epoch 14/200, Iteration 36/250, Loss: 0.0711\n",
      "Epoch 14/200, Iteration 37/250, Loss: 0.0697\n",
      "Epoch 14/200, Iteration 38/250, Loss: 0.0491\n",
      "Epoch 14/200, Iteration 39/250, Loss: 0.0984\n",
      "Epoch 14/200, Iteration 40/250, Loss: 0.0787\n",
      "Epoch 14/200, Iteration 41/250, Loss: 0.0887\n",
      "Epoch 14/200, Iteration 42/250, Loss: 0.0518\n",
      "Epoch 14/200, Iteration 43/250, Loss: 0.1104\n",
      "Epoch 14/200, Iteration 44/250, Loss: 0.0816\n",
      "Epoch 14/200, Iteration 45/250, Loss: 0.0600\n",
      "Epoch 14/200, Iteration 46/250, Loss: 0.0595\n",
      "Epoch 14/200, Iteration 47/250, Loss: 0.0714\n",
      "Epoch 14/200, Iteration 48/250, Loss: 0.0816\n",
      "Epoch 14/200, Iteration 49/250, Loss: 0.0807\n",
      "Epoch 14/200, Iteration 50/250, Loss: 0.0399\n",
      "Epoch 14/200, Iteration 51/250, Loss: 0.0488\n",
      "Epoch 14/200, Iteration 52/250, Loss: 0.0805\n",
      "Epoch 14/200, Iteration 53/250, Loss: 0.0542\n",
      "Epoch 14/200, Iteration 54/250, Loss: 0.0981\n",
      "Epoch 14/200, Iteration 55/250, Loss: 0.1283\n",
      "Epoch 14/200, Iteration 56/250, Loss: 0.1016\n",
      "Epoch 14/200, Iteration 57/250, Loss: 0.0633\n",
      "Epoch 14/200, Iteration 58/250, Loss: 0.0541\n",
      "Epoch 14/200, Iteration 59/250, Loss: 0.0708\n",
      "Epoch 14/200, Iteration 60/250, Loss: 0.0727\n",
      "Epoch 14/200, Iteration 61/250, Loss: 0.0843\n",
      "Epoch 14/200, Iteration 62/250, Loss: 0.0531\n",
      "Epoch 14/200, Iteration 63/250, Loss: 0.0611\n",
      "Epoch 14/200, Iteration 64/250, Loss: 0.0670\n",
      "Epoch 14/200, Iteration 65/250, Loss: 0.0617\n",
      "Epoch 14/200, Iteration 66/250, Loss: 0.0512\n",
      "Epoch 14/200, Iteration 67/250, Loss: 0.0671\n",
      "Epoch 14/200, Iteration 68/250, Loss: 0.0563\n",
      "Epoch 14/200, Iteration 69/250, Loss: 0.0646\n",
      "Epoch 14/200, Iteration 70/250, Loss: 0.0465\n",
      "Epoch 14/200, Iteration 71/250, Loss: 0.0609\n",
      "Epoch 14/200, Iteration 72/250, Loss: 0.0552\n",
      "Epoch 14/200, Iteration 73/250, Loss: 0.0638\n",
      "Epoch 14/200, Iteration 74/250, Loss: 0.0763\n",
      "Epoch 14/200, Iteration 75/250, Loss: 0.0737\n",
      "Epoch 14/200, Iteration 76/250, Loss: 0.1059\n",
      "Epoch 14/200, Iteration 77/250, Loss: 0.0657\n",
      "Epoch 14/200, Iteration 78/250, Loss: 0.1272\n",
      "Epoch 14/200, Iteration 79/250, Loss: 0.1133\n",
      "Epoch 14/200, Iteration 80/250, Loss: 0.0759\n",
      "Epoch 14/200, Iteration 81/250, Loss: 0.1406\n",
      "Epoch 14/200, Iteration 82/250, Loss: 0.1864\n",
      "Epoch 14/200, Iteration 83/250, Loss: 0.1319\n",
      "Epoch 14/200, Iteration 84/250, Loss: 0.1207\n",
      "Epoch 14/200, Iteration 85/250, Loss: 0.1140\n",
      "Epoch 14/200, Iteration 86/250, Loss: 0.1013\n",
      "Epoch 14/200, Iteration 87/250, Loss: 0.0568\n",
      "Epoch 14/200, Iteration 88/250, Loss: 0.0693\n",
      "Epoch 14/200, Iteration 89/250, Loss: 0.0833\n",
      "Epoch 14/200, Iteration 90/250, Loss: 0.0775\n",
      "Epoch 14/200, Iteration 91/250, Loss: 0.0492\n",
      "Epoch 14/200, Iteration 92/250, Loss: 0.1069\n",
      "Epoch 14/200, Iteration 93/250, Loss: 0.1199\n",
      "Epoch 14/200, Iteration 94/250, Loss: 0.0691\n",
      "Epoch 14/200, Iteration 95/250, Loss: 0.0933\n",
      "Epoch 14/200, Iteration 96/250, Loss: 0.1212\n",
      "Epoch 14/200, Iteration 97/250, Loss: 0.0834\n",
      "Epoch 14/200, Iteration 98/250, Loss: 0.0813\n",
      "Epoch 14/200, Iteration 99/250, Loss: 0.1108\n",
      "Epoch 14/200, Iteration 100/250, Loss: 0.1102\n",
      "Epoch 14/200, Iteration 101/250, Loss: 0.1189\n",
      "Epoch 14/200, Iteration 102/250, Loss: 0.1464\n",
      "Epoch 14/200, Iteration 103/250, Loss: 0.1054\n",
      "Epoch 14/200, Iteration 104/250, Loss: 0.1297\n",
      "Epoch 14/200, Iteration 105/250, Loss: 0.1261\n",
      "Epoch 14/200, Iteration 106/250, Loss: 0.0978\n",
      "Epoch 14/200, Iteration 107/250, Loss: 0.1277\n",
      "Epoch 14/200, Iteration 108/250, Loss: 0.1609\n",
      "Epoch 14/200, Iteration 109/250, Loss: 0.0970\n",
      "Epoch 14/200, Iteration 110/250, Loss: 0.0772\n",
      "Epoch 14/200, Iteration 111/250, Loss: 0.1109\n",
      "Epoch 14/200, Iteration 112/250, Loss: 0.0827\n",
      "Epoch 14/200, Iteration 113/250, Loss: 0.0734\n",
      "Epoch 14/200, Iteration 114/250, Loss: 0.0674\n",
      "Epoch 14/200, Iteration 115/250, Loss: 0.0534\n",
      "Epoch 14/200, Iteration 116/250, Loss: 0.0790\n",
      "Epoch 14/200, Iteration 117/250, Loss: 0.0739\n",
      "Epoch 14/200, Iteration 118/250, Loss: 0.1249\n",
      "Epoch 14/200, Iteration 119/250, Loss: 0.0971\n",
      "Epoch 14/200, Iteration 120/250, Loss: 0.0959\n",
      "Epoch 14/200, Iteration 121/250, Loss: 0.0877\n",
      "Epoch 14/200, Iteration 122/250, Loss: 0.1241\n",
      "Epoch 14/200, Iteration 123/250, Loss: 0.1038\n",
      "Epoch 14/200, Iteration 124/250, Loss: 0.0683\n",
      "Epoch 14/200, Iteration 125/250, Loss: 0.1229\n",
      "Epoch 14/200, Iteration 126/250, Loss: 0.1155\n",
      "Epoch 14/200, Iteration 127/250, Loss: 0.0753\n",
      "Epoch 14/200, Iteration 128/250, Loss: 0.0904\n",
      "Epoch 14/200, Iteration 129/250, Loss: 0.0902\n",
      "Epoch 14/200, Iteration 130/250, Loss: 0.0724\n",
      "Epoch 14/200, Iteration 131/250, Loss: 0.1283\n",
      "Epoch 14/200, Iteration 132/250, Loss: 0.1276\n",
      "Epoch 14/200, Iteration 133/250, Loss: 0.1290\n",
      "Epoch 14/200, Iteration 134/250, Loss: 0.0473\n",
      "Epoch 14/200, Iteration 135/250, Loss: 0.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Iteration 136/250, Loss: 0.1385\n",
      "Epoch 14/200, Iteration 137/250, Loss: 0.1025\n",
      "Epoch 14/200, Iteration 138/250, Loss: 0.0443\n",
      "Epoch 14/200, Iteration 139/250, Loss: 0.0949\n",
      "Epoch 14/200, Iteration 140/250, Loss: 0.0990\n",
      "Epoch 14/200, Iteration 141/250, Loss: 0.0917\n",
      "Epoch 14/200, Iteration 142/250, Loss: 0.0791\n",
      "Epoch 14/200, Iteration 143/250, Loss: 0.0950\n",
      "Epoch 14/200, Iteration 144/250, Loss: 0.1206\n",
      "Epoch 14/200, Iteration 145/250, Loss: 0.0532\n",
      "Epoch 14/200, Iteration 146/250, Loss: 0.0534\n",
      "Epoch 14/200, Iteration 147/250, Loss: 0.0566\n",
      "Epoch 14/200, Iteration 148/250, Loss: 0.0581\n",
      "Epoch 14/200, Iteration 149/250, Loss: 0.0910\n",
      "Epoch 14/200, Iteration 150/250, Loss: 0.0982\n",
      "Epoch 14/200, Iteration 151/250, Loss: 0.0976\n",
      "Epoch 14/200, Iteration 152/250, Loss: 0.0507\n",
      "Epoch 14/200, Iteration 153/250, Loss: 0.0631\n",
      "Epoch 14/200, Iteration 154/250, Loss: 0.0903\n",
      "Epoch 14/200, Iteration 155/250, Loss: 0.1037\n",
      "Epoch 14/200, Iteration 156/250, Loss: 0.0803\n",
      "Epoch 14/200, Iteration 157/250, Loss: 0.0920\n",
      "Epoch 14/200, Iteration 158/250, Loss: 0.0639\n",
      "Epoch 14/200, Iteration 159/250, Loss: 0.0645\n",
      "Epoch 14/200, Iteration 160/250, Loss: 0.1071\n",
      "Epoch 14/200, Iteration 161/250, Loss: 0.0513\n",
      "Epoch 14/200, Iteration 162/250, Loss: 0.0724\n",
      "Epoch 14/200, Iteration 163/250, Loss: 0.0863\n",
      "Epoch 14/200, Iteration 164/250, Loss: 0.0646\n",
      "Epoch 14/200, Iteration 165/250, Loss: 0.0590\n",
      "Epoch 14/200, Iteration 166/250, Loss: 0.0981\n",
      "Epoch 14/200, Iteration 167/250, Loss: 0.0548\n",
      "Epoch 14/200, Iteration 168/250, Loss: 0.0778\n",
      "Epoch 14/200, Iteration 169/250, Loss: 0.0477\n",
      "Epoch 14/200, Iteration 170/250, Loss: 0.1084\n",
      "Epoch 14/200, Iteration 171/250, Loss: 0.0684\n",
      "Epoch 14/200, Iteration 172/250, Loss: 0.1157\n",
      "Epoch 14/200, Iteration 173/250, Loss: 0.0993\n",
      "Epoch 14/200, Iteration 174/250, Loss: 0.0696\n",
      "Epoch 14/200, Iteration 175/250, Loss: 0.0913\n",
      "Epoch 14/200, Iteration 176/250, Loss: 0.0510\n",
      "Epoch 14/200, Iteration 177/250, Loss: 0.0520\n",
      "Epoch 14/200, Iteration 178/250, Loss: 0.0608\n",
      "Epoch 14/200, Iteration 179/250, Loss: 0.0585\n",
      "Epoch 14/200, Iteration 180/250, Loss: 0.0783\n",
      "Epoch 14/200, Iteration 181/250, Loss: 0.0441\n",
      "Epoch 14/200, Iteration 182/250, Loss: 0.0867\n",
      "Epoch 14/200, Iteration 183/250, Loss: 0.1030\n",
      "Epoch 14/200, Iteration 184/250, Loss: 0.0856\n",
      "Epoch 14/200, Iteration 185/250, Loss: 0.0918\n",
      "Epoch 14/200, Iteration 186/250, Loss: 0.0601\n",
      "Epoch 14/200, Iteration 187/250, Loss: 0.1075\n",
      "Epoch 14/200, Iteration 188/250, Loss: 0.1259\n",
      "Epoch 14/200, Iteration 189/250, Loss: 0.1055\n",
      "Epoch 14/200, Iteration 190/250, Loss: 0.0850\n",
      "Epoch 14/200, Iteration 191/250, Loss: 0.1247\n",
      "Epoch 14/200, Iteration 192/250, Loss: 0.1214\n",
      "Epoch 14/200, Iteration 193/250, Loss: 0.0530\n",
      "Epoch 14/200, Iteration 194/250, Loss: 0.1691\n",
      "Epoch 14/200, Iteration 195/250, Loss: 0.1400\n",
      "Epoch 14/200, Iteration 196/250, Loss: 0.0855\n",
      "Epoch 14/200, Iteration 197/250, Loss: 0.1489\n",
      "Epoch 14/200, Iteration 198/250, Loss: 0.1195\n",
      "Epoch 14/200, Iteration 199/250, Loss: 0.1283\n",
      "Epoch 14/200, Iteration 200/250, Loss: 0.1833\n",
      "Epoch 14/200, Iteration 201/250, Loss: 0.0843\n",
      "Epoch 14/200, Iteration 202/250, Loss: 0.1805\n",
      "Epoch 14/200, Iteration 203/250, Loss: 0.1566\n",
      "Epoch 14/200, Iteration 204/250, Loss: 0.0874\n",
      "Epoch 14/200, Iteration 205/250, Loss: 0.1403\n",
      "Epoch 14/200, Iteration 206/250, Loss: 0.1859\n",
      "Epoch 14/200, Iteration 207/250, Loss: 0.1279\n",
      "Epoch 14/200, Iteration 208/250, Loss: 0.0973\n",
      "Epoch 14/200, Iteration 209/250, Loss: 0.1527\n",
      "Epoch 14/200, Iteration 210/250, Loss: 0.1348\n",
      "Epoch 14/200, Iteration 211/250, Loss: 0.1767\n",
      "Epoch 14/200, Iteration 212/250, Loss: 0.1158\n",
      "Epoch 14/200, Iteration 213/250, Loss: 0.1037\n",
      "Epoch 14/200, Iteration 214/250, Loss: 0.1633\n",
      "Epoch 14/200, Iteration 215/250, Loss: 0.1309\n",
      "Epoch 14/200, Iteration 216/250, Loss: 0.0981\n",
      "Epoch 14/200, Iteration 217/250, Loss: 0.0901\n",
      "Epoch 14/200, Iteration 218/250, Loss: 0.0954\n",
      "Epoch 14/200, Iteration 219/250, Loss: 0.1196\n",
      "Epoch 14/200, Iteration 220/250, Loss: 0.1322\n",
      "Epoch 14/200, Iteration 221/250, Loss: 0.1055\n",
      "Epoch 14/200, Iteration 222/250, Loss: 0.1020\n",
      "Epoch 14/200, Iteration 223/250, Loss: 0.0911\n",
      "Epoch 14/200, Iteration 224/250, Loss: 0.1116\n",
      "Epoch 14/200, Iteration 225/250, Loss: 0.0618\n",
      "Epoch 14/200, Iteration 226/250, Loss: 0.1159\n",
      "Epoch 14/200, Iteration 227/250, Loss: 0.1477\n",
      "Epoch 14/200, Iteration 228/250, Loss: 0.1156\n",
      "Epoch 14/200, Iteration 229/250, Loss: 0.1354\n",
      "Epoch 14/200, Iteration 230/250, Loss: 0.0735\n",
      "Epoch 14/200, Iteration 231/250, Loss: 0.1415\n",
      "Epoch 14/200, Iteration 232/250, Loss: 0.1151\n",
      "Epoch 14/200, Iteration 233/250, Loss: 0.0870\n",
      "Epoch 14/200, Iteration 234/250, Loss: 0.0608\n",
      "Epoch 14/200, Iteration 235/250, Loss: 0.0867\n",
      "Epoch 14/200, Iteration 236/250, Loss: 0.1450\n",
      "Epoch 14/200, Iteration 237/250, Loss: 0.0920\n",
      "Epoch 14/200, Iteration 238/250, Loss: 0.0943\n",
      "Epoch 14/200, Iteration 239/250, Loss: 0.0815\n",
      "Epoch 14/200, Iteration 240/250, Loss: 0.1063\n",
      "Epoch 14/200, Iteration 241/250, Loss: 0.1563\n",
      "Epoch 14/200, Iteration 242/250, Loss: 0.0533\n",
      "Epoch 14/200, Iteration 243/250, Loss: 0.1139\n",
      "Epoch 14/200, Iteration 244/250, Loss: 0.0407\n",
      "Epoch 14/200, Iteration 245/250, Loss: 0.0900\n",
      "Epoch 14/200, Iteration 246/250, Loss: 0.0551\n",
      "Epoch 14/200, Iteration 247/250, Loss: 0.1105\n",
      "Epoch 14/200, Iteration 248/250, Loss: 0.0655\n",
      "Epoch 14/200, Iteration 249/250, Loss: 0.0457\n",
      "Epoch 14/200, Iteration 250/250, Loss: 0.0423\n",
      "Train Error: \n",
      " Accuracy: 41.19%, Avg loss: 0.073680, MRE: 5.671798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.35%, Avg loss: 0.075639, MRE: 8.799974 \n",
      "\n",
      "Epoch 15/200, Iteration 1/250, Loss: 0.0835\n",
      "Epoch 15/200, Iteration 2/250, Loss: 0.0605\n",
      "Epoch 15/200, Iteration 3/250, Loss: 0.0553\n",
      "Epoch 15/200, Iteration 4/250, Loss: 0.0607\n",
      "Epoch 15/200, Iteration 5/250, Loss: 0.0483\n",
      "Epoch 15/200, Iteration 6/250, Loss: 0.0541\n",
      "Epoch 15/200, Iteration 7/250, Loss: 0.0702\n",
      "Epoch 15/200, Iteration 8/250, Loss: 0.0967\n",
      "Epoch 15/200, Iteration 9/250, Loss: 0.0838\n",
      "Epoch 15/200, Iteration 10/250, Loss: 0.0634\n",
      "Epoch 15/200, Iteration 11/250, Loss: 0.0877\n",
      "Epoch 15/200, Iteration 12/250, Loss: 0.0836\n",
      "Epoch 15/200, Iteration 13/250, Loss: 0.1078\n",
      "Epoch 15/200, Iteration 14/250, Loss: 0.0655\n",
      "Epoch 15/200, Iteration 15/250, Loss: 0.1076\n",
      "Epoch 15/200, Iteration 16/250, Loss: 0.0599\n",
      "Epoch 15/200, Iteration 17/250, Loss: 0.1129\n",
      "Epoch 15/200, Iteration 18/250, Loss: 0.1307\n",
      "Epoch 15/200, Iteration 19/250, Loss: 0.0893\n",
      "Epoch 15/200, Iteration 20/250, Loss: 0.1052\n",
      "Epoch 15/200, Iteration 21/250, Loss: 0.0841\n",
      "Epoch 15/200, Iteration 22/250, Loss: 0.1346\n",
      "Epoch 15/200, Iteration 23/250, Loss: 0.2143\n",
      "Epoch 15/200, Iteration 24/250, Loss: 0.1130\n",
      "Epoch 15/200, Iteration 25/250, Loss: 0.1832\n",
      "Epoch 15/200, Iteration 26/250, Loss: 0.2633\n",
      "Epoch 15/200, Iteration 27/250, Loss: 0.1992\n",
      "Epoch 15/200, Iteration 28/250, Loss: 0.1253\n",
      "Epoch 15/200, Iteration 29/250, Loss: 0.2122\n",
      "Epoch 15/200, Iteration 30/250, Loss: 0.1860\n",
      "Epoch 15/200, Iteration 31/250, Loss: 0.0931\n",
      "Epoch 15/200, Iteration 32/250, Loss: 0.1783\n",
      "Epoch 15/200, Iteration 33/250, Loss: 0.2363\n",
      "Epoch 15/200, Iteration 34/250, Loss: 0.1825\n",
      "Epoch 15/200, Iteration 35/250, Loss: 0.1133\n",
      "Epoch 15/200, Iteration 36/250, Loss: 0.1252\n",
      "Epoch 15/200, Iteration 37/250, Loss: 0.1599\n",
      "Epoch 15/200, Iteration 38/250, Loss: 0.1743\n",
      "Epoch 15/200, Iteration 39/250, Loss: 0.1201\n",
      "Epoch 15/200, Iteration 40/250, Loss: 0.1074\n",
      "Epoch 15/200, Iteration 41/250, Loss: 0.1247\n",
      "Epoch 15/200, Iteration 42/250, Loss: 0.0759\n",
      "Epoch 15/200, Iteration 43/250, Loss: 0.1445\n",
      "Epoch 15/200, Iteration 44/250, Loss: 0.1647\n",
      "Epoch 15/200, Iteration 45/250, Loss: 0.0855\n",
      "Epoch 15/200, Iteration 46/250, Loss: 0.1113\n",
      "Epoch 15/200, Iteration 47/250, Loss: 0.1114\n",
      "Epoch 15/200, Iteration 48/250, Loss: 0.1230\n",
      "Epoch 15/200, Iteration 49/250, Loss: 0.1238\n",
      "Epoch 15/200, Iteration 50/250, Loss: 0.1137\n",
      "Epoch 15/200, Iteration 51/250, Loss: 0.0683\n",
      "Epoch 15/200, Iteration 52/250, Loss: 0.0750\n",
      "Epoch 15/200, Iteration 53/250, Loss: 0.0726\n",
      "Epoch 15/200, Iteration 54/250, Loss: 0.0905\n",
      "Epoch 15/200, Iteration 55/250, Loss: 0.0686\n",
      "Epoch 15/200, Iteration 56/250, Loss: 0.0512\n",
      "Epoch 15/200, Iteration 57/250, Loss: 0.0848\n",
      "Epoch 15/200, Iteration 58/250, Loss: 0.0747\n",
      "Epoch 15/200, Iteration 59/250, Loss: 0.0877\n",
      "Epoch 15/200, Iteration 60/250, Loss: 0.1131\n",
      "Epoch 15/200, Iteration 61/250, Loss: 0.0649\n",
      "Epoch 15/200, Iteration 62/250, Loss: 0.1043\n",
      "Epoch 15/200, Iteration 63/250, Loss: 0.0693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Iteration 64/250, Loss: 0.0731\n",
      "Epoch 15/200, Iteration 65/250, Loss: 0.0643\n",
      "Epoch 15/200, Iteration 66/250, Loss: 0.0907\n",
      "Epoch 15/200, Iteration 67/250, Loss: 0.0817\n",
      "Epoch 15/200, Iteration 68/250, Loss: 0.0790\n",
      "Epoch 15/200, Iteration 69/250, Loss: 0.0780\n",
      "Epoch 15/200, Iteration 70/250, Loss: 0.0494\n",
      "Epoch 15/200, Iteration 71/250, Loss: 0.0689\n",
      "Epoch 15/200, Iteration 72/250, Loss: 0.0613\n",
      "Epoch 15/200, Iteration 73/250, Loss: 0.0688\n",
      "Epoch 15/200, Iteration 74/250, Loss: 0.0598\n",
      "Epoch 15/200, Iteration 75/250, Loss: 0.0640\n",
      "Epoch 15/200, Iteration 76/250, Loss: 0.0699\n",
      "Epoch 15/200, Iteration 77/250, Loss: 0.0824\n",
      "Epoch 15/200, Iteration 78/250, Loss: 0.0816\n",
      "Epoch 15/200, Iteration 79/250, Loss: 0.0541\n",
      "Epoch 15/200, Iteration 80/250, Loss: 0.0681\n",
      "Epoch 15/200, Iteration 81/250, Loss: 0.0810\n",
      "Epoch 15/200, Iteration 82/250, Loss: 0.0855\n",
      "Epoch 15/200, Iteration 83/250, Loss: 0.0671\n",
      "Epoch 15/200, Iteration 84/250, Loss: 0.0728\n",
      "Epoch 15/200, Iteration 85/250, Loss: 0.0576\n",
      "Epoch 15/200, Iteration 86/250, Loss: 0.0527\n",
      "Epoch 15/200, Iteration 87/250, Loss: 0.0557\n",
      "Epoch 15/200, Iteration 88/250, Loss: 0.0830\n",
      "Epoch 15/200, Iteration 89/250, Loss: 0.0958\n",
      "Epoch 15/200, Iteration 90/250, Loss: 0.0657\n",
      "Epoch 15/200, Iteration 91/250, Loss: 0.0817\n",
      "Epoch 15/200, Iteration 92/250, Loss: 0.0666\n",
      "Epoch 15/200, Iteration 93/250, Loss: 0.0751\n",
      "Epoch 15/200, Iteration 94/250, Loss: 0.0599\n",
      "Epoch 15/200, Iteration 95/250, Loss: 0.1102\n",
      "Epoch 15/200, Iteration 96/250, Loss: 0.0438\n",
      "Epoch 15/200, Iteration 97/250, Loss: 0.0932\n",
      "Epoch 15/200, Iteration 98/250, Loss: 0.0863\n",
      "Epoch 15/200, Iteration 99/250, Loss: 0.0550\n",
      "Epoch 15/200, Iteration 100/250, Loss: 0.1130\n",
      "Epoch 15/200, Iteration 101/250, Loss: 0.1198\n",
      "Epoch 15/200, Iteration 102/250, Loss: 0.1117\n",
      "Epoch 15/200, Iteration 103/250, Loss: 0.1034\n",
      "Epoch 15/200, Iteration 104/250, Loss: 0.0942\n",
      "Epoch 15/200, Iteration 105/250, Loss: 0.0832\n",
      "Epoch 15/200, Iteration 106/250, Loss: 0.1476\n",
      "Epoch 15/200, Iteration 107/250, Loss: 0.0891\n",
      "Epoch 15/200, Iteration 108/250, Loss: 0.0891\n",
      "Epoch 15/200, Iteration 109/250, Loss: 0.1709\n",
      "Epoch 15/200, Iteration 110/250, Loss: 0.1524\n",
      "Epoch 15/200, Iteration 111/250, Loss: 0.1047\n",
      "Epoch 15/200, Iteration 112/250, Loss: 0.1243\n",
      "Epoch 15/200, Iteration 113/250, Loss: 0.1627\n",
      "Epoch 15/200, Iteration 114/250, Loss: 0.1415\n",
      "Epoch 15/200, Iteration 115/250, Loss: 0.0606\n",
      "Epoch 15/200, Iteration 116/250, Loss: 0.1348\n",
      "Epoch 15/200, Iteration 117/250, Loss: 0.1248\n",
      "Epoch 15/200, Iteration 118/250, Loss: 0.1285\n",
      "Epoch 15/200, Iteration 119/250, Loss: 0.0873\n",
      "Epoch 15/200, Iteration 120/250, Loss: 0.1106\n",
      "Epoch 15/200, Iteration 121/250, Loss: 0.1083\n",
      "Epoch 15/200, Iteration 122/250, Loss: 0.1264\n",
      "Epoch 15/200, Iteration 123/250, Loss: 0.1170\n",
      "Epoch 15/200, Iteration 124/250, Loss: 0.0870\n",
      "Epoch 15/200, Iteration 125/250, Loss: 0.0685\n",
      "Epoch 15/200, Iteration 126/250, Loss: 0.0851\n",
      "Epoch 15/200, Iteration 127/250, Loss: 0.1009\n",
      "Epoch 15/200, Iteration 128/250, Loss: 0.1018\n",
      "Epoch 15/200, Iteration 129/250, Loss: 0.0734\n",
      "Epoch 15/200, Iteration 130/250, Loss: 0.1076\n",
      "Epoch 15/200, Iteration 131/250, Loss: 0.1027\n",
      "Epoch 15/200, Iteration 132/250, Loss: 0.0659\n",
      "Epoch 15/200, Iteration 133/250, Loss: 0.1274\n",
      "Epoch 15/200, Iteration 134/250, Loss: 0.1031\n",
      "Epoch 15/200, Iteration 135/250, Loss: 0.0635\n",
      "Epoch 15/200, Iteration 136/250, Loss: 0.1397\n",
      "Epoch 15/200, Iteration 137/250, Loss: 0.1475\n",
      "Epoch 15/200, Iteration 138/250, Loss: 0.1447\n",
      "Epoch 15/200, Iteration 139/250, Loss: 0.0785\n",
      "Epoch 15/200, Iteration 140/250, Loss: 0.0967\n",
      "Epoch 15/200, Iteration 141/250, Loss: 0.1621\n",
      "Epoch 15/200, Iteration 142/250, Loss: 0.1151\n",
      "Epoch 15/200, Iteration 143/250, Loss: 0.0865\n",
      "Epoch 15/200, Iteration 144/250, Loss: 0.1351\n",
      "Epoch 15/200, Iteration 145/250, Loss: 0.1036\n",
      "Epoch 15/200, Iteration 146/250, Loss: 0.0675\n",
      "Epoch 15/200, Iteration 147/250, Loss: 0.1177\n",
      "Epoch 15/200, Iteration 148/250, Loss: 0.1230\n",
      "Epoch 15/200, Iteration 149/250, Loss: 0.1061\n",
      "Epoch 15/200, Iteration 150/250, Loss: 0.0762\n",
      "Epoch 15/200, Iteration 151/250, Loss: 0.0775\n",
      "Epoch 15/200, Iteration 152/250, Loss: 0.1264\n",
      "Epoch 15/200, Iteration 153/250, Loss: 0.0972\n",
      "Epoch 15/200, Iteration 154/250, Loss: 0.1381\n",
      "Epoch 15/200, Iteration 155/250, Loss: 0.1701\n",
      "Epoch 15/200, Iteration 156/250, Loss: 0.1291\n",
      "Epoch 15/200, Iteration 157/250, Loss: 0.0788\n",
      "Epoch 15/200, Iteration 158/250, Loss: 0.0706\n",
      "Epoch 15/200, Iteration 159/250, Loss: 0.0802\n",
      "Epoch 15/200, Iteration 160/250, Loss: 0.0606\n",
      "Epoch 15/200, Iteration 161/250, Loss: 0.0648\n",
      "Epoch 15/200, Iteration 162/250, Loss: 0.0519\n",
      "Epoch 15/200, Iteration 163/250, Loss: 0.0446\n",
      "Epoch 15/200, Iteration 164/250, Loss: 0.0722\n",
      "Epoch 15/200, Iteration 165/250, Loss: 0.0652\n",
      "Epoch 15/200, Iteration 166/250, Loss: 0.1010\n",
      "Epoch 15/200, Iteration 167/250, Loss: 0.0974\n",
      "Epoch 15/200, Iteration 168/250, Loss: 0.0856\n",
      "Epoch 15/200, Iteration 169/250, Loss: 0.0918\n",
      "Epoch 15/200, Iteration 170/250, Loss: 0.0676\n",
      "Epoch 15/200, Iteration 171/250, Loss: 0.0906\n",
      "Epoch 15/200, Iteration 172/250, Loss: 0.0687\n",
      "Epoch 15/200, Iteration 173/250, Loss: 0.0909\n",
      "Epoch 15/200, Iteration 174/250, Loss: 0.0666\n",
      "Epoch 15/200, Iteration 175/250, Loss: 0.0559\n",
      "Epoch 15/200, Iteration 176/250, Loss: 0.0911\n",
      "Epoch 15/200, Iteration 177/250, Loss: 0.0708\n",
      "Epoch 15/200, Iteration 178/250, Loss: 0.0418\n",
      "Epoch 15/200, Iteration 179/250, Loss: 0.0877\n",
      "Epoch 15/200, Iteration 180/250, Loss: 0.0635\n",
      "Epoch 15/200, Iteration 181/250, Loss: 0.0537\n",
      "Epoch 15/200, Iteration 182/250, Loss: 0.0521\n",
      "Epoch 15/200, Iteration 183/250, Loss: 0.0502\n",
      "Epoch 15/200, Iteration 184/250, Loss: 0.0536\n",
      "Epoch 15/200, Iteration 185/250, Loss: 0.0537\n",
      "Epoch 15/200, Iteration 186/250, Loss: 0.0490\n",
      "Epoch 15/200, Iteration 187/250, Loss: 0.0480\n",
      "Epoch 15/200, Iteration 188/250, Loss: 0.0763\n",
      "Epoch 15/200, Iteration 189/250, Loss: 0.0835\n",
      "Epoch 15/200, Iteration 190/250, Loss: 0.0844\n",
      "Epoch 15/200, Iteration 191/250, Loss: 0.0727\n",
      "Epoch 15/200, Iteration 192/250, Loss: 0.0422\n",
      "Epoch 15/200, Iteration 193/250, Loss: 0.0845\n",
      "Epoch 15/200, Iteration 194/250, Loss: 0.0660\n",
      "Epoch 15/200, Iteration 195/250, Loss: 0.0510\n",
      "Epoch 15/200, Iteration 196/250, Loss: 0.0517\n",
      "Epoch 15/200, Iteration 197/250, Loss: 0.0355\n",
      "Epoch 15/200, Iteration 198/250, Loss: 0.0715\n",
      "Epoch 15/200, Iteration 199/250, Loss: 0.0737\n",
      "Epoch 15/200, Iteration 200/250, Loss: 0.0471\n",
      "Epoch 15/200, Iteration 201/250, Loss: 0.0568\n",
      "Epoch 15/200, Iteration 202/250, Loss: 0.0540\n",
      "Epoch 15/200, Iteration 203/250, Loss: 0.0373\n",
      "Epoch 15/200, Iteration 204/250, Loss: 0.0542\n",
      "Epoch 15/200, Iteration 205/250, Loss: 0.0380\n",
      "Epoch 15/200, Iteration 206/250, Loss: 0.0752\n",
      "Epoch 15/200, Iteration 207/250, Loss: 0.0753\n",
      "Epoch 15/200, Iteration 208/250, Loss: 0.0604\n",
      "Epoch 15/200, Iteration 209/250, Loss: 0.0764\n",
      "Epoch 15/200, Iteration 210/250, Loss: 0.0590\n",
      "Epoch 15/200, Iteration 211/250, Loss: 0.0833\n",
      "Epoch 15/200, Iteration 212/250, Loss: 0.0729\n",
      "Epoch 15/200, Iteration 213/250, Loss: 0.0396\n",
      "Epoch 15/200, Iteration 214/250, Loss: 0.0459\n",
      "Epoch 15/200, Iteration 215/250, Loss: 0.1108\n",
      "Epoch 15/200, Iteration 216/250, Loss: 0.1112\n",
      "Epoch 15/200, Iteration 217/250, Loss: 0.1204\n",
      "Epoch 15/200, Iteration 218/250, Loss: 0.0932\n",
      "Epoch 15/200, Iteration 219/250, Loss: 0.0975\n",
      "Epoch 15/200, Iteration 220/250, Loss: 0.1380\n",
      "Epoch 15/200, Iteration 221/250, Loss: 0.0790\n",
      "Epoch 15/200, Iteration 222/250, Loss: 0.1440\n",
      "Epoch 15/200, Iteration 223/250, Loss: 0.1225\n",
      "Epoch 15/200, Iteration 224/250, Loss: 0.1145\n",
      "Epoch 15/200, Iteration 225/250, Loss: 0.1687\n",
      "Epoch 15/200, Iteration 226/250, Loss: 0.1104\n",
      "Epoch 15/200, Iteration 227/250, Loss: 0.1446\n",
      "Epoch 15/200, Iteration 228/250, Loss: 0.1412\n",
      "Epoch 15/200, Iteration 229/250, Loss: 0.0896\n",
      "Epoch 15/200, Iteration 230/250, Loss: 0.1424\n",
      "Epoch 15/200, Iteration 231/250, Loss: 0.2236\n",
      "Epoch 15/200, Iteration 232/250, Loss: 0.1190\n",
      "Epoch 15/200, Iteration 233/250, Loss: 0.0943\n",
      "Epoch 15/200, Iteration 234/250, Loss: 0.1901\n",
      "Epoch 15/200, Iteration 235/250, Loss: 0.1668\n",
      "Epoch 15/200, Iteration 236/250, Loss: 0.1130\n",
      "Epoch 15/200, Iteration 237/250, Loss: 0.1575\n",
      "Epoch 15/200, Iteration 238/250, Loss: 0.1410\n",
      "Epoch 15/200, Iteration 239/250, Loss: 0.0926\n",
      "Epoch 15/200, Iteration 240/250, Loss: 0.0818\n",
      "Epoch 15/200, Iteration 241/250, Loss: 0.0879\n",
      "Epoch 15/200, Iteration 242/250, Loss: 0.0616\n",
      "Epoch 15/200, Iteration 243/250, Loss: 0.0746\n",
      "Epoch 15/200, Iteration 244/250, Loss: 0.0610\n",
      "Epoch 15/200, Iteration 245/250, Loss: 0.1088\n",
      "Epoch 15/200, Iteration 246/250, Loss: 0.1047\n",
      "Epoch 15/200, Iteration 247/250, Loss: 0.0979\n",
      "Epoch 15/200, Iteration 248/250, Loss: 0.1647\n",
      "Epoch 15/200, Iteration 249/250, Loss: 0.1025\n",
      "Epoch 15/200, Iteration 250/250, Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 55.29%, Avg loss: 0.124499, MRE: 7.562928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 0.119017, MRE: 6.414140 \n",
      "\n",
      "Epoch 16/200, Iteration 1/250, Loss: 0.1141\n",
      "Epoch 16/200, Iteration 2/250, Loss: 0.1200\n",
      "Epoch 16/200, Iteration 3/250, Loss: 0.1077\n",
      "Epoch 16/200, Iteration 4/250, Loss: 0.0732\n",
      "Epoch 16/200, Iteration 5/250, Loss: 0.0744\n",
      "Epoch 16/200, Iteration 6/250, Loss: 0.0590\n",
      "Epoch 16/200, Iteration 7/250, Loss: 0.0455\n",
      "Epoch 16/200, Iteration 8/250, Loss: 0.0650\n",
      "Epoch 16/200, Iteration 9/250, Loss: 0.0739\n",
      "Epoch 16/200, Iteration 10/250, Loss: 0.0679\n",
      "Epoch 16/200, Iteration 11/250, Loss: 0.0554\n",
      "Epoch 16/200, Iteration 12/250, Loss: 0.0829\n",
      "Epoch 16/200, Iteration 13/250, Loss: 0.0760\n",
      "Epoch 16/200, Iteration 14/250, Loss: 0.0520\n",
      "Epoch 16/200, Iteration 15/250, Loss: 0.0519\n",
      "Epoch 16/200, Iteration 16/250, Loss: 0.0401\n",
      "Epoch 16/200, Iteration 17/250, Loss: 0.0385\n",
      "Epoch 16/200, Iteration 18/250, Loss: 0.0594\n",
      "Epoch 16/200, Iteration 19/250, Loss: 0.0407\n",
      "Epoch 16/200, Iteration 20/250, Loss: 0.0419\n",
      "Epoch 16/200, Iteration 21/250, Loss: 0.0533\n",
      "Epoch 16/200, Iteration 22/250, Loss: 0.0429\n",
      "Epoch 16/200, Iteration 23/250, Loss: 0.0337\n",
      "Epoch 16/200, Iteration 24/250, Loss: 0.0305\n",
      "Epoch 16/200, Iteration 25/250, Loss: 0.0409\n",
      "Epoch 16/200, Iteration 26/250, Loss: 0.0463\n",
      "Epoch 16/200, Iteration 27/250, Loss: 0.0343\n",
      "Epoch 16/200, Iteration 28/250, Loss: 0.0403\n",
      "Epoch 16/200, Iteration 29/250, Loss: 0.0382\n",
      "Epoch 16/200, Iteration 30/250, Loss: 0.0292\n",
      "Epoch 16/200, Iteration 31/250, Loss: 0.0687\n",
      "Epoch 16/200, Iteration 32/250, Loss: 0.0322\n",
      "Epoch 16/200, Iteration 33/250, Loss: 0.0369\n",
      "Epoch 16/200, Iteration 34/250, Loss: 0.0360\n",
      "Epoch 16/200, Iteration 35/250, Loss: 0.0293\n",
      "Epoch 16/200, Iteration 36/250, Loss: 0.0347\n",
      "Epoch 16/200, Iteration 37/250, Loss: 0.0317\n",
      "Epoch 16/200, Iteration 38/250, Loss: 0.0303\n",
      "Epoch 16/200, Iteration 39/250, Loss: 0.0444\n",
      "Epoch 16/200, Iteration 40/250, Loss: 0.0418\n",
      "Epoch 16/200, Iteration 41/250, Loss: 0.0242\n",
      "Epoch 16/200, Iteration 42/250, Loss: 0.0337\n",
      "Epoch 16/200, Iteration 43/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 44/250, Loss: 0.0300\n",
      "Epoch 16/200, Iteration 45/250, Loss: 0.0284\n",
      "Epoch 16/200, Iteration 46/250, Loss: 0.0355\n",
      "Epoch 16/200, Iteration 47/250, Loss: 0.0511\n",
      "Epoch 16/200, Iteration 48/250, Loss: 0.0305\n",
      "Epoch 16/200, Iteration 49/250, Loss: 0.0344\n",
      "Epoch 16/200, Iteration 50/250, Loss: 0.0346\n",
      "Epoch 16/200, Iteration 51/250, Loss: 0.0394\n",
      "Epoch 16/200, Iteration 52/250, Loss: 0.0372\n",
      "Epoch 16/200, Iteration 53/250, Loss: 0.0346\n",
      "Epoch 16/200, Iteration 54/250, Loss: 0.0284\n",
      "Epoch 16/200, Iteration 55/250, Loss: 0.0277\n",
      "Epoch 16/200, Iteration 56/250, Loss: 0.0220\n",
      "Epoch 16/200, Iteration 57/250, Loss: 0.0226\n",
      "Epoch 16/200, Iteration 58/250, Loss: 0.0216\n",
      "Epoch 16/200, Iteration 59/250, Loss: 0.0295\n",
      "Epoch 16/200, Iteration 60/250, Loss: 0.0281\n",
      "Epoch 16/200, Iteration 61/250, Loss: 0.0257\n",
      "Epoch 16/200, Iteration 62/250, Loss: 0.0325\n",
      "Epoch 16/200, Iteration 63/250, Loss: 0.0334\n",
      "Epoch 16/200, Iteration 64/250, Loss: 0.0362\n",
      "Epoch 16/200, Iteration 65/250, Loss: 0.0264\n",
      "Epoch 16/200, Iteration 66/250, Loss: 0.0290\n",
      "Epoch 16/200, Iteration 67/250, Loss: 0.0544\n",
      "Epoch 16/200, Iteration 68/250, Loss: 0.0471\n",
      "Epoch 16/200, Iteration 69/250, Loss: 0.0376\n",
      "Epoch 16/200, Iteration 70/250, Loss: 0.0256\n",
      "Epoch 16/200, Iteration 71/250, Loss: 0.0207\n",
      "Epoch 16/200, Iteration 72/250, Loss: 0.0360\n",
      "Epoch 16/200, Iteration 73/250, Loss: 0.0350\n",
      "Epoch 16/200, Iteration 74/250, Loss: 0.0174\n",
      "Epoch 16/200, Iteration 75/250, Loss: 0.0325\n",
      "Epoch 16/200, Iteration 76/250, Loss: 0.0273\n",
      "Epoch 16/200, Iteration 77/250, Loss: 0.0355\n",
      "Epoch 16/200, Iteration 78/250, Loss: 0.0253\n",
      "Epoch 16/200, Iteration 79/250, Loss: 0.0333\n",
      "Epoch 16/200, Iteration 80/250, Loss: 0.0278\n",
      "Epoch 16/200, Iteration 81/250, Loss: 0.0317\n",
      "Epoch 16/200, Iteration 82/250, Loss: 0.0253\n",
      "Epoch 16/200, Iteration 83/250, Loss: 0.0256\n",
      "Epoch 16/200, Iteration 84/250, Loss: 0.0406\n",
      "Epoch 16/200, Iteration 85/250, Loss: 0.0220\n",
      "Epoch 16/200, Iteration 86/250, Loss: 0.0221\n",
      "Epoch 16/200, Iteration 87/250, Loss: 0.0209\n",
      "Epoch 16/200, Iteration 88/250, Loss: 0.0214\n",
      "Epoch 16/200, Iteration 89/250, Loss: 0.0193\n",
      "Epoch 16/200, Iteration 90/250, Loss: 0.0295\n",
      "Epoch 16/200, Iteration 91/250, Loss: 0.0281\n",
      "Epoch 16/200, Iteration 92/250, Loss: 0.0242\n",
      "Epoch 16/200, Iteration 93/250, Loss: 0.0270\n",
      "Epoch 16/200, Iteration 94/250, Loss: 0.0195\n",
      "Epoch 16/200, Iteration 95/250, Loss: 0.0295\n",
      "Epoch 16/200, Iteration 96/250, Loss: 0.0211\n",
      "Epoch 16/200, Iteration 97/250, Loss: 0.0283\n",
      "Epoch 16/200, Iteration 98/250, Loss: 0.0197\n",
      "Epoch 16/200, Iteration 99/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 100/250, Loss: 0.0318\n",
      "Epoch 16/200, Iteration 101/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 102/250, Loss: 0.0277\n",
      "Epoch 16/200, Iteration 103/250, Loss: 0.0196\n",
      "Epoch 16/200, Iteration 104/250, Loss: 0.0306\n",
      "Epoch 16/200, Iteration 105/250, Loss: 0.0233\n",
      "Epoch 16/200, Iteration 106/250, Loss: 0.0212\n",
      "Epoch 16/200, Iteration 107/250, Loss: 0.0514\n",
      "Epoch 16/200, Iteration 108/250, Loss: 0.0352\n",
      "Epoch 16/200, Iteration 109/250, Loss: 0.0451\n",
      "Epoch 16/200, Iteration 110/250, Loss: 0.0412\n",
      "Epoch 16/200, Iteration 111/250, Loss: 0.0271\n",
      "Epoch 16/200, Iteration 112/250, Loss: 0.0199\n",
      "Epoch 16/200, Iteration 113/250, Loss: 0.0288\n",
      "Epoch 16/200, Iteration 114/250, Loss: 0.0294\n",
      "Epoch 16/200, Iteration 115/250, Loss: 0.0399\n",
      "Epoch 16/200, Iteration 116/250, Loss: 0.0336\n",
      "Epoch 16/200, Iteration 117/250, Loss: 0.0311\n",
      "Epoch 16/200, Iteration 118/250, Loss: 0.0256\n",
      "Epoch 16/200, Iteration 119/250, Loss: 0.0308\n",
      "Epoch 16/200, Iteration 120/250, Loss: 0.0238\n",
      "Epoch 16/200, Iteration 121/250, Loss: 0.0276\n",
      "Epoch 16/200, Iteration 122/250, Loss: 0.0265\n",
      "Epoch 16/200, Iteration 123/250, Loss: 0.0254\n",
      "Epoch 16/200, Iteration 124/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 125/250, Loss: 0.0161\n",
      "Epoch 16/200, Iteration 126/250, Loss: 0.0248\n",
      "Epoch 16/200, Iteration 127/250, Loss: 0.0207\n",
      "Epoch 16/200, Iteration 128/250, Loss: 0.0242\n",
      "Epoch 16/200, Iteration 129/250, Loss: 0.0415\n",
      "Epoch 16/200, Iteration 130/250, Loss: 0.0230\n",
      "Epoch 16/200, Iteration 131/250, Loss: 0.0330\n",
      "Epoch 16/200, Iteration 132/250, Loss: 0.0302\n",
      "Epoch 16/200, Iteration 133/250, Loss: 0.0224\n",
      "Epoch 16/200, Iteration 134/250, Loss: 0.0265\n",
      "Epoch 16/200, Iteration 135/250, Loss: 0.0248\n",
      "Epoch 16/200, Iteration 136/250, Loss: 0.0209\n",
      "Epoch 16/200, Iteration 137/250, Loss: 0.0334\n",
      "Epoch 16/200, Iteration 138/250, Loss: 0.0208\n",
      "Epoch 16/200, Iteration 139/250, Loss: 0.0388\n",
      "Epoch 16/200, Iteration 140/250, Loss: 0.0228\n",
      "Epoch 16/200, Iteration 141/250, Loss: 0.0212\n",
      "Epoch 16/200, Iteration 142/250, Loss: 0.0279\n",
      "Epoch 16/200, Iteration 143/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 144/250, Loss: 0.0274\n",
      "Epoch 16/200, Iteration 145/250, Loss: 0.0214\n",
      "Epoch 16/200, Iteration 146/250, Loss: 0.0220\n",
      "Epoch 16/200, Iteration 147/250, Loss: 0.0339\n",
      "Epoch 16/200, Iteration 148/250, Loss: 0.0285\n",
      "Epoch 16/200, Iteration 149/250, Loss: 0.0186\n",
      "Epoch 16/200, Iteration 150/250, Loss: 0.0272\n",
      "Epoch 16/200, Iteration 151/250, Loss: 0.0239\n",
      "Epoch 16/200, Iteration 152/250, Loss: 0.0176\n",
      "Epoch 16/200, Iteration 153/250, Loss: 0.0270\n",
      "Epoch 16/200, Iteration 154/250, Loss: 0.0213\n",
      "Epoch 16/200, Iteration 155/250, Loss: 0.0286\n",
      "Epoch 16/200, Iteration 156/250, Loss: 0.0235\n",
      "Epoch 16/200, Iteration 157/250, Loss: 0.0320\n",
      "Epoch 16/200, Iteration 158/250, Loss: 0.0246\n",
      "Epoch 16/200, Iteration 159/250, Loss: 0.0303\n",
      "Epoch 16/200, Iteration 160/250, Loss: 0.0317\n",
      "Epoch 16/200, Iteration 161/250, Loss: 0.0374\n",
      "Epoch 16/200, Iteration 162/250, Loss: 0.0268\n",
      "Epoch 16/200, Iteration 163/250, Loss: 0.0249\n",
      "Epoch 16/200, Iteration 164/250, Loss: 0.0194\n",
      "Epoch 16/200, Iteration 165/250, Loss: 0.0302\n",
      "Epoch 16/200, Iteration 166/250, Loss: 0.0338\n",
      "Epoch 16/200, Iteration 167/250, Loss: 0.0292\n",
      "Epoch 16/200, Iteration 168/250, Loss: 0.0312\n",
      "Epoch 16/200, Iteration 169/250, Loss: 0.0294\n",
      "Epoch 16/200, Iteration 170/250, Loss: 0.0237\n",
      "Epoch 16/200, Iteration 171/250, Loss: 0.0324\n",
      "Epoch 16/200, Iteration 172/250, Loss: 0.0325\n",
      "Epoch 16/200, Iteration 173/250, Loss: 0.0312\n",
      "Epoch 16/200, Iteration 174/250, Loss: 0.0328\n",
      "Epoch 16/200, Iteration 175/250, Loss: 0.0218\n",
      "Epoch 16/200, Iteration 176/250, Loss: 0.0284\n",
      "Epoch 16/200, Iteration 177/250, Loss: 0.0259\n",
      "Epoch 16/200, Iteration 178/250, Loss: 0.0263\n",
      "Epoch 16/200, Iteration 179/250, Loss: 0.0232\n",
      "Epoch 16/200, Iteration 180/250, Loss: 0.0260\n",
      "Epoch 16/200, Iteration 181/250, Loss: 0.0325\n",
      "Epoch 16/200, Iteration 182/250, Loss: 0.0251\n",
      "Epoch 16/200, Iteration 183/250, Loss: 0.0173\n",
      "Epoch 16/200, Iteration 184/250, Loss: 0.0205\n",
      "Epoch 16/200, Iteration 185/250, Loss: 0.0269\n",
      "Epoch 16/200, Iteration 186/250, Loss: 0.0208\n",
      "Epoch 16/200, Iteration 187/250, Loss: 0.0188\n",
      "Epoch 16/200, Iteration 188/250, Loss: 0.0240\n",
      "Epoch 16/200, Iteration 189/250, Loss: 0.0194\n",
      "Epoch 16/200, Iteration 190/250, Loss: 0.0228\n",
      "Epoch 16/200, Iteration 191/250, Loss: 0.0226\n",
      "Epoch 16/200, Iteration 192/250, Loss: 0.0261\n",
      "Epoch 16/200, Iteration 193/250, Loss: 0.0274\n",
      "Epoch 16/200, Iteration 194/250, Loss: 0.0248\n",
      "Epoch 16/200, Iteration 195/250, Loss: 0.0247\n",
      "Epoch 16/200, Iteration 196/250, Loss: 0.0192\n",
      "Epoch 16/200, Iteration 197/250, Loss: 0.0223\n",
      "Epoch 16/200, Iteration 198/250, Loss: 0.0199\n",
      "Epoch 16/200, Iteration 199/250, Loss: 0.0382\n",
      "Epoch 16/200, Iteration 200/250, Loss: 0.0253\n",
      "Epoch 16/200, Iteration 201/250, Loss: 0.0307\n",
      "Epoch 16/200, Iteration 202/250, Loss: 0.0344\n",
      "Epoch 16/200, Iteration 203/250, Loss: 0.0294\n",
      "Epoch 16/200, Iteration 204/250, Loss: 0.0262\n",
      "Epoch 16/200, Iteration 205/250, Loss: 0.0176\n",
      "Epoch 16/200, Iteration 206/250, Loss: 0.0358\n",
      "Epoch 16/200, Iteration 207/250, Loss: 0.0373\n",
      "Epoch 16/200, Iteration 208/250, Loss: 0.0253\n",
      "Epoch 16/200, Iteration 209/250, Loss: 0.0364\n",
      "Epoch 16/200, Iteration 210/250, Loss: 0.0219\n",
      "Epoch 16/200, Iteration 211/250, Loss: 0.0223\n",
      "Epoch 16/200, Iteration 212/250, Loss: 0.0292\n",
      "Epoch 16/200, Iteration 213/250, Loss: 0.0193\n",
      "Epoch 16/200, Iteration 214/250, Loss: 0.0161\n",
      "Epoch 16/200, Iteration 215/250, Loss: 0.0266\n",
      "Epoch 16/200, Iteration 216/250, Loss: 0.0168\n",
      "Epoch 16/200, Iteration 217/250, Loss: 0.0124\n",
      "Epoch 16/200, Iteration 218/250, Loss: 0.0225\n",
      "Epoch 16/200, Iteration 219/250, Loss: 0.0197\n",
      "Epoch 16/200, Iteration 220/250, Loss: 0.0233\n",
      "Epoch 16/200, Iteration 221/250, Loss: 0.0201\n",
      "Epoch 16/200, Iteration 222/250, Loss: 0.0329\n",
      "Epoch 16/200, Iteration 223/250, Loss: 0.0259\n",
      "Epoch 16/200, Iteration 224/250, Loss: 0.0320\n",
      "Epoch 16/200, Iteration 225/250, Loss: 0.0200\n",
      "Epoch 16/200, Iteration 226/250, Loss: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Iteration 227/250, Loss: 0.0360\n",
      "Epoch 16/200, Iteration 228/250, Loss: 0.0303\n",
      "Epoch 16/200, Iteration 229/250, Loss: 0.0226\n",
      "Epoch 16/200, Iteration 230/250, Loss: 0.0153\n",
      "Epoch 16/200, Iteration 231/250, Loss: 0.0199\n",
      "Epoch 16/200, Iteration 232/250, Loss: 0.0245\n",
      "Epoch 16/200, Iteration 233/250, Loss: 0.0227\n",
      "Epoch 16/200, Iteration 234/250, Loss: 0.0241\n",
      "Epoch 16/200, Iteration 235/250, Loss: 0.0223\n",
      "Epoch 16/200, Iteration 236/250, Loss: 0.0222\n",
      "Epoch 16/200, Iteration 237/250, Loss: 0.0376\n",
      "Epoch 16/200, Iteration 238/250, Loss: 0.0178\n",
      "Epoch 16/200, Iteration 239/250, Loss: 0.0194\n",
      "Epoch 16/200, Iteration 240/250, Loss: 0.0160\n",
      "Epoch 16/200, Iteration 241/250, Loss: 0.0183\n",
      "Epoch 16/200, Iteration 242/250, Loss: 0.0244\n",
      "Epoch 16/200, Iteration 243/250, Loss: 0.0291\n",
      "Epoch 16/200, Iteration 244/250, Loss: 0.0296\n",
      "Epoch 16/200, Iteration 245/250, Loss: 0.0457\n",
      "Epoch 16/200, Iteration 246/250, Loss: 0.0292\n",
      "Epoch 16/200, Iteration 247/250, Loss: 0.0248\n",
      "Epoch 16/200, Iteration 248/250, Loss: 0.0232\n",
      "Epoch 16/200, Iteration 249/250, Loss: 0.0198\n",
      "Epoch 16/200, Iteration 250/250, Loss: 0.0198\n",
      "Train Error: \n",
      " Accuracy: 53.49%, Avg loss: 0.021728, MRE: 1.570544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 0.021891, MRE: 1.690561 \n",
      "\n",
      "Epoch 17/200, Iteration 1/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 2/250, Loss: 0.0245\n",
      "Epoch 17/200, Iteration 3/250, Loss: 0.0178\n",
      "Epoch 17/200, Iteration 4/250, Loss: 0.0270\n",
      "Epoch 17/200, Iteration 5/250, Loss: 0.0272\n",
      "Epoch 17/200, Iteration 6/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 7/250, Loss: 0.0252\n",
      "Epoch 17/200, Iteration 8/250, Loss: 0.0479\n",
      "Epoch 17/200, Iteration 9/250, Loss: 0.0426\n",
      "Epoch 17/200, Iteration 10/250, Loss: 0.0332\n",
      "Epoch 17/200, Iteration 11/250, Loss: 0.0307\n",
      "Epoch 17/200, Iteration 12/250, Loss: 0.0313\n",
      "Epoch 17/200, Iteration 13/250, Loss: 0.0306\n",
      "Epoch 17/200, Iteration 14/250, Loss: 0.0338\n",
      "Epoch 17/200, Iteration 15/250, Loss: 0.0343\n",
      "Epoch 17/200, Iteration 16/250, Loss: 0.0356\n",
      "Epoch 17/200, Iteration 17/250, Loss: 0.0212\n",
      "Epoch 17/200, Iteration 18/250, Loss: 0.0236\n",
      "Epoch 17/200, Iteration 19/250, Loss: 0.0274\n",
      "Epoch 17/200, Iteration 20/250, Loss: 0.0175\n",
      "Epoch 17/200, Iteration 21/250, Loss: 0.0205\n",
      "Epoch 17/200, Iteration 22/250, Loss: 0.0209\n",
      "Epoch 17/200, Iteration 23/250, Loss: 0.0236\n",
      "Epoch 17/200, Iteration 24/250, Loss: 0.0162\n",
      "Epoch 17/200, Iteration 25/250, Loss: 0.0204\n",
      "Epoch 17/200, Iteration 26/250, Loss: 0.0271\n",
      "Epoch 17/200, Iteration 27/250, Loss: 0.0320\n",
      "Epoch 17/200, Iteration 28/250, Loss: 0.0141\n",
      "Epoch 17/200, Iteration 29/250, Loss: 0.0239\n",
      "Epoch 17/200, Iteration 30/250, Loss: 0.0222\n",
      "Epoch 17/200, Iteration 31/250, Loss: 0.0281\n",
      "Epoch 17/200, Iteration 32/250, Loss: 0.0222\n",
      "Epoch 17/200, Iteration 33/250, Loss: 0.0387\n",
      "Epoch 17/200, Iteration 34/250, Loss: 0.0341\n",
      "Epoch 17/200, Iteration 35/250, Loss: 0.0240\n",
      "Epoch 17/200, Iteration 36/250, Loss: 0.0252\n",
      "Epoch 17/200, Iteration 37/250, Loss: 0.0301\n",
      "Epoch 17/200, Iteration 38/250, Loss: 0.0333\n",
      "Epoch 17/200, Iteration 39/250, Loss: 0.0276\n",
      "Epoch 17/200, Iteration 40/250, Loss: 0.0236\n",
      "Epoch 17/200, Iteration 41/250, Loss: 0.0292\n",
      "Epoch 17/200, Iteration 42/250, Loss: 0.0303\n",
      "Epoch 17/200, Iteration 43/250, Loss: 0.0291\n",
      "Epoch 17/200, Iteration 44/250, Loss: 0.0170\n",
      "Epoch 17/200, Iteration 45/250, Loss: 0.0217\n",
      "Epoch 17/200, Iteration 46/250, Loss: 0.0304\n",
      "Epoch 17/200, Iteration 47/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 48/250, Loss: 0.0215\n",
      "Epoch 17/200, Iteration 49/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 50/250, Loss: 0.0331\n",
      "Epoch 17/200, Iteration 51/250, Loss: 0.0387\n",
      "Epoch 17/200, Iteration 52/250, Loss: 0.0230\n",
      "Epoch 17/200, Iteration 53/250, Loss: 0.0495\n",
      "Epoch 17/200, Iteration 54/250, Loss: 0.0199\n",
      "Epoch 17/200, Iteration 55/250, Loss: 0.0278\n",
      "Epoch 17/200, Iteration 56/250, Loss: 0.0186\n",
      "Epoch 17/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 17/200, Iteration 58/250, Loss: 0.0296\n",
      "Epoch 17/200, Iteration 59/250, Loss: 0.0207\n",
      "Epoch 17/200, Iteration 60/250, Loss: 0.0271\n",
      "Epoch 17/200, Iteration 61/250, Loss: 0.0290\n",
      "Epoch 17/200, Iteration 62/250, Loss: 0.0166\n",
      "Epoch 17/200, Iteration 63/250, Loss: 0.0234\n",
      "Epoch 17/200, Iteration 64/250, Loss: 0.0186\n",
      "Epoch 17/200, Iteration 65/250, Loss: 0.0197\n",
      "Epoch 17/200, Iteration 66/250, Loss: 0.0150\n",
      "Epoch 17/200, Iteration 67/250, Loss: 0.0203\n",
      "Epoch 17/200, Iteration 68/250, Loss: 0.0276\n",
      "Epoch 17/200, Iteration 69/250, Loss: 0.0233\n",
      "Epoch 17/200, Iteration 70/250, Loss: 0.0211\n",
      "Epoch 17/200, Iteration 71/250, Loss: 0.0259\n",
      "Epoch 17/200, Iteration 72/250, Loss: 0.0173\n",
      "Epoch 17/200, Iteration 73/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 74/250, Loss: 0.0205\n",
      "Epoch 17/200, Iteration 75/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 76/250, Loss: 0.0291\n",
      "Epoch 17/200, Iteration 77/250, Loss: 0.0285\n",
      "Epoch 17/200, Iteration 78/250, Loss: 0.0372\n",
      "Epoch 17/200, Iteration 79/250, Loss: 0.0254\n",
      "Epoch 17/200, Iteration 80/250, Loss: 0.0171\n",
      "Epoch 17/200, Iteration 81/250, Loss: 0.0247\n",
      "Epoch 17/200, Iteration 82/250, Loss: 0.0209\n",
      "Epoch 17/200, Iteration 83/250, Loss: 0.0223\n",
      "Epoch 17/200, Iteration 84/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 85/250, Loss: 0.0210\n",
      "Epoch 17/200, Iteration 86/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 87/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 88/250, Loss: 0.0314\n",
      "Epoch 17/200, Iteration 89/250, Loss: 0.0250\n",
      "Epoch 17/200, Iteration 90/250, Loss: 0.0158\n",
      "Epoch 17/200, Iteration 91/250, Loss: 0.0246\n",
      "Epoch 17/200, Iteration 92/250, Loss: 0.0233\n",
      "Epoch 17/200, Iteration 93/250, Loss: 0.0213\n",
      "Epoch 17/200, Iteration 94/250, Loss: 0.0250\n",
      "Epoch 17/200, Iteration 95/250, Loss: 0.0267\n",
      "Epoch 17/200, Iteration 96/250, Loss: 0.0183\n",
      "Epoch 17/200, Iteration 97/250, Loss: 0.0188\n",
      "Epoch 17/200, Iteration 98/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 99/250, Loss: 0.0302\n",
      "Epoch 17/200, Iteration 100/250, Loss: 0.0427\n",
      "Epoch 17/200, Iteration 101/250, Loss: 0.0214\n",
      "Epoch 17/200, Iteration 102/250, Loss: 0.0175\n",
      "Epoch 17/200, Iteration 103/250, Loss: 0.0203\n",
      "Epoch 17/200, Iteration 104/250, Loss: 0.0270\n",
      "Epoch 17/200, Iteration 105/250, Loss: 0.0230\n",
      "Epoch 17/200, Iteration 106/250, Loss: 0.0451\n",
      "Epoch 17/200, Iteration 107/250, Loss: 0.0180\n",
      "Epoch 17/200, Iteration 108/250, Loss: 0.0301\n",
      "Epoch 17/200, Iteration 109/250, Loss: 0.0277\n",
      "Epoch 17/200, Iteration 110/250, Loss: 0.0457\n",
      "Epoch 17/200, Iteration 111/250, Loss: 0.0168\n",
      "Epoch 17/200, Iteration 112/250, Loss: 0.0183\n",
      "Epoch 17/200, Iteration 113/250, Loss: 0.0236\n",
      "Epoch 17/200, Iteration 114/250, Loss: 0.0225\n",
      "Epoch 17/200, Iteration 115/250, Loss: 0.0202\n",
      "Epoch 17/200, Iteration 116/250, Loss: 0.0246\n",
      "Epoch 17/200, Iteration 117/250, Loss: 0.0205\n",
      "Epoch 17/200, Iteration 118/250, Loss: 0.0239\n",
      "Epoch 17/200, Iteration 119/250, Loss: 0.0202\n",
      "Epoch 17/200, Iteration 120/250, Loss: 0.0279\n",
      "Epoch 17/200, Iteration 121/250, Loss: 0.0333\n",
      "Epoch 17/200, Iteration 122/250, Loss: 0.0309\n",
      "Epoch 17/200, Iteration 123/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 124/250, Loss: 0.0214\n",
      "Epoch 17/200, Iteration 125/250, Loss: 0.0175\n",
      "Epoch 17/200, Iteration 126/250, Loss: 0.0191\n",
      "Epoch 17/200, Iteration 127/250, Loss: 0.0213\n",
      "Epoch 17/200, Iteration 128/250, Loss: 0.0185\n",
      "Epoch 17/200, Iteration 129/250, Loss: 0.0219\n",
      "Epoch 17/200, Iteration 130/250, Loss: 0.0182\n",
      "Epoch 17/200, Iteration 131/250, Loss: 0.0303\n",
      "Epoch 17/200, Iteration 132/250, Loss: 0.0259\n",
      "Epoch 17/200, Iteration 133/250, Loss: 0.0284\n",
      "Epoch 17/200, Iteration 134/250, Loss: 0.0289\n",
      "Epoch 17/200, Iteration 135/250, Loss: 0.0172\n",
      "Epoch 17/200, Iteration 136/250, Loss: 0.0171\n",
      "Epoch 17/200, Iteration 137/250, Loss: 0.0302\n",
      "Epoch 17/200, Iteration 138/250, Loss: 0.0288\n",
      "Epoch 17/200, Iteration 139/250, Loss: 0.0403\n",
      "Epoch 17/200, Iteration 140/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 141/250, Loss: 0.0707\n",
      "Epoch 17/200, Iteration 142/250, Loss: 0.0349\n",
      "Epoch 17/200, Iteration 143/250, Loss: 0.0433\n",
      "Epoch 17/200, Iteration 144/250, Loss: 0.0343\n",
      "Epoch 17/200, Iteration 145/250, Loss: 0.0228\n",
      "Epoch 17/200, Iteration 146/250, Loss: 0.0276\n",
      "Epoch 17/200, Iteration 147/250, Loss: 0.0495\n",
      "Epoch 17/200, Iteration 148/250, Loss: 0.0410\n",
      "Epoch 17/200, Iteration 149/250, Loss: 0.0442\n",
      "Epoch 17/200, Iteration 150/250, Loss: 0.0187\n",
      "Epoch 17/200, Iteration 151/250, Loss: 0.0272\n",
      "Epoch 17/200, Iteration 152/250, Loss: 0.0291\n",
      "Epoch 17/200, Iteration 153/250, Loss: 0.0275\n",
      "Epoch 17/200, Iteration 154/250, Loss: 0.0298\n",
      "Epoch 17/200, Iteration 155/250, Loss: 0.0328\n",
      "Epoch 17/200, Iteration 156/250, Loss: 0.0200\n",
      "Epoch 17/200, Iteration 157/250, Loss: 0.0301\n",
      "Epoch 17/200, Iteration 158/250, Loss: 0.0425\n",
      "Epoch 17/200, Iteration 159/250, Loss: 0.0301\n",
      "Epoch 17/200, Iteration 160/250, Loss: 0.0218\n",
      "Epoch 17/200, Iteration 161/250, Loss: 0.0250\n",
      "Epoch 17/200, Iteration 162/250, Loss: 0.0295\n",
      "Epoch 17/200, Iteration 163/250, Loss: 0.0229\n",
      "Epoch 17/200, Iteration 164/250, Loss: 0.0144\n",
      "Epoch 17/200, Iteration 165/250, Loss: 0.0208\n",
      "Epoch 17/200, Iteration 166/250, Loss: 0.0227\n",
      "Epoch 17/200, Iteration 167/250, Loss: 0.0470\n",
      "Epoch 17/200, Iteration 168/250, Loss: 0.0251\n",
      "Epoch 17/200, Iteration 169/250, Loss: 0.0198\n",
      "Epoch 17/200, Iteration 170/250, Loss: 0.0194\n",
      "Epoch 17/200, Iteration 171/250, Loss: 0.0244\n",
      "Epoch 17/200, Iteration 172/250, Loss: 0.0232\n",
      "Epoch 17/200, Iteration 173/250, Loss: 0.0216\n",
      "Epoch 17/200, Iteration 174/250, Loss: 0.0142\n",
      "Epoch 17/200, Iteration 175/250, Loss: 0.0147\n",
      "Epoch 17/200, Iteration 176/250, Loss: 0.0342\n",
      "Epoch 17/200, Iteration 177/250, Loss: 0.0212\n",
      "Epoch 17/200, Iteration 178/250, Loss: 0.0293\n",
      "Epoch 17/200, Iteration 179/250, Loss: 0.0229\n",
      "Epoch 17/200, Iteration 180/250, Loss: 0.0182\n",
      "Epoch 17/200, Iteration 181/250, Loss: 0.0228\n",
      "Epoch 17/200, Iteration 182/250, Loss: 0.0191\n",
      "Epoch 17/200, Iteration 183/250, Loss: 0.0277\n",
      "Epoch 17/200, Iteration 184/250, Loss: 0.0182\n",
      "Epoch 17/200, Iteration 185/250, Loss: 0.0251\n",
      "Epoch 17/200, Iteration 186/250, Loss: 0.0257\n",
      "Epoch 17/200, Iteration 187/250, Loss: 0.0212\n",
      "Epoch 17/200, Iteration 188/250, Loss: 0.0172\n",
      "Epoch 17/200, Iteration 189/250, Loss: 0.0211\n",
      "Epoch 17/200, Iteration 190/250, Loss: 0.0280\n",
      "Epoch 17/200, Iteration 191/250, Loss: 0.0227\n",
      "Epoch 17/200, Iteration 192/250, Loss: 0.0188\n",
      "Epoch 17/200, Iteration 193/250, Loss: 0.0180\n",
      "Epoch 17/200, Iteration 194/250, Loss: 0.0210\n",
      "Epoch 17/200, Iteration 195/250, Loss: 0.0254\n",
      "Epoch 17/200, Iteration 196/250, Loss: 0.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Iteration 197/250, Loss: 0.0202\n",
      "Epoch 17/200, Iteration 198/250, Loss: 0.0208\n",
      "Epoch 17/200, Iteration 199/250, Loss: 0.0150\n",
      "Epoch 17/200, Iteration 200/250, Loss: 0.0381\n",
      "Epoch 17/200, Iteration 201/250, Loss: 0.0192\n",
      "Epoch 17/200, Iteration 202/250, Loss: 0.0188\n",
      "Epoch 17/200, Iteration 203/250, Loss: 0.0357\n",
      "Epoch 17/200, Iteration 204/250, Loss: 0.0227\n",
      "Epoch 17/200, Iteration 205/250, Loss: 0.0251\n",
      "Epoch 17/200, Iteration 206/250, Loss: 0.0209\n",
      "Epoch 17/200, Iteration 207/250, Loss: 0.0562\n",
      "Epoch 17/200, Iteration 208/250, Loss: 0.0260\n",
      "Epoch 17/200, Iteration 209/250, Loss: 0.0212\n",
      "Epoch 17/200, Iteration 210/250, Loss: 0.0254\n",
      "Epoch 17/200, Iteration 211/250, Loss: 0.0189\n",
      "Epoch 17/200, Iteration 212/250, Loss: 0.0193\n",
      "Epoch 17/200, Iteration 213/250, Loss: 0.0330\n",
      "Epoch 17/200, Iteration 214/250, Loss: 0.0230\n",
      "Epoch 17/200, Iteration 215/250, Loss: 0.0196\n",
      "Epoch 17/200, Iteration 216/250, Loss: 0.0220\n",
      "Epoch 17/200, Iteration 217/250, Loss: 0.0408\n",
      "Epoch 17/200, Iteration 218/250, Loss: 0.0277\n",
      "Epoch 17/200, Iteration 219/250, Loss: 0.0207\n",
      "Epoch 17/200, Iteration 220/250, Loss: 0.0211\n",
      "Epoch 17/200, Iteration 221/250, Loss: 0.0253\n",
      "Epoch 17/200, Iteration 222/250, Loss: 0.0237\n",
      "Epoch 17/200, Iteration 223/250, Loss: 0.0278\n",
      "Epoch 17/200, Iteration 224/250, Loss: 0.0193\n",
      "Epoch 17/200, Iteration 225/250, Loss: 0.0206\n",
      "Epoch 17/200, Iteration 226/250, Loss: 0.0199\n",
      "Epoch 17/200, Iteration 227/250, Loss: 0.0230\n",
      "Epoch 17/200, Iteration 228/250, Loss: 0.0201\n",
      "Epoch 17/200, Iteration 229/250, Loss: 0.0310\n",
      "Epoch 17/200, Iteration 230/250, Loss: 0.0255\n",
      "Epoch 17/200, Iteration 231/250, Loss: 0.0267\n",
      "Epoch 17/200, Iteration 232/250, Loss: 0.0221\n",
      "Epoch 17/200, Iteration 233/250, Loss: 0.0148\n",
      "Epoch 17/200, Iteration 234/250, Loss: 0.0245\n",
      "Epoch 17/200, Iteration 235/250, Loss: 0.0227\n",
      "Epoch 17/200, Iteration 236/250, Loss: 0.0272\n",
      "Epoch 17/200, Iteration 237/250, Loss: 0.0138\n",
      "Epoch 17/200, Iteration 238/250, Loss: 0.0247\n",
      "Epoch 17/200, Iteration 239/250, Loss: 0.0362\n",
      "Epoch 17/200, Iteration 240/250, Loss: 0.0447\n",
      "Epoch 17/200, Iteration 241/250, Loss: 0.0405\n",
      "Epoch 17/200, Iteration 242/250, Loss: 0.0176\n",
      "Epoch 17/200, Iteration 243/250, Loss: 0.0375\n",
      "Epoch 17/200, Iteration 244/250, Loss: 0.0331\n",
      "Epoch 17/200, Iteration 245/250, Loss: 0.0363\n",
      "Epoch 17/200, Iteration 246/250, Loss: 0.0306\n",
      "Epoch 17/200, Iteration 247/250, Loss: 0.0169\n",
      "Epoch 17/200, Iteration 248/250, Loss: 0.0233\n",
      "Epoch 17/200, Iteration 249/250, Loss: 0.0347\n",
      "Epoch 17/200, Iteration 250/250, Loss: 0.0408\n",
      "Train Error: \n",
      " Accuracy: 54.35%, Avg loss: 0.027301, MRE: 2.487761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.027661, MRE: 2.967004 \n",
      "\n",
      "Epoch 18/200, Iteration 1/250, Loss: 0.0313\n",
      "Epoch 18/200, Iteration 2/250, Loss: 0.0204\n",
      "Epoch 18/200, Iteration 3/250, Loss: 0.0371\n",
      "Epoch 18/200, Iteration 4/250, Loss: 0.0312\n",
      "Epoch 18/200, Iteration 5/250, Loss: 0.0393\n",
      "Epoch 18/200, Iteration 6/250, Loss: 0.0306\n",
      "Epoch 18/200, Iteration 7/250, Loss: 0.0215\n",
      "Epoch 18/200, Iteration 8/250, Loss: 0.0255\n",
      "Epoch 18/200, Iteration 9/250, Loss: 0.0257\n",
      "Epoch 18/200, Iteration 10/250, Loss: 0.0256\n",
      "Epoch 18/200, Iteration 11/250, Loss: 0.0206\n",
      "Epoch 18/200, Iteration 12/250, Loss: 0.0130\n",
      "Epoch 18/200, Iteration 13/250, Loss: 0.0195\n",
      "Epoch 18/200, Iteration 14/250, Loss: 0.0275\n",
      "Epoch 18/200, Iteration 15/250, Loss: 0.0283\n",
      "Epoch 18/200, Iteration 16/250, Loss: 0.0264\n",
      "Epoch 18/200, Iteration 17/250, Loss: 0.0213\n",
      "Epoch 18/200, Iteration 18/250, Loss: 0.0207\n",
      "Epoch 18/200, Iteration 19/250, Loss: 0.0166\n",
      "Epoch 18/200, Iteration 20/250, Loss: 0.0216\n",
      "Epoch 18/200, Iteration 21/250, Loss: 0.0282\n",
      "Epoch 18/200, Iteration 22/250, Loss: 0.0192\n",
      "Epoch 18/200, Iteration 23/250, Loss: 0.0303\n",
      "Epoch 18/200, Iteration 24/250, Loss: 0.0289\n",
      "Epoch 18/200, Iteration 25/250, Loss: 0.0209\n",
      "Epoch 18/200, Iteration 26/250, Loss: 0.0207\n",
      "Epoch 18/200, Iteration 27/250, Loss: 0.0283\n",
      "Epoch 18/200, Iteration 28/250, Loss: 0.0402\n",
      "Epoch 18/200, Iteration 29/250, Loss: 0.0361\n",
      "Epoch 18/200, Iteration 30/250, Loss: 0.0205\n",
      "Epoch 18/200, Iteration 31/250, Loss: 0.0203\n",
      "Epoch 18/200, Iteration 32/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 33/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 34/250, Loss: 0.0251\n",
      "Epoch 18/200, Iteration 35/250, Loss: 0.0367\n",
      "Epoch 18/200, Iteration 36/250, Loss: 0.0283\n",
      "Epoch 18/200, Iteration 37/250, Loss: 0.0284\n",
      "Epoch 18/200, Iteration 38/250, Loss: 0.0301\n",
      "Epoch 18/200, Iteration 39/250, Loss: 0.0309\n",
      "Epoch 18/200, Iteration 40/250, Loss: 0.0326\n",
      "Epoch 18/200, Iteration 41/250, Loss: 0.0423\n",
      "Epoch 18/200, Iteration 42/250, Loss: 0.0267\n",
      "Epoch 18/200, Iteration 43/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 44/250, Loss: 0.0227\n",
      "Epoch 18/200, Iteration 45/250, Loss: 0.0454\n",
      "Epoch 18/200, Iteration 46/250, Loss: 0.0300\n",
      "Epoch 18/200, Iteration 47/250, Loss: 0.0354\n",
      "Epoch 18/200, Iteration 48/250, Loss: 0.0183\n",
      "Epoch 18/200, Iteration 49/250, Loss: 0.0250\n",
      "Epoch 18/200, Iteration 50/250, Loss: 0.0353\n",
      "Epoch 18/200, Iteration 51/250, Loss: 0.0260\n",
      "Epoch 18/200, Iteration 52/250, Loss: 0.0324\n",
      "Epoch 18/200, Iteration 53/250, Loss: 0.0308\n",
      "Epoch 18/200, Iteration 54/250, Loss: 0.0290\n",
      "Epoch 18/200, Iteration 55/250, Loss: 0.0344\n",
      "Epoch 18/200, Iteration 56/250, Loss: 0.0228\n",
      "Epoch 18/200, Iteration 57/250, Loss: 0.0272\n",
      "Epoch 18/200, Iteration 58/250, Loss: 0.0194\n",
      "Epoch 18/200, Iteration 59/250, Loss: 0.0259\n",
      "Epoch 18/200, Iteration 60/250, Loss: 0.0267\n",
      "Epoch 18/200, Iteration 61/250, Loss: 0.0182\n",
      "Epoch 18/200, Iteration 62/250, Loss: 0.0294\n",
      "Epoch 18/200, Iteration 63/250, Loss: 0.0262\n",
      "Epoch 18/200, Iteration 64/250, Loss: 0.0308\n",
      "Epoch 18/200, Iteration 65/250, Loss: 0.0474\n",
      "Epoch 18/200, Iteration 66/250, Loss: 0.0310\n",
      "Epoch 18/200, Iteration 67/250, Loss: 0.0126\n",
      "Epoch 18/200, Iteration 68/250, Loss: 0.0213\n",
      "Epoch 18/200, Iteration 69/250, Loss: 0.0303\n",
      "Epoch 18/200, Iteration 70/250, Loss: 0.0217\n",
      "Epoch 18/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 18/200, Iteration 72/250, Loss: 0.0182\n",
      "Epoch 18/200, Iteration 73/250, Loss: 0.0330\n",
      "Epoch 18/200, Iteration 74/250, Loss: 0.0219\n",
      "Epoch 18/200, Iteration 75/250, Loss: 0.0200\n",
      "Epoch 18/200, Iteration 76/250, Loss: 0.0272\n",
      "Epoch 18/200, Iteration 77/250, Loss: 0.0233\n",
      "Epoch 18/200, Iteration 78/250, Loss: 0.0272\n",
      "Epoch 18/200, Iteration 79/250, Loss: 0.0464\n",
      "Epoch 18/200, Iteration 80/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 81/250, Loss: 0.0240\n",
      "Epoch 18/200, Iteration 82/250, Loss: 0.0295\n",
      "Epoch 18/200, Iteration 83/250, Loss: 0.0316\n",
      "Epoch 18/200, Iteration 84/250, Loss: 0.0364\n",
      "Epoch 18/200, Iteration 85/250, Loss: 0.0330\n",
      "Epoch 18/200, Iteration 86/250, Loss: 0.0223\n",
      "Epoch 18/200, Iteration 87/250, Loss: 0.0247\n",
      "Epoch 18/200, Iteration 88/250, Loss: 0.0316\n",
      "Epoch 18/200, Iteration 89/250, Loss: 0.0289\n",
      "Epoch 18/200, Iteration 90/250, Loss: 0.0237\n",
      "Epoch 18/200, Iteration 91/250, Loss: 0.0305\n",
      "Epoch 18/200, Iteration 92/250, Loss: 0.0397\n",
      "Epoch 18/200, Iteration 93/250, Loss: 0.0395\n",
      "Epoch 18/200, Iteration 94/250, Loss: 0.0330\n",
      "Epoch 18/200, Iteration 95/250, Loss: 0.0215\n",
      "Epoch 18/200, Iteration 96/250, Loss: 0.0327\n",
      "Epoch 18/200, Iteration 97/250, Loss: 0.0274\n",
      "Epoch 18/200, Iteration 98/250, Loss: 0.0310\n",
      "Epoch 18/200, Iteration 99/250, Loss: 0.0198\n",
      "Epoch 18/200, Iteration 100/250, Loss: 0.0139\n",
      "Epoch 18/200, Iteration 101/250, Loss: 0.0179\n",
      "Epoch 18/200, Iteration 102/250, Loss: 0.0200\n",
      "Epoch 18/200, Iteration 103/250, Loss: 0.0310\n",
      "Epoch 18/200, Iteration 104/250, Loss: 0.0216\n",
      "Epoch 18/200, Iteration 105/250, Loss: 0.0342\n",
      "Epoch 18/200, Iteration 106/250, Loss: 0.0242\n",
      "Epoch 18/200, Iteration 107/250, Loss: 0.0249\n",
      "Epoch 18/200, Iteration 108/250, Loss: 0.0281\n",
      "Epoch 18/200, Iteration 109/250, Loss: 0.0245\n",
      "Epoch 18/200, Iteration 110/250, Loss: 0.0169\n",
      "Epoch 18/200, Iteration 111/250, Loss: 0.0300\n",
      "Epoch 18/200, Iteration 112/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 113/250, Loss: 0.0306\n",
      "Epoch 18/200, Iteration 114/250, Loss: 0.0214\n",
      "Epoch 18/200, Iteration 115/250, Loss: 0.0381\n",
      "Epoch 18/200, Iteration 116/250, Loss: 0.0200\n",
      "Epoch 18/200, Iteration 117/250, Loss: 0.0210\n",
      "Epoch 18/200, Iteration 118/250, Loss: 0.0193\n",
      "Epoch 18/200, Iteration 119/250, Loss: 0.0201\n",
      "Epoch 18/200, Iteration 120/250, Loss: 0.0160\n",
      "Epoch 18/200, Iteration 121/250, Loss: 0.0189\n",
      "Epoch 18/200, Iteration 122/250, Loss: 0.0282\n",
      "Epoch 18/200, Iteration 123/250, Loss: 0.0245\n",
      "Epoch 18/200, Iteration 124/250, Loss: 0.0201\n",
      "Epoch 18/200, Iteration 125/250, Loss: 0.0281\n",
      "Epoch 18/200, Iteration 126/250, Loss: 0.0181\n",
      "Epoch 18/200, Iteration 127/250, Loss: 0.0124\n",
      "Epoch 18/200, Iteration 128/250, Loss: 0.0247\n",
      "Epoch 18/200, Iteration 129/250, Loss: 0.0231\n",
      "Epoch 18/200, Iteration 130/250, Loss: 0.0217\n",
      "Epoch 18/200, Iteration 131/250, Loss: 0.0490\n",
      "Epoch 18/200, Iteration 132/250, Loss: 0.0350\n",
      "Epoch 18/200, Iteration 133/250, Loss: 0.0238\n",
      "Epoch 18/200, Iteration 134/250, Loss: 0.0182\n",
      "Epoch 18/200, Iteration 135/250, Loss: 0.0324\n",
      "Epoch 18/200, Iteration 136/250, Loss: 0.0201\n",
      "Epoch 18/200, Iteration 137/250, Loss: 0.0333\n",
      "Epoch 18/200, Iteration 138/250, Loss: 0.0336\n",
      "Epoch 18/200, Iteration 139/250, Loss: 0.0226\n",
      "Epoch 18/200, Iteration 140/250, Loss: 0.0240\n",
      "Epoch 18/200, Iteration 141/250, Loss: 0.0331\n",
      "Epoch 18/200, Iteration 142/250, Loss: 0.0193\n",
      "Epoch 18/200, Iteration 143/250, Loss: 0.0237\n",
      "Epoch 18/200, Iteration 144/250, Loss: 0.0193\n",
      "Epoch 18/200, Iteration 145/250, Loss: 0.0342\n",
      "Epoch 18/200, Iteration 146/250, Loss: 0.0358\n",
      "Epoch 18/200, Iteration 147/250, Loss: 0.0321\n",
      "Epoch 18/200, Iteration 148/250, Loss: 0.0178\n",
      "Epoch 18/200, Iteration 149/250, Loss: 0.0304\n",
      "Epoch 18/200, Iteration 150/250, Loss: 0.0266\n",
      "Epoch 18/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 18/200, Iteration 152/250, Loss: 0.0379\n",
      "Epoch 18/200, Iteration 153/250, Loss: 0.0187\n",
      "Epoch 18/200, Iteration 154/250, Loss: 0.0337\n",
      "Epoch 18/200, Iteration 155/250, Loss: 0.0282\n",
      "Epoch 18/200, Iteration 156/250, Loss: 0.0157\n",
      "Epoch 18/200, Iteration 157/250, Loss: 0.0237\n",
      "Epoch 18/200, Iteration 158/250, Loss: 0.0119\n",
      "Epoch 18/200, Iteration 159/250, Loss: 0.0258\n",
      "Epoch 18/200, Iteration 160/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 161/250, Loss: 0.0251\n",
      "Epoch 18/200, Iteration 162/250, Loss: 0.0226\n",
      "Epoch 18/200, Iteration 163/250, Loss: 0.0365\n",
      "Epoch 18/200, Iteration 164/250, Loss: 0.0321\n",
      "Epoch 18/200, Iteration 165/250, Loss: 0.0339\n",
      "Epoch 18/200, Iteration 166/250, Loss: 0.0277\n",
      "Epoch 18/200, Iteration 167/250, Loss: 0.0235\n",
      "Epoch 18/200, Iteration 168/250, Loss: 0.0299\n",
      "Epoch 18/200, Iteration 169/250, Loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Iteration 170/250, Loss: 0.0230\n",
      "Epoch 18/200, Iteration 171/250, Loss: 0.0204\n",
      "Epoch 18/200, Iteration 172/250, Loss: 0.0169\n",
      "Epoch 18/200, Iteration 173/250, Loss: 0.0497\n",
      "Epoch 18/200, Iteration 174/250, Loss: 0.0290\n",
      "Epoch 18/200, Iteration 175/250, Loss: 0.0179\n",
      "Epoch 18/200, Iteration 176/250, Loss: 0.0184\n",
      "Epoch 18/200, Iteration 177/250, Loss: 0.0212\n",
      "Epoch 18/200, Iteration 178/250, Loss: 0.0215\n",
      "Epoch 18/200, Iteration 179/250, Loss: 0.0274\n",
      "Epoch 18/200, Iteration 180/250, Loss: 0.0129\n",
      "Epoch 18/200, Iteration 181/250, Loss: 0.0224\n",
      "Epoch 18/200, Iteration 182/250, Loss: 0.0256\n",
      "Epoch 18/200, Iteration 183/250, Loss: 0.0196\n",
      "Epoch 18/200, Iteration 184/250, Loss: 0.0162\n",
      "Epoch 18/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 18/200, Iteration 186/250, Loss: 0.0160\n",
      "Epoch 18/200, Iteration 187/250, Loss: 0.0224\n",
      "Epoch 18/200, Iteration 188/250, Loss: 0.0359\n",
      "Epoch 18/200, Iteration 189/250, Loss: 0.0254\n",
      "Epoch 18/200, Iteration 190/250, Loss: 0.0262\n",
      "Epoch 18/200, Iteration 191/250, Loss: 0.0231\n",
      "Epoch 18/200, Iteration 192/250, Loss: 0.0184\n",
      "Epoch 18/200, Iteration 193/250, Loss: 0.0273\n",
      "Epoch 18/200, Iteration 194/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 195/250, Loss: 0.0230\n",
      "Epoch 18/200, Iteration 196/250, Loss: 0.0425\n",
      "Epoch 18/200, Iteration 197/250, Loss: 0.0250\n",
      "Epoch 18/200, Iteration 198/250, Loss: 0.0148\n",
      "Epoch 18/200, Iteration 199/250, Loss: 0.0281\n",
      "Epoch 18/200, Iteration 200/250, Loss: 0.0273\n",
      "Epoch 18/200, Iteration 201/250, Loss: 0.0398\n",
      "Epoch 18/200, Iteration 202/250, Loss: 0.0337\n",
      "Epoch 18/200, Iteration 203/250, Loss: 0.0352\n",
      "Epoch 18/200, Iteration 204/250, Loss: 0.0180\n",
      "Epoch 18/200, Iteration 205/250, Loss: 0.0209\n",
      "Epoch 18/200, Iteration 206/250, Loss: 0.0325\n",
      "Epoch 18/200, Iteration 207/250, Loss: 0.0272\n",
      "Epoch 18/200, Iteration 208/250, Loss: 0.0269\n",
      "Epoch 18/200, Iteration 209/250, Loss: 0.0255\n",
      "Epoch 18/200, Iteration 210/250, Loss: 0.0256\n",
      "Epoch 18/200, Iteration 211/250, Loss: 0.0329\n",
      "Epoch 18/200, Iteration 212/250, Loss: 0.0329\n",
      "Epoch 18/200, Iteration 213/250, Loss: 0.0325\n",
      "Epoch 18/200, Iteration 214/250, Loss: 0.0219\n",
      "Epoch 18/200, Iteration 215/250, Loss: 0.0233\n",
      "Epoch 18/200, Iteration 216/250, Loss: 0.0191\n",
      "Epoch 18/200, Iteration 217/250, Loss: 0.0281\n",
      "Epoch 18/200, Iteration 218/250, Loss: 0.0218\n",
      "Epoch 18/200, Iteration 219/250, Loss: 0.0275\n",
      "Epoch 18/200, Iteration 220/250, Loss: 0.0384\n",
      "Epoch 18/200, Iteration 221/250, Loss: 0.0232\n",
      "Epoch 18/200, Iteration 222/250, Loss: 0.0199\n",
      "Epoch 18/200, Iteration 223/250, Loss: 0.0181\n",
      "Epoch 18/200, Iteration 224/250, Loss: 0.0385\n",
      "Epoch 18/200, Iteration 225/250, Loss: 0.0158\n",
      "Epoch 18/200, Iteration 226/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 227/250, Loss: 0.0223\n",
      "Epoch 18/200, Iteration 228/250, Loss: 0.0323\n",
      "Epoch 18/200, Iteration 229/250, Loss: 0.0220\n",
      "Epoch 18/200, Iteration 230/250, Loss: 0.0205\n",
      "Epoch 18/200, Iteration 231/250, Loss: 0.0221\n",
      "Epoch 18/200, Iteration 232/250, Loss: 0.0202\n",
      "Epoch 18/200, Iteration 233/250, Loss: 0.0224\n",
      "Epoch 18/200, Iteration 234/250, Loss: 0.0145\n",
      "Epoch 18/200, Iteration 235/250, Loss: 0.0214\n",
      "Epoch 18/200, Iteration 236/250, Loss: 0.0204\n",
      "Epoch 18/200, Iteration 237/250, Loss: 0.0244\n",
      "Epoch 18/200, Iteration 238/250, Loss: 0.0265\n",
      "Epoch 18/200, Iteration 239/250, Loss: 0.0190\n",
      "Epoch 18/200, Iteration 240/250, Loss: 0.0376\n",
      "Epoch 18/200, Iteration 241/250, Loss: 0.0315\n",
      "Epoch 18/200, Iteration 242/250, Loss: 0.0409\n",
      "Epoch 18/200, Iteration 243/250, Loss: 0.0246\n",
      "Epoch 18/200, Iteration 244/250, Loss: 0.0409\n",
      "Epoch 18/200, Iteration 245/250, Loss: 0.0370\n",
      "Epoch 18/200, Iteration 246/250, Loss: 0.0397\n",
      "Epoch 18/200, Iteration 247/250, Loss: 0.0289\n",
      "Epoch 18/200, Iteration 248/250, Loss: 0.0387\n",
      "Epoch 18/200, Iteration 249/250, Loss: 0.0300\n",
      "Epoch 18/200, Iteration 250/250, Loss: 0.0175\n",
      "Train Error: \n",
      " Accuracy: 55.2%, Avg loss: 0.024863, MRE: 1.757024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 0.025191, MRE: 1.627267 \n",
      "\n",
      "Epoch 19/200, Iteration 1/250, Loss: 0.0288\n",
      "Epoch 19/200, Iteration 2/250, Loss: 0.0445\n",
      "Epoch 19/200, Iteration 3/250, Loss: 0.0421\n",
      "Epoch 19/200, Iteration 4/250, Loss: 0.0419\n",
      "Epoch 19/200, Iteration 5/250, Loss: 0.0222\n",
      "Epoch 19/200, Iteration 6/250, Loss: 0.0255\n",
      "Epoch 19/200, Iteration 7/250, Loss: 0.0455\n",
      "Epoch 19/200, Iteration 8/250, Loss: 0.0340\n",
      "Epoch 19/200, Iteration 9/250, Loss: 0.0332\n",
      "Epoch 19/200, Iteration 10/250, Loss: 0.0183\n",
      "Epoch 19/200, Iteration 11/250, Loss: 0.0240\n",
      "Epoch 19/200, Iteration 12/250, Loss: 0.0375\n",
      "Epoch 19/200, Iteration 13/250, Loss: 0.0421\n",
      "Epoch 19/200, Iteration 14/250, Loss: 0.0316\n",
      "Epoch 19/200, Iteration 15/250, Loss: 0.0168\n",
      "Epoch 19/200, Iteration 16/250, Loss: 0.0205\n",
      "Epoch 19/200, Iteration 17/250, Loss: 0.0322\n",
      "Epoch 19/200, Iteration 18/250, Loss: 0.0456\n",
      "Epoch 19/200, Iteration 19/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 20/250, Loss: 0.0176\n",
      "Epoch 19/200, Iteration 21/250, Loss: 0.0363\n",
      "Epoch 19/200, Iteration 22/250, Loss: 0.0380\n",
      "Epoch 19/200, Iteration 23/250, Loss: 0.0291\n",
      "Epoch 19/200, Iteration 24/250, Loss: 0.0233\n",
      "Epoch 19/200, Iteration 25/250, Loss: 0.0147\n",
      "Epoch 19/200, Iteration 26/250, Loss: 0.0198\n",
      "Epoch 19/200, Iteration 27/250, Loss: 0.0313\n",
      "Epoch 19/200, Iteration 28/250, Loss: 0.0334\n",
      "Epoch 19/200, Iteration 29/250, Loss: 0.0270\n",
      "Epoch 19/200, Iteration 30/250, Loss: 0.0167\n",
      "Epoch 19/200, Iteration 31/250, Loss: 0.0307\n",
      "Epoch 19/200, Iteration 32/250, Loss: 0.0325\n",
      "Epoch 19/200, Iteration 33/250, Loss: 0.0330\n",
      "Epoch 19/200, Iteration 34/250, Loss: 0.0390\n",
      "Epoch 19/200, Iteration 35/250, Loss: 0.0214\n",
      "Epoch 19/200, Iteration 36/250, Loss: 0.0159\n",
      "Epoch 19/200, Iteration 37/250, Loss: 0.0185\n",
      "Epoch 19/200, Iteration 38/250, Loss: 0.0206\n",
      "Epoch 19/200, Iteration 39/250, Loss: 0.0345\n",
      "Epoch 19/200, Iteration 40/250, Loss: 0.0219\n",
      "Epoch 19/200, Iteration 41/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 42/250, Loss: 0.0356\n",
      "Epoch 19/200, Iteration 43/250, Loss: 0.0301\n",
      "Epoch 19/200, Iteration 44/250, Loss: 0.0281\n",
      "Epoch 19/200, Iteration 45/250, Loss: 0.0217\n",
      "Epoch 19/200, Iteration 46/250, Loss: 0.0155\n",
      "Epoch 19/200, Iteration 47/250, Loss: 0.0330\n",
      "Epoch 19/200, Iteration 48/250, Loss: 0.0394\n",
      "Epoch 19/200, Iteration 49/250, Loss: 0.0313\n",
      "Epoch 19/200, Iteration 50/250, Loss: 0.0270\n",
      "Epoch 19/200, Iteration 51/250, Loss: 0.0327\n",
      "Epoch 19/200, Iteration 52/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 53/250, Loss: 0.0284\n",
      "Epoch 19/200, Iteration 54/250, Loss: 0.0286\n",
      "Epoch 19/200, Iteration 55/250, Loss: 0.0222\n",
      "Epoch 19/200, Iteration 56/250, Loss: 0.0151\n",
      "Epoch 19/200, Iteration 57/250, Loss: 0.0298\n",
      "Epoch 19/200, Iteration 58/250, Loss: 0.0283\n",
      "Epoch 19/200, Iteration 59/250, Loss: 0.0334\n",
      "Epoch 19/200, Iteration 60/250, Loss: 0.0305\n",
      "Epoch 19/200, Iteration 61/250, Loss: 0.0209\n",
      "Epoch 19/200, Iteration 62/250, Loss: 0.0287\n",
      "Epoch 19/200, Iteration 63/250, Loss: 0.0288\n",
      "Epoch 19/200, Iteration 64/250, Loss: 0.0344\n",
      "Epoch 19/200, Iteration 65/250, Loss: 0.0201\n",
      "Epoch 19/200, Iteration 66/250, Loss: 0.0217\n",
      "Epoch 19/200, Iteration 67/250, Loss: 0.0222\n",
      "Epoch 19/200, Iteration 68/250, Loss: 0.0486\n",
      "Epoch 19/200, Iteration 69/250, Loss: 0.0228\n",
      "Epoch 19/200, Iteration 70/250, Loss: 0.0226\n",
      "Epoch 19/200, Iteration 71/250, Loss: 0.0245\n",
      "Epoch 19/200, Iteration 72/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 73/250, Loss: 0.0290\n",
      "Epoch 19/200, Iteration 74/250, Loss: 0.0207\n",
      "Epoch 19/200, Iteration 75/250, Loss: 0.0296\n",
      "Epoch 19/200, Iteration 76/250, Loss: 0.0234\n",
      "Epoch 19/200, Iteration 77/250, Loss: 0.0523\n",
      "Epoch 19/200, Iteration 78/250, Loss: 0.0332\n",
      "Epoch 19/200, Iteration 79/250, Loss: 0.0351\n",
      "Epoch 19/200, Iteration 80/250, Loss: 0.0355\n",
      "Epoch 19/200, Iteration 81/250, Loss: 0.0345\n",
      "Epoch 19/200, Iteration 82/250, Loss: 0.0291\n",
      "Epoch 19/200, Iteration 83/250, Loss: 0.0263\n",
      "Epoch 19/200, Iteration 84/250, Loss: 0.0407\n",
      "Epoch 19/200, Iteration 85/250, Loss: 0.0265\n",
      "Epoch 19/200, Iteration 86/250, Loss: 0.0240\n",
      "Epoch 19/200, Iteration 87/250, Loss: 0.0191\n",
      "Epoch 19/200, Iteration 88/250, Loss: 0.0315\n",
      "Epoch 19/200, Iteration 89/250, Loss: 0.0292\n",
      "Epoch 19/200, Iteration 90/250, Loss: 0.0365\n",
      "Epoch 19/200, Iteration 91/250, Loss: 0.0327\n",
      "Epoch 19/200, Iteration 92/250, Loss: 0.0310\n",
      "Epoch 19/200, Iteration 93/250, Loss: 0.0276\n",
      "Epoch 19/200, Iteration 94/250, Loss: 0.0372\n",
      "Epoch 19/200, Iteration 95/250, Loss: 0.0330\n",
      "Epoch 19/200, Iteration 96/250, Loss: 0.0259\n",
      "Epoch 19/200, Iteration 97/250, Loss: 0.0322\n",
      "Epoch 19/200, Iteration 98/250, Loss: 0.0435\n",
      "Epoch 19/200, Iteration 99/250, Loss: 0.0414\n",
      "Epoch 19/200, Iteration 100/250, Loss: 0.0388\n",
      "Epoch 19/200, Iteration 101/250, Loss: 0.0186\n",
      "Epoch 19/200, Iteration 102/250, Loss: 0.0258\n",
      "Epoch 19/200, Iteration 103/250, Loss: 0.0323\n",
      "Epoch 19/200, Iteration 104/250, Loss: 0.0276\n",
      "Epoch 19/200, Iteration 105/250, Loss: 0.0375\n",
      "Epoch 19/200, Iteration 106/250, Loss: 0.0340\n",
      "Epoch 19/200, Iteration 107/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 108/250, Loss: 0.0228\n",
      "Epoch 19/200, Iteration 109/250, Loss: 0.0254\n",
      "Epoch 19/200, Iteration 110/250, Loss: 0.0148\n",
      "Epoch 19/200, Iteration 111/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 112/250, Loss: 0.0171\n",
      "Epoch 19/200, Iteration 113/250, Loss: 0.0255\n",
      "Epoch 19/200, Iteration 114/250, Loss: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Iteration 115/250, Loss: 0.0247\n",
      "Epoch 19/200, Iteration 116/250, Loss: 0.0177\n",
      "Epoch 19/200, Iteration 117/250, Loss: 0.0187\n",
      "Epoch 19/200, Iteration 118/250, Loss: 0.0158\n",
      "Epoch 19/200, Iteration 119/250, Loss: 0.0171\n",
      "Epoch 19/200, Iteration 120/250, Loss: 0.0179\n",
      "Epoch 19/200, Iteration 121/250, Loss: 0.0243\n",
      "Epoch 19/200, Iteration 122/250, Loss: 0.0407\n",
      "Epoch 19/200, Iteration 123/250, Loss: 0.0187\n",
      "Epoch 19/200, Iteration 124/250, Loss: 0.0155\n",
      "Epoch 19/200, Iteration 125/250, Loss: 0.0154\n",
      "Epoch 19/200, Iteration 126/250, Loss: 0.0174\n",
      "Epoch 19/200, Iteration 127/250, Loss: 0.0276\n",
      "Epoch 19/200, Iteration 128/250, Loss: 0.0221\n",
      "Epoch 19/200, Iteration 129/250, Loss: 0.0315\n",
      "Epoch 19/200, Iteration 130/250, Loss: 0.0124\n",
      "Epoch 19/200, Iteration 131/250, Loss: 0.0144\n",
      "Epoch 19/200, Iteration 132/250, Loss: 0.0251\n",
      "Epoch 19/200, Iteration 133/250, Loss: 0.0248\n",
      "Epoch 19/200, Iteration 134/250, Loss: 0.0239\n",
      "Epoch 19/200, Iteration 135/250, Loss: 0.0226\n",
      "Epoch 19/200, Iteration 136/250, Loss: 0.0288\n",
      "Epoch 19/200, Iteration 137/250, Loss: 0.0257\n",
      "Epoch 19/200, Iteration 138/250, Loss: 0.0261\n",
      "Epoch 19/200, Iteration 139/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 140/250, Loss: 0.0236\n",
      "Epoch 19/200, Iteration 141/250, Loss: 0.0421\n",
      "Epoch 19/200, Iteration 142/250, Loss: 0.0280\n",
      "Epoch 19/200, Iteration 143/250, Loss: 0.0287\n",
      "Epoch 19/200, Iteration 144/250, Loss: 0.0181\n",
      "Epoch 19/200, Iteration 145/250, Loss: 0.0297\n",
      "Epoch 19/200, Iteration 146/250, Loss: 0.0304\n",
      "Epoch 19/200, Iteration 147/250, Loss: 0.0251\n",
      "Epoch 19/200, Iteration 148/250, Loss: 0.0237\n",
      "Epoch 19/200, Iteration 149/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 150/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 151/250, Loss: 0.0382\n",
      "Epoch 19/200, Iteration 152/250, Loss: 0.0264\n",
      "Epoch 19/200, Iteration 153/250, Loss: 0.0161\n",
      "Epoch 19/200, Iteration 154/250, Loss: 0.0393\n",
      "Epoch 19/200, Iteration 155/250, Loss: 0.0191\n",
      "Epoch 19/200, Iteration 156/250, Loss: 0.0139\n",
      "Epoch 19/200, Iteration 157/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 158/250, Loss: 0.0248\n",
      "Epoch 19/200, Iteration 159/250, Loss: 0.0219\n",
      "Epoch 19/200, Iteration 160/250, Loss: 0.0237\n",
      "Epoch 19/200, Iteration 161/250, Loss: 0.0308\n",
      "Epoch 19/200, Iteration 162/250, Loss: 0.0368\n",
      "Epoch 19/200, Iteration 163/250, Loss: 0.0251\n",
      "Epoch 19/200, Iteration 164/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 165/250, Loss: 0.0231\n",
      "Epoch 19/200, Iteration 166/250, Loss: 0.0171\n",
      "Epoch 19/200, Iteration 167/250, Loss: 0.0250\n",
      "Epoch 19/200, Iteration 168/250, Loss: 0.0298\n",
      "Epoch 19/200, Iteration 169/250, Loss: 0.0317\n",
      "Epoch 19/200, Iteration 170/250, Loss: 0.0199\n",
      "Epoch 19/200, Iteration 171/250, Loss: 0.0377\n",
      "Epoch 19/200, Iteration 172/250, Loss: 0.0238\n",
      "Epoch 19/200, Iteration 173/250, Loss: 0.0313\n",
      "Epoch 19/200, Iteration 174/250, Loss: 0.0307\n",
      "Epoch 19/200, Iteration 175/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 176/250, Loss: 0.0465\n",
      "Epoch 19/200, Iteration 177/250, Loss: 0.0385\n",
      "Epoch 19/200, Iteration 178/250, Loss: 0.0337\n",
      "Epoch 19/200, Iteration 179/250, Loss: 0.0272\n",
      "Epoch 19/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 19/200, Iteration 181/250, Loss: 0.0256\n",
      "Epoch 19/200, Iteration 182/250, Loss: 0.0273\n",
      "Epoch 19/200, Iteration 183/250, Loss: 0.0161\n",
      "Epoch 19/200, Iteration 184/250, Loss: 0.0181\n",
      "Epoch 19/200, Iteration 185/250, Loss: 0.0267\n",
      "Epoch 19/200, Iteration 186/250, Loss: 0.0259\n",
      "Epoch 19/200, Iteration 187/250, Loss: 0.0302\n",
      "Epoch 19/200, Iteration 188/250, Loss: 0.0171\n",
      "Epoch 19/200, Iteration 189/250, Loss: 0.0187\n",
      "Epoch 19/200, Iteration 190/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 191/250, Loss: 0.0214\n",
      "Epoch 19/200, Iteration 192/250, Loss: 0.0231\n",
      "Epoch 19/200, Iteration 193/250, Loss: 0.0141\n",
      "Epoch 19/200, Iteration 194/250, Loss: 0.0194\n",
      "Epoch 19/200, Iteration 195/250, Loss: 0.0288\n",
      "Epoch 19/200, Iteration 196/250, Loss: 0.0312\n",
      "Epoch 19/200, Iteration 197/250, Loss: 0.0208\n",
      "Epoch 19/200, Iteration 198/250, Loss: 0.0290\n",
      "Epoch 19/200, Iteration 199/250, Loss: 0.0387\n",
      "Epoch 19/200, Iteration 200/250, Loss: 0.0444\n",
      "Epoch 19/200, Iteration 201/250, Loss: 0.0185\n",
      "Epoch 19/200, Iteration 202/250, Loss: 0.0289\n",
      "Epoch 19/200, Iteration 203/250, Loss: 0.0176\n",
      "Epoch 19/200, Iteration 204/250, Loss: 0.0284\n",
      "Epoch 19/200, Iteration 205/250, Loss: 0.0427\n",
      "Epoch 19/200, Iteration 206/250, Loss: 0.0193\n",
      "Epoch 19/200, Iteration 207/250, Loss: 0.0213\n",
      "Epoch 19/200, Iteration 208/250, Loss: 0.0285\n",
      "Epoch 19/200, Iteration 209/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 210/250, Loss: 0.0263\n",
      "Epoch 19/200, Iteration 211/250, Loss: 0.0206\n",
      "Epoch 19/200, Iteration 212/250, Loss: 0.0334\n",
      "Epoch 19/200, Iteration 213/250, Loss: 0.0232\n",
      "Epoch 19/200, Iteration 214/250, Loss: 0.0225\n",
      "Epoch 19/200, Iteration 215/250, Loss: 0.0218\n",
      "Epoch 19/200, Iteration 216/250, Loss: 0.0200\n",
      "Epoch 19/200, Iteration 217/250, Loss: 0.0182\n",
      "Epoch 19/200, Iteration 218/250, Loss: 0.0149\n",
      "Epoch 19/200, Iteration 219/250, Loss: 0.0223\n",
      "Epoch 19/200, Iteration 220/250, Loss: 0.0196\n",
      "Epoch 19/200, Iteration 221/250, Loss: 0.0200\n",
      "Epoch 19/200, Iteration 222/250, Loss: 0.0180\n",
      "Epoch 19/200, Iteration 223/250, Loss: 0.0225\n",
      "Epoch 19/200, Iteration 224/250, Loss: 0.0294\n",
      "Epoch 19/200, Iteration 225/250, Loss: 0.0257\n",
      "Epoch 19/200, Iteration 226/250, Loss: 0.0169\n",
      "Epoch 19/200, Iteration 227/250, Loss: 0.0266\n",
      "Epoch 19/200, Iteration 228/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 229/250, Loss: 0.0172\n",
      "Epoch 19/200, Iteration 230/250, Loss: 0.0290\n",
      "Epoch 19/200, Iteration 231/250, Loss: 0.0277\n",
      "Epoch 19/200, Iteration 232/250, Loss: 0.0252\n",
      "Epoch 19/200, Iteration 233/250, Loss: 0.0170\n",
      "Epoch 19/200, Iteration 234/250, Loss: 0.0193\n",
      "Epoch 19/200, Iteration 235/250, Loss: 0.0317\n",
      "Epoch 19/200, Iteration 236/250, Loss: 0.0195\n",
      "Epoch 19/200, Iteration 237/250, Loss: 0.0172\n",
      "Epoch 19/200, Iteration 238/250, Loss: 0.0159\n",
      "Epoch 19/200, Iteration 239/250, Loss: 0.0285\n",
      "Epoch 19/200, Iteration 240/250, Loss: 0.0237\n",
      "Epoch 19/200, Iteration 241/250, Loss: 0.0188\n",
      "Epoch 19/200, Iteration 242/250, Loss: 0.0199\n",
      "Epoch 19/200, Iteration 243/250, Loss: 0.0287\n",
      "Epoch 19/200, Iteration 244/250, Loss: 0.0269\n",
      "Epoch 19/200, Iteration 245/250, Loss: 0.0190\n",
      "Epoch 19/200, Iteration 246/250, Loss: 0.0189\n",
      "Epoch 19/200, Iteration 247/250, Loss: 0.0301\n",
      "Epoch 19/200, Iteration 248/250, Loss: 0.0206\n",
      "Epoch 19/200, Iteration 249/250, Loss: 0.0248\n",
      "Epoch 19/200, Iteration 250/250, Loss: 0.0256\n",
      "Train Error: \n",
      " Accuracy: 76.45%, Avg loss: 0.020504, MRE: 1.308345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.15%, Avg loss: 0.021117, MRE: 3.357780 \n",
      "\n",
      "Epoch 20/200, Iteration 1/250, Loss: 0.0454\n",
      "Epoch 20/200, Iteration 2/250, Loss: 0.0186\n",
      "Epoch 20/200, Iteration 3/250, Loss: 0.0170\n",
      "Epoch 20/200, Iteration 4/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 5/250, Loss: 0.0203\n",
      "Epoch 20/200, Iteration 6/250, Loss: 0.0354\n",
      "Epoch 20/200, Iteration 7/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 8/250, Loss: 0.0346\n",
      "Epoch 20/200, Iteration 9/250, Loss: 0.0225\n",
      "Epoch 20/200, Iteration 10/250, Loss: 0.0331\n",
      "Epoch 20/200, Iteration 11/250, Loss: 0.0276\n",
      "Epoch 20/200, Iteration 12/250, Loss: 0.0277\n",
      "Epoch 20/200, Iteration 13/250, Loss: 0.0215\n",
      "Epoch 20/200, Iteration 14/250, Loss: 0.0255\n",
      "Epoch 20/200, Iteration 15/250, Loss: 0.0182\n",
      "Epoch 20/200, Iteration 16/250, Loss: 0.0314\n",
      "Epoch 20/200, Iteration 17/250, Loss: 0.0363\n",
      "Epoch 20/200, Iteration 18/250, Loss: 0.0405\n",
      "Epoch 20/200, Iteration 19/250, Loss: 0.0293\n",
      "Epoch 20/200, Iteration 20/250, Loss: 0.0381\n",
      "Epoch 20/200, Iteration 21/250, Loss: 0.0208\n",
      "Epoch 20/200, Iteration 22/250, Loss: 0.0188\n",
      "Epoch 20/200, Iteration 23/250, Loss: 0.0316\n",
      "Epoch 20/200, Iteration 24/250, Loss: 0.0191\n",
      "Epoch 20/200, Iteration 25/250, Loss: 0.0388\n",
      "Epoch 20/200, Iteration 26/250, Loss: 0.0181\n",
      "Epoch 20/200, Iteration 27/250, Loss: 0.0453\n",
      "Epoch 20/200, Iteration 28/250, Loss: 0.0361\n",
      "Epoch 20/200, Iteration 29/250, Loss: 0.0478\n",
      "Epoch 20/200, Iteration 30/250, Loss: 0.0171\n",
      "Epoch 20/200, Iteration 31/250, Loss: 0.0229\n",
      "Epoch 20/200, Iteration 32/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 33/250, Loss: 0.0399\n",
      "Epoch 20/200, Iteration 34/250, Loss: 0.0204\n",
      "Epoch 20/200, Iteration 35/250, Loss: 0.0255\n",
      "Epoch 20/200, Iteration 36/250, Loss: 0.0176\n",
      "Epoch 20/200, Iteration 37/250, Loss: 0.0317\n",
      "Epoch 20/200, Iteration 38/250, Loss: 0.0207\n",
      "Epoch 20/200, Iteration 39/250, Loss: 0.0258\n",
      "Epoch 20/200, Iteration 40/250, Loss: 0.0319\n",
      "Epoch 20/200, Iteration 41/250, Loss: 0.0244\n",
      "Epoch 20/200, Iteration 42/250, Loss: 0.0219\n",
      "Epoch 20/200, Iteration 43/250, Loss: 0.0190\n",
      "Epoch 20/200, Iteration 44/250, Loss: 0.0280\n",
      "Epoch 20/200, Iteration 45/250, Loss: 0.0389\n",
      "Epoch 20/200, Iteration 46/250, Loss: 0.0168\n",
      "Epoch 20/200, Iteration 47/250, Loss: 0.0160\n",
      "Epoch 20/200, Iteration 48/250, Loss: 0.0207\n",
      "Epoch 20/200, Iteration 49/250, Loss: 0.0208\n",
      "Epoch 20/200, Iteration 50/250, Loss: 0.0156\n",
      "Epoch 20/200, Iteration 51/250, Loss: 0.0375\n",
      "Epoch 20/200, Iteration 52/250, Loss: 0.0252\n",
      "Epoch 20/200, Iteration 53/250, Loss: 0.0170\n",
      "Epoch 20/200, Iteration 54/250, Loss: 0.0291\n",
      "Epoch 20/200, Iteration 55/250, Loss: 0.0182\n",
      "Epoch 20/200, Iteration 56/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 57/250, Loss: 0.0171\n",
      "Epoch 20/200, Iteration 58/250, Loss: 0.0211\n",
      "Epoch 20/200, Iteration 59/250, Loss: 0.0183\n",
      "Epoch 20/200, Iteration 60/250, Loss: 0.0431\n",
      "Epoch 20/200, Iteration 61/250, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Iteration 62/250, Loss: 0.0423\n",
      "Epoch 20/200, Iteration 63/250, Loss: 0.0438\n",
      "Epoch 20/200, Iteration 64/250, Loss: 0.0363\n",
      "Epoch 20/200, Iteration 65/250, Loss: 0.0195\n",
      "Epoch 20/200, Iteration 66/250, Loss: 0.0330\n",
      "Epoch 20/200, Iteration 67/250, Loss: 0.0264\n",
      "Epoch 20/200, Iteration 68/250, Loss: 0.0427\n",
      "Epoch 20/200, Iteration 69/250, Loss: 0.0349\n",
      "Epoch 20/200, Iteration 70/250, Loss: 0.0256\n",
      "Epoch 20/200, Iteration 71/250, Loss: 0.0215\n",
      "Epoch 20/200, Iteration 72/250, Loss: 0.0340\n",
      "Epoch 20/200, Iteration 73/250, Loss: 0.0275\n",
      "Epoch 20/200, Iteration 74/250, Loss: 0.0205\n",
      "Epoch 20/200, Iteration 75/250, Loss: 0.0162\n",
      "Epoch 20/200, Iteration 76/250, Loss: 0.0238\n",
      "Epoch 20/200, Iteration 77/250, Loss: 0.0244\n",
      "Epoch 20/200, Iteration 78/250, Loss: 0.0201\n",
      "Epoch 20/200, Iteration 79/250, Loss: 0.0137\n",
      "Epoch 20/200, Iteration 80/250, Loss: 0.0194\n",
      "Epoch 20/200, Iteration 81/250, Loss: 0.0230\n",
      "Epoch 20/200, Iteration 82/250, Loss: 0.0151\n",
      "Epoch 20/200, Iteration 83/250, Loss: 0.0235\n",
      "Epoch 20/200, Iteration 84/250, Loss: 0.0180\n",
      "Epoch 20/200, Iteration 85/250, Loss: 0.0197\n",
      "Epoch 20/200, Iteration 86/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 87/250, Loss: 0.0255\n",
      "Epoch 20/200, Iteration 88/250, Loss: 0.0289\n",
      "Epoch 20/200, Iteration 89/250, Loss: 0.0364\n",
      "Epoch 20/200, Iteration 90/250, Loss: 0.0221\n",
      "Epoch 20/200, Iteration 91/250, Loss: 0.0197\n",
      "Epoch 20/200, Iteration 92/250, Loss: 0.0264\n",
      "Epoch 20/200, Iteration 93/250, Loss: 0.0344\n",
      "Epoch 20/200, Iteration 94/250, Loss: 0.0259\n",
      "Epoch 20/200, Iteration 95/250, Loss: 0.0380\n",
      "Epoch 20/200, Iteration 96/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 97/250, Loss: 0.0281\n",
      "Epoch 20/200, Iteration 98/250, Loss: 0.0239\n",
      "Epoch 20/200, Iteration 99/250, Loss: 0.0260\n",
      "Epoch 20/200, Iteration 100/250, Loss: 0.0219\n",
      "Epoch 20/200, Iteration 101/250, Loss: 0.0376\n",
      "Epoch 20/200, Iteration 102/250, Loss: 0.0197\n",
      "Epoch 20/200, Iteration 103/250, Loss: 0.0237\n",
      "Epoch 20/200, Iteration 104/250, Loss: 0.0170\n",
      "Epoch 20/200, Iteration 105/250, Loss: 0.0174\n",
      "Epoch 20/200, Iteration 106/250, Loss: 0.0203\n",
      "Epoch 20/200, Iteration 107/250, Loss: 0.0174\n",
      "Epoch 20/200, Iteration 108/250, Loss: 0.0154\n",
      "Epoch 20/200, Iteration 109/250, Loss: 0.0181\n",
      "Epoch 20/200, Iteration 110/250, Loss: 0.0261\n",
      "Epoch 20/200, Iteration 111/250, Loss: 0.0365\n",
      "Epoch 20/200, Iteration 112/250, Loss: 0.0370\n",
      "Epoch 20/200, Iteration 113/250, Loss: 0.0226\n",
      "Epoch 20/200, Iteration 114/250, Loss: 0.0211\n",
      "Epoch 20/200, Iteration 115/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 116/250, Loss: 0.0204\n",
      "Epoch 20/200, Iteration 117/250, Loss: 0.0191\n",
      "Epoch 20/200, Iteration 118/250, Loss: 0.0340\n",
      "Epoch 20/200, Iteration 119/250, Loss: 0.0189\n",
      "Epoch 20/200, Iteration 120/250, Loss: 0.0220\n",
      "Epoch 20/200, Iteration 121/250, Loss: 0.0264\n",
      "Epoch 20/200, Iteration 122/250, Loss: 0.0220\n",
      "Epoch 20/200, Iteration 123/250, Loss: 0.0204\n",
      "Epoch 20/200, Iteration 124/250, Loss: 0.0151\n",
      "Epoch 20/200, Iteration 125/250, Loss: 0.0250\n",
      "Epoch 20/200, Iteration 126/250, Loss: 0.0346\n",
      "Epoch 20/200, Iteration 127/250, Loss: 0.0252\n",
      "Epoch 20/200, Iteration 128/250, Loss: 0.0204\n",
      "Epoch 20/200, Iteration 129/250, Loss: 0.0360\n",
      "Epoch 20/200, Iteration 130/250, Loss: 0.0268\n",
      "Epoch 20/200, Iteration 131/250, Loss: 0.0196\n",
      "Epoch 20/200, Iteration 132/250, Loss: 0.0187\n",
      "Epoch 20/200, Iteration 133/250, Loss: 0.0280\n",
      "Epoch 20/200, Iteration 134/250, Loss: 0.0244\n",
      "Epoch 20/200, Iteration 135/250, Loss: 0.0397\n",
      "Epoch 20/200, Iteration 136/250, Loss: 0.0230\n",
      "Epoch 20/200, Iteration 137/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 138/250, Loss: 0.0206\n",
      "Epoch 20/200, Iteration 139/250, Loss: 0.0150\n",
      "Epoch 20/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 20/200, Iteration 141/250, Loss: 0.0167\n",
      "Epoch 20/200, Iteration 142/250, Loss: 0.0206\n",
      "Epoch 20/200, Iteration 143/250, Loss: 0.0172\n",
      "Epoch 20/200, Iteration 144/250, Loss: 0.0261\n",
      "Epoch 20/200, Iteration 145/250, Loss: 0.0271\n",
      "Epoch 20/200, Iteration 146/250, Loss: 0.0266\n",
      "Epoch 20/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 148/250, Loss: 0.0175\n",
      "Epoch 20/200, Iteration 149/250, Loss: 0.0319\n",
      "Epoch 20/200, Iteration 150/250, Loss: 0.0198\n",
      "Epoch 20/200, Iteration 151/250, Loss: 0.0195\n",
      "Epoch 20/200, Iteration 152/250, Loss: 0.0158\n",
      "Epoch 20/200, Iteration 153/250, Loss: 0.0137\n",
      "Epoch 20/200, Iteration 154/250, Loss: 0.0161\n",
      "Epoch 20/200, Iteration 155/250, Loss: 0.0167\n",
      "Epoch 20/200, Iteration 156/250, Loss: 0.0217\n",
      "Epoch 20/200, Iteration 157/250, Loss: 0.0303\n",
      "Epoch 20/200, Iteration 158/250, Loss: 0.0193\n",
      "Epoch 20/200, Iteration 159/250, Loss: 0.0177\n",
      "Epoch 20/200, Iteration 160/250, Loss: 0.0200\n",
      "Epoch 20/200, Iteration 161/250, Loss: 0.0239\n",
      "Epoch 20/200, Iteration 162/250, Loss: 0.0159\n",
      "Epoch 20/200, Iteration 163/250, Loss: 0.0154\n",
      "Epoch 20/200, Iteration 164/250, Loss: 0.0281\n",
      "Epoch 20/200, Iteration 165/250, Loss: 0.0190\n",
      "Epoch 20/200, Iteration 166/250, Loss: 0.0271\n",
      "Epoch 20/200, Iteration 167/250, Loss: 0.0276\n",
      "Epoch 20/200, Iteration 168/250, Loss: 0.0337\n",
      "Epoch 20/200, Iteration 169/250, Loss: 0.0290\n",
      "Epoch 20/200, Iteration 170/250, Loss: 0.0366\n",
      "Epoch 20/200, Iteration 171/250, Loss: 0.0197\n",
      "Epoch 20/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 20/200, Iteration 173/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 174/250, Loss: 0.0261\n",
      "Epoch 20/200, Iteration 175/250, Loss: 0.0233\n",
      "Epoch 20/200, Iteration 176/250, Loss: 0.0424\n",
      "Epoch 20/200, Iteration 177/250, Loss: 0.0248\n",
      "Epoch 20/200, Iteration 178/250, Loss: 0.0225\n",
      "Epoch 20/200, Iteration 179/250, Loss: 0.0208\n",
      "Epoch 20/200, Iteration 180/250, Loss: 0.0173\n",
      "Epoch 20/200, Iteration 181/250, Loss: 0.0289\n",
      "Epoch 20/200, Iteration 182/250, Loss: 0.0298\n",
      "Epoch 20/200, Iteration 183/250, Loss: 0.0349\n",
      "Epoch 20/200, Iteration 184/250, Loss: 0.0455\n",
      "Epoch 20/200, Iteration 185/250, Loss: 0.0292\n",
      "Epoch 20/200, Iteration 186/250, Loss: 0.0307\n",
      "Epoch 20/200, Iteration 187/250, Loss: 0.0287\n",
      "Epoch 20/200, Iteration 188/250, Loss: 0.0321\n",
      "Epoch 20/200, Iteration 189/250, Loss: 0.0311\n",
      "Epoch 20/200, Iteration 190/250, Loss: 0.0384\n",
      "Epoch 20/200, Iteration 191/250, Loss: 0.0284\n",
      "Epoch 20/200, Iteration 192/250, Loss: 0.0237\n",
      "Epoch 20/200, Iteration 193/250, Loss: 0.0275\n",
      "Epoch 20/200, Iteration 194/250, Loss: 0.0290\n",
      "Epoch 20/200, Iteration 195/250, Loss: 0.0336\n",
      "Epoch 20/200, Iteration 196/250, Loss: 0.0256\n",
      "Epoch 20/200, Iteration 197/250, Loss: 0.0349\n",
      "Epoch 20/200, Iteration 198/250, Loss: 0.0304\n",
      "Epoch 20/200, Iteration 199/250, Loss: 0.0312\n",
      "Epoch 20/200, Iteration 200/250, Loss: 0.0262\n",
      "Epoch 20/200, Iteration 201/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 202/250, Loss: 0.0319\n",
      "Epoch 20/200, Iteration 203/250, Loss: 0.0331\n",
      "Epoch 20/200, Iteration 204/250, Loss: 0.0219\n",
      "Epoch 20/200, Iteration 205/250, Loss: 0.0207\n",
      "Epoch 20/200, Iteration 206/250, Loss: 0.0208\n",
      "Epoch 20/200, Iteration 207/250, Loss: 0.0381\n",
      "Epoch 20/200, Iteration 208/250, Loss: 0.0352\n",
      "Epoch 20/200, Iteration 209/250, Loss: 0.0235\n",
      "Epoch 20/200, Iteration 210/250, Loss: 0.0191\n",
      "Epoch 20/200, Iteration 211/250, Loss: 0.0257\n",
      "Epoch 20/200, Iteration 212/250, Loss: 0.0224\n",
      "Epoch 20/200, Iteration 213/250, Loss: 0.0202\n",
      "Epoch 20/200, Iteration 214/250, Loss: 0.0162\n",
      "Epoch 20/200, Iteration 215/250, Loss: 0.0145\n",
      "Epoch 20/200, Iteration 216/250, Loss: 0.0222\n",
      "Epoch 20/200, Iteration 217/250, Loss: 0.0281\n",
      "Epoch 20/200, Iteration 218/250, Loss: 0.0461\n",
      "Epoch 20/200, Iteration 219/250, Loss: 0.0218\n",
      "Epoch 20/200, Iteration 220/250, Loss: 0.0148\n",
      "Epoch 20/200, Iteration 221/250, Loss: 0.0237\n",
      "Epoch 20/200, Iteration 222/250, Loss: 0.0210\n",
      "Epoch 20/200, Iteration 223/250, Loss: 0.0222\n",
      "Epoch 20/200, Iteration 224/250, Loss: 0.0285\n",
      "Epoch 20/200, Iteration 225/250, Loss: 0.0273\n",
      "Epoch 20/200, Iteration 226/250, Loss: 0.0226\n",
      "Epoch 20/200, Iteration 227/250, Loss: 0.0262\n",
      "Epoch 20/200, Iteration 228/250, Loss: 0.0248\n",
      "Epoch 20/200, Iteration 229/250, Loss: 0.0438\n",
      "Epoch 20/200, Iteration 230/250, Loss: 0.0457\n",
      "Epoch 20/200, Iteration 231/250, Loss: 0.0276\n",
      "Epoch 20/200, Iteration 232/250, Loss: 0.0310\n",
      "Epoch 20/200, Iteration 233/250, Loss: 0.0268\n",
      "Epoch 20/200, Iteration 234/250, Loss: 0.0205\n",
      "Epoch 20/200, Iteration 235/250, Loss: 0.0144\n",
      "Epoch 20/200, Iteration 236/250, Loss: 0.0222\n",
      "Epoch 20/200, Iteration 237/250, Loss: 0.0191\n",
      "Epoch 20/200, Iteration 238/250, Loss: 0.0299\n",
      "Epoch 20/200, Iteration 239/250, Loss: 0.0308\n",
      "Epoch 20/200, Iteration 240/250, Loss: 0.0177\n",
      "Epoch 20/200, Iteration 241/250, Loss: 0.0262\n",
      "Epoch 20/200, Iteration 242/250, Loss: 0.0170\n",
      "Epoch 20/200, Iteration 243/250, Loss: 0.0571\n",
      "Epoch 20/200, Iteration 244/250, Loss: 0.0204\n",
      "Epoch 20/200, Iteration 245/250, Loss: 0.0194\n",
      "Epoch 20/200, Iteration 246/250, Loss: 0.0242\n",
      "Epoch 20/200, Iteration 247/250, Loss: 0.0257\n",
      "Epoch 20/200, Iteration 248/250, Loss: 0.0212\n",
      "Epoch 20/200, Iteration 249/250, Loss: 0.0165\n",
      "Epoch 20/200, Iteration 250/250, Loss: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 52.88%, Avg loss: 0.024167, MRE: 1.952926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.85%, Avg loss: 0.024073, MRE: 2.320547 \n",
      "\n",
      "Epoch 21/200, Iteration 1/250, Loss: 0.0294\n",
      "Epoch 21/200, Iteration 2/250, Loss: 0.0355\n",
      "Epoch 21/200, Iteration 3/250, Loss: 0.0214\n",
      "Epoch 21/200, Iteration 4/250, Loss: 0.0114\n",
      "Epoch 21/200, Iteration 5/250, Loss: 0.0176\n",
      "Epoch 21/200, Iteration 6/250, Loss: 0.0258\n",
      "Epoch 21/200, Iteration 7/250, Loss: 0.0337\n",
      "Epoch 21/200, Iteration 8/250, Loss: 0.0279\n",
      "Epoch 21/200, Iteration 9/250, Loss: 0.0203\n",
      "Epoch 21/200, Iteration 10/250, Loss: 0.0219\n",
      "Epoch 21/200, Iteration 11/250, Loss: 0.0258\n",
      "Epoch 21/200, Iteration 12/250, Loss: 0.0223\n",
      "Epoch 21/200, Iteration 13/250, Loss: 0.0202\n",
      "Epoch 21/200, Iteration 14/250, Loss: 0.0223\n",
      "Epoch 21/200, Iteration 15/250, Loss: 0.0313\n",
      "Epoch 21/200, Iteration 16/250, Loss: 0.0166\n",
      "Epoch 21/200, Iteration 17/250, Loss: 0.0212\n",
      "Epoch 21/200, Iteration 18/250, Loss: 0.0246\n",
      "Epoch 21/200, Iteration 19/250, Loss: 0.0451\n",
      "Epoch 21/200, Iteration 20/250, Loss: 0.0263\n",
      "Epoch 21/200, Iteration 21/250, Loss: 0.0295\n",
      "Epoch 21/200, Iteration 22/250, Loss: 0.0287\n",
      "Epoch 21/200, Iteration 23/250, Loss: 0.0313\n",
      "Epoch 21/200, Iteration 24/250, Loss: 0.0308\n",
      "Epoch 21/200, Iteration 25/250, Loss: 0.0237\n",
      "Epoch 21/200, Iteration 26/250, Loss: 0.0225\n",
      "Epoch 21/200, Iteration 27/250, Loss: 0.0221\n",
      "Epoch 21/200, Iteration 28/250, Loss: 0.0301\n",
      "Epoch 21/200, Iteration 29/250, Loss: 0.0230\n",
      "Epoch 21/200, Iteration 30/250, Loss: 0.0246\n",
      "Epoch 21/200, Iteration 31/250, Loss: 0.0348\n",
      "Epoch 21/200, Iteration 32/250, Loss: 0.0257\n",
      "Epoch 21/200, Iteration 33/250, Loss: 0.0266\n",
      "Epoch 21/200, Iteration 34/250, Loss: 0.0390\n",
      "Epoch 21/200, Iteration 35/250, Loss: 0.0422\n",
      "Epoch 21/200, Iteration 36/250, Loss: 0.0358\n",
      "Epoch 21/200, Iteration 37/250, Loss: 0.0424\n",
      "Epoch 21/200, Iteration 38/250, Loss: 0.0203\n",
      "Epoch 21/200, Iteration 39/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 40/250, Loss: 0.0401\n",
      "Epoch 21/200, Iteration 41/250, Loss: 0.0429\n",
      "Epoch 21/200, Iteration 42/250, Loss: 0.0325\n",
      "Epoch 21/200, Iteration 43/250, Loss: 0.0208\n",
      "Epoch 21/200, Iteration 44/250, Loss: 0.0253\n",
      "Epoch 21/200, Iteration 45/250, Loss: 0.0304\n",
      "Epoch 21/200, Iteration 46/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 47/250, Loss: 0.0213\n",
      "Epoch 21/200, Iteration 48/250, Loss: 0.0302\n",
      "Epoch 21/200, Iteration 49/250, Loss: 0.0235\n",
      "Epoch 21/200, Iteration 50/250, Loss: 0.0155\n",
      "Epoch 21/200, Iteration 51/250, Loss: 0.0229\n",
      "Epoch 21/200, Iteration 52/250, Loss: 0.0393\n",
      "Epoch 21/200, Iteration 53/250, Loss: 0.0347\n",
      "Epoch 21/200, Iteration 54/250, Loss: 0.0204\n",
      "Epoch 21/200, Iteration 55/250, Loss: 0.0277\n",
      "Epoch 21/200, Iteration 56/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 57/250, Loss: 0.0254\n",
      "Epoch 21/200, Iteration 58/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 59/250, Loss: 0.0151\n",
      "Epoch 21/200, Iteration 60/250, Loss: 0.0212\n",
      "Epoch 21/200, Iteration 61/250, Loss: 0.0185\n",
      "Epoch 21/200, Iteration 62/250, Loss: 0.0175\n",
      "Epoch 21/200, Iteration 63/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 64/250, Loss: 0.0285\n",
      "Epoch 21/200, Iteration 65/250, Loss: 0.0191\n",
      "Epoch 21/200, Iteration 66/250, Loss: 0.0240\n",
      "Epoch 21/200, Iteration 67/250, Loss: 0.0204\n",
      "Epoch 21/200, Iteration 68/250, Loss: 0.0312\n",
      "Epoch 21/200, Iteration 69/250, Loss: 0.0252\n",
      "Epoch 21/200, Iteration 70/250, Loss: 0.0273\n",
      "Epoch 21/200, Iteration 71/250, Loss: 0.0212\n",
      "Epoch 21/200, Iteration 72/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 73/250, Loss: 0.0288\n",
      "Epoch 21/200, Iteration 74/250, Loss: 0.0269\n",
      "Epoch 21/200, Iteration 75/250, Loss: 0.0252\n",
      "Epoch 21/200, Iteration 76/250, Loss: 0.0190\n",
      "Epoch 21/200, Iteration 77/250, Loss: 0.0232\n",
      "Epoch 21/200, Iteration 78/250, Loss: 0.0256\n",
      "Epoch 21/200, Iteration 79/250, Loss: 0.0331\n",
      "Epoch 21/200, Iteration 80/250, Loss: 0.0373\n",
      "Epoch 21/200, Iteration 81/250, Loss: 0.0271\n",
      "Epoch 21/200, Iteration 82/250, Loss: 0.0256\n",
      "Epoch 21/200, Iteration 83/250, Loss: 0.0448\n",
      "Epoch 21/200, Iteration 84/250, Loss: 0.0436\n",
      "Epoch 21/200, Iteration 85/250, Loss: 0.0261\n",
      "Epoch 21/200, Iteration 86/250, Loss: 0.0301\n",
      "Epoch 21/200, Iteration 87/250, Loss: 0.0468\n",
      "Epoch 21/200, Iteration 88/250, Loss: 0.0408\n",
      "Epoch 21/200, Iteration 89/250, Loss: 0.0369\n",
      "Epoch 21/200, Iteration 90/250, Loss: 0.0263\n",
      "Epoch 21/200, Iteration 91/250, Loss: 0.0238\n",
      "Epoch 21/200, Iteration 92/250, Loss: 0.0265\n",
      "Epoch 21/200, Iteration 93/250, Loss: 0.0409\n",
      "Epoch 21/200, Iteration 94/250, Loss: 0.0358\n",
      "Epoch 21/200, Iteration 95/250, Loss: 0.0234\n",
      "Epoch 21/200, Iteration 96/250, Loss: 0.0196\n",
      "Epoch 21/200, Iteration 97/250, Loss: 0.0276\n",
      "Epoch 21/200, Iteration 98/250, Loss: 0.0282\n",
      "Epoch 21/200, Iteration 99/250, Loss: 0.0294\n",
      "Epoch 21/200, Iteration 100/250, Loss: 0.0207\n",
      "Epoch 21/200, Iteration 101/250, Loss: 0.0264\n",
      "Epoch 21/200, Iteration 102/250, Loss: 0.0174\n",
      "Epoch 21/200, Iteration 103/250, Loss: 0.0238\n",
      "Epoch 21/200, Iteration 104/250, Loss: 0.0317\n",
      "Epoch 21/200, Iteration 105/250, Loss: 0.0154\n",
      "Epoch 21/200, Iteration 106/250, Loss: 0.0195\n",
      "Epoch 21/200, Iteration 107/250, Loss: 0.0221\n",
      "Epoch 21/200, Iteration 108/250, Loss: 0.0277\n",
      "Epoch 21/200, Iteration 109/250, Loss: 0.0247\n",
      "Epoch 21/200, Iteration 110/250, Loss: 0.0322\n",
      "Epoch 21/200, Iteration 111/250, Loss: 0.0232\n",
      "Epoch 21/200, Iteration 112/250, Loss: 0.0311\n",
      "Epoch 21/200, Iteration 113/250, Loss: 0.0343\n",
      "Epoch 21/200, Iteration 114/250, Loss: 0.0307\n",
      "Epoch 21/200, Iteration 115/250, Loss: 0.0359\n",
      "Epoch 21/200, Iteration 116/250, Loss: 0.0170\n",
      "Epoch 21/200, Iteration 117/250, Loss: 0.0165\n",
      "Epoch 21/200, Iteration 118/250, Loss: 0.0222\n",
      "Epoch 21/200, Iteration 119/250, Loss: 0.0255\n",
      "Epoch 21/200, Iteration 120/250, Loss: 0.0194\n",
      "Epoch 21/200, Iteration 121/250, Loss: 0.0171\n",
      "Epoch 21/200, Iteration 122/250, Loss: 0.0257\n",
      "Epoch 21/200, Iteration 123/250, Loss: 0.0326\n",
      "Epoch 21/200, Iteration 124/250, Loss: 0.0173\n",
      "Epoch 21/200, Iteration 125/250, Loss: 0.0188\n",
      "Epoch 21/200, Iteration 126/250, Loss: 0.0315\n",
      "Epoch 21/200, Iteration 127/250, Loss: 0.0179\n",
      "Epoch 21/200, Iteration 128/250, Loss: 0.0221\n",
      "Epoch 21/200, Iteration 129/250, Loss: 0.0206\n",
      "Epoch 21/200, Iteration 130/250, Loss: 0.0251\n",
      "Epoch 21/200, Iteration 131/250, Loss: 0.0216\n",
      "Epoch 21/200, Iteration 132/250, Loss: 0.0296\n",
      "Epoch 21/200, Iteration 133/250, Loss: 0.0355\n",
      "Epoch 21/200, Iteration 134/250, Loss: 0.0194\n",
      "Epoch 21/200, Iteration 135/250, Loss: 0.0264\n",
      "Epoch 21/200, Iteration 136/250, Loss: 0.0173\n",
      "Epoch 21/200, Iteration 137/250, Loss: 0.0315\n",
      "Epoch 21/200, Iteration 138/250, Loss: 0.0278\n",
      "Epoch 21/200, Iteration 139/250, Loss: 0.0244\n",
      "Epoch 21/200, Iteration 140/250, Loss: 0.0245\n",
      "Epoch 21/200, Iteration 141/250, Loss: 0.0175\n",
      "Epoch 21/200, Iteration 142/250, Loss: 0.0573\n",
      "Epoch 21/200, Iteration 143/250, Loss: 0.0372\n",
      "Epoch 21/200, Iteration 144/250, Loss: 0.0338\n",
      "Epoch 21/200, Iteration 145/250, Loss: 0.0236\n",
      "Epoch 21/200, Iteration 146/250, Loss: 0.0178\n",
      "Epoch 21/200, Iteration 147/250, Loss: 0.0169\n",
      "Epoch 21/200, Iteration 148/250, Loss: 0.0265\n",
      "Epoch 21/200, Iteration 149/250, Loss: 0.0240\n",
      "Epoch 21/200, Iteration 150/250, Loss: 0.0248\n",
      "Epoch 21/200, Iteration 151/250, Loss: 0.0196\n",
      "Epoch 21/200, Iteration 152/250, Loss: 0.0268\n",
      "Epoch 21/200, Iteration 153/250, Loss: 0.0322\n",
      "Epoch 21/200, Iteration 154/250, Loss: 0.0241\n",
      "Epoch 21/200, Iteration 155/250, Loss: 0.0179\n",
      "Epoch 21/200, Iteration 156/250, Loss: 0.0267\n",
      "Epoch 21/200, Iteration 157/250, Loss: 0.0315\n",
      "Epoch 21/200, Iteration 158/250, Loss: 0.0295\n",
      "Epoch 21/200, Iteration 159/250, Loss: 0.0376\n",
      "Epoch 21/200, Iteration 160/250, Loss: 0.0370\n",
      "Epoch 21/200, Iteration 161/250, Loss: 0.0210\n",
      "Epoch 21/200, Iteration 162/250, Loss: 0.0276\n",
      "Epoch 21/200, Iteration 163/250, Loss: 0.0210\n",
      "Epoch 21/200, Iteration 164/250, Loss: 0.0237\n",
      "Epoch 21/200, Iteration 165/250, Loss: 0.0359\n",
      "Epoch 21/200, Iteration 166/250, Loss: 0.0217\n",
      "Epoch 21/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 21/200, Iteration 168/250, Loss: 0.0224\n",
      "Epoch 21/200, Iteration 169/250, Loss: 0.0264\n",
      "Epoch 21/200, Iteration 170/250, Loss: 0.0184\n",
      "Epoch 21/200, Iteration 171/250, Loss: 0.0226\n",
      "Epoch 21/200, Iteration 172/250, Loss: 0.0203\n",
      "Epoch 21/200, Iteration 173/250, Loss: 0.0206\n",
      "Epoch 21/200, Iteration 174/250, Loss: 0.0398\n",
      "Epoch 21/200, Iteration 175/250, Loss: 0.0291\n",
      "Epoch 21/200, Iteration 176/250, Loss: 0.0346\n",
      "Epoch 21/200, Iteration 177/250, Loss: 0.0323\n",
      "Epoch 21/200, Iteration 178/250, Loss: 0.0282\n",
      "Epoch 21/200, Iteration 179/250, Loss: 0.0174\n",
      "Epoch 21/200, Iteration 180/250, Loss: 0.0223\n",
      "Epoch 21/200, Iteration 181/250, Loss: 0.0273\n",
      "Epoch 21/200, Iteration 182/250, Loss: 0.0257\n",
      "Epoch 21/200, Iteration 183/250, Loss: 0.0288\n",
      "Epoch 21/200, Iteration 184/250, Loss: 0.0284\n",
      "Epoch 21/200, Iteration 185/250, Loss: 0.0324\n",
      "Epoch 21/200, Iteration 186/250, Loss: 0.0341\n",
      "Epoch 21/200, Iteration 187/250, Loss: 0.0326\n",
      "Epoch 21/200, Iteration 188/250, Loss: 0.0278\n",
      "Epoch 21/200, Iteration 189/250, Loss: 0.0271\n",
      "Epoch 21/200, Iteration 190/250, Loss: 0.0256\n",
      "Epoch 21/200, Iteration 191/250, Loss: 0.0404\n",
      "Epoch 21/200, Iteration 192/250, Loss: 0.0386\n",
      "Epoch 21/200, Iteration 193/250, Loss: 0.0271\n",
      "Epoch 21/200, Iteration 194/250, Loss: 0.0277\n",
      "Epoch 21/200, Iteration 195/250, Loss: 0.0383\n",
      "Epoch 21/200, Iteration 196/250, Loss: 0.0205\n",
      "Epoch 21/200, Iteration 197/250, Loss: 0.0242\n",
      "Epoch 21/200, Iteration 198/250, Loss: 0.0187\n",
      "Epoch 21/200, Iteration 199/250, Loss: 0.0278\n",
      "Epoch 21/200, Iteration 200/250, Loss: 0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Iteration 201/250, Loss: 0.0241\n",
      "Epoch 21/200, Iteration 202/250, Loss: 0.0218\n",
      "Epoch 21/200, Iteration 203/250, Loss: 0.0331\n",
      "Epoch 21/200, Iteration 204/250, Loss: 0.0250\n",
      "Epoch 21/200, Iteration 205/250, Loss: 0.0270\n",
      "Epoch 21/200, Iteration 206/250, Loss: 0.0260\n",
      "Epoch 21/200, Iteration 207/250, Loss: 0.0284\n",
      "Epoch 21/200, Iteration 208/250, Loss: 0.0227\n",
      "Epoch 21/200, Iteration 209/250, Loss: 0.0155\n",
      "Epoch 21/200, Iteration 210/250, Loss: 0.0383\n",
      "Epoch 21/200, Iteration 211/250, Loss: 0.0230\n",
      "Epoch 21/200, Iteration 212/250, Loss: 0.0268\n",
      "Epoch 21/200, Iteration 213/250, Loss: 0.0207\n",
      "Epoch 21/200, Iteration 214/250, Loss: 0.0189\n",
      "Epoch 21/200, Iteration 215/250, Loss: 0.0321\n",
      "Epoch 21/200, Iteration 216/250, Loss: 0.0218\n",
      "Epoch 21/200, Iteration 217/250, Loss: 0.0380\n",
      "Epoch 21/200, Iteration 218/250, Loss: 0.0449\n",
      "Epoch 21/200, Iteration 219/250, Loss: 0.0254\n",
      "Epoch 21/200, Iteration 220/250, Loss: 0.0271\n",
      "Epoch 21/200, Iteration 221/250, Loss: 0.0276\n",
      "Epoch 21/200, Iteration 222/250, Loss: 0.0312\n",
      "Epoch 21/200, Iteration 223/250, Loss: 0.0210\n",
      "Epoch 21/200, Iteration 224/250, Loss: 0.0198\n",
      "Epoch 21/200, Iteration 225/250, Loss: 0.0165\n",
      "Epoch 21/200, Iteration 226/250, Loss: 0.0160\n",
      "Epoch 21/200, Iteration 227/250, Loss: 0.0214\n",
      "Epoch 21/200, Iteration 228/250, Loss: 0.0312\n",
      "Epoch 21/200, Iteration 229/250, Loss: 0.0219\n",
      "Epoch 21/200, Iteration 230/250, Loss: 0.0214\n",
      "Epoch 21/200, Iteration 231/250, Loss: 0.0241\n",
      "Epoch 21/200, Iteration 232/250, Loss: 0.0290\n",
      "Epoch 21/200, Iteration 233/250, Loss: 0.0224\n",
      "Epoch 21/200, Iteration 234/250, Loss: 0.0292\n",
      "Epoch 21/200, Iteration 235/250, Loss: 0.0222\n",
      "Epoch 21/200, Iteration 236/250, Loss: 0.0396\n",
      "Epoch 21/200, Iteration 237/250, Loss: 0.0275\n",
      "Epoch 21/200, Iteration 238/250, Loss: 0.0134\n",
      "Epoch 21/200, Iteration 239/250, Loss: 0.0276\n",
      "Epoch 21/200, Iteration 240/250, Loss: 0.0406\n",
      "Epoch 21/200, Iteration 241/250, Loss: 0.0350\n",
      "Epoch 21/200, Iteration 242/250, Loss: 0.0229\n",
      "Epoch 21/200, Iteration 243/250, Loss: 0.0352\n",
      "Epoch 21/200, Iteration 244/250, Loss: 0.0307\n",
      "Epoch 21/200, Iteration 245/250, Loss: 0.0457\n",
      "Epoch 21/200, Iteration 246/250, Loss: 0.0650\n",
      "Epoch 21/200, Iteration 247/250, Loss: 0.0314\n",
      "Epoch 21/200, Iteration 248/250, Loss: 0.0310\n",
      "Epoch 21/200, Iteration 249/250, Loss: 0.0169\n",
      "Epoch 21/200, Iteration 250/250, Loss: 0.0217\n",
      "Train Error: \n",
      " Accuracy: 78.09%, Avg loss: 0.025506, MRE: 2.280710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.05%, Avg loss: 0.025825, MRE: 4.432202 \n",
      "\n",
      "Epoch 22/200, Iteration 1/250, Loss: 0.0239\n",
      "Epoch 22/200, Iteration 2/250, Loss: 0.0243\n",
      "Epoch 22/200, Iteration 3/250, Loss: 0.0237\n",
      "Epoch 22/200, Iteration 4/250, Loss: 0.0172\n",
      "Epoch 22/200, Iteration 5/250, Loss: 0.0418\n",
      "Epoch 22/200, Iteration 6/250, Loss: 0.0289\n",
      "Epoch 22/200, Iteration 7/250, Loss: 0.0261\n",
      "Epoch 22/200, Iteration 8/250, Loss: 0.0316\n",
      "Epoch 22/200, Iteration 9/250, Loss: 0.0200\n",
      "Epoch 22/200, Iteration 10/250, Loss: 0.0203\n",
      "Epoch 22/200, Iteration 11/250, Loss: 0.0230\n",
      "Epoch 22/200, Iteration 12/250, Loss: 0.0246\n",
      "Epoch 22/200, Iteration 13/250, Loss: 0.0165\n",
      "Epoch 22/200, Iteration 14/250, Loss: 0.0232\n",
      "Epoch 22/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 22/200, Iteration 16/250, Loss: 0.0243\n",
      "Epoch 22/200, Iteration 17/250, Loss: 0.0200\n",
      "Epoch 22/200, Iteration 18/250, Loss: 0.0216\n",
      "Epoch 22/200, Iteration 19/250, Loss: 0.0233\n",
      "Epoch 22/200, Iteration 20/250, Loss: 0.0197\n",
      "Epoch 22/200, Iteration 21/250, Loss: 0.0219\n",
      "Epoch 22/200, Iteration 22/250, Loss: 0.0199\n",
      "Epoch 22/200, Iteration 23/250, Loss: 0.0368\n",
      "Epoch 22/200, Iteration 24/250, Loss: 0.0298\n",
      "Epoch 22/200, Iteration 25/250, Loss: 0.0205\n",
      "Epoch 22/200, Iteration 26/250, Loss: 0.0188\n",
      "Epoch 22/200, Iteration 27/250, Loss: 0.0264\n",
      "Epoch 22/200, Iteration 28/250, Loss: 0.0269\n",
      "Epoch 22/200, Iteration 29/250, Loss: 0.0198\n",
      "Epoch 22/200, Iteration 30/250, Loss: 0.0214\n",
      "Epoch 22/200, Iteration 31/250, Loss: 0.0209\n",
      "Epoch 22/200, Iteration 32/250, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 33/250, Loss: 0.0208\n",
      "Epoch 22/200, Iteration 34/250, Loss: 0.0198\n",
      "Epoch 22/200, Iteration 35/250, Loss: 0.0247\n",
      "Epoch 22/200, Iteration 36/250, Loss: 0.0326\n",
      "Epoch 22/200, Iteration 37/250, Loss: 0.0186\n",
      "Epoch 22/200, Iteration 38/250, Loss: 0.0202\n",
      "Epoch 22/200, Iteration 39/250, Loss: 0.0220\n",
      "Epoch 22/200, Iteration 40/250, Loss: 0.0387\n",
      "Epoch 22/200, Iteration 41/250, Loss: 0.0295\n",
      "Epoch 22/200, Iteration 42/250, Loss: 0.0332\n",
      "Epoch 22/200, Iteration 43/250, Loss: 0.0252\n",
      "Epoch 22/200, Iteration 44/250, Loss: 0.0296\n",
      "Epoch 22/200, Iteration 45/250, Loss: 0.0289\n",
      "Epoch 22/200, Iteration 46/250, Loss: 0.0362\n",
      "Epoch 22/200, Iteration 47/250, Loss: 0.0231\n",
      "Epoch 22/200, Iteration 48/250, Loss: 0.0266\n",
      "Epoch 22/200, Iteration 49/250, Loss: 0.0279\n",
      "Epoch 22/200, Iteration 50/250, Loss: 0.0353\n",
      "Epoch 22/200, Iteration 51/250, Loss: 0.0319\n",
      "Epoch 22/200, Iteration 52/250, Loss: 0.0198\n",
      "Epoch 22/200, Iteration 53/250, Loss: 0.0242\n",
      "Epoch 22/200, Iteration 54/250, Loss: 0.0295\n",
      "Epoch 22/200, Iteration 55/250, Loss: 0.0297\n",
      "Epoch 22/200, Iteration 56/250, Loss: 0.0225\n",
      "Epoch 22/200, Iteration 57/250, Loss: 0.0355\n",
      "Epoch 22/200, Iteration 58/250, Loss: 0.0272\n",
      "Epoch 22/200, Iteration 59/250, Loss: 0.0427\n",
      "Epoch 22/200, Iteration 60/250, Loss: 0.0322\n",
      "Epoch 22/200, Iteration 61/250, Loss: 0.0300\n",
      "Epoch 22/200, Iteration 62/250, Loss: 0.0222\n",
      "Epoch 22/200, Iteration 63/250, Loss: 0.0267\n",
      "Epoch 22/200, Iteration 64/250, Loss: 0.0287\n",
      "Epoch 22/200, Iteration 65/250, Loss: 0.0237\n",
      "Epoch 22/200, Iteration 66/250, Loss: 0.0201\n",
      "Epoch 22/200, Iteration 67/250, Loss: 0.0215\n",
      "Epoch 22/200, Iteration 68/250, Loss: 0.0351\n",
      "Epoch 22/200, Iteration 69/250, Loss: 0.0482\n",
      "Epoch 22/200, Iteration 70/250, Loss: 0.0224\n",
      "Epoch 22/200, Iteration 71/250, Loss: 0.0191\n",
      "Epoch 22/200, Iteration 72/250, Loss: 0.0183\n",
      "Epoch 22/200, Iteration 73/250, Loss: 0.0313\n",
      "Epoch 22/200, Iteration 74/250, Loss: 0.0290\n",
      "Epoch 22/200, Iteration 75/250, Loss: 0.0197\n",
      "Epoch 22/200, Iteration 76/250, Loss: 0.0208\n",
      "Epoch 22/200, Iteration 77/250, Loss: 0.0365\n",
      "Epoch 22/200, Iteration 78/250, Loss: 0.0243\n",
      "Epoch 22/200, Iteration 79/250, Loss: 0.0174\n",
      "Epoch 22/200, Iteration 80/250, Loss: 0.0178\n",
      "Epoch 22/200, Iteration 81/250, Loss: 0.0186\n",
      "Epoch 22/200, Iteration 82/250, Loss: 0.0146\n",
      "Epoch 22/200, Iteration 83/250, Loss: 0.0189\n",
      "Epoch 22/200, Iteration 84/250, Loss: 0.0254\n",
      "Epoch 22/200, Iteration 85/250, Loss: 0.0369\n",
      "Epoch 22/200, Iteration 86/250, Loss: 0.0214\n",
      "Epoch 22/200, Iteration 87/250, Loss: 0.0247\n",
      "Epoch 22/200, Iteration 88/250, Loss: 0.0191\n",
      "Epoch 22/200, Iteration 89/250, Loss: 0.0188\n",
      "Epoch 22/200, Iteration 90/250, Loss: 0.0223\n",
      "Epoch 22/200, Iteration 91/250, Loss: 0.0291\n",
      "Epoch 22/200, Iteration 92/250, Loss: 0.0261\n",
      "Epoch 22/200, Iteration 93/250, Loss: 0.0349\n",
      "Epoch 22/200, Iteration 94/250, Loss: 0.0269\n",
      "Epoch 22/200, Iteration 95/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 96/250, Loss: 0.0222\n",
      "Epoch 22/200, Iteration 97/250, Loss: 0.0306\n",
      "Epoch 22/200, Iteration 98/250, Loss: 0.0149\n",
      "Epoch 22/200, Iteration 99/250, Loss: 0.0194\n",
      "Epoch 22/200, Iteration 100/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 101/250, Loss: 0.0224\n",
      "Epoch 22/200, Iteration 102/250, Loss: 0.0232\n",
      "Epoch 22/200, Iteration 103/250, Loss: 0.0173\n",
      "Epoch 22/200, Iteration 104/250, Loss: 0.0157\n",
      "Epoch 22/200, Iteration 105/250, Loss: 0.0221\n",
      "Epoch 22/200, Iteration 106/250, Loss: 0.0224\n",
      "Epoch 22/200, Iteration 107/250, Loss: 0.0228\n",
      "Epoch 22/200, Iteration 108/250, Loss: 0.0210\n",
      "Epoch 22/200, Iteration 109/250, Loss: 0.0165\n",
      "Epoch 22/200, Iteration 110/250, Loss: 0.0322\n",
      "Epoch 22/200, Iteration 111/250, Loss: 0.0204\n",
      "Epoch 22/200, Iteration 112/250, Loss: 0.0162\n",
      "Epoch 22/200, Iteration 113/250, Loss: 0.0200\n",
      "Epoch 22/200, Iteration 114/250, Loss: 0.0199\n",
      "Epoch 22/200, Iteration 115/250, Loss: 0.0103\n",
      "Epoch 22/200, Iteration 116/250, Loss: 0.0193\n",
      "Epoch 22/200, Iteration 117/250, Loss: 0.0157\n",
      "Epoch 22/200, Iteration 118/250, Loss: 0.0266\n",
      "Epoch 22/200, Iteration 119/250, Loss: 0.0260\n",
      "Epoch 22/200, Iteration 120/250, Loss: 0.0267\n",
      "Epoch 22/200, Iteration 121/250, Loss: 0.0219\n",
      "Epoch 22/200, Iteration 122/250, Loss: 0.0205\n",
      "Epoch 22/200, Iteration 123/250, Loss: 0.0132\n",
      "Epoch 22/200, Iteration 124/250, Loss: 0.0253\n",
      "Epoch 22/200, Iteration 125/250, Loss: 0.0201\n",
      "Epoch 22/200, Iteration 126/250, Loss: 0.0183\n",
      "Epoch 22/200, Iteration 127/250, Loss: 0.0202\n",
      "Epoch 22/200, Iteration 128/250, Loss: 0.0140\n",
      "Epoch 22/200, Iteration 129/250, Loss: 0.0178\n",
      "Epoch 22/200, Iteration 130/250, Loss: 0.0265\n",
      "Epoch 22/200, Iteration 131/250, Loss: 0.0304\n",
      "Epoch 22/200, Iteration 132/250, Loss: 0.0201\n",
      "Epoch 22/200, Iteration 133/250, Loss: 0.0448\n",
      "Epoch 22/200, Iteration 134/250, Loss: 0.0141\n",
      "Epoch 22/200, Iteration 135/250, Loss: 0.0251\n",
      "Epoch 22/200, Iteration 136/250, Loss: 0.0256\n",
      "Epoch 22/200, Iteration 137/250, Loss: 0.0152\n",
      "Epoch 22/200, Iteration 138/250, Loss: 0.0161\n",
      "Epoch 22/200, Iteration 139/250, Loss: 0.0298\n",
      "Epoch 22/200, Iteration 140/250, Loss: 0.0222\n",
      "Epoch 22/200, Iteration 141/250, Loss: 0.0470\n",
      "Epoch 22/200, Iteration 142/250, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 143/250, Loss: 0.0223\n",
      "Epoch 22/200, Iteration 144/250, Loss: 0.0183\n",
      "Epoch 22/200, Iteration 145/250, Loss: 0.0226\n",
      "Epoch 22/200, Iteration 146/250, Loss: 0.0250\n",
      "Epoch 22/200, Iteration 147/250, Loss: 0.0277\n",
      "Epoch 22/200, Iteration 148/250, Loss: 0.0401\n",
      "Epoch 22/200, Iteration 149/250, Loss: 0.0243\n",
      "Epoch 22/200, Iteration 150/250, Loss: 0.0448\n",
      "Epoch 22/200, Iteration 151/250, Loss: 0.0269\n",
      "Epoch 22/200, Iteration 152/250, Loss: 0.0194\n",
      "Epoch 22/200, Iteration 153/250, Loss: 0.0225\n",
      "Epoch 22/200, Iteration 154/250, Loss: 0.0200\n",
      "Epoch 22/200, Iteration 155/250, Loss: 0.0326\n",
      "Epoch 22/200, Iteration 156/250, Loss: 0.0261\n",
      "Epoch 22/200, Iteration 157/250, Loss: 0.0311\n",
      "Epoch 22/200, Iteration 158/250, Loss: 0.0241\n",
      "Epoch 22/200, Iteration 159/250, Loss: 0.0181\n",
      "Epoch 22/200, Iteration 160/250, Loss: 0.0207\n",
      "Epoch 22/200, Iteration 161/250, Loss: 0.0384\n",
      "Epoch 22/200, Iteration 162/250, Loss: 0.0235\n",
      "Epoch 22/200, Iteration 163/250, Loss: 0.0220\n",
      "Epoch 22/200, Iteration 164/250, Loss: 0.0444\n",
      "Epoch 22/200, Iteration 165/250, Loss: 0.0209\n",
      "Epoch 22/200, Iteration 166/250, Loss: 0.0212\n",
      "Epoch 22/200, Iteration 167/250, Loss: 0.0211\n",
      "Epoch 22/200, Iteration 168/250, Loss: 0.0206\n",
      "Epoch 22/200, Iteration 169/250, Loss: 0.0213\n",
      "Epoch 22/200, Iteration 170/250, Loss: 0.0206\n",
      "Epoch 22/200, Iteration 171/250, Loss: 0.0170\n",
      "Epoch 22/200, Iteration 172/250, Loss: 0.0210\n",
      "Epoch 22/200, Iteration 173/250, Loss: 0.0344\n",
      "Epoch 22/200, Iteration 174/250, Loss: 0.0226\n",
      "Epoch 22/200, Iteration 175/250, Loss: 0.0308\n",
      "Epoch 22/200, Iteration 176/250, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Iteration 177/250, Loss: 0.0267\n",
      "Epoch 22/200, Iteration 178/250, Loss: 0.0437\n",
      "Epoch 22/200, Iteration 179/250, Loss: 0.0432\n",
      "Epoch 22/200, Iteration 180/250, Loss: 0.0216\n",
      "Epoch 22/200, Iteration 181/250, Loss: 0.0339\n",
      "Epoch 22/200, Iteration 182/250, Loss: 0.0274\n",
      "Epoch 22/200, Iteration 183/250, Loss: 0.0316\n",
      "Epoch 22/200, Iteration 184/250, Loss: 0.0181\n",
      "Epoch 22/200, Iteration 185/250, Loss: 0.0198\n",
      "Epoch 22/200, Iteration 186/250, Loss: 0.0377\n",
      "Epoch 22/200, Iteration 187/250, Loss: 0.0196\n",
      "Epoch 22/200, Iteration 188/250, Loss: 0.0430\n",
      "Epoch 22/200, Iteration 189/250, Loss: 0.0347\n",
      "Epoch 22/200, Iteration 190/250, Loss: 0.0230\n",
      "Epoch 22/200, Iteration 191/250, Loss: 0.0219\n",
      "Epoch 22/200, Iteration 192/250, Loss: 0.0145\n",
      "Epoch 22/200, Iteration 193/250, Loss: 0.0237\n",
      "Epoch 22/200, Iteration 194/250, Loss: 0.0168\n",
      "Epoch 22/200, Iteration 195/250, Loss: 0.0280\n",
      "Epoch 22/200, Iteration 196/250, Loss: 0.0242\n",
      "Epoch 22/200, Iteration 197/250, Loss: 0.0176\n",
      "Epoch 22/200, Iteration 198/250, Loss: 0.0220\n",
      "Epoch 22/200, Iteration 199/250, Loss: 0.0256\n",
      "Epoch 22/200, Iteration 200/250, Loss: 0.0334\n",
      "Epoch 22/200, Iteration 201/250, Loss: 0.0217\n",
      "Epoch 22/200, Iteration 202/250, Loss: 0.0238\n",
      "Epoch 22/200, Iteration 203/250, Loss: 0.0303\n",
      "Epoch 22/200, Iteration 204/250, Loss: 0.0210\n",
      "Epoch 22/200, Iteration 205/250, Loss: 0.0375\n",
      "Epoch 22/200, Iteration 206/250, Loss: 0.0225\n",
      "Epoch 22/200, Iteration 207/250, Loss: 0.0241\n",
      "Epoch 22/200, Iteration 208/250, Loss: 0.0240\n",
      "Epoch 22/200, Iteration 209/250, Loss: 0.0210\n",
      "Epoch 22/200, Iteration 210/250, Loss: 0.0229\n",
      "Epoch 22/200, Iteration 211/250, Loss: 0.0219\n",
      "Epoch 22/200, Iteration 212/250, Loss: 0.0193\n",
      "Epoch 22/200, Iteration 213/250, Loss: 0.0187\n",
      "Epoch 22/200, Iteration 214/250, Loss: 0.0248\n",
      "Epoch 22/200, Iteration 215/250, Loss: 0.0176\n",
      "Epoch 22/200, Iteration 216/250, Loss: 0.0214\n",
      "Epoch 22/200, Iteration 217/250, Loss: 0.0432\n",
      "Epoch 22/200, Iteration 218/250, Loss: 0.0208\n",
      "Epoch 22/200, Iteration 219/250, Loss: 0.0220\n",
      "Epoch 22/200, Iteration 220/250, Loss: 0.0190\n",
      "Epoch 22/200, Iteration 221/250, Loss: 0.0162\n",
      "Epoch 22/200, Iteration 222/250, Loss: 0.0202\n",
      "Epoch 22/200, Iteration 223/250, Loss: 0.0330\n",
      "Epoch 22/200, Iteration 224/250, Loss: 0.0268\n",
      "Epoch 22/200, Iteration 225/250, Loss: 0.0234\n",
      "Epoch 22/200, Iteration 226/250, Loss: 0.0403\n",
      "Epoch 22/200, Iteration 227/250, Loss: 0.0292\n",
      "Epoch 22/200, Iteration 228/250, Loss: 0.0177\n",
      "Epoch 22/200, Iteration 229/250, Loss: 0.0244\n",
      "Epoch 22/200, Iteration 230/250, Loss: 0.0204\n",
      "Epoch 22/200, Iteration 231/250, Loss: 0.0211\n",
      "Epoch 22/200, Iteration 232/250, Loss: 0.0263\n",
      "Epoch 22/200, Iteration 233/250, Loss: 0.0236\n",
      "Epoch 22/200, Iteration 234/250, Loss: 0.0292\n",
      "Epoch 22/200, Iteration 235/250, Loss: 0.0494\n",
      "Epoch 22/200, Iteration 236/250, Loss: 0.0310\n",
      "Epoch 22/200, Iteration 237/250, Loss: 0.0279\n",
      "Epoch 22/200, Iteration 238/250, Loss: 0.0398\n",
      "Epoch 22/200, Iteration 239/250, Loss: 0.0343\n",
      "Epoch 22/200, Iteration 240/250, Loss: 0.0226\n",
      "Epoch 22/200, Iteration 241/250, Loss: 0.0517\n",
      "Epoch 22/200, Iteration 242/250, Loss: 0.0384\n",
      "Epoch 22/200, Iteration 243/250, Loss: 0.0319\n",
      "Epoch 22/200, Iteration 244/250, Loss: 0.0228\n",
      "Epoch 22/200, Iteration 245/250, Loss: 0.0165\n",
      "Epoch 22/200, Iteration 246/250, Loss: 0.0253\n",
      "Epoch 22/200, Iteration 247/250, Loss: 0.0337\n",
      "Epoch 22/200, Iteration 248/250, Loss: 0.0410\n",
      "Epoch 22/200, Iteration 249/250, Loss: 0.0340\n",
      "Epoch 22/200, Iteration 250/250, Loss: 0.0257\n",
      "Train Error: \n",
      " Accuracy: 71.39%, Avg loss: 0.017223, MRE: 1.213865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.85%, Avg loss: 0.017077, MRE: 1.548060 \n",
      "\n",
      "Epoch 23/200, Iteration 1/250, Loss: 0.0213\n",
      "Epoch 23/200, Iteration 2/250, Loss: 0.0321\n",
      "Epoch 23/200, Iteration 3/250, Loss: 0.0414\n",
      "Epoch 23/200, Iteration 4/250, Loss: 0.0314\n",
      "Epoch 23/200, Iteration 5/250, Loss: 0.0220\n",
      "Epoch 23/200, Iteration 6/250, Loss: 0.0217\n",
      "Epoch 23/200, Iteration 7/250, Loss: 0.0232\n",
      "Epoch 23/200, Iteration 8/250, Loss: 0.0253\n",
      "Epoch 23/200, Iteration 9/250, Loss: 0.0249\n",
      "Epoch 23/200, Iteration 10/250, Loss: 0.0196\n",
      "Epoch 23/200, Iteration 11/250, Loss: 0.0229\n",
      "Epoch 23/200, Iteration 12/250, Loss: 0.0288\n",
      "Epoch 23/200, Iteration 13/250, Loss: 0.0247\n",
      "Epoch 23/200, Iteration 14/250, Loss: 0.0175\n",
      "Epoch 23/200, Iteration 15/250, Loss: 0.0244\n",
      "Epoch 23/200, Iteration 16/250, Loss: 0.0197\n",
      "Epoch 23/200, Iteration 17/250, Loss: 0.0287\n",
      "Epoch 23/200, Iteration 18/250, Loss: 0.0185\n",
      "Epoch 23/200, Iteration 19/250, Loss: 0.0181\n",
      "Epoch 23/200, Iteration 20/250, Loss: 0.0229\n",
      "Epoch 23/200, Iteration 21/250, Loss: 0.0167\n",
      "Epoch 23/200, Iteration 22/250, Loss: 0.0263\n",
      "Epoch 23/200, Iteration 23/250, Loss: 0.0201\n",
      "Epoch 23/200, Iteration 24/250, Loss: 0.0219\n",
      "Epoch 23/200, Iteration 25/250, Loss: 0.0224\n",
      "Epoch 23/200, Iteration 26/250, Loss: 0.0208\n",
      "Epoch 23/200, Iteration 27/250, Loss: 0.0210\n",
      "Epoch 23/200, Iteration 28/250, Loss: 0.0303\n",
      "Epoch 23/200, Iteration 29/250, Loss: 0.0280\n",
      "Epoch 23/200, Iteration 30/250, Loss: 0.0299\n",
      "Epoch 23/200, Iteration 31/250, Loss: 0.0175\n",
      "Epoch 23/200, Iteration 32/250, Loss: 0.0247\n",
      "Epoch 23/200, Iteration 33/250, Loss: 0.0287\n",
      "Epoch 23/200, Iteration 34/250, Loss: 0.0318\n",
      "Epoch 23/200, Iteration 35/250, Loss: 0.0253\n",
      "Epoch 23/200, Iteration 36/250, Loss: 0.0396\n",
      "Epoch 23/200, Iteration 37/250, Loss: 0.0320\n",
      "Epoch 23/200, Iteration 38/250, Loss: 0.0163\n",
      "Epoch 23/200, Iteration 39/250, Loss: 0.0313\n",
      "Epoch 23/200, Iteration 40/250, Loss: 0.0289\n",
      "Epoch 23/200, Iteration 41/250, Loss: 0.0185\n",
      "Epoch 23/200, Iteration 42/250, Loss: 0.0215\n",
      "Epoch 23/200, Iteration 43/250, Loss: 0.0185\n",
      "Epoch 23/200, Iteration 44/250, Loss: 0.0174\n",
      "Epoch 23/200, Iteration 45/250, Loss: 0.0171\n",
      "Epoch 23/200, Iteration 46/250, Loss: 0.0162\n",
      "Epoch 23/200, Iteration 47/250, Loss: 0.0224\n",
      "Epoch 23/200, Iteration 48/250, Loss: 0.0214\n",
      "Epoch 23/200, Iteration 49/250, Loss: 0.0456\n",
      "Epoch 23/200, Iteration 50/250, Loss: 0.0238\n",
      "Epoch 23/200, Iteration 51/250, Loss: 0.0192\n",
      "Epoch 23/200, Iteration 52/250, Loss: 0.0292\n",
      "Epoch 23/200, Iteration 53/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 54/250, Loss: 0.0106\n",
      "Epoch 23/200, Iteration 55/250, Loss: 0.0172\n",
      "Epoch 23/200, Iteration 56/250, Loss: 0.0244\n",
      "Epoch 23/200, Iteration 57/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 58/250, Loss: 0.0329\n",
      "Epoch 23/200, Iteration 59/250, Loss: 0.0211\n",
      "Epoch 23/200, Iteration 60/250, Loss: 0.0516\n",
      "Epoch 23/200, Iteration 61/250, Loss: 0.0207\n",
      "Epoch 23/200, Iteration 62/250, Loss: 0.0222\n",
      "Epoch 23/200, Iteration 63/250, Loss: 0.0208\n",
      "Epoch 23/200, Iteration 64/250, Loss: 0.0259\n",
      "Epoch 23/200, Iteration 65/250, Loss: 0.0248\n",
      "Epoch 23/200, Iteration 66/250, Loss: 0.0200\n",
      "Epoch 23/200, Iteration 67/250, Loss: 0.0206\n",
      "Epoch 23/200, Iteration 68/250, Loss: 0.0282\n",
      "Epoch 23/200, Iteration 69/250, Loss: 0.0170\n",
      "Epoch 23/200, Iteration 70/250, Loss: 0.0252\n",
      "Epoch 23/200, Iteration 71/250, Loss: 0.0249\n",
      "Epoch 23/200, Iteration 72/250, Loss: 0.0290\n",
      "Epoch 23/200, Iteration 73/250, Loss: 0.0453\n",
      "Epoch 23/200, Iteration 74/250, Loss: 0.0321\n",
      "Epoch 23/200, Iteration 75/250, Loss: 0.0193\n",
      "Epoch 23/200, Iteration 76/250, Loss: 0.0167\n",
      "Epoch 23/200, Iteration 77/250, Loss: 0.0331\n",
      "Epoch 23/200, Iteration 78/250, Loss: 0.0265\n",
      "Epoch 23/200, Iteration 79/250, Loss: 0.0247\n",
      "Epoch 23/200, Iteration 80/250, Loss: 0.0150\n",
      "Epoch 23/200, Iteration 81/250, Loss: 0.0242\n",
      "Epoch 23/200, Iteration 82/250, Loss: 0.0365\n",
      "Epoch 23/200, Iteration 83/250, Loss: 0.0302\n",
      "Epoch 23/200, Iteration 84/250, Loss: 0.0265\n",
      "Epoch 23/200, Iteration 85/250, Loss: 0.0200\n",
      "Epoch 23/200, Iteration 86/250, Loss: 0.0335\n",
      "Epoch 23/200, Iteration 87/250, Loss: 0.0339\n",
      "Epoch 23/200, Iteration 88/250, Loss: 0.0205\n",
      "Epoch 23/200, Iteration 89/250, Loss: 0.0266\n",
      "Epoch 23/200, Iteration 90/250, Loss: 0.0134\n",
      "Epoch 23/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 23/200, Iteration 92/250, Loss: 0.0335\n",
      "Epoch 23/200, Iteration 93/250, Loss: 0.0356\n",
      "Epoch 23/200, Iteration 94/250, Loss: 0.0158\n",
      "Epoch 23/200, Iteration 95/250, Loss: 0.0334\n",
      "Epoch 23/200, Iteration 96/250, Loss: 0.0272\n",
      "Epoch 23/200, Iteration 97/250, Loss: 0.0227\n",
      "Epoch 23/200, Iteration 98/250, Loss: 0.0195\n",
      "Epoch 23/200, Iteration 99/250, Loss: 0.0179\n",
      "Epoch 23/200, Iteration 100/250, Loss: 0.0284\n",
      "Epoch 23/200, Iteration 101/250, Loss: 0.0236\n",
      "Epoch 23/200, Iteration 102/250, Loss: 0.0284\n",
      "Epoch 23/200, Iteration 103/250, Loss: 0.0361\n",
      "Epoch 23/200, Iteration 104/250, Loss: 0.0360\n",
      "Epoch 23/200, Iteration 105/250, Loss: 0.0277\n",
      "Epoch 23/200, Iteration 106/250, Loss: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Iteration 107/250, Loss: 0.0352\n",
      "Epoch 23/200, Iteration 108/250, Loss: 0.0229\n",
      "Epoch 23/200, Iteration 109/250, Loss: 0.0173\n",
      "Epoch 23/200, Iteration 110/250, Loss: 0.0307\n",
      "Epoch 23/200, Iteration 111/250, Loss: 0.0380\n",
      "Epoch 23/200, Iteration 112/250, Loss: 0.0329\n",
      "Epoch 23/200, Iteration 113/250, Loss: 0.0230\n",
      "Epoch 23/200, Iteration 114/250, Loss: 0.0157\n",
      "Epoch 23/200, Iteration 115/250, Loss: 0.0184\n",
      "Epoch 23/200, Iteration 116/250, Loss: 0.0231\n",
      "Epoch 23/200, Iteration 117/250, Loss: 0.0370\n",
      "Epoch 23/200, Iteration 118/250, Loss: 0.0160\n",
      "Epoch 23/200, Iteration 119/250, Loss: 0.0338\n",
      "Epoch 23/200, Iteration 120/250, Loss: 0.0340\n",
      "Epoch 23/200, Iteration 121/250, Loss: 0.0330\n",
      "Epoch 23/200, Iteration 122/250, Loss: 0.0529\n",
      "Epoch 23/200, Iteration 123/250, Loss: 0.0247\n",
      "Epoch 23/200, Iteration 124/250, Loss: 0.0270\n",
      "Epoch 23/200, Iteration 125/250, Loss: 0.0300\n",
      "Epoch 23/200, Iteration 126/250, Loss: 0.0196\n",
      "Epoch 23/200, Iteration 127/250, Loss: 0.0310\n",
      "Epoch 23/200, Iteration 128/250, Loss: 0.0265\n",
      "Epoch 23/200, Iteration 129/250, Loss: 0.0421\n",
      "Epoch 23/200, Iteration 130/250, Loss: 0.0281\n",
      "Epoch 23/200, Iteration 131/250, Loss: 0.0224\n",
      "Epoch 23/200, Iteration 132/250, Loss: 0.0269\n",
      "Epoch 23/200, Iteration 133/250, Loss: 0.0223\n",
      "Epoch 23/200, Iteration 134/250, Loss: 0.0229\n",
      "Epoch 23/200, Iteration 135/250, Loss: 0.0234\n",
      "Epoch 23/200, Iteration 136/250, Loss: 0.0144\n",
      "Epoch 23/200, Iteration 137/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 138/250, Loss: 0.0357\n",
      "Epoch 23/200, Iteration 139/250, Loss: 0.0244\n",
      "Epoch 23/200, Iteration 140/250, Loss: 0.0266\n",
      "Epoch 23/200, Iteration 141/250, Loss: 0.0232\n",
      "Epoch 23/200, Iteration 142/250, Loss: 0.0182\n",
      "Epoch 23/200, Iteration 143/250, Loss: 0.0219\n",
      "Epoch 23/200, Iteration 144/250, Loss: 0.0197\n",
      "Epoch 23/200, Iteration 145/250, Loss: 0.0343\n",
      "Epoch 23/200, Iteration 146/250, Loss: 0.0199\n",
      "Epoch 23/200, Iteration 147/250, Loss: 0.0209\n",
      "Epoch 23/200, Iteration 148/250, Loss: 0.0325\n",
      "Epoch 23/200, Iteration 149/250, Loss: 0.0230\n",
      "Epoch 23/200, Iteration 150/250, Loss: 0.0259\n",
      "Epoch 23/200, Iteration 151/250, Loss: 0.0292\n",
      "Epoch 23/200, Iteration 152/250, Loss: 0.0171\n",
      "Epoch 23/200, Iteration 153/250, Loss: 0.0289\n",
      "Epoch 23/200, Iteration 154/250, Loss: 0.0287\n",
      "Epoch 23/200, Iteration 155/250, Loss: 0.0217\n",
      "Epoch 23/200, Iteration 156/250, Loss: 0.0174\n",
      "Epoch 23/200, Iteration 157/250, Loss: 0.0345\n",
      "Epoch 23/200, Iteration 158/250, Loss: 0.0305\n",
      "Epoch 23/200, Iteration 159/250, Loss: 0.0335\n",
      "Epoch 23/200, Iteration 160/250, Loss: 0.0145\n",
      "Epoch 23/200, Iteration 161/250, Loss: 0.0183\n",
      "Epoch 23/200, Iteration 162/250, Loss: 0.0237\n",
      "Epoch 23/200, Iteration 163/250, Loss: 0.0217\n",
      "Epoch 23/200, Iteration 164/250, Loss: 0.0130\n",
      "Epoch 23/200, Iteration 165/250, Loss: 0.0327\n",
      "Epoch 23/200, Iteration 166/250, Loss: 0.0257\n",
      "Epoch 23/200, Iteration 167/250, Loss: 0.0247\n",
      "Epoch 23/200, Iteration 168/250, Loss: 0.0145\n",
      "Epoch 23/200, Iteration 169/250, Loss: 0.0349\n",
      "Epoch 23/200, Iteration 170/250, Loss: 0.0252\n",
      "Epoch 23/200, Iteration 171/250, Loss: 0.0296\n",
      "Epoch 23/200, Iteration 172/250, Loss: 0.0276\n",
      "Epoch 23/200, Iteration 173/250, Loss: 0.0298\n",
      "Epoch 23/200, Iteration 174/250, Loss: 0.0526\n",
      "Epoch 23/200, Iteration 175/250, Loss: 0.0490\n",
      "Epoch 23/200, Iteration 176/250, Loss: 0.0379\n",
      "Epoch 23/200, Iteration 177/250, Loss: 0.0272\n",
      "Epoch 23/200, Iteration 178/250, Loss: 0.0196\n",
      "Epoch 23/200, Iteration 179/250, Loss: 0.0225\n",
      "Epoch 23/200, Iteration 180/250, Loss: 0.0252\n",
      "Epoch 23/200, Iteration 181/250, Loss: 0.0228\n",
      "Epoch 23/200, Iteration 182/250, Loss: 0.0256\n",
      "Epoch 23/200, Iteration 183/250, Loss: 0.0346\n",
      "Epoch 23/200, Iteration 184/250, Loss: 0.0293\n",
      "Epoch 23/200, Iteration 185/250, Loss: 0.0217\n",
      "Epoch 23/200, Iteration 186/250, Loss: 0.0255\n",
      "Epoch 23/200, Iteration 187/250, Loss: 0.0288\n",
      "Epoch 23/200, Iteration 188/250, Loss: 0.0239\n",
      "Epoch 23/200, Iteration 189/250, Loss: 0.0224\n",
      "Epoch 23/200, Iteration 190/250, Loss: 0.0159\n",
      "Epoch 23/200, Iteration 191/250, Loss: 0.0253\n",
      "Epoch 23/200, Iteration 192/250, Loss: 0.0294\n",
      "Epoch 23/200, Iteration 193/250, Loss: 0.0291\n",
      "Epoch 23/200, Iteration 194/250, Loss: 0.0309\n",
      "Epoch 23/200, Iteration 195/250, Loss: 0.0318\n",
      "Epoch 23/200, Iteration 196/250, Loss: 0.0202\n",
      "Epoch 23/200, Iteration 197/250, Loss: 0.0231\n",
      "Epoch 23/200, Iteration 198/250, Loss: 0.0148\n",
      "Epoch 23/200, Iteration 199/250, Loss: 0.0210\n",
      "Epoch 23/200, Iteration 200/250, Loss: 0.0198\n",
      "Epoch 23/200, Iteration 201/250, Loss: 0.0241\n",
      "Epoch 23/200, Iteration 202/250, Loss: 0.0209\n",
      "Epoch 23/200, Iteration 203/250, Loss: 0.0170\n",
      "Epoch 23/200, Iteration 204/250, Loss: 0.0164\n",
      "Epoch 23/200, Iteration 205/250, Loss: 0.0213\n",
      "Epoch 23/200, Iteration 206/250, Loss: 0.0296\n",
      "Epoch 23/200, Iteration 207/250, Loss: 0.0279\n",
      "Epoch 23/200, Iteration 208/250, Loss: 0.0204\n",
      "Epoch 23/200, Iteration 209/250, Loss: 0.0190\n",
      "Epoch 23/200, Iteration 210/250, Loss: 0.0182\n",
      "Epoch 23/200, Iteration 211/250, Loss: 0.0291\n",
      "Epoch 23/200, Iteration 212/250, Loss: 0.0292\n",
      "Epoch 23/200, Iteration 213/250, Loss: 0.0246\n",
      "Epoch 23/200, Iteration 214/250, Loss: 0.0241\n",
      "Epoch 23/200, Iteration 215/250, Loss: 0.0358\n",
      "Epoch 23/200, Iteration 216/250, Loss: 0.0322\n",
      "Epoch 23/200, Iteration 217/250, Loss: 0.0184\n",
      "Epoch 23/200, Iteration 218/250, Loss: 0.0308\n",
      "Epoch 23/200, Iteration 219/250, Loss: 0.0201\n",
      "Epoch 23/200, Iteration 220/250, Loss: 0.0173\n",
      "Epoch 23/200, Iteration 221/250, Loss: 0.0261\n",
      "Epoch 23/200, Iteration 222/250, Loss: 0.0245\n",
      "Epoch 23/200, Iteration 223/250, Loss: 0.0283\n",
      "Epoch 23/200, Iteration 224/250, Loss: 0.0179\n",
      "Epoch 23/200, Iteration 225/250, Loss: 0.0187\n",
      "Epoch 23/200, Iteration 226/250, Loss: 0.0234\n",
      "Epoch 23/200, Iteration 227/250, Loss: 0.0311\n",
      "Epoch 23/200, Iteration 228/250, Loss: 0.0474\n",
      "Epoch 23/200, Iteration 229/250, Loss: 0.0122\n",
      "Epoch 23/200, Iteration 230/250, Loss: 0.0194\n",
      "Epoch 23/200, Iteration 231/250, Loss: 0.0167\n",
      "Epoch 23/200, Iteration 232/250, Loss: 0.0246\n",
      "Epoch 23/200, Iteration 233/250, Loss: 0.0141\n",
      "Epoch 23/200, Iteration 234/250, Loss: 0.0211\n",
      "Epoch 23/200, Iteration 235/250, Loss: 0.0201\n",
      "Epoch 23/200, Iteration 236/250, Loss: 0.0227\n",
      "Epoch 23/200, Iteration 237/250, Loss: 0.0192\n",
      "Epoch 23/200, Iteration 238/250, Loss: 0.0161\n",
      "Epoch 23/200, Iteration 239/250, Loss: 0.0259\n",
      "Epoch 23/200, Iteration 240/250, Loss: 0.0176\n",
      "Epoch 23/200, Iteration 241/250, Loss: 0.0236\n",
      "Epoch 23/200, Iteration 242/250, Loss: 0.0268\n",
      "Epoch 23/200, Iteration 243/250, Loss: 0.0280\n",
      "Epoch 23/200, Iteration 244/250, Loss: 0.0195\n",
      "Epoch 23/200, Iteration 245/250, Loss: 0.0259\n",
      "Epoch 23/200, Iteration 246/250, Loss: 0.0272\n",
      "Epoch 23/200, Iteration 247/250, Loss: 0.0252\n",
      "Epoch 23/200, Iteration 248/250, Loss: 0.0358\n",
      "Epoch 23/200, Iteration 249/250, Loss: 0.0271\n",
      "Epoch 23/200, Iteration 250/250, Loss: 0.0155\n",
      "Train Error: \n",
      " Accuracy: 73.88%, Avg loss: 0.014312, MRE: 1.069999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.013849, MRE: 1.309626 \n",
      "\n",
      "Epoch 24/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 2/250, Loss: 0.0138\n",
      "Epoch 24/200, Iteration 3/250, Loss: 0.0213\n",
      "Epoch 24/200, Iteration 4/250, Loss: 0.0184\n",
      "Epoch 24/200, Iteration 5/250, Loss: 0.0151\n",
      "Epoch 24/200, Iteration 6/250, Loss: 0.0164\n",
      "Epoch 24/200, Iteration 7/250, Loss: 0.0186\n",
      "Epoch 24/200, Iteration 8/250, Loss: 0.0184\n",
      "Epoch 24/200, Iteration 9/250, Loss: 0.0213\n",
      "Epoch 24/200, Iteration 10/250, Loss: 0.0147\n",
      "Epoch 24/200, Iteration 11/250, Loss: 0.0204\n",
      "Epoch 24/200, Iteration 12/250, Loss: 0.0181\n",
      "Epoch 24/200, Iteration 13/250, Loss: 0.0199\n",
      "Epoch 24/200, Iteration 14/250, Loss: 0.0194\n",
      "Epoch 24/200, Iteration 15/250, Loss: 0.0184\n",
      "Epoch 24/200, Iteration 16/250, Loss: 0.0350\n",
      "Epoch 24/200, Iteration 17/250, Loss: 0.0219\n",
      "Epoch 24/200, Iteration 18/250, Loss: 0.0211\n",
      "Epoch 24/200, Iteration 19/250, Loss: 0.0227\n",
      "Epoch 24/200, Iteration 20/250, Loss: 0.0205\n",
      "Epoch 24/200, Iteration 21/250, Loss: 0.0136\n",
      "Epoch 24/200, Iteration 22/250, Loss: 0.0239\n",
      "Epoch 24/200, Iteration 23/250, Loss: 0.0293\n",
      "Epoch 24/200, Iteration 24/250, Loss: 0.0223\n",
      "Epoch 24/200, Iteration 25/250, Loss: 0.0258\n",
      "Epoch 24/200, Iteration 26/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 27/250, Loss: 0.0245\n",
      "Epoch 24/200, Iteration 28/250, Loss: 0.0235\n",
      "Epoch 24/200, Iteration 29/250, Loss: 0.0251\n",
      "Epoch 24/200, Iteration 30/250, Loss: 0.0223\n",
      "Epoch 24/200, Iteration 31/250, Loss: 0.0266\n",
      "Epoch 24/200, Iteration 32/250, Loss: 0.0210\n",
      "Epoch 24/200, Iteration 33/250, Loss: 0.0233\n",
      "Epoch 24/200, Iteration 34/250, Loss: 0.0201\n",
      "Epoch 24/200, Iteration 35/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 36/250, Loss: 0.0364\n",
      "Epoch 24/200, Iteration 37/250, Loss: 0.0383\n",
      "Epoch 24/200, Iteration 38/250, Loss: 0.0149\n",
      "Epoch 24/200, Iteration 39/250, Loss: 0.0180\n",
      "Epoch 24/200, Iteration 40/250, Loss: 0.0251\n",
      "Epoch 24/200, Iteration 41/250, Loss: 0.0301\n",
      "Epoch 24/200, Iteration 42/250, Loss: 0.0167\n",
      "Epoch 24/200, Iteration 43/250, Loss: 0.0186\n",
      "Epoch 24/200, Iteration 44/250, Loss: 0.0372\n",
      "Epoch 24/200, Iteration 45/250, Loss: 0.0324\n",
      "Epoch 24/200, Iteration 46/250, Loss: 0.0211\n",
      "Epoch 24/200, Iteration 47/250, Loss: 0.0333\n",
      "Epoch 24/200, Iteration 48/250, Loss: 0.0495\n",
      "Epoch 24/200, Iteration 49/250, Loss: 0.0273\n",
      "Epoch 24/200, Iteration 50/250, Loss: 0.0263\n",
      "Epoch 24/200, Iteration 51/250, Loss: 0.0207\n",
      "Epoch 24/200, Iteration 52/250, Loss: 0.0169\n",
      "Epoch 24/200, Iteration 53/250, Loss: 0.0248\n",
      "Epoch 24/200, Iteration 54/250, Loss: 0.0164\n",
      "Epoch 24/200, Iteration 55/250, Loss: 0.0183\n",
      "Epoch 24/200, Iteration 56/250, Loss: 0.0278\n",
      "Epoch 24/200, Iteration 57/250, Loss: 0.0321\n",
      "Epoch 24/200, Iteration 58/250, Loss: 0.0409\n",
      "Epoch 24/200, Iteration 59/250, Loss: 0.0257\n",
      "Epoch 24/200, Iteration 60/250, Loss: 0.0275\n",
      "Epoch 24/200, Iteration 61/250, Loss: 0.0448\n",
      "Epoch 24/200, Iteration 62/250, Loss: 0.0282\n",
      "Epoch 24/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 24/200, Iteration 64/250, Loss: 0.0361\n",
      "Epoch 24/200, Iteration 65/250, Loss: 0.0190\n",
      "Epoch 24/200, Iteration 66/250, Loss: 0.0224\n",
      "Epoch 24/200, Iteration 67/250, Loss: 0.0297\n",
      "Epoch 24/200, Iteration 68/250, Loss: 0.0289\n",
      "Epoch 24/200, Iteration 69/250, Loss: 0.0240\n",
      "Epoch 24/200, Iteration 70/250, Loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Iteration 71/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 72/250, Loss: 0.0198\n",
      "Epoch 24/200, Iteration 73/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 74/250, Loss: 0.0269\n",
      "Epoch 24/200, Iteration 75/250, Loss: 0.0215\n",
      "Epoch 24/200, Iteration 76/250, Loss: 0.0315\n",
      "Epoch 24/200, Iteration 77/250, Loss: 0.0303\n",
      "Epoch 24/200, Iteration 78/250, Loss: 0.0197\n",
      "Epoch 24/200, Iteration 79/250, Loss: 0.0268\n",
      "Epoch 24/200, Iteration 80/250, Loss: 0.0241\n",
      "Epoch 24/200, Iteration 81/250, Loss: 0.0505\n",
      "Epoch 24/200, Iteration 82/250, Loss: 0.0164\n",
      "Epoch 24/200, Iteration 83/250, Loss: 0.0260\n",
      "Epoch 24/200, Iteration 84/250, Loss: 0.0198\n",
      "Epoch 24/200, Iteration 85/250, Loss: 0.0129\n",
      "Epoch 24/200, Iteration 86/250, Loss: 0.0172\n",
      "Epoch 24/200, Iteration 87/250, Loss: 0.0158\n",
      "Epoch 24/200, Iteration 88/250, Loss: 0.0280\n",
      "Epoch 24/200, Iteration 89/250, Loss: 0.0137\n",
      "Epoch 24/200, Iteration 90/250, Loss: 0.0187\n",
      "Epoch 24/200, Iteration 91/250, Loss: 0.0203\n",
      "Epoch 24/200, Iteration 92/250, Loss: 0.0188\n",
      "Epoch 24/200, Iteration 93/250, Loss: 0.0173\n",
      "Epoch 24/200, Iteration 94/250, Loss: 0.0141\n",
      "Epoch 24/200, Iteration 95/250, Loss: 0.0166\n",
      "Epoch 24/200, Iteration 96/250, Loss: 0.0134\n",
      "Epoch 24/200, Iteration 97/250, Loss: 0.0317\n",
      "Epoch 24/200, Iteration 98/250, Loss: 0.0158\n",
      "Epoch 24/200, Iteration 99/250, Loss: 0.0211\n",
      "Epoch 24/200, Iteration 100/250, Loss: 0.0235\n",
      "Epoch 24/200, Iteration 101/250, Loss: 0.0416\n",
      "Epoch 24/200, Iteration 102/250, Loss: 0.0211\n",
      "Epoch 24/200, Iteration 103/250, Loss: 0.0234\n",
      "Epoch 24/200, Iteration 104/250, Loss: 0.0201\n",
      "Epoch 24/200, Iteration 105/250, Loss: 0.0155\n",
      "Epoch 24/200, Iteration 106/250, Loss: 0.0247\n",
      "Epoch 24/200, Iteration 107/250, Loss: 0.0259\n",
      "Epoch 24/200, Iteration 108/250, Loss: 0.0290\n",
      "Epoch 24/200, Iteration 109/250, Loss: 0.0137\n",
      "Epoch 24/200, Iteration 110/250, Loss: 0.0270\n",
      "Epoch 24/200, Iteration 111/250, Loss: 0.0269\n",
      "Epoch 24/200, Iteration 112/250, Loss: 0.0198\n",
      "Epoch 24/200, Iteration 113/250, Loss: 0.0391\n",
      "Epoch 24/200, Iteration 114/250, Loss: 0.0141\n",
      "Epoch 24/200, Iteration 115/250, Loss: 0.0423\n",
      "Epoch 24/200, Iteration 116/250, Loss: 0.0166\n",
      "Epoch 24/200, Iteration 117/250, Loss: 0.0159\n",
      "Epoch 24/200, Iteration 118/250, Loss: 0.0132\n",
      "Epoch 24/200, Iteration 119/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 120/250, Loss: 0.0232\n",
      "Epoch 24/200, Iteration 121/250, Loss: 0.0207\n",
      "Epoch 24/200, Iteration 122/250, Loss: 0.0157\n",
      "Epoch 24/200, Iteration 123/250, Loss: 0.0187\n",
      "Epoch 24/200, Iteration 124/250, Loss: 0.0171\n",
      "Epoch 24/200, Iteration 125/250, Loss: 0.0316\n",
      "Epoch 24/200, Iteration 126/250, Loss: 0.0241\n",
      "Epoch 24/200, Iteration 127/250, Loss: 0.0201\n",
      "Epoch 24/200, Iteration 128/250, Loss: 0.0228\n",
      "Epoch 24/200, Iteration 129/250, Loss: 0.0346\n",
      "Epoch 24/200, Iteration 130/250, Loss: 0.0300\n",
      "Epoch 24/200, Iteration 131/250, Loss: 0.0184\n",
      "Epoch 24/200, Iteration 132/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 133/250, Loss: 0.0305\n",
      "Epoch 24/200, Iteration 134/250, Loss: 0.0346\n",
      "Epoch 24/200, Iteration 135/250, Loss: 0.0196\n",
      "Epoch 24/200, Iteration 136/250, Loss: 0.0289\n",
      "Epoch 24/200, Iteration 137/250, Loss: 0.0293\n",
      "Epoch 24/200, Iteration 138/250, Loss: 0.0343\n",
      "Epoch 24/200, Iteration 139/250, Loss: 0.0292\n",
      "Epoch 24/200, Iteration 140/250, Loss: 0.0212\n",
      "Epoch 24/200, Iteration 141/250, Loss: 0.0254\n",
      "Epoch 24/200, Iteration 142/250, Loss: 0.0150\n",
      "Epoch 24/200, Iteration 143/250, Loss: 0.0362\n",
      "Epoch 24/200, Iteration 144/250, Loss: 0.0212\n",
      "Epoch 24/200, Iteration 145/250, Loss: 0.0214\n",
      "Epoch 24/200, Iteration 146/250, Loss: 0.0482\n",
      "Epoch 24/200, Iteration 147/250, Loss: 0.0272\n",
      "Epoch 24/200, Iteration 148/250, Loss: 0.0471\n",
      "Epoch 24/200, Iteration 149/250, Loss: 0.0188\n",
      "Epoch 24/200, Iteration 150/250, Loss: 0.0195\n",
      "Epoch 24/200, Iteration 151/250, Loss: 0.0243\n",
      "Epoch 24/200, Iteration 152/250, Loss: 0.0203\n",
      "Epoch 24/200, Iteration 153/250, Loss: 0.0235\n",
      "Epoch 24/200, Iteration 154/250, Loss: 0.0214\n",
      "Epoch 24/200, Iteration 155/250, Loss: 0.0154\n",
      "Epoch 24/200, Iteration 156/250, Loss: 0.0409\n",
      "Epoch 24/200, Iteration 157/250, Loss: 0.0292\n",
      "Epoch 24/200, Iteration 158/250, Loss: 0.0299\n",
      "Epoch 24/200, Iteration 159/250, Loss: 0.0337\n",
      "Epoch 24/200, Iteration 160/250, Loss: 0.0257\n",
      "Epoch 24/200, Iteration 161/250, Loss: 0.0272\n",
      "Epoch 24/200, Iteration 162/250, Loss: 0.0325\n",
      "Epoch 24/200, Iteration 163/250, Loss: 0.0280\n",
      "Epoch 24/200, Iteration 164/250, Loss: 0.0273\n",
      "Epoch 24/200, Iteration 165/250, Loss: 0.0284\n",
      "Epoch 24/200, Iteration 166/250, Loss: 0.0241\n",
      "Epoch 24/200, Iteration 167/250, Loss: 0.0267\n",
      "Epoch 24/200, Iteration 168/250, Loss: 0.0206\n",
      "Epoch 24/200, Iteration 169/250, Loss: 0.0177\n",
      "Epoch 24/200, Iteration 170/250, Loss: 0.0225\n",
      "Epoch 24/200, Iteration 171/250, Loss: 0.0172\n",
      "Epoch 24/200, Iteration 172/250, Loss: 0.0258\n",
      "Epoch 24/200, Iteration 173/250, Loss: 0.0226\n",
      "Epoch 24/200, Iteration 174/250, Loss: 0.0183\n",
      "Epoch 24/200, Iteration 175/250, Loss: 0.0171\n",
      "Epoch 24/200, Iteration 176/250, Loss: 0.0171\n",
      "Epoch 24/200, Iteration 177/250, Loss: 0.0332\n",
      "Epoch 24/200, Iteration 178/250, Loss: 0.0323\n",
      "Epoch 24/200, Iteration 179/250, Loss: 0.0253\n",
      "Epoch 24/200, Iteration 180/250, Loss: 0.0392\n",
      "Epoch 24/200, Iteration 181/250, Loss: 0.0298\n",
      "Epoch 24/200, Iteration 182/250, Loss: 0.0349\n",
      "Epoch 24/200, Iteration 183/250, Loss: 0.0420\n",
      "Epoch 24/200, Iteration 184/250, Loss: 0.0476\n",
      "Epoch 24/200, Iteration 185/250, Loss: 0.0267\n",
      "Epoch 24/200, Iteration 186/250, Loss: 0.0357\n",
      "Epoch 24/200, Iteration 187/250, Loss: 0.0384\n",
      "Epoch 24/200, Iteration 188/250, Loss: 0.0303\n",
      "Epoch 24/200, Iteration 189/250, Loss: 0.0296\n",
      "Epoch 24/200, Iteration 190/250, Loss: 0.0247\n",
      "Epoch 24/200, Iteration 191/250, Loss: 0.0237\n",
      "Epoch 24/200, Iteration 192/250, Loss: 0.0190\n",
      "Epoch 24/200, Iteration 193/250, Loss: 0.0289\n",
      "Epoch 24/200, Iteration 194/250, Loss: 0.0297\n",
      "Epoch 24/200, Iteration 195/250, Loss: 0.0196\n",
      "Epoch 24/200, Iteration 196/250, Loss: 0.0237\n",
      "Epoch 24/200, Iteration 197/250, Loss: 0.0206\n",
      "Epoch 24/200, Iteration 198/250, Loss: 0.0284\n",
      "Epoch 24/200, Iteration 199/250, Loss: 0.0241\n",
      "Epoch 24/200, Iteration 200/250, Loss: 0.0244\n",
      "Epoch 24/200, Iteration 201/250, Loss: 0.0217\n",
      "Epoch 24/200, Iteration 202/250, Loss: 0.0316\n",
      "Epoch 24/200, Iteration 203/250, Loss: 0.0243\n",
      "Epoch 24/200, Iteration 204/250, Loss: 0.0146\n",
      "Epoch 24/200, Iteration 205/250, Loss: 0.0644\n",
      "Epoch 24/200, Iteration 206/250, Loss: 0.0235\n",
      "Epoch 24/200, Iteration 207/250, Loss: 0.0155\n",
      "Epoch 24/200, Iteration 208/250, Loss: 0.0185\n",
      "Epoch 24/200, Iteration 209/250, Loss: 0.0212\n",
      "Epoch 24/200, Iteration 210/250, Loss: 0.0250\n",
      "Epoch 24/200, Iteration 211/250, Loss: 0.0157\n",
      "Epoch 24/200, Iteration 212/250, Loss: 0.0231\n",
      "Epoch 24/200, Iteration 213/250, Loss: 0.0247\n",
      "Epoch 24/200, Iteration 214/250, Loss: 0.0277\n",
      "Epoch 24/200, Iteration 215/250, Loss: 0.0250\n",
      "Epoch 24/200, Iteration 216/250, Loss: 0.0193\n",
      "Epoch 24/200, Iteration 217/250, Loss: 0.0198\n",
      "Epoch 24/200, Iteration 218/250, Loss: 0.0254\n",
      "Epoch 24/200, Iteration 219/250, Loss: 0.0220\n",
      "Epoch 24/200, Iteration 220/250, Loss: 0.0150\n",
      "Epoch 24/200, Iteration 221/250, Loss: 0.0243\n",
      "Epoch 24/200, Iteration 222/250, Loss: 0.0327\n",
      "Epoch 24/200, Iteration 223/250, Loss: 0.0286\n",
      "Epoch 24/200, Iteration 224/250, Loss: 0.0173\n",
      "Epoch 24/200, Iteration 225/250, Loss: 0.0144\n",
      "Epoch 24/200, Iteration 226/250, Loss: 0.0226\n",
      "Epoch 24/200, Iteration 227/250, Loss: 0.0229\n",
      "Epoch 24/200, Iteration 228/250, Loss: 0.0474\n",
      "Epoch 24/200, Iteration 229/250, Loss: 0.0173\n",
      "Epoch 24/200, Iteration 230/250, Loss: 0.0294\n",
      "Epoch 24/200, Iteration 231/250, Loss: 0.0189\n",
      "Epoch 24/200, Iteration 232/250, Loss: 0.0143\n",
      "Epoch 24/200, Iteration 233/250, Loss: 0.0176\n",
      "Epoch 24/200, Iteration 234/250, Loss: 0.0294\n",
      "Epoch 24/200, Iteration 235/250, Loss: 0.0246\n",
      "Epoch 24/200, Iteration 236/250, Loss: 0.0131\n",
      "Epoch 24/200, Iteration 237/250, Loss: 0.0210\n",
      "Epoch 24/200, Iteration 238/250, Loss: 0.0136\n",
      "Epoch 24/200, Iteration 239/250, Loss: 0.0179\n",
      "Epoch 24/200, Iteration 240/250, Loss: 0.0208\n",
      "Epoch 24/200, Iteration 241/250, Loss: 0.0199\n",
      "Epoch 24/200, Iteration 242/250, Loss: 0.0192\n",
      "Epoch 24/200, Iteration 243/250, Loss: 0.0293\n",
      "Epoch 24/200, Iteration 244/250, Loss: 0.0209\n",
      "Epoch 24/200, Iteration 245/250, Loss: 0.0505\n",
      "Epoch 24/200, Iteration 246/250, Loss: 0.0348\n",
      "Epoch 24/200, Iteration 247/250, Loss: 0.0257\n",
      "Epoch 24/200, Iteration 248/250, Loss: 0.0311\n",
      "Epoch 24/200, Iteration 249/250, Loss: 0.0347\n",
      "Epoch 24/200, Iteration 250/250, Loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 70.53%, Avg loss: 0.020995, MRE: 1.628119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.05%, Avg loss: 0.020723, MRE: 1.681922 \n",
      "\n",
      "Epoch 25/200, Iteration 1/250, Loss: 0.0268\n",
      "Epoch 25/200, Iteration 2/250, Loss: 0.0336\n",
      "Epoch 25/200, Iteration 3/250, Loss: 0.0317\n",
      "Epoch 25/200, Iteration 4/250, Loss: 0.0259\n",
      "Epoch 25/200, Iteration 5/250, Loss: 0.0203\n",
      "Epoch 25/200, Iteration 6/250, Loss: 0.0241\n",
      "Epoch 25/200, Iteration 7/250, Loss: 0.0337\n",
      "Epoch 25/200, Iteration 8/250, Loss: 0.0341\n",
      "Epoch 25/200, Iteration 9/250, Loss: 0.0152\n",
      "Epoch 25/200, Iteration 10/250, Loss: 0.0229\n",
      "Epoch 25/200, Iteration 11/250, Loss: 0.0242\n",
      "Epoch 25/200, Iteration 12/250, Loss: 0.0169\n",
      "Epoch 25/200, Iteration 13/250, Loss: 0.0107\n",
      "Epoch 25/200, Iteration 14/250, Loss: 0.0187\n",
      "Epoch 25/200, Iteration 15/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 16/250, Loss: 0.0255\n",
      "Epoch 25/200, Iteration 17/250, Loss: 0.0261\n",
      "Epoch 25/200, Iteration 18/250, Loss: 0.0155\n",
      "Epoch 25/200, Iteration 19/250, Loss: 0.0196\n",
      "Epoch 25/200, Iteration 20/250, Loss: 0.0177\n",
      "Epoch 25/200, Iteration 21/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 22/250, Loss: 0.0459\n",
      "Epoch 25/200, Iteration 23/250, Loss: 0.0244\n",
      "Epoch 25/200, Iteration 24/250, Loss: 0.0351\n",
      "Epoch 25/200, Iteration 25/250, Loss: 0.0215\n",
      "Epoch 25/200, Iteration 26/250, Loss: 0.0177\n",
      "Epoch 25/200, Iteration 27/250, Loss: 0.0221\n",
      "Epoch 25/200, Iteration 28/250, Loss: 0.0150\n",
      "Epoch 25/200, Iteration 29/250, Loss: 0.0307\n",
      "Epoch 25/200, Iteration 30/250, Loss: 0.0258\n",
      "Epoch 25/200, Iteration 31/250, Loss: 0.0261\n",
      "Epoch 25/200, Iteration 32/250, Loss: 0.0255\n",
      "Epoch 25/200, Iteration 33/250, Loss: 0.0289\n",
      "Epoch 25/200, Iteration 34/250, Loss: 0.0306\n",
      "Epoch 25/200, Iteration 35/250, Loss: 0.0319\n",
      "Epoch 25/200, Iteration 36/250, Loss: 0.0205\n",
      "Epoch 25/200, Iteration 37/250, Loss: 0.0193\n",
      "Epoch 25/200, Iteration 38/250, Loss: 0.0268\n",
      "Epoch 25/200, Iteration 39/250, Loss: 0.0224\n",
      "Epoch 25/200, Iteration 40/250, Loss: 0.0351\n",
      "Epoch 25/200, Iteration 41/250, Loss: 0.0294\n",
      "Epoch 25/200, Iteration 42/250, Loss: 0.0371\n",
      "Epoch 25/200, Iteration 43/250, Loss: 0.0264\n",
      "Epoch 25/200, Iteration 44/250, Loss: 0.0261\n",
      "Epoch 25/200, Iteration 45/250, Loss: 0.0304\n",
      "Epoch 25/200, Iteration 46/250, Loss: 0.0248\n",
      "Epoch 25/200, Iteration 47/250, Loss: 0.0236\n",
      "Epoch 25/200, Iteration 48/250, Loss: 0.0191\n",
      "Epoch 25/200, Iteration 49/250, Loss: 0.0286\n",
      "Epoch 25/200, Iteration 50/250, Loss: 0.0309\n",
      "Epoch 25/200, Iteration 51/250, Loss: 0.0291\n",
      "Epoch 25/200, Iteration 52/250, Loss: 0.0208\n",
      "Epoch 25/200, Iteration 53/250, Loss: 0.0249\n",
      "Epoch 25/200, Iteration 54/250, Loss: 0.0311\n",
      "Epoch 25/200, Iteration 55/250, Loss: 0.0419\n",
      "Epoch 25/200, Iteration 56/250, Loss: 0.0257\n",
      "Epoch 25/200, Iteration 57/250, Loss: 0.0240\n",
      "Epoch 25/200, Iteration 58/250, Loss: 0.0201\n",
      "Epoch 25/200, Iteration 59/250, Loss: 0.0254\n",
      "Epoch 25/200, Iteration 60/250, Loss: 0.0198\n",
      "Epoch 25/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 25/200, Iteration 62/250, Loss: 0.0201\n",
      "Epoch 25/200, Iteration 63/250, Loss: 0.0209\n",
      "Epoch 25/200, Iteration 64/250, Loss: 0.0228\n",
      "Epoch 25/200, Iteration 65/250, Loss: 0.0267\n",
      "Epoch 25/200, Iteration 66/250, Loss: 0.0429\n",
      "Epoch 25/200, Iteration 67/250, Loss: 0.0256\n",
      "Epoch 25/200, Iteration 68/250, Loss: 0.0228\n",
      "Epoch 25/200, Iteration 69/250, Loss: 0.0360\n",
      "Epoch 25/200, Iteration 70/250, Loss: 0.0202\n",
      "Epoch 25/200, Iteration 71/250, Loss: 0.0140\n",
      "Epoch 25/200, Iteration 72/250, Loss: 0.0239\n",
      "Epoch 25/200, Iteration 73/250, Loss: 0.0186\n",
      "Epoch 25/200, Iteration 74/250, Loss: 0.0266\n",
      "Epoch 25/200, Iteration 75/250, Loss: 0.0230\n",
      "Epoch 25/200, Iteration 76/250, Loss: 0.0210\n",
      "Epoch 25/200, Iteration 77/250, Loss: 0.0263\n",
      "Epoch 25/200, Iteration 78/250, Loss: 0.0300\n",
      "Epoch 25/200, Iteration 79/250, Loss: 0.0333\n",
      "Epoch 25/200, Iteration 80/250, Loss: 0.0142\n",
      "Epoch 25/200, Iteration 81/250, Loss: 0.0190\n",
      "Epoch 25/200, Iteration 82/250, Loss: 0.0122\n",
      "Epoch 25/200, Iteration 83/250, Loss: 0.0155\n",
      "Epoch 25/200, Iteration 84/250, Loss: 0.0297\n",
      "Epoch 25/200, Iteration 85/250, Loss: 0.0212\n",
      "Epoch 25/200, Iteration 86/250, Loss: 0.0192\n",
      "Epoch 25/200, Iteration 87/250, Loss: 0.0230\n",
      "Epoch 25/200, Iteration 88/250, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 89/250, Loss: 0.0188\n",
      "Epoch 25/200, Iteration 90/250, Loss: 0.0210\n",
      "Epoch 25/200, Iteration 91/250, Loss: 0.0173\n",
      "Epoch 25/200, Iteration 92/250, Loss: 0.0187\n",
      "Epoch 25/200, Iteration 93/250, Loss: 0.0265\n",
      "Epoch 25/200, Iteration 94/250, Loss: 0.0214\n",
      "Epoch 25/200, Iteration 95/250, Loss: 0.0374\n",
      "Epoch 25/200, Iteration 96/250, Loss: 0.0271\n",
      "Epoch 25/200, Iteration 97/250, Loss: 0.0167\n",
      "Epoch 25/200, Iteration 98/250, Loss: 0.0140\n",
      "Epoch 25/200, Iteration 99/250, Loss: 0.0237\n",
      "Epoch 25/200, Iteration 100/250, Loss: 0.0216\n",
      "Epoch 25/200, Iteration 101/250, Loss: 0.0209\n",
      "Epoch 25/200, Iteration 102/250, Loss: 0.0151\n",
      "Epoch 25/200, Iteration 103/250, Loss: 0.0263\n",
      "Epoch 25/200, Iteration 104/250, Loss: 0.0317\n",
      "Epoch 25/200, Iteration 105/250, Loss: 0.0198\n",
      "Epoch 25/200, Iteration 106/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 107/250, Loss: 0.0268\n",
      "Epoch 25/200, Iteration 108/250, Loss: 0.0189\n",
      "Epoch 25/200, Iteration 109/250, Loss: 0.0185\n",
      "Epoch 25/200, Iteration 110/250, Loss: 0.0307\n",
      "Epoch 25/200, Iteration 111/250, Loss: 0.0283\n",
      "Epoch 25/200, Iteration 112/250, Loss: 0.0253\n",
      "Epoch 25/200, Iteration 113/250, Loss: 0.0204\n",
      "Epoch 25/200, Iteration 114/250, Loss: 0.0212\n",
      "Epoch 25/200, Iteration 115/250, Loss: 0.0192\n",
      "Epoch 25/200, Iteration 116/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 117/250, Loss: 0.0291\n",
      "Epoch 25/200, Iteration 118/250, Loss: 0.0294\n",
      "Epoch 25/200, Iteration 119/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 120/250, Loss: 0.0191\n",
      "Epoch 25/200, Iteration 121/250, Loss: 0.0228\n",
      "Epoch 25/200, Iteration 122/250, Loss: 0.0410\n",
      "Epoch 25/200, Iteration 123/250, Loss: 0.0303\n",
      "Epoch 25/200, Iteration 124/250, Loss: 0.0243\n",
      "Epoch 25/200, Iteration 125/250, Loss: 0.0188\n",
      "Epoch 25/200, Iteration 126/250, Loss: 0.0240\n",
      "Epoch 25/200, Iteration 127/250, Loss: 0.0399\n",
      "Epoch 25/200, Iteration 128/250, Loss: 0.0393\n",
      "Epoch 25/200, Iteration 129/250, Loss: 0.0213\n",
      "Epoch 25/200, Iteration 130/250, Loss: 0.0334\n",
      "Epoch 25/200, Iteration 131/250, Loss: 0.0193\n",
      "Epoch 25/200, Iteration 132/250, Loss: 0.0238\n",
      "Epoch 25/200, Iteration 133/250, Loss: 0.0155\n",
      "Epoch 25/200, Iteration 134/250, Loss: 0.0283\n",
      "Epoch 25/200, Iteration 135/250, Loss: 0.0334\n",
      "Epoch 25/200, Iteration 136/250, Loss: 0.0349\n",
      "Epoch 25/200, Iteration 137/250, Loss: 0.0380\n",
      "Epoch 25/200, Iteration 138/250, Loss: 0.0242\n",
      "Epoch 25/200, Iteration 139/250, Loss: 0.0235\n",
      "Epoch 25/200, Iteration 140/250, Loss: 0.0248\n",
      "Epoch 25/200, Iteration 141/250, Loss: 0.0505\n",
      "Epoch 25/200, Iteration 142/250, Loss: 0.0413\n",
      "Epoch 25/200, Iteration 143/250, Loss: 0.0310\n",
      "Epoch 25/200, Iteration 144/250, Loss: 0.0242\n",
      "Epoch 25/200, Iteration 145/250, Loss: 0.0148\n",
      "Epoch 25/200, Iteration 146/250, Loss: 0.0375\n",
      "Epoch 25/200, Iteration 147/250, Loss: 0.0308\n",
      "Epoch 25/200, Iteration 148/250, Loss: 0.0247\n",
      "Epoch 25/200, Iteration 149/250, Loss: 0.0288\n",
      "Epoch 25/200, Iteration 150/250, Loss: 0.0281\n",
      "Epoch 25/200, Iteration 151/250, Loss: 0.0434\n",
      "Epoch 25/200, Iteration 152/250, Loss: 0.0344\n",
      "Epoch 25/200, Iteration 153/250, Loss: 0.0306\n",
      "Epoch 25/200, Iteration 154/250, Loss: 0.0316\n",
      "Epoch 25/200, Iteration 155/250, Loss: 0.0220\n",
      "Epoch 25/200, Iteration 156/250, Loss: 0.0262\n",
      "Epoch 25/200, Iteration 157/250, Loss: 0.0250\n",
      "Epoch 25/200, Iteration 158/250, Loss: 0.0183\n",
      "Epoch 25/200, Iteration 159/250, Loss: 0.0203\n",
      "Epoch 25/200, Iteration 160/250, Loss: 0.0224\n",
      "Epoch 25/200, Iteration 161/250, Loss: 0.0278\n",
      "Epoch 25/200, Iteration 162/250, Loss: 0.0165\n",
      "Epoch 25/200, Iteration 163/250, Loss: 0.0245\n",
      "Epoch 25/200, Iteration 164/250, Loss: 0.0193\n",
      "Epoch 25/200, Iteration 165/250, Loss: 0.0286\n",
      "Epoch 25/200, Iteration 166/250, Loss: 0.0316\n",
      "Epoch 25/200, Iteration 167/250, Loss: 0.0269\n",
      "Epoch 25/200, Iteration 168/250, Loss: 0.0138\n",
      "Epoch 25/200, Iteration 169/250, Loss: 0.0240\n",
      "Epoch 25/200, Iteration 170/250, Loss: 0.0332\n",
      "Epoch 25/200, Iteration 171/250, Loss: 0.0324\n",
      "Epoch 25/200, Iteration 172/250, Loss: 0.0165\n",
      "Epoch 25/200, Iteration 173/250, Loss: 0.0161\n",
      "Epoch 25/200, Iteration 174/250, Loss: 0.0311\n",
      "Epoch 25/200, Iteration 175/250, Loss: 0.0311\n",
      "Epoch 25/200, Iteration 176/250, Loss: 0.0339\n",
      "Epoch 25/200, Iteration 177/250, Loss: 0.0220\n",
      "Epoch 25/200, Iteration 178/250, Loss: 0.0188\n",
      "Epoch 25/200, Iteration 179/250, Loss: 0.0237\n",
      "Epoch 25/200, Iteration 180/250, Loss: 0.0252\n",
      "Epoch 25/200, Iteration 181/250, Loss: 0.0247\n",
      "Epoch 25/200, Iteration 182/250, Loss: 0.0171\n",
      "Epoch 25/200, Iteration 183/250, Loss: 0.0171\n",
      "Epoch 25/200, Iteration 184/250, Loss: 0.0136\n",
      "Epoch 25/200, Iteration 185/250, Loss: 0.0288\n",
      "Epoch 25/200, Iteration 186/250, Loss: 0.0211\n",
      "Epoch 25/200, Iteration 187/250, Loss: 0.0313\n",
      "Epoch 25/200, Iteration 188/250, Loss: 0.0246\n",
      "Epoch 25/200, Iteration 189/250, Loss: 0.0241\n",
      "Epoch 25/200, Iteration 190/250, Loss: 0.0243\n",
      "Epoch 25/200, Iteration 191/250, Loss: 0.0164\n",
      "Epoch 25/200, Iteration 192/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 193/250, Loss: 0.0212\n",
      "Epoch 25/200, Iteration 194/250, Loss: 0.0328\n",
      "Epoch 25/200, Iteration 195/250, Loss: 0.0181\n",
      "Epoch 25/200, Iteration 196/250, Loss: 0.0208\n",
      "Epoch 25/200, Iteration 197/250, Loss: 0.0216\n",
      "Epoch 25/200, Iteration 198/250, Loss: 0.0278\n",
      "Epoch 25/200, Iteration 199/250, Loss: 0.0271\n",
      "Epoch 25/200, Iteration 200/250, Loss: 0.0211\n",
      "Epoch 25/200, Iteration 201/250, Loss: 0.0255\n",
      "Epoch 25/200, Iteration 202/250, Loss: 0.0301\n",
      "Epoch 25/200, Iteration 203/250, Loss: 0.0269\n",
      "Epoch 25/200, Iteration 204/250, Loss: 0.0207\n",
      "Epoch 25/200, Iteration 205/250, Loss: 0.0258\n",
      "Epoch 25/200, Iteration 206/250, Loss: 0.0362\n",
      "Epoch 25/200, Iteration 207/250, Loss: 0.0289\n",
      "Epoch 25/200, Iteration 208/250, Loss: 0.0236\n",
      "Epoch 25/200, Iteration 209/250, Loss: 0.0165\n",
      "Epoch 25/200, Iteration 210/250, Loss: 0.0255\n",
      "Epoch 25/200, Iteration 211/250, Loss: 0.0323\n",
      "Epoch 25/200, Iteration 212/250, Loss: 0.0317\n",
      "Epoch 25/200, Iteration 213/250, Loss: 0.0328\n",
      "Epoch 25/200, Iteration 214/250, Loss: 0.0170\n",
      "Epoch 25/200, Iteration 215/250, Loss: 0.0174\n",
      "Epoch 25/200, Iteration 216/250, Loss: 0.0206\n",
      "Epoch 25/200, Iteration 217/250, Loss: 0.0200\n",
      "Epoch 25/200, Iteration 218/250, Loss: 0.0160\n",
      "Epoch 25/200, Iteration 219/250, Loss: 0.0177\n",
      "Epoch 25/200, Iteration 220/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 221/250, Loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Iteration 222/250, Loss: 0.0186\n",
      "Epoch 25/200, Iteration 223/250, Loss: 0.0160\n",
      "Epoch 25/200, Iteration 224/250, Loss: 0.0248\n",
      "Epoch 25/200, Iteration 225/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 226/250, Loss: 0.0251\n",
      "Epoch 25/200, Iteration 227/250, Loss: 0.0121\n",
      "Epoch 25/200, Iteration 228/250, Loss: 0.0285\n",
      "Epoch 25/200, Iteration 229/250, Loss: 0.0443\n",
      "Epoch 25/200, Iteration 230/250, Loss: 0.0363\n",
      "Epoch 25/200, Iteration 231/250, Loss: 0.0138\n",
      "Epoch 25/200, Iteration 232/250, Loss: 0.0222\n",
      "Epoch 25/200, Iteration 233/250, Loss: 0.0219\n",
      "Epoch 25/200, Iteration 234/250, Loss: 0.0131\n",
      "Epoch 25/200, Iteration 235/250, Loss: 0.0191\n",
      "Epoch 25/200, Iteration 236/250, Loss: 0.0214\n",
      "Epoch 25/200, Iteration 237/250, Loss: 0.0226\n",
      "Epoch 25/200, Iteration 238/250, Loss: 0.0220\n",
      "Epoch 25/200, Iteration 239/250, Loss: 0.0251\n",
      "Epoch 25/200, Iteration 240/250, Loss: 0.0146\n",
      "Epoch 25/200, Iteration 241/250, Loss: 0.0138\n",
      "Epoch 25/200, Iteration 242/250, Loss: 0.0199\n",
      "Epoch 25/200, Iteration 243/250, Loss: 0.0292\n",
      "Epoch 25/200, Iteration 244/250, Loss: 0.0144\n",
      "Epoch 25/200, Iteration 245/250, Loss: 0.0175\n",
      "Epoch 25/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 25/200, Iteration 247/250, Loss: 0.0171\n",
      "Epoch 25/200, Iteration 248/250, Loss: 0.0144\n",
      "Epoch 25/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 25/200, Iteration 250/250, Loss: 0.0335\n",
      "Train Error: \n",
      " Accuracy: 57.38%, Avg loss: 0.024847, MRE: 1.691850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 0.025565, MRE: 2.823207 \n",
      "\n",
      "Epoch 26/200, Iteration 1/250, Loss: 0.0237\n",
      "Epoch 26/200, Iteration 2/250, Loss: 0.0282\n",
      "Epoch 26/200, Iteration 3/250, Loss: 0.0257\n",
      "Epoch 26/200, Iteration 4/250, Loss: 0.0136\n",
      "Epoch 26/200, Iteration 5/250, Loss: 0.0262\n",
      "Epoch 26/200, Iteration 6/250, Loss: 0.0170\n",
      "Epoch 26/200, Iteration 7/250, Loss: 0.0243\n",
      "Epoch 26/200, Iteration 8/250, Loss: 0.0229\n",
      "Epoch 26/200, Iteration 9/250, Loss: 0.0194\n",
      "Epoch 26/200, Iteration 10/250, Loss: 0.0185\n",
      "Epoch 26/200, Iteration 11/250, Loss: 0.0285\n",
      "Epoch 26/200, Iteration 12/250, Loss: 0.0355\n",
      "Epoch 26/200, Iteration 13/250, Loss: 0.0306\n",
      "Epoch 26/200, Iteration 14/250, Loss: 0.0244\n",
      "Epoch 26/200, Iteration 15/250, Loss: 0.0299\n",
      "Epoch 26/200, Iteration 16/250, Loss: 0.0131\n",
      "Epoch 26/200, Iteration 17/250, Loss: 0.0178\n",
      "Epoch 26/200, Iteration 18/250, Loss: 0.0172\n",
      "Epoch 26/200, Iteration 19/250, Loss: 0.0210\n",
      "Epoch 26/200, Iteration 20/250, Loss: 0.0388\n",
      "Epoch 26/200, Iteration 21/250, Loss: 0.0249\n",
      "Epoch 26/200, Iteration 22/250, Loss: 0.0336\n",
      "Epoch 26/200, Iteration 23/250, Loss: 0.0273\n",
      "Epoch 26/200, Iteration 24/250, Loss: 0.0177\n",
      "Epoch 26/200, Iteration 25/250, Loss: 0.0115\n",
      "Epoch 26/200, Iteration 26/250, Loss: 0.0210\n",
      "Epoch 26/200, Iteration 27/250, Loss: 0.0166\n",
      "Epoch 26/200, Iteration 28/250, Loss: 0.0181\n",
      "Epoch 26/200, Iteration 29/250, Loss: 0.0297\n",
      "Epoch 26/200, Iteration 30/250, Loss: 0.0152\n",
      "Epoch 26/200, Iteration 31/250, Loss: 0.0194\n",
      "Epoch 26/200, Iteration 32/250, Loss: 0.0205\n",
      "Epoch 26/200, Iteration 33/250, Loss: 0.0287\n",
      "Epoch 26/200, Iteration 34/250, Loss: 0.0246\n",
      "Epoch 26/200, Iteration 35/250, Loss: 0.0328\n",
      "Epoch 26/200, Iteration 36/250, Loss: 0.0180\n",
      "Epoch 26/200, Iteration 37/250, Loss: 0.0231\n",
      "Epoch 26/200, Iteration 38/250, Loss: 0.0417\n",
      "Epoch 26/200, Iteration 39/250, Loss: 0.0339\n",
      "Epoch 26/200, Iteration 40/250, Loss: 0.0144\n",
      "Epoch 26/200, Iteration 41/250, Loss: 0.0189\n",
      "Epoch 26/200, Iteration 42/250, Loss: 0.0178\n",
      "Epoch 26/200, Iteration 43/250, Loss: 0.0348\n",
      "Epoch 26/200, Iteration 44/250, Loss: 0.0135\n",
      "Epoch 26/200, Iteration 45/250, Loss: 0.0165\n",
      "Epoch 26/200, Iteration 46/250, Loss: 0.0376\n",
      "Epoch 26/200, Iteration 47/250, Loss: 0.0163\n",
      "Epoch 26/200, Iteration 48/250, Loss: 0.0248\n",
      "Epoch 26/200, Iteration 49/250, Loss: 0.0154\n",
      "Epoch 26/200, Iteration 50/250, Loss: 0.0418\n",
      "Epoch 26/200, Iteration 51/250, Loss: 0.0140\n",
      "Epoch 26/200, Iteration 52/250, Loss: 0.0145\n",
      "Epoch 26/200, Iteration 53/250, Loss: 0.0167\n",
      "Epoch 26/200, Iteration 54/250, Loss: 0.0173\n",
      "Epoch 26/200, Iteration 55/250, Loss: 0.0187\n",
      "Epoch 26/200, Iteration 56/250, Loss: 0.0218\n",
      "Epoch 26/200, Iteration 57/250, Loss: 0.0150\n",
      "Epoch 26/200, Iteration 58/250, Loss: 0.0193\n",
      "Epoch 26/200, Iteration 59/250, Loss: 0.0309\n",
      "Epoch 26/200, Iteration 60/250, Loss: 0.0187\n",
      "Epoch 26/200, Iteration 61/250, Loss: 0.0220\n",
      "Epoch 26/200, Iteration 62/250, Loss: 0.0300\n",
      "Epoch 26/200, Iteration 63/250, Loss: 0.0336\n",
      "Epoch 26/200, Iteration 64/250, Loss: 0.0212\n",
      "Epoch 26/200, Iteration 65/250, Loss: 0.0118\n",
      "Epoch 26/200, Iteration 66/250, Loss: 0.0331\n",
      "Epoch 26/200, Iteration 67/250, Loss: 0.0410\n",
      "Epoch 26/200, Iteration 68/250, Loss: 0.0193\n",
      "Epoch 26/200, Iteration 69/250, Loss: 0.0197\n",
      "Epoch 26/200, Iteration 70/250, Loss: 0.0217\n",
      "Epoch 26/200, Iteration 71/250, Loss: 0.0206\n",
      "Epoch 26/200, Iteration 72/250, Loss: 0.0179\n",
      "Epoch 26/200, Iteration 73/250, Loss: 0.0204\n",
      "Epoch 26/200, Iteration 74/250, Loss: 0.0148\n",
      "Epoch 26/200, Iteration 75/250, Loss: 0.0335\n",
      "Epoch 26/200, Iteration 76/250, Loss: 0.0285\n",
      "Epoch 26/200, Iteration 77/250, Loss: 0.0294\n",
      "Epoch 26/200, Iteration 78/250, Loss: 0.0152\n",
      "Epoch 26/200, Iteration 79/250, Loss: 0.0170\n",
      "Epoch 26/200, Iteration 80/250, Loss: 0.0237\n",
      "Epoch 26/200, Iteration 81/250, Loss: 0.0283\n",
      "Epoch 26/200, Iteration 82/250, Loss: 0.0275\n",
      "Epoch 26/200, Iteration 83/250, Loss: 0.0370\n",
      "Epoch 26/200, Iteration 84/250, Loss: 0.0234\n",
      "Epoch 26/200, Iteration 85/250, Loss: 0.0293\n",
      "Epoch 26/200, Iteration 86/250, Loss: 0.0318\n",
      "Epoch 26/200, Iteration 87/250, Loss: 0.0268\n",
      "Epoch 26/200, Iteration 88/250, Loss: 0.0206\n",
      "Epoch 26/200, Iteration 89/250, Loss: 0.0253\n",
      "Epoch 26/200, Iteration 90/250, Loss: 0.0265\n",
      "Epoch 26/200, Iteration 91/250, Loss: 0.0367\n",
      "Epoch 26/200, Iteration 92/250, Loss: 0.0218\n",
      "Epoch 26/200, Iteration 93/250, Loss: 0.0247\n",
      "Epoch 26/200, Iteration 94/250, Loss: 0.0368\n",
      "Epoch 26/200, Iteration 95/250, Loss: 0.0630\n",
      "Epoch 26/200, Iteration 96/250, Loss: 0.0425\n",
      "Epoch 26/200, Iteration 97/250, Loss: 0.0274\n",
      "Epoch 26/200, Iteration 98/250, Loss: 0.0151\n",
      "Epoch 26/200, Iteration 99/250, Loss: 0.0234\n",
      "Epoch 26/200, Iteration 100/250, Loss: 0.0188\n",
      "Epoch 26/200, Iteration 101/250, Loss: 0.0308\n",
      "Epoch 26/200, Iteration 102/250, Loss: 0.0238\n",
      "Epoch 26/200, Iteration 103/250, Loss: 0.0177\n",
      "Epoch 26/200, Iteration 104/250, Loss: 0.0128\n",
      "Epoch 26/200, Iteration 105/250, Loss: 0.0383\n",
      "Epoch 26/200, Iteration 106/250, Loss: 0.0339\n",
      "Epoch 26/200, Iteration 107/250, Loss: 0.0313\n",
      "Epoch 26/200, Iteration 108/250, Loss: 0.0210\n",
      "Epoch 26/200, Iteration 109/250, Loss: 0.0229\n",
      "Epoch 26/200, Iteration 110/250, Loss: 0.0403\n",
      "Epoch 26/200, Iteration 111/250, Loss: 0.0333\n",
      "Epoch 26/200, Iteration 112/250, Loss: 0.0206\n",
      "Epoch 26/200, Iteration 113/250, Loss: 0.0305\n",
      "Epoch 26/200, Iteration 114/250, Loss: 0.0193\n",
      "Epoch 26/200, Iteration 115/250, Loss: 0.0263\n",
      "Epoch 26/200, Iteration 116/250, Loss: 0.0192\n",
      "Epoch 26/200, Iteration 117/250, Loss: 0.0182\n",
      "Epoch 26/200, Iteration 118/250, Loss: 0.0155\n",
      "Epoch 26/200, Iteration 119/250, Loss: 0.0588\n",
      "Epoch 26/200, Iteration 120/250, Loss: 0.0303\n",
      "Epoch 26/200, Iteration 121/250, Loss: 0.0309\n",
      "Epoch 26/200, Iteration 122/250, Loss: 0.0165\n",
      "Epoch 26/200, Iteration 123/250, Loss: 0.0304\n",
      "Epoch 26/200, Iteration 124/250, Loss: 0.0143\n",
      "Epoch 26/200, Iteration 125/250, Loss: 0.0165\n",
      "Epoch 26/200, Iteration 126/250, Loss: 0.0163\n",
      "Epoch 26/200, Iteration 127/250, Loss: 0.0238\n",
      "Epoch 26/200, Iteration 128/250, Loss: 0.0218\n",
      "Epoch 26/200, Iteration 129/250, Loss: 0.0275\n",
      "Epoch 26/200, Iteration 130/250, Loss: 0.0457\n",
      "Epoch 26/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 26/200, Iteration 132/250, Loss: 0.0211\n",
      "Epoch 26/200, Iteration 133/250, Loss: 0.0259\n",
      "Epoch 26/200, Iteration 134/250, Loss: 0.0453\n",
      "Epoch 26/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 26/200, Iteration 136/250, Loss: 0.0188\n",
      "Epoch 26/200, Iteration 137/250, Loss: 0.0242\n",
      "Epoch 26/200, Iteration 138/250, Loss: 0.0243\n",
      "Epoch 26/200, Iteration 139/250, Loss: 0.0187\n",
      "Epoch 26/200, Iteration 140/250, Loss: 0.0168\n",
      "Epoch 26/200, Iteration 141/250, Loss: 0.0243\n",
      "Epoch 26/200, Iteration 142/250, Loss: 0.0260\n",
      "Epoch 26/200, Iteration 143/250, Loss: 0.0184\n",
      "Epoch 26/200, Iteration 144/250, Loss: 0.0169\n",
      "Epoch 26/200, Iteration 145/250, Loss: 0.0231\n",
      "Epoch 26/200, Iteration 146/250, Loss: 0.0117\n",
      "Epoch 26/200, Iteration 147/250, Loss: 0.0186\n",
      "Epoch 26/200, Iteration 148/250, Loss: 0.0127\n",
      "Epoch 26/200, Iteration 149/250, Loss: 0.0239\n",
      "Epoch 26/200, Iteration 150/250, Loss: 0.0373\n",
      "Epoch 26/200, Iteration 151/250, Loss: 0.0300\n",
      "Epoch 26/200, Iteration 152/250, Loss: 0.0251\n",
      "Epoch 26/200, Iteration 153/250, Loss: 0.0254\n",
      "Epoch 26/200, Iteration 154/250, Loss: 0.0218\n",
      "Epoch 26/200, Iteration 155/250, Loss: 0.0205\n",
      "Epoch 26/200, Iteration 156/250, Loss: 0.0241\n",
      "Epoch 26/200, Iteration 157/250, Loss: 0.0154\n",
      "Epoch 26/200, Iteration 158/250, Loss: 0.0198\n",
      "Epoch 26/200, Iteration 159/250, Loss: 0.0138\n",
      "Epoch 26/200, Iteration 160/250, Loss: 0.0178\n",
      "Epoch 26/200, Iteration 161/250, Loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Iteration 162/250, Loss: 0.0334\n",
      "Epoch 26/200, Iteration 163/250, Loss: 0.0297\n",
      "Epoch 26/200, Iteration 164/250, Loss: 0.0160\n",
      "Epoch 26/200, Iteration 165/250, Loss: 0.0154\n",
      "Epoch 26/200, Iteration 166/250, Loss: 0.0340\n",
      "Epoch 26/200, Iteration 167/250, Loss: 0.0284\n",
      "Epoch 26/200, Iteration 168/250, Loss: 0.0364\n",
      "Epoch 26/200, Iteration 169/250, Loss: 0.0162\n",
      "Epoch 26/200, Iteration 170/250, Loss: 0.0222\n",
      "Epoch 26/200, Iteration 171/250, Loss: 0.0273\n",
      "Epoch 26/200, Iteration 172/250, Loss: 0.0264\n",
      "Epoch 26/200, Iteration 173/250, Loss: 0.0251\n",
      "Epoch 26/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 26/200, Iteration 175/250, Loss: 0.0434\n",
      "Epoch 26/200, Iteration 176/250, Loss: 0.0219\n",
      "Epoch 26/200, Iteration 177/250, Loss: 0.0238\n",
      "Epoch 26/200, Iteration 178/250, Loss: 0.0205\n",
      "Epoch 26/200, Iteration 179/250, Loss: 0.0198\n",
      "Epoch 26/200, Iteration 180/250, Loss: 0.0301\n",
      "Epoch 26/200, Iteration 181/250, Loss: 0.0266\n",
      "Epoch 26/200, Iteration 182/250, Loss: 0.0426\n",
      "Epoch 26/200, Iteration 183/250, Loss: 0.0300\n",
      "Epoch 26/200, Iteration 184/250, Loss: 0.0338\n",
      "Epoch 26/200, Iteration 185/250, Loss: 0.0532\n",
      "Epoch 26/200, Iteration 186/250, Loss: 0.0315\n",
      "Epoch 26/200, Iteration 187/250, Loss: 0.0178\n",
      "Epoch 26/200, Iteration 188/250, Loss: 0.0245\n",
      "Epoch 26/200, Iteration 189/250, Loss: 0.0245\n",
      "Epoch 26/200, Iteration 190/250, Loss: 0.0130\n",
      "Epoch 26/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 26/200, Iteration 192/250, Loss: 0.0342\n",
      "Epoch 26/200, Iteration 193/250, Loss: 0.0260\n",
      "Epoch 26/200, Iteration 194/250, Loss: 0.0234\n",
      "Epoch 26/200, Iteration 195/250, Loss: 0.0198\n",
      "Epoch 26/200, Iteration 196/250, Loss: 0.0164\n",
      "Epoch 26/200, Iteration 197/250, Loss: 0.0322\n",
      "Epoch 26/200, Iteration 198/250, Loss: 0.0190\n",
      "Epoch 26/200, Iteration 199/250, Loss: 0.0253\n",
      "Epoch 26/200, Iteration 200/250, Loss: 0.0156\n",
      "Epoch 26/200, Iteration 201/250, Loss: 0.0218\n",
      "Epoch 26/200, Iteration 202/250, Loss: 0.0250\n",
      "Epoch 26/200, Iteration 203/250, Loss: 0.0219\n",
      "Epoch 26/200, Iteration 204/250, Loss: 0.0429\n",
      "Epoch 26/200, Iteration 205/250, Loss: 0.0264\n",
      "Epoch 26/200, Iteration 206/250, Loss: 0.0327\n",
      "Epoch 26/200, Iteration 207/250, Loss: 0.0333\n",
      "Epoch 26/200, Iteration 208/250, Loss: 0.0323\n",
      "Epoch 26/200, Iteration 209/250, Loss: 0.0337\n",
      "Epoch 26/200, Iteration 210/250, Loss: 0.0488\n",
      "Epoch 26/200, Iteration 211/250, Loss: 0.0324\n",
      "Epoch 26/200, Iteration 212/250, Loss: 0.0322\n",
      "Epoch 26/200, Iteration 213/250, Loss: 0.0164\n",
      "Epoch 26/200, Iteration 214/250, Loss: 0.0274\n",
      "Epoch 26/200, Iteration 215/250, Loss: 0.0198\n",
      "Epoch 26/200, Iteration 216/250, Loss: 0.0202\n",
      "Epoch 26/200, Iteration 217/250, Loss: 0.0260\n",
      "Epoch 26/200, Iteration 218/250, Loss: 0.0345\n",
      "Epoch 26/200, Iteration 219/250, Loss: 0.0183\n",
      "Epoch 26/200, Iteration 220/250, Loss: 0.0162\n",
      "Epoch 26/200, Iteration 221/250, Loss: 0.0235\n",
      "Epoch 26/200, Iteration 222/250, Loss: 0.0389\n",
      "Epoch 26/200, Iteration 223/250, Loss: 0.0239\n",
      "Epoch 26/200, Iteration 224/250, Loss: 0.0412\n",
      "Epoch 26/200, Iteration 225/250, Loss: 0.0275\n",
      "Epoch 26/200, Iteration 226/250, Loss: 0.0242\n",
      "Epoch 26/200, Iteration 227/250, Loss: 0.0413\n",
      "Epoch 26/200, Iteration 228/250, Loss: 0.0225\n",
      "Epoch 26/200, Iteration 229/250, Loss: 0.0173\n",
      "Epoch 26/200, Iteration 230/250, Loss: 0.0257\n",
      "Epoch 26/200, Iteration 231/250, Loss: 0.0293\n",
      "Epoch 26/200, Iteration 232/250, Loss: 0.0215\n",
      "Epoch 26/200, Iteration 233/250, Loss: 0.0256\n",
      "Epoch 26/200, Iteration 234/250, Loss: 0.0255\n",
      "Epoch 26/200, Iteration 235/250, Loss: 0.0237\n",
      "Epoch 26/200, Iteration 236/250, Loss: 0.0361\n",
      "Epoch 26/200, Iteration 237/250, Loss: 0.0265\n",
      "Epoch 26/200, Iteration 238/250, Loss: 0.0345\n",
      "Epoch 26/200, Iteration 239/250, Loss: 0.0285\n",
      "Epoch 26/200, Iteration 240/250, Loss: 0.0283\n",
      "Epoch 26/200, Iteration 241/250, Loss: 0.0173\n",
      "Epoch 26/200, Iteration 242/250, Loss: 0.0196\n",
      "Epoch 26/200, Iteration 243/250, Loss: 0.0293\n",
      "Epoch 26/200, Iteration 244/250, Loss: 0.0311\n",
      "Epoch 26/200, Iteration 245/250, Loss: 0.0211\n",
      "Epoch 26/200, Iteration 246/250, Loss: 0.0403\n",
      "Epoch 26/200, Iteration 247/250, Loss: 0.0368\n",
      "Epoch 26/200, Iteration 248/250, Loss: 0.0210\n",
      "Epoch 26/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 26/200, Iteration 250/250, Loss: 0.0235\n",
      "Train Error: \n",
      " Accuracy: 66.06%, Avg loss: 0.027099, MRE: 2.015048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.027836, MRE: 3.044458 \n",
      "\n",
      "Epoch 27/200, Iteration 1/250, Loss: 0.0362\n",
      "Epoch 27/200, Iteration 2/250, Loss: 0.0222\n",
      "Epoch 27/200, Iteration 3/250, Loss: 0.0255\n",
      "Epoch 27/200, Iteration 4/250, Loss: 0.0426\n",
      "Epoch 27/200, Iteration 5/250, Loss: 0.0275\n",
      "Epoch 27/200, Iteration 6/250, Loss: 0.0202\n",
      "Epoch 27/200, Iteration 7/250, Loss: 0.0194\n",
      "Epoch 27/200, Iteration 8/250, Loss: 0.0231\n",
      "Epoch 27/200, Iteration 9/250, Loss: 0.0512\n",
      "Epoch 27/200, Iteration 10/250, Loss: 0.0291\n",
      "Epoch 27/200, Iteration 11/250, Loss: 0.0122\n",
      "Epoch 27/200, Iteration 12/250, Loss: 0.0232\n",
      "Epoch 27/200, Iteration 13/250, Loss: 0.0230\n",
      "Epoch 27/200, Iteration 14/250, Loss: 0.0305\n",
      "Epoch 27/200, Iteration 15/250, Loss: 0.0252\n",
      "Epoch 27/200, Iteration 16/250, Loss: 0.0292\n",
      "Epoch 27/200, Iteration 17/250, Loss: 0.0629\n",
      "Epoch 27/200, Iteration 18/250, Loss: 0.0366\n",
      "Epoch 27/200, Iteration 19/250, Loss: 0.0384\n",
      "Epoch 27/200, Iteration 20/250, Loss: 0.0211\n",
      "Epoch 27/200, Iteration 21/250, Loss: 0.0091\n",
      "Epoch 27/200, Iteration 22/250, Loss: 0.0200\n",
      "Epoch 27/200, Iteration 23/250, Loss: 0.0270\n",
      "Epoch 27/200, Iteration 24/250, Loss: 0.0241\n",
      "Epoch 27/200, Iteration 25/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 26/250, Loss: 0.0147\n",
      "Epoch 27/200, Iteration 27/250, Loss: 0.0162\n",
      "Epoch 27/200, Iteration 28/250, Loss: 0.0389\n",
      "Epoch 27/200, Iteration 29/250, Loss: 0.0272\n",
      "Epoch 27/200, Iteration 30/250, Loss: 0.0193\n",
      "Epoch 27/200, Iteration 31/250, Loss: 0.0323\n",
      "Epoch 27/200, Iteration 32/250, Loss: 0.0222\n",
      "Epoch 27/200, Iteration 33/250, Loss: 0.0404\n",
      "Epoch 27/200, Iteration 34/250, Loss: 0.0167\n",
      "Epoch 27/200, Iteration 35/250, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 36/250, Loss: 0.0230\n",
      "Epoch 27/200, Iteration 37/250, Loss: 0.0174\n",
      "Epoch 27/200, Iteration 38/250, Loss: 0.0162\n",
      "Epoch 27/200, Iteration 39/250, Loss: 0.0144\n",
      "Epoch 27/200, Iteration 40/250, Loss: 0.0108\n",
      "Epoch 27/200, Iteration 41/250, Loss: 0.0164\n",
      "Epoch 27/200, Iteration 42/250, Loss: 0.0191\n",
      "Epoch 27/200, Iteration 43/250, Loss: 0.0306\n",
      "Epoch 27/200, Iteration 44/250, Loss: 0.0110\n",
      "Epoch 27/200, Iteration 45/250, Loss: 0.0284\n",
      "Epoch 27/200, Iteration 46/250, Loss: 0.0136\n",
      "Epoch 27/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 27/200, Iteration 48/250, Loss: 0.0210\n",
      "Epoch 27/200, Iteration 49/250, Loss: 0.0236\n",
      "Epoch 27/200, Iteration 50/250, Loss: 0.0220\n",
      "Epoch 27/200, Iteration 51/250, Loss: 0.0180\n",
      "Epoch 27/200, Iteration 52/250, Loss: 0.0263\n",
      "Epoch 27/200, Iteration 53/250, Loss: 0.0322\n",
      "Epoch 27/200, Iteration 54/250, Loss: 0.0273\n",
      "Epoch 27/200, Iteration 55/250, Loss: 0.0182\n",
      "Epoch 27/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 27/200, Iteration 57/250, Loss: 0.0238\n",
      "Epoch 27/200, Iteration 58/250, Loss: 0.0442\n",
      "Epoch 27/200, Iteration 59/250, Loss: 0.0271\n",
      "Epoch 27/200, Iteration 60/250, Loss: 0.0278\n",
      "Epoch 27/200, Iteration 61/250, Loss: 0.0239\n",
      "Epoch 27/200, Iteration 62/250, Loss: 0.0194\n",
      "Epoch 27/200, Iteration 63/250, Loss: 0.0284\n",
      "Epoch 27/200, Iteration 64/250, Loss: 0.0222\n",
      "Epoch 27/200, Iteration 65/250, Loss: 0.0270\n",
      "Epoch 27/200, Iteration 66/250, Loss: 0.0122\n",
      "Epoch 27/200, Iteration 67/250, Loss: 0.0329\n",
      "Epoch 27/200, Iteration 68/250, Loss: 0.0246\n",
      "Epoch 27/200, Iteration 69/250, Loss: 0.0320\n",
      "Epoch 27/200, Iteration 70/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 71/250, Loss: 0.0238\n",
      "Epoch 27/200, Iteration 72/250, Loss: 0.0357\n",
      "Epoch 27/200, Iteration 73/250, Loss: 0.0210\n",
      "Epoch 27/200, Iteration 74/250, Loss: 0.0208\n",
      "Epoch 27/200, Iteration 75/250, Loss: 0.0269\n",
      "Epoch 27/200, Iteration 76/250, Loss: 0.0257\n",
      "Epoch 27/200, Iteration 77/250, Loss: 0.0235\n",
      "Epoch 27/200, Iteration 78/250, Loss: 0.0236\n",
      "Epoch 27/200, Iteration 79/250, Loss: 0.0191\n",
      "Epoch 27/200, Iteration 80/250, Loss: 0.0142\n",
      "Epoch 27/200, Iteration 81/250, Loss: 0.0155\n",
      "Epoch 27/200, Iteration 82/250, Loss: 0.0152\n",
      "Epoch 27/200, Iteration 83/250, Loss: 0.0137\n",
      "Epoch 27/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 27/200, Iteration 85/250, Loss: 0.0145\n",
      "Epoch 27/200, Iteration 86/250, Loss: 0.0145\n",
      "Epoch 27/200, Iteration 87/250, Loss: 0.0207\n",
      "Epoch 27/200, Iteration 88/250, Loss: 0.0153\n",
      "Epoch 27/200, Iteration 89/250, Loss: 0.0255\n",
      "Epoch 27/200, Iteration 90/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 91/250, Loss: 0.0171\n",
      "Epoch 27/200, Iteration 92/250, Loss: 0.0269\n",
      "Epoch 27/200, Iteration 93/250, Loss: 0.0217\n",
      "Epoch 27/200, Iteration 94/250, Loss: 0.0272\n",
      "Epoch 27/200, Iteration 95/250, Loss: 0.0208\n",
      "Epoch 27/200, Iteration 96/250, Loss: 0.0152\n",
      "Epoch 27/200, Iteration 97/250, Loss: 0.0324\n",
      "Epoch 27/200, Iteration 98/250, Loss: 0.0318\n",
      "Epoch 27/200, Iteration 99/250, Loss: 0.0229\n",
      "Epoch 27/200, Iteration 100/250, Loss: 0.0155\n",
      "Epoch 27/200, Iteration 101/250, Loss: 0.0159\n",
      "Epoch 27/200, Iteration 102/250, Loss: 0.0376\n",
      "Epoch 27/200, Iteration 103/250, Loss: 0.0374\n",
      "Epoch 27/200, Iteration 104/250, Loss: 0.0399\n",
      "Epoch 27/200, Iteration 105/250, Loss: 0.0211\n",
      "Epoch 27/200, Iteration 106/250, Loss: 0.0167\n",
      "Epoch 27/200, Iteration 107/250, Loss: 0.0195\n",
      "Epoch 27/200, Iteration 108/250, Loss: 0.0119\n",
      "Epoch 27/200, Iteration 109/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 110/250, Loss: 0.0250\n",
      "Epoch 27/200, Iteration 111/250, Loss: 0.0159\n",
      "Epoch 27/200, Iteration 112/250, Loss: 0.0190\n",
      "Epoch 27/200, Iteration 113/250, Loss: 0.0195\n",
      "Epoch 27/200, Iteration 114/250, Loss: 0.0214\n",
      "Epoch 27/200, Iteration 115/250, Loss: 0.0313\n",
      "Epoch 27/200, Iteration 116/250, Loss: 0.0225\n",
      "Epoch 27/200, Iteration 117/250, Loss: 0.0247\n",
      "Epoch 27/200, Iteration 118/250, Loss: 0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Iteration 119/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 120/250, Loss: 0.0229\n",
      "Epoch 27/200, Iteration 121/250, Loss: 0.0228\n",
      "Epoch 27/200, Iteration 122/250, Loss: 0.0204\n",
      "Epoch 27/200, Iteration 123/250, Loss: 0.0202\n",
      "Epoch 27/200, Iteration 124/250, Loss: 0.0233\n",
      "Epoch 27/200, Iteration 125/250, Loss: 0.0184\n",
      "Epoch 27/200, Iteration 126/250, Loss: 0.0161\n",
      "Epoch 27/200, Iteration 127/250, Loss: 0.0243\n",
      "Epoch 27/200, Iteration 128/250, Loss: 0.0340\n",
      "Epoch 27/200, Iteration 129/250, Loss: 0.0145\n",
      "Epoch 27/200, Iteration 130/250, Loss: 0.0206\n",
      "Epoch 27/200, Iteration 131/250, Loss: 0.0206\n",
      "Epoch 27/200, Iteration 132/250, Loss: 0.0157\n",
      "Epoch 27/200, Iteration 133/250, Loss: 0.0149\n",
      "Epoch 27/200, Iteration 134/250, Loss: 0.0282\n",
      "Epoch 27/200, Iteration 135/250, Loss: 0.0248\n",
      "Epoch 27/200, Iteration 136/250, Loss: 0.0253\n",
      "Epoch 27/200, Iteration 137/250, Loss: 0.0175\n",
      "Epoch 27/200, Iteration 138/250, Loss: 0.0145\n",
      "Epoch 27/200, Iteration 139/250, Loss: 0.0169\n",
      "Epoch 27/200, Iteration 140/250, Loss: 0.0228\n",
      "Epoch 27/200, Iteration 141/250, Loss: 0.0206\n",
      "Epoch 27/200, Iteration 142/250, Loss: 0.0154\n",
      "Epoch 27/200, Iteration 143/250, Loss: 0.0137\n",
      "Epoch 27/200, Iteration 144/250, Loss: 0.0204\n",
      "Epoch 27/200, Iteration 145/250, Loss: 0.0438\n",
      "Epoch 27/200, Iteration 146/250, Loss: 0.0263\n",
      "Epoch 27/200, Iteration 147/250, Loss: 0.0265\n",
      "Epoch 27/200, Iteration 148/250, Loss: 0.0194\n",
      "Epoch 27/200, Iteration 149/250, Loss: 0.0191\n",
      "Epoch 27/200, Iteration 150/250, Loss: 0.0327\n",
      "Epoch 27/200, Iteration 151/250, Loss: 0.0210\n",
      "Epoch 27/200, Iteration 152/250, Loss: 0.0211\n",
      "Epoch 27/200, Iteration 153/250, Loss: 0.0159\n",
      "Epoch 27/200, Iteration 154/250, Loss: 0.0229\n",
      "Epoch 27/200, Iteration 155/250, Loss: 0.0176\n",
      "Epoch 27/200, Iteration 156/250, Loss: 0.0224\n",
      "Epoch 27/200, Iteration 157/250, Loss: 0.0203\n",
      "Epoch 27/200, Iteration 158/250, Loss: 0.0242\n",
      "Epoch 27/200, Iteration 159/250, Loss: 0.0412\n",
      "Epoch 27/200, Iteration 160/250, Loss: 0.0182\n",
      "Epoch 27/200, Iteration 161/250, Loss: 0.0227\n",
      "Epoch 27/200, Iteration 162/250, Loss: 0.0202\n",
      "Epoch 27/200, Iteration 163/250, Loss: 0.0287\n",
      "Epoch 27/200, Iteration 164/250, Loss: 0.0179\n",
      "Epoch 27/200, Iteration 165/250, Loss: 0.0145\n",
      "Epoch 27/200, Iteration 166/250, Loss: 0.0181\n",
      "Epoch 27/200, Iteration 167/250, Loss: 0.0164\n",
      "Epoch 27/200, Iteration 168/250, Loss: 0.0100\n",
      "Epoch 27/200, Iteration 169/250, Loss: 0.0199\n",
      "Epoch 27/200, Iteration 170/250, Loss: 0.0217\n",
      "Epoch 27/200, Iteration 171/250, Loss: 0.0187\n",
      "Epoch 27/200, Iteration 172/250, Loss: 0.0166\n",
      "Epoch 27/200, Iteration 173/250, Loss: 0.0197\n",
      "Epoch 27/200, Iteration 174/250, Loss: 0.0242\n",
      "Epoch 27/200, Iteration 175/250, Loss: 0.0162\n",
      "Epoch 27/200, Iteration 176/250, Loss: 0.0126\n",
      "Epoch 27/200, Iteration 177/250, Loss: 0.0184\n",
      "Epoch 27/200, Iteration 178/250, Loss: 0.0343\n",
      "Epoch 27/200, Iteration 179/250, Loss: 0.0320\n",
      "Epoch 27/200, Iteration 180/250, Loss: 0.0198\n",
      "Epoch 27/200, Iteration 181/250, Loss: 0.0172\n",
      "Epoch 27/200, Iteration 182/250, Loss: 0.0161\n",
      "Epoch 27/200, Iteration 183/250, Loss: 0.0200\n",
      "Epoch 27/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 27/200, Iteration 185/250, Loss: 0.0247\n",
      "Epoch 27/200, Iteration 186/250, Loss: 0.0168\n",
      "Epoch 27/200, Iteration 187/250, Loss: 0.0278\n",
      "Epoch 27/200, Iteration 188/250, Loss: 0.0277\n",
      "Epoch 27/200, Iteration 189/250, Loss: 0.0175\n",
      "Epoch 27/200, Iteration 190/250, Loss: 0.0180\n",
      "Epoch 27/200, Iteration 191/250, Loss: 0.0301\n",
      "Epoch 27/200, Iteration 192/250, Loss: 0.0202\n",
      "Epoch 27/200, Iteration 193/250, Loss: 0.0315\n",
      "Epoch 27/200, Iteration 194/250, Loss: 0.0302\n",
      "Epoch 27/200, Iteration 195/250, Loss: 0.0302\n",
      "Epoch 27/200, Iteration 196/250, Loss: 0.0192\n",
      "Epoch 27/200, Iteration 197/250, Loss: 0.0423\n",
      "Epoch 27/200, Iteration 198/250, Loss: 0.0258\n",
      "Epoch 27/200, Iteration 199/250, Loss: 0.0296\n",
      "Epoch 27/200, Iteration 200/250, Loss: 0.0280\n",
      "Epoch 27/200, Iteration 201/250, Loss: 0.0247\n",
      "Epoch 27/200, Iteration 202/250, Loss: 0.0231\n",
      "Epoch 27/200, Iteration 203/250, Loss: 0.0177\n",
      "Epoch 27/200, Iteration 204/250, Loss: 0.0275\n",
      "Epoch 27/200, Iteration 205/250, Loss: 0.0210\n",
      "Epoch 27/200, Iteration 206/250, Loss: 0.0215\n",
      "Epoch 27/200, Iteration 207/250, Loss: 0.0190\n",
      "Epoch 27/200, Iteration 208/250, Loss: 0.0147\n",
      "Epoch 27/200, Iteration 209/250, Loss: 0.0188\n",
      "Epoch 27/200, Iteration 210/250, Loss: 0.0226\n",
      "Epoch 27/200, Iteration 211/250, Loss: 0.0309\n",
      "Epoch 27/200, Iteration 212/250, Loss: 0.0114\n",
      "Epoch 27/200, Iteration 213/250, Loss: 0.0317\n",
      "Epoch 27/200, Iteration 214/250, Loss: 0.0201\n",
      "Epoch 27/200, Iteration 215/250, Loss: 0.0135\n",
      "Epoch 27/200, Iteration 216/250, Loss: 0.0310\n",
      "Epoch 27/200, Iteration 217/250, Loss: 0.0373\n",
      "Epoch 27/200, Iteration 218/250, Loss: 0.0248\n",
      "Epoch 27/200, Iteration 219/250, Loss: 0.0232\n",
      "Epoch 27/200, Iteration 220/250, Loss: 0.0223\n",
      "Epoch 27/200, Iteration 221/250, Loss: 0.0136\n",
      "Epoch 27/200, Iteration 222/250, Loss: 0.0266\n",
      "Epoch 27/200, Iteration 223/250, Loss: 0.0213\n",
      "Epoch 27/200, Iteration 224/250, Loss: 0.0216\n",
      "Epoch 27/200, Iteration 225/250, Loss: 0.0207\n",
      "Epoch 27/200, Iteration 226/250, Loss: 0.0253\n",
      "Epoch 27/200, Iteration 227/250, Loss: 0.0149\n",
      "Epoch 27/200, Iteration 228/250, Loss: 0.0260\n",
      "Epoch 27/200, Iteration 229/250, Loss: 0.0336\n",
      "Epoch 27/200, Iteration 230/250, Loss: 0.0177\n",
      "Epoch 27/200, Iteration 231/250, Loss: 0.0148\n",
      "Epoch 27/200, Iteration 232/250, Loss: 0.0264\n",
      "Epoch 27/200, Iteration 233/250, Loss: 0.0250\n",
      "Epoch 27/200, Iteration 234/250, Loss: 0.0146\n",
      "Epoch 27/200, Iteration 235/250, Loss: 0.0168\n",
      "Epoch 27/200, Iteration 236/250, Loss: 0.0231\n",
      "Epoch 27/200, Iteration 237/250, Loss: 0.0261\n",
      "Epoch 27/200, Iteration 238/250, Loss: 0.0253\n",
      "Epoch 27/200, Iteration 239/250, Loss: 0.0253\n",
      "Epoch 27/200, Iteration 240/250, Loss: 0.0185\n",
      "Epoch 27/200, Iteration 241/250, Loss: 0.0139\n",
      "Epoch 27/200, Iteration 242/250, Loss: 0.0250\n",
      "Epoch 27/200, Iteration 243/250, Loss: 0.0244\n",
      "Epoch 27/200, Iteration 244/250, Loss: 0.0219\n",
      "Epoch 27/200, Iteration 245/250, Loss: 0.0264\n",
      "Epoch 27/200, Iteration 246/250, Loss: 0.0206\n",
      "Epoch 27/200, Iteration 247/250, Loss: 0.0166\n",
      "Epoch 27/200, Iteration 248/250, Loss: 0.0150\n",
      "Epoch 27/200, Iteration 249/250, Loss: 0.0150\n",
      "Epoch 27/200, Iteration 250/250, Loss: 0.0167\n",
      "Train Error: \n",
      " Accuracy: 70.86%, Avg loss: 0.018126, MRE: 1.158311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.018708, MRE: 1.811736 \n",
      "\n",
      "Epoch 28/200, Iteration 1/250, Loss: 0.0345\n",
      "Epoch 28/200, Iteration 2/250, Loss: 0.0200\n",
      "Epoch 28/200, Iteration 3/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 4/250, Loss: 0.0293\n",
      "Epoch 28/200, Iteration 5/250, Loss: 0.0228\n",
      "Epoch 28/200, Iteration 6/250, Loss: 0.0207\n",
      "Epoch 28/200, Iteration 7/250, Loss: 0.0304\n",
      "Epoch 28/200, Iteration 8/250, Loss: 0.0181\n",
      "Epoch 28/200, Iteration 9/250, Loss: 0.0263\n",
      "Epoch 28/200, Iteration 10/250, Loss: 0.0204\n",
      "Epoch 28/200, Iteration 11/250, Loss: 0.0309\n",
      "Epoch 28/200, Iteration 12/250, Loss: 0.0216\n",
      "Epoch 28/200, Iteration 13/250, Loss: 0.0229\n",
      "Epoch 28/200, Iteration 14/250, Loss: 0.0129\n",
      "Epoch 28/200, Iteration 15/250, Loss: 0.0184\n",
      "Epoch 28/200, Iteration 16/250, Loss: 0.0322\n",
      "Epoch 28/200, Iteration 17/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 18/250, Loss: 0.0413\n",
      "Epoch 28/200, Iteration 19/250, Loss: 0.0321\n",
      "Epoch 28/200, Iteration 20/250, Loss: 0.0309\n",
      "Epoch 28/200, Iteration 21/250, Loss: 0.0266\n",
      "Epoch 28/200, Iteration 22/250, Loss: 0.0317\n",
      "Epoch 28/200, Iteration 23/250, Loss: 0.0151\n",
      "Epoch 28/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 28/200, Iteration 25/250, Loss: 0.0165\n",
      "Epoch 28/200, Iteration 26/250, Loss: 0.0520\n",
      "Epoch 28/200, Iteration 27/250, Loss: 0.0288\n",
      "Epoch 28/200, Iteration 28/250, Loss: 0.0214\n",
      "Epoch 28/200, Iteration 29/250, Loss: 0.0340\n",
      "Epoch 28/200, Iteration 30/250, Loss: 0.0262\n",
      "Epoch 28/200, Iteration 31/250, Loss: 0.0217\n",
      "Epoch 28/200, Iteration 32/250, Loss: 0.0153\n",
      "Epoch 28/200, Iteration 33/250, Loss: 0.0289\n",
      "Epoch 28/200, Iteration 34/250, Loss: 0.0324\n",
      "Epoch 28/200, Iteration 35/250, Loss: 0.0338\n",
      "Epoch 28/200, Iteration 36/250, Loss: 0.0496\n",
      "Epoch 28/200, Iteration 37/250, Loss: 0.0273\n",
      "Epoch 28/200, Iteration 38/250, Loss: 0.0254\n",
      "Epoch 28/200, Iteration 39/250, Loss: 0.0511\n",
      "Epoch 28/200, Iteration 40/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 41/250, Loss: 0.0186\n",
      "Epoch 28/200, Iteration 42/250, Loss: 0.0169\n",
      "Epoch 28/200, Iteration 43/250, Loss: 0.0222\n",
      "Epoch 28/200, Iteration 44/250, Loss: 0.0254\n",
      "Epoch 28/200, Iteration 45/250, Loss: 0.0327\n",
      "Epoch 28/200, Iteration 46/250, Loss: 0.0221\n",
      "Epoch 28/200, Iteration 47/250, Loss: 0.0201\n",
      "Epoch 28/200, Iteration 48/250, Loss: 0.0291\n",
      "Epoch 28/200, Iteration 49/250, Loss: 0.0313\n",
      "Epoch 28/200, Iteration 50/250, Loss: 0.0261\n",
      "Epoch 28/200, Iteration 51/250, Loss: 0.0263\n",
      "Epoch 28/200, Iteration 52/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 53/250, Loss: 0.0273\n",
      "Epoch 28/200, Iteration 54/250, Loss: 0.0362\n",
      "Epoch 28/200, Iteration 55/250, Loss: 0.0273\n",
      "Epoch 28/200, Iteration 56/250, Loss: 0.0354\n",
      "Epoch 28/200, Iteration 57/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 58/250, Loss: 0.0149\n",
      "Epoch 28/200, Iteration 59/250, Loss: 0.0252\n",
      "Epoch 28/200, Iteration 60/250, Loss: 0.0375\n",
      "Epoch 28/200, Iteration 61/250, Loss: 0.0357\n",
      "Epoch 28/200, Iteration 62/250, Loss: 0.0220\n",
      "Epoch 28/200, Iteration 63/250, Loss: 0.0138\n",
      "Epoch 28/200, Iteration 64/250, Loss: 0.0304\n",
      "Epoch 28/200, Iteration 65/250, Loss: 0.0460\n",
      "Epoch 28/200, Iteration 66/250, Loss: 0.0207\n",
      "Epoch 28/200, Iteration 67/250, Loss: 0.0114\n",
      "Epoch 28/200, Iteration 68/250, Loss: 0.0242\n",
      "Epoch 28/200, Iteration 69/250, Loss: 0.0306\n",
      "Epoch 28/200, Iteration 70/250, Loss: 0.0191\n",
      "Epoch 28/200, Iteration 71/250, Loss: 0.0184\n",
      "Epoch 28/200, Iteration 72/250, Loss: 0.0129\n",
      "Epoch 28/200, Iteration 73/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 74/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 75/250, Loss: 0.0265\n",
      "Epoch 28/200, Iteration 76/250, Loss: 0.0363\n",
      "Epoch 28/200, Iteration 77/250, Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Iteration 78/250, Loss: 0.0197\n",
      "Epoch 28/200, Iteration 79/250, Loss: 0.0161\n",
      "Epoch 28/200, Iteration 80/250, Loss: 0.0183\n",
      "Epoch 28/200, Iteration 81/250, Loss: 0.0166\n",
      "Epoch 28/200, Iteration 82/250, Loss: 0.0220\n",
      "Epoch 28/200, Iteration 83/250, Loss: 0.0290\n",
      "Epoch 28/200, Iteration 84/250, Loss: 0.0279\n",
      "Epoch 28/200, Iteration 85/250, Loss: 0.0295\n",
      "Epoch 28/200, Iteration 86/250, Loss: 0.0305\n",
      "Epoch 28/200, Iteration 87/250, Loss: 0.0309\n",
      "Epoch 28/200, Iteration 88/250, Loss: 0.0324\n",
      "Epoch 28/200, Iteration 89/250, Loss: 0.0151\n",
      "Epoch 28/200, Iteration 90/250, Loss: 0.0410\n",
      "Epoch 28/200, Iteration 91/250, Loss: 0.0243\n",
      "Epoch 28/200, Iteration 92/250, Loss: 0.0215\n",
      "Epoch 28/200, Iteration 93/250, Loss: 0.0168\n",
      "Epoch 28/200, Iteration 94/250, Loss: 0.0322\n",
      "Epoch 28/200, Iteration 95/250, Loss: 0.0289\n",
      "Epoch 28/200, Iteration 96/250, Loss: 0.0224\n",
      "Epoch 28/200, Iteration 97/250, Loss: 0.0195\n",
      "Epoch 28/200, Iteration 98/250, Loss: 0.0206\n",
      "Epoch 28/200, Iteration 99/250, Loss: 0.0262\n",
      "Epoch 28/200, Iteration 100/250, Loss: 0.0305\n",
      "Epoch 28/200, Iteration 101/250, Loss: 0.0268\n",
      "Epoch 28/200, Iteration 102/250, Loss: 0.0317\n",
      "Epoch 28/200, Iteration 103/250, Loss: 0.0368\n",
      "Epoch 28/200, Iteration 104/250, Loss: 0.0360\n",
      "Epoch 28/200, Iteration 105/250, Loss: 0.0311\n",
      "Epoch 28/200, Iteration 106/250, Loss: 0.0218\n",
      "Epoch 28/200, Iteration 107/250, Loss: 0.0242\n",
      "Epoch 28/200, Iteration 108/250, Loss: 0.0259\n",
      "Epoch 28/200, Iteration 109/250, Loss: 0.0221\n",
      "Epoch 28/200, Iteration 110/250, Loss: 0.0233\n",
      "Epoch 28/200, Iteration 111/250, Loss: 0.0218\n",
      "Epoch 28/200, Iteration 112/250, Loss: 0.0370\n",
      "Epoch 28/200, Iteration 113/250, Loss: 0.0290\n",
      "Epoch 28/200, Iteration 114/250, Loss: 0.0279\n",
      "Epoch 28/200, Iteration 115/250, Loss: 0.0361\n",
      "Epoch 28/200, Iteration 116/250, Loss: 0.0305\n",
      "Epoch 28/200, Iteration 117/250, Loss: 0.0257\n",
      "Epoch 28/200, Iteration 118/250, Loss: 0.0351\n",
      "Epoch 28/200, Iteration 119/250, Loss: 0.0262\n",
      "Epoch 28/200, Iteration 120/250, Loss: 0.0304\n",
      "Epoch 28/200, Iteration 121/250, Loss: 0.0189\n",
      "Epoch 28/200, Iteration 122/250, Loss: 0.0170\n",
      "Epoch 28/200, Iteration 123/250, Loss: 0.0290\n",
      "Epoch 28/200, Iteration 124/250, Loss: 0.0228\n",
      "Epoch 28/200, Iteration 125/250, Loss: 0.0283\n",
      "Epoch 28/200, Iteration 126/250, Loss: 0.0240\n",
      "Epoch 28/200, Iteration 127/250, Loss: 0.0205\n",
      "Epoch 28/200, Iteration 128/250, Loss: 0.0330\n",
      "Epoch 28/200, Iteration 129/250, Loss: 0.0369\n",
      "Epoch 28/200, Iteration 130/250, Loss: 0.0229\n",
      "Epoch 28/200, Iteration 131/250, Loss: 0.0213\n",
      "Epoch 28/200, Iteration 132/250, Loss: 0.0196\n",
      "Epoch 28/200, Iteration 133/250, Loss: 0.0216\n",
      "Epoch 28/200, Iteration 134/250, Loss: 0.0206\n",
      "Epoch 28/200, Iteration 135/250, Loss: 0.0185\n",
      "Epoch 28/200, Iteration 136/250, Loss: 0.0277\n",
      "Epoch 28/200, Iteration 137/250, Loss: 0.0249\n",
      "Epoch 28/200, Iteration 138/250, Loss: 0.0231\n",
      "Epoch 28/200, Iteration 139/250, Loss: 0.0273\n",
      "Epoch 28/200, Iteration 140/250, Loss: 0.0167\n",
      "Epoch 28/200, Iteration 141/250, Loss: 0.0159\n",
      "Epoch 28/200, Iteration 142/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 143/250, Loss: 0.0231\n",
      "Epoch 28/200, Iteration 144/250, Loss: 0.0189\n",
      "Epoch 28/200, Iteration 145/250, Loss: 0.0156\n",
      "Epoch 28/200, Iteration 146/250, Loss: 0.0207\n",
      "Epoch 28/200, Iteration 147/250, Loss: 0.0133\n",
      "Epoch 28/200, Iteration 148/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 149/250, Loss: 0.0199\n",
      "Epoch 28/200, Iteration 150/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 151/250, Loss: 0.0117\n",
      "Epoch 28/200, Iteration 152/250, Loss: 0.0272\n",
      "Epoch 28/200, Iteration 153/250, Loss: 0.0294\n",
      "Epoch 28/200, Iteration 154/250, Loss: 0.0194\n",
      "Epoch 28/200, Iteration 155/250, Loss: 0.0225\n",
      "Epoch 28/200, Iteration 156/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 157/250, Loss: 0.0185\n",
      "Epoch 28/200, Iteration 158/250, Loss: 0.0168\n",
      "Epoch 28/200, Iteration 159/250, Loss: 0.0279\n",
      "Epoch 28/200, Iteration 160/250, Loss: 0.0192\n",
      "Epoch 28/200, Iteration 161/250, Loss: 0.0244\n",
      "Epoch 28/200, Iteration 162/250, Loss: 0.0145\n",
      "Epoch 28/200, Iteration 163/250, Loss: 0.0119\n",
      "Epoch 28/200, Iteration 164/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 165/250, Loss: 0.0156\n",
      "Epoch 28/200, Iteration 166/250, Loss: 0.0113\n",
      "Epoch 28/200, Iteration 167/250, Loss: 0.0329\n",
      "Epoch 28/200, Iteration 168/250, Loss: 0.0160\n",
      "Epoch 28/200, Iteration 169/250, Loss: 0.0242\n",
      "Epoch 28/200, Iteration 170/250, Loss: 0.0161\n",
      "Epoch 28/200, Iteration 171/250, Loss: 0.0259\n",
      "Epoch 28/200, Iteration 172/250, Loss: 0.0257\n",
      "Epoch 28/200, Iteration 173/250, Loss: 0.0292\n",
      "Epoch 28/200, Iteration 174/250, Loss: 0.0268\n",
      "Epoch 28/200, Iteration 175/250, Loss: 0.0380\n",
      "Epoch 28/200, Iteration 176/250, Loss: 0.0203\n",
      "Epoch 28/200, Iteration 177/250, Loss: 0.0133\n",
      "Epoch 28/200, Iteration 178/250, Loss: 0.0284\n",
      "Epoch 28/200, Iteration 179/250, Loss: 0.0278\n",
      "Epoch 28/200, Iteration 180/250, Loss: 0.0279\n",
      "Epoch 28/200, Iteration 181/250, Loss: 0.0236\n",
      "Epoch 28/200, Iteration 182/250, Loss: 0.0178\n",
      "Epoch 28/200, Iteration 183/250, Loss: 0.0244\n",
      "Epoch 28/200, Iteration 184/250, Loss: 0.0297\n",
      "Epoch 28/200, Iteration 185/250, Loss: 0.0319\n",
      "Epoch 28/200, Iteration 186/250, Loss: 0.0166\n",
      "Epoch 28/200, Iteration 187/250, Loss: 0.0233\n",
      "Epoch 28/200, Iteration 188/250, Loss: 0.0263\n",
      "Epoch 28/200, Iteration 189/250, Loss: 0.0308\n",
      "Epoch 28/200, Iteration 190/250, Loss: 0.0300\n",
      "Epoch 28/200, Iteration 191/250, Loss: 0.0383\n",
      "Epoch 28/200, Iteration 192/250, Loss: 0.0206\n",
      "Epoch 28/200, Iteration 193/250, Loss: 0.0438\n",
      "Epoch 28/200, Iteration 194/250, Loss: 0.0412\n",
      "Epoch 28/200, Iteration 195/250, Loss: 0.0380\n",
      "Epoch 28/200, Iteration 196/250, Loss: 0.0201\n",
      "Epoch 28/200, Iteration 197/250, Loss: 0.0241\n",
      "Epoch 28/200, Iteration 198/250, Loss: 0.0286\n",
      "Epoch 28/200, Iteration 199/250, Loss: 0.0337\n",
      "Epoch 28/200, Iteration 200/250, Loss: 0.0317\n",
      "Epoch 28/200, Iteration 201/250, Loss: 0.0184\n",
      "Epoch 28/200, Iteration 202/250, Loss: 0.0207\n",
      "Epoch 28/200, Iteration 203/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 204/250, Loss: 0.0505\n",
      "Epoch 28/200, Iteration 205/250, Loss: 0.0309\n",
      "Epoch 28/200, Iteration 206/250, Loss: 0.0193\n",
      "Epoch 28/200, Iteration 207/250, Loss: 0.0246\n",
      "Epoch 28/200, Iteration 208/250, Loss: 0.0514\n",
      "Epoch 28/200, Iteration 209/250, Loss: 0.0328\n",
      "Epoch 28/200, Iteration 210/250, Loss: 0.0342\n",
      "Epoch 28/200, Iteration 211/250, Loss: 0.0252\n",
      "Epoch 28/200, Iteration 212/250, Loss: 0.0283\n",
      "Epoch 28/200, Iteration 213/250, Loss: 0.0326\n",
      "Epoch 28/200, Iteration 214/250, Loss: 0.0342\n",
      "Epoch 28/200, Iteration 215/250, Loss: 0.0367\n",
      "Epoch 28/200, Iteration 216/250, Loss: 0.0265\n",
      "Epoch 28/200, Iteration 217/250, Loss: 0.0392\n",
      "Epoch 28/200, Iteration 218/250, Loss: 0.0432\n",
      "Epoch 28/200, Iteration 219/250, Loss: 0.0317\n",
      "Epoch 28/200, Iteration 220/250, Loss: 0.0298\n",
      "Epoch 28/200, Iteration 221/250, Loss: 0.0280\n",
      "Epoch 28/200, Iteration 222/250, Loss: 0.0251\n",
      "Epoch 28/200, Iteration 223/250, Loss: 0.0271\n",
      "Epoch 28/200, Iteration 224/250, Loss: 0.0187\n",
      "Epoch 28/200, Iteration 225/250, Loss: 0.0230\n",
      "Epoch 28/200, Iteration 226/250, Loss: 0.0217\n",
      "Epoch 28/200, Iteration 227/250, Loss: 0.0350\n",
      "Epoch 28/200, Iteration 228/250, Loss: 0.0294\n",
      "Epoch 28/200, Iteration 229/250, Loss: 0.0310\n",
      "Epoch 28/200, Iteration 230/250, Loss: 0.0185\n",
      "Epoch 28/200, Iteration 231/250, Loss: 0.0312\n",
      "Epoch 28/200, Iteration 232/250, Loss: 0.0324\n",
      "Epoch 28/200, Iteration 233/250, Loss: 0.0365\n",
      "Epoch 28/200, Iteration 234/250, Loss: 0.0241\n",
      "Epoch 28/200, Iteration 235/250, Loss: 0.0229\n",
      "Epoch 28/200, Iteration 236/250, Loss: 0.0206\n",
      "Epoch 28/200, Iteration 237/250, Loss: 0.0270\n",
      "Epoch 28/200, Iteration 238/250, Loss: 0.0370\n",
      "Epoch 28/200, Iteration 239/250, Loss: 0.0406\n",
      "Epoch 28/200, Iteration 240/250, Loss: 0.0294\n",
      "Epoch 28/200, Iteration 241/250, Loss: 0.0238\n",
      "Epoch 28/200, Iteration 242/250, Loss: 0.0205\n",
      "Epoch 28/200, Iteration 243/250, Loss: 0.0243\n",
      "Epoch 28/200, Iteration 244/250, Loss: 0.0361\n",
      "Epoch 28/200, Iteration 245/250, Loss: 0.0341\n",
      "Epoch 28/200, Iteration 246/250, Loss: 0.0260\n",
      "Epoch 28/200, Iteration 247/250, Loss: 0.0123\n",
      "Epoch 28/200, Iteration 248/250, Loss: 0.0271\n",
      "Epoch 28/200, Iteration 249/250, Loss: 0.0250\n",
      "Epoch 28/200, Iteration 250/250, Loss: 0.0289\n",
      "Train Error: \n",
      " Accuracy: 47.36%, Avg loss: 0.029190, MRE: 2.148654 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 0.029638, MRE: 2.927531 \n",
      "\n",
      "Epoch 29/200, Iteration 1/250, Loss: 0.0238\n",
      "Epoch 29/200, Iteration 2/250, Loss: 0.0262\n",
      "Epoch 29/200, Iteration 3/250, Loss: 0.0160\n",
      "Epoch 29/200, Iteration 4/250, Loss: 0.0188\n",
      "Epoch 29/200, Iteration 5/250, Loss: 0.0215\n",
      "Epoch 29/200, Iteration 6/250, Loss: 0.0151\n",
      "Epoch 29/200, Iteration 7/250, Loss: 0.0201\n",
      "Epoch 29/200, Iteration 8/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 9/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 10/250, Loss: 0.0169\n",
      "Epoch 29/200, Iteration 11/250, Loss: 0.0166\n",
      "Epoch 29/200, Iteration 12/250, Loss: 0.0194\n",
      "Epoch 29/200, Iteration 13/250, Loss: 0.0435\n",
      "Epoch 29/200, Iteration 14/250, Loss: 0.0190\n",
      "Epoch 29/200, Iteration 15/250, Loss: 0.0223\n",
      "Epoch 29/200, Iteration 16/250, Loss: 0.0225\n",
      "Epoch 29/200, Iteration 17/250, Loss: 0.0249\n",
      "Epoch 29/200, Iteration 18/250, Loss: 0.0182\n",
      "Epoch 29/200, Iteration 19/250, Loss: 0.0328\n",
      "Epoch 29/200, Iteration 20/250, Loss: 0.0306\n",
      "Epoch 29/200, Iteration 21/250, Loss: 0.0208\n",
      "Epoch 29/200, Iteration 22/250, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Iteration 23/250, Loss: 0.0180\n",
      "Epoch 29/200, Iteration 24/250, Loss: 0.0518\n",
      "Epoch 29/200, Iteration 25/250, Loss: 0.0241\n",
      "Epoch 29/200, Iteration 26/250, Loss: 0.0174\n",
      "Epoch 29/200, Iteration 27/250, Loss: 0.0200\n",
      "Epoch 29/200, Iteration 28/250, Loss: 0.0160\n",
      "Epoch 29/200, Iteration 29/250, Loss: 0.0236\n",
      "Epoch 29/200, Iteration 30/250, Loss: 0.0252\n",
      "Epoch 29/200, Iteration 31/250, Loss: 0.0134\n",
      "Epoch 29/200, Iteration 32/250, Loss: 0.0209\n",
      "Epoch 29/200, Iteration 33/250, Loss: 0.0303\n",
      "Epoch 29/200, Iteration 34/250, Loss: 0.0232\n",
      "Epoch 29/200, Iteration 35/250, Loss: 0.0190\n",
      "Epoch 29/200, Iteration 36/250, Loss: 0.0197\n",
      "Epoch 29/200, Iteration 37/250, Loss: 0.0323\n",
      "Epoch 29/200, Iteration 38/250, Loss: 0.0299\n",
      "Epoch 29/200, Iteration 39/250, Loss: 0.0268\n",
      "Epoch 29/200, Iteration 40/250, Loss: 0.0175\n",
      "Epoch 29/200, Iteration 41/250, Loss: 0.0198\n",
      "Epoch 29/200, Iteration 42/250, Loss: 0.0292\n",
      "Epoch 29/200, Iteration 43/250, Loss: 0.0313\n",
      "Epoch 29/200, Iteration 44/250, Loss: 0.0343\n",
      "Epoch 29/200, Iteration 45/250, Loss: 0.0327\n",
      "Epoch 29/200, Iteration 46/250, Loss: 0.0277\n",
      "Epoch 29/200, Iteration 47/250, Loss: 0.0264\n",
      "Epoch 29/200, Iteration 48/250, Loss: 0.0277\n",
      "Epoch 29/200, Iteration 49/250, Loss: 0.0269\n",
      "Epoch 29/200, Iteration 50/250, Loss: 0.0500\n",
      "Epoch 29/200, Iteration 51/250, Loss: 0.0326\n",
      "Epoch 29/200, Iteration 52/250, Loss: 0.0398\n",
      "Epoch 29/200, Iteration 53/250, Loss: 0.0296\n",
      "Epoch 29/200, Iteration 54/250, Loss: 0.0345\n",
      "Epoch 29/200, Iteration 55/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 56/250, Loss: 0.0185\n",
      "Epoch 29/200, Iteration 57/250, Loss: 0.0344\n",
      "Epoch 29/200, Iteration 58/250, Loss: 0.0344\n",
      "Epoch 29/200, Iteration 59/250, Loss: 0.0242\n",
      "Epoch 29/200, Iteration 60/250, Loss: 0.0172\n",
      "Epoch 29/200, Iteration 61/250, Loss: 0.0202\n",
      "Epoch 29/200, Iteration 62/250, Loss: 0.0240\n",
      "Epoch 29/200, Iteration 63/250, Loss: 0.0349\n",
      "Epoch 29/200, Iteration 64/250, Loss: 0.0186\n",
      "Epoch 29/200, Iteration 65/250, Loss: 0.0230\n",
      "Epoch 29/200, Iteration 66/250, Loss: 0.0269\n",
      "Epoch 29/200, Iteration 67/250, Loss: 0.0221\n",
      "Epoch 29/200, Iteration 68/250, Loss: 0.0245\n",
      "Epoch 29/200, Iteration 69/250, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 70/250, Loss: 0.0258\n",
      "Epoch 29/200, Iteration 71/250, Loss: 0.0436\n",
      "Epoch 29/200, Iteration 72/250, Loss: 0.0336\n",
      "Epoch 29/200, Iteration 73/250, Loss: 0.0357\n",
      "Epoch 29/200, Iteration 74/250, Loss: 0.0231\n",
      "Epoch 29/200, Iteration 75/250, Loss: 0.0208\n",
      "Epoch 29/200, Iteration 76/250, Loss: 0.0224\n",
      "Epoch 29/200, Iteration 77/250, Loss: 0.0274\n",
      "Epoch 29/200, Iteration 78/250, Loss: 0.0256\n",
      "Epoch 29/200, Iteration 79/250, Loss: 0.0281\n",
      "Epoch 29/200, Iteration 80/250, Loss: 0.0188\n",
      "Epoch 29/200, Iteration 81/250, Loss: 0.0297\n",
      "Epoch 29/200, Iteration 82/250, Loss: 0.0173\n",
      "Epoch 29/200, Iteration 83/250, Loss: 0.0192\n",
      "Epoch 29/200, Iteration 84/250, Loss: 0.0174\n",
      "Epoch 29/200, Iteration 85/250, Loss: 0.0206\n",
      "Epoch 29/200, Iteration 86/250, Loss: 0.0257\n",
      "Epoch 29/200, Iteration 87/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 88/250, Loss: 0.0357\n",
      "Epoch 29/200, Iteration 89/250, Loss: 0.0262\n",
      "Epoch 29/200, Iteration 90/250, Loss: 0.0300\n",
      "Epoch 29/200, Iteration 91/250, Loss: 0.0260\n",
      "Epoch 29/200, Iteration 92/250, Loss: 0.0196\n",
      "Epoch 29/200, Iteration 93/250, Loss: 0.0234\n",
      "Epoch 29/200, Iteration 94/250, Loss: 0.0182\n",
      "Epoch 29/200, Iteration 95/250, Loss: 0.0250\n",
      "Epoch 29/200, Iteration 96/250, Loss: 0.0237\n",
      "Epoch 29/200, Iteration 97/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 98/250, Loss: 0.0155\n",
      "Epoch 29/200, Iteration 99/250, Loss: 0.0242\n",
      "Epoch 29/200, Iteration 100/250, Loss: 0.0251\n",
      "Epoch 29/200, Iteration 101/250, Loss: 0.0304\n",
      "Epoch 29/200, Iteration 102/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 103/250, Loss: 0.0266\n",
      "Epoch 29/200, Iteration 104/250, Loss: 0.0521\n",
      "Epoch 29/200, Iteration 105/250, Loss: 0.0278\n",
      "Epoch 29/200, Iteration 106/250, Loss: 0.0161\n",
      "Epoch 29/200, Iteration 107/250, Loss: 0.0139\n",
      "Epoch 29/200, Iteration 108/250, Loss: 0.0314\n",
      "Epoch 29/200, Iteration 109/250, Loss: 0.0211\n",
      "Epoch 29/200, Iteration 110/250, Loss: 0.0259\n",
      "Epoch 29/200, Iteration 111/250, Loss: 0.0222\n",
      "Epoch 29/200, Iteration 112/250, Loss: 0.0130\n",
      "Epoch 29/200, Iteration 113/250, Loss: 0.0195\n",
      "Epoch 29/200, Iteration 114/250, Loss: 0.0295\n",
      "Epoch 29/200, Iteration 115/250, Loss: 0.0312\n",
      "Epoch 29/200, Iteration 116/250, Loss: 0.0256\n",
      "Epoch 29/200, Iteration 117/250, Loss: 0.0267\n",
      "Epoch 29/200, Iteration 118/250, Loss: 0.0145\n",
      "Epoch 29/200, Iteration 119/250, Loss: 0.0256\n",
      "Epoch 29/200, Iteration 120/250, Loss: 0.0251\n",
      "Epoch 29/200, Iteration 121/250, Loss: 0.0225\n",
      "Epoch 29/200, Iteration 122/250, Loss: 0.0220\n",
      "Epoch 29/200, Iteration 123/250, Loss: 0.0231\n",
      "Epoch 29/200, Iteration 124/250, Loss: 0.0212\n",
      "Epoch 29/200, Iteration 125/250, Loss: 0.0276\n",
      "Epoch 29/200, Iteration 126/250, Loss: 0.0277\n",
      "Epoch 29/200, Iteration 127/250, Loss: 0.0210\n",
      "Epoch 29/200, Iteration 128/250, Loss: 0.0169\n",
      "Epoch 29/200, Iteration 129/250, Loss: 0.0275\n",
      "Epoch 29/200, Iteration 130/250, Loss: 0.0264\n",
      "Epoch 29/200, Iteration 131/250, Loss: 0.0160\n",
      "Epoch 29/200, Iteration 132/250, Loss: 0.0180\n",
      "Epoch 29/200, Iteration 133/250, Loss: 0.0234\n",
      "Epoch 29/200, Iteration 134/250, Loss: 0.0170\n",
      "Epoch 29/200, Iteration 135/250, Loss: 0.0261\n",
      "Epoch 29/200, Iteration 136/250, Loss: 0.0286\n",
      "Epoch 29/200, Iteration 137/250, Loss: 0.0247\n",
      "Epoch 29/200, Iteration 138/250, Loss: 0.0179\n",
      "Epoch 29/200, Iteration 139/250, Loss: 0.0264\n",
      "Epoch 29/200, Iteration 140/250, Loss: 0.0435\n",
      "Epoch 29/200, Iteration 141/250, Loss: 0.0187\n",
      "Epoch 29/200, Iteration 142/250, Loss: 0.0246\n",
      "Epoch 29/200, Iteration 143/250, Loss: 0.0316\n",
      "Epoch 29/200, Iteration 144/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 145/250, Loss: 0.0178\n",
      "Epoch 29/200, Iteration 146/250, Loss: 0.0242\n",
      "Epoch 29/200, Iteration 147/250, Loss: 0.0257\n",
      "Epoch 29/200, Iteration 148/250, Loss: 0.0262\n",
      "Epoch 29/200, Iteration 149/250, Loss: 0.0271\n",
      "Epoch 29/200, Iteration 150/250, Loss: 0.0226\n",
      "Epoch 29/200, Iteration 151/250, Loss: 0.0275\n",
      "Epoch 29/200, Iteration 152/250, Loss: 0.0196\n",
      "Epoch 29/200, Iteration 153/250, Loss: 0.0382\n",
      "Epoch 29/200, Iteration 154/250, Loss: 0.0364\n",
      "Epoch 29/200, Iteration 155/250, Loss: 0.0286\n",
      "Epoch 29/200, Iteration 156/250, Loss: 0.0243\n",
      "Epoch 29/200, Iteration 157/250, Loss: 0.0175\n",
      "Epoch 29/200, Iteration 158/250, Loss: 0.0217\n",
      "Epoch 29/200, Iteration 159/250, Loss: 0.0399\n",
      "Epoch 29/200, Iteration 160/250, Loss: 0.0552\n",
      "Epoch 29/200, Iteration 161/250, Loss: 0.0406\n",
      "Epoch 29/200, Iteration 162/250, Loss: 0.0375\n",
      "Epoch 29/200, Iteration 163/250, Loss: 0.0278\n",
      "Epoch 29/200, Iteration 164/250, Loss: 0.0251\n",
      "Epoch 29/200, Iteration 165/250, Loss: 0.0316\n",
      "Epoch 29/200, Iteration 166/250, Loss: 0.0215\n",
      "Epoch 29/200, Iteration 167/250, Loss: 0.0274\n",
      "Epoch 29/200, Iteration 168/250, Loss: 0.0230\n",
      "Epoch 29/200, Iteration 169/250, Loss: 0.0282\n",
      "Epoch 29/200, Iteration 170/250, Loss: 0.0166\n",
      "Epoch 29/200, Iteration 171/250, Loss: 0.0172\n",
      "Epoch 29/200, Iteration 172/250, Loss: 0.0344\n",
      "Epoch 29/200, Iteration 173/250, Loss: 0.0170\n",
      "Epoch 29/200, Iteration 174/250, Loss: 0.0212\n",
      "Epoch 29/200, Iteration 175/250, Loss: 0.0219\n",
      "Epoch 29/200, Iteration 176/250, Loss: 0.0263\n",
      "Epoch 29/200, Iteration 177/250, Loss: 0.0186\n",
      "Epoch 29/200, Iteration 178/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 179/250, Loss: 0.0197\n",
      "Epoch 29/200, Iteration 180/250, Loss: 0.0294\n",
      "Epoch 29/200, Iteration 181/250, Loss: 0.0188\n",
      "Epoch 29/200, Iteration 182/250, Loss: 0.0266\n",
      "Epoch 29/200, Iteration 183/250, Loss: 0.0318\n",
      "Epoch 29/200, Iteration 184/250, Loss: 0.0358\n",
      "Epoch 29/200, Iteration 185/250, Loss: 0.0334\n",
      "Epoch 29/200, Iteration 186/250, Loss: 0.0327\n",
      "Epoch 29/200, Iteration 187/250, Loss: 0.0197\n",
      "Epoch 29/200, Iteration 188/250, Loss: 0.0218\n",
      "Epoch 29/200, Iteration 189/250, Loss: 0.0364\n",
      "Epoch 29/200, Iteration 190/250, Loss: 0.0357\n",
      "Epoch 29/200, Iteration 191/250, Loss: 0.0267\n",
      "Epoch 29/200, Iteration 192/250, Loss: 0.0270\n",
      "Epoch 29/200, Iteration 193/250, Loss: 0.0291\n",
      "Epoch 29/200, Iteration 194/250, Loss: 0.0160\n",
      "Epoch 29/200, Iteration 195/250, Loss: 0.0232\n",
      "Epoch 29/200, Iteration 196/250, Loss: 0.0184\n",
      "Epoch 29/200, Iteration 197/250, Loss: 0.0177\n",
      "Epoch 29/200, Iteration 198/250, Loss: 0.0189\n",
      "Epoch 29/200, Iteration 199/250, Loss: 0.0323\n",
      "Epoch 29/200, Iteration 200/250, Loss: 0.0208\n",
      "Epoch 29/200, Iteration 201/250, Loss: 0.0228\n",
      "Epoch 29/200, Iteration 202/250, Loss: 0.0236\n",
      "Epoch 29/200, Iteration 203/250, Loss: 0.0199\n",
      "Epoch 29/200, Iteration 204/250, Loss: 0.0229\n",
      "Epoch 29/200, Iteration 205/250, Loss: 0.0180\n",
      "Epoch 29/200, Iteration 206/250, Loss: 0.0220\n",
      "Epoch 29/200, Iteration 207/250, Loss: 0.0270\n",
      "Epoch 29/200, Iteration 208/250, Loss: 0.0217\n",
      "Epoch 29/200, Iteration 209/250, Loss: 0.0241\n",
      "Epoch 29/200, Iteration 210/250, Loss: 0.0217\n",
      "Epoch 29/200, Iteration 211/250, Loss: 0.0221\n",
      "Epoch 29/200, Iteration 212/250, Loss: 0.0273\n",
      "Epoch 29/200, Iteration 213/250, Loss: 0.0266\n",
      "Epoch 29/200, Iteration 214/250, Loss: 0.0308\n",
      "Epoch 29/200, Iteration 215/250, Loss: 0.0209\n",
      "Epoch 29/200, Iteration 216/250, Loss: 0.0167\n",
      "Epoch 29/200, Iteration 217/250, Loss: 0.0195\n",
      "Epoch 29/200, Iteration 218/250, Loss: 0.0319\n",
      "Epoch 29/200, Iteration 219/250, Loss: 0.0368\n",
      "Epoch 29/200, Iteration 220/250, Loss: 0.0168\n",
      "Epoch 29/200, Iteration 221/250, Loss: 0.0243\n",
      "Epoch 29/200, Iteration 222/250, Loss: 0.0254\n",
      "Epoch 29/200, Iteration 223/250, Loss: 0.0230\n",
      "Epoch 29/200, Iteration 224/250, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Iteration 225/250, Loss: 0.0176\n",
      "Epoch 29/200, Iteration 226/250, Loss: 0.0239\n",
      "Epoch 29/200, Iteration 227/250, Loss: 0.0215\n",
      "Epoch 29/200, Iteration 228/250, Loss: 0.0400\n",
      "Epoch 29/200, Iteration 229/250, Loss: 0.0212\n",
      "Epoch 29/200, Iteration 230/250, Loss: 0.0307\n",
      "Epoch 29/200, Iteration 231/250, Loss: 0.0259\n",
      "Epoch 29/200, Iteration 232/250, Loss: 0.0204\n",
      "Epoch 29/200, Iteration 233/250, Loss: 0.0199\n",
      "Epoch 29/200, Iteration 234/250, Loss: 0.0250\n",
      "Epoch 29/200, Iteration 235/250, Loss: 0.0221\n",
      "Epoch 29/200, Iteration 236/250, Loss: 0.0385\n",
      "Epoch 29/200, Iteration 237/250, Loss: 0.0357\n",
      "Epoch 29/200, Iteration 238/250, Loss: 0.0187\n",
      "Epoch 29/200, Iteration 239/250, Loss: 0.0344\n",
      "Epoch 29/200, Iteration 240/250, Loss: 0.0454\n",
      "Epoch 29/200, Iteration 241/250, Loss: 0.0254\n",
      "Epoch 29/200, Iteration 242/250, Loss: 0.0349\n",
      "Epoch 29/200, Iteration 243/250, Loss: 0.0180\n",
      "Epoch 29/200, Iteration 244/250, Loss: 0.0184\n",
      "Epoch 29/200, Iteration 245/250, Loss: 0.0176\n",
      "Epoch 29/200, Iteration 246/250, Loss: 0.0232\n",
      "Epoch 29/200, Iteration 247/250, Loss: 0.0288\n",
      "Epoch 29/200, Iteration 248/250, Loss: 0.0236\n",
      "Epoch 29/200, Iteration 249/250, Loss: 0.0172\n",
      "Epoch 29/200, Iteration 250/250, Loss: 0.0266\n",
      "Train Error: \n",
      " Accuracy: 81.92%, Avg loss: 0.017329, MRE: 1.140707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.95%, Avg loss: 0.017492, MRE: 2.383566 \n",
      "\n",
      "Epoch 30/200, Iteration 1/250, Loss: 0.0182\n",
      "Epoch 30/200, Iteration 2/250, Loss: 0.0136\n",
      "Epoch 30/200, Iteration 3/250, Loss: 0.0191\n",
      "Epoch 30/200, Iteration 4/250, Loss: 0.0177\n",
      "Epoch 30/200, Iteration 5/250, Loss: 0.0191\n",
      "Epoch 30/200, Iteration 6/250, Loss: 0.0421\n",
      "Epoch 30/200, Iteration 7/250, Loss: 0.0158\n",
      "Epoch 30/200, Iteration 8/250, Loss: 0.0221\n",
      "Epoch 30/200, Iteration 9/250, Loss: 0.0199\n",
      "Epoch 30/200, Iteration 10/250, Loss: 0.0219\n",
      "Epoch 30/200, Iteration 11/250, Loss: 0.0149\n",
      "Epoch 30/200, Iteration 12/250, Loss: 0.0231\n",
      "Epoch 30/200, Iteration 13/250, Loss: 0.0244\n",
      "Epoch 30/200, Iteration 14/250, Loss: 0.0247\n",
      "Epoch 30/200, Iteration 15/250, Loss: 0.0268\n",
      "Epoch 30/200, Iteration 16/250, Loss: 0.0370\n",
      "Epoch 30/200, Iteration 17/250, Loss: 0.0206\n",
      "Epoch 30/200, Iteration 18/250, Loss: 0.0235\n",
      "Epoch 30/200, Iteration 19/250, Loss: 0.0315\n",
      "Epoch 30/200, Iteration 20/250, Loss: 0.0254\n",
      "Epoch 30/200, Iteration 21/250, Loss: 0.0234\n",
      "Epoch 30/200, Iteration 22/250, Loss: 0.0251\n",
      "Epoch 30/200, Iteration 23/250, Loss: 0.0266\n",
      "Epoch 30/200, Iteration 24/250, Loss: 0.0402\n",
      "Epoch 30/200, Iteration 25/250, Loss: 0.0397\n",
      "Epoch 30/200, Iteration 26/250, Loss: 0.0161\n",
      "Epoch 30/200, Iteration 27/250, Loss: 0.0281\n",
      "Epoch 30/200, Iteration 28/250, Loss: 0.0363\n",
      "Epoch 30/200, Iteration 29/250, Loss: 0.0269\n",
      "Epoch 30/200, Iteration 30/250, Loss: 0.0451\n",
      "Epoch 30/200, Iteration 31/250, Loss: 0.0222\n",
      "Epoch 30/200, Iteration 32/250, Loss: 0.0232\n",
      "Epoch 30/200, Iteration 33/250, Loss: 0.0227\n",
      "Epoch 30/200, Iteration 34/250, Loss: 0.0253\n",
      "Epoch 30/200, Iteration 35/250, Loss: 0.0304\n",
      "Epoch 30/200, Iteration 36/250, Loss: 0.0279\n",
      "Epoch 30/200, Iteration 37/250, Loss: 0.0207\n",
      "Epoch 30/200, Iteration 38/250, Loss: 0.0256\n",
      "Epoch 30/200, Iteration 39/250, Loss: 0.0291\n",
      "Epoch 30/200, Iteration 40/250, Loss: 0.0320\n",
      "Epoch 30/200, Iteration 41/250, Loss: 0.0386\n",
      "Epoch 30/200, Iteration 42/250, Loss: 0.0221\n",
      "Epoch 30/200, Iteration 43/250, Loss: 0.0273\n",
      "Epoch 30/200, Iteration 44/250, Loss: 0.0144\n",
      "Epoch 30/200, Iteration 45/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 46/250, Loss: 0.0354\n",
      "Epoch 30/200, Iteration 47/250, Loss: 0.0220\n",
      "Epoch 30/200, Iteration 48/250, Loss: 0.0242\n",
      "Epoch 30/200, Iteration 49/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 50/250, Loss: 0.0182\n",
      "Epoch 30/200, Iteration 51/250, Loss: 0.0211\n",
      "Epoch 30/200, Iteration 52/250, Loss: 0.0242\n",
      "Epoch 30/200, Iteration 53/250, Loss: 0.0369\n",
      "Epoch 30/200, Iteration 54/250, Loss: 0.0333\n",
      "Epoch 30/200, Iteration 55/250, Loss: 0.0432\n",
      "Epoch 30/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 30/200, Iteration 57/250, Loss: 0.0133\n",
      "Epoch 30/200, Iteration 58/250, Loss: 0.0205\n",
      "Epoch 30/200, Iteration 59/250, Loss: 0.0451\n",
      "Epoch 30/200, Iteration 60/250, Loss: 0.0288\n",
      "Epoch 30/200, Iteration 61/250, Loss: 0.0173\n",
      "Epoch 30/200, Iteration 62/250, Loss: 0.0286\n",
      "Epoch 30/200, Iteration 63/250, Loss: 0.0322\n",
      "Epoch 30/200, Iteration 64/250, Loss: 0.0358\n",
      "Epoch 30/200, Iteration 65/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 66/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 67/250, Loss: 0.0320\n",
      "Epoch 30/200, Iteration 68/250, Loss: 0.0328\n",
      "Epoch 30/200, Iteration 69/250, Loss: 0.0251\n",
      "Epoch 30/200, Iteration 70/250, Loss: 0.0299\n",
      "Epoch 30/200, Iteration 71/250, Loss: 0.0248\n",
      "Epoch 30/200, Iteration 72/250, Loss: 0.0342\n",
      "Epoch 30/200, Iteration 73/250, Loss: 0.0146\n",
      "Epoch 30/200, Iteration 74/250, Loss: 0.0507\n",
      "Epoch 30/200, Iteration 75/250, Loss: 0.0285\n",
      "Epoch 30/200, Iteration 76/250, Loss: 0.0264\n",
      "Epoch 30/200, Iteration 77/250, Loss: 0.0205\n",
      "Epoch 30/200, Iteration 78/250, Loss: 0.0179\n",
      "Epoch 30/200, Iteration 79/250, Loss: 0.0259\n",
      "Epoch 30/200, Iteration 80/250, Loss: 0.0276\n",
      "Epoch 30/200, Iteration 81/250, Loss: 0.0410\n",
      "Epoch 30/200, Iteration 82/250, Loss: 0.0315\n",
      "Epoch 30/200, Iteration 83/250, Loss: 0.0194\n",
      "Epoch 30/200, Iteration 84/250, Loss: 0.0321\n",
      "Epoch 30/200, Iteration 85/250, Loss: 0.0327\n",
      "Epoch 30/200, Iteration 86/250, Loss: 0.0308\n",
      "Epoch 30/200, Iteration 87/250, Loss: 0.0309\n",
      "Epoch 30/200, Iteration 88/250, Loss: 0.0191\n",
      "Epoch 30/200, Iteration 89/250, Loss: 0.0242\n",
      "Epoch 30/200, Iteration 90/250, Loss: 0.0296\n",
      "Epoch 30/200, Iteration 91/250, Loss: 0.0389\n",
      "Epoch 30/200, Iteration 92/250, Loss: 0.0311\n",
      "Epoch 30/200, Iteration 93/250, Loss: 0.0184\n",
      "Epoch 30/200, Iteration 94/250, Loss: 0.0233\n",
      "Epoch 30/200, Iteration 95/250, Loss: 0.0326\n",
      "Epoch 30/200, Iteration 96/250, Loss: 0.0388\n",
      "Epoch 30/200, Iteration 97/250, Loss: 0.0332\n",
      "Epoch 30/200, Iteration 98/250, Loss: 0.0338\n",
      "Epoch 30/200, Iteration 99/250, Loss: 0.0229\n",
      "Epoch 30/200, Iteration 100/250, Loss: 0.0185\n",
      "Epoch 30/200, Iteration 101/250, Loss: 0.0224\n",
      "Epoch 30/200, Iteration 102/250, Loss: 0.0184\n",
      "Epoch 30/200, Iteration 103/250, Loss: 0.0202\n",
      "Epoch 30/200, Iteration 104/250, Loss: 0.0162\n",
      "Epoch 30/200, Iteration 105/250, Loss: 0.0144\n",
      "Epoch 30/200, Iteration 106/250, Loss: 0.0294\n",
      "Epoch 30/200, Iteration 107/250, Loss: 0.0207\n",
      "Epoch 30/200, Iteration 108/250, Loss: 0.0180\n",
      "Epoch 30/200, Iteration 109/250, Loss: 0.0220\n",
      "Epoch 30/200, Iteration 110/250, Loss: 0.0226\n",
      "Epoch 30/200, Iteration 111/250, Loss: 0.0212\n",
      "Epoch 30/200, Iteration 112/250, Loss: 0.0278\n",
      "Epoch 30/200, Iteration 113/250, Loss: 0.0292\n",
      "Epoch 30/200, Iteration 114/250, Loss: 0.0271\n",
      "Epoch 30/200, Iteration 115/250, Loss: 0.0260\n",
      "Epoch 30/200, Iteration 116/250, Loss: 0.0167\n",
      "Epoch 30/200, Iteration 117/250, Loss: 0.0304\n",
      "Epoch 30/200, Iteration 118/250, Loss: 0.0168\n",
      "Epoch 30/200, Iteration 119/250, Loss: 0.0204\n",
      "Epoch 30/200, Iteration 120/250, Loss: 0.0315\n",
      "Epoch 30/200, Iteration 121/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 122/250, Loss: 0.0329\n",
      "Epoch 30/200, Iteration 123/250, Loss: 0.0163\n",
      "Epoch 30/200, Iteration 124/250, Loss: 0.0199\n",
      "Epoch 30/200, Iteration 125/250, Loss: 0.0156\n",
      "Epoch 30/200, Iteration 126/250, Loss: 0.0363\n",
      "Epoch 30/200, Iteration 127/250, Loss: 0.0216\n",
      "Epoch 30/200, Iteration 128/250, Loss: 0.0212\n",
      "Epoch 30/200, Iteration 129/250, Loss: 0.0257\n",
      "Epoch 30/200, Iteration 130/250, Loss: 0.0183\n",
      "Epoch 30/200, Iteration 131/250, Loss: 0.0157\n",
      "Epoch 30/200, Iteration 132/250, Loss: 0.0194\n",
      "Epoch 30/200, Iteration 133/250, Loss: 0.0168\n",
      "Epoch 30/200, Iteration 134/250, Loss: 0.0121\n",
      "Epoch 30/200, Iteration 135/250, Loss: 0.0203\n",
      "Epoch 30/200, Iteration 136/250, Loss: 0.0252\n",
      "Epoch 30/200, Iteration 137/250, Loss: 0.0210\n",
      "Epoch 30/200, Iteration 138/250, Loss: 0.0326\n",
      "Epoch 30/200, Iteration 139/250, Loss: 0.0136\n",
      "Epoch 30/200, Iteration 140/250, Loss: 0.0187\n",
      "Epoch 30/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 30/200, Iteration 142/250, Loss: 0.0367\n",
      "Epoch 30/200, Iteration 143/250, Loss: 0.0144\n",
      "Epoch 30/200, Iteration 144/250, Loss: 0.0404\n",
      "Epoch 30/200, Iteration 145/250, Loss: 0.0297\n",
      "Epoch 30/200, Iteration 146/250, Loss: 0.0324\n",
      "Epoch 30/200, Iteration 147/250, Loss: 0.0134\n",
      "Epoch 30/200, Iteration 148/250, Loss: 0.0263\n",
      "Epoch 30/200, Iteration 149/250, Loss: 0.0240\n",
      "Epoch 30/200, Iteration 150/250, Loss: 0.0223\n",
      "Epoch 30/200, Iteration 151/250, Loss: 0.0149\n",
      "Epoch 30/200, Iteration 152/250, Loss: 0.0245\n",
      "Epoch 30/200, Iteration 153/250, Loss: 0.0237\n",
      "Epoch 30/200, Iteration 154/250, Loss: 0.0427\n",
      "Epoch 30/200, Iteration 155/250, Loss: 0.0367\n",
      "Epoch 30/200, Iteration 156/250, Loss: 0.0414\n",
      "Epoch 30/200, Iteration 157/250, Loss: 0.0322\n",
      "Epoch 30/200, Iteration 158/250, Loss: 0.0214\n",
      "Epoch 30/200, Iteration 159/250, Loss: 0.0285\n",
      "Epoch 30/200, Iteration 160/250, Loss: 0.0238\n",
      "Epoch 30/200, Iteration 161/250, Loss: 0.0307\n",
      "Epoch 30/200, Iteration 162/250, Loss: 0.0349\n",
      "Epoch 30/200, Iteration 163/250, Loss: 0.0181\n",
      "Epoch 30/200, Iteration 164/250, Loss: 0.0305\n",
      "Epoch 30/200, Iteration 165/250, Loss: 0.0279\n",
      "Epoch 30/200, Iteration 166/250, Loss: 0.0251\n",
      "Epoch 30/200, Iteration 167/250, Loss: 0.0287\n",
      "Epoch 30/200, Iteration 168/250, Loss: 0.0189\n",
      "Epoch 30/200, Iteration 169/250, Loss: 0.0298\n",
      "Epoch 30/200, Iteration 170/250, Loss: 0.0238\n",
      "Epoch 30/200, Iteration 171/250, Loss: 0.0274\n",
      "Epoch 30/200, Iteration 172/250, Loss: 0.0243\n",
      "Epoch 30/200, Iteration 173/250, Loss: 0.0243\n",
      "Epoch 30/200, Iteration 174/250, Loss: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Iteration 175/250, Loss: 0.0231\n",
      "Epoch 30/200, Iteration 176/250, Loss: 0.0220\n",
      "Epoch 30/200, Iteration 177/250, Loss: 0.0228\n",
      "Epoch 30/200, Iteration 178/250, Loss: 0.0218\n",
      "Epoch 30/200, Iteration 179/250, Loss: 0.0364\n",
      "Epoch 30/200, Iteration 180/250, Loss: 0.0335\n",
      "Epoch 30/200, Iteration 181/250, Loss: 0.0229\n",
      "Epoch 30/200, Iteration 182/250, Loss: 0.0282\n",
      "Epoch 30/200, Iteration 183/250, Loss: 0.0281\n",
      "Epoch 30/200, Iteration 184/250, Loss: 0.0166\n",
      "Epoch 30/200, Iteration 185/250, Loss: 0.0413\n",
      "Epoch 30/200, Iteration 186/250, Loss: 0.0290\n",
      "Epoch 30/200, Iteration 187/250, Loss: 0.0245\n",
      "Epoch 30/200, Iteration 188/250, Loss: 0.0317\n",
      "Epoch 30/200, Iteration 189/250, Loss: 0.0213\n",
      "Epoch 30/200, Iteration 190/250, Loss: 0.0275\n",
      "Epoch 30/200, Iteration 191/250, Loss: 0.0256\n",
      "Epoch 30/200, Iteration 192/250, Loss: 0.0334\n",
      "Epoch 30/200, Iteration 193/250, Loss: 0.0257\n",
      "Epoch 30/200, Iteration 194/250, Loss: 0.0304\n",
      "Epoch 30/200, Iteration 195/250, Loss: 0.0292\n",
      "Epoch 30/200, Iteration 196/250, Loss: 0.0241\n",
      "Epoch 30/200, Iteration 197/250, Loss: 0.0299\n",
      "Epoch 30/200, Iteration 198/250, Loss: 0.0325\n",
      "Epoch 30/200, Iteration 199/250, Loss: 0.0225\n",
      "Epoch 30/200, Iteration 200/250, Loss: 0.0305\n",
      "Epoch 30/200, Iteration 201/250, Loss: 0.0153\n",
      "Epoch 30/200, Iteration 202/250, Loss: 0.0182\n",
      "Epoch 30/200, Iteration 203/250, Loss: 0.0175\n",
      "Epoch 30/200, Iteration 204/250, Loss: 0.0187\n",
      "Epoch 30/200, Iteration 205/250, Loss: 0.0192\n",
      "Epoch 30/200, Iteration 206/250, Loss: 0.0266\n",
      "Epoch 30/200, Iteration 207/250, Loss: 0.0307\n",
      "Epoch 30/200, Iteration 208/250, Loss: 0.0228\n",
      "Epoch 30/200, Iteration 209/250, Loss: 0.0522\n",
      "Epoch 30/200, Iteration 210/250, Loss: 0.0322\n",
      "Epoch 30/200, Iteration 211/250, Loss: 0.0136\n",
      "Epoch 30/200, Iteration 212/250, Loss: 0.0247\n",
      "Epoch 30/200, Iteration 213/250, Loss: 0.0209\n",
      "Epoch 30/200, Iteration 214/250, Loss: 0.0157\n",
      "Epoch 30/200, Iteration 215/250, Loss: 0.0189\n",
      "Epoch 30/200, Iteration 216/250, Loss: 0.0148\n",
      "Epoch 30/200, Iteration 217/250, Loss: 0.0174\n",
      "Epoch 30/200, Iteration 218/250, Loss: 0.0171\n",
      "Epoch 30/200, Iteration 219/250, Loss: 0.0156\n",
      "Epoch 30/200, Iteration 220/250, Loss: 0.0160\n",
      "Epoch 30/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 30/200, Iteration 222/250, Loss: 0.0198\n",
      "Epoch 30/200, Iteration 223/250, Loss: 0.0137\n",
      "Epoch 30/200, Iteration 224/250, Loss: 0.0208\n",
      "Epoch 30/200, Iteration 225/250, Loss: 0.0152\n",
      "Epoch 30/200, Iteration 226/250, Loss: 0.0226\n",
      "Epoch 30/200, Iteration 227/250, Loss: 0.0136\n",
      "Epoch 30/200, Iteration 228/250, Loss: 0.0160\n",
      "Epoch 30/200, Iteration 229/250, Loss: 0.0123\n",
      "Epoch 30/200, Iteration 230/250, Loss: 0.0233\n",
      "Epoch 30/200, Iteration 231/250, Loss: 0.0367\n",
      "Epoch 30/200, Iteration 232/250, Loss: 0.0348\n",
      "Epoch 30/200, Iteration 233/250, Loss: 0.0167\n",
      "Epoch 30/200, Iteration 234/250, Loss: 0.0286\n",
      "Epoch 30/200, Iteration 235/250, Loss: 0.0323\n",
      "Epoch 30/200, Iteration 236/250, Loss: 0.0402\n",
      "Epoch 30/200, Iteration 237/250, Loss: 0.0387\n",
      "Epoch 30/200, Iteration 238/250, Loss: 0.0368\n",
      "Epoch 30/200, Iteration 239/250, Loss: 0.0327\n",
      "Epoch 30/200, Iteration 240/250, Loss: 0.0247\n",
      "Epoch 30/200, Iteration 241/250, Loss: 0.0230\n",
      "Epoch 30/200, Iteration 242/250, Loss: 0.0395\n",
      "Epoch 30/200, Iteration 243/250, Loss: 0.0262\n",
      "Epoch 30/200, Iteration 244/250, Loss: 0.0244\n",
      "Epoch 30/200, Iteration 245/250, Loss: 0.0161\n",
      "Epoch 30/200, Iteration 246/250, Loss: 0.0313\n",
      "Epoch 30/200, Iteration 247/250, Loss: 0.0406\n",
      "Epoch 30/200, Iteration 248/250, Loss: 0.0518\n",
      "Epoch 30/200, Iteration 249/250, Loss: 0.0318\n",
      "Epoch 30/200, Iteration 250/250, Loss: 0.0268\n",
      "Train Error: \n",
      " Accuracy: 62.58%, Avg loss: 0.018167, MRE: 1.804423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.85%, Avg loss: 0.018277, MRE: 1.471788 \n",
      "\n",
      "Epoch 31/200, Iteration 1/250, Loss: 0.0167\n",
      "Epoch 31/200, Iteration 2/250, Loss: 0.0416\n",
      "Epoch 31/200, Iteration 3/250, Loss: 0.0258\n",
      "Epoch 31/200, Iteration 4/250, Loss: 0.0286\n",
      "Epoch 31/200, Iteration 5/250, Loss: 0.0402\n",
      "Epoch 31/200, Iteration 6/250, Loss: 0.0180\n",
      "Epoch 31/200, Iteration 7/250, Loss: 0.0185\n",
      "Epoch 31/200, Iteration 8/250, Loss: 0.0308\n",
      "Epoch 31/200, Iteration 9/250, Loss: 0.0384\n",
      "Epoch 31/200, Iteration 10/250, Loss: 0.0470\n",
      "Epoch 31/200, Iteration 11/250, Loss: 0.0206\n",
      "Epoch 31/200, Iteration 12/250, Loss: 0.0171\n",
      "Epoch 31/200, Iteration 13/250, Loss: 0.0173\n",
      "Epoch 31/200, Iteration 14/250, Loss: 0.0235\n",
      "Epoch 31/200, Iteration 15/250, Loss: 0.0231\n",
      "Epoch 31/200, Iteration 16/250, Loss: 0.0314\n",
      "Epoch 31/200, Iteration 17/250, Loss: 0.0251\n",
      "Epoch 31/200, Iteration 18/250, Loss: 0.0258\n",
      "Epoch 31/200, Iteration 19/250, Loss: 0.0137\n",
      "Epoch 31/200, Iteration 20/250, Loss: 0.0276\n",
      "Epoch 31/200, Iteration 21/250, Loss: 0.0128\n",
      "Epoch 31/200, Iteration 22/250, Loss: 0.0272\n",
      "Epoch 31/200, Iteration 23/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 24/250, Loss: 0.0133\n",
      "Epoch 31/200, Iteration 25/250, Loss: 0.0202\n",
      "Epoch 31/200, Iteration 26/250, Loss: 0.0203\n",
      "Epoch 31/200, Iteration 27/250, Loss: 0.0170\n",
      "Epoch 31/200, Iteration 28/250, Loss: 0.0221\n",
      "Epoch 31/200, Iteration 29/250, Loss: 0.0229\n",
      "Epoch 31/200, Iteration 30/250, Loss: 0.0201\n",
      "Epoch 31/200, Iteration 31/250, Loss: 0.0366\n",
      "Epoch 31/200, Iteration 32/250, Loss: 0.0174\n",
      "Epoch 31/200, Iteration 33/250, Loss: 0.0264\n",
      "Epoch 31/200, Iteration 34/250, Loss: 0.0171\n",
      "Epoch 31/200, Iteration 35/250, Loss: 0.0184\n",
      "Epoch 31/200, Iteration 36/250, Loss: 0.0180\n",
      "Epoch 31/200, Iteration 37/250, Loss: 0.0289\n",
      "Epoch 31/200, Iteration 38/250, Loss: 0.0291\n",
      "Epoch 31/200, Iteration 39/250, Loss: 0.0231\n",
      "Epoch 31/200, Iteration 40/250, Loss: 0.0213\n",
      "Epoch 31/200, Iteration 41/250, Loss: 0.0152\n",
      "Epoch 31/200, Iteration 42/250, Loss: 0.0182\n",
      "Epoch 31/200, Iteration 43/250, Loss: 0.0185\n",
      "Epoch 31/200, Iteration 44/250, Loss: 0.0132\n",
      "Epoch 31/200, Iteration 45/250, Loss: 0.0184\n",
      "Epoch 31/200, Iteration 46/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 47/250, Loss: 0.0218\n",
      "Epoch 31/200, Iteration 48/250, Loss: 0.0176\n",
      "Epoch 31/200, Iteration 49/250, Loss: 0.0274\n",
      "Epoch 31/200, Iteration 50/250, Loss: 0.0140\n",
      "Epoch 31/200, Iteration 51/250, Loss: 0.0190\n",
      "Epoch 31/200, Iteration 52/250, Loss: 0.0294\n",
      "Epoch 31/200, Iteration 53/250, Loss: 0.0113\n",
      "Epoch 31/200, Iteration 54/250, Loss: 0.0198\n",
      "Epoch 31/200, Iteration 55/250, Loss: 0.0222\n",
      "Epoch 31/200, Iteration 56/250, Loss: 0.0211\n",
      "Epoch 31/200, Iteration 57/250, Loss: 0.0338\n",
      "Epoch 31/200, Iteration 58/250, Loss: 0.0232\n",
      "Epoch 31/200, Iteration 59/250, Loss: 0.0123\n",
      "Epoch 31/200, Iteration 60/250, Loss: 0.0179\n",
      "Epoch 31/200, Iteration 61/250, Loss: 0.0196\n",
      "Epoch 31/200, Iteration 62/250, Loss: 0.0198\n",
      "Epoch 31/200, Iteration 63/250, Loss: 0.0249\n",
      "Epoch 31/200, Iteration 64/250, Loss: 0.0279\n",
      "Epoch 31/200, Iteration 65/250, Loss: 0.0257\n",
      "Epoch 31/200, Iteration 66/250, Loss: 0.0240\n",
      "Epoch 31/200, Iteration 67/250, Loss: 0.0435\n",
      "Epoch 31/200, Iteration 68/250, Loss: 0.0321\n",
      "Epoch 31/200, Iteration 69/250, Loss: 0.0221\n",
      "Epoch 31/200, Iteration 70/250, Loss: 0.0219\n",
      "Epoch 31/200, Iteration 71/250, Loss: 0.0330\n",
      "Epoch 31/200, Iteration 72/250, Loss: 0.0194\n",
      "Epoch 31/200, Iteration 73/250, Loss: 0.0144\n",
      "Epoch 31/200, Iteration 74/250, Loss: 0.0320\n",
      "Epoch 31/200, Iteration 75/250, Loss: 0.0381\n",
      "Epoch 31/200, Iteration 76/250, Loss: 0.0398\n",
      "Epoch 31/200, Iteration 77/250, Loss: 0.0276\n",
      "Epoch 31/200, Iteration 78/250, Loss: 0.0257\n",
      "Epoch 31/200, Iteration 79/250, Loss: 0.0186\n",
      "Epoch 31/200, Iteration 80/250, Loss: 0.0345\n",
      "Epoch 31/200, Iteration 81/250, Loss: 0.0322\n",
      "Epoch 31/200, Iteration 82/250, Loss: 0.0257\n",
      "Epoch 31/200, Iteration 83/250, Loss: 0.0284\n",
      "Epoch 31/200, Iteration 84/250, Loss: 0.0392\n",
      "Epoch 31/200, Iteration 85/250, Loss: 0.0216\n",
      "Epoch 31/200, Iteration 86/250, Loss: 0.0357\n",
      "Epoch 31/200, Iteration 87/250, Loss: 0.0488\n",
      "Epoch 31/200, Iteration 88/250, Loss: 0.0271\n",
      "Epoch 31/200, Iteration 89/250, Loss: 0.0282\n",
      "Epoch 31/200, Iteration 90/250, Loss: 0.0417\n",
      "Epoch 31/200, Iteration 91/250, Loss: 0.0203\n",
      "Epoch 31/200, Iteration 92/250, Loss: 0.0263\n",
      "Epoch 31/200, Iteration 93/250, Loss: 0.0286\n",
      "Epoch 31/200, Iteration 94/250, Loss: 0.0322\n",
      "Epoch 31/200, Iteration 95/250, Loss: 0.0160\n",
      "Epoch 31/200, Iteration 96/250, Loss: 0.0195\n",
      "Epoch 31/200, Iteration 97/250, Loss: 0.0283\n",
      "Epoch 31/200, Iteration 98/250, Loss: 0.0239\n",
      "Epoch 31/200, Iteration 99/250, Loss: 0.0238\n",
      "Epoch 31/200, Iteration 100/250, Loss: 0.0201\n",
      "Epoch 31/200, Iteration 101/250, Loss: 0.0168\n",
      "Epoch 31/200, Iteration 102/250, Loss: 0.0170\n",
      "Epoch 31/200, Iteration 103/250, Loss: 0.0164\n",
      "Epoch 31/200, Iteration 104/250, Loss: 0.0134\n",
      "Epoch 31/200, Iteration 105/250, Loss: 0.0212\n",
      "Epoch 31/200, Iteration 106/250, Loss: 0.0180\n",
      "Epoch 31/200, Iteration 107/250, Loss: 0.0212\n",
      "Epoch 31/200, Iteration 108/250, Loss: 0.0253\n",
      "Epoch 31/200, Iteration 109/250, Loss: 0.0212\n",
      "Epoch 31/200, Iteration 110/250, Loss: 0.0176\n",
      "Epoch 31/200, Iteration 111/250, Loss: 0.0136\n",
      "Epoch 31/200, Iteration 112/250, Loss: 0.0223\n",
      "Epoch 31/200, Iteration 113/250, Loss: 0.0177\n",
      "Epoch 31/200, Iteration 114/250, Loss: 0.0174\n",
      "Epoch 31/200, Iteration 115/250, Loss: 0.0329\n",
      "Epoch 31/200, Iteration 116/250, Loss: 0.0196\n",
      "Epoch 31/200, Iteration 117/250, Loss: 0.0184\n",
      "Epoch 31/200, Iteration 118/250, Loss: 0.0271\n",
      "Epoch 31/200, Iteration 119/250, Loss: 0.0152\n",
      "Epoch 31/200, Iteration 120/250, Loss: 0.0237\n",
      "Epoch 31/200, Iteration 121/250, Loss: 0.0181\n",
      "Epoch 31/200, Iteration 122/250, Loss: 0.0130\n",
      "Epoch 31/200, Iteration 123/250, Loss: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Iteration 124/250, Loss: 0.0498\n",
      "Epoch 31/200, Iteration 125/250, Loss: 0.0279\n",
      "Epoch 31/200, Iteration 126/250, Loss: 0.0208\n",
      "Epoch 31/200, Iteration 127/250, Loss: 0.0223\n",
      "Epoch 31/200, Iteration 128/250, Loss: 0.0197\n",
      "Epoch 31/200, Iteration 129/250, Loss: 0.0263\n",
      "Epoch 31/200, Iteration 130/250, Loss: 0.0216\n",
      "Epoch 31/200, Iteration 131/250, Loss: 0.0155\n",
      "Epoch 31/200, Iteration 132/250, Loss: 0.0194\n",
      "Epoch 31/200, Iteration 133/250, Loss: 0.0168\n",
      "Epoch 31/200, Iteration 134/250, Loss: 0.0200\n",
      "Epoch 31/200, Iteration 135/250, Loss: 0.0212\n",
      "Epoch 31/200, Iteration 136/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 137/250, Loss: 0.0253\n",
      "Epoch 31/200, Iteration 138/250, Loss: 0.0303\n",
      "Epoch 31/200, Iteration 139/250, Loss: 0.0384\n",
      "Epoch 31/200, Iteration 140/250, Loss: 0.0157\n",
      "Epoch 31/200, Iteration 141/250, Loss: 0.0157\n",
      "Epoch 31/200, Iteration 142/250, Loss: 0.0176\n",
      "Epoch 31/200, Iteration 143/250, Loss: 0.0269\n",
      "Epoch 31/200, Iteration 144/250, Loss: 0.0156\n",
      "Epoch 31/200, Iteration 145/250, Loss: 0.0210\n",
      "Epoch 31/200, Iteration 146/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 147/250, Loss: 0.0446\n",
      "Epoch 31/200, Iteration 148/250, Loss: 0.0142\n",
      "Epoch 31/200, Iteration 149/250, Loss: 0.0179\n",
      "Epoch 31/200, Iteration 150/250, Loss: 0.0380\n",
      "Epoch 31/200, Iteration 151/250, Loss: 0.0255\n",
      "Epoch 31/200, Iteration 152/250, Loss: 0.0227\n",
      "Epoch 31/200, Iteration 153/250, Loss: 0.0250\n",
      "Epoch 31/200, Iteration 154/250, Loss: 0.0241\n",
      "Epoch 31/200, Iteration 155/250, Loss: 0.0280\n",
      "Epoch 31/200, Iteration 156/250, Loss: 0.0231\n",
      "Epoch 31/200, Iteration 157/250, Loss: 0.0223\n",
      "Epoch 31/200, Iteration 158/250, Loss: 0.0266\n",
      "Epoch 31/200, Iteration 159/250, Loss: 0.0350\n",
      "Epoch 31/200, Iteration 160/250, Loss: 0.0289\n",
      "Epoch 31/200, Iteration 161/250, Loss: 0.0299\n",
      "Epoch 31/200, Iteration 162/250, Loss: 0.0255\n",
      "Epoch 31/200, Iteration 163/250, Loss: 0.0246\n",
      "Epoch 31/200, Iteration 164/250, Loss: 0.0660\n",
      "Epoch 31/200, Iteration 165/250, Loss: 0.0679\n",
      "Epoch 31/200, Iteration 166/250, Loss: 0.0490\n",
      "Epoch 31/200, Iteration 167/250, Loss: 0.0264\n",
      "Epoch 31/200, Iteration 168/250, Loss: 0.0237\n",
      "Epoch 31/200, Iteration 169/250, Loss: 0.0258\n",
      "Epoch 31/200, Iteration 170/250, Loss: 0.0339\n",
      "Epoch 31/200, Iteration 171/250, Loss: 0.0496\n",
      "Epoch 31/200, Iteration 172/250, Loss: 0.0430\n",
      "Epoch 31/200, Iteration 173/250, Loss: 0.0317\n",
      "Epoch 31/200, Iteration 174/250, Loss: 0.0360\n",
      "Epoch 31/200, Iteration 175/250, Loss: 0.0330\n",
      "Epoch 31/200, Iteration 176/250, Loss: 0.0324\n",
      "Epoch 31/200, Iteration 177/250, Loss: 0.0308\n",
      "Epoch 31/200, Iteration 178/250, Loss: 0.0264\n",
      "Epoch 31/200, Iteration 179/250, Loss: 0.0263\n",
      "Epoch 31/200, Iteration 180/250, Loss: 0.0407\n",
      "Epoch 31/200, Iteration 181/250, Loss: 0.0309\n",
      "Epoch 31/200, Iteration 182/250, Loss: 0.0142\n",
      "Epoch 31/200, Iteration 183/250, Loss: 0.0213\n",
      "Epoch 31/200, Iteration 184/250, Loss: 0.0306\n",
      "Epoch 31/200, Iteration 185/250, Loss: 0.0394\n",
      "Epoch 31/200, Iteration 186/250, Loss: 0.0220\n",
      "Epoch 31/200, Iteration 187/250, Loss: 0.0253\n",
      "Epoch 31/200, Iteration 188/250, Loss: 0.0354\n",
      "Epoch 31/200, Iteration 189/250, Loss: 0.0327\n",
      "Epoch 31/200, Iteration 190/250, Loss: 0.0195\n",
      "Epoch 31/200, Iteration 191/250, Loss: 0.0137\n",
      "Epoch 31/200, Iteration 192/250, Loss: 0.0234\n",
      "Epoch 31/200, Iteration 193/250, Loss: 0.0345\n",
      "Epoch 31/200, Iteration 194/250, Loss: 0.0236\n",
      "Epoch 31/200, Iteration 195/250, Loss: 0.0245\n",
      "Epoch 31/200, Iteration 196/250, Loss: 0.0208\n",
      "Epoch 31/200, Iteration 197/250, Loss: 0.0294\n",
      "Epoch 31/200, Iteration 198/250, Loss: 0.0224\n",
      "Epoch 31/200, Iteration 199/250, Loss: 0.0148\n",
      "Epoch 31/200, Iteration 200/250, Loss: 0.0137\n",
      "Epoch 31/200, Iteration 201/250, Loss: 0.0254\n",
      "Epoch 31/200, Iteration 202/250, Loss: 0.0269\n",
      "Epoch 31/200, Iteration 203/250, Loss: 0.0258\n",
      "Epoch 31/200, Iteration 204/250, Loss: 0.0223\n",
      "Epoch 31/200, Iteration 205/250, Loss: 0.0382\n",
      "Epoch 31/200, Iteration 206/250, Loss: 0.0314\n",
      "Epoch 31/200, Iteration 207/250, Loss: 0.0213\n",
      "Epoch 31/200, Iteration 208/250, Loss: 0.0214\n",
      "Epoch 31/200, Iteration 209/250, Loss: 0.0206\n",
      "Epoch 31/200, Iteration 210/250, Loss: 0.0272\n",
      "Epoch 31/200, Iteration 211/250, Loss: 0.0228\n",
      "Epoch 31/200, Iteration 212/250, Loss: 0.0353\n",
      "Epoch 31/200, Iteration 213/250, Loss: 0.0206\n",
      "Epoch 31/200, Iteration 214/250, Loss: 0.0258\n",
      "Epoch 31/200, Iteration 215/250, Loss: 0.0218\n",
      "Epoch 31/200, Iteration 216/250, Loss: 0.0172\n",
      "Epoch 31/200, Iteration 217/250, Loss: 0.0178\n",
      "Epoch 31/200, Iteration 218/250, Loss: 0.0215\n",
      "Epoch 31/200, Iteration 219/250, Loss: 0.0257\n",
      "Epoch 31/200, Iteration 220/250, Loss: 0.0383\n",
      "Epoch 31/200, Iteration 221/250, Loss: 0.0282\n",
      "Epoch 31/200, Iteration 222/250, Loss: 0.0310\n",
      "Epoch 31/200, Iteration 223/250, Loss: 0.0309\n",
      "Epoch 31/200, Iteration 224/250, Loss: 0.0362\n",
      "Epoch 31/200, Iteration 225/250, Loss: 0.0192\n",
      "Epoch 31/200, Iteration 226/250, Loss: 0.0340\n",
      "Epoch 31/200, Iteration 227/250, Loss: 0.0392\n",
      "Epoch 31/200, Iteration 228/250, Loss: 0.0379\n",
      "Epoch 31/200, Iteration 229/250, Loss: 0.0281\n",
      "Epoch 31/200, Iteration 230/250, Loss: 0.0238\n",
      "Epoch 31/200, Iteration 231/250, Loss: 0.0273\n",
      "Epoch 31/200, Iteration 232/250, Loss: 0.0357\n",
      "Epoch 31/200, Iteration 233/250, Loss: 0.0305\n",
      "Epoch 31/200, Iteration 234/250, Loss: 0.0199\n",
      "Epoch 31/200, Iteration 235/250, Loss: 0.0214\n",
      "Epoch 31/200, Iteration 236/250, Loss: 0.0255\n",
      "Epoch 31/200, Iteration 237/250, Loss: 0.0321\n",
      "Epoch 31/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 31/200, Iteration 239/250, Loss: 0.0214\n",
      "Epoch 31/200, Iteration 240/250, Loss: 0.0464\n",
      "Epoch 31/200, Iteration 241/250, Loss: 0.0438\n",
      "Epoch 31/200, Iteration 242/250, Loss: 0.0250\n",
      "Epoch 31/200, Iteration 243/250, Loss: 0.0385\n",
      "Epoch 31/200, Iteration 244/250, Loss: 0.0233\n",
      "Epoch 31/200, Iteration 245/250, Loss: 0.0365\n",
      "Epoch 31/200, Iteration 246/250, Loss: 0.0401\n",
      "Epoch 31/200, Iteration 247/250, Loss: 0.0263\n",
      "Epoch 31/200, Iteration 248/250, Loss: 0.0218\n",
      "Epoch 31/200, Iteration 249/250, Loss: 0.0174\n",
      "Epoch 31/200, Iteration 250/250, Loss: 0.0305\n",
      "Train Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.033103, MRE: 2.747494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.034071, MRE: 3.137283 \n",
      "\n",
      "Epoch 32/200, Iteration 1/250, Loss: 0.0320\n",
      "Epoch 32/200, Iteration 2/250, Loss: 0.0487\n",
      "Epoch 32/200, Iteration 3/250, Loss: 0.0359\n",
      "Epoch 32/200, Iteration 4/250, Loss: 0.0266\n",
      "Epoch 32/200, Iteration 5/250, Loss: 0.0179\n",
      "Epoch 32/200, Iteration 6/250, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 7/250, Loss: 0.0166\n",
      "Epoch 32/200, Iteration 8/250, Loss: 0.0201\n",
      "Epoch 32/200, Iteration 9/250, Loss: 0.0218\n",
      "Epoch 32/200, Iteration 10/250, Loss: 0.0170\n",
      "Epoch 32/200, Iteration 11/250, Loss: 0.0185\n",
      "Epoch 32/200, Iteration 12/250, Loss: 0.0378\n",
      "Epoch 32/200, Iteration 13/250, Loss: 0.0260\n",
      "Epoch 32/200, Iteration 14/250, Loss: 0.0309\n",
      "Epoch 32/200, Iteration 15/250, Loss: 0.0180\n",
      "Epoch 32/200, Iteration 16/250, Loss: 0.0205\n",
      "Epoch 32/200, Iteration 17/250, Loss: 0.0197\n",
      "Epoch 32/200, Iteration 18/250, Loss: 0.0226\n",
      "Epoch 32/200, Iteration 19/250, Loss: 0.0308\n",
      "Epoch 32/200, Iteration 20/250, Loss: 0.0228\n",
      "Epoch 32/200, Iteration 21/250, Loss: 0.0203\n",
      "Epoch 32/200, Iteration 22/250, Loss: 0.0345\n",
      "Epoch 32/200, Iteration 23/250, Loss: 0.0447\n",
      "Epoch 32/200, Iteration 24/250, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 25/250, Loss: 0.0162\n",
      "Epoch 32/200, Iteration 26/250, Loss: 0.0299\n",
      "Epoch 32/200, Iteration 27/250, Loss: 0.0196\n",
      "Epoch 32/200, Iteration 28/250, Loss: 0.0156\n",
      "Epoch 32/200, Iteration 29/250, Loss: 0.0260\n",
      "Epoch 32/200, Iteration 30/250, Loss: 0.0143\n",
      "Epoch 32/200, Iteration 31/250, Loss: 0.0403\n",
      "Epoch 32/200, Iteration 32/250, Loss: 0.0333\n",
      "Epoch 32/200, Iteration 33/250, Loss: 0.0407\n",
      "Epoch 32/200, Iteration 34/250, Loss: 0.0180\n",
      "Epoch 32/200, Iteration 35/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 36/250, Loss: 0.0223\n",
      "Epoch 32/200, Iteration 37/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 38/250, Loss: 0.0317\n",
      "Epoch 32/200, Iteration 39/250, Loss: 0.0240\n",
      "Epoch 32/200, Iteration 40/250, Loss: 0.0220\n",
      "Epoch 32/200, Iteration 41/250, Loss: 0.0178\n",
      "Epoch 32/200, Iteration 42/250, Loss: 0.0263\n",
      "Epoch 32/200, Iteration 43/250, Loss: 0.0267\n",
      "Epoch 32/200, Iteration 44/250, Loss: 0.0238\n",
      "Epoch 32/200, Iteration 45/250, Loss: 0.0155\n",
      "Epoch 32/200, Iteration 46/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 47/250, Loss: 0.0242\n",
      "Epoch 32/200, Iteration 48/250, Loss: 0.0188\n",
      "Epoch 32/200, Iteration 49/250, Loss: 0.0193\n",
      "Epoch 32/200, Iteration 50/250, Loss: 0.0245\n",
      "Epoch 32/200, Iteration 51/250, Loss: 0.0255\n",
      "Epoch 32/200, Iteration 52/250, Loss: 0.0327\n",
      "Epoch 32/200, Iteration 53/250, Loss: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Iteration 54/250, Loss: 0.0419\n",
      "Epoch 32/200, Iteration 55/250, Loss: 0.0467\n",
      "Epoch 32/200, Iteration 56/250, Loss: 0.0153\n",
      "Epoch 32/200, Iteration 57/250, Loss: 0.0495\n",
      "Epoch 32/200, Iteration 58/250, Loss: 0.0374\n",
      "Epoch 32/200, Iteration 59/250, Loss: 0.0247\n",
      "Epoch 32/200, Iteration 60/250, Loss: 0.0206\n",
      "Epoch 32/200, Iteration 61/250, Loss: 0.0295\n",
      "Epoch 32/200, Iteration 62/250, Loss: 0.0156\n",
      "Epoch 32/200, Iteration 63/250, Loss: 0.0178\n",
      "Epoch 32/200, Iteration 64/250, Loss: 0.0232\n",
      "Epoch 32/200, Iteration 65/250, Loss: 0.0195\n",
      "Epoch 32/200, Iteration 66/250, Loss: 0.0261\n",
      "Epoch 32/200, Iteration 67/250, Loss: 0.0301\n",
      "Epoch 32/200, Iteration 68/250, Loss: 0.0240\n",
      "Epoch 32/200, Iteration 69/250, Loss: 0.0210\n",
      "Epoch 32/200, Iteration 70/250, Loss: 0.0172\n",
      "Epoch 32/200, Iteration 71/250, Loss: 0.0282\n",
      "Epoch 32/200, Iteration 72/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 73/250, Loss: 0.0142\n",
      "Epoch 32/200, Iteration 74/250, Loss: 0.0223\n",
      "Epoch 32/200, Iteration 75/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 76/250, Loss: 0.0136\n",
      "Epoch 32/200, Iteration 77/250, Loss: 0.0175\n",
      "Epoch 32/200, Iteration 78/250, Loss: 0.0183\n",
      "Epoch 32/200, Iteration 79/250, Loss: 0.0223\n",
      "Epoch 32/200, Iteration 80/250, Loss: 0.0236\n",
      "Epoch 32/200, Iteration 81/250, Loss: 0.0324\n",
      "Epoch 32/200, Iteration 82/250, Loss: 0.0162\n",
      "Epoch 32/200, Iteration 83/250, Loss: 0.0197\n",
      "Epoch 32/200, Iteration 84/250, Loss: 0.0181\n",
      "Epoch 32/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 32/200, Iteration 86/250, Loss: 0.0141\n",
      "Epoch 32/200, Iteration 87/250, Loss: 0.0203\n",
      "Epoch 32/200, Iteration 88/250, Loss: 0.0152\n",
      "Epoch 32/200, Iteration 89/250, Loss: 0.0324\n",
      "Epoch 32/200, Iteration 90/250, Loss: 0.0329\n",
      "Epoch 32/200, Iteration 91/250, Loss: 0.0210\n",
      "Epoch 32/200, Iteration 92/250, Loss: 0.0240\n",
      "Epoch 32/200, Iteration 93/250, Loss: 0.0288\n",
      "Epoch 32/200, Iteration 94/250, Loss: 0.0271\n",
      "Epoch 32/200, Iteration 95/250, Loss: 0.0161\n",
      "Epoch 32/200, Iteration 96/250, Loss: 0.0172\n",
      "Epoch 32/200, Iteration 97/250, Loss: 0.0214\n",
      "Epoch 32/200, Iteration 98/250, Loss: 0.0253\n",
      "Epoch 32/200, Iteration 99/250, Loss: 0.0311\n",
      "Epoch 32/200, Iteration 100/250, Loss: 0.0145\n",
      "Epoch 32/200, Iteration 101/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 102/250, Loss: 0.0241\n",
      "Epoch 32/200, Iteration 103/250, Loss: 0.0193\n",
      "Epoch 32/200, Iteration 104/250, Loss: 0.0249\n",
      "Epoch 32/200, Iteration 105/250, Loss: 0.0204\n",
      "Epoch 32/200, Iteration 106/250, Loss: 0.0149\n",
      "Epoch 32/200, Iteration 107/250, Loss: 0.0132\n",
      "Epoch 32/200, Iteration 108/250, Loss: 0.0193\n",
      "Epoch 32/200, Iteration 109/250, Loss: 0.0263\n",
      "Epoch 32/200, Iteration 110/250, Loss: 0.0237\n",
      "Epoch 32/200, Iteration 111/250, Loss: 0.0223\n",
      "Epoch 32/200, Iteration 112/250, Loss: 0.0200\n",
      "Epoch 32/200, Iteration 113/250, Loss: 0.0234\n",
      "Epoch 32/200, Iteration 114/250, Loss: 0.0187\n",
      "Epoch 32/200, Iteration 115/250, Loss: 0.0260\n",
      "Epoch 32/200, Iteration 116/250, Loss: 0.0176\n",
      "Epoch 32/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 32/200, Iteration 118/250, Loss: 0.0197\n",
      "Epoch 32/200, Iteration 119/250, Loss: 0.0186\n",
      "Epoch 32/200, Iteration 120/250, Loss: 0.0603\n",
      "Epoch 32/200, Iteration 121/250, Loss: 0.0290\n",
      "Epoch 32/200, Iteration 122/250, Loss: 0.0304\n",
      "Epoch 32/200, Iteration 123/250, Loss: 0.0149\n",
      "Epoch 32/200, Iteration 124/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 125/250, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 126/250, Loss: 0.0261\n",
      "Epoch 32/200, Iteration 127/250, Loss: 0.0522\n",
      "Epoch 32/200, Iteration 128/250, Loss: 0.0375\n",
      "Epoch 32/200, Iteration 129/250, Loss: 0.0178\n",
      "Epoch 32/200, Iteration 130/250, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 131/250, Loss: 0.0271\n",
      "Epoch 32/200, Iteration 132/250, Loss: 0.0421\n",
      "Epoch 32/200, Iteration 133/250, Loss: 0.0150\n",
      "Epoch 32/200, Iteration 134/250, Loss: 0.0173\n",
      "Epoch 32/200, Iteration 135/250, Loss: 0.0155\n",
      "Epoch 32/200, Iteration 136/250, Loss: 0.0170\n",
      "Epoch 32/200, Iteration 137/250, Loss: 0.0258\n",
      "Epoch 32/200, Iteration 138/250, Loss: 0.0192\n",
      "Epoch 32/200, Iteration 139/250, Loss: 0.0216\n",
      "Epoch 32/200, Iteration 140/250, Loss: 0.0188\n",
      "Epoch 32/200, Iteration 141/250, Loss: 0.0342\n",
      "Epoch 32/200, Iteration 142/250, Loss: 0.0276\n",
      "Epoch 32/200, Iteration 143/250, Loss: 0.0205\n",
      "Epoch 32/200, Iteration 144/250, Loss: 0.0205\n",
      "Epoch 32/200, Iteration 145/250, Loss: 0.0250\n",
      "Epoch 32/200, Iteration 146/250, Loss: 0.0222\n",
      "Epoch 32/200, Iteration 147/250, Loss: 0.0234\n",
      "Epoch 32/200, Iteration 148/250, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 149/250, Loss: 0.0213\n",
      "Epoch 32/200, Iteration 150/250, Loss: 0.0323\n",
      "Epoch 32/200, Iteration 151/250, Loss: 0.0299\n",
      "Epoch 32/200, Iteration 152/250, Loss: 0.0227\n",
      "Epoch 32/200, Iteration 153/250, Loss: 0.0225\n",
      "Epoch 32/200, Iteration 154/250, Loss: 0.0215\n",
      "Epoch 32/200, Iteration 155/250, Loss: 0.0242\n",
      "Epoch 32/200, Iteration 156/250, Loss: 0.0195\n",
      "Epoch 32/200, Iteration 157/250, Loss: 0.0222\n",
      "Epoch 32/200, Iteration 158/250, Loss: 0.0225\n",
      "Epoch 32/200, Iteration 159/250, Loss: 0.0320\n",
      "Epoch 32/200, Iteration 160/250, Loss: 0.0455\n",
      "Epoch 32/200, Iteration 161/250, Loss: 0.0155\n",
      "Epoch 32/200, Iteration 162/250, Loss: 0.0162\n",
      "Epoch 32/200, Iteration 163/250, Loss: 0.0245\n",
      "Epoch 32/200, Iteration 164/250, Loss: 0.0268\n",
      "Epoch 32/200, Iteration 165/250, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 166/250, Loss: 0.0286\n",
      "Epoch 32/200, Iteration 167/250, Loss: 0.0270\n",
      "Epoch 32/200, Iteration 168/250, Loss: 0.0297\n",
      "Epoch 32/200, Iteration 169/250, Loss: 0.0242\n",
      "Epoch 32/200, Iteration 170/250, Loss: 0.0291\n",
      "Epoch 32/200, Iteration 171/250, Loss: 0.0142\n",
      "Epoch 32/200, Iteration 172/250, Loss: 0.0266\n",
      "Epoch 32/200, Iteration 173/250, Loss: 0.0329\n",
      "Epoch 32/200, Iteration 174/250, Loss: 0.0262\n",
      "Epoch 32/200, Iteration 175/250, Loss: 0.0269\n",
      "Epoch 32/200, Iteration 176/250, Loss: 0.0604\n",
      "Epoch 32/200, Iteration 177/250, Loss: 0.0266\n",
      "Epoch 32/200, Iteration 178/250, Loss: 0.0297\n",
      "Epoch 32/200, Iteration 179/250, Loss: 0.0252\n",
      "Epoch 32/200, Iteration 180/250, Loss: 0.0355\n",
      "Epoch 32/200, Iteration 181/250, Loss: 0.0320\n",
      "Epoch 32/200, Iteration 182/250, Loss: 0.0502\n",
      "Epoch 32/200, Iteration 183/250, Loss: 0.0374\n",
      "Epoch 32/200, Iteration 184/250, Loss: 0.0282\n",
      "Epoch 32/200, Iteration 185/250, Loss: 0.0252\n",
      "Epoch 32/200, Iteration 186/250, Loss: 0.0303\n",
      "Epoch 32/200, Iteration 187/250, Loss: 0.0426\n",
      "Epoch 32/200, Iteration 188/250, Loss: 0.0379\n",
      "Epoch 32/200, Iteration 189/250, Loss: 0.0268\n",
      "Epoch 32/200, Iteration 190/250, Loss: 0.0271\n",
      "Epoch 32/200, Iteration 191/250, Loss: 0.0376\n",
      "Epoch 32/200, Iteration 192/250, Loss: 0.0351\n",
      "Epoch 32/200, Iteration 193/250, Loss: 0.0364\n",
      "Epoch 32/200, Iteration 194/250, Loss: 0.0291\n",
      "Epoch 32/200, Iteration 195/250, Loss: 0.0259\n",
      "Epoch 32/200, Iteration 196/250, Loss: 0.0281\n",
      "Epoch 32/200, Iteration 197/250, Loss: 0.0326\n",
      "Epoch 32/200, Iteration 198/250, Loss: 0.0336\n",
      "Epoch 32/200, Iteration 199/250, Loss: 0.0248\n",
      "Epoch 32/200, Iteration 200/250, Loss: 0.0273\n",
      "Epoch 32/200, Iteration 201/250, Loss: 0.0271\n",
      "Epoch 32/200, Iteration 202/250, Loss: 0.0337\n",
      "Epoch 32/200, Iteration 203/250, Loss: 0.0245\n",
      "Epoch 32/200, Iteration 204/250, Loss: 0.0152\n",
      "Epoch 32/200, Iteration 205/250, Loss: 0.0163\n",
      "Epoch 32/200, Iteration 206/250, Loss: 0.0242\n",
      "Epoch 32/200, Iteration 207/250, Loss: 0.0255\n",
      "Epoch 32/200, Iteration 208/250, Loss: 0.0308\n",
      "Epoch 32/200, Iteration 209/250, Loss: 0.0350\n",
      "Epoch 32/200, Iteration 210/250, Loss: 0.0339\n",
      "Epoch 32/200, Iteration 211/250, Loss: 0.0471\n",
      "Epoch 32/200, Iteration 212/250, Loss: 0.0246\n",
      "Epoch 32/200, Iteration 213/250, Loss: 0.0132\n",
      "Epoch 32/200, Iteration 214/250, Loss: 0.0203\n",
      "Epoch 32/200, Iteration 215/250, Loss: 0.0364\n",
      "Epoch 32/200, Iteration 216/250, Loss: 0.0321\n",
      "Epoch 32/200, Iteration 217/250, Loss: 0.0172\n",
      "Epoch 32/200, Iteration 218/250, Loss: 0.0204\n",
      "Epoch 32/200, Iteration 219/250, Loss: 0.0411\n",
      "Epoch 32/200, Iteration 220/250, Loss: 0.0211\n",
      "Epoch 32/200, Iteration 221/250, Loss: 0.0234\n",
      "Epoch 32/200, Iteration 222/250, Loss: 0.0213\n",
      "Epoch 32/200, Iteration 223/250, Loss: 0.0241\n",
      "Epoch 32/200, Iteration 224/250, Loss: 0.0292\n",
      "Epoch 32/200, Iteration 225/250, Loss: 0.0179\n",
      "Epoch 32/200, Iteration 226/250, Loss: 0.0209\n",
      "Epoch 32/200, Iteration 227/250, Loss: 0.0085\n",
      "Epoch 32/200, Iteration 228/250, Loss: 0.0166\n",
      "Epoch 32/200, Iteration 229/250, Loss: 0.0253\n",
      "Epoch 32/200, Iteration 230/250, Loss: 0.0303\n",
      "Epoch 32/200, Iteration 231/250, Loss: 0.0323\n",
      "Epoch 32/200, Iteration 232/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 233/250, Loss: 0.0162\n",
      "Epoch 32/200, Iteration 234/250, Loss: 0.0230\n",
      "Epoch 32/200, Iteration 235/250, Loss: 0.0160\n",
      "Epoch 32/200, Iteration 236/250, Loss: 0.0259\n",
      "Epoch 32/200, Iteration 237/250, Loss: 0.0191\n",
      "Epoch 32/200, Iteration 238/250, Loss: 0.0213\n",
      "Epoch 32/200, Iteration 239/250, Loss: 0.0213\n",
      "Epoch 32/200, Iteration 240/250, Loss: 0.0140\n",
      "Epoch 32/200, Iteration 241/250, Loss: 0.0299\n",
      "Epoch 32/200, Iteration 242/250, Loss: 0.0154\n",
      "Epoch 32/200, Iteration 243/250, Loss: 0.0184\n",
      "Epoch 32/200, Iteration 244/250, Loss: 0.0189\n",
      "Epoch 32/200, Iteration 245/250, Loss: 0.0153\n",
      "Epoch 32/200, Iteration 246/250, Loss: 0.0231\n",
      "Epoch 32/200, Iteration 247/250, Loss: 0.0286\n",
      "Epoch 32/200, Iteration 248/250, Loss: 0.0245\n",
      "Epoch 32/200, Iteration 249/250, Loss: 0.0258\n",
      "Epoch 32/200, Iteration 250/250, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 87.12%, Avg loss: 0.015426, MRE: 1.204497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.25%, Avg loss: 0.015952, MRE: 2.055857 \n",
      "\n",
      "Epoch 33/200, Iteration 1/250, Loss: 0.0180\n",
      "Epoch 33/200, Iteration 2/250, Loss: 0.0323\n",
      "Epoch 33/200, Iteration 3/250, Loss: 0.0146\n",
      "Epoch 33/200, Iteration 4/250, Loss: 0.0142\n",
      "Epoch 33/200, Iteration 5/250, Loss: 0.0233\n",
      "Epoch 33/200, Iteration 6/250, Loss: 0.0221\n",
      "Epoch 33/200, Iteration 7/250, Loss: 0.0205\n",
      "Epoch 33/200, Iteration 8/250, Loss: 0.0276\n",
      "Epoch 33/200, Iteration 9/250, Loss: 0.0183\n",
      "Epoch 33/200, Iteration 10/250, Loss: 0.0187\n",
      "Epoch 33/200, Iteration 11/250, Loss: 0.0257\n",
      "Epoch 33/200, Iteration 12/250, Loss: 0.0192\n",
      "Epoch 33/200, Iteration 13/250, Loss: 0.0439\n",
      "Epoch 33/200, Iteration 14/250, Loss: 0.0333\n",
      "Epoch 33/200, Iteration 15/250, Loss: 0.0386\n",
      "Epoch 33/200, Iteration 16/250, Loss: 0.0258\n",
      "Epoch 33/200, Iteration 17/250, Loss: 0.0346\n",
      "Epoch 33/200, Iteration 18/250, Loss: 0.0293\n",
      "Epoch 33/200, Iteration 19/250, Loss: 0.0455\n",
      "Epoch 33/200, Iteration 20/250, Loss: 0.0423\n",
      "Epoch 33/200, Iteration 21/250, Loss: 0.0252\n",
      "Epoch 33/200, Iteration 22/250, Loss: 0.0216\n",
      "Epoch 33/200, Iteration 23/250, Loss: 0.0363\n",
      "Epoch 33/200, Iteration 24/250, Loss: 0.0325\n",
      "Epoch 33/200, Iteration 25/250, Loss: 0.0371\n",
      "Epoch 33/200, Iteration 26/250, Loss: 0.0213\n",
      "Epoch 33/200, Iteration 27/250, Loss: 0.0214\n",
      "Epoch 33/200, Iteration 28/250, Loss: 0.0205\n",
      "Epoch 33/200, Iteration 29/250, Loss: 0.0233\n",
      "Epoch 33/200, Iteration 30/250, Loss: 0.0334\n",
      "Epoch 33/200, Iteration 31/250, Loss: 0.0343\n",
      "Epoch 33/200, Iteration 32/250, Loss: 0.0347\n",
      "Epoch 33/200, Iteration 33/250, Loss: 0.0336\n",
      "Epoch 33/200, Iteration 34/250, Loss: 0.0209\n",
      "Epoch 33/200, Iteration 35/250, Loss: 0.0271\n",
      "Epoch 33/200, Iteration 36/250, Loss: 0.0222\n",
      "Epoch 33/200, Iteration 37/250, Loss: 0.0239\n",
      "Epoch 33/200, Iteration 38/250, Loss: 0.0192\n",
      "Epoch 33/200, Iteration 39/250, Loss: 0.0289\n",
      "Epoch 33/200, Iteration 40/250, Loss: 0.0243\n",
      "Epoch 33/200, Iteration 41/250, Loss: 0.0181\n",
      "Epoch 33/200, Iteration 42/250, Loss: 0.0358\n",
      "Epoch 33/200, Iteration 43/250, Loss: 0.0282\n",
      "Epoch 33/200, Iteration 44/250, Loss: 0.0218\n",
      "Epoch 33/200, Iteration 45/250, Loss: 0.0231\n",
      "Epoch 33/200, Iteration 46/250, Loss: 0.0153\n",
      "Epoch 33/200, Iteration 47/250, Loss: 0.0171\n",
      "Epoch 33/200, Iteration 48/250, Loss: 0.0180\n",
      "Epoch 33/200, Iteration 49/250, Loss: 0.0186\n",
      "Epoch 33/200, Iteration 50/250, Loss: 0.0193\n",
      "Epoch 33/200, Iteration 51/250, Loss: 0.0189\n",
      "Epoch 33/200, Iteration 52/250, Loss: 0.0322\n",
      "Epoch 33/200, Iteration 53/250, Loss: 0.0217\n",
      "Epoch 33/200, Iteration 54/250, Loss: 0.0229\n",
      "Epoch 33/200, Iteration 55/250, Loss: 0.0172\n",
      "Epoch 33/200, Iteration 56/250, Loss: 0.0243\n",
      "Epoch 33/200, Iteration 57/250, Loss: 0.0280\n",
      "Epoch 33/200, Iteration 58/250, Loss: 0.0253\n",
      "Epoch 33/200, Iteration 59/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 60/250, Loss: 0.0198\n",
      "Epoch 33/200, Iteration 61/250, Loss: 0.0235\n",
      "Epoch 33/200, Iteration 62/250, Loss: 0.0257\n",
      "Epoch 33/200, Iteration 63/250, Loss: 0.0360\n",
      "Epoch 33/200, Iteration 64/250, Loss: 0.0555\n",
      "Epoch 33/200, Iteration 65/250, Loss: 0.0251\n",
      "Epoch 33/200, Iteration 66/250, Loss: 0.0247\n",
      "Epoch 33/200, Iteration 67/250, Loss: 0.0328\n",
      "Epoch 33/200, Iteration 68/250, Loss: 0.0187\n",
      "Epoch 33/200, Iteration 69/250, Loss: 0.0171\n",
      "Epoch 33/200, Iteration 70/250, Loss: 0.0341\n",
      "Epoch 33/200, Iteration 71/250, Loss: 0.0311\n",
      "Epoch 33/200, Iteration 72/250, Loss: 0.0215\n",
      "Epoch 33/200, Iteration 73/250, Loss: 0.0196\n",
      "Epoch 33/200, Iteration 74/250, Loss: 0.0442\n",
      "Epoch 33/200, Iteration 75/250, Loss: 0.0257\n",
      "Epoch 33/200, Iteration 76/250, Loss: 0.0388\n",
      "Epoch 33/200, Iteration 77/250, Loss: 0.0377\n",
      "Epoch 33/200, Iteration 78/250, Loss: 0.0289\n",
      "Epoch 33/200, Iteration 79/250, Loss: 0.0299\n",
      "Epoch 33/200, Iteration 80/250, Loss: 0.0400\n",
      "Epoch 33/200, Iteration 81/250, Loss: 0.0324\n",
      "Epoch 33/200, Iteration 82/250, Loss: 0.0259\n",
      "Epoch 33/200, Iteration 83/250, Loss: 0.0263\n",
      "Epoch 33/200, Iteration 84/250, Loss: 0.0314\n",
      "Epoch 33/200, Iteration 85/250, Loss: 0.0290\n",
      "Epoch 33/200, Iteration 86/250, Loss: 0.0304\n",
      "Epoch 33/200, Iteration 87/250, Loss: 0.0278\n",
      "Epoch 33/200, Iteration 88/250, Loss: 0.0133\n",
      "Epoch 33/200, Iteration 89/250, Loss: 0.0214\n",
      "Epoch 33/200, Iteration 90/250, Loss: 0.0236\n",
      "Epoch 33/200, Iteration 91/250, Loss: 0.0170\n",
      "Epoch 33/200, Iteration 92/250, Loss: 0.0190\n",
      "Epoch 33/200, Iteration 93/250, Loss: 0.0248\n",
      "Epoch 33/200, Iteration 94/250, Loss: 0.0308\n",
      "Epoch 33/200, Iteration 95/250, Loss: 0.0385\n",
      "Epoch 33/200, Iteration 96/250, Loss: 0.0299\n",
      "Epoch 33/200, Iteration 97/250, Loss: 0.0179\n",
      "Epoch 33/200, Iteration 98/250, Loss: 0.0199\n",
      "Epoch 33/200, Iteration 99/250, Loss: 0.0283\n",
      "Epoch 33/200, Iteration 100/250, Loss: 0.0364\n",
      "Epoch 33/200, Iteration 101/250, Loss: 0.0275\n",
      "Epoch 33/200, Iteration 102/250, Loss: 0.0404\n",
      "Epoch 33/200, Iteration 103/250, Loss: 0.0246\n",
      "Epoch 33/200, Iteration 104/250, Loss: 0.0241\n",
      "Epoch 33/200, Iteration 105/250, Loss: 0.0292\n",
      "Epoch 33/200, Iteration 106/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 107/250, Loss: 0.0320\n",
      "Epoch 33/200, Iteration 108/250, Loss: 0.0223\n",
      "Epoch 33/200, Iteration 109/250, Loss: 0.0600\n",
      "Epoch 33/200, Iteration 110/250, Loss: 0.0377\n",
      "Epoch 33/200, Iteration 111/250, Loss: 0.0246\n",
      "Epoch 33/200, Iteration 112/250, Loss: 0.0480\n",
      "Epoch 33/200, Iteration 113/250, Loss: 0.0360\n",
      "Epoch 33/200, Iteration 114/250, Loss: 0.0233\n",
      "Epoch 33/200, Iteration 115/250, Loss: 0.0282\n",
      "Epoch 33/200, Iteration 116/250, Loss: 0.0403\n",
      "Epoch 33/200, Iteration 117/250, Loss: 0.0205\n",
      "Epoch 33/200, Iteration 118/250, Loss: 0.0219\n",
      "Epoch 33/200, Iteration 119/250, Loss: 0.0339\n",
      "Epoch 33/200, Iteration 120/250, Loss: 0.0320\n",
      "Epoch 33/200, Iteration 121/250, Loss: 0.0297\n",
      "Epoch 33/200, Iteration 122/250, Loss: 0.0354\n",
      "Epoch 33/200, Iteration 123/250, Loss: 0.0161\n",
      "Epoch 33/200, Iteration 124/250, Loss: 0.0225\n",
      "Epoch 33/200, Iteration 125/250, Loss: 0.0230\n",
      "Epoch 33/200, Iteration 126/250, Loss: 0.0269\n",
      "Epoch 33/200, Iteration 127/250, Loss: 0.0194\n",
      "Epoch 33/200, Iteration 128/250, Loss: 0.0210\n",
      "Epoch 33/200, Iteration 129/250, Loss: 0.0247\n",
      "Epoch 33/200, Iteration 130/250, Loss: 0.0176\n",
      "Epoch 33/200, Iteration 131/250, Loss: 0.0166\n",
      "Epoch 33/200, Iteration 132/250, Loss: 0.0263\n",
      "Epoch 33/200, Iteration 133/250, Loss: 0.0182\n",
      "Epoch 33/200, Iteration 134/250, Loss: 0.0217\n",
      "Epoch 33/200, Iteration 135/250, Loss: 0.0144\n",
      "Epoch 33/200, Iteration 136/250, Loss: 0.0242\n",
      "Epoch 33/200, Iteration 137/250, Loss: 0.0295\n",
      "Epoch 33/200, Iteration 138/250, Loss: 0.0317\n",
      "Epoch 33/200, Iteration 139/250, Loss: 0.0250\n",
      "Epoch 33/200, Iteration 140/250, Loss: 0.0154\n",
      "Epoch 33/200, Iteration 141/250, Loss: 0.0207\n",
      "Epoch 33/200, Iteration 142/250, Loss: 0.0290\n",
      "Epoch 33/200, Iteration 143/250, Loss: 0.0221\n",
      "Epoch 33/200, Iteration 144/250, Loss: 0.0172\n",
      "Epoch 33/200, Iteration 145/250, Loss: 0.0165\n",
      "Epoch 33/200, Iteration 146/250, Loss: 0.0305\n",
      "Epoch 33/200, Iteration 147/250, Loss: 0.0297\n",
      "Epoch 33/200, Iteration 148/250, Loss: 0.0269\n",
      "Epoch 33/200, Iteration 149/250, Loss: 0.0208\n",
      "Epoch 33/200, Iteration 150/250, Loss: 0.0175\n",
      "Epoch 33/200, Iteration 151/250, Loss: 0.0173\n",
      "Epoch 33/200, Iteration 152/250, Loss: 0.0195\n",
      "Epoch 33/200, Iteration 153/250, Loss: 0.0193\n",
      "Epoch 33/200, Iteration 154/250, Loss: 0.0160\n",
      "Epoch 33/200, Iteration 155/250, Loss: 0.0187\n",
      "Epoch 33/200, Iteration 156/250, Loss: 0.0196\n",
      "Epoch 33/200, Iteration 157/250, Loss: 0.0216\n",
      "Epoch 33/200, Iteration 158/250, Loss: 0.0351\n",
      "Epoch 33/200, Iteration 159/250, Loss: 0.0129\n",
      "Epoch 33/200, Iteration 160/250, Loss: 0.0150\n",
      "Epoch 33/200, Iteration 161/250, Loss: 0.0172\n",
      "Epoch 33/200, Iteration 162/250, Loss: 0.0190\n",
      "Epoch 33/200, Iteration 163/250, Loss: 0.0210\n",
      "Epoch 33/200, Iteration 164/250, Loss: 0.0168\n",
      "Epoch 33/200, Iteration 165/250, Loss: 0.0186\n",
      "Epoch 33/200, Iteration 166/250, Loss: 0.0201\n",
      "Epoch 33/200, Iteration 167/250, Loss: 0.0131\n",
      "Epoch 33/200, Iteration 168/250, Loss: 0.0197\n",
      "Epoch 33/200, Iteration 169/250, Loss: 0.0160\n",
      "Epoch 33/200, Iteration 170/250, Loss: 0.0253\n",
      "Epoch 33/200, Iteration 171/250, Loss: 0.0275\n",
      "Epoch 33/200, Iteration 172/250, Loss: 0.0216\n",
      "Epoch 33/200, Iteration 173/250, Loss: 0.0220\n",
      "Epoch 33/200, Iteration 174/250, Loss: 0.0217\n",
      "Epoch 33/200, Iteration 175/250, Loss: 0.0316\n",
      "Epoch 33/200, Iteration 176/250, Loss: 0.0258\n",
      "Epoch 33/200, Iteration 177/250, Loss: 0.0143\n",
      "Epoch 33/200, Iteration 178/250, Loss: 0.0244\n",
      "Epoch 33/200, Iteration 179/250, Loss: 0.0218\n",
      "Epoch 33/200, Iteration 180/250, Loss: 0.0322\n",
      "Epoch 33/200, Iteration 181/250, Loss: 0.0360\n",
      "Epoch 33/200, Iteration 182/250, Loss: 0.0217\n",
      "Epoch 33/200, Iteration 183/250, Loss: 0.0220\n",
      "Epoch 33/200, Iteration 184/250, Loss: 0.0190\n",
      "Epoch 33/200, Iteration 185/250, Loss: 0.0353\n",
      "Epoch 33/200, Iteration 186/250, Loss: 0.0410\n",
      "Epoch 33/200, Iteration 187/250, Loss: 0.0457\n",
      "Epoch 33/200, Iteration 188/250, Loss: 0.0366\n",
      "Epoch 33/200, Iteration 189/250, Loss: 0.0279\n",
      "Epoch 33/200, Iteration 190/250, Loss: 0.0248\n",
      "Epoch 33/200, Iteration 191/250, Loss: 0.0357\n",
      "Epoch 33/200, Iteration 192/250, Loss: 0.0380\n",
      "Epoch 33/200, Iteration 193/250, Loss: 0.0299\n",
      "Epoch 33/200, Iteration 194/250, Loss: 0.0251\n",
      "Epoch 33/200, Iteration 195/250, Loss: 0.0242\n",
      "Epoch 33/200, Iteration 196/250, Loss: 0.0443\n",
      "Epoch 33/200, Iteration 197/250, Loss: 0.0250\n",
      "Epoch 33/200, Iteration 198/250, Loss: 0.0381\n",
      "Epoch 33/200, Iteration 199/250, Loss: 0.0235\n",
      "Epoch 33/200, Iteration 200/250, Loss: 0.0204\n",
      "Epoch 33/200, Iteration 201/250, Loss: 0.0269\n",
      "Epoch 33/200, Iteration 202/250, Loss: 0.0334\n",
      "Epoch 33/200, Iteration 203/250, Loss: 0.0382\n",
      "Epoch 33/200, Iteration 204/250, Loss: 0.0199\n",
      "Epoch 33/200, Iteration 205/250, Loss: 0.0285\n",
      "Epoch 33/200, Iteration 206/250, Loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Iteration 207/250, Loss: 0.0324\n",
      "Epoch 33/200, Iteration 208/250, Loss: 0.0269\n",
      "Epoch 33/200, Iteration 209/250, Loss: 0.0304\n",
      "Epoch 33/200, Iteration 210/250, Loss: 0.0238\n",
      "Epoch 33/200, Iteration 211/250, Loss: 0.0194\n",
      "Epoch 33/200, Iteration 212/250, Loss: 0.0225\n",
      "Epoch 33/200, Iteration 213/250, Loss: 0.0226\n",
      "Epoch 33/200, Iteration 214/250, Loss: 0.0286\n",
      "Epoch 33/200, Iteration 215/250, Loss: 0.0245\n",
      "Epoch 33/200, Iteration 216/250, Loss: 0.0150\n",
      "Epoch 33/200, Iteration 217/250, Loss: 0.0150\n",
      "Epoch 33/200, Iteration 218/250, Loss: 0.0126\n",
      "Epoch 33/200, Iteration 219/250, Loss: 0.0141\n",
      "Epoch 33/200, Iteration 220/250, Loss: 0.0148\n",
      "Epoch 33/200, Iteration 221/250, Loss: 0.0135\n",
      "Epoch 33/200, Iteration 222/250, Loss: 0.0179\n",
      "Epoch 33/200, Iteration 223/250, Loss: 0.0185\n",
      "Epoch 33/200, Iteration 224/250, Loss: 0.0141\n",
      "Epoch 33/200, Iteration 225/250, Loss: 0.0129\n",
      "Epoch 33/200, Iteration 226/250, Loss: 0.0202\n",
      "Epoch 33/200, Iteration 227/250, Loss: 0.0207\n",
      "Epoch 33/200, Iteration 228/250, Loss: 0.0115\n",
      "Epoch 33/200, Iteration 229/250, Loss: 0.0144\n",
      "Epoch 33/200, Iteration 230/250, Loss: 0.0145\n",
      "Epoch 33/200, Iteration 231/250, Loss: 0.0209\n",
      "Epoch 33/200, Iteration 232/250, Loss: 0.0130\n",
      "Epoch 33/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 33/200, Iteration 234/250, Loss: 0.0169\n",
      "Epoch 33/200, Iteration 235/250, Loss: 0.0159\n",
      "Epoch 33/200, Iteration 236/250, Loss: 0.0151\n",
      "Epoch 33/200, Iteration 237/250, Loss: 0.0144\n",
      "Epoch 33/200, Iteration 238/250, Loss: 0.0139\n",
      "Epoch 33/200, Iteration 239/250, Loss: 0.0266\n",
      "Epoch 33/200, Iteration 240/250, Loss: 0.0133\n",
      "Epoch 33/200, Iteration 241/250, Loss: 0.0172\n",
      "Epoch 33/200, Iteration 242/250, Loss: 0.0143\n",
      "Epoch 33/200, Iteration 243/250, Loss: 0.0215\n",
      "Epoch 33/200, Iteration 244/250, Loss: 0.0276\n",
      "Epoch 33/200, Iteration 245/250, Loss: 0.0165\n",
      "Epoch 33/200, Iteration 246/250, Loss: 0.0278\n",
      "Epoch 33/200, Iteration 247/250, Loss: 0.0233\n",
      "Epoch 33/200, Iteration 248/250, Loss: 0.0299\n",
      "Epoch 33/200, Iteration 249/250, Loss: 0.0289\n",
      "Epoch 33/200, Iteration 250/250, Loss: 0.0280\n",
      "Train Error: \n",
      " Accuracy: 67.07%, Avg loss: 0.016822, MRE: 1.199210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.016818, MRE: 1.313712 \n",
      "\n",
      "Epoch 34/200, Iteration 1/250, Loss: 0.0158\n",
      "Epoch 34/200, Iteration 2/250, Loss: 0.0196\n",
      "Epoch 34/200, Iteration 3/250, Loss: 0.0177\n",
      "Epoch 34/200, Iteration 4/250, Loss: 0.0121\n",
      "Epoch 34/200, Iteration 5/250, Loss: 0.0228\n",
      "Epoch 34/200, Iteration 6/250, Loss: 0.0226\n",
      "Epoch 34/200, Iteration 7/250, Loss: 0.0186\n",
      "Epoch 34/200, Iteration 8/250, Loss: 0.0124\n",
      "Epoch 34/200, Iteration 9/250, Loss: 0.0215\n",
      "Epoch 34/200, Iteration 10/250, Loss: 0.0223\n",
      "Epoch 34/200, Iteration 11/250, Loss: 0.0161\n",
      "Epoch 34/200, Iteration 12/250, Loss: 0.0167\n",
      "Epoch 34/200, Iteration 13/250, Loss: 0.0175\n",
      "Epoch 34/200, Iteration 14/250, Loss: 0.0409\n",
      "Epoch 34/200, Iteration 15/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 34/200, Iteration 17/250, Loss: 0.0205\n",
      "Epoch 34/200, Iteration 18/250, Loss: 0.0240\n",
      "Epoch 34/200, Iteration 19/250, Loss: 0.0385\n",
      "Epoch 34/200, Iteration 20/250, Loss: 0.0363\n",
      "Epoch 34/200, Iteration 21/250, Loss: 0.0292\n",
      "Epoch 34/200, Iteration 22/250, Loss: 0.0313\n",
      "Epoch 34/200, Iteration 23/250, Loss: 0.0135\n",
      "Epoch 34/200, Iteration 24/250, Loss: 0.0185\n",
      "Epoch 34/200, Iteration 25/250, Loss: 0.0235\n",
      "Epoch 34/200, Iteration 26/250, Loss: 0.0310\n",
      "Epoch 34/200, Iteration 27/250, Loss: 0.0205\n",
      "Epoch 34/200, Iteration 28/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 29/250, Loss: 0.0204\n",
      "Epoch 34/200, Iteration 30/250, Loss: 0.0222\n",
      "Epoch 34/200, Iteration 31/250, Loss: 0.0224\n",
      "Epoch 34/200, Iteration 32/250, Loss: 0.0164\n",
      "Epoch 34/200, Iteration 33/250, Loss: 0.0158\n",
      "Epoch 34/200, Iteration 34/250, Loss: 0.0233\n",
      "Epoch 34/200, Iteration 35/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 36/250, Loss: 0.0215\n",
      "Epoch 34/200, Iteration 37/250, Loss: 0.0384\n",
      "Epoch 34/200, Iteration 38/250, Loss: 0.0424\n",
      "Epoch 34/200, Iteration 39/250, Loss: 0.0366\n",
      "Epoch 34/200, Iteration 40/250, Loss: 0.0426\n",
      "Epoch 34/200, Iteration 41/250, Loss: 0.0452\n",
      "Epoch 34/200, Iteration 42/250, Loss: 0.0396\n",
      "Epoch 34/200, Iteration 43/250, Loss: 0.0246\n",
      "Epoch 34/200, Iteration 44/250, Loss: 0.0278\n",
      "Epoch 34/200, Iteration 45/250, Loss: 0.0359\n",
      "Epoch 34/200, Iteration 46/250, Loss: 0.0312\n",
      "Epoch 34/200, Iteration 47/250, Loss: 0.0337\n",
      "Epoch 34/200, Iteration 48/250, Loss: 0.0359\n",
      "Epoch 34/200, Iteration 49/250, Loss: 0.0392\n",
      "Epoch 34/200, Iteration 50/250, Loss: 0.0385\n",
      "Epoch 34/200, Iteration 51/250, Loss: 0.0221\n",
      "Epoch 34/200, Iteration 52/250, Loss: 0.0230\n",
      "Epoch 34/200, Iteration 53/250, Loss: 0.0289\n",
      "Epoch 34/200, Iteration 54/250, Loss: 0.0245\n",
      "Epoch 34/200, Iteration 55/250, Loss: 0.0131\n",
      "Epoch 34/200, Iteration 56/250, Loss: 0.0133\n",
      "Epoch 34/200, Iteration 57/250, Loss: 0.0333\n",
      "Epoch 34/200, Iteration 58/250, Loss: 0.0239\n",
      "Epoch 34/200, Iteration 59/250, Loss: 0.0340\n",
      "Epoch 34/200, Iteration 60/250, Loss: 0.0168\n",
      "Epoch 34/200, Iteration 61/250, Loss: 0.0245\n",
      "Epoch 34/200, Iteration 62/250, Loss: 0.0243\n",
      "Epoch 34/200, Iteration 63/250, Loss: 0.0270\n",
      "Epoch 34/200, Iteration 64/250, Loss: 0.0314\n",
      "Epoch 34/200, Iteration 65/250, Loss: 0.0271\n",
      "Epoch 34/200, Iteration 66/250, Loss: 0.0175\n",
      "Epoch 34/200, Iteration 67/250, Loss: 0.0288\n",
      "Epoch 34/200, Iteration 68/250, Loss: 0.0379\n",
      "Epoch 34/200, Iteration 69/250, Loss: 0.0359\n",
      "Epoch 34/200, Iteration 70/250, Loss: 0.0345\n",
      "Epoch 34/200, Iteration 71/250, Loss: 0.0269\n",
      "Epoch 34/200, Iteration 72/250, Loss: 0.0253\n",
      "Epoch 34/200, Iteration 73/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 74/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 75/250, Loss: 0.0305\n",
      "Epoch 34/200, Iteration 76/250, Loss: 0.0220\n",
      "Epoch 34/200, Iteration 77/250, Loss: 0.0144\n",
      "Epoch 34/200, Iteration 78/250, Loss: 0.0130\n",
      "Epoch 34/200, Iteration 79/250, Loss: 0.0213\n",
      "Epoch 34/200, Iteration 80/250, Loss: 0.0221\n",
      "Epoch 34/200, Iteration 81/250, Loss: 0.0247\n",
      "Epoch 34/200, Iteration 82/250, Loss: 0.0194\n",
      "Epoch 34/200, Iteration 83/250, Loss: 0.0256\n",
      "Epoch 34/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 34/200, Iteration 85/250, Loss: 0.0215\n",
      "Epoch 34/200, Iteration 86/250, Loss: 0.0195\n",
      "Epoch 34/200, Iteration 87/250, Loss: 0.0199\n",
      "Epoch 34/200, Iteration 88/250, Loss: 0.0176\n",
      "Epoch 34/200, Iteration 89/250, Loss: 0.0245\n",
      "Epoch 34/200, Iteration 90/250, Loss: 0.0141\n",
      "Epoch 34/200, Iteration 91/250, Loss: 0.0196\n",
      "Epoch 34/200, Iteration 92/250, Loss: 0.0191\n",
      "Epoch 34/200, Iteration 93/250, Loss: 0.0175\n",
      "Epoch 34/200, Iteration 94/250, Loss: 0.0310\n",
      "Epoch 34/200, Iteration 95/250, Loss: 0.0147\n",
      "Epoch 34/200, Iteration 96/250, Loss: 0.0186\n",
      "Epoch 34/200, Iteration 97/250, Loss: 0.0321\n",
      "Epoch 34/200, Iteration 98/250, Loss: 0.0219\n",
      "Epoch 34/200, Iteration 99/250, Loss: 0.0432\n",
      "Epoch 34/200, Iteration 100/250, Loss: 0.0248\n",
      "Epoch 34/200, Iteration 101/250, Loss: 0.0314\n",
      "Epoch 34/200, Iteration 102/250, Loss: 0.0165\n",
      "Epoch 34/200, Iteration 103/250, Loss: 0.0191\n",
      "Epoch 34/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 34/200, Iteration 105/250, Loss: 0.0241\n",
      "Epoch 34/200, Iteration 106/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 107/250, Loss: 0.0217\n",
      "Epoch 34/200, Iteration 108/250, Loss: 0.0188\n",
      "Epoch 34/200, Iteration 109/250, Loss: 0.0142\n",
      "Epoch 34/200, Iteration 110/250, Loss: 0.0231\n",
      "Epoch 34/200, Iteration 111/250, Loss: 0.0217\n",
      "Epoch 34/200, Iteration 112/250, Loss: 0.0199\n",
      "Epoch 34/200, Iteration 113/250, Loss: 0.0301\n",
      "Epoch 34/200, Iteration 114/250, Loss: 0.0200\n",
      "Epoch 34/200, Iteration 115/250, Loss: 0.0195\n",
      "Epoch 34/200, Iteration 116/250, Loss: 0.0175\n",
      "Epoch 34/200, Iteration 117/250, Loss: 0.0335\n",
      "Epoch 34/200, Iteration 118/250, Loss: 0.0263\n",
      "Epoch 34/200, Iteration 119/250, Loss: 0.0185\n",
      "Epoch 34/200, Iteration 120/250, Loss: 0.0260\n",
      "Epoch 34/200, Iteration 121/250, Loss: 0.0352\n",
      "Epoch 34/200, Iteration 122/250, Loss: 0.0290\n",
      "Epoch 34/200, Iteration 123/250, Loss: 0.0275\n",
      "Epoch 34/200, Iteration 124/250, Loss: 0.0247\n",
      "Epoch 34/200, Iteration 125/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 126/250, Loss: 0.0328\n",
      "Epoch 34/200, Iteration 127/250, Loss: 0.0322\n",
      "Epoch 34/200, Iteration 128/250, Loss: 0.0384\n",
      "Epoch 34/200, Iteration 129/250, Loss: 0.0340\n",
      "Epoch 34/200, Iteration 130/250, Loss: 0.0311\n",
      "Epoch 34/200, Iteration 131/250, Loss: 0.0217\n",
      "Epoch 34/200, Iteration 132/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 133/250, Loss: 0.0455\n",
      "Epoch 34/200, Iteration 134/250, Loss: 0.0358\n",
      "Epoch 34/200, Iteration 135/250, Loss: 0.0370\n",
      "Epoch 34/200, Iteration 136/250, Loss: 0.0173\n",
      "Epoch 34/200, Iteration 137/250, Loss: 0.0189\n",
      "Epoch 34/200, Iteration 138/250, Loss: 0.0317\n",
      "Epoch 34/200, Iteration 139/250, Loss: 0.0301\n",
      "Epoch 34/200, Iteration 140/250, Loss: 0.0220\n",
      "Epoch 34/200, Iteration 141/250, Loss: 0.0267\n",
      "Epoch 34/200, Iteration 142/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 143/250, Loss: 0.0306\n",
      "Epoch 34/200, Iteration 144/250, Loss: 0.0302\n",
      "Epoch 34/200, Iteration 145/250, Loss: 0.0154\n",
      "Epoch 34/200, Iteration 146/250, Loss: 0.0193\n",
      "Epoch 34/200, Iteration 147/250, Loss: 0.0231\n",
      "Epoch 34/200, Iteration 148/250, Loss: 0.0369\n",
      "Epoch 34/200, Iteration 149/250, Loss: 0.0280\n",
      "Epoch 34/200, Iteration 150/250, Loss: 0.0168\n",
      "Epoch 34/200, Iteration 151/250, Loss: 0.0149\n",
      "Epoch 34/200, Iteration 152/250, Loss: 0.0204\n",
      "Epoch 34/200, Iteration 153/250, Loss: 0.0240\n",
      "Epoch 34/200, Iteration 154/250, Loss: 0.0230\n",
      "Epoch 34/200, Iteration 155/250, Loss: 0.0147\n",
      "Epoch 34/200, Iteration 156/250, Loss: 0.0203\n",
      "Epoch 34/200, Iteration 157/250, Loss: 0.0264\n",
      "Epoch 34/200, Iteration 158/250, Loss: 0.0191\n",
      "Epoch 34/200, Iteration 159/250, Loss: 0.0241\n",
      "Epoch 34/200, Iteration 160/250, Loss: 0.0159\n",
      "Epoch 34/200, Iteration 161/250, Loss: 0.0143\n",
      "Epoch 34/200, Iteration 162/250, Loss: 0.0174\n",
      "Epoch 34/200, Iteration 163/250, Loss: 0.0219\n",
      "Epoch 34/200, Iteration 164/250, Loss: 0.0438\n",
      "Epoch 34/200, Iteration 165/250, Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Iteration 166/250, Loss: 0.0284\n",
      "Epoch 34/200, Iteration 167/250, Loss: 0.0276\n",
      "Epoch 34/200, Iteration 168/250, Loss: 0.0244\n",
      "Epoch 34/200, Iteration 169/250, Loss: 0.0170\n",
      "Epoch 34/200, Iteration 170/250, Loss: 0.0274\n",
      "Epoch 34/200, Iteration 171/250, Loss: 0.0192\n",
      "Epoch 34/200, Iteration 172/250, Loss: 0.0113\n",
      "Epoch 34/200, Iteration 173/250, Loss: 0.0232\n",
      "Epoch 34/200, Iteration 174/250, Loss: 0.0289\n",
      "Epoch 34/200, Iteration 175/250, Loss: 0.0170\n",
      "Epoch 34/200, Iteration 176/250, Loss: 0.0253\n",
      "Epoch 34/200, Iteration 177/250, Loss: 0.0250\n",
      "Epoch 34/200, Iteration 178/250, Loss: 0.0286\n",
      "Epoch 34/200, Iteration 179/250, Loss: 0.0265\n",
      "Epoch 34/200, Iteration 180/250, Loss: 0.0187\n",
      "Epoch 34/200, Iteration 181/250, Loss: 0.0315\n",
      "Epoch 34/200, Iteration 182/250, Loss: 0.0224\n",
      "Epoch 34/200, Iteration 183/250, Loss: 0.0187\n",
      "Epoch 34/200, Iteration 184/250, Loss: 0.0216\n",
      "Epoch 34/200, Iteration 185/250, Loss: 0.0161\n",
      "Epoch 34/200, Iteration 186/250, Loss: 0.0220\n",
      "Epoch 34/200, Iteration 187/250, Loss: 0.0367\n",
      "Epoch 34/200, Iteration 188/250, Loss: 0.0169\n",
      "Epoch 34/200, Iteration 189/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 190/250, Loss: 0.0299\n",
      "Epoch 34/200, Iteration 191/250, Loss: 0.0280\n",
      "Epoch 34/200, Iteration 192/250, Loss: 0.0519\n",
      "Epoch 34/200, Iteration 193/250, Loss: 0.0366\n",
      "Epoch 34/200, Iteration 194/250, Loss: 0.0249\n",
      "Epoch 34/200, Iteration 195/250, Loss: 0.0373\n",
      "Epoch 34/200, Iteration 196/250, Loss: 0.0213\n",
      "Epoch 34/200, Iteration 197/250, Loss: 0.0182\n",
      "Epoch 34/200, Iteration 198/250, Loss: 0.0130\n",
      "Epoch 34/200, Iteration 199/250, Loss: 0.0275\n",
      "Epoch 34/200, Iteration 200/250, Loss: 0.0218\n",
      "Epoch 34/200, Iteration 201/250, Loss: 0.0235\n",
      "Epoch 34/200, Iteration 202/250, Loss: 0.0127\n",
      "Epoch 34/200, Iteration 203/250, Loss: 0.0159\n",
      "Epoch 34/200, Iteration 204/250, Loss: 0.0258\n",
      "Epoch 34/200, Iteration 205/250, Loss: 0.0223\n",
      "Epoch 34/200, Iteration 206/250, Loss: 0.0228\n",
      "Epoch 34/200, Iteration 207/250, Loss: 0.0328\n",
      "Epoch 34/200, Iteration 208/250, Loss: 0.0295\n",
      "Epoch 34/200, Iteration 209/250, Loss: 0.0245\n",
      "Epoch 34/200, Iteration 210/250, Loss: 0.0188\n",
      "Epoch 34/200, Iteration 211/250, Loss: 0.0242\n",
      "Epoch 34/200, Iteration 212/250, Loss: 0.0331\n",
      "Epoch 34/200, Iteration 213/250, Loss: 0.0234\n",
      "Epoch 34/200, Iteration 214/250, Loss: 0.0199\n",
      "Epoch 34/200, Iteration 215/250, Loss: 0.0224\n",
      "Epoch 34/200, Iteration 216/250, Loss: 0.0316\n",
      "Epoch 34/200, Iteration 217/250, Loss: 0.0253\n",
      "Epoch 34/200, Iteration 218/250, Loss: 0.0223\n",
      "Epoch 34/200, Iteration 219/250, Loss: 0.0241\n",
      "Epoch 34/200, Iteration 220/250, Loss: 0.0255\n",
      "Epoch 34/200, Iteration 221/250, Loss: 0.0164\n",
      "Epoch 34/200, Iteration 222/250, Loss: 0.0215\n",
      "Epoch 34/200, Iteration 223/250, Loss: 0.0388\n",
      "Epoch 34/200, Iteration 224/250, Loss: 0.0226\n",
      "Epoch 34/200, Iteration 225/250, Loss: 0.0167\n",
      "Epoch 34/200, Iteration 226/250, Loss: 0.0216\n",
      "Epoch 34/200, Iteration 227/250, Loss: 0.0200\n",
      "Epoch 34/200, Iteration 228/250, Loss: 0.0276\n",
      "Epoch 34/200, Iteration 229/250, Loss: 0.0201\n",
      "Epoch 34/200, Iteration 230/250, Loss: 0.0166\n",
      "Epoch 34/200, Iteration 231/250, Loss: 0.0214\n",
      "Epoch 34/200, Iteration 232/250, Loss: 0.0289\n",
      "Epoch 34/200, Iteration 233/250, Loss: 0.0355\n",
      "Epoch 34/200, Iteration 234/250, Loss: 0.0208\n",
      "Epoch 34/200, Iteration 235/250, Loss: 0.0433\n",
      "Epoch 34/200, Iteration 236/250, Loss: 0.0207\n",
      "Epoch 34/200, Iteration 237/250, Loss: 0.0253\n",
      "Epoch 34/200, Iteration 238/250, Loss: 0.0254\n",
      "Epoch 34/200, Iteration 239/250, Loss: 0.0261\n",
      "Epoch 34/200, Iteration 240/250, Loss: 0.0315\n",
      "Epoch 34/200, Iteration 241/250, Loss: 0.0278\n",
      "Epoch 34/200, Iteration 242/250, Loss: 0.0195\n",
      "Epoch 34/200, Iteration 243/250, Loss: 0.0179\n",
      "Epoch 34/200, Iteration 244/250, Loss: 0.0238\n",
      "Epoch 34/200, Iteration 245/250, Loss: 0.0224\n",
      "Epoch 34/200, Iteration 246/250, Loss: 0.0251\n",
      "Epoch 34/200, Iteration 247/250, Loss: 0.0211\n",
      "Epoch 34/200, Iteration 248/250, Loss: 0.0303\n",
      "Epoch 34/200, Iteration 249/250, Loss: 0.0155\n",
      "Epoch 34/200, Iteration 250/250, Loss: 0.0184\n",
      "Train Error: \n",
      " Accuracy: 38.21%, Avg loss: 0.021235, MRE: 1.833328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.25%, Avg loss: 0.020989, MRE: 2.239032 \n",
      "\n",
      "Epoch 35/200, Iteration 1/250, Loss: 0.0554\n",
      "Epoch 35/200, Iteration 2/250, Loss: 0.0210\n",
      "Epoch 35/200, Iteration 3/250, Loss: 0.0221\n",
      "Epoch 35/200, Iteration 4/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 5/250, Loss: 0.0232\n",
      "Epoch 35/200, Iteration 6/250, Loss: 0.0252\n",
      "Epoch 35/200, Iteration 7/250, Loss: 0.0216\n",
      "Epoch 35/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 35/200, Iteration 9/250, Loss: 0.0175\n",
      "Epoch 35/200, Iteration 10/250, Loss: 0.0283\n",
      "Epoch 35/200, Iteration 11/250, Loss: 0.0138\n",
      "Epoch 35/200, Iteration 12/250, Loss: 0.0118\n",
      "Epoch 35/200, Iteration 13/250, Loss: 0.0174\n",
      "Epoch 35/200, Iteration 14/250, Loss: 0.0111\n",
      "Epoch 35/200, Iteration 15/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 16/250, Loss: 0.0349\n",
      "Epoch 35/200, Iteration 17/250, Loss: 0.0162\n",
      "Epoch 35/200, Iteration 18/250, Loss: 0.0124\n",
      "Epoch 35/200, Iteration 19/250, Loss: 0.0210\n",
      "Epoch 35/200, Iteration 20/250, Loss: 0.0148\n",
      "Epoch 35/200, Iteration 21/250, Loss: 0.0207\n",
      "Epoch 35/200, Iteration 22/250, Loss: 0.0158\n",
      "Epoch 35/200, Iteration 23/250, Loss: 0.0143\n",
      "Epoch 35/200, Iteration 24/250, Loss: 0.0168\n",
      "Epoch 35/200, Iteration 25/250, Loss: 0.0268\n",
      "Epoch 35/200, Iteration 26/250, Loss: 0.0201\n",
      "Epoch 35/200, Iteration 27/250, Loss: 0.0147\n",
      "Epoch 35/200, Iteration 28/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 29/250, Loss: 0.0157\n",
      "Epoch 35/200, Iteration 30/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 31/250, Loss: 0.0175\n",
      "Epoch 35/200, Iteration 32/250, Loss: 0.0252\n",
      "Epoch 35/200, Iteration 33/250, Loss: 0.0120\n",
      "Epoch 35/200, Iteration 34/250, Loss: 0.0125\n",
      "Epoch 35/200, Iteration 35/250, Loss: 0.0152\n",
      "Epoch 35/200, Iteration 36/250, Loss: 0.0242\n",
      "Epoch 35/200, Iteration 37/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 38/250, Loss: 0.0172\n",
      "Epoch 35/200, Iteration 39/250, Loss: 0.0097\n",
      "Epoch 35/200, Iteration 40/250, Loss: 0.0199\n",
      "Epoch 35/200, Iteration 41/250, Loss: 0.0183\n",
      "Epoch 35/200, Iteration 42/250, Loss: 0.0213\n",
      "Epoch 35/200, Iteration 43/250, Loss: 0.0080\n",
      "Epoch 35/200, Iteration 44/250, Loss: 0.0127\n",
      "Epoch 35/200, Iteration 45/250, Loss: 0.0340\n",
      "Epoch 35/200, Iteration 46/250, Loss: 0.0134\n",
      "Epoch 35/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 35/200, Iteration 48/250, Loss: 0.0192\n",
      "Epoch 35/200, Iteration 49/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 50/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 51/250, Loss: 0.0097\n",
      "Epoch 35/200, Iteration 52/250, Loss: 0.0163\n",
      "Epoch 35/200, Iteration 53/250, Loss: 0.0142\n",
      "Epoch 35/200, Iteration 54/250, Loss: 0.0119\n",
      "Epoch 35/200, Iteration 55/250, Loss: 0.0130\n",
      "Epoch 35/200, Iteration 56/250, Loss: 0.0222\n",
      "Epoch 35/200, Iteration 57/250, Loss: 0.0232\n",
      "Epoch 35/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 35/200, Iteration 59/250, Loss: 0.0178\n",
      "Epoch 35/200, Iteration 60/250, Loss: 0.0106\n",
      "Epoch 35/200, Iteration 61/250, Loss: 0.0363\n",
      "Epoch 35/200, Iteration 62/250, Loss: 0.0204\n",
      "Epoch 35/200, Iteration 63/250, Loss: 0.0175\n",
      "Epoch 35/200, Iteration 64/250, Loss: 0.0143\n",
      "Epoch 35/200, Iteration 65/250, Loss: 0.0133\n",
      "Epoch 35/200, Iteration 66/250, Loss: 0.0213\n",
      "Epoch 35/200, Iteration 67/250, Loss: 0.0196\n",
      "Epoch 35/200, Iteration 68/250, Loss: 0.0199\n",
      "Epoch 35/200, Iteration 69/250, Loss: 0.0184\n",
      "Epoch 35/200, Iteration 70/250, Loss: 0.0333\n",
      "Epoch 35/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 35/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 35/200, Iteration 73/250, Loss: 0.0181\n",
      "Epoch 35/200, Iteration 74/250, Loss: 0.0138\n",
      "Epoch 35/200, Iteration 75/250, Loss: 0.0325\n",
      "Epoch 35/200, Iteration 76/250, Loss: 0.0175\n",
      "Epoch 35/200, Iteration 77/250, Loss: 0.0361\n",
      "Epoch 35/200, Iteration 78/250, Loss: 0.0108\n",
      "Epoch 35/200, Iteration 79/250, Loss: 0.0153\n",
      "Epoch 35/200, Iteration 80/250, Loss: 0.0171\n",
      "Epoch 35/200, Iteration 81/250, Loss: 0.0167\n",
      "Epoch 35/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 83/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 84/250, Loss: 0.0154\n",
      "Epoch 35/200, Iteration 85/250, Loss: 0.0257\n",
      "Epoch 35/200, Iteration 86/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 87/250, Loss: 0.0226\n",
      "Epoch 35/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 89/250, Loss: 0.0111\n",
      "Epoch 35/200, Iteration 90/250, Loss: 0.0131\n",
      "Epoch 35/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 92/250, Loss: 0.0167\n",
      "Epoch 35/200, Iteration 93/250, Loss: 0.0353\n",
      "Epoch 35/200, Iteration 94/250, Loss: 0.0161\n",
      "Epoch 35/200, Iteration 95/250, Loss: 0.0159\n",
      "Epoch 35/200, Iteration 96/250, Loss: 0.0087\n",
      "Epoch 35/200, Iteration 97/250, Loss: 0.0290\n",
      "Epoch 35/200, Iteration 98/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 99/250, Loss: 0.0142\n",
      "Epoch 35/200, Iteration 100/250, Loss: 0.0275\n",
      "Epoch 35/200, Iteration 101/250, Loss: 0.0093\n",
      "Epoch 35/200, Iteration 102/250, Loss: 0.0154\n",
      "Epoch 35/200, Iteration 103/250, Loss: 0.0155\n",
      "Epoch 35/200, Iteration 104/250, Loss: 0.0102\n",
      "Epoch 35/200, Iteration 105/250, Loss: 0.0237\n",
      "Epoch 35/200, Iteration 106/250, Loss: 0.0191\n",
      "Epoch 35/200, Iteration 107/250, Loss: 0.0219\n",
      "Epoch 35/200, Iteration 108/250, Loss: 0.0178\n",
      "Epoch 35/200, Iteration 109/250, Loss: 0.0166\n",
      "Epoch 35/200, Iteration 110/250, Loss: 0.0148\n",
      "Epoch 35/200, Iteration 111/250, Loss: 0.0227\n",
      "Epoch 35/200, Iteration 112/250, Loss: 0.0174\n",
      "Epoch 35/200, Iteration 113/250, Loss: 0.0314\n",
      "Epoch 35/200, Iteration 114/250, Loss: 0.0191\n",
      "Epoch 35/200, Iteration 115/250, Loss: 0.0249\n",
      "Epoch 35/200, Iteration 116/250, Loss: 0.0393\n",
      "Epoch 35/200, Iteration 117/250, Loss: 0.0192\n",
      "Epoch 35/200, Iteration 118/250, Loss: 0.0402\n",
      "Epoch 35/200, Iteration 119/250, Loss: 0.0305\n",
      "Epoch 35/200, Iteration 120/250, Loss: 0.0149\n",
      "Epoch 35/200, Iteration 121/250, Loss: 0.0145\n",
      "Epoch 35/200, Iteration 122/250, Loss: 0.0234\n",
      "Epoch 35/200, Iteration 123/250, Loss: 0.0174\n",
      "Epoch 35/200, Iteration 124/250, Loss: 0.0215\n",
      "Epoch 35/200, Iteration 125/250, Loss: 0.0262\n",
      "Epoch 35/200, Iteration 126/250, Loss: 0.0210\n",
      "Epoch 35/200, Iteration 127/250, Loss: 0.0149\n",
      "Epoch 35/200, Iteration 128/250, Loss: 0.0200\n",
      "Epoch 35/200, Iteration 129/250, Loss: 0.0214\n",
      "Epoch 35/200, Iteration 130/250, Loss: 0.0150\n",
      "Epoch 35/200, Iteration 131/250, Loss: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Iteration 132/250, Loss: 0.0147\n",
      "Epoch 35/200, Iteration 133/250, Loss: 0.0259\n",
      "Epoch 35/200, Iteration 134/250, Loss: 0.0205\n",
      "Epoch 35/200, Iteration 135/250, Loss: 0.0166\n",
      "Epoch 35/200, Iteration 136/250, Loss: 0.0174\n",
      "Epoch 35/200, Iteration 137/250, Loss: 0.0176\n",
      "Epoch 35/200, Iteration 138/250, Loss: 0.0187\n",
      "Epoch 35/200, Iteration 139/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 140/250, Loss: 0.0329\n",
      "Epoch 35/200, Iteration 141/250, Loss: 0.0153\n",
      "Epoch 35/200, Iteration 142/250, Loss: 0.0131\n",
      "Epoch 35/200, Iteration 143/250, Loss: 0.0168\n",
      "Epoch 35/200, Iteration 144/250, Loss: 0.0236\n",
      "Epoch 35/200, Iteration 145/250, Loss: 0.0232\n",
      "Epoch 35/200, Iteration 146/250, Loss: 0.0112\n",
      "Epoch 35/200, Iteration 147/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 148/250, Loss: 0.0204\n",
      "Epoch 35/200, Iteration 149/250, Loss: 0.0214\n",
      "Epoch 35/200, Iteration 150/250, Loss: 0.0145\n",
      "Epoch 35/200, Iteration 151/250, Loss: 0.0185\n",
      "Epoch 35/200, Iteration 152/250, Loss: 0.0304\n",
      "Epoch 35/200, Iteration 153/250, Loss: 0.0098\n",
      "Epoch 35/200, Iteration 154/250, Loss: 0.0164\n",
      "Epoch 35/200, Iteration 155/250, Loss: 0.0168\n",
      "Epoch 35/200, Iteration 156/250, Loss: 0.0119\n",
      "Epoch 35/200, Iteration 157/250, Loss: 0.0275\n",
      "Epoch 35/200, Iteration 158/250, Loss: 0.0136\n",
      "Epoch 35/200, Iteration 159/250, Loss: 0.0114\n",
      "Epoch 35/200, Iteration 160/250, Loss: 0.0385\n",
      "Epoch 35/200, Iteration 161/250, Loss: 0.0502\n",
      "Epoch 35/200, Iteration 162/250, Loss: 0.0475\n",
      "Epoch 35/200, Iteration 163/250, Loss: 0.0430\n",
      "Epoch 35/200, Iteration 164/250, Loss: 0.0351\n",
      "Epoch 35/200, Iteration 165/250, Loss: 0.0186\n",
      "Epoch 35/200, Iteration 166/250, Loss: 0.0163\n",
      "Epoch 35/200, Iteration 167/250, Loss: 0.0281\n",
      "Epoch 35/200, Iteration 168/250, Loss: 0.0130\n",
      "Epoch 35/200, Iteration 169/250, Loss: 0.0151\n",
      "Epoch 35/200, Iteration 170/250, Loss: 0.0135\n",
      "Epoch 35/200, Iteration 171/250, Loss: 0.0153\n",
      "Epoch 35/200, Iteration 172/250, Loss: 0.0161\n",
      "Epoch 35/200, Iteration 173/250, Loss: 0.0132\n",
      "Epoch 35/200, Iteration 174/250, Loss: 0.0344\n",
      "Epoch 35/200, Iteration 175/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 176/250, Loss: 0.0131\n",
      "Epoch 35/200, Iteration 177/250, Loss: 0.0208\n",
      "Epoch 35/200, Iteration 178/250, Loss: 0.0135\n",
      "Epoch 35/200, Iteration 179/250, Loss: 0.0152\n",
      "Epoch 35/200, Iteration 180/250, Loss: 0.0122\n",
      "Epoch 35/200, Iteration 181/250, Loss: 0.0100\n",
      "Epoch 35/200, Iteration 182/250, Loss: 0.0115\n",
      "Epoch 35/200, Iteration 183/250, Loss: 0.0160\n",
      "Epoch 35/200, Iteration 184/250, Loss: 0.0165\n",
      "Epoch 35/200, Iteration 185/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 186/250, Loss: 0.0299\n",
      "Epoch 35/200, Iteration 187/250, Loss: 0.0118\n",
      "Epoch 35/200, Iteration 188/250, Loss: 0.0239\n",
      "Epoch 35/200, Iteration 189/250, Loss: 0.0096\n",
      "Epoch 35/200, Iteration 190/250, Loss: 0.0134\n",
      "Epoch 35/200, Iteration 191/250, Loss: 0.0178\n",
      "Epoch 35/200, Iteration 192/250, Loss: 0.0144\n",
      "Epoch 35/200, Iteration 193/250, Loss: 0.0098\n",
      "Epoch 35/200, Iteration 194/250, Loss: 0.0167\n",
      "Epoch 35/200, Iteration 195/250, Loss: 0.0189\n",
      "Epoch 35/200, Iteration 196/250, Loss: 0.0124\n",
      "Epoch 35/200, Iteration 197/250, Loss: 0.0336\n",
      "Epoch 35/200, Iteration 198/250, Loss: 0.0148\n",
      "Epoch 35/200, Iteration 199/250, Loss: 0.0141\n",
      "Epoch 35/200, Iteration 200/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 201/250, Loss: 0.0164\n",
      "Epoch 35/200, Iteration 202/250, Loss: 0.0130\n",
      "Epoch 35/200, Iteration 203/250, Loss: 0.0128\n",
      "Epoch 35/200, Iteration 204/250, Loss: 0.0225\n",
      "Epoch 35/200, Iteration 205/250, Loss: 0.0458\n",
      "Epoch 35/200, Iteration 206/250, Loss: 0.0124\n",
      "Epoch 35/200, Iteration 207/250, Loss: 0.0173\n",
      "Epoch 35/200, Iteration 208/250, Loss: 0.0251\n",
      "Epoch 35/200, Iteration 209/250, Loss: 0.0449\n",
      "Epoch 35/200, Iteration 210/250, Loss: 0.0099\n",
      "Epoch 35/200, Iteration 211/250, Loss: 0.0181\n",
      "Epoch 35/200, Iteration 212/250, Loss: 0.0190\n",
      "Epoch 35/200, Iteration 213/250, Loss: 0.0155\n",
      "Epoch 35/200, Iteration 214/250, Loss: 0.0106\n",
      "Epoch 35/200, Iteration 215/250, Loss: 0.0184\n",
      "Epoch 35/200, Iteration 216/250, Loss: 0.0249\n",
      "Epoch 35/200, Iteration 217/250, Loss: 0.0446\n",
      "Epoch 35/200, Iteration 218/250, Loss: 0.0145\n",
      "Epoch 35/200, Iteration 219/250, Loss: 0.0276\n",
      "Epoch 35/200, Iteration 220/250, Loss: 0.0091\n",
      "Epoch 35/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 35/200, Iteration 222/250, Loss: 0.0393\n",
      "Epoch 35/200, Iteration 223/250, Loss: 0.0190\n",
      "Epoch 35/200, Iteration 224/250, Loss: 0.0117\n",
      "Epoch 35/200, Iteration 225/250, Loss: 0.0141\n",
      "Epoch 35/200, Iteration 226/250, Loss: 0.0172\n",
      "Epoch 35/200, Iteration 227/250, Loss: 0.0114\n",
      "Epoch 35/200, Iteration 228/250, Loss: 0.0120\n",
      "Epoch 35/200, Iteration 229/250, Loss: 0.0256\n",
      "Epoch 35/200, Iteration 230/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 231/250, Loss: 0.0140\n",
      "Epoch 35/200, Iteration 232/250, Loss: 0.0092\n",
      "Epoch 35/200, Iteration 233/250, Loss: 0.0133\n",
      "Epoch 35/200, Iteration 234/250, Loss: 0.0099\n",
      "Epoch 35/200, Iteration 235/250, Loss: 0.0155\n",
      "Epoch 35/200, Iteration 236/250, Loss: 0.0120\n",
      "Epoch 35/200, Iteration 237/250, Loss: 0.0107\n",
      "Epoch 35/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 35/200, Iteration 239/250, Loss: 0.0088\n",
      "Epoch 35/200, Iteration 240/250, Loss: 0.0114\n",
      "Epoch 35/200, Iteration 241/250, Loss: 0.0229\n",
      "Epoch 35/200, Iteration 242/250, Loss: 0.0172\n",
      "Epoch 35/200, Iteration 243/250, Loss: 0.0147\n",
      "Epoch 35/200, Iteration 244/250, Loss: 0.0232\n",
      "Epoch 35/200, Iteration 245/250, Loss: 0.0215\n",
      "Epoch 35/200, Iteration 246/250, Loss: 0.0151\n",
      "Epoch 35/200, Iteration 247/250, Loss: 0.0271\n",
      "Epoch 35/200, Iteration 248/250, Loss: 0.0072\n",
      "Epoch 35/200, Iteration 249/250, Loss: 0.0086\n",
      "Epoch 35/200, Iteration 250/250, Loss: 0.0112\n",
      "Train Error: \n",
      " Accuracy: 81.36%, Avg loss: 0.009623, MRE: 0.672534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.15%, Avg loss: 0.009987, MRE: 0.589675 \n",
      "\n",
      "Epoch 36/200, Iteration 1/250, Loss: 0.0216\n",
      "Epoch 36/200, Iteration 2/250, Loss: 0.0197\n",
      "Epoch 36/200, Iteration 3/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 4/250, Loss: 0.0209\n",
      "Epoch 36/200, Iteration 5/250, Loss: 0.0135\n",
      "Epoch 36/200, Iteration 6/250, Loss: 0.0185\n",
      "Epoch 36/200, Iteration 7/250, Loss: 0.0175\n",
      "Epoch 36/200, Iteration 8/250, Loss: 0.0113\n",
      "Epoch 36/200, Iteration 9/250, Loss: 0.0259\n",
      "Epoch 36/200, Iteration 10/250, Loss: 0.0175\n",
      "Epoch 36/200, Iteration 11/250, Loss: 0.0105\n",
      "Epoch 36/200, Iteration 12/250, Loss: 0.0198\n",
      "Epoch 36/200, Iteration 13/250, Loss: 0.0159\n",
      "Epoch 36/200, Iteration 14/250, Loss: 0.0164\n",
      "Epoch 36/200, Iteration 15/250, Loss: 0.0189\n",
      "Epoch 36/200, Iteration 16/250, Loss: 0.0261\n",
      "Epoch 36/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 36/200, Iteration 18/250, Loss: 0.0279\n",
      "Epoch 36/200, Iteration 19/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 20/250, Loss: 0.0147\n",
      "Epoch 36/200, Iteration 21/250, Loss: 0.0154\n",
      "Epoch 36/200, Iteration 22/250, Loss: 0.0459\n",
      "Epoch 36/200, Iteration 23/250, Loss: 0.0163\n",
      "Epoch 36/200, Iteration 24/250, Loss: 0.0171\n",
      "Epoch 36/200, Iteration 25/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 36/200, Iteration 27/250, Loss: 0.0165\n",
      "Epoch 36/200, Iteration 28/250, Loss: 0.0195\n",
      "Epoch 36/200, Iteration 29/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 30/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 31/250, Loss: 0.0244\n",
      "Epoch 36/200, Iteration 32/250, Loss: 0.0102\n",
      "Epoch 36/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 34/250, Loss: 0.0123\n",
      "Epoch 36/200, Iteration 35/250, Loss: 0.0162\n",
      "Epoch 36/200, Iteration 36/250, Loss: 0.0115\n",
      "Epoch 36/200, Iteration 37/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 38/250, Loss: 0.0179\n",
      "Epoch 36/200, Iteration 39/250, Loss: 0.0085\n",
      "Epoch 36/200, Iteration 40/250, Loss: 0.0314\n",
      "Epoch 36/200, Iteration 41/250, Loss: 0.0084\n",
      "Epoch 36/200, Iteration 42/250, Loss: 0.0161\n",
      "Epoch 36/200, Iteration 43/250, Loss: 0.0167\n",
      "Epoch 36/200, Iteration 44/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 45/250, Loss: 0.0173\n",
      "Epoch 36/200, Iteration 46/250, Loss: 0.0158\n",
      "Epoch 36/200, Iteration 47/250, Loss: 0.0309\n",
      "Epoch 36/200, Iteration 48/250, Loss: 0.0092\n",
      "Epoch 36/200, Iteration 49/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 50/250, Loss: 0.0087\n",
      "Epoch 36/200, Iteration 51/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 52/250, Loss: 0.0190\n",
      "Epoch 36/200, Iteration 53/250, Loss: 0.0148\n",
      "Epoch 36/200, Iteration 54/250, Loss: 0.0269\n",
      "Epoch 36/200, Iteration 55/250, Loss: 0.0203\n",
      "Epoch 36/200, Iteration 56/250, Loss: 0.0169\n",
      "Epoch 36/200, Iteration 57/250, Loss: 0.0170\n",
      "Epoch 36/200, Iteration 58/250, Loss: 0.0173\n",
      "Epoch 36/200, Iteration 59/250, Loss: 0.0069\n",
      "Epoch 36/200, Iteration 60/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 61/250, Loss: 0.0130\n",
      "Epoch 36/200, Iteration 62/250, Loss: 0.0166\n",
      "Epoch 36/200, Iteration 63/250, Loss: 0.0091\n",
      "Epoch 36/200, Iteration 64/250, Loss: 0.0331\n",
      "Epoch 36/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 36/200, Iteration 66/250, Loss: 0.0393\n",
      "Epoch 36/200, Iteration 67/250, Loss: 0.0108\n",
      "Epoch 36/200, Iteration 68/250, Loss: 0.0292\n",
      "Epoch 36/200, Iteration 69/250, Loss: 0.0104\n",
      "Epoch 36/200, Iteration 70/250, Loss: 0.0148\n",
      "Epoch 36/200, Iteration 71/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 72/250, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 36/200, Iteration 74/250, Loss: 0.0274\n",
      "Epoch 36/200, Iteration 75/250, Loss: 0.0209\n",
      "Epoch 36/200, Iteration 76/250, Loss: 0.0116\n",
      "Epoch 36/200, Iteration 77/250, Loss: 0.0182\n",
      "Epoch 36/200, Iteration 78/250, Loss: 0.0232\n",
      "Epoch 36/200, Iteration 79/250, Loss: 0.0110\n",
      "Epoch 36/200, Iteration 80/250, Loss: 0.0154\n",
      "Epoch 36/200, Iteration 81/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 82/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 83/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 84/250, Loss: 0.0132\n",
      "Epoch 36/200, Iteration 85/250, Loss: 0.0114\n",
      "Epoch 36/200, Iteration 86/250, Loss: 0.0148\n",
      "Epoch 36/200, Iteration 87/250, Loss: 0.0178\n",
      "Epoch 36/200, Iteration 88/250, Loss: 0.0215\n",
      "Epoch 36/200, Iteration 89/250, Loss: 0.0207\n",
      "Epoch 36/200, Iteration 90/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 91/250, Loss: 0.0125\n",
      "Epoch 36/200, Iteration 92/250, Loss: 0.0129\n",
      "Epoch 36/200, Iteration 93/250, Loss: 0.0192\n",
      "Epoch 36/200, Iteration 94/250, Loss: 0.0231\n",
      "Epoch 36/200, Iteration 95/250, Loss: 0.0143\n",
      "Epoch 36/200, Iteration 96/250, Loss: 0.0177\n",
      "Epoch 36/200, Iteration 97/250, Loss: 0.0157\n",
      "Epoch 36/200, Iteration 98/250, Loss: 0.0194\n",
      "Epoch 36/200, Iteration 99/250, Loss: 0.0263\n",
      "Epoch 36/200, Iteration 100/250, Loss: 0.0238\n",
      "Epoch 36/200, Iteration 101/250, Loss: 0.0111\n",
      "Epoch 36/200, Iteration 102/250, Loss: 0.0108\n",
      "Epoch 36/200, Iteration 103/250, Loss: 0.0103\n",
      "Epoch 36/200, Iteration 104/250, Loss: 0.0316\n",
      "Epoch 36/200, Iteration 105/250, Loss: 0.0240\n",
      "Epoch 36/200, Iteration 106/250, Loss: 0.0269\n",
      "Epoch 36/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 36/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 109/250, Loss: 0.0175\n",
      "Epoch 36/200, Iteration 110/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 111/250, Loss: 0.0171\n",
      "Epoch 36/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 36/200, Iteration 113/250, Loss: 0.0125\n",
      "Epoch 36/200, Iteration 114/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 115/250, Loss: 0.0146\n",
      "Epoch 36/200, Iteration 116/250, Loss: 0.0159\n",
      "Epoch 36/200, Iteration 117/250, Loss: 0.0269\n",
      "Epoch 36/200, Iteration 118/250, Loss: 0.0293\n",
      "Epoch 36/200, Iteration 119/250, Loss: 0.0127\n",
      "Epoch 36/200, Iteration 120/250, Loss: 0.0112\n",
      "Epoch 36/200, Iteration 121/250, Loss: 0.0121\n",
      "Epoch 36/200, Iteration 122/250, Loss: 0.0178\n",
      "Epoch 36/200, Iteration 123/250, Loss: 0.0124\n",
      "Epoch 36/200, Iteration 124/250, Loss: 0.0427\n",
      "Epoch 36/200, Iteration 125/250, Loss: 0.0151\n",
      "Epoch 36/200, Iteration 126/250, Loss: 0.0117\n",
      "Epoch 36/200, Iteration 127/250, Loss: 0.0138\n",
      "Epoch 36/200, Iteration 128/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 129/250, Loss: 0.0109\n",
      "Epoch 36/200, Iteration 130/250, Loss: 0.0121\n",
      "Epoch 36/200, Iteration 131/250, Loss: 0.0195\n",
      "Epoch 36/200, Iteration 132/250, Loss: 0.0105\n",
      "Epoch 36/200, Iteration 133/250, Loss: 0.0124\n",
      "Epoch 36/200, Iteration 134/250, Loss: 0.0232\n",
      "Epoch 36/200, Iteration 135/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 136/250, Loss: 0.0126\n",
      "Epoch 36/200, Iteration 137/250, Loss: 0.0117\n",
      "Epoch 36/200, Iteration 138/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 139/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 140/250, Loss: 0.0289\n",
      "Epoch 36/200, Iteration 141/250, Loss: 0.0204\n",
      "Epoch 36/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 36/200, Iteration 143/250, Loss: 0.0096\n",
      "Epoch 36/200, Iteration 144/250, Loss: 0.0248\n",
      "Epoch 36/200, Iteration 145/250, Loss: 0.0141\n",
      "Epoch 36/200, Iteration 146/250, Loss: 0.0197\n",
      "Epoch 36/200, Iteration 147/250, Loss: 0.0158\n",
      "Epoch 36/200, Iteration 148/250, Loss: 0.0125\n",
      "Epoch 36/200, Iteration 149/250, Loss: 0.0174\n",
      "Epoch 36/200, Iteration 150/250, Loss: 0.0172\n",
      "Epoch 36/200, Iteration 151/250, Loss: 0.0228\n",
      "Epoch 36/200, Iteration 152/250, Loss: 0.0101\n",
      "Epoch 36/200, Iteration 153/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 154/250, Loss: 0.0300\n",
      "Epoch 36/200, Iteration 155/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 156/250, Loss: 0.0141\n",
      "Epoch 36/200, Iteration 157/250, Loss: 0.0155\n",
      "Epoch 36/200, Iteration 158/250, Loss: 0.0227\n",
      "Epoch 36/200, Iteration 159/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 160/250, Loss: 0.0229\n",
      "Epoch 36/200, Iteration 161/250, Loss: 0.0109\n",
      "Epoch 36/200, Iteration 162/250, Loss: 0.0193\n",
      "Epoch 36/200, Iteration 163/250, Loss: 0.0232\n",
      "Epoch 36/200, Iteration 164/250, Loss: 0.0136\n",
      "Epoch 36/200, Iteration 165/250, Loss: 0.0225\n",
      "Epoch 36/200, Iteration 166/250, Loss: 0.0323\n",
      "Epoch 36/200, Iteration 167/250, Loss: 0.0274\n",
      "Epoch 36/200, Iteration 168/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 169/250, Loss: 0.0400\n",
      "Epoch 36/200, Iteration 170/250, Loss: 0.0179\n",
      "Epoch 36/200, Iteration 171/250, Loss: 0.0134\n",
      "Epoch 36/200, Iteration 172/250, Loss: 0.0135\n",
      "Epoch 36/200, Iteration 173/250, Loss: 0.0160\n",
      "Epoch 36/200, Iteration 174/250, Loss: 0.0255\n",
      "Epoch 36/200, Iteration 175/250, Loss: 0.0108\n",
      "Epoch 36/200, Iteration 176/250, Loss: 0.0091\n",
      "Epoch 36/200, Iteration 177/250, Loss: 0.0286\n",
      "Epoch 36/200, Iteration 178/250, Loss: 0.0131\n",
      "Epoch 36/200, Iteration 179/250, Loss: 0.0176\n",
      "Epoch 36/200, Iteration 180/250, Loss: 0.0249\n",
      "Epoch 36/200, Iteration 181/250, Loss: 0.0199\n",
      "Epoch 36/200, Iteration 182/250, Loss: 0.0479\n",
      "Epoch 36/200, Iteration 183/250, Loss: 0.0271\n",
      "Epoch 36/200, Iteration 184/250, Loss: 0.0178\n",
      "Epoch 36/200, Iteration 185/250, Loss: 0.0120\n",
      "Epoch 36/200, Iteration 186/250, Loss: 0.0125\n",
      "Epoch 36/200, Iteration 187/250, Loss: 0.0096\n",
      "Epoch 36/200, Iteration 188/250, Loss: 0.0232\n",
      "Epoch 36/200, Iteration 189/250, Loss: 0.0107\n",
      "Epoch 36/200, Iteration 190/250, Loss: 0.0160\n",
      "Epoch 36/200, Iteration 191/250, Loss: 0.0099\n",
      "Epoch 36/200, Iteration 192/250, Loss: 0.0116\n",
      "Epoch 36/200, Iteration 193/250, Loss: 0.0159\n",
      "Epoch 36/200, Iteration 194/250, Loss: 0.0219\n",
      "Epoch 36/200, Iteration 195/250, Loss: 0.0183\n",
      "Epoch 36/200, Iteration 196/250, Loss: 0.0121\n",
      "Epoch 36/200, Iteration 197/250, Loss: 0.0198\n",
      "Epoch 36/200, Iteration 198/250, Loss: 0.0151\n",
      "Epoch 36/200, Iteration 199/250, Loss: 0.0150\n",
      "Epoch 36/200, Iteration 200/250, Loss: 0.0207\n",
      "Epoch 36/200, Iteration 201/250, Loss: 0.0337\n",
      "Epoch 36/200, Iteration 202/250, Loss: 0.0173\n",
      "Epoch 36/200, Iteration 203/250, Loss: 0.0167\n",
      "Epoch 36/200, Iteration 204/250, Loss: 0.0099\n",
      "Epoch 36/200, Iteration 205/250, Loss: 0.0105\n",
      "Epoch 36/200, Iteration 206/250, Loss: 0.0288\n",
      "Epoch 36/200, Iteration 207/250, Loss: 0.0201\n",
      "Epoch 36/200, Iteration 208/250, Loss: 0.0108\n",
      "Epoch 36/200, Iteration 209/250, Loss: 0.0201\n",
      "Epoch 36/200, Iteration 210/250, Loss: 0.0273\n",
      "Epoch 36/200, Iteration 211/250, Loss: 0.0215\n",
      "Epoch 36/200, Iteration 212/250, Loss: 0.0132\n",
      "Epoch 36/200, Iteration 213/250, Loss: 0.0143\n",
      "Epoch 36/200, Iteration 214/250, Loss: 0.0162\n",
      "Epoch 36/200, Iteration 215/250, Loss: 0.0110\n",
      "Epoch 36/200, Iteration 216/250, Loss: 0.0162\n",
      "Epoch 36/200, Iteration 217/250, Loss: 0.0138\n",
      "Epoch 36/200, Iteration 218/250, Loss: 0.0214\n",
      "Epoch 36/200, Iteration 219/250, Loss: 0.0095\n",
      "Epoch 36/200, Iteration 220/250, Loss: 0.0186\n",
      "Epoch 36/200, Iteration 221/250, Loss: 0.0196\n",
      "Epoch 36/200, Iteration 222/250, Loss: 0.0283\n",
      "Epoch 36/200, Iteration 223/250, Loss: 0.0128\n",
      "Epoch 36/200, Iteration 224/250, Loss: 0.0122\n",
      "Epoch 36/200, Iteration 225/250, Loss: 0.0233\n",
      "Epoch 36/200, Iteration 226/250, Loss: 0.0171\n",
      "Epoch 36/200, Iteration 227/250, Loss: 0.0118\n",
      "Epoch 36/200, Iteration 228/250, Loss: 0.0173\n",
      "Epoch 36/200, Iteration 229/250, Loss: 0.0241\n",
      "Epoch 36/200, Iteration 230/250, Loss: 0.0257\n",
      "Epoch 36/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 36/200, Iteration 232/250, Loss: 0.0116\n",
      "Epoch 36/200, Iteration 233/250, Loss: 0.0366\n",
      "Epoch 36/200, Iteration 234/250, Loss: 0.0228\n",
      "Epoch 36/200, Iteration 235/250, Loss: 0.0258\n",
      "Epoch 36/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 36/200, Iteration 237/250, Loss: 0.0151\n",
      "Epoch 36/200, Iteration 238/250, Loss: 0.0163\n",
      "Epoch 36/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 36/200, Iteration 240/250, Loss: 0.0132\n",
      "Epoch 36/200, Iteration 241/250, Loss: 0.0100\n",
      "Epoch 36/200, Iteration 242/250, Loss: 0.0349\n",
      "Epoch 36/200, Iteration 243/250, Loss: 0.0371\n",
      "Epoch 36/200, Iteration 244/250, Loss: 0.0204\n",
      "Epoch 36/200, Iteration 245/250, Loss: 0.0133\n",
      "Epoch 36/200, Iteration 246/250, Loss: 0.0146\n",
      "Epoch 36/200, Iteration 247/250, Loss: 0.0119\n",
      "Epoch 36/200, Iteration 248/250, Loss: 0.0334\n",
      "Epoch 36/200, Iteration 249/250, Loss: 0.0209\n",
      "Epoch 36/200, Iteration 250/250, Loss: 0.0318\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.011186, MRE: 0.946419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.011633, MRE: 1.216556 \n",
      "\n",
      "Epoch 37/200, Iteration 1/250, Loss: 0.0125\n",
      "Epoch 37/200, Iteration 2/250, Loss: 0.0126\n",
      "Epoch 37/200, Iteration 3/250, Loss: 0.0253\n",
      "Epoch 37/200, Iteration 4/250, Loss: 0.0169\n",
      "Epoch 37/200, Iteration 5/250, Loss: 0.0164\n",
      "Epoch 37/200, Iteration 6/250, Loss: 0.0143\n",
      "Epoch 37/200, Iteration 7/250, Loss: 0.0139\n",
      "Epoch 37/200, Iteration 8/250, Loss: 0.0294\n",
      "Epoch 37/200, Iteration 9/250, Loss: 0.0190\n",
      "Epoch 37/200, Iteration 10/250, Loss: 0.0287\n",
      "Epoch 37/200, Iteration 11/250, Loss: 0.0244\n",
      "Epoch 37/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 37/200, Iteration 13/250, Loss: 0.0237\n",
      "Epoch 37/200, Iteration 14/250, Loss: 0.0096\n",
      "Epoch 37/200, Iteration 15/250, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 16/250, Loss: 0.0388\n",
      "Epoch 37/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 37/200, Iteration 18/250, Loss: 0.0288\n",
      "Epoch 37/200, Iteration 19/250, Loss: 0.0207\n",
      "Epoch 37/200, Iteration 20/250, Loss: 0.0338\n",
      "Epoch 37/200, Iteration 21/250, Loss: 0.0238\n",
      "Epoch 37/200, Iteration 22/250, Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Iteration 23/250, Loss: 0.0163\n",
      "Epoch 37/200, Iteration 24/250, Loss: 0.0097\n",
      "Epoch 37/200, Iteration 25/250, Loss: 0.0122\n",
      "Epoch 37/200, Iteration 26/250, Loss: 0.0136\n",
      "Epoch 37/200, Iteration 27/250, Loss: 0.0104\n",
      "Epoch 37/200, Iteration 28/250, Loss: 0.0276\n",
      "Epoch 37/200, Iteration 29/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 30/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 31/250, Loss: 0.0446\n",
      "Epoch 37/200, Iteration 32/250, Loss: 0.0224\n",
      "Epoch 37/200, Iteration 33/250, Loss: 0.0250\n",
      "Epoch 37/200, Iteration 34/250, Loss: 0.0224\n",
      "Epoch 37/200, Iteration 35/250, Loss: 0.0215\n",
      "Epoch 37/200, Iteration 36/250, Loss: 0.0251\n",
      "Epoch 37/200, Iteration 37/250, Loss: 0.0145\n",
      "Epoch 37/200, Iteration 38/250, Loss: 0.0327\n",
      "Epoch 37/200, Iteration 39/250, Loss: 0.0206\n",
      "Epoch 37/200, Iteration 40/250, Loss: 0.0272\n",
      "Epoch 37/200, Iteration 41/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 42/250, Loss: 0.0171\n",
      "Epoch 37/200, Iteration 43/250, Loss: 0.0141\n",
      "Epoch 37/200, Iteration 44/250, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 45/250, Loss: 0.0118\n",
      "Epoch 37/200, Iteration 46/250, Loss: 0.0148\n",
      "Epoch 37/200, Iteration 47/250, Loss: 0.0235\n",
      "Epoch 37/200, Iteration 48/250, Loss: 0.0281\n",
      "Epoch 37/200, Iteration 49/250, Loss: 0.0278\n",
      "Epoch 37/200, Iteration 50/250, Loss: 0.0189\n",
      "Epoch 37/200, Iteration 51/250, Loss: 0.0093\n",
      "Epoch 37/200, Iteration 52/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 53/250, Loss: 0.0230\n",
      "Epoch 37/200, Iteration 54/250, Loss: 0.0309\n",
      "Epoch 37/200, Iteration 55/250, Loss: 0.0219\n",
      "Epoch 37/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 37/200, Iteration 57/250, Loss: 0.0170\n",
      "Epoch 37/200, Iteration 58/250, Loss: 0.0119\n",
      "Epoch 37/200, Iteration 59/250, Loss: 0.0234\n",
      "Epoch 37/200, Iteration 60/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 61/250, Loss: 0.0271\n",
      "Epoch 37/200, Iteration 62/250, Loss: 0.0123\n",
      "Epoch 37/200, Iteration 63/250, Loss: 0.0162\n",
      "Epoch 37/200, Iteration 64/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 65/250, Loss: 0.0202\n",
      "Epoch 37/200, Iteration 66/250, Loss: 0.0145\n",
      "Epoch 37/200, Iteration 67/250, Loss: 0.0243\n",
      "Epoch 37/200, Iteration 68/250, Loss: 0.0340\n",
      "Epoch 37/200, Iteration 69/250, Loss: 0.0179\n",
      "Epoch 37/200, Iteration 70/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 71/250, Loss: 0.0231\n",
      "Epoch 37/200, Iteration 72/250, Loss: 0.0145\n",
      "Epoch 37/200, Iteration 73/250, Loss: 0.0203\n",
      "Epoch 37/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 37/200, Iteration 75/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 76/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 77/250, Loss: 0.0097\n",
      "Epoch 37/200, Iteration 78/250, Loss: 0.0143\n",
      "Epoch 37/200, Iteration 79/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 80/250, Loss: 0.0240\n",
      "Epoch 37/200, Iteration 81/250, Loss: 0.0212\n",
      "Epoch 37/200, Iteration 82/250, Loss: 0.0262\n",
      "Epoch 37/200, Iteration 83/250, Loss: 0.0170\n",
      "Epoch 37/200, Iteration 84/250, Loss: 0.0128\n",
      "Epoch 37/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 37/200, Iteration 86/250, Loss: 0.0320\n",
      "Epoch 37/200, Iteration 87/250, Loss: 0.0108\n",
      "Epoch 37/200, Iteration 88/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 89/250, Loss: 0.0161\n",
      "Epoch 37/200, Iteration 90/250, Loss: 0.0266\n",
      "Epoch 37/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 92/250, Loss: 0.0164\n",
      "Epoch 37/200, Iteration 93/250, Loss: 0.0209\n",
      "Epoch 37/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 37/200, Iteration 95/250, Loss: 0.0150\n",
      "Epoch 37/200, Iteration 96/250, Loss: 0.0184\n",
      "Epoch 37/200, Iteration 97/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 98/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 99/250, Loss: 0.0155\n",
      "Epoch 37/200, Iteration 100/250, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 101/250, Loss: 0.0126\n",
      "Epoch 37/200, Iteration 102/250, Loss: 0.0122\n",
      "Epoch 37/200, Iteration 103/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 104/250, Loss: 0.0254\n",
      "Epoch 37/200, Iteration 105/250, Loss: 0.0165\n",
      "Epoch 37/200, Iteration 106/250, Loss: 0.0287\n",
      "Epoch 37/200, Iteration 107/250, Loss: 0.0265\n",
      "Epoch 37/200, Iteration 108/250, Loss: 0.0128\n",
      "Epoch 37/200, Iteration 109/250, Loss: 0.0133\n",
      "Epoch 37/200, Iteration 110/250, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 111/250, Loss: 0.0105\n",
      "Epoch 37/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 37/200, Iteration 113/250, Loss: 0.0166\n",
      "Epoch 37/200, Iteration 114/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 115/250, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 116/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 117/250, Loss: 0.0157\n",
      "Epoch 37/200, Iteration 118/250, Loss: 0.0147\n",
      "Epoch 37/200, Iteration 119/250, Loss: 0.0092\n",
      "Epoch 37/200, Iteration 120/250, Loss: 0.0148\n",
      "Epoch 37/200, Iteration 121/250, Loss: 0.0295\n",
      "Epoch 37/200, Iteration 122/250, Loss: 0.0291\n",
      "Epoch 37/200, Iteration 123/250, Loss: 0.0114\n",
      "Epoch 37/200, Iteration 124/250, Loss: 0.0116\n",
      "Epoch 37/200, Iteration 125/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 126/250, Loss: 0.0232\n",
      "Epoch 37/200, Iteration 127/250, Loss: 0.0258\n",
      "Epoch 37/200, Iteration 128/250, Loss: 0.0116\n",
      "Epoch 37/200, Iteration 129/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 130/250, Loss: 0.0282\n",
      "Epoch 37/200, Iteration 131/250, Loss: 0.0306\n",
      "Epoch 37/200, Iteration 132/250, Loss: 0.0277\n",
      "Epoch 37/200, Iteration 133/250, Loss: 0.0126\n",
      "Epoch 37/200, Iteration 134/250, Loss: 0.0133\n",
      "Epoch 37/200, Iteration 135/250, Loss: 0.0267\n",
      "Epoch 37/200, Iteration 136/250, Loss: 0.0182\n",
      "Epoch 37/200, Iteration 137/250, Loss: 0.0223\n",
      "Epoch 37/200, Iteration 138/250, Loss: 0.0129\n",
      "Epoch 37/200, Iteration 139/250, Loss: 0.0146\n",
      "Epoch 37/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 37/200, Iteration 141/250, Loss: 0.0164\n",
      "Epoch 37/200, Iteration 142/250, Loss: 0.0179\n",
      "Epoch 37/200, Iteration 143/250, Loss: 0.0168\n",
      "Epoch 37/200, Iteration 144/250, Loss: 0.0264\n",
      "Epoch 37/200, Iteration 145/250, Loss: 0.0172\n",
      "Epoch 37/200, Iteration 146/250, Loss: 0.0174\n",
      "Epoch 37/200, Iteration 147/250, Loss: 0.0196\n",
      "Epoch 37/200, Iteration 148/250, Loss: 0.0231\n",
      "Epoch 37/200, Iteration 149/250, Loss: 0.0175\n",
      "Epoch 37/200, Iteration 150/250, Loss: 0.0344\n",
      "Epoch 37/200, Iteration 151/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 152/250, Loss: 0.0207\n",
      "Epoch 37/200, Iteration 153/250, Loss: 0.0355\n",
      "Epoch 37/200, Iteration 154/250, Loss: 0.0185\n",
      "Epoch 37/200, Iteration 155/250, Loss: 0.0120\n",
      "Epoch 37/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 37/200, Iteration 157/250, Loss: 0.0147\n",
      "Epoch 37/200, Iteration 158/250, Loss: 0.0148\n",
      "Epoch 37/200, Iteration 159/250, Loss: 0.0110\n",
      "Epoch 37/200, Iteration 160/250, Loss: 0.0401\n",
      "Epoch 37/200, Iteration 161/250, Loss: 0.0181\n",
      "Epoch 37/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 37/200, Iteration 163/250, Loss: 0.0272\n",
      "Epoch 37/200, Iteration 164/250, Loss: 0.0178\n",
      "Epoch 37/200, Iteration 165/250, Loss: 0.0212\n",
      "Epoch 37/200, Iteration 166/250, Loss: 0.0153\n",
      "Epoch 37/200, Iteration 167/250, Loss: 0.0160\n",
      "Epoch 37/200, Iteration 168/250, Loss: 0.0174\n",
      "Epoch 37/200, Iteration 169/250, Loss: 0.0226\n",
      "Epoch 37/200, Iteration 170/250, Loss: 0.0207\n",
      "Epoch 37/200, Iteration 171/250, Loss: 0.0214\n",
      "Epoch 37/200, Iteration 172/250, Loss: 0.0251\n",
      "Epoch 37/200, Iteration 173/250, Loss: 0.0131\n",
      "Epoch 37/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 37/200, Iteration 175/250, Loss: 0.0241\n",
      "Epoch 37/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 37/200, Iteration 177/250, Loss: 0.0257\n",
      "Epoch 37/200, Iteration 178/250, Loss: 0.0133\n",
      "Epoch 37/200, Iteration 179/250, Loss: 0.0125\n",
      "Epoch 37/200, Iteration 180/250, Loss: 0.0176\n",
      "Epoch 37/200, Iteration 181/250, Loss: 0.0186\n",
      "Epoch 37/200, Iteration 182/250, Loss: 0.0184\n",
      "Epoch 37/200, Iteration 183/250, Loss: 0.0205\n",
      "Epoch 37/200, Iteration 184/250, Loss: 0.0112\n",
      "Epoch 37/200, Iteration 185/250, Loss: 0.0214\n",
      "Epoch 37/200, Iteration 186/250, Loss: 0.0213\n",
      "Epoch 37/200, Iteration 187/250, Loss: 0.0105\n",
      "Epoch 37/200, Iteration 188/250, Loss: 0.0117\n",
      "Epoch 37/200, Iteration 189/250, Loss: 0.0158\n",
      "Epoch 37/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 37/200, Iteration 191/250, Loss: 0.0189\n",
      "Epoch 37/200, Iteration 192/250, Loss: 0.0159\n",
      "Epoch 37/200, Iteration 193/250, Loss: 0.0166\n",
      "Epoch 37/200, Iteration 194/250, Loss: 0.0135\n",
      "Epoch 37/200, Iteration 195/250, Loss: 0.0173\n",
      "Epoch 37/200, Iteration 196/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 197/250, Loss: 0.0120\n",
      "Epoch 37/200, Iteration 198/250, Loss: 0.0144\n",
      "Epoch 37/200, Iteration 199/250, Loss: 0.0113\n",
      "Epoch 37/200, Iteration 200/250, Loss: 0.0320\n",
      "Epoch 37/200, Iteration 201/250, Loss: 0.0272\n",
      "Epoch 37/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 37/200, Iteration 203/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 204/250, Loss: 0.0173\n",
      "Epoch 37/200, Iteration 205/250, Loss: 0.0138\n",
      "Epoch 37/200, Iteration 206/250, Loss: 0.0228\n",
      "Epoch 37/200, Iteration 207/250, Loss: 0.0235\n",
      "Epoch 37/200, Iteration 208/250, Loss: 0.0118\n",
      "Epoch 37/200, Iteration 209/250, Loss: 0.0356\n",
      "Epoch 37/200, Iteration 210/250, Loss: 0.0165\n",
      "Epoch 37/200, Iteration 211/250, Loss: 0.0203\n",
      "Epoch 37/200, Iteration 212/250, Loss: 0.0208\n",
      "Epoch 37/200, Iteration 213/250, Loss: 0.0205\n",
      "Epoch 37/200, Iteration 214/250, Loss: 0.0118\n",
      "Epoch 37/200, Iteration 215/250, Loss: 0.0106\n",
      "Epoch 37/200, Iteration 216/250, Loss: 0.0152\n",
      "Epoch 37/200, Iteration 217/250, Loss: 0.0129\n",
      "Epoch 37/200, Iteration 218/250, Loss: 0.0348\n",
      "Epoch 37/200, Iteration 219/250, Loss: 0.0120\n",
      "Epoch 37/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 37/200, Iteration 221/250, Loss: 0.0354\n",
      "Epoch 37/200, Iteration 222/250, Loss: 0.0098\n",
      "Epoch 37/200, Iteration 223/250, Loss: 0.0133\n",
      "Epoch 37/200, Iteration 224/250, Loss: 0.0113\n",
      "Epoch 37/200, Iteration 225/250, Loss: 0.0228\n",
      "Epoch 37/200, Iteration 226/250, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Iteration 227/250, Loss: 0.0183\n",
      "Epoch 37/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 37/200, Iteration 229/250, Loss: 0.0272\n",
      "Epoch 37/200, Iteration 230/250, Loss: 0.0139\n",
      "Epoch 37/200, Iteration 231/250, Loss: 0.0129\n",
      "Epoch 37/200, Iteration 232/250, Loss: 0.0312\n",
      "Epoch 37/200, Iteration 233/250, Loss: 0.0165\n",
      "Epoch 37/200, Iteration 234/250, Loss: 0.0111\n",
      "Epoch 37/200, Iteration 235/250, Loss: 0.0205\n",
      "Epoch 37/200, Iteration 236/250, Loss: 0.0124\n",
      "Epoch 37/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 238/250, Loss: 0.0109\n",
      "Epoch 37/200, Iteration 239/250, Loss: 0.0149\n",
      "Epoch 37/200, Iteration 240/250, Loss: 0.0198\n",
      "Epoch 37/200, Iteration 241/250, Loss: 0.0137\n",
      "Epoch 37/200, Iteration 242/250, Loss: 0.0185\n",
      "Epoch 37/200, Iteration 243/250, Loss: 0.0495\n",
      "Epoch 37/200, Iteration 244/250, Loss: 0.0181\n",
      "Epoch 37/200, Iteration 245/250, Loss: 0.0190\n",
      "Epoch 37/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 37/200, Iteration 247/250, Loss: 0.0183\n",
      "Epoch 37/200, Iteration 248/250, Loss: 0.0091\n",
      "Epoch 37/200, Iteration 249/250, Loss: 0.0157\n",
      "Epoch 37/200, Iteration 250/250, Loss: 0.0115\n",
      "Train Error: \n",
      " Accuracy: 79.29%, Avg loss: 0.008931, MRE: 0.672004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.009325, MRE: 0.609918 \n",
      "\n",
      "Epoch 38/200, Iteration 1/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 2/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 3/250, Loss: 0.0157\n",
      "Epoch 38/200, Iteration 4/250, Loss: 0.0217\n",
      "Epoch 38/200, Iteration 5/250, Loss: 0.0219\n",
      "Epoch 38/200, Iteration 6/250, Loss: 0.0170\n",
      "Epoch 38/200, Iteration 7/250, Loss: 0.0172\n",
      "Epoch 38/200, Iteration 8/250, Loss: 0.0133\n",
      "Epoch 38/200, Iteration 9/250, Loss: 0.0174\n",
      "Epoch 38/200, Iteration 10/250, Loss: 0.0097\n",
      "Epoch 38/200, Iteration 11/250, Loss: 0.0360\n",
      "Epoch 38/200, Iteration 12/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 13/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 38/200, Iteration 15/250, Loss: 0.0173\n",
      "Epoch 38/200, Iteration 16/250, Loss: 0.0146\n",
      "Epoch 38/200, Iteration 17/250, Loss: 0.0100\n",
      "Epoch 38/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 38/200, Iteration 19/250, Loss: 0.0139\n",
      "Epoch 38/200, Iteration 20/250, Loss: 0.0090\n",
      "Epoch 38/200, Iteration 21/250, Loss: 0.0182\n",
      "Epoch 38/200, Iteration 22/250, Loss: 0.0126\n",
      "Epoch 38/200, Iteration 23/250, Loss: 0.0137\n",
      "Epoch 38/200, Iteration 24/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 25/250, Loss: 0.0202\n",
      "Epoch 38/200, Iteration 26/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 27/250, Loss: 0.0124\n",
      "Epoch 38/200, Iteration 28/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 29/250, Loss: 0.0139\n",
      "Epoch 38/200, Iteration 30/250, Loss: 0.0119\n",
      "Epoch 38/200, Iteration 31/250, Loss: 0.0127\n",
      "Epoch 38/200, Iteration 32/250, Loss: 0.0096\n",
      "Epoch 38/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 34/250, Loss: 0.0241\n",
      "Epoch 38/200, Iteration 35/250, Loss: 0.0167\n",
      "Epoch 38/200, Iteration 36/250, Loss: 0.0163\n",
      "Epoch 38/200, Iteration 37/250, Loss: 0.0441\n",
      "Epoch 38/200, Iteration 38/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 39/250, Loss: 0.0098\n",
      "Epoch 38/200, Iteration 40/250, Loss: 0.0347\n",
      "Epoch 38/200, Iteration 41/250, Loss: 0.0306\n",
      "Epoch 38/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 43/250, Loss: 0.0181\n",
      "Epoch 38/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 38/200, Iteration 45/250, Loss: 0.0123\n",
      "Epoch 38/200, Iteration 46/250, Loss: 0.0171\n",
      "Epoch 38/200, Iteration 47/250, Loss: 0.0082\n",
      "Epoch 38/200, Iteration 48/250, Loss: 0.0078\n",
      "Epoch 38/200, Iteration 49/250, Loss: 0.0149\n",
      "Epoch 38/200, Iteration 50/250, Loss: 0.0156\n",
      "Epoch 38/200, Iteration 51/250, Loss: 0.0165\n",
      "Epoch 38/200, Iteration 52/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 53/250, Loss: 0.0085\n",
      "Epoch 38/200, Iteration 54/250, Loss: 0.0087\n",
      "Epoch 38/200, Iteration 55/250, Loss: 0.0112\n",
      "Epoch 38/200, Iteration 56/250, Loss: 0.0172\n",
      "Epoch 38/200, Iteration 57/250, Loss: 0.0223\n",
      "Epoch 38/200, Iteration 58/250, Loss: 0.0230\n",
      "Epoch 38/200, Iteration 59/250, Loss: 0.0141\n",
      "Epoch 38/200, Iteration 60/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 61/250, Loss: 0.0224\n",
      "Epoch 38/200, Iteration 62/250, Loss: 0.0163\n",
      "Epoch 38/200, Iteration 63/250, Loss: 0.0151\n",
      "Epoch 38/200, Iteration 64/250, Loss: 0.0260\n",
      "Epoch 38/200, Iteration 65/250, Loss: 0.0157\n",
      "Epoch 38/200, Iteration 66/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 67/250, Loss: 0.0106\n",
      "Epoch 38/200, Iteration 68/250, Loss: 0.0233\n",
      "Epoch 38/200, Iteration 69/250, Loss: 0.0256\n",
      "Epoch 38/200, Iteration 70/250, Loss: 0.0135\n",
      "Epoch 38/200, Iteration 71/250, Loss: 0.0167\n",
      "Epoch 38/200, Iteration 72/250, Loss: 0.0169\n",
      "Epoch 38/200, Iteration 73/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 74/250, Loss: 0.0107\n",
      "Epoch 38/200, Iteration 75/250, Loss: 0.0146\n",
      "Epoch 38/200, Iteration 76/250, Loss: 0.0190\n",
      "Epoch 38/200, Iteration 77/250, Loss: 0.0185\n",
      "Epoch 38/200, Iteration 78/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 38/200, Iteration 80/250, Loss: 0.0158\n",
      "Epoch 38/200, Iteration 81/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 82/250, Loss: 0.0118\n",
      "Epoch 38/200, Iteration 83/250, Loss: 0.0154\n",
      "Epoch 38/200, Iteration 84/250, Loss: 0.0208\n",
      "Epoch 38/200, Iteration 85/250, Loss: 0.0190\n",
      "Epoch 38/200, Iteration 86/250, Loss: 0.0228\n",
      "Epoch 38/200, Iteration 87/250, Loss: 0.0155\n",
      "Epoch 38/200, Iteration 88/250, Loss: 0.0194\n",
      "Epoch 38/200, Iteration 89/250, Loss: 0.0214\n",
      "Epoch 38/200, Iteration 90/250, Loss: 0.0112\n",
      "Epoch 38/200, Iteration 91/250, Loss: 0.0186\n",
      "Epoch 38/200, Iteration 92/250, Loss: 0.0193\n",
      "Epoch 38/200, Iteration 93/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 94/250, Loss: 0.0160\n",
      "Epoch 38/200, Iteration 95/250, Loss: 0.0175\n",
      "Epoch 38/200, Iteration 96/250, Loss: 0.0395\n",
      "Epoch 38/200, Iteration 97/250, Loss: 0.0177\n",
      "Epoch 38/200, Iteration 98/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 99/250, Loss: 0.0148\n",
      "Epoch 38/200, Iteration 100/250, Loss: 0.0092\n",
      "Epoch 38/200, Iteration 101/250, Loss: 0.0096\n",
      "Epoch 38/200, Iteration 102/250, Loss: 0.0247\n",
      "Epoch 38/200, Iteration 103/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 104/250, Loss: 0.0137\n",
      "Epoch 38/200, Iteration 105/250, Loss: 0.0216\n",
      "Epoch 38/200, Iteration 106/250, Loss: 0.0132\n",
      "Epoch 38/200, Iteration 107/250, Loss: 0.0173\n",
      "Epoch 38/200, Iteration 108/250, Loss: 0.0170\n",
      "Epoch 38/200, Iteration 109/250, Loss: 0.0198\n",
      "Epoch 38/200, Iteration 110/250, Loss: 0.0152\n",
      "Epoch 38/200, Iteration 111/250, Loss: 0.0177\n",
      "Epoch 38/200, Iteration 112/250, Loss: 0.0096\n",
      "Epoch 38/200, Iteration 113/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 114/250, Loss: 0.0177\n",
      "Epoch 38/200, Iteration 115/250, Loss: 0.0171\n",
      "Epoch 38/200, Iteration 116/250, Loss: 0.0094\n",
      "Epoch 38/200, Iteration 117/250, Loss: 0.0197\n",
      "Epoch 38/200, Iteration 118/250, Loss: 0.0403\n",
      "Epoch 38/200, Iteration 119/250, Loss: 0.0389\n",
      "Epoch 38/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 38/200, Iteration 121/250, Loss: 0.0156\n",
      "Epoch 38/200, Iteration 122/250, Loss: 0.0148\n",
      "Epoch 38/200, Iteration 123/250, Loss: 0.0276\n",
      "Epoch 38/200, Iteration 124/250, Loss: 0.0185\n",
      "Epoch 38/200, Iteration 125/250, Loss: 0.0182\n",
      "Epoch 38/200, Iteration 126/250, Loss: 0.0277\n",
      "Epoch 38/200, Iteration 127/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 128/250, Loss: 0.0182\n",
      "Epoch 38/200, Iteration 129/250, Loss: 0.0142\n",
      "Epoch 38/200, Iteration 130/250, Loss: 0.0138\n",
      "Epoch 38/200, Iteration 131/250, Loss: 0.0169\n",
      "Epoch 38/200, Iteration 132/250, Loss: 0.0172\n",
      "Epoch 38/200, Iteration 133/250, Loss: 0.0169\n",
      "Epoch 38/200, Iteration 134/250, Loss: 0.0246\n",
      "Epoch 38/200, Iteration 135/250, Loss: 0.0148\n",
      "Epoch 38/200, Iteration 136/250, Loss: 0.0101\n",
      "Epoch 38/200, Iteration 137/250, Loss: 0.0252\n",
      "Epoch 38/200, Iteration 138/250, Loss: 0.0121\n",
      "Epoch 38/200, Iteration 139/250, Loss: 0.0222\n",
      "Epoch 38/200, Iteration 140/250, Loss: 0.0122\n",
      "Epoch 38/200, Iteration 141/250, Loss: 0.0174\n",
      "Epoch 38/200, Iteration 142/250, Loss: 0.0107\n",
      "Epoch 38/200, Iteration 143/250, Loss: 0.0210\n",
      "Epoch 38/200, Iteration 144/250, Loss: 0.0106\n",
      "Epoch 38/200, Iteration 145/250, Loss: 0.0130\n",
      "Epoch 38/200, Iteration 146/250, Loss: 0.0296\n",
      "Epoch 38/200, Iteration 147/250, Loss: 0.0236\n",
      "Epoch 38/200, Iteration 148/250, Loss: 0.0177\n",
      "Epoch 38/200, Iteration 149/250, Loss: 0.0192\n",
      "Epoch 38/200, Iteration 150/250, Loss: 0.0143\n",
      "Epoch 38/200, Iteration 151/250, Loss: 0.0088\n",
      "Epoch 38/200, Iteration 152/250, Loss: 0.0309\n",
      "Epoch 38/200, Iteration 153/250, Loss: 0.0276\n",
      "Epoch 38/200, Iteration 154/250, Loss: 0.0130\n",
      "Epoch 38/200, Iteration 155/250, Loss: 0.0184\n",
      "Epoch 38/200, Iteration 156/250, Loss: 0.0344\n",
      "Epoch 38/200, Iteration 157/250, Loss: 0.0094\n",
      "Epoch 38/200, Iteration 158/250, Loss: 0.0313\n",
      "Epoch 38/200, Iteration 159/250, Loss: 0.0133\n",
      "Epoch 38/200, Iteration 160/250, Loss: 0.0209\n",
      "Epoch 38/200, Iteration 161/250, Loss: 0.0152\n",
      "Epoch 38/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 163/250, Loss: 0.0137\n",
      "Epoch 38/200, Iteration 164/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 165/250, Loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Iteration 166/250, Loss: 0.0145\n",
      "Epoch 38/200, Iteration 167/250, Loss: 0.0136\n",
      "Epoch 38/200, Iteration 168/250, Loss: 0.0143\n",
      "Epoch 38/200, Iteration 169/250, Loss: 0.0150\n",
      "Epoch 38/200, Iteration 170/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 171/250, Loss: 0.0097\n",
      "Epoch 38/200, Iteration 172/250, Loss: 0.0093\n",
      "Epoch 38/200, Iteration 173/250, Loss: 0.0217\n",
      "Epoch 38/200, Iteration 174/250, Loss: 0.0237\n",
      "Epoch 38/200, Iteration 175/250, Loss: 0.0103\n",
      "Epoch 38/200, Iteration 176/250, Loss: 0.0159\n",
      "Epoch 38/200, Iteration 177/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 178/250, Loss: 0.0164\n",
      "Epoch 38/200, Iteration 179/250, Loss: 0.0102\n",
      "Epoch 38/200, Iteration 180/250, Loss: 0.0135\n",
      "Epoch 38/200, Iteration 181/250, Loss: 0.0140\n",
      "Epoch 38/200, Iteration 182/250, Loss: 0.0154\n",
      "Epoch 38/200, Iteration 183/250, Loss: 0.0152\n",
      "Epoch 38/200, Iteration 184/250, Loss: 0.0131\n",
      "Epoch 38/200, Iteration 185/250, Loss: 0.0163\n",
      "Epoch 38/200, Iteration 186/250, Loss: 0.0330\n",
      "Epoch 38/200, Iteration 187/250, Loss: 0.0107\n",
      "Epoch 38/200, Iteration 188/250, Loss: 0.0130\n",
      "Epoch 38/200, Iteration 189/250, Loss: 0.0137\n",
      "Epoch 38/200, Iteration 190/250, Loss: 0.0311\n",
      "Epoch 38/200, Iteration 191/250, Loss: 0.0087\n",
      "Epoch 38/200, Iteration 192/250, Loss: 0.0106\n",
      "Epoch 38/200, Iteration 193/250, Loss: 0.0127\n",
      "Epoch 38/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 38/200, Iteration 195/250, Loss: 0.0356\n",
      "Epoch 38/200, Iteration 196/250, Loss: 0.0123\n",
      "Epoch 38/200, Iteration 197/250, Loss: 0.0081\n",
      "Epoch 38/200, Iteration 198/250, Loss: 0.0128\n",
      "Epoch 38/200, Iteration 199/250, Loss: 0.0098\n",
      "Epoch 38/200, Iteration 200/250, Loss: 0.0189\n",
      "Epoch 38/200, Iteration 201/250, Loss: 0.0091\n",
      "Epoch 38/200, Iteration 202/250, Loss: 0.0238\n",
      "Epoch 38/200, Iteration 203/250, Loss: 0.0118\n",
      "Epoch 38/200, Iteration 204/250, Loss: 0.0235\n",
      "Epoch 38/200, Iteration 205/250, Loss: 0.0109\n",
      "Epoch 38/200, Iteration 206/250, Loss: 0.0241\n",
      "Epoch 38/200, Iteration 207/250, Loss: 0.0101\n",
      "Epoch 38/200, Iteration 208/250, Loss: 0.0143\n",
      "Epoch 38/200, Iteration 209/250, Loss: 0.0209\n",
      "Epoch 38/200, Iteration 210/250, Loss: 0.0220\n",
      "Epoch 38/200, Iteration 211/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 212/250, Loss: 0.0228\n",
      "Epoch 38/200, Iteration 213/250, Loss: 0.0105\n",
      "Epoch 38/200, Iteration 214/250, Loss: 0.0158\n",
      "Epoch 38/200, Iteration 215/250, Loss: 0.0316\n",
      "Epoch 38/200, Iteration 216/250, Loss: 0.0146\n",
      "Epoch 38/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 38/200, Iteration 218/250, Loss: 0.0205\n",
      "Epoch 38/200, Iteration 219/250, Loss: 0.0293\n",
      "Epoch 38/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 38/200, Iteration 221/250, Loss: 0.0265\n",
      "Epoch 38/200, Iteration 222/250, Loss: 0.0101\n",
      "Epoch 38/200, Iteration 223/250, Loss: 0.0122\n",
      "Epoch 38/200, Iteration 224/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 225/250, Loss: 0.0219\n",
      "Epoch 38/200, Iteration 226/250, Loss: 0.0093\n",
      "Epoch 38/200, Iteration 227/250, Loss: 0.0078\n",
      "Epoch 38/200, Iteration 228/250, Loss: 0.0101\n",
      "Epoch 38/200, Iteration 229/250, Loss: 0.0108\n",
      "Epoch 38/200, Iteration 230/250, Loss: 0.0116\n",
      "Epoch 38/200, Iteration 231/250, Loss: 0.0117\n",
      "Epoch 38/200, Iteration 232/250, Loss: 0.0124\n",
      "Epoch 38/200, Iteration 233/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 38/200, Iteration 235/250, Loss: 0.0149\n",
      "Epoch 38/200, Iteration 236/250, Loss: 0.0168\n",
      "Epoch 38/200, Iteration 237/250, Loss: 0.0153\n",
      "Epoch 38/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 38/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 38/200, Iteration 240/250, Loss: 0.0155\n",
      "Epoch 38/200, Iteration 241/250, Loss: 0.0140\n",
      "Epoch 38/200, Iteration 242/250, Loss: 0.0209\n",
      "Epoch 38/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 38/200, Iteration 244/250, Loss: 0.0210\n",
      "Epoch 38/200, Iteration 245/250, Loss: 0.0448\n",
      "Epoch 38/200, Iteration 246/250, Loss: 0.0059\n",
      "Epoch 38/200, Iteration 247/250, Loss: 0.0183\n",
      "Epoch 38/200, Iteration 248/250, Loss: 0.0138\n",
      "Epoch 38/200, Iteration 249/250, Loss: 0.0221\n",
      "Epoch 38/200, Iteration 250/250, Loss: 0.0140\n",
      "Train Error: \n",
      " Accuracy: 82.62%, Avg loss: 0.010125, MRE: 0.808125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.010528, MRE: 1.057195 \n",
      "\n",
      "Epoch 39/200, Iteration 1/250, Loss: 0.0147\n",
      "Epoch 39/200, Iteration 2/250, Loss: 0.0304\n",
      "Epoch 39/200, Iteration 3/250, Loss: 0.0142\n",
      "Epoch 39/200, Iteration 4/250, Loss: 0.0097\n",
      "Epoch 39/200, Iteration 5/250, Loss: 0.0348\n",
      "Epoch 39/200, Iteration 6/250, Loss: 0.0220\n",
      "Epoch 39/200, Iteration 7/250, Loss: 0.0110\n",
      "Epoch 39/200, Iteration 8/250, Loss: 0.0169\n",
      "Epoch 39/200, Iteration 9/250, Loss: 0.0222\n",
      "Epoch 39/200, Iteration 10/250, Loss: 0.0102\n",
      "Epoch 39/200, Iteration 11/250, Loss: 0.0230\n",
      "Epoch 39/200, Iteration 12/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 13/250, Loss: 0.0462\n",
      "Epoch 39/200, Iteration 14/250, Loss: 0.0110\n",
      "Epoch 39/200, Iteration 15/250, Loss: 0.0124\n",
      "Epoch 39/200, Iteration 16/250, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 17/250, Loss: 0.0212\n",
      "Epoch 39/200, Iteration 18/250, Loss: 0.0242\n",
      "Epoch 39/200, Iteration 19/250, Loss: 0.0267\n",
      "Epoch 39/200, Iteration 20/250, Loss: 0.0155\n",
      "Epoch 39/200, Iteration 21/250, Loss: 0.0126\n",
      "Epoch 39/200, Iteration 22/250, Loss: 0.0304\n",
      "Epoch 39/200, Iteration 23/250, Loss: 0.0191\n",
      "Epoch 39/200, Iteration 24/250, Loss: 0.0103\n",
      "Epoch 39/200, Iteration 25/250, Loss: 0.0141\n",
      "Epoch 39/200, Iteration 26/250, Loss: 0.0125\n",
      "Epoch 39/200, Iteration 27/250, Loss: 0.0234\n",
      "Epoch 39/200, Iteration 28/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 39/200, Iteration 30/250, Loss: 0.0165\n",
      "Epoch 39/200, Iteration 31/250, Loss: 0.0248\n",
      "Epoch 39/200, Iteration 32/250, Loss: 0.0170\n",
      "Epoch 39/200, Iteration 33/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 34/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 35/250, Loss: 0.0083\n",
      "Epoch 39/200, Iteration 36/250, Loss: 0.0213\n",
      "Epoch 39/200, Iteration 37/250, Loss: 0.0162\n",
      "Epoch 39/200, Iteration 38/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 39/250, Loss: 0.0197\n",
      "Epoch 39/200, Iteration 40/250, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 41/250, Loss: 0.0289\n",
      "Epoch 39/200, Iteration 42/250, Loss: 0.0131\n",
      "Epoch 39/200, Iteration 43/250, Loss: 0.0092\n",
      "Epoch 39/200, Iteration 44/250, Loss: 0.0208\n",
      "Epoch 39/200, Iteration 45/250, Loss: 0.0278\n",
      "Epoch 39/200, Iteration 46/250, Loss: 0.0158\n",
      "Epoch 39/200, Iteration 47/250, Loss: 0.0149\n",
      "Epoch 39/200, Iteration 48/250, Loss: 0.0103\n",
      "Epoch 39/200, Iteration 49/250, Loss: 0.0355\n",
      "Epoch 39/200, Iteration 50/250, Loss: 0.0259\n",
      "Epoch 39/200, Iteration 51/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 52/250, Loss: 0.0210\n",
      "Epoch 39/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 39/200, Iteration 54/250, Loss: 0.0157\n",
      "Epoch 39/200, Iteration 55/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 56/250, Loss: 0.0174\n",
      "Epoch 39/200, Iteration 57/250, Loss: 0.0131\n",
      "Epoch 39/200, Iteration 58/250, Loss: 0.0197\n",
      "Epoch 39/200, Iteration 59/250, Loss: 0.0246\n",
      "Epoch 39/200, Iteration 60/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 61/250, Loss: 0.0173\n",
      "Epoch 39/200, Iteration 62/250, Loss: 0.0201\n",
      "Epoch 39/200, Iteration 63/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 64/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 65/250, Loss: 0.0170\n",
      "Epoch 39/200, Iteration 66/250, Loss: 0.0277\n",
      "Epoch 39/200, Iteration 67/250, Loss: 0.0242\n",
      "Epoch 39/200, Iteration 68/250, Loss: 0.0276\n",
      "Epoch 39/200, Iteration 69/250, Loss: 0.0264\n",
      "Epoch 39/200, Iteration 70/250, Loss: 0.0234\n",
      "Epoch 39/200, Iteration 71/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 72/250, Loss: 0.0097\n",
      "Epoch 39/200, Iteration 73/250, Loss: 0.0161\n",
      "Epoch 39/200, Iteration 74/250, Loss: 0.0109\n",
      "Epoch 39/200, Iteration 75/250, Loss: 0.0141\n",
      "Epoch 39/200, Iteration 76/250, Loss: 0.0128\n",
      "Epoch 39/200, Iteration 77/250, Loss: 0.0092\n",
      "Epoch 39/200, Iteration 78/250, Loss: 0.0146\n",
      "Epoch 39/200, Iteration 79/250, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 80/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 81/250, Loss: 0.0209\n",
      "Epoch 39/200, Iteration 82/250, Loss: 0.0094\n",
      "Epoch 39/200, Iteration 83/250, Loss: 0.0137\n",
      "Epoch 39/200, Iteration 84/250, Loss: 0.0181\n",
      "Epoch 39/200, Iteration 85/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 86/250, Loss: 0.0206\n",
      "Epoch 39/200, Iteration 87/250, Loss: 0.0170\n",
      "Epoch 39/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 39/200, Iteration 89/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 90/250, Loss: 0.0179\n",
      "Epoch 39/200, Iteration 91/250, Loss: 0.0167\n",
      "Epoch 39/200, Iteration 92/250, Loss: 0.0135\n",
      "Epoch 39/200, Iteration 93/250, Loss: 0.0292\n",
      "Epoch 39/200, Iteration 94/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 95/250, Loss: 0.0284\n",
      "Epoch 39/200, Iteration 96/250, Loss: 0.0104\n",
      "Epoch 39/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 39/200, Iteration 98/250, Loss: 0.0173\n",
      "Epoch 39/200, Iteration 99/250, Loss: 0.0130\n",
      "Epoch 39/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 39/200, Iteration 101/250, Loss: 0.0089\n",
      "Epoch 39/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 39/200, Iteration 103/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 104/250, Loss: 0.0326\n",
      "Epoch 39/200, Iteration 105/250, Loss: 0.0227\n",
      "Epoch 39/200, Iteration 106/250, Loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Iteration 107/250, Loss: 0.0165\n",
      "Epoch 39/200, Iteration 108/250, Loss: 0.0148\n",
      "Epoch 39/200, Iteration 109/250, Loss: 0.0320\n",
      "Epoch 39/200, Iteration 110/250, Loss: 0.0107\n",
      "Epoch 39/200, Iteration 111/250, Loss: 0.0130\n",
      "Epoch 39/200, Iteration 112/250, Loss: 0.0202\n",
      "Epoch 39/200, Iteration 113/250, Loss: 0.0172\n",
      "Epoch 39/200, Iteration 114/250, Loss: 0.0136\n",
      "Epoch 39/200, Iteration 115/250, Loss: 0.0088\n",
      "Epoch 39/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 39/200, Iteration 117/250, Loss: 0.0169\n",
      "Epoch 39/200, Iteration 118/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 119/250, Loss: 0.0140\n",
      "Epoch 39/200, Iteration 120/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 121/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 122/250, Loss: 0.0123\n",
      "Epoch 39/200, Iteration 123/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 124/250, Loss: 0.0111\n",
      "Epoch 39/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 126/250, Loss: 0.0188\n",
      "Epoch 39/200, Iteration 127/250, Loss: 0.0081\n",
      "Epoch 39/200, Iteration 128/250, Loss: 0.0108\n",
      "Epoch 39/200, Iteration 129/250, Loss: 0.0100\n",
      "Epoch 39/200, Iteration 130/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 131/250, Loss: 0.0339\n",
      "Epoch 39/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 133/250, Loss: 0.0115\n",
      "Epoch 39/200, Iteration 134/250, Loss: 0.0094\n",
      "Epoch 39/200, Iteration 135/250, Loss: 0.0112\n",
      "Epoch 39/200, Iteration 136/250, Loss: 0.0132\n",
      "Epoch 39/200, Iteration 137/250, Loss: 0.0112\n",
      "Epoch 39/200, Iteration 138/250, Loss: 0.0163\n",
      "Epoch 39/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 39/200, Iteration 140/250, Loss: 0.0287\n",
      "Epoch 39/200, Iteration 141/250, Loss: 0.0106\n",
      "Epoch 39/200, Iteration 142/250, Loss: 0.0247\n",
      "Epoch 39/200, Iteration 143/250, Loss: 0.0132\n",
      "Epoch 39/200, Iteration 144/250, Loss: 0.0405\n",
      "Epoch 39/200, Iteration 145/250, Loss: 0.0090\n",
      "Epoch 39/200, Iteration 146/250, Loss: 0.0217\n",
      "Epoch 39/200, Iteration 147/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 148/250, Loss: 0.0150\n",
      "Epoch 39/200, Iteration 149/250, Loss: 0.0156\n",
      "Epoch 39/200, Iteration 150/250, Loss: 0.0299\n",
      "Epoch 39/200, Iteration 151/250, Loss: 0.0139\n",
      "Epoch 39/200, Iteration 152/250, Loss: 0.0191\n",
      "Epoch 39/200, Iteration 153/250, Loss: 0.0132\n",
      "Epoch 39/200, Iteration 154/250, Loss: 0.0175\n",
      "Epoch 39/200, Iteration 155/250, Loss: 0.0230\n",
      "Epoch 39/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 157/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 158/250, Loss: 0.0126\n",
      "Epoch 39/200, Iteration 159/250, Loss: 0.0360\n",
      "Epoch 39/200, Iteration 160/250, Loss: 0.0131\n",
      "Epoch 39/200, Iteration 161/250, Loss: 0.0157\n",
      "Epoch 39/200, Iteration 162/250, Loss: 0.0115\n",
      "Epoch 39/200, Iteration 163/250, Loss: 0.0129\n",
      "Epoch 39/200, Iteration 164/250, Loss: 0.0327\n",
      "Epoch 39/200, Iteration 165/250, Loss: 0.0211\n",
      "Epoch 39/200, Iteration 166/250, Loss: 0.0281\n",
      "Epoch 39/200, Iteration 167/250, Loss: 0.0118\n",
      "Epoch 39/200, Iteration 168/250, Loss: 0.0136\n",
      "Epoch 39/200, Iteration 169/250, Loss: 0.0192\n",
      "Epoch 39/200, Iteration 170/250, Loss: 0.0102\n",
      "Epoch 39/200, Iteration 171/250, Loss: 0.0079\n",
      "Epoch 39/200, Iteration 172/250, Loss: 0.0221\n",
      "Epoch 39/200, Iteration 173/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 174/250, Loss: 0.0178\n",
      "Epoch 39/200, Iteration 175/250, Loss: 0.0104\n",
      "Epoch 39/200, Iteration 176/250, Loss: 0.0135\n",
      "Epoch 39/200, Iteration 177/250, Loss: 0.0203\n",
      "Epoch 39/200, Iteration 178/250, Loss: 0.0205\n",
      "Epoch 39/200, Iteration 179/250, Loss: 0.0125\n",
      "Epoch 39/200, Iteration 180/250, Loss: 0.0174\n",
      "Epoch 39/200, Iteration 181/250, Loss: 0.0103\n",
      "Epoch 39/200, Iteration 182/250, Loss: 0.0108\n",
      "Epoch 39/200, Iteration 183/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 184/250, Loss: 0.0116\n",
      "Epoch 39/200, Iteration 185/250, Loss: 0.0130\n",
      "Epoch 39/200, Iteration 186/250, Loss: 0.0211\n",
      "Epoch 39/200, Iteration 187/250, Loss: 0.0119\n",
      "Epoch 39/200, Iteration 188/250, Loss: 0.0222\n",
      "Epoch 39/200, Iteration 189/250, Loss: 0.0162\n",
      "Epoch 39/200, Iteration 190/250, Loss: 0.0117\n",
      "Epoch 39/200, Iteration 191/250, Loss: 0.0217\n",
      "Epoch 39/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 39/200, Iteration 193/250, Loss: 0.0116\n",
      "Epoch 39/200, Iteration 194/250, Loss: 0.0215\n",
      "Epoch 39/200, Iteration 195/250, Loss: 0.0267\n",
      "Epoch 39/200, Iteration 196/250, Loss: 0.0190\n",
      "Epoch 39/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 39/200, Iteration 198/250, Loss: 0.0127\n",
      "Epoch 39/200, Iteration 199/250, Loss: 0.0151\n",
      "Epoch 39/200, Iteration 200/250, Loss: 0.0109\n",
      "Epoch 39/200, Iteration 201/250, Loss: 0.0123\n",
      "Epoch 39/200, Iteration 202/250, Loss: 0.0161\n",
      "Epoch 39/200, Iteration 203/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 204/250, Loss: 0.0146\n",
      "Epoch 39/200, Iteration 205/250, Loss: 0.0192\n",
      "Epoch 39/200, Iteration 206/250, Loss: 0.0114\n",
      "Epoch 39/200, Iteration 207/250, Loss: 0.0152\n",
      "Epoch 39/200, Iteration 208/250, Loss: 0.0333\n",
      "Epoch 39/200, Iteration 209/250, Loss: 0.0128\n",
      "Epoch 39/200, Iteration 210/250, Loss: 0.0184\n",
      "Epoch 39/200, Iteration 211/250, Loss: 0.0371\n",
      "Epoch 39/200, Iteration 212/250, Loss: 0.0205\n",
      "Epoch 39/200, Iteration 213/250, Loss: 0.0132\n",
      "Epoch 39/200, Iteration 214/250, Loss: 0.0156\n",
      "Epoch 39/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 39/200, Iteration 216/250, Loss: 0.0196\n",
      "Epoch 39/200, Iteration 217/250, Loss: 0.0159\n",
      "Epoch 39/200, Iteration 218/250, Loss: 0.0091\n",
      "Epoch 39/200, Iteration 219/250, Loss: 0.0100\n",
      "Epoch 39/200, Iteration 220/250, Loss: 0.0175\n",
      "Epoch 39/200, Iteration 221/250, Loss: 0.0136\n",
      "Epoch 39/200, Iteration 222/250, Loss: 0.0150\n",
      "Epoch 39/200, Iteration 223/250, Loss: 0.0416\n",
      "Epoch 39/200, Iteration 224/250, Loss: 0.0102\n",
      "Epoch 39/200, Iteration 225/250, Loss: 0.0182\n",
      "Epoch 39/200, Iteration 226/250, Loss: 0.0138\n",
      "Epoch 39/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 39/200, Iteration 228/250, Loss: 0.0249\n",
      "Epoch 39/200, Iteration 229/250, Loss: 0.0109\n",
      "Epoch 39/200, Iteration 230/250, Loss: 0.0202\n",
      "Epoch 39/200, Iteration 231/250, Loss: 0.0420\n",
      "Epoch 39/200, Iteration 232/250, Loss: 0.0098\n",
      "Epoch 39/200, Iteration 233/250, Loss: 0.0101\n",
      "Epoch 39/200, Iteration 234/250, Loss: 0.0093\n",
      "Epoch 39/200, Iteration 235/250, Loss: 0.0076\n",
      "Epoch 39/200, Iteration 236/250, Loss: 0.0187\n",
      "Epoch 39/200, Iteration 237/250, Loss: 0.0311\n",
      "Epoch 39/200, Iteration 238/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 239/250, Loss: 0.0154\n",
      "Epoch 39/200, Iteration 240/250, Loss: 0.0177\n",
      "Epoch 39/200, Iteration 241/250, Loss: 0.0128\n",
      "Epoch 39/200, Iteration 242/250, Loss: 0.0178\n",
      "Epoch 39/200, Iteration 243/250, Loss: 0.0148\n",
      "Epoch 39/200, Iteration 244/250, Loss: 0.0153\n",
      "Epoch 39/200, Iteration 245/250, Loss: 0.0085\n",
      "Epoch 39/200, Iteration 246/250, Loss: 0.0136\n",
      "Epoch 39/200, Iteration 247/250, Loss: 0.0151\n",
      "Epoch 39/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 39/200, Iteration 249/250, Loss: 0.0266\n",
      "Epoch 39/200, Iteration 250/250, Loss: 0.0120\n",
      "Train Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.011281, MRE: 0.917026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.011829, MRE: 1.214651 \n",
      "\n",
      "Epoch 40/200, Iteration 1/250, Loss: 0.0136\n",
      "Epoch 40/200, Iteration 2/250, Loss: 0.0150\n",
      "Epoch 40/200, Iteration 3/250, Loss: 0.0101\n",
      "Epoch 40/200, Iteration 4/250, Loss: 0.0248\n",
      "Epoch 40/200, Iteration 5/250, Loss: 0.0092\n",
      "Epoch 40/200, Iteration 6/250, Loss: 0.0151\n",
      "Epoch 40/200, Iteration 7/250, Loss: 0.0189\n",
      "Epoch 40/200, Iteration 8/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 9/250, Loss: 0.0210\n",
      "Epoch 40/200, Iteration 10/250, Loss: 0.0148\n",
      "Epoch 40/200, Iteration 11/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 13/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 14/250, Loss: 0.0151\n",
      "Epoch 40/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 40/200, Iteration 16/250, Loss: 0.0131\n",
      "Epoch 40/200, Iteration 17/250, Loss: 0.0152\n",
      "Epoch 40/200, Iteration 18/250, Loss: 0.0193\n",
      "Epoch 40/200, Iteration 19/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 20/250, Loss: 0.0207\n",
      "Epoch 40/200, Iteration 21/250, Loss: 0.0274\n",
      "Epoch 40/200, Iteration 22/250, Loss: 0.0109\n",
      "Epoch 40/200, Iteration 23/250, Loss: 0.0266\n",
      "Epoch 40/200, Iteration 24/250, Loss: 0.0114\n",
      "Epoch 40/200, Iteration 25/250, Loss: 0.0115\n",
      "Epoch 40/200, Iteration 26/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 27/250, Loss: 0.0241\n",
      "Epoch 40/200, Iteration 28/250, Loss: 0.0081\n",
      "Epoch 40/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 40/200, Iteration 30/250, Loss: 0.0219\n",
      "Epoch 40/200, Iteration 31/250, Loss: 0.0178\n",
      "Epoch 40/200, Iteration 32/250, Loss: 0.0156\n",
      "Epoch 40/200, Iteration 33/250, Loss: 0.0272\n",
      "Epoch 40/200, Iteration 34/250, Loss: 0.0451\n",
      "Epoch 40/200, Iteration 35/250, Loss: 0.0188\n",
      "Epoch 40/200, Iteration 36/250, Loss: 0.0112\n",
      "Epoch 40/200, Iteration 37/250, Loss: 0.0126\n",
      "Epoch 40/200, Iteration 38/250, Loss: 0.0110\n",
      "Epoch 40/200, Iteration 39/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 40/250, Loss: 0.0159\n",
      "Epoch 40/200, Iteration 41/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 42/250, Loss: 0.0147\n",
      "Epoch 40/200, Iteration 43/250, Loss: 0.0122\n",
      "Epoch 40/200, Iteration 44/250, Loss: 0.0209\n",
      "Epoch 40/200, Iteration 45/250, Loss: 0.0099\n",
      "Epoch 40/200, Iteration 46/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 47/250, Loss: 0.0086\n",
      "Epoch 40/200, Iteration 48/250, Loss: 0.0327\n",
      "Epoch 40/200, Iteration 49/250, Loss: 0.0180\n",
      "Epoch 40/200, Iteration 50/250, Loss: 0.0312\n",
      "Epoch 40/200, Iteration 51/250, Loss: 0.0160\n",
      "Epoch 40/200, Iteration 52/250, Loss: 0.0144\n",
      "Epoch 40/200, Iteration 53/250, Loss: 0.0182\n",
      "Epoch 40/200, Iteration 54/250, Loss: 0.0114\n",
      "Epoch 40/200, Iteration 55/250, Loss: 0.0116\n",
      "Epoch 40/200, Iteration 56/250, Loss: 0.0174\n",
      "Epoch 40/200, Iteration 57/250, Loss: 0.0212\n",
      "Epoch 40/200, Iteration 58/250, Loss: 0.0097\n",
      "Epoch 40/200, Iteration 59/250, Loss: 0.0238\n",
      "Epoch 40/200, Iteration 60/250, Loss: 0.0116\n",
      "Epoch 40/200, Iteration 61/250, Loss: 0.0174\n",
      "Epoch 40/200, Iteration 62/250, Loss: 0.0161\n",
      "Epoch 40/200, Iteration 63/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 64/250, Loss: 0.0123\n",
      "Epoch 40/200, Iteration 65/250, Loss: 0.0201\n",
      "Epoch 40/200, Iteration 66/250, Loss: 0.0169\n",
      "Epoch 40/200, Iteration 67/250, Loss: 0.0132\n",
      "Epoch 40/200, Iteration 68/250, Loss: 0.0277\n",
      "Epoch 40/200, Iteration 69/250, Loss: 0.0272\n",
      "Epoch 40/200, Iteration 70/250, Loss: 0.0147\n",
      "Epoch 40/200, Iteration 71/250, Loss: 0.0178\n",
      "Epoch 40/200, Iteration 72/250, Loss: 0.0157\n",
      "Epoch 40/200, Iteration 73/250, Loss: 0.0139\n",
      "Epoch 40/200, Iteration 74/250, Loss: 0.0143\n",
      "Epoch 40/200, Iteration 75/250, Loss: 0.0273\n",
      "Epoch 40/200, Iteration 76/250, Loss: 0.0165\n",
      "Epoch 40/200, Iteration 77/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 78/250, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Iteration 79/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 80/250, Loss: 0.0121\n",
      "Epoch 40/200, Iteration 81/250, Loss: 0.0099\n",
      "Epoch 40/200, Iteration 82/250, Loss: 0.0141\n",
      "Epoch 40/200, Iteration 83/250, Loss: 0.0446\n",
      "Epoch 40/200, Iteration 84/250, Loss: 0.0161\n",
      "Epoch 40/200, Iteration 85/250, Loss: 0.0378\n",
      "Epoch 40/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 87/250, Loss: 0.0338\n",
      "Epoch 40/200, Iteration 88/250, Loss: 0.0327\n",
      "Epoch 40/200, Iteration 89/250, Loss: 0.0131\n",
      "Epoch 40/200, Iteration 90/250, Loss: 0.0119\n",
      "Epoch 40/200, Iteration 91/250, Loss: 0.0221\n",
      "Epoch 40/200, Iteration 92/250, Loss: 0.0155\n",
      "Epoch 40/200, Iteration 93/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 94/250, Loss: 0.0281\n",
      "Epoch 40/200, Iteration 95/250, Loss: 0.0122\n",
      "Epoch 40/200, Iteration 96/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 97/250, Loss: 0.0145\n",
      "Epoch 40/200, Iteration 98/250, Loss: 0.0149\n",
      "Epoch 40/200, Iteration 99/250, Loss: 0.0095\n",
      "Epoch 40/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 101/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 102/250, Loss: 0.0189\n",
      "Epoch 40/200, Iteration 103/250, Loss: 0.0213\n",
      "Epoch 40/200, Iteration 104/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 105/250, Loss: 0.0302\n",
      "Epoch 40/200, Iteration 106/250, Loss: 0.0199\n",
      "Epoch 40/200, Iteration 107/250, Loss: 0.0086\n",
      "Epoch 40/200, Iteration 108/250, Loss: 0.0151\n",
      "Epoch 40/200, Iteration 109/250, Loss: 0.0260\n",
      "Epoch 40/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 40/200, Iteration 111/250, Loss: 0.0221\n",
      "Epoch 40/200, Iteration 112/250, Loss: 0.0173\n",
      "Epoch 40/200, Iteration 113/250, Loss: 0.0200\n",
      "Epoch 40/200, Iteration 114/250, Loss: 0.0127\n",
      "Epoch 40/200, Iteration 115/250, Loss: 0.0319\n",
      "Epoch 40/200, Iteration 116/250, Loss: 0.0181\n",
      "Epoch 40/200, Iteration 117/250, Loss: 0.0149\n",
      "Epoch 40/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 119/250, Loss: 0.0141\n",
      "Epoch 40/200, Iteration 120/250, Loss: 0.0404\n",
      "Epoch 40/200, Iteration 121/250, Loss: 0.0127\n",
      "Epoch 40/200, Iteration 122/250, Loss: 0.0168\n",
      "Epoch 40/200, Iteration 123/250, Loss: 0.0275\n",
      "Epoch 40/200, Iteration 124/250, Loss: 0.0197\n",
      "Epoch 40/200, Iteration 125/250, Loss: 0.0169\n",
      "Epoch 40/200, Iteration 126/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 127/250, Loss: 0.0119\n",
      "Epoch 40/200, Iteration 128/250, Loss: 0.0148\n",
      "Epoch 40/200, Iteration 129/250, Loss: 0.0185\n",
      "Epoch 40/200, Iteration 130/250, Loss: 0.0121\n",
      "Epoch 40/200, Iteration 131/250, Loss: 0.0146\n",
      "Epoch 40/200, Iteration 132/250, Loss: 0.0203\n",
      "Epoch 40/200, Iteration 133/250, Loss: 0.0138\n",
      "Epoch 40/200, Iteration 134/250, Loss: 0.0321\n",
      "Epoch 40/200, Iteration 135/250, Loss: 0.0208\n",
      "Epoch 40/200, Iteration 136/250, Loss: 0.0363\n",
      "Epoch 40/200, Iteration 137/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 138/250, Loss: 0.0191\n",
      "Epoch 40/200, Iteration 139/250, Loss: 0.0290\n",
      "Epoch 40/200, Iteration 140/250, Loss: 0.0340\n",
      "Epoch 40/200, Iteration 141/250, Loss: 0.0101\n",
      "Epoch 40/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 143/250, Loss: 0.0130\n",
      "Epoch 40/200, Iteration 144/250, Loss: 0.0131\n",
      "Epoch 40/200, Iteration 145/250, Loss: 0.0222\n",
      "Epoch 40/200, Iteration 146/250, Loss: 0.0150\n",
      "Epoch 40/200, Iteration 147/250, Loss: 0.0138\n",
      "Epoch 40/200, Iteration 148/250, Loss: 0.0146\n",
      "Epoch 40/200, Iteration 149/250, Loss: 0.0239\n",
      "Epoch 40/200, Iteration 150/250, Loss: 0.0127\n",
      "Epoch 40/200, Iteration 151/250, Loss: 0.0206\n",
      "Epoch 40/200, Iteration 152/250, Loss: 0.0115\n",
      "Epoch 40/200, Iteration 153/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 40/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 40/200, Iteration 156/250, Loss: 0.0168\n",
      "Epoch 40/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 40/200, Iteration 158/250, Loss: 0.0404\n",
      "Epoch 40/200, Iteration 159/250, Loss: 0.0095\n",
      "Epoch 40/200, Iteration 160/250, Loss: 0.0251\n",
      "Epoch 40/200, Iteration 161/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 162/250, Loss: 0.0263\n",
      "Epoch 40/200, Iteration 163/250, Loss: 0.0213\n",
      "Epoch 40/200, Iteration 164/250, Loss: 0.0204\n",
      "Epoch 40/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 40/200, Iteration 166/250, Loss: 0.0149\n",
      "Epoch 40/200, Iteration 167/250, Loss: 0.0315\n",
      "Epoch 40/200, Iteration 168/250, Loss: 0.0113\n",
      "Epoch 40/200, Iteration 169/250, Loss: 0.0174\n",
      "Epoch 40/200, Iteration 170/250, Loss: 0.0233\n",
      "Epoch 40/200, Iteration 171/250, Loss: 0.0154\n",
      "Epoch 40/200, Iteration 172/250, Loss: 0.0190\n",
      "Epoch 40/200, Iteration 173/250, Loss: 0.0215\n",
      "Epoch 40/200, Iteration 174/250, Loss: 0.0152\n",
      "Epoch 40/200, Iteration 175/250, Loss: 0.0162\n",
      "Epoch 40/200, Iteration 176/250, Loss: 0.0096\n",
      "Epoch 40/200, Iteration 177/250, Loss: 0.0306\n",
      "Epoch 40/200, Iteration 178/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 179/250, Loss: 0.0153\n",
      "Epoch 40/200, Iteration 180/250, Loss: 0.0333\n",
      "Epoch 40/200, Iteration 181/250, Loss: 0.0279\n",
      "Epoch 40/200, Iteration 182/250, Loss: 0.0071\n",
      "Epoch 40/200, Iteration 183/250, Loss: 0.0298\n",
      "Epoch 40/200, Iteration 184/250, Loss: 0.0137\n",
      "Epoch 40/200, Iteration 185/250, Loss: 0.0156\n",
      "Epoch 40/200, Iteration 186/250, Loss: 0.0176\n",
      "Epoch 40/200, Iteration 187/250, Loss: 0.0197\n",
      "Epoch 40/200, Iteration 188/250, Loss: 0.0471\n",
      "Epoch 40/200, Iteration 189/250, Loss: 0.0172\n",
      "Epoch 40/200, Iteration 190/250, Loss: 0.0221\n",
      "Epoch 40/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 40/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 40/200, Iteration 193/250, Loss: 0.0090\n",
      "Epoch 40/200, Iteration 194/250, Loss: 0.0308\n",
      "Epoch 40/200, Iteration 195/250, Loss: 0.0120\n",
      "Epoch 40/200, Iteration 196/250, Loss: 0.0397\n",
      "Epoch 40/200, Iteration 197/250, Loss: 0.0061\n",
      "Epoch 40/200, Iteration 198/250, Loss: 0.0171\n",
      "Epoch 40/200, Iteration 199/250, Loss: 0.0117\n",
      "Epoch 40/200, Iteration 200/250, Loss: 0.0217\n",
      "Epoch 40/200, Iteration 201/250, Loss: 0.0130\n",
      "Epoch 40/200, Iteration 202/250, Loss: 0.0192\n",
      "Epoch 40/200, Iteration 203/250, Loss: 0.0178\n",
      "Epoch 40/200, Iteration 204/250, Loss: 0.0313\n",
      "Epoch 40/200, Iteration 205/250, Loss: 0.0130\n",
      "Epoch 40/200, Iteration 206/250, Loss: 0.0329\n",
      "Epoch 40/200, Iteration 207/250, Loss: 0.0177\n",
      "Epoch 40/200, Iteration 208/250, Loss: 0.0172\n",
      "Epoch 40/200, Iteration 209/250, Loss: 0.0128\n",
      "Epoch 40/200, Iteration 210/250, Loss: 0.0209\n",
      "Epoch 40/200, Iteration 211/250, Loss: 0.0178\n",
      "Epoch 40/200, Iteration 212/250, Loss: 0.0097\n",
      "Epoch 40/200, Iteration 213/250, Loss: 0.0147\n",
      "Epoch 40/200, Iteration 214/250, Loss: 0.0125\n",
      "Epoch 40/200, Iteration 215/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 216/250, Loss: 0.0165\n",
      "Epoch 40/200, Iteration 217/250, Loss: 0.0337\n",
      "Epoch 40/200, Iteration 218/250, Loss: 0.0096\n",
      "Epoch 40/200, Iteration 219/250, Loss: 0.0080\n",
      "Epoch 40/200, Iteration 220/250, Loss: 0.0133\n",
      "Epoch 40/200, Iteration 221/250, Loss: 0.0230\n",
      "Epoch 40/200, Iteration 222/250, Loss: 0.0100\n",
      "Epoch 40/200, Iteration 223/250, Loss: 0.0103\n",
      "Epoch 40/200, Iteration 224/250, Loss: 0.0164\n",
      "Epoch 40/200, Iteration 225/250, Loss: 0.0170\n",
      "Epoch 40/200, Iteration 226/250, Loss: 0.0118\n",
      "Epoch 40/200, Iteration 227/250, Loss: 0.0110\n",
      "Epoch 40/200, Iteration 228/250, Loss: 0.0108\n",
      "Epoch 40/200, Iteration 229/250, Loss: 0.0113\n",
      "Epoch 40/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 40/200, Iteration 231/250, Loss: 0.0219\n",
      "Epoch 40/200, Iteration 232/250, Loss: 0.0137\n",
      "Epoch 40/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 40/200, Iteration 234/250, Loss: 0.0300\n",
      "Epoch 40/200, Iteration 235/250, Loss: 0.0149\n",
      "Epoch 40/200, Iteration 236/250, Loss: 0.0151\n",
      "Epoch 40/200, Iteration 237/250, Loss: 0.0126\n",
      "Epoch 40/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 40/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 40/200, Iteration 240/250, Loss: 0.0255\n",
      "Epoch 40/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 40/200, Iteration 242/250, Loss: 0.0224\n",
      "Epoch 40/200, Iteration 243/250, Loss: 0.0303\n",
      "Epoch 40/200, Iteration 244/250, Loss: 0.0180\n",
      "Epoch 40/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 40/200, Iteration 246/250, Loss: 0.0288\n",
      "Epoch 40/200, Iteration 247/250, Loss: 0.0091\n",
      "Epoch 40/200, Iteration 248/250, Loss: 0.0158\n",
      "Epoch 40/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 40/200, Iteration 250/250, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 83.54%, Avg loss: 0.008206, MRE: 0.544460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.85%, Avg loss: 0.008611, MRE: 0.743291 \n",
      "\n",
      "Epoch 41/200, Iteration 1/250, Loss: 0.0180\n",
      "Epoch 41/200, Iteration 2/250, Loss: 0.0168\n",
      "Epoch 41/200, Iteration 3/250, Loss: 0.0226\n",
      "Epoch 41/200, Iteration 4/250, Loss: 0.0154\n",
      "Epoch 41/200, Iteration 5/250, Loss: 0.0221\n",
      "Epoch 41/200, Iteration 6/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 7/250, Loss: 0.0109\n",
      "Epoch 41/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 41/200, Iteration 9/250, Loss: 0.0185\n",
      "Epoch 41/200, Iteration 10/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 11/250, Loss: 0.0115\n",
      "Epoch 41/200, Iteration 12/250, Loss: 0.0087\n",
      "Epoch 41/200, Iteration 13/250, Loss: 0.0091\n",
      "Epoch 41/200, Iteration 14/250, Loss: 0.0266\n",
      "Epoch 41/200, Iteration 15/250, Loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Iteration 16/250, Loss: 0.0136\n",
      "Epoch 41/200, Iteration 17/250, Loss: 0.0113\n",
      "Epoch 41/200, Iteration 18/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 41/200, Iteration 20/250, Loss: 0.0104\n",
      "Epoch 41/200, Iteration 21/250, Loss: 0.0109\n",
      "Epoch 41/200, Iteration 22/250, Loss: 0.0130\n",
      "Epoch 41/200, Iteration 23/250, Loss: 0.0330\n",
      "Epoch 41/200, Iteration 24/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 25/250, Loss: 0.0319\n",
      "Epoch 41/200, Iteration 26/250, Loss: 0.0268\n",
      "Epoch 41/200, Iteration 27/250, Loss: 0.0116\n",
      "Epoch 41/200, Iteration 28/250, Loss: 0.0344\n",
      "Epoch 41/200, Iteration 29/250, Loss: 0.0106\n",
      "Epoch 41/200, Iteration 30/250, Loss: 0.0133\n",
      "Epoch 41/200, Iteration 31/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 32/250, Loss: 0.0171\n",
      "Epoch 41/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 34/250, Loss: 0.0276\n",
      "Epoch 41/200, Iteration 35/250, Loss: 0.0238\n",
      "Epoch 41/200, Iteration 36/250, Loss: 0.0231\n",
      "Epoch 41/200, Iteration 37/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 38/250, Loss: 0.0200\n",
      "Epoch 41/200, Iteration 39/250, Loss: 0.0130\n",
      "Epoch 41/200, Iteration 40/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 41/250, Loss: 0.0202\n",
      "Epoch 41/200, Iteration 42/250, Loss: 0.0149\n",
      "Epoch 41/200, Iteration 43/250, Loss: 0.0081\n",
      "Epoch 41/200, Iteration 44/250, Loss: 0.0116\n",
      "Epoch 41/200, Iteration 45/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 46/250, Loss: 0.0254\n",
      "Epoch 41/200, Iteration 47/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 48/250, Loss: 0.0177\n",
      "Epoch 41/200, Iteration 49/250, Loss: 0.0163\n",
      "Epoch 41/200, Iteration 50/250, Loss: 0.0313\n",
      "Epoch 41/200, Iteration 51/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 52/250, Loss: 0.0112\n",
      "Epoch 41/200, Iteration 53/250, Loss: 0.0078\n",
      "Epoch 41/200, Iteration 54/250, Loss: 0.0155\n",
      "Epoch 41/200, Iteration 55/250, Loss: 0.0129\n",
      "Epoch 41/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 41/200, Iteration 57/250, Loss: 0.0135\n",
      "Epoch 41/200, Iteration 58/250, Loss: 0.0162\n",
      "Epoch 41/200, Iteration 59/250, Loss: 0.0223\n",
      "Epoch 41/200, Iteration 60/250, Loss: 0.0191\n",
      "Epoch 41/200, Iteration 61/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 62/250, Loss: 0.0094\n",
      "Epoch 41/200, Iteration 63/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 64/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 65/250, Loss: 0.0221\n",
      "Epoch 41/200, Iteration 66/250, Loss: 0.0291\n",
      "Epoch 41/200, Iteration 67/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 68/250, Loss: 0.0240\n",
      "Epoch 41/200, Iteration 69/250, Loss: 0.0085\n",
      "Epoch 41/200, Iteration 70/250, Loss: 0.0084\n",
      "Epoch 41/200, Iteration 71/250, Loss: 0.0155\n",
      "Epoch 41/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 41/200, Iteration 73/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 74/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 75/250, Loss: 0.0088\n",
      "Epoch 41/200, Iteration 76/250, Loss: 0.0090\n",
      "Epoch 41/200, Iteration 77/250, Loss: 0.0212\n",
      "Epoch 41/200, Iteration 78/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 79/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 80/250, Loss: 0.0186\n",
      "Epoch 41/200, Iteration 81/250, Loss: 0.0129\n",
      "Epoch 41/200, Iteration 82/250, Loss: 0.0134\n",
      "Epoch 41/200, Iteration 83/250, Loss: 0.0288\n",
      "Epoch 41/200, Iteration 84/250, Loss: 0.0264\n",
      "Epoch 41/200, Iteration 85/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 86/250, Loss: 0.0169\n",
      "Epoch 41/200, Iteration 87/250, Loss: 0.0149\n",
      "Epoch 41/200, Iteration 88/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 90/250, Loss: 0.0217\n",
      "Epoch 41/200, Iteration 91/250, Loss: 0.0179\n",
      "Epoch 41/200, Iteration 92/250, Loss: 0.0157\n",
      "Epoch 41/200, Iteration 93/250, Loss: 0.0214\n",
      "Epoch 41/200, Iteration 94/250, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 95/250, Loss: 0.0130\n",
      "Epoch 41/200, Iteration 96/250, Loss: 0.0280\n",
      "Epoch 41/200, Iteration 97/250, Loss: 0.0175\n",
      "Epoch 41/200, Iteration 98/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 99/250, Loss: 0.0135\n",
      "Epoch 41/200, Iteration 100/250, Loss: 0.0089\n",
      "Epoch 41/200, Iteration 101/250, Loss: 0.0154\n",
      "Epoch 41/200, Iteration 102/250, Loss: 0.0159\n",
      "Epoch 41/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 104/250, Loss: 0.0286\n",
      "Epoch 41/200, Iteration 105/250, Loss: 0.0117\n",
      "Epoch 41/200, Iteration 106/250, Loss: 0.0348\n",
      "Epoch 41/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 108/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 109/250, Loss: 0.0280\n",
      "Epoch 41/200, Iteration 110/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 111/250, Loss: 0.0269\n",
      "Epoch 41/200, Iteration 112/250, Loss: 0.0148\n",
      "Epoch 41/200, Iteration 113/250, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 114/250, Loss: 0.0124\n",
      "Epoch 41/200, Iteration 115/250, Loss: 0.0162\n",
      "Epoch 41/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 41/200, Iteration 117/250, Loss: 0.0175\n",
      "Epoch 41/200, Iteration 118/250, Loss: 0.0202\n",
      "Epoch 41/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 41/200, Iteration 120/250, Loss: 0.0125\n",
      "Epoch 41/200, Iteration 121/250, Loss: 0.0131\n",
      "Epoch 41/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 41/200, Iteration 123/250, Loss: 0.0142\n",
      "Epoch 41/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 41/200, Iteration 125/250, Loss: 0.0129\n",
      "Epoch 41/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 41/200, Iteration 127/250, Loss: 0.0082\n",
      "Epoch 41/200, Iteration 128/250, Loss: 0.0088\n",
      "Epoch 41/200, Iteration 129/250, Loss: 0.0120\n",
      "Epoch 41/200, Iteration 130/250, Loss: 0.0101\n",
      "Epoch 41/200, Iteration 131/250, Loss: 0.0222\n",
      "Epoch 41/200, Iteration 132/250, Loss: 0.0128\n",
      "Epoch 41/200, Iteration 133/250, Loss: 0.0308\n",
      "Epoch 41/200, Iteration 134/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 135/250, Loss: 0.0158\n",
      "Epoch 41/200, Iteration 136/250, Loss: 0.0208\n",
      "Epoch 41/200, Iteration 137/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 138/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 139/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 140/250, Loss: 0.0142\n",
      "Epoch 41/200, Iteration 141/250, Loss: 0.0090\n",
      "Epoch 41/200, Iteration 142/250, Loss: 0.0078\n",
      "Epoch 41/200, Iteration 143/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 41/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 41/200, Iteration 146/250, Loss: 0.0168\n",
      "Epoch 41/200, Iteration 147/250, Loss: 0.0126\n",
      "Epoch 41/200, Iteration 148/250, Loss: 0.0150\n",
      "Epoch 41/200, Iteration 149/250, Loss: 0.0178\n",
      "Epoch 41/200, Iteration 150/250, Loss: 0.0270\n",
      "Epoch 41/200, Iteration 151/250, Loss: 0.0273\n",
      "Epoch 41/200, Iteration 152/250, Loss: 0.0100\n",
      "Epoch 41/200, Iteration 153/250, Loss: 0.0153\n",
      "Epoch 41/200, Iteration 154/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 155/250, Loss: 0.0201\n",
      "Epoch 41/200, Iteration 156/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 157/250, Loss: 0.0095\n",
      "Epoch 41/200, Iteration 158/250, Loss: 0.0163\n",
      "Epoch 41/200, Iteration 159/250, Loss: 0.0435\n",
      "Epoch 41/200, Iteration 160/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 161/250, Loss: 0.0071\n",
      "Epoch 41/200, Iteration 162/250, Loss: 0.0132\n",
      "Epoch 41/200, Iteration 163/250, Loss: 0.0068\n",
      "Epoch 41/200, Iteration 164/250, Loss: 0.0149\n",
      "Epoch 41/200, Iteration 165/250, Loss: 0.0155\n",
      "Epoch 41/200, Iteration 166/250, Loss: 0.0160\n",
      "Epoch 41/200, Iteration 167/250, Loss: 0.0123\n",
      "Epoch 41/200, Iteration 168/250, Loss: 0.0211\n",
      "Epoch 41/200, Iteration 169/250, Loss: 0.0186\n",
      "Epoch 41/200, Iteration 170/250, Loss: 0.0179\n",
      "Epoch 41/200, Iteration 171/250, Loss: 0.0128\n",
      "Epoch 41/200, Iteration 172/250, Loss: 0.0119\n",
      "Epoch 41/200, Iteration 173/250, Loss: 0.0107\n",
      "Epoch 41/200, Iteration 174/250, Loss: 0.0113\n",
      "Epoch 41/200, Iteration 175/250, Loss: 0.0133\n",
      "Epoch 41/200, Iteration 176/250, Loss: 0.0146\n",
      "Epoch 41/200, Iteration 177/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 178/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 179/250, Loss: 0.0143\n",
      "Epoch 41/200, Iteration 180/250, Loss: 0.0209\n",
      "Epoch 41/200, Iteration 181/250, Loss: 0.0145\n",
      "Epoch 41/200, Iteration 182/250, Loss: 0.0121\n",
      "Epoch 41/200, Iteration 183/250, Loss: 0.0092\n",
      "Epoch 41/200, Iteration 184/250, Loss: 0.0137\n",
      "Epoch 41/200, Iteration 185/250, Loss: 0.0102\n",
      "Epoch 41/200, Iteration 186/250, Loss: 0.0115\n",
      "Epoch 41/200, Iteration 187/250, Loss: 0.0169\n",
      "Epoch 41/200, Iteration 188/250, Loss: 0.0169\n",
      "Epoch 41/200, Iteration 189/250, Loss: 0.0162\n",
      "Epoch 41/200, Iteration 190/250, Loss: 0.0335\n",
      "Epoch 41/200, Iteration 191/250, Loss: 0.0181\n",
      "Epoch 41/200, Iteration 192/250, Loss: 0.0140\n",
      "Epoch 41/200, Iteration 193/250, Loss: 0.0136\n",
      "Epoch 41/200, Iteration 194/250, Loss: 0.0206\n",
      "Epoch 41/200, Iteration 195/250, Loss: 0.0096\n",
      "Epoch 41/200, Iteration 196/250, Loss: 0.0184\n",
      "Epoch 41/200, Iteration 197/250, Loss: 0.0093\n",
      "Epoch 41/200, Iteration 198/250, Loss: 0.0177\n",
      "Epoch 41/200, Iteration 199/250, Loss: 0.0156\n",
      "Epoch 41/200, Iteration 200/250, Loss: 0.0205\n",
      "Epoch 41/200, Iteration 201/250, Loss: 0.0148\n",
      "Epoch 41/200, Iteration 202/250, Loss: 0.0107\n",
      "Epoch 41/200, Iteration 203/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 204/250, Loss: 0.0264\n",
      "Epoch 41/200, Iteration 205/250, Loss: 0.0116\n",
      "Epoch 41/200, Iteration 206/250, Loss: 0.0095\n",
      "Epoch 41/200, Iteration 207/250, Loss: 0.0098\n",
      "Epoch 41/200, Iteration 208/250, Loss: 0.0176\n",
      "Epoch 41/200, Iteration 209/250, Loss: 0.0160\n",
      "Epoch 41/200, Iteration 210/250, Loss: 0.0202\n",
      "Epoch 41/200, Iteration 211/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 212/250, Loss: 0.0194\n",
      "Epoch 41/200, Iteration 213/250, Loss: 0.0106\n",
      "Epoch 41/200, Iteration 214/250, Loss: 0.0248\n",
      "Epoch 41/200, Iteration 215/250, Loss: 0.0187\n",
      "Epoch 41/200, Iteration 216/250, Loss: 0.0152\n",
      "Epoch 41/200, Iteration 217/250, Loss: 0.0111\n",
      "Epoch 41/200, Iteration 218/250, Loss: 0.0171\n",
      "Epoch 41/200, Iteration 219/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 220/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 221/250, Loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Iteration 222/250, Loss: 0.0103\n",
      "Epoch 41/200, Iteration 223/250, Loss: 0.0233\n",
      "Epoch 41/200, Iteration 224/250, Loss: 0.0127\n",
      "Epoch 41/200, Iteration 225/250, Loss: 0.0147\n",
      "Epoch 41/200, Iteration 226/250, Loss: 0.0167\n",
      "Epoch 41/200, Iteration 227/250, Loss: 0.0137\n",
      "Epoch 41/200, Iteration 228/250, Loss: 0.0144\n",
      "Epoch 41/200, Iteration 229/250, Loss: 0.0084\n",
      "Epoch 41/200, Iteration 230/250, Loss: 0.0098\n",
      "Epoch 41/200, Iteration 231/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 232/250, Loss: 0.0102\n",
      "Epoch 41/200, Iteration 233/250, Loss: 0.0238\n",
      "Epoch 41/200, Iteration 234/250, Loss: 0.0121\n",
      "Epoch 41/200, Iteration 235/250, Loss: 0.0279\n",
      "Epoch 41/200, Iteration 236/250, Loss: 0.0114\n",
      "Epoch 41/200, Iteration 237/250, Loss: 0.0131\n",
      "Epoch 41/200, Iteration 238/250, Loss: 0.0083\n",
      "Epoch 41/200, Iteration 239/250, Loss: 0.0174\n",
      "Epoch 41/200, Iteration 240/250, Loss: 0.0197\n",
      "Epoch 41/200, Iteration 241/250, Loss: 0.0150\n",
      "Epoch 41/200, Iteration 242/250, Loss: 0.0131\n",
      "Epoch 41/200, Iteration 243/250, Loss: 0.0128\n",
      "Epoch 41/200, Iteration 244/250, Loss: 0.0110\n",
      "Epoch 41/200, Iteration 245/250, Loss: 0.0099\n",
      "Epoch 41/200, Iteration 246/250, Loss: 0.0164\n",
      "Epoch 41/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 41/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 41/200, Iteration 249/250, Loss: 0.0122\n",
      "Epoch 41/200, Iteration 250/250, Loss: 0.0091\n",
      "Train Error: \n",
      " Accuracy: 85.67%, Avg loss: 0.008020, MRE: 0.501380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.008603, MRE: 0.666236 \n",
      "\n",
      "Epoch 42/200, Iteration 1/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 2/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 3/250, Loss: 0.0240\n",
      "Epoch 42/200, Iteration 4/250, Loss: 0.0233\n",
      "Epoch 42/200, Iteration 5/250, Loss: 0.0156\n",
      "Epoch 42/200, Iteration 6/250, Loss: 0.0164\n",
      "Epoch 42/200, Iteration 7/250, Loss: 0.0151\n",
      "Epoch 42/200, Iteration 8/250, Loss: 0.0091\n",
      "Epoch 42/200, Iteration 9/250, Loss: 0.0135\n",
      "Epoch 42/200, Iteration 10/250, Loss: 0.0161\n",
      "Epoch 42/200, Iteration 11/250, Loss: 0.0189\n",
      "Epoch 42/200, Iteration 12/250, Loss: 0.0090\n",
      "Epoch 42/200, Iteration 13/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 14/250, Loss: 0.0191\n",
      "Epoch 42/200, Iteration 15/250, Loss: 0.0252\n",
      "Epoch 42/200, Iteration 16/250, Loss: 0.0125\n",
      "Epoch 42/200, Iteration 17/250, Loss: 0.0193\n",
      "Epoch 42/200, Iteration 18/250, Loss: 0.0126\n",
      "Epoch 42/200, Iteration 19/250, Loss: 0.0158\n",
      "Epoch 42/200, Iteration 20/250, Loss: 0.0150\n",
      "Epoch 42/200, Iteration 21/250, Loss: 0.0200\n",
      "Epoch 42/200, Iteration 22/250, Loss: 0.0151\n",
      "Epoch 42/200, Iteration 23/250, Loss: 0.0071\n",
      "Epoch 42/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 42/200, Iteration 25/250, Loss: 0.0121\n",
      "Epoch 42/200, Iteration 26/250, Loss: 0.0154\n",
      "Epoch 42/200, Iteration 27/250, Loss: 0.0076\n",
      "Epoch 42/200, Iteration 28/250, Loss: 0.0240\n",
      "Epoch 42/200, Iteration 29/250, Loss: 0.0265\n",
      "Epoch 42/200, Iteration 30/250, Loss: 0.0128\n",
      "Epoch 42/200, Iteration 31/250, Loss: 0.0155\n",
      "Epoch 42/200, Iteration 32/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 33/250, Loss: 0.0437\n",
      "Epoch 42/200, Iteration 34/250, Loss: 0.0150\n",
      "Epoch 42/200, Iteration 35/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 36/250, Loss: 0.0186\n",
      "Epoch 42/200, Iteration 37/250, Loss: 0.0137\n",
      "Epoch 42/200, Iteration 38/250, Loss: 0.0376\n",
      "Epoch 42/200, Iteration 39/250, Loss: 0.0131\n",
      "Epoch 42/200, Iteration 40/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 41/250, Loss: 0.0232\n",
      "Epoch 42/200, Iteration 42/250, Loss: 0.0260\n",
      "Epoch 42/200, Iteration 43/250, Loss: 0.0179\n",
      "Epoch 42/200, Iteration 44/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 45/250, Loss: 0.0127\n",
      "Epoch 42/200, Iteration 46/250, Loss: 0.0166\n",
      "Epoch 42/200, Iteration 47/250, Loss: 0.0165\n",
      "Epoch 42/200, Iteration 48/250, Loss: 0.0175\n",
      "Epoch 42/200, Iteration 49/250, Loss: 0.0100\n",
      "Epoch 42/200, Iteration 50/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 51/250, Loss: 0.0418\n",
      "Epoch 42/200, Iteration 52/250, Loss: 0.0127\n",
      "Epoch 42/200, Iteration 53/250, Loss: 0.0113\n",
      "Epoch 42/200, Iteration 54/250, Loss: 0.0136\n",
      "Epoch 42/200, Iteration 55/250, Loss: 0.0163\n",
      "Epoch 42/200, Iteration 56/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 57/250, Loss: 0.0268\n",
      "Epoch 42/200, Iteration 58/250, Loss: 0.0223\n",
      "Epoch 42/200, Iteration 59/250, Loss: 0.0183\n",
      "Epoch 42/200, Iteration 60/250, Loss: 0.0303\n",
      "Epoch 42/200, Iteration 61/250, Loss: 0.0184\n",
      "Epoch 42/200, Iteration 62/250, Loss: 0.0121\n",
      "Epoch 42/200, Iteration 63/250, Loss: 0.0166\n",
      "Epoch 42/200, Iteration 64/250, Loss: 0.0151\n",
      "Epoch 42/200, Iteration 65/250, Loss: 0.0204\n",
      "Epoch 42/200, Iteration 66/250, Loss: 0.0233\n",
      "Epoch 42/200, Iteration 67/250, Loss: 0.0133\n",
      "Epoch 42/200, Iteration 68/250, Loss: 0.0140\n",
      "Epoch 42/200, Iteration 69/250, Loss: 0.0342\n",
      "Epoch 42/200, Iteration 70/250, Loss: 0.0176\n",
      "Epoch 42/200, Iteration 71/250, Loss: 0.0123\n",
      "Epoch 42/200, Iteration 72/250, Loss: 0.0125\n",
      "Epoch 42/200, Iteration 73/250, Loss: 0.0102\n",
      "Epoch 42/200, Iteration 74/250, Loss: 0.0146\n",
      "Epoch 42/200, Iteration 75/250, Loss: 0.0077\n",
      "Epoch 42/200, Iteration 76/250, Loss: 0.0120\n",
      "Epoch 42/200, Iteration 77/250, Loss: 0.0095\n",
      "Epoch 42/200, Iteration 78/250, Loss: 0.0256\n",
      "Epoch 42/200, Iteration 79/250, Loss: 0.0133\n",
      "Epoch 42/200, Iteration 80/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 81/250, Loss: 0.0088\n",
      "Epoch 42/200, Iteration 82/250, Loss: 0.0187\n",
      "Epoch 42/200, Iteration 83/250, Loss: 0.0195\n",
      "Epoch 42/200, Iteration 84/250, Loss: 0.0115\n",
      "Epoch 42/200, Iteration 85/250, Loss: 0.0280\n",
      "Epoch 42/200, Iteration 86/250, Loss: 0.0362\n",
      "Epoch 42/200, Iteration 87/250, Loss: 0.0195\n",
      "Epoch 42/200, Iteration 88/250, Loss: 0.0131\n",
      "Epoch 42/200, Iteration 89/250, Loss: 0.0148\n",
      "Epoch 42/200, Iteration 90/250, Loss: 0.0088\n",
      "Epoch 42/200, Iteration 91/250, Loss: 0.0146\n",
      "Epoch 42/200, Iteration 92/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 93/250, Loss: 0.0219\n",
      "Epoch 42/200, Iteration 94/250, Loss: 0.0296\n",
      "Epoch 42/200, Iteration 95/250, Loss: 0.0154\n",
      "Epoch 42/200, Iteration 96/250, Loss: 0.0232\n",
      "Epoch 42/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 42/200, Iteration 98/250, Loss: 0.0123\n",
      "Epoch 42/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 42/200, Iteration 100/250, Loss: 0.0355\n",
      "Epoch 42/200, Iteration 101/250, Loss: 0.0168\n",
      "Epoch 42/200, Iteration 102/250, Loss: 0.0229\n",
      "Epoch 42/200, Iteration 103/250, Loss: 0.0285\n",
      "Epoch 42/200, Iteration 104/250, Loss: 0.0164\n",
      "Epoch 42/200, Iteration 105/250, Loss: 0.0093\n",
      "Epoch 42/200, Iteration 106/250, Loss: 0.0173\n",
      "Epoch 42/200, Iteration 107/250, Loss: 0.0175\n",
      "Epoch 42/200, Iteration 108/250, Loss: 0.0262\n",
      "Epoch 42/200, Iteration 109/250, Loss: 0.0212\n",
      "Epoch 42/200, Iteration 110/250, Loss: 0.0281\n",
      "Epoch 42/200, Iteration 111/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 112/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 113/250, Loss: 0.0169\n",
      "Epoch 42/200, Iteration 114/250, Loss: 0.0088\n",
      "Epoch 42/200, Iteration 115/250, Loss: 0.0200\n",
      "Epoch 42/200, Iteration 116/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 117/250, Loss: 0.0181\n",
      "Epoch 42/200, Iteration 118/250, Loss: 0.0167\n",
      "Epoch 42/200, Iteration 119/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 120/250, Loss: 0.0304\n",
      "Epoch 42/200, Iteration 121/250, Loss: 0.0225\n",
      "Epoch 42/200, Iteration 122/250, Loss: 0.0132\n",
      "Epoch 42/200, Iteration 123/250, Loss: 0.0297\n",
      "Epoch 42/200, Iteration 124/250, Loss: 0.0192\n",
      "Epoch 42/200, Iteration 125/250, Loss: 0.0163\n",
      "Epoch 42/200, Iteration 126/250, Loss: 0.0355\n",
      "Epoch 42/200, Iteration 127/250, Loss: 0.0271\n",
      "Epoch 42/200, Iteration 128/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 129/250, Loss: 0.0163\n",
      "Epoch 42/200, Iteration 130/250, Loss: 0.0128\n",
      "Epoch 42/200, Iteration 131/250, Loss: 0.0193\n",
      "Epoch 42/200, Iteration 132/250, Loss: 0.0211\n",
      "Epoch 42/200, Iteration 133/250, Loss: 0.0152\n",
      "Epoch 42/200, Iteration 134/250, Loss: 0.0129\n",
      "Epoch 42/200, Iteration 135/250, Loss: 0.0167\n",
      "Epoch 42/200, Iteration 136/250, Loss: 0.0293\n",
      "Epoch 42/200, Iteration 137/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 138/250, Loss: 0.0279\n",
      "Epoch 42/200, Iteration 139/250, Loss: 0.0100\n",
      "Epoch 42/200, Iteration 140/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 141/250, Loss: 0.0237\n",
      "Epoch 42/200, Iteration 142/250, Loss: 0.0145\n",
      "Epoch 42/200, Iteration 143/250, Loss: 0.0142\n",
      "Epoch 42/200, Iteration 144/250, Loss: 0.0161\n",
      "Epoch 42/200, Iteration 145/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 146/250, Loss: 0.0171\n",
      "Epoch 42/200, Iteration 147/250, Loss: 0.0155\n",
      "Epoch 42/200, Iteration 148/250, Loss: 0.0097\n",
      "Epoch 42/200, Iteration 149/250, Loss: 0.0373\n",
      "Epoch 42/200, Iteration 150/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 151/250, Loss: 0.0480\n",
      "Epoch 42/200, Iteration 152/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 153/250, Loss: 0.0440\n",
      "Epoch 42/200, Iteration 154/250, Loss: 0.0168\n",
      "Epoch 42/200, Iteration 155/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 156/250, Loss: 0.0169\n",
      "Epoch 42/200, Iteration 157/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 158/250, Loss: 0.0171\n",
      "Epoch 42/200, Iteration 159/250, Loss: 0.0208\n",
      "Epoch 42/200, Iteration 160/250, Loss: 0.0200\n",
      "Epoch 42/200, Iteration 161/250, Loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Iteration 162/250, Loss: 0.0263\n",
      "Epoch 42/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 42/200, Iteration 164/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 165/250, Loss: 0.0093\n",
      "Epoch 42/200, Iteration 166/250, Loss: 0.0224\n",
      "Epoch 42/200, Iteration 167/250, Loss: 0.0170\n",
      "Epoch 42/200, Iteration 168/250, Loss: 0.0160\n",
      "Epoch 42/200, Iteration 169/250, Loss: 0.0156\n",
      "Epoch 42/200, Iteration 170/250, Loss: 0.0183\n",
      "Epoch 42/200, Iteration 171/250, Loss: 0.0119\n",
      "Epoch 42/200, Iteration 172/250, Loss: 0.0113\n",
      "Epoch 42/200, Iteration 173/250, Loss: 0.0116\n",
      "Epoch 42/200, Iteration 174/250, Loss: 0.0103\n",
      "Epoch 42/200, Iteration 175/250, Loss: 0.0165\n",
      "Epoch 42/200, Iteration 176/250, Loss: 0.0175\n",
      "Epoch 42/200, Iteration 177/250, Loss: 0.0247\n",
      "Epoch 42/200, Iteration 178/250, Loss: 0.0275\n",
      "Epoch 42/200, Iteration 179/250, Loss: 0.0311\n",
      "Epoch 42/200, Iteration 180/250, Loss: 0.0123\n",
      "Epoch 42/200, Iteration 181/250, Loss: 0.0202\n",
      "Epoch 42/200, Iteration 182/250, Loss: 0.0392\n",
      "Epoch 42/200, Iteration 183/250, Loss: 0.0204\n",
      "Epoch 42/200, Iteration 184/250, Loss: 0.0163\n",
      "Epoch 42/200, Iteration 185/250, Loss: 0.0152\n",
      "Epoch 42/200, Iteration 186/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 187/250, Loss: 0.0230\n",
      "Epoch 42/200, Iteration 188/250, Loss: 0.0221\n",
      "Epoch 42/200, Iteration 189/250, Loss: 0.0129\n",
      "Epoch 42/200, Iteration 190/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 191/250, Loss: 0.0155\n",
      "Epoch 42/200, Iteration 192/250, Loss: 0.0277\n",
      "Epoch 42/200, Iteration 193/250, Loss: 0.0196\n",
      "Epoch 42/200, Iteration 194/250, Loss: 0.0107\n",
      "Epoch 42/200, Iteration 195/250, Loss: 0.0237\n",
      "Epoch 42/200, Iteration 196/250, Loss: 0.0170\n",
      "Epoch 42/200, Iteration 197/250, Loss: 0.0131\n",
      "Epoch 42/200, Iteration 198/250, Loss: 0.0108\n",
      "Epoch 42/200, Iteration 199/250, Loss: 0.0146\n",
      "Epoch 42/200, Iteration 200/250, Loss: 0.0113\n",
      "Epoch 42/200, Iteration 201/250, Loss: 0.0182\n",
      "Epoch 42/200, Iteration 202/250, Loss: 0.0131\n",
      "Epoch 42/200, Iteration 203/250, Loss: 0.0236\n",
      "Epoch 42/200, Iteration 204/250, Loss: 0.0095\n",
      "Epoch 42/200, Iteration 205/250, Loss: 0.0247\n",
      "Epoch 42/200, Iteration 206/250, Loss: 0.0117\n",
      "Epoch 42/200, Iteration 207/250, Loss: 0.0210\n",
      "Epoch 42/200, Iteration 208/250, Loss: 0.0130\n",
      "Epoch 42/200, Iteration 209/250, Loss: 0.0120\n",
      "Epoch 42/200, Iteration 210/250, Loss: 0.0111\n",
      "Epoch 42/200, Iteration 211/250, Loss: 0.0186\n",
      "Epoch 42/200, Iteration 212/250, Loss: 0.0145\n",
      "Epoch 42/200, Iteration 213/250, Loss: 0.0227\n",
      "Epoch 42/200, Iteration 214/250, Loss: 0.0159\n",
      "Epoch 42/200, Iteration 215/250, Loss: 0.0178\n",
      "Epoch 42/200, Iteration 216/250, Loss: 0.0220\n",
      "Epoch 42/200, Iteration 217/250, Loss: 0.0139\n",
      "Epoch 42/200, Iteration 218/250, Loss: 0.0194\n",
      "Epoch 42/200, Iteration 219/250, Loss: 0.0138\n",
      "Epoch 42/200, Iteration 220/250, Loss: 0.0114\n",
      "Epoch 42/200, Iteration 221/250, Loss: 0.0103\n",
      "Epoch 42/200, Iteration 222/250, Loss: 0.0355\n",
      "Epoch 42/200, Iteration 223/250, Loss: 0.0104\n",
      "Epoch 42/200, Iteration 224/250, Loss: 0.0099\n",
      "Epoch 42/200, Iteration 225/250, Loss: 0.0134\n",
      "Epoch 42/200, Iteration 226/250, Loss: 0.0118\n",
      "Epoch 42/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 42/200, Iteration 228/250, Loss: 0.0189\n",
      "Epoch 42/200, Iteration 229/250, Loss: 0.0119\n",
      "Epoch 42/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 42/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 42/200, Iteration 232/250, Loss: 0.0138\n",
      "Epoch 42/200, Iteration 233/250, Loss: 0.0340\n",
      "Epoch 42/200, Iteration 234/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 235/250, Loss: 0.0239\n",
      "Epoch 42/200, Iteration 236/250, Loss: 0.0114\n",
      "Epoch 42/200, Iteration 237/250, Loss: 0.0139\n",
      "Epoch 42/200, Iteration 238/250, Loss: 0.0179\n",
      "Epoch 42/200, Iteration 239/250, Loss: 0.0284\n",
      "Epoch 42/200, Iteration 240/250, Loss: 0.0106\n",
      "Epoch 42/200, Iteration 241/250, Loss: 0.0244\n",
      "Epoch 42/200, Iteration 242/250, Loss: 0.0157\n",
      "Epoch 42/200, Iteration 243/250, Loss: 0.0348\n",
      "Epoch 42/200, Iteration 244/250, Loss: 0.0153\n",
      "Epoch 42/200, Iteration 245/250, Loss: 0.0188\n",
      "Epoch 42/200, Iteration 246/250, Loss: 0.0227\n",
      "Epoch 42/200, Iteration 247/250, Loss: 0.0097\n",
      "Epoch 42/200, Iteration 248/250, Loss: 0.0173\n",
      "Epoch 42/200, Iteration 249/250, Loss: 0.0120\n",
      "Epoch 42/200, Iteration 250/250, Loss: 0.0207\n",
      "Train Error: \n",
      " Accuracy: 89.31%, Avg loss: 0.008730, MRE: 0.565716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.15%, Avg loss: 0.009261, MRE: 0.712381 \n",
      "\n",
      "Epoch 43/200, Iteration 1/250, Loss: 0.0079\n",
      "Epoch 43/200, Iteration 2/250, Loss: 0.0166\n",
      "Epoch 43/200, Iteration 3/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 4/250, Loss: 0.0204\n",
      "Epoch 43/200, Iteration 5/250, Loss: 0.0148\n",
      "Epoch 43/200, Iteration 6/250, Loss: 0.0226\n",
      "Epoch 43/200, Iteration 7/250, Loss: 0.0206\n",
      "Epoch 43/200, Iteration 8/250, Loss: 0.0260\n",
      "Epoch 43/200, Iteration 9/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 10/250, Loss: 0.0157\n",
      "Epoch 43/200, Iteration 11/250, Loss: 0.0370\n",
      "Epoch 43/200, Iteration 12/250, Loss: 0.0301\n",
      "Epoch 43/200, Iteration 13/250, Loss: 0.0108\n",
      "Epoch 43/200, Iteration 14/250, Loss: 0.0166\n",
      "Epoch 43/200, Iteration 15/250, Loss: 0.0139\n",
      "Epoch 43/200, Iteration 16/250, Loss: 0.0092\n",
      "Epoch 43/200, Iteration 17/250, Loss: 0.0213\n",
      "Epoch 43/200, Iteration 18/250, Loss: 0.0119\n",
      "Epoch 43/200, Iteration 19/250, Loss: 0.0229\n",
      "Epoch 43/200, Iteration 20/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 21/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 22/250, Loss: 0.0140\n",
      "Epoch 43/200, Iteration 23/250, Loss: 0.0337\n",
      "Epoch 43/200, Iteration 24/250, Loss: 0.0102\n",
      "Epoch 43/200, Iteration 25/250, Loss: 0.0108\n",
      "Epoch 43/200, Iteration 26/250, Loss: 0.0093\n",
      "Epoch 43/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 43/200, Iteration 28/250, Loss: 0.0154\n",
      "Epoch 43/200, Iteration 29/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 30/250, Loss: 0.0113\n",
      "Epoch 43/200, Iteration 31/250, Loss: 0.0279\n",
      "Epoch 43/200, Iteration 32/250, Loss: 0.0134\n",
      "Epoch 43/200, Iteration 33/250, Loss: 0.0114\n",
      "Epoch 43/200, Iteration 34/250, Loss: 0.0213\n",
      "Epoch 43/200, Iteration 35/250, Loss: 0.0195\n",
      "Epoch 43/200, Iteration 36/250, Loss: 0.0333\n",
      "Epoch 43/200, Iteration 37/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 38/250, Loss: 0.0119\n",
      "Epoch 43/200, Iteration 39/250, Loss: 0.0178\n",
      "Epoch 43/200, Iteration 40/250, Loss: 0.0079\n",
      "Epoch 43/200, Iteration 41/250, Loss: 0.0172\n",
      "Epoch 43/200, Iteration 42/250, Loss: 0.0139\n",
      "Epoch 43/200, Iteration 43/250, Loss: 0.0541\n",
      "Epoch 43/200, Iteration 44/250, Loss: 0.0140\n",
      "Epoch 43/200, Iteration 45/250, Loss: 0.0131\n",
      "Epoch 43/200, Iteration 46/250, Loss: 0.0131\n",
      "Epoch 43/200, Iteration 47/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 48/250, Loss: 0.0104\n",
      "Epoch 43/200, Iteration 49/250, Loss: 0.0201\n",
      "Epoch 43/200, Iteration 50/250, Loss: 0.0203\n",
      "Epoch 43/200, Iteration 51/250, Loss: 0.0183\n",
      "Epoch 43/200, Iteration 52/250, Loss: 0.0228\n",
      "Epoch 43/200, Iteration 53/250, Loss: 0.0394\n",
      "Epoch 43/200, Iteration 54/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 55/250, Loss: 0.0112\n",
      "Epoch 43/200, Iteration 56/250, Loss: 0.0097\n",
      "Epoch 43/200, Iteration 57/250, Loss: 0.0138\n",
      "Epoch 43/200, Iteration 58/250, Loss: 0.0265\n",
      "Epoch 43/200, Iteration 59/250, Loss: 0.0172\n",
      "Epoch 43/200, Iteration 60/250, Loss: 0.0242\n",
      "Epoch 43/200, Iteration 61/250, Loss: 0.0125\n",
      "Epoch 43/200, Iteration 62/250, Loss: 0.0194\n",
      "Epoch 43/200, Iteration 63/250, Loss: 0.0252\n",
      "Epoch 43/200, Iteration 64/250, Loss: 0.0167\n",
      "Epoch 43/200, Iteration 65/250, Loss: 0.0330\n",
      "Epoch 43/200, Iteration 66/250, Loss: 0.0132\n",
      "Epoch 43/200, Iteration 67/250, Loss: 0.0149\n",
      "Epoch 43/200, Iteration 68/250, Loss: 0.0270\n",
      "Epoch 43/200, Iteration 69/250, Loss: 0.0213\n",
      "Epoch 43/200, Iteration 70/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 71/250, Loss: 0.0169\n",
      "Epoch 43/200, Iteration 72/250, Loss: 0.0110\n",
      "Epoch 43/200, Iteration 73/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 74/250, Loss: 0.0441\n",
      "Epoch 43/200, Iteration 75/250, Loss: 0.0197\n",
      "Epoch 43/200, Iteration 76/250, Loss: 0.0265\n",
      "Epoch 43/200, Iteration 77/250, Loss: 0.0220\n",
      "Epoch 43/200, Iteration 78/250, Loss: 0.0178\n",
      "Epoch 43/200, Iteration 79/250, Loss: 0.0310\n",
      "Epoch 43/200, Iteration 80/250, Loss: 0.0173\n",
      "Epoch 43/200, Iteration 81/250, Loss: 0.0100\n",
      "Epoch 43/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 83/250, Loss: 0.0117\n",
      "Epoch 43/200, Iteration 84/250, Loss: 0.0119\n",
      "Epoch 43/200, Iteration 85/250, Loss: 0.0078\n",
      "Epoch 43/200, Iteration 86/250, Loss: 0.0176\n",
      "Epoch 43/200, Iteration 87/250, Loss: 0.0332\n",
      "Epoch 43/200, Iteration 88/250, Loss: 0.0100\n",
      "Epoch 43/200, Iteration 89/250, Loss: 0.0105\n",
      "Epoch 43/200, Iteration 90/250, Loss: 0.0144\n",
      "Epoch 43/200, Iteration 91/250, Loss: 0.0330\n",
      "Epoch 43/200, Iteration 92/250, Loss: 0.0157\n",
      "Epoch 43/200, Iteration 93/250, Loss: 0.0132\n",
      "Epoch 43/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 43/200, Iteration 95/250, Loss: 0.0215\n",
      "Epoch 43/200, Iteration 96/250, Loss: 0.0220\n",
      "Epoch 43/200, Iteration 97/250, Loss: 0.0163\n",
      "Epoch 43/200, Iteration 98/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 99/250, Loss: 0.0118\n",
      "Epoch 43/200, Iteration 100/250, Loss: 0.0261\n",
      "Epoch 43/200, Iteration 101/250, Loss: 0.0257\n",
      "Epoch 43/200, Iteration 102/250, Loss: 0.0161\n",
      "Epoch 43/200, Iteration 103/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 104/250, Loss: 0.0165\n",
      "Epoch 43/200, Iteration 105/250, Loss: 0.0134\n",
      "Epoch 43/200, Iteration 106/250, Loss: 0.0111\n",
      "Epoch 43/200, Iteration 107/250, Loss: 0.0312\n",
      "Epoch 43/200, Iteration 108/250, Loss: 0.0315\n",
      "Epoch 43/200, Iteration 109/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 110/250, Loss: 0.0200\n",
      "Epoch 43/200, Iteration 111/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 112/250, Loss: 0.0096\n",
      "Epoch 43/200, Iteration 113/250, Loss: 0.0168\n",
      "Epoch 43/200, Iteration 114/250, Loss: 0.0157\n",
      "Epoch 43/200, Iteration 115/250, Loss: 0.0189\n",
      "Epoch 43/200, Iteration 116/250, Loss: 0.0221\n",
      "Epoch 43/200, Iteration 117/250, Loss: 0.0150\n",
      "Epoch 43/200, Iteration 118/250, Loss: 0.0095\n",
      "Epoch 43/200, Iteration 119/250, Loss: 0.0207\n",
      "Epoch 43/200, Iteration 120/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 121/250, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Iteration 122/250, Loss: 0.0116\n",
      "Epoch 43/200, Iteration 123/250, Loss: 0.0064\n",
      "Epoch 43/200, Iteration 124/250, Loss: 0.0197\n",
      "Epoch 43/200, Iteration 125/250, Loss: 0.0077\n",
      "Epoch 43/200, Iteration 126/250, Loss: 0.0118\n",
      "Epoch 43/200, Iteration 127/250, Loss: 0.0110\n",
      "Epoch 43/200, Iteration 128/250, Loss: 0.0293\n",
      "Epoch 43/200, Iteration 129/250, Loss: 0.0166\n",
      "Epoch 43/200, Iteration 130/250, Loss: 0.0105\n",
      "Epoch 43/200, Iteration 131/250, Loss: 0.0165\n",
      "Epoch 43/200, Iteration 132/250, Loss: 0.0115\n",
      "Epoch 43/200, Iteration 133/250, Loss: 0.0176\n",
      "Epoch 43/200, Iteration 134/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 135/250, Loss: 0.0081\n",
      "Epoch 43/200, Iteration 136/250, Loss: 0.0242\n",
      "Epoch 43/200, Iteration 137/250, Loss: 0.0156\n",
      "Epoch 43/200, Iteration 138/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 139/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 140/250, Loss: 0.0129\n",
      "Epoch 43/200, Iteration 141/250, Loss: 0.0155\n",
      "Epoch 43/200, Iteration 142/250, Loss: 0.0119\n",
      "Epoch 43/200, Iteration 143/250, Loss: 0.0102\n",
      "Epoch 43/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 145/250, Loss: 0.0289\n",
      "Epoch 43/200, Iteration 146/250, Loss: 0.0107\n",
      "Epoch 43/200, Iteration 147/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 148/250, Loss: 0.0179\n",
      "Epoch 43/200, Iteration 149/250, Loss: 0.0236\n",
      "Epoch 43/200, Iteration 150/250, Loss: 0.0142\n",
      "Epoch 43/200, Iteration 151/250, Loss: 0.0161\n",
      "Epoch 43/200, Iteration 152/250, Loss: 0.0207\n",
      "Epoch 43/200, Iteration 153/250, Loss: 0.0129\n",
      "Epoch 43/200, Iteration 154/250, Loss: 0.0124\n",
      "Epoch 43/200, Iteration 155/250, Loss: 0.0145\n",
      "Epoch 43/200, Iteration 156/250, Loss: 0.0122\n",
      "Epoch 43/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 43/200, Iteration 158/250, Loss: 0.0131\n",
      "Epoch 43/200, Iteration 159/250, Loss: 0.0241\n",
      "Epoch 43/200, Iteration 160/250, Loss: 0.0155\n",
      "Epoch 43/200, Iteration 161/250, Loss: 0.0258\n",
      "Epoch 43/200, Iteration 162/250, Loss: 0.0161\n",
      "Epoch 43/200, Iteration 163/250, Loss: 0.0231\n",
      "Epoch 43/200, Iteration 164/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 165/250, Loss: 0.0180\n",
      "Epoch 43/200, Iteration 166/250, Loss: 0.0136\n",
      "Epoch 43/200, Iteration 167/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 168/250, Loss: 0.0260\n",
      "Epoch 43/200, Iteration 169/250, Loss: 0.0158\n",
      "Epoch 43/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 43/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 43/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 43/200, Iteration 173/250, Loss: 0.0206\n",
      "Epoch 43/200, Iteration 174/250, Loss: 0.0141\n",
      "Epoch 43/200, Iteration 175/250, Loss: 0.0128\n",
      "Epoch 43/200, Iteration 176/250, Loss: 0.0072\n",
      "Epoch 43/200, Iteration 177/250, Loss: 0.0072\n",
      "Epoch 43/200, Iteration 178/250, Loss: 0.0147\n",
      "Epoch 43/200, Iteration 179/250, Loss: 0.0160\n",
      "Epoch 43/200, Iteration 180/250, Loss: 0.0160\n",
      "Epoch 43/200, Iteration 181/250, Loss: 0.0196\n",
      "Epoch 43/200, Iteration 182/250, Loss: 0.0138\n",
      "Epoch 43/200, Iteration 183/250, Loss: 0.0316\n",
      "Epoch 43/200, Iteration 184/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 185/250, Loss: 0.0238\n",
      "Epoch 43/200, Iteration 186/250, Loss: 0.0232\n",
      "Epoch 43/200, Iteration 187/250, Loss: 0.0163\n",
      "Epoch 43/200, Iteration 188/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 189/250, Loss: 0.0137\n",
      "Epoch 43/200, Iteration 190/250, Loss: 0.0140\n",
      "Epoch 43/200, Iteration 191/250, Loss: 0.0203\n",
      "Epoch 43/200, Iteration 192/250, Loss: 0.0454\n",
      "Epoch 43/200, Iteration 193/250, Loss: 0.0088\n",
      "Epoch 43/200, Iteration 194/250, Loss: 0.0197\n",
      "Epoch 43/200, Iteration 195/250, Loss: 0.0149\n",
      "Epoch 43/200, Iteration 196/250, Loss: 0.0100\n",
      "Epoch 43/200, Iteration 197/250, Loss: 0.0357\n",
      "Epoch 43/200, Iteration 198/250, Loss: 0.0174\n",
      "Epoch 43/200, Iteration 199/250, Loss: 0.0104\n",
      "Epoch 43/200, Iteration 200/250, Loss: 0.0310\n",
      "Epoch 43/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 43/200, Iteration 202/250, Loss: 0.0129\n",
      "Epoch 43/200, Iteration 203/250, Loss: 0.0123\n",
      "Epoch 43/200, Iteration 204/250, Loss: 0.0186\n",
      "Epoch 43/200, Iteration 205/250, Loss: 0.0199\n",
      "Epoch 43/200, Iteration 206/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 207/250, Loss: 0.0106\n",
      "Epoch 43/200, Iteration 208/250, Loss: 0.0170\n",
      "Epoch 43/200, Iteration 209/250, Loss: 0.0247\n",
      "Epoch 43/200, Iteration 210/250, Loss: 0.0085\n",
      "Epoch 43/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 212/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 213/250, Loss: 0.0087\n",
      "Epoch 43/200, Iteration 214/250, Loss: 0.0101\n",
      "Epoch 43/200, Iteration 215/250, Loss: 0.0259\n",
      "Epoch 43/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 43/200, Iteration 217/250, Loss: 0.0260\n",
      "Epoch 43/200, Iteration 218/250, Loss: 0.0143\n",
      "Epoch 43/200, Iteration 219/250, Loss: 0.0228\n",
      "Epoch 43/200, Iteration 220/250, Loss: 0.0380\n",
      "Epoch 43/200, Iteration 221/250, Loss: 0.0194\n",
      "Epoch 43/200, Iteration 222/250, Loss: 0.0313\n",
      "Epoch 43/200, Iteration 223/250, Loss: 0.0131\n",
      "Epoch 43/200, Iteration 224/250, Loss: 0.0182\n",
      "Epoch 43/200, Iteration 225/250, Loss: 0.0160\n",
      "Epoch 43/200, Iteration 226/250, Loss: 0.0172\n",
      "Epoch 43/200, Iteration 227/250, Loss: 0.0115\n",
      "Epoch 43/200, Iteration 228/250, Loss: 0.0163\n",
      "Epoch 43/200, Iteration 229/250, Loss: 0.0210\n",
      "Epoch 43/200, Iteration 230/250, Loss: 0.0239\n",
      "Epoch 43/200, Iteration 231/250, Loss: 0.0208\n",
      "Epoch 43/200, Iteration 232/250, Loss: 0.0135\n",
      "Epoch 43/200, Iteration 233/250, Loss: 0.0082\n",
      "Epoch 43/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 43/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 43/200, Iteration 236/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 237/250, Loss: 0.0103\n",
      "Epoch 43/200, Iteration 238/250, Loss: 0.0252\n",
      "Epoch 43/200, Iteration 239/250, Loss: 0.0146\n",
      "Epoch 43/200, Iteration 240/250, Loss: 0.0150\n",
      "Epoch 43/200, Iteration 241/250, Loss: 0.0256\n",
      "Epoch 43/200, Iteration 242/250, Loss: 0.0355\n",
      "Epoch 43/200, Iteration 243/250, Loss: 0.0254\n",
      "Epoch 43/200, Iteration 244/250, Loss: 0.0356\n",
      "Epoch 43/200, Iteration 245/250, Loss: 0.0113\n",
      "Epoch 43/200, Iteration 246/250, Loss: 0.0130\n",
      "Epoch 43/200, Iteration 247/250, Loss: 0.0153\n",
      "Epoch 43/200, Iteration 248/250, Loss: 0.0176\n",
      "Epoch 43/200, Iteration 249/250, Loss: 0.0138\n",
      "Epoch 43/200, Iteration 250/250, Loss: 0.0117\n",
      "Train Error: \n",
      " Accuracy: 82.88%, Avg loss: 0.010305, MRE: 0.845327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.45%, Avg loss: 0.010644, MRE: 1.145394 \n",
      "\n",
      "Epoch 44/200, Iteration 1/250, Loss: 0.0257\n",
      "Epoch 44/200, Iteration 2/250, Loss: 0.0095\n",
      "Epoch 44/200, Iteration 3/250, Loss: 0.0207\n",
      "Epoch 44/200, Iteration 4/250, Loss: 0.0192\n",
      "Epoch 44/200, Iteration 5/250, Loss: 0.0370\n",
      "Epoch 44/200, Iteration 6/250, Loss: 0.0165\n",
      "Epoch 44/200, Iteration 7/250, Loss: 0.0178\n",
      "Epoch 44/200, Iteration 8/250, Loss: 0.0397\n",
      "Epoch 44/200, Iteration 9/250, Loss: 0.0092\n",
      "Epoch 44/200, Iteration 10/250, Loss: 0.0243\n",
      "Epoch 44/200, Iteration 11/250, Loss: 0.0117\n",
      "Epoch 44/200, Iteration 12/250, Loss: 0.0294\n",
      "Epoch 44/200, Iteration 13/250, Loss: 0.0247\n",
      "Epoch 44/200, Iteration 14/250, Loss: 0.0177\n",
      "Epoch 44/200, Iteration 15/250, Loss: 0.0219\n",
      "Epoch 44/200, Iteration 16/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 17/250, Loss: 0.0216\n",
      "Epoch 44/200, Iteration 18/250, Loss: 0.0223\n",
      "Epoch 44/200, Iteration 19/250, Loss: 0.0156\n",
      "Epoch 44/200, Iteration 20/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 21/250, Loss: 0.0243\n",
      "Epoch 44/200, Iteration 22/250, Loss: 0.0359\n",
      "Epoch 44/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 24/250, Loss: 0.0180\n",
      "Epoch 44/200, Iteration 25/250, Loss: 0.0144\n",
      "Epoch 44/200, Iteration 26/250, Loss: 0.0167\n",
      "Epoch 44/200, Iteration 27/250, Loss: 0.0385\n",
      "Epoch 44/200, Iteration 28/250, Loss: 0.0358\n",
      "Epoch 44/200, Iteration 29/250, Loss: 0.0172\n",
      "Epoch 44/200, Iteration 30/250, Loss: 0.0257\n",
      "Epoch 44/200, Iteration 31/250, Loss: 0.0272\n",
      "Epoch 44/200, Iteration 32/250, Loss: 0.0157\n",
      "Epoch 44/200, Iteration 33/250, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 34/250, Loss: 0.0255\n",
      "Epoch 44/200, Iteration 35/250, Loss: 0.0105\n",
      "Epoch 44/200, Iteration 36/250, Loss: 0.0304\n",
      "Epoch 44/200, Iteration 37/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 38/250, Loss: 0.0090\n",
      "Epoch 44/200, Iteration 39/250, Loss: 0.0151\n",
      "Epoch 44/200, Iteration 40/250, Loss: 0.0137\n",
      "Epoch 44/200, Iteration 41/250, Loss: 0.0114\n",
      "Epoch 44/200, Iteration 42/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 44/250, Loss: 0.0249\n",
      "Epoch 44/200, Iteration 45/250, Loss: 0.0144\n",
      "Epoch 44/200, Iteration 46/250, Loss: 0.0201\n",
      "Epoch 44/200, Iteration 47/250, Loss: 0.0350\n",
      "Epoch 44/200, Iteration 48/250, Loss: 0.0144\n",
      "Epoch 44/200, Iteration 49/250, Loss: 0.0181\n",
      "Epoch 44/200, Iteration 50/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 51/250, Loss: 0.0126\n",
      "Epoch 44/200, Iteration 52/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 44/200, Iteration 54/250, Loss: 0.0097\n",
      "Epoch 44/200, Iteration 55/250, Loss: 0.0313\n",
      "Epoch 44/200, Iteration 56/250, Loss: 0.0148\n",
      "Epoch 44/200, Iteration 57/250, Loss: 0.0151\n",
      "Epoch 44/200, Iteration 58/250, Loss: 0.0128\n",
      "Epoch 44/200, Iteration 59/250, Loss: 0.0139\n",
      "Epoch 44/200, Iteration 60/250, Loss: 0.0237\n",
      "Epoch 44/200, Iteration 61/250, Loss: 0.0175\n",
      "Epoch 44/200, Iteration 62/250, Loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Iteration 63/250, Loss: 0.0263\n",
      "Epoch 44/200, Iteration 64/250, Loss: 0.0150\n",
      "Epoch 44/200, Iteration 65/250, Loss: 0.0163\n",
      "Epoch 44/200, Iteration 66/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 67/250, Loss: 0.0112\n",
      "Epoch 44/200, Iteration 68/250, Loss: 0.0245\n",
      "Epoch 44/200, Iteration 69/250, Loss: 0.0096\n",
      "Epoch 44/200, Iteration 70/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 71/250, Loss: 0.0272\n",
      "Epoch 44/200, Iteration 72/250, Loss: 0.0253\n",
      "Epoch 44/200, Iteration 73/250, Loss: 0.0175\n",
      "Epoch 44/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 44/200, Iteration 75/250, Loss: 0.0124\n",
      "Epoch 44/200, Iteration 76/250, Loss: 0.0116\n",
      "Epoch 44/200, Iteration 77/250, Loss: 0.0140\n",
      "Epoch 44/200, Iteration 78/250, Loss: 0.0189\n",
      "Epoch 44/200, Iteration 79/250, Loss: 0.0202\n",
      "Epoch 44/200, Iteration 80/250, Loss: 0.0225\n",
      "Epoch 44/200, Iteration 81/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 82/250, Loss: 0.0288\n",
      "Epoch 44/200, Iteration 83/250, Loss: 0.0132\n",
      "Epoch 44/200, Iteration 84/250, Loss: 0.0093\n",
      "Epoch 44/200, Iteration 85/250, Loss: 0.0368\n",
      "Epoch 44/200, Iteration 86/250, Loss: 0.0174\n",
      "Epoch 44/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 88/250, Loss: 0.0152\n",
      "Epoch 44/200, Iteration 89/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 90/250, Loss: 0.0201\n",
      "Epoch 44/200, Iteration 91/250, Loss: 0.0099\n",
      "Epoch 44/200, Iteration 92/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 93/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 94/250, Loss: 0.0129\n",
      "Epoch 44/200, Iteration 95/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 96/250, Loss: 0.0095\n",
      "Epoch 44/200, Iteration 97/250, Loss: 0.0180\n",
      "Epoch 44/200, Iteration 98/250, Loss: 0.0167\n",
      "Epoch 44/200, Iteration 99/250, Loss: 0.0143\n",
      "Epoch 44/200, Iteration 100/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 101/250, Loss: 0.0169\n",
      "Epoch 44/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 44/200, Iteration 103/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 104/250, Loss: 0.0139\n",
      "Epoch 44/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 44/200, Iteration 106/250, Loss: 0.0144\n",
      "Epoch 44/200, Iteration 107/250, Loss: 0.0138\n",
      "Epoch 44/200, Iteration 108/250, Loss: 0.0177\n",
      "Epoch 44/200, Iteration 109/250, Loss: 0.0290\n",
      "Epoch 44/200, Iteration 110/250, Loss: 0.0119\n",
      "Epoch 44/200, Iteration 111/250, Loss: 0.0132\n",
      "Epoch 44/200, Iteration 112/250, Loss: 0.0144\n",
      "Epoch 44/200, Iteration 113/250, Loss: 0.0306\n",
      "Epoch 44/200, Iteration 114/250, Loss: 0.0399\n",
      "Epoch 44/200, Iteration 115/250, Loss: 0.0320\n",
      "Epoch 44/200, Iteration 116/250, Loss: 0.0116\n",
      "Epoch 44/200, Iteration 117/250, Loss: 0.0107\n",
      "Epoch 44/200, Iteration 118/250, Loss: 0.0163\n",
      "Epoch 44/200, Iteration 119/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 120/250, Loss: 0.0169\n",
      "Epoch 44/200, Iteration 121/250, Loss: 0.0173\n",
      "Epoch 44/200, Iteration 122/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 123/250, Loss: 0.0142\n",
      "Epoch 44/200, Iteration 124/250, Loss: 0.0159\n",
      "Epoch 44/200, Iteration 125/250, Loss: 0.0168\n",
      "Epoch 44/200, Iteration 126/250, Loss: 0.0388\n",
      "Epoch 44/200, Iteration 127/250, Loss: 0.0199\n",
      "Epoch 44/200, Iteration 128/250, Loss: 0.0178\n",
      "Epoch 44/200, Iteration 129/250, Loss: 0.0164\n",
      "Epoch 44/200, Iteration 130/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 131/250, Loss: 0.0223\n",
      "Epoch 44/200, Iteration 132/250, Loss: 0.0243\n",
      "Epoch 44/200, Iteration 133/250, Loss: 0.0197\n",
      "Epoch 44/200, Iteration 134/250, Loss: 0.0145\n",
      "Epoch 44/200, Iteration 135/250, Loss: 0.0227\n",
      "Epoch 44/200, Iteration 136/250, Loss: 0.0161\n",
      "Epoch 44/200, Iteration 137/250, Loss: 0.0210\n",
      "Epoch 44/200, Iteration 138/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 139/250, Loss: 0.0142\n",
      "Epoch 44/200, Iteration 140/250, Loss: 0.0102\n",
      "Epoch 44/200, Iteration 141/250, Loss: 0.0137\n",
      "Epoch 44/200, Iteration 142/250, Loss: 0.0088\n",
      "Epoch 44/200, Iteration 143/250, Loss: 0.0125\n",
      "Epoch 44/200, Iteration 144/250, Loss: 0.0157\n",
      "Epoch 44/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 44/200, Iteration 146/250, Loss: 0.0195\n",
      "Epoch 44/200, Iteration 147/250, Loss: 0.0203\n",
      "Epoch 44/200, Iteration 148/250, Loss: 0.0163\n",
      "Epoch 44/200, Iteration 149/250, Loss: 0.0110\n",
      "Epoch 44/200, Iteration 150/250, Loss: 0.0158\n",
      "Epoch 44/200, Iteration 151/250, Loss: 0.0167\n",
      "Epoch 44/200, Iteration 152/250, Loss: 0.0143\n",
      "Epoch 44/200, Iteration 153/250, Loss: 0.0126\n",
      "Epoch 44/200, Iteration 154/250, Loss: 0.0283\n",
      "Epoch 44/200, Iteration 155/250, Loss: 0.0145\n",
      "Epoch 44/200, Iteration 156/250, Loss: 0.0080\n",
      "Epoch 44/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 44/200, Iteration 158/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 159/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 160/250, Loss: 0.0178\n",
      "Epoch 44/200, Iteration 161/250, Loss: 0.0142\n",
      "Epoch 44/200, Iteration 162/250, Loss: 0.0207\n",
      "Epoch 44/200, Iteration 163/250, Loss: 0.0139\n",
      "Epoch 44/200, Iteration 164/250, Loss: 0.0085\n",
      "Epoch 44/200, Iteration 165/250, Loss: 0.0174\n",
      "Epoch 44/200, Iteration 166/250, Loss: 0.0115\n",
      "Epoch 44/200, Iteration 167/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 168/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 169/250, Loss: 0.0115\n",
      "Epoch 44/200, Iteration 170/250, Loss: 0.0166\n",
      "Epoch 44/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 44/200, Iteration 172/250, Loss: 0.0121\n",
      "Epoch 44/200, Iteration 173/250, Loss: 0.0102\n",
      "Epoch 44/200, Iteration 174/250, Loss: 0.0204\n",
      "Epoch 44/200, Iteration 175/250, Loss: 0.0120\n",
      "Epoch 44/200, Iteration 176/250, Loss: 0.0268\n",
      "Epoch 44/200, Iteration 177/250, Loss: 0.0115\n",
      "Epoch 44/200, Iteration 178/250, Loss: 0.0319\n",
      "Epoch 44/200, Iteration 179/250, Loss: 0.0172\n",
      "Epoch 44/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 44/200, Iteration 181/250, Loss: 0.0228\n",
      "Epoch 44/200, Iteration 182/250, Loss: 0.0152\n",
      "Epoch 44/200, Iteration 183/250, Loss: 0.0252\n",
      "Epoch 44/200, Iteration 184/250, Loss: 0.0187\n",
      "Epoch 44/200, Iteration 185/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 44/200, Iteration 187/250, Loss: 0.0141\n",
      "Epoch 44/200, Iteration 188/250, Loss: 0.0096\n",
      "Epoch 44/200, Iteration 189/250, Loss: 0.0195\n",
      "Epoch 44/200, Iteration 190/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 191/250, Loss: 0.0230\n",
      "Epoch 44/200, Iteration 192/250, Loss: 0.0216\n",
      "Epoch 44/200, Iteration 193/250, Loss: 0.0104\n",
      "Epoch 44/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 195/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 44/200, Iteration 197/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 199/250, Loss: 0.0077\n",
      "Epoch 44/200, Iteration 200/250, Loss: 0.0125\n",
      "Epoch 44/200, Iteration 201/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 202/250, Loss: 0.0216\n",
      "Epoch 44/200, Iteration 203/250, Loss: 0.0085\n",
      "Epoch 44/200, Iteration 204/250, Loss: 0.0115\n",
      "Epoch 44/200, Iteration 205/250, Loss: 0.0119\n",
      "Epoch 44/200, Iteration 206/250, Loss: 0.0108\n",
      "Epoch 44/200, Iteration 207/250, Loss: 0.0094\n",
      "Epoch 44/200, Iteration 208/250, Loss: 0.0155\n",
      "Epoch 44/200, Iteration 209/250, Loss: 0.0128\n",
      "Epoch 44/200, Iteration 210/250, Loss: 0.0097\n",
      "Epoch 44/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 44/200, Iteration 212/250, Loss: 0.0106\n",
      "Epoch 44/200, Iteration 213/250, Loss: 0.0229\n",
      "Epoch 44/200, Iteration 214/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 215/250, Loss: 0.0174\n",
      "Epoch 44/200, Iteration 216/250, Loss: 0.0305\n",
      "Epoch 44/200, Iteration 217/250, Loss: 0.0113\n",
      "Epoch 44/200, Iteration 218/250, Loss: 0.0292\n",
      "Epoch 44/200, Iteration 219/250, Loss: 0.0303\n",
      "Epoch 44/200, Iteration 220/250, Loss: 0.0133\n",
      "Epoch 44/200, Iteration 221/250, Loss: 0.0258\n",
      "Epoch 44/200, Iteration 222/250, Loss: 0.0084\n",
      "Epoch 44/200, Iteration 223/250, Loss: 0.0129\n",
      "Epoch 44/200, Iteration 224/250, Loss: 0.0162\n",
      "Epoch 44/200, Iteration 225/250, Loss: 0.0141\n",
      "Epoch 44/200, Iteration 226/250, Loss: 0.0126\n",
      "Epoch 44/200, Iteration 227/250, Loss: 0.0141\n",
      "Epoch 44/200, Iteration 228/250, Loss: 0.0329\n",
      "Epoch 44/200, Iteration 229/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 230/250, Loss: 0.0111\n",
      "Epoch 44/200, Iteration 231/250, Loss: 0.0170\n",
      "Epoch 44/200, Iteration 232/250, Loss: 0.0116\n",
      "Epoch 44/200, Iteration 233/250, Loss: 0.0204\n",
      "Epoch 44/200, Iteration 234/250, Loss: 0.0197\n",
      "Epoch 44/200, Iteration 235/250, Loss: 0.0136\n",
      "Epoch 44/200, Iteration 236/250, Loss: 0.0100\n",
      "Epoch 44/200, Iteration 237/250, Loss: 0.0211\n",
      "Epoch 44/200, Iteration 238/250, Loss: 0.0236\n",
      "Epoch 44/200, Iteration 239/250, Loss: 0.0171\n",
      "Epoch 44/200, Iteration 240/250, Loss: 0.0081\n",
      "Epoch 44/200, Iteration 241/250, Loss: 0.0157\n",
      "Epoch 44/200, Iteration 242/250, Loss: 0.0134\n",
      "Epoch 44/200, Iteration 243/250, Loss: 0.0102\n",
      "Epoch 44/200, Iteration 244/250, Loss: 0.0083\n",
      "Epoch 44/200, Iteration 245/250, Loss: 0.0201\n",
      "Epoch 44/200, Iteration 246/250, Loss: 0.0131\n",
      "Epoch 44/200, Iteration 247/250, Loss: 0.0103\n",
      "Epoch 44/200, Iteration 248/250, Loss: 0.0265\n",
      "Epoch 44/200, Iteration 249/250, Loss: 0.0140\n",
      "Epoch 44/200, Iteration 250/250, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 78.11%, Avg loss: 0.010244, MRE: 0.698984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.010567, MRE: 0.941906 \n",
      "\n",
      "Epoch 45/200, Iteration 1/250, Loss: 0.0187\n",
      "Epoch 45/200, Iteration 2/250, Loss: 0.0176\n",
      "Epoch 45/200, Iteration 3/250, Loss: 0.0176\n",
      "Epoch 45/200, Iteration 4/250, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 5/250, Loss: 0.0263\n",
      "Epoch 45/200, Iteration 6/250, Loss: 0.0136\n",
      "Epoch 45/200, Iteration 7/250, Loss: 0.0105\n",
      "Epoch 45/200, Iteration 8/250, Loss: 0.0095\n",
      "Epoch 45/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 10/250, Loss: 0.0191\n",
      "Epoch 45/200, Iteration 11/250, Loss: 0.0146\n",
      "Epoch 45/200, Iteration 12/250, Loss: 0.0224\n",
      "Epoch 45/200, Iteration 13/250, Loss: 0.0135\n",
      "Epoch 45/200, Iteration 14/250, Loss: 0.0379\n",
      "Epoch 45/200, Iteration 15/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 16/250, Loss: 0.0124\n",
      "Epoch 45/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 45/200, Iteration 18/250, Loss: 0.0157\n",
      "Epoch 45/200, Iteration 19/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 20/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 45/200, Iteration 22/250, Loss: 0.0125\n",
      "Epoch 45/200, Iteration 23/250, Loss: 0.0128\n",
      "Epoch 45/200, Iteration 24/250, Loss: 0.0146\n",
      "Epoch 45/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 45/200, Iteration 26/250, Loss: 0.0174\n",
      "Epoch 45/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 45/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 45/200, Iteration 29/250, Loss: 0.0249\n",
      "Epoch 45/200, Iteration 30/250, Loss: 0.0151\n",
      "Epoch 45/200, Iteration 31/250, Loss: 0.0201\n",
      "Epoch 45/200, Iteration 32/250, Loss: 0.0356\n",
      "Epoch 45/200, Iteration 33/250, Loss: 0.0141\n",
      "Epoch 45/200, Iteration 34/250, Loss: 0.0180\n",
      "Epoch 45/200, Iteration 35/250, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 36/250, Loss: 0.0134\n",
      "Epoch 45/200, Iteration 37/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 38/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 39/250, Loss: 0.0138\n",
      "Epoch 45/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 45/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 42/250, Loss: 0.0322\n",
      "Epoch 45/200, Iteration 43/250, Loss: 0.0339\n",
      "Epoch 45/200, Iteration 44/250, Loss: 0.0200\n",
      "Epoch 45/200, Iteration 45/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 45/200, Iteration 47/250, Loss: 0.0087\n",
      "Epoch 45/200, Iteration 48/250, Loss: 0.0186\n",
      "Epoch 45/200, Iteration 49/250, Loss: 0.0113\n",
      "Epoch 45/200, Iteration 50/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 51/250, Loss: 0.0167\n",
      "Epoch 45/200, Iteration 52/250, Loss: 0.0191\n",
      "Epoch 45/200, Iteration 53/250, Loss: 0.0108\n",
      "Epoch 45/200, Iteration 54/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 55/250, Loss: 0.0272\n",
      "Epoch 45/200, Iteration 56/250, Loss: 0.0115\n",
      "Epoch 45/200, Iteration 57/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 58/250, Loss: 0.0078\n",
      "Epoch 45/200, Iteration 59/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 60/250, Loss: 0.0132\n",
      "Epoch 45/200, Iteration 61/250, Loss: 0.0230\n",
      "Epoch 45/200, Iteration 62/250, Loss: 0.0408\n",
      "Epoch 45/200, Iteration 63/250, Loss: 0.0344\n",
      "Epoch 45/200, Iteration 64/250, Loss: 0.0251\n",
      "Epoch 45/200, Iteration 65/250, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 66/250, Loss: 0.0180\n",
      "Epoch 45/200, Iteration 67/250, Loss: 0.0222\n",
      "Epoch 45/200, Iteration 68/250, Loss: 0.0195\n",
      "Epoch 45/200, Iteration 69/250, Loss: 0.0137\n",
      "Epoch 45/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 45/200, Iteration 71/250, Loss: 0.0333\n",
      "Epoch 45/200, Iteration 72/250, Loss: 0.0171\n",
      "Epoch 45/200, Iteration 73/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 74/250, Loss: 0.0189\n",
      "Epoch 45/200, Iteration 75/250, Loss: 0.0238\n",
      "Epoch 45/200, Iteration 76/250, Loss: 0.0134\n",
      "Epoch 45/200, Iteration 77/250, Loss: 0.0147\n",
      "Epoch 45/200, Iteration 78/250, Loss: 0.0130\n",
      "Epoch 45/200, Iteration 79/250, Loss: 0.0203\n",
      "Epoch 45/200, Iteration 80/250, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 81/250, Loss: 0.0190\n",
      "Epoch 45/200, Iteration 82/250, Loss: 0.0133\n",
      "Epoch 45/200, Iteration 83/250, Loss: 0.0126\n",
      "Epoch 45/200, Iteration 84/250, Loss: 0.0142\n",
      "Epoch 45/200, Iteration 85/250, Loss: 0.0153\n",
      "Epoch 45/200, Iteration 86/250, Loss: 0.0231\n",
      "Epoch 45/200, Iteration 87/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 88/250, Loss: 0.0175\n",
      "Epoch 45/200, Iteration 89/250, Loss: 0.0097\n",
      "Epoch 45/200, Iteration 90/250, Loss: 0.0232\n",
      "Epoch 45/200, Iteration 91/250, Loss: 0.0138\n",
      "Epoch 45/200, Iteration 92/250, Loss: 0.0113\n",
      "Epoch 45/200, Iteration 93/250, Loss: 0.0324\n",
      "Epoch 45/200, Iteration 94/250, Loss: 0.0235\n",
      "Epoch 45/200, Iteration 95/250, Loss: 0.0150\n",
      "Epoch 45/200, Iteration 96/250, Loss: 0.0136\n",
      "Epoch 45/200, Iteration 97/250, Loss: 0.0173\n",
      "Epoch 45/200, Iteration 98/250, Loss: 0.0112\n",
      "Epoch 45/200, Iteration 99/250, Loss: 0.0197\n",
      "Epoch 45/200, Iteration 100/250, Loss: 0.0187\n",
      "Epoch 45/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 45/200, Iteration 102/250, Loss: 0.0111\n",
      "Epoch 45/200, Iteration 103/250, Loss: 0.0167\n",
      "Epoch 45/200, Iteration 104/250, Loss: 0.0085\n",
      "Epoch 45/200, Iteration 105/250, Loss: 0.0126\n",
      "Epoch 45/200, Iteration 106/250, Loss: 0.0093\n",
      "Epoch 45/200, Iteration 107/250, Loss: 0.0165\n",
      "Epoch 45/200, Iteration 108/250, Loss: 0.0161\n",
      "Epoch 45/200, Iteration 109/250, Loss: 0.0106\n",
      "Epoch 45/200, Iteration 110/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 111/250, Loss: 0.0183\n",
      "Epoch 45/200, Iteration 112/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 113/250, Loss: 0.0162\n",
      "Epoch 45/200, Iteration 114/250, Loss: 0.0101\n",
      "Epoch 45/200, Iteration 115/250, Loss: 0.0084\n",
      "Epoch 45/200, Iteration 116/250, Loss: 0.0198\n",
      "Epoch 45/200, Iteration 117/250, Loss: 0.0121\n",
      "Epoch 45/200, Iteration 118/250, Loss: 0.0185\n",
      "Epoch 45/200, Iteration 119/250, Loss: 0.0191\n",
      "Epoch 45/200, Iteration 120/250, Loss: 0.0312\n",
      "Epoch 45/200, Iteration 121/250, Loss: 0.0173\n",
      "Epoch 45/200, Iteration 122/250, Loss: 0.0358\n",
      "Epoch 45/200, Iteration 123/250, Loss: 0.0119\n",
      "Epoch 45/200, Iteration 124/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 125/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 126/250, Loss: 0.0154\n",
      "Epoch 45/200, Iteration 127/250, Loss: 0.0317\n",
      "Epoch 45/200, Iteration 128/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 129/250, Loss: 0.0093\n",
      "Epoch 45/200, Iteration 130/250, Loss: 0.0135\n",
      "Epoch 45/200, Iteration 131/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 132/250, Loss: 0.0135\n",
      "Epoch 45/200, Iteration 133/250, Loss: 0.0214\n",
      "Epoch 45/200, Iteration 134/250, Loss: 0.0101\n",
      "Epoch 45/200, Iteration 135/250, Loss: 0.0158\n",
      "Epoch 45/200, Iteration 136/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 137/250, Loss: 0.0080\n",
      "Epoch 45/200, Iteration 138/250, Loss: 0.0217\n",
      "Epoch 45/200, Iteration 139/250, Loss: 0.0136\n",
      "Epoch 45/200, Iteration 140/250, Loss: 0.0152\n",
      "Epoch 45/200, Iteration 141/250, Loss: 0.0148\n",
      "Epoch 45/200, Iteration 142/250, Loss: 0.0153\n",
      "Epoch 45/200, Iteration 143/250, Loss: 0.0203\n",
      "Epoch 45/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 45/200, Iteration 145/250, Loss: 0.0133\n",
      "Epoch 45/200, Iteration 146/250, Loss: 0.0154\n",
      "Epoch 45/200, Iteration 147/250, Loss: 0.0105\n",
      "Epoch 45/200, Iteration 148/250, Loss: 0.0115\n",
      "Epoch 45/200, Iteration 149/250, Loss: 0.0371\n",
      "Epoch 45/200, Iteration 150/250, Loss: 0.0307\n",
      "Epoch 45/200, Iteration 151/250, Loss: 0.0172\n",
      "Epoch 45/200, Iteration 152/250, Loss: 0.0107\n",
      "Epoch 45/200, Iteration 153/250, Loss: 0.0095\n",
      "Epoch 45/200, Iteration 154/250, Loss: 0.0247\n",
      "Epoch 45/200, Iteration 155/250, Loss: 0.0277\n",
      "Epoch 45/200, Iteration 156/250, Loss: 0.0152\n",
      "Epoch 45/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 45/200, Iteration 158/250, Loss: 0.0126\n",
      "Epoch 45/200, Iteration 159/250, Loss: 0.0077\n",
      "Epoch 45/200, Iteration 160/250, Loss: 0.0078\n",
      "Epoch 45/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 162/250, Loss: 0.0147\n",
      "Epoch 45/200, Iteration 163/250, Loss: 0.0145\n",
      "Epoch 45/200, Iteration 164/250, Loss: 0.0190\n",
      "Epoch 45/200, Iteration 165/250, Loss: 0.0134\n",
      "Epoch 45/200, Iteration 166/250, Loss: 0.0294\n",
      "Epoch 45/200, Iteration 167/250, Loss: 0.0226\n",
      "Epoch 45/200, Iteration 168/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 169/250, Loss: 0.0181\n",
      "Epoch 45/200, Iteration 170/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 171/250, Loss: 0.0095\n",
      "Epoch 45/200, Iteration 172/250, Loss: 0.0123\n",
      "Epoch 45/200, Iteration 173/250, Loss: 0.0186\n",
      "Epoch 45/200, Iteration 174/250, Loss: 0.0123\n",
      "Epoch 45/200, Iteration 175/250, Loss: 0.0255\n",
      "Epoch 45/200, Iteration 176/250, Loss: 0.0123\n",
      "Epoch 45/200, Iteration 177/250, Loss: 0.0139\n",
      "Epoch 45/200, Iteration 178/250, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 179/250, Loss: 0.0301\n",
      "Epoch 45/200, Iteration 180/250, Loss: 0.0181\n",
      "Epoch 45/200, Iteration 181/250, Loss: 0.0246\n",
      "Epoch 45/200, Iteration 182/250, Loss: 0.0138\n",
      "Epoch 45/200, Iteration 183/250, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Iteration 184/250, Loss: 0.0144\n",
      "Epoch 45/200, Iteration 185/250, Loss: 0.0155\n",
      "Epoch 45/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 187/250, Loss: 0.0207\n",
      "Epoch 45/200, Iteration 188/250, Loss: 0.0315\n",
      "Epoch 45/200, Iteration 189/250, Loss: 0.0381\n",
      "Epoch 45/200, Iteration 190/250, Loss: 0.0243\n",
      "Epoch 45/200, Iteration 191/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 192/250, Loss: 0.0117\n",
      "Epoch 45/200, Iteration 193/250, Loss: 0.0157\n",
      "Epoch 45/200, Iteration 194/250, Loss: 0.0127\n",
      "Epoch 45/200, Iteration 195/250, Loss: 0.0150\n",
      "Epoch 45/200, Iteration 196/250, Loss: 0.0143\n",
      "Epoch 45/200, Iteration 197/250, Loss: 0.0134\n",
      "Epoch 45/200, Iteration 198/250, Loss: 0.0123\n",
      "Epoch 45/200, Iteration 199/250, Loss: 0.0189\n",
      "Epoch 45/200, Iteration 200/250, Loss: 0.0258\n",
      "Epoch 45/200, Iteration 201/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 202/250, Loss: 0.0085\n",
      "Epoch 45/200, Iteration 203/250, Loss: 0.0100\n",
      "Epoch 45/200, Iteration 204/250, Loss: 0.0108\n",
      "Epoch 45/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 45/200, Iteration 206/250, Loss: 0.0103\n",
      "Epoch 45/200, Iteration 207/250, Loss: 0.0164\n",
      "Epoch 45/200, Iteration 208/250, Loss: 0.0095\n",
      "Epoch 45/200, Iteration 209/250, Loss: 0.0096\n",
      "Epoch 45/200, Iteration 210/250, Loss: 0.0209\n",
      "Epoch 45/200, Iteration 211/250, Loss: 0.0086\n",
      "Epoch 45/200, Iteration 212/250, Loss: 0.0225\n",
      "Epoch 45/200, Iteration 213/250, Loss: 0.0135\n",
      "Epoch 45/200, Iteration 214/250, Loss: 0.0173\n",
      "Epoch 45/200, Iteration 215/250, Loss: 0.0172\n",
      "Epoch 45/200, Iteration 216/250, Loss: 0.0200\n",
      "Epoch 45/200, Iteration 217/250, Loss: 0.0128\n",
      "Epoch 45/200, Iteration 218/250, Loss: 0.0287\n",
      "Epoch 45/200, Iteration 219/250, Loss: 0.0238\n",
      "Epoch 45/200, Iteration 220/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 221/250, Loss: 0.0161\n",
      "Epoch 45/200, Iteration 222/250, Loss: 0.0131\n",
      "Epoch 45/200, Iteration 223/250, Loss: 0.0067\n",
      "Epoch 45/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 225/250, Loss: 0.0179\n",
      "Epoch 45/200, Iteration 226/250, Loss: 0.0176\n",
      "Epoch 45/200, Iteration 227/250, Loss: 0.0261\n",
      "Epoch 45/200, Iteration 228/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 229/250, Loss: 0.0121\n",
      "Epoch 45/200, Iteration 230/250, Loss: 0.0172\n",
      "Epoch 45/200, Iteration 231/250, Loss: 0.0103\n",
      "Epoch 45/200, Iteration 232/250, Loss: 0.0130\n",
      "Epoch 45/200, Iteration 233/250, Loss: 0.0094\n",
      "Epoch 45/200, Iteration 234/250, Loss: 0.0090\n",
      "Epoch 45/200, Iteration 235/250, Loss: 0.0118\n",
      "Epoch 45/200, Iteration 236/250, Loss: 0.0239\n",
      "Epoch 45/200, Iteration 237/250, Loss: 0.0211\n",
      "Epoch 45/200, Iteration 238/250, Loss: 0.0115\n",
      "Epoch 45/200, Iteration 239/250, Loss: 0.0199\n",
      "Epoch 45/200, Iteration 240/250, Loss: 0.0107\n",
      "Epoch 45/200, Iteration 241/250, Loss: 0.0224\n",
      "Epoch 45/200, Iteration 242/250, Loss: 0.0241\n",
      "Epoch 45/200, Iteration 243/250, Loss: 0.0190\n",
      "Epoch 45/200, Iteration 244/250, Loss: 0.0215\n",
      "Epoch 45/200, Iteration 245/250, Loss: 0.0106\n",
      "Epoch 45/200, Iteration 246/250, Loss: 0.0145\n",
      "Epoch 45/200, Iteration 247/250, Loss: 0.0122\n",
      "Epoch 45/200, Iteration 248/250, Loss: 0.0169\n",
      "Epoch 45/200, Iteration 249/250, Loss: 0.0169\n",
      "Epoch 45/200, Iteration 250/250, Loss: 0.0163\n",
      "Train Error: \n",
      " Accuracy: 85.15%, Avg loss: 0.008703, MRE: 0.597829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.009136, MRE: 0.692597 \n",
      "\n",
      "Epoch 46/200, Iteration 1/250, Loss: 0.0191\n",
      "Epoch 46/200, Iteration 2/250, Loss: 0.0255\n",
      "Epoch 46/200, Iteration 3/250, Loss: 0.0258\n",
      "Epoch 46/200, Iteration 4/250, Loss: 0.0171\n",
      "Epoch 46/200, Iteration 5/250, Loss: 0.0182\n",
      "Epoch 46/200, Iteration 6/250, Loss: 0.0232\n",
      "Epoch 46/200, Iteration 7/250, Loss: 0.0144\n",
      "Epoch 46/200, Iteration 8/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 9/250, Loss: 0.0119\n",
      "Epoch 46/200, Iteration 10/250, Loss: 0.0096\n",
      "Epoch 46/200, Iteration 11/250, Loss: 0.0118\n",
      "Epoch 46/200, Iteration 12/250, Loss: 0.0169\n",
      "Epoch 46/200, Iteration 13/250, Loss: 0.0219\n",
      "Epoch 46/200, Iteration 14/250, Loss: 0.0133\n",
      "Epoch 46/200, Iteration 15/250, Loss: 0.0264\n",
      "Epoch 46/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 46/200, Iteration 17/250, Loss: 0.0280\n",
      "Epoch 46/200, Iteration 18/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 19/250, Loss: 0.0277\n",
      "Epoch 46/200, Iteration 20/250, Loss: 0.0093\n",
      "Epoch 46/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 46/200, Iteration 22/250, Loss: 0.0155\n",
      "Epoch 46/200, Iteration 23/250, Loss: 0.0114\n",
      "Epoch 46/200, Iteration 24/250, Loss: 0.0128\n",
      "Epoch 46/200, Iteration 25/250, Loss: 0.0075\n",
      "Epoch 46/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 46/200, Iteration 27/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 28/250, Loss: 0.0134\n",
      "Epoch 46/200, Iteration 29/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 30/250, Loss: 0.0210\n",
      "Epoch 46/200, Iteration 31/250, Loss: 0.0158\n",
      "Epoch 46/200, Iteration 32/250, Loss: 0.0166\n",
      "Epoch 46/200, Iteration 33/250, Loss: 0.0292\n",
      "Epoch 46/200, Iteration 34/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 35/250, Loss: 0.0219\n",
      "Epoch 46/200, Iteration 36/250, Loss: 0.0171\n",
      "Epoch 46/200, Iteration 37/250, Loss: 0.0214\n",
      "Epoch 46/200, Iteration 38/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 39/250, Loss: 0.0191\n",
      "Epoch 46/200, Iteration 40/250, Loss: 0.0118\n",
      "Epoch 46/200, Iteration 41/250, Loss: 0.0170\n",
      "Epoch 46/200, Iteration 42/250, Loss: 0.0125\n",
      "Epoch 46/200, Iteration 43/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 44/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 46/200, Iteration 46/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 47/250, Loss: 0.0203\n",
      "Epoch 46/200, Iteration 48/250, Loss: 0.0131\n",
      "Epoch 46/200, Iteration 49/250, Loss: 0.0126\n",
      "Epoch 46/200, Iteration 50/250, Loss: 0.0126\n",
      "Epoch 46/200, Iteration 51/250, Loss: 0.0144\n",
      "Epoch 46/200, Iteration 52/250, Loss: 0.0086\n",
      "Epoch 46/200, Iteration 53/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 54/250, Loss: 0.0121\n",
      "Epoch 46/200, Iteration 55/250, Loss: 0.0175\n",
      "Epoch 46/200, Iteration 56/250, Loss: 0.0161\n",
      "Epoch 46/200, Iteration 57/250, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 58/250, Loss: 0.0177\n",
      "Epoch 46/200, Iteration 59/250, Loss: 0.0141\n",
      "Epoch 46/200, Iteration 60/250, Loss: 0.0185\n",
      "Epoch 46/200, Iteration 61/250, Loss: 0.0270\n",
      "Epoch 46/200, Iteration 62/250, Loss: 0.0237\n",
      "Epoch 46/200, Iteration 63/250, Loss: 0.0411\n",
      "Epoch 46/200, Iteration 64/250, Loss: 0.0208\n",
      "Epoch 46/200, Iteration 65/250, Loss: 0.0145\n",
      "Epoch 46/200, Iteration 66/250, Loss: 0.0075\n",
      "Epoch 46/200, Iteration 67/250, Loss: 0.0095\n",
      "Epoch 46/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 46/200, Iteration 69/250, Loss: 0.0240\n",
      "Epoch 46/200, Iteration 70/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 71/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 72/250, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 73/250, Loss: 0.0108\n",
      "Epoch 46/200, Iteration 74/250, Loss: 0.0325\n",
      "Epoch 46/200, Iteration 75/250, Loss: 0.0099\n",
      "Epoch 46/200, Iteration 76/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 77/250, Loss: 0.0193\n",
      "Epoch 46/200, Iteration 78/250, Loss: 0.0224\n",
      "Epoch 46/200, Iteration 79/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 80/250, Loss: 0.0209\n",
      "Epoch 46/200, Iteration 81/250, Loss: 0.0141\n",
      "Epoch 46/200, Iteration 82/250, Loss: 0.0117\n",
      "Epoch 46/200, Iteration 83/250, Loss: 0.0125\n",
      "Epoch 46/200, Iteration 84/250, Loss: 0.0119\n",
      "Epoch 46/200, Iteration 85/250, Loss: 0.0288\n",
      "Epoch 46/200, Iteration 86/250, Loss: 0.0080\n",
      "Epoch 46/200, Iteration 87/250, Loss: 0.0204\n",
      "Epoch 46/200, Iteration 88/250, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 89/250, Loss: 0.0163\n",
      "Epoch 46/200, Iteration 90/250, Loss: 0.0120\n",
      "Epoch 46/200, Iteration 91/250, Loss: 0.0273\n",
      "Epoch 46/200, Iteration 92/250, Loss: 0.0108\n",
      "Epoch 46/200, Iteration 93/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 94/250, Loss: 0.0173\n",
      "Epoch 46/200, Iteration 95/250, Loss: 0.0101\n",
      "Epoch 46/200, Iteration 96/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 97/250, Loss: 0.0401\n",
      "Epoch 46/200, Iteration 98/250, Loss: 0.0117\n",
      "Epoch 46/200, Iteration 99/250, Loss: 0.0155\n",
      "Epoch 46/200, Iteration 100/250, Loss: 0.0131\n",
      "Epoch 46/200, Iteration 101/250, Loss: 0.0190\n",
      "Epoch 46/200, Iteration 102/250, Loss: 0.0187\n",
      "Epoch 46/200, Iteration 103/250, Loss: 0.0196\n",
      "Epoch 46/200, Iteration 104/250, Loss: 0.0226\n",
      "Epoch 46/200, Iteration 105/250, Loss: 0.0134\n",
      "Epoch 46/200, Iteration 106/250, Loss: 0.0203\n",
      "Epoch 46/200, Iteration 107/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 108/250, Loss: 0.0184\n",
      "Epoch 46/200, Iteration 109/250, Loss: 0.0124\n",
      "Epoch 46/200, Iteration 110/250, Loss: 0.0147\n",
      "Epoch 46/200, Iteration 111/250, Loss: 0.0166\n",
      "Epoch 46/200, Iteration 112/250, Loss: 0.0116\n",
      "Epoch 46/200, Iteration 113/250, Loss: 0.0138\n",
      "Epoch 46/200, Iteration 114/250, Loss: 0.0137\n",
      "Epoch 46/200, Iteration 115/250, Loss: 0.0215\n",
      "Epoch 46/200, Iteration 116/250, Loss: 0.0128\n",
      "Epoch 46/200, Iteration 117/250, Loss: 0.0099\n",
      "Epoch 46/200, Iteration 118/250, Loss: 0.0179\n",
      "Epoch 46/200, Iteration 119/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 120/250, Loss: 0.0167\n",
      "Epoch 46/200, Iteration 121/250, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Iteration 122/250, Loss: 0.0125\n",
      "Epoch 46/200, Iteration 123/250, Loss: 0.0149\n",
      "Epoch 46/200, Iteration 124/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 125/250, Loss: 0.0130\n",
      "Epoch 46/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 46/200, Iteration 127/250, Loss: 0.0252\n",
      "Epoch 46/200, Iteration 128/250, Loss: 0.0100\n",
      "Epoch 46/200, Iteration 129/250, Loss: 0.0089\n",
      "Epoch 46/200, Iteration 130/250, Loss: 0.0162\n",
      "Epoch 46/200, Iteration 131/250, Loss: 0.0390\n",
      "Epoch 46/200, Iteration 132/250, Loss: 0.0126\n",
      "Epoch 46/200, Iteration 133/250, Loss: 0.0151\n",
      "Epoch 46/200, Iteration 134/250, Loss: 0.0146\n",
      "Epoch 46/200, Iteration 135/250, Loss: 0.0265\n",
      "Epoch 46/200, Iteration 136/250, Loss: 0.0116\n",
      "Epoch 46/200, Iteration 137/250, Loss: 0.0172\n",
      "Epoch 46/200, Iteration 138/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 139/250, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 140/250, Loss: 0.0153\n",
      "Epoch 46/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 46/200, Iteration 142/250, Loss: 0.0143\n",
      "Epoch 46/200, Iteration 143/250, Loss: 0.0118\n",
      "Epoch 46/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 46/200, Iteration 145/250, Loss: 0.0216\n",
      "Epoch 46/200, Iteration 146/250, Loss: 0.0295\n",
      "Epoch 46/200, Iteration 147/250, Loss: 0.0183\n",
      "Epoch 46/200, Iteration 148/250, Loss: 0.0188\n",
      "Epoch 46/200, Iteration 149/250, Loss: 0.0105\n",
      "Epoch 46/200, Iteration 150/250, Loss: 0.0230\n",
      "Epoch 46/200, Iteration 151/250, Loss: 0.0129\n",
      "Epoch 46/200, Iteration 152/250, Loss: 0.0098\n",
      "Epoch 46/200, Iteration 153/250, Loss: 0.0206\n",
      "Epoch 46/200, Iteration 154/250, Loss: 0.0162\n",
      "Epoch 46/200, Iteration 155/250, Loss: 0.0298\n",
      "Epoch 46/200, Iteration 156/250, Loss: 0.0294\n",
      "Epoch 46/200, Iteration 157/250, Loss: 0.0165\n",
      "Epoch 46/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 46/200, Iteration 159/250, Loss: 0.0313\n",
      "Epoch 46/200, Iteration 160/250, Loss: 0.0274\n",
      "Epoch 46/200, Iteration 161/250, Loss: 0.0131\n",
      "Epoch 46/200, Iteration 162/250, Loss: 0.0125\n",
      "Epoch 46/200, Iteration 163/250, Loss: 0.0206\n",
      "Epoch 46/200, Iteration 164/250, Loss: 0.0238\n",
      "Epoch 46/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 46/200, Iteration 166/250, Loss: 0.0311\n",
      "Epoch 46/200, Iteration 167/250, Loss: 0.0092\n",
      "Epoch 46/200, Iteration 168/250, Loss: 0.0110\n",
      "Epoch 46/200, Iteration 169/250, Loss: 0.0142\n",
      "Epoch 46/200, Iteration 170/250, Loss: 0.0178\n",
      "Epoch 46/200, Iteration 171/250, Loss: 0.0127\n",
      "Epoch 46/200, Iteration 172/250, Loss: 0.0132\n",
      "Epoch 46/200, Iteration 173/250, Loss: 0.0171\n",
      "Epoch 46/200, Iteration 174/250, Loss: 0.0121\n",
      "Epoch 46/200, Iteration 175/250, Loss: 0.0165\n",
      "Epoch 46/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 46/200, Iteration 177/250, Loss: 0.0167\n",
      "Epoch 46/200, Iteration 178/250, Loss: 0.0106\n",
      "Epoch 46/200, Iteration 179/250, Loss: 0.0205\n",
      "Epoch 46/200, Iteration 180/250, Loss: 0.0085\n",
      "Epoch 46/200, Iteration 181/250, Loss: 0.0139\n",
      "Epoch 46/200, Iteration 182/250, Loss: 0.0213\n",
      "Epoch 46/200, Iteration 183/250, Loss: 0.0140\n",
      "Epoch 46/200, Iteration 184/250, Loss: 0.0091\n",
      "Epoch 46/200, Iteration 185/250, Loss: 0.0149\n",
      "Epoch 46/200, Iteration 186/250, Loss: 0.0199\n",
      "Epoch 46/200, Iteration 187/250, Loss: 0.0148\n",
      "Epoch 46/200, Iteration 188/250, Loss: 0.0116\n",
      "Epoch 46/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 46/200, Iteration 190/250, Loss: 0.0146\n",
      "Epoch 46/200, Iteration 191/250, Loss: 0.0144\n",
      "Epoch 46/200, Iteration 192/250, Loss: 0.0101\n",
      "Epoch 46/200, Iteration 193/250, Loss: 0.0392\n",
      "Epoch 46/200, Iteration 194/250, Loss: 0.0086\n",
      "Epoch 46/200, Iteration 195/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 196/250, Loss: 0.0096\n",
      "Epoch 46/200, Iteration 197/250, Loss: 0.0313\n",
      "Epoch 46/200, Iteration 198/250, Loss: 0.0168\n",
      "Epoch 46/200, Iteration 199/250, Loss: 0.0275\n",
      "Epoch 46/200, Iteration 200/250, Loss: 0.0152\n",
      "Epoch 46/200, Iteration 201/250, Loss: 0.0093\n",
      "Epoch 46/200, Iteration 202/250, Loss: 0.0154\n",
      "Epoch 46/200, Iteration 203/250, Loss: 0.0209\n",
      "Epoch 46/200, Iteration 204/250, Loss: 0.0338\n",
      "Epoch 46/200, Iteration 205/250, Loss: 0.0091\n",
      "Epoch 46/200, Iteration 206/250, Loss: 0.0083\n",
      "Epoch 46/200, Iteration 207/250, Loss: 0.0074\n",
      "Epoch 46/200, Iteration 208/250, Loss: 0.0504\n",
      "Epoch 46/200, Iteration 209/250, Loss: 0.0250\n",
      "Epoch 46/200, Iteration 210/250, Loss: 0.0112\n",
      "Epoch 46/200, Iteration 211/250, Loss: 0.0097\n",
      "Epoch 46/200, Iteration 212/250, Loss: 0.0122\n",
      "Epoch 46/200, Iteration 213/250, Loss: 0.0145\n",
      "Epoch 46/200, Iteration 214/250, Loss: 0.0182\n",
      "Epoch 46/200, Iteration 215/250, Loss: 0.0184\n",
      "Epoch 46/200, Iteration 216/250, Loss: 0.0093\n",
      "Epoch 46/200, Iteration 217/250, Loss: 0.0103\n",
      "Epoch 46/200, Iteration 218/250, Loss: 0.0160\n",
      "Epoch 46/200, Iteration 219/250, Loss: 0.0136\n",
      "Epoch 46/200, Iteration 220/250, Loss: 0.0286\n",
      "Epoch 46/200, Iteration 221/250, Loss: 0.0214\n",
      "Epoch 46/200, Iteration 222/250, Loss: 0.0164\n",
      "Epoch 46/200, Iteration 223/250, Loss: 0.0123\n",
      "Epoch 46/200, Iteration 224/250, Loss: 0.0137\n",
      "Epoch 46/200, Iteration 225/250, Loss: 0.0155\n",
      "Epoch 46/200, Iteration 226/250, Loss: 0.0270\n",
      "Epoch 46/200, Iteration 227/250, Loss: 0.0208\n",
      "Epoch 46/200, Iteration 228/250, Loss: 0.0213\n",
      "Epoch 46/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 46/200, Iteration 230/250, Loss: 0.0153\n",
      "Epoch 46/200, Iteration 231/250, Loss: 0.0163\n",
      "Epoch 46/200, Iteration 232/250, Loss: 0.0113\n",
      "Epoch 46/200, Iteration 233/250, Loss: 0.0143\n",
      "Epoch 46/200, Iteration 234/250, Loss: 0.0116\n",
      "Epoch 46/200, Iteration 235/250, Loss: 0.0175\n",
      "Epoch 46/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 46/200, Iteration 237/250, Loss: 0.0090\n",
      "Epoch 46/200, Iteration 238/250, Loss: 0.0109\n",
      "Epoch 46/200, Iteration 239/250, Loss: 0.0101\n",
      "Epoch 46/200, Iteration 240/250, Loss: 0.0280\n",
      "Epoch 46/200, Iteration 241/250, Loss: 0.0182\n",
      "Epoch 46/200, Iteration 242/250, Loss: 0.0250\n",
      "Epoch 46/200, Iteration 243/250, Loss: 0.0128\n",
      "Epoch 46/200, Iteration 244/250, Loss: 0.0244\n",
      "Epoch 46/200, Iteration 245/250, Loss: 0.0226\n",
      "Epoch 46/200, Iteration 246/250, Loss: 0.0104\n",
      "Epoch 46/200, Iteration 247/250, Loss: 0.0293\n",
      "Epoch 46/200, Iteration 248/250, Loss: 0.0088\n",
      "Epoch 46/200, Iteration 249/250, Loss: 0.0218\n",
      "Epoch 46/200, Iteration 250/250, Loss: 0.0212\n",
      "Train Error: \n",
      " Accuracy: 80.64%, Avg loss: 0.009827, MRE: 0.749505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.15%, Avg loss: 0.010307, MRE: 1.129053 \n",
      "\n",
      "Epoch 47/200, Iteration 1/250, Loss: 0.0121\n",
      "Epoch 47/200, Iteration 2/250, Loss: 0.0270\n",
      "Epoch 47/200, Iteration 3/250, Loss: 0.0272\n",
      "Epoch 47/200, Iteration 4/250, Loss: 0.0166\n",
      "Epoch 47/200, Iteration 5/250, Loss: 0.0255\n",
      "Epoch 47/200, Iteration 6/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 7/250, Loss: 0.0093\n",
      "Epoch 47/200, Iteration 8/250, Loss: 0.0188\n",
      "Epoch 47/200, Iteration 9/250, Loss: 0.0357\n",
      "Epoch 47/200, Iteration 10/250, Loss: 0.0330\n",
      "Epoch 47/200, Iteration 11/250, Loss: 0.0268\n",
      "Epoch 47/200, Iteration 12/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 13/250, Loss: 0.0099\n",
      "Epoch 47/200, Iteration 14/250, Loss: 0.0096\n",
      "Epoch 47/200, Iteration 15/250, Loss: 0.0169\n",
      "Epoch 47/200, Iteration 16/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 17/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 18/250, Loss: 0.0145\n",
      "Epoch 47/200, Iteration 19/250, Loss: 0.0139\n",
      "Epoch 47/200, Iteration 20/250, Loss: 0.0116\n",
      "Epoch 47/200, Iteration 21/250, Loss: 0.0254\n",
      "Epoch 47/200, Iteration 22/250, Loss: 0.0155\n",
      "Epoch 47/200, Iteration 23/250, Loss: 0.0188\n",
      "Epoch 47/200, Iteration 24/250, Loss: 0.0145\n",
      "Epoch 47/200, Iteration 25/250, Loss: 0.0131\n",
      "Epoch 47/200, Iteration 26/250, Loss: 0.0147\n",
      "Epoch 47/200, Iteration 27/250, Loss: 0.0231\n",
      "Epoch 47/200, Iteration 28/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 29/250, Loss: 0.0273\n",
      "Epoch 47/200, Iteration 30/250, Loss: 0.0191\n",
      "Epoch 47/200, Iteration 31/250, Loss: 0.0110\n",
      "Epoch 47/200, Iteration 32/250, Loss: 0.0137\n",
      "Epoch 47/200, Iteration 33/250, Loss: 0.0148\n",
      "Epoch 47/200, Iteration 34/250, Loss: 0.0178\n",
      "Epoch 47/200, Iteration 35/250, Loss: 0.0138\n",
      "Epoch 47/200, Iteration 36/250, Loss: 0.0179\n",
      "Epoch 47/200, Iteration 37/250, Loss: 0.0108\n",
      "Epoch 47/200, Iteration 38/250, Loss: 0.0194\n",
      "Epoch 47/200, Iteration 39/250, Loss: 0.0261\n",
      "Epoch 47/200, Iteration 40/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 41/250, Loss: 0.0119\n",
      "Epoch 47/200, Iteration 42/250, Loss: 0.0175\n",
      "Epoch 47/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 47/200, Iteration 44/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 45/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 46/250, Loss: 0.0087\n",
      "Epoch 47/200, Iteration 47/250, Loss: 0.0247\n",
      "Epoch 47/200, Iteration 48/250, Loss: 0.0100\n",
      "Epoch 47/200, Iteration 49/250, Loss: 0.0183\n",
      "Epoch 47/200, Iteration 50/250, Loss: 0.0196\n",
      "Epoch 47/200, Iteration 51/250, Loss: 0.0080\n",
      "Epoch 47/200, Iteration 52/250, Loss: 0.0191\n",
      "Epoch 47/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 47/200, Iteration 54/250, Loss: 0.0220\n",
      "Epoch 47/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 47/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 47/200, Iteration 57/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 58/250, Loss: 0.0085\n",
      "Epoch 47/200, Iteration 59/250, Loss: 0.0257\n",
      "Epoch 47/200, Iteration 60/250, Loss: 0.0246\n",
      "Epoch 47/200, Iteration 61/250, Loss: 0.0378\n",
      "Epoch 47/200, Iteration 62/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 63/250, Loss: 0.0084\n",
      "Epoch 47/200, Iteration 64/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 65/250, Loss: 0.0096\n",
      "Epoch 47/200, Iteration 66/250, Loss: 0.0182\n",
      "Epoch 47/200, Iteration 67/250, Loss: 0.0114\n",
      "Epoch 47/200, Iteration 68/250, Loss: 0.0151\n",
      "Epoch 47/200, Iteration 69/250, Loss: 0.0094\n",
      "Epoch 47/200, Iteration 70/250, Loss: 0.0290\n",
      "Epoch 47/200, Iteration 71/250, Loss: 0.0164\n",
      "Epoch 47/200, Iteration 72/250, Loss: 0.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Iteration 73/250, Loss: 0.0252\n",
      "Epoch 47/200, Iteration 74/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 75/250, Loss: 0.0095\n",
      "Epoch 47/200, Iteration 76/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 47/200, Iteration 78/250, Loss: 0.0213\n",
      "Epoch 47/200, Iteration 79/250, Loss: 0.0098\n",
      "Epoch 47/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 81/250, Loss: 0.0120\n",
      "Epoch 47/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 47/200, Iteration 83/250, Loss: 0.0127\n",
      "Epoch 47/200, Iteration 84/250, Loss: 0.0109\n",
      "Epoch 47/200, Iteration 85/250, Loss: 0.0200\n",
      "Epoch 47/200, Iteration 86/250, Loss: 0.0095\n",
      "Epoch 47/200, Iteration 87/250, Loss: 0.0322\n",
      "Epoch 47/200, Iteration 88/250, Loss: 0.0114\n",
      "Epoch 47/200, Iteration 89/250, Loss: 0.0096\n",
      "Epoch 47/200, Iteration 90/250, Loss: 0.0126\n",
      "Epoch 47/200, Iteration 91/250, Loss: 0.0102\n",
      "Epoch 47/200, Iteration 92/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 93/250, Loss: 0.0264\n",
      "Epoch 47/200, Iteration 94/250, Loss: 0.0098\n",
      "Epoch 47/200, Iteration 95/250, Loss: 0.0175\n",
      "Epoch 47/200, Iteration 96/250, Loss: 0.0124\n",
      "Epoch 47/200, Iteration 97/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 98/250, Loss: 0.0196\n",
      "Epoch 47/200, Iteration 99/250, Loss: 0.0116\n",
      "Epoch 47/200, Iteration 100/250, Loss: 0.0210\n",
      "Epoch 47/200, Iteration 101/250, Loss: 0.0290\n",
      "Epoch 47/200, Iteration 102/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 103/250, Loss: 0.0198\n",
      "Epoch 47/200, Iteration 104/250, Loss: 0.0151\n",
      "Epoch 47/200, Iteration 105/250, Loss: 0.0256\n",
      "Epoch 47/200, Iteration 106/250, Loss: 0.0412\n",
      "Epoch 47/200, Iteration 107/250, Loss: 0.0072\n",
      "Epoch 47/200, Iteration 108/250, Loss: 0.0105\n",
      "Epoch 47/200, Iteration 109/250, Loss: 0.0118\n",
      "Epoch 47/200, Iteration 110/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 111/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 112/250, Loss: 0.0264\n",
      "Epoch 47/200, Iteration 113/250, Loss: 0.0089\n",
      "Epoch 47/200, Iteration 114/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 115/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 116/250, Loss: 0.0118\n",
      "Epoch 47/200, Iteration 117/250, Loss: 0.0213\n",
      "Epoch 47/200, Iteration 118/250, Loss: 0.0144\n",
      "Epoch 47/200, Iteration 119/250, Loss: 0.0175\n",
      "Epoch 47/200, Iteration 120/250, Loss: 0.0088\n",
      "Epoch 47/200, Iteration 121/250, Loss: 0.0197\n",
      "Epoch 47/200, Iteration 122/250, Loss: 0.0245\n",
      "Epoch 47/200, Iteration 123/250, Loss: 0.0202\n",
      "Epoch 47/200, Iteration 124/250, Loss: 0.0144\n",
      "Epoch 47/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 126/250, Loss: 0.0205\n",
      "Epoch 47/200, Iteration 127/250, Loss: 0.0137\n",
      "Epoch 47/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 47/200, Iteration 129/250, Loss: 0.0162\n",
      "Epoch 47/200, Iteration 130/250, Loss: 0.0149\n",
      "Epoch 47/200, Iteration 131/250, Loss: 0.0364\n",
      "Epoch 47/200, Iteration 132/250, Loss: 0.0162\n",
      "Epoch 47/200, Iteration 133/250, Loss: 0.0127\n",
      "Epoch 47/200, Iteration 134/250, Loss: 0.0213\n",
      "Epoch 47/200, Iteration 135/250, Loss: 0.0330\n",
      "Epoch 47/200, Iteration 136/250, Loss: 0.0138\n",
      "Epoch 47/200, Iteration 137/250, Loss: 0.0177\n",
      "Epoch 47/200, Iteration 138/250, Loss: 0.0104\n",
      "Epoch 47/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 47/200, Iteration 140/250, Loss: 0.0101\n",
      "Epoch 47/200, Iteration 141/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 142/250, Loss: 0.0148\n",
      "Epoch 47/200, Iteration 143/250, Loss: 0.0478\n",
      "Epoch 47/200, Iteration 144/250, Loss: 0.0196\n",
      "Epoch 47/200, Iteration 145/250, Loss: 0.0203\n",
      "Epoch 47/200, Iteration 146/250, Loss: 0.0143\n",
      "Epoch 47/200, Iteration 147/250, Loss: 0.0169\n",
      "Epoch 47/200, Iteration 148/250, Loss: 0.0185\n",
      "Epoch 47/200, Iteration 149/250, Loss: 0.0117\n",
      "Epoch 47/200, Iteration 150/250, Loss: 0.0101\n",
      "Epoch 47/200, Iteration 151/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 152/250, Loss: 0.0085\n",
      "Epoch 47/200, Iteration 153/250, Loss: 0.0131\n",
      "Epoch 47/200, Iteration 154/250, Loss: 0.0138\n",
      "Epoch 47/200, Iteration 155/250, Loss: 0.0136\n",
      "Epoch 47/200, Iteration 156/250, Loss: 0.0148\n",
      "Epoch 47/200, Iteration 157/250, Loss: 0.0157\n",
      "Epoch 47/200, Iteration 158/250, Loss: 0.0170\n",
      "Epoch 47/200, Iteration 159/250, Loss: 0.0340\n",
      "Epoch 47/200, Iteration 160/250, Loss: 0.0090\n",
      "Epoch 47/200, Iteration 161/250, Loss: 0.0101\n",
      "Epoch 47/200, Iteration 162/250, Loss: 0.0105\n",
      "Epoch 47/200, Iteration 163/250, Loss: 0.0105\n",
      "Epoch 47/200, Iteration 164/250, Loss: 0.0172\n",
      "Epoch 47/200, Iteration 165/250, Loss: 0.0380\n",
      "Epoch 47/200, Iteration 166/250, Loss: 0.0245\n",
      "Epoch 47/200, Iteration 167/250, Loss: 0.0241\n",
      "Epoch 47/200, Iteration 168/250, Loss: 0.0182\n",
      "Epoch 47/200, Iteration 169/250, Loss: 0.0223\n",
      "Epoch 47/200, Iteration 170/250, Loss: 0.0113\n",
      "Epoch 47/200, Iteration 171/250, Loss: 0.0191\n",
      "Epoch 47/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 47/200, Iteration 173/250, Loss: 0.0235\n",
      "Epoch 47/200, Iteration 174/250, Loss: 0.0234\n",
      "Epoch 47/200, Iteration 175/250, Loss: 0.0283\n",
      "Epoch 47/200, Iteration 176/250, Loss: 0.0134\n",
      "Epoch 47/200, Iteration 177/250, Loss: 0.0103\n",
      "Epoch 47/200, Iteration 178/250, Loss: 0.0096\n",
      "Epoch 47/200, Iteration 179/250, Loss: 0.0117\n",
      "Epoch 47/200, Iteration 180/250, Loss: 0.0192\n",
      "Epoch 47/200, Iteration 181/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 182/250, Loss: 0.0246\n",
      "Epoch 47/200, Iteration 183/250, Loss: 0.0077\n",
      "Epoch 47/200, Iteration 184/250, Loss: 0.0204\n",
      "Epoch 47/200, Iteration 185/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 186/250, Loss: 0.0113\n",
      "Epoch 47/200, Iteration 187/250, Loss: 0.0126\n",
      "Epoch 47/200, Iteration 188/250, Loss: 0.0140\n",
      "Epoch 47/200, Iteration 189/250, Loss: 0.0190\n",
      "Epoch 47/200, Iteration 190/250, Loss: 0.0108\n",
      "Epoch 47/200, Iteration 191/250, Loss: 0.0166\n",
      "Epoch 47/200, Iteration 192/250, Loss: 0.0100\n",
      "Epoch 47/200, Iteration 193/250, Loss: 0.0134\n",
      "Epoch 47/200, Iteration 194/250, Loss: 0.0121\n",
      "Epoch 47/200, Iteration 195/250, Loss: 0.0071\n",
      "Epoch 47/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 47/200, Iteration 197/250, Loss: 0.0195\n",
      "Epoch 47/200, Iteration 198/250, Loss: 0.0122\n",
      "Epoch 47/200, Iteration 199/250, Loss: 0.0128\n",
      "Epoch 47/200, Iteration 200/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 201/250, Loss: 0.0229\n",
      "Epoch 47/200, Iteration 202/250, Loss: 0.0196\n",
      "Epoch 47/200, Iteration 203/250, Loss: 0.0101\n",
      "Epoch 47/200, Iteration 204/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 205/250, Loss: 0.0243\n",
      "Epoch 47/200, Iteration 206/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 207/250, Loss: 0.0151\n",
      "Epoch 47/200, Iteration 208/250, Loss: 0.0274\n",
      "Epoch 47/200, Iteration 209/250, Loss: 0.0130\n",
      "Epoch 47/200, Iteration 210/250, Loss: 0.0329\n",
      "Epoch 47/200, Iteration 211/250, Loss: 0.0359\n",
      "Epoch 47/200, Iteration 212/250, Loss: 0.0205\n",
      "Epoch 47/200, Iteration 213/250, Loss: 0.0221\n",
      "Epoch 47/200, Iteration 214/250, Loss: 0.0238\n",
      "Epoch 47/200, Iteration 215/250, Loss: 0.0167\n",
      "Epoch 47/200, Iteration 216/250, Loss: 0.0186\n",
      "Epoch 47/200, Iteration 217/250, Loss: 0.0166\n",
      "Epoch 47/200, Iteration 218/250, Loss: 0.0080\n",
      "Epoch 47/200, Iteration 219/250, Loss: 0.0092\n",
      "Epoch 47/200, Iteration 220/250, Loss: 0.0268\n",
      "Epoch 47/200, Iteration 221/250, Loss: 0.0114\n",
      "Epoch 47/200, Iteration 222/250, Loss: 0.0109\n",
      "Epoch 47/200, Iteration 223/250, Loss: 0.0293\n",
      "Epoch 47/200, Iteration 224/250, Loss: 0.0324\n",
      "Epoch 47/200, Iteration 225/250, Loss: 0.0148\n",
      "Epoch 47/200, Iteration 226/250, Loss: 0.0125\n",
      "Epoch 47/200, Iteration 227/250, Loss: 0.0147\n",
      "Epoch 47/200, Iteration 228/250, Loss: 0.0377\n",
      "Epoch 47/200, Iteration 229/250, Loss: 0.0123\n",
      "Epoch 47/200, Iteration 230/250, Loss: 0.0107\n",
      "Epoch 47/200, Iteration 231/250, Loss: 0.0166\n",
      "Epoch 47/200, Iteration 232/250, Loss: 0.0290\n",
      "Epoch 47/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 47/200, Iteration 234/250, Loss: 0.0162\n",
      "Epoch 47/200, Iteration 235/250, Loss: 0.0180\n",
      "Epoch 47/200, Iteration 236/250, Loss: 0.0147\n",
      "Epoch 47/200, Iteration 237/250, Loss: 0.0135\n",
      "Epoch 47/200, Iteration 238/250, Loss: 0.0132\n",
      "Epoch 47/200, Iteration 239/250, Loss: 0.0163\n",
      "Epoch 47/200, Iteration 240/250, Loss: 0.0151\n",
      "Epoch 47/200, Iteration 241/250, Loss: 0.0088\n",
      "Epoch 47/200, Iteration 242/250, Loss: 0.0140\n",
      "Epoch 47/200, Iteration 243/250, Loss: 0.0119\n",
      "Epoch 47/200, Iteration 244/250, Loss: 0.0171\n",
      "Epoch 47/200, Iteration 245/250, Loss: 0.0118\n",
      "Epoch 47/200, Iteration 246/250, Loss: 0.0112\n",
      "Epoch 47/200, Iteration 247/250, Loss: 0.0104\n",
      "Epoch 47/200, Iteration 248/250, Loss: 0.0106\n",
      "Epoch 47/200, Iteration 249/250, Loss: 0.0250\n",
      "Epoch 47/200, Iteration 250/250, Loss: 0.0178\n",
      "Train Error: \n",
      " Accuracy: 82.34%, Avg loss: 0.008928, MRE: 0.554459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.009214, MRE: 0.769137 \n",
      "\n",
      "Epoch 48/200, Iteration 1/250, Loss: 0.0076\n",
      "Epoch 48/200, Iteration 2/250, Loss: 0.0292\n",
      "Epoch 48/200, Iteration 3/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 4/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 5/250, Loss: 0.0247\n",
      "Epoch 48/200, Iteration 6/250, Loss: 0.0120\n",
      "Epoch 48/200, Iteration 7/250, Loss: 0.0110\n",
      "Epoch 48/200, Iteration 8/250, Loss: 0.0478\n",
      "Epoch 48/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 48/200, Iteration 10/250, Loss: 0.0335\n",
      "Epoch 48/200, Iteration 11/250, Loss: 0.0119\n",
      "Epoch 48/200, Iteration 12/250, Loss: 0.0260\n",
      "Epoch 48/200, Iteration 13/250, Loss: 0.0231\n",
      "Epoch 48/200, Iteration 14/250, Loss: 0.0157\n",
      "Epoch 48/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 48/200, Iteration 16/250, Loss: 0.0100\n",
      "Epoch 48/200, Iteration 17/250, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Iteration 18/250, Loss: 0.0178\n",
      "Epoch 48/200, Iteration 19/250, Loss: 0.0084\n",
      "Epoch 48/200, Iteration 20/250, Loss: 0.0182\n",
      "Epoch 48/200, Iteration 21/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 22/250, Loss: 0.0085\n",
      "Epoch 48/200, Iteration 23/250, Loss: 0.0093\n",
      "Epoch 48/200, Iteration 24/250, Loss: 0.0102\n",
      "Epoch 48/200, Iteration 25/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 48/200, Iteration 27/250, Loss: 0.0157\n",
      "Epoch 48/200, Iteration 28/250, Loss: 0.0256\n",
      "Epoch 48/200, Iteration 29/250, Loss: 0.0281\n",
      "Epoch 48/200, Iteration 30/250, Loss: 0.0086\n",
      "Epoch 48/200, Iteration 31/250, Loss: 0.0331\n",
      "Epoch 48/200, Iteration 32/250, Loss: 0.0120\n",
      "Epoch 48/200, Iteration 33/250, Loss: 0.0373\n",
      "Epoch 48/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 35/250, Loss: 0.0072\n",
      "Epoch 48/200, Iteration 36/250, Loss: 0.0219\n",
      "Epoch 48/200, Iteration 37/250, Loss: 0.0182\n",
      "Epoch 48/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 48/200, Iteration 39/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 40/250, Loss: 0.0161\n",
      "Epoch 48/200, Iteration 41/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 42/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 43/250, Loss: 0.0203\n",
      "Epoch 48/200, Iteration 44/250, Loss: 0.0118\n",
      "Epoch 48/200, Iteration 45/250, Loss: 0.0113\n",
      "Epoch 48/200, Iteration 46/250, Loss: 0.0243\n",
      "Epoch 48/200, Iteration 47/250, Loss: 0.0139\n",
      "Epoch 48/200, Iteration 48/250, Loss: 0.0129\n",
      "Epoch 48/200, Iteration 49/250, Loss: 0.0158\n",
      "Epoch 48/200, Iteration 50/250, Loss: 0.0231\n",
      "Epoch 48/200, Iteration 51/250, Loss: 0.0193\n",
      "Epoch 48/200, Iteration 52/250, Loss: 0.0091\n",
      "Epoch 48/200, Iteration 53/250, Loss: 0.0193\n",
      "Epoch 48/200, Iteration 54/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 55/250, Loss: 0.0225\n",
      "Epoch 48/200, Iteration 56/250, Loss: 0.0114\n",
      "Epoch 48/200, Iteration 57/250, Loss: 0.0157\n",
      "Epoch 48/200, Iteration 58/250, Loss: 0.0089\n",
      "Epoch 48/200, Iteration 59/250, Loss: 0.0083\n",
      "Epoch 48/200, Iteration 60/250, Loss: 0.0128\n",
      "Epoch 48/200, Iteration 61/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 62/250, Loss: 0.0201\n",
      "Epoch 48/200, Iteration 63/250, Loss: 0.0118\n",
      "Epoch 48/200, Iteration 64/250, Loss: 0.0308\n",
      "Epoch 48/200, Iteration 65/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 66/250, Loss: 0.0130\n",
      "Epoch 48/200, Iteration 67/250, Loss: 0.0144\n",
      "Epoch 48/200, Iteration 68/250, Loss: 0.0353\n",
      "Epoch 48/200, Iteration 69/250, Loss: 0.0345\n",
      "Epoch 48/200, Iteration 70/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 71/250, Loss: 0.0208\n",
      "Epoch 48/200, Iteration 72/250, Loss: 0.0258\n",
      "Epoch 48/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 74/250, Loss: 0.0116\n",
      "Epoch 48/200, Iteration 75/250, Loss: 0.0142\n",
      "Epoch 48/200, Iteration 76/250, Loss: 0.0301\n",
      "Epoch 48/200, Iteration 77/250, Loss: 0.0096\n",
      "Epoch 48/200, Iteration 78/250, Loss: 0.0179\n",
      "Epoch 48/200, Iteration 79/250, Loss: 0.0125\n",
      "Epoch 48/200, Iteration 80/250, Loss: 0.0121\n",
      "Epoch 48/200, Iteration 81/250, Loss: 0.0115\n",
      "Epoch 48/200, Iteration 82/250, Loss: 0.0152\n",
      "Epoch 48/200, Iteration 83/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 48/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 48/200, Iteration 86/250, Loss: 0.0089\n",
      "Epoch 48/200, Iteration 87/250, Loss: 0.0262\n",
      "Epoch 48/200, Iteration 88/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 90/250, Loss: 0.0067\n",
      "Epoch 48/200, Iteration 91/250, Loss: 0.0173\n",
      "Epoch 48/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 48/200, Iteration 93/250, Loss: 0.0150\n",
      "Epoch 48/200, Iteration 94/250, Loss: 0.0097\n",
      "Epoch 48/200, Iteration 95/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 96/250, Loss: 0.0178\n",
      "Epoch 48/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 48/200, Iteration 98/250, Loss: 0.0262\n",
      "Epoch 48/200, Iteration 99/250, Loss: 0.0138\n",
      "Epoch 48/200, Iteration 100/250, Loss: 0.0277\n",
      "Epoch 48/200, Iteration 101/250, Loss: 0.0070\n",
      "Epoch 48/200, Iteration 102/250, Loss: 0.0269\n",
      "Epoch 48/200, Iteration 103/250, Loss: 0.0147\n",
      "Epoch 48/200, Iteration 104/250, Loss: 0.0238\n",
      "Epoch 48/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 48/200, Iteration 106/250, Loss: 0.0221\n",
      "Epoch 48/200, Iteration 107/250, Loss: 0.0111\n",
      "Epoch 48/200, Iteration 108/250, Loss: 0.0201\n",
      "Epoch 48/200, Iteration 109/250, Loss: 0.0142\n",
      "Epoch 48/200, Iteration 110/250, Loss: 0.0181\n",
      "Epoch 48/200, Iteration 111/250, Loss: 0.0135\n",
      "Epoch 48/200, Iteration 112/250, Loss: 0.0201\n",
      "Epoch 48/200, Iteration 113/250, Loss: 0.0144\n",
      "Epoch 48/200, Iteration 114/250, Loss: 0.0098\n",
      "Epoch 48/200, Iteration 115/250, Loss: 0.0190\n",
      "Epoch 48/200, Iteration 116/250, Loss: 0.0481\n",
      "Epoch 48/200, Iteration 117/250, Loss: 0.0204\n",
      "Epoch 48/200, Iteration 118/250, Loss: 0.0176\n",
      "Epoch 48/200, Iteration 119/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 120/250, Loss: 0.0160\n",
      "Epoch 48/200, Iteration 121/250, Loss: 0.0272\n",
      "Epoch 48/200, Iteration 122/250, Loss: 0.0196\n",
      "Epoch 48/200, Iteration 123/250, Loss: 0.0139\n",
      "Epoch 48/200, Iteration 124/250, Loss: 0.0254\n",
      "Epoch 48/200, Iteration 125/250, Loss: 0.0239\n",
      "Epoch 48/200, Iteration 126/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 127/250, Loss: 0.0196\n",
      "Epoch 48/200, Iteration 128/250, Loss: 0.0221\n",
      "Epoch 48/200, Iteration 129/250, Loss: 0.0134\n",
      "Epoch 48/200, Iteration 130/250, Loss: 0.0139\n",
      "Epoch 48/200, Iteration 131/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 132/250, Loss: 0.0146\n",
      "Epoch 48/200, Iteration 133/250, Loss: 0.0123\n",
      "Epoch 48/200, Iteration 134/250, Loss: 0.0128\n",
      "Epoch 48/200, Iteration 135/250, Loss: 0.0234\n",
      "Epoch 48/200, Iteration 136/250, Loss: 0.0091\n",
      "Epoch 48/200, Iteration 137/250, Loss: 0.0172\n",
      "Epoch 48/200, Iteration 138/250, Loss: 0.0136\n",
      "Epoch 48/200, Iteration 139/250, Loss: 0.0146\n",
      "Epoch 48/200, Iteration 140/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 141/250, Loss: 0.0133\n",
      "Epoch 48/200, Iteration 142/250, Loss: 0.0147\n",
      "Epoch 48/200, Iteration 143/250, Loss: 0.0165\n",
      "Epoch 48/200, Iteration 144/250, Loss: 0.0144\n",
      "Epoch 48/200, Iteration 145/250, Loss: 0.0174\n",
      "Epoch 48/200, Iteration 146/250, Loss: 0.0097\n",
      "Epoch 48/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 48/200, Iteration 148/250, Loss: 0.0134\n",
      "Epoch 48/200, Iteration 149/250, Loss: 0.0156\n",
      "Epoch 48/200, Iteration 150/250, Loss: 0.0104\n",
      "Epoch 48/200, Iteration 151/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 152/250, Loss: 0.0133\n",
      "Epoch 48/200, Iteration 153/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 154/250, Loss: 0.0108\n",
      "Epoch 48/200, Iteration 155/250, Loss: 0.0084\n",
      "Epoch 48/200, Iteration 156/250, Loss: 0.0329\n",
      "Epoch 48/200, Iteration 157/250, Loss: 0.0285\n",
      "Epoch 48/200, Iteration 158/250, Loss: 0.0173\n",
      "Epoch 48/200, Iteration 159/250, Loss: 0.0133\n",
      "Epoch 48/200, Iteration 160/250, Loss: 0.0181\n",
      "Epoch 48/200, Iteration 161/250, Loss: 0.0340\n",
      "Epoch 48/200, Iteration 162/250, Loss: 0.0147\n",
      "Epoch 48/200, Iteration 163/250, Loss: 0.0113\n",
      "Epoch 48/200, Iteration 164/250, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 165/250, Loss: 0.0368\n",
      "Epoch 48/200, Iteration 166/250, Loss: 0.0087\n",
      "Epoch 48/200, Iteration 167/250, Loss: 0.0106\n",
      "Epoch 48/200, Iteration 168/250, Loss: 0.0109\n",
      "Epoch 48/200, Iteration 169/250, Loss: 0.0212\n",
      "Epoch 48/200, Iteration 170/250, Loss: 0.0143\n",
      "Epoch 48/200, Iteration 171/250, Loss: 0.0146\n",
      "Epoch 48/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 48/200, Iteration 173/250, Loss: 0.0352\n",
      "Epoch 48/200, Iteration 174/250, Loss: 0.0160\n",
      "Epoch 48/200, Iteration 175/250, Loss: 0.0272\n",
      "Epoch 48/200, Iteration 176/250, Loss: 0.0133\n",
      "Epoch 48/200, Iteration 177/250, Loss: 0.0116\n",
      "Epoch 48/200, Iteration 178/250, Loss: 0.0163\n",
      "Epoch 48/200, Iteration 179/250, Loss: 0.0467\n",
      "Epoch 48/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 48/200, Iteration 181/250, Loss: 0.0214\n",
      "Epoch 48/200, Iteration 182/250, Loss: 0.0176\n",
      "Epoch 48/200, Iteration 183/250, Loss: 0.0212\n",
      "Epoch 48/200, Iteration 184/250, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 185/250, Loss: 0.0381\n",
      "Epoch 48/200, Iteration 186/250, Loss: 0.0101\n",
      "Epoch 48/200, Iteration 187/250, Loss: 0.0140\n",
      "Epoch 48/200, Iteration 188/250, Loss: 0.0179\n",
      "Epoch 48/200, Iteration 189/250, Loss: 0.0150\n",
      "Epoch 48/200, Iteration 190/250, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 48/200, Iteration 192/250, Loss: 0.0383\n",
      "Epoch 48/200, Iteration 193/250, Loss: 0.0192\n",
      "Epoch 48/200, Iteration 194/250, Loss: 0.0236\n",
      "Epoch 48/200, Iteration 195/250, Loss: 0.0131\n",
      "Epoch 48/200, Iteration 196/250, Loss: 0.0116\n",
      "Epoch 48/200, Iteration 197/250, Loss: 0.0177\n",
      "Epoch 48/200, Iteration 198/250, Loss: 0.0159\n",
      "Epoch 48/200, Iteration 199/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 200/250, Loss: 0.0228\n",
      "Epoch 48/200, Iteration 201/250, Loss: 0.0206\n",
      "Epoch 48/200, Iteration 202/250, Loss: 0.0112\n",
      "Epoch 48/200, Iteration 203/250, Loss: 0.0151\n",
      "Epoch 48/200, Iteration 204/250, Loss: 0.0118\n",
      "Epoch 48/200, Iteration 205/250, Loss: 0.0201\n",
      "Epoch 48/200, Iteration 206/250, Loss: 0.0279\n",
      "Epoch 48/200, Iteration 207/250, Loss: 0.0235\n",
      "Epoch 48/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 48/200, Iteration 209/250, Loss: 0.0238\n",
      "Epoch 48/200, Iteration 210/250, Loss: 0.0254\n",
      "Epoch 48/200, Iteration 211/250, Loss: 0.0150\n",
      "Epoch 48/200, Iteration 212/250, Loss: 0.0115\n",
      "Epoch 48/200, Iteration 213/250, Loss: 0.0078\n",
      "Epoch 48/200, Iteration 214/250, Loss: 0.0115\n",
      "Epoch 48/200, Iteration 215/250, Loss: 0.0092\n",
      "Epoch 48/200, Iteration 216/250, Loss: 0.0091\n",
      "Epoch 48/200, Iteration 217/250, Loss: 0.0127\n",
      "Epoch 48/200, Iteration 218/250, Loss: 0.0086\n",
      "Epoch 48/200, Iteration 219/250, Loss: 0.0129\n",
      "Epoch 48/200, Iteration 220/250, Loss: 0.0137\n",
      "Epoch 48/200, Iteration 221/250, Loss: 0.0147\n",
      "Epoch 48/200, Iteration 222/250, Loss: 0.0165\n",
      "Epoch 48/200, Iteration 223/250, Loss: 0.0128\n",
      "Epoch 48/200, Iteration 224/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Iteration 225/250, Loss: 0.0106\n",
      "Epoch 48/200, Iteration 226/250, Loss: 0.0205\n",
      "Epoch 48/200, Iteration 227/250, Loss: 0.0247\n",
      "Epoch 48/200, Iteration 228/250, Loss: 0.0377\n",
      "Epoch 48/200, Iteration 229/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 230/250, Loss: 0.0213\n",
      "Epoch 48/200, Iteration 231/250, Loss: 0.0215\n",
      "Epoch 48/200, Iteration 232/250, Loss: 0.0449\n",
      "Epoch 48/200, Iteration 233/250, Loss: 0.0166\n",
      "Epoch 48/200, Iteration 234/250, Loss: 0.0258\n",
      "Epoch 48/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 48/200, Iteration 236/250, Loss: 0.0164\n",
      "Epoch 48/200, Iteration 237/250, Loss: 0.0100\n",
      "Epoch 48/200, Iteration 238/250, Loss: 0.0233\n",
      "Epoch 48/200, Iteration 239/250, Loss: 0.0102\n",
      "Epoch 48/200, Iteration 240/250, Loss: 0.0196\n",
      "Epoch 48/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 48/200, Iteration 242/250, Loss: 0.0270\n",
      "Epoch 48/200, Iteration 243/250, Loss: 0.0214\n",
      "Epoch 48/200, Iteration 244/250, Loss: 0.0153\n",
      "Epoch 48/200, Iteration 245/250, Loss: 0.0397\n",
      "Epoch 48/200, Iteration 246/250, Loss: 0.0136\n",
      "Epoch 48/200, Iteration 247/250, Loss: 0.0342\n",
      "Epoch 48/200, Iteration 248/250, Loss: 0.0131\n",
      "Epoch 48/200, Iteration 249/250, Loss: 0.0188\n",
      "Epoch 48/200, Iteration 250/250, Loss: 0.0164\n",
      "Train Error: \n",
      " Accuracy: 84.24%, Avg loss: 0.008811, MRE: 0.584574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.009439, MRE: 0.638470 \n",
      "\n",
      "Epoch 49/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 49/200, Iteration 2/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 3/250, Loss: 0.0181\n",
      "Epoch 49/200, Iteration 4/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 5/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 6/250, Loss: 0.0209\n",
      "Epoch 49/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 49/200, Iteration 8/250, Loss: 0.0124\n",
      "Epoch 49/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 49/200, Iteration 11/250, Loss: 0.0151\n",
      "Epoch 49/200, Iteration 12/250, Loss: 0.0112\n",
      "Epoch 49/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 14/250, Loss: 0.0097\n",
      "Epoch 49/200, Iteration 15/250, Loss: 0.0086\n",
      "Epoch 49/200, Iteration 16/250, Loss: 0.0143\n",
      "Epoch 49/200, Iteration 17/250, Loss: 0.0101\n",
      "Epoch 49/200, Iteration 18/250, Loss: 0.0252\n",
      "Epoch 49/200, Iteration 19/250, Loss: 0.0177\n",
      "Epoch 49/200, Iteration 20/250, Loss: 0.0118\n",
      "Epoch 49/200, Iteration 21/250, Loss: 0.0086\n",
      "Epoch 49/200, Iteration 22/250, Loss: 0.0113\n",
      "Epoch 49/200, Iteration 23/250, Loss: 0.0124\n",
      "Epoch 49/200, Iteration 24/250, Loss: 0.0092\n",
      "Epoch 49/200, Iteration 25/250, Loss: 0.0366\n",
      "Epoch 49/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 27/250, Loss: 0.0117\n",
      "Epoch 49/200, Iteration 28/250, Loss: 0.0325\n",
      "Epoch 49/200, Iteration 29/250, Loss: 0.0104\n",
      "Epoch 49/200, Iteration 30/250, Loss: 0.0122\n",
      "Epoch 49/200, Iteration 31/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 32/250, Loss: 0.0303\n",
      "Epoch 49/200, Iteration 33/250, Loss: 0.0106\n",
      "Epoch 49/200, Iteration 34/250, Loss: 0.0170\n",
      "Epoch 49/200, Iteration 35/250, Loss: 0.0080\n",
      "Epoch 49/200, Iteration 36/250, Loss: 0.0297\n",
      "Epoch 49/200, Iteration 37/250, Loss: 0.0150\n",
      "Epoch 49/200, Iteration 38/250, Loss: 0.0203\n",
      "Epoch 49/200, Iteration 39/250, Loss: 0.0253\n",
      "Epoch 49/200, Iteration 40/250, Loss: 0.0122\n",
      "Epoch 49/200, Iteration 41/250, Loss: 0.0098\n",
      "Epoch 49/200, Iteration 42/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 43/250, Loss: 0.0246\n",
      "Epoch 49/200, Iteration 44/250, Loss: 0.0153\n",
      "Epoch 49/200, Iteration 45/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 46/250, Loss: 0.0295\n",
      "Epoch 49/200, Iteration 47/250, Loss: 0.0085\n",
      "Epoch 49/200, Iteration 48/250, Loss: 0.0109\n",
      "Epoch 49/200, Iteration 49/250, Loss: 0.0104\n",
      "Epoch 49/200, Iteration 50/250, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 51/250, Loss: 0.0237\n",
      "Epoch 49/200, Iteration 52/250, Loss: 0.0103\n",
      "Epoch 49/200, Iteration 53/250, Loss: 0.0220\n",
      "Epoch 49/200, Iteration 54/250, Loss: 0.0101\n",
      "Epoch 49/200, Iteration 55/250, Loss: 0.0152\n",
      "Epoch 49/200, Iteration 56/250, Loss: 0.0122\n",
      "Epoch 49/200, Iteration 57/250, Loss: 0.0246\n",
      "Epoch 49/200, Iteration 58/250, Loss: 0.0196\n",
      "Epoch 49/200, Iteration 59/250, Loss: 0.0182\n",
      "Epoch 49/200, Iteration 60/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 61/250, Loss: 0.0195\n",
      "Epoch 49/200, Iteration 62/250, Loss: 0.0164\n",
      "Epoch 49/200, Iteration 63/250, Loss: 0.0270\n",
      "Epoch 49/200, Iteration 64/250, Loss: 0.0094\n",
      "Epoch 49/200, Iteration 65/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 66/250, Loss: 0.0104\n",
      "Epoch 49/200, Iteration 67/250, Loss: 0.0309\n",
      "Epoch 49/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 49/200, Iteration 69/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 70/250, Loss: 0.0153\n",
      "Epoch 49/200, Iteration 71/250, Loss: 0.0328\n",
      "Epoch 49/200, Iteration 72/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 73/250, Loss: 0.0224\n",
      "Epoch 49/200, Iteration 74/250, Loss: 0.0177\n",
      "Epoch 49/200, Iteration 75/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 76/250, Loss: 0.0142\n",
      "Epoch 49/200, Iteration 77/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 78/250, Loss: 0.0220\n",
      "Epoch 49/200, Iteration 79/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 80/250, Loss: 0.0118\n",
      "Epoch 49/200, Iteration 81/250, Loss: 0.0144\n",
      "Epoch 49/200, Iteration 82/250, Loss: 0.0156\n",
      "Epoch 49/200, Iteration 83/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 84/250, Loss: 0.0235\n",
      "Epoch 49/200, Iteration 85/250, Loss: 0.0073\n",
      "Epoch 49/200, Iteration 86/250, Loss: 0.0101\n",
      "Epoch 49/200, Iteration 87/250, Loss: 0.0118\n",
      "Epoch 49/200, Iteration 88/250, Loss: 0.0095\n",
      "Epoch 49/200, Iteration 89/250, Loss: 0.0260\n",
      "Epoch 49/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 49/200, Iteration 91/250, Loss: 0.0171\n",
      "Epoch 49/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 93/250, Loss: 0.0409\n",
      "Epoch 49/200, Iteration 94/250, Loss: 0.0192\n",
      "Epoch 49/200, Iteration 95/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 96/250, Loss: 0.0154\n",
      "Epoch 49/200, Iteration 97/250, Loss: 0.0205\n",
      "Epoch 49/200, Iteration 98/250, Loss: 0.0129\n",
      "Epoch 49/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 49/200, Iteration 100/250, Loss: 0.0199\n",
      "Epoch 49/200, Iteration 101/250, Loss: 0.0230\n",
      "Epoch 49/200, Iteration 102/250, Loss: 0.0262\n",
      "Epoch 49/200, Iteration 103/250, Loss: 0.0271\n",
      "Epoch 49/200, Iteration 104/250, Loss: 0.0115\n",
      "Epoch 49/200, Iteration 105/250, Loss: 0.0205\n",
      "Epoch 49/200, Iteration 106/250, Loss: 0.0196\n",
      "Epoch 49/200, Iteration 107/250, Loss: 0.0251\n",
      "Epoch 49/200, Iteration 108/250, Loss: 0.0121\n",
      "Epoch 49/200, Iteration 109/250, Loss: 0.0187\n",
      "Epoch 49/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 49/200, Iteration 111/250, Loss: 0.0310\n",
      "Epoch 49/200, Iteration 112/250, Loss: 0.0158\n",
      "Epoch 49/200, Iteration 113/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 114/250, Loss: 0.0178\n",
      "Epoch 49/200, Iteration 115/250, Loss: 0.0239\n",
      "Epoch 49/200, Iteration 116/250, Loss: 0.0154\n",
      "Epoch 49/200, Iteration 117/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 118/250, Loss: 0.0099\n",
      "Epoch 49/200, Iteration 119/250, Loss: 0.0141\n",
      "Epoch 49/200, Iteration 120/250, Loss: 0.0101\n",
      "Epoch 49/200, Iteration 121/250, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 122/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 123/250, Loss: 0.0218\n",
      "Epoch 49/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 125/250, Loss: 0.0204\n",
      "Epoch 49/200, Iteration 126/250, Loss: 0.0193\n",
      "Epoch 49/200, Iteration 127/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 128/250, Loss: 0.0208\n",
      "Epoch 49/200, Iteration 129/250, Loss: 0.0090\n",
      "Epoch 49/200, Iteration 130/250, Loss: 0.0305\n",
      "Epoch 49/200, Iteration 131/250, Loss: 0.0173\n",
      "Epoch 49/200, Iteration 132/250, Loss: 0.0369\n",
      "Epoch 49/200, Iteration 133/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 134/250, Loss: 0.0169\n",
      "Epoch 49/200, Iteration 135/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 49/200, Iteration 137/250, Loss: 0.0120\n",
      "Epoch 49/200, Iteration 138/250, Loss: 0.0077\n",
      "Epoch 49/200, Iteration 139/250, Loss: 0.0192\n",
      "Epoch 49/200, Iteration 140/250, Loss: 0.0386\n",
      "Epoch 49/200, Iteration 141/250, Loss: 0.0086\n",
      "Epoch 49/200, Iteration 142/250, Loss: 0.0313\n",
      "Epoch 49/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 49/200, Iteration 144/250, Loss: 0.0105\n",
      "Epoch 49/200, Iteration 145/250, Loss: 0.0133\n",
      "Epoch 49/200, Iteration 146/250, Loss: 0.0121\n",
      "Epoch 49/200, Iteration 147/250, Loss: 0.0269\n",
      "Epoch 49/200, Iteration 148/250, Loss: 0.0205\n",
      "Epoch 49/200, Iteration 149/250, Loss: 0.0111\n",
      "Epoch 49/200, Iteration 150/250, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 151/250, Loss: 0.0140\n",
      "Epoch 49/200, Iteration 152/250, Loss: 0.0099\n",
      "Epoch 49/200, Iteration 153/250, Loss: 0.0440\n",
      "Epoch 49/200, Iteration 154/250, Loss: 0.0193\n",
      "Epoch 49/200, Iteration 155/250, Loss: 0.0160\n",
      "Epoch 49/200, Iteration 156/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Iteration 157/250, Loss: 0.0242\n",
      "Epoch 49/200, Iteration 158/250, Loss: 0.0113\n",
      "Epoch 49/200, Iteration 159/250, Loss: 0.0207\n",
      "Epoch 49/200, Iteration 160/250, Loss: 0.0203\n",
      "Epoch 49/200, Iteration 161/250, Loss: 0.0127\n",
      "Epoch 49/200, Iteration 162/250, Loss: 0.0225\n",
      "Epoch 49/200, Iteration 163/250, Loss: 0.0097\n",
      "Epoch 49/200, Iteration 164/250, Loss: 0.0149\n",
      "Epoch 49/200, Iteration 165/250, Loss: 0.0189\n",
      "Epoch 49/200, Iteration 166/250, Loss: 0.0110\n",
      "Epoch 49/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 49/200, Iteration 168/250, Loss: 0.0099\n",
      "Epoch 49/200, Iteration 169/250, Loss: 0.0141\n",
      "Epoch 49/200, Iteration 170/250, Loss: 0.0133\n",
      "Epoch 49/200, Iteration 171/250, Loss: 0.0204\n",
      "Epoch 49/200, Iteration 172/250, Loss: 0.0220\n",
      "Epoch 49/200, Iteration 173/250, Loss: 0.0121\n",
      "Epoch 49/200, Iteration 174/250, Loss: 0.0098\n",
      "Epoch 49/200, Iteration 175/250, Loss: 0.0310\n",
      "Epoch 49/200, Iteration 176/250, Loss: 0.0192\n",
      "Epoch 49/200, Iteration 177/250, Loss: 0.0234\n",
      "Epoch 49/200, Iteration 178/250, Loss: 0.0163\n",
      "Epoch 49/200, Iteration 179/250, Loss: 0.0116\n",
      "Epoch 49/200, Iteration 180/250, Loss: 0.0164\n",
      "Epoch 49/200, Iteration 181/250, Loss: 0.0114\n",
      "Epoch 49/200, Iteration 182/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 183/250, Loss: 0.0139\n",
      "Epoch 49/200, Iteration 184/250, Loss: 0.0386\n",
      "Epoch 49/200, Iteration 185/250, Loss: 0.0265\n",
      "Epoch 49/200, Iteration 186/250, Loss: 0.0278\n",
      "Epoch 49/200, Iteration 187/250, Loss: 0.0381\n",
      "Epoch 49/200, Iteration 188/250, Loss: 0.0071\n",
      "Epoch 49/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 190/250, Loss: 0.0148\n",
      "Epoch 49/200, Iteration 191/250, Loss: 0.0090\n",
      "Epoch 49/200, Iteration 192/250, Loss: 0.0166\n",
      "Epoch 49/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 49/200, Iteration 194/250, Loss: 0.0269\n",
      "Epoch 49/200, Iteration 195/250, Loss: 0.0134\n",
      "Epoch 49/200, Iteration 196/250, Loss: 0.0230\n",
      "Epoch 49/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 49/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 49/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 49/200, Iteration 200/250, Loss: 0.0070\n",
      "Epoch 49/200, Iteration 201/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 202/250, Loss: 0.0138\n",
      "Epoch 49/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 49/200, Iteration 204/250, Loss: 0.0140\n",
      "Epoch 49/200, Iteration 205/250, Loss: 0.0146\n",
      "Epoch 49/200, Iteration 206/250, Loss: 0.0090\n",
      "Epoch 49/200, Iteration 207/250, Loss: 0.0104\n",
      "Epoch 49/200, Iteration 208/250, Loss: 0.0245\n",
      "Epoch 49/200, Iteration 209/250, Loss: 0.0159\n",
      "Epoch 49/200, Iteration 210/250, Loss: 0.0102\n",
      "Epoch 49/200, Iteration 211/250, Loss: 0.0146\n",
      "Epoch 49/200, Iteration 212/250, Loss: 0.0126\n",
      "Epoch 49/200, Iteration 213/250, Loss: 0.0171\n",
      "Epoch 49/200, Iteration 214/250, Loss: 0.0272\n",
      "Epoch 49/200, Iteration 215/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 216/250, Loss: 0.0237\n",
      "Epoch 49/200, Iteration 217/250, Loss: 0.0131\n",
      "Epoch 49/200, Iteration 218/250, Loss: 0.0300\n",
      "Epoch 49/200, Iteration 219/250, Loss: 0.0175\n",
      "Epoch 49/200, Iteration 220/250, Loss: 0.0209\n",
      "Epoch 49/200, Iteration 221/250, Loss: 0.0137\n",
      "Epoch 49/200, Iteration 222/250, Loss: 0.0162\n",
      "Epoch 49/200, Iteration 223/250, Loss: 0.0127\n",
      "Epoch 49/200, Iteration 224/250, Loss: 0.0186\n",
      "Epoch 49/200, Iteration 225/250, Loss: 0.0167\n",
      "Epoch 49/200, Iteration 226/250, Loss: 0.0175\n",
      "Epoch 49/200, Iteration 227/250, Loss: 0.0094\n",
      "Epoch 49/200, Iteration 228/250, Loss: 0.0373\n",
      "Epoch 49/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 49/200, Iteration 230/250, Loss: 0.0215\n",
      "Epoch 49/200, Iteration 231/250, Loss: 0.0381\n",
      "Epoch 49/200, Iteration 232/250, Loss: 0.0151\n",
      "Epoch 49/200, Iteration 233/250, Loss: 0.0255\n",
      "Epoch 49/200, Iteration 234/250, Loss: 0.0166\n",
      "Epoch 49/200, Iteration 235/250, Loss: 0.0147\n",
      "Epoch 49/200, Iteration 236/250, Loss: 0.0236\n",
      "Epoch 49/200, Iteration 237/250, Loss: 0.0100\n",
      "Epoch 49/200, Iteration 238/250, Loss: 0.0149\n",
      "Epoch 49/200, Iteration 239/250, Loss: 0.0146\n",
      "Epoch 49/200, Iteration 240/250, Loss: 0.0150\n",
      "Epoch 49/200, Iteration 241/250, Loss: 0.0123\n",
      "Epoch 49/200, Iteration 242/250, Loss: 0.0262\n",
      "Epoch 49/200, Iteration 243/250, Loss: 0.0089\n",
      "Epoch 49/200, Iteration 244/250, Loss: 0.0279\n",
      "Epoch 49/200, Iteration 245/250, Loss: 0.0140\n",
      "Epoch 49/200, Iteration 246/250, Loss: 0.0108\n",
      "Epoch 49/200, Iteration 247/250, Loss: 0.0124\n",
      "Epoch 49/200, Iteration 248/250, Loss: 0.0271\n",
      "Epoch 49/200, Iteration 249/250, Loss: 0.0166\n",
      "Epoch 49/200, Iteration 250/250, Loss: 0.0181\n",
      "Train Error: \n",
      " Accuracy: 82.91%, Avg loss: 0.009895, MRE: 0.695463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.010520, MRE: 0.718922 \n",
      "\n",
      "Epoch 50/200, Iteration 1/250, Loss: 0.0192\n",
      "Epoch 50/200, Iteration 2/250, Loss: 0.0123\n",
      "Epoch 50/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 4/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 5/250, Loss: 0.0139\n",
      "Epoch 50/200, Iteration 6/250, Loss: 0.0139\n",
      "Epoch 50/200, Iteration 7/250, Loss: 0.0149\n",
      "Epoch 50/200, Iteration 8/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 9/250, Loss: 0.0118\n",
      "Epoch 50/200, Iteration 10/250, Loss: 0.0384\n",
      "Epoch 50/200, Iteration 11/250, Loss: 0.0127\n",
      "Epoch 50/200, Iteration 12/250, Loss: 0.0244\n",
      "Epoch 50/200, Iteration 13/250, Loss: 0.0076\n",
      "Epoch 50/200, Iteration 14/250, Loss: 0.0184\n",
      "Epoch 50/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 50/200, Iteration 16/250, Loss: 0.0117\n",
      "Epoch 50/200, Iteration 17/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 18/250, Loss: 0.0161\n",
      "Epoch 50/200, Iteration 19/250, Loss: 0.0389\n",
      "Epoch 50/200, Iteration 20/250, Loss: 0.0379\n",
      "Epoch 50/200, Iteration 21/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 22/250, Loss: 0.0177\n",
      "Epoch 50/200, Iteration 23/250, Loss: 0.0141\n",
      "Epoch 50/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 50/200, Iteration 25/250, Loss: 0.0138\n",
      "Epoch 50/200, Iteration 26/250, Loss: 0.0328\n",
      "Epoch 50/200, Iteration 27/250, Loss: 0.0114\n",
      "Epoch 50/200, Iteration 28/250, Loss: 0.0317\n",
      "Epoch 50/200, Iteration 29/250, Loss: 0.0188\n",
      "Epoch 50/200, Iteration 30/250, Loss: 0.0082\n",
      "Epoch 50/200, Iteration 31/250, Loss: 0.0127\n",
      "Epoch 50/200, Iteration 32/250, Loss: 0.0132\n",
      "Epoch 50/200, Iteration 33/250, Loss: 0.0185\n",
      "Epoch 50/200, Iteration 34/250, Loss: 0.0182\n",
      "Epoch 50/200, Iteration 35/250, Loss: 0.0169\n",
      "Epoch 50/200, Iteration 36/250, Loss: 0.0201\n",
      "Epoch 50/200, Iteration 37/250, Loss: 0.0234\n",
      "Epoch 50/200, Iteration 38/250, Loss: 0.0131\n",
      "Epoch 50/200, Iteration 39/250, Loss: 0.0205\n",
      "Epoch 50/200, Iteration 40/250, Loss: 0.0244\n",
      "Epoch 50/200, Iteration 41/250, Loss: 0.0074\n",
      "Epoch 50/200, Iteration 42/250, Loss: 0.0200\n",
      "Epoch 50/200, Iteration 43/250, Loss: 0.0134\n",
      "Epoch 50/200, Iteration 44/250, Loss: 0.0229\n",
      "Epoch 50/200, Iteration 45/250, Loss: 0.0221\n",
      "Epoch 50/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 50/200, Iteration 47/250, Loss: 0.0161\n",
      "Epoch 50/200, Iteration 48/250, Loss: 0.0085\n",
      "Epoch 50/200, Iteration 49/250, Loss: 0.0277\n",
      "Epoch 50/200, Iteration 50/250, Loss: 0.0204\n",
      "Epoch 50/200, Iteration 51/250, Loss: 0.0177\n",
      "Epoch 50/200, Iteration 52/250, Loss: 0.0103\n",
      "Epoch 50/200, Iteration 53/250, Loss: 0.0275\n",
      "Epoch 50/200, Iteration 54/250, Loss: 0.0078\n",
      "Epoch 50/200, Iteration 55/250, Loss: 0.0256\n",
      "Epoch 50/200, Iteration 56/250, Loss: 0.0151\n",
      "Epoch 50/200, Iteration 57/250, Loss: 0.0217\n",
      "Epoch 50/200, Iteration 58/250, Loss: 0.0322\n",
      "Epoch 50/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 50/200, Iteration 60/250, Loss: 0.0125\n",
      "Epoch 50/200, Iteration 61/250, Loss: 0.0139\n",
      "Epoch 50/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 50/200, Iteration 63/250, Loss: 0.0139\n",
      "Epoch 50/200, Iteration 64/250, Loss: 0.0129\n",
      "Epoch 50/200, Iteration 65/250, Loss: 0.0106\n",
      "Epoch 50/200, Iteration 66/250, Loss: 0.0112\n",
      "Epoch 50/200, Iteration 67/250, Loss: 0.0168\n",
      "Epoch 50/200, Iteration 68/250, Loss: 0.0231\n",
      "Epoch 50/200, Iteration 69/250, Loss: 0.0187\n",
      "Epoch 50/200, Iteration 70/250, Loss: 0.0155\n",
      "Epoch 50/200, Iteration 71/250, Loss: 0.0178\n",
      "Epoch 50/200, Iteration 72/250, Loss: 0.0355\n",
      "Epoch 50/200, Iteration 73/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 74/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 75/250, Loss: 0.0217\n",
      "Epoch 50/200, Iteration 76/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 77/250, Loss: 0.0166\n",
      "Epoch 50/200, Iteration 78/250, Loss: 0.0146\n",
      "Epoch 50/200, Iteration 79/250, Loss: 0.0202\n",
      "Epoch 50/200, Iteration 80/250, Loss: 0.0174\n",
      "Epoch 50/200, Iteration 81/250, Loss: 0.0185\n",
      "Epoch 50/200, Iteration 82/250, Loss: 0.0116\n",
      "Epoch 50/200, Iteration 83/250, Loss: 0.0236\n",
      "Epoch 50/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 50/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 50/200, Iteration 86/250, Loss: 0.0144\n",
      "Epoch 50/200, Iteration 87/250, Loss: 0.0209\n",
      "Epoch 50/200, Iteration 88/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 89/250, Loss: 0.0087\n",
      "Epoch 50/200, Iteration 90/250, Loss: 0.0211\n",
      "Epoch 50/200, Iteration 91/250, Loss: 0.0102\n",
      "Epoch 50/200, Iteration 92/250, Loss: 0.0162\n",
      "Epoch 50/200, Iteration 93/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 94/250, Loss: 0.0102\n",
      "Epoch 50/200, Iteration 95/250, Loss: 0.0179\n",
      "Epoch 50/200, Iteration 96/250, Loss: 0.0184\n",
      "Epoch 50/200, Iteration 97/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 98/250, Loss: 0.0193\n",
      "Epoch 50/200, Iteration 99/250, Loss: 0.0191\n",
      "Epoch 50/200, Iteration 100/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 101/250, Loss: 0.0146\n",
      "Epoch 50/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 103/250, Loss: 0.0103\n",
      "Epoch 50/200, Iteration 104/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 50/200, Iteration 106/250, Loss: 0.0075\n",
      "Epoch 50/200, Iteration 107/250, Loss: 0.0109\n",
      "Epoch 50/200, Iteration 108/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 109/250, Loss: 0.0116\n",
      "Epoch 50/200, Iteration 110/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 111/250, Loss: 0.0237\n",
      "Epoch 50/200, Iteration 112/250, Loss: 0.0133\n",
      "Epoch 50/200, Iteration 113/250, Loss: 0.0120\n",
      "Epoch 50/200, Iteration 114/250, Loss: 0.0293\n",
      "Epoch 50/200, Iteration 115/250, Loss: 0.0131\n",
      "Epoch 50/200, Iteration 116/250, Loss: 0.0251\n",
      "Epoch 50/200, Iteration 117/250, Loss: 0.0168\n",
      "Epoch 50/200, Iteration 118/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 119/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 120/250, Loss: 0.0097\n",
      "Epoch 50/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 50/200, Iteration 122/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 123/250, Loss: 0.0217\n",
      "Epoch 50/200, Iteration 124/250, Loss: 0.0116\n",
      "Epoch 50/200, Iteration 125/250, Loss: 0.0181\n",
      "Epoch 50/200, Iteration 126/250, Loss: 0.0273\n",
      "Epoch 50/200, Iteration 127/250, Loss: 0.0316\n",
      "Epoch 50/200, Iteration 128/250, Loss: 0.0159\n",
      "Epoch 50/200, Iteration 129/250, Loss: 0.0289\n",
      "Epoch 50/200, Iteration 130/250, Loss: 0.0191\n",
      "Epoch 50/200, Iteration 131/250, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 50/200, Iteration 133/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 134/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 135/250, Loss: 0.0090\n",
      "Epoch 50/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 137/250, Loss: 0.0184\n",
      "Epoch 50/200, Iteration 138/250, Loss: 0.0155\n",
      "Epoch 50/200, Iteration 139/250, Loss: 0.0176\n",
      "Epoch 50/200, Iteration 140/250, Loss: 0.0124\n",
      "Epoch 50/200, Iteration 141/250, Loss: 0.0158\n",
      "Epoch 50/200, Iteration 142/250, Loss: 0.0133\n",
      "Epoch 50/200, Iteration 143/250, Loss: 0.0163\n",
      "Epoch 50/200, Iteration 144/250, Loss: 0.0147\n",
      "Epoch 50/200, Iteration 145/250, Loss: 0.0086\n",
      "Epoch 50/200, Iteration 146/250, Loss: 0.0103\n",
      "Epoch 50/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 50/200, Iteration 148/250, Loss: 0.0127\n",
      "Epoch 50/200, Iteration 149/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 150/250, Loss: 0.0235\n",
      "Epoch 50/200, Iteration 151/250, Loss: 0.0235\n",
      "Epoch 50/200, Iteration 152/250, Loss: 0.0298\n",
      "Epoch 50/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 50/200, Iteration 154/250, Loss: 0.0131\n",
      "Epoch 50/200, Iteration 155/250, Loss: 0.0173\n",
      "Epoch 50/200, Iteration 156/250, Loss: 0.0097\n",
      "Epoch 50/200, Iteration 157/250, Loss: 0.0165\n",
      "Epoch 50/200, Iteration 158/250, Loss: 0.0109\n",
      "Epoch 50/200, Iteration 159/250, Loss: 0.0144\n",
      "Epoch 50/200, Iteration 160/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 161/250, Loss: 0.0331\n",
      "Epoch 50/200, Iteration 162/250, Loss: 0.0088\n",
      "Epoch 50/200, Iteration 163/250, Loss: 0.0079\n",
      "Epoch 50/200, Iteration 164/250, Loss: 0.0189\n",
      "Epoch 50/200, Iteration 165/250, Loss: 0.0101\n",
      "Epoch 50/200, Iteration 166/250, Loss: 0.0188\n",
      "Epoch 50/200, Iteration 167/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 168/250, Loss: 0.0202\n",
      "Epoch 50/200, Iteration 169/250, Loss: 0.0296\n",
      "Epoch 50/200, Iteration 170/250, Loss: 0.0194\n",
      "Epoch 50/200, Iteration 171/250, Loss: 0.0121\n",
      "Epoch 50/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 50/200, Iteration 174/250, Loss: 0.0122\n",
      "Epoch 50/200, Iteration 175/250, Loss: 0.0111\n",
      "Epoch 50/200, Iteration 176/250, Loss: 0.0138\n",
      "Epoch 50/200, Iteration 177/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 178/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 179/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 180/250, Loss: 0.0130\n",
      "Epoch 50/200, Iteration 181/250, Loss: 0.0186\n",
      "Epoch 50/200, Iteration 182/250, Loss: 0.0100\n",
      "Epoch 50/200, Iteration 183/250, Loss: 0.0161\n",
      "Epoch 50/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 50/200, Iteration 185/250, Loss: 0.0161\n",
      "Epoch 50/200, Iteration 186/250, Loss: 0.0071\n",
      "Epoch 50/200, Iteration 187/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 188/250, Loss: 0.0313\n",
      "Epoch 50/200, Iteration 189/250, Loss: 0.0091\n",
      "Epoch 50/200, Iteration 190/250, Loss: 0.0119\n",
      "Epoch 50/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 192/250, Loss: 0.0332\n",
      "Epoch 50/200, Iteration 193/250, Loss: 0.0123\n",
      "Epoch 50/200, Iteration 194/250, Loss: 0.0188\n",
      "Epoch 50/200, Iteration 195/250, Loss: 0.0173\n",
      "Epoch 50/200, Iteration 196/250, Loss: 0.0121\n",
      "Epoch 50/200, Iteration 197/250, Loss: 0.0092\n",
      "Epoch 50/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 50/200, Iteration 199/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 200/250, Loss: 0.0090\n",
      "Epoch 50/200, Iteration 201/250, Loss: 0.0194\n",
      "Epoch 50/200, Iteration 202/250, Loss: 0.0167\n",
      "Epoch 50/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 50/200, Iteration 204/250, Loss: 0.0277\n",
      "Epoch 50/200, Iteration 205/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 206/250, Loss: 0.0111\n",
      "Epoch 50/200, Iteration 207/250, Loss: 0.0145\n",
      "Epoch 50/200, Iteration 208/250, Loss: 0.0193\n",
      "Epoch 50/200, Iteration 209/250, Loss: 0.0218\n",
      "Epoch 50/200, Iteration 210/250, Loss: 0.0153\n",
      "Epoch 50/200, Iteration 211/250, Loss: 0.0105\n",
      "Epoch 50/200, Iteration 212/250, Loss: 0.0112\n",
      "Epoch 50/200, Iteration 213/250, Loss: 0.0132\n",
      "Epoch 50/200, Iteration 214/250, Loss: 0.0295\n",
      "Epoch 50/200, Iteration 215/250, Loss: 0.0097\n",
      "Epoch 50/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 50/200, Iteration 217/250, Loss: 0.0115\n",
      "Epoch 50/200, Iteration 218/250, Loss: 0.0281\n",
      "Epoch 50/200, Iteration 219/250, Loss: 0.0121\n",
      "Epoch 50/200, Iteration 220/250, Loss: 0.0150\n",
      "Epoch 50/200, Iteration 221/250, Loss: 0.0117\n",
      "Epoch 50/200, Iteration 222/250, Loss: 0.0110\n",
      "Epoch 50/200, Iteration 223/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 224/250, Loss: 0.0181\n",
      "Epoch 50/200, Iteration 225/250, Loss: 0.0148\n",
      "Epoch 50/200, Iteration 226/250, Loss: 0.0306\n",
      "Epoch 50/200, Iteration 227/250, Loss: 0.0293\n",
      "Epoch 50/200, Iteration 228/250, Loss: 0.0113\n",
      "Epoch 50/200, Iteration 229/250, Loss: 0.0279\n",
      "Epoch 50/200, Iteration 230/250, Loss: 0.0085\n",
      "Epoch 50/200, Iteration 231/250, Loss: 0.0163\n",
      "Epoch 50/200, Iteration 232/250, Loss: 0.0130\n",
      "Epoch 50/200, Iteration 233/250, Loss: 0.0082\n",
      "Epoch 50/200, Iteration 234/250, Loss: 0.0135\n",
      "Epoch 50/200, Iteration 235/250, Loss: 0.0137\n",
      "Epoch 50/200, Iteration 236/250, Loss: 0.0104\n",
      "Epoch 50/200, Iteration 237/250, Loss: 0.0261\n",
      "Epoch 50/200, Iteration 238/250, Loss: 0.0153\n",
      "Epoch 50/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 50/200, Iteration 240/250, Loss: 0.0130\n",
      "Epoch 50/200, Iteration 241/250, Loss: 0.0125\n",
      "Epoch 50/200, Iteration 242/250, Loss: 0.0163\n",
      "Epoch 50/200, Iteration 243/250, Loss: 0.0136\n",
      "Epoch 50/200, Iteration 244/250, Loss: 0.0096\n",
      "Epoch 50/200, Iteration 245/250, Loss: 0.0154\n",
      "Epoch 50/200, Iteration 246/250, Loss: 0.0140\n",
      "Epoch 50/200, Iteration 247/250, Loss: 0.0142\n",
      "Epoch 50/200, Iteration 248/250, Loss: 0.0183\n",
      "Epoch 50/200, Iteration 249/250, Loss: 0.0082\n",
      "Epoch 50/200, Iteration 250/250, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 83.53%, Avg loss: 0.007524, MRE: 0.494533 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.35%, Avg loss: 0.007852, MRE: 0.543505 \n",
      "\n",
      "Epoch 51/200, Iteration 1/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 2/250, Loss: 0.0125\n",
      "Epoch 51/200, Iteration 3/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 4/250, Loss: 0.0120\n",
      "Epoch 51/200, Iteration 5/250, Loss: 0.0077\n",
      "Epoch 51/200, Iteration 6/250, Loss: 0.0262\n",
      "Epoch 51/200, Iteration 7/250, Loss: 0.0234\n",
      "Epoch 51/200, Iteration 8/250, Loss: 0.0175\n",
      "Epoch 51/200, Iteration 9/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 10/250, Loss: 0.0176\n",
      "Epoch 51/200, Iteration 11/250, Loss: 0.0173\n",
      "Epoch 51/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 51/200, Iteration 13/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 14/250, Loss: 0.0243\n",
      "Epoch 51/200, Iteration 15/250, Loss: 0.0269\n",
      "Epoch 51/200, Iteration 16/250, Loss: 0.0146\n",
      "Epoch 51/200, Iteration 17/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 18/250, Loss: 0.0097\n",
      "Epoch 51/200, Iteration 19/250, Loss: 0.0191\n",
      "Epoch 51/200, Iteration 20/250, Loss: 0.0161\n",
      "Epoch 51/200, Iteration 21/250, Loss: 0.0161\n",
      "Epoch 51/200, Iteration 22/250, Loss: 0.0073\n",
      "Epoch 51/200, Iteration 23/250, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 24/250, Loss: 0.0125\n",
      "Epoch 51/200, Iteration 25/250, Loss: 0.0160\n",
      "Epoch 51/200, Iteration 26/250, Loss: 0.0276\n",
      "Epoch 51/200, Iteration 27/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 28/250, Loss: 0.0213\n",
      "Epoch 51/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 51/200, Iteration 30/250, Loss: 0.0105\n",
      "Epoch 51/200, Iteration 31/250, Loss: 0.0156\n",
      "Epoch 51/200, Iteration 32/250, Loss: 0.0129\n",
      "Epoch 51/200, Iteration 33/250, Loss: 0.0228\n",
      "Epoch 51/200, Iteration 34/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 35/250, Loss: 0.0275\n",
      "Epoch 51/200, Iteration 36/250, Loss: 0.0303\n",
      "Epoch 51/200, Iteration 37/250, Loss: 0.0191\n",
      "Epoch 51/200, Iteration 38/250, Loss: 0.0365\n",
      "Epoch 51/200, Iteration 39/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 40/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 41/250, Loss: 0.0150\n",
      "Epoch 51/200, Iteration 42/250, Loss: 0.0079\n",
      "Epoch 51/200, Iteration 43/250, Loss: 0.0173\n",
      "Epoch 51/200, Iteration 44/250, Loss: 0.0098\n",
      "Epoch 51/200, Iteration 45/250, Loss: 0.0271\n",
      "Epoch 51/200, Iteration 46/250, Loss: 0.0117\n",
      "Epoch 51/200, Iteration 47/250, Loss: 0.0542\n",
      "Epoch 51/200, Iteration 48/250, Loss: 0.0181\n",
      "Epoch 51/200, Iteration 49/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 50/250, Loss: 0.0102\n",
      "Epoch 51/200, Iteration 51/250, Loss: 0.0077\n",
      "Epoch 51/200, Iteration 52/250, Loss: 0.0082\n",
      "Epoch 51/200, Iteration 53/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 54/250, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 55/250, Loss: 0.0224\n",
      "Epoch 51/200, Iteration 56/250, Loss: 0.0179\n",
      "Epoch 51/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 51/200, Iteration 58/250, Loss: 0.0205\n",
      "Epoch 51/200, Iteration 59/250, Loss: 0.0316\n",
      "Epoch 51/200, Iteration 60/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 61/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 63/250, Loss: 0.0252\n",
      "Epoch 51/200, Iteration 64/250, Loss: 0.0090\n",
      "Epoch 51/200, Iteration 65/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 66/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 67/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 68/250, Loss: 0.0417\n",
      "Epoch 51/200, Iteration 69/250, Loss: 0.0221\n",
      "Epoch 51/200, Iteration 70/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 71/250, Loss: 0.0130\n",
      "Epoch 51/200, Iteration 72/250, Loss: 0.0302\n",
      "Epoch 51/200, Iteration 73/250, Loss: 0.0207\n",
      "Epoch 51/200, Iteration 74/250, Loss: 0.0284\n",
      "Epoch 51/200, Iteration 75/250, Loss: 0.0094\n",
      "Epoch 51/200, Iteration 76/250, Loss: 0.0114\n",
      "Epoch 51/200, Iteration 77/250, Loss: 0.0110\n",
      "Epoch 51/200, Iteration 78/250, Loss: 0.0186\n",
      "Epoch 51/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 80/250, Loss: 0.0116\n",
      "Epoch 51/200, Iteration 81/250, Loss: 0.0197\n",
      "Epoch 51/200, Iteration 82/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 83/250, Loss: 0.0143\n",
      "Epoch 51/200, Iteration 84/250, Loss: 0.0075\n",
      "Epoch 51/200, Iteration 85/250, Loss: 0.0169\n",
      "Epoch 51/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 87/250, Loss: 0.0186\n",
      "Epoch 51/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 51/200, Iteration 89/250, Loss: 0.0173\n",
      "Epoch 51/200, Iteration 90/250, Loss: 0.0083\n",
      "Epoch 51/200, Iteration 91/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 92/250, Loss: 0.0169\n",
      "Epoch 51/200, Iteration 93/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 51/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 96/250, Loss: 0.0207\n",
      "Epoch 51/200, Iteration 97/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 98/250, Loss: 0.0163\n",
      "Epoch 51/200, Iteration 99/250, Loss: 0.0237\n",
      "Epoch 51/200, Iteration 100/250, Loss: 0.0426\n",
      "Epoch 51/200, Iteration 101/250, Loss: 0.0153\n",
      "Epoch 51/200, Iteration 102/250, Loss: 0.0293\n",
      "Epoch 51/200, Iteration 103/250, Loss: 0.0122\n",
      "Epoch 51/200, Iteration 104/250, Loss: 0.0188\n",
      "Epoch 51/200, Iteration 105/250, Loss: 0.0226\n",
      "Epoch 51/200, Iteration 106/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 107/250, Loss: 0.0075\n",
      "Epoch 51/200, Iteration 108/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 109/250, Loss: 0.0160\n",
      "Epoch 51/200, Iteration 110/250, Loss: 0.0192\n",
      "Epoch 51/200, Iteration 111/250, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 112/250, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 113/250, Loss: 0.0137\n",
      "Epoch 51/200, Iteration 114/250, Loss: 0.0243\n",
      "Epoch 51/200, Iteration 115/250, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 116/250, Loss: 0.0163\n",
      "Epoch 51/200, Iteration 117/250, Loss: 0.0177\n",
      "Epoch 51/200, Iteration 118/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 119/250, Loss: 0.0195\n",
      "Epoch 51/200, Iteration 120/250, Loss: 0.0187\n",
      "Epoch 51/200, Iteration 121/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 122/250, Loss: 0.0166\n",
      "Epoch 51/200, Iteration 123/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 124/250, Loss: 0.0284\n",
      "Epoch 51/200, Iteration 125/250, Loss: 0.0224\n",
      "Epoch 51/200, Iteration 126/250, Loss: 0.0159\n",
      "Epoch 51/200, Iteration 127/250, Loss: 0.0142\n",
      "Epoch 51/200, Iteration 128/250, Loss: 0.0279\n",
      "Epoch 51/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 130/250, Loss: 0.0118\n",
      "Epoch 51/200, Iteration 131/250, Loss: 0.0094\n",
      "Epoch 51/200, Iteration 132/250, Loss: 0.0234\n",
      "Epoch 51/200, Iteration 133/250, Loss: 0.0126\n",
      "Epoch 51/200, Iteration 134/250, Loss: 0.0116\n",
      "Epoch 51/200, Iteration 135/250, Loss: 0.0258\n",
      "Epoch 51/200, Iteration 136/250, Loss: 0.0177\n",
      "Epoch 51/200, Iteration 137/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 138/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 139/250, Loss: 0.0198\n",
      "Epoch 51/200, Iteration 140/250, Loss: 0.0076\n",
      "Epoch 51/200, Iteration 141/250, Loss: 0.0154\n",
      "Epoch 51/200, Iteration 142/250, Loss: 0.0244\n",
      "Epoch 51/200, Iteration 143/250, Loss: 0.0155\n",
      "Epoch 51/200, Iteration 144/250, Loss: 0.0220\n",
      "Epoch 51/200, Iteration 145/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 146/250, Loss: 0.0145\n",
      "Epoch 51/200, Iteration 147/250, Loss: 0.0421\n",
      "Epoch 51/200, Iteration 148/250, Loss: 0.0192\n",
      "Epoch 51/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 150/250, Loss: 0.0110\n",
      "Epoch 51/200, Iteration 151/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 152/250, Loss: 0.0170\n",
      "Epoch 51/200, Iteration 153/250, Loss: 0.0177\n",
      "Epoch 51/200, Iteration 154/250, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 155/250, Loss: 0.0110\n",
      "Epoch 51/200, Iteration 156/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 157/250, Loss: 0.0108\n",
      "Epoch 51/200, Iteration 158/250, Loss: 0.0141\n",
      "Epoch 51/200, Iteration 159/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 51/200, Iteration 161/250, Loss: 0.0190\n",
      "Epoch 51/200, Iteration 162/250, Loss: 0.0440\n",
      "Epoch 51/200, Iteration 163/250, Loss: 0.0186\n",
      "Epoch 51/200, Iteration 164/250, Loss: 0.0131\n",
      "Epoch 51/200, Iteration 165/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 166/250, Loss: 0.0195\n",
      "Epoch 51/200, Iteration 167/250, Loss: 0.0126\n",
      "Epoch 51/200, Iteration 168/250, Loss: 0.0102\n",
      "Epoch 51/200, Iteration 169/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 170/250, Loss: 0.0136\n",
      "Epoch 51/200, Iteration 171/250, Loss: 0.0172\n",
      "Epoch 51/200, Iteration 172/250, Loss: 0.0175\n",
      "Epoch 51/200, Iteration 173/250, Loss: 0.0194\n",
      "Epoch 51/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 175/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 177/250, Loss: 0.0293\n",
      "Epoch 51/200, Iteration 178/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 179/250, Loss: 0.0328\n",
      "Epoch 51/200, Iteration 180/250, Loss: 0.0089\n",
      "Epoch 51/200, Iteration 181/250, Loss: 0.0172\n",
      "Epoch 51/200, Iteration 182/250, Loss: 0.0330\n",
      "Epoch 51/200, Iteration 183/250, Loss: 0.0358\n",
      "Epoch 51/200, Iteration 184/250, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 185/250, Loss: 0.0127\n",
      "Epoch 51/200, Iteration 186/250, Loss: 0.0120\n",
      "Epoch 51/200, Iteration 187/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 188/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 51/200, Iteration 190/250, Loss: 0.0101\n",
      "Epoch 51/200, Iteration 191/250, Loss: 0.0281\n",
      "Epoch 51/200, Iteration 192/250, Loss: 0.0107\n",
      "Epoch 51/200, Iteration 193/250, Loss: 0.0093\n",
      "Epoch 51/200, Iteration 194/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 195/250, Loss: 0.0103\n",
      "Epoch 51/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 197/250, Loss: 0.0166\n",
      "Epoch 51/200, Iteration 198/250, Loss: 0.0157\n",
      "Epoch 51/200, Iteration 199/250, Loss: 0.0199\n",
      "Epoch 51/200, Iteration 200/250, Loss: 0.0160\n",
      "Epoch 51/200, Iteration 201/250, Loss: 0.0194\n",
      "Epoch 51/200, Iteration 202/250, Loss: 0.0359\n",
      "Epoch 51/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 51/200, Iteration 204/250, Loss: 0.0095\n",
      "Epoch 51/200, Iteration 205/250, Loss: 0.0163\n",
      "Epoch 51/200, Iteration 206/250, Loss: 0.0276\n",
      "Epoch 51/200, Iteration 207/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 208/250, Loss: 0.0132\n",
      "Epoch 51/200, Iteration 209/250, Loss: 0.0115\n",
      "Epoch 51/200, Iteration 210/250, Loss: 0.0100\n",
      "Epoch 51/200, Iteration 211/250, Loss: 0.0067\n",
      "Epoch 51/200, Iteration 212/250, Loss: 0.0124\n",
      "Epoch 51/200, Iteration 213/250, Loss: 0.0090\n",
      "Epoch 51/200, Iteration 214/250, Loss: 0.0160\n",
      "Epoch 51/200, Iteration 215/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 216/250, Loss: 0.0212\n",
      "Epoch 51/200, Iteration 217/250, Loss: 0.0094\n",
      "Epoch 51/200, Iteration 218/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 219/250, Loss: 0.0217\n",
      "Epoch 51/200, Iteration 220/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 221/250, Loss: 0.0106\n",
      "Epoch 51/200, Iteration 222/250, Loss: 0.0175\n",
      "Epoch 51/200, Iteration 223/250, Loss: 0.0104\n",
      "Epoch 51/200, Iteration 224/250, Loss: 0.0140\n",
      "Epoch 51/200, Iteration 225/250, Loss: 0.0174\n",
      "Epoch 51/200, Iteration 226/250, Loss: 0.0109\n",
      "Epoch 51/200, Iteration 227/250, Loss: 0.0113\n",
      "Epoch 51/200, Iteration 228/250, Loss: 0.0133\n",
      "Epoch 51/200, Iteration 229/250, Loss: 0.0135\n",
      "Epoch 51/200, Iteration 230/250, Loss: 0.0169\n",
      "Epoch 51/200, Iteration 231/250, Loss: 0.0079\n",
      "Epoch 51/200, Iteration 232/250, Loss: 0.0107\n",
      "Epoch 51/200, Iteration 233/250, Loss: 0.0136\n",
      "Epoch 51/200, Iteration 234/250, Loss: 0.0333\n",
      "Epoch 51/200, Iteration 235/250, Loss: 0.0146\n",
      "Epoch 51/200, Iteration 236/250, Loss: 0.0394\n",
      "Epoch 51/200, Iteration 237/250, Loss: 0.0223\n",
      "Epoch 51/200, Iteration 238/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 51/200, Iteration 240/250, Loss: 0.0165\n",
      "Epoch 51/200, Iteration 241/250, Loss: 0.0112\n",
      "Epoch 51/200, Iteration 242/250, Loss: 0.0119\n",
      "Epoch 51/200, Iteration 243/250, Loss: 0.0265\n",
      "Epoch 51/200, Iteration 244/250, Loss: 0.0322\n",
      "Epoch 51/200, Iteration 245/250, Loss: 0.0205\n",
      "Epoch 51/200, Iteration 246/250, Loss: 0.0130\n",
      "Epoch 51/200, Iteration 247/250, Loss: 0.0188\n",
      "Epoch 51/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 51/200, Iteration 249/250, Loss: 0.0252\n",
      "Epoch 51/200, Iteration 250/250, Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 83.34%, Avg loss: 0.007935, MRE: 0.612538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.008388, MRE: 0.761148 \n",
      "\n",
      "Epoch 52/200, Iteration 1/250, Loss: 0.0117\n",
      "Epoch 52/200, Iteration 2/250, Loss: 0.0237\n",
      "Epoch 52/200, Iteration 3/250, Loss: 0.0253\n",
      "Epoch 52/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 5/250, Loss: 0.0225\n",
      "Epoch 52/200, Iteration 6/250, Loss: 0.0201\n",
      "Epoch 52/200, Iteration 7/250, Loss: 0.0226\n",
      "Epoch 52/200, Iteration 8/250, Loss: 0.0126\n",
      "Epoch 52/200, Iteration 9/250, Loss: 0.0169\n",
      "Epoch 52/200, Iteration 10/250, Loss: 0.0222\n",
      "Epoch 52/200, Iteration 11/250, Loss: 0.0261\n",
      "Epoch 52/200, Iteration 12/250, Loss: 0.0150\n",
      "Epoch 52/200, Iteration 13/250, Loss: 0.0220\n",
      "Epoch 52/200, Iteration 14/250, Loss: 0.0234\n",
      "Epoch 52/200, Iteration 15/250, Loss: 0.0230\n",
      "Epoch 52/200, Iteration 16/250, Loss: 0.0173\n",
      "Epoch 52/200, Iteration 17/250, Loss: 0.0167\n",
      "Epoch 52/200, Iteration 18/250, Loss: 0.0248\n",
      "Epoch 52/200, Iteration 19/250, Loss: 0.0122\n",
      "Epoch 52/200, Iteration 20/250, Loss: 0.0170\n",
      "Epoch 52/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 52/200, Iteration 22/250, Loss: 0.0379\n",
      "Epoch 52/200, Iteration 23/250, Loss: 0.0174\n",
      "Epoch 52/200, Iteration 24/250, Loss: 0.0117\n",
      "Epoch 52/200, Iteration 25/250, Loss: 0.0206\n",
      "Epoch 52/200, Iteration 26/250, Loss: 0.0139\n",
      "Epoch 52/200, Iteration 27/250, Loss: 0.0194\n",
      "Epoch 52/200, Iteration 28/250, Loss: 0.0118\n",
      "Epoch 52/200, Iteration 29/250, Loss: 0.0241\n",
      "Epoch 52/200, Iteration 30/250, Loss: 0.0180\n",
      "Epoch 52/200, Iteration 31/250, Loss: 0.0119\n",
      "Epoch 52/200, Iteration 32/250, Loss: 0.0166\n",
      "Epoch 52/200, Iteration 33/250, Loss: 0.0126\n",
      "Epoch 52/200, Iteration 34/250, Loss: 0.0077\n",
      "Epoch 52/200, Iteration 35/250, Loss: 0.0131\n",
      "Epoch 52/200, Iteration 36/250, Loss: 0.0179\n",
      "Epoch 52/200, Iteration 37/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 38/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 39/250, Loss: 0.0136\n",
      "Epoch 52/200, Iteration 40/250, Loss: 0.0124\n",
      "Epoch 52/200, Iteration 41/250, Loss: 0.0108\n",
      "Epoch 52/200, Iteration 42/250, Loss: 0.0133\n",
      "Epoch 52/200, Iteration 43/250, Loss: 0.0094\n",
      "Epoch 52/200, Iteration 44/250, Loss: 0.0124\n",
      "Epoch 52/200, Iteration 45/250, Loss: 0.0152\n",
      "Epoch 52/200, Iteration 46/250, Loss: 0.0243\n",
      "Epoch 52/200, Iteration 47/250, Loss: 0.0115\n",
      "Epoch 52/200, Iteration 48/250, Loss: 0.0202\n",
      "Epoch 52/200, Iteration 49/250, Loss: 0.0486\n",
      "Epoch 52/200, Iteration 50/250, Loss: 0.0158\n",
      "Epoch 52/200, Iteration 51/250, Loss: 0.0166\n",
      "Epoch 52/200, Iteration 52/250, Loss: 0.0139\n",
      "Epoch 52/200, Iteration 53/250, Loss: 0.0236\n",
      "Epoch 52/200, Iteration 54/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 55/250, Loss: 0.0178\n",
      "Epoch 52/200, Iteration 56/250, Loss: 0.0232\n",
      "Epoch 52/200, Iteration 57/250, Loss: 0.0097\n",
      "Epoch 52/200, Iteration 58/250, Loss: 0.0254\n",
      "Epoch 52/200, Iteration 59/250, Loss: 0.0170\n",
      "Epoch 52/200, Iteration 60/250, Loss: 0.0186\n",
      "Epoch 52/200, Iteration 61/250, Loss: 0.0315\n",
      "Epoch 52/200, Iteration 62/250, Loss: 0.0161\n",
      "Epoch 52/200, Iteration 63/250, Loss: 0.0198\n",
      "Epoch 52/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 52/200, Iteration 65/250, Loss: 0.0151\n",
      "Epoch 52/200, Iteration 66/250, Loss: 0.0251\n",
      "Epoch 52/200, Iteration 67/250, Loss: 0.0149\n",
      "Epoch 52/200, Iteration 68/250, Loss: 0.0353\n",
      "Epoch 52/200, Iteration 69/250, Loss: 0.0133\n",
      "Epoch 52/200, Iteration 70/250, Loss: 0.0130\n",
      "Epoch 52/200, Iteration 71/250, Loss: 0.0142\n",
      "Epoch 52/200, Iteration 72/250, Loss: 0.0103\n",
      "Epoch 52/200, Iteration 73/250, Loss: 0.0190\n",
      "Epoch 52/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 52/200, Iteration 75/250, Loss: 0.0207\n",
      "Epoch 52/200, Iteration 76/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 77/250, Loss: 0.0114\n",
      "Epoch 52/200, Iteration 78/250, Loss: 0.0245\n",
      "Epoch 52/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 80/250, Loss: 0.0210\n",
      "Epoch 52/200, Iteration 81/250, Loss: 0.0131\n",
      "Epoch 52/200, Iteration 82/250, Loss: 0.0124\n",
      "Epoch 52/200, Iteration 83/250, Loss: 0.0140\n",
      "Epoch 52/200, Iteration 84/250, Loss: 0.0137\n",
      "Epoch 52/200, Iteration 85/250, Loss: 0.0167\n",
      "Epoch 52/200, Iteration 86/250, Loss: 0.0341\n",
      "Epoch 52/200, Iteration 87/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 88/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 89/250, Loss: 0.0136\n",
      "Epoch 52/200, Iteration 90/250, Loss: 0.0156\n",
      "Epoch 52/200, Iteration 91/250, Loss: 0.0206\n",
      "Epoch 52/200, Iteration 92/250, Loss: 0.0101\n",
      "Epoch 52/200, Iteration 93/250, Loss: 0.0185\n",
      "Epoch 52/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 52/200, Iteration 95/250, Loss: 0.0073\n",
      "Epoch 52/200, Iteration 96/250, Loss: 0.0225\n",
      "Epoch 52/200, Iteration 97/250, Loss: 0.0164\n",
      "Epoch 52/200, Iteration 98/250, Loss: 0.0273\n",
      "Epoch 52/200, Iteration 99/250, Loss: 0.0201\n",
      "Epoch 52/200, Iteration 100/250, Loss: 0.0224\n",
      "Epoch 52/200, Iteration 101/250, Loss: 0.0110\n",
      "Epoch 52/200, Iteration 102/250, Loss: 0.0176\n",
      "Epoch 52/200, Iteration 103/250, Loss: 0.0357\n",
      "Epoch 52/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 52/200, Iteration 105/250, Loss: 0.0115\n",
      "Epoch 52/200, Iteration 106/250, Loss: 0.0305\n",
      "Epoch 52/200, Iteration 107/250, Loss: 0.0324\n",
      "Epoch 52/200, Iteration 108/250, Loss: 0.0115\n",
      "Epoch 52/200, Iteration 109/250, Loss: 0.0221\n",
      "Epoch 52/200, Iteration 110/250, Loss: 0.0196\n",
      "Epoch 52/200, Iteration 111/250, Loss: 0.0386\n",
      "Epoch 52/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 52/200, Iteration 113/250, Loss: 0.0232\n",
      "Epoch 52/200, Iteration 114/250, Loss: 0.0147\n",
      "Epoch 52/200, Iteration 115/250, Loss: 0.0185\n",
      "Epoch 52/200, Iteration 116/250, Loss: 0.0216\n",
      "Epoch 52/200, Iteration 117/250, Loss: 0.0175\n",
      "Epoch 52/200, Iteration 118/250, Loss: 0.0132\n",
      "Epoch 52/200, Iteration 119/250, Loss: 0.0278\n",
      "Epoch 52/200, Iteration 120/250, Loss: 0.0184\n",
      "Epoch 52/200, Iteration 121/250, Loss: 0.0166\n",
      "Epoch 52/200, Iteration 122/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 123/250, Loss: 0.0235\n",
      "Epoch 52/200, Iteration 124/250, Loss: 0.0191\n",
      "Epoch 52/200, Iteration 125/250, Loss: 0.0147\n",
      "Epoch 52/200, Iteration 126/250, Loss: 0.0206\n",
      "Epoch 52/200, Iteration 127/250, Loss: 0.0184\n",
      "Epoch 52/200, Iteration 128/250, Loss: 0.0094\n",
      "Epoch 52/200, Iteration 129/250, Loss: 0.0201\n",
      "Epoch 52/200, Iteration 130/250, Loss: 0.0153\n",
      "Epoch 52/200, Iteration 131/250, Loss: 0.0142\n",
      "Epoch 52/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 52/200, Iteration 133/250, Loss: 0.0087\n",
      "Epoch 52/200, Iteration 134/250, Loss: 0.0177\n",
      "Epoch 52/200, Iteration 135/250, Loss: 0.0171\n",
      "Epoch 52/200, Iteration 136/250, Loss: 0.0188\n",
      "Epoch 52/200, Iteration 137/250, Loss: 0.0091\n",
      "Epoch 52/200, Iteration 138/250, Loss: 0.0197\n",
      "Epoch 52/200, Iteration 139/250, Loss: 0.0153\n",
      "Epoch 52/200, Iteration 140/250, Loss: 0.0073\n",
      "Epoch 52/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 142/250, Loss: 0.0167\n",
      "Epoch 52/200, Iteration 143/250, Loss: 0.0140\n",
      "Epoch 52/200, Iteration 144/250, Loss: 0.0123\n",
      "Epoch 52/200, Iteration 145/250, Loss: 0.0140\n",
      "Epoch 52/200, Iteration 146/250, Loss: 0.0124\n",
      "Epoch 52/200, Iteration 147/250, Loss: 0.0225\n",
      "Epoch 52/200, Iteration 148/250, Loss: 0.0080\n",
      "Epoch 52/200, Iteration 149/250, Loss: 0.0140\n",
      "Epoch 52/200, Iteration 150/250, Loss: 0.0165\n",
      "Epoch 52/200, Iteration 151/250, Loss: 0.0108\n",
      "Epoch 52/200, Iteration 152/250, Loss: 0.0283\n",
      "Epoch 52/200, Iteration 153/250, Loss: 0.0093\n",
      "Epoch 52/200, Iteration 154/250, Loss: 0.0125\n",
      "Epoch 52/200, Iteration 155/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 156/250, Loss: 0.0373\n",
      "Epoch 52/200, Iteration 157/250, Loss: 0.0364\n",
      "Epoch 52/200, Iteration 158/250, Loss: 0.0145\n",
      "Epoch 52/200, Iteration 159/250, Loss: 0.0385\n",
      "Epoch 52/200, Iteration 160/250, Loss: 0.0274\n",
      "Epoch 52/200, Iteration 161/250, Loss: 0.0234\n",
      "Epoch 52/200, Iteration 162/250, Loss: 0.0277\n",
      "Epoch 52/200, Iteration 163/250, Loss: 0.0158\n",
      "Epoch 52/200, Iteration 164/250, Loss: 0.0111\n",
      "Epoch 52/200, Iteration 165/250, Loss: 0.0148\n",
      "Epoch 52/200, Iteration 166/250, Loss: 0.0144\n",
      "Epoch 52/200, Iteration 167/250, Loss: 0.0150\n",
      "Epoch 52/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 52/200, Iteration 169/250, Loss: 0.0122\n",
      "Epoch 52/200, Iteration 170/250, Loss: 0.0116\n",
      "Epoch 52/200, Iteration 171/250, Loss: 0.0102\n",
      "Epoch 52/200, Iteration 172/250, Loss: 0.0128\n",
      "Epoch 52/200, Iteration 173/250, Loss: 0.0186\n",
      "Epoch 52/200, Iteration 174/250, Loss: 0.0180\n",
      "Epoch 52/200, Iteration 175/250, Loss: 0.0126\n",
      "Epoch 52/200, Iteration 176/250, Loss: 0.0132\n",
      "Epoch 52/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 52/200, Iteration 178/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 179/250, Loss: 0.0141\n",
      "Epoch 52/200, Iteration 180/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 181/250, Loss: 0.0146\n",
      "Epoch 52/200, Iteration 182/250, Loss: 0.0230\n",
      "Epoch 52/200, Iteration 183/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 184/250, Loss: 0.0177\n",
      "Epoch 52/200, Iteration 185/250, Loss: 0.0171\n",
      "Epoch 52/200, Iteration 186/250, Loss: 0.0107\n",
      "Epoch 52/200, Iteration 187/250, Loss: 0.0152\n",
      "Epoch 52/200, Iteration 188/250, Loss: 0.0138\n",
      "Epoch 52/200, Iteration 189/250, Loss: 0.0101\n",
      "Epoch 52/200, Iteration 190/250, Loss: 0.0338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Iteration 191/250, Loss: 0.0113\n",
      "Epoch 52/200, Iteration 192/250, Loss: 0.0096\n",
      "Epoch 52/200, Iteration 193/250, Loss: 0.0130\n",
      "Epoch 52/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 195/250, Loss: 0.0150\n",
      "Epoch 52/200, Iteration 196/250, Loss: 0.0247\n",
      "Epoch 52/200, Iteration 197/250, Loss: 0.0131\n",
      "Epoch 52/200, Iteration 198/250, Loss: 0.0125\n",
      "Epoch 52/200, Iteration 199/250, Loss: 0.0155\n",
      "Epoch 52/200, Iteration 200/250, Loss: 0.0224\n",
      "Epoch 52/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 52/200, Iteration 202/250, Loss: 0.0180\n",
      "Epoch 52/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 52/200, Iteration 204/250, Loss: 0.0185\n",
      "Epoch 52/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 52/200, Iteration 206/250, Loss: 0.0194\n",
      "Epoch 52/200, Iteration 207/250, Loss: 0.0239\n",
      "Epoch 52/200, Iteration 208/250, Loss: 0.0258\n",
      "Epoch 52/200, Iteration 209/250, Loss: 0.0081\n",
      "Epoch 52/200, Iteration 210/250, Loss: 0.0149\n",
      "Epoch 52/200, Iteration 211/250, Loss: 0.0148\n",
      "Epoch 52/200, Iteration 212/250, Loss: 0.0171\n",
      "Epoch 52/200, Iteration 213/250, Loss: 0.0363\n",
      "Epoch 52/200, Iteration 214/250, Loss: 0.0106\n",
      "Epoch 52/200, Iteration 215/250, Loss: 0.0108\n",
      "Epoch 52/200, Iteration 216/250, Loss: 0.0218\n",
      "Epoch 52/200, Iteration 217/250, Loss: 0.0080\n",
      "Epoch 52/200, Iteration 218/250, Loss: 0.0213\n",
      "Epoch 52/200, Iteration 219/250, Loss: 0.0095\n",
      "Epoch 52/200, Iteration 220/250, Loss: 0.0100\n",
      "Epoch 52/200, Iteration 221/250, Loss: 0.0176\n",
      "Epoch 52/200, Iteration 222/250, Loss: 0.0106\n",
      "Epoch 52/200, Iteration 223/250, Loss: 0.0088\n",
      "Epoch 52/200, Iteration 224/250, Loss: 0.0135\n",
      "Epoch 52/200, Iteration 225/250, Loss: 0.0142\n",
      "Epoch 52/200, Iteration 226/250, Loss: 0.0103\n",
      "Epoch 52/200, Iteration 227/250, Loss: 0.0216\n",
      "Epoch 52/200, Iteration 228/250, Loss: 0.0120\n",
      "Epoch 52/200, Iteration 229/250, Loss: 0.0094\n",
      "Epoch 52/200, Iteration 230/250, Loss: 0.0137\n",
      "Epoch 52/200, Iteration 231/250, Loss: 0.0121\n",
      "Epoch 52/200, Iteration 232/250, Loss: 0.0148\n",
      "Epoch 52/200, Iteration 233/250, Loss: 0.0102\n",
      "Epoch 52/200, Iteration 234/250, Loss: 0.0158\n",
      "Epoch 52/200, Iteration 235/250, Loss: 0.0303\n",
      "Epoch 52/200, Iteration 236/250, Loss: 0.0081\n",
      "Epoch 52/200, Iteration 237/250, Loss: 0.0112\n",
      "Epoch 52/200, Iteration 238/250, Loss: 0.0177\n",
      "Epoch 52/200, Iteration 239/250, Loss: 0.0163\n",
      "Epoch 52/200, Iteration 240/250, Loss: 0.0118\n",
      "Epoch 52/200, Iteration 241/250, Loss: 0.0186\n",
      "Epoch 52/200, Iteration 242/250, Loss: 0.0144\n",
      "Epoch 52/200, Iteration 243/250, Loss: 0.0417\n",
      "Epoch 52/200, Iteration 244/250, Loss: 0.0228\n",
      "Epoch 52/200, Iteration 245/250, Loss: 0.0312\n",
      "Epoch 52/200, Iteration 246/250, Loss: 0.0190\n",
      "Epoch 52/200, Iteration 247/250, Loss: 0.0144\n",
      "Epoch 52/200, Iteration 248/250, Loss: 0.0359\n",
      "Epoch 52/200, Iteration 249/250, Loss: 0.0345\n",
      "Epoch 52/200, Iteration 250/250, Loss: 0.0126\n",
      "Train Error: \n",
      " Accuracy: 59.91%, Avg loss: 0.011944, MRE: 1.215039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.012176, MRE: 1.142725 \n",
      "\n",
      "Epoch 53/200, Iteration 1/250, Loss: 0.0122\n",
      "Epoch 53/200, Iteration 2/250, Loss: 0.0185\n",
      "Epoch 53/200, Iteration 3/250, Loss: 0.0126\n",
      "Epoch 53/200, Iteration 4/250, Loss: 0.0306\n",
      "Epoch 53/200, Iteration 5/250, Loss: 0.0104\n",
      "Epoch 53/200, Iteration 6/250, Loss: 0.0134\n",
      "Epoch 53/200, Iteration 7/250, Loss: 0.0197\n",
      "Epoch 53/200, Iteration 8/250, Loss: 0.0146\n",
      "Epoch 53/200, Iteration 9/250, Loss: 0.0166\n",
      "Epoch 53/200, Iteration 10/250, Loss: 0.0074\n",
      "Epoch 53/200, Iteration 11/250, Loss: 0.0097\n",
      "Epoch 53/200, Iteration 12/250, Loss: 0.0116\n",
      "Epoch 53/200, Iteration 13/250, Loss: 0.0179\n",
      "Epoch 53/200, Iteration 14/250, Loss: 0.0232\n",
      "Epoch 53/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 16/250, Loss: 0.0233\n",
      "Epoch 53/200, Iteration 17/250, Loss: 0.0180\n",
      "Epoch 53/200, Iteration 18/250, Loss: 0.0157\n",
      "Epoch 53/200, Iteration 19/250, Loss: 0.0164\n",
      "Epoch 53/200, Iteration 20/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 21/250, Loss: 0.0163\n",
      "Epoch 53/200, Iteration 22/250, Loss: 0.0085\n",
      "Epoch 53/200, Iteration 23/250, Loss: 0.0264\n",
      "Epoch 53/200, Iteration 24/250, Loss: 0.0269\n",
      "Epoch 53/200, Iteration 25/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 26/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 27/250, Loss: 0.0233\n",
      "Epoch 53/200, Iteration 28/250, Loss: 0.0118\n",
      "Epoch 53/200, Iteration 29/250, Loss: 0.0156\n",
      "Epoch 53/200, Iteration 30/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 31/250, Loss: 0.0266\n",
      "Epoch 53/200, Iteration 32/250, Loss: 0.0153\n",
      "Epoch 53/200, Iteration 33/250, Loss: 0.0210\n",
      "Epoch 53/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 35/250, Loss: 0.0127\n",
      "Epoch 53/200, Iteration 36/250, Loss: 0.0117\n",
      "Epoch 53/200, Iteration 37/250, Loss: 0.0169\n",
      "Epoch 53/200, Iteration 38/250, Loss: 0.0109\n",
      "Epoch 53/200, Iteration 39/250, Loss: 0.0092\n",
      "Epoch 53/200, Iteration 40/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 41/250, Loss: 0.0128\n",
      "Epoch 53/200, Iteration 42/250, Loss: 0.0215\n",
      "Epoch 53/200, Iteration 43/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 44/250, Loss: 0.0142\n",
      "Epoch 53/200, Iteration 45/250, Loss: 0.0241\n",
      "Epoch 53/200, Iteration 46/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 47/250, Loss: 0.0153\n",
      "Epoch 53/200, Iteration 48/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 49/250, Loss: 0.0118\n",
      "Epoch 53/200, Iteration 50/250, Loss: 0.0087\n",
      "Epoch 53/200, Iteration 51/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 52/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 53/250, Loss: 0.0158\n",
      "Epoch 53/200, Iteration 54/250, Loss: 0.0227\n",
      "Epoch 53/200, Iteration 55/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 56/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 57/250, Loss: 0.0237\n",
      "Epoch 53/200, Iteration 58/250, Loss: 0.0360\n",
      "Epoch 53/200, Iteration 59/250, Loss: 0.0151\n",
      "Epoch 53/200, Iteration 60/250, Loss: 0.0244\n",
      "Epoch 53/200, Iteration 61/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 62/250, Loss: 0.0173\n",
      "Epoch 53/200, Iteration 63/250, Loss: 0.0146\n",
      "Epoch 53/200, Iteration 64/250, Loss: 0.0153\n",
      "Epoch 53/200, Iteration 65/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 53/200, Iteration 67/250, Loss: 0.0183\n",
      "Epoch 53/200, Iteration 68/250, Loss: 0.0334\n",
      "Epoch 53/200, Iteration 69/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 70/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 71/250, Loss: 0.0181\n",
      "Epoch 53/200, Iteration 72/250, Loss: 0.0218\n",
      "Epoch 53/200, Iteration 73/250, Loss: 0.0097\n",
      "Epoch 53/200, Iteration 74/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 75/250, Loss: 0.0125\n",
      "Epoch 53/200, Iteration 76/250, Loss: 0.0116\n",
      "Epoch 53/200, Iteration 77/250, Loss: 0.0178\n",
      "Epoch 53/200, Iteration 78/250, Loss: 0.0217\n",
      "Epoch 53/200, Iteration 79/250, Loss: 0.0192\n",
      "Epoch 53/200, Iteration 80/250, Loss: 0.0254\n",
      "Epoch 53/200, Iteration 81/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 82/250, Loss: 0.0079\n",
      "Epoch 53/200, Iteration 83/250, Loss: 0.0293\n",
      "Epoch 53/200, Iteration 84/250, Loss: 0.0127\n",
      "Epoch 53/200, Iteration 85/250, Loss: 0.0243\n",
      "Epoch 53/200, Iteration 86/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 87/250, Loss: 0.0099\n",
      "Epoch 53/200, Iteration 88/250, Loss: 0.0170\n",
      "Epoch 53/200, Iteration 89/250, Loss: 0.0138\n",
      "Epoch 53/200, Iteration 90/250, Loss: 0.0126\n",
      "Epoch 53/200, Iteration 91/250, Loss: 0.0166\n",
      "Epoch 53/200, Iteration 92/250, Loss: 0.0133\n",
      "Epoch 53/200, Iteration 93/250, Loss: 0.0297\n",
      "Epoch 53/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 53/200, Iteration 95/250, Loss: 0.0266\n",
      "Epoch 53/200, Iteration 96/250, Loss: 0.0152\n",
      "Epoch 53/200, Iteration 97/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 98/250, Loss: 0.0078\n",
      "Epoch 53/200, Iteration 99/250, Loss: 0.0282\n",
      "Epoch 53/200, Iteration 100/250, Loss: 0.0127\n",
      "Epoch 53/200, Iteration 101/250, Loss: 0.0240\n",
      "Epoch 53/200, Iteration 102/250, Loss: 0.0150\n",
      "Epoch 53/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 53/200, Iteration 104/250, Loss: 0.0105\n",
      "Epoch 53/200, Iteration 105/250, Loss: 0.0129\n",
      "Epoch 53/200, Iteration 106/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 108/250, Loss: 0.0077\n",
      "Epoch 53/200, Iteration 109/250, Loss: 0.0125\n",
      "Epoch 53/200, Iteration 110/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 111/250, Loss: 0.0240\n",
      "Epoch 53/200, Iteration 112/250, Loss: 0.0233\n",
      "Epoch 53/200, Iteration 113/250, Loss: 0.0183\n",
      "Epoch 53/200, Iteration 114/250, Loss: 0.0119\n",
      "Epoch 53/200, Iteration 115/250, Loss: 0.0184\n",
      "Epoch 53/200, Iteration 116/250, Loss: 0.0090\n",
      "Epoch 53/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 53/200, Iteration 118/250, Loss: 0.0107\n",
      "Epoch 53/200, Iteration 119/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 120/250, Loss: 0.0109\n",
      "Epoch 53/200, Iteration 121/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 53/200, Iteration 123/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 124/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 125/250, Loss: 0.0140\n",
      "Epoch 53/200, Iteration 126/250, Loss: 0.0297\n",
      "Epoch 53/200, Iteration 127/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 128/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 129/250, Loss: 0.0168\n",
      "Epoch 53/200, Iteration 130/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 131/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 53/200, Iteration 133/250, Loss: 0.0158\n",
      "Epoch 53/200, Iteration 134/250, Loss: 0.0167\n",
      "Epoch 53/200, Iteration 135/250, Loss: 0.0113\n",
      "Epoch 53/200, Iteration 136/250, Loss: 0.0149\n",
      "Epoch 53/200, Iteration 137/250, Loss: 0.0172\n",
      "Epoch 53/200, Iteration 138/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 139/250, Loss: 0.0122\n",
      "Epoch 53/200, Iteration 140/250, Loss: 0.0225\n",
      "Epoch 53/200, Iteration 141/250, Loss: 0.0169\n",
      "Epoch 53/200, Iteration 142/250, Loss: 0.0069\n",
      "Epoch 53/200, Iteration 143/250, Loss: 0.0091\n",
      "Epoch 53/200, Iteration 144/250, Loss: 0.0082\n",
      "Epoch 53/200, Iteration 145/250, Loss: 0.0176\n",
      "Epoch 53/200, Iteration 146/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 147/250, Loss: 0.0337\n",
      "Epoch 53/200, Iteration 148/250, Loss: 0.0175\n",
      "Epoch 53/200, Iteration 149/250, Loss: 0.0279\n",
      "Epoch 53/200, Iteration 150/250, Loss: 0.0267\n",
      "Epoch 53/200, Iteration 151/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 152/250, Loss: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Iteration 153/250, Loss: 0.0134\n",
      "Epoch 53/200, Iteration 154/250, Loss: 0.0300\n",
      "Epoch 53/200, Iteration 155/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 156/250, Loss: 0.0156\n",
      "Epoch 53/200, Iteration 157/250, Loss: 0.0079\n",
      "Epoch 53/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 53/200, Iteration 159/250, Loss: 0.0210\n",
      "Epoch 53/200, Iteration 160/250, Loss: 0.0150\n",
      "Epoch 53/200, Iteration 161/250, Loss: 0.0118\n",
      "Epoch 53/200, Iteration 162/250, Loss: 0.0179\n",
      "Epoch 53/200, Iteration 163/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 164/250, Loss: 0.0150\n",
      "Epoch 53/200, Iteration 165/250, Loss: 0.0144\n",
      "Epoch 53/200, Iteration 166/250, Loss: 0.0173\n",
      "Epoch 53/200, Iteration 167/250, Loss: 0.0097\n",
      "Epoch 53/200, Iteration 168/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 169/250, Loss: 0.0404\n",
      "Epoch 53/200, Iteration 170/250, Loss: 0.0231\n",
      "Epoch 53/200, Iteration 171/250, Loss: 0.0070\n",
      "Epoch 53/200, Iteration 172/250, Loss: 0.0242\n",
      "Epoch 53/200, Iteration 173/250, Loss: 0.0150\n",
      "Epoch 53/200, Iteration 174/250, Loss: 0.0211\n",
      "Epoch 53/200, Iteration 175/250, Loss: 0.0136\n",
      "Epoch 53/200, Iteration 176/250, Loss: 0.0153\n",
      "Epoch 53/200, Iteration 177/250, Loss: 0.0118\n",
      "Epoch 53/200, Iteration 178/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 179/250, Loss: 0.0293\n",
      "Epoch 53/200, Iteration 180/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 181/250, Loss: 0.0110\n",
      "Epoch 53/200, Iteration 182/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 183/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 184/250, Loss: 0.0240\n",
      "Epoch 53/200, Iteration 185/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 186/250, Loss: 0.0097\n",
      "Epoch 53/200, Iteration 187/250, Loss: 0.0124\n",
      "Epoch 53/200, Iteration 188/250, Loss: 0.0276\n",
      "Epoch 53/200, Iteration 189/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 190/250, Loss: 0.0070\n",
      "Epoch 53/200, Iteration 191/250, Loss: 0.0319\n",
      "Epoch 53/200, Iteration 192/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 193/250, Loss: 0.0091\n",
      "Epoch 53/200, Iteration 194/250, Loss: 0.0073\n",
      "Epoch 53/200, Iteration 195/250, Loss: 0.0111\n",
      "Epoch 53/200, Iteration 196/250, Loss: 0.0214\n",
      "Epoch 53/200, Iteration 197/250, Loss: 0.0106\n",
      "Epoch 53/200, Iteration 198/250, Loss: 0.0258\n",
      "Epoch 53/200, Iteration 199/250, Loss: 0.0145\n",
      "Epoch 53/200, Iteration 200/250, Loss: 0.0145\n",
      "Epoch 53/200, Iteration 201/250, Loss: 0.0161\n",
      "Epoch 53/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 53/200, Iteration 203/250, Loss: 0.0213\n",
      "Epoch 53/200, Iteration 204/250, Loss: 0.0108\n",
      "Epoch 53/200, Iteration 205/250, Loss: 0.0107\n",
      "Epoch 53/200, Iteration 206/250, Loss: 0.0116\n",
      "Epoch 53/200, Iteration 207/250, Loss: 0.0169\n",
      "Epoch 53/200, Iteration 208/250, Loss: 0.0099\n",
      "Epoch 53/200, Iteration 209/250, Loss: 0.0107\n",
      "Epoch 53/200, Iteration 210/250, Loss: 0.0162\n",
      "Epoch 53/200, Iteration 211/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 212/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 213/250, Loss: 0.0250\n",
      "Epoch 53/200, Iteration 214/250, Loss: 0.0096\n",
      "Epoch 53/200, Iteration 215/250, Loss: 0.0117\n",
      "Epoch 53/200, Iteration 216/250, Loss: 0.0141\n",
      "Epoch 53/200, Iteration 217/250, Loss: 0.0152\n",
      "Epoch 53/200, Iteration 218/250, Loss: 0.0139\n",
      "Epoch 53/200, Iteration 219/250, Loss: 0.0276\n",
      "Epoch 53/200, Iteration 220/250, Loss: 0.0237\n",
      "Epoch 53/200, Iteration 221/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 222/250, Loss: 0.0115\n",
      "Epoch 53/200, Iteration 223/250, Loss: 0.0089\n",
      "Epoch 53/200, Iteration 224/250, Loss: 0.0165\n",
      "Epoch 53/200, Iteration 225/250, Loss: 0.0160\n",
      "Epoch 53/200, Iteration 226/250, Loss: 0.0251\n",
      "Epoch 53/200, Iteration 227/250, Loss: 0.0363\n",
      "Epoch 53/200, Iteration 228/250, Loss: 0.0159\n",
      "Epoch 53/200, Iteration 229/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 230/250, Loss: 0.0157\n",
      "Epoch 53/200, Iteration 231/250, Loss: 0.0142\n",
      "Epoch 53/200, Iteration 232/250, Loss: 0.0131\n",
      "Epoch 53/200, Iteration 233/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 234/250, Loss: 0.0103\n",
      "Epoch 53/200, Iteration 235/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 236/250, Loss: 0.0126\n",
      "Epoch 53/200, Iteration 237/250, Loss: 0.0243\n",
      "Epoch 53/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 53/200, Iteration 239/250, Loss: 0.0266\n",
      "Epoch 53/200, Iteration 240/250, Loss: 0.0135\n",
      "Epoch 53/200, Iteration 241/250, Loss: 0.0177\n",
      "Epoch 53/200, Iteration 242/250, Loss: 0.0132\n",
      "Epoch 53/200, Iteration 243/250, Loss: 0.0070\n",
      "Epoch 53/200, Iteration 244/250, Loss: 0.0100\n",
      "Epoch 53/200, Iteration 245/250, Loss: 0.0151\n",
      "Epoch 53/200, Iteration 246/250, Loss: 0.0112\n",
      "Epoch 53/200, Iteration 247/250, Loss: 0.0123\n",
      "Epoch 53/200, Iteration 248/250, Loss: 0.0244\n",
      "Epoch 53/200, Iteration 249/250, Loss: 0.0129\n",
      "Epoch 53/200, Iteration 250/250, Loss: 0.0190\n",
      "Train Error: \n",
      " Accuracy: 73.51%, Avg loss: 0.008425, MRE: 0.719136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.008919, MRE: 0.732709 \n",
      "\n",
      "Epoch 54/200, Iteration 1/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 2/250, Loss: 0.0081\n",
      "Epoch 54/200, Iteration 3/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 4/250, Loss: 0.0157\n",
      "Epoch 54/200, Iteration 5/250, Loss: 0.0080\n",
      "Epoch 54/200, Iteration 6/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 7/250, Loss: 0.0144\n",
      "Epoch 54/200, Iteration 8/250, Loss: 0.0154\n",
      "Epoch 54/200, Iteration 9/250, Loss: 0.0311\n",
      "Epoch 54/200, Iteration 10/250, Loss: 0.0099\n",
      "Epoch 54/200, Iteration 11/250, Loss: 0.0078\n",
      "Epoch 54/200, Iteration 12/250, Loss: 0.0201\n",
      "Epoch 54/200, Iteration 13/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 14/250, Loss: 0.0394\n",
      "Epoch 54/200, Iteration 15/250, Loss: 0.0093\n",
      "Epoch 54/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 54/200, Iteration 17/250, Loss: 0.0102\n",
      "Epoch 54/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 19/250, Loss: 0.0264\n",
      "Epoch 54/200, Iteration 20/250, Loss: 0.0096\n",
      "Epoch 54/200, Iteration 21/250, Loss: 0.0200\n",
      "Epoch 54/200, Iteration 22/250, Loss: 0.0108\n",
      "Epoch 54/200, Iteration 23/250, Loss: 0.0197\n",
      "Epoch 54/200, Iteration 24/250, Loss: 0.0119\n",
      "Epoch 54/200, Iteration 25/250, Loss: 0.0157\n",
      "Epoch 54/200, Iteration 26/250, Loss: 0.0101\n",
      "Epoch 54/200, Iteration 27/250, Loss: 0.0273\n",
      "Epoch 54/200, Iteration 28/250, Loss: 0.0131\n",
      "Epoch 54/200, Iteration 29/250, Loss: 0.0210\n",
      "Epoch 54/200, Iteration 30/250, Loss: 0.0230\n",
      "Epoch 54/200, Iteration 31/250, Loss: 0.0123\n",
      "Epoch 54/200, Iteration 32/250, Loss: 0.0176\n",
      "Epoch 54/200, Iteration 33/250, Loss: 0.0127\n",
      "Epoch 54/200, Iteration 34/250, Loss: 0.0182\n",
      "Epoch 54/200, Iteration 35/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 36/250, Loss: 0.0159\n",
      "Epoch 54/200, Iteration 37/250, Loss: 0.0093\n",
      "Epoch 54/200, Iteration 38/250, Loss: 0.0236\n",
      "Epoch 54/200, Iteration 39/250, Loss: 0.0209\n",
      "Epoch 54/200, Iteration 40/250, Loss: 0.0168\n",
      "Epoch 54/200, Iteration 41/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 42/250, Loss: 0.0082\n",
      "Epoch 54/200, Iteration 43/250, Loss: 0.0201\n",
      "Epoch 54/200, Iteration 44/250, Loss: 0.0174\n",
      "Epoch 54/200, Iteration 45/250, Loss: 0.0211\n",
      "Epoch 54/200, Iteration 46/250, Loss: 0.0235\n",
      "Epoch 54/200, Iteration 47/250, Loss: 0.0190\n",
      "Epoch 54/200, Iteration 48/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 49/250, Loss: 0.0381\n",
      "Epoch 54/200, Iteration 50/250, Loss: 0.0168\n",
      "Epoch 54/200, Iteration 51/250, Loss: 0.0151\n",
      "Epoch 54/200, Iteration 52/250, Loss: 0.0275\n",
      "Epoch 54/200, Iteration 53/250, Loss: 0.0147\n",
      "Epoch 54/200, Iteration 54/250, Loss: 0.0221\n",
      "Epoch 54/200, Iteration 55/250, Loss: 0.0172\n",
      "Epoch 54/200, Iteration 56/250, Loss: 0.0289\n",
      "Epoch 54/200, Iteration 57/250, Loss: 0.0147\n",
      "Epoch 54/200, Iteration 58/250, Loss: 0.0140\n",
      "Epoch 54/200, Iteration 59/250, Loss: 0.0311\n",
      "Epoch 54/200, Iteration 60/250, Loss: 0.0149\n",
      "Epoch 54/200, Iteration 61/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 62/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 63/250, Loss: 0.0336\n",
      "Epoch 54/200, Iteration 64/250, Loss: 0.0132\n",
      "Epoch 54/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 54/200, Iteration 66/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 67/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 68/250, Loss: 0.0171\n",
      "Epoch 54/200, Iteration 69/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 70/250, Loss: 0.0107\n",
      "Epoch 54/200, Iteration 71/250, Loss: 0.0099\n",
      "Epoch 54/200, Iteration 72/250, Loss: 0.0288\n",
      "Epoch 54/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 74/250, Loss: 0.0106\n",
      "Epoch 54/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 54/200, Iteration 76/250, Loss: 0.0181\n",
      "Epoch 54/200, Iteration 77/250, Loss: 0.0058\n",
      "Epoch 54/200, Iteration 78/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 79/250, Loss: 0.0100\n",
      "Epoch 54/200, Iteration 80/250, Loss: 0.0204\n",
      "Epoch 54/200, Iteration 81/250, Loss: 0.0079\n",
      "Epoch 54/200, Iteration 82/250, Loss: 0.0240\n",
      "Epoch 54/200, Iteration 83/250, Loss: 0.0111\n",
      "Epoch 54/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 85/250, Loss: 0.0093\n",
      "Epoch 54/200, Iteration 86/250, Loss: 0.0143\n",
      "Epoch 54/200, Iteration 87/250, Loss: 0.0078\n",
      "Epoch 54/200, Iteration 88/250, Loss: 0.0191\n",
      "Epoch 54/200, Iteration 89/250, Loss: 0.0148\n",
      "Epoch 54/200, Iteration 90/250, Loss: 0.0098\n",
      "Epoch 54/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 54/200, Iteration 92/250, Loss: 0.0140\n",
      "Epoch 54/200, Iteration 93/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 94/250, Loss: 0.0293\n",
      "Epoch 54/200, Iteration 95/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 96/250, Loss: 0.0124\n",
      "Epoch 54/200, Iteration 97/250, Loss: 0.0086\n",
      "Epoch 54/200, Iteration 98/250, Loss: 0.0294\n",
      "Epoch 54/200, Iteration 99/250, Loss: 0.0319\n",
      "Epoch 54/200, Iteration 100/250, Loss: 0.0123\n",
      "Epoch 54/200, Iteration 101/250, Loss: 0.0089\n",
      "Epoch 54/200, Iteration 102/250, Loss: 0.0133\n",
      "Epoch 54/200, Iteration 103/250, Loss: 0.0153\n",
      "Epoch 54/200, Iteration 104/250, Loss: 0.0232\n",
      "Epoch 54/200, Iteration 105/250, Loss: 0.0204\n",
      "Epoch 54/200, Iteration 106/250, Loss: 0.0144\n",
      "Epoch 54/200, Iteration 107/250, Loss: 0.0239\n",
      "Epoch 54/200, Iteration 108/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 109/250, Loss: 0.0125\n",
      "Epoch 54/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 111/250, Loss: 0.0098\n",
      "Epoch 54/200, Iteration 112/250, Loss: 0.0136\n",
      "Epoch 54/200, Iteration 113/250, Loss: 0.0095\n",
      "Epoch 54/200, Iteration 114/250, Loss: 0.0129\n",
      "Epoch 54/200, Iteration 115/250, Loss: 0.0083\n",
      "Epoch 54/200, Iteration 116/250, Loss: 0.0091\n",
      "Epoch 54/200, Iteration 117/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 118/250, Loss: 0.0099\n",
      "Epoch 54/200, Iteration 119/250, Loss: 0.0175\n",
      "Epoch 54/200, Iteration 120/250, Loss: 0.0073\n",
      "Epoch 54/200, Iteration 121/250, Loss: 0.0216\n",
      "Epoch 54/200, Iteration 122/250, Loss: 0.0245\n",
      "Epoch 54/200, Iteration 123/250, Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200, Iteration 124/250, Loss: 0.0112\n",
      "Epoch 54/200, Iteration 125/250, Loss: 0.0137\n",
      "Epoch 54/200, Iteration 126/250, Loss: 0.0143\n",
      "Epoch 54/200, Iteration 127/250, Loss: 0.0103\n",
      "Epoch 54/200, Iteration 128/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 129/250, Loss: 0.0205\n",
      "Epoch 54/200, Iteration 130/250, Loss: 0.0184\n",
      "Epoch 54/200, Iteration 131/250, Loss: 0.0267\n",
      "Epoch 54/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 54/200, Iteration 133/250, Loss: 0.0197\n",
      "Epoch 54/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 54/200, Iteration 135/250, Loss: 0.0203\n",
      "Epoch 54/200, Iteration 136/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 137/250, Loss: 0.0249\n",
      "Epoch 54/200, Iteration 138/250, Loss: 0.0149\n",
      "Epoch 54/200, Iteration 139/250, Loss: 0.0206\n",
      "Epoch 54/200, Iteration 140/250, Loss: 0.0268\n",
      "Epoch 54/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 54/200, Iteration 142/250, Loss: 0.0096\n",
      "Epoch 54/200, Iteration 143/250, Loss: 0.0138\n",
      "Epoch 54/200, Iteration 144/250, Loss: 0.0115\n",
      "Epoch 54/200, Iteration 145/250, Loss: 0.0206\n",
      "Epoch 54/200, Iteration 146/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 147/250, Loss: 0.0076\n",
      "Epoch 54/200, Iteration 148/250, Loss: 0.0128\n",
      "Epoch 54/200, Iteration 149/250, Loss: 0.0133\n",
      "Epoch 54/200, Iteration 150/250, Loss: 0.0102\n",
      "Epoch 54/200, Iteration 151/250, Loss: 0.0092\n",
      "Epoch 54/200, Iteration 152/250, Loss: 0.0090\n",
      "Epoch 54/200, Iteration 153/250, Loss: 0.0093\n",
      "Epoch 54/200, Iteration 154/250, Loss: 0.0307\n",
      "Epoch 54/200, Iteration 155/250, Loss: 0.0302\n",
      "Epoch 54/200, Iteration 156/250, Loss: 0.0162\n",
      "Epoch 54/200, Iteration 157/250, Loss: 0.0146\n",
      "Epoch 54/200, Iteration 158/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 159/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 160/250, Loss: 0.0133\n",
      "Epoch 54/200, Iteration 161/250, Loss: 0.0232\n",
      "Epoch 54/200, Iteration 162/250, Loss: 0.0192\n",
      "Epoch 54/200, Iteration 163/250, Loss: 0.0192\n",
      "Epoch 54/200, Iteration 164/250, Loss: 0.0080\n",
      "Epoch 54/200, Iteration 165/250, Loss: 0.0290\n",
      "Epoch 54/200, Iteration 166/250, Loss: 0.0140\n",
      "Epoch 54/200, Iteration 167/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 168/250, Loss: 0.0177\n",
      "Epoch 54/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 54/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 171/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 172/250, Loss: 0.0148\n",
      "Epoch 54/200, Iteration 173/250, Loss: 0.0147\n",
      "Epoch 54/200, Iteration 174/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 175/250, Loss: 0.0266\n",
      "Epoch 54/200, Iteration 176/250, Loss: 0.0284\n",
      "Epoch 54/200, Iteration 177/250, Loss: 0.0188\n",
      "Epoch 54/200, Iteration 178/250, Loss: 0.0124\n",
      "Epoch 54/200, Iteration 179/250, Loss: 0.0215\n",
      "Epoch 54/200, Iteration 180/250, Loss: 0.0220\n",
      "Epoch 54/200, Iteration 181/250, Loss: 0.0210\n",
      "Epoch 54/200, Iteration 182/250, Loss: 0.0152\n",
      "Epoch 54/200, Iteration 183/250, Loss: 0.0154\n",
      "Epoch 54/200, Iteration 184/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 185/250, Loss: 0.0117\n",
      "Epoch 54/200, Iteration 186/250, Loss: 0.0178\n",
      "Epoch 54/200, Iteration 187/250, Loss: 0.0192\n",
      "Epoch 54/200, Iteration 188/250, Loss: 0.0220\n",
      "Epoch 54/200, Iteration 189/250, Loss: 0.0115\n",
      "Epoch 54/200, Iteration 190/250, Loss: 0.0118\n",
      "Epoch 54/200, Iteration 191/250, Loss: 0.0355\n",
      "Epoch 54/200, Iteration 192/250, Loss: 0.0179\n",
      "Epoch 54/200, Iteration 193/250, Loss: 0.0183\n",
      "Epoch 54/200, Iteration 194/250, Loss: 0.0127\n",
      "Epoch 54/200, Iteration 195/250, Loss: 0.0104\n",
      "Epoch 54/200, Iteration 196/250, Loss: 0.0114\n",
      "Epoch 54/200, Iteration 197/250, Loss: 0.0272\n",
      "Epoch 54/200, Iteration 198/250, Loss: 0.0126\n",
      "Epoch 54/200, Iteration 199/250, Loss: 0.0327\n",
      "Epoch 54/200, Iteration 200/250, Loss: 0.0151\n",
      "Epoch 54/200, Iteration 201/250, Loss: 0.0208\n",
      "Epoch 54/200, Iteration 202/250, Loss: 0.0234\n",
      "Epoch 54/200, Iteration 203/250, Loss: 0.0144\n",
      "Epoch 54/200, Iteration 204/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 205/250, Loss: 0.0199\n",
      "Epoch 54/200, Iteration 206/250, Loss: 0.0121\n",
      "Epoch 54/200, Iteration 207/250, Loss: 0.0077\n",
      "Epoch 54/200, Iteration 208/250, Loss: 0.0152\n",
      "Epoch 54/200, Iteration 209/250, Loss: 0.0104\n",
      "Epoch 54/200, Iteration 210/250, Loss: 0.0135\n",
      "Epoch 54/200, Iteration 211/250, Loss: 0.0081\n",
      "Epoch 54/200, Iteration 212/250, Loss: 0.0113\n",
      "Epoch 54/200, Iteration 213/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 54/200, Iteration 215/250, Loss: 0.0153\n",
      "Epoch 54/200, Iteration 216/250, Loss: 0.0156\n",
      "Epoch 54/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 54/200, Iteration 218/250, Loss: 0.0233\n",
      "Epoch 54/200, Iteration 219/250, Loss: 0.0106\n",
      "Epoch 54/200, Iteration 220/250, Loss: 0.0182\n",
      "Epoch 54/200, Iteration 221/250, Loss: 0.0160\n",
      "Epoch 54/200, Iteration 222/250, Loss: 0.0172\n",
      "Epoch 54/200, Iteration 223/250, Loss: 0.0147\n",
      "Epoch 54/200, Iteration 224/250, Loss: 0.0139\n",
      "Epoch 54/200, Iteration 225/250, Loss: 0.0170\n",
      "Epoch 54/200, Iteration 226/250, Loss: 0.0122\n",
      "Epoch 54/200, Iteration 227/250, Loss: 0.0191\n",
      "Epoch 54/200, Iteration 228/250, Loss: 0.0157\n",
      "Epoch 54/200, Iteration 229/250, Loss: 0.0177\n",
      "Epoch 54/200, Iteration 230/250, Loss: 0.0178\n",
      "Epoch 54/200, Iteration 231/250, Loss: 0.0194\n",
      "Epoch 54/200, Iteration 232/250, Loss: 0.0214\n",
      "Epoch 54/200, Iteration 233/250, Loss: 0.0215\n",
      "Epoch 54/200, Iteration 234/250, Loss: 0.0318\n",
      "Epoch 54/200, Iteration 235/250, Loss: 0.0178\n",
      "Epoch 54/200, Iteration 236/250, Loss: 0.0141\n",
      "Epoch 54/200, Iteration 237/250, Loss: 0.0243\n",
      "Epoch 54/200, Iteration 238/250, Loss: 0.0144\n",
      "Epoch 54/200, Iteration 239/250, Loss: 0.0359\n",
      "Epoch 54/200, Iteration 240/250, Loss: 0.0174\n",
      "Epoch 54/200, Iteration 241/250, Loss: 0.0253\n",
      "Epoch 54/200, Iteration 242/250, Loss: 0.0112\n",
      "Epoch 54/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 54/200, Iteration 244/250, Loss: 0.0199\n",
      "Epoch 54/200, Iteration 245/250, Loss: 0.0190\n",
      "Epoch 54/200, Iteration 246/250, Loss: 0.0158\n",
      "Epoch 54/200, Iteration 247/250, Loss: 0.0176\n",
      "Epoch 54/200, Iteration 248/250, Loss: 0.0227\n",
      "Epoch 54/200, Iteration 249/250, Loss: 0.0243\n",
      "Epoch 54/200, Iteration 250/250, Loss: 0.0212\n",
      "Train Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.009853, MRE: 0.880449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.95%, Avg loss: 0.010345, MRE: 0.990986 \n",
      "\n",
      "Epoch 55/200, Iteration 1/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 2/250, Loss: 0.0150\n",
      "Epoch 55/200, Iteration 3/250, Loss: 0.0080\n",
      "Epoch 55/200, Iteration 4/250, Loss: 0.0261\n",
      "Epoch 55/200, Iteration 5/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 6/250, Loss: 0.0111\n",
      "Epoch 55/200, Iteration 7/250, Loss: 0.0076\n",
      "Epoch 55/200, Iteration 8/250, Loss: 0.0196\n",
      "Epoch 55/200, Iteration 9/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 10/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 55/200, Iteration 12/250, Loss: 0.0343\n",
      "Epoch 55/200, Iteration 13/250, Loss: 0.0228\n",
      "Epoch 55/200, Iteration 14/250, Loss: 0.0150\n",
      "Epoch 55/200, Iteration 15/250, Loss: 0.0079\n",
      "Epoch 55/200, Iteration 16/250, Loss: 0.0154\n",
      "Epoch 55/200, Iteration 17/250, Loss: 0.0217\n",
      "Epoch 55/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 55/200, Iteration 19/250, Loss: 0.0099\n",
      "Epoch 55/200, Iteration 20/250, Loss: 0.0142\n",
      "Epoch 55/200, Iteration 21/250, Loss: 0.0145\n",
      "Epoch 55/200, Iteration 22/250, Loss: 0.0226\n",
      "Epoch 55/200, Iteration 23/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 24/250, Loss: 0.0092\n",
      "Epoch 55/200, Iteration 25/250, Loss: 0.0399\n",
      "Epoch 55/200, Iteration 26/250, Loss: 0.0132\n",
      "Epoch 55/200, Iteration 27/250, Loss: 0.0280\n",
      "Epoch 55/200, Iteration 28/250, Loss: 0.0198\n",
      "Epoch 55/200, Iteration 29/250, Loss: 0.0187\n",
      "Epoch 55/200, Iteration 30/250, Loss: 0.0125\n",
      "Epoch 55/200, Iteration 31/250, Loss: 0.0184\n",
      "Epoch 55/200, Iteration 32/250, Loss: 0.0173\n",
      "Epoch 55/200, Iteration 33/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 34/250, Loss: 0.0247\n",
      "Epoch 55/200, Iteration 35/250, Loss: 0.0112\n",
      "Epoch 55/200, Iteration 36/250, Loss: 0.0152\n",
      "Epoch 55/200, Iteration 37/250, Loss: 0.0174\n",
      "Epoch 55/200, Iteration 38/250, Loss: 0.0280\n",
      "Epoch 55/200, Iteration 39/250, Loss: 0.0121\n",
      "Epoch 55/200, Iteration 40/250, Loss: 0.0300\n",
      "Epoch 55/200, Iteration 41/250, Loss: 0.0151\n",
      "Epoch 55/200, Iteration 42/250, Loss: 0.0150\n",
      "Epoch 55/200, Iteration 43/250, Loss: 0.0291\n",
      "Epoch 55/200, Iteration 44/250, Loss: 0.0085\n",
      "Epoch 55/200, Iteration 45/250, Loss: 0.0309\n",
      "Epoch 55/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 55/200, Iteration 47/250, Loss: 0.0164\n",
      "Epoch 55/200, Iteration 48/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 49/250, Loss: 0.0232\n",
      "Epoch 55/200, Iteration 50/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 51/250, Loss: 0.0220\n",
      "Epoch 55/200, Iteration 52/250, Loss: 0.0185\n",
      "Epoch 55/200, Iteration 53/250, Loss: 0.0197\n",
      "Epoch 55/200, Iteration 54/250, Loss: 0.0167\n",
      "Epoch 55/200, Iteration 55/250, Loss: 0.0171\n",
      "Epoch 55/200, Iteration 56/250, Loss: 0.0434\n",
      "Epoch 55/200, Iteration 57/250, Loss: 0.0129\n",
      "Epoch 55/200, Iteration 58/250, Loss: 0.0163\n",
      "Epoch 55/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 55/200, Iteration 60/250, Loss: 0.0156\n",
      "Epoch 55/200, Iteration 61/250, Loss: 0.0118\n",
      "Epoch 55/200, Iteration 62/250, Loss: 0.0185\n",
      "Epoch 55/200, Iteration 63/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 64/250, Loss: 0.0261\n",
      "Epoch 55/200, Iteration 65/250, Loss: 0.0140\n",
      "Epoch 55/200, Iteration 66/250, Loss: 0.0114\n",
      "Epoch 55/200, Iteration 67/250, Loss: 0.0299\n",
      "Epoch 55/200, Iteration 68/250, Loss: 0.0190\n",
      "Epoch 55/200, Iteration 69/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 70/250, Loss: 0.0449\n",
      "Epoch 55/200, Iteration 71/250, Loss: 0.0141\n",
      "Epoch 55/200, Iteration 72/250, Loss: 0.0111\n",
      "Epoch 55/200, Iteration 73/250, Loss: 0.0175\n",
      "Epoch 55/200, Iteration 74/250, Loss: 0.0225\n",
      "Epoch 55/200, Iteration 75/250, Loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Iteration 76/250, Loss: 0.0192\n",
      "Epoch 55/200, Iteration 77/250, Loss: 0.0238\n",
      "Epoch 55/200, Iteration 78/250, Loss: 0.0114\n",
      "Epoch 55/200, Iteration 79/250, Loss: 0.0109\n",
      "Epoch 55/200, Iteration 80/250, Loss: 0.0128\n",
      "Epoch 55/200, Iteration 81/250, Loss: 0.0305\n",
      "Epoch 55/200, Iteration 82/250, Loss: 0.0167\n",
      "Epoch 55/200, Iteration 83/250, Loss: 0.0202\n",
      "Epoch 55/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 55/200, Iteration 85/250, Loss: 0.0139\n",
      "Epoch 55/200, Iteration 86/250, Loss: 0.0100\n",
      "Epoch 55/200, Iteration 87/250, Loss: 0.0220\n",
      "Epoch 55/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 55/200, Iteration 89/250, Loss: 0.0078\n",
      "Epoch 55/200, Iteration 90/250, Loss: 0.0124\n",
      "Epoch 55/200, Iteration 91/250, Loss: 0.0252\n",
      "Epoch 55/200, Iteration 92/250, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 93/250, Loss: 0.0089\n",
      "Epoch 55/200, Iteration 94/250, Loss: 0.0207\n",
      "Epoch 55/200, Iteration 95/250, Loss: 0.0181\n",
      "Epoch 55/200, Iteration 96/250, Loss: 0.0284\n",
      "Epoch 55/200, Iteration 97/250, Loss: 0.0099\n",
      "Epoch 55/200, Iteration 98/250, Loss: 0.0183\n",
      "Epoch 55/200, Iteration 99/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 100/250, Loss: 0.0096\n",
      "Epoch 55/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 102/250, Loss: 0.0174\n",
      "Epoch 55/200, Iteration 103/250, Loss: 0.0154\n",
      "Epoch 55/200, Iteration 104/250, Loss: 0.0191\n",
      "Epoch 55/200, Iteration 105/250, Loss: 0.0117\n",
      "Epoch 55/200, Iteration 106/250, Loss: 0.0102\n",
      "Epoch 55/200, Iteration 107/250, Loss: 0.0104\n",
      "Epoch 55/200, Iteration 108/250, Loss: 0.0109\n",
      "Epoch 55/200, Iteration 109/250, Loss: 0.0165\n",
      "Epoch 55/200, Iteration 110/250, Loss: 0.0151\n",
      "Epoch 55/200, Iteration 111/250, Loss: 0.0170\n",
      "Epoch 55/200, Iteration 112/250, Loss: 0.0107\n",
      "Epoch 55/200, Iteration 113/250, Loss: 0.0251\n",
      "Epoch 55/200, Iteration 114/250, Loss: 0.0312\n",
      "Epoch 55/200, Iteration 115/250, Loss: 0.0183\n",
      "Epoch 55/200, Iteration 116/250, Loss: 0.0142\n",
      "Epoch 55/200, Iteration 117/250, Loss: 0.0126\n",
      "Epoch 55/200, Iteration 118/250, Loss: 0.0113\n",
      "Epoch 55/200, Iteration 119/250, Loss: 0.0166\n",
      "Epoch 55/200, Iteration 120/250, Loss: 0.0297\n",
      "Epoch 55/200, Iteration 121/250, Loss: 0.0177\n",
      "Epoch 55/200, Iteration 122/250, Loss: 0.0155\n",
      "Epoch 55/200, Iteration 123/250, Loss: 0.0083\n",
      "Epoch 55/200, Iteration 124/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 125/250, Loss: 0.0130\n",
      "Epoch 55/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 55/200, Iteration 127/250, Loss: 0.0107\n",
      "Epoch 55/200, Iteration 128/250, Loss: 0.0234\n",
      "Epoch 55/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 55/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 55/200, Iteration 131/250, Loss: 0.0118\n",
      "Epoch 55/200, Iteration 132/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 133/250, Loss: 0.0079\n",
      "Epoch 55/200, Iteration 134/250, Loss: 0.0116\n",
      "Epoch 55/200, Iteration 135/250, Loss: 0.0171\n",
      "Epoch 55/200, Iteration 136/250, Loss: 0.0137\n",
      "Epoch 55/200, Iteration 137/250, Loss: 0.0294\n",
      "Epoch 55/200, Iteration 138/250, Loss: 0.0143\n",
      "Epoch 55/200, Iteration 139/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 140/250, Loss: 0.0267\n",
      "Epoch 55/200, Iteration 141/250, Loss: 0.0275\n",
      "Epoch 55/200, Iteration 142/250, Loss: 0.0201\n",
      "Epoch 55/200, Iteration 143/250, Loss: 0.0096\n",
      "Epoch 55/200, Iteration 144/250, Loss: 0.0124\n",
      "Epoch 55/200, Iteration 145/250, Loss: 0.0263\n",
      "Epoch 55/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 55/200, Iteration 147/250, Loss: 0.0166\n",
      "Epoch 55/200, Iteration 148/250, Loss: 0.0214\n",
      "Epoch 55/200, Iteration 149/250, Loss: 0.0163\n",
      "Epoch 55/200, Iteration 150/250, Loss: 0.0159\n",
      "Epoch 55/200, Iteration 151/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 152/250, Loss: 0.0132\n",
      "Epoch 55/200, Iteration 153/250, Loss: 0.0078\n",
      "Epoch 55/200, Iteration 154/250, Loss: 0.0134\n",
      "Epoch 55/200, Iteration 155/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 156/250, Loss: 0.0096\n",
      "Epoch 55/200, Iteration 157/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 158/250, Loss: 0.0142\n",
      "Epoch 55/200, Iteration 159/250, Loss: 0.0145\n",
      "Epoch 55/200, Iteration 160/250, Loss: 0.0097\n",
      "Epoch 55/200, Iteration 161/250, Loss: 0.0096\n",
      "Epoch 55/200, Iteration 162/250, Loss: 0.0254\n",
      "Epoch 55/200, Iteration 163/250, Loss: 0.0109\n",
      "Epoch 55/200, Iteration 164/250, Loss: 0.0142\n",
      "Epoch 55/200, Iteration 165/250, Loss: 0.0227\n",
      "Epoch 55/200, Iteration 166/250, Loss: 0.0116\n",
      "Epoch 55/200, Iteration 167/250, Loss: 0.0081\n",
      "Epoch 55/200, Iteration 168/250, Loss: 0.0301\n",
      "Epoch 55/200, Iteration 169/250, Loss: 0.0184\n",
      "Epoch 55/200, Iteration 170/250, Loss: 0.0135\n",
      "Epoch 55/200, Iteration 171/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 172/250, Loss: 0.0112\n",
      "Epoch 55/200, Iteration 173/250, Loss: 0.0068\n",
      "Epoch 55/200, Iteration 174/250, Loss: 0.0073\n",
      "Epoch 55/200, Iteration 175/250, Loss: 0.0068\n",
      "Epoch 55/200, Iteration 176/250, Loss: 0.0140\n",
      "Epoch 55/200, Iteration 177/250, Loss: 0.0131\n",
      "Epoch 55/200, Iteration 178/250, Loss: 0.0115\n",
      "Epoch 55/200, Iteration 179/250, Loss: 0.0205\n",
      "Epoch 55/200, Iteration 180/250, Loss: 0.0105\n",
      "Epoch 55/200, Iteration 181/250, Loss: 0.0207\n",
      "Epoch 55/200, Iteration 182/250, Loss: 0.0125\n",
      "Epoch 55/200, Iteration 183/250, Loss: 0.0195\n",
      "Epoch 55/200, Iteration 184/250, Loss: 0.0344\n",
      "Epoch 55/200, Iteration 185/250, Loss: 0.0479\n",
      "Epoch 55/200, Iteration 186/250, Loss: 0.0076\n",
      "Epoch 55/200, Iteration 187/250, Loss: 0.0280\n",
      "Epoch 55/200, Iteration 188/250, Loss: 0.0074\n",
      "Epoch 55/200, Iteration 189/250, Loss: 0.0311\n",
      "Epoch 55/200, Iteration 190/250, Loss: 0.0122\n",
      "Epoch 55/200, Iteration 191/250, Loss: 0.0098\n",
      "Epoch 55/200, Iteration 192/250, Loss: 0.0137\n",
      "Epoch 55/200, Iteration 193/250, Loss: 0.0260\n",
      "Epoch 55/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 55/200, Iteration 195/250, Loss: 0.0185\n",
      "Epoch 55/200, Iteration 196/250, Loss: 0.0131\n",
      "Epoch 55/200, Iteration 197/250, Loss: 0.0187\n",
      "Epoch 55/200, Iteration 198/250, Loss: 0.0118\n",
      "Epoch 55/200, Iteration 199/250, Loss: 0.0270\n",
      "Epoch 55/200, Iteration 200/250, Loss: 0.0197\n",
      "Epoch 55/200, Iteration 201/250, Loss: 0.0085\n",
      "Epoch 55/200, Iteration 202/250, Loss: 0.0154\n",
      "Epoch 55/200, Iteration 203/250, Loss: 0.0221\n",
      "Epoch 55/200, Iteration 204/250, Loss: 0.0217\n",
      "Epoch 55/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 55/200, Iteration 206/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 207/250, Loss: 0.0134\n",
      "Epoch 55/200, Iteration 208/250, Loss: 0.0126\n",
      "Epoch 55/200, Iteration 209/250, Loss: 0.0217\n",
      "Epoch 55/200, Iteration 210/250, Loss: 0.0136\n",
      "Epoch 55/200, Iteration 211/250, Loss: 0.0119\n",
      "Epoch 55/200, Iteration 212/250, Loss: 0.0137\n",
      "Epoch 55/200, Iteration 213/250, Loss: 0.0140\n",
      "Epoch 55/200, Iteration 214/250, Loss: 0.0108\n",
      "Epoch 55/200, Iteration 215/250, Loss: 0.0146\n",
      "Epoch 55/200, Iteration 216/250, Loss: 0.0083\n",
      "Epoch 55/200, Iteration 217/250, Loss: 0.0206\n",
      "Epoch 55/200, Iteration 218/250, Loss: 0.0144\n",
      "Epoch 55/200, Iteration 219/250, Loss: 0.0181\n",
      "Epoch 55/200, Iteration 220/250, Loss: 0.0314\n",
      "Epoch 55/200, Iteration 221/250, Loss: 0.0114\n",
      "Epoch 55/200, Iteration 222/250, Loss: 0.0093\n",
      "Epoch 55/200, Iteration 223/250, Loss: 0.0194\n",
      "Epoch 55/200, Iteration 224/250, Loss: 0.0452\n",
      "Epoch 55/200, Iteration 225/250, Loss: 0.0209\n",
      "Epoch 55/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 55/200, Iteration 227/250, Loss: 0.0132\n",
      "Epoch 55/200, Iteration 228/250, Loss: 0.0180\n",
      "Epoch 55/200, Iteration 229/250, Loss: 0.0134\n",
      "Epoch 55/200, Iteration 230/250, Loss: 0.0163\n",
      "Epoch 55/200, Iteration 231/250, Loss: 0.0123\n",
      "Epoch 55/200, Iteration 232/250, Loss: 0.0087\n",
      "Epoch 55/200, Iteration 233/250, Loss: 0.0328\n",
      "Epoch 55/200, Iteration 234/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 235/250, Loss: 0.0161\n",
      "Epoch 55/200, Iteration 236/250, Loss: 0.0183\n",
      "Epoch 55/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 55/200, Iteration 238/250, Loss: 0.0138\n",
      "Epoch 55/200, Iteration 239/250, Loss: 0.0138\n",
      "Epoch 55/200, Iteration 240/250, Loss: 0.0098\n",
      "Epoch 55/200, Iteration 241/250, Loss: 0.0229\n",
      "Epoch 55/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 55/200, Iteration 243/250, Loss: 0.0083\n",
      "Epoch 55/200, Iteration 244/250, Loss: 0.0155\n",
      "Epoch 55/200, Iteration 245/250, Loss: 0.0106\n",
      "Epoch 55/200, Iteration 246/250, Loss: 0.0175\n",
      "Epoch 55/200, Iteration 247/250, Loss: 0.0068\n",
      "Epoch 55/200, Iteration 248/250, Loss: 0.0101\n",
      "Epoch 55/200, Iteration 249/250, Loss: 0.0079\n",
      "Epoch 55/200, Iteration 250/250, Loss: 0.0321\n",
      "Train Error: \n",
      " Accuracy: 76.46%, Avg loss: 0.008092, MRE: 0.632933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.008447, MRE: 0.710887 \n",
      "\n",
      "Epoch 56/200, Iteration 1/250, Loss: 0.0114\n",
      "Epoch 56/200, Iteration 2/250, Loss: 0.0264\n",
      "Epoch 56/200, Iteration 3/250, Loss: 0.0113\n",
      "Epoch 56/200, Iteration 4/250, Loss: 0.0129\n",
      "Epoch 56/200, Iteration 5/250, Loss: 0.0095\n",
      "Epoch 56/200, Iteration 6/250, Loss: 0.0130\n",
      "Epoch 56/200, Iteration 7/250, Loss: 0.0100\n",
      "Epoch 56/200, Iteration 8/250, Loss: 0.0225\n",
      "Epoch 56/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 10/250, Loss: 0.0110\n",
      "Epoch 56/200, Iteration 11/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 12/250, Loss: 0.0084\n",
      "Epoch 56/200, Iteration 13/250, Loss: 0.0136\n",
      "Epoch 56/200, Iteration 14/250, Loss: 0.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Iteration 15/250, Loss: 0.0103\n",
      "Epoch 56/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 56/200, Iteration 17/250, Loss: 0.0203\n",
      "Epoch 56/200, Iteration 18/250, Loss: 0.0302\n",
      "Epoch 56/200, Iteration 19/250, Loss: 0.0076\n",
      "Epoch 56/200, Iteration 20/250, Loss: 0.0162\n",
      "Epoch 56/200, Iteration 21/250, Loss: 0.0095\n",
      "Epoch 56/200, Iteration 22/250, Loss: 0.0086\n",
      "Epoch 56/200, Iteration 23/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 24/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 25/250, Loss: 0.0103\n",
      "Epoch 56/200, Iteration 26/250, Loss: 0.0195\n",
      "Epoch 56/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 56/200, Iteration 28/250, Loss: 0.0189\n",
      "Epoch 56/200, Iteration 29/250, Loss: 0.0322\n",
      "Epoch 56/200, Iteration 30/250, Loss: 0.0131\n",
      "Epoch 56/200, Iteration 31/250, Loss: 0.0245\n",
      "Epoch 56/200, Iteration 32/250, Loss: 0.0215\n",
      "Epoch 56/200, Iteration 33/250, Loss: 0.0157\n",
      "Epoch 56/200, Iteration 34/250, Loss: 0.0203\n",
      "Epoch 56/200, Iteration 35/250, Loss: 0.0103\n",
      "Epoch 56/200, Iteration 36/250, Loss: 0.0156\n",
      "Epoch 56/200, Iteration 37/250, Loss: 0.0261\n",
      "Epoch 56/200, Iteration 38/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 39/250, Loss: 0.0236\n",
      "Epoch 56/200, Iteration 40/250, Loss: 0.0155\n",
      "Epoch 56/200, Iteration 41/250, Loss: 0.0196\n",
      "Epoch 56/200, Iteration 42/250, Loss: 0.0216\n",
      "Epoch 56/200, Iteration 43/250, Loss: 0.0150\n",
      "Epoch 56/200, Iteration 44/250, Loss: 0.0233\n",
      "Epoch 56/200, Iteration 45/250, Loss: 0.0099\n",
      "Epoch 56/200, Iteration 46/250, Loss: 0.0150\n",
      "Epoch 56/200, Iteration 47/250, Loss: 0.0113\n",
      "Epoch 56/200, Iteration 48/250, Loss: 0.0210\n",
      "Epoch 56/200, Iteration 49/250, Loss: 0.0194\n",
      "Epoch 56/200, Iteration 50/250, Loss: 0.0125\n",
      "Epoch 56/200, Iteration 51/250, Loss: 0.0126\n",
      "Epoch 56/200, Iteration 52/250, Loss: 0.0085\n",
      "Epoch 56/200, Iteration 53/250, Loss: 0.0093\n",
      "Epoch 56/200, Iteration 54/250, Loss: 0.0370\n",
      "Epoch 56/200, Iteration 55/250, Loss: 0.0142\n",
      "Epoch 56/200, Iteration 56/250, Loss: 0.0082\n",
      "Epoch 56/200, Iteration 57/250, Loss: 0.0162\n",
      "Epoch 56/200, Iteration 58/250, Loss: 0.0141\n",
      "Epoch 56/200, Iteration 59/250, Loss: 0.0147\n",
      "Epoch 56/200, Iteration 60/250, Loss: 0.0095\n",
      "Epoch 56/200, Iteration 61/250, Loss: 0.0216\n",
      "Epoch 56/200, Iteration 62/250, Loss: 0.0401\n",
      "Epoch 56/200, Iteration 63/250, Loss: 0.0138\n",
      "Epoch 56/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 56/200, Iteration 65/250, Loss: 0.0492\n",
      "Epoch 56/200, Iteration 66/250, Loss: 0.0155\n",
      "Epoch 56/200, Iteration 67/250, Loss: 0.0177\n",
      "Epoch 56/200, Iteration 68/250, Loss: 0.0091\n",
      "Epoch 56/200, Iteration 69/250, Loss: 0.0109\n",
      "Epoch 56/200, Iteration 70/250, Loss: 0.0137\n",
      "Epoch 56/200, Iteration 71/250, Loss: 0.0093\n",
      "Epoch 56/200, Iteration 72/250, Loss: 0.0279\n",
      "Epoch 56/200, Iteration 73/250, Loss: 0.0251\n",
      "Epoch 56/200, Iteration 74/250, Loss: 0.0190\n",
      "Epoch 56/200, Iteration 75/250, Loss: 0.0071\n",
      "Epoch 56/200, Iteration 76/250, Loss: 0.0193\n",
      "Epoch 56/200, Iteration 77/250, Loss: 0.0407\n",
      "Epoch 56/200, Iteration 78/250, Loss: 0.0132\n",
      "Epoch 56/200, Iteration 79/250, Loss: 0.0281\n",
      "Epoch 56/200, Iteration 80/250, Loss: 0.0145\n",
      "Epoch 56/200, Iteration 81/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 82/250, Loss: 0.0211\n",
      "Epoch 56/200, Iteration 83/250, Loss: 0.0145\n",
      "Epoch 56/200, Iteration 84/250, Loss: 0.0141\n",
      "Epoch 56/200, Iteration 85/250, Loss: 0.0375\n",
      "Epoch 56/200, Iteration 86/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 87/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 56/200, Iteration 89/250, Loss: 0.0136\n",
      "Epoch 56/200, Iteration 90/250, Loss: 0.0161\n",
      "Epoch 56/200, Iteration 91/250, Loss: 0.0314\n",
      "Epoch 56/200, Iteration 92/250, Loss: 0.0213\n",
      "Epoch 56/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 56/200, Iteration 94/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 95/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 96/250, Loss: 0.0086\n",
      "Epoch 56/200, Iteration 97/250, Loss: 0.0372\n",
      "Epoch 56/200, Iteration 98/250, Loss: 0.0092\n",
      "Epoch 56/200, Iteration 99/250, Loss: 0.0169\n",
      "Epoch 56/200, Iteration 100/250, Loss: 0.0202\n",
      "Epoch 56/200, Iteration 101/250, Loss: 0.0141\n",
      "Epoch 56/200, Iteration 102/250, Loss: 0.0178\n",
      "Epoch 56/200, Iteration 103/250, Loss: 0.0145\n",
      "Epoch 56/200, Iteration 104/250, Loss: 0.0183\n",
      "Epoch 56/200, Iteration 105/250, Loss: 0.0208\n",
      "Epoch 56/200, Iteration 106/250, Loss: 0.0179\n",
      "Epoch 56/200, Iteration 107/250, Loss: 0.0157\n",
      "Epoch 56/200, Iteration 108/250, Loss: 0.0089\n",
      "Epoch 56/200, Iteration 109/250, Loss: 0.0191\n",
      "Epoch 56/200, Iteration 110/250, Loss: 0.0083\n",
      "Epoch 56/200, Iteration 111/250, Loss: 0.0124\n",
      "Epoch 56/200, Iteration 112/250, Loss: 0.0437\n",
      "Epoch 56/200, Iteration 113/250, Loss: 0.0225\n",
      "Epoch 56/200, Iteration 114/250, Loss: 0.0106\n",
      "Epoch 56/200, Iteration 115/250, Loss: 0.0318\n",
      "Epoch 56/200, Iteration 116/250, Loss: 0.0373\n",
      "Epoch 56/200, Iteration 117/250, Loss: 0.0185\n",
      "Epoch 56/200, Iteration 118/250, Loss: 0.0199\n",
      "Epoch 56/200, Iteration 119/250, Loss: 0.0263\n",
      "Epoch 56/200, Iteration 120/250, Loss: 0.0309\n",
      "Epoch 56/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 56/200, Iteration 122/250, Loss: 0.0126\n",
      "Epoch 56/200, Iteration 123/250, Loss: 0.0135\n",
      "Epoch 56/200, Iteration 124/250, Loss: 0.0143\n",
      "Epoch 56/200, Iteration 125/250, Loss: 0.0201\n",
      "Epoch 56/200, Iteration 126/250, Loss: 0.0268\n",
      "Epoch 56/200, Iteration 127/250, Loss: 0.0240\n",
      "Epoch 56/200, Iteration 128/250, Loss: 0.0211\n",
      "Epoch 56/200, Iteration 129/250, Loss: 0.0114\n",
      "Epoch 56/200, Iteration 130/250, Loss: 0.0106\n",
      "Epoch 56/200, Iteration 131/250, Loss: 0.0127\n",
      "Epoch 56/200, Iteration 132/250, Loss: 0.0262\n",
      "Epoch 56/200, Iteration 133/250, Loss: 0.0106\n",
      "Epoch 56/200, Iteration 134/250, Loss: 0.0118\n",
      "Epoch 56/200, Iteration 135/250, Loss: 0.0099\n",
      "Epoch 56/200, Iteration 136/250, Loss: 0.0115\n",
      "Epoch 56/200, Iteration 137/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 138/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 139/250, Loss: 0.0116\n",
      "Epoch 56/200, Iteration 140/250, Loss: 0.0225\n",
      "Epoch 56/200, Iteration 141/250, Loss: 0.0168\n",
      "Epoch 56/200, Iteration 142/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 143/250, Loss: 0.0243\n",
      "Epoch 56/200, Iteration 144/250, Loss: 0.0306\n",
      "Epoch 56/200, Iteration 145/250, Loss: 0.0092\n",
      "Epoch 56/200, Iteration 146/250, Loss: 0.0158\n",
      "Epoch 56/200, Iteration 147/250, Loss: 0.0133\n",
      "Epoch 56/200, Iteration 148/250, Loss: 0.0190\n",
      "Epoch 56/200, Iteration 149/250, Loss: 0.0220\n",
      "Epoch 56/200, Iteration 150/250, Loss: 0.0263\n",
      "Epoch 56/200, Iteration 151/250, Loss: 0.0123\n",
      "Epoch 56/200, Iteration 152/250, Loss: 0.0284\n",
      "Epoch 56/200, Iteration 153/250, Loss: 0.0110\n",
      "Epoch 56/200, Iteration 154/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 155/250, Loss: 0.0288\n",
      "Epoch 56/200, Iteration 156/250, Loss: 0.0254\n",
      "Epoch 56/200, Iteration 157/250, Loss: 0.0123\n",
      "Epoch 56/200, Iteration 158/250, Loss: 0.0178\n",
      "Epoch 56/200, Iteration 159/250, Loss: 0.0090\n",
      "Epoch 56/200, Iteration 160/250, Loss: 0.0172\n",
      "Epoch 56/200, Iteration 161/250, Loss: 0.0105\n",
      "Epoch 56/200, Iteration 162/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 163/250, Loss: 0.0130\n",
      "Epoch 56/200, Iteration 164/250, Loss: 0.0254\n",
      "Epoch 56/200, Iteration 165/250, Loss: 0.0220\n",
      "Epoch 56/200, Iteration 166/250, Loss: 0.0177\n",
      "Epoch 56/200, Iteration 167/250, Loss: 0.0147\n",
      "Epoch 56/200, Iteration 168/250, Loss: 0.0096\n",
      "Epoch 56/200, Iteration 169/250, Loss: 0.0244\n",
      "Epoch 56/200, Iteration 170/250, Loss: 0.0105\n",
      "Epoch 56/200, Iteration 171/250, Loss: 0.0266\n",
      "Epoch 56/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 56/200, Iteration 173/250, Loss: 0.0244\n",
      "Epoch 56/200, Iteration 174/250, Loss: 0.0125\n",
      "Epoch 56/200, Iteration 175/250, Loss: 0.0690\n",
      "Epoch 56/200, Iteration 176/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 177/250, Loss: 0.0114\n",
      "Epoch 56/200, Iteration 178/250, Loss: 0.0135\n",
      "Epoch 56/200, Iteration 179/250, Loss: 0.0119\n",
      "Epoch 56/200, Iteration 180/250, Loss: 0.0115\n",
      "Epoch 56/200, Iteration 181/250, Loss: 0.0199\n",
      "Epoch 56/200, Iteration 182/250, Loss: 0.0104\n",
      "Epoch 56/200, Iteration 183/250, Loss: 0.0131\n",
      "Epoch 56/200, Iteration 184/250, Loss: 0.0176\n",
      "Epoch 56/200, Iteration 185/250, Loss: 0.0141\n",
      "Epoch 56/200, Iteration 186/250, Loss: 0.0108\n",
      "Epoch 56/200, Iteration 187/250, Loss: 0.0118\n",
      "Epoch 56/200, Iteration 188/250, Loss: 0.0302\n",
      "Epoch 56/200, Iteration 189/250, Loss: 0.0106\n",
      "Epoch 56/200, Iteration 190/250, Loss: 0.0142\n",
      "Epoch 56/200, Iteration 191/250, Loss: 0.0196\n",
      "Epoch 56/200, Iteration 192/250, Loss: 0.0332\n",
      "Epoch 56/200, Iteration 193/250, Loss: 0.0180\n",
      "Epoch 56/200, Iteration 194/250, Loss: 0.0272\n",
      "Epoch 56/200, Iteration 195/250, Loss: 0.0230\n",
      "Epoch 56/200, Iteration 196/250, Loss: 0.0099\n",
      "Epoch 56/200, Iteration 197/250, Loss: 0.0236\n",
      "Epoch 56/200, Iteration 198/250, Loss: 0.0147\n",
      "Epoch 56/200, Iteration 199/250, Loss: 0.0161\n",
      "Epoch 56/200, Iteration 200/250, Loss: 0.0135\n",
      "Epoch 56/200, Iteration 201/250, Loss: 0.0154\n",
      "Epoch 56/200, Iteration 202/250, Loss: 0.0120\n",
      "Epoch 56/200, Iteration 203/250, Loss: 0.0282\n",
      "Epoch 56/200, Iteration 204/250, Loss: 0.0171\n",
      "Epoch 56/200, Iteration 205/250, Loss: 0.0111\n",
      "Epoch 56/200, Iteration 206/250, Loss: 0.0132\n",
      "Epoch 56/200, Iteration 207/250, Loss: 0.0158\n",
      "Epoch 56/200, Iteration 208/250, Loss: 0.0224\n",
      "Epoch 56/200, Iteration 209/250, Loss: 0.0091\n",
      "Epoch 56/200, Iteration 210/250, Loss: 0.0102\n",
      "Epoch 56/200, Iteration 211/250, Loss: 0.0138\n",
      "Epoch 56/200, Iteration 212/250, Loss: 0.0182\n",
      "Epoch 56/200, Iteration 213/250, Loss: 0.0121\n",
      "Epoch 56/200, Iteration 214/250, Loss: 0.0102\n",
      "Epoch 56/200, Iteration 215/250, Loss: 0.0109\n",
      "Epoch 56/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 56/200, Iteration 217/250, Loss: 0.0189\n",
      "Epoch 56/200, Iteration 218/250, Loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Iteration 219/250, Loss: 0.0170\n",
      "Epoch 56/200, Iteration 220/250, Loss: 0.0079\n",
      "Epoch 56/200, Iteration 221/250, Loss: 0.0246\n",
      "Epoch 56/200, Iteration 222/250, Loss: 0.0425\n",
      "Epoch 56/200, Iteration 223/250, Loss: 0.0168\n",
      "Epoch 56/200, Iteration 224/250, Loss: 0.0144\n",
      "Epoch 56/200, Iteration 225/250, Loss: 0.0179\n",
      "Epoch 56/200, Iteration 226/250, Loss: 0.0289\n",
      "Epoch 56/200, Iteration 227/250, Loss: 0.0124\n",
      "Epoch 56/200, Iteration 228/250, Loss: 0.0094\n",
      "Epoch 56/200, Iteration 229/250, Loss: 0.0179\n",
      "Epoch 56/200, Iteration 230/250, Loss: 0.0278\n",
      "Epoch 56/200, Iteration 231/250, Loss: 0.0097\n",
      "Epoch 56/200, Iteration 232/250, Loss: 0.0139\n",
      "Epoch 56/200, Iteration 233/250, Loss: 0.0168\n",
      "Epoch 56/200, Iteration 234/250, Loss: 0.0161\n",
      "Epoch 56/200, Iteration 235/250, Loss: 0.0167\n",
      "Epoch 56/200, Iteration 236/250, Loss: 0.0112\n",
      "Epoch 56/200, Iteration 237/250, Loss: 0.0185\n",
      "Epoch 56/200, Iteration 238/250, Loss: 0.0112\n",
      "Epoch 56/200, Iteration 239/250, Loss: 0.0147\n",
      "Epoch 56/200, Iteration 240/250, Loss: 0.0233\n",
      "Epoch 56/200, Iteration 241/250, Loss: 0.0089\n",
      "Epoch 56/200, Iteration 242/250, Loss: 0.0169\n",
      "Epoch 56/200, Iteration 243/250, Loss: 0.0177\n",
      "Epoch 56/200, Iteration 244/250, Loss: 0.0134\n",
      "Epoch 56/200, Iteration 245/250, Loss: 0.0205\n",
      "Epoch 56/200, Iteration 246/250, Loss: 0.0378\n",
      "Epoch 56/200, Iteration 247/250, Loss: 0.0133\n",
      "Epoch 56/200, Iteration 248/250, Loss: 0.0136\n",
      "Epoch 56/200, Iteration 249/250, Loss: 0.0137\n",
      "Epoch 56/200, Iteration 250/250, Loss: 0.0353\n",
      "Train Error: \n",
      " Accuracy: 70.91%, Avg loss: 0.009122, MRE: 0.758149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.35%, Avg loss: 0.009420, MRE: 0.873343 \n",
      "\n",
      "Epoch 57/200, Iteration 1/250, Loss: 0.0116\n",
      "Epoch 57/200, Iteration 2/250, Loss: 0.0264\n",
      "Epoch 57/200, Iteration 3/250, Loss: 0.0140\n",
      "Epoch 57/200, Iteration 4/250, Loss: 0.0167\n",
      "Epoch 57/200, Iteration 5/250, Loss: 0.0092\n",
      "Epoch 57/200, Iteration 6/250, Loss: 0.0223\n",
      "Epoch 57/200, Iteration 7/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 8/250, Loss: 0.0117\n",
      "Epoch 57/200, Iteration 9/250, Loss: 0.0195\n",
      "Epoch 57/200, Iteration 10/250, Loss: 0.0191\n",
      "Epoch 57/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 57/200, Iteration 12/250, Loss: 0.0280\n",
      "Epoch 57/200, Iteration 13/250, Loss: 0.0260\n",
      "Epoch 57/200, Iteration 14/250, Loss: 0.0225\n",
      "Epoch 57/200, Iteration 15/250, Loss: 0.0081\n",
      "Epoch 57/200, Iteration 16/250, Loss: 0.0098\n",
      "Epoch 57/200, Iteration 17/250, Loss: 0.0317\n",
      "Epoch 57/200, Iteration 18/250, Loss: 0.0131\n",
      "Epoch 57/200, Iteration 19/250, Loss: 0.0311\n",
      "Epoch 57/200, Iteration 20/250, Loss: 0.0216\n",
      "Epoch 57/200, Iteration 21/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 22/250, Loss: 0.0116\n",
      "Epoch 57/200, Iteration 23/250, Loss: 0.0289\n",
      "Epoch 57/200, Iteration 24/250, Loss: 0.0122\n",
      "Epoch 57/200, Iteration 25/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 26/250, Loss: 0.0356\n",
      "Epoch 57/200, Iteration 27/250, Loss: 0.0181\n",
      "Epoch 57/200, Iteration 28/250, Loss: 0.0150\n",
      "Epoch 57/200, Iteration 29/250, Loss: 0.0126\n",
      "Epoch 57/200, Iteration 30/250, Loss: 0.0129\n",
      "Epoch 57/200, Iteration 31/250, Loss: 0.0193\n",
      "Epoch 57/200, Iteration 32/250, Loss: 0.0119\n",
      "Epoch 57/200, Iteration 33/250, Loss: 0.0259\n",
      "Epoch 57/200, Iteration 34/250, Loss: 0.0117\n",
      "Epoch 57/200, Iteration 35/250, Loss: 0.0144\n",
      "Epoch 57/200, Iteration 36/250, Loss: 0.0176\n",
      "Epoch 57/200, Iteration 37/250, Loss: 0.0187\n",
      "Epoch 57/200, Iteration 38/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 39/250, Loss: 0.0441\n",
      "Epoch 57/200, Iteration 40/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 41/250, Loss: 0.0110\n",
      "Epoch 57/200, Iteration 42/250, Loss: 0.0110\n",
      "Epoch 57/200, Iteration 43/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 44/250, Loss: 0.0214\n",
      "Epoch 57/200, Iteration 45/250, Loss: 0.0117\n",
      "Epoch 57/200, Iteration 46/250, Loss: 0.0135\n",
      "Epoch 57/200, Iteration 47/250, Loss: 0.0100\n",
      "Epoch 57/200, Iteration 48/250, Loss: 0.0178\n",
      "Epoch 57/200, Iteration 49/250, Loss: 0.0108\n",
      "Epoch 57/200, Iteration 50/250, Loss: 0.0107\n",
      "Epoch 57/200, Iteration 51/250, Loss: 0.0126\n",
      "Epoch 57/200, Iteration 52/250, Loss: 0.0258\n",
      "Epoch 57/200, Iteration 53/250, Loss: 0.0069\n",
      "Epoch 57/200, Iteration 54/250, Loss: 0.0087\n",
      "Epoch 57/200, Iteration 55/250, Loss: 0.0124\n",
      "Epoch 57/200, Iteration 56/250, Loss: 0.0150\n",
      "Epoch 57/200, Iteration 57/250, Loss: 0.0376\n",
      "Epoch 57/200, Iteration 58/250, Loss: 0.0094\n",
      "Epoch 57/200, Iteration 59/250, Loss: 0.0137\n",
      "Epoch 57/200, Iteration 60/250, Loss: 0.0100\n",
      "Epoch 57/200, Iteration 61/250, Loss: 0.0185\n",
      "Epoch 57/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 57/200, Iteration 63/250, Loss: 0.0181\n",
      "Epoch 57/200, Iteration 64/250, Loss: 0.0080\n",
      "Epoch 57/200, Iteration 65/250, Loss: 0.0193\n",
      "Epoch 57/200, Iteration 66/250, Loss: 0.0090\n",
      "Epoch 57/200, Iteration 67/250, Loss: 0.0124\n",
      "Epoch 57/200, Iteration 68/250, Loss: 0.0423\n",
      "Epoch 57/200, Iteration 69/250, Loss: 0.0118\n",
      "Epoch 57/200, Iteration 70/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 71/250, Loss: 0.0340\n",
      "Epoch 57/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 73/250, Loss: 0.0136\n",
      "Epoch 57/200, Iteration 74/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 75/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 76/250, Loss: 0.0160\n",
      "Epoch 57/200, Iteration 77/250, Loss: 0.0118\n",
      "Epoch 57/200, Iteration 78/250, Loss: 0.0099\n",
      "Epoch 57/200, Iteration 79/250, Loss: 0.0245\n",
      "Epoch 57/200, Iteration 80/250, Loss: 0.0133\n",
      "Epoch 57/200, Iteration 81/250, Loss: 0.0157\n",
      "Epoch 57/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 83/250, Loss: 0.0235\n",
      "Epoch 57/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 57/200, Iteration 85/250, Loss: 0.0187\n",
      "Epoch 57/200, Iteration 86/250, Loss: 0.0130\n",
      "Epoch 57/200, Iteration 87/250, Loss: 0.0203\n",
      "Epoch 57/200, Iteration 88/250, Loss: 0.0103\n",
      "Epoch 57/200, Iteration 89/250, Loss: 0.0145\n",
      "Epoch 57/200, Iteration 90/250, Loss: 0.0276\n",
      "Epoch 57/200, Iteration 91/250, Loss: 0.0350\n",
      "Epoch 57/200, Iteration 92/250, Loss: 0.0152\n",
      "Epoch 57/200, Iteration 93/250, Loss: 0.0171\n",
      "Epoch 57/200, Iteration 94/250, Loss: 0.0116\n",
      "Epoch 57/200, Iteration 95/250, Loss: 0.0094\n",
      "Epoch 57/200, Iteration 96/250, Loss: 0.0269\n",
      "Epoch 57/200, Iteration 97/250, Loss: 0.0180\n",
      "Epoch 57/200, Iteration 98/250, Loss: 0.0171\n",
      "Epoch 57/200, Iteration 99/250, Loss: 0.0255\n",
      "Epoch 57/200, Iteration 100/250, Loss: 0.0217\n",
      "Epoch 57/200, Iteration 101/250, Loss: 0.0111\n",
      "Epoch 57/200, Iteration 102/250, Loss: 0.0177\n",
      "Epoch 57/200, Iteration 103/250, Loss: 0.0179\n",
      "Epoch 57/200, Iteration 104/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 105/250, Loss: 0.0118\n",
      "Epoch 57/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 57/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 57/200, Iteration 108/250, Loss: 0.0089\n",
      "Epoch 57/200, Iteration 109/250, Loss: 0.0130\n",
      "Epoch 57/200, Iteration 110/250, Loss: 0.0092\n",
      "Epoch 57/200, Iteration 111/250, Loss: 0.0239\n",
      "Epoch 57/200, Iteration 112/250, Loss: 0.0107\n",
      "Epoch 57/200, Iteration 113/250, Loss: 0.0152\n",
      "Epoch 57/200, Iteration 114/250, Loss: 0.0425\n",
      "Epoch 57/200, Iteration 115/250, Loss: 0.0103\n",
      "Epoch 57/200, Iteration 116/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 117/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 118/250, Loss: 0.0112\n",
      "Epoch 57/200, Iteration 119/250, Loss: 0.0190\n",
      "Epoch 57/200, Iteration 120/250, Loss: 0.0106\n",
      "Epoch 57/200, Iteration 121/250, Loss: 0.0072\n",
      "Epoch 57/200, Iteration 122/250, Loss: 0.0154\n",
      "Epoch 57/200, Iteration 123/250, Loss: 0.0427\n",
      "Epoch 57/200, Iteration 124/250, Loss: 0.0270\n",
      "Epoch 57/200, Iteration 125/250, Loss: 0.0091\n",
      "Epoch 57/200, Iteration 126/250, Loss: 0.0098\n",
      "Epoch 57/200, Iteration 127/250, Loss: 0.0287\n",
      "Epoch 57/200, Iteration 128/250, Loss: 0.0092\n",
      "Epoch 57/200, Iteration 129/250, Loss: 0.0271\n",
      "Epoch 57/200, Iteration 130/250, Loss: 0.0144\n",
      "Epoch 57/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 57/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 57/200, Iteration 133/250, Loss: 0.0280\n",
      "Epoch 57/200, Iteration 134/250, Loss: 0.0090\n",
      "Epoch 57/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 136/250, Loss: 0.0411\n",
      "Epoch 57/200, Iteration 137/250, Loss: 0.0132\n",
      "Epoch 57/200, Iteration 138/250, Loss: 0.0105\n",
      "Epoch 57/200, Iteration 139/250, Loss: 0.0155\n",
      "Epoch 57/200, Iteration 140/250, Loss: 0.0176\n",
      "Epoch 57/200, Iteration 141/250, Loss: 0.0178\n",
      "Epoch 57/200, Iteration 142/250, Loss: 0.0115\n",
      "Epoch 57/200, Iteration 143/250, Loss: 0.0114\n",
      "Epoch 57/200, Iteration 144/250, Loss: 0.0133\n",
      "Epoch 57/200, Iteration 145/250, Loss: 0.0102\n",
      "Epoch 57/200, Iteration 146/250, Loss: 0.0217\n",
      "Epoch 57/200, Iteration 147/250, Loss: 0.0143\n",
      "Epoch 57/200, Iteration 148/250, Loss: 0.0102\n",
      "Epoch 57/200, Iteration 149/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 57/200, Iteration 151/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 152/250, Loss: 0.0091\n",
      "Epoch 57/200, Iteration 153/250, Loss: 0.0305\n",
      "Epoch 57/200, Iteration 154/250, Loss: 0.0149\n",
      "Epoch 57/200, Iteration 155/250, Loss: 0.0097\n",
      "Epoch 57/200, Iteration 156/250, Loss: 0.0350\n",
      "Epoch 57/200, Iteration 157/250, Loss: 0.0177\n",
      "Epoch 57/200, Iteration 158/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 159/250, Loss: 0.0305\n",
      "Epoch 57/200, Iteration 160/250, Loss: 0.0081\n",
      "Epoch 57/200, Iteration 161/250, Loss: 0.0121\n",
      "Epoch 57/200, Iteration 162/250, Loss: 0.0133\n",
      "Epoch 57/200, Iteration 163/250, Loss: 0.0146\n",
      "Epoch 57/200, Iteration 164/250, Loss: 0.0081\n",
      "Epoch 57/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 57/200, Iteration 166/250, Loss: 0.0114\n",
      "Epoch 57/200, Iteration 167/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 168/250, Loss: 0.0191\n",
      "Epoch 57/200, Iteration 169/250, Loss: 0.0194\n",
      "Epoch 57/200, Iteration 170/250, Loss: 0.0198\n",
      "Epoch 57/200, Iteration 171/250, Loss: 0.0221\n",
      "Epoch 57/200, Iteration 172/250, Loss: 0.0203\n",
      "Epoch 57/200, Iteration 173/250, Loss: 0.0491\n",
      "Epoch 57/200, Iteration 174/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 175/250, Loss: 0.0431\n",
      "Epoch 57/200, Iteration 176/250, Loss: 0.0127\n",
      "Epoch 57/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 178/250, Loss: 0.0289\n",
      "Epoch 57/200, Iteration 179/250, Loss: 0.0173\n",
      "Epoch 57/200, Iteration 180/250, Loss: 0.0145\n",
      "Epoch 57/200, Iteration 181/250, Loss: 0.0160\n",
      "Epoch 57/200, Iteration 182/250, Loss: 0.0183\n",
      "Epoch 57/200, Iteration 183/250, Loss: 0.0153\n",
      "Epoch 57/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 185/250, Loss: 0.0082\n",
      "Epoch 57/200, Iteration 186/250, Loss: 0.0127\n",
      "Epoch 57/200, Iteration 187/250, Loss: 0.0180\n",
      "Epoch 57/200, Iteration 188/250, Loss: 0.0161\n",
      "Epoch 57/200, Iteration 189/250, Loss: 0.0186\n",
      "Epoch 57/200, Iteration 190/250, Loss: 0.0129\n",
      "Epoch 57/200, Iteration 191/250, Loss: 0.0150\n",
      "Epoch 57/200, Iteration 192/250, Loss: 0.0367\n",
      "Epoch 57/200, Iteration 193/250, Loss: 0.0147\n",
      "Epoch 57/200, Iteration 194/250, Loss: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Iteration 195/250, Loss: 0.0153\n",
      "Epoch 57/200, Iteration 196/250, Loss: 0.0131\n",
      "Epoch 57/200, Iteration 197/250, Loss: 0.0234\n",
      "Epoch 57/200, Iteration 198/250, Loss: 0.0376\n",
      "Epoch 57/200, Iteration 199/250, Loss: 0.0163\n",
      "Epoch 57/200, Iteration 200/250, Loss: 0.0184\n",
      "Epoch 57/200, Iteration 201/250, Loss: 0.0244\n",
      "Epoch 57/200, Iteration 202/250, Loss: 0.0210\n",
      "Epoch 57/200, Iteration 203/250, Loss: 0.0107\n",
      "Epoch 57/200, Iteration 204/250, Loss: 0.0218\n",
      "Epoch 57/200, Iteration 205/250, Loss: 0.0122\n",
      "Epoch 57/200, Iteration 206/250, Loss: 0.0348\n",
      "Epoch 57/200, Iteration 207/250, Loss: 0.0312\n",
      "Epoch 57/200, Iteration 208/250, Loss: 0.0221\n",
      "Epoch 57/200, Iteration 209/250, Loss: 0.0197\n",
      "Epoch 57/200, Iteration 210/250, Loss: 0.0128\n",
      "Epoch 57/200, Iteration 211/250, Loss: 0.0079\n",
      "Epoch 57/200, Iteration 212/250, Loss: 0.0139\n",
      "Epoch 57/200, Iteration 213/250, Loss: 0.0124\n",
      "Epoch 57/200, Iteration 214/250, Loss: 0.0415\n",
      "Epoch 57/200, Iteration 215/250, Loss: 0.0085\n",
      "Epoch 57/200, Iteration 216/250, Loss: 0.0234\n",
      "Epoch 57/200, Iteration 217/250, Loss: 0.0206\n",
      "Epoch 57/200, Iteration 218/250, Loss: 0.0132\n",
      "Epoch 57/200, Iteration 219/250, Loss: 0.0209\n",
      "Epoch 57/200, Iteration 220/250, Loss: 0.0134\n",
      "Epoch 57/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 57/200, Iteration 222/250, Loss: 0.0176\n",
      "Epoch 57/200, Iteration 223/250, Loss: 0.0185\n",
      "Epoch 57/200, Iteration 224/250, Loss: 0.0223\n",
      "Epoch 57/200, Iteration 225/250, Loss: 0.0277\n",
      "Epoch 57/200, Iteration 226/250, Loss: 0.0082\n",
      "Epoch 57/200, Iteration 227/250, Loss: 0.0168\n",
      "Epoch 57/200, Iteration 228/250, Loss: 0.0136\n",
      "Epoch 57/200, Iteration 229/250, Loss: 0.0141\n",
      "Epoch 57/200, Iteration 230/250, Loss: 0.0102\n",
      "Epoch 57/200, Iteration 231/250, Loss: 0.0184\n",
      "Epoch 57/200, Iteration 232/250, Loss: 0.0396\n",
      "Epoch 57/200, Iteration 233/250, Loss: 0.0102\n",
      "Epoch 57/200, Iteration 234/250, Loss: 0.0274\n",
      "Epoch 57/200, Iteration 235/250, Loss: 0.0098\n",
      "Epoch 57/200, Iteration 236/250, Loss: 0.0068\n",
      "Epoch 57/200, Iteration 237/250, Loss: 0.0189\n",
      "Epoch 57/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 57/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 57/200, Iteration 240/250, Loss: 0.0125\n",
      "Epoch 57/200, Iteration 241/250, Loss: 0.0088\n",
      "Epoch 57/200, Iteration 242/250, Loss: 0.0167\n",
      "Epoch 57/200, Iteration 243/250, Loss: 0.0194\n",
      "Epoch 57/200, Iteration 244/250, Loss: 0.0214\n",
      "Epoch 57/200, Iteration 245/250, Loss: 0.0189\n",
      "Epoch 57/200, Iteration 246/250, Loss: 0.0246\n",
      "Epoch 57/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 57/200, Iteration 248/250, Loss: 0.0106\n",
      "Epoch 57/200, Iteration 249/250, Loss: 0.0172\n",
      "Epoch 57/200, Iteration 250/250, Loss: 0.0134\n",
      "Train Error: \n",
      " Accuracy: 78.31%, Avg loss: 0.008243, MRE: 0.428622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.008793, MRE: 0.556768 \n",
      "\n",
      "Epoch 58/200, Iteration 1/250, Loss: 0.0194\n",
      "Epoch 58/200, Iteration 2/250, Loss: 0.0155\n",
      "Epoch 58/200, Iteration 3/250, Loss: 0.0079\n",
      "Epoch 58/200, Iteration 4/250, Loss: 0.0106\n",
      "Epoch 58/200, Iteration 5/250, Loss: 0.0186\n",
      "Epoch 58/200, Iteration 6/250, Loss: 0.0182\n",
      "Epoch 58/200, Iteration 7/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 8/250, Loss: 0.0127\n",
      "Epoch 58/200, Iteration 9/250, Loss: 0.0081\n",
      "Epoch 58/200, Iteration 10/250, Loss: 0.0215\n",
      "Epoch 58/200, Iteration 11/250, Loss: 0.0126\n",
      "Epoch 58/200, Iteration 12/250, Loss: 0.0097\n",
      "Epoch 58/200, Iteration 13/250, Loss: 0.0077\n",
      "Epoch 58/200, Iteration 14/250, Loss: 0.0105\n",
      "Epoch 58/200, Iteration 15/250, Loss: 0.0293\n",
      "Epoch 58/200, Iteration 16/250, Loss: 0.0149\n",
      "Epoch 58/200, Iteration 17/250, Loss: 0.0194\n",
      "Epoch 58/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 19/250, Loss: 0.0135\n",
      "Epoch 58/200, Iteration 20/250, Loss: 0.0247\n",
      "Epoch 58/200, Iteration 21/250, Loss: 0.0159\n",
      "Epoch 58/200, Iteration 22/250, Loss: 0.0147\n",
      "Epoch 58/200, Iteration 23/250, Loss: 0.0159\n",
      "Epoch 58/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 25/250, Loss: 0.0225\n",
      "Epoch 58/200, Iteration 26/250, Loss: 0.0110\n",
      "Epoch 58/200, Iteration 27/250, Loss: 0.0082\n",
      "Epoch 58/200, Iteration 28/250, Loss: 0.0236\n",
      "Epoch 58/200, Iteration 29/250, Loss: 0.0323\n",
      "Epoch 58/200, Iteration 30/250, Loss: 0.0184\n",
      "Epoch 58/200, Iteration 31/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 32/250, Loss: 0.0191\n",
      "Epoch 58/200, Iteration 33/250, Loss: 0.0202\n",
      "Epoch 58/200, Iteration 34/250, Loss: 0.0122\n",
      "Epoch 58/200, Iteration 35/250, Loss: 0.0178\n",
      "Epoch 58/200, Iteration 36/250, Loss: 0.0257\n",
      "Epoch 58/200, Iteration 37/250, Loss: 0.0158\n",
      "Epoch 58/200, Iteration 38/250, Loss: 0.0233\n",
      "Epoch 58/200, Iteration 39/250, Loss: 0.0277\n",
      "Epoch 58/200, Iteration 40/250, Loss: 0.0110\n",
      "Epoch 58/200, Iteration 41/250, Loss: 0.0240\n",
      "Epoch 58/200, Iteration 42/250, Loss: 0.0243\n",
      "Epoch 58/200, Iteration 43/250, Loss: 0.0127\n",
      "Epoch 58/200, Iteration 44/250, Loss: 0.0306\n",
      "Epoch 58/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 58/200, Iteration 46/250, Loss: 0.0166\n",
      "Epoch 58/200, Iteration 47/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 48/250, Loss: 0.0070\n",
      "Epoch 58/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 58/200, Iteration 50/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 51/250, Loss: 0.0131\n",
      "Epoch 58/200, Iteration 52/250, Loss: 0.0125\n",
      "Epoch 58/200, Iteration 53/250, Loss: 0.0111\n",
      "Epoch 58/200, Iteration 54/250, Loss: 0.0107\n",
      "Epoch 58/200, Iteration 55/250, Loss: 0.0169\n",
      "Epoch 58/200, Iteration 56/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 57/250, Loss: 0.0203\n",
      "Epoch 58/200, Iteration 58/250, Loss: 0.0171\n",
      "Epoch 58/200, Iteration 59/250, Loss: 0.0202\n",
      "Epoch 58/200, Iteration 60/250, Loss: 0.0141\n",
      "Epoch 58/200, Iteration 61/250, Loss: 0.0206\n",
      "Epoch 58/200, Iteration 62/250, Loss: 0.0211\n",
      "Epoch 58/200, Iteration 63/250, Loss: 0.0180\n",
      "Epoch 58/200, Iteration 64/250, Loss: 0.0318\n",
      "Epoch 58/200, Iteration 65/250, Loss: 0.0162\n",
      "Epoch 58/200, Iteration 66/250, Loss: 0.0117\n",
      "Epoch 58/200, Iteration 67/250, Loss: 0.0298\n",
      "Epoch 58/200, Iteration 68/250, Loss: 0.0185\n",
      "Epoch 58/200, Iteration 69/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 70/250, Loss: 0.0148\n",
      "Epoch 58/200, Iteration 71/250, Loss: 0.0199\n",
      "Epoch 58/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 73/250, Loss: 0.0112\n",
      "Epoch 58/200, Iteration 74/250, Loss: 0.0207\n",
      "Epoch 58/200, Iteration 75/250, Loss: 0.0150\n",
      "Epoch 58/200, Iteration 76/250, Loss: 0.0115\n",
      "Epoch 58/200, Iteration 77/250, Loss: 0.0121\n",
      "Epoch 58/200, Iteration 78/250, Loss: 0.0230\n",
      "Epoch 58/200, Iteration 79/250, Loss: 0.0183\n",
      "Epoch 58/200, Iteration 80/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 58/200, Iteration 82/250, Loss: 0.0113\n",
      "Epoch 58/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 84/250, Loss: 0.0114\n",
      "Epoch 58/200, Iteration 85/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 86/250, Loss: 0.0104\n",
      "Epoch 58/200, Iteration 87/250, Loss: 0.0163\n",
      "Epoch 58/200, Iteration 88/250, Loss: 0.0119\n",
      "Epoch 58/200, Iteration 89/250, Loss: 0.0168\n",
      "Epoch 58/200, Iteration 90/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 91/250, Loss: 0.0231\n",
      "Epoch 58/200, Iteration 92/250, Loss: 0.0100\n",
      "Epoch 58/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 58/200, Iteration 94/250, Loss: 0.0126\n",
      "Epoch 58/200, Iteration 95/250, Loss: 0.0221\n",
      "Epoch 58/200, Iteration 96/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 97/250, Loss: 0.0364\n",
      "Epoch 58/200, Iteration 98/250, Loss: 0.0155\n",
      "Epoch 58/200, Iteration 99/250, Loss: 0.0351\n",
      "Epoch 58/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 58/200, Iteration 101/250, Loss: 0.0184\n",
      "Epoch 58/200, Iteration 102/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 103/250, Loss: 0.0234\n",
      "Epoch 58/200, Iteration 104/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 105/250, Loss: 0.0147\n",
      "Epoch 58/200, Iteration 106/250, Loss: 0.0151\n",
      "Epoch 58/200, Iteration 107/250, Loss: 0.0245\n",
      "Epoch 58/200, Iteration 108/250, Loss: 0.0135\n",
      "Epoch 58/200, Iteration 109/250, Loss: 0.0296\n",
      "Epoch 58/200, Iteration 110/250, Loss: 0.0191\n",
      "Epoch 58/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 58/200, Iteration 112/250, Loss: 0.0165\n",
      "Epoch 58/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 58/200, Iteration 114/250, Loss: 0.0110\n",
      "Epoch 58/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 58/200, Iteration 116/250, Loss: 0.0131\n",
      "Epoch 58/200, Iteration 117/250, Loss: 0.0268\n",
      "Epoch 58/200, Iteration 118/250, Loss: 0.0198\n",
      "Epoch 58/200, Iteration 119/250, Loss: 0.0208\n",
      "Epoch 58/200, Iteration 120/250, Loss: 0.0158\n",
      "Epoch 58/200, Iteration 121/250, Loss: 0.0138\n",
      "Epoch 58/200, Iteration 122/250, Loss: 0.0440\n",
      "Epoch 58/200, Iteration 123/250, Loss: 0.0146\n",
      "Epoch 58/200, Iteration 124/250, Loss: 0.0097\n",
      "Epoch 58/200, Iteration 125/250, Loss: 0.0195\n",
      "Epoch 58/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 58/200, Iteration 127/250, Loss: 0.0167\n",
      "Epoch 58/200, Iteration 128/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 129/250, Loss: 0.0206\n",
      "Epoch 58/200, Iteration 130/250, Loss: 0.0178\n",
      "Epoch 58/200, Iteration 131/250, Loss: 0.0158\n",
      "Epoch 58/200, Iteration 132/250, Loss: 0.0089\n",
      "Epoch 58/200, Iteration 133/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 134/250, Loss: 0.0137\n",
      "Epoch 58/200, Iteration 135/250, Loss: 0.0170\n",
      "Epoch 58/200, Iteration 136/250, Loss: 0.0154\n",
      "Epoch 58/200, Iteration 137/250, Loss: 0.0156\n",
      "Epoch 58/200, Iteration 138/250, Loss: 0.0224\n",
      "Epoch 58/200, Iteration 139/250, Loss: 0.0160\n",
      "Epoch 58/200, Iteration 140/250, Loss: 0.0160\n",
      "Epoch 58/200, Iteration 141/250, Loss: 0.0256\n",
      "Epoch 58/200, Iteration 142/250, Loss: 0.0184\n",
      "Epoch 58/200, Iteration 143/250, Loss: 0.0192\n",
      "Epoch 58/200, Iteration 144/250, Loss: 0.0102\n",
      "Epoch 58/200, Iteration 145/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 146/250, Loss: 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Iteration 147/250, Loss: 0.0102\n",
      "Epoch 58/200, Iteration 148/250, Loss: 0.0082\n",
      "Epoch 58/200, Iteration 149/250, Loss: 0.0178\n",
      "Epoch 58/200, Iteration 150/250, Loss: 0.0118\n",
      "Epoch 58/200, Iteration 151/250, Loss: 0.0097\n",
      "Epoch 58/200, Iteration 152/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 153/250, Loss: 0.0083\n",
      "Epoch 58/200, Iteration 154/250, Loss: 0.0177\n",
      "Epoch 58/200, Iteration 155/250, Loss: 0.0277\n",
      "Epoch 58/200, Iteration 156/250, Loss: 0.0119\n",
      "Epoch 58/200, Iteration 157/250, Loss: 0.0229\n",
      "Epoch 58/200, Iteration 158/250, Loss: 0.0132\n",
      "Epoch 58/200, Iteration 159/250, Loss: 0.0137\n",
      "Epoch 58/200, Iteration 160/250, Loss: 0.0156\n",
      "Epoch 58/200, Iteration 161/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 162/250, Loss: 0.0133\n",
      "Epoch 58/200, Iteration 163/250, Loss: 0.0149\n",
      "Epoch 58/200, Iteration 164/250, Loss: 0.0146\n",
      "Epoch 58/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 58/200, Iteration 166/250, Loss: 0.0139\n",
      "Epoch 58/200, Iteration 167/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 168/250, Loss: 0.0177\n",
      "Epoch 58/200, Iteration 169/250, Loss: 0.0113\n",
      "Epoch 58/200, Iteration 170/250, Loss: 0.0136\n",
      "Epoch 58/200, Iteration 171/250, Loss: 0.0165\n",
      "Epoch 58/200, Iteration 172/250, Loss: 0.0096\n",
      "Epoch 58/200, Iteration 173/250, Loss: 0.0320\n",
      "Epoch 58/200, Iteration 174/250, Loss: 0.0121\n",
      "Epoch 58/200, Iteration 175/250, Loss: 0.0231\n",
      "Epoch 58/200, Iteration 176/250, Loss: 0.0155\n",
      "Epoch 58/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 58/200, Iteration 178/250, Loss: 0.0282\n",
      "Epoch 58/200, Iteration 179/250, Loss: 0.0114\n",
      "Epoch 58/200, Iteration 180/250, Loss: 0.0104\n",
      "Epoch 58/200, Iteration 181/250, Loss: 0.0113\n",
      "Epoch 58/200, Iteration 182/250, Loss: 0.0124\n",
      "Epoch 58/200, Iteration 183/250, Loss: 0.0274\n",
      "Epoch 58/200, Iteration 184/250, Loss: 0.0169\n",
      "Epoch 58/200, Iteration 185/250, Loss: 0.0198\n",
      "Epoch 58/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 187/250, Loss: 0.0249\n",
      "Epoch 58/200, Iteration 188/250, Loss: 0.0238\n",
      "Epoch 58/200, Iteration 189/250, Loss: 0.0185\n",
      "Epoch 58/200, Iteration 190/250, Loss: 0.0188\n",
      "Epoch 58/200, Iteration 191/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 192/250, Loss: 0.0231\n",
      "Epoch 58/200, Iteration 193/250, Loss: 0.0183\n",
      "Epoch 58/200, Iteration 194/250, Loss: 0.0314\n",
      "Epoch 58/200, Iteration 195/250, Loss: 0.0215\n",
      "Epoch 58/200, Iteration 196/250, Loss: 0.0325\n",
      "Epoch 58/200, Iteration 197/250, Loss: 0.0147\n",
      "Epoch 58/200, Iteration 198/250, Loss: 0.0131\n",
      "Epoch 58/200, Iteration 199/250, Loss: 0.0188\n",
      "Epoch 58/200, Iteration 200/250, Loss: 0.0139\n",
      "Epoch 58/200, Iteration 201/250, Loss: 0.0257\n",
      "Epoch 58/200, Iteration 202/250, Loss: 0.0325\n",
      "Epoch 58/200, Iteration 203/250, Loss: 0.0178\n",
      "Epoch 58/200, Iteration 204/250, Loss: 0.0123\n",
      "Epoch 58/200, Iteration 205/250, Loss: 0.0122\n",
      "Epoch 58/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 58/200, Iteration 207/250, Loss: 0.0160\n",
      "Epoch 58/200, Iteration 208/250, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 209/250, Loss: 0.0119\n",
      "Epoch 58/200, Iteration 210/250, Loss: 0.0213\n",
      "Epoch 58/200, Iteration 211/250, Loss: 0.0177\n",
      "Epoch 58/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 58/200, Iteration 213/250, Loss: 0.0219\n",
      "Epoch 58/200, Iteration 214/250, Loss: 0.0088\n",
      "Epoch 58/200, Iteration 215/250, Loss: 0.0367\n",
      "Epoch 58/200, Iteration 216/250, Loss: 0.0232\n",
      "Epoch 58/200, Iteration 217/250, Loss: 0.0144\n",
      "Epoch 58/200, Iteration 218/250, Loss: 0.0140\n",
      "Epoch 58/200, Iteration 219/250, Loss: 0.0118\n",
      "Epoch 58/200, Iteration 220/250, Loss: 0.0147\n",
      "Epoch 58/200, Iteration 221/250, Loss: 0.0129\n",
      "Epoch 58/200, Iteration 222/250, Loss: 0.0109\n",
      "Epoch 58/200, Iteration 223/250, Loss: 0.0066\n",
      "Epoch 58/200, Iteration 224/250, Loss: 0.0068\n",
      "Epoch 58/200, Iteration 225/250, Loss: 0.0110\n",
      "Epoch 58/200, Iteration 226/250, Loss: 0.0122\n",
      "Epoch 58/200, Iteration 227/250, Loss: 0.0090\n",
      "Epoch 58/200, Iteration 228/250, Loss: 0.0252\n",
      "Epoch 58/200, Iteration 229/250, Loss: 0.0097\n",
      "Epoch 58/200, Iteration 230/250, Loss: 0.0422\n",
      "Epoch 58/200, Iteration 231/250, Loss: 0.0277\n",
      "Epoch 58/200, Iteration 232/250, Loss: 0.0127\n",
      "Epoch 58/200, Iteration 233/250, Loss: 0.0173\n",
      "Epoch 58/200, Iteration 234/250, Loss: 0.0255\n",
      "Epoch 58/200, Iteration 235/250, Loss: 0.0149\n",
      "Epoch 58/200, Iteration 236/250, Loss: 0.0143\n",
      "Epoch 58/200, Iteration 237/250, Loss: 0.0134\n",
      "Epoch 58/200, Iteration 238/250, Loss: 0.0128\n",
      "Epoch 58/200, Iteration 239/250, Loss: 0.0115\n",
      "Epoch 58/200, Iteration 240/250, Loss: 0.0218\n",
      "Epoch 58/200, Iteration 241/250, Loss: 0.0130\n",
      "Epoch 58/200, Iteration 242/250, Loss: 0.0213\n",
      "Epoch 58/200, Iteration 243/250, Loss: 0.0086\n",
      "Epoch 58/200, Iteration 244/250, Loss: 0.0268\n",
      "Epoch 58/200, Iteration 245/250, Loss: 0.0213\n",
      "Epoch 58/200, Iteration 246/250, Loss: 0.0180\n",
      "Epoch 58/200, Iteration 247/250, Loss: 0.0132\n",
      "Epoch 58/200, Iteration 248/250, Loss: 0.0116\n",
      "Epoch 58/200, Iteration 249/250, Loss: 0.0174\n",
      "Epoch 58/200, Iteration 250/250, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 84.17%, Avg loss: 0.008077, MRE: 0.555987 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.008523, MRE: 0.666095 \n",
      "\n",
      "Epoch 59/200, Iteration 1/250, Loss: 0.0075\n",
      "Epoch 59/200, Iteration 2/250, Loss: 0.0428\n",
      "Epoch 59/200, Iteration 3/250, Loss: 0.0199\n",
      "Epoch 59/200, Iteration 4/250, Loss: 0.0227\n",
      "Epoch 59/200, Iteration 5/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 6/250, Loss: 0.0186\n",
      "Epoch 59/200, Iteration 7/250, Loss: 0.0107\n",
      "Epoch 59/200, Iteration 8/250, Loss: 0.0098\n",
      "Epoch 59/200, Iteration 9/250, Loss: 0.0324\n",
      "Epoch 59/200, Iteration 10/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 11/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 12/250, Loss: 0.0190\n",
      "Epoch 59/200, Iteration 13/250, Loss: 0.0196\n",
      "Epoch 59/200, Iteration 14/250, Loss: 0.0116\n",
      "Epoch 59/200, Iteration 15/250, Loss: 0.0123\n",
      "Epoch 59/200, Iteration 16/250, Loss: 0.0092\n",
      "Epoch 59/200, Iteration 17/250, Loss: 0.0201\n",
      "Epoch 59/200, Iteration 18/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 59/200, Iteration 20/250, Loss: 0.0085\n",
      "Epoch 59/200, Iteration 21/250, Loss: 0.0258\n",
      "Epoch 59/200, Iteration 22/250, Loss: 0.0158\n",
      "Epoch 59/200, Iteration 23/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 59/200, Iteration 25/250, Loss: 0.0122\n",
      "Epoch 59/200, Iteration 26/250, Loss: 0.0157\n",
      "Epoch 59/200, Iteration 27/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 28/250, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 29/250, Loss: 0.0204\n",
      "Epoch 59/200, Iteration 30/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 31/250, Loss: 0.0153\n",
      "Epoch 59/200, Iteration 32/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 33/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 59/200, Iteration 35/250, Loss: 0.0190\n",
      "Epoch 59/200, Iteration 36/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 37/250, Loss: 0.0128\n",
      "Epoch 59/200, Iteration 38/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 39/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 40/250, Loss: 0.0150\n",
      "Epoch 59/200, Iteration 41/250, Loss: 0.0166\n",
      "Epoch 59/200, Iteration 42/250, Loss: 0.0313\n",
      "Epoch 59/200, Iteration 43/250, Loss: 0.0223\n",
      "Epoch 59/200, Iteration 44/250, Loss: 0.0196\n",
      "Epoch 59/200, Iteration 45/250, Loss: 0.0087\n",
      "Epoch 59/200, Iteration 46/250, Loss: 0.0287\n",
      "Epoch 59/200, Iteration 47/250, Loss: 0.0137\n",
      "Epoch 59/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 49/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 50/250, Loss: 0.0131\n",
      "Epoch 59/200, Iteration 51/250, Loss: 0.0085\n",
      "Epoch 59/200, Iteration 52/250, Loss: 0.0205\n",
      "Epoch 59/200, Iteration 53/250, Loss: 0.0118\n",
      "Epoch 59/200, Iteration 54/250, Loss: 0.0253\n",
      "Epoch 59/200, Iteration 55/250, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 56/250, Loss: 0.0126\n",
      "Epoch 59/200, Iteration 57/250, Loss: 0.0191\n",
      "Epoch 59/200, Iteration 58/250, Loss: 0.0088\n",
      "Epoch 59/200, Iteration 59/250, Loss: 0.0142\n",
      "Epoch 59/200, Iteration 60/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 61/250, Loss: 0.0125\n",
      "Epoch 59/200, Iteration 62/250, Loss: 0.0161\n",
      "Epoch 59/200, Iteration 63/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 59/200, Iteration 65/250, Loss: 0.0182\n",
      "Epoch 59/200, Iteration 66/250, Loss: 0.0147\n",
      "Epoch 59/200, Iteration 67/250, Loss: 0.0122\n",
      "Epoch 59/200, Iteration 68/250, Loss: 0.0331\n",
      "Epoch 59/200, Iteration 69/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 70/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 71/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 72/250, Loss: 0.0098\n",
      "Epoch 59/200, Iteration 73/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 74/250, Loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Iteration 75/250, Loss: 0.0155\n",
      "Epoch 59/200, Iteration 76/250, Loss: 0.0119\n",
      "Epoch 59/200, Iteration 77/250, Loss: 0.0133\n",
      "Epoch 59/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 59/200, Iteration 79/250, Loss: 0.0140\n",
      "Epoch 59/200, Iteration 80/250, Loss: 0.0365\n",
      "Epoch 59/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 59/200, Iteration 82/250, Loss: 0.0101\n",
      "Epoch 59/200, Iteration 83/250, Loss: 0.0248\n",
      "Epoch 59/200, Iteration 84/250, Loss: 0.0103\n",
      "Epoch 59/200, Iteration 85/250, Loss: 0.0224\n",
      "Epoch 59/200, Iteration 86/250, Loss: 0.0217\n",
      "Epoch 59/200, Iteration 87/250, Loss: 0.0117\n",
      "Epoch 59/200, Iteration 88/250, Loss: 0.0099\n",
      "Epoch 59/200, Iteration 89/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 90/250, Loss: 0.0175\n",
      "Epoch 59/200, Iteration 91/250, Loss: 0.0157\n",
      "Epoch 59/200, Iteration 92/250, Loss: 0.0256\n",
      "Epoch 59/200, Iteration 93/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 94/250, Loss: 0.0149\n",
      "Epoch 59/200, Iteration 95/250, Loss: 0.0074\n",
      "Epoch 59/200, Iteration 96/250, Loss: 0.0151\n",
      "Epoch 59/200, Iteration 97/250, Loss: 0.0199\n",
      "Epoch 59/200, Iteration 98/250, Loss: 0.0106\n",
      "Epoch 59/200, Iteration 99/250, Loss: 0.0083\n",
      "Epoch 59/200, Iteration 100/250, Loss: 0.0200\n",
      "Epoch 59/200, Iteration 101/250, Loss: 0.0274\n",
      "Epoch 59/200, Iteration 102/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 59/200, Iteration 104/250, Loss: 0.0129\n",
      "Epoch 59/200, Iteration 105/250, Loss: 0.0132\n",
      "Epoch 59/200, Iteration 106/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 107/250, Loss: 0.0117\n",
      "Epoch 59/200, Iteration 108/250, Loss: 0.0208\n",
      "Epoch 59/200, Iteration 109/250, Loss: 0.0129\n",
      "Epoch 59/200, Iteration 110/250, Loss: 0.0123\n",
      "Epoch 59/200, Iteration 111/250, Loss: 0.0168\n",
      "Epoch 59/200, Iteration 112/250, Loss: 0.0101\n",
      "Epoch 59/200, Iteration 113/250, Loss: 0.0107\n",
      "Epoch 59/200, Iteration 114/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 115/250, Loss: 0.0130\n",
      "Epoch 59/200, Iteration 116/250, Loss: 0.0128\n",
      "Epoch 59/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 59/200, Iteration 118/250, Loss: 0.0166\n",
      "Epoch 59/200, Iteration 119/250, Loss: 0.0076\n",
      "Epoch 59/200, Iteration 120/250, Loss: 0.0220\n",
      "Epoch 59/200, Iteration 121/250, Loss: 0.0147\n",
      "Epoch 59/200, Iteration 122/250, Loss: 0.0204\n",
      "Epoch 59/200, Iteration 123/250, Loss: 0.0115\n",
      "Epoch 59/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 59/200, Iteration 125/250, Loss: 0.0306\n",
      "Epoch 59/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 59/200, Iteration 127/250, Loss: 0.0121\n",
      "Epoch 59/200, Iteration 128/250, Loss: 0.0127\n",
      "Epoch 59/200, Iteration 129/250, Loss: 0.0176\n",
      "Epoch 59/200, Iteration 130/250, Loss: 0.0195\n",
      "Epoch 59/200, Iteration 131/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 132/250, Loss: 0.0130\n",
      "Epoch 59/200, Iteration 133/250, Loss: 0.0119\n",
      "Epoch 59/200, Iteration 134/250, Loss: 0.0202\n",
      "Epoch 59/200, Iteration 135/250, Loss: 0.0083\n",
      "Epoch 59/200, Iteration 136/250, Loss: 0.0079\n",
      "Epoch 59/200, Iteration 137/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 138/250, Loss: 0.0099\n",
      "Epoch 59/200, Iteration 139/250, Loss: 0.0090\n",
      "Epoch 59/200, Iteration 140/250, Loss: 0.0199\n",
      "Epoch 59/200, Iteration 141/250, Loss: 0.0179\n",
      "Epoch 59/200, Iteration 142/250, Loss: 0.0216\n",
      "Epoch 59/200, Iteration 143/250, Loss: 0.0116\n",
      "Epoch 59/200, Iteration 144/250, Loss: 0.0229\n",
      "Epoch 59/200, Iteration 145/250, Loss: 0.0119\n",
      "Epoch 59/200, Iteration 146/250, Loss: 0.0088\n",
      "Epoch 59/200, Iteration 147/250, Loss: 0.0096\n",
      "Epoch 59/200, Iteration 148/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 149/250, Loss: 0.0213\n",
      "Epoch 59/200, Iteration 150/250, Loss: 0.0236\n",
      "Epoch 59/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 59/200, Iteration 152/250, Loss: 0.0076\n",
      "Epoch 59/200, Iteration 153/250, Loss: 0.0169\n",
      "Epoch 59/200, Iteration 154/250, Loss: 0.0080\n",
      "Epoch 59/200, Iteration 155/250, Loss: 0.0291\n",
      "Epoch 59/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 59/200, Iteration 157/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 158/250, Loss: 0.0211\n",
      "Epoch 59/200, Iteration 159/250, Loss: 0.0116\n",
      "Epoch 59/200, Iteration 160/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 161/250, Loss: 0.0249\n",
      "Epoch 59/200, Iteration 162/250, Loss: 0.0088\n",
      "Epoch 59/200, Iteration 163/250, Loss: 0.0456\n",
      "Epoch 59/200, Iteration 164/250, Loss: 0.0143\n",
      "Epoch 59/200, Iteration 165/250, Loss: 0.0147\n",
      "Epoch 59/200, Iteration 166/250, Loss: 0.0164\n",
      "Epoch 59/200, Iteration 167/250, Loss: 0.0107\n",
      "Epoch 59/200, Iteration 168/250, Loss: 0.0268\n",
      "Epoch 59/200, Iteration 169/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 170/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 171/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 172/250, Loss: 0.0368\n",
      "Epoch 59/200, Iteration 173/250, Loss: 0.0307\n",
      "Epoch 59/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 59/200, Iteration 175/250, Loss: 0.0444\n",
      "Epoch 59/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 59/200, Iteration 177/250, Loss: 0.0286\n",
      "Epoch 59/200, Iteration 178/250, Loss: 0.0172\n",
      "Epoch 59/200, Iteration 179/250, Loss: 0.0174\n",
      "Epoch 59/200, Iteration 180/250, Loss: 0.0215\n",
      "Epoch 59/200, Iteration 181/250, Loss: 0.0208\n",
      "Epoch 59/200, Iteration 182/250, Loss: 0.0084\n",
      "Epoch 59/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 59/200, Iteration 184/250, Loss: 0.0148\n",
      "Epoch 59/200, Iteration 185/250, Loss: 0.0123\n",
      "Epoch 59/200, Iteration 186/250, Loss: 0.0144\n",
      "Epoch 59/200, Iteration 187/250, Loss: 0.0099\n",
      "Epoch 59/200, Iteration 188/250, Loss: 0.0152\n",
      "Epoch 59/200, Iteration 189/250, Loss: 0.0183\n",
      "Epoch 59/200, Iteration 190/250, Loss: 0.0223\n",
      "Epoch 59/200, Iteration 191/250, Loss: 0.0137\n",
      "Epoch 59/200, Iteration 192/250, Loss: 0.0164\n",
      "Epoch 59/200, Iteration 193/250, Loss: 0.0179\n",
      "Epoch 59/200, Iteration 194/250, Loss: 0.0092\n",
      "Epoch 59/200, Iteration 195/250, Loss: 0.0142\n",
      "Epoch 59/200, Iteration 196/250, Loss: 0.0570\n",
      "Epoch 59/200, Iteration 197/250, Loss: 0.0215\n",
      "Epoch 59/200, Iteration 198/250, Loss: 0.0100\n",
      "Epoch 59/200, Iteration 199/250, Loss: 0.0180\n",
      "Epoch 59/200, Iteration 200/250, Loss: 0.0423\n",
      "Epoch 59/200, Iteration 201/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 202/250, Loss: 0.0173\n",
      "Epoch 59/200, Iteration 203/250, Loss: 0.0160\n",
      "Epoch 59/200, Iteration 204/250, Loss: 0.0097\n",
      "Epoch 59/200, Iteration 205/250, Loss: 0.0194\n",
      "Epoch 59/200, Iteration 206/250, Loss: 0.0084\n",
      "Epoch 59/200, Iteration 207/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 208/250, Loss: 0.0187\n",
      "Epoch 59/200, Iteration 209/250, Loss: 0.0146\n",
      "Epoch 59/200, Iteration 210/250, Loss: 0.0089\n",
      "Epoch 59/200, Iteration 211/250, Loss: 0.0081\n",
      "Epoch 59/200, Iteration 212/250, Loss: 0.0195\n",
      "Epoch 59/200, Iteration 213/250, Loss: 0.0163\n",
      "Epoch 59/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 59/200, Iteration 215/250, Loss: 0.0234\n",
      "Epoch 59/200, Iteration 216/250, Loss: 0.0233\n",
      "Epoch 59/200, Iteration 217/250, Loss: 0.0156\n",
      "Epoch 59/200, Iteration 218/250, Loss: 0.0105\n",
      "Epoch 59/200, Iteration 219/250, Loss: 0.0159\n",
      "Epoch 59/200, Iteration 220/250, Loss: 0.0278\n",
      "Epoch 59/200, Iteration 221/250, Loss: 0.0093\n",
      "Epoch 59/200, Iteration 222/250, Loss: 0.0105\n",
      "Epoch 59/200, Iteration 223/250, Loss: 0.0301\n",
      "Epoch 59/200, Iteration 224/250, Loss: 0.0308\n",
      "Epoch 59/200, Iteration 225/250, Loss: 0.0174\n",
      "Epoch 59/200, Iteration 226/250, Loss: 0.0131\n",
      "Epoch 59/200, Iteration 227/250, Loss: 0.0141\n",
      "Epoch 59/200, Iteration 228/250, Loss: 0.0136\n",
      "Epoch 59/200, Iteration 229/250, Loss: 0.0194\n",
      "Epoch 59/200, Iteration 230/250, Loss: 0.0135\n",
      "Epoch 59/200, Iteration 231/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 232/250, Loss: 0.0179\n",
      "Epoch 59/200, Iteration 233/250, Loss: 0.0436\n",
      "Epoch 59/200, Iteration 234/250, Loss: 0.0098\n",
      "Epoch 59/200, Iteration 235/250, Loss: 0.0124\n",
      "Epoch 59/200, Iteration 236/250, Loss: 0.0113\n",
      "Epoch 59/200, Iteration 237/250, Loss: 0.0181\n",
      "Epoch 59/200, Iteration 238/250, Loss: 0.0141\n",
      "Epoch 59/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 59/200, Iteration 240/250, Loss: 0.0253\n",
      "Epoch 59/200, Iteration 241/250, Loss: 0.0149\n",
      "Epoch 59/200, Iteration 242/250, Loss: 0.0111\n",
      "Epoch 59/200, Iteration 243/250, Loss: 0.0160\n",
      "Epoch 59/200, Iteration 244/250, Loss: 0.0365\n",
      "Epoch 59/200, Iteration 245/250, Loss: 0.0178\n",
      "Epoch 59/200, Iteration 246/250, Loss: 0.0127\n",
      "Epoch 59/200, Iteration 247/250, Loss: 0.0102\n",
      "Epoch 59/200, Iteration 248/250, Loss: 0.0204\n",
      "Epoch 59/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 59/200, Iteration 250/250, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 74.67%, Avg loss: 0.008412, MRE: 0.622945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.95%, Avg loss: 0.008854, MRE: 0.701890 \n",
      "\n",
      "Epoch 60/200, Iteration 1/250, Loss: 0.0240\n",
      "Epoch 60/200, Iteration 2/250, Loss: 0.0126\n",
      "Epoch 60/200, Iteration 3/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 4/250, Loss: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 60/200, Iteration 6/250, Loss: 0.0072\n",
      "Epoch 60/200, Iteration 7/250, Loss: 0.0229\n",
      "Epoch 60/200, Iteration 8/250, Loss: 0.0214\n",
      "Epoch 60/200, Iteration 9/250, Loss: 0.0167\n",
      "Epoch 60/200, Iteration 10/250, Loss: 0.0125\n",
      "Epoch 60/200, Iteration 11/250, Loss: 0.0172\n",
      "Epoch 60/200, Iteration 12/250, Loss: 0.0165\n",
      "Epoch 60/200, Iteration 13/250, Loss: 0.0116\n",
      "Epoch 60/200, Iteration 14/250, Loss: 0.0080\n",
      "Epoch 60/200, Iteration 15/250, Loss: 0.0271\n",
      "Epoch 60/200, Iteration 16/250, Loss: 0.0145\n",
      "Epoch 60/200, Iteration 17/250, Loss: 0.0117\n",
      "Epoch 60/200, Iteration 18/250, Loss: 0.0155\n",
      "Epoch 60/200, Iteration 19/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 20/250, Loss: 0.0086\n",
      "Epoch 60/200, Iteration 21/250, Loss: 0.0123\n",
      "Epoch 60/200, Iteration 22/250, Loss: 0.0094\n",
      "Epoch 60/200, Iteration 23/250, Loss: 0.0227\n",
      "Epoch 60/200, Iteration 24/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 25/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 26/250, Loss: 0.0255\n",
      "Epoch 60/200, Iteration 27/250, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 28/250, Loss: 0.0104\n",
      "Epoch 60/200, Iteration 29/250, Loss: 0.0099\n",
      "Epoch 60/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 60/200, Iteration 31/250, Loss: 0.0214\n",
      "Epoch 60/200, Iteration 32/250, Loss: 0.0324\n",
      "Epoch 60/200, Iteration 33/250, Loss: 0.0213\n",
      "Epoch 60/200, Iteration 34/250, Loss: 0.0340\n",
      "Epoch 60/200, Iteration 35/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 36/250, Loss: 0.0132\n",
      "Epoch 60/200, Iteration 37/250, Loss: 0.0193\n",
      "Epoch 60/200, Iteration 38/250, Loss: 0.0116\n",
      "Epoch 60/200, Iteration 39/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 40/250, Loss: 0.0458\n",
      "Epoch 60/200, Iteration 41/250, Loss: 0.0345\n",
      "Epoch 60/200, Iteration 42/250, Loss: 0.0159\n",
      "Epoch 60/200, Iteration 43/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 44/250, Loss: 0.0135\n",
      "Epoch 60/200, Iteration 45/250, Loss: 0.0120\n",
      "Epoch 60/200, Iteration 46/250, Loss: 0.0127\n",
      "Epoch 60/200, Iteration 47/250, Loss: 0.0145\n",
      "Epoch 60/200, Iteration 48/250, Loss: 0.0265\n",
      "Epoch 60/200, Iteration 49/250, Loss: 0.0112\n",
      "Epoch 60/200, Iteration 50/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 51/250, Loss: 0.0113\n",
      "Epoch 60/200, Iteration 52/250, Loss: 0.0168\n",
      "Epoch 60/200, Iteration 53/250, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 54/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 55/250, Loss: 0.0183\n",
      "Epoch 60/200, Iteration 56/250, Loss: 0.0271\n",
      "Epoch 60/200, Iteration 57/250, Loss: 0.0390\n",
      "Epoch 60/200, Iteration 58/250, Loss: 0.0161\n",
      "Epoch 60/200, Iteration 59/250, Loss: 0.0135\n",
      "Epoch 60/200, Iteration 60/250, Loss: 0.0247\n",
      "Epoch 60/200, Iteration 61/250, Loss: 0.0272\n",
      "Epoch 60/200, Iteration 62/250, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 63/250, Loss: 0.0070\n",
      "Epoch 60/200, Iteration 64/250, Loss: 0.0186\n",
      "Epoch 60/200, Iteration 65/250, Loss: 0.0304\n",
      "Epoch 60/200, Iteration 66/250, Loss: 0.0130\n",
      "Epoch 60/200, Iteration 67/250, Loss: 0.0166\n",
      "Epoch 60/200, Iteration 68/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 69/250, Loss: 0.0268\n",
      "Epoch 60/200, Iteration 70/250, Loss: 0.0177\n",
      "Epoch 60/200, Iteration 71/250, Loss: 0.0182\n",
      "Epoch 60/200, Iteration 72/250, Loss: 0.0202\n",
      "Epoch 60/200, Iteration 73/250, Loss: 0.0322\n",
      "Epoch 60/200, Iteration 74/250, Loss: 0.0160\n",
      "Epoch 60/200, Iteration 75/250, Loss: 0.0083\n",
      "Epoch 60/200, Iteration 76/250, Loss: 0.0214\n",
      "Epoch 60/200, Iteration 77/250, Loss: 0.0150\n",
      "Epoch 60/200, Iteration 78/250, Loss: 0.0187\n",
      "Epoch 60/200, Iteration 79/250, Loss: 0.0081\n",
      "Epoch 60/200, Iteration 80/250, Loss: 0.0073\n",
      "Epoch 60/200, Iteration 81/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 60/200, Iteration 83/250, Loss: 0.0170\n",
      "Epoch 60/200, Iteration 84/250, Loss: 0.0132\n",
      "Epoch 60/200, Iteration 85/250, Loss: 0.0158\n",
      "Epoch 60/200, Iteration 86/250, Loss: 0.0140\n",
      "Epoch 60/200, Iteration 87/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 88/250, Loss: 0.0412\n",
      "Epoch 60/200, Iteration 89/250, Loss: 0.0120\n",
      "Epoch 60/200, Iteration 90/250, Loss: 0.0117\n",
      "Epoch 60/200, Iteration 91/250, Loss: 0.0126\n",
      "Epoch 60/200, Iteration 92/250, Loss: 0.0069\n",
      "Epoch 60/200, Iteration 93/250, Loss: 0.0131\n",
      "Epoch 60/200, Iteration 94/250, Loss: 0.0088\n",
      "Epoch 60/200, Iteration 95/250, Loss: 0.0283\n",
      "Epoch 60/200, Iteration 96/250, Loss: 0.0276\n",
      "Epoch 60/200, Iteration 97/250, Loss: 0.0250\n",
      "Epoch 60/200, Iteration 98/250, Loss: 0.0150\n",
      "Epoch 60/200, Iteration 99/250, Loss: 0.0168\n",
      "Epoch 60/200, Iteration 100/250, Loss: 0.0169\n",
      "Epoch 60/200, Iteration 101/250, Loss: 0.0306\n",
      "Epoch 60/200, Iteration 102/250, Loss: 0.0290\n",
      "Epoch 60/200, Iteration 103/250, Loss: 0.0276\n",
      "Epoch 60/200, Iteration 104/250, Loss: 0.0148\n",
      "Epoch 60/200, Iteration 105/250, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 106/250, Loss: 0.0233\n",
      "Epoch 60/200, Iteration 107/250, Loss: 0.0266\n",
      "Epoch 60/200, Iteration 108/250, Loss: 0.0098\n",
      "Epoch 60/200, Iteration 109/250, Loss: 0.0153\n",
      "Epoch 60/200, Iteration 110/250, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 111/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 112/250, Loss: 0.0113\n",
      "Epoch 60/200, Iteration 113/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 114/250, Loss: 0.0153\n",
      "Epoch 60/200, Iteration 115/250, Loss: 0.0245\n",
      "Epoch 60/200, Iteration 116/250, Loss: 0.0221\n",
      "Epoch 60/200, Iteration 117/250, Loss: 0.0190\n",
      "Epoch 60/200, Iteration 118/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 119/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 120/250, Loss: 0.0097\n",
      "Epoch 60/200, Iteration 121/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 122/250, Loss: 0.0131\n",
      "Epoch 60/200, Iteration 123/250, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 124/250, Loss: 0.0167\n",
      "Epoch 60/200, Iteration 125/250, Loss: 0.0274\n",
      "Epoch 60/200, Iteration 126/250, Loss: 0.0165\n",
      "Epoch 60/200, Iteration 127/250, Loss: 0.0238\n",
      "Epoch 60/200, Iteration 128/250, Loss: 0.0158\n",
      "Epoch 60/200, Iteration 129/250, Loss: 0.0141\n",
      "Epoch 60/200, Iteration 130/250, Loss: 0.0220\n",
      "Epoch 60/200, Iteration 131/250, Loss: 0.0094\n",
      "Epoch 60/200, Iteration 132/250, Loss: 0.0200\n",
      "Epoch 60/200, Iteration 133/250, Loss: 0.0093\n",
      "Epoch 60/200, Iteration 134/250, Loss: 0.0107\n",
      "Epoch 60/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 136/250, Loss: 0.0144\n",
      "Epoch 60/200, Iteration 137/250, Loss: 0.0317\n",
      "Epoch 60/200, Iteration 138/250, Loss: 0.0186\n",
      "Epoch 60/200, Iteration 139/250, Loss: 0.0065\n",
      "Epoch 60/200, Iteration 140/250, Loss: 0.0111\n",
      "Epoch 60/200, Iteration 141/250, Loss: 0.0268\n",
      "Epoch 60/200, Iteration 142/250, Loss: 0.0119\n",
      "Epoch 60/200, Iteration 143/250, Loss: 0.0183\n",
      "Epoch 60/200, Iteration 144/250, Loss: 0.0089\n",
      "Epoch 60/200, Iteration 145/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 146/250, Loss: 0.0056\n",
      "Epoch 60/200, Iteration 147/250, Loss: 0.0356\n",
      "Epoch 60/200, Iteration 148/250, Loss: 0.0119\n",
      "Epoch 60/200, Iteration 149/250, Loss: 0.0189\n",
      "Epoch 60/200, Iteration 150/250, Loss: 0.0123\n",
      "Epoch 60/200, Iteration 151/250, Loss: 0.0454\n",
      "Epoch 60/200, Iteration 152/250, Loss: 0.0205\n",
      "Epoch 60/200, Iteration 153/250, Loss: 0.0090\n",
      "Epoch 60/200, Iteration 154/250, Loss: 0.0149\n",
      "Epoch 60/200, Iteration 155/250, Loss: 0.0115\n",
      "Epoch 60/200, Iteration 156/250, Loss: 0.0196\n",
      "Epoch 60/200, Iteration 157/250, Loss: 0.0146\n",
      "Epoch 60/200, Iteration 158/250, Loss: 0.0227\n",
      "Epoch 60/200, Iteration 159/250, Loss: 0.0108\n",
      "Epoch 60/200, Iteration 160/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 162/250, Loss: 0.0114\n",
      "Epoch 60/200, Iteration 163/250, Loss: 0.0496\n",
      "Epoch 60/200, Iteration 164/250, Loss: 0.0261\n",
      "Epoch 60/200, Iteration 165/250, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 166/250, Loss: 0.0327\n",
      "Epoch 60/200, Iteration 167/250, Loss: 0.0141\n",
      "Epoch 60/200, Iteration 168/250, Loss: 0.0163\n",
      "Epoch 60/200, Iteration 169/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 170/250, Loss: 0.0083\n",
      "Epoch 60/200, Iteration 171/250, Loss: 0.0121\n",
      "Epoch 60/200, Iteration 172/250, Loss: 0.0109\n",
      "Epoch 60/200, Iteration 173/250, Loss: 0.0218\n",
      "Epoch 60/200, Iteration 174/250, Loss: 0.0287\n",
      "Epoch 60/200, Iteration 175/250, Loss: 0.0147\n",
      "Epoch 60/200, Iteration 176/250, Loss: 0.0232\n",
      "Epoch 60/200, Iteration 177/250, Loss: 0.0201\n",
      "Epoch 60/200, Iteration 178/250, Loss: 0.0141\n",
      "Epoch 60/200, Iteration 179/250, Loss: 0.0426\n",
      "Epoch 60/200, Iteration 180/250, Loss: 0.0111\n",
      "Epoch 60/200, Iteration 181/250, Loss: 0.0135\n",
      "Epoch 60/200, Iteration 182/250, Loss: 0.0156\n",
      "Epoch 60/200, Iteration 183/250, Loss: 0.0170\n",
      "Epoch 60/200, Iteration 184/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 185/250, Loss: 0.0307\n",
      "Epoch 60/200, Iteration 186/250, Loss: 0.0167\n",
      "Epoch 60/200, Iteration 187/250, Loss: 0.0201\n",
      "Epoch 60/200, Iteration 188/250, Loss: 0.0260\n",
      "Epoch 60/200, Iteration 189/250, Loss: 0.0153\n",
      "Epoch 60/200, Iteration 190/250, Loss: 0.0141\n",
      "Epoch 60/200, Iteration 191/250, Loss: 0.0182\n",
      "Epoch 60/200, Iteration 192/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 193/250, Loss: 0.0098\n",
      "Epoch 60/200, Iteration 194/250, Loss: 0.0166\n",
      "Epoch 60/200, Iteration 195/250, Loss: 0.0198\n",
      "Epoch 60/200, Iteration 196/250, Loss: 0.0127\n",
      "Epoch 60/200, Iteration 197/250, Loss: 0.0392\n",
      "Epoch 60/200, Iteration 198/250, Loss: 0.0287\n",
      "Epoch 60/200, Iteration 199/250, Loss: 0.0209\n",
      "Epoch 60/200, Iteration 200/250, Loss: 0.0086\n",
      "Epoch 60/200, Iteration 201/250, Loss: 0.0144\n",
      "Epoch 60/200, Iteration 202/250, Loss: 0.0123\n",
      "Epoch 60/200, Iteration 203/250, Loss: 0.0146\n",
      "Epoch 60/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 205/250, Loss: 0.0173\n",
      "Epoch 60/200, Iteration 206/250, Loss: 0.0300\n",
      "Epoch 60/200, Iteration 207/250, Loss: 0.0385\n",
      "Epoch 60/200, Iteration 208/250, Loss: 0.0178\n",
      "Epoch 60/200, Iteration 209/250, Loss: 0.0185\n",
      "Epoch 60/200, Iteration 210/250, Loss: 0.0114\n",
      "Epoch 60/200, Iteration 211/250, Loss: 0.0172\n",
      "Epoch 60/200, Iteration 212/250, Loss: 0.0092\n",
      "Epoch 60/200, Iteration 213/250, Loss: 0.0070\n",
      "Epoch 60/200, Iteration 214/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 215/250, Loss: 0.0084\n",
      "Epoch 60/200, Iteration 216/250, Loss: 0.0361\n",
      "Epoch 60/200, Iteration 217/250, Loss: 0.0300\n",
      "Epoch 60/200, Iteration 218/250, Loss: 0.0190\n",
      "Epoch 60/200, Iteration 219/250, Loss: 0.0128\n",
      "Epoch 60/200, Iteration 220/250, Loss: 0.0090\n",
      "Epoch 60/200, Iteration 221/250, Loss: 0.0105\n",
      "Epoch 60/200, Iteration 222/250, Loss: 0.0183\n",
      "Epoch 60/200, Iteration 223/250, Loss: 0.0516\n",
      "Epoch 60/200, Iteration 224/250, Loss: 0.0078\n",
      "Epoch 60/200, Iteration 225/250, Loss: 0.0122\n",
      "Epoch 60/200, Iteration 226/250, Loss: 0.0154\n",
      "Epoch 60/200, Iteration 227/250, Loss: 0.0334\n",
      "Epoch 60/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 60/200, Iteration 229/250, Loss: 0.0140\n",
      "Epoch 60/200, Iteration 230/250, Loss: 0.0104\n",
      "Epoch 60/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 60/200, Iteration 232/250, Loss: 0.0295\n",
      "Epoch 60/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 60/200, Iteration 234/250, Loss: 0.0131\n",
      "Epoch 60/200, Iteration 235/250, Loss: 0.0134\n",
      "Epoch 60/200, Iteration 236/250, Loss: 0.0138\n",
      "Epoch 60/200, Iteration 237/250, Loss: 0.0126\n",
      "Epoch 60/200, Iteration 238/250, Loss: 0.0205\n",
      "Epoch 60/200, Iteration 239/250, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Iteration 240/250, Loss: 0.0129\n",
      "Epoch 60/200, Iteration 241/250, Loss: 0.0168\n",
      "Epoch 60/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 60/200, Iteration 243/250, Loss: 0.0139\n",
      "Epoch 60/200, Iteration 244/250, Loss: 0.0127\n",
      "Epoch 60/200, Iteration 245/250, Loss: 0.0270\n",
      "Epoch 60/200, Iteration 246/250, Loss: 0.0296\n",
      "Epoch 60/200, Iteration 247/250, Loss: 0.0130\n",
      "Epoch 60/200, Iteration 248/250, Loss: 0.0254\n",
      "Epoch 60/200, Iteration 249/250, Loss: 0.0103\n",
      "Epoch 60/200, Iteration 250/250, Loss: 0.0095\n",
      "Train Error: \n",
      " Accuracy: 85.17%, Avg loss: 0.008077, MRE: 0.626446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.008675, MRE: 0.673282 \n",
      "\n",
      "Epoch 61/200, Iteration 1/250, Loss: 0.0179\n",
      "Epoch 61/200, Iteration 2/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 3/250, Loss: 0.0178\n",
      "Epoch 61/200, Iteration 4/250, Loss: 0.0103\n",
      "Epoch 61/200, Iteration 5/250, Loss: 0.0094\n",
      "Epoch 61/200, Iteration 6/250, Loss: 0.0195\n",
      "Epoch 61/200, Iteration 7/250, Loss: 0.0147\n",
      "Epoch 61/200, Iteration 8/250, Loss: 0.0128\n",
      "Epoch 61/200, Iteration 9/250, Loss: 0.0170\n",
      "Epoch 61/200, Iteration 10/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 11/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 61/200, Iteration 13/250, Loss: 0.0115\n",
      "Epoch 61/200, Iteration 14/250, Loss: 0.0084\n",
      "Epoch 61/200, Iteration 15/250, Loss: 0.0204\n",
      "Epoch 61/200, Iteration 16/250, Loss: 0.0080\n",
      "Epoch 61/200, Iteration 17/250, Loss: 0.0147\n",
      "Epoch 61/200, Iteration 18/250, Loss: 0.0148\n",
      "Epoch 61/200, Iteration 19/250, Loss: 0.0128\n",
      "Epoch 61/200, Iteration 20/250, Loss: 0.0101\n",
      "Epoch 61/200, Iteration 21/250, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 22/250, Loss: 0.0179\n",
      "Epoch 61/200, Iteration 23/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 24/250, Loss: 0.0334\n",
      "Epoch 61/200, Iteration 25/250, Loss: 0.0168\n",
      "Epoch 61/200, Iteration 26/250, Loss: 0.0080\n",
      "Epoch 61/200, Iteration 27/250, Loss: 0.0223\n",
      "Epoch 61/200, Iteration 28/250, Loss: 0.0238\n",
      "Epoch 61/200, Iteration 29/250, Loss: 0.0127\n",
      "Epoch 61/200, Iteration 30/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 31/250, Loss: 0.0129\n",
      "Epoch 61/200, Iteration 32/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 33/250, Loss: 0.0094\n",
      "Epoch 61/200, Iteration 34/250, Loss: 0.0305\n",
      "Epoch 61/200, Iteration 35/250, Loss: 0.0227\n",
      "Epoch 61/200, Iteration 36/250, Loss: 0.0062\n",
      "Epoch 61/200, Iteration 37/250, Loss: 0.0168\n",
      "Epoch 61/200, Iteration 38/250, Loss: 0.0109\n",
      "Epoch 61/200, Iteration 39/250, Loss: 0.0197\n",
      "Epoch 61/200, Iteration 40/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 61/200, Iteration 42/250, Loss: 0.0235\n",
      "Epoch 61/200, Iteration 43/250, Loss: 0.0158\n",
      "Epoch 61/200, Iteration 44/250, Loss: 0.0155\n",
      "Epoch 61/200, Iteration 45/250, Loss: 0.0124\n",
      "Epoch 61/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 47/250, Loss: 0.0169\n",
      "Epoch 61/200, Iteration 48/250, Loss: 0.0323\n",
      "Epoch 61/200, Iteration 49/250, Loss: 0.0105\n",
      "Epoch 61/200, Iteration 50/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 51/250, Loss: 0.0114\n",
      "Epoch 61/200, Iteration 52/250, Loss: 0.0121\n",
      "Epoch 61/200, Iteration 53/250, Loss: 0.0101\n",
      "Epoch 61/200, Iteration 54/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 55/250, Loss: 0.0134\n",
      "Epoch 61/200, Iteration 56/250, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 57/250, Loss: 0.0093\n",
      "Epoch 61/200, Iteration 58/250, Loss: 0.0240\n",
      "Epoch 61/200, Iteration 59/250, Loss: 0.0093\n",
      "Epoch 61/200, Iteration 60/250, Loss: 0.0311\n",
      "Epoch 61/200, Iteration 61/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 62/250, Loss: 0.0130\n",
      "Epoch 61/200, Iteration 63/250, Loss: 0.0084\n",
      "Epoch 61/200, Iteration 64/250, Loss: 0.0120\n",
      "Epoch 61/200, Iteration 65/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 66/250, Loss: 0.0183\n",
      "Epoch 61/200, Iteration 67/250, Loss: 0.0105\n",
      "Epoch 61/200, Iteration 68/250, Loss: 0.0309\n",
      "Epoch 61/200, Iteration 69/250, Loss: 0.0088\n",
      "Epoch 61/200, Iteration 70/250, Loss: 0.0163\n",
      "Epoch 61/200, Iteration 71/250, Loss: 0.0080\n",
      "Epoch 61/200, Iteration 72/250, Loss: 0.0121\n",
      "Epoch 61/200, Iteration 73/250, Loss: 0.0095\n",
      "Epoch 61/200, Iteration 74/250, Loss: 0.0140\n",
      "Epoch 61/200, Iteration 75/250, Loss: 0.0153\n",
      "Epoch 61/200, Iteration 76/250, Loss: 0.0075\n",
      "Epoch 61/200, Iteration 77/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 78/250, Loss: 0.0184\n",
      "Epoch 61/200, Iteration 79/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 80/250, Loss: 0.0397\n",
      "Epoch 61/200, Iteration 81/250, Loss: 0.0133\n",
      "Epoch 61/200, Iteration 82/250, Loss: 0.0318\n",
      "Epoch 61/200, Iteration 83/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 84/250, Loss: 0.0192\n",
      "Epoch 61/200, Iteration 85/250, Loss: 0.0286\n",
      "Epoch 61/200, Iteration 86/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 87/250, Loss: 0.0147\n",
      "Epoch 61/200, Iteration 88/250, Loss: 0.0227\n",
      "Epoch 61/200, Iteration 89/250, Loss: 0.0179\n",
      "Epoch 61/200, Iteration 90/250, Loss: 0.0201\n",
      "Epoch 61/200, Iteration 91/250, Loss: 0.0202\n",
      "Epoch 61/200, Iteration 92/250, Loss: 0.0177\n",
      "Epoch 61/200, Iteration 93/250, Loss: 0.0108\n",
      "Epoch 61/200, Iteration 94/250, Loss: 0.0154\n",
      "Epoch 61/200, Iteration 95/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 96/250, Loss: 0.0439\n",
      "Epoch 61/200, Iteration 97/250, Loss: 0.0136\n",
      "Epoch 61/200, Iteration 98/250, Loss: 0.0419\n",
      "Epoch 61/200, Iteration 99/250, Loss: 0.0132\n",
      "Epoch 61/200, Iteration 100/250, Loss: 0.0242\n",
      "Epoch 61/200, Iteration 101/250, Loss: 0.0157\n",
      "Epoch 61/200, Iteration 102/250, Loss: 0.0203\n",
      "Epoch 61/200, Iteration 103/250, Loss: 0.0102\n",
      "Epoch 61/200, Iteration 104/250, Loss: 0.0141\n",
      "Epoch 61/200, Iteration 105/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 106/250, Loss: 0.0135\n",
      "Epoch 61/200, Iteration 107/250, Loss: 0.0126\n",
      "Epoch 61/200, Iteration 108/250, Loss: 0.0108\n",
      "Epoch 61/200, Iteration 109/250, Loss: 0.0121\n",
      "Epoch 61/200, Iteration 110/250, Loss: 0.0185\n",
      "Epoch 61/200, Iteration 111/250, Loss: 0.0255\n",
      "Epoch 61/200, Iteration 112/250, Loss: 0.0188\n",
      "Epoch 61/200, Iteration 113/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 114/250, Loss: 0.0407\n",
      "Epoch 61/200, Iteration 115/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 116/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 117/250, Loss: 0.0093\n",
      "Epoch 61/200, Iteration 118/250, Loss: 0.0198\n",
      "Epoch 61/200, Iteration 119/250, Loss: 0.0154\n",
      "Epoch 61/200, Iteration 120/250, Loss: 0.0215\n",
      "Epoch 61/200, Iteration 121/250, Loss: 0.0277\n",
      "Epoch 61/200, Iteration 122/250, Loss: 0.0270\n",
      "Epoch 61/200, Iteration 123/250, Loss: 0.0211\n",
      "Epoch 61/200, Iteration 124/250, Loss: 0.0145\n",
      "Epoch 61/200, Iteration 125/250, Loss: 0.0120\n",
      "Epoch 61/200, Iteration 126/250, Loss: 0.0259\n",
      "Epoch 61/200, Iteration 127/250, Loss: 0.0201\n",
      "Epoch 61/200, Iteration 128/250, Loss: 0.0158\n",
      "Epoch 61/200, Iteration 129/250, Loss: 0.0194\n",
      "Epoch 61/200, Iteration 130/250, Loss: 0.0101\n",
      "Epoch 61/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 132/250, Loss: 0.0092\n",
      "Epoch 61/200, Iteration 133/250, Loss: 0.0185\n",
      "Epoch 61/200, Iteration 134/250, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 135/250, Loss: 0.0263\n",
      "Epoch 61/200, Iteration 136/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 137/250, Loss: 0.0150\n",
      "Epoch 61/200, Iteration 138/250, Loss: 0.0151\n",
      "Epoch 61/200, Iteration 139/250, Loss: 0.0129\n",
      "Epoch 61/200, Iteration 140/250, Loss: 0.0269\n",
      "Epoch 61/200, Iteration 141/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 142/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 61/200, Iteration 144/250, Loss: 0.0134\n",
      "Epoch 61/200, Iteration 145/250, Loss: 0.0337\n",
      "Epoch 61/200, Iteration 146/250, Loss: 0.0088\n",
      "Epoch 61/200, Iteration 147/250, Loss: 0.0197\n",
      "Epoch 61/200, Iteration 148/250, Loss: 0.0216\n",
      "Epoch 61/200, Iteration 149/250, Loss: 0.0180\n",
      "Epoch 61/200, Iteration 150/250, Loss: 0.0177\n",
      "Epoch 61/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 152/250, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 153/250, Loss: 0.0131\n",
      "Epoch 61/200, Iteration 154/250, Loss: 0.0130\n",
      "Epoch 61/200, Iteration 155/250, Loss: 0.0336\n",
      "Epoch 61/200, Iteration 156/250, Loss: 0.0100\n",
      "Epoch 61/200, Iteration 157/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 158/250, Loss: 0.0137\n",
      "Epoch 61/200, Iteration 159/250, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 160/250, Loss: 0.0243\n",
      "Epoch 61/200, Iteration 161/250, Loss: 0.0149\n",
      "Epoch 61/200, Iteration 162/250, Loss: 0.0263\n",
      "Epoch 61/200, Iteration 163/250, Loss: 0.0109\n",
      "Epoch 61/200, Iteration 164/250, Loss: 0.0167\n",
      "Epoch 61/200, Iteration 165/250, Loss: 0.0123\n",
      "Epoch 61/200, Iteration 166/250, Loss: 0.0160\n",
      "Epoch 61/200, Iteration 167/250, Loss: 0.0178\n",
      "Epoch 61/200, Iteration 168/250, Loss: 0.0210\n",
      "Epoch 61/200, Iteration 169/250, Loss: 0.0133\n",
      "Epoch 61/200, Iteration 170/250, Loss: 0.0096\n",
      "Epoch 61/200, Iteration 171/250, Loss: 0.0159\n",
      "Epoch 61/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 61/200, Iteration 173/250, Loss: 0.0085\n",
      "Epoch 61/200, Iteration 174/250, Loss: 0.0213\n",
      "Epoch 61/200, Iteration 175/250, Loss: 0.0063\n",
      "Epoch 61/200, Iteration 176/250, Loss: 0.0074\n",
      "Epoch 61/200, Iteration 177/250, Loss: 0.0136\n",
      "Epoch 61/200, Iteration 178/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 179/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 180/250, Loss: 0.0159\n",
      "Epoch 61/200, Iteration 181/250, Loss: 0.0223\n",
      "Epoch 61/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 61/200, Iteration 183/250, Loss: 0.0237\n",
      "Epoch 61/200, Iteration 184/250, Loss: 0.0156\n",
      "Epoch 61/200, Iteration 185/250, Loss: 0.0145\n",
      "Epoch 61/200, Iteration 186/250, Loss: 0.0239\n",
      "Epoch 61/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 188/250, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200, Iteration 189/250, Loss: 0.0236\n",
      "Epoch 61/200, Iteration 190/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 191/250, Loss: 0.0099\n",
      "Epoch 61/200, Iteration 192/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 193/250, Loss: 0.0249\n",
      "Epoch 61/200, Iteration 194/250, Loss: 0.0104\n",
      "Epoch 61/200, Iteration 195/250, Loss: 0.0331\n",
      "Epoch 61/200, Iteration 196/250, Loss: 0.0107\n",
      "Epoch 61/200, Iteration 197/250, Loss: 0.0146\n",
      "Epoch 61/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 61/200, Iteration 199/250, Loss: 0.0142\n",
      "Epoch 61/200, Iteration 200/250, Loss: 0.0138\n",
      "Epoch 61/200, Iteration 201/250, Loss: 0.0128\n",
      "Epoch 61/200, Iteration 202/250, Loss: 0.0083\n",
      "Epoch 61/200, Iteration 203/250, Loss: 0.0195\n",
      "Epoch 61/200, Iteration 204/250, Loss: 0.0265\n",
      "Epoch 61/200, Iteration 205/250, Loss: 0.0122\n",
      "Epoch 61/200, Iteration 206/250, Loss: 0.0261\n",
      "Epoch 61/200, Iteration 207/250, Loss: 0.0120\n",
      "Epoch 61/200, Iteration 208/250, Loss: 0.0207\n",
      "Epoch 61/200, Iteration 209/250, Loss: 0.0184\n",
      "Epoch 61/200, Iteration 210/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 211/250, Loss: 0.0325\n",
      "Epoch 61/200, Iteration 212/250, Loss: 0.0125\n",
      "Epoch 61/200, Iteration 213/250, Loss: 0.0321\n",
      "Epoch 61/200, Iteration 214/250, Loss: 0.0333\n",
      "Epoch 61/200, Iteration 215/250, Loss: 0.0119\n",
      "Epoch 61/200, Iteration 216/250, Loss: 0.0243\n",
      "Epoch 61/200, Iteration 217/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 218/250, Loss: 0.0162\n",
      "Epoch 61/200, Iteration 219/250, Loss: 0.0158\n",
      "Epoch 61/200, Iteration 220/250, Loss: 0.0152\n",
      "Epoch 61/200, Iteration 221/250, Loss: 0.0148\n",
      "Epoch 61/200, Iteration 222/250, Loss: 0.0341\n",
      "Epoch 61/200, Iteration 223/250, Loss: 0.0166\n",
      "Epoch 61/200, Iteration 224/250, Loss: 0.0116\n",
      "Epoch 61/200, Iteration 225/250, Loss: 0.0117\n",
      "Epoch 61/200, Iteration 226/250, Loss: 0.0258\n",
      "Epoch 61/200, Iteration 227/250, Loss: 0.0237\n",
      "Epoch 61/200, Iteration 228/250, Loss: 0.0334\n",
      "Epoch 61/200, Iteration 229/250, Loss: 0.0087\n",
      "Epoch 61/200, Iteration 230/250, Loss: 0.0254\n",
      "Epoch 61/200, Iteration 231/250, Loss: 0.0076\n",
      "Epoch 61/200, Iteration 232/250, Loss: 0.0118\n",
      "Epoch 61/200, Iteration 233/250, Loss: 0.0143\n",
      "Epoch 61/200, Iteration 234/250, Loss: 0.0213\n",
      "Epoch 61/200, Iteration 235/250, Loss: 0.0105\n",
      "Epoch 61/200, Iteration 236/250, Loss: 0.0106\n",
      "Epoch 61/200, Iteration 237/250, Loss: 0.0107\n",
      "Epoch 61/200, Iteration 238/250, Loss: 0.0185\n",
      "Epoch 61/200, Iteration 239/250, Loss: 0.0209\n",
      "Epoch 61/200, Iteration 240/250, Loss: 0.0165\n",
      "Epoch 61/200, Iteration 241/250, Loss: 0.0099\n",
      "Epoch 61/200, Iteration 242/250, Loss: 0.0140\n",
      "Epoch 61/200, Iteration 243/250, Loss: 0.0111\n",
      "Epoch 61/200, Iteration 244/250, Loss: 0.0124\n",
      "Epoch 61/200, Iteration 245/250, Loss: 0.0192\n",
      "Epoch 61/200, Iteration 246/250, Loss: 0.0273\n",
      "Epoch 61/200, Iteration 247/250, Loss: 0.0178\n",
      "Epoch 61/200, Iteration 248/250, Loss: 0.0264\n",
      "Epoch 61/200, Iteration 249/250, Loss: 0.0136\n",
      "Epoch 61/200, Iteration 250/250, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 77.68%, Avg loss: 0.012060, MRE: 0.885756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.012446, MRE: 1.090892 \n",
      "\n",
      "Epoch 62/200, Iteration 1/250, Loss: 0.0213\n",
      "Epoch 62/200, Iteration 2/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 3/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 4/250, Loss: 0.0229\n",
      "Epoch 62/200, Iteration 5/250, Loss: 0.0228\n",
      "Epoch 62/200, Iteration 6/250, Loss: 0.0248\n",
      "Epoch 62/200, Iteration 7/250, Loss: 0.0149\n",
      "Epoch 62/200, Iteration 8/250, Loss: 0.0518\n",
      "Epoch 62/200, Iteration 9/250, Loss: 0.0251\n",
      "Epoch 62/200, Iteration 10/250, Loss: 0.0158\n",
      "Epoch 62/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 62/200, Iteration 12/250, Loss: 0.0145\n",
      "Epoch 62/200, Iteration 13/250, Loss: 0.0445\n",
      "Epoch 62/200, Iteration 14/250, Loss: 0.0284\n",
      "Epoch 62/200, Iteration 15/250, Loss: 0.0077\n",
      "Epoch 62/200, Iteration 16/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 17/250, Loss: 0.0186\n",
      "Epoch 62/200, Iteration 18/250, Loss: 0.0192\n",
      "Epoch 62/200, Iteration 19/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 20/250, Loss: 0.0158\n",
      "Epoch 62/200, Iteration 21/250, Loss: 0.0247\n",
      "Epoch 62/200, Iteration 22/250, Loss: 0.0124\n",
      "Epoch 62/200, Iteration 23/250, Loss: 0.0130\n",
      "Epoch 62/200, Iteration 24/250, Loss: 0.0260\n",
      "Epoch 62/200, Iteration 25/250, Loss: 0.0167\n",
      "Epoch 62/200, Iteration 26/250, Loss: 0.0122\n",
      "Epoch 62/200, Iteration 27/250, Loss: 0.0218\n",
      "Epoch 62/200, Iteration 28/250, Loss: 0.0296\n",
      "Epoch 62/200, Iteration 29/250, Loss: 0.0236\n",
      "Epoch 62/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 31/250, Loss: 0.0312\n",
      "Epoch 62/200, Iteration 32/250, Loss: 0.0131\n",
      "Epoch 62/200, Iteration 33/250, Loss: 0.0142\n",
      "Epoch 62/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 62/200, Iteration 35/250, Loss: 0.0302\n",
      "Epoch 62/200, Iteration 36/250, Loss: 0.0144\n",
      "Epoch 62/200, Iteration 37/250, Loss: 0.0315\n",
      "Epoch 62/200, Iteration 38/250, Loss: 0.0079\n",
      "Epoch 62/200, Iteration 39/250, Loss: 0.0149\n",
      "Epoch 62/200, Iteration 40/250, Loss: 0.0185\n",
      "Epoch 62/200, Iteration 41/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 42/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 43/250, Loss: 0.0158\n",
      "Epoch 62/200, Iteration 44/250, Loss: 0.0075\n",
      "Epoch 62/200, Iteration 45/250, Loss: 0.0188\n",
      "Epoch 62/200, Iteration 46/250, Loss: 0.0139\n",
      "Epoch 62/200, Iteration 47/250, Loss: 0.0091\n",
      "Epoch 62/200, Iteration 48/250, Loss: 0.0267\n",
      "Epoch 62/200, Iteration 49/250, Loss: 0.0090\n",
      "Epoch 62/200, Iteration 50/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 51/250, Loss: 0.0206\n",
      "Epoch 62/200, Iteration 52/250, Loss: 0.0226\n",
      "Epoch 62/200, Iteration 53/250, Loss: 0.0211\n",
      "Epoch 62/200, Iteration 54/250, Loss: 0.0253\n",
      "Epoch 62/200, Iteration 55/250, Loss: 0.0203\n",
      "Epoch 62/200, Iteration 56/250, Loss: 0.0231\n",
      "Epoch 62/200, Iteration 57/250, Loss: 0.0336\n",
      "Epoch 62/200, Iteration 58/250, Loss: 0.0177\n",
      "Epoch 62/200, Iteration 59/250, Loss: 0.0134\n",
      "Epoch 62/200, Iteration 60/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 61/250, Loss: 0.0273\n",
      "Epoch 62/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 63/250, Loss: 0.0184\n",
      "Epoch 62/200, Iteration 64/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 65/250, Loss: 0.0198\n",
      "Epoch 62/200, Iteration 66/250, Loss: 0.0161\n",
      "Epoch 62/200, Iteration 67/250, Loss: 0.0183\n",
      "Epoch 62/200, Iteration 68/250, Loss: 0.0083\n",
      "Epoch 62/200, Iteration 69/250, Loss: 0.0110\n",
      "Epoch 62/200, Iteration 70/250, Loss: 0.0148\n",
      "Epoch 62/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 62/200, Iteration 72/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 73/250, Loss: 0.0064\n",
      "Epoch 62/200, Iteration 74/250, Loss: 0.0093\n",
      "Epoch 62/200, Iteration 75/250, Loss: 0.0152\n",
      "Epoch 62/200, Iteration 76/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 77/250, Loss: 0.0235\n",
      "Epoch 62/200, Iteration 78/250, Loss: 0.0182\n",
      "Epoch 62/200, Iteration 79/250, Loss: 0.0112\n",
      "Epoch 62/200, Iteration 80/250, Loss: 0.0149\n",
      "Epoch 62/200, Iteration 81/250, Loss: 0.0186\n",
      "Epoch 62/200, Iteration 82/250, Loss: 0.0163\n",
      "Epoch 62/200, Iteration 83/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 84/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 85/250, Loss: 0.0191\n",
      "Epoch 62/200, Iteration 86/250, Loss: 0.0336\n",
      "Epoch 62/200, Iteration 87/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 88/250, Loss: 0.0450\n",
      "Epoch 62/200, Iteration 89/250, Loss: 0.0134\n",
      "Epoch 62/200, Iteration 90/250, Loss: 0.0248\n",
      "Epoch 62/200, Iteration 91/250, Loss: 0.0316\n",
      "Epoch 62/200, Iteration 92/250, Loss: 0.0434\n",
      "Epoch 62/200, Iteration 93/250, Loss: 0.0292\n",
      "Epoch 62/200, Iteration 94/250, Loss: 0.0154\n",
      "Epoch 62/200, Iteration 95/250, Loss: 0.0156\n",
      "Epoch 62/200, Iteration 96/250, Loss: 0.0270\n",
      "Epoch 62/200, Iteration 97/250, Loss: 0.0111\n",
      "Epoch 62/200, Iteration 98/250, Loss: 0.0161\n",
      "Epoch 62/200, Iteration 99/250, Loss: 0.0193\n",
      "Epoch 62/200, Iteration 100/250, Loss: 0.0132\n",
      "Epoch 62/200, Iteration 101/250, Loss: 0.0160\n",
      "Epoch 62/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 62/200, Iteration 103/250, Loss: 0.0074\n",
      "Epoch 62/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 62/200, Iteration 105/250, Loss: 0.0273\n",
      "Epoch 62/200, Iteration 106/250, Loss: 0.0179\n",
      "Epoch 62/200, Iteration 107/250, Loss: 0.0081\n",
      "Epoch 62/200, Iteration 108/250, Loss: 0.0078\n",
      "Epoch 62/200, Iteration 109/250, Loss: 0.0083\n",
      "Epoch 62/200, Iteration 110/250, Loss: 0.0113\n",
      "Epoch 62/200, Iteration 111/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 112/250, Loss: 0.0142\n",
      "Epoch 62/200, Iteration 113/250, Loss: 0.0121\n",
      "Epoch 62/200, Iteration 114/250, Loss: 0.0188\n",
      "Epoch 62/200, Iteration 115/250, Loss: 0.0081\n",
      "Epoch 62/200, Iteration 116/250, Loss: 0.0140\n",
      "Epoch 62/200, Iteration 117/250, Loss: 0.0097\n",
      "Epoch 62/200, Iteration 118/250, Loss: 0.0077\n",
      "Epoch 62/200, Iteration 119/250, Loss: 0.0214\n",
      "Epoch 62/200, Iteration 120/250, Loss: 0.0224\n",
      "Epoch 62/200, Iteration 121/250, Loss: 0.0213\n",
      "Epoch 62/200, Iteration 122/250, Loss: 0.0197\n",
      "Epoch 62/200, Iteration 123/250, Loss: 0.0123\n",
      "Epoch 62/200, Iteration 124/250, Loss: 0.0198\n",
      "Epoch 62/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 62/200, Iteration 126/250, Loss: 0.0165\n",
      "Epoch 62/200, Iteration 127/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 128/250, Loss: 0.0206\n",
      "Epoch 62/200, Iteration 129/250, Loss: 0.0157\n",
      "Epoch 62/200, Iteration 130/250, Loss: 0.0132\n",
      "Epoch 62/200, Iteration 131/250, Loss: 0.0231\n",
      "Epoch 62/200, Iteration 132/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 133/250, Loss: 0.0280\n",
      "Epoch 62/200, Iteration 134/250, Loss: 0.0271\n",
      "Epoch 62/200, Iteration 135/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 136/250, Loss: 0.0145\n",
      "Epoch 62/200, Iteration 137/250, Loss: 0.0351\n",
      "Epoch 62/200, Iteration 138/250, Loss: 0.0270\n",
      "Epoch 62/200, Iteration 139/250, Loss: 0.0202\n",
      "Epoch 62/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 62/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 62/200, Iteration 142/250, Loss: 0.0131\n",
      "Epoch 62/200, Iteration 143/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 144/250, Loss: 0.0177\n",
      "Epoch 62/200, Iteration 145/250, Loss: 0.0111\n",
      "Epoch 62/200, Iteration 146/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 147/250, Loss: 0.0133\n",
      "Epoch 62/200, Iteration 148/250, Loss: 0.0207\n",
      "Epoch 62/200, Iteration 149/250, Loss: 0.0068\n",
      "Epoch 62/200, Iteration 150/250, Loss: 0.0296\n",
      "Epoch 62/200, Iteration 151/250, Loss: 0.0387\n",
      "Epoch 62/200, Iteration 152/250, Loss: 0.0190\n",
      "Epoch 62/200, Iteration 153/250, Loss: 0.0263\n",
      "Epoch 62/200, Iteration 154/250, Loss: 0.0074\n",
      "Epoch 62/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 156/250, Loss: 0.0199\n",
      "Epoch 62/200, Iteration 157/250, Loss: 0.0201\n",
      "Epoch 62/200, Iteration 158/250, Loss: 0.0276\n",
      "Epoch 62/200, Iteration 159/250, Loss: 0.0077\n",
      "Epoch 62/200, Iteration 160/250, Loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200, Iteration 161/250, Loss: 0.0210\n",
      "Epoch 62/200, Iteration 162/250, Loss: 0.0105\n",
      "Epoch 62/200, Iteration 163/250, Loss: 0.0182\n",
      "Epoch 62/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 62/200, Iteration 165/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 166/250, Loss: 0.0160\n",
      "Epoch 62/200, Iteration 167/250, Loss: 0.0168\n",
      "Epoch 62/200, Iteration 168/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 169/250, Loss: 0.0070\n",
      "Epoch 62/200, Iteration 170/250, Loss: 0.0109\n",
      "Epoch 62/200, Iteration 171/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 172/250, Loss: 0.0104\n",
      "Epoch 62/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 62/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 62/200, Iteration 175/250, Loss: 0.0109\n",
      "Epoch 62/200, Iteration 176/250, Loss: 0.0157\n",
      "Epoch 62/200, Iteration 177/250, Loss: 0.0163\n",
      "Epoch 62/200, Iteration 178/250, Loss: 0.0251\n",
      "Epoch 62/200, Iteration 179/250, Loss: 0.0244\n",
      "Epoch 62/200, Iteration 180/250, Loss: 0.0174\n",
      "Epoch 62/200, Iteration 181/250, Loss: 0.0096\n",
      "Epoch 62/200, Iteration 182/250, Loss: 0.0106\n",
      "Epoch 62/200, Iteration 183/250, Loss: 0.0140\n",
      "Epoch 62/200, Iteration 184/250, Loss: 0.0082\n",
      "Epoch 62/200, Iteration 185/250, Loss: 0.0094\n",
      "Epoch 62/200, Iteration 186/250, Loss: 0.0132\n",
      "Epoch 62/200, Iteration 187/250, Loss: 0.0197\n",
      "Epoch 62/200, Iteration 188/250, Loss: 0.0080\n",
      "Epoch 62/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 62/200, Iteration 190/250, Loss: 0.0243\n",
      "Epoch 62/200, Iteration 191/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 192/250, Loss: 0.0106\n",
      "Epoch 62/200, Iteration 193/250, Loss: 0.0123\n",
      "Epoch 62/200, Iteration 194/250, Loss: 0.0110\n",
      "Epoch 62/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 62/200, Iteration 196/250, Loss: 0.0139\n",
      "Epoch 62/200, Iteration 197/250, Loss: 0.0097\n",
      "Epoch 62/200, Iteration 198/250, Loss: 0.0062\n",
      "Epoch 62/200, Iteration 199/250, Loss: 0.0188\n",
      "Epoch 62/200, Iteration 200/250, Loss: 0.0107\n",
      "Epoch 62/200, Iteration 201/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 202/250, Loss: 0.0151\n",
      "Epoch 62/200, Iteration 203/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 204/250, Loss: 0.0161\n",
      "Epoch 62/200, Iteration 205/250, Loss: 0.0169\n",
      "Epoch 62/200, Iteration 206/250, Loss: 0.0188\n",
      "Epoch 62/200, Iteration 207/250, Loss: 0.0082\n",
      "Epoch 62/200, Iteration 208/250, Loss: 0.0192\n",
      "Epoch 62/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 62/200, Iteration 210/250, Loss: 0.0116\n",
      "Epoch 62/200, Iteration 211/250, Loss: 0.0083\n",
      "Epoch 62/200, Iteration 212/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 62/200, Iteration 214/250, Loss: 0.0333\n",
      "Epoch 62/200, Iteration 215/250, Loss: 0.0262\n",
      "Epoch 62/200, Iteration 216/250, Loss: 0.0119\n",
      "Epoch 62/200, Iteration 217/250, Loss: 0.0066\n",
      "Epoch 62/200, Iteration 218/250, Loss: 0.0073\n",
      "Epoch 62/200, Iteration 219/250, Loss: 0.0126\n",
      "Epoch 62/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 62/200, Iteration 221/250, Loss: 0.0290\n",
      "Epoch 62/200, Iteration 222/250, Loss: 0.0143\n",
      "Epoch 62/200, Iteration 223/250, Loss: 0.0131\n",
      "Epoch 62/200, Iteration 224/250, Loss: 0.0112\n",
      "Epoch 62/200, Iteration 225/250, Loss: 0.0205\n",
      "Epoch 62/200, Iteration 226/250, Loss: 0.0276\n",
      "Epoch 62/200, Iteration 227/250, Loss: 0.0074\n",
      "Epoch 62/200, Iteration 228/250, Loss: 0.0162\n",
      "Epoch 62/200, Iteration 229/250, Loss: 0.0085\n",
      "Epoch 62/200, Iteration 230/250, Loss: 0.0076\n",
      "Epoch 62/200, Iteration 231/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 232/250, Loss: 0.0153\n",
      "Epoch 62/200, Iteration 233/250, Loss: 0.0166\n",
      "Epoch 62/200, Iteration 234/250, Loss: 0.0239\n",
      "Epoch 62/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 62/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 62/200, Iteration 237/250, Loss: 0.0070\n",
      "Epoch 62/200, Iteration 238/250, Loss: 0.0071\n",
      "Epoch 62/200, Iteration 239/250, Loss: 0.0229\n",
      "Epoch 62/200, Iteration 240/250, Loss: 0.0106\n",
      "Epoch 62/200, Iteration 241/250, Loss: 0.0432\n",
      "Epoch 62/200, Iteration 242/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 243/250, Loss: 0.0156\n",
      "Epoch 62/200, Iteration 244/250, Loss: 0.0085\n",
      "Epoch 62/200, Iteration 245/250, Loss: 0.0125\n",
      "Epoch 62/200, Iteration 246/250, Loss: 0.0215\n",
      "Epoch 62/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 248/250, Loss: 0.0180\n",
      "Epoch 62/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 62/200, Iteration 250/250, Loss: 0.0231\n",
      "Train Error: \n",
      " Accuracy: 83.59%, Avg loss: 0.007228, MRE: 0.533816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.007813, MRE: 0.736714 \n",
      "\n",
      "Epoch 63/200, Iteration 1/250, Loss: 0.0099\n",
      "Epoch 63/200, Iteration 2/250, Loss: 0.0148\n",
      "Epoch 63/200, Iteration 3/250, Loss: 0.0107\n",
      "Epoch 63/200, Iteration 4/250, Loss: 0.0149\n",
      "Epoch 63/200, Iteration 5/250, Loss: 0.0123\n",
      "Epoch 63/200, Iteration 6/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 7/250, Loss: 0.0234\n",
      "Epoch 63/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 9/250, Loss: 0.0125\n",
      "Epoch 63/200, Iteration 10/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 11/250, Loss: 0.0123\n",
      "Epoch 63/200, Iteration 12/250, Loss: 0.0154\n",
      "Epoch 63/200, Iteration 13/250, Loss: 0.0235\n",
      "Epoch 63/200, Iteration 14/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 15/250, Loss: 0.0114\n",
      "Epoch 63/200, Iteration 16/250, Loss: 0.0124\n",
      "Epoch 63/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 18/250, Loss: 0.0150\n",
      "Epoch 63/200, Iteration 19/250, Loss: 0.0155\n",
      "Epoch 63/200, Iteration 20/250, Loss: 0.0200\n",
      "Epoch 63/200, Iteration 21/250, Loss: 0.0143\n",
      "Epoch 63/200, Iteration 22/250, Loss: 0.0134\n",
      "Epoch 63/200, Iteration 23/250, Loss: 0.0122\n",
      "Epoch 63/200, Iteration 24/250, Loss: 0.0154\n",
      "Epoch 63/200, Iteration 25/250, Loss: 0.0102\n",
      "Epoch 63/200, Iteration 26/250, Loss: 0.0143\n",
      "Epoch 63/200, Iteration 27/250, Loss: 0.0088\n",
      "Epoch 63/200, Iteration 28/250, Loss: 0.0052\n",
      "Epoch 63/200, Iteration 29/250, Loss: 0.0132\n",
      "Epoch 63/200, Iteration 30/250, Loss: 0.0186\n",
      "Epoch 63/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 32/250, Loss: 0.0146\n",
      "Epoch 63/200, Iteration 33/250, Loss: 0.0248\n",
      "Epoch 63/200, Iteration 34/250, Loss: 0.0115\n",
      "Epoch 63/200, Iteration 35/250, Loss: 0.0231\n",
      "Epoch 63/200, Iteration 36/250, Loss: 0.0262\n",
      "Epoch 63/200, Iteration 37/250, Loss: 0.0266\n",
      "Epoch 63/200, Iteration 38/250, Loss: 0.0135\n",
      "Epoch 63/200, Iteration 39/250, Loss: 0.0187\n",
      "Epoch 63/200, Iteration 40/250, Loss: 0.0177\n",
      "Epoch 63/200, Iteration 41/250, Loss: 0.0073\n",
      "Epoch 63/200, Iteration 42/250, Loss: 0.0228\n",
      "Epoch 63/200, Iteration 43/250, Loss: 0.0217\n",
      "Epoch 63/200, Iteration 44/250, Loss: 0.0300\n",
      "Epoch 63/200, Iteration 45/250, Loss: 0.0086\n",
      "Epoch 63/200, Iteration 46/250, Loss: 0.0068\n",
      "Epoch 63/200, Iteration 47/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 49/250, Loss: 0.0215\n",
      "Epoch 63/200, Iteration 50/250, Loss: 0.0137\n",
      "Epoch 63/200, Iteration 51/250, Loss: 0.0083\n",
      "Epoch 63/200, Iteration 52/250, Loss: 0.0180\n",
      "Epoch 63/200, Iteration 53/250, Loss: 0.0242\n",
      "Epoch 63/200, Iteration 54/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 55/250, Loss: 0.0074\n",
      "Epoch 63/200, Iteration 56/250, Loss: 0.0149\n",
      "Epoch 63/200, Iteration 57/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 58/250, Loss: 0.0088\n",
      "Epoch 63/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 63/200, Iteration 60/250, Loss: 0.0279\n",
      "Epoch 63/200, Iteration 61/250, Loss: 0.0083\n",
      "Epoch 63/200, Iteration 62/250, Loss: 0.0215\n",
      "Epoch 63/200, Iteration 63/250, Loss: 0.0169\n",
      "Epoch 63/200, Iteration 64/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 63/200, Iteration 66/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 67/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 68/250, Loss: 0.0230\n",
      "Epoch 63/200, Iteration 69/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 70/250, Loss: 0.0186\n",
      "Epoch 63/200, Iteration 71/250, Loss: 0.0113\n",
      "Epoch 63/200, Iteration 72/250, Loss: 0.0174\n",
      "Epoch 63/200, Iteration 73/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 74/250, Loss: 0.0276\n",
      "Epoch 63/200, Iteration 75/250, Loss: 0.0154\n",
      "Epoch 63/200, Iteration 76/250, Loss: 0.0133\n",
      "Epoch 63/200, Iteration 77/250, Loss: 0.0089\n",
      "Epoch 63/200, Iteration 78/250, Loss: 0.0240\n",
      "Epoch 63/200, Iteration 79/250, Loss: 0.0127\n",
      "Epoch 63/200, Iteration 80/250, Loss: 0.0126\n",
      "Epoch 63/200, Iteration 81/250, Loss: 0.0117\n",
      "Epoch 63/200, Iteration 82/250, Loss: 0.0113\n",
      "Epoch 63/200, Iteration 83/250, Loss: 0.0171\n",
      "Epoch 63/200, Iteration 84/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 85/250, Loss: 0.0082\n",
      "Epoch 63/200, Iteration 86/250, Loss: 0.0113\n",
      "Epoch 63/200, Iteration 87/250, Loss: 0.0084\n",
      "Epoch 63/200, Iteration 88/250, Loss: 0.0303\n",
      "Epoch 63/200, Iteration 89/250, Loss: 0.0133\n",
      "Epoch 63/200, Iteration 90/250, Loss: 0.0082\n",
      "Epoch 63/200, Iteration 91/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 92/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 93/250, Loss: 0.0104\n",
      "Epoch 63/200, Iteration 94/250, Loss: 0.0087\n",
      "Epoch 63/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 63/200, Iteration 96/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 97/250, Loss: 0.0200\n",
      "Epoch 63/200, Iteration 98/250, Loss: 0.0188\n",
      "Epoch 63/200, Iteration 99/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 100/250, Loss: 0.0129\n",
      "Epoch 63/200, Iteration 101/250, Loss: 0.0235\n",
      "Epoch 63/200, Iteration 102/250, Loss: 0.0226\n",
      "Epoch 63/200, Iteration 103/250, Loss: 0.0108\n",
      "Epoch 63/200, Iteration 104/250, Loss: 0.0406\n",
      "Epoch 63/200, Iteration 105/250, Loss: 0.0108\n",
      "Epoch 63/200, Iteration 106/250, Loss: 0.0204\n",
      "Epoch 63/200, Iteration 107/250, Loss: 0.0120\n",
      "Epoch 63/200, Iteration 108/250, Loss: 0.0126\n",
      "Epoch 63/200, Iteration 109/250, Loss: 0.0281\n",
      "Epoch 63/200, Iteration 110/250, Loss: 0.0132\n",
      "Epoch 63/200, Iteration 111/250, Loss: 0.0266\n",
      "Epoch 63/200, Iteration 112/250, Loss: 0.0233\n",
      "Epoch 63/200, Iteration 113/250, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 114/250, Loss: 0.0287\n",
      "Epoch 63/200, Iteration 115/250, Loss: 0.0142\n",
      "Epoch 63/200, Iteration 116/250, Loss: 0.0171\n",
      "Epoch 63/200, Iteration 117/250, Loss: 0.0130\n",
      "Epoch 63/200, Iteration 118/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 119/250, Loss: 0.0305\n",
      "Epoch 63/200, Iteration 120/250, Loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 63/200, Iteration 122/250, Loss: 0.0254\n",
      "Epoch 63/200, Iteration 123/250, Loss: 0.0111\n",
      "Epoch 63/200, Iteration 124/250, Loss: 0.0112\n",
      "Epoch 63/200, Iteration 125/250, Loss: 0.0167\n",
      "Epoch 63/200, Iteration 126/250, Loss: 0.0090\n",
      "Epoch 63/200, Iteration 127/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 128/250, Loss: 0.0080\n",
      "Epoch 63/200, Iteration 129/250, Loss: 0.0131\n",
      "Epoch 63/200, Iteration 130/250, Loss: 0.0146\n",
      "Epoch 63/200, Iteration 131/250, Loss: 0.0147\n",
      "Epoch 63/200, Iteration 132/250, Loss: 0.0237\n",
      "Epoch 63/200, Iteration 133/250, Loss: 0.0105\n",
      "Epoch 63/200, Iteration 134/250, Loss: 0.0231\n",
      "Epoch 63/200, Iteration 135/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 136/250, Loss: 0.0101\n",
      "Epoch 63/200, Iteration 137/250, Loss: 0.0127\n",
      "Epoch 63/200, Iteration 138/250, Loss: 0.0074\n",
      "Epoch 63/200, Iteration 139/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 140/250, Loss: 0.0256\n",
      "Epoch 63/200, Iteration 141/250, Loss: 0.0231\n",
      "Epoch 63/200, Iteration 142/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 143/250, Loss: 0.0262\n",
      "Epoch 63/200, Iteration 144/250, Loss: 0.0159\n",
      "Epoch 63/200, Iteration 145/250, Loss: 0.0147\n",
      "Epoch 63/200, Iteration 146/250, Loss: 0.0332\n",
      "Epoch 63/200, Iteration 147/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 148/250, Loss: 0.0120\n",
      "Epoch 63/200, Iteration 149/250, Loss: 0.0336\n",
      "Epoch 63/200, Iteration 150/250, Loss: 0.0079\n",
      "Epoch 63/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 63/200, Iteration 152/250, Loss: 0.0175\n",
      "Epoch 63/200, Iteration 153/250, Loss: 0.0116\n",
      "Epoch 63/200, Iteration 154/250, Loss: 0.0110\n",
      "Epoch 63/200, Iteration 155/250, Loss: 0.0157\n",
      "Epoch 63/200, Iteration 156/250, Loss: 0.0077\n",
      "Epoch 63/200, Iteration 157/250, Loss: 0.0103\n",
      "Epoch 63/200, Iteration 158/250, Loss: 0.0096\n",
      "Epoch 63/200, Iteration 159/250, Loss: 0.0134\n",
      "Epoch 63/200, Iteration 160/250, Loss: 0.0157\n",
      "Epoch 63/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 63/200, Iteration 162/250, Loss: 0.0171\n",
      "Epoch 63/200, Iteration 163/250, Loss: 0.0072\n",
      "Epoch 63/200, Iteration 164/250, Loss: 0.0188\n",
      "Epoch 63/200, Iteration 165/250, Loss: 0.0079\n",
      "Epoch 63/200, Iteration 166/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 167/250, Loss: 0.0197\n",
      "Epoch 63/200, Iteration 168/250, Loss: 0.0189\n",
      "Epoch 63/200, Iteration 169/250, Loss: 0.0130\n",
      "Epoch 63/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 63/200, Iteration 171/250, Loss: 0.0121\n",
      "Epoch 63/200, Iteration 172/250, Loss: 0.0098\n",
      "Epoch 63/200, Iteration 173/250, Loss: 0.0151\n",
      "Epoch 63/200, Iteration 174/250, Loss: 0.0195\n",
      "Epoch 63/200, Iteration 175/250, Loss: 0.0085\n",
      "Epoch 63/200, Iteration 176/250, Loss: 0.0083\n",
      "Epoch 63/200, Iteration 177/250, Loss: 0.0232\n",
      "Epoch 63/200, Iteration 178/250, Loss: 0.0090\n",
      "Epoch 63/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 180/250, Loss: 0.0100\n",
      "Epoch 63/200, Iteration 181/250, Loss: 0.0266\n",
      "Epoch 63/200, Iteration 182/250, Loss: 0.0071\n",
      "Epoch 63/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 63/200, Iteration 184/250, Loss: 0.0102\n",
      "Epoch 63/200, Iteration 185/250, Loss: 0.0088\n",
      "Epoch 63/200, Iteration 186/250, Loss: 0.0132\n",
      "Epoch 63/200, Iteration 187/250, Loss: 0.0096\n",
      "Epoch 63/200, Iteration 188/250, Loss: 0.0139\n",
      "Epoch 63/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 190/250, Loss: 0.0325\n",
      "Epoch 63/200, Iteration 191/250, Loss: 0.0188\n",
      "Epoch 63/200, Iteration 192/250, Loss: 0.0070\n",
      "Epoch 63/200, Iteration 193/250, Loss: 0.0134\n",
      "Epoch 63/200, Iteration 194/250, Loss: 0.0189\n",
      "Epoch 63/200, Iteration 195/250, Loss: 0.0086\n",
      "Epoch 63/200, Iteration 196/250, Loss: 0.0216\n",
      "Epoch 63/200, Iteration 197/250, Loss: 0.0086\n",
      "Epoch 63/200, Iteration 198/250, Loss: 0.0093\n",
      "Epoch 63/200, Iteration 199/250, Loss: 0.0180\n",
      "Epoch 63/200, Iteration 200/250, Loss: 0.0205\n",
      "Epoch 63/200, Iteration 201/250, Loss: 0.0178\n",
      "Epoch 63/200, Iteration 202/250, Loss: 0.0117\n",
      "Epoch 63/200, Iteration 203/250, Loss: 0.0098\n",
      "Epoch 63/200, Iteration 204/250, Loss: 0.0160\n",
      "Epoch 63/200, Iteration 205/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 206/250, Loss: 0.0077\n",
      "Epoch 63/200, Iteration 207/250, Loss: 0.0095\n",
      "Epoch 63/200, Iteration 208/250, Loss: 0.0095\n",
      "Epoch 63/200, Iteration 209/250, Loss: 0.0284\n",
      "Epoch 63/200, Iteration 210/250, Loss: 0.0108\n",
      "Epoch 63/200, Iteration 211/250, Loss: 0.0149\n",
      "Epoch 63/200, Iteration 212/250, Loss: 0.0167\n",
      "Epoch 63/200, Iteration 213/250, Loss: 0.0222\n",
      "Epoch 63/200, Iteration 214/250, Loss: 0.0139\n",
      "Epoch 63/200, Iteration 215/250, Loss: 0.0106\n",
      "Epoch 63/200, Iteration 216/250, Loss: 0.0103\n",
      "Epoch 63/200, Iteration 217/250, Loss: 0.0195\n",
      "Epoch 63/200, Iteration 218/250, Loss: 0.0109\n",
      "Epoch 63/200, Iteration 219/250, Loss: 0.0157\n",
      "Epoch 63/200, Iteration 220/250, Loss: 0.0148\n",
      "Epoch 63/200, Iteration 221/250, Loss: 0.0075\n",
      "Epoch 63/200, Iteration 222/250, Loss: 0.0130\n",
      "Epoch 63/200, Iteration 223/250, Loss: 0.0076\n",
      "Epoch 63/200, Iteration 224/250, Loss: 0.0070\n",
      "Epoch 63/200, Iteration 225/250, Loss: 0.0096\n",
      "Epoch 63/200, Iteration 226/250, Loss: 0.0065\n",
      "Epoch 63/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 63/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 63/200, Iteration 229/250, Loss: 0.0141\n",
      "Epoch 63/200, Iteration 230/250, Loss: 0.0327\n",
      "Epoch 63/200, Iteration 231/250, Loss: 0.0183\n",
      "Epoch 63/200, Iteration 232/250, Loss: 0.0397\n",
      "Epoch 63/200, Iteration 233/250, Loss: 0.0201\n",
      "Epoch 63/200, Iteration 234/250, Loss: 0.0220\n",
      "Epoch 63/200, Iteration 235/250, Loss: 0.0105\n",
      "Epoch 63/200, Iteration 236/250, Loss: 0.0084\n",
      "Epoch 63/200, Iteration 237/250, Loss: 0.0093\n",
      "Epoch 63/200, Iteration 238/250, Loss: 0.0083\n",
      "Epoch 63/200, Iteration 239/250, Loss: 0.0084\n",
      "Epoch 63/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 63/200, Iteration 241/250, Loss: 0.0175\n",
      "Epoch 63/200, Iteration 242/250, Loss: 0.0091\n",
      "Epoch 63/200, Iteration 243/250, Loss: 0.0292\n",
      "Epoch 63/200, Iteration 244/250, Loss: 0.0280\n",
      "Epoch 63/200, Iteration 245/250, Loss: 0.0093\n",
      "Epoch 63/200, Iteration 246/250, Loss: 0.0320\n",
      "Epoch 63/200, Iteration 247/250, Loss: 0.0118\n",
      "Epoch 63/200, Iteration 248/250, Loss: 0.0135\n",
      "Epoch 63/200, Iteration 249/250, Loss: 0.0094\n",
      "Epoch 63/200, Iteration 250/250, Loss: 0.0141\n",
      "Train Error: \n",
      " Accuracy: 93.46%, Avg loss: 0.007951, MRE: 0.531898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.85%, Avg loss: 0.008547, MRE: 0.685504 \n",
      "\n",
      "Epoch 64/200, Iteration 1/250, Loss: 0.0156\n",
      "Epoch 64/200, Iteration 2/250, Loss: 0.0211\n",
      "Epoch 64/200, Iteration 3/250, Loss: 0.0105\n",
      "Epoch 64/200, Iteration 4/250, Loss: 0.0129\n",
      "Epoch 64/200, Iteration 5/250, Loss: 0.0119\n",
      "Epoch 64/200, Iteration 6/250, Loss: 0.0079\n",
      "Epoch 64/200, Iteration 7/250, Loss: 0.0190\n",
      "Epoch 64/200, Iteration 8/250, Loss: 0.0156\n",
      "Epoch 64/200, Iteration 9/250, Loss: 0.0212\n",
      "Epoch 64/200, Iteration 10/250, Loss: 0.0188\n",
      "Epoch 64/200, Iteration 11/250, Loss: 0.0131\n",
      "Epoch 64/200, Iteration 12/250, Loss: 0.0127\n",
      "Epoch 64/200, Iteration 13/250, Loss: 0.0086\n",
      "Epoch 64/200, Iteration 14/250, Loss: 0.0295\n",
      "Epoch 64/200, Iteration 15/250, Loss: 0.0101\n",
      "Epoch 64/200, Iteration 16/250, Loss: 0.0228\n",
      "Epoch 64/200, Iteration 17/250, Loss: 0.0191\n",
      "Epoch 64/200, Iteration 18/250, Loss: 0.0296\n",
      "Epoch 64/200, Iteration 19/250, Loss: 0.0145\n",
      "Epoch 64/200, Iteration 20/250, Loss: 0.0288\n",
      "Epoch 64/200, Iteration 21/250, Loss: 0.0142\n",
      "Epoch 64/200, Iteration 22/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 23/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 24/250, Loss: 0.0231\n",
      "Epoch 64/200, Iteration 25/250, Loss: 0.0262\n",
      "Epoch 64/200, Iteration 26/250, Loss: 0.0215\n",
      "Epoch 64/200, Iteration 27/250, Loss: 0.0281\n",
      "Epoch 64/200, Iteration 28/250, Loss: 0.0103\n",
      "Epoch 64/200, Iteration 29/250, Loss: 0.0235\n",
      "Epoch 64/200, Iteration 30/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 31/250, Loss: 0.0087\n",
      "Epoch 64/200, Iteration 32/250, Loss: 0.0098\n",
      "Epoch 64/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 34/250, Loss: 0.0267\n",
      "Epoch 64/200, Iteration 35/250, Loss: 0.0085\n",
      "Epoch 64/200, Iteration 36/250, Loss: 0.0078\n",
      "Epoch 64/200, Iteration 37/250, Loss: 0.0119\n",
      "Epoch 64/200, Iteration 38/250, Loss: 0.0199\n",
      "Epoch 64/200, Iteration 39/250, Loss: 0.0252\n",
      "Epoch 64/200, Iteration 40/250, Loss: 0.0247\n",
      "Epoch 64/200, Iteration 41/250, Loss: 0.0265\n",
      "Epoch 64/200, Iteration 42/250, Loss: 0.0149\n",
      "Epoch 64/200, Iteration 43/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 44/250, Loss: 0.0089\n",
      "Epoch 64/200, Iteration 45/250, Loss: 0.0203\n",
      "Epoch 64/200, Iteration 46/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 47/250, Loss: 0.0134\n",
      "Epoch 64/200, Iteration 48/250, Loss: 0.0107\n",
      "Epoch 64/200, Iteration 49/250, Loss: 0.0104\n",
      "Epoch 64/200, Iteration 50/250, Loss: 0.0181\n",
      "Epoch 64/200, Iteration 51/250, Loss: 0.0122\n",
      "Epoch 64/200, Iteration 52/250, Loss: 0.0242\n",
      "Epoch 64/200, Iteration 53/250, Loss: 0.0142\n",
      "Epoch 64/200, Iteration 54/250, Loss: 0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200, Iteration 55/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 56/250, Loss: 0.0167\n",
      "Epoch 64/200, Iteration 57/250, Loss: 0.0135\n",
      "Epoch 64/200, Iteration 58/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 59/250, Loss: 0.0269\n",
      "Epoch 64/200, Iteration 60/250, Loss: 0.0173\n",
      "Epoch 64/200, Iteration 61/250, Loss: 0.0114\n",
      "Epoch 64/200, Iteration 62/250, Loss: 0.0189\n",
      "Epoch 64/200, Iteration 63/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 64/250, Loss: 0.0256\n",
      "Epoch 64/200, Iteration 65/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 66/250, Loss: 0.0129\n",
      "Epoch 64/200, Iteration 67/250, Loss: 0.0184\n",
      "Epoch 64/200, Iteration 68/250, Loss: 0.0201\n",
      "Epoch 64/200, Iteration 69/250, Loss: 0.0111\n",
      "Epoch 64/200, Iteration 70/250, Loss: 0.0261\n",
      "Epoch 64/200, Iteration 71/250, Loss: 0.0143\n",
      "Epoch 64/200, Iteration 72/250, Loss: 0.0257\n",
      "Epoch 64/200, Iteration 73/250, Loss: 0.0084\n",
      "Epoch 64/200, Iteration 74/250, Loss: 0.0179\n",
      "Epoch 64/200, Iteration 75/250, Loss: 0.0163\n",
      "Epoch 64/200, Iteration 76/250, Loss: 0.0120\n",
      "Epoch 64/200, Iteration 77/250, Loss: 0.0102\n",
      "Epoch 64/200, Iteration 78/250, Loss: 0.0202\n",
      "Epoch 64/200, Iteration 79/250, Loss: 0.0102\n",
      "Epoch 64/200, Iteration 80/250, Loss: 0.0092\n",
      "Epoch 64/200, Iteration 81/250, Loss: 0.0203\n",
      "Epoch 64/200, Iteration 82/250, Loss: 0.0147\n",
      "Epoch 64/200, Iteration 83/250, Loss: 0.0121\n",
      "Epoch 64/200, Iteration 84/250, Loss: 0.0186\n",
      "Epoch 64/200, Iteration 85/250, Loss: 0.0202\n",
      "Epoch 64/200, Iteration 86/250, Loss: 0.0178\n",
      "Epoch 64/200, Iteration 87/250, Loss: 0.0173\n",
      "Epoch 64/200, Iteration 88/250, Loss: 0.0123\n",
      "Epoch 64/200, Iteration 89/250, Loss: 0.0145\n",
      "Epoch 64/200, Iteration 90/250, Loss: 0.0148\n",
      "Epoch 64/200, Iteration 91/250, Loss: 0.0159\n",
      "Epoch 64/200, Iteration 92/250, Loss: 0.0104\n",
      "Epoch 64/200, Iteration 93/250, Loss: 0.0094\n",
      "Epoch 64/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 64/200, Iteration 95/250, Loss: 0.0101\n",
      "Epoch 64/200, Iteration 96/250, Loss: 0.0157\n",
      "Epoch 64/200, Iteration 97/250, Loss: 0.0177\n",
      "Epoch 64/200, Iteration 98/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 99/250, Loss: 0.0336\n",
      "Epoch 64/200, Iteration 100/250, Loss: 0.0138\n",
      "Epoch 64/200, Iteration 101/250, Loss: 0.0200\n",
      "Epoch 64/200, Iteration 102/250, Loss: 0.0196\n",
      "Epoch 64/200, Iteration 103/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 104/250, Loss: 0.0293\n",
      "Epoch 64/200, Iteration 105/250, Loss: 0.0109\n",
      "Epoch 64/200, Iteration 106/250, Loss: 0.0326\n",
      "Epoch 64/200, Iteration 107/250, Loss: 0.0196\n",
      "Epoch 64/200, Iteration 108/250, Loss: 0.0082\n",
      "Epoch 64/200, Iteration 109/250, Loss: 0.0130\n",
      "Epoch 64/200, Iteration 110/250, Loss: 0.0098\n",
      "Epoch 64/200, Iteration 111/250, Loss: 0.0135\n",
      "Epoch 64/200, Iteration 112/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 113/250, Loss: 0.0085\n",
      "Epoch 64/200, Iteration 114/250, Loss: 0.0074\n",
      "Epoch 64/200, Iteration 115/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 116/250, Loss: 0.0196\n",
      "Epoch 64/200, Iteration 117/250, Loss: 0.0092\n",
      "Epoch 64/200, Iteration 118/250, Loss: 0.0111\n",
      "Epoch 64/200, Iteration 119/250, Loss: 0.0090\n",
      "Epoch 64/200, Iteration 120/250, Loss: 0.0236\n",
      "Epoch 64/200, Iteration 121/250, Loss: 0.0094\n",
      "Epoch 64/200, Iteration 122/250, Loss: 0.0065\n",
      "Epoch 64/200, Iteration 123/250, Loss: 0.0123\n",
      "Epoch 64/200, Iteration 124/250, Loss: 0.0064\n",
      "Epoch 64/200, Iteration 125/250, Loss: 0.0216\n",
      "Epoch 64/200, Iteration 126/250, Loss: 0.0094\n",
      "Epoch 64/200, Iteration 127/250, Loss: 0.0193\n",
      "Epoch 64/200, Iteration 128/250, Loss: 0.0196\n",
      "Epoch 64/200, Iteration 129/250, Loss: 0.0284\n",
      "Epoch 64/200, Iteration 130/250, Loss: 0.0147\n",
      "Epoch 64/200, Iteration 131/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 132/250, Loss: 0.0074\n",
      "Epoch 64/200, Iteration 133/250, Loss: 0.0117\n",
      "Epoch 64/200, Iteration 134/250, Loss: 0.0403\n",
      "Epoch 64/200, Iteration 135/250, Loss: 0.0105\n",
      "Epoch 64/200, Iteration 136/250, Loss: 0.0139\n",
      "Epoch 64/200, Iteration 137/250, Loss: 0.0142\n",
      "Epoch 64/200, Iteration 138/250, Loss: 0.0197\n",
      "Epoch 64/200, Iteration 139/250, Loss: 0.0153\n",
      "Epoch 64/200, Iteration 140/250, Loss: 0.0256\n",
      "Epoch 64/200, Iteration 141/250, Loss: 0.0152\n",
      "Epoch 64/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 64/200, Iteration 143/250, Loss: 0.0149\n",
      "Epoch 64/200, Iteration 144/250, Loss: 0.0136\n",
      "Epoch 64/200, Iteration 145/250, Loss: 0.0152\n",
      "Epoch 64/200, Iteration 146/250, Loss: 0.0066\n",
      "Epoch 64/200, Iteration 147/250, Loss: 0.0106\n",
      "Epoch 64/200, Iteration 148/250, Loss: 0.0080\n",
      "Epoch 64/200, Iteration 149/250, Loss: 0.0151\n",
      "Epoch 64/200, Iteration 150/250, Loss: 0.0103\n",
      "Epoch 64/200, Iteration 151/250, Loss: 0.0151\n",
      "Epoch 64/200, Iteration 152/250, Loss: 0.0115\n",
      "Epoch 64/200, Iteration 153/250, Loss: 0.0189\n",
      "Epoch 64/200, Iteration 154/250, Loss: 0.0148\n",
      "Epoch 64/200, Iteration 155/250, Loss: 0.0092\n",
      "Epoch 64/200, Iteration 156/250, Loss: 0.0155\n",
      "Epoch 64/200, Iteration 157/250, Loss: 0.0103\n",
      "Epoch 64/200, Iteration 158/250, Loss: 0.0098\n",
      "Epoch 64/200, Iteration 159/250, Loss: 0.0089\n",
      "Epoch 64/200, Iteration 160/250, Loss: 0.0196\n",
      "Epoch 64/200, Iteration 161/250, Loss: 0.0335\n",
      "Epoch 64/200, Iteration 162/250, Loss: 0.0100\n",
      "Epoch 64/200, Iteration 163/250, Loss: 0.0205\n",
      "Epoch 64/200, Iteration 164/250, Loss: 0.0391\n",
      "Epoch 64/200, Iteration 165/250, Loss: 0.0130\n",
      "Epoch 64/200, Iteration 166/250, Loss: 0.0131\n",
      "Epoch 64/200, Iteration 167/250, Loss: 0.0143\n",
      "Epoch 64/200, Iteration 168/250, Loss: 0.0206\n",
      "Epoch 64/200, Iteration 169/250, Loss: 0.0217\n",
      "Epoch 64/200, Iteration 170/250, Loss: 0.0146\n",
      "Epoch 64/200, Iteration 171/250, Loss: 0.0164\n",
      "Epoch 64/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 64/200, Iteration 173/250, Loss: 0.0134\n",
      "Epoch 64/200, Iteration 174/250, Loss: 0.0230\n",
      "Epoch 64/200, Iteration 175/250, Loss: 0.0099\n",
      "Epoch 64/200, Iteration 176/250, Loss: 0.0119\n",
      "Epoch 64/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 64/200, Iteration 178/250, Loss: 0.0065\n",
      "Epoch 64/200, Iteration 179/250, Loss: 0.0166\n",
      "Epoch 64/200, Iteration 180/250, Loss: 0.0169\n",
      "Epoch 64/200, Iteration 181/250, Loss: 0.0123\n",
      "Epoch 64/200, Iteration 182/250, Loss: 0.0096\n",
      "Epoch 64/200, Iteration 183/250, Loss: 0.0271\n",
      "Epoch 64/200, Iteration 184/250, Loss: 0.0157\n",
      "Epoch 64/200, Iteration 185/250, Loss: 0.0090\n",
      "Epoch 64/200, Iteration 186/250, Loss: 0.0097\n",
      "Epoch 64/200, Iteration 187/250, Loss: 0.0115\n",
      "Epoch 64/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 189/250, Loss: 0.0121\n",
      "Epoch 64/200, Iteration 190/250, Loss: 0.0145\n",
      "Epoch 64/200, Iteration 191/250, Loss: 0.0163\n",
      "Epoch 64/200, Iteration 192/250, Loss: 0.0081\n",
      "Epoch 64/200, Iteration 193/250, Loss: 0.0096\n",
      "Epoch 64/200, Iteration 194/250, Loss: 0.0122\n",
      "Epoch 64/200, Iteration 195/250, Loss: 0.0105\n",
      "Epoch 64/200, Iteration 196/250, Loss: 0.0165\n",
      "Epoch 64/200, Iteration 197/250, Loss: 0.0132\n",
      "Epoch 64/200, Iteration 198/250, Loss: 0.0270\n",
      "Epoch 64/200, Iteration 199/250, Loss: 0.0069\n",
      "Epoch 64/200, Iteration 200/250, Loss: 0.0131\n",
      "Epoch 64/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 64/200, Iteration 202/250, Loss: 0.0118\n",
      "Epoch 64/200, Iteration 203/250, Loss: 0.0112\n",
      "Epoch 64/200, Iteration 204/250, Loss: 0.0174\n",
      "Epoch 64/200, Iteration 205/250, Loss: 0.0153\n",
      "Epoch 64/200, Iteration 206/250, Loss: 0.0108\n",
      "Epoch 64/200, Iteration 207/250, Loss: 0.0062\n",
      "Epoch 64/200, Iteration 208/250, Loss: 0.0117\n",
      "Epoch 64/200, Iteration 209/250, Loss: 0.0135\n",
      "Epoch 64/200, Iteration 210/250, Loss: 0.0122\n",
      "Epoch 64/200, Iteration 211/250, Loss: 0.0129\n",
      "Epoch 64/200, Iteration 212/250, Loss: 0.0106\n",
      "Epoch 64/200, Iteration 213/250, Loss: 0.0257\n",
      "Epoch 64/200, Iteration 214/250, Loss: 0.0072\n",
      "Epoch 64/200, Iteration 215/250, Loss: 0.0110\n",
      "Epoch 64/200, Iteration 216/250, Loss: 0.0133\n",
      "Epoch 64/200, Iteration 217/250, Loss: 0.0126\n",
      "Epoch 64/200, Iteration 218/250, Loss: 0.0103\n",
      "Epoch 64/200, Iteration 219/250, Loss: 0.0270\n",
      "Epoch 64/200, Iteration 220/250, Loss: 0.0155\n",
      "Epoch 64/200, Iteration 221/250, Loss: 0.0122\n",
      "Epoch 64/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 64/200, Iteration 223/250, Loss: 0.0288\n",
      "Epoch 64/200, Iteration 224/250, Loss: 0.0138\n",
      "Epoch 64/200, Iteration 225/250, Loss: 0.0274\n",
      "Epoch 64/200, Iteration 226/250, Loss: 0.0214\n",
      "Epoch 64/200, Iteration 227/250, Loss: 0.0236\n",
      "Epoch 64/200, Iteration 228/250, Loss: 0.0161\n",
      "Epoch 64/200, Iteration 229/250, Loss: 0.0095\n",
      "Epoch 64/200, Iteration 230/250, Loss: 0.0278\n",
      "Epoch 64/200, Iteration 231/250, Loss: 0.0095\n",
      "Epoch 64/200, Iteration 232/250, Loss: 0.0166\n",
      "Epoch 64/200, Iteration 233/250, Loss: 0.0240\n",
      "Epoch 64/200, Iteration 234/250, Loss: 0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200, Iteration 235/250, Loss: 0.0182\n",
      "Epoch 64/200, Iteration 236/250, Loss: 0.0209\n",
      "Epoch 64/200, Iteration 237/250, Loss: 0.0123\n",
      "Epoch 64/200, Iteration 238/250, Loss: 0.0115\n",
      "Epoch 64/200, Iteration 239/250, Loss: 0.0160\n",
      "Epoch 64/200, Iteration 240/250, Loss: 0.0224\n",
      "Epoch 64/200, Iteration 241/250, Loss: 0.0230\n",
      "Epoch 64/200, Iteration 242/250, Loss: 0.0119\n",
      "Epoch 64/200, Iteration 243/250, Loss: 0.0129\n",
      "Epoch 64/200, Iteration 244/250, Loss: 0.0173\n",
      "Epoch 64/200, Iteration 245/250, Loss: 0.0176\n",
      "Epoch 64/200, Iteration 246/250, Loss: 0.0231\n",
      "Epoch 64/200, Iteration 247/250, Loss: 0.0156\n",
      "Epoch 64/200, Iteration 248/250, Loss: 0.0239\n",
      "Epoch 64/200, Iteration 249/250, Loss: 0.0095\n",
      "Epoch 64/200, Iteration 250/250, Loss: 0.0210\n",
      "Train Error: \n",
      " Accuracy: 69.34%, Avg loss: 0.008741, MRE: 0.616633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.75%, Avg loss: 0.009164, MRE: 0.592622 \n",
      "\n",
      "Epoch 65/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 65/200, Iteration 2/250, Loss: 0.0142\n",
      "Epoch 65/200, Iteration 3/250, Loss: 0.0102\n",
      "Epoch 65/200, Iteration 4/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 5/250, Loss: 0.0144\n",
      "Epoch 65/200, Iteration 6/250, Loss: 0.0139\n",
      "Epoch 65/200, Iteration 7/250, Loss: 0.0389\n",
      "Epoch 65/200, Iteration 8/250, Loss: 0.0067\n",
      "Epoch 65/200, Iteration 9/250, Loss: 0.0164\n",
      "Epoch 65/200, Iteration 10/250, Loss: 0.0403\n",
      "Epoch 65/200, Iteration 11/250, Loss: 0.0195\n",
      "Epoch 65/200, Iteration 12/250, Loss: 0.0108\n",
      "Epoch 65/200, Iteration 13/250, Loss: 0.0276\n",
      "Epoch 65/200, Iteration 14/250, Loss: 0.0189\n",
      "Epoch 65/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 65/200, Iteration 16/250, Loss: 0.0229\n",
      "Epoch 65/200, Iteration 17/250, Loss: 0.0282\n",
      "Epoch 65/200, Iteration 18/250, Loss: 0.0205\n",
      "Epoch 65/200, Iteration 19/250, Loss: 0.0194\n",
      "Epoch 65/200, Iteration 20/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 21/250, Loss: 0.0150\n",
      "Epoch 65/200, Iteration 22/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 65/200, Iteration 24/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 25/250, Loss: 0.0129\n",
      "Epoch 65/200, Iteration 26/250, Loss: 0.0344\n",
      "Epoch 65/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 65/200, Iteration 28/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 29/250, Loss: 0.0093\n",
      "Epoch 65/200, Iteration 30/250, Loss: 0.0151\n",
      "Epoch 65/200, Iteration 31/250, Loss: 0.0098\n",
      "Epoch 65/200, Iteration 32/250, Loss: 0.0189\n",
      "Epoch 65/200, Iteration 33/250, Loss: 0.0130\n",
      "Epoch 65/200, Iteration 34/250, Loss: 0.0158\n",
      "Epoch 65/200, Iteration 35/250, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 36/250, Loss: 0.0177\n",
      "Epoch 65/200, Iteration 37/250, Loss: 0.0299\n",
      "Epoch 65/200, Iteration 38/250, Loss: 0.0189\n",
      "Epoch 65/200, Iteration 39/250, Loss: 0.0144\n",
      "Epoch 65/200, Iteration 40/250, Loss: 0.0127\n",
      "Epoch 65/200, Iteration 41/250, Loss: 0.0192\n",
      "Epoch 65/200, Iteration 42/250, Loss: 0.0208\n",
      "Epoch 65/200, Iteration 43/250, Loss: 0.0238\n",
      "Epoch 65/200, Iteration 44/250, Loss: 0.0085\n",
      "Epoch 65/200, Iteration 45/250, Loss: 0.0248\n",
      "Epoch 65/200, Iteration 46/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 47/250, Loss: 0.0086\n",
      "Epoch 65/200, Iteration 48/250, Loss: 0.0257\n",
      "Epoch 65/200, Iteration 49/250, Loss: 0.0117\n",
      "Epoch 65/200, Iteration 50/250, Loss: 0.0070\n",
      "Epoch 65/200, Iteration 51/250, Loss: 0.0165\n",
      "Epoch 65/200, Iteration 52/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 53/250, Loss: 0.0075\n",
      "Epoch 65/200, Iteration 54/250, Loss: 0.0125\n",
      "Epoch 65/200, Iteration 55/250, Loss: 0.0108\n",
      "Epoch 65/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 65/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 65/200, Iteration 58/250, Loss: 0.0152\n",
      "Epoch 65/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 60/250, Loss: 0.0257\n",
      "Epoch 65/200, Iteration 61/250, Loss: 0.0135\n",
      "Epoch 65/200, Iteration 62/250, Loss: 0.0085\n",
      "Epoch 65/200, Iteration 63/250, Loss: 0.0077\n",
      "Epoch 65/200, Iteration 64/250, Loss: 0.0135\n",
      "Epoch 65/200, Iteration 65/250, Loss: 0.0186\n",
      "Epoch 65/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 65/200, Iteration 67/250, Loss: 0.0157\n",
      "Epoch 65/200, Iteration 68/250, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 69/250, Loss: 0.0229\n",
      "Epoch 65/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 65/200, Iteration 71/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 72/250, Loss: 0.0068\n",
      "Epoch 65/200, Iteration 73/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 74/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 75/250, Loss: 0.0105\n",
      "Epoch 65/200, Iteration 76/250, Loss: 0.0237\n",
      "Epoch 65/200, Iteration 77/250, Loss: 0.0174\n",
      "Epoch 65/200, Iteration 78/250, Loss: 0.0159\n",
      "Epoch 65/200, Iteration 79/250, Loss: 0.0203\n",
      "Epoch 65/200, Iteration 80/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 81/250, Loss: 0.0087\n",
      "Epoch 65/200, Iteration 82/250, Loss: 0.0129\n",
      "Epoch 65/200, Iteration 83/250, Loss: 0.0256\n",
      "Epoch 65/200, Iteration 84/250, Loss: 0.0132\n",
      "Epoch 65/200, Iteration 85/250, Loss: 0.0120\n",
      "Epoch 65/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 88/250, Loss: 0.0246\n",
      "Epoch 65/200, Iteration 89/250, Loss: 0.0256\n",
      "Epoch 65/200, Iteration 90/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 91/250, Loss: 0.0284\n",
      "Epoch 65/200, Iteration 92/250, Loss: 0.0242\n",
      "Epoch 65/200, Iteration 93/250, Loss: 0.0098\n",
      "Epoch 65/200, Iteration 94/250, Loss: 0.0287\n",
      "Epoch 65/200, Iteration 95/250, Loss: 0.0110\n",
      "Epoch 65/200, Iteration 96/250, Loss: 0.0104\n",
      "Epoch 65/200, Iteration 97/250, Loss: 0.0130\n",
      "Epoch 65/200, Iteration 98/250, Loss: 0.0185\n",
      "Epoch 65/200, Iteration 99/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 100/250, Loss: 0.0222\n",
      "Epoch 65/200, Iteration 101/250, Loss: 0.0105\n",
      "Epoch 65/200, Iteration 102/250, Loss: 0.0096\n",
      "Epoch 65/200, Iteration 103/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 104/250, Loss: 0.0147\n",
      "Epoch 65/200, Iteration 105/250, Loss: 0.0135\n",
      "Epoch 65/200, Iteration 106/250, Loss: 0.0081\n",
      "Epoch 65/200, Iteration 107/250, Loss: 0.0257\n",
      "Epoch 65/200, Iteration 108/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 109/250, Loss: 0.0123\n",
      "Epoch 65/200, Iteration 110/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 111/250, Loss: 0.0170\n",
      "Epoch 65/200, Iteration 112/250, Loss: 0.0130\n",
      "Epoch 65/200, Iteration 113/250, Loss: 0.0147\n",
      "Epoch 65/200, Iteration 114/250, Loss: 0.0192\n",
      "Epoch 65/200, Iteration 115/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 116/250, Loss: 0.0211\n",
      "Epoch 65/200, Iteration 117/250, Loss: 0.0110\n",
      "Epoch 65/200, Iteration 118/250, Loss: 0.0081\n",
      "Epoch 65/200, Iteration 119/250, Loss: 0.0374\n",
      "Epoch 65/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 121/250, Loss: 0.0231\n",
      "Epoch 65/200, Iteration 122/250, Loss: 0.0084\n",
      "Epoch 65/200, Iteration 123/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 124/250, Loss: 0.0140\n",
      "Epoch 65/200, Iteration 125/250, Loss: 0.0101\n",
      "Epoch 65/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 127/250, Loss: 0.0205\n",
      "Epoch 65/200, Iteration 128/250, Loss: 0.0100\n",
      "Epoch 65/200, Iteration 129/250, Loss: 0.0140\n",
      "Epoch 65/200, Iteration 130/250, Loss: 0.0273\n",
      "Epoch 65/200, Iteration 131/250, Loss: 0.0196\n",
      "Epoch 65/200, Iteration 132/250, Loss: 0.0086\n",
      "Epoch 65/200, Iteration 133/250, Loss: 0.0092\n",
      "Epoch 65/200, Iteration 134/250, Loss: 0.0083\n",
      "Epoch 65/200, Iteration 135/250, Loss: 0.0131\n",
      "Epoch 65/200, Iteration 136/250, Loss: 0.0073\n",
      "Epoch 65/200, Iteration 137/250, Loss: 0.0184\n",
      "Epoch 65/200, Iteration 138/250, Loss: 0.0123\n",
      "Epoch 65/200, Iteration 139/250, Loss: 0.0106\n",
      "Epoch 65/200, Iteration 140/250, Loss: 0.0157\n",
      "Epoch 65/200, Iteration 141/250, Loss: 0.0188\n",
      "Epoch 65/200, Iteration 142/250, Loss: 0.0129\n",
      "Epoch 65/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 65/200, Iteration 144/250, Loss: 0.0129\n",
      "Epoch 65/200, Iteration 145/250, Loss: 0.0127\n",
      "Epoch 65/200, Iteration 146/250, Loss: 0.0287\n",
      "Epoch 65/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 65/200, Iteration 148/250, Loss: 0.0164\n",
      "Epoch 65/200, Iteration 149/250, Loss: 0.0077\n",
      "Epoch 65/200, Iteration 150/250, Loss: 0.0148\n",
      "Epoch 65/200, Iteration 151/250, Loss: 0.0185\n",
      "Epoch 65/200, Iteration 152/250, Loss: 0.0146\n",
      "Epoch 65/200, Iteration 153/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 155/250, Loss: 0.0464\n",
      "Epoch 65/200, Iteration 156/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 157/250, Loss: 0.0109\n",
      "Epoch 65/200, Iteration 158/250, Loss: 0.0232\n",
      "Epoch 65/200, Iteration 159/250, Loss: 0.0224\n",
      "Epoch 65/200, Iteration 160/250, Loss: 0.0158\n",
      "Epoch 65/200, Iteration 161/250, Loss: 0.0081\n",
      "Epoch 65/200, Iteration 162/250, Loss: 0.0138\n",
      "Epoch 65/200, Iteration 163/250, Loss: 0.0102\n",
      "Epoch 65/200, Iteration 164/250, Loss: 0.0250\n",
      "Epoch 65/200, Iteration 165/250, Loss: 0.0095\n",
      "Epoch 65/200, Iteration 166/250, Loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200, Iteration 167/250, Loss: 0.0094\n",
      "Epoch 65/200, Iteration 168/250, Loss: 0.0102\n",
      "Epoch 65/200, Iteration 169/250, Loss: 0.0164\n",
      "Epoch 65/200, Iteration 170/250, Loss: 0.0112\n",
      "Epoch 65/200, Iteration 171/250, Loss: 0.0204\n",
      "Epoch 65/200, Iteration 172/250, Loss: 0.0193\n",
      "Epoch 65/200, Iteration 173/250, Loss: 0.0090\n",
      "Epoch 65/200, Iteration 174/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 175/250, Loss: 0.0158\n",
      "Epoch 65/200, Iteration 176/250, Loss: 0.0117\n",
      "Epoch 65/200, Iteration 177/250, Loss: 0.0267\n",
      "Epoch 65/200, Iteration 178/250, Loss: 0.0141\n",
      "Epoch 65/200, Iteration 179/250, Loss: 0.0095\n",
      "Epoch 65/200, Iteration 180/250, Loss: 0.0086\n",
      "Epoch 65/200, Iteration 181/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 182/250, Loss: 0.0121\n",
      "Epoch 65/200, Iteration 183/250, Loss: 0.0208\n",
      "Epoch 65/200, Iteration 184/250, Loss: 0.0099\n",
      "Epoch 65/200, Iteration 185/250, Loss: 0.0118\n",
      "Epoch 65/200, Iteration 186/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 188/250, Loss: 0.0089\n",
      "Epoch 65/200, Iteration 189/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 190/250, Loss: 0.0152\n",
      "Epoch 65/200, Iteration 191/250, Loss: 0.0167\n",
      "Epoch 65/200, Iteration 192/250, Loss: 0.0082\n",
      "Epoch 65/200, Iteration 193/250, Loss: 0.0126\n",
      "Epoch 65/200, Iteration 194/250, Loss: 0.0202\n",
      "Epoch 65/200, Iteration 195/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 196/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 197/250, Loss: 0.0124\n",
      "Epoch 65/200, Iteration 198/250, Loss: 0.0088\n",
      "Epoch 65/200, Iteration 199/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 65/200, Iteration 201/250, Loss: 0.0110\n",
      "Epoch 65/200, Iteration 202/250, Loss: 0.0074\n",
      "Epoch 65/200, Iteration 203/250, Loss: 0.0161\n",
      "Epoch 65/200, Iteration 204/250, Loss: 0.0184\n",
      "Epoch 65/200, Iteration 205/250, Loss: 0.0281\n",
      "Epoch 65/200, Iteration 206/250, Loss: 0.0156\n",
      "Epoch 65/200, Iteration 207/250, Loss: 0.0077\n",
      "Epoch 65/200, Iteration 208/250, Loss: 0.0183\n",
      "Epoch 65/200, Iteration 209/250, Loss: 0.0183\n",
      "Epoch 65/200, Iteration 210/250, Loss: 0.0181\n",
      "Epoch 65/200, Iteration 211/250, Loss: 0.0076\n",
      "Epoch 65/200, Iteration 212/250, Loss: 0.0165\n",
      "Epoch 65/200, Iteration 213/250, Loss: 0.0101\n",
      "Epoch 65/200, Iteration 214/250, Loss: 0.0116\n",
      "Epoch 65/200, Iteration 215/250, Loss: 0.0179\n",
      "Epoch 65/200, Iteration 216/250, Loss: 0.0120\n",
      "Epoch 65/200, Iteration 217/250, Loss: 0.0128\n",
      "Epoch 65/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 65/200, Iteration 219/250, Loss: 0.0116\n",
      "Epoch 65/200, Iteration 220/250, Loss: 0.0155\n",
      "Epoch 65/200, Iteration 221/250, Loss: 0.0154\n",
      "Epoch 65/200, Iteration 222/250, Loss: 0.0277\n",
      "Epoch 65/200, Iteration 223/250, Loss: 0.0161\n",
      "Epoch 65/200, Iteration 224/250, Loss: 0.0148\n",
      "Epoch 65/200, Iteration 225/250, Loss: 0.0078\n",
      "Epoch 65/200, Iteration 226/250, Loss: 0.0096\n",
      "Epoch 65/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 65/200, Iteration 228/250, Loss: 0.0140\n",
      "Epoch 65/200, Iteration 229/250, Loss: 0.0227\n",
      "Epoch 65/200, Iteration 230/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 231/250, Loss: 0.0208\n",
      "Epoch 65/200, Iteration 232/250, Loss: 0.0151\n",
      "Epoch 65/200, Iteration 233/250, Loss: 0.0201\n",
      "Epoch 65/200, Iteration 234/250, Loss: 0.0107\n",
      "Epoch 65/200, Iteration 235/250, Loss: 0.0181\n",
      "Epoch 65/200, Iteration 236/250, Loss: 0.0115\n",
      "Epoch 65/200, Iteration 237/250, Loss: 0.0167\n",
      "Epoch 65/200, Iteration 238/250, Loss: 0.0178\n",
      "Epoch 65/200, Iteration 239/250, Loss: 0.0080\n",
      "Epoch 65/200, Iteration 240/250, Loss: 0.0073\n",
      "Epoch 65/200, Iteration 241/250, Loss: 0.0156\n",
      "Epoch 65/200, Iteration 242/250, Loss: 0.0259\n",
      "Epoch 65/200, Iteration 243/250, Loss: 0.0103\n",
      "Epoch 65/200, Iteration 244/250, Loss: 0.0099\n",
      "Epoch 65/200, Iteration 245/250, Loss: 0.0146\n",
      "Epoch 65/200, Iteration 246/250, Loss: 0.0154\n",
      "Epoch 65/200, Iteration 247/250, Loss: 0.0097\n",
      "Epoch 65/200, Iteration 248/250, Loss: 0.0168\n",
      "Epoch 65/200, Iteration 249/250, Loss: 0.0162\n",
      "Epoch 65/200, Iteration 250/250, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.007189, MRE: 0.504310 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.75%, Avg loss: 0.007729, MRE: 0.531225 \n",
      "\n",
      "Epoch 66/200, Iteration 1/250, Loss: 0.0120\n",
      "Epoch 66/200, Iteration 2/250, Loss: 0.0075\n",
      "Epoch 66/200, Iteration 3/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 4/250, Loss: 0.0101\n",
      "Epoch 66/200, Iteration 5/250, Loss: 0.0170\n",
      "Epoch 66/200, Iteration 6/250, Loss: 0.0119\n",
      "Epoch 66/200, Iteration 7/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 8/250, Loss: 0.0127\n",
      "Epoch 66/200, Iteration 9/250, Loss: 0.0125\n",
      "Epoch 66/200, Iteration 10/250, Loss: 0.0085\n",
      "Epoch 66/200, Iteration 11/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 12/250, Loss: 0.0070\n",
      "Epoch 66/200, Iteration 13/250, Loss: 0.0221\n",
      "Epoch 66/200, Iteration 14/250, Loss: 0.0320\n",
      "Epoch 66/200, Iteration 15/250, Loss: 0.0168\n",
      "Epoch 66/200, Iteration 16/250, Loss: 0.0218\n",
      "Epoch 66/200, Iteration 17/250, Loss: 0.0219\n",
      "Epoch 66/200, Iteration 18/250, Loss: 0.0119\n",
      "Epoch 66/200, Iteration 19/250, Loss: 0.0084\n",
      "Epoch 66/200, Iteration 20/250, Loss: 0.0086\n",
      "Epoch 66/200, Iteration 21/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 22/250, Loss: 0.0127\n",
      "Epoch 66/200, Iteration 23/250, Loss: 0.0094\n",
      "Epoch 66/200, Iteration 24/250, Loss: 0.0134\n",
      "Epoch 66/200, Iteration 25/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 26/250, Loss: 0.0197\n",
      "Epoch 66/200, Iteration 27/250, Loss: 0.0090\n",
      "Epoch 66/200, Iteration 28/250, Loss: 0.0173\n",
      "Epoch 66/200, Iteration 29/250, Loss: 0.0110\n",
      "Epoch 66/200, Iteration 30/250, Loss: 0.0070\n",
      "Epoch 66/200, Iteration 31/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 32/250, Loss: 0.0173\n",
      "Epoch 66/200, Iteration 33/250, Loss: 0.0184\n",
      "Epoch 66/200, Iteration 34/250, Loss: 0.0160\n",
      "Epoch 66/200, Iteration 35/250, Loss: 0.0079\n",
      "Epoch 66/200, Iteration 36/250, Loss: 0.0173\n",
      "Epoch 66/200, Iteration 37/250, Loss: 0.0362\n",
      "Epoch 66/200, Iteration 38/250, Loss: 0.0139\n",
      "Epoch 66/200, Iteration 39/250, Loss: 0.0081\n",
      "Epoch 66/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 41/250, Loss: 0.0129\n",
      "Epoch 66/200, Iteration 42/250, Loss: 0.0465\n",
      "Epoch 66/200, Iteration 43/250, Loss: 0.0188\n",
      "Epoch 66/200, Iteration 44/250, Loss: 0.0135\n",
      "Epoch 66/200, Iteration 45/250, Loss: 0.0096\n",
      "Epoch 66/200, Iteration 46/250, Loss: 0.0623\n",
      "Epoch 66/200, Iteration 47/250, Loss: 0.0098\n",
      "Epoch 66/200, Iteration 48/250, Loss: 0.0116\n",
      "Epoch 66/200, Iteration 49/250, Loss: 0.0142\n",
      "Epoch 66/200, Iteration 50/250, Loss: 0.0147\n",
      "Epoch 66/200, Iteration 51/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 52/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 53/250, Loss: 0.0206\n",
      "Epoch 66/200, Iteration 54/250, Loss: 0.0133\n",
      "Epoch 66/200, Iteration 55/250, Loss: 0.0247\n",
      "Epoch 66/200, Iteration 56/250, Loss: 0.0134\n",
      "Epoch 66/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 66/200, Iteration 58/250, Loss: 0.0107\n",
      "Epoch 66/200, Iteration 59/250, Loss: 0.0197\n",
      "Epoch 66/200, Iteration 60/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 61/250, Loss: 0.0201\n",
      "Epoch 66/200, Iteration 62/250, Loss: 0.0105\n",
      "Epoch 66/200, Iteration 63/250, Loss: 0.0067\n",
      "Epoch 66/200, Iteration 64/250, Loss: 0.0077\n",
      "Epoch 66/200, Iteration 65/250, Loss: 0.0144\n",
      "Epoch 66/200, Iteration 66/250, Loss: 0.0220\n",
      "Epoch 66/200, Iteration 67/250, Loss: 0.0131\n",
      "Epoch 66/200, Iteration 68/250, Loss: 0.0140\n",
      "Epoch 66/200, Iteration 69/250, Loss: 0.0179\n",
      "Epoch 66/200, Iteration 70/250, Loss: 0.0163\n",
      "Epoch 66/200, Iteration 71/250, Loss: 0.0064\n",
      "Epoch 66/200, Iteration 72/250, Loss: 0.0106\n",
      "Epoch 66/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 66/200, Iteration 74/250, Loss: 0.0244\n",
      "Epoch 66/200, Iteration 75/250, Loss: 0.0163\n",
      "Epoch 66/200, Iteration 76/250, Loss: 0.0216\n",
      "Epoch 66/200, Iteration 77/250, Loss: 0.0083\n",
      "Epoch 66/200, Iteration 78/250, Loss: 0.0109\n",
      "Epoch 66/200, Iteration 79/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 80/250, Loss: 0.0072\n",
      "Epoch 66/200, Iteration 81/250, Loss: 0.0185\n",
      "Epoch 66/200, Iteration 82/250, Loss: 0.0235\n",
      "Epoch 66/200, Iteration 83/250, Loss: 0.0114\n",
      "Epoch 66/200, Iteration 84/250, Loss: 0.0112\n",
      "Epoch 66/200, Iteration 85/250, Loss: 0.0176\n",
      "Epoch 66/200, Iteration 86/250, Loss: 0.0100\n",
      "Epoch 66/200, Iteration 87/250, Loss: 0.0091\n",
      "Epoch 66/200, Iteration 88/250, Loss: 0.0182\n",
      "Epoch 66/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 66/200, Iteration 90/250, Loss: 0.0192\n",
      "Epoch 66/200, Iteration 91/250, Loss: 0.0305\n",
      "Epoch 66/200, Iteration 92/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 93/250, Loss: 0.0123\n",
      "Epoch 66/200, Iteration 94/250, Loss: 0.0095\n",
      "Epoch 66/200, Iteration 95/250, Loss: 0.0116\n",
      "Epoch 66/200, Iteration 96/250, Loss: 0.0159\n",
      "Epoch 66/200, Iteration 97/250, Loss: 0.0092\n",
      "Epoch 66/200, Iteration 98/250, Loss: 0.0160\n",
      "Epoch 66/200, Iteration 99/250, Loss: 0.0112\n",
      "Epoch 66/200, Iteration 100/250, Loss: 0.0161\n",
      "Epoch 66/200, Iteration 101/250, Loss: 0.0134\n",
      "Epoch 66/200, Iteration 102/250, Loss: 0.0141\n",
      "Epoch 66/200, Iteration 103/250, Loss: 0.0251\n",
      "Epoch 66/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 66/200, Iteration 105/250, Loss: 0.0147\n",
      "Epoch 66/200, Iteration 106/250, Loss: 0.0090\n",
      "Epoch 66/200, Iteration 107/250, Loss: 0.0125\n",
      "Epoch 66/200, Iteration 108/250, Loss: 0.0182\n",
      "Epoch 66/200, Iteration 109/250, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200, Iteration 110/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 111/250, Loss: 0.0066\n",
      "Epoch 66/200, Iteration 112/250, Loss: 0.0126\n",
      "Epoch 66/200, Iteration 113/250, Loss: 0.0115\n",
      "Epoch 66/200, Iteration 114/250, Loss: 0.0099\n",
      "Epoch 66/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 66/200, Iteration 116/250, Loss: 0.0097\n",
      "Epoch 66/200, Iteration 117/250, Loss: 0.0152\n",
      "Epoch 66/200, Iteration 118/250, Loss: 0.0157\n",
      "Epoch 66/200, Iteration 119/250, Loss: 0.0095\n",
      "Epoch 66/200, Iteration 120/250, Loss: 0.0123\n",
      "Epoch 66/200, Iteration 121/250, Loss: 0.0068\n",
      "Epoch 66/200, Iteration 122/250, Loss: 0.0105\n",
      "Epoch 66/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 66/200, Iteration 124/250, Loss: 0.0121\n",
      "Epoch 66/200, Iteration 125/250, Loss: 0.0138\n",
      "Epoch 66/200, Iteration 126/250, Loss: 0.0108\n",
      "Epoch 66/200, Iteration 127/250, Loss: 0.0166\n",
      "Epoch 66/200, Iteration 128/250, Loss: 0.0174\n",
      "Epoch 66/200, Iteration 129/250, Loss: 0.0114\n",
      "Epoch 66/200, Iteration 130/250, Loss: 0.0092\n",
      "Epoch 66/200, Iteration 131/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 132/250, Loss: 0.0059\n",
      "Epoch 66/200, Iteration 133/250, Loss: 0.0134\n",
      "Epoch 66/200, Iteration 134/250, Loss: 0.0229\n",
      "Epoch 66/200, Iteration 135/250, Loss: 0.0157\n",
      "Epoch 66/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 66/200, Iteration 137/250, Loss: 0.0242\n",
      "Epoch 66/200, Iteration 138/250, Loss: 0.0158\n",
      "Epoch 66/200, Iteration 139/250, Loss: 0.0207\n",
      "Epoch 66/200, Iteration 140/250, Loss: 0.0143\n",
      "Epoch 66/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 66/200, Iteration 142/250, Loss: 0.0311\n",
      "Epoch 66/200, Iteration 143/250, Loss: 0.0195\n",
      "Epoch 66/200, Iteration 144/250, Loss: 0.0132\n",
      "Epoch 66/200, Iteration 145/250, Loss: 0.0129\n",
      "Epoch 66/200, Iteration 146/250, Loss: 0.0071\n",
      "Epoch 66/200, Iteration 147/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 148/250, Loss: 0.0107\n",
      "Epoch 66/200, Iteration 149/250, Loss: 0.0197\n",
      "Epoch 66/200, Iteration 150/250, Loss: 0.0126\n",
      "Epoch 66/200, Iteration 151/250, Loss: 0.0178\n",
      "Epoch 66/200, Iteration 152/250, Loss: 0.0346\n",
      "Epoch 66/200, Iteration 153/250, Loss: 0.0145\n",
      "Epoch 66/200, Iteration 154/250, Loss: 0.0276\n",
      "Epoch 66/200, Iteration 155/250, Loss: 0.0233\n",
      "Epoch 66/200, Iteration 156/250, Loss: 0.0094\n",
      "Epoch 66/200, Iteration 157/250, Loss: 0.0175\n",
      "Epoch 66/200, Iteration 158/250, Loss: 0.0122\n",
      "Epoch 66/200, Iteration 159/250, Loss: 0.0254\n",
      "Epoch 66/200, Iteration 160/250, Loss: 0.0278\n",
      "Epoch 66/200, Iteration 161/250, Loss: 0.0148\n",
      "Epoch 66/200, Iteration 162/250, Loss: 0.0129\n",
      "Epoch 66/200, Iteration 163/250, Loss: 0.0234\n",
      "Epoch 66/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 66/200, Iteration 165/250, Loss: 0.0071\n",
      "Epoch 66/200, Iteration 166/250, Loss: 0.0172\n",
      "Epoch 66/200, Iteration 167/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 168/250, Loss: 0.0161\n",
      "Epoch 66/200, Iteration 169/250, Loss: 0.0133\n",
      "Epoch 66/200, Iteration 170/250, Loss: 0.0131\n",
      "Epoch 66/200, Iteration 171/250, Loss: 0.0116\n",
      "Epoch 66/200, Iteration 172/250, Loss: 0.0243\n",
      "Epoch 66/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 66/200, Iteration 175/250, Loss: 0.0095\n",
      "Epoch 66/200, Iteration 176/250, Loss: 0.0260\n",
      "Epoch 66/200, Iteration 177/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 178/250, Loss: 0.0167\n",
      "Epoch 66/200, Iteration 179/250, Loss: 0.0092\n",
      "Epoch 66/200, Iteration 180/250, Loss: 0.0243\n",
      "Epoch 66/200, Iteration 181/250, Loss: 0.0094\n",
      "Epoch 66/200, Iteration 182/250, Loss: 0.0161\n",
      "Epoch 66/200, Iteration 183/250, Loss: 0.0120\n",
      "Epoch 66/200, Iteration 184/250, Loss: 0.0267\n",
      "Epoch 66/200, Iteration 185/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 186/250, Loss: 0.0194\n",
      "Epoch 66/200, Iteration 187/250, Loss: 0.0183\n",
      "Epoch 66/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 66/200, Iteration 189/250, Loss: 0.0341\n",
      "Epoch 66/200, Iteration 190/250, Loss: 0.0199\n",
      "Epoch 66/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 66/200, Iteration 192/250, Loss: 0.0096\n",
      "Epoch 66/200, Iteration 193/250, Loss: 0.0069\n",
      "Epoch 66/200, Iteration 194/250, Loss: 0.0168\n",
      "Epoch 66/200, Iteration 195/250, Loss: 0.0173\n",
      "Epoch 66/200, Iteration 196/250, Loss: 0.0108\n",
      "Epoch 66/200, Iteration 197/250, Loss: 0.0354\n",
      "Epoch 66/200, Iteration 198/250, Loss: 0.0239\n",
      "Epoch 66/200, Iteration 199/250, Loss: 0.0104\n",
      "Epoch 66/200, Iteration 200/250, Loss: 0.0139\n",
      "Epoch 66/200, Iteration 201/250, Loss: 0.0163\n",
      "Epoch 66/200, Iteration 202/250, Loss: 0.0205\n",
      "Epoch 66/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 66/200, Iteration 204/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 205/250, Loss: 0.0124\n",
      "Epoch 66/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 66/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 66/200, Iteration 208/250, Loss: 0.0165\n",
      "Epoch 66/200, Iteration 209/250, Loss: 0.0111\n",
      "Epoch 66/200, Iteration 210/250, Loss: 0.0159\n",
      "Epoch 66/200, Iteration 211/250, Loss: 0.0151\n",
      "Epoch 66/200, Iteration 212/250, Loss: 0.0098\n",
      "Epoch 66/200, Iteration 213/250, Loss: 0.0106\n",
      "Epoch 66/200, Iteration 214/250, Loss: 0.0232\n",
      "Epoch 66/200, Iteration 215/250, Loss: 0.0091\n",
      "Epoch 66/200, Iteration 216/250, Loss: 0.0097\n",
      "Epoch 66/200, Iteration 217/250, Loss: 0.0183\n",
      "Epoch 66/200, Iteration 218/250, Loss: 0.0103\n",
      "Epoch 66/200, Iteration 219/250, Loss: 0.0130\n",
      "Epoch 66/200, Iteration 220/250, Loss: 0.0085\n",
      "Epoch 66/200, Iteration 221/250, Loss: 0.0186\n",
      "Epoch 66/200, Iteration 222/250, Loss: 0.0192\n",
      "Epoch 66/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 66/200, Iteration 224/250, Loss: 0.0393\n",
      "Epoch 66/200, Iteration 225/250, Loss: 0.0163\n",
      "Epoch 66/200, Iteration 226/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 227/250, Loss: 0.0071\n",
      "Epoch 66/200, Iteration 228/250, Loss: 0.0137\n",
      "Epoch 66/200, Iteration 229/250, Loss: 0.0084\n",
      "Epoch 66/200, Iteration 230/250, Loss: 0.0097\n",
      "Epoch 66/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 66/200, Iteration 232/250, Loss: 0.0130\n",
      "Epoch 66/200, Iteration 233/250, Loss: 0.0122\n",
      "Epoch 66/200, Iteration 234/250, Loss: 0.0117\n",
      "Epoch 66/200, Iteration 235/250, Loss: 0.0113\n",
      "Epoch 66/200, Iteration 236/250, Loss: 0.0088\n",
      "Epoch 66/200, Iteration 237/250, Loss: 0.0100\n",
      "Epoch 66/200, Iteration 238/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 239/250, Loss: 0.0403\n",
      "Epoch 66/200, Iteration 240/250, Loss: 0.0246\n",
      "Epoch 66/200, Iteration 241/250, Loss: 0.0276\n",
      "Epoch 66/200, Iteration 242/250, Loss: 0.0128\n",
      "Epoch 66/200, Iteration 243/250, Loss: 0.0118\n",
      "Epoch 66/200, Iteration 244/250, Loss: 0.0215\n",
      "Epoch 66/200, Iteration 245/250, Loss: 0.0116\n",
      "Epoch 66/200, Iteration 246/250, Loss: 0.0440\n",
      "Epoch 66/200, Iteration 247/250, Loss: 0.0160\n",
      "Epoch 66/200, Iteration 248/250, Loss: 0.0075\n",
      "Epoch 66/200, Iteration 249/250, Loss: 0.0094\n",
      "Epoch 66/200, Iteration 250/250, Loss: 0.0117\n",
      "Train Error: \n",
      " Accuracy: 70.46%, Avg loss: 0.008382, MRE: 0.648959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.05%, Avg loss: 0.008773, MRE: 0.657022 \n",
      "\n",
      "Epoch 67/200, Iteration 1/250, Loss: 0.0093\n",
      "Epoch 67/200, Iteration 2/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 3/250, Loss: 0.0075\n",
      "Epoch 67/200, Iteration 4/250, Loss: 0.0204\n",
      "Epoch 67/200, Iteration 5/250, Loss: 0.0287\n",
      "Epoch 67/200, Iteration 6/250, Loss: 0.0153\n",
      "Epoch 67/200, Iteration 7/250, Loss: 0.0256\n",
      "Epoch 67/200, Iteration 8/250, Loss: 0.0114\n",
      "Epoch 67/200, Iteration 9/250, Loss: 0.0112\n",
      "Epoch 67/200, Iteration 10/250, Loss: 0.0089\n",
      "Epoch 67/200, Iteration 11/250, Loss: 0.0263\n",
      "Epoch 67/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 67/200, Iteration 13/250, Loss: 0.0245\n",
      "Epoch 67/200, Iteration 14/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 15/250, Loss: 0.0156\n",
      "Epoch 67/200, Iteration 16/250, Loss: 0.0111\n",
      "Epoch 67/200, Iteration 17/250, Loss: 0.0151\n",
      "Epoch 67/200, Iteration 18/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 19/250, Loss: 0.0183\n",
      "Epoch 67/200, Iteration 20/250, Loss: 0.0136\n",
      "Epoch 67/200, Iteration 21/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 22/250, Loss: 0.0191\n",
      "Epoch 67/200, Iteration 23/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 24/250, Loss: 0.0128\n",
      "Epoch 67/200, Iteration 25/250, Loss: 0.0128\n",
      "Epoch 67/200, Iteration 26/250, Loss: 0.0170\n",
      "Epoch 67/200, Iteration 27/250, Loss: 0.0188\n",
      "Epoch 67/200, Iteration 28/250, Loss: 0.0114\n",
      "Epoch 67/200, Iteration 29/250, Loss: 0.0149\n",
      "Epoch 67/200, Iteration 30/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 31/250, Loss: 0.0125\n",
      "Epoch 67/200, Iteration 32/250, Loss: 0.0098\n",
      "Epoch 67/200, Iteration 33/250, Loss: 0.0150\n",
      "Epoch 67/200, Iteration 34/250, Loss: 0.0070\n",
      "Epoch 67/200, Iteration 35/250, Loss: 0.0147\n",
      "Epoch 67/200, Iteration 36/250, Loss: 0.0094\n",
      "Epoch 67/200, Iteration 37/250, Loss: 0.0297\n",
      "Epoch 67/200, Iteration 38/250, Loss: 0.0152\n",
      "Epoch 67/200, Iteration 39/250, Loss: 0.0190\n",
      "Epoch 67/200, Iteration 40/250, Loss: 0.0188\n",
      "Epoch 67/200, Iteration 41/250, Loss: 0.0132\n",
      "Epoch 67/200, Iteration 42/250, Loss: 0.0256\n",
      "Epoch 67/200, Iteration 43/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 44/250, Loss: 0.0091\n",
      "Epoch 67/200, Iteration 45/250, Loss: 0.0179\n",
      "Epoch 67/200, Iteration 46/250, Loss: 0.0175\n",
      "Epoch 67/200, Iteration 47/250, Loss: 0.0236\n",
      "Epoch 67/200, Iteration 48/250, Loss: 0.0268\n",
      "Epoch 67/200, Iteration 49/250, Loss: 0.0149\n",
      "Epoch 67/200, Iteration 50/250, Loss: 0.0213\n",
      "Epoch 67/200, Iteration 51/250, Loss: 0.0101\n",
      "Epoch 67/200, Iteration 52/250, Loss: 0.0098\n",
      "Epoch 67/200, Iteration 53/250, Loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200, Iteration 54/250, Loss: 0.0120\n",
      "Epoch 67/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 67/200, Iteration 56/250, Loss: 0.0098\n",
      "Epoch 67/200, Iteration 57/250, Loss: 0.0155\n",
      "Epoch 67/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 67/200, Iteration 59/250, Loss: 0.0111\n",
      "Epoch 67/200, Iteration 60/250, Loss: 0.0080\n",
      "Epoch 67/200, Iteration 61/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 62/250, Loss: 0.0130\n",
      "Epoch 67/200, Iteration 63/250, Loss: 0.0137\n",
      "Epoch 67/200, Iteration 64/250, Loss: 0.0104\n",
      "Epoch 67/200, Iteration 65/250, Loss: 0.0211\n",
      "Epoch 67/200, Iteration 66/250, Loss: 0.0168\n",
      "Epoch 67/200, Iteration 67/250, Loss: 0.0067\n",
      "Epoch 67/200, Iteration 68/250, Loss: 0.0164\n",
      "Epoch 67/200, Iteration 69/250, Loss: 0.0152\n",
      "Epoch 67/200, Iteration 70/250, Loss: 0.0205\n",
      "Epoch 67/200, Iteration 71/250, Loss: 0.0141\n",
      "Epoch 67/200, Iteration 72/250, Loss: 0.0132\n",
      "Epoch 67/200, Iteration 73/250, Loss: 0.0184\n",
      "Epoch 67/200, Iteration 74/250, Loss: 0.0350\n",
      "Epoch 67/200, Iteration 75/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 76/250, Loss: 0.0157\n",
      "Epoch 67/200, Iteration 77/250, Loss: 0.0232\n",
      "Epoch 67/200, Iteration 78/250, Loss: 0.0133\n",
      "Epoch 67/200, Iteration 79/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 80/250, Loss: 0.0545\n",
      "Epoch 67/200, Iteration 81/250, Loss: 0.0300\n",
      "Epoch 67/200, Iteration 82/250, Loss: 0.0276\n",
      "Epoch 67/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 67/200, Iteration 84/250, Loss: 0.0215\n",
      "Epoch 67/200, Iteration 85/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 86/250, Loss: 0.0118\n",
      "Epoch 67/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 88/250, Loss: 0.0245\n",
      "Epoch 67/200, Iteration 89/250, Loss: 0.0190\n",
      "Epoch 67/200, Iteration 90/250, Loss: 0.0174\n",
      "Epoch 67/200, Iteration 91/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 92/250, Loss: 0.0083\n",
      "Epoch 67/200, Iteration 93/250, Loss: 0.0216\n",
      "Epoch 67/200, Iteration 94/250, Loss: 0.0091\n",
      "Epoch 67/200, Iteration 95/250, Loss: 0.0238\n",
      "Epoch 67/200, Iteration 96/250, Loss: 0.0244\n",
      "Epoch 67/200, Iteration 97/250, Loss: 0.0210\n",
      "Epoch 67/200, Iteration 98/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 67/200, Iteration 100/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 67/200, Iteration 102/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 103/250, Loss: 0.0072\n",
      "Epoch 67/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 67/200, Iteration 105/250, Loss: 0.0191\n",
      "Epoch 67/200, Iteration 106/250, Loss: 0.0298\n",
      "Epoch 67/200, Iteration 107/250, Loss: 0.0100\n",
      "Epoch 67/200, Iteration 108/250, Loss: 0.0111\n",
      "Epoch 67/200, Iteration 109/250, Loss: 0.0127\n",
      "Epoch 67/200, Iteration 110/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 111/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 112/250, Loss: 0.0169\n",
      "Epoch 67/200, Iteration 113/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 114/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 115/250, Loss: 0.0109\n",
      "Epoch 67/200, Iteration 116/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 117/250, Loss: 0.0191\n",
      "Epoch 67/200, Iteration 118/250, Loss: 0.0325\n",
      "Epoch 67/200, Iteration 119/250, Loss: 0.0106\n",
      "Epoch 67/200, Iteration 120/250, Loss: 0.0144\n",
      "Epoch 67/200, Iteration 121/250, Loss: 0.0300\n",
      "Epoch 67/200, Iteration 122/250, Loss: 0.0126\n",
      "Epoch 67/200, Iteration 123/250, Loss: 0.0080\n",
      "Epoch 67/200, Iteration 124/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 125/250, Loss: 0.0105\n",
      "Epoch 67/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 67/200, Iteration 127/250, Loss: 0.0073\n",
      "Epoch 67/200, Iteration 128/250, Loss: 0.0206\n",
      "Epoch 67/200, Iteration 129/250, Loss: 0.0226\n",
      "Epoch 67/200, Iteration 130/250, Loss: 0.0204\n",
      "Epoch 67/200, Iteration 131/250, Loss: 0.0079\n",
      "Epoch 67/200, Iteration 132/250, Loss: 0.0222\n",
      "Epoch 67/200, Iteration 133/250, Loss: 0.0169\n",
      "Epoch 67/200, Iteration 134/250, Loss: 0.0147\n",
      "Epoch 67/200, Iteration 135/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 136/250, Loss: 0.0089\n",
      "Epoch 67/200, Iteration 137/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 138/250, Loss: 0.0269\n",
      "Epoch 67/200, Iteration 139/250, Loss: 0.0130\n",
      "Epoch 67/200, Iteration 140/250, Loss: 0.0242\n",
      "Epoch 67/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 67/200, Iteration 142/250, Loss: 0.0098\n",
      "Epoch 67/200, Iteration 143/250, Loss: 0.0197\n",
      "Epoch 67/200, Iteration 144/250, Loss: 0.0223\n",
      "Epoch 67/200, Iteration 145/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 146/250, Loss: 0.0169\n",
      "Epoch 67/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 148/250, Loss: 0.0118\n",
      "Epoch 67/200, Iteration 149/250, Loss: 0.0116\n",
      "Epoch 67/200, Iteration 150/250, Loss: 0.0077\n",
      "Epoch 67/200, Iteration 151/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 152/250, Loss: 0.0251\n",
      "Epoch 67/200, Iteration 153/250, Loss: 0.0119\n",
      "Epoch 67/200, Iteration 154/250, Loss: 0.0064\n",
      "Epoch 67/200, Iteration 155/250, Loss: 0.0163\n",
      "Epoch 67/200, Iteration 156/250, Loss: 0.0170\n",
      "Epoch 67/200, Iteration 157/250, Loss: 0.0197\n",
      "Epoch 67/200, Iteration 158/250, Loss: 0.0124\n",
      "Epoch 67/200, Iteration 159/250, Loss: 0.0278\n",
      "Epoch 67/200, Iteration 160/250, Loss: 0.0144\n",
      "Epoch 67/200, Iteration 161/250, Loss: 0.0072\n",
      "Epoch 67/200, Iteration 162/250, Loss: 0.0091\n",
      "Epoch 67/200, Iteration 163/250, Loss: 0.0093\n",
      "Epoch 67/200, Iteration 164/250, Loss: 0.0126\n",
      "Epoch 67/200, Iteration 165/250, Loss: 0.0226\n",
      "Epoch 67/200, Iteration 166/250, Loss: 0.0358\n",
      "Epoch 67/200, Iteration 167/250, Loss: 0.0105\n",
      "Epoch 67/200, Iteration 168/250, Loss: 0.0303\n",
      "Epoch 67/200, Iteration 169/250, Loss: 0.0135\n",
      "Epoch 67/200, Iteration 170/250, Loss: 0.0094\n",
      "Epoch 67/200, Iteration 171/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 172/250, Loss: 0.0265\n",
      "Epoch 67/200, Iteration 173/250, Loss: 0.0231\n",
      "Epoch 67/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 67/200, Iteration 175/250, Loss: 0.0103\n",
      "Epoch 67/200, Iteration 176/250, Loss: 0.0285\n",
      "Epoch 67/200, Iteration 177/250, Loss: 0.0194\n",
      "Epoch 67/200, Iteration 178/250, Loss: 0.0130\n",
      "Epoch 67/200, Iteration 179/250, Loss: 0.0310\n",
      "Epoch 67/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 67/200, Iteration 181/250, Loss: 0.0107\n",
      "Epoch 67/200, Iteration 182/250, Loss: 0.0143\n",
      "Epoch 67/200, Iteration 183/250, Loss: 0.0157\n",
      "Epoch 67/200, Iteration 184/250, Loss: 0.0153\n",
      "Epoch 67/200, Iteration 185/250, Loss: 0.0085\n",
      "Epoch 67/200, Iteration 186/250, Loss: 0.0143\n",
      "Epoch 67/200, Iteration 187/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 188/250, Loss: 0.0137\n",
      "Epoch 67/200, Iteration 189/250, Loss: 0.0234\n",
      "Epoch 67/200, Iteration 190/250, Loss: 0.0204\n",
      "Epoch 67/200, Iteration 191/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 192/250, Loss: 0.0106\n",
      "Epoch 67/200, Iteration 193/250, Loss: 0.0054\n",
      "Epoch 67/200, Iteration 194/250, Loss: 0.0362\n",
      "Epoch 67/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 67/200, Iteration 196/250, Loss: 0.0317\n",
      "Epoch 67/200, Iteration 197/250, Loss: 0.0448\n",
      "Epoch 67/200, Iteration 198/250, Loss: 0.0172\n",
      "Epoch 67/200, Iteration 199/250, Loss: 0.0186\n",
      "Epoch 67/200, Iteration 200/250, Loss: 0.0155\n",
      "Epoch 67/200, Iteration 201/250, Loss: 0.0188\n",
      "Epoch 67/200, Iteration 202/250, Loss: 0.0171\n",
      "Epoch 67/200, Iteration 203/250, Loss: 0.0198\n",
      "Epoch 67/200, Iteration 204/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 205/250, Loss: 0.0102\n",
      "Epoch 67/200, Iteration 206/250, Loss: 0.0138\n",
      "Epoch 67/200, Iteration 207/250, Loss: 0.0129\n",
      "Epoch 67/200, Iteration 208/250, Loss: 0.0158\n",
      "Epoch 67/200, Iteration 209/250, Loss: 0.0131\n",
      "Epoch 67/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 67/200, Iteration 211/250, Loss: 0.0119\n",
      "Epoch 67/200, Iteration 212/250, Loss: 0.0274\n",
      "Epoch 67/200, Iteration 213/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 214/250, Loss: 0.0283\n",
      "Epoch 67/200, Iteration 215/250, Loss: 0.0192\n",
      "Epoch 67/200, Iteration 216/250, Loss: 0.0099\n",
      "Epoch 67/200, Iteration 217/250, Loss: 0.0118\n",
      "Epoch 67/200, Iteration 218/250, Loss: 0.0081\n",
      "Epoch 67/200, Iteration 219/250, Loss: 0.0169\n",
      "Epoch 67/200, Iteration 220/250, Loss: 0.0092\n",
      "Epoch 67/200, Iteration 221/250, Loss: 0.0086\n",
      "Epoch 67/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 67/200, Iteration 223/250, Loss: 0.0139\n",
      "Epoch 67/200, Iteration 224/250, Loss: 0.0113\n",
      "Epoch 67/200, Iteration 225/250, Loss: 0.0357\n",
      "Epoch 67/200, Iteration 226/250, Loss: 0.0082\n",
      "Epoch 67/200, Iteration 227/250, Loss: 0.0181\n",
      "Epoch 67/200, Iteration 228/250, Loss: 0.0260\n",
      "Epoch 67/200, Iteration 229/250, Loss: 0.0077\n",
      "Epoch 67/200, Iteration 230/250, Loss: 0.0151\n",
      "Epoch 67/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 67/200, Iteration 232/250, Loss: 0.0146\n",
      "Epoch 67/200, Iteration 233/250, Loss: 0.0093\n",
      "Epoch 67/200, Iteration 234/250, Loss: 0.0115\n",
      "Epoch 67/200, Iteration 235/250, Loss: 0.0110\n",
      "Epoch 67/200, Iteration 236/250, Loss: 0.0183\n",
      "Epoch 67/200, Iteration 237/250, Loss: 0.0132\n",
      "Epoch 67/200, Iteration 238/250, Loss: 0.0130\n",
      "Epoch 67/200, Iteration 239/250, Loss: 0.0143\n",
      "Epoch 67/200, Iteration 240/250, Loss: 0.0111\n",
      "Epoch 67/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 67/200, Iteration 242/250, Loss: 0.0137\n",
      "Epoch 67/200, Iteration 243/250, Loss: 0.0118\n",
      "Epoch 67/200, Iteration 244/250, Loss: 0.0165\n",
      "Epoch 67/200, Iteration 245/250, Loss: 0.0168\n",
      "Epoch 67/200, Iteration 246/250, Loss: 0.0358\n",
      "Epoch 67/200, Iteration 247/250, Loss: 0.0100\n",
      "Epoch 67/200, Iteration 248/250, Loss: 0.0078\n",
      "Epoch 67/200, Iteration 249/250, Loss: 0.0153\n",
      "Epoch 67/200, Iteration 250/250, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 84.95%, Avg loss: 0.007220, MRE: 0.541788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.25%, Avg loss: 0.007764, MRE: 0.730972 \n",
      "\n",
      "Epoch 68/200, Iteration 1/250, Loss: 0.0134\n",
      "Epoch 68/200, Iteration 2/250, Loss: 0.0286\n",
      "Epoch 68/200, Iteration 3/250, Loss: 0.0151\n",
      "Epoch 68/200, Iteration 4/250, Loss: 0.0099\n",
      "Epoch 68/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 68/200, Iteration 6/250, Loss: 0.0162\n",
      "Epoch 68/200, Iteration 7/250, Loss: 0.0124\n",
      "Epoch 68/200, Iteration 8/250, Loss: 0.0117\n",
      "Epoch 68/200, Iteration 9/250, Loss: 0.0144\n",
      "Epoch 68/200, Iteration 10/250, Loss: 0.0316\n",
      "Epoch 68/200, Iteration 11/250, Loss: 0.0273\n",
      "Epoch 68/200, Iteration 12/250, Loss: 0.0158\n",
      "Epoch 68/200, Iteration 13/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 14/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 15/250, Loss: 0.0135\n",
      "Epoch 68/200, Iteration 16/250, Loss: 0.0084\n",
      "Epoch 68/200, Iteration 17/250, Loss: 0.0109\n",
      "Epoch 68/200, Iteration 18/250, Loss: 0.0205\n",
      "Epoch 68/200, Iteration 19/250, Loss: 0.0144\n",
      "Epoch 68/200, Iteration 20/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 21/250, Loss: 0.0092\n",
      "Epoch 68/200, Iteration 22/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 23/250, Loss: 0.0155\n",
      "Epoch 68/200, Iteration 24/250, Loss: 0.0132\n",
      "Epoch 68/200, Iteration 25/250, Loss: 0.0217\n",
      "Epoch 68/200, Iteration 26/250, Loss: 0.0085\n",
      "Epoch 68/200, Iteration 27/250, Loss: 0.0095\n",
      "Epoch 68/200, Iteration 28/250, Loss: 0.0089\n",
      "Epoch 68/200, Iteration 29/250, Loss: 0.0077\n",
      "Epoch 68/200, Iteration 30/250, Loss: 0.0100\n",
      "Epoch 68/200, Iteration 31/250, Loss: 0.0120\n",
      "Epoch 68/200, Iteration 32/250, Loss: 0.0081\n",
      "Epoch 68/200, Iteration 33/250, Loss: 0.0129\n",
      "Epoch 68/200, Iteration 34/250, Loss: 0.0067\n",
      "Epoch 68/200, Iteration 35/250, Loss: 0.0086\n",
      "Epoch 68/200, Iteration 36/250, Loss: 0.0194\n",
      "Epoch 68/200, Iteration 37/250, Loss: 0.0084\n",
      "Epoch 68/200, Iteration 38/250, Loss: 0.0164\n",
      "Epoch 68/200, Iteration 39/250, Loss: 0.0129\n",
      "Epoch 68/200, Iteration 40/250, Loss: 0.0138\n",
      "Epoch 68/200, Iteration 41/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 42/250, Loss: 0.0155\n",
      "Epoch 68/200, Iteration 43/250, Loss: 0.0143\n",
      "Epoch 68/200, Iteration 44/250, Loss: 0.0138\n",
      "Epoch 68/200, Iteration 45/250, Loss: 0.0176\n",
      "Epoch 68/200, Iteration 46/250, Loss: 0.0293\n",
      "Epoch 68/200, Iteration 47/250, Loss: 0.0073\n",
      "Epoch 68/200, Iteration 48/250, Loss: 0.0120\n",
      "Epoch 68/200, Iteration 49/250, Loss: 0.0140\n",
      "Epoch 68/200, Iteration 50/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 51/250, Loss: 0.0113\n",
      "Epoch 68/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 53/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 54/250, Loss: 0.0103\n",
      "Epoch 68/200, Iteration 55/250, Loss: 0.0084\n",
      "Epoch 68/200, Iteration 56/250, Loss: 0.0316\n",
      "Epoch 68/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 68/200, Iteration 58/250, Loss: 0.0244\n",
      "Epoch 68/200, Iteration 59/250, Loss: 0.0130\n",
      "Epoch 68/200, Iteration 60/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 61/250, Loss: 0.0160\n",
      "Epoch 68/200, Iteration 62/250, Loss: 0.0098\n",
      "Epoch 68/200, Iteration 63/250, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 64/250, Loss: 0.0315\n",
      "Epoch 68/200, Iteration 65/250, Loss: 0.0185\n",
      "Epoch 68/200, Iteration 66/250, Loss: 0.0111\n",
      "Epoch 68/200, Iteration 67/250, Loss: 0.0183\n",
      "Epoch 68/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 68/200, Iteration 69/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 70/250, Loss: 0.0182\n",
      "Epoch 68/200, Iteration 71/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 72/250, Loss: 0.0286\n",
      "Epoch 68/200, Iteration 73/250, Loss: 0.0112\n",
      "Epoch 68/200, Iteration 74/250, Loss: 0.0081\n",
      "Epoch 68/200, Iteration 75/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 76/250, Loss: 0.0140\n",
      "Epoch 68/200, Iteration 77/250, Loss: 0.0106\n",
      "Epoch 68/200, Iteration 78/250, Loss: 0.0277\n",
      "Epoch 68/200, Iteration 79/250, Loss: 0.0182\n",
      "Epoch 68/200, Iteration 80/250, Loss: 0.0155\n",
      "Epoch 68/200, Iteration 81/250, Loss: 0.0246\n",
      "Epoch 68/200, Iteration 82/250, Loss: 0.0084\n",
      "Epoch 68/200, Iteration 83/250, Loss: 0.0244\n",
      "Epoch 68/200, Iteration 84/250, Loss: 0.0338\n",
      "Epoch 68/200, Iteration 85/250, Loss: 0.0207\n",
      "Epoch 68/200, Iteration 86/250, Loss: 0.0220\n",
      "Epoch 68/200, Iteration 87/250, Loss: 0.0191\n",
      "Epoch 68/200, Iteration 88/250, Loss: 0.0255\n",
      "Epoch 68/200, Iteration 89/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 90/250, Loss: 0.0188\n",
      "Epoch 68/200, Iteration 91/250, Loss: 0.0083\n",
      "Epoch 68/200, Iteration 92/250, Loss: 0.0069\n",
      "Epoch 68/200, Iteration 93/250, Loss: 0.0156\n",
      "Epoch 68/200, Iteration 94/250, Loss: 0.0158\n",
      "Epoch 68/200, Iteration 95/250, Loss: 0.0206\n",
      "Epoch 68/200, Iteration 96/250, Loss: 0.0148\n",
      "Epoch 68/200, Iteration 97/250, Loss: 0.0108\n",
      "Epoch 68/200, Iteration 98/250, Loss: 0.0208\n",
      "Epoch 68/200, Iteration 99/250, Loss: 0.0465\n",
      "Epoch 68/200, Iteration 100/250, Loss: 0.0228\n",
      "Epoch 68/200, Iteration 101/250, Loss: 0.0135\n",
      "Epoch 68/200, Iteration 102/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 103/250, Loss: 0.0210\n",
      "Epoch 68/200, Iteration 104/250, Loss: 0.0175\n",
      "Epoch 68/200, Iteration 105/250, Loss: 0.0101\n",
      "Epoch 68/200, Iteration 106/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 107/250, Loss: 0.0296\n",
      "Epoch 68/200, Iteration 108/250, Loss: 0.0096\n",
      "Epoch 68/200, Iteration 109/250, Loss: 0.0340\n",
      "Epoch 68/200, Iteration 110/250, Loss: 0.0106\n",
      "Epoch 68/200, Iteration 111/250, Loss: 0.0134\n",
      "Epoch 68/200, Iteration 112/250, Loss: 0.0187\n",
      "Epoch 68/200, Iteration 113/250, Loss: 0.0160\n",
      "Epoch 68/200, Iteration 114/250, Loss: 0.0117\n",
      "Epoch 68/200, Iteration 115/250, Loss: 0.0195\n",
      "Epoch 68/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 68/200, Iteration 117/250, Loss: 0.0294\n",
      "Epoch 68/200, Iteration 118/250, Loss: 0.0204\n",
      "Epoch 68/200, Iteration 119/250, Loss: 0.0152\n",
      "Epoch 68/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 68/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 68/200, Iteration 122/250, Loss: 0.0163\n",
      "Epoch 68/200, Iteration 123/250, Loss: 0.0349\n",
      "Epoch 68/200, Iteration 124/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 125/250, Loss: 0.0170\n",
      "Epoch 68/200, Iteration 126/250, Loss: 0.0217\n",
      "Epoch 68/200, Iteration 127/250, Loss: 0.0220\n",
      "Epoch 68/200, Iteration 128/250, Loss: 0.0367\n",
      "Epoch 68/200, Iteration 129/250, Loss: 0.0079\n",
      "Epoch 68/200, Iteration 130/250, Loss: 0.0248\n",
      "Epoch 68/200, Iteration 131/250, Loss: 0.0268\n",
      "Epoch 68/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 68/200, Iteration 133/250, Loss: 0.0385\n",
      "Epoch 68/200, Iteration 134/250, Loss: 0.0186\n",
      "Epoch 68/200, Iteration 135/250, Loss: 0.0130\n",
      "Epoch 68/200, Iteration 136/250, Loss: 0.0107\n",
      "Epoch 68/200, Iteration 137/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 138/250, Loss: 0.0285\n",
      "Epoch 68/200, Iteration 139/250, Loss: 0.0227\n",
      "Epoch 68/200, Iteration 140/250, Loss: 0.0127\n",
      "Epoch 68/200, Iteration 141/250, Loss: 0.0079\n",
      "Epoch 68/200, Iteration 142/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 143/250, Loss: 0.0207\n",
      "Epoch 68/200, Iteration 144/250, Loss: 0.0099\n",
      "Epoch 68/200, Iteration 145/250, Loss: 0.0131\n",
      "Epoch 68/200, Iteration 146/250, Loss: 0.0290\n",
      "Epoch 68/200, Iteration 147/250, Loss: 0.0118\n",
      "Epoch 68/200, Iteration 148/250, Loss: 0.0122\n",
      "Epoch 68/200, Iteration 149/250, Loss: 0.0189\n",
      "Epoch 68/200, Iteration 150/250, Loss: 0.0124\n",
      "Epoch 68/200, Iteration 151/250, Loss: 0.0168\n",
      "Epoch 68/200, Iteration 152/250, Loss: 0.0098\n",
      "Epoch 68/200, Iteration 153/250, Loss: 0.0102\n",
      "Epoch 68/200, Iteration 154/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 155/250, Loss: 0.0109\n",
      "Epoch 68/200, Iteration 156/250, Loss: 0.0114\n",
      "Epoch 68/200, Iteration 157/250, Loss: 0.0142\n",
      "Epoch 68/200, Iteration 158/250, Loss: 0.0305\n",
      "Epoch 68/200, Iteration 159/250, Loss: 0.0183\n",
      "Epoch 68/200, Iteration 160/250, Loss: 0.0177\n",
      "Epoch 68/200, Iteration 161/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 68/200, Iteration 163/250, Loss: 0.0126\n",
      "Epoch 68/200, Iteration 164/250, Loss: 0.0265\n",
      "Epoch 68/200, Iteration 165/250, Loss: 0.0165\n",
      "Epoch 68/200, Iteration 166/250, Loss: 0.0292\n",
      "Epoch 68/200, Iteration 167/250, Loss: 0.0099\n",
      "Epoch 68/200, Iteration 168/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 169/250, Loss: 0.0092\n",
      "Epoch 68/200, Iteration 170/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 171/250, Loss: 0.0152\n",
      "Epoch 68/200, Iteration 172/250, Loss: 0.0214\n",
      "Epoch 68/200, Iteration 173/250, Loss: 0.0267\n",
      "Epoch 68/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 68/200, Iteration 175/250, Loss: 0.0098\n",
      "Epoch 68/200, Iteration 176/250, Loss: 0.0091\n",
      "Epoch 68/200, Iteration 177/250, Loss: 0.0101\n",
      "Epoch 68/200, Iteration 178/250, Loss: 0.0195\n",
      "Epoch 68/200, Iteration 179/250, Loss: 0.0114\n",
      "Epoch 68/200, Iteration 180/250, Loss: 0.0210\n",
      "Epoch 68/200, Iteration 181/250, Loss: 0.0151\n",
      "Epoch 68/200, Iteration 182/250, Loss: 0.0110\n",
      "Epoch 68/200, Iteration 183/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 184/250, Loss: 0.0328\n",
      "Epoch 68/200, Iteration 185/250, Loss: 0.0107\n",
      "Epoch 68/200, Iteration 186/250, Loss: 0.0198\n",
      "Epoch 68/200, Iteration 187/250, Loss: 0.0183\n",
      "Epoch 68/200, Iteration 188/250, Loss: 0.0175\n",
      "Epoch 68/200, Iteration 189/250, Loss: 0.0280\n",
      "Epoch 68/200, Iteration 190/250, Loss: 0.0200\n",
      "Epoch 68/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 68/200, Iteration 192/250, Loss: 0.0153\n",
      "Epoch 68/200, Iteration 193/250, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200, Iteration 194/250, Loss: 0.0188\n",
      "Epoch 68/200, Iteration 195/250, Loss: 0.0092\n",
      "Epoch 68/200, Iteration 196/250, Loss: 0.0223\n",
      "Epoch 68/200, Iteration 197/250, Loss: 0.0158\n",
      "Epoch 68/200, Iteration 198/250, Loss: 0.0085\n",
      "Epoch 68/200, Iteration 199/250, Loss: 0.0280\n",
      "Epoch 68/200, Iteration 200/250, Loss: 0.0170\n",
      "Epoch 68/200, Iteration 201/250, Loss: 0.0101\n",
      "Epoch 68/200, Iteration 202/250, Loss: 0.0145\n",
      "Epoch 68/200, Iteration 203/250, Loss: 0.0101\n",
      "Epoch 68/200, Iteration 204/250, Loss: 0.0231\n",
      "Epoch 68/200, Iteration 205/250, Loss: 0.0095\n",
      "Epoch 68/200, Iteration 206/250, Loss: 0.0156\n",
      "Epoch 68/200, Iteration 207/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 208/250, Loss: 0.0094\n",
      "Epoch 68/200, Iteration 209/250, Loss: 0.0190\n",
      "Epoch 68/200, Iteration 210/250, Loss: 0.0173\n",
      "Epoch 68/200, Iteration 211/250, Loss: 0.0121\n",
      "Epoch 68/200, Iteration 212/250, Loss: 0.0143\n",
      "Epoch 68/200, Iteration 213/250, Loss: 0.0106\n",
      "Epoch 68/200, Iteration 214/250, Loss: 0.0124\n",
      "Epoch 68/200, Iteration 215/250, Loss: 0.0090\n",
      "Epoch 68/200, Iteration 216/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 217/250, Loss: 0.0083\n",
      "Epoch 68/200, Iteration 218/250, Loss: 0.0232\n",
      "Epoch 68/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 68/200, Iteration 220/250, Loss: 0.0302\n",
      "Epoch 68/200, Iteration 221/250, Loss: 0.0265\n",
      "Epoch 68/200, Iteration 222/250, Loss: 0.0076\n",
      "Epoch 68/200, Iteration 223/250, Loss: 0.0212\n",
      "Epoch 68/200, Iteration 224/250, Loss: 0.0120\n",
      "Epoch 68/200, Iteration 225/250, Loss: 0.0089\n",
      "Epoch 68/200, Iteration 226/250, Loss: 0.0091\n",
      "Epoch 68/200, Iteration 227/250, Loss: 0.0300\n",
      "Epoch 68/200, Iteration 228/250, Loss: 0.0140\n",
      "Epoch 68/200, Iteration 229/250, Loss: 0.0076\n",
      "Epoch 68/200, Iteration 230/250, Loss: 0.0075\n",
      "Epoch 68/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 68/200, Iteration 232/250, Loss: 0.0198\n",
      "Epoch 68/200, Iteration 233/250, Loss: 0.0256\n",
      "Epoch 68/200, Iteration 234/250, Loss: 0.0160\n",
      "Epoch 68/200, Iteration 235/250, Loss: 0.0345\n",
      "Epoch 68/200, Iteration 236/250, Loss: 0.0138\n",
      "Epoch 68/200, Iteration 237/250, Loss: 0.0233\n",
      "Epoch 68/200, Iteration 238/250, Loss: 0.0199\n",
      "Epoch 68/200, Iteration 239/250, Loss: 0.0137\n",
      "Epoch 68/200, Iteration 240/250, Loss: 0.0201\n",
      "Epoch 68/200, Iteration 241/250, Loss: 0.0133\n",
      "Epoch 68/200, Iteration 242/250, Loss: 0.0114\n",
      "Epoch 68/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 68/200, Iteration 244/250, Loss: 0.0104\n",
      "Epoch 68/200, Iteration 245/250, Loss: 0.0097\n",
      "Epoch 68/200, Iteration 246/250, Loss: 0.0221\n",
      "Epoch 68/200, Iteration 247/250, Loss: 0.0252\n",
      "Epoch 68/200, Iteration 248/250, Loss: 0.0146\n",
      "Epoch 68/200, Iteration 249/250, Loss: 0.0145\n",
      "Epoch 68/200, Iteration 250/250, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 87.45%, Avg loss: 0.007206, MRE: 0.489293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.007661, MRE: 0.520728 \n",
      "\n",
      "Epoch 69/200, Iteration 1/250, Loss: 0.0183\n",
      "Epoch 69/200, Iteration 2/250, Loss: 0.0076\n",
      "Epoch 69/200, Iteration 3/250, Loss: 0.0080\n",
      "Epoch 69/200, Iteration 4/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 5/250, Loss: 0.0085\n",
      "Epoch 69/200, Iteration 6/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 7/250, Loss: 0.0105\n",
      "Epoch 69/200, Iteration 8/250, Loss: 0.0136\n",
      "Epoch 69/200, Iteration 9/250, Loss: 0.0068\n",
      "Epoch 69/200, Iteration 10/250, Loss: 0.0141\n",
      "Epoch 69/200, Iteration 11/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 12/250, Loss: 0.0372\n",
      "Epoch 69/200, Iteration 13/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 14/250, Loss: 0.0165\n",
      "Epoch 69/200, Iteration 15/250, Loss: 0.0087\n",
      "Epoch 69/200, Iteration 16/250, Loss: 0.0155\n",
      "Epoch 69/200, Iteration 17/250, Loss: 0.0344\n",
      "Epoch 69/200, Iteration 18/250, Loss: 0.0225\n",
      "Epoch 69/200, Iteration 19/250, Loss: 0.0374\n",
      "Epoch 69/200, Iteration 20/250, Loss: 0.0080\n",
      "Epoch 69/200, Iteration 21/250, Loss: 0.0104\n",
      "Epoch 69/200, Iteration 22/250, Loss: 0.0093\n",
      "Epoch 69/200, Iteration 23/250, Loss: 0.0086\n",
      "Epoch 69/200, Iteration 24/250, Loss: 0.0150\n",
      "Epoch 69/200, Iteration 25/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 26/250, Loss: 0.0078\n",
      "Epoch 69/200, Iteration 27/250, Loss: 0.0141\n",
      "Epoch 69/200, Iteration 28/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 69/200, Iteration 30/250, Loss: 0.0073\n",
      "Epoch 69/200, Iteration 31/250, Loss: 0.0297\n",
      "Epoch 69/200, Iteration 32/250, Loss: 0.0178\n",
      "Epoch 69/200, Iteration 33/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 34/250, Loss: 0.0147\n",
      "Epoch 69/200, Iteration 35/250, Loss: 0.0296\n",
      "Epoch 69/200, Iteration 36/250, Loss: 0.0090\n",
      "Epoch 69/200, Iteration 37/250, Loss: 0.0113\n",
      "Epoch 69/200, Iteration 38/250, Loss: 0.0117\n",
      "Epoch 69/200, Iteration 39/250, Loss: 0.0211\n",
      "Epoch 69/200, Iteration 40/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 41/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 42/250, Loss: 0.0307\n",
      "Epoch 69/200, Iteration 43/250, Loss: 0.0265\n",
      "Epoch 69/200, Iteration 44/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 45/250, Loss: 0.0164\n",
      "Epoch 69/200, Iteration 46/250, Loss: 0.0242\n",
      "Epoch 69/200, Iteration 47/250, Loss: 0.0070\n",
      "Epoch 69/200, Iteration 48/250, Loss: 0.0104\n",
      "Epoch 69/200, Iteration 49/250, Loss: 0.0084\n",
      "Epoch 69/200, Iteration 50/250, Loss: 0.0198\n",
      "Epoch 69/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 52/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 53/250, Loss: 0.0098\n",
      "Epoch 69/200, Iteration 54/250, Loss: 0.0259\n",
      "Epoch 69/200, Iteration 55/250, Loss: 0.0269\n",
      "Epoch 69/200, Iteration 56/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 69/200, Iteration 58/250, Loss: 0.0143\n",
      "Epoch 69/200, Iteration 59/250, Loss: 0.0260\n",
      "Epoch 69/200, Iteration 60/250, Loss: 0.0126\n",
      "Epoch 69/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 62/250, Loss: 0.0132\n",
      "Epoch 69/200, Iteration 63/250, Loss: 0.0116\n",
      "Epoch 69/200, Iteration 64/250, Loss: 0.0121\n",
      "Epoch 69/200, Iteration 65/250, Loss: 0.0153\n",
      "Epoch 69/200, Iteration 66/250, Loss: 0.0106\n",
      "Epoch 69/200, Iteration 67/250, Loss: 0.0079\n",
      "Epoch 69/200, Iteration 68/250, Loss: 0.0127\n",
      "Epoch 69/200, Iteration 69/250, Loss: 0.0330\n",
      "Epoch 69/200, Iteration 70/250, Loss: 0.0082\n",
      "Epoch 69/200, Iteration 71/250, Loss: 0.0220\n",
      "Epoch 69/200, Iteration 72/250, Loss: 0.0112\n",
      "Epoch 69/200, Iteration 73/250, Loss: 0.0099\n",
      "Epoch 69/200, Iteration 74/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 75/250, Loss: 0.0222\n",
      "Epoch 69/200, Iteration 76/250, Loss: 0.0169\n",
      "Epoch 69/200, Iteration 77/250, Loss: 0.0127\n",
      "Epoch 69/200, Iteration 78/250, Loss: 0.0207\n",
      "Epoch 69/200, Iteration 79/250, Loss: 0.0078\n",
      "Epoch 69/200, Iteration 80/250, Loss: 0.0315\n",
      "Epoch 69/200, Iteration 81/250, Loss: 0.0194\n",
      "Epoch 69/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 83/250, Loss: 0.0309\n",
      "Epoch 69/200, Iteration 84/250, Loss: 0.0341\n",
      "Epoch 69/200, Iteration 85/250, Loss: 0.0228\n",
      "Epoch 69/200, Iteration 86/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 87/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 88/250, Loss: 0.0341\n",
      "Epoch 69/200, Iteration 89/250, Loss: 0.0093\n",
      "Epoch 69/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 69/200, Iteration 91/250, Loss: 0.0230\n",
      "Epoch 69/200, Iteration 92/250, Loss: 0.0185\n",
      "Epoch 69/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 69/200, Iteration 94/250, Loss: 0.0269\n",
      "Epoch 69/200, Iteration 95/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 96/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 97/250, Loss: 0.0139\n",
      "Epoch 69/200, Iteration 98/250, Loss: 0.0318\n",
      "Epoch 69/200, Iteration 99/250, Loss: 0.0142\n",
      "Epoch 69/200, Iteration 100/250, Loss: 0.0160\n",
      "Epoch 69/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 69/200, Iteration 102/250, Loss: 0.0118\n",
      "Epoch 69/200, Iteration 103/250, Loss: 0.0243\n",
      "Epoch 69/200, Iteration 104/250, Loss: 0.0245\n",
      "Epoch 69/200, Iteration 105/250, Loss: 0.0300\n",
      "Epoch 69/200, Iteration 106/250, Loss: 0.0074\n",
      "Epoch 69/200, Iteration 107/250, Loss: 0.0185\n",
      "Epoch 69/200, Iteration 108/250, Loss: 0.0213\n",
      "Epoch 69/200, Iteration 109/250, Loss: 0.0239\n",
      "Epoch 69/200, Iteration 110/250, Loss: 0.0104\n",
      "Epoch 69/200, Iteration 111/250, Loss: 0.0098\n",
      "Epoch 69/200, Iteration 112/250, Loss: 0.0118\n",
      "Epoch 69/200, Iteration 113/250, Loss: 0.0192\n",
      "Epoch 69/200, Iteration 114/250, Loss: 0.0266\n",
      "Epoch 69/200, Iteration 115/250, Loss: 0.0143\n",
      "Epoch 69/200, Iteration 116/250, Loss: 0.0236\n",
      "Epoch 69/200, Iteration 117/250, Loss: 0.0121\n",
      "Epoch 69/200, Iteration 118/250, Loss: 0.0181\n",
      "Epoch 69/200, Iteration 119/250, Loss: 0.0079\n",
      "Epoch 69/200, Iteration 120/250, Loss: 0.0226\n",
      "Epoch 69/200, Iteration 121/250, Loss: 0.0275\n",
      "Epoch 69/200, Iteration 122/250, Loss: 0.0123\n",
      "Epoch 69/200, Iteration 123/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 124/250, Loss: 0.0274\n",
      "Epoch 69/200, Iteration 125/250, Loss: 0.0184\n",
      "Epoch 69/200, Iteration 126/250, Loss: 0.0374\n",
      "Epoch 69/200, Iteration 127/250, Loss: 0.0159\n",
      "Epoch 69/200, Iteration 128/250, Loss: 0.0150\n",
      "Epoch 69/200, Iteration 129/250, Loss: 0.0193\n",
      "Epoch 69/200, Iteration 130/250, Loss: 0.0170\n",
      "Epoch 69/200, Iteration 131/250, Loss: 0.0202\n",
      "Epoch 69/200, Iteration 132/250, Loss: 0.0190\n",
      "Epoch 69/200, Iteration 133/250, Loss: 0.0060\n",
      "Epoch 69/200, Iteration 134/250, Loss: 0.0077\n",
      "Epoch 69/200, Iteration 135/250, Loss: 0.0077\n",
      "Epoch 69/200, Iteration 136/250, Loss: 0.0093\n",
      "Epoch 69/200, Iteration 137/250, Loss: 0.0156\n",
      "Epoch 69/200, Iteration 138/250, Loss: 0.0482\n",
      "Epoch 69/200, Iteration 139/250, Loss: 0.0296\n",
      "Epoch 69/200, Iteration 140/250, Loss: 0.0071\n",
      "Epoch 69/200, Iteration 141/250, Loss: 0.0071\n",
      "Epoch 69/200, Iteration 142/250, Loss: 0.0101\n",
      "Epoch 69/200, Iteration 143/250, Loss: 0.0199\n",
      "Epoch 69/200, Iteration 144/250, Loss: 0.0133\n",
      "Epoch 69/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 69/200, Iteration 146/250, Loss: 0.0082\n",
      "Epoch 69/200, Iteration 147/250, Loss: 0.0148\n",
      "Epoch 69/200, Iteration 148/250, Loss: 0.0229\n",
      "Epoch 69/200, Iteration 149/250, Loss: 0.0095\n",
      "Epoch 69/200, Iteration 150/250, Loss: 0.0287\n",
      "Epoch 69/200, Iteration 151/250, Loss: 0.0112\n",
      "Epoch 69/200, Iteration 152/250, Loss: 0.0208\n",
      "Epoch 69/200, Iteration 153/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 154/250, Loss: 0.0126\n",
      "Epoch 69/200, Iteration 155/250, Loss: 0.0231\n",
      "Epoch 69/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 69/200, Iteration 157/250, Loss: 0.0288\n",
      "Epoch 69/200, Iteration 158/250, Loss: 0.0135\n",
      "Epoch 69/200, Iteration 159/250, Loss: 0.0061\n",
      "Epoch 69/200, Iteration 160/250, Loss: 0.0109\n",
      "Epoch 69/200, Iteration 161/250, Loss: 0.0272\n",
      "Epoch 69/200, Iteration 162/250, Loss: 0.0133\n",
      "Epoch 69/200, Iteration 163/250, Loss: 0.0144\n",
      "Epoch 69/200, Iteration 164/250, Loss: 0.0121\n",
      "Epoch 69/200, Iteration 165/250, Loss: 0.0163\n",
      "Epoch 69/200, Iteration 166/250, Loss: 0.0220\n",
      "Epoch 69/200, Iteration 167/250, Loss: 0.0107\n",
      "Epoch 69/200, Iteration 168/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 169/250, Loss: 0.0229\n",
      "Epoch 69/200, Iteration 170/250, Loss: 0.0211\n",
      "Epoch 69/200, Iteration 171/250, Loss: 0.0359\n",
      "Epoch 69/200, Iteration 172/250, Loss: 0.0214\n",
      "Epoch 69/200, Iteration 173/250, Loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Iteration 174/250, Loss: 0.0081\n",
      "Epoch 69/200, Iteration 175/250, Loss: 0.0241\n",
      "Epoch 69/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 69/200, Iteration 177/250, Loss: 0.0306\n",
      "Epoch 69/200, Iteration 178/250, Loss: 0.0077\n",
      "Epoch 69/200, Iteration 179/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 180/250, Loss: 0.0063\n",
      "Epoch 69/200, Iteration 181/250, Loss: 0.0056\n",
      "Epoch 69/200, Iteration 182/250, Loss: 0.0136\n",
      "Epoch 69/200, Iteration 183/250, Loss: 0.0245\n",
      "Epoch 69/200, Iteration 184/250, Loss: 0.0226\n",
      "Epoch 69/200, Iteration 185/250, Loss: 0.0153\n",
      "Epoch 69/200, Iteration 186/250, Loss: 0.0166\n",
      "Epoch 69/200, Iteration 187/250, Loss: 0.0132\n",
      "Epoch 69/200, Iteration 188/250, Loss: 0.0208\n",
      "Epoch 69/200, Iteration 189/250, Loss: 0.0178\n",
      "Epoch 69/200, Iteration 190/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 69/200, Iteration 192/250, Loss: 0.0192\n",
      "Epoch 69/200, Iteration 193/250, Loss: 0.0126\n",
      "Epoch 69/200, Iteration 194/250, Loss: 0.0115\n",
      "Epoch 69/200, Iteration 195/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 196/250, Loss: 0.0329\n",
      "Epoch 69/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 69/200, Iteration 198/250, Loss: 0.0224\n",
      "Epoch 69/200, Iteration 199/250, Loss: 0.0128\n",
      "Epoch 69/200, Iteration 200/250, Loss: 0.0070\n",
      "Epoch 69/200, Iteration 201/250, Loss: 0.0208\n",
      "Epoch 69/200, Iteration 202/250, Loss: 0.0122\n",
      "Epoch 69/200, Iteration 203/250, Loss: 0.0100\n",
      "Epoch 69/200, Iteration 204/250, Loss: 0.0125\n",
      "Epoch 69/200, Iteration 205/250, Loss: 0.0256\n",
      "Epoch 69/200, Iteration 206/250, Loss: 0.0134\n",
      "Epoch 69/200, Iteration 207/250, Loss: 0.0283\n",
      "Epoch 69/200, Iteration 208/250, Loss: 0.0109\n",
      "Epoch 69/200, Iteration 209/250, Loss: 0.0214\n",
      "Epoch 69/200, Iteration 210/250, Loss: 0.0173\n",
      "Epoch 69/200, Iteration 211/250, Loss: 0.0088\n",
      "Epoch 69/200, Iteration 212/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 213/250, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 214/250, Loss: 0.0186\n",
      "Epoch 69/200, Iteration 215/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 216/250, Loss: 0.0247\n",
      "Epoch 69/200, Iteration 217/250, Loss: 0.0380\n",
      "Epoch 69/200, Iteration 218/250, Loss: 0.0163\n",
      "Epoch 69/200, Iteration 219/250, Loss: 0.0214\n",
      "Epoch 69/200, Iteration 220/250, Loss: 0.0152\n",
      "Epoch 69/200, Iteration 221/250, Loss: 0.0147\n",
      "Epoch 69/200, Iteration 222/250, Loss: 0.0091\n",
      "Epoch 69/200, Iteration 223/250, Loss: 0.0097\n",
      "Epoch 69/200, Iteration 224/250, Loss: 0.0096\n",
      "Epoch 69/200, Iteration 225/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 226/250, Loss: 0.0103\n",
      "Epoch 69/200, Iteration 227/250, Loss: 0.0145\n",
      "Epoch 69/200, Iteration 228/250, Loss: 0.0187\n",
      "Epoch 69/200, Iteration 229/250, Loss: 0.0266\n",
      "Epoch 69/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 69/200, Iteration 231/250, Loss: 0.0115\n",
      "Epoch 69/200, Iteration 232/250, Loss: 0.0118\n",
      "Epoch 69/200, Iteration 233/250, Loss: 0.0144\n",
      "Epoch 69/200, Iteration 234/250, Loss: 0.0169\n",
      "Epoch 69/200, Iteration 235/250, Loss: 0.0265\n",
      "Epoch 69/200, Iteration 236/250, Loss: 0.0129\n",
      "Epoch 69/200, Iteration 237/250, Loss: 0.0119\n",
      "Epoch 69/200, Iteration 238/250, Loss: 0.0133\n",
      "Epoch 69/200, Iteration 239/250, Loss: 0.0106\n",
      "Epoch 69/200, Iteration 240/250, Loss: 0.0157\n",
      "Epoch 69/200, Iteration 241/250, Loss: 0.0207\n",
      "Epoch 69/200, Iteration 242/250, Loss: 0.0269\n",
      "Epoch 69/200, Iteration 243/250, Loss: 0.0243\n",
      "Epoch 69/200, Iteration 244/250, Loss: 0.0114\n",
      "Epoch 69/200, Iteration 245/250, Loss: 0.0240\n",
      "Epoch 69/200, Iteration 246/250, Loss: 0.0162\n",
      "Epoch 69/200, Iteration 247/250, Loss: 0.0291\n",
      "Epoch 69/200, Iteration 248/250, Loss: 0.0103\n",
      "Epoch 69/200, Iteration 249/250, Loss: 0.0110\n",
      "Epoch 69/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 90.64%, Avg loss: 0.007046, MRE: 0.486819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.75%, Avg loss: 0.007652, MRE: 0.657842 \n",
      "\n",
      "Epoch 70/200, Iteration 1/250, Loss: 0.0196\n",
      "Epoch 70/200, Iteration 2/250, Loss: 0.0118\n",
      "Epoch 70/200, Iteration 3/250, Loss: 0.0130\n",
      "Epoch 70/200, Iteration 4/250, Loss: 0.0075\n",
      "Epoch 70/200, Iteration 5/250, Loss: 0.0201\n",
      "Epoch 70/200, Iteration 6/250, Loss: 0.0113\n",
      "Epoch 70/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 70/200, Iteration 8/250, Loss: 0.0113\n",
      "Epoch 70/200, Iteration 9/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 10/250, Loss: 0.0087\n",
      "Epoch 70/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 12/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 13/250, Loss: 0.0205\n",
      "Epoch 70/200, Iteration 14/250, Loss: 0.0178\n",
      "Epoch 70/200, Iteration 15/250, Loss: 0.0119\n",
      "Epoch 70/200, Iteration 16/250, Loss: 0.0165\n",
      "Epoch 70/200, Iteration 17/250, Loss: 0.0089\n",
      "Epoch 70/200, Iteration 18/250, Loss: 0.0384\n",
      "Epoch 70/200, Iteration 19/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 20/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 21/250, Loss: 0.0129\n",
      "Epoch 70/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 70/200, Iteration 23/250, Loss: 0.0342\n",
      "Epoch 70/200, Iteration 24/250, Loss: 0.0073\n",
      "Epoch 70/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 70/200, Iteration 26/250, Loss: 0.0219\n",
      "Epoch 70/200, Iteration 27/250, Loss: 0.0137\n",
      "Epoch 70/200, Iteration 28/250, Loss: 0.0083\n",
      "Epoch 70/200, Iteration 29/250, Loss: 0.0137\n",
      "Epoch 70/200, Iteration 30/250, Loss: 0.0311\n",
      "Epoch 70/200, Iteration 31/250, Loss: 0.0083\n",
      "Epoch 70/200, Iteration 32/250, Loss: 0.0140\n",
      "Epoch 70/200, Iteration 33/250, Loss: 0.0245\n",
      "Epoch 70/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 70/200, Iteration 35/250, Loss: 0.0173\n",
      "Epoch 70/200, Iteration 36/250, Loss: 0.0183\n",
      "Epoch 70/200, Iteration 37/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 38/250, Loss: 0.0087\n",
      "Epoch 70/200, Iteration 39/250, Loss: 0.0158\n",
      "Epoch 70/200, Iteration 40/250, Loss: 0.0290\n",
      "Epoch 70/200, Iteration 41/250, Loss: 0.0156\n",
      "Epoch 70/200, Iteration 42/250, Loss: 0.0098\n",
      "Epoch 70/200, Iteration 43/250, Loss: 0.0090\n",
      "Epoch 70/200, Iteration 44/250, Loss: 0.0105\n",
      "Epoch 70/200, Iteration 45/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 46/250, Loss: 0.0141\n",
      "Epoch 70/200, Iteration 47/250, Loss: 0.0121\n",
      "Epoch 70/200, Iteration 48/250, Loss: 0.0195\n",
      "Epoch 70/200, Iteration 49/250, Loss: 0.0124\n",
      "Epoch 70/200, Iteration 50/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 51/250, Loss: 0.0084\n",
      "Epoch 70/200, Iteration 52/250, Loss: 0.0201\n",
      "Epoch 70/200, Iteration 53/250, Loss: 0.0111\n",
      "Epoch 70/200, Iteration 54/250, Loss: 0.0217\n",
      "Epoch 70/200, Iteration 55/250, Loss: 0.0142\n",
      "Epoch 70/200, Iteration 56/250, Loss: 0.0147\n",
      "Epoch 70/200, Iteration 57/250, Loss: 0.0084\n",
      "Epoch 70/200, Iteration 58/250, Loss: 0.0154\n",
      "Epoch 70/200, Iteration 59/250, Loss: 0.0200\n",
      "Epoch 70/200, Iteration 60/250, Loss: 0.0140\n",
      "Epoch 70/200, Iteration 61/250, Loss: 0.0323\n",
      "Epoch 70/200, Iteration 62/250, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 63/250, Loss: 0.0246\n",
      "Epoch 70/200, Iteration 64/250, Loss: 0.0118\n",
      "Epoch 70/200, Iteration 65/250, Loss: 0.0094\n",
      "Epoch 70/200, Iteration 66/250, Loss: 0.0169\n",
      "Epoch 70/200, Iteration 67/250, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 68/250, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 69/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 70/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 71/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 72/250, Loss: 0.0097\n",
      "Epoch 70/200, Iteration 73/250, Loss: 0.0224\n",
      "Epoch 70/200, Iteration 74/250, Loss: 0.0092\n",
      "Epoch 70/200, Iteration 75/250, Loss: 0.0134\n",
      "Epoch 70/200, Iteration 76/250, Loss: 0.0097\n",
      "Epoch 70/200, Iteration 77/250, Loss: 0.0279\n",
      "Epoch 70/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 70/200, Iteration 79/250, Loss: 0.0118\n",
      "Epoch 70/200, Iteration 80/250, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 81/250, Loss: 0.0078\n",
      "Epoch 70/200, Iteration 82/250, Loss: 0.0154\n",
      "Epoch 70/200, Iteration 83/250, Loss: 0.0149\n",
      "Epoch 70/200, Iteration 84/250, Loss: 0.0174\n",
      "Epoch 70/200, Iteration 85/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 86/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 87/250, Loss: 0.0091\n",
      "Epoch 70/200, Iteration 88/250, Loss: 0.0181\n",
      "Epoch 70/200, Iteration 89/250, Loss: 0.0388\n",
      "Epoch 70/200, Iteration 90/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 91/250, Loss: 0.0266\n",
      "Epoch 70/200, Iteration 92/250, Loss: 0.0155\n",
      "Epoch 70/200, Iteration 93/250, Loss: 0.0131\n",
      "Epoch 70/200, Iteration 94/250, Loss: 0.0175\n",
      "Epoch 70/200, Iteration 95/250, Loss: 0.0064\n",
      "Epoch 70/200, Iteration 96/250, Loss: 0.0121\n",
      "Epoch 70/200, Iteration 97/250, Loss: 0.0092\n",
      "Epoch 70/200, Iteration 98/250, Loss: 0.0114\n",
      "Epoch 70/200, Iteration 99/250, Loss: 0.0228\n",
      "Epoch 70/200, Iteration 100/250, Loss: 0.0089\n",
      "Epoch 70/200, Iteration 101/250, Loss: 0.0085\n",
      "Epoch 70/200, Iteration 102/250, Loss: 0.0249\n",
      "Epoch 70/200, Iteration 103/250, Loss: 0.0084\n",
      "Epoch 70/200, Iteration 104/250, Loss: 0.0074\n",
      "Epoch 70/200, Iteration 105/250, Loss: 0.0317\n",
      "Epoch 70/200, Iteration 106/250, Loss: 0.0300\n",
      "Epoch 70/200, Iteration 107/250, Loss: 0.0170\n",
      "Epoch 70/200, Iteration 108/250, Loss: 0.0122\n",
      "Epoch 70/200, Iteration 109/250, Loss: 0.0133\n",
      "Epoch 70/200, Iteration 110/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 111/250, Loss: 0.0141\n",
      "Epoch 70/200, Iteration 112/250, Loss: 0.0109\n",
      "Epoch 70/200, Iteration 113/250, Loss: 0.0227\n",
      "Epoch 70/200, Iteration 114/250, Loss: 0.0097\n",
      "Epoch 70/200, Iteration 115/250, Loss: 0.0097\n",
      "Epoch 70/200, Iteration 116/250, Loss: 0.0074\n",
      "Epoch 70/200, Iteration 117/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 118/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 119/250, Loss: 0.0100\n",
      "Epoch 70/200, Iteration 120/250, Loss: 0.0104\n",
      "Epoch 70/200, Iteration 121/250, Loss: 0.0141\n",
      "Epoch 70/200, Iteration 122/250, Loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200, Iteration 123/250, Loss: 0.0087\n",
      "Epoch 70/200, Iteration 124/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 125/250, Loss: 0.0234\n",
      "Epoch 70/200, Iteration 126/250, Loss: 0.0163\n",
      "Epoch 70/200, Iteration 127/250, Loss: 0.0245\n",
      "Epoch 70/200, Iteration 128/250, Loss: 0.0187\n",
      "Epoch 70/200, Iteration 129/250, Loss: 0.0073\n",
      "Epoch 70/200, Iteration 130/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 131/250, Loss: 0.0150\n",
      "Epoch 70/200, Iteration 132/250, Loss: 0.0289\n",
      "Epoch 70/200, Iteration 133/250, Loss: 0.0110\n",
      "Epoch 70/200, Iteration 134/250, Loss: 0.0149\n",
      "Epoch 70/200, Iteration 135/250, Loss: 0.0078\n",
      "Epoch 70/200, Iteration 136/250, Loss: 0.0157\n",
      "Epoch 70/200, Iteration 137/250, Loss: 0.0249\n",
      "Epoch 70/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 139/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 140/250, Loss: 0.0214\n",
      "Epoch 70/200, Iteration 141/250, Loss: 0.0124\n",
      "Epoch 70/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 143/250, Loss: 0.0096\n",
      "Epoch 70/200, Iteration 144/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 145/250, Loss: 0.0166\n",
      "Epoch 70/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 70/200, Iteration 147/250, Loss: 0.0258\n",
      "Epoch 70/200, Iteration 148/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 149/250, Loss: 0.0152\n",
      "Epoch 70/200, Iteration 150/250, Loss: 0.0200\n",
      "Epoch 70/200, Iteration 151/250, Loss: 0.0106\n",
      "Epoch 70/200, Iteration 152/250, Loss: 0.0365\n",
      "Epoch 70/200, Iteration 153/250, Loss: 0.0103\n",
      "Epoch 70/200, Iteration 154/250, Loss: 0.0089\n",
      "Epoch 70/200, Iteration 155/250, Loss: 0.0174\n",
      "Epoch 70/200, Iteration 156/250, Loss: 0.0185\n",
      "Epoch 70/200, Iteration 157/250, Loss: 0.0079\n",
      "Epoch 70/200, Iteration 158/250, Loss: 0.0283\n",
      "Epoch 70/200, Iteration 159/250, Loss: 0.0144\n",
      "Epoch 70/200, Iteration 160/250, Loss: 0.0183\n",
      "Epoch 70/200, Iteration 161/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 162/250, Loss: 0.0107\n",
      "Epoch 70/200, Iteration 163/250, Loss: 0.0099\n",
      "Epoch 70/200, Iteration 164/250, Loss: 0.0080\n",
      "Epoch 70/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 70/200, Iteration 166/250, Loss: 0.0120\n",
      "Epoch 70/200, Iteration 167/250, Loss: 0.0075\n",
      "Epoch 70/200, Iteration 168/250, Loss: 0.0261\n",
      "Epoch 70/200, Iteration 169/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 170/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 171/250, Loss: 0.0269\n",
      "Epoch 70/200, Iteration 172/250, Loss: 0.0078\n",
      "Epoch 70/200, Iteration 173/250, Loss: 0.0112\n",
      "Epoch 70/200, Iteration 174/250, Loss: 0.0256\n",
      "Epoch 70/200, Iteration 175/250, Loss: 0.0302\n",
      "Epoch 70/200, Iteration 176/250, Loss: 0.0120\n",
      "Epoch 70/200, Iteration 177/250, Loss: 0.0130\n",
      "Epoch 70/200, Iteration 178/250, Loss: 0.0199\n",
      "Epoch 70/200, Iteration 179/250, Loss: 0.0212\n",
      "Epoch 70/200, Iteration 180/250, Loss: 0.0391\n",
      "Epoch 70/200, Iteration 181/250, Loss: 0.0151\n",
      "Epoch 70/200, Iteration 182/250, Loss: 0.0160\n",
      "Epoch 70/200, Iteration 183/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 184/250, Loss: 0.0145\n",
      "Epoch 70/200, Iteration 185/250, Loss: 0.0296\n",
      "Epoch 70/200, Iteration 186/250, Loss: 0.0213\n",
      "Epoch 70/200, Iteration 187/250, Loss: 0.0128\n",
      "Epoch 70/200, Iteration 188/250, Loss: 0.0224\n",
      "Epoch 70/200, Iteration 189/250, Loss: 0.0115\n",
      "Epoch 70/200, Iteration 190/250, Loss: 0.0104\n",
      "Epoch 70/200, Iteration 191/250, Loss: 0.0183\n",
      "Epoch 70/200, Iteration 192/250, Loss: 0.0127\n",
      "Epoch 70/200, Iteration 193/250, Loss: 0.0247\n",
      "Epoch 70/200, Iteration 194/250, Loss: 0.0080\n",
      "Epoch 70/200, Iteration 195/250, Loss: 0.0133\n",
      "Epoch 70/200, Iteration 196/250, Loss: 0.0267\n",
      "Epoch 70/200, Iteration 197/250, Loss: 0.0169\n",
      "Epoch 70/200, Iteration 198/250, Loss: 0.0229\n",
      "Epoch 70/200, Iteration 199/250, Loss: 0.0105\n",
      "Epoch 70/200, Iteration 200/250, Loss: 0.0177\n",
      "Epoch 70/200, Iteration 201/250, Loss: 0.0175\n",
      "Epoch 70/200, Iteration 202/250, Loss: 0.0156\n",
      "Epoch 70/200, Iteration 203/250, Loss: 0.0233\n",
      "Epoch 70/200, Iteration 204/250, Loss: 0.0111\n",
      "Epoch 70/200, Iteration 205/250, Loss: 0.0224\n",
      "Epoch 70/200, Iteration 206/250, Loss: 0.0136\n",
      "Epoch 70/200, Iteration 207/250, Loss: 0.0119\n",
      "Epoch 70/200, Iteration 208/250, Loss: 0.0178\n",
      "Epoch 70/200, Iteration 209/250, Loss: 0.0223\n",
      "Epoch 70/200, Iteration 210/250, Loss: 0.0184\n",
      "Epoch 70/200, Iteration 211/250, Loss: 0.0102\n",
      "Epoch 70/200, Iteration 212/250, Loss: 0.0101\n",
      "Epoch 70/200, Iteration 213/250, Loss: 0.0106\n",
      "Epoch 70/200, Iteration 214/250, Loss: 0.0074\n",
      "Epoch 70/200, Iteration 215/250, Loss: 0.0326\n",
      "Epoch 70/200, Iteration 216/250, Loss: 0.0253\n",
      "Epoch 70/200, Iteration 217/250, Loss: 0.0160\n",
      "Epoch 70/200, Iteration 218/250, Loss: 0.0148\n",
      "Epoch 70/200, Iteration 219/250, Loss: 0.0361\n",
      "Epoch 70/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 70/200, Iteration 221/250, Loss: 0.0251\n",
      "Epoch 70/200, Iteration 222/250, Loss: 0.0215\n",
      "Epoch 70/200, Iteration 223/250, Loss: 0.0178\n",
      "Epoch 70/200, Iteration 224/250, Loss: 0.0213\n",
      "Epoch 70/200, Iteration 225/250, Loss: 0.0098\n",
      "Epoch 70/200, Iteration 226/250, Loss: 0.0107\n",
      "Epoch 70/200, Iteration 227/250, Loss: 0.0211\n",
      "Epoch 70/200, Iteration 228/250, Loss: 0.0171\n",
      "Epoch 70/200, Iteration 229/250, Loss: 0.0098\n",
      "Epoch 70/200, Iteration 230/250, Loss: 0.0065\n",
      "Epoch 70/200, Iteration 231/250, Loss: 0.0093\n",
      "Epoch 70/200, Iteration 232/250, Loss: 0.0229\n",
      "Epoch 70/200, Iteration 233/250, Loss: 0.0253\n",
      "Epoch 70/200, Iteration 234/250, Loss: 0.0080\n",
      "Epoch 70/200, Iteration 235/250, Loss: 0.0115\n",
      "Epoch 70/200, Iteration 236/250, Loss: 0.0082\n",
      "Epoch 70/200, Iteration 237/250, Loss: 0.0112\n",
      "Epoch 70/200, Iteration 238/250, Loss: 0.0126\n",
      "Epoch 70/200, Iteration 239/250, Loss: 0.0156\n",
      "Epoch 70/200, Iteration 240/250, Loss: 0.0149\n",
      "Epoch 70/200, Iteration 241/250, Loss: 0.0108\n",
      "Epoch 70/200, Iteration 242/250, Loss: 0.0165\n",
      "Epoch 70/200, Iteration 243/250, Loss: 0.0344\n",
      "Epoch 70/200, Iteration 244/250, Loss: 0.0146\n",
      "Epoch 70/200, Iteration 245/250, Loss: 0.0153\n",
      "Epoch 70/200, Iteration 246/250, Loss: 0.0116\n",
      "Epoch 70/200, Iteration 247/250, Loss: 0.0209\n",
      "Epoch 70/200, Iteration 248/250, Loss: 0.0160\n",
      "Epoch 70/200, Iteration 249/250, Loss: 0.0073\n",
      "Epoch 70/200, Iteration 250/250, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 62.34%, Avg loss: 0.009826, MRE: 0.639293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.010262, MRE: 0.586602 \n",
      "\n",
      "Epoch 71/200, Iteration 1/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 2/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 3/250, Loss: 0.0143\n",
      "Epoch 71/200, Iteration 4/250, Loss: 0.0185\n",
      "Epoch 71/200, Iteration 5/250, Loss: 0.0304\n",
      "Epoch 71/200, Iteration 6/250, Loss: 0.0421\n",
      "Epoch 71/200, Iteration 7/250, Loss: 0.0155\n",
      "Epoch 71/200, Iteration 8/250, Loss: 0.0113\n",
      "Epoch 71/200, Iteration 9/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 10/250, Loss: 0.0084\n",
      "Epoch 71/200, Iteration 11/250, Loss: 0.0114\n",
      "Epoch 71/200, Iteration 12/250, Loss: 0.0166\n",
      "Epoch 71/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 14/250, Loss: 0.0121\n",
      "Epoch 71/200, Iteration 15/250, Loss: 0.0106\n",
      "Epoch 71/200, Iteration 16/250, Loss: 0.0119\n",
      "Epoch 71/200, Iteration 17/250, Loss: 0.0097\n",
      "Epoch 71/200, Iteration 18/250, Loss: 0.0076\n",
      "Epoch 71/200, Iteration 19/250, Loss: 0.0383\n",
      "Epoch 71/200, Iteration 20/250, Loss: 0.0297\n",
      "Epoch 71/200, Iteration 21/250, Loss: 0.0174\n",
      "Epoch 71/200, Iteration 22/250, Loss: 0.0191\n",
      "Epoch 71/200, Iteration 23/250, Loss: 0.0158\n",
      "Epoch 71/200, Iteration 24/250, Loss: 0.0079\n",
      "Epoch 71/200, Iteration 25/250, Loss: 0.0258\n",
      "Epoch 71/200, Iteration 26/250, Loss: 0.0172\n",
      "Epoch 71/200, Iteration 27/250, Loss: 0.0117\n",
      "Epoch 71/200, Iteration 28/250, Loss: 0.0170\n",
      "Epoch 71/200, Iteration 29/250, Loss: 0.0191\n",
      "Epoch 71/200, Iteration 30/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 31/250, Loss: 0.0148\n",
      "Epoch 71/200, Iteration 32/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 33/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 34/250, Loss: 0.0116\n",
      "Epoch 71/200, Iteration 35/250, Loss: 0.0244\n",
      "Epoch 71/200, Iteration 36/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 37/250, Loss: 0.0271\n",
      "Epoch 71/200, Iteration 38/250, Loss: 0.0159\n",
      "Epoch 71/200, Iteration 39/250, Loss: 0.0085\n",
      "Epoch 71/200, Iteration 40/250, Loss: 0.0063\n",
      "Epoch 71/200, Iteration 41/250, Loss: 0.0121\n",
      "Epoch 71/200, Iteration 42/250, Loss: 0.0168\n",
      "Epoch 71/200, Iteration 43/250, Loss: 0.0117\n",
      "Epoch 71/200, Iteration 44/250, Loss: 0.0087\n",
      "Epoch 71/200, Iteration 45/250, Loss: 0.0078\n",
      "Epoch 71/200, Iteration 46/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 47/250, Loss: 0.0289\n",
      "Epoch 71/200, Iteration 48/250, Loss: 0.0122\n",
      "Epoch 71/200, Iteration 49/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 50/250, Loss: 0.0111\n",
      "Epoch 71/200, Iteration 51/250, Loss: 0.0124\n",
      "Epoch 71/200, Iteration 52/250, Loss: 0.0139\n",
      "Epoch 71/200, Iteration 53/250, Loss: 0.0136\n",
      "Epoch 71/200, Iteration 54/250, Loss: 0.0238\n",
      "Epoch 71/200, Iteration 55/250, Loss: 0.0095\n",
      "Epoch 71/200, Iteration 56/250, Loss: 0.0372\n",
      "Epoch 71/200, Iteration 57/250, Loss: 0.0133\n",
      "Epoch 71/200, Iteration 58/250, Loss: 0.0215\n",
      "Epoch 71/200, Iteration 59/250, Loss: 0.0140\n",
      "Epoch 71/200, Iteration 60/250, Loss: 0.0098\n",
      "Epoch 71/200, Iteration 61/250, Loss: 0.0092\n",
      "Epoch 71/200, Iteration 62/250, Loss: 0.0097\n",
      "Epoch 71/200, Iteration 63/250, Loss: 0.0308\n",
      "Epoch 71/200, Iteration 64/250, Loss: 0.0304\n",
      "Epoch 71/200, Iteration 65/250, Loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200, Iteration 66/250, Loss: 0.0078\n",
      "Epoch 71/200, Iteration 67/250, Loss: 0.0267\n",
      "Epoch 71/200, Iteration 68/250, Loss: 0.0227\n",
      "Epoch 71/200, Iteration 69/250, Loss: 0.0138\n",
      "Epoch 71/200, Iteration 70/250, Loss: 0.0095\n",
      "Epoch 71/200, Iteration 71/250, Loss: 0.0087\n",
      "Epoch 71/200, Iteration 72/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 73/250, Loss: 0.0108\n",
      "Epoch 71/200, Iteration 74/250, Loss: 0.0265\n",
      "Epoch 71/200, Iteration 75/250, Loss: 0.0076\n",
      "Epoch 71/200, Iteration 76/250, Loss: 0.0064\n",
      "Epoch 71/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 71/200, Iteration 78/250, Loss: 0.0172\n",
      "Epoch 71/200, Iteration 79/250, Loss: 0.0167\n",
      "Epoch 71/200, Iteration 80/250, Loss: 0.0173\n",
      "Epoch 71/200, Iteration 81/250, Loss: 0.0178\n",
      "Epoch 71/200, Iteration 82/250, Loss: 0.0139\n",
      "Epoch 71/200, Iteration 83/250, Loss: 0.0208\n",
      "Epoch 71/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 85/250, Loss: 0.0151\n",
      "Epoch 71/200, Iteration 86/250, Loss: 0.0205\n",
      "Epoch 71/200, Iteration 87/250, Loss: 0.0104\n",
      "Epoch 71/200, Iteration 88/250, Loss: 0.0083\n",
      "Epoch 71/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 71/200, Iteration 90/250, Loss: 0.0077\n",
      "Epoch 71/200, Iteration 91/250, Loss: 0.0106\n",
      "Epoch 71/200, Iteration 92/250, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 93/250, Loss: 0.0305\n",
      "Epoch 71/200, Iteration 94/250, Loss: 0.0191\n",
      "Epoch 71/200, Iteration 95/250, Loss: 0.0180\n",
      "Epoch 71/200, Iteration 96/250, Loss: 0.0113\n",
      "Epoch 71/200, Iteration 97/250, Loss: 0.0142\n",
      "Epoch 71/200, Iteration 98/250, Loss: 0.0170\n",
      "Epoch 71/200, Iteration 99/250, Loss: 0.0096\n",
      "Epoch 71/200, Iteration 100/250, Loss: 0.0257\n",
      "Epoch 71/200, Iteration 101/250, Loss: 0.0145\n",
      "Epoch 71/200, Iteration 102/250, Loss: 0.0184\n",
      "Epoch 71/200, Iteration 103/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 104/250, Loss: 0.0145\n",
      "Epoch 71/200, Iteration 105/250, Loss: 0.0137\n",
      "Epoch 71/200, Iteration 106/250, Loss: 0.0235\n",
      "Epoch 71/200, Iteration 107/250, Loss: 0.0102\n",
      "Epoch 71/200, Iteration 108/250, Loss: 0.0152\n",
      "Epoch 71/200, Iteration 109/250, Loss: 0.0111\n",
      "Epoch 71/200, Iteration 110/250, Loss: 0.0219\n",
      "Epoch 71/200, Iteration 111/250, Loss: 0.0074\n",
      "Epoch 71/200, Iteration 112/250, Loss: 0.0286\n",
      "Epoch 71/200, Iteration 113/250, Loss: 0.0103\n",
      "Epoch 71/200, Iteration 114/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 115/250, Loss: 0.0131\n",
      "Epoch 71/200, Iteration 116/250, Loss: 0.0118\n",
      "Epoch 71/200, Iteration 117/250, Loss: 0.0193\n",
      "Epoch 71/200, Iteration 118/250, Loss: 0.0218\n",
      "Epoch 71/200, Iteration 119/250, Loss: 0.0125\n",
      "Epoch 71/200, Iteration 120/250, Loss: 0.0092\n",
      "Epoch 71/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 71/200, Iteration 122/250, Loss: 0.0079\n",
      "Epoch 71/200, Iteration 123/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 124/250, Loss: 0.0365\n",
      "Epoch 71/200, Iteration 125/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 126/250, Loss: 0.0289\n",
      "Epoch 71/200, Iteration 127/250, Loss: 0.0204\n",
      "Epoch 71/200, Iteration 128/250, Loss: 0.0161\n",
      "Epoch 71/200, Iteration 129/250, Loss: 0.0115\n",
      "Epoch 71/200, Iteration 130/250, Loss: 0.0141\n",
      "Epoch 71/200, Iteration 131/250, Loss: 0.0074\n",
      "Epoch 71/200, Iteration 132/250, Loss: 0.0141\n",
      "Epoch 71/200, Iteration 133/250, Loss: 0.0190\n",
      "Epoch 71/200, Iteration 134/250, Loss: 0.0143\n",
      "Epoch 71/200, Iteration 135/250, Loss: 0.0157\n",
      "Epoch 71/200, Iteration 136/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 137/250, Loss: 0.0166\n",
      "Epoch 71/200, Iteration 138/250, Loss: 0.0119\n",
      "Epoch 71/200, Iteration 139/250, Loss: 0.0128\n",
      "Epoch 71/200, Iteration 140/250, Loss: 0.0277\n",
      "Epoch 71/200, Iteration 141/250, Loss: 0.0144\n",
      "Epoch 71/200, Iteration 142/250, Loss: 0.0210\n",
      "Epoch 71/200, Iteration 143/250, Loss: 0.0146\n",
      "Epoch 71/200, Iteration 144/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 145/250, Loss: 0.0080\n",
      "Epoch 71/200, Iteration 146/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 147/250, Loss: 0.0068\n",
      "Epoch 71/200, Iteration 148/250, Loss: 0.0117\n",
      "Epoch 71/200, Iteration 149/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 150/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 151/250, Loss: 0.0098\n",
      "Epoch 71/200, Iteration 152/250, Loss: 0.0081\n",
      "Epoch 71/200, Iteration 153/250, Loss: 0.0119\n",
      "Epoch 71/200, Iteration 154/250, Loss: 0.0169\n",
      "Epoch 71/200, Iteration 155/250, Loss: 0.0103\n",
      "Epoch 71/200, Iteration 156/250, Loss: 0.0136\n",
      "Epoch 71/200, Iteration 157/250, Loss: 0.0147\n",
      "Epoch 71/200, Iteration 158/250, Loss: 0.0128\n",
      "Epoch 71/200, Iteration 159/250, Loss: 0.0248\n",
      "Epoch 71/200, Iteration 160/250, Loss: 0.0171\n",
      "Epoch 71/200, Iteration 161/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 162/250, Loss: 0.0092\n",
      "Epoch 71/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 71/200, Iteration 164/250, Loss: 0.0145\n",
      "Epoch 71/200, Iteration 165/250, Loss: 0.0124\n",
      "Epoch 71/200, Iteration 166/250, Loss: 0.0148\n",
      "Epoch 71/200, Iteration 167/250, Loss: 0.0087\n",
      "Epoch 71/200, Iteration 168/250, Loss: 0.0112\n",
      "Epoch 71/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 71/200, Iteration 170/250, Loss: 0.0205\n",
      "Epoch 71/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 71/200, Iteration 172/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 173/250, Loss: 0.0174\n",
      "Epoch 71/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 71/200, Iteration 175/250, Loss: 0.0100\n",
      "Epoch 71/200, Iteration 176/250, Loss: 0.0211\n",
      "Epoch 71/200, Iteration 177/250, Loss: 0.0176\n",
      "Epoch 71/200, Iteration 178/250, Loss: 0.0101\n",
      "Epoch 71/200, Iteration 179/250, Loss: 0.0107\n",
      "Epoch 71/200, Iteration 180/250, Loss: 0.0180\n",
      "Epoch 71/200, Iteration 181/250, Loss: 0.0195\n",
      "Epoch 71/200, Iteration 182/250, Loss: 0.0346\n",
      "Epoch 71/200, Iteration 183/250, Loss: 0.0215\n",
      "Epoch 71/200, Iteration 184/250, Loss: 0.0053\n",
      "Epoch 71/200, Iteration 185/250, Loss: 0.0079\n",
      "Epoch 71/200, Iteration 186/250, Loss: 0.0353\n",
      "Epoch 71/200, Iteration 187/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 188/250, Loss: 0.0189\n",
      "Epoch 71/200, Iteration 189/250, Loss: 0.0244\n",
      "Epoch 71/200, Iteration 190/250, Loss: 0.0104\n",
      "Epoch 71/200, Iteration 191/250, Loss: 0.0130\n",
      "Epoch 71/200, Iteration 192/250, Loss: 0.0228\n",
      "Epoch 71/200, Iteration 193/250, Loss: 0.0097\n",
      "Epoch 71/200, Iteration 194/250, Loss: 0.0104\n",
      "Epoch 71/200, Iteration 195/250, Loss: 0.0125\n",
      "Epoch 71/200, Iteration 196/250, Loss: 0.0079\n",
      "Epoch 71/200, Iteration 197/250, Loss: 0.0157\n",
      "Epoch 71/200, Iteration 198/250, Loss: 0.0121\n",
      "Epoch 71/200, Iteration 199/250, Loss: 0.0162\n",
      "Epoch 71/200, Iteration 200/250, Loss: 0.0113\n",
      "Epoch 71/200, Iteration 201/250, Loss: 0.0131\n",
      "Epoch 71/200, Iteration 202/250, Loss: 0.0190\n",
      "Epoch 71/200, Iteration 203/250, Loss: 0.0118\n",
      "Epoch 71/200, Iteration 204/250, Loss: 0.0224\n",
      "Epoch 71/200, Iteration 205/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 206/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 207/250, Loss: 0.0245\n",
      "Epoch 71/200, Iteration 208/250, Loss: 0.0247\n",
      "Epoch 71/200, Iteration 209/250, Loss: 0.0081\n",
      "Epoch 71/200, Iteration 210/250, Loss: 0.0094\n",
      "Epoch 71/200, Iteration 211/250, Loss: 0.0123\n",
      "Epoch 71/200, Iteration 212/250, Loss: 0.0157\n",
      "Epoch 71/200, Iteration 213/250, Loss: 0.0090\n",
      "Epoch 71/200, Iteration 214/250, Loss: 0.0149\n",
      "Epoch 71/200, Iteration 215/250, Loss: 0.0176\n",
      "Epoch 71/200, Iteration 216/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 217/250, Loss: 0.0070\n",
      "Epoch 71/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 71/200, Iteration 219/250, Loss: 0.0196\n",
      "Epoch 71/200, Iteration 220/250, Loss: 0.0231\n",
      "Epoch 71/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 71/200, Iteration 222/250, Loss: 0.0132\n",
      "Epoch 71/200, Iteration 223/250, Loss: 0.0069\n",
      "Epoch 71/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 71/200, Iteration 225/250, Loss: 0.0070\n",
      "Epoch 71/200, Iteration 226/250, Loss: 0.0101\n",
      "Epoch 71/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 71/200, Iteration 228/250, Loss: 0.0130\n",
      "Epoch 71/200, Iteration 229/250, Loss: 0.0215\n",
      "Epoch 71/200, Iteration 230/250, Loss: 0.0134\n",
      "Epoch 71/200, Iteration 231/250, Loss: 0.0095\n",
      "Epoch 71/200, Iteration 232/250, Loss: 0.0077\n",
      "Epoch 71/200, Iteration 233/250, Loss: 0.0140\n",
      "Epoch 71/200, Iteration 234/250, Loss: 0.0150\n",
      "Epoch 71/200, Iteration 235/250, Loss: 0.0064\n",
      "Epoch 71/200, Iteration 236/250, Loss: 0.0145\n",
      "Epoch 71/200, Iteration 237/250, Loss: 0.0285\n",
      "Epoch 71/200, Iteration 238/250, Loss: 0.0282\n",
      "Epoch 71/200, Iteration 239/250, Loss: 0.0089\n",
      "Epoch 71/200, Iteration 240/250, Loss: 0.0093\n",
      "Epoch 71/200, Iteration 241/250, Loss: 0.0138\n",
      "Epoch 71/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 71/200, Iteration 243/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 244/250, Loss: 0.0214\n",
      "Epoch 71/200, Iteration 245/250, Loss: 0.0091\n",
      "Epoch 71/200, Iteration 246/250, Loss: 0.0200\n",
      "Epoch 71/200, Iteration 247/250, Loss: 0.0127\n",
      "Epoch 71/200, Iteration 248/250, Loss: 0.0114\n",
      "Epoch 71/200, Iteration 249/250, Loss: 0.0224\n",
      "Epoch 71/200, Iteration 250/250, Loss: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 76.31%, Avg loss: 0.007702, MRE: 0.566184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.15%, Avg loss: 0.008086, MRE: 0.670514 \n",
      "\n",
      "Epoch 72/200, Iteration 1/250, Loss: 0.0279\n",
      "Epoch 72/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 3/250, Loss: 0.0240\n",
      "Epoch 72/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 5/250, Loss: 0.0123\n",
      "Epoch 72/200, Iteration 6/250, Loss: 0.0092\n",
      "Epoch 72/200, Iteration 7/250, Loss: 0.0125\n",
      "Epoch 72/200, Iteration 8/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 9/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 10/250, Loss: 0.0201\n",
      "Epoch 72/200, Iteration 11/250, Loss: 0.0069\n",
      "Epoch 72/200, Iteration 12/250, Loss: 0.0086\n",
      "Epoch 72/200, Iteration 13/250, Loss: 0.0369\n",
      "Epoch 72/200, Iteration 14/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 15/250, Loss: 0.0079\n",
      "Epoch 72/200, Iteration 16/250, Loss: 0.0098\n",
      "Epoch 72/200, Iteration 17/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 18/250, Loss: 0.0138\n",
      "Epoch 72/200, Iteration 19/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 20/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 21/250, Loss: 0.0104\n",
      "Epoch 72/200, Iteration 22/250, Loss: 0.0196\n",
      "Epoch 72/200, Iteration 23/250, Loss: 0.0222\n",
      "Epoch 72/200, Iteration 24/250, Loss: 0.0097\n",
      "Epoch 72/200, Iteration 25/250, Loss: 0.0083\n",
      "Epoch 72/200, Iteration 26/250, Loss: 0.0079\n",
      "Epoch 72/200, Iteration 27/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 28/250, Loss: 0.0115\n",
      "Epoch 72/200, Iteration 29/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 30/250, Loss: 0.0096\n",
      "Epoch 72/200, Iteration 31/250, Loss: 0.0176\n",
      "Epoch 72/200, Iteration 32/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 33/250, Loss: 0.0092\n",
      "Epoch 72/200, Iteration 34/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 35/250, Loss: 0.0151\n",
      "Epoch 72/200, Iteration 36/250, Loss: 0.0078\n",
      "Epoch 72/200, Iteration 37/250, Loss: 0.0139\n",
      "Epoch 72/200, Iteration 38/250, Loss: 0.0164\n",
      "Epoch 72/200, Iteration 39/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 40/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 41/250, Loss: 0.0207\n",
      "Epoch 72/200, Iteration 42/250, Loss: 0.0172\n",
      "Epoch 72/200, Iteration 43/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 44/250, Loss: 0.0245\n",
      "Epoch 72/200, Iteration 45/250, Loss: 0.0212\n",
      "Epoch 72/200, Iteration 46/250, Loss: 0.0271\n",
      "Epoch 72/200, Iteration 47/250, Loss: 0.0061\n",
      "Epoch 72/200, Iteration 48/250, Loss: 0.0251\n",
      "Epoch 72/200, Iteration 49/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 50/250, Loss: 0.0187\n",
      "Epoch 72/200, Iteration 51/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 52/250, Loss: 0.0311\n",
      "Epoch 72/200, Iteration 53/250, Loss: 0.0238\n",
      "Epoch 72/200, Iteration 54/250, Loss: 0.0181\n",
      "Epoch 72/200, Iteration 55/250, Loss: 0.0220\n",
      "Epoch 72/200, Iteration 56/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 57/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 58/250, Loss: 0.0175\n",
      "Epoch 72/200, Iteration 59/250, Loss: 0.0243\n",
      "Epoch 72/200, Iteration 60/250, Loss: 0.0290\n",
      "Epoch 72/200, Iteration 61/250, Loss: 0.0103\n",
      "Epoch 72/200, Iteration 62/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 63/250, Loss: 0.0173\n",
      "Epoch 72/200, Iteration 64/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 65/250, Loss: 0.0222\n",
      "Epoch 72/200, Iteration 66/250, Loss: 0.0422\n",
      "Epoch 72/200, Iteration 67/250, Loss: 0.0094\n",
      "Epoch 72/200, Iteration 68/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 69/250, Loss: 0.0202\n",
      "Epoch 72/200, Iteration 70/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 71/250, Loss: 0.0110\n",
      "Epoch 72/200, Iteration 72/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 73/250, Loss: 0.0117\n",
      "Epoch 72/200, Iteration 74/250, Loss: 0.0094\n",
      "Epoch 72/200, Iteration 75/250, Loss: 0.0085\n",
      "Epoch 72/200, Iteration 76/250, Loss: 0.0186\n",
      "Epoch 72/200, Iteration 77/250, Loss: 0.0139\n",
      "Epoch 72/200, Iteration 78/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 79/250, Loss: 0.0250\n",
      "Epoch 72/200, Iteration 80/250, Loss: 0.0112\n",
      "Epoch 72/200, Iteration 81/250, Loss: 0.0212\n",
      "Epoch 72/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 83/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 84/250, Loss: 0.0265\n",
      "Epoch 72/200, Iteration 85/250, Loss: 0.0083\n",
      "Epoch 72/200, Iteration 86/250, Loss: 0.0147\n",
      "Epoch 72/200, Iteration 87/250, Loss: 0.0092\n",
      "Epoch 72/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 89/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 90/250, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 91/250, Loss: 0.0114\n",
      "Epoch 72/200, Iteration 92/250, Loss: 0.0363\n",
      "Epoch 72/200, Iteration 93/250, Loss: 0.0233\n",
      "Epoch 72/200, Iteration 94/250, Loss: 0.0307\n",
      "Epoch 72/200, Iteration 95/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 96/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 97/250, Loss: 0.0205\n",
      "Epoch 72/200, Iteration 98/250, Loss: 0.0175\n",
      "Epoch 72/200, Iteration 99/250, Loss: 0.0088\n",
      "Epoch 72/200, Iteration 100/250, Loss: 0.0303\n",
      "Epoch 72/200, Iteration 101/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 102/250, Loss: 0.0182\n",
      "Epoch 72/200, Iteration 103/250, Loss: 0.0139\n",
      "Epoch 72/200, Iteration 104/250, Loss: 0.0098\n",
      "Epoch 72/200, Iteration 105/250, Loss: 0.0186\n",
      "Epoch 72/200, Iteration 106/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 107/250, Loss: 0.0395\n",
      "Epoch 72/200, Iteration 108/250, Loss: 0.0104\n",
      "Epoch 72/200, Iteration 109/250, Loss: 0.0145\n",
      "Epoch 72/200, Iteration 110/250, Loss: 0.0154\n",
      "Epoch 72/200, Iteration 111/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 112/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 113/250, Loss: 0.0165\n",
      "Epoch 72/200, Iteration 114/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 116/250, Loss: 0.0111\n",
      "Epoch 72/200, Iteration 117/250, Loss: 0.0105\n",
      "Epoch 72/200, Iteration 118/250, Loss: 0.0202\n",
      "Epoch 72/200, Iteration 119/250, Loss: 0.0262\n",
      "Epoch 72/200, Iteration 120/250, Loss: 0.0273\n",
      "Epoch 72/200, Iteration 121/250, Loss: 0.0148\n",
      "Epoch 72/200, Iteration 122/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 123/250, Loss: 0.0264\n",
      "Epoch 72/200, Iteration 124/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 125/250, Loss: 0.0167\n",
      "Epoch 72/200, Iteration 126/250, Loss: 0.0115\n",
      "Epoch 72/200, Iteration 127/250, Loss: 0.0368\n",
      "Epoch 72/200, Iteration 128/250, Loss: 0.0167\n",
      "Epoch 72/200, Iteration 129/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 130/250, Loss: 0.0123\n",
      "Epoch 72/200, Iteration 131/250, Loss: 0.0131\n",
      "Epoch 72/200, Iteration 132/250, Loss: 0.0110\n",
      "Epoch 72/200, Iteration 133/250, Loss: 0.0114\n",
      "Epoch 72/200, Iteration 134/250, Loss: 0.0214\n",
      "Epoch 72/200, Iteration 135/250, Loss: 0.0105\n",
      "Epoch 72/200, Iteration 136/250, Loss: 0.0139\n",
      "Epoch 72/200, Iteration 137/250, Loss: 0.0142\n",
      "Epoch 72/200, Iteration 138/250, Loss: 0.0076\n",
      "Epoch 72/200, Iteration 139/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 140/250, Loss: 0.0201\n",
      "Epoch 72/200, Iteration 141/250, Loss: 0.0259\n",
      "Epoch 72/200, Iteration 142/250, Loss: 0.0196\n",
      "Epoch 72/200, Iteration 143/250, Loss: 0.0149\n",
      "Epoch 72/200, Iteration 144/250, Loss: 0.0171\n",
      "Epoch 72/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 146/250, Loss: 0.0222\n",
      "Epoch 72/200, Iteration 147/250, Loss: 0.0098\n",
      "Epoch 72/200, Iteration 148/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 149/250, Loss: 0.0092\n",
      "Epoch 72/200, Iteration 150/250, Loss: 0.0198\n",
      "Epoch 72/200, Iteration 151/250, Loss: 0.0137\n",
      "Epoch 72/200, Iteration 152/250, Loss: 0.0219\n",
      "Epoch 72/200, Iteration 153/250, Loss: 0.0229\n",
      "Epoch 72/200, Iteration 154/250, Loss: 0.0110\n",
      "Epoch 72/200, Iteration 155/250, Loss: 0.0153\n",
      "Epoch 72/200, Iteration 156/250, Loss: 0.0174\n",
      "Epoch 72/200, Iteration 157/250, Loss: 0.0170\n",
      "Epoch 72/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 72/200, Iteration 159/250, Loss: 0.0179\n",
      "Epoch 72/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 161/250, Loss: 0.0075\n",
      "Epoch 72/200, Iteration 162/250, Loss: 0.0256\n",
      "Epoch 72/200, Iteration 163/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 72/200, Iteration 165/250, Loss: 0.0120\n",
      "Epoch 72/200, Iteration 166/250, Loss: 0.0125\n",
      "Epoch 72/200, Iteration 167/250, Loss: 0.0140\n",
      "Epoch 72/200, Iteration 168/250, Loss: 0.0191\n",
      "Epoch 72/200, Iteration 169/250, Loss: 0.0153\n",
      "Epoch 72/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 72/200, Iteration 171/250, Loss: 0.0106\n",
      "Epoch 72/200, Iteration 172/250, Loss: 0.0077\n",
      "Epoch 72/200, Iteration 173/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 174/250, Loss: 0.0178\n",
      "Epoch 72/200, Iteration 175/250, Loss: 0.0173\n",
      "Epoch 72/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 72/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 72/200, Iteration 178/250, Loss: 0.0123\n",
      "Epoch 72/200, Iteration 179/250, Loss: 0.0187\n",
      "Epoch 72/200, Iteration 180/250, Loss: 0.0154\n",
      "Epoch 72/200, Iteration 181/250, Loss: 0.0299\n",
      "Epoch 72/200, Iteration 182/250, Loss: 0.0080\n",
      "Epoch 72/200, Iteration 183/250, Loss: 0.0198\n",
      "Epoch 72/200, Iteration 184/250, Loss: 0.0209\n",
      "Epoch 72/200, Iteration 185/250, Loss: 0.0107\n",
      "Epoch 72/200, Iteration 186/250, Loss: 0.0301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200, Iteration 187/250, Loss: 0.0183\n",
      "Epoch 72/200, Iteration 188/250, Loss: 0.0530\n",
      "Epoch 72/200, Iteration 189/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 190/250, Loss: 0.0066\n",
      "Epoch 72/200, Iteration 191/250, Loss: 0.0149\n",
      "Epoch 72/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 72/200, Iteration 193/250, Loss: 0.0176\n",
      "Epoch 72/200, Iteration 194/250, Loss: 0.0094\n",
      "Epoch 72/200, Iteration 195/250, Loss: 0.0250\n",
      "Epoch 72/200, Iteration 196/250, Loss: 0.0196\n",
      "Epoch 72/200, Iteration 197/250, Loss: 0.0136\n",
      "Epoch 72/200, Iteration 198/250, Loss: 0.0082\n",
      "Epoch 72/200, Iteration 199/250, Loss: 0.0294\n",
      "Epoch 72/200, Iteration 200/250, Loss: 0.0087\n",
      "Epoch 72/200, Iteration 201/250, Loss: 0.0229\n",
      "Epoch 72/200, Iteration 202/250, Loss: 0.0091\n",
      "Epoch 72/200, Iteration 203/250, Loss: 0.0149\n",
      "Epoch 72/200, Iteration 204/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 205/250, Loss: 0.0102\n",
      "Epoch 72/200, Iteration 206/250, Loss: 0.0191\n",
      "Epoch 72/200, Iteration 207/250, Loss: 0.0104\n",
      "Epoch 72/200, Iteration 208/250, Loss: 0.0182\n",
      "Epoch 72/200, Iteration 209/250, Loss: 0.0177\n",
      "Epoch 72/200, Iteration 210/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 72/200, Iteration 212/250, Loss: 0.0078\n",
      "Epoch 72/200, Iteration 213/250, Loss: 0.0209\n",
      "Epoch 72/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 72/200, Iteration 215/250, Loss: 0.0153\n",
      "Epoch 72/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 72/200, Iteration 217/250, Loss: 0.0091\n",
      "Epoch 72/200, Iteration 218/250, Loss: 0.0138\n",
      "Epoch 72/200, Iteration 219/250, Loss: 0.0080\n",
      "Epoch 72/200, Iteration 220/250, Loss: 0.0289\n",
      "Epoch 72/200, Iteration 221/250, Loss: 0.0101\n",
      "Epoch 72/200, Iteration 222/250, Loss: 0.0163\n",
      "Epoch 72/200, Iteration 223/250, Loss: 0.0118\n",
      "Epoch 72/200, Iteration 224/250, Loss: 0.0160\n",
      "Epoch 72/200, Iteration 225/250, Loss: 0.0148\n",
      "Epoch 72/200, Iteration 226/250, Loss: 0.0124\n",
      "Epoch 72/200, Iteration 227/250, Loss: 0.0261\n",
      "Epoch 72/200, Iteration 228/250, Loss: 0.0116\n",
      "Epoch 72/200, Iteration 229/250, Loss: 0.0125\n",
      "Epoch 72/200, Iteration 230/250, Loss: 0.0216\n",
      "Epoch 72/200, Iteration 231/250, Loss: 0.0245\n",
      "Epoch 72/200, Iteration 232/250, Loss: 0.0098\n",
      "Epoch 72/200, Iteration 233/250, Loss: 0.0091\n",
      "Epoch 72/200, Iteration 234/250, Loss: 0.0293\n",
      "Epoch 72/200, Iteration 235/250, Loss: 0.0090\n",
      "Epoch 72/200, Iteration 236/250, Loss: 0.0128\n",
      "Epoch 72/200, Iteration 237/250, Loss: 0.0179\n",
      "Epoch 72/200, Iteration 238/250, Loss: 0.0225\n",
      "Epoch 72/200, Iteration 239/250, Loss: 0.0562\n",
      "Epoch 72/200, Iteration 240/250, Loss: 0.0231\n",
      "Epoch 72/200, Iteration 241/250, Loss: 0.0071\n",
      "Epoch 72/200, Iteration 242/250, Loss: 0.0259\n",
      "Epoch 72/200, Iteration 243/250, Loss: 0.0143\n",
      "Epoch 72/200, Iteration 244/250, Loss: 0.0137\n",
      "Epoch 72/200, Iteration 245/250, Loss: 0.0118\n",
      "Epoch 72/200, Iteration 246/250, Loss: 0.0224\n",
      "Epoch 72/200, Iteration 247/250, Loss: 0.0108\n",
      "Epoch 72/200, Iteration 248/250, Loss: 0.0102\n",
      "Epoch 72/200, Iteration 249/250, Loss: 0.0099\n",
      "Epoch 72/200, Iteration 250/250, Loss: 0.0542\n",
      "Train Error: \n",
      " Accuracy: 96.99%, Avg loss: 0.010375, MRE: 0.565883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.010868, MRE: 0.654113 \n",
      "\n",
      "Epoch 73/200, Iteration 1/250, Loss: 0.0127\n",
      "Epoch 73/200, Iteration 2/250, Loss: 0.0117\n",
      "Epoch 73/200, Iteration 3/250, Loss: 0.0415\n",
      "Epoch 73/200, Iteration 4/250, Loss: 0.0173\n",
      "Epoch 73/200, Iteration 5/250, Loss: 0.0125\n",
      "Epoch 73/200, Iteration 6/250, Loss: 0.0203\n",
      "Epoch 73/200, Iteration 7/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 8/250, Loss: 0.0171\n",
      "Epoch 73/200, Iteration 9/250, Loss: 0.0157\n",
      "Epoch 73/200, Iteration 10/250, Loss: 0.0071\n",
      "Epoch 73/200, Iteration 11/250, Loss: 0.0184\n",
      "Epoch 73/200, Iteration 12/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 73/200, Iteration 14/250, Loss: 0.0077\n",
      "Epoch 73/200, Iteration 15/250, Loss: 0.0086\n",
      "Epoch 73/200, Iteration 16/250, Loss: 0.0115\n",
      "Epoch 73/200, Iteration 17/250, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 18/250, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 19/250, Loss: 0.0077\n",
      "Epoch 73/200, Iteration 20/250, Loss: 0.0108\n",
      "Epoch 73/200, Iteration 21/250, Loss: 0.0254\n",
      "Epoch 73/200, Iteration 22/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 23/250, Loss: 0.0073\n",
      "Epoch 73/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 25/250, Loss: 0.0299\n",
      "Epoch 73/200, Iteration 26/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 28/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 29/250, Loss: 0.0102\n",
      "Epoch 73/200, Iteration 30/250, Loss: 0.0094\n",
      "Epoch 73/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 73/200, Iteration 32/250, Loss: 0.0137\n",
      "Epoch 73/200, Iteration 33/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 34/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 35/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 36/250, Loss: 0.0087\n",
      "Epoch 73/200, Iteration 37/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 38/250, Loss: 0.0112\n",
      "Epoch 73/200, Iteration 39/250, Loss: 0.0120\n",
      "Epoch 73/200, Iteration 40/250, Loss: 0.0193\n",
      "Epoch 73/200, Iteration 41/250, Loss: 0.0142\n",
      "Epoch 73/200, Iteration 42/250, Loss: 0.0099\n",
      "Epoch 73/200, Iteration 43/250, Loss: 0.0413\n",
      "Epoch 73/200, Iteration 44/250, Loss: 0.0130\n",
      "Epoch 73/200, Iteration 45/250, Loss: 0.0127\n",
      "Epoch 73/200, Iteration 46/250, Loss: 0.0085\n",
      "Epoch 73/200, Iteration 47/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 48/250, Loss: 0.0439\n",
      "Epoch 73/200, Iteration 49/250, Loss: 0.0072\n",
      "Epoch 73/200, Iteration 50/250, Loss: 0.0086\n",
      "Epoch 73/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 73/200, Iteration 52/250, Loss: 0.0343\n",
      "Epoch 73/200, Iteration 53/250, Loss: 0.0176\n",
      "Epoch 73/200, Iteration 54/250, Loss: 0.0123\n",
      "Epoch 73/200, Iteration 55/250, Loss: 0.0103\n",
      "Epoch 73/200, Iteration 56/250, Loss: 0.0244\n",
      "Epoch 73/200, Iteration 57/250, Loss: 0.0201\n",
      "Epoch 73/200, Iteration 58/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 59/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 60/250, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 61/250, Loss: 0.0124\n",
      "Epoch 73/200, Iteration 62/250, Loss: 0.0092\n",
      "Epoch 73/200, Iteration 63/250, Loss: 0.0425\n",
      "Epoch 73/200, Iteration 64/250, Loss: 0.0153\n",
      "Epoch 73/200, Iteration 65/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 66/250, Loss: 0.0332\n",
      "Epoch 73/200, Iteration 67/250, Loss: 0.0120\n",
      "Epoch 73/200, Iteration 68/250, Loss: 0.0133\n",
      "Epoch 73/200, Iteration 69/250, Loss: 0.0125\n",
      "Epoch 73/200, Iteration 70/250, Loss: 0.0128\n",
      "Epoch 73/200, Iteration 71/250, Loss: 0.0137\n",
      "Epoch 73/200, Iteration 72/250, Loss: 0.0161\n",
      "Epoch 73/200, Iteration 73/250, Loss: 0.0079\n",
      "Epoch 73/200, Iteration 74/250, Loss: 0.0101\n",
      "Epoch 73/200, Iteration 75/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 76/250, Loss: 0.0079\n",
      "Epoch 73/200, Iteration 77/250, Loss: 0.0080\n",
      "Epoch 73/200, Iteration 78/250, Loss: 0.0203\n",
      "Epoch 73/200, Iteration 79/250, Loss: 0.0458\n",
      "Epoch 73/200, Iteration 80/250, Loss: 0.0293\n",
      "Epoch 73/200, Iteration 81/250, Loss: 0.0201\n",
      "Epoch 73/200, Iteration 82/250, Loss: 0.0089\n",
      "Epoch 73/200, Iteration 83/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 84/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 85/250, Loss: 0.0075\n",
      "Epoch 73/200, Iteration 86/250, Loss: 0.0211\n",
      "Epoch 73/200, Iteration 87/250, Loss: 0.0080\n",
      "Epoch 73/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 73/200, Iteration 89/250, Loss: 0.0140\n",
      "Epoch 73/200, Iteration 90/250, Loss: 0.0173\n",
      "Epoch 73/200, Iteration 91/250, Loss: 0.0248\n",
      "Epoch 73/200, Iteration 92/250, Loss: 0.0169\n",
      "Epoch 73/200, Iteration 93/250, Loss: 0.0204\n",
      "Epoch 73/200, Iteration 94/250, Loss: 0.0164\n",
      "Epoch 73/200, Iteration 95/250, Loss: 0.0179\n",
      "Epoch 73/200, Iteration 96/250, Loss: 0.0217\n",
      "Epoch 73/200, Iteration 97/250, Loss: 0.0189\n",
      "Epoch 73/200, Iteration 98/250, Loss: 0.0147\n",
      "Epoch 73/200, Iteration 99/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 100/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 101/250, Loss: 0.0158\n",
      "Epoch 73/200, Iteration 102/250, Loss: 0.0100\n",
      "Epoch 73/200, Iteration 103/250, Loss: 0.0129\n",
      "Epoch 73/200, Iteration 104/250, Loss: 0.0093\n",
      "Epoch 73/200, Iteration 105/250, Loss: 0.0208\n",
      "Epoch 73/200, Iteration 106/250, Loss: 0.0128\n",
      "Epoch 73/200, Iteration 107/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 108/250, Loss: 0.0275\n",
      "Epoch 73/200, Iteration 109/250, Loss: 0.0098\n",
      "Epoch 73/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 73/200, Iteration 111/250, Loss: 0.0182\n",
      "Epoch 73/200, Iteration 112/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 113/250, Loss: 0.0152\n",
      "Epoch 73/200, Iteration 114/250, Loss: 0.0076\n",
      "Epoch 73/200, Iteration 115/250, Loss: 0.0121\n",
      "Epoch 73/200, Iteration 116/250, Loss: 0.0083\n",
      "Epoch 73/200, Iteration 117/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 118/250, Loss: 0.0164\n",
      "Epoch 73/200, Iteration 119/250, Loss: 0.0110\n",
      "Epoch 73/200, Iteration 120/250, Loss: 0.0275\n",
      "Epoch 73/200, Iteration 121/250, Loss: 0.0200\n",
      "Epoch 73/200, Iteration 122/250, Loss: 0.0200\n",
      "Epoch 73/200, Iteration 123/250, Loss: 0.0222\n",
      "Epoch 73/200, Iteration 124/250, Loss: 0.0188\n",
      "Epoch 73/200, Iteration 125/250, Loss: 0.0154\n",
      "Epoch 73/200, Iteration 126/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 127/250, Loss: 0.0125\n",
      "Epoch 73/200, Iteration 128/250, Loss: 0.0182\n",
      "Epoch 73/200, Iteration 129/250, Loss: 0.0141\n",
      "Epoch 73/200, Iteration 130/250, Loss: 0.0146\n",
      "Epoch 73/200, Iteration 131/250, Loss: 0.0154\n",
      "Epoch 73/200, Iteration 132/250, Loss: 0.0115\n",
      "Epoch 73/200, Iteration 133/250, Loss: 0.0112\n",
      "Epoch 73/200, Iteration 134/250, Loss: 0.0126\n",
      "Epoch 73/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 73/200, Iteration 136/250, Loss: 0.0062\n",
      "Epoch 73/200, Iteration 137/250, Loss: 0.0140\n",
      "Epoch 73/200, Iteration 138/250, Loss: 0.0156\n",
      "Epoch 73/200, Iteration 139/250, Loss: 0.0184\n",
      "Epoch 73/200, Iteration 140/250, Loss: 0.0145\n",
      "Epoch 73/200, Iteration 141/250, Loss: 0.0382\n",
      "Epoch 73/200, Iteration 142/250, Loss: 0.0289\n",
      "Epoch 73/200, Iteration 143/250, Loss: 0.0093\n",
      "Epoch 73/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 145/250, Loss: 0.0116\n",
      "Epoch 73/200, Iteration 146/250, Loss: 0.0208\n",
      "Epoch 73/200, Iteration 147/250, Loss: 0.0145\n",
      "Epoch 73/200, Iteration 148/250, Loss: 0.0178\n",
      "Epoch 73/200, Iteration 149/250, Loss: 0.0097\n",
      "Epoch 73/200, Iteration 150/250, Loss: 0.0241\n",
      "Epoch 73/200, Iteration 151/250, Loss: 0.0287\n",
      "Epoch 73/200, Iteration 152/250, Loss: 0.0064\n",
      "Epoch 73/200, Iteration 153/250, Loss: 0.0111\n",
      "Epoch 73/200, Iteration 154/250, Loss: 0.0179\n",
      "Epoch 73/200, Iteration 155/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Iteration 156/250, Loss: 0.0112\n",
      "Epoch 73/200, Iteration 157/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 158/250, Loss: 0.0110\n",
      "Epoch 73/200, Iteration 159/250, Loss: 0.0073\n",
      "Epoch 73/200, Iteration 160/250, Loss: 0.0223\n",
      "Epoch 73/200, Iteration 161/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 162/250, Loss: 0.0191\n",
      "Epoch 73/200, Iteration 163/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 164/250, Loss: 0.0422\n",
      "Epoch 73/200, Iteration 165/250, Loss: 0.0135\n",
      "Epoch 73/200, Iteration 166/250, Loss: 0.0092\n",
      "Epoch 73/200, Iteration 167/250, Loss: 0.0117\n",
      "Epoch 73/200, Iteration 168/250, Loss: 0.0121\n",
      "Epoch 73/200, Iteration 169/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 170/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 171/250, Loss: 0.0192\n",
      "Epoch 73/200, Iteration 172/250, Loss: 0.0114\n",
      "Epoch 73/200, Iteration 173/250, Loss: 0.0067\n",
      "Epoch 73/200, Iteration 174/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 175/250, Loss: 0.0258\n",
      "Epoch 73/200, Iteration 176/250, Loss: 0.0252\n",
      "Epoch 73/200, Iteration 177/250, Loss: 0.0166\n",
      "Epoch 73/200, Iteration 178/250, Loss: 0.0144\n",
      "Epoch 73/200, Iteration 179/250, Loss: 0.0156\n",
      "Epoch 73/200, Iteration 180/250, Loss: 0.0081\n",
      "Epoch 73/200, Iteration 181/250, Loss: 0.0180\n",
      "Epoch 73/200, Iteration 182/250, Loss: 0.0135\n",
      "Epoch 73/200, Iteration 183/250, Loss: 0.0165\n",
      "Epoch 73/200, Iteration 184/250, Loss: 0.0175\n",
      "Epoch 73/200, Iteration 185/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 186/250, Loss: 0.0252\n",
      "Epoch 73/200, Iteration 187/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 188/250, Loss: 0.0082\n",
      "Epoch 73/200, Iteration 189/250, Loss: 0.0266\n",
      "Epoch 73/200, Iteration 190/250, Loss: 0.0122\n",
      "Epoch 73/200, Iteration 191/250, Loss: 0.0118\n",
      "Epoch 73/200, Iteration 192/250, Loss: 0.0092\n",
      "Epoch 73/200, Iteration 193/250, Loss: 0.0324\n",
      "Epoch 73/200, Iteration 194/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 195/250, Loss: 0.0230\n",
      "Epoch 73/200, Iteration 196/250, Loss: 0.0093\n",
      "Epoch 73/200, Iteration 197/250, Loss: 0.0124\n",
      "Epoch 73/200, Iteration 198/250, Loss: 0.0149\n",
      "Epoch 73/200, Iteration 199/250, Loss: 0.0406\n",
      "Epoch 73/200, Iteration 200/250, Loss: 0.0073\n",
      "Epoch 73/200, Iteration 201/250, Loss: 0.0231\n",
      "Epoch 73/200, Iteration 202/250, Loss: 0.0105\n",
      "Epoch 73/200, Iteration 203/250, Loss: 0.0240\n",
      "Epoch 73/200, Iteration 204/250, Loss: 0.0119\n",
      "Epoch 73/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 73/200, Iteration 206/250, Loss: 0.0143\n",
      "Epoch 73/200, Iteration 207/250, Loss: 0.0285\n",
      "Epoch 73/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 73/200, Iteration 209/250, Loss: 0.0197\n",
      "Epoch 73/200, Iteration 210/250, Loss: 0.0244\n",
      "Epoch 73/200, Iteration 211/250, Loss: 0.0168\n",
      "Epoch 73/200, Iteration 212/250, Loss: 0.0291\n",
      "Epoch 73/200, Iteration 213/250, Loss: 0.0153\n",
      "Epoch 73/200, Iteration 214/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 215/250, Loss: 0.0283\n",
      "Epoch 73/200, Iteration 216/250, Loss: 0.0064\n",
      "Epoch 73/200, Iteration 217/250, Loss: 0.0182\n",
      "Epoch 73/200, Iteration 218/250, Loss: 0.0129\n",
      "Epoch 73/200, Iteration 219/250, Loss: 0.0113\n",
      "Epoch 73/200, Iteration 220/250, Loss: 0.0229\n",
      "Epoch 73/200, Iteration 221/250, Loss: 0.0096\n",
      "Epoch 73/200, Iteration 222/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 223/250, Loss: 0.0151\n",
      "Epoch 73/200, Iteration 224/250, Loss: 0.0170\n",
      "Epoch 73/200, Iteration 225/250, Loss: 0.0134\n",
      "Epoch 73/200, Iteration 226/250, Loss: 0.0084\n",
      "Epoch 73/200, Iteration 227/250, Loss: 0.0134\n",
      "Epoch 73/200, Iteration 228/250, Loss: 0.0132\n",
      "Epoch 73/200, Iteration 229/250, Loss: 0.0083\n",
      "Epoch 73/200, Iteration 230/250, Loss: 0.0107\n",
      "Epoch 73/200, Iteration 231/250, Loss: 0.0151\n",
      "Epoch 73/200, Iteration 232/250, Loss: 0.0112\n",
      "Epoch 73/200, Iteration 233/250, Loss: 0.0084\n",
      "Epoch 73/200, Iteration 234/250, Loss: 0.0251\n",
      "Epoch 73/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 73/200, Iteration 236/250, Loss: 0.0114\n",
      "Epoch 73/200, Iteration 237/250, Loss: 0.0216\n",
      "Epoch 73/200, Iteration 238/250, Loss: 0.0131\n",
      "Epoch 73/200, Iteration 239/250, Loss: 0.0101\n",
      "Epoch 73/200, Iteration 240/250, Loss: 0.0125\n",
      "Epoch 73/200, Iteration 241/250, Loss: 0.0297\n",
      "Epoch 73/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 73/200, Iteration 243/250, Loss: 0.0173\n",
      "Epoch 73/200, Iteration 244/250, Loss: 0.0086\n",
      "Epoch 73/200, Iteration 245/250, Loss: 0.0103\n",
      "Epoch 73/200, Iteration 246/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 247/250, Loss: 0.0192\n",
      "Epoch 73/200, Iteration 248/250, Loss: 0.0095\n",
      "Epoch 73/200, Iteration 249/250, Loss: 0.0088\n",
      "Epoch 73/200, Iteration 250/250, Loss: 0.0209\n",
      "Train Error: \n",
      " Accuracy: 94.71%, Avg loss: 0.008037, MRE: 0.543711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.15%, Avg loss: 0.008696, MRE: 0.646525 \n",
      "\n",
      "Epoch 74/200, Iteration 1/250, Loss: 0.0202\n",
      "Epoch 74/200, Iteration 2/250, Loss: 0.0211\n",
      "Epoch 74/200, Iteration 3/250, Loss: 0.0095\n",
      "Epoch 74/200, Iteration 4/250, Loss: 0.0201\n",
      "Epoch 74/200, Iteration 5/250, Loss: 0.0110\n",
      "Epoch 74/200, Iteration 6/250, Loss: 0.0126\n",
      "Epoch 74/200, Iteration 7/250, Loss: 0.0261\n",
      "Epoch 74/200, Iteration 8/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 9/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 10/250, Loss: 0.0207\n",
      "Epoch 74/200, Iteration 11/250, Loss: 0.0187\n",
      "Epoch 74/200, Iteration 12/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 13/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 14/250, Loss: 0.0182\n",
      "Epoch 74/200, Iteration 15/250, Loss: 0.0230\n",
      "Epoch 74/200, Iteration 16/250, Loss: 0.0150\n",
      "Epoch 74/200, Iteration 17/250, Loss: 0.0298\n",
      "Epoch 74/200, Iteration 18/250, Loss: 0.0277\n",
      "Epoch 74/200, Iteration 19/250, Loss: 0.0105\n",
      "Epoch 74/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 74/200, Iteration 21/250, Loss: 0.0091\n",
      "Epoch 74/200, Iteration 22/250, Loss: 0.0329\n",
      "Epoch 74/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 24/250, Loss: 0.0195\n",
      "Epoch 74/200, Iteration 25/250, Loss: 0.0187\n",
      "Epoch 74/200, Iteration 26/250, Loss: 0.0280\n",
      "Epoch 74/200, Iteration 27/250, Loss: 0.0130\n",
      "Epoch 74/200, Iteration 28/250, Loss: 0.0195\n",
      "Epoch 74/200, Iteration 29/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 30/250, Loss: 0.0149\n",
      "Epoch 74/200, Iteration 31/250, Loss: 0.0181\n",
      "Epoch 74/200, Iteration 32/250, Loss: 0.0092\n",
      "Epoch 74/200, Iteration 33/250, Loss: 0.0149\n",
      "Epoch 74/200, Iteration 34/250, Loss: 0.0086\n",
      "Epoch 74/200, Iteration 35/250, Loss: 0.0137\n",
      "Epoch 74/200, Iteration 36/250, Loss: 0.0118\n",
      "Epoch 74/200, Iteration 37/250, Loss: 0.0241\n",
      "Epoch 74/200, Iteration 38/250, Loss: 0.0091\n",
      "Epoch 74/200, Iteration 39/250, Loss: 0.0121\n",
      "Epoch 74/200, Iteration 40/250, Loss: 0.0084\n",
      "Epoch 74/200, Iteration 41/250, Loss: 0.0145\n",
      "Epoch 74/200, Iteration 42/250, Loss: 0.0073\n",
      "Epoch 74/200, Iteration 43/250, Loss: 0.0147\n",
      "Epoch 74/200, Iteration 44/250, Loss: 0.0131\n",
      "Epoch 74/200, Iteration 45/250, Loss: 0.0156\n",
      "Epoch 74/200, Iteration 46/250, Loss: 0.0130\n",
      "Epoch 74/200, Iteration 47/250, Loss: 0.0167\n",
      "Epoch 74/200, Iteration 48/250, Loss: 0.0128\n",
      "Epoch 74/200, Iteration 49/250, Loss: 0.0174\n",
      "Epoch 74/200, Iteration 50/250, Loss: 0.0175\n",
      "Epoch 74/200, Iteration 51/250, Loss: 0.0165\n",
      "Epoch 74/200, Iteration 52/250, Loss: 0.0143\n",
      "Epoch 74/200, Iteration 53/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 54/250, Loss: 0.0129\n",
      "Epoch 74/200, Iteration 55/250, Loss: 0.0088\n",
      "Epoch 74/200, Iteration 56/250, Loss: 0.0291\n",
      "Epoch 74/200, Iteration 57/250, Loss: 0.0176\n",
      "Epoch 74/200, Iteration 58/250, Loss: 0.0324\n",
      "Epoch 74/200, Iteration 59/250, Loss: 0.0123\n",
      "Epoch 74/200, Iteration 60/250, Loss: 0.0349\n",
      "Epoch 74/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 74/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 74/200, Iteration 63/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 74/200, Iteration 65/250, Loss: 0.0073\n",
      "Epoch 74/200, Iteration 66/250, Loss: 0.0200\n",
      "Epoch 74/200, Iteration 67/250, Loss: 0.0150\n",
      "Epoch 74/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 74/200, Iteration 69/250, Loss: 0.0397\n",
      "Epoch 74/200, Iteration 70/250, Loss: 0.0112\n",
      "Epoch 74/200, Iteration 71/250, Loss: 0.0193\n",
      "Epoch 74/200, Iteration 72/250, Loss: 0.0164\n",
      "Epoch 74/200, Iteration 73/250, Loss: 0.0261\n",
      "Epoch 74/200, Iteration 74/250, Loss: 0.0096\n",
      "Epoch 74/200, Iteration 75/250, Loss: 0.0090\n",
      "Epoch 74/200, Iteration 76/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 77/250, Loss: 0.0341\n",
      "Epoch 74/200, Iteration 78/250, Loss: 0.0348\n",
      "Epoch 74/200, Iteration 79/250, Loss: 0.0213\n",
      "Epoch 74/200, Iteration 80/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 81/250, Loss: 0.0185\n",
      "Epoch 74/200, Iteration 82/250, Loss: 0.0067\n",
      "Epoch 74/200, Iteration 83/250, Loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200, Iteration 84/250, Loss: 0.0112\n",
      "Epoch 74/200, Iteration 85/250, Loss: 0.0138\n",
      "Epoch 74/200, Iteration 86/250, Loss: 0.0079\n",
      "Epoch 74/200, Iteration 87/250, Loss: 0.0136\n",
      "Epoch 74/200, Iteration 88/250, Loss: 0.0065\n",
      "Epoch 74/200, Iteration 89/250, Loss: 0.0339\n",
      "Epoch 74/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 91/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 92/250, Loss: 0.0076\n",
      "Epoch 74/200, Iteration 93/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 94/250, Loss: 0.0138\n",
      "Epoch 74/200, Iteration 95/250, Loss: 0.0083\n",
      "Epoch 74/200, Iteration 96/250, Loss: 0.0381\n",
      "Epoch 74/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 98/250, Loss: 0.0103\n",
      "Epoch 74/200, Iteration 99/250, Loss: 0.0124\n",
      "Epoch 74/200, Iteration 100/250, Loss: 0.0090\n",
      "Epoch 74/200, Iteration 101/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 102/250, Loss: 0.0169\n",
      "Epoch 74/200, Iteration 103/250, Loss: 0.0170\n",
      "Epoch 74/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 74/200, Iteration 105/250, Loss: 0.0167\n",
      "Epoch 74/200, Iteration 106/250, Loss: 0.0241\n",
      "Epoch 74/200, Iteration 107/250, Loss: 0.0155\n",
      "Epoch 74/200, Iteration 108/250, Loss: 0.0218\n",
      "Epoch 74/200, Iteration 109/250, Loss: 0.0233\n",
      "Epoch 74/200, Iteration 110/250, Loss: 0.0157\n",
      "Epoch 74/200, Iteration 111/250, Loss: 0.0093\n",
      "Epoch 74/200, Iteration 112/250, Loss: 0.0154\n",
      "Epoch 74/200, Iteration 113/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 114/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 115/250, Loss: 0.0223\n",
      "Epoch 74/200, Iteration 116/250, Loss: 0.0186\n",
      "Epoch 74/200, Iteration 117/250, Loss: 0.0178\n",
      "Epoch 74/200, Iteration 118/250, Loss: 0.0172\n",
      "Epoch 74/200, Iteration 119/250, Loss: 0.0077\n",
      "Epoch 74/200, Iteration 120/250, Loss: 0.0093\n",
      "Epoch 74/200, Iteration 121/250, Loss: 0.0225\n",
      "Epoch 74/200, Iteration 122/250, Loss: 0.0155\n",
      "Epoch 74/200, Iteration 123/250, Loss: 0.0115\n",
      "Epoch 74/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 125/250, Loss: 0.0226\n",
      "Epoch 74/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 74/200, Iteration 127/250, Loss: 0.0096\n",
      "Epoch 74/200, Iteration 128/250, Loss: 0.0214\n",
      "Epoch 74/200, Iteration 129/250, Loss: 0.0074\n",
      "Epoch 74/200, Iteration 130/250, Loss: 0.0160\n",
      "Epoch 74/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 132/250, Loss: 0.0115\n",
      "Epoch 74/200, Iteration 133/250, Loss: 0.0385\n",
      "Epoch 74/200, Iteration 134/250, Loss: 0.0241\n",
      "Epoch 74/200, Iteration 135/250, Loss: 0.0133\n",
      "Epoch 74/200, Iteration 136/250, Loss: 0.0145\n",
      "Epoch 74/200, Iteration 137/250, Loss: 0.0120\n",
      "Epoch 74/200, Iteration 138/250, Loss: 0.0146\n",
      "Epoch 74/200, Iteration 139/250, Loss: 0.0091\n",
      "Epoch 74/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 74/200, Iteration 141/250, Loss: 0.0125\n",
      "Epoch 74/200, Iteration 142/250, Loss: 0.0186\n",
      "Epoch 74/200, Iteration 143/250, Loss: 0.0113\n",
      "Epoch 74/200, Iteration 144/250, Loss: 0.0096\n",
      "Epoch 74/200, Iteration 145/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 146/250, Loss: 0.0116\n",
      "Epoch 74/200, Iteration 147/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 148/250, Loss: 0.0127\n",
      "Epoch 74/200, Iteration 149/250, Loss: 0.0104\n",
      "Epoch 74/200, Iteration 150/250, Loss: 0.0138\n",
      "Epoch 74/200, Iteration 151/250, Loss: 0.0232\n",
      "Epoch 74/200, Iteration 152/250, Loss: 0.0079\n",
      "Epoch 74/200, Iteration 153/250, Loss: 0.0222\n",
      "Epoch 74/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 74/200, Iteration 155/250, Loss: 0.0125\n",
      "Epoch 74/200, Iteration 156/250, Loss: 0.0069\n",
      "Epoch 74/200, Iteration 157/250, Loss: 0.0112\n",
      "Epoch 74/200, Iteration 158/250, Loss: 0.0209\n",
      "Epoch 74/200, Iteration 159/250, Loss: 0.0263\n",
      "Epoch 74/200, Iteration 160/250, Loss: 0.0272\n",
      "Epoch 74/200, Iteration 161/250, Loss: 0.0205\n",
      "Epoch 74/200, Iteration 162/250, Loss: 0.0109\n",
      "Epoch 74/200, Iteration 163/250, Loss: 0.0276\n",
      "Epoch 74/200, Iteration 164/250, Loss: 0.0100\n",
      "Epoch 74/200, Iteration 165/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 166/250, Loss: 0.0186\n",
      "Epoch 74/200, Iteration 167/250, Loss: 0.0144\n",
      "Epoch 74/200, Iteration 168/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 169/250, Loss: 0.0068\n",
      "Epoch 74/200, Iteration 170/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 172/250, Loss: 0.0227\n",
      "Epoch 74/200, Iteration 173/250, Loss: 0.0181\n",
      "Epoch 74/200, Iteration 174/250, Loss: 0.0126\n",
      "Epoch 74/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 176/250, Loss: 0.0122\n",
      "Epoch 74/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 74/200, Iteration 178/250, Loss: 0.0102\n",
      "Epoch 74/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 180/250, Loss: 0.0234\n",
      "Epoch 74/200, Iteration 181/250, Loss: 0.0072\n",
      "Epoch 74/200, Iteration 182/250, Loss: 0.0147\n",
      "Epoch 74/200, Iteration 183/250, Loss: 0.0270\n",
      "Epoch 74/200, Iteration 184/250, Loss: 0.0228\n",
      "Epoch 74/200, Iteration 185/250, Loss: 0.0263\n",
      "Epoch 74/200, Iteration 186/250, Loss: 0.0193\n",
      "Epoch 74/200, Iteration 187/250, Loss: 0.0104\n",
      "Epoch 74/200, Iteration 188/250, Loss: 0.0082\n",
      "Epoch 74/200, Iteration 189/250, Loss: 0.0073\n",
      "Epoch 74/200, Iteration 190/250, Loss: 0.0146\n",
      "Epoch 74/200, Iteration 191/250, Loss: 0.0112\n",
      "Epoch 74/200, Iteration 192/250, Loss: 0.0117\n",
      "Epoch 74/200, Iteration 193/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 194/250, Loss: 0.0342\n",
      "Epoch 74/200, Iteration 195/250, Loss: 0.0105\n",
      "Epoch 74/200, Iteration 196/250, Loss: 0.0171\n",
      "Epoch 74/200, Iteration 197/250, Loss: 0.0254\n",
      "Epoch 74/200, Iteration 198/250, Loss: 0.0117\n",
      "Epoch 74/200, Iteration 199/250, Loss: 0.0179\n",
      "Epoch 74/200, Iteration 200/250, Loss: 0.0120\n",
      "Epoch 74/200, Iteration 201/250, Loss: 0.0277\n",
      "Epoch 74/200, Iteration 202/250, Loss: 0.0121\n",
      "Epoch 74/200, Iteration 203/250, Loss: 0.0115\n",
      "Epoch 74/200, Iteration 204/250, Loss: 0.0268\n",
      "Epoch 74/200, Iteration 205/250, Loss: 0.0089\n",
      "Epoch 74/200, Iteration 206/250, Loss: 0.0307\n",
      "Epoch 74/200, Iteration 207/250, Loss: 0.0342\n",
      "Epoch 74/200, Iteration 208/250, Loss: 0.0096\n",
      "Epoch 74/200, Iteration 209/250, Loss: 0.0206\n",
      "Epoch 74/200, Iteration 210/250, Loss: 0.0098\n",
      "Epoch 74/200, Iteration 211/250, Loss: 0.0148\n",
      "Epoch 74/200, Iteration 212/250, Loss: 0.0133\n",
      "Epoch 74/200, Iteration 213/250, Loss: 0.0470\n",
      "Epoch 74/200, Iteration 214/250, Loss: 0.0085\n",
      "Epoch 74/200, Iteration 215/250, Loss: 0.0108\n",
      "Epoch 74/200, Iteration 216/250, Loss: 0.0315\n",
      "Epoch 74/200, Iteration 217/250, Loss: 0.0147\n",
      "Epoch 74/200, Iteration 218/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 219/250, Loss: 0.0150\n",
      "Epoch 74/200, Iteration 220/250, Loss: 0.0086\n",
      "Epoch 74/200, Iteration 221/250, Loss: 0.0119\n",
      "Epoch 74/200, Iteration 222/250, Loss: 0.0467\n",
      "Epoch 74/200, Iteration 223/250, Loss: 0.0100\n",
      "Epoch 74/200, Iteration 224/250, Loss: 0.0149\n",
      "Epoch 74/200, Iteration 225/250, Loss: 0.0077\n",
      "Epoch 74/200, Iteration 226/250, Loss: 0.0104\n",
      "Epoch 74/200, Iteration 227/250, Loss: 0.0080\n",
      "Epoch 74/200, Iteration 228/250, Loss: 0.0120\n",
      "Epoch 74/200, Iteration 229/250, Loss: 0.0205\n",
      "Epoch 74/200, Iteration 230/250, Loss: 0.0099\n",
      "Epoch 74/200, Iteration 231/250, Loss: 0.0130\n",
      "Epoch 74/200, Iteration 232/250, Loss: 0.0106\n",
      "Epoch 74/200, Iteration 233/250, Loss: 0.0213\n",
      "Epoch 74/200, Iteration 234/250, Loss: 0.0201\n",
      "Epoch 74/200, Iteration 235/250, Loss: 0.0219\n",
      "Epoch 74/200, Iteration 236/250, Loss: 0.0107\n",
      "Epoch 74/200, Iteration 237/250, Loss: 0.0219\n",
      "Epoch 74/200, Iteration 238/250, Loss: 0.0239\n",
      "Epoch 74/200, Iteration 239/250, Loss: 0.0094\n",
      "Epoch 74/200, Iteration 240/250, Loss: 0.0111\n",
      "Epoch 74/200, Iteration 241/250, Loss: 0.0153\n",
      "Epoch 74/200, Iteration 242/250, Loss: 0.0097\n",
      "Epoch 74/200, Iteration 243/250, Loss: 0.0143\n",
      "Epoch 74/200, Iteration 244/250, Loss: 0.0067\n",
      "Epoch 74/200, Iteration 245/250, Loss: 0.0132\n",
      "Epoch 74/200, Iteration 246/250, Loss: 0.0115\n",
      "Epoch 74/200, Iteration 247/250, Loss: 0.0080\n",
      "Epoch 74/200, Iteration 248/250, Loss: 0.0219\n",
      "Epoch 74/200, Iteration 249/250, Loss: 0.0119\n",
      "Epoch 74/200, Iteration 250/250, Loss: 0.0323\n",
      "Train Error: \n",
      " Accuracy: 95.38%, Avg loss: 0.008190, MRE: 0.516459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.15%, Avg loss: 0.008777, MRE: 0.620387 \n",
      "\n",
      "Epoch 75/200, Iteration 1/250, Loss: 0.0183\n",
      "Epoch 75/200, Iteration 2/250, Loss: 0.0077\n",
      "Epoch 75/200, Iteration 3/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 4/250, Loss: 0.0198\n",
      "Epoch 75/200, Iteration 5/250, Loss: 0.0169\n",
      "Epoch 75/200, Iteration 6/250, Loss: 0.0207\n",
      "Epoch 75/200, Iteration 7/250, Loss: 0.0194\n",
      "Epoch 75/200, Iteration 8/250, Loss: 0.0206\n",
      "Epoch 75/200, Iteration 9/250, Loss: 0.0207\n",
      "Epoch 75/200, Iteration 10/250, Loss: 0.0090\n",
      "Epoch 75/200, Iteration 11/250, Loss: 0.0152\n",
      "Epoch 75/200, Iteration 12/250, Loss: 0.0112\n",
      "Epoch 75/200, Iteration 13/250, Loss: 0.0156\n",
      "Epoch 75/200, Iteration 14/250, Loss: 0.0198\n",
      "Epoch 75/200, Iteration 15/250, Loss: 0.0095\n",
      "Epoch 75/200, Iteration 16/250, Loss: 0.0100\n",
      "Epoch 75/200, Iteration 17/250, Loss: 0.0131\n",
      "Epoch 75/200, Iteration 18/250, Loss: 0.0143\n",
      "Epoch 75/200, Iteration 19/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 20/250, Loss: 0.0296\n",
      "Epoch 75/200, Iteration 21/250, Loss: 0.0202\n",
      "Epoch 75/200, Iteration 22/250, Loss: 0.0193\n",
      "Epoch 75/200, Iteration 23/250, Loss: 0.0123\n",
      "Epoch 75/200, Iteration 24/250, Loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Iteration 25/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 26/250, Loss: 0.0163\n",
      "Epoch 75/200, Iteration 27/250, Loss: 0.0125\n",
      "Epoch 75/200, Iteration 28/250, Loss: 0.0113\n",
      "Epoch 75/200, Iteration 29/250, Loss: 0.0147\n",
      "Epoch 75/200, Iteration 30/250, Loss: 0.0069\n",
      "Epoch 75/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 75/200, Iteration 32/250, Loss: 0.0097\n",
      "Epoch 75/200, Iteration 33/250, Loss: 0.0123\n",
      "Epoch 75/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 75/200, Iteration 35/250, Loss: 0.0111\n",
      "Epoch 75/200, Iteration 36/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 37/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 38/250, Loss: 0.0261\n",
      "Epoch 75/200, Iteration 39/250, Loss: 0.0159\n",
      "Epoch 75/200, Iteration 40/250, Loss: 0.0069\n",
      "Epoch 75/200, Iteration 41/250, Loss: 0.0191\n",
      "Epoch 75/200, Iteration 42/250, Loss: 0.0210\n",
      "Epoch 75/200, Iteration 43/250, Loss: 0.0078\n",
      "Epoch 75/200, Iteration 44/250, Loss: 0.0183\n",
      "Epoch 75/200, Iteration 45/250, Loss: 0.0162\n",
      "Epoch 75/200, Iteration 46/250, Loss: 0.0184\n",
      "Epoch 75/200, Iteration 47/250, Loss: 0.0506\n",
      "Epoch 75/200, Iteration 48/250, Loss: 0.0178\n",
      "Epoch 75/200, Iteration 49/250, Loss: 0.0138\n",
      "Epoch 75/200, Iteration 50/250, Loss: 0.0236\n",
      "Epoch 75/200, Iteration 51/250, Loss: 0.0182\n",
      "Epoch 75/200, Iteration 52/250, Loss: 0.0233\n",
      "Epoch 75/200, Iteration 53/250, Loss: 0.0219\n",
      "Epoch 75/200, Iteration 54/250, Loss: 0.0214\n",
      "Epoch 75/200, Iteration 55/250, Loss: 0.0077\n",
      "Epoch 75/200, Iteration 56/250, Loss: 0.0135\n",
      "Epoch 75/200, Iteration 57/250, Loss: 0.0097\n",
      "Epoch 75/200, Iteration 58/250, Loss: 0.0072\n",
      "Epoch 75/200, Iteration 59/250, Loss: 0.0136\n",
      "Epoch 75/200, Iteration 60/250, Loss: 0.0288\n",
      "Epoch 75/200, Iteration 61/250, Loss: 0.0075\n",
      "Epoch 75/200, Iteration 62/250, Loss: 0.0250\n",
      "Epoch 75/200, Iteration 63/250, Loss: 0.0245\n",
      "Epoch 75/200, Iteration 64/250, Loss: 0.0186\n",
      "Epoch 75/200, Iteration 65/250, Loss: 0.0105\n",
      "Epoch 75/200, Iteration 66/250, Loss: 0.0135\n",
      "Epoch 75/200, Iteration 67/250, Loss: 0.0153\n",
      "Epoch 75/200, Iteration 68/250, Loss: 0.0091\n",
      "Epoch 75/200, Iteration 69/250, Loss: 0.0230\n",
      "Epoch 75/200, Iteration 70/250, Loss: 0.0210\n",
      "Epoch 75/200, Iteration 71/250, Loss: 0.0172\n",
      "Epoch 75/200, Iteration 72/250, Loss: 0.0177\n",
      "Epoch 75/200, Iteration 73/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 74/250, Loss: 0.0262\n",
      "Epoch 75/200, Iteration 75/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 76/250, Loss: 0.0077\n",
      "Epoch 75/200, Iteration 77/250, Loss: 0.0180\n",
      "Epoch 75/200, Iteration 78/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 79/250, Loss: 0.0296\n",
      "Epoch 75/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 75/200, Iteration 81/250, Loss: 0.0084\n",
      "Epoch 75/200, Iteration 82/250, Loss: 0.0108\n",
      "Epoch 75/200, Iteration 83/250, Loss: 0.0086\n",
      "Epoch 75/200, Iteration 84/250, Loss: 0.0289\n",
      "Epoch 75/200, Iteration 85/250, Loss: 0.0145\n",
      "Epoch 75/200, Iteration 86/250, Loss: 0.0198\n",
      "Epoch 75/200, Iteration 87/250, Loss: 0.0201\n",
      "Epoch 75/200, Iteration 88/250, Loss: 0.0173\n",
      "Epoch 75/200, Iteration 89/250, Loss: 0.0118\n",
      "Epoch 75/200, Iteration 90/250, Loss: 0.0092\n",
      "Epoch 75/200, Iteration 91/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 92/250, Loss: 0.0210\n",
      "Epoch 75/200, Iteration 93/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 94/250, Loss: 0.0124\n",
      "Epoch 75/200, Iteration 95/250, Loss: 0.0087\n",
      "Epoch 75/200, Iteration 96/250, Loss: 0.0189\n",
      "Epoch 75/200, Iteration 97/250, Loss: 0.0120\n",
      "Epoch 75/200, Iteration 98/250, Loss: 0.0084\n",
      "Epoch 75/200, Iteration 99/250, Loss: 0.0286\n",
      "Epoch 75/200, Iteration 100/250, Loss: 0.0302\n",
      "Epoch 75/200, Iteration 101/250, Loss: 0.0134\n",
      "Epoch 75/200, Iteration 102/250, Loss: 0.0104\n",
      "Epoch 75/200, Iteration 103/250, Loss: 0.0273\n",
      "Epoch 75/200, Iteration 104/250, Loss: 0.0226\n",
      "Epoch 75/200, Iteration 105/250, Loss: 0.0268\n",
      "Epoch 75/200, Iteration 106/250, Loss: 0.0076\n",
      "Epoch 75/200, Iteration 107/250, Loss: 0.0075\n",
      "Epoch 75/200, Iteration 108/250, Loss: 0.0093\n",
      "Epoch 75/200, Iteration 109/250, Loss: 0.0096\n",
      "Epoch 75/200, Iteration 110/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 111/250, Loss: 0.0198\n",
      "Epoch 75/200, Iteration 112/250, Loss: 0.0081\n",
      "Epoch 75/200, Iteration 113/250, Loss: 0.0062\n",
      "Epoch 75/200, Iteration 114/250, Loss: 0.0063\n",
      "Epoch 75/200, Iteration 115/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 116/250, Loss: 0.0176\n",
      "Epoch 75/200, Iteration 117/250, Loss: 0.0319\n",
      "Epoch 75/200, Iteration 118/250, Loss: 0.0131\n",
      "Epoch 75/200, Iteration 119/250, Loss: 0.0128\n",
      "Epoch 75/200, Iteration 120/250, Loss: 0.0074\n",
      "Epoch 75/200, Iteration 121/250, Loss: 0.0166\n",
      "Epoch 75/200, Iteration 122/250, Loss: 0.0072\n",
      "Epoch 75/200, Iteration 123/250, Loss: 0.0192\n",
      "Epoch 75/200, Iteration 124/250, Loss: 0.0138\n",
      "Epoch 75/200, Iteration 125/250, Loss: 0.0251\n",
      "Epoch 75/200, Iteration 126/250, Loss: 0.0110\n",
      "Epoch 75/200, Iteration 127/250, Loss: 0.0091\n",
      "Epoch 75/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 75/200, Iteration 129/250, Loss: 0.0220\n",
      "Epoch 75/200, Iteration 130/250, Loss: 0.0131\n",
      "Epoch 75/200, Iteration 131/250, Loss: 0.0106\n",
      "Epoch 75/200, Iteration 132/250, Loss: 0.0140\n",
      "Epoch 75/200, Iteration 133/250, Loss: 0.0093\n",
      "Epoch 75/200, Iteration 134/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 135/250, Loss: 0.0113\n",
      "Epoch 75/200, Iteration 136/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 137/250, Loss: 0.0072\n",
      "Epoch 75/200, Iteration 138/250, Loss: 0.0278\n",
      "Epoch 75/200, Iteration 139/250, Loss: 0.0090\n",
      "Epoch 75/200, Iteration 140/250, Loss: 0.0088\n",
      "Epoch 75/200, Iteration 141/250, Loss: 0.0096\n",
      "Epoch 75/200, Iteration 142/250, Loss: 0.0078\n",
      "Epoch 75/200, Iteration 143/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 144/250, Loss: 0.0090\n",
      "Epoch 75/200, Iteration 145/250, Loss: 0.0088\n",
      "Epoch 75/200, Iteration 146/250, Loss: 0.0164\n",
      "Epoch 75/200, Iteration 147/250, Loss: 0.0107\n",
      "Epoch 75/200, Iteration 148/250, Loss: 0.0252\n",
      "Epoch 75/200, Iteration 149/250, Loss: 0.0126\n",
      "Epoch 75/200, Iteration 150/250, Loss: 0.0136\n",
      "Epoch 75/200, Iteration 151/250, Loss: 0.0209\n",
      "Epoch 75/200, Iteration 152/250, Loss: 0.0079\n",
      "Epoch 75/200, Iteration 153/250, Loss: 0.0188\n",
      "Epoch 75/200, Iteration 154/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 155/250, Loss: 0.0080\n",
      "Epoch 75/200, Iteration 156/250, Loss: 0.0124\n",
      "Epoch 75/200, Iteration 157/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 158/250, Loss: 0.0074\n",
      "Epoch 75/200, Iteration 159/250, Loss: 0.0150\n",
      "Epoch 75/200, Iteration 160/250, Loss: 0.0201\n",
      "Epoch 75/200, Iteration 161/250, Loss: 0.0124\n",
      "Epoch 75/200, Iteration 162/250, Loss: 0.0229\n",
      "Epoch 75/200, Iteration 163/250, Loss: 0.0239\n",
      "Epoch 75/200, Iteration 164/250, Loss: 0.0122\n",
      "Epoch 75/200, Iteration 165/250, Loss: 0.0074\n",
      "Epoch 75/200, Iteration 166/250, Loss: 0.0137\n",
      "Epoch 75/200, Iteration 167/250, Loss: 0.0095\n",
      "Epoch 75/200, Iteration 168/250, Loss: 0.0289\n",
      "Epoch 75/200, Iteration 169/250, Loss: 0.0120\n",
      "Epoch 75/200, Iteration 170/250, Loss: 0.0191\n",
      "Epoch 75/200, Iteration 171/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 75/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 75/200, Iteration 175/250, Loss: 0.0139\n",
      "Epoch 75/200, Iteration 176/250, Loss: 0.0096\n",
      "Epoch 75/200, Iteration 177/250, Loss: 0.0218\n",
      "Epoch 75/200, Iteration 178/250, Loss: 0.0110\n",
      "Epoch 75/200, Iteration 179/250, Loss: 0.0069\n",
      "Epoch 75/200, Iteration 180/250, Loss: 0.0144\n",
      "Epoch 75/200, Iteration 181/250, Loss: 0.0217\n",
      "Epoch 75/200, Iteration 182/250, Loss: 0.0129\n",
      "Epoch 75/200, Iteration 183/250, Loss: 0.0091\n",
      "Epoch 75/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 75/200, Iteration 185/250, Loss: 0.0317\n",
      "Epoch 75/200, Iteration 186/250, Loss: 0.0176\n",
      "Epoch 75/200, Iteration 187/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 188/250, Loss: 0.0153\n",
      "Epoch 75/200, Iteration 189/250, Loss: 0.0142\n",
      "Epoch 75/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 75/200, Iteration 191/250, Loss: 0.0157\n",
      "Epoch 75/200, Iteration 192/250, Loss: 0.0308\n",
      "Epoch 75/200, Iteration 193/250, Loss: 0.0202\n",
      "Epoch 75/200, Iteration 194/250, Loss: 0.0422\n",
      "Epoch 75/200, Iteration 195/250, Loss: 0.0113\n",
      "Epoch 75/200, Iteration 196/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 197/250, Loss: 0.0067\n",
      "Epoch 75/200, Iteration 198/250, Loss: 0.0165\n",
      "Epoch 75/200, Iteration 199/250, Loss: 0.0419\n",
      "Epoch 75/200, Iteration 200/250, Loss: 0.0267\n",
      "Epoch 75/200, Iteration 201/250, Loss: 0.0178\n",
      "Epoch 75/200, Iteration 202/250, Loss: 0.0169\n",
      "Epoch 75/200, Iteration 203/250, Loss: 0.0131\n",
      "Epoch 75/200, Iteration 204/250, Loss: 0.0142\n",
      "Epoch 75/200, Iteration 205/250, Loss: 0.0056\n",
      "Epoch 75/200, Iteration 206/250, Loss: 0.0118\n",
      "Epoch 75/200, Iteration 207/250, Loss: 0.0207\n",
      "Epoch 75/200, Iteration 208/250, Loss: 0.0119\n",
      "Epoch 75/200, Iteration 209/250, Loss: 0.0094\n",
      "Epoch 75/200, Iteration 210/250, Loss: 0.0130\n",
      "Epoch 75/200, Iteration 211/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 212/250, Loss: 0.0096\n",
      "Epoch 75/200, Iteration 213/250, Loss: 0.0095\n",
      "Epoch 75/200, Iteration 214/250, Loss: 0.0143\n",
      "Epoch 75/200, Iteration 215/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 75/200, Iteration 217/250, Loss: 0.0112\n",
      "Epoch 75/200, Iteration 218/250, Loss: 0.0201\n",
      "Epoch 75/200, Iteration 219/250, Loss: 0.0133\n",
      "Epoch 75/200, Iteration 220/250, Loss: 0.0103\n",
      "Epoch 75/200, Iteration 221/250, Loss: 0.0110\n",
      "Epoch 75/200, Iteration 222/250, Loss: 0.0163\n",
      "Epoch 75/200, Iteration 223/250, Loss: 0.0090\n",
      "Epoch 75/200, Iteration 224/250, Loss: 0.0158\n",
      "Epoch 75/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 75/200, Iteration 226/250, Loss: 0.0529\n",
      "Epoch 75/200, Iteration 227/250, Loss: 0.0099\n",
      "Epoch 75/200, Iteration 228/250, Loss: 0.0098\n",
      "Epoch 75/200, Iteration 229/250, Loss: 0.0310\n",
      "Epoch 75/200, Iteration 230/250, Loss: 0.0201\n",
      "Epoch 75/200, Iteration 231/250, Loss: 0.0099\n",
      "Epoch 75/200, Iteration 232/250, Loss: 0.0213\n",
      "Epoch 75/200, Iteration 233/250, Loss: 0.0194\n",
      "Epoch 75/200, Iteration 234/250, Loss: 0.0109\n",
      "Epoch 75/200, Iteration 235/250, Loss: 0.0189\n",
      "Epoch 75/200, Iteration 236/250, Loss: 0.0450\n",
      "Epoch 75/200, Iteration 237/250, Loss: 0.0153\n",
      "Epoch 75/200, Iteration 238/250, Loss: 0.0113\n",
      "Epoch 75/200, Iteration 239/250, Loss: 0.0128\n",
      "Epoch 75/200, Iteration 240/250, Loss: 0.0122\n",
      "Epoch 75/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 75/200, Iteration 242/250, Loss: 0.0213\n",
      "Epoch 75/200, Iteration 243/250, Loss: 0.0077\n",
      "Epoch 75/200, Iteration 244/250, Loss: 0.0110\n",
      "Epoch 75/200, Iteration 245/250, Loss: 0.0106\n",
      "Epoch 75/200, Iteration 246/250, Loss: 0.0081\n",
      "Epoch 75/200, Iteration 247/250, Loss: 0.0087\n",
      "Epoch 75/200, Iteration 248/250, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Iteration 249/250, Loss: 0.0138\n",
      "Epoch 75/200, Iteration 250/250, Loss: 0.0111\n",
      "Train Error: \n",
      " Accuracy: 94.11%, Avg loss: 0.007274, MRE: 0.422945 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.05%, Avg loss: 0.007912, MRE: 0.500438 \n",
      "\n",
      "Epoch 76/200, Iteration 1/250, Loss: 0.0262\n",
      "Epoch 76/200, Iteration 2/250, Loss: 0.0077\n",
      "Epoch 76/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 76/200, Iteration 4/250, Loss: 0.0243\n",
      "Epoch 76/200, Iteration 5/250, Loss: 0.0245\n",
      "Epoch 76/200, Iteration 6/250, Loss: 0.0214\n",
      "Epoch 76/200, Iteration 7/250, Loss: 0.0099\n",
      "Epoch 76/200, Iteration 8/250, Loss: 0.0100\n",
      "Epoch 76/200, Iteration 9/250, Loss: 0.0314\n",
      "Epoch 76/200, Iteration 10/250, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 11/250, Loss: 0.0089\n",
      "Epoch 76/200, Iteration 12/250, Loss: 0.0095\n",
      "Epoch 76/200, Iteration 13/250, Loss: 0.0333\n",
      "Epoch 76/200, Iteration 14/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 15/250, Loss: 0.0346\n",
      "Epoch 76/200, Iteration 16/250, Loss: 0.0184\n",
      "Epoch 76/200, Iteration 17/250, Loss: 0.0092\n",
      "Epoch 76/200, Iteration 18/250, Loss: 0.0124\n",
      "Epoch 76/200, Iteration 19/250, Loss: 0.0135\n",
      "Epoch 76/200, Iteration 20/250, Loss: 0.0081\n",
      "Epoch 76/200, Iteration 21/250, Loss: 0.0087\n",
      "Epoch 76/200, Iteration 22/250, Loss: 0.0112\n",
      "Epoch 76/200, Iteration 23/250, Loss: 0.0108\n",
      "Epoch 76/200, Iteration 24/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 25/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 26/250, Loss: 0.0088\n",
      "Epoch 76/200, Iteration 27/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 28/250, Loss: 0.0297\n",
      "Epoch 76/200, Iteration 29/250, Loss: 0.0069\n",
      "Epoch 76/200, Iteration 30/250, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 31/250, Loss: 0.0085\n",
      "Epoch 76/200, Iteration 32/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 33/250, Loss: 0.0130\n",
      "Epoch 76/200, Iteration 34/250, Loss: 0.0096\n",
      "Epoch 76/200, Iteration 35/250, Loss: 0.0167\n",
      "Epoch 76/200, Iteration 36/250, Loss: 0.0113\n",
      "Epoch 76/200, Iteration 37/250, Loss: 0.0129\n",
      "Epoch 76/200, Iteration 38/250, Loss: 0.0367\n",
      "Epoch 76/200, Iteration 39/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 76/200, Iteration 41/250, Loss: 0.0345\n",
      "Epoch 76/200, Iteration 42/250, Loss: 0.0215\n",
      "Epoch 76/200, Iteration 43/250, Loss: 0.0121\n",
      "Epoch 76/200, Iteration 44/250, Loss: 0.0101\n",
      "Epoch 76/200, Iteration 45/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 46/250, Loss: 0.0150\n",
      "Epoch 76/200, Iteration 47/250, Loss: 0.0162\n",
      "Epoch 76/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 49/250, Loss: 0.0200\n",
      "Epoch 76/200, Iteration 50/250, Loss: 0.0153\n",
      "Epoch 76/200, Iteration 51/250, Loss: 0.0144\n",
      "Epoch 76/200, Iteration 52/250, Loss: 0.0195\n",
      "Epoch 76/200, Iteration 53/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 54/250, Loss: 0.0266\n",
      "Epoch 76/200, Iteration 55/250, Loss: 0.0083\n",
      "Epoch 76/200, Iteration 56/250, Loss: 0.0169\n",
      "Epoch 76/200, Iteration 57/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 58/250, Loss: 0.0124\n",
      "Epoch 76/200, Iteration 59/250, Loss: 0.0116\n",
      "Epoch 76/200, Iteration 60/250, Loss: 0.0178\n",
      "Epoch 76/200, Iteration 61/250, Loss: 0.0184\n",
      "Epoch 76/200, Iteration 62/250, Loss: 0.0239\n",
      "Epoch 76/200, Iteration 63/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 64/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 65/250, Loss: 0.0157\n",
      "Epoch 76/200, Iteration 66/250, Loss: 0.0088\n",
      "Epoch 76/200, Iteration 67/250, Loss: 0.0109\n",
      "Epoch 76/200, Iteration 68/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 69/250, Loss: 0.0288\n",
      "Epoch 76/200, Iteration 70/250, Loss: 0.0232\n",
      "Epoch 76/200, Iteration 71/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 72/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 73/250, Loss: 0.0171\n",
      "Epoch 76/200, Iteration 74/250, Loss: 0.0150\n",
      "Epoch 76/200, Iteration 75/250, Loss: 0.0283\n",
      "Epoch 76/200, Iteration 76/250, Loss: 0.0258\n",
      "Epoch 76/200, Iteration 77/250, Loss: 0.0142\n",
      "Epoch 76/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 76/200, Iteration 79/250, Loss: 0.0125\n",
      "Epoch 76/200, Iteration 80/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 81/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 82/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 83/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 84/250, Loss: 0.0280\n",
      "Epoch 76/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 76/200, Iteration 86/250, Loss: 0.0294\n",
      "Epoch 76/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 76/200, Iteration 88/250, Loss: 0.0204\n",
      "Epoch 76/200, Iteration 89/250, Loss: 0.0077\n",
      "Epoch 76/200, Iteration 90/250, Loss: 0.0077\n",
      "Epoch 76/200, Iteration 91/250, Loss: 0.0169\n",
      "Epoch 76/200, Iteration 92/250, Loss: 0.0101\n",
      "Epoch 76/200, Iteration 93/250, Loss: 0.0075\n",
      "Epoch 76/200, Iteration 94/250, Loss: 0.0086\n",
      "Epoch 76/200, Iteration 95/250, Loss: 0.0077\n",
      "Epoch 76/200, Iteration 96/250, Loss: 0.0199\n",
      "Epoch 76/200, Iteration 97/250, Loss: 0.0373\n",
      "Epoch 76/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 76/200, Iteration 99/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 76/200, Iteration 101/250, Loss: 0.0119\n",
      "Epoch 76/200, Iteration 102/250, Loss: 0.0193\n",
      "Epoch 76/200, Iteration 103/250, Loss: 0.0081\n",
      "Epoch 76/200, Iteration 104/250, Loss: 0.0167\n",
      "Epoch 76/200, Iteration 105/250, Loss: 0.0130\n",
      "Epoch 76/200, Iteration 106/250, Loss: 0.0111\n",
      "Epoch 76/200, Iteration 107/250, Loss: 0.0359\n",
      "Epoch 76/200, Iteration 108/250, Loss: 0.0331\n",
      "Epoch 76/200, Iteration 109/250, Loss: 0.0184\n",
      "Epoch 76/200, Iteration 110/250, Loss: 0.0068\n",
      "Epoch 76/200, Iteration 111/250, Loss: 0.0094\n",
      "Epoch 76/200, Iteration 112/250, Loss: 0.0076\n",
      "Epoch 76/200, Iteration 113/250, Loss: 0.0131\n",
      "Epoch 76/200, Iteration 114/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 115/250, Loss: 0.0184\n",
      "Epoch 76/200, Iteration 116/250, Loss: 0.0242\n",
      "Epoch 76/200, Iteration 117/250, Loss: 0.0134\n",
      "Epoch 76/200, Iteration 118/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 119/250, Loss: 0.0212\n",
      "Epoch 76/200, Iteration 120/250, Loss: 0.0134\n",
      "Epoch 76/200, Iteration 121/250, Loss: 0.0156\n",
      "Epoch 76/200, Iteration 122/250, Loss: 0.0244\n",
      "Epoch 76/200, Iteration 123/250, Loss: 0.0237\n",
      "Epoch 76/200, Iteration 124/250, Loss: 0.0156\n",
      "Epoch 76/200, Iteration 125/250, Loss: 0.0232\n",
      "Epoch 76/200, Iteration 126/250, Loss: 0.0194\n",
      "Epoch 76/200, Iteration 127/250, Loss: 0.0147\n",
      "Epoch 76/200, Iteration 128/250, Loss: 0.0105\n",
      "Epoch 76/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 130/250, Loss: 0.0167\n",
      "Epoch 76/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 76/200, Iteration 132/250, Loss: 0.0217\n",
      "Epoch 76/200, Iteration 133/250, Loss: 0.0201\n",
      "Epoch 76/200, Iteration 134/250, Loss: 0.0122\n",
      "Epoch 76/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 76/200, Iteration 136/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 137/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 138/250, Loss: 0.0414\n",
      "Epoch 76/200, Iteration 139/250, Loss: 0.0200\n",
      "Epoch 76/200, Iteration 140/250, Loss: 0.0222\n",
      "Epoch 76/200, Iteration 141/250, Loss: 0.0144\n",
      "Epoch 76/200, Iteration 142/250, Loss: 0.0091\n",
      "Epoch 76/200, Iteration 143/250, Loss: 0.0140\n",
      "Epoch 76/200, Iteration 144/250, Loss: 0.0176\n",
      "Epoch 76/200, Iteration 145/250, Loss: 0.0168\n",
      "Epoch 76/200, Iteration 146/250, Loss: 0.0118\n",
      "Epoch 76/200, Iteration 147/250, Loss: 0.0162\n",
      "Epoch 76/200, Iteration 148/250, Loss: 0.0069\n",
      "Epoch 76/200, Iteration 149/250, Loss: 0.0177\n",
      "Epoch 76/200, Iteration 150/250, Loss: 0.0106\n",
      "Epoch 76/200, Iteration 151/250, Loss: 0.0089\n",
      "Epoch 76/200, Iteration 152/250, Loss: 0.0093\n",
      "Epoch 76/200, Iteration 153/250, Loss: 0.0136\n",
      "Epoch 76/200, Iteration 154/250, Loss: 0.0114\n",
      "Epoch 76/200, Iteration 155/250, Loss: 0.0176\n",
      "Epoch 76/200, Iteration 156/250, Loss: 0.0155\n",
      "Epoch 76/200, Iteration 157/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 158/250, Loss: 0.0125\n",
      "Epoch 76/200, Iteration 159/250, Loss: 0.0180\n",
      "Epoch 76/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 76/200, Iteration 161/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 162/250, Loss: 0.0072\n",
      "Epoch 76/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 164/250, Loss: 0.0232\n",
      "Epoch 76/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 76/200, Iteration 166/250, Loss: 0.0302\n",
      "Epoch 76/200, Iteration 167/250, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 168/250, Loss: 0.0172\n",
      "Epoch 76/200, Iteration 169/250, Loss: 0.0216\n",
      "Epoch 76/200, Iteration 170/250, Loss: 0.0117\n",
      "Epoch 76/200, Iteration 171/250, Loss: 0.0190\n",
      "Epoch 76/200, Iteration 172/250, Loss: 0.0243\n",
      "Epoch 76/200, Iteration 173/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 174/250, Loss: 0.0145\n",
      "Epoch 76/200, Iteration 175/250, Loss: 0.0126\n",
      "Epoch 76/200, Iteration 176/250, Loss: 0.0311\n",
      "Epoch 76/200, Iteration 177/250, Loss: 0.0087\n",
      "Epoch 76/200, Iteration 178/250, Loss: 0.0161\n",
      "Epoch 76/200, Iteration 179/250, Loss: 0.0109\n",
      "Epoch 76/200, Iteration 180/250, Loss: 0.0371\n",
      "Epoch 76/200, Iteration 181/250, Loss: 0.0073\n",
      "Epoch 76/200, Iteration 182/250, Loss: 0.0112\n",
      "Epoch 76/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 76/200, Iteration 184/250, Loss: 0.0096\n",
      "Epoch 76/200, Iteration 185/250, Loss: 0.0143\n",
      "Epoch 76/200, Iteration 186/250, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200, Iteration 187/250, Loss: 0.0170\n",
      "Epoch 76/200, Iteration 188/250, Loss: 0.0119\n",
      "Epoch 76/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 76/200, Iteration 190/250, Loss: 0.0105\n",
      "Epoch 76/200, Iteration 191/250, Loss: 0.0170\n",
      "Epoch 76/200, Iteration 192/250, Loss: 0.0169\n",
      "Epoch 76/200, Iteration 193/250, Loss: 0.0129\n",
      "Epoch 76/200, Iteration 194/250, Loss: 0.0155\n",
      "Epoch 76/200, Iteration 195/250, Loss: 0.0328\n",
      "Epoch 76/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 76/200, Iteration 197/250, Loss: 0.0211\n",
      "Epoch 76/200, Iteration 198/250, Loss: 0.0146\n",
      "Epoch 76/200, Iteration 199/250, Loss: 0.0120\n",
      "Epoch 76/200, Iteration 200/250, Loss: 0.0326\n",
      "Epoch 76/200, Iteration 201/250, Loss: 0.0296\n",
      "Epoch 76/200, Iteration 202/250, Loss: 0.0296\n",
      "Epoch 76/200, Iteration 203/250, Loss: 0.0085\n",
      "Epoch 76/200, Iteration 204/250, Loss: 0.0132\n",
      "Epoch 76/200, Iteration 205/250, Loss: 0.0117\n",
      "Epoch 76/200, Iteration 206/250, Loss: 0.0075\n",
      "Epoch 76/200, Iteration 207/250, Loss: 0.0156\n",
      "Epoch 76/200, Iteration 208/250, Loss: 0.0204\n",
      "Epoch 76/200, Iteration 209/250, Loss: 0.0099\n",
      "Epoch 76/200, Iteration 210/250, Loss: 0.0257\n",
      "Epoch 76/200, Iteration 211/250, Loss: 0.0211\n",
      "Epoch 76/200, Iteration 212/250, Loss: 0.0068\n",
      "Epoch 76/200, Iteration 213/250, Loss: 0.0161\n",
      "Epoch 76/200, Iteration 214/250, Loss: 0.0255\n",
      "Epoch 76/200, Iteration 215/250, Loss: 0.0310\n",
      "Epoch 76/200, Iteration 216/250, Loss: 0.0145\n",
      "Epoch 76/200, Iteration 217/250, Loss: 0.0176\n",
      "Epoch 76/200, Iteration 218/250, Loss: 0.0169\n",
      "Epoch 76/200, Iteration 219/250, Loss: 0.0137\n",
      "Epoch 76/200, Iteration 220/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 221/250, Loss: 0.0110\n",
      "Epoch 76/200, Iteration 222/250, Loss: 0.0080\n",
      "Epoch 76/200, Iteration 223/250, Loss: 0.0163\n",
      "Epoch 76/200, Iteration 224/250, Loss: 0.0108\n",
      "Epoch 76/200, Iteration 225/250, Loss: 0.0116\n",
      "Epoch 76/200, Iteration 226/250, Loss: 0.0176\n",
      "Epoch 76/200, Iteration 227/250, Loss: 0.0096\n",
      "Epoch 76/200, Iteration 228/250, Loss: 0.0065\n",
      "Epoch 76/200, Iteration 229/250, Loss: 0.0275\n",
      "Epoch 76/200, Iteration 230/250, Loss: 0.0365\n",
      "Epoch 76/200, Iteration 231/250, Loss: 0.0090\n",
      "Epoch 76/200, Iteration 232/250, Loss: 0.0166\n",
      "Epoch 76/200, Iteration 233/250, Loss: 0.0101\n",
      "Epoch 76/200, Iteration 234/250, Loss: 0.0079\n",
      "Epoch 76/200, Iteration 235/250, Loss: 0.0096\n",
      "Epoch 76/200, Iteration 236/250, Loss: 0.0188\n",
      "Epoch 76/200, Iteration 237/250, Loss: 0.0313\n",
      "Epoch 76/200, Iteration 238/250, Loss: 0.0227\n",
      "Epoch 76/200, Iteration 239/250, Loss: 0.0128\n",
      "Epoch 76/200, Iteration 240/250, Loss: 0.0084\n",
      "Epoch 76/200, Iteration 241/250, Loss: 0.0121\n",
      "Epoch 76/200, Iteration 242/250, Loss: 0.0226\n",
      "Epoch 76/200, Iteration 243/250, Loss: 0.0150\n",
      "Epoch 76/200, Iteration 244/250, Loss: 0.0117\n",
      "Epoch 76/200, Iteration 245/250, Loss: 0.0174\n",
      "Epoch 76/200, Iteration 246/250, Loss: 0.0116\n",
      "Epoch 76/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 76/200, Iteration 248/250, Loss: 0.0132\n",
      "Epoch 76/200, Iteration 249/250, Loss: 0.0173\n",
      "Epoch 76/200, Iteration 250/250, Loss: 0.0242\n",
      "Train Error: \n",
      " Accuracy: 93.08%, Avg loss: 0.007408, MRE: 0.446737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.007875, MRE: 0.566411 \n",
      "\n",
      "Epoch 77/200, Iteration 1/250, Loss: 0.0078\n",
      "Epoch 77/200, Iteration 2/250, Loss: 0.0131\n",
      "Epoch 77/200, Iteration 3/250, Loss: 0.0241\n",
      "Epoch 77/200, Iteration 4/250, Loss: 0.0069\n",
      "Epoch 77/200, Iteration 5/250, Loss: 0.0113\n",
      "Epoch 77/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 77/200, Iteration 7/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 8/250, Loss: 0.0096\n",
      "Epoch 77/200, Iteration 9/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 10/250, Loss: 0.0167\n",
      "Epoch 77/200, Iteration 11/250, Loss: 0.0412\n",
      "Epoch 77/200, Iteration 12/250, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 13/250, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 14/250, Loss: 0.0230\n",
      "Epoch 77/200, Iteration 15/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 16/250, Loss: 0.0134\n",
      "Epoch 77/200, Iteration 17/250, Loss: 0.0223\n",
      "Epoch 77/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 77/200, Iteration 19/250, Loss: 0.0149\n",
      "Epoch 77/200, Iteration 20/250, Loss: 0.0098\n",
      "Epoch 77/200, Iteration 21/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 22/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 23/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 24/250, Loss: 0.0208\n",
      "Epoch 77/200, Iteration 25/250, Loss: 0.0238\n",
      "Epoch 77/200, Iteration 26/250, Loss: 0.0247\n",
      "Epoch 77/200, Iteration 27/250, Loss: 0.0389\n",
      "Epoch 77/200, Iteration 28/250, Loss: 0.0207\n",
      "Epoch 77/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 77/200, Iteration 30/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 31/250, Loss: 0.0168\n",
      "Epoch 77/200, Iteration 32/250, Loss: 0.0117\n",
      "Epoch 77/200, Iteration 33/250, Loss: 0.0114\n",
      "Epoch 77/200, Iteration 34/250, Loss: 0.0296\n",
      "Epoch 77/200, Iteration 35/250, Loss: 0.0105\n",
      "Epoch 77/200, Iteration 36/250, Loss: 0.0231\n",
      "Epoch 77/200, Iteration 37/250, Loss: 0.0415\n",
      "Epoch 77/200, Iteration 38/250, Loss: 0.0117\n",
      "Epoch 77/200, Iteration 39/250, Loss: 0.0127\n",
      "Epoch 77/200, Iteration 40/250, Loss: 0.0164\n",
      "Epoch 77/200, Iteration 41/250, Loss: 0.0152\n",
      "Epoch 77/200, Iteration 42/250, Loss: 0.0186\n",
      "Epoch 77/200, Iteration 43/250, Loss: 0.0226\n",
      "Epoch 77/200, Iteration 44/250, Loss: 0.0243\n",
      "Epoch 77/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 77/200, Iteration 46/250, Loss: 0.0152\n",
      "Epoch 77/200, Iteration 47/250, Loss: 0.0195\n",
      "Epoch 77/200, Iteration 48/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 77/200, Iteration 50/250, Loss: 0.0192\n",
      "Epoch 77/200, Iteration 51/250, Loss: 0.0305\n",
      "Epoch 77/200, Iteration 52/250, Loss: 0.0089\n",
      "Epoch 77/200, Iteration 53/250, Loss: 0.0088\n",
      "Epoch 77/200, Iteration 54/250, Loss: 0.0199\n",
      "Epoch 77/200, Iteration 55/250, Loss: 0.0098\n",
      "Epoch 77/200, Iteration 56/250, Loss: 0.0354\n",
      "Epoch 77/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 58/250, Loss: 0.0165\n",
      "Epoch 77/200, Iteration 59/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 60/250, Loss: 0.0174\n",
      "Epoch 77/200, Iteration 61/250, Loss: 0.0143\n",
      "Epoch 77/200, Iteration 62/250, Loss: 0.0121\n",
      "Epoch 77/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 77/200, Iteration 64/250, Loss: 0.0085\n",
      "Epoch 77/200, Iteration 65/250, Loss: 0.0261\n",
      "Epoch 77/200, Iteration 66/250, Loss: 0.0147\n",
      "Epoch 77/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 77/200, Iteration 68/250, Loss: 0.0124\n",
      "Epoch 77/200, Iteration 69/250, Loss: 0.0102\n",
      "Epoch 77/200, Iteration 70/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 71/250, Loss: 0.0404\n",
      "Epoch 77/200, Iteration 72/250, Loss: 0.0116\n",
      "Epoch 77/200, Iteration 73/250, Loss: 0.0155\n",
      "Epoch 77/200, Iteration 74/250, Loss: 0.0190\n",
      "Epoch 77/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 76/250, Loss: 0.0252\n",
      "Epoch 77/200, Iteration 77/250, Loss: 0.0212\n",
      "Epoch 77/200, Iteration 78/250, Loss: 0.0240\n",
      "Epoch 77/200, Iteration 79/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 80/250, Loss: 0.0204\n",
      "Epoch 77/200, Iteration 81/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 82/250, Loss: 0.0189\n",
      "Epoch 77/200, Iteration 83/250, Loss: 0.0166\n",
      "Epoch 77/200, Iteration 84/250, Loss: 0.0456\n",
      "Epoch 77/200, Iteration 85/250, Loss: 0.0129\n",
      "Epoch 77/200, Iteration 86/250, Loss: 0.0200\n",
      "Epoch 77/200, Iteration 87/250, Loss: 0.0118\n",
      "Epoch 77/200, Iteration 88/250, Loss: 0.0189\n",
      "Epoch 77/200, Iteration 89/250, Loss: 0.0066\n",
      "Epoch 77/200, Iteration 90/250, Loss: 0.0213\n",
      "Epoch 77/200, Iteration 91/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 92/250, Loss: 0.0161\n",
      "Epoch 77/200, Iteration 93/250, Loss: 0.0092\n",
      "Epoch 77/200, Iteration 94/250, Loss: 0.0146\n",
      "Epoch 77/200, Iteration 95/250, Loss: 0.0132\n",
      "Epoch 77/200, Iteration 96/250, Loss: 0.0133\n",
      "Epoch 77/200, Iteration 97/250, Loss: 0.0140\n",
      "Epoch 77/200, Iteration 98/250, Loss: 0.0190\n",
      "Epoch 77/200, Iteration 99/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 100/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 101/250, Loss: 0.0109\n",
      "Epoch 77/200, Iteration 102/250, Loss: 0.0067\n",
      "Epoch 77/200, Iteration 103/250, Loss: 0.0193\n",
      "Epoch 77/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 77/200, Iteration 105/250, Loss: 0.0099\n",
      "Epoch 77/200, Iteration 106/250, Loss: 0.0182\n",
      "Epoch 77/200, Iteration 107/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 108/250, Loss: 0.0134\n",
      "Epoch 77/200, Iteration 109/250, Loss: 0.0192\n",
      "Epoch 77/200, Iteration 110/250, Loss: 0.0219\n",
      "Epoch 77/200, Iteration 111/250, Loss: 0.0104\n",
      "Epoch 77/200, Iteration 112/250, Loss: 0.0126\n",
      "Epoch 77/200, Iteration 113/250, Loss: 0.0323\n",
      "Epoch 77/200, Iteration 114/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 115/250, Loss: 0.0118\n",
      "Epoch 77/200, Iteration 116/250, Loss: 0.0126\n",
      "Epoch 77/200, Iteration 117/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 118/250, Loss: 0.0145\n",
      "Epoch 77/200, Iteration 119/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 120/250, Loss: 0.0210\n",
      "Epoch 77/200, Iteration 121/250, Loss: 0.0128\n",
      "Epoch 77/200, Iteration 122/250, Loss: 0.0122\n",
      "Epoch 77/200, Iteration 123/250, Loss: 0.0074\n",
      "Epoch 77/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 77/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 77/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 127/250, Loss: 0.0114\n",
      "Epoch 77/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 129/250, Loss: 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200, Iteration 130/250, Loss: 0.0259\n",
      "Epoch 77/200, Iteration 131/250, Loss: 0.0316\n",
      "Epoch 77/200, Iteration 132/250, Loss: 0.0228\n",
      "Epoch 77/200, Iteration 133/250, Loss: 0.0135\n",
      "Epoch 77/200, Iteration 134/250, Loss: 0.0104\n",
      "Epoch 77/200, Iteration 135/250, Loss: 0.0129\n",
      "Epoch 77/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 77/200, Iteration 137/250, Loss: 0.0111\n",
      "Epoch 77/200, Iteration 138/250, Loss: 0.0133\n",
      "Epoch 77/200, Iteration 139/250, Loss: 0.0220\n",
      "Epoch 77/200, Iteration 140/250, Loss: 0.0174\n",
      "Epoch 77/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 77/200, Iteration 142/250, Loss: 0.0087\n",
      "Epoch 77/200, Iteration 143/250, Loss: 0.0218\n",
      "Epoch 77/200, Iteration 144/250, Loss: 0.0081\n",
      "Epoch 77/200, Iteration 145/250, Loss: 0.0069\n",
      "Epoch 77/200, Iteration 146/250, Loss: 0.0081\n",
      "Epoch 77/200, Iteration 147/250, Loss: 0.0108\n",
      "Epoch 77/200, Iteration 148/250, Loss: 0.0138\n",
      "Epoch 77/200, Iteration 149/250, Loss: 0.0152\n",
      "Epoch 77/200, Iteration 150/250, Loss: 0.0139\n",
      "Epoch 77/200, Iteration 151/250, Loss: 0.0111\n",
      "Epoch 77/200, Iteration 152/250, Loss: 0.0180\n",
      "Epoch 77/200, Iteration 153/250, Loss: 0.0063\n",
      "Epoch 77/200, Iteration 154/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 155/250, Loss: 0.0085\n",
      "Epoch 77/200, Iteration 156/250, Loss: 0.0229\n",
      "Epoch 77/200, Iteration 157/250, Loss: 0.0213\n",
      "Epoch 77/200, Iteration 158/250, Loss: 0.0194\n",
      "Epoch 77/200, Iteration 159/250, Loss: 0.0080\n",
      "Epoch 77/200, Iteration 160/250, Loss: 0.0060\n",
      "Epoch 77/200, Iteration 161/250, Loss: 0.0097\n",
      "Epoch 77/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 77/200, Iteration 163/250, Loss: 0.0154\n",
      "Epoch 77/200, Iteration 164/250, Loss: 0.0071\n",
      "Epoch 77/200, Iteration 165/250, Loss: 0.0274\n",
      "Epoch 77/200, Iteration 166/250, Loss: 0.0171\n",
      "Epoch 77/200, Iteration 167/250, Loss: 0.0125\n",
      "Epoch 77/200, Iteration 168/250, Loss: 0.0144\n",
      "Epoch 77/200, Iteration 169/250, Loss: 0.0173\n",
      "Epoch 77/200, Iteration 170/250, Loss: 0.0131\n",
      "Epoch 77/200, Iteration 171/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 172/250, Loss: 0.0423\n",
      "Epoch 77/200, Iteration 173/250, Loss: 0.0087\n",
      "Epoch 77/200, Iteration 174/250, Loss: 0.0255\n",
      "Epoch 77/200, Iteration 175/250, Loss: 0.0180\n",
      "Epoch 77/200, Iteration 176/250, Loss: 0.0322\n",
      "Epoch 77/200, Iteration 177/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 178/250, Loss: 0.0161\n",
      "Epoch 77/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 77/200, Iteration 180/250, Loss: 0.0136\n",
      "Epoch 77/200, Iteration 181/250, Loss: 0.0271\n",
      "Epoch 77/200, Iteration 182/250, Loss: 0.0138\n",
      "Epoch 77/200, Iteration 183/250, Loss: 0.0104\n",
      "Epoch 77/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 185/250, Loss: 0.0117\n",
      "Epoch 77/200, Iteration 186/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 187/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 188/250, Loss: 0.0130\n",
      "Epoch 77/200, Iteration 189/250, Loss: 0.0317\n",
      "Epoch 77/200, Iteration 190/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 191/250, Loss: 0.0206\n",
      "Epoch 77/200, Iteration 192/250, Loss: 0.0178\n",
      "Epoch 77/200, Iteration 193/250, Loss: 0.0097\n",
      "Epoch 77/200, Iteration 194/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 195/250, Loss: 0.0265\n",
      "Epoch 77/200, Iteration 196/250, Loss: 0.0148\n",
      "Epoch 77/200, Iteration 197/250, Loss: 0.0254\n",
      "Epoch 77/200, Iteration 198/250, Loss: 0.0097\n",
      "Epoch 77/200, Iteration 199/250, Loss: 0.0235\n",
      "Epoch 77/200, Iteration 200/250, Loss: 0.0160\n",
      "Epoch 77/200, Iteration 201/250, Loss: 0.0119\n",
      "Epoch 77/200, Iteration 202/250, Loss: 0.0128\n",
      "Epoch 77/200, Iteration 203/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 204/250, Loss: 0.0079\n",
      "Epoch 77/200, Iteration 205/250, Loss: 0.0139\n",
      "Epoch 77/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 77/200, Iteration 207/250, Loss: 0.0092\n",
      "Epoch 77/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 77/200, Iteration 209/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 210/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 211/250, Loss: 0.0115\n",
      "Epoch 77/200, Iteration 212/250, Loss: 0.0077\n",
      "Epoch 77/200, Iteration 213/250, Loss: 0.0166\n",
      "Epoch 77/200, Iteration 214/250, Loss: 0.0260\n",
      "Epoch 77/200, Iteration 215/250, Loss: 0.0089\n",
      "Epoch 77/200, Iteration 216/250, Loss: 0.0290\n",
      "Epoch 77/200, Iteration 217/250, Loss: 0.0269\n",
      "Epoch 77/200, Iteration 218/250, Loss: 0.0107\n",
      "Epoch 77/200, Iteration 219/250, Loss: 0.0127\n",
      "Epoch 77/200, Iteration 220/250, Loss: 0.0103\n",
      "Epoch 77/200, Iteration 221/250, Loss: 0.0174\n",
      "Epoch 77/200, Iteration 222/250, Loss: 0.0093\n",
      "Epoch 77/200, Iteration 223/250, Loss: 0.0214\n",
      "Epoch 77/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 77/200, Iteration 225/250, Loss: 0.0110\n",
      "Epoch 77/200, Iteration 226/250, Loss: 0.0175\n",
      "Epoch 77/200, Iteration 227/250, Loss: 0.0178\n",
      "Epoch 77/200, Iteration 228/250, Loss: 0.0250\n",
      "Epoch 77/200, Iteration 229/250, Loss: 0.0142\n",
      "Epoch 77/200, Iteration 230/250, Loss: 0.0155\n",
      "Epoch 77/200, Iteration 231/250, Loss: 0.0699\n",
      "Epoch 77/200, Iteration 232/250, Loss: 0.0059\n",
      "Epoch 77/200, Iteration 233/250, Loss: 0.0112\n",
      "Epoch 77/200, Iteration 234/250, Loss: 0.0095\n",
      "Epoch 77/200, Iteration 235/250, Loss: 0.0081\n",
      "Epoch 77/200, Iteration 236/250, Loss: 0.0217\n",
      "Epoch 77/200, Iteration 237/250, Loss: 0.0101\n",
      "Epoch 77/200, Iteration 238/250, Loss: 0.0130\n",
      "Epoch 77/200, Iteration 239/250, Loss: 0.0077\n",
      "Epoch 77/200, Iteration 240/250, Loss: 0.0084\n",
      "Epoch 77/200, Iteration 241/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 242/250, Loss: 0.0064\n",
      "Epoch 77/200, Iteration 243/250, Loss: 0.0093\n",
      "Epoch 77/200, Iteration 244/250, Loss: 0.0209\n",
      "Epoch 77/200, Iteration 245/250, Loss: 0.0087\n",
      "Epoch 77/200, Iteration 246/250, Loss: 0.0177\n",
      "Epoch 77/200, Iteration 247/250, Loss: 0.0078\n",
      "Epoch 77/200, Iteration 248/250, Loss: 0.0141\n",
      "Epoch 77/200, Iteration 249/250, Loss: 0.0148\n",
      "Epoch 77/200, Iteration 250/250, Loss: 0.0143\n",
      "Train Error: \n",
      " Accuracy: 87.67%, Avg loss: 0.006853, MRE: 0.477152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.007326, MRE: 0.608494 \n",
      "\n",
      "Epoch 78/200, Iteration 1/250, Loss: 0.0300\n",
      "Epoch 78/200, Iteration 2/250, Loss: 0.0121\n",
      "Epoch 78/200, Iteration 3/250, Loss: 0.0077\n",
      "Epoch 78/200, Iteration 4/250, Loss: 0.0119\n",
      "Epoch 78/200, Iteration 5/250, Loss: 0.0119\n",
      "Epoch 78/200, Iteration 6/250, Loss: 0.0086\n",
      "Epoch 78/200, Iteration 7/250, Loss: 0.0121\n",
      "Epoch 78/200, Iteration 8/250, Loss: 0.0087\n",
      "Epoch 78/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 78/200, Iteration 10/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 11/250, Loss: 0.0164\n",
      "Epoch 78/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 13/250, Loss: 0.0348\n",
      "Epoch 78/200, Iteration 14/250, Loss: 0.0115\n",
      "Epoch 78/200, Iteration 15/250, Loss: 0.0119\n",
      "Epoch 78/200, Iteration 16/250, Loss: 0.0165\n",
      "Epoch 78/200, Iteration 17/250, Loss: 0.0084\n",
      "Epoch 78/200, Iteration 18/250, Loss: 0.0230\n",
      "Epoch 78/200, Iteration 19/250, Loss: 0.0158\n",
      "Epoch 78/200, Iteration 20/250, Loss: 0.0172\n",
      "Epoch 78/200, Iteration 21/250, Loss: 0.0226\n",
      "Epoch 78/200, Iteration 22/250, Loss: 0.0094\n",
      "Epoch 78/200, Iteration 23/250, Loss: 0.0151\n",
      "Epoch 78/200, Iteration 24/250, Loss: 0.0197\n",
      "Epoch 78/200, Iteration 25/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 26/250, Loss: 0.0136\n",
      "Epoch 78/200, Iteration 27/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 28/250, Loss: 0.0133\n",
      "Epoch 78/200, Iteration 29/250, Loss: 0.0354\n",
      "Epoch 78/200, Iteration 30/250, Loss: 0.0226\n",
      "Epoch 78/200, Iteration 31/250, Loss: 0.0165\n",
      "Epoch 78/200, Iteration 32/250, Loss: 0.0082\n",
      "Epoch 78/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 34/250, Loss: 0.0143\n",
      "Epoch 78/200, Iteration 35/250, Loss: 0.0184\n",
      "Epoch 78/200, Iteration 36/250, Loss: 0.0106\n",
      "Epoch 78/200, Iteration 37/250, Loss: 0.0125\n",
      "Epoch 78/200, Iteration 38/250, Loss: 0.0171\n",
      "Epoch 78/200, Iteration 39/250, Loss: 0.0132\n",
      "Epoch 78/200, Iteration 40/250, Loss: 0.0101\n",
      "Epoch 78/200, Iteration 41/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 42/250, Loss: 0.0078\n",
      "Epoch 78/200, Iteration 43/250, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 44/250, Loss: 0.0081\n",
      "Epoch 78/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 78/200, Iteration 46/250, Loss: 0.0112\n",
      "Epoch 78/200, Iteration 47/250, Loss: 0.0242\n",
      "Epoch 78/200, Iteration 48/250, Loss: 0.0125\n",
      "Epoch 78/200, Iteration 49/250, Loss: 0.0318\n",
      "Epoch 78/200, Iteration 50/250, Loss: 0.0332\n",
      "Epoch 78/200, Iteration 51/250, Loss: 0.0078\n",
      "Epoch 78/200, Iteration 52/250, Loss: 0.0075\n",
      "Epoch 78/200, Iteration 53/250, Loss: 0.0141\n",
      "Epoch 78/200, Iteration 54/250, Loss: 0.0266\n",
      "Epoch 78/200, Iteration 55/250, Loss: 0.0194\n",
      "Epoch 78/200, Iteration 56/250, Loss: 0.0251\n",
      "Epoch 78/200, Iteration 57/250, Loss: 0.0074\n",
      "Epoch 78/200, Iteration 58/250, Loss: 0.0267\n",
      "Epoch 78/200, Iteration 59/250, Loss: 0.0159\n",
      "Epoch 78/200, Iteration 60/250, Loss: 0.0134\n",
      "Epoch 78/200, Iteration 61/250, Loss: 0.0110\n",
      "Epoch 78/200, Iteration 62/250, Loss: 0.0314\n",
      "Epoch 78/200, Iteration 63/250, Loss: 0.0209\n",
      "Epoch 78/200, Iteration 64/250, Loss: 0.0216\n",
      "Epoch 78/200, Iteration 65/250, Loss: 0.0130\n",
      "Epoch 78/200, Iteration 66/250, Loss: 0.0102\n",
      "Epoch 78/200, Iteration 67/250, Loss: 0.0192\n",
      "Epoch 78/200, Iteration 68/250, Loss: 0.0141\n",
      "Epoch 78/200, Iteration 69/250, Loss: 0.0284\n",
      "Epoch 78/200, Iteration 70/250, Loss: 0.0060\n",
      "Epoch 78/200, Iteration 71/250, Loss: 0.0319\n",
      "Epoch 78/200, Iteration 72/250, Loss: 0.0069\n",
      "Epoch 78/200, Iteration 73/250, Loss: 0.0093\n",
      "Epoch 78/200, Iteration 74/250, Loss: 0.0081\n",
      "Epoch 78/200, Iteration 75/250, Loss: 0.0348\n",
      "Epoch 78/200, Iteration 76/250, Loss: 0.0230\n",
      "Epoch 78/200, Iteration 77/250, Loss: 0.0287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200, Iteration 78/250, Loss: 0.0354\n",
      "Epoch 78/200, Iteration 79/250, Loss: 0.0153\n",
      "Epoch 78/200, Iteration 80/250, Loss: 0.0151\n",
      "Epoch 78/200, Iteration 81/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 82/250, Loss: 0.0071\n",
      "Epoch 78/200, Iteration 83/250, Loss: 0.0199\n",
      "Epoch 78/200, Iteration 84/250, Loss: 0.0187\n",
      "Epoch 78/200, Iteration 85/250, Loss: 0.0219\n",
      "Epoch 78/200, Iteration 86/250, Loss: 0.0092\n",
      "Epoch 78/200, Iteration 87/250, Loss: 0.0121\n",
      "Epoch 78/200, Iteration 88/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 89/250, Loss: 0.0186\n",
      "Epoch 78/200, Iteration 90/250, Loss: 0.0085\n",
      "Epoch 78/200, Iteration 91/250, Loss: 0.0227\n",
      "Epoch 78/200, Iteration 92/250, Loss: 0.0230\n",
      "Epoch 78/200, Iteration 93/250, Loss: 0.0081\n",
      "Epoch 78/200, Iteration 94/250, Loss: 0.0089\n",
      "Epoch 78/200, Iteration 95/250, Loss: 0.0235\n",
      "Epoch 78/200, Iteration 96/250, Loss: 0.0158\n",
      "Epoch 78/200, Iteration 97/250, Loss: 0.0159\n",
      "Epoch 78/200, Iteration 98/250, Loss: 0.0148\n",
      "Epoch 78/200, Iteration 99/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 100/250, Loss: 0.0162\n",
      "Epoch 78/200, Iteration 101/250, Loss: 0.0133\n",
      "Epoch 78/200, Iteration 102/250, Loss: 0.0231\n",
      "Epoch 78/200, Iteration 103/250, Loss: 0.0199\n",
      "Epoch 78/200, Iteration 104/250, Loss: 0.0403\n",
      "Epoch 78/200, Iteration 105/250, Loss: 0.0170\n",
      "Epoch 78/200, Iteration 106/250, Loss: 0.0244\n",
      "Epoch 78/200, Iteration 107/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 108/250, Loss: 0.0285\n",
      "Epoch 78/200, Iteration 109/250, Loss: 0.0146\n",
      "Epoch 78/200, Iteration 110/250, Loss: 0.0122\n",
      "Epoch 78/200, Iteration 111/250, Loss: 0.0179\n",
      "Epoch 78/200, Iteration 112/250, Loss: 0.0104\n",
      "Epoch 78/200, Iteration 113/250, Loss: 0.0283\n",
      "Epoch 78/200, Iteration 114/250, Loss: 0.0122\n",
      "Epoch 78/200, Iteration 115/250, Loss: 0.0208\n",
      "Epoch 78/200, Iteration 116/250, Loss: 0.0176\n",
      "Epoch 78/200, Iteration 117/250, Loss: 0.0234\n",
      "Epoch 78/200, Iteration 118/250, Loss: 0.0162\n",
      "Epoch 78/200, Iteration 119/250, Loss: 0.0268\n",
      "Epoch 78/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 78/200, Iteration 121/250, Loss: 0.0069\n",
      "Epoch 78/200, Iteration 122/250, Loss: 0.0107\n",
      "Epoch 78/200, Iteration 123/250, Loss: 0.0302\n",
      "Epoch 78/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 78/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 78/200, Iteration 126/250, Loss: 0.0130\n",
      "Epoch 78/200, Iteration 127/250, Loss: 0.0074\n",
      "Epoch 78/200, Iteration 128/250, Loss: 0.0155\n",
      "Epoch 78/200, Iteration 129/250, Loss: 0.0151\n",
      "Epoch 78/200, Iteration 130/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 131/250, Loss: 0.0078\n",
      "Epoch 78/200, Iteration 132/250, Loss: 0.0267\n",
      "Epoch 78/200, Iteration 133/250, Loss: 0.0066\n",
      "Epoch 78/200, Iteration 134/250, Loss: 0.0171\n",
      "Epoch 78/200, Iteration 135/250, Loss: 0.0235\n",
      "Epoch 78/200, Iteration 136/250, Loss: 0.0133\n",
      "Epoch 78/200, Iteration 137/250, Loss: 0.0086\n",
      "Epoch 78/200, Iteration 138/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 139/250, Loss: 0.0168\n",
      "Epoch 78/200, Iteration 140/250, Loss: 0.0150\n",
      "Epoch 78/200, Iteration 141/250, Loss: 0.0161\n",
      "Epoch 78/200, Iteration 142/250, Loss: 0.0109\n",
      "Epoch 78/200, Iteration 143/250, Loss: 0.0251\n",
      "Epoch 78/200, Iteration 144/250, Loss: 0.0188\n",
      "Epoch 78/200, Iteration 145/250, Loss: 0.0127\n",
      "Epoch 78/200, Iteration 146/250, Loss: 0.0098\n",
      "Epoch 78/200, Iteration 147/250, Loss: 0.0219\n",
      "Epoch 78/200, Iteration 148/250, Loss: 0.0240\n",
      "Epoch 78/200, Iteration 149/250, Loss: 0.0142\n",
      "Epoch 78/200, Iteration 150/250, Loss: 0.0096\n",
      "Epoch 78/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 78/200, Iteration 152/250, Loss: 0.0166\n",
      "Epoch 78/200, Iteration 153/250, Loss: 0.0074\n",
      "Epoch 78/200, Iteration 154/250, Loss: 0.0229\n",
      "Epoch 78/200, Iteration 155/250, Loss: 0.0216\n",
      "Epoch 78/200, Iteration 156/250, Loss: 0.0397\n",
      "Epoch 78/200, Iteration 157/250, Loss: 0.0243\n",
      "Epoch 78/200, Iteration 158/250, Loss: 0.0110\n",
      "Epoch 78/200, Iteration 159/250, Loss: 0.0089\n",
      "Epoch 78/200, Iteration 160/250, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 78/200, Iteration 162/250, Loss: 0.0174\n",
      "Epoch 78/200, Iteration 163/250, Loss: 0.0057\n",
      "Epoch 78/200, Iteration 164/250, Loss: 0.0082\n",
      "Epoch 78/200, Iteration 165/250, Loss: 0.0115\n",
      "Epoch 78/200, Iteration 166/250, Loss: 0.0127\n",
      "Epoch 78/200, Iteration 167/250, Loss: 0.0214\n",
      "Epoch 78/200, Iteration 168/250, Loss: 0.0293\n",
      "Epoch 78/200, Iteration 169/250, Loss: 0.0096\n",
      "Epoch 78/200, Iteration 170/250, Loss: 0.0123\n",
      "Epoch 78/200, Iteration 171/250, Loss: 0.0246\n",
      "Epoch 78/200, Iteration 172/250, Loss: 0.0091\n",
      "Epoch 78/200, Iteration 173/250, Loss: 0.0253\n",
      "Epoch 78/200, Iteration 174/250, Loss: 0.0178\n",
      "Epoch 78/200, Iteration 175/250, Loss: 0.0246\n",
      "Epoch 78/200, Iteration 176/250, Loss: 0.0087\n",
      "Epoch 78/200, Iteration 177/250, Loss: 0.0103\n",
      "Epoch 78/200, Iteration 178/250, Loss: 0.0089\n",
      "Epoch 78/200, Iteration 179/250, Loss: 0.0204\n",
      "Epoch 78/200, Iteration 180/250, Loss: 0.0330\n",
      "Epoch 78/200, Iteration 181/250, Loss: 0.0198\n",
      "Epoch 78/200, Iteration 182/250, Loss: 0.0159\n",
      "Epoch 78/200, Iteration 183/250, Loss: 0.0149\n",
      "Epoch 78/200, Iteration 184/250, Loss: 0.0095\n",
      "Epoch 78/200, Iteration 185/250, Loss: 0.0072\n",
      "Epoch 78/200, Iteration 186/250, Loss: 0.0162\n",
      "Epoch 78/200, Iteration 187/250, Loss: 0.0140\n",
      "Epoch 78/200, Iteration 188/250, Loss: 0.0182\n",
      "Epoch 78/200, Iteration 189/250, Loss: 0.0137\n",
      "Epoch 78/200, Iteration 190/250, Loss: 0.0351\n",
      "Epoch 78/200, Iteration 191/250, Loss: 0.0388\n",
      "Epoch 78/200, Iteration 192/250, Loss: 0.0071\n",
      "Epoch 78/200, Iteration 193/250, Loss: 0.0258\n",
      "Epoch 78/200, Iteration 194/250, Loss: 0.0182\n",
      "Epoch 78/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 78/200, Iteration 196/250, Loss: 0.0224\n",
      "Epoch 78/200, Iteration 197/250, Loss: 0.0100\n",
      "Epoch 78/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 78/200, Iteration 199/250, Loss: 0.0278\n",
      "Epoch 78/200, Iteration 200/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 201/250, Loss: 0.0105\n",
      "Epoch 78/200, Iteration 202/250, Loss: 0.0083\n",
      "Epoch 78/200, Iteration 203/250, Loss: 0.0096\n",
      "Epoch 78/200, Iteration 204/250, Loss: 0.0113\n",
      "Epoch 78/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 78/200, Iteration 206/250, Loss: 0.0338\n",
      "Epoch 78/200, Iteration 207/250, Loss: 0.0405\n",
      "Epoch 78/200, Iteration 208/250, Loss: 0.0144\n",
      "Epoch 78/200, Iteration 209/250, Loss: 0.0162\n",
      "Epoch 78/200, Iteration 210/250, Loss: 0.0110\n",
      "Epoch 78/200, Iteration 211/250, Loss: 0.0093\n",
      "Epoch 78/200, Iteration 212/250, Loss: 0.0081\n",
      "Epoch 78/200, Iteration 213/250, Loss: 0.0079\n",
      "Epoch 78/200, Iteration 214/250, Loss: 0.0155\n",
      "Epoch 78/200, Iteration 215/250, Loss: 0.0090\n",
      "Epoch 78/200, Iteration 216/250, Loss: 0.0124\n",
      "Epoch 78/200, Iteration 217/250, Loss: 0.0275\n",
      "Epoch 78/200, Iteration 218/250, Loss: 0.0185\n",
      "Epoch 78/200, Iteration 219/250, Loss: 0.0139\n",
      "Epoch 78/200, Iteration 220/250, Loss: 0.0140\n",
      "Epoch 78/200, Iteration 221/250, Loss: 0.0205\n",
      "Epoch 78/200, Iteration 222/250, Loss: 0.0175\n",
      "Epoch 78/200, Iteration 223/250, Loss: 0.0105\n",
      "Epoch 78/200, Iteration 224/250, Loss: 0.0148\n",
      "Epoch 78/200, Iteration 225/250, Loss: 0.0106\n",
      "Epoch 78/200, Iteration 226/250, Loss: 0.0316\n",
      "Epoch 78/200, Iteration 227/250, Loss: 0.0157\n",
      "Epoch 78/200, Iteration 228/250, Loss: 0.0085\n",
      "Epoch 78/200, Iteration 229/250, Loss: 0.0123\n",
      "Epoch 78/200, Iteration 230/250, Loss: 0.0192\n",
      "Epoch 78/200, Iteration 231/250, Loss: 0.0087\n",
      "Epoch 78/200, Iteration 232/250, Loss: 0.0161\n",
      "Epoch 78/200, Iteration 233/250, Loss: 0.0168\n",
      "Epoch 78/200, Iteration 234/250, Loss: 0.0191\n",
      "Epoch 78/200, Iteration 235/250, Loss: 0.0120\n",
      "Epoch 78/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 78/200, Iteration 237/250, Loss: 0.0206\n",
      "Epoch 78/200, Iteration 238/250, Loss: 0.0199\n",
      "Epoch 78/200, Iteration 239/250, Loss: 0.0228\n",
      "Epoch 78/200, Iteration 240/250, Loss: 0.0165\n",
      "Epoch 78/200, Iteration 241/250, Loss: 0.0273\n",
      "Epoch 78/200, Iteration 242/250, Loss: 0.0119\n",
      "Epoch 78/200, Iteration 243/250, Loss: 0.0129\n",
      "Epoch 78/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 78/200, Iteration 245/250, Loss: 0.0231\n",
      "Epoch 78/200, Iteration 246/250, Loss: 0.0236\n",
      "Epoch 78/200, Iteration 247/250, Loss: 0.0068\n",
      "Epoch 78/200, Iteration 248/250, Loss: 0.0117\n",
      "Epoch 78/200, Iteration 249/250, Loss: 0.0075\n",
      "Epoch 78/200, Iteration 250/250, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 93.05%, Avg loss: 0.007200, MRE: 0.459427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.007932, MRE: 0.595096 \n",
      "\n",
      "Epoch 79/200, Iteration 1/250, Loss: 0.0123\n",
      "Epoch 79/200, Iteration 2/250, Loss: 0.0087\n",
      "Epoch 79/200, Iteration 3/250, Loss: 0.0160\n",
      "Epoch 79/200, Iteration 4/250, Loss: 0.0076\n",
      "Epoch 79/200, Iteration 5/250, Loss: 0.0306\n",
      "Epoch 79/200, Iteration 6/250, Loss: 0.0150\n",
      "Epoch 79/200, Iteration 7/250, Loss: 0.0337\n",
      "Epoch 79/200, Iteration 8/250, Loss: 0.0173\n",
      "Epoch 79/200, Iteration 9/250, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 10/250, Loss: 0.0286\n",
      "Epoch 79/200, Iteration 11/250, Loss: 0.0372\n",
      "Epoch 79/200, Iteration 12/250, Loss: 0.0090\n",
      "Epoch 79/200, Iteration 13/250, Loss: 0.0068\n",
      "Epoch 79/200, Iteration 14/250, Loss: 0.0132\n",
      "Epoch 79/200, Iteration 15/250, Loss: 0.0197\n",
      "Epoch 79/200, Iteration 16/250, Loss: 0.0167\n",
      "Epoch 79/200, Iteration 17/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 18/250, Loss: 0.0317\n",
      "Epoch 79/200, Iteration 19/250, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200, Iteration 20/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 21/250, Loss: 0.0085\n",
      "Epoch 79/200, Iteration 22/250, Loss: 0.0362\n",
      "Epoch 79/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 79/200, Iteration 24/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 25/250, Loss: 0.0100\n",
      "Epoch 79/200, Iteration 26/250, Loss: 0.0079\n",
      "Epoch 79/200, Iteration 27/250, Loss: 0.0233\n",
      "Epoch 79/200, Iteration 28/250, Loss: 0.0120\n",
      "Epoch 79/200, Iteration 29/250, Loss: 0.0102\n",
      "Epoch 79/200, Iteration 30/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 31/250, Loss: 0.0254\n",
      "Epoch 79/200, Iteration 32/250, Loss: 0.0222\n",
      "Epoch 79/200, Iteration 33/250, Loss: 0.0312\n",
      "Epoch 79/200, Iteration 34/250, Loss: 0.0237\n",
      "Epoch 79/200, Iteration 35/250, Loss: 0.0111\n",
      "Epoch 79/200, Iteration 36/250, Loss: 0.0268\n",
      "Epoch 79/200, Iteration 37/250, Loss: 0.0149\n",
      "Epoch 79/200, Iteration 38/250, Loss: 0.0170\n",
      "Epoch 79/200, Iteration 39/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 40/250, Loss: 0.0240\n",
      "Epoch 79/200, Iteration 41/250, Loss: 0.0102\n",
      "Epoch 79/200, Iteration 42/250, Loss: 0.0079\n",
      "Epoch 79/200, Iteration 43/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 44/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 45/250, Loss: 0.0355\n",
      "Epoch 79/200, Iteration 46/250, Loss: 0.0115\n",
      "Epoch 79/200, Iteration 47/250, Loss: 0.0079\n",
      "Epoch 79/200, Iteration 48/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 49/250, Loss: 0.0085\n",
      "Epoch 79/200, Iteration 50/250, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 51/250, Loss: 0.0057\n",
      "Epoch 79/200, Iteration 52/250, Loss: 0.0108\n",
      "Epoch 79/200, Iteration 53/250, Loss: 0.0238\n",
      "Epoch 79/200, Iteration 54/250, Loss: 0.0138\n",
      "Epoch 79/200, Iteration 55/250, Loss: 0.0278\n",
      "Epoch 79/200, Iteration 56/250, Loss: 0.0261\n",
      "Epoch 79/200, Iteration 57/250, Loss: 0.0251\n",
      "Epoch 79/200, Iteration 58/250, Loss: 0.0155\n",
      "Epoch 79/200, Iteration 59/250, Loss: 0.0107\n",
      "Epoch 79/200, Iteration 60/250, Loss: 0.0093\n",
      "Epoch 79/200, Iteration 61/250, Loss: 0.0084\n",
      "Epoch 79/200, Iteration 62/250, Loss: 0.0318\n",
      "Epoch 79/200, Iteration 63/250, Loss: 0.0178\n",
      "Epoch 79/200, Iteration 64/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 65/250, Loss: 0.0171\n",
      "Epoch 79/200, Iteration 66/250, Loss: 0.0165\n",
      "Epoch 79/200, Iteration 67/250, Loss: 0.0493\n",
      "Epoch 79/200, Iteration 68/250, Loss: 0.0137\n",
      "Epoch 79/200, Iteration 69/250, Loss: 0.0225\n",
      "Epoch 79/200, Iteration 70/250, Loss: 0.0082\n",
      "Epoch 79/200, Iteration 71/250, Loss: 0.0208\n",
      "Epoch 79/200, Iteration 72/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 73/250, Loss: 0.0119\n",
      "Epoch 79/200, Iteration 74/250, Loss: 0.0089\n",
      "Epoch 79/200, Iteration 75/250, Loss: 0.0123\n",
      "Epoch 79/200, Iteration 76/250, Loss: 0.0109\n",
      "Epoch 79/200, Iteration 77/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 78/250, Loss: 0.0124\n",
      "Epoch 79/200, Iteration 79/250, Loss: 0.0123\n",
      "Epoch 79/200, Iteration 80/250, Loss: 0.0154\n",
      "Epoch 79/200, Iteration 81/250, Loss: 0.0176\n",
      "Epoch 79/200, Iteration 82/250, Loss: 0.0176\n",
      "Epoch 79/200, Iteration 83/250, Loss: 0.0086\n",
      "Epoch 79/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 79/200, Iteration 85/250, Loss: 0.0158\n",
      "Epoch 79/200, Iteration 86/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 79/200, Iteration 88/250, Loss: 0.0212\n",
      "Epoch 79/200, Iteration 89/250, Loss: 0.0166\n",
      "Epoch 79/200, Iteration 90/250, Loss: 0.0405\n",
      "Epoch 79/200, Iteration 91/250, Loss: 0.0099\n",
      "Epoch 79/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 93/250, Loss: 0.0158\n",
      "Epoch 79/200, Iteration 94/250, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 95/250, Loss: 0.0157\n",
      "Epoch 79/200, Iteration 96/250, Loss: 0.0137\n",
      "Epoch 79/200, Iteration 97/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 98/250, Loss: 0.0284\n",
      "Epoch 79/200, Iteration 99/250, Loss: 0.0264\n",
      "Epoch 79/200, Iteration 100/250, Loss: 0.0312\n",
      "Epoch 79/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 79/200, Iteration 102/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 103/250, Loss: 0.0240\n",
      "Epoch 79/200, Iteration 104/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 105/250, Loss: 0.0081\n",
      "Epoch 79/200, Iteration 106/250, Loss: 0.0121\n",
      "Epoch 79/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 79/200, Iteration 108/250, Loss: 0.0120\n",
      "Epoch 79/200, Iteration 109/250, Loss: 0.0203\n",
      "Epoch 79/200, Iteration 110/250, Loss: 0.0165\n",
      "Epoch 79/200, Iteration 111/250, Loss: 0.0146\n",
      "Epoch 79/200, Iteration 112/250, Loss: 0.0399\n",
      "Epoch 79/200, Iteration 113/250, Loss: 0.0163\n",
      "Epoch 79/200, Iteration 114/250, Loss: 0.0287\n",
      "Epoch 79/200, Iteration 115/250, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 116/250, Loss: 0.0144\n",
      "Epoch 79/200, Iteration 117/250, Loss: 0.0149\n",
      "Epoch 79/200, Iteration 118/250, Loss: 0.0176\n",
      "Epoch 79/200, Iteration 119/250, Loss: 0.0154\n",
      "Epoch 79/200, Iteration 120/250, Loss: 0.0368\n",
      "Epoch 79/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 79/200, Iteration 122/250, Loss: 0.0114\n",
      "Epoch 79/200, Iteration 123/250, Loss: 0.0138\n",
      "Epoch 79/200, Iteration 124/250, Loss: 0.0266\n",
      "Epoch 79/200, Iteration 125/250, Loss: 0.0126\n",
      "Epoch 79/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 79/200, Iteration 127/250, Loss: 0.0118\n",
      "Epoch 79/200, Iteration 128/250, Loss: 0.0083\n",
      "Epoch 79/200, Iteration 129/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 130/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 131/250, Loss: 0.0227\n",
      "Epoch 79/200, Iteration 132/250, Loss: 0.0114\n",
      "Epoch 79/200, Iteration 133/250, Loss: 0.0084\n",
      "Epoch 79/200, Iteration 134/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 135/250, Loss: 0.0124\n",
      "Epoch 79/200, Iteration 136/250, Loss: 0.0227\n",
      "Epoch 79/200, Iteration 137/250, Loss: 0.0068\n",
      "Epoch 79/200, Iteration 138/250, Loss: 0.0382\n",
      "Epoch 79/200, Iteration 139/250, Loss: 0.0062\n",
      "Epoch 79/200, Iteration 140/250, Loss: 0.0090\n",
      "Epoch 79/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 79/200, Iteration 142/250, Loss: 0.0117\n",
      "Epoch 79/200, Iteration 143/250, Loss: 0.0091\n",
      "Epoch 79/200, Iteration 144/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 145/250, Loss: 0.0099\n",
      "Epoch 79/200, Iteration 146/250, Loss: 0.0176\n",
      "Epoch 79/200, Iteration 147/250, Loss: 0.0144\n",
      "Epoch 79/200, Iteration 148/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 149/250, Loss: 0.0228\n",
      "Epoch 79/200, Iteration 150/250, Loss: 0.0194\n",
      "Epoch 79/200, Iteration 151/250, Loss: 0.0151\n",
      "Epoch 79/200, Iteration 152/250, Loss: 0.0103\n",
      "Epoch 79/200, Iteration 153/250, Loss: 0.0137\n",
      "Epoch 79/200, Iteration 154/250, Loss: 0.0083\n",
      "Epoch 79/200, Iteration 155/250, Loss: 0.0219\n",
      "Epoch 79/200, Iteration 156/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 157/250, Loss: 0.0286\n",
      "Epoch 79/200, Iteration 158/250, Loss: 0.0133\n",
      "Epoch 79/200, Iteration 159/250, Loss: 0.0150\n",
      "Epoch 79/200, Iteration 160/250, Loss: 0.0282\n",
      "Epoch 79/200, Iteration 161/250, Loss: 0.0140\n",
      "Epoch 79/200, Iteration 162/250, Loss: 0.0139\n",
      "Epoch 79/200, Iteration 163/250, Loss: 0.0164\n",
      "Epoch 79/200, Iteration 164/250, Loss: 0.0195\n",
      "Epoch 79/200, Iteration 165/250, Loss: 0.0102\n",
      "Epoch 79/200, Iteration 166/250, Loss: 0.0110\n",
      "Epoch 79/200, Iteration 167/250, Loss: 0.0152\n",
      "Epoch 79/200, Iteration 168/250, Loss: 0.0183\n",
      "Epoch 79/200, Iteration 169/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 171/250, Loss: 0.0114\n",
      "Epoch 79/200, Iteration 172/250, Loss: 0.0261\n",
      "Epoch 79/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 79/200, Iteration 174/250, Loss: 0.0101\n",
      "Epoch 79/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 79/200, Iteration 176/250, Loss: 0.0130\n",
      "Epoch 79/200, Iteration 177/250, Loss: 0.0112\n",
      "Epoch 79/200, Iteration 178/250, Loss: 0.0096\n",
      "Epoch 79/200, Iteration 179/250, Loss: 0.0094\n",
      "Epoch 79/200, Iteration 180/250, Loss: 0.0359\n",
      "Epoch 79/200, Iteration 181/250, Loss: 0.0216\n",
      "Epoch 79/200, Iteration 182/250, Loss: 0.0248\n",
      "Epoch 79/200, Iteration 183/250, Loss: 0.0189\n",
      "Epoch 79/200, Iteration 184/250, Loss: 0.0213\n",
      "Epoch 79/200, Iteration 185/250, Loss: 0.0135\n",
      "Epoch 79/200, Iteration 186/250, Loss: 0.0076\n",
      "Epoch 79/200, Iteration 187/250, Loss: 0.0194\n",
      "Epoch 79/200, Iteration 188/250, Loss: 0.0118\n",
      "Epoch 79/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 79/200, Iteration 190/250, Loss: 0.0079\n",
      "Epoch 79/200, Iteration 191/250, Loss: 0.0073\n",
      "Epoch 79/200, Iteration 192/250, Loss: 0.0138\n",
      "Epoch 79/200, Iteration 193/250, Loss: 0.0168\n",
      "Epoch 79/200, Iteration 194/250, Loss: 0.0270\n",
      "Epoch 79/200, Iteration 195/250, Loss: 0.0150\n",
      "Epoch 79/200, Iteration 196/250, Loss: 0.0119\n",
      "Epoch 79/200, Iteration 197/250, Loss: 0.0059\n",
      "Epoch 79/200, Iteration 198/250, Loss: 0.0184\n",
      "Epoch 79/200, Iteration 199/250, Loss: 0.0348\n",
      "Epoch 79/200, Iteration 200/250, Loss: 0.0182\n",
      "Epoch 79/200, Iteration 201/250, Loss: 0.0100\n",
      "Epoch 79/200, Iteration 202/250, Loss: 0.0149\n",
      "Epoch 79/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 204/250, Loss: 0.0311\n",
      "Epoch 79/200, Iteration 205/250, Loss: 0.0175\n",
      "Epoch 79/200, Iteration 206/250, Loss: 0.0191\n",
      "Epoch 79/200, Iteration 207/250, Loss: 0.0380\n",
      "Epoch 79/200, Iteration 208/250, Loss: 0.0141\n",
      "Epoch 79/200, Iteration 209/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 210/250, Loss: 0.0321\n",
      "Epoch 79/200, Iteration 211/250, Loss: 0.0093\n",
      "Epoch 79/200, Iteration 212/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 213/250, Loss: 0.0246\n",
      "Epoch 79/200, Iteration 214/250, Loss: 0.0131\n",
      "Epoch 79/200, Iteration 215/250, Loss: 0.0227\n",
      "Epoch 79/200, Iteration 216/250, Loss: 0.0278\n",
      "Epoch 79/200, Iteration 217/250, Loss: 0.0126\n",
      "Epoch 79/200, Iteration 218/250, Loss: 0.0104\n",
      "Epoch 79/200, Iteration 219/250, Loss: 0.0092\n",
      "Epoch 79/200, Iteration 220/250, Loss: 0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 222/250, Loss: 0.0203\n",
      "Epoch 79/200, Iteration 223/250, Loss: 0.0235\n",
      "Epoch 79/200, Iteration 224/250, Loss: 0.0088\n",
      "Epoch 79/200, Iteration 225/250, Loss: 0.0412\n",
      "Epoch 79/200, Iteration 226/250, Loss: 0.0125\n",
      "Epoch 79/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 79/200, Iteration 228/250, Loss: 0.0265\n",
      "Epoch 79/200, Iteration 229/250, Loss: 0.0076\n",
      "Epoch 79/200, Iteration 230/250, Loss: 0.0305\n",
      "Epoch 79/200, Iteration 231/250, Loss: 0.0154\n",
      "Epoch 79/200, Iteration 232/250, Loss: 0.0241\n",
      "Epoch 79/200, Iteration 233/250, Loss: 0.0219\n",
      "Epoch 79/200, Iteration 234/250, Loss: 0.0083\n",
      "Epoch 79/200, Iteration 235/250, Loss: 0.0116\n",
      "Epoch 79/200, Iteration 236/250, Loss: 0.0139\n",
      "Epoch 79/200, Iteration 237/250, Loss: 0.0256\n",
      "Epoch 79/200, Iteration 238/250, Loss: 0.0116\n",
      "Epoch 79/200, Iteration 239/250, Loss: 0.0113\n",
      "Epoch 79/200, Iteration 240/250, Loss: 0.0121\n",
      "Epoch 79/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 79/200, Iteration 242/250, Loss: 0.0098\n",
      "Epoch 79/200, Iteration 243/250, Loss: 0.0145\n",
      "Epoch 79/200, Iteration 244/250, Loss: 0.0117\n",
      "Epoch 79/200, Iteration 245/250, Loss: 0.0412\n",
      "Epoch 79/200, Iteration 246/250, Loss: 0.0101\n",
      "Epoch 79/200, Iteration 247/250, Loss: 0.0493\n",
      "Epoch 79/200, Iteration 248/250, Loss: 0.0143\n",
      "Epoch 79/200, Iteration 249/250, Loss: 0.0151\n",
      "Epoch 79/200, Iteration 250/250, Loss: 0.0281\n",
      "Train Error: \n",
      " Accuracy: 73.65%, Avg loss: 0.008034, MRE: 0.604276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.25%, Avg loss: 0.008381, MRE: 0.713989 \n",
      "\n",
      "Epoch 80/200, Iteration 1/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 2/250, Loss: 0.0174\n",
      "Epoch 80/200, Iteration 3/250, Loss: 0.0213\n",
      "Epoch 80/200, Iteration 4/250, Loss: 0.0105\n",
      "Epoch 80/200, Iteration 5/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 7/250, Loss: 0.0213\n",
      "Epoch 80/200, Iteration 8/250, Loss: 0.0389\n",
      "Epoch 80/200, Iteration 9/250, Loss: 0.0122\n",
      "Epoch 80/200, Iteration 10/250, Loss: 0.0128\n",
      "Epoch 80/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 12/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 13/250, Loss: 0.0068\n",
      "Epoch 80/200, Iteration 14/250, Loss: 0.0071\n",
      "Epoch 80/200, Iteration 15/250, Loss: 0.0194\n",
      "Epoch 80/200, Iteration 16/250, Loss: 0.0353\n",
      "Epoch 80/200, Iteration 17/250, Loss: 0.0483\n",
      "Epoch 80/200, Iteration 18/250, Loss: 0.0161\n",
      "Epoch 80/200, Iteration 19/250, Loss: 0.0189\n",
      "Epoch 80/200, Iteration 20/250, Loss: 0.0116\n",
      "Epoch 80/200, Iteration 21/250, Loss: 0.0372\n",
      "Epoch 80/200, Iteration 22/250, Loss: 0.0093\n",
      "Epoch 80/200, Iteration 23/250, Loss: 0.0238\n",
      "Epoch 80/200, Iteration 24/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 25/250, Loss: 0.0216\n",
      "Epoch 80/200, Iteration 26/250, Loss: 0.0114\n",
      "Epoch 80/200, Iteration 27/250, Loss: 0.0197\n",
      "Epoch 80/200, Iteration 28/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 29/250, Loss: 0.0105\n",
      "Epoch 80/200, Iteration 30/250, Loss: 0.0147\n",
      "Epoch 80/200, Iteration 31/250, Loss: 0.0195\n",
      "Epoch 80/200, Iteration 32/250, Loss: 0.0258\n",
      "Epoch 80/200, Iteration 33/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 34/250, Loss: 0.0077\n",
      "Epoch 80/200, Iteration 35/250, Loss: 0.0247\n",
      "Epoch 80/200, Iteration 36/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 37/250, Loss: 0.0321\n",
      "Epoch 80/200, Iteration 38/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 39/250, Loss: 0.0134\n",
      "Epoch 80/200, Iteration 40/250, Loss: 0.0118\n",
      "Epoch 80/200, Iteration 41/250, Loss: 0.0142\n",
      "Epoch 80/200, Iteration 42/250, Loss: 0.0177\n",
      "Epoch 80/200, Iteration 43/250, Loss: 0.0118\n",
      "Epoch 80/200, Iteration 44/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 45/250, Loss: 0.0136\n",
      "Epoch 80/200, Iteration 46/250, Loss: 0.0362\n",
      "Epoch 80/200, Iteration 47/250, Loss: 0.0106\n",
      "Epoch 80/200, Iteration 48/250, Loss: 0.0148\n",
      "Epoch 80/200, Iteration 49/250, Loss: 0.0123\n",
      "Epoch 80/200, Iteration 50/250, Loss: 0.0467\n",
      "Epoch 80/200, Iteration 51/250, Loss: 0.0169\n",
      "Epoch 80/200, Iteration 52/250, Loss: 0.0280\n",
      "Epoch 80/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 80/200, Iteration 54/250, Loss: 0.0110\n",
      "Epoch 80/200, Iteration 55/250, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 56/250, Loss: 0.0189\n",
      "Epoch 80/200, Iteration 57/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 58/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 59/250, Loss: 0.0222\n",
      "Epoch 80/200, Iteration 60/250, Loss: 0.0135\n",
      "Epoch 80/200, Iteration 61/250, Loss: 0.0128\n",
      "Epoch 80/200, Iteration 62/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 63/250, Loss: 0.0079\n",
      "Epoch 80/200, Iteration 64/250, Loss: 0.0168\n",
      "Epoch 80/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 80/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 67/250, Loss: 0.0080\n",
      "Epoch 80/200, Iteration 68/250, Loss: 0.0070\n",
      "Epoch 80/200, Iteration 69/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 70/250, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 71/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 72/250, Loss: 0.0235\n",
      "Epoch 80/200, Iteration 73/250, Loss: 0.0221\n",
      "Epoch 80/200, Iteration 74/250, Loss: 0.0060\n",
      "Epoch 80/200, Iteration 75/250, Loss: 0.0329\n",
      "Epoch 80/200, Iteration 76/250, Loss: 0.0085\n",
      "Epoch 80/200, Iteration 77/250, Loss: 0.0176\n",
      "Epoch 80/200, Iteration 78/250, Loss: 0.0443\n",
      "Epoch 80/200, Iteration 79/250, Loss: 0.0073\n",
      "Epoch 80/200, Iteration 80/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 81/250, Loss: 0.0102\n",
      "Epoch 80/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 80/200, Iteration 83/250, Loss: 0.0170\n",
      "Epoch 80/200, Iteration 84/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 85/250, Loss: 0.0097\n",
      "Epoch 80/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 80/200, Iteration 87/250, Loss: 0.0105\n",
      "Epoch 80/200, Iteration 88/250, Loss: 0.0230\n",
      "Epoch 80/200, Iteration 89/250, Loss: 0.0077\n",
      "Epoch 80/200, Iteration 90/250, Loss: 0.0061\n",
      "Epoch 80/200, Iteration 91/250, Loss: 0.0169\n",
      "Epoch 80/200, Iteration 92/250, Loss: 0.0074\n",
      "Epoch 80/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 80/200, Iteration 94/250, Loss: 0.0186\n",
      "Epoch 80/200, Iteration 95/250, Loss: 0.0196\n",
      "Epoch 80/200, Iteration 96/250, Loss: 0.0092\n",
      "Epoch 80/200, Iteration 97/250, Loss: 0.0166\n",
      "Epoch 80/200, Iteration 98/250, Loss: 0.0235\n",
      "Epoch 80/200, Iteration 99/250, Loss: 0.0098\n",
      "Epoch 80/200, Iteration 100/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 101/250, Loss: 0.0180\n",
      "Epoch 80/200, Iteration 102/250, Loss: 0.0145\n",
      "Epoch 80/200, Iteration 103/250, Loss: 0.0198\n",
      "Epoch 80/200, Iteration 104/250, Loss: 0.0072\n",
      "Epoch 80/200, Iteration 105/250, Loss: 0.0254\n",
      "Epoch 80/200, Iteration 106/250, Loss: 0.0117\n",
      "Epoch 80/200, Iteration 107/250, Loss: 0.0275\n",
      "Epoch 80/200, Iteration 108/250, Loss: 0.0087\n",
      "Epoch 80/200, Iteration 109/250, Loss: 0.0084\n",
      "Epoch 80/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 80/200, Iteration 111/250, Loss: 0.0166\n",
      "Epoch 80/200, Iteration 112/250, Loss: 0.0086\n",
      "Epoch 80/200, Iteration 113/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 114/250, Loss: 0.0271\n",
      "Epoch 80/200, Iteration 115/250, Loss: 0.0095\n",
      "Epoch 80/200, Iteration 116/250, Loss: 0.0222\n",
      "Epoch 80/200, Iteration 117/250, Loss: 0.0087\n",
      "Epoch 80/200, Iteration 118/250, Loss: 0.0108\n",
      "Epoch 80/200, Iteration 119/250, Loss: 0.0265\n",
      "Epoch 80/200, Iteration 120/250, Loss: 0.0134\n",
      "Epoch 80/200, Iteration 121/250, Loss: 0.0206\n",
      "Epoch 80/200, Iteration 122/250, Loss: 0.0197\n",
      "Epoch 80/200, Iteration 123/250, Loss: 0.0113\n",
      "Epoch 80/200, Iteration 124/250, Loss: 0.0117\n",
      "Epoch 80/200, Iteration 125/250, Loss: 0.0230\n",
      "Epoch 80/200, Iteration 126/250, Loss: 0.0095\n",
      "Epoch 80/200, Iteration 127/250, Loss: 0.0116\n",
      "Epoch 80/200, Iteration 128/250, Loss: 0.0201\n",
      "Epoch 80/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 80/200, Iteration 130/250, Loss: 0.0261\n",
      "Epoch 80/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 80/200, Iteration 132/250, Loss: 0.0119\n",
      "Epoch 80/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 80/200, Iteration 134/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 135/250, Loss: 0.0110\n",
      "Epoch 80/200, Iteration 136/250, Loss: 0.0113\n",
      "Epoch 80/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 80/200, Iteration 138/250, Loss: 0.0200\n",
      "Epoch 80/200, Iteration 139/250, Loss: 0.0122\n",
      "Epoch 80/200, Iteration 140/250, Loss: 0.0206\n",
      "Epoch 80/200, Iteration 141/250, Loss: 0.0075\n",
      "Epoch 80/200, Iteration 142/250, Loss: 0.0143\n",
      "Epoch 80/200, Iteration 143/250, Loss: 0.0117\n",
      "Epoch 80/200, Iteration 144/250, Loss: 0.0139\n",
      "Epoch 80/200, Iteration 145/250, Loss: 0.0163\n",
      "Epoch 80/200, Iteration 146/250, Loss: 0.0089\n",
      "Epoch 80/200, Iteration 147/250, Loss: 0.0176\n",
      "Epoch 80/200, Iteration 148/250, Loss: 0.0113\n",
      "Epoch 80/200, Iteration 149/250, Loss: 0.0224\n",
      "Epoch 80/200, Iteration 150/250, Loss: 0.0132\n",
      "Epoch 80/200, Iteration 151/250, Loss: 0.0110\n",
      "Epoch 80/200, Iteration 152/250, Loss: 0.0156\n",
      "Epoch 80/200, Iteration 153/250, Loss: 0.0259\n",
      "Epoch 80/200, Iteration 154/250, Loss: 0.0155\n",
      "Epoch 80/200, Iteration 155/250, Loss: 0.0158\n",
      "Epoch 80/200, Iteration 156/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 157/250, Loss: 0.0101\n",
      "Epoch 80/200, Iteration 158/250, Loss: 0.0111\n",
      "Epoch 80/200, Iteration 159/250, Loss: 0.0139\n",
      "Epoch 80/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 80/200, Iteration 161/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 162/250, Loss: 0.0101\n",
      "Epoch 80/200, Iteration 163/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 164/250, Loss: 0.0165\n",
      "Epoch 80/200, Iteration 165/250, Loss: 0.0199\n",
      "Epoch 80/200, Iteration 166/250, Loss: 0.0162\n",
      "Epoch 80/200, Iteration 167/250, Loss: 0.0102\n",
      "Epoch 80/200, Iteration 168/250, Loss: 0.0114\n",
      "Epoch 80/200, Iteration 169/250, Loss: 0.0094\n",
      "Epoch 80/200, Iteration 170/250, Loss: 0.0190\n",
      "Epoch 80/200, Iteration 171/250, Loss: 0.0151\n",
      "Epoch 80/200, Iteration 172/250, Loss: 0.0221\n",
      "Epoch 80/200, Iteration 173/250, Loss: 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200, Iteration 174/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 175/250, Loss: 0.0217\n",
      "Epoch 80/200, Iteration 176/250, Loss: 0.0073\n",
      "Epoch 80/200, Iteration 177/250, Loss: 0.0100\n",
      "Epoch 80/200, Iteration 178/250, Loss: 0.0142\n",
      "Epoch 80/200, Iteration 179/250, Loss: 0.0170\n",
      "Epoch 80/200, Iteration 180/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 181/250, Loss: 0.0115\n",
      "Epoch 80/200, Iteration 182/250, Loss: 0.0177\n",
      "Epoch 80/200, Iteration 183/250, Loss: 0.0157\n",
      "Epoch 80/200, Iteration 184/250, Loss: 0.0112\n",
      "Epoch 80/200, Iteration 185/250, Loss: 0.0127\n",
      "Epoch 80/200, Iteration 186/250, Loss: 0.0088\n",
      "Epoch 80/200, Iteration 187/250, Loss: 0.0171\n",
      "Epoch 80/200, Iteration 188/250, Loss: 0.0359\n",
      "Epoch 80/200, Iteration 189/250, Loss: 0.0097\n",
      "Epoch 80/200, Iteration 190/250, Loss: 0.0081\n",
      "Epoch 80/200, Iteration 191/250, Loss: 0.0169\n",
      "Epoch 80/200, Iteration 192/250, Loss: 0.0078\n",
      "Epoch 80/200, Iteration 193/250, Loss: 0.0133\n",
      "Epoch 80/200, Iteration 194/250, Loss: 0.0127\n",
      "Epoch 80/200, Iteration 195/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 196/250, Loss: 0.0160\n",
      "Epoch 80/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 80/200, Iteration 198/250, Loss: 0.0145\n",
      "Epoch 80/200, Iteration 199/250, Loss: 0.0194\n",
      "Epoch 80/200, Iteration 200/250, Loss: 0.0082\n",
      "Epoch 80/200, Iteration 201/250, Loss: 0.0177\n",
      "Epoch 80/200, Iteration 202/250, Loss: 0.0154\n",
      "Epoch 80/200, Iteration 203/250, Loss: 0.0285\n",
      "Epoch 80/200, Iteration 204/250, Loss: 0.0271\n",
      "Epoch 80/200, Iteration 205/250, Loss: 0.0235\n",
      "Epoch 80/200, Iteration 206/250, Loss: 0.0102\n",
      "Epoch 80/200, Iteration 207/250, Loss: 0.0092\n",
      "Epoch 80/200, Iteration 208/250, Loss: 0.0212\n",
      "Epoch 80/200, Iteration 209/250, Loss: 0.0167\n",
      "Epoch 80/200, Iteration 210/250, Loss: 0.0250\n",
      "Epoch 80/200, Iteration 211/250, Loss: 0.0264\n",
      "Epoch 80/200, Iteration 212/250, Loss: 0.0084\n",
      "Epoch 80/200, Iteration 213/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 214/250, Loss: 0.0153\n",
      "Epoch 80/200, Iteration 215/250, Loss: 0.0131\n",
      "Epoch 80/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 80/200, Iteration 217/250, Loss: 0.0247\n",
      "Epoch 80/200, Iteration 218/250, Loss: 0.0061\n",
      "Epoch 80/200, Iteration 219/250, Loss: 0.0180\n",
      "Epoch 80/200, Iteration 220/250, Loss: 0.0188\n",
      "Epoch 80/200, Iteration 221/250, Loss: 0.0125\n",
      "Epoch 80/200, Iteration 222/250, Loss: 0.0120\n",
      "Epoch 80/200, Iteration 223/250, Loss: 0.0149\n",
      "Epoch 80/200, Iteration 224/250, Loss: 0.0279\n",
      "Epoch 80/200, Iteration 225/250, Loss: 0.0241\n",
      "Epoch 80/200, Iteration 226/250, Loss: 0.0162\n",
      "Epoch 80/200, Iteration 227/250, Loss: 0.0232\n",
      "Epoch 80/200, Iteration 228/250, Loss: 0.0165\n",
      "Epoch 80/200, Iteration 229/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 230/250, Loss: 0.0070\n",
      "Epoch 80/200, Iteration 231/250, Loss: 0.0118\n",
      "Epoch 80/200, Iteration 232/250, Loss: 0.0228\n",
      "Epoch 80/200, Iteration 233/250, Loss: 0.0152\n",
      "Epoch 80/200, Iteration 234/250, Loss: 0.0181\n",
      "Epoch 80/200, Iteration 235/250, Loss: 0.0097\n",
      "Epoch 80/200, Iteration 236/250, Loss: 0.0223\n",
      "Epoch 80/200, Iteration 237/250, Loss: 0.0140\n",
      "Epoch 80/200, Iteration 238/250, Loss: 0.0228\n",
      "Epoch 80/200, Iteration 239/250, Loss: 0.0171\n",
      "Epoch 80/200, Iteration 240/250, Loss: 0.0260\n",
      "Epoch 80/200, Iteration 241/250, Loss: 0.0319\n",
      "Epoch 80/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 80/200, Iteration 243/250, Loss: 0.0130\n",
      "Epoch 80/200, Iteration 244/250, Loss: 0.0151\n",
      "Epoch 80/200, Iteration 245/250, Loss: 0.0090\n",
      "Epoch 80/200, Iteration 246/250, Loss: 0.0146\n",
      "Epoch 80/200, Iteration 247/250, Loss: 0.0146\n",
      "Epoch 80/200, Iteration 248/250, Loss: 0.0238\n",
      "Epoch 80/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 80/200, Iteration 250/250, Loss: 0.0135\n",
      "Train Error: \n",
      " Accuracy: 83.16%, Avg loss: 0.007065, MRE: 0.499388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.007473, MRE: 0.607518 \n",
      "\n",
      "Epoch 81/200, Iteration 1/250, Loss: 0.0168\n",
      "Epoch 81/200, Iteration 2/250, Loss: 0.0198\n",
      "Epoch 81/200, Iteration 3/250, Loss: 0.0218\n",
      "Epoch 81/200, Iteration 4/250, Loss: 0.0136\n",
      "Epoch 81/200, Iteration 5/250, Loss: 0.0143\n",
      "Epoch 81/200, Iteration 6/250, Loss: 0.0111\n",
      "Epoch 81/200, Iteration 7/250, Loss: 0.0275\n",
      "Epoch 81/200, Iteration 8/250, Loss: 0.0228\n",
      "Epoch 81/200, Iteration 9/250, Loss: 0.0114\n",
      "Epoch 81/200, Iteration 10/250, Loss: 0.0076\n",
      "Epoch 81/200, Iteration 11/250, Loss: 0.0127\n",
      "Epoch 81/200, Iteration 12/250, Loss: 0.0128\n",
      "Epoch 81/200, Iteration 13/250, Loss: 0.0218\n",
      "Epoch 81/200, Iteration 14/250, Loss: 0.0234\n",
      "Epoch 81/200, Iteration 15/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 16/250, Loss: 0.0132\n",
      "Epoch 81/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 81/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 81/200, Iteration 19/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 20/250, Loss: 0.0147\n",
      "Epoch 81/200, Iteration 21/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 22/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 23/250, Loss: 0.0130\n",
      "Epoch 81/200, Iteration 24/250, Loss: 0.0348\n",
      "Epoch 81/200, Iteration 25/250, Loss: 0.0243\n",
      "Epoch 81/200, Iteration 26/250, Loss: 0.0176\n",
      "Epoch 81/200, Iteration 27/250, Loss: 0.0182\n",
      "Epoch 81/200, Iteration 28/250, Loss: 0.0117\n",
      "Epoch 81/200, Iteration 29/250, Loss: 0.0153\n",
      "Epoch 81/200, Iteration 30/250, Loss: 0.0097\n",
      "Epoch 81/200, Iteration 31/250, Loss: 0.0102\n",
      "Epoch 81/200, Iteration 32/250, Loss: 0.0169\n",
      "Epoch 81/200, Iteration 33/250, Loss: 0.0085\n",
      "Epoch 81/200, Iteration 34/250, Loss: 0.0164\n",
      "Epoch 81/200, Iteration 35/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 36/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 37/250, Loss: 0.0218\n",
      "Epoch 81/200, Iteration 38/250, Loss: 0.0088\n",
      "Epoch 81/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 40/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 41/250, Loss: 0.0095\n",
      "Epoch 81/200, Iteration 42/250, Loss: 0.0085\n",
      "Epoch 81/200, Iteration 43/250, Loss: 0.0391\n",
      "Epoch 81/200, Iteration 44/250, Loss: 0.0102\n",
      "Epoch 81/200, Iteration 45/250, Loss: 0.0092\n",
      "Epoch 81/200, Iteration 46/250, Loss: 0.0231\n",
      "Epoch 81/200, Iteration 47/250, Loss: 0.0161\n",
      "Epoch 81/200, Iteration 48/250, Loss: 0.0312\n",
      "Epoch 81/200, Iteration 49/250, Loss: 0.0089\n",
      "Epoch 81/200, Iteration 50/250, Loss: 0.0103\n",
      "Epoch 81/200, Iteration 51/250, Loss: 0.0219\n",
      "Epoch 81/200, Iteration 52/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 53/250, Loss: 0.0180\n",
      "Epoch 81/200, Iteration 54/250, Loss: 0.0071\n",
      "Epoch 81/200, Iteration 55/250, Loss: 0.0146\n",
      "Epoch 81/200, Iteration 56/250, Loss: 0.0133\n",
      "Epoch 81/200, Iteration 57/250, Loss: 0.0286\n",
      "Epoch 81/200, Iteration 58/250, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 59/250, Loss: 0.0075\n",
      "Epoch 81/200, Iteration 60/250, Loss: 0.0331\n",
      "Epoch 81/200, Iteration 61/250, Loss: 0.0158\n",
      "Epoch 81/200, Iteration 62/250, Loss: 0.0117\n",
      "Epoch 81/200, Iteration 63/250, Loss: 0.0068\n",
      "Epoch 81/200, Iteration 64/250, Loss: 0.0091\n",
      "Epoch 81/200, Iteration 65/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 66/250, Loss: 0.0262\n",
      "Epoch 81/200, Iteration 67/250, Loss: 0.0173\n",
      "Epoch 81/200, Iteration 68/250, Loss: 0.0676\n",
      "Epoch 81/200, Iteration 69/250, Loss: 0.0202\n",
      "Epoch 81/200, Iteration 70/250, Loss: 0.0072\n",
      "Epoch 81/200, Iteration 71/250, Loss: 0.0080\n",
      "Epoch 81/200, Iteration 72/250, Loss: 0.0131\n",
      "Epoch 81/200, Iteration 73/250, Loss: 0.0214\n",
      "Epoch 81/200, Iteration 74/250, Loss: 0.0068\n",
      "Epoch 81/200, Iteration 75/250, Loss: 0.0271\n",
      "Epoch 81/200, Iteration 76/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 78/250, Loss: 0.0100\n",
      "Epoch 81/200, Iteration 79/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 80/250, Loss: 0.0081\n",
      "Epoch 81/200, Iteration 81/250, Loss: 0.0160\n",
      "Epoch 81/200, Iteration 82/250, Loss: 0.0096\n",
      "Epoch 81/200, Iteration 83/250, Loss: 0.0403\n",
      "Epoch 81/200, Iteration 84/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 85/250, Loss: 0.0116\n",
      "Epoch 81/200, Iteration 86/250, Loss: 0.0102\n",
      "Epoch 81/200, Iteration 87/250, Loss: 0.0089\n",
      "Epoch 81/200, Iteration 88/250, Loss: 0.0181\n",
      "Epoch 81/200, Iteration 89/250, Loss: 0.0222\n",
      "Epoch 81/200, Iteration 90/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 91/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 92/250, Loss: 0.0256\n",
      "Epoch 81/200, Iteration 93/250, Loss: 0.0137\n",
      "Epoch 81/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 81/200, Iteration 95/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 96/250, Loss: 0.0119\n",
      "Epoch 81/200, Iteration 97/250, Loss: 0.0177\n",
      "Epoch 81/200, Iteration 98/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 99/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 100/250, Loss: 0.0227\n",
      "Epoch 81/200, Iteration 101/250, Loss: 0.0073\n",
      "Epoch 81/200, Iteration 102/250, Loss: 0.0217\n",
      "Epoch 81/200, Iteration 103/250, Loss: 0.0155\n",
      "Epoch 81/200, Iteration 104/250, Loss: 0.0133\n",
      "Epoch 81/200, Iteration 105/250, Loss: 0.0208\n",
      "Epoch 81/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 81/200, Iteration 107/250, Loss: 0.0197\n",
      "Epoch 81/200, Iteration 108/250, Loss: 0.0105\n",
      "Epoch 81/200, Iteration 109/250, Loss: 0.0069\n",
      "Epoch 81/200, Iteration 110/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 111/250, Loss: 0.0240\n",
      "Epoch 81/200, Iteration 112/250, Loss: 0.0248\n",
      "Epoch 81/200, Iteration 113/250, Loss: 0.0300\n",
      "Epoch 81/200, Iteration 114/250, Loss: 0.0108\n",
      "Epoch 81/200, Iteration 115/250, Loss: 0.0186\n",
      "Epoch 81/200, Iteration 116/250, Loss: 0.0164\n",
      "Epoch 81/200, Iteration 117/250, Loss: 0.0146\n",
      "Epoch 81/200, Iteration 118/250, Loss: 0.0146\n",
      "Epoch 81/200, Iteration 119/250, Loss: 0.0200\n",
      "Epoch 81/200, Iteration 120/250, Loss: 0.0064\n",
      "Epoch 81/200, Iteration 121/250, Loss: 0.0073\n",
      "Epoch 81/200, Iteration 122/250, Loss: 0.0174\n",
      "Epoch 81/200, Iteration 123/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 124/250, Loss: 0.0147\n",
      "Epoch 81/200, Iteration 125/250, Loss: 0.0096\n",
      "Epoch 81/200, Iteration 126/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 127/250, Loss: 0.0183\n",
      "Epoch 81/200, Iteration 128/250, Loss: 0.0142\n",
      "Epoch 81/200, Iteration 129/250, Loss: 0.0283\n",
      "Epoch 81/200, Iteration 130/250, Loss: 0.0216\n",
      "Epoch 81/200, Iteration 131/250, Loss: 0.0439\n",
      "Epoch 81/200, Iteration 132/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 133/250, Loss: 0.0232\n",
      "Epoch 81/200, Iteration 134/250, Loss: 0.0095\n",
      "Epoch 81/200, Iteration 135/250, Loss: 0.0302\n",
      "Epoch 81/200, Iteration 136/250, Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200, Iteration 137/250, Loss: 0.0195\n",
      "Epoch 81/200, Iteration 138/250, Loss: 0.0188\n",
      "Epoch 81/200, Iteration 139/250, Loss: 0.0221\n",
      "Epoch 81/200, Iteration 140/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 141/250, Loss: 0.0127\n",
      "Epoch 81/200, Iteration 142/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 143/250, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 144/250, Loss: 0.0186\n",
      "Epoch 81/200, Iteration 145/250, Loss: 0.0124\n",
      "Epoch 81/200, Iteration 146/250, Loss: 0.0200\n",
      "Epoch 81/200, Iteration 147/250, Loss: 0.0220\n",
      "Epoch 81/200, Iteration 148/250, Loss: 0.0111\n",
      "Epoch 81/200, Iteration 149/250, Loss: 0.0066\n",
      "Epoch 81/200, Iteration 150/250, Loss: 0.0104\n",
      "Epoch 81/200, Iteration 151/250, Loss: 0.0103\n",
      "Epoch 81/200, Iteration 152/250, Loss: 0.0232\n",
      "Epoch 81/200, Iteration 153/250, Loss: 0.0114\n",
      "Epoch 81/200, Iteration 154/250, Loss: 0.0098\n",
      "Epoch 81/200, Iteration 155/250, Loss: 0.0082\n",
      "Epoch 81/200, Iteration 156/250, Loss: 0.0086\n",
      "Epoch 81/200, Iteration 157/250, Loss: 0.0135\n",
      "Epoch 81/200, Iteration 158/250, Loss: 0.0219\n",
      "Epoch 81/200, Iteration 159/250, Loss: 0.0091\n",
      "Epoch 81/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 161/250, Loss: 0.0121\n",
      "Epoch 81/200, Iteration 162/250, Loss: 0.0250\n",
      "Epoch 81/200, Iteration 163/250, Loss: 0.0102\n",
      "Epoch 81/200, Iteration 164/250, Loss: 0.0189\n",
      "Epoch 81/200, Iteration 165/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 166/250, Loss: 0.0101\n",
      "Epoch 81/200, Iteration 167/250, Loss: 0.0182\n",
      "Epoch 81/200, Iteration 168/250, Loss: 0.0138\n",
      "Epoch 81/200, Iteration 169/250, Loss: 0.0140\n",
      "Epoch 81/200, Iteration 170/250, Loss: 0.0243\n",
      "Epoch 81/200, Iteration 171/250, Loss: 0.0297\n",
      "Epoch 81/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 81/200, Iteration 173/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 174/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 175/250, Loss: 0.0123\n",
      "Epoch 81/200, Iteration 176/250, Loss: 0.0106\n",
      "Epoch 81/200, Iteration 177/250, Loss: 0.0170\n",
      "Epoch 81/200, Iteration 178/250, Loss: 0.0073\n",
      "Epoch 81/200, Iteration 179/250, Loss: 0.0101\n",
      "Epoch 81/200, Iteration 180/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 181/250, Loss: 0.0386\n",
      "Epoch 81/200, Iteration 182/250, Loss: 0.0232\n",
      "Epoch 81/200, Iteration 183/250, Loss: 0.0143\n",
      "Epoch 81/200, Iteration 184/250, Loss: 0.0142\n",
      "Epoch 81/200, Iteration 185/250, Loss: 0.0109\n",
      "Epoch 81/200, Iteration 186/250, Loss: 0.0266\n",
      "Epoch 81/200, Iteration 187/250, Loss: 0.0223\n",
      "Epoch 81/200, Iteration 188/250, Loss: 0.0073\n",
      "Epoch 81/200, Iteration 189/250, Loss: 0.0460\n",
      "Epoch 81/200, Iteration 190/250, Loss: 0.0324\n",
      "Epoch 81/200, Iteration 191/250, Loss: 0.0202\n",
      "Epoch 81/200, Iteration 192/250, Loss: 0.0266\n",
      "Epoch 81/200, Iteration 193/250, Loss: 0.0360\n",
      "Epoch 81/200, Iteration 194/250, Loss: 0.0245\n",
      "Epoch 81/200, Iteration 195/250, Loss: 0.0084\n",
      "Epoch 81/200, Iteration 196/250, Loss: 0.0097\n",
      "Epoch 81/200, Iteration 197/250, Loss: 0.0391\n",
      "Epoch 81/200, Iteration 198/250, Loss: 0.0076\n",
      "Epoch 81/200, Iteration 199/250, Loss: 0.0083\n",
      "Epoch 81/200, Iteration 200/250, Loss: 0.0161\n",
      "Epoch 81/200, Iteration 201/250, Loss: 0.0221\n",
      "Epoch 81/200, Iteration 202/250, Loss: 0.0112\n",
      "Epoch 81/200, Iteration 203/250, Loss: 0.0129\n",
      "Epoch 81/200, Iteration 204/250, Loss: 0.0074\n",
      "Epoch 81/200, Iteration 205/250, Loss: 0.0150\n",
      "Epoch 81/200, Iteration 206/250, Loss: 0.0211\n",
      "Epoch 81/200, Iteration 207/250, Loss: 0.0260\n",
      "Epoch 81/200, Iteration 208/250, Loss: 0.0081\n",
      "Epoch 81/200, Iteration 209/250, Loss: 0.0180\n",
      "Epoch 81/200, Iteration 210/250, Loss: 0.0268\n",
      "Epoch 81/200, Iteration 211/250, Loss: 0.0203\n",
      "Epoch 81/200, Iteration 212/250, Loss: 0.0126\n",
      "Epoch 81/200, Iteration 213/250, Loss: 0.0118\n",
      "Epoch 81/200, Iteration 214/250, Loss: 0.0184\n",
      "Epoch 81/200, Iteration 215/250, Loss: 0.0154\n",
      "Epoch 81/200, Iteration 216/250, Loss: 0.0095\n",
      "Epoch 81/200, Iteration 217/250, Loss: 0.0288\n",
      "Epoch 81/200, Iteration 218/250, Loss: 0.0112\n",
      "Epoch 81/200, Iteration 219/250, Loss: 0.0324\n",
      "Epoch 81/200, Iteration 220/250, Loss: 0.0087\n",
      "Epoch 81/200, Iteration 221/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 222/250, Loss: 0.0099\n",
      "Epoch 81/200, Iteration 223/250, Loss: 0.0072\n",
      "Epoch 81/200, Iteration 224/250, Loss: 0.0229\n",
      "Epoch 81/200, Iteration 225/250, Loss: 0.0085\n",
      "Epoch 81/200, Iteration 226/250, Loss: 0.0476\n",
      "Epoch 81/200, Iteration 227/250, Loss: 0.0079\n",
      "Epoch 81/200, Iteration 228/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 229/250, Loss: 0.0122\n",
      "Epoch 81/200, Iteration 230/250, Loss: 0.0086\n",
      "Epoch 81/200, Iteration 231/250, Loss: 0.0141\n",
      "Epoch 81/200, Iteration 232/250, Loss: 0.0162\n",
      "Epoch 81/200, Iteration 233/250, Loss: 0.0150\n",
      "Epoch 81/200, Iteration 234/250, Loss: 0.0090\n",
      "Epoch 81/200, Iteration 235/250, Loss: 0.0125\n",
      "Epoch 81/200, Iteration 236/250, Loss: 0.0165\n",
      "Epoch 81/200, Iteration 237/250, Loss: 0.0075\n",
      "Epoch 81/200, Iteration 238/250, Loss: 0.0124\n",
      "Epoch 81/200, Iteration 239/250, Loss: 0.0075\n",
      "Epoch 81/200, Iteration 240/250, Loss: 0.0187\n",
      "Epoch 81/200, Iteration 241/250, Loss: 0.0150\n",
      "Epoch 81/200, Iteration 242/250, Loss: 0.0184\n",
      "Epoch 81/200, Iteration 243/250, Loss: 0.0149\n",
      "Epoch 81/200, Iteration 244/250, Loss: 0.0094\n",
      "Epoch 81/200, Iteration 245/250, Loss: 0.0093\n",
      "Epoch 81/200, Iteration 246/250, Loss: 0.0124\n",
      "Epoch 81/200, Iteration 247/250, Loss: 0.0095\n",
      "Epoch 81/200, Iteration 248/250, Loss: 0.0140\n",
      "Epoch 81/200, Iteration 249/250, Loss: 0.0200\n",
      "Epoch 81/200, Iteration 250/250, Loss: 0.0349\n",
      "Train Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.007481, MRE: 0.419886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.95%, Avg loss: 0.008030, MRE: 0.436881 \n",
      "\n",
      "Epoch 82/200, Iteration 1/250, Loss: 0.0110\n",
      "Epoch 82/200, Iteration 2/250, Loss: 0.0069\n",
      "Epoch 82/200, Iteration 3/250, Loss: 0.0122\n",
      "Epoch 82/200, Iteration 4/250, Loss: 0.0171\n",
      "Epoch 82/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 82/200, Iteration 6/250, Loss: 0.0176\n",
      "Epoch 82/200, Iteration 7/250, Loss: 0.0236\n",
      "Epoch 82/200, Iteration 8/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 9/250, Loss: 0.0149\n",
      "Epoch 82/200, Iteration 10/250, Loss: 0.0114\n",
      "Epoch 82/200, Iteration 11/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 12/250, Loss: 0.0126\n",
      "Epoch 82/200, Iteration 13/250, Loss: 0.0216\n",
      "Epoch 82/200, Iteration 14/250, Loss: 0.0244\n",
      "Epoch 82/200, Iteration 15/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 16/250, Loss: 0.0075\n",
      "Epoch 82/200, Iteration 17/250, Loss: 0.0107\n",
      "Epoch 82/200, Iteration 18/250, Loss: 0.0167\n",
      "Epoch 82/200, Iteration 19/250, Loss: 0.0170\n",
      "Epoch 82/200, Iteration 20/250, Loss: 0.0243\n",
      "Epoch 82/200, Iteration 21/250, Loss: 0.0074\n",
      "Epoch 82/200, Iteration 22/250, Loss: 0.0254\n",
      "Epoch 82/200, Iteration 23/250, Loss: 0.0108\n",
      "Epoch 82/200, Iteration 24/250, Loss: 0.0104\n",
      "Epoch 82/200, Iteration 25/250, Loss: 0.0113\n",
      "Epoch 82/200, Iteration 26/250, Loss: 0.0152\n",
      "Epoch 82/200, Iteration 27/250, Loss: 0.0327\n",
      "Epoch 82/200, Iteration 28/250, Loss: 0.0132\n",
      "Epoch 82/200, Iteration 29/250, Loss: 0.0098\n",
      "Epoch 82/200, Iteration 30/250, Loss: 0.0094\n",
      "Epoch 82/200, Iteration 31/250, Loss: 0.0090\n",
      "Epoch 82/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 33/250, Loss: 0.0159\n",
      "Epoch 82/200, Iteration 34/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 35/250, Loss: 0.0329\n",
      "Epoch 82/200, Iteration 36/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 37/250, Loss: 0.0068\n",
      "Epoch 82/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 82/200, Iteration 39/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 40/250, Loss: 0.0189\n",
      "Epoch 82/200, Iteration 41/250, Loss: 0.0203\n",
      "Epoch 82/200, Iteration 42/250, Loss: 0.0089\n",
      "Epoch 82/200, Iteration 43/250, Loss: 0.0082\n",
      "Epoch 82/200, Iteration 44/250, Loss: 0.0199\n",
      "Epoch 82/200, Iteration 45/250, Loss: 0.0301\n",
      "Epoch 82/200, Iteration 46/250, Loss: 0.0114\n",
      "Epoch 82/200, Iteration 47/250, Loss: 0.0259\n",
      "Epoch 82/200, Iteration 48/250, Loss: 0.0164\n",
      "Epoch 82/200, Iteration 49/250, Loss: 0.0236\n",
      "Epoch 82/200, Iteration 50/250, Loss: 0.0130\n",
      "Epoch 82/200, Iteration 51/250, Loss: 0.0270\n",
      "Epoch 82/200, Iteration 52/250, Loss: 0.0187\n",
      "Epoch 82/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 82/200, Iteration 54/250, Loss: 0.0086\n",
      "Epoch 82/200, Iteration 55/250, Loss: 0.0064\n",
      "Epoch 82/200, Iteration 56/250, Loss: 0.0084\n",
      "Epoch 82/200, Iteration 57/250, Loss: 0.0222\n",
      "Epoch 82/200, Iteration 58/250, Loss: 0.0073\n",
      "Epoch 82/200, Iteration 59/250, Loss: 0.0128\n",
      "Epoch 82/200, Iteration 60/250, Loss: 0.0067\n",
      "Epoch 82/200, Iteration 61/250, Loss: 0.0067\n",
      "Epoch 82/200, Iteration 62/250, Loss: 0.0196\n",
      "Epoch 82/200, Iteration 63/250, Loss: 0.0235\n",
      "Epoch 82/200, Iteration 64/250, Loss: 0.0105\n",
      "Epoch 82/200, Iteration 65/250, Loss: 0.0248\n",
      "Epoch 82/200, Iteration 66/250, Loss: 0.0156\n",
      "Epoch 82/200, Iteration 67/250, Loss: 0.0214\n",
      "Epoch 82/200, Iteration 68/250, Loss: 0.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200, Iteration 69/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 70/250, Loss: 0.0137\n",
      "Epoch 82/200, Iteration 71/250, Loss: 0.0132\n",
      "Epoch 82/200, Iteration 72/250, Loss: 0.0209\n",
      "Epoch 82/200, Iteration 73/250, Loss: 0.0261\n",
      "Epoch 82/200, Iteration 74/250, Loss: 0.0249\n",
      "Epoch 82/200, Iteration 75/250, Loss: 0.0250\n",
      "Epoch 82/200, Iteration 76/250, Loss: 0.0158\n",
      "Epoch 82/200, Iteration 77/250, Loss: 0.0147\n",
      "Epoch 82/200, Iteration 78/250, Loss: 0.0155\n",
      "Epoch 82/200, Iteration 79/250, Loss: 0.0148\n",
      "Epoch 82/200, Iteration 80/250, Loss: 0.0110\n",
      "Epoch 82/200, Iteration 81/250, Loss: 0.0092\n",
      "Epoch 82/200, Iteration 82/250, Loss: 0.0144\n",
      "Epoch 82/200, Iteration 83/250, Loss: 0.0452\n",
      "Epoch 82/200, Iteration 84/250, Loss: 0.0118\n",
      "Epoch 82/200, Iteration 85/250, Loss: 0.0144\n",
      "Epoch 82/200, Iteration 86/250, Loss: 0.0147\n",
      "Epoch 82/200, Iteration 87/250, Loss: 0.0139\n",
      "Epoch 82/200, Iteration 88/250, Loss: 0.0138\n",
      "Epoch 82/200, Iteration 89/250, Loss: 0.0130\n",
      "Epoch 82/200, Iteration 90/250, Loss: 0.0255\n",
      "Epoch 82/200, Iteration 91/250, Loss: 0.0133\n",
      "Epoch 82/200, Iteration 92/250, Loss: 0.0102\n",
      "Epoch 82/200, Iteration 93/250, Loss: 0.0251\n",
      "Epoch 82/200, Iteration 94/250, Loss: 0.0302\n",
      "Epoch 82/200, Iteration 95/250, Loss: 0.0171\n",
      "Epoch 82/200, Iteration 96/250, Loss: 0.0255\n",
      "Epoch 82/200, Iteration 97/250, Loss: 0.0182\n",
      "Epoch 82/200, Iteration 98/250, Loss: 0.0102\n",
      "Epoch 82/200, Iteration 99/250, Loss: 0.0128\n",
      "Epoch 82/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 82/200, Iteration 101/250, Loss: 0.0205\n",
      "Epoch 82/200, Iteration 102/250, Loss: 0.0132\n",
      "Epoch 82/200, Iteration 103/250, Loss: 0.0088\n",
      "Epoch 82/200, Iteration 104/250, Loss: 0.0120\n",
      "Epoch 82/200, Iteration 105/250, Loss: 0.0071\n",
      "Epoch 82/200, Iteration 106/250, Loss: 0.0245\n",
      "Epoch 82/200, Iteration 107/250, Loss: 0.0234\n",
      "Epoch 82/200, Iteration 108/250, Loss: 0.0189\n",
      "Epoch 82/200, Iteration 109/250, Loss: 0.0243\n",
      "Epoch 82/200, Iteration 110/250, Loss: 0.0288\n",
      "Epoch 82/200, Iteration 111/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 112/250, Loss: 0.0147\n",
      "Epoch 82/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 82/200, Iteration 114/250, Loss: 0.0226\n",
      "Epoch 82/200, Iteration 115/250, Loss: 0.0174\n",
      "Epoch 82/200, Iteration 116/250, Loss: 0.0224\n",
      "Epoch 82/200, Iteration 117/250, Loss: 0.0255\n",
      "Epoch 82/200, Iteration 118/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 119/250, Loss: 0.0189\n",
      "Epoch 82/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 82/200, Iteration 121/250, Loss: 0.0143\n",
      "Epoch 82/200, Iteration 122/250, Loss: 0.0103\n",
      "Epoch 82/200, Iteration 123/250, Loss: 0.0159\n",
      "Epoch 82/200, Iteration 124/250, Loss: 0.0097\n",
      "Epoch 82/200, Iteration 125/250, Loss: 0.0100\n",
      "Epoch 82/200, Iteration 126/250, Loss: 0.0179\n",
      "Epoch 82/200, Iteration 127/250, Loss: 0.0180\n",
      "Epoch 82/200, Iteration 128/250, Loss: 0.0296\n",
      "Epoch 82/200, Iteration 129/250, Loss: 0.0083\n",
      "Epoch 82/200, Iteration 130/250, Loss: 0.0136\n",
      "Epoch 82/200, Iteration 131/250, Loss: 0.0172\n",
      "Epoch 82/200, Iteration 132/250, Loss: 0.0199\n",
      "Epoch 82/200, Iteration 133/250, Loss: 0.0182\n",
      "Epoch 82/200, Iteration 134/250, Loss: 0.0193\n",
      "Epoch 82/200, Iteration 135/250, Loss: 0.0143\n",
      "Epoch 82/200, Iteration 136/250, Loss: 0.0141\n",
      "Epoch 82/200, Iteration 137/250, Loss: 0.0128\n",
      "Epoch 82/200, Iteration 138/250, Loss: 0.0093\n",
      "Epoch 82/200, Iteration 139/250, Loss: 0.0128\n",
      "Epoch 82/200, Iteration 140/250, Loss: 0.0329\n",
      "Epoch 82/200, Iteration 141/250, Loss: 0.0147\n",
      "Epoch 82/200, Iteration 142/250, Loss: 0.0154\n",
      "Epoch 82/200, Iteration 143/250, Loss: 0.0124\n",
      "Epoch 82/200, Iteration 144/250, Loss: 0.0157\n",
      "Epoch 82/200, Iteration 145/250, Loss: 0.0145\n",
      "Epoch 82/200, Iteration 146/250, Loss: 0.0081\n",
      "Epoch 82/200, Iteration 147/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 148/250, Loss: 0.0205\n",
      "Epoch 82/200, Iteration 149/250, Loss: 0.0151\n",
      "Epoch 82/200, Iteration 150/250, Loss: 0.0149\n",
      "Epoch 82/200, Iteration 151/250, Loss: 0.0155\n",
      "Epoch 82/200, Iteration 152/250, Loss: 0.0305\n",
      "Epoch 82/200, Iteration 153/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 154/250, Loss: 0.0223\n",
      "Epoch 82/200, Iteration 155/250, Loss: 0.0184\n",
      "Epoch 82/200, Iteration 156/250, Loss: 0.0119\n",
      "Epoch 82/200, Iteration 157/250, Loss: 0.0088\n",
      "Epoch 82/200, Iteration 158/250, Loss: 0.0089\n",
      "Epoch 82/200, Iteration 159/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 160/250, Loss: 0.0193\n",
      "Epoch 82/200, Iteration 161/250, Loss: 0.0161\n",
      "Epoch 82/200, Iteration 162/250, Loss: 0.0158\n",
      "Epoch 82/200, Iteration 163/250, Loss: 0.0179\n",
      "Epoch 82/200, Iteration 164/250, Loss: 0.0167\n",
      "Epoch 82/200, Iteration 165/250, Loss: 0.0188\n",
      "Epoch 82/200, Iteration 166/250, Loss: 0.0225\n",
      "Epoch 82/200, Iteration 167/250, Loss: 0.0353\n",
      "Epoch 82/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 82/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 170/250, Loss: 0.0087\n",
      "Epoch 82/200, Iteration 171/250, Loss: 0.0191\n",
      "Epoch 82/200, Iteration 172/250, Loss: 0.0162\n",
      "Epoch 82/200, Iteration 173/250, Loss: 0.0258\n",
      "Epoch 82/200, Iteration 174/250, Loss: 0.0299\n",
      "Epoch 82/200, Iteration 175/250, Loss: 0.0136\n",
      "Epoch 82/200, Iteration 176/250, Loss: 0.0255\n",
      "Epoch 82/200, Iteration 177/250, Loss: 0.0116\n",
      "Epoch 82/200, Iteration 178/250, Loss: 0.0098\n",
      "Epoch 82/200, Iteration 179/250, Loss: 0.0270\n",
      "Epoch 82/200, Iteration 180/250, Loss: 0.0280\n",
      "Epoch 82/200, Iteration 181/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 182/250, Loss: 0.0133\n",
      "Epoch 82/200, Iteration 183/250, Loss: 0.0138\n",
      "Epoch 82/200, Iteration 184/250, Loss: 0.0275\n",
      "Epoch 82/200, Iteration 185/250, Loss: 0.0243\n",
      "Epoch 82/200, Iteration 186/250, Loss: 0.0148\n",
      "Epoch 82/200, Iteration 187/250, Loss: 0.0182\n",
      "Epoch 82/200, Iteration 188/250, Loss: 0.0153\n",
      "Epoch 82/200, Iteration 189/250, Loss: 0.0149\n",
      "Epoch 82/200, Iteration 190/250, Loss: 0.0094\n",
      "Epoch 82/200, Iteration 191/250, Loss: 0.0220\n",
      "Epoch 82/200, Iteration 192/250, Loss: 0.0094\n",
      "Epoch 82/200, Iteration 193/250, Loss: 0.0100\n",
      "Epoch 82/200, Iteration 194/250, Loss: 0.0159\n",
      "Epoch 82/200, Iteration 195/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 196/250, Loss: 0.0139\n",
      "Epoch 82/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 82/200, Iteration 198/250, Loss: 0.0097\n",
      "Epoch 82/200, Iteration 199/250, Loss: 0.0124\n",
      "Epoch 82/200, Iteration 200/250, Loss: 0.0196\n",
      "Epoch 82/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 82/200, Iteration 202/250, Loss: 0.0091\n",
      "Epoch 82/200, Iteration 203/250, Loss: 0.0214\n",
      "Epoch 82/200, Iteration 204/250, Loss: 0.0116\n",
      "Epoch 82/200, Iteration 205/250, Loss: 0.0077\n",
      "Epoch 82/200, Iteration 206/250, Loss: 0.0169\n",
      "Epoch 82/200, Iteration 207/250, Loss: 0.0128\n",
      "Epoch 82/200, Iteration 208/250, Loss: 0.0140\n",
      "Epoch 82/200, Iteration 209/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 211/250, Loss: 0.0290\n",
      "Epoch 82/200, Iteration 212/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 213/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 214/250, Loss: 0.0151\n",
      "Epoch 82/200, Iteration 215/250, Loss: 0.0168\n",
      "Epoch 82/200, Iteration 216/250, Loss: 0.0119\n",
      "Epoch 82/200, Iteration 217/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 218/250, Loss: 0.0095\n",
      "Epoch 82/200, Iteration 219/250, Loss: 0.0119\n",
      "Epoch 82/200, Iteration 220/250, Loss: 0.0120\n",
      "Epoch 82/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 82/200, Iteration 222/250, Loss: 0.0137\n",
      "Epoch 82/200, Iteration 223/250, Loss: 0.0154\n",
      "Epoch 82/200, Iteration 224/250, Loss: 0.0106\n",
      "Epoch 82/200, Iteration 225/250, Loss: 0.0069\n",
      "Epoch 82/200, Iteration 226/250, Loss: 0.0067\n",
      "Epoch 82/200, Iteration 227/250, Loss: 0.0093\n",
      "Epoch 82/200, Iteration 228/250, Loss: 0.0151\n",
      "Epoch 82/200, Iteration 229/250, Loss: 0.0221\n",
      "Epoch 82/200, Iteration 230/250, Loss: 0.0123\n",
      "Epoch 82/200, Iteration 231/250, Loss: 0.0196\n",
      "Epoch 82/200, Iteration 232/250, Loss: 0.0114\n",
      "Epoch 82/200, Iteration 233/250, Loss: 0.0064\n",
      "Epoch 82/200, Iteration 234/250, Loss: 0.0144\n",
      "Epoch 82/200, Iteration 235/250, Loss: 0.0308\n",
      "Epoch 82/200, Iteration 236/250, Loss: 0.0176\n",
      "Epoch 82/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 82/200, Iteration 238/250, Loss: 0.0130\n",
      "Epoch 82/200, Iteration 239/250, Loss: 0.0079\n",
      "Epoch 82/200, Iteration 240/250, Loss: 0.0097\n",
      "Epoch 82/200, Iteration 241/250, Loss: 0.0116\n",
      "Epoch 82/200, Iteration 242/250, Loss: 0.0102\n",
      "Epoch 82/200, Iteration 243/250, Loss: 0.0132\n",
      "Epoch 82/200, Iteration 244/250, Loss: 0.0113\n",
      "Epoch 82/200, Iteration 245/250, Loss: 0.0167\n",
      "Epoch 82/200, Iteration 246/250, Loss: 0.0130\n",
      "Epoch 82/200, Iteration 247/250, Loss: 0.0139\n",
      "Epoch 82/200, Iteration 248/250, Loss: 0.0113\n",
      "Epoch 82/200, Iteration 249/250, Loss: 0.0149\n",
      "Epoch 82/200, Iteration 250/250, Loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 82.62%, Avg loss: 0.007353, MRE: 0.465807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.65%, Avg loss: 0.007825, MRE: 0.496135 \n",
      "\n",
      "Epoch 83/200, Iteration 1/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 2/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 3/250, Loss: 0.0275\n",
      "Epoch 83/200, Iteration 4/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 5/250, Loss: 0.0135\n",
      "Epoch 83/200, Iteration 6/250, Loss: 0.0146\n",
      "Epoch 83/200, Iteration 7/250, Loss: 0.0204\n",
      "Epoch 83/200, Iteration 8/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 11/250, Loss: 0.0093\n",
      "Epoch 83/200, Iteration 12/250, Loss: 0.0312\n",
      "Epoch 83/200, Iteration 13/250, Loss: 0.0108\n",
      "Epoch 83/200, Iteration 14/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 15/250, Loss: 0.0245\n",
      "Epoch 83/200, Iteration 16/250, Loss: 0.0133\n",
      "Epoch 83/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 83/200, Iteration 18/250, Loss: 0.0131\n",
      "Epoch 83/200, Iteration 19/250, Loss: 0.0169\n",
      "Epoch 83/200, Iteration 20/250, Loss: 0.0088\n",
      "Epoch 83/200, Iteration 21/250, Loss: 0.0121\n",
      "Epoch 83/200, Iteration 22/250, Loss: 0.0240\n",
      "Epoch 83/200, Iteration 23/250, Loss: 0.0077\n",
      "Epoch 83/200, Iteration 24/250, Loss: 0.0108\n",
      "Epoch 83/200, Iteration 25/250, Loss: 0.0147\n",
      "Epoch 83/200, Iteration 26/250, Loss: 0.0369\n",
      "Epoch 83/200, Iteration 27/250, Loss: 0.0115\n",
      "Epoch 83/200, Iteration 28/250, Loss: 0.0225\n",
      "Epoch 83/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 83/200, Iteration 30/250, Loss: 0.0153\n",
      "Epoch 83/200, Iteration 31/250, Loss: 0.0233\n",
      "Epoch 83/200, Iteration 32/250, Loss: 0.0082\n",
      "Epoch 83/200, Iteration 33/250, Loss: 0.0133\n",
      "Epoch 83/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 83/200, Iteration 35/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 36/250, Loss: 0.0261\n",
      "Epoch 83/200, Iteration 37/250, Loss: 0.0198\n",
      "Epoch 83/200, Iteration 38/250, Loss: 0.0160\n",
      "Epoch 83/200, Iteration 39/250, Loss: 0.0114\n",
      "Epoch 83/200, Iteration 40/250, Loss: 0.0228\n",
      "Epoch 83/200, Iteration 41/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 42/250, Loss: 0.0113\n",
      "Epoch 83/200, Iteration 43/250, Loss: 0.0544\n",
      "Epoch 83/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 83/200, Iteration 45/250, Loss: 0.0163\n",
      "Epoch 83/200, Iteration 46/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 47/250, Loss: 0.0151\n",
      "Epoch 83/200, Iteration 48/250, Loss: 0.0099\n",
      "Epoch 83/200, Iteration 49/250, Loss: 0.0236\n",
      "Epoch 83/200, Iteration 50/250, Loss: 0.0184\n",
      "Epoch 83/200, Iteration 51/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 52/250, Loss: 0.0313\n",
      "Epoch 83/200, Iteration 53/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 54/250, Loss: 0.0144\n",
      "Epoch 83/200, Iteration 55/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 56/250, Loss: 0.0145\n",
      "Epoch 83/200, Iteration 57/250, Loss: 0.0131\n",
      "Epoch 83/200, Iteration 58/250, Loss: 0.0110\n",
      "Epoch 83/200, Iteration 59/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 60/250, Loss: 0.0129\n",
      "Epoch 83/200, Iteration 61/250, Loss: 0.0132\n",
      "Epoch 83/200, Iteration 62/250, Loss: 0.0064\n",
      "Epoch 83/200, Iteration 63/250, Loss: 0.0103\n",
      "Epoch 83/200, Iteration 64/250, Loss: 0.0228\n",
      "Epoch 83/200, Iteration 65/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 66/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 67/250, Loss: 0.0112\n",
      "Epoch 83/200, Iteration 68/250, Loss: 0.0264\n",
      "Epoch 83/200, Iteration 69/250, Loss: 0.0260\n",
      "Epoch 83/200, Iteration 70/250, Loss: 0.0166\n",
      "Epoch 83/200, Iteration 71/250, Loss: 0.0166\n",
      "Epoch 83/200, Iteration 72/250, Loss: 0.0202\n",
      "Epoch 83/200, Iteration 73/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 74/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 75/250, Loss: 0.0143\n",
      "Epoch 83/200, Iteration 76/250, Loss: 0.0100\n",
      "Epoch 83/200, Iteration 77/250, Loss: 0.0095\n",
      "Epoch 83/200, Iteration 78/250, Loss: 0.0109\n",
      "Epoch 83/200, Iteration 79/250, Loss: 0.0099\n",
      "Epoch 83/200, Iteration 80/250, Loss: 0.0238\n",
      "Epoch 83/200, Iteration 81/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 82/250, Loss: 0.0229\n",
      "Epoch 83/200, Iteration 83/250, Loss: 0.0138\n",
      "Epoch 83/200, Iteration 84/250, Loss: 0.0077\n",
      "Epoch 83/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 86/250, Loss: 0.0300\n",
      "Epoch 83/200, Iteration 87/250, Loss: 0.0317\n",
      "Epoch 83/200, Iteration 88/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 89/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 90/250, Loss: 0.0195\n",
      "Epoch 83/200, Iteration 91/250, Loss: 0.0210\n",
      "Epoch 83/200, Iteration 92/250, Loss: 0.0174\n",
      "Epoch 83/200, Iteration 93/250, Loss: 0.0209\n",
      "Epoch 83/200, Iteration 94/250, Loss: 0.0151\n",
      "Epoch 83/200, Iteration 95/250, Loss: 0.0167\n",
      "Epoch 83/200, Iteration 96/250, Loss: 0.0098\n",
      "Epoch 83/200, Iteration 97/250, Loss: 0.0083\n",
      "Epoch 83/200, Iteration 98/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 99/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 100/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 102/250, Loss: 0.0139\n",
      "Epoch 83/200, Iteration 103/250, Loss: 0.0280\n",
      "Epoch 83/200, Iteration 104/250, Loss: 0.0099\n",
      "Epoch 83/200, Iteration 105/250, Loss: 0.0160\n",
      "Epoch 83/200, Iteration 106/250, Loss: 0.0146\n",
      "Epoch 83/200, Iteration 107/250, Loss: 0.0090\n",
      "Epoch 83/200, Iteration 108/250, Loss: 0.0257\n",
      "Epoch 83/200, Iteration 109/250, Loss: 0.0109\n",
      "Epoch 83/200, Iteration 110/250, Loss: 0.0186\n",
      "Epoch 83/200, Iteration 111/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 112/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 113/250, Loss: 0.0166\n",
      "Epoch 83/200, Iteration 114/250, Loss: 0.0116\n",
      "Epoch 83/200, Iteration 115/250, Loss: 0.0094\n",
      "Epoch 83/200, Iteration 116/250, Loss: 0.0177\n",
      "Epoch 83/200, Iteration 117/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 118/250, Loss: 0.0206\n",
      "Epoch 83/200, Iteration 119/250, Loss: 0.0174\n",
      "Epoch 83/200, Iteration 120/250, Loss: 0.0174\n",
      "Epoch 83/200, Iteration 121/250, Loss: 0.0170\n",
      "Epoch 83/200, Iteration 122/250, Loss: 0.0109\n",
      "Epoch 83/200, Iteration 123/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 83/200, Iteration 125/250, Loss: 0.0096\n",
      "Epoch 83/200, Iteration 126/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 127/250, Loss: 0.0141\n",
      "Epoch 83/200, Iteration 128/250, Loss: 0.0085\n",
      "Epoch 83/200, Iteration 129/250, Loss: 0.0086\n",
      "Epoch 83/200, Iteration 130/250, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 131/250, Loss: 0.0166\n",
      "Epoch 83/200, Iteration 132/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 133/250, Loss: 0.0152\n",
      "Epoch 83/200, Iteration 134/250, Loss: 0.0159\n",
      "Epoch 83/200, Iteration 135/250, Loss: 0.0101\n",
      "Epoch 83/200, Iteration 136/250, Loss: 0.0086\n",
      "Epoch 83/200, Iteration 137/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 138/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 139/250, Loss: 0.0081\n",
      "Epoch 83/200, Iteration 140/250, Loss: 0.0127\n",
      "Epoch 83/200, Iteration 141/250, Loss: 0.0088\n",
      "Epoch 83/200, Iteration 142/250, Loss: 0.0078\n",
      "Epoch 83/200, Iteration 143/250, Loss: 0.0218\n",
      "Epoch 83/200, Iteration 144/250, Loss: 0.0264\n",
      "Epoch 83/200, Iteration 145/250, Loss: 0.0210\n",
      "Epoch 83/200, Iteration 146/250, Loss: 0.0059\n",
      "Epoch 83/200, Iteration 147/250, Loss: 0.0149\n",
      "Epoch 83/200, Iteration 148/250, Loss: 0.0139\n",
      "Epoch 83/200, Iteration 149/250, Loss: 0.0336\n",
      "Epoch 83/200, Iteration 150/250, Loss: 0.0089\n",
      "Epoch 83/200, Iteration 151/250, Loss: 0.0063\n",
      "Epoch 83/200, Iteration 152/250, Loss: 0.0073\n",
      "Epoch 83/200, Iteration 153/250, Loss: 0.0431\n",
      "Epoch 83/200, Iteration 154/250, Loss: 0.0137\n",
      "Epoch 83/200, Iteration 155/250, Loss: 0.0131\n",
      "Epoch 83/200, Iteration 156/250, Loss: 0.0144\n",
      "Epoch 83/200, Iteration 157/250, Loss: 0.0126\n",
      "Epoch 83/200, Iteration 158/250, Loss: 0.0087\n",
      "Epoch 83/200, Iteration 159/250, Loss: 0.0130\n",
      "Epoch 83/200, Iteration 160/250, Loss: 0.0219\n",
      "Epoch 83/200, Iteration 161/250, Loss: 0.0073\n",
      "Epoch 83/200, Iteration 162/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 163/250, Loss: 0.0218\n",
      "Epoch 83/200, Iteration 164/250, Loss: 0.0145\n",
      "Epoch 83/200, Iteration 165/250, Loss: 0.0154\n",
      "Epoch 83/200, Iteration 166/250, Loss: 0.0267\n",
      "Epoch 83/200, Iteration 167/250, Loss: 0.0154\n",
      "Epoch 83/200, Iteration 168/250, Loss: 0.0091\n",
      "Epoch 83/200, Iteration 169/250, Loss: 0.0140\n",
      "Epoch 83/200, Iteration 170/250, Loss: 0.0236\n",
      "Epoch 83/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 83/200, Iteration 172/250, Loss: 0.0070\n",
      "Epoch 83/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 83/200, Iteration 174/250, Loss: 0.0201\n",
      "Epoch 83/200, Iteration 175/250, Loss: 0.0149\n",
      "Epoch 83/200, Iteration 176/250, Loss: 0.0139\n",
      "Epoch 83/200, Iteration 177/250, Loss: 0.0142\n",
      "Epoch 83/200, Iteration 178/250, Loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Iteration 179/250, Loss: 0.0230\n",
      "Epoch 83/200, Iteration 180/250, Loss: 0.0099\n",
      "Epoch 83/200, Iteration 181/250, Loss: 0.0129\n",
      "Epoch 83/200, Iteration 182/250, Loss: 0.0079\n",
      "Epoch 83/200, Iteration 183/250, Loss: 0.0096\n",
      "Epoch 83/200, Iteration 184/250, Loss: 0.0320\n",
      "Epoch 83/200, Iteration 185/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 186/250, Loss: 0.0163\n",
      "Epoch 83/200, Iteration 187/250, Loss: 0.0162\n",
      "Epoch 83/200, Iteration 188/250, Loss: 0.0136\n",
      "Epoch 83/200, Iteration 189/250, Loss: 0.0195\n",
      "Epoch 83/200, Iteration 190/250, Loss: 0.0111\n",
      "Epoch 83/200, Iteration 191/250, Loss: 0.0157\n",
      "Epoch 83/200, Iteration 192/250, Loss: 0.0312\n",
      "Epoch 83/200, Iteration 193/250, Loss: 0.0154\n",
      "Epoch 83/200, Iteration 194/250, Loss: 0.0121\n",
      "Epoch 83/200, Iteration 195/250, Loss: 0.0136\n",
      "Epoch 83/200, Iteration 196/250, Loss: 0.0109\n",
      "Epoch 83/200, Iteration 197/250, Loss: 0.0207\n",
      "Epoch 83/200, Iteration 198/250, Loss: 0.0149\n",
      "Epoch 83/200, Iteration 199/250, Loss: 0.0128\n",
      "Epoch 83/200, Iteration 200/250, Loss: 0.0092\n",
      "Epoch 83/200, Iteration 201/250, Loss: 0.0082\n",
      "Epoch 83/200, Iteration 202/250, Loss: 0.0123\n",
      "Epoch 83/200, Iteration 203/250, Loss: 0.0120\n",
      "Epoch 83/200, Iteration 204/250, Loss: 0.0483\n",
      "Epoch 83/200, Iteration 205/250, Loss: 0.0156\n",
      "Epoch 83/200, Iteration 206/250, Loss: 0.0237\n",
      "Epoch 83/200, Iteration 207/250, Loss: 0.0225\n",
      "Epoch 83/200, Iteration 208/250, Loss: 0.0152\n",
      "Epoch 83/200, Iteration 209/250, Loss: 0.0086\n",
      "Epoch 83/200, Iteration 210/250, Loss: 0.0126\n",
      "Epoch 83/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 83/200, Iteration 212/250, Loss: 0.0119\n",
      "Epoch 83/200, Iteration 213/250, Loss: 0.0081\n",
      "Epoch 83/200, Iteration 214/250, Loss: 0.0072\n",
      "Epoch 83/200, Iteration 215/250, Loss: 0.0086\n",
      "Epoch 83/200, Iteration 216/250, Loss: 0.0519\n",
      "Epoch 83/200, Iteration 217/250, Loss: 0.0157\n",
      "Epoch 83/200, Iteration 218/250, Loss: 0.0104\n",
      "Epoch 83/200, Iteration 219/250, Loss: 0.0446\n",
      "Epoch 83/200, Iteration 220/250, Loss: 0.0070\n",
      "Epoch 83/200, Iteration 221/250, Loss: 0.0180\n",
      "Epoch 83/200, Iteration 222/250, Loss: 0.0193\n",
      "Epoch 83/200, Iteration 223/250, Loss: 0.0290\n",
      "Epoch 83/200, Iteration 224/250, Loss: 0.0106\n",
      "Epoch 83/200, Iteration 225/250, Loss: 0.0125\n",
      "Epoch 83/200, Iteration 226/250, Loss: 0.0170\n",
      "Epoch 83/200, Iteration 227/250, Loss: 0.0114\n",
      "Epoch 83/200, Iteration 228/250, Loss: 0.0084\n",
      "Epoch 83/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 83/200, Iteration 230/250, Loss: 0.0158\n",
      "Epoch 83/200, Iteration 231/250, Loss: 0.0419\n",
      "Epoch 83/200, Iteration 232/250, Loss: 0.0145\n",
      "Epoch 83/200, Iteration 233/250, Loss: 0.0076\n",
      "Epoch 83/200, Iteration 234/250, Loss: 0.0096\n",
      "Epoch 83/200, Iteration 235/250, Loss: 0.0180\n",
      "Epoch 83/200, Iteration 236/250, Loss: 0.0142\n",
      "Epoch 83/200, Iteration 237/250, Loss: 0.0102\n",
      "Epoch 83/200, Iteration 238/250, Loss: 0.0159\n",
      "Epoch 83/200, Iteration 239/250, Loss: 0.0111\n",
      "Epoch 83/200, Iteration 240/250, Loss: 0.0072\n",
      "Epoch 83/200, Iteration 241/250, Loss: 0.0216\n",
      "Epoch 83/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 83/200, Iteration 243/250, Loss: 0.0269\n",
      "Epoch 83/200, Iteration 244/250, Loss: 0.0330\n",
      "Epoch 83/200, Iteration 245/250, Loss: 0.0122\n",
      "Epoch 83/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 83/200, Iteration 247/250, Loss: 0.0124\n",
      "Epoch 83/200, Iteration 248/250, Loss: 0.0152\n",
      "Epoch 83/200, Iteration 249/250, Loss: 0.0314\n",
      "Epoch 83/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.006856, MRE: 0.432491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.007462, MRE: 0.574497 \n",
      "\n",
      "Epoch 84/200, Iteration 1/250, Loss: 0.0561\n",
      "Epoch 84/200, Iteration 2/250, Loss: 0.0072\n",
      "Epoch 84/200, Iteration 3/250, Loss: 0.0144\n",
      "Epoch 84/200, Iteration 4/250, Loss: 0.0251\n",
      "Epoch 84/200, Iteration 5/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 84/200, Iteration 7/250, Loss: 0.0149\n",
      "Epoch 84/200, Iteration 8/250, Loss: 0.0195\n",
      "Epoch 84/200, Iteration 9/250, Loss: 0.0194\n",
      "Epoch 84/200, Iteration 10/250, Loss: 0.0145\n",
      "Epoch 84/200, Iteration 11/250, Loss: 0.0245\n",
      "Epoch 84/200, Iteration 12/250, Loss: 0.0201\n",
      "Epoch 84/200, Iteration 13/250, Loss: 0.0108\n",
      "Epoch 84/200, Iteration 14/250, Loss: 0.0187\n",
      "Epoch 84/200, Iteration 15/250, Loss: 0.0278\n",
      "Epoch 84/200, Iteration 16/250, Loss: 0.0171\n",
      "Epoch 84/200, Iteration 17/250, Loss: 0.0213\n",
      "Epoch 84/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 19/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 20/250, Loss: 0.0291\n",
      "Epoch 84/200, Iteration 21/250, Loss: 0.0116\n",
      "Epoch 84/200, Iteration 22/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 23/250, Loss: 0.0134\n",
      "Epoch 84/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 84/200, Iteration 25/250, Loss: 0.0181\n",
      "Epoch 84/200, Iteration 26/250, Loss: 0.0496\n",
      "Epoch 84/200, Iteration 27/250, Loss: 0.0077\n",
      "Epoch 84/200, Iteration 28/250, Loss: 0.0175\n",
      "Epoch 84/200, Iteration 29/250, Loss: 0.0095\n",
      "Epoch 84/200, Iteration 30/250, Loss: 0.0161\n",
      "Epoch 84/200, Iteration 31/250, Loss: 0.0088\n",
      "Epoch 84/200, Iteration 32/250, Loss: 0.0264\n",
      "Epoch 84/200, Iteration 33/250, Loss: 0.0148\n",
      "Epoch 84/200, Iteration 34/250, Loss: 0.0434\n",
      "Epoch 84/200, Iteration 35/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 36/250, Loss: 0.0127\n",
      "Epoch 84/200, Iteration 37/250, Loss: 0.0153\n",
      "Epoch 84/200, Iteration 38/250, Loss: 0.0259\n",
      "Epoch 84/200, Iteration 39/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 40/250, Loss: 0.0101\n",
      "Epoch 84/200, Iteration 41/250, Loss: 0.0309\n",
      "Epoch 84/200, Iteration 42/250, Loss: 0.0325\n",
      "Epoch 84/200, Iteration 43/250, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 44/250, Loss: 0.0159\n",
      "Epoch 84/200, Iteration 45/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 84/200, Iteration 47/250, Loss: 0.0191\n",
      "Epoch 84/200, Iteration 48/250, Loss: 0.0215\n",
      "Epoch 84/200, Iteration 49/250, Loss: 0.0231\n",
      "Epoch 84/200, Iteration 50/250, Loss: 0.0202\n",
      "Epoch 84/200, Iteration 51/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 52/250, Loss: 0.0152\n",
      "Epoch 84/200, Iteration 53/250, Loss: 0.0179\n",
      "Epoch 84/200, Iteration 54/250, Loss: 0.0141\n",
      "Epoch 84/200, Iteration 55/250, Loss: 0.0246\n",
      "Epoch 84/200, Iteration 56/250, Loss: 0.0082\n",
      "Epoch 84/200, Iteration 57/250, Loss: 0.0117\n",
      "Epoch 84/200, Iteration 58/250, Loss: 0.0114\n",
      "Epoch 84/200, Iteration 59/250, Loss: 0.0063\n",
      "Epoch 84/200, Iteration 60/250, Loss: 0.0303\n",
      "Epoch 84/200, Iteration 61/250, Loss: 0.0123\n",
      "Epoch 84/200, Iteration 62/250, Loss: 0.0188\n",
      "Epoch 84/200, Iteration 63/250, Loss: 0.0241\n",
      "Epoch 84/200, Iteration 64/250, Loss: 0.0313\n",
      "Epoch 84/200, Iteration 65/250, Loss: 0.0216\n",
      "Epoch 84/200, Iteration 66/250, Loss: 0.0091\n",
      "Epoch 84/200, Iteration 67/250, Loss: 0.0240\n",
      "Epoch 84/200, Iteration 68/250, Loss: 0.0260\n",
      "Epoch 84/200, Iteration 69/250, Loss: 0.0132\n",
      "Epoch 84/200, Iteration 70/250, Loss: 0.0127\n",
      "Epoch 84/200, Iteration 71/250, Loss: 0.0094\n",
      "Epoch 84/200, Iteration 72/250, Loss: 0.0173\n",
      "Epoch 84/200, Iteration 73/250, Loss: 0.0094\n",
      "Epoch 84/200, Iteration 74/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 75/250, Loss: 0.0143\n",
      "Epoch 84/200, Iteration 76/250, Loss: 0.0245\n",
      "Epoch 84/200, Iteration 77/250, Loss: 0.0331\n",
      "Epoch 84/200, Iteration 78/250, Loss: 0.0154\n",
      "Epoch 84/200, Iteration 79/250, Loss: 0.0152\n",
      "Epoch 84/200, Iteration 80/250, Loss: 0.0151\n",
      "Epoch 84/200, Iteration 81/250, Loss: 0.0076\n",
      "Epoch 84/200, Iteration 82/250, Loss: 0.0171\n",
      "Epoch 84/200, Iteration 83/250, Loss: 0.0144\n",
      "Epoch 84/200, Iteration 84/250, Loss: 0.0134\n",
      "Epoch 84/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 84/200, Iteration 86/250, Loss: 0.0162\n",
      "Epoch 84/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 88/250, Loss: 0.0144\n",
      "Epoch 84/200, Iteration 89/250, Loss: 0.0144\n",
      "Epoch 84/200, Iteration 90/250, Loss: 0.0094\n",
      "Epoch 84/200, Iteration 91/250, Loss: 0.0122\n",
      "Epoch 84/200, Iteration 92/250, Loss: 0.0260\n",
      "Epoch 84/200, Iteration 93/250, Loss: 0.0168\n",
      "Epoch 84/200, Iteration 94/250, Loss: 0.0162\n",
      "Epoch 84/200, Iteration 95/250, Loss: 0.0155\n",
      "Epoch 84/200, Iteration 96/250, Loss: 0.0100\n",
      "Epoch 84/200, Iteration 97/250, Loss: 0.0380\n",
      "Epoch 84/200, Iteration 98/250, Loss: 0.0087\n",
      "Epoch 84/200, Iteration 99/250, Loss: 0.0116\n",
      "Epoch 84/200, Iteration 100/250, Loss: 0.0125\n",
      "Epoch 84/200, Iteration 101/250, Loss: 0.0243\n",
      "Epoch 84/200, Iteration 102/250, Loss: 0.0132\n",
      "Epoch 84/200, Iteration 103/250, Loss: 0.0095\n",
      "Epoch 84/200, Iteration 104/250, Loss: 0.0114\n",
      "Epoch 84/200, Iteration 105/250, Loss: 0.0186\n",
      "Epoch 84/200, Iteration 106/250, Loss: 0.0216\n",
      "Epoch 84/200, Iteration 107/250, Loss: 0.0069\n",
      "Epoch 84/200, Iteration 108/250, Loss: 0.0149\n",
      "Epoch 84/200, Iteration 109/250, Loss: 0.0136\n",
      "Epoch 84/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 84/200, Iteration 111/250, Loss: 0.0217\n",
      "Epoch 84/200, Iteration 112/250, Loss: 0.0135\n",
      "Epoch 84/200, Iteration 113/250, Loss: 0.0182\n",
      "Epoch 84/200, Iteration 114/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 115/250, Loss: 0.0103\n",
      "Epoch 84/200, Iteration 116/250, Loss: 0.0123\n",
      "Epoch 84/200, Iteration 117/250, Loss: 0.0069\n",
      "Epoch 84/200, Iteration 118/250, Loss: 0.0152\n",
      "Epoch 84/200, Iteration 119/250, Loss: 0.0172\n",
      "Epoch 84/200, Iteration 120/250, Loss: 0.0112\n",
      "Epoch 84/200, Iteration 121/250, Loss: 0.0264\n",
      "Epoch 84/200, Iteration 122/250, Loss: 0.0277\n",
      "Epoch 84/200, Iteration 123/250, Loss: 0.0268\n",
      "Epoch 84/200, Iteration 124/250, Loss: 0.0273\n",
      "Epoch 84/200, Iteration 125/250, Loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200, Iteration 126/250, Loss: 0.0246\n",
      "Epoch 84/200, Iteration 127/250, Loss: 0.0225\n",
      "Epoch 84/200, Iteration 128/250, Loss: 0.0168\n",
      "Epoch 84/200, Iteration 129/250, Loss: 0.0179\n",
      "Epoch 84/200, Iteration 130/250, Loss: 0.0229\n",
      "Epoch 84/200, Iteration 131/250, Loss: 0.0201\n",
      "Epoch 84/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 84/200, Iteration 133/250, Loss: 0.0105\n",
      "Epoch 84/200, Iteration 134/250, Loss: 0.0072\n",
      "Epoch 84/200, Iteration 135/250, Loss: 0.0102\n",
      "Epoch 84/200, Iteration 136/250, Loss: 0.0074\n",
      "Epoch 84/200, Iteration 137/250, Loss: 0.0379\n",
      "Epoch 84/200, Iteration 138/250, Loss: 0.0265\n",
      "Epoch 84/200, Iteration 139/250, Loss: 0.0219\n",
      "Epoch 84/200, Iteration 140/250, Loss: 0.0155\n",
      "Epoch 84/200, Iteration 141/250, Loss: 0.0205\n",
      "Epoch 84/200, Iteration 142/250, Loss: 0.0235\n",
      "Epoch 84/200, Iteration 143/250, Loss: 0.0352\n",
      "Epoch 84/200, Iteration 144/250, Loss: 0.0276\n",
      "Epoch 84/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 84/200, Iteration 146/250, Loss: 0.0256\n",
      "Epoch 84/200, Iteration 147/250, Loss: 0.0170\n",
      "Epoch 84/200, Iteration 148/250, Loss: 0.0230\n",
      "Epoch 84/200, Iteration 149/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 150/250, Loss: 0.0246\n",
      "Epoch 84/200, Iteration 151/250, Loss: 0.0119\n",
      "Epoch 84/200, Iteration 152/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 153/250, Loss: 0.0084\n",
      "Epoch 84/200, Iteration 154/250, Loss: 0.0185\n",
      "Epoch 84/200, Iteration 155/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 156/250, Loss: 0.0163\n",
      "Epoch 84/200, Iteration 157/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 158/250, Loss: 0.0142\n",
      "Epoch 84/200, Iteration 159/250, Loss: 0.0210\n",
      "Epoch 84/200, Iteration 160/250, Loss: 0.0134\n",
      "Epoch 84/200, Iteration 161/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 162/250, Loss: 0.0062\n",
      "Epoch 84/200, Iteration 163/250, Loss: 0.0164\n",
      "Epoch 84/200, Iteration 164/250, Loss: 0.0183\n",
      "Epoch 84/200, Iteration 165/250, Loss: 0.0119\n",
      "Epoch 84/200, Iteration 166/250, Loss: 0.0089\n",
      "Epoch 84/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 84/200, Iteration 168/250, Loss: 0.0168\n",
      "Epoch 84/200, Iteration 169/250, Loss: 0.0100\n",
      "Epoch 84/200, Iteration 170/250, Loss: 0.0105\n",
      "Epoch 84/200, Iteration 171/250, Loss: 0.0335\n",
      "Epoch 84/200, Iteration 172/250, Loss: 0.0215\n",
      "Epoch 84/200, Iteration 173/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 174/250, Loss: 0.0124\n",
      "Epoch 84/200, Iteration 175/250, Loss: 0.0079\n",
      "Epoch 84/200, Iteration 176/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 177/250, Loss: 0.0221\n",
      "Epoch 84/200, Iteration 178/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 179/250, Loss: 0.0123\n",
      "Epoch 84/200, Iteration 180/250, Loss: 0.0243\n",
      "Epoch 84/200, Iteration 181/250, Loss: 0.0139\n",
      "Epoch 84/200, Iteration 182/250, Loss: 0.0339\n",
      "Epoch 84/200, Iteration 183/250, Loss: 0.0305\n",
      "Epoch 84/200, Iteration 184/250, Loss: 0.0172\n",
      "Epoch 84/200, Iteration 185/250, Loss: 0.0113\n",
      "Epoch 84/200, Iteration 186/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 187/250, Loss: 0.0262\n",
      "Epoch 84/200, Iteration 188/250, Loss: 0.0119\n",
      "Epoch 84/200, Iteration 189/250, Loss: 0.0261\n",
      "Epoch 84/200, Iteration 190/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 191/250, Loss: 0.0085\n",
      "Epoch 84/200, Iteration 192/250, Loss: 0.0097\n",
      "Epoch 84/200, Iteration 193/250, Loss: 0.0176\n",
      "Epoch 84/200, Iteration 194/250, Loss: 0.0128\n",
      "Epoch 84/200, Iteration 195/250, Loss: 0.0111\n",
      "Epoch 84/200, Iteration 196/250, Loss: 0.0110\n",
      "Epoch 84/200, Iteration 197/250, Loss: 0.0246\n",
      "Epoch 84/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 84/200, Iteration 199/250, Loss: 0.0140\n",
      "Epoch 84/200, Iteration 200/250, Loss: 0.0129\n",
      "Epoch 84/200, Iteration 201/250, Loss: 0.0156\n",
      "Epoch 84/200, Iteration 202/250, Loss: 0.0155\n",
      "Epoch 84/200, Iteration 203/250, Loss: 0.0133\n",
      "Epoch 84/200, Iteration 204/250, Loss: 0.0145\n",
      "Epoch 84/200, Iteration 205/250, Loss: 0.0093\n",
      "Epoch 84/200, Iteration 206/250, Loss: 0.0084\n",
      "Epoch 84/200, Iteration 207/250, Loss: 0.0266\n",
      "Epoch 84/200, Iteration 208/250, Loss: 0.0174\n",
      "Epoch 84/200, Iteration 209/250, Loss: 0.0246\n",
      "Epoch 84/200, Iteration 210/250, Loss: 0.0117\n",
      "Epoch 84/200, Iteration 211/250, Loss: 0.0096\n",
      "Epoch 84/200, Iteration 212/250, Loss: 0.0311\n",
      "Epoch 84/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 214/250, Loss: 0.0081\n",
      "Epoch 84/200, Iteration 215/250, Loss: 0.0096\n",
      "Epoch 84/200, Iteration 216/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 217/250, Loss: 0.0153\n",
      "Epoch 84/200, Iteration 218/250, Loss: 0.0116\n",
      "Epoch 84/200, Iteration 219/250, Loss: 0.0111\n",
      "Epoch 84/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 84/200, Iteration 221/250, Loss: 0.0289\n",
      "Epoch 84/200, Iteration 222/250, Loss: 0.0320\n",
      "Epoch 84/200, Iteration 223/250, Loss: 0.0138\n",
      "Epoch 84/200, Iteration 224/250, Loss: 0.0277\n",
      "Epoch 84/200, Iteration 225/250, Loss: 0.0109\n",
      "Epoch 84/200, Iteration 226/250, Loss: 0.0186\n",
      "Epoch 84/200, Iteration 227/250, Loss: 0.0075\n",
      "Epoch 84/200, Iteration 228/250, Loss: 0.0158\n",
      "Epoch 84/200, Iteration 229/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 84/200, Iteration 232/250, Loss: 0.0098\n",
      "Epoch 84/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 84/200, Iteration 234/250, Loss: 0.0232\n",
      "Epoch 84/200, Iteration 235/250, Loss: 0.0075\n",
      "Epoch 84/200, Iteration 236/250, Loss: 0.0172\n",
      "Epoch 84/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 84/200, Iteration 238/250, Loss: 0.0082\n",
      "Epoch 84/200, Iteration 239/250, Loss: 0.0278\n",
      "Epoch 84/200, Iteration 240/250, Loss: 0.0146\n",
      "Epoch 84/200, Iteration 241/250, Loss: 0.0071\n",
      "Epoch 84/200, Iteration 242/250, Loss: 0.0274\n",
      "Epoch 84/200, Iteration 243/250, Loss: 0.0150\n",
      "Epoch 84/200, Iteration 244/250, Loss: 0.0102\n",
      "Epoch 84/200, Iteration 245/250, Loss: 0.0111\n",
      "Epoch 84/200, Iteration 246/250, Loss: 0.0090\n",
      "Epoch 84/200, Iteration 247/250, Loss: 0.0146\n",
      "Epoch 84/200, Iteration 248/250, Loss: 0.0182\n",
      "Epoch 84/200, Iteration 249/250, Loss: 0.0125\n",
      "Epoch 84/200, Iteration 250/250, Loss: 0.0122\n",
      "Train Error: \n",
      " Accuracy: 84.36%, Avg loss: 0.007280, MRE: 0.467898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.007814, MRE: 0.461785 \n",
      "\n",
      "Epoch 85/200, Iteration 1/250, Loss: 0.0132\n",
      "Epoch 85/200, Iteration 2/250, Loss: 0.0072\n",
      "Epoch 85/200, Iteration 3/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 4/250, Loss: 0.0090\n",
      "Epoch 85/200, Iteration 5/250, Loss: 0.0254\n",
      "Epoch 85/200, Iteration 6/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 7/250, Loss: 0.0172\n",
      "Epoch 85/200, Iteration 8/250, Loss: 0.0176\n",
      "Epoch 85/200, Iteration 9/250, Loss: 0.0145\n",
      "Epoch 85/200, Iteration 10/250, Loss: 0.0220\n",
      "Epoch 85/200, Iteration 11/250, Loss: 0.0183\n",
      "Epoch 85/200, Iteration 12/250, Loss: 0.0172\n",
      "Epoch 85/200, Iteration 13/250, Loss: 0.0073\n",
      "Epoch 85/200, Iteration 14/250, Loss: 0.0124\n",
      "Epoch 85/200, Iteration 15/250, Loss: 0.0204\n",
      "Epoch 85/200, Iteration 16/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 17/250, Loss: 0.0243\n",
      "Epoch 85/200, Iteration 18/250, Loss: 0.0130\n",
      "Epoch 85/200, Iteration 19/250, Loss: 0.0070\n",
      "Epoch 85/200, Iteration 20/250, Loss: 0.0105\n",
      "Epoch 85/200, Iteration 21/250, Loss: 0.0086\n",
      "Epoch 85/200, Iteration 22/250, Loss: 0.0147\n",
      "Epoch 85/200, Iteration 23/250, Loss: 0.0295\n",
      "Epoch 85/200, Iteration 24/250, Loss: 0.0120\n",
      "Epoch 85/200, Iteration 25/250, Loss: 0.0220\n",
      "Epoch 85/200, Iteration 26/250, Loss: 0.0127\n",
      "Epoch 85/200, Iteration 27/250, Loss: 0.0081\n",
      "Epoch 85/200, Iteration 28/250, Loss: 0.0094\n",
      "Epoch 85/200, Iteration 29/250, Loss: 0.0422\n",
      "Epoch 85/200, Iteration 30/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 31/250, Loss: 0.0203\n",
      "Epoch 85/200, Iteration 32/250, Loss: 0.0104\n",
      "Epoch 85/200, Iteration 33/250, Loss: 0.0298\n",
      "Epoch 85/200, Iteration 34/250, Loss: 0.0108\n",
      "Epoch 85/200, Iteration 35/250, Loss: 0.0102\n",
      "Epoch 85/200, Iteration 36/250, Loss: 0.0137\n",
      "Epoch 85/200, Iteration 37/250, Loss: 0.0180\n",
      "Epoch 85/200, Iteration 38/250, Loss: 0.0261\n",
      "Epoch 85/200, Iteration 39/250, Loss: 0.0291\n",
      "Epoch 85/200, Iteration 40/250, Loss: 0.0352\n",
      "Epoch 85/200, Iteration 41/250, Loss: 0.0194\n",
      "Epoch 85/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 43/250, Loss: 0.0134\n",
      "Epoch 85/200, Iteration 44/250, Loss: 0.0104\n",
      "Epoch 85/200, Iteration 45/250, Loss: 0.0081\n",
      "Epoch 85/200, Iteration 46/250, Loss: 0.0184\n",
      "Epoch 85/200, Iteration 47/250, Loss: 0.0202\n",
      "Epoch 85/200, Iteration 48/250, Loss: 0.0111\n",
      "Epoch 85/200, Iteration 49/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 50/250, Loss: 0.0095\n",
      "Epoch 85/200, Iteration 51/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 52/250, Loss: 0.0134\n",
      "Epoch 85/200, Iteration 53/250, Loss: 0.0219\n",
      "Epoch 85/200, Iteration 54/250, Loss: 0.0098\n",
      "Epoch 85/200, Iteration 55/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 56/250, Loss: 0.0058\n",
      "Epoch 85/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 85/200, Iteration 58/250, Loss: 0.0123\n",
      "Epoch 85/200, Iteration 59/250, Loss: 0.0248\n",
      "Epoch 85/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 85/200, Iteration 61/250, Loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200, Iteration 62/250, Loss: 0.0165\n",
      "Epoch 85/200, Iteration 63/250, Loss: 0.0489\n",
      "Epoch 85/200, Iteration 64/250, Loss: 0.0199\n",
      "Epoch 85/200, Iteration 65/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 66/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 67/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 68/250, Loss: 0.0104\n",
      "Epoch 85/200, Iteration 69/250, Loss: 0.0077\n",
      "Epoch 85/200, Iteration 70/250, Loss: 0.0416\n",
      "Epoch 85/200, Iteration 71/250, Loss: 0.0079\n",
      "Epoch 85/200, Iteration 72/250, Loss: 0.0119\n",
      "Epoch 85/200, Iteration 73/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 74/250, Loss: 0.0088\n",
      "Epoch 85/200, Iteration 75/250, Loss: 0.0155\n",
      "Epoch 85/200, Iteration 76/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 77/250, Loss: 0.0078\n",
      "Epoch 85/200, Iteration 78/250, Loss: 0.0157\n",
      "Epoch 85/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 80/250, Loss: 0.0116\n",
      "Epoch 85/200, Iteration 81/250, Loss: 0.0151\n",
      "Epoch 85/200, Iteration 82/250, Loss: 0.0226\n",
      "Epoch 85/200, Iteration 83/250, Loss: 0.0119\n",
      "Epoch 85/200, Iteration 84/250, Loss: 0.0353\n",
      "Epoch 85/200, Iteration 85/250, Loss: 0.0221\n",
      "Epoch 85/200, Iteration 86/250, Loss: 0.0127\n",
      "Epoch 85/200, Iteration 87/250, Loss: 0.0107\n",
      "Epoch 85/200, Iteration 88/250, Loss: 0.0130\n",
      "Epoch 85/200, Iteration 89/250, Loss: 0.0210\n",
      "Epoch 85/200, Iteration 90/250, Loss: 0.0108\n",
      "Epoch 85/200, Iteration 91/250, Loss: 0.0202\n",
      "Epoch 85/200, Iteration 92/250, Loss: 0.0157\n",
      "Epoch 85/200, Iteration 93/250, Loss: 0.0143\n",
      "Epoch 85/200, Iteration 94/250, Loss: 0.0323\n",
      "Epoch 85/200, Iteration 95/250, Loss: 0.0141\n",
      "Epoch 85/200, Iteration 96/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 97/250, Loss: 0.0178\n",
      "Epoch 85/200, Iteration 98/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 99/250, Loss: 0.0114\n",
      "Epoch 85/200, Iteration 100/250, Loss: 0.0156\n",
      "Epoch 85/200, Iteration 101/250, Loss: 0.0139\n",
      "Epoch 85/200, Iteration 102/250, Loss: 0.0092\n",
      "Epoch 85/200, Iteration 103/250, Loss: 0.0196\n",
      "Epoch 85/200, Iteration 104/250, Loss: 0.0202\n",
      "Epoch 85/200, Iteration 105/250, Loss: 0.0098\n",
      "Epoch 85/200, Iteration 106/250, Loss: 0.0094\n",
      "Epoch 85/200, Iteration 107/250, Loss: 0.0164\n",
      "Epoch 85/200, Iteration 108/250, Loss: 0.0152\n",
      "Epoch 85/200, Iteration 109/250, Loss: 0.0293\n",
      "Epoch 85/200, Iteration 110/250, Loss: 0.0217\n",
      "Epoch 85/200, Iteration 111/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 112/250, Loss: 0.0136\n",
      "Epoch 85/200, Iteration 113/250, Loss: 0.0172\n",
      "Epoch 85/200, Iteration 114/250, Loss: 0.0158\n",
      "Epoch 85/200, Iteration 115/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 116/250, Loss: 0.0264\n",
      "Epoch 85/200, Iteration 117/250, Loss: 0.0171\n",
      "Epoch 85/200, Iteration 118/250, Loss: 0.0205\n",
      "Epoch 85/200, Iteration 119/250, Loss: 0.0219\n",
      "Epoch 85/200, Iteration 120/250, Loss: 0.0131\n",
      "Epoch 85/200, Iteration 121/250, Loss: 0.0068\n",
      "Epoch 85/200, Iteration 122/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 123/250, Loss: 0.0229\n",
      "Epoch 85/200, Iteration 124/250, Loss: 0.0145\n",
      "Epoch 85/200, Iteration 125/250, Loss: 0.0359\n",
      "Epoch 85/200, Iteration 126/250, Loss: 0.0137\n",
      "Epoch 85/200, Iteration 127/250, Loss: 0.0125\n",
      "Epoch 85/200, Iteration 128/250, Loss: 0.0281\n",
      "Epoch 85/200, Iteration 129/250, Loss: 0.0118\n",
      "Epoch 85/200, Iteration 130/250, Loss: 0.0080\n",
      "Epoch 85/200, Iteration 131/250, Loss: 0.0190\n",
      "Epoch 85/200, Iteration 132/250, Loss: 0.0081\n",
      "Epoch 85/200, Iteration 133/250, Loss: 0.0221\n",
      "Epoch 85/200, Iteration 134/250, Loss: 0.0291\n",
      "Epoch 85/200, Iteration 135/250, Loss: 0.0140\n",
      "Epoch 85/200, Iteration 136/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 137/250, Loss: 0.0090\n",
      "Epoch 85/200, Iteration 138/250, Loss: 0.0084\n",
      "Epoch 85/200, Iteration 139/250, Loss: 0.0511\n",
      "Epoch 85/200, Iteration 140/250, Loss: 0.0224\n",
      "Epoch 85/200, Iteration 141/250, Loss: 0.0095\n",
      "Epoch 85/200, Iteration 142/250, Loss: 0.0245\n",
      "Epoch 85/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 85/200, Iteration 144/250, Loss: 0.0232\n",
      "Epoch 85/200, Iteration 145/250, Loss: 0.0175\n",
      "Epoch 85/200, Iteration 146/250, Loss: 0.0159\n",
      "Epoch 85/200, Iteration 147/250, Loss: 0.0166\n",
      "Epoch 85/200, Iteration 148/250, Loss: 0.0079\n",
      "Epoch 85/200, Iteration 149/250, Loss: 0.0080\n",
      "Epoch 85/200, Iteration 150/250, Loss: 0.0110\n",
      "Epoch 85/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 85/200, Iteration 152/250, Loss: 0.0069\n",
      "Epoch 85/200, Iteration 153/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 154/250, Loss: 0.0302\n",
      "Epoch 85/200, Iteration 155/250, Loss: 0.0101\n",
      "Epoch 85/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 85/200, Iteration 157/250, Loss: 0.0079\n",
      "Epoch 85/200, Iteration 158/250, Loss: 0.0125\n",
      "Epoch 85/200, Iteration 159/250, Loss: 0.0106\n",
      "Epoch 85/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 85/200, Iteration 161/250, Loss: 0.0111\n",
      "Epoch 85/200, Iteration 162/250, Loss: 0.0179\n",
      "Epoch 85/200, Iteration 163/250, Loss: 0.0211\n",
      "Epoch 85/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 85/200, Iteration 165/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 85/200, Iteration 167/250, Loss: 0.0126\n",
      "Epoch 85/200, Iteration 168/250, Loss: 0.0071\n",
      "Epoch 85/200, Iteration 169/250, Loss: 0.0183\n",
      "Epoch 85/200, Iteration 170/250, Loss: 0.0148\n",
      "Epoch 85/200, Iteration 171/250, Loss: 0.0094\n",
      "Epoch 85/200, Iteration 172/250, Loss: 0.0113\n",
      "Epoch 85/200, Iteration 173/250, Loss: 0.0260\n",
      "Epoch 85/200, Iteration 174/250, Loss: 0.0105\n",
      "Epoch 85/200, Iteration 175/250, Loss: 0.0073\n",
      "Epoch 85/200, Iteration 176/250, Loss: 0.0307\n",
      "Epoch 85/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 85/200, Iteration 178/250, Loss: 0.0089\n",
      "Epoch 85/200, Iteration 179/250, Loss: 0.0068\n",
      "Epoch 85/200, Iteration 180/250, Loss: 0.0298\n",
      "Epoch 85/200, Iteration 181/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 182/250, Loss: 0.0177\n",
      "Epoch 85/200, Iteration 183/250, Loss: 0.0190\n",
      "Epoch 85/200, Iteration 184/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 185/250, Loss: 0.0095\n",
      "Epoch 85/200, Iteration 186/250, Loss: 0.0305\n",
      "Epoch 85/200, Iteration 187/250, Loss: 0.0083\n",
      "Epoch 85/200, Iteration 188/250, Loss: 0.0294\n",
      "Epoch 85/200, Iteration 189/250, Loss: 0.0135\n",
      "Epoch 85/200, Iteration 190/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 191/250, Loss: 0.0150\n",
      "Epoch 85/200, Iteration 192/250, Loss: 0.0208\n",
      "Epoch 85/200, Iteration 193/250, Loss: 0.0110\n",
      "Epoch 85/200, Iteration 194/250, Loss: 0.0093\n",
      "Epoch 85/200, Iteration 195/250, Loss: 0.0221\n",
      "Epoch 85/200, Iteration 196/250, Loss: 0.0252\n",
      "Epoch 85/200, Iteration 197/250, Loss: 0.0421\n",
      "Epoch 85/200, Iteration 198/250, Loss: 0.0104\n",
      "Epoch 85/200, Iteration 199/250, Loss: 0.0209\n",
      "Epoch 85/200, Iteration 200/250, Loss: 0.0096\n",
      "Epoch 85/200, Iteration 201/250, Loss: 0.0195\n",
      "Epoch 85/200, Iteration 202/250, Loss: 0.0073\n",
      "Epoch 85/200, Iteration 203/250, Loss: 0.0281\n",
      "Epoch 85/200, Iteration 204/250, Loss: 0.0132\n",
      "Epoch 85/200, Iteration 205/250, Loss: 0.0363\n",
      "Epoch 85/200, Iteration 206/250, Loss: 0.0103\n",
      "Epoch 85/200, Iteration 207/250, Loss: 0.0092\n",
      "Epoch 85/200, Iteration 208/250, Loss: 0.0152\n",
      "Epoch 85/200, Iteration 209/250, Loss: 0.0068\n",
      "Epoch 85/200, Iteration 210/250, Loss: 0.0158\n",
      "Epoch 85/200, Iteration 211/250, Loss: 0.0237\n",
      "Epoch 85/200, Iteration 212/250, Loss: 0.0202\n",
      "Epoch 85/200, Iteration 213/250, Loss: 0.0208\n",
      "Epoch 85/200, Iteration 214/250, Loss: 0.0057\n",
      "Epoch 85/200, Iteration 215/250, Loss: 0.0352\n",
      "Epoch 85/200, Iteration 216/250, Loss: 0.0157\n",
      "Epoch 85/200, Iteration 217/250, Loss: 0.0107\n",
      "Epoch 85/200, Iteration 218/250, Loss: 0.0183\n",
      "Epoch 85/200, Iteration 219/250, Loss: 0.0097\n",
      "Epoch 85/200, Iteration 220/250, Loss: 0.0128\n",
      "Epoch 85/200, Iteration 221/250, Loss: 0.0199\n",
      "Epoch 85/200, Iteration 222/250, Loss: 0.0156\n",
      "Epoch 85/200, Iteration 223/250, Loss: 0.0196\n",
      "Epoch 85/200, Iteration 224/250, Loss: 0.0242\n",
      "Epoch 85/200, Iteration 225/250, Loss: 0.0117\n",
      "Epoch 85/200, Iteration 226/250, Loss: 0.0133\n",
      "Epoch 85/200, Iteration 227/250, Loss: 0.0252\n",
      "Epoch 85/200, Iteration 228/250, Loss: 0.0141\n",
      "Epoch 85/200, Iteration 229/250, Loss: 0.0114\n",
      "Epoch 85/200, Iteration 230/250, Loss: 0.0314\n",
      "Epoch 85/200, Iteration 231/250, Loss: 0.0263\n",
      "Epoch 85/200, Iteration 232/250, Loss: 0.0099\n",
      "Epoch 85/200, Iteration 233/250, Loss: 0.0069\n",
      "Epoch 85/200, Iteration 234/250, Loss: 0.0095\n",
      "Epoch 85/200, Iteration 235/250, Loss: 0.0204\n",
      "Epoch 85/200, Iteration 236/250, Loss: 0.0121\n",
      "Epoch 85/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 85/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 85/200, Iteration 239/250, Loss: 0.0046\n",
      "Epoch 85/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 85/200, Iteration 241/250, Loss: 0.0089\n",
      "Epoch 85/200, Iteration 242/250, Loss: 0.0147\n",
      "Epoch 85/200, Iteration 243/250, Loss: 0.0085\n",
      "Epoch 85/200, Iteration 244/250, Loss: 0.0146\n",
      "Epoch 85/200, Iteration 245/250, Loss: 0.0233\n",
      "Epoch 85/200, Iteration 246/250, Loss: 0.0303\n",
      "Epoch 85/200, Iteration 247/250, Loss: 0.0219\n",
      "Epoch 85/200, Iteration 248/250, Loss: 0.0277\n",
      "Epoch 85/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 85/200, Iteration 250/250, Loss: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.007165, MRE: 0.471559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.007891, MRE: 0.563364 \n",
      "\n",
      "Epoch 86/200, Iteration 1/250, Loss: 0.0141\n",
      "Epoch 86/200, Iteration 2/250, Loss: 0.0164\n",
      "Epoch 86/200, Iteration 3/250, Loss: 0.0221\n",
      "Epoch 86/200, Iteration 4/250, Loss: 0.0076\n",
      "Epoch 86/200, Iteration 5/250, Loss: 0.0277\n",
      "Epoch 86/200, Iteration 6/250, Loss: 0.0127\n",
      "Epoch 86/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 8/250, Loss: 0.0209\n",
      "Epoch 86/200, Iteration 9/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 10/250, Loss: 0.0220\n",
      "Epoch 86/200, Iteration 11/250, Loss: 0.0136\n",
      "Epoch 86/200, Iteration 12/250, Loss: 0.0233\n",
      "Epoch 86/200, Iteration 13/250, Loss: 0.0119\n",
      "Epoch 86/200, Iteration 14/250, Loss: 0.0220\n",
      "Epoch 86/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 16/250, Loss: 0.0215\n",
      "Epoch 86/200, Iteration 17/250, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 18/250, Loss: 0.0071\n",
      "Epoch 86/200, Iteration 19/250, Loss: 0.0131\n",
      "Epoch 86/200, Iteration 20/250, Loss: 0.0155\n",
      "Epoch 86/200, Iteration 21/250, Loss: 0.0250\n",
      "Epoch 86/200, Iteration 22/250, Loss: 0.0156\n",
      "Epoch 86/200, Iteration 23/250, Loss: 0.0180\n",
      "Epoch 86/200, Iteration 24/250, Loss: 0.0126\n",
      "Epoch 86/200, Iteration 25/250, Loss: 0.0213\n",
      "Epoch 86/200, Iteration 26/250, Loss: 0.0247\n",
      "Epoch 86/200, Iteration 27/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 28/250, Loss: 0.0153\n",
      "Epoch 86/200, Iteration 29/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 30/250, Loss: 0.0076\n",
      "Epoch 86/200, Iteration 31/250, Loss: 0.0168\n",
      "Epoch 86/200, Iteration 32/250, Loss: 0.0068\n",
      "Epoch 86/200, Iteration 33/250, Loss: 0.0125\n",
      "Epoch 86/200, Iteration 34/250, Loss: 0.0205\n",
      "Epoch 86/200, Iteration 35/250, Loss: 0.0208\n",
      "Epoch 86/200, Iteration 36/250, Loss: 0.0092\n",
      "Epoch 86/200, Iteration 37/250, Loss: 0.0101\n",
      "Epoch 86/200, Iteration 38/250, Loss: 0.0233\n",
      "Epoch 86/200, Iteration 39/250, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 41/250, Loss: 0.0125\n",
      "Epoch 86/200, Iteration 42/250, Loss: 0.0178\n",
      "Epoch 86/200, Iteration 43/250, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 86/200, Iteration 45/250, Loss: 0.0171\n",
      "Epoch 86/200, Iteration 46/250, Loss: 0.0147\n",
      "Epoch 86/200, Iteration 47/250, Loss: 0.0141\n",
      "Epoch 86/200, Iteration 48/250, Loss: 0.0118\n",
      "Epoch 86/200, Iteration 49/250, Loss: 0.0168\n",
      "Epoch 86/200, Iteration 50/250, Loss: 0.0133\n",
      "Epoch 86/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 86/200, Iteration 52/250, Loss: 0.0081\n",
      "Epoch 86/200, Iteration 53/250, Loss: 0.0176\n",
      "Epoch 86/200, Iteration 54/250, Loss: 0.0210\n",
      "Epoch 86/200, Iteration 55/250, Loss: 0.0233\n",
      "Epoch 86/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 86/200, Iteration 57/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 58/250, Loss: 0.0154\n",
      "Epoch 86/200, Iteration 59/250, Loss: 0.0221\n",
      "Epoch 86/200, Iteration 60/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 61/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 86/200, Iteration 63/250, Loss: 0.0254\n",
      "Epoch 86/200, Iteration 64/250, Loss: 0.0112\n",
      "Epoch 86/200, Iteration 65/250, Loss: 0.0172\n",
      "Epoch 86/200, Iteration 66/250, Loss: 0.0313\n",
      "Epoch 86/200, Iteration 67/250, Loss: 0.0249\n",
      "Epoch 86/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 69/250, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 70/250, Loss: 0.0079\n",
      "Epoch 86/200, Iteration 71/250, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 72/250, Loss: 0.0143\n",
      "Epoch 86/200, Iteration 73/250, Loss: 0.0081\n",
      "Epoch 86/200, Iteration 74/250, Loss: 0.0088\n",
      "Epoch 86/200, Iteration 75/250, Loss: 0.0235\n",
      "Epoch 86/200, Iteration 76/250, Loss: 0.0183\n",
      "Epoch 86/200, Iteration 77/250, Loss: 0.0090\n",
      "Epoch 86/200, Iteration 78/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 79/250, Loss: 0.0117\n",
      "Epoch 86/200, Iteration 80/250, Loss: 0.0088\n",
      "Epoch 86/200, Iteration 81/250, Loss: 0.0278\n",
      "Epoch 86/200, Iteration 82/250, Loss: 0.0119\n",
      "Epoch 86/200, Iteration 83/250, Loss: 0.0117\n",
      "Epoch 86/200, Iteration 84/250, Loss: 0.0150\n",
      "Epoch 86/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 86/200, Iteration 86/250, Loss: 0.0212\n",
      "Epoch 86/200, Iteration 87/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 88/250, Loss: 0.0228\n",
      "Epoch 86/200, Iteration 89/250, Loss: 0.0133\n",
      "Epoch 86/200, Iteration 90/250, Loss: 0.0143\n",
      "Epoch 86/200, Iteration 91/250, Loss: 0.0349\n",
      "Epoch 86/200, Iteration 92/250, Loss: 0.0116\n",
      "Epoch 86/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 94/250, Loss: 0.0150\n",
      "Epoch 86/200, Iteration 95/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 96/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 97/250, Loss: 0.0128\n",
      "Epoch 86/200, Iteration 98/250, Loss: 0.0097\n",
      "Epoch 86/200, Iteration 99/250, Loss: 0.0053\n",
      "Epoch 86/200, Iteration 100/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 101/250, Loss: 0.0090\n",
      "Epoch 86/200, Iteration 102/250, Loss: 0.0108\n",
      "Epoch 86/200, Iteration 103/250, Loss: 0.0117\n",
      "Epoch 86/200, Iteration 104/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 105/250, Loss: 0.0118\n",
      "Epoch 86/200, Iteration 106/250, Loss: 0.0104\n",
      "Epoch 86/200, Iteration 107/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 108/250, Loss: 0.0136\n",
      "Epoch 86/200, Iteration 109/250, Loss: 0.0257\n",
      "Epoch 86/200, Iteration 110/250, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 112/250, Loss: 0.0192\n",
      "Epoch 86/200, Iteration 113/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 114/250, Loss: 0.0191\n",
      "Epoch 86/200, Iteration 115/250, Loss: 0.0091\n",
      "Epoch 86/200, Iteration 116/250, Loss: 0.0200\n",
      "Epoch 86/200, Iteration 117/250, Loss: 0.0136\n",
      "Epoch 86/200, Iteration 118/250, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 119/250, Loss: 0.0101\n",
      "Epoch 86/200, Iteration 120/250, Loss: 0.0147\n",
      "Epoch 86/200, Iteration 121/250, Loss: 0.0171\n",
      "Epoch 86/200, Iteration 122/250, Loss: 0.0195\n",
      "Epoch 86/200, Iteration 123/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 124/250, Loss: 0.0242\n",
      "Epoch 86/200, Iteration 125/250, Loss: 0.0108\n",
      "Epoch 86/200, Iteration 126/250, Loss: 0.0128\n",
      "Epoch 86/200, Iteration 127/250, Loss: 0.0122\n",
      "Epoch 86/200, Iteration 128/250, Loss: 0.0254\n",
      "Epoch 86/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 86/200, Iteration 130/250, Loss: 0.0382\n",
      "Epoch 86/200, Iteration 131/250, Loss: 0.0109\n",
      "Epoch 86/200, Iteration 132/250, Loss: 0.0161\n",
      "Epoch 86/200, Iteration 133/250, Loss: 0.0357\n",
      "Epoch 86/200, Iteration 134/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 135/250, Loss: 0.0532\n",
      "Epoch 86/200, Iteration 136/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 137/250, Loss: 0.0099\n",
      "Epoch 86/200, Iteration 138/250, Loss: 0.0282\n",
      "Epoch 86/200, Iteration 139/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 140/250, Loss: 0.0094\n",
      "Epoch 86/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 86/200, Iteration 142/250, Loss: 0.0092\n",
      "Epoch 86/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 86/200, Iteration 144/250, Loss: 0.0169\n",
      "Epoch 86/200, Iteration 145/250, Loss: 0.0078\n",
      "Epoch 86/200, Iteration 146/250, Loss: 0.0129\n",
      "Epoch 86/200, Iteration 147/250, Loss: 0.0167\n",
      "Epoch 86/200, Iteration 148/250, Loss: 0.0154\n",
      "Epoch 86/200, Iteration 149/250, Loss: 0.0231\n",
      "Epoch 86/200, Iteration 150/250, Loss: 0.0111\n",
      "Epoch 86/200, Iteration 151/250, Loss: 0.0199\n",
      "Epoch 86/200, Iteration 152/250, Loss: 0.0282\n",
      "Epoch 86/200, Iteration 153/250, Loss: 0.0126\n",
      "Epoch 86/200, Iteration 154/250, Loss: 0.0194\n",
      "Epoch 86/200, Iteration 155/250, Loss: 0.0438\n",
      "Epoch 86/200, Iteration 156/250, Loss: 0.0128\n",
      "Epoch 86/200, Iteration 157/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 158/250, Loss: 0.0123\n",
      "Epoch 86/200, Iteration 159/250, Loss: 0.0105\n",
      "Epoch 86/200, Iteration 160/250, Loss: 0.0134\n",
      "Epoch 86/200, Iteration 161/250, Loss: 0.0153\n",
      "Epoch 86/200, Iteration 162/250, Loss: 0.0080\n",
      "Epoch 86/200, Iteration 163/250, Loss: 0.0216\n",
      "Epoch 86/200, Iteration 164/250, Loss: 0.0213\n",
      "Epoch 86/200, Iteration 165/250, Loss: 0.0138\n",
      "Epoch 86/200, Iteration 166/250, Loss: 0.0293\n",
      "Epoch 86/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 86/200, Iteration 168/250, Loss: 0.0104\n",
      "Epoch 86/200, Iteration 169/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 170/250, Loss: 0.0084\n",
      "Epoch 86/200, Iteration 171/250, Loss: 0.0145\n",
      "Epoch 86/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 86/200, Iteration 173/250, Loss: 0.0116\n",
      "Epoch 86/200, Iteration 174/250, Loss: 0.0115\n",
      "Epoch 86/200, Iteration 175/250, Loss: 0.0105\n",
      "Epoch 86/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 86/200, Iteration 177/250, Loss: 0.0127\n",
      "Epoch 86/200, Iteration 178/250, Loss: 0.0149\n",
      "Epoch 86/200, Iteration 179/250, Loss: 0.0193\n",
      "Epoch 86/200, Iteration 180/250, Loss: 0.0319\n",
      "Epoch 86/200, Iteration 181/250, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 182/250, Loss: 0.0146\n",
      "Epoch 86/200, Iteration 183/250, Loss: 0.0123\n",
      "Epoch 86/200, Iteration 184/250, Loss: 0.0160\n",
      "Epoch 86/200, Iteration 185/250, Loss: 0.0198\n",
      "Epoch 86/200, Iteration 186/250, Loss: 0.0096\n",
      "Epoch 86/200, Iteration 187/250, Loss: 0.0089\n",
      "Epoch 86/200, Iteration 188/250, Loss: 0.0095\n",
      "Epoch 86/200, Iteration 189/250, Loss: 0.0125\n",
      "Epoch 86/200, Iteration 190/250, Loss: 0.0092\n",
      "Epoch 86/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 86/200, Iteration 192/250, Loss: 0.0166\n",
      "Epoch 86/200, Iteration 193/250, Loss: 0.0126\n",
      "Epoch 86/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 86/200, Iteration 195/250, Loss: 0.0116\n",
      "Epoch 86/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 86/200, Iteration 197/250, Loss: 0.0082\n",
      "Epoch 86/200, Iteration 198/250, Loss: 0.0168\n",
      "Epoch 86/200, Iteration 199/250, Loss: 0.0220\n",
      "Epoch 86/200, Iteration 200/250, Loss: 0.0088\n",
      "Epoch 86/200, Iteration 201/250, Loss: 0.0200\n",
      "Epoch 86/200, Iteration 202/250, Loss: 0.0114\n",
      "Epoch 86/200, Iteration 203/250, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200, Iteration 204/250, Loss: 0.0306\n",
      "Epoch 86/200, Iteration 205/250, Loss: 0.0159\n",
      "Epoch 86/200, Iteration 206/250, Loss: 0.0309\n",
      "Epoch 86/200, Iteration 207/250, Loss: 0.0382\n",
      "Epoch 86/200, Iteration 208/250, Loss: 0.0156\n",
      "Epoch 86/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 86/200, Iteration 210/250, Loss: 0.0071\n",
      "Epoch 86/200, Iteration 211/250, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 212/250, Loss: 0.0107\n",
      "Epoch 86/200, Iteration 213/250, Loss: 0.0154\n",
      "Epoch 86/200, Iteration 214/250, Loss: 0.0097\n",
      "Epoch 86/200, Iteration 215/250, Loss: 0.0285\n",
      "Epoch 86/200, Iteration 216/250, Loss: 0.0139\n",
      "Epoch 86/200, Iteration 217/250, Loss: 0.0102\n",
      "Epoch 86/200, Iteration 218/250, Loss: 0.0232\n",
      "Epoch 86/200, Iteration 219/250, Loss: 0.0100\n",
      "Epoch 86/200, Iteration 220/250, Loss: 0.0253\n",
      "Epoch 86/200, Iteration 221/250, Loss: 0.0142\n",
      "Epoch 86/200, Iteration 222/250, Loss: 0.0119\n",
      "Epoch 86/200, Iteration 223/250, Loss: 0.0227\n",
      "Epoch 86/200, Iteration 224/250, Loss: 0.0087\n",
      "Epoch 86/200, Iteration 225/250, Loss: 0.0090\n",
      "Epoch 86/200, Iteration 226/250, Loss: 0.0203\n",
      "Epoch 86/200, Iteration 227/250, Loss: 0.0113\n",
      "Epoch 86/200, Iteration 228/250, Loss: 0.0220\n",
      "Epoch 86/200, Iteration 229/250, Loss: 0.0072\n",
      "Epoch 86/200, Iteration 230/250, Loss: 0.0194\n",
      "Epoch 86/200, Iteration 231/250, Loss: 0.0186\n",
      "Epoch 86/200, Iteration 232/250, Loss: 0.0179\n",
      "Epoch 86/200, Iteration 233/250, Loss: 0.0086\n",
      "Epoch 86/200, Iteration 234/250, Loss: 0.0093\n",
      "Epoch 86/200, Iteration 235/250, Loss: 0.0245\n",
      "Epoch 86/200, Iteration 236/250, Loss: 0.0113\n",
      "Epoch 86/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 86/200, Iteration 238/250, Loss: 0.0064\n",
      "Epoch 86/200, Iteration 239/250, Loss: 0.0281\n",
      "Epoch 86/200, Iteration 240/250, Loss: 0.0103\n",
      "Epoch 86/200, Iteration 241/250, Loss: 0.0098\n",
      "Epoch 86/200, Iteration 242/250, Loss: 0.0162\n",
      "Epoch 86/200, Iteration 243/250, Loss: 0.0202\n",
      "Epoch 86/200, Iteration 244/250, Loss: 0.0106\n",
      "Epoch 86/200, Iteration 245/250, Loss: 0.0203\n",
      "Epoch 86/200, Iteration 246/250, Loss: 0.0124\n",
      "Epoch 86/200, Iteration 247/250, Loss: 0.0174\n",
      "Epoch 86/200, Iteration 248/250, Loss: 0.0087\n",
      "Epoch 86/200, Iteration 249/250, Loss: 0.0270\n",
      "Epoch 86/200, Iteration 250/250, Loss: 0.0133\n",
      "Train Error: \n",
      " Accuracy: 80.73%, Avg loss: 0.007359, MRE: 0.470071 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.75%, Avg loss: 0.007837, MRE: 0.646116 \n",
      "\n",
      "Epoch 87/200, Iteration 1/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 2/250, Loss: 0.0063\n",
      "Epoch 87/200, Iteration 3/250, Loss: 0.0224\n",
      "Epoch 87/200, Iteration 4/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 5/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 7/250, Loss: 0.0067\n",
      "Epoch 87/200, Iteration 8/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 9/250, Loss: 0.0084\n",
      "Epoch 87/200, Iteration 10/250, Loss: 0.0227\n",
      "Epoch 87/200, Iteration 11/250, Loss: 0.0369\n",
      "Epoch 87/200, Iteration 12/250, Loss: 0.0086\n",
      "Epoch 87/200, Iteration 13/250, Loss: 0.0255\n",
      "Epoch 87/200, Iteration 14/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 15/250, Loss: 0.0071\n",
      "Epoch 87/200, Iteration 16/250, Loss: 0.0238\n",
      "Epoch 87/200, Iteration 17/250, Loss: 0.0323\n",
      "Epoch 87/200, Iteration 18/250, Loss: 0.0237\n",
      "Epoch 87/200, Iteration 19/250, Loss: 0.0166\n",
      "Epoch 87/200, Iteration 20/250, Loss: 0.0248\n",
      "Epoch 87/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 87/200, Iteration 22/250, Loss: 0.0300\n",
      "Epoch 87/200, Iteration 23/250, Loss: 0.0126\n",
      "Epoch 87/200, Iteration 24/250, Loss: 0.0155\n",
      "Epoch 87/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 87/200, Iteration 26/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 27/250, Loss: 0.0291\n",
      "Epoch 87/200, Iteration 28/250, Loss: 0.0154\n",
      "Epoch 87/200, Iteration 29/250, Loss: 0.0185\n",
      "Epoch 87/200, Iteration 30/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 31/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 32/250, Loss: 0.0211\n",
      "Epoch 87/200, Iteration 33/250, Loss: 0.0124\n",
      "Epoch 87/200, Iteration 34/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 35/250, Loss: 0.0120\n",
      "Epoch 87/200, Iteration 36/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 37/250, Loss: 0.0111\n",
      "Epoch 87/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 87/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 87/200, Iteration 40/250, Loss: 0.0178\n",
      "Epoch 87/200, Iteration 41/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 42/250, Loss: 0.0084\n",
      "Epoch 87/200, Iteration 43/250, Loss: 0.0147\n",
      "Epoch 87/200, Iteration 44/250, Loss: 0.0127\n",
      "Epoch 87/200, Iteration 45/250, Loss: 0.0078\n",
      "Epoch 87/200, Iteration 46/250, Loss: 0.0074\n",
      "Epoch 87/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 87/200, Iteration 49/250, Loss: 0.0169\n",
      "Epoch 87/200, Iteration 50/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 51/250, Loss: 0.0265\n",
      "Epoch 87/200, Iteration 52/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 53/250, Loss: 0.0073\n",
      "Epoch 87/200, Iteration 54/250, Loss: 0.0070\n",
      "Epoch 87/200, Iteration 55/250, Loss: 0.0126\n",
      "Epoch 87/200, Iteration 56/250, Loss: 0.0069\n",
      "Epoch 87/200, Iteration 57/250, Loss: 0.0129\n",
      "Epoch 87/200, Iteration 58/250, Loss: 0.0116\n",
      "Epoch 87/200, Iteration 59/250, Loss: 0.0329\n",
      "Epoch 87/200, Iteration 60/250, Loss: 0.0167\n",
      "Epoch 87/200, Iteration 61/250, Loss: 0.0112\n",
      "Epoch 87/200, Iteration 62/250, Loss: 0.0171\n",
      "Epoch 87/200, Iteration 63/250, Loss: 0.0256\n",
      "Epoch 87/200, Iteration 64/250, Loss: 0.0177\n",
      "Epoch 87/200, Iteration 65/250, Loss: 0.0130\n",
      "Epoch 87/200, Iteration 66/250, Loss: 0.0158\n",
      "Epoch 87/200, Iteration 67/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 68/250, Loss: 0.0222\n",
      "Epoch 87/200, Iteration 69/250, Loss: 0.0147\n",
      "Epoch 87/200, Iteration 70/250, Loss: 0.0144\n",
      "Epoch 87/200, Iteration 71/250, Loss: 0.0065\n",
      "Epoch 87/200, Iteration 72/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 73/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 74/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 75/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 76/250, Loss: 0.0184\n",
      "Epoch 87/200, Iteration 77/250, Loss: 0.0142\n",
      "Epoch 87/200, Iteration 78/250, Loss: 0.0106\n",
      "Epoch 87/200, Iteration 79/250, Loss: 0.0200\n",
      "Epoch 87/200, Iteration 80/250, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 81/250, Loss: 0.0104\n",
      "Epoch 87/200, Iteration 82/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 83/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 84/250, Loss: 0.0381\n",
      "Epoch 87/200, Iteration 85/250, Loss: 0.0148\n",
      "Epoch 87/200, Iteration 86/250, Loss: 0.0067\n",
      "Epoch 87/200, Iteration 87/250, Loss: 0.0115\n",
      "Epoch 87/200, Iteration 88/250, Loss: 0.0203\n",
      "Epoch 87/200, Iteration 89/250, Loss: 0.0126\n",
      "Epoch 87/200, Iteration 90/250, Loss: 0.0083\n",
      "Epoch 87/200, Iteration 91/250, Loss: 0.0195\n",
      "Epoch 87/200, Iteration 92/250, Loss: 0.0088\n",
      "Epoch 87/200, Iteration 93/250, Loss: 0.0091\n",
      "Epoch 87/200, Iteration 94/250, Loss: 0.0226\n",
      "Epoch 87/200, Iteration 95/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 96/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 97/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 99/250, Loss: 0.0137\n",
      "Epoch 87/200, Iteration 100/250, Loss: 0.0173\n",
      "Epoch 87/200, Iteration 101/250, Loss: 0.0221\n",
      "Epoch 87/200, Iteration 102/250, Loss: 0.0150\n",
      "Epoch 87/200, Iteration 103/250, Loss: 0.0097\n",
      "Epoch 87/200, Iteration 104/250, Loss: 0.0146\n",
      "Epoch 87/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 106/250, Loss: 0.0104\n",
      "Epoch 87/200, Iteration 107/250, Loss: 0.0126\n",
      "Epoch 87/200, Iteration 108/250, Loss: 0.0172\n",
      "Epoch 87/200, Iteration 109/250, Loss: 0.0260\n",
      "Epoch 87/200, Iteration 110/250, Loss: 0.0132\n",
      "Epoch 87/200, Iteration 111/250, Loss: 0.0074\n",
      "Epoch 87/200, Iteration 112/250, Loss: 0.0281\n",
      "Epoch 87/200, Iteration 113/250, Loss: 0.0229\n",
      "Epoch 87/200, Iteration 114/250, Loss: 0.0146\n",
      "Epoch 87/200, Iteration 115/250, Loss: 0.0335\n",
      "Epoch 87/200, Iteration 116/250, Loss: 0.0096\n",
      "Epoch 87/200, Iteration 117/250, Loss: 0.0197\n",
      "Epoch 87/200, Iteration 118/250, Loss: 0.0063\n",
      "Epoch 87/200, Iteration 119/250, Loss: 0.0159\n",
      "Epoch 87/200, Iteration 120/250, Loss: 0.0097\n",
      "Epoch 87/200, Iteration 121/250, Loss: 0.0136\n",
      "Epoch 87/200, Iteration 122/250, Loss: 0.0169\n",
      "Epoch 87/200, Iteration 123/250, Loss: 0.0172\n",
      "Epoch 87/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 87/200, Iteration 125/250, Loss: 0.0190\n",
      "Epoch 87/200, Iteration 126/250, Loss: 0.0248\n",
      "Epoch 87/200, Iteration 127/250, Loss: 0.0139\n",
      "Epoch 87/200, Iteration 128/250, Loss: 0.0150\n",
      "Epoch 87/200, Iteration 129/250, Loss: 0.0091\n",
      "Epoch 87/200, Iteration 130/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 131/250, Loss: 0.0070\n",
      "Epoch 87/200, Iteration 132/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 133/250, Loss: 0.0136\n",
      "Epoch 87/200, Iteration 134/250, Loss: 0.0329\n",
      "Epoch 87/200, Iteration 135/250, Loss: 0.0098\n",
      "Epoch 87/200, Iteration 136/250, Loss: 0.0066\n",
      "Epoch 87/200, Iteration 137/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 138/250, Loss: 0.0100\n",
      "Epoch 87/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 87/200, Iteration 140/250, Loss: 0.0179\n",
      "Epoch 87/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 142/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 143/250, Loss: 0.0154\n",
      "Epoch 87/200, Iteration 144/250, Loss: 0.0066\n",
      "Epoch 87/200, Iteration 145/250, Loss: 0.0234\n",
      "Epoch 87/200, Iteration 146/250, Loss: 0.0150\n",
      "Epoch 87/200, Iteration 147/250, Loss: 0.0106\n",
      "Epoch 87/200, Iteration 148/250, Loss: 0.0140\n",
      "Epoch 87/200, Iteration 149/250, Loss: 0.0106\n",
      "Epoch 87/200, Iteration 150/250, Loss: 0.0155\n",
      "Epoch 87/200, Iteration 151/250, Loss: 0.0268\n",
      "Epoch 87/200, Iteration 152/250, Loss: 0.0163\n",
      "Epoch 87/200, Iteration 153/250, Loss: 0.0138\n",
      "Epoch 87/200, Iteration 154/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 155/250, Loss: 0.0209\n",
      "Epoch 87/200, Iteration 156/250, Loss: 0.0185\n",
      "Epoch 87/200, Iteration 157/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 159/250, Loss: 0.0182\n",
      "Epoch 87/200, Iteration 160/250, Loss: 0.0154\n",
      "Epoch 87/200, Iteration 161/250, Loss: 0.0195\n",
      "Epoch 87/200, Iteration 162/250, Loss: 0.0376\n",
      "Epoch 87/200, Iteration 163/250, Loss: 0.0124\n",
      "Epoch 87/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 87/200, Iteration 165/250, Loss: 0.0091\n",
      "Epoch 87/200, Iteration 166/250, Loss: 0.0172\n",
      "Epoch 87/200, Iteration 167/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 168/250, Loss: 0.0142\n",
      "Epoch 87/200, Iteration 169/250, Loss: 0.0179\n",
      "Epoch 87/200, Iteration 170/250, Loss: 0.0184\n",
      "Epoch 87/200, Iteration 171/250, Loss: 0.0114\n",
      "Epoch 87/200, Iteration 172/250, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 173/250, Loss: 0.0141\n",
      "Epoch 87/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 175/250, Loss: 0.0331\n",
      "Epoch 87/200, Iteration 176/250, Loss: 0.0240\n",
      "Epoch 87/200, Iteration 177/250, Loss: 0.0223\n",
      "Epoch 87/200, Iteration 178/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 179/250, Loss: 0.0155\n",
      "Epoch 87/200, Iteration 180/250, Loss: 0.0120\n",
      "Epoch 87/200, Iteration 181/250, Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200, Iteration 182/250, Loss: 0.0169\n",
      "Epoch 87/200, Iteration 183/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 184/250, Loss: 0.0108\n",
      "Epoch 87/200, Iteration 185/250, Loss: 0.0078\n",
      "Epoch 87/200, Iteration 186/250, Loss: 0.0085\n",
      "Epoch 87/200, Iteration 187/250, Loss: 0.0093\n",
      "Epoch 87/200, Iteration 188/250, Loss: 0.0097\n",
      "Epoch 87/200, Iteration 189/250, Loss: 0.0163\n",
      "Epoch 87/200, Iteration 190/250, Loss: 0.0302\n",
      "Epoch 87/200, Iteration 191/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 192/250, Loss: 0.0079\n",
      "Epoch 87/200, Iteration 193/250, Loss: 0.0087\n",
      "Epoch 87/200, Iteration 194/250, Loss: 0.0131\n",
      "Epoch 87/200, Iteration 195/250, Loss: 0.0247\n",
      "Epoch 87/200, Iteration 196/250, Loss: 0.0116\n",
      "Epoch 87/200, Iteration 197/250, Loss: 0.0168\n",
      "Epoch 87/200, Iteration 198/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 199/250, Loss: 0.0082\n",
      "Epoch 87/200, Iteration 200/250, Loss: 0.0108\n",
      "Epoch 87/200, Iteration 201/250, Loss: 0.0122\n",
      "Epoch 87/200, Iteration 202/250, Loss: 0.0287\n",
      "Epoch 87/200, Iteration 203/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 204/250, Loss: 0.0303\n",
      "Epoch 87/200, Iteration 205/250, Loss: 0.0139\n",
      "Epoch 87/200, Iteration 206/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 207/250, Loss: 0.0175\n",
      "Epoch 87/200, Iteration 208/250, Loss: 0.0088\n",
      "Epoch 87/200, Iteration 209/250, Loss: 0.0110\n",
      "Epoch 87/200, Iteration 210/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 211/250, Loss: 0.0137\n",
      "Epoch 87/200, Iteration 212/250, Loss: 0.0129\n",
      "Epoch 87/200, Iteration 213/250, Loss: 0.0073\n",
      "Epoch 87/200, Iteration 214/250, Loss: 0.0124\n",
      "Epoch 87/200, Iteration 215/250, Loss: 0.0319\n",
      "Epoch 87/200, Iteration 216/250, Loss: 0.0107\n",
      "Epoch 87/200, Iteration 217/250, Loss: 0.0125\n",
      "Epoch 87/200, Iteration 218/250, Loss: 0.0524\n",
      "Epoch 87/200, Iteration 219/250, Loss: 0.0091\n",
      "Epoch 87/200, Iteration 220/250, Loss: 0.0123\n",
      "Epoch 87/200, Iteration 221/250, Loss: 0.0164\n",
      "Epoch 87/200, Iteration 222/250, Loss: 0.0112\n",
      "Epoch 87/200, Iteration 223/250, Loss: 0.0124\n",
      "Epoch 87/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 87/200, Iteration 225/250, Loss: 0.0071\n",
      "Epoch 87/200, Iteration 226/250, Loss: 0.0109\n",
      "Epoch 87/200, Iteration 227/250, Loss: 0.0247\n",
      "Epoch 87/200, Iteration 228/250, Loss: 0.0142\n",
      "Epoch 87/200, Iteration 229/250, Loss: 0.0124\n",
      "Epoch 87/200, Iteration 230/250, Loss: 0.0401\n",
      "Epoch 87/200, Iteration 231/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 232/250, Loss: 0.0162\n",
      "Epoch 87/200, Iteration 233/250, Loss: 0.0342\n",
      "Epoch 87/200, Iteration 234/250, Loss: 0.0090\n",
      "Epoch 87/200, Iteration 235/250, Loss: 0.0228\n",
      "Epoch 87/200, Iteration 236/250, Loss: 0.0258\n",
      "Epoch 87/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 87/200, Iteration 238/250, Loss: 0.0164\n",
      "Epoch 87/200, Iteration 239/250, Loss: 0.0184\n",
      "Epoch 87/200, Iteration 240/250, Loss: 0.0180\n",
      "Epoch 87/200, Iteration 241/250, Loss: 0.0105\n",
      "Epoch 87/200, Iteration 242/250, Loss: 0.0133\n",
      "Epoch 87/200, Iteration 243/250, Loss: 0.0213\n",
      "Epoch 87/200, Iteration 244/250, Loss: 0.0113\n",
      "Epoch 87/200, Iteration 245/250, Loss: 0.0092\n",
      "Epoch 87/200, Iteration 246/250, Loss: 0.0083\n",
      "Epoch 87/200, Iteration 247/250, Loss: 0.0099\n",
      "Epoch 87/200, Iteration 248/250, Loss: 0.0128\n",
      "Epoch 87/200, Iteration 249/250, Loss: 0.0119\n",
      "Epoch 87/200, Iteration 250/250, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 89.75%, Avg loss: 0.007049, MRE: 0.496548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.007535, MRE: 0.563488 \n",
      "\n",
      "Epoch 88/200, Iteration 1/250, Loss: 0.0230\n",
      "Epoch 88/200, Iteration 2/250, Loss: 0.0112\n",
      "Epoch 88/200, Iteration 3/250, Loss: 0.0234\n",
      "Epoch 88/200, Iteration 4/250, Loss: 0.0270\n",
      "Epoch 88/200, Iteration 5/250, Loss: 0.0157\n",
      "Epoch 88/200, Iteration 6/250, Loss: 0.0135\n",
      "Epoch 88/200, Iteration 7/250, Loss: 0.0098\n",
      "Epoch 88/200, Iteration 8/250, Loss: 0.0138\n",
      "Epoch 88/200, Iteration 9/250, Loss: 0.0266\n",
      "Epoch 88/200, Iteration 10/250, Loss: 0.0209\n",
      "Epoch 88/200, Iteration 11/250, Loss: 0.0354\n",
      "Epoch 88/200, Iteration 12/250, Loss: 0.0195\n",
      "Epoch 88/200, Iteration 13/250, Loss: 0.0094\n",
      "Epoch 88/200, Iteration 14/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 15/250, Loss: 0.0076\n",
      "Epoch 88/200, Iteration 16/250, Loss: 0.0268\n",
      "Epoch 88/200, Iteration 17/250, Loss: 0.0204\n",
      "Epoch 88/200, Iteration 18/250, Loss: 0.0430\n",
      "Epoch 88/200, Iteration 19/250, Loss: 0.0150\n",
      "Epoch 88/200, Iteration 20/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 21/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 22/250, Loss: 0.0106\n",
      "Epoch 88/200, Iteration 23/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 24/250, Loss: 0.0072\n",
      "Epoch 88/200, Iteration 25/250, Loss: 0.0081\n",
      "Epoch 88/200, Iteration 26/250, Loss: 0.0135\n",
      "Epoch 88/200, Iteration 27/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 28/250, Loss: 0.0157\n",
      "Epoch 88/200, Iteration 29/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 30/250, Loss: 0.0108\n",
      "Epoch 88/200, Iteration 31/250, Loss: 0.0314\n",
      "Epoch 88/200, Iteration 32/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 33/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 88/200, Iteration 35/250, Loss: 0.0088\n",
      "Epoch 88/200, Iteration 36/250, Loss: 0.0120\n",
      "Epoch 88/200, Iteration 37/250, Loss: 0.0093\n",
      "Epoch 88/200, Iteration 38/250, Loss: 0.0213\n",
      "Epoch 88/200, Iteration 39/250, Loss: 0.0244\n",
      "Epoch 88/200, Iteration 40/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 41/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 42/250, Loss: 0.0155\n",
      "Epoch 88/200, Iteration 43/250, Loss: 0.0211\n",
      "Epoch 88/200, Iteration 44/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 45/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 46/250, Loss: 0.0263\n",
      "Epoch 88/200, Iteration 47/250, Loss: 0.0107\n",
      "Epoch 88/200, Iteration 48/250, Loss: 0.0112\n",
      "Epoch 88/200, Iteration 49/250, Loss: 0.0159\n",
      "Epoch 88/200, Iteration 50/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 51/250, Loss: 0.0279\n",
      "Epoch 88/200, Iteration 52/250, Loss: 0.0149\n",
      "Epoch 88/200, Iteration 53/250, Loss: 0.0179\n",
      "Epoch 88/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 88/200, Iteration 55/250, Loss: 0.0185\n",
      "Epoch 88/200, Iteration 56/250, Loss: 0.0378\n",
      "Epoch 88/200, Iteration 57/250, Loss: 0.0343\n",
      "Epoch 88/200, Iteration 58/250, Loss: 0.0248\n",
      "Epoch 88/200, Iteration 59/250, Loss: 0.0213\n",
      "Epoch 88/200, Iteration 60/250, Loss: 0.0425\n",
      "Epoch 88/200, Iteration 61/250, Loss: 0.0110\n",
      "Epoch 88/200, Iteration 62/250, Loss: 0.0138\n",
      "Epoch 88/200, Iteration 63/250, Loss: 0.0095\n",
      "Epoch 88/200, Iteration 64/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 65/250, Loss: 0.0214\n",
      "Epoch 88/200, Iteration 66/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 67/250, Loss: 0.0207\n",
      "Epoch 88/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 69/250, Loss: 0.0379\n",
      "Epoch 88/200, Iteration 70/250, Loss: 0.0151\n",
      "Epoch 88/200, Iteration 71/250, Loss: 0.0252\n",
      "Epoch 88/200, Iteration 72/250, Loss: 0.0087\n",
      "Epoch 88/200, Iteration 73/250, Loss: 0.0267\n",
      "Epoch 88/200, Iteration 74/250, Loss: 0.0303\n",
      "Epoch 88/200, Iteration 75/250, Loss: 0.0336\n",
      "Epoch 88/200, Iteration 76/250, Loss: 0.0082\n",
      "Epoch 88/200, Iteration 77/250, Loss: 0.0147\n",
      "Epoch 88/200, Iteration 78/250, Loss: 0.0165\n",
      "Epoch 88/200, Iteration 79/250, Loss: 0.0081\n",
      "Epoch 88/200, Iteration 80/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 81/250, Loss: 0.0133\n",
      "Epoch 88/200, Iteration 82/250, Loss: 0.0140\n",
      "Epoch 88/200, Iteration 83/250, Loss: 0.0137\n",
      "Epoch 88/200, Iteration 84/250, Loss: 0.0061\n",
      "Epoch 88/200, Iteration 85/250, Loss: 0.0102\n",
      "Epoch 88/200, Iteration 86/250, Loss: 0.0323\n",
      "Epoch 88/200, Iteration 87/250, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 88/200, Iteration 89/250, Loss: 0.0318\n",
      "Epoch 88/200, Iteration 90/250, Loss: 0.0092\n",
      "Epoch 88/200, Iteration 91/250, Loss: 0.0122\n",
      "Epoch 88/200, Iteration 92/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 93/250, Loss: 0.0239\n",
      "Epoch 88/200, Iteration 94/250, Loss: 0.0076\n",
      "Epoch 88/200, Iteration 95/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 96/250, Loss: 0.0132\n",
      "Epoch 88/200, Iteration 97/250, Loss: 0.0173\n",
      "Epoch 88/200, Iteration 98/250, Loss: 0.0240\n",
      "Epoch 88/200, Iteration 99/250, Loss: 0.0246\n",
      "Epoch 88/200, Iteration 100/250, Loss: 0.0140\n",
      "Epoch 88/200, Iteration 101/250, Loss: 0.0133\n",
      "Epoch 88/200, Iteration 102/250, Loss: 0.0150\n",
      "Epoch 88/200, Iteration 103/250, Loss: 0.0217\n",
      "Epoch 88/200, Iteration 104/250, Loss: 0.0350\n",
      "Epoch 88/200, Iteration 105/250, Loss: 0.0230\n",
      "Epoch 88/200, Iteration 106/250, Loss: 0.0100\n",
      "Epoch 88/200, Iteration 107/250, Loss: 0.0086\n",
      "Epoch 88/200, Iteration 108/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 109/250, Loss: 0.0123\n",
      "Epoch 88/200, Iteration 110/250, Loss: 0.0294\n",
      "Epoch 88/200, Iteration 111/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 112/250, Loss: 0.0162\n",
      "Epoch 88/200, Iteration 113/250, Loss: 0.0182\n",
      "Epoch 88/200, Iteration 114/250, Loss: 0.0130\n",
      "Epoch 88/200, Iteration 115/250, Loss: 0.0231\n",
      "Epoch 88/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 88/200, Iteration 117/250, Loss: 0.0182\n",
      "Epoch 88/200, Iteration 118/250, Loss: 0.0238\n",
      "Epoch 88/200, Iteration 119/250, Loss: 0.0108\n",
      "Epoch 88/200, Iteration 120/250, Loss: 0.0293\n",
      "Epoch 88/200, Iteration 121/250, Loss: 0.0156\n",
      "Epoch 88/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 88/200, Iteration 123/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200, Iteration 124/250, Loss: 0.0225\n",
      "Epoch 88/200, Iteration 125/250, Loss: 0.0071\n",
      "Epoch 88/200, Iteration 126/250, Loss: 0.0127\n",
      "Epoch 88/200, Iteration 127/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 128/250, Loss: 0.0091\n",
      "Epoch 88/200, Iteration 129/250, Loss: 0.0211\n",
      "Epoch 88/200, Iteration 130/250, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 131/250, Loss: 0.0202\n",
      "Epoch 88/200, Iteration 132/250, Loss: 0.0125\n",
      "Epoch 88/200, Iteration 133/250, Loss: 0.0117\n",
      "Epoch 88/200, Iteration 134/250, Loss: 0.0241\n",
      "Epoch 88/200, Iteration 135/250, Loss: 0.0135\n",
      "Epoch 88/200, Iteration 136/250, Loss: 0.0338\n",
      "Epoch 88/200, Iteration 137/250, Loss: 0.0170\n",
      "Epoch 88/200, Iteration 138/250, Loss: 0.0261\n",
      "Epoch 88/200, Iteration 139/250, Loss: 0.0186\n",
      "Epoch 88/200, Iteration 140/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 141/250, Loss: 0.0140\n",
      "Epoch 88/200, Iteration 142/250, Loss: 0.0221\n",
      "Epoch 88/200, Iteration 143/250, Loss: 0.0090\n",
      "Epoch 88/200, Iteration 144/250, Loss: 0.0213\n",
      "Epoch 88/200, Iteration 145/250, Loss: 0.0244\n",
      "Epoch 88/200, Iteration 146/250, Loss: 0.0113\n",
      "Epoch 88/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 148/250, Loss: 0.0144\n",
      "Epoch 88/200, Iteration 149/250, Loss: 0.0067\n",
      "Epoch 88/200, Iteration 150/250, Loss: 0.0100\n",
      "Epoch 88/200, Iteration 151/250, Loss: 0.0158\n",
      "Epoch 88/200, Iteration 152/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 153/250, Loss: 0.0126\n",
      "Epoch 88/200, Iteration 154/250, Loss: 0.0068\n",
      "Epoch 88/200, Iteration 155/250, Loss: 0.0181\n",
      "Epoch 88/200, Iteration 156/250, Loss: 0.0069\n",
      "Epoch 88/200, Iteration 157/250, Loss: 0.0126\n",
      "Epoch 88/200, Iteration 158/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 159/250, Loss: 0.0076\n",
      "Epoch 88/200, Iteration 160/250, Loss: 0.0108\n",
      "Epoch 88/200, Iteration 161/250, Loss: 0.0177\n",
      "Epoch 88/200, Iteration 162/250, Loss: 0.0089\n",
      "Epoch 88/200, Iteration 163/250, Loss: 0.0090\n",
      "Epoch 88/200, Iteration 164/250, Loss: 0.0204\n",
      "Epoch 88/200, Iteration 165/250, Loss: 0.0187\n",
      "Epoch 88/200, Iteration 166/250, Loss: 0.0070\n",
      "Epoch 88/200, Iteration 167/250, Loss: 0.0201\n",
      "Epoch 88/200, Iteration 168/250, Loss: 0.0285\n",
      "Epoch 88/200, Iteration 169/250, Loss: 0.0109\n",
      "Epoch 88/200, Iteration 170/250, Loss: 0.0095\n",
      "Epoch 88/200, Iteration 171/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 172/250, Loss: 0.0226\n",
      "Epoch 88/200, Iteration 173/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 174/250, Loss: 0.0122\n",
      "Epoch 88/200, Iteration 175/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 176/250, Loss: 0.0193\n",
      "Epoch 88/200, Iteration 177/250, Loss: 0.0134\n",
      "Epoch 88/200, Iteration 178/250, Loss: 0.0072\n",
      "Epoch 88/200, Iteration 179/250, Loss: 0.0264\n",
      "Epoch 88/200, Iteration 180/250, Loss: 0.0131\n",
      "Epoch 88/200, Iteration 181/250, Loss: 0.0134\n",
      "Epoch 88/200, Iteration 182/250, Loss: 0.0163\n",
      "Epoch 88/200, Iteration 183/250, Loss: 0.0254\n",
      "Epoch 88/200, Iteration 184/250, Loss: 0.0101\n",
      "Epoch 88/200, Iteration 185/250, Loss: 0.0117\n",
      "Epoch 88/200, Iteration 186/250, Loss: 0.0342\n",
      "Epoch 88/200, Iteration 187/250, Loss: 0.0101\n",
      "Epoch 88/200, Iteration 188/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 189/250, Loss: 0.0103\n",
      "Epoch 88/200, Iteration 190/250, Loss: 0.0152\n",
      "Epoch 88/200, Iteration 191/250, Loss: 0.0132\n",
      "Epoch 88/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 193/250, Loss: 0.0135\n",
      "Epoch 88/200, Iteration 194/250, Loss: 0.0075\n",
      "Epoch 88/200, Iteration 195/250, Loss: 0.0118\n",
      "Epoch 88/200, Iteration 196/250, Loss: 0.0248\n",
      "Epoch 88/200, Iteration 197/250, Loss: 0.0081\n",
      "Epoch 88/200, Iteration 198/250, Loss: 0.0258\n",
      "Epoch 88/200, Iteration 199/250, Loss: 0.0247\n",
      "Epoch 88/200, Iteration 200/250, Loss: 0.0147\n",
      "Epoch 88/200, Iteration 201/250, Loss: 0.0145\n",
      "Epoch 88/200, Iteration 202/250, Loss: 0.0170\n",
      "Epoch 88/200, Iteration 203/250, Loss: 0.0200\n",
      "Epoch 88/200, Iteration 204/250, Loss: 0.0259\n",
      "Epoch 88/200, Iteration 205/250, Loss: 0.0108\n",
      "Epoch 88/200, Iteration 206/250, Loss: 0.0231\n",
      "Epoch 88/200, Iteration 207/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 208/250, Loss: 0.0102\n",
      "Epoch 88/200, Iteration 209/250, Loss: 0.0112\n",
      "Epoch 88/200, Iteration 210/250, Loss: 0.0291\n",
      "Epoch 88/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 88/200, Iteration 212/250, Loss: 0.0378\n",
      "Epoch 88/200, Iteration 213/250, Loss: 0.0070\n",
      "Epoch 88/200, Iteration 214/250, Loss: 0.0063\n",
      "Epoch 88/200, Iteration 215/250, Loss: 0.0212\n",
      "Epoch 88/200, Iteration 216/250, Loss: 0.0097\n",
      "Epoch 88/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 88/200, Iteration 218/250, Loss: 0.0121\n",
      "Epoch 88/200, Iteration 219/250, Loss: 0.0127\n",
      "Epoch 88/200, Iteration 220/250, Loss: 0.0153\n",
      "Epoch 88/200, Iteration 221/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 222/250, Loss: 0.0165\n",
      "Epoch 88/200, Iteration 223/250, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 224/250, Loss: 0.0084\n",
      "Epoch 88/200, Iteration 225/250, Loss: 0.0264\n",
      "Epoch 88/200, Iteration 226/250, Loss: 0.0129\n",
      "Epoch 88/200, Iteration 227/250, Loss: 0.0137\n",
      "Epoch 88/200, Iteration 228/250, Loss: 0.0185\n",
      "Epoch 88/200, Iteration 229/250, Loss: 0.0279\n",
      "Epoch 88/200, Iteration 230/250, Loss: 0.0099\n",
      "Epoch 88/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 88/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 88/200, Iteration 233/250, Loss: 0.0096\n",
      "Epoch 88/200, Iteration 234/250, Loss: 0.0097\n",
      "Epoch 88/200, Iteration 235/250, Loss: 0.0165\n",
      "Epoch 88/200, Iteration 236/250, Loss: 0.0293\n",
      "Epoch 88/200, Iteration 237/250, Loss: 0.0146\n",
      "Epoch 88/200, Iteration 238/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 239/250, Loss: 0.0136\n",
      "Epoch 88/200, Iteration 240/250, Loss: 0.0157\n",
      "Epoch 88/200, Iteration 241/250, Loss: 0.0156\n",
      "Epoch 88/200, Iteration 242/250, Loss: 0.0174\n",
      "Epoch 88/200, Iteration 243/250, Loss: 0.0139\n",
      "Epoch 88/200, Iteration 244/250, Loss: 0.0114\n",
      "Epoch 88/200, Iteration 245/250, Loss: 0.0187\n",
      "Epoch 88/200, Iteration 246/250, Loss: 0.0111\n",
      "Epoch 88/200, Iteration 247/250, Loss: 0.0157\n",
      "Epoch 88/200, Iteration 248/250, Loss: 0.0160\n",
      "Epoch 88/200, Iteration 249/250, Loss: 0.0092\n",
      "Epoch 88/200, Iteration 250/250, Loss: 0.0063\n",
      "Train Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.006966, MRE: 0.477788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.05%, Avg loss: 0.007600, MRE: 0.583537 \n",
      "\n",
      "Epoch 89/200, Iteration 1/250, Loss: 0.0070\n",
      "Epoch 89/200, Iteration 2/250, Loss: 0.0161\n",
      "Epoch 89/200, Iteration 3/250, Loss: 0.0144\n",
      "Epoch 89/200, Iteration 4/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 5/250, Loss: 0.0428\n",
      "Epoch 89/200, Iteration 6/250, Loss: 0.0172\n",
      "Epoch 89/200, Iteration 7/250, Loss: 0.0177\n",
      "Epoch 89/200, Iteration 8/250, Loss: 0.0108\n",
      "Epoch 89/200, Iteration 9/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 10/250, Loss: 0.0118\n",
      "Epoch 89/200, Iteration 11/250, Loss: 0.0226\n",
      "Epoch 89/200, Iteration 12/250, Loss: 0.0190\n",
      "Epoch 89/200, Iteration 13/250, Loss: 0.0085\n",
      "Epoch 89/200, Iteration 14/250, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 15/250, Loss: 0.0070\n",
      "Epoch 89/200, Iteration 16/250, Loss: 0.0120\n",
      "Epoch 89/200, Iteration 17/250, Loss: 0.0098\n",
      "Epoch 89/200, Iteration 18/250, Loss: 0.0078\n",
      "Epoch 89/200, Iteration 19/250, Loss: 0.0256\n",
      "Epoch 89/200, Iteration 20/250, Loss: 0.0104\n",
      "Epoch 89/200, Iteration 21/250, Loss: 0.0193\n",
      "Epoch 89/200, Iteration 22/250, Loss: 0.0223\n",
      "Epoch 89/200, Iteration 23/250, Loss: 0.0395\n",
      "Epoch 89/200, Iteration 24/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 26/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 27/250, Loss: 0.0232\n",
      "Epoch 89/200, Iteration 28/250, Loss: 0.0290\n",
      "Epoch 89/200, Iteration 29/250, Loss: 0.0219\n",
      "Epoch 89/200, Iteration 30/250, Loss: 0.0267\n",
      "Epoch 89/200, Iteration 31/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 32/250, Loss: 0.0304\n",
      "Epoch 89/200, Iteration 33/250, Loss: 0.0143\n",
      "Epoch 89/200, Iteration 34/250, Loss: 0.0085\n",
      "Epoch 89/200, Iteration 35/250, Loss: 0.0194\n",
      "Epoch 89/200, Iteration 36/250, Loss: 0.0107\n",
      "Epoch 89/200, Iteration 37/250, Loss: 0.0207\n",
      "Epoch 89/200, Iteration 38/250, Loss: 0.0161\n",
      "Epoch 89/200, Iteration 39/250, Loss: 0.0201\n",
      "Epoch 89/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 89/200, Iteration 41/250, Loss: 0.0083\n",
      "Epoch 89/200, Iteration 42/250, Loss: 0.0292\n",
      "Epoch 89/200, Iteration 43/250, Loss: 0.0141\n",
      "Epoch 89/200, Iteration 44/250, Loss: 0.0203\n",
      "Epoch 89/200, Iteration 45/250, Loss: 0.0300\n",
      "Epoch 89/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 89/200, Iteration 47/250, Loss: 0.0184\n",
      "Epoch 89/200, Iteration 48/250, Loss: 0.0139\n",
      "Epoch 89/200, Iteration 49/250, Loss: 0.0144\n",
      "Epoch 89/200, Iteration 50/250, Loss: 0.0430\n",
      "Epoch 89/200, Iteration 51/250, Loss: 0.0071\n",
      "Epoch 89/200, Iteration 52/250, Loss: 0.0095\n",
      "Epoch 89/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 89/200, Iteration 54/250, Loss: 0.0069\n",
      "Epoch 89/200, Iteration 55/250, Loss: 0.0197\n",
      "Epoch 89/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 57/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 58/250, Loss: 0.0208\n",
      "Epoch 89/200, Iteration 59/250, Loss: 0.0261\n",
      "Epoch 89/200, Iteration 60/250, Loss: 0.0158\n",
      "Epoch 89/200, Iteration 61/250, Loss: 0.0128\n",
      "Epoch 89/200, Iteration 62/250, Loss: 0.0152\n",
      "Epoch 89/200, Iteration 63/250, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200, Iteration 64/250, Loss: 0.0173\n",
      "Epoch 89/200, Iteration 65/250, Loss: 0.0333\n",
      "Epoch 89/200, Iteration 66/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 67/250, Loss: 0.0181\n",
      "Epoch 89/200, Iteration 68/250, Loss: 0.0104\n",
      "Epoch 89/200, Iteration 69/250, Loss: 0.0341\n",
      "Epoch 89/200, Iteration 70/250, Loss: 0.0164\n",
      "Epoch 89/200, Iteration 71/250, Loss: 0.0084\n",
      "Epoch 89/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 89/200, Iteration 73/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 74/250, Loss: 0.0137\n",
      "Epoch 89/200, Iteration 75/250, Loss: 0.0309\n",
      "Epoch 89/200, Iteration 76/250, Loss: 0.0124\n",
      "Epoch 89/200, Iteration 77/250, Loss: 0.0267\n",
      "Epoch 89/200, Iteration 78/250, Loss: 0.0059\n",
      "Epoch 89/200, Iteration 79/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 80/250, Loss: 0.0097\n",
      "Epoch 89/200, Iteration 81/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 89/200, Iteration 83/250, Loss: 0.0175\n",
      "Epoch 89/200, Iteration 84/250, Loss: 0.0069\n",
      "Epoch 89/200, Iteration 85/250, Loss: 0.0117\n",
      "Epoch 89/200, Iteration 86/250, Loss: 0.0284\n",
      "Epoch 89/200, Iteration 87/250, Loss: 0.0146\n",
      "Epoch 89/200, Iteration 88/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 89/250, Loss: 0.0263\n",
      "Epoch 89/200, Iteration 90/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 91/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 89/200, Iteration 93/250, Loss: 0.0195\n",
      "Epoch 89/200, Iteration 94/250, Loss: 0.0073\n",
      "Epoch 89/200, Iteration 95/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 96/250, Loss: 0.0074\n",
      "Epoch 89/200, Iteration 97/250, Loss: 0.0120\n",
      "Epoch 89/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 89/200, Iteration 99/250, Loss: 0.0143\n",
      "Epoch 89/200, Iteration 100/250, Loss: 0.0314\n",
      "Epoch 89/200, Iteration 101/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 102/250, Loss: 0.0064\n",
      "Epoch 89/200, Iteration 103/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 104/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 105/250, Loss: 0.0115\n",
      "Epoch 89/200, Iteration 106/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 107/250, Loss: 0.0177\n",
      "Epoch 89/200, Iteration 108/250, Loss: 0.0126\n",
      "Epoch 89/200, Iteration 109/250, Loss: 0.0094\n",
      "Epoch 89/200, Iteration 110/250, Loss: 0.0268\n",
      "Epoch 89/200, Iteration 111/250, Loss: 0.0143\n",
      "Epoch 89/200, Iteration 112/250, Loss: 0.0228\n",
      "Epoch 89/200, Iteration 113/250, Loss: 0.0083\n",
      "Epoch 89/200, Iteration 114/250, Loss: 0.0120\n",
      "Epoch 89/200, Iteration 115/250, Loss: 0.0104\n",
      "Epoch 89/200, Iteration 116/250, Loss: 0.0168\n",
      "Epoch 89/200, Iteration 117/250, Loss: 0.0076\n",
      "Epoch 89/200, Iteration 118/250, Loss: 0.0217\n",
      "Epoch 89/200, Iteration 119/250, Loss: 0.0132\n",
      "Epoch 89/200, Iteration 120/250, Loss: 0.0182\n",
      "Epoch 89/200, Iteration 121/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 122/250, Loss: 0.0285\n",
      "Epoch 89/200, Iteration 123/250, Loss: 0.0133\n",
      "Epoch 89/200, Iteration 124/250, Loss: 0.0070\n",
      "Epoch 89/200, Iteration 125/250, Loss: 0.0071\n",
      "Epoch 89/200, Iteration 126/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 127/250, Loss: 0.0198\n",
      "Epoch 89/200, Iteration 128/250, Loss: 0.0126\n",
      "Epoch 89/200, Iteration 129/250, Loss: 0.0122\n",
      "Epoch 89/200, Iteration 130/250, Loss: 0.0097\n",
      "Epoch 89/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 132/250, Loss: 0.0093\n",
      "Epoch 89/200, Iteration 133/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 134/250, Loss: 0.0135\n",
      "Epoch 89/200, Iteration 135/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 136/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 137/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 138/250, Loss: 0.0118\n",
      "Epoch 89/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 89/200, Iteration 140/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 141/250, Loss: 0.0187\n",
      "Epoch 89/200, Iteration 142/250, Loss: 0.0172\n",
      "Epoch 89/200, Iteration 143/250, Loss: 0.0188\n",
      "Epoch 89/200, Iteration 144/250, Loss: 0.0123\n",
      "Epoch 89/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 89/200, Iteration 146/250, Loss: 0.0131\n",
      "Epoch 89/200, Iteration 147/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 148/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 149/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 150/250, Loss: 0.0082\n",
      "Epoch 89/200, Iteration 151/250, Loss: 0.0131\n",
      "Epoch 89/200, Iteration 152/250, Loss: 0.0328\n",
      "Epoch 89/200, Iteration 153/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 154/250, Loss: 0.0108\n",
      "Epoch 89/200, Iteration 155/250, Loss: 0.0162\n",
      "Epoch 89/200, Iteration 156/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 157/250, Loss: 0.0097\n",
      "Epoch 89/200, Iteration 158/250, Loss: 0.0075\n",
      "Epoch 89/200, Iteration 159/250, Loss: 0.0320\n",
      "Epoch 89/200, Iteration 160/250, Loss: 0.0410\n",
      "Epoch 89/200, Iteration 161/250, Loss: 0.0286\n",
      "Epoch 89/200, Iteration 162/250, Loss: 0.0176\n",
      "Epoch 89/200, Iteration 163/250, Loss: 0.0061\n",
      "Epoch 89/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 89/200, Iteration 165/250, Loss: 0.0129\n",
      "Epoch 89/200, Iteration 166/250, Loss: 0.0166\n",
      "Epoch 89/200, Iteration 167/250, Loss: 0.0130\n",
      "Epoch 89/200, Iteration 168/250, Loss: 0.0172\n",
      "Epoch 89/200, Iteration 169/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 170/250, Loss: 0.0117\n",
      "Epoch 89/200, Iteration 171/250, Loss: 0.0087\n",
      "Epoch 89/200, Iteration 172/250, Loss: 0.0096\n",
      "Epoch 89/200, Iteration 173/250, Loss: 0.0287\n",
      "Epoch 89/200, Iteration 174/250, Loss: 0.0098\n",
      "Epoch 89/200, Iteration 175/250, Loss: 0.0187\n",
      "Epoch 89/200, Iteration 176/250, Loss: 0.0193\n",
      "Epoch 89/200, Iteration 177/250, Loss: 0.0100\n",
      "Epoch 89/200, Iteration 178/250, Loss: 0.0157\n",
      "Epoch 89/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 89/200, Iteration 180/250, Loss: 0.0171\n",
      "Epoch 89/200, Iteration 181/250, Loss: 0.0244\n",
      "Epoch 89/200, Iteration 182/250, Loss: 0.0111\n",
      "Epoch 89/200, Iteration 183/250, Loss: 0.0134\n",
      "Epoch 89/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 89/200, Iteration 185/250, Loss: 0.0110\n",
      "Epoch 89/200, Iteration 186/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 187/250, Loss: 0.0113\n",
      "Epoch 89/200, Iteration 188/250, Loss: 0.0191\n",
      "Epoch 89/200, Iteration 189/250, Loss: 0.0143\n",
      "Epoch 89/200, Iteration 190/250, Loss: 0.0243\n",
      "Epoch 89/200, Iteration 191/250, Loss: 0.0109\n",
      "Epoch 89/200, Iteration 192/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 193/250, Loss: 0.0186\n",
      "Epoch 89/200, Iteration 194/250, Loss: 0.0143\n",
      "Epoch 89/200, Iteration 195/250, Loss: 0.0150\n",
      "Epoch 89/200, Iteration 196/250, Loss: 0.0112\n",
      "Epoch 89/200, Iteration 197/250, Loss: 0.0116\n",
      "Epoch 89/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 89/200, Iteration 199/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 200/250, Loss: 0.0164\n",
      "Epoch 89/200, Iteration 201/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 202/250, Loss: 0.0109\n",
      "Epoch 89/200, Iteration 203/250, Loss: 0.0261\n",
      "Epoch 89/200, Iteration 204/250, Loss: 0.0179\n",
      "Epoch 89/200, Iteration 205/250, Loss: 0.0164\n",
      "Epoch 89/200, Iteration 206/250, Loss: 0.0262\n",
      "Epoch 89/200, Iteration 207/250, Loss: 0.0301\n",
      "Epoch 89/200, Iteration 208/250, Loss: 0.0139\n",
      "Epoch 89/200, Iteration 209/250, Loss: 0.0076\n",
      "Epoch 89/200, Iteration 210/250, Loss: 0.0127\n",
      "Epoch 89/200, Iteration 211/250, Loss: 0.0164\n",
      "Epoch 89/200, Iteration 212/250, Loss: 0.0151\n",
      "Epoch 89/200, Iteration 213/250, Loss: 0.0359\n",
      "Epoch 89/200, Iteration 214/250, Loss: 0.0127\n",
      "Epoch 89/200, Iteration 215/250, Loss: 0.0102\n",
      "Epoch 89/200, Iteration 216/250, Loss: 0.0235\n",
      "Epoch 89/200, Iteration 217/250, Loss: 0.0267\n",
      "Epoch 89/200, Iteration 218/250, Loss: 0.0084\n",
      "Epoch 89/200, Iteration 219/250, Loss: 0.0089\n",
      "Epoch 89/200, Iteration 220/250, Loss: 0.0118\n",
      "Epoch 89/200, Iteration 221/250, Loss: 0.0195\n",
      "Epoch 89/200, Iteration 222/250, Loss: 0.0295\n",
      "Epoch 89/200, Iteration 223/250, Loss: 0.0133\n",
      "Epoch 89/200, Iteration 224/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 225/250, Loss: 0.0139\n",
      "Epoch 89/200, Iteration 226/250, Loss: 0.0092\n",
      "Epoch 89/200, Iteration 227/250, Loss: 0.0178\n",
      "Epoch 89/200, Iteration 228/250, Loss: 0.0075\n",
      "Epoch 89/200, Iteration 229/250, Loss: 0.0086\n",
      "Epoch 89/200, Iteration 230/250, Loss: 0.0109\n",
      "Epoch 89/200, Iteration 231/250, Loss: 0.0109\n",
      "Epoch 89/200, Iteration 232/250, Loss: 0.0137\n",
      "Epoch 89/200, Iteration 233/250, Loss: 0.0119\n",
      "Epoch 89/200, Iteration 234/250, Loss: 0.0183\n",
      "Epoch 89/200, Iteration 235/250, Loss: 0.0160\n",
      "Epoch 89/200, Iteration 236/250, Loss: 0.0101\n",
      "Epoch 89/200, Iteration 237/250, Loss: 0.0275\n",
      "Epoch 89/200, Iteration 238/250, Loss: 0.0135\n",
      "Epoch 89/200, Iteration 239/250, Loss: 0.0198\n",
      "Epoch 89/200, Iteration 240/250, Loss: 0.0396\n",
      "Epoch 89/200, Iteration 241/250, Loss: 0.0161\n",
      "Epoch 89/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 89/200, Iteration 243/250, Loss: 0.0136\n",
      "Epoch 89/200, Iteration 244/250, Loss: 0.0103\n",
      "Epoch 89/200, Iteration 245/250, Loss: 0.0194\n",
      "Epoch 89/200, Iteration 246/250, Loss: 0.0128\n",
      "Epoch 89/200, Iteration 247/250, Loss: 0.0099\n",
      "Epoch 89/200, Iteration 248/250, Loss: 0.0177\n",
      "Epoch 89/200, Iteration 249/250, Loss: 0.0074\n",
      "Epoch 89/200, Iteration 250/250, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 82.94%, Avg loss: 0.007063, MRE: 0.434847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.75%, Avg loss: 0.007522, MRE: 0.558073 \n",
      "\n",
      "Epoch 90/200, Iteration 1/250, Loss: 0.0123\n",
      "Epoch 90/200, Iteration 2/250, Loss: 0.0182\n",
      "Epoch 90/200, Iteration 3/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 4/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 5/250, Loss: 0.0175\n",
      "Epoch 90/200, Iteration 6/250, Loss: 0.0126\n",
      "Epoch 90/200, Iteration 7/250, Loss: 0.0105\n",
      "Epoch 90/200, Iteration 8/250, Loss: 0.0183\n",
      "Epoch 90/200, Iteration 9/250, Loss: 0.0116\n",
      "Epoch 90/200, Iteration 10/250, Loss: 0.0146\n",
      "Epoch 90/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 12/250, Loss: 0.0185\n",
      "Epoch 90/200, Iteration 13/250, Loss: 0.0121\n",
      "Epoch 90/200, Iteration 14/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 15/250, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 16/250, Loss: 0.0308\n",
      "Epoch 90/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 90/200, Iteration 18/250, Loss: 0.0360\n",
      "Epoch 90/200, Iteration 19/250, Loss: 0.0190\n",
      "Epoch 90/200, Iteration 20/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 21/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 22/250, Loss: 0.0094\n",
      "Epoch 90/200, Iteration 23/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 24/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 25/250, Loss: 0.0135\n",
      "Epoch 90/200, Iteration 26/250, Loss: 0.0098\n",
      "Epoch 90/200, Iteration 27/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 28/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 29/250, Loss: 0.0096\n",
      "Epoch 90/200, Iteration 30/250, Loss: 0.0217\n",
      "Epoch 90/200, Iteration 31/250, Loss: 0.0227\n",
      "Epoch 90/200, Iteration 32/250, Loss: 0.0188\n",
      "Epoch 90/200, Iteration 33/250, Loss: 0.0202\n",
      "Epoch 90/200, Iteration 34/250, Loss: 0.0151\n",
      "Epoch 90/200, Iteration 35/250, Loss: 0.0180\n",
      "Epoch 90/200, Iteration 36/250, Loss: 0.0098\n",
      "Epoch 90/200, Iteration 37/250, Loss: 0.0120\n",
      "Epoch 90/200, Iteration 38/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 39/250, Loss: 0.0077\n",
      "Epoch 90/200, Iteration 40/250, Loss: 0.0158\n",
      "Epoch 90/200, Iteration 41/250, Loss: 0.0091\n",
      "Epoch 90/200, Iteration 42/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 43/250, Loss: 0.0192\n",
      "Epoch 90/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 45/250, Loss: 0.0251\n",
      "Epoch 90/200, Iteration 46/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 47/250, Loss: 0.0147\n",
      "Epoch 90/200, Iteration 48/250, Loss: 0.0210\n",
      "Epoch 90/200, Iteration 49/250, Loss: 0.0104\n",
      "Epoch 90/200, Iteration 50/250, Loss: 0.0090\n",
      "Epoch 90/200, Iteration 51/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 52/250, Loss: 0.0163\n",
      "Epoch 90/200, Iteration 53/250, Loss: 0.0152\n",
      "Epoch 90/200, Iteration 54/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 55/250, Loss: 0.0115\n",
      "Epoch 90/200, Iteration 56/250, Loss: 0.0071\n",
      "Epoch 90/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 90/200, Iteration 58/250, Loss: 0.0231\n",
      "Epoch 90/200, Iteration 59/250, Loss: 0.0144\n",
      "Epoch 90/200, Iteration 60/250, Loss: 0.0309\n",
      "Epoch 90/200, Iteration 61/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 62/250, Loss: 0.0163\n",
      "Epoch 90/200, Iteration 63/250, Loss: 0.0109\n",
      "Epoch 90/200, Iteration 64/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 65/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 66/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 67/250, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 68/250, Loss: 0.0183\n",
      "Epoch 90/200, Iteration 69/250, Loss: 0.0209\n",
      "Epoch 90/200, Iteration 70/250, Loss: 0.0445\n",
      "Epoch 90/200, Iteration 71/250, Loss: 0.0099\n",
      "Epoch 90/200, Iteration 72/250, Loss: 0.0150\n",
      "Epoch 90/200, Iteration 73/250, Loss: 0.0250\n",
      "Epoch 90/200, Iteration 74/250, Loss: 0.0115\n",
      "Epoch 90/200, Iteration 75/250, Loss: 0.0418\n",
      "Epoch 90/200, Iteration 76/250, Loss: 0.0181\n",
      "Epoch 90/200, Iteration 77/250, Loss: 0.0194\n",
      "Epoch 90/200, Iteration 78/250, Loss: 0.0225\n",
      "Epoch 90/200, Iteration 79/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 80/250, Loss: 0.0197\n",
      "Epoch 90/200, Iteration 81/250, Loss: 0.0175\n",
      "Epoch 90/200, Iteration 82/250, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 83/250, Loss: 0.0082\n",
      "Epoch 90/200, Iteration 84/250, Loss: 0.0061\n",
      "Epoch 90/200, Iteration 85/250, Loss: 0.0118\n",
      "Epoch 90/200, Iteration 86/250, Loss: 0.0204\n",
      "Epoch 90/200, Iteration 87/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 88/250, Loss: 0.0187\n",
      "Epoch 90/200, Iteration 89/250, Loss: 0.0127\n",
      "Epoch 90/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 91/250, Loss: 0.0262\n",
      "Epoch 90/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 90/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 90/200, Iteration 94/250, Loss: 0.0131\n",
      "Epoch 90/200, Iteration 95/250, Loss: 0.0296\n",
      "Epoch 90/200, Iteration 96/250, Loss: 0.0109\n",
      "Epoch 90/200, Iteration 97/250, Loss: 0.0207\n",
      "Epoch 90/200, Iteration 98/250, Loss: 0.0108\n",
      "Epoch 90/200, Iteration 99/250, Loss: 0.0177\n",
      "Epoch 90/200, Iteration 100/250, Loss: 0.0319\n",
      "Epoch 90/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 90/200, Iteration 102/250, Loss: 0.0198\n",
      "Epoch 90/200, Iteration 103/250, Loss: 0.0221\n",
      "Epoch 90/200, Iteration 104/250, Loss: 0.0160\n",
      "Epoch 90/200, Iteration 105/250, Loss: 0.0348\n",
      "Epoch 90/200, Iteration 106/250, Loss: 0.0082\n",
      "Epoch 90/200, Iteration 107/250, Loss: 0.0183\n",
      "Epoch 90/200, Iteration 108/250, Loss: 0.0190\n",
      "Epoch 90/200, Iteration 109/250, Loss: 0.0196\n",
      "Epoch 90/200, Iteration 110/250, Loss: 0.0265\n",
      "Epoch 90/200, Iteration 111/250, Loss: 0.0108\n",
      "Epoch 90/200, Iteration 112/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 113/250, Loss: 0.0069\n",
      "Epoch 90/200, Iteration 114/250, Loss: 0.0339\n",
      "Epoch 90/200, Iteration 115/250, Loss: 0.0311\n",
      "Epoch 90/200, Iteration 116/250, Loss: 0.0139\n",
      "Epoch 90/200, Iteration 117/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 118/250, Loss: 0.0107\n",
      "Epoch 90/200, Iteration 119/250, Loss: 0.0155\n",
      "Epoch 90/200, Iteration 120/250, Loss: 0.0070\n",
      "Epoch 90/200, Iteration 121/250, Loss: 0.0142\n",
      "Epoch 90/200, Iteration 122/250, Loss: 0.0275\n",
      "Epoch 90/200, Iteration 123/250, Loss: 0.0120\n",
      "Epoch 90/200, Iteration 124/250, Loss: 0.0101\n",
      "Epoch 90/200, Iteration 125/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 126/250, Loss: 0.0105\n",
      "Epoch 90/200, Iteration 127/250, Loss: 0.0106\n",
      "Epoch 90/200, Iteration 128/250, Loss: 0.0227\n",
      "Epoch 90/200, Iteration 129/250, Loss: 0.0148\n",
      "Epoch 90/200, Iteration 130/250, Loss: 0.0128\n",
      "Epoch 90/200, Iteration 131/250, Loss: 0.0083\n",
      "Epoch 90/200, Iteration 132/250, Loss: 0.0084\n",
      "Epoch 90/200, Iteration 133/250, Loss: 0.0319\n",
      "Epoch 90/200, Iteration 134/250, Loss: 0.0309\n",
      "Epoch 90/200, Iteration 135/250, Loss: 0.0078\n",
      "Epoch 90/200, Iteration 136/250, Loss: 0.0076\n",
      "Epoch 90/200, Iteration 137/250, Loss: 0.0100\n",
      "Epoch 90/200, Iteration 138/250, Loss: 0.0151\n",
      "Epoch 90/200, Iteration 139/250, Loss: 0.0149\n",
      "Epoch 90/200, Iteration 140/250, Loss: 0.0068\n",
      "Epoch 90/200, Iteration 141/250, Loss: 0.0125\n",
      "Epoch 90/200, Iteration 142/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 143/250, Loss: 0.0291\n",
      "Epoch 90/200, Iteration 144/250, Loss: 0.0194\n",
      "Epoch 90/200, Iteration 145/250, Loss: 0.0143\n",
      "Epoch 90/200, Iteration 146/250, Loss: 0.0144\n",
      "Epoch 90/200, Iteration 147/250, Loss: 0.0263\n",
      "Epoch 90/200, Iteration 148/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 149/250, Loss: 0.0144\n",
      "Epoch 90/200, Iteration 150/250, Loss: 0.0147\n",
      "Epoch 90/200, Iteration 151/250, Loss: 0.0097\n",
      "Epoch 90/200, Iteration 152/250, Loss: 0.0299\n",
      "Epoch 90/200, Iteration 153/250, Loss: 0.0239\n",
      "Epoch 90/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 90/200, Iteration 155/250, Loss: 0.0214\n",
      "Epoch 90/200, Iteration 156/250, Loss: 0.0149\n",
      "Epoch 90/200, Iteration 157/250, Loss: 0.0221\n",
      "Epoch 90/200, Iteration 158/250, Loss: 0.0141\n",
      "Epoch 90/200, Iteration 159/250, Loss: 0.0231\n",
      "Epoch 90/200, Iteration 160/250, Loss: 0.0201\n",
      "Epoch 90/200, Iteration 161/250, Loss: 0.0066\n",
      "Epoch 90/200, Iteration 162/250, Loss: 0.0092\n",
      "Epoch 90/200, Iteration 163/250, Loss: 0.0190\n",
      "Epoch 90/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 90/200, Iteration 165/250, Loss: 0.0157\n",
      "Epoch 90/200, Iteration 166/250, Loss: 0.0127\n",
      "Epoch 90/200, Iteration 167/250, Loss: 0.0099\n",
      "Epoch 90/200, Iteration 168/250, Loss: 0.0183\n",
      "Epoch 90/200, Iteration 169/250, Loss: 0.0171\n",
      "Epoch 90/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 90/200, Iteration 171/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 172/250, Loss: 0.0065\n",
      "Epoch 90/200, Iteration 173/250, Loss: 0.0100\n",
      "Epoch 90/200, Iteration 174/250, Loss: 0.0158\n",
      "Epoch 90/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 90/200, Iteration 176/250, Loss: 0.0114\n",
      "Epoch 90/200, Iteration 177/250, Loss: 0.0251\n",
      "Epoch 90/200, Iteration 178/250, Loss: 0.0152\n",
      "Epoch 90/200, Iteration 179/250, Loss: 0.0437\n",
      "Epoch 90/200, Iteration 180/250, Loss: 0.0230\n",
      "Epoch 90/200, Iteration 181/250, Loss: 0.0069\n",
      "Epoch 90/200, Iteration 182/250, Loss: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 184/250, Loss: 0.0392\n",
      "Epoch 90/200, Iteration 185/250, Loss: 0.0167\n",
      "Epoch 90/200, Iteration 186/250, Loss: 0.0096\n",
      "Epoch 90/200, Iteration 187/250, Loss: 0.0093\n",
      "Epoch 90/200, Iteration 188/250, Loss: 0.0138\n",
      "Epoch 90/200, Iteration 189/250, Loss: 0.0161\n",
      "Epoch 90/200, Iteration 190/250, Loss: 0.0065\n",
      "Epoch 90/200, Iteration 191/250, Loss: 0.0185\n",
      "Epoch 90/200, Iteration 192/250, Loss: 0.0085\n",
      "Epoch 90/200, Iteration 193/250, Loss: 0.0126\n",
      "Epoch 90/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 90/200, Iteration 195/250, Loss: 0.0244\n",
      "Epoch 90/200, Iteration 196/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 197/250, Loss: 0.0153\n",
      "Epoch 90/200, Iteration 198/250, Loss: 0.0129\n",
      "Epoch 90/200, Iteration 199/250, Loss: 0.0268\n",
      "Epoch 90/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 90/200, Iteration 201/250, Loss: 0.0449\n",
      "Epoch 90/200, Iteration 202/250, Loss: 0.0257\n",
      "Epoch 90/200, Iteration 203/250, Loss: 0.0100\n",
      "Epoch 90/200, Iteration 204/250, Loss: 0.0236\n",
      "Epoch 90/200, Iteration 205/250, Loss: 0.0122\n",
      "Epoch 90/200, Iteration 206/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 207/250, Loss: 0.0101\n",
      "Epoch 90/200, Iteration 208/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 209/250, Loss: 0.0095\n",
      "Epoch 90/200, Iteration 210/250, Loss: 0.0147\n",
      "Epoch 90/200, Iteration 211/250, Loss: 0.0166\n",
      "Epoch 90/200, Iteration 212/250, Loss: 0.0360\n",
      "Epoch 90/200, Iteration 213/250, Loss: 0.0089\n",
      "Epoch 90/200, Iteration 214/250, Loss: 0.0101\n",
      "Epoch 90/200, Iteration 215/250, Loss: 0.0129\n",
      "Epoch 90/200, Iteration 216/250, Loss: 0.0232\n",
      "Epoch 90/200, Iteration 217/250, Loss: 0.0153\n",
      "Epoch 90/200, Iteration 218/250, Loss: 0.0081\n",
      "Epoch 90/200, Iteration 219/250, Loss: 0.0244\n",
      "Epoch 90/200, Iteration 220/250, Loss: 0.0112\n",
      "Epoch 90/200, Iteration 221/250, Loss: 0.0263\n",
      "Epoch 90/200, Iteration 222/250, Loss: 0.0111\n",
      "Epoch 90/200, Iteration 223/250, Loss: 0.0096\n",
      "Epoch 90/200, Iteration 224/250, Loss: 0.0145\n",
      "Epoch 90/200, Iteration 225/250, Loss: 0.0205\n",
      "Epoch 90/200, Iteration 226/250, Loss: 0.0132\n",
      "Epoch 90/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 90/200, Iteration 228/250, Loss: 0.0277\n",
      "Epoch 90/200, Iteration 229/250, Loss: 0.0093\n",
      "Epoch 90/200, Iteration 230/250, Loss: 0.0207\n",
      "Epoch 90/200, Iteration 231/250, Loss: 0.0110\n",
      "Epoch 90/200, Iteration 232/250, Loss: 0.0191\n",
      "Epoch 90/200, Iteration 233/250, Loss: 0.0127\n",
      "Epoch 90/200, Iteration 234/250, Loss: 0.0233\n",
      "Epoch 90/200, Iteration 235/250, Loss: 0.0172\n",
      "Epoch 90/200, Iteration 236/250, Loss: 0.0094\n",
      "Epoch 90/200, Iteration 237/250, Loss: 0.0439\n",
      "Epoch 90/200, Iteration 238/250, Loss: 0.0133\n",
      "Epoch 90/200, Iteration 239/250, Loss: 0.0164\n",
      "Epoch 90/200, Iteration 240/250, Loss: 0.0080\n",
      "Epoch 90/200, Iteration 241/250, Loss: 0.0186\n",
      "Epoch 90/200, Iteration 242/250, Loss: 0.0239\n",
      "Epoch 90/200, Iteration 243/250, Loss: 0.0132\n",
      "Epoch 90/200, Iteration 244/250, Loss: 0.0068\n",
      "Epoch 90/200, Iteration 245/250, Loss: 0.0173\n",
      "Epoch 90/200, Iteration 246/250, Loss: 0.0151\n",
      "Epoch 90/200, Iteration 247/250, Loss: 0.0111\n",
      "Epoch 90/200, Iteration 248/250, Loss: 0.0288\n",
      "Epoch 90/200, Iteration 249/250, Loss: 0.0063\n",
      "Epoch 90/200, Iteration 250/250, Loss: 0.0171\n",
      "Train Error: \n",
      " Accuracy: 92.73%, Avg loss: 0.007423, MRE: 0.418036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.008023, MRE: 0.514481 \n",
      "\n",
      "Epoch 91/200, Iteration 1/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 2/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 3/250, Loss: 0.0102\n",
      "Epoch 91/200, Iteration 4/250, Loss: 0.0113\n",
      "Epoch 91/200, Iteration 5/250, Loss: 0.0095\n",
      "Epoch 91/200, Iteration 6/250, Loss: 0.0123\n",
      "Epoch 91/200, Iteration 7/250, Loss: 0.0338\n",
      "Epoch 91/200, Iteration 8/250, Loss: 0.0158\n",
      "Epoch 91/200, Iteration 9/250, Loss: 0.0100\n",
      "Epoch 91/200, Iteration 10/250, Loss: 0.0116\n",
      "Epoch 91/200, Iteration 11/250, Loss: 0.0149\n",
      "Epoch 91/200, Iteration 12/250, Loss: 0.0166\n",
      "Epoch 91/200, Iteration 13/250, Loss: 0.0131\n",
      "Epoch 91/200, Iteration 14/250, Loss: 0.0155\n",
      "Epoch 91/200, Iteration 15/250, Loss: 0.0185\n",
      "Epoch 91/200, Iteration 16/250, Loss: 0.0270\n",
      "Epoch 91/200, Iteration 17/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 18/250, Loss: 0.0113\n",
      "Epoch 91/200, Iteration 19/250, Loss: 0.0100\n",
      "Epoch 91/200, Iteration 20/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 21/250, Loss: 0.0098\n",
      "Epoch 91/200, Iteration 22/250, Loss: 0.0246\n",
      "Epoch 91/200, Iteration 23/250, Loss: 0.0077\n",
      "Epoch 91/200, Iteration 24/250, Loss: 0.0103\n",
      "Epoch 91/200, Iteration 25/250, Loss: 0.0151\n",
      "Epoch 91/200, Iteration 26/250, Loss: 0.0150\n",
      "Epoch 91/200, Iteration 27/250, Loss: 0.0139\n",
      "Epoch 91/200, Iteration 28/250, Loss: 0.0262\n",
      "Epoch 91/200, Iteration 29/250, Loss: 0.0097\n",
      "Epoch 91/200, Iteration 30/250, Loss: 0.0068\n",
      "Epoch 91/200, Iteration 31/250, Loss: 0.0074\n",
      "Epoch 91/200, Iteration 32/250, Loss: 0.0275\n",
      "Epoch 91/200, Iteration 33/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 34/250, Loss: 0.0296\n",
      "Epoch 91/200, Iteration 35/250, Loss: 0.0143\n",
      "Epoch 91/200, Iteration 36/250, Loss: 0.0206\n",
      "Epoch 91/200, Iteration 37/250, Loss: 0.0382\n",
      "Epoch 91/200, Iteration 38/250, Loss: 0.0142\n",
      "Epoch 91/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 91/200, Iteration 40/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 41/250, Loss: 0.0238\n",
      "Epoch 91/200, Iteration 42/250, Loss: 0.0183\n",
      "Epoch 91/200, Iteration 43/250, Loss: 0.0376\n",
      "Epoch 91/200, Iteration 44/250, Loss: 0.0241\n",
      "Epoch 91/200, Iteration 45/250, Loss: 0.0136\n",
      "Epoch 91/200, Iteration 46/250, Loss: 0.0146\n",
      "Epoch 91/200, Iteration 47/250, Loss: 0.0160\n",
      "Epoch 91/200, Iteration 48/250, Loss: 0.0405\n",
      "Epoch 91/200, Iteration 49/250, Loss: 0.0085\n",
      "Epoch 91/200, Iteration 50/250, Loss: 0.0178\n",
      "Epoch 91/200, Iteration 51/250, Loss: 0.0154\n",
      "Epoch 91/200, Iteration 52/250, Loss: 0.0233\n",
      "Epoch 91/200, Iteration 53/250, Loss: 0.0153\n",
      "Epoch 91/200, Iteration 54/250, Loss: 0.0441\n",
      "Epoch 91/200, Iteration 55/250, Loss: 0.0092\n",
      "Epoch 91/200, Iteration 56/250, Loss: 0.0165\n",
      "Epoch 91/200, Iteration 57/250, Loss: 0.0109\n",
      "Epoch 91/200, Iteration 58/250, Loss: 0.0217\n",
      "Epoch 91/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 91/200, Iteration 60/250, Loss: 0.0179\n",
      "Epoch 91/200, Iteration 61/250, Loss: 0.0286\n",
      "Epoch 91/200, Iteration 62/250, Loss: 0.0065\n",
      "Epoch 91/200, Iteration 63/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 64/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 65/250, Loss: 0.0082\n",
      "Epoch 91/200, Iteration 66/250, Loss: 0.0204\n",
      "Epoch 91/200, Iteration 67/250, Loss: 0.0130\n",
      "Epoch 91/200, Iteration 68/250, Loss: 0.0143\n",
      "Epoch 91/200, Iteration 69/250, Loss: 0.0165\n",
      "Epoch 91/200, Iteration 70/250, Loss: 0.0152\n",
      "Epoch 91/200, Iteration 71/250, Loss: 0.0149\n",
      "Epoch 91/200, Iteration 72/250, Loss: 0.0091\n",
      "Epoch 91/200, Iteration 73/250, Loss: 0.0159\n",
      "Epoch 91/200, Iteration 74/250, Loss: 0.0390\n",
      "Epoch 91/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 91/200, Iteration 76/250, Loss: 0.0115\n",
      "Epoch 91/200, Iteration 77/250, Loss: 0.0099\n",
      "Epoch 91/200, Iteration 78/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 79/250, Loss: 0.0083\n",
      "Epoch 91/200, Iteration 80/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 81/250, Loss: 0.0212\n",
      "Epoch 91/200, Iteration 82/250, Loss: 0.0079\n",
      "Epoch 91/200, Iteration 83/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 84/250, Loss: 0.0085\n",
      "Epoch 91/200, Iteration 85/250, Loss: 0.0239\n",
      "Epoch 91/200, Iteration 86/250, Loss: 0.0152\n",
      "Epoch 91/200, Iteration 87/250, Loss: 0.0203\n",
      "Epoch 91/200, Iteration 88/250, Loss: 0.0090\n",
      "Epoch 91/200, Iteration 89/250, Loss: 0.0149\n",
      "Epoch 91/200, Iteration 90/250, Loss: 0.0090\n",
      "Epoch 91/200, Iteration 91/250, Loss: 0.0235\n",
      "Epoch 91/200, Iteration 92/250, Loss: 0.0134\n",
      "Epoch 91/200, Iteration 93/250, Loss: 0.0254\n",
      "Epoch 91/200, Iteration 94/250, Loss: 0.0093\n",
      "Epoch 91/200, Iteration 95/250, Loss: 0.0243\n",
      "Epoch 91/200, Iteration 96/250, Loss: 0.0194\n",
      "Epoch 91/200, Iteration 97/250, Loss: 0.0202\n",
      "Epoch 91/200, Iteration 98/250, Loss: 0.0107\n",
      "Epoch 91/200, Iteration 99/250, Loss: 0.0097\n",
      "Epoch 91/200, Iteration 100/250, Loss: 0.0105\n",
      "Epoch 91/200, Iteration 101/250, Loss: 0.0127\n",
      "Epoch 91/200, Iteration 102/250, Loss: 0.0109\n",
      "Epoch 91/200, Iteration 103/250, Loss: 0.0099\n",
      "Epoch 91/200, Iteration 104/250, Loss: 0.0123\n",
      "Epoch 91/200, Iteration 105/250, Loss: 0.0213\n",
      "Epoch 91/200, Iteration 106/250, Loss: 0.0234\n",
      "Epoch 91/200, Iteration 107/250, Loss: 0.0147\n",
      "Epoch 91/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 91/200, Iteration 109/250, Loss: 0.0082\n",
      "Epoch 91/200, Iteration 110/250, Loss: 0.0350\n",
      "Epoch 91/200, Iteration 111/250, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 112/250, Loss: 0.0086\n",
      "Epoch 91/200, Iteration 113/250, Loss: 0.0271\n",
      "Epoch 91/200, Iteration 114/250, Loss: 0.0077\n",
      "Epoch 91/200, Iteration 115/250, Loss: 0.0152\n",
      "Epoch 91/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 91/200, Iteration 117/250, Loss: 0.0329\n",
      "Epoch 91/200, Iteration 118/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 119/250, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Iteration 120/250, Loss: 0.0087\n",
      "Epoch 91/200, Iteration 121/250, Loss: 0.0093\n",
      "Epoch 91/200, Iteration 122/250, Loss: 0.0104\n",
      "Epoch 91/200, Iteration 123/250, Loss: 0.0089\n",
      "Epoch 91/200, Iteration 124/250, Loss: 0.0089\n",
      "Epoch 91/200, Iteration 125/250, Loss: 0.0175\n",
      "Epoch 91/200, Iteration 126/250, Loss: 0.0080\n",
      "Epoch 91/200, Iteration 127/250, Loss: 0.0165\n",
      "Epoch 91/200, Iteration 128/250, Loss: 0.0070\n",
      "Epoch 91/200, Iteration 129/250, Loss: 0.0082\n",
      "Epoch 91/200, Iteration 130/250, Loss: 0.0253\n",
      "Epoch 91/200, Iteration 131/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 132/250, Loss: 0.0159\n",
      "Epoch 91/200, Iteration 133/250, Loss: 0.0425\n",
      "Epoch 91/200, Iteration 134/250, Loss: 0.0220\n",
      "Epoch 91/200, Iteration 135/250, Loss: 0.0086\n",
      "Epoch 91/200, Iteration 136/250, Loss: 0.0077\n",
      "Epoch 91/200, Iteration 137/250, Loss: 0.0163\n",
      "Epoch 91/200, Iteration 138/250, Loss: 0.0199\n",
      "Epoch 91/200, Iteration 139/250, Loss: 0.0088\n",
      "Epoch 91/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 91/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 91/200, Iteration 142/250, Loss: 0.0081\n",
      "Epoch 91/200, Iteration 143/250, Loss: 0.0143\n",
      "Epoch 91/200, Iteration 144/250, Loss: 0.0283\n",
      "Epoch 91/200, Iteration 145/250, Loss: 0.0443\n",
      "Epoch 91/200, Iteration 146/250, Loss: 0.0261\n",
      "Epoch 91/200, Iteration 147/250, Loss: 0.0094\n",
      "Epoch 91/200, Iteration 148/250, Loss: 0.0263\n",
      "Epoch 91/200, Iteration 149/250, Loss: 0.0087\n",
      "Epoch 91/200, Iteration 150/250, Loss: 0.0118\n",
      "Epoch 91/200, Iteration 151/250, Loss: 0.0172\n",
      "Epoch 91/200, Iteration 152/250, Loss: 0.0148\n",
      "Epoch 91/200, Iteration 153/250, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 154/250, Loss: 0.0095\n",
      "Epoch 91/200, Iteration 155/250, Loss: 0.0168\n",
      "Epoch 91/200, Iteration 156/250, Loss: 0.0142\n",
      "Epoch 91/200, Iteration 157/250, Loss: 0.0084\n",
      "Epoch 91/200, Iteration 158/250, Loss: 0.0055\n",
      "Epoch 91/200, Iteration 159/250, Loss: 0.0104\n",
      "Epoch 91/200, Iteration 160/250, Loss: 0.0145\n",
      "Epoch 91/200, Iteration 161/250, Loss: 0.0117\n",
      "Epoch 91/200, Iteration 162/250, Loss: 0.0082\n",
      "Epoch 91/200, Iteration 163/250, Loss: 0.0092\n",
      "Epoch 91/200, Iteration 164/250, Loss: 0.0139\n",
      "Epoch 91/200, Iteration 165/250, Loss: 0.0055\n",
      "Epoch 91/200, Iteration 166/250, Loss: 0.0176\n",
      "Epoch 91/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 91/200, Iteration 168/250, Loss: 0.0392\n",
      "Epoch 91/200, Iteration 169/250, Loss: 0.0260\n",
      "Epoch 91/200, Iteration 170/250, Loss: 0.0179\n",
      "Epoch 91/200, Iteration 171/250, Loss: 0.0106\n",
      "Epoch 91/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 91/200, Iteration 173/250, Loss: 0.0123\n",
      "Epoch 91/200, Iteration 174/250, Loss: 0.0097\n",
      "Epoch 91/200, Iteration 175/250, Loss: 0.0274\n",
      "Epoch 91/200, Iteration 176/250, Loss: 0.0191\n",
      "Epoch 91/200, Iteration 177/250, Loss: 0.0139\n",
      "Epoch 91/200, Iteration 178/250, Loss: 0.0114\n",
      "Epoch 91/200, Iteration 179/250, Loss: 0.0089\n",
      "Epoch 91/200, Iteration 180/250, Loss: 0.0131\n",
      "Epoch 91/200, Iteration 181/250, Loss: 0.0125\n",
      "Epoch 91/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 183/250, Loss: 0.0192\n",
      "Epoch 91/200, Iteration 184/250, Loss: 0.0111\n",
      "Epoch 91/200, Iteration 185/250, Loss: 0.0092\n",
      "Epoch 91/200, Iteration 186/250, Loss: 0.0357\n",
      "Epoch 91/200, Iteration 187/250, Loss: 0.0358\n",
      "Epoch 91/200, Iteration 188/250, Loss: 0.0102\n",
      "Epoch 91/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 91/200, Iteration 190/250, Loss: 0.0228\n",
      "Epoch 91/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 91/200, Iteration 192/250, Loss: 0.0133\n",
      "Epoch 91/200, Iteration 193/250, Loss: 0.0184\n",
      "Epoch 91/200, Iteration 194/250, Loss: 0.0255\n",
      "Epoch 91/200, Iteration 195/250, Loss: 0.0166\n",
      "Epoch 91/200, Iteration 196/250, Loss: 0.0078\n",
      "Epoch 91/200, Iteration 197/250, Loss: 0.0302\n",
      "Epoch 91/200, Iteration 198/250, Loss: 0.0135\n",
      "Epoch 91/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 91/200, Iteration 200/250, Loss: 0.0172\n",
      "Epoch 91/200, Iteration 201/250, Loss: 0.0401\n",
      "Epoch 91/200, Iteration 202/250, Loss: 0.0108\n",
      "Epoch 91/200, Iteration 203/250, Loss: 0.0116\n",
      "Epoch 91/200, Iteration 204/250, Loss: 0.0203\n",
      "Epoch 91/200, Iteration 205/250, Loss: 0.0165\n",
      "Epoch 91/200, Iteration 206/250, Loss: 0.0209\n",
      "Epoch 91/200, Iteration 207/250, Loss: 0.0133\n",
      "Epoch 91/200, Iteration 208/250, Loss: 0.0196\n",
      "Epoch 91/200, Iteration 209/250, Loss: 0.0079\n",
      "Epoch 91/200, Iteration 210/250, Loss: 0.0181\n",
      "Epoch 91/200, Iteration 211/250, Loss: 0.0122\n",
      "Epoch 91/200, Iteration 212/250, Loss: 0.0099\n",
      "Epoch 91/200, Iteration 213/250, Loss: 0.0156\n",
      "Epoch 91/200, Iteration 214/250, Loss: 0.0080\n",
      "Epoch 91/200, Iteration 215/250, Loss: 0.0111\n",
      "Epoch 91/200, Iteration 216/250, Loss: 0.0179\n",
      "Epoch 91/200, Iteration 217/250, Loss: 0.0176\n",
      "Epoch 91/200, Iteration 218/250, Loss: 0.0154\n",
      "Epoch 91/200, Iteration 219/250, Loss: 0.0115\n",
      "Epoch 91/200, Iteration 220/250, Loss: 0.0120\n",
      "Epoch 91/200, Iteration 221/250, Loss: 0.0137\n",
      "Epoch 91/200, Iteration 222/250, Loss: 0.0073\n",
      "Epoch 91/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 91/200, Iteration 224/250, Loss: 0.0532\n",
      "Epoch 91/200, Iteration 225/250, Loss: 0.0352\n",
      "Epoch 91/200, Iteration 226/250, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 227/250, Loss: 0.0234\n",
      "Epoch 91/200, Iteration 228/250, Loss: 0.0197\n",
      "Epoch 91/200, Iteration 229/250, Loss: 0.0127\n",
      "Epoch 91/200, Iteration 230/250, Loss: 0.0141\n",
      "Epoch 91/200, Iteration 231/250, Loss: 0.0145\n",
      "Epoch 91/200, Iteration 232/250, Loss: 0.0144\n",
      "Epoch 91/200, Iteration 233/250, Loss: 0.0197\n",
      "Epoch 91/200, Iteration 234/250, Loss: 0.0096\n",
      "Epoch 91/200, Iteration 235/250, Loss: 0.0175\n",
      "Epoch 91/200, Iteration 236/250, Loss: 0.0245\n",
      "Epoch 91/200, Iteration 237/250, Loss: 0.0093\n",
      "Epoch 91/200, Iteration 238/250, Loss: 0.0073\n",
      "Epoch 91/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 91/200, Iteration 240/250, Loss: 0.0221\n",
      "Epoch 91/200, Iteration 241/250, Loss: 0.0443\n",
      "Epoch 91/200, Iteration 242/250, Loss: 0.0130\n",
      "Epoch 91/200, Iteration 243/250, Loss: 0.0268\n",
      "Epoch 91/200, Iteration 244/250, Loss: 0.0110\n",
      "Epoch 91/200, Iteration 245/250, Loss: 0.0193\n",
      "Epoch 91/200, Iteration 246/250, Loss: 0.0122\n",
      "Epoch 91/200, Iteration 247/250, Loss: 0.0361\n",
      "Epoch 91/200, Iteration 248/250, Loss: 0.0286\n",
      "Epoch 91/200, Iteration 249/250, Loss: 0.0164\n",
      "Epoch 91/200, Iteration 250/250, Loss: 0.0296\n",
      "Train Error: \n",
      " Accuracy: 56.93%, Avg loss: 0.010305, MRE: 0.722378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 0.010705, MRE: 0.695092 \n",
      "\n",
      "Epoch 92/200, Iteration 1/250, Loss: 0.0116\n",
      "Epoch 92/200, Iteration 2/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 3/250, Loss: 0.0073\n",
      "Epoch 92/200, Iteration 4/250, Loss: 0.0175\n",
      "Epoch 92/200, Iteration 5/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 6/250, Loss: 0.0187\n",
      "Epoch 92/200, Iteration 7/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 8/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 9/250, Loss: 0.0158\n",
      "Epoch 92/200, Iteration 10/250, Loss: 0.0123\n",
      "Epoch 92/200, Iteration 11/250, Loss: 0.0226\n",
      "Epoch 92/200, Iteration 12/250, Loss: 0.0229\n",
      "Epoch 92/200, Iteration 13/250, Loss: 0.0377\n",
      "Epoch 92/200, Iteration 14/250, Loss: 0.0084\n",
      "Epoch 92/200, Iteration 15/250, Loss: 0.0125\n",
      "Epoch 92/200, Iteration 16/250, Loss: 0.0115\n",
      "Epoch 92/200, Iteration 17/250, Loss: 0.0169\n",
      "Epoch 92/200, Iteration 18/250, Loss: 0.0151\n",
      "Epoch 92/200, Iteration 19/250, Loss: 0.0095\n",
      "Epoch 92/200, Iteration 20/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 92/200, Iteration 22/250, Loss: 0.0169\n",
      "Epoch 92/200, Iteration 23/250, Loss: 0.0281\n",
      "Epoch 92/200, Iteration 24/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 25/250, Loss: 0.0121\n",
      "Epoch 92/200, Iteration 26/250, Loss: 0.0082\n",
      "Epoch 92/200, Iteration 27/250, Loss: 0.0181\n",
      "Epoch 92/200, Iteration 28/250, Loss: 0.0074\n",
      "Epoch 92/200, Iteration 29/250, Loss: 0.0146\n",
      "Epoch 92/200, Iteration 30/250, Loss: 0.0141\n",
      "Epoch 92/200, Iteration 31/250, Loss: 0.0064\n",
      "Epoch 92/200, Iteration 32/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 33/250, Loss: 0.0076\n",
      "Epoch 92/200, Iteration 34/250, Loss: 0.0114\n",
      "Epoch 92/200, Iteration 35/250, Loss: 0.0101\n",
      "Epoch 92/200, Iteration 36/250, Loss: 0.0178\n",
      "Epoch 92/200, Iteration 37/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 38/250, Loss: 0.0101\n",
      "Epoch 92/200, Iteration 39/250, Loss: 0.0132\n",
      "Epoch 92/200, Iteration 40/250, Loss: 0.0316\n",
      "Epoch 92/200, Iteration 41/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 42/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 43/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 44/250, Loss: 0.0249\n",
      "Epoch 92/200, Iteration 45/250, Loss: 0.0238\n",
      "Epoch 92/200, Iteration 46/250, Loss: 0.0079\n",
      "Epoch 92/200, Iteration 47/250, Loss: 0.0102\n",
      "Epoch 92/200, Iteration 48/250, Loss: 0.0205\n",
      "Epoch 92/200, Iteration 49/250, Loss: 0.0142\n",
      "Epoch 92/200, Iteration 50/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 51/250, Loss: 0.0087\n",
      "Epoch 92/200, Iteration 52/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 53/250, Loss: 0.0137\n",
      "Epoch 92/200, Iteration 54/250, Loss: 0.0174\n",
      "Epoch 92/200, Iteration 55/250, Loss: 0.0184\n",
      "Epoch 92/200, Iteration 56/250, Loss: 0.0072\n",
      "Epoch 92/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 58/250, Loss: 0.0355\n",
      "Epoch 92/200, Iteration 59/250, Loss: 0.0147\n",
      "Epoch 92/200, Iteration 60/250, Loss: 0.0160\n",
      "Epoch 92/200, Iteration 61/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 62/250, Loss: 0.0149\n",
      "Epoch 92/200, Iteration 63/250, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 64/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 65/250, Loss: 0.0125\n",
      "Epoch 92/200, Iteration 66/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 67/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 68/250, Loss: 0.0104\n",
      "Epoch 92/200, Iteration 69/250, Loss: 0.0140\n",
      "Epoch 92/200, Iteration 70/250, Loss: 0.0167\n",
      "Epoch 92/200, Iteration 71/250, Loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200, Iteration 72/250, Loss: 0.0150\n",
      "Epoch 92/200, Iteration 73/250, Loss: 0.0238\n",
      "Epoch 92/200, Iteration 74/250, Loss: 0.0087\n",
      "Epoch 92/200, Iteration 75/250, Loss: 0.0232\n",
      "Epoch 92/200, Iteration 76/250, Loss: 0.0102\n",
      "Epoch 92/200, Iteration 77/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 78/250, Loss: 0.0069\n",
      "Epoch 92/200, Iteration 79/250, Loss: 0.0257\n",
      "Epoch 92/200, Iteration 80/250, Loss: 0.0080\n",
      "Epoch 92/200, Iteration 81/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 82/250, Loss: 0.0229\n",
      "Epoch 92/200, Iteration 83/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 84/250, Loss: 0.0115\n",
      "Epoch 92/200, Iteration 85/250, Loss: 0.0150\n",
      "Epoch 92/200, Iteration 86/250, Loss: 0.0255\n",
      "Epoch 92/200, Iteration 87/250, Loss: 0.0065\n",
      "Epoch 92/200, Iteration 88/250, Loss: 0.0309\n",
      "Epoch 92/200, Iteration 89/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 90/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 91/250, Loss: 0.0310\n",
      "Epoch 92/200, Iteration 92/250, Loss: 0.0198\n",
      "Epoch 92/200, Iteration 93/250, Loss: 0.0327\n",
      "Epoch 92/200, Iteration 94/250, Loss: 0.0167\n",
      "Epoch 92/200, Iteration 95/250, Loss: 0.0170\n",
      "Epoch 92/200, Iteration 96/250, Loss: 0.0172\n",
      "Epoch 92/200, Iteration 97/250, Loss: 0.0135\n",
      "Epoch 92/200, Iteration 98/250, Loss: 0.0060\n",
      "Epoch 92/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 92/200, Iteration 100/250, Loss: 0.0149\n",
      "Epoch 92/200, Iteration 101/250, Loss: 0.0229\n",
      "Epoch 92/200, Iteration 102/250, Loss: 0.0256\n",
      "Epoch 92/200, Iteration 103/250, Loss: 0.0192\n",
      "Epoch 92/200, Iteration 104/250, Loss: 0.0254\n",
      "Epoch 92/200, Iteration 105/250, Loss: 0.0127\n",
      "Epoch 92/200, Iteration 106/250, Loss: 0.0100\n",
      "Epoch 92/200, Iteration 107/250, Loss: 0.0080\n",
      "Epoch 92/200, Iteration 108/250, Loss: 0.0109\n",
      "Epoch 92/200, Iteration 109/250, Loss: 0.0070\n",
      "Epoch 92/200, Iteration 110/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 111/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 112/250, Loss: 0.0105\n",
      "Epoch 92/200, Iteration 113/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 114/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 115/250, Loss: 0.0173\n",
      "Epoch 92/200, Iteration 116/250, Loss: 0.0097\n",
      "Epoch 92/200, Iteration 117/250, Loss: 0.0095\n",
      "Epoch 92/200, Iteration 118/250, Loss: 0.0118\n",
      "Epoch 92/200, Iteration 119/250, Loss: 0.0131\n",
      "Epoch 92/200, Iteration 120/250, Loss: 0.0211\n",
      "Epoch 92/200, Iteration 121/250, Loss: 0.0088\n",
      "Epoch 92/200, Iteration 122/250, Loss: 0.0218\n",
      "Epoch 92/200, Iteration 123/250, Loss: 0.0347\n",
      "Epoch 92/200, Iteration 124/250, Loss: 0.0076\n",
      "Epoch 92/200, Iteration 125/250, Loss: 0.0065\n",
      "Epoch 92/200, Iteration 126/250, Loss: 0.0406\n",
      "Epoch 92/200, Iteration 127/250, Loss: 0.0088\n",
      "Epoch 92/200, Iteration 128/250, Loss: 0.0072\n",
      "Epoch 92/200, Iteration 129/250, Loss: 0.0090\n",
      "Epoch 92/200, Iteration 130/250, Loss: 0.0133\n",
      "Epoch 92/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 133/250, Loss: 0.0368\n",
      "Epoch 92/200, Iteration 134/250, Loss: 0.0140\n",
      "Epoch 92/200, Iteration 135/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 136/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 137/250, Loss: 0.0313\n",
      "Epoch 92/200, Iteration 138/250, Loss: 0.0149\n",
      "Epoch 92/200, Iteration 139/250, Loss: 0.0104\n",
      "Epoch 92/200, Iteration 140/250, Loss: 0.0145\n",
      "Epoch 92/200, Iteration 141/250, Loss: 0.0151\n",
      "Epoch 92/200, Iteration 142/250, Loss: 0.0275\n",
      "Epoch 92/200, Iteration 143/250, Loss: 0.0069\n",
      "Epoch 92/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 92/200, Iteration 145/250, Loss: 0.0117\n",
      "Epoch 92/200, Iteration 146/250, Loss: 0.0168\n",
      "Epoch 92/200, Iteration 147/250, Loss: 0.0074\n",
      "Epoch 92/200, Iteration 148/250, Loss: 0.0125\n",
      "Epoch 92/200, Iteration 149/250, Loss: 0.0103\n",
      "Epoch 92/200, Iteration 150/250, Loss: 0.0079\n",
      "Epoch 92/200, Iteration 151/250, Loss: 0.0280\n",
      "Epoch 92/200, Iteration 152/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 153/250, Loss: 0.0109\n",
      "Epoch 92/200, Iteration 154/250, Loss: 0.0255\n",
      "Epoch 92/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 92/200, Iteration 156/250, Loss: 0.0185\n",
      "Epoch 92/200, Iteration 157/250, Loss: 0.0074\n",
      "Epoch 92/200, Iteration 158/250, Loss: 0.0083\n",
      "Epoch 92/200, Iteration 159/250, Loss: 0.0137\n",
      "Epoch 92/200, Iteration 160/250, Loss: 0.0146\n",
      "Epoch 92/200, Iteration 161/250, Loss: 0.0148\n",
      "Epoch 92/200, Iteration 162/250, Loss: 0.0115\n",
      "Epoch 92/200, Iteration 163/250, Loss: 0.0183\n",
      "Epoch 92/200, Iteration 164/250, Loss: 0.0158\n",
      "Epoch 92/200, Iteration 165/250, Loss: 0.0124\n",
      "Epoch 92/200, Iteration 166/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 167/250, Loss: 0.0071\n",
      "Epoch 92/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 169/250, Loss: 0.0083\n",
      "Epoch 92/200, Iteration 170/250, Loss: 0.0129\n",
      "Epoch 92/200, Iteration 171/250, Loss: 0.0196\n",
      "Epoch 92/200, Iteration 172/250, Loss: 0.0081\n",
      "Epoch 92/200, Iteration 173/250, Loss: 0.0125\n",
      "Epoch 92/200, Iteration 174/250, Loss: 0.0217\n",
      "Epoch 92/200, Iteration 175/250, Loss: 0.0201\n",
      "Epoch 92/200, Iteration 176/250, Loss: 0.0094\n",
      "Epoch 92/200, Iteration 177/250, Loss: 0.0134\n",
      "Epoch 92/200, Iteration 178/250, Loss: 0.0185\n",
      "Epoch 92/200, Iteration 179/250, Loss: 0.0138\n",
      "Epoch 92/200, Iteration 180/250, Loss: 0.0159\n",
      "Epoch 92/200, Iteration 181/250, Loss: 0.0100\n",
      "Epoch 92/200, Iteration 182/250, Loss: 0.0115\n",
      "Epoch 92/200, Iteration 183/250, Loss: 0.0129\n",
      "Epoch 92/200, Iteration 184/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 185/250, Loss: 0.0068\n",
      "Epoch 92/200, Iteration 186/250, Loss: 0.0164\n",
      "Epoch 92/200, Iteration 187/250, Loss: 0.0216\n",
      "Epoch 92/200, Iteration 188/250, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 189/250, Loss: 0.0227\n",
      "Epoch 92/200, Iteration 190/250, Loss: 0.0196\n",
      "Epoch 92/200, Iteration 191/250, Loss: 0.0109\n",
      "Epoch 92/200, Iteration 192/250, Loss: 0.0120\n",
      "Epoch 92/200, Iteration 193/250, Loss: 0.0127\n",
      "Epoch 92/200, Iteration 194/250, Loss: 0.0176\n",
      "Epoch 92/200, Iteration 195/250, Loss: 0.0141\n",
      "Epoch 92/200, Iteration 196/250, Loss: 0.0160\n",
      "Epoch 92/200, Iteration 197/250, Loss: 0.0157\n",
      "Epoch 92/200, Iteration 198/250, Loss: 0.0080\n",
      "Epoch 92/200, Iteration 199/250, Loss: 0.0065\n",
      "Epoch 92/200, Iteration 200/250, Loss: 0.0165\n",
      "Epoch 92/200, Iteration 201/250, Loss: 0.0104\n",
      "Epoch 92/200, Iteration 202/250, Loss: 0.0135\n",
      "Epoch 92/200, Iteration 203/250, Loss: 0.0274\n",
      "Epoch 92/200, Iteration 204/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 205/250, Loss: 0.0207\n",
      "Epoch 92/200, Iteration 206/250, Loss: 0.0119\n",
      "Epoch 92/200, Iteration 207/250, Loss: 0.0139\n",
      "Epoch 92/200, Iteration 208/250, Loss: 0.0148\n",
      "Epoch 92/200, Iteration 209/250, Loss: 0.0112\n",
      "Epoch 92/200, Iteration 210/250, Loss: 0.0232\n",
      "Epoch 92/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 92/200, Iteration 212/250, Loss: 0.0097\n",
      "Epoch 92/200, Iteration 213/250, Loss: 0.0090\n",
      "Epoch 92/200, Iteration 214/250, Loss: 0.0111\n",
      "Epoch 92/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 92/200, Iteration 216/250, Loss: 0.0227\n",
      "Epoch 92/200, Iteration 217/250, Loss: 0.0106\n",
      "Epoch 92/200, Iteration 218/250, Loss: 0.0216\n",
      "Epoch 92/200, Iteration 219/250, Loss: 0.0118\n",
      "Epoch 92/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 92/200, Iteration 221/250, Loss: 0.0180\n",
      "Epoch 92/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 92/200, Iteration 223/250, Loss: 0.0121\n",
      "Epoch 92/200, Iteration 224/250, Loss: 0.0163\n",
      "Epoch 92/200, Iteration 225/250, Loss: 0.0092\n",
      "Epoch 92/200, Iteration 226/250, Loss: 0.0097\n",
      "Epoch 92/200, Iteration 227/250, Loss: 0.0091\n",
      "Epoch 92/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 92/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 92/200, Iteration 230/250, Loss: 0.0184\n",
      "Epoch 92/200, Iteration 231/250, Loss: 0.0178\n",
      "Epoch 92/200, Iteration 232/250, Loss: 0.0078\n",
      "Epoch 92/200, Iteration 233/250, Loss: 0.0227\n",
      "Epoch 92/200, Iteration 234/250, Loss: 0.0216\n",
      "Epoch 92/200, Iteration 235/250, Loss: 0.0226\n",
      "Epoch 92/200, Iteration 236/250, Loss: 0.0324\n",
      "Epoch 92/200, Iteration 237/250, Loss: 0.0086\n",
      "Epoch 92/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 92/200, Iteration 239/250, Loss: 0.0322\n",
      "Epoch 92/200, Iteration 240/250, Loss: 0.0099\n",
      "Epoch 92/200, Iteration 241/250, Loss: 0.0133\n",
      "Epoch 92/200, Iteration 242/250, Loss: 0.0093\n",
      "Epoch 92/200, Iteration 243/250, Loss: 0.0113\n",
      "Epoch 92/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 92/200, Iteration 245/250, Loss: 0.0191\n",
      "Epoch 92/200, Iteration 246/250, Loss: 0.0360\n",
      "Epoch 92/200, Iteration 247/250, Loss: 0.0329\n",
      "Epoch 92/200, Iteration 248/250, Loss: 0.0087\n",
      "Epoch 92/200, Iteration 249/250, Loss: 0.0272\n",
      "Epoch 92/200, Iteration 250/250, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.11%, Avg loss: 0.007508, MRE: 0.466581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.85%, Avg loss: 0.007941, MRE: 0.527467 \n",
      "\n",
      "Epoch 93/200, Iteration 1/250, Loss: 0.0103\n",
      "Epoch 93/200, Iteration 2/250, Loss: 0.0077\n",
      "Epoch 93/200, Iteration 3/250, Loss: 0.0200\n",
      "Epoch 93/200, Iteration 4/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 5/250, Loss: 0.0132\n",
      "Epoch 93/200, Iteration 6/250, Loss: 0.0367\n",
      "Epoch 93/200, Iteration 7/250, Loss: 0.0247\n",
      "Epoch 93/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 9/250, Loss: 0.0066\n",
      "Epoch 93/200, Iteration 10/250, Loss: 0.0186\n",
      "Epoch 93/200, Iteration 11/250, Loss: 0.0104\n",
      "Epoch 93/200, Iteration 12/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 13/250, Loss: 0.0112\n",
      "Epoch 93/200, Iteration 14/250, Loss: 0.0179\n",
      "Epoch 93/200, Iteration 15/250, Loss: 0.0153\n",
      "Epoch 93/200, Iteration 16/250, Loss: 0.0470\n",
      "Epoch 93/200, Iteration 17/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 18/250, Loss: 0.0098\n",
      "Epoch 93/200, Iteration 19/250, Loss: 0.0156\n",
      "Epoch 93/200, Iteration 20/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 21/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 22/250, Loss: 0.0253\n",
      "Epoch 93/200, Iteration 23/250, Loss: 0.0151\n",
      "Epoch 93/200, Iteration 24/250, Loss: 0.0145\n",
      "Epoch 93/200, Iteration 25/250, Loss: 0.0165\n",
      "Epoch 93/200, Iteration 26/250, Loss: 0.0194\n",
      "Epoch 93/200, Iteration 27/250, Loss: 0.0274\n",
      "Epoch 93/200, Iteration 28/250, Loss: 0.0164\n",
      "Epoch 93/200, Iteration 29/250, Loss: 0.0094\n",
      "Epoch 93/200, Iteration 30/250, Loss: 0.0118\n",
      "Epoch 93/200, Iteration 31/250, Loss: 0.0290\n",
      "Epoch 93/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 33/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 93/200, Iteration 35/250, Loss: 0.0233\n",
      "Epoch 93/200, Iteration 36/250, Loss: 0.0185\n",
      "Epoch 93/200, Iteration 37/250, Loss: 0.0092\n",
      "Epoch 93/200, Iteration 38/250, Loss: 0.0091\n",
      "Epoch 93/200, Iteration 39/250, Loss: 0.0246\n",
      "Epoch 93/200, Iteration 40/250, Loss: 0.0175\n",
      "Epoch 93/200, Iteration 41/250, Loss: 0.0285\n",
      "Epoch 93/200, Iteration 42/250, Loss: 0.0395\n",
      "Epoch 93/200, Iteration 43/250, Loss: 0.0286\n",
      "Epoch 93/200, Iteration 44/250, Loss: 0.0113\n",
      "Epoch 93/200, Iteration 45/250, Loss: 0.0093\n",
      "Epoch 93/200, Iteration 46/250, Loss: 0.0265\n",
      "Epoch 93/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 48/250, Loss: 0.0073\n",
      "Epoch 93/200, Iteration 49/250, Loss: 0.0111\n",
      "Epoch 93/200, Iteration 50/250, Loss: 0.0222\n",
      "Epoch 93/200, Iteration 51/250, Loss: 0.0082\n",
      "Epoch 93/200, Iteration 52/250, Loss: 0.0230\n",
      "Epoch 93/200, Iteration 53/250, Loss: 0.0102\n",
      "Epoch 93/200, Iteration 54/250, Loss: 0.0196\n",
      "Epoch 93/200, Iteration 55/250, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 56/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 57/250, Loss: 0.0219\n",
      "Epoch 93/200, Iteration 58/250, Loss: 0.0113\n",
      "Epoch 93/200, Iteration 59/250, Loss: 0.0439\n",
      "Epoch 93/200, Iteration 60/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 61/250, Loss: 0.0189\n",
      "Epoch 93/200, Iteration 62/250, Loss: 0.0336\n",
      "Epoch 93/200, Iteration 63/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 64/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 65/250, Loss: 0.0118\n",
      "Epoch 93/200, Iteration 66/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 67/250, Loss: 0.0104\n",
      "Epoch 93/200, Iteration 68/250, Loss: 0.0152\n",
      "Epoch 93/200, Iteration 69/250, Loss: 0.0129\n",
      "Epoch 93/200, Iteration 70/250, Loss: 0.0191\n",
      "Epoch 93/200, Iteration 71/250, Loss: 0.0106\n",
      "Epoch 93/200, Iteration 72/250, Loss: 0.0114\n",
      "Epoch 93/200, Iteration 73/250, Loss: 0.0379\n",
      "Epoch 93/200, Iteration 74/250, Loss: 0.0167\n",
      "Epoch 93/200, Iteration 75/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 76/250, Loss: 0.0091\n",
      "Epoch 93/200, Iteration 77/250, Loss: 0.0082\n",
      "Epoch 93/200, Iteration 78/250, Loss: 0.0153\n",
      "Epoch 93/200, Iteration 79/250, Loss: 0.0341\n",
      "Epoch 93/200, Iteration 80/250, Loss: 0.0225\n",
      "Epoch 93/200, Iteration 81/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 82/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 83/250, Loss: 0.0177\n",
      "Epoch 93/200, Iteration 84/250, Loss: 0.0103\n",
      "Epoch 93/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 93/200, Iteration 86/250, Loss: 0.0167\n",
      "Epoch 93/200, Iteration 87/250, Loss: 0.0218\n",
      "Epoch 93/200, Iteration 88/250, Loss: 0.0165\n",
      "Epoch 93/200, Iteration 89/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 90/250, Loss: 0.0131\n",
      "Epoch 93/200, Iteration 91/250, Loss: 0.0077\n",
      "Epoch 93/200, Iteration 92/250, Loss: 0.0157\n",
      "Epoch 93/200, Iteration 93/250, Loss: 0.0128\n",
      "Epoch 93/200, Iteration 94/250, Loss: 0.0095\n",
      "Epoch 93/200, Iteration 95/250, Loss: 0.0108\n",
      "Epoch 93/200, Iteration 96/250, Loss: 0.0100\n",
      "Epoch 93/200, Iteration 97/250, Loss: 0.0103\n",
      "Epoch 93/200, Iteration 98/250, Loss: 0.0418\n",
      "Epoch 93/200, Iteration 99/250, Loss: 0.0131\n",
      "Epoch 93/200, Iteration 100/250, Loss: 0.0279\n",
      "Epoch 93/200, Iteration 101/250, Loss: 0.0174\n",
      "Epoch 93/200, Iteration 102/250, Loss: 0.0085\n",
      "Epoch 93/200, Iteration 103/250, Loss: 0.0343\n",
      "Epoch 93/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 93/200, Iteration 105/250, Loss: 0.0213\n",
      "Epoch 93/200, Iteration 106/250, Loss: 0.0083\n",
      "Epoch 93/200, Iteration 107/250, Loss: 0.0095\n",
      "Epoch 93/200, Iteration 108/250, Loss: 0.0077\n",
      "Epoch 93/200, Iteration 109/250, Loss: 0.0118\n",
      "Epoch 93/200, Iteration 110/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 111/250, Loss: 0.0140\n",
      "Epoch 93/200, Iteration 112/250, Loss: 0.0379\n",
      "Epoch 93/200, Iteration 113/250, Loss: 0.0107\n",
      "Epoch 93/200, Iteration 114/250, Loss: 0.0072\n",
      "Epoch 93/200, Iteration 115/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 116/250, Loss: 0.0249\n",
      "Epoch 93/200, Iteration 117/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 118/250, Loss: 0.0173\n",
      "Epoch 93/200, Iteration 119/250, Loss: 0.0094\n",
      "Epoch 93/200, Iteration 120/250, Loss: 0.0079\n",
      "Epoch 93/200, Iteration 121/250, Loss: 0.0098\n",
      "Epoch 93/200, Iteration 122/250, Loss: 0.0190\n",
      "Epoch 93/200, Iteration 123/250, Loss: 0.0275\n",
      "Epoch 93/200, Iteration 124/250, Loss: 0.0360\n",
      "Epoch 93/200, Iteration 125/250, Loss: 0.0147\n",
      "Epoch 93/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 93/200, Iteration 127/250, Loss: 0.0166\n",
      "Epoch 93/200, Iteration 128/250, Loss: 0.0128\n",
      "Epoch 93/200, Iteration 129/250, Loss: 0.0180\n",
      "Epoch 93/200, Iteration 130/250, Loss: 0.0184\n",
      "Epoch 93/200, Iteration 131/250, Loss: 0.0145\n",
      "Epoch 93/200, Iteration 132/250, Loss: 0.0129\n",
      "Epoch 93/200, Iteration 133/250, Loss: 0.0199\n",
      "Epoch 93/200, Iteration 134/250, Loss: 0.0071\n",
      "Epoch 93/200, Iteration 135/250, Loss: 0.0301\n",
      "Epoch 93/200, Iteration 136/250, Loss: 0.0131\n",
      "Epoch 93/200, Iteration 137/250, Loss: 0.0247\n",
      "Epoch 93/200, Iteration 138/250, Loss: 0.0216\n",
      "Epoch 93/200, Iteration 139/250, Loss: 0.0169\n",
      "Epoch 93/200, Iteration 140/250, Loss: 0.0080\n",
      "Epoch 93/200, Iteration 141/250, Loss: 0.0132\n",
      "Epoch 93/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 93/200, Iteration 143/250, Loss: 0.0123\n",
      "Epoch 93/200, Iteration 144/250, Loss: 0.0119\n",
      "Epoch 93/200, Iteration 145/250, Loss: 0.0210\n",
      "Epoch 93/200, Iteration 146/250, Loss: 0.0158\n",
      "Epoch 93/200, Iteration 147/250, Loss: 0.0107\n",
      "Epoch 93/200, Iteration 148/250, Loss: 0.0245\n",
      "Epoch 93/200, Iteration 149/250, Loss: 0.0161\n",
      "Epoch 93/200, Iteration 150/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 151/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 152/250, Loss: 0.0195\n",
      "Epoch 93/200, Iteration 153/250, Loss: 0.0128\n",
      "Epoch 93/200, Iteration 154/250, Loss: 0.0075\n",
      "Epoch 93/200, Iteration 155/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 156/250, Loss: 0.0099\n",
      "Epoch 93/200, Iteration 157/250, Loss: 0.0227\n",
      "Epoch 93/200, Iteration 158/250, Loss: 0.0089\n",
      "Epoch 93/200, Iteration 159/250, Loss: 0.0119\n",
      "Epoch 93/200, Iteration 160/250, Loss: 0.0268\n",
      "Epoch 93/200, Iteration 161/250, Loss: 0.0484\n",
      "Epoch 93/200, Iteration 162/250, Loss: 0.0234\n",
      "Epoch 93/200, Iteration 163/250, Loss: 0.0222\n",
      "Epoch 93/200, Iteration 164/250, Loss: 0.0155\n",
      "Epoch 93/200, Iteration 165/250, Loss: 0.0143\n",
      "Epoch 93/200, Iteration 166/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 167/250, Loss: 0.0272\n",
      "Epoch 93/200, Iteration 168/250, Loss: 0.0483\n",
      "Epoch 93/200, Iteration 169/250, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 170/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 171/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 172/250, Loss: 0.0278\n",
      "Epoch 93/200, Iteration 173/250, Loss: 0.0074\n",
      "Epoch 93/200, Iteration 174/250, Loss: 0.0347\n",
      "Epoch 93/200, Iteration 175/250, Loss: 0.0106\n",
      "Epoch 93/200, Iteration 176/250, Loss: 0.0089\n",
      "Epoch 93/200, Iteration 177/250, Loss: 0.0081\n",
      "Epoch 93/200, Iteration 178/250, Loss: 0.0114\n",
      "Epoch 93/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 93/200, Iteration 180/250, Loss: 0.0101\n",
      "Epoch 93/200, Iteration 181/250, Loss: 0.0210\n",
      "Epoch 93/200, Iteration 182/250, Loss: 0.0085\n",
      "Epoch 93/200, Iteration 183/250, Loss: 0.0202\n",
      "Epoch 93/200, Iteration 184/250, Loss: 0.0074\n",
      "Epoch 93/200, Iteration 185/250, Loss: 0.0160\n",
      "Epoch 93/200, Iteration 186/250, Loss: 0.0115\n",
      "Epoch 93/200, Iteration 187/250, Loss: 0.0122\n",
      "Epoch 93/200, Iteration 188/250, Loss: 0.0189\n",
      "Epoch 93/200, Iteration 189/250, Loss: 0.0138\n",
      "Epoch 93/200, Iteration 190/250, Loss: 0.0148\n",
      "Epoch 93/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 93/200, Iteration 192/250, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 193/250, Loss: 0.0164\n",
      "Epoch 93/200, Iteration 194/250, Loss: 0.0236\n",
      "Epoch 93/200, Iteration 195/250, Loss: 0.0120\n",
      "Epoch 93/200, Iteration 196/250, Loss: 0.0238\n",
      "Epoch 93/200, Iteration 197/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 198/250, Loss: 0.0094\n",
      "Epoch 93/200, Iteration 199/250, Loss: 0.0146\n",
      "Epoch 93/200, Iteration 200/250, Loss: 0.0146\n",
      "Epoch 93/200, Iteration 201/250, Loss: 0.0076\n",
      "Epoch 93/200, Iteration 202/250, Loss: 0.0387\n",
      "Epoch 93/200, Iteration 203/250, Loss: 0.0089\n",
      "Epoch 93/200, Iteration 204/250, Loss: 0.0085\n",
      "Epoch 93/200, Iteration 205/250, Loss: 0.0157\n",
      "Epoch 93/200, Iteration 206/250, Loss: 0.0170\n",
      "Epoch 93/200, Iteration 207/250, Loss: 0.0097\n",
      "Epoch 93/200, Iteration 208/250, Loss: 0.0399\n",
      "Epoch 93/200, Iteration 209/250, Loss: 0.0101\n",
      "Epoch 93/200, Iteration 210/250, Loss: 0.0078\n",
      "Epoch 93/200, Iteration 211/250, Loss: 0.0095\n",
      "Epoch 93/200, Iteration 212/250, Loss: 0.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 93/200, Iteration 214/250, Loss: 0.0082\n",
      "Epoch 93/200, Iteration 215/250, Loss: 0.0182\n",
      "Epoch 93/200, Iteration 216/250, Loss: 0.0071\n",
      "Epoch 93/200, Iteration 217/250, Loss: 0.0188\n",
      "Epoch 93/200, Iteration 218/250, Loss: 0.0072\n",
      "Epoch 93/200, Iteration 219/250, Loss: 0.0193\n",
      "Epoch 93/200, Iteration 220/250, Loss: 0.0117\n",
      "Epoch 93/200, Iteration 221/250, Loss: 0.0127\n",
      "Epoch 93/200, Iteration 222/250, Loss: 0.0280\n",
      "Epoch 93/200, Iteration 223/250, Loss: 0.0139\n",
      "Epoch 93/200, Iteration 224/250, Loss: 0.0169\n",
      "Epoch 93/200, Iteration 225/250, Loss: 0.0132\n",
      "Epoch 93/200, Iteration 226/250, Loss: 0.0163\n",
      "Epoch 93/200, Iteration 227/250, Loss: 0.0106\n",
      "Epoch 93/200, Iteration 228/250, Loss: 0.0122\n",
      "Epoch 93/200, Iteration 229/250, Loss: 0.0086\n",
      "Epoch 93/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 93/200, Iteration 231/250, Loss: 0.0192\n",
      "Epoch 93/200, Iteration 232/250, Loss: 0.0106\n",
      "Epoch 93/200, Iteration 233/250, Loss: 0.0338\n",
      "Epoch 93/200, Iteration 234/250, Loss: 0.0216\n",
      "Epoch 93/200, Iteration 235/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 236/250, Loss: 0.0132\n",
      "Epoch 93/200, Iteration 237/250, Loss: 0.0175\n",
      "Epoch 93/200, Iteration 238/250, Loss: 0.0176\n",
      "Epoch 93/200, Iteration 239/250, Loss: 0.0110\n",
      "Epoch 93/200, Iteration 240/250, Loss: 0.0096\n",
      "Epoch 93/200, Iteration 241/250, Loss: 0.0284\n",
      "Epoch 93/200, Iteration 242/250, Loss: 0.0088\n",
      "Epoch 93/200, Iteration 243/250, Loss: 0.0136\n",
      "Epoch 93/200, Iteration 244/250, Loss: 0.0229\n",
      "Epoch 93/200, Iteration 245/250, Loss: 0.0309\n",
      "Epoch 93/200, Iteration 246/250, Loss: 0.0119\n",
      "Epoch 93/200, Iteration 247/250, Loss: 0.0144\n",
      "Epoch 93/200, Iteration 248/250, Loss: 0.0083\n",
      "Epoch 93/200, Iteration 249/250, Loss: 0.0069\n",
      "Epoch 93/200, Iteration 250/250, Loss: 0.0161\n",
      "Train Error: \n",
      " Accuracy: 86.02%, Avg loss: 0.006789, MRE: 0.438464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.007306, MRE: 0.516762 \n",
      "\n",
      "Epoch 94/200, Iteration 1/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 2/250, Loss: 0.0121\n",
      "Epoch 94/200, Iteration 3/250, Loss: 0.0114\n",
      "Epoch 94/200, Iteration 4/250, Loss: 0.0174\n",
      "Epoch 94/200, Iteration 5/250, Loss: 0.0313\n",
      "Epoch 94/200, Iteration 6/250, Loss: 0.0217\n",
      "Epoch 94/200, Iteration 7/250, Loss: 0.0261\n",
      "Epoch 94/200, Iteration 8/250, Loss: 0.0095\n",
      "Epoch 94/200, Iteration 9/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 10/250, Loss: 0.0169\n",
      "Epoch 94/200, Iteration 11/250, Loss: 0.0079\n",
      "Epoch 94/200, Iteration 12/250, Loss: 0.0344\n",
      "Epoch 94/200, Iteration 13/250, Loss: 0.0225\n",
      "Epoch 94/200, Iteration 14/250, Loss: 0.0184\n",
      "Epoch 94/200, Iteration 15/250, Loss: 0.0154\n",
      "Epoch 94/200, Iteration 16/250, Loss: 0.0119\n",
      "Epoch 94/200, Iteration 17/250, Loss: 0.0288\n",
      "Epoch 94/200, Iteration 18/250, Loss: 0.0072\n",
      "Epoch 94/200, Iteration 19/250, Loss: 0.0147\n",
      "Epoch 94/200, Iteration 20/250, Loss: 0.0246\n",
      "Epoch 94/200, Iteration 21/250, Loss: 0.0078\n",
      "Epoch 94/200, Iteration 22/250, Loss: 0.0147\n",
      "Epoch 94/200, Iteration 23/250, Loss: 0.0080\n",
      "Epoch 94/200, Iteration 24/250, Loss: 0.0275\n",
      "Epoch 94/200, Iteration 25/250, Loss: 0.0225\n",
      "Epoch 94/200, Iteration 26/250, Loss: 0.0135\n",
      "Epoch 94/200, Iteration 27/250, Loss: 0.0086\n",
      "Epoch 94/200, Iteration 28/250, Loss: 0.0265\n",
      "Epoch 94/200, Iteration 29/250, Loss: 0.0110\n",
      "Epoch 94/200, Iteration 30/250, Loss: 0.0147\n",
      "Epoch 94/200, Iteration 31/250, Loss: 0.0148\n",
      "Epoch 94/200, Iteration 32/250, Loss: 0.0099\n",
      "Epoch 94/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 94/200, Iteration 34/250, Loss: 0.0258\n",
      "Epoch 94/200, Iteration 35/250, Loss: 0.0057\n",
      "Epoch 94/200, Iteration 36/250, Loss: 0.0142\n",
      "Epoch 94/200, Iteration 37/250, Loss: 0.0173\n",
      "Epoch 94/200, Iteration 38/250, Loss: 0.0319\n",
      "Epoch 94/200, Iteration 39/250, Loss: 0.0113\n",
      "Epoch 94/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 94/200, Iteration 41/250, Loss: 0.0189\n",
      "Epoch 94/200, Iteration 42/250, Loss: 0.0144\n",
      "Epoch 94/200, Iteration 43/250, Loss: 0.0364\n",
      "Epoch 94/200, Iteration 44/250, Loss: 0.0348\n",
      "Epoch 94/200, Iteration 45/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 46/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 47/250, Loss: 0.0122\n",
      "Epoch 94/200, Iteration 48/250, Loss: 0.0135\n",
      "Epoch 94/200, Iteration 49/250, Loss: 0.0125\n",
      "Epoch 94/200, Iteration 50/250, Loss: 0.0211\n",
      "Epoch 94/200, Iteration 51/250, Loss: 0.0389\n",
      "Epoch 94/200, Iteration 52/250, Loss: 0.0082\n",
      "Epoch 94/200, Iteration 53/250, Loss: 0.0202\n",
      "Epoch 94/200, Iteration 54/250, Loss: 0.0181\n",
      "Epoch 94/200, Iteration 55/250, Loss: 0.0075\n",
      "Epoch 94/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 57/250, Loss: 0.0157\n",
      "Epoch 94/200, Iteration 58/250, Loss: 0.0181\n",
      "Epoch 94/200, Iteration 59/250, Loss: 0.0074\n",
      "Epoch 94/200, Iteration 60/250, Loss: 0.0171\n",
      "Epoch 94/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 94/200, Iteration 62/250, Loss: 0.0164\n",
      "Epoch 94/200, Iteration 63/250, Loss: 0.0160\n",
      "Epoch 94/200, Iteration 64/250, Loss: 0.0100\n",
      "Epoch 94/200, Iteration 65/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 66/250, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 67/250, Loss: 0.0173\n",
      "Epoch 94/200, Iteration 68/250, Loss: 0.0116\n",
      "Epoch 94/200, Iteration 69/250, Loss: 0.0172\n",
      "Epoch 94/200, Iteration 70/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 71/250, Loss: 0.0110\n",
      "Epoch 94/200, Iteration 72/250, Loss: 0.0196\n",
      "Epoch 94/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 94/200, Iteration 74/250, Loss: 0.0165\n",
      "Epoch 94/200, Iteration 75/250, Loss: 0.0136\n",
      "Epoch 94/200, Iteration 76/250, Loss: 0.0084\n",
      "Epoch 94/200, Iteration 77/250, Loss: 0.0289\n",
      "Epoch 94/200, Iteration 78/250, Loss: 0.0108\n",
      "Epoch 94/200, Iteration 79/250, Loss: 0.0127\n",
      "Epoch 94/200, Iteration 80/250, Loss: 0.0196\n",
      "Epoch 94/200, Iteration 81/250, Loss: 0.0077\n",
      "Epoch 94/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 83/250, Loss: 0.0164\n",
      "Epoch 94/200, Iteration 84/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 85/250, Loss: 0.0114\n",
      "Epoch 94/200, Iteration 86/250, Loss: 0.0242\n",
      "Epoch 94/200, Iteration 87/250, Loss: 0.0185\n",
      "Epoch 94/200, Iteration 88/250, Loss: 0.0095\n",
      "Epoch 94/200, Iteration 89/250, Loss: 0.0148\n",
      "Epoch 94/200, Iteration 90/250, Loss: 0.0113\n",
      "Epoch 94/200, Iteration 91/250, Loss: 0.0242\n",
      "Epoch 94/200, Iteration 92/250, Loss: 0.0141\n",
      "Epoch 94/200, Iteration 93/250, Loss: 0.0134\n",
      "Epoch 94/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 94/200, Iteration 95/250, Loss: 0.0091\n",
      "Epoch 94/200, Iteration 96/250, Loss: 0.0257\n",
      "Epoch 94/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 94/200, Iteration 98/250, Loss: 0.0170\n",
      "Epoch 94/200, Iteration 99/250, Loss: 0.0089\n",
      "Epoch 94/200, Iteration 100/250, Loss: 0.0082\n",
      "Epoch 94/200, Iteration 101/250, Loss: 0.0280\n",
      "Epoch 94/200, Iteration 102/250, Loss: 0.0191\n",
      "Epoch 94/200, Iteration 103/250, Loss: 0.0221\n",
      "Epoch 94/200, Iteration 104/250, Loss: 0.0085\n",
      "Epoch 94/200, Iteration 105/250, Loss: 0.0208\n",
      "Epoch 94/200, Iteration 106/250, Loss: 0.0317\n",
      "Epoch 94/200, Iteration 107/250, Loss: 0.0123\n",
      "Epoch 94/200, Iteration 108/250, Loss: 0.0075\n",
      "Epoch 94/200, Iteration 109/250, Loss: 0.0080\n",
      "Epoch 94/200, Iteration 110/250, Loss: 0.0144\n",
      "Epoch 94/200, Iteration 111/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 112/250, Loss: 0.0075\n",
      "Epoch 94/200, Iteration 113/250, Loss: 0.0095\n",
      "Epoch 94/200, Iteration 114/250, Loss: 0.0266\n",
      "Epoch 94/200, Iteration 115/250, Loss: 0.0290\n",
      "Epoch 94/200, Iteration 116/250, Loss: 0.0150\n",
      "Epoch 94/200, Iteration 117/250, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 118/250, Loss: 0.0161\n",
      "Epoch 94/200, Iteration 119/250, Loss: 0.0111\n",
      "Epoch 94/200, Iteration 120/250, Loss: 0.0136\n",
      "Epoch 94/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 94/200, Iteration 122/250, Loss: 0.0116\n",
      "Epoch 94/200, Iteration 123/250, Loss: 0.0121\n",
      "Epoch 94/200, Iteration 124/250, Loss: 0.0091\n",
      "Epoch 94/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 126/250, Loss: 0.0089\n",
      "Epoch 94/200, Iteration 127/250, Loss: 0.0396\n",
      "Epoch 94/200, Iteration 128/250, Loss: 0.0151\n",
      "Epoch 94/200, Iteration 129/250, Loss: 0.0195\n",
      "Epoch 94/200, Iteration 130/250, Loss: 0.0271\n",
      "Epoch 94/200, Iteration 131/250, Loss: 0.0096\n",
      "Epoch 94/200, Iteration 132/250, Loss: 0.0069\n",
      "Epoch 94/200, Iteration 133/250, Loss: 0.0178\n",
      "Epoch 94/200, Iteration 134/250, Loss: 0.0186\n",
      "Epoch 94/200, Iteration 135/250, Loss: 0.0226\n",
      "Epoch 94/200, Iteration 136/250, Loss: 0.0073\n",
      "Epoch 94/200, Iteration 137/250, Loss: 0.0076\n",
      "Epoch 94/200, Iteration 138/250, Loss: 0.0248\n",
      "Epoch 94/200, Iteration 139/250, Loss: 0.0110\n",
      "Epoch 94/200, Iteration 140/250, Loss: 0.0228\n",
      "Epoch 94/200, Iteration 141/250, Loss: 0.0300\n",
      "Epoch 94/200, Iteration 142/250, Loss: 0.0057\n",
      "Epoch 94/200, Iteration 143/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 144/250, Loss: 0.0265\n",
      "Epoch 94/200, Iteration 145/250, Loss: 0.0161\n",
      "Epoch 94/200, Iteration 146/250, Loss: 0.0084\n",
      "Epoch 94/200, Iteration 147/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 148/250, Loss: 0.0108\n",
      "Epoch 94/200, Iteration 149/250, Loss: 0.0163\n",
      "Epoch 94/200, Iteration 150/250, Loss: 0.0251\n",
      "Epoch 94/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 94/200, Iteration 152/250, Loss: 0.0254\n",
      "Epoch 94/200, Iteration 153/250, Loss: 0.0099\n",
      "Epoch 94/200, Iteration 154/250, Loss: 0.0211\n",
      "Epoch 94/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 94/200, Iteration 156/250, Loss: 0.0118\n",
      "Epoch 94/200, Iteration 157/250, Loss: 0.0157\n",
      "Epoch 94/200, Iteration 158/250, Loss: 0.0181\n",
      "Epoch 94/200, Iteration 159/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 160/250, Loss: 0.0066\n",
      "Epoch 94/200, Iteration 161/250, Loss: 0.0070\n",
      "Epoch 94/200, Iteration 162/250, Loss: 0.0122\n",
      "Epoch 94/200, Iteration 163/250, Loss: 0.0102\n",
      "Epoch 94/200, Iteration 164/250, Loss: 0.0094\n",
      "Epoch 94/200, Iteration 165/250, Loss: 0.0097\n",
      "Epoch 94/200, Iteration 166/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 167/250, Loss: 0.0118\n",
      "Epoch 94/200, Iteration 168/250, Loss: 0.0091\n",
      "Epoch 94/200, Iteration 169/250, Loss: 0.0379\n",
      "Epoch 94/200, Iteration 170/250, Loss: 0.0156\n",
      "Epoch 94/200, Iteration 171/250, Loss: 0.0144\n",
      "Epoch 94/200, Iteration 172/250, Loss: 0.0089\n",
      "Epoch 94/200, Iteration 173/250, Loss: 0.0142\n",
      "Epoch 94/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 94/200, Iteration 175/250, Loss: 0.0107\n",
      "Epoch 94/200, Iteration 176/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200, Iteration 177/250, Loss: 0.0083\n",
      "Epoch 94/200, Iteration 178/250, Loss: 0.0327\n",
      "Epoch 94/200, Iteration 179/250, Loss: 0.0125\n",
      "Epoch 94/200, Iteration 180/250, Loss: 0.0361\n",
      "Epoch 94/200, Iteration 181/250, Loss: 0.0313\n",
      "Epoch 94/200, Iteration 182/250, Loss: 0.0122\n",
      "Epoch 94/200, Iteration 183/250, Loss: 0.0313\n",
      "Epoch 94/200, Iteration 184/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 185/250, Loss: 0.0131\n",
      "Epoch 94/200, Iteration 186/250, Loss: 0.0099\n",
      "Epoch 94/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 94/200, Iteration 188/250, Loss: 0.0141\n",
      "Epoch 94/200, Iteration 189/250, Loss: 0.0169\n",
      "Epoch 94/200, Iteration 190/250, Loss: 0.0069\n",
      "Epoch 94/200, Iteration 191/250, Loss: 0.0449\n",
      "Epoch 94/200, Iteration 192/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 193/250, Loss: 0.0142\n",
      "Epoch 94/200, Iteration 194/250, Loss: 0.0104\n",
      "Epoch 94/200, Iteration 195/250, Loss: 0.0076\n",
      "Epoch 94/200, Iteration 196/250, Loss: 0.0072\n",
      "Epoch 94/200, Iteration 197/250, Loss: 0.0203\n",
      "Epoch 94/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 94/200, Iteration 199/250, Loss: 0.0221\n",
      "Epoch 94/200, Iteration 200/250, Loss: 0.0176\n",
      "Epoch 94/200, Iteration 201/250, Loss: 0.0250\n",
      "Epoch 94/200, Iteration 202/250, Loss: 0.0072\n",
      "Epoch 94/200, Iteration 203/250, Loss: 0.0215\n",
      "Epoch 94/200, Iteration 204/250, Loss: 0.0139\n",
      "Epoch 94/200, Iteration 205/250, Loss: 0.0279\n",
      "Epoch 94/200, Iteration 206/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 207/250, Loss: 0.0164\n",
      "Epoch 94/200, Iteration 208/250, Loss: 0.0082\n",
      "Epoch 94/200, Iteration 209/250, Loss: 0.0086\n",
      "Epoch 94/200, Iteration 210/250, Loss: 0.0099\n",
      "Epoch 94/200, Iteration 211/250, Loss: 0.0054\n",
      "Epoch 94/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 94/200, Iteration 213/250, Loss: 0.0169\n",
      "Epoch 94/200, Iteration 214/250, Loss: 0.0114\n",
      "Epoch 94/200, Iteration 215/250, Loss: 0.0140\n",
      "Epoch 94/200, Iteration 216/250, Loss: 0.0093\n",
      "Epoch 94/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 94/200, Iteration 218/250, Loss: 0.0216\n",
      "Epoch 94/200, Iteration 219/250, Loss: 0.0203\n",
      "Epoch 94/200, Iteration 220/250, Loss: 0.0106\n",
      "Epoch 94/200, Iteration 221/250, Loss: 0.0117\n",
      "Epoch 94/200, Iteration 222/250, Loss: 0.0233\n",
      "Epoch 94/200, Iteration 223/250, Loss: 0.0185\n",
      "Epoch 94/200, Iteration 224/250, Loss: 0.0238\n",
      "Epoch 94/200, Iteration 225/250, Loss: 0.0098\n",
      "Epoch 94/200, Iteration 226/250, Loss: 0.0141\n",
      "Epoch 94/200, Iteration 227/250, Loss: 0.0135\n",
      "Epoch 94/200, Iteration 228/250, Loss: 0.0223\n",
      "Epoch 94/200, Iteration 229/250, Loss: 0.0101\n",
      "Epoch 94/200, Iteration 230/250, Loss: 0.0323\n",
      "Epoch 94/200, Iteration 231/250, Loss: 0.0239\n",
      "Epoch 94/200, Iteration 232/250, Loss: 0.0120\n",
      "Epoch 94/200, Iteration 233/250, Loss: 0.0126\n",
      "Epoch 94/200, Iteration 234/250, Loss: 0.0135\n",
      "Epoch 94/200, Iteration 235/250, Loss: 0.0121\n",
      "Epoch 94/200, Iteration 236/250, Loss: 0.0292\n",
      "Epoch 94/200, Iteration 237/250, Loss: 0.0264\n",
      "Epoch 94/200, Iteration 238/250, Loss: 0.0089\n",
      "Epoch 94/200, Iteration 239/250, Loss: 0.0143\n",
      "Epoch 94/200, Iteration 240/250, Loss: 0.0154\n",
      "Epoch 94/200, Iteration 241/250, Loss: 0.0128\n",
      "Epoch 94/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 94/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 94/200, Iteration 244/250, Loss: 0.0087\n",
      "Epoch 94/200, Iteration 245/250, Loss: 0.0209\n",
      "Epoch 94/200, Iteration 246/250, Loss: 0.0088\n",
      "Epoch 94/200, Iteration 247/250, Loss: 0.0118\n",
      "Epoch 94/200, Iteration 248/250, Loss: 0.0058\n",
      "Epoch 94/200, Iteration 249/250, Loss: 0.0077\n",
      "Epoch 94/200, Iteration 250/250, Loss: 0.0190\n",
      "Train Error: \n",
      " Accuracy: 89.25%, Avg loss: 0.006706, MRE: 0.420972 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.007268, MRE: 0.523597 \n",
      "\n",
      "Epoch 95/200, Iteration 1/250, Loss: 0.0097\n",
      "Epoch 95/200, Iteration 2/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 3/250, Loss: 0.0184\n",
      "Epoch 95/200, Iteration 4/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 95/200, Iteration 6/250, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 7/250, Loss: 0.0252\n",
      "Epoch 95/200, Iteration 8/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 9/250, Loss: 0.0286\n",
      "Epoch 95/200, Iteration 10/250, Loss: 0.0201\n",
      "Epoch 95/200, Iteration 11/250, Loss: 0.0124\n",
      "Epoch 95/200, Iteration 12/250, Loss: 0.0153\n",
      "Epoch 95/200, Iteration 13/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 14/250, Loss: 0.0133\n",
      "Epoch 95/200, Iteration 15/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 16/250, Loss: 0.0169\n",
      "Epoch 95/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 95/200, Iteration 18/250, Loss: 0.0236\n",
      "Epoch 95/200, Iteration 19/250, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 20/250, Loss: 0.0314\n",
      "Epoch 95/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 95/200, Iteration 22/250, Loss: 0.0133\n",
      "Epoch 95/200, Iteration 23/250, Loss: 0.0273\n",
      "Epoch 95/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 25/250, Loss: 0.0196\n",
      "Epoch 95/200, Iteration 26/250, Loss: 0.0091\n",
      "Epoch 95/200, Iteration 27/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 28/250, Loss: 0.0284\n",
      "Epoch 95/200, Iteration 29/250, Loss: 0.0301\n",
      "Epoch 95/200, Iteration 30/250, Loss: 0.0281\n",
      "Epoch 95/200, Iteration 31/250, Loss: 0.0078\n",
      "Epoch 95/200, Iteration 32/250, Loss: 0.0208\n",
      "Epoch 95/200, Iteration 33/250, Loss: 0.0132\n",
      "Epoch 95/200, Iteration 34/250, Loss: 0.0114\n",
      "Epoch 95/200, Iteration 35/250, Loss: 0.0148\n",
      "Epoch 95/200, Iteration 36/250, Loss: 0.0131\n",
      "Epoch 95/200, Iteration 37/250, Loss: 0.0077\n",
      "Epoch 95/200, Iteration 38/250, Loss: 0.0135\n",
      "Epoch 95/200, Iteration 39/250, Loss: 0.0338\n",
      "Epoch 95/200, Iteration 40/250, Loss: 0.0207\n",
      "Epoch 95/200, Iteration 41/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 42/250, Loss: 0.0334\n",
      "Epoch 95/200, Iteration 43/250, Loss: 0.0195\n",
      "Epoch 95/200, Iteration 44/250, Loss: 0.0137\n",
      "Epoch 95/200, Iteration 45/250, Loss: 0.0218\n",
      "Epoch 95/200, Iteration 46/250, Loss: 0.0313\n",
      "Epoch 95/200, Iteration 47/250, Loss: 0.0150\n",
      "Epoch 95/200, Iteration 48/250, Loss: 0.0132\n",
      "Epoch 95/200, Iteration 49/250, Loss: 0.0085\n",
      "Epoch 95/200, Iteration 50/250, Loss: 0.0237\n",
      "Epoch 95/200, Iteration 51/250, Loss: 0.0200\n",
      "Epoch 95/200, Iteration 52/250, Loss: 0.0219\n",
      "Epoch 95/200, Iteration 53/250, Loss: 0.0090\n",
      "Epoch 95/200, Iteration 54/250, Loss: 0.0093\n",
      "Epoch 95/200, Iteration 55/250, Loss: 0.0141\n",
      "Epoch 95/200, Iteration 56/250, Loss: 0.0140\n",
      "Epoch 95/200, Iteration 57/250, Loss: 0.0148\n",
      "Epoch 95/200, Iteration 58/250, Loss: 0.0249\n",
      "Epoch 95/200, Iteration 59/250, Loss: 0.0139\n",
      "Epoch 95/200, Iteration 60/250, Loss: 0.0164\n",
      "Epoch 95/200, Iteration 61/250, Loss: 0.0306\n",
      "Epoch 95/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 63/250, Loss: 0.0172\n",
      "Epoch 95/200, Iteration 64/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 65/250, Loss: 0.0118\n",
      "Epoch 95/200, Iteration 66/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 67/250, Loss: 0.0084\n",
      "Epoch 95/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 95/200, Iteration 69/250, Loss: 0.0103\n",
      "Epoch 95/200, Iteration 70/250, Loss: 0.0275\n",
      "Epoch 95/200, Iteration 71/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 72/250, Loss: 0.0284\n",
      "Epoch 95/200, Iteration 73/250, Loss: 0.0173\n",
      "Epoch 95/200, Iteration 74/250, Loss: 0.0127\n",
      "Epoch 95/200, Iteration 75/250, Loss: 0.0246\n",
      "Epoch 95/200, Iteration 76/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 77/250, Loss: 0.0190\n",
      "Epoch 95/200, Iteration 78/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 79/250, Loss: 0.0122\n",
      "Epoch 95/200, Iteration 80/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 81/250, Loss: 0.0102\n",
      "Epoch 95/200, Iteration 82/250, Loss: 0.0090\n",
      "Epoch 95/200, Iteration 83/250, Loss: 0.0150\n",
      "Epoch 95/200, Iteration 84/250, Loss: 0.0215\n",
      "Epoch 95/200, Iteration 85/250, Loss: 0.0126\n",
      "Epoch 95/200, Iteration 86/250, Loss: 0.0069\n",
      "Epoch 95/200, Iteration 87/250, Loss: 0.0161\n",
      "Epoch 95/200, Iteration 88/250, Loss: 0.0087\n",
      "Epoch 95/200, Iteration 89/250, Loss: 0.0171\n",
      "Epoch 95/200, Iteration 90/250, Loss: 0.0188\n",
      "Epoch 95/200, Iteration 91/250, Loss: 0.0076\n",
      "Epoch 95/200, Iteration 92/250, Loss: 0.0098\n",
      "Epoch 95/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 95/200, Iteration 94/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 95/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 96/250, Loss: 0.0212\n",
      "Epoch 95/200, Iteration 97/250, Loss: 0.0107\n",
      "Epoch 95/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 99/250, Loss: 0.0140\n",
      "Epoch 95/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 95/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 102/250, Loss: 0.0128\n",
      "Epoch 95/200, Iteration 103/250, Loss: 0.0217\n",
      "Epoch 95/200, Iteration 104/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 105/250, Loss: 0.0207\n",
      "Epoch 95/200, Iteration 106/250, Loss: 0.0244\n",
      "Epoch 95/200, Iteration 107/250, Loss: 0.0130\n",
      "Epoch 95/200, Iteration 108/250, Loss: 0.0155\n",
      "Epoch 95/200, Iteration 109/250, Loss: 0.0073\n",
      "Epoch 95/200, Iteration 110/250, Loss: 0.0180\n",
      "Epoch 95/200, Iteration 111/250, Loss: 0.0207\n",
      "Epoch 95/200, Iteration 112/250, Loss: 0.0197\n",
      "Epoch 95/200, Iteration 113/250, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 114/250, Loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200, Iteration 115/250, Loss: 0.0224\n",
      "Epoch 95/200, Iteration 116/250, Loss: 0.0129\n",
      "Epoch 95/200, Iteration 117/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 118/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 119/250, Loss: 0.0072\n",
      "Epoch 95/200, Iteration 120/250, Loss: 0.0188\n",
      "Epoch 95/200, Iteration 121/250, Loss: 0.0174\n",
      "Epoch 95/200, Iteration 122/250, Loss: 0.0236\n",
      "Epoch 95/200, Iteration 123/250, Loss: 0.0252\n",
      "Epoch 95/200, Iteration 124/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 125/250, Loss: 0.0382\n",
      "Epoch 95/200, Iteration 126/250, Loss: 0.0170\n",
      "Epoch 95/200, Iteration 127/250, Loss: 0.0264\n",
      "Epoch 95/200, Iteration 128/250, Loss: 0.0113\n",
      "Epoch 95/200, Iteration 129/250, Loss: 0.0136\n",
      "Epoch 95/200, Iteration 130/250, Loss: 0.0084\n",
      "Epoch 95/200, Iteration 131/250, Loss: 0.0297\n",
      "Epoch 95/200, Iteration 132/250, Loss: 0.0226\n",
      "Epoch 95/200, Iteration 133/250, Loss: 0.0199\n",
      "Epoch 95/200, Iteration 134/250, Loss: 0.0158\n",
      "Epoch 95/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 95/200, Iteration 136/250, Loss: 0.0192\n",
      "Epoch 95/200, Iteration 137/250, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 138/250, Loss: 0.0157\n",
      "Epoch 95/200, Iteration 139/250, Loss: 0.0370\n",
      "Epoch 95/200, Iteration 140/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 141/250, Loss: 0.0402\n",
      "Epoch 95/200, Iteration 142/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 143/250, Loss: 0.0144\n",
      "Epoch 95/200, Iteration 144/250, Loss: 0.0118\n",
      "Epoch 95/200, Iteration 145/250, Loss: 0.0139\n",
      "Epoch 95/200, Iteration 146/250, Loss: 0.0142\n",
      "Epoch 95/200, Iteration 147/250, Loss: 0.0157\n",
      "Epoch 95/200, Iteration 148/250, Loss: 0.0156\n",
      "Epoch 95/200, Iteration 149/250, Loss: 0.0199\n",
      "Epoch 95/200, Iteration 150/250, Loss: 0.0243\n",
      "Epoch 95/200, Iteration 151/250, Loss: 0.0109\n",
      "Epoch 95/200, Iteration 152/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 153/250, Loss: 0.0183\n",
      "Epoch 95/200, Iteration 154/250, Loss: 0.0260\n",
      "Epoch 95/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 95/200, Iteration 156/250, Loss: 0.0187\n",
      "Epoch 95/200, Iteration 157/250, Loss: 0.0194\n",
      "Epoch 95/200, Iteration 158/250, Loss: 0.0232\n",
      "Epoch 95/200, Iteration 159/250, Loss: 0.0195\n",
      "Epoch 95/200, Iteration 160/250, Loss: 0.0251\n",
      "Epoch 95/200, Iteration 161/250, Loss: 0.0126\n",
      "Epoch 95/200, Iteration 162/250, Loss: 0.0114\n",
      "Epoch 95/200, Iteration 163/250, Loss: 0.0320\n",
      "Epoch 95/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 165/250, Loss: 0.0098\n",
      "Epoch 95/200, Iteration 166/250, Loss: 0.0105\n",
      "Epoch 95/200, Iteration 167/250, Loss: 0.0121\n",
      "Epoch 95/200, Iteration 168/250, Loss: 0.0147\n",
      "Epoch 95/200, Iteration 169/250, Loss: 0.0139\n",
      "Epoch 95/200, Iteration 170/250, Loss: 0.0102\n",
      "Epoch 95/200, Iteration 171/250, Loss: 0.0133\n",
      "Epoch 95/200, Iteration 172/250, Loss: 0.0122\n",
      "Epoch 95/200, Iteration 173/250, Loss: 0.0235\n",
      "Epoch 95/200, Iteration 174/250, Loss: 0.0130\n",
      "Epoch 95/200, Iteration 175/250, Loss: 0.0112\n",
      "Epoch 95/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 95/200, Iteration 177/250, Loss: 0.0178\n",
      "Epoch 95/200, Iteration 178/250, Loss: 0.0047\n",
      "Epoch 95/200, Iteration 179/250, Loss: 0.0074\n",
      "Epoch 95/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 95/200, Iteration 181/250, Loss: 0.0348\n",
      "Epoch 95/200, Iteration 182/250, Loss: 0.0081\n",
      "Epoch 95/200, Iteration 183/250, Loss: 0.0092\n",
      "Epoch 95/200, Iteration 184/250, Loss: 0.0079\n",
      "Epoch 95/200, Iteration 185/250, Loss: 0.0083\n",
      "Epoch 95/200, Iteration 186/250, Loss: 0.0118\n",
      "Epoch 95/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 95/200, Iteration 188/250, Loss: 0.0185\n",
      "Epoch 95/200, Iteration 189/250, Loss: 0.0144\n",
      "Epoch 95/200, Iteration 190/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 191/250, Loss: 0.0069\n",
      "Epoch 95/200, Iteration 192/250, Loss: 0.0179\n",
      "Epoch 95/200, Iteration 193/250, Loss: 0.0177\n",
      "Epoch 95/200, Iteration 194/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 195/250, Loss: 0.0187\n",
      "Epoch 95/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 95/200, Iteration 197/250, Loss: 0.0121\n",
      "Epoch 95/200, Iteration 198/250, Loss: 0.0264\n",
      "Epoch 95/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 95/200, Iteration 200/250, Loss: 0.0088\n",
      "Epoch 95/200, Iteration 201/250, Loss: 0.0233\n",
      "Epoch 95/200, Iteration 202/250, Loss: 0.0149\n",
      "Epoch 95/200, Iteration 203/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 204/250, Loss: 0.0120\n",
      "Epoch 95/200, Iteration 205/250, Loss: 0.0113\n",
      "Epoch 95/200, Iteration 206/250, Loss: 0.0070\n",
      "Epoch 95/200, Iteration 207/250, Loss: 0.0065\n",
      "Epoch 95/200, Iteration 208/250, Loss: 0.0110\n",
      "Epoch 95/200, Iteration 209/250, Loss: 0.0111\n",
      "Epoch 95/200, Iteration 210/250, Loss: 0.0379\n",
      "Epoch 95/200, Iteration 211/250, Loss: 0.0096\n",
      "Epoch 95/200, Iteration 212/250, Loss: 0.0218\n",
      "Epoch 95/200, Iteration 213/250, Loss: 0.0175\n",
      "Epoch 95/200, Iteration 214/250, Loss: 0.0099\n",
      "Epoch 95/200, Iteration 215/250, Loss: 0.0277\n",
      "Epoch 95/200, Iteration 216/250, Loss: 0.0121\n",
      "Epoch 95/200, Iteration 217/250, Loss: 0.0187\n",
      "Epoch 95/200, Iteration 218/250, Loss: 0.0173\n",
      "Epoch 95/200, Iteration 219/250, Loss: 0.0333\n",
      "Epoch 95/200, Iteration 220/250, Loss: 0.0376\n",
      "Epoch 95/200, Iteration 221/250, Loss: 0.0089\n",
      "Epoch 95/200, Iteration 222/250, Loss: 0.0229\n",
      "Epoch 95/200, Iteration 223/250, Loss: 0.0182\n",
      "Epoch 95/200, Iteration 224/250, Loss: 0.0100\n",
      "Epoch 95/200, Iteration 225/250, Loss: 0.0170\n",
      "Epoch 95/200, Iteration 226/250, Loss: 0.0198\n",
      "Epoch 95/200, Iteration 227/250, Loss: 0.0063\n",
      "Epoch 95/200, Iteration 228/250, Loss: 0.0342\n",
      "Epoch 95/200, Iteration 229/250, Loss: 0.0238\n",
      "Epoch 95/200, Iteration 230/250, Loss: 0.0152\n",
      "Epoch 95/200, Iteration 231/250, Loss: 0.0082\n",
      "Epoch 95/200, Iteration 232/250, Loss: 0.0075\n",
      "Epoch 95/200, Iteration 233/250, Loss: 0.0095\n",
      "Epoch 95/200, Iteration 234/250, Loss: 0.0077\n",
      "Epoch 95/200, Iteration 235/250, Loss: 0.0148\n",
      "Epoch 95/200, Iteration 236/250, Loss: 0.0101\n",
      "Epoch 95/200, Iteration 237/250, Loss: 0.0084\n",
      "Epoch 95/200, Iteration 238/250, Loss: 0.0080\n",
      "Epoch 95/200, Iteration 239/250, Loss: 0.0085\n",
      "Epoch 95/200, Iteration 240/250, Loss: 0.0143\n",
      "Epoch 95/200, Iteration 241/250, Loss: 0.0094\n",
      "Epoch 95/200, Iteration 242/250, Loss: 0.0152\n",
      "Epoch 95/200, Iteration 243/250, Loss: 0.0349\n",
      "Epoch 95/200, Iteration 244/250, Loss: 0.0352\n",
      "Epoch 95/200, Iteration 245/250, Loss: 0.0224\n",
      "Epoch 95/200, Iteration 246/250, Loss: 0.0154\n",
      "Epoch 95/200, Iteration 247/250, Loss: 0.0160\n",
      "Epoch 95/200, Iteration 248/250, Loss: 0.0126\n",
      "Epoch 95/200, Iteration 249/250, Loss: 0.0055\n",
      "Epoch 95/200, Iteration 250/250, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 82.64%, Avg loss: 0.007235, MRE: 0.511400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.05%, Avg loss: 0.007761, MRE: 0.577660 \n",
      "\n",
      "Epoch 96/200, Iteration 1/250, Loss: 0.0244\n",
      "Epoch 96/200, Iteration 2/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 3/250, Loss: 0.0077\n",
      "Epoch 96/200, Iteration 4/250, Loss: 0.0220\n",
      "Epoch 96/200, Iteration 5/250, Loss: 0.0133\n",
      "Epoch 96/200, Iteration 6/250, Loss: 0.0211\n",
      "Epoch 96/200, Iteration 7/250, Loss: 0.0097\n",
      "Epoch 96/200, Iteration 8/250, Loss: 0.0274\n",
      "Epoch 96/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 10/250, Loss: 0.0451\n",
      "Epoch 96/200, Iteration 11/250, Loss: 0.0136\n",
      "Epoch 96/200, Iteration 12/250, Loss: 0.0280\n",
      "Epoch 96/200, Iteration 13/250, Loss: 0.0234\n",
      "Epoch 96/200, Iteration 14/250, Loss: 0.0185\n",
      "Epoch 96/200, Iteration 15/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 17/250, Loss: 0.0300\n",
      "Epoch 96/200, Iteration 18/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 19/250, Loss: 0.0092\n",
      "Epoch 96/200, Iteration 20/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 22/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 23/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 24/250, Loss: 0.0080\n",
      "Epoch 96/200, Iteration 25/250, Loss: 0.0158\n",
      "Epoch 96/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 96/200, Iteration 27/250, Loss: 0.0074\n",
      "Epoch 96/200, Iteration 28/250, Loss: 0.0429\n",
      "Epoch 96/200, Iteration 29/250, Loss: 0.0122\n",
      "Epoch 96/200, Iteration 30/250, Loss: 0.0102\n",
      "Epoch 96/200, Iteration 31/250, Loss: 0.0279\n",
      "Epoch 96/200, Iteration 32/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 33/250, Loss: 0.0121\n",
      "Epoch 96/200, Iteration 34/250, Loss: 0.0159\n",
      "Epoch 96/200, Iteration 35/250, Loss: 0.0114\n",
      "Epoch 96/200, Iteration 36/250, Loss: 0.0103\n",
      "Epoch 96/200, Iteration 37/250, Loss: 0.0148\n",
      "Epoch 96/200, Iteration 38/250, Loss: 0.0258\n",
      "Epoch 96/200, Iteration 39/250, Loss: 0.0062\n",
      "Epoch 96/200, Iteration 40/250, Loss: 0.0223\n",
      "Epoch 96/200, Iteration 41/250, Loss: 0.0097\n",
      "Epoch 96/200, Iteration 42/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 43/250, Loss: 0.0156\n",
      "Epoch 96/200, Iteration 44/250, Loss: 0.0132\n",
      "Epoch 96/200, Iteration 45/250, Loss: 0.0446\n",
      "Epoch 96/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 47/250, Loss: 0.0132\n",
      "Epoch 96/200, Iteration 48/250, Loss: 0.0170\n",
      "Epoch 96/200, Iteration 49/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 50/250, Loss: 0.0080\n",
      "Epoch 96/200, Iteration 51/250, Loss: 0.0129\n",
      "Epoch 96/200, Iteration 52/250, Loss: 0.0082\n",
      "Epoch 96/200, Iteration 53/250, Loss: 0.0204\n",
      "Epoch 96/200, Iteration 54/250, Loss: 0.0127\n",
      "Epoch 96/200, Iteration 55/250, Loss: 0.0095\n",
      "Epoch 96/200, Iteration 56/250, Loss: 0.0119\n",
      "Epoch 96/200, Iteration 57/250, Loss: 0.0124\n",
      "Epoch 96/200, Iteration 58/250, Loss: 0.0121\n",
      "Epoch 96/200, Iteration 59/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 60/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 61/250, Loss: 0.0195\n",
      "Epoch 96/200, Iteration 62/250, Loss: 0.0118\n",
      "Epoch 96/200, Iteration 63/250, Loss: 0.0171\n",
      "Epoch 96/200, Iteration 64/250, Loss: 0.0180\n",
      "Epoch 96/200, Iteration 65/250, Loss: 0.0253\n",
      "Epoch 96/200, Iteration 66/250, Loss: 0.0222\n",
      "Epoch 96/200, Iteration 67/250, Loss: 0.0085\n",
      "Epoch 96/200, Iteration 68/250, Loss: 0.0090\n",
      "Epoch 96/200, Iteration 69/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 70/250, Loss: 0.0238\n",
      "Epoch 96/200, Iteration 71/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200, Iteration 72/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 73/250, Loss: 0.0080\n",
      "Epoch 96/200, Iteration 74/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 75/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 76/250, Loss: 0.0103\n",
      "Epoch 96/200, Iteration 77/250, Loss: 0.0212\n",
      "Epoch 96/200, Iteration 78/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 79/250, Loss: 0.0087\n",
      "Epoch 96/200, Iteration 80/250, Loss: 0.0105\n",
      "Epoch 96/200, Iteration 81/250, Loss: 0.0082\n",
      "Epoch 96/200, Iteration 82/250, Loss: 0.0078\n",
      "Epoch 96/200, Iteration 83/250, Loss: 0.0277\n",
      "Epoch 96/200, Iteration 84/250, Loss: 0.0186\n",
      "Epoch 96/200, Iteration 85/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 86/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 87/250, Loss: 0.0142\n",
      "Epoch 96/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 89/250, Loss: 0.0067\n",
      "Epoch 96/200, Iteration 90/250, Loss: 0.0079\n",
      "Epoch 96/200, Iteration 91/250, Loss: 0.0203\n",
      "Epoch 96/200, Iteration 92/250, Loss: 0.0170\n",
      "Epoch 96/200, Iteration 93/250, Loss: 0.0141\n",
      "Epoch 96/200, Iteration 94/250, Loss: 0.0173\n",
      "Epoch 96/200, Iteration 95/250, Loss: 0.0066\n",
      "Epoch 96/200, Iteration 96/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 97/250, Loss: 0.0202\n",
      "Epoch 96/200, Iteration 98/250, Loss: 0.0301\n",
      "Epoch 96/200, Iteration 99/250, Loss: 0.0121\n",
      "Epoch 96/200, Iteration 100/250, Loss: 0.0066\n",
      "Epoch 96/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 96/200, Iteration 102/250, Loss: 0.0149\n",
      "Epoch 96/200, Iteration 103/250, Loss: 0.0139\n",
      "Epoch 96/200, Iteration 104/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 105/250, Loss: 0.0148\n",
      "Epoch 96/200, Iteration 106/250, Loss: 0.0342\n",
      "Epoch 96/200, Iteration 107/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 108/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 109/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 110/250, Loss: 0.0132\n",
      "Epoch 96/200, Iteration 111/250, Loss: 0.0064\n",
      "Epoch 96/200, Iteration 112/250, Loss: 0.0114\n",
      "Epoch 96/200, Iteration 113/250, Loss: 0.0111\n",
      "Epoch 96/200, Iteration 114/250, Loss: 0.0185\n",
      "Epoch 96/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 116/250, Loss: 0.0164\n",
      "Epoch 96/200, Iteration 117/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 118/250, Loss: 0.0075\n",
      "Epoch 96/200, Iteration 119/250, Loss: 0.0127\n",
      "Epoch 96/200, Iteration 120/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 121/250, Loss: 0.0133\n",
      "Epoch 96/200, Iteration 122/250, Loss: 0.0166\n",
      "Epoch 96/200, Iteration 123/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 124/250, Loss: 0.0247\n",
      "Epoch 96/200, Iteration 125/250, Loss: 0.0194\n",
      "Epoch 96/200, Iteration 126/250, Loss: 0.0252\n",
      "Epoch 96/200, Iteration 127/250, Loss: 0.0071\n",
      "Epoch 96/200, Iteration 128/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 96/200, Iteration 130/250, Loss: 0.0144\n",
      "Epoch 96/200, Iteration 131/250, Loss: 0.0203\n",
      "Epoch 96/200, Iteration 132/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 133/250, Loss: 0.0119\n",
      "Epoch 96/200, Iteration 134/250, Loss: 0.0141\n",
      "Epoch 96/200, Iteration 135/250, Loss: 0.0222\n",
      "Epoch 96/200, Iteration 136/250, Loss: 0.0260\n",
      "Epoch 96/200, Iteration 137/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 138/250, Loss: 0.0158\n",
      "Epoch 96/200, Iteration 139/250, Loss: 0.0310\n",
      "Epoch 96/200, Iteration 140/250, Loss: 0.0345\n",
      "Epoch 96/200, Iteration 141/250, Loss: 0.0144\n",
      "Epoch 96/200, Iteration 142/250, Loss: 0.0198\n",
      "Epoch 96/200, Iteration 143/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 145/250, Loss: 0.0123\n",
      "Epoch 96/200, Iteration 146/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 147/250, Loss: 0.0131\n",
      "Epoch 96/200, Iteration 148/250, Loss: 0.0142\n",
      "Epoch 96/200, Iteration 149/250, Loss: 0.0145\n",
      "Epoch 96/200, Iteration 150/250, Loss: 0.0306\n",
      "Epoch 96/200, Iteration 151/250, Loss: 0.0115\n",
      "Epoch 96/200, Iteration 152/250, Loss: 0.0185\n",
      "Epoch 96/200, Iteration 153/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 154/250, Loss: 0.0077\n",
      "Epoch 96/200, Iteration 155/250, Loss: 0.0244\n",
      "Epoch 96/200, Iteration 156/250, Loss: 0.0127\n",
      "Epoch 96/200, Iteration 157/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 158/250, Loss: 0.0195\n",
      "Epoch 96/200, Iteration 159/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 160/250, Loss: 0.0156\n",
      "Epoch 96/200, Iteration 161/250, Loss: 0.0111\n",
      "Epoch 96/200, Iteration 162/250, Loss: 0.0074\n",
      "Epoch 96/200, Iteration 163/250, Loss: 0.0233\n",
      "Epoch 96/200, Iteration 164/250, Loss: 0.0253\n",
      "Epoch 96/200, Iteration 165/250, Loss: 0.0248\n",
      "Epoch 96/200, Iteration 166/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 167/250, Loss: 0.0147\n",
      "Epoch 96/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 169/250, Loss: 0.0125\n",
      "Epoch 96/200, Iteration 170/250, Loss: 0.0056\n",
      "Epoch 96/200, Iteration 171/250, Loss: 0.0160\n",
      "Epoch 96/200, Iteration 172/250, Loss: 0.0210\n",
      "Epoch 96/200, Iteration 173/250, Loss: 0.0194\n",
      "Epoch 96/200, Iteration 174/250, Loss: 0.0179\n",
      "Epoch 96/200, Iteration 175/250, Loss: 0.0237\n",
      "Epoch 96/200, Iteration 176/250, Loss: 0.0251\n",
      "Epoch 96/200, Iteration 177/250, Loss: 0.0085\n",
      "Epoch 96/200, Iteration 178/250, Loss: 0.0250\n",
      "Epoch 96/200, Iteration 179/250, Loss: 0.0089\n",
      "Epoch 96/200, Iteration 180/250, Loss: 0.0124\n",
      "Epoch 96/200, Iteration 181/250, Loss: 0.0133\n",
      "Epoch 96/200, Iteration 182/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 183/250, Loss: 0.0335\n",
      "Epoch 96/200, Iteration 184/250, Loss: 0.0120\n",
      "Epoch 96/200, Iteration 185/250, Loss: 0.0097\n",
      "Epoch 96/200, Iteration 186/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 187/250, Loss: 0.0094\n",
      "Epoch 96/200, Iteration 188/250, Loss: 0.0075\n",
      "Epoch 96/200, Iteration 189/250, Loss: 0.0347\n",
      "Epoch 96/200, Iteration 190/250, Loss: 0.0143\n",
      "Epoch 96/200, Iteration 191/250, Loss: 0.0152\n",
      "Epoch 96/200, Iteration 192/250, Loss: 0.0169\n",
      "Epoch 96/200, Iteration 193/250, Loss: 0.0120\n",
      "Epoch 96/200, Iteration 194/250, Loss: 0.0372\n",
      "Epoch 96/200, Iteration 195/250, Loss: 0.0103\n",
      "Epoch 96/200, Iteration 196/250, Loss: 0.0111\n",
      "Epoch 96/200, Iteration 197/250, Loss: 0.0166\n",
      "Epoch 96/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 96/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 96/200, Iteration 200/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 201/250, Loss: 0.0226\n",
      "Epoch 96/200, Iteration 202/250, Loss: 0.0219\n",
      "Epoch 96/200, Iteration 203/250, Loss: 0.0087\n",
      "Epoch 96/200, Iteration 204/250, Loss: 0.0092\n",
      "Epoch 96/200, Iteration 205/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 206/250, Loss: 0.0126\n",
      "Epoch 96/200, Iteration 207/250, Loss: 0.0140\n",
      "Epoch 96/200, Iteration 208/250, Loss: 0.0089\n",
      "Epoch 96/200, Iteration 209/250, Loss: 0.0201\n",
      "Epoch 96/200, Iteration 210/250, Loss: 0.0062\n",
      "Epoch 96/200, Iteration 211/250, Loss: 0.0061\n",
      "Epoch 96/200, Iteration 212/250, Loss: 0.0194\n",
      "Epoch 96/200, Iteration 213/250, Loss: 0.0157\n",
      "Epoch 96/200, Iteration 214/250, Loss: 0.0303\n",
      "Epoch 96/200, Iteration 215/250, Loss: 0.0099\n",
      "Epoch 96/200, Iteration 216/250, Loss: 0.0146\n",
      "Epoch 96/200, Iteration 217/250, Loss: 0.0068\n",
      "Epoch 96/200, Iteration 218/250, Loss: 0.0166\n",
      "Epoch 96/200, Iteration 219/250, Loss: 0.0231\n",
      "Epoch 96/200, Iteration 220/250, Loss: 0.0107\n",
      "Epoch 96/200, Iteration 221/250, Loss: 0.0232\n",
      "Epoch 96/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 96/200, Iteration 223/250, Loss: 0.0137\n",
      "Epoch 96/200, Iteration 224/250, Loss: 0.0093\n",
      "Epoch 96/200, Iteration 225/250, Loss: 0.0216\n",
      "Epoch 96/200, Iteration 226/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 227/250, Loss: 0.0216\n",
      "Epoch 96/200, Iteration 228/250, Loss: 0.0155\n",
      "Epoch 96/200, Iteration 229/250, Loss: 0.0160\n",
      "Epoch 96/200, Iteration 230/250, Loss: 0.0105\n",
      "Epoch 96/200, Iteration 231/250, Loss: 0.0186\n",
      "Epoch 96/200, Iteration 232/250, Loss: 0.0194\n",
      "Epoch 96/200, Iteration 233/250, Loss: 0.0206\n",
      "Epoch 96/200, Iteration 234/250, Loss: 0.0160\n",
      "Epoch 96/200, Iteration 235/250, Loss: 0.0086\n",
      "Epoch 96/200, Iteration 236/250, Loss: 0.0096\n",
      "Epoch 96/200, Iteration 237/250, Loss: 0.0247\n",
      "Epoch 96/200, Iteration 238/250, Loss: 0.0110\n",
      "Epoch 96/200, Iteration 239/250, Loss: 0.0265\n",
      "Epoch 96/200, Iteration 240/250, Loss: 0.0283\n",
      "Epoch 96/200, Iteration 241/250, Loss: 0.0135\n",
      "Epoch 96/200, Iteration 242/250, Loss: 0.0108\n",
      "Epoch 96/200, Iteration 243/250, Loss: 0.0087\n",
      "Epoch 96/200, Iteration 244/250, Loss: 0.0138\n",
      "Epoch 96/200, Iteration 245/250, Loss: 0.0249\n",
      "Epoch 96/200, Iteration 246/250, Loss: 0.0265\n",
      "Epoch 96/200, Iteration 247/250, Loss: 0.0147\n",
      "Epoch 96/200, Iteration 248/250, Loss: 0.0104\n",
      "Epoch 96/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 96/200, Iteration 250/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 88.48%, Avg loss: 0.006651, MRE: 0.424766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.007204, MRE: 0.559786 \n",
      "\n",
      "Epoch 97/200, Iteration 1/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 2/250, Loss: 0.0225\n",
      "Epoch 97/200, Iteration 3/250, Loss: 0.0240\n",
      "Epoch 97/200, Iteration 4/250, Loss: 0.0332\n",
      "Epoch 97/200, Iteration 5/250, Loss: 0.0319\n",
      "Epoch 97/200, Iteration 6/250, Loss: 0.0074\n",
      "Epoch 97/200, Iteration 7/250, Loss: 0.0132\n",
      "Epoch 97/200, Iteration 8/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 9/250, Loss: 0.0186\n",
      "Epoch 97/200, Iteration 10/250, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 11/250, Loss: 0.0319\n",
      "Epoch 97/200, Iteration 12/250, Loss: 0.0214\n",
      "Epoch 97/200, Iteration 13/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 14/250, Loss: 0.0264\n",
      "Epoch 97/200, Iteration 15/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 16/250, Loss: 0.0154\n",
      "Epoch 97/200, Iteration 17/250, Loss: 0.0083\n",
      "Epoch 97/200, Iteration 18/250, Loss: 0.0347\n",
      "Epoch 97/200, Iteration 19/250, Loss: 0.0104\n",
      "Epoch 97/200, Iteration 20/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 21/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 22/250, Loss: 0.0134\n",
      "Epoch 97/200, Iteration 23/250, Loss: 0.0144\n",
      "Epoch 97/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 97/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 97/200, Iteration 26/250, Loss: 0.0095\n",
      "Epoch 97/200, Iteration 27/250, Loss: 0.0090\n",
      "Epoch 97/200, Iteration 28/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 29/250, Loss: 0.0102\n",
      "Epoch 97/200, Iteration 30/250, Loss: 0.0187\n",
      "Epoch 97/200, Iteration 31/250, Loss: 0.0165\n",
      "Epoch 97/200, Iteration 32/250, Loss: 0.0116\n",
      "Epoch 97/200, Iteration 33/250, Loss: 0.0231\n",
      "Epoch 97/200, Iteration 34/250, Loss: 0.0428\n",
      "Epoch 97/200, Iteration 35/250, Loss: 0.0133\n",
      "Epoch 97/200, Iteration 36/250, Loss: 0.0303\n",
      "Epoch 97/200, Iteration 37/250, Loss: 0.0088\n",
      "Epoch 97/200, Iteration 38/250, Loss: 0.0222\n",
      "Epoch 97/200, Iteration 39/250, Loss: 0.0198\n",
      "Epoch 97/200, Iteration 40/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 41/250, Loss: 0.0220\n",
      "Epoch 97/200, Iteration 42/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 97/200, Iteration 44/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 45/250, Loss: 0.0130\n",
      "Epoch 97/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 97/200, Iteration 47/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 48/250, Loss: 0.0162\n",
      "Epoch 97/200, Iteration 49/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 50/250, Loss: 0.0139\n",
      "Epoch 97/200, Iteration 51/250, Loss: 0.0333\n",
      "Epoch 97/200, Iteration 52/250, Loss: 0.0098\n",
      "Epoch 97/200, Iteration 53/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 54/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 55/250, Loss: 0.0117\n",
      "Epoch 97/200, Iteration 56/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 57/250, Loss: 0.0349\n",
      "Epoch 97/200, Iteration 58/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 59/250, Loss: 0.0081\n",
      "Epoch 97/200, Iteration 60/250, Loss: 0.0142\n",
      "Epoch 97/200, Iteration 61/250, Loss: 0.0262\n",
      "Epoch 97/200, Iteration 62/250, Loss: 0.0067\n",
      "Epoch 97/200, Iteration 63/250, Loss: 0.0119\n",
      "Epoch 97/200, Iteration 64/250, Loss: 0.0183\n",
      "Epoch 97/200, Iteration 65/250, Loss: 0.0169\n",
      "Epoch 97/200, Iteration 66/250, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 67/250, Loss: 0.0276\n",
      "Epoch 97/200, Iteration 68/250, Loss: 0.0157\n",
      "Epoch 97/200, Iteration 69/250, Loss: 0.0156\n",
      "Epoch 97/200, Iteration 70/250, Loss: 0.0181\n",
      "Epoch 97/200, Iteration 71/250, Loss: 0.0077\n",
      "Epoch 97/200, Iteration 72/250, Loss: 0.0226\n",
      "Epoch 97/200, Iteration 73/250, Loss: 0.0310\n",
      "Epoch 97/200, Iteration 74/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 75/250, Loss: 0.0281\n",
      "Epoch 97/200, Iteration 76/250, Loss: 0.0164\n",
      "Epoch 97/200, Iteration 77/250, Loss: 0.0381\n",
      "Epoch 97/200, Iteration 78/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 79/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 80/250, Loss: 0.0232\n",
      "Epoch 97/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 82/250, Loss: 0.0072\n",
      "Epoch 97/200, Iteration 83/250, Loss: 0.0159\n",
      "Epoch 97/200, Iteration 84/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 85/250, Loss: 0.0205\n",
      "Epoch 97/200, Iteration 86/250, Loss: 0.0292\n",
      "Epoch 97/200, Iteration 87/250, Loss: 0.0121\n",
      "Epoch 97/200, Iteration 88/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 89/250, Loss: 0.0297\n",
      "Epoch 97/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 97/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 97/200, Iteration 92/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 93/250, Loss: 0.0121\n",
      "Epoch 97/200, Iteration 94/250, Loss: 0.0158\n",
      "Epoch 97/200, Iteration 95/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 96/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 97/250, Loss: 0.0110\n",
      "Epoch 97/200, Iteration 98/250, Loss: 0.0173\n",
      "Epoch 97/200, Iteration 99/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 100/250, Loss: 0.0154\n",
      "Epoch 97/200, Iteration 101/250, Loss: 0.0111\n",
      "Epoch 97/200, Iteration 102/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 97/200, Iteration 104/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 105/250, Loss: 0.0141\n",
      "Epoch 97/200, Iteration 106/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 107/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 108/250, Loss: 0.0082\n",
      "Epoch 97/200, Iteration 109/250, Loss: 0.0129\n",
      "Epoch 97/200, Iteration 110/250, Loss: 0.0386\n",
      "Epoch 97/200, Iteration 111/250, Loss: 0.0103\n",
      "Epoch 97/200, Iteration 112/250, Loss: 0.0134\n",
      "Epoch 97/200, Iteration 113/250, Loss: 0.0100\n",
      "Epoch 97/200, Iteration 114/250, Loss: 0.0235\n",
      "Epoch 97/200, Iteration 115/250, Loss: 0.0177\n",
      "Epoch 97/200, Iteration 116/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 117/250, Loss: 0.0187\n",
      "Epoch 97/200, Iteration 118/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 119/250, Loss: 0.0128\n",
      "Epoch 97/200, Iteration 120/250, Loss: 0.0237\n",
      "Epoch 97/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 122/250, Loss: 0.0377\n",
      "Epoch 97/200, Iteration 123/250, Loss: 0.0100\n",
      "Epoch 97/200, Iteration 124/250, Loss: 0.0109\n",
      "Epoch 97/200, Iteration 125/250, Loss: 0.0144\n",
      "Epoch 97/200, Iteration 126/250, Loss: 0.0144\n",
      "Epoch 97/200, Iteration 127/250, Loss: 0.0084\n",
      "Epoch 97/200, Iteration 128/250, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 129/250, Loss: 0.0197\n",
      "Epoch 97/200, Iteration 130/250, Loss: 0.0230\n",
      "Epoch 97/200, Iteration 131/250, Loss: 0.0107\n",
      "Epoch 97/200, Iteration 132/250, Loss: 0.0078\n",
      "Epoch 97/200, Iteration 133/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 134/250, Loss: 0.0110\n",
      "Epoch 97/200, Iteration 135/250, Loss: 0.0323\n",
      "Epoch 97/200, Iteration 136/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 137/250, Loss: 0.0457\n",
      "Epoch 97/200, Iteration 138/250, Loss: 0.0338\n",
      "Epoch 97/200, Iteration 139/250, Loss: 0.0153\n",
      "Epoch 97/200, Iteration 140/250, Loss: 0.0080\n",
      "Epoch 97/200, Iteration 141/250, Loss: 0.0287\n",
      "Epoch 97/200, Iteration 142/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 143/250, Loss: 0.0098\n",
      "Epoch 97/200, Iteration 144/250, Loss: 0.0129\n",
      "Epoch 97/200, Iteration 145/250, Loss: 0.0294\n",
      "Epoch 97/200, Iteration 146/250, Loss: 0.0105\n",
      "Epoch 97/200, Iteration 147/250, Loss: 0.0226\n",
      "Epoch 97/200, Iteration 148/250, Loss: 0.0076\n",
      "Epoch 97/200, Iteration 149/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 150/250, Loss: 0.0285\n",
      "Epoch 97/200, Iteration 151/250, Loss: 0.0261\n",
      "Epoch 97/200, Iteration 152/250, Loss: 0.0130\n",
      "Epoch 97/200, Iteration 153/250, Loss: 0.0204\n",
      "Epoch 97/200, Iteration 154/250, Loss: 0.0128\n",
      "Epoch 97/200, Iteration 155/250, Loss: 0.0078\n",
      "Epoch 97/200, Iteration 156/250, Loss: 0.0125\n",
      "Epoch 97/200, Iteration 157/250, Loss: 0.0123\n",
      "Epoch 97/200, Iteration 158/250, Loss: 0.0103\n",
      "Epoch 97/200, Iteration 159/250, Loss: 0.0267\n",
      "Epoch 97/200, Iteration 160/250, Loss: 0.0091\n",
      "Epoch 97/200, Iteration 161/250, Loss: 0.0199\n",
      "Epoch 97/200, Iteration 162/250, Loss: 0.0113\n",
      "Epoch 97/200, Iteration 163/250, Loss: 0.0277\n",
      "Epoch 97/200, Iteration 164/250, Loss: 0.0146\n",
      "Epoch 97/200, Iteration 165/250, Loss: 0.0096\n",
      "Epoch 97/200, Iteration 166/250, Loss: 0.0063\n",
      "Epoch 97/200, Iteration 167/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 168/250, Loss: 0.0144\n",
      "Epoch 97/200, Iteration 169/250, Loss: 0.0278\n",
      "Epoch 97/200, Iteration 170/250, Loss: 0.0182\n",
      "Epoch 97/200, Iteration 171/250, Loss: 0.0138\n",
      "Epoch 97/200, Iteration 172/250, Loss: 0.0162\n",
      "Epoch 97/200, Iteration 173/250, Loss: 0.0194\n",
      "Epoch 97/200, Iteration 174/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 175/250, Loss: 0.0317\n",
      "Epoch 97/200, Iteration 176/250, Loss: 0.0169\n",
      "Epoch 97/200, Iteration 177/250, Loss: 0.0188\n",
      "Epoch 97/200, Iteration 178/250, Loss: 0.0242\n",
      "Epoch 97/200, Iteration 179/250, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 180/250, Loss: 0.0075\n",
      "Epoch 97/200, Iteration 181/250, Loss: 0.0114\n",
      "Epoch 97/200, Iteration 182/250, Loss: 0.0162\n",
      "Epoch 97/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 97/200, Iteration 184/250, Loss: 0.0191\n",
      "Epoch 97/200, Iteration 185/250, Loss: 0.0073\n",
      "Epoch 97/200, Iteration 186/250, Loss: 0.0132\n",
      "Epoch 97/200, Iteration 187/250, Loss: 0.0097\n",
      "Epoch 97/200, Iteration 188/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 189/250, Loss: 0.0115\n",
      "Epoch 97/200, Iteration 190/250, Loss: 0.0206\n",
      "Epoch 97/200, Iteration 191/250, Loss: 0.0139\n",
      "Epoch 97/200, Iteration 192/250, Loss: 0.0238\n",
      "Epoch 97/200, Iteration 193/250, Loss: 0.0171\n",
      "Epoch 97/200, Iteration 194/250, Loss: 0.0148\n",
      "Epoch 97/200, Iteration 195/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 97/200, Iteration 197/250, Loss: 0.0140\n",
      "Epoch 97/200, Iteration 198/250, Loss: 0.0085\n",
      "Epoch 97/200, Iteration 199/250, Loss: 0.0087\n",
      "Epoch 97/200, Iteration 200/250, Loss: 0.0161\n",
      "Epoch 97/200, Iteration 201/250, Loss: 0.0118\n",
      "Epoch 97/200, Iteration 202/250, Loss: 0.0230\n",
      "Epoch 97/200, Iteration 203/250, Loss: 0.0084\n",
      "Epoch 97/200, Iteration 204/250, Loss: 0.0276\n",
      "Epoch 97/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 97/200, Iteration 206/250, Loss: 0.0128\n",
      "Epoch 97/200, Iteration 207/250, Loss: 0.0149\n",
      "Epoch 97/200, Iteration 208/250, Loss: 0.0407\n",
      "Epoch 97/200, Iteration 209/250, Loss: 0.0146\n",
      "Epoch 97/200, Iteration 210/250, Loss: 0.0193\n",
      "Epoch 97/200, Iteration 211/250, Loss: 0.0171\n",
      "Epoch 97/200, Iteration 212/250, Loss: 0.0093\n",
      "Epoch 97/200, Iteration 213/250, Loss: 0.0093\n",
      "Epoch 97/200, Iteration 214/250, Loss: 0.0139\n",
      "Epoch 97/200, Iteration 215/250, Loss: 0.0364\n",
      "Epoch 97/200, Iteration 216/250, Loss: 0.0221\n",
      "Epoch 97/200, Iteration 217/250, Loss: 0.0238\n",
      "Epoch 97/200, Iteration 218/250, Loss: 0.0158\n",
      "Epoch 97/200, Iteration 219/250, Loss: 0.0166\n",
      "Epoch 97/200, Iteration 220/250, Loss: 0.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 97/200, Iteration 222/250, Loss: 0.0075\n",
      "Epoch 97/200, Iteration 223/250, Loss: 0.0090\n",
      "Epoch 97/200, Iteration 224/250, Loss: 0.0267\n",
      "Epoch 97/200, Iteration 225/250, Loss: 0.0094\n",
      "Epoch 97/200, Iteration 226/250, Loss: 0.0082\n",
      "Epoch 97/200, Iteration 227/250, Loss: 0.0458\n",
      "Epoch 97/200, Iteration 228/250, Loss: 0.0233\n",
      "Epoch 97/200, Iteration 229/250, Loss: 0.0159\n",
      "Epoch 97/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 97/200, Iteration 231/250, Loss: 0.0089\n",
      "Epoch 97/200, Iteration 232/250, Loss: 0.0256\n",
      "Epoch 97/200, Iteration 233/250, Loss: 0.0106\n",
      "Epoch 97/200, Iteration 234/250, Loss: 0.0170\n",
      "Epoch 97/200, Iteration 235/250, Loss: 0.0206\n",
      "Epoch 97/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 97/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 97/200, Iteration 238/250, Loss: 0.0124\n",
      "Epoch 97/200, Iteration 239/250, Loss: 0.0082\n",
      "Epoch 97/200, Iteration 240/250, Loss: 0.0239\n",
      "Epoch 97/200, Iteration 241/250, Loss: 0.0237\n",
      "Epoch 97/200, Iteration 242/250, Loss: 0.0086\n",
      "Epoch 97/200, Iteration 243/250, Loss: 0.0112\n",
      "Epoch 97/200, Iteration 244/250, Loss: 0.0215\n",
      "Epoch 97/200, Iteration 245/250, Loss: 0.0080\n",
      "Epoch 97/200, Iteration 246/250, Loss: 0.0102\n",
      "Epoch 97/200, Iteration 247/250, Loss: 0.0079\n",
      "Epoch 97/200, Iteration 248/250, Loss: 0.0122\n",
      "Epoch 97/200, Iteration 249/250, Loss: 0.0247\n",
      "Epoch 97/200, Iteration 250/250, Loss: 0.0161\n",
      "Train Error: \n",
      " Accuracy: 82.94%, Avg loss: 0.007046, MRE: 0.467780 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.007558, MRE: 0.614823 \n",
      "\n",
      "Epoch 98/200, Iteration 1/250, Loss: 0.0110\n",
      "Epoch 98/200, Iteration 2/250, Loss: 0.0096\n",
      "Epoch 98/200, Iteration 3/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 4/250, Loss: 0.0096\n",
      "Epoch 98/200, Iteration 5/250, Loss: 0.0045\n",
      "Epoch 98/200, Iteration 6/250, Loss: 0.0083\n",
      "Epoch 98/200, Iteration 7/250, Loss: 0.0123\n",
      "Epoch 98/200, Iteration 8/250, Loss: 0.0067\n",
      "Epoch 98/200, Iteration 9/250, Loss: 0.0317\n",
      "Epoch 98/200, Iteration 10/250, Loss: 0.0068\n",
      "Epoch 98/200, Iteration 11/250, Loss: 0.0196\n",
      "Epoch 98/200, Iteration 12/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 13/250, Loss: 0.0072\n",
      "Epoch 98/200, Iteration 14/250, Loss: 0.0312\n",
      "Epoch 98/200, Iteration 15/250, Loss: 0.0096\n",
      "Epoch 98/200, Iteration 16/250, Loss: 0.0181\n",
      "Epoch 98/200, Iteration 17/250, Loss: 0.0085\n",
      "Epoch 98/200, Iteration 18/250, Loss: 0.0104\n",
      "Epoch 98/200, Iteration 19/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 20/250, Loss: 0.0171\n",
      "Epoch 98/200, Iteration 21/250, Loss: 0.0149\n",
      "Epoch 98/200, Iteration 22/250, Loss: 0.0217\n",
      "Epoch 98/200, Iteration 23/250, Loss: 0.0304\n",
      "Epoch 98/200, Iteration 24/250, Loss: 0.0125\n",
      "Epoch 98/200, Iteration 25/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 26/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 27/250, Loss: 0.0141\n",
      "Epoch 98/200, Iteration 28/250, Loss: 0.0148\n",
      "Epoch 98/200, Iteration 29/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 30/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 31/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 32/250, Loss: 0.0192\n",
      "Epoch 98/200, Iteration 33/250, Loss: 0.0085\n",
      "Epoch 98/200, Iteration 34/250, Loss: 0.0106\n",
      "Epoch 98/200, Iteration 35/250, Loss: 0.0256\n",
      "Epoch 98/200, Iteration 36/250, Loss: 0.0093\n",
      "Epoch 98/200, Iteration 37/250, Loss: 0.0101\n",
      "Epoch 98/200, Iteration 38/250, Loss: 0.0327\n",
      "Epoch 98/200, Iteration 39/250, Loss: 0.0253\n",
      "Epoch 98/200, Iteration 40/250, Loss: 0.0172\n",
      "Epoch 98/200, Iteration 41/250, Loss: 0.0209\n",
      "Epoch 98/200, Iteration 42/250, Loss: 0.0267\n",
      "Epoch 98/200, Iteration 43/250, Loss: 0.0232\n",
      "Epoch 98/200, Iteration 44/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 98/200, Iteration 46/250, Loss: 0.0123\n",
      "Epoch 98/200, Iteration 47/250, Loss: 0.0139\n",
      "Epoch 98/200, Iteration 48/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 49/250, Loss: 0.0227\n",
      "Epoch 98/200, Iteration 50/250, Loss: 0.0203\n",
      "Epoch 98/200, Iteration 51/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 52/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 53/250, Loss: 0.0173\n",
      "Epoch 98/200, Iteration 54/250, Loss: 0.0155\n",
      "Epoch 98/200, Iteration 55/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 56/250, Loss: 0.0077\n",
      "Epoch 98/200, Iteration 57/250, Loss: 0.0158\n",
      "Epoch 98/200, Iteration 58/250, Loss: 0.0156\n",
      "Epoch 98/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 98/200, Iteration 60/250, Loss: 0.0120\n",
      "Epoch 98/200, Iteration 61/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 62/250, Loss: 0.0449\n",
      "Epoch 98/200, Iteration 63/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 65/250, Loss: 0.0117\n",
      "Epoch 98/200, Iteration 66/250, Loss: 0.0318\n",
      "Epoch 98/200, Iteration 67/250, Loss: 0.0311\n",
      "Epoch 98/200, Iteration 68/250, Loss: 0.0221\n",
      "Epoch 98/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 98/200, Iteration 70/250, Loss: 0.0076\n",
      "Epoch 98/200, Iteration 71/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 72/250, Loss: 0.0280\n",
      "Epoch 98/200, Iteration 73/250, Loss: 0.0071\n",
      "Epoch 98/200, Iteration 74/250, Loss: 0.0146\n",
      "Epoch 98/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 76/250, Loss: 0.0093\n",
      "Epoch 98/200, Iteration 77/250, Loss: 0.0212\n",
      "Epoch 98/200, Iteration 78/250, Loss: 0.0089\n",
      "Epoch 98/200, Iteration 79/250, Loss: 0.0133\n",
      "Epoch 98/200, Iteration 80/250, Loss: 0.0192\n",
      "Epoch 98/200, Iteration 81/250, Loss: 0.0187\n",
      "Epoch 98/200, Iteration 82/250, Loss: 0.0300\n",
      "Epoch 98/200, Iteration 83/250, Loss: 0.0077\n",
      "Epoch 98/200, Iteration 84/250, Loss: 0.0106\n",
      "Epoch 98/200, Iteration 85/250, Loss: 0.0231\n",
      "Epoch 98/200, Iteration 86/250, Loss: 0.0173\n",
      "Epoch 98/200, Iteration 87/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 88/250, Loss: 0.0342\n",
      "Epoch 98/200, Iteration 89/250, Loss: 0.0083\n",
      "Epoch 98/200, Iteration 90/250, Loss: 0.0106\n",
      "Epoch 98/200, Iteration 91/250, Loss: 0.0184\n",
      "Epoch 98/200, Iteration 92/250, Loss: 0.0232\n",
      "Epoch 98/200, Iteration 93/250, Loss: 0.0184\n",
      "Epoch 98/200, Iteration 94/250, Loss: 0.0106\n",
      "Epoch 98/200, Iteration 95/250, Loss: 0.0147\n",
      "Epoch 98/200, Iteration 96/250, Loss: 0.0140\n",
      "Epoch 98/200, Iteration 97/250, Loss: 0.0222\n",
      "Epoch 98/200, Iteration 98/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 99/250, Loss: 0.0104\n",
      "Epoch 98/200, Iteration 100/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 98/200, Iteration 102/250, Loss: 0.0231\n",
      "Epoch 98/200, Iteration 103/250, Loss: 0.0130\n",
      "Epoch 98/200, Iteration 104/250, Loss: 0.0069\n",
      "Epoch 98/200, Iteration 105/250, Loss: 0.0094\n",
      "Epoch 98/200, Iteration 106/250, Loss: 0.0171\n",
      "Epoch 98/200, Iteration 107/250, Loss: 0.0140\n",
      "Epoch 98/200, Iteration 108/250, Loss: 0.0180\n",
      "Epoch 98/200, Iteration 109/250, Loss: 0.0074\n",
      "Epoch 98/200, Iteration 110/250, Loss: 0.0163\n",
      "Epoch 98/200, Iteration 111/250, Loss: 0.0264\n",
      "Epoch 98/200, Iteration 112/250, Loss: 0.0256\n",
      "Epoch 98/200, Iteration 113/250, Loss: 0.0090\n",
      "Epoch 98/200, Iteration 114/250, Loss: 0.0108\n",
      "Epoch 98/200, Iteration 115/250, Loss: 0.0153\n",
      "Epoch 98/200, Iteration 116/250, Loss: 0.0151\n",
      "Epoch 98/200, Iteration 117/250, Loss: 0.0088\n",
      "Epoch 98/200, Iteration 118/250, Loss: 0.0304\n",
      "Epoch 98/200, Iteration 119/250, Loss: 0.0069\n",
      "Epoch 98/200, Iteration 120/250, Loss: 0.0092\n",
      "Epoch 98/200, Iteration 121/250, Loss: 0.0203\n",
      "Epoch 98/200, Iteration 122/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 123/250, Loss: 0.0140\n",
      "Epoch 98/200, Iteration 124/250, Loss: 0.0174\n",
      "Epoch 98/200, Iteration 125/250, Loss: 0.0105\n",
      "Epoch 98/200, Iteration 126/250, Loss: 0.0151\n",
      "Epoch 98/200, Iteration 127/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 128/250, Loss: 0.0302\n",
      "Epoch 98/200, Iteration 129/250, Loss: 0.0091\n",
      "Epoch 98/200, Iteration 130/250, Loss: 0.0158\n",
      "Epoch 98/200, Iteration 131/250, Loss: 0.0273\n",
      "Epoch 98/200, Iteration 132/250, Loss: 0.0117\n",
      "Epoch 98/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 134/250, Loss: 0.0133\n",
      "Epoch 98/200, Iteration 135/250, Loss: 0.0134\n",
      "Epoch 98/200, Iteration 136/250, Loss: 0.0141\n",
      "Epoch 98/200, Iteration 137/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 138/250, Loss: 0.0150\n",
      "Epoch 98/200, Iteration 139/250, Loss: 0.0170\n",
      "Epoch 98/200, Iteration 140/250, Loss: 0.0134\n",
      "Epoch 98/200, Iteration 141/250, Loss: 0.0076\n",
      "Epoch 98/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 98/200, Iteration 143/250, Loss: 0.0232\n",
      "Epoch 98/200, Iteration 144/250, Loss: 0.0153\n",
      "Epoch 98/200, Iteration 145/250, Loss: 0.0123\n",
      "Epoch 98/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 147/250, Loss: 0.0071\n",
      "Epoch 98/200, Iteration 148/250, Loss: 0.0101\n",
      "Epoch 98/200, Iteration 149/250, Loss: 0.0366\n",
      "Epoch 98/200, Iteration 150/250, Loss: 0.0102\n",
      "Epoch 98/200, Iteration 151/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 152/250, Loss: 0.0235\n",
      "Epoch 98/200, Iteration 153/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 154/250, Loss: 0.0150\n",
      "Epoch 98/200, Iteration 155/250, Loss: 0.0302\n",
      "Epoch 98/200, Iteration 156/250, Loss: 0.0094\n",
      "Epoch 98/200, Iteration 157/250, Loss: 0.0084\n",
      "Epoch 98/200, Iteration 158/250, Loss: 0.0131\n",
      "Epoch 98/200, Iteration 159/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 160/250, Loss: 0.0145\n",
      "Epoch 98/200, Iteration 161/250, Loss: 0.0197\n",
      "Epoch 98/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 98/200, Iteration 163/250, Loss: 0.0086\n",
      "Epoch 98/200, Iteration 164/250, Loss: 0.0115\n",
      "Epoch 98/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 166/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 167/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 168/250, Loss: 0.0085\n",
      "Epoch 98/200, Iteration 169/250, Loss: 0.0288\n",
      "Epoch 98/200, Iteration 170/250, Loss: 0.0157\n",
      "Epoch 98/200, Iteration 171/250, Loss: 0.0097\n",
      "Epoch 98/200, Iteration 172/250, Loss: 0.0099\n",
      "Epoch 98/200, Iteration 173/250, Loss: 0.0156\n",
      "Epoch 98/200, Iteration 174/250, Loss: 0.0123\n",
      "Epoch 98/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 98/200, Iteration 176/250, Loss: 0.0320\n",
      "Epoch 98/200, Iteration 177/250, Loss: 0.0246\n",
      "Epoch 98/200, Iteration 178/250, Loss: 0.0068\n",
      "Epoch 98/200, Iteration 179/250, Loss: 0.0286\n",
      "Epoch 98/200, Iteration 180/250, Loss: 0.0066\n",
      "Epoch 98/200, Iteration 181/250, Loss: 0.0107\n",
      "Epoch 98/200, Iteration 182/250, Loss: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200, Iteration 183/250, Loss: 0.0072\n",
      "Epoch 98/200, Iteration 184/250, Loss: 0.0117\n",
      "Epoch 98/200, Iteration 185/250, Loss: 0.0193\n",
      "Epoch 98/200, Iteration 186/250, Loss: 0.0186\n",
      "Epoch 98/200, Iteration 187/250, Loss: 0.0099\n",
      "Epoch 98/200, Iteration 188/250, Loss: 0.0198\n",
      "Epoch 98/200, Iteration 189/250, Loss: 0.0081\n",
      "Epoch 98/200, Iteration 190/250, Loss: 0.0075\n",
      "Epoch 98/200, Iteration 191/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 192/250, Loss: 0.0173\n",
      "Epoch 98/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 194/250, Loss: 0.0206\n",
      "Epoch 98/200, Iteration 195/250, Loss: 0.0087\n",
      "Epoch 98/200, Iteration 196/250, Loss: 0.0110\n",
      "Epoch 98/200, Iteration 197/250, Loss: 0.0278\n",
      "Epoch 98/200, Iteration 198/250, Loss: 0.0149\n",
      "Epoch 98/200, Iteration 199/250, Loss: 0.0194\n",
      "Epoch 98/200, Iteration 200/250, Loss: 0.0136\n",
      "Epoch 98/200, Iteration 201/250, Loss: 0.0118\n",
      "Epoch 98/200, Iteration 202/250, Loss: 0.0138\n",
      "Epoch 98/200, Iteration 203/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 204/250, Loss: 0.0109\n",
      "Epoch 98/200, Iteration 205/250, Loss: 0.0254\n",
      "Epoch 98/200, Iteration 206/250, Loss: 0.0289\n",
      "Epoch 98/200, Iteration 207/250, Loss: 0.0079\n",
      "Epoch 98/200, Iteration 208/250, Loss: 0.0243\n",
      "Epoch 98/200, Iteration 209/250, Loss: 0.0152\n",
      "Epoch 98/200, Iteration 210/250, Loss: 0.0110\n",
      "Epoch 98/200, Iteration 211/250, Loss: 0.0281\n",
      "Epoch 98/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 98/200, Iteration 213/250, Loss: 0.0084\n",
      "Epoch 98/200, Iteration 214/250, Loss: 0.0261\n",
      "Epoch 98/200, Iteration 215/250, Loss: 0.0092\n",
      "Epoch 98/200, Iteration 216/250, Loss: 0.0241\n",
      "Epoch 98/200, Iteration 217/250, Loss: 0.0102\n",
      "Epoch 98/200, Iteration 218/250, Loss: 0.0077\n",
      "Epoch 98/200, Iteration 219/250, Loss: 0.0082\n",
      "Epoch 98/200, Iteration 220/250, Loss: 0.0194\n",
      "Epoch 98/200, Iteration 221/250, Loss: 0.0348\n",
      "Epoch 98/200, Iteration 222/250, Loss: 0.0095\n",
      "Epoch 98/200, Iteration 223/250, Loss: 0.0205\n",
      "Epoch 98/200, Iteration 224/250, Loss: 0.0158\n",
      "Epoch 98/200, Iteration 225/250, Loss: 0.0112\n",
      "Epoch 98/200, Iteration 226/250, Loss: 0.0141\n",
      "Epoch 98/200, Iteration 227/250, Loss: 0.0057\n",
      "Epoch 98/200, Iteration 228/250, Loss: 0.0148\n",
      "Epoch 98/200, Iteration 229/250, Loss: 0.0146\n",
      "Epoch 98/200, Iteration 230/250, Loss: 0.0120\n",
      "Epoch 98/200, Iteration 231/250, Loss: 0.0135\n",
      "Epoch 98/200, Iteration 232/250, Loss: 0.0146\n",
      "Epoch 98/200, Iteration 233/250, Loss: 0.0121\n",
      "Epoch 98/200, Iteration 234/250, Loss: 0.0076\n",
      "Epoch 98/200, Iteration 235/250, Loss: 0.0072\n",
      "Epoch 98/200, Iteration 236/250, Loss: 0.0253\n",
      "Epoch 98/200, Iteration 237/250, Loss: 0.0245\n",
      "Epoch 98/200, Iteration 238/250, Loss: 0.0132\n",
      "Epoch 98/200, Iteration 239/250, Loss: 0.0092\n",
      "Epoch 98/200, Iteration 240/250, Loss: 0.0098\n",
      "Epoch 98/200, Iteration 241/250, Loss: 0.0119\n",
      "Epoch 98/200, Iteration 242/250, Loss: 0.0278\n",
      "Epoch 98/200, Iteration 243/250, Loss: 0.0169\n",
      "Epoch 98/200, Iteration 244/250, Loss: 0.0180\n",
      "Epoch 98/200, Iteration 245/250, Loss: 0.0176\n",
      "Epoch 98/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 98/200, Iteration 247/250, Loss: 0.0129\n",
      "Epoch 98/200, Iteration 248/250, Loss: 0.0353\n",
      "Epoch 98/200, Iteration 249/250, Loss: 0.0131\n",
      "Epoch 98/200, Iteration 250/250, Loss: 0.0261\n",
      "Train Error: \n",
      " Accuracy: 86.45%, Avg loss: 0.006875, MRE: 0.486609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.65%, Avg loss: 0.007422, MRE: 0.507398 \n",
      "\n",
      "Epoch 99/200, Iteration 1/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 2/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 3/250, Loss: 0.0173\n",
      "Epoch 99/200, Iteration 4/250, Loss: 0.0145\n",
      "Epoch 99/200, Iteration 5/250, Loss: 0.0331\n",
      "Epoch 99/200, Iteration 6/250, Loss: 0.0200\n",
      "Epoch 99/200, Iteration 7/250, Loss: 0.0121\n",
      "Epoch 99/200, Iteration 8/250, Loss: 0.0227\n",
      "Epoch 99/200, Iteration 9/250, Loss: 0.0108\n",
      "Epoch 99/200, Iteration 10/250, Loss: 0.0156\n",
      "Epoch 99/200, Iteration 11/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 12/250, Loss: 0.0084\n",
      "Epoch 99/200, Iteration 13/250, Loss: 0.0166\n",
      "Epoch 99/200, Iteration 14/250, Loss: 0.0183\n",
      "Epoch 99/200, Iteration 15/250, Loss: 0.0193\n",
      "Epoch 99/200, Iteration 16/250, Loss: 0.0309\n",
      "Epoch 99/200, Iteration 17/250, Loss: 0.0416\n",
      "Epoch 99/200, Iteration 18/250, Loss: 0.0070\n",
      "Epoch 99/200, Iteration 19/250, Loss: 0.0060\n",
      "Epoch 99/200, Iteration 20/250, Loss: 0.0427\n",
      "Epoch 99/200, Iteration 21/250, Loss: 0.0082\n",
      "Epoch 99/200, Iteration 22/250, Loss: 0.0130\n",
      "Epoch 99/200, Iteration 23/250, Loss: 0.0189\n",
      "Epoch 99/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 99/200, Iteration 25/250, Loss: 0.0114\n",
      "Epoch 99/200, Iteration 26/250, Loss: 0.0291\n",
      "Epoch 99/200, Iteration 27/250, Loss: 0.0230\n",
      "Epoch 99/200, Iteration 28/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 29/250, Loss: 0.0068\n",
      "Epoch 99/200, Iteration 30/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 99/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 99/200, Iteration 33/250, Loss: 0.0281\n",
      "Epoch 99/200, Iteration 34/250, Loss: 0.0130\n",
      "Epoch 99/200, Iteration 35/250, Loss: 0.0178\n",
      "Epoch 99/200, Iteration 36/250, Loss: 0.0075\n",
      "Epoch 99/200, Iteration 37/250, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 38/250, Loss: 0.0113\n",
      "Epoch 99/200, Iteration 39/250, Loss: 0.0217\n",
      "Epoch 99/200, Iteration 40/250, Loss: 0.0418\n",
      "Epoch 99/200, Iteration 41/250, Loss: 0.0220\n",
      "Epoch 99/200, Iteration 42/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 43/250, Loss: 0.0119\n",
      "Epoch 99/200, Iteration 44/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 45/250, Loss: 0.0213\n",
      "Epoch 99/200, Iteration 46/250, Loss: 0.0087\n",
      "Epoch 99/200, Iteration 47/250, Loss: 0.0097\n",
      "Epoch 99/200, Iteration 48/250, Loss: 0.0289\n",
      "Epoch 99/200, Iteration 49/250, Loss: 0.0117\n",
      "Epoch 99/200, Iteration 50/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 51/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 99/200, Iteration 53/250, Loss: 0.0116\n",
      "Epoch 99/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 99/200, Iteration 55/250, Loss: 0.0231\n",
      "Epoch 99/200, Iteration 56/250, Loss: 0.0086\n",
      "Epoch 99/200, Iteration 57/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 58/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 59/250, Loss: 0.0094\n",
      "Epoch 99/200, Iteration 60/250, Loss: 0.0101\n",
      "Epoch 99/200, Iteration 61/250, Loss: 0.0159\n",
      "Epoch 99/200, Iteration 62/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 63/250, Loss: 0.0192\n",
      "Epoch 99/200, Iteration 64/250, Loss: 0.0298\n",
      "Epoch 99/200, Iteration 65/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 66/250, Loss: 0.0110\n",
      "Epoch 99/200, Iteration 67/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 99/200, Iteration 69/250, Loss: 0.0096\n",
      "Epoch 99/200, Iteration 70/250, Loss: 0.0078\n",
      "Epoch 99/200, Iteration 71/250, Loss: 0.0109\n",
      "Epoch 99/200, Iteration 72/250, Loss: 0.0332\n",
      "Epoch 99/200, Iteration 73/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 99/200, Iteration 75/250, Loss: 0.0127\n",
      "Epoch 99/200, Iteration 76/250, Loss: 0.0279\n",
      "Epoch 99/200, Iteration 77/250, Loss: 0.0084\n",
      "Epoch 99/200, Iteration 78/250, Loss: 0.0175\n",
      "Epoch 99/200, Iteration 79/250, Loss: 0.0162\n",
      "Epoch 99/200, Iteration 80/250, Loss: 0.0157\n",
      "Epoch 99/200, Iteration 81/250, Loss: 0.0207\n",
      "Epoch 99/200, Iteration 82/250, Loss: 0.0124\n",
      "Epoch 99/200, Iteration 83/250, Loss: 0.0219\n",
      "Epoch 99/200, Iteration 84/250, Loss: 0.0142\n",
      "Epoch 99/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 86/250, Loss: 0.0148\n",
      "Epoch 99/200, Iteration 87/250, Loss: 0.0154\n",
      "Epoch 99/200, Iteration 88/250, Loss: 0.0259\n",
      "Epoch 99/200, Iteration 89/250, Loss: 0.0220\n",
      "Epoch 99/200, Iteration 90/250, Loss: 0.0115\n",
      "Epoch 99/200, Iteration 91/250, Loss: 0.0088\n",
      "Epoch 99/200, Iteration 92/250, Loss: 0.0123\n",
      "Epoch 99/200, Iteration 93/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 99/200, Iteration 95/250, Loss: 0.0225\n",
      "Epoch 99/200, Iteration 96/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 97/250, Loss: 0.0161\n",
      "Epoch 99/200, Iteration 98/250, Loss: 0.0222\n",
      "Epoch 99/200, Iteration 99/250, Loss: 0.0174\n",
      "Epoch 99/200, Iteration 100/250, Loss: 0.0168\n",
      "Epoch 99/200, Iteration 101/250, Loss: 0.0172\n",
      "Epoch 99/200, Iteration 102/250, Loss: 0.0142\n",
      "Epoch 99/200, Iteration 103/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 104/250, Loss: 0.0269\n",
      "Epoch 99/200, Iteration 105/250, Loss: 0.0313\n",
      "Epoch 99/200, Iteration 106/250, Loss: 0.0167\n",
      "Epoch 99/200, Iteration 107/250, Loss: 0.0160\n",
      "Epoch 99/200, Iteration 108/250, Loss: 0.0074\n",
      "Epoch 99/200, Iteration 109/250, Loss: 0.0084\n",
      "Epoch 99/200, Iteration 110/250, Loss: 0.0506\n",
      "Epoch 99/200, Iteration 111/250, Loss: 0.0290\n",
      "Epoch 99/200, Iteration 112/250, Loss: 0.0118\n",
      "Epoch 99/200, Iteration 113/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 114/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 115/250, Loss: 0.0142\n",
      "Epoch 99/200, Iteration 116/250, Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200, Iteration 117/250, Loss: 0.0146\n",
      "Epoch 99/200, Iteration 118/250, Loss: 0.0065\n",
      "Epoch 99/200, Iteration 119/250, Loss: 0.0162\n",
      "Epoch 99/200, Iteration 120/250, Loss: 0.0307\n",
      "Epoch 99/200, Iteration 121/250, Loss: 0.0139\n",
      "Epoch 99/200, Iteration 122/250, Loss: 0.0114\n",
      "Epoch 99/200, Iteration 123/250, Loss: 0.0128\n",
      "Epoch 99/200, Iteration 124/250, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 125/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 126/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 127/250, Loss: 0.0064\n",
      "Epoch 99/200, Iteration 128/250, Loss: 0.0149\n",
      "Epoch 99/200, Iteration 129/250, Loss: 0.0159\n",
      "Epoch 99/200, Iteration 130/250, Loss: 0.0089\n",
      "Epoch 99/200, Iteration 131/250, Loss: 0.0190\n",
      "Epoch 99/200, Iteration 132/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 133/250, Loss: 0.0223\n",
      "Epoch 99/200, Iteration 134/250, Loss: 0.0164\n",
      "Epoch 99/200, Iteration 135/250, Loss: 0.0171\n",
      "Epoch 99/200, Iteration 136/250, Loss: 0.0109\n",
      "Epoch 99/200, Iteration 137/250, Loss: 0.0342\n",
      "Epoch 99/200, Iteration 138/250, Loss: 0.0140\n",
      "Epoch 99/200, Iteration 139/250, Loss: 0.0134\n",
      "Epoch 99/200, Iteration 140/250, Loss: 0.0121\n",
      "Epoch 99/200, Iteration 141/250, Loss: 0.0127\n",
      "Epoch 99/200, Iteration 142/250, Loss: 0.0120\n",
      "Epoch 99/200, Iteration 143/250, Loss: 0.0198\n",
      "Epoch 99/200, Iteration 144/250, Loss: 0.0110\n",
      "Epoch 99/200, Iteration 145/250, Loss: 0.0227\n",
      "Epoch 99/200, Iteration 146/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 99/200, Iteration 148/250, Loss: 0.0099\n",
      "Epoch 99/200, Iteration 149/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 150/250, Loss: 0.0240\n",
      "Epoch 99/200, Iteration 151/250, Loss: 0.0150\n",
      "Epoch 99/200, Iteration 152/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 153/250, Loss: 0.0276\n",
      "Epoch 99/200, Iteration 154/250, Loss: 0.0150\n",
      "Epoch 99/200, Iteration 155/250, Loss: 0.0180\n",
      "Epoch 99/200, Iteration 156/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 157/250, Loss: 0.0201\n",
      "Epoch 99/200, Iteration 158/250, Loss: 0.0135\n",
      "Epoch 99/200, Iteration 159/250, Loss: 0.0100\n",
      "Epoch 99/200, Iteration 160/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 161/250, Loss: 0.0090\n",
      "Epoch 99/200, Iteration 162/250, Loss: 0.0210\n",
      "Epoch 99/200, Iteration 163/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 164/250, Loss: 0.0202\n",
      "Epoch 99/200, Iteration 165/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 166/250, Loss: 0.0220\n",
      "Epoch 99/200, Iteration 167/250, Loss: 0.0085\n",
      "Epoch 99/200, Iteration 168/250, Loss: 0.0182\n",
      "Epoch 99/200, Iteration 169/250, Loss: 0.0088\n",
      "Epoch 99/200, Iteration 170/250, Loss: 0.0096\n",
      "Epoch 99/200, Iteration 171/250, Loss: 0.0083\n",
      "Epoch 99/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 99/200, Iteration 173/250, Loss: 0.0212\n",
      "Epoch 99/200, Iteration 174/250, Loss: 0.0289\n",
      "Epoch 99/200, Iteration 175/250, Loss: 0.0068\n",
      "Epoch 99/200, Iteration 176/250, Loss: 0.0109\n",
      "Epoch 99/200, Iteration 177/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 178/250, Loss: 0.0298\n",
      "Epoch 99/200, Iteration 179/250, Loss: 0.0112\n",
      "Epoch 99/200, Iteration 180/250, Loss: 0.0289\n",
      "Epoch 99/200, Iteration 181/250, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 182/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 183/250, Loss: 0.0098\n",
      "Epoch 99/200, Iteration 184/250, Loss: 0.0107\n",
      "Epoch 99/200, Iteration 185/250, Loss: 0.0141\n",
      "Epoch 99/200, Iteration 186/250, Loss: 0.0185\n",
      "Epoch 99/200, Iteration 187/250, Loss: 0.0138\n",
      "Epoch 99/200, Iteration 188/250, Loss: 0.0238\n",
      "Epoch 99/200, Iteration 189/250, Loss: 0.0206\n",
      "Epoch 99/200, Iteration 190/250, Loss: 0.0083\n",
      "Epoch 99/200, Iteration 191/250, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 192/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 193/250, Loss: 0.0094\n",
      "Epoch 99/200, Iteration 194/250, Loss: 0.0201\n",
      "Epoch 99/200, Iteration 195/250, Loss: 0.0203\n",
      "Epoch 99/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 99/200, Iteration 197/250, Loss: 0.0256\n",
      "Epoch 99/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 99/200, Iteration 199/250, Loss: 0.0284\n",
      "Epoch 99/200, Iteration 200/250, Loss: 0.0145\n",
      "Epoch 99/200, Iteration 201/250, Loss: 0.0102\n",
      "Epoch 99/200, Iteration 202/250, Loss: 0.0100\n",
      "Epoch 99/200, Iteration 203/250, Loss: 0.0078\n",
      "Epoch 99/200, Iteration 204/250, Loss: 0.0086\n",
      "Epoch 99/200, Iteration 205/250, Loss: 0.0128\n",
      "Epoch 99/200, Iteration 206/250, Loss: 0.0284\n",
      "Epoch 99/200, Iteration 207/250, Loss: 0.0402\n",
      "Epoch 99/200, Iteration 208/250, Loss: 0.0126\n",
      "Epoch 99/200, Iteration 209/250, Loss: 0.0154\n",
      "Epoch 99/200, Iteration 210/250, Loss: 0.0118\n",
      "Epoch 99/200, Iteration 211/250, Loss: 0.0115\n",
      "Epoch 99/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 99/200, Iteration 213/250, Loss: 0.0082\n",
      "Epoch 99/200, Iteration 214/250, Loss: 0.0149\n",
      "Epoch 99/200, Iteration 215/250, Loss: 0.0174\n",
      "Epoch 99/200, Iteration 216/250, Loss: 0.0093\n",
      "Epoch 99/200, Iteration 217/250, Loss: 0.0153\n",
      "Epoch 99/200, Iteration 218/250, Loss: 0.0116\n",
      "Epoch 99/200, Iteration 219/250, Loss: 0.0360\n",
      "Epoch 99/200, Iteration 220/250, Loss: 0.0105\n",
      "Epoch 99/200, Iteration 221/250, Loss: 0.0212\n",
      "Epoch 99/200, Iteration 222/250, Loss: 0.0574\n",
      "Epoch 99/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 99/200, Iteration 224/250, Loss: 0.0134\n",
      "Epoch 99/200, Iteration 225/250, Loss: 0.0110\n",
      "Epoch 99/200, Iteration 226/250, Loss: 0.0170\n",
      "Epoch 99/200, Iteration 227/250, Loss: 0.0072\n",
      "Epoch 99/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 99/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 99/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 99/200, Iteration 231/250, Loss: 0.0172\n",
      "Epoch 99/200, Iteration 232/250, Loss: 0.0174\n",
      "Epoch 99/200, Iteration 233/250, Loss: 0.0168\n",
      "Epoch 99/200, Iteration 234/250, Loss: 0.0108\n",
      "Epoch 99/200, Iteration 235/250, Loss: 0.0141\n",
      "Epoch 99/200, Iteration 236/250, Loss: 0.0063\n",
      "Epoch 99/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 99/200, Iteration 238/250, Loss: 0.0111\n",
      "Epoch 99/200, Iteration 239/250, Loss: 0.0082\n",
      "Epoch 99/200, Iteration 240/250, Loss: 0.0353\n",
      "Epoch 99/200, Iteration 241/250, Loss: 0.0071\n",
      "Epoch 99/200, Iteration 242/250, Loss: 0.0218\n",
      "Epoch 99/200, Iteration 243/250, Loss: 0.0103\n",
      "Epoch 99/200, Iteration 244/250, Loss: 0.0204\n",
      "Epoch 99/200, Iteration 245/250, Loss: 0.0233\n",
      "Epoch 99/200, Iteration 246/250, Loss: 0.0201\n",
      "Epoch 99/200, Iteration 247/250, Loss: 0.0103\n",
      "Epoch 99/200, Iteration 248/250, Loss: 0.0225\n",
      "Epoch 99/200, Iteration 249/250, Loss: 0.0191\n",
      "Epoch 99/200, Iteration 250/250, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 91.95%, Avg loss: 0.007125, MRE: 0.466207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.007711, MRE: 0.513710 \n",
      "\n",
      "Epoch 100/200, Iteration 1/250, Loss: 0.0257\n",
      "Epoch 100/200, Iteration 2/250, Loss: 0.0171\n",
      "Epoch 100/200, Iteration 3/250, Loss: 0.0126\n",
      "Epoch 100/200, Iteration 4/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 5/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 6/250, Loss: 0.0332\n",
      "Epoch 100/200, Iteration 7/250, Loss: 0.0125\n",
      "Epoch 100/200, Iteration 8/250, Loss: 0.0179\n",
      "Epoch 100/200, Iteration 9/250, Loss: 0.0253\n",
      "Epoch 100/200, Iteration 10/250, Loss: 0.0205\n",
      "Epoch 100/200, Iteration 11/250, Loss: 0.0182\n",
      "Epoch 100/200, Iteration 12/250, Loss: 0.0146\n",
      "Epoch 100/200, Iteration 13/250, Loss: 0.0150\n",
      "Epoch 100/200, Iteration 14/250, Loss: 0.0158\n",
      "Epoch 100/200, Iteration 15/250, Loss: 0.0087\n",
      "Epoch 100/200, Iteration 16/250, Loss: 0.0140\n",
      "Epoch 100/200, Iteration 17/250, Loss: 0.0146\n",
      "Epoch 100/200, Iteration 18/250, Loss: 0.0129\n",
      "Epoch 100/200, Iteration 19/250, Loss: 0.0230\n",
      "Epoch 100/200, Iteration 20/250, Loss: 0.0127\n",
      "Epoch 100/200, Iteration 21/250, Loss: 0.0085\n",
      "Epoch 100/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 23/250, Loss: 0.0142\n",
      "Epoch 100/200, Iteration 24/250, Loss: 0.0148\n",
      "Epoch 100/200, Iteration 25/250, Loss: 0.0116\n",
      "Epoch 100/200, Iteration 26/250, Loss: 0.0213\n",
      "Epoch 100/200, Iteration 27/250, Loss: 0.0135\n",
      "Epoch 100/200, Iteration 28/250, Loss: 0.0142\n",
      "Epoch 100/200, Iteration 29/250, Loss: 0.0225\n",
      "Epoch 100/200, Iteration 30/250, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 31/250, Loss: 0.0106\n",
      "Epoch 100/200, Iteration 32/250, Loss: 0.0179\n",
      "Epoch 100/200, Iteration 33/250, Loss: 0.0315\n",
      "Epoch 100/200, Iteration 34/250, Loss: 0.0192\n",
      "Epoch 100/200, Iteration 35/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 36/250, Loss: 0.0281\n",
      "Epoch 100/200, Iteration 37/250, Loss: 0.0192\n",
      "Epoch 100/200, Iteration 38/250, Loss: 0.0184\n",
      "Epoch 100/200, Iteration 39/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 40/250, Loss: 0.0075\n",
      "Epoch 100/200, Iteration 41/250, Loss: 0.0187\n",
      "Epoch 100/200, Iteration 42/250, Loss: 0.0096\n",
      "Epoch 100/200, Iteration 43/250, Loss: 0.0071\n",
      "Epoch 100/200, Iteration 44/250, Loss: 0.0079\n",
      "Epoch 100/200, Iteration 45/250, Loss: 0.0112\n",
      "Epoch 100/200, Iteration 46/250, Loss: 0.0145\n",
      "Epoch 100/200, Iteration 47/250, Loss: 0.0136\n",
      "Epoch 100/200, Iteration 48/250, Loss: 0.0115\n",
      "Epoch 100/200, Iteration 49/250, Loss: 0.0155\n",
      "Epoch 100/200, Iteration 50/250, Loss: 0.0326\n",
      "Epoch 100/200, Iteration 51/250, Loss: 0.0101\n",
      "Epoch 100/200, Iteration 52/250, Loss: 0.0072\n",
      "Epoch 100/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 100/200, Iteration 54/250, Loss: 0.0160\n",
      "Epoch 100/200, Iteration 55/250, Loss: 0.0086\n",
      "Epoch 100/200, Iteration 56/250, Loss: 0.0372\n",
      "Epoch 100/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 58/250, Loss: 0.0096\n",
      "Epoch 100/200, Iteration 59/250, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 60/250, Loss: 0.0064\n",
      "Epoch 100/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 100/200, Iteration 62/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 63/250, Loss: 0.0071\n",
      "Epoch 100/200, Iteration 64/250, Loss: 0.0077\n",
      "Epoch 100/200, Iteration 65/250, Loss: 0.0221\n",
      "Epoch 100/200, Iteration 66/250, Loss: 0.0120\n",
      "Epoch 100/200, Iteration 67/250, Loss: 0.0198\n",
      "Epoch 100/200, Iteration 68/250, Loss: 0.0228\n",
      "Epoch 100/200, Iteration 69/250, Loss: 0.0115\n",
      "Epoch 100/200, Iteration 70/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 71/250, Loss: 0.0115\n",
      "Epoch 100/200, Iteration 72/250, Loss: 0.0122\n",
      "Epoch 100/200, Iteration 73/250, Loss: 0.0211\n",
      "Epoch 100/200, Iteration 74/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 75/250, Loss: 0.0251\n",
      "Epoch 100/200, Iteration 76/250, Loss: 0.0125\n",
      "Epoch 100/200, Iteration 77/250, Loss: 0.0067\n",
      "Epoch 100/200, Iteration 78/250, Loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200, Iteration 79/250, Loss: 0.0172\n",
      "Epoch 100/200, Iteration 80/250, Loss: 0.0186\n",
      "Epoch 100/200, Iteration 81/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 82/250, Loss: 0.0298\n",
      "Epoch 100/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 100/200, Iteration 84/250, Loss: 0.0115\n",
      "Epoch 100/200, Iteration 85/250, Loss: 0.0199\n",
      "Epoch 100/200, Iteration 86/250, Loss: 0.0101\n",
      "Epoch 100/200, Iteration 87/250, Loss: 0.0185\n",
      "Epoch 100/200, Iteration 88/250, Loss: 0.0241\n",
      "Epoch 100/200, Iteration 89/250, Loss: 0.0155\n",
      "Epoch 100/200, Iteration 90/250, Loss: 0.0078\n",
      "Epoch 100/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 92/250, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 93/250, Loss: 0.0073\n",
      "Epoch 100/200, Iteration 94/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 95/250, Loss: 0.0136\n",
      "Epoch 100/200, Iteration 96/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 97/250, Loss: 0.0231\n",
      "Epoch 100/200, Iteration 98/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 99/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 100/250, Loss: 0.0207\n",
      "Epoch 100/200, Iteration 101/250, Loss: 0.0147\n",
      "Epoch 100/200, Iteration 102/250, Loss: 0.0167\n",
      "Epoch 100/200, Iteration 103/250, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 104/250, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 105/250, Loss: 0.0175\n",
      "Epoch 100/200, Iteration 106/250, Loss: 0.0135\n",
      "Epoch 100/200, Iteration 107/250, Loss: 0.0380\n",
      "Epoch 100/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 109/250, Loss: 0.0192\n",
      "Epoch 100/200, Iteration 110/250, Loss: 0.0124\n",
      "Epoch 100/200, Iteration 111/250, Loss: 0.0074\n",
      "Epoch 100/200, Iteration 112/250, Loss: 0.0218\n",
      "Epoch 100/200, Iteration 113/250, Loss: 0.0223\n",
      "Epoch 100/200, Iteration 114/250, Loss: 0.0083\n",
      "Epoch 100/200, Iteration 115/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 116/250, Loss: 0.0119\n",
      "Epoch 100/200, Iteration 117/250, Loss: 0.0434\n",
      "Epoch 100/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 100/200, Iteration 119/250, Loss: 0.0256\n",
      "Epoch 100/200, Iteration 120/250, Loss: 0.0161\n",
      "Epoch 100/200, Iteration 121/250, Loss: 0.0286\n",
      "Epoch 100/200, Iteration 122/250, Loss: 0.0155\n",
      "Epoch 100/200, Iteration 123/250, Loss: 0.0063\n",
      "Epoch 100/200, Iteration 124/250, Loss: 0.0183\n",
      "Epoch 100/200, Iteration 125/250, Loss: 0.0461\n",
      "Epoch 100/200, Iteration 126/250, Loss: 0.0129\n",
      "Epoch 100/200, Iteration 127/250, Loss: 0.0253\n",
      "Epoch 100/200, Iteration 128/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 129/250, Loss: 0.0332\n",
      "Epoch 100/200, Iteration 130/250, Loss: 0.0140\n",
      "Epoch 100/200, Iteration 131/250, Loss: 0.0145\n",
      "Epoch 100/200, Iteration 132/250, Loss: 0.0074\n",
      "Epoch 100/200, Iteration 133/250, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 134/250, Loss: 0.0374\n",
      "Epoch 100/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 100/200, Iteration 136/250, Loss: 0.0156\n",
      "Epoch 100/200, Iteration 137/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 138/250, Loss: 0.0246\n",
      "Epoch 100/200, Iteration 139/250, Loss: 0.0170\n",
      "Epoch 100/200, Iteration 140/250, Loss: 0.0267\n",
      "Epoch 100/200, Iteration 141/250, Loss: 0.0110\n",
      "Epoch 100/200, Iteration 142/250, Loss: 0.0124\n",
      "Epoch 100/200, Iteration 143/250, Loss: 0.0172\n",
      "Epoch 100/200, Iteration 144/250, Loss: 0.0368\n",
      "Epoch 100/200, Iteration 145/250, Loss: 0.0345\n",
      "Epoch 100/200, Iteration 146/250, Loss: 0.0086\n",
      "Epoch 100/200, Iteration 147/250, Loss: 0.0110\n",
      "Epoch 100/200, Iteration 148/250, Loss: 0.0105\n",
      "Epoch 100/200, Iteration 149/250, Loss: 0.0169\n",
      "Epoch 100/200, Iteration 150/250, Loss: 0.0085\n",
      "Epoch 100/200, Iteration 151/250, Loss: 0.0301\n",
      "Epoch 100/200, Iteration 152/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 153/250, Loss: 0.0252\n",
      "Epoch 100/200, Iteration 154/250, Loss: 0.0187\n",
      "Epoch 100/200, Iteration 155/250, Loss: 0.0170\n",
      "Epoch 100/200, Iteration 156/250, Loss: 0.0148\n",
      "Epoch 100/200, Iteration 157/250, Loss: 0.0143\n",
      "Epoch 100/200, Iteration 158/250, Loss: 0.0184\n",
      "Epoch 100/200, Iteration 159/250, Loss: 0.0070\n",
      "Epoch 100/200, Iteration 160/250, Loss: 0.0231\n",
      "Epoch 100/200, Iteration 161/250, Loss: 0.0155\n",
      "Epoch 100/200, Iteration 162/250, Loss: 0.0206\n",
      "Epoch 100/200, Iteration 163/250, Loss: 0.0188\n",
      "Epoch 100/200, Iteration 164/250, Loss: 0.0161\n",
      "Epoch 100/200, Iteration 165/250, Loss: 0.0177\n",
      "Epoch 100/200, Iteration 166/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 167/250, Loss: 0.0180\n",
      "Epoch 100/200, Iteration 168/250, Loss: 0.0066\n",
      "Epoch 100/200, Iteration 169/250, Loss: 0.0228\n",
      "Epoch 100/200, Iteration 170/250, Loss: 0.0081\n",
      "Epoch 100/200, Iteration 171/250, Loss: 0.0105\n",
      "Epoch 100/200, Iteration 172/250, Loss: 0.0130\n",
      "Epoch 100/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 100/200, Iteration 174/250, Loss: 0.0174\n",
      "Epoch 100/200, Iteration 175/250, Loss: 0.0401\n",
      "Epoch 100/200, Iteration 176/250, Loss: 0.0221\n",
      "Epoch 100/200, Iteration 177/250, Loss: 0.0099\n",
      "Epoch 100/200, Iteration 178/250, Loss: 0.0111\n",
      "Epoch 100/200, Iteration 179/250, Loss: 0.0110\n",
      "Epoch 100/200, Iteration 180/250, Loss: 0.0097\n",
      "Epoch 100/200, Iteration 181/250, Loss: 0.0159\n",
      "Epoch 100/200, Iteration 182/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 183/250, Loss: 0.0277\n",
      "Epoch 100/200, Iteration 184/250, Loss: 0.0098\n",
      "Epoch 100/200, Iteration 185/250, Loss: 0.0087\n",
      "Epoch 100/200, Iteration 186/250, Loss: 0.0130\n",
      "Epoch 100/200, Iteration 187/250, Loss: 0.0117\n",
      "Epoch 100/200, Iteration 188/250, Loss: 0.0082\n",
      "Epoch 100/200, Iteration 189/250, Loss: 0.0284\n",
      "Epoch 100/200, Iteration 190/250, Loss: 0.0122\n",
      "Epoch 100/200, Iteration 191/250, Loss: 0.0126\n",
      "Epoch 100/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 193/250, Loss: 0.0285\n",
      "Epoch 100/200, Iteration 194/250, Loss: 0.0147\n",
      "Epoch 100/200, Iteration 195/250, Loss: 0.0132\n",
      "Epoch 100/200, Iteration 196/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 197/250, Loss: 0.0159\n",
      "Epoch 100/200, Iteration 198/250, Loss: 0.0160\n",
      "Epoch 100/200, Iteration 199/250, Loss: 0.0142\n",
      "Epoch 100/200, Iteration 200/250, Loss: 0.0097\n",
      "Epoch 100/200, Iteration 201/250, Loss: 0.0162\n",
      "Epoch 100/200, Iteration 202/250, Loss: 0.0183\n",
      "Epoch 100/200, Iteration 203/250, Loss: 0.0153\n",
      "Epoch 100/200, Iteration 204/250, Loss: 0.0110\n",
      "Epoch 100/200, Iteration 205/250, Loss: 0.0270\n",
      "Epoch 100/200, Iteration 206/250, Loss: 0.0112\n",
      "Epoch 100/200, Iteration 207/250, Loss: 0.0164\n",
      "Epoch 100/200, Iteration 208/250, Loss: 0.0140\n",
      "Epoch 100/200, Iteration 209/250, Loss: 0.0157\n",
      "Epoch 100/200, Iteration 210/250, Loss: 0.0076\n",
      "Epoch 100/200, Iteration 211/250, Loss: 0.0196\n",
      "Epoch 100/200, Iteration 212/250, Loss: 0.0072\n",
      "Epoch 100/200, Iteration 213/250, Loss: 0.0102\n",
      "Epoch 100/200, Iteration 214/250, Loss: 0.0094\n",
      "Epoch 100/200, Iteration 215/250, Loss: 0.0144\n",
      "Epoch 100/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 100/200, Iteration 217/250, Loss: 0.0107\n",
      "Epoch 100/200, Iteration 218/250, Loss: 0.0065\n",
      "Epoch 100/200, Iteration 219/250, Loss: 0.0076\n",
      "Epoch 100/200, Iteration 220/250, Loss: 0.0209\n",
      "Epoch 100/200, Iteration 221/250, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 222/250, Loss: 0.0135\n",
      "Epoch 100/200, Iteration 223/250, Loss: 0.0079\n",
      "Epoch 100/200, Iteration 224/250, Loss: 0.0183\n",
      "Epoch 100/200, Iteration 225/250, Loss: 0.0107\n",
      "Epoch 100/200, Iteration 226/250, Loss: 0.0096\n",
      "Epoch 100/200, Iteration 227/250, Loss: 0.0154\n",
      "Epoch 100/200, Iteration 228/250, Loss: 0.0131\n",
      "Epoch 100/200, Iteration 229/250, Loss: 0.0091\n",
      "Epoch 100/200, Iteration 230/250, Loss: 0.0141\n",
      "Epoch 100/200, Iteration 231/250, Loss: 0.0105\n",
      "Epoch 100/200, Iteration 232/250, Loss: 0.0325\n",
      "Epoch 100/200, Iteration 233/250, Loss: 0.0166\n",
      "Epoch 100/200, Iteration 234/250, Loss: 0.0094\n",
      "Epoch 100/200, Iteration 235/250, Loss: 0.0187\n",
      "Epoch 100/200, Iteration 236/250, Loss: 0.0209\n",
      "Epoch 100/200, Iteration 237/250, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 238/250, Loss: 0.0171\n",
      "Epoch 100/200, Iteration 239/250, Loss: 0.0103\n",
      "Epoch 100/200, Iteration 240/250, Loss: 0.0129\n",
      "Epoch 100/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 100/200, Iteration 242/250, Loss: 0.0148\n",
      "Epoch 100/200, Iteration 243/250, Loss: 0.0175\n",
      "Epoch 100/200, Iteration 244/250, Loss: 0.0227\n",
      "Epoch 100/200, Iteration 245/250, Loss: 0.0114\n",
      "Epoch 100/200, Iteration 246/250, Loss: 0.0286\n",
      "Epoch 100/200, Iteration 247/250, Loss: 0.0116\n",
      "Epoch 100/200, Iteration 248/250, Loss: 0.0222\n",
      "Epoch 100/200, Iteration 249/250, Loss: 0.0183\n",
      "Epoch 100/200, Iteration 250/250, Loss: 0.0186\n",
      "Train Error: \n",
      " Accuracy: 60.27%, Avg loss: 0.009829, MRE: 0.614658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.010253, MRE: 0.715378 \n",
      "\n",
      "Epoch 101/200, Iteration 1/250, Loss: 0.0473\n",
      "Epoch 101/200, Iteration 2/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 3/250, Loss: 0.0168\n",
      "Epoch 101/200, Iteration 4/250, Loss: 0.0190\n",
      "Epoch 101/200, Iteration 5/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 6/250, Loss: 0.0095\n",
      "Epoch 101/200, Iteration 7/250, Loss: 0.0231\n",
      "Epoch 101/200, Iteration 8/250, Loss: 0.0247\n",
      "Epoch 101/200, Iteration 9/250, Loss: 0.0173\n",
      "Epoch 101/200, Iteration 10/250, Loss: 0.0170\n",
      "Epoch 101/200, Iteration 11/250, Loss: 0.0167\n",
      "Epoch 101/200, Iteration 12/250, Loss: 0.0210\n",
      "Epoch 101/200, Iteration 13/250, Loss: 0.0071\n",
      "Epoch 101/200, Iteration 14/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 15/250, Loss: 0.0407\n",
      "Epoch 101/200, Iteration 16/250, Loss: 0.0223\n",
      "Epoch 101/200, Iteration 17/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 18/250, Loss: 0.0183\n",
      "Epoch 101/200, Iteration 19/250, Loss: 0.0234\n",
      "Epoch 101/200, Iteration 20/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200, Iteration 21/250, Loss: 0.0169\n",
      "Epoch 101/200, Iteration 22/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 23/250, Loss: 0.0063\n",
      "Epoch 101/200, Iteration 24/250, Loss: 0.0113\n",
      "Epoch 101/200, Iteration 25/250, Loss: 0.0319\n",
      "Epoch 101/200, Iteration 26/250, Loss: 0.0112\n",
      "Epoch 101/200, Iteration 27/250, Loss: 0.0322\n",
      "Epoch 101/200, Iteration 28/250, Loss: 0.0122\n",
      "Epoch 101/200, Iteration 29/250, Loss: 0.0232\n",
      "Epoch 101/200, Iteration 30/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 31/250, Loss: 0.0611\n",
      "Epoch 101/200, Iteration 32/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 33/250, Loss: 0.0195\n",
      "Epoch 101/200, Iteration 34/250, Loss: 0.0228\n",
      "Epoch 101/200, Iteration 35/250, Loss: 0.0105\n",
      "Epoch 101/200, Iteration 36/250, Loss: 0.0207\n",
      "Epoch 101/200, Iteration 37/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 38/250, Loss: 0.0209\n",
      "Epoch 101/200, Iteration 39/250, Loss: 0.0142\n",
      "Epoch 101/200, Iteration 40/250, Loss: 0.0137\n",
      "Epoch 101/200, Iteration 41/250, Loss: 0.0260\n",
      "Epoch 101/200, Iteration 42/250, Loss: 0.0125\n",
      "Epoch 101/200, Iteration 43/250, Loss: 0.0101\n",
      "Epoch 101/200, Iteration 44/250, Loss: 0.0307\n",
      "Epoch 101/200, Iteration 45/250, Loss: 0.0108\n",
      "Epoch 101/200, Iteration 46/250, Loss: 0.0301\n",
      "Epoch 101/200, Iteration 47/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 48/250, Loss: 0.0132\n",
      "Epoch 101/200, Iteration 49/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 50/250, Loss: 0.0259\n",
      "Epoch 101/200, Iteration 51/250, Loss: 0.0096\n",
      "Epoch 101/200, Iteration 52/250, Loss: 0.0182\n",
      "Epoch 101/200, Iteration 53/250, Loss: 0.0105\n",
      "Epoch 101/200, Iteration 54/250, Loss: 0.0140\n",
      "Epoch 101/200, Iteration 55/250, Loss: 0.0214\n",
      "Epoch 101/200, Iteration 56/250, Loss: 0.0114\n",
      "Epoch 101/200, Iteration 57/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 58/250, Loss: 0.0070\n",
      "Epoch 101/200, Iteration 59/250, Loss: 0.0200\n",
      "Epoch 101/200, Iteration 60/250, Loss: 0.0095\n",
      "Epoch 101/200, Iteration 61/250, Loss: 0.0104\n",
      "Epoch 101/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 101/200, Iteration 63/250, Loss: 0.0135\n",
      "Epoch 101/200, Iteration 64/250, Loss: 0.0072\n",
      "Epoch 101/200, Iteration 65/250, Loss: 0.0192\n",
      "Epoch 101/200, Iteration 66/250, Loss: 0.0100\n",
      "Epoch 101/200, Iteration 67/250, Loss: 0.0076\n",
      "Epoch 101/200, Iteration 68/250, Loss: 0.0069\n",
      "Epoch 101/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 101/200, Iteration 70/250, Loss: 0.0094\n",
      "Epoch 101/200, Iteration 71/250, Loss: 0.0150\n",
      "Epoch 101/200, Iteration 72/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 73/250, Loss: 0.0221\n",
      "Epoch 101/200, Iteration 74/250, Loss: 0.0101\n",
      "Epoch 101/200, Iteration 75/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 76/250, Loss: 0.0195\n",
      "Epoch 101/200, Iteration 77/250, Loss: 0.0177\n",
      "Epoch 101/200, Iteration 78/250, Loss: 0.0068\n",
      "Epoch 101/200, Iteration 79/250, Loss: 0.0100\n",
      "Epoch 101/200, Iteration 80/250, Loss: 0.0188\n",
      "Epoch 101/200, Iteration 81/250, Loss: 0.0142\n",
      "Epoch 101/200, Iteration 82/250, Loss: 0.0065\n",
      "Epoch 101/200, Iteration 83/250, Loss: 0.0165\n",
      "Epoch 101/200, Iteration 84/250, Loss: 0.0117\n",
      "Epoch 101/200, Iteration 85/250, Loss: 0.0098\n",
      "Epoch 101/200, Iteration 86/250, Loss: 0.0097\n",
      "Epoch 101/200, Iteration 87/250, Loss: 0.0131\n",
      "Epoch 101/200, Iteration 88/250, Loss: 0.0232\n",
      "Epoch 101/200, Iteration 89/250, Loss: 0.0325\n",
      "Epoch 101/200, Iteration 90/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 91/250, Loss: 0.0164\n",
      "Epoch 101/200, Iteration 92/250, Loss: 0.0069\n",
      "Epoch 101/200, Iteration 93/250, Loss: 0.0226\n",
      "Epoch 101/200, Iteration 94/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 95/250, Loss: 0.0238\n",
      "Epoch 101/200, Iteration 96/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 97/250, Loss: 0.0209\n",
      "Epoch 101/200, Iteration 98/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 99/250, Loss: 0.0154\n",
      "Epoch 101/200, Iteration 100/250, Loss: 0.0100\n",
      "Epoch 101/200, Iteration 101/250, Loss: 0.0154\n",
      "Epoch 101/200, Iteration 102/250, Loss: 0.0284\n",
      "Epoch 101/200, Iteration 103/250, Loss: 0.0187\n",
      "Epoch 101/200, Iteration 104/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 105/250, Loss: 0.0201\n",
      "Epoch 101/200, Iteration 106/250, Loss: 0.0237\n",
      "Epoch 101/200, Iteration 107/250, Loss: 0.0357\n",
      "Epoch 101/200, Iteration 108/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 109/250, Loss: 0.0164\n",
      "Epoch 101/200, Iteration 110/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 111/250, Loss: 0.0196\n",
      "Epoch 101/200, Iteration 112/250, Loss: 0.0206\n",
      "Epoch 101/200, Iteration 113/250, Loss: 0.0217\n",
      "Epoch 101/200, Iteration 114/250, Loss: 0.0123\n",
      "Epoch 101/200, Iteration 115/250, Loss: 0.0091\n",
      "Epoch 101/200, Iteration 116/250, Loss: 0.0280\n",
      "Epoch 101/200, Iteration 117/250, Loss: 0.0138\n",
      "Epoch 101/200, Iteration 118/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 119/250, Loss: 0.0106\n",
      "Epoch 101/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 101/200, Iteration 121/250, Loss: 0.0131\n",
      "Epoch 101/200, Iteration 122/250, Loss: 0.0063\n",
      "Epoch 101/200, Iteration 123/250, Loss: 0.0151\n",
      "Epoch 101/200, Iteration 124/250, Loss: 0.0193\n",
      "Epoch 101/200, Iteration 125/250, Loss: 0.0164\n",
      "Epoch 101/200, Iteration 126/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 127/250, Loss: 0.0231\n",
      "Epoch 101/200, Iteration 128/250, Loss: 0.0110\n",
      "Epoch 101/200, Iteration 129/250, Loss: 0.0095\n",
      "Epoch 101/200, Iteration 130/250, Loss: 0.0333\n",
      "Epoch 101/200, Iteration 131/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 101/200, Iteration 133/250, Loss: 0.0137\n",
      "Epoch 101/200, Iteration 134/250, Loss: 0.0185\n",
      "Epoch 101/200, Iteration 135/250, Loss: 0.0227\n",
      "Epoch 101/200, Iteration 136/250, Loss: 0.0122\n",
      "Epoch 101/200, Iteration 137/250, Loss: 0.0217\n",
      "Epoch 101/200, Iteration 138/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 139/250, Loss: 0.0149\n",
      "Epoch 101/200, Iteration 140/250, Loss: 0.0190\n",
      "Epoch 101/200, Iteration 141/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 142/250, Loss: 0.0318\n",
      "Epoch 101/200, Iteration 143/250, Loss: 0.0155\n",
      "Epoch 101/200, Iteration 144/250, Loss: 0.0098\n",
      "Epoch 101/200, Iteration 145/250, Loss: 0.0089\n",
      "Epoch 101/200, Iteration 146/250, Loss: 0.0159\n",
      "Epoch 101/200, Iteration 147/250, Loss: 0.0114\n",
      "Epoch 101/200, Iteration 148/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 149/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 150/250, Loss: 0.0157\n",
      "Epoch 101/200, Iteration 151/250, Loss: 0.0254\n",
      "Epoch 101/200, Iteration 152/250, Loss: 0.0103\n",
      "Epoch 101/200, Iteration 153/250, Loss: 0.0168\n",
      "Epoch 101/200, Iteration 154/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 155/250, Loss: 0.0094\n",
      "Epoch 101/200, Iteration 156/250, Loss: 0.0159\n",
      "Epoch 101/200, Iteration 157/250, Loss: 0.0088\n",
      "Epoch 101/200, Iteration 158/250, Loss: 0.0219\n",
      "Epoch 101/200, Iteration 159/250, Loss: 0.0081\n",
      "Epoch 101/200, Iteration 160/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 161/250, Loss: 0.0086\n",
      "Epoch 101/200, Iteration 162/250, Loss: 0.0079\n",
      "Epoch 101/200, Iteration 163/250, Loss: 0.0194\n",
      "Epoch 101/200, Iteration 164/250, Loss: 0.0120\n",
      "Epoch 101/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 101/200, Iteration 166/250, Loss: 0.0080\n",
      "Epoch 101/200, Iteration 167/250, Loss: 0.0144\n",
      "Epoch 101/200, Iteration 168/250, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 169/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 170/250, Loss: 0.0139\n",
      "Epoch 101/200, Iteration 171/250, Loss: 0.0138\n",
      "Epoch 101/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 101/200, Iteration 173/250, Loss: 0.0153\n",
      "Epoch 101/200, Iteration 174/250, Loss: 0.0117\n",
      "Epoch 101/200, Iteration 175/250, Loss: 0.0129\n",
      "Epoch 101/200, Iteration 176/250, Loss: 0.0116\n",
      "Epoch 101/200, Iteration 177/250, Loss: 0.0291\n",
      "Epoch 101/200, Iteration 178/250, Loss: 0.0066\n",
      "Epoch 101/200, Iteration 179/250, Loss: 0.0276\n",
      "Epoch 101/200, Iteration 180/250, Loss: 0.0111\n",
      "Epoch 101/200, Iteration 181/250, Loss: 0.0189\n",
      "Epoch 101/200, Iteration 182/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 183/250, Loss: 0.0078\n",
      "Epoch 101/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 185/250, Loss: 0.0126\n",
      "Epoch 101/200, Iteration 186/250, Loss: 0.0132\n",
      "Epoch 101/200, Iteration 187/250, Loss: 0.0083\n",
      "Epoch 101/200, Iteration 188/250, Loss: 0.0194\n",
      "Epoch 101/200, Iteration 189/250, Loss: 0.0110\n",
      "Epoch 101/200, Iteration 190/250, Loss: 0.0087\n",
      "Epoch 101/200, Iteration 191/250, Loss: 0.0119\n",
      "Epoch 101/200, Iteration 192/250, Loss: 0.0258\n",
      "Epoch 101/200, Iteration 193/250, Loss: 0.0152\n",
      "Epoch 101/200, Iteration 194/250, Loss: 0.0172\n",
      "Epoch 101/200, Iteration 195/250, Loss: 0.0107\n",
      "Epoch 101/200, Iteration 196/250, Loss: 0.0160\n",
      "Epoch 101/200, Iteration 197/250, Loss: 0.0123\n",
      "Epoch 101/200, Iteration 198/250, Loss: 0.0175\n",
      "Epoch 101/200, Iteration 199/250, Loss: 0.0139\n",
      "Epoch 101/200, Iteration 200/250, Loss: 0.0181\n",
      "Epoch 101/200, Iteration 201/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 202/250, Loss: 0.0079\n",
      "Epoch 101/200, Iteration 203/250, Loss: 0.0200\n",
      "Epoch 101/200, Iteration 204/250, Loss: 0.0125\n",
      "Epoch 101/200, Iteration 205/250, Loss: 0.0450\n",
      "Epoch 101/200, Iteration 206/250, Loss: 0.0209\n",
      "Epoch 101/200, Iteration 207/250, Loss: 0.0219\n",
      "Epoch 101/200, Iteration 208/250, Loss: 0.0149\n",
      "Epoch 101/200, Iteration 209/250, Loss: 0.0336\n",
      "Epoch 101/200, Iteration 210/250, Loss: 0.0150\n",
      "Epoch 101/200, Iteration 211/250, Loss: 0.0133\n",
      "Epoch 101/200, Iteration 212/250, Loss: 0.0150\n",
      "Epoch 101/200, Iteration 213/250, Loss: 0.0093\n",
      "Epoch 101/200, Iteration 214/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 215/250, Loss: 0.0198\n",
      "Epoch 101/200, Iteration 216/250, Loss: 0.0094\n",
      "Epoch 101/200, Iteration 217/250, Loss: 0.0162\n",
      "Epoch 101/200, Iteration 218/250, Loss: 0.0274\n",
      "Epoch 101/200, Iteration 219/250, Loss: 0.0118\n",
      "Epoch 101/200, Iteration 220/250, Loss: 0.0143\n",
      "Epoch 101/200, Iteration 221/250, Loss: 0.0209\n",
      "Epoch 101/200, Iteration 222/250, Loss: 0.0417\n",
      "Epoch 101/200, Iteration 223/250, Loss: 0.0139\n",
      "Epoch 101/200, Iteration 224/250, Loss: 0.0212\n",
      "Epoch 101/200, Iteration 225/250, Loss: 0.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200, Iteration 226/250, Loss: 0.0238\n",
      "Epoch 101/200, Iteration 227/250, Loss: 0.0171\n",
      "Epoch 101/200, Iteration 228/250, Loss: 0.0157\n",
      "Epoch 101/200, Iteration 229/250, Loss: 0.0100\n",
      "Epoch 101/200, Iteration 230/250, Loss: 0.0140\n",
      "Epoch 101/200, Iteration 231/250, Loss: 0.0115\n",
      "Epoch 101/200, Iteration 232/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 233/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 234/250, Loss: 0.0120\n",
      "Epoch 101/200, Iteration 235/250, Loss: 0.0124\n",
      "Epoch 101/200, Iteration 236/250, Loss: 0.0085\n",
      "Epoch 101/200, Iteration 237/250, Loss: 0.0090\n",
      "Epoch 101/200, Iteration 238/250, Loss: 0.0092\n",
      "Epoch 101/200, Iteration 239/250, Loss: 0.0102\n",
      "Epoch 101/200, Iteration 240/250, Loss: 0.0251\n",
      "Epoch 101/200, Iteration 241/250, Loss: 0.0174\n",
      "Epoch 101/200, Iteration 242/250, Loss: 0.0107\n",
      "Epoch 101/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 101/200, Iteration 244/250, Loss: 0.0085\n",
      "Epoch 101/200, Iteration 245/250, Loss: 0.0095\n",
      "Epoch 101/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 101/200, Iteration 247/250, Loss: 0.0263\n",
      "Epoch 101/200, Iteration 248/250, Loss: 0.0168\n",
      "Epoch 101/200, Iteration 249/250, Loss: 0.0106\n",
      "Epoch 101/200, Iteration 250/250, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 88.31%, Avg loss: 0.006819, MRE: 0.451048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.007310, MRE: 0.600082 \n",
      "\n",
      "Epoch 102/200, Iteration 1/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 2/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 3/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 4/250, Loss: 0.0154\n",
      "Epoch 102/200, Iteration 5/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 6/250, Loss: 0.0085\n",
      "Epoch 102/200, Iteration 7/250, Loss: 0.0189\n",
      "Epoch 102/200, Iteration 8/250, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 9/250, Loss: 0.0138\n",
      "Epoch 102/200, Iteration 10/250, Loss: 0.0143\n",
      "Epoch 102/200, Iteration 11/250, Loss: 0.0107\n",
      "Epoch 102/200, Iteration 12/250, Loss: 0.0080\n",
      "Epoch 102/200, Iteration 13/250, Loss: 0.0188\n",
      "Epoch 102/200, Iteration 14/250, Loss: 0.0085\n",
      "Epoch 102/200, Iteration 15/250, Loss: 0.0167\n",
      "Epoch 102/200, Iteration 16/250, Loss: 0.0109\n",
      "Epoch 102/200, Iteration 17/250, Loss: 0.0211\n",
      "Epoch 102/200, Iteration 18/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 19/250, Loss: 0.0071\n",
      "Epoch 102/200, Iteration 20/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 21/250, Loss: 0.0182\n",
      "Epoch 102/200, Iteration 22/250, Loss: 0.0071\n",
      "Epoch 102/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 24/250, Loss: 0.0116\n",
      "Epoch 102/200, Iteration 25/250, Loss: 0.0208\n",
      "Epoch 102/200, Iteration 26/250, Loss: 0.0138\n",
      "Epoch 102/200, Iteration 27/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 28/250, Loss: 0.0284\n",
      "Epoch 102/200, Iteration 29/250, Loss: 0.0231\n",
      "Epoch 102/200, Iteration 30/250, Loss: 0.0295\n",
      "Epoch 102/200, Iteration 31/250, Loss: 0.0203\n",
      "Epoch 102/200, Iteration 32/250, Loss: 0.0153\n",
      "Epoch 102/200, Iteration 33/250, Loss: 0.0139\n",
      "Epoch 102/200, Iteration 34/250, Loss: 0.0197\n",
      "Epoch 102/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 36/250, Loss: 0.0233\n",
      "Epoch 102/200, Iteration 37/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 38/250, Loss: 0.0341\n",
      "Epoch 102/200, Iteration 39/250, Loss: 0.0169\n",
      "Epoch 102/200, Iteration 40/250, Loss: 0.0196\n",
      "Epoch 102/200, Iteration 41/250, Loss: 0.0109\n",
      "Epoch 102/200, Iteration 42/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 43/250, Loss: 0.0099\n",
      "Epoch 102/200, Iteration 44/250, Loss: 0.0110\n",
      "Epoch 102/200, Iteration 45/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 46/250, Loss: 0.0094\n",
      "Epoch 102/200, Iteration 47/250, Loss: 0.0181\n",
      "Epoch 102/200, Iteration 48/250, Loss: 0.0114\n",
      "Epoch 102/200, Iteration 49/250, Loss: 0.0198\n",
      "Epoch 102/200, Iteration 50/250, Loss: 0.0119\n",
      "Epoch 102/200, Iteration 51/250, Loss: 0.0121\n",
      "Epoch 102/200, Iteration 52/250, Loss: 0.0301\n",
      "Epoch 102/200, Iteration 53/250, Loss: 0.0089\n",
      "Epoch 102/200, Iteration 54/250, Loss: 0.0093\n",
      "Epoch 102/200, Iteration 55/250, Loss: 0.0116\n",
      "Epoch 102/200, Iteration 56/250, Loss: 0.0148\n",
      "Epoch 102/200, Iteration 57/250, Loss: 0.0087\n",
      "Epoch 102/200, Iteration 58/250, Loss: 0.0173\n",
      "Epoch 102/200, Iteration 59/250, Loss: 0.0192\n",
      "Epoch 102/200, Iteration 60/250, Loss: 0.0180\n",
      "Epoch 102/200, Iteration 61/250, Loss: 0.0253\n",
      "Epoch 102/200, Iteration 62/250, Loss: 0.0241\n",
      "Epoch 102/200, Iteration 63/250, Loss: 0.0112\n",
      "Epoch 102/200, Iteration 64/250, Loss: 0.0183\n",
      "Epoch 102/200, Iteration 65/250, Loss: 0.0124\n",
      "Epoch 102/200, Iteration 66/250, Loss: 0.0173\n",
      "Epoch 102/200, Iteration 67/250, Loss: 0.0110\n",
      "Epoch 102/200, Iteration 68/250, Loss: 0.0190\n",
      "Epoch 102/200, Iteration 69/250, Loss: 0.0485\n",
      "Epoch 102/200, Iteration 70/250, Loss: 0.0363\n",
      "Epoch 102/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 72/250, Loss: 0.0130\n",
      "Epoch 102/200, Iteration 73/250, Loss: 0.0260\n",
      "Epoch 102/200, Iteration 74/250, Loss: 0.0203\n",
      "Epoch 102/200, Iteration 75/250, Loss: 0.0399\n",
      "Epoch 102/200, Iteration 76/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 77/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 78/250, Loss: 0.0099\n",
      "Epoch 102/200, Iteration 79/250, Loss: 0.0126\n",
      "Epoch 102/200, Iteration 80/250, Loss: 0.0111\n",
      "Epoch 102/200, Iteration 81/250, Loss: 0.0135\n",
      "Epoch 102/200, Iteration 82/250, Loss: 0.0289\n",
      "Epoch 102/200, Iteration 83/250, Loss: 0.0112\n",
      "Epoch 102/200, Iteration 84/250, Loss: 0.0197\n",
      "Epoch 102/200, Iteration 85/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 86/250, Loss: 0.0102\n",
      "Epoch 102/200, Iteration 87/250, Loss: 0.0392\n",
      "Epoch 102/200, Iteration 88/250, Loss: 0.0262\n",
      "Epoch 102/200, Iteration 89/250, Loss: 0.0252\n",
      "Epoch 102/200, Iteration 90/250, Loss: 0.0194\n",
      "Epoch 102/200, Iteration 91/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 92/250, Loss: 0.0152\n",
      "Epoch 102/200, Iteration 93/250, Loss: 0.0164\n",
      "Epoch 102/200, Iteration 94/250, Loss: 0.0142\n",
      "Epoch 102/200, Iteration 95/250, Loss: 0.0201\n",
      "Epoch 102/200, Iteration 96/250, Loss: 0.0134\n",
      "Epoch 102/200, Iteration 97/250, Loss: 0.0150\n",
      "Epoch 102/200, Iteration 98/250, Loss: 0.0182\n",
      "Epoch 102/200, Iteration 99/250, Loss: 0.0128\n",
      "Epoch 102/200, Iteration 100/250, Loss: 0.0176\n",
      "Epoch 102/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 102/200, Iteration 102/250, Loss: 0.0134\n",
      "Epoch 102/200, Iteration 103/250, Loss: 0.0076\n",
      "Epoch 102/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 102/200, Iteration 105/250, Loss: 0.0287\n",
      "Epoch 102/200, Iteration 106/250, Loss: 0.0198\n",
      "Epoch 102/200, Iteration 107/250, Loss: 0.0182\n",
      "Epoch 102/200, Iteration 108/250, Loss: 0.0396\n",
      "Epoch 102/200, Iteration 109/250, Loss: 0.0161\n",
      "Epoch 102/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 102/200, Iteration 111/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 112/250, Loss: 0.0196\n",
      "Epoch 102/200, Iteration 113/250, Loss: 0.0229\n",
      "Epoch 102/200, Iteration 114/250, Loss: 0.0166\n",
      "Epoch 102/200, Iteration 115/250, Loss: 0.0078\n",
      "Epoch 102/200, Iteration 116/250, Loss: 0.0147\n",
      "Epoch 102/200, Iteration 117/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 118/250, Loss: 0.0191\n",
      "Epoch 102/200, Iteration 119/250, Loss: 0.0172\n",
      "Epoch 102/200, Iteration 120/250, Loss: 0.0107\n",
      "Epoch 102/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 102/200, Iteration 122/250, Loss: 0.0423\n",
      "Epoch 102/200, Iteration 123/250, Loss: 0.0070\n",
      "Epoch 102/200, Iteration 124/250, Loss: 0.0204\n",
      "Epoch 102/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 126/250, Loss: 0.0100\n",
      "Epoch 102/200, Iteration 127/250, Loss: 0.0156\n",
      "Epoch 102/200, Iteration 128/250, Loss: 0.0141\n",
      "Epoch 102/200, Iteration 129/250, Loss: 0.0234\n",
      "Epoch 102/200, Iteration 130/250, Loss: 0.0124\n",
      "Epoch 102/200, Iteration 131/250, Loss: 0.0093\n",
      "Epoch 102/200, Iteration 132/250, Loss: 0.0094\n",
      "Epoch 102/200, Iteration 133/250, Loss: 0.0169\n",
      "Epoch 102/200, Iteration 134/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 135/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 136/250, Loss: 0.0097\n",
      "Epoch 102/200, Iteration 137/250, Loss: 0.0154\n",
      "Epoch 102/200, Iteration 138/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 139/250, Loss: 0.0109\n",
      "Epoch 102/200, Iteration 140/250, Loss: 0.0075\n",
      "Epoch 102/200, Iteration 141/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 142/250, Loss: 0.0135\n",
      "Epoch 102/200, Iteration 143/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 144/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 145/250, Loss: 0.0171\n",
      "Epoch 102/200, Iteration 146/250, Loss: 0.0089\n",
      "Epoch 102/200, Iteration 147/250, Loss: 0.0187\n",
      "Epoch 102/200, Iteration 148/250, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 149/250, Loss: 0.0064\n",
      "Epoch 102/200, Iteration 150/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 151/250, Loss: 0.0187\n",
      "Epoch 102/200, Iteration 152/250, Loss: 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200, Iteration 153/250, Loss: 0.0155\n",
      "Epoch 102/200, Iteration 154/250, Loss: 0.0074\n",
      "Epoch 102/200, Iteration 155/250, Loss: 0.0141\n",
      "Epoch 102/200, Iteration 156/250, Loss: 0.0134\n",
      "Epoch 102/200, Iteration 157/250, Loss: 0.0217\n",
      "Epoch 102/200, Iteration 158/250, Loss: 0.0150\n",
      "Epoch 102/200, Iteration 159/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 160/250, Loss: 0.0073\n",
      "Epoch 102/200, Iteration 161/250, Loss: 0.0192\n",
      "Epoch 102/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 163/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 164/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 102/200, Iteration 166/250, Loss: 0.0079\n",
      "Epoch 102/200, Iteration 167/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 168/250, Loss: 0.0136\n",
      "Epoch 102/200, Iteration 169/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 170/250, Loss: 0.0253\n",
      "Epoch 102/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 102/200, Iteration 172/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 173/250, Loss: 0.0162\n",
      "Epoch 102/200, Iteration 174/250, Loss: 0.0067\n",
      "Epoch 102/200, Iteration 175/250, Loss: 0.0285\n",
      "Epoch 102/200, Iteration 176/250, Loss: 0.0174\n",
      "Epoch 102/200, Iteration 177/250, Loss: 0.0146\n",
      "Epoch 102/200, Iteration 178/250, Loss: 0.0134\n",
      "Epoch 102/200, Iteration 179/250, Loss: 0.0232\n",
      "Epoch 102/200, Iteration 180/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 181/250, Loss: 0.0229\n",
      "Epoch 102/200, Iteration 182/250, Loss: 0.0104\n",
      "Epoch 102/200, Iteration 183/250, Loss: 0.0147\n",
      "Epoch 102/200, Iteration 184/250, Loss: 0.0163\n",
      "Epoch 102/200, Iteration 185/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 186/250, Loss: 0.0072\n",
      "Epoch 102/200, Iteration 187/250, Loss: 0.0089\n",
      "Epoch 102/200, Iteration 188/250, Loss: 0.0074\n",
      "Epoch 102/200, Iteration 189/250, Loss: 0.0148\n",
      "Epoch 102/200, Iteration 190/250, Loss: 0.0307\n",
      "Epoch 102/200, Iteration 191/250, Loss: 0.0222\n",
      "Epoch 102/200, Iteration 192/250, Loss: 0.0096\n",
      "Epoch 102/200, Iteration 193/250, Loss: 0.0279\n",
      "Epoch 102/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 102/200, Iteration 195/250, Loss: 0.0318\n",
      "Epoch 102/200, Iteration 196/250, Loss: 0.0141\n",
      "Epoch 102/200, Iteration 197/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 198/250, Loss: 0.0099\n",
      "Epoch 102/200, Iteration 199/250, Loss: 0.0191\n",
      "Epoch 102/200, Iteration 200/250, Loss: 0.0292\n",
      "Epoch 102/200, Iteration 201/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 202/250, Loss: 0.0074\n",
      "Epoch 102/200, Iteration 203/250, Loss: 0.0187\n",
      "Epoch 102/200, Iteration 204/250, Loss: 0.0163\n",
      "Epoch 102/200, Iteration 205/250, Loss: 0.0133\n",
      "Epoch 102/200, Iteration 206/250, Loss: 0.0046\n",
      "Epoch 102/200, Iteration 207/250, Loss: 0.0086\n",
      "Epoch 102/200, Iteration 208/250, Loss: 0.0088\n",
      "Epoch 102/200, Iteration 209/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 210/250, Loss: 0.0251\n",
      "Epoch 102/200, Iteration 211/250, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 212/250, Loss: 0.0117\n",
      "Epoch 102/200, Iteration 213/250, Loss: 0.0105\n",
      "Epoch 102/200, Iteration 214/250, Loss: 0.0226\n",
      "Epoch 102/200, Iteration 215/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 216/250, Loss: 0.0077\n",
      "Epoch 102/200, Iteration 217/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 218/250, Loss: 0.0097\n",
      "Epoch 102/200, Iteration 219/250, Loss: 0.0352\n",
      "Epoch 102/200, Iteration 220/250, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 221/250, Loss: 0.0396\n",
      "Epoch 102/200, Iteration 222/250, Loss: 0.0087\n",
      "Epoch 102/200, Iteration 223/250, Loss: 0.0084\n",
      "Epoch 102/200, Iteration 224/250, Loss: 0.0164\n",
      "Epoch 102/200, Iteration 225/250, Loss: 0.0132\n",
      "Epoch 102/200, Iteration 226/250, Loss: 0.0151\n",
      "Epoch 102/200, Iteration 227/250, Loss: 0.0180\n",
      "Epoch 102/200, Iteration 228/250, Loss: 0.0098\n",
      "Epoch 102/200, Iteration 229/250, Loss: 0.0120\n",
      "Epoch 102/200, Iteration 230/250, Loss: 0.0159\n",
      "Epoch 102/200, Iteration 231/250, Loss: 0.0150\n",
      "Epoch 102/200, Iteration 232/250, Loss: 0.0082\n",
      "Epoch 102/200, Iteration 233/250, Loss: 0.0118\n",
      "Epoch 102/200, Iteration 234/250, Loss: 0.0353\n",
      "Epoch 102/200, Iteration 235/250, Loss: 0.0207\n",
      "Epoch 102/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 102/200, Iteration 237/250, Loss: 0.0122\n",
      "Epoch 102/200, Iteration 238/250, Loss: 0.0204\n",
      "Epoch 102/200, Iteration 239/250, Loss: 0.0186\n",
      "Epoch 102/200, Iteration 240/250, Loss: 0.0110\n",
      "Epoch 102/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 102/200, Iteration 242/250, Loss: 0.0115\n",
      "Epoch 102/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 102/200, Iteration 244/250, Loss: 0.0092\n",
      "Epoch 102/200, Iteration 245/250, Loss: 0.0100\n",
      "Epoch 102/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 102/200, Iteration 247/250, Loss: 0.0339\n",
      "Epoch 102/200, Iteration 248/250, Loss: 0.0257\n",
      "Epoch 102/200, Iteration 249/250, Loss: 0.0243\n",
      "Epoch 102/200, Iteration 250/250, Loss: 0.0211\n",
      "Train Error: \n",
      " Accuracy: 85.62%, Avg loss: 0.006779, MRE: 0.418746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.05%, Avg loss: 0.007350, MRE: 0.502428 \n",
      "\n",
      "Epoch 103/200, Iteration 1/250, Loss: 0.0155\n",
      "Epoch 103/200, Iteration 2/250, Loss: 0.0139\n",
      "Epoch 103/200, Iteration 3/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 4/250, Loss: 0.0065\n",
      "Epoch 103/200, Iteration 5/250, Loss: 0.0051\n",
      "Epoch 103/200, Iteration 6/250, Loss: 0.0121\n",
      "Epoch 103/200, Iteration 7/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 8/250, Loss: 0.0171\n",
      "Epoch 103/200, Iteration 9/250, Loss: 0.0130\n",
      "Epoch 103/200, Iteration 10/250, Loss: 0.0281\n",
      "Epoch 103/200, Iteration 11/250, Loss: 0.0113\n",
      "Epoch 103/200, Iteration 12/250, Loss: 0.0160\n",
      "Epoch 103/200, Iteration 13/250, Loss: 0.0128\n",
      "Epoch 103/200, Iteration 14/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 15/250, Loss: 0.0127\n",
      "Epoch 103/200, Iteration 16/250, Loss: 0.0131\n",
      "Epoch 103/200, Iteration 17/250, Loss: 0.0158\n",
      "Epoch 103/200, Iteration 18/250, Loss: 0.0143\n",
      "Epoch 103/200, Iteration 19/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 20/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 21/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 22/250, Loss: 0.0070\n",
      "Epoch 103/200, Iteration 23/250, Loss: 0.0325\n",
      "Epoch 103/200, Iteration 24/250, Loss: 0.0145\n",
      "Epoch 103/200, Iteration 25/250, Loss: 0.0065\n",
      "Epoch 103/200, Iteration 26/250, Loss: 0.0314\n",
      "Epoch 103/200, Iteration 27/250, Loss: 0.0405\n",
      "Epoch 103/200, Iteration 28/250, Loss: 0.0251\n",
      "Epoch 103/200, Iteration 29/250, Loss: 0.0138\n",
      "Epoch 103/200, Iteration 30/250, Loss: 0.0149\n",
      "Epoch 103/200, Iteration 31/250, Loss: 0.0205\n",
      "Epoch 103/200, Iteration 32/250, Loss: 0.0136\n",
      "Epoch 103/200, Iteration 33/250, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 34/250, Loss: 0.0059\n",
      "Epoch 103/200, Iteration 35/250, Loss: 0.0183\n",
      "Epoch 103/200, Iteration 36/250, Loss: 0.0231\n",
      "Epoch 103/200, Iteration 37/250, Loss: 0.0153\n",
      "Epoch 103/200, Iteration 38/250, Loss: 0.0184\n",
      "Epoch 103/200, Iteration 39/250, Loss: 0.0201\n",
      "Epoch 103/200, Iteration 40/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 41/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 42/250, Loss: 0.0261\n",
      "Epoch 103/200, Iteration 43/250, Loss: 0.0195\n",
      "Epoch 103/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 103/200, Iteration 45/250, Loss: 0.0066\n",
      "Epoch 103/200, Iteration 46/250, Loss: 0.0138\n",
      "Epoch 103/200, Iteration 47/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 48/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 49/250, Loss: 0.0164\n",
      "Epoch 103/200, Iteration 50/250, Loss: 0.0142\n",
      "Epoch 103/200, Iteration 51/250, Loss: 0.0354\n",
      "Epoch 103/200, Iteration 52/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 53/250, Loss: 0.0232\n",
      "Epoch 103/200, Iteration 54/250, Loss: 0.0146\n",
      "Epoch 103/200, Iteration 55/250, Loss: 0.0118\n",
      "Epoch 103/200, Iteration 56/250, Loss: 0.0200\n",
      "Epoch 103/200, Iteration 57/250, Loss: 0.0181\n",
      "Epoch 103/200, Iteration 58/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 59/250, Loss: 0.0057\n",
      "Epoch 103/200, Iteration 60/250, Loss: 0.0134\n",
      "Epoch 103/200, Iteration 61/250, Loss: 0.0192\n",
      "Epoch 103/200, Iteration 62/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 63/250, Loss: 0.0153\n",
      "Epoch 103/200, Iteration 64/250, Loss: 0.0064\n",
      "Epoch 103/200, Iteration 65/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 66/250, Loss: 0.0126\n",
      "Epoch 103/200, Iteration 67/250, Loss: 0.0136\n",
      "Epoch 103/200, Iteration 68/250, Loss: 0.0087\n",
      "Epoch 103/200, Iteration 69/250, Loss: 0.0251\n",
      "Epoch 103/200, Iteration 70/250, Loss: 0.0223\n",
      "Epoch 103/200, Iteration 71/250, Loss: 0.0082\n",
      "Epoch 103/200, Iteration 72/250, Loss: 0.0152\n",
      "Epoch 103/200, Iteration 73/250, Loss: 0.0138\n",
      "Epoch 103/200, Iteration 74/250, Loss: 0.0255\n",
      "Epoch 103/200, Iteration 75/250, Loss: 0.0104\n",
      "Epoch 103/200, Iteration 76/250, Loss: 0.0160\n",
      "Epoch 103/200, Iteration 77/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 78/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 79/250, Loss: 0.0298\n",
      "Epoch 103/200, Iteration 80/250, Loss: 0.0202\n",
      "Epoch 103/200, Iteration 81/250, Loss: 0.0090\n",
      "Epoch 103/200, Iteration 82/250, Loss: 0.0301\n",
      "Epoch 103/200, Iteration 83/250, Loss: 0.0200\n",
      "Epoch 103/200, Iteration 84/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 85/250, Loss: 0.0097\n",
      "Epoch 103/200, Iteration 86/250, Loss: 0.0131\n",
      "Epoch 103/200, Iteration 87/250, Loss: 0.0218\n",
      "Epoch 103/200, Iteration 88/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 89/250, Loss: 0.0267\n",
      "Epoch 103/200, Iteration 90/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 91/250, Loss: 0.0110\n",
      "Epoch 103/200, Iteration 92/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 93/250, Loss: 0.0111\n",
      "Epoch 103/200, Iteration 94/250, Loss: 0.0199\n",
      "Epoch 103/200, Iteration 95/250, Loss: 0.0101\n",
      "Epoch 103/200, Iteration 96/250, Loss: 0.0164\n",
      "Epoch 103/200, Iteration 97/250, Loss: 0.0099\n",
      "Epoch 103/200, Iteration 98/250, Loss: 0.0195\n",
      "Epoch 103/200, Iteration 99/250, Loss: 0.0126\n",
      "Epoch 103/200, Iteration 100/250, Loss: 0.0241\n",
      "Epoch 103/200, Iteration 101/250, Loss: 0.0109\n",
      "Epoch 103/200, Iteration 102/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 103/250, Loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200, Iteration 104/250, Loss: 0.0091\n",
      "Epoch 103/200, Iteration 105/250, Loss: 0.0156\n",
      "Epoch 103/200, Iteration 106/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 107/250, Loss: 0.0077\n",
      "Epoch 103/200, Iteration 108/250, Loss: 0.0167\n",
      "Epoch 103/200, Iteration 109/250, Loss: 0.0173\n",
      "Epoch 103/200, Iteration 110/250, Loss: 0.0200\n",
      "Epoch 103/200, Iteration 111/250, Loss: 0.0245\n",
      "Epoch 103/200, Iteration 112/250, Loss: 0.0095\n",
      "Epoch 103/200, Iteration 113/250, Loss: 0.0219\n",
      "Epoch 103/200, Iteration 114/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 115/250, Loss: 0.0122\n",
      "Epoch 103/200, Iteration 116/250, Loss: 0.0091\n",
      "Epoch 103/200, Iteration 117/250, Loss: 0.0104\n",
      "Epoch 103/200, Iteration 118/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 119/250, Loss: 0.0152\n",
      "Epoch 103/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 103/200, Iteration 121/250, Loss: 0.0098\n",
      "Epoch 103/200, Iteration 122/250, Loss: 0.0150\n",
      "Epoch 103/200, Iteration 123/250, Loss: 0.0196\n",
      "Epoch 103/200, Iteration 124/250, Loss: 0.0176\n",
      "Epoch 103/200, Iteration 125/250, Loss: 0.0179\n",
      "Epoch 103/200, Iteration 126/250, Loss: 0.0083\n",
      "Epoch 103/200, Iteration 127/250, Loss: 0.0087\n",
      "Epoch 103/200, Iteration 128/250, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 129/250, Loss: 0.0222\n",
      "Epoch 103/200, Iteration 130/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 131/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 133/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 134/250, Loss: 0.0184\n",
      "Epoch 103/200, Iteration 135/250, Loss: 0.0099\n",
      "Epoch 103/200, Iteration 136/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 137/250, Loss: 0.0100\n",
      "Epoch 103/200, Iteration 138/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 139/250, Loss: 0.0291\n",
      "Epoch 103/200, Iteration 140/250, Loss: 0.0079\n",
      "Epoch 103/200, Iteration 141/250, Loss: 0.0227\n",
      "Epoch 103/200, Iteration 142/250, Loss: 0.0256\n",
      "Epoch 103/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 144/250, Loss: 0.0198\n",
      "Epoch 103/200, Iteration 145/250, Loss: 0.0106\n",
      "Epoch 103/200, Iteration 146/250, Loss: 0.0102\n",
      "Epoch 103/200, Iteration 147/250, Loss: 0.0311\n",
      "Epoch 103/200, Iteration 148/250, Loss: 0.0292\n",
      "Epoch 103/200, Iteration 149/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 150/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 151/250, Loss: 0.0078\n",
      "Epoch 103/200, Iteration 152/250, Loss: 0.0161\n",
      "Epoch 103/200, Iteration 153/250, Loss: 0.0114\n",
      "Epoch 103/200, Iteration 154/250, Loss: 0.0101\n",
      "Epoch 103/200, Iteration 155/250, Loss: 0.0164\n",
      "Epoch 103/200, Iteration 156/250, Loss: 0.0079\n",
      "Epoch 103/200, Iteration 157/250, Loss: 0.0099\n",
      "Epoch 103/200, Iteration 158/250, Loss: 0.0057\n",
      "Epoch 103/200, Iteration 159/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 160/250, Loss: 0.0175\n",
      "Epoch 103/200, Iteration 161/250, Loss: 0.0137\n",
      "Epoch 103/200, Iteration 162/250, Loss: 0.0456\n",
      "Epoch 103/200, Iteration 163/250, Loss: 0.0110\n",
      "Epoch 103/200, Iteration 164/250, Loss: 0.0139\n",
      "Epoch 103/200, Iteration 165/250, Loss: 0.0200\n",
      "Epoch 103/200, Iteration 166/250, Loss: 0.0064\n",
      "Epoch 103/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 103/200, Iteration 168/250, Loss: 0.0208\n",
      "Epoch 103/200, Iteration 169/250, Loss: 0.0361\n",
      "Epoch 103/200, Iteration 170/250, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 171/250, Loss: 0.0296\n",
      "Epoch 103/200, Iteration 172/250, Loss: 0.0158\n",
      "Epoch 103/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 103/200, Iteration 174/250, Loss: 0.0089\n",
      "Epoch 103/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 103/200, Iteration 176/250, Loss: 0.0066\n",
      "Epoch 103/200, Iteration 177/250, Loss: 0.0096\n",
      "Epoch 103/200, Iteration 178/250, Loss: 0.0279\n",
      "Epoch 103/200, Iteration 179/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 180/250, Loss: 0.0096\n",
      "Epoch 103/200, Iteration 181/250, Loss: 0.0132\n",
      "Epoch 103/200, Iteration 182/250, Loss: 0.0128\n",
      "Epoch 103/200, Iteration 183/250, Loss: 0.0203\n",
      "Epoch 103/200, Iteration 184/250, Loss: 0.0282\n",
      "Epoch 103/200, Iteration 185/250, Loss: 0.0136\n",
      "Epoch 103/200, Iteration 186/250, Loss: 0.0065\n",
      "Epoch 103/200, Iteration 187/250, Loss: 0.0199\n",
      "Epoch 103/200, Iteration 188/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 189/250, Loss: 0.0161\n",
      "Epoch 103/200, Iteration 190/250, Loss: 0.0193\n",
      "Epoch 103/200, Iteration 191/250, Loss: 0.0103\n",
      "Epoch 103/200, Iteration 192/250, Loss: 0.0157\n",
      "Epoch 103/200, Iteration 193/250, Loss: 0.0219\n",
      "Epoch 103/200, Iteration 194/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 195/250, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 196/250, Loss: 0.0106\n",
      "Epoch 103/200, Iteration 197/250, Loss: 0.0184\n",
      "Epoch 103/200, Iteration 198/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 199/250, Loss: 0.0127\n",
      "Epoch 103/200, Iteration 200/250, Loss: 0.0105\n",
      "Epoch 103/200, Iteration 201/250, Loss: 0.0084\n",
      "Epoch 103/200, Iteration 202/250, Loss: 0.0115\n",
      "Epoch 103/200, Iteration 203/250, Loss: 0.0308\n",
      "Epoch 103/200, Iteration 204/250, Loss: 0.0062\n",
      "Epoch 103/200, Iteration 205/250, Loss: 0.0219\n",
      "Epoch 103/200, Iteration 206/250, Loss: 0.0126\n",
      "Epoch 103/200, Iteration 207/250, Loss: 0.0120\n",
      "Epoch 103/200, Iteration 208/250, Loss: 0.0107\n",
      "Epoch 103/200, Iteration 209/250, Loss: 0.0209\n",
      "Epoch 103/200, Iteration 210/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 211/250, Loss: 0.0293\n",
      "Epoch 103/200, Iteration 212/250, Loss: 0.0093\n",
      "Epoch 103/200, Iteration 213/250, Loss: 0.0113\n",
      "Epoch 103/200, Iteration 214/250, Loss: 0.0152\n",
      "Epoch 103/200, Iteration 215/250, Loss: 0.0301\n",
      "Epoch 103/200, Iteration 216/250, Loss: 0.0116\n",
      "Epoch 103/200, Iteration 217/250, Loss: 0.0075\n",
      "Epoch 103/200, Iteration 218/250, Loss: 0.0241\n",
      "Epoch 103/200, Iteration 219/250, Loss: 0.0117\n",
      "Epoch 103/200, Iteration 220/250, Loss: 0.0085\n",
      "Epoch 103/200, Iteration 221/250, Loss: 0.0074\n",
      "Epoch 103/200, Iteration 222/250, Loss: 0.0254\n",
      "Epoch 103/200, Iteration 223/250, Loss: 0.0168\n",
      "Epoch 103/200, Iteration 224/250, Loss: 0.0179\n",
      "Epoch 103/200, Iteration 225/250, Loss: 0.0108\n",
      "Epoch 103/200, Iteration 226/250, Loss: 0.0248\n",
      "Epoch 103/200, Iteration 227/250, Loss: 0.0177\n",
      "Epoch 103/200, Iteration 228/250, Loss: 0.0194\n",
      "Epoch 103/200, Iteration 229/250, Loss: 0.0080\n",
      "Epoch 103/200, Iteration 230/250, Loss: 0.0139\n",
      "Epoch 103/200, Iteration 231/250, Loss: 0.0156\n",
      "Epoch 103/200, Iteration 232/250, Loss: 0.0158\n",
      "Epoch 103/200, Iteration 233/250, Loss: 0.0143\n",
      "Epoch 103/200, Iteration 234/250, Loss: 0.0074\n",
      "Epoch 103/200, Iteration 235/250, Loss: 0.0079\n",
      "Epoch 103/200, Iteration 236/250, Loss: 0.0197\n",
      "Epoch 103/200, Iteration 237/250, Loss: 0.0096\n",
      "Epoch 103/200, Iteration 238/250, Loss: 0.0124\n",
      "Epoch 103/200, Iteration 239/250, Loss: 0.0141\n",
      "Epoch 103/200, Iteration 240/250, Loss: 0.0187\n",
      "Epoch 103/200, Iteration 241/250, Loss: 0.0097\n",
      "Epoch 103/200, Iteration 242/250, Loss: 0.0083\n",
      "Epoch 103/200, Iteration 243/250, Loss: 0.0158\n",
      "Epoch 103/200, Iteration 244/250, Loss: 0.0081\n",
      "Epoch 103/200, Iteration 245/250, Loss: 0.0110\n",
      "Epoch 103/200, Iteration 246/250, Loss: 0.0214\n",
      "Epoch 103/200, Iteration 247/250, Loss: 0.0133\n",
      "Epoch 103/200, Iteration 248/250, Loss: 0.0246\n",
      "Epoch 103/200, Iteration 249/250, Loss: 0.0096\n",
      "Epoch 103/200, Iteration 250/250, Loss: 0.0335\n",
      "Train Error: \n",
      " Accuracy: 73.36%, Avg loss: 0.008144, MRE: 0.640483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.15%, Avg loss: 0.008659, MRE: 0.677660 \n",
      "\n",
      "Epoch 104/200, Iteration 1/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 2/250, Loss: 0.0217\n",
      "Epoch 104/200, Iteration 3/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 4/250, Loss: 0.0104\n",
      "Epoch 104/200, Iteration 5/250, Loss: 0.0219\n",
      "Epoch 104/200, Iteration 6/250, Loss: 0.0175\n",
      "Epoch 104/200, Iteration 7/250, Loss: 0.0109\n",
      "Epoch 104/200, Iteration 8/250, Loss: 0.0114\n",
      "Epoch 104/200, Iteration 9/250, Loss: 0.0135\n",
      "Epoch 104/200, Iteration 10/250, Loss: 0.0169\n",
      "Epoch 104/200, Iteration 11/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 12/250, Loss: 0.0149\n",
      "Epoch 104/200, Iteration 13/250, Loss: 0.0121\n",
      "Epoch 104/200, Iteration 14/250, Loss: 0.0332\n",
      "Epoch 104/200, Iteration 15/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 16/250, Loss: 0.0112\n",
      "Epoch 104/200, Iteration 17/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 18/250, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 19/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 20/250, Loss: 0.0122\n",
      "Epoch 104/200, Iteration 21/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 22/250, Loss: 0.0263\n",
      "Epoch 104/200, Iteration 23/250, Loss: 0.0216\n",
      "Epoch 104/200, Iteration 24/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 25/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 26/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 27/250, Loss: 0.0162\n",
      "Epoch 104/200, Iteration 28/250, Loss: 0.0189\n",
      "Epoch 104/200, Iteration 29/250, Loss: 0.0158\n",
      "Epoch 104/200, Iteration 30/250, Loss: 0.0179\n",
      "Epoch 104/200, Iteration 31/250, Loss: 0.0405\n",
      "Epoch 104/200, Iteration 32/250, Loss: 0.0218\n",
      "Epoch 104/200, Iteration 33/250, Loss: 0.0150\n",
      "Epoch 104/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 35/250, Loss: 0.0160\n",
      "Epoch 104/200, Iteration 36/250, Loss: 0.0107\n",
      "Epoch 104/200, Iteration 37/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 38/250, Loss: 0.0202\n",
      "Epoch 104/200, Iteration 39/250, Loss: 0.0291\n",
      "Epoch 104/200, Iteration 40/250, Loss: 0.0222\n",
      "Epoch 104/200, Iteration 41/250, Loss: 0.0103\n",
      "Epoch 104/200, Iteration 42/250, Loss: 0.0186\n",
      "Epoch 104/200, Iteration 43/250, Loss: 0.0075\n",
      "Epoch 104/200, Iteration 44/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 45/250, Loss: 0.0310\n",
      "Epoch 104/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 104/200, Iteration 47/250, Loss: 0.0125\n",
      "Epoch 104/200, Iteration 48/250, Loss: 0.0166\n",
      "Epoch 104/200, Iteration 49/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 50/250, Loss: 0.0069\n",
      "Epoch 104/200, Iteration 51/250, Loss: 0.0062\n",
      "Epoch 104/200, Iteration 52/250, Loss: 0.0091\n",
      "Epoch 104/200, Iteration 53/250, Loss: 0.0427\n",
      "Epoch 104/200, Iteration 54/250, Loss: 0.0173\n",
      "Epoch 104/200, Iteration 55/250, Loss: 0.0130\n",
      "Epoch 104/200, Iteration 56/250, Loss: 0.0214\n",
      "Epoch 104/200, Iteration 57/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 58/250, Loss: 0.0079\n",
      "Epoch 104/200, Iteration 59/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 60/250, Loss: 0.0270\n",
      "Epoch 104/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 104/200, Iteration 62/250, Loss: 0.0394\n",
      "Epoch 104/200, Iteration 63/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 64/250, Loss: 0.0201\n",
      "Epoch 104/200, Iteration 65/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 66/250, Loss: 0.0439\n",
      "Epoch 104/200, Iteration 67/250, Loss: 0.0307\n",
      "Epoch 104/200, Iteration 68/250, Loss: 0.0150\n",
      "Epoch 104/200, Iteration 69/250, Loss: 0.0243\n",
      "Epoch 104/200, Iteration 70/250, Loss: 0.0235\n",
      "Epoch 104/200, Iteration 71/250, Loss: 0.0200\n",
      "Epoch 104/200, Iteration 72/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 73/250, Loss: 0.0287\n",
      "Epoch 104/200, Iteration 74/250, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200, Iteration 75/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 76/250, Loss: 0.0137\n",
      "Epoch 104/200, Iteration 77/250, Loss: 0.0079\n",
      "Epoch 104/200, Iteration 78/250, Loss: 0.0240\n",
      "Epoch 104/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 104/200, Iteration 80/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 81/250, Loss: 0.0133\n",
      "Epoch 104/200, Iteration 82/250, Loss: 0.0126\n",
      "Epoch 104/200, Iteration 83/250, Loss: 0.0228\n",
      "Epoch 104/200, Iteration 84/250, Loss: 0.0316\n",
      "Epoch 104/200, Iteration 85/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 86/250, Loss: 0.0186\n",
      "Epoch 104/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 104/200, Iteration 88/250, Loss: 0.0278\n",
      "Epoch 104/200, Iteration 89/250, Loss: 0.0338\n",
      "Epoch 104/200, Iteration 90/250, Loss: 0.0139\n",
      "Epoch 104/200, Iteration 91/250, Loss: 0.0141\n",
      "Epoch 104/200, Iteration 92/250, Loss: 0.0165\n",
      "Epoch 104/200, Iteration 93/250, Loss: 0.0118\n",
      "Epoch 104/200, Iteration 94/250, Loss: 0.0344\n",
      "Epoch 104/200, Iteration 95/250, Loss: 0.0165\n",
      "Epoch 104/200, Iteration 96/250, Loss: 0.0124\n",
      "Epoch 104/200, Iteration 97/250, Loss: 0.0112\n",
      "Epoch 104/200, Iteration 98/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 99/250, Loss: 0.0147\n",
      "Epoch 104/200, Iteration 100/250, Loss: 0.0126\n",
      "Epoch 104/200, Iteration 101/250, Loss: 0.0100\n",
      "Epoch 104/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 103/250, Loss: 0.0076\n",
      "Epoch 104/200, Iteration 104/250, Loss: 0.0173\n",
      "Epoch 104/200, Iteration 105/250, Loss: 0.0151\n",
      "Epoch 104/200, Iteration 106/250, Loss: 0.0181\n",
      "Epoch 104/200, Iteration 107/250, Loss: 0.0131\n",
      "Epoch 104/200, Iteration 108/250, Loss: 0.0208\n",
      "Epoch 104/200, Iteration 109/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 110/250, Loss: 0.0242\n",
      "Epoch 104/200, Iteration 111/250, Loss: 0.0167\n",
      "Epoch 104/200, Iteration 112/250, Loss: 0.0159\n",
      "Epoch 104/200, Iteration 113/250, Loss: 0.0188\n",
      "Epoch 104/200, Iteration 114/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 115/250, Loss: 0.0119\n",
      "Epoch 104/200, Iteration 116/250, Loss: 0.0160\n",
      "Epoch 104/200, Iteration 117/250, Loss: 0.0220\n",
      "Epoch 104/200, Iteration 118/250, Loss: 0.0204\n",
      "Epoch 104/200, Iteration 119/250, Loss: 0.0106\n",
      "Epoch 104/200, Iteration 120/250, Loss: 0.0096\n",
      "Epoch 104/200, Iteration 121/250, Loss: 0.0127\n",
      "Epoch 104/200, Iteration 122/250, Loss: 0.0129\n",
      "Epoch 104/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 104/200, Iteration 124/250, Loss: 0.0206\n",
      "Epoch 104/200, Iteration 125/250, Loss: 0.0309\n",
      "Epoch 104/200, Iteration 126/250, Loss: 0.0245\n",
      "Epoch 104/200, Iteration 127/250, Loss: 0.0170\n",
      "Epoch 104/200, Iteration 128/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 129/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 130/250, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 131/250, Loss: 0.0142\n",
      "Epoch 104/200, Iteration 132/250, Loss: 0.0103\n",
      "Epoch 104/200, Iteration 133/250, Loss: 0.0162\n",
      "Epoch 104/200, Iteration 134/250, Loss: 0.0225\n",
      "Epoch 104/200, Iteration 135/250, Loss: 0.0471\n",
      "Epoch 104/200, Iteration 136/250, Loss: 0.0255\n",
      "Epoch 104/200, Iteration 137/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 138/250, Loss: 0.0325\n",
      "Epoch 104/200, Iteration 139/250, Loss: 0.0050\n",
      "Epoch 104/200, Iteration 140/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 141/250, Loss: 0.0078\n",
      "Epoch 104/200, Iteration 142/250, Loss: 0.0105\n",
      "Epoch 104/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 104/200, Iteration 144/250, Loss: 0.0186\n",
      "Epoch 104/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 104/200, Iteration 146/250, Loss: 0.0089\n",
      "Epoch 104/200, Iteration 147/250, Loss: 0.0110\n",
      "Epoch 104/200, Iteration 148/250, Loss: 0.0178\n",
      "Epoch 104/200, Iteration 149/250, Loss: 0.0109\n",
      "Epoch 104/200, Iteration 150/250, Loss: 0.0234\n",
      "Epoch 104/200, Iteration 151/250, Loss: 0.0132\n",
      "Epoch 104/200, Iteration 152/250, Loss: 0.0162\n",
      "Epoch 104/200, Iteration 153/250, Loss: 0.0147\n",
      "Epoch 104/200, Iteration 154/250, Loss: 0.0317\n",
      "Epoch 104/200, Iteration 155/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 156/250, Loss: 0.0394\n",
      "Epoch 104/200, Iteration 157/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 104/200, Iteration 159/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 160/250, Loss: 0.0132\n",
      "Epoch 104/200, Iteration 161/250, Loss: 0.0094\n",
      "Epoch 104/200, Iteration 162/250, Loss: 0.0208\n",
      "Epoch 104/200, Iteration 163/250, Loss: 0.0076\n",
      "Epoch 104/200, Iteration 164/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 165/250, Loss: 0.0306\n",
      "Epoch 104/200, Iteration 166/250, Loss: 0.0175\n",
      "Epoch 104/200, Iteration 167/250, Loss: 0.0100\n",
      "Epoch 104/200, Iteration 168/250, Loss: 0.0209\n",
      "Epoch 104/200, Iteration 169/250, Loss: 0.0311\n",
      "Epoch 104/200, Iteration 170/250, Loss: 0.0278\n",
      "Epoch 104/200, Iteration 171/250, Loss: 0.0252\n",
      "Epoch 104/200, Iteration 172/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 173/250, Loss: 0.0130\n",
      "Epoch 104/200, Iteration 174/250, Loss: 0.0120\n",
      "Epoch 104/200, Iteration 175/250, Loss: 0.0124\n",
      "Epoch 104/200, Iteration 176/250, Loss: 0.0087\n",
      "Epoch 104/200, Iteration 177/250, Loss: 0.0171\n",
      "Epoch 104/200, Iteration 178/250, Loss: 0.0074\n",
      "Epoch 104/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 104/200, Iteration 180/250, Loss: 0.0300\n",
      "Epoch 104/200, Iteration 181/250, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 182/250, Loss: 0.0221\n",
      "Epoch 104/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 104/200, Iteration 184/250, Loss: 0.0144\n",
      "Epoch 104/200, Iteration 185/250, Loss: 0.0155\n",
      "Epoch 104/200, Iteration 186/250, Loss: 0.0113\n",
      "Epoch 104/200, Iteration 187/250, Loss: 0.0209\n",
      "Epoch 104/200, Iteration 188/250, Loss: 0.0101\n",
      "Epoch 104/200, Iteration 189/250, Loss: 0.0113\n",
      "Epoch 104/200, Iteration 190/250, Loss: 0.0117\n",
      "Epoch 104/200, Iteration 191/250, Loss: 0.0107\n",
      "Epoch 104/200, Iteration 192/250, Loss: 0.0072\n",
      "Epoch 104/200, Iteration 193/250, Loss: 0.0135\n",
      "Epoch 104/200, Iteration 194/250, Loss: 0.0072\n",
      "Epoch 104/200, Iteration 195/250, Loss: 0.0191\n",
      "Epoch 104/200, Iteration 196/250, Loss: 0.0225\n",
      "Epoch 104/200, Iteration 197/250, Loss: 0.0152\n",
      "Epoch 104/200, Iteration 198/250, Loss: 0.0082\n",
      "Epoch 104/200, Iteration 199/250, Loss: 0.0089\n",
      "Epoch 104/200, Iteration 200/250, Loss: 0.0405\n",
      "Epoch 104/200, Iteration 201/250, Loss: 0.0099\n",
      "Epoch 104/200, Iteration 202/250, Loss: 0.0226\n",
      "Epoch 104/200, Iteration 203/250, Loss: 0.0081\n",
      "Epoch 104/200, Iteration 204/250, Loss: 0.0114\n",
      "Epoch 104/200, Iteration 205/250, Loss: 0.0242\n",
      "Epoch 104/200, Iteration 206/250, Loss: 0.0218\n",
      "Epoch 104/200, Iteration 207/250, Loss: 0.0192\n",
      "Epoch 104/200, Iteration 208/250, Loss: 0.0079\n",
      "Epoch 104/200, Iteration 209/250, Loss: 0.0122\n",
      "Epoch 104/200, Iteration 210/250, Loss: 0.0138\n",
      "Epoch 104/200, Iteration 211/250, Loss: 0.0164\n",
      "Epoch 104/200, Iteration 212/250, Loss: 0.0145\n",
      "Epoch 104/200, Iteration 213/250, Loss: 0.0167\n",
      "Epoch 104/200, Iteration 214/250, Loss: 0.0191\n",
      "Epoch 104/200, Iteration 215/250, Loss: 0.0084\n",
      "Epoch 104/200, Iteration 216/250, Loss: 0.0065\n",
      "Epoch 104/200, Iteration 217/250, Loss: 0.0216\n",
      "Epoch 104/200, Iteration 218/250, Loss: 0.0227\n",
      "Epoch 104/200, Iteration 219/250, Loss: 0.0078\n",
      "Epoch 104/200, Iteration 220/250, Loss: 0.0213\n",
      "Epoch 104/200, Iteration 221/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 222/250, Loss: 0.0201\n",
      "Epoch 104/200, Iteration 223/250, Loss: 0.0145\n",
      "Epoch 104/200, Iteration 224/250, Loss: 0.0062\n",
      "Epoch 104/200, Iteration 225/250, Loss: 0.0097\n",
      "Epoch 104/200, Iteration 226/250, Loss: 0.0293\n",
      "Epoch 104/200, Iteration 227/250, Loss: 0.0174\n",
      "Epoch 104/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 104/200, Iteration 229/250, Loss: 0.0088\n",
      "Epoch 104/200, Iteration 230/250, Loss: 0.0163\n",
      "Epoch 104/200, Iteration 231/250, Loss: 0.0350\n",
      "Epoch 104/200, Iteration 232/250, Loss: 0.0124\n",
      "Epoch 104/200, Iteration 233/250, Loss: 0.0146\n",
      "Epoch 104/200, Iteration 234/250, Loss: 0.0417\n",
      "Epoch 104/200, Iteration 235/250, Loss: 0.0270\n",
      "Epoch 104/200, Iteration 236/250, Loss: 0.0202\n",
      "Epoch 104/200, Iteration 237/250, Loss: 0.0126\n",
      "Epoch 104/200, Iteration 238/250, Loss: 0.0088\n",
      "Epoch 104/200, Iteration 239/250, Loss: 0.0195\n",
      "Epoch 104/200, Iteration 240/250, Loss: 0.0134\n",
      "Epoch 104/200, Iteration 241/250, Loss: 0.0102\n",
      "Epoch 104/200, Iteration 242/250, Loss: 0.0128\n",
      "Epoch 104/200, Iteration 243/250, Loss: 0.0273\n",
      "Epoch 104/200, Iteration 244/250, Loss: 0.0143\n",
      "Epoch 104/200, Iteration 245/250, Loss: 0.0132\n",
      "Epoch 104/200, Iteration 246/250, Loss: 0.0140\n",
      "Epoch 104/200, Iteration 247/250, Loss: 0.0116\n",
      "Epoch 104/200, Iteration 248/250, Loss: 0.0166\n",
      "Epoch 104/200, Iteration 249/250, Loss: 0.0203\n",
      "Epoch 104/200, Iteration 250/250, Loss: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.36%, Avg loss: 0.006855, MRE: 0.420811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.007471, MRE: 0.532238 \n",
      "\n",
      "Epoch 105/200, Iteration 1/250, Loss: 0.0123\n",
      "Epoch 105/200, Iteration 2/250, Loss: 0.0365\n",
      "Epoch 105/200, Iteration 3/250, Loss: 0.0128\n",
      "Epoch 105/200, Iteration 4/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 105/200, Iteration 6/250, Loss: 0.0162\n",
      "Epoch 105/200, Iteration 7/250, Loss: 0.0110\n",
      "Epoch 105/200, Iteration 8/250, Loss: 0.0139\n",
      "Epoch 105/200, Iteration 9/250, Loss: 0.0186\n",
      "Epoch 105/200, Iteration 10/250, Loss: 0.0202\n",
      "Epoch 105/200, Iteration 11/250, Loss: 0.0089\n",
      "Epoch 105/200, Iteration 12/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 13/250, Loss: 0.0137\n",
      "Epoch 105/200, Iteration 14/250, Loss: 0.0184\n",
      "Epoch 105/200, Iteration 15/250, Loss: 0.0111\n",
      "Epoch 105/200, Iteration 16/250, Loss: 0.0096\n",
      "Epoch 105/200, Iteration 17/250, Loss: 0.0151\n",
      "Epoch 105/200, Iteration 18/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 19/250, Loss: 0.0090\n",
      "Epoch 105/200, Iteration 20/250, Loss: 0.0084\n",
      "Epoch 105/200, Iteration 21/250, Loss: 0.0177\n",
      "Epoch 105/200, Iteration 22/250, Loss: 0.0178\n",
      "Epoch 105/200, Iteration 23/250, Loss: 0.0096\n",
      "Epoch 105/200, Iteration 24/250, Loss: 0.0241\n",
      "Epoch 105/200, Iteration 25/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 26/250, Loss: 0.0134\n",
      "Epoch 105/200, Iteration 27/250, Loss: 0.0290\n",
      "Epoch 105/200, Iteration 28/250, Loss: 0.0125\n",
      "Epoch 105/200, Iteration 29/250, Loss: 0.0228\n",
      "Epoch 105/200, Iteration 30/250, Loss: 0.0110\n",
      "Epoch 105/200, Iteration 31/250, Loss: 0.0227\n",
      "Epoch 105/200, Iteration 32/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 33/250, Loss: 0.0157\n",
      "Epoch 105/200, Iteration 34/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 35/250, Loss: 0.0151\n",
      "Epoch 105/200, Iteration 36/250, Loss: 0.0313\n",
      "Epoch 105/200, Iteration 37/250, Loss: 0.0117\n",
      "Epoch 105/200, Iteration 38/250, Loss: 0.0083\n",
      "Epoch 105/200, Iteration 39/250, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 40/250, Loss: 0.0145\n",
      "Epoch 105/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 105/200, Iteration 42/250, Loss: 0.0075\n",
      "Epoch 105/200, Iteration 43/250, Loss: 0.0160\n",
      "Epoch 105/200, Iteration 44/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 45/250, Loss: 0.0164\n",
      "Epoch 105/200, Iteration 46/250, Loss: 0.0091\n",
      "Epoch 105/200, Iteration 47/250, Loss: 0.0093\n",
      "Epoch 105/200, Iteration 48/250, Loss: 0.0423\n",
      "Epoch 105/200, Iteration 49/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 50/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 51/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 52/250, Loss: 0.0201\n",
      "Epoch 105/200, Iteration 53/250, Loss: 0.0078\n",
      "Epoch 105/200, Iteration 54/250, Loss: 0.0377\n",
      "Epoch 105/200, Iteration 55/250, Loss: 0.0189\n",
      "Epoch 105/200, Iteration 56/250, Loss: 0.0171\n",
      "Epoch 105/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 58/250, Loss: 0.0257\n",
      "Epoch 105/200, Iteration 59/250, Loss: 0.0127\n",
      "Epoch 105/200, Iteration 60/250, Loss: 0.0211\n",
      "Epoch 105/200, Iteration 61/250, Loss: 0.0087\n",
      "Epoch 105/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 105/200, Iteration 63/250, Loss: 0.0181\n",
      "Epoch 105/200, Iteration 64/250, Loss: 0.0107\n",
      "Epoch 105/200, Iteration 65/250, Loss: 0.0178\n",
      "Epoch 105/200, Iteration 66/250, Loss: 0.0186\n",
      "Epoch 105/200, Iteration 67/250, Loss: 0.0164\n",
      "Epoch 105/200, Iteration 68/250, Loss: 0.0128\n",
      "Epoch 105/200, Iteration 69/250, Loss: 0.0076\n",
      "Epoch 105/200, Iteration 70/250, Loss: 0.0122\n",
      "Epoch 105/200, Iteration 71/250, Loss: 0.0158\n",
      "Epoch 105/200, Iteration 72/250, Loss: 0.0171\n",
      "Epoch 105/200, Iteration 73/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 74/250, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 75/250, Loss: 0.0133\n",
      "Epoch 105/200, Iteration 76/250, Loss: 0.0238\n",
      "Epoch 105/200, Iteration 77/250, Loss: 0.0105\n",
      "Epoch 105/200, Iteration 78/250, Loss: 0.0292\n",
      "Epoch 105/200, Iteration 79/250, Loss: 0.0171\n",
      "Epoch 105/200, Iteration 80/250, Loss: 0.0061\n",
      "Epoch 105/200, Iteration 81/250, Loss: 0.0121\n",
      "Epoch 105/200, Iteration 82/250, Loss: 0.0160\n",
      "Epoch 105/200, Iteration 83/250, Loss: 0.0156\n",
      "Epoch 105/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 105/200, Iteration 85/250, Loss: 0.0294\n",
      "Epoch 105/200, Iteration 86/250, Loss: 0.0214\n",
      "Epoch 105/200, Iteration 87/250, Loss: 0.0252\n",
      "Epoch 105/200, Iteration 88/250, Loss: 0.0306\n",
      "Epoch 105/200, Iteration 89/250, Loss: 0.0079\n",
      "Epoch 105/200, Iteration 90/250, Loss: 0.0246\n",
      "Epoch 105/200, Iteration 91/250, Loss: 0.0147\n",
      "Epoch 105/200, Iteration 92/250, Loss: 0.0123\n",
      "Epoch 105/200, Iteration 93/250, Loss: 0.0130\n",
      "Epoch 105/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 105/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 105/200, Iteration 96/250, Loss: 0.0185\n",
      "Epoch 105/200, Iteration 97/250, Loss: 0.0170\n",
      "Epoch 105/200, Iteration 98/250, Loss: 0.0140\n",
      "Epoch 105/200, Iteration 99/250, Loss: 0.0332\n",
      "Epoch 105/200, Iteration 100/250, Loss: 0.0105\n",
      "Epoch 105/200, Iteration 101/250, Loss: 0.0198\n",
      "Epoch 105/200, Iteration 102/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 103/250, Loss: 0.0124\n",
      "Epoch 105/200, Iteration 104/250, Loss: 0.0202\n",
      "Epoch 105/200, Iteration 105/250, Loss: 0.0041\n",
      "Epoch 105/200, Iteration 106/250, Loss: 0.0105\n",
      "Epoch 105/200, Iteration 107/250, Loss: 0.0080\n",
      "Epoch 105/200, Iteration 108/250, Loss: 0.0221\n",
      "Epoch 105/200, Iteration 109/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 110/250, Loss: 0.0091\n",
      "Epoch 105/200, Iteration 111/250, Loss: 0.0098\n",
      "Epoch 105/200, Iteration 112/250, Loss: 0.0129\n",
      "Epoch 105/200, Iteration 113/250, Loss: 0.0159\n",
      "Epoch 105/200, Iteration 114/250, Loss: 0.0110\n",
      "Epoch 105/200, Iteration 115/250, Loss: 0.0130\n",
      "Epoch 105/200, Iteration 116/250, Loss: 0.0196\n",
      "Epoch 105/200, Iteration 117/250, Loss: 0.0166\n",
      "Epoch 105/200, Iteration 118/250, Loss: 0.0109\n",
      "Epoch 105/200, Iteration 119/250, Loss: 0.0247\n",
      "Epoch 105/200, Iteration 120/250, Loss: 0.0082\n",
      "Epoch 105/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 105/200, Iteration 122/250, Loss: 0.0195\n",
      "Epoch 105/200, Iteration 123/250, Loss: 0.0092\n",
      "Epoch 105/200, Iteration 124/250, Loss: 0.0080\n",
      "Epoch 105/200, Iteration 125/250, Loss: 0.0197\n",
      "Epoch 105/200, Iteration 126/250, Loss: 0.0114\n",
      "Epoch 105/200, Iteration 127/250, Loss: 0.0095\n",
      "Epoch 105/200, Iteration 128/250, Loss: 0.0145\n",
      "Epoch 105/200, Iteration 129/250, Loss: 0.0180\n",
      "Epoch 105/200, Iteration 130/250, Loss: 0.0123\n",
      "Epoch 105/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 105/200, Iteration 132/250, Loss: 0.0096\n",
      "Epoch 105/200, Iteration 133/250, Loss: 0.0151\n",
      "Epoch 105/200, Iteration 134/250, Loss: 0.0134\n",
      "Epoch 105/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 105/200, Iteration 136/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 137/250, Loss: 0.0200\n",
      "Epoch 105/200, Iteration 138/250, Loss: 0.0148\n",
      "Epoch 105/200, Iteration 139/250, Loss: 0.0250\n",
      "Epoch 105/200, Iteration 140/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 141/250, Loss: 0.0067\n",
      "Epoch 105/200, Iteration 142/250, Loss: 0.0118\n",
      "Epoch 105/200, Iteration 143/250, Loss: 0.0089\n",
      "Epoch 105/200, Iteration 144/250, Loss: 0.0106\n",
      "Epoch 105/200, Iteration 145/250, Loss: 0.0086\n",
      "Epoch 105/200, Iteration 146/250, Loss: 0.0115\n",
      "Epoch 105/200, Iteration 147/250, Loss: 0.0114\n",
      "Epoch 105/200, Iteration 148/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 149/250, Loss: 0.0090\n",
      "Epoch 105/200, Iteration 150/250, Loss: 0.0203\n",
      "Epoch 105/200, Iteration 151/250, Loss: 0.0158\n",
      "Epoch 105/200, Iteration 152/250, Loss: 0.0202\n",
      "Epoch 105/200, Iteration 153/250, Loss: 0.0178\n",
      "Epoch 105/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 105/200, Iteration 155/250, Loss: 0.0099\n",
      "Epoch 105/200, Iteration 156/250, Loss: 0.0161\n",
      "Epoch 105/200, Iteration 157/250, Loss: 0.0296\n",
      "Epoch 105/200, Iteration 158/250, Loss: 0.0377\n",
      "Epoch 105/200, Iteration 159/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 105/200, Iteration 161/250, Loss: 0.0112\n",
      "Epoch 105/200, Iteration 162/250, Loss: 0.0164\n",
      "Epoch 105/200, Iteration 163/250, Loss: 0.0288\n",
      "Epoch 105/200, Iteration 164/250, Loss: 0.0097\n",
      "Epoch 105/200, Iteration 165/250, Loss: 0.0389\n",
      "Epoch 105/200, Iteration 166/250, Loss: 0.0175\n",
      "Epoch 105/200, Iteration 167/250, Loss: 0.0175\n",
      "Epoch 105/200, Iteration 168/250, Loss: 0.0247\n",
      "Epoch 105/200, Iteration 169/250, Loss: 0.0169\n",
      "Epoch 105/200, Iteration 170/250, Loss: 0.0131\n",
      "Epoch 105/200, Iteration 171/250, Loss: 0.0213\n",
      "Epoch 105/200, Iteration 172/250, Loss: 0.0059\n",
      "Epoch 105/200, Iteration 173/250, Loss: 0.0104\n",
      "Epoch 105/200, Iteration 174/250, Loss: 0.0195\n",
      "Epoch 105/200, Iteration 175/250, Loss: 0.0061\n",
      "Epoch 105/200, Iteration 176/250, Loss: 0.0071\n",
      "Epoch 105/200, Iteration 177/250, Loss: 0.0133\n",
      "Epoch 105/200, Iteration 178/250, Loss: 0.0120\n",
      "Epoch 105/200, Iteration 179/250, Loss: 0.0101\n",
      "Epoch 105/200, Iteration 180/250, Loss: 0.0146\n",
      "Epoch 105/200, Iteration 181/250, Loss: 0.0126\n",
      "Epoch 105/200, Iteration 182/250, Loss: 0.0227\n",
      "Epoch 105/200, Iteration 183/250, Loss: 0.0070\n",
      "Epoch 105/200, Iteration 184/250, Loss: 0.0111\n",
      "Epoch 105/200, Iteration 185/250, Loss: 0.0296\n",
      "Epoch 105/200, Iteration 186/250, Loss: 0.0335\n",
      "Epoch 105/200, Iteration 187/250, Loss: 0.0070\n",
      "Epoch 105/200, Iteration 188/250, Loss: 0.0248\n",
      "Epoch 105/200, Iteration 189/250, Loss: 0.0196\n",
      "Epoch 105/200, Iteration 190/250, Loss: 0.0161\n",
      "Epoch 105/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 105/200, Iteration 192/250, Loss: 0.0150\n",
      "Epoch 105/200, Iteration 193/250, Loss: 0.0062\n",
      "Epoch 105/200, Iteration 194/250, Loss: 0.0143\n",
      "Epoch 105/200, Iteration 195/250, Loss: 0.0222\n",
      "Epoch 105/200, Iteration 196/250, Loss: 0.0150\n",
      "Epoch 105/200, Iteration 197/250, Loss: 0.0190\n",
      "Epoch 105/200, Iteration 198/250, Loss: 0.0243\n",
      "Epoch 105/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 105/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 105/200, Iteration 201/250, Loss: 0.0272\n",
      "Epoch 105/200, Iteration 202/250, Loss: 0.0138\n",
      "Epoch 105/200, Iteration 203/250, Loss: 0.0253\n",
      "Epoch 105/200, Iteration 204/250, Loss: 0.0205\n",
      "Epoch 105/200, Iteration 205/250, Loss: 0.0137\n",
      "Epoch 105/200, Iteration 206/250, Loss: 0.0269\n",
      "Epoch 105/200, Iteration 207/250, Loss: 0.0100\n",
      "Epoch 105/200, Iteration 208/250, Loss: 0.0131\n",
      "Epoch 105/200, Iteration 209/250, Loss: 0.0067\n",
      "Epoch 105/200, Iteration 210/250, Loss: 0.0142\n",
      "Epoch 105/200, Iteration 211/250, Loss: 0.0310\n",
      "Epoch 105/200, Iteration 212/250, Loss: 0.0167\n",
      "Epoch 105/200, Iteration 213/250, Loss: 0.0152\n",
      "Epoch 105/200, Iteration 214/250, Loss: 0.0104\n",
      "Epoch 105/200, Iteration 215/250, Loss: 0.0131\n",
      "Epoch 105/200, Iteration 216/250, Loss: 0.0106\n",
      "Epoch 105/200, Iteration 217/250, Loss: 0.0145\n",
      "Epoch 105/200, Iteration 218/250, Loss: 0.0061\n",
      "Epoch 105/200, Iteration 219/250, Loss: 0.0280\n",
      "Epoch 105/200, Iteration 220/250, Loss: 0.0087\n",
      "Epoch 105/200, Iteration 221/250, Loss: 0.0239\n",
      "Epoch 105/200, Iteration 222/250, Loss: 0.0116\n",
      "Epoch 105/200, Iteration 223/250, Loss: 0.0450\n",
      "Epoch 105/200, Iteration 224/250, Loss: 0.0136\n",
      "Epoch 105/200, Iteration 225/250, Loss: 0.0085\n",
      "Epoch 105/200, Iteration 226/250, Loss: 0.0106\n",
      "Epoch 105/200, Iteration 227/250, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200, Iteration 228/250, Loss: 0.0090\n",
      "Epoch 105/200, Iteration 229/250, Loss: 0.0165\n",
      "Epoch 105/200, Iteration 230/250, Loss: 0.0173\n",
      "Epoch 105/200, Iteration 231/250, Loss: 0.0132\n",
      "Epoch 105/200, Iteration 232/250, Loss: 0.0180\n",
      "Epoch 105/200, Iteration 233/250, Loss: 0.0189\n",
      "Epoch 105/200, Iteration 234/250, Loss: 0.0231\n",
      "Epoch 105/200, Iteration 235/250, Loss: 0.0151\n",
      "Epoch 105/200, Iteration 236/250, Loss: 0.0094\n",
      "Epoch 105/200, Iteration 237/250, Loss: 0.0156\n",
      "Epoch 105/200, Iteration 238/250, Loss: 0.0169\n",
      "Epoch 105/200, Iteration 239/250, Loss: 0.0125\n",
      "Epoch 105/200, Iteration 240/250, Loss: 0.0199\n",
      "Epoch 105/200, Iteration 241/250, Loss: 0.0261\n",
      "Epoch 105/200, Iteration 242/250, Loss: 0.0296\n",
      "Epoch 105/200, Iteration 243/250, Loss: 0.0066\n",
      "Epoch 105/200, Iteration 244/250, Loss: 0.0144\n",
      "Epoch 105/200, Iteration 245/250, Loss: 0.0311\n",
      "Epoch 105/200, Iteration 246/250, Loss: 0.0098\n",
      "Epoch 105/200, Iteration 247/250, Loss: 0.0108\n",
      "Epoch 105/200, Iteration 248/250, Loss: 0.0237\n",
      "Epoch 105/200, Iteration 249/250, Loss: 0.0266\n",
      "Epoch 105/200, Iteration 250/250, Loss: 0.0067\n",
      "Train Error: \n",
      " Accuracy: 78.59%, Avg loss: 0.007414, MRE: 0.533287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.007822, MRE: 0.564247 \n",
      "\n",
      "Epoch 106/200, Iteration 1/250, Loss: 0.0199\n",
      "Epoch 106/200, Iteration 2/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 3/250, Loss: 0.0164\n",
      "Epoch 106/200, Iteration 4/250, Loss: 0.0142\n",
      "Epoch 106/200, Iteration 5/250, Loss: 0.0180\n",
      "Epoch 106/200, Iteration 6/250, Loss: 0.0090\n",
      "Epoch 106/200, Iteration 7/250, Loss: 0.0072\n",
      "Epoch 106/200, Iteration 8/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 9/250, Loss: 0.0132\n",
      "Epoch 106/200, Iteration 10/250, Loss: 0.0093\n",
      "Epoch 106/200, Iteration 11/250, Loss: 0.0197\n",
      "Epoch 106/200, Iteration 12/250, Loss: 0.0305\n",
      "Epoch 106/200, Iteration 13/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 14/250, Loss: 0.0226\n",
      "Epoch 106/200, Iteration 15/250, Loss: 0.0082\n",
      "Epoch 106/200, Iteration 16/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 17/250, Loss: 0.0094\n",
      "Epoch 106/200, Iteration 18/250, Loss: 0.0161\n",
      "Epoch 106/200, Iteration 19/250, Loss: 0.0156\n",
      "Epoch 106/200, Iteration 20/250, Loss: 0.0138\n",
      "Epoch 106/200, Iteration 21/250, Loss: 0.0303\n",
      "Epoch 106/200, Iteration 22/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 24/250, Loss: 0.0158\n",
      "Epoch 106/200, Iteration 25/250, Loss: 0.0124\n",
      "Epoch 106/200, Iteration 26/250, Loss: 0.0078\n",
      "Epoch 106/200, Iteration 27/250, Loss: 0.0189\n",
      "Epoch 106/200, Iteration 28/250, Loss: 0.0092\n",
      "Epoch 106/200, Iteration 29/250, Loss: 0.0093\n",
      "Epoch 106/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 106/200, Iteration 31/250, Loss: 0.0121\n",
      "Epoch 106/200, Iteration 32/250, Loss: 0.0189\n",
      "Epoch 106/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 106/200, Iteration 34/250, Loss: 0.0157\n",
      "Epoch 106/200, Iteration 35/250, Loss: 0.0208\n",
      "Epoch 106/200, Iteration 36/250, Loss: 0.0197\n",
      "Epoch 106/200, Iteration 37/250, Loss: 0.0308\n",
      "Epoch 106/200, Iteration 38/250, Loss: 0.0120\n",
      "Epoch 106/200, Iteration 39/250, Loss: 0.0326\n",
      "Epoch 106/200, Iteration 40/250, Loss: 0.0178\n",
      "Epoch 106/200, Iteration 41/250, Loss: 0.0119\n",
      "Epoch 106/200, Iteration 42/250, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 43/250, Loss: 0.0307\n",
      "Epoch 106/200, Iteration 44/250, Loss: 0.0239\n",
      "Epoch 106/200, Iteration 45/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 46/250, Loss: 0.0378\n",
      "Epoch 106/200, Iteration 47/250, Loss: 0.0078\n",
      "Epoch 106/200, Iteration 48/250, Loss: 0.0153\n",
      "Epoch 106/200, Iteration 49/250, Loss: 0.0086\n",
      "Epoch 106/200, Iteration 50/250, Loss: 0.0257\n",
      "Epoch 106/200, Iteration 51/250, Loss: 0.0192\n",
      "Epoch 106/200, Iteration 52/250, Loss: 0.0096\n",
      "Epoch 106/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 106/200, Iteration 54/250, Loss: 0.0147\n",
      "Epoch 106/200, Iteration 55/250, Loss: 0.0077\n",
      "Epoch 106/200, Iteration 56/250, Loss: 0.0083\n",
      "Epoch 106/200, Iteration 57/250, Loss: 0.0224\n",
      "Epoch 106/200, Iteration 58/250, Loss: 0.0131\n",
      "Epoch 106/200, Iteration 59/250, Loss: 0.0142\n",
      "Epoch 106/200, Iteration 60/250, Loss: 0.0153\n",
      "Epoch 106/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 106/200, Iteration 62/250, Loss: 0.0199\n",
      "Epoch 106/200, Iteration 63/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 64/250, Loss: 0.0173\n",
      "Epoch 106/200, Iteration 65/250, Loss: 0.0306\n",
      "Epoch 106/200, Iteration 66/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 67/250, Loss: 0.0124\n",
      "Epoch 106/200, Iteration 68/250, Loss: 0.0228\n",
      "Epoch 106/200, Iteration 69/250, Loss: 0.0153\n",
      "Epoch 106/200, Iteration 70/250, Loss: 0.0090\n",
      "Epoch 106/200, Iteration 71/250, Loss: 0.0255\n",
      "Epoch 106/200, Iteration 72/250, Loss: 0.0072\n",
      "Epoch 106/200, Iteration 73/250, Loss: 0.0101\n",
      "Epoch 106/200, Iteration 74/250, Loss: 0.0136\n",
      "Epoch 106/200, Iteration 75/250, Loss: 0.0115\n",
      "Epoch 106/200, Iteration 76/250, Loss: 0.0096\n",
      "Epoch 106/200, Iteration 77/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 78/250, Loss: 0.0292\n",
      "Epoch 106/200, Iteration 79/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 80/250, Loss: 0.0144\n",
      "Epoch 106/200, Iteration 81/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 82/250, Loss: 0.0147\n",
      "Epoch 106/200, Iteration 83/250, Loss: 0.0073\n",
      "Epoch 106/200, Iteration 84/250, Loss: 0.0141\n",
      "Epoch 106/200, Iteration 85/250, Loss: 0.0138\n",
      "Epoch 106/200, Iteration 86/250, Loss: 0.0215\n",
      "Epoch 106/200, Iteration 87/250, Loss: 0.0156\n",
      "Epoch 106/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 106/200, Iteration 89/250, Loss: 0.0282\n",
      "Epoch 106/200, Iteration 90/250, Loss: 0.0186\n",
      "Epoch 106/200, Iteration 91/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 92/250, Loss: 0.0172\n",
      "Epoch 106/200, Iteration 93/250, Loss: 0.0244\n",
      "Epoch 106/200, Iteration 94/250, Loss: 0.0191\n",
      "Epoch 106/200, Iteration 95/250, Loss: 0.0095\n",
      "Epoch 106/200, Iteration 96/250, Loss: 0.0262\n",
      "Epoch 106/200, Iteration 97/250, Loss: 0.0187\n",
      "Epoch 106/200, Iteration 98/250, Loss: 0.0174\n",
      "Epoch 106/200, Iteration 99/250, Loss: 0.0156\n",
      "Epoch 106/200, Iteration 100/250, Loss: 0.0074\n",
      "Epoch 106/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 106/200, Iteration 102/250, Loss: 0.0061\n",
      "Epoch 106/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 106/200, Iteration 104/250, Loss: 0.0221\n",
      "Epoch 106/200, Iteration 105/250, Loss: 0.0180\n",
      "Epoch 106/200, Iteration 106/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 107/250, Loss: 0.0222\n",
      "Epoch 106/200, Iteration 108/250, Loss: 0.0196\n",
      "Epoch 106/200, Iteration 109/250, Loss: 0.0183\n",
      "Epoch 106/200, Iteration 110/250, Loss: 0.0154\n",
      "Epoch 106/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 106/200, Iteration 112/250, Loss: 0.0081\n",
      "Epoch 106/200, Iteration 113/250, Loss: 0.0178\n",
      "Epoch 106/200, Iteration 114/250, Loss: 0.0143\n",
      "Epoch 106/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 106/200, Iteration 116/250, Loss: 0.0140\n",
      "Epoch 106/200, Iteration 117/250, Loss: 0.0080\n",
      "Epoch 106/200, Iteration 118/250, Loss: 0.0139\n",
      "Epoch 106/200, Iteration 119/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 120/250, Loss: 0.0141\n",
      "Epoch 106/200, Iteration 121/250, Loss: 0.0063\n",
      "Epoch 106/200, Iteration 122/250, Loss: 0.0102\n",
      "Epoch 106/200, Iteration 123/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 124/250, Loss: 0.0166\n",
      "Epoch 106/200, Iteration 125/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 126/250, Loss: 0.0117\n",
      "Epoch 106/200, Iteration 127/250, Loss: 0.0062\n",
      "Epoch 106/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 106/200, Iteration 129/250, Loss: 0.0126\n",
      "Epoch 106/200, Iteration 130/250, Loss: 0.0083\n",
      "Epoch 106/200, Iteration 131/250, Loss: 0.0104\n",
      "Epoch 106/200, Iteration 132/250, Loss: 0.0152\n",
      "Epoch 106/200, Iteration 133/250, Loss: 0.0404\n",
      "Epoch 106/200, Iteration 134/250, Loss: 0.0231\n",
      "Epoch 106/200, Iteration 135/250, Loss: 0.0243\n",
      "Epoch 106/200, Iteration 136/250, Loss: 0.0179\n",
      "Epoch 106/200, Iteration 137/250, Loss: 0.0155\n",
      "Epoch 106/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 106/200, Iteration 139/250, Loss: 0.0130\n",
      "Epoch 106/200, Iteration 140/250, Loss: 0.0164\n",
      "Epoch 106/200, Iteration 141/250, Loss: 0.0210\n",
      "Epoch 106/200, Iteration 142/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 143/250, Loss: 0.0084\n",
      "Epoch 106/200, Iteration 144/250, Loss: 0.0080\n",
      "Epoch 106/200, Iteration 145/250, Loss: 0.0117\n",
      "Epoch 106/200, Iteration 146/250, Loss: 0.0106\n",
      "Epoch 106/200, Iteration 147/250, Loss: 0.0105\n",
      "Epoch 106/200, Iteration 148/250, Loss: 0.0214\n",
      "Epoch 106/200, Iteration 149/250, Loss: 0.0249\n",
      "Epoch 106/200, Iteration 150/250, Loss: 0.0261\n",
      "Epoch 106/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 106/200, Iteration 153/250, Loss: 0.0198\n",
      "Epoch 106/200, Iteration 154/250, Loss: 0.0242\n",
      "Epoch 106/200, Iteration 155/250, Loss: 0.0107\n",
      "Epoch 106/200, Iteration 156/250, Loss: 0.0281\n",
      "Epoch 106/200, Iteration 157/250, Loss: 0.0082\n",
      "Epoch 106/200, Iteration 158/250, Loss: 0.0122\n",
      "Epoch 106/200, Iteration 159/250, Loss: 0.0201\n",
      "Epoch 106/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 106/200, Iteration 161/250, Loss: 0.0096\n",
      "Epoch 106/200, Iteration 162/250, Loss: 0.0176\n",
      "Epoch 106/200, Iteration 163/250, Loss: 0.0403\n",
      "Epoch 106/200, Iteration 164/250, Loss: 0.0408\n",
      "Epoch 106/200, Iteration 165/250, Loss: 0.0160\n",
      "Epoch 106/200, Iteration 166/250, Loss: 0.0241\n",
      "Epoch 106/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 168/250, Loss: 0.0185\n",
      "Epoch 106/200, Iteration 169/250, Loss: 0.0122\n",
      "Epoch 106/200, Iteration 170/250, Loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 106/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 173/250, Loss: 0.0180\n",
      "Epoch 106/200, Iteration 174/250, Loss: 0.0102\n",
      "Epoch 106/200, Iteration 175/250, Loss: 0.0131\n",
      "Epoch 106/200, Iteration 176/250, Loss: 0.0161\n",
      "Epoch 106/200, Iteration 177/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 178/250, Loss: 0.0242\n",
      "Epoch 106/200, Iteration 179/250, Loss: 0.0149\n",
      "Epoch 106/200, Iteration 180/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 181/250, Loss: 0.0185\n",
      "Epoch 106/200, Iteration 182/250, Loss: 0.0087\n",
      "Epoch 106/200, Iteration 183/250, Loss: 0.0143\n",
      "Epoch 106/200, Iteration 184/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 185/250, Loss: 0.0361\n",
      "Epoch 106/200, Iteration 186/250, Loss: 0.0109\n",
      "Epoch 106/200, Iteration 187/250, Loss: 0.0060\n",
      "Epoch 106/200, Iteration 188/250, Loss: 0.0181\n",
      "Epoch 106/200, Iteration 189/250, Loss: 0.0088\n",
      "Epoch 106/200, Iteration 190/250, Loss: 0.0068\n",
      "Epoch 106/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 106/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 193/250, Loss: 0.0172\n",
      "Epoch 106/200, Iteration 194/250, Loss: 0.0281\n",
      "Epoch 106/200, Iteration 195/250, Loss: 0.0202\n",
      "Epoch 106/200, Iteration 196/250, Loss: 0.0099\n",
      "Epoch 106/200, Iteration 197/250, Loss: 0.0089\n",
      "Epoch 106/200, Iteration 198/250, Loss: 0.0098\n",
      "Epoch 106/200, Iteration 199/250, Loss: 0.0067\n",
      "Epoch 106/200, Iteration 200/250, Loss: 0.0177\n",
      "Epoch 106/200, Iteration 201/250, Loss: 0.0072\n",
      "Epoch 106/200, Iteration 202/250, Loss: 0.0225\n",
      "Epoch 106/200, Iteration 203/250, Loss: 0.0170\n",
      "Epoch 106/200, Iteration 204/250, Loss: 0.0143\n",
      "Epoch 106/200, Iteration 205/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 206/250, Loss: 0.0228\n",
      "Epoch 106/200, Iteration 207/250, Loss: 0.0149\n",
      "Epoch 106/200, Iteration 208/250, Loss: 0.0194\n",
      "Epoch 106/200, Iteration 209/250, Loss: 0.0308\n",
      "Epoch 106/200, Iteration 210/250, Loss: 0.0135\n",
      "Epoch 106/200, Iteration 211/250, Loss: 0.0178\n",
      "Epoch 106/200, Iteration 212/250, Loss: 0.0138\n",
      "Epoch 106/200, Iteration 213/250, Loss: 0.0295\n",
      "Epoch 106/200, Iteration 214/250, Loss: 0.0157\n",
      "Epoch 106/200, Iteration 215/250, Loss: 0.0313\n",
      "Epoch 106/200, Iteration 216/250, Loss: 0.0245\n",
      "Epoch 106/200, Iteration 217/250, Loss: 0.0103\n",
      "Epoch 106/200, Iteration 218/250, Loss: 0.0130\n",
      "Epoch 106/200, Iteration 219/250, Loss: 0.0124\n",
      "Epoch 106/200, Iteration 220/250, Loss: 0.0228\n",
      "Epoch 106/200, Iteration 221/250, Loss: 0.0106\n",
      "Epoch 106/200, Iteration 222/250, Loss: 0.0120\n",
      "Epoch 106/200, Iteration 223/250, Loss: 0.0070\n",
      "Epoch 106/200, Iteration 224/250, Loss: 0.0132\n",
      "Epoch 106/200, Iteration 225/250, Loss: 0.0194\n",
      "Epoch 106/200, Iteration 226/250, Loss: 0.0097\n",
      "Epoch 106/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 106/200, Iteration 228/250, Loss: 0.0121\n",
      "Epoch 106/200, Iteration 229/250, Loss: 0.0073\n",
      "Epoch 106/200, Iteration 230/250, Loss: 0.0114\n",
      "Epoch 106/200, Iteration 231/250, Loss: 0.0134\n",
      "Epoch 106/200, Iteration 232/250, Loss: 0.0244\n",
      "Epoch 106/200, Iteration 233/250, Loss: 0.0139\n",
      "Epoch 106/200, Iteration 234/250, Loss: 0.0204\n",
      "Epoch 106/200, Iteration 235/250, Loss: 0.0100\n",
      "Epoch 106/200, Iteration 236/250, Loss: 0.0091\n",
      "Epoch 106/200, Iteration 237/250, Loss: 0.0175\n",
      "Epoch 106/200, Iteration 238/250, Loss: 0.0121\n",
      "Epoch 106/200, Iteration 239/250, Loss: 0.0119\n",
      "Epoch 106/200, Iteration 240/250, Loss: 0.0297\n",
      "Epoch 106/200, Iteration 241/250, Loss: 0.0085\n",
      "Epoch 106/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 106/200, Iteration 243/250, Loss: 0.0173\n",
      "Epoch 106/200, Iteration 244/250, Loss: 0.0092\n",
      "Epoch 106/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 106/200, Iteration 246/250, Loss: 0.0122\n",
      "Epoch 106/200, Iteration 247/250, Loss: 0.0165\n",
      "Epoch 106/200, Iteration 248/250, Loss: 0.0112\n",
      "Epoch 106/200, Iteration 249/250, Loss: 0.0084\n",
      "Epoch 106/200, Iteration 250/250, Loss: 0.0158\n",
      "Train Error: \n",
      " Accuracy: 91.26%, Avg loss: 0.006818, MRE: 0.414458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.007377, MRE: 0.538701 \n",
      "\n",
      "Epoch 107/200, Iteration 1/250, Loss: 0.0135\n",
      "Epoch 107/200, Iteration 2/250, Loss: 0.0216\n",
      "Epoch 107/200, Iteration 3/250, Loss: 0.0094\n",
      "Epoch 107/200, Iteration 4/250, Loss: 0.0114\n",
      "Epoch 107/200, Iteration 5/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 6/250, Loss: 0.0068\n",
      "Epoch 107/200, Iteration 7/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 8/250, Loss: 0.0260\n",
      "Epoch 107/200, Iteration 9/250, Loss: 0.0131\n",
      "Epoch 107/200, Iteration 10/250, Loss: 0.0130\n",
      "Epoch 107/200, Iteration 11/250, Loss: 0.0317\n",
      "Epoch 107/200, Iteration 12/250, Loss: 0.0237\n",
      "Epoch 107/200, Iteration 13/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 14/250, Loss: 0.0085\n",
      "Epoch 107/200, Iteration 15/250, Loss: 0.0080\n",
      "Epoch 107/200, Iteration 16/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 17/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 18/250, Loss: 0.0218\n",
      "Epoch 107/200, Iteration 19/250, Loss: 0.0127\n",
      "Epoch 107/200, Iteration 20/250, Loss: 0.0061\n",
      "Epoch 107/200, Iteration 21/250, Loss: 0.0114\n",
      "Epoch 107/200, Iteration 22/250, Loss: 0.0070\n",
      "Epoch 107/200, Iteration 23/250, Loss: 0.0099\n",
      "Epoch 107/200, Iteration 24/250, Loss: 0.0188\n",
      "Epoch 107/200, Iteration 25/250, Loss: 0.0254\n",
      "Epoch 107/200, Iteration 26/250, Loss: 0.0110\n",
      "Epoch 107/200, Iteration 27/250, Loss: 0.0096\n",
      "Epoch 107/200, Iteration 28/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 29/250, Loss: 0.0252\n",
      "Epoch 107/200, Iteration 30/250, Loss: 0.0144\n",
      "Epoch 107/200, Iteration 31/250, Loss: 0.0133\n",
      "Epoch 107/200, Iteration 32/250, Loss: 0.0137\n",
      "Epoch 107/200, Iteration 33/250, Loss: 0.0285\n",
      "Epoch 107/200, Iteration 34/250, Loss: 0.0128\n",
      "Epoch 107/200, Iteration 35/250, Loss: 0.0128\n",
      "Epoch 107/200, Iteration 36/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 37/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 38/250, Loss: 0.0167\n",
      "Epoch 107/200, Iteration 39/250, Loss: 0.0248\n",
      "Epoch 107/200, Iteration 40/250, Loss: 0.0175\n",
      "Epoch 107/200, Iteration 41/250, Loss: 0.0203\n",
      "Epoch 107/200, Iteration 42/250, Loss: 0.0155\n",
      "Epoch 107/200, Iteration 43/250, Loss: 0.0273\n",
      "Epoch 107/200, Iteration 44/250, Loss: 0.0212\n",
      "Epoch 107/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 46/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 47/250, Loss: 0.0152\n",
      "Epoch 107/200, Iteration 48/250, Loss: 0.0113\n",
      "Epoch 107/200, Iteration 49/250, Loss: 0.0127\n",
      "Epoch 107/200, Iteration 50/250, Loss: 0.0133\n",
      "Epoch 107/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 107/200, Iteration 52/250, Loss: 0.0093\n",
      "Epoch 107/200, Iteration 53/250, Loss: 0.0237\n",
      "Epoch 107/200, Iteration 54/250, Loss: 0.0131\n",
      "Epoch 107/200, Iteration 55/250, Loss: 0.0211\n",
      "Epoch 107/200, Iteration 56/250, Loss: 0.0105\n",
      "Epoch 107/200, Iteration 57/250, Loss: 0.0136\n",
      "Epoch 107/200, Iteration 58/250, Loss: 0.0147\n",
      "Epoch 107/200, Iteration 59/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 60/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 61/250, Loss: 0.0136\n",
      "Epoch 107/200, Iteration 62/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 63/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 64/250, Loss: 0.0379\n",
      "Epoch 107/200, Iteration 65/250, Loss: 0.0206\n",
      "Epoch 107/200, Iteration 66/250, Loss: 0.0071\n",
      "Epoch 107/200, Iteration 67/250, Loss: 0.0143\n",
      "Epoch 107/200, Iteration 68/250, Loss: 0.0178\n",
      "Epoch 107/200, Iteration 69/250, Loss: 0.0074\n",
      "Epoch 107/200, Iteration 70/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 71/250, Loss: 0.0376\n",
      "Epoch 107/200, Iteration 72/250, Loss: 0.0098\n",
      "Epoch 107/200, Iteration 73/250, Loss: 0.0171\n",
      "Epoch 107/200, Iteration 74/250, Loss: 0.0146\n",
      "Epoch 107/200, Iteration 75/250, Loss: 0.0320\n",
      "Epoch 107/200, Iteration 76/250, Loss: 0.0098\n",
      "Epoch 107/200, Iteration 77/250, Loss: 0.0209\n",
      "Epoch 107/200, Iteration 78/250, Loss: 0.0082\n",
      "Epoch 107/200, Iteration 79/250, Loss: 0.0183\n",
      "Epoch 107/200, Iteration 80/250, Loss: 0.0165\n",
      "Epoch 107/200, Iteration 81/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 82/250, Loss: 0.0083\n",
      "Epoch 107/200, Iteration 83/250, Loss: 0.0133\n",
      "Epoch 107/200, Iteration 84/250, Loss: 0.0175\n",
      "Epoch 107/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 86/250, Loss: 0.0106\n",
      "Epoch 107/200, Iteration 87/250, Loss: 0.0140\n",
      "Epoch 107/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 107/200, Iteration 89/250, Loss: 0.0175\n",
      "Epoch 107/200, Iteration 90/250, Loss: 0.0163\n",
      "Epoch 107/200, Iteration 91/250, Loss: 0.0294\n",
      "Epoch 107/200, Iteration 92/250, Loss: 0.0105\n",
      "Epoch 107/200, Iteration 93/250, Loss: 0.0129\n",
      "Epoch 107/200, Iteration 94/250, Loss: 0.0135\n",
      "Epoch 107/200, Iteration 95/250, Loss: 0.0291\n",
      "Epoch 107/200, Iteration 96/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 97/250, Loss: 0.0204\n",
      "Epoch 107/200, Iteration 98/250, Loss: 0.0194\n",
      "Epoch 107/200, Iteration 99/250, Loss: 0.0139\n",
      "Epoch 107/200, Iteration 100/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 101/250, Loss: 0.0186\n",
      "Epoch 107/200, Iteration 102/250, Loss: 0.0110\n",
      "Epoch 107/200, Iteration 103/250, Loss: 0.0446\n",
      "Epoch 107/200, Iteration 104/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 105/250, Loss: 0.0179\n",
      "Epoch 107/200, Iteration 106/250, Loss: 0.0071\n",
      "Epoch 107/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 107/200, Iteration 108/250, Loss: 0.0199\n",
      "Epoch 107/200, Iteration 109/250, Loss: 0.0103\n",
      "Epoch 107/200, Iteration 110/250, Loss: 0.0199\n",
      "Epoch 107/200, Iteration 111/250, Loss: 0.0163\n",
      "Epoch 107/200, Iteration 112/250, Loss: 0.0072\n",
      "Epoch 107/200, Iteration 113/250, Loss: 0.0333\n",
      "Epoch 107/200, Iteration 114/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 115/250, Loss: 0.0241\n",
      "Epoch 107/200, Iteration 116/250, Loss: 0.0171\n",
      "Epoch 107/200, Iteration 117/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200, Iteration 118/250, Loss: 0.0114\n",
      "Epoch 107/200, Iteration 119/250, Loss: 0.0168\n",
      "Epoch 107/200, Iteration 120/250, Loss: 0.0093\n",
      "Epoch 107/200, Iteration 121/250, Loss: 0.0078\n",
      "Epoch 107/200, Iteration 122/250, Loss: 0.0097\n",
      "Epoch 107/200, Iteration 123/250, Loss: 0.0294\n",
      "Epoch 107/200, Iteration 124/250, Loss: 0.0080\n",
      "Epoch 107/200, Iteration 125/250, Loss: 0.0237\n",
      "Epoch 107/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 127/250, Loss: 0.0172\n",
      "Epoch 107/200, Iteration 128/250, Loss: 0.0181\n",
      "Epoch 107/200, Iteration 129/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 130/250, Loss: 0.0238\n",
      "Epoch 107/200, Iteration 131/250, Loss: 0.0561\n",
      "Epoch 107/200, Iteration 132/250, Loss: 0.0244\n",
      "Epoch 107/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 107/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 107/200, Iteration 135/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 136/250, Loss: 0.0313\n",
      "Epoch 107/200, Iteration 137/250, Loss: 0.0251\n",
      "Epoch 107/200, Iteration 138/250, Loss: 0.0080\n",
      "Epoch 107/200, Iteration 139/250, Loss: 0.0269\n",
      "Epoch 107/200, Iteration 140/250, Loss: 0.0117\n",
      "Epoch 107/200, Iteration 141/250, Loss: 0.0158\n",
      "Epoch 107/200, Iteration 142/250, Loss: 0.0130\n",
      "Epoch 107/200, Iteration 143/250, Loss: 0.0193\n",
      "Epoch 107/200, Iteration 144/250, Loss: 0.0200\n",
      "Epoch 107/200, Iteration 145/250, Loss: 0.0130\n",
      "Epoch 107/200, Iteration 146/250, Loss: 0.0240\n",
      "Epoch 107/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 107/200, Iteration 148/250, Loss: 0.0163\n",
      "Epoch 107/200, Iteration 149/250, Loss: 0.0084\n",
      "Epoch 107/200, Iteration 150/250, Loss: 0.0155\n",
      "Epoch 107/200, Iteration 151/250, Loss: 0.0131\n",
      "Epoch 107/200, Iteration 152/250, Loss: 0.0214\n",
      "Epoch 107/200, Iteration 153/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 154/250, Loss: 0.0105\n",
      "Epoch 107/200, Iteration 155/250, Loss: 0.0222\n",
      "Epoch 107/200, Iteration 156/250, Loss: 0.0099\n",
      "Epoch 107/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 107/200, Iteration 158/250, Loss: 0.0110\n",
      "Epoch 107/200, Iteration 159/250, Loss: 0.0081\n",
      "Epoch 107/200, Iteration 160/250, Loss: 0.0093\n",
      "Epoch 107/200, Iteration 161/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 162/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 163/250, Loss: 0.0144\n",
      "Epoch 107/200, Iteration 164/250, Loss: 0.0258\n",
      "Epoch 107/200, Iteration 165/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 166/250, Loss: 0.0189\n",
      "Epoch 107/200, Iteration 167/250, Loss: 0.0069\n",
      "Epoch 107/200, Iteration 168/250, Loss: 0.0101\n",
      "Epoch 107/200, Iteration 169/250, Loss: 0.0126\n",
      "Epoch 107/200, Iteration 170/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 171/250, Loss: 0.0302\n",
      "Epoch 107/200, Iteration 172/250, Loss: 0.0147\n",
      "Epoch 107/200, Iteration 173/250, Loss: 0.0082\n",
      "Epoch 107/200, Iteration 174/250, Loss: 0.0401\n",
      "Epoch 107/200, Iteration 175/250, Loss: 0.0137\n",
      "Epoch 107/200, Iteration 176/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 177/250, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 178/250, Loss: 0.0257\n",
      "Epoch 107/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 107/200, Iteration 180/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 181/250, Loss: 0.0132\n",
      "Epoch 107/200, Iteration 182/250, Loss: 0.0091\n",
      "Epoch 107/200, Iteration 183/250, Loss: 0.0097\n",
      "Epoch 107/200, Iteration 184/250, Loss: 0.0436\n",
      "Epoch 107/200, Iteration 185/250, Loss: 0.0209\n",
      "Epoch 107/200, Iteration 186/250, Loss: 0.0140\n",
      "Epoch 107/200, Iteration 187/250, Loss: 0.0133\n",
      "Epoch 107/200, Iteration 188/250, Loss: 0.0285\n",
      "Epoch 107/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 107/200, Iteration 190/250, Loss: 0.0263\n",
      "Epoch 107/200, Iteration 191/250, Loss: 0.0260\n",
      "Epoch 107/200, Iteration 192/250, Loss: 0.0183\n",
      "Epoch 107/200, Iteration 193/250, Loss: 0.0296\n",
      "Epoch 107/200, Iteration 194/250, Loss: 0.0177\n",
      "Epoch 107/200, Iteration 195/250, Loss: 0.0208\n",
      "Epoch 107/200, Iteration 196/250, Loss: 0.0122\n",
      "Epoch 107/200, Iteration 197/250, Loss: 0.0128\n",
      "Epoch 107/200, Iteration 198/250, Loss: 0.0088\n",
      "Epoch 107/200, Iteration 199/250, Loss: 0.0199\n",
      "Epoch 107/200, Iteration 200/250, Loss: 0.0225\n",
      "Epoch 107/200, Iteration 201/250, Loss: 0.0158\n",
      "Epoch 107/200, Iteration 202/250, Loss: 0.0393\n",
      "Epoch 107/200, Iteration 203/250, Loss: 0.0249\n",
      "Epoch 107/200, Iteration 204/250, Loss: 0.0375\n",
      "Epoch 107/200, Iteration 205/250, Loss: 0.0100\n",
      "Epoch 107/200, Iteration 206/250, Loss: 0.0202\n",
      "Epoch 107/200, Iteration 207/250, Loss: 0.0081\n",
      "Epoch 107/200, Iteration 208/250, Loss: 0.0076\n",
      "Epoch 107/200, Iteration 209/250, Loss: 0.0191\n",
      "Epoch 107/200, Iteration 210/250, Loss: 0.0121\n",
      "Epoch 107/200, Iteration 211/250, Loss: 0.0104\n",
      "Epoch 107/200, Iteration 212/250, Loss: 0.0207\n",
      "Epoch 107/200, Iteration 213/250, Loss: 0.0159\n",
      "Epoch 107/200, Iteration 214/250, Loss: 0.0214\n",
      "Epoch 107/200, Iteration 215/250, Loss: 0.0112\n",
      "Epoch 107/200, Iteration 216/250, Loss: 0.0337\n",
      "Epoch 107/200, Iteration 217/250, Loss: 0.0125\n",
      "Epoch 107/200, Iteration 218/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 219/250, Loss: 0.0291\n",
      "Epoch 107/200, Iteration 220/250, Loss: 0.0091\n",
      "Epoch 107/200, Iteration 221/250, Loss: 0.0327\n",
      "Epoch 107/200, Iteration 222/250, Loss: 0.0077\n",
      "Epoch 107/200, Iteration 223/250, Loss: 0.0114\n",
      "Epoch 107/200, Iteration 224/250, Loss: 0.0091\n",
      "Epoch 107/200, Iteration 225/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 226/250, Loss: 0.0123\n",
      "Epoch 107/200, Iteration 227/250, Loss: 0.0362\n",
      "Epoch 107/200, Iteration 228/250, Loss: 0.0094\n",
      "Epoch 107/200, Iteration 229/250, Loss: 0.0080\n",
      "Epoch 107/200, Iteration 230/250, Loss: 0.0135\n",
      "Epoch 107/200, Iteration 231/250, Loss: 0.0090\n",
      "Epoch 107/200, Iteration 232/250, Loss: 0.0121\n",
      "Epoch 107/200, Iteration 233/250, Loss: 0.0148\n",
      "Epoch 107/200, Iteration 234/250, Loss: 0.0157\n",
      "Epoch 107/200, Iteration 235/250, Loss: 0.0143\n",
      "Epoch 107/200, Iteration 236/250, Loss: 0.0138\n",
      "Epoch 107/200, Iteration 237/250, Loss: 0.0089\n",
      "Epoch 107/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 107/200, Iteration 239/250, Loss: 0.0099\n",
      "Epoch 107/200, Iteration 240/250, Loss: 0.0166\n",
      "Epoch 107/200, Iteration 241/250, Loss: 0.0183\n",
      "Epoch 107/200, Iteration 242/250, Loss: 0.0147\n",
      "Epoch 107/200, Iteration 243/250, Loss: 0.0097\n",
      "Epoch 107/200, Iteration 244/250, Loss: 0.0188\n",
      "Epoch 107/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 107/200, Iteration 246/250, Loss: 0.0221\n",
      "Epoch 107/200, Iteration 247/250, Loss: 0.0108\n",
      "Epoch 107/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 107/200, Iteration 249/250, Loss: 0.0109\n",
      "Epoch 107/200, Iteration 250/250, Loss: 0.0175\n",
      "Train Error: \n",
      " Accuracy: 85.29%, Avg loss: 0.006801, MRE: 0.454325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.15%, Avg loss: 0.007243, MRE: 0.577144 \n",
      "\n",
      "Epoch 108/200, Iteration 1/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 2/250, Loss: 0.0189\n",
      "Epoch 108/200, Iteration 3/250, Loss: 0.0138\n",
      "Epoch 108/200, Iteration 4/250, Loss: 0.0180\n",
      "Epoch 108/200, Iteration 5/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 6/250, Loss: 0.0146\n",
      "Epoch 108/200, Iteration 7/250, Loss: 0.0091\n",
      "Epoch 108/200, Iteration 8/250, Loss: 0.0107\n",
      "Epoch 108/200, Iteration 9/250, Loss: 0.0168\n",
      "Epoch 108/200, Iteration 10/250, Loss: 0.0170\n",
      "Epoch 108/200, Iteration 11/250, Loss: 0.0207\n",
      "Epoch 108/200, Iteration 12/250, Loss: 0.0187\n",
      "Epoch 108/200, Iteration 13/250, Loss: 0.0142\n",
      "Epoch 108/200, Iteration 14/250, Loss: 0.0175\n",
      "Epoch 108/200, Iteration 15/250, Loss: 0.0079\n",
      "Epoch 108/200, Iteration 16/250, Loss: 0.0078\n",
      "Epoch 108/200, Iteration 17/250, Loss: 0.0284\n",
      "Epoch 108/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 108/200, Iteration 19/250, Loss: 0.0154\n",
      "Epoch 108/200, Iteration 20/250, Loss: 0.0288\n",
      "Epoch 108/200, Iteration 21/250, Loss: 0.0171\n",
      "Epoch 108/200, Iteration 22/250, Loss: 0.0158\n",
      "Epoch 108/200, Iteration 23/250, Loss: 0.0098\n",
      "Epoch 108/200, Iteration 24/250, Loss: 0.0138\n",
      "Epoch 108/200, Iteration 25/250, Loss: 0.0181\n",
      "Epoch 108/200, Iteration 26/250, Loss: 0.0261\n",
      "Epoch 108/200, Iteration 27/250, Loss: 0.0194\n",
      "Epoch 108/200, Iteration 28/250, Loss: 0.0420\n",
      "Epoch 108/200, Iteration 29/250, Loss: 0.0107\n",
      "Epoch 108/200, Iteration 30/250, Loss: 0.0094\n",
      "Epoch 108/200, Iteration 31/250, Loss: 0.0224\n",
      "Epoch 108/200, Iteration 32/250, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 33/250, Loss: 0.0174\n",
      "Epoch 108/200, Iteration 34/250, Loss: 0.0096\n",
      "Epoch 108/200, Iteration 35/250, Loss: 0.0091\n",
      "Epoch 108/200, Iteration 36/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 37/250, Loss: 0.0218\n",
      "Epoch 108/200, Iteration 38/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 39/250, Loss: 0.0174\n",
      "Epoch 108/200, Iteration 40/250, Loss: 0.0283\n",
      "Epoch 108/200, Iteration 41/250, Loss: 0.0073\n",
      "Epoch 108/200, Iteration 42/250, Loss: 0.0160\n",
      "Epoch 108/200, Iteration 43/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 44/250, Loss: 0.0093\n",
      "Epoch 108/200, Iteration 45/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 46/250, Loss: 0.0173\n",
      "Epoch 108/200, Iteration 47/250, Loss: 0.0163\n",
      "Epoch 108/200, Iteration 48/250, Loss: 0.0097\n",
      "Epoch 108/200, Iteration 49/250, Loss: 0.0194\n",
      "Epoch 108/200, Iteration 50/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 51/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 52/250, Loss: 0.0076\n",
      "Epoch 108/200, Iteration 53/250, Loss: 0.0242\n",
      "Epoch 108/200, Iteration 54/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 55/250, Loss: 0.0284\n",
      "Epoch 108/200, Iteration 56/250, Loss: 0.0062\n",
      "Epoch 108/200, Iteration 57/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 58/250, Loss: 0.0125\n",
      "Epoch 108/200, Iteration 59/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 60/250, Loss: 0.0238\n",
      "Epoch 108/200, Iteration 61/250, Loss: 0.0121\n",
      "Epoch 108/200, Iteration 62/250, Loss: 0.0125\n",
      "Epoch 108/200, Iteration 63/250, Loss: 0.0091\n",
      "Epoch 108/200, Iteration 64/250, Loss: 0.0093\n",
      "Epoch 108/200, Iteration 65/250, Loss: 0.0219\n",
      "Epoch 108/200, Iteration 66/250, Loss: 0.0144\n",
      "Epoch 108/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 68/250, Loss: 0.0225\n",
      "Epoch 108/200, Iteration 69/250, Loss: 0.0089\n",
      "Epoch 108/200, Iteration 70/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 71/250, Loss: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 73/250, Loss: 0.0158\n",
      "Epoch 108/200, Iteration 74/250, Loss: 0.0135\n",
      "Epoch 108/200, Iteration 75/250, Loss: 0.0079\n",
      "Epoch 108/200, Iteration 76/250, Loss: 0.0059\n",
      "Epoch 108/200, Iteration 77/250, Loss: 0.0188\n",
      "Epoch 108/200, Iteration 78/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 79/250, Loss: 0.0247\n",
      "Epoch 108/200, Iteration 80/250, Loss: 0.0249\n",
      "Epoch 108/200, Iteration 81/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 82/250, Loss: 0.0066\n",
      "Epoch 108/200, Iteration 83/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 84/250, Loss: 0.0079\n",
      "Epoch 108/200, Iteration 85/250, Loss: 0.0135\n",
      "Epoch 108/200, Iteration 86/250, Loss: 0.0271\n",
      "Epoch 108/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 108/200, Iteration 88/250, Loss: 0.0101\n",
      "Epoch 108/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 90/250, Loss: 0.0078\n",
      "Epoch 108/200, Iteration 91/250, Loss: 0.0105\n",
      "Epoch 108/200, Iteration 92/250, Loss: 0.0116\n",
      "Epoch 108/200, Iteration 93/250, Loss: 0.0080\n",
      "Epoch 108/200, Iteration 94/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 95/250, Loss: 0.0160\n",
      "Epoch 108/200, Iteration 96/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 97/250, Loss: 0.0162\n",
      "Epoch 108/200, Iteration 98/250, Loss: 0.0277\n",
      "Epoch 108/200, Iteration 99/250, Loss: 0.0194\n",
      "Epoch 108/200, Iteration 100/250, Loss: 0.0108\n",
      "Epoch 108/200, Iteration 101/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 102/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 103/250, Loss: 0.0153\n",
      "Epoch 108/200, Iteration 104/250, Loss: 0.0150\n",
      "Epoch 108/200, Iteration 105/250, Loss: 0.0170\n",
      "Epoch 108/200, Iteration 106/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 107/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 108/250, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 109/250, Loss: 0.0179\n",
      "Epoch 108/200, Iteration 110/250, Loss: 0.0317\n",
      "Epoch 108/200, Iteration 111/250, Loss: 0.0109\n",
      "Epoch 108/200, Iteration 112/250, Loss: 0.0237\n",
      "Epoch 108/200, Iteration 113/250, Loss: 0.0164\n",
      "Epoch 108/200, Iteration 114/250, Loss: 0.0340\n",
      "Epoch 108/200, Iteration 115/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 116/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 117/250, Loss: 0.0239\n",
      "Epoch 108/200, Iteration 118/250, Loss: 0.0321\n",
      "Epoch 108/200, Iteration 119/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 120/250, Loss: 0.0079\n",
      "Epoch 108/200, Iteration 121/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 122/250, Loss: 0.0124\n",
      "Epoch 108/200, Iteration 123/250, Loss: 0.0096\n",
      "Epoch 108/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 125/250, Loss: 0.0113\n",
      "Epoch 108/200, Iteration 126/250, Loss: 0.0194\n",
      "Epoch 108/200, Iteration 127/250, Loss: 0.0103\n",
      "Epoch 108/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 129/250, Loss: 0.0215\n",
      "Epoch 108/200, Iteration 130/250, Loss: 0.0118\n",
      "Epoch 108/200, Iteration 131/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 132/250, Loss: 0.0203\n",
      "Epoch 108/200, Iteration 133/250, Loss: 0.0068\n",
      "Epoch 108/200, Iteration 134/250, Loss: 0.0073\n",
      "Epoch 108/200, Iteration 135/250, Loss: 0.0189\n",
      "Epoch 108/200, Iteration 136/250, Loss: 0.0175\n",
      "Epoch 108/200, Iteration 137/250, Loss: 0.0155\n",
      "Epoch 108/200, Iteration 138/250, Loss: 0.0155\n",
      "Epoch 108/200, Iteration 139/250, Loss: 0.0259\n",
      "Epoch 108/200, Iteration 140/250, Loss: 0.0094\n",
      "Epoch 108/200, Iteration 141/250, Loss: 0.0356\n",
      "Epoch 108/200, Iteration 142/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 143/250, Loss: 0.0244\n",
      "Epoch 108/200, Iteration 144/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 145/250, Loss: 0.0093\n",
      "Epoch 108/200, Iteration 146/250, Loss: 0.0230\n",
      "Epoch 108/200, Iteration 147/250, Loss: 0.0186\n",
      "Epoch 108/200, Iteration 148/250, Loss: 0.0127\n",
      "Epoch 108/200, Iteration 149/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 150/250, Loss: 0.0435\n",
      "Epoch 108/200, Iteration 151/250, Loss: 0.0109\n",
      "Epoch 108/200, Iteration 152/250, Loss: 0.0093\n",
      "Epoch 108/200, Iteration 153/250, Loss: 0.0074\n",
      "Epoch 108/200, Iteration 154/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 155/250, Loss: 0.0133\n",
      "Epoch 108/200, Iteration 156/250, Loss: 0.0088\n",
      "Epoch 108/200, Iteration 157/250, Loss: 0.0143\n",
      "Epoch 108/200, Iteration 158/250, Loss: 0.0173\n",
      "Epoch 108/200, Iteration 159/250, Loss: 0.0082\n",
      "Epoch 108/200, Iteration 160/250, Loss: 0.0268\n",
      "Epoch 108/200, Iteration 161/250, Loss: 0.0293\n",
      "Epoch 108/200, Iteration 162/250, Loss: 0.0103\n",
      "Epoch 108/200, Iteration 163/250, Loss: 0.0091\n",
      "Epoch 108/200, Iteration 164/250, Loss: 0.0190\n",
      "Epoch 108/200, Iteration 165/250, Loss: 0.0164\n",
      "Epoch 108/200, Iteration 166/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 167/250, Loss: 0.0133\n",
      "Epoch 108/200, Iteration 168/250, Loss: 0.0131\n",
      "Epoch 108/200, Iteration 169/250, Loss: 0.0069\n",
      "Epoch 108/200, Iteration 170/250, Loss: 0.0139\n",
      "Epoch 108/200, Iteration 171/250, Loss: 0.0088\n",
      "Epoch 108/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 108/200, Iteration 173/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 174/250, Loss: 0.0198\n",
      "Epoch 108/200, Iteration 175/250, Loss: 0.0200\n",
      "Epoch 108/200, Iteration 176/250, Loss: 0.0217\n",
      "Epoch 108/200, Iteration 177/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 178/250, Loss: 0.0261\n",
      "Epoch 108/200, Iteration 179/250, Loss: 0.0117\n",
      "Epoch 108/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 108/200, Iteration 181/250, Loss: 0.0287\n",
      "Epoch 108/200, Iteration 182/250, Loss: 0.0099\n",
      "Epoch 108/200, Iteration 183/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 184/250, Loss: 0.0132\n",
      "Epoch 108/200, Iteration 185/250, Loss: 0.0306\n",
      "Epoch 108/200, Iteration 186/250, Loss: 0.0145\n",
      "Epoch 108/200, Iteration 187/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 188/250, Loss: 0.0156\n",
      "Epoch 108/200, Iteration 189/250, Loss: 0.0183\n",
      "Epoch 108/200, Iteration 190/250, Loss: 0.0185\n",
      "Epoch 108/200, Iteration 191/250, Loss: 0.0234\n",
      "Epoch 108/200, Iteration 192/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 193/250, Loss: 0.0194\n",
      "Epoch 108/200, Iteration 194/250, Loss: 0.0087\n",
      "Epoch 108/200, Iteration 195/250, Loss: 0.0167\n",
      "Epoch 108/200, Iteration 196/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 197/250, Loss: 0.0108\n",
      "Epoch 108/200, Iteration 198/250, Loss: 0.0160\n",
      "Epoch 108/200, Iteration 199/250, Loss: 0.0157\n",
      "Epoch 108/200, Iteration 200/250, Loss: 0.0127\n",
      "Epoch 108/200, Iteration 201/250, Loss: 0.0098\n",
      "Epoch 108/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 108/200, Iteration 203/250, Loss: 0.0266\n",
      "Epoch 108/200, Iteration 204/250, Loss: 0.0204\n",
      "Epoch 108/200, Iteration 205/250, Loss: 0.0071\n",
      "Epoch 108/200, Iteration 206/250, Loss: 0.0176\n",
      "Epoch 108/200, Iteration 207/250, Loss: 0.0123\n",
      "Epoch 108/200, Iteration 208/250, Loss: 0.0193\n",
      "Epoch 108/200, Iteration 209/250, Loss: 0.0080\n",
      "Epoch 108/200, Iteration 210/250, Loss: 0.0155\n",
      "Epoch 108/200, Iteration 211/250, Loss: 0.0147\n",
      "Epoch 108/200, Iteration 212/250, Loss: 0.0088\n",
      "Epoch 108/200, Iteration 213/250, Loss: 0.0112\n",
      "Epoch 108/200, Iteration 214/250, Loss: 0.0106\n",
      "Epoch 108/200, Iteration 215/250, Loss: 0.0144\n",
      "Epoch 108/200, Iteration 216/250, Loss: 0.0236\n",
      "Epoch 108/200, Iteration 217/250, Loss: 0.0076\n",
      "Epoch 108/200, Iteration 218/250, Loss: 0.0205\n",
      "Epoch 108/200, Iteration 219/250, Loss: 0.0071\n",
      "Epoch 108/200, Iteration 220/250, Loss: 0.0077\n",
      "Epoch 108/200, Iteration 221/250, Loss: 0.0295\n",
      "Epoch 108/200, Iteration 222/250, Loss: 0.0086\n",
      "Epoch 108/200, Iteration 223/250, Loss: 0.0128\n",
      "Epoch 108/200, Iteration 224/250, Loss: 0.0068\n",
      "Epoch 108/200, Iteration 225/250, Loss: 0.0168\n",
      "Epoch 108/200, Iteration 226/250, Loss: 0.0080\n",
      "Epoch 108/200, Iteration 227/250, Loss: 0.0104\n",
      "Epoch 108/200, Iteration 228/250, Loss: 0.0085\n",
      "Epoch 108/200, Iteration 229/250, Loss: 0.0083\n",
      "Epoch 108/200, Iteration 230/250, Loss: 0.0174\n",
      "Epoch 108/200, Iteration 231/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 232/250, Loss: 0.0363\n",
      "Epoch 108/200, Iteration 233/250, Loss: 0.0145\n",
      "Epoch 108/200, Iteration 234/250, Loss: 0.0250\n",
      "Epoch 108/200, Iteration 235/250, Loss: 0.0377\n",
      "Epoch 108/200, Iteration 236/250, Loss: 0.0103\n",
      "Epoch 108/200, Iteration 237/250, Loss: 0.0141\n",
      "Epoch 108/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 108/200, Iteration 239/250, Loss: 0.0102\n",
      "Epoch 108/200, Iteration 240/250, Loss: 0.0377\n",
      "Epoch 108/200, Iteration 241/250, Loss: 0.0129\n",
      "Epoch 108/200, Iteration 242/250, Loss: 0.0084\n",
      "Epoch 108/200, Iteration 243/250, Loss: 0.0369\n",
      "Epoch 108/200, Iteration 244/250, Loss: 0.0094\n",
      "Epoch 108/200, Iteration 245/250, Loss: 0.0386\n",
      "Epoch 108/200, Iteration 246/250, Loss: 0.0149\n",
      "Epoch 108/200, Iteration 247/250, Loss: 0.0190\n",
      "Epoch 108/200, Iteration 248/250, Loss: 0.0089\n",
      "Epoch 108/200, Iteration 249/250, Loss: 0.0118\n",
      "Epoch 108/200, Iteration 250/250, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 98.02%, Avg loss: 0.011012, MRE: 0.739550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.011565, MRE: 0.699009 \n",
      "\n",
      "Epoch 109/200, Iteration 1/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 2/250, Loss: 0.0157\n",
      "Epoch 109/200, Iteration 3/250, Loss: 0.0208\n",
      "Epoch 109/200, Iteration 4/250, Loss: 0.0164\n",
      "Epoch 109/200, Iteration 5/250, Loss: 0.0117\n",
      "Epoch 109/200, Iteration 6/250, Loss: 0.0142\n",
      "Epoch 109/200, Iteration 7/250, Loss: 0.0083\n",
      "Epoch 109/200, Iteration 8/250, Loss: 0.0185\n",
      "Epoch 109/200, Iteration 9/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 10/250, Loss: 0.0201\n",
      "Epoch 109/200, Iteration 11/250, Loss: 0.0129\n",
      "Epoch 109/200, Iteration 12/250, Loss: 0.0331\n",
      "Epoch 109/200, Iteration 13/250, Loss: 0.0414\n",
      "Epoch 109/200, Iteration 14/250, Loss: 0.0141\n",
      "Epoch 109/200, Iteration 15/250, Loss: 0.0121\n",
      "Epoch 109/200, Iteration 16/250, Loss: 0.0248\n",
      "Epoch 109/200, Iteration 17/250, Loss: 0.0168\n",
      "Epoch 109/200, Iteration 18/250, Loss: 0.0108\n",
      "Epoch 109/200, Iteration 19/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 20/250, Loss: 0.0129\n",
      "Epoch 109/200, Iteration 21/250, Loss: 0.0295\n",
      "Epoch 109/200, Iteration 22/250, Loss: 0.0105\n",
      "Epoch 109/200, Iteration 23/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 24/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 25/250, Loss: 0.0266\n",
      "Epoch 109/200, Iteration 26/250, Loss: 0.0166\n",
      "Epoch 109/200, Iteration 27/250, Loss: 0.0146\n",
      "Epoch 109/200, Iteration 28/250, Loss: 0.0096\n",
      "Epoch 109/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 109/200, Iteration 30/250, Loss: 0.0146\n",
      "Epoch 109/200, Iteration 31/250, Loss: 0.0233\n",
      "Epoch 109/200, Iteration 32/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 33/250, Loss: 0.0066\n",
      "Epoch 109/200, Iteration 34/250, Loss: 0.0206\n",
      "Epoch 109/200, Iteration 35/250, Loss: 0.0105\n",
      "Epoch 109/200, Iteration 36/250, Loss: 0.0272\n",
      "Epoch 109/200, Iteration 37/250, Loss: 0.0099\n",
      "Epoch 109/200, Iteration 38/250, Loss: 0.0104\n",
      "Epoch 109/200, Iteration 39/250, Loss: 0.0305\n",
      "Epoch 109/200, Iteration 40/250, Loss: 0.0157\n",
      "Epoch 109/200, Iteration 41/250, Loss: 0.0108\n",
      "Epoch 109/200, Iteration 42/250, Loss: 0.0154\n",
      "Epoch 109/200, Iteration 43/250, Loss: 0.0342\n",
      "Epoch 109/200, Iteration 44/250, Loss: 0.0176\n",
      "Epoch 109/200, Iteration 45/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 46/250, Loss: 0.0080\n",
      "Epoch 109/200, Iteration 47/250, Loss: 0.0219\n",
      "Epoch 109/200, Iteration 48/250, Loss: 0.0098\n",
      "Epoch 109/200, Iteration 49/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 50/250, Loss: 0.0113\n",
      "Epoch 109/200, Iteration 51/250, Loss: 0.0146\n",
      "Epoch 109/200, Iteration 52/250, Loss: 0.0172\n",
      "Epoch 109/200, Iteration 53/250, Loss: 0.0122\n",
      "Epoch 109/200, Iteration 54/250, Loss: 0.0128\n",
      "Epoch 109/200, Iteration 55/250, Loss: 0.0098\n",
      "Epoch 109/200, Iteration 56/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 57/250, Loss: 0.0123\n",
      "Epoch 109/200, Iteration 58/250, Loss: 0.0259\n",
      "Epoch 109/200, Iteration 59/250, Loss: 0.0132\n",
      "Epoch 109/200, Iteration 60/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 61/250, Loss: 0.0312\n",
      "Epoch 109/200, Iteration 62/250, Loss: 0.0106\n",
      "Epoch 109/200, Iteration 63/250, Loss: 0.0402\n",
      "Epoch 109/200, Iteration 64/250, Loss: 0.0251\n",
      "Epoch 109/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 109/200, Iteration 66/250, Loss: 0.0171\n",
      "Epoch 109/200, Iteration 67/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 68/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 69/250, Loss: 0.0151\n",
      "Epoch 109/200, Iteration 70/250, Loss: 0.0086\n",
      "Epoch 109/200, Iteration 71/250, Loss: 0.0217\n",
      "Epoch 109/200, Iteration 72/250, Loss: 0.0069\n",
      "Epoch 109/200, Iteration 73/250, Loss: 0.0082\n",
      "Epoch 109/200, Iteration 74/250, Loss: 0.0125\n",
      "Epoch 109/200, Iteration 75/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 76/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 77/250, Loss: 0.0135\n",
      "Epoch 109/200, Iteration 78/250, Loss: 0.0076\n",
      "Epoch 109/200, Iteration 79/250, Loss: 0.0187\n",
      "Epoch 109/200, Iteration 80/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 81/250, Loss: 0.0170\n",
      "Epoch 109/200, Iteration 82/250, Loss: 0.0075\n",
      "Epoch 109/200, Iteration 83/250, Loss: 0.0382\n",
      "Epoch 109/200, Iteration 84/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 85/250, Loss: 0.0193\n",
      "Epoch 109/200, Iteration 86/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 87/250, Loss: 0.0140\n",
      "Epoch 109/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 109/200, Iteration 89/250, Loss: 0.0173\n",
      "Epoch 109/200, Iteration 90/250, Loss: 0.0158\n",
      "Epoch 109/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 92/250, Loss: 0.0166\n",
      "Epoch 109/200, Iteration 93/250, Loss: 0.0134\n",
      "Epoch 109/200, Iteration 94/250, Loss: 0.0117\n",
      "Epoch 109/200, Iteration 95/250, Loss: 0.0269\n",
      "Epoch 109/200, Iteration 96/250, Loss: 0.0116\n",
      "Epoch 109/200, Iteration 97/250, Loss: 0.0220\n",
      "Epoch 109/200, Iteration 98/250, Loss: 0.0237\n",
      "Epoch 109/200, Iteration 99/250, Loss: 0.0183\n",
      "Epoch 109/200, Iteration 100/250, Loss: 0.0223\n",
      "Epoch 109/200, Iteration 101/250, Loss: 0.0277\n",
      "Epoch 109/200, Iteration 102/250, Loss: 0.0211\n",
      "Epoch 109/200, Iteration 103/250, Loss: 0.0095\n",
      "Epoch 109/200, Iteration 104/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 105/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 106/250, Loss: 0.0144\n",
      "Epoch 109/200, Iteration 107/250, Loss: 0.0132\n",
      "Epoch 109/200, Iteration 108/250, Loss: 0.0181\n",
      "Epoch 109/200, Iteration 109/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 111/250, Loss: 0.0115\n",
      "Epoch 109/200, Iteration 112/250, Loss: 0.0240\n",
      "Epoch 109/200, Iteration 113/250, Loss: 0.0163\n",
      "Epoch 109/200, Iteration 114/250, Loss: 0.0197\n",
      "Epoch 109/200, Iteration 115/250, Loss: 0.0169\n",
      "Epoch 109/200, Iteration 116/250, Loss: 0.0163\n",
      "Epoch 109/200, Iteration 117/250, Loss: 0.0095\n",
      "Epoch 109/200, Iteration 118/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 119/250, Loss: 0.0486\n",
      "Epoch 109/200, Iteration 120/250, Loss: 0.0061\n",
      "Epoch 109/200, Iteration 121/250, Loss: 0.0119\n",
      "Epoch 109/200, Iteration 122/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 123/250, Loss: 0.0128\n",
      "Epoch 109/200, Iteration 124/250, Loss: 0.0132\n",
      "Epoch 109/200, Iteration 125/250, Loss: 0.0137\n",
      "Epoch 109/200, Iteration 126/250, Loss: 0.0110\n",
      "Epoch 109/200, Iteration 127/250, Loss: 0.0257\n",
      "Epoch 109/200, Iteration 128/250, Loss: 0.0215\n",
      "Epoch 109/200, Iteration 129/250, Loss: 0.0170\n",
      "Epoch 109/200, Iteration 130/250, Loss: 0.0193\n",
      "Epoch 109/200, Iteration 131/250, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 132/250, Loss: 0.0081\n",
      "Epoch 109/200, Iteration 133/250, Loss: 0.0160\n",
      "Epoch 109/200, Iteration 134/250, Loss: 0.0141\n",
      "Epoch 109/200, Iteration 135/250, Loss: 0.0109\n",
      "Epoch 109/200, Iteration 136/250, Loss: 0.0111\n",
      "Epoch 109/200, Iteration 137/250, Loss: 0.0132\n",
      "Epoch 109/200, Iteration 138/250, Loss: 0.0114\n",
      "Epoch 109/200, Iteration 139/250, Loss: 0.0208\n",
      "Epoch 109/200, Iteration 140/250, Loss: 0.0204\n",
      "Epoch 109/200, Iteration 141/250, Loss: 0.0177\n",
      "Epoch 109/200, Iteration 142/250, Loss: 0.0125\n",
      "Epoch 109/200, Iteration 143/250, Loss: 0.0132\n",
      "Epoch 109/200, Iteration 144/250, Loss: 0.0268\n",
      "Epoch 109/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 109/200, Iteration 146/250, Loss: 0.0199\n",
      "Epoch 109/200, Iteration 147/250, Loss: 0.0286\n",
      "Epoch 109/200, Iteration 148/250, Loss: 0.0131\n",
      "Epoch 109/200, Iteration 149/250, Loss: 0.0193\n",
      "Epoch 109/200, Iteration 150/250, Loss: 0.0155\n",
      "Epoch 109/200, Iteration 151/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 152/250, Loss: 0.0187\n",
      "Epoch 109/200, Iteration 153/250, Loss: 0.0305\n",
      "Epoch 109/200, Iteration 154/250, Loss: 0.0275\n",
      "Epoch 109/200, Iteration 155/250, Loss: 0.0247\n",
      "Epoch 109/200, Iteration 156/250, Loss: 0.0130\n",
      "Epoch 109/200, Iteration 157/250, Loss: 0.0129\n",
      "Epoch 109/200, Iteration 158/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 159/250, Loss: 0.0108\n",
      "Epoch 109/200, Iteration 160/250, Loss: 0.0310\n",
      "Epoch 109/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 109/200, Iteration 162/250, Loss: 0.0403\n",
      "Epoch 109/200, Iteration 163/250, Loss: 0.0393\n",
      "Epoch 109/200, Iteration 164/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 165/250, Loss: 0.0140\n",
      "Epoch 109/200, Iteration 166/250, Loss: 0.0142\n",
      "Epoch 109/200, Iteration 167/250, Loss: 0.0170\n",
      "Epoch 109/200, Iteration 168/250, Loss: 0.0143\n",
      "Epoch 109/200, Iteration 169/250, Loss: 0.0130\n",
      "Epoch 109/200, Iteration 170/250, Loss: 0.0112\n",
      "Epoch 109/200, Iteration 171/250, Loss: 0.0136\n",
      "Epoch 109/200, Iteration 172/250, Loss: 0.0084\n",
      "Epoch 109/200, Iteration 173/250, Loss: 0.0090\n",
      "Epoch 109/200, Iteration 174/250, Loss: 0.0102\n",
      "Epoch 109/200, Iteration 175/250, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 176/250, Loss: 0.0144\n",
      "Epoch 109/200, Iteration 177/250, Loss: 0.0097\n",
      "Epoch 109/200, Iteration 178/250, Loss: 0.0162\n",
      "Epoch 109/200, Iteration 179/250, Loss: 0.0267\n",
      "Epoch 109/200, Iteration 180/250, Loss: 0.0218\n",
      "Epoch 109/200, Iteration 181/250, Loss: 0.0104\n",
      "Epoch 109/200, Iteration 182/250, Loss: 0.0126\n",
      "Epoch 109/200, Iteration 183/250, Loss: 0.0069\n",
      "Epoch 109/200, Iteration 184/250, Loss: 0.0218\n",
      "Epoch 109/200, Iteration 185/250, Loss: 0.0080\n",
      "Epoch 109/200, Iteration 186/250, Loss: 0.0073\n",
      "Epoch 109/200, Iteration 187/250, Loss: 0.0073\n",
      "Epoch 109/200, Iteration 188/250, Loss: 0.0124\n",
      "Epoch 109/200, Iteration 189/250, Loss: 0.0298\n",
      "Epoch 109/200, Iteration 190/250, Loss: 0.0096\n",
      "Epoch 109/200, Iteration 191/250, Loss: 0.0350\n",
      "Epoch 109/200, Iteration 192/250, Loss: 0.0093\n",
      "Epoch 109/200, Iteration 193/250, Loss: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 109/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 109/200, Iteration 196/250, Loss: 0.0091\n",
      "Epoch 109/200, Iteration 197/250, Loss: 0.0249\n",
      "Epoch 109/200, Iteration 198/250, Loss: 0.0333\n",
      "Epoch 109/200, Iteration 199/250, Loss: 0.0107\n",
      "Epoch 109/200, Iteration 200/250, Loss: 0.0087\n",
      "Epoch 109/200, Iteration 201/250, Loss: 0.0210\n",
      "Epoch 109/200, Iteration 202/250, Loss: 0.0092\n",
      "Epoch 109/200, Iteration 203/250, Loss: 0.0197\n",
      "Epoch 109/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 109/200, Iteration 205/250, Loss: 0.0085\n",
      "Epoch 109/200, Iteration 206/250, Loss: 0.0115\n",
      "Epoch 109/200, Iteration 207/250, Loss: 0.0082\n",
      "Epoch 109/200, Iteration 208/250, Loss: 0.0169\n",
      "Epoch 109/200, Iteration 209/250, Loss: 0.0176\n",
      "Epoch 109/200, Iteration 210/250, Loss: 0.0122\n",
      "Epoch 109/200, Iteration 211/250, Loss: 0.0115\n",
      "Epoch 109/200, Iteration 212/250, Loss: 0.0210\n",
      "Epoch 109/200, Iteration 213/250, Loss: 0.0373\n",
      "Epoch 109/200, Iteration 214/250, Loss: 0.0099\n",
      "Epoch 109/200, Iteration 215/250, Loss: 0.0064\n",
      "Epoch 109/200, Iteration 216/250, Loss: 0.0230\n",
      "Epoch 109/200, Iteration 217/250, Loss: 0.0094\n",
      "Epoch 109/200, Iteration 218/250, Loss: 0.0191\n",
      "Epoch 109/200, Iteration 219/250, Loss: 0.0177\n",
      "Epoch 109/200, Iteration 220/250, Loss: 0.0157\n",
      "Epoch 109/200, Iteration 221/250, Loss: 0.0063\n",
      "Epoch 109/200, Iteration 222/250, Loss: 0.0147\n",
      "Epoch 109/200, Iteration 223/250, Loss: 0.0118\n",
      "Epoch 109/200, Iteration 224/250, Loss: 0.0167\n",
      "Epoch 109/200, Iteration 225/250, Loss: 0.0071\n",
      "Epoch 109/200, Iteration 226/250, Loss: 0.0292\n",
      "Epoch 109/200, Iteration 227/250, Loss: 0.0185\n",
      "Epoch 109/200, Iteration 228/250, Loss: 0.0105\n",
      "Epoch 109/200, Iteration 229/250, Loss: 0.0269\n",
      "Epoch 109/200, Iteration 230/250, Loss: 0.0112\n",
      "Epoch 109/200, Iteration 231/250, Loss: 0.0069\n",
      "Epoch 109/200, Iteration 232/250, Loss: 0.0174\n",
      "Epoch 109/200, Iteration 233/250, Loss: 0.0187\n",
      "Epoch 109/200, Iteration 234/250, Loss: 0.0306\n",
      "Epoch 109/200, Iteration 235/250, Loss: 0.0387\n",
      "Epoch 109/200, Iteration 236/250, Loss: 0.0100\n",
      "Epoch 109/200, Iteration 237/250, Loss: 0.0117\n",
      "Epoch 109/200, Iteration 238/250, Loss: 0.0192\n",
      "Epoch 109/200, Iteration 239/250, Loss: 0.0262\n",
      "Epoch 109/200, Iteration 240/250, Loss: 0.0214\n",
      "Epoch 109/200, Iteration 241/250, Loss: 0.0146\n",
      "Epoch 109/200, Iteration 242/250, Loss: 0.0156\n",
      "Epoch 109/200, Iteration 243/250, Loss: 0.0196\n",
      "Epoch 109/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 109/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 109/200, Iteration 246/250, Loss: 0.0289\n",
      "Epoch 109/200, Iteration 247/250, Loss: 0.0169\n",
      "Epoch 109/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 109/200, Iteration 249/250, Loss: 0.0115\n",
      "Epoch 109/200, Iteration 250/250, Loss: 0.0132\n",
      "Train Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.006751, MRE: 0.464596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.007441, MRE: 0.562428 \n",
      "\n",
      "Epoch 110/200, Iteration 1/250, Loss: 0.0116\n",
      "Epoch 110/200, Iteration 2/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 3/250, Loss: 0.0146\n",
      "Epoch 110/200, Iteration 4/250, Loss: 0.0181\n",
      "Epoch 110/200, Iteration 5/250, Loss: 0.0214\n",
      "Epoch 110/200, Iteration 6/250, Loss: 0.0390\n",
      "Epoch 110/200, Iteration 7/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 8/250, Loss: 0.0212\n",
      "Epoch 110/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 10/250, Loss: 0.0237\n",
      "Epoch 110/200, Iteration 11/250, Loss: 0.0236\n",
      "Epoch 110/200, Iteration 12/250, Loss: 0.0076\n",
      "Epoch 110/200, Iteration 13/250, Loss: 0.0132\n",
      "Epoch 110/200, Iteration 14/250, Loss: 0.0156\n",
      "Epoch 110/200, Iteration 15/250, Loss: 0.0129\n",
      "Epoch 110/200, Iteration 16/250, Loss: 0.0140\n",
      "Epoch 110/200, Iteration 17/250, Loss: 0.0319\n",
      "Epoch 110/200, Iteration 18/250, Loss: 0.0315\n",
      "Epoch 110/200, Iteration 19/250, Loss: 0.0222\n",
      "Epoch 110/200, Iteration 20/250, Loss: 0.0146\n",
      "Epoch 110/200, Iteration 21/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 22/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 24/250, Loss: 0.0116\n",
      "Epoch 110/200, Iteration 25/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 26/250, Loss: 0.0148\n",
      "Epoch 110/200, Iteration 27/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 28/250, Loss: 0.0157\n",
      "Epoch 110/200, Iteration 29/250, Loss: 0.0137\n",
      "Epoch 110/200, Iteration 30/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 31/250, Loss: 0.0240\n",
      "Epoch 110/200, Iteration 32/250, Loss: 0.0092\n",
      "Epoch 110/200, Iteration 33/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 34/250, Loss: 0.0219\n",
      "Epoch 110/200, Iteration 35/250, Loss: 0.0121\n",
      "Epoch 110/200, Iteration 36/250, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 37/250, Loss: 0.0136\n",
      "Epoch 110/200, Iteration 38/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 110/200, Iteration 40/250, Loss: 0.0148\n",
      "Epoch 110/200, Iteration 41/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 42/250, Loss: 0.0109\n",
      "Epoch 110/200, Iteration 43/250, Loss: 0.0274\n",
      "Epoch 110/200, Iteration 44/250, Loss: 0.0327\n",
      "Epoch 110/200, Iteration 45/250, Loss: 0.0146\n",
      "Epoch 110/200, Iteration 46/250, Loss: 0.0214\n",
      "Epoch 110/200, Iteration 47/250, Loss: 0.0197\n",
      "Epoch 110/200, Iteration 48/250, Loss: 0.0099\n",
      "Epoch 110/200, Iteration 49/250, Loss: 0.0080\n",
      "Epoch 110/200, Iteration 50/250, Loss: 0.0153\n",
      "Epoch 110/200, Iteration 51/250, Loss: 0.0129\n",
      "Epoch 110/200, Iteration 52/250, Loss: 0.0231\n",
      "Epoch 110/200, Iteration 53/250, Loss: 0.0103\n",
      "Epoch 110/200, Iteration 54/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 55/250, Loss: 0.0077\n",
      "Epoch 110/200, Iteration 56/250, Loss: 0.0152\n",
      "Epoch 110/200, Iteration 57/250, Loss: 0.0237\n",
      "Epoch 110/200, Iteration 58/250, Loss: 0.0147\n",
      "Epoch 110/200, Iteration 59/250, Loss: 0.0128\n",
      "Epoch 110/200, Iteration 60/250, Loss: 0.0126\n",
      "Epoch 110/200, Iteration 61/250, Loss: 0.0156\n",
      "Epoch 110/200, Iteration 62/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 63/250, Loss: 0.0359\n",
      "Epoch 110/200, Iteration 64/250, Loss: 0.0168\n",
      "Epoch 110/200, Iteration 65/250, Loss: 0.0339\n",
      "Epoch 110/200, Iteration 66/250, Loss: 0.0096\n",
      "Epoch 110/200, Iteration 67/250, Loss: 0.0198\n",
      "Epoch 110/200, Iteration 68/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 69/250, Loss: 0.0173\n",
      "Epoch 110/200, Iteration 70/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 71/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 72/250, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 73/250, Loss: 0.0135\n",
      "Epoch 110/200, Iteration 74/250, Loss: 0.0147\n",
      "Epoch 110/200, Iteration 75/250, Loss: 0.0252\n",
      "Epoch 110/200, Iteration 76/250, Loss: 0.0196\n",
      "Epoch 110/200, Iteration 77/250, Loss: 0.0270\n",
      "Epoch 110/200, Iteration 78/250, Loss: 0.0187\n",
      "Epoch 110/200, Iteration 79/250, Loss: 0.0381\n",
      "Epoch 110/200, Iteration 80/250, Loss: 0.0135\n",
      "Epoch 110/200, Iteration 81/250, Loss: 0.0271\n",
      "Epoch 110/200, Iteration 82/250, Loss: 0.0392\n",
      "Epoch 110/200, Iteration 83/250, Loss: 0.0164\n",
      "Epoch 110/200, Iteration 84/250, Loss: 0.0175\n",
      "Epoch 110/200, Iteration 85/250, Loss: 0.0189\n",
      "Epoch 110/200, Iteration 86/250, Loss: 0.0108\n",
      "Epoch 110/200, Iteration 87/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 88/250, Loss: 0.0193\n",
      "Epoch 110/200, Iteration 89/250, Loss: 0.0175\n",
      "Epoch 110/200, Iteration 90/250, Loss: 0.0062\n",
      "Epoch 110/200, Iteration 91/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 92/250, Loss: 0.0134\n",
      "Epoch 110/200, Iteration 93/250, Loss: 0.0127\n",
      "Epoch 110/200, Iteration 94/250, Loss: 0.0145\n",
      "Epoch 110/200, Iteration 95/250, Loss: 0.0180\n",
      "Epoch 110/200, Iteration 96/250, Loss: 0.0150\n",
      "Epoch 110/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 98/250, Loss: 0.0165\n",
      "Epoch 110/200, Iteration 99/250, Loss: 0.0087\n",
      "Epoch 110/200, Iteration 100/250, Loss: 0.0123\n",
      "Epoch 110/200, Iteration 101/250, Loss: 0.0148\n",
      "Epoch 110/200, Iteration 102/250, Loss: 0.0164\n",
      "Epoch 110/200, Iteration 103/250, Loss: 0.0197\n",
      "Epoch 110/200, Iteration 104/250, Loss: 0.0125\n",
      "Epoch 110/200, Iteration 105/250, Loss: 0.0064\n",
      "Epoch 110/200, Iteration 106/250, Loss: 0.0070\n",
      "Epoch 110/200, Iteration 107/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 108/250, Loss: 0.0078\n",
      "Epoch 110/200, Iteration 109/250, Loss: 0.0069\n",
      "Epoch 110/200, Iteration 110/250, Loss: 0.0110\n",
      "Epoch 110/200, Iteration 111/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 112/250, Loss: 0.0168\n",
      "Epoch 110/200, Iteration 113/250, Loss: 0.0157\n",
      "Epoch 110/200, Iteration 114/250, Loss: 0.0131\n",
      "Epoch 110/200, Iteration 115/250, Loss: 0.0062\n",
      "Epoch 110/200, Iteration 116/250, Loss: 0.0351\n",
      "Epoch 110/200, Iteration 117/250, Loss: 0.0131\n",
      "Epoch 110/200, Iteration 118/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 119/250, Loss: 0.0070\n",
      "Epoch 110/200, Iteration 120/250, Loss: 0.0186\n",
      "Epoch 110/200, Iteration 121/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 122/250, Loss: 0.0115\n",
      "Epoch 110/200, Iteration 123/250, Loss: 0.0078\n",
      "Epoch 110/200, Iteration 124/250, Loss: 0.0266\n",
      "Epoch 110/200, Iteration 125/250, Loss: 0.0075\n",
      "Epoch 110/200, Iteration 126/250, Loss: 0.0076\n",
      "Epoch 110/200, Iteration 127/250, Loss: 0.0148\n",
      "Epoch 110/200, Iteration 128/250, Loss: 0.0146\n",
      "Epoch 110/200, Iteration 129/250, Loss: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200, Iteration 130/250, Loss: 0.0232\n",
      "Epoch 110/200, Iteration 131/250, Loss: 0.0113\n",
      "Epoch 110/200, Iteration 132/250, Loss: 0.0182\n",
      "Epoch 110/200, Iteration 133/250, Loss: 0.0293\n",
      "Epoch 110/200, Iteration 134/250, Loss: 0.0087\n",
      "Epoch 110/200, Iteration 135/250, Loss: 0.0149\n",
      "Epoch 110/200, Iteration 136/250, Loss: 0.0081\n",
      "Epoch 110/200, Iteration 137/250, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 138/250, Loss: 0.0114\n",
      "Epoch 110/200, Iteration 139/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 140/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 141/250, Loss: 0.0200\n",
      "Epoch 110/200, Iteration 142/250, Loss: 0.0163\n",
      "Epoch 110/200, Iteration 143/250, Loss: 0.0185\n",
      "Epoch 110/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 145/250, Loss: 0.0090\n",
      "Epoch 110/200, Iteration 146/250, Loss: 0.0097\n",
      "Epoch 110/200, Iteration 147/250, Loss: 0.0163\n",
      "Epoch 110/200, Iteration 148/250, Loss: 0.0123\n",
      "Epoch 110/200, Iteration 149/250, Loss: 0.0088\n",
      "Epoch 110/200, Iteration 150/250, Loss: 0.0206\n",
      "Epoch 110/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 110/200, Iteration 152/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 154/250, Loss: 0.0202\n",
      "Epoch 110/200, Iteration 155/250, Loss: 0.0072\n",
      "Epoch 110/200, Iteration 156/250, Loss: 0.0202\n",
      "Epoch 110/200, Iteration 157/250, Loss: 0.0136\n",
      "Epoch 110/200, Iteration 158/250, Loss: 0.0124\n",
      "Epoch 110/200, Iteration 159/250, Loss: 0.0103\n",
      "Epoch 110/200, Iteration 160/250, Loss: 0.0097\n",
      "Epoch 110/200, Iteration 161/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 162/250, Loss: 0.0228\n",
      "Epoch 110/200, Iteration 163/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 164/250, Loss: 0.0393\n",
      "Epoch 110/200, Iteration 165/250, Loss: 0.0173\n",
      "Epoch 110/200, Iteration 166/250, Loss: 0.0130\n",
      "Epoch 110/200, Iteration 167/250, Loss: 0.0243\n",
      "Epoch 110/200, Iteration 168/250, Loss: 0.0193\n",
      "Epoch 110/200, Iteration 169/250, Loss: 0.0146\n",
      "Epoch 110/200, Iteration 170/250, Loss: 0.0181\n",
      "Epoch 110/200, Iteration 171/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 173/250, Loss: 0.0183\n",
      "Epoch 110/200, Iteration 174/250, Loss: 0.0098\n",
      "Epoch 110/200, Iteration 175/250, Loss: 0.0080\n",
      "Epoch 110/200, Iteration 176/250, Loss: 0.0158\n",
      "Epoch 110/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 178/250, Loss: 0.0153\n",
      "Epoch 110/200, Iteration 179/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 180/250, Loss: 0.0088\n",
      "Epoch 110/200, Iteration 181/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 182/250, Loss: 0.0096\n",
      "Epoch 110/200, Iteration 183/250, Loss: 0.0221\n",
      "Epoch 110/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 110/200, Iteration 185/250, Loss: 0.0151\n",
      "Epoch 110/200, Iteration 186/250, Loss: 0.0121\n",
      "Epoch 110/200, Iteration 187/250, Loss: 0.0144\n",
      "Epoch 110/200, Iteration 188/250, Loss: 0.0136\n",
      "Epoch 110/200, Iteration 189/250, Loss: 0.0193\n",
      "Epoch 110/200, Iteration 190/250, Loss: 0.0209\n",
      "Epoch 110/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 192/250, Loss: 0.0091\n",
      "Epoch 110/200, Iteration 193/250, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 194/250, Loss: 0.0084\n",
      "Epoch 110/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 110/200, Iteration 196/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 197/250, Loss: 0.0104\n",
      "Epoch 110/200, Iteration 198/250, Loss: 0.0272\n",
      "Epoch 110/200, Iteration 199/250, Loss: 0.0101\n",
      "Epoch 110/200, Iteration 200/250, Loss: 0.0292\n",
      "Epoch 110/200, Iteration 201/250, Loss: 0.0113\n",
      "Epoch 110/200, Iteration 202/250, Loss: 0.0073\n",
      "Epoch 110/200, Iteration 203/250, Loss: 0.0180\n",
      "Epoch 110/200, Iteration 204/250, Loss: 0.0205\n",
      "Epoch 110/200, Iteration 205/250, Loss: 0.0137\n",
      "Epoch 110/200, Iteration 206/250, Loss: 0.0163\n",
      "Epoch 110/200, Iteration 207/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 208/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 209/250, Loss: 0.0100\n",
      "Epoch 110/200, Iteration 210/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 211/250, Loss: 0.0086\n",
      "Epoch 110/200, Iteration 212/250, Loss: 0.0080\n",
      "Epoch 110/200, Iteration 213/250, Loss: 0.0140\n",
      "Epoch 110/200, Iteration 214/250, Loss: 0.0301\n",
      "Epoch 110/200, Iteration 215/250, Loss: 0.0161\n",
      "Epoch 110/200, Iteration 216/250, Loss: 0.0125\n",
      "Epoch 110/200, Iteration 217/250, Loss: 0.0161\n",
      "Epoch 110/200, Iteration 218/250, Loss: 0.0175\n",
      "Epoch 110/200, Iteration 219/250, Loss: 0.0109\n",
      "Epoch 110/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 110/200, Iteration 221/250, Loss: 0.0238\n",
      "Epoch 110/200, Iteration 222/250, Loss: 0.0112\n",
      "Epoch 110/200, Iteration 223/250, Loss: 0.0094\n",
      "Epoch 110/200, Iteration 224/250, Loss: 0.0096\n",
      "Epoch 110/200, Iteration 225/250, Loss: 0.0088\n",
      "Epoch 110/200, Iteration 226/250, Loss: 0.0117\n",
      "Epoch 110/200, Iteration 227/250, Loss: 0.0173\n",
      "Epoch 110/200, Iteration 228/250, Loss: 0.0141\n",
      "Epoch 110/200, Iteration 229/250, Loss: 0.0216\n",
      "Epoch 110/200, Iteration 230/250, Loss: 0.0099\n",
      "Epoch 110/200, Iteration 231/250, Loss: 0.0180\n",
      "Epoch 110/200, Iteration 232/250, Loss: 0.0143\n",
      "Epoch 110/200, Iteration 233/250, Loss: 0.0277\n",
      "Epoch 110/200, Iteration 234/250, Loss: 0.0305\n",
      "Epoch 110/200, Iteration 235/250, Loss: 0.0080\n",
      "Epoch 110/200, Iteration 236/250, Loss: 0.0107\n",
      "Epoch 110/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 110/200, Iteration 238/250, Loss: 0.0125\n",
      "Epoch 110/200, Iteration 239/250, Loss: 0.0226\n",
      "Epoch 110/200, Iteration 240/250, Loss: 0.0162\n",
      "Epoch 110/200, Iteration 241/250, Loss: 0.0154\n",
      "Epoch 110/200, Iteration 242/250, Loss: 0.0164\n",
      "Epoch 110/200, Iteration 243/250, Loss: 0.0144\n",
      "Epoch 110/200, Iteration 244/250, Loss: 0.0129\n",
      "Epoch 110/200, Iteration 245/250, Loss: 0.0071\n",
      "Epoch 110/200, Iteration 246/250, Loss: 0.0211\n",
      "Epoch 110/200, Iteration 247/250, Loss: 0.0167\n",
      "Epoch 110/200, Iteration 248/250, Loss: 0.0196\n",
      "Epoch 110/200, Iteration 249/250, Loss: 0.0095\n",
      "Epoch 110/200, Iteration 250/250, Loss: 0.0108\n",
      "Train Error: \n",
      " Accuracy: 85.95%, Avg loss: 0.006781, MRE: 0.455317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.15%, Avg loss: 0.007320, MRE: 0.553581 \n",
      "\n",
      "Epoch 111/200, Iteration 1/250, Loss: 0.0108\n",
      "Epoch 111/200, Iteration 2/250, Loss: 0.0169\n",
      "Epoch 111/200, Iteration 3/250, Loss: 0.0138\n",
      "Epoch 111/200, Iteration 4/250, Loss: 0.0107\n",
      "Epoch 111/200, Iteration 5/250, Loss: 0.0289\n",
      "Epoch 111/200, Iteration 6/250, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 7/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 8/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 9/250, Loss: 0.0220\n",
      "Epoch 111/200, Iteration 10/250, Loss: 0.0165\n",
      "Epoch 111/200, Iteration 11/250, Loss: 0.0291\n",
      "Epoch 111/200, Iteration 12/250, Loss: 0.0154\n",
      "Epoch 111/200, Iteration 13/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 14/250, Loss: 0.0296\n",
      "Epoch 111/200, Iteration 15/250, Loss: 0.0274\n",
      "Epoch 111/200, Iteration 16/250, Loss: 0.0142\n",
      "Epoch 111/200, Iteration 17/250, Loss: 0.0158\n",
      "Epoch 111/200, Iteration 18/250, Loss: 0.0248\n",
      "Epoch 111/200, Iteration 19/250, Loss: 0.0078\n",
      "Epoch 111/200, Iteration 20/250, Loss: 0.0075\n",
      "Epoch 111/200, Iteration 21/250, Loss: 0.0205\n",
      "Epoch 111/200, Iteration 22/250, Loss: 0.0182\n",
      "Epoch 111/200, Iteration 23/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 24/250, Loss: 0.0235\n",
      "Epoch 111/200, Iteration 25/250, Loss: 0.0127\n",
      "Epoch 111/200, Iteration 26/250, Loss: 0.0160\n",
      "Epoch 111/200, Iteration 27/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 28/250, Loss: 0.0225\n",
      "Epoch 111/200, Iteration 29/250, Loss: 0.0354\n",
      "Epoch 111/200, Iteration 30/250, Loss: 0.0076\n",
      "Epoch 111/200, Iteration 31/250, Loss: 0.0249\n",
      "Epoch 111/200, Iteration 32/250, Loss: 0.0126\n",
      "Epoch 111/200, Iteration 33/250, Loss: 0.0109\n",
      "Epoch 111/200, Iteration 34/250, Loss: 0.0076\n",
      "Epoch 111/200, Iteration 35/250, Loss: 0.0237\n",
      "Epoch 111/200, Iteration 36/250, Loss: 0.0192\n",
      "Epoch 111/200, Iteration 37/250, Loss: 0.0333\n",
      "Epoch 111/200, Iteration 38/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 39/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 40/250, Loss: 0.0175\n",
      "Epoch 111/200, Iteration 41/250, Loss: 0.0303\n",
      "Epoch 111/200, Iteration 42/250, Loss: 0.0098\n",
      "Epoch 111/200, Iteration 43/250, Loss: 0.0123\n",
      "Epoch 111/200, Iteration 44/250, Loss: 0.0137\n",
      "Epoch 111/200, Iteration 45/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 46/250, Loss: 0.0188\n",
      "Epoch 111/200, Iteration 47/250, Loss: 0.0075\n",
      "Epoch 111/200, Iteration 48/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 49/250, Loss: 0.0343\n",
      "Epoch 111/200, Iteration 50/250, Loss: 0.0211\n",
      "Epoch 111/200, Iteration 51/250, Loss: 0.0226\n",
      "Epoch 111/200, Iteration 52/250, Loss: 0.0173\n",
      "Epoch 111/200, Iteration 53/250, Loss: 0.0083\n",
      "Epoch 111/200, Iteration 54/250, Loss: 0.0101\n",
      "Epoch 111/200, Iteration 55/250, Loss: 0.0215\n",
      "Epoch 111/200, Iteration 56/250, Loss: 0.0136\n",
      "Epoch 111/200, Iteration 57/250, Loss: 0.0140\n",
      "Epoch 111/200, Iteration 58/250, Loss: 0.0470\n",
      "Epoch 111/200, Iteration 59/250, Loss: 0.0263\n",
      "Epoch 111/200, Iteration 60/250, Loss: 0.0078\n",
      "Epoch 111/200, Iteration 61/250, Loss: 0.0195\n",
      "Epoch 111/200, Iteration 62/250, Loss: 0.0141\n",
      "Epoch 111/200, Iteration 63/250, Loss: 0.0195\n",
      "Epoch 111/200, Iteration 64/250, Loss: 0.0207\n",
      "Epoch 111/200, Iteration 65/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 66/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 67/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200, Iteration 68/250, Loss: 0.0086\n",
      "Epoch 111/200, Iteration 69/250, Loss: 0.0081\n",
      "Epoch 111/200, Iteration 70/250, Loss: 0.0165\n",
      "Epoch 111/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 72/250, Loss: 0.0303\n",
      "Epoch 111/200, Iteration 73/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 74/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 75/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 76/250, Loss: 0.0103\n",
      "Epoch 111/200, Iteration 77/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 78/250, Loss: 0.0145\n",
      "Epoch 111/200, Iteration 79/250, Loss: 0.0305\n",
      "Epoch 111/200, Iteration 80/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 81/250, Loss: 0.0179\n",
      "Epoch 111/200, Iteration 82/250, Loss: 0.0061\n",
      "Epoch 111/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 84/250, Loss: 0.0148\n",
      "Epoch 111/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 86/250, Loss: 0.0074\n",
      "Epoch 111/200, Iteration 87/250, Loss: 0.0320\n",
      "Epoch 111/200, Iteration 88/250, Loss: 0.0057\n",
      "Epoch 111/200, Iteration 89/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 90/250, Loss: 0.0253\n",
      "Epoch 111/200, Iteration 91/250, Loss: 0.0238\n",
      "Epoch 111/200, Iteration 92/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 93/250, Loss: 0.0135\n",
      "Epoch 111/200, Iteration 94/250, Loss: 0.0139\n",
      "Epoch 111/200, Iteration 95/250, Loss: 0.0240\n",
      "Epoch 111/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 97/250, Loss: 0.0075\n",
      "Epoch 111/200, Iteration 98/250, Loss: 0.0082\n",
      "Epoch 111/200, Iteration 99/250, Loss: 0.0238\n",
      "Epoch 111/200, Iteration 100/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 101/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 102/250, Loss: 0.0091\n",
      "Epoch 111/200, Iteration 103/250, Loss: 0.0080\n",
      "Epoch 111/200, Iteration 104/250, Loss: 0.0178\n",
      "Epoch 111/200, Iteration 105/250, Loss: 0.0113\n",
      "Epoch 111/200, Iteration 106/250, Loss: 0.0108\n",
      "Epoch 111/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 111/200, Iteration 108/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 109/250, Loss: 0.0216\n",
      "Epoch 111/200, Iteration 110/250, Loss: 0.0150\n",
      "Epoch 111/200, Iteration 111/250, Loss: 0.0323\n",
      "Epoch 111/200, Iteration 112/250, Loss: 0.0097\n",
      "Epoch 111/200, Iteration 113/250, Loss: 0.0157\n",
      "Epoch 111/200, Iteration 114/250, Loss: 0.0126\n",
      "Epoch 111/200, Iteration 115/250, Loss: 0.0138\n",
      "Epoch 111/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 111/200, Iteration 117/250, Loss: 0.0117\n",
      "Epoch 111/200, Iteration 118/250, Loss: 0.0128\n",
      "Epoch 111/200, Iteration 119/250, Loss: 0.0185\n",
      "Epoch 111/200, Iteration 120/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 121/250, Loss: 0.0141\n",
      "Epoch 111/200, Iteration 122/250, Loss: 0.0158\n",
      "Epoch 111/200, Iteration 123/250, Loss: 0.0222\n",
      "Epoch 111/200, Iteration 124/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 125/250, Loss: 0.0138\n",
      "Epoch 111/200, Iteration 126/250, Loss: 0.0134\n",
      "Epoch 111/200, Iteration 127/250, Loss: 0.0142\n",
      "Epoch 111/200, Iteration 128/250, Loss: 0.0247\n",
      "Epoch 111/200, Iteration 129/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 130/250, Loss: 0.0151\n",
      "Epoch 111/200, Iteration 131/250, Loss: 0.0112\n",
      "Epoch 111/200, Iteration 132/250, Loss: 0.0315\n",
      "Epoch 111/200, Iteration 133/250, Loss: 0.0185\n",
      "Epoch 111/200, Iteration 134/250, Loss: 0.0084\n",
      "Epoch 111/200, Iteration 135/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 136/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 137/250, Loss: 0.0095\n",
      "Epoch 111/200, Iteration 138/250, Loss: 0.0111\n",
      "Epoch 111/200, Iteration 139/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 140/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 111/200, Iteration 142/250, Loss: 0.0210\n",
      "Epoch 111/200, Iteration 143/250, Loss: 0.0240\n",
      "Epoch 111/200, Iteration 144/250, Loss: 0.0127\n",
      "Epoch 111/200, Iteration 145/250, Loss: 0.0125\n",
      "Epoch 111/200, Iteration 146/250, Loss: 0.0137\n",
      "Epoch 111/200, Iteration 147/250, Loss: 0.0147\n",
      "Epoch 111/200, Iteration 148/250, Loss: 0.0181\n",
      "Epoch 111/200, Iteration 149/250, Loss: 0.0170\n",
      "Epoch 111/200, Iteration 150/250, Loss: 0.0125\n",
      "Epoch 111/200, Iteration 151/250, Loss: 0.0113\n",
      "Epoch 111/200, Iteration 152/250, Loss: 0.0132\n",
      "Epoch 111/200, Iteration 153/250, Loss: 0.0333\n",
      "Epoch 111/200, Iteration 154/250, Loss: 0.0135\n",
      "Epoch 111/200, Iteration 155/250, Loss: 0.0271\n",
      "Epoch 111/200, Iteration 156/250, Loss: 0.0270\n",
      "Epoch 111/200, Iteration 157/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 158/250, Loss: 0.0097\n",
      "Epoch 111/200, Iteration 159/250, Loss: 0.0194\n",
      "Epoch 111/200, Iteration 160/250, Loss: 0.0195\n",
      "Epoch 111/200, Iteration 161/250, Loss: 0.0226\n",
      "Epoch 111/200, Iteration 162/250, Loss: 0.0184\n",
      "Epoch 111/200, Iteration 163/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 164/250, Loss: 0.0179\n",
      "Epoch 111/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 111/200, Iteration 166/250, Loss: 0.0278\n",
      "Epoch 111/200, Iteration 167/250, Loss: 0.0111\n",
      "Epoch 111/200, Iteration 168/250, Loss: 0.0160\n",
      "Epoch 111/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 111/200, Iteration 170/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 171/250, Loss: 0.0153\n",
      "Epoch 111/200, Iteration 172/250, Loss: 0.0295\n",
      "Epoch 111/200, Iteration 173/250, Loss: 0.0080\n",
      "Epoch 111/200, Iteration 174/250, Loss: 0.0096\n",
      "Epoch 111/200, Iteration 175/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 176/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 177/250, Loss: 0.0180\n",
      "Epoch 111/200, Iteration 178/250, Loss: 0.0299\n",
      "Epoch 111/200, Iteration 179/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 111/200, Iteration 181/250, Loss: 0.0140\n",
      "Epoch 111/200, Iteration 182/250, Loss: 0.0150\n",
      "Epoch 111/200, Iteration 183/250, Loss: 0.0157\n",
      "Epoch 111/200, Iteration 184/250, Loss: 0.0102\n",
      "Epoch 111/200, Iteration 185/250, Loss: 0.0060\n",
      "Epoch 111/200, Iteration 186/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 187/250, Loss: 0.0161\n",
      "Epoch 111/200, Iteration 188/250, Loss: 0.0105\n",
      "Epoch 111/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 111/200, Iteration 190/250, Loss: 0.0194\n",
      "Epoch 111/200, Iteration 191/250, Loss: 0.0199\n",
      "Epoch 111/200, Iteration 192/250, Loss: 0.0167\n",
      "Epoch 111/200, Iteration 193/250, Loss: 0.0149\n",
      "Epoch 111/200, Iteration 194/250, Loss: 0.0076\n",
      "Epoch 111/200, Iteration 195/250, Loss: 0.0172\n",
      "Epoch 111/200, Iteration 196/250, Loss: 0.0262\n",
      "Epoch 111/200, Iteration 197/250, Loss: 0.0127\n",
      "Epoch 111/200, Iteration 198/250, Loss: 0.0294\n",
      "Epoch 111/200, Iteration 199/250, Loss: 0.0155\n",
      "Epoch 111/200, Iteration 200/250, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 201/250, Loss: 0.0129\n",
      "Epoch 111/200, Iteration 202/250, Loss: 0.0137\n",
      "Epoch 111/200, Iteration 203/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 204/250, Loss: 0.0079\n",
      "Epoch 111/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 206/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 207/250, Loss: 0.0230\n",
      "Epoch 111/200, Iteration 208/250, Loss: 0.0382\n",
      "Epoch 111/200, Iteration 209/250, Loss: 0.0216\n",
      "Epoch 111/200, Iteration 210/250, Loss: 0.0388\n",
      "Epoch 111/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 111/200, Iteration 212/250, Loss: 0.0089\n",
      "Epoch 111/200, Iteration 213/250, Loss: 0.0183\n",
      "Epoch 111/200, Iteration 214/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 215/250, Loss: 0.0161\n",
      "Epoch 111/200, Iteration 216/250, Loss: 0.0234\n",
      "Epoch 111/200, Iteration 217/250, Loss: 0.0136\n",
      "Epoch 111/200, Iteration 218/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 219/250, Loss: 0.0116\n",
      "Epoch 111/200, Iteration 220/250, Loss: 0.0119\n",
      "Epoch 111/200, Iteration 221/250, Loss: 0.0088\n",
      "Epoch 111/200, Iteration 222/250, Loss: 0.0126\n",
      "Epoch 111/200, Iteration 223/250, Loss: 0.0079\n",
      "Epoch 111/200, Iteration 224/250, Loss: 0.0095\n",
      "Epoch 111/200, Iteration 225/250, Loss: 0.0105\n",
      "Epoch 111/200, Iteration 226/250, Loss: 0.0114\n",
      "Epoch 111/200, Iteration 227/250, Loss: 0.0176\n",
      "Epoch 111/200, Iteration 228/250, Loss: 0.0104\n",
      "Epoch 111/200, Iteration 229/250, Loss: 0.0151\n",
      "Epoch 111/200, Iteration 230/250, Loss: 0.0201\n",
      "Epoch 111/200, Iteration 231/250, Loss: 0.0172\n",
      "Epoch 111/200, Iteration 232/250, Loss: 0.0087\n",
      "Epoch 111/200, Iteration 233/250, Loss: 0.0397\n",
      "Epoch 111/200, Iteration 234/250, Loss: 0.0136\n",
      "Epoch 111/200, Iteration 235/250, Loss: 0.0268\n",
      "Epoch 111/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 111/200, Iteration 237/250, Loss: 0.0225\n",
      "Epoch 111/200, Iteration 238/250, Loss: 0.0099\n",
      "Epoch 111/200, Iteration 239/250, Loss: 0.0098\n",
      "Epoch 111/200, Iteration 240/250, Loss: 0.0184\n",
      "Epoch 111/200, Iteration 241/250, Loss: 0.0094\n",
      "Epoch 111/200, Iteration 242/250, Loss: 0.0233\n",
      "Epoch 111/200, Iteration 243/250, Loss: 0.0213\n",
      "Epoch 111/200, Iteration 244/250, Loss: 0.0143\n",
      "Epoch 111/200, Iteration 245/250, Loss: 0.0169\n",
      "Epoch 111/200, Iteration 246/250, Loss: 0.0073\n",
      "Epoch 111/200, Iteration 247/250, Loss: 0.0091\n",
      "Epoch 111/200, Iteration 248/250, Loss: 0.0109\n",
      "Epoch 111/200, Iteration 249/250, Loss: 0.0121\n",
      "Epoch 111/200, Iteration 250/250, Loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.66%, Avg loss: 0.007109, MRE: 0.483959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.007702, MRE: 0.482622 \n",
      "\n",
      "Epoch 112/200, Iteration 1/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 2/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 3/250, Loss: 0.0113\n",
      "Epoch 112/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 112/200, Iteration 5/250, Loss: 0.0068\n",
      "Epoch 112/200, Iteration 6/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 8/250, Loss: 0.0139\n",
      "Epoch 112/200, Iteration 9/250, Loss: 0.0083\n",
      "Epoch 112/200, Iteration 10/250, Loss: 0.0272\n",
      "Epoch 112/200, Iteration 11/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 12/250, Loss: 0.0125\n",
      "Epoch 112/200, Iteration 13/250, Loss: 0.0155\n",
      "Epoch 112/200, Iteration 14/250, Loss: 0.0311\n",
      "Epoch 112/200, Iteration 15/250, Loss: 0.0246\n",
      "Epoch 112/200, Iteration 16/250, Loss: 0.0283\n",
      "Epoch 112/200, Iteration 17/250, Loss: 0.0092\n",
      "Epoch 112/200, Iteration 18/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 19/250, Loss: 0.0086\n",
      "Epoch 112/200, Iteration 20/250, Loss: 0.0104\n",
      "Epoch 112/200, Iteration 21/250, Loss: 0.0123\n",
      "Epoch 112/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 23/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 24/250, Loss: 0.0086\n",
      "Epoch 112/200, Iteration 25/250, Loss: 0.0256\n",
      "Epoch 112/200, Iteration 26/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 27/250, Loss: 0.0199\n",
      "Epoch 112/200, Iteration 28/250, Loss: 0.0136\n",
      "Epoch 112/200, Iteration 29/250, Loss: 0.0212\n",
      "Epoch 112/200, Iteration 30/250, Loss: 0.0060\n",
      "Epoch 112/200, Iteration 31/250, Loss: 0.0065\n",
      "Epoch 112/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 112/200, Iteration 33/250, Loss: 0.0273\n",
      "Epoch 112/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 35/250, Loss: 0.0153\n",
      "Epoch 112/200, Iteration 36/250, Loss: 0.0116\n",
      "Epoch 112/200, Iteration 37/250, Loss: 0.0250\n",
      "Epoch 112/200, Iteration 38/250, Loss: 0.0198\n",
      "Epoch 112/200, Iteration 39/250, Loss: 0.0071\n",
      "Epoch 112/200, Iteration 40/250, Loss: 0.0164\n",
      "Epoch 112/200, Iteration 41/250, Loss: 0.0106\n",
      "Epoch 112/200, Iteration 42/250, Loss: 0.0191\n",
      "Epoch 112/200, Iteration 43/250, Loss: 0.0201\n",
      "Epoch 112/200, Iteration 44/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 45/250, Loss: 0.0148\n",
      "Epoch 112/200, Iteration 46/250, Loss: 0.0120\n",
      "Epoch 112/200, Iteration 47/250, Loss: 0.0214\n",
      "Epoch 112/200, Iteration 48/250, Loss: 0.0168\n",
      "Epoch 112/200, Iteration 49/250, Loss: 0.0205\n",
      "Epoch 112/200, Iteration 50/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 51/250, Loss: 0.0216\n",
      "Epoch 112/200, Iteration 52/250, Loss: 0.0221\n",
      "Epoch 112/200, Iteration 53/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 54/250, Loss: 0.0225\n",
      "Epoch 112/200, Iteration 55/250, Loss: 0.0164\n",
      "Epoch 112/200, Iteration 56/250, Loss: 0.0218\n",
      "Epoch 112/200, Iteration 57/250, Loss: 0.0248\n",
      "Epoch 112/200, Iteration 58/250, Loss: 0.0123\n",
      "Epoch 112/200, Iteration 59/250, Loss: 0.0196\n",
      "Epoch 112/200, Iteration 60/250, Loss: 0.0073\n",
      "Epoch 112/200, Iteration 61/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 62/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 63/250, Loss: 0.0078\n",
      "Epoch 112/200, Iteration 64/250, Loss: 0.0348\n",
      "Epoch 112/200, Iteration 65/250, Loss: 0.0079\n",
      "Epoch 112/200, Iteration 66/250, Loss: 0.0079\n",
      "Epoch 112/200, Iteration 67/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 68/250, Loss: 0.0138\n",
      "Epoch 112/200, Iteration 69/250, Loss: 0.0188\n",
      "Epoch 112/200, Iteration 70/250, Loss: 0.0275\n",
      "Epoch 112/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 112/200, Iteration 72/250, Loss: 0.0129\n",
      "Epoch 112/200, Iteration 73/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 74/250, Loss: 0.0124\n",
      "Epoch 112/200, Iteration 75/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 76/250, Loss: 0.0179\n",
      "Epoch 112/200, Iteration 77/250, Loss: 0.0124\n",
      "Epoch 112/200, Iteration 78/250, Loss: 0.0199\n",
      "Epoch 112/200, Iteration 79/250, Loss: 0.0141\n",
      "Epoch 112/200, Iteration 80/250, Loss: 0.0088\n",
      "Epoch 112/200, Iteration 81/250, Loss: 0.0159\n",
      "Epoch 112/200, Iteration 82/250, Loss: 0.0119\n",
      "Epoch 112/200, Iteration 83/250, Loss: 0.0089\n",
      "Epoch 112/200, Iteration 84/250, Loss: 0.0195\n",
      "Epoch 112/200, Iteration 85/250, Loss: 0.0134\n",
      "Epoch 112/200, Iteration 86/250, Loss: 0.0237\n",
      "Epoch 112/200, Iteration 87/250, Loss: 0.0079\n",
      "Epoch 112/200, Iteration 88/250, Loss: 0.0140\n",
      "Epoch 112/200, Iteration 89/250, Loss: 0.0252\n",
      "Epoch 112/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 91/250, Loss: 0.0134\n",
      "Epoch 112/200, Iteration 92/250, Loss: 0.0173\n",
      "Epoch 112/200, Iteration 93/250, Loss: 0.0314\n",
      "Epoch 112/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 95/250, Loss: 0.0097\n",
      "Epoch 112/200, Iteration 96/250, Loss: 0.0093\n",
      "Epoch 112/200, Iteration 97/250, Loss: 0.0092\n",
      "Epoch 112/200, Iteration 98/250, Loss: 0.0209\n",
      "Epoch 112/200, Iteration 99/250, Loss: 0.0113\n",
      "Epoch 112/200, Iteration 100/250, Loss: 0.0152\n",
      "Epoch 112/200, Iteration 101/250, Loss: 0.0153\n",
      "Epoch 112/200, Iteration 102/250, Loss: 0.0102\n",
      "Epoch 112/200, Iteration 103/250, Loss: 0.0074\n",
      "Epoch 112/200, Iteration 104/250, Loss: 0.0155\n",
      "Epoch 112/200, Iteration 105/250, Loss: 0.0085\n",
      "Epoch 112/200, Iteration 106/250, Loss: 0.0109\n",
      "Epoch 112/200, Iteration 107/250, Loss: 0.0087\n",
      "Epoch 112/200, Iteration 108/250, Loss: 0.0114\n",
      "Epoch 112/200, Iteration 109/250, Loss: 0.0198\n",
      "Epoch 112/200, Iteration 110/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 111/250, Loss: 0.0212\n",
      "Epoch 112/200, Iteration 112/250, Loss: 0.0407\n",
      "Epoch 112/200, Iteration 113/250, Loss: 0.0095\n",
      "Epoch 112/200, Iteration 114/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 115/250, Loss: 0.0127\n",
      "Epoch 112/200, Iteration 116/250, Loss: 0.0197\n",
      "Epoch 112/200, Iteration 117/250, Loss: 0.0168\n",
      "Epoch 112/200, Iteration 118/250, Loss: 0.0124\n",
      "Epoch 112/200, Iteration 119/250, Loss: 0.0117\n",
      "Epoch 112/200, Iteration 120/250, Loss: 0.0271\n",
      "Epoch 112/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 112/200, Iteration 122/250, Loss: 0.0133\n",
      "Epoch 112/200, Iteration 123/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 124/250, Loss: 0.0128\n",
      "Epoch 112/200, Iteration 125/250, Loss: 0.0055\n",
      "Epoch 112/200, Iteration 126/250, Loss: 0.0270\n",
      "Epoch 112/200, Iteration 127/250, Loss: 0.0132\n",
      "Epoch 112/200, Iteration 128/250, Loss: 0.0148\n",
      "Epoch 112/200, Iteration 129/250, Loss: 0.0241\n",
      "Epoch 112/200, Iteration 130/250, Loss: 0.0159\n",
      "Epoch 112/200, Iteration 131/250, Loss: 0.0108\n",
      "Epoch 112/200, Iteration 132/250, Loss: 0.0278\n",
      "Epoch 112/200, Iteration 133/250, Loss: 0.0162\n",
      "Epoch 112/200, Iteration 134/250, Loss: 0.0187\n",
      "Epoch 112/200, Iteration 135/250, Loss: 0.0158\n",
      "Epoch 112/200, Iteration 136/250, Loss: 0.0213\n",
      "Epoch 112/200, Iteration 137/250, Loss: 0.0088\n",
      "Epoch 112/200, Iteration 138/250, Loss: 0.0224\n",
      "Epoch 112/200, Iteration 139/250, Loss: 0.0080\n",
      "Epoch 112/200, Iteration 140/250, Loss: 0.0185\n",
      "Epoch 112/200, Iteration 141/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 143/250, Loss: 0.0173\n",
      "Epoch 112/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 112/200, Iteration 145/250, Loss: 0.0115\n",
      "Epoch 112/200, Iteration 146/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 147/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 148/250, Loss: 0.0137\n",
      "Epoch 112/200, Iteration 149/250, Loss: 0.0205\n",
      "Epoch 112/200, Iteration 150/250, Loss: 0.0310\n",
      "Epoch 112/200, Iteration 151/250, Loss: 0.0319\n",
      "Epoch 112/200, Iteration 152/250, Loss: 0.0096\n",
      "Epoch 112/200, Iteration 153/250, Loss: 0.0248\n",
      "Epoch 112/200, Iteration 154/250, Loss: 0.0228\n",
      "Epoch 112/200, Iteration 155/250, Loss: 0.0117\n",
      "Epoch 112/200, Iteration 156/250, Loss: 0.0081\n",
      "Epoch 112/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 112/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 112/200, Iteration 159/250, Loss: 0.0146\n",
      "Epoch 112/200, Iteration 160/250, Loss: 0.0207\n",
      "Epoch 112/200, Iteration 161/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 162/250, Loss: 0.0170\n",
      "Epoch 112/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 112/200, Iteration 164/250, Loss: 0.0089\n",
      "Epoch 112/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 166/250, Loss: 0.0117\n",
      "Epoch 112/200, Iteration 167/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 168/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 169/250, Loss: 0.0309\n",
      "Epoch 112/200, Iteration 170/250, Loss: 0.0165\n",
      "Epoch 112/200, Iteration 171/250, Loss: 0.0167\n",
      "Epoch 112/200, Iteration 172/250, Loss: 0.0110\n",
      "Epoch 112/200, Iteration 173/250, Loss: 0.0322\n",
      "Epoch 112/200, Iteration 174/250, Loss: 0.0160\n",
      "Epoch 112/200, Iteration 175/250, Loss: 0.0094\n",
      "Epoch 112/200, Iteration 176/250, Loss: 0.0122\n",
      "Epoch 112/200, Iteration 177/250, Loss: 0.0074\n",
      "Epoch 112/200, Iteration 178/250, Loss: 0.0420\n",
      "Epoch 112/200, Iteration 179/250, Loss: 0.0108\n",
      "Epoch 112/200, Iteration 180/250, Loss: 0.0348\n",
      "Epoch 112/200, Iteration 181/250, Loss: 0.0165\n",
      "Epoch 112/200, Iteration 182/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 183/250, Loss: 0.0266\n",
      "Epoch 112/200, Iteration 184/250, Loss: 0.0172\n",
      "Epoch 112/200, Iteration 185/250, Loss: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200, Iteration 186/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 187/250, Loss: 0.0222\n",
      "Epoch 112/200, Iteration 188/250, Loss: 0.0091\n",
      "Epoch 112/200, Iteration 189/250, Loss: 0.0103\n",
      "Epoch 112/200, Iteration 190/250, Loss: 0.0079\n",
      "Epoch 112/200, Iteration 191/250, Loss: 0.0206\n",
      "Epoch 112/200, Iteration 192/250, Loss: 0.0154\n",
      "Epoch 112/200, Iteration 193/250, Loss: 0.0100\n",
      "Epoch 112/200, Iteration 194/250, Loss: 0.0118\n",
      "Epoch 112/200, Iteration 195/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 196/250, Loss: 0.0148\n",
      "Epoch 112/200, Iteration 197/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 198/250, Loss: 0.0114\n",
      "Epoch 112/200, Iteration 199/250, Loss: 0.0176\n",
      "Epoch 112/200, Iteration 200/250, Loss: 0.0097\n",
      "Epoch 112/200, Iteration 201/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 202/250, Loss: 0.0132\n",
      "Epoch 112/200, Iteration 203/250, Loss: 0.0273\n",
      "Epoch 112/200, Iteration 204/250, Loss: 0.0083\n",
      "Epoch 112/200, Iteration 205/250, Loss: 0.0182\n",
      "Epoch 112/200, Iteration 206/250, Loss: 0.0157\n",
      "Epoch 112/200, Iteration 207/250, Loss: 0.0156\n",
      "Epoch 112/200, Iteration 208/250, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 209/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 210/250, Loss: 0.0099\n",
      "Epoch 112/200, Iteration 211/250, Loss: 0.0184\n",
      "Epoch 112/200, Iteration 212/250, Loss: 0.0220\n",
      "Epoch 112/200, Iteration 213/250, Loss: 0.0160\n",
      "Epoch 112/200, Iteration 214/250, Loss: 0.0140\n",
      "Epoch 112/200, Iteration 215/250, Loss: 0.0167\n",
      "Epoch 112/200, Iteration 216/250, Loss: 0.0071\n",
      "Epoch 112/200, Iteration 217/250, Loss: 0.0114\n",
      "Epoch 112/200, Iteration 218/250, Loss: 0.0110\n",
      "Epoch 112/200, Iteration 219/250, Loss: 0.0113\n",
      "Epoch 112/200, Iteration 220/250, Loss: 0.0139\n",
      "Epoch 112/200, Iteration 221/250, Loss: 0.0101\n",
      "Epoch 112/200, Iteration 222/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 223/250, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 224/250, Loss: 0.0161\n",
      "Epoch 112/200, Iteration 225/250, Loss: 0.0121\n",
      "Epoch 112/200, Iteration 226/250, Loss: 0.0151\n",
      "Epoch 112/200, Iteration 227/250, Loss: 0.0241\n",
      "Epoch 112/200, Iteration 228/250, Loss: 0.0072\n",
      "Epoch 112/200, Iteration 229/250, Loss: 0.0078\n",
      "Epoch 112/200, Iteration 230/250, Loss: 0.0177\n",
      "Epoch 112/200, Iteration 231/250, Loss: 0.0168\n",
      "Epoch 112/200, Iteration 232/250, Loss: 0.0275\n",
      "Epoch 112/200, Iteration 233/250, Loss: 0.0109\n",
      "Epoch 112/200, Iteration 234/250, Loss: 0.0112\n",
      "Epoch 112/200, Iteration 235/250, Loss: 0.0090\n",
      "Epoch 112/200, Iteration 236/250, Loss: 0.0100\n",
      "Epoch 112/200, Iteration 237/250, Loss: 0.0116\n",
      "Epoch 112/200, Iteration 238/250, Loss: 0.0138\n",
      "Epoch 112/200, Iteration 239/250, Loss: 0.0113\n",
      "Epoch 112/200, Iteration 240/250, Loss: 0.0112\n",
      "Epoch 112/200, Iteration 241/250, Loss: 0.0166\n",
      "Epoch 112/200, Iteration 242/250, Loss: 0.0190\n",
      "Epoch 112/200, Iteration 243/250, Loss: 0.0227\n",
      "Epoch 112/200, Iteration 244/250, Loss: 0.0098\n",
      "Epoch 112/200, Iteration 245/250, Loss: 0.0096\n",
      "Epoch 112/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 112/200, Iteration 247/250, Loss: 0.0129\n",
      "Epoch 112/200, Iteration 248/250, Loss: 0.0111\n",
      "Epoch 112/200, Iteration 249/250, Loss: 0.0177\n",
      "Epoch 112/200, Iteration 250/250, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 91.99%, Avg loss: 0.006791, MRE: 0.507208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.007449, MRE: 0.568312 \n",
      "\n",
      "Epoch 113/200, Iteration 1/250, Loss: 0.0269\n",
      "Epoch 113/200, Iteration 2/250, Loss: 0.0151\n",
      "Epoch 113/200, Iteration 3/250, Loss: 0.0196\n",
      "Epoch 113/200, Iteration 4/250, Loss: 0.0198\n",
      "Epoch 113/200, Iteration 5/250, Loss: 0.0179\n",
      "Epoch 113/200, Iteration 6/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 7/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 9/250, Loss: 0.0215\n",
      "Epoch 113/200, Iteration 10/250, Loss: 0.0080\n",
      "Epoch 113/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 113/200, Iteration 12/250, Loss: 0.0170\n",
      "Epoch 113/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 113/200, Iteration 14/250, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 15/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 16/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 17/250, Loss: 0.0158\n",
      "Epoch 113/200, Iteration 18/250, Loss: 0.0105\n",
      "Epoch 113/200, Iteration 19/250, Loss: 0.0119\n",
      "Epoch 113/200, Iteration 20/250, Loss: 0.0215\n",
      "Epoch 113/200, Iteration 21/250, Loss: 0.0166\n",
      "Epoch 113/200, Iteration 22/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 113/200, Iteration 24/250, Loss: 0.0144\n",
      "Epoch 113/200, Iteration 25/250, Loss: 0.0132\n",
      "Epoch 113/200, Iteration 26/250, Loss: 0.0142\n",
      "Epoch 113/200, Iteration 27/250, Loss: 0.0203\n",
      "Epoch 113/200, Iteration 28/250, Loss: 0.0095\n",
      "Epoch 113/200, Iteration 29/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 30/250, Loss: 0.0089\n",
      "Epoch 113/200, Iteration 31/250, Loss: 0.0154\n",
      "Epoch 113/200, Iteration 32/250, Loss: 0.0121\n",
      "Epoch 113/200, Iteration 33/250, Loss: 0.0250\n",
      "Epoch 113/200, Iteration 34/250, Loss: 0.0155\n",
      "Epoch 113/200, Iteration 35/250, Loss: 0.0198\n",
      "Epoch 113/200, Iteration 36/250, Loss: 0.0326\n",
      "Epoch 113/200, Iteration 37/250, Loss: 0.0163\n",
      "Epoch 113/200, Iteration 38/250, Loss: 0.0148\n",
      "Epoch 113/200, Iteration 39/250, Loss: 0.0064\n",
      "Epoch 113/200, Iteration 40/250, Loss: 0.0282\n",
      "Epoch 113/200, Iteration 41/250, Loss: 0.0111\n",
      "Epoch 113/200, Iteration 42/250, Loss: 0.0178\n",
      "Epoch 113/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 113/200, Iteration 45/250, Loss: 0.0077\n",
      "Epoch 113/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 113/200, Iteration 47/250, Loss: 0.0203\n",
      "Epoch 113/200, Iteration 48/250, Loss: 0.0066\n",
      "Epoch 113/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 113/200, Iteration 50/250, Loss: 0.0072\n",
      "Epoch 113/200, Iteration 51/250, Loss: 0.0161\n",
      "Epoch 113/200, Iteration 52/250, Loss: 0.0210\n",
      "Epoch 113/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 54/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 55/250, Loss: 0.0160\n",
      "Epoch 113/200, Iteration 56/250, Loss: 0.0104\n",
      "Epoch 113/200, Iteration 57/250, Loss: 0.0222\n",
      "Epoch 113/200, Iteration 58/250, Loss: 0.0306\n",
      "Epoch 113/200, Iteration 59/250, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 60/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 61/250, Loss: 0.0146\n",
      "Epoch 113/200, Iteration 62/250, Loss: 0.0283\n",
      "Epoch 113/200, Iteration 63/250, Loss: 0.0127\n",
      "Epoch 113/200, Iteration 64/250, Loss: 0.0106\n",
      "Epoch 113/200, Iteration 65/250, Loss: 0.0126\n",
      "Epoch 113/200, Iteration 66/250, Loss: 0.0180\n",
      "Epoch 113/200, Iteration 67/250, Loss: 0.0066\n",
      "Epoch 113/200, Iteration 68/250, Loss: 0.0114\n",
      "Epoch 113/200, Iteration 69/250, Loss: 0.0097\n",
      "Epoch 113/200, Iteration 70/250, Loss: 0.0073\n",
      "Epoch 113/200, Iteration 71/250, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 72/250, Loss: 0.0110\n",
      "Epoch 113/200, Iteration 73/250, Loss: 0.0115\n",
      "Epoch 113/200, Iteration 74/250, Loss: 0.0086\n",
      "Epoch 113/200, Iteration 75/250, Loss: 0.0383\n",
      "Epoch 113/200, Iteration 76/250, Loss: 0.0101\n",
      "Epoch 113/200, Iteration 77/250, Loss: 0.0144\n",
      "Epoch 113/200, Iteration 78/250, Loss: 0.0136\n",
      "Epoch 113/200, Iteration 79/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 80/250, Loss: 0.0219\n",
      "Epoch 113/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 82/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 83/250, Loss: 0.0229\n",
      "Epoch 113/200, Iteration 84/250, Loss: 0.0148\n",
      "Epoch 113/200, Iteration 85/250, Loss: 0.0136\n",
      "Epoch 113/200, Iteration 86/250, Loss: 0.0081\n",
      "Epoch 113/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 113/200, Iteration 88/250, Loss: 0.0121\n",
      "Epoch 113/200, Iteration 89/250, Loss: 0.0175\n",
      "Epoch 113/200, Iteration 90/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 91/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 92/250, Loss: 0.0144\n",
      "Epoch 113/200, Iteration 93/250, Loss: 0.0201\n",
      "Epoch 113/200, Iteration 94/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 95/250, Loss: 0.0191\n",
      "Epoch 113/200, Iteration 96/250, Loss: 0.0119\n",
      "Epoch 113/200, Iteration 97/250, Loss: 0.0159\n",
      "Epoch 113/200, Iteration 98/250, Loss: 0.0168\n",
      "Epoch 113/200, Iteration 99/250, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 100/250, Loss: 0.0155\n",
      "Epoch 113/200, Iteration 101/250, Loss: 0.0093\n",
      "Epoch 113/200, Iteration 102/250, Loss: 0.0288\n",
      "Epoch 113/200, Iteration 103/250, Loss: 0.0373\n",
      "Epoch 113/200, Iteration 104/250, Loss: 0.0089\n",
      "Epoch 113/200, Iteration 105/250, Loss: 0.0158\n",
      "Epoch 113/200, Iteration 106/250, Loss: 0.0146\n",
      "Epoch 113/200, Iteration 107/250, Loss: 0.0221\n",
      "Epoch 113/200, Iteration 108/250, Loss: 0.0159\n",
      "Epoch 113/200, Iteration 109/250, Loss: 0.0095\n",
      "Epoch 113/200, Iteration 110/250, Loss: 0.0176\n",
      "Epoch 113/200, Iteration 111/250, Loss: 0.0108\n",
      "Epoch 113/200, Iteration 112/250, Loss: 0.0187\n",
      "Epoch 113/200, Iteration 113/250, Loss: 0.0088\n",
      "Epoch 113/200, Iteration 114/250, Loss: 0.0149\n",
      "Epoch 113/200, Iteration 115/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 116/250, Loss: 0.0248\n",
      "Epoch 113/200, Iteration 117/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 118/250, Loss: 0.0164\n",
      "Epoch 113/200, Iteration 119/250, Loss: 0.0114\n",
      "Epoch 113/200, Iteration 120/250, Loss: 0.0126\n",
      "Epoch 113/200, Iteration 121/250, Loss: 0.0178\n",
      "Epoch 113/200, Iteration 122/250, Loss: 0.0234\n",
      "Epoch 113/200, Iteration 123/250, Loss: 0.0158\n",
      "Epoch 113/200, Iteration 124/250, Loss: 0.0077\n",
      "Epoch 113/200, Iteration 125/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 126/250, Loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200, Iteration 127/250, Loss: 0.0242\n",
      "Epoch 113/200, Iteration 128/250, Loss: 0.0156\n",
      "Epoch 113/200, Iteration 129/250, Loss: 0.0261\n",
      "Epoch 113/200, Iteration 130/250, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 131/250, Loss: 0.0197\n",
      "Epoch 113/200, Iteration 132/250, Loss: 0.0133\n",
      "Epoch 113/200, Iteration 133/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 134/250, Loss: 0.0186\n",
      "Epoch 113/200, Iteration 135/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 136/250, Loss: 0.0109\n",
      "Epoch 113/200, Iteration 137/250, Loss: 0.0174\n",
      "Epoch 113/200, Iteration 138/250, Loss: 0.0230\n",
      "Epoch 113/200, Iteration 139/250, Loss: 0.0205\n",
      "Epoch 113/200, Iteration 140/250, Loss: 0.0209\n",
      "Epoch 113/200, Iteration 141/250, Loss: 0.0199\n",
      "Epoch 113/200, Iteration 142/250, Loss: 0.0175\n",
      "Epoch 113/200, Iteration 143/250, Loss: 0.0099\n",
      "Epoch 113/200, Iteration 144/250, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 145/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 147/250, Loss: 0.0155\n",
      "Epoch 113/200, Iteration 148/250, Loss: 0.0170\n",
      "Epoch 113/200, Iteration 149/250, Loss: 0.0082\n",
      "Epoch 113/200, Iteration 150/250, Loss: 0.0168\n",
      "Epoch 113/200, Iteration 151/250, Loss: 0.0136\n",
      "Epoch 113/200, Iteration 152/250, Loss: 0.0065\n",
      "Epoch 113/200, Iteration 153/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 154/250, Loss: 0.0174\n",
      "Epoch 113/200, Iteration 155/250, Loss: 0.0069\n",
      "Epoch 113/200, Iteration 156/250, Loss: 0.0173\n",
      "Epoch 113/200, Iteration 157/250, Loss: 0.0104\n",
      "Epoch 113/200, Iteration 158/250, Loss: 0.0301\n",
      "Epoch 113/200, Iteration 159/250, Loss: 0.0143\n",
      "Epoch 113/200, Iteration 160/250, Loss: 0.0151\n",
      "Epoch 113/200, Iteration 161/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 162/250, Loss: 0.0198\n",
      "Epoch 113/200, Iteration 163/250, Loss: 0.0233\n",
      "Epoch 113/200, Iteration 164/250, Loss: 0.0237\n",
      "Epoch 113/200, Iteration 165/250, Loss: 0.0189\n",
      "Epoch 113/200, Iteration 166/250, Loss: 0.0208\n",
      "Epoch 113/200, Iteration 167/250, Loss: 0.0108\n",
      "Epoch 113/200, Iteration 168/250, Loss: 0.0102\n",
      "Epoch 113/200, Iteration 169/250, Loss: 0.0062\n",
      "Epoch 113/200, Iteration 170/250, Loss: 0.0095\n",
      "Epoch 113/200, Iteration 171/250, Loss: 0.0167\n",
      "Epoch 113/200, Iteration 172/250, Loss: 0.0087\n",
      "Epoch 113/200, Iteration 173/250, Loss: 0.0114\n",
      "Epoch 113/200, Iteration 174/250, Loss: 0.0173\n",
      "Epoch 113/200, Iteration 175/250, Loss: 0.0117\n",
      "Epoch 113/200, Iteration 176/250, Loss: 0.0226\n",
      "Epoch 113/200, Iteration 177/250, Loss: 0.0190\n",
      "Epoch 113/200, Iteration 178/250, Loss: 0.0220\n",
      "Epoch 113/200, Iteration 179/250, Loss: 0.0117\n",
      "Epoch 113/200, Iteration 180/250, Loss: 0.0114\n",
      "Epoch 113/200, Iteration 181/250, Loss: 0.0179\n",
      "Epoch 113/200, Iteration 182/250, Loss: 0.0136\n",
      "Epoch 113/200, Iteration 183/250, Loss: 0.0061\n",
      "Epoch 113/200, Iteration 184/250, Loss: 0.0317\n",
      "Epoch 113/200, Iteration 185/250, Loss: 0.0124\n",
      "Epoch 113/200, Iteration 186/250, Loss: 0.0146\n",
      "Epoch 113/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 188/250, Loss: 0.0106\n",
      "Epoch 113/200, Iteration 189/250, Loss: 0.0094\n",
      "Epoch 113/200, Iteration 190/250, Loss: 0.0172\n",
      "Epoch 113/200, Iteration 191/250, Loss: 0.0144\n",
      "Epoch 113/200, Iteration 192/250, Loss: 0.0249\n",
      "Epoch 113/200, Iteration 193/250, Loss: 0.0305\n",
      "Epoch 113/200, Iteration 194/250, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 195/250, Loss: 0.0085\n",
      "Epoch 113/200, Iteration 196/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 197/250, Loss: 0.0067\n",
      "Epoch 113/200, Iteration 198/250, Loss: 0.0189\n",
      "Epoch 113/200, Iteration 199/250, Loss: 0.0355\n",
      "Epoch 113/200, Iteration 200/250, Loss: 0.0182\n",
      "Epoch 113/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 113/200, Iteration 202/250, Loss: 0.0180\n",
      "Epoch 113/200, Iteration 203/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 204/250, Loss: 0.0163\n",
      "Epoch 113/200, Iteration 205/250, Loss: 0.0096\n",
      "Epoch 113/200, Iteration 206/250, Loss: 0.0289\n",
      "Epoch 113/200, Iteration 207/250, Loss: 0.0224\n",
      "Epoch 113/200, Iteration 208/250, Loss: 0.0140\n",
      "Epoch 113/200, Iteration 209/250, Loss: 0.0091\n",
      "Epoch 113/200, Iteration 210/250, Loss: 0.0092\n",
      "Epoch 113/200, Iteration 211/250, Loss: 0.0116\n",
      "Epoch 113/200, Iteration 212/250, Loss: 0.0142\n",
      "Epoch 113/200, Iteration 213/250, Loss: 0.0112\n",
      "Epoch 113/200, Iteration 214/250, Loss: 0.0130\n",
      "Epoch 113/200, Iteration 215/250, Loss: 0.0153\n",
      "Epoch 113/200, Iteration 216/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 217/250, Loss: 0.0239\n",
      "Epoch 113/200, Iteration 218/250, Loss: 0.0307\n",
      "Epoch 113/200, Iteration 219/250, Loss: 0.0107\n",
      "Epoch 113/200, Iteration 220/250, Loss: 0.0240\n",
      "Epoch 113/200, Iteration 221/250, Loss: 0.0272\n",
      "Epoch 113/200, Iteration 222/250, Loss: 0.0148\n",
      "Epoch 113/200, Iteration 223/250, Loss: 0.0125\n",
      "Epoch 113/200, Iteration 224/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 225/250, Loss: 0.0182\n",
      "Epoch 113/200, Iteration 226/250, Loss: 0.0230\n",
      "Epoch 113/200, Iteration 227/250, Loss: 0.0155\n",
      "Epoch 113/200, Iteration 228/250, Loss: 0.0210\n",
      "Epoch 113/200, Iteration 229/250, Loss: 0.0085\n",
      "Epoch 113/200, Iteration 230/250, Loss: 0.0097\n",
      "Epoch 113/200, Iteration 231/250, Loss: 0.0274\n",
      "Epoch 113/200, Iteration 232/250, Loss: 0.0120\n",
      "Epoch 113/200, Iteration 233/250, Loss: 0.0274\n",
      "Epoch 113/200, Iteration 234/250, Loss: 0.0256\n",
      "Epoch 113/200, Iteration 235/250, Loss: 0.0316\n",
      "Epoch 113/200, Iteration 236/250, Loss: 0.0088\n",
      "Epoch 113/200, Iteration 237/250, Loss: 0.0187\n",
      "Epoch 113/200, Iteration 238/250, Loss: 0.0093\n",
      "Epoch 113/200, Iteration 239/250, Loss: 0.0074\n",
      "Epoch 113/200, Iteration 240/250, Loss: 0.0075\n",
      "Epoch 113/200, Iteration 241/250, Loss: 0.0241\n",
      "Epoch 113/200, Iteration 242/250, Loss: 0.0084\n",
      "Epoch 113/200, Iteration 243/250, Loss: 0.0059\n",
      "Epoch 113/200, Iteration 244/250, Loss: 0.0080\n",
      "Epoch 113/200, Iteration 245/250, Loss: 0.0219\n",
      "Epoch 113/200, Iteration 246/250, Loss: 0.0133\n",
      "Epoch 113/200, Iteration 247/250, Loss: 0.0141\n",
      "Epoch 113/200, Iteration 248/250, Loss: 0.0090\n",
      "Epoch 113/200, Iteration 249/250, Loss: 0.0093\n",
      "Epoch 113/200, Iteration 250/250, Loss: 0.0123\n",
      "Train Error: \n",
      " Accuracy: 95.24%, Avg loss: 0.007490, MRE: 0.467268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.008163, MRE: 0.535864 \n",
      "\n",
      "Epoch 114/200, Iteration 1/250, Loss: 0.0091\n",
      "Epoch 114/200, Iteration 2/250, Loss: 0.0190\n",
      "Epoch 114/200, Iteration 3/250, Loss: 0.0085\n",
      "Epoch 114/200, Iteration 4/250, Loss: 0.0207\n",
      "Epoch 114/200, Iteration 5/250, Loss: 0.0141\n",
      "Epoch 114/200, Iteration 6/250, Loss: 0.0285\n",
      "Epoch 114/200, Iteration 7/250, Loss: 0.0190\n",
      "Epoch 114/200, Iteration 8/250, Loss: 0.0123\n",
      "Epoch 114/200, Iteration 9/250, Loss: 0.0138\n",
      "Epoch 114/200, Iteration 10/250, Loss: 0.0109\n",
      "Epoch 114/200, Iteration 11/250, Loss: 0.0085\n",
      "Epoch 114/200, Iteration 12/250, Loss: 0.0117\n",
      "Epoch 114/200, Iteration 13/250, Loss: 0.0083\n",
      "Epoch 114/200, Iteration 14/250, Loss: 0.0183\n",
      "Epoch 114/200, Iteration 15/250, Loss: 0.0158\n",
      "Epoch 114/200, Iteration 16/250, Loss: 0.0202\n",
      "Epoch 114/200, Iteration 17/250, Loss: 0.0149\n",
      "Epoch 114/200, Iteration 18/250, Loss: 0.0068\n",
      "Epoch 114/200, Iteration 19/250, Loss: 0.0140\n",
      "Epoch 114/200, Iteration 20/250, Loss: 0.0292\n",
      "Epoch 114/200, Iteration 21/250, Loss: 0.0140\n",
      "Epoch 114/200, Iteration 22/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 23/250, Loss: 0.0122\n",
      "Epoch 114/200, Iteration 24/250, Loss: 0.0118\n",
      "Epoch 114/200, Iteration 25/250, Loss: 0.0168\n",
      "Epoch 114/200, Iteration 26/250, Loss: 0.0229\n",
      "Epoch 114/200, Iteration 27/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 28/250, Loss: 0.0114\n",
      "Epoch 114/200, Iteration 29/250, Loss: 0.0180\n",
      "Epoch 114/200, Iteration 30/250, Loss: 0.0132\n",
      "Epoch 114/200, Iteration 31/250, Loss: 0.0180\n",
      "Epoch 114/200, Iteration 32/250, Loss: 0.0189\n",
      "Epoch 114/200, Iteration 33/250, Loss: 0.0104\n",
      "Epoch 114/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 114/200, Iteration 35/250, Loss: 0.0337\n",
      "Epoch 114/200, Iteration 36/250, Loss: 0.0273\n",
      "Epoch 114/200, Iteration 37/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 38/250, Loss: 0.0147\n",
      "Epoch 114/200, Iteration 39/250, Loss: 0.0261\n",
      "Epoch 114/200, Iteration 40/250, Loss: 0.0282\n",
      "Epoch 114/200, Iteration 41/250, Loss: 0.0142\n",
      "Epoch 114/200, Iteration 42/250, Loss: 0.0128\n",
      "Epoch 114/200, Iteration 43/250, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 44/250, Loss: 0.0092\n",
      "Epoch 114/200, Iteration 45/250, Loss: 0.0253\n",
      "Epoch 114/200, Iteration 46/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 47/250, Loss: 0.0121\n",
      "Epoch 114/200, Iteration 48/250, Loss: 0.0380\n",
      "Epoch 114/200, Iteration 49/250, Loss: 0.0245\n",
      "Epoch 114/200, Iteration 50/250, Loss: 0.0117\n",
      "Epoch 114/200, Iteration 51/250, Loss: 0.0444\n",
      "Epoch 114/200, Iteration 52/250, Loss: 0.0087\n",
      "Epoch 114/200, Iteration 53/250, Loss: 0.0102\n",
      "Epoch 114/200, Iteration 54/250, Loss: 0.0248\n",
      "Epoch 114/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 56/250, Loss: 0.0082\n",
      "Epoch 114/200, Iteration 57/250, Loss: 0.0135\n",
      "Epoch 114/200, Iteration 58/250, Loss: 0.0267\n",
      "Epoch 114/200, Iteration 59/250, Loss: 0.0174\n",
      "Epoch 114/200, Iteration 60/250, Loss: 0.0162\n",
      "Epoch 114/200, Iteration 61/250, Loss: 0.0227\n",
      "Epoch 114/200, Iteration 62/250, Loss: 0.0152\n",
      "Epoch 114/200, Iteration 63/250, Loss: 0.0148\n",
      "Epoch 114/200, Iteration 64/250, Loss: 0.0232\n",
      "Epoch 114/200, Iteration 65/250, Loss: 0.0103\n",
      "Epoch 114/200, Iteration 66/250, Loss: 0.0205\n",
      "Epoch 114/200, Iteration 67/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 68/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 69/250, Loss: 0.0158\n",
      "Epoch 114/200, Iteration 70/250, Loss: 0.0155\n",
      "Epoch 114/200, Iteration 71/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 72/250, Loss: 0.0191\n",
      "Epoch 114/200, Iteration 73/250, Loss: 0.0082\n",
      "Epoch 114/200, Iteration 74/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 75/250, Loss: 0.0436\n",
      "Epoch 114/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 77/250, Loss: 0.0108\n",
      "Epoch 114/200, Iteration 78/250, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 79/250, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 81/250, Loss: 0.0088\n",
      "Epoch 114/200, Iteration 82/250, Loss: 0.0124\n",
      "Epoch 114/200, Iteration 83/250, Loss: 0.0108\n",
      "Epoch 114/200, Iteration 84/250, Loss: 0.0263\n",
      "Epoch 114/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 86/250, Loss: 0.0086\n",
      "Epoch 114/200, Iteration 87/250, Loss: 0.0132\n",
      "Epoch 114/200, Iteration 88/250, Loss: 0.0115\n",
      "Epoch 114/200, Iteration 89/250, Loss: 0.0087\n",
      "Epoch 114/200, Iteration 90/250, Loss: 0.0132\n",
      "Epoch 114/200, Iteration 91/250, Loss: 0.0145\n",
      "Epoch 114/200, Iteration 92/250, Loss: 0.0116\n",
      "Epoch 114/200, Iteration 93/250, Loss: 0.0160\n",
      "Epoch 114/200, Iteration 94/250, Loss: 0.0125\n",
      "Epoch 114/200, Iteration 95/250, Loss: 0.0164\n",
      "Epoch 114/200, Iteration 96/250, Loss: 0.0203\n",
      "Epoch 114/200, Iteration 97/250, Loss: 0.0173\n",
      "Epoch 114/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 99/250, Loss: 0.0224\n",
      "Epoch 114/200, Iteration 100/250, Loss: 0.0145\n",
      "Epoch 114/200, Iteration 101/250, Loss: 0.0102\n",
      "Epoch 114/200, Iteration 102/250, Loss: 0.0185\n",
      "Epoch 114/200, Iteration 103/250, Loss: 0.0099\n",
      "Epoch 114/200, Iteration 104/250, Loss: 0.0150\n",
      "Epoch 114/200, Iteration 105/250, Loss: 0.0090\n",
      "Epoch 114/200, Iteration 106/250, Loss: 0.0235\n",
      "Epoch 114/200, Iteration 107/250, Loss: 0.0269\n",
      "Epoch 114/200, Iteration 108/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 109/250, Loss: 0.0210\n",
      "Epoch 114/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 114/200, Iteration 111/250, Loss: 0.0220\n",
      "Epoch 114/200, Iteration 112/250, Loss: 0.0124\n",
      "Epoch 114/200, Iteration 113/250, Loss: 0.0094\n",
      "Epoch 114/200, Iteration 114/250, Loss: 0.0108\n",
      "Epoch 114/200, Iteration 115/250, Loss: 0.0182\n",
      "Epoch 114/200, Iteration 116/250, Loss: 0.0200\n",
      "Epoch 114/200, Iteration 117/250, Loss: 0.0172\n",
      "Epoch 114/200, Iteration 118/250, Loss: 0.0083\n",
      "Epoch 114/200, Iteration 119/250, Loss: 0.0356\n",
      "Epoch 114/200, Iteration 120/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 121/250, Loss: 0.0124\n",
      "Epoch 114/200, Iteration 122/250, Loss: 0.0211\n",
      "Epoch 114/200, Iteration 123/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 124/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 125/250, Loss: 0.0109\n",
      "Epoch 114/200, Iteration 126/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 127/250, Loss: 0.0115\n",
      "Epoch 114/200, Iteration 128/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 129/250, Loss: 0.0165\n",
      "Epoch 114/200, Iteration 130/250, Loss: 0.0129\n",
      "Epoch 114/200, Iteration 131/250, Loss: 0.0276\n",
      "Epoch 114/200, Iteration 132/250, Loss: 0.0104\n",
      "Epoch 114/200, Iteration 133/250, Loss: 0.0234\n",
      "Epoch 114/200, Iteration 134/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 135/250, Loss: 0.0189\n",
      "Epoch 114/200, Iteration 136/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 137/250, Loss: 0.0203\n",
      "Epoch 114/200, Iteration 138/250, Loss: 0.0123\n",
      "Epoch 114/200, Iteration 139/250, Loss: 0.0064\n",
      "Epoch 114/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 114/200, Iteration 141/250, Loss: 0.0078\n",
      "Epoch 114/200, Iteration 142/250, Loss: 0.0337\n",
      "Epoch 114/200, Iteration 143/250, Loss: 0.0109\n",
      "Epoch 114/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 114/200, Iteration 145/250, Loss: 0.0114\n",
      "Epoch 114/200, Iteration 146/250, Loss: 0.0100\n",
      "Epoch 114/200, Iteration 147/250, Loss: 0.0181\n",
      "Epoch 114/200, Iteration 148/250, Loss: 0.0065\n",
      "Epoch 114/200, Iteration 149/250, Loss: 0.0195\n",
      "Epoch 114/200, Iteration 150/250, Loss: 0.0252\n",
      "Epoch 114/200, Iteration 151/250, Loss: 0.0069\n",
      "Epoch 114/200, Iteration 152/250, Loss: 0.0150\n",
      "Epoch 114/200, Iteration 153/250, Loss: 0.0252\n",
      "Epoch 114/200, Iteration 154/250, Loss: 0.0198\n",
      "Epoch 114/200, Iteration 155/250, Loss: 0.0280\n",
      "Epoch 114/200, Iteration 156/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 157/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 158/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 159/250, Loss: 0.0065\n",
      "Epoch 114/200, Iteration 160/250, Loss: 0.0116\n",
      "Epoch 114/200, Iteration 161/250, Loss: 0.0095\n",
      "Epoch 114/200, Iteration 162/250, Loss: 0.0095\n",
      "Epoch 114/200, Iteration 163/250, Loss: 0.0173\n",
      "Epoch 114/200, Iteration 164/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 165/250, Loss: 0.0206\n",
      "Epoch 114/200, Iteration 166/250, Loss: 0.0094\n",
      "Epoch 114/200, Iteration 167/250, Loss: 0.0127\n",
      "Epoch 114/200, Iteration 168/250, Loss: 0.0121\n",
      "Epoch 114/200, Iteration 169/250, Loss: 0.0285\n",
      "Epoch 114/200, Iteration 170/250, Loss: 0.0288\n",
      "Epoch 114/200, Iteration 171/250, Loss: 0.0216\n",
      "Epoch 114/200, Iteration 172/250, Loss: 0.0218\n",
      "Epoch 114/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 114/200, Iteration 174/250, Loss: 0.0153\n",
      "Epoch 114/200, Iteration 175/250, Loss: 0.0119\n",
      "Epoch 114/200, Iteration 176/250, Loss: 0.0091\n",
      "Epoch 114/200, Iteration 177/250, Loss: 0.0144\n",
      "Epoch 114/200, Iteration 178/250, Loss: 0.0101\n",
      "Epoch 114/200, Iteration 179/250, Loss: 0.0157\n",
      "Epoch 114/200, Iteration 180/250, Loss: 0.0174\n",
      "Epoch 114/200, Iteration 181/250, Loss: 0.0246\n",
      "Epoch 114/200, Iteration 182/250, Loss: 0.0107\n",
      "Epoch 114/200, Iteration 183/250, Loss: 0.0132\n",
      "Epoch 114/200, Iteration 184/250, Loss: 0.0069\n",
      "Epoch 114/200, Iteration 185/250, Loss: 0.0381\n",
      "Epoch 114/200, Iteration 186/250, Loss: 0.0215\n",
      "Epoch 114/200, Iteration 187/250, Loss: 0.0123\n",
      "Epoch 114/200, Iteration 188/250, Loss: 0.0088\n",
      "Epoch 114/200, Iteration 189/250, Loss: 0.0108\n",
      "Epoch 114/200, Iteration 190/250, Loss: 0.0213\n",
      "Epoch 114/200, Iteration 191/250, Loss: 0.0092\n",
      "Epoch 114/200, Iteration 192/250, Loss: 0.0184\n",
      "Epoch 114/200, Iteration 193/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 194/250, Loss: 0.0244\n",
      "Epoch 114/200, Iteration 195/250, Loss: 0.0175\n",
      "Epoch 114/200, Iteration 196/250, Loss: 0.0171\n",
      "Epoch 114/200, Iteration 197/250, Loss: 0.0114\n",
      "Epoch 114/200, Iteration 198/250, Loss: 0.0220\n",
      "Epoch 114/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 114/200, Iteration 200/250, Loss: 0.0093\n",
      "Epoch 114/200, Iteration 201/250, Loss: 0.0267\n",
      "Epoch 114/200, Iteration 202/250, Loss: 0.0189\n",
      "Epoch 114/200, Iteration 203/250, Loss: 0.0229\n",
      "Epoch 114/200, Iteration 204/250, Loss: 0.0196\n",
      "Epoch 114/200, Iteration 205/250, Loss: 0.0174\n",
      "Epoch 114/200, Iteration 206/250, Loss: 0.0113\n",
      "Epoch 114/200, Iteration 207/250, Loss: 0.0284\n",
      "Epoch 114/200, Iteration 208/250, Loss: 0.0150\n",
      "Epoch 114/200, Iteration 209/250, Loss: 0.0208\n",
      "Epoch 114/200, Iteration 210/250, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 211/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 212/250, Loss: 0.0296\n",
      "Epoch 114/200, Iteration 213/250, Loss: 0.0145\n",
      "Epoch 114/200, Iteration 214/250, Loss: 0.0131\n",
      "Epoch 114/200, Iteration 215/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 114/200, Iteration 217/250, Loss: 0.0164\n",
      "Epoch 114/200, Iteration 218/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 219/250, Loss: 0.0285\n",
      "Epoch 114/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 114/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 114/200, Iteration 222/250, Loss: 0.0226\n",
      "Epoch 114/200, Iteration 223/250, Loss: 0.0089\n",
      "Epoch 114/200, Iteration 224/250, Loss: 0.0138\n",
      "Epoch 114/200, Iteration 225/250, Loss: 0.0178\n",
      "Epoch 114/200, Iteration 226/250, Loss: 0.0121\n",
      "Epoch 114/200, Iteration 227/250, Loss: 0.0252\n",
      "Epoch 114/200, Iteration 228/250, Loss: 0.0151\n",
      "Epoch 114/200, Iteration 229/250, Loss: 0.0139\n",
      "Epoch 114/200, Iteration 230/250, Loss: 0.0179\n",
      "Epoch 114/200, Iteration 231/250, Loss: 0.0103\n",
      "Epoch 114/200, Iteration 232/250, Loss: 0.0203\n",
      "Epoch 114/200, Iteration 233/250, Loss: 0.0106\n",
      "Epoch 114/200, Iteration 234/250, Loss: 0.0176\n",
      "Epoch 114/200, Iteration 235/250, Loss: 0.0240\n",
      "Epoch 114/200, Iteration 236/250, Loss: 0.0333\n",
      "Epoch 114/200, Iteration 237/250, Loss: 0.0090\n",
      "Epoch 114/200, Iteration 238/250, Loss: 0.0228\n",
      "Epoch 114/200, Iteration 239/250, Loss: 0.0128\n",
      "Epoch 114/200, Iteration 240/250, Loss: 0.0197\n",
      "Epoch 114/200, Iteration 241/250, Loss: 0.0193\n",
      "Epoch 114/200, Iteration 242/250, Loss: 0.0130\n",
      "Epoch 114/200, Iteration 243/250, Loss: 0.0096\n",
      "Epoch 114/200, Iteration 244/250, Loss: 0.0173\n",
      "Epoch 114/200, Iteration 245/250, Loss: 0.0085\n",
      "Epoch 114/200, Iteration 246/250, Loss: 0.0207\n",
      "Epoch 114/200, Iteration 247/250, Loss: 0.0136\n",
      "Epoch 114/200, Iteration 248/250, Loss: 0.0080\n",
      "Epoch 114/200, Iteration 249/250, Loss: 0.0130\n",
      "Epoch 114/200, Iteration 250/250, Loss: 0.0125\n",
      "Train Error: \n",
      " Accuracy: 85.08%, Avg loss: 0.006820, MRE: 0.435417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.35%, Avg loss: 0.007369, MRE: 0.535348 \n",
      "\n",
      "Epoch 115/200, Iteration 1/250, Loss: 0.0157\n",
      "Epoch 115/200, Iteration 2/250, Loss: 0.0107\n",
      "Epoch 115/200, Iteration 3/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 4/250, Loss: 0.0322\n",
      "Epoch 115/200, Iteration 5/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 6/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 7/250, Loss: 0.0202\n",
      "Epoch 115/200, Iteration 8/250, Loss: 0.0123\n",
      "Epoch 115/200, Iteration 9/250, Loss: 0.0114\n",
      "Epoch 115/200, Iteration 10/250, Loss: 0.0105\n",
      "Epoch 115/200, Iteration 11/250, Loss: 0.0196\n",
      "Epoch 115/200, Iteration 12/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 13/250, Loss: 0.0160\n",
      "Epoch 115/200, Iteration 14/250, Loss: 0.0191\n",
      "Epoch 115/200, Iteration 15/250, Loss: 0.0116\n",
      "Epoch 115/200, Iteration 16/250, Loss: 0.0141\n",
      "Epoch 115/200, Iteration 17/250, Loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200, Iteration 18/250, Loss: 0.0110\n",
      "Epoch 115/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 20/250, Loss: 0.0082\n",
      "Epoch 115/200, Iteration 21/250, Loss: 0.0148\n",
      "Epoch 115/200, Iteration 22/250, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 23/250, Loss: 0.0273\n",
      "Epoch 115/200, Iteration 24/250, Loss: 0.0090\n",
      "Epoch 115/200, Iteration 25/250, Loss: 0.0223\n",
      "Epoch 115/200, Iteration 26/250, Loss: 0.0206\n",
      "Epoch 115/200, Iteration 27/250, Loss: 0.0181\n",
      "Epoch 115/200, Iteration 28/250, Loss: 0.0118\n",
      "Epoch 115/200, Iteration 29/250, Loss: 0.0111\n",
      "Epoch 115/200, Iteration 30/250, Loss: 0.0147\n",
      "Epoch 115/200, Iteration 31/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 32/250, Loss: 0.0143\n",
      "Epoch 115/200, Iteration 33/250, Loss: 0.0070\n",
      "Epoch 115/200, Iteration 34/250, Loss: 0.0084\n",
      "Epoch 115/200, Iteration 35/250, Loss: 0.0283\n",
      "Epoch 115/200, Iteration 36/250, Loss: 0.0298\n",
      "Epoch 115/200, Iteration 37/250, Loss: 0.0217\n",
      "Epoch 115/200, Iteration 38/250, Loss: 0.0126\n",
      "Epoch 115/200, Iteration 39/250, Loss: 0.0113\n",
      "Epoch 115/200, Iteration 40/250, Loss: 0.0173\n",
      "Epoch 115/200, Iteration 41/250, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 42/250, Loss: 0.0186\n",
      "Epoch 115/200, Iteration 43/250, Loss: 0.0379\n",
      "Epoch 115/200, Iteration 44/250, Loss: 0.0173\n",
      "Epoch 115/200, Iteration 45/250, Loss: 0.0110\n",
      "Epoch 115/200, Iteration 46/250, Loss: 0.0291\n",
      "Epoch 115/200, Iteration 47/250, Loss: 0.0122\n",
      "Epoch 115/200, Iteration 48/250, Loss: 0.0122\n",
      "Epoch 115/200, Iteration 49/250, Loss: 0.0161\n",
      "Epoch 115/200, Iteration 50/250, Loss: 0.0222\n",
      "Epoch 115/200, Iteration 51/250, Loss: 0.0184\n",
      "Epoch 115/200, Iteration 52/250, Loss: 0.0189\n",
      "Epoch 115/200, Iteration 53/250, Loss: 0.0076\n",
      "Epoch 115/200, Iteration 54/250, Loss: 0.0158\n",
      "Epoch 115/200, Iteration 55/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 56/250, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 115/200, Iteration 58/250, Loss: 0.0174\n",
      "Epoch 115/200, Iteration 59/250, Loss: 0.0177\n",
      "Epoch 115/200, Iteration 60/250, Loss: 0.0313\n",
      "Epoch 115/200, Iteration 61/250, Loss: 0.0311\n",
      "Epoch 115/200, Iteration 62/250, Loss: 0.0211\n",
      "Epoch 115/200, Iteration 63/250, Loss: 0.0109\n",
      "Epoch 115/200, Iteration 64/250, Loss: 0.0180\n",
      "Epoch 115/200, Iteration 65/250, Loss: 0.0086\n",
      "Epoch 115/200, Iteration 66/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 67/250, Loss: 0.0230\n",
      "Epoch 115/200, Iteration 68/250, Loss: 0.0092\n",
      "Epoch 115/200, Iteration 69/250, Loss: 0.0082\n",
      "Epoch 115/200, Iteration 70/250, Loss: 0.0180\n",
      "Epoch 115/200, Iteration 71/250, Loss: 0.0160\n",
      "Epoch 115/200, Iteration 72/250, Loss: 0.0273\n",
      "Epoch 115/200, Iteration 73/250, Loss: 0.0335\n",
      "Epoch 115/200, Iteration 74/250, Loss: 0.0105\n",
      "Epoch 115/200, Iteration 75/250, Loss: 0.0214\n",
      "Epoch 115/200, Iteration 76/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 77/250, Loss: 0.0098\n",
      "Epoch 115/200, Iteration 78/250, Loss: 0.0230\n",
      "Epoch 115/200, Iteration 79/250, Loss: 0.0102\n",
      "Epoch 115/200, Iteration 80/250, Loss: 0.0137\n",
      "Epoch 115/200, Iteration 81/250, Loss: 0.0104\n",
      "Epoch 115/200, Iteration 82/250, Loss: 0.0085\n",
      "Epoch 115/200, Iteration 83/250, Loss: 0.0097\n",
      "Epoch 115/200, Iteration 84/250, Loss: 0.0108\n",
      "Epoch 115/200, Iteration 85/250, Loss: 0.0186\n",
      "Epoch 115/200, Iteration 86/250, Loss: 0.0304\n",
      "Epoch 115/200, Iteration 87/250, Loss: 0.0140\n",
      "Epoch 115/200, Iteration 88/250, Loss: 0.0139\n",
      "Epoch 115/200, Iteration 89/250, Loss: 0.0131\n",
      "Epoch 115/200, Iteration 90/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 91/250, Loss: 0.0185\n",
      "Epoch 115/200, Iteration 92/250, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 93/250, Loss: 0.0149\n",
      "Epoch 115/200, Iteration 94/250, Loss: 0.0065\n",
      "Epoch 115/200, Iteration 95/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 96/250, Loss: 0.0064\n",
      "Epoch 115/200, Iteration 97/250, Loss: 0.0081\n",
      "Epoch 115/200, Iteration 98/250, Loss: 0.0207\n",
      "Epoch 115/200, Iteration 99/250, Loss: 0.0303\n",
      "Epoch 115/200, Iteration 100/250, Loss: 0.0101\n",
      "Epoch 115/200, Iteration 101/250, Loss: 0.0078\n",
      "Epoch 115/200, Iteration 102/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 103/250, Loss: 0.0177\n",
      "Epoch 115/200, Iteration 104/250, Loss: 0.0181\n",
      "Epoch 115/200, Iteration 105/250, Loss: 0.0114\n",
      "Epoch 115/200, Iteration 106/250, Loss: 0.0174\n",
      "Epoch 115/200, Iteration 107/250, Loss: 0.0153\n",
      "Epoch 115/200, Iteration 108/250, Loss: 0.0153\n",
      "Epoch 115/200, Iteration 109/250, Loss: 0.0142\n",
      "Epoch 115/200, Iteration 110/250, Loss: 0.0179\n",
      "Epoch 115/200, Iteration 111/250, Loss: 0.0291\n",
      "Epoch 115/200, Iteration 112/250, Loss: 0.0112\n",
      "Epoch 115/200, Iteration 113/250, Loss: 0.0074\n",
      "Epoch 115/200, Iteration 114/250, Loss: 0.0325\n",
      "Epoch 115/200, Iteration 115/250, Loss: 0.0170\n",
      "Epoch 115/200, Iteration 116/250, Loss: 0.0079\n",
      "Epoch 115/200, Iteration 117/250, Loss: 0.0171\n",
      "Epoch 115/200, Iteration 118/250, Loss: 0.0155\n",
      "Epoch 115/200, Iteration 119/250, Loss: 0.0129\n",
      "Epoch 115/200, Iteration 120/250, Loss: 0.0092\n",
      "Epoch 115/200, Iteration 121/250, Loss: 0.0133\n",
      "Epoch 115/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 115/200, Iteration 123/250, Loss: 0.0304\n",
      "Epoch 115/200, Iteration 124/250, Loss: 0.0239\n",
      "Epoch 115/200, Iteration 125/250, Loss: 0.0137\n",
      "Epoch 115/200, Iteration 126/250, Loss: 0.0118\n",
      "Epoch 115/200, Iteration 127/250, Loss: 0.0099\n",
      "Epoch 115/200, Iteration 128/250, Loss: 0.0092\n",
      "Epoch 115/200, Iteration 129/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 130/250, Loss: 0.0100\n",
      "Epoch 115/200, Iteration 131/250, Loss: 0.0270\n",
      "Epoch 115/200, Iteration 132/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 133/250, Loss: 0.0194\n",
      "Epoch 115/200, Iteration 134/250, Loss: 0.0471\n",
      "Epoch 115/200, Iteration 135/250, Loss: 0.0146\n",
      "Epoch 115/200, Iteration 136/250, Loss: 0.0326\n",
      "Epoch 115/200, Iteration 137/250, Loss: 0.0080\n",
      "Epoch 115/200, Iteration 138/250, Loss: 0.0128\n",
      "Epoch 115/200, Iteration 139/250, Loss: 0.0120\n",
      "Epoch 115/200, Iteration 140/250, Loss: 0.0196\n",
      "Epoch 115/200, Iteration 141/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 143/250, Loss: 0.0286\n",
      "Epoch 115/200, Iteration 144/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 145/250, Loss: 0.0144\n",
      "Epoch 115/200, Iteration 146/250, Loss: 0.0141\n",
      "Epoch 115/200, Iteration 147/250, Loss: 0.0145\n",
      "Epoch 115/200, Iteration 148/250, Loss: 0.0090\n",
      "Epoch 115/200, Iteration 149/250, Loss: 0.0124\n",
      "Epoch 115/200, Iteration 150/250, Loss: 0.0124\n",
      "Epoch 115/200, Iteration 151/250, Loss: 0.0179\n",
      "Epoch 115/200, Iteration 152/250, Loss: 0.0343\n",
      "Epoch 115/200, Iteration 153/250, Loss: 0.0196\n",
      "Epoch 115/200, Iteration 154/250, Loss: 0.0098\n",
      "Epoch 115/200, Iteration 155/250, Loss: 0.0265\n",
      "Epoch 115/200, Iteration 156/250, Loss: 0.0145\n",
      "Epoch 115/200, Iteration 157/250, Loss: 0.0200\n",
      "Epoch 115/200, Iteration 158/250, Loss: 0.0180\n",
      "Epoch 115/200, Iteration 159/250, Loss: 0.0222\n",
      "Epoch 115/200, Iteration 160/250, Loss: 0.0080\n",
      "Epoch 115/200, Iteration 161/250, Loss: 0.0231\n",
      "Epoch 115/200, Iteration 162/250, Loss: 0.0106\n",
      "Epoch 115/200, Iteration 163/250, Loss: 0.0121\n",
      "Epoch 115/200, Iteration 164/250, Loss: 0.0376\n",
      "Epoch 115/200, Iteration 165/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 166/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 167/250, Loss: 0.0182\n",
      "Epoch 115/200, Iteration 168/250, Loss: 0.0156\n",
      "Epoch 115/200, Iteration 169/250, Loss: 0.0112\n",
      "Epoch 115/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 115/200, Iteration 171/250, Loss: 0.0138\n",
      "Epoch 115/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 173/250, Loss: 0.0152\n",
      "Epoch 115/200, Iteration 174/250, Loss: 0.0310\n",
      "Epoch 115/200, Iteration 175/250, Loss: 0.0111\n",
      "Epoch 115/200, Iteration 176/250, Loss: 0.0150\n",
      "Epoch 115/200, Iteration 177/250, Loss: 0.0250\n",
      "Epoch 115/200, Iteration 178/250, Loss: 0.0155\n",
      "Epoch 115/200, Iteration 179/250, Loss: 0.0326\n",
      "Epoch 115/200, Iteration 180/250, Loss: 0.0142\n",
      "Epoch 115/200, Iteration 181/250, Loss: 0.0262\n",
      "Epoch 115/200, Iteration 182/250, Loss: 0.0312\n",
      "Epoch 115/200, Iteration 183/250, Loss: 0.0158\n",
      "Epoch 115/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 185/250, Loss: 0.0179\n",
      "Epoch 115/200, Iteration 186/250, Loss: 0.0142\n",
      "Epoch 115/200, Iteration 187/250, Loss: 0.0093\n",
      "Epoch 115/200, Iteration 188/250, Loss: 0.0237\n",
      "Epoch 115/200, Iteration 189/250, Loss: 0.0102\n",
      "Epoch 115/200, Iteration 190/250, Loss: 0.0154\n",
      "Epoch 115/200, Iteration 191/250, Loss: 0.0287\n",
      "Epoch 115/200, Iteration 192/250, Loss: 0.0135\n",
      "Epoch 115/200, Iteration 193/250, Loss: 0.0083\n",
      "Epoch 115/200, Iteration 194/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 195/250, Loss: 0.0191\n",
      "Epoch 115/200, Iteration 196/250, Loss: 0.0101\n",
      "Epoch 115/200, Iteration 197/250, Loss: 0.0103\n",
      "Epoch 115/200, Iteration 198/250, Loss: 0.0119\n",
      "Epoch 115/200, Iteration 199/250, Loss: 0.0119\n",
      "Epoch 115/200, Iteration 200/250, Loss: 0.0128\n",
      "Epoch 115/200, Iteration 201/250, Loss: 0.0093\n",
      "Epoch 115/200, Iteration 202/250, Loss: 0.0224\n",
      "Epoch 115/200, Iteration 203/250, Loss: 0.0172\n",
      "Epoch 115/200, Iteration 204/250, Loss: 0.0070\n",
      "Epoch 115/200, Iteration 205/250, Loss: 0.0075\n",
      "Epoch 115/200, Iteration 206/250, Loss: 0.0396\n",
      "Epoch 115/200, Iteration 207/250, Loss: 0.0143\n",
      "Epoch 115/200, Iteration 208/250, Loss: 0.0148\n",
      "Epoch 115/200, Iteration 209/250, Loss: 0.0089\n",
      "Epoch 115/200, Iteration 210/250, Loss: 0.0096\n",
      "Epoch 115/200, Iteration 211/250, Loss: 0.0107\n",
      "Epoch 115/200, Iteration 212/250, Loss: 0.0215\n",
      "Epoch 115/200, Iteration 213/250, Loss: 0.0088\n",
      "Epoch 115/200, Iteration 214/250, Loss: 0.0287\n",
      "Epoch 115/200, Iteration 215/250, Loss: 0.0321\n",
      "Epoch 115/200, Iteration 216/250, Loss: 0.0175\n",
      "Epoch 115/200, Iteration 217/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 218/250, Loss: 0.0253\n",
      "Epoch 115/200, Iteration 219/250, Loss: 0.0205\n",
      "Epoch 115/200, Iteration 220/250, Loss: 0.0118\n",
      "Epoch 115/200, Iteration 221/250, Loss: 0.0155\n",
      "Epoch 115/200, Iteration 222/250, Loss: 0.0074\n",
      "Epoch 115/200, Iteration 223/250, Loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200, Iteration 224/250, Loss: 0.0125\n",
      "Epoch 115/200, Iteration 225/250, Loss: 0.0226\n",
      "Epoch 115/200, Iteration 226/250, Loss: 0.0268\n",
      "Epoch 115/200, Iteration 227/250, Loss: 0.0162\n",
      "Epoch 115/200, Iteration 228/250, Loss: 0.0130\n",
      "Epoch 115/200, Iteration 229/250, Loss: 0.0221\n",
      "Epoch 115/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 115/200, Iteration 231/250, Loss: 0.0075\n",
      "Epoch 115/200, Iteration 232/250, Loss: 0.0147\n",
      "Epoch 115/200, Iteration 233/250, Loss: 0.0081\n",
      "Epoch 115/200, Iteration 234/250, Loss: 0.0112\n",
      "Epoch 115/200, Iteration 235/250, Loss: 0.0205\n",
      "Epoch 115/200, Iteration 236/250, Loss: 0.0219\n",
      "Epoch 115/200, Iteration 237/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 238/250, Loss: 0.0078\n",
      "Epoch 115/200, Iteration 239/250, Loss: 0.0159\n",
      "Epoch 115/200, Iteration 240/250, Loss: 0.0126\n",
      "Epoch 115/200, Iteration 241/250, Loss: 0.0163\n",
      "Epoch 115/200, Iteration 242/250, Loss: 0.0084\n",
      "Epoch 115/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 115/200, Iteration 244/250, Loss: 0.0415\n",
      "Epoch 115/200, Iteration 245/250, Loss: 0.0172\n",
      "Epoch 115/200, Iteration 246/250, Loss: 0.0132\n",
      "Epoch 115/200, Iteration 247/250, Loss: 0.0069\n",
      "Epoch 115/200, Iteration 248/250, Loss: 0.0109\n",
      "Epoch 115/200, Iteration 249/250, Loss: 0.0175\n",
      "Epoch 115/200, Iteration 250/250, Loss: 0.0221\n",
      "Train Error: \n",
      " Accuracy: 81.64%, Avg loss: 0.007061, MRE: 0.480249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.007497, MRE: 0.549304 \n",
      "\n",
      "Epoch 116/200, Iteration 1/250, Loss: 0.0080\n",
      "Epoch 116/200, Iteration 2/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 3/250, Loss: 0.0130\n",
      "Epoch 116/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 5/250, Loss: 0.0101\n",
      "Epoch 116/200, Iteration 6/250, Loss: 0.0149\n",
      "Epoch 116/200, Iteration 7/250, Loss: 0.0122\n",
      "Epoch 116/200, Iteration 8/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 9/250, Loss: 0.0321\n",
      "Epoch 116/200, Iteration 10/250, Loss: 0.0123\n",
      "Epoch 116/200, Iteration 11/250, Loss: 0.0239\n",
      "Epoch 116/200, Iteration 12/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 13/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 14/250, Loss: 0.0130\n",
      "Epoch 116/200, Iteration 15/250, Loss: 0.0362\n",
      "Epoch 116/200, Iteration 16/250, Loss: 0.0081\n",
      "Epoch 116/200, Iteration 17/250, Loss: 0.0357\n",
      "Epoch 116/200, Iteration 18/250, Loss: 0.0135\n",
      "Epoch 116/200, Iteration 19/250, Loss: 0.0223\n",
      "Epoch 116/200, Iteration 20/250, Loss: 0.0161\n",
      "Epoch 116/200, Iteration 21/250, Loss: 0.0287\n",
      "Epoch 116/200, Iteration 22/250, Loss: 0.0223\n",
      "Epoch 116/200, Iteration 23/250, Loss: 0.0221\n",
      "Epoch 116/200, Iteration 24/250, Loss: 0.0440\n",
      "Epoch 116/200, Iteration 25/250, Loss: 0.0100\n",
      "Epoch 116/200, Iteration 26/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 27/250, Loss: 0.0278\n",
      "Epoch 116/200, Iteration 28/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 29/250, Loss: 0.0096\n",
      "Epoch 116/200, Iteration 30/250, Loss: 0.0103\n",
      "Epoch 116/200, Iteration 31/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 32/250, Loss: 0.0070\n",
      "Epoch 116/200, Iteration 33/250, Loss: 0.0248\n",
      "Epoch 116/200, Iteration 34/250, Loss: 0.0255\n",
      "Epoch 116/200, Iteration 35/250, Loss: 0.0065\n",
      "Epoch 116/200, Iteration 36/250, Loss: 0.0302\n",
      "Epoch 116/200, Iteration 37/250, Loss: 0.0122\n",
      "Epoch 116/200, Iteration 38/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 39/250, Loss: 0.0187\n",
      "Epoch 116/200, Iteration 40/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 41/250, Loss: 0.0103\n",
      "Epoch 116/200, Iteration 42/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 43/250, Loss: 0.0090\n",
      "Epoch 116/200, Iteration 44/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 45/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 46/250, Loss: 0.0445\n",
      "Epoch 116/200, Iteration 47/250, Loss: 0.0204\n",
      "Epoch 116/200, Iteration 48/250, Loss: 0.0078\n",
      "Epoch 116/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 50/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 51/250, Loss: 0.0224\n",
      "Epoch 116/200, Iteration 52/250, Loss: 0.0134\n",
      "Epoch 116/200, Iteration 53/250, Loss: 0.0180\n",
      "Epoch 116/200, Iteration 54/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 55/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 56/250, Loss: 0.0090\n",
      "Epoch 116/200, Iteration 57/250, Loss: 0.0118\n",
      "Epoch 116/200, Iteration 58/250, Loss: 0.0139\n",
      "Epoch 116/200, Iteration 59/250, Loss: 0.0120\n",
      "Epoch 116/200, Iteration 60/250, Loss: 0.0248\n",
      "Epoch 116/200, Iteration 61/250, Loss: 0.0163\n",
      "Epoch 116/200, Iteration 62/250, Loss: 0.0240\n",
      "Epoch 116/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 64/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 65/250, Loss: 0.0077\n",
      "Epoch 116/200, Iteration 66/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 67/250, Loss: 0.0156\n",
      "Epoch 116/200, Iteration 68/250, Loss: 0.0275\n",
      "Epoch 116/200, Iteration 69/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 116/200, Iteration 71/250, Loss: 0.0164\n",
      "Epoch 116/200, Iteration 72/250, Loss: 0.0297\n",
      "Epoch 116/200, Iteration 73/250, Loss: 0.0220\n",
      "Epoch 116/200, Iteration 74/250, Loss: 0.0255\n",
      "Epoch 116/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 116/200, Iteration 76/250, Loss: 0.0341\n",
      "Epoch 116/200, Iteration 77/250, Loss: 0.0104\n",
      "Epoch 116/200, Iteration 78/250, Loss: 0.0119\n",
      "Epoch 116/200, Iteration 79/250, Loss: 0.0116\n",
      "Epoch 116/200, Iteration 80/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 81/250, Loss: 0.0154\n",
      "Epoch 116/200, Iteration 82/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 83/250, Loss: 0.0291\n",
      "Epoch 116/200, Iteration 84/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 85/250, Loss: 0.0195\n",
      "Epoch 116/200, Iteration 86/250, Loss: 0.0088\n",
      "Epoch 116/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 116/200, Iteration 88/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 89/250, Loss: 0.0078\n",
      "Epoch 116/200, Iteration 90/250, Loss: 0.0155\n",
      "Epoch 116/200, Iteration 91/250, Loss: 0.0267\n",
      "Epoch 116/200, Iteration 92/250, Loss: 0.0134\n",
      "Epoch 116/200, Iteration 93/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 94/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 95/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 96/250, Loss: 0.0282\n",
      "Epoch 116/200, Iteration 97/250, Loss: 0.0183\n",
      "Epoch 116/200, Iteration 98/250, Loss: 0.0122\n",
      "Epoch 116/200, Iteration 99/250, Loss: 0.0257\n",
      "Epoch 116/200, Iteration 100/250, Loss: 0.0303\n",
      "Epoch 116/200, Iteration 101/250, Loss: 0.0074\n",
      "Epoch 116/200, Iteration 102/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 103/250, Loss: 0.0114\n",
      "Epoch 116/200, Iteration 104/250, Loss: 0.0187\n",
      "Epoch 116/200, Iteration 105/250, Loss: 0.0098\n",
      "Epoch 116/200, Iteration 106/250, Loss: 0.0178\n",
      "Epoch 116/200, Iteration 107/250, Loss: 0.0242\n",
      "Epoch 116/200, Iteration 108/250, Loss: 0.0068\n",
      "Epoch 116/200, Iteration 109/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 110/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 111/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 112/250, Loss: 0.0273\n",
      "Epoch 116/200, Iteration 113/250, Loss: 0.0125\n",
      "Epoch 116/200, Iteration 114/250, Loss: 0.0157\n",
      "Epoch 116/200, Iteration 115/250, Loss: 0.0264\n",
      "Epoch 116/200, Iteration 116/250, Loss: 0.0126\n",
      "Epoch 116/200, Iteration 117/250, Loss: 0.0233\n",
      "Epoch 116/200, Iteration 118/250, Loss: 0.0214\n",
      "Epoch 116/200, Iteration 119/250, Loss: 0.0151\n",
      "Epoch 116/200, Iteration 120/250, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 121/250, Loss: 0.0166\n",
      "Epoch 116/200, Iteration 122/250, Loss: 0.0309\n",
      "Epoch 116/200, Iteration 123/250, Loss: 0.0211\n",
      "Epoch 116/200, Iteration 124/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 125/250, Loss: 0.0094\n",
      "Epoch 116/200, Iteration 126/250, Loss: 0.0109\n",
      "Epoch 116/200, Iteration 127/250, Loss: 0.0290\n",
      "Epoch 116/200, Iteration 128/250, Loss: 0.0121\n",
      "Epoch 116/200, Iteration 129/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 130/250, Loss: 0.0205\n",
      "Epoch 116/200, Iteration 131/250, Loss: 0.0078\n",
      "Epoch 116/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 116/200, Iteration 133/250, Loss: 0.0102\n",
      "Epoch 116/200, Iteration 134/250, Loss: 0.0128\n",
      "Epoch 116/200, Iteration 135/250, Loss: 0.0146\n",
      "Epoch 116/200, Iteration 136/250, Loss: 0.0083\n",
      "Epoch 116/200, Iteration 137/250, Loss: 0.0109\n",
      "Epoch 116/200, Iteration 138/250, Loss: 0.0124\n",
      "Epoch 116/200, Iteration 139/250, Loss: 0.0333\n",
      "Epoch 116/200, Iteration 140/250, Loss: 0.0190\n",
      "Epoch 116/200, Iteration 141/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 142/250, Loss: 0.0194\n",
      "Epoch 116/200, Iteration 143/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 144/250, Loss: 0.0108\n",
      "Epoch 116/200, Iteration 145/250, Loss: 0.0316\n",
      "Epoch 116/200, Iteration 146/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 147/250, Loss: 0.0124\n",
      "Epoch 116/200, Iteration 148/250, Loss: 0.0345\n",
      "Epoch 116/200, Iteration 149/250, Loss: 0.0199\n",
      "Epoch 116/200, Iteration 150/250, Loss: 0.0076\n",
      "Epoch 116/200, Iteration 151/250, Loss: 0.0137\n",
      "Epoch 116/200, Iteration 152/250, Loss: 0.0397\n",
      "Epoch 116/200, Iteration 153/250, Loss: 0.0170\n",
      "Epoch 116/200, Iteration 154/250, Loss: 0.0143\n",
      "Epoch 116/200, Iteration 155/250, Loss: 0.0081\n",
      "Epoch 116/200, Iteration 156/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 157/250, Loss: 0.0199\n",
      "Epoch 116/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 159/250, Loss: 0.0277\n",
      "Epoch 116/200, Iteration 160/250, Loss: 0.0324\n",
      "Epoch 116/200, Iteration 161/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 162/250, Loss: 0.0089\n",
      "Epoch 116/200, Iteration 163/250, Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200, Iteration 164/250, Loss: 0.0075\n",
      "Epoch 116/200, Iteration 165/250, Loss: 0.0079\n",
      "Epoch 116/200, Iteration 166/250, Loss: 0.0131\n",
      "Epoch 116/200, Iteration 167/250, Loss: 0.0159\n",
      "Epoch 116/200, Iteration 168/250, Loss: 0.0210\n",
      "Epoch 116/200, Iteration 169/250, Loss: 0.0203\n",
      "Epoch 116/200, Iteration 170/250, Loss: 0.0073\n",
      "Epoch 116/200, Iteration 171/250, Loss: 0.0164\n",
      "Epoch 116/200, Iteration 172/250, Loss: 0.0269\n",
      "Epoch 116/200, Iteration 173/250, Loss: 0.0211\n",
      "Epoch 116/200, Iteration 174/250, Loss: 0.0213\n",
      "Epoch 116/200, Iteration 175/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 176/250, Loss: 0.0147\n",
      "Epoch 116/200, Iteration 177/250, Loss: 0.0150\n",
      "Epoch 116/200, Iteration 178/250, Loss: 0.0082\n",
      "Epoch 116/200, Iteration 179/250, Loss: 0.0345\n",
      "Epoch 116/200, Iteration 180/250, Loss: 0.0204\n",
      "Epoch 116/200, Iteration 181/250, Loss: 0.0129\n",
      "Epoch 116/200, Iteration 182/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 183/250, Loss: 0.0084\n",
      "Epoch 116/200, Iteration 184/250, Loss: 0.0232\n",
      "Epoch 116/200, Iteration 185/250, Loss: 0.0296\n",
      "Epoch 116/200, Iteration 186/250, Loss: 0.0481\n",
      "Epoch 116/200, Iteration 187/250, Loss: 0.0267\n",
      "Epoch 116/200, Iteration 188/250, Loss: 0.0139\n",
      "Epoch 116/200, Iteration 189/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 190/250, Loss: 0.0318\n",
      "Epoch 116/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 116/200, Iteration 192/250, Loss: 0.0086\n",
      "Epoch 116/200, Iteration 193/250, Loss: 0.0077\n",
      "Epoch 116/200, Iteration 194/250, Loss: 0.0069\n",
      "Epoch 116/200, Iteration 195/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 196/250, Loss: 0.0147\n",
      "Epoch 116/200, Iteration 197/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 198/250, Loss: 0.0206\n",
      "Epoch 116/200, Iteration 199/250, Loss: 0.0148\n",
      "Epoch 116/200, Iteration 200/250, Loss: 0.0105\n",
      "Epoch 116/200, Iteration 201/250, Loss: 0.0100\n",
      "Epoch 116/200, Iteration 202/250, Loss: 0.0117\n",
      "Epoch 116/200, Iteration 203/250, Loss: 0.0131\n",
      "Epoch 116/200, Iteration 204/250, Loss: 0.0152\n",
      "Epoch 116/200, Iteration 205/250, Loss: 0.0192\n",
      "Epoch 116/200, Iteration 206/250, Loss: 0.0173\n",
      "Epoch 116/200, Iteration 207/250, Loss: 0.0218\n",
      "Epoch 116/200, Iteration 208/250, Loss: 0.0205\n",
      "Epoch 116/200, Iteration 209/250, Loss: 0.0140\n",
      "Epoch 116/200, Iteration 210/250, Loss: 0.0095\n",
      "Epoch 116/200, Iteration 211/250, Loss: 0.0085\n",
      "Epoch 116/200, Iteration 212/250, Loss: 0.0180\n",
      "Epoch 116/200, Iteration 213/250, Loss: 0.0071\n",
      "Epoch 116/200, Iteration 214/250, Loss: 0.0115\n",
      "Epoch 116/200, Iteration 215/250, Loss: 0.0079\n",
      "Epoch 116/200, Iteration 216/250, Loss: 0.0111\n",
      "Epoch 116/200, Iteration 217/250, Loss: 0.0110\n",
      "Epoch 116/200, Iteration 218/250, Loss: 0.0289\n",
      "Epoch 116/200, Iteration 219/250, Loss: 0.0123\n",
      "Epoch 116/200, Iteration 220/250, Loss: 0.0401\n",
      "Epoch 116/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 116/200, Iteration 222/250, Loss: 0.0411\n",
      "Epoch 116/200, Iteration 223/250, Loss: 0.0141\n",
      "Epoch 116/200, Iteration 224/250, Loss: 0.0131\n",
      "Epoch 116/200, Iteration 225/250, Loss: 0.0080\n",
      "Epoch 116/200, Iteration 226/250, Loss: 0.0238\n",
      "Epoch 116/200, Iteration 227/250, Loss: 0.0099\n",
      "Epoch 116/200, Iteration 228/250, Loss: 0.0124\n",
      "Epoch 116/200, Iteration 229/250, Loss: 0.0150\n",
      "Epoch 116/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 116/200, Iteration 231/250, Loss: 0.0243\n",
      "Epoch 116/200, Iteration 232/250, Loss: 0.0241\n",
      "Epoch 116/200, Iteration 233/250, Loss: 0.0116\n",
      "Epoch 116/200, Iteration 234/250, Loss: 0.0079\n",
      "Epoch 116/200, Iteration 235/250, Loss: 0.0097\n",
      "Epoch 116/200, Iteration 236/250, Loss: 0.0222\n",
      "Epoch 116/200, Iteration 237/250, Loss: 0.0097\n",
      "Epoch 116/200, Iteration 238/250, Loss: 0.0091\n",
      "Epoch 116/200, Iteration 239/250, Loss: 0.0135\n",
      "Epoch 116/200, Iteration 240/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 241/250, Loss: 0.0142\n",
      "Epoch 116/200, Iteration 242/250, Loss: 0.0077\n",
      "Epoch 116/200, Iteration 243/250, Loss: 0.0385\n",
      "Epoch 116/200, Iteration 244/250, Loss: 0.0109\n",
      "Epoch 116/200, Iteration 245/250, Loss: 0.0163\n",
      "Epoch 116/200, Iteration 246/250, Loss: 0.0256\n",
      "Epoch 116/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 116/200, Iteration 248/250, Loss: 0.0285\n",
      "Epoch 116/200, Iteration 249/250, Loss: 0.0145\n",
      "Epoch 116/200, Iteration 250/250, Loss: 0.0302\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.007548, MRE: 0.548518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.007894, MRE: 0.550178 \n",
      "\n",
      "Epoch 117/200, Iteration 1/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 2/250, Loss: 0.0470\n",
      "Epoch 117/200, Iteration 3/250, Loss: 0.0260\n",
      "Epoch 117/200, Iteration 4/250, Loss: 0.0150\n",
      "Epoch 117/200, Iteration 5/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 6/250, Loss: 0.0289\n",
      "Epoch 117/200, Iteration 7/250, Loss: 0.0175\n",
      "Epoch 117/200, Iteration 8/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 9/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 117/200, Iteration 11/250, Loss: 0.0271\n",
      "Epoch 117/200, Iteration 12/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 13/250, Loss: 0.0097\n",
      "Epoch 117/200, Iteration 14/250, Loss: 0.0102\n",
      "Epoch 117/200, Iteration 15/250, Loss: 0.0226\n",
      "Epoch 117/200, Iteration 16/250, Loss: 0.0217\n",
      "Epoch 117/200, Iteration 17/250, Loss: 0.0197\n",
      "Epoch 117/200, Iteration 18/250, Loss: 0.0181\n",
      "Epoch 117/200, Iteration 19/250, Loss: 0.0156\n",
      "Epoch 117/200, Iteration 20/250, Loss: 0.0065\n",
      "Epoch 117/200, Iteration 21/250, Loss: 0.0302\n",
      "Epoch 117/200, Iteration 22/250, Loss: 0.0149\n",
      "Epoch 117/200, Iteration 23/250, Loss: 0.0262\n",
      "Epoch 117/200, Iteration 24/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 25/250, Loss: 0.0079\n",
      "Epoch 117/200, Iteration 26/250, Loss: 0.0136\n",
      "Epoch 117/200, Iteration 27/250, Loss: 0.0118\n",
      "Epoch 117/200, Iteration 28/250, Loss: 0.0303\n",
      "Epoch 117/200, Iteration 29/250, Loss: 0.0222\n",
      "Epoch 117/200, Iteration 30/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 31/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 32/250, Loss: 0.0070\n",
      "Epoch 117/200, Iteration 33/250, Loss: 0.0488\n",
      "Epoch 117/200, Iteration 34/250, Loss: 0.0156\n",
      "Epoch 117/200, Iteration 35/250, Loss: 0.0120\n",
      "Epoch 117/200, Iteration 36/250, Loss: 0.0228\n",
      "Epoch 117/200, Iteration 37/250, Loss: 0.0146\n",
      "Epoch 117/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 117/200, Iteration 39/250, Loss: 0.0086\n",
      "Epoch 117/200, Iteration 40/250, Loss: 0.0110\n",
      "Epoch 117/200, Iteration 41/250, Loss: 0.0079\n",
      "Epoch 117/200, Iteration 42/250, Loss: 0.0187\n",
      "Epoch 117/200, Iteration 43/250, Loss: 0.0162\n",
      "Epoch 117/200, Iteration 44/250, Loss: 0.0140\n",
      "Epoch 117/200, Iteration 45/250, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 46/250, Loss: 0.0193\n",
      "Epoch 117/200, Iteration 47/250, Loss: 0.0245\n",
      "Epoch 117/200, Iteration 48/250, Loss: 0.0083\n",
      "Epoch 117/200, Iteration 49/250, Loss: 0.0179\n",
      "Epoch 117/200, Iteration 50/250, Loss: 0.0271\n",
      "Epoch 117/200, Iteration 51/250, Loss: 0.0167\n",
      "Epoch 117/200, Iteration 52/250, Loss: 0.0197\n",
      "Epoch 117/200, Iteration 53/250, Loss: 0.0410\n",
      "Epoch 117/200, Iteration 54/250, Loss: 0.0073\n",
      "Epoch 117/200, Iteration 55/250, Loss: 0.0244\n",
      "Epoch 117/200, Iteration 56/250, Loss: 0.0122\n",
      "Epoch 117/200, Iteration 57/250, Loss: 0.0140\n",
      "Epoch 117/200, Iteration 58/250, Loss: 0.0104\n",
      "Epoch 117/200, Iteration 59/250, Loss: 0.0145\n",
      "Epoch 117/200, Iteration 60/250, Loss: 0.0135\n",
      "Epoch 117/200, Iteration 61/250, Loss: 0.0065\n",
      "Epoch 117/200, Iteration 62/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 63/250, Loss: 0.0125\n",
      "Epoch 117/200, Iteration 64/250, Loss: 0.0157\n",
      "Epoch 117/200, Iteration 65/250, Loss: 0.0250\n",
      "Epoch 117/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 117/200, Iteration 67/250, Loss: 0.0237\n",
      "Epoch 117/200, Iteration 68/250, Loss: 0.0100\n",
      "Epoch 117/200, Iteration 69/250, Loss: 0.0185\n",
      "Epoch 117/200, Iteration 70/250, Loss: 0.0114\n",
      "Epoch 117/200, Iteration 71/250, Loss: 0.0225\n",
      "Epoch 117/200, Iteration 72/250, Loss: 0.0162\n",
      "Epoch 117/200, Iteration 73/250, Loss: 0.0163\n",
      "Epoch 117/200, Iteration 74/250, Loss: 0.0131\n",
      "Epoch 117/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 117/200, Iteration 76/250, Loss: 0.0153\n",
      "Epoch 117/200, Iteration 77/250, Loss: 0.0076\n",
      "Epoch 117/200, Iteration 78/250, Loss: 0.0387\n",
      "Epoch 117/200, Iteration 79/250, Loss: 0.0226\n",
      "Epoch 117/200, Iteration 80/250, Loss: 0.0196\n",
      "Epoch 117/200, Iteration 81/250, Loss: 0.0093\n",
      "Epoch 117/200, Iteration 82/250, Loss: 0.0174\n",
      "Epoch 117/200, Iteration 83/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 84/250, Loss: 0.0180\n",
      "Epoch 117/200, Iteration 85/250, Loss: 0.0120\n",
      "Epoch 117/200, Iteration 86/250, Loss: 0.0096\n",
      "Epoch 117/200, Iteration 87/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 88/250, Loss: 0.0178\n",
      "Epoch 117/200, Iteration 89/250, Loss: 0.0128\n",
      "Epoch 117/200, Iteration 90/250, Loss: 0.0082\n",
      "Epoch 117/200, Iteration 91/250, Loss: 0.0152\n",
      "Epoch 117/200, Iteration 92/250, Loss: 0.0189\n",
      "Epoch 117/200, Iteration 93/250, Loss: 0.0166\n",
      "Epoch 117/200, Iteration 94/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 117/200, Iteration 96/250, Loss: 0.0137\n",
      "Epoch 117/200, Iteration 97/250, Loss: 0.0094\n",
      "Epoch 117/200, Iteration 98/250, Loss: 0.0138\n",
      "Epoch 117/200, Iteration 99/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 100/250, Loss: 0.0223\n",
      "Epoch 117/200, Iteration 101/250, Loss: 0.0095\n",
      "Epoch 117/200, Iteration 102/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 103/250, Loss: 0.0286\n",
      "Epoch 117/200, Iteration 104/250, Loss: 0.0171\n",
      "Epoch 117/200, Iteration 105/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 106/250, Loss: 0.0071\n",
      "Epoch 117/200, Iteration 107/250, Loss: 0.0069\n",
      "Epoch 117/200, Iteration 108/250, Loss: 0.0375\n",
      "Epoch 117/200, Iteration 109/250, Loss: 0.0070\n",
      "Epoch 117/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 117/200, Iteration 111/250, Loss: 0.0220\n",
      "Epoch 117/200, Iteration 112/250, Loss: 0.0098\n",
      "Epoch 117/200, Iteration 113/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 114/250, Loss: 0.0132\n",
      "Epoch 117/200, Iteration 115/250, Loss: 0.0207\n",
      "Epoch 117/200, Iteration 116/250, Loss: 0.0183\n",
      "Epoch 117/200, Iteration 117/250, Loss: 0.0229\n",
      "Epoch 117/200, Iteration 118/250, Loss: 0.0174\n",
      "Epoch 117/200, Iteration 119/250, Loss: 0.0082\n",
      "Epoch 117/200, Iteration 120/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 117/200, Iteration 122/250, Loss: 0.0121\n",
      "Epoch 117/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 117/200, Iteration 125/250, Loss: 0.0119\n",
      "Epoch 117/200, Iteration 126/250, Loss: 0.0070\n",
      "Epoch 117/200, Iteration 127/250, Loss: 0.0084\n",
      "Epoch 117/200, Iteration 128/250, Loss: 0.0088\n",
      "Epoch 117/200, Iteration 129/250, Loss: 0.0077\n",
      "Epoch 117/200, Iteration 130/250, Loss: 0.0210\n",
      "Epoch 117/200, Iteration 131/250, Loss: 0.0167\n",
      "Epoch 117/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 117/200, Iteration 133/250, Loss: 0.0105\n",
      "Epoch 117/200, Iteration 134/250, Loss: 0.0228\n",
      "Epoch 117/200, Iteration 135/250, Loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200, Iteration 136/250, Loss: 0.0213\n",
      "Epoch 117/200, Iteration 137/250, Loss: 0.0098\n",
      "Epoch 117/200, Iteration 138/250, Loss: 0.0138\n",
      "Epoch 117/200, Iteration 139/250, Loss: 0.0205\n",
      "Epoch 117/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 117/200, Iteration 141/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 142/250, Loss: 0.0134\n",
      "Epoch 117/200, Iteration 143/250, Loss: 0.0253\n",
      "Epoch 117/200, Iteration 144/250, Loss: 0.0144\n",
      "Epoch 117/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 117/200, Iteration 146/250, Loss: 0.0211\n",
      "Epoch 117/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 148/250, Loss: 0.0355\n",
      "Epoch 117/200, Iteration 149/250, Loss: 0.0225\n",
      "Epoch 117/200, Iteration 150/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 151/250, Loss: 0.0149\n",
      "Epoch 117/200, Iteration 152/250, Loss: 0.0078\n",
      "Epoch 117/200, Iteration 153/250, Loss: 0.0177\n",
      "Epoch 117/200, Iteration 154/250, Loss: 0.0086\n",
      "Epoch 117/200, Iteration 155/250, Loss: 0.0183\n",
      "Epoch 117/200, Iteration 156/250, Loss: 0.0154\n",
      "Epoch 117/200, Iteration 157/250, Loss: 0.0078\n",
      "Epoch 117/200, Iteration 158/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 159/250, Loss: 0.0100\n",
      "Epoch 117/200, Iteration 160/250, Loss: 0.0250\n",
      "Epoch 117/200, Iteration 161/250, Loss: 0.0077\n",
      "Epoch 117/200, Iteration 162/250, Loss: 0.0164\n",
      "Epoch 117/200, Iteration 163/250, Loss: 0.0108\n",
      "Epoch 117/200, Iteration 164/250, Loss: 0.0104\n",
      "Epoch 117/200, Iteration 165/250, Loss: 0.0089\n",
      "Epoch 117/200, Iteration 166/250, Loss: 0.0172\n",
      "Epoch 117/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 117/200, Iteration 168/250, Loss: 0.0212\n",
      "Epoch 117/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 170/250, Loss: 0.0301\n",
      "Epoch 117/200, Iteration 171/250, Loss: 0.0173\n",
      "Epoch 117/200, Iteration 172/250, Loss: 0.0278\n",
      "Epoch 117/200, Iteration 173/250, Loss: 0.0054\n",
      "Epoch 117/200, Iteration 174/250, Loss: 0.0117\n",
      "Epoch 117/200, Iteration 175/250, Loss: 0.0128\n",
      "Epoch 117/200, Iteration 176/250, Loss: 0.0112\n",
      "Epoch 117/200, Iteration 177/250, Loss: 0.0287\n",
      "Epoch 117/200, Iteration 178/250, Loss: 0.0252\n",
      "Epoch 117/200, Iteration 179/250, Loss: 0.0316\n",
      "Epoch 117/200, Iteration 180/250, Loss: 0.0089\n",
      "Epoch 117/200, Iteration 181/250, Loss: 0.0141\n",
      "Epoch 117/200, Iteration 182/250, Loss: 0.0091\n",
      "Epoch 117/200, Iteration 183/250, Loss: 0.0071\n",
      "Epoch 117/200, Iteration 184/250, Loss: 0.0155\n",
      "Epoch 117/200, Iteration 185/250, Loss: 0.0182\n",
      "Epoch 117/200, Iteration 186/250, Loss: 0.0153\n",
      "Epoch 117/200, Iteration 187/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 188/250, Loss: 0.0078\n",
      "Epoch 117/200, Iteration 189/250, Loss: 0.0103\n",
      "Epoch 117/200, Iteration 190/250, Loss: 0.0064\n",
      "Epoch 117/200, Iteration 191/250, Loss: 0.0135\n",
      "Epoch 117/200, Iteration 192/250, Loss: 0.0084\n",
      "Epoch 117/200, Iteration 193/250, Loss: 0.0321\n",
      "Epoch 117/200, Iteration 194/250, Loss: 0.0256\n",
      "Epoch 117/200, Iteration 195/250, Loss: 0.0105\n",
      "Epoch 117/200, Iteration 196/250, Loss: 0.0139\n",
      "Epoch 117/200, Iteration 197/250, Loss: 0.0103\n",
      "Epoch 117/200, Iteration 198/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 199/250, Loss: 0.0133\n",
      "Epoch 117/200, Iteration 200/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 201/250, Loss: 0.0178\n",
      "Epoch 117/200, Iteration 202/250, Loss: 0.0110\n",
      "Epoch 117/200, Iteration 203/250, Loss: 0.0359\n",
      "Epoch 117/200, Iteration 204/250, Loss: 0.0095\n",
      "Epoch 117/200, Iteration 205/250, Loss: 0.0075\n",
      "Epoch 117/200, Iteration 206/250, Loss: 0.0125\n",
      "Epoch 117/200, Iteration 207/250, Loss: 0.0084\n",
      "Epoch 117/200, Iteration 208/250, Loss: 0.0150\n",
      "Epoch 117/200, Iteration 209/250, Loss: 0.0194\n",
      "Epoch 117/200, Iteration 210/250, Loss: 0.0086\n",
      "Epoch 117/200, Iteration 211/250, Loss: 0.0154\n",
      "Epoch 117/200, Iteration 212/250, Loss: 0.0139\n",
      "Epoch 117/200, Iteration 213/250, Loss: 0.0108\n",
      "Epoch 117/200, Iteration 214/250, Loss: 0.0102\n",
      "Epoch 117/200, Iteration 215/250, Loss: 0.0085\n",
      "Epoch 117/200, Iteration 216/250, Loss: 0.0083\n",
      "Epoch 117/200, Iteration 217/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 218/250, Loss: 0.0092\n",
      "Epoch 117/200, Iteration 219/250, Loss: 0.0164\n",
      "Epoch 117/200, Iteration 220/250, Loss: 0.0113\n",
      "Epoch 117/200, Iteration 221/250, Loss: 0.0323\n",
      "Epoch 117/200, Iteration 222/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 223/250, Loss: 0.0080\n",
      "Epoch 117/200, Iteration 224/250, Loss: 0.0110\n",
      "Epoch 117/200, Iteration 225/250, Loss: 0.0119\n",
      "Epoch 117/200, Iteration 226/250, Loss: 0.0116\n",
      "Epoch 117/200, Iteration 227/250, Loss: 0.0162\n",
      "Epoch 117/200, Iteration 228/250, Loss: 0.0060\n",
      "Epoch 117/200, Iteration 229/250, Loss: 0.0087\n",
      "Epoch 117/200, Iteration 230/250, Loss: 0.0072\n",
      "Epoch 117/200, Iteration 231/250, Loss: 0.0285\n",
      "Epoch 117/200, Iteration 232/250, Loss: 0.0176\n",
      "Epoch 117/200, Iteration 233/250, Loss: 0.0227\n",
      "Epoch 117/200, Iteration 234/250, Loss: 0.0089\n",
      "Epoch 117/200, Iteration 235/250, Loss: 0.0110\n",
      "Epoch 117/200, Iteration 236/250, Loss: 0.0153\n",
      "Epoch 117/200, Iteration 237/250, Loss: 0.0199\n",
      "Epoch 117/200, Iteration 238/250, Loss: 0.0270\n",
      "Epoch 117/200, Iteration 239/250, Loss: 0.0124\n",
      "Epoch 117/200, Iteration 240/250, Loss: 0.0167\n",
      "Epoch 117/200, Iteration 241/250, Loss: 0.0168\n",
      "Epoch 117/200, Iteration 242/250, Loss: 0.0155\n",
      "Epoch 117/200, Iteration 243/250, Loss: 0.0126\n",
      "Epoch 117/200, Iteration 244/250, Loss: 0.0168\n",
      "Epoch 117/200, Iteration 245/250, Loss: 0.0128\n",
      "Epoch 117/200, Iteration 246/250, Loss: 0.0156\n",
      "Epoch 117/200, Iteration 247/250, Loss: 0.0074\n",
      "Epoch 117/200, Iteration 248/250, Loss: 0.0143\n",
      "Epoch 117/200, Iteration 249/250, Loss: 0.0194\n",
      "Epoch 117/200, Iteration 250/250, Loss: 0.0070\n",
      "Train Error: \n",
      " Accuracy: 88.15%, Avg loss: 0.006659, MRE: 0.444964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.007205, MRE: 0.516852 \n",
      "\n",
      "Epoch 118/200, Iteration 1/250, Loss: 0.0118\n",
      "Epoch 118/200, Iteration 2/250, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 118/200, Iteration 5/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 6/250, Loss: 0.0184\n",
      "Epoch 118/200, Iteration 7/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 8/250, Loss: 0.0164\n",
      "Epoch 118/200, Iteration 9/250, Loss: 0.0135\n",
      "Epoch 118/200, Iteration 10/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 11/250, Loss: 0.0097\n",
      "Epoch 118/200, Iteration 12/250, Loss: 0.0272\n",
      "Epoch 118/200, Iteration 13/250, Loss: 0.0170\n",
      "Epoch 118/200, Iteration 14/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 15/250, Loss: 0.0256\n",
      "Epoch 118/200, Iteration 16/250, Loss: 0.0235\n",
      "Epoch 118/200, Iteration 17/250, Loss: 0.0143\n",
      "Epoch 118/200, Iteration 18/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 19/250, Loss: 0.0128\n",
      "Epoch 118/200, Iteration 20/250, Loss: 0.0161\n",
      "Epoch 118/200, Iteration 21/250, Loss: 0.0192\n",
      "Epoch 118/200, Iteration 22/250, Loss: 0.0307\n",
      "Epoch 118/200, Iteration 23/250, Loss: 0.0091\n",
      "Epoch 118/200, Iteration 24/250, Loss: 0.0193\n",
      "Epoch 118/200, Iteration 25/250, Loss: 0.0093\n",
      "Epoch 118/200, Iteration 26/250, Loss: 0.0363\n",
      "Epoch 118/200, Iteration 27/250, Loss: 0.0143\n",
      "Epoch 118/200, Iteration 28/250, Loss: 0.0289\n",
      "Epoch 118/200, Iteration 29/250, Loss: 0.0105\n",
      "Epoch 118/200, Iteration 30/250, Loss: 0.0194\n",
      "Epoch 118/200, Iteration 31/250, Loss: 0.0187\n",
      "Epoch 118/200, Iteration 32/250, Loss: 0.0251\n",
      "Epoch 118/200, Iteration 33/250, Loss: 0.0212\n",
      "Epoch 118/200, Iteration 34/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 35/250, Loss: 0.0174\n",
      "Epoch 118/200, Iteration 36/250, Loss: 0.0336\n",
      "Epoch 118/200, Iteration 37/250, Loss: 0.0135\n",
      "Epoch 118/200, Iteration 38/250, Loss: 0.0119\n",
      "Epoch 118/200, Iteration 39/250, Loss: 0.0422\n",
      "Epoch 118/200, Iteration 40/250, Loss: 0.0192\n",
      "Epoch 118/200, Iteration 41/250, Loss: 0.0107\n",
      "Epoch 118/200, Iteration 42/250, Loss: 0.0089\n",
      "Epoch 118/200, Iteration 43/250, Loss: 0.0161\n",
      "Epoch 118/200, Iteration 44/250, Loss: 0.0311\n",
      "Epoch 118/200, Iteration 45/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 46/250, Loss: 0.0072\n",
      "Epoch 118/200, Iteration 47/250, Loss: 0.0132\n",
      "Epoch 118/200, Iteration 48/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 49/250, Loss: 0.0132\n",
      "Epoch 118/200, Iteration 50/250, Loss: 0.0087\n",
      "Epoch 118/200, Iteration 51/250, Loss: 0.0349\n",
      "Epoch 118/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 118/200, Iteration 53/250, Loss: 0.0165\n",
      "Epoch 118/200, Iteration 54/250, Loss: 0.0148\n",
      "Epoch 118/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 56/250, Loss: 0.0254\n",
      "Epoch 118/200, Iteration 57/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 58/250, Loss: 0.0182\n",
      "Epoch 118/200, Iteration 59/250, Loss: 0.0231\n",
      "Epoch 118/200, Iteration 60/250, Loss: 0.0252\n",
      "Epoch 118/200, Iteration 61/250, Loss: 0.0151\n",
      "Epoch 118/200, Iteration 62/250, Loss: 0.0136\n",
      "Epoch 118/200, Iteration 63/250, Loss: 0.0113\n",
      "Epoch 118/200, Iteration 64/250, Loss: 0.0136\n",
      "Epoch 118/200, Iteration 65/250, Loss: 0.0079\n",
      "Epoch 118/200, Iteration 66/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 67/250, Loss: 0.0088\n",
      "Epoch 118/200, Iteration 68/250, Loss: 0.0212\n",
      "Epoch 118/200, Iteration 69/250, Loss: 0.0139\n",
      "Epoch 118/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 118/200, Iteration 71/250, Loss: 0.0120\n",
      "Epoch 118/200, Iteration 72/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 73/250, Loss: 0.0101\n",
      "Epoch 118/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 118/200, Iteration 75/250, Loss: 0.0220\n",
      "Epoch 118/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 118/200, Iteration 77/250, Loss: 0.0227\n",
      "Epoch 118/200, Iteration 78/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200, Iteration 79/250, Loss: 0.0348\n",
      "Epoch 118/200, Iteration 80/250, Loss: 0.0419\n",
      "Epoch 118/200, Iteration 81/250, Loss: 0.0187\n",
      "Epoch 118/200, Iteration 82/250, Loss: 0.0168\n",
      "Epoch 118/200, Iteration 83/250, Loss: 0.0240\n",
      "Epoch 118/200, Iteration 84/250, Loss: 0.0185\n",
      "Epoch 118/200, Iteration 85/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 86/250, Loss: 0.0077\n",
      "Epoch 118/200, Iteration 87/250, Loss: 0.0133\n",
      "Epoch 118/200, Iteration 88/250, Loss: 0.0163\n",
      "Epoch 118/200, Iteration 89/250, Loss: 0.0313\n",
      "Epoch 118/200, Iteration 90/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 91/250, Loss: 0.0183\n",
      "Epoch 118/200, Iteration 92/250, Loss: 0.0114\n",
      "Epoch 118/200, Iteration 93/250, Loss: 0.0131\n",
      "Epoch 118/200, Iteration 94/250, Loss: 0.0109\n",
      "Epoch 118/200, Iteration 95/250, Loss: 0.0101\n",
      "Epoch 118/200, Iteration 96/250, Loss: 0.0412\n",
      "Epoch 118/200, Iteration 97/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 98/250, Loss: 0.0235\n",
      "Epoch 118/200, Iteration 99/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 100/250, Loss: 0.0166\n",
      "Epoch 118/200, Iteration 101/250, Loss: 0.0385\n",
      "Epoch 118/200, Iteration 102/250, Loss: 0.0388\n",
      "Epoch 118/200, Iteration 103/250, Loss: 0.0082\n",
      "Epoch 118/200, Iteration 104/250, Loss: 0.0079\n",
      "Epoch 118/200, Iteration 105/250, Loss: 0.0242\n",
      "Epoch 118/200, Iteration 106/250, Loss: 0.0315\n",
      "Epoch 118/200, Iteration 107/250, Loss: 0.0139\n",
      "Epoch 118/200, Iteration 108/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 109/250, Loss: 0.0236\n",
      "Epoch 118/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 111/250, Loss: 0.0090\n",
      "Epoch 118/200, Iteration 112/250, Loss: 0.0138\n",
      "Epoch 118/200, Iteration 113/250, Loss: 0.0212\n",
      "Epoch 118/200, Iteration 114/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 115/250, Loss: 0.0183\n",
      "Epoch 118/200, Iteration 116/250, Loss: 0.0144\n",
      "Epoch 118/200, Iteration 117/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 118/250, Loss: 0.0244\n",
      "Epoch 118/200, Iteration 119/250, Loss: 0.0091\n",
      "Epoch 118/200, Iteration 120/250, Loss: 0.0275\n",
      "Epoch 118/200, Iteration 121/250, Loss: 0.0173\n",
      "Epoch 118/200, Iteration 122/250, Loss: 0.0400\n",
      "Epoch 118/200, Iteration 123/250, Loss: 0.0096\n",
      "Epoch 118/200, Iteration 124/250, Loss: 0.0103\n",
      "Epoch 118/200, Iteration 125/250, Loss: 0.0209\n",
      "Epoch 118/200, Iteration 126/250, Loss: 0.0327\n",
      "Epoch 118/200, Iteration 127/250, Loss: 0.0259\n",
      "Epoch 118/200, Iteration 128/250, Loss: 0.0299\n",
      "Epoch 118/200, Iteration 129/250, Loss: 0.0094\n",
      "Epoch 118/200, Iteration 130/250, Loss: 0.0157\n",
      "Epoch 118/200, Iteration 131/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 132/250, Loss: 0.0057\n",
      "Epoch 118/200, Iteration 133/250, Loss: 0.0263\n",
      "Epoch 118/200, Iteration 134/250, Loss: 0.0405\n",
      "Epoch 118/200, Iteration 135/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 136/250, Loss: 0.0158\n",
      "Epoch 118/200, Iteration 137/250, Loss: 0.0232\n",
      "Epoch 118/200, Iteration 138/250, Loss: 0.0132\n",
      "Epoch 118/200, Iteration 139/250, Loss: 0.0063\n",
      "Epoch 118/200, Iteration 140/250, Loss: 0.0328\n",
      "Epoch 118/200, Iteration 141/250, Loss: 0.0149\n",
      "Epoch 118/200, Iteration 142/250, Loss: 0.0168\n",
      "Epoch 118/200, Iteration 143/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 144/250, Loss: 0.0364\n",
      "Epoch 118/200, Iteration 145/250, Loss: 0.0111\n",
      "Epoch 118/200, Iteration 146/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 147/250, Loss: 0.0213\n",
      "Epoch 118/200, Iteration 148/250, Loss: 0.0152\n",
      "Epoch 118/200, Iteration 149/250, Loss: 0.0079\n",
      "Epoch 118/200, Iteration 150/250, Loss: 0.0166\n",
      "Epoch 118/200, Iteration 151/250, Loss: 0.0178\n",
      "Epoch 118/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 153/250, Loss: 0.0112\n",
      "Epoch 118/200, Iteration 154/250, Loss: 0.0178\n",
      "Epoch 118/200, Iteration 155/250, Loss: 0.0179\n",
      "Epoch 118/200, Iteration 156/250, Loss: 0.0201\n",
      "Epoch 118/200, Iteration 157/250, Loss: 0.0263\n",
      "Epoch 118/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 118/200, Iteration 159/250, Loss: 0.0204\n",
      "Epoch 118/200, Iteration 160/250, Loss: 0.0181\n",
      "Epoch 118/200, Iteration 161/250, Loss: 0.0108\n",
      "Epoch 118/200, Iteration 162/250, Loss: 0.0086\n",
      "Epoch 118/200, Iteration 163/250, Loss: 0.0150\n",
      "Epoch 118/200, Iteration 164/250, Loss: 0.0193\n",
      "Epoch 118/200, Iteration 165/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 166/250, Loss: 0.0168\n",
      "Epoch 118/200, Iteration 167/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 168/250, Loss: 0.0128\n",
      "Epoch 118/200, Iteration 169/250, Loss: 0.0123\n",
      "Epoch 118/200, Iteration 170/250, Loss: 0.0205\n",
      "Epoch 118/200, Iteration 171/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 172/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 173/250, Loss: 0.0182\n",
      "Epoch 118/200, Iteration 174/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 175/250, Loss: 0.0083\n",
      "Epoch 118/200, Iteration 176/250, Loss: 0.0150\n",
      "Epoch 118/200, Iteration 177/250, Loss: 0.0328\n",
      "Epoch 118/200, Iteration 178/250, Loss: 0.0074\n",
      "Epoch 118/200, Iteration 179/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 180/250, Loss: 0.0091\n",
      "Epoch 118/200, Iteration 181/250, Loss: 0.0098\n",
      "Epoch 118/200, Iteration 182/250, Loss: 0.0288\n",
      "Epoch 118/200, Iteration 183/250, Loss: 0.0225\n",
      "Epoch 118/200, Iteration 184/250, Loss: 0.0154\n",
      "Epoch 118/200, Iteration 185/250, Loss: 0.0127\n",
      "Epoch 118/200, Iteration 186/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 188/250, Loss: 0.0078\n",
      "Epoch 118/200, Iteration 189/250, Loss: 0.0432\n",
      "Epoch 118/200, Iteration 190/250, Loss: 0.0138\n",
      "Epoch 118/200, Iteration 191/250, Loss: 0.0128\n",
      "Epoch 118/200, Iteration 192/250, Loss: 0.0172\n",
      "Epoch 118/200, Iteration 193/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 194/250, Loss: 0.0143\n",
      "Epoch 118/200, Iteration 195/250, Loss: 0.0125\n",
      "Epoch 118/200, Iteration 196/250, Loss: 0.0181\n",
      "Epoch 118/200, Iteration 197/250, Loss: 0.0158\n",
      "Epoch 118/200, Iteration 198/250, Loss: 0.0110\n",
      "Epoch 118/200, Iteration 199/250, Loss: 0.0199\n",
      "Epoch 118/200, Iteration 200/250, Loss: 0.0156\n",
      "Epoch 118/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 118/200, Iteration 202/250, Loss: 0.0252\n",
      "Epoch 118/200, Iteration 203/250, Loss: 0.0144\n",
      "Epoch 118/200, Iteration 204/250, Loss: 0.0087\n",
      "Epoch 118/200, Iteration 205/250, Loss: 0.0090\n",
      "Epoch 118/200, Iteration 206/250, Loss: 0.0250\n",
      "Epoch 118/200, Iteration 207/250, Loss: 0.0095\n",
      "Epoch 118/200, Iteration 208/250, Loss: 0.0129\n",
      "Epoch 118/200, Iteration 209/250, Loss: 0.0124\n",
      "Epoch 118/200, Iteration 210/250, Loss: 0.0213\n",
      "Epoch 118/200, Iteration 211/250, Loss: 0.0153\n",
      "Epoch 118/200, Iteration 212/250, Loss: 0.0135\n",
      "Epoch 118/200, Iteration 213/250, Loss: 0.0210\n",
      "Epoch 118/200, Iteration 214/250, Loss: 0.0139\n",
      "Epoch 118/200, Iteration 215/250, Loss: 0.0117\n",
      "Epoch 118/200, Iteration 216/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 217/250, Loss: 0.0351\n",
      "Epoch 118/200, Iteration 218/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 219/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 220/250, Loss: 0.0082\n",
      "Epoch 118/200, Iteration 221/250, Loss: 0.0076\n",
      "Epoch 118/200, Iteration 222/250, Loss: 0.0167\n",
      "Epoch 118/200, Iteration 223/250, Loss: 0.0124\n",
      "Epoch 118/200, Iteration 224/250, Loss: 0.0089\n",
      "Epoch 118/200, Iteration 225/250, Loss: 0.0264\n",
      "Epoch 118/200, Iteration 226/250, Loss: 0.0185\n",
      "Epoch 118/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 118/200, Iteration 228/250, Loss: 0.0249\n",
      "Epoch 118/200, Iteration 229/250, Loss: 0.0070\n",
      "Epoch 118/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 118/200, Iteration 231/250, Loss: 0.0122\n",
      "Epoch 118/200, Iteration 232/250, Loss: 0.0133\n",
      "Epoch 118/200, Iteration 233/250, Loss: 0.0151\n",
      "Epoch 118/200, Iteration 234/250, Loss: 0.0061\n",
      "Epoch 118/200, Iteration 235/250, Loss: 0.0165\n",
      "Epoch 118/200, Iteration 236/250, Loss: 0.0294\n",
      "Epoch 118/200, Iteration 237/250, Loss: 0.0280\n",
      "Epoch 118/200, Iteration 238/250, Loss: 0.0137\n",
      "Epoch 118/200, Iteration 239/250, Loss: 0.0113\n",
      "Epoch 118/200, Iteration 240/250, Loss: 0.0194\n",
      "Epoch 118/200, Iteration 241/250, Loss: 0.0395\n",
      "Epoch 118/200, Iteration 242/250, Loss: 0.0267\n",
      "Epoch 118/200, Iteration 243/250, Loss: 0.0213\n",
      "Epoch 118/200, Iteration 244/250, Loss: 0.0175\n",
      "Epoch 118/200, Iteration 245/250, Loss: 0.0171\n",
      "Epoch 118/200, Iteration 246/250, Loss: 0.0102\n",
      "Epoch 118/200, Iteration 247/250, Loss: 0.0215\n",
      "Epoch 118/200, Iteration 248/250, Loss: 0.0115\n",
      "Epoch 118/200, Iteration 249/250, Loss: 0.0104\n",
      "Epoch 118/200, Iteration 250/250, Loss: 0.0130\n",
      "Train Error: \n",
      " Accuracy: 93.15%, Avg loss: 0.007226, MRE: 0.573187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.35%, Avg loss: 0.007871, MRE: 0.554474 \n",
      "\n",
      "Epoch 119/200, Iteration 1/250, Loss: 0.0103\n",
      "Epoch 119/200, Iteration 2/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 3/250, Loss: 0.0226\n",
      "Epoch 119/200, Iteration 4/250, Loss: 0.0155\n",
      "Epoch 119/200, Iteration 5/250, Loss: 0.0111\n",
      "Epoch 119/200, Iteration 6/250, Loss: 0.0369\n",
      "Epoch 119/200, Iteration 7/250, Loss: 0.0091\n",
      "Epoch 119/200, Iteration 8/250, Loss: 0.0216\n",
      "Epoch 119/200, Iteration 9/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 10/250, Loss: 0.0070\n",
      "Epoch 119/200, Iteration 11/250, Loss: 0.0353\n",
      "Epoch 119/200, Iteration 12/250, Loss: 0.0424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 14/250, Loss: 0.0062\n",
      "Epoch 119/200, Iteration 15/250, Loss: 0.0129\n",
      "Epoch 119/200, Iteration 16/250, Loss: 0.0257\n",
      "Epoch 119/200, Iteration 17/250, Loss: 0.0183\n",
      "Epoch 119/200, Iteration 18/250, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 19/250, Loss: 0.0121\n",
      "Epoch 119/200, Iteration 20/250, Loss: 0.0137\n",
      "Epoch 119/200, Iteration 21/250, Loss: 0.0167\n",
      "Epoch 119/200, Iteration 22/250, Loss: 0.0362\n",
      "Epoch 119/200, Iteration 23/250, Loss: 0.0170\n",
      "Epoch 119/200, Iteration 24/250, Loss: 0.0197\n",
      "Epoch 119/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 119/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 119/200, Iteration 27/250, Loss: 0.0173\n",
      "Epoch 119/200, Iteration 28/250, Loss: 0.0257\n",
      "Epoch 119/200, Iteration 29/250, Loss: 0.0395\n",
      "Epoch 119/200, Iteration 30/250, Loss: 0.0100\n",
      "Epoch 119/200, Iteration 31/250, Loss: 0.0110\n",
      "Epoch 119/200, Iteration 32/250, Loss: 0.0100\n",
      "Epoch 119/200, Iteration 33/250, Loss: 0.0133\n",
      "Epoch 119/200, Iteration 34/250, Loss: 0.0101\n",
      "Epoch 119/200, Iteration 35/250, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 36/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 37/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 38/250, Loss: 0.0076\n",
      "Epoch 119/200, Iteration 39/250, Loss: 0.0117\n",
      "Epoch 119/200, Iteration 40/250, Loss: 0.0095\n",
      "Epoch 119/200, Iteration 41/250, Loss: 0.0169\n",
      "Epoch 119/200, Iteration 42/250, Loss: 0.0189\n",
      "Epoch 119/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 119/200, Iteration 44/250, Loss: 0.0128\n",
      "Epoch 119/200, Iteration 45/250, Loss: 0.0215\n",
      "Epoch 119/200, Iteration 46/250, Loss: 0.0131\n",
      "Epoch 119/200, Iteration 47/250, Loss: 0.0194\n",
      "Epoch 119/200, Iteration 48/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 49/250, Loss: 0.0113\n",
      "Epoch 119/200, Iteration 50/250, Loss: 0.0081\n",
      "Epoch 119/200, Iteration 51/250, Loss: 0.0258\n",
      "Epoch 119/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 53/250, Loss: 0.0094\n",
      "Epoch 119/200, Iteration 54/250, Loss: 0.0084\n",
      "Epoch 119/200, Iteration 55/250, Loss: 0.0099\n",
      "Epoch 119/200, Iteration 56/250, Loss: 0.0101\n",
      "Epoch 119/200, Iteration 57/250, Loss: 0.0322\n",
      "Epoch 119/200, Iteration 58/250, Loss: 0.0148\n",
      "Epoch 119/200, Iteration 59/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 60/250, Loss: 0.0114\n",
      "Epoch 119/200, Iteration 61/250, Loss: 0.0069\n",
      "Epoch 119/200, Iteration 62/250, Loss: 0.0108\n",
      "Epoch 119/200, Iteration 63/250, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 64/250, Loss: 0.0202\n",
      "Epoch 119/200, Iteration 65/250, Loss: 0.0147\n",
      "Epoch 119/200, Iteration 66/250, Loss: 0.0122\n",
      "Epoch 119/200, Iteration 67/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 68/250, Loss: 0.0076\n",
      "Epoch 119/200, Iteration 69/250, Loss: 0.0337\n",
      "Epoch 119/200, Iteration 70/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 71/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 72/250, Loss: 0.0061\n",
      "Epoch 119/200, Iteration 73/250, Loss: 0.0091\n",
      "Epoch 119/200, Iteration 74/250, Loss: 0.0069\n",
      "Epoch 119/200, Iteration 75/250, Loss: 0.0253\n",
      "Epoch 119/200, Iteration 76/250, Loss: 0.0313\n",
      "Epoch 119/200, Iteration 77/250, Loss: 0.0120\n",
      "Epoch 119/200, Iteration 78/250, Loss: 0.0101\n",
      "Epoch 119/200, Iteration 79/250, Loss: 0.0096\n",
      "Epoch 119/200, Iteration 80/250, Loss: 0.0315\n",
      "Epoch 119/200, Iteration 81/250, Loss: 0.0144\n",
      "Epoch 119/200, Iteration 82/250, Loss: 0.0089\n",
      "Epoch 119/200, Iteration 83/250, Loss: 0.0188\n",
      "Epoch 119/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 119/200, Iteration 85/250, Loss: 0.0185\n",
      "Epoch 119/200, Iteration 86/250, Loss: 0.0086\n",
      "Epoch 119/200, Iteration 87/250, Loss: 0.0097\n",
      "Epoch 119/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 89/250, Loss: 0.0115\n",
      "Epoch 119/200, Iteration 90/250, Loss: 0.0157\n",
      "Epoch 119/200, Iteration 91/250, Loss: 0.0084\n",
      "Epoch 119/200, Iteration 92/250, Loss: 0.0084\n",
      "Epoch 119/200, Iteration 93/250, Loss: 0.0101\n",
      "Epoch 119/200, Iteration 94/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 95/250, Loss: 0.0160\n",
      "Epoch 119/200, Iteration 96/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 97/250, Loss: 0.0154\n",
      "Epoch 119/200, Iteration 98/250, Loss: 0.0069\n",
      "Epoch 119/200, Iteration 99/250, Loss: 0.0242\n",
      "Epoch 119/200, Iteration 100/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 101/250, Loss: 0.0245\n",
      "Epoch 119/200, Iteration 102/250, Loss: 0.0118\n",
      "Epoch 119/200, Iteration 103/250, Loss: 0.0122\n",
      "Epoch 119/200, Iteration 104/250, Loss: 0.0303\n",
      "Epoch 119/200, Iteration 105/250, Loss: 0.0246\n",
      "Epoch 119/200, Iteration 106/250, Loss: 0.0125\n",
      "Epoch 119/200, Iteration 107/250, Loss: 0.0239\n",
      "Epoch 119/200, Iteration 108/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 109/250, Loss: 0.0082\n",
      "Epoch 119/200, Iteration 110/250, Loss: 0.0068\n",
      "Epoch 119/200, Iteration 111/250, Loss: 0.0124\n",
      "Epoch 119/200, Iteration 112/250, Loss: 0.0071\n",
      "Epoch 119/200, Iteration 113/250, Loss: 0.0154\n",
      "Epoch 119/200, Iteration 114/250, Loss: 0.0500\n",
      "Epoch 119/200, Iteration 115/250, Loss: 0.0167\n",
      "Epoch 119/200, Iteration 116/250, Loss: 0.0202\n",
      "Epoch 119/200, Iteration 117/250, Loss: 0.0091\n",
      "Epoch 119/200, Iteration 118/250, Loss: 0.0149\n",
      "Epoch 119/200, Iteration 119/250, Loss: 0.0070\n",
      "Epoch 119/200, Iteration 120/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 121/250, Loss: 0.0141\n",
      "Epoch 119/200, Iteration 122/250, Loss: 0.0247\n",
      "Epoch 119/200, Iteration 123/250, Loss: 0.0171\n",
      "Epoch 119/200, Iteration 124/250, Loss: 0.0146\n",
      "Epoch 119/200, Iteration 125/250, Loss: 0.0162\n",
      "Epoch 119/200, Iteration 126/250, Loss: 0.0122\n",
      "Epoch 119/200, Iteration 127/250, Loss: 0.0309\n",
      "Epoch 119/200, Iteration 128/250, Loss: 0.0204\n",
      "Epoch 119/200, Iteration 129/250, Loss: 0.0279\n",
      "Epoch 119/200, Iteration 130/250, Loss: 0.0121\n",
      "Epoch 119/200, Iteration 131/250, Loss: 0.0167\n",
      "Epoch 119/200, Iteration 132/250, Loss: 0.0185\n",
      "Epoch 119/200, Iteration 133/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 134/250, Loss: 0.0184\n",
      "Epoch 119/200, Iteration 135/250, Loss: 0.0207\n",
      "Epoch 119/200, Iteration 136/250, Loss: 0.0106\n",
      "Epoch 119/200, Iteration 137/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 138/250, Loss: 0.0102\n",
      "Epoch 119/200, Iteration 139/250, Loss: 0.0368\n",
      "Epoch 119/200, Iteration 140/250, Loss: 0.0084\n",
      "Epoch 119/200, Iteration 141/250, Loss: 0.0150\n",
      "Epoch 119/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 143/250, Loss: 0.0205\n",
      "Epoch 119/200, Iteration 144/250, Loss: 0.0264\n",
      "Epoch 119/200, Iteration 145/250, Loss: 0.0215\n",
      "Epoch 119/200, Iteration 146/250, Loss: 0.0084\n",
      "Epoch 119/200, Iteration 147/250, Loss: 0.0126\n",
      "Epoch 119/200, Iteration 148/250, Loss: 0.0136\n",
      "Epoch 119/200, Iteration 149/250, Loss: 0.0377\n",
      "Epoch 119/200, Iteration 150/250, Loss: 0.0189\n",
      "Epoch 119/200, Iteration 151/250, Loss: 0.0147\n",
      "Epoch 119/200, Iteration 152/250, Loss: 0.0216\n",
      "Epoch 119/200, Iteration 153/250, Loss: 0.0227\n",
      "Epoch 119/200, Iteration 154/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 155/250, Loss: 0.0114\n",
      "Epoch 119/200, Iteration 156/250, Loss: 0.0082\n",
      "Epoch 119/200, Iteration 157/250, Loss: 0.0133\n",
      "Epoch 119/200, Iteration 158/250, Loss: 0.0066\n",
      "Epoch 119/200, Iteration 159/250, Loss: 0.0099\n",
      "Epoch 119/200, Iteration 160/250, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 161/250, Loss: 0.0138\n",
      "Epoch 119/200, Iteration 162/250, Loss: 0.0157\n",
      "Epoch 119/200, Iteration 163/250, Loss: 0.0211\n",
      "Epoch 119/200, Iteration 164/250, Loss: 0.0358\n",
      "Epoch 119/200, Iteration 165/250, Loss: 0.0191\n",
      "Epoch 119/200, Iteration 166/250, Loss: 0.0128\n",
      "Epoch 119/200, Iteration 167/250, Loss: 0.0155\n",
      "Epoch 119/200, Iteration 168/250, Loss: 0.0219\n",
      "Epoch 119/200, Iteration 169/250, Loss: 0.0162\n",
      "Epoch 119/200, Iteration 170/250, Loss: 0.0175\n",
      "Epoch 119/200, Iteration 171/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 172/250, Loss: 0.0118\n",
      "Epoch 119/200, Iteration 173/250, Loss: 0.0170\n",
      "Epoch 119/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 119/200, Iteration 175/250, Loss: 0.0174\n",
      "Epoch 119/200, Iteration 176/250, Loss: 0.0247\n",
      "Epoch 119/200, Iteration 177/250, Loss: 0.0203\n",
      "Epoch 119/200, Iteration 178/250, Loss: 0.0099\n",
      "Epoch 119/200, Iteration 179/250, Loss: 0.0282\n",
      "Epoch 119/200, Iteration 180/250, Loss: 0.0094\n",
      "Epoch 119/200, Iteration 181/250, Loss: 0.0143\n",
      "Epoch 119/200, Iteration 182/250, Loss: 0.0117\n",
      "Epoch 119/200, Iteration 183/250, Loss: 0.0092\n",
      "Epoch 119/200, Iteration 184/250, Loss: 0.0087\n",
      "Epoch 119/200, Iteration 185/250, Loss: 0.0161\n",
      "Epoch 119/200, Iteration 186/250, Loss: 0.0118\n",
      "Epoch 119/200, Iteration 187/250, Loss: 0.0214\n",
      "Epoch 119/200, Iteration 188/250, Loss: 0.0128\n",
      "Epoch 119/200, Iteration 189/250, Loss: 0.0124\n",
      "Epoch 119/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 119/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 119/200, Iteration 192/250, Loss: 0.0111\n",
      "Epoch 119/200, Iteration 193/250, Loss: 0.0104\n",
      "Epoch 119/200, Iteration 194/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 195/250, Loss: 0.0135\n",
      "Epoch 119/200, Iteration 196/250, Loss: 0.0132\n",
      "Epoch 119/200, Iteration 197/250, Loss: 0.0083\n",
      "Epoch 119/200, Iteration 198/250, Loss: 0.0146\n",
      "Epoch 119/200, Iteration 199/250, Loss: 0.0149\n",
      "Epoch 119/200, Iteration 200/250, Loss: 0.0098\n",
      "Epoch 119/200, Iteration 201/250, Loss: 0.0110\n",
      "Epoch 119/200, Iteration 202/250, Loss: 0.0110\n",
      "Epoch 119/200, Iteration 203/250, Loss: 0.0136\n",
      "Epoch 119/200, Iteration 204/250, Loss: 0.0126\n",
      "Epoch 119/200, Iteration 205/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 206/250, Loss: 0.0120\n",
      "Epoch 119/200, Iteration 207/250, Loss: 0.0197\n",
      "Epoch 119/200, Iteration 208/250, Loss: 0.0082\n",
      "Epoch 119/200, Iteration 209/250, Loss: 0.0227\n",
      "Epoch 119/200, Iteration 210/250, Loss: 0.0144\n",
      "Epoch 119/200, Iteration 211/250, Loss: 0.0080\n",
      "Epoch 119/200, Iteration 212/250, Loss: 0.0063\n",
      "Epoch 119/200, Iteration 213/250, Loss: 0.0068\n",
      "Epoch 119/200, Iteration 214/250, Loss: 0.0150\n",
      "Epoch 119/200, Iteration 215/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 216/250, Loss: 0.0088\n",
      "Epoch 119/200, Iteration 217/250, Loss: 0.0130\n",
      "Epoch 119/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 119/200, Iteration 219/250, Loss: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 119/200, Iteration 221/250, Loss: 0.0119\n",
      "Epoch 119/200, Iteration 222/250, Loss: 0.0235\n",
      "Epoch 119/200, Iteration 223/250, Loss: 0.0362\n",
      "Epoch 119/200, Iteration 224/250, Loss: 0.0124\n",
      "Epoch 119/200, Iteration 225/250, Loss: 0.0075\n",
      "Epoch 119/200, Iteration 226/250, Loss: 0.0128\n",
      "Epoch 119/200, Iteration 227/250, Loss: 0.0156\n",
      "Epoch 119/200, Iteration 228/250, Loss: 0.0127\n",
      "Epoch 119/200, Iteration 229/250, Loss: 0.0385\n",
      "Epoch 119/200, Iteration 230/250, Loss: 0.0199\n",
      "Epoch 119/200, Iteration 231/250, Loss: 0.0168\n",
      "Epoch 119/200, Iteration 232/250, Loss: 0.0205\n",
      "Epoch 119/200, Iteration 233/250, Loss: 0.0357\n",
      "Epoch 119/200, Iteration 234/250, Loss: 0.0065\n",
      "Epoch 119/200, Iteration 235/250, Loss: 0.0103\n",
      "Epoch 119/200, Iteration 236/250, Loss: 0.0165\n",
      "Epoch 119/200, Iteration 237/250, Loss: 0.0218\n",
      "Epoch 119/200, Iteration 238/250, Loss: 0.0087\n",
      "Epoch 119/200, Iteration 239/250, Loss: 0.0124\n",
      "Epoch 119/200, Iteration 240/250, Loss: 0.0128\n",
      "Epoch 119/200, Iteration 241/250, Loss: 0.0193\n",
      "Epoch 119/200, Iteration 242/250, Loss: 0.0192\n",
      "Epoch 119/200, Iteration 243/250, Loss: 0.0079\n",
      "Epoch 119/200, Iteration 244/250, Loss: 0.0071\n",
      "Epoch 119/200, Iteration 245/250, Loss: 0.0145\n",
      "Epoch 119/200, Iteration 246/250, Loss: 0.0093\n",
      "Epoch 119/200, Iteration 247/250, Loss: 0.0220\n",
      "Epoch 119/200, Iteration 248/250, Loss: 0.0148\n",
      "Epoch 119/200, Iteration 249/250, Loss: 0.0115\n",
      "Epoch 119/200, Iteration 250/250, Loss: 0.0078\n",
      "Train Error: \n",
      " Accuracy: 87.01%, Avg loss: 0.006747, MRE: 0.425550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.007318, MRE: 0.472865 \n",
      "\n",
      "Epoch 120/200, Iteration 1/250, Loss: 0.0157\n",
      "Epoch 120/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 120/200, Iteration 3/250, Loss: 0.0255\n",
      "Epoch 120/200, Iteration 4/250, Loss: 0.0071\n",
      "Epoch 120/200, Iteration 5/250, Loss: 0.0152\n",
      "Epoch 120/200, Iteration 6/250, Loss: 0.0125\n",
      "Epoch 120/200, Iteration 7/250, Loss: 0.0124\n",
      "Epoch 120/200, Iteration 8/250, Loss: 0.0159\n",
      "Epoch 120/200, Iteration 9/250, Loss: 0.0126\n",
      "Epoch 120/200, Iteration 10/250, Loss: 0.0145\n",
      "Epoch 120/200, Iteration 11/250, Loss: 0.0139\n",
      "Epoch 120/200, Iteration 12/250, Loss: 0.0111\n",
      "Epoch 120/200, Iteration 13/250, Loss: 0.0277\n",
      "Epoch 120/200, Iteration 14/250, Loss: 0.0136\n",
      "Epoch 120/200, Iteration 15/250, Loss: 0.0259\n",
      "Epoch 120/200, Iteration 16/250, Loss: 0.0115\n",
      "Epoch 120/200, Iteration 17/250, Loss: 0.0216\n",
      "Epoch 120/200, Iteration 18/250, Loss: 0.0149\n",
      "Epoch 120/200, Iteration 19/250, Loss: 0.0295\n",
      "Epoch 120/200, Iteration 20/250, Loss: 0.0110\n",
      "Epoch 120/200, Iteration 21/250, Loss: 0.0242\n",
      "Epoch 120/200, Iteration 22/250, Loss: 0.0127\n",
      "Epoch 120/200, Iteration 23/250, Loss: 0.0153\n",
      "Epoch 120/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 120/200, Iteration 25/250, Loss: 0.0252\n",
      "Epoch 120/200, Iteration 26/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 27/250, Loss: 0.0235\n",
      "Epoch 120/200, Iteration 28/250, Loss: 0.0191\n",
      "Epoch 120/200, Iteration 29/250, Loss: 0.0248\n",
      "Epoch 120/200, Iteration 30/250, Loss: 0.0159\n",
      "Epoch 120/200, Iteration 31/250, Loss: 0.0164\n",
      "Epoch 120/200, Iteration 32/250, Loss: 0.0082\n",
      "Epoch 120/200, Iteration 33/250, Loss: 0.0083\n",
      "Epoch 120/200, Iteration 34/250, Loss: 0.0242\n",
      "Epoch 120/200, Iteration 35/250, Loss: 0.0138\n",
      "Epoch 120/200, Iteration 36/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 37/250, Loss: 0.0123\n",
      "Epoch 120/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 120/200, Iteration 39/250, Loss: 0.0347\n",
      "Epoch 120/200, Iteration 40/250, Loss: 0.0184\n",
      "Epoch 120/200, Iteration 41/250, Loss: 0.0192\n",
      "Epoch 120/200, Iteration 42/250, Loss: 0.0150\n",
      "Epoch 120/200, Iteration 43/250, Loss: 0.0274\n",
      "Epoch 120/200, Iteration 44/250, Loss: 0.0170\n",
      "Epoch 120/200, Iteration 45/250, Loss: 0.0325\n",
      "Epoch 120/200, Iteration 46/250, Loss: 0.0255\n",
      "Epoch 120/200, Iteration 47/250, Loss: 0.0199\n",
      "Epoch 120/200, Iteration 48/250, Loss: 0.0126\n",
      "Epoch 120/200, Iteration 49/250, Loss: 0.0082\n",
      "Epoch 120/200, Iteration 50/250, Loss: 0.0145\n",
      "Epoch 120/200, Iteration 51/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 52/250, Loss: 0.0163\n",
      "Epoch 120/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 54/250, Loss: 0.0109\n",
      "Epoch 120/200, Iteration 55/250, Loss: 0.0174\n",
      "Epoch 120/200, Iteration 56/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 57/250, Loss: 0.0139\n",
      "Epoch 120/200, Iteration 58/250, Loss: 0.0167\n",
      "Epoch 120/200, Iteration 59/250, Loss: 0.0208\n",
      "Epoch 120/200, Iteration 60/250, Loss: 0.0192\n",
      "Epoch 120/200, Iteration 61/250, Loss: 0.0197\n",
      "Epoch 120/200, Iteration 62/250, Loss: 0.0290\n",
      "Epoch 120/200, Iteration 63/250, Loss: 0.0195\n",
      "Epoch 120/200, Iteration 64/250, Loss: 0.0317\n",
      "Epoch 120/200, Iteration 65/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 66/250, Loss: 0.0146\n",
      "Epoch 120/200, Iteration 67/250, Loss: 0.0143\n",
      "Epoch 120/200, Iteration 68/250, Loss: 0.0367\n",
      "Epoch 120/200, Iteration 69/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 70/250, Loss: 0.0154\n",
      "Epoch 120/200, Iteration 71/250, Loss: 0.0195\n",
      "Epoch 120/200, Iteration 72/250, Loss: 0.0152\n",
      "Epoch 120/200, Iteration 73/250, Loss: 0.0145\n",
      "Epoch 120/200, Iteration 74/250, Loss: 0.0208\n",
      "Epoch 120/200, Iteration 75/250, Loss: 0.0212\n",
      "Epoch 120/200, Iteration 76/250, Loss: 0.0197\n",
      "Epoch 120/200, Iteration 77/250, Loss: 0.0155\n",
      "Epoch 120/200, Iteration 78/250, Loss: 0.0182\n",
      "Epoch 120/200, Iteration 79/250, Loss: 0.0123\n",
      "Epoch 120/200, Iteration 80/250, Loss: 0.0155\n",
      "Epoch 120/200, Iteration 81/250, Loss: 0.0095\n",
      "Epoch 120/200, Iteration 82/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 83/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 84/250, Loss: 0.0245\n",
      "Epoch 120/200, Iteration 85/250, Loss: 0.0207\n",
      "Epoch 120/200, Iteration 86/250, Loss: 0.0067\n",
      "Epoch 120/200, Iteration 87/250, Loss: 0.0132\n",
      "Epoch 120/200, Iteration 88/250, Loss: 0.0147\n",
      "Epoch 120/200, Iteration 89/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 90/250, Loss: 0.0067\n",
      "Epoch 120/200, Iteration 91/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 92/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 93/250, Loss: 0.0164\n",
      "Epoch 120/200, Iteration 94/250, Loss: 0.0074\n",
      "Epoch 120/200, Iteration 95/250, Loss: 0.0139\n",
      "Epoch 120/200, Iteration 96/250, Loss: 0.0080\n",
      "Epoch 120/200, Iteration 97/250, Loss: 0.0112\n",
      "Epoch 120/200, Iteration 98/250, Loss: 0.0143\n",
      "Epoch 120/200, Iteration 99/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 100/250, Loss: 0.0215\n",
      "Epoch 120/200, Iteration 101/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 102/250, Loss: 0.0073\n",
      "Epoch 120/200, Iteration 103/250, Loss: 0.0072\n",
      "Epoch 120/200, Iteration 104/250, Loss: 0.0135\n",
      "Epoch 120/200, Iteration 105/250, Loss: 0.0262\n",
      "Epoch 120/200, Iteration 106/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 107/250, Loss: 0.0213\n",
      "Epoch 120/200, Iteration 108/250, Loss: 0.0286\n",
      "Epoch 120/200, Iteration 109/250, Loss: 0.0181\n",
      "Epoch 120/200, Iteration 110/250, Loss: 0.0074\n",
      "Epoch 120/200, Iteration 111/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 112/250, Loss: 0.0076\n",
      "Epoch 120/200, Iteration 113/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 114/250, Loss: 0.0134\n",
      "Epoch 120/200, Iteration 115/250, Loss: 0.0175\n",
      "Epoch 120/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 120/200, Iteration 117/250, Loss: 0.0189\n",
      "Epoch 120/200, Iteration 118/250, Loss: 0.0177\n",
      "Epoch 120/200, Iteration 119/250, Loss: 0.0060\n",
      "Epoch 120/200, Iteration 120/250, Loss: 0.0189\n",
      "Epoch 120/200, Iteration 121/250, Loss: 0.0079\n",
      "Epoch 120/200, Iteration 122/250, Loss: 0.0085\n",
      "Epoch 120/200, Iteration 123/250, Loss: 0.0084\n",
      "Epoch 120/200, Iteration 124/250, Loss: 0.0077\n",
      "Epoch 120/200, Iteration 125/250, Loss: 0.0158\n",
      "Epoch 120/200, Iteration 126/250, Loss: 0.0080\n",
      "Epoch 120/200, Iteration 127/250, Loss: 0.0172\n",
      "Epoch 120/200, Iteration 128/250, Loss: 0.0122\n",
      "Epoch 120/200, Iteration 129/250, Loss: 0.0090\n",
      "Epoch 120/200, Iteration 130/250, Loss: 0.0273\n",
      "Epoch 120/200, Iteration 131/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 132/250, Loss: 0.0083\n",
      "Epoch 120/200, Iteration 133/250, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 134/250, Loss: 0.0218\n",
      "Epoch 120/200, Iteration 135/250, Loss: 0.0086\n",
      "Epoch 120/200, Iteration 136/250, Loss: 0.0125\n",
      "Epoch 120/200, Iteration 137/250, Loss: 0.0081\n",
      "Epoch 120/200, Iteration 138/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 139/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 140/250, Loss: 0.0338\n",
      "Epoch 120/200, Iteration 141/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 142/250, Loss: 0.0095\n",
      "Epoch 120/200, Iteration 143/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 144/250, Loss: 0.0110\n",
      "Epoch 120/200, Iteration 145/250, Loss: 0.0073\n",
      "Epoch 120/200, Iteration 146/250, Loss: 0.0267\n",
      "Epoch 120/200, Iteration 147/250, Loss: 0.0211\n",
      "Epoch 120/200, Iteration 148/250, Loss: 0.0161\n",
      "Epoch 120/200, Iteration 149/250, Loss: 0.0127\n",
      "Epoch 120/200, Iteration 150/250, Loss: 0.0164\n",
      "Epoch 120/200, Iteration 151/250, Loss: 0.0242\n",
      "Epoch 120/200, Iteration 152/250, Loss: 0.0260\n",
      "Epoch 120/200, Iteration 153/250, Loss: 0.0118\n",
      "Epoch 120/200, Iteration 154/250, Loss: 0.0187\n",
      "Epoch 120/200, Iteration 155/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 156/250, Loss: 0.0134\n",
      "Epoch 120/200, Iteration 157/250, Loss: 0.0136\n",
      "Epoch 120/200, Iteration 158/250, Loss: 0.0122\n",
      "Epoch 120/200, Iteration 159/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 160/250, Loss: 0.0087\n",
      "Epoch 120/200, Iteration 161/250, Loss: 0.0176\n",
      "Epoch 120/200, Iteration 162/250, Loss: 0.0295\n",
      "Epoch 120/200, Iteration 163/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 164/250, Loss: 0.0205\n",
      "Epoch 120/200, Iteration 165/250, Loss: 0.0106\n",
      "Epoch 120/200, Iteration 166/250, Loss: 0.0168\n",
      "Epoch 120/200, Iteration 167/250, Loss: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200, Iteration 168/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 169/250, Loss: 0.0058\n",
      "Epoch 120/200, Iteration 170/250, Loss: 0.0099\n",
      "Epoch 120/200, Iteration 171/250, Loss: 0.0204\n",
      "Epoch 120/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 120/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 120/200, Iteration 175/250, Loss: 0.0233\n",
      "Epoch 120/200, Iteration 176/250, Loss: 0.0179\n",
      "Epoch 120/200, Iteration 177/250, Loss: 0.0111\n",
      "Epoch 120/200, Iteration 178/250, Loss: 0.0113\n",
      "Epoch 120/200, Iteration 179/250, Loss: 0.0096\n",
      "Epoch 120/200, Iteration 180/250, Loss: 0.0170\n",
      "Epoch 120/200, Iteration 181/250, Loss: 0.0223\n",
      "Epoch 120/200, Iteration 182/250, Loss: 0.0339\n",
      "Epoch 120/200, Iteration 183/250, Loss: 0.0111\n",
      "Epoch 120/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 120/200, Iteration 185/250, Loss: 0.0137\n",
      "Epoch 120/200, Iteration 186/250, Loss: 0.0114\n",
      "Epoch 120/200, Iteration 187/250, Loss: 0.0169\n",
      "Epoch 120/200, Iteration 188/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 189/250, Loss: 0.0278\n",
      "Epoch 120/200, Iteration 190/250, Loss: 0.0050\n",
      "Epoch 120/200, Iteration 191/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 192/250, Loss: 0.0394\n",
      "Epoch 120/200, Iteration 193/250, Loss: 0.0392\n",
      "Epoch 120/200, Iteration 194/250, Loss: 0.0190\n",
      "Epoch 120/200, Iteration 195/250, Loss: 0.0186\n",
      "Epoch 120/200, Iteration 196/250, Loss: 0.0074\n",
      "Epoch 120/200, Iteration 197/250, Loss: 0.0116\n",
      "Epoch 120/200, Iteration 198/250, Loss: 0.0089\n",
      "Epoch 120/200, Iteration 199/250, Loss: 0.0157\n",
      "Epoch 120/200, Iteration 200/250, Loss: 0.0154\n",
      "Epoch 120/200, Iteration 201/250, Loss: 0.0183\n",
      "Epoch 120/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 203/250, Loss: 0.0249\n",
      "Epoch 120/200, Iteration 204/250, Loss: 0.0189\n",
      "Epoch 120/200, Iteration 205/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 206/250, Loss: 0.0262\n",
      "Epoch 120/200, Iteration 207/250, Loss: 0.0105\n",
      "Epoch 120/200, Iteration 208/250, Loss: 0.0068\n",
      "Epoch 120/200, Iteration 209/250, Loss: 0.0192\n",
      "Epoch 120/200, Iteration 210/250, Loss: 0.0162\n",
      "Epoch 120/200, Iteration 211/250, Loss: 0.0106\n",
      "Epoch 120/200, Iteration 212/250, Loss: 0.0263\n",
      "Epoch 120/200, Iteration 213/250, Loss: 0.0154\n",
      "Epoch 120/200, Iteration 214/250, Loss: 0.0223\n",
      "Epoch 120/200, Iteration 215/250, Loss: 0.0212\n",
      "Epoch 120/200, Iteration 216/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 217/250, Loss: 0.0117\n",
      "Epoch 120/200, Iteration 218/250, Loss: 0.0128\n",
      "Epoch 120/200, Iteration 219/250, Loss: 0.0094\n",
      "Epoch 120/200, Iteration 220/250, Loss: 0.0088\n",
      "Epoch 120/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 222/250, Loss: 0.0104\n",
      "Epoch 120/200, Iteration 223/250, Loss: 0.0279\n",
      "Epoch 120/200, Iteration 224/250, Loss: 0.0126\n",
      "Epoch 120/200, Iteration 225/250, Loss: 0.0152\n",
      "Epoch 120/200, Iteration 226/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 227/250, Loss: 0.0308\n",
      "Epoch 120/200, Iteration 228/250, Loss: 0.0089\n",
      "Epoch 120/200, Iteration 229/250, Loss: 0.0107\n",
      "Epoch 120/200, Iteration 230/250, Loss: 0.0108\n",
      "Epoch 120/200, Iteration 231/250, Loss: 0.0227\n",
      "Epoch 120/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 120/200, Iteration 233/250, Loss: 0.0100\n",
      "Epoch 120/200, Iteration 234/250, Loss: 0.0226\n",
      "Epoch 120/200, Iteration 235/250, Loss: 0.0123\n",
      "Epoch 120/200, Iteration 236/250, Loss: 0.0271\n",
      "Epoch 120/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 120/200, Iteration 238/250, Loss: 0.0124\n",
      "Epoch 120/200, Iteration 239/250, Loss: 0.0093\n",
      "Epoch 120/200, Iteration 240/250, Loss: 0.0143\n",
      "Epoch 120/200, Iteration 241/250, Loss: 0.0102\n",
      "Epoch 120/200, Iteration 242/250, Loss: 0.0262\n",
      "Epoch 120/200, Iteration 243/250, Loss: 0.0133\n",
      "Epoch 120/200, Iteration 244/250, Loss: 0.0131\n",
      "Epoch 120/200, Iteration 245/250, Loss: 0.0098\n",
      "Epoch 120/200, Iteration 246/250, Loss: 0.0119\n",
      "Epoch 120/200, Iteration 247/250, Loss: 0.0093\n",
      "Epoch 120/200, Iteration 248/250, Loss: 0.0101\n",
      "Epoch 120/200, Iteration 249/250, Loss: 0.0442\n",
      "Epoch 120/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 96.35%, Avg loss: 0.008743, MRE: 0.520281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.009290, MRE: 0.527597 \n",
      "\n",
      "Epoch 121/200, Iteration 1/250, Loss: 0.0205\n",
      "Epoch 121/200, Iteration 2/250, Loss: 0.0168\n",
      "Epoch 121/200, Iteration 3/250, Loss: 0.0123\n",
      "Epoch 121/200, Iteration 4/250, Loss: 0.0130\n",
      "Epoch 121/200, Iteration 5/250, Loss: 0.0082\n",
      "Epoch 121/200, Iteration 6/250, Loss: 0.0244\n",
      "Epoch 121/200, Iteration 7/250, Loss: 0.0367\n",
      "Epoch 121/200, Iteration 8/250, Loss: 0.0141\n",
      "Epoch 121/200, Iteration 9/250, Loss: 0.0166\n",
      "Epoch 121/200, Iteration 10/250, Loss: 0.0093\n",
      "Epoch 121/200, Iteration 11/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 12/250, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 13/250, Loss: 0.0185\n",
      "Epoch 121/200, Iteration 14/250, Loss: 0.0079\n",
      "Epoch 121/200, Iteration 15/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 17/250, Loss: 0.0164\n",
      "Epoch 121/200, Iteration 18/250, Loss: 0.0123\n",
      "Epoch 121/200, Iteration 19/250, Loss: 0.0256\n",
      "Epoch 121/200, Iteration 20/250, Loss: 0.0208\n",
      "Epoch 121/200, Iteration 21/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 22/250, Loss: 0.0118\n",
      "Epoch 121/200, Iteration 23/250, Loss: 0.0083\n",
      "Epoch 121/200, Iteration 24/250, Loss: 0.0064\n",
      "Epoch 121/200, Iteration 25/250, Loss: 0.0113\n",
      "Epoch 121/200, Iteration 26/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 27/250, Loss: 0.0093\n",
      "Epoch 121/200, Iteration 28/250, Loss: 0.0163\n",
      "Epoch 121/200, Iteration 29/250, Loss: 0.0129\n",
      "Epoch 121/200, Iteration 30/250, Loss: 0.0139\n",
      "Epoch 121/200, Iteration 31/250, Loss: 0.0125\n",
      "Epoch 121/200, Iteration 32/250, Loss: 0.0203\n",
      "Epoch 121/200, Iteration 33/250, Loss: 0.0257\n",
      "Epoch 121/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 121/200, Iteration 35/250, Loss: 0.0147\n",
      "Epoch 121/200, Iteration 36/250, Loss: 0.0096\n",
      "Epoch 121/200, Iteration 37/250, Loss: 0.0118\n",
      "Epoch 121/200, Iteration 38/250, Loss: 0.0185\n",
      "Epoch 121/200, Iteration 39/250, Loss: 0.0126\n",
      "Epoch 121/200, Iteration 40/250, Loss: 0.0141\n",
      "Epoch 121/200, Iteration 41/250, Loss: 0.0109\n",
      "Epoch 121/200, Iteration 42/250, Loss: 0.0141\n",
      "Epoch 121/200, Iteration 43/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 44/250, Loss: 0.0278\n",
      "Epoch 121/200, Iteration 45/250, Loss: 0.0250\n",
      "Epoch 121/200, Iteration 46/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 47/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 48/250, Loss: 0.0099\n",
      "Epoch 121/200, Iteration 49/250, Loss: 0.0077\n",
      "Epoch 121/200, Iteration 50/250, Loss: 0.0147\n",
      "Epoch 121/200, Iteration 51/250, Loss: 0.0073\n",
      "Epoch 121/200, Iteration 52/250, Loss: 0.0092\n",
      "Epoch 121/200, Iteration 53/250, Loss: 0.0253\n",
      "Epoch 121/200, Iteration 54/250, Loss: 0.0077\n",
      "Epoch 121/200, Iteration 55/250, Loss: 0.0242\n",
      "Epoch 121/200, Iteration 56/250, Loss: 0.0179\n",
      "Epoch 121/200, Iteration 57/250, Loss: 0.0081\n",
      "Epoch 121/200, Iteration 58/250, Loss: 0.0179\n",
      "Epoch 121/200, Iteration 59/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 60/250, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 61/250, Loss: 0.0188\n",
      "Epoch 121/200, Iteration 62/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 63/250, Loss: 0.0196\n",
      "Epoch 121/200, Iteration 64/250, Loss: 0.0098\n",
      "Epoch 121/200, Iteration 65/250, Loss: 0.0272\n",
      "Epoch 121/200, Iteration 66/250, Loss: 0.0302\n",
      "Epoch 121/200, Iteration 67/250, Loss: 0.0180\n",
      "Epoch 121/200, Iteration 68/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 69/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 70/250, Loss: 0.0083\n",
      "Epoch 121/200, Iteration 71/250, Loss: 0.0303\n",
      "Epoch 121/200, Iteration 72/250, Loss: 0.0192\n",
      "Epoch 121/200, Iteration 73/250, Loss: 0.0259\n",
      "Epoch 121/200, Iteration 74/250, Loss: 0.0068\n",
      "Epoch 121/200, Iteration 75/250, Loss: 0.0145\n",
      "Epoch 121/200, Iteration 76/250, Loss: 0.0121\n",
      "Epoch 121/200, Iteration 77/250, Loss: 0.0238\n",
      "Epoch 121/200, Iteration 78/250, Loss: 0.0240\n",
      "Epoch 121/200, Iteration 79/250, Loss: 0.0259\n",
      "Epoch 121/200, Iteration 80/250, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 81/250, Loss: 0.0098\n",
      "Epoch 121/200, Iteration 82/250, Loss: 0.0130\n",
      "Epoch 121/200, Iteration 83/250, Loss: 0.0152\n",
      "Epoch 121/200, Iteration 84/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 85/250, Loss: 0.0130\n",
      "Epoch 121/200, Iteration 86/250, Loss: 0.0112\n",
      "Epoch 121/200, Iteration 87/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 88/250, Loss: 0.0085\n",
      "Epoch 121/200, Iteration 89/250, Loss: 0.0170\n",
      "Epoch 121/200, Iteration 90/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 91/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 92/250, Loss: 0.0071\n",
      "Epoch 121/200, Iteration 93/250, Loss: 0.0204\n",
      "Epoch 121/200, Iteration 94/250, Loss: 0.0167\n",
      "Epoch 121/200, Iteration 95/250, Loss: 0.0147\n",
      "Epoch 121/200, Iteration 96/250, Loss: 0.0096\n",
      "Epoch 121/200, Iteration 97/250, Loss: 0.0220\n",
      "Epoch 121/200, Iteration 98/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 99/250, Loss: 0.0082\n",
      "Epoch 121/200, Iteration 100/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 101/250, Loss: 0.0111\n",
      "Epoch 121/200, Iteration 102/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 103/250, Loss: 0.0078\n",
      "Epoch 121/200, Iteration 104/250, Loss: 0.0261\n",
      "Epoch 121/200, Iteration 105/250, Loss: 0.0054\n",
      "Epoch 121/200, Iteration 106/250, Loss: 0.0119\n",
      "Epoch 121/200, Iteration 107/250, Loss: 0.0060\n",
      "Epoch 121/200, Iteration 108/250, Loss: 0.0234\n",
      "Epoch 121/200, Iteration 109/250, Loss: 0.0128\n",
      "Epoch 121/200, Iteration 110/250, Loss: 0.0218\n",
      "Epoch 121/200, Iteration 111/250, Loss: 0.0084\n",
      "Epoch 121/200, Iteration 112/250, Loss: 0.0202\n",
      "Epoch 121/200, Iteration 113/250, Loss: 0.0286\n",
      "Epoch 121/200, Iteration 114/250, Loss: 0.0127\n",
      "Epoch 121/200, Iteration 115/250, Loss: 0.0109\n",
      "Epoch 121/200, Iteration 116/250, Loss: 0.0135\n",
      "Epoch 121/200, Iteration 117/250, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 118/250, Loss: 0.0142\n",
      "Epoch 121/200, Iteration 119/250, Loss: 0.0282\n",
      "Epoch 121/200, Iteration 120/250, Loss: 0.0103\n",
      "Epoch 121/200, Iteration 121/250, Loss: 0.0217\n",
      "Epoch 121/200, Iteration 122/250, Loss: 0.0065\n",
      "Epoch 121/200, Iteration 123/250, Loss: 0.0188\n",
      "Epoch 121/200, Iteration 124/250, Loss: 0.0305\n",
      "Epoch 121/200, Iteration 125/250, Loss: 0.0165\n",
      "Epoch 121/200, Iteration 126/250, Loss: 0.0113\n",
      "Epoch 121/200, Iteration 127/250, Loss: 0.0117\n",
      "Epoch 121/200, Iteration 128/250, Loss: 0.0157\n",
      "Epoch 121/200, Iteration 129/250, Loss: 0.0162\n",
      "Epoch 121/200, Iteration 130/250, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200, Iteration 131/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 132/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 133/250, Loss: 0.0143\n",
      "Epoch 121/200, Iteration 134/250, Loss: 0.0195\n",
      "Epoch 121/200, Iteration 135/250, Loss: 0.0212\n",
      "Epoch 121/200, Iteration 136/250, Loss: 0.0159\n",
      "Epoch 121/200, Iteration 137/250, Loss: 0.0080\n",
      "Epoch 121/200, Iteration 138/250, Loss: 0.0224\n",
      "Epoch 121/200, Iteration 139/250, Loss: 0.0132\n",
      "Epoch 121/200, Iteration 140/250, Loss: 0.0116\n",
      "Epoch 121/200, Iteration 141/250, Loss: 0.0150\n",
      "Epoch 121/200, Iteration 142/250, Loss: 0.0195\n",
      "Epoch 121/200, Iteration 143/250, Loss: 0.0086\n",
      "Epoch 121/200, Iteration 144/250, Loss: 0.0083\n",
      "Epoch 121/200, Iteration 145/250, Loss: 0.0153\n",
      "Epoch 121/200, Iteration 146/250, Loss: 0.0126\n",
      "Epoch 121/200, Iteration 147/250, Loss: 0.0261\n",
      "Epoch 121/200, Iteration 148/250, Loss: 0.0163\n",
      "Epoch 121/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 121/200, Iteration 150/250, Loss: 0.0189\n",
      "Epoch 121/200, Iteration 151/250, Loss: 0.0088\n",
      "Epoch 121/200, Iteration 152/250, Loss: 0.0161\n",
      "Epoch 121/200, Iteration 153/250, Loss: 0.0192\n",
      "Epoch 121/200, Iteration 154/250, Loss: 0.0059\n",
      "Epoch 121/200, Iteration 155/250, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 156/250, Loss: 0.0114\n",
      "Epoch 121/200, Iteration 157/250, Loss: 0.0337\n",
      "Epoch 121/200, Iteration 158/250, Loss: 0.0076\n",
      "Epoch 121/200, Iteration 159/250, Loss: 0.0134\n",
      "Epoch 121/200, Iteration 160/250, Loss: 0.0135\n",
      "Epoch 121/200, Iteration 161/250, Loss: 0.0085\n",
      "Epoch 121/200, Iteration 162/250, Loss: 0.0075\n",
      "Epoch 121/200, Iteration 163/250, Loss: 0.0067\n",
      "Epoch 121/200, Iteration 164/250, Loss: 0.0083\n",
      "Epoch 121/200, Iteration 165/250, Loss: 0.0049\n",
      "Epoch 121/200, Iteration 166/250, Loss: 0.0128\n",
      "Epoch 121/200, Iteration 167/250, Loss: 0.0331\n",
      "Epoch 121/200, Iteration 168/250, Loss: 0.0075\n",
      "Epoch 121/200, Iteration 169/250, Loss: 0.0146\n",
      "Epoch 121/200, Iteration 170/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 171/250, Loss: 0.0126\n",
      "Epoch 121/200, Iteration 172/250, Loss: 0.0151\n",
      "Epoch 121/200, Iteration 173/250, Loss: 0.0142\n",
      "Epoch 121/200, Iteration 174/250, Loss: 0.0156\n",
      "Epoch 121/200, Iteration 175/250, Loss: 0.0407\n",
      "Epoch 121/200, Iteration 176/250, Loss: 0.0097\n",
      "Epoch 121/200, Iteration 177/250, Loss: 0.0080\n",
      "Epoch 121/200, Iteration 178/250, Loss: 0.0160\n",
      "Epoch 121/200, Iteration 179/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 180/250, Loss: 0.0379\n",
      "Epoch 121/200, Iteration 181/250, Loss: 0.0177\n",
      "Epoch 121/200, Iteration 182/250, Loss: 0.0155\n",
      "Epoch 121/200, Iteration 183/250, Loss: 0.0095\n",
      "Epoch 121/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 185/250, Loss: 0.0090\n",
      "Epoch 121/200, Iteration 186/250, Loss: 0.0198\n",
      "Epoch 121/200, Iteration 187/250, Loss: 0.0122\n",
      "Epoch 121/200, Iteration 188/250, Loss: 0.0185\n",
      "Epoch 121/200, Iteration 189/250, Loss: 0.0120\n",
      "Epoch 121/200, Iteration 190/250, Loss: 0.0181\n",
      "Epoch 121/200, Iteration 191/250, Loss: 0.0102\n",
      "Epoch 121/200, Iteration 192/250, Loss: 0.0145\n",
      "Epoch 121/200, Iteration 193/250, Loss: 0.0328\n",
      "Epoch 121/200, Iteration 194/250, Loss: 0.0111\n",
      "Epoch 121/200, Iteration 195/250, Loss: 0.0165\n",
      "Epoch 121/200, Iteration 196/250, Loss: 0.0084\n",
      "Epoch 121/200, Iteration 197/250, Loss: 0.0085\n",
      "Epoch 121/200, Iteration 198/250, Loss: 0.0120\n",
      "Epoch 121/200, Iteration 199/250, Loss: 0.0085\n",
      "Epoch 121/200, Iteration 200/250, Loss: 0.0289\n",
      "Epoch 121/200, Iteration 201/250, Loss: 0.0146\n",
      "Epoch 121/200, Iteration 202/250, Loss: 0.0116\n",
      "Epoch 121/200, Iteration 203/250, Loss: 0.0086\n",
      "Epoch 121/200, Iteration 204/250, Loss: 0.0200\n",
      "Epoch 121/200, Iteration 205/250, Loss: 0.0075\n",
      "Epoch 121/200, Iteration 206/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 207/250, Loss: 0.0193\n",
      "Epoch 121/200, Iteration 208/250, Loss: 0.0172\n",
      "Epoch 121/200, Iteration 209/250, Loss: 0.0370\n",
      "Epoch 121/200, Iteration 210/250, Loss: 0.0054\n",
      "Epoch 121/200, Iteration 211/250, Loss: 0.0101\n",
      "Epoch 121/200, Iteration 212/250, Loss: 0.0145\n",
      "Epoch 121/200, Iteration 213/250, Loss: 0.0126\n",
      "Epoch 121/200, Iteration 214/250, Loss: 0.0079\n",
      "Epoch 121/200, Iteration 215/250, Loss: 0.0117\n",
      "Epoch 121/200, Iteration 216/250, Loss: 0.0109\n",
      "Epoch 121/200, Iteration 217/250, Loss: 0.0128\n",
      "Epoch 121/200, Iteration 218/250, Loss: 0.0213\n",
      "Epoch 121/200, Iteration 219/250, Loss: 0.0134\n",
      "Epoch 121/200, Iteration 220/250, Loss: 0.0137\n",
      "Epoch 121/200, Iteration 221/250, Loss: 0.0100\n",
      "Epoch 121/200, Iteration 222/250, Loss: 0.0149\n",
      "Epoch 121/200, Iteration 223/250, Loss: 0.0131\n",
      "Epoch 121/200, Iteration 224/250, Loss: 0.0151\n",
      "Epoch 121/200, Iteration 225/250, Loss: 0.0160\n",
      "Epoch 121/200, Iteration 226/250, Loss: 0.0135\n",
      "Epoch 121/200, Iteration 227/250, Loss: 0.0120\n",
      "Epoch 121/200, Iteration 228/250, Loss: 0.0158\n",
      "Epoch 121/200, Iteration 229/250, Loss: 0.0107\n",
      "Epoch 121/200, Iteration 230/250, Loss: 0.0061\n",
      "Epoch 121/200, Iteration 231/250, Loss: 0.0134\n",
      "Epoch 121/200, Iteration 232/250, Loss: 0.0117\n",
      "Epoch 121/200, Iteration 233/250, Loss: 0.0150\n",
      "Epoch 121/200, Iteration 234/250, Loss: 0.0140\n",
      "Epoch 121/200, Iteration 235/250, Loss: 0.0070\n",
      "Epoch 121/200, Iteration 236/250, Loss: 0.0197\n",
      "Epoch 121/200, Iteration 237/250, Loss: 0.0074\n",
      "Epoch 121/200, Iteration 238/250, Loss: 0.0209\n",
      "Epoch 121/200, Iteration 239/250, Loss: 0.0302\n",
      "Epoch 121/200, Iteration 240/250, Loss: 0.0182\n",
      "Epoch 121/200, Iteration 241/250, Loss: 0.0121\n",
      "Epoch 121/200, Iteration 242/250, Loss: 0.0094\n",
      "Epoch 121/200, Iteration 243/250, Loss: 0.0106\n",
      "Epoch 121/200, Iteration 244/250, Loss: 0.0123\n",
      "Epoch 121/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 121/200, Iteration 246/250, Loss: 0.0111\n",
      "Epoch 121/200, Iteration 247/250, Loss: 0.0207\n",
      "Epoch 121/200, Iteration 248/250, Loss: 0.0078\n",
      "Epoch 121/200, Iteration 249/250, Loss: 0.0110\n",
      "Epoch 121/200, Iteration 250/250, Loss: 0.0089\n",
      "Train Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.006793, MRE: 0.457028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.25%, Avg loss: 0.007290, MRE: 0.469205 \n",
      "\n",
      "Epoch 122/200, Iteration 1/250, Loss: 0.0104\n",
      "Epoch 122/200, Iteration 2/250, Loss: 0.0221\n",
      "Epoch 122/200, Iteration 3/250, Loss: 0.0195\n",
      "Epoch 122/200, Iteration 4/250, Loss: 0.0228\n",
      "Epoch 122/200, Iteration 5/250, Loss: 0.0124\n",
      "Epoch 122/200, Iteration 6/250, Loss: 0.0108\n",
      "Epoch 122/200, Iteration 7/250, Loss: 0.0199\n",
      "Epoch 122/200, Iteration 8/250, Loss: 0.0130\n",
      "Epoch 122/200, Iteration 9/250, Loss: 0.0128\n",
      "Epoch 122/200, Iteration 10/250, Loss: 0.0143\n",
      "Epoch 122/200, Iteration 11/250, Loss: 0.0098\n",
      "Epoch 122/200, Iteration 12/250, Loss: 0.0140\n",
      "Epoch 122/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 122/200, Iteration 14/250, Loss: 0.0092\n",
      "Epoch 122/200, Iteration 15/250, Loss: 0.0252\n",
      "Epoch 122/200, Iteration 16/250, Loss: 0.0088\n",
      "Epoch 122/200, Iteration 17/250, Loss: 0.0184\n",
      "Epoch 122/200, Iteration 18/250, Loss: 0.0137\n",
      "Epoch 122/200, Iteration 19/250, Loss: 0.0178\n",
      "Epoch 122/200, Iteration 20/250, Loss: 0.0222\n",
      "Epoch 122/200, Iteration 21/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 22/250, Loss: 0.0335\n",
      "Epoch 122/200, Iteration 23/250, Loss: 0.0090\n",
      "Epoch 122/200, Iteration 24/250, Loss: 0.0075\n",
      "Epoch 122/200, Iteration 25/250, Loss: 0.0233\n",
      "Epoch 122/200, Iteration 26/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 27/250, Loss: 0.0223\n",
      "Epoch 122/200, Iteration 28/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 29/250, Loss: 0.0087\n",
      "Epoch 122/200, Iteration 30/250, Loss: 0.0127\n",
      "Epoch 122/200, Iteration 31/250, Loss: 0.0220\n",
      "Epoch 122/200, Iteration 32/250, Loss: 0.0085\n",
      "Epoch 122/200, Iteration 33/250, Loss: 0.0154\n",
      "Epoch 122/200, Iteration 34/250, Loss: 0.0094\n",
      "Epoch 122/200, Iteration 35/250, Loss: 0.0162\n",
      "Epoch 122/200, Iteration 36/250, Loss: 0.0190\n",
      "Epoch 122/200, Iteration 37/250, Loss: 0.0158\n",
      "Epoch 122/200, Iteration 38/250, Loss: 0.0223\n",
      "Epoch 122/200, Iteration 39/250, Loss: 0.0186\n",
      "Epoch 122/200, Iteration 40/250, Loss: 0.0074\n",
      "Epoch 122/200, Iteration 41/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 42/250, Loss: 0.0141\n",
      "Epoch 122/200, Iteration 43/250, Loss: 0.0109\n",
      "Epoch 122/200, Iteration 44/250, Loss: 0.0087\n",
      "Epoch 122/200, Iteration 45/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 46/250, Loss: 0.0138\n",
      "Epoch 122/200, Iteration 47/250, Loss: 0.0265\n",
      "Epoch 122/200, Iteration 48/250, Loss: 0.0093\n",
      "Epoch 122/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 122/200, Iteration 50/250, Loss: 0.0129\n",
      "Epoch 122/200, Iteration 51/250, Loss: 0.0097\n",
      "Epoch 122/200, Iteration 52/250, Loss: 0.0213\n",
      "Epoch 122/200, Iteration 53/250, Loss: 0.0245\n",
      "Epoch 122/200, Iteration 54/250, Loss: 0.0245\n",
      "Epoch 122/200, Iteration 55/250, Loss: 0.0103\n",
      "Epoch 122/200, Iteration 56/250, Loss: 0.0131\n",
      "Epoch 122/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 58/250, Loss: 0.0102\n",
      "Epoch 122/200, Iteration 59/250, Loss: 0.0095\n",
      "Epoch 122/200, Iteration 60/250, Loss: 0.0148\n",
      "Epoch 122/200, Iteration 61/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 62/250, Loss: 0.0139\n",
      "Epoch 122/200, Iteration 63/250, Loss: 0.0151\n",
      "Epoch 122/200, Iteration 64/250, Loss: 0.0079\n",
      "Epoch 122/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 66/250, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 67/250, Loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200, Iteration 68/250, Loss: 0.0324\n",
      "Epoch 122/200, Iteration 69/250, Loss: 0.0166\n",
      "Epoch 122/200, Iteration 70/250, Loss: 0.0340\n",
      "Epoch 122/200, Iteration 71/250, Loss: 0.0080\n",
      "Epoch 122/200, Iteration 72/250, Loss: 0.0142\n",
      "Epoch 122/200, Iteration 73/250, Loss: 0.0207\n",
      "Epoch 122/200, Iteration 74/250, Loss: 0.0178\n",
      "Epoch 122/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 76/250, Loss: 0.0228\n",
      "Epoch 122/200, Iteration 77/250, Loss: 0.0073\n",
      "Epoch 122/200, Iteration 78/250, Loss: 0.0276\n",
      "Epoch 122/200, Iteration 79/250, Loss: 0.0231\n",
      "Epoch 122/200, Iteration 80/250, Loss: 0.0174\n",
      "Epoch 122/200, Iteration 81/250, Loss: 0.0281\n",
      "Epoch 122/200, Iteration 82/250, Loss: 0.0178\n",
      "Epoch 122/200, Iteration 83/250, Loss: 0.0092\n",
      "Epoch 122/200, Iteration 84/250, Loss: 0.0160\n",
      "Epoch 122/200, Iteration 85/250, Loss: 0.0192\n",
      "Epoch 122/200, Iteration 86/250, Loss: 0.0189\n",
      "Epoch 122/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 122/200, Iteration 88/250, Loss: 0.0089\n",
      "Epoch 122/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 122/200, Iteration 90/250, Loss: 0.0150\n",
      "Epoch 122/200, Iteration 91/250, Loss: 0.0070\n",
      "Epoch 122/200, Iteration 92/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 93/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 94/250, Loss: 0.0312\n",
      "Epoch 122/200, Iteration 95/250, Loss: 0.0153\n",
      "Epoch 122/200, Iteration 96/250, Loss: 0.0479\n",
      "Epoch 122/200, Iteration 97/250, Loss: 0.0059\n",
      "Epoch 122/200, Iteration 98/250, Loss: 0.0187\n",
      "Epoch 122/200, Iteration 99/250, Loss: 0.0169\n",
      "Epoch 122/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 101/250, Loss: 0.0114\n",
      "Epoch 122/200, Iteration 102/250, Loss: 0.0094\n",
      "Epoch 122/200, Iteration 103/250, Loss: 0.0071\n",
      "Epoch 122/200, Iteration 104/250, Loss: 0.0296\n",
      "Epoch 122/200, Iteration 105/250, Loss: 0.0180\n",
      "Epoch 122/200, Iteration 106/250, Loss: 0.0237\n",
      "Epoch 122/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 122/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 109/250, Loss: 0.0182\n",
      "Epoch 122/200, Iteration 110/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 112/250, Loss: 0.0189\n",
      "Epoch 122/200, Iteration 113/250, Loss: 0.0236\n",
      "Epoch 122/200, Iteration 114/250, Loss: 0.0237\n",
      "Epoch 122/200, Iteration 115/250, Loss: 0.0197\n",
      "Epoch 122/200, Iteration 116/250, Loss: 0.0077\n",
      "Epoch 122/200, Iteration 117/250, Loss: 0.0098\n",
      "Epoch 122/200, Iteration 118/250, Loss: 0.0085\n",
      "Epoch 122/200, Iteration 119/250, Loss: 0.0144\n",
      "Epoch 122/200, Iteration 120/250, Loss: 0.0166\n",
      "Epoch 122/200, Iteration 121/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 122/250, Loss: 0.0081\n",
      "Epoch 122/200, Iteration 123/250, Loss: 0.0154\n",
      "Epoch 122/200, Iteration 124/250, Loss: 0.0082\n",
      "Epoch 122/200, Iteration 125/250, Loss: 0.0206\n",
      "Epoch 122/200, Iteration 126/250, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 127/250, Loss: 0.0191\n",
      "Epoch 122/200, Iteration 128/250, Loss: 0.0132\n",
      "Epoch 122/200, Iteration 129/250, Loss: 0.0430\n",
      "Epoch 122/200, Iteration 130/250, Loss: 0.0135\n",
      "Epoch 122/200, Iteration 131/250, Loss: 0.0079\n",
      "Epoch 122/200, Iteration 132/250, Loss: 0.0119\n",
      "Epoch 122/200, Iteration 133/250, Loss: 0.0141\n",
      "Epoch 122/200, Iteration 134/250, Loss: 0.0097\n",
      "Epoch 122/200, Iteration 135/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 136/250, Loss: 0.0335\n",
      "Epoch 122/200, Iteration 137/250, Loss: 0.0090\n",
      "Epoch 122/200, Iteration 138/250, Loss: 0.0136\n",
      "Epoch 122/200, Iteration 139/250, Loss: 0.0325\n",
      "Epoch 122/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 122/200, Iteration 141/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 142/250, Loss: 0.0166\n",
      "Epoch 122/200, Iteration 143/250, Loss: 0.0125\n",
      "Epoch 122/200, Iteration 144/250, Loss: 0.0075\n",
      "Epoch 122/200, Iteration 145/250, Loss: 0.0066\n",
      "Epoch 122/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 122/200, Iteration 147/250, Loss: 0.0211\n",
      "Epoch 122/200, Iteration 148/250, Loss: 0.0098\n",
      "Epoch 122/200, Iteration 149/250, Loss: 0.0164\n",
      "Epoch 122/200, Iteration 150/250, Loss: 0.0200\n",
      "Epoch 122/200, Iteration 151/250, Loss: 0.0369\n",
      "Epoch 122/200, Iteration 152/250, Loss: 0.0147\n",
      "Epoch 122/200, Iteration 153/250, Loss: 0.0076\n",
      "Epoch 122/200, Iteration 154/250, Loss: 0.0221\n",
      "Epoch 122/200, Iteration 155/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 156/250, Loss: 0.0167\n",
      "Epoch 122/200, Iteration 157/250, Loss: 0.0091\n",
      "Epoch 122/200, Iteration 158/250, Loss: 0.0308\n",
      "Epoch 122/200, Iteration 159/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 160/250, Loss: 0.0288\n",
      "Epoch 122/200, Iteration 161/250, Loss: 0.0112\n",
      "Epoch 122/200, Iteration 162/250, Loss: 0.0107\n",
      "Epoch 122/200, Iteration 163/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 164/250, Loss: 0.0522\n",
      "Epoch 122/200, Iteration 165/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 166/250, Loss: 0.0262\n",
      "Epoch 122/200, Iteration 167/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 168/250, Loss: 0.0103\n",
      "Epoch 122/200, Iteration 169/250, Loss: 0.0116\n",
      "Epoch 122/200, Iteration 170/250, Loss: 0.0297\n",
      "Epoch 122/200, Iteration 171/250, Loss: 0.0226\n",
      "Epoch 122/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 122/200, Iteration 173/250, Loss: 0.0082\n",
      "Epoch 122/200, Iteration 174/250, Loss: 0.0255\n",
      "Epoch 122/200, Iteration 175/250, Loss: 0.0305\n",
      "Epoch 122/200, Iteration 176/250, Loss: 0.0357\n",
      "Epoch 122/200, Iteration 177/250, Loss: 0.0141\n",
      "Epoch 122/200, Iteration 178/250, Loss: 0.0117\n",
      "Epoch 122/200, Iteration 179/250, Loss: 0.0240\n",
      "Epoch 122/200, Iteration 180/250, Loss: 0.0128\n",
      "Epoch 122/200, Iteration 181/250, Loss: 0.0138\n",
      "Epoch 122/200, Iteration 182/250, Loss: 0.0210\n",
      "Epoch 122/200, Iteration 183/250, Loss: 0.0128\n",
      "Epoch 122/200, Iteration 184/250, Loss: 0.0221\n",
      "Epoch 122/200, Iteration 185/250, Loss: 0.0074\n",
      "Epoch 122/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 187/250, Loss: 0.0074\n",
      "Epoch 122/200, Iteration 188/250, Loss: 0.0184\n",
      "Epoch 122/200, Iteration 189/250, Loss: 0.0134\n",
      "Epoch 122/200, Iteration 190/250, Loss: 0.0099\n",
      "Epoch 122/200, Iteration 191/250, Loss: 0.0353\n",
      "Epoch 122/200, Iteration 192/250, Loss: 0.0122\n",
      "Epoch 122/200, Iteration 193/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 194/250, Loss: 0.0096\n",
      "Epoch 122/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 122/200, Iteration 196/250, Loss: 0.0166\n",
      "Epoch 122/200, Iteration 197/250, Loss: 0.0121\n",
      "Epoch 122/200, Iteration 198/250, Loss: 0.0116\n",
      "Epoch 122/200, Iteration 199/250, Loss: 0.0197\n",
      "Epoch 122/200, Iteration 200/250, Loss: 0.0119\n",
      "Epoch 122/200, Iteration 201/250, Loss: 0.0245\n",
      "Epoch 122/200, Iteration 202/250, Loss: 0.0145\n",
      "Epoch 122/200, Iteration 203/250, Loss: 0.0063\n",
      "Epoch 122/200, Iteration 204/250, Loss: 0.0106\n",
      "Epoch 122/200, Iteration 205/250, Loss: 0.0175\n",
      "Epoch 122/200, Iteration 206/250, Loss: 0.0104\n",
      "Epoch 122/200, Iteration 207/250, Loss: 0.0077\n",
      "Epoch 122/200, Iteration 208/250, Loss: 0.0181\n",
      "Epoch 122/200, Iteration 209/250, Loss: 0.0101\n",
      "Epoch 122/200, Iteration 210/250, Loss: 0.0111\n",
      "Epoch 122/200, Iteration 211/250, Loss: 0.0155\n",
      "Epoch 122/200, Iteration 212/250, Loss: 0.0085\n",
      "Epoch 122/200, Iteration 213/250, Loss: 0.0127\n",
      "Epoch 122/200, Iteration 214/250, Loss: 0.0179\n",
      "Epoch 122/200, Iteration 215/250, Loss: 0.0078\n",
      "Epoch 122/200, Iteration 216/250, Loss: 0.0140\n",
      "Epoch 122/200, Iteration 217/250, Loss: 0.0232\n",
      "Epoch 122/200, Iteration 218/250, Loss: 0.0086\n",
      "Epoch 122/200, Iteration 219/250, Loss: 0.0238\n",
      "Epoch 122/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 122/200, Iteration 221/250, Loss: 0.0145\n",
      "Epoch 122/200, Iteration 222/250, Loss: 0.0156\n",
      "Epoch 122/200, Iteration 223/250, Loss: 0.0125\n",
      "Epoch 122/200, Iteration 224/250, Loss: 0.0105\n",
      "Epoch 122/200, Iteration 225/250, Loss: 0.0196\n",
      "Epoch 122/200, Iteration 226/250, Loss: 0.0094\n",
      "Epoch 122/200, Iteration 227/250, Loss: 0.0210\n",
      "Epoch 122/200, Iteration 228/250, Loss: 0.0137\n",
      "Epoch 122/200, Iteration 229/250, Loss: 0.0084\n",
      "Epoch 122/200, Iteration 230/250, Loss: 0.0073\n",
      "Epoch 122/200, Iteration 231/250, Loss: 0.0110\n",
      "Epoch 122/200, Iteration 232/250, Loss: 0.0088\n",
      "Epoch 122/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 122/200, Iteration 234/250, Loss: 0.0146\n",
      "Epoch 122/200, Iteration 235/250, Loss: 0.0241\n",
      "Epoch 122/200, Iteration 236/250, Loss: 0.0130\n",
      "Epoch 122/200, Iteration 237/250, Loss: 0.0214\n",
      "Epoch 122/200, Iteration 238/250, Loss: 0.0165\n",
      "Epoch 122/200, Iteration 239/250, Loss: 0.0279\n",
      "Epoch 122/200, Iteration 240/250, Loss: 0.0102\n",
      "Epoch 122/200, Iteration 241/250, Loss: 0.0222\n",
      "Epoch 122/200, Iteration 242/250, Loss: 0.0149\n",
      "Epoch 122/200, Iteration 243/250, Loss: 0.0115\n",
      "Epoch 122/200, Iteration 244/250, Loss: 0.0153\n",
      "Epoch 122/200, Iteration 245/250, Loss: 0.0210\n",
      "Epoch 122/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 122/200, Iteration 247/250, Loss: 0.0175\n",
      "Epoch 122/200, Iteration 248/250, Loss: 0.0178\n",
      "Epoch 122/200, Iteration 249/250, Loss: 0.0201\n",
      "Epoch 122/200, Iteration 250/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.39%, Avg loss: 0.006708, MRE: 0.470271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.007387, MRE: 0.558958 \n",
      "\n",
      "Epoch 123/200, Iteration 1/250, Loss: 0.0172\n",
      "Epoch 123/200, Iteration 2/250, Loss: 0.0143\n",
      "Epoch 123/200, Iteration 3/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 123/200, Iteration 5/250, Loss: 0.0334\n",
      "Epoch 123/200, Iteration 6/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 7/250, Loss: 0.0315\n",
      "Epoch 123/200, Iteration 8/250, Loss: 0.0252\n",
      "Epoch 123/200, Iteration 9/250, Loss: 0.0184\n",
      "Epoch 123/200, Iteration 10/250, Loss: 0.0135\n",
      "Epoch 123/200, Iteration 11/250, Loss: 0.0165\n",
      "Epoch 123/200, Iteration 12/250, Loss: 0.0207\n",
      "Epoch 123/200, Iteration 13/250, Loss: 0.0236\n",
      "Epoch 123/200, Iteration 14/250, Loss: 0.0045\n",
      "Epoch 123/200, Iteration 15/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 16/250, Loss: 0.0122\n",
      "Epoch 123/200, Iteration 17/250, Loss: 0.0203\n",
      "Epoch 123/200, Iteration 18/250, Loss: 0.0149\n",
      "Epoch 123/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 123/200, Iteration 20/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 21/250, Loss: 0.0164\n",
      "Epoch 123/200, Iteration 22/250, Loss: 0.0169\n",
      "Epoch 123/200, Iteration 23/250, Loss: 0.0095\n",
      "Epoch 123/200, Iteration 24/250, Loss: 0.0285\n",
      "Epoch 123/200, Iteration 25/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 26/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 27/250, Loss: 0.0173\n",
      "Epoch 123/200, Iteration 28/250, Loss: 0.0092\n",
      "Epoch 123/200, Iteration 29/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 30/250, Loss: 0.0088\n",
      "Epoch 123/200, Iteration 31/250, Loss: 0.0134\n",
      "Epoch 123/200, Iteration 32/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 33/250, Loss: 0.0144\n",
      "Epoch 123/200, Iteration 34/250, Loss: 0.0314\n",
      "Epoch 123/200, Iteration 35/250, Loss: 0.0090\n",
      "Epoch 123/200, Iteration 36/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 37/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 38/250, Loss: 0.0183\n",
      "Epoch 123/200, Iteration 39/250, Loss: 0.0162\n",
      "Epoch 123/200, Iteration 40/250, Loss: 0.0091\n",
      "Epoch 123/200, Iteration 41/250, Loss: 0.0098\n",
      "Epoch 123/200, Iteration 42/250, Loss: 0.0158\n",
      "Epoch 123/200, Iteration 43/250, Loss: 0.0079\n",
      "Epoch 123/200, Iteration 44/250, Loss: 0.0336\n",
      "Epoch 123/200, Iteration 45/250, Loss: 0.0138\n",
      "Epoch 123/200, Iteration 46/250, Loss: 0.0125\n",
      "Epoch 123/200, Iteration 47/250, Loss: 0.0169\n",
      "Epoch 123/200, Iteration 48/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 49/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 50/250, Loss: 0.0237\n",
      "Epoch 123/200, Iteration 51/250, Loss: 0.0091\n",
      "Epoch 123/200, Iteration 52/250, Loss: 0.0135\n",
      "Epoch 123/200, Iteration 53/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 54/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 55/250, Loss: 0.0114\n",
      "Epoch 123/200, Iteration 56/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 57/250, Loss: 0.0092\n",
      "Epoch 123/200, Iteration 58/250, Loss: 0.0208\n",
      "Epoch 123/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 123/200, Iteration 60/250, Loss: 0.0117\n",
      "Epoch 123/200, Iteration 61/250, Loss: 0.0085\n",
      "Epoch 123/200, Iteration 62/250, Loss: 0.0130\n",
      "Epoch 123/200, Iteration 63/250, Loss: 0.0201\n",
      "Epoch 123/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 65/250, Loss: 0.0198\n",
      "Epoch 123/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 123/200, Iteration 67/250, Loss: 0.0181\n",
      "Epoch 123/200, Iteration 68/250, Loss: 0.0082\n",
      "Epoch 123/200, Iteration 69/250, Loss: 0.0267\n",
      "Epoch 123/200, Iteration 70/250, Loss: 0.0157\n",
      "Epoch 123/200, Iteration 71/250, Loss: 0.0190\n",
      "Epoch 123/200, Iteration 72/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 73/250, Loss: 0.0147\n",
      "Epoch 123/200, Iteration 74/250, Loss: 0.0207\n",
      "Epoch 123/200, Iteration 75/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 76/250, Loss: 0.0145\n",
      "Epoch 123/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 123/200, Iteration 78/250, Loss: 0.0217\n",
      "Epoch 123/200, Iteration 79/250, Loss: 0.0101\n",
      "Epoch 123/200, Iteration 80/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 123/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 123/200, Iteration 83/250, Loss: 0.0368\n",
      "Epoch 123/200, Iteration 84/250, Loss: 0.0173\n",
      "Epoch 123/200, Iteration 85/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 86/250, Loss: 0.0157\n",
      "Epoch 123/200, Iteration 87/250, Loss: 0.0124\n",
      "Epoch 123/200, Iteration 88/250, Loss: 0.0311\n",
      "Epoch 123/200, Iteration 89/250, Loss: 0.0261\n",
      "Epoch 123/200, Iteration 90/250, Loss: 0.0123\n",
      "Epoch 123/200, Iteration 91/250, Loss: 0.0142\n",
      "Epoch 123/200, Iteration 92/250, Loss: 0.0176\n",
      "Epoch 123/200, Iteration 93/250, Loss: 0.0205\n",
      "Epoch 123/200, Iteration 94/250, Loss: 0.0259\n",
      "Epoch 123/200, Iteration 95/250, Loss: 0.0315\n",
      "Epoch 123/200, Iteration 96/250, Loss: 0.0110\n",
      "Epoch 123/200, Iteration 97/250, Loss: 0.0212\n",
      "Epoch 123/200, Iteration 98/250, Loss: 0.0101\n",
      "Epoch 123/200, Iteration 99/250, Loss: 0.0293\n",
      "Epoch 123/200, Iteration 100/250, Loss: 0.0091\n",
      "Epoch 123/200, Iteration 101/250, Loss: 0.0189\n",
      "Epoch 123/200, Iteration 102/250, Loss: 0.0121\n",
      "Epoch 123/200, Iteration 103/250, Loss: 0.0112\n",
      "Epoch 123/200, Iteration 104/250, Loss: 0.0057\n",
      "Epoch 123/200, Iteration 105/250, Loss: 0.0240\n",
      "Epoch 123/200, Iteration 106/250, Loss: 0.0183\n",
      "Epoch 123/200, Iteration 107/250, Loss: 0.0139\n",
      "Epoch 123/200, Iteration 108/250, Loss: 0.0206\n",
      "Epoch 123/200, Iteration 109/250, Loss: 0.0115\n",
      "Epoch 123/200, Iteration 110/250, Loss: 0.0163\n",
      "Epoch 123/200, Iteration 111/250, Loss: 0.0280\n",
      "Epoch 123/200, Iteration 112/250, Loss: 0.0184\n",
      "Epoch 123/200, Iteration 113/250, Loss: 0.0376\n",
      "Epoch 123/200, Iteration 114/250, Loss: 0.0053\n",
      "Epoch 123/200, Iteration 115/250, Loss: 0.0072\n",
      "Epoch 123/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 117/250, Loss: 0.0083\n",
      "Epoch 123/200, Iteration 118/250, Loss: 0.0076\n",
      "Epoch 123/200, Iteration 119/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 120/250, Loss: 0.0132\n",
      "Epoch 123/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 123/200, Iteration 122/250, Loss: 0.0499\n",
      "Epoch 123/200, Iteration 123/250, Loss: 0.0159\n",
      "Epoch 123/200, Iteration 124/250, Loss: 0.0104\n",
      "Epoch 123/200, Iteration 125/250, Loss: 0.0223\n",
      "Epoch 123/200, Iteration 126/250, Loss: 0.0158\n",
      "Epoch 123/200, Iteration 127/250, Loss: 0.0199\n",
      "Epoch 123/200, Iteration 128/250, Loss: 0.0192\n",
      "Epoch 123/200, Iteration 129/250, Loss: 0.0083\n",
      "Epoch 123/200, Iteration 130/250, Loss: 0.0137\n",
      "Epoch 123/200, Iteration 131/250, Loss: 0.0216\n",
      "Epoch 123/200, Iteration 132/250, Loss: 0.0164\n",
      "Epoch 123/200, Iteration 133/250, Loss: 0.0224\n",
      "Epoch 123/200, Iteration 134/250, Loss: 0.0363\n",
      "Epoch 123/200, Iteration 135/250, Loss: 0.0374\n",
      "Epoch 123/200, Iteration 136/250, Loss: 0.0149\n",
      "Epoch 123/200, Iteration 137/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 138/250, Loss: 0.0175\n",
      "Epoch 123/200, Iteration 139/250, Loss: 0.0118\n",
      "Epoch 123/200, Iteration 140/250, Loss: 0.0143\n",
      "Epoch 123/200, Iteration 141/250, Loss: 0.0168\n",
      "Epoch 123/200, Iteration 142/250, Loss: 0.0110\n",
      "Epoch 123/200, Iteration 143/250, Loss: 0.0123\n",
      "Epoch 123/200, Iteration 144/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 145/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 146/250, Loss: 0.0123\n",
      "Epoch 123/200, Iteration 147/250, Loss: 0.0412\n",
      "Epoch 123/200, Iteration 148/250, Loss: 0.0135\n",
      "Epoch 123/200, Iteration 149/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 150/250, Loss: 0.0317\n",
      "Epoch 123/200, Iteration 151/250, Loss: 0.0082\n",
      "Epoch 123/200, Iteration 152/250, Loss: 0.0081\n",
      "Epoch 123/200, Iteration 153/250, Loss: 0.0096\n",
      "Epoch 123/200, Iteration 154/250, Loss: 0.0181\n",
      "Epoch 123/200, Iteration 155/250, Loss: 0.0099\n",
      "Epoch 123/200, Iteration 156/250, Loss: 0.0130\n",
      "Epoch 123/200, Iteration 157/250, Loss: 0.0159\n",
      "Epoch 123/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 123/200, Iteration 159/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 160/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 161/250, Loss: 0.0193\n",
      "Epoch 123/200, Iteration 162/250, Loss: 0.0153\n",
      "Epoch 123/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 123/200, Iteration 164/250, Loss: 0.0155\n",
      "Epoch 123/200, Iteration 165/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 166/250, Loss: 0.0107\n",
      "Epoch 123/200, Iteration 167/250, Loss: 0.0148\n",
      "Epoch 123/200, Iteration 168/250, Loss: 0.0186\n",
      "Epoch 123/200, Iteration 169/250, Loss: 0.0230\n",
      "Epoch 123/200, Iteration 170/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 171/250, Loss: 0.0133\n",
      "Epoch 123/200, Iteration 172/250, Loss: 0.0140\n",
      "Epoch 123/200, Iteration 173/250, Loss: 0.0269\n",
      "Epoch 123/200, Iteration 174/250, Loss: 0.0081\n",
      "Epoch 123/200, Iteration 175/250, Loss: 0.0200\n",
      "Epoch 123/200, Iteration 176/250, Loss: 0.0100\n",
      "Epoch 123/200, Iteration 177/250, Loss: 0.0073\n",
      "Epoch 123/200, Iteration 178/250, Loss: 0.0131\n",
      "Epoch 123/200, Iteration 179/250, Loss: 0.0076\n",
      "Epoch 123/200, Iteration 180/250, Loss: 0.0319\n",
      "Epoch 123/200, Iteration 181/250, Loss: 0.0087\n",
      "Epoch 123/200, Iteration 182/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 183/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 184/250, Loss: 0.0316\n",
      "Epoch 123/200, Iteration 185/250, Loss: 0.0387\n",
      "Epoch 123/200, Iteration 186/250, Loss: 0.0104\n",
      "Epoch 123/200, Iteration 187/250, Loss: 0.0145\n",
      "Epoch 123/200, Iteration 188/250, Loss: 0.0253\n",
      "Epoch 123/200, Iteration 189/250, Loss: 0.0126\n",
      "Epoch 123/200, Iteration 190/250, Loss: 0.0180\n",
      "Epoch 123/200, Iteration 191/250, Loss: 0.0124\n",
      "Epoch 123/200, Iteration 192/250, Loss: 0.0084\n",
      "Epoch 123/200, Iteration 193/250, Loss: 0.0248\n",
      "Epoch 123/200, Iteration 194/250, Loss: 0.0423\n",
      "Epoch 123/200, Iteration 195/250, Loss: 0.0091\n",
      "Epoch 123/200, Iteration 196/250, Loss: 0.0269\n",
      "Epoch 123/200, Iteration 197/250, Loss: 0.0142\n",
      "Epoch 123/200, Iteration 198/250, Loss: 0.0133\n",
      "Epoch 123/200, Iteration 199/250, Loss: 0.0085\n",
      "Epoch 123/200, Iteration 200/250, Loss: 0.0075\n",
      "Epoch 123/200, Iteration 201/250, Loss: 0.0145\n",
      "Epoch 123/200, Iteration 202/250, Loss: 0.0089\n",
      "Epoch 123/200, Iteration 203/250, Loss: 0.0127\n",
      "Epoch 123/200, Iteration 204/250, Loss: 0.0321\n",
      "Epoch 123/200, Iteration 205/250, Loss: 0.0273\n",
      "Epoch 123/200, Iteration 206/250, Loss: 0.0099\n",
      "Epoch 123/200, Iteration 207/250, Loss: 0.0097\n",
      "Epoch 123/200, Iteration 208/250, Loss: 0.0075\n",
      "Epoch 123/200, Iteration 209/250, Loss: 0.0119\n",
      "Epoch 123/200, Iteration 210/250, Loss: 0.0205\n",
      "Epoch 123/200, Iteration 211/250, Loss: 0.0173\n",
      "Epoch 123/200, Iteration 212/250, Loss: 0.0102\n",
      "Epoch 123/200, Iteration 213/250, Loss: 0.0133\n",
      "Epoch 123/200, Iteration 214/250, Loss: 0.0070\n",
      "Epoch 123/200, Iteration 215/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200, Iteration 216/250, Loss: 0.0082\n",
      "Epoch 123/200, Iteration 217/250, Loss: 0.0069\n",
      "Epoch 123/200, Iteration 218/250, Loss: 0.0192\n",
      "Epoch 123/200, Iteration 219/250, Loss: 0.0193\n",
      "Epoch 123/200, Iteration 220/250, Loss: 0.0265\n",
      "Epoch 123/200, Iteration 221/250, Loss: 0.0141\n",
      "Epoch 123/200, Iteration 222/250, Loss: 0.0080\n",
      "Epoch 123/200, Iteration 223/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 224/250, Loss: 0.0363\n",
      "Epoch 123/200, Iteration 225/250, Loss: 0.0266\n",
      "Epoch 123/200, Iteration 226/250, Loss: 0.0148\n",
      "Epoch 123/200, Iteration 227/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 228/250, Loss: 0.0134\n",
      "Epoch 123/200, Iteration 229/250, Loss: 0.0108\n",
      "Epoch 123/200, Iteration 230/250, Loss: 0.0113\n",
      "Epoch 123/200, Iteration 231/250, Loss: 0.0159\n",
      "Epoch 123/200, Iteration 232/250, Loss: 0.0085\n",
      "Epoch 123/200, Iteration 233/250, Loss: 0.0227\n",
      "Epoch 123/200, Iteration 234/250, Loss: 0.0213\n",
      "Epoch 123/200, Iteration 235/250, Loss: 0.0094\n",
      "Epoch 123/200, Iteration 236/250, Loss: 0.0101\n",
      "Epoch 123/200, Iteration 237/250, Loss: 0.0152\n",
      "Epoch 123/200, Iteration 238/250, Loss: 0.0157\n",
      "Epoch 123/200, Iteration 239/250, Loss: 0.0123\n",
      "Epoch 123/200, Iteration 240/250, Loss: 0.0208\n",
      "Epoch 123/200, Iteration 241/250, Loss: 0.0119\n",
      "Epoch 123/200, Iteration 242/250, Loss: 0.0206\n",
      "Epoch 123/200, Iteration 243/250, Loss: 0.0136\n",
      "Epoch 123/200, Iteration 244/250, Loss: 0.0139\n",
      "Epoch 123/200, Iteration 245/250, Loss: 0.0075\n",
      "Epoch 123/200, Iteration 246/250, Loss: 0.0076\n",
      "Epoch 123/200, Iteration 247/250, Loss: 0.0161\n",
      "Epoch 123/200, Iteration 248/250, Loss: 0.0164\n",
      "Epoch 123/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 123/200, Iteration 250/250, Loss: 0.0124\n",
      "Train Error: \n",
      " Accuracy: 90.94%, Avg loss: 0.006672, MRE: 0.483002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.05%, Avg loss: 0.007352, MRE: 0.584892 \n",
      "\n",
      "Epoch 124/200, Iteration 1/250, Loss: 0.0073\n",
      "Epoch 124/200, Iteration 2/250, Loss: 0.0152\n",
      "Epoch 124/200, Iteration 3/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 4/250, Loss: 0.0129\n",
      "Epoch 124/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 124/200, Iteration 6/250, Loss: 0.0076\n",
      "Epoch 124/200, Iteration 7/250, Loss: 0.0164\n",
      "Epoch 124/200, Iteration 8/250, Loss: 0.0194\n",
      "Epoch 124/200, Iteration 9/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 10/250, Loss: 0.0126\n",
      "Epoch 124/200, Iteration 11/250, Loss: 0.0206\n",
      "Epoch 124/200, Iteration 12/250, Loss: 0.0107\n",
      "Epoch 124/200, Iteration 13/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 14/250, Loss: 0.0334\n",
      "Epoch 124/200, Iteration 15/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 16/250, Loss: 0.0235\n",
      "Epoch 124/200, Iteration 17/250, Loss: 0.0316\n",
      "Epoch 124/200, Iteration 18/250, Loss: 0.0160\n",
      "Epoch 124/200, Iteration 19/250, Loss: 0.0194\n",
      "Epoch 124/200, Iteration 20/250, Loss: 0.0242\n",
      "Epoch 124/200, Iteration 21/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 22/250, Loss: 0.0099\n",
      "Epoch 124/200, Iteration 23/250, Loss: 0.0263\n",
      "Epoch 124/200, Iteration 24/250, Loss: 0.0136\n",
      "Epoch 124/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 124/200, Iteration 26/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 27/250, Loss: 0.0112\n",
      "Epoch 124/200, Iteration 28/250, Loss: 0.0147\n",
      "Epoch 124/200, Iteration 29/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 30/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 31/250, Loss: 0.0158\n",
      "Epoch 124/200, Iteration 32/250, Loss: 0.0122\n",
      "Epoch 124/200, Iteration 33/250, Loss: 0.0074\n",
      "Epoch 124/200, Iteration 34/250, Loss: 0.0125\n",
      "Epoch 124/200, Iteration 35/250, Loss: 0.0207\n",
      "Epoch 124/200, Iteration 36/250, Loss: 0.0138\n",
      "Epoch 124/200, Iteration 37/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 38/250, Loss: 0.0145\n",
      "Epoch 124/200, Iteration 39/250, Loss: 0.0064\n",
      "Epoch 124/200, Iteration 40/250, Loss: 0.0160\n",
      "Epoch 124/200, Iteration 41/250, Loss: 0.0105\n",
      "Epoch 124/200, Iteration 42/250, Loss: 0.0099\n",
      "Epoch 124/200, Iteration 43/250, Loss: 0.0084\n",
      "Epoch 124/200, Iteration 44/250, Loss: 0.0138\n",
      "Epoch 124/200, Iteration 45/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 46/250, Loss: 0.0105\n",
      "Epoch 124/200, Iteration 47/250, Loss: 0.0079\n",
      "Epoch 124/200, Iteration 48/250, Loss: 0.0252\n",
      "Epoch 124/200, Iteration 49/250, Loss: 0.0211\n",
      "Epoch 124/200, Iteration 50/250, Loss: 0.0093\n",
      "Epoch 124/200, Iteration 51/250, Loss: 0.0093\n",
      "Epoch 124/200, Iteration 52/250, Loss: 0.0149\n",
      "Epoch 124/200, Iteration 53/250, Loss: 0.0222\n",
      "Epoch 124/200, Iteration 54/250, Loss: 0.0074\n",
      "Epoch 124/200, Iteration 55/250, Loss: 0.0180\n",
      "Epoch 124/200, Iteration 56/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 57/250, Loss: 0.0071\n",
      "Epoch 124/200, Iteration 58/250, Loss: 0.0431\n",
      "Epoch 124/200, Iteration 59/250, Loss: 0.0176\n",
      "Epoch 124/200, Iteration 60/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 61/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 62/250, Loss: 0.0153\n",
      "Epoch 124/200, Iteration 63/250, Loss: 0.0173\n",
      "Epoch 124/200, Iteration 64/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 65/250, Loss: 0.0108\n",
      "Epoch 124/200, Iteration 66/250, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 67/250, Loss: 0.0337\n",
      "Epoch 124/200, Iteration 68/250, Loss: 0.0253\n",
      "Epoch 124/200, Iteration 69/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 70/250, Loss: 0.0120\n",
      "Epoch 124/200, Iteration 71/250, Loss: 0.0225\n",
      "Epoch 124/200, Iteration 72/250, Loss: 0.0083\n",
      "Epoch 124/200, Iteration 73/250, Loss: 0.0071\n",
      "Epoch 124/200, Iteration 74/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 75/250, Loss: 0.0198\n",
      "Epoch 124/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 77/250, Loss: 0.0260\n",
      "Epoch 124/200, Iteration 78/250, Loss: 0.0268\n",
      "Epoch 124/200, Iteration 79/250, Loss: 0.0182\n",
      "Epoch 124/200, Iteration 80/250, Loss: 0.0440\n",
      "Epoch 124/200, Iteration 81/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 82/250, Loss: 0.0173\n",
      "Epoch 124/200, Iteration 83/250, Loss: 0.0082\n",
      "Epoch 124/200, Iteration 84/250, Loss: 0.0152\n",
      "Epoch 124/200, Iteration 85/250, Loss: 0.0067\n",
      "Epoch 124/200, Iteration 86/250, Loss: 0.0170\n",
      "Epoch 124/200, Iteration 87/250, Loss: 0.0261\n",
      "Epoch 124/200, Iteration 88/250, Loss: 0.0064\n",
      "Epoch 124/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 90/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 91/250, Loss: 0.0162\n",
      "Epoch 124/200, Iteration 92/250, Loss: 0.0340\n",
      "Epoch 124/200, Iteration 93/250, Loss: 0.0215\n",
      "Epoch 124/200, Iteration 94/250, Loss: 0.0071\n",
      "Epoch 124/200, Iteration 95/250, Loss: 0.0191\n",
      "Epoch 124/200, Iteration 96/250, Loss: 0.0125\n",
      "Epoch 124/200, Iteration 97/250, Loss: 0.0116\n",
      "Epoch 124/200, Iteration 98/250, Loss: 0.0084\n",
      "Epoch 124/200, Iteration 99/250, Loss: 0.0132\n",
      "Epoch 124/200, Iteration 100/250, Loss: 0.0101\n",
      "Epoch 124/200, Iteration 101/250, Loss: 0.0127\n",
      "Epoch 124/200, Iteration 102/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 103/250, Loss: 0.0083\n",
      "Epoch 124/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 105/250, Loss: 0.0089\n",
      "Epoch 124/200, Iteration 106/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 107/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 108/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 109/250, Loss: 0.0182\n",
      "Epoch 124/200, Iteration 110/250, Loss: 0.0412\n",
      "Epoch 124/200, Iteration 111/250, Loss: 0.0120\n",
      "Epoch 124/200, Iteration 112/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 113/250, Loss: 0.0068\n",
      "Epoch 124/200, Iteration 114/250, Loss: 0.0160\n",
      "Epoch 124/200, Iteration 115/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 116/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 117/250, Loss: 0.0130\n",
      "Epoch 124/200, Iteration 118/250, Loss: 0.0157\n",
      "Epoch 124/200, Iteration 119/250, Loss: 0.0223\n",
      "Epoch 124/200, Iteration 120/250, Loss: 0.0150\n",
      "Epoch 124/200, Iteration 121/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 122/250, Loss: 0.0098\n",
      "Epoch 124/200, Iteration 123/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 124/250, Loss: 0.0319\n",
      "Epoch 124/200, Iteration 125/250, Loss: 0.0247\n",
      "Epoch 124/200, Iteration 126/250, Loss: 0.0188\n",
      "Epoch 124/200, Iteration 127/250, Loss: 0.0061\n",
      "Epoch 124/200, Iteration 128/250, Loss: 0.0104\n",
      "Epoch 124/200, Iteration 129/250, Loss: 0.0096\n",
      "Epoch 124/200, Iteration 130/250, Loss: 0.0112\n",
      "Epoch 124/200, Iteration 131/250, Loss: 0.0100\n",
      "Epoch 124/200, Iteration 132/250, Loss: 0.0104\n",
      "Epoch 124/200, Iteration 133/250, Loss: 0.0169\n",
      "Epoch 124/200, Iteration 134/250, Loss: 0.0213\n",
      "Epoch 124/200, Iteration 135/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 136/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 137/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 138/250, Loss: 0.0105\n",
      "Epoch 124/200, Iteration 139/250, Loss: 0.0086\n",
      "Epoch 124/200, Iteration 140/250, Loss: 0.0101\n",
      "Epoch 124/200, Iteration 141/250, Loss: 0.0104\n",
      "Epoch 124/200, Iteration 142/250, Loss: 0.0136\n",
      "Epoch 124/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 144/250, Loss: 0.0225\n",
      "Epoch 124/200, Iteration 145/250, Loss: 0.0114\n",
      "Epoch 124/200, Iteration 146/250, Loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200, Iteration 147/250, Loss: 0.0114\n",
      "Epoch 124/200, Iteration 148/250, Loss: 0.0111\n",
      "Epoch 124/200, Iteration 149/250, Loss: 0.0154\n",
      "Epoch 124/200, Iteration 150/250, Loss: 0.0097\n",
      "Epoch 124/200, Iteration 151/250, Loss: 0.0258\n",
      "Epoch 124/200, Iteration 152/250, Loss: 0.0124\n",
      "Epoch 124/200, Iteration 153/250, Loss: 0.0132\n",
      "Epoch 124/200, Iteration 154/250, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 155/250, Loss: 0.0179\n",
      "Epoch 124/200, Iteration 156/250, Loss: 0.0081\n",
      "Epoch 124/200, Iteration 157/250, Loss: 0.0249\n",
      "Epoch 124/200, Iteration 158/250, Loss: 0.0165\n",
      "Epoch 124/200, Iteration 159/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 160/250, Loss: 0.0085\n",
      "Epoch 124/200, Iteration 161/250, Loss: 0.0246\n",
      "Epoch 124/200, Iteration 162/250, Loss: 0.0284\n",
      "Epoch 124/200, Iteration 163/250, Loss: 0.0070\n",
      "Epoch 124/200, Iteration 164/250, Loss: 0.0066\n",
      "Epoch 124/200, Iteration 165/250, Loss: 0.0139\n",
      "Epoch 124/200, Iteration 166/250, Loss: 0.0252\n",
      "Epoch 124/200, Iteration 167/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 168/250, Loss: 0.0130\n",
      "Epoch 124/200, Iteration 169/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 170/250, Loss: 0.0209\n",
      "Epoch 124/200, Iteration 171/250, Loss: 0.0121\n",
      "Epoch 124/200, Iteration 172/250, Loss: 0.0122\n",
      "Epoch 124/200, Iteration 173/250, Loss: 0.0074\n",
      "Epoch 124/200, Iteration 174/250, Loss: 0.0134\n",
      "Epoch 124/200, Iteration 175/250, Loss: 0.0273\n",
      "Epoch 124/200, Iteration 176/250, Loss: 0.0085\n",
      "Epoch 124/200, Iteration 177/250, Loss: 0.0140\n",
      "Epoch 124/200, Iteration 178/250, Loss: 0.0121\n",
      "Epoch 124/200, Iteration 179/250, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 180/250, Loss: 0.0187\n",
      "Epoch 124/200, Iteration 181/250, Loss: 0.0269\n",
      "Epoch 124/200, Iteration 182/250, Loss: 0.0287\n",
      "Epoch 124/200, Iteration 183/250, Loss: 0.0069\n",
      "Epoch 124/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 124/200, Iteration 185/250, Loss: 0.0119\n",
      "Epoch 124/200, Iteration 186/250, Loss: 0.0466\n",
      "Epoch 124/200, Iteration 187/250, Loss: 0.0117\n",
      "Epoch 124/200, Iteration 188/250, Loss: 0.0140\n",
      "Epoch 124/200, Iteration 189/250, Loss: 0.0142\n",
      "Epoch 124/200, Iteration 190/250, Loss: 0.0098\n",
      "Epoch 124/200, Iteration 191/250, Loss: 0.0209\n",
      "Epoch 124/200, Iteration 192/250, Loss: 0.0113\n",
      "Epoch 124/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 124/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 195/250, Loss: 0.0260\n",
      "Epoch 124/200, Iteration 196/250, Loss: 0.0084\n",
      "Epoch 124/200, Iteration 197/250, Loss: 0.0142\n",
      "Epoch 124/200, Iteration 198/250, Loss: 0.0221\n",
      "Epoch 124/200, Iteration 199/250, Loss: 0.0095\n",
      "Epoch 124/200, Iteration 200/250, Loss: 0.0091\n",
      "Epoch 124/200, Iteration 201/250, Loss: 0.0230\n",
      "Epoch 124/200, Iteration 202/250, Loss: 0.0224\n",
      "Epoch 124/200, Iteration 203/250, Loss: 0.0195\n",
      "Epoch 124/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 205/250, Loss: 0.0429\n",
      "Epoch 124/200, Iteration 206/250, Loss: 0.0087\n",
      "Epoch 124/200, Iteration 207/250, Loss: 0.0231\n",
      "Epoch 124/200, Iteration 208/250, Loss: 0.0275\n",
      "Epoch 124/200, Iteration 209/250, Loss: 0.0186\n",
      "Epoch 124/200, Iteration 210/250, Loss: 0.0077\n",
      "Epoch 124/200, Iteration 211/250, Loss: 0.0301\n",
      "Epoch 124/200, Iteration 212/250, Loss: 0.0223\n",
      "Epoch 124/200, Iteration 213/250, Loss: 0.0448\n",
      "Epoch 124/200, Iteration 214/250, Loss: 0.0089\n",
      "Epoch 124/200, Iteration 215/250, Loss: 0.0137\n",
      "Epoch 124/200, Iteration 216/250, Loss: 0.0144\n",
      "Epoch 124/200, Iteration 217/250, Loss: 0.0076\n",
      "Epoch 124/200, Iteration 218/250, Loss: 0.0125\n",
      "Epoch 124/200, Iteration 219/250, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 220/250, Loss: 0.0127\n",
      "Epoch 124/200, Iteration 221/250, Loss: 0.0188\n",
      "Epoch 124/200, Iteration 222/250, Loss: 0.0289\n",
      "Epoch 124/200, Iteration 223/250, Loss: 0.0173\n",
      "Epoch 124/200, Iteration 224/250, Loss: 0.0216\n",
      "Epoch 124/200, Iteration 225/250, Loss: 0.0239\n",
      "Epoch 124/200, Iteration 226/250, Loss: 0.0252\n",
      "Epoch 124/200, Iteration 227/250, Loss: 0.0345\n",
      "Epoch 124/200, Iteration 228/250, Loss: 0.0106\n",
      "Epoch 124/200, Iteration 229/250, Loss: 0.0140\n",
      "Epoch 124/200, Iteration 230/250, Loss: 0.0136\n",
      "Epoch 124/200, Iteration 231/250, Loss: 0.0144\n",
      "Epoch 124/200, Iteration 232/250, Loss: 0.0094\n",
      "Epoch 124/200, Iteration 233/250, Loss: 0.0168\n",
      "Epoch 124/200, Iteration 234/250, Loss: 0.0393\n",
      "Epoch 124/200, Iteration 235/250, Loss: 0.0363\n",
      "Epoch 124/200, Iteration 236/250, Loss: 0.0210\n",
      "Epoch 124/200, Iteration 237/250, Loss: 0.0166\n",
      "Epoch 124/200, Iteration 238/250, Loss: 0.0071\n",
      "Epoch 124/200, Iteration 239/250, Loss: 0.0087\n",
      "Epoch 124/200, Iteration 240/250, Loss: 0.0102\n",
      "Epoch 124/200, Iteration 241/250, Loss: 0.0215\n",
      "Epoch 124/200, Iteration 242/250, Loss: 0.0077\n",
      "Epoch 124/200, Iteration 243/250, Loss: 0.0092\n",
      "Epoch 124/200, Iteration 244/250, Loss: 0.0134\n",
      "Epoch 124/200, Iteration 245/250, Loss: 0.0194\n",
      "Epoch 124/200, Iteration 246/250, Loss: 0.0090\n",
      "Epoch 124/200, Iteration 247/250, Loss: 0.0177\n",
      "Epoch 124/200, Iteration 248/250, Loss: 0.0224\n",
      "Epoch 124/200, Iteration 249/250, Loss: 0.0089\n",
      "Epoch 124/200, Iteration 250/250, Loss: 0.0087\n",
      "Train Error: \n",
      " Accuracy: 90.89%, Avg loss: 0.006726, MRE: 0.491450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.007292, MRE: 0.547205 \n",
      "\n",
      "Epoch 125/200, Iteration 1/250, Loss: 0.0158\n",
      "Epoch 125/200, Iteration 2/250, Loss: 0.0322\n",
      "Epoch 125/200, Iteration 3/250, Loss: 0.0136\n",
      "Epoch 125/200, Iteration 4/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 5/250, Loss: 0.0168\n",
      "Epoch 125/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 125/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 8/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 9/250, Loss: 0.0192\n",
      "Epoch 125/200, Iteration 10/250, Loss: 0.0218\n",
      "Epoch 125/200, Iteration 11/250, Loss: 0.0196\n",
      "Epoch 125/200, Iteration 12/250, Loss: 0.0195\n",
      "Epoch 125/200, Iteration 13/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 14/250, Loss: 0.0265\n",
      "Epoch 125/200, Iteration 15/250, Loss: 0.0142\n",
      "Epoch 125/200, Iteration 16/250, Loss: 0.0085\n",
      "Epoch 125/200, Iteration 17/250, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 18/250, Loss: 0.0074\n",
      "Epoch 125/200, Iteration 19/250, Loss: 0.0285\n",
      "Epoch 125/200, Iteration 20/250, Loss: 0.0326\n",
      "Epoch 125/200, Iteration 21/250, Loss: 0.0234\n",
      "Epoch 125/200, Iteration 22/250, Loss: 0.0095\n",
      "Epoch 125/200, Iteration 23/250, Loss: 0.0096\n",
      "Epoch 125/200, Iteration 24/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 25/250, Loss: 0.0071\n",
      "Epoch 125/200, Iteration 26/250, Loss: 0.0126\n",
      "Epoch 125/200, Iteration 27/250, Loss: 0.0085\n",
      "Epoch 125/200, Iteration 28/250, Loss: 0.0175\n",
      "Epoch 125/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 125/200, Iteration 30/250, Loss: 0.0117\n",
      "Epoch 125/200, Iteration 31/250, Loss: 0.0150\n",
      "Epoch 125/200, Iteration 32/250, Loss: 0.0186\n",
      "Epoch 125/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 34/250, Loss: 0.0166\n",
      "Epoch 125/200, Iteration 35/250, Loss: 0.0174\n",
      "Epoch 125/200, Iteration 36/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 37/250, Loss: 0.0159\n",
      "Epoch 125/200, Iteration 38/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 39/250, Loss: 0.0219\n",
      "Epoch 125/200, Iteration 40/250, Loss: 0.0211\n",
      "Epoch 125/200, Iteration 41/250, Loss: 0.0144\n",
      "Epoch 125/200, Iteration 42/250, Loss: 0.0165\n",
      "Epoch 125/200, Iteration 43/250, Loss: 0.0092\n",
      "Epoch 125/200, Iteration 44/250, Loss: 0.0083\n",
      "Epoch 125/200, Iteration 45/250, Loss: 0.0094\n",
      "Epoch 125/200, Iteration 46/250, Loss: 0.0083\n",
      "Epoch 125/200, Iteration 47/250, Loss: 0.0094\n",
      "Epoch 125/200, Iteration 48/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 49/250, Loss: 0.0174\n",
      "Epoch 125/200, Iteration 50/250, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 51/250, Loss: 0.0439\n",
      "Epoch 125/200, Iteration 52/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 53/250, Loss: 0.0116\n",
      "Epoch 125/200, Iteration 54/250, Loss: 0.0121\n",
      "Epoch 125/200, Iteration 55/250, Loss: 0.0188\n",
      "Epoch 125/200, Iteration 56/250, Loss: 0.0085\n",
      "Epoch 125/200, Iteration 57/250, Loss: 0.0338\n",
      "Epoch 125/200, Iteration 58/250, Loss: 0.0157\n",
      "Epoch 125/200, Iteration 59/250, Loss: 0.0185\n",
      "Epoch 125/200, Iteration 60/250, Loss: 0.0155\n",
      "Epoch 125/200, Iteration 61/250, Loss: 0.0247\n",
      "Epoch 125/200, Iteration 62/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 63/250, Loss: 0.0219\n",
      "Epoch 125/200, Iteration 64/250, Loss: 0.0250\n",
      "Epoch 125/200, Iteration 65/250, Loss: 0.0158\n",
      "Epoch 125/200, Iteration 66/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 67/250, Loss: 0.0136\n",
      "Epoch 125/200, Iteration 68/250, Loss: 0.0068\n",
      "Epoch 125/200, Iteration 69/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 70/250, Loss: 0.0116\n",
      "Epoch 125/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 125/200, Iteration 72/250, Loss: 0.0139\n",
      "Epoch 125/200, Iteration 73/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 74/250, Loss: 0.0260\n",
      "Epoch 125/200, Iteration 75/250, Loss: 0.0177\n",
      "Epoch 125/200, Iteration 76/250, Loss: 0.0212\n",
      "Epoch 125/200, Iteration 77/250, Loss: 0.0311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200, Iteration 78/250, Loss: 0.0181\n",
      "Epoch 125/200, Iteration 79/250, Loss: 0.0294\n",
      "Epoch 125/200, Iteration 80/250, Loss: 0.0228\n",
      "Epoch 125/200, Iteration 81/250, Loss: 0.0103\n",
      "Epoch 125/200, Iteration 82/250, Loss: 0.0245\n",
      "Epoch 125/200, Iteration 83/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 84/250, Loss: 0.0163\n",
      "Epoch 125/200, Iteration 85/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 86/250, Loss: 0.0122\n",
      "Epoch 125/200, Iteration 87/250, Loss: 0.0077\n",
      "Epoch 125/200, Iteration 88/250, Loss: 0.0180\n",
      "Epoch 125/200, Iteration 89/250, Loss: 0.0058\n",
      "Epoch 125/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 91/250, Loss: 0.0142\n",
      "Epoch 125/200, Iteration 92/250, Loss: 0.0144\n",
      "Epoch 125/200, Iteration 93/250, Loss: 0.0074\n",
      "Epoch 125/200, Iteration 94/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 95/250, Loss: 0.0142\n",
      "Epoch 125/200, Iteration 96/250, Loss: 0.0221\n",
      "Epoch 125/200, Iteration 97/250, Loss: 0.0185\n",
      "Epoch 125/200, Iteration 98/250, Loss: 0.0190\n",
      "Epoch 125/200, Iteration 99/250, Loss: 0.0383\n",
      "Epoch 125/200, Iteration 100/250, Loss: 0.0160\n",
      "Epoch 125/200, Iteration 101/250, Loss: 0.0369\n",
      "Epoch 125/200, Iteration 102/250, Loss: 0.0121\n",
      "Epoch 125/200, Iteration 103/250, Loss: 0.0276\n",
      "Epoch 125/200, Iteration 104/250, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 105/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 106/250, Loss: 0.0154\n",
      "Epoch 125/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 125/200, Iteration 108/250, Loss: 0.0325\n",
      "Epoch 125/200, Iteration 109/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 110/250, Loss: 0.0135\n",
      "Epoch 125/200, Iteration 111/250, Loss: 0.0065\n",
      "Epoch 125/200, Iteration 112/250, Loss: 0.0103\n",
      "Epoch 125/200, Iteration 113/250, Loss: 0.0210\n",
      "Epoch 125/200, Iteration 114/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 115/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 116/250, Loss: 0.0145\n",
      "Epoch 125/200, Iteration 117/250, Loss: 0.0144\n",
      "Epoch 125/200, Iteration 118/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 119/250, Loss: 0.0289\n",
      "Epoch 125/200, Iteration 120/250, Loss: 0.0160\n",
      "Epoch 125/200, Iteration 121/250, Loss: 0.0214\n",
      "Epoch 125/200, Iteration 122/250, Loss: 0.0134\n",
      "Epoch 125/200, Iteration 123/250, Loss: 0.0135\n",
      "Epoch 125/200, Iteration 124/250, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 125/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 126/250, Loss: 0.0141\n",
      "Epoch 125/200, Iteration 127/250, Loss: 0.0288\n",
      "Epoch 125/200, Iteration 128/250, Loss: 0.0132\n",
      "Epoch 125/200, Iteration 129/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 130/250, Loss: 0.0257\n",
      "Epoch 125/200, Iteration 131/250, Loss: 0.0198\n",
      "Epoch 125/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 133/250, Loss: 0.0079\n",
      "Epoch 125/200, Iteration 134/250, Loss: 0.0159\n",
      "Epoch 125/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 125/200, Iteration 136/250, Loss: 0.0108\n",
      "Epoch 125/200, Iteration 137/250, Loss: 0.0163\n",
      "Epoch 125/200, Iteration 138/250, Loss: 0.0292\n",
      "Epoch 125/200, Iteration 139/250, Loss: 0.0324\n",
      "Epoch 125/200, Iteration 140/250, Loss: 0.0243\n",
      "Epoch 125/200, Iteration 141/250, Loss: 0.0105\n",
      "Epoch 125/200, Iteration 142/250, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 125/200, Iteration 144/250, Loss: 0.0078\n",
      "Epoch 125/200, Iteration 145/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 146/250, Loss: 0.0165\n",
      "Epoch 125/200, Iteration 147/250, Loss: 0.0099\n",
      "Epoch 125/200, Iteration 148/250, Loss: 0.0119\n",
      "Epoch 125/200, Iteration 149/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 150/250, Loss: 0.0283\n",
      "Epoch 125/200, Iteration 151/250, Loss: 0.0208\n",
      "Epoch 125/200, Iteration 152/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 153/250, Loss: 0.0070\n",
      "Epoch 125/200, Iteration 154/250, Loss: 0.0110\n",
      "Epoch 125/200, Iteration 155/250, Loss: 0.0074\n",
      "Epoch 125/200, Iteration 156/250, Loss: 0.0222\n",
      "Epoch 125/200, Iteration 157/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 158/250, Loss: 0.0104\n",
      "Epoch 125/200, Iteration 159/250, Loss: 0.0107\n",
      "Epoch 125/200, Iteration 160/250, Loss: 0.0135\n",
      "Epoch 125/200, Iteration 161/250, Loss: 0.0113\n",
      "Epoch 125/200, Iteration 162/250, Loss: 0.0065\n",
      "Epoch 125/200, Iteration 163/250, Loss: 0.0121\n",
      "Epoch 125/200, Iteration 164/250, Loss: 0.0227\n",
      "Epoch 125/200, Iteration 165/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 166/250, Loss: 0.0145\n",
      "Epoch 125/200, Iteration 167/250, Loss: 0.0287\n",
      "Epoch 125/200, Iteration 168/250, Loss: 0.0082\n",
      "Epoch 125/200, Iteration 169/250, Loss: 0.0126\n",
      "Epoch 125/200, Iteration 170/250, Loss: 0.0384\n",
      "Epoch 125/200, Iteration 171/250, Loss: 0.0217\n",
      "Epoch 125/200, Iteration 172/250, Loss: 0.0127\n",
      "Epoch 125/200, Iteration 173/250, Loss: 0.0086\n",
      "Epoch 125/200, Iteration 174/250, Loss: 0.0235\n",
      "Epoch 125/200, Iteration 175/250, Loss: 0.0122\n",
      "Epoch 125/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 125/200, Iteration 177/250, Loss: 0.0123\n",
      "Epoch 125/200, Iteration 178/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 179/250, Loss: 0.0091\n",
      "Epoch 125/200, Iteration 180/250, Loss: 0.0273\n",
      "Epoch 125/200, Iteration 181/250, Loss: 0.0076\n",
      "Epoch 125/200, Iteration 182/250, Loss: 0.0118\n",
      "Epoch 125/200, Iteration 183/250, Loss: 0.0085\n",
      "Epoch 125/200, Iteration 184/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 185/250, Loss: 0.0231\n",
      "Epoch 125/200, Iteration 186/250, Loss: 0.0146\n",
      "Epoch 125/200, Iteration 187/250, Loss: 0.0152\n",
      "Epoch 125/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 125/200, Iteration 189/250, Loss: 0.0128\n",
      "Epoch 125/200, Iteration 190/250, Loss: 0.0143\n",
      "Epoch 125/200, Iteration 191/250, Loss: 0.0157\n",
      "Epoch 125/200, Iteration 192/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 193/250, Loss: 0.0084\n",
      "Epoch 125/200, Iteration 194/250, Loss: 0.0141\n",
      "Epoch 125/200, Iteration 195/250, Loss: 0.0097\n",
      "Epoch 125/200, Iteration 196/250, Loss: 0.0223\n",
      "Epoch 125/200, Iteration 197/250, Loss: 0.0190\n",
      "Epoch 125/200, Iteration 198/250, Loss: 0.0233\n",
      "Epoch 125/200, Iteration 199/250, Loss: 0.0270\n",
      "Epoch 125/200, Iteration 200/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 201/250, Loss: 0.0118\n",
      "Epoch 125/200, Iteration 202/250, Loss: 0.0179\n",
      "Epoch 125/200, Iteration 203/250, Loss: 0.0065\n",
      "Epoch 125/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 125/200, Iteration 205/250, Loss: 0.0250\n",
      "Epoch 125/200, Iteration 206/250, Loss: 0.0142\n",
      "Epoch 125/200, Iteration 207/250, Loss: 0.0252\n",
      "Epoch 125/200, Iteration 208/250, Loss: 0.0112\n",
      "Epoch 125/200, Iteration 209/250, Loss: 0.0137\n",
      "Epoch 125/200, Iteration 210/250, Loss: 0.0435\n",
      "Epoch 125/200, Iteration 211/250, Loss: 0.0094\n",
      "Epoch 125/200, Iteration 212/250, Loss: 0.0220\n",
      "Epoch 125/200, Iteration 213/250, Loss: 0.0233\n",
      "Epoch 125/200, Iteration 214/250, Loss: 0.0056\n",
      "Epoch 125/200, Iteration 215/250, Loss: 0.0064\n",
      "Epoch 125/200, Iteration 216/250, Loss: 0.0124\n",
      "Epoch 125/200, Iteration 217/250, Loss: 0.0249\n",
      "Epoch 125/200, Iteration 218/250, Loss: 0.0260\n",
      "Epoch 125/200, Iteration 219/250, Loss: 0.0098\n",
      "Epoch 125/200, Iteration 220/250, Loss: 0.0152\n",
      "Epoch 125/200, Iteration 221/250, Loss: 0.0244\n",
      "Epoch 125/200, Iteration 222/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 223/250, Loss: 0.0144\n",
      "Epoch 125/200, Iteration 224/250, Loss: 0.0225\n",
      "Epoch 125/200, Iteration 225/250, Loss: 0.0106\n",
      "Epoch 125/200, Iteration 226/250, Loss: 0.0291\n",
      "Epoch 125/200, Iteration 227/250, Loss: 0.0299\n",
      "Epoch 125/200, Iteration 228/250, Loss: 0.0097\n",
      "Epoch 125/200, Iteration 229/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 230/250, Loss: 0.0166\n",
      "Epoch 125/200, Iteration 231/250, Loss: 0.0203\n",
      "Epoch 125/200, Iteration 232/250, Loss: 0.0108\n",
      "Epoch 125/200, Iteration 233/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 234/250, Loss: 0.0153\n",
      "Epoch 125/200, Iteration 235/250, Loss: 0.0095\n",
      "Epoch 125/200, Iteration 236/250, Loss: 0.0080\n",
      "Epoch 125/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 125/200, Iteration 238/250, Loss: 0.0086\n",
      "Epoch 125/200, Iteration 239/250, Loss: 0.0183\n",
      "Epoch 125/200, Iteration 240/250, Loss: 0.0056\n",
      "Epoch 125/200, Iteration 241/250, Loss: 0.0121\n",
      "Epoch 125/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 125/200, Iteration 243/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 244/250, Loss: 0.0120\n",
      "Epoch 125/200, Iteration 245/250, Loss: 0.0093\n",
      "Epoch 125/200, Iteration 246/250, Loss: 0.0089\n",
      "Epoch 125/200, Iteration 247/250, Loss: 0.0090\n",
      "Epoch 125/200, Iteration 248/250, Loss: 0.0133\n",
      "Epoch 125/200, Iteration 249/250, Loss: 0.0308\n",
      "Epoch 125/200, Iteration 250/250, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 87.86%, Avg loss: 0.006658, MRE: 0.438086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.007219, MRE: 0.564532 \n",
      "\n",
      "Epoch 126/200, Iteration 1/250, Loss: 0.0068\n",
      "Epoch 126/200, Iteration 2/250, Loss: 0.0108\n",
      "Epoch 126/200, Iteration 3/250, Loss: 0.0098\n",
      "Epoch 126/200, Iteration 4/250, Loss: 0.0407\n",
      "Epoch 126/200, Iteration 5/250, Loss: 0.0182\n",
      "Epoch 126/200, Iteration 6/250, Loss: 0.0121\n",
      "Epoch 126/200, Iteration 7/250, Loss: 0.0134\n",
      "Epoch 126/200, Iteration 8/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200, Iteration 9/250, Loss: 0.0076\n",
      "Epoch 126/200, Iteration 10/250, Loss: 0.0162\n",
      "Epoch 126/200, Iteration 11/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 12/250, Loss: 0.0097\n",
      "Epoch 126/200, Iteration 13/250, Loss: 0.0216\n",
      "Epoch 126/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 126/200, Iteration 15/250, Loss: 0.0155\n",
      "Epoch 126/200, Iteration 16/250, Loss: 0.0113\n",
      "Epoch 126/200, Iteration 17/250, Loss: 0.0195\n",
      "Epoch 126/200, Iteration 18/250, Loss: 0.0070\n",
      "Epoch 126/200, Iteration 19/250, Loss: 0.0259\n",
      "Epoch 126/200, Iteration 20/250, Loss: 0.0131\n",
      "Epoch 126/200, Iteration 21/250, Loss: 0.0183\n",
      "Epoch 126/200, Iteration 22/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 23/250, Loss: 0.0181\n",
      "Epoch 126/200, Iteration 24/250, Loss: 0.0187\n",
      "Epoch 126/200, Iteration 25/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 26/250, Loss: 0.0130\n",
      "Epoch 126/200, Iteration 27/250, Loss: 0.0100\n",
      "Epoch 126/200, Iteration 28/250, Loss: 0.0135\n",
      "Epoch 126/200, Iteration 29/250, Loss: 0.0261\n",
      "Epoch 126/200, Iteration 30/250, Loss: 0.0105\n",
      "Epoch 126/200, Iteration 31/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 32/250, Loss: 0.0144\n",
      "Epoch 126/200, Iteration 33/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 34/250, Loss: 0.0102\n",
      "Epoch 126/200, Iteration 35/250, Loss: 0.0129\n",
      "Epoch 126/200, Iteration 36/250, Loss: 0.0063\n",
      "Epoch 126/200, Iteration 37/250, Loss: 0.0102\n",
      "Epoch 126/200, Iteration 38/250, Loss: 0.0120\n",
      "Epoch 126/200, Iteration 39/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 40/250, Loss: 0.0063\n",
      "Epoch 126/200, Iteration 41/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 42/250, Loss: 0.0140\n",
      "Epoch 126/200, Iteration 43/250, Loss: 0.0111\n",
      "Epoch 126/200, Iteration 44/250, Loss: 0.0099\n",
      "Epoch 126/200, Iteration 45/250, Loss: 0.0160\n",
      "Epoch 126/200, Iteration 46/250, Loss: 0.0107\n",
      "Epoch 126/200, Iteration 47/250, Loss: 0.0090\n",
      "Epoch 126/200, Iteration 48/250, Loss: 0.0292\n",
      "Epoch 126/200, Iteration 49/250, Loss: 0.0183\n",
      "Epoch 126/200, Iteration 50/250, Loss: 0.0340\n",
      "Epoch 126/200, Iteration 51/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 52/250, Loss: 0.0130\n",
      "Epoch 126/200, Iteration 53/250, Loss: 0.0212\n",
      "Epoch 126/200, Iteration 54/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 55/250, Loss: 0.0165\n",
      "Epoch 126/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 126/200, Iteration 57/250, Loss: 0.0180\n",
      "Epoch 126/200, Iteration 58/250, Loss: 0.0132\n",
      "Epoch 126/200, Iteration 59/250, Loss: 0.0242\n",
      "Epoch 126/200, Iteration 60/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 61/250, Loss: 0.0178\n",
      "Epoch 126/200, Iteration 62/250, Loss: 0.0213\n",
      "Epoch 126/200, Iteration 63/250, Loss: 0.0133\n",
      "Epoch 126/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 126/200, Iteration 65/250, Loss: 0.0182\n",
      "Epoch 126/200, Iteration 66/250, Loss: 0.0278\n",
      "Epoch 126/200, Iteration 67/250, Loss: 0.0123\n",
      "Epoch 126/200, Iteration 68/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 69/250, Loss: 0.0213\n",
      "Epoch 126/200, Iteration 70/250, Loss: 0.0269\n",
      "Epoch 126/200, Iteration 71/250, Loss: 0.0132\n",
      "Epoch 126/200, Iteration 72/250, Loss: 0.0284\n",
      "Epoch 126/200, Iteration 73/250, Loss: 0.0169\n",
      "Epoch 126/200, Iteration 74/250, Loss: 0.0088\n",
      "Epoch 126/200, Iteration 75/250, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 76/250, Loss: 0.0086\n",
      "Epoch 126/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 126/200, Iteration 78/250, Loss: 0.0091\n",
      "Epoch 126/200, Iteration 79/250, Loss: 0.0145\n",
      "Epoch 126/200, Iteration 80/250, Loss: 0.0134\n",
      "Epoch 126/200, Iteration 81/250, Loss: 0.0174\n",
      "Epoch 126/200, Iteration 82/250, Loss: 0.0173\n",
      "Epoch 126/200, Iteration 83/250, Loss: 0.0075\n",
      "Epoch 126/200, Iteration 84/250, Loss: 0.0150\n",
      "Epoch 126/200, Iteration 85/250, Loss: 0.0259\n",
      "Epoch 126/200, Iteration 86/250, Loss: 0.0111\n",
      "Epoch 126/200, Iteration 87/250, Loss: 0.0150\n",
      "Epoch 126/200, Iteration 88/250, Loss: 0.0067\n",
      "Epoch 126/200, Iteration 89/250, Loss: 0.0154\n",
      "Epoch 126/200, Iteration 90/250, Loss: 0.0248\n",
      "Epoch 126/200, Iteration 91/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 92/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 93/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 94/250, Loss: 0.0291\n",
      "Epoch 126/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 126/200, Iteration 96/250, Loss: 0.0131\n",
      "Epoch 126/200, Iteration 97/250, Loss: 0.0239\n",
      "Epoch 126/200, Iteration 98/250, Loss: 0.0212\n",
      "Epoch 126/200, Iteration 99/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 100/250, Loss: 0.0338\n",
      "Epoch 126/200, Iteration 101/250, Loss: 0.0115\n",
      "Epoch 126/200, Iteration 102/250, Loss: 0.0182\n",
      "Epoch 126/200, Iteration 103/250, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 104/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 105/250, Loss: 0.0245\n",
      "Epoch 126/200, Iteration 106/250, Loss: 0.0200\n",
      "Epoch 126/200, Iteration 107/250, Loss: 0.0204\n",
      "Epoch 126/200, Iteration 108/250, Loss: 0.0099\n",
      "Epoch 126/200, Iteration 109/250, Loss: 0.0146\n",
      "Epoch 126/200, Iteration 110/250, Loss: 0.0072\n",
      "Epoch 126/200, Iteration 111/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 112/250, Loss: 0.0106\n",
      "Epoch 126/200, Iteration 113/250, Loss: 0.0177\n",
      "Epoch 126/200, Iteration 114/250, Loss: 0.0079\n",
      "Epoch 126/200, Iteration 115/250, Loss: 0.0086\n",
      "Epoch 126/200, Iteration 116/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 117/250, Loss: 0.0123\n",
      "Epoch 126/200, Iteration 118/250, Loss: 0.0068\n",
      "Epoch 126/200, Iteration 119/250, Loss: 0.0220\n",
      "Epoch 126/200, Iteration 120/250, Loss: 0.0127\n",
      "Epoch 126/200, Iteration 121/250, Loss: 0.0138\n",
      "Epoch 126/200, Iteration 122/250, Loss: 0.0258\n",
      "Epoch 126/200, Iteration 123/250, Loss: 0.0175\n",
      "Epoch 126/200, Iteration 124/250, Loss: 0.0193\n",
      "Epoch 126/200, Iteration 125/250, Loss: 0.0084\n",
      "Epoch 126/200, Iteration 126/250, Loss: 0.0083\n",
      "Epoch 126/200, Iteration 127/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 128/250, Loss: 0.0117\n",
      "Epoch 126/200, Iteration 129/250, Loss: 0.0093\n",
      "Epoch 126/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 126/200, Iteration 131/250, Loss: 0.0115\n",
      "Epoch 126/200, Iteration 132/250, Loss: 0.0133\n",
      "Epoch 126/200, Iteration 133/250, Loss: 0.0283\n",
      "Epoch 126/200, Iteration 134/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 135/250, Loss: 0.0406\n",
      "Epoch 126/200, Iteration 136/250, Loss: 0.0090\n",
      "Epoch 126/200, Iteration 137/250, Loss: 0.0131\n",
      "Epoch 126/200, Iteration 138/250, Loss: 0.0113\n",
      "Epoch 126/200, Iteration 139/250, Loss: 0.0397\n",
      "Epoch 126/200, Iteration 140/250, Loss: 0.0065\n",
      "Epoch 126/200, Iteration 141/250, Loss: 0.0200\n",
      "Epoch 126/200, Iteration 142/250, Loss: 0.0145\n",
      "Epoch 126/200, Iteration 143/250, Loss: 0.0179\n",
      "Epoch 126/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 126/200, Iteration 145/250, Loss: 0.0097\n",
      "Epoch 126/200, Iteration 146/250, Loss: 0.0100\n",
      "Epoch 126/200, Iteration 147/250, Loss: 0.0120\n",
      "Epoch 126/200, Iteration 148/250, Loss: 0.0087\n",
      "Epoch 126/200, Iteration 149/250, Loss: 0.0094\n",
      "Epoch 126/200, Iteration 150/250, Loss: 0.0124\n",
      "Epoch 126/200, Iteration 151/250, Loss: 0.0101\n",
      "Epoch 126/200, Iteration 152/250, Loss: 0.0105\n",
      "Epoch 126/200, Iteration 153/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 154/250, Loss: 0.0258\n",
      "Epoch 126/200, Iteration 155/250, Loss: 0.0109\n",
      "Epoch 126/200, Iteration 156/250, Loss: 0.0084\n",
      "Epoch 126/200, Iteration 157/250, Loss: 0.0084\n",
      "Epoch 126/200, Iteration 158/250, Loss: 0.0137\n",
      "Epoch 126/200, Iteration 159/250, Loss: 0.0320\n",
      "Epoch 126/200, Iteration 160/250, Loss: 0.0253\n",
      "Epoch 126/200, Iteration 161/250, Loss: 0.0105\n",
      "Epoch 126/200, Iteration 162/250, Loss: 0.0159\n",
      "Epoch 126/200, Iteration 163/250, Loss: 0.0207\n",
      "Epoch 126/200, Iteration 164/250, Loss: 0.0097\n",
      "Epoch 126/200, Iteration 165/250, Loss: 0.0128\n",
      "Epoch 126/200, Iteration 166/250, Loss: 0.0123\n",
      "Epoch 126/200, Iteration 167/250, Loss: 0.0125\n",
      "Epoch 126/200, Iteration 168/250, Loss: 0.0098\n",
      "Epoch 126/200, Iteration 169/250, Loss: 0.0115\n",
      "Epoch 126/200, Iteration 170/250, Loss: 0.0069\n",
      "Epoch 126/200, Iteration 171/250, Loss: 0.0164\n",
      "Epoch 126/200, Iteration 172/250, Loss: 0.0152\n",
      "Epoch 126/200, Iteration 173/250, Loss: 0.0186\n",
      "Epoch 126/200, Iteration 174/250, Loss: 0.0139\n",
      "Epoch 126/200, Iteration 175/250, Loss: 0.0114\n",
      "Epoch 126/200, Iteration 176/250, Loss: 0.0150\n",
      "Epoch 126/200, Iteration 177/250, Loss: 0.0143\n",
      "Epoch 126/200, Iteration 178/250, Loss: 0.0099\n",
      "Epoch 126/200, Iteration 179/250, Loss: 0.0127\n",
      "Epoch 126/200, Iteration 180/250, Loss: 0.0099\n",
      "Epoch 126/200, Iteration 181/250, Loss: 0.0126\n",
      "Epoch 126/200, Iteration 182/250, Loss: 0.0237\n",
      "Epoch 126/200, Iteration 183/250, Loss: 0.0176\n",
      "Epoch 126/200, Iteration 184/250, Loss: 0.0205\n",
      "Epoch 126/200, Iteration 185/250, Loss: 0.0075\n",
      "Epoch 126/200, Iteration 186/250, Loss: 0.0135\n",
      "Epoch 126/200, Iteration 187/250, Loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200, Iteration 188/250, Loss: 0.0111\n",
      "Epoch 126/200, Iteration 189/250, Loss: 0.0116\n",
      "Epoch 126/200, Iteration 190/250, Loss: 0.0132\n",
      "Epoch 126/200, Iteration 191/250, Loss: 0.0200\n",
      "Epoch 126/200, Iteration 192/250, Loss: 0.0118\n",
      "Epoch 126/200, Iteration 193/250, Loss: 0.0213\n",
      "Epoch 126/200, Iteration 194/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 195/250, Loss: 0.0085\n",
      "Epoch 126/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 126/200, Iteration 197/250, Loss: 0.0077\n",
      "Epoch 126/200, Iteration 198/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 199/250, Loss: 0.0092\n",
      "Epoch 126/200, Iteration 200/250, Loss: 0.0229\n",
      "Epoch 126/200, Iteration 201/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 202/250, Loss: 0.0088\n",
      "Epoch 126/200, Iteration 203/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 204/250, Loss: 0.0247\n",
      "Epoch 126/200, Iteration 205/250, Loss: 0.0222\n",
      "Epoch 126/200, Iteration 206/250, Loss: 0.0161\n",
      "Epoch 126/200, Iteration 207/250, Loss: 0.0131\n",
      "Epoch 126/200, Iteration 208/250, Loss: 0.0103\n",
      "Epoch 126/200, Iteration 209/250, Loss: 0.0200\n",
      "Epoch 126/200, Iteration 210/250, Loss: 0.0098\n",
      "Epoch 126/200, Iteration 211/250, Loss: 0.0156\n",
      "Epoch 126/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 126/200, Iteration 213/250, Loss: 0.0149\n",
      "Epoch 126/200, Iteration 214/250, Loss: 0.0241\n",
      "Epoch 126/200, Iteration 215/250, Loss: 0.0252\n",
      "Epoch 126/200, Iteration 216/250, Loss: 0.0238\n",
      "Epoch 126/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 126/200, Iteration 218/250, Loss: 0.0226\n",
      "Epoch 126/200, Iteration 219/250, Loss: 0.0155\n",
      "Epoch 126/200, Iteration 220/250, Loss: 0.0167\n",
      "Epoch 126/200, Iteration 221/250, Loss: 0.0152\n",
      "Epoch 126/200, Iteration 222/250, Loss: 0.0168\n",
      "Epoch 126/200, Iteration 223/250, Loss: 0.0091\n",
      "Epoch 126/200, Iteration 224/250, Loss: 0.0142\n",
      "Epoch 126/200, Iteration 225/250, Loss: 0.0246\n",
      "Epoch 126/200, Iteration 226/250, Loss: 0.0082\n",
      "Epoch 126/200, Iteration 227/250, Loss: 0.0120\n",
      "Epoch 126/200, Iteration 228/250, Loss: 0.0112\n",
      "Epoch 126/200, Iteration 229/250, Loss: 0.0121\n",
      "Epoch 126/200, Iteration 230/250, Loss: 0.0449\n",
      "Epoch 126/200, Iteration 231/250, Loss: 0.0203\n",
      "Epoch 126/200, Iteration 232/250, Loss: 0.0310\n",
      "Epoch 126/200, Iteration 233/250, Loss: 0.0107\n",
      "Epoch 126/200, Iteration 234/250, Loss: 0.0191\n",
      "Epoch 126/200, Iteration 235/250, Loss: 0.0089\n",
      "Epoch 126/200, Iteration 236/250, Loss: 0.0110\n",
      "Epoch 126/200, Iteration 237/250, Loss: 0.0135\n",
      "Epoch 126/200, Iteration 238/250, Loss: 0.0263\n",
      "Epoch 126/200, Iteration 239/250, Loss: 0.0096\n",
      "Epoch 126/200, Iteration 240/250, Loss: 0.0128\n",
      "Epoch 126/200, Iteration 241/250, Loss: 0.0211\n",
      "Epoch 126/200, Iteration 242/250, Loss: 0.0139\n",
      "Epoch 126/200, Iteration 243/250, Loss: 0.0133\n",
      "Epoch 126/200, Iteration 244/250, Loss: 0.0265\n",
      "Epoch 126/200, Iteration 245/250, Loss: 0.0283\n",
      "Epoch 126/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 126/200, Iteration 247/250, Loss: 0.0208\n",
      "Epoch 126/200, Iteration 248/250, Loss: 0.0153\n",
      "Epoch 126/200, Iteration 249/250, Loss: 0.0126\n",
      "Epoch 126/200, Iteration 250/250, Loss: 0.0081\n",
      "Train Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006744, MRE: 0.445408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.007256, MRE: 0.467476 \n",
      "\n",
      "Epoch 127/200, Iteration 1/250, Loss: 0.0139\n",
      "Epoch 127/200, Iteration 2/250, Loss: 0.0151\n",
      "Epoch 127/200, Iteration 3/250, Loss: 0.0066\n",
      "Epoch 127/200, Iteration 4/250, Loss: 0.0099\n",
      "Epoch 127/200, Iteration 5/250, Loss: 0.0205\n",
      "Epoch 127/200, Iteration 6/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 7/250, Loss: 0.0134\n",
      "Epoch 127/200, Iteration 8/250, Loss: 0.0431\n",
      "Epoch 127/200, Iteration 9/250, Loss: 0.0417\n",
      "Epoch 127/200, Iteration 10/250, Loss: 0.0103\n",
      "Epoch 127/200, Iteration 11/250, Loss: 0.0136\n",
      "Epoch 127/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 127/200, Iteration 13/250, Loss: 0.0169\n",
      "Epoch 127/200, Iteration 14/250, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 15/250, Loss: 0.0144\n",
      "Epoch 127/200, Iteration 16/250, Loss: 0.0144\n",
      "Epoch 127/200, Iteration 17/250, Loss: 0.0382\n",
      "Epoch 127/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 127/200, Iteration 19/250, Loss: 0.0073\n",
      "Epoch 127/200, Iteration 20/250, Loss: 0.0074\n",
      "Epoch 127/200, Iteration 21/250, Loss: 0.0125\n",
      "Epoch 127/200, Iteration 22/250, Loss: 0.0095\n",
      "Epoch 127/200, Iteration 23/250, Loss: 0.0076\n",
      "Epoch 127/200, Iteration 24/250, Loss: 0.0375\n",
      "Epoch 127/200, Iteration 25/250, Loss: 0.0128\n",
      "Epoch 127/200, Iteration 26/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 27/250, Loss: 0.0231\n",
      "Epoch 127/200, Iteration 28/250, Loss: 0.0185\n",
      "Epoch 127/200, Iteration 29/250, Loss: 0.0118\n",
      "Epoch 127/200, Iteration 30/250, Loss: 0.0159\n",
      "Epoch 127/200, Iteration 31/250, Loss: 0.0295\n",
      "Epoch 127/200, Iteration 32/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 33/250, Loss: 0.0174\n",
      "Epoch 127/200, Iteration 34/250, Loss: 0.0113\n",
      "Epoch 127/200, Iteration 35/250, Loss: 0.0247\n",
      "Epoch 127/200, Iteration 36/250, Loss: 0.0144\n",
      "Epoch 127/200, Iteration 37/250, Loss: 0.0132\n",
      "Epoch 127/200, Iteration 38/250, Loss: 0.0094\n",
      "Epoch 127/200, Iteration 39/250, Loss: 0.0202\n",
      "Epoch 127/200, Iteration 40/250, Loss: 0.0253\n",
      "Epoch 127/200, Iteration 41/250, Loss: 0.0164\n",
      "Epoch 127/200, Iteration 42/250, Loss: 0.0229\n",
      "Epoch 127/200, Iteration 43/250, Loss: 0.0061\n",
      "Epoch 127/200, Iteration 44/250, Loss: 0.0254\n",
      "Epoch 127/200, Iteration 45/250, Loss: 0.0140\n",
      "Epoch 127/200, Iteration 46/250, Loss: 0.0066\n",
      "Epoch 127/200, Iteration 47/250, Loss: 0.0096\n",
      "Epoch 127/200, Iteration 48/250, Loss: 0.0104\n",
      "Epoch 127/200, Iteration 49/250, Loss: 0.0135\n",
      "Epoch 127/200, Iteration 50/250, Loss: 0.0161\n",
      "Epoch 127/200, Iteration 51/250, Loss: 0.0101\n",
      "Epoch 127/200, Iteration 52/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 53/250, Loss: 0.0063\n",
      "Epoch 127/200, Iteration 54/250, Loss: 0.0242\n",
      "Epoch 127/200, Iteration 55/250, Loss: 0.0278\n",
      "Epoch 127/200, Iteration 56/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 57/250, Loss: 0.0262\n",
      "Epoch 127/200, Iteration 58/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 59/250, Loss: 0.0338\n",
      "Epoch 127/200, Iteration 60/250, Loss: 0.0141\n",
      "Epoch 127/200, Iteration 61/250, Loss: 0.0291\n",
      "Epoch 127/200, Iteration 62/250, Loss: 0.0123\n",
      "Epoch 127/200, Iteration 63/250, Loss: 0.0082\n",
      "Epoch 127/200, Iteration 64/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 65/250, Loss: 0.0141\n",
      "Epoch 127/200, Iteration 66/250, Loss: 0.0280\n",
      "Epoch 127/200, Iteration 67/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 68/250, Loss: 0.0234\n",
      "Epoch 127/200, Iteration 69/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 70/250, Loss: 0.0325\n",
      "Epoch 127/200, Iteration 71/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 72/250, Loss: 0.0165\n",
      "Epoch 127/200, Iteration 73/250, Loss: 0.0201\n",
      "Epoch 127/200, Iteration 74/250, Loss: 0.0143\n",
      "Epoch 127/200, Iteration 75/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 76/250, Loss: 0.0196\n",
      "Epoch 127/200, Iteration 77/250, Loss: 0.0314\n",
      "Epoch 127/200, Iteration 78/250, Loss: 0.0093\n",
      "Epoch 127/200, Iteration 79/250, Loss: 0.0180\n",
      "Epoch 127/200, Iteration 80/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 81/250, Loss: 0.0158\n",
      "Epoch 127/200, Iteration 82/250, Loss: 0.0093\n",
      "Epoch 127/200, Iteration 83/250, Loss: 0.0090\n",
      "Epoch 127/200, Iteration 84/250, Loss: 0.0075\n",
      "Epoch 127/200, Iteration 85/250, Loss: 0.0137\n",
      "Epoch 127/200, Iteration 86/250, Loss: 0.0298\n",
      "Epoch 127/200, Iteration 87/250, Loss: 0.0167\n",
      "Epoch 127/200, Iteration 88/250, Loss: 0.0171\n",
      "Epoch 127/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 127/200, Iteration 90/250, Loss: 0.0278\n",
      "Epoch 127/200, Iteration 91/250, Loss: 0.0082\n",
      "Epoch 127/200, Iteration 92/250, Loss: 0.0119\n",
      "Epoch 127/200, Iteration 93/250, Loss: 0.0103\n",
      "Epoch 127/200, Iteration 94/250, Loss: 0.0350\n",
      "Epoch 127/200, Iteration 95/250, Loss: 0.0236\n",
      "Epoch 127/200, Iteration 96/250, Loss: 0.0160\n",
      "Epoch 127/200, Iteration 97/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 98/250, Loss: 0.0339\n",
      "Epoch 127/200, Iteration 99/250, Loss: 0.0175\n",
      "Epoch 127/200, Iteration 100/250, Loss: 0.0100\n",
      "Epoch 127/200, Iteration 101/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 102/250, Loss: 0.0157\n",
      "Epoch 127/200, Iteration 103/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 104/250, Loss: 0.0130\n",
      "Epoch 127/200, Iteration 105/250, Loss: 0.0074\n",
      "Epoch 127/200, Iteration 106/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 107/250, Loss: 0.0114\n",
      "Epoch 127/200, Iteration 108/250, Loss: 0.0192\n",
      "Epoch 127/200, Iteration 109/250, Loss: 0.0240\n",
      "Epoch 127/200, Iteration 110/250, Loss: 0.0174\n",
      "Epoch 127/200, Iteration 111/250, Loss: 0.0084\n",
      "Epoch 127/200, Iteration 112/250, Loss: 0.0109\n",
      "Epoch 127/200, Iteration 113/250, Loss: 0.0170\n",
      "Epoch 127/200, Iteration 114/250, Loss: 0.0176\n",
      "Epoch 127/200, Iteration 115/250, Loss: 0.0126\n",
      "Epoch 127/200, Iteration 116/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 117/250, Loss: 0.0290\n",
      "Epoch 127/200, Iteration 118/250, Loss: 0.0091\n",
      "Epoch 127/200, Iteration 119/250, Loss: 0.0080\n",
      "Epoch 127/200, Iteration 120/250, Loss: 0.0076\n",
      "Epoch 127/200, Iteration 121/250, Loss: 0.0230\n",
      "Epoch 127/200, Iteration 122/250, Loss: 0.0120\n",
      "Epoch 127/200, Iteration 123/250, Loss: 0.0151\n",
      "Epoch 127/200, Iteration 124/250, Loss: 0.0141\n",
      "Epoch 127/200, Iteration 125/250, Loss: 0.0194\n",
      "Epoch 127/200, Iteration 126/250, Loss: 0.0113\n",
      "Epoch 127/200, Iteration 127/250, Loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200, Iteration 128/250, Loss: 0.0069\n",
      "Epoch 127/200, Iteration 129/250, Loss: 0.0073\n",
      "Epoch 127/200, Iteration 130/250, Loss: 0.0300\n",
      "Epoch 127/200, Iteration 131/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 132/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 133/250, Loss: 0.0340\n",
      "Epoch 127/200, Iteration 134/250, Loss: 0.0118\n",
      "Epoch 127/200, Iteration 135/250, Loss: 0.0255\n",
      "Epoch 127/200, Iteration 136/250, Loss: 0.0085\n",
      "Epoch 127/200, Iteration 137/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 138/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 139/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 140/250, Loss: 0.0209\n",
      "Epoch 127/200, Iteration 141/250, Loss: 0.0081\n",
      "Epoch 127/200, Iteration 142/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 143/250, Loss: 0.0089\n",
      "Epoch 127/200, Iteration 144/250, Loss: 0.0153\n",
      "Epoch 127/200, Iteration 145/250, Loss: 0.0216\n",
      "Epoch 127/200, Iteration 146/250, Loss: 0.0104\n",
      "Epoch 127/200, Iteration 147/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 148/250, Loss: 0.0177\n",
      "Epoch 127/200, Iteration 149/250, Loss: 0.0067\n",
      "Epoch 127/200, Iteration 150/250, Loss: 0.0286\n",
      "Epoch 127/200, Iteration 151/250, Loss: 0.0116\n",
      "Epoch 127/200, Iteration 152/250, Loss: 0.0132\n",
      "Epoch 127/200, Iteration 153/250, Loss: 0.0235\n",
      "Epoch 127/200, Iteration 154/250, Loss: 0.0216\n",
      "Epoch 127/200, Iteration 155/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 156/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 157/250, Loss: 0.0133\n",
      "Epoch 127/200, Iteration 158/250, Loss: 0.0078\n",
      "Epoch 127/200, Iteration 159/250, Loss: 0.0151\n",
      "Epoch 127/200, Iteration 160/250, Loss: 0.0185\n",
      "Epoch 127/200, Iteration 161/250, Loss: 0.0087\n",
      "Epoch 127/200, Iteration 162/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 163/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 164/250, Loss: 0.0087\n",
      "Epoch 127/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 127/200, Iteration 166/250, Loss: 0.0083\n",
      "Epoch 127/200, Iteration 167/250, Loss: 0.0190\n",
      "Epoch 127/200, Iteration 168/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 169/250, Loss: 0.0070\n",
      "Epoch 127/200, Iteration 170/250, Loss: 0.0089\n",
      "Epoch 127/200, Iteration 171/250, Loss: 0.0092\n",
      "Epoch 127/200, Iteration 172/250, Loss: 0.0168\n",
      "Epoch 127/200, Iteration 173/250, Loss: 0.0070\n",
      "Epoch 127/200, Iteration 174/250, Loss: 0.0095\n",
      "Epoch 127/200, Iteration 175/250, Loss: 0.0213\n",
      "Epoch 127/200, Iteration 176/250, Loss: 0.0209\n",
      "Epoch 127/200, Iteration 177/250, Loss: 0.0178\n",
      "Epoch 127/200, Iteration 178/250, Loss: 0.0069\n",
      "Epoch 127/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 127/200, Iteration 180/250, Loss: 0.0148\n",
      "Epoch 127/200, Iteration 181/250, Loss: 0.0193\n",
      "Epoch 127/200, Iteration 182/250, Loss: 0.0152\n",
      "Epoch 127/200, Iteration 183/250, Loss: 0.0113\n",
      "Epoch 127/200, Iteration 184/250, Loss: 0.0125\n",
      "Epoch 127/200, Iteration 185/250, Loss: 0.0178\n",
      "Epoch 127/200, Iteration 186/250, Loss: 0.0189\n",
      "Epoch 127/200, Iteration 187/250, Loss: 0.0104\n",
      "Epoch 127/200, Iteration 188/250, Loss: 0.0127\n",
      "Epoch 127/200, Iteration 189/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 190/250, Loss: 0.0121\n",
      "Epoch 127/200, Iteration 191/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 192/250, Loss: 0.0182\n",
      "Epoch 127/200, Iteration 193/250, Loss: 0.0137\n",
      "Epoch 127/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 127/200, Iteration 195/250, Loss: 0.0128\n",
      "Epoch 127/200, Iteration 196/250, Loss: 0.0131\n",
      "Epoch 127/200, Iteration 197/250, Loss: 0.0133\n",
      "Epoch 127/200, Iteration 198/250, Loss: 0.0156\n",
      "Epoch 127/200, Iteration 199/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 200/250, Loss: 0.0110\n",
      "Epoch 127/200, Iteration 201/250, Loss: 0.0153\n",
      "Epoch 127/200, Iteration 202/250, Loss: 0.0122\n",
      "Epoch 127/200, Iteration 203/250, Loss: 0.0105\n",
      "Epoch 127/200, Iteration 204/250, Loss: 0.0143\n",
      "Epoch 127/200, Iteration 205/250, Loss: 0.0155\n",
      "Epoch 127/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 127/200, Iteration 207/250, Loss: 0.0131\n",
      "Epoch 127/200, Iteration 208/250, Loss: 0.0083\n",
      "Epoch 127/200, Iteration 209/250, Loss: 0.0107\n",
      "Epoch 127/200, Iteration 210/250, Loss: 0.0072\n",
      "Epoch 127/200, Iteration 211/250, Loss: 0.0134\n",
      "Epoch 127/200, Iteration 212/250, Loss: 0.0071\n",
      "Epoch 127/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 127/200, Iteration 214/250, Loss: 0.0115\n",
      "Epoch 127/200, Iteration 215/250, Loss: 0.0213\n",
      "Epoch 127/200, Iteration 216/250, Loss: 0.0117\n",
      "Epoch 127/200, Iteration 217/250, Loss: 0.0108\n",
      "Epoch 127/200, Iteration 218/250, Loss: 0.0206\n",
      "Epoch 127/200, Iteration 219/250, Loss: 0.0226\n",
      "Epoch 127/200, Iteration 220/250, Loss: 0.0064\n",
      "Epoch 127/200, Iteration 221/250, Loss: 0.0188\n",
      "Epoch 127/200, Iteration 222/250, Loss: 0.0079\n",
      "Epoch 127/200, Iteration 223/250, Loss: 0.0114\n",
      "Epoch 127/200, Iteration 224/250, Loss: 0.0165\n",
      "Epoch 127/200, Iteration 225/250, Loss: 0.0111\n",
      "Epoch 127/200, Iteration 226/250, Loss: 0.0136\n",
      "Epoch 127/200, Iteration 227/250, Loss: 0.0167\n",
      "Epoch 127/200, Iteration 228/250, Loss: 0.0153\n",
      "Epoch 127/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 127/200, Iteration 230/250, Loss: 0.0135\n",
      "Epoch 127/200, Iteration 231/250, Loss: 0.0099\n",
      "Epoch 127/200, Iteration 232/250, Loss: 0.0187\n",
      "Epoch 127/200, Iteration 233/250, Loss: 0.0120\n",
      "Epoch 127/200, Iteration 234/250, Loss: 0.0123\n",
      "Epoch 127/200, Iteration 235/250, Loss: 0.0246\n",
      "Epoch 127/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 127/200, Iteration 237/250, Loss: 0.0101\n",
      "Epoch 127/200, Iteration 238/250, Loss: 0.0090\n",
      "Epoch 127/200, Iteration 239/250, Loss: 0.0110\n",
      "Epoch 127/200, Iteration 240/250, Loss: 0.0253\n",
      "Epoch 127/200, Iteration 241/250, Loss: 0.0174\n",
      "Epoch 127/200, Iteration 242/250, Loss: 0.0231\n",
      "Epoch 127/200, Iteration 243/250, Loss: 0.0088\n",
      "Epoch 127/200, Iteration 244/250, Loss: 0.0181\n",
      "Epoch 127/200, Iteration 245/250, Loss: 0.0165\n",
      "Epoch 127/200, Iteration 246/250, Loss: 0.0228\n",
      "Epoch 127/200, Iteration 247/250, Loss: 0.0150\n",
      "Epoch 127/200, Iteration 248/250, Loss: 0.0129\n",
      "Epoch 127/200, Iteration 249/250, Loss: 0.0287\n",
      "Epoch 127/200, Iteration 250/250, Loss: 0.0118\n",
      "Train Error: \n",
      " Accuracy: 91.75%, Avg loss: 0.006883, MRE: 0.424595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.45%, Avg loss: 0.007446, MRE: 0.491337 \n",
      "\n",
      "Epoch 128/200, Iteration 1/250, Loss: 0.0489\n",
      "Epoch 128/200, Iteration 2/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 3/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 4/250, Loss: 0.0151\n",
      "Epoch 128/200, Iteration 5/250, Loss: 0.0135\n",
      "Epoch 128/200, Iteration 6/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 7/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 8/250, Loss: 0.0416\n",
      "Epoch 128/200, Iteration 9/250, Loss: 0.0120\n",
      "Epoch 128/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 11/250, Loss: 0.0083\n",
      "Epoch 128/200, Iteration 12/250, Loss: 0.0321\n",
      "Epoch 128/200, Iteration 13/250, Loss: 0.0313\n",
      "Epoch 128/200, Iteration 14/250, Loss: 0.0166\n",
      "Epoch 128/200, Iteration 15/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 16/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 17/250, Loss: 0.0146\n",
      "Epoch 128/200, Iteration 18/250, Loss: 0.0320\n",
      "Epoch 128/200, Iteration 19/250, Loss: 0.0178\n",
      "Epoch 128/200, Iteration 20/250, Loss: 0.0127\n",
      "Epoch 128/200, Iteration 21/250, Loss: 0.0111\n",
      "Epoch 128/200, Iteration 22/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 24/250, Loss: 0.0271\n",
      "Epoch 128/200, Iteration 25/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 26/250, Loss: 0.0088\n",
      "Epoch 128/200, Iteration 27/250, Loss: 0.0112\n",
      "Epoch 128/200, Iteration 28/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 29/250, Loss: 0.0138\n",
      "Epoch 128/200, Iteration 30/250, Loss: 0.0082\n",
      "Epoch 128/200, Iteration 31/250, Loss: 0.0292\n",
      "Epoch 128/200, Iteration 32/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 33/250, Loss: 0.0150\n",
      "Epoch 128/200, Iteration 34/250, Loss: 0.0126\n",
      "Epoch 128/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 128/200, Iteration 36/250, Loss: 0.0096\n",
      "Epoch 128/200, Iteration 37/250, Loss: 0.0198\n",
      "Epoch 128/200, Iteration 38/250, Loss: 0.0133\n",
      "Epoch 128/200, Iteration 39/250, Loss: 0.0148\n",
      "Epoch 128/200, Iteration 40/250, Loss: 0.0170\n",
      "Epoch 128/200, Iteration 41/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 42/250, Loss: 0.0077\n",
      "Epoch 128/200, Iteration 43/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 44/250, Loss: 0.0165\n",
      "Epoch 128/200, Iteration 45/250, Loss: 0.0288\n",
      "Epoch 128/200, Iteration 46/250, Loss: 0.0083\n",
      "Epoch 128/200, Iteration 47/250, Loss: 0.0157\n",
      "Epoch 128/200, Iteration 48/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 49/250, Loss: 0.0078\n",
      "Epoch 128/200, Iteration 50/250, Loss: 0.0157\n",
      "Epoch 128/200, Iteration 51/250, Loss: 0.0222\n",
      "Epoch 128/200, Iteration 52/250, Loss: 0.0072\n",
      "Epoch 128/200, Iteration 53/250, Loss: 0.0095\n",
      "Epoch 128/200, Iteration 54/250, Loss: 0.0085\n",
      "Epoch 128/200, Iteration 55/250, Loss: 0.0243\n",
      "Epoch 128/200, Iteration 56/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 57/250, Loss: 0.0132\n",
      "Epoch 128/200, Iteration 58/250, Loss: 0.0106\n",
      "Epoch 128/200, Iteration 59/250, Loss: 0.0107\n",
      "Epoch 128/200, Iteration 60/250, Loss: 0.0193\n",
      "Epoch 128/200, Iteration 61/250, Loss: 0.0129\n",
      "Epoch 128/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 63/250, Loss: 0.0077\n",
      "Epoch 128/200, Iteration 64/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 65/250, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200, Iteration 66/250, Loss: 0.0183\n",
      "Epoch 128/200, Iteration 67/250, Loss: 0.0352\n",
      "Epoch 128/200, Iteration 68/250, Loss: 0.0078\n",
      "Epoch 128/200, Iteration 69/250, Loss: 0.0132\n",
      "Epoch 128/200, Iteration 70/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 71/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 72/250, Loss: 0.0201\n",
      "Epoch 128/200, Iteration 73/250, Loss: 0.0109\n",
      "Epoch 128/200, Iteration 74/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 75/250, Loss: 0.0119\n",
      "Epoch 128/200, Iteration 76/250, Loss: 0.0226\n",
      "Epoch 128/200, Iteration 77/250, Loss: 0.0298\n",
      "Epoch 128/200, Iteration 78/250, Loss: 0.0326\n",
      "Epoch 128/200, Iteration 79/250, Loss: 0.0236\n",
      "Epoch 128/200, Iteration 80/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 81/250, Loss: 0.0223\n",
      "Epoch 128/200, Iteration 82/250, Loss: 0.0359\n",
      "Epoch 128/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 128/200, Iteration 84/250, Loss: 0.0077\n",
      "Epoch 128/200, Iteration 85/250, Loss: 0.0137\n",
      "Epoch 128/200, Iteration 86/250, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 87/250, Loss: 0.0091\n",
      "Epoch 128/200, Iteration 88/250, Loss: 0.0264\n",
      "Epoch 128/200, Iteration 89/250, Loss: 0.0154\n",
      "Epoch 128/200, Iteration 90/250, Loss: 0.0179\n",
      "Epoch 128/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 128/200, Iteration 92/250, Loss: 0.0140\n",
      "Epoch 128/200, Iteration 93/250, Loss: 0.0078\n",
      "Epoch 128/200, Iteration 94/250, Loss: 0.0098\n",
      "Epoch 128/200, Iteration 95/250, Loss: 0.0102\n",
      "Epoch 128/200, Iteration 96/250, Loss: 0.0191\n",
      "Epoch 128/200, Iteration 97/250, Loss: 0.0079\n",
      "Epoch 128/200, Iteration 98/250, Loss: 0.0126\n",
      "Epoch 128/200, Iteration 99/250, Loss: 0.0143\n",
      "Epoch 128/200, Iteration 100/250, Loss: 0.0071\n",
      "Epoch 128/200, Iteration 101/250, Loss: 0.0103\n",
      "Epoch 128/200, Iteration 102/250, Loss: 0.0124\n",
      "Epoch 128/200, Iteration 103/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 128/200, Iteration 105/250, Loss: 0.0069\n",
      "Epoch 128/200, Iteration 106/250, Loss: 0.0098\n",
      "Epoch 128/200, Iteration 107/250, Loss: 0.0090\n",
      "Epoch 128/200, Iteration 108/250, Loss: 0.0088\n",
      "Epoch 128/200, Iteration 109/250, Loss: 0.0133\n",
      "Epoch 128/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 128/200, Iteration 111/250, Loss: 0.0076\n",
      "Epoch 128/200, Iteration 112/250, Loss: 0.0129\n",
      "Epoch 128/200, Iteration 113/250, Loss: 0.0145\n",
      "Epoch 128/200, Iteration 114/250, Loss: 0.0125\n",
      "Epoch 128/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 117/250, Loss: 0.0171\n",
      "Epoch 128/200, Iteration 118/250, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 119/250, Loss: 0.0277\n",
      "Epoch 128/200, Iteration 120/250, Loss: 0.0157\n",
      "Epoch 128/200, Iteration 121/250, Loss: 0.0094\n",
      "Epoch 128/200, Iteration 122/250, Loss: 0.0086\n",
      "Epoch 128/200, Iteration 123/250, Loss: 0.0113\n",
      "Epoch 128/200, Iteration 124/250, Loss: 0.0149\n",
      "Epoch 128/200, Iteration 125/250, Loss: 0.0060\n",
      "Epoch 128/200, Iteration 126/250, Loss: 0.0109\n",
      "Epoch 128/200, Iteration 127/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 128/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 129/250, Loss: 0.0110\n",
      "Epoch 128/200, Iteration 130/250, Loss: 0.0073\n",
      "Epoch 128/200, Iteration 131/250, Loss: 0.0136\n",
      "Epoch 128/200, Iteration 132/250, Loss: 0.0084\n",
      "Epoch 128/200, Iteration 133/250, Loss: 0.0301\n",
      "Epoch 128/200, Iteration 134/250, Loss: 0.0109\n",
      "Epoch 128/200, Iteration 135/250, Loss: 0.0189\n",
      "Epoch 128/200, Iteration 136/250, Loss: 0.0197\n",
      "Epoch 128/200, Iteration 137/250, Loss: 0.0069\n",
      "Epoch 128/200, Iteration 138/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 128/200, Iteration 140/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 141/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 142/250, Loss: 0.0128\n",
      "Epoch 128/200, Iteration 143/250, Loss: 0.0210\n",
      "Epoch 128/200, Iteration 144/250, Loss: 0.0095\n",
      "Epoch 128/200, Iteration 145/250, Loss: 0.0090\n",
      "Epoch 128/200, Iteration 146/250, Loss: 0.0082\n",
      "Epoch 128/200, Iteration 147/250, Loss: 0.0141\n",
      "Epoch 128/200, Iteration 148/250, Loss: 0.0260\n",
      "Epoch 128/200, Iteration 149/250, Loss: 0.0139\n",
      "Epoch 128/200, Iteration 150/250, Loss: 0.0236\n",
      "Epoch 128/200, Iteration 151/250, Loss: 0.0075\n",
      "Epoch 128/200, Iteration 152/250, Loss: 0.0152\n",
      "Epoch 128/200, Iteration 153/250, Loss: 0.0166\n",
      "Epoch 128/200, Iteration 154/250, Loss: 0.0228\n",
      "Epoch 128/200, Iteration 155/250, Loss: 0.0077\n",
      "Epoch 128/200, Iteration 156/250, Loss: 0.0268\n",
      "Epoch 128/200, Iteration 157/250, Loss: 0.0351\n",
      "Epoch 128/200, Iteration 158/250, Loss: 0.0220\n",
      "Epoch 128/200, Iteration 159/250, Loss: 0.0082\n",
      "Epoch 128/200, Iteration 160/250, Loss: 0.0143\n",
      "Epoch 128/200, Iteration 161/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 162/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 163/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 164/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 165/250, Loss: 0.0190\n",
      "Epoch 128/200, Iteration 166/250, Loss: 0.0325\n",
      "Epoch 128/200, Iteration 167/250, Loss: 0.0200\n",
      "Epoch 128/200, Iteration 168/250, Loss: 0.0118\n",
      "Epoch 128/200, Iteration 169/250, Loss: 0.0155\n",
      "Epoch 128/200, Iteration 170/250, Loss: 0.0304\n",
      "Epoch 128/200, Iteration 171/250, Loss: 0.0075\n",
      "Epoch 128/200, Iteration 172/250, Loss: 0.0119\n",
      "Epoch 128/200, Iteration 173/250, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 174/250, Loss: 0.0184\n",
      "Epoch 128/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 176/250, Loss: 0.0350\n",
      "Epoch 128/200, Iteration 177/250, Loss: 0.0093\n",
      "Epoch 128/200, Iteration 178/250, Loss: 0.0283\n",
      "Epoch 128/200, Iteration 179/250, Loss: 0.0091\n",
      "Epoch 128/200, Iteration 180/250, Loss: 0.0194\n",
      "Epoch 128/200, Iteration 181/250, Loss: 0.0100\n",
      "Epoch 128/200, Iteration 182/250, Loss: 0.0119\n",
      "Epoch 128/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 184/250, Loss: 0.0107\n",
      "Epoch 128/200, Iteration 185/250, Loss: 0.0113\n",
      "Epoch 128/200, Iteration 186/250, Loss: 0.0163\n",
      "Epoch 128/200, Iteration 187/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 188/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 189/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 190/250, Loss: 0.0080\n",
      "Epoch 128/200, Iteration 191/250, Loss: 0.0085\n",
      "Epoch 128/200, Iteration 192/250, Loss: 0.0124\n",
      "Epoch 128/200, Iteration 193/250, Loss: 0.0090\n",
      "Epoch 128/200, Iteration 194/250, Loss: 0.0257\n",
      "Epoch 128/200, Iteration 195/250, Loss: 0.0227\n",
      "Epoch 128/200, Iteration 196/250, Loss: 0.0135\n",
      "Epoch 128/200, Iteration 197/250, Loss: 0.0189\n",
      "Epoch 128/200, Iteration 198/250, Loss: 0.0170\n",
      "Epoch 128/200, Iteration 199/250, Loss: 0.0162\n",
      "Epoch 128/200, Iteration 200/250, Loss: 0.0092\n",
      "Epoch 128/200, Iteration 201/250, Loss: 0.0231\n",
      "Epoch 128/200, Iteration 202/250, Loss: 0.0181\n",
      "Epoch 128/200, Iteration 203/250, Loss: 0.0167\n",
      "Epoch 128/200, Iteration 204/250, Loss: 0.0121\n",
      "Epoch 128/200, Iteration 205/250, Loss: 0.0146\n",
      "Epoch 128/200, Iteration 206/250, Loss: 0.0151\n",
      "Epoch 128/200, Iteration 207/250, Loss: 0.0147\n",
      "Epoch 128/200, Iteration 208/250, Loss: 0.0105\n",
      "Epoch 128/200, Iteration 209/250, Loss: 0.0122\n",
      "Epoch 128/200, Iteration 210/250, Loss: 0.0104\n",
      "Epoch 128/200, Iteration 211/250, Loss: 0.0087\n",
      "Epoch 128/200, Iteration 212/250, Loss: 0.0095\n",
      "Epoch 128/200, Iteration 213/250, Loss: 0.0105\n",
      "Epoch 128/200, Iteration 214/250, Loss: 0.0097\n",
      "Epoch 128/200, Iteration 215/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 216/250, Loss: 0.0095\n",
      "Epoch 128/200, Iteration 217/250, Loss: 0.0143\n",
      "Epoch 128/200, Iteration 218/250, Loss: 0.0081\n",
      "Epoch 128/200, Iteration 219/250, Loss: 0.0210\n",
      "Epoch 128/200, Iteration 220/250, Loss: 0.0106\n",
      "Epoch 128/200, Iteration 221/250, Loss: 0.0310\n",
      "Epoch 128/200, Iteration 222/250, Loss: 0.0254\n",
      "Epoch 128/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 128/200, Iteration 224/250, Loss: 0.0164\n",
      "Epoch 128/200, Iteration 225/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 226/250, Loss: 0.0227\n",
      "Epoch 128/200, Iteration 227/250, Loss: 0.0161\n",
      "Epoch 128/200, Iteration 228/250, Loss: 0.0141\n",
      "Epoch 128/200, Iteration 229/250, Loss: 0.0178\n",
      "Epoch 128/200, Iteration 230/250, Loss: 0.0159\n",
      "Epoch 128/200, Iteration 231/250, Loss: 0.0224\n",
      "Epoch 128/200, Iteration 232/250, Loss: 0.0265\n",
      "Epoch 128/200, Iteration 233/250, Loss: 0.0083\n",
      "Epoch 128/200, Iteration 234/250, Loss: 0.0237\n",
      "Epoch 128/200, Iteration 235/250, Loss: 0.0127\n",
      "Epoch 128/200, Iteration 236/250, Loss: 0.0260\n",
      "Epoch 128/200, Iteration 237/250, Loss: 0.0143\n",
      "Epoch 128/200, Iteration 238/250, Loss: 0.0114\n",
      "Epoch 128/200, Iteration 239/250, Loss: 0.0105\n",
      "Epoch 128/200, Iteration 240/250, Loss: 0.0155\n",
      "Epoch 128/200, Iteration 241/250, Loss: 0.0105\n",
      "Epoch 128/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 128/200, Iteration 243/250, Loss: 0.0183\n",
      "Epoch 128/200, Iteration 244/250, Loss: 0.0138\n",
      "Epoch 128/200, Iteration 245/250, Loss: 0.0101\n",
      "Epoch 128/200, Iteration 246/250, Loss: 0.0129\n",
      "Epoch 128/200, Iteration 247/250, Loss: 0.0205\n",
      "Epoch 128/200, Iteration 248/250, Loss: 0.0128\n",
      "Epoch 128/200, Iteration 249/250, Loss: 0.0142\n",
      "Epoch 128/200, Iteration 250/250, Loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 82.34%, Avg loss: 0.007013, MRE: 0.454424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.007510, MRE: 0.576680 \n",
      "\n",
      "Epoch 129/200, Iteration 1/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 2/250, Loss: 0.0306\n",
      "Epoch 129/200, Iteration 3/250, Loss: 0.0076\n",
      "Epoch 129/200, Iteration 4/250, Loss: 0.0134\n",
      "Epoch 129/200, Iteration 5/250, Loss: 0.0279\n",
      "Epoch 129/200, Iteration 6/250, Loss: 0.0217\n",
      "Epoch 129/200, Iteration 7/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 8/250, Loss: 0.0080\n",
      "Epoch 129/200, Iteration 9/250, Loss: 0.0316\n",
      "Epoch 129/200, Iteration 10/250, Loss: 0.0203\n",
      "Epoch 129/200, Iteration 11/250, Loss: 0.0160\n",
      "Epoch 129/200, Iteration 12/250, Loss: 0.0369\n",
      "Epoch 129/200, Iteration 13/250, Loss: 0.0153\n",
      "Epoch 129/200, Iteration 14/250, Loss: 0.0062\n",
      "Epoch 129/200, Iteration 15/250, Loss: 0.0121\n",
      "Epoch 129/200, Iteration 16/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 17/250, Loss: 0.0207\n",
      "Epoch 129/200, Iteration 18/250, Loss: 0.0173\n",
      "Epoch 129/200, Iteration 19/250, Loss: 0.0111\n",
      "Epoch 129/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 129/200, Iteration 21/250, Loss: 0.0119\n",
      "Epoch 129/200, Iteration 22/250, Loss: 0.0140\n",
      "Epoch 129/200, Iteration 23/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 24/250, Loss: 0.0224\n",
      "Epoch 129/200, Iteration 25/250, Loss: 0.0123\n",
      "Epoch 129/200, Iteration 26/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 27/250, Loss: 0.0190\n",
      "Epoch 129/200, Iteration 28/250, Loss: 0.0284\n",
      "Epoch 129/200, Iteration 29/250, Loss: 0.0187\n",
      "Epoch 129/200, Iteration 30/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 31/250, Loss: 0.0150\n",
      "Epoch 129/200, Iteration 32/250, Loss: 0.0071\n",
      "Epoch 129/200, Iteration 33/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 34/250, Loss: 0.0189\n",
      "Epoch 129/200, Iteration 35/250, Loss: 0.0120\n",
      "Epoch 129/200, Iteration 36/250, Loss: 0.0123\n",
      "Epoch 129/200, Iteration 37/250, Loss: 0.0085\n",
      "Epoch 129/200, Iteration 38/250, Loss: 0.0241\n",
      "Epoch 129/200, Iteration 39/250, Loss: 0.0326\n",
      "Epoch 129/200, Iteration 40/250, Loss: 0.0190\n",
      "Epoch 129/200, Iteration 41/250, Loss: 0.0097\n",
      "Epoch 129/200, Iteration 42/250, Loss: 0.0115\n",
      "Epoch 129/200, Iteration 43/250, Loss: 0.0191\n",
      "Epoch 129/200, Iteration 44/250, Loss: 0.0178\n",
      "Epoch 129/200, Iteration 45/250, Loss: 0.0063\n",
      "Epoch 129/200, Iteration 46/250, Loss: 0.0276\n",
      "Epoch 129/200, Iteration 47/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 48/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 49/250, Loss: 0.0105\n",
      "Epoch 129/200, Iteration 50/250, Loss: 0.0169\n",
      "Epoch 129/200, Iteration 51/250, Loss: 0.0070\n",
      "Epoch 129/200, Iteration 52/250, Loss: 0.0086\n",
      "Epoch 129/200, Iteration 53/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 54/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 56/250, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 57/250, Loss: 0.0182\n",
      "Epoch 129/200, Iteration 58/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 59/250, Loss: 0.0121\n",
      "Epoch 129/200, Iteration 60/250, Loss: 0.0104\n",
      "Epoch 129/200, Iteration 61/250, Loss: 0.0147\n",
      "Epoch 129/200, Iteration 62/250, Loss: 0.0130\n",
      "Epoch 129/200, Iteration 63/250, Loss: 0.0144\n",
      "Epoch 129/200, Iteration 64/250, Loss: 0.0109\n",
      "Epoch 129/200, Iteration 65/250, Loss: 0.0223\n",
      "Epoch 129/200, Iteration 66/250, Loss: 0.0235\n",
      "Epoch 129/200, Iteration 67/250, Loss: 0.0169\n",
      "Epoch 129/200, Iteration 68/250, Loss: 0.0151\n",
      "Epoch 129/200, Iteration 69/250, Loss: 0.0242\n",
      "Epoch 129/200, Iteration 70/250, Loss: 0.0183\n",
      "Epoch 129/200, Iteration 71/250, Loss: 0.0207\n",
      "Epoch 129/200, Iteration 72/250, Loss: 0.0202\n",
      "Epoch 129/200, Iteration 73/250, Loss: 0.0242\n",
      "Epoch 129/200, Iteration 74/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 75/250, Loss: 0.0146\n",
      "Epoch 129/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 129/200, Iteration 77/250, Loss: 0.0235\n",
      "Epoch 129/200, Iteration 78/250, Loss: 0.0106\n",
      "Epoch 129/200, Iteration 79/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 80/250, Loss: 0.0175\n",
      "Epoch 129/200, Iteration 81/250, Loss: 0.0107\n",
      "Epoch 129/200, Iteration 82/250, Loss: 0.0193\n",
      "Epoch 129/200, Iteration 83/250, Loss: 0.0161\n",
      "Epoch 129/200, Iteration 84/250, Loss: 0.0160\n",
      "Epoch 129/200, Iteration 85/250, Loss: 0.0317\n",
      "Epoch 129/200, Iteration 86/250, Loss: 0.0121\n",
      "Epoch 129/200, Iteration 87/250, Loss: 0.0208\n",
      "Epoch 129/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 129/200, Iteration 89/250, Loss: 0.0111\n",
      "Epoch 129/200, Iteration 90/250, Loss: 0.0096\n",
      "Epoch 129/200, Iteration 91/250, Loss: 0.0191\n",
      "Epoch 129/200, Iteration 92/250, Loss: 0.0219\n",
      "Epoch 129/200, Iteration 93/250, Loss: 0.0072\n",
      "Epoch 129/200, Iteration 94/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 95/250, Loss: 0.0213\n",
      "Epoch 129/200, Iteration 96/250, Loss: 0.0215\n",
      "Epoch 129/200, Iteration 97/250, Loss: 0.0163\n",
      "Epoch 129/200, Iteration 98/250, Loss: 0.0116\n",
      "Epoch 129/200, Iteration 99/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 100/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 101/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 102/250, Loss: 0.0083\n",
      "Epoch 129/200, Iteration 103/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 104/250, Loss: 0.0255\n",
      "Epoch 129/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 106/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 107/250, Loss: 0.0109\n",
      "Epoch 129/200, Iteration 108/250, Loss: 0.0204\n",
      "Epoch 129/200, Iteration 109/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 110/250, Loss: 0.0242\n",
      "Epoch 129/200, Iteration 111/250, Loss: 0.0160\n",
      "Epoch 129/200, Iteration 112/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 113/250, Loss: 0.0277\n",
      "Epoch 129/200, Iteration 114/250, Loss: 0.0096\n",
      "Epoch 129/200, Iteration 115/250, Loss: 0.0239\n",
      "Epoch 129/200, Iteration 116/250, Loss: 0.0106\n",
      "Epoch 129/200, Iteration 117/250, Loss: 0.0357\n",
      "Epoch 129/200, Iteration 118/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 119/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 120/250, Loss: 0.0128\n",
      "Epoch 129/200, Iteration 121/250, Loss: 0.0273\n",
      "Epoch 129/200, Iteration 122/250, Loss: 0.0218\n",
      "Epoch 129/200, Iteration 123/250, Loss: 0.0084\n",
      "Epoch 129/200, Iteration 124/250, Loss: 0.0089\n",
      "Epoch 129/200, Iteration 125/250, Loss: 0.0219\n",
      "Epoch 129/200, Iteration 126/250, Loss: 0.0127\n",
      "Epoch 129/200, Iteration 127/250, Loss: 0.0133\n",
      "Epoch 129/200, Iteration 128/250, Loss: 0.0118\n",
      "Epoch 129/200, Iteration 129/250, Loss: 0.0133\n",
      "Epoch 129/200, Iteration 130/250, Loss: 0.0222\n",
      "Epoch 129/200, Iteration 131/250, Loss: 0.0154\n",
      "Epoch 129/200, Iteration 132/250, Loss: 0.0340\n",
      "Epoch 129/200, Iteration 133/250, Loss: 0.0237\n",
      "Epoch 129/200, Iteration 134/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 135/250, Loss: 0.0077\n",
      "Epoch 129/200, Iteration 136/250, Loss: 0.0182\n",
      "Epoch 129/200, Iteration 137/250, Loss: 0.0261\n",
      "Epoch 129/200, Iteration 138/250, Loss: 0.0225\n",
      "Epoch 129/200, Iteration 139/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 140/250, Loss: 0.0113\n",
      "Epoch 129/200, Iteration 141/250, Loss: 0.0152\n",
      "Epoch 129/200, Iteration 142/250, Loss: 0.0264\n",
      "Epoch 129/200, Iteration 143/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 144/250, Loss: 0.0102\n",
      "Epoch 129/200, Iteration 145/250, Loss: 0.0114\n",
      "Epoch 129/200, Iteration 146/250, Loss: 0.0149\n",
      "Epoch 129/200, Iteration 147/250, Loss: 0.0070\n",
      "Epoch 129/200, Iteration 148/250, Loss: 0.0100\n",
      "Epoch 129/200, Iteration 149/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 150/250, Loss: 0.0192\n",
      "Epoch 129/200, Iteration 151/250, Loss: 0.0216\n",
      "Epoch 129/200, Iteration 152/250, Loss: 0.0138\n",
      "Epoch 129/200, Iteration 153/250, Loss: 0.0353\n",
      "Epoch 129/200, Iteration 154/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 155/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 156/250, Loss: 0.0247\n",
      "Epoch 129/200, Iteration 157/250, Loss: 0.0073\n",
      "Epoch 129/200, Iteration 158/250, Loss: 0.0104\n",
      "Epoch 129/200, Iteration 159/250, Loss: 0.0098\n",
      "Epoch 129/200, Iteration 160/250, Loss: 0.0164\n",
      "Epoch 129/200, Iteration 161/250, Loss: 0.0217\n",
      "Epoch 129/200, Iteration 162/250, Loss: 0.0160\n",
      "Epoch 129/200, Iteration 163/250, Loss: 0.0184\n",
      "Epoch 129/200, Iteration 164/250, Loss: 0.0090\n",
      "Epoch 129/200, Iteration 165/250, Loss: 0.0159\n",
      "Epoch 129/200, Iteration 166/250, Loss: 0.0404\n",
      "Epoch 129/200, Iteration 167/250, Loss: 0.0227\n",
      "Epoch 129/200, Iteration 168/250, Loss: 0.0233\n",
      "Epoch 129/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 170/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 171/250, Loss: 0.0175\n",
      "Epoch 129/200, Iteration 172/250, Loss: 0.0085\n",
      "Epoch 129/200, Iteration 173/250, Loss: 0.0087\n",
      "Epoch 129/200, Iteration 174/250, Loss: 0.0166\n",
      "Epoch 129/200, Iteration 175/250, Loss: 0.0222\n",
      "Epoch 129/200, Iteration 176/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 177/250, Loss: 0.0106\n",
      "Epoch 129/200, Iteration 178/250, Loss: 0.0138\n",
      "Epoch 129/200, Iteration 179/250, Loss: 0.0124\n",
      "Epoch 129/200, Iteration 180/250, Loss: 0.0092\n",
      "Epoch 129/200, Iteration 181/250, Loss: 0.0071\n",
      "Epoch 129/200, Iteration 182/250, Loss: 0.0185\n",
      "Epoch 129/200, Iteration 183/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 184/250, Loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200, Iteration 185/250, Loss: 0.0185\n",
      "Epoch 129/200, Iteration 186/250, Loss: 0.0122\n",
      "Epoch 129/200, Iteration 187/250, Loss: 0.0078\n",
      "Epoch 129/200, Iteration 188/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 189/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 190/250, Loss: 0.0164\n",
      "Epoch 129/200, Iteration 191/250, Loss: 0.0121\n",
      "Epoch 129/200, Iteration 192/250, Loss: 0.0329\n",
      "Epoch 129/200, Iteration 193/250, Loss: 0.0127\n",
      "Epoch 129/200, Iteration 194/250, Loss: 0.0151\n",
      "Epoch 129/200, Iteration 195/250, Loss: 0.0128\n",
      "Epoch 129/200, Iteration 196/250, Loss: 0.0088\n",
      "Epoch 129/200, Iteration 197/250, Loss: 0.0222\n",
      "Epoch 129/200, Iteration 198/250, Loss: 0.0093\n",
      "Epoch 129/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 129/200, Iteration 200/250, Loss: 0.0340\n",
      "Epoch 129/200, Iteration 201/250, Loss: 0.0094\n",
      "Epoch 129/200, Iteration 202/250, Loss: 0.0114\n",
      "Epoch 129/200, Iteration 203/250, Loss: 0.0210\n",
      "Epoch 129/200, Iteration 204/250, Loss: 0.0091\n",
      "Epoch 129/200, Iteration 205/250, Loss: 0.0320\n",
      "Epoch 129/200, Iteration 206/250, Loss: 0.0112\n",
      "Epoch 129/200, Iteration 207/250, Loss: 0.0082\n",
      "Epoch 129/200, Iteration 208/250, Loss: 0.0263\n",
      "Epoch 129/200, Iteration 209/250, Loss: 0.0176\n",
      "Epoch 129/200, Iteration 210/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 211/250, Loss: 0.0415\n",
      "Epoch 129/200, Iteration 212/250, Loss: 0.0175\n",
      "Epoch 129/200, Iteration 213/250, Loss: 0.0128\n",
      "Epoch 129/200, Iteration 214/250, Loss: 0.0127\n",
      "Epoch 129/200, Iteration 215/250, Loss: 0.0096\n",
      "Epoch 129/200, Iteration 216/250, Loss: 0.0118\n",
      "Epoch 129/200, Iteration 217/250, Loss: 0.0127\n",
      "Epoch 129/200, Iteration 218/250, Loss: 0.0136\n",
      "Epoch 129/200, Iteration 219/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 220/250, Loss: 0.0073\n",
      "Epoch 129/200, Iteration 221/250, Loss: 0.0269\n",
      "Epoch 129/200, Iteration 222/250, Loss: 0.0129\n",
      "Epoch 129/200, Iteration 223/250, Loss: 0.0374\n",
      "Epoch 129/200, Iteration 224/250, Loss: 0.0412\n",
      "Epoch 129/200, Iteration 225/250, Loss: 0.0150\n",
      "Epoch 129/200, Iteration 226/250, Loss: 0.0122\n",
      "Epoch 129/200, Iteration 227/250, Loss: 0.0296\n",
      "Epoch 129/200, Iteration 228/250, Loss: 0.0118\n",
      "Epoch 129/200, Iteration 229/250, Loss: 0.0142\n",
      "Epoch 129/200, Iteration 230/250, Loss: 0.0241\n",
      "Epoch 129/200, Iteration 231/250, Loss: 0.0156\n",
      "Epoch 129/200, Iteration 232/250, Loss: 0.0309\n",
      "Epoch 129/200, Iteration 233/250, Loss: 0.0138\n",
      "Epoch 129/200, Iteration 234/250, Loss: 0.0167\n",
      "Epoch 129/200, Iteration 235/250, Loss: 0.0214\n",
      "Epoch 129/200, Iteration 236/250, Loss: 0.0103\n",
      "Epoch 129/200, Iteration 237/250, Loss: 0.0063\n",
      "Epoch 129/200, Iteration 238/250, Loss: 0.0212\n",
      "Epoch 129/200, Iteration 239/250, Loss: 0.0155\n",
      "Epoch 129/200, Iteration 240/250, Loss: 0.0124\n",
      "Epoch 129/200, Iteration 241/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 242/250, Loss: 0.0197\n",
      "Epoch 129/200, Iteration 243/250, Loss: 0.0075\n",
      "Epoch 129/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 129/200, Iteration 245/250, Loss: 0.0075\n",
      "Epoch 129/200, Iteration 246/250, Loss: 0.0192\n",
      "Epoch 129/200, Iteration 247/250, Loss: 0.0108\n",
      "Epoch 129/200, Iteration 248/250, Loss: 0.0203\n",
      "Epoch 129/200, Iteration 249/250, Loss: 0.0160\n",
      "Epoch 129/200, Iteration 250/250, Loss: 0.0121\n",
      "Train Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.006885, MRE: 0.442880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.85%, Avg loss: 0.007382, MRE: 0.512443 \n",
      "\n",
      "Epoch 130/200, Iteration 1/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 2/250, Loss: 0.0193\n",
      "Epoch 130/200, Iteration 3/250, Loss: 0.0101\n",
      "Epoch 130/200, Iteration 4/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 5/250, Loss: 0.0074\n",
      "Epoch 130/200, Iteration 6/250, Loss: 0.0123\n",
      "Epoch 130/200, Iteration 7/250, Loss: 0.0093\n",
      "Epoch 130/200, Iteration 8/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 9/250, Loss: 0.0429\n",
      "Epoch 130/200, Iteration 10/250, Loss: 0.0406\n",
      "Epoch 130/200, Iteration 11/250, Loss: 0.0203\n",
      "Epoch 130/200, Iteration 12/250, Loss: 0.0189\n",
      "Epoch 130/200, Iteration 13/250, Loss: 0.0135\n",
      "Epoch 130/200, Iteration 14/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 15/250, Loss: 0.0138\n",
      "Epoch 130/200, Iteration 16/250, Loss: 0.0291\n",
      "Epoch 130/200, Iteration 17/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 18/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 19/250, Loss: 0.0280\n",
      "Epoch 130/200, Iteration 20/250, Loss: 0.0095\n",
      "Epoch 130/200, Iteration 21/250, Loss: 0.0212\n",
      "Epoch 130/200, Iteration 22/250, Loss: 0.0078\n",
      "Epoch 130/200, Iteration 23/250, Loss: 0.0078\n",
      "Epoch 130/200, Iteration 24/250, Loss: 0.0330\n",
      "Epoch 130/200, Iteration 25/250, Loss: 0.0109\n",
      "Epoch 130/200, Iteration 26/250, Loss: 0.0265\n",
      "Epoch 130/200, Iteration 27/250, Loss: 0.0118\n",
      "Epoch 130/200, Iteration 28/250, Loss: 0.0309\n",
      "Epoch 130/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 130/200, Iteration 30/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 31/250, Loss: 0.0270\n",
      "Epoch 130/200, Iteration 32/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 33/250, Loss: 0.0082\n",
      "Epoch 130/200, Iteration 34/250, Loss: 0.0151\n",
      "Epoch 130/200, Iteration 35/250, Loss: 0.0137\n",
      "Epoch 130/200, Iteration 36/250, Loss: 0.0241\n",
      "Epoch 130/200, Iteration 37/250, Loss: 0.0153\n",
      "Epoch 130/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 130/200, Iteration 39/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 40/250, Loss: 0.0222\n",
      "Epoch 130/200, Iteration 41/250, Loss: 0.0160\n",
      "Epoch 130/200, Iteration 42/250, Loss: 0.0156\n",
      "Epoch 130/200, Iteration 43/250, Loss: 0.0130\n",
      "Epoch 130/200, Iteration 44/250, Loss: 0.0141\n",
      "Epoch 130/200, Iteration 45/250, Loss: 0.0156\n",
      "Epoch 130/200, Iteration 46/250, Loss: 0.0324\n",
      "Epoch 130/200, Iteration 47/250, Loss: 0.0158\n",
      "Epoch 130/200, Iteration 48/250, Loss: 0.0163\n",
      "Epoch 130/200, Iteration 49/250, Loss: 0.0202\n",
      "Epoch 130/200, Iteration 50/250, Loss: 0.0310\n",
      "Epoch 130/200, Iteration 51/250, Loss: 0.0201\n",
      "Epoch 130/200, Iteration 52/250, Loss: 0.0141\n",
      "Epoch 130/200, Iteration 53/250, Loss: 0.0126\n",
      "Epoch 130/200, Iteration 54/250, Loss: 0.0256\n",
      "Epoch 130/200, Iteration 55/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 56/250, Loss: 0.0156\n",
      "Epoch 130/200, Iteration 57/250, Loss: 0.0153\n",
      "Epoch 130/200, Iteration 58/250, Loss: 0.0165\n",
      "Epoch 130/200, Iteration 59/250, Loss: 0.0103\n",
      "Epoch 130/200, Iteration 60/250, Loss: 0.0226\n",
      "Epoch 130/200, Iteration 61/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 62/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 63/250, Loss: 0.0171\n",
      "Epoch 130/200, Iteration 64/250, Loss: 0.0141\n",
      "Epoch 130/200, Iteration 65/250, Loss: 0.0139\n",
      "Epoch 130/200, Iteration 66/250, Loss: 0.0151\n",
      "Epoch 130/200, Iteration 67/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 68/250, Loss: 0.0119\n",
      "Epoch 130/200, Iteration 69/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 70/250, Loss: 0.0061\n",
      "Epoch 130/200, Iteration 71/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 72/250, Loss: 0.0185\n",
      "Epoch 130/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 130/200, Iteration 74/250, Loss: 0.0118\n",
      "Epoch 130/200, Iteration 75/250, Loss: 0.0087\n",
      "Epoch 130/200, Iteration 76/250, Loss: 0.0246\n",
      "Epoch 130/200, Iteration 77/250, Loss: 0.0120\n",
      "Epoch 130/200, Iteration 78/250, Loss: 0.0106\n",
      "Epoch 130/200, Iteration 79/250, Loss: 0.0168\n",
      "Epoch 130/200, Iteration 80/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 81/250, Loss: 0.0340\n",
      "Epoch 130/200, Iteration 82/250, Loss: 0.0127\n",
      "Epoch 130/200, Iteration 83/250, Loss: 0.0121\n",
      "Epoch 130/200, Iteration 84/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 86/250, Loss: 0.0124\n",
      "Epoch 130/200, Iteration 87/250, Loss: 0.0148\n",
      "Epoch 130/200, Iteration 88/250, Loss: 0.0086\n",
      "Epoch 130/200, Iteration 89/250, Loss: 0.0128\n",
      "Epoch 130/200, Iteration 90/250, Loss: 0.0097\n",
      "Epoch 130/200, Iteration 91/250, Loss: 0.0153\n",
      "Epoch 130/200, Iteration 92/250, Loss: 0.0071\n",
      "Epoch 130/200, Iteration 93/250, Loss: 0.0140\n",
      "Epoch 130/200, Iteration 94/250, Loss: 0.0306\n",
      "Epoch 130/200, Iteration 95/250, Loss: 0.0150\n",
      "Epoch 130/200, Iteration 96/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 97/250, Loss: 0.0059\n",
      "Epoch 130/200, Iteration 98/250, Loss: 0.0134\n",
      "Epoch 130/200, Iteration 99/250, Loss: 0.0072\n",
      "Epoch 130/200, Iteration 100/250, Loss: 0.0125\n",
      "Epoch 130/200, Iteration 101/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 102/250, Loss: 0.0358\n",
      "Epoch 130/200, Iteration 103/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 104/250, Loss: 0.0387\n",
      "Epoch 130/200, Iteration 105/250, Loss: 0.0251\n",
      "Epoch 130/200, Iteration 106/250, Loss: 0.0096\n",
      "Epoch 130/200, Iteration 107/250, Loss: 0.0243\n",
      "Epoch 130/200, Iteration 108/250, Loss: 0.0189\n",
      "Epoch 130/200, Iteration 109/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 130/200, Iteration 111/250, Loss: 0.0165\n",
      "Epoch 130/200, Iteration 112/250, Loss: 0.0087\n",
      "Epoch 130/200, Iteration 113/250, Loss: 0.0117\n",
      "Epoch 130/200, Iteration 114/250, Loss: 0.0277\n",
      "Epoch 130/200, Iteration 115/250, Loss: 0.0078\n",
      "Epoch 130/200, Iteration 116/250, Loss: 0.0085\n",
      "Epoch 130/200, Iteration 117/250, Loss: 0.0280\n",
      "Epoch 130/200, Iteration 118/250, Loss: 0.0076\n",
      "Epoch 130/200, Iteration 119/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 120/250, Loss: 0.0151\n",
      "Epoch 130/200, Iteration 121/250, Loss: 0.0133\n",
      "Epoch 130/200, Iteration 122/250, Loss: 0.0161\n",
      "Epoch 130/200, Iteration 123/250, Loss: 0.0285\n",
      "Epoch 130/200, Iteration 124/250, Loss: 0.0136\n",
      "Epoch 130/200, Iteration 125/250, Loss: 0.0161\n",
      "Epoch 130/200, Iteration 126/250, Loss: 0.0114\n",
      "Epoch 130/200, Iteration 127/250, Loss: 0.0065\n",
      "Epoch 130/200, Iteration 128/250, Loss: 0.0059\n",
      "Epoch 130/200, Iteration 129/250, Loss: 0.0260\n",
      "Epoch 130/200, Iteration 130/250, Loss: 0.0159\n",
      "Epoch 130/200, Iteration 131/250, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200, Iteration 132/250, Loss: 0.0105\n",
      "Epoch 130/200, Iteration 133/250, Loss: 0.0199\n",
      "Epoch 130/200, Iteration 134/250, Loss: 0.0236\n",
      "Epoch 130/200, Iteration 135/250, Loss: 0.0111\n",
      "Epoch 130/200, Iteration 136/250, Loss: 0.0197\n",
      "Epoch 130/200, Iteration 137/250, Loss: 0.0123\n",
      "Epoch 130/200, Iteration 138/250, Loss: 0.0140\n",
      "Epoch 130/200, Iteration 139/250, Loss: 0.0108\n",
      "Epoch 130/200, Iteration 140/250, Loss: 0.0413\n",
      "Epoch 130/200, Iteration 141/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 142/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 143/250, Loss: 0.0157\n",
      "Epoch 130/200, Iteration 144/250, Loss: 0.0105\n",
      "Epoch 130/200, Iteration 145/250, Loss: 0.0135\n",
      "Epoch 130/200, Iteration 146/250, Loss: 0.0119\n",
      "Epoch 130/200, Iteration 147/250, Loss: 0.0116\n",
      "Epoch 130/200, Iteration 148/250, Loss: 0.0083\n",
      "Epoch 130/200, Iteration 149/250, Loss: 0.0274\n",
      "Epoch 130/200, Iteration 150/250, Loss: 0.0134\n",
      "Epoch 130/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 130/200, Iteration 152/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 153/250, Loss: 0.0130\n",
      "Epoch 130/200, Iteration 154/250, Loss: 0.0172\n",
      "Epoch 130/200, Iteration 155/250, Loss: 0.0096\n",
      "Epoch 130/200, Iteration 156/250, Loss: 0.0117\n",
      "Epoch 130/200, Iteration 157/250, Loss: 0.0088\n",
      "Epoch 130/200, Iteration 158/250, Loss: 0.0209\n",
      "Epoch 130/200, Iteration 159/250, Loss: 0.0184\n",
      "Epoch 130/200, Iteration 160/250, Loss: 0.0096\n",
      "Epoch 130/200, Iteration 161/250, Loss: 0.0082\n",
      "Epoch 130/200, Iteration 162/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 163/250, Loss: 0.0254\n",
      "Epoch 130/200, Iteration 164/250, Loss: 0.0114\n",
      "Epoch 130/200, Iteration 165/250, Loss: 0.0293\n",
      "Epoch 130/200, Iteration 166/250, Loss: 0.0432\n",
      "Epoch 130/200, Iteration 167/250, Loss: 0.0094\n",
      "Epoch 130/200, Iteration 168/250, Loss: 0.0120\n",
      "Epoch 130/200, Iteration 169/250, Loss: 0.0103\n",
      "Epoch 130/200, Iteration 170/250, Loss: 0.0289\n",
      "Epoch 130/200, Iteration 171/250, Loss: 0.0273\n",
      "Epoch 130/200, Iteration 172/250, Loss: 0.0243\n",
      "Epoch 130/200, Iteration 173/250, Loss: 0.0142\n",
      "Epoch 130/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 175/250, Loss: 0.0166\n",
      "Epoch 130/200, Iteration 176/250, Loss: 0.0239\n",
      "Epoch 130/200, Iteration 177/250, Loss: 0.0161\n",
      "Epoch 130/200, Iteration 178/250, Loss: 0.0187\n",
      "Epoch 130/200, Iteration 179/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 180/250, Loss: 0.0171\n",
      "Epoch 130/200, Iteration 181/250, Loss: 0.0378\n",
      "Epoch 130/200, Iteration 182/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 183/250, Loss: 0.0418\n",
      "Epoch 130/200, Iteration 184/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 185/250, Loss: 0.0104\n",
      "Epoch 130/200, Iteration 186/250, Loss: 0.0089\n",
      "Epoch 130/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 130/200, Iteration 188/250, Loss: 0.0121\n",
      "Epoch 130/200, Iteration 189/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 190/250, Loss: 0.0077\n",
      "Epoch 130/200, Iteration 191/250, Loss: 0.0271\n",
      "Epoch 130/200, Iteration 192/250, Loss: 0.0115\n",
      "Epoch 130/200, Iteration 193/250, Loss: 0.0268\n",
      "Epoch 130/200, Iteration 194/250, Loss: 0.0118\n",
      "Epoch 130/200, Iteration 195/250, Loss: 0.0187\n",
      "Epoch 130/200, Iteration 196/250, Loss: 0.0407\n",
      "Epoch 130/200, Iteration 197/250, Loss: 0.0228\n",
      "Epoch 130/200, Iteration 198/250, Loss: 0.0080\n",
      "Epoch 130/200, Iteration 199/250, Loss: 0.0123\n",
      "Epoch 130/200, Iteration 200/250, Loss: 0.0069\n",
      "Epoch 130/200, Iteration 201/250, Loss: 0.0125\n",
      "Epoch 130/200, Iteration 202/250, Loss: 0.0094\n",
      "Epoch 130/200, Iteration 203/250, Loss: 0.0136\n",
      "Epoch 130/200, Iteration 204/250, Loss: 0.0157\n",
      "Epoch 130/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 206/250, Loss: 0.0169\n",
      "Epoch 130/200, Iteration 207/250, Loss: 0.0269\n",
      "Epoch 130/200, Iteration 208/250, Loss: 0.0114\n",
      "Epoch 130/200, Iteration 209/250, Loss: 0.0079\n",
      "Epoch 130/200, Iteration 210/250, Loss: 0.0082\n",
      "Epoch 130/200, Iteration 211/250, Loss: 0.0090\n",
      "Epoch 130/200, Iteration 212/250, Loss: 0.0142\n",
      "Epoch 130/200, Iteration 213/250, Loss: 0.0080\n",
      "Epoch 130/200, Iteration 214/250, Loss: 0.0167\n",
      "Epoch 130/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 130/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 130/200, Iteration 217/250, Loss: 0.0322\n",
      "Epoch 130/200, Iteration 218/250, Loss: 0.0178\n",
      "Epoch 130/200, Iteration 219/250, Loss: 0.0264\n",
      "Epoch 130/200, Iteration 220/250, Loss: 0.0254\n",
      "Epoch 130/200, Iteration 221/250, Loss: 0.0252\n",
      "Epoch 130/200, Iteration 222/250, Loss: 0.0072\n",
      "Epoch 130/200, Iteration 223/250, Loss: 0.0092\n",
      "Epoch 130/200, Iteration 224/250, Loss: 0.0095\n",
      "Epoch 130/200, Iteration 225/250, Loss: 0.0099\n",
      "Epoch 130/200, Iteration 226/250, Loss: 0.0117\n",
      "Epoch 130/200, Iteration 227/250, Loss: 0.0163\n",
      "Epoch 130/200, Iteration 228/250, Loss: 0.0106\n",
      "Epoch 130/200, Iteration 229/250, Loss: 0.0189\n",
      "Epoch 130/200, Iteration 230/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 231/250, Loss: 0.0282\n",
      "Epoch 130/200, Iteration 232/250, Loss: 0.0081\n",
      "Epoch 130/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 130/200, Iteration 234/250, Loss: 0.0135\n",
      "Epoch 130/200, Iteration 235/250, Loss: 0.0310\n",
      "Epoch 130/200, Iteration 236/250, Loss: 0.0093\n",
      "Epoch 130/200, Iteration 237/250, Loss: 0.0156\n",
      "Epoch 130/200, Iteration 238/250, Loss: 0.0107\n",
      "Epoch 130/200, Iteration 239/250, Loss: 0.0126\n",
      "Epoch 130/200, Iteration 240/250, Loss: 0.0276\n",
      "Epoch 130/200, Iteration 241/250, Loss: 0.0110\n",
      "Epoch 130/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 130/200, Iteration 243/250, Loss: 0.0107\n",
      "Epoch 130/200, Iteration 244/250, Loss: 0.0162\n",
      "Epoch 130/200, Iteration 245/250, Loss: 0.0122\n",
      "Epoch 130/200, Iteration 246/250, Loss: 0.0091\n",
      "Epoch 130/200, Iteration 247/250, Loss: 0.0206\n",
      "Epoch 130/200, Iteration 248/250, Loss: 0.0128\n",
      "Epoch 130/200, Iteration 249/250, Loss: 0.0120\n",
      "Epoch 130/200, Iteration 250/250, Loss: 0.0229\n",
      "Train Error: \n",
      " Accuracy: 87.09%, Avg loss: 0.006805, MRE: 0.429036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.007353, MRE: 0.520066 \n",
      "\n",
      "Epoch 131/200, Iteration 1/250, Loss: 0.0066\n",
      "Epoch 131/200, Iteration 2/250, Loss: 0.0190\n",
      "Epoch 131/200, Iteration 3/250, Loss: 0.0253\n",
      "Epoch 131/200, Iteration 4/250, Loss: 0.0169\n",
      "Epoch 131/200, Iteration 5/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 6/250, Loss: 0.0075\n",
      "Epoch 131/200, Iteration 7/250, Loss: 0.0288\n",
      "Epoch 131/200, Iteration 8/250, Loss: 0.0097\n",
      "Epoch 131/200, Iteration 9/250, Loss: 0.0319\n",
      "Epoch 131/200, Iteration 10/250, Loss: 0.0159\n",
      "Epoch 131/200, Iteration 11/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 12/250, Loss: 0.0075\n",
      "Epoch 131/200, Iteration 13/250, Loss: 0.0073\n",
      "Epoch 131/200, Iteration 14/250, Loss: 0.0070\n",
      "Epoch 131/200, Iteration 15/250, Loss: 0.0098\n",
      "Epoch 131/200, Iteration 16/250, Loss: 0.0122\n",
      "Epoch 131/200, Iteration 17/250, Loss: 0.0075\n",
      "Epoch 131/200, Iteration 18/250, Loss: 0.0080\n",
      "Epoch 131/200, Iteration 19/250, Loss: 0.0068\n",
      "Epoch 131/200, Iteration 20/250, Loss: 0.0160\n",
      "Epoch 131/200, Iteration 21/250, Loss: 0.0132\n",
      "Epoch 131/200, Iteration 22/250, Loss: 0.0143\n",
      "Epoch 131/200, Iteration 23/250, Loss: 0.0381\n",
      "Epoch 131/200, Iteration 24/250, Loss: 0.0055\n",
      "Epoch 131/200, Iteration 25/250, Loss: 0.0148\n",
      "Epoch 131/200, Iteration 26/250, Loss: 0.0249\n",
      "Epoch 131/200, Iteration 27/250, Loss: 0.0323\n",
      "Epoch 131/200, Iteration 28/250, Loss: 0.0176\n",
      "Epoch 131/200, Iteration 29/250, Loss: 0.0074\n",
      "Epoch 131/200, Iteration 30/250, Loss: 0.0136\n",
      "Epoch 131/200, Iteration 31/250, Loss: 0.0242\n",
      "Epoch 131/200, Iteration 32/250, Loss: 0.0073\n",
      "Epoch 131/200, Iteration 33/250, Loss: 0.0409\n",
      "Epoch 131/200, Iteration 34/250, Loss: 0.0159\n",
      "Epoch 131/200, Iteration 35/250, Loss: 0.0195\n",
      "Epoch 131/200, Iteration 36/250, Loss: 0.0133\n",
      "Epoch 131/200, Iteration 37/250, Loss: 0.0468\n",
      "Epoch 131/200, Iteration 38/250, Loss: 0.0113\n",
      "Epoch 131/200, Iteration 39/250, Loss: 0.0091\n",
      "Epoch 131/200, Iteration 40/250, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 41/250, Loss: 0.0057\n",
      "Epoch 131/200, Iteration 42/250, Loss: 0.0082\n",
      "Epoch 131/200, Iteration 43/250, Loss: 0.0175\n",
      "Epoch 131/200, Iteration 44/250, Loss: 0.0198\n",
      "Epoch 131/200, Iteration 45/250, Loss: 0.0403\n",
      "Epoch 131/200, Iteration 46/250, Loss: 0.0176\n",
      "Epoch 131/200, Iteration 47/250, Loss: 0.0103\n",
      "Epoch 131/200, Iteration 48/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 49/250, Loss: 0.0141\n",
      "Epoch 131/200, Iteration 50/250, Loss: 0.0143\n",
      "Epoch 131/200, Iteration 51/250, Loss: 0.0168\n",
      "Epoch 131/200, Iteration 52/250, Loss: 0.0071\n",
      "Epoch 131/200, Iteration 53/250, Loss: 0.0102\n",
      "Epoch 131/200, Iteration 54/250, Loss: 0.0125\n",
      "Epoch 131/200, Iteration 55/250, Loss: 0.0089\n",
      "Epoch 131/200, Iteration 56/250, Loss: 0.0137\n",
      "Epoch 131/200, Iteration 57/250, Loss: 0.0142\n",
      "Epoch 131/200, Iteration 58/250, Loss: 0.0166\n",
      "Epoch 131/200, Iteration 59/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 60/250, Loss: 0.0193\n",
      "Epoch 131/200, Iteration 61/250, Loss: 0.0098\n",
      "Epoch 131/200, Iteration 62/250, Loss: 0.0169\n",
      "Epoch 131/200, Iteration 63/250, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200, Iteration 64/250, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 65/250, Loss: 0.0297\n",
      "Epoch 131/200, Iteration 66/250, Loss: 0.0075\n",
      "Epoch 131/200, Iteration 67/250, Loss: 0.0077\n",
      "Epoch 131/200, Iteration 68/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 69/250, Loss: 0.0095\n",
      "Epoch 131/200, Iteration 70/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 71/250, Loss: 0.0215\n",
      "Epoch 131/200, Iteration 72/250, Loss: 0.0181\n",
      "Epoch 131/200, Iteration 73/250, Loss: 0.0077\n",
      "Epoch 131/200, Iteration 74/250, Loss: 0.0067\n",
      "Epoch 131/200, Iteration 75/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 76/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 77/250, Loss: 0.0166\n",
      "Epoch 131/200, Iteration 78/250, Loss: 0.0103\n",
      "Epoch 131/200, Iteration 79/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 80/250, Loss: 0.0210\n",
      "Epoch 131/200, Iteration 81/250, Loss: 0.0115\n",
      "Epoch 131/200, Iteration 82/250, Loss: 0.0105\n",
      "Epoch 131/200, Iteration 83/250, Loss: 0.0287\n",
      "Epoch 131/200, Iteration 84/250, Loss: 0.0169\n",
      "Epoch 131/200, Iteration 85/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 86/250, Loss: 0.0235\n",
      "Epoch 131/200, Iteration 87/250, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 88/250, Loss: 0.0072\n",
      "Epoch 131/200, Iteration 89/250, Loss: 0.0163\n",
      "Epoch 131/200, Iteration 90/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 91/250, Loss: 0.0157\n",
      "Epoch 131/200, Iteration 92/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 93/250, Loss: 0.0279\n",
      "Epoch 131/200, Iteration 94/250, Loss: 0.0083\n",
      "Epoch 131/200, Iteration 95/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 96/250, Loss: 0.0166\n",
      "Epoch 131/200, Iteration 97/250, Loss: 0.0120\n",
      "Epoch 131/200, Iteration 98/250, Loss: 0.0198\n",
      "Epoch 131/200, Iteration 99/250, Loss: 0.0083\n",
      "Epoch 131/200, Iteration 100/250, Loss: 0.0279\n",
      "Epoch 131/200, Iteration 101/250, Loss: 0.0408\n",
      "Epoch 131/200, Iteration 102/250, Loss: 0.0154\n",
      "Epoch 131/200, Iteration 103/250, Loss: 0.0124\n",
      "Epoch 131/200, Iteration 104/250, Loss: 0.0330\n",
      "Epoch 131/200, Iteration 105/250, Loss: 0.0199\n",
      "Epoch 131/200, Iteration 106/250, Loss: 0.0113\n",
      "Epoch 131/200, Iteration 107/250, Loss: 0.0129\n",
      "Epoch 131/200, Iteration 108/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 109/250, Loss: 0.0081\n",
      "Epoch 131/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 131/200, Iteration 111/250, Loss: 0.0141\n",
      "Epoch 131/200, Iteration 112/250, Loss: 0.0169\n",
      "Epoch 131/200, Iteration 113/250, Loss: 0.0056\n",
      "Epoch 131/200, Iteration 114/250, Loss: 0.0257\n",
      "Epoch 131/200, Iteration 115/250, Loss: 0.0085\n",
      "Epoch 131/200, Iteration 116/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 117/250, Loss: 0.0109\n",
      "Epoch 131/200, Iteration 118/250, Loss: 0.0117\n",
      "Epoch 131/200, Iteration 119/250, Loss: 0.0190\n",
      "Epoch 131/200, Iteration 120/250, Loss: 0.0240\n",
      "Epoch 131/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 131/200, Iteration 122/250, Loss: 0.0151\n",
      "Epoch 131/200, Iteration 123/250, Loss: 0.0103\n",
      "Epoch 131/200, Iteration 124/250, Loss: 0.0116\n",
      "Epoch 131/200, Iteration 125/250, Loss: 0.0224\n",
      "Epoch 131/200, Iteration 126/250, Loss: 0.0256\n",
      "Epoch 131/200, Iteration 127/250, Loss: 0.0128\n",
      "Epoch 131/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 129/250, Loss: 0.0178\n",
      "Epoch 131/200, Iteration 130/250, Loss: 0.0221\n",
      "Epoch 131/200, Iteration 131/250, Loss: 0.0095\n",
      "Epoch 131/200, Iteration 132/250, Loss: 0.0154\n",
      "Epoch 131/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 131/200, Iteration 134/250, Loss: 0.0167\n",
      "Epoch 131/200, Iteration 135/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 136/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 137/250, Loss: 0.0143\n",
      "Epoch 131/200, Iteration 138/250, Loss: 0.0225\n",
      "Epoch 131/200, Iteration 139/250, Loss: 0.0177\n",
      "Epoch 131/200, Iteration 140/250, Loss: 0.0106\n",
      "Epoch 131/200, Iteration 141/250, Loss: 0.0242\n",
      "Epoch 131/200, Iteration 142/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 143/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 144/250, Loss: 0.0079\n",
      "Epoch 131/200, Iteration 145/250, Loss: 0.0061\n",
      "Epoch 131/200, Iteration 146/250, Loss: 0.0207\n",
      "Epoch 131/200, Iteration 147/250, Loss: 0.0153\n",
      "Epoch 131/200, Iteration 148/250, Loss: 0.0142\n",
      "Epoch 131/200, Iteration 149/250, Loss: 0.0140\n",
      "Epoch 131/200, Iteration 150/250, Loss: 0.0138\n",
      "Epoch 131/200, Iteration 151/250, Loss: 0.0088\n",
      "Epoch 131/200, Iteration 152/250, Loss: 0.0178\n",
      "Epoch 131/200, Iteration 153/250, Loss: 0.0092\n",
      "Epoch 131/200, Iteration 154/250, Loss: 0.0193\n",
      "Epoch 131/200, Iteration 155/250, Loss: 0.0135\n",
      "Epoch 131/200, Iteration 156/250, Loss: 0.0197\n",
      "Epoch 131/200, Iteration 157/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 158/250, Loss: 0.0129\n",
      "Epoch 131/200, Iteration 159/250, Loss: 0.0264\n",
      "Epoch 131/200, Iteration 160/250, Loss: 0.0133\n",
      "Epoch 131/200, Iteration 161/250, Loss: 0.0139\n",
      "Epoch 131/200, Iteration 162/250, Loss: 0.0288\n",
      "Epoch 131/200, Iteration 163/250, Loss: 0.0277\n",
      "Epoch 131/200, Iteration 164/250, Loss: 0.0091\n",
      "Epoch 131/200, Iteration 165/250, Loss: 0.0167\n",
      "Epoch 131/200, Iteration 166/250, Loss: 0.0192\n",
      "Epoch 131/200, Iteration 167/250, Loss: 0.0232\n",
      "Epoch 131/200, Iteration 168/250, Loss: 0.0203\n",
      "Epoch 131/200, Iteration 169/250, Loss: 0.0068\n",
      "Epoch 131/200, Iteration 170/250, Loss: 0.0130\n",
      "Epoch 131/200, Iteration 171/250, Loss: 0.0129\n",
      "Epoch 131/200, Iteration 172/250, Loss: 0.0079\n",
      "Epoch 131/200, Iteration 173/250, Loss: 0.0090\n",
      "Epoch 131/200, Iteration 174/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 175/250, Loss: 0.0184\n",
      "Epoch 131/200, Iteration 176/250, Loss: 0.0146\n",
      "Epoch 131/200, Iteration 177/250, Loss: 0.0098\n",
      "Epoch 131/200, Iteration 178/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 179/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 180/250, Loss: 0.0153\n",
      "Epoch 131/200, Iteration 181/250, Loss: 0.0330\n",
      "Epoch 131/200, Iteration 182/250, Loss: 0.0127\n",
      "Epoch 131/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 131/200, Iteration 184/250, Loss: 0.0231\n",
      "Epoch 131/200, Iteration 185/250, Loss: 0.0357\n",
      "Epoch 131/200, Iteration 186/250, Loss: 0.0263\n",
      "Epoch 131/200, Iteration 187/250, Loss: 0.0063\n",
      "Epoch 131/200, Iteration 188/250, Loss: 0.0135\n",
      "Epoch 131/200, Iteration 189/250, Loss: 0.0186\n",
      "Epoch 131/200, Iteration 190/250, Loss: 0.0228\n",
      "Epoch 131/200, Iteration 191/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 192/250, Loss: 0.0181\n",
      "Epoch 131/200, Iteration 193/250, Loss: 0.0123\n",
      "Epoch 131/200, Iteration 194/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 195/250, Loss: 0.0075\n",
      "Epoch 131/200, Iteration 196/250, Loss: 0.0128\n",
      "Epoch 131/200, Iteration 197/250, Loss: 0.0086\n",
      "Epoch 131/200, Iteration 198/250, Loss: 0.0103\n",
      "Epoch 131/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 131/200, Iteration 200/250, Loss: 0.0162\n",
      "Epoch 131/200, Iteration 201/250, Loss: 0.0235\n",
      "Epoch 131/200, Iteration 202/250, Loss: 0.0160\n",
      "Epoch 131/200, Iteration 203/250, Loss: 0.0073\n",
      "Epoch 131/200, Iteration 204/250, Loss: 0.0127\n",
      "Epoch 131/200, Iteration 205/250, Loss: 0.0116\n",
      "Epoch 131/200, Iteration 206/250, Loss: 0.0095\n",
      "Epoch 131/200, Iteration 207/250, Loss: 0.0296\n",
      "Epoch 131/200, Iteration 208/250, Loss: 0.0094\n",
      "Epoch 131/200, Iteration 209/250, Loss: 0.0277\n",
      "Epoch 131/200, Iteration 210/250, Loss: 0.0118\n",
      "Epoch 131/200, Iteration 211/250, Loss: 0.0067\n",
      "Epoch 131/200, Iteration 212/250, Loss: 0.0093\n",
      "Epoch 131/200, Iteration 213/250, Loss: 0.0201\n",
      "Epoch 131/200, Iteration 214/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 215/250, Loss: 0.0179\n",
      "Epoch 131/200, Iteration 216/250, Loss: 0.0138\n",
      "Epoch 131/200, Iteration 217/250, Loss: 0.0132\n",
      "Epoch 131/200, Iteration 218/250, Loss: 0.0102\n",
      "Epoch 131/200, Iteration 219/250, Loss: 0.0109\n",
      "Epoch 131/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 131/200, Iteration 221/250, Loss: 0.0098\n",
      "Epoch 131/200, Iteration 222/250, Loss: 0.0058\n",
      "Epoch 131/200, Iteration 223/250, Loss: 0.0108\n",
      "Epoch 131/200, Iteration 224/250, Loss: 0.0103\n",
      "Epoch 131/200, Iteration 225/250, Loss: 0.0112\n",
      "Epoch 131/200, Iteration 226/250, Loss: 0.0087\n",
      "Epoch 131/200, Iteration 227/250, Loss: 0.0150\n",
      "Epoch 131/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 131/200, Iteration 230/250, Loss: 0.0347\n",
      "Epoch 131/200, Iteration 231/250, Loss: 0.0122\n",
      "Epoch 131/200, Iteration 232/250, Loss: 0.0152\n",
      "Epoch 131/200, Iteration 233/250, Loss: 0.0232\n",
      "Epoch 131/200, Iteration 234/250, Loss: 0.0215\n",
      "Epoch 131/200, Iteration 235/250, Loss: 0.0209\n",
      "Epoch 131/200, Iteration 236/250, Loss: 0.0191\n",
      "Epoch 131/200, Iteration 237/250, Loss: 0.0324\n",
      "Epoch 131/200, Iteration 238/250, Loss: 0.0199\n",
      "Epoch 131/200, Iteration 239/250, Loss: 0.0206\n",
      "Epoch 131/200, Iteration 240/250, Loss: 0.0172\n",
      "Epoch 131/200, Iteration 241/250, Loss: 0.0126\n",
      "Epoch 131/200, Iteration 242/250, Loss: 0.0229\n",
      "Epoch 131/200, Iteration 243/250, Loss: 0.0120\n",
      "Epoch 131/200, Iteration 244/250, Loss: 0.0115\n",
      "Epoch 131/200, Iteration 245/250, Loss: 0.0106\n",
      "Epoch 131/200, Iteration 246/250, Loss: 0.0058\n",
      "Epoch 131/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 131/200, Iteration 248/250, Loss: 0.0225\n",
      "Epoch 131/200, Iteration 249/250, Loss: 0.0286\n",
      "Epoch 131/200, Iteration 250/250, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 63.74%, Avg loss: 0.009322, MRE: 0.590221 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.009868, MRE: 0.739681 \n",
      "\n",
      "Epoch 132/200, Iteration 1/250, Loss: 0.0137\n",
      "Epoch 132/200, Iteration 2/250, Loss: 0.0157\n",
      "Epoch 132/200, Iteration 3/250, Loss: 0.0070\n",
      "Epoch 132/200, Iteration 4/250, Loss: 0.0113\n",
      "Epoch 132/200, Iteration 5/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 6/250, Loss: 0.0323\n",
      "Epoch 132/200, Iteration 7/250, Loss: 0.0092\n",
      "Epoch 132/200, Iteration 8/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 9/250, Loss: 0.0225\n",
      "Epoch 132/200, Iteration 10/250, Loss: 0.0197\n",
      "Epoch 132/200, Iteration 11/250, Loss: 0.0338\n",
      "Epoch 132/200, Iteration 12/250, Loss: 0.0152\n",
      "Epoch 132/200, Iteration 13/250, Loss: 0.0160\n",
      "Epoch 132/200, Iteration 14/250, Loss: 0.0083\n",
      "Epoch 132/200, Iteration 15/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 16/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 17/250, Loss: 0.0127\n",
      "Epoch 132/200, Iteration 18/250, Loss: 0.0096\n",
      "Epoch 132/200, Iteration 19/250, Loss: 0.0269\n",
      "Epoch 132/200, Iteration 20/250, Loss: 0.0188\n",
      "Epoch 132/200, Iteration 21/250, Loss: 0.0073\n",
      "Epoch 132/200, Iteration 22/250, Loss: 0.0167\n",
      "Epoch 132/200, Iteration 23/250, Loss: 0.0177\n",
      "Epoch 132/200, Iteration 24/250, Loss: 0.0172\n",
      "Epoch 132/200, Iteration 25/250, Loss: 0.0251\n",
      "Epoch 132/200, Iteration 26/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 27/250, Loss: 0.0274\n",
      "Epoch 132/200, Iteration 28/250, Loss: 0.0341\n",
      "Epoch 132/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 31/250, Loss: 0.0380\n",
      "Epoch 132/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 33/250, Loss: 0.0071\n",
      "Epoch 132/200, Iteration 34/250, Loss: 0.0068\n",
      "Epoch 132/200, Iteration 35/250, Loss: 0.0083\n",
      "Epoch 132/200, Iteration 36/250, Loss: 0.0099\n",
      "Epoch 132/200, Iteration 37/250, Loss: 0.0229\n",
      "Epoch 132/200, Iteration 38/250, Loss: 0.0105\n",
      "Epoch 132/200, Iteration 39/250, Loss: 0.0144\n",
      "Epoch 132/200, Iteration 40/250, Loss: 0.0217\n",
      "Epoch 132/200, Iteration 41/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 42/250, Loss: 0.0209\n",
      "Epoch 132/200, Iteration 43/250, Loss: 0.0231\n",
      "Epoch 132/200, Iteration 44/250, Loss: 0.0143\n",
      "Epoch 132/200, Iteration 45/250, Loss: 0.0122\n",
      "Epoch 132/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 132/200, Iteration 47/250, Loss: 0.0409\n",
      "Epoch 132/200, Iteration 48/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 49/250, Loss: 0.0118\n",
      "Epoch 132/200, Iteration 50/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 51/250, Loss: 0.0114\n",
      "Epoch 132/200, Iteration 52/250, Loss: 0.0168\n",
      "Epoch 132/200, Iteration 53/250, Loss: 0.0118\n",
      "Epoch 132/200, Iteration 54/250, Loss: 0.0128\n",
      "Epoch 132/200, Iteration 55/250, Loss: 0.0120\n",
      "Epoch 132/200, Iteration 56/250, Loss: 0.0241\n",
      "Epoch 132/200, Iteration 57/250, Loss: 0.0266\n",
      "Epoch 132/200, Iteration 58/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 59/250, Loss: 0.0191\n",
      "Epoch 132/200, Iteration 60/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 61/250, Loss: 0.0217\n",
      "Epoch 132/200, Iteration 62/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 63/250, Loss: 0.0166\n",
      "Epoch 132/200, Iteration 64/250, Loss: 0.0137\n",
      "Epoch 132/200, Iteration 65/250, Loss: 0.0519\n",
      "Epoch 132/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 132/200, Iteration 67/250, Loss: 0.0121\n",
      "Epoch 132/200, Iteration 68/250, Loss: 0.0211\n",
      "Epoch 132/200, Iteration 69/250, Loss: 0.0189\n",
      "Epoch 132/200, Iteration 70/250, Loss: 0.0092\n",
      "Epoch 132/200, Iteration 71/250, Loss: 0.0195\n",
      "Epoch 132/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 73/250, Loss: 0.0137\n",
      "Epoch 132/200, Iteration 74/250, Loss: 0.0257\n",
      "Epoch 132/200, Iteration 75/250, Loss: 0.0242\n",
      "Epoch 132/200, Iteration 76/250, Loss: 0.0113\n",
      "Epoch 132/200, Iteration 77/250, Loss: 0.0211\n",
      "Epoch 132/200, Iteration 78/250, Loss: 0.0351\n",
      "Epoch 132/200, Iteration 79/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 80/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 81/250, Loss: 0.0142\n",
      "Epoch 132/200, Iteration 82/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 83/250, Loss: 0.0121\n",
      "Epoch 132/200, Iteration 84/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 85/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 86/250, Loss: 0.0153\n",
      "Epoch 132/200, Iteration 87/250, Loss: 0.0164\n",
      "Epoch 132/200, Iteration 88/250, Loss: 0.0147\n",
      "Epoch 132/200, Iteration 89/250, Loss: 0.0083\n",
      "Epoch 132/200, Iteration 90/250, Loss: 0.0152\n",
      "Epoch 132/200, Iteration 91/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 92/250, Loss: 0.0084\n",
      "Epoch 132/200, Iteration 93/250, Loss: 0.0131\n",
      "Epoch 132/200, Iteration 94/250, Loss: 0.0155\n",
      "Epoch 132/200, Iteration 95/250, Loss: 0.0168\n",
      "Epoch 132/200, Iteration 96/250, Loss: 0.0105\n",
      "Epoch 132/200, Iteration 97/250, Loss: 0.0104\n",
      "Epoch 132/200, Iteration 98/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 99/250, Loss: 0.0107\n",
      "Epoch 132/200, Iteration 100/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 101/250, Loss: 0.0121\n",
      "Epoch 132/200, Iteration 102/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 103/250, Loss: 0.0147\n",
      "Epoch 132/200, Iteration 104/250, Loss: 0.0189\n",
      "Epoch 132/200, Iteration 105/250, Loss: 0.0271\n",
      "Epoch 132/200, Iteration 106/250, Loss: 0.0182\n",
      "Epoch 132/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 132/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 109/250, Loss: 0.0127\n",
      "Epoch 132/200, Iteration 110/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 111/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 112/250, Loss: 0.0254\n",
      "Epoch 132/200, Iteration 113/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 114/250, Loss: 0.0163\n",
      "Epoch 132/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 132/200, Iteration 116/250, Loss: 0.0113\n",
      "Epoch 132/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 132/200, Iteration 118/250, Loss: 0.0096\n",
      "Epoch 132/200, Iteration 119/250, Loss: 0.0159\n",
      "Epoch 132/200, Iteration 120/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 121/250, Loss: 0.0167\n",
      "Epoch 132/200, Iteration 122/250, Loss: 0.0128\n",
      "Epoch 132/200, Iteration 123/250, Loss: 0.0112\n",
      "Epoch 132/200, Iteration 124/250, Loss: 0.0162\n",
      "Epoch 132/200, Iteration 125/250, Loss: 0.0116\n",
      "Epoch 132/200, Iteration 126/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 127/250, Loss: 0.0097\n",
      "Epoch 132/200, Iteration 128/250, Loss: 0.0121\n",
      "Epoch 132/200, Iteration 129/250, Loss: 0.0292\n",
      "Epoch 132/200, Iteration 130/250, Loss: 0.0205\n",
      "Epoch 132/200, Iteration 131/250, Loss: 0.0101\n",
      "Epoch 132/200, Iteration 132/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 133/250, Loss: 0.0252\n",
      "Epoch 132/200, Iteration 134/250, Loss: 0.0450\n",
      "Epoch 132/200, Iteration 135/250, Loss: 0.0079\n",
      "Epoch 132/200, Iteration 136/250, Loss: 0.0238\n",
      "Epoch 132/200, Iteration 137/250, Loss: 0.0268\n",
      "Epoch 132/200, Iteration 138/250, Loss: 0.0230\n",
      "Epoch 132/200, Iteration 139/250, Loss: 0.0243\n",
      "Epoch 132/200, Iteration 140/250, Loss: 0.0171\n",
      "Epoch 132/200, Iteration 141/250, Loss: 0.0075\n",
      "Epoch 132/200, Iteration 142/250, Loss: 0.0169\n",
      "Epoch 132/200, Iteration 143/250, Loss: 0.0133\n",
      "Epoch 132/200, Iteration 144/250, Loss: 0.0136\n",
      "Epoch 132/200, Iteration 145/250, Loss: 0.0198\n",
      "Epoch 132/200, Iteration 146/250, Loss: 0.0161\n",
      "Epoch 132/200, Iteration 147/250, Loss: 0.0105\n",
      "Epoch 132/200, Iteration 148/250, Loss: 0.0199\n",
      "Epoch 132/200, Iteration 149/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 150/250, Loss: 0.0253\n",
      "Epoch 132/200, Iteration 151/250, Loss: 0.0103\n",
      "Epoch 132/200, Iteration 152/250, Loss: 0.0064\n",
      "Epoch 132/200, Iteration 153/250, Loss: 0.0130\n",
      "Epoch 132/200, Iteration 154/250, Loss: 0.0074\n",
      "Epoch 132/200, Iteration 155/250, Loss: 0.0139\n",
      "Epoch 132/200, Iteration 156/250, Loss: 0.0146\n",
      "Epoch 132/200, Iteration 157/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 158/250, Loss: 0.0159\n",
      "Epoch 132/200, Iteration 159/250, Loss: 0.0208\n",
      "Epoch 132/200, Iteration 160/250, Loss: 0.0134\n",
      "Epoch 132/200, Iteration 161/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 162/250, Loss: 0.0130\n",
      "Epoch 132/200, Iteration 163/250, Loss: 0.0117\n",
      "Epoch 132/200, Iteration 164/250, Loss: 0.0257\n",
      "Epoch 132/200, Iteration 165/250, Loss: 0.0159\n",
      "Epoch 132/200, Iteration 166/250, Loss: 0.0106\n",
      "Epoch 132/200, Iteration 167/250, Loss: 0.0105\n",
      "Epoch 132/200, Iteration 168/250, Loss: 0.0103\n",
      "Epoch 132/200, Iteration 169/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 170/250, Loss: 0.0118\n",
      "Epoch 132/200, Iteration 171/250, Loss: 0.0111\n",
      "Epoch 132/200, Iteration 172/250, Loss: 0.0136\n",
      "Epoch 132/200, Iteration 173/250, Loss: 0.0127\n",
      "Epoch 132/200, Iteration 174/250, Loss: 0.0299\n",
      "Epoch 132/200, Iteration 175/250, Loss: 0.0092\n",
      "Epoch 132/200, Iteration 176/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 177/250, Loss: 0.0376\n",
      "Epoch 132/200, Iteration 178/250, Loss: 0.0206\n",
      "Epoch 132/200, Iteration 179/250, Loss: 0.0085\n",
      "Epoch 132/200, Iteration 180/250, Loss: 0.0087\n",
      "Epoch 132/200, Iteration 181/250, Loss: 0.0135\n",
      "Epoch 132/200, Iteration 182/250, Loss: 0.0082\n",
      "Epoch 132/200, Iteration 183/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 184/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 185/250, Loss: 0.0224\n",
      "Epoch 132/200, Iteration 186/250, Loss: 0.0092\n",
      "Epoch 132/200, Iteration 187/250, Loss: 0.0098\n",
      "Epoch 132/200, Iteration 188/250, Loss: 0.0103\n",
      "Epoch 132/200, Iteration 189/250, Loss: 0.0142\n",
      "Epoch 132/200, Iteration 190/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 191/250, Loss: 0.0088\n",
      "Epoch 132/200, Iteration 192/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 193/250, Loss: 0.0114\n",
      "Epoch 132/200, Iteration 194/250, Loss: 0.0286\n",
      "Epoch 132/200, Iteration 195/250, Loss: 0.0241\n",
      "Epoch 132/200, Iteration 196/250, Loss: 0.0128\n",
      "Epoch 132/200, Iteration 197/250, Loss: 0.0213\n",
      "Epoch 132/200, Iteration 198/250, Loss: 0.0122\n",
      "Epoch 132/200, Iteration 199/250, Loss: 0.0268\n",
      "Epoch 132/200, Iteration 200/250, Loss: 0.0155\n",
      "Epoch 132/200, Iteration 201/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200, Iteration 202/250, Loss: 0.0075\n",
      "Epoch 132/200, Iteration 203/250, Loss: 0.0293\n",
      "Epoch 132/200, Iteration 204/250, Loss: 0.0248\n",
      "Epoch 132/200, Iteration 205/250, Loss: 0.0345\n",
      "Epoch 132/200, Iteration 206/250, Loss: 0.0081\n",
      "Epoch 132/200, Iteration 207/250, Loss: 0.0250\n",
      "Epoch 132/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 132/200, Iteration 209/250, Loss: 0.0108\n",
      "Epoch 132/200, Iteration 210/250, Loss: 0.0602\n",
      "Epoch 132/200, Iteration 211/250, Loss: 0.0364\n",
      "Epoch 132/200, Iteration 212/250, Loss: 0.0474\n",
      "Epoch 132/200, Iteration 213/250, Loss: 0.0080\n",
      "Epoch 132/200, Iteration 214/250, Loss: 0.0137\n",
      "Epoch 132/200, Iteration 215/250, Loss: 0.0134\n",
      "Epoch 132/200, Iteration 216/250, Loss: 0.0142\n",
      "Epoch 132/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 218/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 219/250, Loss: 0.0076\n",
      "Epoch 132/200, Iteration 220/250, Loss: 0.0097\n",
      "Epoch 132/200, Iteration 221/250, Loss: 0.0086\n",
      "Epoch 132/200, Iteration 222/250, Loss: 0.0110\n",
      "Epoch 132/200, Iteration 223/250, Loss: 0.0109\n",
      "Epoch 132/200, Iteration 224/250, Loss: 0.0058\n",
      "Epoch 132/200, Iteration 225/250, Loss: 0.0173\n",
      "Epoch 132/200, Iteration 226/250, Loss: 0.0162\n",
      "Epoch 132/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 132/200, Iteration 228/250, Loss: 0.0100\n",
      "Epoch 132/200, Iteration 229/250, Loss: 0.0154\n",
      "Epoch 132/200, Iteration 230/250, Loss: 0.0094\n",
      "Epoch 132/200, Iteration 231/250, Loss: 0.0091\n",
      "Epoch 132/200, Iteration 232/250, Loss: 0.0102\n",
      "Epoch 132/200, Iteration 233/250, Loss: 0.0099\n",
      "Epoch 132/200, Iteration 234/250, Loss: 0.0092\n",
      "Epoch 132/200, Iteration 235/250, Loss: 0.0121\n",
      "Epoch 132/200, Iteration 236/250, Loss: 0.0332\n",
      "Epoch 132/200, Iteration 237/250, Loss: 0.0070\n",
      "Epoch 132/200, Iteration 238/250, Loss: 0.0150\n",
      "Epoch 132/200, Iteration 239/250, Loss: 0.0065\n",
      "Epoch 132/200, Iteration 240/250, Loss: 0.0155\n",
      "Epoch 132/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 132/200, Iteration 242/250, Loss: 0.0259\n",
      "Epoch 132/200, Iteration 243/250, Loss: 0.0100\n",
      "Epoch 132/200, Iteration 244/250, Loss: 0.0199\n",
      "Epoch 132/200, Iteration 245/250, Loss: 0.0115\n",
      "Epoch 132/200, Iteration 246/250, Loss: 0.0194\n",
      "Epoch 132/200, Iteration 247/250, Loss: 0.0122\n",
      "Epoch 132/200, Iteration 248/250, Loss: 0.0170\n",
      "Epoch 132/200, Iteration 249/250, Loss: 0.0125\n",
      "Epoch 132/200, Iteration 250/250, Loss: 0.0202\n",
      "Train Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.006731, MRE: 0.457177 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.25%, Avg loss: 0.007241, MRE: 0.472337 \n",
      "\n",
      "Epoch 133/200, Iteration 1/250, Loss: 0.0197\n",
      "Epoch 133/200, Iteration 2/250, Loss: 0.0195\n",
      "Epoch 133/200, Iteration 3/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 4/250, Loss: 0.0175\n",
      "Epoch 133/200, Iteration 5/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 6/250, Loss: 0.0147\n",
      "Epoch 133/200, Iteration 7/250, Loss: 0.0150\n",
      "Epoch 133/200, Iteration 8/250, Loss: 0.0257\n",
      "Epoch 133/200, Iteration 9/250, Loss: 0.0171\n",
      "Epoch 133/200, Iteration 10/250, Loss: 0.0134\n",
      "Epoch 133/200, Iteration 11/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 12/250, Loss: 0.0124\n",
      "Epoch 133/200, Iteration 13/250, Loss: 0.0075\n",
      "Epoch 133/200, Iteration 14/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 15/250, Loss: 0.0207\n",
      "Epoch 133/200, Iteration 16/250, Loss: 0.0085\n",
      "Epoch 133/200, Iteration 17/250, Loss: 0.0200\n",
      "Epoch 133/200, Iteration 18/250, Loss: 0.0117\n",
      "Epoch 133/200, Iteration 19/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 20/250, Loss: 0.0117\n",
      "Epoch 133/200, Iteration 21/250, Loss: 0.0068\n",
      "Epoch 133/200, Iteration 22/250, Loss: 0.0176\n",
      "Epoch 133/200, Iteration 23/250, Loss: 0.0120\n",
      "Epoch 133/200, Iteration 24/250, Loss: 0.0271\n",
      "Epoch 133/200, Iteration 25/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 26/250, Loss: 0.0164\n",
      "Epoch 133/200, Iteration 27/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 28/250, Loss: 0.0160\n",
      "Epoch 133/200, Iteration 29/250, Loss: 0.0142\n",
      "Epoch 133/200, Iteration 30/250, Loss: 0.0288\n",
      "Epoch 133/200, Iteration 31/250, Loss: 0.0103\n",
      "Epoch 133/200, Iteration 32/250, Loss: 0.0218\n",
      "Epoch 133/200, Iteration 33/250, Loss: 0.0204\n",
      "Epoch 133/200, Iteration 34/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 35/250, Loss: 0.0328\n",
      "Epoch 133/200, Iteration 36/250, Loss: 0.0077\n",
      "Epoch 133/200, Iteration 37/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 38/250, Loss: 0.0138\n",
      "Epoch 133/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 40/250, Loss: 0.0143\n",
      "Epoch 133/200, Iteration 41/250, Loss: 0.0073\n",
      "Epoch 133/200, Iteration 42/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 43/250, Loss: 0.0218\n",
      "Epoch 133/200, Iteration 44/250, Loss: 0.0173\n",
      "Epoch 133/200, Iteration 45/250, Loss: 0.0218\n",
      "Epoch 133/200, Iteration 46/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 47/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 48/250, Loss: 0.0211\n",
      "Epoch 133/200, Iteration 49/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 50/250, Loss: 0.0198\n",
      "Epoch 133/200, Iteration 51/250, Loss: 0.0103\n",
      "Epoch 133/200, Iteration 52/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 53/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 54/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 55/250, Loss: 0.0219\n",
      "Epoch 133/200, Iteration 56/250, Loss: 0.0338\n",
      "Epoch 133/200, Iteration 57/250, Loss: 0.0182\n",
      "Epoch 133/200, Iteration 58/250, Loss: 0.0216\n",
      "Epoch 133/200, Iteration 59/250, Loss: 0.0129\n",
      "Epoch 133/200, Iteration 60/250, Loss: 0.0246\n",
      "Epoch 133/200, Iteration 61/250, Loss: 0.0082\n",
      "Epoch 133/200, Iteration 62/250, Loss: 0.0153\n",
      "Epoch 133/200, Iteration 63/250, Loss: 0.0281\n",
      "Epoch 133/200, Iteration 64/250, Loss: 0.0146\n",
      "Epoch 133/200, Iteration 65/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 66/250, Loss: 0.0205\n",
      "Epoch 133/200, Iteration 67/250, Loss: 0.0330\n",
      "Epoch 133/200, Iteration 68/250, Loss: 0.0181\n",
      "Epoch 133/200, Iteration 69/250, Loss: 0.0167\n",
      "Epoch 133/200, Iteration 70/250, Loss: 0.0215\n",
      "Epoch 133/200, Iteration 71/250, Loss: 0.0076\n",
      "Epoch 133/200, Iteration 72/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 73/250, Loss: 0.0133\n",
      "Epoch 133/200, Iteration 74/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 75/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 76/250, Loss: 0.0122\n",
      "Epoch 133/200, Iteration 77/250, Loss: 0.0151\n",
      "Epoch 133/200, Iteration 78/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 79/250, Loss: 0.0085\n",
      "Epoch 133/200, Iteration 80/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 81/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 82/250, Loss: 0.0078\n",
      "Epoch 133/200, Iteration 83/250, Loss: 0.0079\n",
      "Epoch 133/200, Iteration 84/250, Loss: 0.0204\n",
      "Epoch 133/200, Iteration 85/250, Loss: 0.0079\n",
      "Epoch 133/200, Iteration 86/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 87/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 88/250, Loss: 0.0080\n",
      "Epoch 133/200, Iteration 89/250, Loss: 0.0296\n",
      "Epoch 133/200, Iteration 90/250, Loss: 0.0308\n",
      "Epoch 133/200, Iteration 91/250, Loss: 0.0128\n",
      "Epoch 133/200, Iteration 92/250, Loss: 0.0104\n",
      "Epoch 133/200, Iteration 93/250, Loss: 0.0116\n",
      "Epoch 133/200, Iteration 94/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 95/250, Loss: 0.0208\n",
      "Epoch 133/200, Iteration 96/250, Loss: 0.0060\n",
      "Epoch 133/200, Iteration 97/250, Loss: 0.0113\n",
      "Epoch 133/200, Iteration 98/250, Loss: 0.0230\n",
      "Epoch 133/200, Iteration 99/250, Loss: 0.0307\n",
      "Epoch 133/200, Iteration 100/250, Loss: 0.0083\n",
      "Epoch 133/200, Iteration 101/250, Loss: 0.0323\n",
      "Epoch 133/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 133/200, Iteration 103/250, Loss: 0.0294\n",
      "Epoch 133/200, Iteration 104/250, Loss: 0.0117\n",
      "Epoch 133/200, Iteration 105/250, Loss: 0.0069\n",
      "Epoch 133/200, Iteration 106/250, Loss: 0.0156\n",
      "Epoch 133/200, Iteration 107/250, Loss: 0.0466\n",
      "Epoch 133/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 109/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 110/250, Loss: 0.0128\n",
      "Epoch 133/200, Iteration 111/250, Loss: 0.0311\n",
      "Epoch 133/200, Iteration 112/250, Loss: 0.0067\n",
      "Epoch 133/200, Iteration 113/250, Loss: 0.0186\n",
      "Epoch 133/200, Iteration 114/250, Loss: 0.0083\n",
      "Epoch 133/200, Iteration 115/250, Loss: 0.0192\n",
      "Epoch 133/200, Iteration 116/250, Loss: 0.0129\n",
      "Epoch 133/200, Iteration 117/250, Loss: 0.0122\n",
      "Epoch 133/200, Iteration 118/250, Loss: 0.0133\n",
      "Epoch 133/200, Iteration 119/250, Loss: 0.0123\n",
      "Epoch 133/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 133/200, Iteration 121/250, Loss: 0.0103\n",
      "Epoch 133/200, Iteration 122/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 123/250, Loss: 0.0378\n",
      "Epoch 133/200, Iteration 124/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 125/250, Loss: 0.0215\n",
      "Epoch 133/200, Iteration 126/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 127/250, Loss: 0.0164\n",
      "Epoch 133/200, Iteration 128/250, Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200, Iteration 129/250, Loss: 0.0113\n",
      "Epoch 133/200, Iteration 130/250, Loss: 0.0166\n",
      "Epoch 133/200, Iteration 131/250, Loss: 0.0131\n",
      "Epoch 133/200, Iteration 132/250, Loss: 0.0075\n",
      "Epoch 133/200, Iteration 133/250, Loss: 0.0108\n",
      "Epoch 133/200, Iteration 134/250, Loss: 0.0355\n",
      "Epoch 133/200, Iteration 135/250, Loss: 0.0095\n",
      "Epoch 133/200, Iteration 136/250, Loss: 0.0114\n",
      "Epoch 133/200, Iteration 137/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 138/250, Loss: 0.0077\n",
      "Epoch 133/200, Iteration 139/250, Loss: 0.0135\n",
      "Epoch 133/200, Iteration 140/250, Loss: 0.0144\n",
      "Epoch 133/200, Iteration 141/250, Loss: 0.0071\n",
      "Epoch 133/200, Iteration 142/250, Loss: 0.0285\n",
      "Epoch 133/200, Iteration 143/250, Loss: 0.0129\n",
      "Epoch 133/200, Iteration 144/250, Loss: 0.0230\n",
      "Epoch 133/200, Iteration 145/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 146/250, Loss: 0.0147\n",
      "Epoch 133/200, Iteration 147/250, Loss: 0.0075\n",
      "Epoch 133/200, Iteration 148/250, Loss: 0.0118\n",
      "Epoch 133/200, Iteration 149/250, Loss: 0.0142\n",
      "Epoch 133/200, Iteration 150/250, Loss: 0.0081\n",
      "Epoch 133/200, Iteration 151/250, Loss: 0.0156\n",
      "Epoch 133/200, Iteration 152/250, Loss: 0.0212\n",
      "Epoch 133/200, Iteration 153/250, Loss: 0.0076\n",
      "Epoch 133/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 155/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 156/250, Loss: 0.0251\n",
      "Epoch 133/200, Iteration 157/250, Loss: 0.0212\n",
      "Epoch 133/200, Iteration 158/250, Loss: 0.0128\n",
      "Epoch 133/200, Iteration 159/250, Loss: 0.0146\n",
      "Epoch 133/200, Iteration 160/250, Loss: 0.0132\n",
      "Epoch 133/200, Iteration 161/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 162/250, Loss: 0.0098\n",
      "Epoch 133/200, Iteration 163/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 164/250, Loss: 0.0128\n",
      "Epoch 133/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 133/200, Iteration 166/250, Loss: 0.0121\n",
      "Epoch 133/200, Iteration 167/250, Loss: 0.0142\n",
      "Epoch 133/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 133/200, Iteration 169/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 170/250, Loss: 0.0165\n",
      "Epoch 133/200, Iteration 171/250, Loss: 0.0232\n",
      "Epoch 133/200, Iteration 172/250, Loss: 0.0099\n",
      "Epoch 133/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 133/200, Iteration 174/250, Loss: 0.0137\n",
      "Epoch 133/200, Iteration 175/250, Loss: 0.0095\n",
      "Epoch 133/200, Iteration 176/250, Loss: 0.0065\n",
      "Epoch 133/200, Iteration 177/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 178/250, Loss: 0.0127\n",
      "Epoch 133/200, Iteration 179/250, Loss: 0.0182\n",
      "Epoch 133/200, Iteration 180/250, Loss: 0.0107\n",
      "Epoch 133/200, Iteration 181/250, Loss: 0.0069\n",
      "Epoch 133/200, Iteration 182/250, Loss: 0.0130\n",
      "Epoch 133/200, Iteration 183/250, Loss: 0.0068\n",
      "Epoch 133/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 185/250, Loss: 0.0174\n",
      "Epoch 133/200, Iteration 186/250, Loss: 0.0122\n",
      "Epoch 133/200, Iteration 187/250, Loss: 0.0194\n",
      "Epoch 133/200, Iteration 188/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 190/250, Loss: 0.0110\n",
      "Epoch 133/200, Iteration 191/250, Loss: 0.0106\n",
      "Epoch 133/200, Iteration 192/250, Loss: 0.0154\n",
      "Epoch 133/200, Iteration 193/250, Loss: 0.0385\n",
      "Epoch 133/200, Iteration 194/250, Loss: 0.0142\n",
      "Epoch 133/200, Iteration 195/250, Loss: 0.0118\n",
      "Epoch 133/200, Iteration 196/250, Loss: 0.0171\n",
      "Epoch 133/200, Iteration 197/250, Loss: 0.0215\n",
      "Epoch 133/200, Iteration 198/250, Loss: 0.0152\n",
      "Epoch 133/200, Iteration 199/250, Loss: 0.0097\n",
      "Epoch 133/200, Iteration 200/250, Loss: 0.0082\n",
      "Epoch 133/200, Iteration 201/250, Loss: 0.0169\n",
      "Epoch 133/200, Iteration 202/250, Loss: 0.0079\n",
      "Epoch 133/200, Iteration 203/250, Loss: 0.0320\n",
      "Epoch 133/200, Iteration 204/250, Loss: 0.0100\n",
      "Epoch 133/200, Iteration 205/250, Loss: 0.0069\n",
      "Epoch 133/200, Iteration 206/250, Loss: 0.0092\n",
      "Epoch 133/200, Iteration 207/250, Loss: 0.0136\n",
      "Epoch 133/200, Iteration 208/250, Loss: 0.0209\n",
      "Epoch 133/200, Iteration 209/250, Loss: 0.0101\n",
      "Epoch 133/200, Iteration 210/250, Loss: 0.0299\n",
      "Epoch 133/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 133/200, Iteration 212/250, Loss: 0.0256\n",
      "Epoch 133/200, Iteration 213/250, Loss: 0.0176\n",
      "Epoch 133/200, Iteration 214/250, Loss: 0.0118\n",
      "Epoch 133/200, Iteration 215/250, Loss: 0.0160\n",
      "Epoch 133/200, Iteration 216/250, Loss: 0.0100\n",
      "Epoch 133/200, Iteration 217/250, Loss: 0.0216\n",
      "Epoch 133/200, Iteration 218/250, Loss: 0.0223\n",
      "Epoch 133/200, Iteration 219/250, Loss: 0.0087\n",
      "Epoch 133/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 133/200, Iteration 221/250, Loss: 0.0173\n",
      "Epoch 133/200, Iteration 222/250, Loss: 0.0143\n",
      "Epoch 133/200, Iteration 223/250, Loss: 0.0140\n",
      "Epoch 133/200, Iteration 224/250, Loss: 0.0159\n",
      "Epoch 133/200, Iteration 225/250, Loss: 0.0249\n",
      "Epoch 133/200, Iteration 226/250, Loss: 0.0115\n",
      "Epoch 133/200, Iteration 227/250, Loss: 0.0272\n",
      "Epoch 133/200, Iteration 228/250, Loss: 0.0096\n",
      "Epoch 133/200, Iteration 229/250, Loss: 0.0092\n",
      "Epoch 133/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 133/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 233/250, Loss: 0.0199\n",
      "Epoch 133/200, Iteration 234/250, Loss: 0.0102\n",
      "Epoch 133/200, Iteration 235/250, Loss: 0.0089\n",
      "Epoch 133/200, Iteration 236/250, Loss: 0.0091\n",
      "Epoch 133/200, Iteration 237/250, Loss: 0.0092\n",
      "Epoch 133/200, Iteration 238/250, Loss: 0.0108\n",
      "Epoch 133/200, Iteration 239/250, Loss: 0.0065\n",
      "Epoch 133/200, Iteration 240/250, Loss: 0.0183\n",
      "Epoch 133/200, Iteration 241/250, Loss: 0.0093\n",
      "Epoch 133/200, Iteration 242/250, Loss: 0.0293\n",
      "Epoch 133/200, Iteration 243/250, Loss: 0.0076\n",
      "Epoch 133/200, Iteration 244/250, Loss: 0.0095\n",
      "Epoch 133/200, Iteration 245/250, Loss: 0.0234\n",
      "Epoch 133/200, Iteration 246/250, Loss: 0.0112\n",
      "Epoch 133/200, Iteration 247/250, Loss: 0.0082\n",
      "Epoch 133/200, Iteration 248/250, Loss: 0.0090\n",
      "Epoch 133/200, Iteration 249/250, Loss: 0.0247\n",
      "Epoch 133/200, Iteration 250/250, Loss: 0.0086\n",
      "Train Error: \n",
      " Accuracy: 82.75%, Avg loss: 0.007209, MRE: 0.542083 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.007666, MRE: 0.525063 \n",
      "\n",
      "Epoch 134/200, Iteration 1/250, Loss: 0.0125\n",
      "Epoch 134/200, Iteration 2/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 3/250, Loss: 0.0075\n",
      "Epoch 134/200, Iteration 4/250, Loss: 0.0192\n",
      "Epoch 134/200, Iteration 5/250, Loss: 0.0183\n",
      "Epoch 134/200, Iteration 6/250, Loss: 0.0280\n",
      "Epoch 134/200, Iteration 7/250, Loss: 0.0170\n",
      "Epoch 134/200, Iteration 8/250, Loss: 0.0212\n",
      "Epoch 134/200, Iteration 9/250, Loss: 0.0291\n",
      "Epoch 134/200, Iteration 10/250, Loss: 0.0209\n",
      "Epoch 134/200, Iteration 11/250, Loss: 0.0088\n",
      "Epoch 134/200, Iteration 12/250, Loss: 0.0130\n",
      "Epoch 134/200, Iteration 13/250, Loss: 0.0072\n",
      "Epoch 134/200, Iteration 14/250, Loss: 0.0296\n",
      "Epoch 134/200, Iteration 15/250, Loss: 0.0082\n",
      "Epoch 134/200, Iteration 16/250, Loss: 0.0159\n",
      "Epoch 134/200, Iteration 17/250, Loss: 0.0120\n",
      "Epoch 134/200, Iteration 18/250, Loss: 0.0244\n",
      "Epoch 134/200, Iteration 19/250, Loss: 0.0126\n",
      "Epoch 134/200, Iteration 20/250, Loss: 0.0368\n",
      "Epoch 134/200, Iteration 21/250, Loss: 0.0211\n",
      "Epoch 134/200, Iteration 22/250, Loss: 0.0115\n",
      "Epoch 134/200, Iteration 23/250, Loss: 0.0209\n",
      "Epoch 134/200, Iteration 24/250, Loss: 0.0130\n",
      "Epoch 134/200, Iteration 25/250, Loss: 0.0089\n",
      "Epoch 134/200, Iteration 26/250, Loss: 0.0070\n",
      "Epoch 134/200, Iteration 27/250, Loss: 0.0270\n",
      "Epoch 134/200, Iteration 28/250, Loss: 0.0143\n",
      "Epoch 134/200, Iteration 29/250, Loss: 0.0119\n",
      "Epoch 134/200, Iteration 30/250, Loss: 0.0136\n",
      "Epoch 134/200, Iteration 31/250, Loss: 0.0462\n",
      "Epoch 134/200, Iteration 32/250, Loss: 0.0145\n",
      "Epoch 134/200, Iteration 33/250, Loss: 0.0133\n",
      "Epoch 134/200, Iteration 34/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 35/250, Loss: 0.0114\n",
      "Epoch 134/200, Iteration 36/250, Loss: 0.0092\n",
      "Epoch 134/200, Iteration 37/250, Loss: 0.0068\n",
      "Epoch 134/200, Iteration 38/250, Loss: 0.0146\n",
      "Epoch 134/200, Iteration 39/250, Loss: 0.0074\n",
      "Epoch 134/200, Iteration 40/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 41/250, Loss: 0.0141\n",
      "Epoch 134/200, Iteration 42/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 43/250, Loss: 0.0148\n",
      "Epoch 134/200, Iteration 44/250, Loss: 0.0116\n",
      "Epoch 134/200, Iteration 45/250, Loss: 0.0213\n",
      "Epoch 134/200, Iteration 46/250, Loss: 0.0117\n",
      "Epoch 134/200, Iteration 47/250, Loss: 0.0147\n",
      "Epoch 134/200, Iteration 48/250, Loss: 0.0133\n",
      "Epoch 134/200, Iteration 49/250, Loss: 0.0148\n",
      "Epoch 134/200, Iteration 50/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 51/250, Loss: 0.0316\n",
      "Epoch 134/200, Iteration 52/250, Loss: 0.0322\n",
      "Epoch 134/200, Iteration 53/250, Loss: 0.0135\n",
      "Epoch 134/200, Iteration 54/250, Loss: 0.0207\n",
      "Epoch 134/200, Iteration 55/250, Loss: 0.0080\n",
      "Epoch 134/200, Iteration 56/250, Loss: 0.0129\n",
      "Epoch 134/200, Iteration 57/250, Loss: 0.0271\n",
      "Epoch 134/200, Iteration 58/250, Loss: 0.0094\n",
      "Epoch 134/200, Iteration 59/250, Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200, Iteration 60/250, Loss: 0.0108\n",
      "Epoch 134/200, Iteration 61/250, Loss: 0.0132\n",
      "Epoch 134/200, Iteration 62/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 63/250, Loss: 0.0099\n",
      "Epoch 134/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 134/200, Iteration 65/250, Loss: 0.0178\n",
      "Epoch 134/200, Iteration 66/250, Loss: 0.0163\n",
      "Epoch 134/200, Iteration 67/250, Loss: 0.0254\n",
      "Epoch 134/200, Iteration 68/250, Loss: 0.0109\n",
      "Epoch 134/200, Iteration 69/250, Loss: 0.0128\n",
      "Epoch 134/200, Iteration 70/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 71/250, Loss: 0.0231\n",
      "Epoch 134/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 134/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 134/200, Iteration 74/250, Loss: 0.0253\n",
      "Epoch 134/200, Iteration 75/250, Loss: 0.0098\n",
      "Epoch 134/200, Iteration 76/250, Loss: 0.0186\n",
      "Epoch 134/200, Iteration 77/250, Loss: 0.0150\n",
      "Epoch 134/200, Iteration 78/250, Loss: 0.0327\n",
      "Epoch 134/200, Iteration 79/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 80/250, Loss: 0.0347\n",
      "Epoch 134/200, Iteration 81/250, Loss: 0.0233\n",
      "Epoch 134/200, Iteration 82/250, Loss: 0.0155\n",
      "Epoch 134/200, Iteration 83/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 84/250, Loss: 0.0096\n",
      "Epoch 134/200, Iteration 85/250, Loss: 0.0138\n",
      "Epoch 134/200, Iteration 86/250, Loss: 0.0224\n",
      "Epoch 134/200, Iteration 87/250, Loss: 0.0281\n",
      "Epoch 134/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 134/200, Iteration 89/250, Loss: 0.0121\n",
      "Epoch 134/200, Iteration 90/250, Loss: 0.0205\n",
      "Epoch 134/200, Iteration 91/250, Loss: 0.0079\n",
      "Epoch 134/200, Iteration 92/250, Loss: 0.0416\n",
      "Epoch 134/200, Iteration 93/250, Loss: 0.0270\n",
      "Epoch 134/200, Iteration 94/250, Loss: 0.0340\n",
      "Epoch 134/200, Iteration 95/250, Loss: 0.0250\n",
      "Epoch 134/200, Iteration 96/250, Loss: 0.0163\n",
      "Epoch 134/200, Iteration 97/250, Loss: 0.0071\n",
      "Epoch 134/200, Iteration 98/250, Loss: 0.0122\n",
      "Epoch 134/200, Iteration 99/250, Loss: 0.0239\n",
      "Epoch 134/200, Iteration 100/250, Loss: 0.0079\n",
      "Epoch 134/200, Iteration 101/250, Loss: 0.0187\n",
      "Epoch 134/200, Iteration 102/250, Loss: 0.0165\n",
      "Epoch 134/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 134/200, Iteration 104/250, Loss: 0.0105\n",
      "Epoch 134/200, Iteration 105/250, Loss: 0.0142\n",
      "Epoch 134/200, Iteration 106/250, Loss: 0.0135\n",
      "Epoch 134/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 108/250, Loss: 0.0178\n",
      "Epoch 134/200, Iteration 109/250, Loss: 0.0099\n",
      "Epoch 134/200, Iteration 110/250, Loss: 0.0197\n",
      "Epoch 134/200, Iteration 111/250, Loss: 0.0070\n",
      "Epoch 134/200, Iteration 112/250, Loss: 0.0084\n",
      "Epoch 134/200, Iteration 113/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 114/250, Loss: 0.0225\n",
      "Epoch 134/200, Iteration 115/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 116/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 117/250, Loss: 0.0089\n",
      "Epoch 134/200, Iteration 118/250, Loss: 0.0220\n",
      "Epoch 134/200, Iteration 119/250, Loss: 0.0301\n",
      "Epoch 134/200, Iteration 120/250, Loss: 0.0163\n",
      "Epoch 134/200, Iteration 121/250, Loss: 0.0074\n",
      "Epoch 134/200, Iteration 122/250, Loss: 0.0221\n",
      "Epoch 134/200, Iteration 123/250, Loss: 0.0079\n",
      "Epoch 134/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 134/200, Iteration 125/250, Loss: 0.0260\n",
      "Epoch 134/200, Iteration 126/250, Loss: 0.0145\n",
      "Epoch 134/200, Iteration 127/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 128/250, Loss: 0.0081\n",
      "Epoch 134/200, Iteration 129/250, Loss: 0.0273\n",
      "Epoch 134/200, Iteration 130/250, Loss: 0.0302\n",
      "Epoch 134/200, Iteration 131/250, Loss: 0.0129\n",
      "Epoch 134/200, Iteration 132/250, Loss: 0.0144\n",
      "Epoch 134/200, Iteration 133/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 134/250, Loss: 0.0116\n",
      "Epoch 134/200, Iteration 135/250, Loss: 0.0120\n",
      "Epoch 134/200, Iteration 136/250, Loss: 0.0182\n",
      "Epoch 134/200, Iteration 137/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 138/250, Loss: 0.0080\n",
      "Epoch 134/200, Iteration 139/250, Loss: 0.0083\n",
      "Epoch 134/200, Iteration 140/250, Loss: 0.0236\n",
      "Epoch 134/200, Iteration 141/250, Loss: 0.0171\n",
      "Epoch 134/200, Iteration 142/250, Loss: 0.0194\n",
      "Epoch 134/200, Iteration 143/250, Loss: 0.0146\n",
      "Epoch 134/200, Iteration 144/250, Loss: 0.0121\n",
      "Epoch 134/200, Iteration 145/250, Loss: 0.0096\n",
      "Epoch 134/200, Iteration 146/250, Loss: 0.0133\n",
      "Epoch 134/200, Iteration 147/250, Loss: 0.0095\n",
      "Epoch 134/200, Iteration 148/250, Loss: 0.0109\n",
      "Epoch 134/200, Iteration 149/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 150/250, Loss: 0.0210\n",
      "Epoch 134/200, Iteration 151/250, Loss: 0.0264\n",
      "Epoch 134/200, Iteration 152/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 153/250, Loss: 0.0087\n",
      "Epoch 134/200, Iteration 154/250, Loss: 0.0086\n",
      "Epoch 134/200, Iteration 155/250, Loss: 0.0130\n",
      "Epoch 134/200, Iteration 156/250, Loss: 0.0310\n",
      "Epoch 134/200, Iteration 157/250, Loss: 0.0116\n",
      "Epoch 134/200, Iteration 158/250, Loss: 0.0307\n",
      "Epoch 134/200, Iteration 159/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 160/250, Loss: 0.0234\n",
      "Epoch 134/200, Iteration 161/250, Loss: 0.0338\n",
      "Epoch 134/200, Iteration 162/250, Loss: 0.0136\n",
      "Epoch 134/200, Iteration 163/250, Loss: 0.0110\n",
      "Epoch 134/200, Iteration 164/250, Loss: 0.0083\n",
      "Epoch 134/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 134/200, Iteration 166/250, Loss: 0.0144\n",
      "Epoch 134/200, Iteration 167/250, Loss: 0.0289\n",
      "Epoch 134/200, Iteration 168/250, Loss: 0.0112\n",
      "Epoch 134/200, Iteration 169/250, Loss: 0.0073\n",
      "Epoch 134/200, Iteration 170/250, Loss: 0.0096\n",
      "Epoch 134/200, Iteration 171/250, Loss: 0.0181\n",
      "Epoch 134/200, Iteration 172/250, Loss: 0.0166\n",
      "Epoch 134/200, Iteration 173/250, Loss: 0.0128\n",
      "Epoch 134/200, Iteration 174/250, Loss: 0.0198\n",
      "Epoch 134/200, Iteration 175/250, Loss: 0.0121\n",
      "Epoch 134/200, Iteration 176/250, Loss: 0.0115\n",
      "Epoch 134/200, Iteration 177/250, Loss: 0.0164\n",
      "Epoch 134/200, Iteration 178/250, Loss: 0.0264\n",
      "Epoch 134/200, Iteration 179/250, Loss: 0.0313\n",
      "Epoch 134/200, Iteration 180/250, Loss: 0.0139\n",
      "Epoch 134/200, Iteration 181/250, Loss: 0.0102\n",
      "Epoch 134/200, Iteration 182/250, Loss: 0.0143\n",
      "Epoch 134/200, Iteration 183/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 184/250, Loss: 0.0098\n",
      "Epoch 134/200, Iteration 185/250, Loss: 0.0278\n",
      "Epoch 134/200, Iteration 186/250, Loss: 0.0077\n",
      "Epoch 134/200, Iteration 187/250, Loss: 0.0130\n",
      "Epoch 134/200, Iteration 188/250, Loss: 0.0142\n",
      "Epoch 134/200, Iteration 189/250, Loss: 0.0091\n",
      "Epoch 134/200, Iteration 190/250, Loss: 0.0234\n",
      "Epoch 134/200, Iteration 191/250, Loss: 0.0179\n",
      "Epoch 134/200, Iteration 192/250, Loss: 0.0095\n",
      "Epoch 134/200, Iteration 193/250, Loss: 0.0133\n",
      "Epoch 134/200, Iteration 194/250, Loss: 0.0137\n",
      "Epoch 134/200, Iteration 195/250, Loss: 0.0131\n",
      "Epoch 134/200, Iteration 196/250, Loss: 0.0078\n",
      "Epoch 134/200, Iteration 197/250, Loss: 0.0142\n",
      "Epoch 134/200, Iteration 198/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 134/200, Iteration 200/250, Loss: 0.0117\n",
      "Epoch 134/200, Iteration 201/250, Loss: 0.0300\n",
      "Epoch 134/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 134/200, Iteration 203/250, Loss: 0.0181\n",
      "Epoch 134/200, Iteration 204/250, Loss: 0.0089\n",
      "Epoch 134/200, Iteration 205/250, Loss: 0.0092\n",
      "Epoch 134/200, Iteration 206/250, Loss: 0.0155\n",
      "Epoch 134/200, Iteration 207/250, Loss: 0.0190\n",
      "Epoch 134/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 134/200, Iteration 209/250, Loss: 0.0160\n",
      "Epoch 134/200, Iteration 210/250, Loss: 0.0126\n",
      "Epoch 134/200, Iteration 211/250, Loss: 0.0115\n",
      "Epoch 134/200, Iteration 212/250, Loss: 0.0116\n",
      "Epoch 134/200, Iteration 213/250, Loss: 0.0078\n",
      "Epoch 134/200, Iteration 214/250, Loss: 0.0132\n",
      "Epoch 134/200, Iteration 215/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 216/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 217/250, Loss: 0.0096\n",
      "Epoch 134/200, Iteration 218/250, Loss: 0.0090\n",
      "Epoch 134/200, Iteration 219/250, Loss: 0.0184\n",
      "Epoch 134/200, Iteration 220/250, Loss: 0.0169\n",
      "Epoch 134/200, Iteration 221/250, Loss: 0.0135\n",
      "Epoch 134/200, Iteration 222/250, Loss: 0.0163\n",
      "Epoch 134/200, Iteration 223/250, Loss: 0.0094\n",
      "Epoch 134/200, Iteration 224/250, Loss: 0.0158\n",
      "Epoch 134/200, Iteration 225/250, Loss: 0.0078\n",
      "Epoch 134/200, Iteration 226/250, Loss: 0.0271\n",
      "Epoch 134/200, Iteration 227/250, Loss: 0.0322\n",
      "Epoch 134/200, Iteration 228/250, Loss: 0.0101\n",
      "Epoch 134/200, Iteration 229/250, Loss: 0.0067\n",
      "Epoch 134/200, Iteration 230/250, Loss: 0.0096\n",
      "Epoch 134/200, Iteration 231/250, Loss: 0.0124\n",
      "Epoch 134/200, Iteration 232/250, Loss: 0.0275\n",
      "Epoch 134/200, Iteration 233/250, Loss: 0.0234\n",
      "Epoch 134/200, Iteration 234/250, Loss: 0.0121\n",
      "Epoch 134/200, Iteration 235/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 236/250, Loss: 0.0107\n",
      "Epoch 134/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 134/200, Iteration 238/250, Loss: 0.0137\n",
      "Epoch 134/200, Iteration 239/250, Loss: 0.0312\n",
      "Epoch 134/200, Iteration 240/250, Loss: 0.0085\n",
      "Epoch 134/200, Iteration 241/250, Loss: 0.0168\n",
      "Epoch 134/200, Iteration 242/250, Loss: 0.0106\n",
      "Epoch 134/200, Iteration 243/250, Loss: 0.0206\n",
      "Epoch 134/200, Iteration 244/250, Loss: 0.0224\n",
      "Epoch 134/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 134/200, Iteration 246/250, Loss: 0.0093\n",
      "Epoch 134/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 134/200, Iteration 248/250, Loss: 0.0105\n",
      "Epoch 134/200, Iteration 249/250, Loss: 0.0111\n",
      "Epoch 134/200, Iteration 250/250, Loss: 0.0336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.53%, Avg loss: 0.007516, MRE: 0.593002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.008140, MRE: 0.596203 \n",
      "\n",
      "Epoch 135/200, Iteration 1/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 2/250, Loss: 0.0244\n",
      "Epoch 135/200, Iteration 3/250, Loss: 0.0196\n",
      "Epoch 135/200, Iteration 4/250, Loss: 0.0058\n",
      "Epoch 135/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 135/200, Iteration 6/250, Loss: 0.0170\n",
      "Epoch 135/200, Iteration 7/250, Loss: 0.0096\n",
      "Epoch 135/200, Iteration 8/250, Loss: 0.0430\n",
      "Epoch 135/200, Iteration 9/250, Loss: 0.0183\n",
      "Epoch 135/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 11/250, Loss: 0.0297\n",
      "Epoch 135/200, Iteration 12/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 13/250, Loss: 0.0150\n",
      "Epoch 135/200, Iteration 14/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 15/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 16/250, Loss: 0.0089\n",
      "Epoch 135/200, Iteration 17/250, Loss: 0.0132\n",
      "Epoch 135/200, Iteration 18/250, Loss: 0.0096\n",
      "Epoch 135/200, Iteration 19/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 20/250, Loss: 0.0185\n",
      "Epoch 135/200, Iteration 21/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 22/250, Loss: 0.0101\n",
      "Epoch 135/200, Iteration 23/250, Loss: 0.0069\n",
      "Epoch 135/200, Iteration 24/250, Loss: 0.0184\n",
      "Epoch 135/200, Iteration 25/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 26/250, Loss: 0.0415\n",
      "Epoch 135/200, Iteration 27/250, Loss: 0.0109\n",
      "Epoch 135/200, Iteration 28/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 29/250, Loss: 0.0188\n",
      "Epoch 135/200, Iteration 30/250, Loss: 0.0081\n",
      "Epoch 135/200, Iteration 31/250, Loss: 0.0155\n",
      "Epoch 135/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 135/200, Iteration 33/250, Loss: 0.0241\n",
      "Epoch 135/200, Iteration 34/250, Loss: 0.0071\n",
      "Epoch 135/200, Iteration 35/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 36/250, Loss: 0.0075\n",
      "Epoch 135/200, Iteration 37/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 38/250, Loss: 0.0362\n",
      "Epoch 135/200, Iteration 39/250, Loss: 0.0276\n",
      "Epoch 135/200, Iteration 40/250, Loss: 0.0107\n",
      "Epoch 135/200, Iteration 41/250, Loss: 0.0157\n",
      "Epoch 135/200, Iteration 42/250, Loss: 0.0350\n",
      "Epoch 135/200, Iteration 43/250, Loss: 0.0151\n",
      "Epoch 135/200, Iteration 44/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 45/250, Loss: 0.0079\n",
      "Epoch 135/200, Iteration 46/250, Loss: 0.0445\n",
      "Epoch 135/200, Iteration 47/250, Loss: 0.0258\n",
      "Epoch 135/200, Iteration 48/250, Loss: 0.0183\n",
      "Epoch 135/200, Iteration 49/250, Loss: 0.0194\n",
      "Epoch 135/200, Iteration 50/250, Loss: 0.0075\n",
      "Epoch 135/200, Iteration 51/250, Loss: 0.0239\n",
      "Epoch 135/200, Iteration 52/250, Loss: 0.0209\n",
      "Epoch 135/200, Iteration 53/250, Loss: 0.0360\n",
      "Epoch 135/200, Iteration 54/250, Loss: 0.0097\n",
      "Epoch 135/200, Iteration 55/250, Loss: 0.0206\n",
      "Epoch 135/200, Iteration 56/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 135/200, Iteration 58/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 59/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 60/250, Loss: 0.0105\n",
      "Epoch 135/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 62/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 63/250, Loss: 0.0227\n",
      "Epoch 135/200, Iteration 64/250, Loss: 0.0208\n",
      "Epoch 135/200, Iteration 65/250, Loss: 0.0441\n",
      "Epoch 135/200, Iteration 66/250, Loss: 0.0133\n",
      "Epoch 135/200, Iteration 67/250, Loss: 0.0234\n",
      "Epoch 135/200, Iteration 68/250, Loss: 0.0129\n",
      "Epoch 135/200, Iteration 69/250, Loss: 0.0175\n",
      "Epoch 135/200, Iteration 70/250, Loss: 0.0100\n",
      "Epoch 135/200, Iteration 71/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 72/250, Loss: 0.0084\n",
      "Epoch 135/200, Iteration 73/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 74/250, Loss: 0.0241\n",
      "Epoch 135/200, Iteration 75/250, Loss: 0.0145\n",
      "Epoch 135/200, Iteration 76/250, Loss: 0.0080\n",
      "Epoch 135/200, Iteration 77/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 78/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 80/250, Loss: 0.0196\n",
      "Epoch 135/200, Iteration 81/250, Loss: 0.0207\n",
      "Epoch 135/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 135/200, Iteration 83/250, Loss: 0.0153\n",
      "Epoch 135/200, Iteration 84/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 85/250, Loss: 0.0097\n",
      "Epoch 135/200, Iteration 86/250, Loss: 0.0263\n",
      "Epoch 135/200, Iteration 87/250, Loss: 0.0131\n",
      "Epoch 135/200, Iteration 88/250, Loss: 0.0327\n",
      "Epoch 135/200, Iteration 89/250, Loss: 0.0259\n",
      "Epoch 135/200, Iteration 90/250, Loss: 0.0144\n",
      "Epoch 135/200, Iteration 91/250, Loss: 0.0094\n",
      "Epoch 135/200, Iteration 92/250, Loss: 0.0061\n",
      "Epoch 135/200, Iteration 93/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 94/250, Loss: 0.0122\n",
      "Epoch 135/200, Iteration 95/250, Loss: 0.0191\n",
      "Epoch 135/200, Iteration 96/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 97/250, Loss: 0.0139\n",
      "Epoch 135/200, Iteration 98/250, Loss: 0.0212\n",
      "Epoch 135/200, Iteration 99/250, Loss: 0.0108\n",
      "Epoch 135/200, Iteration 100/250, Loss: 0.0319\n",
      "Epoch 135/200, Iteration 101/250, Loss: 0.0322\n",
      "Epoch 135/200, Iteration 102/250, Loss: 0.0179\n",
      "Epoch 135/200, Iteration 103/250, Loss: 0.0144\n",
      "Epoch 135/200, Iteration 104/250, Loss: 0.0212\n",
      "Epoch 135/200, Iteration 105/250, Loss: 0.0172\n",
      "Epoch 135/200, Iteration 106/250, Loss: 0.0148\n",
      "Epoch 135/200, Iteration 107/250, Loss: 0.0216\n",
      "Epoch 135/200, Iteration 108/250, Loss: 0.0271\n",
      "Epoch 135/200, Iteration 109/250, Loss: 0.0155\n",
      "Epoch 135/200, Iteration 110/250, Loss: 0.0303\n",
      "Epoch 135/200, Iteration 111/250, Loss: 0.0191\n",
      "Epoch 135/200, Iteration 112/250, Loss: 0.0074\n",
      "Epoch 135/200, Iteration 113/250, Loss: 0.0088\n",
      "Epoch 135/200, Iteration 114/250, Loss: 0.0307\n",
      "Epoch 135/200, Iteration 115/250, Loss: 0.0225\n",
      "Epoch 135/200, Iteration 116/250, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 117/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 118/250, Loss: 0.0099\n",
      "Epoch 135/200, Iteration 119/250, Loss: 0.0098\n",
      "Epoch 135/200, Iteration 120/250, Loss: 0.0086\n",
      "Epoch 135/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 135/200, Iteration 122/250, Loss: 0.0253\n",
      "Epoch 135/200, Iteration 123/250, Loss: 0.0163\n",
      "Epoch 135/200, Iteration 124/250, Loss: 0.0175\n",
      "Epoch 135/200, Iteration 125/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 135/200, Iteration 127/250, Loss: 0.0154\n",
      "Epoch 135/200, Iteration 128/250, Loss: 0.0261\n",
      "Epoch 135/200, Iteration 129/250, Loss: 0.0235\n",
      "Epoch 135/200, Iteration 130/250, Loss: 0.0121\n",
      "Epoch 135/200, Iteration 131/250, Loss: 0.0094\n",
      "Epoch 135/200, Iteration 132/250, Loss: 0.0275\n",
      "Epoch 135/200, Iteration 133/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 134/250, Loss: 0.0123\n",
      "Epoch 135/200, Iteration 135/250, Loss: 0.0400\n",
      "Epoch 135/200, Iteration 136/250, Loss: 0.0283\n",
      "Epoch 135/200, Iteration 137/250, Loss: 0.0069\n",
      "Epoch 135/200, Iteration 138/250, Loss: 0.0197\n",
      "Epoch 135/200, Iteration 139/250, Loss: 0.0123\n",
      "Epoch 135/200, Iteration 140/250, Loss: 0.0295\n",
      "Epoch 135/200, Iteration 141/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 142/250, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 143/250, Loss: 0.0139\n",
      "Epoch 135/200, Iteration 144/250, Loss: 0.0106\n",
      "Epoch 135/200, Iteration 145/250, Loss: 0.0129\n",
      "Epoch 135/200, Iteration 146/250, Loss: 0.0146\n",
      "Epoch 135/200, Iteration 147/250, Loss: 0.0115\n",
      "Epoch 135/200, Iteration 148/250, Loss: 0.0170\n",
      "Epoch 135/200, Iteration 149/250, Loss: 0.0105\n",
      "Epoch 135/200, Iteration 150/250, Loss: 0.0336\n",
      "Epoch 135/200, Iteration 151/250, Loss: 0.0145\n",
      "Epoch 135/200, Iteration 152/250, Loss: 0.0089\n",
      "Epoch 135/200, Iteration 153/250, Loss: 0.0099\n",
      "Epoch 135/200, Iteration 154/250, Loss: 0.0111\n",
      "Epoch 135/200, Iteration 155/250, Loss: 0.0159\n",
      "Epoch 135/200, Iteration 156/250, Loss: 0.0216\n",
      "Epoch 135/200, Iteration 157/250, Loss: 0.0140\n",
      "Epoch 135/200, Iteration 158/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 159/250, Loss: 0.0184\n",
      "Epoch 135/200, Iteration 160/250, Loss: 0.0094\n",
      "Epoch 135/200, Iteration 161/250, Loss: 0.0070\n",
      "Epoch 135/200, Iteration 162/250, Loss: 0.0168\n",
      "Epoch 135/200, Iteration 163/250, Loss: 0.0249\n",
      "Epoch 135/200, Iteration 164/250, Loss: 0.0071\n",
      "Epoch 135/200, Iteration 165/250, Loss: 0.0148\n",
      "Epoch 135/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 135/200, Iteration 167/250, Loss: 0.0220\n",
      "Epoch 135/200, Iteration 168/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 169/250, Loss: 0.0241\n",
      "Epoch 135/200, Iteration 170/250, Loss: 0.0126\n",
      "Epoch 135/200, Iteration 171/250, Loss: 0.0089\n",
      "Epoch 135/200, Iteration 172/250, Loss: 0.0090\n",
      "Epoch 135/200, Iteration 173/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 174/250, Loss: 0.0082\n",
      "Epoch 135/200, Iteration 175/250, Loss: 0.0086\n",
      "Epoch 135/200, Iteration 176/250, Loss: 0.0129\n",
      "Epoch 135/200, Iteration 177/250, Loss: 0.0130\n",
      "Epoch 135/200, Iteration 178/250, Loss: 0.0227\n",
      "Epoch 135/200, Iteration 179/250, Loss: 0.0107\n",
      "Epoch 135/200, Iteration 180/250, Loss: 0.0118\n",
      "Epoch 135/200, Iteration 181/250, Loss: 0.0102\n",
      "Epoch 135/200, Iteration 182/250, Loss: 0.0182\n",
      "Epoch 135/200, Iteration 183/250, Loss: 0.0218\n",
      "Epoch 135/200, Iteration 184/250, Loss: 0.0234\n",
      "Epoch 135/200, Iteration 185/250, Loss: 0.0187\n",
      "Epoch 135/200, Iteration 186/250, Loss: 0.0112\n",
      "Epoch 135/200, Iteration 187/250, Loss: 0.0125\n",
      "Epoch 135/200, Iteration 188/250, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200, Iteration 189/250, Loss: 0.0308\n",
      "Epoch 135/200, Iteration 190/250, Loss: 0.0122\n",
      "Epoch 135/200, Iteration 191/250, Loss: 0.0093\n",
      "Epoch 135/200, Iteration 192/250, Loss: 0.0160\n",
      "Epoch 135/200, Iteration 193/250, Loss: 0.0246\n",
      "Epoch 135/200, Iteration 194/250, Loss: 0.0170\n",
      "Epoch 135/200, Iteration 195/250, Loss: 0.0064\n",
      "Epoch 135/200, Iteration 196/250, Loss: 0.0502\n",
      "Epoch 135/200, Iteration 197/250, Loss: 0.0095\n",
      "Epoch 135/200, Iteration 198/250, Loss: 0.0138\n",
      "Epoch 135/200, Iteration 199/250, Loss: 0.0118\n",
      "Epoch 135/200, Iteration 200/250, Loss: 0.0250\n",
      "Epoch 135/200, Iteration 201/250, Loss: 0.0314\n",
      "Epoch 135/200, Iteration 202/250, Loss: 0.0189\n",
      "Epoch 135/200, Iteration 203/250, Loss: 0.0217\n",
      "Epoch 135/200, Iteration 204/250, Loss: 0.0292\n",
      "Epoch 135/200, Iteration 205/250, Loss: 0.0071\n",
      "Epoch 135/200, Iteration 206/250, Loss: 0.0100\n",
      "Epoch 135/200, Iteration 207/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 208/250, Loss: 0.0198\n",
      "Epoch 135/200, Iteration 209/250, Loss: 0.0118\n",
      "Epoch 135/200, Iteration 210/250, Loss: 0.0096\n",
      "Epoch 135/200, Iteration 211/250, Loss: 0.0154\n",
      "Epoch 135/200, Iteration 212/250, Loss: 0.0137\n",
      "Epoch 135/200, Iteration 213/250, Loss: 0.0083\n",
      "Epoch 135/200, Iteration 214/250, Loss: 0.0124\n",
      "Epoch 135/200, Iteration 215/250, Loss: 0.0125\n",
      "Epoch 135/200, Iteration 216/250, Loss: 0.0091\n",
      "Epoch 135/200, Iteration 217/250, Loss: 0.0177\n",
      "Epoch 135/200, Iteration 218/250, Loss: 0.0119\n",
      "Epoch 135/200, Iteration 219/250, Loss: 0.0143\n",
      "Epoch 135/200, Iteration 220/250, Loss: 0.0166\n",
      "Epoch 135/200, Iteration 221/250, Loss: 0.0226\n",
      "Epoch 135/200, Iteration 222/250, Loss: 0.0092\n",
      "Epoch 135/200, Iteration 223/250, Loss: 0.0143\n",
      "Epoch 135/200, Iteration 224/250, Loss: 0.0236\n",
      "Epoch 135/200, Iteration 225/250, Loss: 0.0258\n",
      "Epoch 135/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 135/200, Iteration 227/250, Loss: 0.0261\n",
      "Epoch 135/200, Iteration 228/250, Loss: 0.0246\n",
      "Epoch 135/200, Iteration 229/250, Loss: 0.0075\n",
      "Epoch 135/200, Iteration 230/250, Loss: 0.0080\n",
      "Epoch 135/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 135/200, Iteration 232/250, Loss: 0.0073\n",
      "Epoch 135/200, Iteration 233/250, Loss: 0.0237\n",
      "Epoch 135/200, Iteration 234/250, Loss: 0.0255\n",
      "Epoch 135/200, Iteration 235/250, Loss: 0.0391\n",
      "Epoch 135/200, Iteration 236/250, Loss: 0.0256\n",
      "Epoch 135/200, Iteration 237/250, Loss: 0.0126\n",
      "Epoch 135/200, Iteration 238/250, Loss: 0.0104\n",
      "Epoch 135/200, Iteration 239/250, Loss: 0.0127\n",
      "Epoch 135/200, Iteration 240/250, Loss: 0.0306\n",
      "Epoch 135/200, Iteration 241/250, Loss: 0.0103\n",
      "Epoch 135/200, Iteration 242/250, Loss: 0.0134\n",
      "Epoch 135/200, Iteration 243/250, Loss: 0.0132\n",
      "Epoch 135/200, Iteration 244/250, Loss: 0.0217\n",
      "Epoch 135/200, Iteration 245/250, Loss: 0.0072\n",
      "Epoch 135/200, Iteration 246/250, Loss: 0.0112\n",
      "Epoch 135/200, Iteration 247/250, Loss: 0.0148\n",
      "Epoch 135/200, Iteration 248/250, Loss: 0.0075\n",
      "Epoch 135/200, Iteration 249/250, Loss: 0.0133\n",
      "Epoch 135/200, Iteration 250/250, Loss: 0.0161\n",
      "Train Error: \n",
      " Accuracy: 88.11%, Avg loss: 0.007111, MRE: 0.479522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.75%, Avg loss: 0.007647, MRE: 0.550358 \n",
      "\n",
      "Epoch 136/200, Iteration 1/250, Loss: 0.0093\n",
      "Epoch 136/200, Iteration 2/250, Loss: 0.0165\n",
      "Epoch 136/200, Iteration 3/250, Loss: 0.0162\n",
      "Epoch 136/200, Iteration 4/250, Loss: 0.0207\n",
      "Epoch 136/200, Iteration 5/250, Loss: 0.0122\n",
      "Epoch 136/200, Iteration 6/250, Loss: 0.0155\n",
      "Epoch 136/200, Iteration 7/250, Loss: 0.0136\n",
      "Epoch 136/200, Iteration 8/250, Loss: 0.0216\n",
      "Epoch 136/200, Iteration 9/250, Loss: 0.0149\n",
      "Epoch 136/200, Iteration 10/250, Loss: 0.0194\n",
      "Epoch 136/200, Iteration 11/250, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 12/250, Loss: 0.0066\n",
      "Epoch 136/200, Iteration 13/250, Loss: 0.0139\n",
      "Epoch 136/200, Iteration 14/250, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 15/250, Loss: 0.0254\n",
      "Epoch 136/200, Iteration 16/250, Loss: 0.0101\n",
      "Epoch 136/200, Iteration 17/250, Loss: 0.0209\n",
      "Epoch 136/200, Iteration 18/250, Loss: 0.0089\n",
      "Epoch 136/200, Iteration 19/250, Loss: 0.0069\n",
      "Epoch 136/200, Iteration 20/250, Loss: 0.0077\n",
      "Epoch 136/200, Iteration 21/250, Loss: 0.0215\n",
      "Epoch 136/200, Iteration 22/250, Loss: 0.0086\n",
      "Epoch 136/200, Iteration 23/250, Loss: 0.0234\n",
      "Epoch 136/200, Iteration 24/250, Loss: 0.0131\n",
      "Epoch 136/200, Iteration 25/250, Loss: 0.0089\n",
      "Epoch 136/200, Iteration 26/250, Loss: 0.0301\n",
      "Epoch 136/200, Iteration 27/250, Loss: 0.0157\n",
      "Epoch 136/200, Iteration 28/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 29/250, Loss: 0.0106\n",
      "Epoch 136/200, Iteration 30/250, Loss: 0.0157\n",
      "Epoch 136/200, Iteration 31/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 32/250, Loss: 0.0233\n",
      "Epoch 136/200, Iteration 33/250, Loss: 0.0084\n",
      "Epoch 136/200, Iteration 34/250, Loss: 0.0096\n",
      "Epoch 136/200, Iteration 35/250, Loss: 0.0205\n",
      "Epoch 136/200, Iteration 36/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 37/250, Loss: 0.0219\n",
      "Epoch 136/200, Iteration 38/250, Loss: 0.0151\n",
      "Epoch 136/200, Iteration 39/250, Loss: 0.0085\n",
      "Epoch 136/200, Iteration 40/250, Loss: 0.0092\n",
      "Epoch 136/200, Iteration 41/250, Loss: 0.0076\n",
      "Epoch 136/200, Iteration 42/250, Loss: 0.0141\n",
      "Epoch 136/200, Iteration 43/250, Loss: 0.0217\n",
      "Epoch 136/200, Iteration 44/250, Loss: 0.0156\n",
      "Epoch 136/200, Iteration 45/250, Loss: 0.0319\n",
      "Epoch 136/200, Iteration 46/250, Loss: 0.0089\n",
      "Epoch 136/200, Iteration 47/250, Loss: 0.0082\n",
      "Epoch 136/200, Iteration 48/250, Loss: 0.0113\n",
      "Epoch 136/200, Iteration 49/250, Loss: 0.0316\n",
      "Epoch 136/200, Iteration 50/250, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 51/250, Loss: 0.0146\n",
      "Epoch 136/200, Iteration 52/250, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 53/250, Loss: 0.0080\n",
      "Epoch 136/200, Iteration 54/250, Loss: 0.0088\n",
      "Epoch 136/200, Iteration 55/250, Loss: 0.0091\n",
      "Epoch 136/200, Iteration 56/250, Loss: 0.0283\n",
      "Epoch 136/200, Iteration 57/250, Loss: 0.0066\n",
      "Epoch 136/200, Iteration 58/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 59/250, Loss: 0.0115\n",
      "Epoch 136/200, Iteration 60/250, Loss: 0.0104\n",
      "Epoch 136/200, Iteration 61/250, Loss: 0.0407\n",
      "Epoch 136/200, Iteration 62/250, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 63/250, Loss: 0.0150\n",
      "Epoch 136/200, Iteration 64/250, Loss: 0.0114\n",
      "Epoch 136/200, Iteration 65/250, Loss: 0.0179\n",
      "Epoch 136/200, Iteration 66/250, Loss: 0.0200\n",
      "Epoch 136/200, Iteration 67/250, Loss: 0.0078\n",
      "Epoch 136/200, Iteration 68/250, Loss: 0.0088\n",
      "Epoch 136/200, Iteration 69/250, Loss: 0.0101\n",
      "Epoch 136/200, Iteration 70/250, Loss: 0.0104\n",
      "Epoch 136/200, Iteration 71/250, Loss: 0.0119\n",
      "Epoch 136/200, Iteration 72/250, Loss: 0.0246\n",
      "Epoch 136/200, Iteration 73/250, Loss: 0.0138\n",
      "Epoch 136/200, Iteration 74/250, Loss: 0.0142\n",
      "Epoch 136/200, Iteration 75/250, Loss: 0.0100\n",
      "Epoch 136/200, Iteration 76/250, Loss: 0.0140\n",
      "Epoch 136/200, Iteration 77/250, Loss: 0.0131\n",
      "Epoch 136/200, Iteration 78/250, Loss: 0.0150\n",
      "Epoch 136/200, Iteration 79/250, Loss: 0.0102\n",
      "Epoch 136/200, Iteration 80/250, Loss: 0.0139\n",
      "Epoch 136/200, Iteration 81/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 82/250, Loss: 0.0083\n",
      "Epoch 136/200, Iteration 83/250, Loss: 0.0092\n",
      "Epoch 136/200, Iteration 84/250, Loss: 0.0130\n",
      "Epoch 136/200, Iteration 85/250, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 86/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 87/250, Loss: 0.0166\n",
      "Epoch 136/200, Iteration 88/250, Loss: 0.0284\n",
      "Epoch 136/200, Iteration 89/250, Loss: 0.0127\n",
      "Epoch 136/200, Iteration 90/250, Loss: 0.0229\n",
      "Epoch 136/200, Iteration 91/250, Loss: 0.0113\n",
      "Epoch 136/200, Iteration 92/250, Loss: 0.0117\n",
      "Epoch 136/200, Iteration 93/250, Loss: 0.0153\n",
      "Epoch 136/200, Iteration 94/250, Loss: 0.0158\n",
      "Epoch 136/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 136/200, Iteration 96/250, Loss: 0.0160\n",
      "Epoch 136/200, Iteration 97/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 98/250, Loss: 0.0151\n",
      "Epoch 136/200, Iteration 99/250, Loss: 0.0260\n",
      "Epoch 136/200, Iteration 100/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 101/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 102/250, Loss: 0.0112\n",
      "Epoch 136/200, Iteration 103/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 104/250, Loss: 0.0109\n",
      "Epoch 136/200, Iteration 105/250, Loss: 0.0277\n",
      "Epoch 136/200, Iteration 106/250, Loss: 0.0086\n",
      "Epoch 136/200, Iteration 107/250, Loss: 0.0119\n",
      "Epoch 136/200, Iteration 108/250, Loss: 0.0219\n",
      "Epoch 136/200, Iteration 109/250, Loss: 0.0111\n",
      "Epoch 136/200, Iteration 110/250, Loss: 0.0108\n",
      "Epoch 136/200, Iteration 111/250, Loss: 0.0281\n",
      "Epoch 136/200, Iteration 112/250, Loss: 0.0097\n",
      "Epoch 136/200, Iteration 113/250, Loss: 0.0167\n",
      "Epoch 136/200, Iteration 114/250, Loss: 0.0072\n",
      "Epoch 136/200, Iteration 115/250, Loss: 0.0182\n",
      "Epoch 136/200, Iteration 116/250, Loss: 0.0083\n",
      "Epoch 136/200, Iteration 117/250, Loss: 0.0347\n",
      "Epoch 136/200, Iteration 118/250, Loss: 0.0111\n",
      "Epoch 136/200, Iteration 119/250, Loss: 0.0194\n",
      "Epoch 136/200, Iteration 120/250, Loss: 0.0165\n",
      "Epoch 136/200, Iteration 121/250, Loss: 0.0153\n",
      "Epoch 136/200, Iteration 122/250, Loss: 0.0140\n",
      "Epoch 136/200, Iteration 123/250, Loss: 0.0124\n",
      "Epoch 136/200, Iteration 124/250, Loss: 0.0182\n",
      "Epoch 136/200, Iteration 125/250, Loss: 0.0362\n",
      "Epoch 136/200, Iteration 126/250, Loss: 0.0164\n",
      "Epoch 136/200, Iteration 127/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 128/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 129/250, Loss: 0.0156\n",
      "Epoch 136/200, Iteration 130/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 131/250, Loss: 0.0106\n",
      "Epoch 136/200, Iteration 132/250, Loss: 0.0229\n",
      "Epoch 136/200, Iteration 133/250, Loss: 0.0093\n",
      "Epoch 136/200, Iteration 134/250, Loss: 0.0113\n",
      "Epoch 136/200, Iteration 135/250, Loss: 0.0232\n",
      "Epoch 136/200, Iteration 136/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 137/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 138/250, Loss: 0.0082\n",
      "Epoch 136/200, Iteration 139/250, Loss: 0.0079\n",
      "Epoch 136/200, Iteration 140/250, Loss: 0.0173\n",
      "Epoch 136/200, Iteration 141/250, Loss: 0.0123\n",
      "Epoch 136/200, Iteration 142/250, Loss: 0.0379\n",
      "Epoch 136/200, Iteration 143/250, Loss: 0.0149\n",
      "Epoch 136/200, Iteration 144/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 145/250, Loss: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200, Iteration 146/250, Loss: 0.0095\n",
      "Epoch 136/200, Iteration 147/250, Loss: 0.0188\n",
      "Epoch 136/200, Iteration 148/250, Loss: 0.0180\n",
      "Epoch 136/200, Iteration 149/250, Loss: 0.0133\n",
      "Epoch 136/200, Iteration 150/250, Loss: 0.0360\n",
      "Epoch 136/200, Iteration 151/250, Loss: 0.0239\n",
      "Epoch 136/200, Iteration 152/250, Loss: 0.0243\n",
      "Epoch 136/200, Iteration 153/250, Loss: 0.0230\n",
      "Epoch 136/200, Iteration 154/250, Loss: 0.0145\n",
      "Epoch 136/200, Iteration 155/250, Loss: 0.0154\n",
      "Epoch 136/200, Iteration 156/250, Loss: 0.0251\n",
      "Epoch 136/200, Iteration 157/250, Loss: 0.0179\n",
      "Epoch 136/200, Iteration 158/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 159/250, Loss: 0.0159\n",
      "Epoch 136/200, Iteration 160/250, Loss: 0.0171\n",
      "Epoch 136/200, Iteration 161/250, Loss: 0.0303\n",
      "Epoch 136/200, Iteration 162/250, Loss: 0.0163\n",
      "Epoch 136/200, Iteration 163/250, Loss: 0.0064\n",
      "Epoch 136/200, Iteration 164/250, Loss: 0.0151\n",
      "Epoch 136/200, Iteration 165/250, Loss: 0.0089\n",
      "Epoch 136/200, Iteration 166/250, Loss: 0.0121\n",
      "Epoch 136/200, Iteration 167/250, Loss: 0.0165\n",
      "Epoch 136/200, Iteration 168/250, Loss: 0.0107\n",
      "Epoch 136/200, Iteration 169/250, Loss: 0.0129\n",
      "Epoch 136/200, Iteration 170/250, Loss: 0.0147\n",
      "Epoch 136/200, Iteration 171/250, Loss: 0.0243\n",
      "Epoch 136/200, Iteration 172/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 173/250, Loss: 0.0407\n",
      "Epoch 136/200, Iteration 174/250, Loss: 0.0150\n",
      "Epoch 136/200, Iteration 175/250, Loss: 0.0087\n",
      "Epoch 136/200, Iteration 176/250, Loss: 0.0110\n",
      "Epoch 136/200, Iteration 177/250, Loss: 0.0467\n",
      "Epoch 136/200, Iteration 178/250, Loss: 0.0077\n",
      "Epoch 136/200, Iteration 179/250, Loss: 0.0092\n",
      "Epoch 136/200, Iteration 180/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 181/250, Loss: 0.0226\n",
      "Epoch 136/200, Iteration 182/250, Loss: 0.0239\n",
      "Epoch 136/200, Iteration 183/250, Loss: 0.0146\n",
      "Epoch 136/200, Iteration 184/250, Loss: 0.0176\n",
      "Epoch 136/200, Iteration 185/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 186/250, Loss: 0.0067\n",
      "Epoch 136/200, Iteration 187/250, Loss: 0.0114\n",
      "Epoch 136/200, Iteration 188/250, Loss: 0.0195\n",
      "Epoch 136/200, Iteration 189/250, Loss: 0.0221\n",
      "Epoch 136/200, Iteration 190/250, Loss: 0.0105\n",
      "Epoch 136/200, Iteration 191/250, Loss: 0.0232\n",
      "Epoch 136/200, Iteration 192/250, Loss: 0.0204\n",
      "Epoch 136/200, Iteration 193/250, Loss: 0.0074\n",
      "Epoch 136/200, Iteration 194/250, Loss: 0.0083\n",
      "Epoch 136/200, Iteration 195/250, Loss: 0.0154\n",
      "Epoch 136/200, Iteration 196/250, Loss: 0.0278\n",
      "Epoch 136/200, Iteration 197/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 136/200, Iteration 199/250, Loss: 0.0223\n",
      "Epoch 136/200, Iteration 200/250, Loss: 0.0331\n",
      "Epoch 136/200, Iteration 201/250, Loss: 0.0373\n",
      "Epoch 136/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 136/200, Iteration 203/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 204/250, Loss: 0.0101\n",
      "Epoch 136/200, Iteration 205/250, Loss: 0.0132\n",
      "Epoch 136/200, Iteration 206/250, Loss: 0.0070\n",
      "Epoch 136/200, Iteration 207/250, Loss: 0.0145\n",
      "Epoch 136/200, Iteration 208/250, Loss: 0.0197\n",
      "Epoch 136/200, Iteration 209/250, Loss: 0.0080\n",
      "Epoch 136/200, Iteration 210/250, Loss: 0.0123\n",
      "Epoch 136/200, Iteration 211/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 212/250, Loss: 0.0182\n",
      "Epoch 136/200, Iteration 213/250, Loss: 0.0190\n",
      "Epoch 136/200, Iteration 214/250, Loss: 0.0113\n",
      "Epoch 136/200, Iteration 215/250, Loss: 0.0076\n",
      "Epoch 136/200, Iteration 216/250, Loss: 0.0139\n",
      "Epoch 136/200, Iteration 217/250, Loss: 0.0116\n",
      "Epoch 136/200, Iteration 218/250, Loss: 0.0185\n",
      "Epoch 136/200, Iteration 219/250, Loss: 0.0160\n",
      "Epoch 136/200, Iteration 220/250, Loss: 0.0101\n",
      "Epoch 136/200, Iteration 221/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 222/250, Loss: 0.0175\n",
      "Epoch 136/200, Iteration 223/250, Loss: 0.0101\n",
      "Epoch 136/200, Iteration 224/250, Loss: 0.0125\n",
      "Epoch 136/200, Iteration 225/250, Loss: 0.0123\n",
      "Epoch 136/200, Iteration 226/250, Loss: 0.0137\n",
      "Epoch 136/200, Iteration 227/250, Loss: 0.0159\n",
      "Epoch 136/200, Iteration 228/250, Loss: 0.0208\n",
      "Epoch 136/200, Iteration 229/250, Loss: 0.0159\n",
      "Epoch 136/200, Iteration 230/250, Loss: 0.0274\n",
      "Epoch 136/200, Iteration 231/250, Loss: 0.0112\n",
      "Epoch 136/200, Iteration 232/250, Loss: 0.0202\n",
      "Epoch 136/200, Iteration 233/250, Loss: 0.0078\n",
      "Epoch 136/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 136/200, Iteration 235/250, Loss: 0.0174\n",
      "Epoch 136/200, Iteration 236/250, Loss: 0.0130\n",
      "Epoch 136/200, Iteration 237/250, Loss: 0.0145\n",
      "Epoch 136/200, Iteration 238/250, Loss: 0.0199\n",
      "Epoch 136/200, Iteration 239/250, Loss: 0.0165\n",
      "Epoch 136/200, Iteration 240/250, Loss: 0.0152\n",
      "Epoch 136/200, Iteration 241/250, Loss: 0.0120\n",
      "Epoch 136/200, Iteration 242/250, Loss: 0.0308\n",
      "Epoch 136/200, Iteration 243/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 244/250, Loss: 0.0068\n",
      "Epoch 136/200, Iteration 245/250, Loss: 0.0118\n",
      "Epoch 136/200, Iteration 246/250, Loss: 0.0143\n",
      "Epoch 136/200, Iteration 247/250, Loss: 0.0094\n",
      "Epoch 136/200, Iteration 248/250, Loss: 0.0147\n",
      "Epoch 136/200, Iteration 249/250, Loss: 0.0173\n",
      "Epoch 136/200, Iteration 250/250, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 87.74%, Avg loss: 0.006758, MRE: 0.485447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.007307, MRE: 0.494041 \n",
      "\n",
      "Epoch 137/200, Iteration 1/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 2/250, Loss: 0.0151\n",
      "Epoch 137/200, Iteration 3/250, Loss: 0.0286\n",
      "Epoch 137/200, Iteration 4/250, Loss: 0.0092\n",
      "Epoch 137/200, Iteration 5/250, Loss: 0.0288\n",
      "Epoch 137/200, Iteration 6/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 7/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 8/250, Loss: 0.0229\n",
      "Epoch 137/200, Iteration 9/250, Loss: 0.0072\n",
      "Epoch 137/200, Iteration 10/250, Loss: 0.0127\n",
      "Epoch 137/200, Iteration 11/250, Loss: 0.0148\n",
      "Epoch 137/200, Iteration 12/250, Loss: 0.0172\n",
      "Epoch 137/200, Iteration 13/250, Loss: 0.0367\n",
      "Epoch 137/200, Iteration 14/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 15/250, Loss: 0.0094\n",
      "Epoch 137/200, Iteration 16/250, Loss: 0.0104\n",
      "Epoch 137/200, Iteration 17/250, Loss: 0.0136\n",
      "Epoch 137/200, Iteration 18/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 19/250, Loss: 0.0195\n",
      "Epoch 137/200, Iteration 20/250, Loss: 0.0108\n",
      "Epoch 137/200, Iteration 21/250, Loss: 0.0207\n",
      "Epoch 137/200, Iteration 22/250, Loss: 0.0143\n",
      "Epoch 137/200, Iteration 23/250, Loss: 0.0149\n",
      "Epoch 137/200, Iteration 24/250, Loss: 0.0308\n",
      "Epoch 137/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 137/200, Iteration 26/250, Loss: 0.0191\n",
      "Epoch 137/200, Iteration 27/250, Loss: 0.0110\n",
      "Epoch 137/200, Iteration 28/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 29/250, Loss: 0.0261\n",
      "Epoch 137/200, Iteration 30/250, Loss: 0.0171\n",
      "Epoch 137/200, Iteration 31/250, Loss: 0.0120\n",
      "Epoch 137/200, Iteration 32/250, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 33/250, Loss: 0.0258\n",
      "Epoch 137/200, Iteration 34/250, Loss: 0.0090\n",
      "Epoch 137/200, Iteration 35/250, Loss: 0.0204\n",
      "Epoch 137/200, Iteration 36/250, Loss: 0.0077\n",
      "Epoch 137/200, Iteration 37/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 38/250, Loss: 0.0076\n",
      "Epoch 137/200, Iteration 39/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 40/250, Loss: 0.0074\n",
      "Epoch 137/200, Iteration 41/250, Loss: 0.0180\n",
      "Epoch 137/200, Iteration 42/250, Loss: 0.0094\n",
      "Epoch 137/200, Iteration 43/250, Loss: 0.0179\n",
      "Epoch 137/200, Iteration 44/250, Loss: 0.0087\n",
      "Epoch 137/200, Iteration 45/250, Loss: 0.0124\n",
      "Epoch 137/200, Iteration 46/250, Loss: 0.0251\n",
      "Epoch 137/200, Iteration 47/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 48/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 49/250, Loss: 0.0081\n",
      "Epoch 137/200, Iteration 50/250, Loss: 0.0144\n",
      "Epoch 137/200, Iteration 51/250, Loss: 0.0142\n",
      "Epoch 137/200, Iteration 52/250, Loss: 0.0237\n",
      "Epoch 137/200, Iteration 53/250, Loss: 0.0282\n",
      "Epoch 137/200, Iteration 54/250, Loss: 0.0145\n",
      "Epoch 137/200, Iteration 55/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 56/250, Loss: 0.0257\n",
      "Epoch 137/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 137/200, Iteration 58/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 59/250, Loss: 0.0160\n",
      "Epoch 137/200, Iteration 60/250, Loss: 0.0160\n",
      "Epoch 137/200, Iteration 61/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 62/250, Loss: 0.0166\n",
      "Epoch 137/200, Iteration 63/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 137/200, Iteration 65/250, Loss: 0.0262\n",
      "Epoch 137/200, Iteration 66/250, Loss: 0.0140\n",
      "Epoch 137/200, Iteration 67/250, Loss: 0.0318\n",
      "Epoch 137/200, Iteration 68/250, Loss: 0.0124\n",
      "Epoch 137/200, Iteration 69/250, Loss: 0.0103\n",
      "Epoch 137/200, Iteration 70/250, Loss: 0.0117\n",
      "Epoch 137/200, Iteration 71/250, Loss: 0.0076\n",
      "Epoch 137/200, Iteration 72/250, Loss: 0.0197\n",
      "Epoch 137/200, Iteration 73/250, Loss: 0.0169\n",
      "Epoch 137/200, Iteration 74/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 75/250, Loss: 0.0144\n",
      "Epoch 137/200, Iteration 76/250, Loss: 0.0166\n",
      "Epoch 137/200, Iteration 77/250, Loss: 0.0418\n",
      "Epoch 137/200, Iteration 78/250, Loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200, Iteration 79/250, Loss: 0.0416\n",
      "Epoch 137/200, Iteration 80/250, Loss: 0.0074\n",
      "Epoch 137/200, Iteration 81/250, Loss: 0.0269\n",
      "Epoch 137/200, Iteration 82/250, Loss: 0.0173\n",
      "Epoch 137/200, Iteration 83/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 84/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 85/250, Loss: 0.0166\n",
      "Epoch 137/200, Iteration 86/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 87/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 88/250, Loss: 0.0163\n",
      "Epoch 137/200, Iteration 89/250, Loss: 0.0197\n",
      "Epoch 137/200, Iteration 90/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 91/250, Loss: 0.0089\n",
      "Epoch 137/200, Iteration 92/250, Loss: 0.0138\n",
      "Epoch 137/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 137/200, Iteration 94/250, Loss: 0.0108\n",
      "Epoch 137/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 137/200, Iteration 96/250, Loss: 0.0174\n",
      "Epoch 137/200, Iteration 97/250, Loss: 0.0186\n",
      "Epoch 137/200, Iteration 98/250, Loss: 0.0222\n",
      "Epoch 137/200, Iteration 99/250, Loss: 0.0320\n",
      "Epoch 137/200, Iteration 100/250, Loss: 0.0219\n",
      "Epoch 137/200, Iteration 101/250, Loss: 0.0138\n",
      "Epoch 137/200, Iteration 102/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 103/250, Loss: 0.0230\n",
      "Epoch 137/200, Iteration 104/250, Loss: 0.0189\n",
      "Epoch 137/200, Iteration 105/250, Loss: 0.0151\n",
      "Epoch 137/200, Iteration 106/250, Loss: 0.0162\n",
      "Epoch 137/200, Iteration 107/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 108/250, Loss: 0.0199\n",
      "Epoch 137/200, Iteration 109/250, Loss: 0.0088\n",
      "Epoch 137/200, Iteration 110/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 111/250, Loss: 0.0087\n",
      "Epoch 137/200, Iteration 112/250, Loss: 0.0230\n",
      "Epoch 137/200, Iteration 113/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 114/250, Loss: 0.0139\n",
      "Epoch 137/200, Iteration 115/250, Loss: 0.0096\n",
      "Epoch 137/200, Iteration 116/250, Loss: 0.0194\n",
      "Epoch 137/200, Iteration 117/250, Loss: 0.0309\n",
      "Epoch 137/200, Iteration 118/250, Loss: 0.0106\n",
      "Epoch 137/200, Iteration 119/250, Loss: 0.0338\n",
      "Epoch 137/200, Iteration 120/250, Loss: 0.0235\n",
      "Epoch 137/200, Iteration 121/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 122/250, Loss: 0.0107\n",
      "Epoch 137/200, Iteration 123/250, Loss: 0.0208\n",
      "Epoch 137/200, Iteration 124/250, Loss: 0.0235\n",
      "Epoch 137/200, Iteration 125/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 126/250, Loss: 0.0209\n",
      "Epoch 137/200, Iteration 127/250, Loss: 0.0106\n",
      "Epoch 137/200, Iteration 128/250, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 129/250, Loss: 0.0257\n",
      "Epoch 137/200, Iteration 130/250, Loss: 0.0083\n",
      "Epoch 137/200, Iteration 131/250, Loss: 0.0074\n",
      "Epoch 137/200, Iteration 132/250, Loss: 0.0091\n",
      "Epoch 137/200, Iteration 133/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 135/250, Loss: 0.0089\n",
      "Epoch 137/200, Iteration 136/250, Loss: 0.0130\n",
      "Epoch 137/200, Iteration 137/250, Loss: 0.0088\n",
      "Epoch 137/200, Iteration 138/250, Loss: 0.0165\n",
      "Epoch 137/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 137/200, Iteration 140/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 141/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 142/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 143/250, Loss: 0.0311\n",
      "Epoch 137/200, Iteration 144/250, Loss: 0.0258\n",
      "Epoch 137/200, Iteration 145/250, Loss: 0.0142\n",
      "Epoch 137/200, Iteration 146/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 148/250, Loss: 0.0065\n",
      "Epoch 137/200, Iteration 149/250, Loss: 0.0172\n",
      "Epoch 137/200, Iteration 150/250, Loss: 0.0241\n",
      "Epoch 137/200, Iteration 151/250, Loss: 0.0118\n",
      "Epoch 137/200, Iteration 152/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 137/200, Iteration 154/250, Loss: 0.0423\n",
      "Epoch 137/200, Iteration 155/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 156/250, Loss: 0.0199\n",
      "Epoch 137/200, Iteration 157/250, Loss: 0.0204\n",
      "Epoch 137/200, Iteration 158/250, Loss: 0.0090\n",
      "Epoch 137/200, Iteration 159/250, Loss: 0.0155\n",
      "Epoch 137/200, Iteration 160/250, Loss: 0.0098\n",
      "Epoch 137/200, Iteration 161/250, Loss: 0.0152\n",
      "Epoch 137/200, Iteration 162/250, Loss: 0.0160\n",
      "Epoch 137/200, Iteration 163/250, Loss: 0.0152\n",
      "Epoch 137/200, Iteration 164/250, Loss: 0.0114\n",
      "Epoch 137/200, Iteration 165/250, Loss: 0.0152\n",
      "Epoch 137/200, Iteration 166/250, Loss: 0.0414\n",
      "Epoch 137/200, Iteration 167/250, Loss: 0.0317\n",
      "Epoch 137/200, Iteration 168/250, Loss: 0.0132\n",
      "Epoch 137/200, Iteration 169/250, Loss: 0.0097\n",
      "Epoch 137/200, Iteration 170/250, Loss: 0.0119\n",
      "Epoch 137/200, Iteration 171/250, Loss: 0.0079\n",
      "Epoch 137/200, Iteration 172/250, Loss: 0.0181\n",
      "Epoch 137/200, Iteration 173/250, Loss: 0.0336\n",
      "Epoch 137/200, Iteration 174/250, Loss: 0.0153\n",
      "Epoch 137/200, Iteration 175/250, Loss: 0.0077\n",
      "Epoch 137/200, Iteration 176/250, Loss: 0.0063\n",
      "Epoch 137/200, Iteration 177/250, Loss: 0.0123\n",
      "Epoch 137/200, Iteration 178/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 179/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 180/250, Loss: 0.0136\n",
      "Epoch 137/200, Iteration 181/250, Loss: 0.0131\n",
      "Epoch 137/200, Iteration 182/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 137/200, Iteration 184/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 185/250, Loss: 0.0099\n",
      "Epoch 137/200, Iteration 186/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 187/250, Loss: 0.0132\n",
      "Epoch 137/200, Iteration 188/250, Loss: 0.0106\n",
      "Epoch 137/200, Iteration 189/250, Loss: 0.0076\n",
      "Epoch 137/200, Iteration 190/250, Loss: 0.0077\n",
      "Epoch 137/200, Iteration 191/250, Loss: 0.0223\n",
      "Epoch 137/200, Iteration 192/250, Loss: 0.0136\n",
      "Epoch 137/200, Iteration 193/250, Loss: 0.0122\n",
      "Epoch 137/200, Iteration 194/250, Loss: 0.0329\n",
      "Epoch 137/200, Iteration 195/250, Loss: 0.0085\n",
      "Epoch 137/200, Iteration 196/250, Loss: 0.0161\n",
      "Epoch 137/200, Iteration 197/250, Loss: 0.0093\n",
      "Epoch 137/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 199/250, Loss: 0.0186\n",
      "Epoch 137/200, Iteration 200/250, Loss: 0.0223\n",
      "Epoch 137/200, Iteration 201/250, Loss: 0.0096\n",
      "Epoch 137/200, Iteration 202/250, Loss: 0.0082\n",
      "Epoch 137/200, Iteration 203/250, Loss: 0.0094\n",
      "Epoch 137/200, Iteration 204/250, Loss: 0.0079\n",
      "Epoch 137/200, Iteration 205/250, Loss: 0.0158\n",
      "Epoch 137/200, Iteration 206/250, Loss: 0.0170\n",
      "Epoch 137/200, Iteration 207/250, Loss: 0.0149\n",
      "Epoch 137/200, Iteration 208/250, Loss: 0.0153\n",
      "Epoch 137/200, Iteration 209/250, Loss: 0.0090\n",
      "Epoch 137/200, Iteration 210/250, Loss: 0.0138\n",
      "Epoch 137/200, Iteration 211/250, Loss: 0.0106\n",
      "Epoch 137/200, Iteration 212/250, Loss: 0.0144\n",
      "Epoch 137/200, Iteration 213/250, Loss: 0.0219\n",
      "Epoch 137/200, Iteration 214/250, Loss: 0.0101\n",
      "Epoch 137/200, Iteration 215/250, Loss: 0.0138\n",
      "Epoch 137/200, Iteration 216/250, Loss: 0.0163\n",
      "Epoch 137/200, Iteration 217/250, Loss: 0.0306\n",
      "Epoch 137/200, Iteration 218/250, Loss: 0.0109\n",
      "Epoch 137/200, Iteration 219/250, Loss: 0.0154\n",
      "Epoch 137/200, Iteration 220/250, Loss: 0.0121\n",
      "Epoch 137/200, Iteration 221/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 222/250, Loss: 0.0148\n",
      "Epoch 137/200, Iteration 223/250, Loss: 0.0118\n",
      "Epoch 137/200, Iteration 224/250, Loss: 0.0124\n",
      "Epoch 137/200, Iteration 225/250, Loss: 0.0153\n",
      "Epoch 137/200, Iteration 226/250, Loss: 0.0202\n",
      "Epoch 137/200, Iteration 227/250, Loss: 0.0221\n",
      "Epoch 137/200, Iteration 228/250, Loss: 0.0207\n",
      "Epoch 137/200, Iteration 229/250, Loss: 0.0150\n",
      "Epoch 137/200, Iteration 230/250, Loss: 0.0075\n",
      "Epoch 137/200, Iteration 231/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 232/250, Loss: 0.0128\n",
      "Epoch 137/200, Iteration 233/250, Loss: 0.0162\n",
      "Epoch 137/200, Iteration 234/250, Loss: 0.0317\n",
      "Epoch 137/200, Iteration 235/250, Loss: 0.0166\n",
      "Epoch 137/200, Iteration 236/250, Loss: 0.0105\n",
      "Epoch 137/200, Iteration 237/250, Loss: 0.0166\n",
      "Epoch 137/200, Iteration 238/250, Loss: 0.0204\n",
      "Epoch 137/200, Iteration 239/250, Loss: 0.0150\n",
      "Epoch 137/200, Iteration 240/250, Loss: 0.0116\n",
      "Epoch 137/200, Iteration 241/250, Loss: 0.0095\n",
      "Epoch 137/200, Iteration 242/250, Loss: 0.0129\n",
      "Epoch 137/200, Iteration 243/250, Loss: 0.0168\n",
      "Epoch 137/200, Iteration 244/250, Loss: 0.0125\n",
      "Epoch 137/200, Iteration 245/250, Loss: 0.0086\n",
      "Epoch 137/200, Iteration 246/250, Loss: 0.0356\n",
      "Epoch 137/200, Iteration 247/250, Loss: 0.0165\n",
      "Epoch 137/200, Iteration 248/250, Loss: 0.0107\n",
      "Epoch 137/200, Iteration 249/250, Loss: 0.0178\n",
      "Epoch 137/200, Iteration 250/250, Loss: 0.0468\n",
      "Train Error: \n",
      " Accuracy: 97.26%, Avg loss: 0.009532, MRE: 0.593744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.010074, MRE: 0.634958 \n",
      "\n",
      "Epoch 138/200, Iteration 1/250, Loss: 0.0229\n",
      "Epoch 138/200, Iteration 2/250, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200, Iteration 3/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 4/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 5/250, Loss: 0.0358\n",
      "Epoch 138/200, Iteration 6/250, Loss: 0.0235\n",
      "Epoch 138/200, Iteration 7/250, Loss: 0.0139\n",
      "Epoch 138/200, Iteration 8/250, Loss: 0.0434\n",
      "Epoch 138/200, Iteration 9/250, Loss: 0.0194\n",
      "Epoch 138/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 11/250, Loss: 0.0087\n",
      "Epoch 138/200, Iteration 12/250, Loss: 0.0108\n",
      "Epoch 138/200, Iteration 13/250, Loss: 0.0105\n",
      "Epoch 138/200, Iteration 14/250, Loss: 0.0138\n",
      "Epoch 138/200, Iteration 15/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 16/250, Loss: 0.0158\n",
      "Epoch 138/200, Iteration 17/250, Loss: 0.0279\n",
      "Epoch 138/200, Iteration 18/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 138/200, Iteration 20/250, Loss: 0.0197\n",
      "Epoch 138/200, Iteration 21/250, Loss: 0.0088\n",
      "Epoch 138/200, Iteration 22/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 23/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 24/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 25/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 26/250, Loss: 0.0122\n",
      "Epoch 138/200, Iteration 27/250, Loss: 0.0270\n",
      "Epoch 138/200, Iteration 28/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 29/250, Loss: 0.0099\n",
      "Epoch 138/200, Iteration 30/250, Loss: 0.0217\n",
      "Epoch 138/200, Iteration 31/250, Loss: 0.0267\n",
      "Epoch 138/200, Iteration 32/250, Loss: 0.0119\n",
      "Epoch 138/200, Iteration 33/250, Loss: 0.0080\n",
      "Epoch 138/200, Iteration 34/250, Loss: 0.0221\n",
      "Epoch 138/200, Iteration 35/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 36/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 37/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 38/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 39/250, Loss: 0.0101\n",
      "Epoch 138/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 138/200, Iteration 41/250, Loss: 0.0119\n",
      "Epoch 138/200, Iteration 42/250, Loss: 0.0175\n",
      "Epoch 138/200, Iteration 43/250, Loss: 0.0160\n",
      "Epoch 138/200, Iteration 44/250, Loss: 0.0081\n",
      "Epoch 138/200, Iteration 45/250, Loss: 0.0167\n",
      "Epoch 138/200, Iteration 46/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 47/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 48/250, Loss: 0.0089\n",
      "Epoch 138/200, Iteration 49/250, Loss: 0.0159\n",
      "Epoch 138/200, Iteration 50/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 51/250, Loss: 0.0259\n",
      "Epoch 138/200, Iteration 52/250, Loss: 0.0116\n",
      "Epoch 138/200, Iteration 53/250, Loss: 0.0096\n",
      "Epoch 138/200, Iteration 54/250, Loss: 0.0166\n",
      "Epoch 138/200, Iteration 55/250, Loss: 0.0123\n",
      "Epoch 138/200, Iteration 56/250, Loss: 0.0198\n",
      "Epoch 138/200, Iteration 57/250, Loss: 0.0177\n",
      "Epoch 138/200, Iteration 58/250, Loss: 0.0198\n",
      "Epoch 138/200, Iteration 59/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 60/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 61/250, Loss: 0.0070\n",
      "Epoch 138/200, Iteration 62/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 63/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 64/250, Loss: 0.0217\n",
      "Epoch 138/200, Iteration 65/250, Loss: 0.0089\n",
      "Epoch 138/200, Iteration 66/250, Loss: 0.0064\n",
      "Epoch 138/200, Iteration 67/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 68/250, Loss: 0.0236\n",
      "Epoch 138/200, Iteration 69/250, Loss: 0.0075\n",
      "Epoch 138/200, Iteration 70/250, Loss: 0.0188\n",
      "Epoch 138/200, Iteration 71/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 72/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 73/250, Loss: 0.0118\n",
      "Epoch 138/200, Iteration 74/250, Loss: 0.0156\n",
      "Epoch 138/200, Iteration 75/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 76/250, Loss: 0.0118\n",
      "Epoch 138/200, Iteration 77/250, Loss: 0.0110\n",
      "Epoch 138/200, Iteration 78/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 79/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 80/250, Loss: 0.0079\n",
      "Epoch 138/200, Iteration 81/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 82/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 83/250, Loss: 0.0221\n",
      "Epoch 138/200, Iteration 84/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 85/250, Loss: 0.0212\n",
      "Epoch 138/200, Iteration 86/250, Loss: 0.0131\n",
      "Epoch 138/200, Iteration 87/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 88/250, Loss: 0.0192\n",
      "Epoch 138/200, Iteration 89/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 90/250, Loss: 0.0145\n",
      "Epoch 138/200, Iteration 91/250, Loss: 0.0120\n",
      "Epoch 138/200, Iteration 92/250, Loss: 0.0264\n",
      "Epoch 138/200, Iteration 93/250, Loss: 0.0140\n",
      "Epoch 138/200, Iteration 94/250, Loss: 0.0139\n",
      "Epoch 138/200, Iteration 95/250, Loss: 0.0303\n",
      "Epoch 138/200, Iteration 96/250, Loss: 0.0189\n",
      "Epoch 138/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 98/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 99/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 100/250, Loss: 0.0116\n",
      "Epoch 138/200, Iteration 101/250, Loss: 0.0181\n",
      "Epoch 138/200, Iteration 102/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 103/250, Loss: 0.0210\n",
      "Epoch 138/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 105/250, Loss: 0.0160\n",
      "Epoch 138/200, Iteration 106/250, Loss: 0.0206\n",
      "Epoch 138/200, Iteration 107/250, Loss: 0.0313\n",
      "Epoch 138/200, Iteration 108/250, Loss: 0.0104\n",
      "Epoch 138/200, Iteration 109/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 110/250, Loss: 0.0205\n",
      "Epoch 138/200, Iteration 111/250, Loss: 0.0090\n",
      "Epoch 138/200, Iteration 112/250, Loss: 0.0281\n",
      "Epoch 138/200, Iteration 113/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 114/250, Loss: 0.0190\n",
      "Epoch 138/200, Iteration 115/250, Loss: 0.0316\n",
      "Epoch 138/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 138/200, Iteration 117/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 118/250, Loss: 0.0181\n",
      "Epoch 138/200, Iteration 119/250, Loss: 0.0095\n",
      "Epoch 138/200, Iteration 120/250, Loss: 0.0281\n",
      "Epoch 138/200, Iteration 121/250, Loss: 0.0260\n",
      "Epoch 138/200, Iteration 122/250, Loss: 0.0073\n",
      "Epoch 138/200, Iteration 123/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 124/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 125/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 126/250, Loss: 0.0107\n",
      "Epoch 138/200, Iteration 127/250, Loss: 0.0250\n",
      "Epoch 138/200, Iteration 128/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 129/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 130/250, Loss: 0.0097\n",
      "Epoch 138/200, Iteration 131/250, Loss: 0.0081\n",
      "Epoch 138/200, Iteration 132/250, Loss: 0.0102\n",
      "Epoch 138/200, Iteration 133/250, Loss: 0.0183\n",
      "Epoch 138/200, Iteration 134/250, Loss: 0.0134\n",
      "Epoch 138/200, Iteration 135/250, Loss: 0.0120\n",
      "Epoch 138/200, Iteration 136/250, Loss: 0.0304\n",
      "Epoch 138/200, Iteration 137/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 138/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 139/250, Loss: 0.0148\n",
      "Epoch 138/200, Iteration 140/250, Loss: 0.0130\n",
      "Epoch 138/200, Iteration 141/250, Loss: 0.0130\n",
      "Epoch 138/200, Iteration 142/250, Loss: 0.0164\n",
      "Epoch 138/200, Iteration 143/250, Loss: 0.0144\n",
      "Epoch 138/200, Iteration 144/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 145/250, Loss: 0.0108\n",
      "Epoch 138/200, Iteration 146/250, Loss: 0.0176\n",
      "Epoch 138/200, Iteration 147/250, Loss: 0.0149\n",
      "Epoch 138/200, Iteration 148/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 149/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 150/250, Loss: 0.0093\n",
      "Epoch 138/200, Iteration 151/250, Loss: 0.0125\n",
      "Epoch 138/200, Iteration 152/250, Loss: 0.0106\n",
      "Epoch 138/200, Iteration 153/250, Loss: 0.0294\n",
      "Epoch 138/200, Iteration 154/250, Loss: 0.0135\n",
      "Epoch 138/200, Iteration 155/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 156/250, Loss: 0.0100\n",
      "Epoch 138/200, Iteration 157/250, Loss: 0.0322\n",
      "Epoch 138/200, Iteration 158/250, Loss: 0.0285\n",
      "Epoch 138/200, Iteration 159/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 138/200, Iteration 161/250, Loss: 0.0064\n",
      "Epoch 138/200, Iteration 162/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 163/250, Loss: 0.0112\n",
      "Epoch 138/200, Iteration 164/250, Loss: 0.0117\n",
      "Epoch 138/200, Iteration 165/250, Loss: 0.0104\n",
      "Epoch 138/200, Iteration 166/250, Loss: 0.0098\n",
      "Epoch 138/200, Iteration 167/250, Loss: 0.0077\n",
      "Epoch 138/200, Iteration 168/250, Loss: 0.0068\n",
      "Epoch 138/200, Iteration 169/250, Loss: 0.0145\n",
      "Epoch 138/200, Iteration 170/250, Loss: 0.0073\n",
      "Epoch 138/200, Iteration 171/250, Loss: 0.0103\n",
      "Epoch 138/200, Iteration 172/250, Loss: 0.0079\n",
      "Epoch 138/200, Iteration 173/250, Loss: 0.0098\n",
      "Epoch 138/200, Iteration 174/250, Loss: 0.0136\n",
      "Epoch 138/200, Iteration 175/250, Loss: 0.0277\n",
      "Epoch 138/200, Iteration 176/250, Loss: 0.0071\n",
      "Epoch 138/200, Iteration 177/250, Loss: 0.0087\n",
      "Epoch 138/200, Iteration 178/250, Loss: 0.0115\n",
      "Epoch 138/200, Iteration 179/250, Loss: 0.0159\n",
      "Epoch 138/200, Iteration 180/250, Loss: 0.0126\n",
      "Epoch 138/200, Iteration 181/250, Loss: 0.0101\n",
      "Epoch 138/200, Iteration 182/250, Loss: 0.0254\n",
      "Epoch 138/200, Iteration 183/250, Loss: 0.0098\n",
      "Epoch 138/200, Iteration 184/250, Loss: 0.0083\n",
      "Epoch 138/200, Iteration 185/250, Loss: 0.0204\n",
      "Epoch 138/200, Iteration 186/250, Loss: 0.0162\n",
      "Epoch 138/200, Iteration 187/250, Loss: 0.0089\n",
      "Epoch 138/200, Iteration 188/250, Loss: 0.0130\n",
      "Epoch 138/200, Iteration 189/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200, Iteration 190/250, Loss: 0.0193\n",
      "Epoch 138/200, Iteration 191/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 192/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 193/250, Loss: 0.0111\n",
      "Epoch 138/200, Iteration 194/250, Loss: 0.0151\n",
      "Epoch 138/200, Iteration 195/250, Loss: 0.0121\n",
      "Epoch 138/200, Iteration 196/250, Loss: 0.0115\n",
      "Epoch 138/200, Iteration 197/250, Loss: 0.0208\n",
      "Epoch 138/200, Iteration 198/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 199/250, Loss: 0.0127\n",
      "Epoch 138/200, Iteration 200/250, Loss: 0.0145\n",
      "Epoch 138/200, Iteration 201/250, Loss: 0.0386\n",
      "Epoch 138/200, Iteration 202/250, Loss: 0.0094\n",
      "Epoch 138/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 204/250, Loss: 0.0179\n",
      "Epoch 138/200, Iteration 205/250, Loss: 0.0234\n",
      "Epoch 138/200, Iteration 206/250, Loss: 0.0144\n",
      "Epoch 138/200, Iteration 207/250, Loss: 0.0076\n",
      "Epoch 138/200, Iteration 208/250, Loss: 0.0100\n",
      "Epoch 138/200, Iteration 209/250, Loss: 0.0177\n",
      "Epoch 138/200, Iteration 210/250, Loss: 0.0121\n",
      "Epoch 138/200, Iteration 211/250, Loss: 0.0079\n",
      "Epoch 138/200, Iteration 212/250, Loss: 0.0153\n",
      "Epoch 138/200, Iteration 213/250, Loss: 0.0099\n",
      "Epoch 138/200, Iteration 214/250, Loss: 0.0124\n",
      "Epoch 138/200, Iteration 215/250, Loss: 0.0294\n",
      "Epoch 138/200, Iteration 216/250, Loss: 0.0053\n",
      "Epoch 138/200, Iteration 217/250, Loss: 0.0086\n",
      "Epoch 138/200, Iteration 218/250, Loss: 0.0148\n",
      "Epoch 138/200, Iteration 219/250, Loss: 0.0076\n",
      "Epoch 138/200, Iteration 220/250, Loss: 0.0089\n",
      "Epoch 138/200, Iteration 221/250, Loss: 0.0112\n",
      "Epoch 138/200, Iteration 222/250, Loss: 0.0136\n",
      "Epoch 138/200, Iteration 223/250, Loss: 0.0085\n",
      "Epoch 138/200, Iteration 224/250, Loss: 0.0078\n",
      "Epoch 138/200, Iteration 225/250, Loss: 0.0132\n",
      "Epoch 138/200, Iteration 226/250, Loss: 0.0123\n",
      "Epoch 138/200, Iteration 227/250, Loss: 0.0118\n",
      "Epoch 138/200, Iteration 228/250, Loss: 0.0129\n",
      "Epoch 138/200, Iteration 229/250, Loss: 0.0099\n",
      "Epoch 138/200, Iteration 230/250, Loss: 0.0137\n",
      "Epoch 138/200, Iteration 231/250, Loss: 0.0088\n",
      "Epoch 138/200, Iteration 232/250, Loss: 0.0412\n",
      "Epoch 138/200, Iteration 233/250, Loss: 0.0177\n",
      "Epoch 138/200, Iteration 234/250, Loss: 0.0179\n",
      "Epoch 138/200, Iteration 235/250, Loss: 0.0129\n",
      "Epoch 138/200, Iteration 236/250, Loss: 0.0226\n",
      "Epoch 138/200, Iteration 237/250, Loss: 0.0143\n",
      "Epoch 138/200, Iteration 238/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 239/250, Loss: 0.0081\n",
      "Epoch 138/200, Iteration 240/250, Loss: 0.0141\n",
      "Epoch 138/200, Iteration 241/250, Loss: 0.0101\n",
      "Epoch 138/200, Iteration 242/250, Loss: 0.0246\n",
      "Epoch 138/200, Iteration 243/250, Loss: 0.0091\n",
      "Epoch 138/200, Iteration 244/250, Loss: 0.0084\n",
      "Epoch 138/200, Iteration 245/250, Loss: 0.0109\n",
      "Epoch 138/200, Iteration 246/250, Loss: 0.0178\n",
      "Epoch 138/200, Iteration 247/250, Loss: 0.0102\n",
      "Epoch 138/200, Iteration 248/250, Loss: 0.0203\n",
      "Epoch 138/200, Iteration 249/250, Loss: 0.0079\n",
      "Epoch 138/200, Iteration 250/250, Loss: 0.0139\n",
      "Train Error: \n",
      " Accuracy: 84.71%, Avg loss: 0.006916, MRE: 0.447571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.25%, Avg loss: 0.007394, MRE: 0.515080 \n",
      "\n",
      "Epoch 139/200, Iteration 1/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 2/250, Loss: 0.0353\n",
      "Epoch 139/200, Iteration 3/250, Loss: 0.0172\n",
      "Epoch 139/200, Iteration 4/250, Loss: 0.0105\n",
      "Epoch 139/200, Iteration 5/250, Loss: 0.0331\n",
      "Epoch 139/200, Iteration 6/250, Loss: 0.0148\n",
      "Epoch 139/200, Iteration 7/250, Loss: 0.0257\n",
      "Epoch 139/200, Iteration 8/250, Loss: 0.0096\n",
      "Epoch 139/200, Iteration 9/250, Loss: 0.0262\n",
      "Epoch 139/200, Iteration 10/250, Loss: 0.0100\n",
      "Epoch 139/200, Iteration 11/250, Loss: 0.0076\n",
      "Epoch 139/200, Iteration 12/250, Loss: 0.0207\n",
      "Epoch 139/200, Iteration 13/250, Loss: 0.0109\n",
      "Epoch 139/200, Iteration 14/250, Loss: 0.0232\n",
      "Epoch 139/200, Iteration 15/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 16/250, Loss: 0.0383\n",
      "Epoch 139/200, Iteration 17/250, Loss: 0.0250\n",
      "Epoch 139/200, Iteration 18/250, Loss: 0.0100\n",
      "Epoch 139/200, Iteration 19/250, Loss: 0.0159\n",
      "Epoch 139/200, Iteration 20/250, Loss: 0.0136\n",
      "Epoch 139/200, Iteration 21/250, Loss: 0.0157\n",
      "Epoch 139/200, Iteration 22/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 23/250, Loss: 0.0195\n",
      "Epoch 139/200, Iteration 24/250, Loss: 0.0113\n",
      "Epoch 139/200, Iteration 25/250, Loss: 0.0167\n",
      "Epoch 139/200, Iteration 26/250, Loss: 0.0248\n",
      "Epoch 139/200, Iteration 27/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 28/250, Loss: 0.0146\n",
      "Epoch 139/200, Iteration 29/250, Loss: 0.0117\n",
      "Epoch 139/200, Iteration 30/250, Loss: 0.0198\n",
      "Epoch 139/200, Iteration 31/250, Loss: 0.0273\n",
      "Epoch 139/200, Iteration 32/250, Loss: 0.0205\n",
      "Epoch 139/200, Iteration 33/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 34/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 35/250, Loss: 0.0102\n",
      "Epoch 139/200, Iteration 36/250, Loss: 0.0135\n",
      "Epoch 139/200, Iteration 37/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 39/250, Loss: 0.0137\n",
      "Epoch 139/200, Iteration 40/250, Loss: 0.0193\n",
      "Epoch 139/200, Iteration 41/250, Loss: 0.0120\n",
      "Epoch 139/200, Iteration 42/250, Loss: 0.0075\n",
      "Epoch 139/200, Iteration 43/250, Loss: 0.0118\n",
      "Epoch 139/200, Iteration 44/250, Loss: 0.0355\n",
      "Epoch 139/200, Iteration 45/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 46/250, Loss: 0.0256\n",
      "Epoch 139/200, Iteration 47/250, Loss: 0.0345\n",
      "Epoch 139/200, Iteration 48/250, Loss: 0.0179\n",
      "Epoch 139/200, Iteration 49/250, Loss: 0.0100\n",
      "Epoch 139/200, Iteration 50/250, Loss: 0.0087\n",
      "Epoch 139/200, Iteration 51/250, Loss: 0.0189\n",
      "Epoch 139/200, Iteration 52/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 53/250, Loss: 0.0203\n",
      "Epoch 139/200, Iteration 54/250, Loss: 0.0133\n",
      "Epoch 139/200, Iteration 55/250, Loss: 0.0089\n",
      "Epoch 139/200, Iteration 56/250, Loss: 0.0145\n",
      "Epoch 139/200, Iteration 57/250, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 58/250, Loss: 0.0141\n",
      "Epoch 139/200, Iteration 59/250, Loss: 0.0063\n",
      "Epoch 139/200, Iteration 60/250, Loss: 0.0075\n",
      "Epoch 139/200, Iteration 61/250, Loss: 0.0144\n",
      "Epoch 139/200, Iteration 62/250, Loss: 0.0113\n",
      "Epoch 139/200, Iteration 63/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 64/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 65/250, Loss: 0.0172\n",
      "Epoch 139/200, Iteration 66/250, Loss: 0.0367\n",
      "Epoch 139/200, Iteration 67/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 68/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 69/250, Loss: 0.0125\n",
      "Epoch 139/200, Iteration 70/250, Loss: 0.0220\n",
      "Epoch 139/200, Iteration 71/250, Loss: 0.0116\n",
      "Epoch 139/200, Iteration 72/250, Loss: 0.0163\n",
      "Epoch 139/200, Iteration 73/250, Loss: 0.0099\n",
      "Epoch 139/200, Iteration 74/250, Loss: 0.0072\n",
      "Epoch 139/200, Iteration 75/250, Loss: 0.0137\n",
      "Epoch 139/200, Iteration 76/250, Loss: 0.0142\n",
      "Epoch 139/200, Iteration 77/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 78/250, Loss: 0.0417\n",
      "Epoch 139/200, Iteration 79/250, Loss: 0.0256\n",
      "Epoch 139/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 81/250, Loss: 0.0187\n",
      "Epoch 139/200, Iteration 82/250, Loss: 0.0195\n",
      "Epoch 139/200, Iteration 83/250, Loss: 0.0224\n",
      "Epoch 139/200, Iteration 84/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 85/250, Loss: 0.0318\n",
      "Epoch 139/200, Iteration 86/250, Loss: 0.0187\n",
      "Epoch 139/200, Iteration 87/250, Loss: 0.0077\n",
      "Epoch 139/200, Iteration 88/250, Loss: 0.0177\n",
      "Epoch 139/200, Iteration 89/250, Loss: 0.0376\n",
      "Epoch 139/200, Iteration 90/250, Loss: 0.0166\n",
      "Epoch 139/200, Iteration 91/250, Loss: 0.0274\n",
      "Epoch 139/200, Iteration 92/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 93/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 94/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 95/250, Loss: 0.0183\n",
      "Epoch 139/200, Iteration 96/250, Loss: 0.0185\n",
      "Epoch 139/200, Iteration 97/250, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 98/250, Loss: 0.0162\n",
      "Epoch 139/200, Iteration 99/250, Loss: 0.0168\n",
      "Epoch 139/200, Iteration 100/250, Loss: 0.0158\n",
      "Epoch 139/200, Iteration 101/250, Loss: 0.0171\n",
      "Epoch 139/200, Iteration 102/250, Loss: 0.0064\n",
      "Epoch 139/200, Iteration 103/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 104/250, Loss: 0.0147\n",
      "Epoch 139/200, Iteration 105/250, Loss: 0.0104\n",
      "Epoch 139/200, Iteration 106/250, Loss: 0.0196\n",
      "Epoch 139/200, Iteration 107/250, Loss: 0.0122\n",
      "Epoch 139/200, Iteration 108/250, Loss: 0.0144\n",
      "Epoch 139/200, Iteration 109/250, Loss: 0.0230\n",
      "Epoch 139/200, Iteration 110/250, Loss: 0.0268\n",
      "Epoch 139/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 139/200, Iteration 112/250, Loss: 0.0196\n",
      "Epoch 139/200, Iteration 113/250, Loss: 0.0244\n",
      "Epoch 139/200, Iteration 114/250, Loss: 0.0230\n",
      "Epoch 139/200, Iteration 115/250, Loss: 0.0111\n",
      "Epoch 139/200, Iteration 116/250, Loss: 0.0234\n",
      "Epoch 139/200, Iteration 117/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 118/250, Loss: 0.0175\n",
      "Epoch 139/200, Iteration 119/250, Loss: 0.0187\n",
      "Epoch 139/200, Iteration 120/250, Loss: 0.0154\n",
      "Epoch 139/200, Iteration 121/250, Loss: 0.0094\n",
      "Epoch 139/200, Iteration 122/250, Loss: 0.0237\n",
      "Epoch 139/200, Iteration 123/250, Loss: 0.0207\n",
      "Epoch 139/200, Iteration 124/250, Loss: 0.0070\n",
      "Epoch 139/200, Iteration 125/250, Loss: 0.0175\n",
      "Epoch 139/200, Iteration 126/250, Loss: 0.0171\n",
      "Epoch 139/200, Iteration 127/250, Loss: 0.0110\n",
      "Epoch 139/200, Iteration 128/250, Loss: 0.0106\n",
      "Epoch 139/200, Iteration 129/250, Loss: 0.0081\n",
      "Epoch 139/200, Iteration 130/250, Loss: 0.0140\n",
      "Epoch 139/200, Iteration 131/250, Loss: 0.0123\n",
      "Epoch 139/200, Iteration 132/250, Loss: 0.0080\n",
      "Epoch 139/200, Iteration 133/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 134/250, Loss: 0.0135\n",
      "Epoch 139/200, Iteration 135/250, Loss: 0.0141\n",
      "Epoch 139/200, Iteration 136/250, Loss: 0.0152\n",
      "Epoch 139/200, Iteration 137/250, Loss: 0.0326\n",
      "Epoch 139/200, Iteration 138/250, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 139/250, Loss: 0.0322\n",
      "Epoch 139/200, Iteration 140/250, Loss: 0.0431\n",
      "Epoch 139/200, Iteration 141/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 142/250, Loss: 0.0141\n",
      "Epoch 139/200, Iteration 143/250, Loss: 0.0103\n",
      "Epoch 139/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 139/200, Iteration 145/250, Loss: 0.0316\n",
      "Epoch 139/200, Iteration 146/250, Loss: 0.0240\n",
      "Epoch 139/200, Iteration 147/250, Loss: 0.0237\n",
      "Epoch 139/200, Iteration 148/250, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/200, Iteration 149/250, Loss: 0.0213\n",
      "Epoch 139/200, Iteration 150/250, Loss: 0.0160\n",
      "Epoch 139/200, Iteration 151/250, Loss: 0.0411\n",
      "Epoch 139/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 139/200, Iteration 153/250, Loss: 0.0086\n",
      "Epoch 139/200, Iteration 154/250, Loss: 0.0152\n",
      "Epoch 139/200, Iteration 155/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 156/250, Loss: 0.0108\n",
      "Epoch 139/200, Iteration 157/250, Loss: 0.0101\n",
      "Epoch 139/200, Iteration 158/250, Loss: 0.0218\n",
      "Epoch 139/200, Iteration 159/250, Loss: 0.0098\n",
      "Epoch 139/200, Iteration 160/250, Loss: 0.0238\n",
      "Epoch 139/200, Iteration 161/250, Loss: 0.0151\n",
      "Epoch 139/200, Iteration 162/250, Loss: 0.0261\n",
      "Epoch 139/200, Iteration 163/250, Loss: 0.0074\n",
      "Epoch 139/200, Iteration 164/250, Loss: 0.0070\n",
      "Epoch 139/200, Iteration 165/250, Loss: 0.0225\n",
      "Epoch 139/200, Iteration 166/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 167/250, Loss: 0.0170\n",
      "Epoch 139/200, Iteration 168/250, Loss: 0.0114\n",
      "Epoch 139/200, Iteration 169/250, Loss: 0.0091\n",
      "Epoch 139/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 139/200, Iteration 171/250, Loss: 0.0195\n",
      "Epoch 139/200, Iteration 172/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 173/250, Loss: 0.0345\n",
      "Epoch 139/200, Iteration 174/250, Loss: 0.0214\n",
      "Epoch 139/200, Iteration 175/250, Loss: 0.0160\n",
      "Epoch 139/200, Iteration 176/250, Loss: 0.0283\n",
      "Epoch 139/200, Iteration 177/250, Loss: 0.0189\n",
      "Epoch 139/200, Iteration 178/250, Loss: 0.0069\n",
      "Epoch 139/200, Iteration 179/250, Loss: 0.0158\n",
      "Epoch 139/200, Iteration 180/250, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 181/250, Loss: 0.0084\n",
      "Epoch 139/200, Iteration 182/250, Loss: 0.0134\n",
      "Epoch 139/200, Iteration 183/250, Loss: 0.0483\n",
      "Epoch 139/200, Iteration 184/250, Loss: 0.0171\n",
      "Epoch 139/200, Iteration 185/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 186/250, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 187/250, Loss: 0.0136\n",
      "Epoch 139/200, Iteration 188/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 189/250, Loss: 0.0132\n",
      "Epoch 139/200, Iteration 190/250, Loss: 0.0138\n",
      "Epoch 139/200, Iteration 191/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 192/250, Loss: 0.0207\n",
      "Epoch 139/200, Iteration 193/250, Loss: 0.0088\n",
      "Epoch 139/200, Iteration 194/250, Loss: 0.0214\n",
      "Epoch 139/200, Iteration 195/250, Loss: 0.0374\n",
      "Epoch 139/200, Iteration 196/250, Loss: 0.0202\n",
      "Epoch 139/200, Iteration 197/250, Loss: 0.0201\n",
      "Epoch 139/200, Iteration 198/250, Loss: 0.0083\n",
      "Epoch 139/200, Iteration 199/250, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 200/250, Loss: 0.0076\n",
      "Epoch 139/200, Iteration 201/250, Loss: 0.0084\n",
      "Epoch 139/200, Iteration 202/250, Loss: 0.0078\n",
      "Epoch 139/200, Iteration 203/250, Loss: 0.0156\n",
      "Epoch 139/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 205/250, Loss: 0.0248\n",
      "Epoch 139/200, Iteration 206/250, Loss: 0.0217\n",
      "Epoch 139/200, Iteration 207/250, Loss: 0.0094\n",
      "Epoch 139/200, Iteration 208/250, Loss: 0.0113\n",
      "Epoch 139/200, Iteration 209/250, Loss: 0.0148\n",
      "Epoch 139/200, Iteration 210/250, Loss: 0.0382\n",
      "Epoch 139/200, Iteration 211/250, Loss: 0.0192\n",
      "Epoch 139/200, Iteration 212/250, Loss: 0.0163\n",
      "Epoch 139/200, Iteration 213/250, Loss: 0.0085\n",
      "Epoch 139/200, Iteration 214/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 215/250, Loss: 0.0173\n",
      "Epoch 139/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 139/200, Iteration 217/250, Loss: 0.0127\n",
      "Epoch 139/200, Iteration 218/250, Loss: 0.0217\n",
      "Epoch 139/200, Iteration 219/250, Loss: 0.0192\n",
      "Epoch 139/200, Iteration 220/250, Loss: 0.0095\n",
      "Epoch 139/200, Iteration 221/250, Loss: 0.0210\n",
      "Epoch 139/200, Iteration 222/250, Loss: 0.0141\n",
      "Epoch 139/200, Iteration 223/250, Loss: 0.0185\n",
      "Epoch 139/200, Iteration 224/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 225/250, Loss: 0.0441\n",
      "Epoch 139/200, Iteration 226/250, Loss: 0.0241\n",
      "Epoch 139/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 139/200, Iteration 228/250, Loss: 0.0154\n",
      "Epoch 139/200, Iteration 229/250, Loss: 0.0162\n",
      "Epoch 139/200, Iteration 230/250, Loss: 0.0056\n",
      "Epoch 139/200, Iteration 231/250, Loss: 0.0090\n",
      "Epoch 139/200, Iteration 232/250, Loss: 0.0092\n",
      "Epoch 139/200, Iteration 233/250, Loss: 0.0119\n",
      "Epoch 139/200, Iteration 234/250, Loss: 0.0059\n",
      "Epoch 139/200, Iteration 235/250, Loss: 0.0134\n",
      "Epoch 139/200, Iteration 236/250, Loss: 0.0253\n",
      "Epoch 139/200, Iteration 237/250, Loss: 0.0097\n",
      "Epoch 139/200, Iteration 238/250, Loss: 0.0155\n",
      "Epoch 139/200, Iteration 239/250, Loss: 0.0121\n",
      "Epoch 139/200, Iteration 240/250, Loss: 0.0107\n",
      "Epoch 139/200, Iteration 241/250, Loss: 0.0115\n",
      "Epoch 139/200, Iteration 242/250, Loss: 0.0188\n",
      "Epoch 139/200, Iteration 243/250, Loss: 0.0140\n",
      "Epoch 139/200, Iteration 244/250, Loss: 0.0093\n",
      "Epoch 139/200, Iteration 245/250, Loss: 0.0173\n",
      "Epoch 139/200, Iteration 246/250, Loss: 0.0081\n",
      "Epoch 139/200, Iteration 247/250, Loss: 0.0089\n",
      "Epoch 139/200, Iteration 248/250, Loss: 0.0112\n",
      "Epoch 139/200, Iteration 249/250, Loss: 0.0124\n",
      "Epoch 139/200, Iteration 250/250, Loss: 0.0090\n",
      "Train Error: \n",
      " Accuracy: 90.08%, Avg loss: 0.006762, MRE: 0.424263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.007339, MRE: 0.515706 \n",
      "\n",
      "Epoch 140/200, Iteration 1/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 2/250, Loss: 0.0211\n",
      "Epoch 140/200, Iteration 3/250, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 140/200, Iteration 5/250, Loss: 0.0086\n",
      "Epoch 140/200, Iteration 6/250, Loss: 0.0066\n",
      "Epoch 140/200, Iteration 7/250, Loss: 0.0178\n",
      "Epoch 140/200, Iteration 8/250, Loss: 0.0074\n",
      "Epoch 140/200, Iteration 9/250, Loss: 0.0113\n",
      "Epoch 140/200, Iteration 10/250, Loss: 0.0167\n",
      "Epoch 140/200, Iteration 11/250, Loss: 0.0315\n",
      "Epoch 140/200, Iteration 12/250, Loss: 0.0114\n",
      "Epoch 140/200, Iteration 13/250, Loss: 0.0089\n",
      "Epoch 140/200, Iteration 14/250, Loss: 0.0220\n",
      "Epoch 140/200, Iteration 15/250, Loss: 0.0091\n",
      "Epoch 140/200, Iteration 16/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 17/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 18/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 19/250, Loss: 0.0091\n",
      "Epoch 140/200, Iteration 20/250, Loss: 0.0094\n",
      "Epoch 140/200, Iteration 21/250, Loss: 0.0147\n",
      "Epoch 140/200, Iteration 22/250, Loss: 0.0064\n",
      "Epoch 140/200, Iteration 23/250, Loss: 0.0178\n",
      "Epoch 140/200, Iteration 24/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 25/250, Loss: 0.0094\n",
      "Epoch 140/200, Iteration 26/250, Loss: 0.0193\n",
      "Epoch 140/200, Iteration 27/250, Loss: 0.0076\n",
      "Epoch 140/200, Iteration 28/250, Loss: 0.0227\n",
      "Epoch 140/200, Iteration 29/250, Loss: 0.0132\n",
      "Epoch 140/200, Iteration 30/250, Loss: 0.0143\n",
      "Epoch 140/200, Iteration 31/250, Loss: 0.0328\n",
      "Epoch 140/200, Iteration 32/250, Loss: 0.0136\n",
      "Epoch 140/200, Iteration 33/250, Loss: 0.0119\n",
      "Epoch 140/200, Iteration 34/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 35/250, Loss: 0.0232\n",
      "Epoch 140/200, Iteration 36/250, Loss: 0.0249\n",
      "Epoch 140/200, Iteration 37/250, Loss: 0.0124\n",
      "Epoch 140/200, Iteration 38/250, Loss: 0.0084\n",
      "Epoch 140/200, Iteration 39/250, Loss: 0.0109\n",
      "Epoch 140/200, Iteration 40/250, Loss: 0.0065\n",
      "Epoch 140/200, Iteration 41/250, Loss: 0.0299\n",
      "Epoch 140/200, Iteration 42/250, Loss: 0.0229\n",
      "Epoch 140/200, Iteration 43/250, Loss: 0.0140\n",
      "Epoch 140/200, Iteration 44/250, Loss: 0.0248\n",
      "Epoch 140/200, Iteration 45/250, Loss: 0.0241\n",
      "Epoch 140/200, Iteration 46/250, Loss: 0.0130\n",
      "Epoch 140/200, Iteration 47/250, Loss: 0.0083\n",
      "Epoch 140/200, Iteration 48/250, Loss: 0.0202\n",
      "Epoch 140/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 140/200, Iteration 50/250, Loss: 0.0120\n",
      "Epoch 140/200, Iteration 51/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 52/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 53/250, Loss: 0.0146\n",
      "Epoch 140/200, Iteration 54/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 55/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 56/250, Loss: 0.0184\n",
      "Epoch 140/200, Iteration 57/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 58/250, Loss: 0.0141\n",
      "Epoch 140/200, Iteration 59/250, Loss: 0.0101\n",
      "Epoch 140/200, Iteration 60/250, Loss: 0.0226\n",
      "Epoch 140/200, Iteration 61/250, Loss: 0.0132\n",
      "Epoch 140/200, Iteration 62/250, Loss: 0.0103\n",
      "Epoch 140/200, Iteration 63/250, Loss: 0.0094\n",
      "Epoch 140/200, Iteration 64/250, Loss: 0.0110\n",
      "Epoch 140/200, Iteration 65/250, Loss: 0.0164\n",
      "Epoch 140/200, Iteration 66/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 67/250, Loss: 0.0078\n",
      "Epoch 140/200, Iteration 68/250, Loss: 0.0179\n",
      "Epoch 140/200, Iteration 69/250, Loss: 0.0147\n",
      "Epoch 140/200, Iteration 70/250, Loss: 0.0278\n",
      "Epoch 140/200, Iteration 71/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 72/250, Loss: 0.0070\n",
      "Epoch 140/200, Iteration 73/250, Loss: 0.0228\n",
      "Epoch 140/200, Iteration 74/250, Loss: 0.0127\n",
      "Epoch 140/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 140/200, Iteration 76/250, Loss: 0.0159\n",
      "Epoch 140/200, Iteration 77/250, Loss: 0.0204\n",
      "Epoch 140/200, Iteration 78/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 79/250, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 80/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 81/250, Loss: 0.0243\n",
      "Epoch 140/200, Iteration 82/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 83/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 84/250, Loss: 0.0173\n",
      "Epoch 140/200, Iteration 85/250, Loss: 0.0070\n",
      "Epoch 140/200, Iteration 86/250, Loss: 0.0255\n",
      "Epoch 140/200, Iteration 87/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 88/250, Loss: 0.0160\n",
      "Epoch 140/200, Iteration 89/250, Loss: 0.0090\n",
      "Epoch 140/200, Iteration 90/250, Loss: 0.0122\n",
      "Epoch 140/200, Iteration 91/250, Loss: 0.0158\n",
      "Epoch 140/200, Iteration 92/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 93/250, Loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200, Iteration 94/250, Loss: 0.0128\n",
      "Epoch 140/200, Iteration 95/250, Loss: 0.0163\n",
      "Epoch 140/200, Iteration 96/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 97/250, Loss: 0.0250\n",
      "Epoch 140/200, Iteration 98/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 99/250, Loss: 0.0120\n",
      "Epoch 140/200, Iteration 100/250, Loss: 0.0189\n",
      "Epoch 140/200, Iteration 101/250, Loss: 0.0265\n",
      "Epoch 140/200, Iteration 102/250, Loss: 0.0129\n",
      "Epoch 140/200, Iteration 103/250, Loss: 0.0153\n",
      "Epoch 140/200, Iteration 104/250, Loss: 0.0065\n",
      "Epoch 140/200, Iteration 105/250, Loss: 0.0122\n",
      "Epoch 140/200, Iteration 106/250, Loss: 0.0107\n",
      "Epoch 140/200, Iteration 107/250, Loss: 0.0134\n",
      "Epoch 140/200, Iteration 108/250, Loss: 0.0134\n",
      "Epoch 140/200, Iteration 109/250, Loss: 0.0174\n",
      "Epoch 140/200, Iteration 110/250, Loss: 0.0175\n",
      "Epoch 140/200, Iteration 111/250, Loss: 0.0186\n",
      "Epoch 140/200, Iteration 112/250, Loss: 0.0074\n",
      "Epoch 140/200, Iteration 113/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 114/250, Loss: 0.0131\n",
      "Epoch 140/200, Iteration 115/250, Loss: 0.0149\n",
      "Epoch 140/200, Iteration 116/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 117/250, Loss: 0.0124\n",
      "Epoch 140/200, Iteration 118/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 119/250, Loss: 0.0141\n",
      "Epoch 140/200, Iteration 120/250, Loss: 0.0152\n",
      "Epoch 140/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 140/200, Iteration 122/250, Loss: 0.0078\n",
      "Epoch 140/200, Iteration 123/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 124/250, Loss: 0.0078\n",
      "Epoch 140/200, Iteration 125/250, Loss: 0.0093\n",
      "Epoch 140/200, Iteration 126/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 127/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 128/250, Loss: 0.0058\n",
      "Epoch 140/200, Iteration 129/250, Loss: 0.0128\n",
      "Epoch 140/200, Iteration 130/250, Loss: 0.0157\n",
      "Epoch 140/200, Iteration 131/250, Loss: 0.0083\n",
      "Epoch 140/200, Iteration 132/250, Loss: 0.0190\n",
      "Epoch 140/200, Iteration 133/250, Loss: 0.0103\n",
      "Epoch 140/200, Iteration 134/250, Loss: 0.0165\n",
      "Epoch 140/200, Iteration 135/250, Loss: 0.0109\n",
      "Epoch 140/200, Iteration 136/250, Loss: 0.0208\n",
      "Epoch 140/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 140/200, Iteration 138/250, Loss: 0.0261\n",
      "Epoch 140/200, Iteration 139/250, Loss: 0.0379\n",
      "Epoch 140/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 140/200, Iteration 141/250, Loss: 0.0342\n",
      "Epoch 140/200, Iteration 142/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 143/250, Loss: 0.0173\n",
      "Epoch 140/200, Iteration 144/250, Loss: 0.0175\n",
      "Epoch 140/200, Iteration 145/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 146/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 147/250, Loss: 0.0179\n",
      "Epoch 140/200, Iteration 148/250, Loss: 0.0427\n",
      "Epoch 140/200, Iteration 149/250, Loss: 0.0138\n",
      "Epoch 140/200, Iteration 150/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 151/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 152/250, Loss: 0.0386\n",
      "Epoch 140/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 140/200, Iteration 154/250, Loss: 0.0277\n",
      "Epoch 140/200, Iteration 155/250, Loss: 0.0354\n",
      "Epoch 140/200, Iteration 156/250, Loss: 0.0086\n",
      "Epoch 140/200, Iteration 157/250, Loss: 0.0111\n",
      "Epoch 140/200, Iteration 158/250, Loss: 0.0079\n",
      "Epoch 140/200, Iteration 159/250, Loss: 0.0282\n",
      "Epoch 140/200, Iteration 160/250, Loss: 0.0205\n",
      "Epoch 140/200, Iteration 161/250, Loss: 0.0305\n",
      "Epoch 140/200, Iteration 162/250, Loss: 0.0192\n",
      "Epoch 140/200, Iteration 163/250, Loss: 0.0093\n",
      "Epoch 140/200, Iteration 164/250, Loss: 0.0228\n",
      "Epoch 140/200, Iteration 165/250, Loss: 0.0113\n",
      "Epoch 140/200, Iteration 166/250, Loss: 0.0087\n",
      "Epoch 140/200, Iteration 167/250, Loss: 0.0102\n",
      "Epoch 140/200, Iteration 168/250, Loss: 0.0085\n",
      "Epoch 140/200, Iteration 169/250, Loss: 0.0138\n",
      "Epoch 140/200, Iteration 170/250, Loss: 0.0144\n",
      "Epoch 140/200, Iteration 171/250, Loss: 0.0110\n",
      "Epoch 140/200, Iteration 172/250, Loss: 0.0104\n",
      "Epoch 140/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 140/200, Iteration 174/250, Loss: 0.0176\n",
      "Epoch 140/200, Iteration 175/250, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 176/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 177/250, Loss: 0.0192\n",
      "Epoch 140/200, Iteration 178/250, Loss: 0.0062\n",
      "Epoch 140/200, Iteration 179/250, Loss: 0.0258\n",
      "Epoch 140/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 140/200, Iteration 181/250, Loss: 0.0162\n",
      "Epoch 140/200, Iteration 182/250, Loss: 0.0098\n",
      "Epoch 140/200, Iteration 183/250, Loss: 0.0067\n",
      "Epoch 140/200, Iteration 184/250, Loss: 0.0250\n",
      "Epoch 140/200, Iteration 185/250, Loss: 0.0096\n",
      "Epoch 140/200, Iteration 186/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 187/250, Loss: 0.0214\n",
      "Epoch 140/200, Iteration 188/250, Loss: 0.0129\n",
      "Epoch 140/200, Iteration 189/250, Loss: 0.0136\n",
      "Epoch 140/200, Iteration 190/250, Loss: 0.0292\n",
      "Epoch 140/200, Iteration 191/250, Loss: 0.0251\n",
      "Epoch 140/200, Iteration 192/250, Loss: 0.0153\n",
      "Epoch 140/200, Iteration 193/250, Loss: 0.0142\n",
      "Epoch 140/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 140/200, Iteration 195/250, Loss: 0.0177\n",
      "Epoch 140/200, Iteration 196/250, Loss: 0.0248\n",
      "Epoch 140/200, Iteration 197/250, Loss: 0.0463\n",
      "Epoch 140/200, Iteration 198/250, Loss: 0.0194\n",
      "Epoch 140/200, Iteration 199/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 200/250, Loss: 0.0295\n",
      "Epoch 140/200, Iteration 201/250, Loss: 0.0222\n",
      "Epoch 140/200, Iteration 202/250, Loss: 0.0099\n",
      "Epoch 140/200, Iteration 203/250, Loss: 0.0152\n",
      "Epoch 140/200, Iteration 204/250, Loss: 0.0245\n",
      "Epoch 140/200, Iteration 205/250, Loss: 0.0284\n",
      "Epoch 140/200, Iteration 206/250, Loss: 0.0110\n",
      "Epoch 140/200, Iteration 207/250, Loss: 0.0152\n",
      "Epoch 140/200, Iteration 208/250, Loss: 0.0149\n",
      "Epoch 140/200, Iteration 209/250, Loss: 0.0195\n",
      "Epoch 140/200, Iteration 210/250, Loss: 0.0203\n",
      "Epoch 140/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 212/250, Loss: 0.0095\n",
      "Epoch 140/200, Iteration 213/250, Loss: 0.0087\n",
      "Epoch 140/200, Iteration 214/250, Loss: 0.0171\n",
      "Epoch 140/200, Iteration 215/250, Loss: 0.0248\n",
      "Epoch 140/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 140/200, Iteration 217/250, Loss: 0.0189\n",
      "Epoch 140/200, Iteration 218/250, Loss: 0.0115\n",
      "Epoch 140/200, Iteration 219/250, Loss: 0.0194\n",
      "Epoch 140/200, Iteration 220/250, Loss: 0.0116\n",
      "Epoch 140/200, Iteration 221/250, Loss: 0.0090\n",
      "Epoch 140/200, Iteration 222/250, Loss: 0.0098\n",
      "Epoch 140/200, Iteration 223/250, Loss: 0.0165\n",
      "Epoch 140/200, Iteration 224/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 225/250, Loss: 0.0055\n",
      "Epoch 140/200, Iteration 226/250, Loss: 0.0066\n",
      "Epoch 140/200, Iteration 227/250, Loss: 0.0175\n",
      "Epoch 140/200, Iteration 228/250, Loss: 0.0088\n",
      "Epoch 140/200, Iteration 229/250, Loss: 0.0243\n",
      "Epoch 140/200, Iteration 230/250, Loss: 0.0100\n",
      "Epoch 140/200, Iteration 231/250, Loss: 0.0174\n",
      "Epoch 140/200, Iteration 232/250, Loss: 0.0073\n",
      "Epoch 140/200, Iteration 233/250, Loss: 0.0061\n",
      "Epoch 140/200, Iteration 234/250, Loss: 0.0146\n",
      "Epoch 140/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 140/200, Iteration 236/250, Loss: 0.0109\n",
      "Epoch 140/200, Iteration 237/250, Loss: 0.0086\n",
      "Epoch 140/200, Iteration 238/250, Loss: 0.0145\n",
      "Epoch 140/200, Iteration 239/250, Loss: 0.0121\n",
      "Epoch 140/200, Iteration 240/250, Loss: 0.0190\n",
      "Epoch 140/200, Iteration 241/250, Loss: 0.0108\n",
      "Epoch 140/200, Iteration 242/250, Loss: 0.0155\n",
      "Epoch 140/200, Iteration 243/250, Loss: 0.0097\n",
      "Epoch 140/200, Iteration 244/250, Loss: 0.0124\n",
      "Epoch 140/200, Iteration 245/250, Loss: 0.0143\n",
      "Epoch 140/200, Iteration 246/250, Loss: 0.0235\n",
      "Epoch 140/200, Iteration 247/250, Loss: 0.0107\n",
      "Epoch 140/200, Iteration 248/250, Loss: 0.0445\n",
      "Epoch 140/200, Iteration 249/250, Loss: 0.0090\n",
      "Epoch 140/200, Iteration 250/250, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 67.56%, Avg loss: 0.008827, MRE: 0.564910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.35%, Avg loss: 0.009127, MRE: 0.534691 \n",
      "\n",
      "Epoch 141/200, Iteration 1/250, Loss: 0.0083\n",
      "Epoch 141/200, Iteration 2/250, Loss: 0.0229\n",
      "Epoch 141/200, Iteration 3/250, Loss: 0.0177\n",
      "Epoch 141/200, Iteration 4/250, Loss: 0.0317\n",
      "Epoch 141/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 141/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 7/250, Loss: 0.0140\n",
      "Epoch 141/200, Iteration 8/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 9/250, Loss: 0.0153\n",
      "Epoch 141/200, Iteration 10/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 11/250, Loss: 0.0132\n",
      "Epoch 141/200, Iteration 12/250, Loss: 0.0427\n",
      "Epoch 141/200, Iteration 13/250, Loss: 0.0140\n",
      "Epoch 141/200, Iteration 14/250, Loss: 0.0135\n",
      "Epoch 141/200, Iteration 15/250, Loss: 0.0116\n",
      "Epoch 141/200, Iteration 16/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 17/250, Loss: 0.0165\n",
      "Epoch 141/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 141/200, Iteration 19/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 20/250, Loss: 0.0072\n",
      "Epoch 141/200, Iteration 21/250, Loss: 0.0165\n",
      "Epoch 141/200, Iteration 22/250, Loss: 0.0158\n",
      "Epoch 141/200, Iteration 23/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 24/250, Loss: 0.0166\n",
      "Epoch 141/200, Iteration 25/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 26/250, Loss: 0.0188\n",
      "Epoch 141/200, Iteration 27/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 28/250, Loss: 0.0149\n",
      "Epoch 141/200, Iteration 29/250, Loss: 0.0261\n",
      "Epoch 141/200, Iteration 30/250, Loss: 0.0086\n",
      "Epoch 141/200, Iteration 31/250, Loss: 0.0103\n",
      "Epoch 141/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 33/250, Loss: 0.0077\n",
      "Epoch 141/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 141/200, Iteration 35/250, Loss: 0.0142\n",
      "Epoch 141/200, Iteration 36/250, Loss: 0.0201\n",
      "Epoch 141/200, Iteration 37/250, Loss: 0.0280\n",
      "Epoch 141/200, Iteration 38/250, Loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200, Iteration 39/250, Loss: 0.0398\n",
      "Epoch 141/200, Iteration 40/250, Loss: 0.0123\n",
      "Epoch 141/200, Iteration 41/250, Loss: 0.0190\n",
      "Epoch 141/200, Iteration 42/250, Loss: 0.0122\n",
      "Epoch 141/200, Iteration 43/250, Loss: 0.0084\n",
      "Epoch 141/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 141/200, Iteration 45/250, Loss: 0.0181\n",
      "Epoch 141/200, Iteration 46/250, Loss: 0.0294\n",
      "Epoch 141/200, Iteration 47/250, Loss: 0.0203\n",
      "Epoch 141/200, Iteration 48/250, Loss: 0.0208\n",
      "Epoch 141/200, Iteration 49/250, Loss: 0.0168\n",
      "Epoch 141/200, Iteration 50/250, Loss: 0.0164\n",
      "Epoch 141/200, Iteration 51/250, Loss: 0.0141\n",
      "Epoch 141/200, Iteration 52/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 53/250, Loss: 0.0152\n",
      "Epoch 141/200, Iteration 54/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 55/250, Loss: 0.0117\n",
      "Epoch 141/200, Iteration 56/250, Loss: 0.0104\n",
      "Epoch 141/200, Iteration 57/250, Loss: 0.0143\n",
      "Epoch 141/200, Iteration 58/250, Loss: 0.0151\n",
      "Epoch 141/200, Iteration 59/250, Loss: 0.0289\n",
      "Epoch 141/200, Iteration 60/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 61/250, Loss: 0.0142\n",
      "Epoch 141/200, Iteration 62/250, Loss: 0.0143\n",
      "Epoch 141/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 64/250, Loss: 0.0102\n",
      "Epoch 141/200, Iteration 65/250, Loss: 0.0213\n",
      "Epoch 141/200, Iteration 66/250, Loss: 0.0274\n",
      "Epoch 141/200, Iteration 67/250, Loss: 0.0260\n",
      "Epoch 141/200, Iteration 68/250, Loss: 0.0213\n",
      "Epoch 141/200, Iteration 69/250, Loss: 0.0305\n",
      "Epoch 141/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 141/200, Iteration 71/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 72/250, Loss: 0.0101\n",
      "Epoch 141/200, Iteration 73/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 74/250, Loss: 0.0158\n",
      "Epoch 141/200, Iteration 75/250, Loss: 0.0277\n",
      "Epoch 141/200, Iteration 76/250, Loss: 0.0105\n",
      "Epoch 141/200, Iteration 77/250, Loss: 0.0105\n",
      "Epoch 141/200, Iteration 78/250, Loss: 0.0275\n",
      "Epoch 141/200, Iteration 79/250, Loss: 0.0268\n",
      "Epoch 141/200, Iteration 80/250, Loss: 0.0182\n",
      "Epoch 141/200, Iteration 81/250, Loss: 0.0293\n",
      "Epoch 141/200, Iteration 82/250, Loss: 0.0318\n",
      "Epoch 141/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 141/200, Iteration 84/250, Loss: 0.0485\n",
      "Epoch 141/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 86/250, Loss: 0.0152\n",
      "Epoch 141/200, Iteration 87/250, Loss: 0.0166\n",
      "Epoch 141/200, Iteration 88/250, Loss: 0.0255\n",
      "Epoch 141/200, Iteration 89/250, Loss: 0.0278\n",
      "Epoch 141/200, Iteration 90/250, Loss: 0.0268\n",
      "Epoch 141/200, Iteration 91/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 93/250, Loss: 0.0153\n",
      "Epoch 141/200, Iteration 94/250, Loss: 0.0133\n",
      "Epoch 141/200, Iteration 95/250, Loss: 0.0231\n",
      "Epoch 141/200, Iteration 96/250, Loss: 0.0084\n",
      "Epoch 141/200, Iteration 97/250, Loss: 0.0137\n",
      "Epoch 141/200, Iteration 98/250, Loss: 0.0110\n",
      "Epoch 141/200, Iteration 99/250, Loss: 0.0205\n",
      "Epoch 141/200, Iteration 100/250, Loss: 0.0150\n",
      "Epoch 141/200, Iteration 101/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 102/250, Loss: 0.0145\n",
      "Epoch 141/200, Iteration 103/250, Loss: 0.0152\n",
      "Epoch 141/200, Iteration 104/250, Loss: 0.0121\n",
      "Epoch 141/200, Iteration 105/250, Loss: 0.0090\n",
      "Epoch 141/200, Iteration 106/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 107/250, Loss: 0.0251\n",
      "Epoch 141/200, Iteration 108/250, Loss: 0.0250\n",
      "Epoch 141/200, Iteration 109/250, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 110/250, Loss: 0.0137\n",
      "Epoch 141/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 141/200, Iteration 112/250, Loss: 0.0086\n",
      "Epoch 141/200, Iteration 113/250, Loss: 0.0287\n",
      "Epoch 141/200, Iteration 114/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 115/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 116/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 117/250, Loss: 0.0135\n",
      "Epoch 141/200, Iteration 118/250, Loss: 0.0126\n",
      "Epoch 141/200, Iteration 119/250, Loss: 0.0113\n",
      "Epoch 141/200, Iteration 120/250, Loss: 0.0219\n",
      "Epoch 141/200, Iteration 121/250, Loss: 0.0272\n",
      "Epoch 141/200, Iteration 122/250, Loss: 0.0118\n",
      "Epoch 141/200, Iteration 123/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 124/250, Loss: 0.0214\n",
      "Epoch 141/200, Iteration 125/250, Loss: 0.0173\n",
      "Epoch 141/200, Iteration 126/250, Loss: 0.0172\n",
      "Epoch 141/200, Iteration 127/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 128/250, Loss: 0.0141\n",
      "Epoch 141/200, Iteration 129/250, Loss: 0.0078\n",
      "Epoch 141/200, Iteration 130/250, Loss: 0.0108\n",
      "Epoch 141/200, Iteration 131/250, Loss: 0.0080\n",
      "Epoch 141/200, Iteration 132/250, Loss: 0.0078\n",
      "Epoch 141/200, Iteration 133/250, Loss: 0.0160\n",
      "Epoch 141/200, Iteration 134/250, Loss: 0.0128\n",
      "Epoch 141/200, Iteration 135/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 136/250, Loss: 0.0351\n",
      "Epoch 141/200, Iteration 137/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 138/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 139/250, Loss: 0.0088\n",
      "Epoch 141/200, Iteration 140/250, Loss: 0.0175\n",
      "Epoch 141/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 141/200, Iteration 143/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 144/250, Loss: 0.0220\n",
      "Epoch 141/200, Iteration 145/250, Loss: 0.0134\n",
      "Epoch 141/200, Iteration 146/250, Loss: 0.0114\n",
      "Epoch 141/200, Iteration 147/250, Loss: 0.0179\n",
      "Epoch 141/200, Iteration 148/250, Loss: 0.0129\n",
      "Epoch 141/200, Iteration 149/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 150/250, Loss: 0.0190\n",
      "Epoch 141/200, Iteration 151/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 141/200, Iteration 153/250, Loss: 0.0121\n",
      "Epoch 141/200, Iteration 154/250, Loss: 0.0105\n",
      "Epoch 141/200, Iteration 155/250, Loss: 0.0071\n",
      "Epoch 141/200, Iteration 156/250, Loss: 0.0242\n",
      "Epoch 141/200, Iteration 157/250, Loss: 0.0147\n",
      "Epoch 141/200, Iteration 158/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 159/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 160/250, Loss: 0.0410\n",
      "Epoch 141/200, Iteration 161/250, Loss: 0.0093\n",
      "Epoch 141/200, Iteration 162/250, Loss: 0.0101\n",
      "Epoch 141/200, Iteration 163/250, Loss: 0.0156\n",
      "Epoch 141/200, Iteration 164/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 165/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 166/250, Loss: 0.0163\n",
      "Epoch 141/200, Iteration 167/250, Loss: 0.0148\n",
      "Epoch 141/200, Iteration 168/250, Loss: 0.0100\n",
      "Epoch 141/200, Iteration 169/250, Loss: 0.0099\n",
      "Epoch 141/200, Iteration 170/250, Loss: 0.0092\n",
      "Epoch 141/200, Iteration 171/250, Loss: 0.0256\n",
      "Epoch 141/200, Iteration 172/250, Loss: 0.0261\n",
      "Epoch 141/200, Iteration 173/250, Loss: 0.0188\n",
      "Epoch 141/200, Iteration 174/250, Loss: 0.0141\n",
      "Epoch 141/200, Iteration 175/250, Loss: 0.0169\n",
      "Epoch 141/200, Iteration 176/250, Loss: 0.0087\n",
      "Epoch 141/200, Iteration 177/250, Loss: 0.0059\n",
      "Epoch 141/200, Iteration 178/250, Loss: 0.0116\n",
      "Epoch 141/200, Iteration 179/250, Loss: 0.0251\n",
      "Epoch 141/200, Iteration 180/250, Loss: 0.0087\n",
      "Epoch 141/200, Iteration 181/250, Loss: 0.0134\n",
      "Epoch 141/200, Iteration 182/250, Loss: 0.0114\n",
      "Epoch 141/200, Iteration 183/250, Loss: 0.0138\n",
      "Epoch 141/200, Iteration 184/250, Loss: 0.0197\n",
      "Epoch 141/200, Iteration 185/250, Loss: 0.0154\n",
      "Epoch 141/200, Iteration 186/250, Loss: 0.0179\n",
      "Epoch 141/200, Iteration 187/250, Loss: 0.0226\n",
      "Epoch 141/200, Iteration 188/250, Loss: 0.0133\n",
      "Epoch 141/200, Iteration 189/250, Loss: 0.0267\n",
      "Epoch 141/200, Iteration 190/250, Loss: 0.0198\n",
      "Epoch 141/200, Iteration 191/250, Loss: 0.0124\n",
      "Epoch 141/200, Iteration 192/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 193/250, Loss: 0.0188\n",
      "Epoch 141/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 141/200, Iteration 195/250, Loss: 0.0104\n",
      "Epoch 141/200, Iteration 196/250, Loss: 0.0097\n",
      "Epoch 141/200, Iteration 197/250, Loss: 0.0194\n",
      "Epoch 141/200, Iteration 198/250, Loss: 0.0144\n",
      "Epoch 141/200, Iteration 199/250, Loss: 0.0229\n",
      "Epoch 141/200, Iteration 200/250, Loss: 0.0187\n",
      "Epoch 141/200, Iteration 201/250, Loss: 0.0091\n",
      "Epoch 141/200, Iteration 202/250, Loss: 0.0191\n",
      "Epoch 141/200, Iteration 203/250, Loss: 0.0291\n",
      "Epoch 141/200, Iteration 204/250, Loss: 0.0258\n",
      "Epoch 141/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 141/200, Iteration 206/250, Loss: 0.0065\n",
      "Epoch 141/200, Iteration 207/250, Loss: 0.0083\n",
      "Epoch 141/200, Iteration 208/250, Loss: 0.0188\n",
      "Epoch 141/200, Iteration 209/250, Loss: 0.0189\n",
      "Epoch 141/200, Iteration 210/250, Loss: 0.0062\n",
      "Epoch 141/200, Iteration 211/250, Loss: 0.0281\n",
      "Epoch 141/200, Iteration 212/250, Loss: 0.0154\n",
      "Epoch 141/200, Iteration 213/250, Loss: 0.0197\n",
      "Epoch 141/200, Iteration 214/250, Loss: 0.0576\n",
      "Epoch 141/200, Iteration 215/250, Loss: 0.0175\n",
      "Epoch 141/200, Iteration 216/250, Loss: 0.0404\n",
      "Epoch 141/200, Iteration 217/250, Loss: 0.0094\n",
      "Epoch 141/200, Iteration 218/250, Loss: 0.0314\n",
      "Epoch 141/200, Iteration 219/250, Loss: 0.0224\n",
      "Epoch 141/200, Iteration 220/250, Loss: 0.0232\n",
      "Epoch 141/200, Iteration 221/250, Loss: 0.0120\n",
      "Epoch 141/200, Iteration 222/250, Loss: 0.0115\n",
      "Epoch 141/200, Iteration 223/250, Loss: 0.0223\n",
      "Epoch 141/200, Iteration 224/250, Loss: 0.0098\n",
      "Epoch 141/200, Iteration 225/250, Loss: 0.0125\n",
      "Epoch 141/200, Iteration 226/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 227/250, Loss: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200, Iteration 228/250, Loss: 0.0131\n",
      "Epoch 141/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 141/200, Iteration 230/250, Loss: 0.0334\n",
      "Epoch 141/200, Iteration 231/250, Loss: 0.0233\n",
      "Epoch 141/200, Iteration 232/250, Loss: 0.0107\n",
      "Epoch 141/200, Iteration 233/250, Loss: 0.0162\n",
      "Epoch 141/200, Iteration 234/250, Loss: 0.0235\n",
      "Epoch 141/200, Iteration 235/250, Loss: 0.0230\n",
      "Epoch 141/200, Iteration 236/250, Loss: 0.0083\n",
      "Epoch 141/200, Iteration 237/250, Loss: 0.0222\n",
      "Epoch 141/200, Iteration 238/250, Loss: 0.0083\n",
      "Epoch 141/200, Iteration 239/250, Loss: 0.0095\n",
      "Epoch 141/200, Iteration 240/250, Loss: 0.0291\n",
      "Epoch 141/200, Iteration 241/250, Loss: 0.0489\n",
      "Epoch 141/200, Iteration 242/250, Loss: 0.0286\n",
      "Epoch 141/200, Iteration 243/250, Loss: 0.0177\n",
      "Epoch 141/200, Iteration 244/250, Loss: 0.0069\n",
      "Epoch 141/200, Iteration 245/250, Loss: 0.0166\n",
      "Epoch 141/200, Iteration 246/250, Loss: 0.0253\n",
      "Epoch 141/200, Iteration 247/250, Loss: 0.0085\n",
      "Epoch 141/200, Iteration 248/250, Loss: 0.0230\n",
      "Epoch 141/200, Iteration 249/250, Loss: 0.0148\n",
      "Epoch 141/200, Iteration 250/250, Loss: 0.0165\n",
      "Train Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.007253, MRE: 0.494899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.007756, MRE: 0.583321 \n",
      "\n",
      "Epoch 142/200, Iteration 1/250, Loss: 0.0067\n",
      "Epoch 142/200, Iteration 2/250, Loss: 0.0302\n",
      "Epoch 142/200, Iteration 3/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 4/250, Loss: 0.0107\n",
      "Epoch 142/200, Iteration 5/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 6/250, Loss: 0.0307\n",
      "Epoch 142/200, Iteration 7/250, Loss: 0.0122\n",
      "Epoch 142/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 9/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 10/250, Loss: 0.0412\n",
      "Epoch 142/200, Iteration 11/250, Loss: 0.0187\n",
      "Epoch 142/200, Iteration 12/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 13/250, Loss: 0.0126\n",
      "Epoch 142/200, Iteration 14/250, Loss: 0.0107\n",
      "Epoch 142/200, Iteration 15/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 16/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 17/250, Loss: 0.0187\n",
      "Epoch 142/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 142/200, Iteration 19/250, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 20/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 21/250, Loss: 0.0271\n",
      "Epoch 142/200, Iteration 22/250, Loss: 0.0168\n",
      "Epoch 142/200, Iteration 23/250, Loss: 0.0085\n",
      "Epoch 142/200, Iteration 24/250, Loss: 0.0142\n",
      "Epoch 142/200, Iteration 25/250, Loss: 0.0098\n",
      "Epoch 142/200, Iteration 26/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 27/250, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 28/250, Loss: 0.0274\n",
      "Epoch 142/200, Iteration 29/250, Loss: 0.0179\n",
      "Epoch 142/200, Iteration 30/250, Loss: 0.0107\n",
      "Epoch 142/200, Iteration 31/250, Loss: 0.0322\n",
      "Epoch 142/200, Iteration 32/250, Loss: 0.0401\n",
      "Epoch 142/200, Iteration 33/250, Loss: 0.0133\n",
      "Epoch 142/200, Iteration 34/250, Loss: 0.0188\n",
      "Epoch 142/200, Iteration 35/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 36/250, Loss: 0.0136\n",
      "Epoch 142/200, Iteration 37/250, Loss: 0.0122\n",
      "Epoch 142/200, Iteration 38/250, Loss: 0.0159\n",
      "Epoch 142/200, Iteration 39/250, Loss: 0.0071\n",
      "Epoch 142/200, Iteration 40/250, Loss: 0.0195\n",
      "Epoch 142/200, Iteration 41/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 42/250, Loss: 0.0115\n",
      "Epoch 142/200, Iteration 43/250, Loss: 0.0292\n",
      "Epoch 142/200, Iteration 44/250, Loss: 0.0169\n",
      "Epoch 142/200, Iteration 45/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 46/250, Loss: 0.0147\n",
      "Epoch 142/200, Iteration 47/250, Loss: 0.0104\n",
      "Epoch 142/200, Iteration 48/250, Loss: 0.0150\n",
      "Epoch 142/200, Iteration 49/250, Loss: 0.0133\n",
      "Epoch 142/200, Iteration 50/250, Loss: 0.0058\n",
      "Epoch 142/200, Iteration 51/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 52/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 142/200, Iteration 54/250, Loss: 0.0129\n",
      "Epoch 142/200, Iteration 55/250, Loss: 0.0390\n",
      "Epoch 142/200, Iteration 56/250, Loss: 0.0175\n",
      "Epoch 142/200, Iteration 57/250, Loss: 0.0072\n",
      "Epoch 142/200, Iteration 58/250, Loss: 0.0108\n",
      "Epoch 142/200, Iteration 59/250, Loss: 0.0222\n",
      "Epoch 142/200, Iteration 60/250, Loss: 0.0142\n",
      "Epoch 142/200, Iteration 61/250, Loss: 0.0144\n",
      "Epoch 142/200, Iteration 62/250, Loss: 0.0195\n",
      "Epoch 142/200, Iteration 63/250, Loss: 0.0229\n",
      "Epoch 142/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 142/200, Iteration 65/250, Loss: 0.0160\n",
      "Epoch 142/200, Iteration 66/250, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 67/250, Loss: 0.0084\n",
      "Epoch 142/200, Iteration 68/250, Loss: 0.0093\n",
      "Epoch 142/200, Iteration 69/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 70/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 71/250, Loss: 0.0148\n",
      "Epoch 142/200, Iteration 72/250, Loss: 0.0134\n",
      "Epoch 142/200, Iteration 73/250, Loss: 0.0155\n",
      "Epoch 142/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 142/200, Iteration 75/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 76/250, Loss: 0.0078\n",
      "Epoch 142/200, Iteration 77/250, Loss: 0.0142\n",
      "Epoch 142/200, Iteration 78/250, Loss: 0.0301\n",
      "Epoch 142/200, Iteration 79/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 80/250, Loss: 0.0143\n",
      "Epoch 142/200, Iteration 81/250, Loss: 0.0134\n",
      "Epoch 142/200, Iteration 82/250, Loss: 0.0226\n",
      "Epoch 142/200, Iteration 83/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 84/250, Loss: 0.0178\n",
      "Epoch 142/200, Iteration 85/250, Loss: 0.0225\n",
      "Epoch 142/200, Iteration 86/250, Loss: 0.0165\n",
      "Epoch 142/200, Iteration 87/250, Loss: 0.0078\n",
      "Epoch 142/200, Iteration 88/250, Loss: 0.0197\n",
      "Epoch 142/200, Iteration 89/250, Loss: 0.0112\n",
      "Epoch 142/200, Iteration 90/250, Loss: 0.0157\n",
      "Epoch 142/200, Iteration 91/250, Loss: 0.0298\n",
      "Epoch 142/200, Iteration 92/250, Loss: 0.0192\n",
      "Epoch 142/200, Iteration 93/250, Loss: 0.0119\n",
      "Epoch 142/200, Iteration 94/250, Loss: 0.0166\n",
      "Epoch 142/200, Iteration 95/250, Loss: 0.0211\n",
      "Epoch 142/200, Iteration 96/250, Loss: 0.0153\n",
      "Epoch 142/200, Iteration 97/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 98/250, Loss: 0.0113\n",
      "Epoch 142/200, Iteration 99/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 100/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 101/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 102/250, Loss: 0.0168\n",
      "Epoch 142/200, Iteration 103/250, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 104/250, Loss: 0.0168\n",
      "Epoch 142/200, Iteration 105/250, Loss: 0.0297\n",
      "Epoch 142/200, Iteration 106/250, Loss: 0.0152\n",
      "Epoch 142/200, Iteration 107/250, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 108/250, Loss: 0.0193\n",
      "Epoch 142/200, Iteration 109/250, Loss: 0.0163\n",
      "Epoch 142/200, Iteration 110/250, Loss: 0.0182\n",
      "Epoch 142/200, Iteration 111/250, Loss: 0.0287\n",
      "Epoch 142/200, Iteration 112/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 113/250, Loss: 0.0141\n",
      "Epoch 142/200, Iteration 114/250, Loss: 0.0222\n",
      "Epoch 142/200, Iteration 115/250, Loss: 0.0125\n",
      "Epoch 142/200, Iteration 116/250, Loss: 0.0156\n",
      "Epoch 142/200, Iteration 117/250, Loss: 0.0103\n",
      "Epoch 142/200, Iteration 118/250, Loss: 0.0477\n",
      "Epoch 142/200, Iteration 119/250, Loss: 0.0141\n",
      "Epoch 142/200, Iteration 120/250, Loss: 0.0061\n",
      "Epoch 142/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 122/250, Loss: 0.0306\n",
      "Epoch 142/200, Iteration 123/250, Loss: 0.0332\n",
      "Epoch 142/200, Iteration 124/250, Loss: 0.0172\n",
      "Epoch 142/200, Iteration 125/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 126/250, Loss: 0.0104\n",
      "Epoch 142/200, Iteration 127/250, Loss: 0.0154\n",
      "Epoch 142/200, Iteration 128/250, Loss: 0.0205\n",
      "Epoch 142/200, Iteration 129/250, Loss: 0.0091\n",
      "Epoch 142/200, Iteration 130/250, Loss: 0.0177\n",
      "Epoch 142/200, Iteration 131/250, Loss: 0.0286\n",
      "Epoch 142/200, Iteration 132/250, Loss: 0.0094\n",
      "Epoch 142/200, Iteration 133/250, Loss: 0.0139\n",
      "Epoch 142/200, Iteration 134/250, Loss: 0.0215\n",
      "Epoch 142/200, Iteration 135/250, Loss: 0.0121\n",
      "Epoch 142/200, Iteration 136/250, Loss: 0.0093\n",
      "Epoch 142/200, Iteration 137/250, Loss: 0.0098\n",
      "Epoch 142/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 139/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 140/250, Loss: 0.0065\n",
      "Epoch 142/200, Iteration 141/250, Loss: 0.0314\n",
      "Epoch 142/200, Iteration 142/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 143/250, Loss: 0.0162\n",
      "Epoch 142/200, Iteration 144/250, Loss: 0.0237\n",
      "Epoch 142/200, Iteration 145/250, Loss: 0.0061\n",
      "Epoch 142/200, Iteration 146/250, Loss: 0.0087\n",
      "Epoch 142/200, Iteration 147/250, Loss: 0.0118\n",
      "Epoch 142/200, Iteration 148/250, Loss: 0.0132\n",
      "Epoch 142/200, Iteration 149/250, Loss: 0.0176\n",
      "Epoch 142/200, Iteration 150/250, Loss: 0.0177\n",
      "Epoch 142/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 152/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 153/250, Loss: 0.0470\n",
      "Epoch 142/200, Iteration 154/250, Loss: 0.0222\n",
      "Epoch 142/200, Iteration 155/250, Loss: 0.0123\n",
      "Epoch 142/200, Iteration 156/250, Loss: 0.0206\n",
      "Epoch 142/200, Iteration 157/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 158/250, Loss: 0.0207\n",
      "Epoch 142/200, Iteration 159/250, Loss: 0.0135\n",
      "Epoch 142/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 142/200, Iteration 161/250, Loss: 0.0163\n",
      "Epoch 142/200, Iteration 162/250, Loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200, Iteration 163/250, Loss: 0.0194\n",
      "Epoch 142/200, Iteration 164/250, Loss: 0.0106\n",
      "Epoch 142/200, Iteration 165/250, Loss: 0.0109\n",
      "Epoch 142/200, Iteration 166/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 167/250, Loss: 0.0114\n",
      "Epoch 142/200, Iteration 168/250, Loss: 0.0203\n",
      "Epoch 142/200, Iteration 169/250, Loss: 0.0166\n",
      "Epoch 142/200, Iteration 170/250, Loss: 0.0108\n",
      "Epoch 142/200, Iteration 171/250, Loss: 0.0150\n",
      "Epoch 142/200, Iteration 172/250, Loss: 0.0122\n",
      "Epoch 142/200, Iteration 173/250, Loss: 0.0117\n",
      "Epoch 142/200, Iteration 174/250, Loss: 0.0074\n",
      "Epoch 142/200, Iteration 175/250, Loss: 0.0080\n",
      "Epoch 142/200, Iteration 176/250, Loss: 0.0216\n",
      "Epoch 142/200, Iteration 177/250, Loss: 0.0161\n",
      "Epoch 142/200, Iteration 178/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 179/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 180/250, Loss: 0.0188\n",
      "Epoch 142/200, Iteration 181/250, Loss: 0.0209\n",
      "Epoch 142/200, Iteration 182/250, Loss: 0.0131\n",
      "Epoch 142/200, Iteration 183/250, Loss: 0.0281\n",
      "Epoch 142/200, Iteration 184/250, Loss: 0.0306\n",
      "Epoch 142/200, Iteration 185/250, Loss: 0.0261\n",
      "Epoch 142/200, Iteration 186/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 142/200, Iteration 188/250, Loss: 0.0115\n",
      "Epoch 142/200, Iteration 189/250, Loss: 0.0097\n",
      "Epoch 142/200, Iteration 190/250, Loss: 0.0196\n",
      "Epoch 142/200, Iteration 191/250, Loss: 0.0158\n",
      "Epoch 142/200, Iteration 192/250, Loss: 0.0099\n",
      "Epoch 142/200, Iteration 193/250, Loss: 0.0220\n",
      "Epoch 142/200, Iteration 194/250, Loss: 0.0112\n",
      "Epoch 142/200, Iteration 195/250, Loss: 0.0107\n",
      "Epoch 142/200, Iteration 196/250, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 197/250, Loss: 0.0107\n",
      "Epoch 142/200, Iteration 198/250, Loss: 0.0151\n",
      "Epoch 142/200, Iteration 199/250, Loss: 0.0218\n",
      "Epoch 142/200, Iteration 200/250, Loss: 0.0125\n",
      "Epoch 142/200, Iteration 201/250, Loss: 0.0159\n",
      "Epoch 142/200, Iteration 202/250, Loss: 0.0171\n",
      "Epoch 142/200, Iteration 203/250, Loss: 0.0199\n",
      "Epoch 142/200, Iteration 204/250, Loss: 0.0104\n",
      "Epoch 142/200, Iteration 205/250, Loss: 0.0075\n",
      "Epoch 142/200, Iteration 206/250, Loss: 0.0088\n",
      "Epoch 142/200, Iteration 207/250, Loss: 0.0178\n",
      "Epoch 142/200, Iteration 208/250, Loss: 0.0125\n",
      "Epoch 142/200, Iteration 209/250, Loss: 0.0200\n",
      "Epoch 142/200, Iteration 210/250, Loss: 0.0297\n",
      "Epoch 142/200, Iteration 211/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 142/200, Iteration 213/250, Loss: 0.0081\n",
      "Epoch 142/200, Iteration 214/250, Loss: 0.0098\n",
      "Epoch 142/200, Iteration 215/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 216/250, Loss: 0.0096\n",
      "Epoch 142/200, Iteration 217/250, Loss: 0.0353\n",
      "Epoch 142/200, Iteration 218/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 219/250, Loss: 0.0130\n",
      "Epoch 142/200, Iteration 220/250, Loss: 0.0116\n",
      "Epoch 142/200, Iteration 221/250, Loss: 0.0095\n",
      "Epoch 142/200, Iteration 222/250, Loss: 0.0131\n",
      "Epoch 142/200, Iteration 223/250, Loss: 0.0119\n",
      "Epoch 142/200, Iteration 224/250, Loss: 0.0184\n",
      "Epoch 142/200, Iteration 225/250, Loss: 0.0289\n",
      "Epoch 142/200, Iteration 226/250, Loss: 0.0092\n",
      "Epoch 142/200, Iteration 227/250, Loss: 0.0097\n",
      "Epoch 142/200, Iteration 228/250, Loss: 0.0102\n",
      "Epoch 142/200, Iteration 229/250, Loss: 0.0217\n",
      "Epoch 142/200, Iteration 230/250, Loss: 0.0466\n",
      "Epoch 142/200, Iteration 231/250, Loss: 0.0087\n",
      "Epoch 142/200, Iteration 232/250, Loss: 0.0089\n",
      "Epoch 142/200, Iteration 233/250, Loss: 0.0136\n",
      "Epoch 142/200, Iteration 234/250, Loss: 0.0101\n",
      "Epoch 142/200, Iteration 235/250, Loss: 0.0166\n",
      "Epoch 142/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 142/200, Iteration 237/250, Loss: 0.0297\n",
      "Epoch 142/200, Iteration 238/250, Loss: 0.0188\n",
      "Epoch 142/200, Iteration 239/250, Loss: 0.0133\n",
      "Epoch 142/200, Iteration 240/250, Loss: 0.0241\n",
      "Epoch 142/200, Iteration 241/250, Loss: 0.0108\n",
      "Epoch 142/200, Iteration 242/250, Loss: 0.0223\n",
      "Epoch 142/200, Iteration 243/250, Loss: 0.0174\n",
      "Epoch 142/200, Iteration 244/250, Loss: 0.0083\n",
      "Epoch 142/200, Iteration 245/250, Loss: 0.0330\n",
      "Epoch 142/200, Iteration 246/250, Loss: 0.0113\n",
      "Epoch 142/200, Iteration 247/250, Loss: 0.0353\n",
      "Epoch 142/200, Iteration 248/250, Loss: 0.0138\n",
      "Epoch 142/200, Iteration 249/250, Loss: 0.0293\n",
      "Epoch 142/200, Iteration 250/250, Loss: 0.0137\n",
      "Train Error: \n",
      " Accuracy: 94.54%, Avg loss: 0.007426, MRE: 0.482683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.008091, MRE: 0.530521 \n",
      "\n",
      "Epoch 143/200, Iteration 1/250, Loss: 0.0144\n",
      "Epoch 143/200, Iteration 2/250, Loss: 0.0458\n",
      "Epoch 143/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 143/200, Iteration 4/250, Loss: 0.0108\n",
      "Epoch 143/200, Iteration 5/250, Loss: 0.0133\n",
      "Epoch 143/200, Iteration 6/250, Loss: 0.0266\n",
      "Epoch 143/200, Iteration 7/250, Loss: 0.0122\n",
      "Epoch 143/200, Iteration 8/250, Loss: 0.0221\n",
      "Epoch 143/200, Iteration 9/250, Loss: 0.0142\n",
      "Epoch 143/200, Iteration 10/250, Loss: 0.0204\n",
      "Epoch 143/200, Iteration 11/250, Loss: 0.0230\n",
      "Epoch 143/200, Iteration 12/250, Loss: 0.0104\n",
      "Epoch 143/200, Iteration 13/250, Loss: 0.0084\n",
      "Epoch 143/200, Iteration 14/250, Loss: 0.0155\n",
      "Epoch 143/200, Iteration 15/250, Loss: 0.0237\n",
      "Epoch 143/200, Iteration 16/250, Loss: 0.0164\n",
      "Epoch 143/200, Iteration 17/250, Loss: 0.0076\n",
      "Epoch 143/200, Iteration 18/250, Loss: 0.0288\n",
      "Epoch 143/200, Iteration 19/250, Loss: 0.0093\n",
      "Epoch 143/200, Iteration 20/250, Loss: 0.0126\n",
      "Epoch 143/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 143/200, Iteration 22/250, Loss: 0.0180\n",
      "Epoch 143/200, Iteration 23/250, Loss: 0.0285\n",
      "Epoch 143/200, Iteration 24/250, Loss: 0.0090\n",
      "Epoch 143/200, Iteration 25/250, Loss: 0.0084\n",
      "Epoch 143/200, Iteration 26/250, Loss: 0.0071\n",
      "Epoch 143/200, Iteration 27/250, Loss: 0.0103\n",
      "Epoch 143/200, Iteration 28/250, Loss: 0.0198\n",
      "Epoch 143/200, Iteration 29/250, Loss: 0.0122\n",
      "Epoch 143/200, Iteration 30/250, Loss: 0.0134\n",
      "Epoch 143/200, Iteration 31/250, Loss: 0.0153\n",
      "Epoch 143/200, Iteration 32/250, Loss: 0.0301\n",
      "Epoch 143/200, Iteration 33/250, Loss: 0.0089\n",
      "Epoch 143/200, Iteration 34/250, Loss: 0.0202\n",
      "Epoch 143/200, Iteration 35/250, Loss: 0.0311\n",
      "Epoch 143/200, Iteration 36/250, Loss: 0.0128\n",
      "Epoch 143/200, Iteration 37/250, Loss: 0.0285\n",
      "Epoch 143/200, Iteration 38/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 39/250, Loss: 0.0135\n",
      "Epoch 143/200, Iteration 40/250, Loss: 0.0200\n",
      "Epoch 143/200, Iteration 41/250, Loss: 0.0276\n",
      "Epoch 143/200, Iteration 42/250, Loss: 0.0140\n",
      "Epoch 143/200, Iteration 43/250, Loss: 0.0114\n",
      "Epoch 143/200, Iteration 44/250, Loss: 0.0103\n",
      "Epoch 143/200, Iteration 45/250, Loss: 0.0222\n",
      "Epoch 143/200, Iteration 46/250, Loss: 0.0410\n",
      "Epoch 143/200, Iteration 47/250, Loss: 0.0092\n",
      "Epoch 143/200, Iteration 48/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 49/250, Loss: 0.0113\n",
      "Epoch 143/200, Iteration 50/250, Loss: 0.0114\n",
      "Epoch 143/200, Iteration 51/250, Loss: 0.0123\n",
      "Epoch 143/200, Iteration 52/250, Loss: 0.0177\n",
      "Epoch 143/200, Iteration 53/250, Loss: 0.0113\n",
      "Epoch 143/200, Iteration 54/250, Loss: 0.0343\n",
      "Epoch 143/200, Iteration 55/250, Loss: 0.0227\n",
      "Epoch 143/200, Iteration 56/250, Loss: 0.0194\n",
      "Epoch 143/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 143/200, Iteration 58/250, Loss: 0.0134\n",
      "Epoch 143/200, Iteration 59/250, Loss: 0.0150\n",
      "Epoch 143/200, Iteration 60/250, Loss: 0.0111\n",
      "Epoch 143/200, Iteration 61/250, Loss: 0.0096\n",
      "Epoch 143/200, Iteration 62/250, Loss: 0.0144\n",
      "Epoch 143/200, Iteration 63/250, Loss: 0.0274\n",
      "Epoch 143/200, Iteration 64/250, Loss: 0.0182\n",
      "Epoch 143/200, Iteration 65/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 66/250, Loss: 0.0116\n",
      "Epoch 143/200, Iteration 67/250, Loss: 0.0153\n",
      "Epoch 143/200, Iteration 68/250, Loss: 0.0074\n",
      "Epoch 143/200, Iteration 69/250, Loss: 0.0259\n",
      "Epoch 143/200, Iteration 70/250, Loss: 0.0108\n",
      "Epoch 143/200, Iteration 71/250, Loss: 0.0181\n",
      "Epoch 143/200, Iteration 72/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 73/250, Loss: 0.0139\n",
      "Epoch 143/200, Iteration 74/250, Loss: 0.0141\n",
      "Epoch 143/200, Iteration 75/250, Loss: 0.0074\n",
      "Epoch 143/200, Iteration 76/250, Loss: 0.0106\n",
      "Epoch 143/200, Iteration 77/250, Loss: 0.0101\n",
      "Epoch 143/200, Iteration 78/250, Loss: 0.0169\n",
      "Epoch 143/200, Iteration 79/250, Loss: 0.0089\n",
      "Epoch 143/200, Iteration 80/250, Loss: 0.0154\n",
      "Epoch 143/200, Iteration 81/250, Loss: 0.0070\n",
      "Epoch 143/200, Iteration 82/250, Loss: 0.0298\n",
      "Epoch 143/200, Iteration 83/250, Loss: 0.0108\n",
      "Epoch 143/200, Iteration 84/250, Loss: 0.0145\n",
      "Epoch 143/200, Iteration 85/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 86/250, Loss: 0.0121\n",
      "Epoch 143/200, Iteration 87/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200, Iteration 88/250, Loss: 0.0154\n",
      "Epoch 143/200, Iteration 89/250, Loss: 0.0087\n",
      "Epoch 143/200, Iteration 90/250, Loss: 0.0117\n",
      "Epoch 143/200, Iteration 91/250, Loss: 0.0109\n",
      "Epoch 143/200, Iteration 92/250, Loss: 0.0363\n",
      "Epoch 143/200, Iteration 93/250, Loss: 0.0144\n",
      "Epoch 143/200, Iteration 94/250, Loss: 0.0254\n",
      "Epoch 143/200, Iteration 95/250, Loss: 0.0086\n",
      "Epoch 143/200, Iteration 96/250, Loss: 0.0307\n",
      "Epoch 143/200, Iteration 97/250, Loss: 0.0148\n",
      "Epoch 143/200, Iteration 98/250, Loss: 0.0263\n",
      "Epoch 143/200, Iteration 99/250, Loss: 0.0249\n",
      "Epoch 143/200, Iteration 100/250, Loss: 0.0215\n",
      "Epoch 143/200, Iteration 101/250, Loss: 0.0139\n",
      "Epoch 143/200, Iteration 102/250, Loss: 0.0137\n",
      "Epoch 143/200, Iteration 103/250, Loss: 0.0100\n",
      "Epoch 143/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 143/200, Iteration 105/250, Loss: 0.0279\n",
      "Epoch 143/200, Iteration 106/250, Loss: 0.0166\n",
      "Epoch 143/200, Iteration 107/250, Loss: 0.0127\n",
      "Epoch 143/200, Iteration 108/250, Loss: 0.0069\n",
      "Epoch 143/200, Iteration 109/250, Loss: 0.0159\n",
      "Epoch 143/200, Iteration 110/250, Loss: 0.0096\n",
      "Epoch 143/200, Iteration 111/250, Loss: 0.0100\n",
      "Epoch 143/200, Iteration 112/250, Loss: 0.0265\n",
      "Epoch 143/200, Iteration 113/250, Loss: 0.0087\n",
      "Epoch 143/200, Iteration 114/250, Loss: 0.0067\n",
      "Epoch 143/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 143/200, Iteration 116/250, Loss: 0.0053\n",
      "Epoch 143/200, Iteration 117/250, Loss: 0.0206\n",
      "Epoch 143/200, Iteration 118/250, Loss: 0.0255\n",
      "Epoch 143/200, Iteration 119/250, Loss: 0.0170\n",
      "Epoch 143/200, Iteration 120/250, Loss: 0.0381\n",
      "Epoch 143/200, Iteration 121/250, Loss: 0.0075\n",
      "Epoch 143/200, Iteration 122/250, Loss: 0.0135\n",
      "Epoch 143/200, Iteration 123/250, Loss: 0.0127\n",
      "Epoch 143/200, Iteration 124/250, Loss: 0.0081\n",
      "Epoch 143/200, Iteration 125/250, Loss: 0.0269\n",
      "Epoch 143/200, Iteration 126/250, Loss: 0.0159\n",
      "Epoch 143/200, Iteration 127/250, Loss: 0.0184\n",
      "Epoch 143/200, Iteration 128/250, Loss: 0.0301\n",
      "Epoch 143/200, Iteration 129/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 130/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 131/250, Loss: 0.0276\n",
      "Epoch 143/200, Iteration 132/250, Loss: 0.0105\n",
      "Epoch 143/200, Iteration 133/250, Loss: 0.0222\n",
      "Epoch 143/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 143/200, Iteration 135/250, Loss: 0.0118\n",
      "Epoch 143/200, Iteration 136/250, Loss: 0.0186\n",
      "Epoch 143/200, Iteration 137/250, Loss: 0.0168\n",
      "Epoch 143/200, Iteration 138/250, Loss: 0.0112\n",
      "Epoch 143/200, Iteration 139/250, Loss: 0.0071\n",
      "Epoch 143/200, Iteration 140/250, Loss: 0.0181\n",
      "Epoch 143/200, Iteration 141/250, Loss: 0.0151\n",
      "Epoch 143/200, Iteration 142/250, Loss: 0.0298\n",
      "Epoch 143/200, Iteration 143/250, Loss: 0.0100\n",
      "Epoch 143/200, Iteration 144/250, Loss: 0.0180\n",
      "Epoch 143/200, Iteration 145/250, Loss: 0.0138\n",
      "Epoch 143/200, Iteration 146/250, Loss: 0.0235\n",
      "Epoch 143/200, Iteration 147/250, Loss: 0.0338\n",
      "Epoch 143/200, Iteration 148/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 149/250, Loss: 0.0219\n",
      "Epoch 143/200, Iteration 150/250, Loss: 0.0103\n",
      "Epoch 143/200, Iteration 151/250, Loss: 0.0200\n",
      "Epoch 143/200, Iteration 152/250, Loss: 0.0104\n",
      "Epoch 143/200, Iteration 153/250, Loss: 0.0144\n",
      "Epoch 143/200, Iteration 154/250, Loss: 0.0131\n",
      "Epoch 143/200, Iteration 155/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 143/200, Iteration 157/250, Loss: 0.0212\n",
      "Epoch 143/200, Iteration 158/250, Loss: 0.0119\n",
      "Epoch 143/200, Iteration 159/250, Loss: 0.0212\n",
      "Epoch 143/200, Iteration 160/250, Loss: 0.0129\n",
      "Epoch 143/200, Iteration 161/250, Loss: 0.0153\n",
      "Epoch 143/200, Iteration 162/250, Loss: 0.0187\n",
      "Epoch 143/200, Iteration 163/250, Loss: 0.0088\n",
      "Epoch 143/200, Iteration 164/250, Loss: 0.0180\n",
      "Epoch 143/200, Iteration 165/250, Loss: 0.0068\n",
      "Epoch 143/200, Iteration 166/250, Loss: 0.0127\n",
      "Epoch 143/200, Iteration 167/250, Loss: 0.0182\n",
      "Epoch 143/200, Iteration 168/250, Loss: 0.0142\n",
      "Epoch 143/200, Iteration 169/250, Loss: 0.0091\n",
      "Epoch 143/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 143/200, Iteration 171/250, Loss: 0.0079\n",
      "Epoch 143/200, Iteration 172/250, Loss: 0.0227\n",
      "Epoch 143/200, Iteration 173/250, Loss: 0.0171\n",
      "Epoch 143/200, Iteration 174/250, Loss: 0.0111\n",
      "Epoch 143/200, Iteration 175/250, Loss: 0.0233\n",
      "Epoch 143/200, Iteration 176/250, Loss: 0.0345\n",
      "Epoch 143/200, Iteration 177/250, Loss: 0.0140\n",
      "Epoch 143/200, Iteration 178/250, Loss: 0.0090\n",
      "Epoch 143/200, Iteration 179/250, Loss: 0.0115\n",
      "Epoch 143/200, Iteration 180/250, Loss: 0.0267\n",
      "Epoch 143/200, Iteration 181/250, Loss: 0.0175\n",
      "Epoch 143/200, Iteration 182/250, Loss: 0.0217\n",
      "Epoch 143/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 143/200, Iteration 184/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 185/250, Loss: 0.0320\n",
      "Epoch 143/200, Iteration 186/250, Loss: 0.0189\n",
      "Epoch 143/200, Iteration 187/250, Loss: 0.0332\n",
      "Epoch 143/200, Iteration 188/250, Loss: 0.0126\n",
      "Epoch 143/200, Iteration 189/250, Loss: 0.0113\n",
      "Epoch 143/200, Iteration 190/250, Loss: 0.0271\n",
      "Epoch 143/200, Iteration 191/250, Loss: 0.0188\n",
      "Epoch 143/200, Iteration 192/250, Loss: 0.0275\n",
      "Epoch 143/200, Iteration 193/250, Loss: 0.0382\n",
      "Epoch 143/200, Iteration 194/250, Loss: 0.0154\n",
      "Epoch 143/200, Iteration 195/250, Loss: 0.0083\n",
      "Epoch 143/200, Iteration 196/250, Loss: 0.0217\n",
      "Epoch 143/200, Iteration 197/250, Loss: 0.0132\n",
      "Epoch 143/200, Iteration 198/250, Loss: 0.0189\n",
      "Epoch 143/200, Iteration 199/250, Loss: 0.0377\n",
      "Epoch 143/200, Iteration 200/250, Loss: 0.0149\n",
      "Epoch 143/200, Iteration 201/250, Loss: 0.0171\n",
      "Epoch 143/200, Iteration 202/250, Loss: 0.0229\n",
      "Epoch 143/200, Iteration 203/250, Loss: 0.0131\n",
      "Epoch 143/200, Iteration 204/250, Loss: 0.0185\n",
      "Epoch 143/200, Iteration 205/250, Loss: 0.0273\n",
      "Epoch 143/200, Iteration 206/250, Loss: 0.0120\n",
      "Epoch 143/200, Iteration 207/250, Loss: 0.0074\n",
      "Epoch 143/200, Iteration 208/250, Loss: 0.0123\n",
      "Epoch 143/200, Iteration 209/250, Loss: 0.0190\n",
      "Epoch 143/200, Iteration 210/250, Loss: 0.0127\n",
      "Epoch 143/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 143/200, Iteration 212/250, Loss: 0.0077\n",
      "Epoch 143/200, Iteration 213/250, Loss: 0.0073\n",
      "Epoch 143/200, Iteration 214/250, Loss: 0.0324\n",
      "Epoch 143/200, Iteration 215/250, Loss: 0.0122\n",
      "Epoch 143/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 143/200, Iteration 217/250, Loss: 0.0108\n",
      "Epoch 143/200, Iteration 218/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 219/250, Loss: 0.0171\n",
      "Epoch 143/200, Iteration 220/250, Loss: 0.0079\n",
      "Epoch 143/200, Iteration 221/250, Loss: 0.0138\n",
      "Epoch 143/200, Iteration 222/250, Loss: 0.0187\n",
      "Epoch 143/200, Iteration 223/250, Loss: 0.0227\n",
      "Epoch 143/200, Iteration 224/250, Loss: 0.0097\n",
      "Epoch 143/200, Iteration 225/250, Loss: 0.0215\n",
      "Epoch 143/200, Iteration 226/250, Loss: 0.0129\n",
      "Epoch 143/200, Iteration 227/250, Loss: 0.0121\n",
      "Epoch 143/200, Iteration 228/250, Loss: 0.0147\n",
      "Epoch 143/200, Iteration 229/250, Loss: 0.0184\n",
      "Epoch 143/200, Iteration 230/250, Loss: 0.0103\n",
      "Epoch 143/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 143/200, Iteration 232/250, Loss: 0.0287\n",
      "Epoch 143/200, Iteration 233/250, Loss: 0.0135\n",
      "Epoch 143/200, Iteration 234/250, Loss: 0.0130\n",
      "Epoch 143/200, Iteration 235/250, Loss: 0.0303\n",
      "Epoch 143/200, Iteration 236/250, Loss: 0.0221\n",
      "Epoch 143/200, Iteration 237/250, Loss: 0.0082\n",
      "Epoch 143/200, Iteration 238/250, Loss: 0.0198\n",
      "Epoch 143/200, Iteration 239/250, Loss: 0.0098\n",
      "Epoch 143/200, Iteration 240/250, Loss: 0.0137\n",
      "Epoch 143/200, Iteration 241/250, Loss: 0.0170\n",
      "Epoch 143/200, Iteration 242/250, Loss: 0.0085\n",
      "Epoch 143/200, Iteration 243/250, Loss: 0.0134\n",
      "Epoch 143/200, Iteration 244/250, Loss: 0.0137\n",
      "Epoch 143/200, Iteration 245/250, Loss: 0.0305\n",
      "Epoch 143/200, Iteration 246/250, Loss: 0.0121\n",
      "Epoch 143/200, Iteration 247/250, Loss: 0.0146\n",
      "Epoch 143/200, Iteration 248/250, Loss: 0.0201\n",
      "Epoch 143/200, Iteration 249/250, Loss: 0.0148\n",
      "Epoch 143/200, Iteration 250/250, Loss: 0.0109\n",
      "Train Error: \n",
      " Accuracy: 87.65%, Avg loss: 0.006981, MRE: 0.494502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.35%, Avg loss: 0.007535, MRE: 0.564865 \n",
      "\n",
      "Epoch 144/200, Iteration 1/250, Loss: 0.0112\n",
      "Epoch 144/200, Iteration 2/250, Loss: 0.0173\n",
      "Epoch 144/200, Iteration 3/250, Loss: 0.0132\n",
      "Epoch 144/200, Iteration 4/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 5/250, Loss: 0.0173\n",
      "Epoch 144/200, Iteration 6/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 7/250, Loss: 0.0081\n",
      "Epoch 144/200, Iteration 8/250, Loss: 0.0170\n",
      "Epoch 144/200, Iteration 9/250, Loss: 0.0192\n",
      "Epoch 144/200, Iteration 10/250, Loss: 0.0172\n",
      "Epoch 144/200, Iteration 11/250, Loss: 0.0085\n",
      "Epoch 144/200, Iteration 12/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 13/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 14/250, Loss: 0.0192\n",
      "Epoch 144/200, Iteration 15/250, Loss: 0.0231\n",
      "Epoch 144/200, Iteration 16/250, Loss: 0.0084\n",
      "Epoch 144/200, Iteration 17/250, Loss: 0.0252\n",
      "Epoch 144/200, Iteration 18/250, Loss: 0.0101\n",
      "Epoch 144/200, Iteration 19/250, Loss: 0.0246\n",
      "Epoch 144/200, Iteration 20/250, Loss: 0.0089\n",
      "Epoch 144/200, Iteration 21/250, Loss: 0.0101\n",
      "Epoch 144/200, Iteration 22/250, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 23/250, Loss: 0.0121\n",
      "Epoch 144/200, Iteration 24/250, Loss: 0.0062\n",
      "Epoch 144/200, Iteration 25/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 26/250, Loss: 0.0197\n",
      "Epoch 144/200, Iteration 27/250, Loss: 0.0106\n",
      "Epoch 144/200, Iteration 28/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 29/250, Loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200, Iteration 30/250, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 31/250, Loss: 0.0290\n",
      "Epoch 144/200, Iteration 32/250, Loss: 0.0095\n",
      "Epoch 144/200, Iteration 33/250, Loss: 0.0072\n",
      "Epoch 144/200, Iteration 34/250, Loss: 0.0259\n",
      "Epoch 144/200, Iteration 35/250, Loss: 0.0338\n",
      "Epoch 144/200, Iteration 36/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 37/250, Loss: 0.0092\n",
      "Epoch 144/200, Iteration 38/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 39/250, Loss: 0.0178\n",
      "Epoch 144/200, Iteration 40/250, Loss: 0.0366\n",
      "Epoch 144/200, Iteration 41/250, Loss: 0.0104\n",
      "Epoch 144/200, Iteration 42/250, Loss: 0.0100\n",
      "Epoch 144/200, Iteration 43/250, Loss: 0.0384\n",
      "Epoch 144/200, Iteration 44/250, Loss: 0.0080\n",
      "Epoch 144/200, Iteration 45/250, Loss: 0.0158\n",
      "Epoch 144/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 144/200, Iteration 47/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 48/250, Loss: 0.0121\n",
      "Epoch 144/200, Iteration 49/250, Loss: 0.0071\n",
      "Epoch 144/200, Iteration 50/250, Loss: 0.0099\n",
      "Epoch 144/200, Iteration 51/250, Loss: 0.0339\n",
      "Epoch 144/200, Iteration 52/250, Loss: 0.0207\n",
      "Epoch 144/200, Iteration 53/250, Loss: 0.0126\n",
      "Epoch 144/200, Iteration 54/250, Loss: 0.0126\n",
      "Epoch 144/200, Iteration 55/250, Loss: 0.0267\n",
      "Epoch 144/200, Iteration 56/250, Loss: 0.0254\n",
      "Epoch 144/200, Iteration 57/250, Loss: 0.0149\n",
      "Epoch 144/200, Iteration 58/250, Loss: 0.0173\n",
      "Epoch 144/200, Iteration 59/250, Loss: 0.0128\n",
      "Epoch 144/200, Iteration 60/250, Loss: 0.0174\n",
      "Epoch 144/200, Iteration 61/250, Loss: 0.0164\n",
      "Epoch 144/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 144/200, Iteration 63/250, Loss: 0.0088\n",
      "Epoch 144/200, Iteration 64/250, Loss: 0.0299\n",
      "Epoch 144/200, Iteration 65/250, Loss: 0.0116\n",
      "Epoch 144/200, Iteration 66/250, Loss: 0.0117\n",
      "Epoch 144/200, Iteration 67/250, Loss: 0.0121\n",
      "Epoch 144/200, Iteration 68/250, Loss: 0.0203\n",
      "Epoch 144/200, Iteration 69/250, Loss: 0.0077\n",
      "Epoch 144/200, Iteration 70/250, Loss: 0.0171\n",
      "Epoch 144/200, Iteration 71/250, Loss: 0.0189\n",
      "Epoch 144/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 144/200, Iteration 73/250, Loss: 0.0146\n",
      "Epoch 144/200, Iteration 74/250, Loss: 0.0207\n",
      "Epoch 144/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 144/200, Iteration 76/250, Loss: 0.0149\n",
      "Epoch 144/200, Iteration 77/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 78/250, Loss: 0.0110\n",
      "Epoch 144/200, Iteration 79/250, Loss: 0.0075\n",
      "Epoch 144/200, Iteration 80/250, Loss: 0.0182\n",
      "Epoch 144/200, Iteration 81/250, Loss: 0.0141\n",
      "Epoch 144/200, Iteration 82/250, Loss: 0.0099\n",
      "Epoch 144/200, Iteration 83/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 84/250, Loss: 0.0186\n",
      "Epoch 144/200, Iteration 85/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 86/250, Loss: 0.0143\n",
      "Epoch 144/200, Iteration 87/250, Loss: 0.0089\n",
      "Epoch 144/200, Iteration 88/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 89/250, Loss: 0.0079\n",
      "Epoch 144/200, Iteration 90/250, Loss: 0.0241\n",
      "Epoch 144/200, Iteration 91/250, Loss: 0.0108\n",
      "Epoch 144/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 144/200, Iteration 93/250, Loss: 0.0117\n",
      "Epoch 144/200, Iteration 94/250, Loss: 0.0162\n",
      "Epoch 144/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 144/200, Iteration 96/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 97/250, Loss: 0.0087\n",
      "Epoch 144/200, Iteration 98/250, Loss: 0.0204\n",
      "Epoch 144/200, Iteration 99/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 100/250, Loss: 0.0190\n",
      "Epoch 144/200, Iteration 101/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 102/250, Loss: 0.0156\n",
      "Epoch 144/200, Iteration 103/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 104/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 105/250, Loss: 0.0131\n",
      "Epoch 144/200, Iteration 106/250, Loss: 0.0128\n",
      "Epoch 144/200, Iteration 107/250, Loss: 0.0082\n",
      "Epoch 144/200, Iteration 108/250, Loss: 0.0222\n",
      "Epoch 144/200, Iteration 109/250, Loss: 0.0085\n",
      "Epoch 144/200, Iteration 110/250, Loss: 0.0178\n",
      "Epoch 144/200, Iteration 111/250, Loss: 0.0233\n",
      "Epoch 144/200, Iteration 112/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 113/250, Loss: 0.0233\n",
      "Epoch 144/200, Iteration 114/250, Loss: 0.0205\n",
      "Epoch 144/200, Iteration 115/250, Loss: 0.0097\n",
      "Epoch 144/200, Iteration 116/250, Loss: 0.0085\n",
      "Epoch 144/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 144/200, Iteration 118/250, Loss: 0.0228\n",
      "Epoch 144/200, Iteration 119/250, Loss: 0.0145\n",
      "Epoch 144/200, Iteration 120/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 121/250, Loss: 0.0127\n",
      "Epoch 144/200, Iteration 122/250, Loss: 0.0143\n",
      "Epoch 144/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 144/200, Iteration 124/250, Loss: 0.0139\n",
      "Epoch 144/200, Iteration 125/250, Loss: 0.0125\n",
      "Epoch 144/200, Iteration 126/250, Loss: 0.0190\n",
      "Epoch 144/200, Iteration 127/250, Loss: 0.0090\n",
      "Epoch 144/200, Iteration 128/250, Loss: 0.0173\n",
      "Epoch 144/200, Iteration 129/250, Loss: 0.0089\n",
      "Epoch 144/200, Iteration 130/250, Loss: 0.0136\n",
      "Epoch 144/200, Iteration 131/250, Loss: 0.0183\n",
      "Epoch 144/200, Iteration 132/250, Loss: 0.0153\n",
      "Epoch 144/200, Iteration 133/250, Loss: 0.0318\n",
      "Epoch 144/200, Iteration 134/250, Loss: 0.0091\n",
      "Epoch 144/200, Iteration 135/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 136/250, Loss: 0.0402\n",
      "Epoch 144/200, Iteration 137/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 144/200, Iteration 139/250, Loss: 0.0122\n",
      "Epoch 144/200, Iteration 140/250, Loss: 0.0062\n",
      "Epoch 144/200, Iteration 141/250, Loss: 0.0164\n",
      "Epoch 144/200, Iteration 142/250, Loss: 0.0439\n",
      "Epoch 144/200, Iteration 143/250, Loss: 0.0095\n",
      "Epoch 144/200, Iteration 144/250, Loss: 0.0113\n",
      "Epoch 144/200, Iteration 145/250, Loss: 0.0198\n",
      "Epoch 144/200, Iteration 146/250, Loss: 0.0254\n",
      "Epoch 144/200, Iteration 147/250, Loss: 0.0152\n",
      "Epoch 144/200, Iteration 148/250, Loss: 0.0542\n",
      "Epoch 144/200, Iteration 149/250, Loss: 0.0083\n",
      "Epoch 144/200, Iteration 150/250, Loss: 0.0185\n",
      "Epoch 144/200, Iteration 151/250, Loss: 0.0073\n",
      "Epoch 144/200, Iteration 152/250, Loss: 0.0152\n",
      "Epoch 144/200, Iteration 153/250, Loss: 0.0332\n",
      "Epoch 144/200, Iteration 154/250, Loss: 0.0229\n",
      "Epoch 144/200, Iteration 155/250, Loss: 0.0157\n",
      "Epoch 144/200, Iteration 156/250, Loss: 0.0152\n",
      "Epoch 144/200, Iteration 157/250, Loss: 0.0282\n",
      "Epoch 144/200, Iteration 158/250, Loss: 0.0186\n",
      "Epoch 144/200, Iteration 159/250, Loss: 0.0074\n",
      "Epoch 144/200, Iteration 160/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 161/250, Loss: 0.0127\n",
      "Epoch 144/200, Iteration 162/250, Loss: 0.0249\n",
      "Epoch 144/200, Iteration 163/250, Loss: 0.0264\n",
      "Epoch 144/200, Iteration 164/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 165/250, Loss: 0.0093\n",
      "Epoch 144/200, Iteration 166/250, Loss: 0.0180\n",
      "Epoch 144/200, Iteration 167/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 168/250, Loss: 0.0168\n",
      "Epoch 144/200, Iteration 169/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 170/250, Loss: 0.0104\n",
      "Epoch 144/200, Iteration 171/250, Loss: 0.0181\n",
      "Epoch 144/200, Iteration 172/250, Loss: 0.0170\n",
      "Epoch 144/200, Iteration 173/250, Loss: 0.0117\n",
      "Epoch 144/200, Iteration 174/250, Loss: 0.0286\n",
      "Epoch 144/200, Iteration 175/250, Loss: 0.0135\n",
      "Epoch 144/200, Iteration 176/250, Loss: 0.0089\n",
      "Epoch 144/200, Iteration 177/250, Loss: 0.0200\n",
      "Epoch 144/200, Iteration 178/250, Loss: 0.0134\n",
      "Epoch 144/200, Iteration 179/250, Loss: 0.0079\n",
      "Epoch 144/200, Iteration 180/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 181/250, Loss: 0.0146\n",
      "Epoch 144/200, Iteration 182/250, Loss: 0.0236\n",
      "Epoch 144/200, Iteration 183/250, Loss: 0.0234\n",
      "Epoch 144/200, Iteration 184/250, Loss: 0.0258\n",
      "Epoch 144/200, Iteration 185/250, Loss: 0.0226\n",
      "Epoch 144/200, Iteration 186/250, Loss: 0.0182\n",
      "Epoch 144/200, Iteration 187/250, Loss: 0.0089\n",
      "Epoch 144/200, Iteration 188/250, Loss: 0.0226\n",
      "Epoch 144/200, Iteration 189/250, Loss: 0.0149\n",
      "Epoch 144/200, Iteration 190/250, Loss: 0.0090\n",
      "Epoch 144/200, Iteration 191/250, Loss: 0.0076\n",
      "Epoch 144/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 144/200, Iteration 193/250, Loss: 0.0107\n",
      "Epoch 144/200, Iteration 194/250, Loss: 0.0106\n",
      "Epoch 144/200, Iteration 195/250, Loss: 0.0461\n",
      "Epoch 144/200, Iteration 196/250, Loss: 0.0177\n",
      "Epoch 144/200, Iteration 197/250, Loss: 0.0367\n",
      "Epoch 144/200, Iteration 198/250, Loss: 0.0197\n",
      "Epoch 144/200, Iteration 199/250, Loss: 0.0375\n",
      "Epoch 144/200, Iteration 200/250, Loss: 0.0131\n",
      "Epoch 144/200, Iteration 201/250, Loss: 0.0231\n",
      "Epoch 144/200, Iteration 202/250, Loss: 0.0088\n",
      "Epoch 144/200, Iteration 203/250, Loss: 0.0295\n",
      "Epoch 144/200, Iteration 204/250, Loss: 0.0234\n",
      "Epoch 144/200, Iteration 205/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 206/250, Loss: 0.0141\n",
      "Epoch 144/200, Iteration 207/250, Loss: 0.0253\n",
      "Epoch 144/200, Iteration 208/250, Loss: 0.0098\n",
      "Epoch 144/200, Iteration 209/250, Loss: 0.0103\n",
      "Epoch 144/200, Iteration 210/250, Loss: 0.0111\n",
      "Epoch 144/200, Iteration 211/250, Loss: 0.0122\n",
      "Epoch 144/200, Iteration 212/250, Loss: 0.0056\n",
      "Epoch 144/200, Iteration 213/250, Loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200, Iteration 214/250, Loss: 0.0246\n",
      "Epoch 144/200, Iteration 215/250, Loss: 0.0257\n",
      "Epoch 144/200, Iteration 216/250, Loss: 0.0102\n",
      "Epoch 144/200, Iteration 217/250, Loss: 0.0114\n",
      "Epoch 144/200, Iteration 218/250, Loss: 0.0108\n",
      "Epoch 144/200, Iteration 219/250, Loss: 0.0075\n",
      "Epoch 144/200, Iteration 220/250, Loss: 0.0266\n",
      "Epoch 144/200, Iteration 221/250, Loss: 0.0131\n",
      "Epoch 144/200, Iteration 222/250, Loss: 0.0301\n",
      "Epoch 144/200, Iteration 223/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 224/250, Loss: 0.0165\n",
      "Epoch 144/200, Iteration 225/250, Loss: 0.0130\n",
      "Epoch 144/200, Iteration 226/250, Loss: 0.0174\n",
      "Epoch 144/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 144/200, Iteration 228/250, Loss: 0.0122\n",
      "Epoch 144/200, Iteration 229/250, Loss: 0.0139\n",
      "Epoch 144/200, Iteration 230/250, Loss: 0.0195\n",
      "Epoch 144/200, Iteration 231/250, Loss: 0.0122\n",
      "Epoch 144/200, Iteration 232/250, Loss: 0.0078\n",
      "Epoch 144/200, Iteration 233/250, Loss: 0.0115\n",
      "Epoch 144/200, Iteration 234/250, Loss: 0.0168\n",
      "Epoch 144/200, Iteration 235/250, Loss: 0.0082\n",
      "Epoch 144/200, Iteration 236/250, Loss: 0.0255\n",
      "Epoch 144/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 144/200, Iteration 238/250, Loss: 0.0171\n",
      "Epoch 144/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 144/200, Iteration 240/250, Loss: 0.0140\n",
      "Epoch 144/200, Iteration 241/250, Loss: 0.0108\n",
      "Epoch 144/200, Iteration 242/250, Loss: 0.0143\n",
      "Epoch 144/200, Iteration 243/250, Loss: 0.0137\n",
      "Epoch 144/200, Iteration 244/250, Loss: 0.0138\n",
      "Epoch 144/200, Iteration 245/250, Loss: 0.0105\n",
      "Epoch 144/200, Iteration 246/250, Loss: 0.0153\n",
      "Epoch 144/200, Iteration 247/250, Loss: 0.0195\n",
      "Epoch 144/200, Iteration 248/250, Loss: 0.0112\n",
      "Epoch 144/200, Iteration 249/250, Loss: 0.0317\n",
      "Epoch 144/200, Iteration 250/250, Loss: 0.0150\n",
      "Train Error: \n",
      " Accuracy: 70.46%, Avg loss: 0.008410, MRE: 0.584087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.008732, MRE: 0.580854 \n",
      "\n",
      "Epoch 145/200, Iteration 1/250, Loss: 0.0127\n",
      "Epoch 145/200, Iteration 2/250, Loss: 0.0110\n",
      "Epoch 145/200, Iteration 3/250, Loss: 0.0093\n",
      "Epoch 145/200, Iteration 4/250, Loss: 0.0186\n",
      "Epoch 145/200, Iteration 5/250, Loss: 0.0116\n",
      "Epoch 145/200, Iteration 6/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 7/250, Loss: 0.0164\n",
      "Epoch 145/200, Iteration 8/250, Loss: 0.0146\n",
      "Epoch 145/200, Iteration 9/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 10/250, Loss: 0.0123\n",
      "Epoch 145/200, Iteration 11/250, Loss: 0.0181\n",
      "Epoch 145/200, Iteration 12/250, Loss: 0.0127\n",
      "Epoch 145/200, Iteration 13/250, Loss: 0.0203\n",
      "Epoch 145/200, Iteration 14/250, Loss: 0.0081\n",
      "Epoch 145/200, Iteration 15/250, Loss: 0.0200\n",
      "Epoch 145/200, Iteration 16/250, Loss: 0.0107\n",
      "Epoch 145/200, Iteration 17/250, Loss: 0.0182\n",
      "Epoch 145/200, Iteration 18/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 145/200, Iteration 20/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 21/250, Loss: 0.0152\n",
      "Epoch 145/200, Iteration 22/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 23/250, Loss: 0.0250\n",
      "Epoch 145/200, Iteration 24/250, Loss: 0.0371\n",
      "Epoch 145/200, Iteration 25/250, Loss: 0.0180\n",
      "Epoch 145/200, Iteration 26/250, Loss: 0.0129\n",
      "Epoch 145/200, Iteration 27/250, Loss: 0.0154\n",
      "Epoch 145/200, Iteration 28/250, Loss: 0.0149\n",
      "Epoch 145/200, Iteration 29/250, Loss: 0.0210\n",
      "Epoch 145/200, Iteration 30/250, Loss: 0.0159\n",
      "Epoch 145/200, Iteration 31/250, Loss: 0.0084\n",
      "Epoch 145/200, Iteration 32/250, Loss: 0.0133\n",
      "Epoch 145/200, Iteration 33/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 34/250, Loss: 0.0170\n",
      "Epoch 145/200, Iteration 35/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 36/250, Loss: 0.0074\n",
      "Epoch 145/200, Iteration 37/250, Loss: 0.0178\n",
      "Epoch 145/200, Iteration 38/250, Loss: 0.0218\n",
      "Epoch 145/200, Iteration 39/250, Loss: 0.0110\n",
      "Epoch 145/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 41/250, Loss: 0.0100\n",
      "Epoch 145/200, Iteration 42/250, Loss: 0.0124\n",
      "Epoch 145/200, Iteration 43/250, Loss: 0.0242\n",
      "Epoch 145/200, Iteration 44/250, Loss: 0.0119\n",
      "Epoch 145/200, Iteration 45/250, Loss: 0.0064\n",
      "Epoch 145/200, Iteration 46/250, Loss: 0.0170\n",
      "Epoch 145/200, Iteration 47/250, Loss: 0.0261\n",
      "Epoch 145/200, Iteration 48/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 145/200, Iteration 50/250, Loss: 0.0352\n",
      "Epoch 145/200, Iteration 51/250, Loss: 0.0222\n",
      "Epoch 145/200, Iteration 52/250, Loss: 0.0155\n",
      "Epoch 145/200, Iteration 53/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 54/250, Loss: 0.0091\n",
      "Epoch 145/200, Iteration 55/250, Loss: 0.0181\n",
      "Epoch 145/200, Iteration 56/250, Loss: 0.0131\n",
      "Epoch 145/200, Iteration 57/250, Loss: 0.0183\n",
      "Epoch 145/200, Iteration 58/250, Loss: 0.0109\n",
      "Epoch 145/200, Iteration 59/250, Loss: 0.0122\n",
      "Epoch 145/200, Iteration 60/250, Loss: 0.0212\n",
      "Epoch 145/200, Iteration 61/250, Loss: 0.0307\n",
      "Epoch 145/200, Iteration 62/250, Loss: 0.0117\n",
      "Epoch 145/200, Iteration 63/250, Loss: 0.0160\n",
      "Epoch 145/200, Iteration 64/250, Loss: 0.0141\n",
      "Epoch 145/200, Iteration 65/250, Loss: 0.0126\n",
      "Epoch 145/200, Iteration 66/250, Loss: 0.0250\n",
      "Epoch 145/200, Iteration 67/250, Loss: 0.0260\n",
      "Epoch 145/200, Iteration 68/250, Loss: 0.0131\n",
      "Epoch 145/200, Iteration 69/250, Loss: 0.0066\n",
      "Epoch 145/200, Iteration 70/250, Loss: 0.0176\n",
      "Epoch 145/200, Iteration 71/250, Loss: 0.0099\n",
      "Epoch 145/200, Iteration 72/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 73/250, Loss: 0.0175\n",
      "Epoch 145/200, Iteration 74/250, Loss: 0.0280\n",
      "Epoch 145/200, Iteration 75/250, Loss: 0.0135\n",
      "Epoch 145/200, Iteration 76/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 77/250, Loss: 0.0222\n",
      "Epoch 145/200, Iteration 78/250, Loss: 0.0084\n",
      "Epoch 145/200, Iteration 79/250, Loss: 0.0244\n",
      "Epoch 145/200, Iteration 80/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 81/250, Loss: 0.0171\n",
      "Epoch 145/200, Iteration 82/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 83/250, Loss: 0.0105\n",
      "Epoch 145/200, Iteration 84/250, Loss: 0.0135\n",
      "Epoch 145/200, Iteration 85/250, Loss: 0.0079\n",
      "Epoch 145/200, Iteration 86/250, Loss: 0.0154\n",
      "Epoch 145/200, Iteration 87/250, Loss: 0.0149\n",
      "Epoch 145/200, Iteration 88/250, Loss: 0.0243\n",
      "Epoch 145/200, Iteration 89/250, Loss: 0.0048\n",
      "Epoch 145/200, Iteration 90/250, Loss: 0.0101\n",
      "Epoch 145/200, Iteration 91/250, Loss: 0.0086\n",
      "Epoch 145/200, Iteration 92/250, Loss: 0.0280\n",
      "Epoch 145/200, Iteration 93/250, Loss: 0.0333\n",
      "Epoch 145/200, Iteration 94/250, Loss: 0.0074\n",
      "Epoch 145/200, Iteration 95/250, Loss: 0.0096\n",
      "Epoch 145/200, Iteration 96/250, Loss: 0.0193\n",
      "Epoch 145/200, Iteration 97/250, Loss: 0.0080\n",
      "Epoch 145/200, Iteration 98/250, Loss: 0.0175\n",
      "Epoch 145/200, Iteration 99/250, Loss: 0.0165\n",
      "Epoch 145/200, Iteration 100/250, Loss: 0.0132\n",
      "Epoch 145/200, Iteration 101/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 102/250, Loss: 0.0268\n",
      "Epoch 145/200, Iteration 103/250, Loss: 0.0199\n",
      "Epoch 145/200, Iteration 104/250, Loss: 0.0282\n",
      "Epoch 145/200, Iteration 105/250, Loss: 0.0113\n",
      "Epoch 145/200, Iteration 106/250, Loss: 0.0132\n",
      "Epoch 145/200, Iteration 107/250, Loss: 0.0102\n",
      "Epoch 145/200, Iteration 108/250, Loss: 0.0099\n",
      "Epoch 145/200, Iteration 109/250, Loss: 0.0183\n",
      "Epoch 145/200, Iteration 110/250, Loss: 0.0267\n",
      "Epoch 145/200, Iteration 111/250, Loss: 0.0282\n",
      "Epoch 145/200, Iteration 112/250, Loss: 0.0137\n",
      "Epoch 145/200, Iteration 113/250, Loss: 0.0204\n",
      "Epoch 145/200, Iteration 114/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 115/250, Loss: 0.0088\n",
      "Epoch 145/200, Iteration 116/250, Loss: 0.0129\n",
      "Epoch 145/200, Iteration 117/250, Loss: 0.0109\n",
      "Epoch 145/200, Iteration 118/250, Loss: 0.0255\n",
      "Epoch 145/200, Iteration 119/250, Loss: 0.0068\n",
      "Epoch 145/200, Iteration 120/250, Loss: 0.0054\n",
      "Epoch 145/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 145/200, Iteration 122/250, Loss: 0.0103\n",
      "Epoch 145/200, Iteration 123/250, Loss: 0.0353\n",
      "Epoch 145/200, Iteration 124/250, Loss: 0.0106\n",
      "Epoch 145/200, Iteration 125/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 126/250, Loss: 0.0058\n",
      "Epoch 145/200, Iteration 127/250, Loss: 0.0186\n",
      "Epoch 145/200, Iteration 128/250, Loss: 0.0118\n",
      "Epoch 145/200, Iteration 129/250, Loss: 0.0144\n",
      "Epoch 145/200, Iteration 130/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 131/250, Loss: 0.0156\n",
      "Epoch 145/200, Iteration 132/250, Loss: 0.0076\n",
      "Epoch 145/200, Iteration 133/250, Loss: 0.0079\n",
      "Epoch 145/200, Iteration 134/250, Loss: 0.0155\n",
      "Epoch 145/200, Iteration 135/250, Loss: 0.0189\n",
      "Epoch 145/200, Iteration 136/250, Loss: 0.0122\n",
      "Epoch 145/200, Iteration 137/250, Loss: 0.0244\n",
      "Epoch 145/200, Iteration 138/250, Loss: 0.0196\n",
      "Epoch 145/200, Iteration 139/250, Loss: 0.0136\n",
      "Epoch 145/200, Iteration 140/250, Loss: 0.0228\n",
      "Epoch 145/200, Iteration 141/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 142/250, Loss: 0.0157\n",
      "Epoch 145/200, Iteration 143/250, Loss: 0.0124\n",
      "Epoch 145/200, Iteration 144/250, Loss: 0.0146\n",
      "Epoch 145/200, Iteration 145/250, Loss: 0.0177\n",
      "Epoch 145/200, Iteration 146/250, Loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200, Iteration 147/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 148/250, Loss: 0.0123\n",
      "Epoch 145/200, Iteration 149/250, Loss: 0.0167\n",
      "Epoch 145/200, Iteration 150/250, Loss: 0.0213\n",
      "Epoch 145/200, Iteration 151/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 152/250, Loss: 0.0167\n",
      "Epoch 145/200, Iteration 153/250, Loss: 0.0151\n",
      "Epoch 145/200, Iteration 154/250, Loss: 0.0063\n",
      "Epoch 145/200, Iteration 155/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 156/250, Loss: 0.0101\n",
      "Epoch 145/200, Iteration 157/250, Loss: 0.0127\n",
      "Epoch 145/200, Iteration 158/250, Loss: 0.0144\n",
      "Epoch 145/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 145/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 145/200, Iteration 161/250, Loss: 0.0141\n",
      "Epoch 145/200, Iteration 162/250, Loss: 0.0125\n",
      "Epoch 145/200, Iteration 163/250, Loss: 0.0208\n",
      "Epoch 145/200, Iteration 164/250, Loss: 0.0148\n",
      "Epoch 145/200, Iteration 165/250, Loss: 0.0090\n",
      "Epoch 145/200, Iteration 166/250, Loss: 0.0108\n",
      "Epoch 145/200, Iteration 167/250, Loss: 0.0147\n",
      "Epoch 145/200, Iteration 168/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 145/200, Iteration 170/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 171/250, Loss: 0.0228\n",
      "Epoch 145/200, Iteration 172/250, Loss: 0.0145\n",
      "Epoch 145/200, Iteration 173/250, Loss: 0.0083\n",
      "Epoch 145/200, Iteration 174/250, Loss: 0.0095\n",
      "Epoch 145/200, Iteration 175/250, Loss: 0.0128\n",
      "Epoch 145/200, Iteration 176/250, Loss: 0.0393\n",
      "Epoch 145/200, Iteration 177/250, Loss: 0.0242\n",
      "Epoch 145/200, Iteration 178/250, Loss: 0.0359\n",
      "Epoch 145/200, Iteration 179/250, Loss: 0.0160\n",
      "Epoch 145/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 145/200, Iteration 181/250, Loss: 0.0101\n",
      "Epoch 145/200, Iteration 182/250, Loss: 0.0092\n",
      "Epoch 145/200, Iteration 183/250, Loss: 0.0173\n",
      "Epoch 145/200, Iteration 184/250, Loss: 0.0176\n",
      "Epoch 145/200, Iteration 185/250, Loss: 0.0137\n",
      "Epoch 145/200, Iteration 186/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 187/250, Loss: 0.0179\n",
      "Epoch 145/200, Iteration 188/250, Loss: 0.0150\n",
      "Epoch 145/200, Iteration 189/250, Loss: 0.0121\n",
      "Epoch 145/200, Iteration 190/250, Loss: 0.0165\n",
      "Epoch 145/200, Iteration 191/250, Loss: 0.0121\n",
      "Epoch 145/200, Iteration 192/250, Loss: 0.0098\n",
      "Epoch 145/200, Iteration 193/250, Loss: 0.0153\n",
      "Epoch 145/200, Iteration 194/250, Loss: 0.0141\n",
      "Epoch 145/200, Iteration 195/250, Loss: 0.0116\n",
      "Epoch 145/200, Iteration 196/250, Loss: 0.0143\n",
      "Epoch 145/200, Iteration 197/250, Loss: 0.0149\n",
      "Epoch 145/200, Iteration 198/250, Loss: 0.0117\n",
      "Epoch 145/200, Iteration 199/250, Loss: 0.0246\n",
      "Epoch 145/200, Iteration 200/250, Loss: 0.0121\n",
      "Epoch 145/200, Iteration 201/250, Loss: 0.0125\n",
      "Epoch 145/200, Iteration 202/250, Loss: 0.0089\n",
      "Epoch 145/200, Iteration 203/250, Loss: 0.0102\n",
      "Epoch 145/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 145/200, Iteration 205/250, Loss: 0.0109\n",
      "Epoch 145/200, Iteration 206/250, Loss: 0.0210\n",
      "Epoch 145/200, Iteration 207/250, Loss: 0.0204\n",
      "Epoch 145/200, Iteration 208/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 209/250, Loss: 0.0113\n",
      "Epoch 145/200, Iteration 210/250, Loss: 0.0161\n",
      "Epoch 145/200, Iteration 211/250, Loss: 0.0167\n",
      "Epoch 145/200, Iteration 212/250, Loss: 0.0120\n",
      "Epoch 145/200, Iteration 213/250, Loss: 0.0403\n",
      "Epoch 145/200, Iteration 214/250, Loss: 0.0193\n",
      "Epoch 145/200, Iteration 215/250, Loss: 0.0113\n",
      "Epoch 145/200, Iteration 216/250, Loss: 0.0075\n",
      "Epoch 145/200, Iteration 217/250, Loss: 0.0116\n",
      "Epoch 145/200, Iteration 218/250, Loss: 0.0130\n",
      "Epoch 145/200, Iteration 219/250, Loss: 0.0123\n",
      "Epoch 145/200, Iteration 220/250, Loss: 0.0119\n",
      "Epoch 145/200, Iteration 221/250, Loss: 0.0172\n",
      "Epoch 145/200, Iteration 222/250, Loss: 0.0117\n",
      "Epoch 145/200, Iteration 223/250, Loss: 0.0261\n",
      "Epoch 145/200, Iteration 224/250, Loss: 0.0118\n",
      "Epoch 145/200, Iteration 225/250, Loss: 0.0189\n",
      "Epoch 145/200, Iteration 226/250, Loss: 0.0151\n",
      "Epoch 145/200, Iteration 227/250, Loss: 0.0069\n",
      "Epoch 145/200, Iteration 228/250, Loss: 0.0081\n",
      "Epoch 145/200, Iteration 229/250, Loss: 0.0213\n",
      "Epoch 145/200, Iteration 230/250, Loss: 0.0148\n",
      "Epoch 145/200, Iteration 231/250, Loss: 0.0357\n",
      "Epoch 145/200, Iteration 232/250, Loss: 0.0111\n",
      "Epoch 145/200, Iteration 233/250, Loss: 0.0140\n",
      "Epoch 145/200, Iteration 234/250, Loss: 0.0069\n",
      "Epoch 145/200, Iteration 235/250, Loss: 0.0225\n",
      "Epoch 145/200, Iteration 236/250, Loss: 0.0248\n",
      "Epoch 145/200, Iteration 237/250, Loss: 0.0085\n",
      "Epoch 145/200, Iteration 238/250, Loss: 0.0073\n",
      "Epoch 145/200, Iteration 239/250, Loss: 0.0077\n",
      "Epoch 145/200, Iteration 240/250, Loss: 0.0160\n",
      "Epoch 145/200, Iteration 241/250, Loss: 0.0288\n",
      "Epoch 145/200, Iteration 242/250, Loss: 0.0269\n",
      "Epoch 145/200, Iteration 243/250, Loss: 0.0066\n",
      "Epoch 145/200, Iteration 244/250, Loss: 0.0097\n",
      "Epoch 145/200, Iteration 245/250, Loss: 0.0144\n",
      "Epoch 145/200, Iteration 246/250, Loss: 0.0070\n",
      "Epoch 145/200, Iteration 247/250, Loss: 0.0219\n",
      "Epoch 145/200, Iteration 248/250, Loss: 0.0238\n",
      "Epoch 145/200, Iteration 249/250, Loss: 0.0139\n",
      "Epoch 145/200, Iteration 250/250, Loss: 0.0087\n",
      "Train Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.006851, MRE: 0.437257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007385, MRE: 0.554866 \n",
      "\n",
      "Epoch 146/200, Iteration 1/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 2/250, Loss: 0.0139\n",
      "Epoch 146/200, Iteration 3/250, Loss: 0.0127\n",
      "Epoch 146/200, Iteration 4/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 5/250, Loss: 0.0298\n",
      "Epoch 146/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 146/200, Iteration 7/250, Loss: 0.0151\n",
      "Epoch 146/200, Iteration 8/250, Loss: 0.0097\n",
      "Epoch 146/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 146/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 146/200, Iteration 11/250, Loss: 0.0158\n",
      "Epoch 146/200, Iteration 12/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 13/250, Loss: 0.0129\n",
      "Epoch 146/200, Iteration 14/250, Loss: 0.0128\n",
      "Epoch 146/200, Iteration 15/250, Loss: 0.0473\n",
      "Epoch 146/200, Iteration 16/250, Loss: 0.0157\n",
      "Epoch 146/200, Iteration 17/250, Loss: 0.0297\n",
      "Epoch 146/200, Iteration 18/250, Loss: 0.0159\n",
      "Epoch 146/200, Iteration 19/250, Loss: 0.0240\n",
      "Epoch 146/200, Iteration 20/250, Loss: 0.0319\n",
      "Epoch 146/200, Iteration 21/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 22/250, Loss: 0.0267\n",
      "Epoch 146/200, Iteration 23/250, Loss: 0.0149\n",
      "Epoch 146/200, Iteration 24/250, Loss: 0.0206\n",
      "Epoch 146/200, Iteration 25/250, Loss: 0.0299\n",
      "Epoch 146/200, Iteration 26/250, Loss: 0.0113\n",
      "Epoch 146/200, Iteration 27/250, Loss: 0.0159\n",
      "Epoch 146/200, Iteration 28/250, Loss: 0.0115\n",
      "Epoch 146/200, Iteration 29/250, Loss: 0.0080\n",
      "Epoch 146/200, Iteration 30/250, Loss: 0.0225\n",
      "Epoch 146/200, Iteration 31/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 146/200, Iteration 33/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 34/250, Loss: 0.0093\n",
      "Epoch 146/200, Iteration 35/250, Loss: 0.0179\n",
      "Epoch 146/200, Iteration 36/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 37/250, Loss: 0.0190\n",
      "Epoch 146/200, Iteration 38/250, Loss: 0.0166\n",
      "Epoch 146/200, Iteration 39/250, Loss: 0.0159\n",
      "Epoch 146/200, Iteration 40/250, Loss: 0.0369\n",
      "Epoch 146/200, Iteration 41/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 42/250, Loss: 0.0218\n",
      "Epoch 146/200, Iteration 43/250, Loss: 0.0094\n",
      "Epoch 146/200, Iteration 44/250, Loss: 0.0259\n",
      "Epoch 146/200, Iteration 45/250, Loss: 0.0296\n",
      "Epoch 146/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 47/250, Loss: 0.0232\n",
      "Epoch 146/200, Iteration 48/250, Loss: 0.0143\n",
      "Epoch 146/200, Iteration 49/250, Loss: 0.0122\n",
      "Epoch 146/200, Iteration 50/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 51/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 52/250, Loss: 0.0331\n",
      "Epoch 146/200, Iteration 53/250, Loss: 0.0150\n",
      "Epoch 146/200, Iteration 54/250, Loss: 0.0102\n",
      "Epoch 146/200, Iteration 55/250, Loss: 0.0093\n",
      "Epoch 146/200, Iteration 56/250, Loss: 0.0083\n",
      "Epoch 146/200, Iteration 57/250, Loss: 0.0107\n",
      "Epoch 146/200, Iteration 58/250, Loss: 0.0119\n",
      "Epoch 146/200, Iteration 59/250, Loss: 0.0109\n",
      "Epoch 146/200, Iteration 60/250, Loss: 0.0101\n",
      "Epoch 146/200, Iteration 61/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 62/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 63/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 64/250, Loss: 0.0274\n",
      "Epoch 146/200, Iteration 65/250, Loss: 0.0176\n",
      "Epoch 146/200, Iteration 66/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 67/250, Loss: 0.0203\n",
      "Epoch 146/200, Iteration 68/250, Loss: 0.0124\n",
      "Epoch 146/200, Iteration 69/250, Loss: 0.0123\n",
      "Epoch 146/200, Iteration 70/250, Loss: 0.0105\n",
      "Epoch 146/200, Iteration 71/250, Loss: 0.0086\n",
      "Epoch 146/200, Iteration 72/250, Loss: 0.0357\n",
      "Epoch 146/200, Iteration 73/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 74/250, Loss: 0.0212\n",
      "Epoch 146/200, Iteration 75/250, Loss: 0.0129\n",
      "Epoch 146/200, Iteration 76/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 77/250, Loss: 0.0284\n",
      "Epoch 146/200, Iteration 78/250, Loss: 0.0087\n",
      "Epoch 146/200, Iteration 79/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 80/250, Loss: 0.0077\n",
      "Epoch 146/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 146/200, Iteration 82/250, Loss: 0.0243\n",
      "Epoch 146/200, Iteration 83/250, Loss: 0.0190\n",
      "Epoch 146/200, Iteration 84/250, Loss: 0.0188\n",
      "Epoch 146/200, Iteration 85/250, Loss: 0.0169\n",
      "Epoch 146/200, Iteration 86/250, Loss: 0.0115\n",
      "Epoch 146/200, Iteration 87/250, Loss: 0.0137\n",
      "Epoch 146/200, Iteration 88/250, Loss: 0.0134\n",
      "Epoch 146/200, Iteration 89/250, Loss: 0.0069\n",
      "Epoch 146/200, Iteration 90/250, Loss: 0.0132\n",
      "Epoch 146/200, Iteration 91/250, Loss: 0.0216\n",
      "Epoch 146/200, Iteration 92/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 93/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 94/250, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200, Iteration 95/250, Loss: 0.0124\n",
      "Epoch 146/200, Iteration 96/250, Loss: 0.0151\n",
      "Epoch 146/200, Iteration 97/250, Loss: 0.0201\n",
      "Epoch 146/200, Iteration 98/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 99/250, Loss: 0.0263\n",
      "Epoch 146/200, Iteration 100/250, Loss: 0.0204\n",
      "Epoch 146/200, Iteration 101/250, Loss: 0.0253\n",
      "Epoch 146/200, Iteration 102/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 103/250, Loss: 0.0121\n",
      "Epoch 146/200, Iteration 104/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 105/250, Loss: 0.0173\n",
      "Epoch 146/200, Iteration 106/250, Loss: 0.0098\n",
      "Epoch 146/200, Iteration 107/250, Loss: 0.0194\n",
      "Epoch 146/200, Iteration 108/250, Loss: 0.0128\n",
      "Epoch 146/200, Iteration 109/250, Loss: 0.0281\n",
      "Epoch 146/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 111/250, Loss: 0.0163\n",
      "Epoch 146/200, Iteration 112/250, Loss: 0.0174\n",
      "Epoch 146/200, Iteration 113/250, Loss: 0.0136\n",
      "Epoch 146/200, Iteration 114/250, Loss: 0.0103\n",
      "Epoch 146/200, Iteration 115/250, Loss: 0.0230\n",
      "Epoch 146/200, Iteration 116/250, Loss: 0.0149\n",
      "Epoch 146/200, Iteration 117/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 118/250, Loss: 0.0180\n",
      "Epoch 146/200, Iteration 119/250, Loss: 0.0125\n",
      "Epoch 146/200, Iteration 120/250, Loss: 0.0118\n",
      "Epoch 146/200, Iteration 121/250, Loss: 0.0192\n",
      "Epoch 146/200, Iteration 122/250, Loss: 0.0134\n",
      "Epoch 146/200, Iteration 123/250, Loss: 0.0230\n",
      "Epoch 146/200, Iteration 124/250, Loss: 0.0366\n",
      "Epoch 146/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 146/200, Iteration 126/250, Loss: 0.0158\n",
      "Epoch 146/200, Iteration 127/250, Loss: 0.0146\n",
      "Epoch 146/200, Iteration 128/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 129/250, Loss: 0.0105\n",
      "Epoch 146/200, Iteration 130/250, Loss: 0.0251\n",
      "Epoch 146/200, Iteration 131/250, Loss: 0.0131\n",
      "Epoch 146/200, Iteration 132/250, Loss: 0.0209\n",
      "Epoch 146/200, Iteration 133/250, Loss: 0.0212\n",
      "Epoch 146/200, Iteration 134/250, Loss: 0.0165\n",
      "Epoch 146/200, Iteration 135/250, Loss: 0.0108\n",
      "Epoch 146/200, Iteration 136/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 137/250, Loss: 0.0327\n",
      "Epoch 146/200, Iteration 138/250, Loss: 0.0100\n",
      "Epoch 146/200, Iteration 139/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 140/250, Loss: 0.0343\n",
      "Epoch 146/200, Iteration 141/250, Loss: 0.0102\n",
      "Epoch 146/200, Iteration 142/250, Loss: 0.0110\n",
      "Epoch 146/200, Iteration 143/250, Loss: 0.0381\n",
      "Epoch 146/200, Iteration 144/250, Loss: 0.0185\n",
      "Epoch 146/200, Iteration 145/250, Loss: 0.0126\n",
      "Epoch 146/200, Iteration 146/250, Loss: 0.0215\n",
      "Epoch 146/200, Iteration 147/250, Loss: 0.0234\n",
      "Epoch 146/200, Iteration 148/250, Loss: 0.0086\n",
      "Epoch 146/200, Iteration 149/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 150/250, Loss: 0.0213\n",
      "Epoch 146/200, Iteration 151/250, Loss: 0.0191\n",
      "Epoch 146/200, Iteration 152/250, Loss: 0.0173\n",
      "Epoch 146/200, Iteration 153/250, Loss: 0.0123\n",
      "Epoch 146/200, Iteration 154/250, Loss: 0.0411\n",
      "Epoch 146/200, Iteration 155/250, Loss: 0.0185\n",
      "Epoch 146/200, Iteration 156/250, Loss: 0.0100\n",
      "Epoch 146/200, Iteration 157/250, Loss: 0.0105\n",
      "Epoch 146/200, Iteration 158/250, Loss: 0.0224\n",
      "Epoch 146/200, Iteration 159/250, Loss: 0.0359\n",
      "Epoch 146/200, Iteration 160/250, Loss: 0.0269\n",
      "Epoch 146/200, Iteration 161/250, Loss: 0.0163\n",
      "Epoch 146/200, Iteration 162/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 163/250, Loss: 0.0129\n",
      "Epoch 146/200, Iteration 164/250, Loss: 0.0120\n",
      "Epoch 146/200, Iteration 165/250, Loss: 0.0187\n",
      "Epoch 146/200, Iteration 166/250, Loss: 0.0096\n",
      "Epoch 146/200, Iteration 167/250, Loss: 0.0149\n",
      "Epoch 146/200, Iteration 168/250, Loss: 0.0126\n",
      "Epoch 146/200, Iteration 169/250, Loss: 0.0286\n",
      "Epoch 146/200, Iteration 170/250, Loss: 0.0153\n",
      "Epoch 146/200, Iteration 171/250, Loss: 0.0111\n",
      "Epoch 146/200, Iteration 172/250, Loss: 0.0080\n",
      "Epoch 146/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 146/200, Iteration 174/250, Loss: 0.0130\n",
      "Epoch 146/200, Iteration 175/250, Loss: 0.0177\n",
      "Epoch 146/200, Iteration 176/250, Loss: 0.0078\n",
      "Epoch 146/200, Iteration 177/250, Loss: 0.0089\n",
      "Epoch 146/200, Iteration 178/250, Loss: 0.0231\n",
      "Epoch 146/200, Iteration 179/250, Loss: 0.0084\n",
      "Epoch 146/200, Iteration 180/250, Loss: 0.0112\n",
      "Epoch 146/200, Iteration 181/250, Loss: 0.0082\n",
      "Epoch 146/200, Iteration 182/250, Loss: 0.0060\n",
      "Epoch 146/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 184/250, Loss: 0.0137\n",
      "Epoch 146/200, Iteration 185/250, Loss: 0.0129\n",
      "Epoch 146/200, Iteration 186/250, Loss: 0.0101\n",
      "Epoch 146/200, Iteration 187/250, Loss: 0.0140\n",
      "Epoch 146/200, Iteration 188/250, Loss: 0.0115\n",
      "Epoch 146/200, Iteration 189/250, Loss: 0.0092\n",
      "Epoch 146/200, Iteration 190/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 146/200, Iteration 192/250, Loss: 0.0068\n",
      "Epoch 146/200, Iteration 193/250, Loss: 0.0174\n",
      "Epoch 146/200, Iteration 194/250, Loss: 0.0112\n",
      "Epoch 146/200, Iteration 195/250, Loss: 0.0135\n",
      "Epoch 146/200, Iteration 196/250, Loss: 0.0132\n",
      "Epoch 146/200, Iteration 197/250, Loss: 0.0193\n",
      "Epoch 146/200, Iteration 198/250, Loss: 0.0278\n",
      "Epoch 146/200, Iteration 199/250, Loss: 0.0192\n",
      "Epoch 146/200, Iteration 200/250, Loss: 0.0236\n",
      "Epoch 146/200, Iteration 201/250, Loss: 0.0272\n",
      "Epoch 146/200, Iteration 202/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 203/250, Loss: 0.0306\n",
      "Epoch 146/200, Iteration 204/250, Loss: 0.0140\n",
      "Epoch 146/200, Iteration 205/250, Loss: 0.0076\n",
      "Epoch 146/200, Iteration 206/250, Loss: 0.0137\n",
      "Epoch 146/200, Iteration 207/250, Loss: 0.0209\n",
      "Epoch 146/200, Iteration 208/250, Loss: 0.0134\n",
      "Epoch 146/200, Iteration 209/250, Loss: 0.0181\n",
      "Epoch 146/200, Iteration 210/250, Loss: 0.0119\n",
      "Epoch 146/200, Iteration 211/250, Loss: 0.0146\n",
      "Epoch 146/200, Iteration 212/250, Loss: 0.0281\n",
      "Epoch 146/200, Iteration 213/250, Loss: 0.0177\n",
      "Epoch 146/200, Iteration 214/250, Loss: 0.0099\n",
      "Epoch 146/200, Iteration 215/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 216/250, Loss: 0.0060\n",
      "Epoch 146/200, Iteration 217/250, Loss: 0.0307\n",
      "Epoch 146/200, Iteration 218/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 219/250, Loss: 0.0216\n",
      "Epoch 146/200, Iteration 220/250, Loss: 0.0199\n",
      "Epoch 146/200, Iteration 221/250, Loss: 0.0148\n",
      "Epoch 146/200, Iteration 222/250, Loss: 0.0090\n",
      "Epoch 146/200, Iteration 223/250, Loss: 0.0220\n",
      "Epoch 146/200, Iteration 224/250, Loss: 0.0081\n",
      "Epoch 146/200, Iteration 225/250, Loss: 0.0159\n",
      "Epoch 146/200, Iteration 226/250, Loss: 0.0249\n",
      "Epoch 146/200, Iteration 227/250, Loss: 0.0072\n",
      "Epoch 146/200, Iteration 228/250, Loss: 0.0171\n",
      "Epoch 146/200, Iteration 229/250, Loss: 0.0055\n",
      "Epoch 146/200, Iteration 230/250, Loss: 0.0271\n",
      "Epoch 146/200, Iteration 231/250, Loss: 0.0149\n",
      "Epoch 146/200, Iteration 232/250, Loss: 0.0091\n",
      "Epoch 146/200, Iteration 233/250, Loss: 0.0276\n",
      "Epoch 146/200, Iteration 234/250, Loss: 0.0177\n",
      "Epoch 146/200, Iteration 235/250, Loss: 0.0168\n",
      "Epoch 146/200, Iteration 236/250, Loss: 0.0085\n",
      "Epoch 146/200, Iteration 237/250, Loss: 0.0186\n",
      "Epoch 146/200, Iteration 238/250, Loss: 0.0203\n",
      "Epoch 146/200, Iteration 239/250, Loss: 0.0363\n",
      "Epoch 146/200, Iteration 240/250, Loss: 0.0117\n",
      "Epoch 146/200, Iteration 241/250, Loss: 0.0138\n",
      "Epoch 146/200, Iteration 242/250, Loss: 0.0077\n",
      "Epoch 146/200, Iteration 243/250, Loss: 0.0076\n",
      "Epoch 146/200, Iteration 244/250, Loss: 0.0233\n",
      "Epoch 146/200, Iteration 245/250, Loss: 0.0083\n",
      "Epoch 146/200, Iteration 246/250, Loss: 0.0087\n",
      "Epoch 146/200, Iteration 247/250, Loss: 0.0119\n",
      "Epoch 146/200, Iteration 248/250, Loss: 0.0132\n",
      "Epoch 146/200, Iteration 249/250, Loss: 0.0153\n",
      "Epoch 146/200, Iteration 250/250, Loss: 0.0100\n",
      "Train Error: \n",
      " Accuracy: 89.55%, Avg loss: 0.006658, MRE: 0.403499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.45%, Avg loss: 0.007293, MRE: 0.514242 \n",
      "\n",
      "Epoch 147/200, Iteration 1/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 2/250, Loss: 0.0091\n",
      "Epoch 147/200, Iteration 3/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 4/250, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 5/250, Loss: 0.0112\n",
      "Epoch 147/200, Iteration 6/250, Loss: 0.0067\n",
      "Epoch 147/200, Iteration 7/250, Loss: 0.0117\n",
      "Epoch 147/200, Iteration 8/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 9/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 10/250, Loss: 0.0219\n",
      "Epoch 147/200, Iteration 11/250, Loss: 0.0121\n",
      "Epoch 147/200, Iteration 12/250, Loss: 0.0078\n",
      "Epoch 147/200, Iteration 13/250, Loss: 0.0267\n",
      "Epoch 147/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 147/200, Iteration 15/250, Loss: 0.0175\n",
      "Epoch 147/200, Iteration 16/250, Loss: 0.0167\n",
      "Epoch 147/200, Iteration 17/250, Loss: 0.0119\n",
      "Epoch 147/200, Iteration 18/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 19/250, Loss: 0.0064\n",
      "Epoch 147/200, Iteration 20/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 21/250, Loss: 0.0123\n",
      "Epoch 147/200, Iteration 22/250, Loss: 0.0185\n",
      "Epoch 147/200, Iteration 23/250, Loss: 0.0146\n",
      "Epoch 147/200, Iteration 24/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 25/250, Loss: 0.0088\n",
      "Epoch 147/200, Iteration 26/250, Loss: 0.0206\n",
      "Epoch 147/200, Iteration 27/250, Loss: 0.0180\n",
      "Epoch 147/200, Iteration 28/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 29/250, Loss: 0.0185\n",
      "Epoch 147/200, Iteration 30/250, Loss: 0.0193\n",
      "Epoch 147/200, Iteration 31/250, Loss: 0.0155\n",
      "Epoch 147/200, Iteration 32/250, Loss: 0.0211\n",
      "Epoch 147/200, Iteration 33/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 34/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 35/250, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 36/250, Loss: 0.0241\n",
      "Epoch 147/200, Iteration 37/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 38/250, Loss: 0.0195\n",
      "Epoch 147/200, Iteration 39/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200, Iteration 40/250, Loss: 0.0128\n",
      "Epoch 147/200, Iteration 41/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 42/250, Loss: 0.0196\n",
      "Epoch 147/200, Iteration 43/250, Loss: 0.0110\n",
      "Epoch 147/200, Iteration 44/250, Loss: 0.0305\n",
      "Epoch 147/200, Iteration 45/250, Loss: 0.0077\n",
      "Epoch 147/200, Iteration 46/250, Loss: 0.0093\n",
      "Epoch 147/200, Iteration 47/250, Loss: 0.0168\n",
      "Epoch 147/200, Iteration 48/250, Loss: 0.0164\n",
      "Epoch 147/200, Iteration 49/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 50/250, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 51/250, Loss: 0.0205\n",
      "Epoch 147/200, Iteration 52/250, Loss: 0.0151\n",
      "Epoch 147/200, Iteration 53/250, Loss: 0.0080\n",
      "Epoch 147/200, Iteration 54/250, Loss: 0.0199\n",
      "Epoch 147/200, Iteration 55/250, Loss: 0.0171\n",
      "Epoch 147/200, Iteration 56/250, Loss: 0.0134\n",
      "Epoch 147/200, Iteration 57/250, Loss: 0.0072\n",
      "Epoch 147/200, Iteration 58/250, Loss: 0.0085\n",
      "Epoch 147/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 147/200, Iteration 60/250, Loss: 0.0149\n",
      "Epoch 147/200, Iteration 61/250, Loss: 0.0063\n",
      "Epoch 147/200, Iteration 62/250, Loss: 0.0117\n",
      "Epoch 147/200, Iteration 63/250, Loss: 0.0303\n",
      "Epoch 147/200, Iteration 64/250, Loss: 0.0177\n",
      "Epoch 147/200, Iteration 65/250, Loss: 0.0161\n",
      "Epoch 147/200, Iteration 66/250, Loss: 0.0099\n",
      "Epoch 147/200, Iteration 67/250, Loss: 0.0318\n",
      "Epoch 147/200, Iteration 68/250, Loss: 0.0191\n",
      "Epoch 147/200, Iteration 69/250, Loss: 0.0157\n",
      "Epoch 147/200, Iteration 70/250, Loss: 0.0110\n",
      "Epoch 147/200, Iteration 71/250, Loss: 0.0174\n",
      "Epoch 147/200, Iteration 72/250, Loss: 0.0078\n",
      "Epoch 147/200, Iteration 73/250, Loss: 0.0074\n",
      "Epoch 147/200, Iteration 74/250, Loss: 0.0308\n",
      "Epoch 147/200, Iteration 75/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 76/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 77/250, Loss: 0.0064\n",
      "Epoch 147/200, Iteration 78/250, Loss: 0.0176\n",
      "Epoch 147/200, Iteration 79/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 80/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 81/250, Loss: 0.0116\n",
      "Epoch 147/200, Iteration 82/250, Loss: 0.0168\n",
      "Epoch 147/200, Iteration 83/250, Loss: 0.0139\n",
      "Epoch 147/200, Iteration 84/250, Loss: 0.0121\n",
      "Epoch 147/200, Iteration 85/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 86/250, Loss: 0.0233\n",
      "Epoch 147/200, Iteration 87/250, Loss: 0.0143\n",
      "Epoch 147/200, Iteration 88/250, Loss: 0.0098\n",
      "Epoch 147/200, Iteration 89/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 90/250, Loss: 0.0110\n",
      "Epoch 147/200, Iteration 91/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 92/250, Loss: 0.0229\n",
      "Epoch 147/200, Iteration 93/250, Loss: 0.0081\n",
      "Epoch 147/200, Iteration 94/250, Loss: 0.0097\n",
      "Epoch 147/200, Iteration 95/250, Loss: 0.0345\n",
      "Epoch 147/200, Iteration 96/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 97/250, Loss: 0.0132\n",
      "Epoch 147/200, Iteration 98/250, Loss: 0.0076\n",
      "Epoch 147/200, Iteration 99/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 100/250, Loss: 0.0084\n",
      "Epoch 147/200, Iteration 101/250, Loss: 0.0147\n",
      "Epoch 147/200, Iteration 102/250, Loss: 0.0085\n",
      "Epoch 147/200, Iteration 103/250, Loss: 0.0142\n",
      "Epoch 147/200, Iteration 104/250, Loss: 0.0224\n",
      "Epoch 147/200, Iteration 105/250, Loss: 0.0077\n",
      "Epoch 147/200, Iteration 106/250, Loss: 0.0106\n",
      "Epoch 147/200, Iteration 107/250, Loss: 0.0094\n",
      "Epoch 147/200, Iteration 108/250, Loss: 0.0068\n",
      "Epoch 147/200, Iteration 109/250, Loss: 0.0106\n",
      "Epoch 147/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 111/250, Loss: 0.0126\n",
      "Epoch 147/200, Iteration 112/250, Loss: 0.0177\n",
      "Epoch 147/200, Iteration 113/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 114/250, Loss: 0.0064\n",
      "Epoch 147/200, Iteration 115/250, Loss: 0.0126\n",
      "Epoch 147/200, Iteration 116/250, Loss: 0.0235\n",
      "Epoch 147/200, Iteration 117/250, Loss: 0.0107\n",
      "Epoch 147/200, Iteration 118/250, Loss: 0.0123\n",
      "Epoch 147/200, Iteration 119/250, Loss: 0.0179\n",
      "Epoch 147/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 147/200, Iteration 121/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 122/250, Loss: 0.0214\n",
      "Epoch 147/200, Iteration 123/250, Loss: 0.0059\n",
      "Epoch 147/200, Iteration 124/250, Loss: 0.0145\n",
      "Epoch 147/200, Iteration 125/250, Loss: 0.0123\n",
      "Epoch 147/200, Iteration 126/250, Loss: 0.0236\n",
      "Epoch 147/200, Iteration 127/250, Loss: 0.0085\n",
      "Epoch 147/200, Iteration 128/250, Loss: 0.0187\n",
      "Epoch 147/200, Iteration 129/250, Loss: 0.0133\n",
      "Epoch 147/200, Iteration 130/250, Loss: 0.0177\n",
      "Epoch 147/200, Iteration 131/250, Loss: 0.0126\n",
      "Epoch 147/200, Iteration 132/250, Loss: 0.0176\n",
      "Epoch 147/200, Iteration 133/250, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 134/250, Loss: 0.0118\n",
      "Epoch 147/200, Iteration 135/250, Loss: 0.0091\n",
      "Epoch 147/200, Iteration 136/250, Loss: 0.0176\n",
      "Epoch 147/200, Iteration 137/250, Loss: 0.0093\n",
      "Epoch 147/200, Iteration 138/250, Loss: 0.0174\n",
      "Epoch 147/200, Iteration 139/250, Loss: 0.0195\n",
      "Epoch 147/200, Iteration 140/250, Loss: 0.0241\n",
      "Epoch 147/200, Iteration 141/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 142/250, Loss: 0.0112\n",
      "Epoch 147/200, Iteration 143/250, Loss: 0.0111\n",
      "Epoch 147/200, Iteration 144/250, Loss: 0.0122\n",
      "Epoch 147/200, Iteration 145/250, Loss: 0.0184\n",
      "Epoch 147/200, Iteration 146/250, Loss: 0.0138\n",
      "Epoch 147/200, Iteration 147/250, Loss: 0.0129\n",
      "Epoch 147/200, Iteration 148/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 149/250, Loss: 0.0098\n",
      "Epoch 147/200, Iteration 150/250, Loss: 0.0208\n",
      "Epoch 147/200, Iteration 151/250, Loss: 0.0293\n",
      "Epoch 147/200, Iteration 152/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 153/250, Loss: 0.0348\n",
      "Epoch 147/200, Iteration 154/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 155/250, Loss: 0.0105\n",
      "Epoch 147/200, Iteration 156/250, Loss: 0.0127\n",
      "Epoch 147/200, Iteration 157/250, Loss: 0.0071\n",
      "Epoch 147/200, Iteration 158/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 159/250, Loss: 0.0319\n",
      "Epoch 147/200, Iteration 160/250, Loss: 0.0194\n",
      "Epoch 147/200, Iteration 161/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 162/250, Loss: 0.0074\n",
      "Epoch 147/200, Iteration 163/250, Loss: 0.0096\n",
      "Epoch 147/200, Iteration 164/250, Loss: 0.0304\n",
      "Epoch 147/200, Iteration 165/250, Loss: 0.0100\n",
      "Epoch 147/200, Iteration 166/250, Loss: 0.0114\n",
      "Epoch 147/200, Iteration 167/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 168/250, Loss: 0.0074\n",
      "Epoch 147/200, Iteration 169/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 147/200, Iteration 171/250, Loss: 0.0241\n",
      "Epoch 147/200, Iteration 172/250, Loss: 0.0157\n",
      "Epoch 147/200, Iteration 173/250, Loss: 0.0216\n",
      "Epoch 147/200, Iteration 174/250, Loss: 0.0112\n",
      "Epoch 147/200, Iteration 175/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 176/250, Loss: 0.0166\n",
      "Epoch 147/200, Iteration 177/250, Loss: 0.0206\n",
      "Epoch 147/200, Iteration 178/250, Loss: 0.0095\n",
      "Epoch 147/200, Iteration 179/250, Loss: 0.0255\n",
      "Epoch 147/200, Iteration 180/250, Loss: 0.0186\n",
      "Epoch 147/200, Iteration 181/250, Loss: 0.0380\n",
      "Epoch 147/200, Iteration 182/250, Loss: 0.0078\n",
      "Epoch 147/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 147/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 147/200, Iteration 185/250, Loss: 0.0193\n",
      "Epoch 147/200, Iteration 186/250, Loss: 0.0109\n",
      "Epoch 147/200, Iteration 187/250, Loss: 0.0122\n",
      "Epoch 147/200, Iteration 188/250, Loss: 0.0283\n",
      "Epoch 147/200, Iteration 189/250, Loss: 0.0155\n",
      "Epoch 147/200, Iteration 190/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 191/250, Loss: 0.0173\n",
      "Epoch 147/200, Iteration 192/250, Loss: 0.0088\n",
      "Epoch 147/200, Iteration 193/250, Loss: 0.0070\n",
      "Epoch 147/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 147/200, Iteration 195/250, Loss: 0.0249\n",
      "Epoch 147/200, Iteration 196/250, Loss: 0.0315\n",
      "Epoch 147/200, Iteration 197/250, Loss: 0.0184\n",
      "Epoch 147/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 147/200, Iteration 199/250, Loss: 0.0072\n",
      "Epoch 147/200, Iteration 200/250, Loss: 0.0091\n",
      "Epoch 147/200, Iteration 201/250, Loss: 0.0179\n",
      "Epoch 147/200, Iteration 202/250, Loss: 0.0074\n",
      "Epoch 147/200, Iteration 203/250, Loss: 0.0116\n",
      "Epoch 147/200, Iteration 204/250, Loss: 0.0151\n",
      "Epoch 147/200, Iteration 205/250, Loss: 0.0122\n",
      "Epoch 147/200, Iteration 206/250, Loss: 0.0121\n",
      "Epoch 147/200, Iteration 207/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 208/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 209/250, Loss: 0.0189\n",
      "Epoch 147/200, Iteration 210/250, Loss: 0.0270\n",
      "Epoch 147/200, Iteration 211/250, Loss: 0.0132\n",
      "Epoch 147/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 147/200, Iteration 213/250, Loss: 0.0078\n",
      "Epoch 147/200, Iteration 214/250, Loss: 0.0067\n",
      "Epoch 147/200, Iteration 215/250, Loss: 0.0182\n",
      "Epoch 147/200, Iteration 216/250, Loss: 0.0390\n",
      "Epoch 147/200, Iteration 217/250, Loss: 0.0073\n",
      "Epoch 147/200, Iteration 218/250, Loss: 0.0121\n",
      "Epoch 147/200, Iteration 219/250, Loss: 0.0083\n",
      "Epoch 147/200, Iteration 220/250, Loss: 0.0070\n",
      "Epoch 147/200, Iteration 221/250, Loss: 0.0130\n",
      "Epoch 147/200, Iteration 222/250, Loss: 0.0152\n",
      "Epoch 147/200, Iteration 223/250, Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200, Iteration 224/250, Loss: 0.0188\n",
      "Epoch 147/200, Iteration 225/250, Loss: 0.0167\n",
      "Epoch 147/200, Iteration 226/250, Loss: 0.0156\n",
      "Epoch 147/200, Iteration 227/250, Loss: 0.0122\n",
      "Epoch 147/200, Iteration 228/250, Loss: 0.0109\n",
      "Epoch 147/200, Iteration 229/250, Loss: 0.0119\n",
      "Epoch 147/200, Iteration 230/250, Loss: 0.0242\n",
      "Epoch 147/200, Iteration 231/250, Loss: 0.0175\n",
      "Epoch 147/200, Iteration 232/250, Loss: 0.0090\n",
      "Epoch 147/200, Iteration 233/250, Loss: 0.0144\n",
      "Epoch 147/200, Iteration 234/250, Loss: 0.0183\n",
      "Epoch 147/200, Iteration 235/250, Loss: 0.0237\n",
      "Epoch 147/200, Iteration 236/250, Loss: 0.0082\n",
      "Epoch 147/200, Iteration 237/250, Loss: 0.0087\n",
      "Epoch 147/200, Iteration 238/250, Loss: 0.0084\n",
      "Epoch 147/200, Iteration 239/250, Loss: 0.0305\n",
      "Epoch 147/200, Iteration 240/250, Loss: 0.0216\n",
      "Epoch 147/200, Iteration 241/250, Loss: 0.0202\n",
      "Epoch 147/200, Iteration 242/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 243/250, Loss: 0.0124\n",
      "Epoch 147/200, Iteration 244/250, Loss: 0.0207\n",
      "Epoch 147/200, Iteration 245/250, Loss: 0.0178\n",
      "Epoch 147/200, Iteration 246/250, Loss: 0.0067\n",
      "Epoch 147/200, Iteration 247/250, Loss: 0.0195\n",
      "Epoch 147/200, Iteration 248/250, Loss: 0.0113\n",
      "Epoch 147/200, Iteration 249/250, Loss: 0.0221\n",
      "Epoch 147/200, Iteration 250/250, Loss: 0.0103\n",
      "Train Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.007057, MRE: 0.434933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.007560, MRE: 0.534541 \n",
      "\n",
      "Epoch 148/200, Iteration 1/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 2/250, Loss: 0.0152\n",
      "Epoch 148/200, Iteration 3/250, Loss: 0.0294\n",
      "Epoch 148/200, Iteration 4/250, Loss: 0.0195\n",
      "Epoch 148/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 7/250, Loss: 0.0184\n",
      "Epoch 148/200, Iteration 8/250, Loss: 0.0248\n",
      "Epoch 148/200, Iteration 9/250, Loss: 0.0116\n",
      "Epoch 148/200, Iteration 10/250, Loss: 0.0136\n",
      "Epoch 148/200, Iteration 11/250, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 12/250, Loss: 0.0169\n",
      "Epoch 148/200, Iteration 13/250, Loss: 0.0146\n",
      "Epoch 148/200, Iteration 14/250, Loss: 0.0227\n",
      "Epoch 148/200, Iteration 15/250, Loss: 0.0125\n",
      "Epoch 148/200, Iteration 16/250, Loss: 0.0095\n",
      "Epoch 148/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 18/250, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 19/250, Loss: 0.0194\n",
      "Epoch 148/200, Iteration 20/250, Loss: 0.0199\n",
      "Epoch 148/200, Iteration 21/250, Loss: 0.0268\n",
      "Epoch 148/200, Iteration 22/250, Loss: 0.0104\n",
      "Epoch 148/200, Iteration 23/250, Loss: 0.0208\n",
      "Epoch 148/200, Iteration 24/250, Loss: 0.0185\n",
      "Epoch 148/200, Iteration 25/250, Loss: 0.0109\n",
      "Epoch 148/200, Iteration 26/250, Loss: 0.0187\n",
      "Epoch 148/200, Iteration 27/250, Loss: 0.0271\n",
      "Epoch 148/200, Iteration 28/250, Loss: 0.0089\n",
      "Epoch 148/200, Iteration 29/250, Loss: 0.0083\n",
      "Epoch 148/200, Iteration 30/250, Loss: 0.0073\n",
      "Epoch 148/200, Iteration 31/250, Loss: 0.0192\n",
      "Epoch 148/200, Iteration 32/250, Loss: 0.0123\n",
      "Epoch 148/200, Iteration 33/250, Loss: 0.0137\n",
      "Epoch 148/200, Iteration 34/250, Loss: 0.0152\n",
      "Epoch 148/200, Iteration 35/250, Loss: 0.0143\n",
      "Epoch 148/200, Iteration 36/250, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 37/250, Loss: 0.0110\n",
      "Epoch 148/200, Iteration 38/250, Loss: 0.0141\n",
      "Epoch 148/200, Iteration 39/250, Loss: 0.0195\n",
      "Epoch 148/200, Iteration 40/250, Loss: 0.0073\n",
      "Epoch 148/200, Iteration 41/250, Loss: 0.0077\n",
      "Epoch 148/200, Iteration 42/250, Loss: 0.0207\n",
      "Epoch 148/200, Iteration 43/250, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 148/200, Iteration 45/250, Loss: 0.0083\n",
      "Epoch 148/200, Iteration 46/250, Loss: 0.0168\n",
      "Epoch 148/200, Iteration 47/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 48/250, Loss: 0.0219\n",
      "Epoch 148/200, Iteration 49/250, Loss: 0.0139\n",
      "Epoch 148/200, Iteration 50/250, Loss: 0.0143\n",
      "Epoch 148/200, Iteration 51/250, Loss: 0.0091\n",
      "Epoch 148/200, Iteration 52/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 53/250, Loss: 0.0072\n",
      "Epoch 148/200, Iteration 54/250, Loss: 0.0062\n",
      "Epoch 148/200, Iteration 55/250, Loss: 0.0198\n",
      "Epoch 148/200, Iteration 56/250, Loss: 0.0150\n",
      "Epoch 148/200, Iteration 57/250, Loss: 0.0148\n",
      "Epoch 148/200, Iteration 58/250, Loss: 0.0087\n",
      "Epoch 148/200, Iteration 59/250, Loss: 0.0234\n",
      "Epoch 148/200, Iteration 60/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 148/200, Iteration 62/250, Loss: 0.0086\n",
      "Epoch 148/200, Iteration 63/250, Loss: 0.0365\n",
      "Epoch 148/200, Iteration 64/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 65/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 66/250, Loss: 0.0189\n",
      "Epoch 148/200, Iteration 67/250, Loss: 0.0287\n",
      "Epoch 148/200, Iteration 68/250, Loss: 0.0168\n",
      "Epoch 148/200, Iteration 69/250, Loss: 0.0136\n",
      "Epoch 148/200, Iteration 70/250, Loss: 0.0400\n",
      "Epoch 148/200, Iteration 71/250, Loss: 0.0066\n",
      "Epoch 148/200, Iteration 72/250, Loss: 0.0136\n",
      "Epoch 148/200, Iteration 73/250, Loss: 0.0358\n",
      "Epoch 148/200, Iteration 74/250, Loss: 0.0195\n",
      "Epoch 148/200, Iteration 75/250, Loss: 0.0073\n",
      "Epoch 148/200, Iteration 76/250, Loss: 0.0100\n",
      "Epoch 148/200, Iteration 77/250, Loss: 0.0061\n",
      "Epoch 148/200, Iteration 78/250, Loss: 0.0138\n",
      "Epoch 148/200, Iteration 79/250, Loss: 0.0092\n",
      "Epoch 148/200, Iteration 80/250, Loss: 0.0146\n",
      "Epoch 148/200, Iteration 81/250, Loss: 0.0072\n",
      "Epoch 148/200, Iteration 82/250, Loss: 0.0090\n",
      "Epoch 148/200, Iteration 83/250, Loss: 0.0094\n",
      "Epoch 148/200, Iteration 84/250, Loss: 0.0203\n",
      "Epoch 148/200, Iteration 85/250, Loss: 0.0149\n",
      "Epoch 148/200, Iteration 86/250, Loss: 0.0092\n",
      "Epoch 148/200, Iteration 87/250, Loss: 0.0145\n",
      "Epoch 148/200, Iteration 88/250, Loss: 0.0121\n",
      "Epoch 148/200, Iteration 89/250, Loss: 0.0095\n",
      "Epoch 148/200, Iteration 90/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 91/250, Loss: 0.0096\n",
      "Epoch 148/200, Iteration 92/250, Loss: 0.0126\n",
      "Epoch 148/200, Iteration 93/250, Loss: 0.0252\n",
      "Epoch 148/200, Iteration 94/250, Loss: 0.0248\n",
      "Epoch 148/200, Iteration 95/250, Loss: 0.0149\n",
      "Epoch 148/200, Iteration 96/250, Loss: 0.0124\n",
      "Epoch 148/200, Iteration 97/250, Loss: 0.0202\n",
      "Epoch 148/200, Iteration 98/250, Loss: 0.0150\n",
      "Epoch 148/200, Iteration 99/250, Loss: 0.0206\n",
      "Epoch 148/200, Iteration 100/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 101/250, Loss: 0.0097\n",
      "Epoch 148/200, Iteration 102/250, Loss: 0.0289\n",
      "Epoch 148/200, Iteration 103/250, Loss: 0.0097\n",
      "Epoch 148/200, Iteration 104/250, Loss: 0.0076\n",
      "Epoch 148/200, Iteration 105/250, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 106/250, Loss: 0.0123\n",
      "Epoch 148/200, Iteration 107/250, Loss: 0.0117\n",
      "Epoch 148/200, Iteration 108/250, Loss: 0.0071\n",
      "Epoch 148/200, Iteration 109/250, Loss: 0.0099\n",
      "Epoch 148/200, Iteration 110/250, Loss: 0.0174\n",
      "Epoch 148/200, Iteration 111/250, Loss: 0.0110\n",
      "Epoch 148/200, Iteration 112/250, Loss: 0.0086\n",
      "Epoch 148/200, Iteration 113/250, Loss: 0.0175\n",
      "Epoch 148/200, Iteration 114/250, Loss: 0.0272\n",
      "Epoch 148/200, Iteration 115/250, Loss: 0.0130\n",
      "Epoch 148/200, Iteration 116/250, Loss: 0.0134\n",
      "Epoch 148/200, Iteration 117/250, Loss: 0.0092\n",
      "Epoch 148/200, Iteration 118/250, Loss: 0.0130\n",
      "Epoch 148/200, Iteration 119/250, Loss: 0.0167\n",
      "Epoch 148/200, Iteration 120/250, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 121/250, Loss: 0.0105\n",
      "Epoch 148/200, Iteration 122/250, Loss: 0.0208\n",
      "Epoch 148/200, Iteration 123/250, Loss: 0.0185\n",
      "Epoch 148/200, Iteration 124/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 125/250, Loss: 0.0104\n",
      "Epoch 148/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 148/200, Iteration 127/250, Loss: 0.0375\n",
      "Epoch 148/200, Iteration 128/250, Loss: 0.0143\n",
      "Epoch 148/200, Iteration 129/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 130/250, Loss: 0.0119\n",
      "Epoch 148/200, Iteration 131/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 132/250, Loss: 0.0235\n",
      "Epoch 148/200, Iteration 133/250, Loss: 0.0315\n",
      "Epoch 148/200, Iteration 134/250, Loss: 0.0257\n",
      "Epoch 148/200, Iteration 135/250, Loss: 0.0438\n",
      "Epoch 148/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 148/200, Iteration 137/250, Loss: 0.0146\n",
      "Epoch 148/200, Iteration 138/250, Loss: 0.0175\n",
      "Epoch 148/200, Iteration 139/250, Loss: 0.0163\n",
      "Epoch 148/200, Iteration 140/250, Loss: 0.0215\n",
      "Epoch 148/200, Iteration 141/250, Loss: 0.0075\n",
      "Epoch 148/200, Iteration 142/250, Loss: 0.0083\n",
      "Epoch 148/200, Iteration 143/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 144/250, Loss: 0.0320\n",
      "Epoch 148/200, Iteration 145/250, Loss: 0.0134\n",
      "Epoch 148/200, Iteration 146/250, Loss: 0.0101\n",
      "Epoch 148/200, Iteration 147/250, Loss: 0.0296\n",
      "Epoch 148/200, Iteration 148/250, Loss: 0.0089\n",
      "Epoch 148/200, Iteration 149/250, Loss: 0.0213\n",
      "Epoch 148/200, Iteration 150/250, Loss: 0.0176\n",
      "Epoch 148/200, Iteration 151/250, Loss: 0.0069\n",
      "Epoch 148/200, Iteration 152/250, Loss: 0.0183\n",
      "Epoch 148/200, Iteration 153/250, Loss: 0.0235\n",
      "Epoch 148/200, Iteration 154/250, Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200, Iteration 155/250, Loss: 0.0176\n",
      "Epoch 148/200, Iteration 156/250, Loss: 0.0149\n",
      "Epoch 148/200, Iteration 157/250, Loss: 0.0225\n",
      "Epoch 148/200, Iteration 158/250, Loss: 0.0117\n",
      "Epoch 148/200, Iteration 159/250, Loss: 0.0346\n",
      "Epoch 148/200, Iteration 160/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 161/250, Loss: 0.0205\n",
      "Epoch 148/200, Iteration 162/250, Loss: 0.0170\n",
      "Epoch 148/200, Iteration 163/250, Loss: 0.0268\n",
      "Epoch 148/200, Iteration 164/250, Loss: 0.0112\n",
      "Epoch 148/200, Iteration 165/250, Loss: 0.0171\n",
      "Epoch 148/200, Iteration 166/250, Loss: 0.0147\n",
      "Epoch 148/200, Iteration 167/250, Loss: 0.0077\n",
      "Epoch 148/200, Iteration 168/250, Loss: 0.0190\n",
      "Epoch 148/200, Iteration 169/250, Loss: 0.0093\n",
      "Epoch 148/200, Iteration 170/250, Loss: 0.0176\n",
      "Epoch 148/200, Iteration 171/250, Loss: 0.0155\n",
      "Epoch 148/200, Iteration 172/250, Loss: 0.0088\n",
      "Epoch 148/200, Iteration 173/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 174/250, Loss: 0.0122\n",
      "Epoch 148/200, Iteration 175/250, Loss: 0.0137\n",
      "Epoch 148/200, Iteration 176/250, Loss: 0.0227\n",
      "Epoch 148/200, Iteration 177/250, Loss: 0.0205\n",
      "Epoch 148/200, Iteration 178/250, Loss: 0.0169\n",
      "Epoch 148/200, Iteration 179/250, Loss: 0.0147\n",
      "Epoch 148/200, Iteration 180/250, Loss: 0.0443\n",
      "Epoch 148/200, Iteration 181/250, Loss: 0.0180\n",
      "Epoch 148/200, Iteration 182/250, Loss: 0.0222\n",
      "Epoch 148/200, Iteration 183/250, Loss: 0.0138\n",
      "Epoch 148/200, Iteration 184/250, Loss: 0.0320\n",
      "Epoch 148/200, Iteration 185/250, Loss: 0.0285\n",
      "Epoch 148/200, Iteration 186/250, Loss: 0.0139\n",
      "Epoch 148/200, Iteration 187/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 188/250, Loss: 0.0141\n",
      "Epoch 148/200, Iteration 189/250, Loss: 0.0111\n",
      "Epoch 148/200, Iteration 190/250, Loss: 0.0124\n",
      "Epoch 148/200, Iteration 191/250, Loss: 0.0236\n",
      "Epoch 148/200, Iteration 192/250, Loss: 0.0096\n",
      "Epoch 148/200, Iteration 193/250, Loss: 0.0291\n",
      "Epoch 148/200, Iteration 194/250, Loss: 0.0093\n",
      "Epoch 148/200, Iteration 195/250, Loss: 0.0102\n",
      "Epoch 148/200, Iteration 196/250, Loss: 0.0230\n",
      "Epoch 148/200, Iteration 197/250, Loss: 0.0174\n",
      "Epoch 148/200, Iteration 198/250, Loss: 0.0160\n",
      "Epoch 148/200, Iteration 199/250, Loss: 0.0080\n",
      "Epoch 148/200, Iteration 200/250, Loss: 0.0069\n",
      "Epoch 148/200, Iteration 201/250, Loss: 0.0235\n",
      "Epoch 148/200, Iteration 202/250, Loss: 0.0120\n",
      "Epoch 148/200, Iteration 203/250, Loss: 0.0098\n",
      "Epoch 148/200, Iteration 204/250, Loss: 0.0107\n",
      "Epoch 148/200, Iteration 205/250, Loss: 0.0082\n",
      "Epoch 148/200, Iteration 206/250, Loss: 0.0105\n",
      "Epoch 148/200, Iteration 207/250, Loss: 0.0177\n",
      "Epoch 148/200, Iteration 208/250, Loss: 0.0125\n",
      "Epoch 148/200, Iteration 209/250, Loss: 0.0214\n",
      "Epoch 148/200, Iteration 210/250, Loss: 0.0200\n",
      "Epoch 148/200, Iteration 211/250, Loss: 0.0170\n",
      "Epoch 148/200, Iteration 212/250, Loss: 0.0086\n",
      "Epoch 148/200, Iteration 213/250, Loss: 0.0158\n",
      "Epoch 148/200, Iteration 214/250, Loss: 0.0104\n",
      "Epoch 148/200, Iteration 215/250, Loss: 0.0145\n",
      "Epoch 148/200, Iteration 216/250, Loss: 0.0182\n",
      "Epoch 148/200, Iteration 217/250, Loss: 0.0135\n",
      "Epoch 148/200, Iteration 218/250, Loss: 0.0076\n",
      "Epoch 148/200, Iteration 219/250, Loss: 0.0185\n",
      "Epoch 148/200, Iteration 220/250, Loss: 0.0140\n",
      "Epoch 148/200, Iteration 221/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 222/250, Loss: 0.0085\n",
      "Epoch 148/200, Iteration 223/250, Loss: 0.0114\n",
      "Epoch 148/200, Iteration 224/250, Loss: 0.0360\n",
      "Epoch 148/200, Iteration 225/250, Loss: 0.0120\n",
      "Epoch 148/200, Iteration 226/250, Loss: 0.0071\n",
      "Epoch 148/200, Iteration 227/250, Loss: 0.0165\n",
      "Epoch 148/200, Iteration 228/250, Loss: 0.0106\n",
      "Epoch 148/200, Iteration 229/250, Loss: 0.0135\n",
      "Epoch 148/200, Iteration 230/250, Loss: 0.0233\n",
      "Epoch 148/200, Iteration 231/250, Loss: 0.0147\n",
      "Epoch 148/200, Iteration 232/250, Loss: 0.0104\n",
      "Epoch 148/200, Iteration 233/250, Loss: 0.0075\n",
      "Epoch 148/200, Iteration 234/250, Loss: 0.0090\n",
      "Epoch 148/200, Iteration 235/250, Loss: 0.0199\n",
      "Epoch 148/200, Iteration 236/250, Loss: 0.0150\n",
      "Epoch 148/200, Iteration 237/250, Loss: 0.0152\n",
      "Epoch 148/200, Iteration 238/250, Loss: 0.0118\n",
      "Epoch 148/200, Iteration 239/250, Loss: 0.0133\n",
      "Epoch 148/200, Iteration 240/250, Loss: 0.0233\n",
      "Epoch 148/200, Iteration 241/250, Loss: 0.0137\n",
      "Epoch 148/200, Iteration 242/250, Loss: 0.0156\n",
      "Epoch 148/200, Iteration 243/250, Loss: 0.0216\n",
      "Epoch 148/200, Iteration 244/250, Loss: 0.0357\n",
      "Epoch 148/200, Iteration 245/250, Loss: 0.0110\n",
      "Epoch 148/200, Iteration 246/250, Loss: 0.0169\n",
      "Epoch 148/200, Iteration 247/250, Loss: 0.0134\n",
      "Epoch 148/200, Iteration 248/250, Loss: 0.0138\n",
      "Epoch 148/200, Iteration 249/250, Loss: 0.0157\n",
      "Epoch 148/200, Iteration 250/250, Loss: 0.0126\n",
      "Train Error: \n",
      " Accuracy: 89.65%, Avg loss: 0.006819, MRE: 0.482674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.007400, MRE: 0.519237 \n",
      "\n",
      "Epoch 149/200, Iteration 1/250, Loss: 0.0135\n",
      "Epoch 149/200, Iteration 2/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 3/250, Loss: 0.0121\n",
      "Epoch 149/200, Iteration 4/250, Loss: 0.0261\n",
      "Epoch 149/200, Iteration 5/250, Loss: 0.0116\n",
      "Epoch 149/200, Iteration 6/250, Loss: 0.0096\n",
      "Epoch 149/200, Iteration 7/250, Loss: 0.0173\n",
      "Epoch 149/200, Iteration 8/250, Loss: 0.0138\n",
      "Epoch 149/200, Iteration 9/250, Loss: 0.0187\n",
      "Epoch 149/200, Iteration 10/250, Loss: 0.0187\n",
      "Epoch 149/200, Iteration 11/250, Loss: 0.0096\n",
      "Epoch 149/200, Iteration 12/250, Loss: 0.0144\n",
      "Epoch 149/200, Iteration 13/250, Loss: 0.0142\n",
      "Epoch 149/200, Iteration 14/250, Loss: 0.0105\n",
      "Epoch 149/200, Iteration 15/250, Loss: 0.0196\n",
      "Epoch 149/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 17/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 18/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 19/250, Loss: 0.0241\n",
      "Epoch 149/200, Iteration 20/250, Loss: 0.0100\n",
      "Epoch 149/200, Iteration 21/250, Loss: 0.0065\n",
      "Epoch 149/200, Iteration 22/250, Loss: 0.0160\n",
      "Epoch 149/200, Iteration 23/250, Loss: 0.0075\n",
      "Epoch 149/200, Iteration 24/250, Loss: 0.0144\n",
      "Epoch 149/200, Iteration 25/250, Loss: 0.0155\n",
      "Epoch 149/200, Iteration 26/250, Loss: 0.0360\n",
      "Epoch 149/200, Iteration 27/250, Loss: 0.0129\n",
      "Epoch 149/200, Iteration 28/250, Loss: 0.0282\n",
      "Epoch 149/200, Iteration 29/250, Loss: 0.0221\n",
      "Epoch 149/200, Iteration 30/250, Loss: 0.0229\n",
      "Epoch 149/200, Iteration 31/250, Loss: 0.0237\n",
      "Epoch 149/200, Iteration 32/250, Loss: 0.0157\n",
      "Epoch 149/200, Iteration 33/250, Loss: 0.0335\n",
      "Epoch 149/200, Iteration 34/250, Loss: 0.0205\n",
      "Epoch 149/200, Iteration 35/250, Loss: 0.0179\n",
      "Epoch 149/200, Iteration 36/250, Loss: 0.0122\n",
      "Epoch 149/200, Iteration 37/250, Loss: 0.0180\n",
      "Epoch 149/200, Iteration 38/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 39/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 40/250, Loss: 0.0188\n",
      "Epoch 149/200, Iteration 41/250, Loss: 0.0147\n",
      "Epoch 149/200, Iteration 42/250, Loss: 0.0078\n",
      "Epoch 149/200, Iteration 43/250, Loss: 0.0342\n",
      "Epoch 149/200, Iteration 44/250, Loss: 0.0174\n",
      "Epoch 149/200, Iteration 45/250, Loss: 0.0245\n",
      "Epoch 149/200, Iteration 46/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 47/250, Loss: 0.0056\n",
      "Epoch 149/200, Iteration 48/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 49/250, Loss: 0.0151\n",
      "Epoch 149/200, Iteration 50/250, Loss: 0.0233\n",
      "Epoch 149/200, Iteration 51/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 52/250, Loss: 0.0127\n",
      "Epoch 149/200, Iteration 53/250, Loss: 0.0141\n",
      "Epoch 149/200, Iteration 54/250, Loss: 0.0079\n",
      "Epoch 149/200, Iteration 55/250, Loss: 0.0164\n",
      "Epoch 149/200, Iteration 56/250, Loss: 0.0420\n",
      "Epoch 149/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 58/250, Loss: 0.0274\n",
      "Epoch 149/200, Iteration 59/250, Loss: 0.0195\n",
      "Epoch 149/200, Iteration 60/250, Loss: 0.0218\n",
      "Epoch 149/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 62/250, Loss: 0.0066\n",
      "Epoch 149/200, Iteration 63/250, Loss: 0.0335\n",
      "Epoch 149/200, Iteration 64/250, Loss: 0.0150\n",
      "Epoch 149/200, Iteration 65/250, Loss: 0.0225\n",
      "Epoch 149/200, Iteration 66/250, Loss: 0.0219\n",
      "Epoch 149/200, Iteration 67/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 68/250, Loss: 0.0177\n",
      "Epoch 149/200, Iteration 69/250, Loss: 0.0149\n",
      "Epoch 149/200, Iteration 70/250, Loss: 0.0176\n",
      "Epoch 149/200, Iteration 71/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 72/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 149/200, Iteration 74/250, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 75/250, Loss: 0.0181\n",
      "Epoch 149/200, Iteration 76/250, Loss: 0.0200\n",
      "Epoch 149/200, Iteration 77/250, Loss: 0.0165\n",
      "Epoch 149/200, Iteration 78/250, Loss: 0.0122\n",
      "Epoch 149/200, Iteration 79/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 80/250, Loss: 0.0089\n",
      "Epoch 149/200, Iteration 81/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 82/250, Loss: 0.0282\n",
      "Epoch 149/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 149/200, Iteration 84/250, Loss: 0.0122\n",
      "Epoch 149/200, Iteration 85/250, Loss: 0.0153\n",
      "Epoch 149/200, Iteration 86/250, Loss: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200, Iteration 87/250, Loss: 0.0218\n",
      "Epoch 149/200, Iteration 88/250, Loss: 0.0133\n",
      "Epoch 149/200, Iteration 89/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 90/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 91/250, Loss: 0.0150\n",
      "Epoch 149/200, Iteration 92/250, Loss: 0.0065\n",
      "Epoch 149/200, Iteration 93/250, Loss: 0.0267\n",
      "Epoch 149/200, Iteration 94/250, Loss: 0.0075\n",
      "Epoch 149/200, Iteration 95/250, Loss: 0.0191\n",
      "Epoch 149/200, Iteration 96/250, Loss: 0.0107\n",
      "Epoch 149/200, Iteration 97/250, Loss: 0.0143\n",
      "Epoch 149/200, Iteration 98/250, Loss: 0.0120\n",
      "Epoch 149/200, Iteration 99/250, Loss: 0.0187\n",
      "Epoch 149/200, Iteration 100/250, Loss: 0.0106\n",
      "Epoch 149/200, Iteration 101/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 102/250, Loss: 0.0102\n",
      "Epoch 149/200, Iteration 103/250, Loss: 0.0162\n",
      "Epoch 149/200, Iteration 104/250, Loss: 0.0123\n",
      "Epoch 149/200, Iteration 105/250, Loss: 0.0153\n",
      "Epoch 149/200, Iteration 106/250, Loss: 0.0204\n",
      "Epoch 149/200, Iteration 107/250, Loss: 0.0104\n",
      "Epoch 149/200, Iteration 108/250, Loss: 0.0203\n",
      "Epoch 149/200, Iteration 109/250, Loss: 0.0204\n",
      "Epoch 149/200, Iteration 110/250, Loss: 0.0274\n",
      "Epoch 149/200, Iteration 111/250, Loss: 0.0075\n",
      "Epoch 149/200, Iteration 112/250, Loss: 0.0190\n",
      "Epoch 149/200, Iteration 113/250, Loss: 0.0206\n",
      "Epoch 149/200, Iteration 114/250, Loss: 0.0104\n",
      "Epoch 149/200, Iteration 115/250, Loss: 0.0146\n",
      "Epoch 149/200, Iteration 116/250, Loss: 0.0061\n",
      "Epoch 149/200, Iteration 117/250, Loss: 0.0351\n",
      "Epoch 149/200, Iteration 118/250, Loss: 0.0235\n",
      "Epoch 149/200, Iteration 119/250, Loss: 0.0074\n",
      "Epoch 149/200, Iteration 120/250, Loss: 0.0085\n",
      "Epoch 149/200, Iteration 121/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 122/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 123/250, Loss: 0.0268\n",
      "Epoch 149/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 149/200, Iteration 125/250, Loss: 0.0102\n",
      "Epoch 149/200, Iteration 126/250, Loss: 0.0110\n",
      "Epoch 149/200, Iteration 127/250, Loss: 0.0080\n",
      "Epoch 149/200, Iteration 128/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 129/250, Loss: 0.0116\n",
      "Epoch 149/200, Iteration 130/250, Loss: 0.0125\n",
      "Epoch 149/200, Iteration 131/250, Loss: 0.0092\n",
      "Epoch 149/200, Iteration 132/250, Loss: 0.0058\n",
      "Epoch 149/200, Iteration 133/250, Loss: 0.0112\n",
      "Epoch 149/200, Iteration 134/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 135/250, Loss: 0.0206\n",
      "Epoch 149/200, Iteration 136/250, Loss: 0.0075\n",
      "Epoch 149/200, Iteration 137/250, Loss: 0.0346\n",
      "Epoch 149/200, Iteration 138/250, Loss: 0.0072\n",
      "Epoch 149/200, Iteration 139/250, Loss: 0.0271\n",
      "Epoch 149/200, Iteration 140/250, Loss: 0.0244\n",
      "Epoch 149/200, Iteration 141/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 142/250, Loss: 0.0255\n",
      "Epoch 149/200, Iteration 143/250, Loss: 0.0299\n",
      "Epoch 149/200, Iteration 144/250, Loss: 0.0164\n",
      "Epoch 149/200, Iteration 145/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 146/250, Loss: 0.0103\n",
      "Epoch 149/200, Iteration 147/250, Loss: 0.0171\n",
      "Epoch 149/200, Iteration 148/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 149/250, Loss: 0.0152\n",
      "Epoch 149/200, Iteration 150/250, Loss: 0.0066\n",
      "Epoch 149/200, Iteration 151/250, Loss: 0.0149\n",
      "Epoch 149/200, Iteration 152/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 153/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 154/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 155/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 156/250, Loss: 0.0096\n",
      "Epoch 149/200, Iteration 157/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 158/250, Loss: 0.0279\n",
      "Epoch 149/200, Iteration 159/250, Loss: 0.0168\n",
      "Epoch 149/200, Iteration 160/250, Loss: 0.0059\n",
      "Epoch 149/200, Iteration 161/250, Loss: 0.0135\n",
      "Epoch 149/200, Iteration 162/250, Loss: 0.0202\n",
      "Epoch 149/200, Iteration 163/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 164/250, Loss: 0.0130\n",
      "Epoch 149/200, Iteration 165/250, Loss: 0.0132\n",
      "Epoch 149/200, Iteration 166/250, Loss: 0.0182\n",
      "Epoch 149/200, Iteration 167/250, Loss: 0.0199\n",
      "Epoch 149/200, Iteration 168/250, Loss: 0.0111\n",
      "Epoch 149/200, Iteration 169/250, Loss: 0.0321\n",
      "Epoch 149/200, Iteration 170/250, Loss: 0.0069\n",
      "Epoch 149/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 172/250, Loss: 0.0154\n",
      "Epoch 149/200, Iteration 173/250, Loss: 0.0196\n",
      "Epoch 149/200, Iteration 174/250, Loss: 0.0347\n",
      "Epoch 149/200, Iteration 175/250, Loss: 0.0322\n",
      "Epoch 149/200, Iteration 176/250, Loss: 0.0173\n",
      "Epoch 149/200, Iteration 177/250, Loss: 0.0114\n",
      "Epoch 149/200, Iteration 178/250, Loss: 0.0132\n",
      "Epoch 149/200, Iteration 179/250, Loss: 0.0097\n",
      "Epoch 149/200, Iteration 180/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 181/250, Loss: 0.0325\n",
      "Epoch 149/200, Iteration 182/250, Loss: 0.0146\n",
      "Epoch 149/200, Iteration 183/250, Loss: 0.0149\n",
      "Epoch 149/200, Iteration 184/250, Loss: 0.0119\n",
      "Epoch 149/200, Iteration 185/250, Loss: 0.0093\n",
      "Epoch 149/200, Iteration 186/250, Loss: 0.0131\n",
      "Epoch 149/200, Iteration 187/250, Loss: 0.0121\n",
      "Epoch 149/200, Iteration 188/250, Loss: 0.0230\n",
      "Epoch 149/200, Iteration 189/250, Loss: 0.0107\n",
      "Epoch 149/200, Iteration 190/250, Loss: 0.0165\n",
      "Epoch 149/200, Iteration 191/250, Loss: 0.0099\n",
      "Epoch 149/200, Iteration 192/250, Loss: 0.0126\n",
      "Epoch 149/200, Iteration 193/250, Loss: 0.0122\n",
      "Epoch 149/200, Iteration 194/250, Loss: 0.0157\n",
      "Epoch 149/200, Iteration 195/250, Loss: 0.0121\n",
      "Epoch 149/200, Iteration 196/250, Loss: 0.0202\n",
      "Epoch 149/200, Iteration 197/250, Loss: 0.0136\n",
      "Epoch 149/200, Iteration 198/250, Loss: 0.0196\n",
      "Epoch 149/200, Iteration 199/250, Loss: 0.0127\n",
      "Epoch 149/200, Iteration 200/250, Loss: 0.0202\n",
      "Epoch 149/200, Iteration 201/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 202/250, Loss: 0.0067\n",
      "Epoch 149/200, Iteration 203/250, Loss: 0.0124\n",
      "Epoch 149/200, Iteration 204/250, Loss: 0.0094\n",
      "Epoch 149/200, Iteration 205/250, Loss: 0.0216\n",
      "Epoch 149/200, Iteration 206/250, Loss: 0.0238\n",
      "Epoch 149/200, Iteration 207/250, Loss: 0.0120\n",
      "Epoch 149/200, Iteration 208/250, Loss: 0.0229\n",
      "Epoch 149/200, Iteration 209/250, Loss: 0.0174\n",
      "Epoch 149/200, Iteration 210/250, Loss: 0.0177\n",
      "Epoch 149/200, Iteration 211/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 149/200, Iteration 213/250, Loss: 0.0121\n",
      "Epoch 149/200, Iteration 214/250, Loss: 0.0310\n",
      "Epoch 149/200, Iteration 215/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 216/250, Loss: 0.0339\n",
      "Epoch 149/200, Iteration 217/250, Loss: 0.0081\n",
      "Epoch 149/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 149/200, Iteration 219/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 220/250, Loss: 0.0229\n",
      "Epoch 149/200, Iteration 221/250, Loss: 0.0109\n",
      "Epoch 149/200, Iteration 222/250, Loss: 0.0076\n",
      "Epoch 149/200, Iteration 223/250, Loss: 0.0136\n",
      "Epoch 149/200, Iteration 224/250, Loss: 0.0092\n",
      "Epoch 149/200, Iteration 225/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 226/250, Loss: 0.0079\n",
      "Epoch 149/200, Iteration 227/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 228/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 229/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 230/250, Loss: 0.0092\n",
      "Epoch 149/200, Iteration 231/250, Loss: 0.0091\n",
      "Epoch 149/200, Iteration 232/250, Loss: 0.0291\n",
      "Epoch 149/200, Iteration 233/250, Loss: 0.0086\n",
      "Epoch 149/200, Iteration 234/250, Loss: 0.0392\n",
      "Epoch 149/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 149/200, Iteration 236/250, Loss: 0.0163\n",
      "Epoch 149/200, Iteration 237/250, Loss: 0.0108\n",
      "Epoch 149/200, Iteration 238/250, Loss: 0.0132\n",
      "Epoch 149/200, Iteration 239/250, Loss: 0.0082\n",
      "Epoch 149/200, Iteration 240/250, Loss: 0.0090\n",
      "Epoch 149/200, Iteration 241/250, Loss: 0.0093\n",
      "Epoch 149/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 149/200, Iteration 243/250, Loss: 0.0113\n",
      "Epoch 149/200, Iteration 244/250, Loss: 0.0096\n",
      "Epoch 149/200, Iteration 245/250, Loss: 0.0072\n",
      "Epoch 149/200, Iteration 246/250, Loss: 0.0211\n",
      "Epoch 149/200, Iteration 247/250, Loss: 0.0223\n",
      "Epoch 149/200, Iteration 248/250, Loss: 0.0168\n",
      "Epoch 149/200, Iteration 249/250, Loss: 0.0095\n",
      "Epoch 149/200, Iteration 250/250, Loss: 0.0266\n",
      "Train Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006811, MRE: 0.450093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.007359, MRE: 0.537376 \n",
      "\n",
      "Epoch 150/200, Iteration 1/250, Loss: 0.0120\n",
      "Epoch 150/200, Iteration 2/250, Loss: 0.0176\n",
      "Epoch 150/200, Iteration 3/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 4/250, Loss: 0.0114\n",
      "Epoch 150/200, Iteration 5/250, Loss: 0.0138\n",
      "Epoch 150/200, Iteration 6/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 7/250, Loss: 0.0266\n",
      "Epoch 150/200, Iteration 8/250, Loss: 0.0075\n",
      "Epoch 150/200, Iteration 9/250, Loss: 0.0101\n",
      "Epoch 150/200, Iteration 10/250, Loss: 0.0144\n",
      "Epoch 150/200, Iteration 11/250, Loss: 0.0269\n",
      "Epoch 150/200, Iteration 12/250, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200, Iteration 13/250, Loss: 0.0174\n",
      "Epoch 150/200, Iteration 14/250, Loss: 0.0174\n",
      "Epoch 150/200, Iteration 15/250, Loss: 0.0339\n",
      "Epoch 150/200, Iteration 16/250, Loss: 0.0330\n",
      "Epoch 150/200, Iteration 17/250, Loss: 0.0186\n",
      "Epoch 150/200, Iteration 18/250, Loss: 0.0182\n",
      "Epoch 150/200, Iteration 19/250, Loss: 0.0124\n",
      "Epoch 150/200, Iteration 20/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 21/250, Loss: 0.0166\n",
      "Epoch 150/200, Iteration 22/250, Loss: 0.0193\n",
      "Epoch 150/200, Iteration 23/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 24/250, Loss: 0.0146\n",
      "Epoch 150/200, Iteration 25/250, Loss: 0.0098\n",
      "Epoch 150/200, Iteration 26/250, Loss: 0.0068\n",
      "Epoch 150/200, Iteration 27/250, Loss: 0.0127\n",
      "Epoch 150/200, Iteration 28/250, Loss: 0.0202\n",
      "Epoch 150/200, Iteration 29/250, Loss: 0.0091\n",
      "Epoch 150/200, Iteration 30/250, Loss: 0.0118\n",
      "Epoch 150/200, Iteration 31/250, Loss: 0.0066\n",
      "Epoch 150/200, Iteration 32/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 33/250, Loss: 0.0075\n",
      "Epoch 150/200, Iteration 34/250, Loss: 0.0102\n",
      "Epoch 150/200, Iteration 35/250, Loss: 0.0127\n",
      "Epoch 150/200, Iteration 36/250, Loss: 0.0144\n",
      "Epoch 150/200, Iteration 37/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 38/250, Loss: 0.0152\n",
      "Epoch 150/200, Iteration 39/250, Loss: 0.0142\n",
      "Epoch 150/200, Iteration 40/250, Loss: 0.0095\n",
      "Epoch 150/200, Iteration 41/250, Loss: 0.0197\n",
      "Epoch 150/200, Iteration 42/250, Loss: 0.0240\n",
      "Epoch 150/200, Iteration 43/250, Loss: 0.0071\n",
      "Epoch 150/200, Iteration 44/250, Loss: 0.0300\n",
      "Epoch 150/200, Iteration 45/250, Loss: 0.0068\n",
      "Epoch 150/200, Iteration 46/250, Loss: 0.0334\n",
      "Epoch 150/200, Iteration 47/250, Loss: 0.0117\n",
      "Epoch 150/200, Iteration 48/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 49/250, Loss: 0.0108\n",
      "Epoch 150/200, Iteration 50/250, Loss: 0.0189\n",
      "Epoch 150/200, Iteration 51/250, Loss: 0.0144\n",
      "Epoch 150/200, Iteration 52/250, Loss: 0.0180\n",
      "Epoch 150/200, Iteration 53/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 54/250, Loss: 0.0104\n",
      "Epoch 150/200, Iteration 55/250, Loss: 0.0206\n",
      "Epoch 150/200, Iteration 56/250, Loss: 0.0106\n",
      "Epoch 150/200, Iteration 57/250, Loss: 0.0143\n",
      "Epoch 150/200, Iteration 58/250, Loss: 0.0146\n",
      "Epoch 150/200, Iteration 59/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 60/250, Loss: 0.0110\n",
      "Epoch 150/200, Iteration 61/250, Loss: 0.0196\n",
      "Epoch 150/200, Iteration 62/250, Loss: 0.0101\n",
      "Epoch 150/200, Iteration 63/250, Loss: 0.0103\n",
      "Epoch 150/200, Iteration 64/250, Loss: 0.0306\n",
      "Epoch 150/200, Iteration 65/250, Loss: 0.0107\n",
      "Epoch 150/200, Iteration 66/250, Loss: 0.0344\n",
      "Epoch 150/200, Iteration 67/250, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 68/250, Loss: 0.0354\n",
      "Epoch 150/200, Iteration 69/250, Loss: 0.0191\n",
      "Epoch 150/200, Iteration 70/250, Loss: 0.0113\n",
      "Epoch 150/200, Iteration 71/250, Loss: 0.0138\n",
      "Epoch 150/200, Iteration 72/250, Loss: 0.0165\n",
      "Epoch 150/200, Iteration 73/250, Loss: 0.0123\n",
      "Epoch 150/200, Iteration 74/250, Loss: 0.0337\n",
      "Epoch 150/200, Iteration 75/250, Loss: 0.0096\n",
      "Epoch 150/200, Iteration 76/250, Loss: 0.0153\n",
      "Epoch 150/200, Iteration 77/250, Loss: 0.0174\n",
      "Epoch 150/200, Iteration 78/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 79/250, Loss: 0.0068\n",
      "Epoch 150/200, Iteration 80/250, Loss: 0.0168\n",
      "Epoch 150/200, Iteration 81/250, Loss: 0.0095\n",
      "Epoch 150/200, Iteration 82/250, Loss: 0.0192\n",
      "Epoch 150/200, Iteration 83/250, Loss: 0.0534\n",
      "Epoch 150/200, Iteration 84/250, Loss: 0.0266\n",
      "Epoch 150/200, Iteration 85/250, Loss: 0.0104\n",
      "Epoch 150/200, Iteration 86/250, Loss: 0.0076\n",
      "Epoch 150/200, Iteration 87/250, Loss: 0.0299\n",
      "Epoch 150/200, Iteration 88/250, Loss: 0.0202\n",
      "Epoch 150/200, Iteration 89/250, Loss: 0.0300\n",
      "Epoch 150/200, Iteration 90/250, Loss: 0.0068\n",
      "Epoch 150/200, Iteration 91/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 92/250, Loss: 0.0082\n",
      "Epoch 150/200, Iteration 93/250, Loss: 0.0087\n",
      "Epoch 150/200, Iteration 94/250, Loss: 0.0150\n",
      "Epoch 150/200, Iteration 95/250, Loss: 0.0147\n",
      "Epoch 150/200, Iteration 96/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 97/250, Loss: 0.0106\n",
      "Epoch 150/200, Iteration 98/250, Loss: 0.0065\n",
      "Epoch 150/200, Iteration 99/250, Loss: 0.0097\n",
      "Epoch 150/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 150/200, Iteration 101/250, Loss: 0.0182\n",
      "Epoch 150/200, Iteration 102/250, Loss: 0.0164\n",
      "Epoch 150/200, Iteration 103/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 104/250, Loss: 0.0356\n",
      "Epoch 150/200, Iteration 105/250, Loss: 0.0148\n",
      "Epoch 150/200, Iteration 106/250, Loss: 0.0276\n",
      "Epoch 150/200, Iteration 107/250, Loss: 0.0115\n",
      "Epoch 150/200, Iteration 108/250, Loss: 0.0084\n",
      "Epoch 150/200, Iteration 109/250, Loss: 0.0477\n",
      "Epoch 150/200, Iteration 110/250, Loss: 0.0159\n",
      "Epoch 150/200, Iteration 111/250, Loss: 0.0115\n",
      "Epoch 150/200, Iteration 112/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 113/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 114/250, Loss: 0.0094\n",
      "Epoch 150/200, Iteration 115/250, Loss: 0.0157\n",
      "Epoch 150/200, Iteration 116/250, Loss: 0.0228\n",
      "Epoch 150/200, Iteration 117/250, Loss: 0.0218\n",
      "Epoch 150/200, Iteration 118/250, Loss: 0.0201\n",
      "Epoch 150/200, Iteration 119/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 120/250, Loss: 0.0095\n",
      "Epoch 150/200, Iteration 121/250, Loss: 0.0073\n",
      "Epoch 150/200, Iteration 122/250, Loss: 0.0346\n",
      "Epoch 150/200, Iteration 123/250, Loss: 0.0117\n",
      "Epoch 150/200, Iteration 124/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 125/250, Loss: 0.0489\n",
      "Epoch 150/200, Iteration 126/250, Loss: 0.0096\n",
      "Epoch 150/200, Iteration 127/250, Loss: 0.0087\n",
      "Epoch 150/200, Iteration 128/250, Loss: 0.0070\n",
      "Epoch 150/200, Iteration 129/250, Loss: 0.0126\n",
      "Epoch 150/200, Iteration 130/250, Loss: 0.0103\n",
      "Epoch 150/200, Iteration 131/250, Loss: 0.0160\n",
      "Epoch 150/200, Iteration 132/250, Loss: 0.0060\n",
      "Epoch 150/200, Iteration 133/250, Loss: 0.0124\n",
      "Epoch 150/200, Iteration 134/250, Loss: 0.0120\n",
      "Epoch 150/200, Iteration 135/250, Loss: 0.0145\n",
      "Epoch 150/200, Iteration 136/250, Loss: 0.0080\n",
      "Epoch 150/200, Iteration 137/250, Loss: 0.0121\n",
      "Epoch 150/200, Iteration 138/250, Loss: 0.0140\n",
      "Epoch 150/200, Iteration 139/250, Loss: 0.0091\n",
      "Epoch 150/200, Iteration 140/250, Loss: 0.0145\n",
      "Epoch 150/200, Iteration 141/250, Loss: 0.0084\n",
      "Epoch 150/200, Iteration 142/250, Loss: 0.0131\n",
      "Epoch 150/200, Iteration 143/250, Loss: 0.0431\n",
      "Epoch 150/200, Iteration 144/250, Loss: 0.0182\n",
      "Epoch 150/200, Iteration 145/250, Loss: 0.0074\n",
      "Epoch 150/200, Iteration 146/250, Loss: 0.0116\n",
      "Epoch 150/200, Iteration 147/250, Loss: 0.0175\n",
      "Epoch 150/200, Iteration 148/250, Loss: 0.0146\n",
      "Epoch 150/200, Iteration 149/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 150/250, Loss: 0.0246\n",
      "Epoch 150/200, Iteration 151/250, Loss: 0.0111\n",
      "Epoch 150/200, Iteration 152/250, Loss: 0.0155\n",
      "Epoch 150/200, Iteration 153/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 154/250, Loss: 0.0063\n",
      "Epoch 150/200, Iteration 155/250, Loss: 0.0063\n",
      "Epoch 150/200, Iteration 156/250, Loss: 0.0195\n",
      "Epoch 150/200, Iteration 157/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 158/250, Loss: 0.0103\n",
      "Epoch 150/200, Iteration 159/250, Loss: 0.0225\n",
      "Epoch 150/200, Iteration 160/250, Loss: 0.0102\n",
      "Epoch 150/200, Iteration 161/250, Loss: 0.0078\n",
      "Epoch 150/200, Iteration 162/250, Loss: 0.0437\n",
      "Epoch 150/200, Iteration 163/250, Loss: 0.0079\n",
      "Epoch 150/200, Iteration 164/250, Loss: 0.0128\n",
      "Epoch 150/200, Iteration 165/250, Loss: 0.0116\n",
      "Epoch 150/200, Iteration 166/250, Loss: 0.0155\n",
      "Epoch 150/200, Iteration 167/250, Loss: 0.0090\n",
      "Epoch 150/200, Iteration 168/250, Loss: 0.0200\n",
      "Epoch 150/200, Iteration 169/250, Loss: 0.0181\n",
      "Epoch 150/200, Iteration 170/250, Loss: 0.0084\n",
      "Epoch 150/200, Iteration 171/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 172/250, Loss: 0.0464\n",
      "Epoch 150/200, Iteration 173/250, Loss: 0.0061\n",
      "Epoch 150/200, Iteration 174/250, Loss: 0.0280\n",
      "Epoch 150/200, Iteration 175/250, Loss: 0.0111\n",
      "Epoch 150/200, Iteration 176/250, Loss: 0.0167\n",
      "Epoch 150/200, Iteration 177/250, Loss: 0.0108\n",
      "Epoch 150/200, Iteration 178/250, Loss: 0.0078\n",
      "Epoch 150/200, Iteration 179/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 150/200, Iteration 181/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 182/250, Loss: 0.0085\n",
      "Epoch 150/200, Iteration 183/250, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 184/250, Loss: 0.0263\n",
      "Epoch 150/200, Iteration 185/250, Loss: 0.0175\n",
      "Epoch 150/200, Iteration 186/250, Loss: 0.0203\n",
      "Epoch 150/200, Iteration 187/250, Loss: 0.0099\n",
      "Epoch 150/200, Iteration 188/250, Loss: 0.0139\n",
      "Epoch 150/200, Iteration 189/250, Loss: 0.0111\n",
      "Epoch 150/200, Iteration 190/250, Loss: 0.0081\n",
      "Epoch 150/200, Iteration 191/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 192/250, Loss: 0.0149\n",
      "Epoch 150/200, Iteration 193/250, Loss: 0.0058\n",
      "Epoch 150/200, Iteration 194/250, Loss: 0.0392\n",
      "Epoch 150/200, Iteration 195/250, Loss: 0.0141\n",
      "Epoch 150/200, Iteration 196/250, Loss: 0.0142\n",
      "Epoch 150/200, Iteration 197/250, Loss: 0.0147\n",
      "Epoch 150/200, Iteration 198/250, Loss: 0.0101\n",
      "Epoch 150/200, Iteration 199/250, Loss: 0.0092\n",
      "Epoch 150/200, Iteration 200/250, Loss: 0.0202\n",
      "Epoch 150/200, Iteration 201/250, Loss: 0.0120\n",
      "Epoch 150/200, Iteration 202/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 203/250, Loss: 0.0119\n",
      "Epoch 150/200, Iteration 204/250, Loss: 0.0198\n",
      "Epoch 150/200, Iteration 205/250, Loss: 0.0117\n",
      "Epoch 150/200, Iteration 206/250, Loss: 0.0159\n",
      "Epoch 150/200, Iteration 207/250, Loss: 0.0234\n",
      "Epoch 150/200, Iteration 208/250, Loss: 0.0088\n",
      "Epoch 150/200, Iteration 209/250, Loss: 0.0169\n",
      "Epoch 150/200, Iteration 210/250, Loss: 0.0326\n",
      "Epoch 150/200, Iteration 211/250, Loss: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200, Iteration 212/250, Loss: 0.0098\n",
      "Epoch 150/200, Iteration 213/250, Loss: 0.0168\n",
      "Epoch 150/200, Iteration 214/250, Loss: 0.0304\n",
      "Epoch 150/200, Iteration 215/250, Loss: 0.0151\n",
      "Epoch 150/200, Iteration 216/250, Loss: 0.0193\n",
      "Epoch 150/200, Iteration 217/250, Loss: 0.0078\n",
      "Epoch 150/200, Iteration 218/250, Loss: 0.0257\n",
      "Epoch 150/200, Iteration 219/250, Loss: 0.0172\n",
      "Epoch 150/200, Iteration 220/250, Loss: 0.0101\n",
      "Epoch 150/200, Iteration 221/250, Loss: 0.0103\n",
      "Epoch 150/200, Iteration 222/250, Loss: 0.0297\n",
      "Epoch 150/200, Iteration 223/250, Loss: 0.0106\n",
      "Epoch 150/200, Iteration 224/250, Loss: 0.0125\n",
      "Epoch 150/200, Iteration 225/250, Loss: 0.0105\n",
      "Epoch 150/200, Iteration 226/250, Loss: 0.0255\n",
      "Epoch 150/200, Iteration 227/250, Loss: 0.0098\n",
      "Epoch 150/200, Iteration 228/250, Loss: 0.0351\n",
      "Epoch 150/200, Iteration 229/250, Loss: 0.0063\n",
      "Epoch 150/200, Iteration 230/250, Loss: 0.0078\n",
      "Epoch 150/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 150/200, Iteration 232/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 233/250, Loss: 0.0124\n",
      "Epoch 150/200, Iteration 234/250, Loss: 0.0107\n",
      "Epoch 150/200, Iteration 235/250, Loss: 0.0061\n",
      "Epoch 150/200, Iteration 236/250, Loss: 0.0075\n",
      "Epoch 150/200, Iteration 237/250, Loss: 0.0268\n",
      "Epoch 150/200, Iteration 238/250, Loss: 0.0243\n",
      "Epoch 150/200, Iteration 239/250, Loss: 0.0168\n",
      "Epoch 150/200, Iteration 240/250, Loss: 0.0112\n",
      "Epoch 150/200, Iteration 241/250, Loss: 0.0083\n",
      "Epoch 150/200, Iteration 242/250, Loss: 0.0210\n",
      "Epoch 150/200, Iteration 243/250, Loss: 0.0183\n",
      "Epoch 150/200, Iteration 244/250, Loss: 0.0217\n",
      "Epoch 150/200, Iteration 245/250, Loss: 0.0089\n",
      "Epoch 150/200, Iteration 246/250, Loss: 0.0146\n",
      "Epoch 150/200, Iteration 247/250, Loss: 0.0302\n",
      "Epoch 150/200, Iteration 248/250, Loss: 0.0232\n",
      "Epoch 150/200, Iteration 249/250, Loss: 0.0220\n",
      "Epoch 150/200, Iteration 250/250, Loss: 0.0154\n",
      "Train Error: \n",
      " Accuracy: 92.84%, Avg loss: 0.006923, MRE: 0.465200 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.75%, Avg loss: 0.007600, MRE: 0.487652 \n",
      "\n",
      "Epoch 151/200, Iteration 1/250, Loss: 0.0093\n",
      "Epoch 151/200, Iteration 2/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 3/250, Loss: 0.0064\n",
      "Epoch 151/200, Iteration 4/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 5/250, Loss: 0.0195\n",
      "Epoch 151/200, Iteration 6/250, Loss: 0.0161\n",
      "Epoch 151/200, Iteration 7/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 8/250, Loss: 0.0147\n",
      "Epoch 151/200, Iteration 9/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 10/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 11/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 12/250, Loss: 0.0161\n",
      "Epoch 151/200, Iteration 13/250, Loss: 0.0153\n",
      "Epoch 151/200, Iteration 14/250, Loss: 0.0172\n",
      "Epoch 151/200, Iteration 15/250, Loss: 0.0201\n",
      "Epoch 151/200, Iteration 16/250, Loss: 0.0219\n",
      "Epoch 151/200, Iteration 17/250, Loss: 0.0062\n",
      "Epoch 151/200, Iteration 18/250, Loss: 0.0173\n",
      "Epoch 151/200, Iteration 19/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 20/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 21/250, Loss: 0.0117\n",
      "Epoch 151/200, Iteration 22/250, Loss: 0.0111\n",
      "Epoch 151/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 24/250, Loss: 0.0102\n",
      "Epoch 151/200, Iteration 25/250, Loss: 0.0378\n",
      "Epoch 151/200, Iteration 26/250, Loss: 0.0183\n",
      "Epoch 151/200, Iteration 27/250, Loss: 0.0194\n",
      "Epoch 151/200, Iteration 28/250, Loss: 0.0131\n",
      "Epoch 151/200, Iteration 29/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 30/250, Loss: 0.0138\n",
      "Epoch 151/200, Iteration 31/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 32/250, Loss: 0.0145\n",
      "Epoch 151/200, Iteration 33/250, Loss: 0.0156\n",
      "Epoch 151/200, Iteration 34/250, Loss: 0.0115\n",
      "Epoch 151/200, Iteration 35/250, Loss: 0.0129\n",
      "Epoch 151/200, Iteration 36/250, Loss: 0.0140\n",
      "Epoch 151/200, Iteration 37/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 38/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 39/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 40/250, Loss: 0.0148\n",
      "Epoch 151/200, Iteration 41/250, Loss: 0.0216\n",
      "Epoch 151/200, Iteration 42/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 43/250, Loss: 0.0117\n",
      "Epoch 151/200, Iteration 44/250, Loss: 0.0129\n",
      "Epoch 151/200, Iteration 45/250, Loss: 0.0076\n",
      "Epoch 151/200, Iteration 46/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 47/250, Loss: 0.0301\n",
      "Epoch 151/200, Iteration 48/250, Loss: 0.0304\n",
      "Epoch 151/200, Iteration 49/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 50/250, Loss: 0.0468\n",
      "Epoch 151/200, Iteration 51/250, Loss: 0.0175\n",
      "Epoch 151/200, Iteration 52/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 53/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 54/250, Loss: 0.0207\n",
      "Epoch 151/200, Iteration 55/250, Loss: 0.0088\n",
      "Epoch 151/200, Iteration 56/250, Loss: 0.0149\n",
      "Epoch 151/200, Iteration 57/250, Loss: 0.0157\n",
      "Epoch 151/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 151/200, Iteration 59/250, Loss: 0.0068\n",
      "Epoch 151/200, Iteration 60/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 61/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 62/250, Loss: 0.0177\n",
      "Epoch 151/200, Iteration 63/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 64/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 151/200, Iteration 66/250, Loss: 0.0371\n",
      "Epoch 151/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 68/250, Loss: 0.0218\n",
      "Epoch 151/200, Iteration 69/250, Loss: 0.0217\n",
      "Epoch 151/200, Iteration 70/250, Loss: 0.0145\n",
      "Epoch 151/200, Iteration 71/250, Loss: 0.0221\n",
      "Epoch 151/200, Iteration 72/250, Loss: 0.0107\n",
      "Epoch 151/200, Iteration 73/250, Loss: 0.0102\n",
      "Epoch 151/200, Iteration 74/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 75/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 76/250, Loss: 0.0254\n",
      "Epoch 151/200, Iteration 77/250, Loss: 0.0072\n",
      "Epoch 151/200, Iteration 78/250, Loss: 0.0124\n",
      "Epoch 151/200, Iteration 79/250, Loss: 0.0079\n",
      "Epoch 151/200, Iteration 80/250, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 81/250, Loss: 0.0165\n",
      "Epoch 151/200, Iteration 82/250, Loss: 0.0101\n",
      "Epoch 151/200, Iteration 83/250, Loss: 0.0115\n",
      "Epoch 151/200, Iteration 84/250, Loss: 0.0192\n",
      "Epoch 151/200, Iteration 85/250, Loss: 0.0063\n",
      "Epoch 151/200, Iteration 86/250, Loss: 0.0299\n",
      "Epoch 151/200, Iteration 87/250, Loss: 0.0190\n",
      "Epoch 151/200, Iteration 88/250, Loss: 0.0073\n",
      "Epoch 151/200, Iteration 89/250, Loss: 0.0208\n",
      "Epoch 151/200, Iteration 90/250, Loss: 0.0185\n",
      "Epoch 151/200, Iteration 91/250, Loss: 0.0289\n",
      "Epoch 151/200, Iteration 92/250, Loss: 0.0092\n",
      "Epoch 151/200, Iteration 93/250, Loss: 0.0256\n",
      "Epoch 151/200, Iteration 94/250, Loss: 0.0375\n",
      "Epoch 151/200, Iteration 95/250, Loss: 0.0113\n",
      "Epoch 151/200, Iteration 96/250, Loss: 0.0172\n",
      "Epoch 151/200, Iteration 97/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 98/250, Loss: 0.0164\n",
      "Epoch 151/200, Iteration 99/250, Loss: 0.0125\n",
      "Epoch 151/200, Iteration 100/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 101/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 102/250, Loss: 0.0068\n",
      "Epoch 151/200, Iteration 103/250, Loss: 0.0066\n",
      "Epoch 151/200, Iteration 104/250, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 105/250, Loss: 0.0279\n",
      "Epoch 151/200, Iteration 106/250, Loss: 0.0077\n",
      "Epoch 151/200, Iteration 107/250, Loss: 0.0124\n",
      "Epoch 151/200, Iteration 108/250, Loss: 0.0118\n",
      "Epoch 151/200, Iteration 109/250, Loss: 0.0322\n",
      "Epoch 151/200, Iteration 110/250, Loss: 0.0074\n",
      "Epoch 151/200, Iteration 111/250, Loss: 0.0182\n",
      "Epoch 151/200, Iteration 112/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 113/250, Loss: 0.0146\n",
      "Epoch 151/200, Iteration 114/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 115/250, Loss: 0.0159\n",
      "Epoch 151/200, Iteration 116/250, Loss: 0.0154\n",
      "Epoch 151/200, Iteration 117/250, Loss: 0.0231\n",
      "Epoch 151/200, Iteration 118/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 119/250, Loss: 0.0078\n",
      "Epoch 151/200, Iteration 120/250, Loss: 0.0160\n",
      "Epoch 151/200, Iteration 121/250, Loss: 0.0120\n",
      "Epoch 151/200, Iteration 122/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 123/250, Loss: 0.0072\n",
      "Epoch 151/200, Iteration 124/250, Loss: 0.0090\n",
      "Epoch 151/200, Iteration 125/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 126/250, Loss: 0.0196\n",
      "Epoch 151/200, Iteration 127/250, Loss: 0.0178\n",
      "Epoch 151/200, Iteration 128/250, Loss: 0.0265\n",
      "Epoch 151/200, Iteration 129/250, Loss: 0.0110\n",
      "Epoch 151/200, Iteration 130/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 131/250, Loss: 0.0085\n",
      "Epoch 151/200, Iteration 132/250, Loss: 0.0328\n",
      "Epoch 151/200, Iteration 133/250, Loss: 0.0116\n",
      "Epoch 151/200, Iteration 134/250, Loss: 0.0306\n",
      "Epoch 151/200, Iteration 135/250, Loss: 0.0126\n",
      "Epoch 151/200, Iteration 136/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200, Iteration 137/250, Loss: 0.0094\n",
      "Epoch 151/200, Iteration 138/250, Loss: 0.0145\n",
      "Epoch 151/200, Iteration 139/250, Loss: 0.0310\n",
      "Epoch 151/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 151/200, Iteration 141/250, Loss: 0.0115\n",
      "Epoch 151/200, Iteration 142/250, Loss: 0.0106\n",
      "Epoch 151/200, Iteration 143/250, Loss: 0.0097\n",
      "Epoch 151/200, Iteration 144/250, Loss: 0.0435\n",
      "Epoch 151/200, Iteration 145/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 146/250, Loss: 0.0259\n",
      "Epoch 151/200, Iteration 147/250, Loss: 0.0073\n",
      "Epoch 151/200, Iteration 148/250, Loss: 0.0234\n",
      "Epoch 151/200, Iteration 149/250, Loss: 0.0122\n",
      "Epoch 151/200, Iteration 150/250, Loss: 0.0236\n",
      "Epoch 151/200, Iteration 151/250, Loss: 0.0301\n",
      "Epoch 151/200, Iteration 152/250, Loss: 0.0310\n",
      "Epoch 151/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 151/200, Iteration 154/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 155/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 156/250, Loss: 0.0141\n",
      "Epoch 151/200, Iteration 157/250, Loss: 0.0129\n",
      "Epoch 151/200, Iteration 158/250, Loss: 0.0148\n",
      "Epoch 151/200, Iteration 159/250, Loss: 0.0261\n",
      "Epoch 151/200, Iteration 160/250, Loss: 0.0116\n",
      "Epoch 151/200, Iteration 161/250, Loss: 0.0161\n",
      "Epoch 151/200, Iteration 162/250, Loss: 0.0126\n",
      "Epoch 151/200, Iteration 163/250, Loss: 0.0172\n",
      "Epoch 151/200, Iteration 164/250, Loss: 0.0139\n",
      "Epoch 151/200, Iteration 165/250, Loss: 0.0135\n",
      "Epoch 151/200, Iteration 166/250, Loss: 0.0206\n",
      "Epoch 151/200, Iteration 167/250, Loss: 0.0074\n",
      "Epoch 151/200, Iteration 168/250, Loss: 0.0086\n",
      "Epoch 151/200, Iteration 169/250, Loss: 0.0279\n",
      "Epoch 151/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 151/200, Iteration 171/250, Loss: 0.0220\n",
      "Epoch 151/200, Iteration 172/250, Loss: 0.0100\n",
      "Epoch 151/200, Iteration 173/250, Loss: 0.0109\n",
      "Epoch 151/200, Iteration 174/250, Loss: 0.0138\n",
      "Epoch 151/200, Iteration 175/250, Loss: 0.0113\n",
      "Epoch 151/200, Iteration 176/250, Loss: 0.0170\n",
      "Epoch 151/200, Iteration 177/250, Loss: 0.0171\n",
      "Epoch 151/200, Iteration 178/250, Loss: 0.0162\n",
      "Epoch 151/200, Iteration 179/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 180/250, Loss: 0.0101\n",
      "Epoch 151/200, Iteration 181/250, Loss: 0.0394\n",
      "Epoch 151/200, Iteration 182/250, Loss: 0.0082\n",
      "Epoch 151/200, Iteration 183/250, Loss: 0.0075\n",
      "Epoch 151/200, Iteration 184/250, Loss: 0.0112\n",
      "Epoch 151/200, Iteration 185/250, Loss: 0.0133\n",
      "Epoch 151/200, Iteration 186/250, Loss: 0.0100\n",
      "Epoch 151/200, Iteration 187/250, Loss: 0.0166\n",
      "Epoch 151/200, Iteration 188/250, Loss: 0.0134\n",
      "Epoch 151/200, Iteration 189/250, Loss: 0.0097\n",
      "Epoch 151/200, Iteration 190/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 191/250, Loss: 0.0156\n",
      "Epoch 151/200, Iteration 192/250, Loss: 0.0113\n",
      "Epoch 151/200, Iteration 193/250, Loss: 0.0127\n",
      "Epoch 151/200, Iteration 194/250, Loss: 0.0147\n",
      "Epoch 151/200, Iteration 195/250, Loss: 0.0114\n",
      "Epoch 151/200, Iteration 196/250, Loss: 0.0118\n",
      "Epoch 151/200, Iteration 197/250, Loss: 0.0319\n",
      "Epoch 151/200, Iteration 198/250, Loss: 0.0095\n",
      "Epoch 151/200, Iteration 199/250, Loss: 0.0196\n",
      "Epoch 151/200, Iteration 200/250, Loss: 0.0094\n",
      "Epoch 151/200, Iteration 201/250, Loss: 0.0147\n",
      "Epoch 151/200, Iteration 202/250, Loss: 0.0153\n",
      "Epoch 151/200, Iteration 203/250, Loss: 0.0076\n",
      "Epoch 151/200, Iteration 204/250, Loss: 0.0119\n",
      "Epoch 151/200, Iteration 205/250, Loss: 0.0203\n",
      "Epoch 151/200, Iteration 206/250, Loss: 0.0227\n",
      "Epoch 151/200, Iteration 207/250, Loss: 0.0109\n",
      "Epoch 151/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 151/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 151/200, Iteration 210/250, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 211/250, Loss: 0.0090\n",
      "Epoch 151/200, Iteration 212/250, Loss: 0.0100\n",
      "Epoch 151/200, Iteration 213/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 214/250, Loss: 0.0308\n",
      "Epoch 151/200, Iteration 215/250, Loss: 0.0136\n",
      "Epoch 151/200, Iteration 216/250, Loss: 0.0227\n",
      "Epoch 151/200, Iteration 217/250, Loss: 0.0142\n",
      "Epoch 151/200, Iteration 218/250, Loss: 0.0178\n",
      "Epoch 151/200, Iteration 219/250, Loss: 0.0164\n",
      "Epoch 151/200, Iteration 220/250, Loss: 0.0243\n",
      "Epoch 151/200, Iteration 221/250, Loss: 0.0133\n",
      "Epoch 151/200, Iteration 222/250, Loss: 0.0193\n",
      "Epoch 151/200, Iteration 223/250, Loss: 0.0261\n",
      "Epoch 151/200, Iteration 224/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 225/250, Loss: 0.0231\n",
      "Epoch 151/200, Iteration 226/250, Loss: 0.0264\n",
      "Epoch 151/200, Iteration 227/250, Loss: 0.0135\n",
      "Epoch 151/200, Iteration 228/250, Loss: 0.0077\n",
      "Epoch 151/200, Iteration 229/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 230/250, Loss: 0.0098\n",
      "Epoch 151/200, Iteration 231/250, Loss: 0.0333\n",
      "Epoch 151/200, Iteration 232/250, Loss: 0.0091\n",
      "Epoch 151/200, Iteration 233/250, Loss: 0.0083\n",
      "Epoch 151/200, Iteration 234/250, Loss: 0.0080\n",
      "Epoch 151/200, Iteration 235/250, Loss: 0.0179\n",
      "Epoch 151/200, Iteration 236/250, Loss: 0.0149\n",
      "Epoch 151/200, Iteration 237/250, Loss: 0.0068\n",
      "Epoch 151/200, Iteration 238/250, Loss: 0.0138\n",
      "Epoch 151/200, Iteration 239/250, Loss: 0.0228\n",
      "Epoch 151/200, Iteration 240/250, Loss: 0.0085\n",
      "Epoch 151/200, Iteration 241/250, Loss: 0.0220\n",
      "Epoch 151/200, Iteration 242/250, Loss: 0.0121\n",
      "Epoch 151/200, Iteration 243/250, Loss: 0.0201\n",
      "Epoch 151/200, Iteration 244/250, Loss: 0.0077\n",
      "Epoch 151/200, Iteration 245/250, Loss: 0.0167\n",
      "Epoch 151/200, Iteration 246/250, Loss: 0.0099\n",
      "Epoch 151/200, Iteration 247/250, Loss: 0.0179\n",
      "Epoch 151/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 151/200, Iteration 249/250, Loss: 0.0089\n",
      "Epoch 151/200, Iteration 250/250, Loss: 0.0101\n",
      "Train Error: \n",
      " Accuracy: 89.81%, Avg loss: 0.006639, MRE: 0.448864 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.007227, MRE: 0.529152 \n",
      "\n",
      "Epoch 152/200, Iteration 1/250, Loss: 0.0188\n",
      "Epoch 152/200, Iteration 2/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 3/250, Loss: 0.0141\n",
      "Epoch 152/200, Iteration 4/250, Loss: 0.0107\n",
      "Epoch 152/200, Iteration 5/250, Loss: 0.0168\n",
      "Epoch 152/200, Iteration 6/250, Loss: 0.0170\n",
      "Epoch 152/200, Iteration 7/250, Loss: 0.0263\n",
      "Epoch 152/200, Iteration 8/250, Loss: 0.0292\n",
      "Epoch 152/200, Iteration 9/250, Loss: 0.0058\n",
      "Epoch 152/200, Iteration 10/250, Loss: 0.0138\n",
      "Epoch 152/200, Iteration 11/250, Loss: 0.0080\n",
      "Epoch 152/200, Iteration 12/250, Loss: 0.0080\n",
      "Epoch 152/200, Iteration 13/250, Loss: 0.0102\n",
      "Epoch 152/200, Iteration 14/250, Loss: 0.0195\n",
      "Epoch 152/200, Iteration 15/250, Loss: 0.0114\n",
      "Epoch 152/200, Iteration 16/250, Loss: 0.0064\n",
      "Epoch 152/200, Iteration 17/250, Loss: 0.0098\n",
      "Epoch 152/200, Iteration 18/250, Loss: 0.0276\n",
      "Epoch 152/200, Iteration 19/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 20/250, Loss: 0.0186\n",
      "Epoch 152/200, Iteration 21/250, Loss: 0.0075\n",
      "Epoch 152/200, Iteration 22/250, Loss: 0.0147\n",
      "Epoch 152/200, Iteration 23/250, Loss: 0.0313\n",
      "Epoch 152/200, Iteration 24/250, Loss: 0.0151\n",
      "Epoch 152/200, Iteration 25/250, Loss: 0.0142\n",
      "Epoch 152/200, Iteration 26/250, Loss: 0.0124\n",
      "Epoch 152/200, Iteration 27/250, Loss: 0.0179\n",
      "Epoch 152/200, Iteration 28/250, Loss: 0.0234\n",
      "Epoch 152/200, Iteration 29/250, Loss: 0.0223\n",
      "Epoch 152/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 31/250, Loss: 0.0261\n",
      "Epoch 152/200, Iteration 32/250, Loss: 0.0097\n",
      "Epoch 152/200, Iteration 33/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 152/200, Iteration 35/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 36/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 37/250, Loss: 0.0095\n",
      "Epoch 152/200, Iteration 38/250, Loss: 0.0065\n",
      "Epoch 152/200, Iteration 39/250, Loss: 0.0184\n",
      "Epoch 152/200, Iteration 40/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 41/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 42/250, Loss: 0.0251\n",
      "Epoch 152/200, Iteration 43/250, Loss: 0.0094\n",
      "Epoch 152/200, Iteration 44/250, Loss: 0.0092\n",
      "Epoch 152/200, Iteration 45/250, Loss: 0.0203\n",
      "Epoch 152/200, Iteration 46/250, Loss: 0.0064\n",
      "Epoch 152/200, Iteration 47/250, Loss: 0.0146\n",
      "Epoch 152/200, Iteration 48/250, Loss: 0.0182\n",
      "Epoch 152/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 50/250, Loss: 0.0070\n",
      "Epoch 152/200, Iteration 51/250, Loss: 0.0143\n",
      "Epoch 152/200, Iteration 52/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 53/250, Loss: 0.0093\n",
      "Epoch 152/200, Iteration 54/250, Loss: 0.0158\n",
      "Epoch 152/200, Iteration 55/250, Loss: 0.0143\n",
      "Epoch 152/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 152/200, Iteration 57/250, Loss: 0.0183\n",
      "Epoch 152/200, Iteration 58/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 59/250, Loss: 0.0087\n",
      "Epoch 152/200, Iteration 60/250, Loss: 0.0183\n",
      "Epoch 152/200, Iteration 61/250, Loss: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200, Iteration 62/250, Loss: 0.0225\n",
      "Epoch 152/200, Iteration 63/250, Loss: 0.0124\n",
      "Epoch 152/200, Iteration 64/250, Loss: 0.0104\n",
      "Epoch 152/200, Iteration 65/250, Loss: 0.0398\n",
      "Epoch 152/200, Iteration 66/250, Loss: 0.0219\n",
      "Epoch 152/200, Iteration 67/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 68/250, Loss: 0.0109\n",
      "Epoch 152/200, Iteration 69/250, Loss: 0.0104\n",
      "Epoch 152/200, Iteration 70/250, Loss: 0.0152\n",
      "Epoch 152/200, Iteration 71/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 72/250, Loss: 0.0167\n",
      "Epoch 152/200, Iteration 73/250, Loss: 0.0235\n",
      "Epoch 152/200, Iteration 74/250, Loss: 0.0108\n",
      "Epoch 152/200, Iteration 75/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 76/250, Loss: 0.0125\n",
      "Epoch 152/200, Iteration 77/250, Loss: 0.0165\n",
      "Epoch 152/200, Iteration 78/250, Loss: 0.0282\n",
      "Epoch 152/200, Iteration 79/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 80/250, Loss: 0.0103\n",
      "Epoch 152/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 152/200, Iteration 82/250, Loss: 0.0135\n",
      "Epoch 152/200, Iteration 83/250, Loss: 0.0135\n",
      "Epoch 152/200, Iteration 84/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 85/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 86/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 87/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 88/250, Loss: 0.0166\n",
      "Epoch 152/200, Iteration 89/250, Loss: 0.0228\n",
      "Epoch 152/200, Iteration 90/250, Loss: 0.0410\n",
      "Epoch 152/200, Iteration 91/250, Loss: 0.0196\n",
      "Epoch 152/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 152/200, Iteration 93/250, Loss: 0.0126\n",
      "Epoch 152/200, Iteration 94/250, Loss: 0.0113\n",
      "Epoch 152/200, Iteration 95/250, Loss: 0.0112\n",
      "Epoch 152/200, Iteration 96/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 97/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 98/250, Loss: 0.0179\n",
      "Epoch 152/200, Iteration 99/250, Loss: 0.0297\n",
      "Epoch 152/200, Iteration 100/250, Loss: 0.0166\n",
      "Epoch 152/200, Iteration 101/250, Loss: 0.0102\n",
      "Epoch 152/200, Iteration 102/250, Loss: 0.0212\n",
      "Epoch 152/200, Iteration 103/250, Loss: 0.0247\n",
      "Epoch 152/200, Iteration 104/250, Loss: 0.0208\n",
      "Epoch 152/200, Iteration 105/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 106/250, Loss: 0.0156\n",
      "Epoch 152/200, Iteration 107/250, Loss: 0.0125\n",
      "Epoch 152/200, Iteration 108/250, Loss: 0.0081\n",
      "Epoch 152/200, Iteration 109/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 110/250, Loss: 0.0122\n",
      "Epoch 152/200, Iteration 111/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 112/250, Loss: 0.0150\n",
      "Epoch 152/200, Iteration 113/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 114/250, Loss: 0.0117\n",
      "Epoch 152/200, Iteration 115/250, Loss: 0.0169\n",
      "Epoch 152/200, Iteration 116/250, Loss: 0.0227\n",
      "Epoch 152/200, Iteration 117/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 118/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 119/250, Loss: 0.0085\n",
      "Epoch 152/200, Iteration 120/250, Loss: 0.0169\n",
      "Epoch 152/200, Iteration 121/250, Loss: 0.0376\n",
      "Epoch 152/200, Iteration 122/250, Loss: 0.0065\n",
      "Epoch 152/200, Iteration 123/250, Loss: 0.0104\n",
      "Epoch 152/200, Iteration 124/250, Loss: 0.0197\n",
      "Epoch 152/200, Iteration 125/250, Loss: 0.0102\n",
      "Epoch 152/200, Iteration 126/250, Loss: 0.0169\n",
      "Epoch 152/200, Iteration 127/250, Loss: 0.0153\n",
      "Epoch 152/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 152/200, Iteration 129/250, Loss: 0.0251\n",
      "Epoch 152/200, Iteration 130/250, Loss: 0.0209\n",
      "Epoch 152/200, Iteration 131/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 132/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 133/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 134/250, Loss: 0.0242\n",
      "Epoch 152/200, Iteration 135/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 136/250, Loss: 0.0108\n",
      "Epoch 152/200, Iteration 137/250, Loss: 0.0327\n",
      "Epoch 152/200, Iteration 138/250, Loss: 0.0198\n",
      "Epoch 152/200, Iteration 139/250, Loss: 0.0206\n",
      "Epoch 152/200, Iteration 140/250, Loss: 0.0236\n",
      "Epoch 152/200, Iteration 141/250, Loss: 0.0120\n",
      "Epoch 152/200, Iteration 142/250, Loss: 0.0293\n",
      "Epoch 152/200, Iteration 143/250, Loss: 0.0126\n",
      "Epoch 152/200, Iteration 144/250, Loss: 0.0131\n",
      "Epoch 152/200, Iteration 145/250, Loss: 0.0292\n",
      "Epoch 152/200, Iteration 146/250, Loss: 0.0221\n",
      "Epoch 152/200, Iteration 147/250, Loss: 0.0151\n",
      "Epoch 152/200, Iteration 148/250, Loss: 0.0174\n",
      "Epoch 152/200, Iteration 149/250, Loss: 0.0119\n",
      "Epoch 152/200, Iteration 150/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 152/250, Loss: 0.0167\n",
      "Epoch 152/200, Iteration 153/250, Loss: 0.0166\n",
      "Epoch 152/200, Iteration 154/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 155/250, Loss: 0.0102\n",
      "Epoch 152/200, Iteration 156/250, Loss: 0.0230\n",
      "Epoch 152/200, Iteration 157/250, Loss: 0.0064\n",
      "Epoch 152/200, Iteration 158/250, Loss: 0.0158\n",
      "Epoch 152/200, Iteration 159/250, Loss: 0.0192\n",
      "Epoch 152/200, Iteration 160/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 161/250, Loss: 0.0122\n",
      "Epoch 152/200, Iteration 162/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 163/250, Loss: 0.0086\n",
      "Epoch 152/200, Iteration 164/250, Loss: 0.0240\n",
      "Epoch 152/200, Iteration 165/250, Loss: 0.0077\n",
      "Epoch 152/200, Iteration 166/250, Loss: 0.0188\n",
      "Epoch 152/200, Iteration 167/250, Loss: 0.0384\n",
      "Epoch 152/200, Iteration 168/250, Loss: 0.0181\n",
      "Epoch 152/200, Iteration 169/250, Loss: 0.0304\n",
      "Epoch 152/200, Iteration 170/250, Loss: 0.0148\n",
      "Epoch 152/200, Iteration 171/250, Loss: 0.0161\n",
      "Epoch 152/200, Iteration 172/250, Loss: 0.0172\n",
      "Epoch 152/200, Iteration 173/250, Loss: 0.0286\n",
      "Epoch 152/200, Iteration 174/250, Loss: 0.0128\n",
      "Epoch 152/200, Iteration 175/250, Loss: 0.0244\n",
      "Epoch 152/200, Iteration 176/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 177/250, Loss: 0.0147\n",
      "Epoch 152/200, Iteration 178/250, Loss: 0.0105\n",
      "Epoch 152/200, Iteration 179/250, Loss: 0.0110\n",
      "Epoch 152/200, Iteration 180/250, Loss: 0.0145\n",
      "Epoch 152/200, Iteration 181/250, Loss: 0.0070\n",
      "Epoch 152/200, Iteration 182/250, Loss: 0.0154\n",
      "Epoch 152/200, Iteration 183/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 184/250, Loss: 0.0134\n",
      "Epoch 152/200, Iteration 185/250, Loss: 0.0104\n",
      "Epoch 152/200, Iteration 186/250, Loss: 0.0098\n",
      "Epoch 152/200, Iteration 187/250, Loss: 0.0117\n",
      "Epoch 152/200, Iteration 188/250, Loss: 0.0162\n",
      "Epoch 152/200, Iteration 189/250, Loss: 0.0217\n",
      "Epoch 152/200, Iteration 190/250, Loss: 0.0091\n",
      "Epoch 152/200, Iteration 191/250, Loss: 0.0116\n",
      "Epoch 152/200, Iteration 192/250, Loss: 0.0099\n",
      "Epoch 152/200, Iteration 193/250, Loss: 0.0156\n",
      "Epoch 152/200, Iteration 194/250, Loss: 0.0117\n",
      "Epoch 152/200, Iteration 195/250, Loss: 0.0213\n",
      "Epoch 152/200, Iteration 196/250, Loss: 0.0098\n",
      "Epoch 152/200, Iteration 197/250, Loss: 0.0247\n",
      "Epoch 152/200, Iteration 198/250, Loss: 0.0181\n",
      "Epoch 152/200, Iteration 199/250, Loss: 0.0083\n",
      "Epoch 152/200, Iteration 200/250, Loss: 0.0130\n",
      "Epoch 152/200, Iteration 201/250, Loss: 0.0204\n",
      "Epoch 152/200, Iteration 202/250, Loss: 0.0084\n",
      "Epoch 152/200, Iteration 203/250, Loss: 0.0105\n",
      "Epoch 152/200, Iteration 204/250, Loss: 0.0254\n",
      "Epoch 152/200, Iteration 205/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 206/250, Loss: 0.0108\n",
      "Epoch 152/200, Iteration 207/250, Loss: 0.0145\n",
      "Epoch 152/200, Iteration 208/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 209/250, Loss: 0.0096\n",
      "Epoch 152/200, Iteration 210/250, Loss: 0.0106\n",
      "Epoch 152/200, Iteration 211/250, Loss: 0.0076\n",
      "Epoch 152/200, Iteration 212/250, Loss: 0.0095\n",
      "Epoch 152/200, Iteration 213/250, Loss: 0.0218\n",
      "Epoch 152/200, Iteration 214/250, Loss: 0.0179\n",
      "Epoch 152/200, Iteration 215/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 216/250, Loss: 0.0177\n",
      "Epoch 152/200, Iteration 217/250, Loss: 0.0129\n",
      "Epoch 152/200, Iteration 218/250, Loss: 0.0088\n",
      "Epoch 152/200, Iteration 219/250, Loss: 0.0114\n",
      "Epoch 152/200, Iteration 220/250, Loss: 0.0137\n",
      "Epoch 152/200, Iteration 221/250, Loss: 0.0162\n",
      "Epoch 152/200, Iteration 222/250, Loss: 0.0100\n",
      "Epoch 152/200, Iteration 223/250, Loss: 0.0074\n",
      "Epoch 152/200, Iteration 224/250, Loss: 0.0181\n",
      "Epoch 152/200, Iteration 225/250, Loss: 0.0087\n",
      "Epoch 152/200, Iteration 226/250, Loss: 0.0235\n",
      "Epoch 152/200, Iteration 227/250, Loss: 0.0177\n",
      "Epoch 152/200, Iteration 228/250, Loss: 0.0097\n",
      "Epoch 152/200, Iteration 229/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 230/250, Loss: 0.0148\n",
      "Epoch 152/200, Iteration 231/250, Loss: 0.0083\n",
      "Epoch 152/200, Iteration 232/250, Loss: 0.0189\n",
      "Epoch 152/200, Iteration 233/250, Loss: 0.0079\n",
      "Epoch 152/200, Iteration 234/250, Loss: 0.0133\n",
      "Epoch 152/200, Iteration 235/250, Loss: 0.0247\n",
      "Epoch 152/200, Iteration 236/250, Loss: 0.0094\n",
      "Epoch 152/200, Iteration 237/250, Loss: 0.0097\n",
      "Epoch 152/200, Iteration 238/250, Loss: 0.0094\n",
      "Epoch 152/200, Iteration 239/250, Loss: 0.0184\n",
      "Epoch 152/200, Iteration 240/250, Loss: 0.0142\n",
      "Epoch 152/200, Iteration 241/250, Loss: 0.0089\n",
      "Epoch 152/200, Iteration 242/250, Loss: 0.0084\n",
      "Epoch 152/200, Iteration 243/250, Loss: 0.0123\n",
      "Epoch 152/200, Iteration 244/250, Loss: 0.0245\n",
      "Epoch 152/200, Iteration 245/250, Loss: 0.0254\n",
      "Epoch 152/200, Iteration 246/250, Loss: 0.0184\n",
      "Epoch 152/200, Iteration 247/250, Loss: 0.0197\n",
      "Epoch 152/200, Iteration 248/250, Loss: 0.0277\n",
      "Epoch 152/200, Iteration 249/250, Loss: 0.0181\n",
      "Epoch 152/200, Iteration 250/250, Loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.006758, MRE: 0.417854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.007315, MRE: 0.492293 \n",
      "\n",
      "Epoch 153/200, Iteration 1/250, Loss: 0.0136\n",
      "Epoch 153/200, Iteration 2/250, Loss: 0.0121\n",
      "Epoch 153/200, Iteration 3/250, Loss: 0.0133\n",
      "Epoch 153/200, Iteration 4/250, Loss: 0.0177\n",
      "Epoch 153/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 153/200, Iteration 6/250, Loss: 0.0178\n",
      "Epoch 153/200, Iteration 7/250, Loss: 0.0320\n",
      "Epoch 153/200, Iteration 8/250, Loss: 0.0134\n",
      "Epoch 153/200, Iteration 9/250, Loss: 0.0081\n",
      "Epoch 153/200, Iteration 10/250, Loss: 0.0242\n",
      "Epoch 153/200, Iteration 11/250, Loss: 0.0097\n",
      "Epoch 153/200, Iteration 12/250, Loss: 0.0081\n",
      "Epoch 153/200, Iteration 13/250, Loss: 0.0160\n",
      "Epoch 153/200, Iteration 14/250, Loss: 0.0102\n",
      "Epoch 153/200, Iteration 15/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 16/250, Loss: 0.0106\n",
      "Epoch 153/200, Iteration 17/250, Loss: 0.0111\n",
      "Epoch 153/200, Iteration 18/250, Loss: 0.0169\n",
      "Epoch 153/200, Iteration 19/250, Loss: 0.0117\n",
      "Epoch 153/200, Iteration 20/250, Loss: 0.0108\n",
      "Epoch 153/200, Iteration 21/250, Loss: 0.0094\n",
      "Epoch 153/200, Iteration 22/250, Loss: 0.0204\n",
      "Epoch 153/200, Iteration 23/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 24/250, Loss: 0.0289\n",
      "Epoch 153/200, Iteration 25/250, Loss: 0.0237\n",
      "Epoch 153/200, Iteration 26/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 27/250, Loss: 0.0213\n",
      "Epoch 153/200, Iteration 28/250, Loss: 0.0192\n",
      "Epoch 153/200, Iteration 29/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 30/250, Loss: 0.0230\n",
      "Epoch 153/200, Iteration 31/250, Loss: 0.0127\n",
      "Epoch 153/200, Iteration 32/250, Loss: 0.0207\n",
      "Epoch 153/200, Iteration 33/250, Loss: 0.0184\n",
      "Epoch 153/200, Iteration 34/250, Loss: 0.0242\n",
      "Epoch 153/200, Iteration 35/250, Loss: 0.0128\n",
      "Epoch 153/200, Iteration 36/250, Loss: 0.0200\n",
      "Epoch 153/200, Iteration 37/250, Loss: 0.0112\n",
      "Epoch 153/200, Iteration 38/250, Loss: 0.0299\n",
      "Epoch 153/200, Iteration 39/250, Loss: 0.0116\n",
      "Epoch 153/200, Iteration 40/250, Loss: 0.0097\n",
      "Epoch 153/200, Iteration 41/250, Loss: 0.0070\n",
      "Epoch 153/200, Iteration 42/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 153/200, Iteration 44/250, Loss: 0.0140\n",
      "Epoch 153/200, Iteration 45/250, Loss: 0.0142\n",
      "Epoch 153/200, Iteration 46/250, Loss: 0.0110\n",
      "Epoch 153/200, Iteration 47/250, Loss: 0.0182\n",
      "Epoch 153/200, Iteration 48/250, Loss: 0.0156\n",
      "Epoch 153/200, Iteration 49/250, Loss: 0.0117\n",
      "Epoch 153/200, Iteration 50/250, Loss: 0.0171\n",
      "Epoch 153/200, Iteration 51/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 52/250, Loss: 0.0079\n",
      "Epoch 153/200, Iteration 53/250, Loss: 0.0200\n",
      "Epoch 153/200, Iteration 54/250, Loss: 0.0096\n",
      "Epoch 153/200, Iteration 55/250, Loss: 0.0267\n",
      "Epoch 153/200, Iteration 56/250, Loss: 0.0151\n",
      "Epoch 153/200, Iteration 57/250, Loss: 0.0138\n",
      "Epoch 153/200, Iteration 58/250, Loss: 0.0088\n",
      "Epoch 153/200, Iteration 59/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 60/250, Loss: 0.0068\n",
      "Epoch 153/200, Iteration 61/250, Loss: 0.0131\n",
      "Epoch 153/200, Iteration 62/250, Loss: 0.0078\n",
      "Epoch 153/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 153/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 65/250, Loss: 0.0159\n",
      "Epoch 153/200, Iteration 66/250, Loss: 0.0350\n",
      "Epoch 153/200, Iteration 67/250, Loss: 0.0058\n",
      "Epoch 153/200, Iteration 68/250, Loss: 0.0344\n",
      "Epoch 153/200, Iteration 69/250, Loss: 0.0264\n",
      "Epoch 153/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 153/200, Iteration 71/250, Loss: 0.0115\n",
      "Epoch 153/200, Iteration 72/250, Loss: 0.0118\n",
      "Epoch 153/200, Iteration 73/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 74/250, Loss: 0.0145\n",
      "Epoch 153/200, Iteration 75/250, Loss: 0.0074\n",
      "Epoch 153/200, Iteration 76/250, Loss: 0.0241\n",
      "Epoch 153/200, Iteration 77/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 78/250, Loss: 0.0177\n",
      "Epoch 153/200, Iteration 79/250, Loss: 0.0120\n",
      "Epoch 153/200, Iteration 80/250, Loss: 0.0198\n",
      "Epoch 153/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 153/200, Iteration 82/250, Loss: 0.0114\n",
      "Epoch 153/200, Iteration 83/250, Loss: 0.0090\n",
      "Epoch 153/200, Iteration 84/250, Loss: 0.0081\n",
      "Epoch 153/200, Iteration 85/250, Loss: 0.0075\n",
      "Epoch 153/200, Iteration 86/250, Loss: 0.0108\n",
      "Epoch 153/200, Iteration 87/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 88/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 89/250, Loss: 0.0234\n",
      "Epoch 153/200, Iteration 90/250, Loss: 0.0105\n",
      "Epoch 153/200, Iteration 91/250, Loss: 0.0436\n",
      "Epoch 153/200, Iteration 92/250, Loss: 0.0176\n",
      "Epoch 153/200, Iteration 93/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 94/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 95/250, Loss: 0.0078\n",
      "Epoch 153/200, Iteration 96/250, Loss: 0.0295\n",
      "Epoch 153/200, Iteration 97/250, Loss: 0.0321\n",
      "Epoch 153/200, Iteration 98/250, Loss: 0.0146\n",
      "Epoch 153/200, Iteration 99/250, Loss: 0.0155\n",
      "Epoch 153/200, Iteration 100/250, Loss: 0.0274\n",
      "Epoch 153/200, Iteration 101/250, Loss: 0.0173\n",
      "Epoch 153/200, Iteration 102/250, Loss: 0.0249\n",
      "Epoch 153/200, Iteration 103/250, Loss: 0.0160\n",
      "Epoch 153/200, Iteration 104/250, Loss: 0.0192\n",
      "Epoch 153/200, Iteration 105/250, Loss: 0.0122\n",
      "Epoch 153/200, Iteration 106/250, Loss: 0.0177\n",
      "Epoch 153/200, Iteration 107/250, Loss: 0.0299\n",
      "Epoch 153/200, Iteration 108/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 109/250, Loss: 0.0077\n",
      "Epoch 153/200, Iteration 110/250, Loss: 0.0121\n",
      "Epoch 153/200, Iteration 111/250, Loss: 0.0192\n",
      "Epoch 153/200, Iteration 112/250, Loss: 0.0224\n",
      "Epoch 153/200, Iteration 113/250, Loss: 0.0156\n",
      "Epoch 153/200, Iteration 114/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 115/250, Loss: 0.0187\n",
      "Epoch 153/200, Iteration 116/250, Loss: 0.0185\n",
      "Epoch 153/200, Iteration 117/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 118/250, Loss: 0.0097\n",
      "Epoch 153/200, Iteration 119/250, Loss: 0.0065\n",
      "Epoch 153/200, Iteration 120/250, Loss: 0.0131\n",
      "Epoch 153/200, Iteration 121/250, Loss: 0.0238\n",
      "Epoch 153/200, Iteration 122/250, Loss: 0.0133\n",
      "Epoch 153/200, Iteration 123/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 124/250, Loss: 0.0094\n",
      "Epoch 153/200, Iteration 125/250, Loss: 0.0070\n",
      "Epoch 153/200, Iteration 126/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 127/250, Loss: 0.0059\n",
      "Epoch 153/200, Iteration 128/250, Loss: 0.0082\n",
      "Epoch 153/200, Iteration 129/250, Loss: 0.0061\n",
      "Epoch 153/200, Iteration 130/250, Loss: 0.0223\n",
      "Epoch 153/200, Iteration 131/250, Loss: 0.0154\n",
      "Epoch 153/200, Iteration 132/250, Loss: 0.0090\n",
      "Epoch 153/200, Iteration 133/250, Loss: 0.0174\n",
      "Epoch 153/200, Iteration 134/250, Loss: 0.0101\n",
      "Epoch 153/200, Iteration 135/250, Loss: 0.0104\n",
      "Epoch 153/200, Iteration 136/250, Loss: 0.0072\n",
      "Epoch 153/200, Iteration 137/250, Loss: 0.0137\n",
      "Epoch 153/200, Iteration 138/250, Loss: 0.0151\n",
      "Epoch 153/200, Iteration 139/250, Loss: 0.0119\n",
      "Epoch 153/200, Iteration 140/250, Loss: 0.0251\n",
      "Epoch 153/200, Iteration 141/250, Loss: 0.0085\n",
      "Epoch 153/200, Iteration 142/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 143/250, Loss: 0.0163\n",
      "Epoch 153/200, Iteration 144/250, Loss: 0.0112\n",
      "Epoch 153/200, Iteration 145/250, Loss: 0.0091\n",
      "Epoch 153/200, Iteration 146/250, Loss: 0.0093\n",
      "Epoch 153/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 153/200, Iteration 148/250, Loss: 0.0073\n",
      "Epoch 153/200, Iteration 149/250, Loss: 0.0111\n",
      "Epoch 153/200, Iteration 150/250, Loss: 0.0141\n",
      "Epoch 153/200, Iteration 151/250, Loss: 0.0074\n",
      "Epoch 153/200, Iteration 152/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 153/250, Loss: 0.0082\n",
      "Epoch 153/200, Iteration 154/250, Loss: 0.0126\n",
      "Epoch 153/200, Iteration 155/250, Loss: 0.0142\n",
      "Epoch 153/200, Iteration 156/250, Loss: 0.0116\n",
      "Epoch 153/200, Iteration 157/250, Loss: 0.0066\n",
      "Epoch 153/200, Iteration 158/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 159/250, Loss: 0.0073\n",
      "Epoch 153/200, Iteration 160/250, Loss: 0.0107\n",
      "Epoch 153/200, Iteration 161/250, Loss: 0.0232\n",
      "Epoch 153/200, Iteration 162/250, Loss: 0.0080\n",
      "Epoch 153/200, Iteration 163/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 164/250, Loss: 0.0206\n",
      "Epoch 153/200, Iteration 165/250, Loss: 0.0194\n",
      "Epoch 153/200, Iteration 166/250, Loss: 0.0207\n",
      "Epoch 153/200, Iteration 167/250, Loss: 0.0100\n",
      "Epoch 153/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 169/250, Loss: 0.0190\n",
      "Epoch 153/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 153/200, Iteration 171/250, Loss: 0.0094\n",
      "Epoch 153/200, Iteration 172/250, Loss: 0.0071\n",
      "Epoch 153/200, Iteration 173/250, Loss: 0.0213\n",
      "Epoch 153/200, Iteration 174/250, Loss: 0.0108\n",
      "Epoch 153/200, Iteration 175/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 176/250, Loss: 0.0304\n",
      "Epoch 153/200, Iteration 177/250, Loss: 0.0113\n",
      "Epoch 153/200, Iteration 178/250, Loss: 0.0300\n",
      "Epoch 153/200, Iteration 179/250, Loss: 0.0073\n",
      "Epoch 153/200, Iteration 180/250, Loss: 0.0139\n",
      "Epoch 153/200, Iteration 181/250, Loss: 0.0133\n",
      "Epoch 153/200, Iteration 182/250, Loss: 0.0377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200, Iteration 183/250, Loss: 0.0168\n",
      "Epoch 153/200, Iteration 184/250, Loss: 0.0068\n",
      "Epoch 153/200, Iteration 185/250, Loss: 0.0316\n",
      "Epoch 153/200, Iteration 186/250, Loss: 0.0224\n",
      "Epoch 153/200, Iteration 187/250, Loss: 0.0283\n",
      "Epoch 153/200, Iteration 188/250, Loss: 0.0166\n",
      "Epoch 153/200, Iteration 189/250, Loss: 0.0244\n",
      "Epoch 153/200, Iteration 190/250, Loss: 0.0287\n",
      "Epoch 153/200, Iteration 191/250, Loss: 0.0167\n",
      "Epoch 153/200, Iteration 192/250, Loss: 0.0209\n",
      "Epoch 153/200, Iteration 193/250, Loss: 0.0240\n",
      "Epoch 153/200, Iteration 194/250, Loss: 0.0072\n",
      "Epoch 153/200, Iteration 195/250, Loss: 0.0098\n",
      "Epoch 153/200, Iteration 196/250, Loss: 0.0086\n",
      "Epoch 153/200, Iteration 197/250, Loss: 0.0242\n",
      "Epoch 153/200, Iteration 198/250, Loss: 0.0202\n",
      "Epoch 153/200, Iteration 199/250, Loss: 0.0325\n",
      "Epoch 153/200, Iteration 200/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 153/200, Iteration 202/250, Loss: 0.0132\n",
      "Epoch 153/200, Iteration 203/250, Loss: 0.0133\n",
      "Epoch 153/200, Iteration 204/250, Loss: 0.0108\n",
      "Epoch 153/200, Iteration 205/250, Loss: 0.0119\n",
      "Epoch 153/200, Iteration 206/250, Loss: 0.0243\n",
      "Epoch 153/200, Iteration 207/250, Loss: 0.0080\n",
      "Epoch 153/200, Iteration 208/250, Loss: 0.0157\n",
      "Epoch 153/200, Iteration 209/250, Loss: 0.0102\n",
      "Epoch 153/200, Iteration 210/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 211/250, Loss: 0.0123\n",
      "Epoch 153/200, Iteration 212/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 213/250, Loss: 0.0135\n",
      "Epoch 153/200, Iteration 214/250, Loss: 0.0118\n",
      "Epoch 153/200, Iteration 215/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 216/250, Loss: 0.0149\n",
      "Epoch 153/200, Iteration 217/250, Loss: 0.0118\n",
      "Epoch 153/200, Iteration 218/250, Loss: 0.0206\n",
      "Epoch 153/200, Iteration 219/250, Loss: 0.0098\n",
      "Epoch 153/200, Iteration 220/250, Loss: 0.0101\n",
      "Epoch 153/200, Iteration 221/250, Loss: 0.0178\n",
      "Epoch 153/200, Iteration 222/250, Loss: 0.0103\n",
      "Epoch 153/200, Iteration 223/250, Loss: 0.0143\n",
      "Epoch 153/200, Iteration 224/250, Loss: 0.0089\n",
      "Epoch 153/200, Iteration 225/250, Loss: 0.0131\n",
      "Epoch 153/200, Iteration 226/250, Loss: 0.0138\n",
      "Epoch 153/200, Iteration 227/250, Loss: 0.0078\n",
      "Epoch 153/200, Iteration 228/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 229/250, Loss: 0.0112\n",
      "Epoch 153/200, Iteration 230/250, Loss: 0.0107\n",
      "Epoch 153/200, Iteration 231/250, Loss: 0.0195\n",
      "Epoch 153/200, Iteration 232/250, Loss: 0.0087\n",
      "Epoch 153/200, Iteration 233/250, Loss: 0.0118\n",
      "Epoch 153/200, Iteration 234/250, Loss: 0.0221\n",
      "Epoch 153/200, Iteration 235/250, Loss: 0.0258\n",
      "Epoch 153/200, Iteration 236/250, Loss: 0.0078\n",
      "Epoch 153/200, Iteration 237/250, Loss: 0.0109\n",
      "Epoch 153/200, Iteration 238/250, Loss: 0.0130\n",
      "Epoch 153/200, Iteration 239/250, Loss: 0.0092\n",
      "Epoch 153/200, Iteration 240/250, Loss: 0.0109\n",
      "Epoch 153/200, Iteration 241/250, Loss: 0.0095\n",
      "Epoch 153/200, Iteration 242/250, Loss: 0.0134\n",
      "Epoch 153/200, Iteration 243/250, Loss: 0.0198\n",
      "Epoch 153/200, Iteration 244/250, Loss: 0.0093\n",
      "Epoch 153/200, Iteration 245/250, Loss: 0.0083\n",
      "Epoch 153/200, Iteration 246/250, Loss: 0.0136\n",
      "Epoch 153/200, Iteration 247/250, Loss: 0.0127\n",
      "Epoch 153/200, Iteration 248/250, Loss: 0.0133\n",
      "Epoch 153/200, Iteration 249/250, Loss: 0.0181\n",
      "Epoch 153/200, Iteration 250/250, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 85.59%, Avg loss: 0.006739, MRE: 0.457875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.007206, MRE: 0.547264 \n",
      "\n",
      "Epoch 154/200, Iteration 1/250, Loss: 0.0218\n",
      "Epoch 154/200, Iteration 2/250, Loss: 0.0073\n",
      "Epoch 154/200, Iteration 3/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 4/250, Loss: 0.0173\n",
      "Epoch 154/200, Iteration 5/250, Loss: 0.0282\n",
      "Epoch 154/200, Iteration 6/250, Loss: 0.0252\n",
      "Epoch 154/200, Iteration 7/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 8/250, Loss: 0.0125\n",
      "Epoch 154/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 10/250, Loss: 0.0171\n",
      "Epoch 154/200, Iteration 11/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 12/250, Loss: 0.0374\n",
      "Epoch 154/200, Iteration 13/250, Loss: 0.0339\n",
      "Epoch 154/200, Iteration 14/250, Loss: 0.0269\n",
      "Epoch 154/200, Iteration 15/250, Loss: 0.0105\n",
      "Epoch 154/200, Iteration 16/250, Loss: 0.0087\n",
      "Epoch 154/200, Iteration 17/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 18/250, Loss: 0.0248\n",
      "Epoch 154/200, Iteration 19/250, Loss: 0.0128\n",
      "Epoch 154/200, Iteration 20/250, Loss: 0.0204\n",
      "Epoch 154/200, Iteration 21/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 22/250, Loss: 0.0107\n",
      "Epoch 154/200, Iteration 23/250, Loss: 0.0066\n",
      "Epoch 154/200, Iteration 24/250, Loss: 0.0096\n",
      "Epoch 154/200, Iteration 25/250, Loss: 0.0313\n",
      "Epoch 154/200, Iteration 26/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 27/250, Loss: 0.0167\n",
      "Epoch 154/200, Iteration 28/250, Loss: 0.0119\n",
      "Epoch 154/200, Iteration 29/250, Loss: 0.0075\n",
      "Epoch 154/200, Iteration 30/250, Loss: 0.0103\n",
      "Epoch 154/200, Iteration 31/250, Loss: 0.0071\n",
      "Epoch 154/200, Iteration 32/250, Loss: 0.0189\n",
      "Epoch 154/200, Iteration 33/250, Loss: 0.0175\n",
      "Epoch 154/200, Iteration 34/250, Loss: 0.0077\n",
      "Epoch 154/200, Iteration 35/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 36/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 37/250, Loss: 0.0151\n",
      "Epoch 154/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 39/250, Loss: 0.0146\n",
      "Epoch 154/200, Iteration 40/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 41/250, Loss: 0.0135\n",
      "Epoch 154/200, Iteration 42/250, Loss: 0.0127\n",
      "Epoch 154/200, Iteration 43/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 44/250, Loss: 0.0170\n",
      "Epoch 154/200, Iteration 45/250, Loss: 0.0217\n",
      "Epoch 154/200, Iteration 46/250, Loss: 0.0129\n",
      "Epoch 154/200, Iteration 47/250, Loss: 0.0133\n",
      "Epoch 154/200, Iteration 48/250, Loss: 0.0149\n",
      "Epoch 154/200, Iteration 49/250, Loss: 0.0110\n",
      "Epoch 154/200, Iteration 50/250, Loss: 0.0262\n",
      "Epoch 154/200, Iteration 51/250, Loss: 0.0238\n",
      "Epoch 154/200, Iteration 52/250, Loss: 0.0117\n",
      "Epoch 154/200, Iteration 53/250, Loss: 0.0197\n",
      "Epoch 154/200, Iteration 54/250, Loss: 0.0394\n",
      "Epoch 154/200, Iteration 55/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 56/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 57/250, Loss: 0.0100\n",
      "Epoch 154/200, Iteration 58/250, Loss: 0.0162\n",
      "Epoch 154/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 154/200, Iteration 60/250, Loss: 0.0079\n",
      "Epoch 154/200, Iteration 61/250, Loss: 0.0311\n",
      "Epoch 154/200, Iteration 62/250, Loss: 0.0158\n",
      "Epoch 154/200, Iteration 63/250, Loss: 0.0096\n",
      "Epoch 154/200, Iteration 64/250, Loss: 0.0121\n",
      "Epoch 154/200, Iteration 65/250, Loss: 0.0105\n",
      "Epoch 154/200, Iteration 66/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 67/250, Loss: 0.0292\n",
      "Epoch 154/200, Iteration 68/250, Loss: 0.0191\n",
      "Epoch 154/200, Iteration 69/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 70/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 71/250, Loss: 0.0094\n",
      "Epoch 154/200, Iteration 72/250, Loss: 0.0181\n",
      "Epoch 154/200, Iteration 73/250, Loss: 0.0150\n",
      "Epoch 154/200, Iteration 74/250, Loss: 0.0444\n",
      "Epoch 154/200, Iteration 75/250, Loss: 0.0126\n",
      "Epoch 154/200, Iteration 76/250, Loss: 0.0112\n",
      "Epoch 154/200, Iteration 77/250, Loss: 0.0175\n",
      "Epoch 154/200, Iteration 78/250, Loss: 0.0166\n",
      "Epoch 154/200, Iteration 79/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 80/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 81/250, Loss: 0.0200\n",
      "Epoch 154/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 154/200, Iteration 83/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 154/200, Iteration 85/250, Loss: 0.0150\n",
      "Epoch 154/200, Iteration 86/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 87/250, Loss: 0.0292\n",
      "Epoch 154/200, Iteration 88/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 89/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 90/250, Loss: 0.0131\n",
      "Epoch 154/200, Iteration 91/250, Loss: 0.0209\n",
      "Epoch 154/200, Iteration 92/250, Loss: 0.0134\n",
      "Epoch 154/200, Iteration 93/250, Loss: 0.0150\n",
      "Epoch 154/200, Iteration 94/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 95/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 96/250, Loss: 0.0317\n",
      "Epoch 154/200, Iteration 97/250, Loss: 0.0155\n",
      "Epoch 154/200, Iteration 98/250, Loss: 0.0140\n",
      "Epoch 154/200, Iteration 99/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 100/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 101/250, Loss: 0.0248\n",
      "Epoch 154/200, Iteration 102/250, Loss: 0.0326\n",
      "Epoch 154/200, Iteration 103/250, Loss: 0.0211\n",
      "Epoch 154/200, Iteration 104/250, Loss: 0.0117\n",
      "Epoch 154/200, Iteration 105/250, Loss: 0.0163\n",
      "Epoch 154/200, Iteration 106/250, Loss: 0.0160\n",
      "Epoch 154/200, Iteration 107/250, Loss: 0.0329\n",
      "Epoch 154/200, Iteration 108/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 109/250, Loss: 0.0111\n",
      "Epoch 154/200, Iteration 110/250, Loss: 0.0147\n",
      "Epoch 154/200, Iteration 111/250, Loss: 0.0112\n",
      "Epoch 154/200, Iteration 112/250, Loss: 0.0123\n",
      "Epoch 154/200, Iteration 113/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 114/250, Loss: 0.0104\n",
      "Epoch 154/200, Iteration 115/250, Loss: 0.0165\n",
      "Epoch 154/200, Iteration 116/250, Loss: 0.0070\n",
      "Epoch 154/200, Iteration 117/250, Loss: 0.0197\n",
      "Epoch 154/200, Iteration 118/250, Loss: 0.0193\n",
      "Epoch 154/200, Iteration 119/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 120/250, Loss: 0.0237\n",
      "Epoch 154/200, Iteration 121/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 122/250, Loss: 0.0154\n",
      "Epoch 154/200, Iteration 123/250, Loss: 0.0131\n",
      "Epoch 154/200, Iteration 124/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 125/250, Loss: 0.0231\n",
      "Epoch 154/200, Iteration 126/250, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200, Iteration 127/250, Loss: 0.0162\n",
      "Epoch 154/200, Iteration 128/250, Loss: 0.0176\n",
      "Epoch 154/200, Iteration 129/250, Loss: 0.0109\n",
      "Epoch 154/200, Iteration 130/250, Loss: 0.0075\n",
      "Epoch 154/200, Iteration 131/250, Loss: 0.0163\n",
      "Epoch 154/200, Iteration 132/250, Loss: 0.0129\n",
      "Epoch 154/200, Iteration 133/250, Loss: 0.0107\n",
      "Epoch 154/200, Iteration 134/250, Loss: 0.0116\n",
      "Epoch 154/200, Iteration 135/250, Loss: 0.0172\n",
      "Epoch 154/200, Iteration 136/250, Loss: 0.0096\n",
      "Epoch 154/200, Iteration 137/250, Loss: 0.0235\n",
      "Epoch 154/200, Iteration 138/250, Loss: 0.0208\n",
      "Epoch 154/200, Iteration 139/250, Loss: 0.0079\n",
      "Epoch 154/200, Iteration 140/250, Loss: 0.0307\n",
      "Epoch 154/200, Iteration 141/250, Loss: 0.0229\n",
      "Epoch 154/200, Iteration 142/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 143/250, Loss: 0.0132\n",
      "Epoch 154/200, Iteration 144/250, Loss: 0.0119\n",
      "Epoch 154/200, Iteration 145/250, Loss: 0.0356\n",
      "Epoch 154/200, Iteration 146/250, Loss: 0.0092\n",
      "Epoch 154/200, Iteration 147/250, Loss: 0.0136\n",
      "Epoch 154/200, Iteration 148/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 149/250, Loss: 0.0064\n",
      "Epoch 154/200, Iteration 150/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 151/250, Loss: 0.0071\n",
      "Epoch 154/200, Iteration 152/250, Loss: 0.0060\n",
      "Epoch 154/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 154/200, Iteration 154/250, Loss: 0.0191\n",
      "Epoch 154/200, Iteration 155/250, Loss: 0.0233\n",
      "Epoch 154/200, Iteration 156/250, Loss: 0.0089\n",
      "Epoch 154/200, Iteration 157/250, Loss: 0.0107\n",
      "Epoch 154/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 159/250, Loss: 0.0126\n",
      "Epoch 154/200, Iteration 160/250, Loss: 0.0082\n",
      "Epoch 154/200, Iteration 161/250, Loss: 0.0166\n",
      "Epoch 154/200, Iteration 162/250, Loss: 0.0220\n",
      "Epoch 154/200, Iteration 163/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 164/250, Loss: 0.0088\n",
      "Epoch 154/200, Iteration 165/250, Loss: 0.0111\n",
      "Epoch 154/200, Iteration 166/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 167/250, Loss: 0.0157\n",
      "Epoch 154/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 154/200, Iteration 169/250, Loss: 0.0123\n",
      "Epoch 154/200, Iteration 170/250, Loss: 0.0130\n",
      "Epoch 154/200, Iteration 171/250, Loss: 0.0093\n",
      "Epoch 154/200, Iteration 172/250, Loss: 0.0141\n",
      "Epoch 154/200, Iteration 173/250, Loss: 0.0359\n",
      "Epoch 154/200, Iteration 174/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 175/250, Loss: 0.0193\n",
      "Epoch 154/200, Iteration 176/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 177/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 178/250, Loss: 0.0118\n",
      "Epoch 154/200, Iteration 179/250, Loss: 0.0166\n",
      "Epoch 154/200, Iteration 180/250, Loss: 0.0283\n",
      "Epoch 154/200, Iteration 181/250, Loss: 0.0136\n",
      "Epoch 154/200, Iteration 182/250, Loss: 0.0196\n",
      "Epoch 154/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 154/200, Iteration 184/250, Loss: 0.0145\n",
      "Epoch 154/200, Iteration 185/250, Loss: 0.0147\n",
      "Epoch 154/200, Iteration 186/250, Loss: 0.0103\n",
      "Epoch 154/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 188/250, Loss: 0.0134\n",
      "Epoch 154/200, Iteration 189/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 190/250, Loss: 0.0182\n",
      "Epoch 154/200, Iteration 191/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 192/250, Loss: 0.0156\n",
      "Epoch 154/200, Iteration 193/250, Loss: 0.0103\n",
      "Epoch 154/200, Iteration 194/250, Loss: 0.0435\n",
      "Epoch 154/200, Iteration 195/250, Loss: 0.0185\n",
      "Epoch 154/200, Iteration 196/250, Loss: 0.0081\n",
      "Epoch 154/200, Iteration 197/250, Loss: 0.0114\n",
      "Epoch 154/200, Iteration 198/250, Loss: 0.0069\n",
      "Epoch 154/200, Iteration 199/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 200/250, Loss: 0.0357\n",
      "Epoch 154/200, Iteration 201/250, Loss: 0.0111\n",
      "Epoch 154/200, Iteration 202/250, Loss: 0.0200\n",
      "Epoch 154/200, Iteration 203/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 204/250, Loss: 0.0437\n",
      "Epoch 154/200, Iteration 205/250, Loss: 0.0177\n",
      "Epoch 154/200, Iteration 206/250, Loss: 0.0199\n",
      "Epoch 154/200, Iteration 207/250, Loss: 0.0134\n",
      "Epoch 154/200, Iteration 208/250, Loss: 0.0101\n",
      "Epoch 154/200, Iteration 209/250, Loss: 0.0086\n",
      "Epoch 154/200, Iteration 210/250, Loss: 0.0336\n",
      "Epoch 154/200, Iteration 211/250, Loss: 0.0247\n",
      "Epoch 154/200, Iteration 212/250, Loss: 0.0085\n",
      "Epoch 154/200, Iteration 213/250, Loss: 0.0201\n",
      "Epoch 154/200, Iteration 214/250, Loss: 0.0195\n",
      "Epoch 154/200, Iteration 215/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 216/250, Loss: 0.0104\n",
      "Epoch 154/200, Iteration 217/250, Loss: 0.0065\n",
      "Epoch 154/200, Iteration 218/250, Loss: 0.0362\n",
      "Epoch 154/200, Iteration 219/250, Loss: 0.0122\n",
      "Epoch 154/200, Iteration 220/250, Loss: 0.0088\n",
      "Epoch 154/200, Iteration 221/250, Loss: 0.0108\n",
      "Epoch 154/200, Iteration 222/250, Loss: 0.0099\n",
      "Epoch 154/200, Iteration 223/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 224/250, Loss: 0.0095\n",
      "Epoch 154/200, Iteration 225/250, Loss: 0.0216\n",
      "Epoch 154/200, Iteration 226/250, Loss: 0.0123\n",
      "Epoch 154/200, Iteration 227/250, Loss: 0.0080\n",
      "Epoch 154/200, Iteration 228/250, Loss: 0.0129\n",
      "Epoch 154/200, Iteration 229/250, Loss: 0.0098\n",
      "Epoch 154/200, Iteration 230/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 231/250, Loss: 0.0097\n",
      "Epoch 154/200, Iteration 232/250, Loss: 0.0096\n",
      "Epoch 154/200, Iteration 233/250, Loss: 0.0084\n",
      "Epoch 154/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 154/200, Iteration 235/250, Loss: 0.0258\n",
      "Epoch 154/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 154/200, Iteration 237/250, Loss: 0.0121\n",
      "Epoch 154/200, Iteration 238/250, Loss: 0.0086\n",
      "Epoch 154/200, Iteration 239/250, Loss: 0.0137\n",
      "Epoch 154/200, Iteration 240/250, Loss: 0.0152\n",
      "Epoch 154/200, Iteration 241/250, Loss: 0.0246\n",
      "Epoch 154/200, Iteration 242/250, Loss: 0.0176\n",
      "Epoch 154/200, Iteration 243/250, Loss: 0.0186\n",
      "Epoch 154/200, Iteration 244/250, Loss: 0.0102\n",
      "Epoch 154/200, Iteration 245/250, Loss: 0.0270\n",
      "Epoch 154/200, Iteration 246/250, Loss: 0.0177\n",
      "Epoch 154/200, Iteration 247/250, Loss: 0.0078\n",
      "Epoch 154/200, Iteration 248/250, Loss: 0.0105\n",
      "Epoch 154/200, Iteration 249/250, Loss: 0.0198\n",
      "Epoch 154/200, Iteration 250/250, Loss: 0.0084\n",
      "Train Error: \n",
      " Accuracy: 81.79%, Avg loss: 0.007132, MRE: 0.503063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.75%, Avg loss: 0.007569, MRE: 0.526285 \n",
      "\n",
      "Epoch 155/200, Iteration 1/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 2/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 3/250, Loss: 0.0142\n",
      "Epoch 155/200, Iteration 4/250, Loss: 0.0186\n",
      "Epoch 155/200, Iteration 5/250, Loss: 0.0118\n",
      "Epoch 155/200, Iteration 6/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 7/250, Loss: 0.0184\n",
      "Epoch 155/200, Iteration 8/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 9/250, Loss: 0.0058\n",
      "Epoch 155/200, Iteration 10/250, Loss: 0.0180\n",
      "Epoch 155/200, Iteration 11/250, Loss: 0.0110\n",
      "Epoch 155/200, Iteration 12/250, Loss: 0.0128\n",
      "Epoch 155/200, Iteration 13/250, Loss: 0.0084\n",
      "Epoch 155/200, Iteration 14/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 15/250, Loss: 0.0145\n",
      "Epoch 155/200, Iteration 16/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 17/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 18/250, Loss: 0.0201\n",
      "Epoch 155/200, Iteration 19/250, Loss: 0.0105\n",
      "Epoch 155/200, Iteration 20/250, Loss: 0.0138\n",
      "Epoch 155/200, Iteration 21/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 22/250, Loss: 0.0107\n",
      "Epoch 155/200, Iteration 23/250, Loss: 0.0223\n",
      "Epoch 155/200, Iteration 24/250, Loss: 0.0206\n",
      "Epoch 155/200, Iteration 25/250, Loss: 0.0189\n",
      "Epoch 155/200, Iteration 26/250, Loss: 0.0232\n",
      "Epoch 155/200, Iteration 27/250, Loss: 0.0159\n",
      "Epoch 155/200, Iteration 28/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 29/250, Loss: 0.0239\n",
      "Epoch 155/200, Iteration 30/250, Loss: 0.0306\n",
      "Epoch 155/200, Iteration 31/250, Loss: 0.0082\n",
      "Epoch 155/200, Iteration 32/250, Loss: 0.0142\n",
      "Epoch 155/200, Iteration 33/250, Loss: 0.0069\n",
      "Epoch 155/200, Iteration 34/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 35/250, Loss: 0.0097\n",
      "Epoch 155/200, Iteration 36/250, Loss: 0.0147\n",
      "Epoch 155/200, Iteration 37/250, Loss: 0.0142\n",
      "Epoch 155/200, Iteration 38/250, Loss: 0.0183\n",
      "Epoch 155/200, Iteration 39/250, Loss: 0.0217\n",
      "Epoch 155/200, Iteration 40/250, Loss: 0.0159\n",
      "Epoch 155/200, Iteration 41/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 42/250, Loss: 0.0226\n",
      "Epoch 155/200, Iteration 43/250, Loss: 0.0184\n",
      "Epoch 155/200, Iteration 44/250, Loss: 0.0165\n",
      "Epoch 155/200, Iteration 45/250, Loss: 0.0136\n",
      "Epoch 155/200, Iteration 46/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 47/250, Loss: 0.0177\n",
      "Epoch 155/200, Iteration 48/250, Loss: 0.0117\n",
      "Epoch 155/200, Iteration 49/250, Loss: 0.0300\n",
      "Epoch 155/200, Iteration 50/250, Loss: 0.0136\n",
      "Epoch 155/200, Iteration 51/250, Loss: 0.0159\n",
      "Epoch 155/200, Iteration 52/250, Loss: 0.0087\n",
      "Epoch 155/200, Iteration 53/250, Loss: 0.0091\n",
      "Epoch 155/200, Iteration 54/250, Loss: 0.0167\n",
      "Epoch 155/200, Iteration 55/250, Loss: 0.0107\n",
      "Epoch 155/200, Iteration 56/250, Loss: 0.0258\n",
      "Epoch 155/200, Iteration 57/250, Loss: 0.0161\n",
      "Epoch 155/200, Iteration 58/250, Loss: 0.0345\n",
      "Epoch 155/200, Iteration 59/250, Loss: 0.0182\n",
      "Epoch 155/200, Iteration 60/250, Loss: 0.0131\n",
      "Epoch 155/200, Iteration 61/250, Loss: 0.0068\n",
      "Epoch 155/200, Iteration 62/250, Loss: 0.0071\n",
      "Epoch 155/200, Iteration 63/250, Loss: 0.0122\n",
      "Epoch 155/200, Iteration 64/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 65/250, Loss: 0.0083\n",
      "Epoch 155/200, Iteration 66/250, Loss: 0.0413\n",
      "Epoch 155/200, Iteration 67/250, Loss: 0.0124\n",
      "Epoch 155/200, Iteration 68/250, Loss: 0.0186\n",
      "Epoch 155/200, Iteration 69/250, Loss: 0.0078\n",
      "Epoch 155/200, Iteration 70/250, Loss: 0.0192\n",
      "Epoch 155/200, Iteration 71/250, Loss: 0.0084\n",
      "Epoch 155/200, Iteration 72/250, Loss: 0.0228\n",
      "Epoch 155/200, Iteration 73/250, Loss: 0.0125\n",
      "Epoch 155/200, Iteration 74/250, Loss: 0.0172\n",
      "Epoch 155/200, Iteration 75/250, Loss: 0.0182\n",
      "Epoch 155/200, Iteration 76/250, Loss: 0.0290\n",
      "Epoch 155/200, Iteration 77/250, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200, Iteration 78/250, Loss: 0.0208\n",
      "Epoch 155/200, Iteration 79/250, Loss: 0.0403\n",
      "Epoch 155/200, Iteration 80/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 81/250, Loss: 0.0124\n",
      "Epoch 155/200, Iteration 82/250, Loss: 0.0162\n",
      "Epoch 155/200, Iteration 83/250, Loss: 0.0271\n",
      "Epoch 155/200, Iteration 84/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 85/250, Loss: 0.0074\n",
      "Epoch 155/200, Iteration 86/250, Loss: 0.0202\n",
      "Epoch 155/200, Iteration 87/250, Loss: 0.0125\n",
      "Epoch 155/200, Iteration 88/250, Loss: 0.0137\n",
      "Epoch 155/200, Iteration 89/250, Loss: 0.0091\n",
      "Epoch 155/200, Iteration 90/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 91/250, Loss: 0.0267\n",
      "Epoch 155/200, Iteration 92/250, Loss: 0.0168\n",
      "Epoch 155/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 94/250, Loss: 0.0106\n",
      "Epoch 155/200, Iteration 95/250, Loss: 0.0071\n",
      "Epoch 155/200, Iteration 96/250, Loss: 0.0171\n",
      "Epoch 155/200, Iteration 97/250, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 98/250, Loss: 0.0285\n",
      "Epoch 155/200, Iteration 99/250, Loss: 0.0113\n",
      "Epoch 155/200, Iteration 100/250, Loss: 0.0304\n",
      "Epoch 155/200, Iteration 101/250, Loss: 0.0283\n",
      "Epoch 155/200, Iteration 102/250, Loss: 0.0080\n",
      "Epoch 155/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 104/250, Loss: 0.0284\n",
      "Epoch 155/200, Iteration 105/250, Loss: 0.0097\n",
      "Epoch 155/200, Iteration 106/250, Loss: 0.0145\n",
      "Epoch 155/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 155/200, Iteration 108/250, Loss: 0.0144\n",
      "Epoch 155/200, Iteration 109/250, Loss: 0.0224\n",
      "Epoch 155/200, Iteration 110/250, Loss: 0.0083\n",
      "Epoch 155/200, Iteration 111/250, Loss: 0.0099\n",
      "Epoch 155/200, Iteration 112/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 113/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 114/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 115/250, Loss: 0.0388\n",
      "Epoch 155/200, Iteration 116/250, Loss: 0.0180\n",
      "Epoch 155/200, Iteration 117/250, Loss: 0.0097\n",
      "Epoch 155/200, Iteration 118/250, Loss: 0.0113\n",
      "Epoch 155/200, Iteration 119/250, Loss: 0.0231\n",
      "Epoch 155/200, Iteration 120/250, Loss: 0.0129\n",
      "Epoch 155/200, Iteration 121/250, Loss: 0.0243\n",
      "Epoch 155/200, Iteration 122/250, Loss: 0.0105\n",
      "Epoch 155/200, Iteration 123/250, Loss: 0.0097\n",
      "Epoch 155/200, Iteration 124/250, Loss: 0.0119\n",
      "Epoch 155/200, Iteration 125/250, Loss: 0.0111\n",
      "Epoch 155/200, Iteration 126/250, Loss: 0.0146\n",
      "Epoch 155/200, Iteration 127/250, Loss: 0.0096\n",
      "Epoch 155/200, Iteration 128/250, Loss: 0.0064\n",
      "Epoch 155/200, Iteration 129/250, Loss: 0.0164\n",
      "Epoch 155/200, Iteration 130/250, Loss: 0.0180\n",
      "Epoch 155/200, Iteration 131/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 132/250, Loss: 0.0147\n",
      "Epoch 155/200, Iteration 133/250, Loss: 0.0242\n",
      "Epoch 155/200, Iteration 134/250, Loss: 0.0062\n",
      "Epoch 155/200, Iteration 135/250, Loss: 0.0366\n",
      "Epoch 155/200, Iteration 136/250, Loss: 0.0190\n",
      "Epoch 155/200, Iteration 137/250, Loss: 0.0217\n",
      "Epoch 155/200, Iteration 138/250, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 139/250, Loss: 0.0140\n",
      "Epoch 155/200, Iteration 140/250, Loss: 0.0244\n",
      "Epoch 155/200, Iteration 141/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 142/250, Loss: 0.0218\n",
      "Epoch 155/200, Iteration 143/250, Loss: 0.0157\n",
      "Epoch 155/200, Iteration 144/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 145/250, Loss: 0.0228\n",
      "Epoch 155/200, Iteration 146/250, Loss: 0.0278\n",
      "Epoch 155/200, Iteration 147/250, Loss: 0.0219\n",
      "Epoch 155/200, Iteration 148/250, Loss: 0.0129\n",
      "Epoch 155/200, Iteration 149/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 150/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 151/250, Loss: 0.0160\n",
      "Epoch 155/200, Iteration 152/250, Loss: 0.0259\n",
      "Epoch 155/200, Iteration 153/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 154/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 155/250, Loss: 0.0174\n",
      "Epoch 155/200, Iteration 156/250, Loss: 0.0078\n",
      "Epoch 155/200, Iteration 157/250, Loss: 0.0232\n",
      "Epoch 155/200, Iteration 158/250, Loss: 0.0317\n",
      "Epoch 155/200, Iteration 159/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 160/250, Loss: 0.0120\n",
      "Epoch 155/200, Iteration 161/250, Loss: 0.0161\n",
      "Epoch 155/200, Iteration 162/250, Loss: 0.0068\n",
      "Epoch 155/200, Iteration 163/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 164/250, Loss: 0.0115\n",
      "Epoch 155/200, Iteration 165/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 166/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 167/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 168/250, Loss: 0.0227\n",
      "Epoch 155/200, Iteration 169/250, Loss: 0.0362\n",
      "Epoch 155/200, Iteration 170/250, Loss: 0.0123\n",
      "Epoch 155/200, Iteration 171/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 172/250, Loss: 0.0083\n",
      "Epoch 155/200, Iteration 173/250, Loss: 0.0111\n",
      "Epoch 155/200, Iteration 174/250, Loss: 0.0071\n",
      "Epoch 155/200, Iteration 175/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 176/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 177/250, Loss: 0.0192\n",
      "Epoch 155/200, Iteration 178/250, Loss: 0.0095\n",
      "Epoch 155/200, Iteration 179/250, Loss: 0.0063\n",
      "Epoch 155/200, Iteration 180/250, Loss: 0.0134\n",
      "Epoch 155/200, Iteration 181/250, Loss: 0.0110\n",
      "Epoch 155/200, Iteration 182/250, Loss: 0.0136\n",
      "Epoch 155/200, Iteration 183/250, Loss: 0.0248\n",
      "Epoch 155/200, Iteration 184/250, Loss: 0.0385\n",
      "Epoch 155/200, Iteration 185/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 186/250, Loss: 0.0362\n",
      "Epoch 155/200, Iteration 187/250, Loss: 0.0277\n",
      "Epoch 155/200, Iteration 188/250, Loss: 0.0166\n",
      "Epoch 155/200, Iteration 189/250, Loss: 0.0070\n",
      "Epoch 155/200, Iteration 190/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 191/250, Loss: 0.0091\n",
      "Epoch 155/200, Iteration 192/250, Loss: 0.0116\n",
      "Epoch 155/200, Iteration 193/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 194/250, Loss: 0.0151\n",
      "Epoch 155/200, Iteration 195/250, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 196/250, Loss: 0.0088\n",
      "Epoch 155/200, Iteration 197/250, Loss: 0.0154\n",
      "Epoch 155/200, Iteration 198/250, Loss: 0.0185\n",
      "Epoch 155/200, Iteration 199/250, Loss: 0.0082\n",
      "Epoch 155/200, Iteration 200/250, Loss: 0.0193\n",
      "Epoch 155/200, Iteration 201/250, Loss: 0.0100\n",
      "Epoch 155/200, Iteration 202/250, Loss: 0.0125\n",
      "Epoch 155/200, Iteration 203/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 204/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 205/250, Loss: 0.0236\n",
      "Epoch 155/200, Iteration 206/250, Loss: 0.0234\n",
      "Epoch 155/200, Iteration 207/250, Loss: 0.0249\n",
      "Epoch 155/200, Iteration 208/250, Loss: 0.0073\n",
      "Epoch 155/200, Iteration 209/250, Loss: 0.0137\n",
      "Epoch 155/200, Iteration 210/250, Loss: 0.0404\n",
      "Epoch 155/200, Iteration 211/250, Loss: 0.0124\n",
      "Epoch 155/200, Iteration 212/250, Loss: 0.0202\n",
      "Epoch 155/200, Iteration 213/250, Loss: 0.0092\n",
      "Epoch 155/200, Iteration 214/250, Loss: 0.0258\n",
      "Epoch 155/200, Iteration 215/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 216/250, Loss: 0.0091\n",
      "Epoch 155/200, Iteration 217/250, Loss: 0.0081\n",
      "Epoch 155/200, Iteration 218/250, Loss: 0.0105\n",
      "Epoch 155/200, Iteration 219/250, Loss: 0.0165\n",
      "Epoch 155/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 155/200, Iteration 221/250, Loss: 0.0113\n",
      "Epoch 155/200, Iteration 222/250, Loss: 0.0170\n",
      "Epoch 155/200, Iteration 223/250, Loss: 0.0079\n",
      "Epoch 155/200, Iteration 224/250, Loss: 0.0098\n",
      "Epoch 155/200, Iteration 225/250, Loss: 0.0174\n",
      "Epoch 155/200, Iteration 226/250, Loss: 0.0162\n",
      "Epoch 155/200, Iteration 227/250, Loss: 0.0121\n",
      "Epoch 155/200, Iteration 228/250, Loss: 0.0200\n",
      "Epoch 155/200, Iteration 229/250, Loss: 0.0170\n",
      "Epoch 155/200, Iteration 230/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 231/250, Loss: 0.0406\n",
      "Epoch 155/200, Iteration 232/250, Loss: 0.0169\n",
      "Epoch 155/200, Iteration 233/250, Loss: 0.0093\n",
      "Epoch 155/200, Iteration 234/250, Loss: 0.0160\n",
      "Epoch 155/200, Iteration 235/250, Loss: 0.0133\n",
      "Epoch 155/200, Iteration 236/250, Loss: 0.0102\n",
      "Epoch 155/200, Iteration 237/250, Loss: 0.0195\n",
      "Epoch 155/200, Iteration 238/250, Loss: 0.0094\n",
      "Epoch 155/200, Iteration 239/250, Loss: 0.0164\n",
      "Epoch 155/200, Iteration 240/250, Loss: 0.0053\n",
      "Epoch 155/200, Iteration 241/250, Loss: 0.0122\n",
      "Epoch 155/200, Iteration 242/250, Loss: 0.0176\n",
      "Epoch 155/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 155/200, Iteration 244/250, Loss: 0.0143\n",
      "Epoch 155/200, Iteration 245/250, Loss: 0.0148\n",
      "Epoch 155/200, Iteration 246/250, Loss: 0.0104\n",
      "Epoch 155/200, Iteration 247/250, Loss: 0.0127\n",
      "Epoch 155/200, Iteration 248/250, Loss: 0.0164\n",
      "Epoch 155/200, Iteration 249/250, Loss: 0.0174\n",
      "Epoch 155/200, Iteration 250/250, Loss: 0.0317\n",
      "Train Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.007051, MRE: 0.509381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.007531, MRE: 0.529388 \n",
      "\n",
      "Epoch 156/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 2/250, Loss: 0.0096\n",
      "Epoch 156/200, Iteration 3/250, Loss: 0.0351\n",
      "Epoch 156/200, Iteration 4/250, Loss: 0.0102\n",
      "Epoch 156/200, Iteration 5/250, Loss: 0.0071\n",
      "Epoch 156/200, Iteration 6/250, Loss: 0.0153\n",
      "Epoch 156/200, Iteration 7/250, Loss: 0.0188\n",
      "Epoch 156/200, Iteration 8/250, Loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200, Iteration 9/250, Loss: 0.0265\n",
      "Epoch 156/200, Iteration 10/250, Loss: 0.0210\n",
      "Epoch 156/200, Iteration 11/250, Loss: 0.0115\n",
      "Epoch 156/200, Iteration 12/250, Loss: 0.0210\n",
      "Epoch 156/200, Iteration 13/250, Loss: 0.0079\n",
      "Epoch 156/200, Iteration 14/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 15/250, Loss: 0.0210\n",
      "Epoch 156/200, Iteration 16/250, Loss: 0.0147\n",
      "Epoch 156/200, Iteration 17/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 18/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 19/250, Loss: 0.0099\n",
      "Epoch 156/200, Iteration 20/250, Loss: 0.0218\n",
      "Epoch 156/200, Iteration 21/250, Loss: 0.0435\n",
      "Epoch 156/200, Iteration 22/250, Loss: 0.0090\n",
      "Epoch 156/200, Iteration 23/250, Loss: 0.0110\n",
      "Epoch 156/200, Iteration 24/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 25/250, Loss: 0.0115\n",
      "Epoch 156/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 27/250, Loss: 0.0362\n",
      "Epoch 156/200, Iteration 28/250, Loss: 0.0143\n",
      "Epoch 156/200, Iteration 29/250, Loss: 0.0065\n",
      "Epoch 156/200, Iteration 30/250, Loss: 0.0148\n",
      "Epoch 156/200, Iteration 31/250, Loss: 0.0209\n",
      "Epoch 156/200, Iteration 32/250, Loss: 0.0108\n",
      "Epoch 156/200, Iteration 33/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 34/250, Loss: 0.0150\n",
      "Epoch 156/200, Iteration 35/250, Loss: 0.0097\n",
      "Epoch 156/200, Iteration 36/250, Loss: 0.0211\n",
      "Epoch 156/200, Iteration 37/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 38/250, Loss: 0.0319\n",
      "Epoch 156/200, Iteration 39/250, Loss: 0.0144\n",
      "Epoch 156/200, Iteration 40/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 41/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 42/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 43/250, Loss: 0.0268\n",
      "Epoch 156/200, Iteration 44/250, Loss: 0.0167\n",
      "Epoch 156/200, Iteration 45/250, Loss: 0.0228\n",
      "Epoch 156/200, Iteration 46/250, Loss: 0.0291\n",
      "Epoch 156/200, Iteration 47/250, Loss: 0.0422\n",
      "Epoch 156/200, Iteration 48/250, Loss: 0.0071\n",
      "Epoch 156/200, Iteration 49/250, Loss: 0.0084\n",
      "Epoch 156/200, Iteration 50/250, Loss: 0.0208\n",
      "Epoch 156/200, Iteration 51/250, Loss: 0.0140\n",
      "Epoch 156/200, Iteration 52/250, Loss: 0.0075\n",
      "Epoch 156/200, Iteration 53/250, Loss: 0.0252\n",
      "Epoch 156/200, Iteration 54/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 56/250, Loss: 0.0146\n",
      "Epoch 156/200, Iteration 57/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 58/250, Loss: 0.0081\n",
      "Epoch 156/200, Iteration 59/250, Loss: 0.0180\n",
      "Epoch 156/200, Iteration 60/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 61/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 62/250, Loss: 0.0203\n",
      "Epoch 156/200, Iteration 63/250, Loss: 0.0147\n",
      "Epoch 156/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 156/200, Iteration 65/250, Loss: 0.0245\n",
      "Epoch 156/200, Iteration 66/250, Loss: 0.0119\n",
      "Epoch 156/200, Iteration 67/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 68/250, Loss: 0.0130\n",
      "Epoch 156/200, Iteration 69/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 70/250, Loss: 0.0245\n",
      "Epoch 156/200, Iteration 71/250, Loss: 0.0236\n",
      "Epoch 156/200, Iteration 72/250, Loss: 0.0154\n",
      "Epoch 156/200, Iteration 73/250, Loss: 0.0168\n",
      "Epoch 156/200, Iteration 74/250, Loss: 0.0169\n",
      "Epoch 156/200, Iteration 75/250, Loss: 0.0072\n",
      "Epoch 156/200, Iteration 76/250, Loss: 0.0291\n",
      "Epoch 156/200, Iteration 77/250, Loss: 0.0148\n",
      "Epoch 156/200, Iteration 78/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 79/250, Loss: 0.0144\n",
      "Epoch 156/200, Iteration 80/250, Loss: 0.0269\n",
      "Epoch 156/200, Iteration 81/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 82/250, Loss: 0.0055\n",
      "Epoch 156/200, Iteration 83/250, Loss: 0.0199\n",
      "Epoch 156/200, Iteration 84/250, Loss: 0.0375\n",
      "Epoch 156/200, Iteration 85/250, Loss: 0.0136\n",
      "Epoch 156/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 156/200, Iteration 87/250, Loss: 0.0098\n",
      "Epoch 156/200, Iteration 88/250, Loss: 0.0165\n",
      "Epoch 156/200, Iteration 89/250, Loss: 0.0138\n",
      "Epoch 156/200, Iteration 90/250, Loss: 0.0095\n",
      "Epoch 156/200, Iteration 91/250, Loss: 0.0140\n",
      "Epoch 156/200, Iteration 92/250, Loss: 0.0080\n",
      "Epoch 156/200, Iteration 93/250, Loss: 0.0088\n",
      "Epoch 156/200, Iteration 94/250, Loss: 0.0078\n",
      "Epoch 156/200, Iteration 95/250, Loss: 0.0090\n",
      "Epoch 156/200, Iteration 96/250, Loss: 0.0116\n",
      "Epoch 156/200, Iteration 97/250, Loss: 0.0202\n",
      "Epoch 156/200, Iteration 98/250, Loss: 0.0245\n",
      "Epoch 156/200, Iteration 99/250, Loss: 0.0218\n",
      "Epoch 156/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 101/250, Loss: 0.0121\n",
      "Epoch 156/200, Iteration 102/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 103/250, Loss: 0.0209\n",
      "Epoch 156/200, Iteration 104/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 105/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 106/250, Loss: 0.0185\n",
      "Epoch 156/200, Iteration 107/250, Loss: 0.0080\n",
      "Epoch 156/200, Iteration 108/250, Loss: 0.0185\n",
      "Epoch 156/200, Iteration 109/250, Loss: 0.0263\n",
      "Epoch 156/200, Iteration 110/250, Loss: 0.0268\n",
      "Epoch 156/200, Iteration 111/250, Loss: 0.0185\n",
      "Epoch 156/200, Iteration 112/250, Loss: 0.0089\n",
      "Epoch 156/200, Iteration 113/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 114/250, Loss: 0.0098\n",
      "Epoch 156/200, Iteration 115/250, Loss: 0.0073\n",
      "Epoch 156/200, Iteration 116/250, Loss: 0.0079\n",
      "Epoch 156/200, Iteration 117/250, Loss: 0.0111\n",
      "Epoch 156/200, Iteration 118/250, Loss: 0.0119\n",
      "Epoch 156/200, Iteration 119/250, Loss: 0.0162\n",
      "Epoch 156/200, Iteration 120/250, Loss: 0.0156\n",
      "Epoch 156/200, Iteration 121/250, Loss: 0.0091\n",
      "Epoch 156/200, Iteration 122/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 123/250, Loss: 0.0164\n",
      "Epoch 156/200, Iteration 124/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 125/250, Loss: 0.0279\n",
      "Epoch 156/200, Iteration 126/250, Loss: 0.0168\n",
      "Epoch 156/200, Iteration 127/250, Loss: 0.0112\n",
      "Epoch 156/200, Iteration 128/250, Loss: 0.0231\n",
      "Epoch 156/200, Iteration 129/250, Loss: 0.0135\n",
      "Epoch 156/200, Iteration 130/250, Loss: 0.0078\n",
      "Epoch 156/200, Iteration 131/250, Loss: 0.0150\n",
      "Epoch 156/200, Iteration 132/250, Loss: 0.0142\n",
      "Epoch 156/200, Iteration 133/250, Loss: 0.0123\n",
      "Epoch 156/200, Iteration 134/250, Loss: 0.0218\n",
      "Epoch 156/200, Iteration 135/250, Loss: 0.0122\n",
      "Epoch 156/200, Iteration 136/250, Loss: 0.0310\n",
      "Epoch 156/200, Iteration 137/250, Loss: 0.0272\n",
      "Epoch 156/200, Iteration 138/250, Loss: 0.0127\n",
      "Epoch 156/200, Iteration 139/250, Loss: 0.0107\n",
      "Epoch 156/200, Iteration 140/250, Loss: 0.0090\n",
      "Epoch 156/200, Iteration 141/250, Loss: 0.0184\n",
      "Epoch 156/200, Iteration 142/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 143/250, Loss: 0.0249\n",
      "Epoch 156/200, Iteration 144/250, Loss: 0.0158\n",
      "Epoch 156/200, Iteration 145/250, Loss: 0.0260\n",
      "Epoch 156/200, Iteration 146/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 147/250, Loss: 0.0117\n",
      "Epoch 156/200, Iteration 148/250, Loss: 0.0139\n",
      "Epoch 156/200, Iteration 149/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 150/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 151/250, Loss: 0.0159\n",
      "Epoch 156/200, Iteration 152/250, Loss: 0.0137\n",
      "Epoch 156/200, Iteration 153/250, Loss: 0.0124\n",
      "Epoch 156/200, Iteration 154/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 155/250, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 156/250, Loss: 0.0062\n",
      "Epoch 156/200, Iteration 157/250, Loss: 0.0130\n",
      "Epoch 156/200, Iteration 158/250, Loss: 0.0089\n",
      "Epoch 156/200, Iteration 159/250, Loss: 0.0082\n",
      "Epoch 156/200, Iteration 160/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 161/250, Loss: 0.0289\n",
      "Epoch 156/200, Iteration 162/250, Loss: 0.0080\n",
      "Epoch 156/200, Iteration 163/250, Loss: 0.0236\n",
      "Epoch 156/200, Iteration 164/250, Loss: 0.0134\n",
      "Epoch 156/200, Iteration 165/250, Loss: 0.0300\n",
      "Epoch 156/200, Iteration 166/250, Loss: 0.0179\n",
      "Epoch 156/200, Iteration 167/250, Loss: 0.0213\n",
      "Epoch 156/200, Iteration 168/250, Loss: 0.0102\n",
      "Epoch 156/200, Iteration 169/250, Loss: 0.0178\n",
      "Epoch 156/200, Iteration 170/250, Loss: 0.0208\n",
      "Epoch 156/200, Iteration 171/250, Loss: 0.0248\n",
      "Epoch 156/200, Iteration 172/250, Loss: 0.0165\n",
      "Epoch 156/200, Iteration 173/250, Loss: 0.0133\n",
      "Epoch 156/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 156/200, Iteration 175/250, Loss: 0.0169\n",
      "Epoch 156/200, Iteration 176/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 177/250, Loss: 0.0150\n",
      "Epoch 156/200, Iteration 178/250, Loss: 0.0193\n",
      "Epoch 156/200, Iteration 179/250, Loss: 0.0200\n",
      "Epoch 156/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 156/200, Iteration 181/250, Loss: 0.0105\n",
      "Epoch 156/200, Iteration 182/250, Loss: 0.0145\n",
      "Epoch 156/200, Iteration 183/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 184/250, Loss: 0.0161\n",
      "Epoch 156/200, Iteration 185/250, Loss: 0.0077\n",
      "Epoch 156/200, Iteration 186/250, Loss: 0.0109\n",
      "Epoch 156/200, Iteration 187/250, Loss: 0.0166\n",
      "Epoch 156/200, Iteration 188/250, Loss: 0.0084\n",
      "Epoch 156/200, Iteration 189/250, Loss: 0.0098\n",
      "Epoch 156/200, Iteration 190/250, Loss: 0.0222\n",
      "Epoch 156/200, Iteration 191/250, Loss: 0.0129\n",
      "Epoch 156/200, Iteration 192/250, Loss: 0.0075\n",
      "Epoch 156/200, Iteration 193/250, Loss: 0.0079\n",
      "Epoch 156/200, Iteration 194/250, Loss: 0.0148\n",
      "Epoch 156/200, Iteration 195/250, Loss: 0.0197\n",
      "Epoch 156/200, Iteration 196/250, Loss: 0.0089\n",
      "Epoch 156/200, Iteration 197/250, Loss: 0.0263\n",
      "Epoch 156/200, Iteration 198/250, Loss: 0.0059\n",
      "Epoch 156/200, Iteration 199/250, Loss: 0.0088\n",
      "Epoch 156/200, Iteration 200/250, Loss: 0.0076\n",
      "Epoch 156/200, Iteration 201/250, Loss: 0.0187\n",
      "Epoch 156/200, Iteration 202/250, Loss: 0.0104\n",
      "Epoch 156/200, Iteration 203/250, Loss: 0.0141\n",
      "Epoch 156/200, Iteration 204/250, Loss: 0.0134\n",
      "Epoch 156/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 156/200, Iteration 206/250, Loss: 0.0103\n",
      "Epoch 156/200, Iteration 207/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 208/250, Loss: 0.0154\n",
      "Epoch 156/200, Iteration 209/250, Loss: 0.0222\n",
      "Epoch 156/200, Iteration 210/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 211/250, Loss: 0.0297\n",
      "Epoch 156/200, Iteration 212/250, Loss: 0.0056\n",
      "Epoch 156/200, Iteration 213/250, Loss: 0.0195\n",
      "Epoch 156/200, Iteration 214/250, Loss: 0.0086\n",
      "Epoch 156/200, Iteration 215/250, Loss: 0.0158\n",
      "Epoch 156/200, Iteration 216/250, Loss: 0.0277\n",
      "Epoch 156/200, Iteration 217/250, Loss: 0.0119\n",
      "Epoch 156/200, Iteration 218/250, Loss: 0.0132\n",
      "Epoch 156/200, Iteration 219/250, Loss: 0.0341\n",
      "Epoch 156/200, Iteration 220/250, Loss: 0.0104\n",
      "Epoch 156/200, Iteration 221/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 222/250, Loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200, Iteration 223/250, Loss: 0.0140\n",
      "Epoch 156/200, Iteration 224/250, Loss: 0.0156\n",
      "Epoch 156/200, Iteration 225/250, Loss: 0.0169\n",
      "Epoch 156/200, Iteration 226/250, Loss: 0.0093\n",
      "Epoch 156/200, Iteration 227/250, Loss: 0.0227\n",
      "Epoch 156/200, Iteration 228/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 229/250, Loss: 0.0118\n",
      "Epoch 156/200, Iteration 230/250, Loss: 0.0125\n",
      "Epoch 156/200, Iteration 231/250, Loss: 0.0114\n",
      "Epoch 156/200, Iteration 232/250, Loss: 0.0085\n",
      "Epoch 156/200, Iteration 233/250, Loss: 0.0352\n",
      "Epoch 156/200, Iteration 234/250, Loss: 0.0110\n",
      "Epoch 156/200, Iteration 235/250, Loss: 0.0329\n",
      "Epoch 156/200, Iteration 236/250, Loss: 0.0090\n",
      "Epoch 156/200, Iteration 237/250, Loss: 0.0101\n",
      "Epoch 156/200, Iteration 238/250, Loss: 0.0289\n",
      "Epoch 156/200, Iteration 239/250, Loss: 0.0075\n",
      "Epoch 156/200, Iteration 240/250, Loss: 0.0166\n",
      "Epoch 156/200, Iteration 241/250, Loss: 0.0116\n",
      "Epoch 156/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 156/200, Iteration 243/250, Loss: 0.0142\n",
      "Epoch 156/200, Iteration 244/250, Loss: 0.0081\n",
      "Epoch 156/200, Iteration 245/250, Loss: 0.0215\n",
      "Epoch 156/200, Iteration 246/250, Loss: 0.0098\n",
      "Epoch 156/200, Iteration 247/250, Loss: 0.0223\n",
      "Epoch 156/200, Iteration 248/250, Loss: 0.0234\n",
      "Epoch 156/200, Iteration 249/250, Loss: 0.0107\n",
      "Epoch 156/200, Iteration 250/250, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 94.58%, Avg loss: 0.007913, MRE: 0.454783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.55%, Avg loss: 0.008430, MRE: 0.479960 \n",
      "\n",
      "Epoch 157/200, Iteration 1/250, Loss: 0.0343\n",
      "Epoch 157/200, Iteration 2/250, Loss: 0.0085\n",
      "Epoch 157/200, Iteration 3/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 4/250, Loss: 0.0172\n",
      "Epoch 157/200, Iteration 5/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 6/250, Loss: 0.0275\n",
      "Epoch 157/200, Iteration 7/250, Loss: 0.0075\n",
      "Epoch 157/200, Iteration 8/250, Loss: 0.0273\n",
      "Epoch 157/200, Iteration 9/250, Loss: 0.0108\n",
      "Epoch 157/200, Iteration 10/250, Loss: 0.0183\n",
      "Epoch 157/200, Iteration 11/250, Loss: 0.0279\n",
      "Epoch 157/200, Iteration 12/250, Loss: 0.0292\n",
      "Epoch 157/200, Iteration 13/250, Loss: 0.0071\n",
      "Epoch 157/200, Iteration 14/250, Loss: 0.0130\n",
      "Epoch 157/200, Iteration 15/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 16/250, Loss: 0.0193\n",
      "Epoch 157/200, Iteration 17/250, Loss: 0.0141\n",
      "Epoch 157/200, Iteration 18/250, Loss: 0.0127\n",
      "Epoch 157/200, Iteration 19/250, Loss: 0.0118\n",
      "Epoch 157/200, Iteration 20/250, Loss: 0.0120\n",
      "Epoch 157/200, Iteration 21/250, Loss: 0.0109\n",
      "Epoch 157/200, Iteration 22/250, Loss: 0.0159\n",
      "Epoch 157/200, Iteration 23/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 24/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 25/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 26/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 27/250, Loss: 0.0143\n",
      "Epoch 157/200, Iteration 28/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 29/250, Loss: 0.0108\n",
      "Epoch 157/200, Iteration 30/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 31/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 32/250, Loss: 0.0190\n",
      "Epoch 157/200, Iteration 33/250, Loss: 0.0118\n",
      "Epoch 157/200, Iteration 34/250, Loss: 0.0113\n",
      "Epoch 157/200, Iteration 35/250, Loss: 0.0061\n",
      "Epoch 157/200, Iteration 36/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 37/250, Loss: 0.0137\n",
      "Epoch 157/200, Iteration 38/250, Loss: 0.0171\n",
      "Epoch 157/200, Iteration 39/250, Loss: 0.0082\n",
      "Epoch 157/200, Iteration 40/250, Loss: 0.0139\n",
      "Epoch 157/200, Iteration 41/250, Loss: 0.0176\n",
      "Epoch 157/200, Iteration 42/250, Loss: 0.0113\n",
      "Epoch 157/200, Iteration 43/250, Loss: 0.0123\n",
      "Epoch 157/200, Iteration 44/250, Loss: 0.0137\n",
      "Epoch 157/200, Iteration 45/250, Loss: 0.0082\n",
      "Epoch 157/200, Iteration 46/250, Loss: 0.0108\n",
      "Epoch 157/200, Iteration 47/250, Loss: 0.0098\n",
      "Epoch 157/200, Iteration 48/250, Loss: 0.0394\n",
      "Epoch 157/200, Iteration 49/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 50/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 51/250, Loss: 0.0164\n",
      "Epoch 157/200, Iteration 52/250, Loss: 0.0168\n",
      "Epoch 157/200, Iteration 53/250, Loss: 0.0154\n",
      "Epoch 157/200, Iteration 54/250, Loss: 0.0164\n",
      "Epoch 157/200, Iteration 55/250, Loss: 0.0169\n",
      "Epoch 157/200, Iteration 56/250, Loss: 0.0127\n",
      "Epoch 157/200, Iteration 57/250, Loss: 0.0189\n",
      "Epoch 157/200, Iteration 58/250, Loss: 0.0091\n",
      "Epoch 157/200, Iteration 59/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 60/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 61/250, Loss: 0.0209\n",
      "Epoch 157/200, Iteration 62/250, Loss: 0.0094\n",
      "Epoch 157/200, Iteration 63/250, Loss: 0.0086\n",
      "Epoch 157/200, Iteration 64/250, Loss: 0.0136\n",
      "Epoch 157/200, Iteration 65/250, Loss: 0.0115\n",
      "Epoch 157/200, Iteration 66/250, Loss: 0.0107\n",
      "Epoch 157/200, Iteration 67/250, Loss: 0.0109\n",
      "Epoch 157/200, Iteration 68/250, Loss: 0.0086\n",
      "Epoch 157/200, Iteration 69/250, Loss: 0.0228\n",
      "Epoch 157/200, Iteration 70/250, Loss: 0.0101\n",
      "Epoch 157/200, Iteration 71/250, Loss: 0.0121\n",
      "Epoch 157/200, Iteration 72/250, Loss: 0.0091\n",
      "Epoch 157/200, Iteration 73/250, Loss: 0.0252\n",
      "Epoch 157/200, Iteration 74/250, Loss: 0.0202\n",
      "Epoch 157/200, Iteration 75/250, Loss: 0.0138\n",
      "Epoch 157/200, Iteration 76/250, Loss: 0.0214\n",
      "Epoch 157/200, Iteration 77/250, Loss: 0.0088\n",
      "Epoch 157/200, Iteration 78/250, Loss: 0.0087\n",
      "Epoch 157/200, Iteration 79/250, Loss: 0.0086\n",
      "Epoch 157/200, Iteration 80/250, Loss: 0.0114\n",
      "Epoch 157/200, Iteration 81/250, Loss: 0.0226\n",
      "Epoch 157/200, Iteration 82/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 83/250, Loss: 0.0434\n",
      "Epoch 157/200, Iteration 84/250, Loss: 0.0061\n",
      "Epoch 157/200, Iteration 85/250, Loss: 0.0156\n",
      "Epoch 157/200, Iteration 86/250, Loss: 0.0136\n",
      "Epoch 157/200, Iteration 87/250, Loss: 0.0165\n",
      "Epoch 157/200, Iteration 88/250, Loss: 0.0237\n",
      "Epoch 157/200, Iteration 89/250, Loss: 0.0069\n",
      "Epoch 157/200, Iteration 90/250, Loss: 0.0159\n",
      "Epoch 157/200, Iteration 91/250, Loss: 0.0085\n",
      "Epoch 157/200, Iteration 92/250, Loss: 0.0114\n",
      "Epoch 157/200, Iteration 93/250, Loss: 0.0092\n",
      "Epoch 157/200, Iteration 94/250, Loss: 0.0238\n",
      "Epoch 157/200, Iteration 95/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 96/250, Loss: 0.0177\n",
      "Epoch 157/200, Iteration 97/250, Loss: 0.0091\n",
      "Epoch 157/200, Iteration 98/250, Loss: 0.0269\n",
      "Epoch 157/200, Iteration 99/250, Loss: 0.0115\n",
      "Epoch 157/200, Iteration 100/250, Loss: 0.0231\n",
      "Epoch 157/200, Iteration 101/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 102/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 103/250, Loss: 0.0075\n",
      "Epoch 157/200, Iteration 104/250, Loss: 0.0157\n",
      "Epoch 157/200, Iteration 105/250, Loss: 0.0088\n",
      "Epoch 157/200, Iteration 106/250, Loss: 0.0127\n",
      "Epoch 157/200, Iteration 107/250, Loss: 0.0106\n",
      "Epoch 157/200, Iteration 108/250, Loss: 0.0142\n",
      "Epoch 157/200, Iteration 109/250, Loss: 0.0223\n",
      "Epoch 157/200, Iteration 110/250, Loss: 0.0094\n",
      "Epoch 157/200, Iteration 111/250, Loss: 0.0142\n",
      "Epoch 157/200, Iteration 112/250, Loss: 0.0157\n",
      "Epoch 157/200, Iteration 113/250, Loss: 0.0253\n",
      "Epoch 157/200, Iteration 114/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 115/250, Loss: 0.0094\n",
      "Epoch 157/200, Iteration 116/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 117/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 118/250, Loss: 0.0153\n",
      "Epoch 157/200, Iteration 119/250, Loss: 0.0143\n",
      "Epoch 157/200, Iteration 120/250, Loss: 0.0232\n",
      "Epoch 157/200, Iteration 121/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 122/250, Loss: 0.0082\n",
      "Epoch 157/200, Iteration 123/250, Loss: 0.0209\n",
      "Epoch 157/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 125/250, Loss: 0.0089\n",
      "Epoch 157/200, Iteration 126/250, Loss: 0.0093\n",
      "Epoch 157/200, Iteration 127/250, Loss: 0.0084\n",
      "Epoch 157/200, Iteration 128/250, Loss: 0.0255\n",
      "Epoch 157/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 157/200, Iteration 130/250, Loss: 0.0112\n",
      "Epoch 157/200, Iteration 131/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 132/250, Loss: 0.0167\n",
      "Epoch 157/200, Iteration 133/250, Loss: 0.0231\n",
      "Epoch 157/200, Iteration 134/250, Loss: 0.0198\n",
      "Epoch 157/200, Iteration 135/250, Loss: 0.0125\n",
      "Epoch 157/200, Iteration 136/250, Loss: 0.0192\n",
      "Epoch 157/200, Iteration 137/250, Loss: 0.0141\n",
      "Epoch 157/200, Iteration 138/250, Loss: 0.0163\n",
      "Epoch 157/200, Iteration 139/250, Loss: 0.0107\n",
      "Epoch 157/200, Iteration 140/250, Loss: 0.0282\n",
      "Epoch 157/200, Iteration 141/250, Loss: 0.0071\n",
      "Epoch 157/200, Iteration 142/250, Loss: 0.0106\n",
      "Epoch 157/200, Iteration 143/250, Loss: 0.0213\n",
      "Epoch 157/200, Iteration 144/250, Loss: 0.0522\n",
      "Epoch 157/200, Iteration 145/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 146/250, Loss: 0.0241\n",
      "Epoch 157/200, Iteration 147/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 148/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 149/250, Loss: 0.0183\n",
      "Epoch 157/200, Iteration 150/250, Loss: 0.0230\n",
      "Epoch 157/200, Iteration 151/250, Loss: 0.0286\n",
      "Epoch 157/200, Iteration 152/250, Loss: 0.0078\n",
      "Epoch 157/200, Iteration 153/250, Loss: 0.0121\n",
      "Epoch 157/200, Iteration 154/250, Loss: 0.0093\n",
      "Epoch 157/200, Iteration 155/250, Loss: 0.0195\n",
      "Epoch 157/200, Iteration 156/250, Loss: 0.0080\n",
      "Epoch 157/200, Iteration 157/250, Loss: 0.0143\n",
      "Epoch 157/200, Iteration 158/250, Loss: 0.0124\n",
      "Epoch 157/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 157/200, Iteration 160/250, Loss: 0.0104\n",
      "Epoch 157/200, Iteration 161/250, Loss: 0.0119\n",
      "Epoch 157/200, Iteration 162/250, Loss: 0.0101\n",
      "Epoch 157/200, Iteration 163/250, Loss: 0.0105\n",
      "Epoch 157/200, Iteration 164/250, Loss: 0.0125\n",
      "Epoch 157/200, Iteration 165/250, Loss: 0.0108\n",
      "Epoch 157/200, Iteration 166/250, Loss: 0.0215\n",
      "Epoch 157/200, Iteration 167/250, Loss: 0.0096\n",
      "Epoch 157/200, Iteration 168/250, Loss: 0.0213\n",
      "Epoch 157/200, Iteration 169/250, Loss: 0.0135\n",
      "Epoch 157/200, Iteration 170/250, Loss: 0.0072\n",
      "Epoch 157/200, Iteration 171/250, Loss: 0.0260\n",
      "Epoch 157/200, Iteration 172/250, Loss: 0.0224\n",
      "Epoch 157/200, Iteration 173/250, Loss: 0.0109\n",
      "Epoch 157/200, Iteration 174/250, Loss: 0.0167\n",
      "Epoch 157/200, Iteration 175/250, Loss: 0.0102\n",
      "Epoch 157/200, Iteration 176/250, Loss: 0.0284\n",
      "Epoch 157/200, Iteration 177/250, Loss: 0.0091\n",
      "Epoch 157/200, Iteration 178/250, Loss: 0.0310\n",
      "Epoch 157/200, Iteration 179/250, Loss: 0.0081\n",
      "Epoch 157/200, Iteration 180/250, Loss: 0.0107\n",
      "Epoch 157/200, Iteration 181/250, Loss: 0.0108\n",
      "Epoch 157/200, Iteration 182/250, Loss: 0.0365\n",
      "Epoch 157/200, Iteration 183/250, Loss: 0.0145\n",
      "Epoch 157/200, Iteration 184/250, Loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200, Iteration 185/250, Loss: 0.0166\n",
      "Epoch 157/200, Iteration 186/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 187/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 188/250, Loss: 0.0193\n",
      "Epoch 157/200, Iteration 189/250, Loss: 0.0210\n",
      "Epoch 157/200, Iteration 190/250, Loss: 0.0111\n",
      "Epoch 157/200, Iteration 191/250, Loss: 0.0183\n",
      "Epoch 157/200, Iteration 192/250, Loss: 0.0238\n",
      "Epoch 157/200, Iteration 193/250, Loss: 0.0309\n",
      "Epoch 157/200, Iteration 194/250, Loss: 0.0159\n",
      "Epoch 157/200, Iteration 195/250, Loss: 0.0204\n",
      "Epoch 157/200, Iteration 196/250, Loss: 0.0190\n",
      "Epoch 157/200, Iteration 197/250, Loss: 0.0122\n",
      "Epoch 157/200, Iteration 198/250, Loss: 0.0154\n",
      "Epoch 157/200, Iteration 199/250, Loss: 0.0140\n",
      "Epoch 157/200, Iteration 200/250, Loss: 0.0190\n",
      "Epoch 157/200, Iteration 201/250, Loss: 0.0290\n",
      "Epoch 157/200, Iteration 202/250, Loss: 0.0148\n",
      "Epoch 157/200, Iteration 203/250, Loss: 0.0143\n",
      "Epoch 157/200, Iteration 204/250, Loss: 0.0131\n",
      "Epoch 157/200, Iteration 205/250, Loss: 0.0155\n",
      "Epoch 157/200, Iteration 206/250, Loss: 0.0240\n",
      "Epoch 157/200, Iteration 207/250, Loss: 0.0152\n",
      "Epoch 157/200, Iteration 208/250, Loss: 0.0431\n",
      "Epoch 157/200, Iteration 209/250, Loss: 0.0276\n",
      "Epoch 157/200, Iteration 210/250, Loss: 0.0141\n",
      "Epoch 157/200, Iteration 211/250, Loss: 0.0249\n",
      "Epoch 157/200, Iteration 212/250, Loss: 0.0154\n",
      "Epoch 157/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 157/200, Iteration 214/250, Loss: 0.0117\n",
      "Epoch 157/200, Iteration 215/250, Loss: 0.0199\n",
      "Epoch 157/200, Iteration 216/250, Loss: 0.0074\n",
      "Epoch 157/200, Iteration 217/250, Loss: 0.0083\n",
      "Epoch 157/200, Iteration 218/250, Loss: 0.0161\n",
      "Epoch 157/200, Iteration 219/250, Loss: 0.0167\n",
      "Epoch 157/200, Iteration 220/250, Loss: 0.0097\n",
      "Epoch 157/200, Iteration 221/250, Loss: 0.0151\n",
      "Epoch 157/200, Iteration 222/250, Loss: 0.0123\n",
      "Epoch 157/200, Iteration 223/250, Loss: 0.0196\n",
      "Epoch 157/200, Iteration 224/250, Loss: 0.0090\n",
      "Epoch 157/200, Iteration 225/250, Loss: 0.0088\n",
      "Epoch 157/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 157/200, Iteration 227/250, Loss: 0.0237\n",
      "Epoch 157/200, Iteration 228/250, Loss: 0.0107\n",
      "Epoch 157/200, Iteration 229/250, Loss: 0.0103\n",
      "Epoch 157/200, Iteration 230/250, Loss: 0.0261\n",
      "Epoch 157/200, Iteration 231/250, Loss: 0.0132\n",
      "Epoch 157/200, Iteration 232/250, Loss: 0.0131\n",
      "Epoch 157/200, Iteration 233/250, Loss: 0.0274\n",
      "Epoch 157/200, Iteration 234/250, Loss: 0.0116\n",
      "Epoch 157/200, Iteration 235/250, Loss: 0.0122\n",
      "Epoch 157/200, Iteration 236/250, Loss: 0.0272\n",
      "Epoch 157/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 157/200, Iteration 238/250, Loss: 0.0088\n",
      "Epoch 157/200, Iteration 239/250, Loss: 0.0244\n",
      "Epoch 157/200, Iteration 240/250, Loss: 0.0254\n",
      "Epoch 157/200, Iteration 241/250, Loss: 0.0184\n",
      "Epoch 157/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 157/200, Iteration 243/250, Loss: 0.0086\n",
      "Epoch 157/200, Iteration 244/250, Loss: 0.0085\n",
      "Epoch 157/200, Iteration 245/250, Loss: 0.0258\n",
      "Epoch 157/200, Iteration 246/250, Loss: 0.0149\n",
      "Epoch 157/200, Iteration 247/250, Loss: 0.0095\n",
      "Epoch 157/200, Iteration 248/250, Loss: 0.0153\n",
      "Epoch 157/200, Iteration 249/250, Loss: 0.0063\n",
      "Epoch 157/200, Iteration 250/250, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 93.31%, Avg loss: 0.006933, MRE: 0.456905 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.55%, Avg loss: 0.007633, MRE: 0.545915 \n",
      "\n",
      "Epoch 158/200, Iteration 1/250, Loss: 0.0091\n",
      "Epoch 158/200, Iteration 2/250, Loss: 0.0212\n",
      "Epoch 158/200, Iteration 3/250, Loss: 0.0180\n",
      "Epoch 158/200, Iteration 4/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 5/250, Loss: 0.0169\n",
      "Epoch 158/200, Iteration 6/250, Loss: 0.0222\n",
      "Epoch 158/200, Iteration 7/250, Loss: 0.0076\n",
      "Epoch 158/200, Iteration 8/250, Loss: 0.0187\n",
      "Epoch 158/200, Iteration 9/250, Loss: 0.0150\n",
      "Epoch 158/200, Iteration 10/250, Loss: 0.0258\n",
      "Epoch 158/200, Iteration 11/250, Loss: 0.0231\n",
      "Epoch 158/200, Iteration 12/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 13/250, Loss: 0.0111\n",
      "Epoch 158/200, Iteration 14/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 15/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 16/250, Loss: 0.0140\n",
      "Epoch 158/200, Iteration 17/250, Loss: 0.0121\n",
      "Epoch 158/200, Iteration 18/250, Loss: 0.0161\n",
      "Epoch 158/200, Iteration 19/250, Loss: 0.0097\n",
      "Epoch 158/200, Iteration 20/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 21/250, Loss: 0.0070\n",
      "Epoch 158/200, Iteration 22/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 23/250, Loss: 0.0173\n",
      "Epoch 158/200, Iteration 24/250, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 25/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 26/250, Loss: 0.0109\n",
      "Epoch 158/200, Iteration 27/250, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 28/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 29/250, Loss: 0.0405\n",
      "Epoch 158/200, Iteration 30/250, Loss: 0.0069\n",
      "Epoch 158/200, Iteration 31/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 32/250, Loss: 0.0077\n",
      "Epoch 158/200, Iteration 33/250, Loss: 0.0151\n",
      "Epoch 158/200, Iteration 34/250, Loss: 0.0113\n",
      "Epoch 158/200, Iteration 35/250, Loss: 0.0284\n",
      "Epoch 158/200, Iteration 36/250, Loss: 0.0421\n",
      "Epoch 158/200, Iteration 37/250, Loss: 0.0116\n",
      "Epoch 158/200, Iteration 38/250, Loss: 0.0167\n",
      "Epoch 158/200, Iteration 39/250, Loss: 0.0243\n",
      "Epoch 158/200, Iteration 40/250, Loss: 0.0112\n",
      "Epoch 158/200, Iteration 41/250, Loss: 0.0110\n",
      "Epoch 158/200, Iteration 42/250, Loss: 0.0177\n",
      "Epoch 158/200, Iteration 43/250, Loss: 0.0071\n",
      "Epoch 158/200, Iteration 44/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 45/250, Loss: 0.0138\n",
      "Epoch 158/200, Iteration 46/250, Loss: 0.0265\n",
      "Epoch 158/200, Iteration 47/250, Loss: 0.0104\n",
      "Epoch 158/200, Iteration 48/250, Loss: 0.0169\n",
      "Epoch 158/200, Iteration 49/250, Loss: 0.0200\n",
      "Epoch 158/200, Iteration 50/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 51/250, Loss: 0.0365\n",
      "Epoch 158/200, Iteration 52/250, Loss: 0.0231\n",
      "Epoch 158/200, Iteration 53/250, Loss: 0.0219\n",
      "Epoch 158/200, Iteration 54/250, Loss: 0.0190\n",
      "Epoch 158/200, Iteration 55/250, Loss: 0.0231\n",
      "Epoch 158/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 158/200, Iteration 57/250, Loss: 0.0112\n",
      "Epoch 158/200, Iteration 58/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 59/250, Loss: 0.0121\n",
      "Epoch 158/200, Iteration 60/250, Loss: 0.0211\n",
      "Epoch 158/200, Iteration 61/250, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 62/250, Loss: 0.0185\n",
      "Epoch 158/200, Iteration 63/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 64/250, Loss: 0.0251\n",
      "Epoch 158/200, Iteration 65/250, Loss: 0.0206\n",
      "Epoch 158/200, Iteration 66/250, Loss: 0.0245\n",
      "Epoch 158/200, Iteration 67/250, Loss: 0.0141\n",
      "Epoch 158/200, Iteration 68/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 69/250, Loss: 0.0272\n",
      "Epoch 158/200, Iteration 70/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 71/250, Loss: 0.0092\n",
      "Epoch 158/200, Iteration 72/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 73/250, Loss: 0.0140\n",
      "Epoch 158/200, Iteration 74/250, Loss: 0.0284\n",
      "Epoch 158/200, Iteration 75/250, Loss: 0.0104\n",
      "Epoch 158/200, Iteration 76/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 77/250, Loss: 0.0098\n",
      "Epoch 158/200, Iteration 78/250, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 79/250, Loss: 0.0239\n",
      "Epoch 158/200, Iteration 80/250, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 81/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 82/250, Loss: 0.0125\n",
      "Epoch 158/200, Iteration 83/250, Loss: 0.0081\n",
      "Epoch 158/200, Iteration 84/250, Loss: 0.0092\n",
      "Epoch 158/200, Iteration 85/250, Loss: 0.0116\n",
      "Epoch 158/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 158/200, Iteration 87/250, Loss: 0.0186\n",
      "Epoch 158/200, Iteration 88/250, Loss: 0.0099\n",
      "Epoch 158/200, Iteration 89/250, Loss: 0.0137\n",
      "Epoch 158/200, Iteration 90/250, Loss: 0.0134\n",
      "Epoch 158/200, Iteration 91/250, Loss: 0.0162\n",
      "Epoch 158/200, Iteration 92/250, Loss: 0.0164\n",
      "Epoch 158/200, Iteration 93/250, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 94/250, Loss: 0.0123\n",
      "Epoch 158/200, Iteration 95/250, Loss: 0.0068\n",
      "Epoch 158/200, Iteration 96/250, Loss: 0.0220\n",
      "Epoch 158/200, Iteration 97/250, Loss: 0.0248\n",
      "Epoch 158/200, Iteration 98/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 99/250, Loss: 0.0139\n",
      "Epoch 158/200, Iteration 100/250, Loss: 0.0234\n",
      "Epoch 158/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 158/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 158/200, Iteration 103/250, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 104/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 105/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 106/250, Loss: 0.0231\n",
      "Epoch 158/200, Iteration 107/250, Loss: 0.0394\n",
      "Epoch 158/200, Iteration 108/250, Loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200, Iteration 109/250, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 110/250, Loss: 0.0168\n",
      "Epoch 158/200, Iteration 111/250, Loss: 0.0295\n",
      "Epoch 158/200, Iteration 112/250, Loss: 0.0105\n",
      "Epoch 158/200, Iteration 113/250, Loss: 0.0123\n",
      "Epoch 158/200, Iteration 114/250, Loss: 0.0110\n",
      "Epoch 158/200, Iteration 115/250, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 116/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 117/250, Loss: 0.0105\n",
      "Epoch 158/200, Iteration 118/250, Loss: 0.0084\n",
      "Epoch 158/200, Iteration 119/250, Loss: 0.0087\n",
      "Epoch 158/200, Iteration 120/250, Loss: 0.0185\n",
      "Epoch 158/200, Iteration 121/250, Loss: 0.0148\n",
      "Epoch 158/200, Iteration 122/250, Loss: 0.0118\n",
      "Epoch 158/200, Iteration 123/250, Loss: 0.0251\n",
      "Epoch 158/200, Iteration 124/250, Loss: 0.0130\n",
      "Epoch 158/200, Iteration 125/250, Loss: 0.0115\n",
      "Epoch 158/200, Iteration 126/250, Loss: 0.0154\n",
      "Epoch 158/200, Iteration 127/250, Loss: 0.0132\n",
      "Epoch 158/200, Iteration 128/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 129/250, Loss: 0.0142\n",
      "Epoch 158/200, Iteration 130/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 131/250, Loss: 0.0136\n",
      "Epoch 158/200, Iteration 132/250, Loss: 0.0078\n",
      "Epoch 158/200, Iteration 133/250, Loss: 0.0237\n",
      "Epoch 158/200, Iteration 134/250, Loss: 0.0150\n",
      "Epoch 158/200, Iteration 135/250, Loss: 0.0124\n",
      "Epoch 158/200, Iteration 136/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 137/250, Loss: 0.0160\n",
      "Epoch 158/200, Iteration 138/250, Loss: 0.0284\n",
      "Epoch 158/200, Iteration 139/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 140/250, Loss: 0.0186\n",
      "Epoch 158/200, Iteration 141/250, Loss: 0.0106\n",
      "Epoch 158/200, Iteration 142/250, Loss: 0.0327\n",
      "Epoch 158/200, Iteration 143/250, Loss: 0.0119\n",
      "Epoch 158/200, Iteration 144/250, Loss: 0.0131\n",
      "Epoch 158/200, Iteration 145/250, Loss: 0.0152\n",
      "Epoch 158/200, Iteration 146/250, Loss: 0.0083\n",
      "Epoch 158/200, Iteration 147/250, Loss: 0.0087\n",
      "Epoch 158/200, Iteration 148/250, Loss: 0.0069\n",
      "Epoch 158/200, Iteration 149/250, Loss: 0.0123\n",
      "Epoch 158/200, Iteration 150/250, Loss: 0.0157\n",
      "Epoch 158/200, Iteration 151/250, Loss: 0.0069\n",
      "Epoch 158/200, Iteration 152/250, Loss: 0.0102\n",
      "Epoch 158/200, Iteration 153/250, Loss: 0.0269\n",
      "Epoch 158/200, Iteration 154/250, Loss: 0.0098\n",
      "Epoch 158/200, Iteration 155/250, Loss: 0.0140\n",
      "Epoch 158/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 158/200, Iteration 157/250, Loss: 0.0125\n",
      "Epoch 158/200, Iteration 158/250, Loss: 0.0199\n",
      "Epoch 158/200, Iteration 159/250, Loss: 0.0316\n",
      "Epoch 158/200, Iteration 160/250, Loss: 0.0172\n",
      "Epoch 158/200, Iteration 161/250, Loss: 0.0193\n",
      "Epoch 158/200, Iteration 162/250, Loss: 0.0228\n",
      "Epoch 158/200, Iteration 163/250, Loss: 0.0105\n",
      "Epoch 158/200, Iteration 164/250, Loss: 0.0481\n",
      "Epoch 158/200, Iteration 165/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 166/250, Loss: 0.0109\n",
      "Epoch 158/200, Iteration 167/250, Loss: 0.0129\n",
      "Epoch 158/200, Iteration 168/250, Loss: 0.0248\n",
      "Epoch 158/200, Iteration 169/250, Loss: 0.0166\n",
      "Epoch 158/200, Iteration 170/250, Loss: 0.0080\n",
      "Epoch 158/200, Iteration 171/250, Loss: 0.0174\n",
      "Epoch 158/200, Iteration 172/250, Loss: 0.0094\n",
      "Epoch 158/200, Iteration 173/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 174/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 175/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 176/250, Loss: 0.0211\n",
      "Epoch 158/200, Iteration 177/250, Loss: 0.0083\n",
      "Epoch 158/200, Iteration 178/250, Loss: 0.0072\n",
      "Epoch 158/200, Iteration 179/250, Loss: 0.0165\n",
      "Epoch 158/200, Iteration 180/250, Loss: 0.0149\n",
      "Epoch 158/200, Iteration 181/250, Loss: 0.0524\n",
      "Epoch 158/200, Iteration 182/250, Loss: 0.0112\n",
      "Epoch 158/200, Iteration 183/250, Loss: 0.0071\n",
      "Epoch 158/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 158/200, Iteration 185/250, Loss: 0.0089\n",
      "Epoch 158/200, Iteration 186/250, Loss: 0.0062\n",
      "Epoch 158/200, Iteration 187/250, Loss: 0.0169\n",
      "Epoch 158/200, Iteration 188/250, Loss: 0.0096\n",
      "Epoch 158/200, Iteration 189/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 190/250, Loss: 0.0261\n",
      "Epoch 158/200, Iteration 191/250, Loss: 0.0158\n",
      "Epoch 158/200, Iteration 192/250, Loss: 0.0120\n",
      "Epoch 158/200, Iteration 193/250, Loss: 0.0137\n",
      "Epoch 158/200, Iteration 194/250, Loss: 0.0060\n",
      "Epoch 158/200, Iteration 195/250, Loss: 0.0235\n",
      "Epoch 158/200, Iteration 196/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 197/250, Loss: 0.0181\n",
      "Epoch 158/200, Iteration 198/250, Loss: 0.0124\n",
      "Epoch 158/200, Iteration 199/250, Loss: 0.0073\n",
      "Epoch 158/200, Iteration 200/250, Loss: 0.0076\n",
      "Epoch 158/200, Iteration 201/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 158/200, Iteration 203/250, Loss: 0.0205\n",
      "Epoch 158/200, Iteration 204/250, Loss: 0.0130\n",
      "Epoch 158/200, Iteration 205/250, Loss: 0.0225\n",
      "Epoch 158/200, Iteration 206/250, Loss: 0.0107\n",
      "Epoch 158/200, Iteration 207/250, Loss: 0.0206\n",
      "Epoch 158/200, Iteration 208/250, Loss: 0.0068\n",
      "Epoch 158/200, Iteration 209/250, Loss: 0.0165\n",
      "Epoch 158/200, Iteration 210/250, Loss: 0.0148\n",
      "Epoch 158/200, Iteration 211/250, Loss: 0.0247\n",
      "Epoch 158/200, Iteration 212/250, Loss: 0.0144\n",
      "Epoch 158/200, Iteration 213/250, Loss: 0.0092\n",
      "Epoch 158/200, Iteration 214/250, Loss: 0.0085\n",
      "Epoch 158/200, Iteration 215/250, Loss: 0.0088\n",
      "Epoch 158/200, Iteration 216/250, Loss: 0.0216\n",
      "Epoch 158/200, Iteration 217/250, Loss: 0.0371\n",
      "Epoch 158/200, Iteration 218/250, Loss: 0.0162\n",
      "Epoch 158/200, Iteration 219/250, Loss: 0.0111\n",
      "Epoch 158/200, Iteration 220/250, Loss: 0.0088\n",
      "Epoch 158/200, Iteration 221/250, Loss: 0.0080\n",
      "Epoch 158/200, Iteration 222/250, Loss: 0.0097\n",
      "Epoch 158/200, Iteration 223/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 224/250, Loss: 0.0230\n",
      "Epoch 158/200, Iteration 225/250, Loss: 0.0117\n",
      "Epoch 158/200, Iteration 226/250, Loss: 0.0263\n",
      "Epoch 158/200, Iteration 227/250, Loss: 0.0339\n",
      "Epoch 158/200, Iteration 228/250, Loss: 0.0142\n",
      "Epoch 158/200, Iteration 229/250, Loss: 0.0274\n",
      "Epoch 158/200, Iteration 230/250, Loss: 0.0209\n",
      "Epoch 158/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 158/200, Iteration 232/250, Loss: 0.0214\n",
      "Epoch 158/200, Iteration 233/250, Loss: 0.0153\n",
      "Epoch 158/200, Iteration 234/250, Loss: 0.0211\n",
      "Epoch 158/200, Iteration 235/250, Loss: 0.0064\n",
      "Epoch 158/200, Iteration 236/250, Loss: 0.0143\n",
      "Epoch 158/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 158/200, Iteration 238/250, Loss: 0.0101\n",
      "Epoch 158/200, Iteration 239/250, Loss: 0.0108\n",
      "Epoch 158/200, Iteration 240/250, Loss: 0.0433\n",
      "Epoch 158/200, Iteration 241/250, Loss: 0.0105\n",
      "Epoch 158/200, Iteration 242/250, Loss: 0.0139\n",
      "Epoch 158/200, Iteration 243/250, Loss: 0.0223\n",
      "Epoch 158/200, Iteration 244/250, Loss: 0.0239\n",
      "Epoch 158/200, Iteration 245/250, Loss: 0.0390\n",
      "Epoch 158/200, Iteration 246/250, Loss: 0.0122\n",
      "Epoch 158/200, Iteration 247/250, Loss: 0.0261\n",
      "Epoch 158/200, Iteration 248/250, Loss: 0.0190\n",
      "Epoch 158/200, Iteration 249/250, Loss: 0.0114\n",
      "Epoch 158/200, Iteration 250/250, Loss: 0.0129\n",
      "Train Error: \n",
      " Accuracy: 95.16%, Avg loss: 0.007482, MRE: 0.513831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.008205, MRE: 0.554134 \n",
      "\n",
      "Epoch 159/200, Iteration 1/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 2/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 3/250, Loss: 0.0267\n",
      "Epoch 159/200, Iteration 4/250, Loss: 0.0127\n",
      "Epoch 159/200, Iteration 5/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 6/250, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 7/250, Loss: 0.0175\n",
      "Epoch 159/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 159/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 159/200, Iteration 10/250, Loss: 0.0300\n",
      "Epoch 159/200, Iteration 11/250, Loss: 0.0160\n",
      "Epoch 159/200, Iteration 12/250, Loss: 0.0228\n",
      "Epoch 159/200, Iteration 13/250, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 14/250, Loss: 0.0135\n",
      "Epoch 159/200, Iteration 15/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 16/250, Loss: 0.0261\n",
      "Epoch 159/200, Iteration 17/250, Loss: 0.0083\n",
      "Epoch 159/200, Iteration 18/250, Loss: 0.0230\n",
      "Epoch 159/200, Iteration 19/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 20/250, Loss: 0.0084\n",
      "Epoch 159/200, Iteration 21/250, Loss: 0.0244\n",
      "Epoch 159/200, Iteration 22/250, Loss: 0.0236\n",
      "Epoch 159/200, Iteration 23/250, Loss: 0.0080\n",
      "Epoch 159/200, Iteration 24/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 25/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 26/250, Loss: 0.0303\n",
      "Epoch 159/200, Iteration 27/250, Loss: 0.0242\n",
      "Epoch 159/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 159/200, Iteration 29/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 30/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 31/250, Loss: 0.0130\n",
      "Epoch 159/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 159/200, Iteration 33/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 34/250, Loss: 0.0091\n",
      "Epoch 159/200, Iteration 35/250, Loss: 0.0134\n",
      "Epoch 159/200, Iteration 36/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 37/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 38/250, Loss: 0.0082\n",
      "Epoch 159/200, Iteration 39/250, Loss: 0.0100\n",
      "Epoch 159/200, Iteration 40/250, Loss: 0.0124\n",
      "Epoch 159/200, Iteration 41/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 42/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 43/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 44/250, Loss: 0.0085\n",
      "Epoch 159/200, Iteration 45/250, Loss: 0.0160\n",
      "Epoch 159/200, Iteration 46/250, Loss: 0.0286\n",
      "Epoch 159/200, Iteration 47/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 48/250, Loss: 0.0115\n",
      "Epoch 159/200, Iteration 49/250, Loss: 0.0279\n",
      "Epoch 159/200, Iteration 50/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 51/250, Loss: 0.0082\n",
      "Epoch 159/200, Iteration 52/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 53/250, Loss: 0.0327\n",
      "Epoch 159/200, Iteration 54/250, Loss: 0.0167\n",
      "Epoch 159/200, Iteration 55/250, Loss: 0.0302\n",
      "Epoch 159/200, Iteration 56/250, Loss: 0.0091\n",
      "Epoch 159/200, Iteration 57/250, Loss: 0.0113\n",
      "Epoch 159/200, Iteration 58/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 59/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 60/250, Loss: 0.0107\n",
      "Epoch 159/200, Iteration 61/250, Loss: 0.0113\n",
      "Epoch 159/200, Iteration 62/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 63/250, Loss: 0.0136\n",
      "Epoch 159/200, Iteration 64/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 65/250, Loss: 0.0292\n",
      "Epoch 159/200, Iteration 66/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 67/250, Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200, Iteration 68/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 69/250, Loss: 0.0234\n",
      "Epoch 159/200, Iteration 70/250, Loss: 0.0095\n",
      "Epoch 159/200, Iteration 71/250, Loss: 0.0274\n",
      "Epoch 159/200, Iteration 72/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 73/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 74/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 75/250, Loss: 0.0130\n",
      "Epoch 159/200, Iteration 76/250, Loss: 0.0080\n",
      "Epoch 159/200, Iteration 77/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 78/250, Loss: 0.0078\n",
      "Epoch 159/200, Iteration 79/250, Loss: 0.0079\n",
      "Epoch 159/200, Iteration 80/250, Loss: 0.0152\n",
      "Epoch 159/200, Iteration 81/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 83/250, Loss: 0.0104\n",
      "Epoch 159/200, Iteration 84/250, Loss: 0.0148\n",
      "Epoch 159/200, Iteration 85/250, Loss: 0.0189\n",
      "Epoch 159/200, Iteration 86/250, Loss: 0.0180\n",
      "Epoch 159/200, Iteration 87/250, Loss: 0.0098\n",
      "Epoch 159/200, Iteration 88/250, Loss: 0.0105\n",
      "Epoch 159/200, Iteration 89/250, Loss: 0.0263\n",
      "Epoch 159/200, Iteration 90/250, Loss: 0.0092\n",
      "Epoch 159/200, Iteration 91/250, Loss: 0.0082\n",
      "Epoch 159/200, Iteration 92/250, Loss: 0.0129\n",
      "Epoch 159/200, Iteration 93/250, Loss: 0.0090\n",
      "Epoch 159/200, Iteration 94/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 95/250, Loss: 0.0107\n",
      "Epoch 159/200, Iteration 96/250, Loss: 0.0072\n",
      "Epoch 159/200, Iteration 97/250, Loss: 0.0273\n",
      "Epoch 159/200, Iteration 98/250, Loss: 0.0240\n",
      "Epoch 159/200, Iteration 99/250, Loss: 0.0253\n",
      "Epoch 159/200, Iteration 100/250, Loss: 0.0093\n",
      "Epoch 159/200, Iteration 101/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 102/250, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 103/250, Loss: 0.0083\n",
      "Epoch 159/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 159/200, Iteration 105/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 106/250, Loss: 0.0258\n",
      "Epoch 159/200, Iteration 107/250, Loss: 0.0091\n",
      "Epoch 159/200, Iteration 108/250, Loss: 0.0150\n",
      "Epoch 159/200, Iteration 109/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 110/250, Loss: 0.0222\n",
      "Epoch 159/200, Iteration 111/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 112/250, Loss: 0.0073\n",
      "Epoch 159/200, Iteration 113/250, Loss: 0.0071\n",
      "Epoch 159/200, Iteration 114/250, Loss: 0.0151\n",
      "Epoch 159/200, Iteration 115/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 116/250, Loss: 0.0246\n",
      "Epoch 159/200, Iteration 117/250, Loss: 0.0096\n",
      "Epoch 159/200, Iteration 118/250, Loss: 0.0147\n",
      "Epoch 159/200, Iteration 119/250, Loss: 0.0199\n",
      "Epoch 159/200, Iteration 120/250, Loss: 0.0072\n",
      "Epoch 159/200, Iteration 121/250, Loss: 0.0078\n",
      "Epoch 159/200, Iteration 122/250, Loss: 0.0080\n",
      "Epoch 159/200, Iteration 123/250, Loss: 0.0074\n",
      "Epoch 159/200, Iteration 124/250, Loss: 0.0231\n",
      "Epoch 159/200, Iteration 125/250, Loss: 0.0349\n",
      "Epoch 159/200, Iteration 126/250, Loss: 0.0179\n",
      "Epoch 159/200, Iteration 127/250, Loss: 0.0105\n",
      "Epoch 159/200, Iteration 128/250, Loss: 0.0110\n",
      "Epoch 159/200, Iteration 129/250, Loss: 0.0098\n",
      "Epoch 159/200, Iteration 130/250, Loss: 0.0155\n",
      "Epoch 159/200, Iteration 131/250, Loss: 0.0319\n",
      "Epoch 159/200, Iteration 132/250, Loss: 0.0088\n",
      "Epoch 159/200, Iteration 133/250, Loss: 0.0171\n",
      "Epoch 159/200, Iteration 134/250, Loss: 0.0132\n",
      "Epoch 159/200, Iteration 135/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 136/250, Loss: 0.0066\n",
      "Epoch 159/200, Iteration 137/250, Loss: 0.0337\n",
      "Epoch 159/200, Iteration 138/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 139/250, Loss: 0.0085\n",
      "Epoch 159/200, Iteration 140/250, Loss: 0.0110\n",
      "Epoch 159/200, Iteration 141/250, Loss: 0.0099\n",
      "Epoch 159/200, Iteration 142/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 159/200, Iteration 144/250, Loss: 0.0172\n",
      "Epoch 159/200, Iteration 145/250, Loss: 0.0235\n",
      "Epoch 159/200, Iteration 146/250, Loss: 0.0231\n",
      "Epoch 159/200, Iteration 147/250, Loss: 0.0126\n",
      "Epoch 159/200, Iteration 148/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 149/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 150/250, Loss: 0.0332\n",
      "Epoch 159/200, Iteration 151/250, Loss: 0.0084\n",
      "Epoch 159/200, Iteration 152/250, Loss: 0.0128\n",
      "Epoch 159/200, Iteration 153/250, Loss: 0.0175\n",
      "Epoch 159/200, Iteration 154/250, Loss: 0.0280\n",
      "Epoch 159/200, Iteration 155/250, Loss: 0.0195\n",
      "Epoch 159/200, Iteration 156/250, Loss: 0.0109\n",
      "Epoch 159/200, Iteration 157/250, Loss: 0.0106\n",
      "Epoch 159/200, Iteration 158/250, Loss: 0.0207\n",
      "Epoch 159/200, Iteration 159/250, Loss: 0.0129\n",
      "Epoch 159/200, Iteration 160/250, Loss: 0.0166\n",
      "Epoch 159/200, Iteration 161/250, Loss: 0.0146\n",
      "Epoch 159/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 159/200, Iteration 163/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 164/250, Loss: 0.0149\n",
      "Epoch 159/200, Iteration 165/250, Loss: 0.0125\n",
      "Epoch 159/200, Iteration 166/250, Loss: 0.0220\n",
      "Epoch 159/200, Iteration 167/250, Loss: 0.0192\n",
      "Epoch 159/200, Iteration 168/250, Loss: 0.0075\n",
      "Epoch 159/200, Iteration 169/250, Loss: 0.0125\n",
      "Epoch 159/200, Iteration 170/250, Loss: 0.0394\n",
      "Epoch 159/200, Iteration 171/250, Loss: 0.0069\n",
      "Epoch 159/200, Iteration 172/250, Loss: 0.0068\n",
      "Epoch 159/200, Iteration 173/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 174/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 175/250, Loss: 0.0086\n",
      "Epoch 159/200, Iteration 176/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 177/250, Loss: 0.0094\n",
      "Epoch 159/200, Iteration 178/250, Loss: 0.0100\n",
      "Epoch 159/200, Iteration 179/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 180/250, Loss: 0.0231\n",
      "Epoch 159/200, Iteration 181/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 182/250, Loss: 0.0132\n",
      "Epoch 159/200, Iteration 183/250, Loss: 0.0112\n",
      "Epoch 159/200, Iteration 184/250, Loss: 0.0075\n",
      "Epoch 159/200, Iteration 185/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 186/250, Loss: 0.0134\n",
      "Epoch 159/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 159/200, Iteration 188/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 189/250, Loss: 0.0165\n",
      "Epoch 159/200, Iteration 190/250, Loss: 0.0224\n",
      "Epoch 159/200, Iteration 191/250, Loss: 0.0188\n",
      "Epoch 159/200, Iteration 192/250, Loss: 0.0207\n",
      "Epoch 159/200, Iteration 193/250, Loss: 0.0171\n",
      "Epoch 159/200, Iteration 194/250, Loss: 0.0076\n",
      "Epoch 159/200, Iteration 195/250, Loss: 0.0173\n",
      "Epoch 159/200, Iteration 196/250, Loss: 0.0153\n",
      "Epoch 159/200, Iteration 197/250, Loss: 0.0171\n",
      "Epoch 159/200, Iteration 198/250, Loss: 0.0104\n",
      "Epoch 159/200, Iteration 199/250, Loss: 0.0177\n",
      "Epoch 159/200, Iteration 200/250, Loss: 0.0281\n",
      "Epoch 159/200, Iteration 201/250, Loss: 0.0133\n",
      "Epoch 159/200, Iteration 202/250, Loss: 0.0093\n",
      "Epoch 159/200, Iteration 203/250, Loss: 0.0183\n",
      "Epoch 159/200, Iteration 204/250, Loss: 0.0101\n",
      "Epoch 159/200, Iteration 205/250, Loss: 0.0300\n",
      "Epoch 159/200, Iteration 206/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 207/250, Loss: 0.0175\n",
      "Epoch 159/200, Iteration 208/250, Loss: 0.0163\n",
      "Epoch 159/200, Iteration 209/250, Loss: 0.0088\n",
      "Epoch 159/200, Iteration 210/250, Loss: 0.0224\n",
      "Epoch 159/200, Iteration 211/250, Loss: 0.0224\n",
      "Epoch 159/200, Iteration 212/250, Loss: 0.0161\n",
      "Epoch 159/200, Iteration 213/250, Loss: 0.0125\n",
      "Epoch 159/200, Iteration 214/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 215/250, Loss: 0.0069\n",
      "Epoch 159/200, Iteration 216/250, Loss: 0.0139\n",
      "Epoch 159/200, Iteration 217/250, Loss: 0.0146\n",
      "Epoch 159/200, Iteration 218/250, Loss: 0.0121\n",
      "Epoch 159/200, Iteration 219/250, Loss: 0.0087\n",
      "Epoch 159/200, Iteration 220/250, Loss: 0.0143\n",
      "Epoch 159/200, Iteration 221/250, Loss: 0.0097\n",
      "Epoch 159/200, Iteration 222/250, Loss: 0.0138\n",
      "Epoch 159/200, Iteration 223/250, Loss: 0.0164\n",
      "Epoch 159/200, Iteration 224/250, Loss: 0.0249\n",
      "Epoch 159/200, Iteration 225/250, Loss: 0.0143\n",
      "Epoch 159/200, Iteration 226/250, Loss: 0.0099\n",
      "Epoch 159/200, Iteration 227/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 228/250, Loss: 0.0145\n",
      "Epoch 159/200, Iteration 229/250, Loss: 0.0163\n",
      "Epoch 159/200, Iteration 230/250, Loss: 0.0108\n",
      "Epoch 159/200, Iteration 231/250, Loss: 0.0183\n",
      "Epoch 159/200, Iteration 232/250, Loss: 0.0193\n",
      "Epoch 159/200, Iteration 233/250, Loss: 0.0059\n",
      "Epoch 159/200, Iteration 234/250, Loss: 0.0181\n",
      "Epoch 159/200, Iteration 235/250, Loss: 0.0095\n",
      "Epoch 159/200, Iteration 236/250, Loss: 0.0249\n",
      "Epoch 159/200, Iteration 237/250, Loss: 0.0184\n",
      "Epoch 159/200, Iteration 238/250, Loss: 0.0116\n",
      "Epoch 159/200, Iteration 239/250, Loss: 0.0167\n",
      "Epoch 159/200, Iteration 240/250, Loss: 0.0079\n",
      "Epoch 159/200, Iteration 241/250, Loss: 0.0095\n",
      "Epoch 159/200, Iteration 242/250, Loss: 0.0080\n",
      "Epoch 159/200, Iteration 243/250, Loss: 0.0253\n",
      "Epoch 159/200, Iteration 244/250, Loss: 0.0119\n",
      "Epoch 159/200, Iteration 245/250, Loss: 0.0070\n",
      "Epoch 159/200, Iteration 246/250, Loss: 0.0101\n",
      "Epoch 159/200, Iteration 247/250, Loss: 0.0066\n",
      "Epoch 159/200, Iteration 248/250, Loss: 0.0189\n",
      "Epoch 159/200, Iteration 249/250, Loss: 0.0132\n",
      "Epoch 159/200, Iteration 250/250, Loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 72.32%, Avg loss: 0.008194, MRE: 0.488382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.008625, MRE: 0.637596 \n",
      "\n",
      "Epoch 160/200, Iteration 1/250, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 2/250, Loss: 0.0185\n",
      "Epoch 160/200, Iteration 3/250, Loss: 0.0097\n",
      "Epoch 160/200, Iteration 4/250, Loss: 0.0236\n",
      "Epoch 160/200, Iteration 5/250, Loss: 0.0135\n",
      "Epoch 160/200, Iteration 6/250, Loss: 0.0144\n",
      "Epoch 160/200, Iteration 7/250, Loss: 0.0247\n",
      "Epoch 160/200, Iteration 8/250, Loss: 0.0151\n",
      "Epoch 160/200, Iteration 9/250, Loss: 0.0185\n",
      "Epoch 160/200, Iteration 10/250, Loss: 0.0100\n",
      "Epoch 160/200, Iteration 11/250, Loss: 0.0173\n",
      "Epoch 160/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 13/250, Loss: 0.0154\n",
      "Epoch 160/200, Iteration 14/250, Loss: 0.0154\n",
      "Epoch 160/200, Iteration 15/250, Loss: 0.0179\n",
      "Epoch 160/200, Iteration 16/250, Loss: 0.0153\n",
      "Epoch 160/200, Iteration 17/250, Loss: 0.0123\n",
      "Epoch 160/200, Iteration 18/250, Loss: 0.0144\n",
      "Epoch 160/200, Iteration 19/250, Loss: 0.0148\n",
      "Epoch 160/200, Iteration 20/250, Loss: 0.0214\n",
      "Epoch 160/200, Iteration 21/250, Loss: 0.0086\n",
      "Epoch 160/200, Iteration 22/250, Loss: 0.0115\n",
      "Epoch 160/200, Iteration 23/250, Loss: 0.0118\n",
      "Epoch 160/200, Iteration 24/250, Loss: 0.0193\n",
      "Epoch 160/200, Iteration 25/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 26/250, Loss: 0.0148\n",
      "Epoch 160/200, Iteration 27/250, Loss: 0.0072\n",
      "Epoch 160/200, Iteration 28/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 29/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 30/250, Loss: 0.0219\n",
      "Epoch 160/200, Iteration 31/250, Loss: 0.0141\n",
      "Epoch 160/200, Iteration 32/250, Loss: 0.0118\n",
      "Epoch 160/200, Iteration 33/250, Loss: 0.0102\n",
      "Epoch 160/200, Iteration 34/250, Loss: 0.0127\n",
      "Epoch 160/200, Iteration 35/250, Loss: 0.0155\n",
      "Epoch 160/200, Iteration 36/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 37/250, Loss: 0.0180\n",
      "Epoch 160/200, Iteration 38/250, Loss: 0.0144\n",
      "Epoch 160/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 160/200, Iteration 40/250, Loss: 0.0133\n",
      "Epoch 160/200, Iteration 41/250, Loss: 0.0136\n",
      "Epoch 160/200, Iteration 42/250, Loss: 0.0323\n",
      "Epoch 160/200, Iteration 43/250, Loss: 0.0174\n",
      "Epoch 160/200, Iteration 44/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 45/250, Loss: 0.0355\n",
      "Epoch 160/200, Iteration 46/250, Loss: 0.0110\n",
      "Epoch 160/200, Iteration 47/250, Loss: 0.0094\n",
      "Epoch 160/200, Iteration 48/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 49/250, Loss: 0.0106\n",
      "Epoch 160/200, Iteration 50/250, Loss: 0.0233\n",
      "Epoch 160/200, Iteration 51/250, Loss: 0.0122\n",
      "Epoch 160/200, Iteration 52/250, Loss: 0.0183\n",
      "Epoch 160/200, Iteration 53/250, Loss: 0.0316\n",
      "Epoch 160/200, Iteration 54/250, Loss: 0.0234\n",
      "Epoch 160/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 56/250, Loss: 0.0088\n",
      "Epoch 160/200, Iteration 57/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 58/250, Loss: 0.0157\n",
      "Epoch 160/200, Iteration 59/250, Loss: 0.0162\n",
      "Epoch 160/200, Iteration 60/250, Loss: 0.0119\n",
      "Epoch 160/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 160/200, Iteration 62/250, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 63/250, Loss: 0.0291\n",
      "Epoch 160/200, Iteration 64/250, Loss: 0.0359\n",
      "Epoch 160/200, Iteration 65/250, Loss: 0.0255\n",
      "Epoch 160/200, Iteration 66/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 67/250, Loss: 0.0102\n",
      "Epoch 160/200, Iteration 68/250, Loss: 0.0125\n",
      "Epoch 160/200, Iteration 69/250, Loss: 0.0235\n",
      "Epoch 160/200, Iteration 70/250, Loss: 0.0176\n",
      "Epoch 160/200, Iteration 71/250, Loss: 0.0150\n",
      "Epoch 160/200, Iteration 72/250, Loss: 0.0124\n",
      "Epoch 160/200, Iteration 73/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 74/250, Loss: 0.0084\n",
      "Epoch 160/200, Iteration 75/250, Loss: 0.0088\n",
      "Epoch 160/200, Iteration 76/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 77/250, Loss: 0.0098\n",
      "Epoch 160/200, Iteration 78/250, Loss: 0.0284\n",
      "Epoch 160/200, Iteration 79/250, Loss: 0.0273\n",
      "Epoch 160/200, Iteration 80/250, Loss: 0.0074\n",
      "Epoch 160/200, Iteration 81/250, Loss: 0.0234\n",
      "Epoch 160/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 160/200, Iteration 83/250, Loss: 0.0108\n",
      "Epoch 160/200, Iteration 84/250, Loss: 0.0117\n",
      "Epoch 160/200, Iteration 85/250, Loss: 0.0236\n",
      "Epoch 160/200, Iteration 86/250, Loss: 0.0111\n",
      "Epoch 160/200, Iteration 87/250, Loss: 0.0153\n",
      "Epoch 160/200, Iteration 88/250, Loss: 0.0182\n",
      "Epoch 160/200, Iteration 89/250, Loss: 0.0120\n",
      "Epoch 160/200, Iteration 90/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 91/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 92/250, Loss: 0.0108\n",
      "Epoch 160/200, Iteration 93/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 94/250, Loss: 0.0142\n",
      "Epoch 160/200, Iteration 95/250, Loss: 0.0261\n",
      "Epoch 160/200, Iteration 96/250, Loss: 0.0113\n",
      "Epoch 160/200, Iteration 97/250, Loss: 0.0103\n",
      "Epoch 160/200, Iteration 98/250, Loss: 0.0349\n",
      "Epoch 160/200, Iteration 99/250, Loss: 0.0412\n",
      "Epoch 160/200, Iteration 100/250, Loss: 0.0197\n",
      "Epoch 160/200, Iteration 101/250, Loss: 0.0220\n",
      "Epoch 160/200, Iteration 102/250, Loss: 0.0078\n",
      "Epoch 160/200, Iteration 103/250, Loss: 0.0126\n",
      "Epoch 160/200, Iteration 104/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 105/250, Loss: 0.0102\n",
      "Epoch 160/200, Iteration 106/250, Loss: 0.0193\n",
      "Epoch 160/200, Iteration 107/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 108/250, Loss: 0.0100\n",
      "Epoch 160/200, Iteration 109/250, Loss: 0.0275\n",
      "Epoch 160/200, Iteration 110/250, Loss: 0.0262\n",
      "Epoch 160/200, Iteration 111/250, Loss: 0.0250\n",
      "Epoch 160/200, Iteration 112/250, Loss: 0.0172\n",
      "Epoch 160/200, Iteration 113/250, Loss: 0.0235\n",
      "Epoch 160/200, Iteration 114/250, Loss: 0.0132\n",
      "Epoch 160/200, Iteration 115/250, Loss: 0.0072\n",
      "Epoch 160/200, Iteration 116/250, Loss: 0.0123\n",
      "Epoch 160/200, Iteration 117/250, Loss: 0.0150\n",
      "Epoch 160/200, Iteration 118/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 119/250, Loss: 0.0082\n",
      "Epoch 160/200, Iteration 120/250, Loss: 0.0136\n",
      "Epoch 160/200, Iteration 121/250, Loss: 0.0071\n",
      "Epoch 160/200, Iteration 122/250, Loss: 0.0250\n",
      "Epoch 160/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 124/250, Loss: 0.0145\n",
      "Epoch 160/200, Iteration 125/250, Loss: 0.0230\n",
      "Epoch 160/200, Iteration 126/250, Loss: 0.0169\n",
      "Epoch 160/200, Iteration 127/250, Loss: 0.0187\n",
      "Epoch 160/200, Iteration 128/250, Loss: 0.0237\n",
      "Epoch 160/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 160/200, Iteration 130/250, Loss: 0.0156\n",
      "Epoch 160/200, Iteration 131/250, Loss: 0.0104\n",
      "Epoch 160/200, Iteration 132/250, Loss: 0.0131\n",
      "Epoch 160/200, Iteration 133/250, Loss: 0.0133\n",
      "Epoch 160/200, Iteration 134/250, Loss: 0.0093\n",
      "Epoch 160/200, Iteration 135/250, Loss: 0.0242\n",
      "Epoch 160/200, Iteration 136/250, Loss: 0.0100\n",
      "Epoch 160/200, Iteration 137/250, Loss: 0.0173\n",
      "Epoch 160/200, Iteration 138/250, Loss: 0.0077\n",
      "Epoch 160/200, Iteration 139/250, Loss: 0.0166\n",
      "Epoch 160/200, Iteration 140/250, Loss: 0.0108\n",
      "Epoch 160/200, Iteration 141/250, Loss: 0.0126\n",
      "Epoch 160/200, Iteration 142/250, Loss: 0.0288\n",
      "Epoch 160/200, Iteration 143/250, Loss: 0.0166\n",
      "Epoch 160/200, Iteration 144/250, Loss: 0.0098\n",
      "Epoch 160/200, Iteration 145/250, Loss: 0.0121\n",
      "Epoch 160/200, Iteration 146/250, Loss: 0.0120\n",
      "Epoch 160/200, Iteration 147/250, Loss: 0.0140\n",
      "Epoch 160/200, Iteration 148/250, Loss: 0.0304\n",
      "Epoch 160/200, Iteration 149/250, Loss: 0.0191\n",
      "Epoch 160/200, Iteration 150/250, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 151/250, Loss: 0.0143\n",
      "Epoch 160/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 160/200, Iteration 153/250, Loss: 0.0173\n",
      "Epoch 160/200, Iteration 154/250, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 155/250, Loss: 0.0247\n",
      "Epoch 160/200, Iteration 156/250, Loss: 0.0163\n",
      "Epoch 160/200, Iteration 157/250, Loss: 0.0084\n",
      "Epoch 160/200, Iteration 158/250, Loss: 0.0112\n",
      "Epoch 160/200, Iteration 159/250, Loss: 0.0294\n",
      "Epoch 160/200, Iteration 160/250, Loss: 0.0303\n",
      "Epoch 160/200, Iteration 161/250, Loss: 0.0127\n",
      "Epoch 160/200, Iteration 162/250, Loss: 0.0127\n",
      "Epoch 160/200, Iteration 163/250, Loss: 0.0183\n",
      "Epoch 160/200, Iteration 164/250, Loss: 0.0216\n",
      "Epoch 160/200, Iteration 165/250, Loss: 0.0113\n",
      "Epoch 160/200, Iteration 166/250, Loss: 0.0106\n",
      "Epoch 160/200, Iteration 167/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 168/250, Loss: 0.0216\n",
      "Epoch 160/200, Iteration 169/250, Loss: 0.0254\n",
      "Epoch 160/200, Iteration 170/250, Loss: 0.0149\n",
      "Epoch 160/200, Iteration 171/250, Loss: 0.0169\n",
      "Epoch 160/200, Iteration 172/250, Loss: 0.0086\n",
      "Epoch 160/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 160/200, Iteration 174/250, Loss: 0.0429\n",
      "Epoch 160/200, Iteration 175/250, Loss: 0.0087\n",
      "Epoch 160/200, Iteration 176/250, Loss: 0.0183\n",
      "Epoch 160/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 178/250, Loss: 0.0273\n",
      "Epoch 160/200, Iteration 179/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 180/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 181/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 182/250, Loss: 0.0207\n",
      "Epoch 160/200, Iteration 183/250, Loss: 0.0175\n",
      "Epoch 160/200, Iteration 184/250, Loss: 0.0103\n",
      "Epoch 160/200, Iteration 185/250, Loss: 0.0281\n",
      "Epoch 160/200, Iteration 186/250, Loss: 0.0327\n",
      "Epoch 160/200, Iteration 187/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 188/250, Loss: 0.0172\n",
      "Epoch 160/200, Iteration 189/250, Loss: 0.0130\n",
      "Epoch 160/200, Iteration 190/250, Loss: 0.0073\n",
      "Epoch 160/200, Iteration 191/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 192/250, Loss: 0.0107\n",
      "Epoch 160/200, Iteration 193/250, Loss: 0.0108\n",
      "Epoch 160/200, Iteration 194/250, Loss: 0.0117\n",
      "Epoch 160/200, Iteration 195/250, Loss: 0.0288\n",
      "Epoch 160/200, Iteration 196/250, Loss: 0.0082\n",
      "Epoch 160/200, Iteration 197/250, Loss: 0.0142\n",
      "Epoch 160/200, Iteration 198/250, Loss: 0.0306\n",
      "Epoch 160/200, Iteration 199/250, Loss: 0.0246\n",
      "Epoch 160/200, Iteration 200/250, Loss: 0.0093\n",
      "Epoch 160/200, Iteration 201/250, Loss: 0.0091\n",
      "Epoch 160/200, Iteration 202/250, Loss: 0.0158\n",
      "Epoch 160/200, Iteration 203/250, Loss: 0.0067\n",
      "Epoch 160/200, Iteration 204/250, Loss: 0.0170\n",
      "Epoch 160/200, Iteration 205/250, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 206/250, Loss: 0.0129\n",
      "Epoch 160/200, Iteration 207/250, Loss: 0.0156\n",
      "Epoch 160/200, Iteration 208/250, Loss: 0.0201\n",
      "Epoch 160/200, Iteration 209/250, Loss: 0.0212\n",
      "Epoch 160/200, Iteration 210/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 160/200, Iteration 212/250, Loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, Iteration 213/250, Loss: 0.0078\n",
      "Epoch 160/200, Iteration 214/250, Loss: 0.0090\n",
      "Epoch 160/200, Iteration 215/250, Loss: 0.0191\n",
      "Epoch 160/200, Iteration 216/250, Loss: 0.0094\n",
      "Epoch 160/200, Iteration 217/250, Loss: 0.0115\n",
      "Epoch 160/200, Iteration 218/250, Loss: 0.0080\n",
      "Epoch 160/200, Iteration 219/250, Loss: 0.0307\n",
      "Epoch 160/200, Iteration 220/250, Loss: 0.0221\n",
      "Epoch 160/200, Iteration 221/250, Loss: 0.0160\n",
      "Epoch 160/200, Iteration 222/250, Loss: 0.0280\n",
      "Epoch 160/200, Iteration 223/250, Loss: 0.0116\n",
      "Epoch 160/200, Iteration 224/250, Loss: 0.0200\n",
      "Epoch 160/200, Iteration 225/250, Loss: 0.0075\n",
      "Epoch 160/200, Iteration 226/250, Loss: 0.0234\n",
      "Epoch 160/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 160/200, Iteration 228/250, Loss: 0.0146\n",
      "Epoch 160/200, Iteration 229/250, Loss: 0.0152\n",
      "Epoch 160/200, Iteration 230/250, Loss: 0.0170\n",
      "Epoch 160/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 160/200, Iteration 232/250, Loss: 0.0097\n",
      "Epoch 160/200, Iteration 233/250, Loss: 0.0134\n",
      "Epoch 160/200, Iteration 234/250, Loss: 0.0138\n",
      "Epoch 160/200, Iteration 235/250, Loss: 0.0069\n",
      "Epoch 160/200, Iteration 236/250, Loss: 0.0135\n",
      "Epoch 160/200, Iteration 237/250, Loss: 0.0098\n",
      "Epoch 160/200, Iteration 238/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 239/250, Loss: 0.0196\n",
      "Epoch 160/200, Iteration 240/250, Loss: 0.0104\n",
      "Epoch 160/200, Iteration 241/250, Loss: 0.0461\n",
      "Epoch 160/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 160/200, Iteration 243/250, Loss: 0.0189\n",
      "Epoch 160/200, Iteration 244/250, Loss: 0.0284\n",
      "Epoch 160/200, Iteration 245/250, Loss: 0.0154\n",
      "Epoch 160/200, Iteration 246/250, Loss: 0.0108\n",
      "Epoch 160/200, Iteration 247/250, Loss: 0.0195\n",
      "Epoch 160/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 160/200, Iteration 249/250, Loss: 0.0081\n",
      "Epoch 160/200, Iteration 250/250, Loss: 0.0136\n",
      "Train Error: \n",
      " Accuracy: 76.44%, Avg loss: 0.007853, MRE: 0.589075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.008241, MRE: 0.697501 \n",
      "\n",
      "Epoch 161/200, Iteration 1/250, Loss: 0.0087\n",
      "Epoch 161/200, Iteration 2/250, Loss: 0.0265\n",
      "Epoch 161/200, Iteration 3/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 4/250, Loss: 0.0117\n",
      "Epoch 161/200, Iteration 5/250, Loss: 0.0378\n",
      "Epoch 161/200, Iteration 6/250, Loss: 0.0344\n",
      "Epoch 161/200, Iteration 7/250, Loss: 0.0084\n",
      "Epoch 161/200, Iteration 8/250, Loss: 0.0154\n",
      "Epoch 161/200, Iteration 9/250, Loss: 0.0148\n",
      "Epoch 161/200, Iteration 10/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 11/250, Loss: 0.0071\n",
      "Epoch 161/200, Iteration 12/250, Loss: 0.0126\n",
      "Epoch 161/200, Iteration 13/250, Loss: 0.0140\n",
      "Epoch 161/200, Iteration 14/250, Loss: 0.0201\n",
      "Epoch 161/200, Iteration 15/250, Loss: 0.0071\n",
      "Epoch 161/200, Iteration 16/250, Loss: 0.0111\n",
      "Epoch 161/200, Iteration 17/250, Loss: 0.0182\n",
      "Epoch 161/200, Iteration 18/250, Loss: 0.0154\n",
      "Epoch 161/200, Iteration 19/250, Loss: 0.0145\n",
      "Epoch 161/200, Iteration 20/250, Loss: 0.0157\n",
      "Epoch 161/200, Iteration 21/250, Loss: 0.0071\n",
      "Epoch 161/200, Iteration 22/250, Loss: 0.0143\n",
      "Epoch 161/200, Iteration 23/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 24/250, Loss: 0.0200\n",
      "Epoch 161/200, Iteration 25/250, Loss: 0.0192\n",
      "Epoch 161/200, Iteration 26/250, Loss: 0.0123\n",
      "Epoch 161/200, Iteration 27/250, Loss: 0.0248\n",
      "Epoch 161/200, Iteration 28/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 29/250, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 30/250, Loss: 0.0223\n",
      "Epoch 161/200, Iteration 31/250, Loss: 0.0244\n",
      "Epoch 161/200, Iteration 32/250, Loss: 0.0148\n",
      "Epoch 161/200, Iteration 33/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 34/250, Loss: 0.0246\n",
      "Epoch 161/200, Iteration 35/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 36/250, Loss: 0.0092\n",
      "Epoch 161/200, Iteration 37/250, Loss: 0.0083\n",
      "Epoch 161/200, Iteration 38/250, Loss: 0.0098\n",
      "Epoch 161/200, Iteration 39/250, Loss: 0.0105\n",
      "Epoch 161/200, Iteration 40/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 41/250, Loss: 0.0084\n",
      "Epoch 161/200, Iteration 42/250, Loss: 0.0064\n",
      "Epoch 161/200, Iteration 43/250, Loss: 0.0249\n",
      "Epoch 161/200, Iteration 44/250, Loss: 0.0081\n",
      "Epoch 161/200, Iteration 45/250, Loss: 0.0476\n",
      "Epoch 161/200, Iteration 46/250, Loss: 0.0118\n",
      "Epoch 161/200, Iteration 47/250, Loss: 0.0189\n",
      "Epoch 161/200, Iteration 48/250, Loss: 0.0155\n",
      "Epoch 161/200, Iteration 49/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 50/250, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 51/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 52/250, Loss: 0.0331\n",
      "Epoch 161/200, Iteration 53/250, Loss: 0.0280\n",
      "Epoch 161/200, Iteration 54/250, Loss: 0.0142\n",
      "Epoch 161/200, Iteration 55/250, Loss: 0.0303\n",
      "Epoch 161/200, Iteration 56/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 57/250, Loss: 0.0120\n",
      "Epoch 161/200, Iteration 58/250, Loss: 0.0223\n",
      "Epoch 161/200, Iteration 59/250, Loss: 0.0084\n",
      "Epoch 161/200, Iteration 60/250, Loss: 0.0157\n",
      "Epoch 161/200, Iteration 61/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 62/250, Loss: 0.0158\n",
      "Epoch 161/200, Iteration 63/250, Loss: 0.0123\n",
      "Epoch 161/200, Iteration 64/250, Loss: 0.0118\n",
      "Epoch 161/200, Iteration 65/250, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 66/250, Loss: 0.0075\n",
      "Epoch 161/200, Iteration 67/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 68/250, Loss: 0.0180\n",
      "Epoch 161/200, Iteration 69/250, Loss: 0.0094\n",
      "Epoch 161/200, Iteration 70/250, Loss: 0.0098\n",
      "Epoch 161/200, Iteration 71/250, Loss: 0.0083\n",
      "Epoch 161/200, Iteration 72/250, Loss: 0.0150\n",
      "Epoch 161/200, Iteration 73/250, Loss: 0.0067\n",
      "Epoch 161/200, Iteration 74/250, Loss: 0.0165\n",
      "Epoch 161/200, Iteration 75/250, Loss: 0.0148\n",
      "Epoch 161/200, Iteration 76/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 77/250, Loss: 0.0340\n",
      "Epoch 161/200, Iteration 78/250, Loss: 0.0161\n",
      "Epoch 161/200, Iteration 79/250, Loss: 0.0104\n",
      "Epoch 161/200, Iteration 80/250, Loss: 0.0405\n",
      "Epoch 161/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 82/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 161/200, Iteration 84/250, Loss: 0.0116\n",
      "Epoch 161/200, Iteration 85/250, Loss: 0.0085\n",
      "Epoch 161/200, Iteration 86/250, Loss: 0.0225\n",
      "Epoch 161/200, Iteration 87/250, Loss: 0.0131\n",
      "Epoch 161/200, Iteration 88/250, Loss: 0.0110\n",
      "Epoch 161/200, Iteration 89/250, Loss: 0.0130\n",
      "Epoch 161/200, Iteration 90/250, Loss: 0.0099\n",
      "Epoch 161/200, Iteration 91/250, Loss: 0.0161\n",
      "Epoch 161/200, Iteration 92/250, Loss: 0.0261\n",
      "Epoch 161/200, Iteration 93/250, Loss: 0.0238\n",
      "Epoch 161/200, Iteration 94/250, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 95/250, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 96/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 97/250, Loss: 0.0249\n",
      "Epoch 161/200, Iteration 98/250, Loss: 0.0240\n",
      "Epoch 161/200, Iteration 99/250, Loss: 0.0172\n",
      "Epoch 161/200, Iteration 100/250, Loss: 0.0179\n",
      "Epoch 161/200, Iteration 101/250, Loss: 0.0195\n",
      "Epoch 161/200, Iteration 102/250, Loss: 0.0182\n",
      "Epoch 161/200, Iteration 103/250, Loss: 0.0171\n",
      "Epoch 161/200, Iteration 104/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 105/250, Loss: 0.0214\n",
      "Epoch 161/200, Iteration 106/250, Loss: 0.0143\n",
      "Epoch 161/200, Iteration 107/250, Loss: 0.0150\n",
      "Epoch 161/200, Iteration 108/250, Loss: 0.0144\n",
      "Epoch 161/200, Iteration 109/250, Loss: 0.0109\n",
      "Epoch 161/200, Iteration 110/250, Loss: 0.0079\n",
      "Epoch 161/200, Iteration 111/250, Loss: 0.0178\n",
      "Epoch 161/200, Iteration 112/250, Loss: 0.0070\n",
      "Epoch 161/200, Iteration 113/250, Loss: 0.0182\n",
      "Epoch 161/200, Iteration 114/250, Loss: 0.0301\n",
      "Epoch 161/200, Iteration 115/250, Loss: 0.0057\n",
      "Epoch 161/200, Iteration 116/250, Loss: 0.0204\n",
      "Epoch 161/200, Iteration 117/250, Loss: 0.0184\n",
      "Epoch 161/200, Iteration 118/250, Loss: 0.0255\n",
      "Epoch 161/200, Iteration 119/250, Loss: 0.0256\n",
      "Epoch 161/200, Iteration 120/250, Loss: 0.0076\n",
      "Epoch 161/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 161/200, Iteration 122/250, Loss: 0.0159\n",
      "Epoch 161/200, Iteration 123/250, Loss: 0.0084\n",
      "Epoch 161/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 125/250, Loss: 0.0111\n",
      "Epoch 161/200, Iteration 126/250, Loss: 0.0222\n",
      "Epoch 161/200, Iteration 127/250, Loss: 0.0151\n",
      "Epoch 161/200, Iteration 128/250, Loss: 0.0145\n",
      "Epoch 161/200, Iteration 129/250, Loss: 0.0093\n",
      "Epoch 161/200, Iteration 130/250, Loss: 0.0137\n",
      "Epoch 161/200, Iteration 131/250, Loss: 0.0258\n",
      "Epoch 161/200, Iteration 132/250, Loss: 0.0208\n",
      "Epoch 161/200, Iteration 133/250, Loss: 0.0220\n",
      "Epoch 161/200, Iteration 134/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 135/250, Loss: 0.0221\n",
      "Epoch 161/200, Iteration 136/250, Loss: 0.0322\n",
      "Epoch 161/200, Iteration 137/250, Loss: 0.0101\n",
      "Epoch 161/200, Iteration 138/250, Loss: 0.0136\n",
      "Epoch 161/200, Iteration 139/250, Loss: 0.0238\n",
      "Epoch 161/200, Iteration 140/250, Loss: 0.0257\n",
      "Epoch 161/200, Iteration 141/250, Loss: 0.0078\n",
      "Epoch 161/200, Iteration 142/250, Loss: 0.0141\n",
      "Epoch 161/200, Iteration 143/250, Loss: 0.0309\n",
      "Epoch 161/200, Iteration 144/250, Loss: 0.0121\n",
      "Epoch 161/200, Iteration 145/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 146/250, Loss: 0.0205\n",
      "Epoch 161/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 161/200, Iteration 148/250, Loss: 0.0115\n",
      "Epoch 161/200, Iteration 149/250, Loss: 0.0079\n",
      "Epoch 161/200, Iteration 150/250, Loss: 0.0142\n",
      "Epoch 161/200, Iteration 151/250, Loss: 0.0180\n",
      "Epoch 161/200, Iteration 152/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 153/250, Loss: 0.0148\n",
      "Epoch 161/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 161/200, Iteration 155/250, Loss: 0.0136\n",
      "Epoch 161/200, Iteration 156/250, Loss: 0.0159\n",
      "Epoch 161/200, Iteration 157/250, Loss: 0.0251\n",
      "Epoch 161/200, Iteration 158/250, Loss: 0.0106\n",
      "Epoch 161/200, Iteration 159/250, Loss: 0.0100\n",
      "Epoch 161/200, Iteration 160/250, Loss: 0.0212\n",
      "Epoch 161/200, Iteration 161/250, Loss: 0.0152\n",
      "Epoch 161/200, Iteration 162/250, Loss: 0.0079\n",
      "Epoch 161/200, Iteration 163/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 164/250, Loss: 0.0165\n",
      "Epoch 161/200, Iteration 165/250, Loss: 0.0224\n",
      "Epoch 161/200, Iteration 166/250, Loss: 0.0201\n",
      "Epoch 161/200, Iteration 167/250, Loss: 0.0278\n",
      "Epoch 161/200, Iteration 168/250, Loss: 0.0232\n",
      "Epoch 161/200, Iteration 169/250, Loss: 0.0193\n",
      "Epoch 161/200, Iteration 170/250, Loss: 0.0114\n",
      "Epoch 161/200, Iteration 171/250, Loss: 0.0056\n",
      "Epoch 161/200, Iteration 172/250, Loss: 0.0099\n",
      "Epoch 161/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 161/200, Iteration 174/250, Loss: 0.0163\n",
      "Epoch 161/200, Iteration 175/250, Loss: 0.0101\n",
      "Epoch 161/200, Iteration 176/250, Loss: 0.0207\n",
      "Epoch 161/200, Iteration 177/250, Loss: 0.0103\n",
      "Epoch 161/200, Iteration 178/250, Loss: 0.0252\n",
      "Epoch 161/200, Iteration 179/250, Loss: 0.0289\n",
      "Epoch 161/200, Iteration 180/250, Loss: 0.0205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200, Iteration 181/250, Loss: 0.0113\n",
      "Epoch 161/200, Iteration 182/250, Loss: 0.0104\n",
      "Epoch 161/200, Iteration 183/250, Loss: 0.0120\n",
      "Epoch 161/200, Iteration 184/250, Loss: 0.0095\n",
      "Epoch 161/200, Iteration 185/250, Loss: 0.0104\n",
      "Epoch 161/200, Iteration 186/250, Loss: 0.0134\n",
      "Epoch 161/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 161/200, Iteration 188/250, Loss: 0.0500\n",
      "Epoch 161/200, Iteration 189/250, Loss: 0.0260\n",
      "Epoch 161/200, Iteration 190/250, Loss: 0.0174\n",
      "Epoch 161/200, Iteration 191/250, Loss: 0.0161\n",
      "Epoch 161/200, Iteration 192/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 193/250, Loss: 0.0162\n",
      "Epoch 161/200, Iteration 194/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 161/200, Iteration 196/250, Loss: 0.0284\n",
      "Epoch 161/200, Iteration 197/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 198/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 199/250, Loss: 0.0245\n",
      "Epoch 161/200, Iteration 200/250, Loss: 0.0339\n",
      "Epoch 161/200, Iteration 201/250, Loss: 0.0244\n",
      "Epoch 161/200, Iteration 202/250, Loss: 0.0111\n",
      "Epoch 161/200, Iteration 203/250, Loss: 0.0183\n",
      "Epoch 161/200, Iteration 204/250, Loss: 0.0208\n",
      "Epoch 161/200, Iteration 205/250, Loss: 0.0511\n",
      "Epoch 161/200, Iteration 206/250, Loss: 0.0330\n",
      "Epoch 161/200, Iteration 207/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 208/250, Loss: 0.0099\n",
      "Epoch 161/200, Iteration 209/250, Loss: 0.0197\n",
      "Epoch 161/200, Iteration 210/250, Loss: 0.0103\n",
      "Epoch 161/200, Iteration 211/250, Loss: 0.0132\n",
      "Epoch 161/200, Iteration 212/250, Loss: 0.0069\n",
      "Epoch 161/200, Iteration 213/250, Loss: 0.0130\n",
      "Epoch 161/200, Iteration 214/250, Loss: 0.0177\n",
      "Epoch 161/200, Iteration 215/250, Loss: 0.0213\n",
      "Epoch 161/200, Iteration 216/250, Loss: 0.0132\n",
      "Epoch 161/200, Iteration 217/250, Loss: 0.0186\n",
      "Epoch 161/200, Iteration 218/250, Loss: 0.0360\n",
      "Epoch 161/200, Iteration 219/250, Loss: 0.0168\n",
      "Epoch 161/200, Iteration 220/250, Loss: 0.0140\n",
      "Epoch 161/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 161/200, Iteration 222/250, Loss: 0.0145\n",
      "Epoch 161/200, Iteration 223/250, Loss: 0.0062\n",
      "Epoch 161/200, Iteration 224/250, Loss: 0.0172\n",
      "Epoch 161/200, Iteration 225/250, Loss: 0.0127\n",
      "Epoch 161/200, Iteration 226/250, Loss: 0.0131\n",
      "Epoch 161/200, Iteration 227/250, Loss: 0.0156\n",
      "Epoch 161/200, Iteration 228/250, Loss: 0.0115\n",
      "Epoch 161/200, Iteration 229/250, Loss: 0.0186\n",
      "Epoch 161/200, Iteration 230/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 231/250, Loss: 0.0135\n",
      "Epoch 161/200, Iteration 232/250, Loss: 0.0077\n",
      "Epoch 161/200, Iteration 233/250, Loss: 0.0088\n",
      "Epoch 161/200, Iteration 234/250, Loss: 0.0147\n",
      "Epoch 161/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 161/200, Iteration 236/250, Loss: 0.0130\n",
      "Epoch 161/200, Iteration 237/250, Loss: 0.0134\n",
      "Epoch 161/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 161/200, Iteration 239/250, Loss: 0.0082\n",
      "Epoch 161/200, Iteration 240/250, Loss: 0.0110\n",
      "Epoch 161/200, Iteration 241/250, Loss: 0.0126\n",
      "Epoch 161/200, Iteration 242/250, Loss: 0.0132\n",
      "Epoch 161/200, Iteration 243/250, Loss: 0.0264\n",
      "Epoch 161/200, Iteration 244/250, Loss: 0.0303\n",
      "Epoch 161/200, Iteration 245/250, Loss: 0.0175\n",
      "Epoch 161/200, Iteration 246/250, Loss: 0.0102\n",
      "Epoch 161/200, Iteration 247/250, Loss: 0.0090\n",
      "Epoch 161/200, Iteration 248/250, Loss: 0.0108\n",
      "Epoch 161/200, Iteration 249/250, Loss: 0.0076\n",
      "Epoch 161/200, Iteration 250/250, Loss: 0.0099\n",
      "Train Error: \n",
      " Accuracy: 85.32%, Avg loss: 0.006783, MRE: 0.426913 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.45%, Avg loss: 0.007293, MRE: 0.541603 \n",
      "\n",
      "Epoch 162/200, Iteration 1/250, Loss: 0.0128\n",
      "Epoch 162/200, Iteration 2/250, Loss: 0.0092\n",
      "Epoch 162/200, Iteration 3/250, Loss: 0.0236\n",
      "Epoch 162/200, Iteration 4/250, Loss: 0.0185\n",
      "Epoch 162/200, Iteration 5/250, Loss: 0.0190\n",
      "Epoch 162/200, Iteration 6/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 162/200, Iteration 8/250, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 9/250, Loss: 0.0098\n",
      "Epoch 162/200, Iteration 10/250, Loss: 0.0082\n",
      "Epoch 162/200, Iteration 11/250, Loss: 0.0117\n",
      "Epoch 162/200, Iteration 12/250, Loss: 0.0077\n",
      "Epoch 162/200, Iteration 13/250, Loss: 0.0239\n",
      "Epoch 162/200, Iteration 14/250, Loss: 0.0174\n",
      "Epoch 162/200, Iteration 15/250, Loss: 0.0132\n",
      "Epoch 162/200, Iteration 16/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 17/250, Loss: 0.0060\n",
      "Epoch 162/200, Iteration 18/250, Loss: 0.0226\n",
      "Epoch 162/200, Iteration 19/250, Loss: 0.0215\n",
      "Epoch 162/200, Iteration 20/250, Loss: 0.0203\n",
      "Epoch 162/200, Iteration 21/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 22/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 23/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 24/250, Loss: 0.0204\n",
      "Epoch 162/200, Iteration 25/250, Loss: 0.0108\n",
      "Epoch 162/200, Iteration 26/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 27/250, Loss: 0.0081\n",
      "Epoch 162/200, Iteration 28/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 29/250, Loss: 0.0093\n",
      "Epoch 162/200, Iteration 30/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 31/250, Loss: 0.0101\n",
      "Epoch 162/200, Iteration 32/250, Loss: 0.0137\n",
      "Epoch 162/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 162/200, Iteration 34/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 35/250, Loss: 0.0202\n",
      "Epoch 162/200, Iteration 36/250, Loss: 0.0137\n",
      "Epoch 162/200, Iteration 37/250, Loss: 0.0170\n",
      "Epoch 162/200, Iteration 38/250, Loss: 0.0211\n",
      "Epoch 162/200, Iteration 39/250, Loss: 0.0205\n",
      "Epoch 162/200, Iteration 40/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 41/250, Loss: 0.0255\n",
      "Epoch 162/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 162/200, Iteration 43/250, Loss: 0.0093\n",
      "Epoch 162/200, Iteration 44/250, Loss: 0.0139\n",
      "Epoch 162/200, Iteration 45/250, Loss: 0.0144\n",
      "Epoch 162/200, Iteration 46/250, Loss: 0.0140\n",
      "Epoch 162/200, Iteration 47/250, Loss: 0.0078\n",
      "Epoch 162/200, Iteration 48/250, Loss: 0.0164\n",
      "Epoch 162/200, Iteration 49/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 50/250, Loss: 0.0122\n",
      "Epoch 162/200, Iteration 51/250, Loss: 0.0317\n",
      "Epoch 162/200, Iteration 52/250, Loss: 0.0270\n",
      "Epoch 162/200, Iteration 53/250, Loss: 0.0157\n",
      "Epoch 162/200, Iteration 54/250, Loss: 0.0187\n",
      "Epoch 162/200, Iteration 55/250, Loss: 0.0101\n",
      "Epoch 162/200, Iteration 56/250, Loss: 0.0140\n",
      "Epoch 162/200, Iteration 57/250, Loss: 0.0113\n",
      "Epoch 162/200, Iteration 58/250, Loss: 0.0104\n",
      "Epoch 162/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 162/200, Iteration 60/250, Loss: 0.0091\n",
      "Epoch 162/200, Iteration 61/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 62/250, Loss: 0.0162\n",
      "Epoch 162/200, Iteration 63/250, Loss: 0.0325\n",
      "Epoch 162/200, Iteration 64/250, Loss: 0.0077\n",
      "Epoch 162/200, Iteration 65/250, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 67/250, Loss: 0.0123\n",
      "Epoch 162/200, Iteration 68/250, Loss: 0.0099\n",
      "Epoch 162/200, Iteration 69/250, Loss: 0.0193\n",
      "Epoch 162/200, Iteration 70/250, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 71/250, Loss: 0.0148\n",
      "Epoch 162/200, Iteration 72/250, Loss: 0.0115\n",
      "Epoch 162/200, Iteration 73/250, Loss: 0.0089\n",
      "Epoch 162/200, Iteration 74/250, Loss: 0.0104\n",
      "Epoch 162/200, Iteration 75/250, Loss: 0.0240\n",
      "Epoch 162/200, Iteration 76/250, Loss: 0.0109\n",
      "Epoch 162/200, Iteration 77/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 78/250, Loss: 0.0119\n",
      "Epoch 162/200, Iteration 79/250, Loss: 0.0135\n",
      "Epoch 162/200, Iteration 80/250, Loss: 0.0319\n",
      "Epoch 162/200, Iteration 81/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 82/250, Loss: 0.0139\n",
      "Epoch 162/200, Iteration 83/250, Loss: 0.0160\n",
      "Epoch 162/200, Iteration 84/250, Loss: 0.0069\n",
      "Epoch 162/200, Iteration 85/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 86/250, Loss: 0.0334\n",
      "Epoch 162/200, Iteration 87/250, Loss: 0.0207\n",
      "Epoch 162/200, Iteration 88/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 89/250, Loss: 0.0089\n",
      "Epoch 162/200, Iteration 90/250, Loss: 0.0313\n",
      "Epoch 162/200, Iteration 91/250, Loss: 0.0255\n",
      "Epoch 162/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 162/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 162/200, Iteration 94/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 95/250, Loss: 0.0118\n",
      "Epoch 162/200, Iteration 96/250, Loss: 0.0089\n",
      "Epoch 162/200, Iteration 97/250, Loss: 0.0134\n",
      "Epoch 162/200, Iteration 98/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 99/250, Loss: 0.0117\n",
      "Epoch 162/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 101/250, Loss: 0.0152\n",
      "Epoch 162/200, Iteration 102/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 103/250, Loss: 0.0099\n",
      "Epoch 162/200, Iteration 104/250, Loss: 0.0156\n",
      "Epoch 162/200, Iteration 105/250, Loss: 0.0160\n",
      "Epoch 162/200, Iteration 106/250, Loss: 0.0316\n",
      "Epoch 162/200, Iteration 107/250, Loss: 0.0348\n",
      "Epoch 162/200, Iteration 108/250, Loss: 0.0309\n",
      "Epoch 162/200, Iteration 109/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 110/250, Loss: 0.0128\n",
      "Epoch 162/200, Iteration 111/250, Loss: 0.0211\n",
      "Epoch 162/200, Iteration 112/250, Loss: 0.0161\n",
      "Epoch 162/200, Iteration 113/250, Loss: 0.0177\n",
      "Epoch 162/200, Iteration 114/250, Loss: 0.0303\n",
      "Epoch 162/200, Iteration 115/250, Loss: 0.0134\n",
      "Epoch 162/200, Iteration 116/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 117/250, Loss: 0.0302\n",
      "Epoch 162/200, Iteration 118/250, Loss: 0.0165\n",
      "Epoch 162/200, Iteration 119/250, Loss: 0.0090\n",
      "Epoch 162/200, Iteration 120/250, Loss: 0.0180\n",
      "Epoch 162/200, Iteration 121/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 122/250, Loss: 0.0290\n",
      "Epoch 162/200, Iteration 123/250, Loss: 0.0247\n",
      "Epoch 162/200, Iteration 124/250, Loss: 0.0073\n",
      "Epoch 162/200, Iteration 125/250, Loss: 0.0118\n",
      "Epoch 162/200, Iteration 126/250, Loss: 0.0108\n",
      "Epoch 162/200, Iteration 127/250, Loss: 0.0086\n",
      "Epoch 162/200, Iteration 128/250, Loss: 0.0425\n",
      "Epoch 162/200, Iteration 129/250, Loss: 0.0072\n",
      "Epoch 162/200, Iteration 130/250, Loss: 0.0094\n",
      "Epoch 162/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 162/200, Iteration 132/250, Loss: 0.0101\n",
      "Epoch 162/200, Iteration 133/250, Loss: 0.0191\n",
      "Epoch 162/200, Iteration 134/250, Loss: 0.0106\n",
      "Epoch 162/200, Iteration 135/250, Loss: 0.0211\n",
      "Epoch 162/200, Iteration 136/250, Loss: 0.0288\n",
      "Epoch 162/200, Iteration 137/250, Loss: 0.0188\n",
      "Epoch 162/200, Iteration 138/250, Loss: 0.0150\n",
      "Epoch 162/200, Iteration 139/250, Loss: 0.0131\n",
      "Epoch 162/200, Iteration 140/250, Loss: 0.0166\n",
      "Epoch 162/200, Iteration 141/250, Loss: 0.0112\n",
      "Epoch 162/200, Iteration 142/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 143/250, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200, Iteration 144/250, Loss: 0.0126\n",
      "Epoch 162/200, Iteration 145/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 146/250, Loss: 0.0091\n",
      "Epoch 162/200, Iteration 147/250, Loss: 0.0183\n",
      "Epoch 162/200, Iteration 148/250, Loss: 0.0122\n",
      "Epoch 162/200, Iteration 149/250, Loss: 0.0112\n",
      "Epoch 162/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 162/200, Iteration 151/250, Loss: 0.0142\n",
      "Epoch 162/200, Iteration 152/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 153/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 154/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 155/250, Loss: 0.0162\n",
      "Epoch 162/200, Iteration 156/250, Loss: 0.0188\n",
      "Epoch 162/200, Iteration 157/250, Loss: 0.0086\n",
      "Epoch 162/200, Iteration 158/250, Loss: 0.0085\n",
      "Epoch 162/200, Iteration 159/250, Loss: 0.0059\n",
      "Epoch 162/200, Iteration 160/250, Loss: 0.0138\n",
      "Epoch 162/200, Iteration 161/250, Loss: 0.0141\n",
      "Epoch 162/200, Iteration 162/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 163/250, Loss: 0.0259\n",
      "Epoch 162/200, Iteration 164/250, Loss: 0.0071\n",
      "Epoch 162/200, Iteration 165/250, Loss: 0.0346\n",
      "Epoch 162/200, Iteration 166/250, Loss: 0.0080\n",
      "Epoch 162/200, Iteration 167/250, Loss: 0.0196\n",
      "Epoch 162/200, Iteration 168/250, Loss: 0.0124\n",
      "Epoch 162/200, Iteration 169/250, Loss: 0.0108\n",
      "Epoch 162/200, Iteration 170/250, Loss: 0.0391\n",
      "Epoch 162/200, Iteration 171/250, Loss: 0.0190\n",
      "Epoch 162/200, Iteration 172/250, Loss: 0.0177\n",
      "Epoch 162/200, Iteration 173/250, Loss: 0.0078\n",
      "Epoch 162/200, Iteration 174/250, Loss: 0.0292\n",
      "Epoch 162/200, Iteration 175/250, Loss: 0.0137\n",
      "Epoch 162/200, Iteration 176/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 177/250, Loss: 0.0307\n",
      "Epoch 162/200, Iteration 178/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 179/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 162/200, Iteration 181/250, Loss: 0.0134\n",
      "Epoch 162/200, Iteration 182/250, Loss: 0.0128\n",
      "Epoch 162/200, Iteration 183/250, Loss: 0.0084\n",
      "Epoch 162/200, Iteration 184/250, Loss: 0.0130\n",
      "Epoch 162/200, Iteration 185/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 186/250, Loss: 0.0129\n",
      "Epoch 162/200, Iteration 187/250, Loss: 0.0079\n",
      "Epoch 162/200, Iteration 188/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 189/250, Loss: 0.0115\n",
      "Epoch 162/200, Iteration 190/250, Loss: 0.0276\n",
      "Epoch 162/200, Iteration 191/250, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 192/250, Loss: 0.0218\n",
      "Epoch 162/200, Iteration 193/250, Loss: 0.0376\n",
      "Epoch 162/200, Iteration 194/250, Loss: 0.0143\n",
      "Epoch 162/200, Iteration 195/250, Loss: 0.0087\n",
      "Epoch 162/200, Iteration 196/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 197/250, Loss: 0.0125\n",
      "Epoch 162/200, Iteration 198/250, Loss: 0.0114\n",
      "Epoch 162/200, Iteration 199/250, Loss: 0.0319\n",
      "Epoch 162/200, Iteration 200/250, Loss: 0.0118\n",
      "Epoch 162/200, Iteration 201/250, Loss: 0.0123\n",
      "Epoch 162/200, Iteration 202/250, Loss: 0.0076\n",
      "Epoch 162/200, Iteration 203/250, Loss: 0.0126\n",
      "Epoch 162/200, Iteration 204/250, Loss: 0.0098\n",
      "Epoch 162/200, Iteration 205/250, Loss: 0.0223\n",
      "Epoch 162/200, Iteration 206/250, Loss: 0.0188\n",
      "Epoch 162/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 162/200, Iteration 208/250, Loss: 0.0075\n",
      "Epoch 162/200, Iteration 209/250, Loss: 0.0304\n",
      "Epoch 162/200, Iteration 210/250, Loss: 0.0138\n",
      "Epoch 162/200, Iteration 211/250, Loss: 0.0103\n",
      "Epoch 162/200, Iteration 212/250, Loss: 0.0240\n",
      "Epoch 162/200, Iteration 213/250, Loss: 0.0190\n",
      "Epoch 162/200, Iteration 214/250, Loss: 0.0136\n",
      "Epoch 162/200, Iteration 215/250, Loss: 0.0096\n",
      "Epoch 162/200, Iteration 216/250, Loss: 0.0091\n",
      "Epoch 162/200, Iteration 217/250, Loss: 0.0177\n",
      "Epoch 162/200, Iteration 218/250, Loss: 0.0123\n",
      "Epoch 162/200, Iteration 219/250, Loss: 0.0162\n",
      "Epoch 162/200, Iteration 220/250, Loss: 0.0219\n",
      "Epoch 162/200, Iteration 221/250, Loss: 0.0201\n",
      "Epoch 162/200, Iteration 222/250, Loss: 0.0157\n",
      "Epoch 162/200, Iteration 223/250, Loss: 0.0097\n",
      "Epoch 162/200, Iteration 224/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 162/200, Iteration 226/250, Loss: 0.0341\n",
      "Epoch 162/200, Iteration 227/250, Loss: 0.0108\n",
      "Epoch 162/200, Iteration 228/250, Loss: 0.0171\n",
      "Epoch 162/200, Iteration 229/250, Loss: 0.0093\n",
      "Epoch 162/200, Iteration 230/250, Loss: 0.0318\n",
      "Epoch 162/200, Iteration 231/250, Loss: 0.0233\n",
      "Epoch 162/200, Iteration 232/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 233/250, Loss: 0.0269\n",
      "Epoch 162/200, Iteration 234/250, Loss: 0.0271\n",
      "Epoch 162/200, Iteration 235/250, Loss: 0.0107\n",
      "Epoch 162/200, Iteration 236/250, Loss: 0.0121\n",
      "Epoch 162/200, Iteration 237/250, Loss: 0.0180\n",
      "Epoch 162/200, Iteration 238/250, Loss: 0.0077\n",
      "Epoch 162/200, Iteration 239/250, Loss: 0.0092\n",
      "Epoch 162/200, Iteration 240/250, Loss: 0.0247\n",
      "Epoch 162/200, Iteration 241/250, Loss: 0.0292\n",
      "Epoch 162/200, Iteration 242/250, Loss: 0.0280\n",
      "Epoch 162/200, Iteration 243/250, Loss: 0.0083\n",
      "Epoch 162/200, Iteration 244/250, Loss: 0.0088\n",
      "Epoch 162/200, Iteration 245/250, Loss: 0.0105\n",
      "Epoch 162/200, Iteration 246/250, Loss: 0.0307\n",
      "Epoch 162/200, Iteration 247/250, Loss: 0.0301\n",
      "Epoch 162/200, Iteration 248/250, Loss: 0.0342\n",
      "Epoch 162/200, Iteration 249/250, Loss: 0.0176\n",
      "Epoch 162/200, Iteration 250/250, Loss: 0.0129\n",
      "Train Error: \n",
      " Accuracy: 93.61%, Avg loss: 0.006942, MRE: 0.466314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.007634, MRE: 0.546698 \n",
      "\n",
      "Epoch 163/200, Iteration 1/250, Loss: 0.0113\n",
      "Epoch 163/200, Iteration 2/250, Loss: 0.0078\n",
      "Epoch 163/200, Iteration 3/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 4/250, Loss: 0.0129\n",
      "Epoch 163/200, Iteration 5/250, Loss: 0.0224\n",
      "Epoch 163/200, Iteration 6/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 7/250, Loss: 0.0359\n",
      "Epoch 163/200, Iteration 8/250, Loss: 0.0307\n",
      "Epoch 163/200, Iteration 9/250, Loss: 0.0241\n",
      "Epoch 163/200, Iteration 10/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 11/250, Loss: 0.0192\n",
      "Epoch 163/200, Iteration 12/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 13/250, Loss: 0.0215\n",
      "Epoch 163/200, Iteration 14/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 15/250, Loss: 0.0291\n",
      "Epoch 163/200, Iteration 16/250, Loss: 0.0093\n",
      "Epoch 163/200, Iteration 17/250, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 163/200, Iteration 19/250, Loss: 0.0109\n",
      "Epoch 163/200, Iteration 20/250, Loss: 0.0120\n",
      "Epoch 163/200, Iteration 21/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 22/250, Loss: 0.0144\n",
      "Epoch 163/200, Iteration 23/250, Loss: 0.0215\n",
      "Epoch 163/200, Iteration 24/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 25/250, Loss: 0.0139\n",
      "Epoch 163/200, Iteration 26/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 27/250, Loss: 0.0138\n",
      "Epoch 163/200, Iteration 28/250, Loss: 0.0121\n",
      "Epoch 163/200, Iteration 29/250, Loss: 0.0245\n",
      "Epoch 163/200, Iteration 30/250, Loss: 0.0100\n",
      "Epoch 163/200, Iteration 31/250, Loss: 0.0129\n",
      "Epoch 163/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 33/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 34/250, Loss: 0.0279\n",
      "Epoch 163/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 163/200, Iteration 36/250, Loss: 0.0237\n",
      "Epoch 163/200, Iteration 37/250, Loss: 0.0198\n",
      "Epoch 163/200, Iteration 38/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 39/250, Loss: 0.0085\n",
      "Epoch 163/200, Iteration 40/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 41/250, Loss: 0.0083\n",
      "Epoch 163/200, Iteration 42/250, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 43/250, Loss: 0.0166\n",
      "Epoch 163/200, Iteration 44/250, Loss: 0.0180\n",
      "Epoch 163/200, Iteration 45/250, Loss: 0.0248\n",
      "Epoch 163/200, Iteration 46/250, Loss: 0.0113\n",
      "Epoch 163/200, Iteration 47/250, Loss: 0.0140\n",
      "Epoch 163/200, Iteration 48/250, Loss: 0.0079\n",
      "Epoch 163/200, Iteration 49/250, Loss: 0.0125\n",
      "Epoch 163/200, Iteration 50/250, Loss: 0.0207\n",
      "Epoch 163/200, Iteration 51/250, Loss: 0.0303\n",
      "Epoch 163/200, Iteration 52/250, Loss: 0.0069\n",
      "Epoch 163/200, Iteration 53/250, Loss: 0.0191\n",
      "Epoch 163/200, Iteration 54/250, Loss: 0.0270\n",
      "Epoch 163/200, Iteration 55/250, Loss: 0.0333\n",
      "Epoch 163/200, Iteration 56/250, Loss: 0.0193\n",
      "Epoch 163/200, Iteration 57/250, Loss: 0.0087\n",
      "Epoch 163/200, Iteration 58/250, Loss: 0.0211\n",
      "Epoch 163/200, Iteration 59/250, Loss: 0.0069\n",
      "Epoch 163/200, Iteration 60/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 61/250, Loss: 0.0115\n",
      "Epoch 163/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 163/200, Iteration 63/250, Loss: 0.0105\n",
      "Epoch 163/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 163/200, Iteration 65/250, Loss: 0.0087\n",
      "Epoch 163/200, Iteration 66/250, Loss: 0.0227\n",
      "Epoch 163/200, Iteration 67/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 68/250, Loss: 0.0210\n",
      "Epoch 163/200, Iteration 69/250, Loss: 0.0245\n",
      "Epoch 163/200, Iteration 70/250, Loss: 0.0152\n",
      "Epoch 163/200, Iteration 71/250, Loss: 0.0090\n",
      "Epoch 163/200, Iteration 72/250, Loss: 0.0168\n",
      "Epoch 163/200, Iteration 73/250, Loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200, Iteration 74/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 75/250, Loss: 0.0312\n",
      "Epoch 163/200, Iteration 76/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 77/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 78/250, Loss: 0.0166\n",
      "Epoch 163/200, Iteration 79/250, Loss: 0.0157\n",
      "Epoch 163/200, Iteration 80/250, Loss: 0.0422\n",
      "Epoch 163/200, Iteration 81/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 82/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 83/250, Loss: 0.0164\n",
      "Epoch 163/200, Iteration 84/250, Loss: 0.0398\n",
      "Epoch 163/200, Iteration 85/250, Loss: 0.0109\n",
      "Epoch 163/200, Iteration 86/250, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 87/250, Loss: 0.0087\n",
      "Epoch 163/200, Iteration 88/250, Loss: 0.0067\n",
      "Epoch 163/200, Iteration 89/250, Loss: 0.0179\n",
      "Epoch 163/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 91/250, Loss: 0.0320\n",
      "Epoch 163/200, Iteration 92/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 93/250, Loss: 0.0093\n",
      "Epoch 163/200, Iteration 94/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 95/250, Loss: 0.0183\n",
      "Epoch 163/200, Iteration 96/250, Loss: 0.0186\n",
      "Epoch 163/200, Iteration 97/250, Loss: 0.0094\n",
      "Epoch 163/200, Iteration 98/250, Loss: 0.0135\n",
      "Epoch 163/200, Iteration 99/250, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 100/250, Loss: 0.0114\n",
      "Epoch 163/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 163/200, Iteration 102/250, Loss: 0.0371\n",
      "Epoch 163/200, Iteration 103/250, Loss: 0.0202\n",
      "Epoch 163/200, Iteration 104/250, Loss: 0.0354\n",
      "Epoch 163/200, Iteration 105/250, Loss: 0.0072\n",
      "Epoch 163/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 107/250, Loss: 0.0169\n",
      "Epoch 163/200, Iteration 108/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 109/250, Loss: 0.0111\n",
      "Epoch 163/200, Iteration 110/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 111/250, Loss: 0.0433\n",
      "Epoch 163/200, Iteration 112/250, Loss: 0.0178\n",
      "Epoch 163/200, Iteration 113/250, Loss: 0.0081\n",
      "Epoch 163/200, Iteration 114/250, Loss: 0.0145\n",
      "Epoch 163/200, Iteration 115/250, Loss: 0.0126\n",
      "Epoch 163/200, Iteration 116/250, Loss: 0.0096\n",
      "Epoch 163/200, Iteration 117/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 118/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 119/250, Loss: 0.0215\n",
      "Epoch 163/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 121/250, Loss: 0.0223\n",
      "Epoch 163/200, Iteration 122/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 123/250, Loss: 0.0095\n",
      "Epoch 163/200, Iteration 124/250, Loss: 0.0223\n",
      "Epoch 163/200, Iteration 125/250, Loss: 0.0318\n",
      "Epoch 163/200, Iteration 126/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 127/250, Loss: 0.0197\n",
      "Epoch 163/200, Iteration 128/250, Loss: 0.0129\n",
      "Epoch 163/200, Iteration 129/250, Loss: 0.0128\n",
      "Epoch 163/200, Iteration 130/250, Loss: 0.0191\n",
      "Epoch 163/200, Iteration 131/250, Loss: 0.0173\n",
      "Epoch 163/200, Iteration 132/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 133/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 134/250, Loss: 0.0124\n",
      "Epoch 163/200, Iteration 135/250, Loss: 0.0192\n",
      "Epoch 163/200, Iteration 136/250, Loss: 0.0212\n",
      "Epoch 163/200, Iteration 137/250, Loss: 0.0158\n",
      "Epoch 163/200, Iteration 138/250, Loss: 0.0200\n",
      "Epoch 163/200, Iteration 139/250, Loss: 0.0167\n",
      "Epoch 163/200, Iteration 140/250, Loss: 0.0099\n",
      "Epoch 163/200, Iteration 141/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 142/250, Loss: 0.0252\n",
      "Epoch 163/200, Iteration 143/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 144/250, Loss: 0.0209\n",
      "Epoch 163/200, Iteration 145/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 146/250, Loss: 0.0175\n",
      "Epoch 163/200, Iteration 147/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 148/250, Loss: 0.0076\n",
      "Epoch 163/200, Iteration 149/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 150/250, Loss: 0.0124\n",
      "Epoch 163/200, Iteration 151/250, Loss: 0.0133\n",
      "Epoch 163/200, Iteration 152/250, Loss: 0.0202\n",
      "Epoch 163/200, Iteration 153/250, Loss: 0.0215\n",
      "Epoch 163/200, Iteration 154/250, Loss: 0.0061\n",
      "Epoch 163/200, Iteration 155/250, Loss: 0.0101\n",
      "Epoch 163/200, Iteration 156/250, Loss: 0.0160\n",
      "Epoch 163/200, Iteration 157/250, Loss: 0.0291\n",
      "Epoch 163/200, Iteration 158/250, Loss: 0.0125\n",
      "Epoch 163/200, Iteration 159/250, Loss: 0.0104\n",
      "Epoch 163/200, Iteration 160/250, Loss: 0.0099\n",
      "Epoch 163/200, Iteration 161/250, Loss: 0.0086\n",
      "Epoch 163/200, Iteration 162/250, Loss: 0.0210\n",
      "Epoch 163/200, Iteration 163/250, Loss: 0.0315\n",
      "Epoch 163/200, Iteration 164/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 165/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 166/250, Loss: 0.0121\n",
      "Epoch 163/200, Iteration 167/250, Loss: 0.0121\n",
      "Epoch 163/200, Iteration 168/250, Loss: 0.0174\n",
      "Epoch 163/200, Iteration 169/250, Loss: 0.0150\n",
      "Epoch 163/200, Iteration 170/250, Loss: 0.0097\n",
      "Epoch 163/200, Iteration 171/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 172/250, Loss: 0.0084\n",
      "Epoch 163/200, Iteration 173/250, Loss: 0.0117\n",
      "Epoch 163/200, Iteration 174/250, Loss: 0.0090\n",
      "Epoch 163/200, Iteration 175/250, Loss: 0.0109\n",
      "Epoch 163/200, Iteration 176/250, Loss: 0.0107\n",
      "Epoch 163/200, Iteration 177/250, Loss: 0.0281\n",
      "Epoch 163/200, Iteration 178/250, Loss: 0.0156\n",
      "Epoch 163/200, Iteration 179/250, Loss: 0.0088\n",
      "Epoch 163/200, Iteration 180/250, Loss: 0.0117\n",
      "Epoch 163/200, Iteration 181/250, Loss: 0.0109\n",
      "Epoch 163/200, Iteration 182/250, Loss: 0.0119\n",
      "Epoch 163/200, Iteration 183/250, Loss: 0.0115\n",
      "Epoch 163/200, Iteration 184/250, Loss: 0.0079\n",
      "Epoch 163/200, Iteration 185/250, Loss: 0.0132\n",
      "Epoch 163/200, Iteration 186/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 187/250, Loss: 0.0082\n",
      "Epoch 163/200, Iteration 188/250, Loss: 0.0163\n",
      "Epoch 163/200, Iteration 189/250, Loss: 0.0171\n",
      "Epoch 163/200, Iteration 190/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 191/250, Loss: 0.0117\n",
      "Epoch 163/200, Iteration 192/250, Loss: 0.0070\n",
      "Epoch 163/200, Iteration 193/250, Loss: 0.0080\n",
      "Epoch 163/200, Iteration 194/250, Loss: 0.0223\n",
      "Epoch 163/200, Iteration 195/250, Loss: 0.0286\n",
      "Epoch 163/200, Iteration 196/250, Loss: 0.0155\n",
      "Epoch 163/200, Iteration 197/250, Loss: 0.0112\n",
      "Epoch 163/200, Iteration 198/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 199/250, Loss: 0.0298\n",
      "Epoch 163/200, Iteration 200/250, Loss: 0.0089\n",
      "Epoch 163/200, Iteration 201/250, Loss: 0.0117\n",
      "Epoch 163/200, Iteration 202/250, Loss: 0.0277\n",
      "Epoch 163/200, Iteration 203/250, Loss: 0.0160\n",
      "Epoch 163/200, Iteration 204/250, Loss: 0.0106\n",
      "Epoch 163/200, Iteration 205/250, Loss: 0.0182\n",
      "Epoch 163/200, Iteration 206/250, Loss: 0.0104\n",
      "Epoch 163/200, Iteration 207/250, Loss: 0.0338\n",
      "Epoch 163/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 163/200, Iteration 209/250, Loss: 0.0108\n",
      "Epoch 163/200, Iteration 210/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 163/200, Iteration 212/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 213/250, Loss: 0.0136\n",
      "Epoch 163/200, Iteration 214/250, Loss: 0.0324\n",
      "Epoch 163/200, Iteration 215/250, Loss: 0.0168\n",
      "Epoch 163/200, Iteration 216/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 217/250, Loss: 0.0207\n",
      "Epoch 163/200, Iteration 218/250, Loss: 0.0122\n",
      "Epoch 163/200, Iteration 219/250, Loss: 0.0125\n",
      "Epoch 163/200, Iteration 220/250, Loss: 0.0102\n",
      "Epoch 163/200, Iteration 221/250, Loss: 0.0159\n",
      "Epoch 163/200, Iteration 222/250, Loss: 0.0087\n",
      "Epoch 163/200, Iteration 223/250, Loss: 0.0175\n",
      "Epoch 163/200, Iteration 224/250, Loss: 0.0210\n",
      "Epoch 163/200, Iteration 225/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 226/250, Loss: 0.0069\n",
      "Epoch 163/200, Iteration 227/250, Loss: 0.0064\n",
      "Epoch 163/200, Iteration 228/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 229/250, Loss: 0.0116\n",
      "Epoch 163/200, Iteration 230/250, Loss: 0.0255\n",
      "Epoch 163/200, Iteration 231/250, Loss: 0.0096\n",
      "Epoch 163/200, Iteration 232/250, Loss: 0.0103\n",
      "Epoch 163/200, Iteration 233/250, Loss: 0.0114\n",
      "Epoch 163/200, Iteration 234/250, Loss: 0.0155\n",
      "Epoch 163/200, Iteration 235/250, Loss: 0.0186\n",
      "Epoch 163/200, Iteration 236/250, Loss: 0.0126\n",
      "Epoch 163/200, Iteration 237/250, Loss: 0.0092\n",
      "Epoch 163/200, Iteration 238/250, Loss: 0.0105\n",
      "Epoch 163/200, Iteration 239/250, Loss: 0.0109\n",
      "Epoch 163/200, Iteration 240/250, Loss: 0.0098\n",
      "Epoch 163/200, Iteration 241/250, Loss: 0.0338\n",
      "Epoch 163/200, Iteration 242/250, Loss: 0.0145\n",
      "Epoch 163/200, Iteration 243/250, Loss: 0.0131\n",
      "Epoch 163/200, Iteration 244/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 245/250, Loss: 0.0168\n",
      "Epoch 163/200, Iteration 246/250, Loss: 0.0202\n",
      "Epoch 163/200, Iteration 247/250, Loss: 0.0137\n",
      "Epoch 163/200, Iteration 248/250, Loss: 0.0110\n",
      "Epoch 163/200, Iteration 249/250, Loss: 0.0091\n",
      "Epoch 163/200, Iteration 250/250, Loss: 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 89.49%, Avg loss: 0.007008, MRE: 0.538885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.15%, Avg loss: 0.007379, MRE: 0.657653 \n",
      "\n",
      "Epoch 164/200, Iteration 1/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 2/250, Loss: 0.0087\n",
      "Epoch 164/200, Iteration 3/250, Loss: 0.0189\n",
      "Epoch 164/200, Iteration 4/250, Loss: 0.0081\n",
      "Epoch 164/200, Iteration 5/250, Loss: 0.0115\n",
      "Epoch 164/200, Iteration 6/250, Loss: 0.0168\n",
      "Epoch 164/200, Iteration 7/250, Loss: 0.0289\n",
      "Epoch 164/200, Iteration 8/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 9/250, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 10/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 11/250, Loss: 0.0299\n",
      "Epoch 164/200, Iteration 12/250, Loss: 0.0199\n",
      "Epoch 164/200, Iteration 13/250, Loss: 0.0355\n",
      "Epoch 164/200, Iteration 14/250, Loss: 0.0147\n",
      "Epoch 164/200, Iteration 15/250, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 16/250, Loss: 0.0089\n",
      "Epoch 164/200, Iteration 17/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 18/250, Loss: 0.0134\n",
      "Epoch 164/200, Iteration 19/250, Loss: 0.0252\n",
      "Epoch 164/200, Iteration 20/250, Loss: 0.0251\n",
      "Epoch 164/200, Iteration 21/250, Loss: 0.0096\n",
      "Epoch 164/200, Iteration 22/250, Loss: 0.0081\n",
      "Epoch 164/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 24/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 25/250, Loss: 0.0167\n",
      "Epoch 164/200, Iteration 26/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 27/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 28/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 29/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 30/250, Loss: 0.0167\n",
      "Epoch 164/200, Iteration 31/250, Loss: 0.0086\n",
      "Epoch 164/200, Iteration 32/250, Loss: 0.0125\n",
      "Epoch 164/200, Iteration 33/250, Loss: 0.0132\n",
      "Epoch 164/200, Iteration 34/250, Loss: 0.0203\n",
      "Epoch 164/200, Iteration 35/250, Loss: 0.0180\n",
      "Epoch 164/200, Iteration 36/250, Loss: 0.0360\n",
      "Epoch 164/200, Iteration 37/250, Loss: 0.0087\n",
      "Epoch 164/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 39/250, Loss: 0.0256\n",
      "Epoch 164/200, Iteration 40/250, Loss: 0.0207\n",
      "Epoch 164/200, Iteration 41/250, Loss: 0.0223\n",
      "Epoch 164/200, Iteration 42/250, Loss: 0.0265\n",
      "Epoch 164/200, Iteration 43/250, Loss: 0.0153\n",
      "Epoch 164/200, Iteration 44/250, Loss: 0.0113\n",
      "Epoch 164/200, Iteration 45/250, Loss: 0.0083\n",
      "Epoch 164/200, Iteration 46/250, Loss: 0.0384\n",
      "Epoch 164/200, Iteration 47/250, Loss: 0.0214\n",
      "Epoch 164/200, Iteration 48/250, Loss: 0.0283\n",
      "Epoch 164/200, Iteration 49/250, Loss: 0.0149\n",
      "Epoch 164/200, Iteration 50/250, Loss: 0.0142\n",
      "Epoch 164/200, Iteration 51/250, Loss: 0.0143\n",
      "Epoch 164/200, Iteration 52/250, Loss: 0.0216\n",
      "Epoch 164/200, Iteration 53/250, Loss: 0.0122\n",
      "Epoch 164/200, Iteration 54/250, Loss: 0.0208\n",
      "Epoch 164/200, Iteration 55/250, Loss: 0.0135\n",
      "Epoch 164/200, Iteration 56/250, Loss: 0.0083\n",
      "Epoch 164/200, Iteration 57/250, Loss: 0.0115\n",
      "Epoch 164/200, Iteration 58/250, Loss: 0.0154\n",
      "Epoch 164/200, Iteration 59/250, Loss: 0.0102\n",
      "Epoch 164/200, Iteration 60/250, Loss: 0.0132\n",
      "Epoch 164/200, Iteration 61/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 62/250, Loss: 0.0100\n",
      "Epoch 164/200, Iteration 63/250, Loss: 0.0204\n",
      "Epoch 164/200, Iteration 64/250, Loss: 0.0089\n",
      "Epoch 164/200, Iteration 65/250, Loss: 0.0085\n",
      "Epoch 164/200, Iteration 66/250, Loss: 0.0068\n",
      "Epoch 164/200, Iteration 67/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 68/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 69/250, Loss: 0.0319\n",
      "Epoch 164/200, Iteration 70/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 71/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 72/250, Loss: 0.0141\n",
      "Epoch 164/200, Iteration 73/250, Loss: 0.0264\n",
      "Epoch 164/200, Iteration 74/250, Loss: 0.0218\n",
      "Epoch 164/200, Iteration 75/250, Loss: 0.0177\n",
      "Epoch 164/200, Iteration 76/250, Loss: 0.0355\n",
      "Epoch 164/200, Iteration 77/250, Loss: 0.0139\n",
      "Epoch 164/200, Iteration 78/250, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 79/250, Loss: 0.0150\n",
      "Epoch 164/200, Iteration 80/250, Loss: 0.0159\n",
      "Epoch 164/200, Iteration 81/250, Loss: 0.0109\n",
      "Epoch 164/200, Iteration 82/250, Loss: 0.0110\n",
      "Epoch 164/200, Iteration 83/250, Loss: 0.0087\n",
      "Epoch 164/200, Iteration 84/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 85/250, Loss: 0.0077\n",
      "Epoch 164/200, Iteration 86/250, Loss: 0.0207\n",
      "Epoch 164/200, Iteration 87/250, Loss: 0.0141\n",
      "Epoch 164/200, Iteration 88/250, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 89/250, Loss: 0.0160\n",
      "Epoch 164/200, Iteration 90/250, Loss: 0.0155\n",
      "Epoch 164/200, Iteration 91/250, Loss: 0.0181\n",
      "Epoch 164/200, Iteration 92/250, Loss: 0.0142\n",
      "Epoch 164/200, Iteration 93/250, Loss: 0.0083\n",
      "Epoch 164/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 95/250, Loss: 0.0198\n",
      "Epoch 164/200, Iteration 96/250, Loss: 0.0187\n",
      "Epoch 164/200, Iteration 97/250, Loss: 0.0167\n",
      "Epoch 164/200, Iteration 98/250, Loss: 0.0138\n",
      "Epoch 164/200, Iteration 99/250, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 100/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 101/250, Loss: 0.0272\n",
      "Epoch 164/200, Iteration 102/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 103/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 104/250, Loss: 0.0308\n",
      "Epoch 164/200, Iteration 105/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 106/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 107/250, Loss: 0.0290\n",
      "Epoch 164/200, Iteration 108/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 109/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 110/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 111/250, Loss: 0.0090\n",
      "Epoch 164/200, Iteration 112/250, Loss: 0.0192\n",
      "Epoch 164/200, Iteration 113/250, Loss: 0.0133\n",
      "Epoch 164/200, Iteration 114/250, Loss: 0.0134\n",
      "Epoch 164/200, Iteration 115/250, Loss: 0.0119\n",
      "Epoch 164/200, Iteration 116/250, Loss: 0.0223\n",
      "Epoch 164/200, Iteration 117/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 118/250, Loss: 0.0206\n",
      "Epoch 164/200, Iteration 119/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 120/250, Loss: 0.0085\n",
      "Epoch 164/200, Iteration 121/250, Loss: 0.0127\n",
      "Epoch 164/200, Iteration 122/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 123/250, Loss: 0.0091\n",
      "Epoch 164/200, Iteration 124/250, Loss: 0.0300\n",
      "Epoch 164/200, Iteration 125/250, Loss: 0.0144\n",
      "Epoch 164/200, Iteration 126/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 127/250, Loss: 0.0095\n",
      "Epoch 164/200, Iteration 128/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 129/250, Loss: 0.0173\n",
      "Epoch 164/200, Iteration 130/250, Loss: 0.0278\n",
      "Epoch 164/200, Iteration 131/250, Loss: 0.0240\n",
      "Epoch 164/200, Iteration 132/250, Loss: 0.0165\n",
      "Epoch 164/200, Iteration 133/250, Loss: 0.0211\n",
      "Epoch 164/200, Iteration 134/250, Loss: 0.0091\n",
      "Epoch 164/200, Iteration 135/250, Loss: 0.0110\n",
      "Epoch 164/200, Iteration 136/250, Loss: 0.0134\n",
      "Epoch 164/200, Iteration 137/250, Loss: 0.0068\n",
      "Epoch 164/200, Iteration 138/250, Loss: 0.0098\n",
      "Epoch 164/200, Iteration 139/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 140/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 141/250, Loss: 0.0243\n",
      "Epoch 164/200, Iteration 142/250, Loss: 0.0236\n",
      "Epoch 164/200, Iteration 143/250, Loss: 0.0110\n",
      "Epoch 164/200, Iteration 144/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 145/250, Loss: 0.0264\n",
      "Epoch 164/200, Iteration 146/250, Loss: 0.0296\n",
      "Epoch 164/200, Iteration 147/250, Loss: 0.0189\n",
      "Epoch 164/200, Iteration 148/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 149/250, Loss: 0.0312\n",
      "Epoch 164/200, Iteration 150/250, Loss: 0.0135\n",
      "Epoch 164/200, Iteration 151/250, Loss: 0.0122\n",
      "Epoch 164/200, Iteration 152/250, Loss: 0.0068\n",
      "Epoch 164/200, Iteration 153/250, Loss: 0.0100\n",
      "Epoch 164/200, Iteration 154/250, Loss: 0.0130\n",
      "Epoch 164/200, Iteration 155/250, Loss: 0.0252\n",
      "Epoch 164/200, Iteration 156/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 157/250, Loss: 0.0446\n",
      "Epoch 164/200, Iteration 158/250, Loss: 0.0130\n",
      "Epoch 164/200, Iteration 159/250, Loss: 0.0213\n",
      "Epoch 164/200, Iteration 160/250, Loss: 0.0183\n",
      "Epoch 164/200, Iteration 161/250, Loss: 0.0208\n",
      "Epoch 164/200, Iteration 162/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 163/250, Loss: 0.0277\n",
      "Epoch 164/200, Iteration 164/250, Loss: 0.0332\n",
      "Epoch 164/200, Iteration 165/250, Loss: 0.0113\n",
      "Epoch 164/200, Iteration 166/250, Loss: 0.0066\n",
      "Epoch 164/200, Iteration 167/250, Loss: 0.0223\n",
      "Epoch 164/200, Iteration 168/250, Loss: 0.0135\n",
      "Epoch 164/200, Iteration 169/250, Loss: 0.0146\n",
      "Epoch 164/200, Iteration 170/250, Loss: 0.0086\n",
      "Epoch 164/200, Iteration 171/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 172/250, Loss: 0.0188\n",
      "Epoch 164/200, Iteration 173/250, Loss: 0.0269\n",
      "Epoch 164/200, Iteration 174/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 175/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 176/250, Loss: 0.0079\n",
      "Epoch 164/200, Iteration 177/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 178/250, Loss: 0.0091\n",
      "Epoch 164/200, Iteration 179/250, Loss: 0.0372\n",
      "Epoch 164/200, Iteration 180/250, Loss: 0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200, Iteration 181/250, Loss: 0.0117\n",
      "Epoch 164/200, Iteration 182/250, Loss: 0.0179\n",
      "Epoch 164/200, Iteration 183/250, Loss: 0.0130\n",
      "Epoch 164/200, Iteration 184/250, Loss: 0.0128\n",
      "Epoch 164/200, Iteration 185/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 186/250, Loss: 0.0069\n",
      "Epoch 164/200, Iteration 187/250, Loss: 0.0270\n",
      "Epoch 164/200, Iteration 188/250, Loss: 0.0082\n",
      "Epoch 164/200, Iteration 189/250, Loss: 0.0088\n",
      "Epoch 164/200, Iteration 190/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 191/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 192/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 193/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 194/250, Loss: 0.0131\n",
      "Epoch 164/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 164/200, Iteration 196/250, Loss: 0.0077\n",
      "Epoch 164/200, Iteration 197/250, Loss: 0.0187\n",
      "Epoch 164/200, Iteration 198/250, Loss: 0.0104\n",
      "Epoch 164/200, Iteration 199/250, Loss: 0.0389\n",
      "Epoch 164/200, Iteration 200/250, Loss: 0.0087\n",
      "Epoch 164/200, Iteration 201/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 202/250, Loss: 0.0078\n",
      "Epoch 164/200, Iteration 203/250, Loss: 0.0330\n",
      "Epoch 164/200, Iteration 204/250, Loss: 0.0126\n",
      "Epoch 164/200, Iteration 205/250, Loss: 0.0269\n",
      "Epoch 164/200, Iteration 206/250, Loss: 0.0071\n",
      "Epoch 164/200, Iteration 207/250, Loss: 0.0124\n",
      "Epoch 164/200, Iteration 208/250, Loss: 0.0132\n",
      "Epoch 164/200, Iteration 209/250, Loss: 0.0105\n",
      "Epoch 164/200, Iteration 210/250, Loss: 0.0224\n",
      "Epoch 164/200, Iteration 211/250, Loss: 0.0091\n",
      "Epoch 164/200, Iteration 212/250, Loss: 0.0202\n",
      "Epoch 164/200, Iteration 213/250, Loss: 0.0283\n",
      "Epoch 164/200, Iteration 214/250, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 215/250, Loss: 0.0287\n",
      "Epoch 164/200, Iteration 216/250, Loss: 0.0100\n",
      "Epoch 164/200, Iteration 217/250, Loss: 0.0154\n",
      "Epoch 164/200, Iteration 218/250, Loss: 0.0261\n",
      "Epoch 164/200, Iteration 219/250, Loss: 0.0141\n",
      "Epoch 164/200, Iteration 220/250, Loss: 0.0153\n",
      "Epoch 164/200, Iteration 221/250, Loss: 0.0080\n",
      "Epoch 164/200, Iteration 222/250, Loss: 0.0119\n",
      "Epoch 164/200, Iteration 223/250, Loss: 0.0084\n",
      "Epoch 164/200, Iteration 224/250, Loss: 0.0226\n",
      "Epoch 164/200, Iteration 225/250, Loss: 0.0159\n",
      "Epoch 164/200, Iteration 226/250, Loss: 0.0076\n",
      "Epoch 164/200, Iteration 227/250, Loss: 0.0145\n",
      "Epoch 164/200, Iteration 228/250, Loss: 0.0144\n",
      "Epoch 164/200, Iteration 229/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 230/250, Loss: 0.0108\n",
      "Epoch 164/200, Iteration 231/250, Loss: 0.0101\n",
      "Epoch 164/200, Iteration 232/250, Loss: 0.0105\n",
      "Epoch 164/200, Iteration 233/250, Loss: 0.0169\n",
      "Epoch 164/200, Iteration 234/250, Loss: 0.0158\n",
      "Epoch 164/200, Iteration 235/250, Loss: 0.0097\n",
      "Epoch 164/200, Iteration 236/250, Loss: 0.0116\n",
      "Epoch 164/200, Iteration 237/250, Loss: 0.0069\n",
      "Epoch 164/200, Iteration 238/250, Loss: 0.0107\n",
      "Epoch 164/200, Iteration 239/250, Loss: 0.0112\n",
      "Epoch 164/200, Iteration 240/250, Loss: 0.0200\n",
      "Epoch 164/200, Iteration 241/250, Loss: 0.0138\n",
      "Epoch 164/200, Iteration 242/250, Loss: 0.0107\n",
      "Epoch 164/200, Iteration 243/250, Loss: 0.0107\n",
      "Epoch 164/200, Iteration 244/250, Loss: 0.0133\n",
      "Epoch 164/200, Iteration 245/250, Loss: 0.0156\n",
      "Epoch 164/200, Iteration 246/250, Loss: 0.0157\n",
      "Epoch 164/200, Iteration 247/250, Loss: 0.0103\n",
      "Epoch 164/200, Iteration 248/250, Loss: 0.0087\n",
      "Epoch 164/200, Iteration 249/250, Loss: 0.0151\n",
      "Epoch 164/200, Iteration 250/250, Loss: 0.0282\n",
      "Train Error: \n",
      " Accuracy: 74.79%, Avg loss: 0.007913, MRE: 0.605422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.008266, MRE: 0.630735 \n",
      "\n",
      "Epoch 165/200, Iteration 1/250, Loss: 0.0069\n",
      "Epoch 165/200, Iteration 2/250, Loss: 0.0164\n",
      "Epoch 165/200, Iteration 3/250, Loss: 0.0072\n",
      "Epoch 165/200, Iteration 4/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 5/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 6/250, Loss: 0.0072\n",
      "Epoch 165/200, Iteration 7/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 8/250, Loss: 0.0094\n",
      "Epoch 165/200, Iteration 9/250, Loss: 0.0086\n",
      "Epoch 165/200, Iteration 10/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 11/250, Loss: 0.0161\n",
      "Epoch 165/200, Iteration 12/250, Loss: 0.0119\n",
      "Epoch 165/200, Iteration 13/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 14/250, Loss: 0.0132\n",
      "Epoch 165/200, Iteration 15/250, Loss: 0.0157\n",
      "Epoch 165/200, Iteration 16/250, Loss: 0.0142\n",
      "Epoch 165/200, Iteration 17/250, Loss: 0.0121\n",
      "Epoch 165/200, Iteration 18/250, Loss: 0.0103\n",
      "Epoch 165/200, Iteration 19/250, Loss: 0.0195\n",
      "Epoch 165/200, Iteration 20/250, Loss: 0.0113\n",
      "Epoch 165/200, Iteration 21/250, Loss: 0.0165\n",
      "Epoch 165/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 165/200, Iteration 23/250, Loss: 0.0108\n",
      "Epoch 165/200, Iteration 24/250, Loss: 0.0098\n",
      "Epoch 165/200, Iteration 25/250, Loss: 0.0265\n",
      "Epoch 165/200, Iteration 26/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 27/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 28/250, Loss: 0.0131\n",
      "Epoch 165/200, Iteration 29/250, Loss: 0.0166\n",
      "Epoch 165/200, Iteration 30/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 31/250, Loss: 0.0300\n",
      "Epoch 165/200, Iteration 32/250, Loss: 0.0181\n",
      "Epoch 165/200, Iteration 33/250, Loss: 0.0160\n",
      "Epoch 165/200, Iteration 34/250, Loss: 0.0118\n",
      "Epoch 165/200, Iteration 35/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 36/250, Loss: 0.0114\n",
      "Epoch 165/200, Iteration 37/250, Loss: 0.0184\n",
      "Epoch 165/200, Iteration 38/250, Loss: 0.0137\n",
      "Epoch 165/200, Iteration 39/250, Loss: 0.0159\n",
      "Epoch 165/200, Iteration 40/250, Loss: 0.0221\n",
      "Epoch 165/200, Iteration 41/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 42/250, Loss: 0.0135\n",
      "Epoch 165/200, Iteration 43/250, Loss: 0.0204\n",
      "Epoch 165/200, Iteration 44/250, Loss: 0.0360\n",
      "Epoch 165/200, Iteration 45/250, Loss: 0.0115\n",
      "Epoch 165/200, Iteration 46/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 47/250, Loss: 0.0131\n",
      "Epoch 165/200, Iteration 48/250, Loss: 0.0134\n",
      "Epoch 165/200, Iteration 49/250, Loss: 0.0116\n",
      "Epoch 165/200, Iteration 50/250, Loss: 0.0155\n",
      "Epoch 165/200, Iteration 51/250, Loss: 0.0108\n",
      "Epoch 165/200, Iteration 52/250, Loss: 0.0169\n",
      "Epoch 165/200, Iteration 53/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 54/250, Loss: 0.0339\n",
      "Epoch 165/200, Iteration 55/250, Loss: 0.0114\n",
      "Epoch 165/200, Iteration 56/250, Loss: 0.0188\n",
      "Epoch 165/200, Iteration 57/250, Loss: 0.0142\n",
      "Epoch 165/200, Iteration 58/250, Loss: 0.0084\n",
      "Epoch 165/200, Iteration 59/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 60/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 61/250, Loss: 0.0202\n",
      "Epoch 165/200, Iteration 62/250, Loss: 0.0168\n",
      "Epoch 165/200, Iteration 63/250, Loss: 0.0216\n",
      "Epoch 165/200, Iteration 64/250, Loss: 0.0269\n",
      "Epoch 165/200, Iteration 65/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 66/250, Loss: 0.0131\n",
      "Epoch 165/200, Iteration 67/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 68/250, Loss: 0.0330\n",
      "Epoch 165/200, Iteration 69/250, Loss: 0.0213\n",
      "Epoch 165/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 165/200, Iteration 71/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 72/250, Loss: 0.0208\n",
      "Epoch 165/200, Iteration 73/250, Loss: 0.0191\n",
      "Epoch 165/200, Iteration 74/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 75/250, Loss: 0.0175\n",
      "Epoch 165/200, Iteration 76/250, Loss: 0.0128\n",
      "Epoch 165/200, Iteration 77/250, Loss: 0.0215\n",
      "Epoch 165/200, Iteration 78/250, Loss: 0.0347\n",
      "Epoch 165/200, Iteration 79/250, Loss: 0.0116\n",
      "Epoch 165/200, Iteration 80/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 81/250, Loss: 0.0205\n",
      "Epoch 165/200, Iteration 82/250, Loss: 0.0077\n",
      "Epoch 165/200, Iteration 83/250, Loss: 0.0109\n",
      "Epoch 165/200, Iteration 84/250, Loss: 0.0118\n",
      "Epoch 165/200, Iteration 85/250, Loss: 0.0119\n",
      "Epoch 165/200, Iteration 86/250, Loss: 0.0160\n",
      "Epoch 165/200, Iteration 87/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 88/250, Loss: 0.0085\n",
      "Epoch 165/200, Iteration 89/250, Loss: 0.0144\n",
      "Epoch 165/200, Iteration 90/250, Loss: 0.0100\n",
      "Epoch 165/200, Iteration 91/250, Loss: 0.0093\n",
      "Epoch 165/200, Iteration 92/250, Loss: 0.0062\n",
      "Epoch 165/200, Iteration 93/250, Loss: 0.0192\n",
      "Epoch 165/200, Iteration 94/250, Loss: 0.0104\n",
      "Epoch 165/200, Iteration 95/250, Loss: 0.0209\n",
      "Epoch 165/200, Iteration 96/250, Loss: 0.0107\n",
      "Epoch 165/200, Iteration 97/250, Loss: 0.0120\n",
      "Epoch 165/200, Iteration 98/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 99/250, Loss: 0.0264\n",
      "Epoch 165/200, Iteration 100/250, Loss: 0.0097\n",
      "Epoch 165/200, Iteration 101/250, Loss: 0.0081\n",
      "Epoch 165/200, Iteration 102/250, Loss: 0.0180\n",
      "Epoch 165/200, Iteration 103/250, Loss: 0.0115\n",
      "Epoch 165/200, Iteration 104/250, Loss: 0.0237\n",
      "Epoch 165/200, Iteration 105/250, Loss: 0.0139\n",
      "Epoch 165/200, Iteration 106/250, Loss: 0.0089\n",
      "Epoch 165/200, Iteration 107/250, Loss: 0.0227\n",
      "Epoch 165/200, Iteration 108/250, Loss: 0.0192\n",
      "Epoch 165/200, Iteration 109/250, Loss: 0.0153\n",
      "Epoch 165/200, Iteration 110/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 111/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 112/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 113/250, Loss: 0.0072\n",
      "Epoch 165/200, Iteration 114/250, Loss: 0.0137\n",
      "Epoch 165/200, Iteration 115/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 116/250, Loss: 0.0125\n",
      "Epoch 165/200, Iteration 117/250, Loss: 0.0095\n",
      "Epoch 165/200, Iteration 118/250, Loss: 0.0104\n",
      "Epoch 165/200, Iteration 119/250, Loss: 0.0090\n",
      "Epoch 165/200, Iteration 120/250, Loss: 0.0138\n",
      "Epoch 165/200, Iteration 121/250, Loss: 0.0140\n",
      "Epoch 165/200, Iteration 122/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 123/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 165/200, Iteration 125/250, Loss: 0.0143\n",
      "Epoch 165/200, Iteration 126/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 127/250, Loss: 0.0354\n",
      "Epoch 165/200, Iteration 128/250, Loss: 0.0188\n",
      "Epoch 165/200, Iteration 129/250, Loss: 0.0303\n",
      "Epoch 165/200, Iteration 130/250, Loss: 0.0268\n",
      "Epoch 165/200, Iteration 131/250, Loss: 0.0113\n",
      "Epoch 165/200, Iteration 132/250, Loss: 0.0126\n",
      "Epoch 165/200, Iteration 133/250, Loss: 0.0356\n",
      "Epoch 165/200, Iteration 134/250, Loss: 0.0102\n",
      "Epoch 165/200, Iteration 135/250, Loss: 0.0187\n",
      "Epoch 165/200, Iteration 136/250, Loss: 0.0093\n",
      "Epoch 165/200, Iteration 137/250, Loss: 0.0111\n",
      "Epoch 165/200, Iteration 138/250, Loss: 0.0178\n",
      "Epoch 165/200, Iteration 139/250, Loss: 0.0075\n",
      "Epoch 165/200, Iteration 140/250, Loss: 0.0203\n",
      "Epoch 165/200, Iteration 141/250, Loss: 0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200, Iteration 142/250, Loss: 0.0071\n",
      "Epoch 165/200, Iteration 143/250, Loss: 0.0136\n",
      "Epoch 165/200, Iteration 144/250, Loss: 0.0213\n",
      "Epoch 165/200, Iteration 145/250, Loss: 0.0106\n",
      "Epoch 165/200, Iteration 146/250, Loss: 0.0298\n",
      "Epoch 165/200, Iteration 147/250, Loss: 0.0165\n",
      "Epoch 165/200, Iteration 148/250, Loss: 0.0088\n",
      "Epoch 165/200, Iteration 149/250, Loss: 0.0090\n",
      "Epoch 165/200, Iteration 150/250, Loss: 0.0241\n",
      "Epoch 165/200, Iteration 151/250, Loss: 0.0083\n",
      "Epoch 165/200, Iteration 152/250, Loss: 0.0499\n",
      "Epoch 165/200, Iteration 153/250, Loss: 0.0090\n",
      "Epoch 165/200, Iteration 154/250, Loss: 0.0080\n",
      "Epoch 165/200, Iteration 155/250, Loss: 0.0188\n",
      "Epoch 165/200, Iteration 156/250, Loss: 0.0158\n",
      "Epoch 165/200, Iteration 157/250, Loss: 0.0185\n",
      "Epoch 165/200, Iteration 158/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 159/250, Loss: 0.0228\n",
      "Epoch 165/200, Iteration 160/250, Loss: 0.0235\n",
      "Epoch 165/200, Iteration 161/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 162/250, Loss: 0.0115\n",
      "Epoch 165/200, Iteration 163/250, Loss: 0.0167\n",
      "Epoch 165/200, Iteration 164/250, Loss: 0.0214\n",
      "Epoch 165/200, Iteration 165/250, Loss: 0.0144\n",
      "Epoch 165/200, Iteration 166/250, Loss: 0.0276\n",
      "Epoch 165/200, Iteration 167/250, Loss: 0.0403\n",
      "Epoch 165/200, Iteration 168/250, Loss: 0.0135\n",
      "Epoch 165/200, Iteration 169/250, Loss: 0.0085\n",
      "Epoch 165/200, Iteration 170/250, Loss: 0.0314\n",
      "Epoch 165/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 165/200, Iteration 172/250, Loss: 0.0126\n",
      "Epoch 165/200, Iteration 173/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 174/250, Loss: 0.0170\n",
      "Epoch 165/200, Iteration 175/250, Loss: 0.0108\n",
      "Epoch 165/200, Iteration 176/250, Loss: 0.0404\n",
      "Epoch 165/200, Iteration 177/250, Loss: 0.0178\n",
      "Epoch 165/200, Iteration 178/250, Loss: 0.0103\n",
      "Epoch 165/200, Iteration 179/250, Loss: 0.0093\n",
      "Epoch 165/200, Iteration 180/250, Loss: 0.0130\n",
      "Epoch 165/200, Iteration 181/250, Loss: 0.0095\n",
      "Epoch 165/200, Iteration 182/250, Loss: 0.0160\n",
      "Epoch 165/200, Iteration 183/250, Loss: 0.0136\n",
      "Epoch 165/200, Iteration 184/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 185/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 165/200, Iteration 187/250, Loss: 0.0073\n",
      "Epoch 165/200, Iteration 188/250, Loss: 0.0132\n",
      "Epoch 165/200, Iteration 189/250, Loss: 0.0169\n",
      "Epoch 165/200, Iteration 190/250, Loss: 0.0233\n",
      "Epoch 165/200, Iteration 191/250, Loss: 0.0191\n",
      "Epoch 165/200, Iteration 192/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 193/250, Loss: 0.0118\n",
      "Epoch 165/200, Iteration 194/250, Loss: 0.0120\n",
      "Epoch 165/200, Iteration 195/250, Loss: 0.0094\n",
      "Epoch 165/200, Iteration 196/250, Loss: 0.0071\n",
      "Epoch 165/200, Iteration 197/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 198/250, Loss: 0.0219\n",
      "Epoch 165/200, Iteration 199/250, Loss: 0.0137\n",
      "Epoch 165/200, Iteration 200/250, Loss: 0.0133\n",
      "Epoch 165/200, Iteration 201/250, Loss: 0.0115\n",
      "Epoch 165/200, Iteration 202/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 203/250, Loss: 0.0084\n",
      "Epoch 165/200, Iteration 204/250, Loss: 0.0309\n",
      "Epoch 165/200, Iteration 205/250, Loss: 0.0110\n",
      "Epoch 165/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 207/250, Loss: 0.0295\n",
      "Epoch 165/200, Iteration 208/250, Loss: 0.0112\n",
      "Epoch 165/200, Iteration 209/250, Loss: 0.0323\n",
      "Epoch 165/200, Iteration 210/250, Loss: 0.0268\n",
      "Epoch 165/200, Iteration 211/250, Loss: 0.0127\n",
      "Epoch 165/200, Iteration 212/250, Loss: 0.0062\n",
      "Epoch 165/200, Iteration 213/250, Loss: 0.0090\n",
      "Epoch 165/200, Iteration 214/250, Loss: 0.0097\n",
      "Epoch 165/200, Iteration 215/250, Loss: 0.0233\n",
      "Epoch 165/200, Iteration 216/250, Loss: 0.0078\n",
      "Epoch 165/200, Iteration 217/250, Loss: 0.0179\n",
      "Epoch 165/200, Iteration 218/250, Loss: 0.0103\n",
      "Epoch 165/200, Iteration 219/250, Loss: 0.0123\n",
      "Epoch 165/200, Iteration 220/250, Loss: 0.0256\n",
      "Epoch 165/200, Iteration 221/250, Loss: 0.0143\n",
      "Epoch 165/200, Iteration 222/250, Loss: 0.0092\n",
      "Epoch 165/200, Iteration 223/250, Loss: 0.0091\n",
      "Epoch 165/200, Iteration 224/250, Loss: 0.0097\n",
      "Epoch 165/200, Iteration 225/250, Loss: 0.0113\n",
      "Epoch 165/200, Iteration 226/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 227/250, Loss: 0.0082\n",
      "Epoch 165/200, Iteration 228/250, Loss: 0.0181\n",
      "Epoch 165/200, Iteration 229/250, Loss: 0.0079\n",
      "Epoch 165/200, Iteration 230/250, Loss: 0.0160\n",
      "Epoch 165/200, Iteration 231/250, Loss: 0.0146\n",
      "Epoch 165/200, Iteration 232/250, Loss: 0.0142\n",
      "Epoch 165/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 165/200, Iteration 234/250, Loss: 0.0124\n",
      "Epoch 165/200, Iteration 235/250, Loss: 0.0101\n",
      "Epoch 165/200, Iteration 236/250, Loss: 0.0078\n",
      "Epoch 165/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 165/200, Iteration 238/250, Loss: 0.0122\n",
      "Epoch 165/200, Iteration 239/250, Loss: 0.0197\n",
      "Epoch 165/200, Iteration 240/250, Loss: 0.0216\n",
      "Epoch 165/200, Iteration 241/250, Loss: 0.0361\n",
      "Epoch 165/200, Iteration 242/250, Loss: 0.0182\n",
      "Epoch 165/200, Iteration 243/250, Loss: 0.0097\n",
      "Epoch 165/200, Iteration 244/250, Loss: 0.0246\n",
      "Epoch 165/200, Iteration 245/250, Loss: 0.0120\n",
      "Epoch 165/200, Iteration 246/250, Loss: 0.0130\n",
      "Epoch 165/200, Iteration 247/250, Loss: 0.0132\n",
      "Epoch 165/200, Iteration 248/250, Loss: 0.0199\n",
      "Epoch 165/200, Iteration 249/250, Loss: 0.0124\n",
      "Epoch 165/200, Iteration 250/250, Loss: 0.0246\n",
      "Train Error: \n",
      " Accuracy: 91.19%, Avg loss: 0.006737, MRE: 0.433291 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.95%, Avg loss: 0.007330, MRE: 0.549777 \n",
      "\n",
      "Epoch 166/200, Iteration 1/250, Loss: 0.0111\n",
      "Epoch 166/200, Iteration 2/250, Loss: 0.0125\n",
      "Epoch 166/200, Iteration 3/250, Loss: 0.0248\n",
      "Epoch 166/200, Iteration 4/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 5/250, Loss: 0.0190\n",
      "Epoch 166/200, Iteration 6/250, Loss: 0.0071\n",
      "Epoch 166/200, Iteration 7/250, Loss: 0.0086\n",
      "Epoch 166/200, Iteration 8/250, Loss: 0.0063\n",
      "Epoch 166/200, Iteration 9/250, Loss: 0.0179\n",
      "Epoch 166/200, Iteration 10/250, Loss: 0.0190\n",
      "Epoch 166/200, Iteration 11/250, Loss: 0.0252\n",
      "Epoch 166/200, Iteration 12/250, Loss: 0.0169\n",
      "Epoch 166/200, Iteration 13/250, Loss: 0.0319\n",
      "Epoch 166/200, Iteration 14/250, Loss: 0.0096\n",
      "Epoch 166/200, Iteration 15/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 16/250, Loss: 0.0103\n",
      "Epoch 166/200, Iteration 17/250, Loss: 0.0174\n",
      "Epoch 166/200, Iteration 18/250, Loss: 0.0088\n",
      "Epoch 166/200, Iteration 19/250, Loss: 0.0181\n",
      "Epoch 166/200, Iteration 20/250, Loss: 0.0110\n",
      "Epoch 166/200, Iteration 21/250, Loss: 0.0190\n",
      "Epoch 166/200, Iteration 22/250, Loss: 0.0191\n",
      "Epoch 166/200, Iteration 23/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 24/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 25/250, Loss: 0.0137\n",
      "Epoch 166/200, Iteration 26/250, Loss: 0.0072\n",
      "Epoch 166/200, Iteration 27/250, Loss: 0.0172\n",
      "Epoch 166/200, Iteration 28/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 29/250, Loss: 0.0103\n",
      "Epoch 166/200, Iteration 30/250, Loss: 0.0133\n",
      "Epoch 166/200, Iteration 31/250, Loss: 0.0305\n",
      "Epoch 166/200, Iteration 32/250, Loss: 0.0125\n",
      "Epoch 166/200, Iteration 33/250, Loss: 0.0161\n",
      "Epoch 166/200, Iteration 34/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 35/250, Loss: 0.0082\n",
      "Epoch 166/200, Iteration 36/250, Loss: 0.0262\n",
      "Epoch 166/200, Iteration 37/250, Loss: 0.0192\n",
      "Epoch 166/200, Iteration 38/250, Loss: 0.0081\n",
      "Epoch 166/200, Iteration 39/250, Loss: 0.0159\n",
      "Epoch 166/200, Iteration 40/250, Loss: 0.0089\n",
      "Epoch 166/200, Iteration 41/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 42/250, Loss: 0.0086\n",
      "Epoch 166/200, Iteration 43/250, Loss: 0.0156\n",
      "Epoch 166/200, Iteration 44/250, Loss: 0.0129\n",
      "Epoch 166/200, Iteration 45/250, Loss: 0.0138\n",
      "Epoch 166/200, Iteration 46/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 47/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 48/250, Loss: 0.0214\n",
      "Epoch 166/200, Iteration 49/250, Loss: 0.0272\n",
      "Epoch 166/200, Iteration 50/250, Loss: 0.0080\n",
      "Epoch 166/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 166/200, Iteration 52/250, Loss: 0.0107\n",
      "Epoch 166/200, Iteration 53/250, Loss: 0.0086\n",
      "Epoch 166/200, Iteration 54/250, Loss: 0.0142\n",
      "Epoch 166/200, Iteration 55/250, Loss: 0.0211\n",
      "Epoch 166/200, Iteration 56/250, Loss: 0.0450\n",
      "Epoch 166/200, Iteration 57/250, Loss: 0.0140\n",
      "Epoch 166/200, Iteration 58/250, Loss: 0.0241\n",
      "Epoch 166/200, Iteration 59/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 60/250, Loss: 0.0116\n",
      "Epoch 166/200, Iteration 61/250, Loss: 0.0148\n",
      "Epoch 166/200, Iteration 62/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 63/250, Loss: 0.0075\n",
      "Epoch 166/200, Iteration 64/250, Loss: 0.0093\n",
      "Epoch 166/200, Iteration 65/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 66/250, Loss: 0.0350\n",
      "Epoch 166/200, Iteration 67/250, Loss: 0.0225\n",
      "Epoch 166/200, Iteration 68/250, Loss: 0.0088\n",
      "Epoch 166/200, Iteration 69/250, Loss: 0.0290\n",
      "Epoch 166/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 71/250, Loss: 0.0324\n",
      "Epoch 166/200, Iteration 72/250, Loss: 0.0212\n",
      "Epoch 166/200, Iteration 73/250, Loss: 0.0311\n",
      "Epoch 166/200, Iteration 74/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 75/250, Loss: 0.0314\n",
      "Epoch 166/200, Iteration 76/250, Loss: 0.0134\n",
      "Epoch 166/200, Iteration 77/250, Loss: 0.0107\n",
      "Epoch 166/200, Iteration 78/250, Loss: 0.0203\n",
      "Epoch 166/200, Iteration 79/250, Loss: 0.0137\n",
      "Epoch 166/200, Iteration 80/250, Loss: 0.0087\n",
      "Epoch 166/200, Iteration 81/250, Loss: 0.0108\n",
      "Epoch 166/200, Iteration 82/250, Loss: 0.0137\n",
      "Epoch 166/200, Iteration 83/250, Loss: 0.0088\n",
      "Epoch 166/200, Iteration 84/250, Loss: 0.0096\n",
      "Epoch 166/200, Iteration 85/250, Loss: 0.0255\n",
      "Epoch 166/200, Iteration 86/250, Loss: 0.0132\n",
      "Epoch 166/200, Iteration 87/250, Loss: 0.0259\n",
      "Epoch 166/200, Iteration 88/250, Loss: 0.0151\n",
      "Epoch 166/200, Iteration 89/250, Loss: 0.0100\n",
      "Epoch 166/200, Iteration 90/250, Loss: 0.0200\n",
      "Epoch 166/200, Iteration 91/250, Loss: 0.0160\n",
      "Epoch 166/200, Iteration 92/250, Loss: 0.0127\n",
      "Epoch 166/200, Iteration 93/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 94/250, Loss: 0.0090\n",
      "Epoch 166/200, Iteration 95/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 96/250, Loss: 0.0113\n",
      "Epoch 166/200, Iteration 97/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 98/250, Loss: 0.0246\n",
      "Epoch 166/200, Iteration 99/250, Loss: 0.0082\n",
      "Epoch 166/200, Iteration 100/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 101/250, Loss: 0.0091\n",
      "Epoch 166/200, Iteration 102/250, Loss: 0.0141\n",
      "Epoch 166/200, Iteration 103/250, Loss: 0.0197\n",
      "Epoch 166/200, Iteration 104/250, Loss: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200, Iteration 105/250, Loss: 0.0078\n",
      "Epoch 166/200, Iteration 106/250, Loss: 0.0105\n",
      "Epoch 166/200, Iteration 107/250, Loss: 0.0260\n",
      "Epoch 166/200, Iteration 108/250, Loss: 0.0174\n",
      "Epoch 166/200, Iteration 109/250, Loss: 0.0124\n",
      "Epoch 166/200, Iteration 110/250, Loss: 0.0286\n",
      "Epoch 166/200, Iteration 111/250, Loss: 0.0127\n",
      "Epoch 166/200, Iteration 112/250, Loss: 0.0291\n",
      "Epoch 166/200, Iteration 113/250, Loss: 0.0121\n",
      "Epoch 166/200, Iteration 114/250, Loss: 0.0276\n",
      "Epoch 166/200, Iteration 115/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 116/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 117/250, Loss: 0.0164\n",
      "Epoch 166/200, Iteration 118/250, Loss: 0.0380\n",
      "Epoch 166/200, Iteration 119/250, Loss: 0.0072\n",
      "Epoch 166/200, Iteration 120/250, Loss: 0.0085\n",
      "Epoch 166/200, Iteration 121/250, Loss: 0.0215\n",
      "Epoch 166/200, Iteration 122/250, Loss: 0.0176\n",
      "Epoch 166/200, Iteration 123/250, Loss: 0.0226\n",
      "Epoch 166/200, Iteration 124/250, Loss: 0.0211\n",
      "Epoch 166/200, Iteration 125/250, Loss: 0.0073\n",
      "Epoch 166/200, Iteration 126/250, Loss: 0.0125\n",
      "Epoch 166/200, Iteration 127/250, Loss: 0.0104\n",
      "Epoch 166/200, Iteration 128/250, Loss: 0.0122\n",
      "Epoch 166/200, Iteration 129/250, Loss: 0.0116\n",
      "Epoch 166/200, Iteration 130/250, Loss: 0.0191\n",
      "Epoch 166/200, Iteration 131/250, Loss: 0.0092\n",
      "Epoch 166/200, Iteration 132/250, Loss: 0.0065\n",
      "Epoch 166/200, Iteration 133/250, Loss: 0.0075\n",
      "Epoch 166/200, Iteration 134/250, Loss: 0.0241\n",
      "Epoch 166/200, Iteration 135/250, Loss: 0.0097\n",
      "Epoch 166/200, Iteration 136/250, Loss: 0.0121\n",
      "Epoch 166/200, Iteration 137/250, Loss: 0.0277\n",
      "Epoch 166/200, Iteration 138/250, Loss: 0.0222\n",
      "Epoch 166/200, Iteration 139/250, Loss: 0.0099\n",
      "Epoch 166/200, Iteration 140/250, Loss: 0.0263\n",
      "Epoch 166/200, Iteration 141/250, Loss: 0.0161\n",
      "Epoch 166/200, Iteration 142/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 143/250, Loss: 0.0190\n",
      "Epoch 166/200, Iteration 144/250, Loss: 0.0173\n",
      "Epoch 166/200, Iteration 145/250, Loss: 0.0163\n",
      "Epoch 166/200, Iteration 146/250, Loss: 0.0177\n",
      "Epoch 166/200, Iteration 147/250, Loss: 0.0125\n",
      "Epoch 166/200, Iteration 148/250, Loss: 0.0124\n",
      "Epoch 166/200, Iteration 149/250, Loss: 0.0201\n",
      "Epoch 166/200, Iteration 150/250, Loss: 0.0229\n",
      "Epoch 166/200, Iteration 151/250, Loss: 0.0151\n",
      "Epoch 166/200, Iteration 152/250, Loss: 0.0252\n",
      "Epoch 166/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 166/200, Iteration 154/250, Loss: 0.0083\n",
      "Epoch 166/200, Iteration 155/250, Loss: 0.0174\n",
      "Epoch 166/200, Iteration 156/250, Loss: 0.0180\n",
      "Epoch 166/200, Iteration 157/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 158/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 159/250, Loss: 0.0413\n",
      "Epoch 166/200, Iteration 160/250, Loss: 0.0293\n",
      "Epoch 166/200, Iteration 161/250, Loss: 0.0104\n",
      "Epoch 166/200, Iteration 162/250, Loss: 0.0195\n",
      "Epoch 166/200, Iteration 163/250, Loss: 0.0174\n",
      "Epoch 166/200, Iteration 164/250, Loss: 0.0097\n",
      "Epoch 166/200, Iteration 165/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 166/250, Loss: 0.0416\n",
      "Epoch 166/200, Iteration 167/250, Loss: 0.0182\n",
      "Epoch 166/200, Iteration 168/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 169/250, Loss: 0.0215\n",
      "Epoch 166/200, Iteration 170/250, Loss: 0.0093\n",
      "Epoch 166/200, Iteration 171/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 172/250, Loss: 0.0130\n",
      "Epoch 166/200, Iteration 173/250, Loss: 0.0135\n",
      "Epoch 166/200, Iteration 174/250, Loss: 0.0101\n",
      "Epoch 166/200, Iteration 175/250, Loss: 0.0412\n",
      "Epoch 166/200, Iteration 176/250, Loss: 0.0089\n",
      "Epoch 166/200, Iteration 177/250, Loss: 0.0105\n",
      "Epoch 166/200, Iteration 178/250, Loss: 0.0197\n",
      "Epoch 166/200, Iteration 179/250, Loss: 0.0207\n",
      "Epoch 166/200, Iteration 180/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 181/250, Loss: 0.0331\n",
      "Epoch 166/200, Iteration 182/250, Loss: 0.0205\n",
      "Epoch 166/200, Iteration 183/250, Loss: 0.0136\n",
      "Epoch 166/200, Iteration 184/250, Loss: 0.0307\n",
      "Epoch 166/200, Iteration 185/250, Loss: 0.0259\n",
      "Epoch 166/200, Iteration 186/250, Loss: 0.0127\n",
      "Epoch 166/200, Iteration 187/250, Loss: 0.0188\n",
      "Epoch 166/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 189/250, Loss: 0.0181\n",
      "Epoch 166/200, Iteration 190/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 191/250, Loss: 0.0065\n",
      "Epoch 166/200, Iteration 192/250, Loss: 0.0115\n",
      "Epoch 166/200, Iteration 193/250, Loss: 0.0153\n",
      "Epoch 166/200, Iteration 194/250, Loss: 0.0090\n",
      "Epoch 166/200, Iteration 195/250, Loss: 0.0081\n",
      "Epoch 166/200, Iteration 196/250, Loss: 0.0143\n",
      "Epoch 166/200, Iteration 197/250, Loss: 0.0136\n",
      "Epoch 166/200, Iteration 198/250, Loss: 0.0078\n",
      "Epoch 166/200, Iteration 199/250, Loss: 0.0119\n",
      "Epoch 166/200, Iteration 200/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 201/250, Loss: 0.0064\n",
      "Epoch 166/200, Iteration 202/250, Loss: 0.0258\n",
      "Epoch 166/200, Iteration 203/250, Loss: 0.0223\n",
      "Epoch 166/200, Iteration 204/250, Loss: 0.0200\n",
      "Epoch 166/200, Iteration 205/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 206/250, Loss: 0.0141\n",
      "Epoch 166/200, Iteration 207/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 208/250, Loss: 0.0244\n",
      "Epoch 166/200, Iteration 209/250, Loss: 0.0144\n",
      "Epoch 166/200, Iteration 210/250, Loss: 0.0107\n",
      "Epoch 166/200, Iteration 211/250, Loss: 0.0099\n",
      "Epoch 166/200, Iteration 212/250, Loss: 0.0183\n",
      "Epoch 166/200, Iteration 213/250, Loss: 0.0112\n",
      "Epoch 166/200, Iteration 214/250, Loss: 0.0144\n",
      "Epoch 166/200, Iteration 215/250, Loss: 0.0184\n",
      "Epoch 166/200, Iteration 216/250, Loss: 0.0097\n",
      "Epoch 166/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 166/200, Iteration 218/250, Loss: 0.0128\n",
      "Epoch 166/200, Iteration 219/250, Loss: 0.0306\n",
      "Epoch 166/200, Iteration 220/250, Loss: 0.0329\n",
      "Epoch 166/200, Iteration 221/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 222/250, Loss: 0.0201\n",
      "Epoch 166/200, Iteration 223/250, Loss: 0.0293\n",
      "Epoch 166/200, Iteration 224/250, Loss: 0.0190\n",
      "Epoch 166/200, Iteration 225/250, Loss: 0.0285\n",
      "Epoch 166/200, Iteration 226/250, Loss: 0.0318\n",
      "Epoch 166/200, Iteration 227/250, Loss: 0.0690\n",
      "Epoch 166/200, Iteration 228/250, Loss: 0.0165\n",
      "Epoch 166/200, Iteration 229/250, Loss: 0.0228\n",
      "Epoch 166/200, Iteration 230/250, Loss: 0.0157\n",
      "Epoch 166/200, Iteration 231/250, Loss: 0.0102\n",
      "Epoch 166/200, Iteration 232/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 233/250, Loss: 0.0193\n",
      "Epoch 166/200, Iteration 234/250, Loss: 0.0151\n",
      "Epoch 166/200, Iteration 235/250, Loss: 0.0149\n",
      "Epoch 166/200, Iteration 236/250, Loss: 0.0095\n",
      "Epoch 166/200, Iteration 237/250, Loss: 0.0096\n",
      "Epoch 166/200, Iteration 238/250, Loss: 0.0268\n",
      "Epoch 166/200, Iteration 239/250, Loss: 0.0177\n",
      "Epoch 166/200, Iteration 240/250, Loss: 0.0251\n",
      "Epoch 166/200, Iteration 241/250, Loss: 0.0109\n",
      "Epoch 166/200, Iteration 242/250, Loss: 0.0196\n",
      "Epoch 166/200, Iteration 243/250, Loss: 0.0146\n",
      "Epoch 166/200, Iteration 244/250, Loss: 0.0172\n",
      "Epoch 166/200, Iteration 245/250, Loss: 0.0151\n",
      "Epoch 166/200, Iteration 246/250, Loss: 0.0114\n",
      "Epoch 166/200, Iteration 247/250, Loss: 0.0135\n",
      "Epoch 166/200, Iteration 248/250, Loss: 0.0100\n",
      "Epoch 166/200, Iteration 249/250, Loss: 0.0193\n",
      "Epoch 166/200, Iteration 250/250, Loss: 0.0076\n",
      "Train Error: \n",
      " Accuracy: 84.62%, Avg loss: 0.006841, MRE: 0.430773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.55%, Avg loss: 0.007349, MRE: 0.545592 \n",
      "\n",
      "Epoch 167/200, Iteration 1/250, Loss: 0.0224\n",
      "Epoch 167/200, Iteration 2/250, Loss: 0.0167\n",
      "Epoch 167/200, Iteration 3/250, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 4/250, Loss: 0.0118\n",
      "Epoch 167/200, Iteration 5/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 6/250, Loss: 0.0073\n",
      "Epoch 167/200, Iteration 7/250, Loss: 0.0215\n",
      "Epoch 167/200, Iteration 8/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 167/200, Iteration 10/250, Loss: 0.0257\n",
      "Epoch 167/200, Iteration 11/250, Loss: 0.0216\n",
      "Epoch 167/200, Iteration 12/250, Loss: 0.0238\n",
      "Epoch 167/200, Iteration 13/250, Loss: 0.0103\n",
      "Epoch 167/200, Iteration 14/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 15/250, Loss: 0.0133\n",
      "Epoch 167/200, Iteration 16/250, Loss: 0.0103\n",
      "Epoch 167/200, Iteration 17/250, Loss: 0.0106\n",
      "Epoch 167/200, Iteration 18/250, Loss: 0.0140\n",
      "Epoch 167/200, Iteration 19/250, Loss: 0.0191\n",
      "Epoch 167/200, Iteration 20/250, Loss: 0.0132\n",
      "Epoch 167/200, Iteration 21/250, Loss: 0.0097\n",
      "Epoch 167/200, Iteration 22/250, Loss: 0.0206\n",
      "Epoch 167/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 24/250, Loss: 0.0475\n",
      "Epoch 167/200, Iteration 25/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 26/250, Loss: 0.0196\n",
      "Epoch 167/200, Iteration 27/250, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200, Iteration 28/250, Loss: 0.0196\n",
      "Epoch 167/200, Iteration 29/250, Loss: 0.0228\n",
      "Epoch 167/200, Iteration 30/250, Loss: 0.0223\n",
      "Epoch 167/200, Iteration 31/250, Loss: 0.0123\n",
      "Epoch 167/200, Iteration 32/250, Loss: 0.0196\n",
      "Epoch 167/200, Iteration 33/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 34/250, Loss: 0.0255\n",
      "Epoch 167/200, Iteration 35/250, Loss: 0.0173\n",
      "Epoch 167/200, Iteration 36/250, Loss: 0.0314\n",
      "Epoch 167/200, Iteration 37/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 38/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 39/250, Loss: 0.0244\n",
      "Epoch 167/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 41/250, Loss: 0.0147\n",
      "Epoch 167/200, Iteration 42/250, Loss: 0.0181\n",
      "Epoch 167/200, Iteration 43/250, Loss: 0.0272\n",
      "Epoch 167/200, Iteration 44/250, Loss: 0.0150\n",
      "Epoch 167/200, Iteration 45/250, Loss: 0.0072\n",
      "Epoch 167/200, Iteration 46/250, Loss: 0.0298\n",
      "Epoch 167/200, Iteration 47/250, Loss: 0.0064\n",
      "Epoch 167/200, Iteration 48/250, Loss: 0.0157\n",
      "Epoch 167/200, Iteration 49/250, Loss: 0.0076\n",
      "Epoch 167/200, Iteration 50/250, Loss: 0.0144\n",
      "Epoch 167/200, Iteration 51/250, Loss: 0.0152\n",
      "Epoch 167/200, Iteration 52/250, Loss: 0.0190\n",
      "Epoch 167/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 54/250, Loss: 0.0174\n",
      "Epoch 167/200, Iteration 55/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 56/250, Loss: 0.0120\n",
      "Epoch 167/200, Iteration 57/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 58/250, Loss: 0.0171\n",
      "Epoch 167/200, Iteration 59/250, Loss: 0.0121\n",
      "Epoch 167/200, Iteration 60/250, Loss: 0.0355\n",
      "Epoch 167/200, Iteration 61/250, Loss: 0.0423\n",
      "Epoch 167/200, Iteration 62/250, Loss: 0.0139\n",
      "Epoch 167/200, Iteration 63/250, Loss: 0.0243\n",
      "Epoch 167/200, Iteration 64/250, Loss: 0.0087\n",
      "Epoch 167/200, Iteration 65/250, Loss: 0.0098\n",
      "Epoch 167/200, Iteration 66/250, Loss: 0.0116\n",
      "Epoch 167/200, Iteration 67/250, Loss: 0.0177\n",
      "Epoch 167/200, Iteration 68/250, Loss: 0.0256\n",
      "Epoch 167/200, Iteration 69/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 70/250, Loss: 0.0178\n",
      "Epoch 167/200, Iteration 71/250, Loss: 0.0073\n",
      "Epoch 167/200, Iteration 72/250, Loss: 0.0067\n",
      "Epoch 167/200, Iteration 73/250, Loss: 0.0279\n",
      "Epoch 167/200, Iteration 74/250, Loss: 0.0144\n",
      "Epoch 167/200, Iteration 75/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 76/250, Loss: 0.0113\n",
      "Epoch 167/200, Iteration 77/250, Loss: 0.0190\n",
      "Epoch 167/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 167/200, Iteration 79/250, Loss: 0.0070\n",
      "Epoch 167/200, Iteration 80/250, Loss: 0.0124\n",
      "Epoch 167/200, Iteration 81/250, Loss: 0.0103\n",
      "Epoch 167/200, Iteration 82/250, Loss: 0.0195\n",
      "Epoch 167/200, Iteration 83/250, Loss: 0.0142\n",
      "Epoch 167/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 167/200, Iteration 85/250, Loss: 0.0168\n",
      "Epoch 167/200, Iteration 86/250, Loss: 0.0140\n",
      "Epoch 167/200, Iteration 87/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 88/250, Loss: 0.0539\n",
      "Epoch 167/200, Iteration 89/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 90/250, Loss: 0.0119\n",
      "Epoch 167/200, Iteration 91/250, Loss: 0.0323\n",
      "Epoch 167/200, Iteration 92/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 93/250, Loss: 0.0144\n",
      "Epoch 167/200, Iteration 94/250, Loss: 0.0150\n",
      "Epoch 167/200, Iteration 95/250, Loss: 0.0081\n",
      "Epoch 167/200, Iteration 96/250, Loss: 0.0168\n",
      "Epoch 167/200, Iteration 97/250, Loss: 0.0110\n",
      "Epoch 167/200, Iteration 98/250, Loss: 0.0308\n",
      "Epoch 167/200, Iteration 99/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 100/250, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 101/250, Loss: 0.0183\n",
      "Epoch 167/200, Iteration 102/250, Loss: 0.0181\n",
      "Epoch 167/200, Iteration 103/250, Loss: 0.0128\n",
      "Epoch 167/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 167/200, Iteration 105/250, Loss: 0.0254\n",
      "Epoch 167/200, Iteration 106/250, Loss: 0.0134\n",
      "Epoch 167/200, Iteration 107/250, Loss: 0.0403\n",
      "Epoch 167/200, Iteration 108/250, Loss: 0.0176\n",
      "Epoch 167/200, Iteration 109/250, Loss: 0.0266\n",
      "Epoch 167/200, Iteration 110/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 111/250, Loss: 0.0438\n",
      "Epoch 167/200, Iteration 112/250, Loss: 0.0072\n",
      "Epoch 167/200, Iteration 113/250, Loss: 0.0314\n",
      "Epoch 167/200, Iteration 114/250, Loss: 0.0142\n",
      "Epoch 167/200, Iteration 115/250, Loss: 0.0151\n",
      "Epoch 167/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 117/250, Loss: 0.0090\n",
      "Epoch 167/200, Iteration 118/250, Loss: 0.0077\n",
      "Epoch 167/200, Iteration 119/250, Loss: 0.0164\n",
      "Epoch 167/200, Iteration 120/250, Loss: 0.0066\n",
      "Epoch 167/200, Iteration 121/250, Loss: 0.0118\n",
      "Epoch 167/200, Iteration 122/250, Loss: 0.0160\n",
      "Epoch 167/200, Iteration 123/250, Loss: 0.0257\n",
      "Epoch 167/200, Iteration 124/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 125/250, Loss: 0.0091\n",
      "Epoch 167/200, Iteration 126/250, Loss: 0.0134\n",
      "Epoch 167/200, Iteration 127/250, Loss: 0.0149\n",
      "Epoch 167/200, Iteration 128/250, Loss: 0.0095\n",
      "Epoch 167/200, Iteration 129/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 130/250, Loss: 0.0101\n",
      "Epoch 167/200, Iteration 131/250, Loss: 0.0125\n",
      "Epoch 167/200, Iteration 132/250, Loss: 0.0161\n",
      "Epoch 167/200, Iteration 133/250, Loss: 0.0254\n",
      "Epoch 167/200, Iteration 134/250, Loss: 0.0084\n",
      "Epoch 167/200, Iteration 135/250, Loss: 0.0164\n",
      "Epoch 167/200, Iteration 136/250, Loss: 0.0142\n",
      "Epoch 167/200, Iteration 137/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 138/250, Loss: 0.0076\n",
      "Epoch 167/200, Iteration 139/250, Loss: 0.0071\n",
      "Epoch 167/200, Iteration 140/250, Loss: 0.0135\n",
      "Epoch 167/200, Iteration 141/250, Loss: 0.0089\n",
      "Epoch 167/200, Iteration 142/250, Loss: 0.0222\n",
      "Epoch 167/200, Iteration 143/250, Loss: 0.0272\n",
      "Epoch 167/200, Iteration 144/250, Loss: 0.0190\n",
      "Epoch 167/200, Iteration 145/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 146/250, Loss: 0.0229\n",
      "Epoch 167/200, Iteration 147/250, Loss: 0.0109\n",
      "Epoch 167/200, Iteration 148/250, Loss: 0.0109\n",
      "Epoch 167/200, Iteration 149/250, Loss: 0.0092\n",
      "Epoch 167/200, Iteration 150/250, Loss: 0.0090\n",
      "Epoch 167/200, Iteration 151/250, Loss: 0.0084\n",
      "Epoch 167/200, Iteration 152/250, Loss: 0.0085\n",
      "Epoch 167/200, Iteration 153/250, Loss: 0.0128\n",
      "Epoch 167/200, Iteration 154/250, Loss: 0.0113\n",
      "Epoch 167/200, Iteration 155/250, Loss: 0.0131\n",
      "Epoch 167/200, Iteration 156/250, Loss: 0.0339\n",
      "Epoch 167/200, Iteration 157/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 158/250, Loss: 0.0162\n",
      "Epoch 167/200, Iteration 159/250, Loss: 0.0095\n",
      "Epoch 167/200, Iteration 160/250, Loss: 0.0163\n",
      "Epoch 167/200, Iteration 161/250, Loss: 0.0307\n",
      "Epoch 167/200, Iteration 162/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 163/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 164/250, Loss: 0.0132\n",
      "Epoch 167/200, Iteration 165/250, Loss: 0.0095\n",
      "Epoch 167/200, Iteration 166/250, Loss: 0.0073\n",
      "Epoch 167/200, Iteration 167/250, Loss: 0.0137\n",
      "Epoch 167/200, Iteration 168/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 169/250, Loss: 0.0159\n",
      "Epoch 167/200, Iteration 170/250, Loss: 0.0155\n",
      "Epoch 167/200, Iteration 171/250, Loss: 0.0103\n",
      "Epoch 167/200, Iteration 172/250, Loss: 0.0143\n",
      "Epoch 167/200, Iteration 173/250, Loss: 0.0116\n",
      "Epoch 167/200, Iteration 174/250, Loss: 0.0090\n",
      "Epoch 167/200, Iteration 175/250, Loss: 0.0103\n",
      "Epoch 167/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 167/200, Iteration 177/250, Loss: 0.0090\n",
      "Epoch 167/200, Iteration 178/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 179/250, Loss: 0.0303\n",
      "Epoch 167/200, Iteration 180/250, Loss: 0.0083\n",
      "Epoch 167/200, Iteration 181/250, Loss: 0.0144\n",
      "Epoch 167/200, Iteration 182/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 167/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 167/200, Iteration 185/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 186/250, Loss: 0.0296\n",
      "Epoch 167/200, Iteration 187/250, Loss: 0.0145\n",
      "Epoch 167/200, Iteration 188/250, Loss: 0.0122\n",
      "Epoch 167/200, Iteration 189/250, Loss: 0.0243\n",
      "Epoch 167/200, Iteration 190/250, Loss: 0.0439\n",
      "Epoch 167/200, Iteration 191/250, Loss: 0.0200\n",
      "Epoch 167/200, Iteration 192/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 193/250, Loss: 0.0171\n",
      "Epoch 167/200, Iteration 194/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 195/250, Loss: 0.0096\n",
      "Epoch 167/200, Iteration 196/250, Loss: 0.0167\n",
      "Epoch 167/200, Iteration 197/250, Loss: 0.0121\n",
      "Epoch 167/200, Iteration 198/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 199/250, Loss: 0.0076\n",
      "Epoch 167/200, Iteration 200/250, Loss: 0.0099\n",
      "Epoch 167/200, Iteration 201/250, Loss: 0.0140\n",
      "Epoch 167/200, Iteration 202/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 203/250, Loss: 0.0152\n",
      "Epoch 167/200, Iteration 204/250, Loss: 0.0106\n",
      "Epoch 167/200, Iteration 205/250, Loss: 0.0320\n",
      "Epoch 167/200, Iteration 206/250, Loss: 0.0315\n",
      "Epoch 167/200, Iteration 207/250, Loss: 0.0078\n",
      "Epoch 167/200, Iteration 208/250, Loss: 0.0157\n",
      "Epoch 167/200, Iteration 209/250, Loss: 0.0129\n",
      "Epoch 167/200, Iteration 210/250, Loss: 0.0224\n",
      "Epoch 167/200, Iteration 211/250, Loss: 0.0117\n",
      "Epoch 167/200, Iteration 212/250, Loss: 0.0460\n",
      "Epoch 167/200, Iteration 213/250, Loss: 0.0162\n",
      "Epoch 167/200, Iteration 214/250, Loss: 0.0088\n",
      "Epoch 167/200, Iteration 215/250, Loss: 0.0185\n",
      "Epoch 167/200, Iteration 216/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 217/250, Loss: 0.0095\n",
      "Epoch 167/200, Iteration 218/250, Loss: 0.0105\n",
      "Epoch 167/200, Iteration 219/250, Loss: 0.0115\n",
      "Epoch 167/200, Iteration 220/250, Loss: 0.0298\n",
      "Epoch 167/200, Iteration 221/250, Loss: 0.0094\n",
      "Epoch 167/200, Iteration 222/250, Loss: 0.0112\n",
      "Epoch 167/200, Iteration 223/250, Loss: 0.0101\n",
      "Epoch 167/200, Iteration 224/250, Loss: 0.0073\n",
      "Epoch 167/200, Iteration 225/250, Loss: 0.0114\n",
      "Epoch 167/200, Iteration 226/250, Loss: 0.0395\n",
      "Epoch 167/200, Iteration 227/250, Loss: 0.0112\n",
      "Epoch 167/200, Iteration 228/250, Loss: 0.0082\n",
      "Epoch 167/200, Iteration 229/250, Loss: 0.0062\n",
      "Epoch 167/200, Iteration 230/250, Loss: 0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200, Iteration 231/250, Loss: 0.0086\n",
      "Epoch 167/200, Iteration 232/250, Loss: 0.0093\n",
      "Epoch 167/200, Iteration 233/250, Loss: 0.0230\n",
      "Epoch 167/200, Iteration 234/250, Loss: 0.0150\n",
      "Epoch 167/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 167/200, Iteration 236/250, Loss: 0.0080\n",
      "Epoch 167/200, Iteration 237/250, Loss: 0.0074\n",
      "Epoch 167/200, Iteration 238/250, Loss: 0.0159\n",
      "Epoch 167/200, Iteration 239/250, Loss: 0.0086\n",
      "Epoch 167/200, Iteration 240/250, Loss: 0.0182\n",
      "Epoch 167/200, Iteration 241/250, Loss: 0.0135\n",
      "Epoch 167/200, Iteration 242/250, Loss: 0.0164\n",
      "Epoch 167/200, Iteration 243/250, Loss: 0.0176\n",
      "Epoch 167/200, Iteration 244/250, Loss: 0.0181\n",
      "Epoch 167/200, Iteration 245/250, Loss: 0.0149\n",
      "Epoch 167/200, Iteration 246/250, Loss: 0.0156\n",
      "Epoch 167/200, Iteration 247/250, Loss: 0.0203\n",
      "Epoch 167/200, Iteration 248/250, Loss: 0.0174\n",
      "Epoch 167/200, Iteration 249/250, Loss: 0.0100\n",
      "Epoch 167/200, Iteration 250/250, Loss: 0.0088\n",
      "Train Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.006703, MRE: 0.415638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.95%, Avg loss: 0.007221, MRE: 0.515957 \n",
      "\n",
      "Epoch 168/200, Iteration 1/250, Loss: 0.0098\n",
      "Epoch 168/200, Iteration 2/250, Loss: 0.0091\n",
      "Epoch 168/200, Iteration 3/250, Loss: 0.0064\n",
      "Epoch 168/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 5/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 6/250, Loss: 0.0183\n",
      "Epoch 168/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 8/250, Loss: 0.0197\n",
      "Epoch 168/200, Iteration 9/250, Loss: 0.0207\n",
      "Epoch 168/200, Iteration 10/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 11/250, Loss: 0.0173\n",
      "Epoch 168/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 13/250, Loss: 0.0118\n",
      "Epoch 168/200, Iteration 14/250, Loss: 0.0107\n",
      "Epoch 168/200, Iteration 15/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 16/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 17/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 19/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 20/250, Loss: 0.0195\n",
      "Epoch 168/200, Iteration 21/250, Loss: 0.0089\n",
      "Epoch 168/200, Iteration 22/250, Loss: 0.0106\n",
      "Epoch 168/200, Iteration 23/250, Loss: 0.0304\n",
      "Epoch 168/200, Iteration 24/250, Loss: 0.0120\n",
      "Epoch 168/200, Iteration 25/250, Loss: 0.0162\n",
      "Epoch 168/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 168/200, Iteration 27/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 28/250, Loss: 0.0175\n",
      "Epoch 168/200, Iteration 29/250, Loss: 0.0156\n",
      "Epoch 168/200, Iteration 30/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 31/250, Loss: 0.0195\n",
      "Epoch 168/200, Iteration 32/250, Loss: 0.0181\n",
      "Epoch 168/200, Iteration 33/250, Loss: 0.0125\n",
      "Epoch 168/200, Iteration 34/250, Loss: 0.0079\n",
      "Epoch 168/200, Iteration 35/250, Loss: 0.0119\n",
      "Epoch 168/200, Iteration 36/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 37/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 38/250, Loss: 0.0120\n",
      "Epoch 168/200, Iteration 39/250, Loss: 0.0295\n",
      "Epoch 168/200, Iteration 40/250, Loss: 0.0148\n",
      "Epoch 168/200, Iteration 41/250, Loss: 0.0263\n",
      "Epoch 168/200, Iteration 42/250, Loss: 0.0221\n",
      "Epoch 168/200, Iteration 43/250, Loss: 0.0175\n",
      "Epoch 168/200, Iteration 44/250, Loss: 0.0267\n",
      "Epoch 168/200, Iteration 45/250, Loss: 0.0104\n",
      "Epoch 168/200, Iteration 46/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 47/250, Loss: 0.0142\n",
      "Epoch 168/200, Iteration 48/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 49/250, Loss: 0.0141\n",
      "Epoch 168/200, Iteration 50/250, Loss: 0.0100\n",
      "Epoch 168/200, Iteration 51/250, Loss: 0.0085\n",
      "Epoch 168/200, Iteration 52/250, Loss: 0.0281\n",
      "Epoch 168/200, Iteration 53/250, Loss: 0.0114\n",
      "Epoch 168/200, Iteration 54/250, Loss: 0.0137\n",
      "Epoch 168/200, Iteration 55/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 56/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 58/250, Loss: 0.0337\n",
      "Epoch 168/200, Iteration 59/250, Loss: 0.0147\n",
      "Epoch 168/200, Iteration 60/250, Loss: 0.0072\n",
      "Epoch 168/200, Iteration 61/250, Loss: 0.0088\n",
      "Epoch 168/200, Iteration 62/250, Loss: 0.0077\n",
      "Epoch 168/200, Iteration 63/250, Loss: 0.0145\n",
      "Epoch 168/200, Iteration 64/250, Loss: 0.0365\n",
      "Epoch 168/200, Iteration 65/250, Loss: 0.0154\n",
      "Epoch 168/200, Iteration 66/250, Loss: 0.0161\n",
      "Epoch 168/200, Iteration 67/250, Loss: 0.0153\n",
      "Epoch 168/200, Iteration 68/250, Loss: 0.0082\n",
      "Epoch 168/200, Iteration 69/250, Loss: 0.0346\n",
      "Epoch 168/200, Iteration 70/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 71/250, Loss: 0.0139\n",
      "Epoch 168/200, Iteration 72/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 73/250, Loss: 0.0238\n",
      "Epoch 168/200, Iteration 74/250, Loss: 0.0098\n",
      "Epoch 168/200, Iteration 75/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 76/250, Loss: 0.0130\n",
      "Epoch 168/200, Iteration 77/250, Loss: 0.0152\n",
      "Epoch 168/200, Iteration 78/250, Loss: 0.0073\n",
      "Epoch 168/200, Iteration 79/250, Loss: 0.0072\n",
      "Epoch 168/200, Iteration 80/250, Loss: 0.0273\n",
      "Epoch 168/200, Iteration 81/250, Loss: 0.0080\n",
      "Epoch 168/200, Iteration 82/250, Loss: 0.0238\n",
      "Epoch 168/200, Iteration 83/250, Loss: 0.0131\n",
      "Epoch 168/200, Iteration 84/250, Loss: 0.0266\n",
      "Epoch 168/200, Iteration 85/250, Loss: 0.0130\n",
      "Epoch 168/200, Iteration 86/250, Loss: 0.0145\n",
      "Epoch 168/200, Iteration 87/250, Loss: 0.0089\n",
      "Epoch 168/200, Iteration 88/250, Loss: 0.0217\n",
      "Epoch 168/200, Iteration 89/250, Loss: 0.0083\n",
      "Epoch 168/200, Iteration 90/250, Loss: 0.0176\n",
      "Epoch 168/200, Iteration 91/250, Loss: 0.0153\n",
      "Epoch 168/200, Iteration 92/250, Loss: 0.0126\n",
      "Epoch 168/200, Iteration 93/250, Loss: 0.0132\n",
      "Epoch 168/200, Iteration 94/250, Loss: 0.0169\n",
      "Epoch 168/200, Iteration 95/250, Loss: 0.0162\n",
      "Epoch 168/200, Iteration 96/250, Loss: 0.0262\n",
      "Epoch 168/200, Iteration 97/250, Loss: 0.0242\n",
      "Epoch 168/200, Iteration 98/250, Loss: 0.0219\n",
      "Epoch 168/200, Iteration 99/250, Loss: 0.0182\n",
      "Epoch 168/200, Iteration 100/250, Loss: 0.0152\n",
      "Epoch 168/200, Iteration 101/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 102/250, Loss: 0.0074\n",
      "Epoch 168/200, Iteration 103/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 104/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 105/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 106/250, Loss: 0.0220\n",
      "Epoch 168/200, Iteration 107/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 108/250, Loss: 0.0117\n",
      "Epoch 168/200, Iteration 109/250, Loss: 0.0235\n",
      "Epoch 168/200, Iteration 110/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 111/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 112/250, Loss: 0.0150\n",
      "Epoch 168/200, Iteration 113/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 114/250, Loss: 0.0288\n",
      "Epoch 168/200, Iteration 115/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 117/250, Loss: 0.0112\n",
      "Epoch 168/200, Iteration 118/250, Loss: 0.0111\n",
      "Epoch 168/200, Iteration 119/250, Loss: 0.0292\n",
      "Epoch 168/200, Iteration 120/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 121/250, Loss: 0.0099\n",
      "Epoch 168/200, Iteration 122/250, Loss: 0.0094\n",
      "Epoch 168/200, Iteration 123/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 168/200, Iteration 125/250, Loss: 0.0240\n",
      "Epoch 168/200, Iteration 126/250, Loss: 0.0227\n",
      "Epoch 168/200, Iteration 127/250, Loss: 0.0133\n",
      "Epoch 168/200, Iteration 128/250, Loss: 0.0135\n",
      "Epoch 168/200, Iteration 129/250, Loss: 0.0086\n",
      "Epoch 168/200, Iteration 130/250, Loss: 0.0078\n",
      "Epoch 168/200, Iteration 131/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 132/250, Loss: 0.0114\n",
      "Epoch 168/200, Iteration 133/250, Loss: 0.0283\n",
      "Epoch 168/200, Iteration 134/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 135/250, Loss: 0.0102\n",
      "Epoch 168/200, Iteration 136/250, Loss: 0.0178\n",
      "Epoch 168/200, Iteration 137/250, Loss: 0.0084\n",
      "Epoch 168/200, Iteration 138/250, Loss: 0.0377\n",
      "Epoch 168/200, Iteration 139/250, Loss: 0.0290\n",
      "Epoch 168/200, Iteration 140/250, Loss: 0.0253\n",
      "Epoch 168/200, Iteration 141/250, Loss: 0.0320\n",
      "Epoch 168/200, Iteration 142/250, Loss: 0.0100\n",
      "Epoch 168/200, Iteration 143/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 144/250, Loss: 0.0547\n",
      "Epoch 168/200, Iteration 145/250, Loss: 0.0104\n",
      "Epoch 168/200, Iteration 146/250, Loss: 0.0077\n",
      "Epoch 168/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 168/200, Iteration 148/250, Loss: 0.0350\n",
      "Epoch 168/200, Iteration 149/250, Loss: 0.0117\n",
      "Epoch 168/200, Iteration 150/250, Loss: 0.0089\n",
      "Epoch 168/200, Iteration 151/250, Loss: 0.0151\n",
      "Epoch 168/200, Iteration 152/250, Loss: 0.0113\n",
      "Epoch 168/200, Iteration 153/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 154/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 155/250, Loss: 0.0164\n",
      "Epoch 168/200, Iteration 156/250, Loss: 0.0097\n",
      "Epoch 168/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 168/200, Iteration 158/250, Loss: 0.0290\n",
      "Epoch 168/200, Iteration 159/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 160/250, Loss: 0.0145\n",
      "Epoch 168/200, Iteration 161/250, Loss: 0.0140\n",
      "Epoch 168/200, Iteration 162/250, Loss: 0.0246\n",
      "Epoch 168/200, Iteration 163/250, Loss: 0.0138\n",
      "Epoch 168/200, Iteration 164/250, Loss: 0.0105\n",
      "Epoch 168/200, Iteration 165/250, Loss: 0.0167\n",
      "Epoch 168/200, Iteration 166/250, Loss: 0.0180\n",
      "Epoch 168/200, Iteration 167/250, Loss: 0.0163\n",
      "Epoch 168/200, Iteration 168/250, Loss: 0.0183\n",
      "Epoch 168/200, Iteration 169/250, Loss: 0.0104\n",
      "Epoch 168/200, Iteration 170/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 171/250, Loss: 0.0081\n",
      "Epoch 168/200, Iteration 172/250, Loss: 0.0137\n",
      "Epoch 168/200, Iteration 173/250, Loss: 0.0440\n",
      "Epoch 168/200, Iteration 174/250, Loss: 0.0119\n",
      "Epoch 168/200, Iteration 175/250, Loss: 0.0174\n",
      "Epoch 168/200, Iteration 176/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 177/250, Loss: 0.0210\n",
      "Epoch 168/200, Iteration 178/250, Loss: 0.0128\n",
      "Epoch 168/200, Iteration 179/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 180/250, Loss: 0.0059\n",
      "Epoch 168/200, Iteration 181/250, Loss: 0.0141\n",
      "Epoch 168/200, Iteration 182/250, Loss: 0.0087\n",
      "Epoch 168/200, Iteration 183/250, Loss: 0.0089\n",
      "Epoch 168/200, Iteration 184/250, Loss: 0.0062\n",
      "Epoch 168/200, Iteration 185/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 186/250, Loss: 0.0143\n",
      "Epoch 168/200, Iteration 187/250, Loss: 0.0385\n",
      "Epoch 168/200, Iteration 188/250, Loss: 0.0109\n",
      "Epoch 168/200, Iteration 189/250, Loss: 0.0401\n",
      "Epoch 168/200, Iteration 190/250, Loss: 0.0110\n",
      "Epoch 168/200, Iteration 191/250, Loss: 0.0121\n",
      "Epoch 168/200, Iteration 192/250, Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200, Iteration 193/250, Loss: 0.0117\n",
      "Epoch 168/200, Iteration 194/250, Loss: 0.0163\n",
      "Epoch 168/200, Iteration 195/250, Loss: 0.0118\n",
      "Epoch 168/200, Iteration 196/250, Loss: 0.0115\n",
      "Epoch 168/200, Iteration 197/250, Loss: 0.0205\n",
      "Epoch 168/200, Iteration 198/250, Loss: 0.0191\n",
      "Epoch 168/200, Iteration 199/250, Loss: 0.0151\n",
      "Epoch 168/200, Iteration 200/250, Loss: 0.0126\n",
      "Epoch 168/200, Iteration 201/250, Loss: 0.0341\n",
      "Epoch 168/200, Iteration 202/250, Loss: 0.0227\n",
      "Epoch 168/200, Iteration 203/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 204/250, Loss: 0.0179\n",
      "Epoch 168/200, Iteration 205/250, Loss: 0.0093\n",
      "Epoch 168/200, Iteration 206/250, Loss: 0.0242\n",
      "Epoch 168/200, Iteration 207/250, Loss: 0.0338\n",
      "Epoch 168/200, Iteration 208/250, Loss: 0.0116\n",
      "Epoch 168/200, Iteration 209/250, Loss: 0.0112\n",
      "Epoch 168/200, Iteration 210/250, Loss: 0.0117\n",
      "Epoch 168/200, Iteration 211/250, Loss: 0.0076\n",
      "Epoch 168/200, Iteration 212/250, Loss: 0.0138\n",
      "Epoch 168/200, Iteration 213/250, Loss: 0.0290\n",
      "Epoch 168/200, Iteration 214/250, Loss: 0.0107\n",
      "Epoch 168/200, Iteration 215/250, Loss: 0.0106\n",
      "Epoch 168/200, Iteration 216/250, Loss: 0.0083\n",
      "Epoch 168/200, Iteration 217/250, Loss: 0.0178\n",
      "Epoch 168/200, Iteration 218/250, Loss: 0.0139\n",
      "Epoch 168/200, Iteration 219/250, Loss: 0.0229\n",
      "Epoch 168/200, Iteration 220/250, Loss: 0.0275\n",
      "Epoch 168/200, Iteration 221/250, Loss: 0.0137\n",
      "Epoch 168/200, Iteration 222/250, Loss: 0.0260\n",
      "Epoch 168/200, Iteration 223/250, Loss: 0.0295\n",
      "Epoch 168/200, Iteration 224/250, Loss: 0.0157\n",
      "Epoch 168/200, Iteration 225/250, Loss: 0.0119\n",
      "Epoch 168/200, Iteration 226/250, Loss: 0.0173\n",
      "Epoch 168/200, Iteration 227/250, Loss: 0.0252\n",
      "Epoch 168/200, Iteration 228/250, Loss: 0.0180\n",
      "Epoch 168/200, Iteration 229/250, Loss: 0.0185\n",
      "Epoch 168/200, Iteration 230/250, Loss: 0.0125\n",
      "Epoch 168/200, Iteration 231/250, Loss: 0.0106\n",
      "Epoch 168/200, Iteration 232/250, Loss: 0.0088\n",
      "Epoch 168/200, Iteration 233/250, Loss: 0.0103\n",
      "Epoch 168/200, Iteration 234/250, Loss: 0.0068\n",
      "Epoch 168/200, Iteration 235/250, Loss: 0.0124\n",
      "Epoch 168/200, Iteration 236/250, Loss: 0.0164\n",
      "Epoch 168/200, Iteration 237/250, Loss: 0.0165\n",
      "Epoch 168/200, Iteration 238/250, Loss: 0.0090\n",
      "Epoch 168/200, Iteration 239/250, Loss: 0.0107\n",
      "Epoch 168/200, Iteration 240/250, Loss: 0.0095\n",
      "Epoch 168/200, Iteration 241/250, Loss: 0.0150\n",
      "Epoch 168/200, Iteration 242/250, Loss: 0.0294\n",
      "Epoch 168/200, Iteration 243/250, Loss: 0.0104\n",
      "Epoch 168/200, Iteration 244/250, Loss: 0.0131\n",
      "Epoch 168/200, Iteration 245/250, Loss: 0.0114\n",
      "Epoch 168/200, Iteration 246/250, Loss: 0.0119\n",
      "Epoch 168/200, Iteration 247/250, Loss: 0.0111\n",
      "Epoch 168/200, Iteration 248/250, Loss: 0.0081\n",
      "Epoch 168/200, Iteration 249/250, Loss: 0.0123\n",
      "Epoch 168/200, Iteration 250/250, Loss: 0.0094\n",
      "Train Error: \n",
      " Accuracy: 81.04%, Avg loss: 0.007225, MRE: 0.450014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.007639, MRE: 0.498796 \n",
      "\n",
      "Epoch 169/200, Iteration 1/250, Loss: 0.0208\n",
      "Epoch 169/200, Iteration 2/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 3/250, Loss: 0.0082\n",
      "Epoch 169/200, Iteration 4/250, Loss: 0.0128\n",
      "Epoch 169/200, Iteration 5/250, Loss: 0.0160\n",
      "Epoch 169/200, Iteration 6/250, Loss: 0.0235\n",
      "Epoch 169/200, Iteration 7/250, Loss: 0.0143\n",
      "Epoch 169/200, Iteration 8/250, Loss: 0.0102\n",
      "Epoch 169/200, Iteration 9/250, Loss: 0.0127\n",
      "Epoch 169/200, Iteration 10/250, Loss: 0.0148\n",
      "Epoch 169/200, Iteration 11/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 12/250, Loss: 0.0072\n",
      "Epoch 169/200, Iteration 13/250, Loss: 0.0211\n",
      "Epoch 169/200, Iteration 14/250, Loss: 0.0075\n",
      "Epoch 169/200, Iteration 15/250, Loss: 0.0154\n",
      "Epoch 169/200, Iteration 16/250, Loss: 0.0080\n",
      "Epoch 169/200, Iteration 17/250, Loss: 0.0361\n",
      "Epoch 169/200, Iteration 18/250, Loss: 0.0136\n",
      "Epoch 169/200, Iteration 19/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 20/250, Loss: 0.0177\n",
      "Epoch 169/200, Iteration 21/250, Loss: 0.0248\n",
      "Epoch 169/200, Iteration 22/250, Loss: 0.0079\n",
      "Epoch 169/200, Iteration 23/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 24/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 25/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 26/250, Loss: 0.0125\n",
      "Epoch 169/200, Iteration 27/250, Loss: 0.0181\n",
      "Epoch 169/200, Iteration 28/250, Loss: 0.0061\n",
      "Epoch 169/200, Iteration 29/250, Loss: 0.0411\n",
      "Epoch 169/200, Iteration 30/250, Loss: 0.0470\n",
      "Epoch 169/200, Iteration 31/250, Loss: 0.0323\n",
      "Epoch 169/200, Iteration 32/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 33/250, Loss: 0.0146\n",
      "Epoch 169/200, Iteration 34/250, Loss: 0.0141\n",
      "Epoch 169/200, Iteration 35/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 36/250, Loss: 0.0068\n",
      "Epoch 169/200, Iteration 37/250, Loss: 0.0393\n",
      "Epoch 169/200, Iteration 38/250, Loss: 0.0145\n",
      "Epoch 169/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 169/200, Iteration 40/250, Loss: 0.0147\n",
      "Epoch 169/200, Iteration 41/250, Loss: 0.0156\n",
      "Epoch 169/200, Iteration 42/250, Loss: 0.0070\n",
      "Epoch 169/200, Iteration 43/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 44/250, Loss: 0.0077\n",
      "Epoch 169/200, Iteration 45/250, Loss: 0.0184\n",
      "Epoch 169/200, Iteration 46/250, Loss: 0.0127\n",
      "Epoch 169/200, Iteration 47/250, Loss: 0.0157\n",
      "Epoch 169/200, Iteration 48/250, Loss: 0.0097\n",
      "Epoch 169/200, Iteration 49/250, Loss: 0.0174\n",
      "Epoch 169/200, Iteration 50/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 51/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 52/250, Loss: 0.0100\n",
      "Epoch 169/200, Iteration 53/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 54/250, Loss: 0.0135\n",
      "Epoch 169/200, Iteration 55/250, Loss: 0.0095\n",
      "Epoch 169/200, Iteration 56/250, Loss: 0.0147\n",
      "Epoch 169/200, Iteration 57/250, Loss: 0.0110\n",
      "Epoch 169/200, Iteration 58/250, Loss: 0.0082\n",
      "Epoch 169/200, Iteration 59/250, Loss: 0.0133\n",
      "Epoch 169/200, Iteration 60/250, Loss: 0.0116\n",
      "Epoch 169/200, Iteration 61/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 62/250, Loss: 0.0256\n",
      "Epoch 169/200, Iteration 63/250, Loss: 0.0090\n",
      "Epoch 169/200, Iteration 64/250, Loss: 0.0141\n",
      "Epoch 169/200, Iteration 65/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 66/250, Loss: 0.0126\n",
      "Epoch 169/200, Iteration 67/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 68/250, Loss: 0.0170\n",
      "Epoch 169/200, Iteration 69/250, Loss: 0.0073\n",
      "Epoch 169/200, Iteration 70/250, Loss: 0.0270\n",
      "Epoch 169/200, Iteration 71/250, Loss: 0.0213\n",
      "Epoch 169/200, Iteration 72/250, Loss: 0.0142\n",
      "Epoch 169/200, Iteration 73/250, Loss: 0.0153\n",
      "Epoch 169/200, Iteration 74/250, Loss: 0.0131\n",
      "Epoch 169/200, Iteration 75/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 76/250, Loss: 0.0253\n",
      "Epoch 169/200, Iteration 77/250, Loss: 0.0438\n",
      "Epoch 169/200, Iteration 78/250, Loss: 0.0101\n",
      "Epoch 169/200, Iteration 79/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 80/250, Loss: 0.0067\n",
      "Epoch 169/200, Iteration 81/250, Loss: 0.0185\n",
      "Epoch 169/200, Iteration 82/250, Loss: 0.0094\n",
      "Epoch 169/200, Iteration 83/250, Loss: 0.0108\n",
      "Epoch 169/200, Iteration 84/250, Loss: 0.0302\n",
      "Epoch 169/200, Iteration 85/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 86/250, Loss: 0.0324\n",
      "Epoch 169/200, Iteration 87/250, Loss: 0.0166\n",
      "Epoch 169/200, Iteration 88/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 89/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 90/250, Loss: 0.0205\n",
      "Epoch 169/200, Iteration 91/250, Loss: 0.0112\n",
      "Epoch 169/200, Iteration 92/250, Loss: 0.0182\n",
      "Epoch 169/200, Iteration 93/250, Loss: 0.0098\n",
      "Epoch 169/200, Iteration 94/250, Loss: 0.0096\n",
      "Epoch 169/200, Iteration 95/250, Loss: 0.0138\n",
      "Epoch 169/200, Iteration 96/250, Loss: 0.0243\n",
      "Epoch 169/200, Iteration 97/250, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 98/250, Loss: 0.0200\n",
      "Epoch 169/200, Iteration 99/250, Loss: 0.0165\n",
      "Epoch 169/200, Iteration 100/250, Loss: 0.0222\n",
      "Epoch 169/200, Iteration 101/250, Loss: 0.0128\n",
      "Epoch 169/200, Iteration 102/250, Loss: 0.0277\n",
      "Epoch 169/200, Iteration 103/250, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 104/250, Loss: 0.0162\n",
      "Epoch 169/200, Iteration 105/250, Loss: 0.0138\n",
      "Epoch 169/200, Iteration 106/250, Loss: 0.0147\n",
      "Epoch 169/200, Iteration 107/250, Loss: 0.0129\n",
      "Epoch 169/200, Iteration 108/250, Loss: 0.0134\n",
      "Epoch 169/200, Iteration 109/250, Loss: 0.0118\n",
      "Epoch 169/200, Iteration 110/250, Loss: 0.0106\n",
      "Epoch 169/200, Iteration 111/250, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 112/250, Loss: 0.0180\n",
      "Epoch 169/200, Iteration 113/250, Loss: 0.0216\n",
      "Epoch 169/200, Iteration 114/250, Loss: 0.0319\n",
      "Epoch 169/200, Iteration 115/250, Loss: 0.0080\n",
      "Epoch 169/200, Iteration 116/250, Loss: 0.0165\n",
      "Epoch 169/200, Iteration 117/250, Loss: 0.0129\n",
      "Epoch 169/200, Iteration 118/250, Loss: 0.0164\n",
      "Epoch 169/200, Iteration 119/250, Loss: 0.0237\n",
      "Epoch 169/200, Iteration 120/250, Loss: 0.0167\n",
      "Epoch 169/200, Iteration 121/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 122/250, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200, Iteration 123/250, Loss: 0.0143\n",
      "Epoch 169/200, Iteration 124/250, Loss: 0.0182\n",
      "Epoch 169/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 169/200, Iteration 126/250, Loss: 0.0152\n",
      "Epoch 169/200, Iteration 127/250, Loss: 0.0189\n",
      "Epoch 169/200, Iteration 128/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 129/250, Loss: 0.0113\n",
      "Epoch 169/200, Iteration 130/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 131/250, Loss: 0.0224\n",
      "Epoch 169/200, Iteration 132/250, Loss: 0.0256\n",
      "Epoch 169/200, Iteration 133/250, Loss: 0.0077\n",
      "Epoch 169/200, Iteration 134/250, Loss: 0.0084\n",
      "Epoch 169/200, Iteration 135/250, Loss: 0.0186\n",
      "Epoch 169/200, Iteration 136/250, Loss: 0.0173\n",
      "Epoch 169/200, Iteration 137/250, Loss: 0.0363\n",
      "Epoch 169/200, Iteration 138/250, Loss: 0.0215\n",
      "Epoch 169/200, Iteration 139/250, Loss: 0.0203\n",
      "Epoch 169/200, Iteration 140/250, Loss: 0.0104\n",
      "Epoch 169/200, Iteration 141/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 142/250, Loss: 0.0112\n",
      "Epoch 169/200, Iteration 143/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 169/200, Iteration 145/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 146/250, Loss: 0.0102\n",
      "Epoch 169/200, Iteration 147/250, Loss: 0.0127\n",
      "Epoch 169/200, Iteration 148/250, Loss: 0.0169\n",
      "Epoch 169/200, Iteration 149/250, Loss: 0.0238\n",
      "Epoch 169/200, Iteration 150/250, Loss: 0.0169\n",
      "Epoch 169/200, Iteration 151/250, Loss: 0.0075\n",
      "Epoch 169/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 169/200, Iteration 153/250, Loss: 0.0096\n",
      "Epoch 169/200, Iteration 154/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 155/250, Loss: 0.0185\n",
      "Epoch 169/200, Iteration 156/250, Loss: 0.0196\n",
      "Epoch 169/200, Iteration 157/250, Loss: 0.0142\n",
      "Epoch 169/200, Iteration 158/250, Loss: 0.0437\n",
      "Epoch 169/200, Iteration 159/250, Loss: 0.0101\n",
      "Epoch 169/200, Iteration 160/250, Loss: 0.0160\n",
      "Epoch 169/200, Iteration 161/250, Loss: 0.0104\n",
      "Epoch 169/200, Iteration 162/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 163/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 164/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 166/250, Loss: 0.0265\n",
      "Epoch 169/200, Iteration 167/250, Loss: 0.0139\n",
      "Epoch 169/200, Iteration 168/250, Loss: 0.0132\n",
      "Epoch 169/200, Iteration 169/250, Loss: 0.0200\n",
      "Epoch 169/200, Iteration 170/250, Loss: 0.0118\n",
      "Epoch 169/200, Iteration 171/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 169/200, Iteration 173/250, Loss: 0.0091\n",
      "Epoch 169/200, Iteration 174/250, Loss: 0.0203\n",
      "Epoch 169/200, Iteration 175/250, Loss: 0.0115\n",
      "Epoch 169/200, Iteration 176/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 177/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 178/250, Loss: 0.0124\n",
      "Epoch 169/200, Iteration 179/250, Loss: 0.0485\n",
      "Epoch 169/200, Iteration 180/250, Loss: 0.0109\n",
      "Epoch 169/200, Iteration 181/250, Loss: 0.0159\n",
      "Epoch 169/200, Iteration 182/250, Loss: 0.0245\n",
      "Epoch 169/200, Iteration 183/250, Loss: 0.0177\n",
      "Epoch 169/200, Iteration 184/250, Loss: 0.0215\n",
      "Epoch 169/200, Iteration 185/250, Loss: 0.0169\n",
      "Epoch 169/200, Iteration 186/250, Loss: 0.0099\n",
      "Epoch 169/200, Iteration 187/250, Loss: 0.0158\n",
      "Epoch 169/200, Iteration 188/250, Loss: 0.0184\n",
      "Epoch 169/200, Iteration 189/250, Loss: 0.0086\n",
      "Epoch 169/200, Iteration 190/250, Loss: 0.0084\n",
      "Epoch 169/200, Iteration 191/250, Loss: 0.0206\n",
      "Epoch 169/200, Iteration 192/250, Loss: 0.0138\n",
      "Epoch 169/200, Iteration 193/250, Loss: 0.0163\n",
      "Epoch 169/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 195/250, Loss: 0.0087\n",
      "Epoch 169/200, Iteration 196/250, Loss: 0.0093\n",
      "Epoch 169/200, Iteration 197/250, Loss: 0.0084\n",
      "Epoch 169/200, Iteration 198/250, Loss: 0.0085\n",
      "Epoch 169/200, Iteration 199/250, Loss: 0.0161\n",
      "Epoch 169/200, Iteration 200/250, Loss: 0.0212\n",
      "Epoch 169/200, Iteration 201/250, Loss: 0.0151\n",
      "Epoch 169/200, Iteration 202/250, Loss: 0.0130\n",
      "Epoch 169/200, Iteration 203/250, Loss: 0.0107\n",
      "Epoch 169/200, Iteration 204/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 205/250, Loss: 0.0071\n",
      "Epoch 169/200, Iteration 206/250, Loss: 0.0165\n",
      "Epoch 169/200, Iteration 207/250, Loss: 0.0081\n",
      "Epoch 169/200, Iteration 208/250, Loss: 0.0137\n",
      "Epoch 169/200, Iteration 209/250, Loss: 0.0097\n",
      "Epoch 169/200, Iteration 210/250, Loss: 0.0119\n",
      "Epoch 169/200, Iteration 211/250, Loss: 0.0097\n",
      "Epoch 169/200, Iteration 212/250, Loss: 0.0363\n",
      "Epoch 169/200, Iteration 213/250, Loss: 0.0210\n",
      "Epoch 169/200, Iteration 214/250, Loss: 0.0120\n",
      "Epoch 169/200, Iteration 215/250, Loss: 0.0201\n",
      "Epoch 169/200, Iteration 216/250, Loss: 0.0236\n",
      "Epoch 169/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 218/250, Loss: 0.0151\n",
      "Epoch 169/200, Iteration 219/250, Loss: 0.0207\n",
      "Epoch 169/200, Iteration 220/250, Loss: 0.0105\n",
      "Epoch 169/200, Iteration 221/250, Loss: 0.0226\n",
      "Epoch 169/200, Iteration 222/250, Loss: 0.0095\n",
      "Epoch 169/200, Iteration 223/250, Loss: 0.0251\n",
      "Epoch 169/200, Iteration 224/250, Loss: 0.0072\n",
      "Epoch 169/200, Iteration 225/250, Loss: 0.0225\n",
      "Epoch 169/200, Iteration 226/250, Loss: 0.0244\n",
      "Epoch 169/200, Iteration 227/250, Loss: 0.0326\n",
      "Epoch 169/200, Iteration 228/250, Loss: 0.0137\n",
      "Epoch 169/200, Iteration 229/250, Loss: 0.0219\n",
      "Epoch 169/200, Iteration 230/250, Loss: 0.0228\n",
      "Epoch 169/200, Iteration 231/250, Loss: 0.0155\n",
      "Epoch 169/200, Iteration 232/250, Loss: 0.0132\n",
      "Epoch 169/200, Iteration 233/250, Loss: 0.0160\n",
      "Epoch 169/200, Iteration 234/250, Loss: 0.0171\n",
      "Epoch 169/200, Iteration 235/250, Loss: 0.0089\n",
      "Epoch 169/200, Iteration 236/250, Loss: 0.0367\n",
      "Epoch 169/200, Iteration 237/250, Loss: 0.0143\n",
      "Epoch 169/200, Iteration 238/250, Loss: 0.0123\n",
      "Epoch 169/200, Iteration 239/250, Loss: 0.0115\n",
      "Epoch 169/200, Iteration 240/250, Loss: 0.0152\n",
      "Epoch 169/200, Iteration 241/250, Loss: 0.0111\n",
      "Epoch 169/200, Iteration 242/250, Loss: 0.0192\n",
      "Epoch 169/200, Iteration 243/250, Loss: 0.0145\n",
      "Epoch 169/200, Iteration 244/250, Loss: 0.0132\n",
      "Epoch 169/200, Iteration 245/250, Loss: 0.0184\n",
      "Epoch 169/200, Iteration 246/250, Loss: 0.0103\n",
      "Epoch 169/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 169/200, Iteration 248/250, Loss: 0.0218\n",
      "Epoch 169/200, Iteration 249/250, Loss: 0.0247\n",
      "Epoch 169/200, Iteration 250/250, Loss: 0.0183\n",
      "Train Error: \n",
      " Accuracy: 86.56%, Avg loss: 0.006870, MRE: 0.438920 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.007426, MRE: 0.527709 \n",
      "\n",
      "Epoch 170/200, Iteration 1/250, Loss: 0.0166\n",
      "Epoch 170/200, Iteration 2/250, Loss: 0.0126\n",
      "Epoch 170/200, Iteration 3/250, Loss: 0.0253\n",
      "Epoch 170/200, Iteration 4/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 5/250, Loss: 0.0115\n",
      "Epoch 170/200, Iteration 6/250, Loss: 0.0219\n",
      "Epoch 170/200, Iteration 7/250, Loss: 0.0193\n",
      "Epoch 170/200, Iteration 8/250, Loss: 0.0245\n",
      "Epoch 170/200, Iteration 9/250, Loss: 0.0289\n",
      "Epoch 170/200, Iteration 10/250, Loss: 0.0098\n",
      "Epoch 170/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 12/250, Loss: 0.0097\n",
      "Epoch 170/200, Iteration 13/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 14/250, Loss: 0.0424\n",
      "Epoch 170/200, Iteration 15/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 16/250, Loss: 0.0090\n",
      "Epoch 170/200, Iteration 17/250, Loss: 0.0120\n",
      "Epoch 170/200, Iteration 18/250, Loss: 0.0132\n",
      "Epoch 170/200, Iteration 19/250, Loss: 0.0135\n",
      "Epoch 170/200, Iteration 20/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 21/250, Loss: 0.0090\n",
      "Epoch 170/200, Iteration 22/250, Loss: 0.0129\n",
      "Epoch 170/200, Iteration 23/250, Loss: 0.0081\n",
      "Epoch 170/200, Iteration 24/250, Loss: 0.0146\n",
      "Epoch 170/200, Iteration 25/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 26/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 27/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 28/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 29/250, Loss: 0.0225\n",
      "Epoch 170/200, Iteration 30/250, Loss: 0.0162\n",
      "Epoch 170/200, Iteration 31/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 32/250, Loss: 0.0109\n",
      "Epoch 170/200, Iteration 33/250, Loss: 0.0227\n",
      "Epoch 170/200, Iteration 34/250, Loss: 0.0180\n",
      "Epoch 170/200, Iteration 35/250, Loss: 0.0101\n",
      "Epoch 170/200, Iteration 36/250, Loss: 0.0080\n",
      "Epoch 170/200, Iteration 37/250, Loss: 0.0341\n",
      "Epoch 170/200, Iteration 38/250, Loss: 0.0189\n",
      "Epoch 170/200, Iteration 39/250, Loss: 0.0252\n",
      "Epoch 170/200, Iteration 40/250, Loss: 0.0084\n",
      "Epoch 170/200, Iteration 41/250, Loss: 0.0144\n",
      "Epoch 170/200, Iteration 42/250, Loss: 0.0151\n",
      "Epoch 170/200, Iteration 43/250, Loss: 0.0104\n",
      "Epoch 170/200, Iteration 44/250, Loss: 0.0386\n",
      "Epoch 170/200, Iteration 45/250, Loss: 0.0258\n",
      "Epoch 170/200, Iteration 46/250, Loss: 0.0163\n",
      "Epoch 170/200, Iteration 47/250, Loss: 0.0120\n",
      "Epoch 170/200, Iteration 48/250, Loss: 0.0068\n",
      "Epoch 170/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 50/250, Loss: 0.0077\n",
      "Epoch 170/200, Iteration 51/250, Loss: 0.0230\n",
      "Epoch 170/200, Iteration 52/250, Loss: 0.0127\n",
      "Epoch 170/200, Iteration 53/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 54/250, Loss: 0.0245\n",
      "Epoch 170/200, Iteration 55/250, Loss: 0.0148\n",
      "Epoch 170/200, Iteration 56/250, Loss: 0.0150\n",
      "Epoch 170/200, Iteration 57/250, Loss: 0.0119\n",
      "Epoch 170/200, Iteration 58/250, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 59/250, Loss: 0.0167\n",
      "Epoch 170/200, Iteration 60/250, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 61/250, Loss: 0.0198\n",
      "Epoch 170/200, Iteration 62/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 63/250, Loss: 0.0110\n",
      "Epoch 170/200, Iteration 64/250, Loss: 0.0192\n",
      "Epoch 170/200, Iteration 65/250, Loss: 0.0199\n",
      "Epoch 170/200, Iteration 66/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 67/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 68/250, Loss: 0.0135\n",
      "Epoch 170/200, Iteration 69/250, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 70/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 71/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 72/250, Loss: 0.0217\n",
      "Epoch 170/200, Iteration 73/250, Loss: 0.0088\n",
      "Epoch 170/200, Iteration 74/250, Loss: 0.0141\n",
      "Epoch 170/200, Iteration 75/250, Loss: 0.0099\n",
      "Epoch 170/200, Iteration 76/250, Loss: 0.0116\n",
      "Epoch 170/200, Iteration 77/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 78/250, Loss: 0.0110\n",
      "Epoch 170/200, Iteration 79/250, Loss: 0.0131\n",
      "Epoch 170/200, Iteration 80/250, Loss: 0.0124\n",
      "Epoch 170/200, Iteration 81/250, Loss: 0.0136\n",
      "Epoch 170/200, Iteration 82/250, Loss: 0.0074\n",
      "Epoch 170/200, Iteration 83/250, Loss: 0.0185\n",
      "Epoch 170/200, Iteration 84/250, Loss: 0.0141\n",
      "Epoch 170/200, Iteration 85/250, Loss: 0.0125\n",
      "Epoch 170/200, Iteration 86/250, Loss: 0.0284\n",
      "Epoch 170/200, Iteration 87/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 88/250, Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200, Iteration 89/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 90/250, Loss: 0.0126\n",
      "Epoch 170/200, Iteration 91/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 92/250, Loss: 0.0119\n",
      "Epoch 170/200, Iteration 93/250, Loss: 0.0163\n",
      "Epoch 170/200, Iteration 94/250, Loss: 0.0059\n",
      "Epoch 170/200, Iteration 95/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 96/250, Loss: 0.0154\n",
      "Epoch 170/200, Iteration 97/250, Loss: 0.0157\n",
      "Epoch 170/200, Iteration 98/250, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 99/250, Loss: 0.0185\n",
      "Epoch 170/200, Iteration 100/250, Loss: 0.0081\n",
      "Epoch 170/200, Iteration 101/250, Loss: 0.0076\n",
      "Epoch 170/200, Iteration 102/250, Loss: 0.0224\n",
      "Epoch 170/200, Iteration 103/250, Loss: 0.0145\n",
      "Epoch 170/200, Iteration 104/250, Loss: 0.0390\n",
      "Epoch 170/200, Iteration 105/250, Loss: 0.0348\n",
      "Epoch 170/200, Iteration 106/250, Loss: 0.0110\n",
      "Epoch 170/200, Iteration 107/250, Loss: 0.0169\n",
      "Epoch 170/200, Iteration 108/250, Loss: 0.0095\n",
      "Epoch 170/200, Iteration 109/250, Loss: 0.0082\n",
      "Epoch 170/200, Iteration 110/250, Loss: 0.0122\n",
      "Epoch 170/200, Iteration 111/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 112/250, Loss: 0.0102\n",
      "Epoch 170/200, Iteration 113/250, Loss: 0.0191\n",
      "Epoch 170/200, Iteration 114/250, Loss: 0.0115\n",
      "Epoch 170/200, Iteration 115/250, Loss: 0.0402\n",
      "Epoch 170/200, Iteration 116/250, Loss: 0.0201\n",
      "Epoch 170/200, Iteration 117/250, Loss: 0.0078\n",
      "Epoch 170/200, Iteration 118/250, Loss: 0.0078\n",
      "Epoch 170/200, Iteration 119/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 120/250, Loss: 0.0177\n",
      "Epoch 170/200, Iteration 121/250, Loss: 0.0085\n",
      "Epoch 170/200, Iteration 122/250, Loss: 0.0146\n",
      "Epoch 170/200, Iteration 123/250, Loss: 0.0114\n",
      "Epoch 170/200, Iteration 124/250, Loss: 0.0135\n",
      "Epoch 170/200, Iteration 125/250, Loss: 0.0364\n",
      "Epoch 170/200, Iteration 126/250, Loss: 0.0087\n",
      "Epoch 170/200, Iteration 127/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 128/250, Loss: 0.0091\n",
      "Epoch 170/200, Iteration 129/250, Loss: 0.0150\n",
      "Epoch 170/200, Iteration 130/250, Loss: 0.0190\n",
      "Epoch 170/200, Iteration 131/250, Loss: 0.0163\n",
      "Epoch 170/200, Iteration 132/250, Loss: 0.0159\n",
      "Epoch 170/200, Iteration 133/250, Loss: 0.0067\n",
      "Epoch 170/200, Iteration 134/250, Loss: 0.0071\n",
      "Epoch 170/200, Iteration 135/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 136/250, Loss: 0.0174\n",
      "Epoch 170/200, Iteration 137/250, Loss: 0.0083\n",
      "Epoch 170/200, Iteration 138/250, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 139/250, Loss: 0.0108\n",
      "Epoch 170/200, Iteration 140/250, Loss: 0.0094\n",
      "Epoch 170/200, Iteration 141/250, Loss: 0.0204\n",
      "Epoch 170/200, Iteration 142/250, Loss: 0.0204\n",
      "Epoch 170/200, Iteration 143/250, Loss: 0.0128\n",
      "Epoch 170/200, Iteration 144/250, Loss: 0.0118\n",
      "Epoch 170/200, Iteration 145/250, Loss: 0.0106\n",
      "Epoch 170/200, Iteration 146/250, Loss: 0.0168\n",
      "Epoch 170/200, Iteration 147/250, Loss: 0.0159\n",
      "Epoch 170/200, Iteration 148/250, Loss: 0.0156\n",
      "Epoch 170/200, Iteration 149/250, Loss: 0.0061\n",
      "Epoch 170/200, Iteration 150/250, Loss: 0.0139\n",
      "Epoch 170/200, Iteration 151/250, Loss: 0.0263\n",
      "Epoch 170/200, Iteration 152/250, Loss: 0.0089\n",
      "Epoch 170/200, Iteration 153/250, Loss: 0.0131\n",
      "Epoch 170/200, Iteration 154/250, Loss: 0.0199\n",
      "Epoch 170/200, Iteration 155/250, Loss: 0.0175\n",
      "Epoch 170/200, Iteration 156/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 157/250, Loss: 0.0112\n",
      "Epoch 170/200, Iteration 158/250, Loss: 0.0075\n",
      "Epoch 170/200, Iteration 159/250, Loss: 0.0133\n",
      "Epoch 170/200, Iteration 160/250, Loss: 0.0183\n",
      "Epoch 170/200, Iteration 161/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 162/250, Loss: 0.0165\n",
      "Epoch 170/200, Iteration 163/250, Loss: 0.0209\n",
      "Epoch 170/200, Iteration 164/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 165/250, Loss: 0.0189\n",
      "Epoch 170/200, Iteration 166/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 167/250, Loss: 0.0275\n",
      "Epoch 170/200, Iteration 168/250, Loss: 0.0129\n",
      "Epoch 170/200, Iteration 169/250, Loss: 0.0262\n",
      "Epoch 170/200, Iteration 170/250, Loss: 0.0149\n",
      "Epoch 170/200, Iteration 171/250, Loss: 0.0078\n",
      "Epoch 170/200, Iteration 172/250, Loss: 0.0106\n",
      "Epoch 170/200, Iteration 173/250, Loss: 0.0180\n",
      "Epoch 170/200, Iteration 174/250, Loss: 0.0127\n",
      "Epoch 170/200, Iteration 175/250, Loss: 0.0240\n",
      "Epoch 170/200, Iteration 176/250, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 177/250, Loss: 0.0176\n",
      "Epoch 170/200, Iteration 178/250, Loss: 0.0085\n",
      "Epoch 170/200, Iteration 179/250, Loss: 0.0128\n",
      "Epoch 170/200, Iteration 180/250, Loss: 0.0082\n",
      "Epoch 170/200, Iteration 181/250, Loss: 0.0267\n",
      "Epoch 170/200, Iteration 182/250, Loss: 0.0207\n",
      "Epoch 170/200, Iteration 183/250, Loss: 0.0106\n",
      "Epoch 170/200, Iteration 184/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 185/250, Loss: 0.0140\n",
      "Epoch 170/200, Iteration 186/250, Loss: 0.0306\n",
      "Epoch 170/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 188/250, Loss: 0.0139\n",
      "Epoch 170/200, Iteration 189/250, Loss: 0.0082\n",
      "Epoch 170/200, Iteration 190/250, Loss: 0.0177\n",
      "Epoch 170/200, Iteration 191/250, Loss: 0.0184\n",
      "Epoch 170/200, Iteration 192/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 193/250, Loss: 0.0121\n",
      "Epoch 170/200, Iteration 194/250, Loss: 0.0154\n",
      "Epoch 170/200, Iteration 195/250, Loss: 0.0271\n",
      "Epoch 170/200, Iteration 196/250, Loss: 0.0261\n",
      "Epoch 170/200, Iteration 197/250, Loss: 0.0120\n",
      "Epoch 170/200, Iteration 198/250, Loss: 0.0161\n",
      "Epoch 170/200, Iteration 199/250, Loss: 0.0115\n",
      "Epoch 170/200, Iteration 200/250, Loss: 0.0069\n",
      "Epoch 170/200, Iteration 201/250, Loss: 0.0313\n",
      "Epoch 170/200, Iteration 202/250, Loss: 0.0100\n",
      "Epoch 170/200, Iteration 203/250, Loss: 0.0187\n",
      "Epoch 170/200, Iteration 204/250, Loss: 0.0192\n",
      "Epoch 170/200, Iteration 205/250, Loss: 0.0141\n",
      "Epoch 170/200, Iteration 206/250, Loss: 0.0133\n",
      "Epoch 170/200, Iteration 207/250, Loss: 0.0181\n",
      "Epoch 170/200, Iteration 208/250, Loss: 0.0131\n",
      "Epoch 170/200, Iteration 209/250, Loss: 0.0143\n",
      "Epoch 170/200, Iteration 210/250, Loss: 0.0152\n",
      "Epoch 170/200, Iteration 211/250, Loss: 0.0212\n",
      "Epoch 170/200, Iteration 212/250, Loss: 0.0079\n",
      "Epoch 170/200, Iteration 213/250, Loss: 0.0107\n",
      "Epoch 170/200, Iteration 214/250, Loss: 0.0291\n",
      "Epoch 170/200, Iteration 215/250, Loss: 0.0289\n",
      "Epoch 170/200, Iteration 216/250, Loss: 0.0104\n",
      "Epoch 170/200, Iteration 217/250, Loss: 0.0163\n",
      "Epoch 170/200, Iteration 218/250, Loss: 0.0138\n",
      "Epoch 170/200, Iteration 219/250, Loss: 0.0172\n",
      "Epoch 170/200, Iteration 220/250, Loss: 0.0074\n",
      "Epoch 170/200, Iteration 221/250, Loss: 0.0154\n",
      "Epoch 170/200, Iteration 222/250, Loss: 0.0296\n",
      "Epoch 170/200, Iteration 223/250, Loss: 0.0284\n",
      "Epoch 170/200, Iteration 224/250, Loss: 0.0280\n",
      "Epoch 170/200, Iteration 225/250, Loss: 0.0189\n",
      "Epoch 170/200, Iteration 226/250, Loss: 0.0284\n",
      "Epoch 170/200, Iteration 227/250, Loss: 0.0105\n",
      "Epoch 170/200, Iteration 228/250, Loss: 0.0147\n",
      "Epoch 170/200, Iteration 229/250, Loss: 0.0157\n",
      "Epoch 170/200, Iteration 230/250, Loss: 0.0178\n",
      "Epoch 170/200, Iteration 231/250, Loss: 0.0175\n",
      "Epoch 170/200, Iteration 232/250, Loss: 0.0062\n",
      "Epoch 170/200, Iteration 233/250, Loss: 0.0113\n",
      "Epoch 170/200, Iteration 234/250, Loss: 0.0251\n",
      "Epoch 170/200, Iteration 235/250, Loss: 0.0111\n",
      "Epoch 170/200, Iteration 236/250, Loss: 0.0243\n",
      "Epoch 170/200, Iteration 237/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 238/250, Loss: 0.0126\n",
      "Epoch 170/200, Iteration 239/250, Loss: 0.0147\n",
      "Epoch 170/200, Iteration 240/250, Loss: 0.0213\n",
      "Epoch 170/200, Iteration 241/250, Loss: 0.0129\n",
      "Epoch 170/200, Iteration 242/250, Loss: 0.0132\n",
      "Epoch 170/200, Iteration 243/250, Loss: 0.0221\n",
      "Epoch 170/200, Iteration 244/250, Loss: 0.0160\n",
      "Epoch 170/200, Iteration 245/250, Loss: 0.0137\n",
      "Epoch 170/200, Iteration 246/250, Loss: 0.0224\n",
      "Epoch 170/200, Iteration 247/250, Loss: 0.0158\n",
      "Epoch 170/200, Iteration 248/250, Loss: 0.0149\n",
      "Epoch 170/200, Iteration 249/250, Loss: 0.0184\n",
      "Epoch 170/200, Iteration 250/250, Loss: 0.0070\n",
      "Train Error: \n",
      " Accuracy: 79.35%, Avg loss: 0.007278, MRE: 0.518600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.007711, MRE: 0.610187 \n",
      "\n",
      "Epoch 171/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 171/200, Iteration 2/250, Loss: 0.0327\n",
      "Epoch 171/200, Iteration 3/250, Loss: 0.0096\n",
      "Epoch 171/200, Iteration 4/250, Loss: 0.0322\n",
      "Epoch 171/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 6/250, Loss: 0.0221\n",
      "Epoch 171/200, Iteration 7/250, Loss: 0.0272\n",
      "Epoch 171/200, Iteration 8/250, Loss: 0.0185\n",
      "Epoch 171/200, Iteration 9/250, Loss: 0.0167\n",
      "Epoch 171/200, Iteration 10/250, Loss: 0.0058\n",
      "Epoch 171/200, Iteration 11/250, Loss: 0.0152\n",
      "Epoch 171/200, Iteration 12/250, Loss: 0.0124\n",
      "Epoch 171/200, Iteration 13/250, Loss: 0.0096\n",
      "Epoch 171/200, Iteration 14/250, Loss: 0.0248\n",
      "Epoch 171/200, Iteration 15/250, Loss: 0.0109\n",
      "Epoch 171/200, Iteration 16/250, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200, Iteration 17/250, Loss: 0.0069\n",
      "Epoch 171/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 171/200, Iteration 19/250, Loss: 0.0089\n",
      "Epoch 171/200, Iteration 20/250, Loss: 0.0115\n",
      "Epoch 171/200, Iteration 21/250, Loss: 0.0311\n",
      "Epoch 171/200, Iteration 22/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 23/250, Loss: 0.0107\n",
      "Epoch 171/200, Iteration 24/250, Loss: 0.0177\n",
      "Epoch 171/200, Iteration 25/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 26/250, Loss: 0.0108\n",
      "Epoch 171/200, Iteration 27/250, Loss: 0.0140\n",
      "Epoch 171/200, Iteration 28/250, Loss: 0.0077\n",
      "Epoch 171/200, Iteration 29/250, Loss: 0.0247\n",
      "Epoch 171/200, Iteration 30/250, Loss: 0.0068\n",
      "Epoch 171/200, Iteration 31/250, Loss: 0.0137\n",
      "Epoch 171/200, Iteration 32/250, Loss: 0.0200\n",
      "Epoch 171/200, Iteration 33/250, Loss: 0.0144\n",
      "Epoch 171/200, Iteration 34/250, Loss: 0.0234\n",
      "Epoch 171/200, Iteration 35/250, Loss: 0.0183\n",
      "Epoch 171/200, Iteration 36/250, Loss: 0.0100\n",
      "Epoch 171/200, Iteration 37/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 38/250, Loss: 0.0173\n",
      "Epoch 171/200, Iteration 39/250, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 40/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 41/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 42/250, Loss: 0.0167\n",
      "Epoch 171/200, Iteration 43/250, Loss: 0.0202\n",
      "Epoch 171/200, Iteration 44/250, Loss: 0.0109\n",
      "Epoch 171/200, Iteration 45/250, Loss: 0.0082\n",
      "Epoch 171/200, Iteration 46/250, Loss: 0.0122\n",
      "Epoch 171/200, Iteration 47/250, Loss: 0.0352\n",
      "Epoch 171/200, Iteration 48/250, Loss: 0.0210\n",
      "Epoch 171/200, Iteration 49/250, Loss: 0.0229\n",
      "Epoch 171/200, Iteration 50/250, Loss: 0.0190\n",
      "Epoch 171/200, Iteration 51/250, Loss: 0.0381\n",
      "Epoch 171/200, Iteration 52/250, Loss: 0.0118\n",
      "Epoch 171/200, Iteration 53/250, Loss: 0.0112\n",
      "Epoch 171/200, Iteration 54/250, Loss: 0.0256\n",
      "Epoch 171/200, Iteration 55/250, Loss: 0.0096\n",
      "Epoch 171/200, Iteration 56/250, Loss: 0.0123\n",
      "Epoch 171/200, Iteration 57/250, Loss: 0.0126\n",
      "Epoch 171/200, Iteration 58/250, Loss: 0.0074\n",
      "Epoch 171/200, Iteration 59/250, Loss: 0.0084\n",
      "Epoch 171/200, Iteration 60/250, Loss: 0.0113\n",
      "Epoch 171/200, Iteration 61/250, Loss: 0.0155\n",
      "Epoch 171/200, Iteration 62/250, Loss: 0.0109\n",
      "Epoch 171/200, Iteration 63/250, Loss: 0.0102\n",
      "Epoch 171/200, Iteration 64/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 65/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 66/250, Loss: 0.0068\n",
      "Epoch 171/200, Iteration 67/250, Loss: 0.0295\n",
      "Epoch 171/200, Iteration 68/250, Loss: 0.0144\n",
      "Epoch 171/200, Iteration 69/250, Loss: 0.0111\n",
      "Epoch 171/200, Iteration 70/250, Loss: 0.0081\n",
      "Epoch 171/200, Iteration 71/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 72/250, Loss: 0.0084\n",
      "Epoch 171/200, Iteration 73/250, Loss: 0.0263\n",
      "Epoch 171/200, Iteration 74/250, Loss: 0.0100\n",
      "Epoch 171/200, Iteration 75/250, Loss: 0.0145\n",
      "Epoch 171/200, Iteration 76/250, Loss: 0.0161\n",
      "Epoch 171/200, Iteration 77/250, Loss: 0.0183\n",
      "Epoch 171/200, Iteration 78/250, Loss: 0.0273\n",
      "Epoch 171/200, Iteration 79/250, Loss: 0.0135\n",
      "Epoch 171/200, Iteration 80/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 81/250, Loss: 0.0343\n",
      "Epoch 171/200, Iteration 82/250, Loss: 0.0280\n",
      "Epoch 171/200, Iteration 83/250, Loss: 0.0176\n",
      "Epoch 171/200, Iteration 84/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 85/250, Loss: 0.0132\n",
      "Epoch 171/200, Iteration 86/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 87/250, Loss: 0.0182\n",
      "Epoch 171/200, Iteration 88/250, Loss: 0.0108\n",
      "Epoch 171/200, Iteration 89/250, Loss: 0.0194\n",
      "Epoch 171/200, Iteration 90/250, Loss: 0.0224\n",
      "Epoch 171/200, Iteration 91/250, Loss: 0.0198\n",
      "Epoch 171/200, Iteration 92/250, Loss: 0.0227\n",
      "Epoch 171/200, Iteration 93/250, Loss: 0.0079\n",
      "Epoch 171/200, Iteration 94/250, Loss: 0.0160\n",
      "Epoch 171/200, Iteration 95/250, Loss: 0.0252\n",
      "Epoch 171/200, Iteration 96/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 97/250, Loss: 0.0178\n",
      "Epoch 171/200, Iteration 98/250, Loss: 0.0129\n",
      "Epoch 171/200, Iteration 99/250, Loss: 0.0308\n",
      "Epoch 171/200, Iteration 100/250, Loss: 0.0193\n",
      "Epoch 171/200, Iteration 101/250, Loss: 0.0137\n",
      "Epoch 171/200, Iteration 102/250, Loss: 0.0488\n",
      "Epoch 171/200, Iteration 103/250, Loss: 0.0134\n",
      "Epoch 171/200, Iteration 104/250, Loss: 0.0139\n",
      "Epoch 171/200, Iteration 105/250, Loss: 0.0193\n",
      "Epoch 171/200, Iteration 106/250, Loss: 0.0217\n",
      "Epoch 171/200, Iteration 107/250, Loss: 0.0118\n",
      "Epoch 171/200, Iteration 108/250, Loss: 0.0095\n",
      "Epoch 171/200, Iteration 109/250, Loss: 0.0286\n",
      "Epoch 171/200, Iteration 110/250, Loss: 0.0082\n",
      "Epoch 171/200, Iteration 111/250, Loss: 0.0154\n",
      "Epoch 171/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 171/200, Iteration 113/250, Loss: 0.0173\n",
      "Epoch 171/200, Iteration 114/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 115/250, Loss: 0.0221\n",
      "Epoch 171/200, Iteration 116/250, Loss: 0.0165\n",
      "Epoch 171/200, Iteration 117/250, Loss: 0.0157\n",
      "Epoch 171/200, Iteration 118/250, Loss: 0.0141\n",
      "Epoch 171/200, Iteration 119/250, Loss: 0.0313\n",
      "Epoch 171/200, Iteration 120/250, Loss: 0.0131\n",
      "Epoch 171/200, Iteration 121/250, Loss: 0.0125\n",
      "Epoch 171/200, Iteration 122/250, Loss: 0.0135\n",
      "Epoch 171/200, Iteration 123/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 124/250, Loss: 0.0080\n",
      "Epoch 171/200, Iteration 125/250, Loss: 0.0090\n",
      "Epoch 171/200, Iteration 126/250, Loss: 0.0177\n",
      "Epoch 171/200, Iteration 127/250, Loss: 0.0144\n",
      "Epoch 171/200, Iteration 128/250, Loss: 0.0140\n",
      "Epoch 171/200, Iteration 129/250, Loss: 0.0144\n",
      "Epoch 171/200, Iteration 130/250, Loss: 0.0190\n",
      "Epoch 171/200, Iteration 131/250, Loss: 0.0065\n",
      "Epoch 171/200, Iteration 132/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 133/250, Loss: 0.0165\n",
      "Epoch 171/200, Iteration 134/250, Loss: 0.0101\n",
      "Epoch 171/200, Iteration 135/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 136/250, Loss: 0.0110\n",
      "Epoch 171/200, Iteration 137/250, Loss: 0.0101\n",
      "Epoch 171/200, Iteration 138/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 139/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 140/250, Loss: 0.0137\n",
      "Epoch 171/200, Iteration 141/250, Loss: 0.0169\n",
      "Epoch 171/200, Iteration 142/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 143/250, Loss: 0.0140\n",
      "Epoch 171/200, Iteration 144/250, Loss: 0.0113\n",
      "Epoch 171/200, Iteration 145/250, Loss: 0.0147\n",
      "Epoch 171/200, Iteration 146/250, Loss: 0.0186\n",
      "Epoch 171/200, Iteration 147/250, Loss: 0.0379\n",
      "Epoch 171/200, Iteration 148/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 149/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 150/250, Loss: 0.0146\n",
      "Epoch 171/200, Iteration 151/250, Loss: 0.0320\n",
      "Epoch 171/200, Iteration 152/250, Loss: 0.0095\n",
      "Epoch 171/200, Iteration 153/250, Loss: 0.0140\n",
      "Epoch 171/200, Iteration 154/250, Loss: 0.0165\n",
      "Epoch 171/200, Iteration 155/250, Loss: 0.0120\n",
      "Epoch 171/200, Iteration 156/250, Loss: 0.0263\n",
      "Epoch 171/200, Iteration 157/250, Loss: 0.0163\n",
      "Epoch 171/200, Iteration 158/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 159/250, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 160/250, Loss: 0.0136\n",
      "Epoch 171/200, Iteration 161/250, Loss: 0.0128\n",
      "Epoch 171/200, Iteration 162/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 163/250, Loss: 0.0083\n",
      "Epoch 171/200, Iteration 164/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 165/250, Loss: 0.0165\n",
      "Epoch 171/200, Iteration 166/250, Loss: 0.0180\n",
      "Epoch 171/200, Iteration 167/250, Loss: 0.0133\n",
      "Epoch 171/200, Iteration 168/250, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 169/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 170/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 171/250, Loss: 0.0096\n",
      "Epoch 171/200, Iteration 172/250, Loss: 0.0120\n",
      "Epoch 171/200, Iteration 173/250, Loss: 0.0085\n",
      "Epoch 171/200, Iteration 174/250, Loss: 0.0126\n",
      "Epoch 171/200, Iteration 175/250, Loss: 0.0142\n",
      "Epoch 171/200, Iteration 176/250, Loss: 0.0101\n",
      "Epoch 171/200, Iteration 177/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 178/250, Loss: 0.0260\n",
      "Epoch 171/200, Iteration 179/250, Loss: 0.0165\n",
      "Epoch 171/200, Iteration 180/250, Loss: 0.0180\n",
      "Epoch 171/200, Iteration 181/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 182/250, Loss: 0.0162\n",
      "Epoch 171/200, Iteration 183/250, Loss: 0.0057\n",
      "Epoch 171/200, Iteration 184/250, Loss: 0.0222\n",
      "Epoch 171/200, Iteration 185/250, Loss: 0.0188\n",
      "Epoch 171/200, Iteration 186/250, Loss: 0.0086\n",
      "Epoch 171/200, Iteration 187/250, Loss: 0.0113\n",
      "Epoch 171/200, Iteration 188/250, Loss: 0.0393\n",
      "Epoch 171/200, Iteration 189/250, Loss: 0.0346\n",
      "Epoch 171/200, Iteration 190/250, Loss: 0.0087\n",
      "Epoch 171/200, Iteration 191/250, Loss: 0.0101\n",
      "Epoch 171/200, Iteration 192/250, Loss: 0.0073\n",
      "Epoch 171/200, Iteration 193/250, Loss: 0.0233\n",
      "Epoch 171/200, Iteration 194/250, Loss: 0.0098\n",
      "Epoch 171/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 196/250, Loss: 0.0112\n",
      "Epoch 171/200, Iteration 197/250, Loss: 0.0086\n",
      "Epoch 171/200, Iteration 198/250, Loss: 0.0215\n",
      "Epoch 171/200, Iteration 199/250, Loss: 0.0124\n",
      "Epoch 171/200, Iteration 200/250, Loss: 0.0231\n",
      "Epoch 171/200, Iteration 201/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 202/250, Loss: 0.0097\n",
      "Epoch 171/200, Iteration 203/250, Loss: 0.0184\n",
      "Epoch 171/200, Iteration 204/250, Loss: 0.0158\n",
      "Epoch 171/200, Iteration 205/250, Loss: 0.0191\n",
      "Epoch 171/200, Iteration 206/250, Loss: 0.0108\n",
      "Epoch 171/200, Iteration 207/250, Loss: 0.0199\n",
      "Epoch 171/200, Iteration 208/250, Loss: 0.0086\n",
      "Epoch 171/200, Iteration 209/250, Loss: 0.0080\n",
      "Epoch 171/200, Iteration 210/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 211/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 212/250, Loss: 0.0130\n",
      "Epoch 171/200, Iteration 213/250, Loss: 0.0092\n",
      "Epoch 171/200, Iteration 214/250, Loss: 0.0119\n",
      "Epoch 171/200, Iteration 215/250, Loss: 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200, Iteration 216/250, Loss: 0.0099\n",
      "Epoch 171/200, Iteration 217/250, Loss: 0.0120\n",
      "Epoch 171/200, Iteration 218/250, Loss: 0.0112\n",
      "Epoch 171/200, Iteration 219/250, Loss: 0.0127\n",
      "Epoch 171/200, Iteration 220/250, Loss: 0.0120\n",
      "Epoch 171/200, Iteration 221/250, Loss: 0.0160\n",
      "Epoch 171/200, Iteration 222/250, Loss: 0.0115\n",
      "Epoch 171/200, Iteration 223/250, Loss: 0.0094\n",
      "Epoch 171/200, Iteration 224/250, Loss: 0.0117\n",
      "Epoch 171/200, Iteration 225/250, Loss: 0.0154\n",
      "Epoch 171/200, Iteration 226/250, Loss: 0.0155\n",
      "Epoch 171/200, Iteration 227/250, Loss: 0.0232\n",
      "Epoch 171/200, Iteration 228/250, Loss: 0.0223\n",
      "Epoch 171/200, Iteration 229/250, Loss: 0.0355\n",
      "Epoch 171/200, Iteration 230/250, Loss: 0.0173\n",
      "Epoch 171/200, Iteration 231/250, Loss: 0.0100\n",
      "Epoch 171/200, Iteration 232/250, Loss: 0.0082\n",
      "Epoch 171/200, Iteration 233/250, Loss: 0.0111\n",
      "Epoch 171/200, Iteration 234/250, Loss: 0.0107\n",
      "Epoch 171/200, Iteration 235/250, Loss: 0.0168\n",
      "Epoch 171/200, Iteration 236/250, Loss: 0.0327\n",
      "Epoch 171/200, Iteration 237/250, Loss: 0.0172\n",
      "Epoch 171/200, Iteration 238/250, Loss: 0.0103\n",
      "Epoch 171/200, Iteration 239/250, Loss: 0.0132\n",
      "Epoch 171/200, Iteration 240/250, Loss: 0.0091\n",
      "Epoch 171/200, Iteration 241/250, Loss: 0.0082\n",
      "Epoch 171/200, Iteration 242/250, Loss: 0.0105\n",
      "Epoch 171/200, Iteration 243/250, Loss: 0.0116\n",
      "Epoch 171/200, Iteration 244/250, Loss: 0.0365\n",
      "Epoch 171/200, Iteration 245/250, Loss: 0.0145\n",
      "Epoch 171/200, Iteration 246/250, Loss: 0.0271\n",
      "Epoch 171/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 171/200, Iteration 248/250, Loss: 0.0157\n",
      "Epoch 171/200, Iteration 249/250, Loss: 0.0076\n",
      "Epoch 171/200, Iteration 250/250, Loss: 0.0218\n",
      "Train Error: \n",
      " Accuracy: 95.83%, Avg loss: 0.007727, MRE: 0.518781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.008356, MRE: 0.561004 \n",
      "\n",
      "Epoch 172/200, Iteration 1/250, Loss: 0.0276\n",
      "Epoch 172/200, Iteration 2/250, Loss: 0.0166\n",
      "Epoch 172/200, Iteration 3/250, Loss: 0.0099\n",
      "Epoch 172/200, Iteration 4/250, Loss: 0.0084\n",
      "Epoch 172/200, Iteration 5/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 6/250, Loss: 0.0114\n",
      "Epoch 172/200, Iteration 7/250, Loss: 0.0297\n",
      "Epoch 172/200, Iteration 8/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 9/250, Loss: 0.0143\n",
      "Epoch 172/200, Iteration 10/250, Loss: 0.0107\n",
      "Epoch 172/200, Iteration 11/250, Loss: 0.0309\n",
      "Epoch 172/200, Iteration 12/250, Loss: 0.0075\n",
      "Epoch 172/200, Iteration 13/250, Loss: 0.0097\n",
      "Epoch 172/200, Iteration 14/250, Loss: 0.0177\n",
      "Epoch 172/200, Iteration 15/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 16/250, Loss: 0.0113\n",
      "Epoch 172/200, Iteration 17/250, Loss: 0.0138\n",
      "Epoch 172/200, Iteration 18/250, Loss: 0.0072\n",
      "Epoch 172/200, Iteration 19/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 20/250, Loss: 0.0101\n",
      "Epoch 172/200, Iteration 21/250, Loss: 0.0151\n",
      "Epoch 172/200, Iteration 22/250, Loss: 0.0137\n",
      "Epoch 172/200, Iteration 23/250, Loss: 0.0213\n",
      "Epoch 172/200, Iteration 24/250, Loss: 0.0292\n",
      "Epoch 172/200, Iteration 25/250, Loss: 0.0276\n",
      "Epoch 172/200, Iteration 26/250, Loss: 0.0316\n",
      "Epoch 172/200, Iteration 27/250, Loss: 0.0142\n",
      "Epoch 172/200, Iteration 28/250, Loss: 0.0223\n",
      "Epoch 172/200, Iteration 29/250, Loss: 0.0144\n",
      "Epoch 172/200, Iteration 30/250, Loss: 0.0098\n",
      "Epoch 172/200, Iteration 31/250, Loss: 0.0135\n",
      "Epoch 172/200, Iteration 32/250, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 33/250, Loss: 0.0088\n",
      "Epoch 172/200, Iteration 34/250, Loss: 0.0129\n",
      "Epoch 172/200, Iteration 35/250, Loss: 0.0188\n",
      "Epoch 172/200, Iteration 36/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 37/250, Loss: 0.0060\n",
      "Epoch 172/200, Iteration 38/250, Loss: 0.0075\n",
      "Epoch 172/200, Iteration 39/250, Loss: 0.0160\n",
      "Epoch 172/200, Iteration 40/250, Loss: 0.0142\n",
      "Epoch 172/200, Iteration 41/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 42/250, Loss: 0.0254\n",
      "Epoch 172/200, Iteration 43/250, Loss: 0.0123\n",
      "Epoch 172/200, Iteration 44/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 45/250, Loss: 0.0146\n",
      "Epoch 172/200, Iteration 46/250, Loss: 0.0163\n",
      "Epoch 172/200, Iteration 47/250, Loss: 0.0187\n",
      "Epoch 172/200, Iteration 48/250, Loss: 0.0173\n",
      "Epoch 172/200, Iteration 49/250, Loss: 0.0385\n",
      "Epoch 172/200, Iteration 50/250, Loss: 0.0177\n",
      "Epoch 172/200, Iteration 51/250, Loss: 0.0162\n",
      "Epoch 172/200, Iteration 52/250, Loss: 0.0062\n",
      "Epoch 172/200, Iteration 53/250, Loss: 0.0189\n",
      "Epoch 172/200, Iteration 54/250, Loss: 0.0229\n",
      "Epoch 172/200, Iteration 55/250, Loss: 0.0304\n",
      "Epoch 172/200, Iteration 56/250, Loss: 0.0154\n",
      "Epoch 172/200, Iteration 57/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 58/250, Loss: 0.0111\n",
      "Epoch 172/200, Iteration 59/250, Loss: 0.0373\n",
      "Epoch 172/200, Iteration 60/250, Loss: 0.0130\n",
      "Epoch 172/200, Iteration 61/250, Loss: 0.0069\n",
      "Epoch 172/200, Iteration 62/250, Loss: 0.0122\n",
      "Epoch 172/200, Iteration 63/250, Loss: 0.0139\n",
      "Epoch 172/200, Iteration 64/250, Loss: 0.0157\n",
      "Epoch 172/200, Iteration 65/250, Loss: 0.0169\n",
      "Epoch 172/200, Iteration 66/250, Loss: 0.0204\n",
      "Epoch 172/200, Iteration 67/250, Loss: 0.0130\n",
      "Epoch 172/200, Iteration 68/250, Loss: 0.0222\n",
      "Epoch 172/200, Iteration 69/250, Loss: 0.0112\n",
      "Epoch 172/200, Iteration 70/250, Loss: 0.0213\n",
      "Epoch 172/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 172/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 73/250, Loss: 0.0080\n",
      "Epoch 172/200, Iteration 74/250, Loss: 0.0211\n",
      "Epoch 172/200, Iteration 75/250, Loss: 0.0259\n",
      "Epoch 172/200, Iteration 76/250, Loss: 0.0147\n",
      "Epoch 172/200, Iteration 77/250, Loss: 0.0151\n",
      "Epoch 172/200, Iteration 78/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 79/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 80/250, Loss: 0.0077\n",
      "Epoch 172/200, Iteration 81/250, Loss: 0.0178\n",
      "Epoch 172/200, Iteration 82/250, Loss: 0.0107\n",
      "Epoch 172/200, Iteration 83/250, Loss: 0.0075\n",
      "Epoch 172/200, Iteration 84/250, Loss: 0.0288\n",
      "Epoch 172/200, Iteration 85/250, Loss: 0.0206\n",
      "Epoch 172/200, Iteration 86/250, Loss: 0.0140\n",
      "Epoch 172/200, Iteration 87/250, Loss: 0.0257\n",
      "Epoch 172/200, Iteration 88/250, Loss: 0.0075\n",
      "Epoch 172/200, Iteration 89/250, Loss: 0.0122\n",
      "Epoch 172/200, Iteration 90/250, Loss: 0.0086\n",
      "Epoch 172/200, Iteration 91/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 92/250, Loss: 0.0101\n",
      "Epoch 172/200, Iteration 93/250, Loss: 0.0235\n",
      "Epoch 172/200, Iteration 94/250, Loss: 0.0194\n",
      "Epoch 172/200, Iteration 95/250, Loss: 0.0218\n",
      "Epoch 172/200, Iteration 96/250, Loss: 0.0350\n",
      "Epoch 172/200, Iteration 97/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 98/250, Loss: 0.0127\n",
      "Epoch 172/200, Iteration 99/250, Loss: 0.0405\n",
      "Epoch 172/200, Iteration 100/250, Loss: 0.0061\n",
      "Epoch 172/200, Iteration 101/250, Loss: 0.0083\n",
      "Epoch 172/200, Iteration 102/250, Loss: 0.0247\n",
      "Epoch 172/200, Iteration 103/250, Loss: 0.0164\n",
      "Epoch 172/200, Iteration 104/250, Loss: 0.0107\n",
      "Epoch 172/200, Iteration 105/250, Loss: 0.0149\n",
      "Epoch 172/200, Iteration 106/250, Loss: 0.0178\n",
      "Epoch 172/200, Iteration 107/250, Loss: 0.0160\n",
      "Epoch 172/200, Iteration 108/250, Loss: 0.0224\n",
      "Epoch 172/200, Iteration 109/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 110/250, Loss: 0.0154\n",
      "Epoch 172/200, Iteration 111/250, Loss: 0.0285\n",
      "Epoch 172/200, Iteration 112/250, Loss: 0.0152\n",
      "Epoch 172/200, Iteration 113/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 114/250, Loss: 0.0149\n",
      "Epoch 172/200, Iteration 115/250, Loss: 0.0203\n",
      "Epoch 172/200, Iteration 116/250, Loss: 0.0082\n",
      "Epoch 172/200, Iteration 117/250, Loss: 0.0338\n",
      "Epoch 172/200, Iteration 118/250, Loss: 0.0066\n",
      "Epoch 172/200, Iteration 119/250, Loss: 0.0061\n",
      "Epoch 172/200, Iteration 120/250, Loss: 0.0214\n",
      "Epoch 172/200, Iteration 121/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 122/250, Loss: 0.0330\n",
      "Epoch 172/200, Iteration 123/250, Loss: 0.0076\n",
      "Epoch 172/200, Iteration 124/250, Loss: 0.0100\n",
      "Epoch 172/200, Iteration 125/250, Loss: 0.0134\n",
      "Epoch 172/200, Iteration 126/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 127/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 128/250, Loss: 0.0092\n",
      "Epoch 172/200, Iteration 129/250, Loss: 0.0236\n",
      "Epoch 172/200, Iteration 130/250, Loss: 0.0331\n",
      "Epoch 172/200, Iteration 131/250, Loss: 0.0065\n",
      "Epoch 172/200, Iteration 132/250, Loss: 0.0162\n",
      "Epoch 172/200, Iteration 133/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 134/250, Loss: 0.0228\n",
      "Epoch 172/200, Iteration 135/250, Loss: 0.0125\n",
      "Epoch 172/200, Iteration 136/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 137/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 138/250, Loss: 0.0171\n",
      "Epoch 172/200, Iteration 139/250, Loss: 0.0105\n",
      "Epoch 172/200, Iteration 140/250, Loss: 0.0093\n",
      "Epoch 172/200, Iteration 141/250, Loss: 0.0158\n",
      "Epoch 172/200, Iteration 142/250, Loss: 0.0135\n",
      "Epoch 172/200, Iteration 143/250, Loss: 0.0114\n",
      "Epoch 172/200, Iteration 144/250, Loss: 0.0135\n",
      "Epoch 172/200, Iteration 145/250, Loss: 0.0286\n",
      "Epoch 172/200, Iteration 146/250, Loss: 0.0089\n",
      "Epoch 172/200, Iteration 147/250, Loss: 0.0189\n",
      "Epoch 172/200, Iteration 148/250, Loss: 0.0097\n",
      "Epoch 172/200, Iteration 149/250, Loss: 0.0373\n",
      "Epoch 172/200, Iteration 150/250, Loss: 0.0091\n",
      "Epoch 172/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 172/200, Iteration 152/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 153/250, Loss: 0.0149\n",
      "Epoch 172/200, Iteration 154/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 155/250, Loss: 0.0145\n",
      "Epoch 172/200, Iteration 156/250, Loss: 0.0186\n",
      "Epoch 172/200, Iteration 157/250, Loss: 0.0189\n",
      "Epoch 172/200, Iteration 158/250, Loss: 0.0118\n",
      "Epoch 172/200, Iteration 159/250, Loss: 0.0096\n",
      "Epoch 172/200, Iteration 160/250, Loss: 0.0113\n",
      "Epoch 172/200, Iteration 161/250, Loss: 0.0091\n",
      "Epoch 172/200, Iteration 162/250, Loss: 0.0171\n",
      "Epoch 172/200, Iteration 163/250, Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200, Iteration 164/250, Loss: 0.0083\n",
      "Epoch 172/200, Iteration 165/250, Loss: 0.0222\n",
      "Epoch 172/200, Iteration 166/250, Loss: 0.0257\n",
      "Epoch 172/200, Iteration 167/250, Loss: 0.0120\n",
      "Epoch 172/200, Iteration 168/250, Loss: 0.0095\n",
      "Epoch 172/200, Iteration 169/250, Loss: 0.0086\n",
      "Epoch 172/200, Iteration 170/250, Loss: 0.0071\n",
      "Epoch 172/200, Iteration 171/250, Loss: 0.0172\n",
      "Epoch 172/200, Iteration 172/250, Loss: 0.0120\n",
      "Epoch 172/200, Iteration 173/250, Loss: 0.0159\n",
      "Epoch 172/200, Iteration 174/250, Loss: 0.0180\n",
      "Epoch 172/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 176/250, Loss: 0.0154\n",
      "Epoch 172/200, Iteration 177/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 178/250, Loss: 0.0151\n",
      "Epoch 172/200, Iteration 179/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 180/250, Loss: 0.0129\n",
      "Epoch 172/200, Iteration 181/250, Loss: 0.0118\n",
      "Epoch 172/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 183/250, Loss: 0.0096\n",
      "Epoch 172/200, Iteration 184/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 185/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 186/250, Loss: 0.0186\n",
      "Epoch 172/200, Iteration 187/250, Loss: 0.0222\n",
      "Epoch 172/200, Iteration 188/250, Loss: 0.0133\n",
      "Epoch 172/200, Iteration 189/250, Loss: 0.0391\n",
      "Epoch 172/200, Iteration 190/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 191/250, Loss: 0.0073\n",
      "Epoch 172/200, Iteration 192/250, Loss: 0.0188\n",
      "Epoch 172/200, Iteration 193/250, Loss: 0.0094\n",
      "Epoch 172/200, Iteration 194/250, Loss: 0.0062\n",
      "Epoch 172/200, Iteration 195/250, Loss: 0.0184\n",
      "Epoch 172/200, Iteration 196/250, Loss: 0.0117\n",
      "Epoch 172/200, Iteration 197/250, Loss: 0.0157\n",
      "Epoch 172/200, Iteration 198/250, Loss: 0.0235\n",
      "Epoch 172/200, Iteration 199/250, Loss: 0.0362\n",
      "Epoch 172/200, Iteration 200/250, Loss: 0.0198\n",
      "Epoch 172/200, Iteration 201/250, Loss: 0.0126\n",
      "Epoch 172/200, Iteration 202/250, Loss: 0.0233\n",
      "Epoch 172/200, Iteration 203/250, Loss: 0.0104\n",
      "Epoch 172/200, Iteration 204/250, Loss: 0.0133\n",
      "Epoch 172/200, Iteration 205/250, Loss: 0.0081\n",
      "Epoch 172/200, Iteration 206/250, Loss: 0.0286\n",
      "Epoch 172/200, Iteration 207/250, Loss: 0.0236\n",
      "Epoch 172/200, Iteration 208/250, Loss: 0.0093\n",
      "Epoch 172/200, Iteration 209/250, Loss: 0.0274\n",
      "Epoch 172/200, Iteration 210/250, Loss: 0.0101\n",
      "Epoch 172/200, Iteration 211/250, Loss: 0.0219\n",
      "Epoch 172/200, Iteration 212/250, Loss: 0.0090\n",
      "Epoch 172/200, Iteration 213/250, Loss: 0.0329\n",
      "Epoch 172/200, Iteration 214/250, Loss: 0.0276\n",
      "Epoch 172/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 172/200, Iteration 216/250, Loss: 0.0094\n",
      "Epoch 172/200, Iteration 217/250, Loss: 0.0270\n",
      "Epoch 172/200, Iteration 218/250, Loss: 0.0131\n",
      "Epoch 172/200, Iteration 219/250, Loss: 0.0085\n",
      "Epoch 172/200, Iteration 220/250, Loss: 0.0187\n",
      "Epoch 172/200, Iteration 221/250, Loss: 0.0124\n",
      "Epoch 172/200, Iteration 222/250, Loss: 0.0220\n",
      "Epoch 172/200, Iteration 223/250, Loss: 0.0125\n",
      "Epoch 172/200, Iteration 224/250, Loss: 0.0174\n",
      "Epoch 172/200, Iteration 225/250, Loss: 0.0108\n",
      "Epoch 172/200, Iteration 226/250, Loss: 0.0095\n",
      "Epoch 172/200, Iteration 227/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 228/250, Loss: 0.0106\n",
      "Epoch 172/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 172/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 172/200, Iteration 231/250, Loss: 0.0124\n",
      "Epoch 172/200, Iteration 232/250, Loss: 0.0087\n",
      "Epoch 172/200, Iteration 233/250, Loss: 0.0060\n",
      "Epoch 172/200, Iteration 234/250, Loss: 0.0088\n",
      "Epoch 172/200, Iteration 235/250, Loss: 0.0091\n",
      "Epoch 172/200, Iteration 236/250, Loss: 0.0282\n",
      "Epoch 172/200, Iteration 237/250, Loss: 0.0168\n",
      "Epoch 172/200, Iteration 238/250, Loss: 0.0228\n",
      "Epoch 172/200, Iteration 239/250, Loss: 0.0116\n",
      "Epoch 172/200, Iteration 240/250, Loss: 0.0136\n",
      "Epoch 172/200, Iteration 241/250, Loss: 0.0096\n",
      "Epoch 172/200, Iteration 242/250, Loss: 0.0232\n",
      "Epoch 172/200, Iteration 243/250, Loss: 0.0115\n",
      "Epoch 172/200, Iteration 244/250, Loss: 0.0086\n",
      "Epoch 172/200, Iteration 245/250, Loss: 0.0424\n",
      "Epoch 172/200, Iteration 246/250, Loss: 0.0122\n",
      "Epoch 172/200, Iteration 247/250, Loss: 0.0134\n",
      "Epoch 172/200, Iteration 248/250, Loss: 0.0119\n",
      "Epoch 172/200, Iteration 249/250, Loss: 0.0106\n",
      "Epoch 172/200, Iteration 250/250, Loss: 0.0250\n",
      "Train Error: \n",
      " Accuracy: 87.02%, Avg loss: 0.007034, MRE: 0.501771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.85%, Avg loss: 0.007548, MRE: 0.551790 \n",
      "\n",
      "Epoch 173/200, Iteration 1/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 2/250, Loss: 0.0119\n",
      "Epoch 173/200, Iteration 3/250, Loss: 0.0157\n",
      "Epoch 173/200, Iteration 4/250, Loss: 0.0072\n",
      "Epoch 173/200, Iteration 5/250, Loss: 0.0114\n",
      "Epoch 173/200, Iteration 6/250, Loss: 0.0131\n",
      "Epoch 173/200, Iteration 7/250, Loss: 0.0060\n",
      "Epoch 173/200, Iteration 8/250, Loss: 0.0079\n",
      "Epoch 173/200, Iteration 9/250, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 10/250, Loss: 0.0261\n",
      "Epoch 173/200, Iteration 11/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 12/250, Loss: 0.0120\n",
      "Epoch 173/200, Iteration 13/250, Loss: 0.0101\n",
      "Epoch 173/200, Iteration 14/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 15/250, Loss: 0.0188\n",
      "Epoch 173/200, Iteration 16/250, Loss: 0.0215\n",
      "Epoch 173/200, Iteration 17/250, Loss: 0.0160\n",
      "Epoch 173/200, Iteration 18/250, Loss: 0.0270\n",
      "Epoch 173/200, Iteration 19/250, Loss: 0.0192\n",
      "Epoch 173/200, Iteration 20/250, Loss: 0.0287\n",
      "Epoch 173/200, Iteration 21/250, Loss: 0.0082\n",
      "Epoch 173/200, Iteration 22/250, Loss: 0.0228\n",
      "Epoch 173/200, Iteration 23/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 24/250, Loss: 0.0098\n",
      "Epoch 173/200, Iteration 25/250, Loss: 0.0112\n",
      "Epoch 173/200, Iteration 26/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 27/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 28/250, Loss: 0.0241\n",
      "Epoch 173/200, Iteration 29/250, Loss: 0.0250\n",
      "Epoch 173/200, Iteration 30/250, Loss: 0.0139\n",
      "Epoch 173/200, Iteration 31/250, Loss: 0.0082\n",
      "Epoch 173/200, Iteration 32/250, Loss: 0.0171\n",
      "Epoch 173/200, Iteration 33/250, Loss: 0.0382\n",
      "Epoch 173/200, Iteration 34/250, Loss: 0.0197\n",
      "Epoch 173/200, Iteration 35/250, Loss: 0.0202\n",
      "Epoch 173/200, Iteration 36/250, Loss: 0.0206\n",
      "Epoch 173/200, Iteration 37/250, Loss: 0.0119\n",
      "Epoch 173/200, Iteration 38/250, Loss: 0.0066\n",
      "Epoch 173/200, Iteration 39/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 40/250, Loss: 0.0065\n",
      "Epoch 173/200, Iteration 41/250, Loss: 0.0172\n",
      "Epoch 173/200, Iteration 42/250, Loss: 0.0128\n",
      "Epoch 173/200, Iteration 43/250, Loss: 0.0105\n",
      "Epoch 173/200, Iteration 44/250, Loss: 0.0120\n",
      "Epoch 173/200, Iteration 45/250, Loss: 0.0196\n",
      "Epoch 173/200, Iteration 46/250, Loss: 0.0161\n",
      "Epoch 173/200, Iteration 47/250, Loss: 0.0162\n",
      "Epoch 173/200, Iteration 48/250, Loss: 0.0104\n",
      "Epoch 173/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 50/250, Loss: 0.0175\n",
      "Epoch 173/200, Iteration 51/250, Loss: 0.0135\n",
      "Epoch 173/200, Iteration 52/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 53/250, Loss: 0.0069\n",
      "Epoch 173/200, Iteration 54/250, Loss: 0.0182\n",
      "Epoch 173/200, Iteration 55/250, Loss: 0.0115\n",
      "Epoch 173/200, Iteration 56/250, Loss: 0.0081\n",
      "Epoch 173/200, Iteration 57/250, Loss: 0.0185\n",
      "Epoch 173/200, Iteration 58/250, Loss: 0.0205\n",
      "Epoch 173/200, Iteration 59/250, Loss: 0.0085\n",
      "Epoch 173/200, Iteration 60/250, Loss: 0.0166\n",
      "Epoch 173/200, Iteration 61/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 62/250, Loss: 0.0113\n",
      "Epoch 173/200, Iteration 63/250, Loss: 0.0192\n",
      "Epoch 173/200, Iteration 64/250, Loss: 0.0168\n",
      "Epoch 173/200, Iteration 65/250, Loss: 0.0115\n",
      "Epoch 173/200, Iteration 66/250, Loss: 0.0103\n",
      "Epoch 173/200, Iteration 67/250, Loss: 0.0133\n",
      "Epoch 173/200, Iteration 68/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 69/250, Loss: 0.0117\n",
      "Epoch 173/200, Iteration 70/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 71/250, Loss: 0.0169\n",
      "Epoch 173/200, Iteration 72/250, Loss: 0.0235\n",
      "Epoch 173/200, Iteration 73/250, Loss: 0.0068\n",
      "Epoch 173/200, Iteration 74/250, Loss: 0.0156\n",
      "Epoch 173/200, Iteration 75/250, Loss: 0.0170\n",
      "Epoch 173/200, Iteration 76/250, Loss: 0.0185\n",
      "Epoch 173/200, Iteration 77/250, Loss: 0.0121\n",
      "Epoch 173/200, Iteration 78/250, Loss: 0.0121\n",
      "Epoch 173/200, Iteration 79/250, Loss: 0.0095\n",
      "Epoch 173/200, Iteration 80/250, Loss: 0.0167\n",
      "Epoch 173/200, Iteration 81/250, Loss: 0.0156\n",
      "Epoch 173/200, Iteration 82/250, Loss: 0.0183\n",
      "Epoch 173/200, Iteration 83/250, Loss: 0.0295\n",
      "Epoch 173/200, Iteration 84/250, Loss: 0.0177\n",
      "Epoch 173/200, Iteration 85/250, Loss: 0.0172\n",
      "Epoch 173/200, Iteration 86/250, Loss: 0.0091\n",
      "Epoch 173/200, Iteration 87/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 88/250, Loss: 0.0175\n",
      "Epoch 173/200, Iteration 89/250, Loss: 0.0117\n",
      "Epoch 173/200, Iteration 90/250, Loss: 0.0167\n",
      "Epoch 173/200, Iteration 91/250, Loss: 0.0207\n",
      "Epoch 173/200, Iteration 92/250, Loss: 0.0074\n",
      "Epoch 173/200, Iteration 93/250, Loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200, Iteration 94/250, Loss: 0.0166\n",
      "Epoch 173/200, Iteration 95/250, Loss: 0.0150\n",
      "Epoch 173/200, Iteration 96/250, Loss: 0.0130\n",
      "Epoch 173/200, Iteration 97/250, Loss: 0.0310\n",
      "Epoch 173/200, Iteration 98/250, Loss: 0.0157\n",
      "Epoch 173/200, Iteration 99/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 100/250, Loss: 0.0189\n",
      "Epoch 173/200, Iteration 101/250, Loss: 0.0163\n",
      "Epoch 173/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 103/250, Loss: 0.0296\n",
      "Epoch 173/200, Iteration 104/250, Loss: 0.0083\n",
      "Epoch 173/200, Iteration 105/250, Loss: 0.0278\n",
      "Epoch 173/200, Iteration 106/250, Loss: 0.0306\n",
      "Epoch 173/200, Iteration 107/250, Loss: 0.0255\n",
      "Epoch 173/200, Iteration 108/250, Loss: 0.0141\n",
      "Epoch 173/200, Iteration 109/250, Loss: 0.0196\n",
      "Epoch 173/200, Iteration 110/250, Loss: 0.0221\n",
      "Epoch 173/200, Iteration 111/250, Loss: 0.0065\n",
      "Epoch 173/200, Iteration 112/250, Loss: 0.0146\n",
      "Epoch 173/200, Iteration 113/250, Loss: 0.0098\n",
      "Epoch 173/200, Iteration 114/250, Loss: 0.0194\n",
      "Epoch 173/200, Iteration 115/250, Loss: 0.0105\n",
      "Epoch 173/200, Iteration 116/250, Loss: 0.0261\n",
      "Epoch 173/200, Iteration 117/250, Loss: 0.0114\n",
      "Epoch 173/200, Iteration 118/250, Loss: 0.0113\n",
      "Epoch 173/200, Iteration 119/250, Loss: 0.0148\n",
      "Epoch 173/200, Iteration 120/250, Loss: 0.0317\n",
      "Epoch 173/200, Iteration 121/250, Loss: 0.0091\n",
      "Epoch 173/200, Iteration 122/250, Loss: 0.0099\n",
      "Epoch 173/200, Iteration 123/250, Loss: 0.0095\n",
      "Epoch 173/200, Iteration 124/250, Loss: 0.0160\n",
      "Epoch 173/200, Iteration 125/250, Loss: 0.0230\n",
      "Epoch 173/200, Iteration 126/250, Loss: 0.0103\n",
      "Epoch 173/200, Iteration 127/250, Loss: 0.0312\n",
      "Epoch 173/200, Iteration 128/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 129/250, Loss: 0.0118\n",
      "Epoch 173/200, Iteration 130/250, Loss: 0.0182\n",
      "Epoch 173/200, Iteration 131/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 132/250, Loss: 0.0096\n",
      "Epoch 173/200, Iteration 133/250, Loss: 0.0088\n",
      "Epoch 173/200, Iteration 134/250, Loss: 0.0300\n",
      "Epoch 173/200, Iteration 135/250, Loss: 0.0219\n",
      "Epoch 173/200, Iteration 136/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 137/250, Loss: 0.0091\n",
      "Epoch 173/200, Iteration 138/250, Loss: 0.0163\n",
      "Epoch 173/200, Iteration 139/250, Loss: 0.0179\n",
      "Epoch 173/200, Iteration 140/250, Loss: 0.0093\n",
      "Epoch 173/200, Iteration 141/250, Loss: 0.0250\n",
      "Epoch 173/200, Iteration 142/250, Loss: 0.0127\n",
      "Epoch 173/200, Iteration 143/250, Loss: 0.0084\n",
      "Epoch 173/200, Iteration 144/250, Loss: 0.0227\n",
      "Epoch 173/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 173/200, Iteration 146/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 147/250, Loss: 0.0117\n",
      "Epoch 173/200, Iteration 148/250, Loss: 0.0083\n",
      "Epoch 173/200, Iteration 149/250, Loss: 0.0289\n",
      "Epoch 173/200, Iteration 150/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 151/250, Loss: 0.0063\n",
      "Epoch 173/200, Iteration 152/250, Loss: 0.0059\n",
      "Epoch 173/200, Iteration 153/250, Loss: 0.0096\n",
      "Epoch 173/200, Iteration 154/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 155/250, Loss: 0.0078\n",
      "Epoch 173/200, Iteration 156/250, Loss: 0.0247\n",
      "Epoch 173/200, Iteration 157/250, Loss: 0.0129\n",
      "Epoch 173/200, Iteration 158/250, Loss: 0.0202\n",
      "Epoch 173/200, Iteration 159/250, Loss: 0.0339\n",
      "Epoch 173/200, Iteration 160/250, Loss: 0.0117\n",
      "Epoch 173/200, Iteration 161/250, Loss: 0.0164\n",
      "Epoch 173/200, Iteration 162/250, Loss: 0.0141\n",
      "Epoch 173/200, Iteration 163/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 164/250, Loss: 0.0115\n",
      "Epoch 173/200, Iteration 165/250, Loss: 0.0254\n",
      "Epoch 173/200, Iteration 166/250, Loss: 0.0253\n",
      "Epoch 173/200, Iteration 167/250, Loss: 0.0260\n",
      "Epoch 173/200, Iteration 168/250, Loss: 0.0214\n",
      "Epoch 173/200, Iteration 169/250, Loss: 0.0454\n",
      "Epoch 173/200, Iteration 170/250, Loss: 0.0089\n",
      "Epoch 173/200, Iteration 171/250, Loss: 0.0267\n",
      "Epoch 173/200, Iteration 172/250, Loss: 0.0257\n",
      "Epoch 173/200, Iteration 173/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 174/250, Loss: 0.0136\n",
      "Epoch 173/200, Iteration 175/250, Loss: 0.0344\n",
      "Epoch 173/200, Iteration 176/250, Loss: 0.0168\n",
      "Epoch 173/200, Iteration 177/250, Loss: 0.0173\n",
      "Epoch 173/200, Iteration 178/250, Loss: 0.0259\n",
      "Epoch 173/200, Iteration 179/250, Loss: 0.0097\n",
      "Epoch 173/200, Iteration 180/250, Loss: 0.0073\n",
      "Epoch 173/200, Iteration 181/250, Loss: 0.0124\n",
      "Epoch 173/200, Iteration 182/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 183/250, Loss: 0.0299\n",
      "Epoch 173/200, Iteration 184/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 185/250, Loss: 0.0252\n",
      "Epoch 173/200, Iteration 186/250, Loss: 0.0185\n",
      "Epoch 173/200, Iteration 187/250, Loss: 0.0185\n",
      "Epoch 173/200, Iteration 188/250, Loss: 0.0174\n",
      "Epoch 173/200, Iteration 189/250, Loss: 0.0082\n",
      "Epoch 173/200, Iteration 190/250, Loss: 0.0077\n",
      "Epoch 173/200, Iteration 191/250, Loss: 0.0334\n",
      "Epoch 173/200, Iteration 192/250, Loss: 0.0145\n",
      "Epoch 173/200, Iteration 193/250, Loss: 0.0172\n",
      "Epoch 173/200, Iteration 194/250, Loss: 0.0200\n",
      "Epoch 173/200, Iteration 195/250, Loss: 0.0290\n",
      "Epoch 173/200, Iteration 196/250, Loss: 0.0114\n",
      "Epoch 173/200, Iteration 197/250, Loss: 0.0110\n",
      "Epoch 173/200, Iteration 198/250, Loss: 0.0137\n",
      "Epoch 173/200, Iteration 199/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 200/250, Loss: 0.0290\n",
      "Epoch 173/200, Iteration 201/250, Loss: 0.0327\n",
      "Epoch 173/200, Iteration 202/250, Loss: 0.0161\n",
      "Epoch 173/200, Iteration 203/250, Loss: 0.0078\n",
      "Epoch 173/200, Iteration 204/250, Loss: 0.0104\n",
      "Epoch 173/200, Iteration 205/250, Loss: 0.0404\n",
      "Epoch 173/200, Iteration 206/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 207/250, Loss: 0.0153\n",
      "Epoch 173/200, Iteration 208/250, Loss: 0.0126\n",
      "Epoch 173/200, Iteration 209/250, Loss: 0.0195\n",
      "Epoch 173/200, Iteration 210/250, Loss: 0.0189\n",
      "Epoch 173/200, Iteration 211/250, Loss: 0.0138\n",
      "Epoch 173/200, Iteration 212/250, Loss: 0.0285\n",
      "Epoch 173/200, Iteration 213/250, Loss: 0.0103\n",
      "Epoch 173/200, Iteration 214/250, Loss: 0.0102\n",
      "Epoch 173/200, Iteration 215/250, Loss: 0.0174\n",
      "Epoch 173/200, Iteration 216/250, Loss: 0.0071\n",
      "Epoch 173/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 173/200, Iteration 218/250, Loss: 0.0228\n",
      "Epoch 173/200, Iteration 219/250, Loss: 0.0131\n",
      "Epoch 173/200, Iteration 220/250, Loss: 0.0068\n",
      "Epoch 173/200, Iteration 221/250, Loss: 0.0269\n",
      "Epoch 173/200, Iteration 222/250, Loss: 0.0111\n",
      "Epoch 173/200, Iteration 223/250, Loss: 0.0100\n",
      "Epoch 173/200, Iteration 224/250, Loss: 0.0251\n",
      "Epoch 173/200, Iteration 225/250, Loss: 0.0278\n",
      "Epoch 173/200, Iteration 226/250, Loss: 0.0266\n",
      "Epoch 173/200, Iteration 227/250, Loss: 0.0178\n",
      "Epoch 173/200, Iteration 228/250, Loss: 0.0108\n",
      "Epoch 173/200, Iteration 229/250, Loss: 0.0266\n",
      "Epoch 173/200, Iteration 230/250, Loss: 0.0085\n",
      "Epoch 173/200, Iteration 231/250, Loss: 0.0166\n",
      "Epoch 173/200, Iteration 232/250, Loss: 0.0164\n",
      "Epoch 173/200, Iteration 233/250, Loss: 0.0221\n",
      "Epoch 173/200, Iteration 234/250, Loss: 0.0258\n",
      "Epoch 173/200, Iteration 235/250, Loss: 0.0064\n",
      "Epoch 173/200, Iteration 236/250, Loss: 0.0140\n",
      "Epoch 173/200, Iteration 237/250, Loss: 0.0131\n",
      "Epoch 173/200, Iteration 238/250, Loss: 0.0220\n",
      "Epoch 173/200, Iteration 239/250, Loss: 0.0069\n",
      "Epoch 173/200, Iteration 240/250, Loss: 0.0083\n",
      "Epoch 173/200, Iteration 241/250, Loss: 0.0209\n",
      "Epoch 173/200, Iteration 242/250, Loss: 0.0106\n",
      "Epoch 173/200, Iteration 243/250, Loss: 0.0110\n",
      "Epoch 173/200, Iteration 244/250, Loss: 0.0245\n",
      "Epoch 173/200, Iteration 245/250, Loss: 0.0092\n",
      "Epoch 173/200, Iteration 246/250, Loss: 0.0265\n",
      "Epoch 173/200, Iteration 247/250, Loss: 0.0307\n",
      "Epoch 173/200, Iteration 248/250, Loss: 0.0069\n",
      "Epoch 173/200, Iteration 249/250, Loss: 0.0164\n",
      "Epoch 173/200, Iteration 250/250, Loss: 0.0157\n",
      "Train Error: \n",
      " Accuracy: 85.25%, Avg loss: 0.006911, MRE: 0.455006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.007421, MRE: 0.526458 \n",
      "\n",
      "Epoch 174/200, Iteration 1/250, Loss: 0.0161\n",
      "Epoch 174/200, Iteration 2/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 3/250, Loss: 0.0219\n",
      "Epoch 174/200, Iteration 4/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 5/250, Loss: 0.0169\n",
      "Epoch 174/200, Iteration 6/250, Loss: 0.0103\n",
      "Epoch 174/200, Iteration 7/250, Loss: 0.0130\n",
      "Epoch 174/200, Iteration 8/250, Loss: 0.0272\n",
      "Epoch 174/200, Iteration 9/250, Loss: 0.0093\n",
      "Epoch 174/200, Iteration 10/250, Loss: 0.0148\n",
      "Epoch 174/200, Iteration 11/250, Loss: 0.0126\n",
      "Epoch 174/200, Iteration 12/250, Loss: 0.0149\n",
      "Epoch 174/200, Iteration 13/250, Loss: 0.0264\n",
      "Epoch 174/200, Iteration 14/250, Loss: 0.0132\n",
      "Epoch 174/200, Iteration 15/250, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 16/250, Loss: 0.0135\n",
      "Epoch 174/200, Iteration 17/250, Loss: 0.0157\n",
      "Epoch 174/200, Iteration 18/250, Loss: 0.0164\n",
      "Epoch 174/200, Iteration 19/250, Loss: 0.0124\n",
      "Epoch 174/200, Iteration 20/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 21/250, Loss: 0.0168\n",
      "Epoch 174/200, Iteration 22/250, Loss: 0.0090\n",
      "Epoch 174/200, Iteration 23/250, Loss: 0.0145\n",
      "Epoch 174/200, Iteration 24/250, Loss: 0.0249\n",
      "Epoch 174/200, Iteration 25/250, Loss: 0.0160\n",
      "Epoch 174/200, Iteration 26/250, Loss: 0.0121\n",
      "Epoch 174/200, Iteration 27/250, Loss: 0.0148\n",
      "Epoch 174/200, Iteration 28/250, Loss: 0.0120\n",
      "Epoch 174/200, Iteration 29/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 30/250, Loss: 0.0169\n",
      "Epoch 174/200, Iteration 31/250, Loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200, Iteration 32/250, Loss: 0.0087\n",
      "Epoch 174/200, Iteration 33/250, Loss: 0.0158\n",
      "Epoch 174/200, Iteration 34/250, Loss: 0.0151\n",
      "Epoch 174/200, Iteration 35/250, Loss: 0.0115\n",
      "Epoch 174/200, Iteration 36/250, Loss: 0.0158\n",
      "Epoch 174/200, Iteration 37/250, Loss: 0.0073\n",
      "Epoch 174/200, Iteration 38/250, Loss: 0.0121\n",
      "Epoch 174/200, Iteration 39/250, Loss: 0.0436\n",
      "Epoch 174/200, Iteration 40/250, Loss: 0.0147\n",
      "Epoch 174/200, Iteration 41/250, Loss: 0.0088\n",
      "Epoch 174/200, Iteration 42/250, Loss: 0.0148\n",
      "Epoch 174/200, Iteration 43/250, Loss: 0.0092\n",
      "Epoch 174/200, Iteration 44/250, Loss: 0.0286\n",
      "Epoch 174/200, Iteration 45/250, Loss: 0.0137\n",
      "Epoch 174/200, Iteration 46/250, Loss: 0.0098\n",
      "Epoch 174/200, Iteration 47/250, Loss: 0.0377\n",
      "Epoch 174/200, Iteration 48/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 49/250, Loss: 0.0175\n",
      "Epoch 174/200, Iteration 50/250, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 51/250, Loss: 0.0182\n",
      "Epoch 174/200, Iteration 52/250, Loss: 0.0298\n",
      "Epoch 174/200, Iteration 53/250, Loss: 0.0121\n",
      "Epoch 174/200, Iteration 54/250, Loss: 0.0218\n",
      "Epoch 174/200, Iteration 55/250, Loss: 0.0258\n",
      "Epoch 174/200, Iteration 56/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 57/250, Loss: 0.0088\n",
      "Epoch 174/200, Iteration 58/250, Loss: 0.0225\n",
      "Epoch 174/200, Iteration 59/250, Loss: 0.0158\n",
      "Epoch 174/200, Iteration 60/250, Loss: 0.0188\n",
      "Epoch 174/200, Iteration 61/250, Loss: 0.0275\n",
      "Epoch 174/200, Iteration 62/250, Loss: 0.0119\n",
      "Epoch 174/200, Iteration 63/250, Loss: 0.0216\n",
      "Epoch 174/200, Iteration 64/250, Loss: 0.0184\n",
      "Epoch 174/200, Iteration 65/250, Loss: 0.0117\n",
      "Epoch 174/200, Iteration 66/250, Loss: 0.0475\n",
      "Epoch 174/200, Iteration 67/250, Loss: 0.0110\n",
      "Epoch 174/200, Iteration 68/250, Loss: 0.0145\n",
      "Epoch 174/200, Iteration 69/250, Loss: 0.0365\n",
      "Epoch 174/200, Iteration 70/250, Loss: 0.0093\n",
      "Epoch 174/200, Iteration 71/250, Loss: 0.0093\n",
      "Epoch 174/200, Iteration 72/250, Loss: 0.0138\n",
      "Epoch 174/200, Iteration 73/250, Loss: 0.0113\n",
      "Epoch 174/200, Iteration 74/250, Loss: 0.0112\n",
      "Epoch 174/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 76/250, Loss: 0.0230\n",
      "Epoch 174/200, Iteration 77/250, Loss: 0.0094\n",
      "Epoch 174/200, Iteration 78/250, Loss: 0.0113\n",
      "Epoch 174/200, Iteration 79/250, Loss: 0.0153\n",
      "Epoch 174/200, Iteration 80/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 81/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 82/250, Loss: 0.0080\n",
      "Epoch 174/200, Iteration 83/250, Loss: 0.0122\n",
      "Epoch 174/200, Iteration 84/250, Loss: 0.0077\n",
      "Epoch 174/200, Iteration 85/250, Loss: 0.0142\n",
      "Epoch 174/200, Iteration 86/250, Loss: 0.0300\n",
      "Epoch 174/200, Iteration 87/250, Loss: 0.0222\n",
      "Epoch 174/200, Iteration 88/250, Loss: 0.0154\n",
      "Epoch 174/200, Iteration 89/250, Loss: 0.0135\n",
      "Epoch 174/200, Iteration 90/250, Loss: 0.0153\n",
      "Epoch 174/200, Iteration 91/250, Loss: 0.0147\n",
      "Epoch 174/200, Iteration 92/250, Loss: 0.0077\n",
      "Epoch 174/200, Iteration 93/250, Loss: 0.0179\n",
      "Epoch 174/200, Iteration 94/250, Loss: 0.0103\n",
      "Epoch 174/200, Iteration 95/250, Loss: 0.0228\n",
      "Epoch 174/200, Iteration 96/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 97/250, Loss: 0.0193\n",
      "Epoch 174/200, Iteration 98/250, Loss: 0.0135\n",
      "Epoch 174/200, Iteration 99/250, Loss: 0.0171\n",
      "Epoch 174/200, Iteration 100/250, Loss: 0.0108\n",
      "Epoch 174/200, Iteration 101/250, Loss: 0.0144\n",
      "Epoch 174/200, Iteration 102/250, Loss: 0.0218\n",
      "Epoch 174/200, Iteration 103/250, Loss: 0.0074\n",
      "Epoch 174/200, Iteration 104/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 105/250, Loss: 0.0112\n",
      "Epoch 174/200, Iteration 106/250, Loss: 0.0118\n",
      "Epoch 174/200, Iteration 107/250, Loss: 0.0289\n",
      "Epoch 174/200, Iteration 108/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 109/250, Loss: 0.0101\n",
      "Epoch 174/200, Iteration 110/250, Loss: 0.0106\n",
      "Epoch 174/200, Iteration 111/250, Loss: 0.0101\n",
      "Epoch 174/200, Iteration 112/250, Loss: 0.0241\n",
      "Epoch 174/200, Iteration 113/250, Loss: 0.0106\n",
      "Epoch 174/200, Iteration 114/250, Loss: 0.0181\n",
      "Epoch 174/200, Iteration 115/250, Loss: 0.0333\n",
      "Epoch 174/200, Iteration 116/250, Loss: 0.0140\n",
      "Epoch 174/200, Iteration 117/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 118/250, Loss: 0.0254\n",
      "Epoch 174/200, Iteration 119/250, Loss: 0.0124\n",
      "Epoch 174/200, Iteration 120/250, Loss: 0.0095\n",
      "Epoch 174/200, Iteration 121/250, Loss: 0.0272\n",
      "Epoch 174/200, Iteration 122/250, Loss: 0.0125\n",
      "Epoch 174/200, Iteration 123/250, Loss: 0.0126\n",
      "Epoch 174/200, Iteration 124/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 125/250, Loss: 0.0174\n",
      "Epoch 174/200, Iteration 126/250, Loss: 0.0165\n",
      "Epoch 174/200, Iteration 127/250, Loss: 0.0308\n",
      "Epoch 174/200, Iteration 128/250, Loss: 0.0162\n",
      "Epoch 174/200, Iteration 129/250, Loss: 0.0268\n",
      "Epoch 174/200, Iteration 130/250, Loss: 0.0207\n",
      "Epoch 174/200, Iteration 131/250, Loss: 0.0306\n",
      "Epoch 174/200, Iteration 132/250, Loss: 0.0110\n",
      "Epoch 174/200, Iteration 133/250, Loss: 0.0107\n",
      "Epoch 174/200, Iteration 134/250, Loss: 0.0084\n",
      "Epoch 174/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 136/250, Loss: 0.0191\n",
      "Epoch 174/200, Iteration 137/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 138/250, Loss: 0.0380\n",
      "Epoch 174/200, Iteration 139/250, Loss: 0.0153\n",
      "Epoch 174/200, Iteration 140/250, Loss: 0.0268\n",
      "Epoch 174/200, Iteration 141/250, Loss: 0.0148\n",
      "Epoch 174/200, Iteration 142/250, Loss: 0.0217\n",
      "Epoch 174/200, Iteration 143/250, Loss: 0.0216\n",
      "Epoch 174/200, Iteration 144/250, Loss: 0.0215\n",
      "Epoch 174/200, Iteration 145/250, Loss: 0.0351\n",
      "Epoch 174/200, Iteration 146/250, Loss: 0.0117\n",
      "Epoch 174/200, Iteration 147/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 148/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 149/250, Loss: 0.0062\n",
      "Epoch 174/200, Iteration 150/250, Loss: 0.0132\n",
      "Epoch 174/200, Iteration 151/250, Loss: 0.0258\n",
      "Epoch 174/200, Iteration 152/250, Loss: 0.0330\n",
      "Epoch 174/200, Iteration 153/250, Loss: 0.0137\n",
      "Epoch 174/200, Iteration 154/250, Loss: 0.0167\n",
      "Epoch 174/200, Iteration 155/250, Loss: 0.0329\n",
      "Epoch 174/200, Iteration 156/250, Loss: 0.0118\n",
      "Epoch 174/200, Iteration 157/250, Loss: 0.0199\n",
      "Epoch 174/200, Iteration 158/250, Loss: 0.0091\n",
      "Epoch 174/200, Iteration 159/250, Loss: 0.0148\n",
      "Epoch 174/200, Iteration 160/250, Loss: 0.0139\n",
      "Epoch 174/200, Iteration 161/250, Loss: 0.0124\n",
      "Epoch 174/200, Iteration 162/250, Loss: 0.0126\n",
      "Epoch 174/200, Iteration 163/250, Loss: 0.0141\n",
      "Epoch 174/200, Iteration 164/250, Loss: 0.0390\n",
      "Epoch 174/200, Iteration 165/250, Loss: 0.0187\n",
      "Epoch 174/200, Iteration 166/250, Loss: 0.0204\n",
      "Epoch 174/200, Iteration 167/250, Loss: 0.0256\n",
      "Epoch 174/200, Iteration 168/250, Loss: 0.0189\n",
      "Epoch 174/200, Iteration 169/250, Loss: 0.0324\n",
      "Epoch 174/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 174/200, Iteration 171/250, Loss: 0.0213\n",
      "Epoch 174/200, Iteration 172/250, Loss: 0.0111\n",
      "Epoch 174/200, Iteration 173/250, Loss: 0.0239\n",
      "Epoch 174/200, Iteration 174/250, Loss: 0.0320\n",
      "Epoch 174/200, Iteration 175/250, Loss: 0.0511\n",
      "Epoch 174/200, Iteration 176/250, Loss: 0.0305\n",
      "Epoch 174/200, Iteration 177/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 178/250, Loss: 0.0225\n",
      "Epoch 174/200, Iteration 179/250, Loss: 0.0267\n",
      "Epoch 174/200, Iteration 180/250, Loss: 0.0221\n",
      "Epoch 174/200, Iteration 181/250, Loss: 0.0141\n",
      "Epoch 174/200, Iteration 182/250, Loss: 0.0093\n",
      "Epoch 174/200, Iteration 183/250, Loss: 0.0311\n",
      "Epoch 174/200, Iteration 184/250, Loss: 0.0164\n",
      "Epoch 174/200, Iteration 185/250, Loss: 0.0085\n",
      "Epoch 174/200, Iteration 186/250, Loss: 0.0083\n",
      "Epoch 174/200, Iteration 187/250, Loss: 0.0121\n",
      "Epoch 174/200, Iteration 188/250, Loss: 0.0141\n",
      "Epoch 174/200, Iteration 189/250, Loss: 0.0492\n",
      "Epoch 174/200, Iteration 190/250, Loss: 0.0066\n",
      "Epoch 174/200, Iteration 191/250, Loss: 0.0197\n",
      "Epoch 174/200, Iteration 192/250, Loss: 0.0098\n",
      "Epoch 174/200, Iteration 193/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 194/250, Loss: 0.0113\n",
      "Epoch 174/200, Iteration 195/250, Loss: 0.0118\n",
      "Epoch 174/200, Iteration 196/250, Loss: 0.0127\n",
      "Epoch 174/200, Iteration 197/250, Loss: 0.0113\n",
      "Epoch 174/200, Iteration 198/250, Loss: 0.0108\n",
      "Epoch 174/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 200/250, Loss: 0.0081\n",
      "Epoch 174/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 174/200, Iteration 202/250, Loss: 0.0180\n",
      "Epoch 174/200, Iteration 203/250, Loss: 0.0119\n",
      "Epoch 174/200, Iteration 204/250, Loss: 0.0104\n",
      "Epoch 174/200, Iteration 205/250, Loss: 0.0116\n",
      "Epoch 174/200, Iteration 206/250, Loss: 0.0095\n",
      "Epoch 174/200, Iteration 207/250, Loss: 0.0242\n",
      "Epoch 174/200, Iteration 208/250, Loss: 0.0200\n",
      "Epoch 174/200, Iteration 209/250, Loss: 0.0198\n",
      "Epoch 174/200, Iteration 210/250, Loss: 0.0208\n",
      "Epoch 174/200, Iteration 211/250, Loss: 0.0172\n",
      "Epoch 174/200, Iteration 212/250, Loss: 0.0162\n",
      "Epoch 174/200, Iteration 213/250, Loss: 0.0111\n",
      "Epoch 174/200, Iteration 214/250, Loss: 0.0092\n",
      "Epoch 174/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 174/200, Iteration 216/250, Loss: 0.0125\n",
      "Epoch 174/200, Iteration 217/250, Loss: 0.0105\n",
      "Epoch 174/200, Iteration 218/250, Loss: 0.0138\n",
      "Epoch 174/200, Iteration 219/250, Loss: 0.0103\n",
      "Epoch 174/200, Iteration 220/250, Loss: 0.0121\n",
      "Epoch 174/200, Iteration 221/250, Loss: 0.0100\n",
      "Epoch 174/200, Iteration 222/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 223/250, Loss: 0.0198\n",
      "Epoch 174/200, Iteration 224/250, Loss: 0.0109\n",
      "Epoch 174/200, Iteration 225/250, Loss: 0.0088\n",
      "Epoch 174/200, Iteration 226/250, Loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200, Iteration 227/250, Loss: 0.0124\n",
      "Epoch 174/200, Iteration 228/250, Loss: 0.0112\n",
      "Epoch 174/200, Iteration 229/250, Loss: 0.0192\n",
      "Epoch 174/200, Iteration 230/250, Loss: 0.0095\n",
      "Epoch 174/200, Iteration 231/250, Loss: 0.0114\n",
      "Epoch 174/200, Iteration 232/250, Loss: 0.0252\n",
      "Epoch 174/200, Iteration 233/250, Loss: 0.0170\n",
      "Epoch 174/200, Iteration 234/250, Loss: 0.0103\n",
      "Epoch 174/200, Iteration 235/250, Loss: 0.0106\n",
      "Epoch 174/200, Iteration 236/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 237/250, Loss: 0.0118\n",
      "Epoch 174/200, Iteration 238/250, Loss: 0.0204\n",
      "Epoch 174/200, Iteration 239/250, Loss: 0.0279\n",
      "Epoch 174/200, Iteration 240/250, Loss: 0.0081\n",
      "Epoch 174/200, Iteration 241/250, Loss: 0.0128\n",
      "Epoch 174/200, Iteration 242/250, Loss: 0.0152\n",
      "Epoch 174/200, Iteration 243/250, Loss: 0.0160\n",
      "Epoch 174/200, Iteration 244/250, Loss: 0.0172\n",
      "Epoch 174/200, Iteration 245/250, Loss: 0.0241\n",
      "Epoch 174/200, Iteration 246/250, Loss: 0.0120\n",
      "Epoch 174/200, Iteration 247/250, Loss: 0.0175\n",
      "Epoch 174/200, Iteration 248/250, Loss: 0.0065\n",
      "Epoch 174/200, Iteration 249/250, Loss: 0.0127\n",
      "Epoch 174/200, Iteration 250/250, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 83.43%, Avg loss: 0.006964, MRE: 0.465083 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.007461, MRE: 0.550785 \n",
      "\n",
      "Epoch 175/200, Iteration 1/250, Loss: 0.0184\n",
      "Epoch 175/200, Iteration 2/250, Loss: 0.0346\n",
      "Epoch 175/200, Iteration 3/250, Loss: 0.0087\n",
      "Epoch 175/200, Iteration 4/250, Loss: 0.0160\n",
      "Epoch 175/200, Iteration 5/250, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 6/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 7/250, Loss: 0.0115\n",
      "Epoch 175/200, Iteration 8/250, Loss: 0.0290\n",
      "Epoch 175/200, Iteration 9/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 10/250, Loss: 0.0090\n",
      "Epoch 175/200, Iteration 11/250, Loss: 0.0128\n",
      "Epoch 175/200, Iteration 12/250, Loss: 0.0077\n",
      "Epoch 175/200, Iteration 13/250, Loss: 0.0119\n",
      "Epoch 175/200, Iteration 14/250, Loss: 0.0219\n",
      "Epoch 175/200, Iteration 15/250, Loss: 0.0099\n",
      "Epoch 175/200, Iteration 16/250, Loss: 0.0127\n",
      "Epoch 175/200, Iteration 17/250, Loss: 0.0108\n",
      "Epoch 175/200, Iteration 18/250, Loss: 0.0059\n",
      "Epoch 175/200, Iteration 19/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 20/250, Loss: 0.0131\n",
      "Epoch 175/200, Iteration 21/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 22/250, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 23/250, Loss: 0.0171\n",
      "Epoch 175/200, Iteration 24/250, Loss: 0.0109\n",
      "Epoch 175/200, Iteration 25/250, Loss: 0.0183\n",
      "Epoch 175/200, Iteration 26/250, Loss: 0.0167\n",
      "Epoch 175/200, Iteration 27/250, Loss: 0.0150\n",
      "Epoch 175/200, Iteration 28/250, Loss: 0.0145\n",
      "Epoch 175/200, Iteration 29/250, Loss: 0.0219\n",
      "Epoch 175/200, Iteration 30/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 31/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 32/250, Loss: 0.0318\n",
      "Epoch 175/200, Iteration 33/250, Loss: 0.0290\n",
      "Epoch 175/200, Iteration 34/250, Loss: 0.0071\n",
      "Epoch 175/200, Iteration 35/250, Loss: 0.0148\n",
      "Epoch 175/200, Iteration 36/250, Loss: 0.0179\n",
      "Epoch 175/200, Iteration 37/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 39/250, Loss: 0.0143\n",
      "Epoch 175/200, Iteration 40/250, Loss: 0.0253\n",
      "Epoch 175/200, Iteration 41/250, Loss: 0.0141\n",
      "Epoch 175/200, Iteration 42/250, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 43/250, Loss: 0.0156\n",
      "Epoch 175/200, Iteration 44/250, Loss: 0.0282\n",
      "Epoch 175/200, Iteration 45/250, Loss: 0.0267\n",
      "Epoch 175/200, Iteration 46/250, Loss: 0.0215\n",
      "Epoch 175/200, Iteration 47/250, Loss: 0.0164\n",
      "Epoch 175/200, Iteration 48/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 49/250, Loss: 0.0094\n",
      "Epoch 175/200, Iteration 50/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 51/250, Loss: 0.0173\n",
      "Epoch 175/200, Iteration 52/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 53/250, Loss: 0.0289\n",
      "Epoch 175/200, Iteration 54/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 55/250, Loss: 0.0197\n",
      "Epoch 175/200, Iteration 56/250, Loss: 0.0229\n",
      "Epoch 175/200, Iteration 57/250, Loss: 0.0096\n",
      "Epoch 175/200, Iteration 58/250, Loss: 0.0101\n",
      "Epoch 175/200, Iteration 59/250, Loss: 0.0164\n",
      "Epoch 175/200, Iteration 60/250, Loss: 0.0071\n",
      "Epoch 175/200, Iteration 61/250, Loss: 0.0102\n",
      "Epoch 175/200, Iteration 62/250, Loss: 0.0125\n",
      "Epoch 175/200, Iteration 63/250, Loss: 0.0125\n",
      "Epoch 175/200, Iteration 64/250, Loss: 0.0065\n",
      "Epoch 175/200, Iteration 65/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 66/250, Loss: 0.0271\n",
      "Epoch 175/200, Iteration 67/250, Loss: 0.0507\n",
      "Epoch 175/200, Iteration 68/250, Loss: 0.0153\n",
      "Epoch 175/200, Iteration 69/250, Loss: 0.0191\n",
      "Epoch 175/200, Iteration 70/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 71/250, Loss: 0.0109\n",
      "Epoch 175/200, Iteration 72/250, Loss: 0.0288\n",
      "Epoch 175/200, Iteration 73/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 74/250, Loss: 0.0116\n",
      "Epoch 175/200, Iteration 75/250, Loss: 0.0073\n",
      "Epoch 175/200, Iteration 76/250, Loss: 0.0083\n",
      "Epoch 175/200, Iteration 77/250, Loss: 0.0329\n",
      "Epoch 175/200, Iteration 78/250, Loss: 0.0136\n",
      "Epoch 175/200, Iteration 79/250, Loss: 0.0075\n",
      "Epoch 175/200, Iteration 80/250, Loss: 0.0086\n",
      "Epoch 175/200, Iteration 81/250, Loss: 0.0260\n",
      "Epoch 175/200, Iteration 82/250, Loss: 0.0219\n",
      "Epoch 175/200, Iteration 83/250, Loss: 0.0117\n",
      "Epoch 175/200, Iteration 84/250, Loss: 0.0132\n",
      "Epoch 175/200, Iteration 85/250, Loss: 0.0139\n",
      "Epoch 175/200, Iteration 86/250, Loss: 0.0079\n",
      "Epoch 175/200, Iteration 87/250, Loss: 0.0316\n",
      "Epoch 175/200, Iteration 88/250, Loss: 0.0079\n",
      "Epoch 175/200, Iteration 89/250, Loss: 0.0066\n",
      "Epoch 175/200, Iteration 90/250, Loss: 0.0110\n",
      "Epoch 175/200, Iteration 91/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 92/250, Loss: 0.0093\n",
      "Epoch 175/200, Iteration 93/250, Loss: 0.0166\n",
      "Epoch 175/200, Iteration 94/250, Loss: 0.0075\n",
      "Epoch 175/200, Iteration 95/250, Loss: 0.0081\n",
      "Epoch 175/200, Iteration 96/250, Loss: 0.0183\n",
      "Epoch 175/200, Iteration 97/250, Loss: 0.0126\n",
      "Epoch 175/200, Iteration 98/250, Loss: 0.0180\n",
      "Epoch 175/200, Iteration 99/250, Loss: 0.0104\n",
      "Epoch 175/200, Iteration 100/250, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 101/250, Loss: 0.0228\n",
      "Epoch 175/200, Iteration 102/250, Loss: 0.0116\n",
      "Epoch 175/200, Iteration 103/250, Loss: 0.0106\n",
      "Epoch 175/200, Iteration 104/250, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 105/250, Loss: 0.0179\n",
      "Epoch 175/200, Iteration 106/250, Loss: 0.0141\n",
      "Epoch 175/200, Iteration 107/250, Loss: 0.0256\n",
      "Epoch 175/200, Iteration 108/250, Loss: 0.0145\n",
      "Epoch 175/200, Iteration 109/250, Loss: 0.0194\n",
      "Epoch 175/200, Iteration 110/250, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 111/250, Loss: 0.0258\n",
      "Epoch 175/200, Iteration 112/250, Loss: 0.0220\n",
      "Epoch 175/200, Iteration 113/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 114/250, Loss: 0.0076\n",
      "Epoch 175/200, Iteration 115/250, Loss: 0.0077\n",
      "Epoch 175/200, Iteration 116/250, Loss: 0.0082\n",
      "Epoch 175/200, Iteration 117/250, Loss: 0.0296\n",
      "Epoch 175/200, Iteration 118/250, Loss: 0.0198\n",
      "Epoch 175/200, Iteration 119/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 120/250, Loss: 0.0179\n",
      "Epoch 175/200, Iteration 121/250, Loss: 0.0073\n",
      "Epoch 175/200, Iteration 122/250, Loss: 0.0075\n",
      "Epoch 175/200, Iteration 123/250, Loss: 0.0156\n",
      "Epoch 175/200, Iteration 124/250, Loss: 0.0283\n",
      "Epoch 175/200, Iteration 125/250, Loss: 0.0131\n",
      "Epoch 175/200, Iteration 126/250, Loss: 0.0082\n",
      "Epoch 175/200, Iteration 127/250, Loss: 0.0152\n",
      "Epoch 175/200, Iteration 128/250, Loss: 0.0199\n",
      "Epoch 175/200, Iteration 129/250, Loss: 0.0129\n",
      "Epoch 175/200, Iteration 130/250, Loss: 0.0208\n",
      "Epoch 175/200, Iteration 131/250, Loss: 0.0149\n",
      "Epoch 175/200, Iteration 132/250, Loss: 0.0120\n",
      "Epoch 175/200, Iteration 133/250, Loss: 0.0089\n",
      "Epoch 175/200, Iteration 134/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 135/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 136/250, Loss: 0.0108\n",
      "Epoch 175/200, Iteration 137/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 138/250, Loss: 0.0108\n",
      "Epoch 175/200, Iteration 139/250, Loss: 0.0145\n",
      "Epoch 175/200, Iteration 140/250, Loss: 0.0118\n",
      "Epoch 175/200, Iteration 141/250, Loss: 0.0135\n",
      "Epoch 175/200, Iteration 142/250, Loss: 0.0075\n",
      "Epoch 175/200, Iteration 143/250, Loss: 0.0081\n",
      "Epoch 175/200, Iteration 144/250, Loss: 0.0091\n",
      "Epoch 175/200, Iteration 145/250, Loss: 0.0137\n",
      "Epoch 175/200, Iteration 146/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 147/250, Loss: 0.0129\n",
      "Epoch 175/200, Iteration 148/250, Loss: 0.0087\n",
      "Epoch 175/200, Iteration 149/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 150/250, Loss: 0.0146\n",
      "Epoch 175/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 175/200, Iteration 152/250, Loss: 0.0152\n",
      "Epoch 175/200, Iteration 153/250, Loss: 0.0228\n",
      "Epoch 175/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 175/200, Iteration 155/250, Loss: 0.0173\n",
      "Epoch 175/200, Iteration 156/250, Loss: 0.0089\n",
      "Epoch 175/200, Iteration 157/250, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200, Iteration 158/250, Loss: 0.0232\n",
      "Epoch 175/200, Iteration 159/250, Loss: 0.0309\n",
      "Epoch 175/200, Iteration 160/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 161/250, Loss: 0.0105\n",
      "Epoch 175/200, Iteration 162/250, Loss: 0.0209\n",
      "Epoch 175/200, Iteration 163/250, Loss: 0.0216\n",
      "Epoch 175/200, Iteration 164/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 165/250, Loss: 0.0178\n",
      "Epoch 175/200, Iteration 166/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 167/250, Loss: 0.0139\n",
      "Epoch 175/200, Iteration 168/250, Loss: 0.0237\n",
      "Epoch 175/200, Iteration 169/250, Loss: 0.0097\n",
      "Epoch 175/200, Iteration 170/250, Loss: 0.0178\n",
      "Epoch 175/200, Iteration 171/250, Loss: 0.0055\n",
      "Epoch 175/200, Iteration 172/250, Loss: 0.0181\n",
      "Epoch 175/200, Iteration 173/250, Loss: 0.0180\n",
      "Epoch 175/200, Iteration 174/250, Loss: 0.0142\n",
      "Epoch 175/200, Iteration 175/250, Loss: 0.0154\n",
      "Epoch 175/200, Iteration 176/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 177/250, Loss: 0.0098\n",
      "Epoch 175/200, Iteration 178/250, Loss: 0.0127\n",
      "Epoch 175/200, Iteration 179/250, Loss: 0.0109\n",
      "Epoch 175/200, Iteration 180/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 181/250, Loss: 0.0093\n",
      "Epoch 175/200, Iteration 182/250, Loss: 0.0073\n",
      "Epoch 175/200, Iteration 183/250, Loss: 0.0155\n",
      "Epoch 175/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 185/250, Loss: 0.0145\n",
      "Epoch 175/200, Iteration 186/250, Loss: 0.0134\n",
      "Epoch 175/200, Iteration 187/250, Loss: 0.0159\n",
      "Epoch 175/200, Iteration 188/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 189/250, Loss: 0.0155\n",
      "Epoch 175/200, Iteration 190/250, Loss: 0.0258\n",
      "Epoch 175/200, Iteration 191/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 192/250, Loss: 0.0101\n",
      "Epoch 175/200, Iteration 193/250, Loss: 0.0314\n",
      "Epoch 175/200, Iteration 194/250, Loss: 0.0223\n",
      "Epoch 175/200, Iteration 195/250, Loss: 0.0228\n",
      "Epoch 175/200, Iteration 196/250, Loss: 0.0265\n",
      "Epoch 175/200, Iteration 197/250, Loss: 0.0229\n",
      "Epoch 175/200, Iteration 198/250, Loss: 0.0178\n",
      "Epoch 175/200, Iteration 199/250, Loss: 0.0124\n",
      "Epoch 175/200, Iteration 200/250, Loss: 0.0350\n",
      "Epoch 175/200, Iteration 201/250, Loss: 0.0130\n",
      "Epoch 175/200, Iteration 202/250, Loss: 0.0157\n",
      "Epoch 175/200, Iteration 203/250, Loss: 0.0157\n",
      "Epoch 175/200, Iteration 204/250, Loss: 0.0224\n",
      "Epoch 175/200, Iteration 205/250, Loss: 0.0217\n",
      "Epoch 175/200, Iteration 206/250, Loss: 0.0183\n",
      "Epoch 175/200, Iteration 207/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 208/250, Loss: 0.0253\n",
      "Epoch 175/200, Iteration 209/250, Loss: 0.0098\n",
      "Epoch 175/200, Iteration 210/250, Loss: 0.0111\n",
      "Epoch 175/200, Iteration 211/250, Loss: 0.0249\n",
      "Epoch 175/200, Iteration 212/250, Loss: 0.0177\n",
      "Epoch 175/200, Iteration 213/250, Loss: 0.0202\n",
      "Epoch 175/200, Iteration 214/250, Loss: 0.0153\n",
      "Epoch 175/200, Iteration 215/250, Loss: 0.0168\n",
      "Epoch 175/200, Iteration 216/250, Loss: 0.0107\n",
      "Epoch 175/200, Iteration 217/250, Loss: 0.0142\n",
      "Epoch 175/200, Iteration 218/250, Loss: 0.0188\n",
      "Epoch 175/200, Iteration 219/250, Loss: 0.0114\n",
      "Epoch 175/200, Iteration 220/250, Loss: 0.0084\n",
      "Epoch 175/200, Iteration 221/250, Loss: 0.0104\n",
      "Epoch 175/200, Iteration 222/250, Loss: 0.0089\n",
      "Epoch 175/200, Iteration 223/250, Loss: 0.0103\n",
      "Epoch 175/200, Iteration 224/250, Loss: 0.0092\n",
      "Epoch 175/200, Iteration 225/250, Loss: 0.0245\n",
      "Epoch 175/200, Iteration 226/250, Loss: 0.0159\n",
      "Epoch 175/200, Iteration 227/250, Loss: 0.0144\n",
      "Epoch 175/200, Iteration 228/250, Loss: 0.0110\n",
      "Epoch 175/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 175/200, Iteration 230/250, Loss: 0.0142\n",
      "Epoch 175/200, Iteration 231/250, Loss: 0.0116\n",
      "Epoch 175/200, Iteration 232/250, Loss: 0.0201\n",
      "Epoch 175/200, Iteration 233/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 234/250, Loss: 0.0130\n",
      "Epoch 175/200, Iteration 235/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 236/250, Loss: 0.0150\n",
      "Epoch 175/200, Iteration 237/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 238/250, Loss: 0.0194\n",
      "Epoch 175/200, Iteration 239/250, Loss: 0.0151\n",
      "Epoch 175/200, Iteration 240/250, Loss: 0.0086\n",
      "Epoch 175/200, Iteration 241/250, Loss: 0.0183\n",
      "Epoch 175/200, Iteration 242/250, Loss: 0.0191\n",
      "Epoch 175/200, Iteration 243/250, Loss: 0.0131\n",
      "Epoch 175/200, Iteration 244/250, Loss: 0.0080\n",
      "Epoch 175/200, Iteration 245/250, Loss: 0.0247\n",
      "Epoch 175/200, Iteration 246/250, Loss: 0.0173\n",
      "Epoch 175/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 175/200, Iteration 248/250, Loss: 0.0088\n",
      "Epoch 175/200, Iteration 249/250, Loss: 0.0299\n",
      "Epoch 175/200, Iteration 250/250, Loss: 0.0079\n",
      "Train Error: \n",
      " Accuracy: 88.21%, Avg loss: 0.006787, MRE: 0.474595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.65%, Avg loss: 0.007255, MRE: 0.491733 \n",
      "\n",
      "Epoch 176/200, Iteration 1/250, Loss: 0.0135\n",
      "Epoch 176/200, Iteration 2/250, Loss: 0.0155\n",
      "Epoch 176/200, Iteration 3/250, Loss: 0.0086\n",
      "Epoch 176/200, Iteration 4/250, Loss: 0.0171\n",
      "Epoch 176/200, Iteration 5/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 6/250, Loss: 0.0174\n",
      "Epoch 176/200, Iteration 7/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 8/250, Loss: 0.0197\n",
      "Epoch 176/200, Iteration 9/250, Loss: 0.0144\n",
      "Epoch 176/200, Iteration 10/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 11/250, Loss: 0.0078\n",
      "Epoch 176/200, Iteration 12/250, Loss: 0.0124\n",
      "Epoch 176/200, Iteration 13/250, Loss: 0.0225\n",
      "Epoch 176/200, Iteration 14/250, Loss: 0.0163\n",
      "Epoch 176/200, Iteration 15/250, Loss: 0.0093\n",
      "Epoch 176/200, Iteration 16/250, Loss: 0.0135\n",
      "Epoch 176/200, Iteration 17/250, Loss: 0.0112\n",
      "Epoch 176/200, Iteration 18/250, Loss: 0.0170\n",
      "Epoch 176/200, Iteration 19/250, Loss: 0.0079\n",
      "Epoch 176/200, Iteration 20/250, Loss: 0.0184\n",
      "Epoch 176/200, Iteration 21/250, Loss: 0.0086\n",
      "Epoch 176/200, Iteration 22/250, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 23/250, Loss: 0.0107\n",
      "Epoch 176/200, Iteration 24/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 25/250, Loss: 0.0147\n",
      "Epoch 176/200, Iteration 26/250, Loss: 0.0295\n",
      "Epoch 176/200, Iteration 27/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 28/250, Loss: 0.0144\n",
      "Epoch 176/200, Iteration 29/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 30/250, Loss: 0.0279\n",
      "Epoch 176/200, Iteration 31/250, Loss: 0.0248\n",
      "Epoch 176/200, Iteration 32/250, Loss: 0.0234\n",
      "Epoch 176/200, Iteration 33/250, Loss: 0.0145\n",
      "Epoch 176/200, Iteration 34/250, Loss: 0.0118\n",
      "Epoch 176/200, Iteration 35/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 36/250, Loss: 0.0142\n",
      "Epoch 176/200, Iteration 37/250, Loss: 0.0135\n",
      "Epoch 176/200, Iteration 38/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 39/250, Loss: 0.0277\n",
      "Epoch 176/200, Iteration 40/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 41/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 42/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 43/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 44/250, Loss: 0.0096\n",
      "Epoch 176/200, Iteration 45/250, Loss: 0.0176\n",
      "Epoch 176/200, Iteration 46/250, Loss: 0.0084\n",
      "Epoch 176/200, Iteration 47/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 48/250, Loss: 0.0253\n",
      "Epoch 176/200, Iteration 49/250, Loss: 0.0164\n",
      "Epoch 176/200, Iteration 50/250, Loss: 0.0097\n",
      "Epoch 176/200, Iteration 51/250, Loss: 0.0067\n",
      "Epoch 176/200, Iteration 52/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 53/250, Loss: 0.0149\n",
      "Epoch 176/200, Iteration 54/250, Loss: 0.0151\n",
      "Epoch 176/200, Iteration 55/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 56/250, Loss: 0.0095\n",
      "Epoch 176/200, Iteration 57/250, Loss: 0.0298\n",
      "Epoch 176/200, Iteration 58/250, Loss: 0.0086\n",
      "Epoch 176/200, Iteration 59/250, Loss: 0.0092\n",
      "Epoch 176/200, Iteration 60/250, Loss: 0.0388\n",
      "Epoch 176/200, Iteration 61/250, Loss: 0.0095\n",
      "Epoch 176/200, Iteration 62/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 63/250, Loss: 0.0305\n",
      "Epoch 176/200, Iteration 64/250, Loss: 0.0157\n",
      "Epoch 176/200, Iteration 65/250, Loss: 0.0202\n",
      "Epoch 176/200, Iteration 66/250, Loss: 0.0149\n",
      "Epoch 176/200, Iteration 67/250, Loss: 0.0290\n",
      "Epoch 176/200, Iteration 68/250, Loss: 0.0215\n",
      "Epoch 176/200, Iteration 69/250, Loss: 0.0124\n",
      "Epoch 176/200, Iteration 70/250, Loss: 0.0068\n",
      "Epoch 176/200, Iteration 71/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 72/250, Loss: 0.0141\n",
      "Epoch 176/200, Iteration 73/250, Loss: 0.0155\n",
      "Epoch 176/200, Iteration 74/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 75/250, Loss: 0.0073\n",
      "Epoch 176/200, Iteration 76/250, Loss: 0.0070\n",
      "Epoch 176/200, Iteration 77/250, Loss: 0.0189\n",
      "Epoch 176/200, Iteration 78/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 79/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 80/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 81/250, Loss: 0.0321\n",
      "Epoch 176/200, Iteration 82/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 83/250, Loss: 0.0128\n",
      "Epoch 176/200, Iteration 84/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 85/250, Loss: 0.0099\n",
      "Epoch 176/200, Iteration 86/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 87/250, Loss: 0.0176\n",
      "Epoch 176/200, Iteration 88/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 89/250, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200, Iteration 90/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 91/250, Loss: 0.0132\n",
      "Epoch 176/200, Iteration 92/250, Loss: 0.0140\n",
      "Epoch 176/200, Iteration 93/250, Loss: 0.0221\n",
      "Epoch 176/200, Iteration 94/250, Loss: 0.0111\n",
      "Epoch 176/200, Iteration 95/250, Loss: 0.0112\n",
      "Epoch 176/200, Iteration 96/250, Loss: 0.0232\n",
      "Epoch 176/200, Iteration 97/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 98/250, Loss: 0.0127\n",
      "Epoch 176/200, Iteration 99/250, Loss: 0.0208\n",
      "Epoch 176/200, Iteration 100/250, Loss: 0.0215\n",
      "Epoch 176/200, Iteration 101/250, Loss: 0.0070\n",
      "Epoch 176/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 176/200, Iteration 103/250, Loss: 0.0094\n",
      "Epoch 176/200, Iteration 104/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 105/250, Loss: 0.0137\n",
      "Epoch 176/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 176/200, Iteration 107/250, Loss: 0.0203\n",
      "Epoch 176/200, Iteration 108/250, Loss: 0.0159\n",
      "Epoch 176/200, Iteration 109/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 110/250, Loss: 0.0394\n",
      "Epoch 176/200, Iteration 111/250, Loss: 0.0190\n",
      "Epoch 176/200, Iteration 112/250, Loss: 0.0136\n",
      "Epoch 176/200, Iteration 113/250, Loss: 0.0191\n",
      "Epoch 176/200, Iteration 114/250, Loss: 0.0317\n",
      "Epoch 176/200, Iteration 115/250, Loss: 0.0139\n",
      "Epoch 176/200, Iteration 116/250, Loss: 0.0310\n",
      "Epoch 176/200, Iteration 117/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 118/250, Loss: 0.0154\n",
      "Epoch 176/200, Iteration 119/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 120/250, Loss: 0.0114\n",
      "Epoch 176/200, Iteration 121/250, Loss: 0.0286\n",
      "Epoch 176/200, Iteration 122/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 123/250, Loss: 0.0212\n",
      "Epoch 176/200, Iteration 124/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 125/250, Loss: 0.0080\n",
      "Epoch 176/200, Iteration 126/250, Loss: 0.0109\n",
      "Epoch 176/200, Iteration 127/250, Loss: 0.0109\n",
      "Epoch 176/200, Iteration 128/250, Loss: 0.0084\n",
      "Epoch 176/200, Iteration 129/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 130/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 131/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 132/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 133/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 134/250, Loss: 0.0094\n",
      "Epoch 176/200, Iteration 135/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 136/250, Loss: 0.0138\n",
      "Epoch 176/200, Iteration 137/250, Loss: 0.0229\n",
      "Epoch 176/200, Iteration 138/250, Loss: 0.0091\n",
      "Epoch 176/200, Iteration 139/250, Loss: 0.0256\n",
      "Epoch 176/200, Iteration 140/250, Loss: 0.0148\n",
      "Epoch 176/200, Iteration 141/250, Loss: 0.0157\n",
      "Epoch 176/200, Iteration 142/250, Loss: 0.0124\n",
      "Epoch 176/200, Iteration 143/250, Loss: 0.0092\n",
      "Epoch 176/200, Iteration 144/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 145/250, Loss: 0.0079\n",
      "Epoch 176/200, Iteration 146/250, Loss: 0.0291\n",
      "Epoch 176/200, Iteration 147/250, Loss: 0.0242\n",
      "Epoch 176/200, Iteration 148/250, Loss: 0.0136\n",
      "Epoch 176/200, Iteration 149/250, Loss: 0.0071\n",
      "Epoch 176/200, Iteration 150/250, Loss: 0.0178\n",
      "Epoch 176/200, Iteration 151/250, Loss: 0.0154\n",
      "Epoch 176/200, Iteration 152/250, Loss: 0.0278\n",
      "Epoch 176/200, Iteration 153/250, Loss: 0.0324\n",
      "Epoch 176/200, Iteration 154/250, Loss: 0.0102\n",
      "Epoch 176/200, Iteration 155/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 156/250, Loss: 0.0154\n",
      "Epoch 176/200, Iteration 157/250, Loss: 0.0088\n",
      "Epoch 176/200, Iteration 158/250, Loss: 0.0150\n",
      "Epoch 176/200, Iteration 159/250, Loss: 0.0285\n",
      "Epoch 176/200, Iteration 160/250, Loss: 0.0173\n",
      "Epoch 176/200, Iteration 161/250, Loss: 0.0167\n",
      "Epoch 176/200, Iteration 162/250, Loss: 0.0198\n",
      "Epoch 176/200, Iteration 163/250, Loss: 0.0284\n",
      "Epoch 176/200, Iteration 164/250, Loss: 0.0108\n",
      "Epoch 176/200, Iteration 165/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 166/250, Loss: 0.0131\n",
      "Epoch 176/200, Iteration 167/250, Loss: 0.0110\n",
      "Epoch 176/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 169/250, Loss: 0.0218\n",
      "Epoch 176/200, Iteration 170/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 171/250, Loss: 0.0119\n",
      "Epoch 176/200, Iteration 172/250, Loss: 0.0087\n",
      "Epoch 176/200, Iteration 173/250, Loss: 0.0215\n",
      "Epoch 176/200, Iteration 174/250, Loss: 0.0124\n",
      "Epoch 176/200, Iteration 175/250, Loss: 0.0305\n",
      "Epoch 176/200, Iteration 176/250, Loss: 0.0095\n",
      "Epoch 176/200, Iteration 177/250, Loss: 0.0276\n",
      "Epoch 176/200, Iteration 178/250, Loss: 0.0434\n",
      "Epoch 176/200, Iteration 179/250, Loss: 0.0305\n",
      "Epoch 176/200, Iteration 180/250, Loss: 0.0106\n",
      "Epoch 176/200, Iteration 181/250, Loss: 0.0104\n",
      "Epoch 176/200, Iteration 182/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 183/250, Loss: 0.0081\n",
      "Epoch 176/200, Iteration 184/250, Loss: 0.0158\n",
      "Epoch 176/200, Iteration 185/250, Loss: 0.0082\n",
      "Epoch 176/200, Iteration 186/250, Loss: 0.0224\n",
      "Epoch 176/200, Iteration 187/250, Loss: 0.0226\n",
      "Epoch 176/200, Iteration 188/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 189/250, Loss: 0.0103\n",
      "Epoch 176/200, Iteration 190/250, Loss: 0.0330\n",
      "Epoch 176/200, Iteration 191/250, Loss: 0.0317\n",
      "Epoch 176/200, Iteration 192/250, Loss: 0.0155\n",
      "Epoch 176/200, Iteration 193/250, Loss: 0.0065\n",
      "Epoch 176/200, Iteration 194/250, Loss: 0.0082\n",
      "Epoch 176/200, Iteration 195/250, Loss: 0.0158\n",
      "Epoch 176/200, Iteration 196/250, Loss: 0.0107\n",
      "Epoch 176/200, Iteration 197/250, Loss: 0.0200\n",
      "Epoch 176/200, Iteration 198/250, Loss: 0.0120\n",
      "Epoch 176/200, Iteration 199/250, Loss: 0.0123\n",
      "Epoch 176/200, Iteration 200/250, Loss: 0.0071\n",
      "Epoch 176/200, Iteration 201/250, Loss: 0.0292\n",
      "Epoch 176/200, Iteration 202/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 203/250, Loss: 0.0125\n",
      "Epoch 176/200, Iteration 204/250, Loss: 0.0100\n",
      "Epoch 176/200, Iteration 205/250, Loss: 0.0144\n",
      "Epoch 176/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 176/200, Iteration 207/250, Loss: 0.0083\n",
      "Epoch 176/200, Iteration 208/250, Loss: 0.0323\n",
      "Epoch 176/200, Iteration 209/250, Loss: 0.0102\n",
      "Epoch 176/200, Iteration 210/250, Loss: 0.0147\n",
      "Epoch 176/200, Iteration 211/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 212/250, Loss: 0.0268\n",
      "Epoch 176/200, Iteration 213/250, Loss: 0.0279\n",
      "Epoch 176/200, Iteration 214/250, Loss: 0.0259\n",
      "Epoch 176/200, Iteration 215/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 216/250, Loss: 0.0128\n",
      "Epoch 176/200, Iteration 217/250, Loss: 0.0109\n",
      "Epoch 176/200, Iteration 218/250, Loss: 0.0376\n",
      "Epoch 176/200, Iteration 219/250, Loss: 0.0076\n",
      "Epoch 176/200, Iteration 220/250, Loss: 0.0158\n",
      "Epoch 176/200, Iteration 221/250, Loss: 0.0177\n",
      "Epoch 176/200, Iteration 222/250, Loss: 0.0096\n",
      "Epoch 176/200, Iteration 223/250, Loss: 0.0281\n",
      "Epoch 176/200, Iteration 224/250, Loss: 0.0101\n",
      "Epoch 176/200, Iteration 225/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 226/250, Loss: 0.0067\n",
      "Epoch 176/200, Iteration 227/250, Loss: 0.0246\n",
      "Epoch 176/200, Iteration 228/250, Loss: 0.0147\n",
      "Epoch 176/200, Iteration 229/250, Loss: 0.0206\n",
      "Epoch 176/200, Iteration 230/250, Loss: 0.0091\n",
      "Epoch 176/200, Iteration 231/250, Loss: 0.0175\n",
      "Epoch 176/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 176/200, Iteration 233/250, Loss: 0.0131\n",
      "Epoch 176/200, Iteration 234/250, Loss: 0.0130\n",
      "Epoch 176/200, Iteration 235/250, Loss: 0.0074\n",
      "Epoch 176/200, Iteration 236/250, Loss: 0.0152\n",
      "Epoch 176/200, Iteration 237/250, Loss: 0.0148\n",
      "Epoch 176/200, Iteration 238/250, Loss: 0.0158\n",
      "Epoch 176/200, Iteration 239/250, Loss: 0.0116\n",
      "Epoch 176/200, Iteration 240/250, Loss: 0.0059\n",
      "Epoch 176/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 176/200, Iteration 242/250, Loss: 0.0255\n",
      "Epoch 176/200, Iteration 243/250, Loss: 0.0119\n",
      "Epoch 176/200, Iteration 244/250, Loss: 0.0170\n",
      "Epoch 176/200, Iteration 245/250, Loss: 0.0153\n",
      "Epoch 176/200, Iteration 246/250, Loss: 0.0185\n",
      "Epoch 176/200, Iteration 247/250, Loss: 0.0145\n",
      "Epoch 176/200, Iteration 248/250, Loss: 0.0092\n",
      "Epoch 176/200, Iteration 249/250, Loss: 0.0098\n",
      "Epoch 176/200, Iteration 250/250, Loss: 0.0130\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.007390, MRE: 0.480719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.95%, Avg loss: 0.007797, MRE: 0.552013 \n",
      "\n",
      "Epoch 177/200, Iteration 1/250, Loss: 0.0224\n",
      "Epoch 177/200, Iteration 2/250, Loss: 0.0159\n",
      "Epoch 177/200, Iteration 3/250, Loss: 0.0228\n",
      "Epoch 177/200, Iteration 4/250, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 5/250, Loss: 0.0302\n",
      "Epoch 177/200, Iteration 6/250, Loss: 0.0171\n",
      "Epoch 177/200, Iteration 7/250, Loss: 0.0162\n",
      "Epoch 177/200, Iteration 8/250, Loss: 0.0223\n",
      "Epoch 177/200, Iteration 9/250, Loss: 0.0159\n",
      "Epoch 177/200, Iteration 10/250, Loss: 0.0153\n",
      "Epoch 177/200, Iteration 11/250, Loss: 0.0102\n",
      "Epoch 177/200, Iteration 12/250, Loss: 0.0144\n",
      "Epoch 177/200, Iteration 13/250, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 14/250, Loss: 0.0129\n",
      "Epoch 177/200, Iteration 15/250, Loss: 0.0085\n",
      "Epoch 177/200, Iteration 16/250, Loss: 0.0390\n",
      "Epoch 177/200, Iteration 17/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 18/250, Loss: 0.0258\n",
      "Epoch 177/200, Iteration 19/250, Loss: 0.0204\n",
      "Epoch 177/200, Iteration 20/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 22/250, Loss: 0.0438\n",
      "Epoch 177/200, Iteration 23/250, Loss: 0.0270\n",
      "Epoch 177/200, Iteration 24/250, Loss: 0.0094\n",
      "Epoch 177/200, Iteration 25/250, Loss: 0.0066\n",
      "Epoch 177/200, Iteration 26/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 27/250, Loss: 0.0177\n",
      "Epoch 177/200, Iteration 28/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 29/250, Loss: 0.0126\n",
      "Epoch 177/200, Iteration 30/250, Loss: 0.0090\n",
      "Epoch 177/200, Iteration 31/250, Loss: 0.0269\n",
      "Epoch 177/200, Iteration 32/250, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200, Iteration 33/250, Loss: 0.0124\n",
      "Epoch 177/200, Iteration 34/250, Loss: 0.0089\n",
      "Epoch 177/200, Iteration 35/250, Loss: 0.0311\n",
      "Epoch 177/200, Iteration 36/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 37/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 38/250, Loss: 0.0089\n",
      "Epoch 177/200, Iteration 39/250, Loss: 0.0141\n",
      "Epoch 177/200, Iteration 40/250, Loss: 0.0142\n",
      "Epoch 177/200, Iteration 41/250, Loss: 0.0122\n",
      "Epoch 177/200, Iteration 42/250, Loss: 0.0184\n",
      "Epoch 177/200, Iteration 43/250, Loss: 0.0421\n",
      "Epoch 177/200, Iteration 44/250, Loss: 0.0351\n",
      "Epoch 177/200, Iteration 45/250, Loss: 0.0070\n",
      "Epoch 177/200, Iteration 46/250, Loss: 0.0151\n",
      "Epoch 177/200, Iteration 47/250, Loss: 0.0236\n",
      "Epoch 177/200, Iteration 48/250, Loss: 0.0088\n",
      "Epoch 177/200, Iteration 49/250, Loss: 0.0150\n",
      "Epoch 177/200, Iteration 50/250, Loss: 0.0163\n",
      "Epoch 177/200, Iteration 51/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 52/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 53/250, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 54/250, Loss: 0.0132\n",
      "Epoch 177/200, Iteration 55/250, Loss: 0.0148\n",
      "Epoch 177/200, Iteration 56/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 57/250, Loss: 0.0339\n",
      "Epoch 177/200, Iteration 58/250, Loss: 0.0097\n",
      "Epoch 177/200, Iteration 59/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 60/250, Loss: 0.0177\n",
      "Epoch 177/200, Iteration 61/250, Loss: 0.0182\n",
      "Epoch 177/200, Iteration 62/250, Loss: 0.0091\n",
      "Epoch 177/200, Iteration 63/250, Loss: 0.0131\n",
      "Epoch 177/200, Iteration 64/250, Loss: 0.0221\n",
      "Epoch 177/200, Iteration 65/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 66/250, Loss: 0.0259\n",
      "Epoch 177/200, Iteration 67/250, Loss: 0.0266\n",
      "Epoch 177/200, Iteration 68/250, Loss: 0.0225\n",
      "Epoch 177/200, Iteration 69/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 70/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 71/250, Loss: 0.0063\n",
      "Epoch 177/200, Iteration 72/250, Loss: 0.0330\n",
      "Epoch 177/200, Iteration 73/250, Loss: 0.0354\n",
      "Epoch 177/200, Iteration 74/250, Loss: 0.0082\n",
      "Epoch 177/200, Iteration 75/250, Loss: 0.0222\n",
      "Epoch 177/200, Iteration 76/250, Loss: 0.0154\n",
      "Epoch 177/200, Iteration 77/250, Loss: 0.0260\n",
      "Epoch 177/200, Iteration 78/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 79/250, Loss: 0.0181\n",
      "Epoch 177/200, Iteration 80/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 81/250, Loss: 0.0190\n",
      "Epoch 177/200, Iteration 82/250, Loss: 0.0324\n",
      "Epoch 177/200, Iteration 83/250, Loss: 0.0129\n",
      "Epoch 177/200, Iteration 84/250, Loss: 0.0117\n",
      "Epoch 177/200, Iteration 85/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 86/250, Loss: 0.0309\n",
      "Epoch 177/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 177/200, Iteration 88/250, Loss: 0.0093\n",
      "Epoch 177/200, Iteration 89/250, Loss: 0.0144\n",
      "Epoch 177/200, Iteration 90/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 91/250, Loss: 0.0125\n",
      "Epoch 177/200, Iteration 92/250, Loss: 0.0120\n",
      "Epoch 177/200, Iteration 93/250, Loss: 0.0089\n",
      "Epoch 177/200, Iteration 94/250, Loss: 0.0076\n",
      "Epoch 177/200, Iteration 95/250, Loss: 0.0129\n",
      "Epoch 177/200, Iteration 96/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 97/250, Loss: 0.0176\n",
      "Epoch 177/200, Iteration 98/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 99/250, Loss: 0.0205\n",
      "Epoch 177/200, Iteration 100/250, Loss: 0.0136\n",
      "Epoch 177/200, Iteration 101/250, Loss: 0.0246\n",
      "Epoch 177/200, Iteration 102/250, Loss: 0.0140\n",
      "Epoch 177/200, Iteration 103/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 104/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 105/250, Loss: 0.0135\n",
      "Epoch 177/200, Iteration 106/250, Loss: 0.0150\n",
      "Epoch 177/200, Iteration 107/250, Loss: 0.0530\n",
      "Epoch 177/200, Iteration 108/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 109/250, Loss: 0.0149\n",
      "Epoch 177/200, Iteration 110/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 111/250, Loss: 0.0126\n",
      "Epoch 177/200, Iteration 112/250, Loss: 0.0108\n",
      "Epoch 177/200, Iteration 113/250, Loss: 0.0188\n",
      "Epoch 177/200, Iteration 114/250, Loss: 0.0200\n",
      "Epoch 177/200, Iteration 115/250, Loss: 0.0151\n",
      "Epoch 177/200, Iteration 116/250, Loss: 0.0115\n",
      "Epoch 177/200, Iteration 117/250, Loss: 0.0118\n",
      "Epoch 177/200, Iteration 118/250, Loss: 0.0138\n",
      "Epoch 177/200, Iteration 119/250, Loss: 0.0228\n",
      "Epoch 177/200, Iteration 120/250, Loss: 0.0230\n",
      "Epoch 177/200, Iteration 121/250, Loss: 0.0125\n",
      "Epoch 177/200, Iteration 122/250, Loss: 0.0151\n",
      "Epoch 177/200, Iteration 123/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 124/250, Loss: 0.0104\n",
      "Epoch 177/200, Iteration 125/250, Loss: 0.0095\n",
      "Epoch 177/200, Iteration 126/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 127/250, Loss: 0.0324\n",
      "Epoch 177/200, Iteration 128/250, Loss: 0.0150\n",
      "Epoch 177/200, Iteration 129/250, Loss: 0.0201\n",
      "Epoch 177/200, Iteration 130/250, Loss: 0.0081\n",
      "Epoch 177/200, Iteration 131/250, Loss: 0.0197\n",
      "Epoch 177/200, Iteration 132/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 133/250, Loss: 0.0216\n",
      "Epoch 177/200, Iteration 134/250, Loss: 0.0390\n",
      "Epoch 177/200, Iteration 135/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 136/250, Loss: 0.0123\n",
      "Epoch 177/200, Iteration 137/250, Loss: 0.0239\n",
      "Epoch 177/200, Iteration 138/250, Loss: 0.0148\n",
      "Epoch 177/200, Iteration 139/250, Loss: 0.0084\n",
      "Epoch 177/200, Iteration 140/250, Loss: 0.0175\n",
      "Epoch 177/200, Iteration 141/250, Loss: 0.0091\n",
      "Epoch 177/200, Iteration 142/250, Loss: 0.0108\n",
      "Epoch 177/200, Iteration 143/250, Loss: 0.0201\n",
      "Epoch 177/200, Iteration 144/250, Loss: 0.0146\n",
      "Epoch 177/200, Iteration 145/250, Loss: 0.0185\n",
      "Epoch 177/200, Iteration 146/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 147/250, Loss: 0.0116\n",
      "Epoch 177/200, Iteration 148/250, Loss: 0.0242\n",
      "Epoch 177/200, Iteration 149/250, Loss: 0.0091\n",
      "Epoch 177/200, Iteration 150/250, Loss: 0.0149\n",
      "Epoch 177/200, Iteration 151/250, Loss: 0.0100\n",
      "Epoch 177/200, Iteration 152/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 153/250, Loss: 0.0147\n",
      "Epoch 177/200, Iteration 154/250, Loss: 0.0152\n",
      "Epoch 177/200, Iteration 155/250, Loss: 0.0188\n",
      "Epoch 177/200, Iteration 156/250, Loss: 0.0166\n",
      "Epoch 177/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 177/200, Iteration 158/250, Loss: 0.0202\n",
      "Epoch 177/200, Iteration 159/250, Loss: 0.0128\n",
      "Epoch 177/200, Iteration 160/250, Loss: 0.0067\n",
      "Epoch 177/200, Iteration 161/250, Loss: 0.0109\n",
      "Epoch 177/200, Iteration 162/250, Loss: 0.0257\n",
      "Epoch 177/200, Iteration 163/250, Loss: 0.0090\n",
      "Epoch 177/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 177/200, Iteration 165/250, Loss: 0.0108\n",
      "Epoch 177/200, Iteration 166/250, Loss: 0.0211\n",
      "Epoch 177/200, Iteration 167/250, Loss: 0.0221\n",
      "Epoch 177/200, Iteration 168/250, Loss: 0.0124\n",
      "Epoch 177/200, Iteration 169/250, Loss: 0.0155\n",
      "Epoch 177/200, Iteration 170/250, Loss: 0.0098\n",
      "Epoch 177/200, Iteration 171/250, Loss: 0.0102\n",
      "Epoch 177/200, Iteration 172/250, Loss: 0.0257\n",
      "Epoch 177/200, Iteration 173/250, Loss: 0.0168\n",
      "Epoch 177/200, Iteration 174/250, Loss: 0.0109\n",
      "Epoch 177/200, Iteration 175/250, Loss: 0.0214\n",
      "Epoch 177/200, Iteration 176/250, Loss: 0.0126\n",
      "Epoch 177/200, Iteration 177/250, Loss: 0.0119\n",
      "Epoch 177/200, Iteration 178/250, Loss: 0.0079\n",
      "Epoch 177/200, Iteration 179/250, Loss: 0.0110\n",
      "Epoch 177/200, Iteration 180/250, Loss: 0.0155\n",
      "Epoch 177/200, Iteration 181/250, Loss: 0.0084\n",
      "Epoch 177/200, Iteration 182/250, Loss: 0.0290\n",
      "Epoch 177/200, Iteration 183/250, Loss: 0.0273\n",
      "Epoch 177/200, Iteration 184/250, Loss: 0.0255\n",
      "Epoch 177/200, Iteration 185/250, Loss: 0.0114\n",
      "Epoch 177/200, Iteration 186/250, Loss: 0.0250\n",
      "Epoch 177/200, Iteration 187/250, Loss: 0.0206\n",
      "Epoch 177/200, Iteration 188/250, Loss: 0.0145\n",
      "Epoch 177/200, Iteration 189/250, Loss: 0.0086\n",
      "Epoch 177/200, Iteration 190/250, Loss: 0.0195\n",
      "Epoch 177/200, Iteration 191/250, Loss: 0.0254\n",
      "Epoch 177/200, Iteration 192/250, Loss: 0.0072\n",
      "Epoch 177/200, Iteration 193/250, Loss: 0.0132\n",
      "Epoch 177/200, Iteration 194/250, Loss: 0.0143\n",
      "Epoch 177/200, Iteration 195/250, Loss: 0.0174\n",
      "Epoch 177/200, Iteration 196/250, Loss: 0.0106\n",
      "Epoch 177/200, Iteration 197/250, Loss: 0.0136\n",
      "Epoch 177/200, Iteration 198/250, Loss: 0.0180\n",
      "Epoch 177/200, Iteration 199/250, Loss: 0.0178\n",
      "Epoch 177/200, Iteration 200/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 201/250, Loss: 0.0071\n",
      "Epoch 177/200, Iteration 202/250, Loss: 0.0241\n",
      "Epoch 177/200, Iteration 203/250, Loss: 0.0115\n",
      "Epoch 177/200, Iteration 204/250, Loss: 0.0268\n",
      "Epoch 177/200, Iteration 205/250, Loss: 0.0116\n",
      "Epoch 177/200, Iteration 206/250, Loss: 0.0383\n",
      "Epoch 177/200, Iteration 207/250, Loss: 0.0372\n",
      "Epoch 177/200, Iteration 208/250, Loss: 0.0097\n",
      "Epoch 177/200, Iteration 209/250, Loss: 0.0134\n",
      "Epoch 177/200, Iteration 210/250, Loss: 0.0145\n",
      "Epoch 177/200, Iteration 211/250, Loss: 0.0072\n",
      "Epoch 177/200, Iteration 212/250, Loss: 0.0075\n",
      "Epoch 177/200, Iteration 213/250, Loss: 0.0225\n",
      "Epoch 177/200, Iteration 214/250, Loss: 0.0114\n",
      "Epoch 177/200, Iteration 215/250, Loss: 0.0267\n",
      "Epoch 177/200, Iteration 216/250, Loss: 0.0080\n",
      "Epoch 177/200, Iteration 217/250, Loss: 0.0130\n",
      "Epoch 177/200, Iteration 218/250, Loss: 0.0131\n",
      "Epoch 177/200, Iteration 219/250, Loss: 0.0391\n",
      "Epoch 177/200, Iteration 220/250, Loss: 0.0115\n",
      "Epoch 177/200, Iteration 221/250, Loss: 0.0190\n",
      "Epoch 177/200, Iteration 222/250, Loss: 0.0254\n",
      "Epoch 177/200, Iteration 223/250, Loss: 0.0115\n",
      "Epoch 177/200, Iteration 224/250, Loss: 0.0152\n",
      "Epoch 177/200, Iteration 225/250, Loss: 0.0079\n",
      "Epoch 177/200, Iteration 226/250, Loss: 0.0076\n",
      "Epoch 177/200, Iteration 227/250, Loss: 0.0107\n",
      "Epoch 177/200, Iteration 228/250, Loss: 0.0129\n",
      "Epoch 177/200, Iteration 229/250, Loss: 0.0207\n",
      "Epoch 177/200, Iteration 230/250, Loss: 0.0112\n",
      "Epoch 177/200, Iteration 231/250, Loss: 0.0126\n",
      "Epoch 177/200, Iteration 232/250, Loss: 0.0071\n",
      "Epoch 177/200, Iteration 233/250, Loss: 0.0078\n",
      "Epoch 177/200, Iteration 234/250, Loss: 0.0317\n",
      "Epoch 177/200, Iteration 235/250, Loss: 0.0144\n",
      "Epoch 177/200, Iteration 236/250, Loss: 0.0104\n",
      "Epoch 177/200, Iteration 237/250, Loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200, Iteration 238/250, Loss: 0.0211\n",
      "Epoch 177/200, Iteration 239/250, Loss: 0.0121\n",
      "Epoch 177/200, Iteration 240/250, Loss: 0.0170\n",
      "Epoch 177/200, Iteration 241/250, Loss: 0.0096\n",
      "Epoch 177/200, Iteration 242/250, Loss: 0.0147\n",
      "Epoch 177/200, Iteration 243/250, Loss: 0.0111\n",
      "Epoch 177/200, Iteration 244/250, Loss: 0.0208\n",
      "Epoch 177/200, Iteration 245/250, Loss: 0.0287\n",
      "Epoch 177/200, Iteration 246/250, Loss: 0.0155\n",
      "Epoch 177/200, Iteration 247/250, Loss: 0.0095\n",
      "Epoch 177/200, Iteration 248/250, Loss: 0.0128\n",
      "Epoch 177/200, Iteration 249/250, Loss: 0.0263\n",
      "Epoch 177/200, Iteration 250/250, Loss: 0.0175\n",
      "Train Error: \n",
      " Accuracy: 88.56%, Avg loss: 0.006628, MRE: 0.440160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.05%, Avg loss: 0.007210, MRE: 0.512983 \n",
      "\n",
      "Epoch 178/200, Iteration 1/250, Loss: 0.0192\n",
      "Epoch 178/200, Iteration 2/250, Loss: 0.0232\n",
      "Epoch 178/200, Iteration 3/250, Loss: 0.0168\n",
      "Epoch 178/200, Iteration 4/250, Loss: 0.0386\n",
      "Epoch 178/200, Iteration 5/250, Loss: 0.0202\n",
      "Epoch 178/200, Iteration 6/250, Loss: 0.0177\n",
      "Epoch 178/200, Iteration 7/250, Loss: 0.0175\n",
      "Epoch 178/200, Iteration 8/250, Loss: 0.0090\n",
      "Epoch 178/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 178/200, Iteration 10/250, Loss: 0.0223\n",
      "Epoch 178/200, Iteration 11/250, Loss: 0.0114\n",
      "Epoch 178/200, Iteration 12/250, Loss: 0.0092\n",
      "Epoch 178/200, Iteration 13/250, Loss: 0.0173\n",
      "Epoch 178/200, Iteration 14/250, Loss: 0.0345\n",
      "Epoch 178/200, Iteration 15/250, Loss: 0.0121\n",
      "Epoch 178/200, Iteration 16/250, Loss: 0.0231\n",
      "Epoch 178/200, Iteration 17/250, Loss: 0.0074\n",
      "Epoch 178/200, Iteration 18/250, Loss: 0.0187\n",
      "Epoch 178/200, Iteration 19/250, Loss: 0.0257\n",
      "Epoch 178/200, Iteration 20/250, Loss: 0.0157\n",
      "Epoch 178/200, Iteration 21/250, Loss: 0.0147\n",
      "Epoch 178/200, Iteration 22/250, Loss: 0.0066\n",
      "Epoch 178/200, Iteration 23/250, Loss: 0.0190\n",
      "Epoch 178/200, Iteration 24/250, Loss: 0.0150\n",
      "Epoch 178/200, Iteration 25/250, Loss: 0.0098\n",
      "Epoch 178/200, Iteration 26/250, Loss: 0.0127\n",
      "Epoch 178/200, Iteration 27/250, Loss: 0.0263\n",
      "Epoch 178/200, Iteration 28/250, Loss: 0.0208\n",
      "Epoch 178/200, Iteration 29/250, Loss: 0.0091\n",
      "Epoch 178/200, Iteration 30/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 31/250, Loss: 0.0133\n",
      "Epoch 178/200, Iteration 32/250, Loss: 0.0147\n",
      "Epoch 178/200, Iteration 33/250, Loss: 0.0157\n",
      "Epoch 178/200, Iteration 34/250, Loss: 0.0242\n",
      "Epoch 178/200, Iteration 35/250, Loss: 0.0252\n",
      "Epoch 178/200, Iteration 36/250, Loss: 0.0252\n",
      "Epoch 178/200, Iteration 37/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 38/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 39/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 40/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 41/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 42/250, Loss: 0.0148\n",
      "Epoch 178/200, Iteration 43/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 44/250, Loss: 0.0133\n",
      "Epoch 178/200, Iteration 45/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 178/200, Iteration 47/250, Loss: 0.0186\n",
      "Epoch 178/200, Iteration 48/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 49/250, Loss: 0.0144\n",
      "Epoch 178/200, Iteration 50/250, Loss: 0.0192\n",
      "Epoch 178/200, Iteration 51/250, Loss: 0.0193\n",
      "Epoch 178/200, Iteration 52/250, Loss: 0.0186\n",
      "Epoch 178/200, Iteration 53/250, Loss: 0.0172\n",
      "Epoch 178/200, Iteration 54/250, Loss: 0.0300\n",
      "Epoch 178/200, Iteration 55/250, Loss: 0.0129\n",
      "Epoch 178/200, Iteration 56/250, Loss: 0.0154\n",
      "Epoch 178/200, Iteration 57/250, Loss: 0.0222\n",
      "Epoch 178/200, Iteration 58/250, Loss: 0.0228\n",
      "Epoch 178/200, Iteration 59/250, Loss: 0.0114\n",
      "Epoch 178/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 178/200, Iteration 61/250, Loss: 0.0231\n",
      "Epoch 178/200, Iteration 62/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 63/250, Loss: 0.0147\n",
      "Epoch 178/200, Iteration 64/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 65/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 66/250, Loss: 0.0069\n",
      "Epoch 178/200, Iteration 67/250, Loss: 0.0225\n",
      "Epoch 178/200, Iteration 68/250, Loss: 0.0202\n",
      "Epoch 178/200, Iteration 69/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 70/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 71/250, Loss: 0.0068\n",
      "Epoch 178/200, Iteration 72/250, Loss: 0.0275\n",
      "Epoch 178/200, Iteration 73/250, Loss: 0.0225\n",
      "Epoch 178/200, Iteration 74/250, Loss: 0.0155\n",
      "Epoch 178/200, Iteration 75/250, Loss: 0.0173\n",
      "Epoch 178/200, Iteration 76/250, Loss: 0.0089\n",
      "Epoch 178/200, Iteration 77/250, Loss: 0.0125\n",
      "Epoch 178/200, Iteration 78/250, Loss: 0.0365\n",
      "Epoch 178/200, Iteration 79/250, Loss: 0.0115\n",
      "Epoch 178/200, Iteration 80/250, Loss: 0.0126\n",
      "Epoch 178/200, Iteration 81/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 82/250, Loss: 0.0101\n",
      "Epoch 178/200, Iteration 83/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 84/250, Loss: 0.0224\n",
      "Epoch 178/200, Iteration 85/250, Loss: 0.0171\n",
      "Epoch 178/200, Iteration 86/250, Loss: 0.0126\n",
      "Epoch 178/200, Iteration 87/250, Loss: 0.0198\n",
      "Epoch 178/200, Iteration 88/250, Loss: 0.0225\n",
      "Epoch 178/200, Iteration 89/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 90/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 91/250, Loss: 0.0078\n",
      "Epoch 178/200, Iteration 92/250, Loss: 0.0109\n",
      "Epoch 178/200, Iteration 93/250, Loss: 0.0096\n",
      "Epoch 178/200, Iteration 94/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 95/250, Loss: 0.0236\n",
      "Epoch 178/200, Iteration 96/250, Loss: 0.0165\n",
      "Epoch 178/200, Iteration 97/250, Loss: 0.0104\n",
      "Epoch 178/200, Iteration 98/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 99/250, Loss: 0.0220\n",
      "Epoch 178/200, Iteration 100/250, Loss: 0.0157\n",
      "Epoch 178/200, Iteration 101/250, Loss: 0.0080\n",
      "Epoch 178/200, Iteration 102/250, Loss: 0.0143\n",
      "Epoch 178/200, Iteration 103/250, Loss: 0.0197\n",
      "Epoch 178/200, Iteration 104/250, Loss: 0.0168\n",
      "Epoch 178/200, Iteration 105/250, Loss: 0.0170\n",
      "Epoch 178/200, Iteration 106/250, Loss: 0.0127\n",
      "Epoch 178/200, Iteration 107/250, Loss: 0.0087\n",
      "Epoch 178/200, Iteration 108/250, Loss: 0.0110\n",
      "Epoch 178/200, Iteration 109/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 110/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 111/250, Loss: 0.0371\n",
      "Epoch 178/200, Iteration 112/250, Loss: 0.0081\n",
      "Epoch 178/200, Iteration 113/250, Loss: 0.0176\n",
      "Epoch 178/200, Iteration 114/250, Loss: 0.0358\n",
      "Epoch 178/200, Iteration 115/250, Loss: 0.0201\n",
      "Epoch 178/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 178/200, Iteration 117/250, Loss: 0.0206\n",
      "Epoch 178/200, Iteration 118/250, Loss: 0.0140\n",
      "Epoch 178/200, Iteration 119/250, Loss: 0.0171\n",
      "Epoch 178/200, Iteration 120/250, Loss: 0.0112\n",
      "Epoch 178/200, Iteration 121/250, Loss: 0.0144\n",
      "Epoch 178/200, Iteration 122/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 123/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 124/250, Loss: 0.0091\n",
      "Epoch 178/200, Iteration 125/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 126/250, Loss: 0.0185\n",
      "Epoch 178/200, Iteration 127/250, Loss: 0.0123\n",
      "Epoch 178/200, Iteration 128/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 129/250, Loss: 0.0287\n",
      "Epoch 178/200, Iteration 130/250, Loss: 0.0105\n",
      "Epoch 178/200, Iteration 131/250, Loss: 0.0103\n",
      "Epoch 178/200, Iteration 132/250, Loss: 0.0169\n",
      "Epoch 178/200, Iteration 133/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 134/250, Loss: 0.0090\n",
      "Epoch 178/200, Iteration 135/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 136/250, Loss: 0.0154\n",
      "Epoch 178/200, Iteration 137/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 138/250, Loss: 0.0153\n",
      "Epoch 178/200, Iteration 139/250, Loss: 0.0092\n",
      "Epoch 178/200, Iteration 140/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 141/250, Loss: 0.0245\n",
      "Epoch 178/200, Iteration 142/250, Loss: 0.0258\n",
      "Epoch 178/200, Iteration 143/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 178/200, Iteration 145/250, Loss: 0.0268\n",
      "Epoch 178/200, Iteration 146/250, Loss: 0.0212\n",
      "Epoch 178/200, Iteration 147/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 148/250, Loss: 0.0179\n",
      "Epoch 178/200, Iteration 149/250, Loss: 0.0158\n",
      "Epoch 178/200, Iteration 150/250, Loss: 0.0120\n",
      "Epoch 178/200, Iteration 151/250, Loss: 0.0099\n",
      "Epoch 178/200, Iteration 152/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 153/250, Loss: 0.0086\n",
      "Epoch 178/200, Iteration 154/250, Loss: 0.0200\n",
      "Epoch 178/200, Iteration 155/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 156/250, Loss: 0.0111\n",
      "Epoch 178/200, Iteration 157/250, Loss: 0.0134\n",
      "Epoch 178/200, Iteration 158/250, Loss: 0.0189\n",
      "Epoch 178/200, Iteration 159/250, Loss: 0.0293\n",
      "Epoch 178/200, Iteration 160/250, Loss: 0.0110\n",
      "Epoch 178/200, Iteration 161/250, Loss: 0.0136\n",
      "Epoch 178/200, Iteration 162/250, Loss: 0.0212\n",
      "Epoch 178/200, Iteration 163/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 164/250, Loss: 0.0191\n",
      "Epoch 178/200, Iteration 165/250, Loss: 0.0162\n",
      "Epoch 178/200, Iteration 166/250, Loss: 0.0076\n",
      "Epoch 178/200, Iteration 167/250, Loss: 0.0198\n",
      "Epoch 178/200, Iteration 168/250, Loss: 0.0285\n",
      "Epoch 178/200, Iteration 169/250, Loss: 0.0139\n",
      "Epoch 178/200, Iteration 170/250, Loss: 0.0222\n",
      "Epoch 178/200, Iteration 171/250, Loss: 0.0375\n",
      "Epoch 178/200, Iteration 172/250, Loss: 0.0101\n",
      "Epoch 178/200, Iteration 173/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 174/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 175/250, Loss: 0.0379\n",
      "Epoch 178/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 178/200, Iteration 177/250, Loss: 0.0175\n",
      "Epoch 178/200, Iteration 178/250, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200, Iteration 179/250, Loss: 0.0220\n",
      "Epoch 178/200, Iteration 180/250, Loss: 0.0168\n",
      "Epoch 178/200, Iteration 181/250, Loss: 0.0084\n",
      "Epoch 178/200, Iteration 182/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 183/250, Loss: 0.0131\n",
      "Epoch 178/200, Iteration 184/250, Loss: 0.0198\n",
      "Epoch 178/200, Iteration 185/250, Loss: 0.0150\n",
      "Epoch 178/200, Iteration 186/250, Loss: 0.0136\n",
      "Epoch 178/200, Iteration 187/250, Loss: 0.0150\n",
      "Epoch 178/200, Iteration 188/250, Loss: 0.0206\n",
      "Epoch 178/200, Iteration 189/250, Loss: 0.0091\n",
      "Epoch 178/200, Iteration 190/250, Loss: 0.0404\n",
      "Epoch 178/200, Iteration 191/250, Loss: 0.0092\n",
      "Epoch 178/200, Iteration 192/250, Loss: 0.0152\n",
      "Epoch 178/200, Iteration 193/250, Loss: 0.0195\n",
      "Epoch 178/200, Iteration 194/250, Loss: 0.0183\n",
      "Epoch 178/200, Iteration 195/250, Loss: 0.0088\n",
      "Epoch 178/200, Iteration 196/250, Loss: 0.0098\n",
      "Epoch 178/200, Iteration 197/250, Loss: 0.0157\n",
      "Epoch 178/200, Iteration 198/250, Loss: 0.0200\n",
      "Epoch 178/200, Iteration 199/250, Loss: 0.0342\n",
      "Epoch 178/200, Iteration 200/250, Loss: 0.0126\n",
      "Epoch 178/200, Iteration 201/250, Loss: 0.0076\n",
      "Epoch 178/200, Iteration 202/250, Loss: 0.0176\n",
      "Epoch 178/200, Iteration 203/250, Loss: 0.0225\n",
      "Epoch 178/200, Iteration 204/250, Loss: 0.0141\n",
      "Epoch 178/200, Iteration 205/250, Loss: 0.0137\n",
      "Epoch 178/200, Iteration 206/250, Loss: 0.0086\n",
      "Epoch 178/200, Iteration 207/250, Loss: 0.0339\n",
      "Epoch 178/200, Iteration 208/250, Loss: 0.0145\n",
      "Epoch 178/200, Iteration 209/250, Loss: 0.0095\n",
      "Epoch 178/200, Iteration 210/250, Loss: 0.0073\n",
      "Epoch 178/200, Iteration 211/250, Loss: 0.0129\n",
      "Epoch 178/200, Iteration 212/250, Loss: 0.0074\n",
      "Epoch 178/200, Iteration 213/250, Loss: 0.0072\n",
      "Epoch 178/200, Iteration 214/250, Loss: 0.0111\n",
      "Epoch 178/200, Iteration 215/250, Loss: 0.0107\n",
      "Epoch 178/200, Iteration 216/250, Loss: 0.0170\n",
      "Epoch 178/200, Iteration 217/250, Loss: 0.0302\n",
      "Epoch 178/200, Iteration 218/250, Loss: 0.0118\n",
      "Epoch 178/200, Iteration 219/250, Loss: 0.0195\n",
      "Epoch 178/200, Iteration 220/250, Loss: 0.0081\n",
      "Epoch 178/200, Iteration 221/250, Loss: 0.0087\n",
      "Epoch 178/200, Iteration 222/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 223/250, Loss: 0.0327\n",
      "Epoch 178/200, Iteration 224/250, Loss: 0.0122\n",
      "Epoch 178/200, Iteration 225/250, Loss: 0.0362\n",
      "Epoch 178/200, Iteration 226/250, Loss: 0.0104\n",
      "Epoch 178/200, Iteration 227/250, Loss: 0.0225\n",
      "Epoch 178/200, Iteration 228/250, Loss: 0.0112\n",
      "Epoch 178/200, Iteration 229/250, Loss: 0.0084\n",
      "Epoch 178/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 231/250, Loss: 0.0079\n",
      "Epoch 178/200, Iteration 232/250, Loss: 0.0167\n",
      "Epoch 178/200, Iteration 233/250, Loss: 0.0311\n",
      "Epoch 178/200, Iteration 234/250, Loss: 0.0075\n",
      "Epoch 178/200, Iteration 235/250, Loss: 0.0108\n",
      "Epoch 178/200, Iteration 236/250, Loss: 0.0130\n",
      "Epoch 178/200, Iteration 237/250, Loss: 0.0377\n",
      "Epoch 178/200, Iteration 238/250, Loss: 0.0118\n",
      "Epoch 178/200, Iteration 239/250, Loss: 0.0290\n",
      "Epoch 178/200, Iteration 240/250, Loss: 0.0085\n",
      "Epoch 178/200, Iteration 241/250, Loss: 0.0077\n",
      "Epoch 178/200, Iteration 242/250, Loss: 0.0116\n",
      "Epoch 178/200, Iteration 243/250, Loss: 0.0258\n",
      "Epoch 178/200, Iteration 244/250, Loss: 0.0144\n",
      "Epoch 178/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 178/200, Iteration 246/250, Loss: 0.0075\n",
      "Epoch 178/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 178/200, Iteration 248/250, Loss: 0.0209\n",
      "Epoch 178/200, Iteration 249/250, Loss: 0.0136\n",
      "Epoch 178/200, Iteration 250/250, Loss: 0.0140\n",
      "Train Error: \n",
      " Accuracy: 87.35%, Avg loss: 0.006828, MRE: 0.457672 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.05%, Avg loss: 0.007378, MRE: 0.505759 \n",
      "\n",
      "Epoch 179/200, Iteration 1/250, Loss: 0.0205\n",
      "Epoch 179/200, Iteration 2/250, Loss: 0.0110\n",
      "Epoch 179/200, Iteration 3/250, Loss: 0.0217\n",
      "Epoch 179/200, Iteration 4/250, Loss: 0.0090\n",
      "Epoch 179/200, Iteration 5/250, Loss: 0.0163\n",
      "Epoch 179/200, Iteration 6/250, Loss: 0.0187\n",
      "Epoch 179/200, Iteration 7/250, Loss: 0.0174\n",
      "Epoch 179/200, Iteration 8/250, Loss: 0.0122\n",
      "Epoch 179/200, Iteration 9/250, Loss: 0.0159\n",
      "Epoch 179/200, Iteration 10/250, Loss: 0.0101\n",
      "Epoch 179/200, Iteration 11/250, Loss: 0.0166\n",
      "Epoch 179/200, Iteration 12/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 179/200, Iteration 14/250, Loss: 0.0121\n",
      "Epoch 179/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 179/200, Iteration 16/250, Loss: 0.0176\n",
      "Epoch 179/200, Iteration 17/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 18/250, Loss: 0.0122\n",
      "Epoch 179/200, Iteration 19/250, Loss: 0.0154\n",
      "Epoch 179/200, Iteration 20/250, Loss: 0.0161\n",
      "Epoch 179/200, Iteration 21/250, Loss: 0.0085\n",
      "Epoch 179/200, Iteration 22/250, Loss: 0.0372\n",
      "Epoch 179/200, Iteration 23/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 24/250, Loss: 0.0346\n",
      "Epoch 179/200, Iteration 25/250, Loss: 0.0361\n",
      "Epoch 179/200, Iteration 26/250, Loss: 0.0129\n",
      "Epoch 179/200, Iteration 27/250, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 28/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 29/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 30/250, Loss: 0.0084\n",
      "Epoch 179/200, Iteration 31/250, Loss: 0.0124\n",
      "Epoch 179/200, Iteration 32/250, Loss: 0.0061\n",
      "Epoch 179/200, Iteration 33/250, Loss: 0.0141\n",
      "Epoch 179/200, Iteration 34/250, Loss: 0.0253\n",
      "Epoch 179/200, Iteration 35/250, Loss: 0.0109\n",
      "Epoch 179/200, Iteration 36/250, Loss: 0.0117\n",
      "Epoch 179/200, Iteration 37/250, Loss: 0.0210\n",
      "Epoch 179/200, Iteration 38/250, Loss: 0.0079\n",
      "Epoch 179/200, Iteration 39/250, Loss: 0.0084\n",
      "Epoch 179/200, Iteration 40/250, Loss: 0.0115\n",
      "Epoch 179/200, Iteration 41/250, Loss: 0.0177\n",
      "Epoch 179/200, Iteration 42/250, Loss: 0.0293\n",
      "Epoch 179/200, Iteration 43/250, Loss: 0.0087\n",
      "Epoch 179/200, Iteration 44/250, Loss: 0.0090\n",
      "Epoch 179/200, Iteration 45/250, Loss: 0.0141\n",
      "Epoch 179/200, Iteration 46/250, Loss: 0.0095\n",
      "Epoch 179/200, Iteration 47/250, Loss: 0.0241\n",
      "Epoch 179/200, Iteration 48/250, Loss: 0.0104\n",
      "Epoch 179/200, Iteration 49/250, Loss: 0.0077\n",
      "Epoch 179/200, Iteration 50/250, Loss: 0.0125\n",
      "Epoch 179/200, Iteration 51/250, Loss: 0.0295\n",
      "Epoch 179/200, Iteration 52/250, Loss: 0.0096\n",
      "Epoch 179/200, Iteration 53/250, Loss: 0.0099\n",
      "Epoch 179/200, Iteration 54/250, Loss: 0.0106\n",
      "Epoch 179/200, Iteration 55/250, Loss: 0.0148\n",
      "Epoch 179/200, Iteration 56/250, Loss: 0.0333\n",
      "Epoch 179/200, Iteration 57/250, Loss: 0.0058\n",
      "Epoch 179/200, Iteration 58/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 59/250, Loss: 0.0098\n",
      "Epoch 179/200, Iteration 60/250, Loss: 0.0069\n",
      "Epoch 179/200, Iteration 61/250, Loss: 0.0226\n",
      "Epoch 179/200, Iteration 62/250, Loss: 0.0181\n",
      "Epoch 179/200, Iteration 63/250, Loss: 0.0153\n",
      "Epoch 179/200, Iteration 64/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 65/250, Loss: 0.0094\n",
      "Epoch 179/200, Iteration 66/250, Loss: 0.0144\n",
      "Epoch 179/200, Iteration 67/250, Loss: 0.0186\n",
      "Epoch 179/200, Iteration 68/250, Loss: 0.0307\n",
      "Epoch 179/200, Iteration 69/250, Loss: 0.0136\n",
      "Epoch 179/200, Iteration 70/250, Loss: 0.0185\n",
      "Epoch 179/200, Iteration 71/250, Loss: 0.0214\n",
      "Epoch 179/200, Iteration 72/250, Loss: 0.0235\n",
      "Epoch 179/200, Iteration 73/250, Loss: 0.0143\n",
      "Epoch 179/200, Iteration 74/250, Loss: 0.0254\n",
      "Epoch 179/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 76/250, Loss: 0.0115\n",
      "Epoch 179/200, Iteration 77/250, Loss: 0.0181\n",
      "Epoch 179/200, Iteration 78/250, Loss: 0.0100\n",
      "Epoch 179/200, Iteration 79/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 80/250, Loss: 0.0124\n",
      "Epoch 179/200, Iteration 81/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 82/250, Loss: 0.0158\n",
      "Epoch 179/200, Iteration 83/250, Loss: 0.0161\n",
      "Epoch 179/200, Iteration 84/250, Loss: 0.0213\n",
      "Epoch 179/200, Iteration 85/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 86/250, Loss: 0.0310\n",
      "Epoch 179/200, Iteration 87/250, Loss: 0.0120\n",
      "Epoch 179/200, Iteration 88/250, Loss: 0.0094\n",
      "Epoch 179/200, Iteration 89/250, Loss: 0.0208\n",
      "Epoch 179/200, Iteration 90/250, Loss: 0.0129\n",
      "Epoch 179/200, Iteration 91/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 92/250, Loss: 0.0244\n",
      "Epoch 179/200, Iteration 93/250, Loss: 0.0084\n",
      "Epoch 179/200, Iteration 94/250, Loss: 0.0180\n",
      "Epoch 179/200, Iteration 95/250, Loss: 0.0201\n",
      "Epoch 179/200, Iteration 96/250, Loss: 0.0134\n",
      "Epoch 179/200, Iteration 97/250, Loss: 0.0153\n",
      "Epoch 179/200, Iteration 98/250, Loss: 0.0080\n",
      "Epoch 179/200, Iteration 99/250, Loss: 0.0360\n",
      "Epoch 179/200, Iteration 100/250, Loss: 0.0157\n",
      "Epoch 179/200, Iteration 101/250, Loss: 0.0167\n",
      "Epoch 179/200, Iteration 102/250, Loss: 0.0114\n",
      "Epoch 179/200, Iteration 103/250, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200, Iteration 104/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 105/250, Loss: 0.0161\n",
      "Epoch 179/200, Iteration 106/250, Loss: 0.0062\n",
      "Epoch 179/200, Iteration 107/250, Loss: 0.0118\n",
      "Epoch 179/200, Iteration 108/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 109/250, Loss: 0.0089\n",
      "Epoch 179/200, Iteration 110/250, Loss: 0.0164\n",
      "Epoch 179/200, Iteration 111/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 112/250, Loss: 0.0083\n",
      "Epoch 179/200, Iteration 113/250, Loss: 0.0113\n",
      "Epoch 179/200, Iteration 114/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 115/250, Loss: 0.0065\n",
      "Epoch 179/200, Iteration 116/250, Loss: 0.0099\n",
      "Epoch 179/200, Iteration 117/250, Loss: 0.0205\n",
      "Epoch 179/200, Iteration 118/250, Loss: 0.0113\n",
      "Epoch 179/200, Iteration 119/250, Loss: 0.0064\n",
      "Epoch 179/200, Iteration 120/250, Loss: 0.0214\n",
      "Epoch 179/200, Iteration 121/250, Loss: 0.0101\n",
      "Epoch 179/200, Iteration 122/250, Loss: 0.0112\n",
      "Epoch 179/200, Iteration 123/250, Loss: 0.0179\n",
      "Epoch 179/200, Iteration 124/250, Loss: 0.0247\n",
      "Epoch 179/200, Iteration 125/250, Loss: 0.0155\n",
      "Epoch 179/200, Iteration 126/250, Loss: 0.0196\n",
      "Epoch 179/200, Iteration 127/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 128/250, Loss: 0.0208\n",
      "Epoch 179/200, Iteration 129/250, Loss: 0.0285\n",
      "Epoch 179/200, Iteration 130/250, Loss: 0.0272\n",
      "Epoch 179/200, Iteration 131/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 132/250, Loss: 0.0067\n",
      "Epoch 179/200, Iteration 133/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 134/250, Loss: 0.0343\n",
      "Epoch 179/200, Iteration 135/250, Loss: 0.0251\n",
      "Epoch 179/200, Iteration 136/250, Loss: 0.0097\n",
      "Epoch 179/200, Iteration 137/250, Loss: 0.0138\n",
      "Epoch 179/200, Iteration 138/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 139/250, Loss: 0.0062\n",
      "Epoch 179/200, Iteration 140/250, Loss: 0.0128\n",
      "Epoch 179/200, Iteration 141/250, Loss: 0.0092\n",
      "Epoch 179/200, Iteration 142/250, Loss: 0.0104\n",
      "Epoch 179/200, Iteration 143/250, Loss: 0.0108\n",
      "Epoch 179/200, Iteration 144/250, Loss: 0.0152\n",
      "Epoch 179/200, Iteration 145/250, Loss: 0.0118\n",
      "Epoch 179/200, Iteration 146/250, Loss: 0.0181\n",
      "Epoch 179/200, Iteration 147/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 148/250, Loss: 0.0108\n",
      "Epoch 179/200, Iteration 149/250, Loss: 0.0158\n",
      "Epoch 179/200, Iteration 150/250, Loss: 0.0140\n",
      "Epoch 179/200, Iteration 151/250, Loss: 0.0102\n",
      "Epoch 179/200, Iteration 152/250, Loss: 0.0215\n",
      "Epoch 179/200, Iteration 153/250, Loss: 0.0135\n",
      "Epoch 179/200, Iteration 154/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 155/250, Loss: 0.0103\n",
      "Epoch 179/200, Iteration 156/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 157/250, Loss: 0.0115\n",
      "Epoch 179/200, Iteration 158/250, Loss: 0.0163\n",
      "Epoch 179/200, Iteration 159/250, Loss: 0.0132\n",
      "Epoch 179/200, Iteration 160/250, Loss: 0.0091\n",
      "Epoch 179/200, Iteration 161/250, Loss: 0.0190\n",
      "Epoch 179/200, Iteration 162/250, Loss: 0.0201\n",
      "Epoch 179/200, Iteration 163/250, Loss: 0.0100\n",
      "Epoch 179/200, Iteration 164/250, Loss: 0.0136\n",
      "Epoch 179/200, Iteration 165/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 166/250, Loss: 0.0216\n",
      "Epoch 179/200, Iteration 167/250, Loss: 0.0121\n",
      "Epoch 179/200, Iteration 168/250, Loss: 0.0210\n",
      "Epoch 179/200, Iteration 169/250, Loss: 0.0229\n",
      "Epoch 179/200, Iteration 170/250, Loss: 0.0196\n",
      "Epoch 179/200, Iteration 171/250, Loss: 0.0085\n",
      "Epoch 179/200, Iteration 172/250, Loss: 0.0156\n",
      "Epoch 179/200, Iteration 173/250, Loss: 0.0097\n",
      "Epoch 179/200, Iteration 174/250, Loss: 0.0075\n",
      "Epoch 179/200, Iteration 175/250, Loss: 0.0079\n",
      "Epoch 179/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 179/200, Iteration 177/250, Loss: 0.0302\n",
      "Epoch 179/200, Iteration 178/250, Loss: 0.0182\n",
      "Epoch 179/200, Iteration 179/250, Loss: 0.0280\n",
      "Epoch 179/200, Iteration 180/250, Loss: 0.0209\n",
      "Epoch 179/200, Iteration 181/250, Loss: 0.0098\n",
      "Epoch 179/200, Iteration 182/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 183/250, Loss: 0.0126\n",
      "Epoch 179/200, Iteration 184/250, Loss: 0.0280\n",
      "Epoch 179/200, Iteration 185/250, Loss: 0.0153\n",
      "Epoch 179/200, Iteration 186/250, Loss: 0.0134\n",
      "Epoch 179/200, Iteration 187/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 188/250, Loss: 0.0177\n",
      "Epoch 179/200, Iteration 189/250, Loss: 0.0261\n",
      "Epoch 179/200, Iteration 190/250, Loss: 0.0088\n",
      "Epoch 179/200, Iteration 191/250, Loss: 0.0441\n",
      "Epoch 179/200, Iteration 192/250, Loss: 0.0162\n",
      "Epoch 179/200, Iteration 193/250, Loss: 0.0135\n",
      "Epoch 179/200, Iteration 194/250, Loss: 0.0081\n",
      "Epoch 179/200, Iteration 195/250, Loss: 0.0267\n",
      "Epoch 179/200, Iteration 196/250, Loss: 0.0063\n",
      "Epoch 179/200, Iteration 197/250, Loss: 0.0144\n",
      "Epoch 179/200, Iteration 198/250, Loss: 0.0098\n",
      "Epoch 179/200, Iteration 199/250, Loss: 0.0152\n",
      "Epoch 179/200, Iteration 200/250, Loss: 0.0196\n",
      "Epoch 179/200, Iteration 201/250, Loss: 0.0095\n",
      "Epoch 179/200, Iteration 202/250, Loss: 0.0135\n",
      "Epoch 179/200, Iteration 203/250, Loss: 0.0134\n",
      "Epoch 179/200, Iteration 204/250, Loss: 0.0147\n",
      "Epoch 179/200, Iteration 205/250, Loss: 0.0183\n",
      "Epoch 179/200, Iteration 206/250, Loss: 0.0100\n",
      "Epoch 179/200, Iteration 207/250, Loss: 0.0119\n",
      "Epoch 179/200, Iteration 208/250, Loss: 0.0130\n",
      "Epoch 179/200, Iteration 209/250, Loss: 0.0173\n",
      "Epoch 179/200, Iteration 210/250, Loss: 0.0076\n",
      "Epoch 179/200, Iteration 211/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 212/250, Loss: 0.0102\n",
      "Epoch 179/200, Iteration 213/250, Loss: 0.0203\n",
      "Epoch 179/200, Iteration 214/250, Loss: 0.0341\n",
      "Epoch 179/200, Iteration 215/250, Loss: 0.0211\n",
      "Epoch 179/200, Iteration 216/250, Loss: 0.0320\n",
      "Epoch 179/200, Iteration 217/250, Loss: 0.0221\n",
      "Epoch 179/200, Iteration 218/250, Loss: 0.0187\n",
      "Epoch 179/200, Iteration 219/250, Loss: 0.0086\n",
      "Epoch 179/200, Iteration 220/250, Loss: 0.0101\n",
      "Epoch 179/200, Iteration 221/250, Loss: 0.0185\n",
      "Epoch 179/200, Iteration 222/250, Loss: 0.0241\n",
      "Epoch 179/200, Iteration 223/250, Loss: 0.0149\n",
      "Epoch 179/200, Iteration 224/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 225/250, Loss: 0.0168\n",
      "Epoch 179/200, Iteration 226/250, Loss: 0.0146\n",
      "Epoch 179/200, Iteration 227/250, Loss: 0.0215\n",
      "Epoch 179/200, Iteration 228/250, Loss: 0.0231\n",
      "Epoch 179/200, Iteration 229/250, Loss: 0.0060\n",
      "Epoch 179/200, Iteration 230/250, Loss: 0.0152\n",
      "Epoch 179/200, Iteration 231/250, Loss: 0.0203\n",
      "Epoch 179/200, Iteration 232/250, Loss: 0.0114\n",
      "Epoch 179/200, Iteration 233/250, Loss: 0.0093\n",
      "Epoch 179/200, Iteration 234/250, Loss: 0.0285\n",
      "Epoch 179/200, Iteration 235/250, Loss: 0.0139\n",
      "Epoch 179/200, Iteration 236/250, Loss: 0.0186\n",
      "Epoch 179/200, Iteration 237/250, Loss: 0.0171\n",
      "Epoch 179/200, Iteration 238/250, Loss: 0.0102\n",
      "Epoch 179/200, Iteration 239/250, Loss: 0.0245\n",
      "Epoch 179/200, Iteration 240/250, Loss: 0.0125\n",
      "Epoch 179/200, Iteration 241/250, Loss: 0.0078\n",
      "Epoch 179/200, Iteration 242/250, Loss: 0.0137\n",
      "Epoch 179/200, Iteration 243/250, Loss: 0.0097\n",
      "Epoch 179/200, Iteration 244/250, Loss: 0.0169\n",
      "Epoch 179/200, Iteration 245/250, Loss: 0.0074\n",
      "Epoch 179/200, Iteration 246/250, Loss: 0.0107\n",
      "Epoch 179/200, Iteration 247/250, Loss: 0.0074\n",
      "Epoch 179/200, Iteration 248/250, Loss: 0.0246\n",
      "Epoch 179/200, Iteration 249/250, Loss: 0.0116\n",
      "Epoch 179/200, Iteration 250/250, Loss: 0.0203\n",
      "Train Error: \n",
      " Accuracy: 87.16%, Avg loss: 0.006817, MRE: 0.459523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.007332, MRE: 0.531770 \n",
      "\n",
      "Epoch 180/200, Iteration 1/250, Loss: 0.0122\n",
      "Epoch 180/200, Iteration 2/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 3/250, Loss: 0.0153\n",
      "Epoch 180/200, Iteration 4/250, Loss: 0.0136\n",
      "Epoch 180/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 6/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 7/250, Loss: 0.0165\n",
      "Epoch 180/200, Iteration 8/250, Loss: 0.0108\n",
      "Epoch 180/200, Iteration 9/250, Loss: 0.0263\n",
      "Epoch 180/200, Iteration 10/250, Loss: 0.0074\n",
      "Epoch 180/200, Iteration 11/250, Loss: 0.0147\n",
      "Epoch 180/200, Iteration 12/250, Loss: 0.0196\n",
      "Epoch 180/200, Iteration 13/250, Loss: 0.0068\n",
      "Epoch 180/200, Iteration 14/250, Loss: 0.0136\n",
      "Epoch 180/200, Iteration 15/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 16/250, Loss: 0.0194\n",
      "Epoch 180/200, Iteration 17/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 18/250, Loss: 0.0232\n",
      "Epoch 180/200, Iteration 19/250, Loss: 0.0150\n",
      "Epoch 180/200, Iteration 20/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 21/250, Loss: 0.0246\n",
      "Epoch 180/200, Iteration 22/250, Loss: 0.0210\n",
      "Epoch 180/200, Iteration 23/250, Loss: 0.0143\n",
      "Epoch 180/200, Iteration 24/250, Loss: 0.0166\n",
      "Epoch 180/200, Iteration 25/250, Loss: 0.0124\n",
      "Epoch 180/200, Iteration 26/250, Loss: 0.0177\n",
      "Epoch 180/200, Iteration 27/250, Loss: 0.0107\n",
      "Epoch 180/200, Iteration 28/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 29/250, Loss: 0.0098\n",
      "Epoch 180/200, Iteration 30/250, Loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Iteration 31/250, Loss: 0.0202\n",
      "Epoch 180/200, Iteration 32/250, Loss: 0.0198\n",
      "Epoch 180/200, Iteration 33/250, Loss: 0.0149\n",
      "Epoch 180/200, Iteration 34/250, Loss: 0.0233\n",
      "Epoch 180/200, Iteration 35/250, Loss: 0.0075\n",
      "Epoch 180/200, Iteration 36/250, Loss: 0.0119\n",
      "Epoch 180/200, Iteration 37/250, Loss: 0.0076\n",
      "Epoch 180/200, Iteration 38/250, Loss: 0.0089\n",
      "Epoch 180/200, Iteration 39/250, Loss: 0.0149\n",
      "Epoch 180/200, Iteration 40/250, Loss: 0.0119\n",
      "Epoch 180/200, Iteration 41/250, Loss: 0.0422\n",
      "Epoch 180/200, Iteration 42/250, Loss: 0.0081\n",
      "Epoch 180/200, Iteration 43/250, Loss: 0.0136\n",
      "Epoch 180/200, Iteration 44/250, Loss: 0.0153\n",
      "Epoch 180/200, Iteration 45/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 46/250, Loss: 0.0127\n",
      "Epoch 180/200, Iteration 47/250, Loss: 0.0154\n",
      "Epoch 180/200, Iteration 48/250, Loss: 0.0072\n",
      "Epoch 180/200, Iteration 49/250, Loss: 0.0081\n",
      "Epoch 180/200, Iteration 50/250, Loss: 0.0234\n",
      "Epoch 180/200, Iteration 51/250, Loss: 0.0275\n",
      "Epoch 180/200, Iteration 52/250, Loss: 0.0095\n",
      "Epoch 180/200, Iteration 53/250, Loss: 0.0136\n",
      "Epoch 180/200, Iteration 54/250, Loss: 0.0122\n",
      "Epoch 180/200, Iteration 55/250, Loss: 0.0310\n",
      "Epoch 180/200, Iteration 56/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 57/250, Loss: 0.0078\n",
      "Epoch 180/200, Iteration 58/250, Loss: 0.0122\n",
      "Epoch 180/200, Iteration 59/250, Loss: 0.0156\n",
      "Epoch 180/200, Iteration 60/250, Loss: 0.0216\n",
      "Epoch 180/200, Iteration 61/250, Loss: 0.0281\n",
      "Epoch 180/200, Iteration 62/250, Loss: 0.0475\n",
      "Epoch 180/200, Iteration 63/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 64/250, Loss: 0.0216\n",
      "Epoch 180/200, Iteration 65/250, Loss: 0.0077\n",
      "Epoch 180/200, Iteration 66/250, Loss: 0.0125\n",
      "Epoch 180/200, Iteration 67/250, Loss: 0.0187\n",
      "Epoch 180/200, Iteration 68/250, Loss: 0.0067\n",
      "Epoch 180/200, Iteration 69/250, Loss: 0.0176\n",
      "Epoch 180/200, Iteration 70/250, Loss: 0.0161\n",
      "Epoch 180/200, Iteration 71/250, Loss: 0.0188\n",
      "Epoch 180/200, Iteration 72/250, Loss: 0.0232\n",
      "Epoch 180/200, Iteration 73/250, Loss: 0.0070\n",
      "Epoch 180/200, Iteration 74/250, Loss: 0.0451\n",
      "Epoch 180/200, Iteration 75/250, Loss: 0.0236\n",
      "Epoch 180/200, Iteration 76/250, Loss: 0.0085\n",
      "Epoch 180/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 180/200, Iteration 78/250, Loss: 0.0278\n",
      "Epoch 180/200, Iteration 79/250, Loss: 0.0094\n",
      "Epoch 180/200, Iteration 80/250, Loss: 0.0078\n",
      "Epoch 180/200, Iteration 81/250, Loss: 0.0091\n",
      "Epoch 180/200, Iteration 82/250, Loss: 0.0112\n",
      "Epoch 180/200, Iteration 83/250, Loss: 0.0095\n",
      "Epoch 180/200, Iteration 84/250, Loss: 0.0155\n",
      "Epoch 180/200, Iteration 85/250, Loss: 0.0074\n",
      "Epoch 180/200, Iteration 86/250, Loss: 0.0222\n",
      "Epoch 180/200, Iteration 87/250, Loss: 0.0105\n",
      "Epoch 180/200, Iteration 88/250, Loss: 0.0094\n",
      "Epoch 180/200, Iteration 89/250, Loss: 0.0070\n",
      "Epoch 180/200, Iteration 90/250, Loss: 0.0216\n",
      "Epoch 180/200, Iteration 91/250, Loss: 0.0095\n",
      "Epoch 180/200, Iteration 92/250, Loss: 0.0104\n",
      "Epoch 180/200, Iteration 93/250, Loss: 0.0077\n",
      "Epoch 180/200, Iteration 94/250, Loss: 0.0170\n",
      "Epoch 180/200, Iteration 95/250, Loss: 0.0099\n",
      "Epoch 180/200, Iteration 96/250, Loss: 0.0271\n",
      "Epoch 180/200, Iteration 97/250, Loss: 0.0141\n",
      "Epoch 180/200, Iteration 98/250, Loss: 0.0103\n",
      "Epoch 180/200, Iteration 99/250, Loss: 0.0186\n",
      "Epoch 180/200, Iteration 100/250, Loss: 0.0207\n",
      "Epoch 180/200, Iteration 101/250, Loss: 0.0216\n",
      "Epoch 180/200, Iteration 102/250, Loss: 0.0140\n",
      "Epoch 180/200, Iteration 103/250, Loss: 0.0090\n",
      "Epoch 180/200, Iteration 104/250, Loss: 0.0075\n",
      "Epoch 180/200, Iteration 105/250, Loss: 0.0239\n",
      "Epoch 180/200, Iteration 106/250, Loss: 0.0124\n",
      "Epoch 180/200, Iteration 107/250, Loss: 0.0156\n",
      "Epoch 180/200, Iteration 108/250, Loss: 0.0142\n",
      "Epoch 180/200, Iteration 109/250, Loss: 0.0110\n",
      "Epoch 180/200, Iteration 110/250, Loss: 0.0097\n",
      "Epoch 180/200, Iteration 111/250, Loss: 0.0125\n",
      "Epoch 180/200, Iteration 112/250, Loss: 0.0283\n",
      "Epoch 180/200, Iteration 113/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 114/250, Loss: 0.0251\n",
      "Epoch 180/200, Iteration 115/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 116/250, Loss: 0.0101\n",
      "Epoch 180/200, Iteration 117/250, Loss: 0.0140\n",
      "Epoch 180/200, Iteration 118/250, Loss: 0.0147\n",
      "Epoch 180/200, Iteration 119/250, Loss: 0.0123\n",
      "Epoch 180/200, Iteration 120/250, Loss: 0.0068\n",
      "Epoch 180/200, Iteration 121/250, Loss: 0.0125\n",
      "Epoch 180/200, Iteration 122/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 123/250, Loss: 0.0128\n",
      "Epoch 180/200, Iteration 124/250, Loss: 0.0277\n",
      "Epoch 180/200, Iteration 125/250, Loss: 0.0159\n",
      "Epoch 180/200, Iteration 126/250, Loss: 0.0142\n",
      "Epoch 180/200, Iteration 127/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 128/250, Loss: 0.0138\n",
      "Epoch 180/200, Iteration 129/250, Loss: 0.0090\n",
      "Epoch 180/200, Iteration 130/250, Loss: 0.0110\n",
      "Epoch 180/200, Iteration 131/250, Loss: 0.0079\n",
      "Epoch 180/200, Iteration 132/250, Loss: 0.0145\n",
      "Epoch 180/200, Iteration 133/250, Loss: 0.0276\n",
      "Epoch 180/200, Iteration 134/250, Loss: 0.0100\n",
      "Epoch 180/200, Iteration 135/250, Loss: 0.0157\n",
      "Epoch 180/200, Iteration 136/250, Loss: 0.0127\n",
      "Epoch 180/200, Iteration 137/250, Loss: 0.0152\n",
      "Epoch 180/200, Iteration 138/250, Loss: 0.0086\n",
      "Epoch 180/200, Iteration 139/250, Loss: 0.0140\n",
      "Epoch 180/200, Iteration 140/250, Loss: 0.0322\n",
      "Epoch 180/200, Iteration 141/250, Loss: 0.0195\n",
      "Epoch 180/200, Iteration 142/250, Loss: 0.0180\n",
      "Epoch 180/200, Iteration 143/250, Loss: 0.0131\n",
      "Epoch 180/200, Iteration 144/250, Loss: 0.0115\n",
      "Epoch 180/200, Iteration 145/250, Loss: 0.0184\n",
      "Epoch 180/200, Iteration 146/250, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 147/250, Loss: 0.0095\n",
      "Epoch 180/200, Iteration 148/250, Loss: 0.0221\n",
      "Epoch 180/200, Iteration 149/250, Loss: 0.0072\n",
      "Epoch 180/200, Iteration 150/250, Loss: 0.0138\n",
      "Epoch 180/200, Iteration 151/250, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 152/250, Loss: 0.0098\n",
      "Epoch 180/200, Iteration 153/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 154/250, Loss: 0.0416\n",
      "Epoch 180/200, Iteration 155/250, Loss: 0.0152\n",
      "Epoch 180/200, Iteration 156/250, Loss: 0.0177\n",
      "Epoch 180/200, Iteration 157/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 158/250, Loss: 0.0169\n",
      "Epoch 180/200, Iteration 159/250, Loss: 0.0487\n",
      "Epoch 180/200, Iteration 160/250, Loss: 0.0092\n",
      "Epoch 180/200, Iteration 161/250, Loss: 0.0110\n",
      "Epoch 180/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 180/200, Iteration 163/250, Loss: 0.0113\n",
      "Epoch 180/200, Iteration 164/250, Loss: 0.0096\n",
      "Epoch 180/200, Iteration 165/250, Loss: 0.0099\n",
      "Epoch 180/200, Iteration 166/250, Loss: 0.0229\n",
      "Epoch 180/200, Iteration 167/250, Loss: 0.0084\n",
      "Epoch 180/200, Iteration 168/250, Loss: 0.0082\n",
      "Epoch 180/200, Iteration 169/250, Loss: 0.0115\n",
      "Epoch 180/200, Iteration 170/250, Loss: 0.0153\n",
      "Epoch 180/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 180/200, Iteration 172/250, Loss: 0.0105\n",
      "Epoch 180/200, Iteration 173/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 174/250, Loss: 0.0174\n",
      "Epoch 180/200, Iteration 175/250, Loss: 0.0293\n",
      "Epoch 180/200, Iteration 176/250, Loss: 0.0233\n",
      "Epoch 180/200, Iteration 177/250, Loss: 0.0140\n",
      "Epoch 180/200, Iteration 178/250, Loss: 0.0188\n",
      "Epoch 180/200, Iteration 179/250, Loss: 0.0169\n",
      "Epoch 180/200, Iteration 180/250, Loss: 0.0070\n",
      "Epoch 180/200, Iteration 181/250, Loss: 0.0095\n",
      "Epoch 180/200, Iteration 182/250, Loss: 0.0197\n",
      "Epoch 180/200, Iteration 183/250, Loss: 0.0076\n",
      "Epoch 180/200, Iteration 184/250, Loss: 0.0081\n",
      "Epoch 180/200, Iteration 185/250, Loss: 0.0161\n",
      "Epoch 180/200, Iteration 186/250, Loss: 0.0319\n",
      "Epoch 180/200, Iteration 187/250, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 188/250, Loss: 0.0080\n",
      "Epoch 180/200, Iteration 189/250, Loss: 0.0083\n",
      "Epoch 180/200, Iteration 190/250, Loss: 0.0323\n",
      "Epoch 180/200, Iteration 191/250, Loss: 0.0134\n",
      "Epoch 180/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 180/200, Iteration 193/250, Loss: 0.0135\n",
      "Epoch 180/200, Iteration 194/250, Loss: 0.0205\n",
      "Epoch 180/200, Iteration 195/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 196/250, Loss: 0.0151\n",
      "Epoch 180/200, Iteration 197/250, Loss: 0.0286\n",
      "Epoch 180/200, Iteration 198/250, Loss: 0.0170\n",
      "Epoch 180/200, Iteration 199/250, Loss: 0.0121\n",
      "Epoch 180/200, Iteration 200/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 201/250, Loss: 0.0139\n",
      "Epoch 180/200, Iteration 202/250, Loss: 0.0122\n",
      "Epoch 180/200, Iteration 203/250, Loss: 0.0117\n",
      "Epoch 180/200, Iteration 204/250, Loss: 0.0112\n",
      "Epoch 180/200, Iteration 205/250, Loss: 0.0113\n",
      "Epoch 180/200, Iteration 206/250, Loss: 0.0148\n",
      "Epoch 180/200, Iteration 207/250, Loss: 0.0113\n",
      "Epoch 180/200, Iteration 208/250, Loss: 0.0193\n",
      "Epoch 180/200, Iteration 209/250, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 210/250, Loss: 0.0229\n",
      "Epoch 180/200, Iteration 211/250, Loss: 0.0172\n",
      "Epoch 180/200, Iteration 212/250, Loss: 0.0137\n",
      "Epoch 180/200, Iteration 213/250, Loss: 0.0115\n",
      "Epoch 180/200, Iteration 214/250, Loss: 0.0207\n",
      "Epoch 180/200, Iteration 215/250, Loss: 0.0074\n",
      "Epoch 180/200, Iteration 216/250, Loss: 0.0177\n",
      "Epoch 180/200, Iteration 217/250, Loss: 0.0088\n",
      "Epoch 180/200, Iteration 218/250, Loss: 0.0216\n",
      "Epoch 180/200, Iteration 219/250, Loss: 0.0146\n",
      "Epoch 180/200, Iteration 220/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 221/250, Loss: 0.0172\n",
      "Epoch 180/200, Iteration 222/250, Loss: 0.0114\n",
      "Epoch 180/200, Iteration 223/250, Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200, Iteration 224/250, Loss: 0.0110\n",
      "Epoch 180/200, Iteration 225/250, Loss: 0.0158\n",
      "Epoch 180/200, Iteration 226/250, Loss: 0.0374\n",
      "Epoch 180/200, Iteration 227/250, Loss: 0.0140\n",
      "Epoch 180/200, Iteration 228/250, Loss: 0.0196\n",
      "Epoch 180/200, Iteration 229/250, Loss: 0.0106\n",
      "Epoch 180/200, Iteration 230/250, Loss: 0.0105\n",
      "Epoch 180/200, Iteration 231/250, Loss: 0.0118\n",
      "Epoch 180/200, Iteration 232/250, Loss: 0.0182\n",
      "Epoch 180/200, Iteration 233/250, Loss: 0.0135\n",
      "Epoch 180/200, Iteration 234/250, Loss: 0.0277\n",
      "Epoch 180/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 180/200, Iteration 236/250, Loss: 0.0189\n",
      "Epoch 180/200, Iteration 237/250, Loss: 0.0111\n",
      "Epoch 180/200, Iteration 238/250, Loss: 0.0228\n",
      "Epoch 180/200, Iteration 239/250, Loss: 0.0146\n",
      "Epoch 180/200, Iteration 240/250, Loss: 0.0100\n",
      "Epoch 180/200, Iteration 241/250, Loss: 0.0156\n",
      "Epoch 180/200, Iteration 242/250, Loss: 0.0120\n",
      "Epoch 180/200, Iteration 243/250, Loss: 0.0376\n",
      "Epoch 180/200, Iteration 244/250, Loss: 0.0093\n",
      "Epoch 180/200, Iteration 245/250, Loss: 0.0198\n",
      "Epoch 180/200, Iteration 246/250, Loss: 0.0134\n",
      "Epoch 180/200, Iteration 247/250, Loss: 0.0186\n",
      "Epoch 180/200, Iteration 248/250, Loss: 0.0146\n",
      "Epoch 180/200, Iteration 249/250, Loss: 0.0113\n",
      "Epoch 180/200, Iteration 250/250, Loss: 0.0311\n",
      "Train Error: \n",
      " Accuracy: 85.51%, Avg loss: 0.006921, MRE: 0.496058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.007438, MRE: 0.557555 \n",
      "\n",
      "Epoch 181/200, Iteration 1/250, Loss: 0.0142\n",
      "Epoch 181/200, Iteration 2/250, Loss: 0.0103\n",
      "Epoch 181/200, Iteration 3/250, Loss: 0.0312\n",
      "Epoch 181/200, Iteration 4/250, Loss: 0.0081\n",
      "Epoch 181/200, Iteration 5/250, Loss: 0.0334\n",
      "Epoch 181/200, Iteration 6/250, Loss: 0.0255\n",
      "Epoch 181/200, Iteration 7/250, Loss: 0.0138\n",
      "Epoch 181/200, Iteration 8/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 9/250, Loss: 0.0155\n",
      "Epoch 181/200, Iteration 10/250, Loss: 0.0139\n",
      "Epoch 181/200, Iteration 11/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 12/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 13/250, Loss: 0.0125\n",
      "Epoch 181/200, Iteration 14/250, Loss: 0.0162\n",
      "Epoch 181/200, Iteration 15/250, Loss: 0.0106\n",
      "Epoch 181/200, Iteration 16/250, Loss: 0.0198\n",
      "Epoch 181/200, Iteration 17/250, Loss: 0.0081\n",
      "Epoch 181/200, Iteration 18/250, Loss: 0.0121\n",
      "Epoch 181/200, Iteration 19/250, Loss: 0.0197\n",
      "Epoch 181/200, Iteration 20/250, Loss: 0.0092\n",
      "Epoch 181/200, Iteration 21/250, Loss: 0.0214\n",
      "Epoch 181/200, Iteration 22/250, Loss: 0.0123\n",
      "Epoch 181/200, Iteration 23/250, Loss: 0.0372\n",
      "Epoch 181/200, Iteration 24/250, Loss: 0.0194\n",
      "Epoch 181/200, Iteration 25/250, Loss: 0.0273\n",
      "Epoch 181/200, Iteration 26/250, Loss: 0.0076\n",
      "Epoch 181/200, Iteration 27/250, Loss: 0.0053\n",
      "Epoch 181/200, Iteration 28/250, Loss: 0.0107\n",
      "Epoch 181/200, Iteration 29/250, Loss: 0.0130\n",
      "Epoch 181/200, Iteration 30/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 31/250, Loss: 0.0135\n",
      "Epoch 181/200, Iteration 32/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 33/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 34/250, Loss: 0.0080\n",
      "Epoch 181/200, Iteration 35/250, Loss: 0.0106\n",
      "Epoch 181/200, Iteration 36/250, Loss: 0.0091\n",
      "Epoch 181/200, Iteration 37/250, Loss: 0.0169\n",
      "Epoch 181/200, Iteration 38/250, Loss: 0.0251\n",
      "Epoch 181/200, Iteration 39/250, Loss: 0.0086\n",
      "Epoch 181/200, Iteration 40/250, Loss: 0.0079\n",
      "Epoch 181/200, Iteration 41/250, Loss: 0.0219\n",
      "Epoch 181/200, Iteration 42/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 43/250, Loss: 0.0245\n",
      "Epoch 181/200, Iteration 44/250, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 45/250, Loss: 0.0169\n",
      "Epoch 181/200, Iteration 46/250, Loss: 0.0067\n",
      "Epoch 181/200, Iteration 47/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 48/250, Loss: 0.0158\n",
      "Epoch 181/200, Iteration 49/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 50/250, Loss: 0.0078\n",
      "Epoch 181/200, Iteration 51/250, Loss: 0.0160\n",
      "Epoch 181/200, Iteration 52/250, Loss: 0.0252\n",
      "Epoch 181/200, Iteration 53/250, Loss: 0.0087\n",
      "Epoch 181/200, Iteration 54/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 55/250, Loss: 0.0132\n",
      "Epoch 181/200, Iteration 56/250, Loss: 0.0109\n",
      "Epoch 181/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 58/250, Loss: 0.0332\n",
      "Epoch 181/200, Iteration 59/250, Loss: 0.0182\n",
      "Epoch 181/200, Iteration 60/250, Loss: 0.0136\n",
      "Epoch 181/200, Iteration 61/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 62/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 63/250, Loss: 0.0096\n",
      "Epoch 181/200, Iteration 64/250, Loss: 0.0067\n",
      "Epoch 181/200, Iteration 65/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 66/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 67/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 68/250, Loss: 0.0131\n",
      "Epoch 181/200, Iteration 69/250, Loss: 0.0319\n",
      "Epoch 181/200, Iteration 70/250, Loss: 0.0115\n",
      "Epoch 181/200, Iteration 71/250, Loss: 0.0076\n",
      "Epoch 181/200, Iteration 72/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 73/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 74/250, Loss: 0.0221\n",
      "Epoch 181/200, Iteration 75/250, Loss: 0.0213\n",
      "Epoch 181/200, Iteration 76/250, Loss: 0.0078\n",
      "Epoch 181/200, Iteration 77/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 78/250, Loss: 0.0137\n",
      "Epoch 181/200, Iteration 79/250, Loss: 0.0236\n",
      "Epoch 181/200, Iteration 80/250, Loss: 0.0148\n",
      "Epoch 181/200, Iteration 81/250, Loss: 0.0202\n",
      "Epoch 181/200, Iteration 82/250, Loss: 0.0179\n",
      "Epoch 181/200, Iteration 83/250, Loss: 0.0264\n",
      "Epoch 181/200, Iteration 84/250, Loss: 0.0215\n",
      "Epoch 181/200, Iteration 85/250, Loss: 0.0113\n",
      "Epoch 181/200, Iteration 86/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 87/250, Loss: 0.0181\n",
      "Epoch 181/200, Iteration 88/250, Loss: 0.0190\n",
      "Epoch 181/200, Iteration 89/250, Loss: 0.0104\n",
      "Epoch 181/200, Iteration 90/250, Loss: 0.0118\n",
      "Epoch 181/200, Iteration 91/250, Loss: 0.0193\n",
      "Epoch 181/200, Iteration 92/250, Loss: 0.0147\n",
      "Epoch 181/200, Iteration 93/250, Loss: 0.0317\n",
      "Epoch 181/200, Iteration 94/250, Loss: 0.0107\n",
      "Epoch 181/200, Iteration 95/250, Loss: 0.0114\n",
      "Epoch 181/200, Iteration 96/250, Loss: 0.0106\n",
      "Epoch 181/200, Iteration 97/250, Loss: 0.0143\n",
      "Epoch 181/200, Iteration 98/250, Loss: 0.0114\n",
      "Epoch 181/200, Iteration 99/250, Loss: 0.0238\n",
      "Epoch 181/200, Iteration 100/250, Loss: 0.0200\n",
      "Epoch 181/200, Iteration 101/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 102/250, Loss: 0.0210\n",
      "Epoch 181/200, Iteration 103/250, Loss: 0.0104\n",
      "Epoch 181/200, Iteration 104/250, Loss: 0.0079\n",
      "Epoch 181/200, Iteration 105/250, Loss: 0.0289\n",
      "Epoch 181/200, Iteration 106/250, Loss: 0.0153\n",
      "Epoch 181/200, Iteration 107/250, Loss: 0.0067\n",
      "Epoch 181/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 181/200, Iteration 109/250, Loss: 0.0100\n",
      "Epoch 181/200, Iteration 110/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 111/250, Loss: 0.0084\n",
      "Epoch 181/200, Iteration 112/250, Loss: 0.0152\n",
      "Epoch 181/200, Iteration 113/250, Loss: 0.0335\n",
      "Epoch 181/200, Iteration 114/250, Loss: 0.0208\n",
      "Epoch 181/200, Iteration 115/250, Loss: 0.0149\n",
      "Epoch 181/200, Iteration 116/250, Loss: 0.0108\n",
      "Epoch 181/200, Iteration 117/250, Loss: 0.0135\n",
      "Epoch 181/200, Iteration 118/250, Loss: 0.0118\n",
      "Epoch 181/200, Iteration 119/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 120/250, Loss: 0.0102\n",
      "Epoch 181/200, Iteration 121/250, Loss: 0.0076\n",
      "Epoch 181/200, Iteration 122/250, Loss: 0.0114\n",
      "Epoch 181/200, Iteration 123/250, Loss: 0.0102\n",
      "Epoch 181/200, Iteration 124/250, Loss: 0.0101\n",
      "Epoch 181/200, Iteration 125/250, Loss: 0.0290\n",
      "Epoch 181/200, Iteration 126/250, Loss: 0.0071\n",
      "Epoch 181/200, Iteration 127/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 128/250, Loss: 0.0350\n",
      "Epoch 181/200, Iteration 129/250, Loss: 0.0088\n",
      "Epoch 181/200, Iteration 130/250, Loss: 0.0162\n",
      "Epoch 181/200, Iteration 131/250, Loss: 0.0330\n",
      "Epoch 181/200, Iteration 132/250, Loss: 0.0241\n",
      "Epoch 181/200, Iteration 133/250, Loss: 0.0098\n",
      "Epoch 181/200, Iteration 134/250, Loss: 0.0182\n",
      "Epoch 181/200, Iteration 135/250, Loss: 0.0265\n",
      "Epoch 181/200, Iteration 136/250, Loss: 0.0168\n",
      "Epoch 181/200, Iteration 137/250, Loss: 0.0358\n",
      "Epoch 181/200, Iteration 138/250, Loss: 0.0071\n",
      "Epoch 181/200, Iteration 139/250, Loss: 0.0267\n",
      "Epoch 181/200, Iteration 140/250, Loss: 0.0091\n",
      "Epoch 181/200, Iteration 141/250, Loss: 0.0074\n",
      "Epoch 181/200, Iteration 142/250, Loss: 0.0131\n",
      "Epoch 181/200, Iteration 143/250, Loss: 0.0138\n",
      "Epoch 181/200, Iteration 144/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 145/250, Loss: 0.0075\n",
      "Epoch 181/200, Iteration 146/250, Loss: 0.0257\n",
      "Epoch 181/200, Iteration 147/250, Loss: 0.0106\n",
      "Epoch 181/200, Iteration 148/250, Loss: 0.0147\n",
      "Epoch 181/200, Iteration 149/250, Loss: 0.0314\n",
      "Epoch 181/200, Iteration 150/250, Loss: 0.0245\n",
      "Epoch 181/200, Iteration 151/250, Loss: 0.0124\n",
      "Epoch 181/200, Iteration 152/250, Loss: 0.0104\n",
      "Epoch 181/200, Iteration 153/250, Loss: 0.0107\n",
      "Epoch 181/200, Iteration 154/250, Loss: 0.0279\n",
      "Epoch 181/200, Iteration 155/250, Loss: 0.0153\n",
      "Epoch 181/200, Iteration 156/250, Loss: 0.0105\n",
      "Epoch 181/200, Iteration 157/250, Loss: 0.0092\n",
      "Epoch 181/200, Iteration 158/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 159/250, Loss: 0.0226\n",
      "Epoch 181/200, Iteration 160/250, Loss: 0.0089\n",
      "Epoch 181/200, Iteration 161/250, Loss: 0.0115\n",
      "Epoch 181/200, Iteration 162/250, Loss: 0.0126\n",
      "Epoch 181/200, Iteration 163/250, Loss: 0.0383\n",
      "Epoch 181/200, Iteration 164/250, Loss: 0.0086\n",
      "Epoch 181/200, Iteration 165/250, Loss: 0.0178\n",
      "Epoch 181/200, Iteration 166/250, Loss: 0.0110\n",
      "Epoch 181/200, Iteration 167/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 168/250, Loss: 0.0137\n",
      "Epoch 181/200, Iteration 169/250, Loss: 0.0093\n",
      "Epoch 181/200, Iteration 170/250, Loss: 0.0069\n",
      "Epoch 181/200, Iteration 171/250, Loss: 0.0247\n",
      "Epoch 181/200, Iteration 172/250, Loss: 0.0145\n",
      "Epoch 181/200, Iteration 173/250, Loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200, Iteration 174/250, Loss: 0.0176\n",
      "Epoch 181/200, Iteration 175/250, Loss: 0.0147\n",
      "Epoch 181/200, Iteration 176/250, Loss: 0.0172\n",
      "Epoch 181/200, Iteration 177/250, Loss: 0.0219\n",
      "Epoch 181/200, Iteration 178/250, Loss: 0.0081\n",
      "Epoch 181/200, Iteration 179/250, Loss: 0.0171\n",
      "Epoch 181/200, Iteration 180/250, Loss: 0.0128\n",
      "Epoch 181/200, Iteration 181/250, Loss: 0.0313\n",
      "Epoch 181/200, Iteration 182/250, Loss: 0.0343\n",
      "Epoch 181/200, Iteration 183/250, Loss: 0.0260\n",
      "Epoch 181/200, Iteration 184/250, Loss: 0.0097\n",
      "Epoch 181/200, Iteration 185/250, Loss: 0.0070\n",
      "Epoch 181/200, Iteration 186/250, Loss: 0.0100\n",
      "Epoch 181/200, Iteration 187/250, Loss: 0.0111\n",
      "Epoch 181/200, Iteration 188/250, Loss: 0.0187\n",
      "Epoch 181/200, Iteration 189/250, Loss: 0.0075\n",
      "Epoch 181/200, Iteration 190/250, Loss: 0.0125\n",
      "Epoch 181/200, Iteration 191/250, Loss: 0.0131\n",
      "Epoch 181/200, Iteration 192/250, Loss: 0.0173\n",
      "Epoch 181/200, Iteration 193/250, Loss: 0.0112\n",
      "Epoch 181/200, Iteration 194/250, Loss: 0.0101\n",
      "Epoch 181/200, Iteration 195/250, Loss: 0.0127\n",
      "Epoch 181/200, Iteration 196/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 197/250, Loss: 0.0061\n",
      "Epoch 181/200, Iteration 198/250, Loss: 0.0087\n",
      "Epoch 181/200, Iteration 199/250, Loss: 0.0116\n",
      "Epoch 181/200, Iteration 200/250, Loss: 0.0103\n",
      "Epoch 181/200, Iteration 201/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 202/250, Loss: 0.0341\n",
      "Epoch 181/200, Iteration 203/250, Loss: 0.0090\n",
      "Epoch 181/200, Iteration 204/250, Loss: 0.0190\n",
      "Epoch 181/200, Iteration 205/250, Loss: 0.0158\n",
      "Epoch 181/200, Iteration 206/250, Loss: 0.0177\n",
      "Epoch 181/200, Iteration 207/250, Loss: 0.0162\n",
      "Epoch 181/200, Iteration 208/250, Loss: 0.0132\n",
      "Epoch 181/200, Iteration 209/250, Loss: 0.0092\n",
      "Epoch 181/200, Iteration 210/250, Loss: 0.0120\n",
      "Epoch 181/200, Iteration 211/250, Loss: 0.0167\n",
      "Epoch 181/200, Iteration 212/250, Loss: 0.0209\n",
      "Epoch 181/200, Iteration 213/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 214/250, Loss: 0.0078\n",
      "Epoch 181/200, Iteration 215/250, Loss: 0.0065\n",
      "Epoch 181/200, Iteration 216/250, Loss: 0.0185\n",
      "Epoch 181/200, Iteration 217/250, Loss: 0.0228\n",
      "Epoch 181/200, Iteration 218/250, Loss: 0.0087\n",
      "Epoch 181/200, Iteration 219/250, Loss: 0.0140\n",
      "Epoch 181/200, Iteration 220/250, Loss: 0.0109\n",
      "Epoch 181/200, Iteration 221/250, Loss: 0.0093\n",
      "Epoch 181/200, Iteration 222/250, Loss: 0.0077\n",
      "Epoch 181/200, Iteration 223/250, Loss: 0.0087\n",
      "Epoch 181/200, Iteration 224/250, Loss: 0.0180\n",
      "Epoch 181/200, Iteration 225/250, Loss: 0.0168\n",
      "Epoch 181/200, Iteration 226/250, Loss: 0.0167\n",
      "Epoch 181/200, Iteration 227/250, Loss: 0.0287\n",
      "Epoch 181/200, Iteration 228/250, Loss: 0.0131\n",
      "Epoch 181/200, Iteration 229/250, Loss: 0.0236\n",
      "Epoch 181/200, Iteration 230/250, Loss: 0.0501\n",
      "Epoch 181/200, Iteration 231/250, Loss: 0.0094\n",
      "Epoch 181/200, Iteration 232/250, Loss: 0.0132\n",
      "Epoch 181/200, Iteration 233/250, Loss: 0.0082\n",
      "Epoch 181/200, Iteration 234/250, Loss: 0.0283\n",
      "Epoch 181/200, Iteration 235/250, Loss: 0.0098\n",
      "Epoch 181/200, Iteration 236/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 237/250, Loss: 0.0152\n",
      "Epoch 181/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 181/200, Iteration 239/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 240/250, Loss: 0.0170\n",
      "Epoch 181/200, Iteration 241/250, Loss: 0.0327\n",
      "Epoch 181/200, Iteration 242/250, Loss: 0.0152\n",
      "Epoch 181/200, Iteration 243/250, Loss: 0.0122\n",
      "Epoch 181/200, Iteration 244/250, Loss: 0.0217\n",
      "Epoch 181/200, Iteration 245/250, Loss: 0.0195\n",
      "Epoch 181/200, Iteration 246/250, Loss: 0.0099\n",
      "Epoch 181/200, Iteration 247/250, Loss: 0.0179\n",
      "Epoch 181/200, Iteration 248/250, Loss: 0.0164\n",
      "Epoch 181/200, Iteration 249/250, Loss: 0.0095\n",
      "Epoch 181/200, Iteration 250/250, Loss: 0.0448\n",
      "Train Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.006819, MRE: 0.460172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.007396, MRE: 0.515471 \n",
      "\n",
      "Epoch 182/200, Iteration 1/250, Loss: 0.0176\n",
      "Epoch 182/200, Iteration 2/250, Loss: 0.0162\n",
      "Epoch 182/200, Iteration 3/250, Loss: 0.0314\n",
      "Epoch 182/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 5/250, Loss: 0.0160\n",
      "Epoch 182/200, Iteration 6/250, Loss: 0.0191\n",
      "Epoch 182/200, Iteration 7/250, Loss: 0.0090\n",
      "Epoch 182/200, Iteration 8/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 9/250, Loss: 0.0203\n",
      "Epoch 182/200, Iteration 10/250, Loss: 0.0237\n",
      "Epoch 182/200, Iteration 11/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 12/250, Loss: 0.0195\n",
      "Epoch 182/200, Iteration 13/250, Loss: 0.0113\n",
      "Epoch 182/200, Iteration 14/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 15/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 16/250, Loss: 0.0178\n",
      "Epoch 182/200, Iteration 17/250, Loss: 0.0237\n",
      "Epoch 182/200, Iteration 18/250, Loss: 0.0274\n",
      "Epoch 182/200, Iteration 19/250, Loss: 0.0238\n",
      "Epoch 182/200, Iteration 20/250, Loss: 0.0383\n",
      "Epoch 182/200, Iteration 21/250, Loss: 0.0108\n",
      "Epoch 182/200, Iteration 22/250, Loss: 0.0180\n",
      "Epoch 182/200, Iteration 23/250, Loss: 0.0109\n",
      "Epoch 182/200, Iteration 24/250, Loss: 0.0222\n",
      "Epoch 182/200, Iteration 25/250, Loss: 0.0220\n",
      "Epoch 182/200, Iteration 26/250, Loss: 0.0140\n",
      "Epoch 182/200, Iteration 27/250, Loss: 0.0253\n",
      "Epoch 182/200, Iteration 28/250, Loss: 0.0083\n",
      "Epoch 182/200, Iteration 29/250, Loss: 0.0083\n",
      "Epoch 182/200, Iteration 30/250, Loss: 0.0176\n",
      "Epoch 182/200, Iteration 31/250, Loss: 0.0084\n",
      "Epoch 182/200, Iteration 32/250, Loss: 0.0111\n",
      "Epoch 182/200, Iteration 33/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 34/250, Loss: 0.0308\n",
      "Epoch 182/200, Iteration 35/250, Loss: 0.0130\n",
      "Epoch 182/200, Iteration 36/250, Loss: 0.0172\n",
      "Epoch 182/200, Iteration 37/250, Loss: 0.0341\n",
      "Epoch 182/200, Iteration 38/250, Loss: 0.0204\n",
      "Epoch 182/200, Iteration 39/250, Loss: 0.0218\n",
      "Epoch 182/200, Iteration 40/250, Loss: 0.0177\n",
      "Epoch 182/200, Iteration 41/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 42/250, Loss: 0.0118\n",
      "Epoch 182/200, Iteration 43/250, Loss: 0.0055\n",
      "Epoch 182/200, Iteration 44/250, Loss: 0.0148\n",
      "Epoch 182/200, Iteration 45/250, Loss: 0.0111\n",
      "Epoch 182/200, Iteration 46/250, Loss: 0.0084\n",
      "Epoch 182/200, Iteration 47/250, Loss: 0.0155\n",
      "Epoch 182/200, Iteration 48/250, Loss: 0.0231\n",
      "Epoch 182/200, Iteration 49/250, Loss: 0.0167\n",
      "Epoch 182/200, Iteration 50/250, Loss: 0.0269\n",
      "Epoch 182/200, Iteration 51/250, Loss: 0.0080\n",
      "Epoch 182/200, Iteration 52/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 53/250, Loss: 0.0188\n",
      "Epoch 182/200, Iteration 54/250, Loss: 0.0158\n",
      "Epoch 182/200, Iteration 55/250, Loss: 0.0069\n",
      "Epoch 182/200, Iteration 56/250, Loss: 0.0156\n",
      "Epoch 182/200, Iteration 57/250, Loss: 0.0132\n",
      "Epoch 182/200, Iteration 58/250, Loss: 0.0116\n",
      "Epoch 182/200, Iteration 59/250, Loss: 0.0088\n",
      "Epoch 182/200, Iteration 60/250, Loss: 0.0126\n",
      "Epoch 182/200, Iteration 61/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 62/250, Loss: 0.0091\n",
      "Epoch 182/200, Iteration 63/250, Loss: 0.0220\n",
      "Epoch 182/200, Iteration 64/250, Loss: 0.0210\n",
      "Epoch 182/200, Iteration 65/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 66/250, Loss: 0.0173\n",
      "Epoch 182/200, Iteration 67/250, Loss: 0.0108\n",
      "Epoch 182/200, Iteration 68/250, Loss: 0.0216\n",
      "Epoch 182/200, Iteration 69/250, Loss: 0.0239\n",
      "Epoch 182/200, Iteration 70/250, Loss: 0.0062\n",
      "Epoch 182/200, Iteration 71/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 72/250, Loss: 0.0291\n",
      "Epoch 182/200, Iteration 73/250, Loss: 0.0112\n",
      "Epoch 182/200, Iteration 74/250, Loss: 0.0133\n",
      "Epoch 182/200, Iteration 75/250, Loss: 0.0091\n",
      "Epoch 182/200, Iteration 76/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 77/250, Loss: 0.0200\n",
      "Epoch 182/200, Iteration 78/250, Loss: 0.0176\n",
      "Epoch 182/200, Iteration 79/250, Loss: 0.0160\n",
      "Epoch 182/200, Iteration 80/250, Loss: 0.0131\n",
      "Epoch 182/200, Iteration 81/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 82/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 83/250, Loss: 0.0100\n",
      "Epoch 182/200, Iteration 84/250, Loss: 0.0146\n",
      "Epoch 182/200, Iteration 85/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 86/250, Loss: 0.0111\n",
      "Epoch 182/200, Iteration 87/250, Loss: 0.0210\n",
      "Epoch 182/200, Iteration 88/250, Loss: 0.0218\n",
      "Epoch 182/200, Iteration 89/250, Loss: 0.0124\n",
      "Epoch 182/200, Iteration 90/250, Loss: 0.0267\n",
      "Epoch 182/200, Iteration 91/250, Loss: 0.0216\n",
      "Epoch 182/200, Iteration 92/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 93/250, Loss: 0.0178\n",
      "Epoch 182/200, Iteration 94/250, Loss: 0.0142\n",
      "Epoch 182/200, Iteration 95/250, Loss: 0.0092\n",
      "Epoch 182/200, Iteration 96/250, Loss: 0.0176\n",
      "Epoch 182/200, Iteration 97/250, Loss: 0.0167\n",
      "Epoch 182/200, Iteration 98/250, Loss: 0.0142\n",
      "Epoch 182/200, Iteration 99/250, Loss: 0.0184\n",
      "Epoch 182/200, Iteration 100/250, Loss: 0.0088\n",
      "Epoch 182/200, Iteration 101/250, Loss: 0.0217\n",
      "Epoch 182/200, Iteration 102/250, Loss: 0.0114\n",
      "Epoch 182/200, Iteration 103/250, Loss: 0.0323\n",
      "Epoch 182/200, Iteration 104/250, Loss: 0.0186\n",
      "Epoch 182/200, Iteration 105/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 106/250, Loss: 0.0191\n",
      "Epoch 182/200, Iteration 107/250, Loss: 0.0232\n",
      "Epoch 182/200, Iteration 108/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 109/250, Loss: 0.0099\n",
      "Epoch 182/200, Iteration 110/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 111/250, Loss: 0.0209\n",
      "Epoch 182/200, Iteration 112/250, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/200, Iteration 113/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 114/250, Loss: 0.0072\n",
      "Epoch 182/200, Iteration 115/250, Loss: 0.0107\n",
      "Epoch 182/200, Iteration 116/250, Loss: 0.0212\n",
      "Epoch 182/200, Iteration 117/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 118/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 119/250, Loss: 0.0117\n",
      "Epoch 182/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 182/200, Iteration 121/250, Loss: 0.0143\n",
      "Epoch 182/200, Iteration 122/250, Loss: 0.0118\n",
      "Epoch 182/200, Iteration 123/250, Loss: 0.0121\n",
      "Epoch 182/200, Iteration 124/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 125/250, Loss: 0.0172\n",
      "Epoch 182/200, Iteration 126/250, Loss: 0.0153\n",
      "Epoch 182/200, Iteration 127/250, Loss: 0.0230\n",
      "Epoch 182/200, Iteration 128/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 129/250, Loss: 0.0177\n",
      "Epoch 182/200, Iteration 130/250, Loss: 0.0179\n",
      "Epoch 182/200, Iteration 131/250, Loss: 0.0130\n",
      "Epoch 182/200, Iteration 132/250, Loss: 0.0114\n",
      "Epoch 182/200, Iteration 133/250, Loss: 0.0192\n",
      "Epoch 182/200, Iteration 134/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 182/200, Iteration 136/250, Loss: 0.0180\n",
      "Epoch 182/200, Iteration 137/250, Loss: 0.0203\n",
      "Epoch 182/200, Iteration 138/250, Loss: 0.0065\n",
      "Epoch 182/200, Iteration 139/250, Loss: 0.0098\n",
      "Epoch 182/200, Iteration 140/250, Loss: 0.0196\n",
      "Epoch 182/200, Iteration 141/250, Loss: 0.0294\n",
      "Epoch 182/200, Iteration 142/250, Loss: 0.0140\n",
      "Epoch 182/200, Iteration 143/250, Loss: 0.0290\n",
      "Epoch 182/200, Iteration 144/250, Loss: 0.0086\n",
      "Epoch 182/200, Iteration 145/250, Loss: 0.0367\n",
      "Epoch 182/200, Iteration 146/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 147/250, Loss: 0.0106\n",
      "Epoch 182/200, Iteration 148/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 149/250, Loss: 0.0071\n",
      "Epoch 182/200, Iteration 150/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 151/250, Loss: 0.0165\n",
      "Epoch 182/200, Iteration 152/250, Loss: 0.0070\n",
      "Epoch 182/200, Iteration 153/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 154/250, Loss: 0.0129\n",
      "Epoch 182/200, Iteration 155/250, Loss: 0.0254\n",
      "Epoch 182/200, Iteration 156/250, Loss: 0.0148\n",
      "Epoch 182/200, Iteration 157/250, Loss: 0.0161\n",
      "Epoch 182/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 182/200, Iteration 159/250, Loss: 0.0177\n",
      "Epoch 182/200, Iteration 160/250, Loss: 0.0107\n",
      "Epoch 182/200, Iteration 161/250, Loss: 0.0099\n",
      "Epoch 182/200, Iteration 162/250, Loss: 0.0197\n",
      "Epoch 182/200, Iteration 163/250, Loss: 0.0159\n",
      "Epoch 182/200, Iteration 164/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 165/250, Loss: 0.0152\n",
      "Epoch 182/200, Iteration 166/250, Loss: 0.0162\n",
      "Epoch 182/200, Iteration 167/250, Loss: 0.0075\n",
      "Epoch 182/200, Iteration 168/250, Loss: 0.0167\n",
      "Epoch 182/200, Iteration 169/250, Loss: 0.0131\n",
      "Epoch 182/200, Iteration 170/250, Loss: 0.0128\n",
      "Epoch 182/200, Iteration 171/250, Loss: 0.0081\n",
      "Epoch 182/200, Iteration 172/250, Loss: 0.0119\n",
      "Epoch 182/200, Iteration 173/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 174/250, Loss: 0.0133\n",
      "Epoch 182/200, Iteration 175/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 176/250, Loss: 0.0256\n",
      "Epoch 182/200, Iteration 177/250, Loss: 0.0225\n",
      "Epoch 182/200, Iteration 178/250, Loss: 0.0156\n",
      "Epoch 182/200, Iteration 179/250, Loss: 0.0136\n",
      "Epoch 182/200, Iteration 180/250, Loss: 0.0139\n",
      "Epoch 182/200, Iteration 181/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 182/250, Loss: 0.0174\n",
      "Epoch 182/200, Iteration 183/250, Loss: 0.0140\n",
      "Epoch 182/200, Iteration 184/250, Loss: 0.0269\n",
      "Epoch 182/200, Iteration 185/250, Loss: 0.0085\n",
      "Epoch 182/200, Iteration 186/250, Loss: 0.0129\n",
      "Epoch 182/200, Iteration 187/250, Loss: 0.0119\n",
      "Epoch 182/200, Iteration 188/250, Loss: 0.0091\n",
      "Epoch 182/200, Iteration 189/250, Loss: 0.0128\n",
      "Epoch 182/200, Iteration 190/250, Loss: 0.0154\n",
      "Epoch 182/200, Iteration 191/250, Loss: 0.0135\n",
      "Epoch 182/200, Iteration 192/250, Loss: 0.0090\n",
      "Epoch 182/200, Iteration 193/250, Loss: 0.0184\n",
      "Epoch 182/200, Iteration 194/250, Loss: 0.0229\n",
      "Epoch 182/200, Iteration 195/250, Loss: 0.0119\n",
      "Epoch 182/200, Iteration 196/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 197/250, Loss: 0.0072\n",
      "Epoch 182/200, Iteration 198/250, Loss: 0.0088\n",
      "Epoch 182/200, Iteration 199/250, Loss: 0.0090\n",
      "Epoch 182/200, Iteration 200/250, Loss: 0.0068\n",
      "Epoch 182/200, Iteration 201/250, Loss: 0.0082\n",
      "Epoch 182/200, Iteration 202/250, Loss: 0.0170\n",
      "Epoch 182/200, Iteration 203/250, Loss: 0.0132\n",
      "Epoch 182/200, Iteration 204/250, Loss: 0.0316\n",
      "Epoch 182/200, Iteration 205/250, Loss: 0.0108\n",
      "Epoch 182/200, Iteration 206/250, Loss: 0.0097\n",
      "Epoch 182/200, Iteration 207/250, Loss: 0.0105\n",
      "Epoch 182/200, Iteration 208/250, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 209/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 210/250, Loss: 0.0097\n",
      "Epoch 182/200, Iteration 211/250, Loss: 0.0184\n",
      "Epoch 182/200, Iteration 212/250, Loss: 0.0220\n",
      "Epoch 182/200, Iteration 213/250, Loss: 0.0105\n",
      "Epoch 182/200, Iteration 214/250, Loss: 0.0072\n",
      "Epoch 182/200, Iteration 215/250, Loss: 0.0103\n",
      "Epoch 182/200, Iteration 216/250, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 217/250, Loss: 0.0267\n",
      "Epoch 182/200, Iteration 218/250, Loss: 0.0087\n",
      "Epoch 182/200, Iteration 219/250, Loss: 0.0143\n",
      "Epoch 182/200, Iteration 220/250, Loss: 0.0303\n",
      "Epoch 182/200, Iteration 221/250, Loss: 0.0323\n",
      "Epoch 182/200, Iteration 222/250, Loss: 0.0193\n",
      "Epoch 182/200, Iteration 223/250, Loss: 0.0117\n",
      "Epoch 182/200, Iteration 224/250, Loss: 0.0220\n",
      "Epoch 182/200, Iteration 225/250, Loss: 0.0102\n",
      "Epoch 182/200, Iteration 226/250, Loss: 0.0104\n",
      "Epoch 182/200, Iteration 227/250, Loss: 0.0175\n",
      "Epoch 182/200, Iteration 228/250, Loss: 0.0115\n",
      "Epoch 182/200, Iteration 229/250, Loss: 0.0089\n",
      "Epoch 182/200, Iteration 230/250, Loss: 0.0134\n",
      "Epoch 182/200, Iteration 231/250, Loss: 0.0064\n",
      "Epoch 182/200, Iteration 232/250, Loss: 0.0116\n",
      "Epoch 182/200, Iteration 233/250, Loss: 0.0123\n",
      "Epoch 182/200, Iteration 234/250, Loss: 0.0096\n",
      "Epoch 182/200, Iteration 235/250, Loss: 0.0084\n",
      "Epoch 182/200, Iteration 236/250, Loss: 0.0197\n",
      "Epoch 182/200, Iteration 237/250, Loss: 0.0313\n",
      "Epoch 182/200, Iteration 238/250, Loss: 0.0100\n",
      "Epoch 182/200, Iteration 239/250, Loss: 0.0137\n",
      "Epoch 182/200, Iteration 240/250, Loss: 0.0171\n",
      "Epoch 182/200, Iteration 241/250, Loss: 0.0099\n",
      "Epoch 182/200, Iteration 242/250, Loss: 0.0174\n",
      "Epoch 182/200, Iteration 243/250, Loss: 0.0214\n",
      "Epoch 182/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 182/200, Iteration 245/250, Loss: 0.0166\n",
      "Epoch 182/200, Iteration 246/250, Loss: 0.0145\n",
      "Epoch 182/200, Iteration 247/250, Loss: 0.0176\n",
      "Epoch 182/200, Iteration 248/250, Loss: 0.0120\n",
      "Epoch 182/200, Iteration 249/250, Loss: 0.0242\n",
      "Epoch 182/200, Iteration 250/250, Loss: 0.0123\n",
      "Train Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.006829, MRE: 0.422105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.85%, Avg loss: 0.007338, MRE: 0.522598 \n",
      "\n",
      "Epoch 183/200, Iteration 1/250, Loss: 0.0241\n",
      "Epoch 183/200, Iteration 2/250, Loss: 0.0174\n",
      "Epoch 183/200, Iteration 3/250, Loss: 0.0224\n",
      "Epoch 183/200, Iteration 4/250, Loss: 0.0139\n",
      "Epoch 183/200, Iteration 5/250, Loss: 0.0250\n",
      "Epoch 183/200, Iteration 6/250, Loss: 0.0193\n",
      "Epoch 183/200, Iteration 7/250, Loss: 0.0246\n",
      "Epoch 183/200, Iteration 8/250, Loss: 0.0131\n",
      "Epoch 183/200, Iteration 9/250, Loss: 0.0171\n",
      "Epoch 183/200, Iteration 10/250, Loss: 0.0215\n",
      "Epoch 183/200, Iteration 11/250, Loss: 0.0277\n",
      "Epoch 183/200, Iteration 12/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 13/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 14/250, Loss: 0.0237\n",
      "Epoch 183/200, Iteration 15/250, Loss: 0.0317\n",
      "Epoch 183/200, Iteration 16/250, Loss: 0.0466\n",
      "Epoch 183/200, Iteration 17/250, Loss: 0.0247\n",
      "Epoch 183/200, Iteration 18/250, Loss: 0.0186\n",
      "Epoch 183/200, Iteration 19/250, Loss: 0.0145\n",
      "Epoch 183/200, Iteration 20/250, Loss: 0.0069\n",
      "Epoch 183/200, Iteration 21/250, Loss: 0.0123\n",
      "Epoch 183/200, Iteration 22/250, Loss: 0.0266\n",
      "Epoch 183/200, Iteration 23/250, Loss: 0.0192\n",
      "Epoch 183/200, Iteration 24/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 25/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 26/250, Loss: 0.0200\n",
      "Epoch 183/200, Iteration 27/250, Loss: 0.0169\n",
      "Epoch 183/200, Iteration 28/250, Loss: 0.0092\n",
      "Epoch 183/200, Iteration 29/250, Loss: 0.0159\n",
      "Epoch 183/200, Iteration 30/250, Loss: 0.0438\n",
      "Epoch 183/200, Iteration 31/250, Loss: 0.0084\n",
      "Epoch 183/200, Iteration 32/250, Loss: 0.0273\n",
      "Epoch 183/200, Iteration 33/250, Loss: 0.0303\n",
      "Epoch 183/200, Iteration 34/250, Loss: 0.0104\n",
      "Epoch 183/200, Iteration 35/250, Loss: 0.0285\n",
      "Epoch 183/200, Iteration 36/250, Loss: 0.0078\n",
      "Epoch 183/200, Iteration 37/250, Loss: 0.0103\n",
      "Epoch 183/200, Iteration 38/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 39/250, Loss: 0.0108\n",
      "Epoch 183/200, Iteration 40/250, Loss: 0.0092\n",
      "Epoch 183/200, Iteration 41/250, Loss: 0.0155\n",
      "Epoch 183/200, Iteration 42/250, Loss: 0.0223\n",
      "Epoch 183/200, Iteration 43/250, Loss: 0.0178\n",
      "Epoch 183/200, Iteration 44/250, Loss: 0.0111\n",
      "Epoch 183/200, Iteration 45/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 46/250, Loss: 0.0208\n",
      "Epoch 183/200, Iteration 47/250, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200, Iteration 48/250, Loss: 0.0254\n",
      "Epoch 183/200, Iteration 49/250, Loss: 0.0168\n",
      "Epoch 183/200, Iteration 50/250, Loss: 0.0079\n",
      "Epoch 183/200, Iteration 51/250, Loss: 0.0150\n",
      "Epoch 183/200, Iteration 52/250, Loss: 0.0357\n",
      "Epoch 183/200, Iteration 53/250, Loss: 0.0139\n",
      "Epoch 183/200, Iteration 54/250, Loss: 0.0099\n",
      "Epoch 183/200, Iteration 55/250, Loss: 0.0094\n",
      "Epoch 183/200, Iteration 56/250, Loss: 0.0098\n",
      "Epoch 183/200, Iteration 57/250, Loss: 0.0146\n",
      "Epoch 183/200, Iteration 58/250, Loss: 0.0124\n",
      "Epoch 183/200, Iteration 59/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 60/250, Loss: 0.0172\n",
      "Epoch 183/200, Iteration 61/250, Loss: 0.0155\n",
      "Epoch 183/200, Iteration 62/250, Loss: 0.0207\n",
      "Epoch 183/200, Iteration 63/250, Loss: 0.0302\n",
      "Epoch 183/200, Iteration 64/250, Loss: 0.0116\n",
      "Epoch 183/200, Iteration 65/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 66/250, Loss: 0.0150\n",
      "Epoch 183/200, Iteration 67/250, Loss: 0.0145\n",
      "Epoch 183/200, Iteration 68/250, Loss: 0.0098\n",
      "Epoch 183/200, Iteration 69/250, Loss: 0.0138\n",
      "Epoch 183/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 183/200, Iteration 71/250, Loss: 0.0094\n",
      "Epoch 183/200, Iteration 72/250, Loss: 0.0078\n",
      "Epoch 183/200, Iteration 73/250, Loss: 0.0279\n",
      "Epoch 183/200, Iteration 74/250, Loss: 0.0154\n",
      "Epoch 183/200, Iteration 75/250, Loss: 0.0095\n",
      "Epoch 183/200, Iteration 76/250, Loss: 0.0113\n",
      "Epoch 183/200, Iteration 77/250, Loss: 0.0141\n",
      "Epoch 183/200, Iteration 78/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 79/250, Loss: 0.0195\n",
      "Epoch 183/200, Iteration 80/250, Loss: 0.0195\n",
      "Epoch 183/200, Iteration 81/250, Loss: 0.0202\n",
      "Epoch 183/200, Iteration 82/250, Loss: 0.0153\n",
      "Epoch 183/200, Iteration 83/250, Loss: 0.0151\n",
      "Epoch 183/200, Iteration 84/250, Loss: 0.0201\n",
      "Epoch 183/200, Iteration 85/250, Loss: 0.0311\n",
      "Epoch 183/200, Iteration 86/250, Loss: 0.0197\n",
      "Epoch 183/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 183/200, Iteration 88/250, Loss: 0.0098\n",
      "Epoch 183/200, Iteration 89/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 90/250, Loss: 0.0189\n",
      "Epoch 183/200, Iteration 91/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 183/200, Iteration 93/250, Loss: 0.0082\n",
      "Epoch 183/200, Iteration 94/250, Loss: 0.0162\n",
      "Epoch 183/200, Iteration 95/250, Loss: 0.0209\n",
      "Epoch 183/200, Iteration 96/250, Loss: 0.0216\n",
      "Epoch 183/200, Iteration 97/250, Loss: 0.0108\n",
      "Epoch 183/200, Iteration 98/250, Loss: 0.0305\n",
      "Epoch 183/200, Iteration 99/250, Loss: 0.0105\n",
      "Epoch 183/200, Iteration 100/250, Loss: 0.0229\n",
      "Epoch 183/200, Iteration 101/250, Loss: 0.0178\n",
      "Epoch 183/200, Iteration 102/250, Loss: 0.0091\n",
      "Epoch 183/200, Iteration 103/250, Loss: 0.0210\n",
      "Epoch 183/200, Iteration 104/250, Loss: 0.0088\n",
      "Epoch 183/200, Iteration 105/250, Loss: 0.0095\n",
      "Epoch 183/200, Iteration 106/250, Loss: 0.0232\n",
      "Epoch 183/200, Iteration 107/250, Loss: 0.0175\n",
      "Epoch 183/200, Iteration 108/250, Loss: 0.0102\n",
      "Epoch 183/200, Iteration 109/250, Loss: 0.0348\n",
      "Epoch 183/200, Iteration 110/250, Loss: 0.0115\n",
      "Epoch 183/200, Iteration 111/250, Loss: 0.0186\n",
      "Epoch 183/200, Iteration 112/250, Loss: 0.0246\n",
      "Epoch 183/200, Iteration 113/250, Loss: 0.0339\n",
      "Epoch 183/200, Iteration 114/250, Loss: 0.0095\n",
      "Epoch 183/200, Iteration 115/250, Loss: 0.0062\n",
      "Epoch 183/200, Iteration 116/250, Loss: 0.0286\n",
      "Epoch 183/200, Iteration 117/250, Loss: 0.0191\n",
      "Epoch 183/200, Iteration 118/250, Loss: 0.0100\n",
      "Epoch 183/200, Iteration 119/250, Loss: 0.0130\n",
      "Epoch 183/200, Iteration 120/250, Loss: 0.0074\n",
      "Epoch 183/200, Iteration 121/250, Loss: 0.0087\n",
      "Epoch 183/200, Iteration 122/250, Loss: 0.0140\n",
      "Epoch 183/200, Iteration 123/250, Loss: 0.0107\n",
      "Epoch 183/200, Iteration 124/250, Loss: 0.0068\n",
      "Epoch 183/200, Iteration 125/250, Loss: 0.0159\n",
      "Epoch 183/200, Iteration 126/250, Loss: 0.0143\n",
      "Epoch 183/200, Iteration 127/250, Loss: 0.0093\n",
      "Epoch 183/200, Iteration 128/250, Loss: 0.0108\n",
      "Epoch 183/200, Iteration 129/250, Loss: 0.0118\n",
      "Epoch 183/200, Iteration 130/250, Loss: 0.0330\n",
      "Epoch 183/200, Iteration 131/250, Loss: 0.0205\n",
      "Epoch 183/200, Iteration 132/250, Loss: 0.0144\n",
      "Epoch 183/200, Iteration 133/250, Loss: 0.0102\n",
      "Epoch 183/200, Iteration 134/250, Loss: 0.0155\n",
      "Epoch 183/200, Iteration 135/250, Loss: 0.0165\n",
      "Epoch 183/200, Iteration 136/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 137/250, Loss: 0.0270\n",
      "Epoch 183/200, Iteration 138/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 139/250, Loss: 0.0172\n",
      "Epoch 183/200, Iteration 140/250, Loss: 0.0180\n",
      "Epoch 183/200, Iteration 141/250, Loss: 0.0094\n",
      "Epoch 183/200, Iteration 142/250, Loss: 0.0082\n",
      "Epoch 183/200, Iteration 143/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 144/250, Loss: 0.0141\n",
      "Epoch 183/200, Iteration 145/250, Loss: 0.0098\n",
      "Epoch 183/200, Iteration 146/250, Loss: 0.0179\n",
      "Epoch 183/200, Iteration 147/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 148/250, Loss: 0.0110\n",
      "Epoch 183/200, Iteration 149/250, Loss: 0.0174\n",
      "Epoch 183/200, Iteration 150/250, Loss: 0.0148\n",
      "Epoch 183/200, Iteration 151/250, Loss: 0.0146\n",
      "Epoch 183/200, Iteration 152/250, Loss: 0.0117\n",
      "Epoch 183/200, Iteration 153/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 154/250, Loss: 0.0153\n",
      "Epoch 183/200, Iteration 155/250, Loss: 0.0179\n",
      "Epoch 183/200, Iteration 156/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 157/250, Loss: 0.0269\n",
      "Epoch 183/200, Iteration 158/250, Loss: 0.0200\n",
      "Epoch 183/200, Iteration 159/250, Loss: 0.0080\n",
      "Epoch 183/200, Iteration 160/250, Loss: 0.0110\n",
      "Epoch 183/200, Iteration 161/250, Loss: 0.0091\n",
      "Epoch 183/200, Iteration 162/250, Loss: 0.0061\n",
      "Epoch 183/200, Iteration 163/250, Loss: 0.0193\n",
      "Epoch 183/200, Iteration 164/250, Loss: 0.0107\n",
      "Epoch 183/200, Iteration 165/250, Loss: 0.0306\n",
      "Epoch 183/200, Iteration 166/250, Loss: 0.0102\n",
      "Epoch 183/200, Iteration 167/250, Loss: 0.0321\n",
      "Epoch 183/200, Iteration 168/250, Loss: 0.0073\n",
      "Epoch 183/200, Iteration 169/250, Loss: 0.0169\n",
      "Epoch 183/200, Iteration 170/250, Loss: 0.0103\n",
      "Epoch 183/200, Iteration 171/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 172/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 173/250, Loss: 0.0194\n",
      "Epoch 183/200, Iteration 174/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 175/250, Loss: 0.0073\n",
      "Epoch 183/200, Iteration 176/250, Loss: 0.0237\n",
      "Epoch 183/200, Iteration 177/250, Loss: 0.0093\n",
      "Epoch 183/200, Iteration 178/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 179/250, Loss: 0.0180\n",
      "Epoch 183/200, Iteration 180/250, Loss: 0.0147\n",
      "Epoch 183/200, Iteration 181/250, Loss: 0.0092\n",
      "Epoch 183/200, Iteration 182/250, Loss: 0.0226\n",
      "Epoch 183/200, Iteration 183/250, Loss: 0.0174\n",
      "Epoch 183/200, Iteration 184/250, Loss: 0.0084\n",
      "Epoch 183/200, Iteration 185/250, Loss: 0.0058\n",
      "Epoch 183/200, Iteration 186/250, Loss: 0.0265\n",
      "Epoch 183/200, Iteration 187/250, Loss: 0.0092\n",
      "Epoch 183/200, Iteration 188/250, Loss: 0.0104\n",
      "Epoch 183/200, Iteration 189/250, Loss: 0.0125\n",
      "Epoch 183/200, Iteration 190/250, Loss: 0.0205\n",
      "Epoch 183/200, Iteration 191/250, Loss: 0.0164\n",
      "Epoch 183/200, Iteration 192/250, Loss: 0.0112\n",
      "Epoch 183/200, Iteration 193/250, Loss: 0.0158\n",
      "Epoch 183/200, Iteration 194/250, Loss: 0.0085\n",
      "Epoch 183/200, Iteration 195/250, Loss: 0.0178\n",
      "Epoch 183/200, Iteration 196/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 197/250, Loss: 0.0097\n",
      "Epoch 183/200, Iteration 198/250, Loss: 0.0077\n",
      "Epoch 183/200, Iteration 199/250, Loss: 0.0157\n",
      "Epoch 183/200, Iteration 200/250, Loss: 0.0214\n",
      "Epoch 183/200, Iteration 201/250, Loss: 0.0064\n",
      "Epoch 183/200, Iteration 202/250, Loss: 0.0197\n",
      "Epoch 183/200, Iteration 203/250, Loss: 0.0188\n",
      "Epoch 183/200, Iteration 204/250, Loss: 0.0201\n",
      "Epoch 183/200, Iteration 205/250, Loss: 0.0224\n",
      "Epoch 183/200, Iteration 206/250, Loss: 0.0240\n",
      "Epoch 183/200, Iteration 207/250, Loss: 0.0108\n",
      "Epoch 183/200, Iteration 208/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 209/250, Loss: 0.0130\n",
      "Epoch 183/200, Iteration 210/250, Loss: 0.0118\n",
      "Epoch 183/200, Iteration 211/250, Loss: 0.0154\n",
      "Epoch 183/200, Iteration 212/250, Loss: 0.0146\n",
      "Epoch 183/200, Iteration 213/250, Loss: 0.0404\n",
      "Epoch 183/200, Iteration 214/250, Loss: 0.0104\n",
      "Epoch 183/200, Iteration 215/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 216/250, Loss: 0.0242\n",
      "Epoch 183/200, Iteration 217/250, Loss: 0.0255\n",
      "Epoch 183/200, Iteration 218/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 219/250, Loss: 0.0066\n",
      "Epoch 183/200, Iteration 220/250, Loss: 0.0099\n",
      "Epoch 183/200, Iteration 221/250, Loss: 0.0130\n",
      "Epoch 183/200, Iteration 222/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 223/250, Loss: 0.0422\n",
      "Epoch 183/200, Iteration 224/250, Loss: 0.0183\n",
      "Epoch 183/200, Iteration 225/250, Loss: 0.0191\n",
      "Epoch 183/200, Iteration 226/250, Loss: 0.0123\n",
      "Epoch 183/200, Iteration 227/250, Loss: 0.0152\n",
      "Epoch 183/200, Iteration 228/250, Loss: 0.0086\n",
      "Epoch 183/200, Iteration 229/250, Loss: 0.0276\n",
      "Epoch 183/200, Iteration 230/250, Loss: 0.0127\n",
      "Epoch 183/200, Iteration 231/250, Loss: 0.0358\n",
      "Epoch 183/200, Iteration 232/250, Loss: 0.0136\n",
      "Epoch 183/200, Iteration 233/250, Loss: 0.0072\n",
      "Epoch 183/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 183/200, Iteration 235/250, Loss: 0.0179\n",
      "Epoch 183/200, Iteration 236/250, Loss: 0.0147\n",
      "Epoch 183/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 183/200, Iteration 238/250, Loss: 0.0083\n",
      "Epoch 183/200, Iteration 239/250, Loss: 0.0095\n",
      "Epoch 183/200, Iteration 240/250, Loss: 0.0091\n",
      "Epoch 183/200, Iteration 241/250, Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200, Iteration 242/250, Loss: 0.0134\n",
      "Epoch 183/200, Iteration 243/250, Loss: 0.0130\n",
      "Epoch 183/200, Iteration 244/250, Loss: 0.0090\n",
      "Epoch 183/200, Iteration 245/250, Loss: 0.0124\n",
      "Epoch 183/200, Iteration 246/250, Loss: 0.0192\n",
      "Epoch 183/200, Iteration 247/250, Loss: 0.0163\n",
      "Epoch 183/200, Iteration 248/250, Loss: 0.0124\n",
      "Epoch 183/200, Iteration 249/250, Loss: 0.0101\n",
      "Epoch 183/200, Iteration 250/250, Loss: 0.0155\n",
      "Train Error: \n",
      " Accuracy: 90.67%, Avg loss: 0.006832, MRE: 0.419061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.007508, MRE: 0.484447 \n",
      "\n",
      "Epoch 184/200, Iteration 1/250, Loss: 0.0149\n",
      "Epoch 184/200, Iteration 2/250, Loss: 0.0128\n",
      "Epoch 184/200, Iteration 3/250, Loss: 0.0150\n",
      "Epoch 184/200, Iteration 4/250, Loss: 0.0082\n",
      "Epoch 184/200, Iteration 5/250, Loss: 0.0100\n",
      "Epoch 184/200, Iteration 6/250, Loss: 0.0107\n",
      "Epoch 184/200, Iteration 7/250, Loss: 0.0079\n",
      "Epoch 184/200, Iteration 8/250, Loss: 0.0124\n",
      "Epoch 184/200, Iteration 9/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 10/250, Loss: 0.0223\n",
      "Epoch 184/200, Iteration 11/250, Loss: 0.0148\n",
      "Epoch 184/200, Iteration 12/250, Loss: 0.0332\n",
      "Epoch 184/200, Iteration 13/250, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 14/250, Loss: 0.0103\n",
      "Epoch 184/200, Iteration 15/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 16/250, Loss: 0.0115\n",
      "Epoch 184/200, Iteration 17/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 18/250, Loss: 0.0070\n",
      "Epoch 184/200, Iteration 19/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 20/250, Loss: 0.0132\n",
      "Epoch 184/200, Iteration 21/250, Loss: 0.0125\n",
      "Epoch 184/200, Iteration 22/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 23/250, Loss: 0.0109\n",
      "Epoch 184/200, Iteration 24/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 25/250, Loss: 0.0156\n",
      "Epoch 184/200, Iteration 26/250, Loss: 0.0154\n",
      "Epoch 184/200, Iteration 27/250, Loss: 0.0140\n",
      "Epoch 184/200, Iteration 28/250, Loss: 0.0375\n",
      "Epoch 184/200, Iteration 29/250, Loss: 0.0185\n",
      "Epoch 184/200, Iteration 30/250, Loss: 0.0156\n",
      "Epoch 184/200, Iteration 31/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 32/250, Loss: 0.0091\n",
      "Epoch 184/200, Iteration 33/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 34/250, Loss: 0.0109\n",
      "Epoch 184/200, Iteration 35/250, Loss: 0.0159\n",
      "Epoch 184/200, Iteration 36/250, Loss: 0.0089\n",
      "Epoch 184/200, Iteration 37/250, Loss: 0.0090\n",
      "Epoch 184/200, Iteration 38/250, Loss: 0.0264\n",
      "Epoch 184/200, Iteration 39/250, Loss: 0.0237\n",
      "Epoch 184/200, Iteration 40/250, Loss: 0.0226\n",
      "Epoch 184/200, Iteration 41/250, Loss: 0.0158\n",
      "Epoch 184/200, Iteration 42/250, Loss: 0.0174\n",
      "Epoch 184/200, Iteration 43/250, Loss: 0.0188\n",
      "Epoch 184/200, Iteration 44/250, Loss: 0.0089\n",
      "Epoch 184/200, Iteration 45/250, Loss: 0.0066\n",
      "Epoch 184/200, Iteration 46/250, Loss: 0.0089\n",
      "Epoch 184/200, Iteration 47/250, Loss: 0.0132\n",
      "Epoch 184/200, Iteration 48/250, Loss: 0.0196\n",
      "Epoch 184/200, Iteration 49/250, Loss: 0.0164\n",
      "Epoch 184/200, Iteration 50/250, Loss: 0.0226\n",
      "Epoch 184/200, Iteration 51/250, Loss: 0.0132\n",
      "Epoch 184/200, Iteration 52/250, Loss: 0.0261\n",
      "Epoch 184/200, Iteration 53/250, Loss: 0.0062\n",
      "Epoch 184/200, Iteration 54/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 55/250, Loss: 0.0291\n",
      "Epoch 184/200, Iteration 56/250, Loss: 0.0227\n",
      "Epoch 184/200, Iteration 57/250, Loss: 0.0130\n",
      "Epoch 184/200, Iteration 58/250, Loss: 0.0238\n",
      "Epoch 184/200, Iteration 59/250, Loss: 0.0193\n",
      "Epoch 184/200, Iteration 60/250, Loss: 0.0202\n",
      "Epoch 184/200, Iteration 61/250, Loss: 0.0277\n",
      "Epoch 184/200, Iteration 62/250, Loss: 0.0109\n",
      "Epoch 184/200, Iteration 63/250, Loss: 0.0107\n",
      "Epoch 184/200, Iteration 64/250, Loss: 0.0124\n",
      "Epoch 184/200, Iteration 65/250, Loss: 0.0249\n",
      "Epoch 184/200, Iteration 66/250, Loss: 0.0086\n",
      "Epoch 184/200, Iteration 67/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 68/250, Loss: 0.0153\n",
      "Epoch 184/200, Iteration 69/250, Loss: 0.0164\n",
      "Epoch 184/200, Iteration 70/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 71/250, Loss: 0.0170\n",
      "Epoch 184/200, Iteration 72/250, Loss: 0.0296\n",
      "Epoch 184/200, Iteration 73/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 74/250, Loss: 0.0074\n",
      "Epoch 184/200, Iteration 75/250, Loss: 0.0173\n",
      "Epoch 184/200, Iteration 76/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 77/250, Loss: 0.0260\n",
      "Epoch 184/200, Iteration 78/250, Loss: 0.0166\n",
      "Epoch 184/200, Iteration 79/250, Loss: 0.0203\n",
      "Epoch 184/200, Iteration 80/250, Loss: 0.0118\n",
      "Epoch 184/200, Iteration 81/250, Loss: 0.0071\n",
      "Epoch 184/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 184/200, Iteration 83/250, Loss: 0.0102\n",
      "Epoch 184/200, Iteration 84/250, Loss: 0.0123\n",
      "Epoch 184/200, Iteration 85/250, Loss: 0.0115\n",
      "Epoch 184/200, Iteration 86/250, Loss: 0.0108\n",
      "Epoch 184/200, Iteration 87/250, Loss: 0.0111\n",
      "Epoch 184/200, Iteration 88/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 89/250, Loss: 0.0218\n",
      "Epoch 184/200, Iteration 90/250, Loss: 0.0157\n",
      "Epoch 184/200, Iteration 91/250, Loss: 0.0119\n",
      "Epoch 184/200, Iteration 92/250, Loss: 0.0096\n",
      "Epoch 184/200, Iteration 93/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 94/250, Loss: 0.0141\n",
      "Epoch 184/200, Iteration 95/250, Loss: 0.0142\n",
      "Epoch 184/200, Iteration 96/250, Loss: 0.0156\n",
      "Epoch 184/200, Iteration 97/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 98/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 99/250, Loss: 0.0237\n",
      "Epoch 184/200, Iteration 100/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 101/250, Loss: 0.0164\n",
      "Epoch 184/200, Iteration 102/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 103/250, Loss: 0.0211\n",
      "Epoch 184/200, Iteration 104/250, Loss: 0.0153\n",
      "Epoch 184/200, Iteration 105/250, Loss: 0.0077\n",
      "Epoch 184/200, Iteration 106/250, Loss: 0.0277\n",
      "Epoch 184/200, Iteration 107/250, Loss: 0.0210\n",
      "Epoch 184/200, Iteration 108/250, Loss: 0.0072\n",
      "Epoch 184/200, Iteration 109/250, Loss: 0.0140\n",
      "Epoch 184/200, Iteration 110/250, Loss: 0.0190\n",
      "Epoch 184/200, Iteration 111/250, Loss: 0.0146\n",
      "Epoch 184/200, Iteration 112/250, Loss: 0.0135\n",
      "Epoch 184/200, Iteration 113/250, Loss: 0.0083\n",
      "Epoch 184/200, Iteration 114/250, Loss: 0.0140\n",
      "Epoch 184/200, Iteration 115/250, Loss: 0.0093\n",
      "Epoch 184/200, Iteration 116/250, Loss: 0.0092\n",
      "Epoch 184/200, Iteration 117/250, Loss: 0.0200\n",
      "Epoch 184/200, Iteration 118/250, Loss: 0.0139\n",
      "Epoch 184/200, Iteration 119/250, Loss: 0.0337\n",
      "Epoch 184/200, Iteration 120/250, Loss: 0.0098\n",
      "Epoch 184/200, Iteration 121/250, Loss: 0.0126\n",
      "Epoch 184/200, Iteration 122/250, Loss: 0.0272\n",
      "Epoch 184/200, Iteration 123/250, Loss: 0.0116\n",
      "Epoch 184/200, Iteration 124/250, Loss: 0.0235\n",
      "Epoch 184/200, Iteration 125/250, Loss: 0.0134\n",
      "Epoch 184/200, Iteration 126/250, Loss: 0.0376\n",
      "Epoch 184/200, Iteration 127/250, Loss: 0.0249\n",
      "Epoch 184/200, Iteration 128/250, Loss: 0.0124\n",
      "Epoch 184/200, Iteration 129/250, Loss: 0.0075\n",
      "Epoch 184/200, Iteration 130/250, Loss: 0.0210\n",
      "Epoch 184/200, Iteration 131/250, Loss: 0.0288\n",
      "Epoch 184/200, Iteration 132/250, Loss: 0.0188\n",
      "Epoch 184/200, Iteration 133/250, Loss: 0.0172\n",
      "Epoch 184/200, Iteration 134/250, Loss: 0.0115\n",
      "Epoch 184/200, Iteration 135/250, Loss: 0.0207\n",
      "Epoch 184/200, Iteration 136/250, Loss: 0.0221\n",
      "Epoch 184/200, Iteration 137/250, Loss: 0.0356\n",
      "Epoch 184/200, Iteration 138/250, Loss: 0.0137\n",
      "Epoch 184/200, Iteration 139/250, Loss: 0.0157\n",
      "Epoch 184/200, Iteration 140/250, Loss: 0.0115\n",
      "Epoch 184/200, Iteration 141/250, Loss: 0.0122\n",
      "Epoch 184/200, Iteration 142/250, Loss: 0.0114\n",
      "Epoch 184/200, Iteration 143/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 144/250, Loss: 0.0128\n",
      "Epoch 184/200, Iteration 145/250, Loss: 0.0108\n",
      "Epoch 184/200, Iteration 146/250, Loss: 0.0143\n",
      "Epoch 184/200, Iteration 147/250, Loss: 0.0180\n",
      "Epoch 184/200, Iteration 148/250, Loss: 0.0118\n",
      "Epoch 184/200, Iteration 149/250, Loss: 0.0245\n",
      "Epoch 184/200, Iteration 150/250, Loss: 0.0104\n",
      "Epoch 184/200, Iteration 151/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 152/250, Loss: 0.0250\n",
      "Epoch 184/200, Iteration 153/250, Loss: 0.0146\n",
      "Epoch 184/200, Iteration 154/250, Loss: 0.0210\n",
      "Epoch 184/200, Iteration 155/250, Loss: 0.0385\n",
      "Epoch 184/200, Iteration 156/250, Loss: 0.0162\n",
      "Epoch 184/200, Iteration 157/250, Loss: 0.0087\n",
      "Epoch 184/200, Iteration 158/250, Loss: 0.0086\n",
      "Epoch 184/200, Iteration 159/250, Loss: 0.0081\n",
      "Epoch 184/200, Iteration 160/250, Loss: 0.0140\n",
      "Epoch 184/200, Iteration 161/250, Loss: 0.0170\n",
      "Epoch 184/200, Iteration 162/250, Loss: 0.0207\n",
      "Epoch 184/200, Iteration 163/250, Loss: 0.0311\n",
      "Epoch 184/200, Iteration 164/250, Loss: 0.0101\n",
      "Epoch 184/200, Iteration 165/250, Loss: 0.0130\n",
      "Epoch 184/200, Iteration 166/250, Loss: 0.0100\n",
      "Epoch 184/200, Iteration 167/250, Loss: 0.0196\n",
      "Epoch 184/200, Iteration 168/250, Loss: 0.0234\n",
      "Epoch 184/200, Iteration 169/250, Loss: 0.0288\n",
      "Epoch 184/200, Iteration 170/250, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200, Iteration 171/250, Loss: 0.0090\n",
      "Epoch 184/200, Iteration 172/250, Loss: 0.0162\n",
      "Epoch 184/200, Iteration 173/250, Loss: 0.0118\n",
      "Epoch 184/200, Iteration 174/250, Loss: 0.0135\n",
      "Epoch 184/200, Iteration 175/250, Loss: 0.0090\n",
      "Epoch 184/200, Iteration 176/250, Loss: 0.0127\n",
      "Epoch 184/200, Iteration 177/250, Loss: 0.0110\n",
      "Epoch 184/200, Iteration 178/250, Loss: 0.0077\n",
      "Epoch 184/200, Iteration 179/250, Loss: 0.0431\n",
      "Epoch 184/200, Iteration 180/250, Loss: 0.0139\n",
      "Epoch 184/200, Iteration 181/250, Loss: 0.0128\n",
      "Epoch 184/200, Iteration 182/250, Loss: 0.0105\n",
      "Epoch 184/200, Iteration 183/250, Loss: 0.0097\n",
      "Epoch 184/200, Iteration 184/250, Loss: 0.0111\n",
      "Epoch 184/200, Iteration 185/250, Loss: 0.0074\n",
      "Epoch 184/200, Iteration 186/250, Loss: 0.0276\n",
      "Epoch 184/200, Iteration 187/250, Loss: 0.0128\n",
      "Epoch 184/200, Iteration 188/250, Loss: 0.0270\n",
      "Epoch 184/200, Iteration 189/250, Loss: 0.0116\n",
      "Epoch 184/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 184/200, Iteration 191/250, Loss: 0.0198\n",
      "Epoch 184/200, Iteration 192/250, Loss: 0.0070\n",
      "Epoch 184/200, Iteration 193/250, Loss: 0.0157\n",
      "Epoch 184/200, Iteration 194/250, Loss: 0.0134\n",
      "Epoch 184/200, Iteration 195/250, Loss: 0.0078\n",
      "Epoch 184/200, Iteration 196/250, Loss: 0.0139\n",
      "Epoch 184/200, Iteration 197/250, Loss: 0.0227\n",
      "Epoch 184/200, Iteration 198/250, Loss: 0.0240\n",
      "Epoch 184/200, Iteration 199/250, Loss: 0.0129\n",
      "Epoch 184/200, Iteration 200/250, Loss: 0.0282\n",
      "Epoch 184/200, Iteration 201/250, Loss: 0.0275\n",
      "Epoch 184/200, Iteration 202/250, Loss: 0.0138\n",
      "Epoch 184/200, Iteration 203/250, Loss: 0.0145\n",
      "Epoch 184/200, Iteration 204/250, Loss: 0.0109\n",
      "Epoch 184/200, Iteration 205/250, Loss: 0.0086\n",
      "Epoch 184/200, Iteration 206/250, Loss: 0.0165\n",
      "Epoch 184/200, Iteration 207/250, Loss: 0.0126\n",
      "Epoch 184/200, Iteration 208/250, Loss: 0.0324\n",
      "Epoch 184/200, Iteration 209/250, Loss: 0.0499\n",
      "Epoch 184/200, Iteration 210/250, Loss: 0.0070\n",
      "Epoch 184/200, Iteration 211/250, Loss: 0.0183\n",
      "Epoch 184/200, Iteration 212/250, Loss: 0.0127\n",
      "Epoch 184/200, Iteration 213/250, Loss: 0.0127\n",
      "Epoch 184/200, Iteration 214/250, Loss: 0.0199\n",
      "Epoch 184/200, Iteration 215/250, Loss: 0.0274\n",
      "Epoch 184/200, Iteration 216/250, Loss: 0.0144\n",
      "Epoch 184/200, Iteration 217/250, Loss: 0.0181\n",
      "Epoch 184/200, Iteration 218/250, Loss: 0.0119\n",
      "Epoch 184/200, Iteration 219/250, Loss: 0.0079\n",
      "Epoch 184/200, Iteration 220/250, Loss: 0.0080\n",
      "Epoch 184/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 184/200, Iteration 222/250, Loss: 0.0152\n",
      "Epoch 184/200, Iteration 223/250, Loss: 0.0099\n",
      "Epoch 184/200, Iteration 224/250, Loss: 0.0213\n",
      "Epoch 184/200, Iteration 225/250, Loss: 0.0146\n",
      "Epoch 184/200, Iteration 226/250, Loss: 0.0084\n",
      "Epoch 184/200, Iteration 227/250, Loss: 0.0108\n",
      "Epoch 184/200, Iteration 228/250, Loss: 0.0083\n",
      "Epoch 184/200, Iteration 229/250, Loss: 0.0088\n",
      "Epoch 184/200, Iteration 230/250, Loss: 0.0135\n",
      "Epoch 184/200, Iteration 231/250, Loss: 0.0092\n",
      "Epoch 184/200, Iteration 232/250, Loss: 0.0208\n",
      "Epoch 184/200, Iteration 233/250, Loss: 0.0154\n",
      "Epoch 184/200, Iteration 234/250, Loss: 0.0371\n",
      "Epoch 184/200, Iteration 235/250, Loss: 0.0277\n",
      "Epoch 184/200, Iteration 236/250, Loss: 0.0271\n",
      "Epoch 184/200, Iteration 237/250, Loss: 0.0273\n",
      "Epoch 184/200, Iteration 238/250, Loss: 0.0138\n",
      "Epoch 184/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 184/200, Iteration 240/250, Loss: 0.0285\n",
      "Epoch 184/200, Iteration 241/250, Loss: 0.0155\n",
      "Epoch 184/200, Iteration 242/250, Loss: 0.0126\n",
      "Epoch 184/200, Iteration 243/250, Loss: 0.0092\n",
      "Epoch 184/200, Iteration 244/250, Loss: 0.0129\n",
      "Epoch 184/200, Iteration 245/250, Loss: 0.0272\n",
      "Epoch 184/200, Iteration 246/250, Loss: 0.0425\n",
      "Epoch 184/200, Iteration 247/250, Loss: 0.0106\n",
      "Epoch 184/200, Iteration 248/250, Loss: 0.0112\n",
      "Epoch 184/200, Iteration 249/250, Loss: 0.0159\n",
      "Epoch 184/200, Iteration 250/250, Loss: 0.0152\n",
      "Train Error: \n",
      " Accuracy: 67.64%, Avg loss: 0.008875, MRE: 0.692508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.009382, MRE: 0.740674 \n",
      "\n",
      "Epoch 185/200, Iteration 1/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 2/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 3/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 4/250, Loss: 0.0066\n",
      "Epoch 185/200, Iteration 5/250, Loss: 0.0056\n",
      "Epoch 185/200, Iteration 6/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 7/250, Loss: 0.0087\n",
      "Epoch 185/200, Iteration 8/250, Loss: 0.0204\n",
      "Epoch 185/200, Iteration 9/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 10/250, Loss: 0.0074\n",
      "Epoch 185/200, Iteration 11/250, Loss: 0.0093\n",
      "Epoch 185/200, Iteration 12/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 13/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 14/250, Loss: 0.0099\n",
      "Epoch 185/200, Iteration 15/250, Loss: 0.0134\n",
      "Epoch 185/200, Iteration 16/250, Loss: 0.0162\n",
      "Epoch 185/200, Iteration 17/250, Loss: 0.0270\n",
      "Epoch 185/200, Iteration 18/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 19/250, Loss: 0.0064\n",
      "Epoch 185/200, Iteration 20/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 21/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 22/250, Loss: 0.0113\n",
      "Epoch 185/200, Iteration 23/250, Loss: 0.0141\n",
      "Epoch 185/200, Iteration 24/250, Loss: 0.0127\n",
      "Epoch 185/200, Iteration 25/250, Loss: 0.0111\n",
      "Epoch 185/200, Iteration 26/250, Loss: 0.0216\n",
      "Epoch 185/200, Iteration 27/250, Loss: 0.0261\n",
      "Epoch 185/200, Iteration 28/250, Loss: 0.0074\n",
      "Epoch 185/200, Iteration 29/250, Loss: 0.0221\n",
      "Epoch 185/200, Iteration 30/250, Loss: 0.0159\n",
      "Epoch 185/200, Iteration 31/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 32/250, Loss: 0.0122\n",
      "Epoch 185/200, Iteration 33/250, Loss: 0.0081\n",
      "Epoch 185/200, Iteration 34/250, Loss: 0.0190\n",
      "Epoch 185/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 36/250, Loss: 0.0122\n",
      "Epoch 185/200, Iteration 37/250, Loss: 0.0147\n",
      "Epoch 185/200, Iteration 38/250, Loss: 0.0185\n",
      "Epoch 185/200, Iteration 39/250, Loss: 0.0139\n",
      "Epoch 185/200, Iteration 40/250, Loss: 0.0219\n",
      "Epoch 185/200, Iteration 41/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 42/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 43/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 44/250, Loss: 0.0252\n",
      "Epoch 185/200, Iteration 45/250, Loss: 0.0198\n",
      "Epoch 185/200, Iteration 46/250, Loss: 0.0159\n",
      "Epoch 185/200, Iteration 47/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 48/250, Loss: 0.0192\n",
      "Epoch 185/200, Iteration 49/250, Loss: 0.0112\n",
      "Epoch 185/200, Iteration 50/250, Loss: 0.0230\n",
      "Epoch 185/200, Iteration 51/250, Loss: 0.0235\n",
      "Epoch 185/200, Iteration 52/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 53/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 54/250, Loss: 0.0082\n",
      "Epoch 185/200, Iteration 55/250, Loss: 0.0186\n",
      "Epoch 185/200, Iteration 56/250, Loss: 0.0144\n",
      "Epoch 185/200, Iteration 57/250, Loss: 0.0157\n",
      "Epoch 185/200, Iteration 58/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 59/250, Loss: 0.0122\n",
      "Epoch 185/200, Iteration 60/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 61/250, Loss: 0.0240\n",
      "Epoch 185/200, Iteration 62/250, Loss: 0.0306\n",
      "Epoch 185/200, Iteration 63/250, Loss: 0.0136\n",
      "Epoch 185/200, Iteration 64/250, Loss: 0.0127\n",
      "Epoch 185/200, Iteration 65/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 66/250, Loss: 0.0109\n",
      "Epoch 185/200, Iteration 67/250, Loss: 0.0192\n",
      "Epoch 185/200, Iteration 68/250, Loss: 0.0212\n",
      "Epoch 185/200, Iteration 69/250, Loss: 0.0081\n",
      "Epoch 185/200, Iteration 70/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 71/250, Loss: 0.0072\n",
      "Epoch 185/200, Iteration 72/250, Loss: 0.0131\n",
      "Epoch 185/200, Iteration 73/250, Loss: 0.0126\n",
      "Epoch 185/200, Iteration 74/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 75/250, Loss: 0.0127\n",
      "Epoch 185/200, Iteration 76/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 77/250, Loss: 0.0116\n",
      "Epoch 185/200, Iteration 78/250, Loss: 0.0085\n",
      "Epoch 185/200, Iteration 79/250, Loss: 0.0340\n",
      "Epoch 185/200, Iteration 80/250, Loss: 0.0129\n",
      "Epoch 185/200, Iteration 81/250, Loss: 0.0076\n",
      "Epoch 185/200, Iteration 82/250, Loss: 0.0101\n",
      "Epoch 185/200, Iteration 83/250, Loss: 0.0235\n",
      "Epoch 185/200, Iteration 84/250, Loss: 0.0461\n",
      "Epoch 185/200, Iteration 85/250, Loss: 0.0192\n",
      "Epoch 185/200, Iteration 86/250, Loss: 0.0078\n",
      "Epoch 185/200, Iteration 87/250, Loss: 0.0083\n",
      "Epoch 185/200, Iteration 88/250, Loss: 0.0091\n",
      "Epoch 185/200, Iteration 89/250, Loss: 0.0145\n",
      "Epoch 185/200, Iteration 90/250, Loss: 0.0111\n",
      "Epoch 185/200, Iteration 91/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 92/250, Loss: 0.0327\n",
      "Epoch 185/200, Iteration 93/250, Loss: 0.0126\n",
      "Epoch 185/200, Iteration 94/250, Loss: 0.0070\n",
      "Epoch 185/200, Iteration 95/250, Loss: 0.0135\n",
      "Epoch 185/200, Iteration 96/250, Loss: 0.0106\n",
      "Epoch 185/200, Iteration 97/250, Loss: 0.0171\n",
      "Epoch 185/200, Iteration 98/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 99/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 100/250, Loss: 0.0088\n",
      "Epoch 185/200, Iteration 101/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 102/250, Loss: 0.0093\n",
      "Epoch 185/200, Iteration 103/250, Loss: 0.0184\n",
      "Epoch 185/200, Iteration 104/250, Loss: 0.0251\n",
      "Epoch 185/200, Iteration 105/250, Loss: 0.0297\n",
      "Epoch 185/200, Iteration 106/250, Loss: 0.0273\n",
      "Epoch 185/200, Iteration 107/250, Loss: 0.0096\n",
      "Epoch 185/200, Iteration 108/250, Loss: 0.0084\n",
      "Epoch 185/200, Iteration 109/250, Loss: 0.0091\n",
      "Epoch 185/200, Iteration 110/250, Loss: 0.0171\n",
      "Epoch 185/200, Iteration 111/250, Loss: 0.0285\n",
      "Epoch 185/200, Iteration 112/250, Loss: 0.0330\n",
      "Epoch 185/200, Iteration 113/250, Loss: 0.0231\n",
      "Epoch 185/200, Iteration 114/250, Loss: 0.0114\n",
      "Epoch 185/200, Iteration 115/250, Loss: 0.0108\n",
      "Epoch 185/200, Iteration 116/250, Loss: 0.0124\n",
      "Epoch 185/200, Iteration 117/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 118/250, Loss: 0.0157\n",
      "Epoch 185/200, Iteration 119/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 120/250, Loss: 0.0133\n",
      "Epoch 185/200, Iteration 121/250, Loss: 0.0252\n",
      "Epoch 185/200, Iteration 122/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 123/250, Loss: 0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200, Iteration 124/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 125/250, Loss: 0.0332\n",
      "Epoch 185/200, Iteration 126/250, Loss: 0.0161\n",
      "Epoch 185/200, Iteration 127/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 128/250, Loss: 0.0273\n",
      "Epoch 185/200, Iteration 129/250, Loss: 0.0087\n",
      "Epoch 185/200, Iteration 130/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 131/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 132/250, Loss: 0.0166\n",
      "Epoch 185/200, Iteration 133/250, Loss: 0.0177\n",
      "Epoch 185/200, Iteration 134/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 135/250, Loss: 0.0132\n",
      "Epoch 185/200, Iteration 136/250, Loss: 0.0220\n",
      "Epoch 185/200, Iteration 137/250, Loss: 0.0086\n",
      "Epoch 185/200, Iteration 138/250, Loss: 0.0168\n",
      "Epoch 185/200, Iteration 139/250, Loss: 0.0091\n",
      "Epoch 185/200, Iteration 140/250, Loss: 0.0098\n",
      "Epoch 185/200, Iteration 141/250, Loss: 0.0121\n",
      "Epoch 185/200, Iteration 142/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 143/250, Loss: 0.0150\n",
      "Epoch 185/200, Iteration 144/250, Loss: 0.0104\n",
      "Epoch 185/200, Iteration 145/250, Loss: 0.0105\n",
      "Epoch 185/200, Iteration 146/250, Loss: 0.0110\n",
      "Epoch 185/200, Iteration 147/250, Loss: 0.0117\n",
      "Epoch 185/200, Iteration 148/250, Loss: 0.0286\n",
      "Epoch 185/200, Iteration 149/250, Loss: 0.0132\n",
      "Epoch 185/200, Iteration 150/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 151/250, Loss: 0.0343\n",
      "Epoch 185/200, Iteration 152/250, Loss: 0.0099\n",
      "Epoch 185/200, Iteration 153/250, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 154/250, Loss: 0.0139\n",
      "Epoch 185/200, Iteration 155/250, Loss: 0.0613\n",
      "Epoch 185/200, Iteration 156/250, Loss: 0.0082\n",
      "Epoch 185/200, Iteration 157/250, Loss: 0.0181\n",
      "Epoch 185/200, Iteration 158/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 159/250, Loss: 0.0362\n",
      "Epoch 185/200, Iteration 160/250, Loss: 0.0092\n",
      "Epoch 185/200, Iteration 161/250, Loss: 0.0240\n",
      "Epoch 185/200, Iteration 162/250, Loss: 0.0117\n",
      "Epoch 185/200, Iteration 163/250, Loss: 0.0144\n",
      "Epoch 185/200, Iteration 164/250, Loss: 0.0070\n",
      "Epoch 185/200, Iteration 165/250, Loss: 0.0233\n",
      "Epoch 185/200, Iteration 166/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 167/250, Loss: 0.0332\n",
      "Epoch 185/200, Iteration 168/250, Loss: 0.0182\n",
      "Epoch 185/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 185/200, Iteration 170/250, Loss: 0.0235\n",
      "Epoch 185/200, Iteration 171/250, Loss: 0.0125\n",
      "Epoch 185/200, Iteration 172/250, Loss: 0.0134\n",
      "Epoch 185/200, Iteration 173/250, Loss: 0.0126\n",
      "Epoch 185/200, Iteration 174/250, Loss: 0.0151\n",
      "Epoch 185/200, Iteration 175/250, Loss: 0.0159\n",
      "Epoch 185/200, Iteration 176/250, Loss: 0.0285\n",
      "Epoch 185/200, Iteration 177/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 178/250, Loss: 0.0126\n",
      "Epoch 185/200, Iteration 179/250, Loss: 0.0113\n",
      "Epoch 185/200, Iteration 180/250, Loss: 0.0327\n",
      "Epoch 185/200, Iteration 181/250, Loss: 0.0086\n",
      "Epoch 185/200, Iteration 182/250, Loss: 0.0101\n",
      "Epoch 185/200, Iteration 183/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 184/250, Loss: 0.0320\n",
      "Epoch 185/200, Iteration 185/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 186/250, Loss: 0.0129\n",
      "Epoch 185/200, Iteration 187/250, Loss: 0.0103\n",
      "Epoch 185/200, Iteration 188/250, Loss: 0.0063\n",
      "Epoch 185/200, Iteration 189/250, Loss: 0.0130\n",
      "Epoch 185/200, Iteration 190/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 191/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 192/250, Loss: 0.0114\n",
      "Epoch 185/200, Iteration 193/250, Loss: 0.0178\n",
      "Epoch 185/200, Iteration 194/250, Loss: 0.0159\n",
      "Epoch 185/200, Iteration 195/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 196/250, Loss: 0.0093\n",
      "Epoch 185/200, Iteration 197/250, Loss: 0.0102\n",
      "Epoch 185/200, Iteration 198/250, Loss: 0.0119\n",
      "Epoch 185/200, Iteration 199/250, Loss: 0.0097\n",
      "Epoch 185/200, Iteration 200/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 201/250, Loss: 0.0087\n",
      "Epoch 185/200, Iteration 202/250, Loss: 0.0173\n",
      "Epoch 185/200, Iteration 203/250, Loss: 0.0252\n",
      "Epoch 185/200, Iteration 204/250, Loss: 0.0107\n",
      "Epoch 185/200, Iteration 205/250, Loss: 0.0099\n",
      "Epoch 185/200, Iteration 206/250, Loss: 0.0123\n",
      "Epoch 185/200, Iteration 207/250, Loss: 0.0204\n",
      "Epoch 185/200, Iteration 208/250, Loss: 0.0144\n",
      "Epoch 185/200, Iteration 209/250, Loss: 0.0100\n",
      "Epoch 185/200, Iteration 210/250, Loss: 0.0064\n",
      "Epoch 185/200, Iteration 211/250, Loss: 0.0190\n",
      "Epoch 185/200, Iteration 212/250, Loss: 0.0071\n",
      "Epoch 185/200, Iteration 213/250, Loss: 0.0103\n",
      "Epoch 185/200, Iteration 214/250, Loss: 0.0172\n",
      "Epoch 185/200, Iteration 215/250, Loss: 0.0298\n",
      "Epoch 185/200, Iteration 216/250, Loss: 0.0096\n",
      "Epoch 185/200, Iteration 217/250, Loss: 0.0140\n",
      "Epoch 185/200, Iteration 218/250, Loss: 0.0163\n",
      "Epoch 185/200, Iteration 219/250, Loss: 0.0106\n",
      "Epoch 185/200, Iteration 220/250, Loss: 0.0108\n",
      "Epoch 185/200, Iteration 221/250, Loss: 0.0120\n",
      "Epoch 185/200, Iteration 222/250, Loss: 0.0108\n",
      "Epoch 185/200, Iteration 223/250, Loss: 0.0346\n",
      "Epoch 185/200, Iteration 224/250, Loss: 0.0084\n",
      "Epoch 185/200, Iteration 225/250, Loss: 0.0094\n",
      "Epoch 185/200, Iteration 226/250, Loss: 0.0237\n",
      "Epoch 185/200, Iteration 227/250, Loss: 0.0122\n",
      "Epoch 185/200, Iteration 228/250, Loss: 0.0073\n",
      "Epoch 185/200, Iteration 229/250, Loss: 0.0111\n",
      "Epoch 185/200, Iteration 230/250, Loss: 0.0198\n",
      "Epoch 185/200, Iteration 231/250, Loss: 0.0095\n",
      "Epoch 185/200, Iteration 232/250, Loss: 0.0244\n",
      "Epoch 185/200, Iteration 233/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 234/250, Loss: 0.0075\n",
      "Epoch 185/200, Iteration 235/250, Loss: 0.0286\n",
      "Epoch 185/200, Iteration 236/250, Loss: 0.0121\n",
      "Epoch 185/200, Iteration 237/250, Loss: 0.0187\n",
      "Epoch 185/200, Iteration 238/250, Loss: 0.0199\n",
      "Epoch 185/200, Iteration 239/250, Loss: 0.0136\n",
      "Epoch 185/200, Iteration 240/250, Loss: 0.0089\n",
      "Epoch 185/200, Iteration 241/250, Loss: 0.0212\n",
      "Epoch 185/200, Iteration 242/250, Loss: 0.0147\n",
      "Epoch 185/200, Iteration 243/250, Loss: 0.0190\n",
      "Epoch 185/200, Iteration 244/250, Loss: 0.0112\n",
      "Epoch 185/200, Iteration 245/250, Loss: 0.0102\n",
      "Epoch 185/200, Iteration 246/250, Loss: 0.0157\n",
      "Epoch 185/200, Iteration 247/250, Loss: 0.0134\n",
      "Epoch 185/200, Iteration 248/250, Loss: 0.0082\n",
      "Epoch 185/200, Iteration 249/250, Loss: 0.0147\n",
      "Epoch 185/200, Iteration 250/250, Loss: 0.0097\n",
      "Train Error: \n",
      " Accuracy: 89.33%, Avg loss: 0.006645, MRE: 0.456410 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.007286, MRE: 0.563754 \n",
      "\n",
      "Epoch 186/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 2/250, Loss: 0.0202\n",
      "Epoch 186/200, Iteration 3/250, Loss: 0.0066\n",
      "Epoch 186/200, Iteration 4/250, Loss: 0.0120\n",
      "Epoch 186/200, Iteration 5/250, Loss: 0.0238\n",
      "Epoch 186/200, Iteration 6/250, Loss: 0.0130\n",
      "Epoch 186/200, Iteration 7/250, Loss: 0.0236\n",
      "Epoch 186/200, Iteration 8/250, Loss: 0.0143\n",
      "Epoch 186/200, Iteration 9/250, Loss: 0.0172\n",
      "Epoch 186/200, Iteration 10/250, Loss: 0.0054\n",
      "Epoch 186/200, Iteration 11/250, Loss: 0.0189\n",
      "Epoch 186/200, Iteration 12/250, Loss: 0.0202\n",
      "Epoch 186/200, Iteration 13/250, Loss: 0.0280\n",
      "Epoch 186/200, Iteration 14/250, Loss: 0.0159\n",
      "Epoch 186/200, Iteration 15/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 16/250, Loss: 0.0088\n",
      "Epoch 186/200, Iteration 17/250, Loss: 0.0199\n",
      "Epoch 186/200, Iteration 18/250, Loss: 0.0148\n",
      "Epoch 186/200, Iteration 19/250, Loss: 0.0151\n",
      "Epoch 186/200, Iteration 20/250, Loss: 0.0070\n",
      "Epoch 186/200, Iteration 21/250, Loss: 0.0089\n",
      "Epoch 186/200, Iteration 22/250, Loss: 0.0086\n",
      "Epoch 186/200, Iteration 23/250, Loss: 0.0095\n",
      "Epoch 186/200, Iteration 24/250, Loss: 0.0165\n",
      "Epoch 186/200, Iteration 25/250, Loss: 0.0074\n",
      "Epoch 186/200, Iteration 26/250, Loss: 0.0085\n",
      "Epoch 186/200, Iteration 27/250, Loss: 0.0069\n",
      "Epoch 186/200, Iteration 28/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 29/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 30/250, Loss: 0.0159\n",
      "Epoch 186/200, Iteration 31/250, Loss: 0.0082\n",
      "Epoch 186/200, Iteration 32/250, Loss: 0.0196\n",
      "Epoch 186/200, Iteration 33/250, Loss: 0.0157\n",
      "Epoch 186/200, Iteration 34/250, Loss: 0.0082\n",
      "Epoch 186/200, Iteration 35/250, Loss: 0.0262\n",
      "Epoch 186/200, Iteration 36/250, Loss: 0.0130\n",
      "Epoch 186/200, Iteration 37/250, Loss: 0.0384\n",
      "Epoch 186/200, Iteration 38/250, Loss: 0.0135\n",
      "Epoch 186/200, Iteration 39/250, Loss: 0.0130\n",
      "Epoch 186/200, Iteration 40/250, Loss: 0.0126\n",
      "Epoch 186/200, Iteration 41/250, Loss: 0.0525\n",
      "Epoch 186/200, Iteration 42/250, Loss: 0.0092\n",
      "Epoch 186/200, Iteration 43/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 44/250, Loss: 0.0063\n",
      "Epoch 186/200, Iteration 45/250, Loss: 0.0080\n",
      "Epoch 186/200, Iteration 46/250, Loss: 0.0173\n",
      "Epoch 186/200, Iteration 47/250, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 48/250, Loss: 0.0074\n",
      "Epoch 186/200, Iteration 49/250, Loss: 0.0171\n",
      "Epoch 186/200, Iteration 50/250, Loss: 0.0154\n",
      "Epoch 186/200, Iteration 51/250, Loss: 0.0241\n",
      "Epoch 186/200, Iteration 52/250, Loss: 0.0088\n",
      "Epoch 186/200, Iteration 53/250, Loss: 0.0099\n",
      "Epoch 186/200, Iteration 54/250, Loss: 0.0264\n",
      "Epoch 186/200, Iteration 55/250, Loss: 0.0152\n",
      "Epoch 186/200, Iteration 56/250, Loss: 0.0123\n",
      "Epoch 186/200, Iteration 57/250, Loss: 0.0177\n",
      "Epoch 186/200, Iteration 58/250, Loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200, Iteration 59/250, Loss: 0.0111\n",
      "Epoch 186/200, Iteration 60/250, Loss: 0.0234\n",
      "Epoch 186/200, Iteration 61/250, Loss: 0.0089\n",
      "Epoch 186/200, Iteration 62/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 63/250, Loss: 0.0080\n",
      "Epoch 186/200, Iteration 64/250, Loss: 0.0201\n",
      "Epoch 186/200, Iteration 65/250, Loss: 0.0096\n",
      "Epoch 186/200, Iteration 66/250, Loss: 0.0095\n",
      "Epoch 186/200, Iteration 67/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 68/250, Loss: 0.0211\n",
      "Epoch 186/200, Iteration 69/250, Loss: 0.0167\n",
      "Epoch 186/200, Iteration 70/250, Loss: 0.0230\n",
      "Epoch 186/200, Iteration 71/250, Loss: 0.0131\n",
      "Epoch 186/200, Iteration 72/250, Loss: 0.0083\n",
      "Epoch 186/200, Iteration 73/250, Loss: 0.0127\n",
      "Epoch 186/200, Iteration 74/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 75/250, Loss: 0.0176\n",
      "Epoch 186/200, Iteration 76/250, Loss: 0.0108\n",
      "Epoch 186/200, Iteration 77/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 78/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 79/250, Loss: 0.0134\n",
      "Epoch 186/200, Iteration 80/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 81/250, Loss: 0.0238\n",
      "Epoch 186/200, Iteration 82/250, Loss: 0.0140\n",
      "Epoch 186/200, Iteration 83/250, Loss: 0.0144\n",
      "Epoch 186/200, Iteration 84/250, Loss: 0.0105\n",
      "Epoch 186/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 186/200, Iteration 86/250, Loss: 0.0161\n",
      "Epoch 186/200, Iteration 87/250, Loss: 0.0120\n",
      "Epoch 186/200, Iteration 88/250, Loss: 0.0370\n",
      "Epoch 186/200, Iteration 89/250, Loss: 0.0095\n",
      "Epoch 186/200, Iteration 90/250, Loss: 0.0154\n",
      "Epoch 186/200, Iteration 91/250, Loss: 0.0200\n",
      "Epoch 186/200, Iteration 92/250, Loss: 0.0261\n",
      "Epoch 186/200, Iteration 93/250, Loss: 0.0256\n",
      "Epoch 186/200, Iteration 94/250, Loss: 0.0231\n",
      "Epoch 186/200, Iteration 95/250, Loss: 0.0112\n",
      "Epoch 186/200, Iteration 96/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 97/250, Loss: 0.0233\n",
      "Epoch 186/200, Iteration 98/250, Loss: 0.0171\n",
      "Epoch 186/200, Iteration 99/250, Loss: 0.0212\n",
      "Epoch 186/200, Iteration 100/250, Loss: 0.0191\n",
      "Epoch 186/200, Iteration 101/250, Loss: 0.0256\n",
      "Epoch 186/200, Iteration 102/250, Loss: 0.0105\n",
      "Epoch 186/200, Iteration 103/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 104/250, Loss: 0.0221\n",
      "Epoch 186/200, Iteration 105/250, Loss: 0.0105\n",
      "Epoch 186/200, Iteration 106/250, Loss: 0.0253\n",
      "Epoch 186/200, Iteration 107/250, Loss: 0.0081\n",
      "Epoch 186/200, Iteration 108/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 109/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 110/250, Loss: 0.0148\n",
      "Epoch 186/200, Iteration 111/250, Loss: 0.0323\n",
      "Epoch 186/200, Iteration 112/250, Loss: 0.0134\n",
      "Epoch 186/200, Iteration 113/250, Loss: 0.0097\n",
      "Epoch 186/200, Iteration 114/250, Loss: 0.0169\n",
      "Epoch 186/200, Iteration 115/250, Loss: 0.0123\n",
      "Epoch 186/200, Iteration 116/250, Loss: 0.0102\n",
      "Epoch 186/200, Iteration 117/250, Loss: 0.0084\n",
      "Epoch 186/200, Iteration 118/250, Loss: 0.0078\n",
      "Epoch 186/200, Iteration 119/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 120/250, Loss: 0.0212\n",
      "Epoch 186/200, Iteration 121/250, Loss: 0.0256\n",
      "Epoch 186/200, Iteration 122/250, Loss: 0.0118\n",
      "Epoch 186/200, Iteration 123/250, Loss: 0.0144\n",
      "Epoch 186/200, Iteration 124/250, Loss: 0.0129\n",
      "Epoch 186/200, Iteration 125/250, Loss: 0.0073\n",
      "Epoch 186/200, Iteration 126/250, Loss: 0.0320\n",
      "Epoch 186/200, Iteration 127/250, Loss: 0.0150\n",
      "Epoch 186/200, Iteration 128/250, Loss: 0.0175\n",
      "Epoch 186/200, Iteration 129/250, Loss: 0.0177\n",
      "Epoch 186/200, Iteration 130/250, Loss: 0.0156\n",
      "Epoch 186/200, Iteration 131/250, Loss: 0.0082\n",
      "Epoch 186/200, Iteration 132/250, Loss: 0.0087\n",
      "Epoch 186/200, Iteration 133/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 134/250, Loss: 0.0195\n",
      "Epoch 186/200, Iteration 135/250, Loss: 0.0077\n",
      "Epoch 186/200, Iteration 136/250, Loss: 0.0209\n",
      "Epoch 186/200, Iteration 137/250, Loss: 0.0134\n",
      "Epoch 186/200, Iteration 138/250, Loss: 0.0118\n",
      "Epoch 186/200, Iteration 139/250, Loss: 0.0169\n",
      "Epoch 186/200, Iteration 140/250, Loss: 0.0108\n",
      "Epoch 186/200, Iteration 141/250, Loss: 0.0146\n",
      "Epoch 186/200, Iteration 142/250, Loss: 0.0088\n",
      "Epoch 186/200, Iteration 143/250, Loss: 0.0171\n",
      "Epoch 186/200, Iteration 144/250, Loss: 0.0098\n",
      "Epoch 186/200, Iteration 145/250, Loss: 0.0170\n",
      "Epoch 186/200, Iteration 146/250, Loss: 0.0114\n",
      "Epoch 186/200, Iteration 147/250, Loss: 0.0142\n",
      "Epoch 186/200, Iteration 148/250, Loss: 0.0257\n",
      "Epoch 186/200, Iteration 149/250, Loss: 0.0085\n",
      "Epoch 186/200, Iteration 150/250, Loss: 0.0203\n",
      "Epoch 186/200, Iteration 151/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 152/250, Loss: 0.0120\n",
      "Epoch 186/200, Iteration 153/250, Loss: 0.0208\n",
      "Epoch 186/200, Iteration 154/250, Loss: 0.0184\n",
      "Epoch 186/200, Iteration 155/250, Loss: 0.0160\n",
      "Epoch 186/200, Iteration 156/250, Loss: 0.0098\n",
      "Epoch 186/200, Iteration 157/250, Loss: 0.0378\n",
      "Epoch 186/200, Iteration 158/250, Loss: 0.0137\n",
      "Epoch 186/200, Iteration 159/250, Loss: 0.0114\n",
      "Epoch 186/200, Iteration 160/250, Loss: 0.0062\n",
      "Epoch 186/200, Iteration 161/250, Loss: 0.0144\n",
      "Epoch 186/200, Iteration 162/250, Loss: 0.0226\n",
      "Epoch 186/200, Iteration 163/250, Loss: 0.0167\n",
      "Epoch 186/200, Iteration 164/250, Loss: 0.0110\n",
      "Epoch 186/200, Iteration 165/250, Loss: 0.0242\n",
      "Epoch 186/200, Iteration 166/250, Loss: 0.0229\n",
      "Epoch 186/200, Iteration 167/250, Loss: 0.0094\n",
      "Epoch 186/200, Iteration 168/250, Loss: 0.0260\n",
      "Epoch 186/200, Iteration 169/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 186/200, Iteration 171/250, Loss: 0.0129\n",
      "Epoch 186/200, Iteration 172/250, Loss: 0.0106\n",
      "Epoch 186/200, Iteration 173/250, Loss: 0.0166\n",
      "Epoch 186/200, Iteration 174/250, Loss: 0.0170\n",
      "Epoch 186/200, Iteration 175/250, Loss: 0.0178\n",
      "Epoch 186/200, Iteration 176/250, Loss: 0.0071\n",
      "Epoch 186/200, Iteration 177/250, Loss: 0.0141\n",
      "Epoch 186/200, Iteration 178/250, Loss: 0.0214\n",
      "Epoch 186/200, Iteration 179/250, Loss: 0.0085\n",
      "Epoch 186/200, Iteration 180/250, Loss: 0.0109\n",
      "Epoch 186/200, Iteration 181/250, Loss: 0.0241\n",
      "Epoch 186/200, Iteration 182/250, Loss: 0.0111\n",
      "Epoch 186/200, Iteration 183/250, Loss: 0.0086\n",
      "Epoch 186/200, Iteration 184/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 185/250, Loss: 0.0075\n",
      "Epoch 186/200, Iteration 186/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 187/250, Loss: 0.0355\n",
      "Epoch 186/200, Iteration 188/250, Loss: 0.0268\n",
      "Epoch 186/200, Iteration 189/250, Loss: 0.0089\n",
      "Epoch 186/200, Iteration 190/250, Loss: 0.0128\n",
      "Epoch 186/200, Iteration 191/250, Loss: 0.0252\n",
      "Epoch 186/200, Iteration 192/250, Loss: 0.0209\n",
      "Epoch 186/200, Iteration 193/250, Loss: 0.0139\n",
      "Epoch 186/200, Iteration 194/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 195/250, Loss: 0.0105\n",
      "Epoch 186/200, Iteration 196/250, Loss: 0.0209\n",
      "Epoch 186/200, Iteration 197/250, Loss: 0.0115\n",
      "Epoch 186/200, Iteration 198/250, Loss: 0.0100\n",
      "Epoch 186/200, Iteration 199/250, Loss: 0.0098\n",
      "Epoch 186/200, Iteration 200/250, Loss: 0.0234\n",
      "Epoch 186/200, Iteration 201/250, Loss: 0.0090\n",
      "Epoch 186/200, Iteration 202/250, Loss: 0.0121\n",
      "Epoch 186/200, Iteration 203/250, Loss: 0.0216\n",
      "Epoch 186/200, Iteration 204/250, Loss: 0.0115\n",
      "Epoch 186/200, Iteration 205/250, Loss: 0.0153\n",
      "Epoch 186/200, Iteration 206/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 207/250, Loss: 0.0175\n",
      "Epoch 186/200, Iteration 208/250, Loss: 0.0088\n",
      "Epoch 186/200, Iteration 209/250, Loss: 0.0096\n",
      "Epoch 186/200, Iteration 210/250, Loss: 0.0105\n",
      "Epoch 186/200, Iteration 211/250, Loss: 0.0263\n",
      "Epoch 186/200, Iteration 212/250, Loss: 0.0107\n",
      "Epoch 186/200, Iteration 213/250, Loss: 0.0098\n",
      "Epoch 186/200, Iteration 214/250, Loss: 0.0205\n",
      "Epoch 186/200, Iteration 215/250, Loss: 0.0106\n",
      "Epoch 186/200, Iteration 216/250, Loss: 0.0196\n",
      "Epoch 186/200, Iteration 217/250, Loss: 0.0255\n",
      "Epoch 186/200, Iteration 218/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 219/250, Loss: 0.0148\n",
      "Epoch 186/200, Iteration 220/250, Loss: 0.0335\n",
      "Epoch 186/200, Iteration 221/250, Loss: 0.0146\n",
      "Epoch 186/200, Iteration 222/250, Loss: 0.0164\n",
      "Epoch 186/200, Iteration 223/250, Loss: 0.0215\n",
      "Epoch 186/200, Iteration 224/250, Loss: 0.0135\n",
      "Epoch 186/200, Iteration 225/250, Loss: 0.0194\n",
      "Epoch 186/200, Iteration 226/250, Loss: 0.0110\n",
      "Epoch 186/200, Iteration 227/250, Loss: 0.0116\n",
      "Epoch 186/200, Iteration 228/250, Loss: 0.0149\n",
      "Epoch 186/200, Iteration 229/250, Loss: 0.0069\n",
      "Epoch 186/200, Iteration 230/250, Loss: 0.0115\n",
      "Epoch 186/200, Iteration 231/250, Loss: 0.0104\n",
      "Epoch 186/200, Iteration 232/250, Loss: 0.0112\n",
      "Epoch 186/200, Iteration 233/250, Loss: 0.0119\n",
      "Epoch 186/200, Iteration 234/250, Loss: 0.0267\n",
      "Epoch 186/200, Iteration 235/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 236/250, Loss: 0.0132\n",
      "Epoch 186/200, Iteration 237/250, Loss: 0.0113\n",
      "Epoch 186/200, Iteration 238/250, Loss: 0.0201\n",
      "Epoch 186/200, Iteration 239/250, Loss: 0.0151\n",
      "Epoch 186/200, Iteration 240/250, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200, Iteration 241/250, Loss: 0.0099\n",
      "Epoch 186/200, Iteration 242/250, Loss: 0.0109\n",
      "Epoch 186/200, Iteration 243/250, Loss: 0.0164\n",
      "Epoch 186/200, Iteration 244/250, Loss: 0.0100\n",
      "Epoch 186/200, Iteration 245/250, Loss: 0.0232\n",
      "Epoch 186/200, Iteration 246/250, Loss: 0.0120\n",
      "Epoch 186/200, Iteration 247/250, Loss: 0.0103\n",
      "Epoch 186/200, Iteration 248/250, Loss: 0.0131\n",
      "Epoch 186/200, Iteration 249/250, Loss: 0.0152\n",
      "Epoch 186/200, Iteration 250/250, Loss: 0.0199\n",
      "Train Error: \n",
      " Accuracy: 84.79%, Avg loss: 0.007075, MRE: 0.500333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.007627, MRE: 0.568828 \n",
      "\n",
      "Epoch 187/200, Iteration 1/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 2/250, Loss: 0.0065\n",
      "Epoch 187/200, Iteration 3/250, Loss: 0.0239\n",
      "Epoch 187/200, Iteration 4/250, Loss: 0.0132\n",
      "Epoch 187/200, Iteration 5/250, Loss: 0.0093\n",
      "Epoch 187/200, Iteration 6/250, Loss: 0.0104\n",
      "Epoch 187/200, Iteration 7/250, Loss: 0.0197\n",
      "Epoch 187/200, Iteration 8/250, Loss: 0.0079\n",
      "Epoch 187/200, Iteration 9/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 10/250, Loss: 0.0305\n",
      "Epoch 187/200, Iteration 11/250, Loss: 0.0164\n",
      "Epoch 187/200, Iteration 12/250, Loss: 0.0228\n",
      "Epoch 187/200, Iteration 13/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 14/250, Loss: 0.0145\n",
      "Epoch 187/200, Iteration 15/250, Loss: 0.0118\n",
      "Epoch 187/200, Iteration 16/250, Loss: 0.0149\n",
      "Epoch 187/200, Iteration 17/250, Loss: 0.0137\n",
      "Epoch 187/200, Iteration 18/250, Loss: 0.0077\n",
      "Epoch 187/200, Iteration 19/250, Loss: 0.0180\n",
      "Epoch 187/200, Iteration 20/250, Loss: 0.0128\n",
      "Epoch 187/200, Iteration 21/250, Loss: 0.0170\n",
      "Epoch 187/200, Iteration 22/250, Loss: 0.0124\n",
      "Epoch 187/200, Iteration 23/250, Loss: 0.0093\n",
      "Epoch 187/200, Iteration 24/250, Loss: 0.0201\n",
      "Epoch 187/200, Iteration 25/250, Loss: 0.0303\n",
      "Epoch 187/200, Iteration 26/250, Loss: 0.0094\n",
      "Epoch 187/200, Iteration 27/250, Loss: 0.0069\n",
      "Epoch 187/200, Iteration 28/250, Loss: 0.0120\n",
      "Epoch 187/200, Iteration 29/250, Loss: 0.0114\n",
      "Epoch 187/200, Iteration 30/250, Loss: 0.0180\n",
      "Epoch 187/200, Iteration 31/250, Loss: 0.0217\n",
      "Epoch 187/200, Iteration 32/250, Loss: 0.0128\n",
      "Epoch 187/200, Iteration 33/250, Loss: 0.0227\n",
      "Epoch 187/200, Iteration 34/250, Loss: 0.0121\n",
      "Epoch 187/200, Iteration 35/250, Loss: 0.0323\n",
      "Epoch 187/200, Iteration 36/250, Loss: 0.0234\n",
      "Epoch 187/200, Iteration 37/250, Loss: 0.0067\n",
      "Epoch 187/200, Iteration 38/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 39/250, Loss: 0.0108\n",
      "Epoch 187/200, Iteration 40/250, Loss: 0.0121\n",
      "Epoch 187/200, Iteration 41/250, Loss: 0.0146\n",
      "Epoch 187/200, Iteration 42/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 43/250, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 44/250, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 45/250, Loss: 0.0129\n",
      "Epoch 187/200, Iteration 46/250, Loss: 0.0099\n",
      "Epoch 187/200, Iteration 47/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 48/250, Loss: 0.0071\n",
      "Epoch 187/200, Iteration 49/250, Loss: 0.0214\n",
      "Epoch 187/200, Iteration 50/250, Loss: 0.0297\n",
      "Epoch 187/200, Iteration 51/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 52/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 53/250, Loss: 0.0265\n",
      "Epoch 187/200, Iteration 54/250, Loss: 0.0141\n",
      "Epoch 187/200, Iteration 55/250, Loss: 0.0108\n",
      "Epoch 187/200, Iteration 56/250, Loss: 0.0303\n",
      "Epoch 187/200, Iteration 57/250, Loss: 0.0219\n",
      "Epoch 187/200, Iteration 58/250, Loss: 0.0171\n",
      "Epoch 187/200, Iteration 59/250, Loss: 0.0186\n",
      "Epoch 187/200, Iteration 60/250, Loss: 0.0155\n",
      "Epoch 187/200, Iteration 61/250, Loss: 0.0063\n",
      "Epoch 187/200, Iteration 62/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 63/250, Loss: 0.0281\n",
      "Epoch 187/200, Iteration 64/250, Loss: 0.0369\n",
      "Epoch 187/200, Iteration 65/250, Loss: 0.0097\n",
      "Epoch 187/200, Iteration 66/250, Loss: 0.0138\n",
      "Epoch 187/200, Iteration 67/250, Loss: 0.0152\n",
      "Epoch 187/200, Iteration 68/250, Loss: 0.0139\n",
      "Epoch 187/200, Iteration 69/250, Loss: 0.0135\n",
      "Epoch 187/200, Iteration 70/250, Loss: 0.0148\n",
      "Epoch 187/200, Iteration 71/250, Loss: 0.0154\n",
      "Epoch 187/200, Iteration 72/250, Loss: 0.0176\n",
      "Epoch 187/200, Iteration 73/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 74/250, Loss: 0.0074\n",
      "Epoch 187/200, Iteration 75/250, Loss: 0.0296\n",
      "Epoch 187/200, Iteration 76/250, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 77/250, Loss: 0.0200\n",
      "Epoch 187/200, Iteration 78/250, Loss: 0.0175\n",
      "Epoch 187/200, Iteration 79/250, Loss: 0.0202\n",
      "Epoch 187/200, Iteration 80/250, Loss: 0.0118\n",
      "Epoch 187/200, Iteration 81/250, Loss: 0.0148\n",
      "Epoch 187/200, Iteration 82/250, Loss: 0.0148\n",
      "Epoch 187/200, Iteration 83/250, Loss: 0.0157\n",
      "Epoch 187/200, Iteration 84/250, Loss: 0.0147\n",
      "Epoch 187/200, Iteration 85/250, Loss: 0.0129\n",
      "Epoch 187/200, Iteration 86/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 87/250, Loss: 0.0177\n",
      "Epoch 187/200, Iteration 88/250, Loss: 0.0270\n",
      "Epoch 187/200, Iteration 89/250, Loss: 0.0073\n",
      "Epoch 187/200, Iteration 90/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 91/250, Loss: 0.0090\n",
      "Epoch 187/200, Iteration 92/250, Loss: 0.0169\n",
      "Epoch 187/200, Iteration 93/250, Loss: 0.0085\n",
      "Epoch 187/200, Iteration 94/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 95/250, Loss: 0.0219\n",
      "Epoch 187/200, Iteration 96/250, Loss: 0.0297\n",
      "Epoch 187/200, Iteration 97/250, Loss: 0.0286\n",
      "Epoch 187/200, Iteration 98/250, Loss: 0.0127\n",
      "Epoch 187/200, Iteration 99/250, Loss: 0.0153\n",
      "Epoch 187/200, Iteration 100/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 101/250, Loss: 0.0238\n",
      "Epoch 187/200, Iteration 102/250, Loss: 0.0121\n",
      "Epoch 187/200, Iteration 103/250, Loss: 0.0115\n",
      "Epoch 187/200, Iteration 104/250, Loss: 0.0072\n",
      "Epoch 187/200, Iteration 105/250, Loss: 0.0204\n",
      "Epoch 187/200, Iteration 106/250, Loss: 0.0193\n",
      "Epoch 187/200, Iteration 107/250, Loss: 0.0124\n",
      "Epoch 187/200, Iteration 108/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 109/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 110/250, Loss: 0.0250\n",
      "Epoch 187/200, Iteration 111/250, Loss: 0.0095\n",
      "Epoch 187/200, Iteration 112/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 113/250, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 114/250, Loss: 0.0066\n",
      "Epoch 187/200, Iteration 115/250, Loss: 0.0135\n",
      "Epoch 187/200, Iteration 116/250, Loss: 0.0208\n",
      "Epoch 187/200, Iteration 117/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 118/250, Loss: 0.0110\n",
      "Epoch 187/200, Iteration 119/250, Loss: 0.0387\n",
      "Epoch 187/200, Iteration 120/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 121/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 122/250, Loss: 0.0198\n",
      "Epoch 187/200, Iteration 123/250, Loss: 0.0261\n",
      "Epoch 187/200, Iteration 124/250, Loss: 0.0271\n",
      "Epoch 187/200, Iteration 125/250, Loss: 0.0119\n",
      "Epoch 187/200, Iteration 126/250, Loss: 0.0113\n",
      "Epoch 187/200, Iteration 127/250, Loss: 0.0185\n",
      "Epoch 187/200, Iteration 128/250, Loss: 0.0120\n",
      "Epoch 187/200, Iteration 129/250, Loss: 0.0098\n",
      "Epoch 187/200, Iteration 130/250, Loss: 0.0261\n",
      "Epoch 187/200, Iteration 131/250, Loss: 0.0247\n",
      "Epoch 187/200, Iteration 132/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 133/250, Loss: 0.0342\n",
      "Epoch 187/200, Iteration 134/250, Loss: 0.0136\n",
      "Epoch 187/200, Iteration 135/250, Loss: 0.0188\n",
      "Epoch 187/200, Iteration 136/250, Loss: 0.0185\n",
      "Epoch 187/200, Iteration 137/250, Loss: 0.0186\n",
      "Epoch 187/200, Iteration 138/250, Loss: 0.0115\n",
      "Epoch 187/200, Iteration 139/250, Loss: 0.0079\n",
      "Epoch 187/200, Iteration 140/250, Loss: 0.0236\n",
      "Epoch 187/200, Iteration 141/250, Loss: 0.0136\n",
      "Epoch 187/200, Iteration 142/250, Loss: 0.0107\n",
      "Epoch 187/200, Iteration 143/250, Loss: 0.0142\n",
      "Epoch 187/200, Iteration 144/250, Loss: 0.0187\n",
      "Epoch 187/200, Iteration 145/250, Loss: 0.0150\n",
      "Epoch 187/200, Iteration 146/250, Loss: 0.0399\n",
      "Epoch 187/200, Iteration 147/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 148/250, Loss: 0.0166\n",
      "Epoch 187/200, Iteration 149/250, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 150/250, Loss: 0.0099\n",
      "Epoch 187/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 152/250, Loss: 0.0258\n",
      "Epoch 187/200, Iteration 153/250, Loss: 0.0102\n",
      "Epoch 187/200, Iteration 154/250, Loss: 0.0218\n",
      "Epoch 187/200, Iteration 155/250, Loss: 0.0099\n",
      "Epoch 187/200, Iteration 156/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 157/250, Loss: 0.0089\n",
      "Epoch 187/200, Iteration 158/250, Loss: 0.0338\n",
      "Epoch 187/200, Iteration 159/250, Loss: 0.0207\n",
      "Epoch 187/200, Iteration 160/250, Loss: 0.0149\n",
      "Epoch 187/200, Iteration 161/250, Loss: 0.0118\n",
      "Epoch 187/200, Iteration 162/250, Loss: 0.0086\n",
      "Epoch 187/200, Iteration 163/250, Loss: 0.0080\n",
      "Epoch 187/200, Iteration 164/250, Loss: 0.0076\n",
      "Epoch 187/200, Iteration 165/250, Loss: 0.0204\n",
      "Epoch 187/200, Iteration 166/250, Loss: 0.0081\n",
      "Epoch 187/200, Iteration 167/250, Loss: 0.0236\n",
      "Epoch 187/200, Iteration 168/250, Loss: 0.0132\n",
      "Epoch 187/200, Iteration 169/250, Loss: 0.0093\n",
      "Epoch 187/200, Iteration 170/250, Loss: 0.0127\n",
      "Epoch 187/200, Iteration 171/250, Loss: 0.0105\n",
      "Epoch 187/200, Iteration 172/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 173/250, Loss: 0.0089\n",
      "Epoch 187/200, Iteration 174/250, Loss: 0.0236\n",
      "Epoch 187/200, Iteration 175/250, Loss: 0.0155\n",
      "Epoch 187/200, Iteration 176/250, Loss: 0.0100\n",
      "Epoch 187/200, Iteration 177/250, Loss: 0.0106\n",
      "Epoch 187/200, Iteration 178/250, Loss: 0.0357\n",
      "Epoch 187/200, Iteration 179/250, Loss: 0.0112\n",
      "Epoch 187/200, Iteration 180/250, Loss: 0.0163\n",
      "Epoch 187/200, Iteration 181/250, Loss: 0.0169\n",
      "Epoch 187/200, Iteration 182/250, Loss: 0.0090\n",
      "Epoch 187/200, Iteration 183/250, Loss: 0.0098\n",
      "Epoch 187/200, Iteration 184/250, Loss: 0.0391\n",
      "Epoch 187/200, Iteration 185/250, Loss: 0.0109\n",
      "Epoch 187/200, Iteration 186/250, Loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200, Iteration 187/250, Loss: 0.0091\n",
      "Epoch 187/200, Iteration 188/250, Loss: 0.0517\n",
      "Epoch 187/200, Iteration 189/250, Loss: 0.0318\n",
      "Epoch 187/200, Iteration 190/250, Loss: 0.0247\n",
      "Epoch 187/200, Iteration 191/250, Loss: 0.0070\n",
      "Epoch 187/200, Iteration 192/250, Loss: 0.0104\n",
      "Epoch 187/200, Iteration 193/250, Loss: 0.0289\n",
      "Epoch 187/200, Iteration 194/250, Loss: 0.0200\n",
      "Epoch 187/200, Iteration 195/250, Loss: 0.0177\n",
      "Epoch 187/200, Iteration 196/250, Loss: 0.0115\n",
      "Epoch 187/200, Iteration 197/250, Loss: 0.0127\n",
      "Epoch 187/200, Iteration 198/250, Loss: 0.0078\n",
      "Epoch 187/200, Iteration 199/250, Loss: 0.0085\n",
      "Epoch 187/200, Iteration 200/250, Loss: 0.0272\n",
      "Epoch 187/200, Iteration 201/250, Loss: 0.0338\n",
      "Epoch 187/200, Iteration 202/250, Loss: 0.0270\n",
      "Epoch 187/200, Iteration 203/250, Loss: 0.0248\n",
      "Epoch 187/200, Iteration 204/250, Loss: 0.0243\n",
      "Epoch 187/200, Iteration 205/250, Loss: 0.0116\n",
      "Epoch 187/200, Iteration 206/250, Loss: 0.0099\n",
      "Epoch 187/200, Iteration 207/250, Loss: 0.0076\n",
      "Epoch 187/200, Iteration 208/250, Loss: 0.0130\n",
      "Epoch 187/200, Iteration 209/250, Loss: 0.0168\n",
      "Epoch 187/200, Iteration 210/250, Loss: 0.0085\n",
      "Epoch 187/200, Iteration 211/250, Loss: 0.0240\n",
      "Epoch 187/200, Iteration 212/250, Loss: 0.0188\n",
      "Epoch 187/200, Iteration 213/250, Loss: 0.0135\n",
      "Epoch 187/200, Iteration 214/250, Loss: 0.0259\n",
      "Epoch 187/200, Iteration 215/250, Loss: 0.0132\n",
      "Epoch 187/200, Iteration 216/250, Loss: 0.0075\n",
      "Epoch 187/200, Iteration 217/250, Loss: 0.0096\n",
      "Epoch 187/200, Iteration 218/250, Loss: 0.0074\n",
      "Epoch 187/200, Iteration 219/250, Loss: 0.0088\n",
      "Epoch 187/200, Iteration 220/250, Loss: 0.0203\n",
      "Epoch 187/200, Iteration 221/250, Loss: 0.0313\n",
      "Epoch 187/200, Iteration 222/250, Loss: 0.0268\n",
      "Epoch 187/200, Iteration 223/250, Loss: 0.0191\n",
      "Epoch 187/200, Iteration 224/250, Loss: 0.0403\n",
      "Epoch 187/200, Iteration 225/250, Loss: 0.0274\n",
      "Epoch 187/200, Iteration 226/250, Loss: 0.0083\n",
      "Epoch 187/200, Iteration 227/250, Loss: 0.0234\n",
      "Epoch 187/200, Iteration 228/250, Loss: 0.0232\n",
      "Epoch 187/200, Iteration 229/250, Loss: 0.0258\n",
      "Epoch 187/200, Iteration 230/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 231/250, Loss: 0.0191\n",
      "Epoch 187/200, Iteration 232/250, Loss: 0.0226\n",
      "Epoch 187/200, Iteration 233/250, Loss: 0.0072\n",
      "Epoch 187/200, Iteration 234/250, Loss: 0.0144\n",
      "Epoch 187/200, Iteration 235/250, Loss: 0.0079\n",
      "Epoch 187/200, Iteration 236/250, Loss: 0.0162\n",
      "Epoch 187/200, Iteration 237/250, Loss: 0.0169\n",
      "Epoch 187/200, Iteration 238/250, Loss: 0.0087\n",
      "Epoch 187/200, Iteration 239/250, Loss: 0.0109\n",
      "Epoch 187/200, Iteration 240/250, Loss: 0.0134\n",
      "Epoch 187/200, Iteration 241/250, Loss: 0.0351\n",
      "Epoch 187/200, Iteration 242/250, Loss: 0.0110\n",
      "Epoch 187/200, Iteration 243/250, Loss: 0.0127\n",
      "Epoch 187/200, Iteration 244/250, Loss: 0.0084\n",
      "Epoch 187/200, Iteration 245/250, Loss: 0.0122\n",
      "Epoch 187/200, Iteration 246/250, Loss: 0.0087\n",
      "Epoch 187/200, Iteration 247/250, Loss: 0.0155\n",
      "Epoch 187/200, Iteration 248/250, Loss: 0.0103\n",
      "Epoch 187/200, Iteration 249/250, Loss: 0.0114\n",
      "Epoch 187/200, Iteration 250/250, Loss: 0.0231\n",
      "Train Error: \n",
      " Accuracy: 74.44%, Avg loss: 0.008049, MRE: 0.475514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.008462, MRE: 0.663135 \n",
      "\n",
      "Epoch 188/200, Iteration 1/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 2/250, Loss: 0.0196\n",
      "Epoch 188/200, Iteration 3/250, Loss: 0.0145\n",
      "Epoch 188/200, Iteration 4/250, Loss: 0.0078\n",
      "Epoch 188/200, Iteration 5/250, Loss: 0.0120\n",
      "Epoch 188/200, Iteration 6/250, Loss: 0.0123\n",
      "Epoch 188/200, Iteration 7/250, Loss: 0.0099\n",
      "Epoch 188/200, Iteration 8/250, Loss: 0.0227\n",
      "Epoch 188/200, Iteration 9/250, Loss: 0.0162\n",
      "Epoch 188/200, Iteration 10/250, Loss: 0.0163\n",
      "Epoch 188/200, Iteration 11/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 12/250, Loss: 0.0162\n",
      "Epoch 188/200, Iteration 13/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 14/250, Loss: 0.0330\n",
      "Epoch 188/200, Iteration 15/250, Loss: 0.0240\n",
      "Epoch 188/200, Iteration 16/250, Loss: 0.0155\n",
      "Epoch 188/200, Iteration 17/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 18/250, Loss: 0.0106\n",
      "Epoch 188/200, Iteration 19/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 20/250, Loss: 0.0150\n",
      "Epoch 188/200, Iteration 21/250, Loss: 0.0102\n",
      "Epoch 188/200, Iteration 22/250, Loss: 0.0165\n",
      "Epoch 188/200, Iteration 23/250, Loss: 0.0122\n",
      "Epoch 188/200, Iteration 24/250, Loss: 0.0219\n",
      "Epoch 188/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 188/200, Iteration 26/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 27/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 28/250, Loss: 0.0192\n",
      "Epoch 188/200, Iteration 29/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 30/250, Loss: 0.0190\n",
      "Epoch 188/200, Iteration 31/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 32/250, Loss: 0.0154\n",
      "Epoch 188/200, Iteration 33/250, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 34/250, Loss: 0.0082\n",
      "Epoch 188/200, Iteration 35/250, Loss: 0.0189\n",
      "Epoch 188/200, Iteration 36/250, Loss: 0.0119\n",
      "Epoch 188/200, Iteration 37/250, Loss: 0.0238\n",
      "Epoch 188/200, Iteration 38/250, Loss: 0.0250\n",
      "Epoch 188/200, Iteration 39/250, Loss: 0.0215\n",
      "Epoch 188/200, Iteration 40/250, Loss: 0.0124\n",
      "Epoch 188/200, Iteration 41/250, Loss: 0.0241\n",
      "Epoch 188/200, Iteration 42/250, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 43/250, Loss: 0.0078\n",
      "Epoch 188/200, Iteration 44/250, Loss: 0.0265\n",
      "Epoch 188/200, Iteration 45/250, Loss: 0.0279\n",
      "Epoch 188/200, Iteration 46/250, Loss: 0.0100\n",
      "Epoch 188/200, Iteration 47/250, Loss: 0.0186\n",
      "Epoch 188/200, Iteration 48/250, Loss: 0.0198\n",
      "Epoch 188/200, Iteration 49/250, Loss: 0.0349\n",
      "Epoch 188/200, Iteration 50/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 51/250, Loss: 0.0288\n",
      "Epoch 188/200, Iteration 52/250, Loss: 0.0128\n",
      "Epoch 188/200, Iteration 53/250, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 54/250, Loss: 0.0089\n",
      "Epoch 188/200, Iteration 55/250, Loss: 0.0111\n",
      "Epoch 188/200, Iteration 56/250, Loss: 0.0200\n",
      "Epoch 188/200, Iteration 57/250, Loss: 0.0118\n",
      "Epoch 188/200, Iteration 58/250, Loss: 0.0093\n",
      "Epoch 188/200, Iteration 59/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 60/250, Loss: 0.0102\n",
      "Epoch 188/200, Iteration 61/250, Loss: 0.0096\n",
      "Epoch 188/200, Iteration 62/250, Loss: 0.0153\n",
      "Epoch 188/200, Iteration 63/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 64/250, Loss: 0.0155\n",
      "Epoch 188/200, Iteration 65/250, Loss: 0.0273\n",
      "Epoch 188/200, Iteration 66/250, Loss: 0.0147\n",
      "Epoch 188/200, Iteration 67/250, Loss: 0.0240\n",
      "Epoch 188/200, Iteration 68/250, Loss: 0.0127\n",
      "Epoch 188/200, Iteration 69/250, Loss: 0.0173\n",
      "Epoch 188/200, Iteration 70/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 71/250, Loss: 0.0183\n",
      "Epoch 188/200, Iteration 72/250, Loss: 0.0090\n",
      "Epoch 188/200, Iteration 73/250, Loss: 0.0098\n",
      "Epoch 188/200, Iteration 74/250, Loss: 0.0353\n",
      "Epoch 188/200, Iteration 75/250, Loss: 0.0069\n",
      "Epoch 188/200, Iteration 76/250, Loss: 0.0162\n",
      "Epoch 188/200, Iteration 77/250, Loss: 0.0202\n",
      "Epoch 188/200, Iteration 78/250, Loss: 0.0237\n",
      "Epoch 188/200, Iteration 79/250, Loss: 0.0151\n",
      "Epoch 188/200, Iteration 80/250, Loss: 0.0398\n",
      "Epoch 188/200, Iteration 81/250, Loss: 0.0157\n",
      "Epoch 188/200, Iteration 82/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 83/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 84/250, Loss: 0.0135\n",
      "Epoch 188/200, Iteration 85/250, Loss: 0.0100\n",
      "Epoch 188/200, Iteration 86/250, Loss: 0.0229\n",
      "Epoch 188/200, Iteration 87/250, Loss: 0.0320\n",
      "Epoch 188/200, Iteration 88/250, Loss: 0.0177\n",
      "Epoch 188/200, Iteration 89/250, Loss: 0.0157\n",
      "Epoch 188/200, Iteration 90/250, Loss: 0.0072\n",
      "Epoch 188/200, Iteration 91/250, Loss: 0.0142\n",
      "Epoch 188/200, Iteration 92/250, Loss: 0.0159\n",
      "Epoch 188/200, Iteration 93/250, Loss: 0.0129\n",
      "Epoch 188/200, Iteration 94/250, Loss: 0.0244\n",
      "Epoch 188/200, Iteration 95/250, Loss: 0.0316\n",
      "Epoch 188/200, Iteration 96/250, Loss: 0.0082\n",
      "Epoch 188/200, Iteration 97/250, Loss: 0.0264\n",
      "Epoch 188/200, Iteration 98/250, Loss: 0.0150\n",
      "Epoch 188/200, Iteration 99/250, Loss: 0.0207\n",
      "Epoch 188/200, Iteration 100/250, Loss: 0.0155\n",
      "Epoch 188/200, Iteration 101/250, Loss: 0.0121\n",
      "Epoch 188/200, Iteration 102/250, Loss: 0.0337\n",
      "Epoch 188/200, Iteration 103/250, Loss: 0.0096\n",
      "Epoch 188/200, Iteration 104/250, Loss: 0.0246\n",
      "Epoch 188/200, Iteration 105/250, Loss: 0.0200\n",
      "Epoch 188/200, Iteration 106/250, Loss: 0.0324\n",
      "Epoch 188/200, Iteration 107/250, Loss: 0.0126\n",
      "Epoch 188/200, Iteration 108/250, Loss: 0.0118\n",
      "Epoch 188/200, Iteration 109/250, Loss: 0.0128\n",
      "Epoch 188/200, Iteration 110/250, Loss: 0.0294\n",
      "Epoch 188/200, Iteration 111/250, Loss: 0.0088\n",
      "Epoch 188/200, Iteration 112/250, Loss: 0.0234\n",
      "Epoch 188/200, Iteration 113/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 114/250, Loss: 0.0195\n",
      "Epoch 188/200, Iteration 115/250, Loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200, Iteration 116/250, Loss: 0.0109\n",
      "Epoch 188/200, Iteration 117/250, Loss: 0.0156\n",
      "Epoch 188/200, Iteration 118/250, Loss: 0.0170\n",
      "Epoch 188/200, Iteration 119/250, Loss: 0.0383\n",
      "Epoch 188/200, Iteration 120/250, Loss: 0.0186\n",
      "Epoch 188/200, Iteration 121/250, Loss: 0.0260\n",
      "Epoch 188/200, Iteration 122/250, Loss: 0.0202\n",
      "Epoch 188/200, Iteration 123/250, Loss: 0.0108\n",
      "Epoch 188/200, Iteration 124/250, Loss: 0.0084\n",
      "Epoch 188/200, Iteration 125/250, Loss: 0.0116\n",
      "Epoch 188/200, Iteration 126/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 127/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 128/250, Loss: 0.0187\n",
      "Epoch 188/200, Iteration 129/250, Loss: 0.0094\n",
      "Epoch 188/200, Iteration 130/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 131/250, Loss: 0.0233\n",
      "Epoch 188/200, Iteration 132/250, Loss: 0.0184\n",
      "Epoch 188/200, Iteration 133/250, Loss: 0.0160\n",
      "Epoch 188/200, Iteration 134/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 135/250, Loss: 0.0164\n",
      "Epoch 188/200, Iteration 136/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 137/250, Loss: 0.0174\n",
      "Epoch 188/200, Iteration 138/250, Loss: 0.0124\n",
      "Epoch 188/200, Iteration 139/250, Loss: 0.0210\n",
      "Epoch 188/200, Iteration 140/250, Loss: 0.0172\n",
      "Epoch 188/200, Iteration 141/250, Loss: 0.0104\n",
      "Epoch 188/200, Iteration 142/250, Loss: 0.0100\n",
      "Epoch 188/200, Iteration 143/250, Loss: 0.0104\n",
      "Epoch 188/200, Iteration 144/250, Loss: 0.0175\n",
      "Epoch 188/200, Iteration 145/250, Loss: 0.0378\n",
      "Epoch 188/200, Iteration 146/250, Loss: 0.0377\n",
      "Epoch 188/200, Iteration 147/250, Loss: 0.0296\n",
      "Epoch 188/200, Iteration 148/250, Loss: 0.0109\n",
      "Epoch 188/200, Iteration 149/250, Loss: 0.0182\n",
      "Epoch 188/200, Iteration 150/250, Loss: 0.0109\n",
      "Epoch 188/200, Iteration 151/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 152/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 153/250, Loss: 0.0175\n",
      "Epoch 188/200, Iteration 154/250, Loss: 0.0083\n",
      "Epoch 188/200, Iteration 155/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 156/250, Loss: 0.0088\n",
      "Epoch 188/200, Iteration 157/250, Loss: 0.0268\n",
      "Epoch 188/200, Iteration 158/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 159/250, Loss: 0.0096\n",
      "Epoch 188/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 188/200, Iteration 161/250, Loss: 0.0291\n",
      "Epoch 188/200, Iteration 162/250, Loss: 0.0096\n",
      "Epoch 188/200, Iteration 163/250, Loss: 0.0075\n",
      "Epoch 188/200, Iteration 164/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 165/250, Loss: 0.0274\n",
      "Epoch 188/200, Iteration 166/250, Loss: 0.0104\n",
      "Epoch 188/200, Iteration 167/250, Loss: 0.0136\n",
      "Epoch 188/200, Iteration 168/250, Loss: 0.0156\n",
      "Epoch 188/200, Iteration 169/250, Loss: 0.0099\n",
      "Epoch 188/200, Iteration 170/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 171/250, Loss: 0.0305\n",
      "Epoch 188/200, Iteration 172/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 173/250, Loss: 0.0109\n",
      "Epoch 188/200, Iteration 174/250, Loss: 0.0107\n",
      "Epoch 188/200, Iteration 175/250, Loss: 0.0207\n",
      "Epoch 188/200, Iteration 176/250, Loss: 0.0072\n",
      "Epoch 188/200, Iteration 177/250, Loss: 0.0366\n",
      "Epoch 188/200, Iteration 178/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 179/250, Loss: 0.0105\n",
      "Epoch 188/200, Iteration 180/250, Loss: 0.0089\n",
      "Epoch 188/200, Iteration 181/250, Loss: 0.0137\n",
      "Epoch 188/200, Iteration 182/250, Loss: 0.0190\n",
      "Epoch 188/200, Iteration 183/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 184/250, Loss: 0.0290\n",
      "Epoch 188/200, Iteration 185/250, Loss: 0.0163\n",
      "Epoch 188/200, Iteration 186/250, Loss: 0.0267\n",
      "Epoch 188/200, Iteration 187/250, Loss: 0.0141\n",
      "Epoch 188/200, Iteration 188/250, Loss: 0.0122\n",
      "Epoch 188/200, Iteration 189/250, Loss: 0.0232\n",
      "Epoch 188/200, Iteration 190/250, Loss: 0.0170\n",
      "Epoch 188/200, Iteration 191/250, Loss: 0.0115\n",
      "Epoch 188/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 188/200, Iteration 193/250, Loss: 0.0131\n",
      "Epoch 188/200, Iteration 194/250, Loss: 0.0270\n",
      "Epoch 188/200, Iteration 195/250, Loss: 0.0182\n",
      "Epoch 188/200, Iteration 196/250, Loss: 0.0200\n",
      "Epoch 188/200, Iteration 197/250, Loss: 0.0199\n",
      "Epoch 188/200, Iteration 198/250, Loss: 0.0081\n",
      "Epoch 188/200, Iteration 199/250, Loss: 0.0111\n",
      "Epoch 188/200, Iteration 200/250, Loss: 0.0074\n",
      "Epoch 188/200, Iteration 201/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 202/250, Loss: 0.0089\n",
      "Epoch 188/200, Iteration 203/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 204/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 205/250, Loss: 0.0198\n",
      "Epoch 188/200, Iteration 206/250, Loss: 0.0127\n",
      "Epoch 188/200, Iteration 207/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 208/250, Loss: 0.0125\n",
      "Epoch 188/200, Iteration 209/250, Loss: 0.0095\n",
      "Epoch 188/200, Iteration 210/250, Loss: 0.0216\n",
      "Epoch 188/200, Iteration 211/250, Loss: 0.0126\n",
      "Epoch 188/200, Iteration 212/250, Loss: 0.0090\n",
      "Epoch 188/200, Iteration 213/250, Loss: 0.0165\n",
      "Epoch 188/200, Iteration 214/250, Loss: 0.0086\n",
      "Epoch 188/200, Iteration 215/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 216/250, Loss: 0.0101\n",
      "Epoch 188/200, Iteration 217/250, Loss: 0.0123\n",
      "Epoch 188/200, Iteration 218/250, Loss: 0.0099\n",
      "Epoch 188/200, Iteration 219/250, Loss: 0.0139\n",
      "Epoch 188/200, Iteration 220/250, Loss: 0.0150\n",
      "Epoch 188/200, Iteration 221/250, Loss: 0.0188\n",
      "Epoch 188/200, Iteration 222/250, Loss: 0.0244\n",
      "Epoch 188/200, Iteration 223/250, Loss: 0.0103\n",
      "Epoch 188/200, Iteration 224/250, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 225/250, Loss: 0.0143\n",
      "Epoch 188/200, Iteration 226/250, Loss: 0.0158\n",
      "Epoch 188/200, Iteration 227/250, Loss: 0.0196\n",
      "Epoch 188/200, Iteration 228/250, Loss: 0.0110\n",
      "Epoch 188/200, Iteration 229/250, Loss: 0.0113\n",
      "Epoch 188/200, Iteration 230/250, Loss: 0.0091\n",
      "Epoch 188/200, Iteration 231/250, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 232/250, Loss: 0.0085\n",
      "Epoch 188/200, Iteration 233/250, Loss: 0.0155\n",
      "Epoch 188/200, Iteration 234/250, Loss: 0.0117\n",
      "Epoch 188/200, Iteration 235/250, Loss: 0.0150\n",
      "Epoch 188/200, Iteration 236/250, Loss: 0.0066\n",
      "Epoch 188/200, Iteration 237/250, Loss: 0.0082\n",
      "Epoch 188/200, Iteration 238/250, Loss: 0.0087\n",
      "Epoch 188/200, Iteration 239/250, Loss: 0.0273\n",
      "Epoch 188/200, Iteration 240/250, Loss: 0.0132\n",
      "Epoch 188/200, Iteration 241/250, Loss: 0.0148\n",
      "Epoch 188/200, Iteration 242/250, Loss: 0.0140\n",
      "Epoch 188/200, Iteration 243/250, Loss: 0.0341\n",
      "Epoch 188/200, Iteration 244/250, Loss: 0.0122\n",
      "Epoch 188/200, Iteration 245/250, Loss: 0.0097\n",
      "Epoch 188/200, Iteration 246/250, Loss: 0.0314\n",
      "Epoch 188/200, Iteration 247/250, Loss: 0.0121\n",
      "Epoch 188/200, Iteration 248/250, Loss: 0.0257\n",
      "Epoch 188/200, Iteration 249/250, Loss: 0.0172\n",
      "Epoch 188/200, Iteration 250/250, Loss: 0.0307\n",
      "Train Error: \n",
      " Accuracy: 96.08%, Avg loss: 0.008812, MRE: 0.684013 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.009450, MRE: 0.850608 \n",
      "\n",
      "Epoch 189/200, Iteration 1/250, Loss: 0.0091\n",
      "Epoch 189/200, Iteration 2/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 3/250, Loss: 0.0138\n",
      "Epoch 189/200, Iteration 4/250, Loss: 0.0105\n",
      "Epoch 189/200, Iteration 5/250, Loss: 0.0280\n",
      "Epoch 189/200, Iteration 6/250, Loss: 0.0300\n",
      "Epoch 189/200, Iteration 7/250, Loss: 0.0161\n",
      "Epoch 189/200, Iteration 8/250, Loss: 0.0248\n",
      "Epoch 189/200, Iteration 9/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 10/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 11/250, Loss: 0.0123\n",
      "Epoch 189/200, Iteration 12/250, Loss: 0.0149\n",
      "Epoch 189/200, Iteration 13/250, Loss: 0.0189\n",
      "Epoch 189/200, Iteration 14/250, Loss: 0.0081\n",
      "Epoch 189/200, Iteration 15/250, Loss: 0.0181\n",
      "Epoch 189/200, Iteration 16/250, Loss: 0.0297\n",
      "Epoch 189/200, Iteration 17/250, Loss: 0.0083\n",
      "Epoch 189/200, Iteration 18/250, Loss: 0.0240\n",
      "Epoch 189/200, Iteration 19/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 20/250, Loss: 0.0098\n",
      "Epoch 189/200, Iteration 21/250, Loss: 0.0106\n",
      "Epoch 189/200, Iteration 22/250, Loss: 0.0177\n",
      "Epoch 189/200, Iteration 23/250, Loss: 0.0082\n",
      "Epoch 189/200, Iteration 24/250, Loss: 0.0138\n",
      "Epoch 189/200, Iteration 25/250, Loss: 0.0132\n",
      "Epoch 189/200, Iteration 26/250, Loss: 0.0190\n",
      "Epoch 189/200, Iteration 27/250, Loss: 0.0107\n",
      "Epoch 189/200, Iteration 28/250, Loss: 0.0069\n",
      "Epoch 189/200, Iteration 29/250, Loss: 0.0217\n",
      "Epoch 189/200, Iteration 30/250, Loss: 0.0067\n",
      "Epoch 189/200, Iteration 31/250, Loss: 0.0077\n",
      "Epoch 189/200, Iteration 32/250, Loss: 0.0190\n",
      "Epoch 189/200, Iteration 33/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 34/250, Loss: 0.0144\n",
      "Epoch 189/200, Iteration 35/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 36/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 37/250, Loss: 0.0160\n",
      "Epoch 189/200, Iteration 38/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 39/250, Loss: 0.0116\n",
      "Epoch 189/200, Iteration 40/250, Loss: 0.0151\n",
      "Epoch 189/200, Iteration 41/250, Loss: 0.0111\n",
      "Epoch 189/200, Iteration 42/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 43/250, Loss: 0.0246\n",
      "Epoch 189/200, Iteration 44/250, Loss: 0.0220\n",
      "Epoch 189/200, Iteration 45/250, Loss: 0.0250\n",
      "Epoch 189/200, Iteration 46/250, Loss: 0.0109\n",
      "Epoch 189/200, Iteration 47/250, Loss: 0.0121\n",
      "Epoch 189/200, Iteration 48/250, Loss: 0.0171\n",
      "Epoch 189/200, Iteration 49/250, Loss: 0.0114\n",
      "Epoch 189/200, Iteration 50/250, Loss: 0.0127\n",
      "Epoch 189/200, Iteration 51/250, Loss: 0.0160\n",
      "Epoch 189/200, Iteration 52/250, Loss: 0.0183\n",
      "Epoch 189/200, Iteration 53/250, Loss: 0.0223\n",
      "Epoch 189/200, Iteration 54/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 55/250, Loss: 0.0085\n",
      "Epoch 189/200, Iteration 56/250, Loss: 0.0222\n",
      "Epoch 189/200, Iteration 57/250, Loss: 0.0165\n",
      "Epoch 189/200, Iteration 58/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 59/250, Loss: 0.0117\n",
      "Epoch 189/200, Iteration 60/250, Loss: 0.0112\n",
      "Epoch 189/200, Iteration 61/250, Loss: 0.0097\n",
      "Epoch 189/200, Iteration 62/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 63/250, Loss: 0.0215\n",
      "Epoch 189/200, Iteration 64/250, Loss: 0.0091\n",
      "Epoch 189/200, Iteration 65/250, Loss: 0.0270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200, Iteration 66/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 67/250, Loss: 0.0154\n",
      "Epoch 189/200, Iteration 68/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 69/250, Loss: 0.0121\n",
      "Epoch 189/200, Iteration 70/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 71/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 72/250, Loss: 0.0259\n",
      "Epoch 189/200, Iteration 73/250, Loss: 0.0066\n",
      "Epoch 189/200, Iteration 74/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 75/250, Loss: 0.0112\n",
      "Epoch 189/200, Iteration 76/250, Loss: 0.0099\n",
      "Epoch 189/200, Iteration 77/250, Loss: 0.0144\n",
      "Epoch 189/200, Iteration 78/250, Loss: 0.0286\n",
      "Epoch 189/200, Iteration 79/250, Loss: 0.0114\n",
      "Epoch 189/200, Iteration 80/250, Loss: 0.0069\n",
      "Epoch 189/200, Iteration 81/250, Loss: 0.0128\n",
      "Epoch 189/200, Iteration 82/250, Loss: 0.0078\n",
      "Epoch 189/200, Iteration 83/250, Loss: 0.0221\n",
      "Epoch 189/200, Iteration 84/250, Loss: 0.0150\n",
      "Epoch 189/200, Iteration 85/250, Loss: 0.0309\n",
      "Epoch 189/200, Iteration 86/250, Loss: 0.0103\n",
      "Epoch 189/200, Iteration 87/250, Loss: 0.0345\n",
      "Epoch 189/200, Iteration 88/250, Loss: 0.0182\n",
      "Epoch 189/200, Iteration 89/250, Loss: 0.0258\n",
      "Epoch 189/200, Iteration 90/250, Loss: 0.0177\n",
      "Epoch 189/200, Iteration 91/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 92/250, Loss: 0.0344\n",
      "Epoch 189/200, Iteration 93/250, Loss: 0.0128\n",
      "Epoch 189/200, Iteration 94/250, Loss: 0.0209\n",
      "Epoch 189/200, Iteration 95/250, Loss: 0.0201\n",
      "Epoch 189/200, Iteration 96/250, Loss: 0.0109\n",
      "Epoch 189/200, Iteration 97/250, Loss: 0.0093\n",
      "Epoch 189/200, Iteration 98/250, Loss: 0.0245\n",
      "Epoch 189/200, Iteration 99/250, Loss: 0.0103\n",
      "Epoch 189/200, Iteration 100/250, Loss: 0.0217\n",
      "Epoch 189/200, Iteration 101/250, Loss: 0.0080\n",
      "Epoch 189/200, Iteration 102/250, Loss: 0.0128\n",
      "Epoch 189/200, Iteration 103/250, Loss: 0.0166\n",
      "Epoch 189/200, Iteration 104/250, Loss: 0.0118\n",
      "Epoch 189/200, Iteration 105/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 106/250, Loss: 0.0074\n",
      "Epoch 189/200, Iteration 107/250, Loss: 0.0305\n",
      "Epoch 189/200, Iteration 108/250, Loss: 0.0254\n",
      "Epoch 189/200, Iteration 109/250, Loss: 0.0140\n",
      "Epoch 189/200, Iteration 110/250, Loss: 0.0106\n",
      "Epoch 189/200, Iteration 111/250, Loss: 0.0164\n",
      "Epoch 189/200, Iteration 112/250, Loss: 0.0237\n",
      "Epoch 189/200, Iteration 113/250, Loss: 0.0191\n",
      "Epoch 189/200, Iteration 114/250, Loss: 0.0203\n",
      "Epoch 189/200, Iteration 115/250, Loss: 0.0212\n",
      "Epoch 189/200, Iteration 116/250, Loss: 0.0093\n",
      "Epoch 189/200, Iteration 117/250, Loss: 0.0116\n",
      "Epoch 189/200, Iteration 118/250, Loss: 0.0088\n",
      "Epoch 189/200, Iteration 119/250, Loss: 0.0107\n",
      "Epoch 189/200, Iteration 120/250, Loss: 0.0208\n",
      "Epoch 189/200, Iteration 121/250, Loss: 0.0246\n",
      "Epoch 189/200, Iteration 122/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 123/250, Loss: 0.0109\n",
      "Epoch 189/200, Iteration 124/250, Loss: 0.0115\n",
      "Epoch 189/200, Iteration 125/250, Loss: 0.0098\n",
      "Epoch 189/200, Iteration 126/250, Loss: 0.0322\n",
      "Epoch 189/200, Iteration 127/250, Loss: 0.0303\n",
      "Epoch 189/200, Iteration 128/250, Loss: 0.0223\n",
      "Epoch 189/200, Iteration 129/250, Loss: 0.0124\n",
      "Epoch 189/200, Iteration 130/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 131/250, Loss: 0.0069\n",
      "Epoch 189/200, Iteration 132/250, Loss: 0.0185\n",
      "Epoch 189/200, Iteration 133/250, Loss: 0.0106\n",
      "Epoch 189/200, Iteration 134/250, Loss: 0.0195\n",
      "Epoch 189/200, Iteration 135/250, Loss: 0.0418\n",
      "Epoch 189/200, Iteration 136/250, Loss: 0.0181\n",
      "Epoch 189/200, Iteration 137/250, Loss: 0.0213\n",
      "Epoch 189/200, Iteration 138/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 139/250, Loss: 0.0206\n",
      "Epoch 189/200, Iteration 140/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 141/250, Loss: 0.0062\n",
      "Epoch 189/200, Iteration 142/250, Loss: 0.0187\n",
      "Epoch 189/200, Iteration 143/250, Loss: 0.0088\n",
      "Epoch 189/200, Iteration 144/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 145/250, Loss: 0.0071\n",
      "Epoch 189/200, Iteration 146/250, Loss: 0.0088\n",
      "Epoch 189/200, Iteration 147/250, Loss: 0.0150\n",
      "Epoch 189/200, Iteration 148/250, Loss: 0.0209\n",
      "Epoch 189/200, Iteration 149/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 150/250, Loss: 0.0189\n",
      "Epoch 189/200, Iteration 151/250, Loss: 0.0256\n",
      "Epoch 189/200, Iteration 152/250, Loss: 0.0149\n",
      "Epoch 189/200, Iteration 153/250, Loss: 0.0096\n",
      "Epoch 189/200, Iteration 154/250, Loss: 0.0093\n",
      "Epoch 189/200, Iteration 155/250, Loss: 0.0116\n",
      "Epoch 189/200, Iteration 156/250, Loss: 0.0126\n",
      "Epoch 189/200, Iteration 157/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 158/250, Loss: 0.0100\n",
      "Epoch 189/200, Iteration 159/250, Loss: 0.0098\n",
      "Epoch 189/200, Iteration 160/250, Loss: 0.0188\n",
      "Epoch 189/200, Iteration 161/250, Loss: 0.0092\n",
      "Epoch 189/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 189/200, Iteration 163/250, Loss: 0.0120\n",
      "Epoch 189/200, Iteration 164/250, Loss: 0.0087\n",
      "Epoch 189/200, Iteration 165/250, Loss: 0.0082\n",
      "Epoch 189/200, Iteration 166/250, Loss: 0.0246\n",
      "Epoch 189/200, Iteration 167/250, Loss: 0.0093\n",
      "Epoch 189/200, Iteration 168/250, Loss: 0.0073\n",
      "Epoch 189/200, Iteration 169/250, Loss: 0.0074\n",
      "Epoch 189/200, Iteration 170/250, Loss: 0.0070\n",
      "Epoch 189/200, Iteration 171/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 172/250, Loss: 0.0157\n",
      "Epoch 189/200, Iteration 173/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 174/250, Loss: 0.0077\n",
      "Epoch 189/200, Iteration 175/250, Loss: 0.0475\n",
      "Epoch 189/200, Iteration 176/250, Loss: 0.0197\n",
      "Epoch 189/200, Iteration 177/250, Loss: 0.0095\n",
      "Epoch 189/200, Iteration 178/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 179/250, Loss: 0.0375\n",
      "Epoch 189/200, Iteration 180/250, Loss: 0.0153\n",
      "Epoch 189/200, Iteration 181/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 182/250, Loss: 0.0228\n",
      "Epoch 189/200, Iteration 183/250, Loss: 0.0154\n",
      "Epoch 189/200, Iteration 184/250, Loss: 0.0156\n",
      "Epoch 189/200, Iteration 185/250, Loss: 0.0092\n",
      "Epoch 189/200, Iteration 186/250, Loss: 0.0069\n",
      "Epoch 189/200, Iteration 187/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 188/250, Loss: 0.0152\n",
      "Epoch 189/200, Iteration 189/250, Loss: 0.0165\n",
      "Epoch 189/200, Iteration 190/250, Loss: 0.0218\n",
      "Epoch 189/200, Iteration 191/250, Loss: 0.0075\n",
      "Epoch 189/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 193/250, Loss: 0.0148\n",
      "Epoch 189/200, Iteration 194/250, Loss: 0.0119\n",
      "Epoch 189/200, Iteration 195/250, Loss: 0.0120\n",
      "Epoch 189/200, Iteration 196/250, Loss: 0.0125\n",
      "Epoch 189/200, Iteration 197/250, Loss: 0.0153\n",
      "Epoch 189/200, Iteration 198/250, Loss: 0.0137\n",
      "Epoch 189/200, Iteration 199/250, Loss: 0.0280\n",
      "Epoch 189/200, Iteration 200/250, Loss: 0.0099\n",
      "Epoch 189/200, Iteration 201/250, Loss: 0.0376\n",
      "Epoch 189/200, Iteration 202/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 203/250, Loss: 0.0129\n",
      "Epoch 189/200, Iteration 204/250, Loss: 0.0083\n",
      "Epoch 189/200, Iteration 205/250, Loss: 0.0118\n",
      "Epoch 189/200, Iteration 206/250, Loss: 0.0146\n",
      "Epoch 189/200, Iteration 207/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 208/250, Loss: 0.0218\n",
      "Epoch 189/200, Iteration 209/250, Loss: 0.0220\n",
      "Epoch 189/200, Iteration 210/250, Loss: 0.0276\n",
      "Epoch 189/200, Iteration 211/250, Loss: 0.0102\n",
      "Epoch 189/200, Iteration 212/250, Loss: 0.0089\n",
      "Epoch 189/200, Iteration 213/250, Loss: 0.0092\n",
      "Epoch 189/200, Iteration 214/250, Loss: 0.0186\n",
      "Epoch 189/200, Iteration 215/250, Loss: 0.0094\n",
      "Epoch 189/200, Iteration 216/250, Loss: 0.0235\n",
      "Epoch 189/200, Iteration 217/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 218/250, Loss: 0.0150\n",
      "Epoch 189/200, Iteration 219/250, Loss: 0.0122\n",
      "Epoch 189/200, Iteration 220/250, Loss: 0.0145\n",
      "Epoch 189/200, Iteration 221/250, Loss: 0.0185\n",
      "Epoch 189/200, Iteration 222/250, Loss: 0.0208\n",
      "Epoch 189/200, Iteration 223/250, Loss: 0.0196\n",
      "Epoch 189/200, Iteration 224/250, Loss: 0.0235\n",
      "Epoch 189/200, Iteration 225/250, Loss: 0.0135\n",
      "Epoch 189/200, Iteration 226/250, Loss: 0.0120\n",
      "Epoch 189/200, Iteration 227/250, Loss: 0.0277\n",
      "Epoch 189/200, Iteration 228/250, Loss: 0.0158\n",
      "Epoch 189/200, Iteration 229/250, Loss: 0.0123\n",
      "Epoch 189/200, Iteration 230/250, Loss: 0.0090\n",
      "Epoch 189/200, Iteration 231/250, Loss: 0.0214\n",
      "Epoch 189/200, Iteration 232/250, Loss: 0.0079\n",
      "Epoch 189/200, Iteration 233/250, Loss: 0.0061\n",
      "Epoch 189/200, Iteration 234/250, Loss: 0.0203\n",
      "Epoch 189/200, Iteration 235/250, Loss: 0.0155\n",
      "Epoch 189/200, Iteration 236/250, Loss: 0.0155\n",
      "Epoch 189/200, Iteration 237/250, Loss: 0.0206\n",
      "Epoch 189/200, Iteration 238/250, Loss: 0.0107\n",
      "Epoch 189/200, Iteration 239/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 240/250, Loss: 0.0127\n",
      "Epoch 189/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 189/200, Iteration 242/250, Loss: 0.0191\n",
      "Epoch 189/200, Iteration 243/250, Loss: 0.0180\n",
      "Epoch 189/200, Iteration 244/250, Loss: 0.0098\n",
      "Epoch 189/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 189/200, Iteration 246/250, Loss: 0.0113\n",
      "Epoch 189/200, Iteration 247/250, Loss: 0.0210\n",
      "Epoch 189/200, Iteration 248/250, Loss: 0.0130\n",
      "Epoch 189/200, Iteration 249/250, Loss: 0.0326\n",
      "Epoch 189/200, Iteration 250/250, Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 91.34%, Avg loss: 0.006892, MRE: 0.445754 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.05%, Avg loss: 0.007441, MRE: 0.526264 \n",
      "\n",
      "Epoch 190/200, Iteration 1/250, Loss: 0.0207\n",
      "Epoch 190/200, Iteration 2/250, Loss: 0.0137\n",
      "Epoch 190/200, Iteration 3/250, Loss: 0.0247\n",
      "Epoch 190/200, Iteration 4/250, Loss: 0.0110\n",
      "Epoch 190/200, Iteration 5/250, Loss: 0.0099\n",
      "Epoch 190/200, Iteration 6/250, Loss: 0.0206\n",
      "Epoch 190/200, Iteration 7/250, Loss: 0.0122\n",
      "Epoch 190/200, Iteration 8/250, Loss: 0.0245\n",
      "Epoch 190/200, Iteration 9/250, Loss: 0.0081\n",
      "Epoch 190/200, Iteration 10/250, Loss: 0.0193\n",
      "Epoch 190/200, Iteration 11/250, Loss: 0.0342\n",
      "Epoch 190/200, Iteration 12/250, Loss: 0.0249\n",
      "Epoch 190/200, Iteration 13/250, Loss: 0.0117\n",
      "Epoch 190/200, Iteration 14/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 15/250, Loss: 0.0138\n",
      "Epoch 190/200, Iteration 16/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 17/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 18/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 19/250, Loss: 0.0168\n",
      "Epoch 190/200, Iteration 20/250, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 21/250, Loss: 0.0097\n",
      "Epoch 190/200, Iteration 22/250, Loss: 0.0147\n",
      "Epoch 190/200, Iteration 23/250, Loss: 0.0104\n",
      "Epoch 190/200, Iteration 24/250, Loss: 0.0079\n",
      "Epoch 190/200, Iteration 25/250, Loss: 0.0340\n",
      "Epoch 190/200, Iteration 26/250, Loss: 0.0189\n",
      "Epoch 190/200, Iteration 27/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 28/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 29/250, Loss: 0.0234\n",
      "Epoch 190/200, Iteration 30/250, Loss: 0.0142\n",
      "Epoch 190/200, Iteration 31/250, Loss: 0.0166\n",
      "Epoch 190/200, Iteration 32/250, Loss: 0.0086\n",
      "Epoch 190/200, Iteration 33/250, Loss: 0.0124\n",
      "Epoch 190/200, Iteration 34/250, Loss: 0.0110\n",
      "Epoch 190/200, Iteration 35/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 36/250, Loss: 0.0301\n",
      "Epoch 190/200, Iteration 37/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 38/250, Loss: 0.0219\n",
      "Epoch 190/200, Iteration 39/250, Loss: 0.0262\n",
      "Epoch 190/200, Iteration 40/250, Loss: 0.0341\n",
      "Epoch 190/200, Iteration 41/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 42/250, Loss: 0.0106\n",
      "Epoch 190/200, Iteration 43/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 44/250, Loss: 0.0097\n",
      "Epoch 190/200, Iteration 45/250, Loss: 0.0099\n",
      "Epoch 190/200, Iteration 46/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 47/250, Loss: 0.0132\n",
      "Epoch 190/200, Iteration 48/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 49/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 50/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 51/250, Loss: 0.0109\n",
      "Epoch 190/200, Iteration 52/250, Loss: 0.0125\n",
      "Epoch 190/200, Iteration 53/250, Loss: 0.0101\n",
      "Epoch 190/200, Iteration 54/250, Loss: 0.0194\n",
      "Epoch 190/200, Iteration 55/250, Loss: 0.0106\n",
      "Epoch 190/200, Iteration 56/250, Loss: 0.0100\n",
      "Epoch 190/200, Iteration 57/250, Loss: 0.0374\n",
      "Epoch 190/200, Iteration 58/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 59/250, Loss: 0.0118\n",
      "Epoch 190/200, Iteration 60/250, Loss: 0.0110\n",
      "Epoch 190/200, Iteration 61/250, Loss: 0.0122\n",
      "Epoch 190/200, Iteration 62/250, Loss: 0.0146\n",
      "Epoch 190/200, Iteration 63/250, Loss: 0.0118\n",
      "Epoch 190/200, Iteration 64/250, Loss: 0.0227\n",
      "Epoch 190/200, Iteration 65/250, Loss: 0.0273\n",
      "Epoch 190/200, Iteration 66/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 67/250, Loss: 0.0124\n",
      "Epoch 190/200, Iteration 68/250, Loss: 0.0162\n",
      "Epoch 190/200, Iteration 69/250, Loss: 0.0168\n",
      "Epoch 190/200, Iteration 70/250, Loss: 0.0216\n",
      "Epoch 190/200, Iteration 71/250, Loss: 0.0166\n",
      "Epoch 190/200, Iteration 72/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 73/250, Loss: 0.0108\n",
      "Epoch 190/200, Iteration 74/250, Loss: 0.0263\n",
      "Epoch 190/200, Iteration 75/250, Loss: 0.0198\n",
      "Epoch 190/200, Iteration 76/250, Loss: 0.0244\n",
      "Epoch 190/200, Iteration 77/250, Loss: 0.0109\n",
      "Epoch 190/200, Iteration 78/250, Loss: 0.0092\n",
      "Epoch 190/200, Iteration 79/250, Loss: 0.0340\n",
      "Epoch 190/200, Iteration 80/250, Loss: 0.0237\n",
      "Epoch 190/200, Iteration 81/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 82/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 83/250, Loss: 0.0173\n",
      "Epoch 190/200, Iteration 84/250, Loss: 0.0279\n",
      "Epoch 190/200, Iteration 85/250, Loss: 0.0128\n",
      "Epoch 190/200, Iteration 86/250, Loss: 0.0146\n",
      "Epoch 190/200, Iteration 87/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 88/250, Loss: 0.0090\n",
      "Epoch 190/200, Iteration 89/250, Loss: 0.0286\n",
      "Epoch 190/200, Iteration 90/250, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 91/250, Loss: 0.0090\n",
      "Epoch 190/200, Iteration 92/250, Loss: 0.0111\n",
      "Epoch 190/200, Iteration 93/250, Loss: 0.0073\n",
      "Epoch 190/200, Iteration 94/250, Loss: 0.0071\n",
      "Epoch 190/200, Iteration 95/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 96/250, Loss: 0.0095\n",
      "Epoch 190/200, Iteration 97/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 98/250, Loss: 0.0154\n",
      "Epoch 190/200, Iteration 99/250, Loss: 0.0079\n",
      "Epoch 190/200, Iteration 100/250, Loss: 0.0102\n",
      "Epoch 190/200, Iteration 101/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 102/250, Loss: 0.0238\n",
      "Epoch 190/200, Iteration 103/250, Loss: 0.0107\n",
      "Epoch 190/200, Iteration 104/250, Loss: 0.0230\n",
      "Epoch 190/200, Iteration 105/250, Loss: 0.0213\n",
      "Epoch 190/200, Iteration 106/250, Loss: 0.0257\n",
      "Epoch 190/200, Iteration 107/250, Loss: 0.0100\n",
      "Epoch 190/200, Iteration 108/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 109/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 110/250, Loss: 0.0366\n",
      "Epoch 190/200, Iteration 111/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 112/250, Loss: 0.0243\n",
      "Epoch 190/200, Iteration 113/250, Loss: 0.0170\n",
      "Epoch 190/200, Iteration 114/250, Loss: 0.0163\n",
      "Epoch 190/200, Iteration 115/250, Loss: 0.0153\n",
      "Epoch 190/200, Iteration 116/250, Loss: 0.0258\n",
      "Epoch 190/200, Iteration 117/250, Loss: 0.0199\n",
      "Epoch 190/200, Iteration 118/250, Loss: 0.0119\n",
      "Epoch 190/200, Iteration 119/250, Loss: 0.0147\n",
      "Epoch 190/200, Iteration 120/250, Loss: 0.0172\n",
      "Epoch 190/200, Iteration 121/250, Loss: 0.0187\n",
      "Epoch 190/200, Iteration 122/250, Loss: 0.0088\n",
      "Epoch 190/200, Iteration 123/250, Loss: 0.0311\n",
      "Epoch 190/200, Iteration 124/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 125/250, Loss: 0.0338\n",
      "Epoch 190/200, Iteration 126/250, Loss: 0.0093\n",
      "Epoch 190/200, Iteration 127/250, Loss: 0.0227\n",
      "Epoch 190/200, Iteration 128/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 129/250, Loss: 0.0102\n",
      "Epoch 190/200, Iteration 130/250, Loss: 0.0116\n",
      "Epoch 190/200, Iteration 131/250, Loss: 0.0235\n",
      "Epoch 190/200, Iteration 132/250, Loss: 0.0178\n",
      "Epoch 190/200, Iteration 133/250, Loss: 0.0193\n",
      "Epoch 190/200, Iteration 134/250, Loss: 0.0275\n",
      "Epoch 190/200, Iteration 135/250, Loss: 0.0170\n",
      "Epoch 190/200, Iteration 136/250, Loss: 0.0191\n",
      "Epoch 190/200, Iteration 137/250, Loss: 0.0097\n",
      "Epoch 190/200, Iteration 138/250, Loss: 0.0238\n",
      "Epoch 190/200, Iteration 139/250, Loss: 0.0219\n",
      "Epoch 190/200, Iteration 140/250, Loss: 0.0260\n",
      "Epoch 190/200, Iteration 141/250, Loss: 0.0070\n",
      "Epoch 190/200, Iteration 142/250, Loss: 0.0209\n",
      "Epoch 190/200, Iteration 143/250, Loss: 0.0114\n",
      "Epoch 190/200, Iteration 144/250, Loss: 0.0137\n",
      "Epoch 190/200, Iteration 145/250, Loss: 0.0156\n",
      "Epoch 190/200, Iteration 146/250, Loss: 0.0073\n",
      "Epoch 190/200, Iteration 147/250, Loss: 0.0144\n",
      "Epoch 190/200, Iteration 148/250, Loss: 0.0078\n",
      "Epoch 190/200, Iteration 149/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 150/250, Loss: 0.0198\n",
      "Epoch 190/200, Iteration 151/250, Loss: 0.0140\n",
      "Epoch 190/200, Iteration 152/250, Loss: 0.0083\n",
      "Epoch 190/200, Iteration 153/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 154/250, Loss: 0.0137\n",
      "Epoch 190/200, Iteration 155/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 156/250, Loss: 0.0149\n",
      "Epoch 190/200, Iteration 157/250, Loss: 0.0206\n",
      "Epoch 190/200, Iteration 158/250, Loss: 0.0206\n",
      "Epoch 190/200, Iteration 159/250, Loss: 0.0338\n",
      "Epoch 190/200, Iteration 160/250, Loss: 0.0103\n",
      "Epoch 190/200, Iteration 161/250, Loss: 0.0092\n",
      "Epoch 190/200, Iteration 162/250, Loss: 0.0076\n",
      "Epoch 190/200, Iteration 163/250, Loss: 0.0130\n",
      "Epoch 190/200, Iteration 164/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 165/250, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 166/250, Loss: 0.0062\n",
      "Epoch 190/200, Iteration 167/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 168/250, Loss: 0.0303\n",
      "Epoch 190/200, Iteration 169/250, Loss: 0.0112\n",
      "Epoch 190/200, Iteration 170/250, Loss: 0.0102\n",
      "Epoch 190/200, Iteration 171/250, Loss: 0.0160\n",
      "Epoch 190/200, Iteration 172/250, Loss: 0.0168\n",
      "Epoch 190/200, Iteration 173/250, Loss: 0.0160\n",
      "Epoch 190/200, Iteration 174/250, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200, Iteration 175/250, Loss: 0.0165\n",
      "Epoch 190/200, Iteration 176/250, Loss: 0.0101\n",
      "Epoch 190/200, Iteration 177/250, Loss: 0.0122\n",
      "Epoch 190/200, Iteration 178/250, Loss: 0.0149\n",
      "Epoch 190/200, Iteration 179/250, Loss: 0.0091\n",
      "Epoch 190/200, Iteration 180/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 181/250, Loss: 0.0137\n",
      "Epoch 190/200, Iteration 182/250, Loss: 0.0075\n",
      "Epoch 190/200, Iteration 183/250, Loss: 0.0311\n",
      "Epoch 190/200, Iteration 184/250, Loss: 0.0106\n",
      "Epoch 190/200, Iteration 185/250, Loss: 0.0192\n",
      "Epoch 190/200, Iteration 186/250, Loss: 0.0181\n",
      "Epoch 190/200, Iteration 187/250, Loss: 0.0113\n",
      "Epoch 190/200, Iteration 188/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 189/250, Loss: 0.0173\n",
      "Epoch 190/200, Iteration 190/250, Loss: 0.0192\n",
      "Epoch 190/200, Iteration 191/250, Loss: 0.0192\n",
      "Epoch 190/200, Iteration 192/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 193/250, Loss: 0.0126\n",
      "Epoch 190/200, Iteration 194/250, Loss: 0.0109\n",
      "Epoch 190/200, Iteration 195/250, Loss: 0.0179\n",
      "Epoch 190/200, Iteration 196/250, Loss: 0.0147\n",
      "Epoch 190/200, Iteration 197/250, Loss: 0.0184\n",
      "Epoch 190/200, Iteration 198/250, Loss: 0.0168\n",
      "Epoch 190/200, Iteration 199/250, Loss: 0.0127\n",
      "Epoch 190/200, Iteration 200/250, Loss: 0.0253\n",
      "Epoch 190/200, Iteration 201/250, Loss: 0.0241\n",
      "Epoch 190/200, Iteration 202/250, Loss: 0.0195\n",
      "Epoch 190/200, Iteration 203/250, Loss: 0.0225\n",
      "Epoch 190/200, Iteration 204/250, Loss: 0.0132\n",
      "Epoch 190/200, Iteration 205/250, Loss: 0.0277\n",
      "Epoch 190/200, Iteration 206/250, Loss: 0.0136\n",
      "Epoch 190/200, Iteration 207/250, Loss: 0.0110\n",
      "Epoch 190/200, Iteration 208/250, Loss: 0.0162\n",
      "Epoch 190/200, Iteration 209/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 210/250, Loss: 0.0202\n",
      "Epoch 190/200, Iteration 211/250, Loss: 0.0121\n",
      "Epoch 190/200, Iteration 212/250, Loss: 0.0105\n",
      "Epoch 190/200, Iteration 213/250, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 214/250, Loss: 0.0117\n",
      "Epoch 190/200, Iteration 215/250, Loss: 0.0171\n",
      "Epoch 190/200, Iteration 216/250, Loss: 0.0203\n",
      "Epoch 190/200, Iteration 217/250, Loss: 0.0096\n",
      "Epoch 190/200, Iteration 218/250, Loss: 0.0129\n",
      "Epoch 190/200, Iteration 219/250, Loss: 0.0166\n",
      "Epoch 190/200, Iteration 220/250, Loss: 0.0244\n",
      "Epoch 190/200, Iteration 221/250, Loss: 0.0161\n",
      "Epoch 190/200, Iteration 222/250, Loss: 0.0153\n",
      "Epoch 190/200, Iteration 223/250, Loss: 0.0230\n",
      "Epoch 190/200, Iteration 224/250, Loss: 0.0158\n",
      "Epoch 190/200, Iteration 225/250, Loss: 0.0167\n",
      "Epoch 190/200, Iteration 226/250, Loss: 0.0253\n",
      "Epoch 190/200, Iteration 227/250, Loss: 0.0167\n",
      "Epoch 190/200, Iteration 228/250, Loss: 0.0084\n",
      "Epoch 190/200, Iteration 229/250, Loss: 0.0151\n",
      "Epoch 190/200, Iteration 230/250, Loss: 0.0124\n",
      "Epoch 190/200, Iteration 231/250, Loss: 0.0405\n",
      "Epoch 190/200, Iteration 232/250, Loss: 0.0094\n",
      "Epoch 190/200, Iteration 233/250, Loss: 0.0165\n",
      "Epoch 190/200, Iteration 234/250, Loss: 0.0099\n",
      "Epoch 190/200, Iteration 235/250, Loss: 0.0075\n",
      "Epoch 190/200, Iteration 236/250, Loss: 0.0123\n",
      "Epoch 190/200, Iteration 237/250, Loss: 0.0075\n",
      "Epoch 190/200, Iteration 238/250, Loss: 0.0135\n",
      "Epoch 190/200, Iteration 239/250, Loss: 0.0080\n",
      "Epoch 190/200, Iteration 240/250, Loss: 0.0120\n",
      "Epoch 190/200, Iteration 241/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 242/250, Loss: 0.0086\n",
      "Epoch 190/200, Iteration 243/250, Loss: 0.0095\n",
      "Epoch 190/200, Iteration 244/250, Loss: 0.0309\n",
      "Epoch 190/200, Iteration 245/250, Loss: 0.0134\n",
      "Epoch 190/200, Iteration 246/250, Loss: 0.0105\n",
      "Epoch 190/200, Iteration 247/250, Loss: 0.0148\n",
      "Epoch 190/200, Iteration 248/250, Loss: 0.0099\n",
      "Epoch 190/200, Iteration 249/250, Loss: 0.0082\n",
      "Epoch 190/200, Iteration 250/250, Loss: 0.0141\n",
      "Train Error: \n",
      " Accuracy: 88.42%, Avg loss: 0.006691, MRE: 0.467504 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.65%, Avg loss: 0.007287, MRE: 0.513341 \n",
      "\n",
      "Epoch 191/200, Iteration 1/250, Loss: 0.0369\n",
      "Epoch 191/200, Iteration 2/250, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 3/250, Loss: 0.0104\n",
      "Epoch 191/200, Iteration 4/250, Loss: 0.0161\n",
      "Epoch 191/200, Iteration 5/250, Loss: 0.0105\n",
      "Epoch 191/200, Iteration 6/250, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 7/250, Loss: 0.0071\n",
      "Epoch 191/200, Iteration 8/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 9/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 10/250, Loss: 0.0166\n",
      "Epoch 191/200, Iteration 11/250, Loss: 0.0189\n",
      "Epoch 191/200, Iteration 12/250, Loss: 0.0095\n",
      "Epoch 191/200, Iteration 13/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 14/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 15/250, Loss: 0.0092\n",
      "Epoch 191/200, Iteration 16/250, Loss: 0.0153\n",
      "Epoch 191/200, Iteration 17/250, Loss: 0.0161\n",
      "Epoch 191/200, Iteration 18/250, Loss: 0.0092\n",
      "Epoch 191/200, Iteration 19/250, Loss: 0.0256\n",
      "Epoch 191/200, Iteration 20/250, Loss: 0.0105\n",
      "Epoch 191/200, Iteration 21/250, Loss: 0.0268\n",
      "Epoch 191/200, Iteration 22/250, Loss: 0.0091\n",
      "Epoch 191/200, Iteration 23/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 24/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 25/250, Loss: 0.0414\n",
      "Epoch 191/200, Iteration 26/250, Loss: 0.0221\n",
      "Epoch 191/200, Iteration 27/250, Loss: 0.0129\n",
      "Epoch 191/200, Iteration 28/250, Loss: 0.0102\n",
      "Epoch 191/200, Iteration 29/250, Loss: 0.0189\n",
      "Epoch 191/200, Iteration 30/250, Loss: 0.0074\n",
      "Epoch 191/200, Iteration 31/250, Loss: 0.0200\n",
      "Epoch 191/200, Iteration 32/250, Loss: 0.0146\n",
      "Epoch 191/200, Iteration 33/250, Loss: 0.0130\n",
      "Epoch 191/200, Iteration 34/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 35/250, Loss: 0.0154\n",
      "Epoch 191/200, Iteration 36/250, Loss: 0.0186\n",
      "Epoch 191/200, Iteration 37/250, Loss: 0.0229\n",
      "Epoch 191/200, Iteration 38/250, Loss: 0.0309\n",
      "Epoch 191/200, Iteration 39/250, Loss: 0.0210\n",
      "Epoch 191/200, Iteration 40/250, Loss: 0.0337\n",
      "Epoch 191/200, Iteration 41/250, Loss: 0.0136\n",
      "Epoch 191/200, Iteration 42/250, Loss: 0.0161\n",
      "Epoch 191/200, Iteration 43/250, Loss: 0.0082\n",
      "Epoch 191/200, Iteration 44/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 45/250, Loss: 0.0334\n",
      "Epoch 191/200, Iteration 46/250, Loss: 0.0220\n",
      "Epoch 191/200, Iteration 47/250, Loss: 0.0116\n",
      "Epoch 191/200, Iteration 48/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 49/250, Loss: 0.0231\n",
      "Epoch 191/200, Iteration 50/250, Loss: 0.0102\n",
      "Epoch 191/200, Iteration 51/250, Loss: 0.0424\n",
      "Epoch 191/200, Iteration 52/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 53/250, Loss: 0.0191\n",
      "Epoch 191/200, Iteration 54/250, Loss: 0.0158\n",
      "Epoch 191/200, Iteration 55/250, Loss: 0.0085\n",
      "Epoch 191/200, Iteration 56/250, Loss: 0.0064\n",
      "Epoch 191/200, Iteration 57/250, Loss: 0.0123\n",
      "Epoch 191/200, Iteration 58/250, Loss: 0.0309\n",
      "Epoch 191/200, Iteration 59/250, Loss: 0.0183\n",
      "Epoch 191/200, Iteration 60/250, Loss: 0.0197\n",
      "Epoch 191/200, Iteration 61/250, Loss: 0.0458\n",
      "Epoch 191/200, Iteration 62/250, Loss: 0.0127\n",
      "Epoch 191/200, Iteration 63/250, Loss: 0.0197\n",
      "Epoch 191/200, Iteration 64/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 65/250, Loss: 0.0263\n",
      "Epoch 191/200, Iteration 66/250, Loss: 0.0184\n",
      "Epoch 191/200, Iteration 67/250, Loss: 0.0102\n",
      "Epoch 191/200, Iteration 68/250, Loss: 0.0087\n",
      "Epoch 191/200, Iteration 69/250, Loss: 0.0218\n",
      "Epoch 191/200, Iteration 70/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 71/250, Loss: 0.0077\n",
      "Epoch 191/200, Iteration 72/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 73/250, Loss: 0.0089\n",
      "Epoch 191/200, Iteration 74/250, Loss: 0.0123\n",
      "Epoch 191/200, Iteration 75/250, Loss: 0.0176\n",
      "Epoch 191/200, Iteration 76/250, Loss: 0.0360\n",
      "Epoch 191/200, Iteration 77/250, Loss: 0.0312\n",
      "Epoch 191/200, Iteration 78/250, Loss: 0.0273\n",
      "Epoch 191/200, Iteration 79/250, Loss: 0.0097\n",
      "Epoch 191/200, Iteration 80/250, Loss: 0.0139\n",
      "Epoch 191/200, Iteration 81/250, Loss: 0.0213\n",
      "Epoch 191/200, Iteration 82/250, Loss: 0.0164\n",
      "Epoch 191/200, Iteration 83/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 84/250, Loss: 0.0127\n",
      "Epoch 191/200, Iteration 85/250, Loss: 0.0241\n",
      "Epoch 191/200, Iteration 86/250, Loss: 0.0232\n",
      "Epoch 191/200, Iteration 87/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 88/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 89/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 90/250, Loss: 0.0244\n",
      "Epoch 191/200, Iteration 91/250, Loss: 0.0147\n",
      "Epoch 191/200, Iteration 92/250, Loss: 0.0211\n",
      "Epoch 191/200, Iteration 93/250, Loss: 0.0111\n",
      "Epoch 191/200, Iteration 94/250, Loss: 0.0302\n",
      "Epoch 191/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 96/250, Loss: 0.0243\n",
      "Epoch 191/200, Iteration 97/250, Loss: 0.0145\n",
      "Epoch 191/200, Iteration 98/250, Loss: 0.0249\n",
      "Epoch 191/200, Iteration 99/250, Loss: 0.0167\n",
      "Epoch 191/200, Iteration 100/250, Loss: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 191/200, Iteration 102/250, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 103/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 104/250, Loss: 0.0110\n",
      "Epoch 191/200, Iteration 105/250, Loss: 0.0176\n",
      "Epoch 191/200, Iteration 106/250, Loss: 0.0091\n",
      "Epoch 191/200, Iteration 107/250, Loss: 0.0116\n",
      "Epoch 191/200, Iteration 108/250, Loss: 0.0125\n",
      "Epoch 191/200, Iteration 109/250, Loss: 0.0107\n",
      "Epoch 191/200, Iteration 110/250, Loss: 0.0145\n",
      "Epoch 191/200, Iteration 111/250, Loss: 0.0099\n",
      "Epoch 191/200, Iteration 112/250, Loss: 0.0212\n",
      "Epoch 191/200, Iteration 113/250, Loss: 0.0171\n",
      "Epoch 191/200, Iteration 114/250, Loss: 0.0353\n",
      "Epoch 191/200, Iteration 115/250, Loss: 0.0121\n",
      "Epoch 191/200, Iteration 116/250, Loss: 0.0104\n",
      "Epoch 191/200, Iteration 117/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 118/250, Loss: 0.0287\n",
      "Epoch 191/200, Iteration 119/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 120/250, Loss: 0.0105\n",
      "Epoch 191/200, Iteration 121/250, Loss: 0.0206\n",
      "Epoch 191/200, Iteration 122/250, Loss: 0.0182\n",
      "Epoch 191/200, Iteration 123/250, Loss: 0.0195\n",
      "Epoch 191/200, Iteration 124/250, Loss: 0.0131\n",
      "Epoch 191/200, Iteration 125/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 126/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 127/250, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 128/250, Loss: 0.0168\n",
      "Epoch 191/200, Iteration 129/250, Loss: 0.0103\n",
      "Epoch 191/200, Iteration 130/250, Loss: 0.0168\n",
      "Epoch 191/200, Iteration 131/250, Loss: 0.0207\n",
      "Epoch 191/200, Iteration 132/250, Loss: 0.0128\n",
      "Epoch 191/200, Iteration 133/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 134/250, Loss: 0.0297\n",
      "Epoch 191/200, Iteration 135/250, Loss: 0.0116\n",
      "Epoch 191/200, Iteration 136/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 137/250, Loss: 0.0082\n",
      "Epoch 191/200, Iteration 138/250, Loss: 0.0175\n",
      "Epoch 191/200, Iteration 139/250, Loss: 0.0141\n",
      "Epoch 191/200, Iteration 140/250, Loss: 0.0245\n",
      "Epoch 191/200, Iteration 141/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 142/250, Loss: 0.0175\n",
      "Epoch 191/200, Iteration 143/250, Loss: 0.0129\n",
      "Epoch 191/200, Iteration 144/250, Loss: 0.0105\n",
      "Epoch 191/200, Iteration 145/250, Loss: 0.0269\n",
      "Epoch 191/200, Iteration 146/250, Loss: 0.0098\n",
      "Epoch 191/200, Iteration 147/250, Loss: 0.0122\n",
      "Epoch 191/200, Iteration 148/250, Loss: 0.0079\n",
      "Epoch 191/200, Iteration 149/250, Loss: 0.0081\n",
      "Epoch 191/200, Iteration 150/250, Loss: 0.0248\n",
      "Epoch 191/200, Iteration 151/250, Loss: 0.0126\n",
      "Epoch 191/200, Iteration 152/250, Loss: 0.0314\n",
      "Epoch 191/200, Iteration 153/250, Loss: 0.0423\n",
      "Epoch 191/200, Iteration 154/250, Loss: 0.0329\n",
      "Epoch 191/200, Iteration 155/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 156/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 157/250, Loss: 0.0121\n",
      "Epoch 191/200, Iteration 158/250, Loss: 0.0090\n",
      "Epoch 191/200, Iteration 159/250, Loss: 0.0152\n",
      "Epoch 191/200, Iteration 160/250, Loss: 0.0111\n",
      "Epoch 191/200, Iteration 161/250, Loss: 0.0185\n",
      "Epoch 191/200, Iteration 162/250, Loss: 0.0143\n",
      "Epoch 191/200, Iteration 163/250, Loss: 0.0210\n",
      "Epoch 191/200, Iteration 164/250, Loss: 0.0122\n",
      "Epoch 191/200, Iteration 165/250, Loss: 0.0229\n",
      "Epoch 191/200, Iteration 166/250, Loss: 0.0179\n",
      "Epoch 191/200, Iteration 167/250, Loss: 0.0124\n",
      "Epoch 191/200, Iteration 168/250, Loss: 0.0119\n",
      "Epoch 191/200, Iteration 169/250, Loss: 0.0312\n",
      "Epoch 191/200, Iteration 170/250, Loss: 0.0072\n",
      "Epoch 191/200, Iteration 171/250, Loss: 0.0107\n",
      "Epoch 191/200, Iteration 172/250, Loss: 0.0165\n",
      "Epoch 191/200, Iteration 173/250, Loss: 0.0122\n",
      "Epoch 191/200, Iteration 174/250, Loss: 0.0337\n",
      "Epoch 191/200, Iteration 175/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 176/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 177/250, Loss: 0.0165\n",
      "Epoch 191/200, Iteration 178/250, Loss: 0.0190\n",
      "Epoch 191/200, Iteration 179/250, Loss: 0.0141\n",
      "Epoch 191/200, Iteration 180/250, Loss: 0.0170\n",
      "Epoch 191/200, Iteration 181/250, Loss: 0.0165\n",
      "Epoch 191/200, Iteration 182/250, Loss: 0.0085\n",
      "Epoch 191/200, Iteration 183/250, Loss: 0.0171\n",
      "Epoch 191/200, Iteration 184/250, Loss: 0.0135\n",
      "Epoch 191/200, Iteration 185/250, Loss: 0.0323\n",
      "Epoch 191/200, Iteration 186/250, Loss: 0.0188\n",
      "Epoch 191/200, Iteration 187/250, Loss: 0.0074\n",
      "Epoch 191/200, Iteration 188/250, Loss: 0.0317\n",
      "Epoch 191/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 190/250, Loss: 0.0154\n",
      "Epoch 191/200, Iteration 191/250, Loss: 0.0157\n",
      "Epoch 191/200, Iteration 192/250, Loss: 0.0450\n",
      "Epoch 191/200, Iteration 193/250, Loss: 0.0152\n",
      "Epoch 191/200, Iteration 194/250, Loss: 0.0094\n",
      "Epoch 191/200, Iteration 195/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 196/250, Loss: 0.0077\n",
      "Epoch 191/200, Iteration 197/250, Loss: 0.0133\n",
      "Epoch 191/200, Iteration 198/250, Loss: 0.0134\n",
      "Epoch 191/200, Iteration 199/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 200/250, Loss: 0.0088\n",
      "Epoch 191/200, Iteration 201/250, Loss: 0.0127\n",
      "Epoch 191/200, Iteration 202/250, Loss: 0.0143\n",
      "Epoch 191/200, Iteration 203/250, Loss: 0.0131\n",
      "Epoch 191/200, Iteration 204/250, Loss: 0.0080\n",
      "Epoch 191/200, Iteration 205/250, Loss: 0.0164\n",
      "Epoch 191/200, Iteration 206/250, Loss: 0.0248\n",
      "Epoch 191/200, Iteration 207/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 208/250, Loss: 0.0176\n",
      "Epoch 191/200, Iteration 209/250, Loss: 0.0093\n",
      "Epoch 191/200, Iteration 210/250, Loss: 0.0203\n",
      "Epoch 191/200, Iteration 211/250, Loss: 0.0216\n",
      "Epoch 191/200, Iteration 212/250, Loss: 0.0138\n",
      "Epoch 191/200, Iteration 213/250, Loss: 0.0114\n",
      "Epoch 191/200, Iteration 214/250, Loss: 0.0112\n",
      "Epoch 191/200, Iteration 215/250, Loss: 0.0081\n",
      "Epoch 191/200, Iteration 216/250, Loss: 0.0087\n",
      "Epoch 191/200, Iteration 217/250, Loss: 0.0155\n",
      "Epoch 191/200, Iteration 218/250, Loss: 0.0207\n",
      "Epoch 191/200, Iteration 219/250, Loss: 0.0270\n",
      "Epoch 191/200, Iteration 220/250, Loss: 0.0269\n",
      "Epoch 191/200, Iteration 221/250, Loss: 0.0075\n",
      "Epoch 191/200, Iteration 222/250, Loss: 0.0240\n",
      "Epoch 191/200, Iteration 223/250, Loss: 0.0108\n",
      "Epoch 191/200, Iteration 224/250, Loss: 0.0109\n",
      "Epoch 191/200, Iteration 225/250, Loss: 0.0100\n",
      "Epoch 191/200, Iteration 226/250, Loss: 0.0118\n",
      "Epoch 191/200, Iteration 227/250, Loss: 0.0113\n",
      "Epoch 191/200, Iteration 228/250, Loss: 0.0137\n",
      "Epoch 191/200, Iteration 229/250, Loss: 0.0185\n",
      "Epoch 191/200, Iteration 230/250, Loss: 0.0177\n",
      "Epoch 191/200, Iteration 231/250, Loss: 0.0158\n",
      "Epoch 191/200, Iteration 232/250, Loss: 0.0081\n",
      "Epoch 191/200, Iteration 233/250, Loss: 0.0094\n",
      "Epoch 191/200, Iteration 234/250, Loss: 0.0154\n",
      "Epoch 191/200, Iteration 235/250, Loss: 0.0073\n",
      "Epoch 191/200, Iteration 236/250, Loss: 0.0078\n",
      "Epoch 191/200, Iteration 237/250, Loss: 0.0144\n",
      "Epoch 191/200, Iteration 238/250, Loss: 0.0121\n",
      "Epoch 191/200, Iteration 239/250, Loss: 0.0120\n",
      "Epoch 191/200, Iteration 240/250, Loss: 0.0113\n",
      "Epoch 191/200, Iteration 241/250, Loss: 0.0156\n",
      "Epoch 191/200, Iteration 242/250, Loss: 0.0263\n",
      "Epoch 191/200, Iteration 243/250, Loss: 0.0084\n",
      "Epoch 191/200, Iteration 244/250, Loss: 0.0218\n",
      "Epoch 191/200, Iteration 245/250, Loss: 0.0080\n",
      "Epoch 191/200, Iteration 246/250, Loss: 0.0118\n",
      "Epoch 191/200, Iteration 247/250, Loss: 0.0117\n",
      "Epoch 191/200, Iteration 248/250, Loss: 0.0123\n",
      "Epoch 191/200, Iteration 249/250, Loss: 0.0283\n",
      "Epoch 191/200, Iteration 250/250, Loss: 0.0227\n",
      "Train Error: \n",
      " Accuracy: 88.48%, Avg loss: 0.006751, MRE: 0.451740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.65%, Avg loss: 0.007325, MRE: 0.534642 \n",
      "\n",
      "Epoch 192/200, Iteration 1/250, Loss: 0.0406\n",
      "Epoch 192/200, Iteration 2/250, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 3/250, Loss: 0.0084\n",
      "Epoch 192/200, Iteration 4/250, Loss: 0.0216\n",
      "Epoch 192/200, Iteration 5/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 6/250, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 7/250, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 8/250, Loss: 0.0214\n",
      "Epoch 192/200, Iteration 9/250, Loss: 0.0127\n",
      "Epoch 192/200, Iteration 10/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 11/250, Loss: 0.0074\n",
      "Epoch 192/200, Iteration 12/250, Loss: 0.0079\n",
      "Epoch 192/200, Iteration 13/250, Loss: 0.0105\n",
      "Epoch 192/200, Iteration 14/250, Loss: 0.0192\n",
      "Epoch 192/200, Iteration 15/250, Loss: 0.0131\n",
      "Epoch 192/200, Iteration 16/250, Loss: 0.0182\n",
      "Epoch 192/200, Iteration 17/250, Loss: 0.0080\n",
      "Epoch 192/200, Iteration 18/250, Loss: 0.0125\n",
      "Epoch 192/200, Iteration 19/250, Loss: 0.0276\n",
      "Epoch 192/200, Iteration 20/250, Loss: 0.0160\n",
      "Epoch 192/200, Iteration 21/250, Loss: 0.0307\n",
      "Epoch 192/200, Iteration 22/250, Loss: 0.0111\n",
      "Epoch 192/200, Iteration 23/250, Loss: 0.0154\n",
      "Epoch 192/200, Iteration 24/250, Loss: 0.0180\n",
      "Epoch 192/200, Iteration 25/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 26/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 27/250, Loss: 0.0255\n",
      "Epoch 192/200, Iteration 28/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 29/250, Loss: 0.0269\n",
      "Epoch 192/200, Iteration 30/250, Loss: 0.0205\n",
      "Epoch 192/200, Iteration 31/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 32/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 33/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 34/250, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200, Iteration 35/250, Loss: 0.0221\n",
      "Epoch 192/200, Iteration 36/250, Loss: 0.0151\n",
      "Epoch 192/200, Iteration 37/250, Loss: 0.0214\n",
      "Epoch 192/200, Iteration 38/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 39/250, Loss: 0.0212\n",
      "Epoch 192/200, Iteration 40/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 41/250, Loss: 0.0170\n",
      "Epoch 192/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 192/200, Iteration 43/250, Loss: 0.0263\n",
      "Epoch 192/200, Iteration 44/250, Loss: 0.0155\n",
      "Epoch 192/200, Iteration 45/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 46/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 47/250, Loss: 0.0312\n",
      "Epoch 192/200, Iteration 48/250, Loss: 0.0201\n",
      "Epoch 192/200, Iteration 49/250, Loss: 0.0253\n",
      "Epoch 192/200, Iteration 50/250, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 51/250, Loss: 0.0127\n",
      "Epoch 192/200, Iteration 52/250, Loss: 0.0115\n",
      "Epoch 192/200, Iteration 53/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 54/250, Loss: 0.0314\n",
      "Epoch 192/200, Iteration 55/250, Loss: 0.0146\n",
      "Epoch 192/200, Iteration 56/250, Loss: 0.0072\n",
      "Epoch 192/200, Iteration 57/250, Loss: 0.0334\n",
      "Epoch 192/200, Iteration 58/250, Loss: 0.0090\n",
      "Epoch 192/200, Iteration 59/250, Loss: 0.0241\n",
      "Epoch 192/200, Iteration 60/250, Loss: 0.0166\n",
      "Epoch 192/200, Iteration 61/250, Loss: 0.0188\n",
      "Epoch 192/200, Iteration 62/250, Loss: 0.0255\n",
      "Epoch 192/200, Iteration 63/250, Loss: 0.0152\n",
      "Epoch 192/200, Iteration 64/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 65/250, Loss: 0.0171\n",
      "Epoch 192/200, Iteration 66/250, Loss: 0.0282\n",
      "Epoch 192/200, Iteration 67/250, Loss: 0.0111\n",
      "Epoch 192/200, Iteration 68/250, Loss: 0.0074\n",
      "Epoch 192/200, Iteration 69/250, Loss: 0.0369\n",
      "Epoch 192/200, Iteration 70/250, Loss: 0.0153\n",
      "Epoch 192/200, Iteration 71/250, Loss: 0.0185\n",
      "Epoch 192/200, Iteration 72/250, Loss: 0.0330\n",
      "Epoch 192/200, Iteration 73/250, Loss: 0.0076\n",
      "Epoch 192/200, Iteration 74/250, Loss: 0.0173\n",
      "Epoch 192/200, Iteration 75/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 76/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 77/250, Loss: 0.0154\n",
      "Epoch 192/200, Iteration 78/250, Loss: 0.0361\n",
      "Epoch 192/200, Iteration 79/250, Loss: 0.0130\n",
      "Epoch 192/200, Iteration 80/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 81/250, Loss: 0.0142\n",
      "Epoch 192/200, Iteration 82/250, Loss: 0.0260\n",
      "Epoch 192/200, Iteration 83/250, Loss: 0.0158\n",
      "Epoch 192/200, Iteration 84/250, Loss: 0.0116\n",
      "Epoch 192/200, Iteration 85/250, Loss: 0.0247\n",
      "Epoch 192/200, Iteration 86/250, Loss: 0.0155\n",
      "Epoch 192/200, Iteration 87/250, Loss: 0.0096\n",
      "Epoch 192/200, Iteration 88/250, Loss: 0.0095\n",
      "Epoch 192/200, Iteration 89/250, Loss: 0.0123\n",
      "Epoch 192/200, Iteration 90/250, Loss: 0.0291\n",
      "Epoch 192/200, Iteration 91/250, Loss: 0.0152\n",
      "Epoch 192/200, Iteration 92/250, Loss: 0.0210\n",
      "Epoch 192/200, Iteration 93/250, Loss: 0.0109\n",
      "Epoch 192/200, Iteration 94/250, Loss: 0.0346\n",
      "Epoch 192/200, Iteration 95/250, Loss: 0.0172\n",
      "Epoch 192/200, Iteration 96/250, Loss: 0.0199\n",
      "Epoch 192/200, Iteration 97/250, Loss: 0.0188\n",
      "Epoch 192/200, Iteration 98/250, Loss: 0.0138\n",
      "Epoch 192/200, Iteration 99/250, Loss: 0.0312\n",
      "Epoch 192/200, Iteration 100/250, Loss: 0.0329\n",
      "Epoch 192/200, Iteration 101/250, Loss: 0.0253\n",
      "Epoch 192/200, Iteration 102/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 103/250, Loss: 0.0169\n",
      "Epoch 192/200, Iteration 104/250, Loss: 0.0273\n",
      "Epoch 192/200, Iteration 105/250, Loss: 0.0209\n",
      "Epoch 192/200, Iteration 106/250, Loss: 0.0164\n",
      "Epoch 192/200, Iteration 107/250, Loss: 0.0135\n",
      "Epoch 192/200, Iteration 108/250, Loss: 0.0122\n",
      "Epoch 192/200, Iteration 109/250, Loss: 0.0282\n",
      "Epoch 192/200, Iteration 110/250, Loss: 0.0157\n",
      "Epoch 192/200, Iteration 111/250, Loss: 0.0209\n",
      "Epoch 192/200, Iteration 112/250, Loss: 0.0066\n",
      "Epoch 192/200, Iteration 113/250, Loss: 0.0227\n",
      "Epoch 192/200, Iteration 114/250, Loss: 0.0206\n",
      "Epoch 192/200, Iteration 115/250, Loss: 0.0158\n",
      "Epoch 192/200, Iteration 116/250, Loss: 0.0157\n",
      "Epoch 192/200, Iteration 117/250, Loss: 0.0120\n",
      "Epoch 192/200, Iteration 118/250, Loss: 0.0108\n",
      "Epoch 192/200, Iteration 119/250, Loss: 0.0136\n",
      "Epoch 192/200, Iteration 120/250, Loss: 0.0091\n",
      "Epoch 192/200, Iteration 121/250, Loss: 0.0094\n",
      "Epoch 192/200, Iteration 122/250, Loss: 0.0261\n",
      "Epoch 192/200, Iteration 123/250, Loss: 0.0088\n",
      "Epoch 192/200, Iteration 124/250, Loss: 0.0193\n",
      "Epoch 192/200, Iteration 125/250, Loss: 0.0099\n",
      "Epoch 192/200, Iteration 126/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 127/250, Loss: 0.0084\n",
      "Epoch 192/200, Iteration 128/250, Loss: 0.0272\n",
      "Epoch 192/200, Iteration 129/250, Loss: 0.0281\n",
      "Epoch 192/200, Iteration 130/250, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 131/250, Loss: 0.0191\n",
      "Epoch 192/200, Iteration 132/250, Loss: 0.0131\n",
      "Epoch 192/200, Iteration 133/250, Loss: 0.0193\n",
      "Epoch 192/200, Iteration 134/250, Loss: 0.0228\n",
      "Epoch 192/200, Iteration 135/250, Loss: 0.0164\n",
      "Epoch 192/200, Iteration 136/250, Loss: 0.0128\n",
      "Epoch 192/200, Iteration 137/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 138/250, Loss: 0.0197\n",
      "Epoch 192/200, Iteration 139/250, Loss: 0.0085\n",
      "Epoch 192/200, Iteration 140/250, Loss: 0.0142\n",
      "Epoch 192/200, Iteration 141/250, Loss: 0.0301\n",
      "Epoch 192/200, Iteration 142/250, Loss: 0.0089\n",
      "Epoch 192/200, Iteration 143/250, Loss: 0.0165\n",
      "Epoch 192/200, Iteration 144/250, Loss: 0.0183\n",
      "Epoch 192/200, Iteration 145/250, Loss: 0.0119\n",
      "Epoch 192/200, Iteration 146/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 147/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 148/250, Loss: 0.0122\n",
      "Epoch 192/200, Iteration 149/250, Loss: 0.0183\n",
      "Epoch 192/200, Iteration 150/250, Loss: 0.0078\n",
      "Epoch 192/200, Iteration 151/250, Loss: 0.0134\n",
      "Epoch 192/200, Iteration 152/250, Loss: 0.0151\n",
      "Epoch 192/200, Iteration 153/250, Loss: 0.0063\n",
      "Epoch 192/200, Iteration 154/250, Loss: 0.0345\n",
      "Epoch 192/200, Iteration 155/250, Loss: 0.0228\n",
      "Epoch 192/200, Iteration 156/250, Loss: 0.0112\n",
      "Epoch 192/200, Iteration 157/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 158/250, Loss: 0.0118\n",
      "Epoch 192/200, Iteration 159/250, Loss: 0.0141\n",
      "Epoch 192/200, Iteration 160/250, Loss: 0.0106\n",
      "Epoch 192/200, Iteration 161/250, Loss: 0.0291\n",
      "Epoch 192/200, Iteration 162/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 163/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 164/250, Loss: 0.0113\n",
      "Epoch 192/200, Iteration 165/250, Loss: 0.0198\n",
      "Epoch 192/200, Iteration 166/250, Loss: 0.0073\n",
      "Epoch 192/200, Iteration 167/250, Loss: 0.0291\n",
      "Epoch 192/200, Iteration 168/250, Loss: 0.0332\n",
      "Epoch 192/200, Iteration 169/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 170/250, Loss: 0.0129\n",
      "Epoch 192/200, Iteration 171/250, Loss: 0.0306\n",
      "Epoch 192/200, Iteration 172/250, Loss: 0.0139\n",
      "Epoch 192/200, Iteration 173/250, Loss: 0.0088\n",
      "Epoch 192/200, Iteration 174/250, Loss: 0.0186\n",
      "Epoch 192/200, Iteration 175/250, Loss: 0.0082\n",
      "Epoch 192/200, Iteration 176/250, Loss: 0.0135\n",
      "Epoch 192/200, Iteration 177/250, Loss: 0.0223\n",
      "Epoch 192/200, Iteration 178/250, Loss: 0.0085\n",
      "Epoch 192/200, Iteration 179/250, Loss: 0.0306\n",
      "Epoch 192/200, Iteration 180/250, Loss: 0.0109\n",
      "Epoch 192/200, Iteration 181/250, Loss: 0.0292\n",
      "Epoch 192/200, Iteration 182/250, Loss: 0.0186\n",
      "Epoch 192/200, Iteration 183/250, Loss: 0.0264\n",
      "Epoch 192/200, Iteration 184/250, Loss: 0.0139\n",
      "Epoch 192/200, Iteration 185/250, Loss: 0.0068\n",
      "Epoch 192/200, Iteration 186/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 187/250, Loss: 0.0447\n",
      "Epoch 192/200, Iteration 188/250, Loss: 0.0092\n",
      "Epoch 192/200, Iteration 189/250, Loss: 0.0247\n",
      "Epoch 192/200, Iteration 190/250, Loss: 0.0180\n",
      "Epoch 192/200, Iteration 191/250, Loss: 0.0188\n",
      "Epoch 192/200, Iteration 192/250, Loss: 0.0119\n",
      "Epoch 192/200, Iteration 193/250, Loss: 0.0215\n",
      "Epoch 192/200, Iteration 194/250, Loss: 0.0274\n",
      "Epoch 192/200, Iteration 195/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 196/250, Loss: 0.0103\n",
      "Epoch 192/200, Iteration 197/250, Loss: 0.0067\n",
      "Epoch 192/200, Iteration 198/250, Loss: 0.0076\n",
      "Epoch 192/200, Iteration 199/250, Loss: 0.0147\n",
      "Epoch 192/200, Iteration 200/250, Loss: 0.0256\n",
      "Epoch 192/200, Iteration 201/250, Loss: 0.0098\n",
      "Epoch 192/200, Iteration 202/250, Loss: 0.0134\n",
      "Epoch 192/200, Iteration 203/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 204/250, Loss: 0.0125\n",
      "Epoch 192/200, Iteration 205/250, Loss: 0.0134\n",
      "Epoch 192/200, Iteration 206/250, Loss: 0.0208\n",
      "Epoch 192/200, Iteration 207/250, Loss: 0.0109\n",
      "Epoch 192/200, Iteration 208/250, Loss: 0.0156\n",
      "Epoch 192/200, Iteration 209/250, Loss: 0.0321\n",
      "Epoch 192/200, Iteration 210/250, Loss: 0.0279\n",
      "Epoch 192/200, Iteration 211/250, Loss: 0.0149\n",
      "Epoch 192/200, Iteration 212/250, Loss: 0.0210\n",
      "Epoch 192/200, Iteration 213/250, Loss: 0.0233\n",
      "Epoch 192/200, Iteration 214/250, Loss: 0.0109\n",
      "Epoch 192/200, Iteration 215/250, Loss: 0.0199\n",
      "Epoch 192/200, Iteration 216/250, Loss: 0.0081\n",
      "Epoch 192/200, Iteration 217/250, Loss: 0.0083\n",
      "Epoch 192/200, Iteration 218/250, Loss: 0.0113\n",
      "Epoch 192/200, Iteration 219/250, Loss: 0.0172\n",
      "Epoch 192/200, Iteration 220/250, Loss: 0.0248\n",
      "Epoch 192/200, Iteration 221/250, Loss: 0.0268\n",
      "Epoch 192/200, Iteration 222/250, Loss: 0.0268\n",
      "Epoch 192/200, Iteration 223/250, Loss: 0.0080\n",
      "Epoch 192/200, Iteration 224/250, Loss: 0.0142\n",
      "Epoch 192/200, Iteration 225/250, Loss: 0.0221\n",
      "Epoch 192/200, Iteration 226/250, Loss: 0.0130\n",
      "Epoch 192/200, Iteration 227/250, Loss: 0.0185\n",
      "Epoch 192/200, Iteration 228/250, Loss: 0.0339\n",
      "Epoch 192/200, Iteration 229/250, Loss: 0.0096\n",
      "Epoch 192/200, Iteration 230/250, Loss: 0.0176\n",
      "Epoch 192/200, Iteration 231/250, Loss: 0.0267\n",
      "Epoch 192/200, Iteration 232/250, Loss: 0.0124\n",
      "Epoch 192/200, Iteration 233/250, Loss: 0.0140\n",
      "Epoch 192/200, Iteration 234/250, Loss: 0.0223\n",
      "Epoch 192/200, Iteration 235/250, Loss: 0.0102\n",
      "Epoch 192/200, Iteration 236/250, Loss: 0.0230\n",
      "Epoch 192/200, Iteration 237/250, Loss: 0.0114\n",
      "Epoch 192/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 192/200, Iteration 239/250, Loss: 0.0150\n",
      "Epoch 192/200, Iteration 240/250, Loss: 0.0122\n",
      "Epoch 192/200, Iteration 241/250, Loss: 0.0104\n",
      "Epoch 192/200, Iteration 242/250, Loss: 0.0101\n",
      "Epoch 192/200, Iteration 243/250, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200, Iteration 244/250, Loss: 0.0317\n",
      "Epoch 192/200, Iteration 245/250, Loss: 0.0162\n",
      "Epoch 192/200, Iteration 246/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 247/250, Loss: 0.0110\n",
      "Epoch 192/200, Iteration 248/250, Loss: 0.0275\n",
      "Epoch 192/200, Iteration 249/250, Loss: 0.0108\n",
      "Epoch 192/200, Iteration 250/250, Loss: 0.0080\n",
      "Train Error: \n",
      " Accuracy: 93.38%, Avg loss: 0.007293, MRE: 0.470695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.007982, MRE: 0.544638 \n",
      "\n",
      "Epoch 193/200, Iteration 1/250, Loss: 0.0084\n",
      "Epoch 193/200, Iteration 2/250, Loss: 0.0183\n",
      "Epoch 193/200, Iteration 3/250, Loss: 0.0154\n",
      "Epoch 193/200, Iteration 4/250, Loss: 0.0163\n",
      "Epoch 193/200, Iteration 5/250, Loss: 0.0107\n",
      "Epoch 193/200, Iteration 6/250, Loss: 0.0188\n",
      "Epoch 193/200, Iteration 7/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 8/250, Loss: 0.0256\n",
      "Epoch 193/200, Iteration 9/250, Loss: 0.0335\n",
      "Epoch 193/200, Iteration 10/250, Loss: 0.0208\n",
      "Epoch 193/200, Iteration 11/250, Loss: 0.0210\n",
      "Epoch 193/200, Iteration 12/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 13/250, Loss: 0.0210\n",
      "Epoch 193/200, Iteration 14/250, Loss: 0.0169\n",
      "Epoch 193/200, Iteration 15/250, Loss: 0.0136\n",
      "Epoch 193/200, Iteration 16/250, Loss: 0.0249\n",
      "Epoch 193/200, Iteration 17/250, Loss: 0.0126\n",
      "Epoch 193/200, Iteration 18/250, Loss: 0.0112\n",
      "Epoch 193/200, Iteration 19/250, Loss: 0.0283\n",
      "Epoch 193/200, Iteration 20/250, Loss: 0.0250\n",
      "Epoch 193/200, Iteration 21/250, Loss: 0.0186\n",
      "Epoch 193/200, Iteration 22/250, Loss: 0.0263\n",
      "Epoch 193/200, Iteration 23/250, Loss: 0.0487\n",
      "Epoch 193/200, Iteration 24/250, Loss: 0.0303\n",
      "Epoch 193/200, Iteration 25/250, Loss: 0.0249\n",
      "Epoch 193/200, Iteration 26/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 27/250, Loss: 0.0266\n",
      "Epoch 193/200, Iteration 28/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 29/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 30/250, Loss: 0.0082\n",
      "Epoch 193/200, Iteration 31/250, Loss: 0.0261\n",
      "Epoch 193/200, Iteration 32/250, Loss: 0.0215\n",
      "Epoch 193/200, Iteration 33/250, Loss: 0.0189\n",
      "Epoch 193/200, Iteration 34/250, Loss: 0.0105\n",
      "Epoch 193/200, Iteration 35/250, Loss: 0.0078\n",
      "Epoch 193/200, Iteration 36/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 37/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 38/250, Loss: 0.0100\n",
      "Epoch 193/200, Iteration 39/250, Loss: 0.0194\n",
      "Epoch 193/200, Iteration 40/250, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 41/250, Loss: 0.0428\n",
      "Epoch 193/200, Iteration 42/250, Loss: 0.0301\n",
      "Epoch 193/200, Iteration 43/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 44/250, Loss: 0.0160\n",
      "Epoch 193/200, Iteration 45/250, Loss: 0.0399\n",
      "Epoch 193/200, Iteration 46/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 47/250, Loss: 0.0116\n",
      "Epoch 193/200, Iteration 48/250, Loss: 0.0147\n",
      "Epoch 193/200, Iteration 49/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 50/250, Loss: 0.0171\n",
      "Epoch 193/200, Iteration 51/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 52/250, Loss: 0.0219\n",
      "Epoch 193/200, Iteration 53/250, Loss: 0.0133\n",
      "Epoch 193/200, Iteration 54/250, Loss: 0.0151\n",
      "Epoch 193/200, Iteration 55/250, Loss: 0.0129\n",
      "Epoch 193/200, Iteration 56/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 57/250, Loss: 0.0075\n",
      "Epoch 193/200, Iteration 58/250, Loss: 0.0090\n",
      "Epoch 193/200, Iteration 59/250, Loss: 0.0094\n",
      "Epoch 193/200, Iteration 60/250, Loss: 0.0182\n",
      "Epoch 193/200, Iteration 61/250, Loss: 0.0171\n",
      "Epoch 193/200, Iteration 62/250, Loss: 0.0089\n",
      "Epoch 193/200, Iteration 63/250, Loss: 0.0201\n",
      "Epoch 193/200, Iteration 64/250, Loss: 0.0118\n",
      "Epoch 193/200, Iteration 65/250, Loss: 0.0167\n",
      "Epoch 193/200, Iteration 66/250, Loss: 0.0091\n",
      "Epoch 193/200, Iteration 67/250, Loss: 0.0181\n",
      "Epoch 193/200, Iteration 68/250, Loss: 0.0128\n",
      "Epoch 193/200, Iteration 69/250, Loss: 0.0256\n",
      "Epoch 193/200, Iteration 70/250, Loss: 0.0306\n",
      "Epoch 193/200, Iteration 71/250, Loss: 0.0169\n",
      "Epoch 193/200, Iteration 72/250, Loss: 0.0167\n",
      "Epoch 193/200, Iteration 73/250, Loss: 0.0135\n",
      "Epoch 193/200, Iteration 74/250, Loss: 0.0081\n",
      "Epoch 193/200, Iteration 75/250, Loss: 0.0363\n",
      "Epoch 193/200, Iteration 76/250, Loss: 0.0177\n",
      "Epoch 193/200, Iteration 77/250, Loss: 0.0079\n",
      "Epoch 193/200, Iteration 78/250, Loss: 0.0201\n",
      "Epoch 193/200, Iteration 79/250, Loss: 0.0091\n",
      "Epoch 193/200, Iteration 80/250, Loss: 0.0167\n",
      "Epoch 193/200, Iteration 81/250, Loss: 0.0132\n",
      "Epoch 193/200, Iteration 82/250, Loss: 0.0282\n",
      "Epoch 193/200, Iteration 83/250, Loss: 0.0142\n",
      "Epoch 193/200, Iteration 84/250, Loss: 0.0113\n",
      "Epoch 193/200, Iteration 85/250, Loss: 0.0188\n",
      "Epoch 193/200, Iteration 86/250, Loss: 0.0299\n",
      "Epoch 193/200, Iteration 87/250, Loss: 0.0263\n",
      "Epoch 193/200, Iteration 88/250, Loss: 0.0119\n",
      "Epoch 193/200, Iteration 89/250, Loss: 0.0163\n",
      "Epoch 193/200, Iteration 90/250, Loss: 0.0108\n",
      "Epoch 193/200, Iteration 91/250, Loss: 0.0181\n",
      "Epoch 193/200, Iteration 92/250, Loss: 0.0128\n",
      "Epoch 193/200, Iteration 93/250, Loss: 0.0183\n",
      "Epoch 193/200, Iteration 94/250, Loss: 0.0255\n",
      "Epoch 193/200, Iteration 95/250, Loss: 0.0079\n",
      "Epoch 193/200, Iteration 96/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 97/250, Loss: 0.0456\n",
      "Epoch 193/200, Iteration 98/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 99/250, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 100/250, Loss: 0.0391\n",
      "Epoch 193/200, Iteration 101/250, Loss: 0.0144\n",
      "Epoch 193/200, Iteration 102/250, Loss: 0.0125\n",
      "Epoch 193/200, Iteration 103/250, Loss: 0.0226\n",
      "Epoch 193/200, Iteration 104/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 105/250, Loss: 0.0253\n",
      "Epoch 193/200, Iteration 106/250, Loss: 0.0072\n",
      "Epoch 193/200, Iteration 107/250, Loss: 0.0162\n",
      "Epoch 193/200, Iteration 108/250, Loss: 0.0087\n",
      "Epoch 193/200, Iteration 109/250, Loss: 0.0076\n",
      "Epoch 193/200, Iteration 110/250, Loss: 0.0126\n",
      "Epoch 193/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 112/250, Loss: 0.0082\n",
      "Epoch 193/200, Iteration 113/250, Loss: 0.0163\n",
      "Epoch 193/200, Iteration 114/250, Loss: 0.0114\n",
      "Epoch 193/200, Iteration 115/250, Loss: 0.0121\n",
      "Epoch 193/200, Iteration 116/250, Loss: 0.0084\n",
      "Epoch 193/200, Iteration 117/250, Loss: 0.0088\n",
      "Epoch 193/200, Iteration 118/250, Loss: 0.0098\n",
      "Epoch 193/200, Iteration 119/250, Loss: 0.0356\n",
      "Epoch 193/200, Iteration 120/250, Loss: 0.0065\n",
      "Epoch 193/200, Iteration 121/250, Loss: 0.0106\n",
      "Epoch 193/200, Iteration 122/250, Loss: 0.0099\n",
      "Epoch 193/200, Iteration 123/250, Loss: 0.0143\n",
      "Epoch 193/200, Iteration 124/250, Loss: 0.0148\n",
      "Epoch 193/200, Iteration 125/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 126/250, Loss: 0.0168\n",
      "Epoch 193/200, Iteration 127/250, Loss: 0.0157\n",
      "Epoch 193/200, Iteration 128/250, Loss: 0.0071\n",
      "Epoch 193/200, Iteration 129/250, Loss: 0.0100\n",
      "Epoch 193/200, Iteration 130/250, Loss: 0.0337\n",
      "Epoch 193/200, Iteration 131/250, Loss: 0.0119\n",
      "Epoch 193/200, Iteration 132/250, Loss: 0.0155\n",
      "Epoch 193/200, Iteration 133/250, Loss: 0.0085\n",
      "Epoch 193/200, Iteration 134/250, Loss: 0.0385\n",
      "Epoch 193/200, Iteration 135/250, Loss: 0.0146\n",
      "Epoch 193/200, Iteration 136/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 137/250, Loss: 0.0344\n",
      "Epoch 193/200, Iteration 138/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 139/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 140/250, Loss: 0.0133\n",
      "Epoch 193/200, Iteration 141/250, Loss: 0.0129\n",
      "Epoch 193/200, Iteration 142/250, Loss: 0.0079\n",
      "Epoch 193/200, Iteration 143/250, Loss: 0.0176\n",
      "Epoch 193/200, Iteration 144/250, Loss: 0.0195\n",
      "Epoch 193/200, Iteration 145/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 146/250, Loss: 0.0154\n",
      "Epoch 193/200, Iteration 147/250, Loss: 0.0207\n",
      "Epoch 193/200, Iteration 148/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 149/250, Loss: 0.0077\n",
      "Epoch 193/200, Iteration 150/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 151/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 152/250, Loss: 0.0318\n",
      "Epoch 193/200, Iteration 153/250, Loss: 0.0200\n",
      "Epoch 193/200, Iteration 154/250, Loss: 0.0234\n",
      "Epoch 193/200, Iteration 155/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 156/250, Loss: 0.0075\n",
      "Epoch 193/200, Iteration 157/250, Loss: 0.0149\n",
      "Epoch 193/200, Iteration 158/250, Loss: 0.0123\n",
      "Epoch 193/200, Iteration 159/250, Loss: 0.0115\n",
      "Epoch 193/200, Iteration 160/250, Loss: 0.0081\n",
      "Epoch 193/200, Iteration 161/250, Loss: 0.0229\n",
      "Epoch 193/200, Iteration 162/250, Loss: 0.0205\n",
      "Epoch 193/200, Iteration 163/250, Loss: 0.0119\n",
      "Epoch 193/200, Iteration 164/250, Loss: 0.0111\n",
      "Epoch 193/200, Iteration 165/250, Loss: 0.0152\n",
      "Epoch 193/200, Iteration 166/250, Loss: 0.0261\n",
      "Epoch 193/200, Iteration 167/250, Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200, Iteration 168/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 169/250, Loss: 0.0086\n",
      "Epoch 193/200, Iteration 170/250, Loss: 0.0159\n",
      "Epoch 193/200, Iteration 171/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 172/250, Loss: 0.0089\n",
      "Epoch 193/200, Iteration 173/250, Loss: 0.0122\n",
      "Epoch 193/200, Iteration 174/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 175/250, Loss: 0.0069\n",
      "Epoch 193/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 177/250, Loss: 0.0310\n",
      "Epoch 193/200, Iteration 178/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 179/250, Loss: 0.0311\n",
      "Epoch 193/200, Iteration 180/250, Loss: 0.0174\n",
      "Epoch 193/200, Iteration 181/250, Loss: 0.0142\n",
      "Epoch 193/200, Iteration 182/250, Loss: 0.0175\n",
      "Epoch 193/200, Iteration 183/250, Loss: 0.0100\n",
      "Epoch 193/200, Iteration 184/250, Loss: 0.0152\n",
      "Epoch 193/200, Iteration 185/250, Loss: 0.0068\n",
      "Epoch 193/200, Iteration 186/250, Loss: 0.0129\n",
      "Epoch 193/200, Iteration 187/250, Loss: 0.0228\n",
      "Epoch 193/200, Iteration 188/250, Loss: 0.0288\n",
      "Epoch 193/200, Iteration 189/250, Loss: 0.0095\n",
      "Epoch 193/200, Iteration 190/250, Loss: 0.0164\n",
      "Epoch 193/200, Iteration 191/250, Loss: 0.0130\n",
      "Epoch 193/200, Iteration 192/250, Loss: 0.0169\n",
      "Epoch 193/200, Iteration 193/250, Loss: 0.0182\n",
      "Epoch 193/200, Iteration 194/250, Loss: 0.0103\n",
      "Epoch 193/200, Iteration 195/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 196/250, Loss: 0.0196\n",
      "Epoch 193/200, Iteration 197/250, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 198/250, Loss: 0.0110\n",
      "Epoch 193/200, Iteration 199/250, Loss: 0.0145\n",
      "Epoch 193/200, Iteration 200/250, Loss: 0.0084\n",
      "Epoch 193/200, Iteration 201/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 202/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 203/250, Loss: 0.0100\n",
      "Epoch 193/200, Iteration 204/250, Loss: 0.0116\n",
      "Epoch 193/200, Iteration 205/250, Loss: 0.0133\n",
      "Epoch 193/200, Iteration 206/250, Loss: 0.0071\n",
      "Epoch 193/200, Iteration 207/250, Loss: 0.0160\n",
      "Epoch 193/200, Iteration 208/250, Loss: 0.0152\n",
      "Epoch 193/200, Iteration 209/250, Loss: 0.0158\n",
      "Epoch 193/200, Iteration 210/250, Loss: 0.0163\n",
      "Epoch 193/200, Iteration 211/250, Loss: 0.0097\n",
      "Epoch 193/200, Iteration 212/250, Loss: 0.0098\n",
      "Epoch 193/200, Iteration 213/250, Loss: 0.0117\n",
      "Epoch 193/200, Iteration 214/250, Loss: 0.0088\n",
      "Epoch 193/200, Iteration 215/250, Loss: 0.0212\n",
      "Epoch 193/200, Iteration 216/250, Loss: 0.0265\n",
      "Epoch 193/200, Iteration 217/250, Loss: 0.0079\n",
      "Epoch 193/200, Iteration 218/250, Loss: 0.0134\n",
      "Epoch 193/200, Iteration 219/250, Loss: 0.0102\n",
      "Epoch 193/200, Iteration 220/250, Loss: 0.0141\n",
      "Epoch 193/200, Iteration 221/250, Loss: 0.0180\n",
      "Epoch 193/200, Iteration 222/250, Loss: 0.0105\n",
      "Epoch 193/200, Iteration 223/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 224/250, Loss: 0.0260\n",
      "Epoch 193/200, Iteration 225/250, Loss: 0.0237\n",
      "Epoch 193/200, Iteration 226/250, Loss: 0.0093\n",
      "Epoch 193/200, Iteration 227/250, Loss: 0.0206\n",
      "Epoch 193/200, Iteration 228/250, Loss: 0.0190\n",
      "Epoch 193/200, Iteration 229/250, Loss: 0.0074\n",
      "Epoch 193/200, Iteration 230/250, Loss: 0.0130\n",
      "Epoch 193/200, Iteration 231/250, Loss: 0.0322\n",
      "Epoch 193/200, Iteration 232/250, Loss: 0.0140\n",
      "Epoch 193/200, Iteration 233/250, Loss: 0.0142\n",
      "Epoch 193/200, Iteration 234/250, Loss: 0.0092\n",
      "Epoch 193/200, Iteration 235/250, Loss: 0.0083\n",
      "Epoch 193/200, Iteration 236/250, Loss: 0.0112\n",
      "Epoch 193/200, Iteration 237/250, Loss: 0.0132\n",
      "Epoch 193/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 193/200, Iteration 239/250, Loss: 0.0105\n",
      "Epoch 193/200, Iteration 240/250, Loss: 0.0158\n",
      "Epoch 193/200, Iteration 241/250, Loss: 0.0090\n",
      "Epoch 193/200, Iteration 242/250, Loss: 0.0090\n",
      "Epoch 193/200, Iteration 243/250, Loss: 0.0134\n",
      "Epoch 193/200, Iteration 244/250, Loss: 0.0099\n",
      "Epoch 193/200, Iteration 245/250, Loss: 0.0224\n",
      "Epoch 193/200, Iteration 246/250, Loss: 0.0137\n",
      "Epoch 193/200, Iteration 247/250, Loss: 0.0101\n",
      "Epoch 193/200, Iteration 248/250, Loss: 0.0187\n",
      "Epoch 193/200, Iteration 249/250, Loss: 0.0080\n",
      "Epoch 193/200, Iteration 250/250, Loss: 0.0351\n",
      "Train Error: \n",
      " Accuracy: 91.17%, Avg loss: 0.006835, MRE: 0.506534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.05%, Avg loss: 0.007457, MRE: 0.496642 \n",
      "\n",
      "Epoch 194/200, Iteration 1/250, Loss: 0.0135\n",
      "Epoch 194/200, Iteration 2/250, Loss: 0.0096\n",
      "Epoch 194/200, Iteration 3/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 4/250, Loss: 0.0379\n",
      "Epoch 194/200, Iteration 5/250, Loss: 0.0417\n",
      "Epoch 194/200, Iteration 6/250, Loss: 0.0186\n",
      "Epoch 194/200, Iteration 7/250, Loss: 0.0098\n",
      "Epoch 194/200, Iteration 8/250, Loss: 0.0223\n",
      "Epoch 194/200, Iteration 9/250, Loss: 0.0071\n",
      "Epoch 194/200, Iteration 10/250, Loss: 0.0104\n",
      "Epoch 194/200, Iteration 11/250, Loss: 0.0137\n",
      "Epoch 194/200, Iteration 12/250, Loss: 0.0225\n",
      "Epoch 194/200, Iteration 13/250, Loss: 0.0155\n",
      "Epoch 194/200, Iteration 14/250, Loss: 0.0104\n",
      "Epoch 194/200, Iteration 15/250, Loss: 0.0128\n",
      "Epoch 194/200, Iteration 16/250, Loss: 0.0243\n",
      "Epoch 194/200, Iteration 17/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 18/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 19/250, Loss: 0.0094\n",
      "Epoch 194/200, Iteration 20/250, Loss: 0.0148\n",
      "Epoch 194/200, Iteration 21/250, Loss: 0.0184\n",
      "Epoch 194/200, Iteration 22/250, Loss: 0.0125\n",
      "Epoch 194/200, Iteration 23/250, Loss: 0.0227\n",
      "Epoch 194/200, Iteration 24/250, Loss: 0.0150\n",
      "Epoch 194/200, Iteration 25/250, Loss: 0.0093\n",
      "Epoch 194/200, Iteration 26/250, Loss: 0.0253\n",
      "Epoch 194/200, Iteration 27/250, Loss: 0.0245\n",
      "Epoch 194/200, Iteration 28/250, Loss: 0.0272\n",
      "Epoch 194/200, Iteration 29/250, Loss: 0.0172\n",
      "Epoch 194/200, Iteration 30/250, Loss: 0.0161\n",
      "Epoch 194/200, Iteration 31/250, Loss: 0.0116\n",
      "Epoch 194/200, Iteration 32/250, Loss: 0.0247\n",
      "Epoch 194/200, Iteration 33/250, Loss: 0.0155\n",
      "Epoch 194/200, Iteration 34/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 35/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 36/250, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 37/250, Loss: 0.0101\n",
      "Epoch 194/200, Iteration 38/250, Loss: 0.0142\n",
      "Epoch 194/200, Iteration 39/250, Loss: 0.0118\n",
      "Epoch 194/200, Iteration 40/250, Loss: 0.0397\n",
      "Epoch 194/200, Iteration 41/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 42/250, Loss: 0.0343\n",
      "Epoch 194/200, Iteration 43/250, Loss: 0.0118\n",
      "Epoch 194/200, Iteration 44/250, Loss: 0.0078\n",
      "Epoch 194/200, Iteration 45/250, Loss: 0.0281\n",
      "Epoch 194/200, Iteration 46/250, Loss: 0.0068\n",
      "Epoch 194/200, Iteration 47/250, Loss: 0.0269\n",
      "Epoch 194/200, Iteration 48/250, Loss: 0.0312\n",
      "Epoch 194/200, Iteration 49/250, Loss: 0.0156\n",
      "Epoch 194/200, Iteration 50/250, Loss: 0.0220\n",
      "Epoch 194/200, Iteration 51/250, Loss: 0.0262\n",
      "Epoch 194/200, Iteration 52/250, Loss: 0.0092\n",
      "Epoch 194/200, Iteration 53/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 54/250, Loss: 0.0231\n",
      "Epoch 194/200, Iteration 55/250, Loss: 0.0296\n",
      "Epoch 194/200, Iteration 56/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 57/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 58/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 59/250, Loss: 0.0175\n",
      "Epoch 194/200, Iteration 60/250, Loss: 0.0100\n",
      "Epoch 194/200, Iteration 61/250, Loss: 0.0101\n",
      "Epoch 194/200, Iteration 62/250, Loss: 0.0084\n",
      "Epoch 194/200, Iteration 63/250, Loss: 0.0301\n",
      "Epoch 194/200, Iteration 64/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 65/250, Loss: 0.0133\n",
      "Epoch 194/200, Iteration 66/250, Loss: 0.0089\n",
      "Epoch 194/200, Iteration 67/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 68/250, Loss: 0.0099\n",
      "Epoch 194/200, Iteration 69/250, Loss: 0.0207\n",
      "Epoch 194/200, Iteration 70/250, Loss: 0.0062\n",
      "Epoch 194/200, Iteration 71/250, Loss: 0.0245\n",
      "Epoch 194/200, Iteration 72/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 73/250, Loss: 0.0287\n",
      "Epoch 194/200, Iteration 74/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 75/250, Loss: 0.0273\n",
      "Epoch 194/200, Iteration 76/250, Loss: 0.0086\n",
      "Epoch 194/200, Iteration 77/250, Loss: 0.0127\n",
      "Epoch 194/200, Iteration 78/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 79/250, Loss: 0.0106\n",
      "Epoch 194/200, Iteration 80/250, Loss: 0.0161\n",
      "Epoch 194/200, Iteration 81/250, Loss: 0.0086\n",
      "Epoch 194/200, Iteration 82/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 83/250, Loss: 0.0269\n",
      "Epoch 194/200, Iteration 84/250, Loss: 0.0180\n",
      "Epoch 194/200, Iteration 85/250, Loss: 0.0089\n",
      "Epoch 194/200, Iteration 86/250, Loss: 0.0335\n",
      "Epoch 194/200, Iteration 87/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 88/250, Loss: 0.0115\n",
      "Epoch 194/200, Iteration 89/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 90/250, Loss: 0.0107\n",
      "Epoch 194/200, Iteration 91/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 92/250, Loss: 0.0072\n",
      "Epoch 194/200, Iteration 93/250, Loss: 0.0263\n",
      "Epoch 194/200, Iteration 94/250, Loss: 0.0157\n",
      "Epoch 194/200, Iteration 95/250, Loss: 0.0143\n",
      "Epoch 194/200, Iteration 96/250, Loss: 0.0108\n",
      "Epoch 194/200, Iteration 97/250, Loss: 0.0073\n",
      "Epoch 194/200, Iteration 98/250, Loss: 0.0177\n",
      "Epoch 194/200, Iteration 99/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 100/250, Loss: 0.0128\n",
      "Epoch 194/200, Iteration 101/250, Loss: 0.0134\n",
      "Epoch 194/200, Iteration 102/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 103/250, Loss: 0.0156\n",
      "Epoch 194/200, Iteration 104/250, Loss: 0.0076\n",
      "Epoch 194/200, Iteration 105/250, Loss: 0.0291\n",
      "Epoch 194/200, Iteration 106/250, Loss: 0.0246\n",
      "Epoch 194/200, Iteration 107/250, Loss: 0.0168\n",
      "Epoch 194/200, Iteration 108/250, Loss: 0.0099\n",
      "Epoch 194/200, Iteration 109/250, Loss: 0.0206\n",
      "Epoch 194/200, Iteration 110/250, Loss: 0.0141\n",
      "Epoch 194/200, Iteration 111/250, Loss: 0.0140\n",
      "Epoch 194/200, Iteration 112/250, Loss: 0.0104\n",
      "Epoch 194/200, Iteration 113/250, Loss: 0.0129\n",
      "Epoch 194/200, Iteration 114/250, Loss: 0.0159\n",
      "Epoch 194/200, Iteration 115/250, Loss: 0.0209\n",
      "Epoch 194/200, Iteration 116/250, Loss: 0.0084\n",
      "Epoch 194/200, Iteration 117/250, Loss: 0.0148\n",
      "Epoch 194/200, Iteration 118/250, Loss: 0.0099\n",
      "Epoch 194/200, Iteration 119/250, Loss: 0.0233\n",
      "Epoch 194/200, Iteration 120/250, Loss: 0.0109\n",
      "Epoch 194/200, Iteration 121/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 122/250, Loss: 0.0171\n",
      "Epoch 194/200, Iteration 123/250, Loss: 0.0287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200, Iteration 124/250, Loss: 0.0088\n",
      "Epoch 194/200, Iteration 125/250, Loss: 0.0312\n",
      "Epoch 194/200, Iteration 126/250, Loss: 0.0149\n",
      "Epoch 194/200, Iteration 127/250, Loss: 0.0075\n",
      "Epoch 194/200, Iteration 128/250, Loss: 0.0112\n",
      "Epoch 194/200, Iteration 129/250, Loss: 0.0125\n",
      "Epoch 194/200, Iteration 130/250, Loss: 0.0165\n",
      "Epoch 194/200, Iteration 131/250, Loss: 0.0076\n",
      "Epoch 194/200, Iteration 132/250, Loss: 0.0125\n",
      "Epoch 194/200, Iteration 133/250, Loss: 0.0086\n",
      "Epoch 194/200, Iteration 134/250, Loss: 0.0108\n",
      "Epoch 194/200, Iteration 135/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 136/250, Loss: 0.0149\n",
      "Epoch 194/200, Iteration 137/250, Loss: 0.0065\n",
      "Epoch 194/200, Iteration 138/250, Loss: 0.0190\n",
      "Epoch 194/200, Iteration 139/250, Loss: 0.0064\n",
      "Epoch 194/200, Iteration 140/250, Loss: 0.0121\n",
      "Epoch 194/200, Iteration 141/250, Loss: 0.0141\n",
      "Epoch 194/200, Iteration 142/250, Loss: 0.0217\n",
      "Epoch 194/200, Iteration 143/250, Loss: 0.0123\n",
      "Epoch 194/200, Iteration 144/250, Loss: 0.0249\n",
      "Epoch 194/200, Iteration 145/250, Loss: 0.0121\n",
      "Epoch 194/200, Iteration 146/250, Loss: 0.0063\n",
      "Epoch 194/200, Iteration 147/250, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 148/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 149/250, Loss: 0.0386\n",
      "Epoch 194/200, Iteration 150/250, Loss: 0.0202\n",
      "Epoch 194/200, Iteration 151/250, Loss: 0.0111\n",
      "Epoch 194/200, Iteration 152/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 153/250, Loss: 0.0159\n",
      "Epoch 194/200, Iteration 154/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 155/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 156/250, Loss: 0.0238\n",
      "Epoch 194/200, Iteration 157/250, Loss: 0.0349\n",
      "Epoch 194/200, Iteration 158/250, Loss: 0.0246\n",
      "Epoch 194/200, Iteration 159/250, Loss: 0.0157\n",
      "Epoch 194/200, Iteration 160/250, Loss: 0.0118\n",
      "Epoch 194/200, Iteration 161/250, Loss: 0.0215\n",
      "Epoch 194/200, Iteration 162/250, Loss: 0.0266\n",
      "Epoch 194/200, Iteration 163/250, Loss: 0.0188\n",
      "Epoch 194/200, Iteration 164/250, Loss: 0.0081\n",
      "Epoch 194/200, Iteration 165/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 166/250, Loss: 0.0090\n",
      "Epoch 194/200, Iteration 167/250, Loss: 0.0069\n",
      "Epoch 194/200, Iteration 168/250, Loss: 0.0138\n",
      "Epoch 194/200, Iteration 169/250, Loss: 0.0137\n",
      "Epoch 194/200, Iteration 170/250, Loss: 0.0185\n",
      "Epoch 194/200, Iteration 171/250, Loss: 0.0076\n",
      "Epoch 194/200, Iteration 172/250, Loss: 0.0094\n",
      "Epoch 194/200, Iteration 173/250, Loss: 0.0156\n",
      "Epoch 194/200, Iteration 174/250, Loss: 0.0352\n",
      "Epoch 194/200, Iteration 175/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 176/250, Loss: 0.0151\n",
      "Epoch 194/200, Iteration 177/250, Loss: 0.0079\n",
      "Epoch 194/200, Iteration 178/250, Loss: 0.0088\n",
      "Epoch 194/200, Iteration 179/250, Loss: 0.0159\n",
      "Epoch 194/200, Iteration 180/250, Loss: 0.0158\n",
      "Epoch 194/200, Iteration 181/250, Loss: 0.0276\n",
      "Epoch 194/200, Iteration 182/250, Loss: 0.0170\n",
      "Epoch 194/200, Iteration 183/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 184/250, Loss: 0.0205\n",
      "Epoch 194/200, Iteration 185/250, Loss: 0.0153\n",
      "Epoch 194/200, Iteration 186/250, Loss: 0.0092\n",
      "Epoch 194/200, Iteration 187/250, Loss: 0.0138\n",
      "Epoch 194/200, Iteration 188/250, Loss: 0.0376\n",
      "Epoch 194/200, Iteration 189/250, Loss: 0.0089\n",
      "Epoch 194/200, Iteration 190/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 191/250, Loss: 0.0121\n",
      "Epoch 194/200, Iteration 192/250, Loss: 0.0135\n",
      "Epoch 194/200, Iteration 193/250, Loss: 0.0197\n",
      "Epoch 194/200, Iteration 194/250, Loss: 0.0158\n",
      "Epoch 194/200, Iteration 195/250, Loss: 0.0141\n",
      "Epoch 194/200, Iteration 196/250, Loss: 0.0232\n",
      "Epoch 194/200, Iteration 197/250, Loss: 0.0126\n",
      "Epoch 194/200, Iteration 198/250, Loss: 0.0107\n",
      "Epoch 194/200, Iteration 199/250, Loss: 0.0135\n",
      "Epoch 194/200, Iteration 200/250, Loss: 0.0145\n",
      "Epoch 194/200, Iteration 201/250, Loss: 0.0142\n",
      "Epoch 194/200, Iteration 202/250, Loss: 0.0139\n",
      "Epoch 194/200, Iteration 203/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 204/250, Loss: 0.0147\n",
      "Epoch 194/200, Iteration 205/250, Loss: 0.0136\n",
      "Epoch 194/200, Iteration 206/250, Loss: 0.0211\n",
      "Epoch 194/200, Iteration 207/250, Loss: 0.0091\n",
      "Epoch 194/200, Iteration 208/250, Loss: 0.0080\n",
      "Epoch 194/200, Iteration 209/250, Loss: 0.0087\n",
      "Epoch 194/200, Iteration 210/250, Loss: 0.0158\n",
      "Epoch 194/200, Iteration 211/250, Loss: 0.0183\n",
      "Epoch 194/200, Iteration 212/250, Loss: 0.0173\n",
      "Epoch 194/200, Iteration 213/250, Loss: 0.0257\n",
      "Epoch 194/200, Iteration 214/250, Loss: 0.0083\n",
      "Epoch 194/200, Iteration 215/250, Loss: 0.0468\n",
      "Epoch 194/200, Iteration 216/250, Loss: 0.0122\n",
      "Epoch 194/200, Iteration 217/250, Loss: 0.0227\n",
      "Epoch 194/200, Iteration 218/250, Loss: 0.0216\n",
      "Epoch 194/200, Iteration 219/250, Loss: 0.0079\n",
      "Epoch 194/200, Iteration 220/250, Loss: 0.0103\n",
      "Epoch 194/200, Iteration 221/250, Loss: 0.0258\n",
      "Epoch 194/200, Iteration 222/250, Loss: 0.0267\n",
      "Epoch 194/200, Iteration 223/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 224/250, Loss: 0.0194\n",
      "Epoch 194/200, Iteration 225/250, Loss: 0.0212\n",
      "Epoch 194/200, Iteration 226/250, Loss: 0.0114\n",
      "Epoch 194/200, Iteration 227/250, Loss: 0.0095\n",
      "Epoch 194/200, Iteration 228/250, Loss: 0.0073\n",
      "Epoch 194/200, Iteration 229/250, Loss: 0.0231\n",
      "Epoch 194/200, Iteration 230/250, Loss: 0.0160\n",
      "Epoch 194/200, Iteration 231/250, Loss: 0.0280\n",
      "Epoch 194/200, Iteration 232/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 233/250, Loss: 0.0117\n",
      "Epoch 194/200, Iteration 234/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 235/250, Loss: 0.0180\n",
      "Epoch 194/200, Iteration 236/250, Loss: 0.0088\n",
      "Epoch 194/200, Iteration 237/250, Loss: 0.0105\n",
      "Epoch 194/200, Iteration 238/250, Loss: 0.0120\n",
      "Epoch 194/200, Iteration 239/250, Loss: 0.0119\n",
      "Epoch 194/200, Iteration 240/250, Loss: 0.0096\n",
      "Epoch 194/200, Iteration 241/250, Loss: 0.0116\n",
      "Epoch 194/200, Iteration 242/250, Loss: 0.0429\n",
      "Epoch 194/200, Iteration 243/250, Loss: 0.0085\n",
      "Epoch 194/200, Iteration 244/250, Loss: 0.0113\n",
      "Epoch 194/200, Iteration 245/250, Loss: 0.0129\n",
      "Epoch 194/200, Iteration 246/250, Loss: 0.0171\n",
      "Epoch 194/200, Iteration 247/250, Loss: 0.0180\n",
      "Epoch 194/200, Iteration 248/250, Loss: 0.0268\n",
      "Epoch 194/200, Iteration 249/250, Loss: 0.0194\n",
      "Epoch 194/200, Iteration 250/250, Loss: 0.0105\n",
      "Train Error: \n",
      " Accuracy: 83.97%, Avg loss: 0.006872, MRE: 0.453523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.007365, MRE: 0.542261 \n",
      "\n",
      "Epoch 195/200, Iteration 1/250, Loss: 0.0232\n",
      "Epoch 195/200, Iteration 2/250, Loss: 0.0231\n",
      "Epoch 195/200, Iteration 3/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 4/250, Loss: 0.0146\n",
      "Epoch 195/200, Iteration 5/250, Loss: 0.0093\n",
      "Epoch 195/200, Iteration 6/250, Loss: 0.0230\n",
      "Epoch 195/200, Iteration 7/250, Loss: 0.0156\n",
      "Epoch 195/200, Iteration 8/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 9/250, Loss: 0.0190\n",
      "Epoch 195/200, Iteration 10/250, Loss: 0.0244\n",
      "Epoch 195/200, Iteration 11/250, Loss: 0.0081\n",
      "Epoch 195/200, Iteration 12/250, Loss: 0.0307\n",
      "Epoch 195/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 195/200, Iteration 14/250, Loss: 0.0093\n",
      "Epoch 195/200, Iteration 15/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 16/250, Loss: 0.0108\n",
      "Epoch 195/200, Iteration 17/250, Loss: 0.0201\n",
      "Epoch 195/200, Iteration 18/250, Loss: 0.0072\n",
      "Epoch 195/200, Iteration 19/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 20/250, Loss: 0.0184\n",
      "Epoch 195/200, Iteration 21/250, Loss: 0.0215\n",
      "Epoch 195/200, Iteration 22/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 23/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 24/250, Loss: 0.0103\n",
      "Epoch 195/200, Iteration 25/250, Loss: 0.0293\n",
      "Epoch 195/200, Iteration 26/250, Loss: 0.0183\n",
      "Epoch 195/200, Iteration 27/250, Loss: 0.0108\n",
      "Epoch 195/200, Iteration 28/250, Loss: 0.0216\n",
      "Epoch 195/200, Iteration 29/250, Loss: 0.0123\n",
      "Epoch 195/200, Iteration 30/250, Loss: 0.0110\n",
      "Epoch 195/200, Iteration 31/250, Loss: 0.0155\n",
      "Epoch 195/200, Iteration 32/250, Loss: 0.0093\n",
      "Epoch 195/200, Iteration 33/250, Loss: 0.0059\n",
      "Epoch 195/200, Iteration 34/250, Loss: 0.0427\n",
      "Epoch 195/200, Iteration 35/250, Loss: 0.0195\n",
      "Epoch 195/200, Iteration 36/250, Loss: 0.0190\n",
      "Epoch 195/200, Iteration 37/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 38/250, Loss: 0.0224\n",
      "Epoch 195/200, Iteration 39/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 40/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 41/250, Loss: 0.0225\n",
      "Epoch 195/200, Iteration 42/250, Loss: 0.0121\n",
      "Epoch 195/200, Iteration 43/250, Loss: 0.0143\n",
      "Epoch 195/200, Iteration 44/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 45/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 46/250, Loss: 0.0088\n",
      "Epoch 195/200, Iteration 47/250, Loss: 0.0124\n",
      "Epoch 195/200, Iteration 48/250, Loss: 0.0227\n",
      "Epoch 195/200, Iteration 49/250, Loss: 0.0137\n",
      "Epoch 195/200, Iteration 50/250, Loss: 0.0100\n",
      "Epoch 195/200, Iteration 51/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 52/250, Loss: 0.0180\n",
      "Epoch 195/200, Iteration 53/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 54/250, Loss: 0.0161\n",
      "Epoch 195/200, Iteration 55/250, Loss: 0.0162\n",
      "Epoch 195/200, Iteration 56/250, Loss: 0.0125\n",
      "Epoch 195/200, Iteration 57/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 58/250, Loss: 0.0212\n",
      "Epoch 195/200, Iteration 59/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 60/250, Loss: 0.0238\n",
      "Epoch 195/200, Iteration 61/250, Loss: 0.0100\n",
      "Epoch 195/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 195/200, Iteration 63/250, Loss: 0.0113\n",
      "Epoch 195/200, Iteration 64/250, Loss: 0.0125\n",
      "Epoch 195/200, Iteration 65/250, Loss: 0.0142\n",
      "Epoch 195/200, Iteration 66/250, Loss: 0.0111\n",
      "Epoch 195/200, Iteration 67/250, Loss: 0.0236\n",
      "Epoch 195/200, Iteration 68/250, Loss: 0.0076\n",
      "Epoch 195/200, Iteration 69/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 70/250, Loss: 0.0353\n",
      "Epoch 195/200, Iteration 71/250, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 72/250, Loss: 0.0108\n",
      "Epoch 195/200, Iteration 73/250, Loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200, Iteration 74/250, Loss: 0.0277\n",
      "Epoch 195/200, Iteration 75/250, Loss: 0.0086\n",
      "Epoch 195/200, Iteration 76/250, Loss: 0.0176\n",
      "Epoch 195/200, Iteration 77/250, Loss: 0.0116\n",
      "Epoch 195/200, Iteration 78/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 79/250, Loss: 0.0227\n",
      "Epoch 195/200, Iteration 80/250, Loss: 0.0166\n",
      "Epoch 195/200, Iteration 81/250, Loss: 0.0246\n",
      "Epoch 195/200, Iteration 82/250, Loss: 0.0126\n",
      "Epoch 195/200, Iteration 83/250, Loss: 0.0103\n",
      "Epoch 195/200, Iteration 84/250, Loss: 0.0136\n",
      "Epoch 195/200, Iteration 85/250, Loss: 0.0076\n",
      "Epoch 195/200, Iteration 86/250, Loss: 0.0203\n",
      "Epoch 195/200, Iteration 87/250, Loss: 0.0205\n",
      "Epoch 195/200, Iteration 88/250, Loss: 0.0098\n",
      "Epoch 195/200, Iteration 89/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 90/250, Loss: 0.0123\n",
      "Epoch 195/200, Iteration 91/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 92/250, Loss: 0.0168\n",
      "Epoch 195/200, Iteration 93/250, Loss: 0.0399\n",
      "Epoch 195/200, Iteration 94/250, Loss: 0.0070\n",
      "Epoch 195/200, Iteration 95/250, Loss: 0.0093\n",
      "Epoch 195/200, Iteration 96/250, Loss: 0.0090\n",
      "Epoch 195/200, Iteration 97/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 98/250, Loss: 0.0119\n",
      "Epoch 195/200, Iteration 99/250, Loss: 0.0385\n",
      "Epoch 195/200, Iteration 100/250, Loss: 0.0141\n",
      "Epoch 195/200, Iteration 101/250, Loss: 0.0130\n",
      "Epoch 195/200, Iteration 102/250, Loss: 0.0154\n",
      "Epoch 195/200, Iteration 103/250, Loss: 0.0179\n",
      "Epoch 195/200, Iteration 104/250, Loss: 0.0154\n",
      "Epoch 195/200, Iteration 105/250, Loss: 0.0195\n",
      "Epoch 195/200, Iteration 106/250, Loss: 0.0147\n",
      "Epoch 195/200, Iteration 107/250, Loss: 0.0069\n",
      "Epoch 195/200, Iteration 108/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 109/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 110/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 111/250, Loss: 0.0148\n",
      "Epoch 195/200, Iteration 112/250, Loss: 0.0102\n",
      "Epoch 195/200, Iteration 113/250, Loss: 0.0065\n",
      "Epoch 195/200, Iteration 114/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 115/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 116/250, Loss: 0.0105\n",
      "Epoch 195/200, Iteration 117/250, Loss: 0.0090\n",
      "Epoch 195/200, Iteration 118/250, Loss: 0.0126\n",
      "Epoch 195/200, Iteration 119/250, Loss: 0.0174\n",
      "Epoch 195/200, Iteration 120/250, Loss: 0.0299\n",
      "Epoch 195/200, Iteration 121/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 122/250, Loss: 0.0116\n",
      "Epoch 195/200, Iteration 123/250, Loss: 0.0086\n",
      "Epoch 195/200, Iteration 124/250, Loss: 0.0127\n",
      "Epoch 195/200, Iteration 125/250, Loss: 0.0270\n",
      "Epoch 195/200, Iteration 126/250, Loss: 0.0108\n",
      "Epoch 195/200, Iteration 127/250, Loss: 0.0116\n",
      "Epoch 195/200, Iteration 128/250, Loss: 0.0212\n",
      "Epoch 195/200, Iteration 129/250, Loss: 0.0149\n",
      "Epoch 195/200, Iteration 130/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 131/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 132/250, Loss: 0.0110\n",
      "Epoch 195/200, Iteration 133/250, Loss: 0.0280\n",
      "Epoch 195/200, Iteration 134/250, Loss: 0.0331\n",
      "Epoch 195/200, Iteration 135/250, Loss: 0.0178\n",
      "Epoch 195/200, Iteration 136/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 137/250, Loss: 0.0144\n",
      "Epoch 195/200, Iteration 138/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 139/250, Loss: 0.0241\n",
      "Epoch 195/200, Iteration 140/250, Loss: 0.0089\n",
      "Epoch 195/200, Iteration 141/250, Loss: 0.0186\n",
      "Epoch 195/200, Iteration 142/250, Loss: 0.0360\n",
      "Epoch 195/200, Iteration 143/250, Loss: 0.0206\n",
      "Epoch 195/200, Iteration 144/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 145/250, Loss: 0.0202\n",
      "Epoch 195/200, Iteration 146/250, Loss: 0.0106\n",
      "Epoch 195/200, Iteration 147/250, Loss: 0.0092\n",
      "Epoch 195/200, Iteration 148/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 149/250, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 150/250, Loss: 0.0318\n",
      "Epoch 195/200, Iteration 151/250, Loss: 0.0171\n",
      "Epoch 195/200, Iteration 152/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 153/250, Loss: 0.0299\n",
      "Epoch 195/200, Iteration 154/250, Loss: 0.0121\n",
      "Epoch 195/200, Iteration 155/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 156/250, Loss: 0.0126\n",
      "Epoch 195/200, Iteration 157/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 158/250, Loss: 0.0128\n",
      "Epoch 195/200, Iteration 159/250, Loss: 0.0163\n",
      "Epoch 195/200, Iteration 160/250, Loss: 0.0091\n",
      "Epoch 195/200, Iteration 161/250, Loss: 0.0178\n",
      "Epoch 195/200, Iteration 162/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 163/250, Loss: 0.0187\n",
      "Epoch 195/200, Iteration 164/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 165/250, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 166/250, Loss: 0.0189\n",
      "Epoch 195/200, Iteration 167/250, Loss: 0.0211\n",
      "Epoch 195/200, Iteration 168/250, Loss: 0.0271\n",
      "Epoch 195/200, Iteration 169/250, Loss: 0.0235\n",
      "Epoch 195/200, Iteration 170/250, Loss: 0.0157\n",
      "Epoch 195/200, Iteration 171/250, Loss: 0.0115\n",
      "Epoch 195/200, Iteration 172/250, Loss: 0.0076\n",
      "Epoch 195/200, Iteration 173/250, Loss: 0.0343\n",
      "Epoch 195/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 195/200, Iteration 175/250, Loss: 0.0184\n",
      "Epoch 195/200, Iteration 176/250, Loss: 0.0092\n",
      "Epoch 195/200, Iteration 177/250, Loss: 0.0162\n",
      "Epoch 195/200, Iteration 178/250, Loss: 0.0142\n",
      "Epoch 195/200, Iteration 179/250, Loss: 0.0075\n",
      "Epoch 195/200, Iteration 180/250, Loss: 0.0099\n",
      "Epoch 195/200, Iteration 181/250, Loss: 0.0120\n",
      "Epoch 195/200, Iteration 182/250, Loss: 0.0225\n",
      "Epoch 195/200, Iteration 183/250, Loss: 0.0216\n",
      "Epoch 195/200, Iteration 184/250, Loss: 0.0160\n",
      "Epoch 195/200, Iteration 185/250, Loss: 0.0074\n",
      "Epoch 195/200, Iteration 186/250, Loss: 0.0132\n",
      "Epoch 195/200, Iteration 187/250, Loss: 0.0148\n",
      "Epoch 195/200, Iteration 188/250, Loss: 0.0117\n",
      "Epoch 195/200, Iteration 189/250, Loss: 0.0123\n",
      "Epoch 195/200, Iteration 190/250, Loss: 0.0267\n",
      "Epoch 195/200, Iteration 191/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 192/250, Loss: 0.0244\n",
      "Epoch 195/200, Iteration 193/250, Loss: 0.0215\n",
      "Epoch 195/200, Iteration 194/250, Loss: 0.0083\n",
      "Epoch 195/200, Iteration 195/250, Loss: 0.0078\n",
      "Epoch 195/200, Iteration 196/250, Loss: 0.0175\n",
      "Epoch 195/200, Iteration 197/250, Loss: 0.0069\n",
      "Epoch 195/200, Iteration 198/250, Loss: 0.0097\n",
      "Epoch 195/200, Iteration 199/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 200/250, Loss: 0.0109\n",
      "Epoch 195/200, Iteration 201/250, Loss: 0.0172\n",
      "Epoch 195/200, Iteration 202/250, Loss: 0.0075\n",
      "Epoch 195/200, Iteration 203/250, Loss: 0.0254\n",
      "Epoch 195/200, Iteration 204/250, Loss: 0.0075\n",
      "Epoch 195/200, Iteration 205/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 195/200, Iteration 207/250, Loss: 0.0346\n",
      "Epoch 195/200, Iteration 208/250, Loss: 0.0115\n",
      "Epoch 195/200, Iteration 209/250, Loss: 0.0080\n",
      "Epoch 195/200, Iteration 210/250, Loss: 0.0204\n",
      "Epoch 195/200, Iteration 211/250, Loss: 0.0314\n",
      "Epoch 195/200, Iteration 212/250, Loss: 0.0088\n",
      "Epoch 195/200, Iteration 213/250, Loss: 0.0198\n",
      "Epoch 195/200, Iteration 214/250, Loss: 0.0072\n",
      "Epoch 195/200, Iteration 215/250, Loss: 0.0275\n",
      "Epoch 195/200, Iteration 216/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 217/250, Loss: 0.0119\n",
      "Epoch 195/200, Iteration 218/250, Loss: 0.0176\n",
      "Epoch 195/200, Iteration 219/250, Loss: 0.0179\n",
      "Epoch 195/200, Iteration 220/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 221/250, Loss: 0.0183\n",
      "Epoch 195/200, Iteration 222/250, Loss: 0.0067\n",
      "Epoch 195/200, Iteration 223/250, Loss: 0.0132\n",
      "Epoch 195/200, Iteration 224/250, Loss: 0.0101\n",
      "Epoch 195/200, Iteration 225/250, Loss: 0.0397\n",
      "Epoch 195/200, Iteration 226/250, Loss: 0.0225\n",
      "Epoch 195/200, Iteration 227/250, Loss: 0.0082\n",
      "Epoch 195/200, Iteration 228/250, Loss: 0.0075\n",
      "Epoch 195/200, Iteration 229/250, Loss: 0.0153\n",
      "Epoch 195/200, Iteration 230/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 231/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 232/250, Loss: 0.0140\n",
      "Epoch 195/200, Iteration 233/250, Loss: 0.0153\n",
      "Epoch 195/200, Iteration 234/250, Loss: 0.0234\n",
      "Epoch 195/200, Iteration 235/250, Loss: 0.0095\n",
      "Epoch 195/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 195/200, Iteration 237/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 238/250, Loss: 0.0107\n",
      "Epoch 195/200, Iteration 239/250, Loss: 0.0129\n",
      "Epoch 195/200, Iteration 240/250, Loss: 0.0118\n",
      "Epoch 195/200, Iteration 241/250, Loss: 0.0133\n",
      "Epoch 195/200, Iteration 242/250, Loss: 0.0114\n",
      "Epoch 195/200, Iteration 243/250, Loss: 0.0084\n",
      "Epoch 195/200, Iteration 244/250, Loss: 0.0135\n",
      "Epoch 195/200, Iteration 245/250, Loss: 0.0094\n",
      "Epoch 195/200, Iteration 246/250, Loss: 0.0117\n",
      "Epoch 195/200, Iteration 247/250, Loss: 0.0085\n",
      "Epoch 195/200, Iteration 248/250, Loss: 0.0139\n",
      "Epoch 195/200, Iteration 249/250, Loss: 0.0137\n",
      "Epoch 195/200, Iteration 250/250, Loss: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 93.36%, Avg loss: 0.007226, MRE: 0.458277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.05%, Avg loss: 0.007825, MRE: 0.486003 \n",
      "\n",
      "Epoch 196/200, Iteration 1/250, Loss: 0.0242\n",
      "Epoch 196/200, Iteration 2/250, Loss: 0.0135\n",
      "Epoch 196/200, Iteration 3/250, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 4/250, Loss: 0.0070\n",
      "Epoch 196/200, Iteration 5/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 6/250, Loss: 0.0155\n",
      "Epoch 196/200, Iteration 7/250, Loss: 0.0323\n",
      "Epoch 196/200, Iteration 8/250, Loss: 0.0197\n",
      "Epoch 196/200, Iteration 9/250, Loss: 0.0235\n",
      "Epoch 196/200, Iteration 10/250, Loss: 0.0157\n",
      "Epoch 196/200, Iteration 11/250, Loss: 0.0108\n",
      "Epoch 196/200, Iteration 12/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 13/250, Loss: 0.0130\n",
      "Epoch 196/200, Iteration 14/250, Loss: 0.0274\n",
      "Epoch 196/200, Iteration 15/250, Loss: 0.0141\n",
      "Epoch 196/200, Iteration 16/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 17/250, Loss: 0.0290\n",
      "Epoch 196/200, Iteration 18/250, Loss: 0.0173\n",
      "Epoch 196/200, Iteration 19/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 20/250, Loss: 0.0091\n",
      "Epoch 196/200, Iteration 21/250, Loss: 0.0218\n",
      "Epoch 196/200, Iteration 22/250, Loss: 0.0200\n",
      "Epoch 196/200, Iteration 23/250, Loss: 0.0100\n",
      "Epoch 196/200, Iteration 24/250, Loss: 0.0111\n",
      "Epoch 196/200, Iteration 25/250, Loss: 0.0167\n",
      "Epoch 196/200, Iteration 26/250, Loss: 0.0064\n",
      "Epoch 196/200, Iteration 27/250, Loss: 0.0192\n",
      "Epoch 196/200, Iteration 28/250, Loss: 0.0183\n",
      "Epoch 196/200, Iteration 29/250, Loss: 0.0096\n",
      "Epoch 196/200, Iteration 30/250, Loss: 0.0170\n",
      "Epoch 196/200, Iteration 31/250, Loss: 0.0140\n",
      "Epoch 196/200, Iteration 32/250, Loss: 0.0101\n",
      "Epoch 196/200, Iteration 33/250, Loss: 0.0209\n",
      "Epoch 196/200, Iteration 34/250, Loss: 0.0104\n",
      "Epoch 196/200, Iteration 35/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 36/250, Loss: 0.0064\n",
      "Epoch 196/200, Iteration 37/250, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 38/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 39/250, Loss: 0.0240\n",
      "Epoch 196/200, Iteration 40/250, Loss: 0.0102\n",
      "Epoch 196/200, Iteration 41/250, Loss: 0.0076\n",
      "Epoch 196/200, Iteration 42/250, Loss: 0.0178\n",
      "Epoch 196/200, Iteration 43/250, Loss: 0.0120\n",
      "Epoch 196/200, Iteration 44/250, Loss: 0.0204\n",
      "Epoch 196/200, Iteration 45/250, Loss: 0.0277\n",
      "Epoch 196/200, Iteration 46/250, Loss: 0.0263\n",
      "Epoch 196/200, Iteration 47/250, Loss: 0.0094\n",
      "Epoch 196/200, Iteration 48/250, Loss: 0.0254\n",
      "Epoch 196/200, Iteration 49/250, Loss: 0.0207\n",
      "Epoch 196/200, Iteration 50/250, Loss: 0.0366\n",
      "Epoch 196/200, Iteration 51/250, Loss: 0.0142\n",
      "Epoch 196/200, Iteration 52/250, Loss: 0.0184\n",
      "Epoch 196/200, Iteration 53/250, Loss: 0.0146\n",
      "Epoch 196/200, Iteration 54/250, Loss: 0.0358\n",
      "Epoch 196/200, Iteration 55/250, Loss: 0.0228\n",
      "Epoch 196/200, Iteration 56/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 57/250, Loss: 0.0125\n",
      "Epoch 196/200, Iteration 58/250, Loss: 0.0161\n",
      "Epoch 196/200, Iteration 59/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 60/250, Loss: 0.0210\n",
      "Epoch 196/200, Iteration 61/250, Loss: 0.0080\n",
      "Epoch 196/200, Iteration 62/250, Loss: 0.0168\n",
      "Epoch 196/200, Iteration 63/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 64/250, Loss: 0.0156\n",
      "Epoch 196/200, Iteration 65/250, Loss: 0.0257\n",
      "Epoch 196/200, Iteration 66/250, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 67/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 68/250, Loss: 0.0075\n",
      "Epoch 196/200, Iteration 69/250, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 70/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 71/250, Loss: 0.0130\n",
      "Epoch 196/200, Iteration 72/250, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 73/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 74/250, Loss: 0.0123\n",
      "Epoch 196/200, Iteration 75/250, Loss: 0.0192\n",
      "Epoch 196/200, Iteration 76/250, Loss: 0.0242\n",
      "Epoch 196/200, Iteration 77/250, Loss: 0.0291\n",
      "Epoch 196/200, Iteration 78/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 79/250, Loss: 0.0176\n",
      "Epoch 196/200, Iteration 80/250, Loss: 0.0123\n",
      "Epoch 196/200, Iteration 81/250, Loss: 0.0230\n",
      "Epoch 196/200, Iteration 82/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 83/250, Loss: 0.0154\n",
      "Epoch 196/200, Iteration 84/250, Loss: 0.0216\n",
      "Epoch 196/200, Iteration 85/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 86/250, Loss: 0.0136\n",
      "Epoch 196/200, Iteration 87/250, Loss: 0.0140\n",
      "Epoch 196/200, Iteration 88/250, Loss: 0.0196\n",
      "Epoch 196/200, Iteration 89/250, Loss: 0.0085\n",
      "Epoch 196/200, Iteration 90/250, Loss: 0.0077\n",
      "Epoch 196/200, Iteration 91/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 92/250, Loss: 0.0110\n",
      "Epoch 196/200, Iteration 93/250, Loss: 0.0085\n",
      "Epoch 196/200, Iteration 94/250, Loss: 0.0163\n",
      "Epoch 196/200, Iteration 95/250, Loss: 0.0164\n",
      "Epoch 196/200, Iteration 96/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 97/250, Loss: 0.0088\n",
      "Epoch 196/200, Iteration 98/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 99/250, Loss: 0.0224\n",
      "Epoch 196/200, Iteration 100/250, Loss: 0.0216\n",
      "Epoch 196/200, Iteration 101/250, Loss: 0.0123\n",
      "Epoch 196/200, Iteration 102/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 103/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 104/250, Loss: 0.0095\n",
      "Epoch 196/200, Iteration 105/250, Loss: 0.0123\n",
      "Epoch 196/200, Iteration 106/250, Loss: 0.0152\n",
      "Epoch 196/200, Iteration 107/250, Loss: 0.0188\n",
      "Epoch 196/200, Iteration 108/250, Loss: 0.0144\n",
      "Epoch 196/200, Iteration 109/250, Loss: 0.0113\n",
      "Epoch 196/200, Iteration 110/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 111/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 112/250, Loss: 0.0139\n",
      "Epoch 196/200, Iteration 113/250, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 114/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 115/250, Loss: 0.0174\n",
      "Epoch 196/200, Iteration 116/250, Loss: 0.0156\n",
      "Epoch 196/200, Iteration 117/250, Loss: 0.0221\n",
      "Epoch 196/200, Iteration 118/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 119/250, Loss: 0.0084\n",
      "Epoch 196/200, Iteration 120/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 121/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 122/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 123/250, Loss: 0.0166\n",
      "Epoch 196/200, Iteration 124/250, Loss: 0.0083\n",
      "Epoch 196/200, Iteration 125/250, Loss: 0.0134\n",
      "Epoch 196/200, Iteration 126/250, Loss: 0.0177\n",
      "Epoch 196/200, Iteration 127/250, Loss: 0.0104\n",
      "Epoch 196/200, Iteration 128/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 129/250, Loss: 0.0263\n",
      "Epoch 196/200, Iteration 130/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 131/250, Loss: 0.0145\n",
      "Epoch 196/200, Iteration 132/250, Loss: 0.0121\n",
      "Epoch 196/200, Iteration 133/250, Loss: 0.0086\n",
      "Epoch 196/200, Iteration 134/250, Loss: 0.0264\n",
      "Epoch 196/200, Iteration 135/250, Loss: 0.0167\n",
      "Epoch 196/200, Iteration 136/250, Loss: 0.0202\n",
      "Epoch 196/200, Iteration 137/250, Loss: 0.0054\n",
      "Epoch 196/200, Iteration 138/250, Loss: 0.0314\n",
      "Epoch 196/200, Iteration 139/250, Loss: 0.0264\n",
      "Epoch 196/200, Iteration 140/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 141/250, Loss: 0.0066\n",
      "Epoch 196/200, Iteration 142/250, Loss: 0.0129\n",
      "Epoch 196/200, Iteration 143/250, Loss: 0.0065\n",
      "Epoch 196/200, Iteration 144/250, Loss: 0.0120\n",
      "Epoch 196/200, Iteration 145/250, Loss: 0.0245\n",
      "Epoch 196/200, Iteration 146/250, Loss: 0.0112\n",
      "Epoch 196/200, Iteration 147/250, Loss: 0.0148\n",
      "Epoch 196/200, Iteration 148/250, Loss: 0.0090\n",
      "Epoch 196/200, Iteration 149/250, Loss: 0.0175\n",
      "Epoch 196/200, Iteration 150/250, Loss: 0.0099\n",
      "Epoch 196/200, Iteration 151/250, Loss: 0.0131\n",
      "Epoch 196/200, Iteration 152/250, Loss: 0.0128\n",
      "Epoch 196/200, Iteration 153/250, Loss: 0.0302\n",
      "Epoch 196/200, Iteration 154/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 155/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 156/250, Loss: 0.0496\n",
      "Epoch 196/200, Iteration 157/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 158/250, Loss: 0.0193\n",
      "Epoch 196/200, Iteration 159/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 160/250, Loss: 0.0234\n",
      "Epoch 196/200, Iteration 161/250, Loss: 0.0183\n",
      "Epoch 196/200, Iteration 162/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 163/250, Loss: 0.0276\n",
      "Epoch 196/200, Iteration 164/250, Loss: 0.0172\n",
      "Epoch 196/200, Iteration 165/250, Loss: 0.0116\n",
      "Epoch 196/200, Iteration 166/250, Loss: 0.0138\n",
      "Epoch 196/200, Iteration 167/250, Loss: 0.0127\n",
      "Epoch 196/200, Iteration 168/250, Loss: 0.0090\n",
      "Epoch 196/200, Iteration 169/250, Loss: 0.0134\n",
      "Epoch 196/200, Iteration 170/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 171/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 172/250, Loss: 0.0108\n",
      "Epoch 196/200, Iteration 173/250, Loss: 0.0215\n",
      "Epoch 196/200, Iteration 174/250, Loss: 0.0099\n",
      "Epoch 196/200, Iteration 175/250, Loss: 0.0076\n",
      "Epoch 196/200, Iteration 176/250, Loss: 0.0210\n",
      "Epoch 196/200, Iteration 177/250, Loss: 0.0137\n",
      "Epoch 196/200, Iteration 178/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 179/250, Loss: 0.0239\n",
      "Epoch 196/200, Iteration 180/250, Loss: 0.0129\n",
      "Epoch 196/200, Iteration 181/250, Loss: 0.0077\n",
      "Epoch 196/200, Iteration 182/250, Loss: 0.0137\n",
      "Epoch 196/200, Iteration 183/250, Loss: 0.0111\n",
      "Epoch 196/200, Iteration 184/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 185/250, Loss: 0.0132\n",
      "Epoch 196/200, Iteration 186/250, Loss: 0.0107\n",
      "Epoch 196/200, Iteration 187/250, Loss: 0.0149\n",
      "Epoch 196/200, Iteration 188/250, Loss: 0.0142\n",
      "Epoch 196/200, Iteration 189/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 190/250, Loss: 0.0107\n",
      "Epoch 196/200, Iteration 191/250, Loss: 0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200, Iteration 192/250, Loss: 0.0120\n",
      "Epoch 196/200, Iteration 193/250, Loss: 0.0165\n",
      "Epoch 196/200, Iteration 194/250, Loss: 0.0200\n",
      "Epoch 196/200, Iteration 195/250, Loss: 0.0240\n",
      "Epoch 196/200, Iteration 196/250, Loss: 0.0160\n",
      "Epoch 196/200, Iteration 197/250, Loss: 0.0357\n",
      "Epoch 196/200, Iteration 198/250, Loss: 0.0128\n",
      "Epoch 196/200, Iteration 199/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 200/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 201/250, Loss: 0.0097\n",
      "Epoch 196/200, Iteration 202/250, Loss: 0.0093\n",
      "Epoch 196/200, Iteration 203/250, Loss: 0.0195\n",
      "Epoch 196/200, Iteration 204/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 205/250, Loss: 0.0500\n",
      "Epoch 196/200, Iteration 206/250, Loss: 0.0101\n",
      "Epoch 196/200, Iteration 207/250, Loss: 0.0125\n",
      "Epoch 196/200, Iteration 208/250, Loss: 0.0151\n",
      "Epoch 196/200, Iteration 209/250, Loss: 0.0384\n",
      "Epoch 196/200, Iteration 210/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 211/250, Loss: 0.0216\n",
      "Epoch 196/200, Iteration 212/250, Loss: 0.0369\n",
      "Epoch 196/200, Iteration 213/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 214/250, Loss: 0.0146\n",
      "Epoch 196/200, Iteration 215/250, Loss: 0.0109\n",
      "Epoch 196/200, Iteration 216/250, Loss: 0.0186\n",
      "Epoch 196/200, Iteration 217/250, Loss: 0.0082\n",
      "Epoch 196/200, Iteration 218/250, Loss: 0.0063\n",
      "Epoch 196/200, Iteration 219/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 220/250, Loss: 0.0243\n",
      "Epoch 196/200, Iteration 221/250, Loss: 0.0145\n",
      "Epoch 196/200, Iteration 222/250, Loss: 0.0143\n",
      "Epoch 196/200, Iteration 223/250, Loss: 0.0105\n",
      "Epoch 196/200, Iteration 224/250, Loss: 0.0299\n",
      "Epoch 196/200, Iteration 225/250, Loss: 0.0079\n",
      "Epoch 196/200, Iteration 226/250, Loss: 0.0091\n",
      "Epoch 196/200, Iteration 227/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 228/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 229/250, Loss: 0.0124\n",
      "Epoch 196/200, Iteration 230/250, Loss: 0.0072\n",
      "Epoch 196/200, Iteration 231/250, Loss: 0.0258\n",
      "Epoch 196/200, Iteration 232/250, Loss: 0.0110\n",
      "Epoch 196/200, Iteration 233/250, Loss: 0.0107\n",
      "Epoch 196/200, Iteration 234/250, Loss: 0.0111\n",
      "Epoch 196/200, Iteration 235/250, Loss: 0.0267\n",
      "Epoch 196/200, Iteration 236/250, Loss: 0.0119\n",
      "Epoch 196/200, Iteration 237/250, Loss: 0.0106\n",
      "Epoch 196/200, Iteration 238/250, Loss: 0.0115\n",
      "Epoch 196/200, Iteration 239/250, Loss: 0.0186\n",
      "Epoch 196/200, Iteration 240/250, Loss: 0.0114\n",
      "Epoch 196/200, Iteration 241/250, Loss: 0.0126\n",
      "Epoch 196/200, Iteration 242/250, Loss: 0.0087\n",
      "Epoch 196/200, Iteration 243/250, Loss: 0.0117\n",
      "Epoch 196/200, Iteration 244/250, Loss: 0.0123\n",
      "Epoch 196/200, Iteration 245/250, Loss: 0.0092\n",
      "Epoch 196/200, Iteration 246/250, Loss: 0.0125\n",
      "Epoch 196/200, Iteration 247/250, Loss: 0.0158\n",
      "Epoch 196/200, Iteration 248/250, Loss: 0.0118\n",
      "Epoch 196/200, Iteration 249/250, Loss: 0.0127\n",
      "Epoch 196/200, Iteration 250/250, Loss: 0.0136\n",
      "Train Error: \n",
      " Accuracy: 96.62%, Avg loss: 0.008424, MRE: 0.576407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.009073, MRE: 0.549814 \n",
      "\n",
      "Epoch 197/200, Iteration 1/250, Loss: 0.0216\n",
      "Epoch 197/200, Iteration 2/250, Loss: 0.0066\n",
      "Epoch 197/200, Iteration 3/250, Loss: 0.0114\n",
      "Epoch 197/200, Iteration 4/250, Loss: 0.0291\n",
      "Epoch 197/200, Iteration 5/250, Loss: 0.0201\n",
      "Epoch 197/200, Iteration 6/250, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 7/250, Loss: 0.0124\n",
      "Epoch 197/200, Iteration 8/250, Loss: 0.0084\n",
      "Epoch 197/200, Iteration 9/250, Loss: 0.0141\n",
      "Epoch 197/200, Iteration 10/250, Loss: 0.0437\n",
      "Epoch 197/200, Iteration 11/250, Loss: 0.0079\n",
      "Epoch 197/200, Iteration 12/250, Loss: 0.0110\n",
      "Epoch 197/200, Iteration 13/250, Loss: 0.0322\n",
      "Epoch 197/200, Iteration 14/250, Loss: 0.0135\n",
      "Epoch 197/200, Iteration 15/250, Loss: 0.0113\n",
      "Epoch 197/200, Iteration 16/250, Loss: 0.0144\n",
      "Epoch 197/200, Iteration 17/250, Loss: 0.0100\n",
      "Epoch 197/200, Iteration 18/250, Loss: 0.0440\n",
      "Epoch 197/200, Iteration 19/250, Loss: 0.0138\n",
      "Epoch 197/200, Iteration 20/250, Loss: 0.0179\n",
      "Epoch 197/200, Iteration 21/250, Loss: 0.0063\n",
      "Epoch 197/200, Iteration 22/250, Loss: 0.0217\n",
      "Epoch 197/200, Iteration 23/250, Loss: 0.0096\n",
      "Epoch 197/200, Iteration 24/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 25/250, Loss: 0.0090\n",
      "Epoch 197/200, Iteration 26/250, Loss: 0.0089\n",
      "Epoch 197/200, Iteration 27/250, Loss: 0.0167\n",
      "Epoch 197/200, Iteration 28/250, Loss: 0.0169\n",
      "Epoch 197/200, Iteration 29/250, Loss: 0.0146\n",
      "Epoch 197/200, Iteration 30/250, Loss: 0.0100\n",
      "Epoch 197/200, Iteration 31/250, Loss: 0.0123\n",
      "Epoch 197/200, Iteration 32/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 33/250, Loss: 0.0212\n",
      "Epoch 197/200, Iteration 34/250, Loss: 0.0185\n",
      "Epoch 197/200, Iteration 35/250, Loss: 0.0084\n",
      "Epoch 197/200, Iteration 36/250, Loss: 0.0089\n",
      "Epoch 197/200, Iteration 37/250, Loss: 0.0113\n",
      "Epoch 197/200, Iteration 38/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 39/250, Loss: 0.0083\n",
      "Epoch 197/200, Iteration 40/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 41/250, Loss: 0.0178\n",
      "Epoch 197/200, Iteration 42/250, Loss: 0.0107\n",
      "Epoch 197/200, Iteration 43/250, Loss: 0.0117\n",
      "Epoch 197/200, Iteration 44/250, Loss: 0.0077\n",
      "Epoch 197/200, Iteration 45/250, Loss: 0.0180\n",
      "Epoch 197/200, Iteration 46/250, Loss: 0.0312\n",
      "Epoch 197/200, Iteration 47/250, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 48/250, Loss: 0.0087\n",
      "Epoch 197/200, Iteration 49/250, Loss: 0.0077\n",
      "Epoch 197/200, Iteration 50/250, Loss: 0.0208\n",
      "Epoch 197/200, Iteration 51/250, Loss: 0.0201\n",
      "Epoch 197/200, Iteration 52/250, Loss: 0.0070\n",
      "Epoch 197/200, Iteration 53/250, Loss: 0.0085\n",
      "Epoch 197/200, Iteration 54/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 55/250, Loss: 0.0133\n",
      "Epoch 197/200, Iteration 56/250, Loss: 0.0137\n",
      "Epoch 197/200, Iteration 57/250, Loss: 0.0068\n",
      "Epoch 197/200, Iteration 58/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 59/250, Loss: 0.0266\n",
      "Epoch 197/200, Iteration 60/250, Loss: 0.0119\n",
      "Epoch 197/200, Iteration 61/250, Loss: 0.0111\n",
      "Epoch 197/200, Iteration 62/250, Loss: 0.0167\n",
      "Epoch 197/200, Iteration 63/250, Loss: 0.0149\n",
      "Epoch 197/200, Iteration 64/250, Loss: 0.0262\n",
      "Epoch 197/200, Iteration 65/250, Loss: 0.0079\n",
      "Epoch 197/200, Iteration 66/250, Loss: 0.0180\n",
      "Epoch 197/200, Iteration 67/250, Loss: 0.0162\n",
      "Epoch 197/200, Iteration 68/250, Loss: 0.0195\n",
      "Epoch 197/200, Iteration 69/250, Loss: 0.0078\n",
      "Epoch 197/200, Iteration 70/250, Loss: 0.0169\n",
      "Epoch 197/200, Iteration 71/250, Loss: 0.0179\n",
      "Epoch 197/200, Iteration 72/250, Loss: 0.0132\n",
      "Epoch 197/200, Iteration 73/250, Loss: 0.0151\n",
      "Epoch 197/200, Iteration 74/250, Loss: 0.0167\n",
      "Epoch 197/200, Iteration 75/250, Loss: 0.0102\n",
      "Epoch 197/200, Iteration 76/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 77/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 78/250, Loss: 0.0253\n",
      "Epoch 197/200, Iteration 79/250, Loss: 0.0404\n",
      "Epoch 197/200, Iteration 80/250, Loss: 0.0082\n",
      "Epoch 197/200, Iteration 81/250, Loss: 0.0098\n",
      "Epoch 197/200, Iteration 82/250, Loss: 0.0275\n",
      "Epoch 197/200, Iteration 83/250, Loss: 0.0279\n",
      "Epoch 197/200, Iteration 84/250, Loss: 0.0130\n",
      "Epoch 197/200, Iteration 85/250, Loss: 0.0274\n",
      "Epoch 197/200, Iteration 86/250, Loss: 0.0295\n",
      "Epoch 197/200, Iteration 87/250, Loss: 0.0101\n",
      "Epoch 197/200, Iteration 88/250, Loss: 0.0138\n",
      "Epoch 197/200, Iteration 89/250, Loss: 0.0279\n",
      "Epoch 197/200, Iteration 90/250, Loss: 0.0205\n",
      "Epoch 197/200, Iteration 91/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 92/250, Loss: 0.0331\n",
      "Epoch 197/200, Iteration 93/250, Loss: 0.0159\n",
      "Epoch 197/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 197/200, Iteration 95/250, Loss: 0.0214\n",
      "Epoch 197/200, Iteration 96/250, Loss: 0.0227\n",
      "Epoch 197/200, Iteration 97/250, Loss: 0.0113\n",
      "Epoch 197/200, Iteration 98/250, Loss: 0.0077\n",
      "Epoch 197/200, Iteration 99/250, Loss: 0.0272\n",
      "Epoch 197/200, Iteration 100/250, Loss: 0.0079\n",
      "Epoch 197/200, Iteration 101/250, Loss: 0.0202\n",
      "Epoch 197/200, Iteration 102/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 103/250, Loss: 0.0198\n",
      "Epoch 197/200, Iteration 104/250, Loss: 0.0117\n",
      "Epoch 197/200, Iteration 105/250, Loss: 0.0124\n",
      "Epoch 197/200, Iteration 106/250, Loss: 0.0094\n",
      "Epoch 197/200, Iteration 107/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 108/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 109/250, Loss: 0.0329\n",
      "Epoch 197/200, Iteration 110/250, Loss: 0.0162\n",
      "Epoch 197/200, Iteration 111/250, Loss: 0.0147\n",
      "Epoch 197/200, Iteration 112/250, Loss: 0.0060\n",
      "Epoch 197/200, Iteration 113/250, Loss: 0.0145\n",
      "Epoch 197/200, Iteration 114/250, Loss: 0.0154\n",
      "Epoch 197/200, Iteration 115/250, Loss: 0.0282\n",
      "Epoch 197/200, Iteration 116/250, Loss: 0.0207\n",
      "Epoch 197/200, Iteration 117/250, Loss: 0.0236\n",
      "Epoch 197/200, Iteration 118/250, Loss: 0.0219\n",
      "Epoch 197/200, Iteration 119/250, Loss: 0.0081\n",
      "Epoch 197/200, Iteration 120/250, Loss: 0.0089\n",
      "Epoch 197/200, Iteration 121/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 122/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 123/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 124/250, Loss: 0.0127\n",
      "Epoch 197/200, Iteration 125/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 126/250, Loss: 0.0110\n",
      "Epoch 197/200, Iteration 127/250, Loss: 0.0111\n",
      "Epoch 197/200, Iteration 128/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 129/250, Loss: 0.0207\n",
      "Epoch 197/200, Iteration 130/250, Loss: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200, Iteration 131/250, Loss: 0.0178\n",
      "Epoch 197/200, Iteration 132/250, Loss: 0.0139\n",
      "Epoch 197/200, Iteration 133/250, Loss: 0.0076\n",
      "Epoch 197/200, Iteration 134/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 135/250, Loss: 0.0119\n",
      "Epoch 197/200, Iteration 136/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 137/250, Loss: 0.0194\n",
      "Epoch 197/200, Iteration 138/250, Loss: 0.0183\n",
      "Epoch 197/200, Iteration 139/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 140/250, Loss: 0.0123\n",
      "Epoch 197/200, Iteration 141/250, Loss: 0.0277\n",
      "Epoch 197/200, Iteration 142/250, Loss: 0.0269\n",
      "Epoch 197/200, Iteration 143/250, Loss: 0.0155\n",
      "Epoch 197/200, Iteration 144/250, Loss: 0.0262\n",
      "Epoch 197/200, Iteration 145/250, Loss: 0.0333\n",
      "Epoch 197/200, Iteration 146/250, Loss: 0.0150\n",
      "Epoch 197/200, Iteration 147/250, Loss: 0.0083\n",
      "Epoch 197/200, Iteration 148/250, Loss: 0.0104\n",
      "Epoch 197/200, Iteration 149/250, Loss: 0.0072\n",
      "Epoch 197/200, Iteration 150/250, Loss: 0.0114\n",
      "Epoch 197/200, Iteration 151/250, Loss: 0.0078\n",
      "Epoch 197/200, Iteration 152/250, Loss: 0.0053\n",
      "Epoch 197/200, Iteration 153/250, Loss: 0.0223\n",
      "Epoch 197/200, Iteration 154/250, Loss: 0.0089\n",
      "Epoch 197/200, Iteration 155/250, Loss: 0.0074\n",
      "Epoch 197/200, Iteration 156/250, Loss: 0.0266\n",
      "Epoch 197/200, Iteration 157/250, Loss: 0.0142\n",
      "Epoch 197/200, Iteration 158/250, Loss: 0.0313\n",
      "Epoch 197/200, Iteration 159/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 160/250, Loss: 0.0152\n",
      "Epoch 197/200, Iteration 161/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 162/250, Loss: 0.0123\n",
      "Epoch 197/200, Iteration 163/250, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 164/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 165/250, Loss: 0.0302\n",
      "Epoch 197/200, Iteration 166/250, Loss: 0.0197\n",
      "Epoch 197/200, Iteration 167/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 168/250, Loss: 0.0070\n",
      "Epoch 197/200, Iteration 169/250, Loss: 0.0060\n",
      "Epoch 197/200, Iteration 170/250, Loss: 0.0125\n",
      "Epoch 197/200, Iteration 171/250, Loss: 0.0104\n",
      "Epoch 197/200, Iteration 172/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 173/250, Loss: 0.0106\n",
      "Epoch 197/200, Iteration 174/250, Loss: 0.0181\n",
      "Epoch 197/200, Iteration 175/250, Loss: 0.0258\n",
      "Epoch 197/200, Iteration 176/250, Loss: 0.0093\n",
      "Epoch 197/200, Iteration 177/250, Loss: 0.0162\n",
      "Epoch 197/200, Iteration 178/250, Loss: 0.0273\n",
      "Epoch 197/200, Iteration 179/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 180/250, Loss: 0.0145\n",
      "Epoch 197/200, Iteration 181/250, Loss: 0.0187\n",
      "Epoch 197/200, Iteration 182/250, Loss: 0.0068\n",
      "Epoch 197/200, Iteration 183/250, Loss: 0.0261\n",
      "Epoch 197/200, Iteration 184/250, Loss: 0.0114\n",
      "Epoch 197/200, Iteration 185/250, Loss: 0.0327\n",
      "Epoch 197/200, Iteration 186/250, Loss: 0.0088\n",
      "Epoch 197/200, Iteration 187/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 188/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 189/250, Loss: 0.0149\n",
      "Epoch 197/200, Iteration 190/250, Loss: 0.0250\n",
      "Epoch 197/200, Iteration 191/250, Loss: 0.0140\n",
      "Epoch 197/200, Iteration 192/250, Loss: 0.0055\n",
      "Epoch 197/200, Iteration 193/250, Loss: 0.0139\n",
      "Epoch 197/200, Iteration 194/250, Loss: 0.0160\n",
      "Epoch 197/200, Iteration 195/250, Loss: 0.0338\n",
      "Epoch 197/200, Iteration 196/250, Loss: 0.0255\n",
      "Epoch 197/200, Iteration 197/250, Loss: 0.0129\n",
      "Epoch 197/200, Iteration 198/250, Loss: 0.0091\n",
      "Epoch 197/200, Iteration 199/250, Loss: 0.0121\n",
      "Epoch 197/200, Iteration 200/250, Loss: 0.0227\n",
      "Epoch 197/200, Iteration 201/250, Loss: 0.0098\n",
      "Epoch 197/200, Iteration 202/250, Loss: 0.0173\n",
      "Epoch 197/200, Iteration 203/250, Loss: 0.0140\n",
      "Epoch 197/200, Iteration 204/250, Loss: 0.0265\n",
      "Epoch 197/200, Iteration 205/250, Loss: 0.0186\n",
      "Epoch 197/200, Iteration 206/250, Loss: 0.0116\n",
      "Epoch 197/200, Iteration 207/250, Loss: 0.0196\n",
      "Epoch 197/200, Iteration 208/250, Loss: 0.0323\n",
      "Epoch 197/200, Iteration 209/250, Loss: 0.0241\n",
      "Epoch 197/200, Iteration 210/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 211/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 212/250, Loss: 0.0123\n",
      "Epoch 197/200, Iteration 213/250, Loss: 0.0117\n",
      "Epoch 197/200, Iteration 214/250, Loss: 0.0106\n",
      "Epoch 197/200, Iteration 215/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 216/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 217/250, Loss: 0.0139\n",
      "Epoch 197/200, Iteration 218/250, Loss: 0.0094\n",
      "Epoch 197/200, Iteration 219/250, Loss: 0.0150\n",
      "Epoch 197/200, Iteration 220/250, Loss: 0.0112\n",
      "Epoch 197/200, Iteration 221/250, Loss: 0.0128\n",
      "Epoch 197/200, Iteration 222/250, Loss: 0.0155\n",
      "Epoch 197/200, Iteration 223/250, Loss: 0.0079\n",
      "Epoch 197/200, Iteration 224/250, Loss: 0.0100\n",
      "Epoch 197/200, Iteration 225/250, Loss: 0.0251\n",
      "Epoch 197/200, Iteration 226/250, Loss: 0.0229\n",
      "Epoch 197/200, Iteration 227/250, Loss: 0.0067\n",
      "Epoch 197/200, Iteration 228/250, Loss: 0.0126\n",
      "Epoch 197/200, Iteration 229/250, Loss: 0.0144\n",
      "Epoch 197/200, Iteration 230/250, Loss: 0.0188\n",
      "Epoch 197/200, Iteration 231/250, Loss: 0.0363\n",
      "Epoch 197/200, Iteration 232/250, Loss: 0.0108\n",
      "Epoch 197/200, Iteration 233/250, Loss: 0.0151\n",
      "Epoch 197/200, Iteration 234/250, Loss: 0.0151\n",
      "Epoch 197/200, Iteration 235/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 236/250, Loss: 0.0258\n",
      "Epoch 197/200, Iteration 237/250, Loss: 0.0136\n",
      "Epoch 197/200, Iteration 238/250, Loss: 0.0151\n",
      "Epoch 197/200, Iteration 239/250, Loss: 0.0286\n",
      "Epoch 197/200, Iteration 240/250, Loss: 0.0061\n",
      "Epoch 197/200, Iteration 241/250, Loss: 0.0244\n",
      "Epoch 197/200, Iteration 242/250, Loss: 0.0144\n",
      "Epoch 197/200, Iteration 243/250, Loss: 0.0109\n",
      "Epoch 197/200, Iteration 244/250, Loss: 0.0092\n",
      "Epoch 197/200, Iteration 245/250, Loss: 0.0095\n",
      "Epoch 197/200, Iteration 246/250, Loss: 0.0355\n",
      "Epoch 197/200, Iteration 247/250, Loss: 0.0105\n",
      "Epoch 197/200, Iteration 248/250, Loss: 0.0155\n",
      "Epoch 197/200, Iteration 249/250, Loss: 0.0097\n",
      "Epoch 197/200, Iteration 250/250, Loss: 0.0082\n",
      "Train Error: \n",
      " Accuracy: 92.92%, Avg loss: 0.007087, MRE: 0.412029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.007580, MRE: 0.468503 \n",
      "\n",
      "Epoch 198/200, Iteration 1/250, Loss: 0.0085\n",
      "Epoch 198/200, Iteration 2/250, Loss: 0.0207\n",
      "Epoch 198/200, Iteration 3/250, Loss: 0.0250\n",
      "Epoch 198/200, Iteration 4/250, Loss: 0.0087\n",
      "Epoch 198/200, Iteration 5/250, Loss: 0.0216\n",
      "Epoch 198/200, Iteration 6/250, Loss: 0.0095\n",
      "Epoch 198/200, Iteration 7/250, Loss: 0.0194\n",
      "Epoch 198/200, Iteration 8/250, Loss: 0.0164\n",
      "Epoch 198/200, Iteration 9/250, Loss: 0.0208\n",
      "Epoch 198/200, Iteration 10/250, Loss: 0.0084\n",
      "Epoch 198/200, Iteration 11/250, Loss: 0.0133\n",
      "Epoch 198/200, Iteration 12/250, Loss: 0.0085\n",
      "Epoch 198/200, Iteration 13/250, Loss: 0.0091\n",
      "Epoch 198/200, Iteration 14/250, Loss: 0.0073\n",
      "Epoch 198/200, Iteration 15/250, Loss: 0.0428\n",
      "Epoch 198/200, Iteration 16/250, Loss: 0.0149\n",
      "Epoch 198/200, Iteration 17/250, Loss: 0.0133\n",
      "Epoch 198/200, Iteration 18/250, Loss: 0.0116\n",
      "Epoch 198/200, Iteration 19/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 20/250, Loss: 0.0092\n",
      "Epoch 198/200, Iteration 21/250, Loss: 0.0067\n",
      "Epoch 198/200, Iteration 22/250, Loss: 0.0243\n",
      "Epoch 198/200, Iteration 23/250, Loss: 0.0136\n",
      "Epoch 198/200, Iteration 24/250, Loss: 0.0086\n",
      "Epoch 198/200, Iteration 25/250, Loss: 0.0169\n",
      "Epoch 198/200, Iteration 26/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 27/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 28/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 29/250, Loss: 0.0131\n",
      "Epoch 198/200, Iteration 30/250, Loss: 0.0205\n",
      "Epoch 198/200, Iteration 31/250, Loss: 0.0188\n",
      "Epoch 198/200, Iteration 32/250, Loss: 0.0174\n",
      "Epoch 198/200, Iteration 33/250, Loss: 0.0156\n",
      "Epoch 198/200, Iteration 34/250, Loss: 0.0155\n",
      "Epoch 198/200, Iteration 35/250, Loss: 0.0287\n",
      "Epoch 198/200, Iteration 36/250, Loss: 0.0241\n",
      "Epoch 198/200, Iteration 37/250, Loss: 0.0106\n",
      "Epoch 198/200, Iteration 38/250, Loss: 0.0139\n",
      "Epoch 198/200, Iteration 39/250, Loss: 0.0256\n",
      "Epoch 198/200, Iteration 40/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 41/250, Loss: 0.0174\n",
      "Epoch 198/200, Iteration 42/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 43/250, Loss: 0.0170\n",
      "Epoch 198/200, Iteration 44/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 45/250, Loss: 0.0067\n",
      "Epoch 198/200, Iteration 46/250, Loss: 0.0111\n",
      "Epoch 198/200, Iteration 47/250, Loss: 0.0117\n",
      "Epoch 198/200, Iteration 48/250, Loss: 0.0162\n",
      "Epoch 198/200, Iteration 49/250, Loss: 0.0075\n",
      "Epoch 198/200, Iteration 50/250, Loss: 0.0124\n",
      "Epoch 198/200, Iteration 51/250, Loss: 0.0215\n",
      "Epoch 198/200, Iteration 52/250, Loss: 0.0106\n",
      "Epoch 198/200, Iteration 53/250, Loss: 0.0123\n",
      "Epoch 198/200, Iteration 54/250, Loss: 0.0074\n",
      "Epoch 198/200, Iteration 55/250, Loss: 0.0203\n",
      "Epoch 198/200, Iteration 56/250, Loss: 0.0217\n",
      "Epoch 198/200, Iteration 57/250, Loss: 0.0359\n",
      "Epoch 198/200, Iteration 58/250, Loss: 0.0156\n",
      "Epoch 198/200, Iteration 59/250, Loss: 0.0238\n",
      "Epoch 198/200, Iteration 60/250, Loss: 0.0172\n",
      "Epoch 198/200, Iteration 61/250, Loss: 0.0242\n",
      "Epoch 198/200, Iteration 62/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 63/250, Loss: 0.0115\n",
      "Epoch 198/200, Iteration 64/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 65/250, Loss: 0.0097\n",
      "Epoch 198/200, Iteration 66/250, Loss: 0.0104\n",
      "Epoch 198/200, Iteration 67/250, Loss: 0.0062\n",
      "Epoch 198/200, Iteration 68/250, Loss: 0.0125\n",
      "Epoch 198/200, Iteration 69/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 70/250, Loss: 0.0259\n",
      "Epoch 198/200, Iteration 71/250, Loss: 0.0068\n",
      "Epoch 198/200, Iteration 72/250, Loss: 0.0342\n",
      "Epoch 198/200, Iteration 73/250, Loss: 0.0145\n",
      "Epoch 198/200, Iteration 74/250, Loss: 0.0228\n",
      "Epoch 198/200, Iteration 75/250, Loss: 0.0119\n",
      "Epoch 198/200, Iteration 76/250, Loss: 0.0226\n",
      "Epoch 198/200, Iteration 77/250, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200, Iteration 78/250, Loss: 0.0380\n",
      "Epoch 198/200, Iteration 79/250, Loss: 0.0124\n",
      "Epoch 198/200, Iteration 80/250, Loss: 0.0117\n",
      "Epoch 198/200, Iteration 81/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 82/250, Loss: 0.0108\n",
      "Epoch 198/200, Iteration 83/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 84/250, Loss: 0.0140\n",
      "Epoch 198/200, Iteration 85/250, Loss: 0.0158\n",
      "Epoch 198/200, Iteration 86/250, Loss: 0.0081\n",
      "Epoch 198/200, Iteration 87/250, Loss: 0.0204\n",
      "Epoch 198/200, Iteration 88/250, Loss: 0.0074\n",
      "Epoch 198/200, Iteration 89/250, Loss: 0.0135\n",
      "Epoch 198/200, Iteration 90/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 91/250, Loss: 0.0193\n",
      "Epoch 198/200, Iteration 92/250, Loss: 0.0129\n",
      "Epoch 198/200, Iteration 93/250, Loss: 0.0195\n",
      "Epoch 198/200, Iteration 94/250, Loss: 0.0168\n",
      "Epoch 198/200, Iteration 95/250, Loss: 0.0106\n",
      "Epoch 198/200, Iteration 96/250, Loss: 0.0103\n",
      "Epoch 198/200, Iteration 97/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 98/250, Loss: 0.0149\n",
      "Epoch 198/200, Iteration 99/250, Loss: 0.0262\n",
      "Epoch 198/200, Iteration 100/250, Loss: 0.0210\n",
      "Epoch 198/200, Iteration 101/250, Loss: 0.0186\n",
      "Epoch 198/200, Iteration 102/250, Loss: 0.0123\n",
      "Epoch 198/200, Iteration 103/250, Loss: 0.0078\n",
      "Epoch 198/200, Iteration 104/250, Loss: 0.0270\n",
      "Epoch 198/200, Iteration 105/250, Loss: 0.0087\n",
      "Epoch 198/200, Iteration 106/250, Loss: 0.0184\n",
      "Epoch 198/200, Iteration 107/250, Loss: 0.0271\n",
      "Epoch 198/200, Iteration 108/250, Loss: 0.0140\n",
      "Epoch 198/200, Iteration 109/250, Loss: 0.0153\n",
      "Epoch 198/200, Iteration 110/250, Loss: 0.0135\n",
      "Epoch 198/200, Iteration 111/250, Loss: 0.0175\n",
      "Epoch 198/200, Iteration 112/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 113/250, Loss: 0.0183\n",
      "Epoch 198/200, Iteration 114/250, Loss: 0.0150\n",
      "Epoch 198/200, Iteration 115/250, Loss: 0.0183\n",
      "Epoch 198/200, Iteration 116/250, Loss: 0.0153\n",
      "Epoch 198/200, Iteration 117/250, Loss: 0.0075\n",
      "Epoch 198/200, Iteration 118/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 119/250, Loss: 0.0364\n",
      "Epoch 198/200, Iteration 120/250, Loss: 0.0125\n",
      "Epoch 198/200, Iteration 121/250, Loss: 0.0148\n",
      "Epoch 198/200, Iteration 122/250, Loss: 0.0087\n",
      "Epoch 198/200, Iteration 123/250, Loss: 0.0074\n",
      "Epoch 198/200, Iteration 124/250, Loss: 0.0162\n",
      "Epoch 198/200, Iteration 125/250, Loss: 0.0304\n",
      "Epoch 198/200, Iteration 126/250, Loss: 0.0112\n",
      "Epoch 198/200, Iteration 127/250, Loss: 0.0084\n",
      "Epoch 198/200, Iteration 128/250, Loss: 0.0155\n",
      "Epoch 198/200, Iteration 129/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 130/250, Loss: 0.0141\n",
      "Epoch 198/200, Iteration 131/250, Loss: 0.0176\n",
      "Epoch 198/200, Iteration 132/250, Loss: 0.0148\n",
      "Epoch 198/200, Iteration 133/250, Loss: 0.0067\n",
      "Epoch 198/200, Iteration 134/250, Loss: 0.0076\n",
      "Epoch 198/200, Iteration 135/250, Loss: 0.0200\n",
      "Epoch 198/200, Iteration 136/250, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 137/250, Loss: 0.0314\n",
      "Epoch 198/200, Iteration 138/250, Loss: 0.0107\n",
      "Epoch 198/200, Iteration 139/250, Loss: 0.0099\n",
      "Epoch 198/200, Iteration 140/250, Loss: 0.0073\n",
      "Epoch 198/200, Iteration 141/250, Loss: 0.0077\n",
      "Epoch 198/200, Iteration 142/250, Loss: 0.0355\n",
      "Epoch 198/200, Iteration 143/250, Loss: 0.0085\n",
      "Epoch 198/200, Iteration 144/250, Loss: 0.0142\n",
      "Epoch 198/200, Iteration 145/250, Loss: 0.0173\n",
      "Epoch 198/200, Iteration 146/250, Loss: 0.0140\n",
      "Epoch 198/200, Iteration 147/250, Loss: 0.0090\n",
      "Epoch 198/200, Iteration 148/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 149/250, Loss: 0.0106\n",
      "Epoch 198/200, Iteration 150/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 151/250, Loss: 0.0159\n",
      "Epoch 198/200, Iteration 152/250, Loss: 0.0121\n",
      "Epoch 198/200, Iteration 153/250, Loss: 0.0094\n",
      "Epoch 198/200, Iteration 154/250, Loss: 0.0164\n",
      "Epoch 198/200, Iteration 155/250, Loss: 0.0165\n",
      "Epoch 198/200, Iteration 156/250, Loss: 0.0236\n",
      "Epoch 198/200, Iteration 157/250, Loss: 0.0379\n",
      "Epoch 198/200, Iteration 158/250, Loss: 0.0286\n",
      "Epoch 198/200, Iteration 159/250, Loss: 0.0177\n",
      "Epoch 198/200, Iteration 160/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 161/250, Loss: 0.0149\n",
      "Epoch 198/200, Iteration 162/250, Loss: 0.0128\n",
      "Epoch 198/200, Iteration 163/250, Loss: 0.0203\n",
      "Epoch 198/200, Iteration 164/250, Loss: 0.0271\n",
      "Epoch 198/200, Iteration 165/250, Loss: 0.0110\n",
      "Epoch 198/200, Iteration 166/250, Loss: 0.0340\n",
      "Epoch 198/200, Iteration 167/250, Loss: 0.0205\n",
      "Epoch 198/200, Iteration 168/250, Loss: 0.0179\n",
      "Epoch 198/200, Iteration 169/250, Loss: 0.0233\n",
      "Epoch 198/200, Iteration 170/250, Loss: 0.0101\n",
      "Epoch 198/200, Iteration 171/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 172/250, Loss: 0.0096\n",
      "Epoch 198/200, Iteration 173/250, Loss: 0.0149\n",
      "Epoch 198/200, Iteration 174/250, Loss: 0.0067\n",
      "Epoch 198/200, Iteration 175/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 176/250, Loss: 0.0079\n",
      "Epoch 198/200, Iteration 177/250, Loss: 0.0166\n",
      "Epoch 198/200, Iteration 178/250, Loss: 0.0186\n",
      "Epoch 198/200, Iteration 179/250, Loss: 0.0089\n",
      "Epoch 198/200, Iteration 180/250, Loss: 0.0169\n",
      "Epoch 198/200, Iteration 181/250, Loss: 0.0217\n",
      "Epoch 198/200, Iteration 182/250, Loss: 0.0197\n",
      "Epoch 198/200, Iteration 183/250, Loss: 0.0178\n",
      "Epoch 198/200, Iteration 184/250, Loss: 0.0101\n",
      "Epoch 198/200, Iteration 185/250, Loss: 0.0206\n",
      "Epoch 198/200, Iteration 186/250, Loss: 0.0154\n",
      "Epoch 198/200, Iteration 187/250, Loss: 0.0186\n",
      "Epoch 198/200, Iteration 188/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 189/250, Loss: 0.0227\n",
      "Epoch 198/200, Iteration 190/250, Loss: 0.0156\n",
      "Epoch 198/200, Iteration 191/250, Loss: 0.0142\n",
      "Epoch 198/200, Iteration 192/250, Loss: 0.0136\n",
      "Epoch 198/200, Iteration 193/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 194/250, Loss: 0.0082\n",
      "Epoch 198/200, Iteration 195/250, Loss: 0.0253\n",
      "Epoch 198/200, Iteration 196/250, Loss: 0.0196\n",
      "Epoch 198/200, Iteration 197/250, Loss: 0.0108\n",
      "Epoch 198/200, Iteration 198/250, Loss: 0.0161\n",
      "Epoch 198/200, Iteration 199/250, Loss: 0.0176\n",
      "Epoch 198/200, Iteration 200/250, Loss: 0.0191\n",
      "Epoch 198/200, Iteration 201/250, Loss: 0.0151\n",
      "Epoch 198/200, Iteration 202/250, Loss: 0.0073\n",
      "Epoch 198/200, Iteration 203/250, Loss: 0.0092\n",
      "Epoch 198/200, Iteration 204/250, Loss: 0.0221\n",
      "Epoch 198/200, Iteration 205/250, Loss: 0.0104\n",
      "Epoch 198/200, Iteration 206/250, Loss: 0.0218\n",
      "Epoch 198/200, Iteration 207/250, Loss: 0.0160\n",
      "Epoch 198/200, Iteration 208/250, Loss: 0.0219\n",
      "Epoch 198/200, Iteration 209/250, Loss: 0.0083\n",
      "Epoch 198/200, Iteration 210/250, Loss: 0.0120\n",
      "Epoch 198/200, Iteration 211/250, Loss: 0.0100\n",
      "Epoch 198/200, Iteration 212/250, Loss: 0.0091\n",
      "Epoch 198/200, Iteration 213/250, Loss: 0.0162\n",
      "Epoch 198/200, Iteration 214/250, Loss: 0.0239\n",
      "Epoch 198/200, Iteration 215/250, Loss: 0.0114\n",
      "Epoch 198/200, Iteration 216/250, Loss: 0.0181\n",
      "Epoch 198/200, Iteration 217/250, Loss: 0.0064\n",
      "Epoch 198/200, Iteration 218/250, Loss: 0.0122\n",
      "Epoch 198/200, Iteration 219/250, Loss: 0.0395\n",
      "Epoch 198/200, Iteration 220/250, Loss: 0.0072\n",
      "Epoch 198/200, Iteration 221/250, Loss: 0.0133\n",
      "Epoch 198/200, Iteration 222/250, Loss: 0.0098\n",
      "Epoch 198/200, Iteration 223/250, Loss: 0.0291\n",
      "Epoch 198/200, Iteration 224/250, Loss: 0.0189\n",
      "Epoch 198/200, Iteration 225/250, Loss: 0.0287\n",
      "Epoch 198/200, Iteration 226/250, Loss: 0.0136\n",
      "Epoch 198/200, Iteration 227/250, Loss: 0.0140\n",
      "Epoch 198/200, Iteration 228/250, Loss: 0.0231\n",
      "Epoch 198/200, Iteration 229/250, Loss: 0.0224\n",
      "Epoch 198/200, Iteration 230/250, Loss: 0.0091\n",
      "Epoch 198/200, Iteration 231/250, Loss: 0.0147\n",
      "Epoch 198/200, Iteration 232/250, Loss: 0.0172\n",
      "Epoch 198/200, Iteration 233/250, Loss: 0.0071\n",
      "Epoch 198/200, Iteration 234/250, Loss: 0.0071\n",
      "Epoch 198/200, Iteration 235/250, Loss: 0.0096\n",
      "Epoch 198/200, Iteration 236/250, Loss: 0.0289\n",
      "Epoch 198/200, Iteration 237/250, Loss: 0.0157\n",
      "Epoch 198/200, Iteration 238/250, Loss: 0.0295\n",
      "Epoch 198/200, Iteration 239/250, Loss: 0.0097\n",
      "Epoch 198/200, Iteration 240/250, Loss: 0.0115\n",
      "Epoch 198/200, Iteration 241/250, Loss: 0.0368\n",
      "Epoch 198/200, Iteration 242/250, Loss: 0.0080\n",
      "Epoch 198/200, Iteration 243/250, Loss: 0.0142\n",
      "Epoch 198/200, Iteration 244/250, Loss: 0.0097\n",
      "Epoch 198/200, Iteration 245/250, Loss: 0.0182\n",
      "Epoch 198/200, Iteration 246/250, Loss: 0.0067\n",
      "Epoch 198/200, Iteration 247/250, Loss: 0.0086\n",
      "Epoch 198/200, Iteration 248/250, Loss: 0.0088\n",
      "Epoch 198/200, Iteration 249/250, Loss: 0.0215\n",
      "Epoch 198/200, Iteration 250/250, Loss: 0.0098\n",
      "Train Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.006951, MRE: 0.474167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.45%, Avg loss: 0.007594, MRE: 0.501620 \n",
      "\n",
      "Epoch 199/200, Iteration 1/250, Loss: 0.0074\n",
      "Epoch 199/200, Iteration 2/250, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 3/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 4/250, Loss: 0.0189\n",
      "Epoch 199/200, Iteration 5/250, Loss: 0.0085\n",
      "Epoch 199/200, Iteration 6/250, Loss: 0.0191\n",
      "Epoch 199/200, Iteration 7/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 8/250, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200, Iteration 9/250, Loss: 0.0150\n",
      "Epoch 199/200, Iteration 10/250, Loss: 0.0138\n",
      "Epoch 199/200, Iteration 11/250, Loss: 0.0151\n",
      "Epoch 199/200, Iteration 12/250, Loss: 0.0119\n",
      "Epoch 199/200, Iteration 13/250, Loss: 0.0247\n",
      "Epoch 199/200, Iteration 14/250, Loss: 0.0083\n",
      "Epoch 199/200, Iteration 15/250, Loss: 0.0069\n",
      "Epoch 199/200, Iteration 16/250, Loss: 0.0135\n",
      "Epoch 199/200, Iteration 17/250, Loss: 0.0220\n",
      "Epoch 199/200, Iteration 18/250, Loss: 0.0114\n",
      "Epoch 199/200, Iteration 19/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 20/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 21/250, Loss: 0.0110\n",
      "Epoch 199/200, Iteration 22/250, Loss: 0.0077\n",
      "Epoch 199/200, Iteration 23/250, Loss: 0.0161\n",
      "Epoch 199/200, Iteration 24/250, Loss: 0.0435\n",
      "Epoch 199/200, Iteration 25/250, Loss: 0.0127\n",
      "Epoch 199/200, Iteration 26/250, Loss: 0.0071\n",
      "Epoch 199/200, Iteration 27/250, Loss: 0.0088\n",
      "Epoch 199/200, Iteration 28/250, Loss: 0.0132\n",
      "Epoch 199/200, Iteration 29/250, Loss: 0.0259\n",
      "Epoch 199/200, Iteration 30/250, Loss: 0.0298\n",
      "Epoch 199/200, Iteration 31/250, Loss: 0.0170\n",
      "Epoch 199/200, Iteration 32/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 33/250, Loss: 0.0163\n",
      "Epoch 199/200, Iteration 34/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 35/250, Loss: 0.0198\n",
      "Epoch 199/200, Iteration 36/250, Loss: 0.0192\n",
      "Epoch 199/200, Iteration 37/250, Loss: 0.0124\n",
      "Epoch 199/200, Iteration 38/250, Loss: 0.0096\n",
      "Epoch 199/200, Iteration 39/250, Loss: 0.0250\n",
      "Epoch 199/200, Iteration 40/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 41/250, Loss: 0.0119\n",
      "Epoch 199/200, Iteration 42/250, Loss: 0.0100\n",
      "Epoch 199/200, Iteration 43/250, Loss: 0.0341\n",
      "Epoch 199/200, Iteration 44/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 45/250, Loss: 0.0080\n",
      "Epoch 199/200, Iteration 46/250, Loss: 0.0141\n",
      "Epoch 199/200, Iteration 47/250, Loss: 0.0189\n",
      "Epoch 199/200, Iteration 48/250, Loss: 0.0250\n",
      "Epoch 199/200, Iteration 49/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 50/250, Loss: 0.0144\n",
      "Epoch 199/200, Iteration 51/250, Loss: 0.0207\n",
      "Epoch 199/200, Iteration 52/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 53/250, Loss: 0.0226\n",
      "Epoch 199/200, Iteration 54/250, Loss: 0.0091\n",
      "Epoch 199/200, Iteration 55/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 56/250, Loss: 0.0316\n",
      "Epoch 199/200, Iteration 57/250, Loss: 0.0211\n",
      "Epoch 199/200, Iteration 58/250, Loss: 0.0177\n",
      "Epoch 199/200, Iteration 59/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 60/250, Loss: 0.0118\n",
      "Epoch 199/200, Iteration 61/250, Loss: 0.0183\n",
      "Epoch 199/200, Iteration 62/250, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 63/250, Loss: 0.0457\n",
      "Epoch 199/200, Iteration 64/250, Loss: 0.0144\n",
      "Epoch 199/200, Iteration 65/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 66/250, Loss: 0.0171\n",
      "Epoch 199/200, Iteration 67/250, Loss: 0.0194\n",
      "Epoch 199/200, Iteration 68/250, Loss: 0.0132\n",
      "Epoch 199/200, Iteration 69/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 70/250, Loss: 0.0119\n",
      "Epoch 199/200, Iteration 71/250, Loss: 0.0083\n",
      "Epoch 199/200, Iteration 72/250, Loss: 0.0230\n",
      "Epoch 199/200, Iteration 73/250, Loss: 0.0184\n",
      "Epoch 199/200, Iteration 74/250, Loss: 0.0085\n",
      "Epoch 199/200, Iteration 75/250, Loss: 0.0148\n",
      "Epoch 199/200, Iteration 76/250, Loss: 0.0173\n",
      "Epoch 199/200, Iteration 77/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 78/250, Loss: 0.0187\n",
      "Epoch 199/200, Iteration 79/250, Loss: 0.0254\n",
      "Epoch 199/200, Iteration 80/250, Loss: 0.0189\n",
      "Epoch 199/200, Iteration 81/250, Loss: 0.0147\n",
      "Epoch 199/200, Iteration 82/250, Loss: 0.0161\n",
      "Epoch 199/200, Iteration 83/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 84/250, Loss: 0.0221\n",
      "Epoch 199/200, Iteration 85/250, Loss: 0.0093\n",
      "Epoch 199/200, Iteration 86/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 87/250, Loss: 0.0176\n",
      "Epoch 199/200, Iteration 88/250, Loss: 0.0120\n",
      "Epoch 199/200, Iteration 89/250, Loss: 0.0090\n",
      "Epoch 199/200, Iteration 90/250, Loss: 0.0131\n",
      "Epoch 199/200, Iteration 91/250, Loss: 0.0157\n",
      "Epoch 199/200, Iteration 92/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 93/250, Loss: 0.0181\n",
      "Epoch 199/200, Iteration 94/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 95/250, Loss: 0.0122\n",
      "Epoch 199/200, Iteration 96/250, Loss: 0.0124\n",
      "Epoch 199/200, Iteration 97/250, Loss: 0.0110\n",
      "Epoch 199/200, Iteration 98/250, Loss: 0.0101\n",
      "Epoch 199/200, Iteration 99/250, Loss: 0.0113\n",
      "Epoch 199/200, Iteration 100/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 101/250, Loss: 0.0095\n",
      "Epoch 199/200, Iteration 102/250, Loss: 0.0313\n",
      "Epoch 199/200, Iteration 103/250, Loss: 0.0079\n",
      "Epoch 199/200, Iteration 104/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 105/250, Loss: 0.0114\n",
      "Epoch 199/200, Iteration 106/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 107/250, Loss: 0.0132\n",
      "Epoch 199/200, Iteration 108/250, Loss: 0.0362\n",
      "Epoch 199/200, Iteration 109/250, Loss: 0.0145\n",
      "Epoch 199/200, Iteration 110/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 111/250, Loss: 0.0083\n",
      "Epoch 199/200, Iteration 112/250, Loss: 0.0124\n",
      "Epoch 199/200, Iteration 113/250, Loss: 0.0180\n",
      "Epoch 199/200, Iteration 114/250, Loss: 0.0209\n",
      "Epoch 199/200, Iteration 115/250, Loss: 0.0071\n",
      "Epoch 199/200, Iteration 116/250, Loss: 0.0138\n",
      "Epoch 199/200, Iteration 117/250, Loss: 0.0070\n",
      "Epoch 199/200, Iteration 118/250, Loss: 0.0092\n",
      "Epoch 199/200, Iteration 119/250, Loss: 0.0085\n",
      "Epoch 199/200, Iteration 120/250, Loss: 0.0188\n",
      "Epoch 199/200, Iteration 121/250, Loss: 0.0365\n",
      "Epoch 199/200, Iteration 122/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 123/250, Loss: 0.0181\n",
      "Epoch 199/200, Iteration 124/250, Loss: 0.0097\n",
      "Epoch 199/200, Iteration 125/250, Loss: 0.0102\n",
      "Epoch 199/200, Iteration 126/250, Loss: 0.0105\n",
      "Epoch 199/200, Iteration 127/250, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 128/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 129/250, Loss: 0.0151\n",
      "Epoch 199/200, Iteration 130/250, Loss: 0.0102\n",
      "Epoch 199/200, Iteration 131/250, Loss: 0.0174\n",
      "Epoch 199/200, Iteration 132/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 133/250, Loss: 0.0098\n",
      "Epoch 199/200, Iteration 134/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 135/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 136/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 137/250, Loss: 0.0137\n",
      "Epoch 199/200, Iteration 138/250, Loss: 0.0150\n",
      "Epoch 199/200, Iteration 139/250, Loss: 0.0122\n",
      "Epoch 199/200, Iteration 140/250, Loss: 0.0078\n",
      "Epoch 199/200, Iteration 141/250, Loss: 0.0076\n",
      "Epoch 199/200, Iteration 142/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 143/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 144/250, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 145/250, Loss: 0.0147\n",
      "Epoch 199/200, Iteration 146/250, Loss: 0.0227\n",
      "Epoch 199/200, Iteration 147/250, Loss: 0.0102\n",
      "Epoch 199/200, Iteration 148/250, Loss: 0.0101\n",
      "Epoch 199/200, Iteration 149/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 150/250, Loss: 0.0064\n",
      "Epoch 199/200, Iteration 151/250, Loss: 0.0141\n",
      "Epoch 199/200, Iteration 152/250, Loss: 0.0087\n",
      "Epoch 199/200, Iteration 153/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 154/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 155/250, Loss: 0.0230\n",
      "Epoch 199/200, Iteration 156/250, Loss: 0.0300\n",
      "Epoch 199/200, Iteration 157/250, Loss: 0.0162\n",
      "Epoch 199/200, Iteration 158/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 159/250, Loss: 0.0165\n",
      "Epoch 199/200, Iteration 160/250, Loss: 0.0137\n",
      "Epoch 199/200, Iteration 161/250, Loss: 0.0251\n",
      "Epoch 199/200, Iteration 162/250, Loss: 0.0115\n",
      "Epoch 199/200, Iteration 163/250, Loss: 0.0137\n",
      "Epoch 199/200, Iteration 164/250, Loss: 0.0212\n",
      "Epoch 199/200, Iteration 165/250, Loss: 0.0142\n",
      "Epoch 199/200, Iteration 166/250, Loss: 0.0126\n",
      "Epoch 199/200, Iteration 167/250, Loss: 0.0095\n",
      "Epoch 199/200, Iteration 168/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 169/250, Loss: 0.0123\n",
      "Epoch 199/200, Iteration 170/250, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 171/250, Loss: 0.0165\n",
      "Epoch 199/200, Iteration 172/250, Loss: 0.0173\n",
      "Epoch 199/200, Iteration 173/250, Loss: 0.0094\n",
      "Epoch 199/200, Iteration 174/250, Loss: 0.0079\n",
      "Epoch 199/200, Iteration 175/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 176/250, Loss: 0.0187\n",
      "Epoch 199/200, Iteration 177/250, Loss: 0.0097\n",
      "Epoch 199/200, Iteration 178/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 179/250, Loss: 0.0098\n",
      "Epoch 199/200, Iteration 180/250, Loss: 0.0206\n",
      "Epoch 199/200, Iteration 181/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 182/250, Loss: 0.0150\n",
      "Epoch 199/200, Iteration 183/250, Loss: 0.0116\n",
      "Epoch 199/200, Iteration 184/250, Loss: 0.0170\n",
      "Epoch 199/200, Iteration 185/250, Loss: 0.0292\n",
      "Epoch 199/200, Iteration 186/250, Loss: 0.0176\n",
      "Epoch 199/200, Iteration 187/250, Loss: 0.0210\n",
      "Epoch 199/200, Iteration 188/250, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 189/250, Loss: 0.0335\n",
      "Epoch 199/200, Iteration 190/250, Loss: 0.0138\n",
      "Epoch 199/200, Iteration 191/250, Loss: 0.0145\n",
      "Epoch 199/200, Iteration 192/250, Loss: 0.0089\n",
      "Epoch 199/200, Iteration 193/250, Loss: 0.0224\n",
      "Epoch 199/200, Iteration 194/250, Loss: 0.0186\n",
      "Epoch 199/200, Iteration 195/250, Loss: 0.0108\n",
      "Epoch 199/200, Iteration 196/250, Loss: 0.0097\n",
      "Epoch 199/200, Iteration 197/250, Loss: 0.0121\n",
      "Epoch 199/200, Iteration 198/250, Loss: 0.0103\n",
      "Epoch 199/200, Iteration 199/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 200/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 201/250, Loss: 0.0120\n",
      "Epoch 199/200, Iteration 202/250, Loss: 0.0175\n",
      "Epoch 199/200, Iteration 203/250, Loss: 0.0309\n",
      "Epoch 199/200, Iteration 204/250, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 205/250, Loss: 0.0149\n",
      "Epoch 199/200, Iteration 206/250, Loss: 0.0148\n",
      "Epoch 199/200, Iteration 207/250, Loss: 0.0106\n",
      "Epoch 199/200, Iteration 208/250, Loss: 0.0257\n",
      "Epoch 199/200, Iteration 209/250, Loss: 0.0137\n",
      "Epoch 199/200, Iteration 210/250, Loss: 0.0252\n",
      "Epoch 199/200, Iteration 211/250, Loss: 0.0231\n",
      "Epoch 199/200, Iteration 212/250, Loss: 0.0184\n",
      "Epoch 199/200, Iteration 213/250, Loss: 0.0074\n",
      "Epoch 199/200, Iteration 214/250, Loss: 0.0175\n",
      "Epoch 199/200, Iteration 215/250, Loss: 0.0074\n",
      "Epoch 199/200, Iteration 216/250, Loss: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200, Iteration 217/250, Loss: 0.0107\n",
      "Epoch 199/200, Iteration 218/250, Loss: 0.0127\n",
      "Epoch 199/200, Iteration 219/250, Loss: 0.0078\n",
      "Epoch 199/200, Iteration 220/250, Loss: 0.0178\n",
      "Epoch 199/200, Iteration 221/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 222/250, Loss: 0.0099\n",
      "Epoch 199/200, Iteration 223/250, Loss: 0.0130\n",
      "Epoch 199/200, Iteration 224/250, Loss: 0.0153\n",
      "Epoch 199/200, Iteration 225/250, Loss: 0.0164\n",
      "Epoch 199/200, Iteration 226/250, Loss: 0.0142\n",
      "Epoch 199/200, Iteration 227/250, Loss: 0.0173\n",
      "Epoch 199/200, Iteration 228/250, Loss: 0.0082\n",
      "Epoch 199/200, Iteration 229/250, Loss: 0.0142\n",
      "Epoch 199/200, Iteration 230/250, Loss: 0.0192\n",
      "Epoch 199/200, Iteration 231/250, Loss: 0.0129\n",
      "Epoch 199/200, Iteration 232/250, Loss: 0.0442\n",
      "Epoch 199/200, Iteration 233/250, Loss: 0.0125\n",
      "Epoch 199/200, Iteration 234/250, Loss: 0.0133\n",
      "Epoch 199/200, Iteration 235/250, Loss: 0.0141\n",
      "Epoch 199/200, Iteration 236/250, Loss: 0.0296\n",
      "Epoch 199/200, Iteration 237/250, Loss: 0.0247\n",
      "Epoch 199/200, Iteration 238/250, Loss: 0.0085\n",
      "Epoch 199/200, Iteration 239/250, Loss: 0.0104\n",
      "Epoch 199/200, Iteration 240/250, Loss: 0.0164\n",
      "Epoch 199/200, Iteration 241/250, Loss: 0.0117\n",
      "Epoch 199/200, Iteration 242/250, Loss: 0.0081\n",
      "Epoch 199/200, Iteration 243/250, Loss: 0.0145\n",
      "Epoch 199/200, Iteration 244/250, Loss: 0.0127\n",
      "Epoch 199/200, Iteration 245/250, Loss: 0.0152\n",
      "Epoch 199/200, Iteration 246/250, Loss: 0.0135\n",
      "Epoch 199/200, Iteration 247/250, Loss: 0.0113\n",
      "Epoch 199/200, Iteration 248/250, Loss: 0.0260\n",
      "Epoch 199/200, Iteration 249/250, Loss: 0.0119\n",
      "Epoch 199/200, Iteration 250/250, Loss: 0.0197\n",
      "Train Error: \n",
      " Accuracy: 91.89%, Avg loss: 0.007246, MRE: 0.487511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.25%, Avg loss: 0.007809, MRE: 0.678273 \n",
      "\n",
      "Epoch 200/200, Iteration 1/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 2/250, Loss: 0.0229\n",
      "Epoch 200/200, Iteration 3/250, Loss: 0.0078\n",
      "Epoch 200/200, Iteration 4/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 5/250, Loss: 0.0167\n",
      "Epoch 200/200, Iteration 6/250, Loss: 0.0188\n",
      "Epoch 200/200, Iteration 7/250, Loss: 0.0149\n",
      "Epoch 200/200, Iteration 8/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 9/250, Loss: 0.0082\n",
      "Epoch 200/200, Iteration 10/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 11/250, Loss: 0.0158\n",
      "Epoch 200/200, Iteration 12/250, Loss: 0.0157\n",
      "Epoch 200/200, Iteration 13/250, Loss: 0.0093\n",
      "Epoch 200/200, Iteration 14/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 15/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 16/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 17/250, Loss: 0.0251\n",
      "Epoch 200/200, Iteration 18/250, Loss: 0.0085\n",
      "Epoch 200/200, Iteration 19/250, Loss: 0.0361\n",
      "Epoch 200/200, Iteration 20/250, Loss: 0.0172\n",
      "Epoch 200/200, Iteration 21/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 22/250, Loss: 0.0234\n",
      "Epoch 200/200, Iteration 23/250, Loss: 0.0143\n",
      "Epoch 200/200, Iteration 24/250, Loss: 0.0122\n",
      "Epoch 200/200, Iteration 25/250, Loss: 0.0108\n",
      "Epoch 200/200, Iteration 26/250, Loss: 0.0152\n",
      "Epoch 200/200, Iteration 27/250, Loss: 0.0208\n",
      "Epoch 200/200, Iteration 28/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 29/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 30/250, Loss: 0.0120\n",
      "Epoch 200/200, Iteration 31/250, Loss: 0.0121\n",
      "Epoch 200/200, Iteration 32/250, Loss: 0.0151\n",
      "Epoch 200/200, Iteration 33/250, Loss: 0.0165\n",
      "Epoch 200/200, Iteration 34/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 35/250, Loss: 0.0213\n",
      "Epoch 200/200, Iteration 36/250, Loss: 0.0157\n",
      "Epoch 200/200, Iteration 37/250, Loss: 0.0149\n",
      "Epoch 200/200, Iteration 38/250, Loss: 0.0090\n",
      "Epoch 200/200, Iteration 39/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 40/250, Loss: 0.0228\n",
      "Epoch 200/200, Iteration 41/250, Loss: 0.0209\n",
      "Epoch 200/200, Iteration 42/250, Loss: 0.0142\n",
      "Epoch 200/200, Iteration 43/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 44/250, Loss: 0.0195\n",
      "Epoch 200/200, Iteration 45/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 46/250, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 47/250, Loss: 0.0252\n",
      "Epoch 200/200, Iteration 48/250, Loss: 0.0131\n",
      "Epoch 200/200, Iteration 49/250, Loss: 0.0222\n",
      "Epoch 200/200, Iteration 50/250, Loss: 0.0206\n",
      "Epoch 200/200, Iteration 51/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 52/250, Loss: 0.0355\n",
      "Epoch 200/200, Iteration 53/250, Loss: 0.0158\n",
      "Epoch 200/200, Iteration 54/250, Loss: 0.0113\n",
      "Epoch 200/200, Iteration 55/250, Loss: 0.0146\n",
      "Epoch 200/200, Iteration 56/250, Loss: 0.0183\n",
      "Epoch 200/200, Iteration 57/250, Loss: 0.0082\n",
      "Epoch 200/200, Iteration 58/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 59/250, Loss: 0.0079\n",
      "Epoch 200/200, Iteration 60/250, Loss: 0.0108\n",
      "Epoch 200/200, Iteration 61/250, Loss: 0.0114\n",
      "Epoch 200/200, Iteration 62/250, Loss: 0.0085\n",
      "Epoch 200/200, Iteration 63/250, Loss: 0.0330\n",
      "Epoch 200/200, Iteration 64/250, Loss: 0.0111\n",
      "Epoch 200/200, Iteration 65/250, Loss: 0.0093\n",
      "Epoch 200/200, Iteration 66/250, Loss: 0.0133\n",
      "Epoch 200/200, Iteration 67/250, Loss: 0.0120\n",
      "Epoch 200/200, Iteration 68/250, Loss: 0.0094\n",
      "Epoch 200/200, Iteration 69/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 70/250, Loss: 0.0085\n",
      "Epoch 200/200, Iteration 71/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 72/250, Loss: 0.0143\n",
      "Epoch 200/200, Iteration 73/250, Loss: 0.0145\n",
      "Epoch 200/200, Iteration 74/250, Loss: 0.0121\n",
      "Epoch 200/200, Iteration 75/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 76/250, Loss: 0.0177\n",
      "Epoch 200/200, Iteration 77/250, Loss: 0.0136\n",
      "Epoch 200/200, Iteration 78/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 79/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 80/250, Loss: 0.0416\n",
      "Epoch 200/200, Iteration 81/250, Loss: 0.0153\n",
      "Epoch 200/200, Iteration 82/250, Loss: 0.0163\n",
      "Epoch 200/200, Iteration 83/250, Loss: 0.0075\n",
      "Epoch 200/200, Iteration 84/250, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 85/250, Loss: 0.0169\n",
      "Epoch 200/200, Iteration 86/250, Loss: 0.0095\n",
      "Epoch 200/200, Iteration 87/250, Loss: 0.0110\n",
      "Epoch 200/200, Iteration 88/250, Loss: 0.0197\n",
      "Epoch 200/200, Iteration 89/250, Loss: 0.0277\n",
      "Epoch 200/200, Iteration 90/250, Loss: 0.0262\n",
      "Epoch 200/200, Iteration 91/250, Loss: 0.0322\n",
      "Epoch 200/200, Iteration 92/250, Loss: 0.0118\n",
      "Epoch 200/200, Iteration 93/250, Loss: 0.0124\n",
      "Epoch 200/200, Iteration 94/250, Loss: 0.0143\n",
      "Epoch 200/200, Iteration 95/250, Loss: 0.0120\n",
      "Epoch 200/200, Iteration 96/250, Loss: 0.0169\n",
      "Epoch 200/200, Iteration 97/250, Loss: 0.0301\n",
      "Epoch 200/200, Iteration 98/250, Loss: 0.0094\n",
      "Epoch 200/200, Iteration 99/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 100/250, Loss: 0.0150\n",
      "Epoch 200/200, Iteration 101/250, Loss: 0.0078\n",
      "Epoch 200/200, Iteration 102/250, Loss: 0.0072\n",
      "Epoch 200/200, Iteration 103/250, Loss: 0.0353\n",
      "Epoch 200/200, Iteration 104/250, Loss: 0.0150\n",
      "Epoch 200/200, Iteration 105/250, Loss: 0.0091\n",
      "Epoch 200/200, Iteration 106/250, Loss: 0.0133\n",
      "Epoch 200/200, Iteration 107/250, Loss: 0.0083\n",
      "Epoch 200/200, Iteration 108/250, Loss: 0.0100\n",
      "Epoch 200/200, Iteration 109/250, Loss: 0.0092\n",
      "Epoch 200/200, Iteration 110/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 111/250, Loss: 0.0107\n",
      "Epoch 200/200, Iteration 112/250, Loss: 0.0112\n",
      "Epoch 200/200, Iteration 113/250, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 114/250, Loss: 0.0152\n",
      "Epoch 200/200, Iteration 115/250, Loss: 0.0088\n",
      "Epoch 200/200, Iteration 116/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 117/250, Loss: 0.0093\n",
      "Epoch 200/200, Iteration 118/250, Loss: 0.0280\n",
      "Epoch 200/200, Iteration 119/250, Loss: 0.0083\n",
      "Epoch 200/200, Iteration 120/250, Loss: 0.0126\n",
      "Epoch 200/200, Iteration 121/250, Loss: 0.0108\n",
      "Epoch 200/200, Iteration 122/250, Loss: 0.0093\n",
      "Epoch 200/200, Iteration 123/250, Loss: 0.0280\n",
      "Epoch 200/200, Iteration 124/250, Loss: 0.0124\n",
      "Epoch 200/200, Iteration 125/250, Loss: 0.0103\n",
      "Epoch 200/200, Iteration 126/250, Loss: 0.0088\n",
      "Epoch 200/200, Iteration 127/250, Loss: 0.0113\n",
      "Epoch 200/200, Iteration 128/250, Loss: 0.0133\n",
      "Epoch 200/200, Iteration 129/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 130/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 131/250, Loss: 0.0222\n",
      "Epoch 200/200, Iteration 132/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 133/250, Loss: 0.0341\n",
      "Epoch 200/200, Iteration 134/250, Loss: 0.0276\n",
      "Epoch 200/200, Iteration 135/250, Loss: 0.0186\n",
      "Epoch 200/200, Iteration 136/250, Loss: 0.0069\n",
      "Epoch 200/200, Iteration 137/250, Loss: 0.0102\n",
      "Epoch 200/200, Iteration 138/250, Loss: 0.0212\n",
      "Epoch 200/200, Iteration 139/250, Loss: 0.0074\n",
      "Epoch 200/200, Iteration 140/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 141/250, Loss: 0.0124\n",
      "Epoch 200/200, Iteration 142/250, Loss: 0.0138\n",
      "Epoch 200/200, Iteration 143/250, Loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200, Iteration 144/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 145/250, Loss: 0.0208\n",
      "Epoch 200/200, Iteration 146/250, Loss: 0.0309\n",
      "Epoch 200/200, Iteration 147/250, Loss: 0.0074\n",
      "Epoch 200/200, Iteration 148/250, Loss: 0.0194\n",
      "Epoch 200/200, Iteration 149/250, Loss: 0.0176\n",
      "Epoch 200/200, Iteration 150/250, Loss: 0.0355\n",
      "Epoch 200/200, Iteration 151/250, Loss: 0.0150\n",
      "Epoch 200/200, Iteration 152/250, Loss: 0.0071\n",
      "Epoch 200/200, Iteration 153/250, Loss: 0.0091\n",
      "Epoch 200/200, Iteration 154/250, Loss: 0.0072\n",
      "Epoch 200/200, Iteration 155/250, Loss: 0.0070\n",
      "Epoch 200/200, Iteration 156/250, Loss: 0.0278\n",
      "Epoch 200/200, Iteration 157/250, Loss: 0.0147\n",
      "Epoch 200/200, Iteration 158/250, Loss: 0.0095\n",
      "Epoch 200/200, Iteration 159/250, Loss: 0.0656\n",
      "Epoch 200/200, Iteration 160/250, Loss: 0.0125\n",
      "Epoch 200/200, Iteration 161/250, Loss: 0.0465\n",
      "Epoch 200/200, Iteration 162/250, Loss: 0.0365\n",
      "Epoch 200/200, Iteration 163/250, Loss: 0.0101\n",
      "Epoch 200/200, Iteration 164/250, Loss: 0.0166\n",
      "Epoch 200/200, Iteration 165/250, Loss: 0.0190\n",
      "Epoch 200/200, Iteration 166/250, Loss: 0.0104\n",
      "Epoch 200/200, Iteration 167/250, Loss: 0.0137\n",
      "Epoch 200/200, Iteration 168/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 169/250, Loss: 0.0274\n",
      "Epoch 200/200, Iteration 170/250, Loss: 0.0084\n",
      "Epoch 200/200, Iteration 171/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 172/250, Loss: 0.0092\n",
      "Epoch 200/200, Iteration 173/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 174/250, Loss: 0.0140\n",
      "Epoch 200/200, Iteration 175/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 176/250, Loss: 0.0248\n",
      "Epoch 200/200, Iteration 177/250, Loss: 0.0146\n",
      "Epoch 200/200, Iteration 178/250, Loss: 0.0299\n",
      "Epoch 200/200, Iteration 179/250, Loss: 0.0112\n",
      "Epoch 200/200, Iteration 180/250, Loss: 0.0152\n",
      "Epoch 200/200, Iteration 181/250, Loss: 0.0126\n",
      "Epoch 200/200, Iteration 182/250, Loss: 0.0260\n",
      "Epoch 200/200, Iteration 183/250, Loss: 0.0139\n",
      "Epoch 200/200, Iteration 184/250, Loss: 0.0090\n",
      "Epoch 200/200, Iteration 185/250, Loss: 0.0140\n",
      "Epoch 200/200, Iteration 186/250, Loss: 0.0249\n",
      "Epoch 200/200, Iteration 187/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 188/250, Loss: 0.0112\n",
      "Epoch 200/200, Iteration 189/250, Loss: 0.0099\n",
      "Epoch 200/200, Iteration 190/250, Loss: 0.0085\n",
      "Epoch 200/200, Iteration 191/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 192/250, Loss: 0.0206\n",
      "Epoch 200/200, Iteration 193/250, Loss: 0.0144\n",
      "Epoch 200/200, Iteration 194/250, Loss: 0.0268\n",
      "Epoch 200/200, Iteration 195/250, Loss: 0.0129\n",
      "Epoch 200/200, Iteration 196/250, Loss: 0.0263\n",
      "Epoch 200/200, Iteration 197/250, Loss: 0.0116\n",
      "Epoch 200/200, Iteration 198/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 199/250, Loss: 0.0119\n",
      "Epoch 200/200, Iteration 200/250, Loss: 0.0077\n",
      "Epoch 200/200, Iteration 201/250, Loss: 0.0139\n",
      "Epoch 200/200, Iteration 202/250, Loss: 0.0262\n",
      "Epoch 200/200, Iteration 203/250, Loss: 0.0318\n",
      "Epoch 200/200, Iteration 204/250, Loss: 0.0398\n",
      "Epoch 200/200, Iteration 205/250, Loss: 0.0195\n",
      "Epoch 200/200, Iteration 206/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 207/250, Loss: 0.0175\n",
      "Epoch 200/200, Iteration 208/250, Loss: 0.0132\n",
      "Epoch 200/200, Iteration 209/250, Loss: 0.0304\n",
      "Epoch 200/200, Iteration 210/250, Loss: 0.0149\n",
      "Epoch 200/200, Iteration 211/250, Loss: 0.0116\n",
      "Epoch 200/200, Iteration 212/250, Loss: 0.0156\n",
      "Epoch 200/200, Iteration 213/250, Loss: 0.0217\n",
      "Epoch 200/200, Iteration 214/250, Loss: 0.0123\n",
      "Epoch 200/200, Iteration 215/250, Loss: 0.0146\n",
      "Epoch 200/200, Iteration 216/250, Loss: 0.0086\n",
      "Epoch 200/200, Iteration 217/250, Loss: 0.0095\n",
      "Epoch 200/200, Iteration 218/250, Loss: 0.0089\n",
      "Epoch 200/200, Iteration 219/250, Loss: 0.0241\n",
      "Epoch 200/200, Iteration 220/250, Loss: 0.0414\n",
      "Epoch 200/200, Iteration 221/250, Loss: 0.0116\n",
      "Epoch 200/200, Iteration 222/250, Loss: 0.0185\n",
      "Epoch 200/200, Iteration 223/250, Loss: 0.0194\n",
      "Epoch 200/200, Iteration 224/250, Loss: 0.0081\n",
      "Epoch 200/200, Iteration 225/250, Loss: 0.0181\n",
      "Epoch 200/200, Iteration 226/250, Loss: 0.0141\n",
      "Epoch 200/200, Iteration 227/250, Loss: 0.0233\n",
      "Epoch 200/200, Iteration 228/250, Loss: 0.0179\n",
      "Epoch 200/200, Iteration 229/250, Loss: 0.0256\n",
      "Epoch 200/200, Iteration 230/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 231/250, Loss: 0.0219\n",
      "Epoch 200/200, Iteration 232/250, Loss: 0.0105\n",
      "Epoch 200/200, Iteration 233/250, Loss: 0.0070\n",
      "Epoch 200/200, Iteration 234/250, Loss: 0.0086\n",
      "Epoch 200/200, Iteration 235/250, Loss: 0.0283\n",
      "Epoch 200/200, Iteration 236/250, Loss: 0.0122\n",
      "Epoch 200/200, Iteration 237/250, Loss: 0.0104\n",
      "Epoch 200/200, Iteration 238/250, Loss: 0.0096\n",
      "Epoch 200/200, Iteration 239/250, Loss: 0.0098\n",
      "Epoch 200/200, Iteration 240/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 241/250, Loss: 0.0139\n",
      "Epoch 200/200, Iteration 242/250, Loss: 0.0192\n",
      "Epoch 200/200, Iteration 243/250, Loss: 0.0227\n",
      "Epoch 200/200, Iteration 244/250, Loss: 0.0190\n",
      "Epoch 200/200, Iteration 245/250, Loss: 0.0106\n",
      "Epoch 200/200, Iteration 246/250, Loss: 0.0238\n",
      "Epoch 200/200, Iteration 247/250, Loss: 0.0361\n",
      "Epoch 200/200, Iteration 248/250, Loss: 0.0343\n",
      "Epoch 200/200, Iteration 249/250, Loss: 0.0128\n",
      "Epoch 200/200, Iteration 250/250, Loss: 0.0113\n",
      "Train Error: \n",
      " Accuracy: 76.91%, Avg loss: 0.007710, MRE: 0.493289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.05%, Avg loss: 0.008088, MRE: 0.545174 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predictions = torch.max(pred.data, 1)\n",
    "#         train_correct += (predictions == y.data).sum()                \n",
    "#         train_total += predictions.size(0)    \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    #scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping\n",
    "    #train_loss.append(loss.item())\n",
    "    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    scheduler.step(tr_loss) # LR scheduler step für reduceonPlateau\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "\n",
    "#     loss = criterion(outputs, Variable(test_classes))\n",
    "#     test_loss.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f9848",
   "metadata": {},
   "source": [
    "#### Parity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098cfb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: R^2 = 0.9582007584004454\n",
      "Test Dataset: R^2 = 0.9635826165550792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xi_real = []\n",
    "xi_pred = []\n",
    "for (X,y) in train_dataloader:\n",
    "    xi_real = np.append(xi_real, y.numpy())\n",
    "    xi_pred = np.append(xi_pred, net(X).detach().numpy())\n",
    "\n",
    "xi_real_test = []\n",
    "xi_pred_test = []\n",
    "for (X,y) in test_dataloader:\n",
    "    xi_real_test = np.append(xi_real_test, y.numpy())\n",
    "    xi_pred_test = np.append(xi_pred_test, net(X).detach().numpy())\n",
    "\n",
    "print('Training Dataset: R^2 =', r2(xi_real,xi_pred))\n",
    "print('Test Dataset: R^2 =', r2(xi_real_test,xi_pred_test))\n",
    "\n",
    "# find the boundaries of X and Y values\n",
    "bounds = (min(xi_real.min(), xi_pred.min()) - int(0.1 * xi_pred.min()), max(xi_real.max(), xi_pred.max())+ int(0.1 * xi_pred.max()))\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize =(10,10))\n",
    "\n",
    "# # Reset the limits\n",
    "# ax[0] = plt.gca()\n",
    "ax[0].set_xlim(bounds)\n",
    "ax[0].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[0].plot(xi_real, xi_pred, '.')\n",
    "ax[0].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[0].transAxes)\n",
    "ax[0].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[0].set_title('Train Data')\n",
    "#ax[0].legend(['$\\\\mathregular{R^2}$ = ', r2(xi_real,xi_pred)], markerscale=0)\n",
    "\n",
    "# Reset the limits\n",
    "#ax[1] = plt.gca()\n",
    "ax[1].set_xlim(bounds)\n",
    "ax[1].set_ylim(bounds)\n",
    "# Ensure the aspect ratio is square\n",
    "ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "ax[1].plot(xi_real_test, xi_pred_test, '.')\n",
    "ax[1].plot([0, 1], [0, 1], \"r-\",lw=2 ,transform=ax[1].transAxes)\n",
    "ax[1].set(xlabel = '$\\\\xi$ / mol', ylabel = '$\\\\xi\\mathregular{_{pred}}$ / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[1].set_title('Test Data')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#fig.suptitle(\"Parity Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390bab",
   "metadata": {},
   "source": [
    "#### Plot Fehler vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428c9744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / mol') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbf7c2",
   "metadata": {},
   "source": [
    "#### Plot Loss vs Variable Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a835602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistake = []\n",
    "param_T = []\n",
    "param_p = []\n",
    "param_x_H2 = []\n",
    "param_x_N2 = []\n",
    "param_x_NH3 = []\n",
    "for X,y in train_dataloader:\n",
    "    mistake = np.append(mistake, abs(y - net(X).detach().numpy()))\n",
    "    param_T = np.append(param_T, X[:,0])\n",
    "    param_p = np.append(param_p, X[:,1])\n",
    "    param_x_H2 = np.append(param_x_H2, X[:,2])\n",
    "    param_x_N2 = np.append(param_x_N2, X[:,3])\n",
    "    param_x_NH3 = np.append(param_x_NH3, X[:,4])\n",
    "    \n",
    "# train_parameters, train_xi = next(iter(train_dataloader))\n",
    "# y = abs(train_xi - net(train_parameters).detach().numpy())\n",
    "# #[T, p ,x_H2, x_N2, x_NH3]\n",
    "# x = [train_parameters[:,0], train_parameters[:,1], train_parameters[:,2], train_parameters[:,3], train_parameters[:,4]]\n",
    "\n",
    "# print(param_T[0])\n",
    "# print(param_T)\n",
    "# print(mistake)\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize = (10, 5), gridspec_kw={'width_ratios': [2,2,3]})\n",
    "\n",
    "ax[0].plot(param_T, mistake, '.', markersize = 2)\n",
    "ax[0].set(xlabel = '$T$ / K', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[0].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[1].plot(param_p, mistake, '.', markersize = 2)\n",
    "ax[1].set(xlabel = '$p$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[1].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "ax[2].plot(param_x_H2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{H_2}}$')\n",
    "ax[2].plot(param_x_N2, mistake, '.', markersize = 2, label = '$x\\mathregular{_{N_2}}$')\n",
    "ax[2].plot(param_x_NH3, mistake, '.', markersize = 2, label = '$x\\mathregular{_{NH_3}}$')\n",
    "ax[2].set(xlabel = '$x\\mathregular{_{NH_3}}$ / bar', ylabel = '|$\\\\xi - \\\\xi\\mathregular{_{pred}}$| / mol')\n",
    "ax[2].tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "ax[2].set\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418caa55",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.4797e+02, 2.2294e+02, 6.7593e-01, 9.5234e-02, 2.2884e-01],\n",
      "        [8.4459e+02, 2.4066e+02, 1.9340e-01, 3.7140e-01, 4.3520e-01],\n",
      "        [8.3801e+02, 1.5534e+02, 2.6214e-01, 7.4046e-02, 6.6381e-01],\n",
      "        [6.7602e+02, 2.2572e+02, 9.2315e-01, 4.1157e-02, 3.5698e-02],\n",
      "        [7.2404e+02, 2.5026e+02, 1.9921e-01, 4.2584e-01, 3.7495e-01],\n",
      "        [8.1329e+02, 1.4748e+02, 3.5946e-02, 6.8654e-01, 2.7752e-01],\n",
      "        [7.0846e+02, 1.8593e+02, 9.7085e-02, 4.0348e-01, 4.9944e-01],\n",
      "        [7.9118e+02, 2.2430e+02, 8.1132e-01, 1.5641e-01, 3.2271e-02],\n",
      "        [7.7441e+02, 1.6088e+02, 1.4844e-01, 7.9346e-01, 5.8103e-02],\n",
      "        [8.2406e+02, 2.4232e+02, 4.7205e-02, 2.5293e-01, 6.9987e-01],\n",
      "        [6.9593e+02, 1.4544e+02, 2.4613e-01, 4.2445e-01, 3.2941e-01],\n",
      "        [6.7809e+02, 1.6165e+02, 1.5822e-01, 7.4258e-01, 9.9204e-02],\n",
      "        [8.4582e+02, 1.9734e+02, 3.3763e-01, 5.7509e-01, 8.7288e-02],\n",
      "        [7.5060e+02, 2.3375e+02, 4.1810e-02, 9.0663e-01, 5.1560e-02],\n",
      "        [7.4560e+02, 1.9247e+02, 3.6868e-02, 1.4811e-02, 9.4832e-01],\n",
      "        [7.4461e+02, 1.8321e+02, 8.5496e-02, 2.4931e-01, 6.6520e-01],\n",
      "        [8.1138e+02, 1.9095e+02, 4.1214e-01, 4.2925e-01, 1.5861e-01],\n",
      "        [6.9240e+02, 1.9009e+02, 1.0184e-02, 9.8871e-01, 1.1096e-03],\n",
      "        [7.0089e+02, 1.4674e+02, 6.0118e-01, 1.8569e-01, 2.1313e-01],\n",
      "        [6.9385e+02, 1.8583e+02, 5.8314e-02, 1.7292e-01, 7.6877e-01],\n",
      "        [7.0591e+02, 1.5397e+02, 3.6143e-01, 1.7849e-01, 4.6009e-01],\n",
      "        [7.9132e+02, 2.4726e+02, 2.3929e-01, 7.3472e-01, 2.5990e-02],\n",
      "        [7.6630e+02, 2.4075e+02, 4.8339e-01, 2.0139e-02, 4.9647e-01],\n",
      "        [8.2666e+02, 1.4415e+02, 7.0756e-01, 1.1488e-01, 1.7756e-01],\n",
      "        [7.8218e+02, 1.9405e+02, 1.0067e-01, 5.3054e-01, 3.6879e-01],\n",
      "        [7.3897e+02, 1.9929e+02, 1.0836e-01, 8.5279e-01, 3.8859e-02],\n",
      "        [6.9502e+02, 2.0635e+02, 9.3374e-01, 6.3252e-02, 3.0040e-03],\n",
      "        [6.8295e+02, 2.0191e+02, 2.6106e-01, 5.7754e-01, 1.6140e-01],\n",
      "        [8.2164e+02, 1.2824e+02, 1.5717e-01, 6.8926e-02, 7.7391e-01],\n",
      "        [6.5603e+02, 1.9412e+02, 6.8745e-01, 2.7780e-01, 3.4744e-02],\n",
      "        [8.4052e+02, 2.3551e+02, 4.5824e-01, 1.9970e-01, 3.4206e-01],\n",
      "        [8.3280e+02, 1.0529e+02, 2.3092e-01, 4.5952e-01, 3.0956e-01]])\n",
      "tensor([[-7.2689e-03],\n",
      "        [-1.5021e-01],\n",
      "        [-2.6525e-01],\n",
      "        [ 3.8708e-02],\n",
      "        [-6.0629e-02],\n",
      "        [-1.0812e-01],\n",
      "        [-1.1514e-01],\n",
      "        [ 5.3243e-02],\n",
      "        [-8.8386e-03],\n",
      "        [-2.5239e-01],\n",
      "        [-5.1228e-02],\n",
      "        [ 2.1408e-03],\n",
      "        [-1.1345e-02],\n",
      "        [-1.3031e-02],\n",
      "        [-3.0531e-01],\n",
      "        [-1.9859e-01],\n",
      "        [-2.4089e-02],\n",
      "        [ 3.1363e-04],\n",
      "        [ 1.4217e-02],\n",
      "        [-1.8573e-01],\n",
      "        [-8.6553e-02],\n",
      "        [ 1.6362e-02],\n",
      "        [-1.2446e-01],\n",
      "        [-4.2452e-02],\n",
      "        [-1.1601e-01],\n",
      "        [-2.2493e-04],\n",
      "        [ 5.7442e-02],\n",
      "        [ 1.3657e-02],\n",
      "        [-3.1793e-01],\n",
      "        [ 1.2769e-01],\n",
      "        [-9.9440e-02],\n",
      "        [-1.2233e-01]])\n",
      "tensor([[-1.6493e-02],\n",
      "        [-1.4870e-01],\n",
      "        [-2.6937e-01],\n",
      "        [ 4.3034e-02],\n",
      "        [-5.6935e-02],\n",
      "        [-1.1753e-01],\n",
      "        [-1.0375e-01],\n",
      "        [ 4.3956e-02],\n",
      "        [-3.2106e-02],\n",
      "        [-2.4134e-01],\n",
      "        [-5.8718e-02],\n",
      "        [ 1.2673e-03],\n",
      "        [-2.7957e-02],\n",
      "        [-8.9075e-03],\n",
      "        [-2.7115e-01],\n",
      "        [-2.2232e-01],\n",
      "        [-4.1557e-02],\n",
      "        [-7.3152e-03],\n",
      "        [ 2.9161e-03],\n",
      "        [-1.8879e-01],\n",
      "        [-8.2401e-02],\n",
      "        [ 2.1074e-04],\n",
      "        [-1.2188e-01],\n",
      "        [-6.5705e-02],\n",
      "        [-1.2656e-01],\n",
      "        [-1.3071e-02],\n",
      "        [ 3.9248e-02],\n",
      "        [ 1.2115e-02],\n",
      "        [-3.1532e-01],\n",
      "        [ 1.0034e-01],\n",
      "        [-1.0517e-01],\n",
      "        [-1.3661e-01]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241eab8",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.2892, 1.3100, 0.8972, 1.1168, 0.8814], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2374,  0.2803, -0.1009,  0.2066, -0.0321], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.1057e+00,  4.3587e-01, -4.6589e-02,  3.2486e-01,  5.9995e-02],\n",
       "         [-8.6043e-01,  5.0332e-01,  3.0329e-01, -3.4175e-01, -4.8067e-01],\n",
       "         [-3.1394e-01, -1.5934e+00,  8.2129e-02, -7.0837e-02, -5.0221e-02],\n",
       "         [ 2.3546e-01, -8.0784e-02, -9.9829e-02, -3.2350e-01,  5.7629e-01],\n",
       "         [ 2.9282e-02, -1.8145e-01, -5.8848e-01,  1.3746e-01,  4.3802e-01],\n",
       "         [ 8.3150e-01, -5.4228e-01,  6.8648e-01, -4.9722e-01,  6.3053e-01],\n",
       "         [ 5.5459e-01,  9.4077e-03,  6.2513e-01, -9.2016e-01,  4.8663e-01],\n",
       "         [ 3.4964e-02,  3.3042e-01, -5.2137e-01, -4.4392e-01,  7.9878e-01],\n",
       "         [ 3.9695e-01, -9.6103e-01,  5.9411e-01,  1.2803e-01,  7.4488e-02],\n",
       "         [ 3.2537e-01, -3.0122e-01, -3.4491e-01, -5.1587e-01,  1.4017e-01],\n",
       "         [-6.1267e-01,  2.7208e-01,  2.5301e-01, -5.0008e-01,  6.5828e-01],\n",
       "         [ 7.7957e-01, -6.8637e-02,  6.0779e-02, -5.1981e-01,  8.2780e-02],\n",
       "         [ 3.0046e-01,  8.9002e-02, -1.2428e-01, -8.1778e-01,  2.2567e-01],\n",
       "         [ 3.7811e-01, -5.3038e-01,  2.8178e-01, -8.7590e-01,  3.1370e-01],\n",
       "         [ 1.1950e-01, -3.8847e-01, -8.7322e-02,  1.2718e+00, -4.6265e-01],\n",
       "         [ 1.0065e-01,  1.0786e+00,  9.8055e-02, -3.6187e-01,  4.6412e-01],\n",
       "         [ 6.1178e-01, -1.1545e-01, -7.4794e-02, -1.6709e-01,  7.3117e-01],\n",
       "         [ 5.7607e-02, -3.5360e-01, -7.0099e-01,  6.6365e-02,  1.1535e-01],\n",
       "         [ 2.8764e-01, -3.5741e-01,  1.0327e+00, -7.5902e-01, -6.0855e-02],\n",
       "         [ 8.2600e-01,  1.1605e+00, -8.7848e-02, -1.6910e-01, -1.3534e-01],\n",
       "         [-2.3692e-02, -8.6847e-02,  9.9984e-01, -4.1849e-01, -3.5676e-02],\n",
       "         [-4.0573e-01, -1.0465e-01,  4.9558e-01,  2.7074e-01,  3.6894e-01],\n",
       "         [-5.1682e-01,  1.4419e-01, -3.5428e-01,  8.5082e-01, -5.7664e-01],\n",
       "         [ 9.0319e-02,  1.3416e-01, -2.5275e-01, -3.2495e-01,  7.4012e-01],\n",
       "         [ 2.7846e-01, -1.5838e+00,  3.9384e-01, -3.3554e-01,  4.2062e-02],\n",
       "         [ 2.5703e-01, -1.1017e-01, -8.5404e-01,  7.3168e-01,  4.6548e-02],\n",
       "         [-7.5290e-02,  5.9297e-02,  3.6031e-01,  2.0431e-01, -1.0716e+00],\n",
       "         [-1.1744e-01,  9.1290e-02,  9.4932e-02,  4.8762e-02, -6.6683e-01],\n",
       "         [-1.0591e+00,  1.4564e-02,  2.0816e-01,  6.3278e-01,  8.4366e-02],\n",
       "         [ 1.1385e-01, -2.2276e-01,  4.4692e-01,  8.3551e-03, -5.9839e-01],\n",
       "         [-9.1102e-02,  3.2356e-01,  4.6768e-01, -1.8609e-01, -3.8738e-01],\n",
       "         [ 2.4964e-01, -2.4406e-01,  2.6416e-02, -8.3019e-02,  7.1850e-01],\n",
       "         [ 3.8081e-02, -9.6684e-02, -1.0110e-01, -6.3866e-01,  7.9533e-01],\n",
       "         [ 3.8650e-01,  7.8844e-01,  1.1389e-01,  1.4090e-01, -4.4927e-01],\n",
       "         [-4.3304e-01,  1.0816e-01,  1.8413e-01, -4.2451e-01,  5.8438e-01],\n",
       "         [-1.4405e-01,  5.3067e-02,  6.2769e-01,  4.7121e-01, -1.3594e-01],\n",
       "         [ 1.6754e-01,  1.0328e+00, -1.2540e-01, -3.5701e-01, -3.6650e-01],\n",
       "         [-1.9383e-01, -1.6381e+00, -9.2572e-02, -2.8135e-01,  2.9708e-01],\n",
       "         [-1.4211e-01,  1.3118e+00, -2.5368e-01, -3.3293e-01,  5.9041e-02],\n",
       "         [ 6.1691e-02, -3.4523e-04, -4.4930e-01, -2.7518e-01,  7.6957e-01],\n",
       "         [-5.0338e-01,  2.2987e-01, -5.2139e-01,  1.0121e+00, -4.4068e-01],\n",
       "         [ 1.6046e+00, -3.0752e-01,  1.1376e-01, -1.6305e-01,  1.3404e-01],\n",
       "         [ 6.1099e-01,  3.4232e-02,  4.2199e-02, -6.4262e-01,  4.5762e-01],\n",
       "         [ 1.3251e+00, -4.4556e-01, -2.5174e-01,  3.5738e-01, -3.2909e-02],\n",
       "         [ 7.3112e-01, -2.6409e-01,  1.9509e-01, -8.7148e-01,  5.3163e-01],\n",
       "         [ 5.7510e-01,  1.0581e+00,  1.6177e-01, -4.0330e-01, -2.2306e-02],\n",
       "         [ 9.8838e-02,  1.1136e+00, -3.1999e-01, -2.6576e-01,  1.2449e-01],\n",
       "         [ 4.9733e-01, -5.7947e-01,  4.6581e-01, -2.1756e-01, -4.3898e-01],\n",
       "         [-7.8051e-01,  1.7493e-01, -9.0836e-02,  7.1856e-01, -5.0667e-01],\n",
       "         [-4.5112e-01, -4.3062e-01,  4.5327e-02,  1.1211e+00, -2.9371e-01],\n",
       "         [ 1.8662e-01,  1.7363e+00,  1.5040e-01,  1.1420e-01, -4.9928e-02],\n",
       "         [-1.2579e+00,  3.8721e-01, -2.4883e-01,  9.7067e-01, -8.7430e-02],\n",
       "         [-6.4626e-01, -6.8713e-01,  2.0590e-01,  5.4433e-01, -4.1651e-01],\n",
       "         [ 6.7802e-01, -2.1678e-01, -2.0358e-01,  5.9835e-01, -1.3308e-01],\n",
       "         [ 2.1961e-01, -2.2203e-01,  2.4513e-01,  3.7691e-01, -5.8985e-01],\n",
       "         [ 9.3436e-02, -5.5837e-02,  5.6030e-02, -7.8807e-01,  3.5027e-01],\n",
       "         [-4.1355e-02, -1.6741e+00, -8.6958e-02, -1.4614e-01, -1.2301e-01],\n",
       "         [ 6.7111e-02, -2.6663e-01, -9.9899e-01,  9.5814e-01, -4.5415e-02],\n",
       "         [-3.7312e-01,  1.8712e-01,  4.4186e-01, -7.2603e-02, -5.7376e-01],\n",
       "         [ 9.3053e-01, -6.3023e-01,  1.0363e-01,  9.9923e-02,  1.2676e-01],\n",
       "         [-1.7640e-01,  2.7243e-01, -8.3075e-01,  8.4687e-01,  1.0200e-01],\n",
       "         [-1.2807e+00,  2.7661e-01, -2.4393e-01,  4.5497e-01, -1.5905e-01],\n",
       "         [ 1.5711e-01,  1.4324e-01, -2.7324e-01, -1.7481e-01,  1.2528e+00],\n",
       "         [ 1.1706e+00, -7.4378e-02,  6.0071e-01, -5.3455e-01,  3.8125e-02],\n",
       "         [-7.2532e-02, -9.0242e-01,  2.7314e-01,  5.2224e-01, -2.1853e-01],\n",
       "         [-5.0715e-01, -5.7732e-01, -3.6847e-01,  7.8958e-02, -2.2082e-01],\n",
       "         [ 9.4122e-02,  4.0814e-01,  6.1407e-01, -9.1438e-01,  3.5120e-01],\n",
       "         [ 6.9093e-02,  2.3430e-01,  3.8349e-01,  5.1454e-01, -4.8830e-01],\n",
       "         [-2.5545e-01, -2.3805e-01,  2.4782e-01, -1.1744e-01, -6.6885e-01],\n",
       "         [-2.2812e-01, -6.9679e-01,  8.4285e-02,  1.0740e-01, -5.1416e-01],\n",
       "         [ 5.7551e-01, -2.8378e-02,  1.2698e-01, -3.7455e-01,  6.6797e-01],\n",
       "         [-3.7434e-01,  1.3305e-01,  2.5231e-01,  2.0152e-01, -7.6581e-01],\n",
       "         [-1.9873e-01, -1.1165e+00, -3.4946e-01,  4.8651e-01, -3.2097e-01],\n",
       "         [-1.4636e+00,  5.1263e-01, -2.5795e-01,  6.9290e-01, -9.1124e-02],\n",
       "         [-1.1454e+00, -9.8703e-03, -1.7794e-01,  1.1193e-01, -5.9735e-02],\n",
       "         [ 2.4300e-01, -1.3674e+00, -1.5179e-01,  1.8849e-01, -2.3576e-01],\n",
       "         [ 1.9570e-01,  2.4966e-01, -6.6402e-01, -1.7146e-01,  4.2133e-01],\n",
       "         [ 1.0181e+00,  8.3724e-02,  2.5305e-01, -9.3889e-02,  3.1581e-01],\n",
       "         [ 8.4545e-01, -4.9776e-01,  7.3484e-01, -7.7848e-01,  4.9513e-01],\n",
       "         [ 5.6338e-01, -3.1720e-01, -9.3795e-01, -1.0291e-01, -9.8049e-02],\n",
       "         [ 7.9857e-02, -1.2639e+00, -2.1272e-02, -4.9014e-02,  7.8573e-02],\n",
       "         [ 4.1826e-01, -5.7413e-02,  1.0285e-01,  8.4787e-01, -2.8595e-01],\n",
       "         [ 1.3615e+00,  4.4720e-02, -2.2268e-01, -3.1624e-01, -9.3895e-02],\n",
       "         [-2.3645e-01, -4.3698e-02,  4.0479e-01,  3.7240e-01, -2.9816e-01],\n",
       "         [-9.4588e-02, -5.0737e-02,  2.1312e-02, -5.0612e-01,  9.3006e-01],\n",
       "         [-1.1092e-01,  3.0476e-01,  1.8584e-01,  3.4857e-02, -1.1072e+00],\n",
       "         [-3.0950e-01,  2.3127e-01,  5.9925e-01,  3.9533e-02,  1.0614e-02],\n",
       "         [-2.8755e-01, -1.1527e-01, -1.9482e-02,  1.2333e-01, -1.3532e+00],\n",
       "         [ 8.9637e-02,  5.4863e-01,  1.4049e-01, -7.3488e-01, -7.6922e-02],\n",
       "         [-2.2701e-01,  1.2377e-01, -2.7623e-01,  5.4383e-01, -7.2024e-01],\n",
       "         [ 3.8918e-01, -4.5624e-01, -8.0052e-01,  5.9545e-01, -7.4145e-02],\n",
       "         [ 9.7204e-02, -5.1686e-01,  1.7756e-01,  1.2350e-02, -7.6210e-01],\n",
       "         [-1.6186e-01,  3.1370e-01, -1.0968e+00,  5.8379e-01,  1.8762e-01],\n",
       "         [ 1.5556e-01,  1.1706e+00, -1.0288e-01, -5.0569e-01, -5.0884e-02],\n",
       "         [ 1.0045e+00, -4.5118e-01,  1.1722e-01,  3.8753e-01, -4.3281e-01],\n",
       "         [ 4.1960e-02,  4.2155e-01,  1.6617e-01,  5.6192e-01, -1.5067e-01],\n",
       "         [-1.5107e-01,  1.9327e-01,  4.7194e-01,  4.6443e-01, -8.4810e-01],\n",
       "         [ 4.6182e-01, -1.6189e+00,  2.6993e-01, -9.1164e-02, -2.4397e-02],\n",
       "         [ 2.5758e-01, -8.2651e-01, -6.3796e-02,  9.6195e-02, -4.2178e-01],\n",
       "         [-9.5095e-01,  5.8480e-01,  3.4034e-01, -4.6499e-01, -7.5243e-02],\n",
       "         [ 1.0708e+00, -2.5163e-01, -4.4522e-01, -4.3192e-01, -3.2392e-01],\n",
       "         [ 1.2664e-01,  7.4183e-02,  5.3654e-01,  4.4232e-01, -2.2362e-01],\n",
       "         [-6.3158e-01,  3.5258e-01,  6.4499e-01,  3.7184e-01,  5.3981e-02],\n",
       "         [ 1.3466e-01,  3.8362e-01,  3.6940e-01, -1.2149e+00,  6.7193e-01],\n",
       "         [-8.8970e-01,  6.1852e-01, -2.3497e-01,  1.1086e+00, -1.7989e-01],\n",
       "         [ 1.9641e-01, -2.8759e-02, -9.2511e-01,  2.0849e-01,  2.0690e-01],\n",
       "         [ 8.6449e-01,  5.6645e-01, -9.8895e-03, -5.3320e-01,  9.3416e-02],\n",
       "         [ 2.6211e-01, -8.2459e-01,  2.0795e-01,  4.5275e-01, -2.8737e-01],\n",
       "         [-1.8793e-01,  1.5255e-01,  8.8161e-01, -3.1068e-01, -2.3710e-01],\n",
       "         [ 4.2426e-02, -2.0055e-02, -1.5448e-01, -3.6371e-02,  8.2317e-01],\n",
       "         [-1.5409e-01, -5.7570e-01, -1.0570e-03,  3.3740e-01,  4.1491e-01],\n",
       "         [ 5.8934e-01,  1.1328e-01, -2.9381e-02, -5.6372e-01,  2.0395e-01],\n",
       "         [ 1.8474e-02,  5.7791e-01, -3.6655e-01,  7.5545e-01, -6.4795e-01],\n",
       "         [ 8.0802e-01, -7.6699e-01, -2.5240e-01,  1.6466e-01, -1.3004e-01],\n",
       "         [-1.4199e-01, -1.9972e-01,  2.5824e-01,  2.1395e-01, -1.1746e+00],\n",
       "         [ 1.8578e-01,  8.9610e-01,  1.8618e-01, -6.5115e-01, -2.3054e-02],\n",
       "         [ 1.7005e-02, -3.5088e-01,  1.2995e+00, -6.4532e-01, -3.0406e-01],\n",
       "         [ 1.3614e-01, -1.3435e-02, -1.4869e-01,  1.2242e-01,  1.1009e+00],\n",
       "         [ 1.2906e-01,  7.0341e-01, -3.2009e-01, -2.4891e-01,  5.8811e-01],\n",
       "         [ 2.3517e-01,  8.7454e-01,  5.5259e-01,  2.9194e-01,  2.2167e-01],\n",
       "         [ 7.4586e-02,  3.1638e-01,  5.0717e-02,  3.1191e-01, -4.8915e-01],\n",
       "         [ 1.2927e-01, -6.4930e-02,  2.1263e-01, -1.0513e+00,  3.3156e-01],\n",
       "         [ 5.5669e-01, -5.3998e-02,  5.3673e-01, -7.7871e-01,  6.0057e-01],\n",
       "         [ 2.9467e-02,  3.7958e-02, -1.5062e-01, -2.4649e-01,  7.4495e-01],\n",
       "         [ 1.9100e-01, -1.0133e+00, -5.2682e-01,  4.7706e-01, -6.4092e-01],\n",
       "         [-7.2978e-01,  1.8249e-01, -4.0026e-01,  9.8356e-01,  4.3691e-02],\n",
       "         [ 3.2790e-01, -6.2774e-01, -2.1085e-01,  1.0102e+00, -2.0685e-01],\n",
       "         [ 1.2255e+00,  2.5283e-01, -3.5328e-02,  2.5587e-02,  3.9988e-02],\n",
       "         [ 5.7957e-01, -3.1203e-01,  5.6957e-01, -1.0484e+00,  2.4840e-01],\n",
       "         [ 6.1510e-01, -3.7160e-01,  2.3787e-01, -8.1401e-01,  3.7187e-01],\n",
       "         [ 2.0302e-02, -5.6908e-02,  9.7527e-01, -5.8586e-01, -1.7709e-01],\n",
       "         [-1.3066e+00, -7.0764e-02,  1.9724e-02, -2.0721e-01,  6.3955e-02],\n",
       "         [ 8.0503e-01, -4.2750e-02, -4.3280e-01,  3.2532e-02,  4.4612e-02],\n",
       "         [ 7.4563e-01, -3.4588e-01, -4.8030e-01,  6.1585e-01, -1.6700e-01],\n",
       "         [-1.0897e+00, -2.4252e-01, -3.3915e-02,  5.0420e-02, -1.8594e-01],\n",
       "         [ 2.3312e-01,  2.6948e-01, -3.5441e-01,  7.5840e-01, -6.4268e-01],\n",
       "         [-4.4828e-02,  1.5135e-01,  7.0259e-01, -9.7097e-02, -2.9545e-01],\n",
       "         [ 6.3002e-01, -7.7357e-01, -5.8794e-03,  2.2389e-01,  2.8720e-01],\n",
       "         [ 8.1551e-01,  3.6326e-01,  4.1851e-01, -1.2182e+00,  1.6270e-01],\n",
       "         [ 1.3296e+00, -2.9050e-01,  6.3578e-02, -2.1491e-01, -2.4553e-02],\n",
       "         [-3.3505e-01,  1.1572e-01,  9.2070e-01, -6.2659e-01, -2.7825e-02],\n",
       "         [-6.0524e-01, -9.0384e-01, -2.0818e-02, -4.0141e-02,  3.4887e-01],\n",
       "         [-1.9812e-01,  2.0925e-01, -2.0611e-01,  7.1771e-01, -8.3355e-01],\n",
       "         [-1.0053e-01,  1.1907e-01,  5.6225e-01,  4.1133e-01, -7.1990e-01],\n",
       "         [ 1.6188e-01,  3.0585e-01, -3.6461e-01, -3.1097e-01,  1.0863e+00],\n",
       "         [-1.6586e-01,  1.6980e+00,  4.2685e-01,  2.0630e-01,  4.9283e-01],\n",
       "         [-3.2123e-01, -6.1333e-01, -5.7895e-01,  3.7264e-01,  1.2302e-01],\n",
       "         [-7.1354e-01,  1.2029e+00,  2.3726e-01,  9.2593e-02,  3.6007e-01],\n",
       "         [ 6.8169e-01, -1.9939e-01,  1.1111e-01, -9.2164e-01,  4.1818e-01],\n",
       "         [-3.0346e-02, -2.0363e-01,  1.2112e+00, -4.8812e-01, -4.0863e-03],\n",
       "         [ 5.6240e-01, -3.3333e-02,  2.9612e-01, -6.2760e-01,  5.4472e-01],\n",
       "         [-3.2448e-02,  1.3327e+00,  3.5784e-02,  4.5326e-01,  1.6417e-01],\n",
       "         [-2.9682e-01,  1.2920e+00,  2.3838e-01,  8.2355e-02,  4.5714e-01],\n",
       "         [-6.8469e-02, -2.3995e-02,  5.3801e-01,  3.3911e-01, -2.1838e-01],\n",
       "         [ 8.0972e-01,  1.0518e+00, -5.2647e-02,  8.1231e-02,  1.1612e-01],\n",
       "         [-8.8057e-01, -5.1990e-01,  5.9611e-01, -2.3003e-01,  2.3617e-02],\n",
       "         [ 7.1761e-01,  7.5275e-01, -4.4646e-01,  3.2998e-01,  1.9031e-01],\n",
       "         [-1.7320e-01, -5.3331e-02, -1.0542e-01,  9.1022e-01, -6.0320e-01],\n",
       "         [-8.8632e-02,  3.0693e-02, -9.6046e-01,  4.6497e-01,  2.4475e-02],\n",
       "         [-9.3755e-01,  1.0759e-01,  3.8630e-01,  6.3017e-01,  1.7614e-01],\n",
       "         [ 9.1966e-01,  3.9307e-02,  6.2965e-01, -3.8582e-01,  2.1779e-01],\n",
       "         [ 2.1963e-01, -2.3431e-01,  5.7248e-01,  2.6231e-01,  9.2198e-02],\n",
       "         [ 9.5892e-01, -7.9597e-01,  2.9584e-01, -3.9523e-01, -6.5890e-02],\n",
       "         [ 3.2633e-01,  2.6472e-01, -2.4116e-01, -5.3946e-02,  6.7862e-01],\n",
       "         [ 2.4145e-02, -7.6060e-02, -3.9979e-02,  7.6322e-03,  9.2767e-01],\n",
       "         [ 1.1380e+00, -9.7935e-02, -1.8054e-01,  3.5244e-01, -5.0473e-01],\n",
       "         [ 2.4675e-01,  2.7055e-01, -2.1007e-01,  1.8213e-01, -1.3049e-01],\n",
       "         [-1.1922e-01, -1.4563e+00, -3.6135e-01, -2.4025e-01, -3.8851e-01],\n",
       "         [ 1.2728e+00, -5.1505e-02, -3.9309e-01, -1.4595e-01, -2.4535e-01],\n",
       "         [ 1.3857e+00, -1.7676e-01, -2.2988e-01, -1.8952e-01, -3.7623e-01],\n",
       "         [ 3.3389e-01, -5.5507e-01, -4.0053e-01,  1.0328e+00, -3.8958e-01],\n",
       "         [-1.0055e-01, -1.7655e-01,  4.7495e-01,  2.8720e-01, -7.1507e-01],\n",
       "         [-6.1781e-01,  9.9304e-01, -2.8412e-01,  8.5533e-01, -3.4264e-01],\n",
       "         [ 3.9432e-01, -1.7829e-01, -4.4538e-01,  1.1123e+00, -5.8097e-01],\n",
       "         [ 4.5914e-01,  5.3480e-04, -1.0531e+00,  2.0685e-01,  1.3427e-01],\n",
       "         [ 1.5105e-01, -5.2565e-02, -4.3558e-01, -4.0473e-01,  2.0920e-01],\n",
       "         [-1.0087e-01,  2.7360e-01,  1.6355e-01, -1.0715e+00,  4.3230e-01],\n",
       "         [ 1.6308e+00, -4.6224e-01,  4.5875e-02,  2.7441e-02,  2.4957e-01],\n",
       "         [-2.8551e-01,  2.9135e-01,  2.5446e-01, -9.2407e-01,  5.9466e-01],\n",
       "         [ 4.6559e-01,  9.7847e-01, -5.3959e-01, -6.6438e-01, -1.4504e-02],\n",
       "         [ 4.0401e-03,  1.5097e-01,  5.6868e-01,  5.0342e-01, -3.6159e-02],\n",
       "         [-1.2146e+00,  3.5066e-01,  4.9669e-01,  3.7852e-01,  2.7185e-01],\n",
       "         [ 7.0247e-01, -1.7884e-01, -6.1038e-02, -4.2916e-01,  1.5555e-01],\n",
       "         [ 1.6155e-01, -1.7195e-01,  7.2528e-02, -7.1920e-01,  2.2250e-01],\n",
       "         [-3.7044e-01,  8.6636e-01, -3.9004e-01,  1.2830e-01, -8.6268e-01],\n",
       "         [-6.4427e-01,  5.8134e-01,  7.2041e-03,  2.9570e-01,  5.5740e-02],\n",
       "         [-7.8207e-01, -6.9677e-01,  3.0715e-01,  7.8141e-01,  4.6364e-02],\n",
       "         [ 3.8453e-01,  8.5051e-01,  9.2171e-02, -9.1149e-01,  4.7284e-01],\n",
       "         [ 2.2225e-01, -7.5969e-02, -1.0070e+00,  1.1259e-02,  9.0048e-02],\n",
       "         [ 1.2905e+00, -2.3771e-01,  3.1765e-01, -6.5274e-01,  1.9286e-01],\n",
       "         [ 1.3023e-01, -2.1229e-01, -5.6965e-03, -9.4611e-02,  6.9861e-01],\n",
       "         [-1.7781e-01,  3.9237e-01,  2.3900e-01,  6.2612e-01, -6.1734e-01],\n",
       "         [ 5.1051e-01,  3.7387e-01, -6.2773e-01, -3.1241e-01,  1.5774e-01],\n",
       "         [-3.0438e-01, -4.7586e-01,  1.1389e-01,  3.5127e-01, -6.6033e-01],\n",
       "         [ 8.0629e-01, -5.2145e-01,  3.5233e-01, -9.1999e-01,  3.6214e-01],\n",
       "         [ 6.4592e-02, -3.9584e-01,  2.1699e-01, -1.5888e-01, -7.0719e-01],\n",
       "         [-1.2002e-01,  1.3593e+00, -5.4085e-01,  4.3014e-01, -4.6034e-01],\n",
       "         [ 3.2924e-01,  1.7218e+00,  2.0271e-01,  1.0637e-01, -1.3277e-01],\n",
       "         [ 1.4119e+00,  3.7956e-01, -1.9891e-01,  5.2682e-02,  1.6602e-01],\n",
       "         [-2.1346e-01, -1.4273e+00,  6.1069e-02, -3.7399e-02,  4.2081e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.0440e-01,  4.4873e-01, -5.6161e-01, -5.7159e-01, -1.3371e-01,\n",
       "          1.7606e-01,  1.9645e-01,  8.1392e-01,  1.3935e-03,  2.9176e-02,\n",
       "          4.4212e-01,  1.8106e-01, -1.6397e-01, -5.7113e-01,  5.5498e-01,\n",
       "          5.8465e-01,  2.8851e-02, -3.2682e-01,  5.7238e-01, -4.1089e-01,\n",
       "          1.3286e-01, -1.1195e-02,  2.4146e-01,  2.2018e-01, -3.8820e-01,\n",
       "          6.2507e-02, -7.8251e-01,  3.8220e-01,  6.0009e-01, -3.4115e-01,\n",
       "         -4.0491e-01, -2.9333e-01,  2.3191e-01, -4.3688e-01, -6.0254e-02,\n",
       "          8.9940e-01,  4.4375e-02, -1.9907e-01,  7.1953e-01,  4.0556e-01,\n",
       "         -2.0594e-02,  1.8715e-02, -4.9754e-01, -3.6982e-01, -6.5182e-01,\n",
       "          7.0121e-02,  5.7584e-01, -3.3836e-01,  4.2028e-01, -2.4788e-01,\n",
       "          2.5608e-01, -2.4812e-01,  8.1542e-01, -3.6889e-01, -3.4880e-01,\n",
       "         -8.6547e-01, -4.9743e-01, -1.7887e-01, -8.1969e-01,  2.6745e-01,\n",
       "         -2.0875e-01, -3.0349e-01,  8.5882e-01,  5.3055e-01, -7.8152e-01,\n",
       "          3.2707e-02,  5.8084e-02, -1.7970e-01, -4.1339e-01, -3.5263e-02,\n",
       "         -5.1083e-01, -5.1690e-01, -5.5369e-01, -5.7114e-02, -7.4509e-01,\n",
       "          2.8680e-02, -1.0461e+00,  6.9788e-01,  4.1270e-01, -4.0401e-01,\n",
       "         -3.0450e-01,  4.1876e-01, -4.9113e-01,  6.6813e-01,  3.1939e-01,\n",
       "         -8.0672e-01,  1.7792e-02, -6.9373e-01, -8.2193e-01, -2.0972e-01,\n",
       "          4.4313e-02, -7.7221e-01, -6.1019e-01,  2.3382e-01, -7.2333e-01,\n",
       "          8.8835e-01, -6.7451e-01, -2.0683e-01, -4.9687e-01,  2.5706e-02,\n",
       "          1.3065e-01,  3.6110e-01,  1.7171e-01, -2.2024e-01, -2.6380e-02,\n",
       "         -5.6644e-01,  6.0667e-01, -7.6308e-01,  6.0634e-01,  2.0324e-01,\n",
       "         -2.7806e-01, -4.1694e-01,  5.1170e-02,  3.3787e-01, -7.6451e-01,\n",
       "         -6.0595e-01,  5.4338e-01,  7.0850e-01,  9.2003e-01,  4.7439e-01,\n",
       "          1.6498e-01, -9.2376e-01,  2.7458e-01,  5.0668e-02, -2.8385e-01,\n",
       "         -2.9405e-01,  4.6386e-01, -3.5295e-01,  2.4803e-01, -7.0417e-01,\n",
       "          4.1824e-01,  4.7311e-01,  9.0567e-01,  3.3725e-02, -8.4851e-01,\n",
       "          5.1524e-01,  5.9444e-01,  4.8637e-01,  5.1698e-01,  4.5058e-01,\n",
       "         -3.7549e-02,  8.4321e-02,  5.6487e-04, -5.1751e-01,  8.3559e-01,\n",
       "          1.5451e-01, -1.6894e-01,  5.3254e-01, -7.9282e-01,  2.2183e-01,\n",
       "          3.0507e-02,  1.2296e-01,  4.3427e-01,  4.0288e-01, -2.7812e-01,\n",
       "         -6.1313e-01,  5.0866e-01,  1.1178e+00, -4.6993e-01, -4.1102e-01,\n",
       "          2.6543e-01,  1.0719e-01, -1.5019e-01, -8.9815e-01,  3.2414e-01,\n",
       "         -6.6641e-01,  1.6218e-01, -5.1442e-01,  2.0256e-01,  6.3778e-01,\n",
       "          1.7816e-01, -4.6934e-01,  2.4910e-01,  9.1506e-02, -3.1853e-01,\n",
       "         -7.0349e-01, -4.0655e-01, -3.7777e-01, -5.0038e-01,  8.1092e-02,\n",
       "          5.7178e-01, -2.4552e-02,  3.6679e-01, -6.8947e-01,  8.7247e-02,\n",
       "          8.0068e-01, -6.8762e-01,  2.3015e-01, -6.9349e-01,  1.5550e-01,\n",
       "         -3.8654e-01, -3.6188e-02,  1.8372e-01,  8.2302e-01,  3.2289e-01,\n",
       "         -1.8686e-01,  5.1618e-01,  3.5962e-01,  3.0884e-02, -1.3996e-01],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.7955, -0.1805,  0.0225,  ...,  0.0113,  0.2244,  0.1894],\n",
       "         [-0.1151,  0.1139, -0.1232,  ...,  0.3106, -0.1470, -0.2497],\n",
       "         [ 0.1539,  0.1303, -0.2938,  ...,  0.0253, -0.2835,  0.0373],\n",
       "         ...,\n",
       "         [-0.1303,  0.2091, -0.3952,  ...,  0.3339, -0.1933, -0.0931],\n",
       "         [ 0.3228,  0.4047,  0.4792,  ..., -0.4785, -0.6401,  0.2776],\n",
       "         [-0.3409, -0.2148,  0.5448,  ..., -0.7857, -0.1153,  0.5031]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.3243e-01, -1.1176e-01,  2.0503e-01, -8.9479e-02,  1.0194e-01,\n",
       "          1.6765e-01,  8.7338e-02, -8.2149e-02, -8.2000e-01,  1.9844e-01,\n",
       "         -2.3096e-01, -2.8993e-01,  3.1736e-01,  2.5301e-01, -9.0895e-03,\n",
       "          1.2393e-01,  1.1194e-01, -4.5390e-01,  3.3537e-01, -2.9735e-01,\n",
       "          2.6866e-01,  1.4054e-02,  7.7855e-02, -1.9197e-01,  2.7073e-02,\n",
       "         -7.8247e-02,  1.1932e-01,  1.2657e-01, -9.0667e-02, -4.1142e-01,\n",
       "         -2.7336e-02, -4.6915e-02,  1.6931e-01, -9.7279e-02,  2.0548e-01,\n",
       "          1.3745e-01, -5.7802e-02,  6.5397e-02, -7.4481e-02, -2.4860e-01,\n",
       "          6.1610e-03, -2.3749e-01,  5.3364e-02, -8.9200e-03, -1.3273e-01,\n",
       "         -1.7770e-01, -1.5331e-01,  3.6486e-01,  2.0135e-01,  7.1471e-02,\n",
       "         -8.6359e-02,  3.9472e-01,  2.1909e-01, -3.3737e-01,  2.3192e-02,\n",
       "          1.2792e-01, -3.9194e-01,  1.7107e-01,  1.4741e-01, -2.4067e-02,\n",
       "         -1.7502e-01, -1.2178e-01, -9.3839e-02, -2.4382e-01, -4.0438e-01,\n",
       "          1.9366e-01,  1.9542e-01, -2.3596e-01, -7.3448e-02, -1.4174e-01,\n",
       "          7.2279e-03,  4.2338e-02,  4.0576e-01,  1.3353e-01,  3.1591e-02,\n",
       "         -1.1800e-01,  2.9960e-01,  3.9272e-01, -5.5560e-04,  1.8718e-01,\n",
       "         -1.9996e-01, -4.5376e-01,  1.2174e-01,  2.9318e-01,  2.4427e-02,\n",
       "          1.7838e-01, -1.2461e-01,  2.9535e-01,  1.7528e-01, -1.2929e-01,\n",
       "          2.1293e-01,  7.1827e-02, -1.7822e-02,  2.8299e-03, -2.2468e-01,\n",
       "         -1.1904e-01, -4.6427e-02, -1.7669e-02,  7.4340e-02,  4.1430e-01,\n",
       "          8.1745e-02,  1.2103e-01,  1.4827e-01, -2.2253e-02, -2.0803e-01,\n",
       "          3.9761e-04, -2.0515e-02, -2.4069e-01,  1.7695e-01, -1.2176e-01,\n",
       "         -1.7129e-01,  1.6592e-01, -2.7522e-02,  7.6457e-02,  2.2301e-01,\n",
       "         -2.4290e-01, -8.1756e-02, -9.1314e-02,  8.9467e-02,  2.4037e-01,\n",
       "         -1.8907e-01, -1.0692e-01,  2.0133e-01,  5.6611e-02, -7.2488e-02,\n",
       "          3.8699e-01, -1.2780e-02, -5.3866e-01, -4.8535e-01,  1.7433e-01,\n",
       "          3.3413e-01,  1.3903e-01,  1.9384e-01, -2.8993e-01, -9.8331e-02,\n",
       "         -1.2961e-01,  1.4648e-01,  2.6883e-01, -1.0084e-01,  1.0572e-01,\n",
       "         -1.2691e-01,  6.1942e-02,  9.7579e-03,  1.7617e-01, -2.0080e-02,\n",
       "         -2.5852e-01, -6.7923e-02, -2.7999e-02, -1.9304e-01,  7.2528e-03,\n",
       "         -6.4977e-02,  3.4468e-01,  2.1484e-01, -4.5834e-02,  3.0472e-01,\n",
       "          4.0859e-02,  1.1330e-01, -1.5901e-01, -1.4649e-02,  3.0676e-01,\n",
       "         -1.4207e-01,  1.8378e-03, -6.1895e-02,  1.7988e-01, -4.6180e-02,\n",
       "          3.6625e-01,  1.6536e-01,  4.1649e-01, -4.7644e-02, -2.9007e-01,\n",
       "          4.9731e-02,  1.8786e-01, -1.7522e-02,  1.9009e-01,  4.2980e-02,\n",
       "          6.6433e-02,  9.6276e-02,  1.5549e-01, -2.2750e-01,  2.0094e-03,\n",
       "          3.5239e-01,  3.0686e-01, -1.5402e-01,  1.6635e-01, -1.1488e-01,\n",
       "          2.0943e-01,  1.9935e-01, -1.0893e-01, -2.0477e-01, -3.5983e-01,\n",
       "         -2.1560e-01, -1.0247e-01,  3.1086e-02,  3.0858e-01,  9.8577e-02,\n",
       "         -8.1923e-03, -4.7255e-02,  4.0256e-01, -1.0818e-01, -5.4023e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1233, -0.1175,  0.0875,  ...,  0.2511,  0.5091,  0.0908],\n",
       "         [ 0.4573,  0.0870,  0.2112,  ...,  0.1470, -0.2986, -0.4877],\n",
       "         [ 0.3821,  0.1231,  0.2414,  ...,  0.3425, -0.2310, -0.0805],\n",
       "         ...,\n",
       "         [-0.2118,  0.0370,  0.1059,  ...,  0.0138,  0.1293,  0.3112],\n",
       "         [-0.4207, -0.7324,  0.2529,  ...,  0.1029,  0.2534,  0.5158],\n",
       "         [ 0.1704, -0.4693,  0.2415,  ...,  0.2171, -0.3349, -0.1309]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1453,  0.4095,  0.0626, -0.1418, -0.0938,  0.2323, -0.1942,  0.2066,\n",
       "          0.0339, -0.1302, -0.7788, -0.3665,  0.1031, -0.1280, -0.2903,  0.0477,\n",
       "         -0.2675,  0.0168, -0.2548,  0.1078,  0.1672,  0.1008,  0.1028,  0.3024,\n",
       "         -0.1488, -0.0979, -0.1667, -0.0303,  0.4029,  0.0928,  0.1427, -0.0658,\n",
       "          0.7705, -0.1790,  0.1614,  0.1344,  0.2384, -0.1201, -0.4395,  0.0385,\n",
       "          0.4310,  0.1811, -0.4849, -0.1264,  0.0381,  0.1821, -0.1639, -0.2208,\n",
       "          0.3003, -0.1403,  0.0569, -0.0744,  0.0107, -0.2619, -0.5130, -0.1118,\n",
       "          0.0107,  0.3062, -0.0408, -0.0023,  0.0573,  0.3724, -0.0176, -0.2376,\n",
       "          0.0031, -0.1712,  0.1522, -0.2242,  0.0051,  0.1850, -0.1032, -0.1503,\n",
       "         -0.0156,  0.1614, -0.1634,  0.2194,  0.1648, -0.2320,  0.2145,  0.1327,\n",
       "          0.1473, -0.2669,  0.0356, -0.1422,  0.0416,  0.0715,  0.1011,  0.1609,\n",
       "          0.4863,  0.0642,  0.1980, -0.3371, -0.0143, -0.4808,  0.0037, -0.0643,\n",
       "         -0.0621,  0.2605,  0.6700, -0.2483,  0.1954, -0.2455, -0.1659, -0.2317,\n",
       "         -0.0612,  0.2931, -0.0171,  0.0028,  0.3613,  0.0987,  0.1229,  0.2684,\n",
       "         -0.0370,  0.0139,  0.1500,  0.0086, -0.0077,  0.1550,  0.0050,  0.1924,\n",
       "         -0.3351, -0.0013,  0.2132, -0.1594,  0.3675, -0.0053,  0.7043,  0.1761,\n",
       "          0.1770, -0.5085, -0.0992,  0.0558,  0.3637,  0.0342,  0.2950, -0.1922,\n",
       "          0.0369, -0.0994,  0.0907,  0.0593,  0.1704,  0.1634,  0.2631, -0.1498,\n",
       "          0.3248, -0.0686,  0.1146,  0.1365, -0.0864, -0.0476,  0.3926, -0.0485,\n",
       "          0.0543,  0.0428, -0.0699, -0.0047, -0.2473,  0.0061,  0.1414,  0.2309,\n",
       "          0.1199, -0.0423, -0.0662,  0.2294, -0.2761, -0.0603, -0.0381, -0.3148,\n",
       "         -0.0832, -0.0019,  0.3172, -0.1381,  0.0575, -0.3470, -0.1551, -0.3133,\n",
       "          0.0336, -0.0380,  0.2104, -0.1415, -0.0707, -0.0463,  0.0690, -0.0932,\n",
       "         -0.0765, -0.0197, -0.1763, -0.4153, -0.0923,  0.2318,  0.2610,  0.0046,\n",
       "          0.0185, -0.0094,  0.1594, -0.3876, -0.1346, -0.1104,  0.0049,  0.0953],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.5492e-03,  1.2768e-03, -7.9175e-04, -1.8976e-04, -2.3210e-03,\n",
       "          -9.9116e-04,  1.6013e-03,  8.7479e-04,  3.0177e-03, -8.1650e-04,\n",
       "          -8.4445e-03, -5.2583e-04,  3.4273e-04,  1.0778e-03,  1.7770e-03,\n",
       "          -3.4305e-04,  1.8746e-03,  5.2245e-04,  7.4050e-04, -6.3894e-04,\n",
       "           1.5759e-03, -9.4017e-04, -7.6970e-04, -9.6241e-04, -1.7886e-03,\n",
       "          -1.1493e-03,  3.7448e-04, -4.0608e-04, -1.3435e-03,  1.1879e-03,\n",
       "          -7.2418e-04, -2.2996e-03,  1.8205e-02, -1.0475e-04,  2.2889e-03,\n",
       "           8.7731e-04, -5.6366e-04, -6.1618e-04, -4.1653e-03, -1.5997e-03,\n",
       "           1.7538e-03,  2.0860e-03, -1.4771e-03,  8.8311e-05, -2.3018e-03,\n",
       "           6.8245e-03,  1.2950e-04, -2.8345e-03, -2.1704e-03,  2.4542e-04,\n",
       "           7.5852e-04, -6.8973e-04, -1.6560e-03, -3.9612e-03,  1.9064e-03,\n",
       "          -3.8382e-04,  1.2781e-03, -4.0214e-03,  4.5660e-04,  7.0994e-04,\n",
       "          -2.4280e-03,  1.5859e-03,  2.1103e-03, -4.8449e-03, -1.7781e-05,\n",
       "           1.5699e-03, -7.0047e-04, -7.4939e-04,  1.3784e-03,  1.8069e-03,\n",
       "          -1.3331e-03, -5.8471e-04, -1.6434e-04,  2.0478e-04,  8.4239e-04,\n",
       "          -1.0722e-03, -1.0074e-03,  2.1349e-04, -7.5930e-04, -6.0417e-04,\n",
       "           1.6031e-03, -2.2097e-03, -1.0642e-03,  2.5960e-03,  4.7176e-04,\n",
       "           2.9400e-04, -4.0227e-03,  3.3684e-03,  2.8646e-03, -3.8208e-04,\n",
       "           1.5874e-03,  3.6347e-03,  1.7678e-03,  1.3411e-03,  2.7931e-04,\n",
       "          -1.7455e-03, -4.0009e-05,  4.0434e-04,  1.0891e-03, -3.7997e-03,\n",
       "           1.1259e-03,  3.5618e-03, -1.1259e-03, -6.0052e-04,  9.3951e-04,\n",
       "          -7.6047e-03, -1.2092e-03,  3.6386e-04, -4.7661e-04, -5.1353e-04,\n",
       "           2.5285e-03, -4.2956e-04, -9.4908e-04,  1.0558e-03,  2.2807e-04,\n",
       "           1.5443e-04,  8.0309e-05,  7.8116e-04,  1.5623e-03,  6.2395e-04,\n",
       "           6.5308e-04, -9.0204e-04, -1.1199e-03,  1.6391e-03,  3.3523e-04,\n",
       "           8.5622e-04, -6.7475e-04, -8.9862e-04,  1.0742e-03, -4.4418e-03,\n",
       "           3.6786e-04,  4.3512e-03, -9.2633e-04, -2.6493e-04,  3.4822e-03,\n",
       "          -2.6321e-03,  2.5114e-04, -2.9966e-04,  1.6543e-03,  3.1340e-03,\n",
       "          -4.2381e-04, -4.3294e-04, -5.7763e-04,  5.4380e-04, -1.2812e-03,\n",
       "           6.4024e-04, -1.9941e-03, -4.5447e-04,  2.5357e-04,  8.4938e-04,\n",
       "           8.1977e-03, -1.8546e-03, -3.4334e-03, -5.1610e-04,  2.3339e-03,\n",
       "           1.2184e-03, -2.3268e-04, -3.2987e-04, -6.6136e-04, -1.4459e-03,\n",
       "           2.8868e-03, -1.4030e-03, -6.1567e-04,  1.9353e-03, -1.7263e-03,\n",
       "           2.2459e-03, -1.1782e-03, -1.3030e-04, -1.1661e-03, -9.7796e-05,\n",
       "           1.0666e-03, -1.6647e-03,  9.6331e-04,  3.6628e-03, -9.3514e-04,\n",
       "          -2.0631e-03, -1.6808e-03, -1.5074e-03, -7.6708e-04, -3.4634e-04,\n",
       "          -1.0476e-03,  3.9826e-04,  4.0064e-03, -8.3417e-04, -9.9204e-05,\n",
       "          -3.1127e-04, -3.9724e-03, -2.7689e-03,  7.4418e-03,  1.2370e-03,\n",
       "          -3.1058e-03, -4.3566e-04,  2.4970e-03, -1.2817e-03, -7.4739e-04,\n",
       "          -2.1755e-04,  5.2369e-04, -3.4106e-03, -2.0977e-03, -3.5433e-04]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1176], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3488, 0.1515, 0.8363, 0.2112, 0.7890],\n",
      "        [0.9999, 0.6034, 0.4520, 0.6607, 0.7999]])\n",
      "tensor([[ 0.0210],\n",
      "        [-0.1551]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lnorm = nn.LayerNorm(5)\n",
    "Bnorm = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f854e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.1385e+02, 1.6111e+02, 2.4511e-01, 5.1809e-02, 7.0308e-01],\n",
      "        [7.0049e+02, 1.0764e+02, 5.1967e-01, 8.9767e-02, 3.9057e-01],\n",
      "        [7.0071e+02, 2.3276e+02, 4.3495e-01, 3.7777e-01, 1.8729e-01],\n",
      "        [7.5411e+02, 2.0480e+02, 4.7358e-01, 3.0204e-02, 4.9622e-01],\n",
      "        [7.4152e+02, 1.9121e+02, 3.3226e-01, 2.2861e-01, 4.3913e-01],\n",
      "        [7.1753e+02, 1.3231e+02, 8.1306e-01, 1.7251e-01, 1.4427e-02],\n",
      "        [6.8244e+02, 2.1791e+02, 6.6918e-02, 7.7668e-01, 1.5640e-01],\n",
      "        [7.3939e+02, 1.4485e+02, 8.6256e-01, 1.1403e-01, 2.3407e-02],\n",
      "        [8.4751e+02, 1.5292e+02, 7.0039e-01, 1.0949e-01, 1.9012e-01],\n",
      "        [7.5393e+02, 1.0764e+02, 2.8375e-01, 1.2442e-01, 5.9183e-01],\n",
      "        [8.0368e+02, 2.4941e+02, 6.8637e-01, 1.1263e-01, 2.0101e-01],\n",
      "        [6.8988e+02, 2.3428e+02, 1.2363e-01, 8.0806e-01, 6.8309e-02],\n",
      "        [6.8209e+02, 1.9505e+02, 3.3419e-02, 9.3058e-01, 3.5999e-02],\n",
      "        [6.7328e+02, 2.4016e+02, 3.1145e-01, 2.2219e-01, 4.6636e-01],\n",
      "        [8.0115e+02, 2.3804e+02, 6.4530e-01, 1.7484e-01, 1.7986e-01],\n",
      "        [8.2707e+02, 1.2762e+02, 2.7872e-01, 6.2162e-01, 9.9663e-02],\n",
      "        [7.2974e+02, 1.6856e+02, 7.5620e-01, 1.5774e-01, 8.6056e-02],\n",
      "        [7.6258e+02, 2.2398e+02, 2.1963e-01, 2.1510e-01, 5.6527e-01],\n",
      "        [7.4903e+02, 1.3364e+02, 1.6116e-01, 6.6914e-01, 1.6970e-01],\n",
      "        [6.7055e+02, 1.6732e+02, 7.2367e-01, 1.2468e-01, 1.5165e-01],\n",
      "        [6.9698e+02, 2.4808e+02, 2.4557e-01, 6.4247e-01, 1.1196e-01],\n",
      "        [7.5522e+02, 1.1687e+02, 8.2785e-01, 1.2518e-01, 4.6969e-02],\n",
      "        [8.2424e+02, 1.0737e+02, 2.0074e-01, 7.0730e-01, 9.1963e-02],\n",
      "        [6.5669e+02, 1.4746e+02, 9.7173e-01, 2.6274e-02, 1.9976e-03],\n",
      "        [7.3022e+02, 1.2288e+02, 3.5670e-02, 7.3773e-02, 8.9056e-01],\n",
      "        [6.5678e+02, 2.2419e+02, 1.9221e-01, 1.9317e-02, 7.8848e-01],\n",
      "        [7.8700e+02, 1.0214e+02, 1.5869e-01, 5.3769e-01, 3.0362e-01],\n",
      "        [6.6662e+02, 2.4638e+02, 4.5439e-01, 1.4354e-01, 4.0207e-01],\n",
      "        [7.6511e+02, 2.0594e+02, 3.9794e-02, 2.3822e-02, 9.3638e-01],\n",
      "        [8.2922e+02, 1.0949e+02, 4.3370e-01, 6.6760e-02, 4.9954e-01],\n",
      "        [6.8452e+02, 2.3801e+02, 4.9892e-01, 9.4287e-03, 4.9166e-01],\n",
      "        [7.5461e+02, 1.1997e+02, 6.4134e-01, 1.8927e-01, 1.6939e-01]])\n",
      "tensor([ 4.4409e-16, -5.4123e-16, -2.2204e-16,  1.8388e-16,  2.7756e-17],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.4087, -0.2820, -0.6382, -0.8101,  1.4914],\n",
      "        [-0.6568, -1.3208,  0.3760, -0.6699,  0.3028],\n",
      "        [-0.6527,  1.1100,  0.0630,  0.3938, -0.4704],\n",
      "        [ 0.3387,  0.5668,  0.2057, -0.8899,  0.7046],\n",
      "        [ 0.1049,  0.3029, -0.3163, -0.1571,  0.4875],\n",
      "        [-0.3404, -0.8416,  1.4598, -0.3643, -1.1279],\n",
      "        [-0.9919,  0.8216, -1.2965,  1.8671, -0.5879],\n",
      "        [ 0.0654, -0.5979,  1.6426, -0.5803, -1.0937],\n",
      "        [ 2.0726, -0.4412,  1.0436, -0.5970, -0.4596],\n",
      "        [ 0.3354, -1.3210, -0.4955, -0.5419,  1.0683],\n",
      "        [ 1.2590,  1.4336,  0.9918, -0.5855, -0.4182],\n",
      "        [-0.8537,  1.1397, -1.0870,  1.9829, -0.9229],\n",
      "        [-0.9984,  0.3774, -1.4202,  2.4355, -1.0458],\n",
      "        [-1.1619,  1.2539, -0.3932, -0.1808,  0.5910],\n",
      "        [ 1.2120,  1.2127,  0.8401, -0.3557, -0.4987],\n",
      "        [ 1.6932, -0.9327, -0.5141,  1.2944, -0.8037],\n",
      "        [-0.1138, -0.1373,  1.2497, -0.4188, -0.8554],\n",
      "        [ 0.4960,  0.9396, -0.7324, -0.2070,  0.9672],\n",
      "        [ 0.2444, -0.8157, -0.9483,  1.4699, -0.5373],\n",
      "        [-1.2126, -0.1613,  1.1296, -0.5409, -0.6060],\n",
      "        [-0.7220,  1.4078, -0.6365,  1.3714, -0.7569],\n",
      "        [ 0.3592, -1.1416,  1.5144, -0.5391, -1.0041],\n",
      "        [ 1.6406, -1.3262, -0.8021,  1.6108, -0.8330],\n",
      "        [-1.4699, -0.5472,  2.0459, -0.9044, -1.1752],\n",
      "        [-0.1048, -1.0247, -1.4119, -0.7289,  2.2045],\n",
      "        [-1.4683,  0.9436, -0.8337, -0.9301,  1.8162],\n",
      "        [ 0.9492, -1.4277, -0.9575,  0.9844, -0.0279],\n",
      "        [-1.2855,  1.3747,  0.1348, -0.4713,  0.3465],\n",
      "        [ 0.5429,  0.5889, -1.3967, -0.9134,  2.3788],\n",
      "        [ 1.7332, -1.2849,  0.0584, -0.7548,  0.7172],\n",
      "        [-0.9532,  1.2120,  0.2993, -0.9666,  0.6872],\n",
      "        [ 0.3480, -1.0814,  0.8254, -0.3024, -0.5385]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    #print(y.reshape((-1,1)))\n",
    "    print(Bnorm(X).mean(dim=0))\n",
    "    print(Bnorm(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
