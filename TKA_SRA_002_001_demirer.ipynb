{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54dc0a0",
   "metadata": {},
   "source": [
    "# Architektur Neuronales Netz Demirer et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aNN Architektur\n",
    "\n",
    "# Importe / Bibliotheken\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import log10\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ebf3",
   "metadata": {},
   "source": [
    "#### Default Datentyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5067",
   "metadata": {},
   "source": [
    "#### Erzeugnung des Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bffc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    #Initalisierung der Netzwerk layers\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "    \n",
    "        super().__init__() #Referenz zur Base Class (nn.Module)\n",
    "        #Kaskade der Layer\n",
    "        self.linear_afunc_stack = nn.Sequential(\n",
    "            #nn.LayerNorm(input_size), # Normalisierung, damit Inputdaten gleiche Größenordnung haben\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size, hidden1_size), #Nicht lineare Aktivierungsfunktion um komplexe nichtlineare Zusammenhänge abzubilden \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.01),\n",
    "            nn.Linear(hidden1_size, hidden2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2_size, output_size),\n",
    "        )\n",
    "\n",
    "    #Implementierung der Operationen auf Input Daten\n",
    "    def forward(self, x):\n",
    "        out = self.linear_afunc_stack(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9ae53",
   "metadata": {},
   "source": [
    "#### Ausgabe Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_afunc_stack): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=5, out_features=200, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.01, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(5, 200, 200, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1d6ae",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08ff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #Zahl der Datenpaare die vor einem erneuten Update der Parameter ins Netzt gegeben werden\n",
    "eq_data_file = Path.cwd() / 'data' / 'eq_dataset.npz' #Import der GGW Daten\n",
    "\n",
    "res = np.load(eq_data_file)\n",
    "\n",
    "# Bei Speicherung wurden Daten als T, p, x_0 und xi gespeichert\n",
    "# Inputs T, p, x_0[H2,N2,NH3]\n",
    "# Outputs xi\n",
    "# Umwandlen der np.arrays in torch.tensors zur besseren Arbeit mit PyTorch\n",
    "T = torch.tensor(res['T'])\n",
    "p = torch.tensor(res['p'])\n",
    "x_0 = torch.tensor(res['x_0'])\n",
    "xi = torch.tensor(res['xi'])\n",
    "\n",
    "#Anpassen der Daten auf gleiche Größenordnung\n",
    "#Bnorm = nn.BatchNorm1d(5)\n",
    "T = log10(T)\n",
    "p = p / 1000\n",
    "# T = torch.tensor(res['T']).float()\n",
    "# p = torch.tensor(res['p']).float()\n",
    "# x_0 = torch.tensor(res['x_0']).float()\n",
    "# xi = torch.tensor(res['xi']).float()\n",
    "\n",
    "# print(T.dtype)\n",
    "# print(xi.dtype)\n",
    "\n",
    "x_input = torch.stack((T, p ,x_0[:,0],x_0[:,1],x_0[:,2]),1)\n",
    "#x_input = Bnorm(x_input)\n",
    "y_output = xi.reshape((-1,1))\n",
    "#print(x_input.size())\n",
    "# print(xi.size())\n",
    "\n",
    "# Tensoren zu einem großen Set gruppieren\n",
    "dataset = TensorDataset(x_input, y_output)\n",
    "\n",
    "# for x,y in dataset:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    \n",
    "# Split in Trainings und Test Set\n",
    "train_dataset, test_dataset = random_split(dataset, \n",
    "                                           [int(0.8*len(dataset)), int(0.2*len(dataset))], # splitting 80/20\n",
    "                                           generator = torch.Generator().manual_seed(42)) # Festlegung seed zur Reproduktivität\n",
    "\n",
    "# Erzeugen der DataLoader zur Arbeit mit Daten\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) # shuffle batches zur Reduzierung von overfitting\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e9841",
   "metadata": {},
   "source": [
    "#### Generierung Netzwerk, Festlegung von loss Funktion und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung aNN\n",
    "net = NeuralNetwork(5, 200, 200, 1)\n",
    "\n",
    "# Loss Funktion; gibt Fehler an\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "#Definition custom loss Funktion, MRE\n",
    "def MRELoss(outputs, targets):\n",
    "    \n",
    "    loss = torch.mean(abs((outputs - targets) / targets))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "#Optimizer\n",
    "learning_rate = 0.02\n",
    "#learnin_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "#scheduler = StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 200], gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b61b7",
   "metadata": {},
   "source": [
    "#### Funktion zur Bestimmung der Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, net):\n",
    "    \n",
    "    loss = 0\n",
    "    MRE = 0\n",
    "    train_correct = 0\n",
    "    train_total = len(loader.dataset)\n",
    "    num_batches = len(loader) \n",
    "    #train_total = 0\n",
    "    \n",
    "    net.eval() # Put network in evaluation mode\n",
    "    \n",
    "    if loader == train_dataloader:\n",
    "        dataset = \"Train\"\n",
    "    else:\n",
    "        dataset = \"Test\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = net(X)\n",
    "            #print(pred.size())\n",
    "           \n",
    "            #loss += MRELoss(pred, y).item()\n",
    "            loss += loss_fn(pred, y) # Calculate the loss\n",
    "            MRE += MRELoss(pred, y)\n",
    "\n",
    "            # Record the correct predictions for training data\n",
    "            #_, predictions = torch.max(pred.data, 1)\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] - y[i] <= 0.01:\n",
    "                    train_correct += 1\n",
    "            #train_correct += (abs(pred.argmax(1) - y) <= 0.01).sum().item()\n",
    "            #train_correct += (abs(predictions - y.data) <= 0.01).sum()\n",
    "            #train_total += predictions.size(0)\n",
    "            \n",
    "        # Genauigkeit berechnen\n",
    "        acc = float(train_correct) / float(train_total) * 100\n",
    "        acc = round(acc, 2)\n",
    "        \n",
    "        loss /= num_batches\n",
    "        MRE /= num_batches\n",
    "        print(f\"{dataset} Error: \\n Accuracy: {acc}%, Avg loss: {loss:>8f}, MRE: {MRE:>8f} \\n\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    return acc, loss, MRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd049ed",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771789d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800, Iteration 1/12, Loss: 0.0139\n",
      "Epoch 1/800, Iteration 2/12, Loss: 0.0074\n",
      "Epoch 1/800, Iteration 3/12, Loss: 0.0082\n",
      "Epoch 1/800, Iteration 4/12, Loss: 0.0088\n",
      "Epoch 1/800, Iteration 5/12, Loss: 0.0084\n",
      "Epoch 1/800, Iteration 6/12, Loss: 0.0063\n",
      "Epoch 1/800, Iteration 7/12, Loss: 0.0068\n",
      "Epoch 1/800, Iteration 8/12, Loss: 0.0060\n",
      "Epoch 1/800, Iteration 9/12, Loss: 0.0071\n",
      "Epoch 1/800, Iteration 10/12, Loss: 0.0095\n",
      "Epoch 1/800, Iteration 11/12, Loss: 0.0045\n",
      "Epoch 1/800, Iteration 12/12, Loss: 0.0073\n",
      "Epoch 1/800, Iteration 13/12, Loss: 0.0050\n",
      "Train Error: \n",
      " Accuracy: 50.25%, Avg loss: 0.005971, MRE: 2.509959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 0.006606, MRE: 3.075942 \n",
      "\n",
      "Epoch 2/800, Iteration 1/12, Loss: 0.0059\n",
      "Epoch 2/800, Iteration 2/12, Loss: 0.0072\n",
      "Epoch 2/800, Iteration 3/12, Loss: 0.0053\n",
      "Epoch 2/800, Iteration 4/12, Loss: 0.0043\n",
      "Epoch 2/800, Iteration 5/12, Loss: 0.0043\n",
      "Epoch 2/800, Iteration 6/12, Loss: 0.0057\n",
      "Epoch 2/800, Iteration 7/12, Loss: 0.0049\n",
      "Epoch 2/800, Iteration 8/12, Loss: 0.0066\n",
      "Epoch 2/800, Iteration 9/12, Loss: 0.0064\n",
      "Epoch 2/800, Iteration 10/12, Loss: 0.0051\n",
      "Epoch 2/800, Iteration 11/12, Loss: 0.0033\n",
      "Epoch 2/800, Iteration 12/12, Loss: 0.0051\n",
      "Epoch 2/800, Iteration 13/12, Loss: 0.0043\n",
      "Train Error: \n",
      " Accuracy: 45.75%, Avg loss: 0.005052, MRE: 1.946258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 0.005803, MRE: 3.383039 \n",
      "\n",
      "Epoch 3/800, Iteration 1/12, Loss: 0.0047\n",
      "Epoch 3/800, Iteration 2/12, Loss: 0.0044\n",
      "Epoch 3/800, Iteration 3/12, Loss: 0.0043\n",
      "Epoch 3/800, Iteration 4/12, Loss: 0.0045\n",
      "Epoch 3/800, Iteration 5/12, Loss: 0.0040\n",
      "Epoch 3/800, Iteration 6/12, Loss: 0.0052\n",
      "Epoch 3/800, Iteration 7/12, Loss: 0.0044\n",
      "Epoch 3/800, Iteration 8/12, Loss: 0.0045\n",
      "Epoch 3/800, Iteration 9/12, Loss: 0.0029\n",
      "Epoch 3/800, Iteration 10/12, Loss: 0.0029\n",
      "Epoch 3/800, Iteration 11/12, Loss: 0.0038\n",
      "Epoch 3/800, Iteration 12/12, Loss: 0.0036\n",
      "Epoch 3/800, Iteration 13/12, Loss: 0.0060\n",
      "Train Error: \n",
      " Accuracy: 65.88%, Avg loss: 0.003395, MRE: 2.746416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.003428, MRE: 2.815221 \n",
      "\n",
      "Epoch 4/800, Iteration 1/12, Loss: 0.0033\n",
      "Epoch 4/800, Iteration 2/12, Loss: 0.0035\n",
      "Epoch 4/800, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 4/800, Iteration 4/12, Loss: 0.0028\n",
      "Epoch 4/800, Iteration 5/12, Loss: 0.0038\n",
      "Epoch 4/800, Iteration 6/12, Loss: 0.0037\n",
      "Epoch 4/800, Iteration 7/12, Loss: 0.0041\n",
      "Epoch 4/800, Iteration 8/12, Loss: 0.0039\n",
      "Epoch 4/800, Iteration 9/12, Loss: 0.0033\n",
      "Epoch 4/800, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 4/800, Iteration 11/12, Loss: 0.0026\n",
      "Epoch 4/800, Iteration 12/12, Loss: 0.0030\n",
      "Epoch 4/800, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 62.25%, Avg loss: 0.002781, MRE: 2.260393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.002960, MRE: 2.358701 \n",
      "\n",
      "Epoch 5/800, Iteration 1/12, Loss: 0.0025\n",
      "Epoch 5/800, Iteration 2/12, Loss: 0.0028\n",
      "Epoch 5/800, Iteration 3/12, Loss: 0.0039\n",
      "Epoch 5/800, Iteration 4/12, Loss: 0.0032\n",
      "Epoch 5/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 5/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 5/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 5/800, Iteration 8/12, Loss: 0.0031\n",
      "Epoch 5/800, Iteration 9/12, Loss: 0.0038\n",
      "Epoch 5/800, Iteration 10/12, Loss: 0.0044\n",
      "Epoch 5/800, Iteration 11/12, Loss: 0.0025\n",
      "Epoch 5/800, Iteration 12/12, Loss: 0.0031\n",
      "Epoch 5/800, Iteration 13/12, Loss: 0.0034\n",
      "Train Error: \n",
      " Accuracy: 67.12%, Avg loss: 0.002505, MRE: 2.441324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.002501, MRE: 2.127105 \n",
      "\n",
      "Epoch 6/800, Iteration 1/12, Loss: 0.0027\n",
      "Epoch 6/800, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 6/800, Iteration 3/12, Loss: 0.0034\n",
      "Epoch 6/800, Iteration 4/12, Loss: 0.0025\n",
      "Epoch 6/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 6/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 6/800, Iteration 7/12, Loss: 0.0030\n",
      "Epoch 6/800, Iteration 8/12, Loss: 0.0024\n",
      "Epoch 6/800, Iteration 9/12, Loss: 0.0037\n",
      "Epoch 6/800, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 6/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 6/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 6/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.002193, MRE: 2.216629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.002225, MRE: 2.279193 \n",
      "\n",
      "Epoch 7/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 7/800, Iteration 2/12, Loss: 0.0026\n",
      "Epoch 7/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 7/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 7/800, Iteration 5/12, Loss: 0.0026\n",
      "Epoch 7/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 7/800, Iteration 7/12, Loss: 0.0038\n",
      "Epoch 7/800, Iteration 8/12, Loss: 0.0029\n",
      "Epoch 7/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 7/800, Iteration 10/12, Loss: 0.0025\n",
      "Epoch 7/800, Iteration 11/12, Loss: 0.0027\n",
      "Epoch 7/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 7/800, Iteration 13/12, Loss: 0.0037\n",
      "Train Error: \n",
      " Accuracy: 63.12%, Avg loss: 0.001922, MRE: 1.945437 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.002041, MRE: 2.504848 \n",
      "\n",
      "Epoch 8/800, Iteration 1/12, Loss: 0.0024\n",
      "Epoch 8/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 8/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 8/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 8/800, Iteration 5/12, Loss: 0.0028\n",
      "Epoch 8/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 8/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 8/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 8/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 8/800, Iteration 10/12, Loss: 0.0027\n",
      "Epoch 8/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 8/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 8/800, Iteration 13/12, Loss: 0.0026\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001783, MRE: 1.747873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001946, MRE: 2.760984 \n",
      "\n",
      "Epoch 9/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 9/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 9/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 9/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 9/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 9/800, Iteration 6/12, Loss: 0.0026\n",
      "Epoch 9/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 9/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 9/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 9/800, Iteration 10/12, Loss: 0.0031\n",
      "Epoch 9/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 9/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 9/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.001907, MRE: 1.517998 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.002168, MRE: 3.395332 \n",
      "\n",
      "Epoch 10/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 10/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 10/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 10/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 10/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 10/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 10/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 10/800, Iteration 8/12, Loss: 0.0022\n",
      "Epoch 10/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 10/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 10/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 10/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 10/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 61.12%, Avg loss: 0.001553, MRE: 1.969884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001656, MRE: 2.743601 \n",
      "\n",
      "Epoch 11/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 11/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 11/800, Iteration 3/12, Loss: 0.0023\n",
      "Epoch 11/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 11/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 11/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 11/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 11/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 11/800, Iteration 9/12, Loss: 0.0023\n",
      "Epoch 11/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 11/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 11/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 11/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001518, MRE: 1.645316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001600, MRE: 2.858279 \n",
      "\n",
      "Epoch 12/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 12/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 12/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 12/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 12/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 12/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 12/800, Iteration 7/12, Loss: 0.0023\n",
      "Epoch 12/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 12/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 12/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 12/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 12/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 12/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001444, MRE: 1.623522 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001518, MRE: 2.858588 \n",
      "\n",
      "Epoch 13/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 13/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 13/800, Iteration 3/12, Loss: 0.0026\n",
      "Epoch 13/800, Iteration 4/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 13/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 13/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 13/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 13/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 13/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 13/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 13/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 13/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 63.62%, Avg loss: 0.001377, MRE: 1.660016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001410, MRE: 2.665120 \n",
      "\n",
      "Epoch 14/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 14/800, Iteration 2/12, Loss: 0.0024\n",
      "Epoch 14/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 14/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 14/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 14/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 14/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 14/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 14/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 14/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 14/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 14/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 14/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 71.12%, Avg loss: 0.001463, MRE: 1.859757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.001382, MRE: 2.263910 \n",
      "\n",
      "Epoch 15/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 15/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 15/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 15/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 15/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 15/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 15/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 15/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 15/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 15/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 15/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 15/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 15/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.001349, MRE: 1.605959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001363, MRE: 2.840541 \n",
      "\n",
      "Epoch 16/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 16/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 16/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 16/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 16/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 16/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 16/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 16/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 16/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 16/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 16/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 16/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 16/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001344, MRE: 2.054679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001388, MRE: 3.106920 \n",
      "\n",
      "Epoch 17/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 17/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 17/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 17/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 17/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 17/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 17/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 17/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 17/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 17/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 17/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 17/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 17/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 70.88%, Avg loss: 0.001418, MRE: 1.793732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.001312, MRE: 2.268630 \n",
      "\n",
      "Epoch 18/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 18/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 18/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 18/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 18/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 18/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 18/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 18/800, Iteration 8/12, Loss: 0.0023\n",
      "Epoch 18/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 18/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 18/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 18/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 18/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.001277, MRE: 1.603768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001274, MRE: 2.749055 \n",
      "\n",
      "Epoch 19/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 19/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 19/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 19/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 19/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 19/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 19/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 19/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 19/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 19/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 19/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 19/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 19/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.001316, MRE: 1.670381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.001253, MRE: 2.468301 \n",
      "\n",
      "Epoch 20/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 20/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 20/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 20/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 20/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 20/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 20/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 20/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 20/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 20/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 20/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 20/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 20/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001295, MRE: 1.673308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001282, MRE: 3.054409 \n",
      "\n",
      "Epoch 21/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 21/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 21/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 21/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 21/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 21/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 21/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 21/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 21/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 21/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 21/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 21/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 21/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001296, MRE: 1.581179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.001286, MRE: 3.170872 \n",
      "\n",
      "Epoch 22/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 22/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 22/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 22/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 22/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 22/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 22/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 22/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 22/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 22/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 22/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 22/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 22/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 61.88%, Avg loss: 0.001269, MRE: 1.611217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001226, MRE: 2.728240 \n",
      "\n",
      "Epoch 23/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 23/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 23/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 23/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 23/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 23/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 23/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 23/800, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 23/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 23/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 23/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 23/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 23/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 61.75%, Avg loss: 0.001269, MRE: 1.615515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001218, MRE: 2.741223 \n",
      "\n",
      "Epoch 24/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 24/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 24/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 24/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 24/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 24/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 24/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 24/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 24/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 24/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 24/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 24/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 24/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 60.88%, Avg loss: 0.001268, MRE: 1.603961 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001218, MRE: 2.895410 \n",
      "\n",
      "Epoch 25/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 25/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 25/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 25/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 25/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 25/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 25/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 25/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 25/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 25/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 25/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 25/800, Iteration 13/12, Loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 63.75%, Avg loss: 0.001283, MRE: 1.627430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.001203, MRE: 2.618004 \n",
      "\n",
      "Epoch 26/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 26/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 26/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 26/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 26/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 26/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 26/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 26/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 26/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 26/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 26/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 26/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 26/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.25%, Avg loss: 0.001245, MRE: 1.605694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001234, MRE: 3.155133 \n",
      "\n",
      "Epoch 27/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 27/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 27/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 27/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 27/800, Iteration 5/12, Loss: 0.0024\n",
      "Epoch 27/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 27/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 27/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 27/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 27/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 27/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 27/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 27/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 67.12%, Avg loss: 0.001313, MRE: 1.669583 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.001211, MRE: 2.341505 \n",
      "\n",
      "Epoch 28/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 28/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 28/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 28/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 28/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 28/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 28/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 28/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 28/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 28/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 28/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 28/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 28/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 55.62%, Avg loss: 0.001258, MRE: 1.683547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.001238, MRE: 3.254193 \n",
      "\n",
      "Epoch 29/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 29/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 29/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 29/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 29/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 29/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 29/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 29/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 29/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 29/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 29/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 29/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 65.25%, Avg loss: 0.001274, MRE: 1.623069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.001189, MRE: 2.438513 \n",
      "\n",
      "Epoch 30/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 30/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 30/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 30/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 30/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 30/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 30/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 30/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 30/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 30/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 30/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 30/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 30/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 61.88%, Avg loss: 0.001251, MRE: 1.594876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001183, MRE: 2.709562 \n",
      "\n",
      "Epoch 31/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 31/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 31/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 31/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 31/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 31/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 31/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 31/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 31/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 31/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 31/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 31/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 31/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001240, MRE: 1.604763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001202, MRE: 3.013421 \n",
      "\n",
      "Epoch 32/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 32/800, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 32/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 32/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 32/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 32/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 32/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 32/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 32/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 32/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 32/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 32/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 32/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001247, MRE: 1.603826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001195, MRE: 2.949735 \n",
      "\n",
      "Epoch 33/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 33/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 33/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 33/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 33/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 33/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 33/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 33/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 33/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 33/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 33/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 33/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 33/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001262, MRE: 1.643854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001198, MRE: 2.983630 \n",
      "\n",
      "Epoch 34/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 34/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 34/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 34/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 34/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 34/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 34/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 34/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 34/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 34/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 34/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 34/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 34/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001233, MRE: 1.597230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001194, MRE: 2.955116 \n",
      "\n",
      "Epoch 35/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 35/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 35/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 35/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 35/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 35/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 35/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 35/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 35/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 35/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 35/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 35/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 35/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001242, MRE: 1.920103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001201, MRE: 3.033090 \n",
      "\n",
      "Epoch 36/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 36/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 36/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 36/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 36/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 36/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 36/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 36/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 36/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 36/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 36/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 36/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 36/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001249, MRE: 1.588687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001195, MRE: 2.973825 \n",
      "\n",
      "Epoch 37/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 37/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 37/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 37/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 37/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 37/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 37/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 37/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 37/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 37/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 37/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 37/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 37/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001243, MRE: 1.600255 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001205, MRE: 3.076876 \n",
      "\n",
      "Epoch 38/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 38/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 38/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 38/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 38/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 38/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 38/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 38/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 38/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 38/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 38/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 38/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 38/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001241, MRE: 1.626849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001203, MRE: 3.065651 \n",
      "\n",
      "Epoch 39/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 39/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 39/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 39/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 39/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 39/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 39/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 39/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 39/800, Iteration 12/12, Loss: 0.0022\n",
      "Epoch 39/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001245, MRE: 1.608659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001193, MRE: 2.958412 \n",
      "\n",
      "Epoch 40/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 40/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 40/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 40/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 40/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 40/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 40/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 40/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 40/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 40/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 40/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 40/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 40/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.001231, MRE: 1.747916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001184, MRE: 2.847015 \n",
      "\n",
      "Epoch 41/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 41/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 41/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 41/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 41/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 41/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 41/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 41/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 41/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 41/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 41/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 41/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 41/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001241, MRE: 1.595741 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001192, MRE: 2.958017 \n",
      "\n",
      "Epoch 42/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 42/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 42/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 42/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 42/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 42/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 42/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 42/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 42/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 42/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 42/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 42/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 42/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001245, MRE: 1.594964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001192, MRE: 2.963459 \n",
      "\n",
      "Epoch 43/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 43/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 43/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 43/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 43/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 43/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 43/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 43/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 43/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 43/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001230, MRE: 1.587455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001199, MRE: 3.041734 \n",
      "\n",
      "Epoch 44/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 44/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 44/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 44/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 44/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 44/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 44/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 44/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 44/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 44/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 44/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 44/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 44/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001243, MRE: 1.591589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001200, MRE: 3.046871 \n",
      "\n",
      "Epoch 45/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 45/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 45/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 45/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 45/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 45/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 45/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 45/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 45/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 45/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 45/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 45/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 45/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.25%, Avg loss: 0.001255, MRE: 1.651038 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001187, MRE: 2.910855 \n",
      "\n",
      "Epoch 46/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 46/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 46/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 46/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 46/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 46/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 46/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 46/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 46/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 46/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 59.88%, Avg loss: 0.001253, MRE: 1.596528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001185, MRE: 2.886161 \n",
      "\n",
      "Epoch 47/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 47/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 47/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 47/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 47/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 47/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 47/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 47/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 47/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 47/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 47/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 47/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 47/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001235, MRE: 1.796813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001190, MRE: 2.965534 \n",
      "\n",
      "Epoch 48/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 48/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 48/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 48/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 48/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 48/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 48/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 48/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 48/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 48/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 48/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 48/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 48/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001230, MRE: 1.597927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001195, MRE: 3.019793 \n",
      "\n",
      "Epoch 49/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 49/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 49/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 49/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 49/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 49/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 49/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 49/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 49/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 49/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 49/800, Iteration 11/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 49/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001240, MRE: 1.592966 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001193, MRE: 3.002687 \n",
      "\n",
      "Epoch 50/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 50/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 50/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 50/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 50/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 50/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 50/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 50/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 50/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 50/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 50/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 50/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 50/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001237, MRE: 1.603185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001187, MRE: 2.931991 \n",
      "\n",
      "Epoch 51/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 51/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 51/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 51/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 51/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 51/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 51/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 51/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 51/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 51/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 51/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 51/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 51/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 57.75%, Avg loss: 0.001246, MRE: 1.592400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001198, MRE: 3.057146 \n",
      "\n",
      "Epoch 52/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 52/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 52/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 52/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 52/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 52/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 52/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 52/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 52/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 52/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 52/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 52/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 52/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.38%, Avg loss: 0.001219, MRE: 1.581675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001184, MRE: 2.902660 \n",
      "\n",
      "Epoch 53/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 53/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 53/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 53/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 53/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 53/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 53/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 53/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 53/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 53/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 53/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 53/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 53/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001222, MRE: 1.593951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001190, MRE: 2.981319 \n",
      "\n",
      "Epoch 54/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 54/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 54/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 54/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 54/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 54/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 54/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 54/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 54/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 54/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 54/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 54/800, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 54/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001231, MRE: 1.590007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001186, MRE: 2.941906 \n",
      "\n",
      "Epoch 55/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 55/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 55/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 55/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 55/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 55/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 55/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 55/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 55/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 55/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 55/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 55/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 55/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001233, MRE: 1.595619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001187, MRE: 2.960722 \n",
      "\n",
      "Epoch 56/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 56/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 56/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 56/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 56/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 56/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 56/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 56/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 56/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 56/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 56/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 56/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 56/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001222, MRE: 1.592657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001190, MRE: 3.001031 \n",
      "\n",
      "Epoch 57/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 57/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 57/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 57/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 57/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 57/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 57/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 57/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 57/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001237, MRE: 1.593347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001194, MRE: 3.039402 \n",
      "\n",
      "Epoch 58/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 58/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 58/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 58/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 58/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 58/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 58/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 58/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 58/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 58/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 58/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001245, MRE: 1.643955 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001188, MRE: 2.983345 \n",
      "\n",
      "Epoch 59/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 59/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 59/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 59/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 59/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 59/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 59/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 59/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 59/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 59/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 59/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 59/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 59/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001220, MRE: 1.594271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001183, MRE: 2.928294 \n",
      "\n",
      "Epoch 60/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 60/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 60/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 60/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 60/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 60/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 60/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 60/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001217, MRE: 1.592577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001188, MRE: 2.983847 \n",
      "\n",
      "Epoch 61/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 61/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 61/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 61/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 61/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 61/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 61/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 61/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 61/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 61/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 61/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 61/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 61/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001221, MRE: 1.594718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001183, MRE: 2.934825 \n",
      "\n",
      "Epoch 62/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 62/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 62/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 62/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 62/800, Iteration 5/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 62/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 62/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 62/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 62/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 62/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 62/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001236, MRE: 1.612497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001192, MRE: 3.035778 \n",
      "\n",
      "Epoch 63/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 63/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 63/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 63/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 63/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 63/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 63/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 63/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 63/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 63/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 63/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 63/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 63/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001226, MRE: 1.605938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001190, MRE: 3.015183 \n",
      "\n",
      "Epoch 64/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 64/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 64/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 64/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 64/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 64/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 64/800, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 64/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 64/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 64/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 64/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 64/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 64/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001238, MRE: 1.581901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001186, MRE: 2.966338 \n",
      "\n",
      "Epoch 65/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 65/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 65/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 65/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 65/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 65/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 65/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 65/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 65/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 65/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 65/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 65/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 65/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001219, MRE: 1.618518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001184, MRE: 2.943849 \n",
      "\n",
      "Epoch 66/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 66/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 66/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 66/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 66/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 66/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 66/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 66/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 66/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 66/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 66/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 66/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 66/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001234, MRE: 1.792635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001183, MRE: 2.938134 \n",
      "\n",
      "Epoch 67/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 67/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 67/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 67/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 67/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 67/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 67/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 67/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 67/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 67/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 67/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 67/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 67/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.38%, Avg loss: 0.001231, MRE: 1.589167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.001198, MRE: 3.096258 \n",
      "\n",
      "Epoch 68/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 68/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 68/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 68/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 68/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 68/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 68/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 68/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 68/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 68/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 68/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 68/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 68/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001239, MRE: 1.925211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001182, MRE: 2.930098 \n",
      "\n",
      "Epoch 69/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 69/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 69/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 69/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 69/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 69/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 69/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 69/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 69/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 69/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 69/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 69/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 69/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001224, MRE: 1.737448 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001181, MRE: 2.925047 \n",
      "\n",
      "Epoch 70/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 70/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 70/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 70/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 70/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 70/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 70/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 70/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 70/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 70/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 70/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 70/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 70/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001246, MRE: 1.593527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001189, MRE: 3.013374 \n",
      "\n",
      "Epoch 71/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 71/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 71/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 71/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 71/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 71/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 71/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 71/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 71/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 71/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 71/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 71/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 71/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001244, MRE: 1.606820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001180, MRE: 2.907985 \n",
      "\n",
      "Epoch 72/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 72/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 72/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 72/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 72/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 72/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 72/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 72/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 72/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 72/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 72/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 72/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 72/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 60.62%, Avg loss: 0.001245, MRE: 1.916682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001174, MRE: 2.830910 \n",
      "\n",
      "Epoch 73/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 73/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 73/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 73/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 73/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 73/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 73/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 73/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 73/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 73/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 73/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 73/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 73/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001219, MRE: 1.595364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001175, MRE: 2.842814 \n",
      "\n",
      "Epoch 74/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 74/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 74/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 74/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 74/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 74/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 74/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 74/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 74/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 74/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 74/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 74/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 74/800, Iteration 13/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001227, MRE: 1.593414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001189, MRE: 3.030699 \n",
      "\n",
      "Epoch 75/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 75/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 75/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 75/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 75/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 75/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 75/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 75/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 75/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 75/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 75/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 75/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 75/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001213, MRE: 1.595731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001181, MRE: 2.945558 \n",
      "\n",
      "Epoch 76/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 76/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 76/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 76/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 76/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 76/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 76/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 76/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 76/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 76/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 76/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001221, MRE: 1.595061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001189, MRE: 3.031563 \n",
      "\n",
      "Epoch 77/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 77/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 77/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 77/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 77/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 77/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 77/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 77/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 77/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 77/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 77/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 77/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 77/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001226, MRE: 1.597973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001188, MRE: 3.024495 \n",
      "\n",
      "Epoch 78/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 78/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 78/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 78/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 78/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 78/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 78/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 78/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 78/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 78/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 78/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 78/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 78/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001219, MRE: 1.652248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001184, MRE: 2.974567 \n",
      "\n",
      "Epoch 79/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 79/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 79/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 79/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 79/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 79/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 79/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 79/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 79/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 79/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 79/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 79/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001232, MRE: 1.618470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001183, MRE: 2.963404 \n",
      "\n",
      "Epoch 80/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 80/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 80/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 80/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 80/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 80/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 80/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 80/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 80/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 80/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 80/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 80/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 80/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001247, MRE: 1.606871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001186, MRE: 2.999254 \n",
      "\n",
      "Epoch 81/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 81/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 81/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 81/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 81/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 81/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 81/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 81/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 81/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 81/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 81/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 81/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 81/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001222, MRE: 1.576833 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001175, MRE: 2.859861 \n",
      "\n",
      "Epoch 82/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 82/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 82/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 82/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 82/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 82/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 82/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 82/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 82/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 82/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 82/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 82/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 82/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001209, MRE: 1.581183 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001186, MRE: 3.007763 \n",
      "\n",
      "Epoch 83/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 83/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 83/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 83/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 83/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 83/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 83/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 83/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 83/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 83/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 83/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 83/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 83/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001222, MRE: 1.607761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001180, MRE: 2.933544 \n",
      "\n",
      "Epoch 84/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 84/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 84/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 84/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 84/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 84/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 84/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 84/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 84/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 84/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 84/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 84/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 84/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001239, MRE: 1.589395 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001174, MRE: 2.859918 \n",
      "\n",
      "Epoch 85/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 85/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 85/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 85/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 85/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 85/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 85/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 85/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 85/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001244, MRE: 1.591612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001185, MRE: 2.994366 \n",
      "\n",
      "Epoch 86/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 86/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 86/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 86/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 86/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 86/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 86/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 86/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 86/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 86/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 86/800, Iteration 13/12, Loss: 0.0005\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001211, MRE: 1.620292 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001181, MRE: 2.954972 \n",
      "\n",
      "Epoch 87/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 87/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 87/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 87/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 87/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 87/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 87/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 87/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 87/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 87/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 87/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 87/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 87/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.001236, MRE: 1.723704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001191, MRE: 3.061336 \n",
      "\n",
      "Epoch 88/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 88/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 88/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 88/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 88/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 88/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 88/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 88/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 88/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 88/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 88/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 88/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 88/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001241, MRE: 1.585536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001188, MRE: 3.038106 \n",
      "\n",
      "Epoch 89/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 89/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 89/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 89/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 89/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 89/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 89/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 89/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 89/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 89/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001227, MRE: 1.614579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001179, MRE: 2.941856 \n",
      "\n",
      "Epoch 90/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 90/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 90/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 90/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 90/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 90/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 90/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 90/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 90/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 90/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 90/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 90/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 90/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.001232, MRE: 1.637220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001172, MRE: 2.838491 \n",
      "\n",
      "Epoch 91/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 91/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 91/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 91/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 91/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 91/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 91/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 91/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 91/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 91/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 91/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 91/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 91/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001210, MRE: 1.745258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001184, MRE: 2.998602 \n",
      "\n",
      "Epoch 92/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 92/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 92/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 92/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 92/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 92/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 92/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 92/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 92/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 92/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 92/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 92/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 92/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001211, MRE: 1.587500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001186, MRE: 3.018413 \n",
      "\n",
      "Epoch 93/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 93/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 93/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 93/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 93/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 93/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 93/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 93/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 93/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 93/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 93/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 93/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 93/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001230, MRE: 1.592681 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001183, MRE: 2.991471 \n",
      "\n",
      "Epoch 94/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 94/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 94/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 94/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 94/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 94/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 94/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 94/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 94/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 94/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 94/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 94/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 94/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001221, MRE: 1.596326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001178, MRE: 2.940195 \n",
      "\n",
      "Epoch 95/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 95/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 95/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 95/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 95/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 95/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 95/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 95/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 95/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 95/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 95/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 95/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 95/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001224, MRE: 1.597579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001188, MRE: 3.039849 \n",
      "\n",
      "Epoch 96/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 96/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 96/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 96/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 96/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 96/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 96/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 96/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 96/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 96/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001224, MRE: 1.589500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001179, MRE: 2.960065 \n",
      "\n",
      "Epoch 97/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 97/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 97/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 97/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 97/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 97/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 97/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 97/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 97/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 97/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 97/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 97/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001222, MRE: 1.632895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001184, MRE: 3.009726 \n",
      "\n",
      "Epoch 98/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 98/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 98/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 98/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 98/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 98/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 98/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 98/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 98/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 98/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 98/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 98/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 98/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001235, MRE: 1.600298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001175, MRE: 2.910364 \n",
      "\n",
      "Epoch 99/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 99/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 99/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 99/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 99/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 99/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 99/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 99/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 99/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 99/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 99/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 99/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 99/800, Iteration 13/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001208, MRE: 1.597931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001170, MRE: 2.835540 \n",
      "\n",
      "Epoch 100/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 100/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 100/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 100/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 100/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 100/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 100/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 100/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001232, MRE: 1.583683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001178, MRE: 2.954238 \n",
      "\n",
      "Epoch 101/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 101/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 101/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 101/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 101/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 101/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 101/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 101/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001222, MRE: 1.779305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001173, MRE: 2.895549 \n",
      "\n",
      "Epoch 102/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 102/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 102/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 102/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 102/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 102/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 102/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 102/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 102/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 102/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 102/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 102/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 102/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001266, MRE: 1.586838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001183, MRE: 3.010553 \n",
      "\n",
      "Epoch 103/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 103/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 103/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 103/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 103/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 103/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 103/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 103/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 103/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 103/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 103/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001221, MRE: 1.619504 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001180, MRE: 2.985171 \n",
      "\n",
      "Epoch 104/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 104/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 104/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 104/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 104/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 104/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 104/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 104/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 104/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 104/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 104/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 104/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 104/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001245, MRE: 1.693143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001182, MRE: 3.008778 \n",
      "\n",
      "Epoch 105/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 105/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 105/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 105/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 105/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 105/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 105/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 105/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 105/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 105/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 105/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 105/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 105/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001223, MRE: 1.578211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001177, MRE: 2.963876 \n",
      "\n",
      "Epoch 106/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 106/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 106/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 106/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 106/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 106/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 106/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 106/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 106/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 106/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001211, MRE: 1.580714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001173, MRE: 2.915003 \n",
      "\n",
      "Epoch 107/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 107/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 107/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 107/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 107/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 107/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 107/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 107/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 107/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 107/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 107/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 107/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 107/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001223, MRE: 1.781311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001175, MRE: 2.948131 \n",
      "\n",
      "Epoch 108/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 108/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 108/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 108/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 108/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 108/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 108/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 108/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 108/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 108/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 108/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 108/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 108/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001207, MRE: 1.584377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001171, MRE: 2.893580 \n",
      "\n",
      "Epoch 109/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 109/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 109/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 109/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 109/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 109/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 109/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 109/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 109/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 109/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 109/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 109/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 109/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001235, MRE: 1.587070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001170, MRE: 2.892866 \n",
      "\n",
      "Epoch 110/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 110/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 110/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 110/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 110/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 110/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 110/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 110/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 110/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 110/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 110/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 110/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 110/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001228, MRE: 1.580692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001176, MRE: 2.966810 \n",
      "\n",
      "Epoch 111/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 111/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 111/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 111/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 111/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 111/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 111/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 111/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 111/800, Iteration 12/12, Loss: 0.0024\n",
      "Epoch 111/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001223, MRE: 1.585153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001177, MRE: 2.982227 \n",
      "\n",
      "Epoch 112/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 112/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 112/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 112/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 112/800, Iteration 5/12, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 112/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 112/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 112/800, Iteration 9/12, Loss: 0.0008\n",
      "Epoch 112/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 112/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 112/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 112/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 56.38%, Avg loss: 0.001216, MRE: 1.597857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001195, MRE: 3.142856 \n",
      "\n",
      "Epoch 113/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 113/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 113/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 113/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 113/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 113/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 113/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 113/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 113/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 113/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 113/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 113/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 113/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001214, MRE: 1.591408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001179, MRE: 3.000777 \n",
      "\n",
      "Epoch 114/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 114/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 114/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 114/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 114/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 114/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 114/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 114/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 114/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 114/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 114/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 114/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001230, MRE: 1.588311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001177, MRE: 2.984348 \n",
      "\n",
      "Epoch 115/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 115/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 115/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 115/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 115/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 115/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 115/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 115/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 115/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 115/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 115/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 115/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 115/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001223, MRE: 1.595258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001172, MRE: 2.926622 \n",
      "\n",
      "Epoch 116/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 116/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 116/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 116/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 116/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 116/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 116/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 116/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 116/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 116/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 116/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 116/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 116/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001226, MRE: 1.593046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001169, MRE: 2.892043 \n",
      "\n",
      "Epoch 117/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 117/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 117/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 117/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 117/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 117/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 117/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 117/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 117/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 117/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 117/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 117/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001215, MRE: 1.647251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001165, MRE: 2.846389 \n",
      "\n",
      "Epoch 118/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 118/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 118/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 118/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 118/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 118/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 118/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 118/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 118/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 118/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 118/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 118/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 118/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001215, MRE: 1.645704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001172, MRE: 2.940348 \n",
      "\n",
      "Epoch 119/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 119/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 119/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 119/800, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 119/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 119/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 119/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 119/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 119/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 119/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 119/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 119/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 119/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001227, MRE: 1.588359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001169, MRE: 2.908657 \n",
      "\n",
      "Epoch 120/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 120/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 120/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 120/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 120/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 120/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 120/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 120/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 120/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 120/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 120/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 120/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 120/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001211, MRE: 1.577460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001173, MRE: 2.955715 \n",
      "\n",
      "Epoch 121/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 121/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 121/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 121/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 121/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 121/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 121/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 121/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 121/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 121/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 121/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001230, MRE: 1.591160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001170, MRE: 2.918250 \n",
      "\n",
      "Epoch 122/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 122/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 122/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 122/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 122/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 122/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 122/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 122/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 122/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 122/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 122/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 122/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 122/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001213, MRE: 1.764392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001172, MRE: 2.951844 \n",
      "\n",
      "Epoch 123/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 123/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 123/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 123/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 123/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 123/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 123/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 123/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 123/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 123/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 123/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 123/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 123/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001220, MRE: 1.587281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001181, MRE: 3.049410 \n",
      "\n",
      "Epoch 124/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 124/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 124/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 124/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 124/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 124/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001198, MRE: 1.586769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001181, MRE: 3.045912 \n",
      "\n",
      "Epoch 125/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 125/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 125/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 125/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 125/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 125/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 125/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 125/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 125/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 125/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 125/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 125/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 125/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001247, MRE: 1.585567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001168, MRE: 2.904922 \n",
      "\n",
      "Epoch 126/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 126/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 126/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 126/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 126/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 126/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 126/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 126/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 126/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 126/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 126/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 126/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 126/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 60.25%, Avg loss: 0.001217, MRE: 1.576352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001160, MRE: 2.788265 \n",
      "\n",
      "Epoch 127/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 127/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 127/800, Iteration 3/12, Loss: 0.0022\n",
      "Epoch 127/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 127/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 127/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 127/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 127/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 127/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 127/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 127/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 127/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 127/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.001235, MRE: 1.576836 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001158, MRE: 2.742528 \n",
      "\n",
      "Epoch 128/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 128/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 128/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 128/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 128/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 128/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 128/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 128/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 128/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 128/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 128/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 128/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001221, MRE: 1.576612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001161, MRE: 2.816316 \n",
      "\n",
      "Epoch 129/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 129/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 129/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 129/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 129/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 129/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 129/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 129/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 129/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 129/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 129/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 129/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 129/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001219, MRE: 1.570630 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001165, MRE: 2.873341 \n",
      "\n",
      "Epoch 130/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 130/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 130/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 130/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 130/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 130/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 130/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 130/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 130/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 130/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 130/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 130/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 130/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.001218, MRE: 1.607103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001178, MRE: 3.032058 \n",
      "\n",
      "Epoch 131/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 131/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 131/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 131/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 131/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 131/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 131/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 131/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 131/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 131/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001232, MRE: 1.767980 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001174, MRE: 2.994367 \n",
      "\n",
      "Epoch 132/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 132/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 132/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 132/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 132/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 132/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 132/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 132/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 132/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 132/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 132/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 132/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 132/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001230, MRE: 1.892532 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001172, MRE: 2.979965 \n",
      "\n",
      "Epoch 133/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 133/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 133/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 133/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 133/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 133/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 133/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 133/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001232, MRE: 1.599744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001171, MRE: 2.966497 \n",
      "\n",
      "Epoch 134/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 134/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 134/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 134/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 134/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 134/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 134/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 134/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 134/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 134/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 134/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 134/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 134/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001208, MRE: 1.608319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001166, MRE: 2.914046 \n",
      "\n",
      "Epoch 135/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 135/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 135/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 135/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 135/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 135/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 135/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 135/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 135/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 135/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 135/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 135/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 135/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001216, MRE: 1.576745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001169, MRE: 2.944782 \n",
      "\n",
      "Epoch 136/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 136/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 136/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 136/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 136/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 136/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 136/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 136/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 136/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 136/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 136/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 136/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 136/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001215, MRE: 1.594347 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001167, MRE: 2.931467 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 137/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 137/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 137/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 137/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 137/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 137/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 137/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 137/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 137/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 137/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 137/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 137/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001223, MRE: 1.609709 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001164, MRE: 2.886470 \n",
      "\n",
      "Epoch 138/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 138/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 138/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 138/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 138/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 138/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 138/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 138/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 138/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 138/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 138/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 138/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 138/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001215, MRE: 1.627854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001161, MRE: 2.844598 \n",
      "\n",
      "Epoch 139/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 139/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 139/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 139/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 139/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 139/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 139/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 139/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 139/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 139/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 139/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 139/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 139/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001218, MRE: 2.078142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001171, MRE: 2.982993 \n",
      "\n",
      "Epoch 140/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 140/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 140/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 140/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 140/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 140/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 140/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 140/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 140/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001237, MRE: 1.645952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001168, MRE: 2.950860 \n",
      "\n",
      "Epoch 141/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 141/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 141/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 141/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 141/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 141/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 141/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 141/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 141/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001215, MRE: 1.583544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001167, MRE: 2.940759 \n",
      "\n",
      "Epoch 142/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 142/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 142/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 142/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 142/800, Iteration 5/12, Loss: 0.0023\n",
      "Epoch 142/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 142/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 142/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 142/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 142/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 142/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 142/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 142/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001235, MRE: 1.580382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001167, MRE: 2.947012 \n",
      "\n",
      "Epoch 143/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 143/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 143/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 143/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 143/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 143/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 143/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 143/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 143/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001216, MRE: 1.599899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001166, MRE: 2.931003 \n",
      "\n",
      "Epoch 144/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 144/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 144/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 144/800, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 144/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 144/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 144/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 144/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 144/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 144/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 144/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 144/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 144/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001204, MRE: 1.599973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001188, MRE: 3.145252 \n",
      "\n",
      "Epoch 145/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 145/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 145/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 145/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 145/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 145/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 145/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 145/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 145/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 145/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 145/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 145/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 145/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001228, MRE: 1.592108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001163, MRE: 2.903643 \n",
      "\n",
      "Epoch 146/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 146/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 146/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 146/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 146/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 146/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 146/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 146/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 146/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 146/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 146/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 146/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 146/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001202, MRE: 1.727846 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001160, MRE: 2.856590 \n",
      "\n",
      "Epoch 147/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 147/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 147/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 147/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 147/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 147/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 147/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 147/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 147/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 147/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 147/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.75%, Avg loss: 0.001199, MRE: 1.573691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001156, MRE: 2.789545 \n",
      "\n",
      "Epoch 148/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 148/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 148/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 148/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 148/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 148/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 148/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 148/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 148/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 148/800, Iteration 10/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 148/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 148/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001211, MRE: 1.806849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001165, MRE: 2.935392 \n",
      "\n",
      "Epoch 149/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 149/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 149/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 149/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 149/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 149/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 149/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 149/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 149/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 149/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 149/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 149/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 149/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001239, MRE: 1.894329 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001164, MRE: 2.912041 \n",
      "\n",
      "Epoch 150/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 150/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 150/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 150/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 150/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 150/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 150/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 150/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 150/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 150/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 150/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 150/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 150/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001210, MRE: 1.608942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001169, MRE: 2.979334 \n",
      "\n",
      "Epoch 151/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 151/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 151/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 151/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 151/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 151/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 151/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 151/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 151/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 151/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 151/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 151/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 151/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001207, MRE: 1.615413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001181, MRE: 3.096194 \n",
      "\n",
      "Epoch 152/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 152/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 152/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 152/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 152/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 152/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 152/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 152/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 152/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 152/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 152/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 152/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 152/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001220, MRE: 1.584113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.001184, MRE: 3.122058 \n",
      "\n",
      "Epoch 153/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 153/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 153/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 153/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 153/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 153/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 153/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 153/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 153/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 153/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 153/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 153/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 153/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001221, MRE: 1.581820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001163, MRE: 2.920064 \n",
      "\n",
      "Epoch 154/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 154/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 154/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 154/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 154/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 154/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 154/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 154/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 154/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 154/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 154/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 154/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 57.25%, Avg loss: 0.001236, MRE: 1.593422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001173, MRE: 3.024577 \n",
      "\n",
      "Epoch 155/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 155/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 155/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 155/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 155/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 155/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 155/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 155/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 155/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 155/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 155/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 155/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001216, MRE: 1.900830 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001170, MRE: 2.996002 \n",
      "\n",
      "Epoch 156/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 156/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 156/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 156/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 156/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 156/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 156/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 156/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 156/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 156/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 156/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 156/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 156/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.581461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.001167, MRE: 2.973642 \n",
      "\n",
      "Epoch 157/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 157/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 157/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 157/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 157/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 157/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 157/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 157/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 157/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 157/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 157/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 157/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 157/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.665989 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001169, MRE: 2.990035 \n",
      "\n",
      "Epoch 158/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 158/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 158/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 158/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 158/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 158/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 158/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 158/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 158/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 158/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001198, MRE: 1.607768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001157, MRE: 2.848760 \n",
      "\n",
      "Epoch 159/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 159/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 159/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 159/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 159/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 159/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 159/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 159/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 159/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001205, MRE: 1.664254 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001161, MRE: 2.898259 \n",
      "\n",
      "Epoch 160/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 160/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 160/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 160/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 160/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 160/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 160/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 160/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 160/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 160/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 160/800, Iteration 13/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.88%, Avg loss: 0.001205, MRE: 1.625876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001158, MRE: 2.863173 \n",
      "\n",
      "Epoch 161/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 161/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 161/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 161/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 161/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 161/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 161/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 161/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 161/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 161/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001227, MRE: 1.599400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001160, MRE: 2.885231 \n",
      "\n",
      "Epoch 162/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 162/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 162/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 162/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 162/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 162/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 162/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 162/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 162/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 162/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 162/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 162/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 162/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.001220, MRE: 1.574848 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.001155, MRE: 2.810186 \n",
      "\n",
      "Epoch 163/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 163/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 163/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 163/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 163/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 163/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 163/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 163/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 163/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 163/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001223, MRE: 1.590713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001156, MRE: 2.843871 \n",
      "\n",
      "Epoch 164/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 164/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 164/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 164/800, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 164/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 164/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 164/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 164/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 164/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 164/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 164/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 164/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 164/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001202, MRE: 1.566679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001160, MRE: 2.894922 \n",
      "\n",
      "Epoch 165/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 165/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 165/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 165/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 165/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 165/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 165/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 165/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 165/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 165/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 165/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 165/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 165/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001222, MRE: 1.578444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001160, MRE: 2.896861 \n",
      "\n",
      "Epoch 166/800, Iteration 1/12, Loss: 0.0008\n",
      "Epoch 166/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 166/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 166/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 166/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 166/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 166/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 166/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 166/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 166/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 166/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 166/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 166/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001213, MRE: 1.569684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001163, MRE: 2.928158 \n",
      "\n",
      "Epoch 167/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 167/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 167/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 167/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 167/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 167/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 167/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 167/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 167/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 167/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 167/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 167/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001207, MRE: 1.576631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001167, MRE: 2.977933 \n",
      "\n",
      "Epoch 168/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 168/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 168/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 168/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 168/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 168/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 168/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 168/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 168/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 168/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 168/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 168/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 168/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.568927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001164, MRE: 2.946935 \n",
      "\n",
      "Epoch 169/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 169/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 169/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 169/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 169/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 169/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 169/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 169/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 169/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.574019 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001163, MRE: 2.927579 \n",
      "\n",
      "Epoch 170/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 170/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 170/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 170/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 170/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 170/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 170/800, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 170/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 170/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 170/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 170/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 170/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 170/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001212, MRE: 1.577340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.001166, MRE: 2.971232 \n",
      "\n",
      "Epoch 171/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 171/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 171/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 171/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 171/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 171/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 171/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 171/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 171/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 171/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 171/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 171/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 171/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001230, MRE: 1.601751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001169, MRE: 3.004409 \n",
      "\n",
      "Epoch 172/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 172/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 172/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 172/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 172/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 172/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 172/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 172/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 172/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 172/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 172/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 172/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 172/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001219, MRE: 1.589937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001174, MRE: 3.050832 \n",
      "\n",
      "Epoch 173/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 173/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 173/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 173/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 173/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 173/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 173/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 173/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 173/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 173/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 173/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 173/800, Iteration 12/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001219, MRE: 1.597852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001161, MRE: 2.910794 \n",
      "\n",
      "Epoch 174/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 174/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 174/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 174/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 174/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 174/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 174/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 174/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 174/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 174/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 174/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.591016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001161, MRE: 2.922730 \n",
      "\n",
      "Epoch 175/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 175/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 175/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 175/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 175/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 175/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 175/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 175/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 175/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.575921 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001164, MRE: 2.958792 \n",
      "\n",
      "Epoch 176/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 176/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 176/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 176/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 176/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 176/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 176/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 176/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 176/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 176/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 176/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 176/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 176/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001211, MRE: 1.636483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001155, MRE: 2.845222 \n",
      "\n",
      "Epoch 177/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 177/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 177/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 177/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 177/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 177/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 177/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 177/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 177/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 177/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 177/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 177/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 177/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001215, MRE: 1.576996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001163, MRE: 2.946103 \n",
      "\n",
      "Epoch 178/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 178/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 178/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 178/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 178/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 178/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 178/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 178/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 178/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 178/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 178/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 178/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 178/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.571967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001161, MRE: 2.930522 \n",
      "\n",
      "Epoch 179/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 179/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 179/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 179/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 179/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 179/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 179/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 179/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 179/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 179/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 179/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 179/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 179/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.75%, Avg loss: 0.001230, MRE: 1.619172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001157, MRE: 2.876072 \n",
      "\n",
      "Epoch 180/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 180/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 180/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 180/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 180/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 180/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 180/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 180/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 180/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 180/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 180/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 180/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 180/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.604037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001163, MRE: 2.948831 \n",
      "\n",
      "Epoch 181/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 181/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 181/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 181/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 181/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 181/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 181/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 181/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 181/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 181/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 181/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 181/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 181/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001205, MRE: 1.628001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001165, MRE: 2.975804 \n",
      "\n",
      "Epoch 182/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 182/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 182/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 182/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 182/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 182/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 182/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 182/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 182/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 182/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 182/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 182/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 182/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001220, MRE: 1.564499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001154, MRE: 2.836312 \n",
      "\n",
      "Epoch 183/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 183/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 183/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 183/800, Iteration 4/12, Loss: 0.0022\n",
      "Epoch 183/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 183/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 183/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 183/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 183/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 183/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 183/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 183/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 183/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001196, MRE: 1.601487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001167, MRE: 2.989107 \n",
      "\n",
      "Epoch 184/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 184/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 184/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 184/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 184/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 184/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 184/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 184/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 184/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 184/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 184/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 184/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 184/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.630770 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001161, MRE: 2.922039 \n",
      "\n",
      "Epoch 185/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 185/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 185/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 185/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 185/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 185/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 185/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 185/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 185/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 185/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 185/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.733020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001159, MRE: 2.900583 \n",
      "\n",
      "Epoch 186/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 186/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 186/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 186/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 186/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 186/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 186/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 186/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 186/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 186/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 186/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 186/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 186/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.580116 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001160, MRE: 2.917377 \n",
      "\n",
      "Epoch 187/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 187/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 187/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 187/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 187/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 187/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 187/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 187/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 187/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 187/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 187/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 187/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 187/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.626514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001161, MRE: 2.933327 \n",
      "\n",
      "Epoch 188/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 188/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 188/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 188/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 188/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 188/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 188/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 188/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 188/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 188/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 188/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.38%, Avg loss: 0.001197, MRE: 1.604350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001167, MRE: 2.993764 \n",
      "\n",
      "Epoch 189/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 189/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 189/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 189/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 189/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 189/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 189/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 189/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 189/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 189/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 59.62%, Avg loss: 0.001205, MRE: 1.579165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.001151, MRE: 2.778709 \n",
      "\n",
      "Epoch 190/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 190/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 190/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 190/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 190/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 190/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 190/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 190/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 190/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 190/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 190/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 190/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 190/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.572136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001162, MRE: 2.941339 \n",
      "\n",
      "Epoch 191/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 191/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 191/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 191/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 191/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 56.62%, Avg loss: 0.001214, MRE: 1.881443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001170, MRE: 3.025084 \n",
      "\n",
      "Epoch 192/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 192/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 192/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 192/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 192/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 192/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 192/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 192/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 192/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 192/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 192/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 192/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 192/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.579507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.904072 \n",
      "\n",
      "Epoch 193/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 193/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 193/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 193/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 193/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 193/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 193/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 193/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 193/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 193/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 193/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 193/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 193/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001201, MRE: 1.573750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.880614 \n",
      "\n",
      "Epoch 194/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 194/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 194/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 194/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 194/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 194/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 194/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 194/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 194/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 194/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 194/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 194/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 194/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.63%, Avg loss: 0.001224, MRE: 1.606036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001164, MRE: 2.975590 \n",
      "\n",
      "Epoch 195/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 195/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 195/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 195/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 195/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 195/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 195/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 195/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 195/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 195/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 195/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 195/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 195/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001208, MRE: 1.586829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001163, MRE: 2.961721 \n",
      "\n",
      "Epoch 196/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 196/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 196/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 196/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 196/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 196/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 196/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 196/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 196/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 196/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 196/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 196/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 196/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001210, MRE: 1.601729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.001163, MRE: 2.966867 \n",
      "\n",
      "Epoch 197/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 197/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 197/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 197/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 197/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 197/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 197/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 197/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 197/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 197/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 197/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 197/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 197/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 59.13%, Avg loss: 0.001223, MRE: 1.601140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.001152, MRE: 2.831194 \n",
      "\n",
      "Epoch 198/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 198/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 198/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 198/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 198/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 198/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 198/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 198/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 198/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 198/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 198/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 198/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 198/800, Iteration 13/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001204, MRE: 1.873847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001161, MRE: 2.939870 \n",
      "\n",
      "Epoch 199/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 199/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 199/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 199/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 199/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 199/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 199/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 199/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 199/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 199/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 199/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 199/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 199/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.594933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.919870 \n",
      "\n",
      "Epoch 200/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 200/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 200/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 200/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 200/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 200/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 200/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 200/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 200/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 200/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 200/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 200/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 200/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001211, MRE: 1.564915 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.884277 \n",
      "\n",
      "Epoch 201/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 201/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 201/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 201/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 201/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 201/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 201/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 201/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 201/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 201/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 201/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001199, MRE: 1.571420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899373 \n",
      "\n",
      "Epoch 202/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 202/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 202/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 202/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 202/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 202/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 202/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 202/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 202/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 202/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 202/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 202/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 202/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.570465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.905705 \n",
      "\n",
      "Epoch 203/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 203/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 203/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 203/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 203/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 203/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 203/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 203/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 203/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 203/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 203/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 203/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 203/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.625887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904192 \n",
      "\n",
      "Epoch 204/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 204/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 204/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 204/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 204/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 204/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 204/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 204/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.564381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.916122 \n",
      "\n",
      "Epoch 205/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 205/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 205/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 205/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 205/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 205/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 205/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 205/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 205/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 205/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001185, MRE: 1.563092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.918869 \n",
      "\n",
      "Epoch 206/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 206/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 206/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 206/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 206/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 206/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 206/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 206/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 206/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 206/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 206/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 206/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 206/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.570651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.914542 \n",
      "\n",
      "Epoch 207/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 207/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 207/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 207/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 207/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 207/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 207/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 207/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 207/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 207/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 207/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 207/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 207/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.587967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.909815 \n",
      "\n",
      "Epoch 208/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 208/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 208/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 208/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 208/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 208/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 208/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 208/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 208/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 208/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 208/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 208/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.572550 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908309 \n",
      "\n",
      "Epoch 209/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 209/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 209/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 209/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 209/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 209/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 209/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 209/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 209/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 209/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 209/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 209/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 209/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.584578 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.910369 \n",
      "\n",
      "Epoch 210/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 210/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 210/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 210/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 210/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 210/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 210/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 210/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 210/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 210/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 210/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 210/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 210/800, Iteration 13/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.597476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907387 \n",
      "\n",
      "Epoch 211/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 211/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 211/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 211/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 211/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 211/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 211/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 211/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 211/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 211/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 211/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 211/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 211/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001202, MRE: 1.574430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.898053 \n",
      "\n",
      "Epoch 212/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 212/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 212/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 212/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 212/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 212/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 212/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 212/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 212/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 212/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 212/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 212/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001198, MRE: 1.581174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899068 \n",
      "\n",
      "Epoch 213/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 213/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 213/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 213/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 213/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 213/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 213/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 213/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 213/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.636620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.898036 \n",
      "\n",
      "Epoch 214/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 214/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 214/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 214/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 214/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 214/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 214/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 214/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 214/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.577668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899827 \n",
      "\n",
      "Epoch 215/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 215/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 215/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 215/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 215/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 215/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 215/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 215/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 215/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 215/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 215/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 215/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 215/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001190, MRE: 1.568303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.890571 \n",
      "\n",
      "Epoch 216/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 216/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 216/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 216/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 216/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 216/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 216/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 216/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 216/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 216/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 216/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 216/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 216/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.881241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.896429 \n",
      "\n",
      "Epoch 217/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 217/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 217/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 217/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 217/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 217/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 217/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 217/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 217/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 217/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 217/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 217/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 217/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001220, MRE: 1.628023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908368 \n",
      "\n",
      "Epoch 218/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 218/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 218/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 218/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 218/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 218/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 218/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 218/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 218/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.867519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.914594 \n",
      "\n",
      "Epoch 219/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 219/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 219/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 219/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 219/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 219/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 219/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 219/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 219/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.564816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.914447 \n",
      "\n",
      "Epoch 220/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 220/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 220/800, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 220/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 220/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 220/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 220/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 220/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 220/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 220/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 220/800, Iteration 11/12, Loss: 0.0024\n",
      "Epoch 220/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 220/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.580059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.914790 \n",
      "\n",
      "Epoch 221/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 221/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 221/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 221/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 221/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 221/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 221/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.576865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.909371 \n",
      "\n",
      "Epoch 222/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 222/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 222/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 222/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 222/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 222/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 222/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 222/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 222/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 222/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 222/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 222/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 222/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.570590 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.908625 \n",
      "\n",
      "Epoch 223/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 223/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 223/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 223/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 223/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 223/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 223/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 223/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 223/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 223/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 223/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 223/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 223/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.578090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.917295 \n",
      "\n",
      "Epoch 224/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 224/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 224/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 224/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 224/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 224/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 224/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 224/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 224/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 224/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 224/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.590058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.920492 \n",
      "\n",
      "Epoch 225/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 225/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 225/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 225/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 225/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 225/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 225/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 225/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 225/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 225/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 225/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 225/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.577180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.917053 \n",
      "\n",
      "Epoch 226/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 226/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 226/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 226/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 226/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 226/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 226/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 226/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 226/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 226/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 226/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 226/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 226/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.568500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.916292 \n",
      "\n",
      "Epoch 227/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 227/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 227/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 227/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 227/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 227/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 227/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 227/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 227/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 227/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 227/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 227/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 227/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.712891 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001159, MRE: 2.921658 \n",
      "\n",
      "Epoch 228/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 228/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 228/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 228/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 228/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 228/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 228/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 228/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 228/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 228/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001213, MRE: 1.566849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908055 \n",
      "\n",
      "Epoch 229/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 229/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 229/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 229/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 229/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 229/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 229/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 229/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 229/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 229/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 229/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 229/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 229/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.558250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.900458 \n",
      "\n",
      "Epoch 230/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 230/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 230/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 230/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 230/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 230/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 230/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 230/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 230/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 230/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 230/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 230/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 230/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001218, MRE: 1.584883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.889868 \n",
      "\n",
      "Epoch 231/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 231/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 231/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 231/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 231/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 231/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 231/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 231/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 231/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 231/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 231/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001207, MRE: 1.571685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.887578 \n",
      "\n",
      "Epoch 232/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 232/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 232/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 232/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 232/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 232/800, Iteration 7/12, Loss: 0.0024\n",
      "Epoch 232/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 232/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 232/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 232/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 232/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 232/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001211, MRE: 1.566632 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.892053 \n",
      "\n",
      "Epoch 233/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 233/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 233/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 233/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 233/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 233/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 233/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 233/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 233/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 233/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 233/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 233/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 233/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.587250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.892735 \n",
      "\n",
      "Epoch 234/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 234/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 234/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 234/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 234/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 234/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 234/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 234/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 234/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 234/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001222, MRE: 1.623345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.890648 \n",
      "\n",
      "Epoch 235/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 235/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 235/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 235/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 235/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 235/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 235/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 10/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 235/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 235/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.574884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.889832 \n",
      "\n",
      "Epoch 236/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 236/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 236/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 236/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 236/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 236/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 236/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 236/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 236/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 236/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 236/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 236/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 236/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001209, MRE: 1.566439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.888280 \n",
      "\n",
      "Epoch 237/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 237/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 237/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 237/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 237/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 237/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 237/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 237/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 237/800, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 237/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 237/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.569391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.902542 \n",
      "\n",
      "Epoch 238/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 238/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 238/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 238/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 238/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 238/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 238/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 238/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 238/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 238/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 238/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 238/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 238/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.618616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.916342 \n",
      "\n",
      "Epoch 239/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 239/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 239/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 239/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 239/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 239/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 239/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 239/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 239/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 239/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 239/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.580916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.919748 \n",
      "\n",
      "Epoch 240/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 240/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 240/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 240/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 240/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 240/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 240/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 240/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 240/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 240/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 240/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 240/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 240/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.580041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908613 \n",
      "\n",
      "Epoch 241/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 241/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 241/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 241/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 241/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 241/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 241/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 241/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 241/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 241/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 241/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.565594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.900785 \n",
      "\n",
      "Epoch 242/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 242/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 242/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 242/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 242/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 242/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 242/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 242/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 242/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 242/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 242/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.590092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.905625 \n",
      "\n",
      "Epoch 243/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 243/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 243/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 243/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 243/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 243/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 243/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 243/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 243/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 243/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.562324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.906179 \n",
      "\n",
      "Epoch 244/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 244/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 244/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 244/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 244/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 244/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 244/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 244/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 244/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 244/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 244/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 244/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 244/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.716556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.909913 \n",
      "\n",
      "Epoch 245/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 245/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 245/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 245/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 245/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 245/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 245/800, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 245/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 245/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 245/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 245/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 245/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 245/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.576345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.902959 \n",
      "\n",
      "Epoch 246/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 246/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 246/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 246/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 246/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 246/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 246/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 246/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 246/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 246/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.559035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.903816 \n",
      "\n",
      "Epoch 247/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 247/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 247/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 247/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 247/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 247/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 247/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 247/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 247/800, Iteration 13/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001221, MRE: 1.578513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907897 \n",
      "\n",
      "Epoch 248/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 248/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 248/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 248/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 248/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 248/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 248/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 248/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 248/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 248/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 248/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 248/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 248/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001219, MRE: 1.707233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.906593 \n",
      "\n",
      "Epoch 249/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 249/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 249/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 249/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 249/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 249/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 249/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 249/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 249/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 249/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 249/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 249/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 249/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.603021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.900579 \n",
      "\n",
      "Epoch 250/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 250/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 250/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 250/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 250/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 250/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 250/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 250/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 250/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 250/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 250/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 250/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001217, MRE: 1.580554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.895950 \n",
      "\n",
      "Epoch 251/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 251/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 251/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 251/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 251/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 251/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 251/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 251/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 251/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 251/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 251/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 251/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 251/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.563053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899932 \n",
      "\n",
      "Epoch 252/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 252/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 252/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 252/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 252/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 252/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 252/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 252/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 252/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 252/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 252/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 252/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 252/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.598376 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.910627 \n",
      "\n",
      "Epoch 253/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 253/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 253/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 253/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 253/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 253/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 253/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 253/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 253/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 253/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 253/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 253/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.603618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.905510 \n",
      "\n",
      "Epoch 254/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 254/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 254/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 254/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 254/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 254/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 254/800, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 254/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 254/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 254/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 254/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 254/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 254/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.623419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.906245 \n",
      "\n",
      "Epoch 255/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 255/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 255/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 255/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 255/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 255/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 255/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 255/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 255/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 255/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 255/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 255/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.562594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.905431 \n",
      "\n",
      "Epoch 256/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 256/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 256/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 256/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 256/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 256/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 256/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 256/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 256/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 256/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 256/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 256/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 256/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.565616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899887 \n",
      "\n",
      "Epoch 257/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 257/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 257/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 257/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 257/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 257/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 257/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 257/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 257/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 257/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 257/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.606396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908264 \n",
      "\n",
      "Epoch 258/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 258/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 258/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 258/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 258/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 258/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 258/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 258/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 258/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.567649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908192 \n",
      "\n",
      "Epoch 259/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 259/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 259/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 259/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 259/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 259/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 259/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 259/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 259/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 259/800, Iteration 10/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 259/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 259/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001221, MRE: 1.654005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.913882 \n",
      "\n",
      "Epoch 260/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 260/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 260/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 260/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 260/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 260/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 260/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 260/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 260/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 260/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 260/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 260/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 260/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.564560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904839 \n",
      "\n",
      "Epoch 261/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 261/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 261/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 261/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 261/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 261/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 261/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 261/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 261/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 261/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 261/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.918482 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.892296 \n",
      "\n",
      "Epoch 262/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 262/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 262/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 262/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 262/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 262/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 262/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 262/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 262/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 262/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 262/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 262/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 262/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001203, MRE: 1.587458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.884886 \n",
      "\n",
      "Epoch 263/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 263/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 263/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 263/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 263/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 263/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 263/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 263/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 263/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 263/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 263/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 263/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 263/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001191, MRE: 1.718908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.885673 \n",
      "\n",
      "Epoch 264/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 264/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 264/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 264/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 264/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 264/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 264/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 264/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 264/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 264/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 264/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 264/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 264/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001236, MRE: 1.573494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.894507 \n",
      "\n",
      "Epoch 265/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 265/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 265/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 265/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 265/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 265/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 265/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 265/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 265/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 265/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 265/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 265/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001223, MRE: 1.559443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899539 \n",
      "\n",
      "Epoch 266/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 266/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 266/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 266/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 266/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 266/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 266/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 266/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 266/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 266/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 266/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 266/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 266/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.562050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.901278 \n",
      "\n",
      "Epoch 267/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 267/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 267/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 267/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 267/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 267/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 267/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 267/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 267/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 267/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 267/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 267/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 267/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.565606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.915766 \n",
      "\n",
      "Epoch 268/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 268/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 268/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 268/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 268/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 268/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 268/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 268/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 268/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 268/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 268/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 268/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 268/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.599293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.918943 \n",
      "\n",
      "Epoch 269/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 269/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 269/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 269/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 269/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 269/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 269/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 269/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 269/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 269/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 269/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 269/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 269/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.598404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.913000 \n",
      "\n",
      "Epoch 270/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 270/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 270/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 270/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 270/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 270/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 270/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 270/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 270/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 270/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 270/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 270/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 270/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.722485 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.913194 \n",
      "\n",
      "Epoch 271/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 271/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 271/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 271/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 271/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 271/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 271/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 271/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 271/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 271/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 271/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 271/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 271/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.707800 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.898662 \n",
      "\n",
      "Epoch 272/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 272/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 272/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 272/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 272/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 272/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 272/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 272/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 272/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 272/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 272/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 272/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 272/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001216, MRE: 1.568134 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.890625 \n",
      "\n",
      "Epoch 273/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 273/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 273/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 273/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 273/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 273/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 273/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 273/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 273/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 273/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 273/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001226, MRE: 1.568088 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.888140 \n",
      "\n",
      "Epoch 274/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 274/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 274/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 274/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 274/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 274/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 274/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 274/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 274/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 274/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.867271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896489 \n",
      "\n",
      "Epoch 275/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 275/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 275/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 275/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 275/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 275/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 275/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 275/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 275/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 275/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 275/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 275/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 275/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.568374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899422 \n",
      "\n",
      "Epoch 276/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 276/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 276/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 276/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 276/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 276/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 276/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 276/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 276/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 276/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 276/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 276/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.572427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907454 \n",
      "\n",
      "Epoch 277/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 277/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 277/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 277/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 277/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 277/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 277/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 277/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 277/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 277/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 277/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 277/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 277/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.597281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.912667 \n",
      "\n",
      "Epoch 278/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 278/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 278/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 278/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 278/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 278/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 278/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 278/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 278/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 278/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 278/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 278/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001218, MRE: 1.579097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.900699 \n",
      "\n",
      "Epoch 279/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 279/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 279/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 279/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 279/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 279/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 279/800, Iteration 7/12, Loss: 0.0025\n",
      "Epoch 279/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 279/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 279/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 279/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 279/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 279/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.568036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.900634 \n",
      "\n",
      "Epoch 280/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 280/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 280/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 280/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 280/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 280/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 280/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 280/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 280/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 280/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 280/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 280/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 280/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001204, MRE: 1.639812 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.894742 \n",
      "\n",
      "Epoch 281/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 281/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 281/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 281/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 281/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 281/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 281/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 281/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 281/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 281/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 281/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 281/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.575197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.901013 \n",
      "\n",
      "Epoch 282/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 282/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 282/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 282/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 282/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 282/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 282/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 282/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 282/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 282/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 282/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001225, MRE: 1.610807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.906712 \n",
      "\n",
      "Epoch 283/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 283/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 283/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 283/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 283/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 283/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 283/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 283/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 283/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 283/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 283/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 283/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 283/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.580923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907232 \n",
      "\n",
      "Epoch 284/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 284/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 284/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 284/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 284/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 284/800, Iteration 6/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 284/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 284/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 284/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 284/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 284/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 284/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.575890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899400 \n",
      "\n",
      "Epoch 285/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 285/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 285/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 285/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 285/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 285/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 285/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 285/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 285/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 285/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 285/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 285/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 285/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.574610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904631 \n",
      "\n",
      "Epoch 286/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 286/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 286/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 286/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 286/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 286/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 286/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 286/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 286/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 286/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 286/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 286/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 286/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.751705 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.895240 \n",
      "\n",
      "Epoch 287/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 287/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 287/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 287/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 287/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 287/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 287/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 287/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 287/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 287/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 287/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.591708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.899057 \n",
      "\n",
      "Epoch 288/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 288/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 288/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 288/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 288/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 288/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 288/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 288/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 288/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 288/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 288/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 288/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.725257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.911587 \n",
      "\n",
      "Epoch 289/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 289/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 289/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 289/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 289/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 289/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 289/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 289/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.595357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907111 \n",
      "\n",
      "Epoch 290/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 290/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 290/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 290/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 290/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 290/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 290/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 290/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 290/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 290/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 290/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 290/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 290/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.629590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.891963 \n",
      "\n",
      "Epoch 291/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 291/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 291/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 291/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 291/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 291/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 291/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 291/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 291/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 291/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 291/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 291/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 291/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001206, MRE: 1.602251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.880097 \n",
      "\n",
      "Epoch 292/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 292/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 292/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 292/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 292/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 292/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 292/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 292/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 292/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 292/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001237, MRE: 1.582034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.874010 \n",
      "\n",
      "Epoch 293/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 293/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 293/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 293/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 293/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 293/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 293/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 293/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 293/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 293/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 293/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 293/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 293/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001194, MRE: 1.559908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.874144 \n",
      "\n",
      "Epoch 294/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 294/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 294/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 294/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 294/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 294/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 294/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 294/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 294/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 294/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 294/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 294/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 294/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001192, MRE: 1.575117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.871080 \n",
      "\n",
      "Epoch 295/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 295/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 295/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 295/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 295/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 295/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 295/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 295/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 295/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 295/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 295/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001223, MRE: 1.619670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001154, MRE: 2.870044 \n",
      "\n",
      "Epoch 296/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 296/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 296/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 296/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 296/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 296/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 296/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 296/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 296/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 296/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 296/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001211, MRE: 1.629623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.874341 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 297/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 297/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 297/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 297/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 297/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 297/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 297/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 297/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 297/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 297/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001203, MRE: 1.559797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001154, MRE: 2.862136 \n",
      "\n",
      "Epoch 298/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 298/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 298/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 298/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 298/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 298/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 298/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 298/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 298/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 298/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001196, MRE: 1.818377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001154, MRE: 2.864368 \n",
      "\n",
      "Epoch 299/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 299/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 299/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 299/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 299/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 299/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 299/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 299/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 299/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 299/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 299/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 299/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 299/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001198, MRE: 1.568286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.871044 \n",
      "\n",
      "Epoch 300/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 300/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 300/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 300/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 300/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 300/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 300/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 300/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 300/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 300/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 300/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 300/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 300/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001206, MRE: 1.570478 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.879263 \n",
      "\n",
      "Epoch 301/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 301/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 301/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 301/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 301/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 301/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 301/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 301/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 301/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 301/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 301/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 301/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 301/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.566432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.884392 \n",
      "\n",
      "Epoch 302/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 302/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 302/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 302/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 302/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 302/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 302/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 302/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 302/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 302/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 302/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 302/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 302/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001204, MRE: 1.563596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.891528 \n",
      "\n",
      "Epoch 303/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 303/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 303/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 303/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 303/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 303/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 303/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 303/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 303/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 303/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.709936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.883735 \n",
      "\n",
      "Epoch 304/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 304/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 304/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 304/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 304/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 304/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 304/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 304/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 304/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 304/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 304/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 304/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 304/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.563479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.886999 \n",
      "\n",
      "Epoch 305/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 305/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 305/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 305/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 305/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 305/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 305/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 305/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 305/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 305/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 305/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 305/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 305/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001209, MRE: 1.576400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.891108 \n",
      "\n",
      "Epoch 306/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 306/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 306/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 306/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 306/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 306/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 306/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 306/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 306/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 306/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 306/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 306/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 306/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.565760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.901938 \n",
      "\n",
      "Epoch 307/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 307/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 307/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 307/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 307/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 307/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 307/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 307/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 307/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 307/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 307/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001226, MRE: 1.562454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.907550 \n",
      "\n",
      "Epoch 308/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 308/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 308/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 308/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 308/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 308/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 308/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 308/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 308/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.565758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.897643 \n",
      "\n",
      "Epoch 309/800, Iteration 1/12, Loss: 0.0022\n",
      "Epoch 309/800, Iteration 2/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 309/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 309/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 309/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 309/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 309/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 309/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 309/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 309/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 309/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 309/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001187, MRE: 1.854447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.881166 \n",
      "\n",
      "Epoch 310/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 310/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 310/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 310/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 310/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 310/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 310/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 310/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 310/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 310/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 310/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 310/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 310/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001223, MRE: 1.888112 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.888397 \n",
      "\n",
      "Epoch 311/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 311/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 311/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 311/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 311/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 311/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 311/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 311/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 311/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 311/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 311/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 311/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 311/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001207, MRE: 1.559849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.889602 \n",
      "\n",
      "Epoch 312/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 312/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 312/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 312/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 312/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 312/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 312/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 312/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 312/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 312/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 312/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 312/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 312/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001207, MRE: 1.584640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.882463 \n",
      "\n",
      "Epoch 313/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 313/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 313/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 313/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 313/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 313/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 313/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 313/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 313/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 313/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 313/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 313/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 313/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001199, MRE: 1.899668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.879700 \n",
      "\n",
      "Epoch 314/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 314/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 314/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 314/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 314/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 314/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 314/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 314/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 314/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 314/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001206, MRE: 1.560053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.879157 \n",
      "\n",
      "Epoch 315/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 315/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 315/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 315/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 315/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 315/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 315/800, Iteration 7/12, Loss: 0.0022\n",
      "Epoch 315/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 315/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 315/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 315/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 315/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 315/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001208, MRE: 1.564217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.879157 \n",
      "\n",
      "Epoch 316/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 316/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 316/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 316/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 316/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 316/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 316/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 316/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 316/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 316/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 316/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 316/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 316/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001191, MRE: 1.580367 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.886203 \n",
      "\n",
      "Epoch 317/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 317/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 317/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 317/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 317/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 317/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 317/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 317/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 317/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 317/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 317/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.567405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.892635 \n",
      "\n",
      "Epoch 318/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 318/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 318/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 318/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 318/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 318/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 318/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 318/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 318/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 318/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 318/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 318/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 318/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.572582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.895202 \n",
      "\n",
      "Epoch 319/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 319/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 319/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 319/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 319/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 319/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 319/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 319/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 319/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 319/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 319/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 319/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 319/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001219, MRE: 1.563641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896274 \n",
      "\n",
      "Epoch 320/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 320/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 320/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 320/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 320/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 320/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 320/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 320/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 320/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 320/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 320/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 320/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 320/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.592072 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901612 \n",
      "\n",
      "Epoch 321/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 321/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 321/800, Iteration 3/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 321/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 321/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 321/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 321/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 321/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 321/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 321/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 321/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 321/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.564185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904683 \n",
      "\n",
      "Epoch 322/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 322/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 322/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 322/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 322/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 322/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 322/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 322/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 322/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 322/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.566647 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.905740 \n",
      "\n",
      "Epoch 323/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 323/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 323/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 323/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 323/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 323/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 323/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 323/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 323/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 323/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 323/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.570607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.909539 \n",
      "\n",
      "Epoch 324/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 324/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 324/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 324/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 324/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 324/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 324/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 324/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 324/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 324/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 324/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.561991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.912943 \n",
      "\n",
      "Epoch 325/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 325/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 325/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 325/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 325/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 325/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 325/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 325/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 325/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 325/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 325/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 325/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 325/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.759735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904916 \n",
      "\n",
      "Epoch 326/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 326/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 326/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 326/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 326/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 326/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 326/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 326/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 326/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 326/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 326/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 326/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 326/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.569682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896835 \n",
      "\n",
      "Epoch 327/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 327/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 327/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 327/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 327/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 327/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 327/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 327/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 327/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 327/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 327/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 327/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 327/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001214, MRE: 1.590511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.890236 \n",
      "\n",
      "Epoch 328/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 328/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 328/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 328/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 328/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 328/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 328/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 328/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 328/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 328/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 328/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 328/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 328/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.556744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.895457 \n",
      "\n",
      "Epoch 329/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 329/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 329/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 329/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 329/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 329/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 329/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 329/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 329/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 329/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 329/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 329/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 329/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.586844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.894153 \n",
      "\n",
      "Epoch 330/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 330/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 330/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 330/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 330/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 330/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 330/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 330/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 330/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 330/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001213, MRE: 1.593707 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896539 \n",
      "\n",
      "Epoch 331/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 331/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 331/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 331/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 331/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 331/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 331/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 331/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 331/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 331/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 331/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 331/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 331/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.580662 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.904931 \n",
      "\n",
      "Epoch 332/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 332/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 332/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 332/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 332/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 332/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 332/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 332/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 332/800, Iteration 13/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.584877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908788 \n",
      "\n",
      "Epoch 333/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 333/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 333/800, Iteration 3/12, Loss: 0.0008\n",
      "Epoch 333/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 333/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 333/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 333/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 333/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 333/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001231, MRE: 1.567787 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.912983 \n",
      "\n",
      "Epoch 334/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 334/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 334/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 334/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 334/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 334/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 334/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 334/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 334/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 334/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 334/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 334/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 334/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.575460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.912972 \n",
      "\n",
      "Epoch 335/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 335/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 335/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 335/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 335/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 335/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 335/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 335/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 335/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 335/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 335/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 335/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 335/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.594917 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.903753 \n",
      "\n",
      "Epoch 336/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 336/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 336/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 336/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 336/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 336/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 336/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 336/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 336/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 336/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 336/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 336/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 336/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001221, MRE: 1.581663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.902934 \n",
      "\n",
      "Epoch 337/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 337/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 337/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 337/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 337/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 337/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 337/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 337/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 337/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 337/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 337/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 337/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 337/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001195, MRE: 1.588118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.893652 \n",
      "\n",
      "Epoch 338/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 338/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 338/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 338/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 338/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 338/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 338/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 338/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 338/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 338/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 338/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 338/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 338/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001210, MRE: 1.870311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891202 \n",
      "\n",
      "Epoch 339/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 339/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 339/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 339/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 339/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 339/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 339/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 339/800, Iteration 10/12, Loss: 0.0026\n",
      "Epoch 339/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 339/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 339/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.602189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887556 \n",
      "\n",
      "Epoch 340/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 340/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 340/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 340/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 340/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 340/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 340/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 340/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 340/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 340/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 340/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 340/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.759712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.886131 \n",
      "\n",
      "Epoch 341/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 341/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 341/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 341/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 341/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 341/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 341/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 341/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 341/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 341/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 341/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 341/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.745361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.893088 \n",
      "\n",
      "Epoch 342/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 342/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 342/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 342/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 342/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 342/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 342/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 342/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 342/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 342/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 342/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 342/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 342/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.580217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.893491 \n",
      "\n",
      "Epoch 343/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 343/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 343/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 343/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 343/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 343/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 343/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 343/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 343/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 343/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 343/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001224, MRE: 1.575257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891131 \n",
      "\n",
      "Epoch 344/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 344/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 344/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 344/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 344/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 344/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 344/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 344/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 344/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 344/800, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 344/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 344/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 344/800, Iteration 13/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001221, MRE: 1.583537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891873 \n",
      "\n",
      "Epoch 345/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 345/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 345/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 345/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 345/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 345/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 345/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 345/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 345/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 345/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 345/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 345/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 345/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.628212 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891660 \n",
      "\n",
      "Epoch 346/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 346/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 346/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 346/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 346/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 346/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 346/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 346/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 346/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 346/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 346/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 346/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 346/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001191, MRE: 1.559383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.885789 \n",
      "\n",
      "Epoch 347/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 347/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 347/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 347/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 347/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 347/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 347/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 347/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 347/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001212, MRE: 1.564096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887610 \n",
      "\n",
      "Epoch 348/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 348/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 348/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 348/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 348/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 348/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 348/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 348/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 348/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 348/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 348/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 348/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 348/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.570438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.892113 \n",
      "\n",
      "Epoch 349/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 349/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 349/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 349/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 349/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 349/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 349/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 349/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 349/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 349/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 349/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 349/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 349/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.555097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.888116 \n",
      "\n",
      "Epoch 350/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 350/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 350/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 350/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 350/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 350/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 350/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 350/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 350/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 350/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 350/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 350/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 350/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.617799 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896470 \n",
      "\n",
      "Epoch 351/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 351/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 351/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 351/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 351/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 351/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 351/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 351/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 351/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 351/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 351/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 351/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 351/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.560185 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.914241 \n",
      "\n",
      "Epoch 352/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 352/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 352/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 352/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 352/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 352/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 352/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 352/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 352/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 352/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 352/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 352/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 352/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.867658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.916169 \n",
      "\n",
      "Epoch 353/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 353/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 353/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 353/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 353/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 353/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 353/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 353/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.621044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.912459 \n",
      "\n",
      "Epoch 354/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 354/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 354/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 354/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 354/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 354/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 354/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 354/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 354/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 354/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.571237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001158, MRE: 2.919350 \n",
      "\n",
      "Epoch 355/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 355/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 355/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 355/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 355/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 355/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 355/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 355/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 355/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 355/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 355/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 355/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 355/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.579506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.914936 \n",
      "\n",
      "Epoch 356/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 356/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 356/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 356/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 356/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 356/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 356/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 356/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 356/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 356/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 356/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 356/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 356/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.898746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908156 \n",
      "\n",
      "Epoch 357/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 357/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 357/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 357/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 357/800, Iteration 7/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 357/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 357/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 357/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 357/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 357/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.571846 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908063 \n",
      "\n",
      "Epoch 358/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 358/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 358/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 358/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 358/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 358/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 358/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 358/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 358/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 358/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.574929 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.903482 \n",
      "\n",
      "Epoch 359/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 359/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 359/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 359/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 359/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 359/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 359/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 359/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 359/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 359/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 359/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 359/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 359/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.578026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908090 \n",
      "\n",
      "Epoch 360/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 360/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 360/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 360/800, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 360/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 360/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 360/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 360/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 360/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 360/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 360/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 360/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 360/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.569358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.900941 \n",
      "\n",
      "Epoch 361/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 361/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 361/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 361/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 361/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 361/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 361/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 361/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 361/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 361/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 361/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 361/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 361/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.564847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901903 \n",
      "\n",
      "Epoch 362/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 362/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 362/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 362/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 362/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 362/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 362/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 362/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 362/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 362/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 362/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 362/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 362/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001192, MRE: 1.570700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.894700 \n",
      "\n",
      "Epoch 363/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 363/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 363/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 363/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 363/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 363/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 363/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 363/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 363/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 363/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 363/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 363/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 363/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.591232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.906162 \n",
      "\n",
      "Epoch 364/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 364/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 364/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 364/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 364/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 364/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 364/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 364/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 364/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 364/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 364/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 364/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 364/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.560046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.908042 \n",
      "\n",
      "Epoch 365/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 365/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 365/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 365/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 365/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 365/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 365/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 365/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 365/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 365/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 365/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 365/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 365/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.617178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.911825 \n",
      "\n",
      "Epoch 366/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 366/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 366/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 366/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 366/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 366/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 366/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 366/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 366/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 366/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001178, MRE: 1.635294 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.903590 \n",
      "\n",
      "Epoch 367/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 367/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 367/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 367/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 367/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 367/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 367/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 367/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 367/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 367/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 367/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 367/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 367/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.574623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.899215 \n",
      "\n",
      "Epoch 368/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 368/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 368/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 368/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 368/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 368/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 368/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 368/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.567428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.902327 \n",
      "\n",
      "Epoch 369/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 369/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 369/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 369/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 369/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 369/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 369/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 369/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 369/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 369/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 369/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 369/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 369/800, Iteration 13/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.867725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.910819 \n",
      "\n",
      "Epoch 370/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 370/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 370/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 370/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 370/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 370/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 370/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 370/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 370/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 370/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 370/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 370/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 370/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.569181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.899507 \n",
      "\n",
      "Epoch 371/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 371/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 371/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 371/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 371/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 371/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 371/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 371/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 371/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 371/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 371/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 371/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 371/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.583616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896923 \n",
      "\n",
      "Epoch 372/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 372/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 372/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 372/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 372/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 372/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 372/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 372/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 372/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 372/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 372/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 372/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 372/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.765157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898739 \n",
      "\n",
      "Epoch 373/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 373/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 373/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 373/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 373/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 373/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 373/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 373/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 373/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 373/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 373/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 373/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 373/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001233, MRE: 1.871336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.904902 \n",
      "\n",
      "Epoch 374/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 374/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 374/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 374/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 374/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 374/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 374/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 374/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 374/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 374/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 374/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 374/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 374/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001215, MRE: 1.598405 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887076 \n",
      "\n",
      "Epoch 375/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 375/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 375/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 375/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 375/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 375/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 375/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 375/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 375/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 375/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 375/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 375/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 375/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001219, MRE: 1.585181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001153, MRE: 2.864466 \n",
      "\n",
      "Epoch 376/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 376/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 376/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 376/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 376/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 376/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 376/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 376/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 376/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 376/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 376/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 376/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 376/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001229, MRE: 1.578313 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.871275 \n",
      "\n",
      "Epoch 377/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 377/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 377/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 377/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 377/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 377/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 377/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 377/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 377/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001193, MRE: 1.591380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.871577 \n",
      "\n",
      "Epoch 378/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 378/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 378/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 378/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 378/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 378/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 378/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 378/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 378/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 378/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 378/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 378/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 378/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001209, MRE: 1.566250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.876975 \n",
      "\n",
      "Epoch 379/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 379/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 379/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 379/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 379/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 379/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 379/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 379/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 379/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 379/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 379/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 379/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.737637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.883989 \n",
      "\n",
      "Epoch 380/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 380/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 380/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 380/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 380/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 380/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 380/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 380/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 380/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 380/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 380/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 380/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 380/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.564819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893098 \n",
      "\n",
      "Epoch 381/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 381/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 381/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 381/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 381/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 381/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 381/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 381/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 381/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 381/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 381/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 381/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 381/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001212, MRE: 1.566704 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.886051 \n",
      "\n",
      "Epoch 382/800, Iteration 1/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 382/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 382/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 382/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 382/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 382/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 382/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 382/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 382/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 382/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 382/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 382/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.567885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.885556 \n",
      "\n",
      "Epoch 383/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 383/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 383/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 383/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 383/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 383/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 383/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 383/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 383/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 383/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001222, MRE: 1.568507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893615 \n",
      "\n",
      "Epoch 384/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 384/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 384/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 384/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 384/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 384/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 384/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 384/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 384/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 384/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 384/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 384/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.619667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898929 \n",
      "\n",
      "Epoch 385/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 385/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 385/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 385/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 385/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 385/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 385/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 385/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 385/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 385/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 385/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 385/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 385/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.576507 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901717 \n",
      "\n",
      "Epoch 386/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 386/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 386/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 386/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 386/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 386/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 386/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 386/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 386/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 386/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 386/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 386/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 386/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.571402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901907 \n",
      "\n",
      "Epoch 387/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 387/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 387/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 387/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 387/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 387/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 387/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 387/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 387/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 387/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 387/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 387/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 387/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.759306 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.900619 \n",
      "\n",
      "Epoch 388/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 388/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 388/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 388/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 388/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 388/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 388/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 388/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 388/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 388/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 388/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 388/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 388/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.906655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.896985 \n",
      "\n",
      "Epoch 389/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 389/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 389/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 389/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 389/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 389/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 389/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 389/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 389/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 389/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 389/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 389/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 389/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001192, MRE: 1.633058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895419 \n",
      "\n",
      "Epoch 390/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 390/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 390/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 390/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 390/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 390/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 390/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 390/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 390/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.560145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894625 \n",
      "\n",
      "Epoch 391/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 391/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 391/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 391/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 391/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 391/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 391/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 391/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 391/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 391/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 391/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001220, MRE: 1.562936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.900729 \n",
      "\n",
      "Epoch 392/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 392/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 392/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 392/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 392/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 392/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 392/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 392/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.574903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901768 \n",
      "\n",
      "Epoch 393/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 393/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 393/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 393/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 393/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 393/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 393/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 393/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 393/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 393/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 393/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 393/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 393/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001211, MRE: 1.571498 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894905 \n",
      "\n",
      "Epoch 394/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 394/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 394/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 394/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 394/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 394/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 394/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 394/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 394/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001218, MRE: 1.565164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891045 \n",
      "\n",
      "Epoch 395/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 395/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 395/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 395/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 395/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 395/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 395/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 395/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 395/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 395/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 395/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 395/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 395/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.561160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.897131 \n",
      "\n",
      "Epoch 396/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 396/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 396/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 396/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 396/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 396/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 396/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 396/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 396/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 396/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 396/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001195, MRE: 1.558578 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891199 \n",
      "\n",
      "Epoch 397/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 397/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 397/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 397/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 397/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 397/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 397/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 397/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 397/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 397/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 397/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 397/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 397/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001211, MRE: 1.596826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894110 \n",
      "\n",
      "Epoch 398/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 398/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 398/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 398/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 398/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 398/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 398/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 398/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 398/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 398/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 398/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 398/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 398/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.569944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896018 \n",
      "\n",
      "Epoch 399/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 399/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 399/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 399/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 399/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 399/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 399/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 399/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 399/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 399/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 399/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 399/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 399/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.596518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887962 \n",
      "\n",
      "Epoch 400/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 400/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 400/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 400/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 400/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 400/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 400/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 400/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 400/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 400/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 400/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 400/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.560866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.878464 \n",
      "\n",
      "Epoch 401/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 401/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 401/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 401/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 401/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 401/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 401/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 401/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 401/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 401/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 401/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 401/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 401/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001192, MRE: 1.702444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.884156 \n",
      "\n",
      "Epoch 402/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 402/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 402/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 402/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 402/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 402/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 402/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 402/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 402/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 402/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 402/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 402/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 402/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.591429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898407 \n",
      "\n",
      "Epoch 403/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 403/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 403/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 403/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 403/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 403/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 403/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 403/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 403/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 403/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 403/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 403/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.570109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.902031 \n",
      "\n",
      "Epoch 404/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 404/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 404/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 404/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 404/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 404/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 404/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 404/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 404/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 404/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 404/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 404/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 404/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.925236 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.905537 \n",
      "\n",
      "Epoch 405/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 405/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 405/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 405/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 405/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 405/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 405/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 405/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 405/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 405/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 405/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 405/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 405/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.567944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.897484 \n",
      "\n",
      "Epoch 406/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 406/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 406/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 406/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 406/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 406/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 406/800, Iteration 10/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 406/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 406/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001202, MRE: 1.560729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.889910 \n",
      "\n",
      "Epoch 407/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 407/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 407/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 407/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 407/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 407/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 407/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 407/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 407/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 407/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 407/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 407/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 407/800, Iteration 13/12, Loss: 0.0006\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001198, MRE: 1.574042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.882910 \n",
      "\n",
      "Epoch 408/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 408/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 408/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 408/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 408/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 408/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 408/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 408/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 408/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 408/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001206, MRE: 1.567458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.870795 \n",
      "\n",
      "Epoch 409/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 409/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 409/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 409/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 409/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 409/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 409/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 409/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 409/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 409/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 409/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 409/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 409/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001209, MRE: 1.569182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.872027 \n",
      "\n",
      "Epoch 410/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 410/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 410/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 410/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 410/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 410/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 410/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 410/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 410/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001189, MRE: 1.567315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.874327 \n",
      "\n",
      "Epoch 411/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 411/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 411/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 411/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 411/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 411/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 411/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 411/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 411/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 411/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 411/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 411/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 411/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001204, MRE: 1.570938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.878956 \n",
      "\n",
      "Epoch 412/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 412/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 412/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 412/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 412/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 412/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 412/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 412/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 412/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 412/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 412/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 412/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 412/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.582720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.886160 \n",
      "\n",
      "Epoch 413/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 413/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 413/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 413/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 413/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 413/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 413/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 413/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 413/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 413/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 413/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001196, MRE: 1.865053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.880195 \n",
      "\n",
      "Epoch 414/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 414/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 414/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 414/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 414/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 414/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 414/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 414/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 414/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 414/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 414/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 414/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.626575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.882193 \n",
      "\n",
      "Epoch 415/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 415/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 415/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 415/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 415/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 415/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 415/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 415/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 415/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 415/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 415/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 415/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 415/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001192, MRE: 1.570183 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.883963 \n",
      "\n",
      "Epoch 416/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 416/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 416/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 416/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 416/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 416/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 416/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 416/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 416/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 416/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 416/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001207, MRE: 1.570792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.890168 \n",
      "\n",
      "Epoch 417/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 417/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 417/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 417/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 417/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 417/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 417/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 417/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 417/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 417/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 417/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 417/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 417/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.603881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893088 \n",
      "\n",
      "Epoch 418/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 418/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 418/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 418/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 418/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 418/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 418/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 418/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 418/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 418/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 418/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001202, MRE: 1.569639 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891252 \n",
      "\n",
      "Epoch 419/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 419/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 419/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 419/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 419/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 419/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 419/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 419/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 419/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 419/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 419/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 419/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 419/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.580979 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895737 \n",
      "\n",
      "Epoch 420/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 420/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 420/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 420/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 420/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 420/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 420/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 420/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 420/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 420/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 420/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 420/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 420/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.635402 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898910 \n",
      "\n",
      "Epoch 421/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 421/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 421/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 421/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 421/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 421/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 421/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 421/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 421/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.564935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894647 \n",
      "\n",
      "Epoch 422/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 422/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 422/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 422/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 422/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 422/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 422/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 422/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 422/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 422/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.568386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.907589 \n",
      "\n",
      "Epoch 423/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 423/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 423/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 423/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 423/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 423/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 423/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 423/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 423/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 423/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 423/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001219, MRE: 1.599720 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.902672 \n",
      "\n",
      "Epoch 424/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 424/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 424/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 424/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 424/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 424/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 424/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 424/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 424/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 424/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 424/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 424/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 424/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.569990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894398 \n",
      "\n",
      "Epoch 425/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 425/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 425/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 425/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 425/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 425/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 425/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 425/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 425/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.568316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.877452 \n",
      "\n",
      "Epoch 426/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 426/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 426/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 426/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 426/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 426/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 426/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 426/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 426/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 426/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 426/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001196, MRE: 1.568124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.889042 \n",
      "\n",
      "Epoch 427/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 427/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 427/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 427/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 427/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 427/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 427/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 427/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 427/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 427/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 427/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 427/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 427/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001196, MRE: 1.561077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884164 \n",
      "\n",
      "Epoch 428/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 428/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 428/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 428/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 428/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 428/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 428/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 428/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 428/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 428/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 428/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.602392 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.878583 \n",
      "\n",
      "Epoch 429/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 429/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 429/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 429/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 429/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 429/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 429/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 429/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001199, MRE: 1.558714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.868605 \n",
      "\n",
      "Epoch 430/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 430/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 430/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 430/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 430/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 430/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 430/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 430/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 430/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 430/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 430/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 430/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 430/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.561444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.874563 \n",
      "\n",
      "Epoch 431/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 431/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 431/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 431/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 431/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 431/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 431/800, Iteration 7/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 431/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 431/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 431/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 431/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 431/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.572992 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.877694 \n",
      "\n",
      "Epoch 432/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 432/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 432/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 432/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 432/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 432/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 432/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 432/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 432/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 432/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 432/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 432/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 432/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001197, MRE: 1.569934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.873451 \n",
      "\n",
      "Epoch 433/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 433/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 433/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 6/12, Loss: 0.0021\n",
      "Epoch 433/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 433/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 433/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 433/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 433/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 433/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 433/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.561952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.886247 \n",
      "\n",
      "Epoch 434/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 434/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 434/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 434/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 434/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 434/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 434/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 434/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 434/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 434/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 434/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 434/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.585285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.892545 \n",
      "\n",
      "Epoch 435/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 435/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 435/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 435/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 435/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 435/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 435/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 435/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 435/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 435/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 435/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 435/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 435/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.562063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.880776 \n",
      "\n",
      "Epoch 436/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 436/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 436/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 436/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 436/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 436/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 436/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 436/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 436/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.593097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872367 \n",
      "\n",
      "Epoch 437/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 437/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 437/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 437/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 437/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 437/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 437/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 437/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 437/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 437/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 437/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 437/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 437/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001185, MRE: 1.555567 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887352 \n",
      "\n",
      "Epoch 438/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 438/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 438/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 438/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 438/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 438/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 438/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 438/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 438/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 438/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 438/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 438/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 438/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001206, MRE: 1.570430 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.882393 \n",
      "\n",
      "Epoch 439/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 439/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 439/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 439/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 439/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 439/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 439/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 439/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 439/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 439/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 439/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 439/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 439/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.598218 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887275 \n",
      "\n",
      "Epoch 440/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 440/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 440/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 440/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 440/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 440/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 440/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 440/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 440/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 440/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 440/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 440/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 440/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.567600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.888011 \n",
      "\n",
      "Epoch 441/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 441/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 441/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 441/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 441/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 441/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 441/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 441/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 441/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 441/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 441/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001215, MRE: 1.554338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895829 \n",
      "\n",
      "Epoch 442/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 442/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 442/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 442/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 442/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 442/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 442/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 442/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 442/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 442/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 442/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 442/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 442/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.616835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896344 \n",
      "\n",
      "Epoch 443/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 443/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 443/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 443/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 443/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 443/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 443/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 443/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 443/800, Iteration 9/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 443/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 443/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 443/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001186, MRE: 1.670987 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.897020 \n",
      "\n",
      "Epoch 444/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 444/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 444/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 444/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 444/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 444/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 444/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 444/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 444/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 444/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 444/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 444/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 444/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.569429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.903158 \n",
      "\n",
      "Epoch 445/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 445/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 445/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 445/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 445/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 445/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 445/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 445/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 445/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 445/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 445/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 445/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 445/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.561907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898106 \n",
      "\n",
      "Epoch 446/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 446/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 446/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 446/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 446/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 446/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 446/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 446/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 446/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 446/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 446/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 446/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 446/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001213, MRE: 1.631902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.898775 \n",
      "\n",
      "Epoch 447/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 447/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 447/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 447/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 447/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 447/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 447/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 447/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 447/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 447/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 447/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 447/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001223, MRE: 1.578887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895660 \n",
      "\n",
      "Epoch 448/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 448/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 448/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 448/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 448/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 448/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 448/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 448/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 448/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.561931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891252 \n",
      "\n",
      "Epoch 449/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 449/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 449/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 449/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 449/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 449/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 449/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 449/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 449/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 449/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 449/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 449/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 449/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.577046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896866 \n",
      "\n",
      "Epoch 450/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 450/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 450/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 450/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 450/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 450/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 450/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 450/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 450/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 450/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 450/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 450/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 450/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001195, MRE: 1.883288 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.907837 \n",
      "\n",
      "Epoch 451/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 451/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 451/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 451/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 451/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 451/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 451/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 451/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 451/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 451/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 451/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 451/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 451/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001203, MRE: 1.572243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001157, MRE: 2.914750 \n",
      "\n",
      "Epoch 452/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 452/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 452/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 452/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 452/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 452/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 452/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 452/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 452/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 452/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 452/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 452/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 452/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001221, MRE: 1.563753 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001158, MRE: 2.924931 \n",
      "\n",
      "Epoch 453/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 453/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 453/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 453/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 453/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 453/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 453/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 453/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 453/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 453/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 453/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 453/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 453/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001186, MRE: 1.622903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001158, MRE: 2.923904 \n",
      "\n",
      "Epoch 454/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 454/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 454/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 454/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 454/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 454/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 454/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 454/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 454/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 454/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 454/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 454/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 454/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.697896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901459 \n",
      "\n",
      "Epoch 455/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 455/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 455/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 455/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 455/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 455/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 455/800, Iteration 7/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 455/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 455/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 455/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 455/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 455/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001225, MRE: 1.569867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.901552 \n",
      "\n",
      "Epoch 456/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 456/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 456/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 456/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 456/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 456/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 456/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 456/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 456/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 456/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 456/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 456/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 456/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.570503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.897878 \n",
      "\n",
      "Epoch 457/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 457/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 457/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 457/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 457/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 457/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 457/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 457/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 457/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 457/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 457/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.565948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896073 \n",
      "\n",
      "Epoch 458/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 458/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 458/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 458/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 458/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 458/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 458/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 458/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 458/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 458/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 458/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 458/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 458/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.570554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896274 \n",
      "\n",
      "Epoch 459/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 459/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 459/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 459/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 459/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 459/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 459/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 459/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 459/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 459/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 459/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 459/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 459/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.836931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.887380 \n",
      "\n",
      "Epoch 460/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 460/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 460/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 460/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 460/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 460/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 460/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 460/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 460/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 460/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 460/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.624767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893097 \n",
      "\n",
      "Epoch 461/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 461/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 461/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 461/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 461/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 461/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 461/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 461/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 461/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 461/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 461/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 461/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 461/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.557774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.902107 \n",
      "\n",
      "Epoch 462/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 462/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 462/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 462/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 462/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 462/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 462/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 462/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 462/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 462/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 462/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 462/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 462/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.874788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.892782 \n",
      "\n",
      "Epoch 463/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 463/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 463/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 463/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 463/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 463/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 463/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 463/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 463/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 463/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 463/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 463/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.607188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.887092 \n",
      "\n",
      "Epoch 464/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 464/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 464/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 464/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 464/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 464/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 464/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 464/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 464/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 464/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 464/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 464/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 464/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.565248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895002 \n",
      "\n",
      "Epoch 465/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 465/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 465/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 465/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 465/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 465/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 465/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 465/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 465/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 465/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 465/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 465/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 465/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.578270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.885891 \n",
      "\n",
      "Epoch 466/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 466/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 466/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 466/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 466/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 466/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 466/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 466/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 466/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 466/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 466/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 466/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 466/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.615872 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.873933 \n",
      "\n",
      "Epoch 467/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 467/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 467/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 467/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 467/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 467/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 467/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 467/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 467/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 467/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 467/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 467/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 467/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001216, MRE: 1.562426 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.877797 \n",
      "\n",
      "Epoch 468/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 468/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 468/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 468/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 468/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 468/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 468/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 468/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 468/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 468/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 468/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.564804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.887605 \n",
      "\n",
      "Epoch 469/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 469/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 469/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 469/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 469/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 469/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 469/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 469/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 469/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 469/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 469/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.556367 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.890047 \n",
      "\n",
      "Epoch 470/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 470/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 470/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 470/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 470/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 470/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 470/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 470/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 470/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 470/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001212, MRE: 1.560715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.869029 \n",
      "\n",
      "Epoch 471/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 471/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 471/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 471/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 471/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 471/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 471/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 471/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 471/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 471/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 471/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 471/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 471/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001199, MRE: 1.573142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.866629 \n",
      "\n",
      "Epoch 472/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 472/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 472/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 472/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 472/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 472/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 472/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 472/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 472/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 472/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 472/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 472/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 472/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.580387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.871167 \n",
      "\n",
      "Epoch 473/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 473/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 473/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 473/800, Iteration 4/12, Loss: 0.0008\n",
      "Epoch 473/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 473/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 473/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 473/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 473/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 473/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 473/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 473/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 473/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001198, MRE: 1.612200 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.876511 \n",
      "\n",
      "Epoch 474/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 474/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 474/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 474/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 474/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 474/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 474/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 474/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 474/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 474/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 474/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 474/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001217, MRE: 1.554702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.871981 \n",
      "\n",
      "Epoch 475/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 475/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 475/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 475/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 475/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 475/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 475/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 475/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 475/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 475/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 475/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 475/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 475/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.564523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889037 \n",
      "\n",
      "Epoch 476/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 476/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 476/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 476/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 476/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 476/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 476/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 476/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 476/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 476/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 476/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 476/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 476/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.569175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.888299 \n",
      "\n",
      "Epoch 477/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 477/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 477/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 477/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 477/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 477/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 477/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 477/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 477/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 477/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 477/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 477/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 477/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.563053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.890112 \n",
      "\n",
      "Epoch 478/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 478/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 478/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 478/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 478/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 478/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 478/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 478/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 478/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 478/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 478/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 478/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 478/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001220, MRE: 1.574229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.900352 \n",
      "\n",
      "Epoch 479/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 479/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 479/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 479/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 479/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 479/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 479/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 479/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 479/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 479/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001218, MRE: 1.564582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895110 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 480/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 480/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 480/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 480/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 480/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 480/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 480/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 480/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 480/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 480/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.586855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895090 \n",
      "\n",
      "Epoch 481/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 481/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 481/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 481/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 481/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 481/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 481/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 481/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 481/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.594323 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889612 \n",
      "\n",
      "Epoch 482/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 482/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 482/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 482/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 482/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 482/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 482/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 482/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 482/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 482/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 482/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 482/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 482/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.581765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.891763 \n",
      "\n",
      "Epoch 483/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 483/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 483/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 483/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 483/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 483/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 483/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 483/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 483/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 483/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.559956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.897271 \n",
      "\n",
      "Epoch 484/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 484/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 484/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 484/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 484/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 484/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 484/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 484/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 484/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 484/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 484/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 484/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 484/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.563491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.890574 \n",
      "\n",
      "Epoch 485/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 485/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 485/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 485/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 485/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 485/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 485/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 485/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 485/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 485/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 485/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 485/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 485/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.570064 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.892587 \n",
      "\n",
      "Epoch 486/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 486/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 486/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 486/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 486/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 486/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 486/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 486/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 486/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 486/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.739592 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893485 \n",
      "\n",
      "Epoch 487/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 487/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 487/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 487/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 487/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 487/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 487/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 487/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 487/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 487/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 487/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 487/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 487/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.573334 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889779 \n",
      "\n",
      "Epoch 488/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 488/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 488/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 488/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 488/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 488/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 488/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 488/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 488/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 488/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.596715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890404 \n",
      "\n",
      "Epoch 489/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 489/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 489/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 489/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 489/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 489/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 489/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001207, MRE: 1.582930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889801 \n",
      "\n",
      "Epoch 490/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 490/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 490/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 490/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 490/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 490/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 490/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 490/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 490/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 490/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 490/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 490/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 490/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.555049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889381 \n",
      "\n",
      "Epoch 491/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 491/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 491/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 491/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 491/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 491/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 491/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 491/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 491/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.889432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.889819 \n",
      "\n",
      "Epoch 492/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 492/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 492/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 492/800, Iteration 5/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 492/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 492/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 492/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 492/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 492/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 492/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.574675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884237 \n",
      "\n",
      "Epoch 493/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 493/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 493/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 493/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 493/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 493/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 493/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 493/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 493/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 493/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 493/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 493/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 493/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.561521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.886287 \n",
      "\n",
      "Epoch 494/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 494/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 494/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 494/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 494/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 494/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 494/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 494/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 494/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 494/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.569035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.879230 \n",
      "\n",
      "Epoch 495/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 495/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 495/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 495/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 495/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 495/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 495/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 495/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 495/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 495/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 495/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 495/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 495/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.623620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894460 \n",
      "\n",
      "Epoch 496/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 496/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 496/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 496/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 496/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 496/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 496/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 496/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 496/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 496/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 496/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 496/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.624339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.899444 \n",
      "\n",
      "Epoch 497/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 497/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 497/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 497/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 497/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 497/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 497/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 497/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 497/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 497/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 497/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 497/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 497/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001183, MRE: 1.566553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890441 \n",
      "\n",
      "Epoch 498/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 498/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 498/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 498/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 498/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 498/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 498/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 498/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 498/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 498/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001195, MRE: 1.649102 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.906058 \n",
      "\n",
      "Epoch 499/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 499/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 499/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 499/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 499/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 499/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 499/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 499/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 499/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 499/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 499/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 499/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 499/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001200, MRE: 1.569541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001156, MRE: 2.909673 \n",
      "\n",
      "Epoch 500/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 500/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 500/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 500/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 500/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 500/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 500/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 500/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 500/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 500/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 500/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 500/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 500/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.749505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896770 \n",
      "\n",
      "Epoch 501/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 501/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 501/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 501/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 501/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 501/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 501/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 501/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 501/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 501/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 501/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 501/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 501/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.750183 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.895550 \n",
      "\n",
      "Epoch 502/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 502/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 502/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 502/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 502/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 502/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 502/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 502/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 502/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 502/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 502/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 502/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 502/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.786290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890846 \n",
      "\n",
      "Epoch 503/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 503/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 503/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 503/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 503/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 503/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 503/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 503/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 503/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 503/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 503/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 503/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 503/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.584900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890462 \n",
      "\n",
      "Epoch 504/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 504/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 504/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 504/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 504/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 504/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 504/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 504/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 504/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 504/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 504/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 504/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 504/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.563194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.877624 \n",
      "\n",
      "Epoch 505/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 505/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 4/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 505/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 505/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 505/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 505/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 505/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 505/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001191, MRE: 1.576472 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872877 \n",
      "\n",
      "Epoch 506/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 506/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 506/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 506/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 506/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 506/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 506/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 506/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 506/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 506/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 506/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 506/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 506/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.551965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.876835 \n",
      "\n",
      "Epoch 507/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 507/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 507/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 507/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 507/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 507/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 507/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 507/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 507/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 507/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 507/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 507/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 507/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001208, MRE: 1.560317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.870182 \n",
      "\n",
      "Epoch 508/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 508/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 508/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 508/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 508/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 508/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 508/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 508/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 508/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 508/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 508/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 508/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 508/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001201, MRE: 1.711231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872771 \n",
      "\n",
      "Epoch 509/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 509/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 509/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 509/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 509/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 509/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 509/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 509/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 509/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 509/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 509/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 509/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 509/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001193, MRE: 1.577456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.863708 \n",
      "\n",
      "Epoch 510/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 510/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 510/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 510/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 510/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 510/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 510/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 510/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 510/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 510/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 510/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001181, MRE: 1.562207 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.854823 \n",
      "\n",
      "Epoch 511/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 511/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 511/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 511/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 511/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 511/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 511/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 511/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 511/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 511/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001193, MRE: 1.858839 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.857875 \n",
      "\n",
      "Epoch 512/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 512/800, Iteration 2/12, Loss: 0.0022\n",
      "Epoch 512/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 512/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 512/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 512/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 512/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 512/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 512/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 512/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 512/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 512/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001189, MRE: 1.576737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.863367 \n",
      "\n",
      "Epoch 513/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 513/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 513/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 513/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 513/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 513/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 513/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 513/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 513/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 513/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 513/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 513/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 513/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001199, MRE: 1.628520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867882 \n",
      "\n",
      "Epoch 514/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 514/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 514/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 514/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 514/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 514/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 514/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 514/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 514/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001209, MRE: 1.714937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.868666 \n",
      "\n",
      "Epoch 515/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 515/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 515/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 515/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 515/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 515/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 515/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 515/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 515/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 515/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.561808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.882200 \n",
      "\n",
      "Epoch 516/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 516/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 516/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 516/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 516/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 516/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 516/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 516/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 516/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 516/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 516/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 516/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 516/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.566795 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884786 \n",
      "\n",
      "Epoch 517/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 517/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 517/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 517/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 517/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 517/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 517/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 517/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 517/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 517/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 517/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 517/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 517/800, Iteration 13/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.575732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889175 \n",
      "\n",
      "Epoch 518/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 518/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 518/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 518/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 518/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 518/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 518/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 518/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 518/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 518/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 518/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 518/800, Iteration 12/12, Loss: 0.0023\n",
      "Epoch 518/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.574556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.893614 \n",
      "\n",
      "Epoch 519/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 519/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 519/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 519/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 519/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 519/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 519/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 519/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 519/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 519/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 519/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 519/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.570649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.892182 \n",
      "\n",
      "Epoch 520/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 520/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 520/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 520/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 520/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 520/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 520/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 520/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 520/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 520/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 520/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 520/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 520/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.606449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.894851 \n",
      "\n",
      "Epoch 521/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 521/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 521/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 521/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 521/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 521/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 521/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 521/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 521/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 521/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 521/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 521/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 521/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.701089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.887056 \n",
      "\n",
      "Epoch 522/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 522/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 522/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 522/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 522/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 522/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 522/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 522/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 522/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 522/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 522/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 522/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 522/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.566243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884339 \n",
      "\n",
      "Epoch 523/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 523/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 523/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 523/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 523/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 523/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 523/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 523/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 523/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 523/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 523/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 523/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 523/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.568475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884746 \n",
      "\n",
      "Epoch 524/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 524/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 524/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 524/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 524/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 524/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 524/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 524/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 524/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 524/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 524/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 524/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 524/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.700613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.874758 \n",
      "\n",
      "Epoch 525/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 525/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 525/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 525/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 525/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 525/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 525/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 525/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 525/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 525/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 525/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 525/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 525/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001200, MRE: 1.586956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872281 \n",
      "\n",
      "Epoch 526/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 526/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 526/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 526/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 526/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 526/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 526/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 526/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 526/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 526/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 526/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 526/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 526/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001197, MRE: 1.570274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.860064 \n",
      "\n",
      "Epoch 527/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 527/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 527/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 527/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 527/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 527/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 527/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 527/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 527/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 527/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 527/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 527/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 527/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001194, MRE: 1.563379 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.849586 \n",
      "\n",
      "Epoch 528/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 528/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 528/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 528/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 528/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 528/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 528/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 528/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 528/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 528/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 528/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 528/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 528/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001197, MRE: 1.562168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001152, MRE: 2.863627 \n",
      "\n",
      "Epoch 529/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 529/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 529/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 529/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 529/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 529/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 529/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 529/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 529/800, Iteration 9/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 529/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 529/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 529/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001195, MRE: 1.800534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.868640 \n",
      "\n",
      "Epoch 530/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 530/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 530/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 530/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 530/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 530/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 530/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 530/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 530/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 530/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 530/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 530/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 530/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.564202 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.875600 \n",
      "\n",
      "Epoch 531/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 531/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 531/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 531/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 531/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 531/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 531/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 531/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 531/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 531/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 531/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 531/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 531/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.570739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.879220 \n",
      "\n",
      "Epoch 532/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 532/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 532/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 532/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 532/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 532/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 532/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 532/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 532/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 532/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001229, MRE: 1.869766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881066 \n",
      "\n",
      "Epoch 533/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 533/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 533/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 533/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 533/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 533/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 533/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 533/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 533/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 533/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 533/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 533/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 533/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.577949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889545 \n",
      "\n",
      "Epoch 534/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 534/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 534/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 534/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 534/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 534/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 534/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 534/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 534/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 534/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.578238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.880907 \n",
      "\n",
      "Epoch 535/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 535/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 535/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 535/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 535/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 535/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 535/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 535/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 535/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 535/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 535/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 535/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 535/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.579084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.883680 \n",
      "\n",
      "Epoch 536/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 536/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 536/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 536/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 536/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 536/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 536/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 536/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 536/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 536/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 536/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 536/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 536/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.560028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881578 \n",
      "\n",
      "Epoch 537/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 537/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 537/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 537/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 537/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 537/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 537/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 537/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 537/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 537/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.558887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.886918 \n",
      "\n",
      "Epoch 538/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 538/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 538/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 538/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 538/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 538/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 538/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 538/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 538/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 538/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 538/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 538/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 538/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.588873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.885156 \n",
      "\n",
      "Epoch 539/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 539/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 539/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 539/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 539/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 539/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 539/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 539/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001202, MRE: 1.575612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867999 \n",
      "\n",
      "Epoch 540/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 540/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 540/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 540/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 540/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 540/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 540/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 540/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 540/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 540/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 540/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.562856 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.865187 \n",
      "\n",
      "Epoch 541/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 541/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 541/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 541/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 541/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 541/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 541/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 541/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 541/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 541/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 541/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 541/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 541/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001205, MRE: 1.585616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.868906 \n",
      "\n",
      "Epoch 542/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 542/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 542/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 542/800, Iteration 4/12, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 542/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 542/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 542/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 542/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 542/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 542/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 542/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 542/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.560552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.873632 \n",
      "\n",
      "Epoch 543/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 543/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 543/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 543/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 543/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 543/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 543/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 543/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 543/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 543/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 543/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 543/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 543/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.587059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872809 \n",
      "\n",
      "Epoch 544/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 544/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 544/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 544/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 544/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 544/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 544/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 544/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 544/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 544/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 544/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 544/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 544/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.563335 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.873662 \n",
      "\n",
      "Epoch 545/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 545/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 545/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 545/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 545/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 545/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 545/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 545/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.561676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881487 \n",
      "\n",
      "Epoch 546/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 546/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 546/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 546/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 546/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 546/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 546/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 546/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 546/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 546/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 546/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 546/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 546/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.559654 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.880616 \n",
      "\n",
      "Epoch 547/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 547/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 547/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 547/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 547/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 547/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 547/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 547/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 547/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 547/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 547/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 547/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 547/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.561873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890550 \n",
      "\n",
      "Epoch 548/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 548/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 548/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 548/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 548/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 548/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 548/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 548/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 548/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 548/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 548/800, Iteration 11/12, Loss: 0.0022\n",
      "Epoch 548/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 548/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.589907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.877878 \n",
      "\n",
      "Epoch 549/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 549/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 549/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 549/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 549/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 549/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 549/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 549/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 549/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 549/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 549/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 549/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 549/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.567275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.874304 \n",
      "\n",
      "Epoch 550/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 550/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 550/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 550/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 550/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 550/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 550/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 550/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 550/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 550/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 550/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 550/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 550/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.561260 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.874303 \n",
      "\n",
      "Epoch 551/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 551/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 551/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 551/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 551/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 551/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 551/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 551/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 551/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 551/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 551/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 551/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 551/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.574149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.882399 \n",
      "\n",
      "Epoch 552/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 552/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 552/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 552/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 552/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 552/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 552/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 552/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 552/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 552/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 552/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 552/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 552/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.583589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.885926 \n",
      "\n",
      "Epoch 553/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 553/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 553/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 553/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 553/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 553/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 553/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 553/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 553/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 553/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 553/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 553/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 553/800, Iteration 13/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001193, MRE: 1.566642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.893425 \n",
      "\n",
      "Epoch 554/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 554/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 554/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 554/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 554/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 554/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 554/800, Iteration 10/12, Loss: 0.0008\n",
      "Epoch 554/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 554/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 554/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.579513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889187 \n",
      "\n",
      "Epoch 555/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 555/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 555/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 555/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 555/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 555/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 555/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 555/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 555/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 555/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 555/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 555/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 555/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001187, MRE: 1.556659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.896187 \n",
      "\n",
      "Epoch 556/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 556/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 556/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 556/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 556/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 556/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 556/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 556/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 556/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 556/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 556/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 556/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 556/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001209, MRE: 1.714646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.902694 \n",
      "\n",
      "Epoch 557/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 557/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 557/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 557/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 557/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 557/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 557/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 557/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001221, MRE: 1.588094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.901927 \n",
      "\n",
      "Epoch 558/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 558/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 558/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 558/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 558/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 558/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 558/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 558/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 558/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 558/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 558/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001211, MRE: 1.581817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001155, MRE: 2.900549 \n",
      "\n",
      "Epoch 559/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 559/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 559/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 559/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 559/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 559/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 559/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 559/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 559/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 559/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 559/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 559/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001194, MRE: 1.565053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.894467 \n",
      "\n",
      "Epoch 560/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 560/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 560/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 560/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 560/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 560/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 560/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 560/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 560/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 560/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 560/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 560/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 560/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001184, MRE: 1.557506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.889122 \n",
      "\n",
      "Epoch 561/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 561/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 561/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 561/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 561/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 561/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 561/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 561/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 561/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 561/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 561/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 561/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 561/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.746517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.879044 \n",
      "\n",
      "Epoch 562/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 562/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 562/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 562/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 562/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 562/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 562/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 562/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 562/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 562/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 562/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.554789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.875886 \n",
      "\n",
      "Epoch 563/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 563/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 563/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 563/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 563/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 563/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 563/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 563/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 563/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 563/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 563/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 563/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 563/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.580599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.872299 \n",
      "\n",
      "Epoch 564/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 564/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 564/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 564/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 564/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 564/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 564/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 564/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 564/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 564/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 564/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 564/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 564/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.584283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867777 \n",
      "\n",
      "Epoch 565/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 565/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 565/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 565/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 565/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 565/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 565/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 565/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 565/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 565/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 565/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 565/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 565/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.576557 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867813 \n",
      "\n",
      "Epoch 566/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 566/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 566/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 566/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 566/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 566/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 566/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 566/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 566/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 566/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 566/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 566/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 566/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.576673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881876 \n",
      "\n",
      "Epoch 567/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 567/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 567/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 567/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 567/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 567/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 567/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 567/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 567/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 567/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 567/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 567/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 567/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.569172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.884872 \n",
      "\n",
      "Epoch 568/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 568/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 568/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 568/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 568/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 568/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 568/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 568/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 568/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 568/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 568/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 568/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001206, MRE: 1.860960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.893042 \n",
      "\n",
      "Epoch 569/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 569/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 569/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 569/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 569/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 569/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 569/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 569/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 569/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 569/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 569/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 569/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 569/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001184, MRE: 1.557692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.885425 \n",
      "\n",
      "Epoch 570/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 570/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 570/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 570/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 570/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 570/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 570/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 570/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.559845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.884180 \n",
      "\n",
      "Epoch 571/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 571/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 571/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 571/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 571/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 571/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 571/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 571/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 571/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 571/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 571/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 571/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 571/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.567560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.891704 \n",
      "\n",
      "Epoch 572/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 572/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 572/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 572/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 572/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 572/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 572/800, Iteration 7/12, Loss: 0.0008\n",
      "Epoch 572/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 572/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 572/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 572/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 572/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 572/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001228, MRE: 1.594600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.896090 \n",
      "\n",
      "Epoch 573/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 573/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 573/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 573/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 573/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 573/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 573/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 573/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 573/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 573/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 573/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 573/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 573/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001195, MRE: 1.561379 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.891574 \n",
      "\n",
      "Epoch 574/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 574/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 574/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 574/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 574/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 574/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 574/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 574/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 574/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 574/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 574/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 574/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 574/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001215, MRE: 1.573101 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.880199 \n",
      "\n",
      "Epoch 575/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 575/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 575/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 575/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 575/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 575/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 575/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 575/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 575/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 575/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 575/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 575/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 575/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.585037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.865199 \n",
      "\n",
      "Epoch 576/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 576/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 576/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 576/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 576/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 576/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 576/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 576/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 576/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 576/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 576/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 576/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 576/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.564997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.874636 \n",
      "\n",
      "Epoch 577/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 577/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 577/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 577/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 577/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 577/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 577/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 577/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 577/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.590513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.873630 \n",
      "\n",
      "Epoch 578/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 578/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 578/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 578/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 578/800, Iteration 5/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 578/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 578/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 578/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 578/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 578/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 578/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 578/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.600863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.873807 \n",
      "\n",
      "Epoch 579/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 579/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 579/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 579/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 579/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 579/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 579/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 579/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 579/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 579/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 579/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 579/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 579/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001188, MRE: 1.560996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.886234 \n",
      "\n",
      "Epoch 580/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 580/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 580/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 580/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 580/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 580/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 580/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 580/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 580/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.581041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.883381 \n",
      "\n",
      "Epoch 581/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 581/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 581/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 581/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 581/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 581/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 581/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 581/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 581/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 581/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 581/800, Iteration 11/12, Loss: 0.0021\n",
      "Epoch 581/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 581/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.562248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881097 \n",
      "\n",
      "Epoch 582/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 582/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 582/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 582/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 582/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 582/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 582/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 582/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 582/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 582/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 582/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 582/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 582/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.856794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870140 \n",
      "\n",
      "Epoch 583/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 583/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 583/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 583/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 583/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 583/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 583/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 583/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 583/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 583/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 583/800, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 583/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 583/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.778316 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870101 \n",
      "\n",
      "Epoch 584/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 584/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 584/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 584/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 584/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 584/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 584/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 584/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 584/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 584/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 584/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 584/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 584/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.581035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.875637 \n",
      "\n",
      "Epoch 585/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 585/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 585/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 585/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 585/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 585/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 585/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 585/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 585/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.563370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.871541 \n",
      "\n",
      "Epoch 586/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 586/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 586/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 586/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 586/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 586/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 586/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 586/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 586/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 586/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 586/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 586/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 586/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.565664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.861976 \n",
      "\n",
      "Epoch 587/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 587/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 587/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 587/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 587/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 587/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 587/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 587/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 587/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 587/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 587/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 587/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 587/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001195, MRE: 1.565951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.866771 \n",
      "\n",
      "Epoch 588/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 588/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 588/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 588/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 588/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 588/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 588/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 588/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 588/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 588/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 588/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 588/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.570926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.862189 \n",
      "\n",
      "Epoch 589/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 589/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 589/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 589/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 589/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 589/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 589/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 589/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 589/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 589/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 589/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001191, MRE: 1.559596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.853743 \n",
      "\n",
      "Epoch 590/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 590/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 590/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 590/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 590/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 590/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 590/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 590/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 590/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 590/800, Iteration 10/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 590/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 590/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001187, MRE: 1.566556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.856681 \n",
      "\n",
      "Epoch 591/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 591/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 591/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 591/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 591/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 591/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 591/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 591/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 591/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 591/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001204, MRE: 1.627193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.854481 \n",
      "\n",
      "Epoch 592/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 592/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 592/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 592/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 592/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 592/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 592/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 592/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 592/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 592/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 592/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 592/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 592/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001197, MRE: 1.577377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.848659 \n",
      "\n",
      "Epoch 593/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 593/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 593/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 593/800, Iteration 4/12, Loss: 0.0021\n",
      "Epoch 593/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 593/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 593/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 593/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 593/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 593/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 593/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 593/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 593/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001210, MRE: 1.571118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.848931 \n",
      "\n",
      "Epoch 594/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 594/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 594/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 594/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 594/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 594/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 594/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 594/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 594/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 594/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 594/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 594/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 594/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001206, MRE: 1.910106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.857273 \n",
      "\n",
      "Epoch 595/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 595/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 595/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 595/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 595/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 595/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 595/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 595/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 595/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 595/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 595/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 595/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 595/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001197, MRE: 1.777626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.858837 \n",
      "\n",
      "Epoch 596/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 596/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 596/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 596/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 596/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 596/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 596/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 596/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 596/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 596/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001216, MRE: 1.573812 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870761 \n",
      "\n",
      "Epoch 597/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 597/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 597/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 597/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 597/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 597/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 597/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 597/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 597/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 597/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 597/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 597/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 597/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001205, MRE: 1.572863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.873854 \n",
      "\n",
      "Epoch 598/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 598/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 598/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 598/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 598/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 598/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 598/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 598/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 598/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 598/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 598/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 598/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 598/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.556282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867495 \n",
      "\n",
      "Epoch 599/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 599/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 599/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 599/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 599/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 599/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 599/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 599/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 599/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.599098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.860389 \n",
      "\n",
      "Epoch 600/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 600/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 600/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 600/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 600/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 600/800, Iteration 6/12, Loss: 0.0024\n",
      "Epoch 600/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 600/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 600/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 600/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 600/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 600/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 600/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001204, MRE: 1.593360 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.857892 \n",
      "\n",
      "Epoch 601/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 601/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 601/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 601/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 5/12, Loss: 0.0022\n",
      "Epoch 601/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 601/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 601/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 601/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 601/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 601/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 601/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001206, MRE: 1.559375 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.848656 \n",
      "\n",
      "Epoch 602/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 602/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 602/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 602/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 602/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 602/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 602/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 602/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 602/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 602/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 602/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 602/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 602/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.556245 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870232 \n",
      "\n",
      "Epoch 603/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 603/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 603/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 603/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 603/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 603/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 603/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 603/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 603/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 603/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 603/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 603/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 603/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.567636 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.868752 \n",
      "\n",
      "Epoch 604/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 604/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 604/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 604/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 604/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 604/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 604/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 604/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 604/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 604/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001219, MRE: 1.565564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.866587 \n",
      "\n",
      "Epoch 605/800, Iteration 1/12, Loss: 0.0023\n",
      "Epoch 605/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 605/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 605/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 605/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 605/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 605/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 605/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 605/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 605/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 605/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 605/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 605/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.604976 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.861442 \n",
      "\n",
      "Epoch 606/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 606/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 606/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 606/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 606/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 606/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 606/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 606/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 606/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.591546 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.865953 \n",
      "\n",
      "Epoch 607/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 607/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 607/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 607/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 607/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 607/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 607/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 607/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 607/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.574092 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864699 \n",
      "\n",
      "Epoch 608/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 608/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 608/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 608/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 608/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 608/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 608/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 608/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 608/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 608/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 608/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 608/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 608/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001180, MRE: 1.558148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.861362 \n",
      "\n",
      "Epoch 609/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 609/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 609/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 609/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 609/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 609/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 609/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 609/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 609/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 609/800, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 609/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 609/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 609/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001199, MRE: 1.558292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.855051 \n",
      "\n",
      "Epoch 610/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 610/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 610/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 610/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 610/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 610/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 610/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 610/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 610/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 610/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001204, MRE: 1.592443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.853649 \n",
      "\n",
      "Epoch 611/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 611/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 611/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 611/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 611/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 611/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 611/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 611/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 611/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 611/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 611/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 611/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001195, MRE: 1.583007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.850012 \n",
      "\n",
      "Epoch 612/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 612/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 612/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 612/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 612/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 612/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 612/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 612/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 612/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 612/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 612/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 612/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 612/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001191, MRE: 1.557355 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870647 \n",
      "\n",
      "Epoch 613/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 613/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 613/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 613/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 613/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 613/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 613/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 613/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 613/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 613/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 613/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.564603 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.869265 \n",
      "\n",
      "Epoch 614/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 614/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 614/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 614/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 614/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 614/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 614/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 614/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 614/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 614/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 614/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 614/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 614/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.596047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.867748 \n",
      "\n",
      "Epoch 615/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 615/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 615/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 615/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 615/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 615/800, Iteration 6/12, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 615/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 615/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 615/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 615/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 615/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 615/800, Iteration 13/12, Loss: 0.0006\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.574786 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.877819 \n",
      "\n",
      "Epoch 616/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 616/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 616/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 616/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 616/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 616/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 616/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 616/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 616/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.567065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.875310 \n",
      "\n",
      "Epoch 617/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 617/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 617/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 617/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 617/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 617/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 617/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 617/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 617/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 617/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 617/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 617/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 617/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.596815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.872959 \n",
      "\n",
      "Epoch 618/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 618/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 618/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 618/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 618/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 618/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 618/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 618/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 618/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 618/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.585694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.882901 \n",
      "\n",
      "Epoch 619/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 619/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 619/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 619/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 619/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 619/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 619/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 619/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 619/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 619/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 619/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 619/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 619/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.569815 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.877222 \n",
      "\n",
      "Epoch 620/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 620/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 620/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 620/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 620/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 620/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 620/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 620/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 620/800, Iteration 9/12, Loss: 0.0009\n",
      "Epoch 620/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 620/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 620/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 620/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001189, MRE: 1.556323 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.884856 \n",
      "\n",
      "Epoch 621/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 621/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 621/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 621/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 621/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 621/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 621/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 621/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 621/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 621/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 621/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 621/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 621/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001200, MRE: 1.559962 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.891686 \n",
      "\n",
      "Epoch 622/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 622/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 622/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 622/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 622/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 622/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 622/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 622/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 622/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.568607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.875075 \n",
      "\n",
      "Epoch 623/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 623/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 623/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 623/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 623/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 623/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 623/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 623/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 623/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 623/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 623/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 623/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 623/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.558746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.876933 \n",
      "\n",
      "Epoch 624/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 624/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 624/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 624/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 624/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 624/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 624/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 624/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 624/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 624/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 624/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 624/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 624/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001213, MRE: 1.576046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.880952 \n",
      "\n",
      "Epoch 625/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 625/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 625/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 625/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 625/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 625/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 625/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 625/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 625/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 625/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 625/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 625/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 625/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001216, MRE: 1.576354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.883755 \n",
      "\n",
      "Epoch 626/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 626/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 626/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 626/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 626/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 626/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 626/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 626/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 626/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 626/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 626/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 626/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 626/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.770371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881215 \n",
      "\n",
      "Epoch 627/800, Iteration 1/12, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 627/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 627/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 627/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 627/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 627/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 627/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 627/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 627/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 627/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.561067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881961 \n",
      "\n",
      "Epoch 628/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 628/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 628/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 628/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 628/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 628/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 628/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 628/800, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 628/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 628/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 628/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 628/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 628/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.571529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.874018 \n",
      "\n",
      "Epoch 629/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 629/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 629/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 629/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 629/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 629/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 629/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 629/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 629/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 629/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 629/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 629/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 629/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.696501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.861584 \n",
      "\n",
      "Epoch 630/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 630/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 630/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 630/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 630/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 630/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 630/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 630/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 630/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 630/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 630/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 630/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 630/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001214, MRE: 1.598319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.857670 \n",
      "\n",
      "Epoch 631/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 631/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 631/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 631/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 631/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 631/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 631/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 631/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 631/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 631/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 631/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 631/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 631/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001203, MRE: 1.553760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.850377 \n",
      "\n",
      "Epoch 632/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 632/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 632/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 632/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 632/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 632/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 632/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 632/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 632/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 632/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 632/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 632/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 632/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001194, MRE: 1.568754 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.854683 \n",
      "\n",
      "Epoch 633/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 633/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 633/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 633/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 633/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 633/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 633/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 633/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 633/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 633/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 633/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 633/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 633/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.565342 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.868620 \n",
      "\n",
      "Epoch 634/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 634/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 634/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 634/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 634/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 634/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 634/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 634/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 634/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 634/800, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 634/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 634/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 634/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001190, MRE: 1.562041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.884779 \n",
      "\n",
      "Epoch 635/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 635/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 635/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 635/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 635/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 635/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 635/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 635/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 635/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 635/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 635/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 635/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 635/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001193, MRE: 1.588614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.895071 \n",
      "\n",
      "Epoch 636/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 636/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 636/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 636/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 636/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 636/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 636/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 636/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 636/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 636/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 636/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 636/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 636/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001207, MRE: 1.557245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.888204 \n",
      "\n",
      "Epoch 637/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 637/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 637/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 637/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 637/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 637/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 637/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 637/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 637/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 637/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 637/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 637/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 637/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001188, MRE: 1.574012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.890712 \n",
      "\n",
      "Epoch 638/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 638/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 638/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 638/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 638/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 638/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 638/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 638/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 638/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 638/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 638/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 638/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 638/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001190, MRE: 1.580397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.894748 \n",
      "\n",
      "Epoch 639/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 639/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 639/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 639/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 639/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 639/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 639/800, Iteration 9/12, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/800, Iteration 10/12, Loss: 0.0020\n",
      "Epoch 639/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 639/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 639/800, Iteration 13/12, Loss: 0.0023\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001189, MRE: 1.576850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001155, MRE: 2.905182 \n",
      "\n",
      "Epoch 640/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 640/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 640/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 640/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 640/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 640/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 640/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 640/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 640/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 640/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 640/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 640/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 640/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001191, MRE: 1.564420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001155, MRE: 2.902027 \n",
      "\n",
      "Epoch 641/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 641/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 641/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 641/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 641/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 641/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 641/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 641/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 641/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 641/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 641/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 641/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 641/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001213, MRE: 1.570460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001154, MRE: 2.891531 \n",
      "\n",
      "Epoch 642/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 642/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 642/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 642/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 642/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 642/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 642/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 642/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 642/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 642/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 642/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 642/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 642/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001211, MRE: 1.558187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.885689 \n",
      "\n",
      "Epoch 643/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 643/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 643/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 643/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 643/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 643/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 643/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 643/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 643/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 643/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 643/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 643/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 643/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001196, MRE: 1.565308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.881462 \n",
      "\n",
      "Epoch 644/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 644/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 644/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 644/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 644/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 644/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 644/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 644/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 644/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 644/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001205, MRE: 1.618524 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.887300 \n",
      "\n",
      "Epoch 645/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 645/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 645/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 645/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 645/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 645/800, Iteration 6/12, Loss: 0.0022\n",
      "Epoch 645/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 645/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 645/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 645/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 645/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 645/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 645/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.565035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.874590 \n",
      "\n",
      "Epoch 646/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 646/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 646/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 646/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 646/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 646/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 646/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 646/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 646/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 646/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 646/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 646/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 646/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.623014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.863996 \n",
      "\n",
      "Epoch 647/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 647/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 647/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 647/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 647/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 647/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 647/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 647/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 647/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 647/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 647/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 647/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.616574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.872172 \n",
      "\n",
      "Epoch 648/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 648/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 648/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 648/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 648/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 648/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 648/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 648/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 648/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 648/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 648/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 648/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 648/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.555965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.861260 \n",
      "\n",
      "Epoch 649/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 649/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 649/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 649/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 649/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 649/800, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 649/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 649/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 649/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 649/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 649/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 649/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 649/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.566197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864276 \n",
      "\n",
      "Epoch 650/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 650/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 650/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 650/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 650/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 650/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 650/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 650/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 650/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 650/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 650/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 650/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 650/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.573113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.870913 \n",
      "\n",
      "Epoch 651/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 651/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 651/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 651/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 651/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 651/800, Iteration 6/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 651/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 651/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 651/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 651/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 651/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 651/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001185, MRE: 1.608524 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.875687 \n",
      "\n",
      "Epoch 652/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 652/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 652/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 652/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 652/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 652/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 652/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 652/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 652/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 652/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 652/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.563190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.867106 \n",
      "\n",
      "Epoch 653/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 653/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 653/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 653/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 653/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 653/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 653/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 653/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 653/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 653/800, Iteration 13/12, Loss: 0.0024\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.570793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.856966 \n",
      "\n",
      "Epoch 654/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 654/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 654/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 654/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 654/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 654/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 654/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 654/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 654/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 654/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 654/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 654/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 654/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.573226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.858947 \n",
      "\n",
      "Epoch 655/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 655/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 655/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 655/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 655/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 655/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 655/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 655/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 655/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 655/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 655/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 655/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 655/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001184, MRE: 1.564615 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.869504 \n",
      "\n",
      "Epoch 656/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 656/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 656/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 656/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 656/800, Iteration 5/12, Loss: 0.0020\n",
      "Epoch 656/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 656/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 656/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 656/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 656/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 656/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 656/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 656/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.556370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.878688 \n",
      "\n",
      "Epoch 657/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 657/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 657/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 657/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 657/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 657/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 657/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 657/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 657/800, Iteration 9/12, Loss: 0.0027\n",
      "Epoch 657/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 657/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 657/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 657/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001189, MRE: 1.694970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.879881 \n",
      "\n",
      "Epoch 658/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 658/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 658/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 658/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 658/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 658/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 658/800, Iteration 7/12, Loss: 0.0021\n",
      "Epoch 658/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 658/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 658/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 658/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 658/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.570745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.868831 \n",
      "\n",
      "Epoch 659/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 659/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 659/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 659/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 659/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 659/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 659/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 659/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 659/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 659/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 659/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 659/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 659/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.566844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.867517 \n",
      "\n",
      "Epoch 660/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 660/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 660/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 660/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 660/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 660/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 660/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 660/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 660/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 660/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 660/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 660/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 660/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.590337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.869413 \n",
      "\n",
      "Epoch 661/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 661/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 661/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 661/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 661/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 661/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 661/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 661/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 661/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 661/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 661/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 661/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 661/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.581703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.859217 \n",
      "\n",
      "Epoch 662/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 662/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 662/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 662/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 662/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 662/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 662/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 662/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 662/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 662/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 662/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 662/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 662/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001180, MRE: 1.571165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.852137 \n",
      "\n",
      "Epoch 663/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 663/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 663/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 663/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 663/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 663/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 663/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 663/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 663/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 663/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 663/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 663/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 663/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001205, MRE: 1.568692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.846825 \n",
      "\n",
      "Epoch 664/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 664/800, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 664/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 664/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 664/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 664/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 664/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 664/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 664/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 664/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 664/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001187, MRE: 1.581476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.837803 \n",
      "\n",
      "Epoch 665/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 665/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 665/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 665/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 665/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 665/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 665/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 665/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 665/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 665/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 665/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 665/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 665/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001189, MRE: 1.561705 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.846536 \n",
      "\n",
      "Epoch 666/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 666/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 666/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 666/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 666/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 666/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 666/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 666/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 666/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 666/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001196, MRE: 1.560618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.849630 \n",
      "\n",
      "Epoch 667/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 667/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 667/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 667/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 667/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 667/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 667/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.582577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.853973 \n",
      "\n",
      "Epoch 668/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 668/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 668/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 668/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 668/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 668/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 668/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 668/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 668/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 668/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 668/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.579124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.859675 \n",
      "\n",
      "Epoch 669/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 669/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 669/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 669/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 669/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 669/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 669/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 669/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 669/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.570442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.859566 \n",
      "\n",
      "Epoch 670/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 670/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 670/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 670/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 670/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 670/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 670/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 670/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 670/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 670/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.561595 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.860700 \n",
      "\n",
      "Epoch 671/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 671/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 671/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 671/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 671/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 671/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 671/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 671/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 671/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 671/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 671/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 671/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 671/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.559217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.856858 \n",
      "\n",
      "Epoch 672/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 672/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 672/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 672/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 672/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 672/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 672/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 672/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 672/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 672/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 672/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 672/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 672/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.63%, Avg loss: 0.001195, MRE: 2.000379 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.841858 \n",
      "\n",
      "Epoch 673/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 673/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 673/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 673/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 673/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 673/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 673/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 673/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 673/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 673/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.560097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.855843 \n",
      "\n",
      "Epoch 674/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 674/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 674/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 674/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 674/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 674/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 674/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 674/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 674/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 674/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 674/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 674/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 674/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.580910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001151, MRE: 2.857330 \n",
      "\n",
      "Epoch 675/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 675/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 675/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 675/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 675/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 675/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 675/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 675/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 675/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 675/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 675/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 675/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 675/800, Iteration 13/12, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.556289 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864891 \n",
      "\n",
      "Epoch 676/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 676/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 676/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 676/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 676/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 676/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 676/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 676/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 676/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 676/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 676/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 676/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 676/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001183, MRE: 1.573164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.854567 \n",
      "\n",
      "Epoch 677/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 677/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 677/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 677/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 677/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 677/800, Iteration 8/12, Loss: 0.0009\n",
      "Epoch 677/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 677/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 677/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 677/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001223, MRE: 1.566768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.855584 \n",
      "\n",
      "Epoch 678/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 678/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 678/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 678/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 678/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 678/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 678/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 678/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 678/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 678/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 678/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.564698 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.868034 \n",
      "\n",
      "Epoch 679/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 679/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 679/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 679/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 679/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 679/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 679/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 679/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 679/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 679/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 679/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001205, MRE: 1.585450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.882468 \n",
      "\n",
      "Epoch 680/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 680/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 680/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 680/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 680/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 680/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 680/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 680/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 680/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 680/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 680/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 680/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 680/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001209, MRE: 1.585055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.887365 \n",
      "\n",
      "Epoch 681/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 681/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 681/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 681/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 681/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 681/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 681/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 681/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 681/800, Iteration 13/12, Loss: 0.0025\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.570231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.885574 \n",
      "\n",
      "Epoch 682/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 682/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 682/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 682/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 682/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 682/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 682/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 682/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 682/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 682/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 682/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 682/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 682/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001188, MRE: 1.703403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.892704 \n",
      "\n",
      "Epoch 683/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 683/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 683/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 683/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 683/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 683/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 683/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 683/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 683/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 683/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 683/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001199, MRE: 1.568828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.892438 \n",
      "\n",
      "Epoch 684/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 684/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 684/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 684/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 684/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 684/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 684/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 684/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 684/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 684/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 684/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 684/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 684/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001190, MRE: 1.554886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001153, MRE: 2.885484 \n",
      "\n",
      "Epoch 685/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 685/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 685/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 685/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 685/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 685/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 685/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 685/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 685/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 685/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 685/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 685/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 685/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001203, MRE: 1.864327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.892022 \n",
      "\n",
      "Epoch 686/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 686/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 686/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 686/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 686/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 686/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 686/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 686/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 686/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 686/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 686/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 686/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 686/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.874810 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.880345 \n",
      "\n",
      "Epoch 687/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 687/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 687/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 687/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 687/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 687/800, Iteration 9/12, Loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 687/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 687/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 687/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.592924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.872971 \n",
      "\n",
      "Epoch 688/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 688/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 688/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 688/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 688/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 688/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 688/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 688/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 688/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 688/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 688/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 688/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 688/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001211, MRE: 1.565123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.859916 \n",
      "\n",
      "Epoch 689/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 689/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 689/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 689/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 689/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 689/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 689/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 689/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 689/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 689/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 689/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 689/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 689/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.574423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.852875 \n",
      "\n",
      "Epoch 690/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 690/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 690/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 690/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 690/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 690/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 690/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 690/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 690/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 690/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 690/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 690/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 690/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001209, MRE: 1.559804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.845098 \n",
      "\n",
      "Epoch 691/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 691/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 691/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 691/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 691/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 691/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 691/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 691/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 691/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 691/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 691/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 691/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 691/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001204, MRE: 1.551955 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.850179 \n",
      "\n",
      "Epoch 692/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 692/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 692/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 692/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 692/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 692/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 692/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 692/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 692/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 692/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 692/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001205, MRE: 1.568095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.845216 \n",
      "\n",
      "Epoch 693/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 693/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 693/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 693/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 693/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 693/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 693/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 693/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 693/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 693/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 693/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 693/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 693/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001216, MRE: 1.878053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.843725 \n",
      "\n",
      "Epoch 694/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 694/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 694/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 694/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 694/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 694/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 694/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 694/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 694/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 694/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001204, MRE: 1.917059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864682 \n",
      "\n",
      "Epoch 695/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 695/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 695/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 695/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 695/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 695/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 695/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 695/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 695/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 695/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 695/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 695/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 695/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.749749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866441 \n",
      "\n",
      "Epoch 696/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 696/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 696/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 696/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 696/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 696/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 696/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 696/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 696/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 696/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 696/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 696/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.584001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.860506 \n",
      "\n",
      "Epoch 697/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 697/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 697/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 697/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 697/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 697/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 697/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 697/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 697/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 697/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 697/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 697/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 697/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.561251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.870269 \n",
      "\n",
      "Epoch 698/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 698/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 698/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 698/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 698/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 698/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 698/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 698/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 698/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 698/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001190, MRE: 1.558345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.873810 \n",
      "\n",
      "Epoch 699/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 699/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 699/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 699/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 699/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 699/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 699/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 699/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 699/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 699/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 699/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 699/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 699/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001187, MRE: 1.576589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.877486 \n",
      "\n",
      "Epoch 700/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 700/800, Iteration 2/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 700/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 700/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 700/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 700/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 700/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 700/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 700/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 700/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 700/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 700/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001206, MRE: 1.576035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.887597 \n",
      "\n",
      "Epoch 701/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 701/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 701/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 701/800, Iteration 4/12, Loss: 0.0024\n",
      "Epoch 701/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 701/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 701/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 701/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 701/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 701/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 701/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 701/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 701/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001195, MRE: 1.868419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.893585 \n",
      "\n",
      "Epoch 702/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 702/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 702/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 702/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 702/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 702/800, Iteration 6/12, Loss: 0.0009\n",
      "Epoch 702/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 702/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 702/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 702/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 702/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 702/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 702/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001191, MRE: 1.566403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.893187 \n",
      "\n",
      "Epoch 703/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 703/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 703/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 703/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 703/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 703/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 703/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 703/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 703/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 703/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 703/800, Iteration 11/12, Loss: 0.0008\n",
      "Epoch 703/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 703/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001209, MRE: 1.573025 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.890431 \n",
      "\n",
      "Epoch 704/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 704/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 704/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 704/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 704/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 704/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 704/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 704/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 704/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 704/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 704/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 704/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 704/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001194, MRE: 1.570687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001154, MRE: 2.896227 \n",
      "\n",
      "Epoch 705/800, Iteration 1/12, Loss: 0.0021\n",
      "Epoch 705/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 705/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 705/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 705/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 705/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 705/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 705/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 705/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 705/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 705/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 705/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 705/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001199, MRE: 1.570122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.881427 \n",
      "\n",
      "Epoch 706/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 706/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 706/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 706/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 706/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 706/800, Iteration 6/12, Loss: 0.0020\n",
      "Epoch 706/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 706/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 706/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 706/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 706/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 706/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 706/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001195, MRE: 1.637943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.882054 \n",
      "\n",
      "Epoch 707/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 707/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 707/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 707/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 707/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 707/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 707/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 707/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 707/800, Iteration 13/12, Loss: 0.0008\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001200, MRE: 1.579926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.876718 \n",
      "\n",
      "Epoch 708/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 708/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 708/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 708/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 708/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 708/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 708/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 708/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 708/800, Iteration 9/12, Loss: 0.0020\n",
      "Epoch 708/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 708/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 708/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 708/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001215, MRE: 1.565904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.871339 \n",
      "\n",
      "Epoch 709/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 709/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 709/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 709/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 709/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 709/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 709/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 709/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 709/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 709/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 709/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 709/800, Iteration 12/12, Loss: 0.0009\n",
      "Epoch 709/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001194, MRE: 1.558269 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.872216 \n",
      "\n",
      "Epoch 710/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 710/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 710/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 710/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 710/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 710/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 710/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 710/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 710/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 710/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 710/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 710/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 710/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001208, MRE: 1.561393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864790 \n",
      "\n",
      "Epoch 711/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 711/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 711/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 711/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 711/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 711/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 711/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 711/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 711/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 711/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 711/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 711/800, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 711/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001206, MRE: 1.561300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.868807 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 712/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 712/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 712/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 712/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 712/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 712/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 712/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 712/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 712/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 712/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 712/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 712/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001181, MRE: 1.581681 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.864010 \n",
      "\n",
      "Epoch 713/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 713/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 713/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 713/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 713/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 713/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 713/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 713/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 713/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 713/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 713/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 713/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 713/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001191, MRE: 1.558339 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.869465 \n",
      "\n",
      "Epoch 714/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 714/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 714/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 714/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 714/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 714/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 714/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 714/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 714/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 714/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 714/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 714/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 714/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.585194 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.858288 \n",
      "\n",
      "Epoch 715/800, Iteration 1/12, Loss: 0.0009\n",
      "Epoch 715/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 715/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 715/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 715/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 715/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 715/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 715/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 715/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 715/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 715/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 715/800, Iteration 13/12, Loss: 0.0022\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001212, MRE: 1.782086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866435 \n",
      "\n",
      "Epoch 716/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 716/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 716/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 716/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 716/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 716/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 716/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 716/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 716/800, Iteration 12/12, Loss: 0.0019\n",
      "Epoch 716/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.622034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.863221 \n",
      "\n",
      "Epoch 717/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 717/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 717/800, Iteration 3/12, Loss: 0.0021\n",
      "Epoch 717/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 717/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 717/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 717/800, Iteration 7/12, Loss: 0.0020\n",
      "Epoch 717/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 717/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 717/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 717/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 717/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 717/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001189, MRE: 1.560687 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.863784 \n",
      "\n",
      "Epoch 718/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 718/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 718/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 718/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 718/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 718/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 718/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 718/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 718/800, Iteration 9/12, Loss: 0.0022\n",
      "Epoch 718/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 718/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 718/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 718/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001217, MRE: 1.560174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.857179 \n",
      "\n",
      "Epoch 719/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 719/800, Iteration 2/12, Loss: 0.0010\n",
      "Epoch 719/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 719/800, Iteration 4/12, Loss: 0.0023\n",
      "Epoch 719/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 719/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 719/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 719/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 719/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 719/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 719/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 719/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 719/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001203, MRE: 1.566147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.868698 \n",
      "\n",
      "Epoch 720/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 720/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 720/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 720/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 720/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 720/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 720/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 720/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 720/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 720/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 720/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 720/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 720/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001185, MRE: 1.555816 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.863895 \n",
      "\n",
      "Epoch 721/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 721/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 721/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 721/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 721/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 721/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 721/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 721/800, Iteration 8/12, Loss: 0.0008\n",
      "Epoch 721/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 721/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 721/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 721/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 721/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001193, MRE: 1.580977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.868307 \n",
      "\n",
      "Epoch 722/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 722/800, Iteration 2/12, Loss: 0.0021\n",
      "Epoch 722/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 722/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 722/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 722/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 722/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 722/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 722/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 722/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 722/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 722/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 722/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001193, MRE: 1.560991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.874802 \n",
      "\n",
      "Epoch 723/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 723/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 723/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 723/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 723/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 723/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 723/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 723/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 723/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 723/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 723/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.571024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.881790 \n",
      "\n",
      "Epoch 724/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 724/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 724/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 724/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 724/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 724/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 724/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 724/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 10/12, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/800, Iteration 11/12, Loss: 0.0020\n",
      "Epoch 724/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 724/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001199, MRE: 1.559469 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.893132 \n",
      "\n",
      "Epoch 725/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 725/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 725/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 725/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 725/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 725/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 725/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 725/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 725/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 725/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 725/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001201, MRE: 1.783359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.887586 \n",
      "\n",
      "Epoch 726/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 726/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 726/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 726/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 726/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 726/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 726/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 726/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 726/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 726/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 726/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 726/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001192, MRE: 1.705552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.889760 \n",
      "\n",
      "Epoch 727/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 727/800, Iteration 2/12, Loss: 0.0008\n",
      "Epoch 727/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 727/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 727/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 727/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 727/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 727/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 727/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 727/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 727/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 727/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 727/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001208, MRE: 1.566450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001152, MRE: 2.884292 \n",
      "\n",
      "Epoch 728/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 728/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 728/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 728/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 728/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 728/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 728/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 728/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 728/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001193, MRE: 1.627523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.893371 \n",
      "\n",
      "Epoch 729/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 729/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 729/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 729/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 729/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 729/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 729/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 729/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 729/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 729/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 729/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 729/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 729/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001192, MRE: 1.612306 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001154, MRE: 2.898686 \n",
      "\n",
      "Epoch 730/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 730/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 730/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 730/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 730/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 730/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 730/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 730/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 730/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 730/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001207, MRE: 1.551713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001154, MRE: 2.901811 \n",
      "\n",
      "Epoch 731/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 731/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 731/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 731/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 731/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 731/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 731/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 731/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 731/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 731/800, Iteration 10/12, Loss: 0.0019\n",
      "Epoch 731/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 731/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 731/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001203, MRE: 1.567794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001154, MRE: 2.902070 \n",
      "\n",
      "Epoch 732/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 732/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 732/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 732/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 732/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 732/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 732/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 732/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 732/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 732/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 732/800, Iteration 11/12, Loss: 0.0009\n",
      "Epoch 732/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 732/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001198, MRE: 1.885245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.895664 \n",
      "\n",
      "Epoch 733/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 733/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 733/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 733/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 733/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 733/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 733/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 733/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 733/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 733/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001212, MRE: 1.561365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001153, MRE: 2.888287 \n",
      "\n",
      "Epoch 734/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 734/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 734/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 734/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 734/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 734/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 734/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 734/800, Iteration 10/12, Loss: 0.0021\n",
      "Epoch 734/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 734/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 734/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001197, MRE: 1.566639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.880706 \n",
      "\n",
      "Epoch 735/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 735/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 735/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 735/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 735/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 735/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 735/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 735/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 735/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 735/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001183, MRE: 1.599884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001152, MRE: 2.876645 \n",
      "\n",
      "Epoch 736/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 736/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 736/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 736/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 736/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 736/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 736/800, Iteration 7/12, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 736/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 736/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 736/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 736/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 736/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 736/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001198, MRE: 1.573186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.867014 \n",
      "\n",
      "Epoch 737/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 737/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 737/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 737/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 737/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 737/800, Iteration 6/12, Loss: 0.0008\n",
      "Epoch 737/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 737/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 737/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 737/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 737/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 737/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 737/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001206, MRE: 1.580415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.873892 \n",
      "\n",
      "Epoch 738/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 738/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 738/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 738/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 738/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 738/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 738/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 738/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 9/12, Loss: 0.0019\n",
      "Epoch 738/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 738/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 738/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.563204 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.872345 \n",
      "\n",
      "Epoch 739/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 739/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 739/800, Iteration 3/12, Loss: 0.0009\n",
      "Epoch 739/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 739/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 739/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 739/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 739/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 739/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 739/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 739/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 739/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 739/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001206, MRE: 1.578604 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866645 \n",
      "\n",
      "Epoch 740/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 740/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 740/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 740/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 740/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 740/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 740/800, Iteration 7/12, Loss: 0.0010\n",
      "Epoch 740/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 740/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 740/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 740/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 740/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 740/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.557900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.859281 \n",
      "\n",
      "Epoch 741/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 741/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 741/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 741/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 741/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 741/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 741/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 741/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 741/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 741/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 741/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 741/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 741/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001222, MRE: 1.566357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.858714 \n",
      "\n",
      "Epoch 742/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 742/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 742/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 742/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 742/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 742/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 742/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 742/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 742/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 742/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.637708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.851920 \n",
      "\n",
      "Epoch 743/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 743/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 743/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 743/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 743/800, Iteration 6/12, Loss: 0.0010\n",
      "Epoch 743/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 743/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 743/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 743/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 743/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 743/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 743/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001189, MRE: 1.570019 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.843224 \n",
      "\n",
      "Epoch 744/800, Iteration 1/12, Loss: 0.0019\n",
      "Epoch 744/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 744/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 744/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 744/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 744/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 744/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 744/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 744/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 744/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 744/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 744/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 744/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001186, MRE: 1.557439 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.840165 \n",
      "\n",
      "Epoch 745/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 745/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 745/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 745/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 745/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 745/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 745/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 745/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 745/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 745/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 745/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 745/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 745/800, Iteration 13/12, Loss: 0.0007\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001201, MRE: 1.567323 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001148, MRE: 2.836516 \n",
      "\n",
      "Epoch 746/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 746/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 746/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 746/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 746/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 746/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 746/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 746/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 746/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 746/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 746/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 746/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 746/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001195, MRE: 1.571451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.839856 \n",
      "\n",
      "Epoch 747/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 747/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 747/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 747/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 747/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 747/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 747/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 747/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 747/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 747/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 747/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001224, MRE: 1.571456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.840912 \n",
      "\n",
      "Epoch 748/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 748/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 748/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 748/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 748/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 748/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 748/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 748/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 748/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 748/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 748/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 748/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 748/800, Iteration 13/12, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.551544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.849206 \n",
      "\n",
      "Epoch 749/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 749/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 749/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 749/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 749/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 749/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 749/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 749/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 749/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 749/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001197, MRE: 1.553594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.848007 \n",
      "\n",
      "Epoch 750/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 750/800, Iteration 2/12, Loss: 0.0009\n",
      "Epoch 750/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 750/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 750/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 750/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 750/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 750/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 750/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 750/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 750/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 750/800, Iteration 12/12, Loss: 0.0021\n",
      "Epoch 750/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.575057 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.851685 \n",
      "\n",
      "Epoch 751/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 751/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 751/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 751/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 751/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 751/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 751/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 751/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 751/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 751/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 751/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 751/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 751/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001192, MRE: 1.557201 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001150, MRE: 2.851651 \n",
      "\n",
      "Epoch 752/800, Iteration 1/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 752/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 752/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 752/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 752/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 752/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 752/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 752/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 752/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 752/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 752/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 752/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001196, MRE: 1.559814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.846864 \n",
      "\n",
      "Epoch 753/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 753/800, Iteration 2/12, Loss: 0.0020\n",
      "Epoch 753/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 753/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 753/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 753/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 753/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 753/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 753/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 753/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 753/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 753/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 753/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.001220, MRE: 1.886938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.843226 \n",
      "\n",
      "Epoch 754/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 754/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 754/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 754/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 754/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 754/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 754/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 754/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 754/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 754/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 754/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 754/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001209, MRE: 1.587357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.846899 \n",
      "\n",
      "Epoch 755/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 755/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 755/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 755/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 755/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 755/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 755/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 755/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 755/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 755/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001181, MRE: 1.559273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.856969 \n",
      "\n",
      "Epoch 756/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 756/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 756/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 756/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 756/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 756/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 756/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 756/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 756/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 756/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 756/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 756/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 756/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001201, MRE: 1.555731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.858937 \n",
      "\n",
      "Epoch 757/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 757/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 757/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 757/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 757/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 757/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 757/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 757/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 757/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 757/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 757/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 757/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 757/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001190, MRE: 1.559577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866593 \n",
      "\n",
      "Epoch 758/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 758/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 758/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 758/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 758/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 758/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 758/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 758/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 758/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 758/800, Iteration 10/12, Loss: 0.0009\n",
      "Epoch 758/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 758/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 758/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001193, MRE: 1.552703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.872854 \n",
      "\n",
      "Epoch 759/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 759/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 759/800, Iteration 3/12, Loss: 0.0020\n",
      "Epoch 759/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 759/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 759/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 759/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 759/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 759/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 759/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 759/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 759/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 759/800, Iteration 13/12, Loss: 0.0009\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001178, MRE: 1.571855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001152, MRE: 2.882008 \n",
      "\n",
      "Epoch 760/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 760/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 760/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 760/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 760/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 760/800, Iteration 6/12, Loss: 0.0017\n",
      "Epoch 760/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 760/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 760/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 760/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 760/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 760/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 760/800, Iteration 13/12, Loss: 0.0008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001209, MRE: 1.563021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866634 \n",
      "\n",
      "Epoch 761/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 761/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 761/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 761/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 761/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 761/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 761/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 761/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 761/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 761/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 761/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001198, MRE: 1.562243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.866088 \n",
      "\n",
      "Epoch 762/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 762/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 762/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 762/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 762/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 762/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 762/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 762/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 762/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 762/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 762/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 762/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001199, MRE: 1.771418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.864313 \n",
      "\n",
      "Epoch 763/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 763/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 763/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 763/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 763/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 763/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 763/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 763/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 763/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 763/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 763/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 763/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 763/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001202, MRE: 1.573066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.861038 \n",
      "\n",
      "Epoch 764/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 764/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 764/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 764/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 764/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 764/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 764/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 764/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 764/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 764/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 764/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001182, MRE: 1.575060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.861573 \n",
      "\n",
      "Epoch 765/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 765/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 765/800, Iteration 4/12, Loss: 0.0020\n",
      "Epoch 765/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 765/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 765/800, Iteration 7/12, Loss: 0.0009\n",
      "Epoch 765/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 765/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 765/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 765/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 765/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001178, MRE: 1.561750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.851356 \n",
      "\n",
      "Epoch 766/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 766/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 766/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 766/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 766/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 766/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 766/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 766/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 766/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 766/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.38%, Avg loss: 0.001185, MRE: 1.563420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.845189 \n",
      "\n",
      "Epoch 767/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 767/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 767/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 767/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 767/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 767/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 767/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 767/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 767/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 767/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 767/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 767/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 767/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.573728 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.855976 \n",
      "\n",
      "Epoch 768/800, Iteration 1/12, Loss: 0.0020\n",
      "Epoch 768/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 768/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 768/800, Iteration 5/12, Loss: 0.0009\n",
      "Epoch 768/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 768/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 768/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 768/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 768/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 768/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 768/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001210, MRE: 1.590033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.857279 \n",
      "\n",
      "Epoch 769/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 769/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 769/800, Iteration 3/12, Loss: 0.0011\n",
      "Epoch 769/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 769/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 769/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 769/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 769/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 769/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 769/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 769/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 769/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 769/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001194, MRE: 1.571005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.851349 \n",
      "\n",
      "Epoch 770/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 770/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 770/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 770/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 770/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 770/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 770/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 770/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 770/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 770/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 770/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 770/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 770/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001203, MRE: 1.610080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.852661 \n",
      "\n",
      "Epoch 771/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 771/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 771/800, Iteration 3/12, Loss: 0.0010\n",
      "Epoch 771/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 771/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 771/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 771/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 771/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 771/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 771/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 771/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 771/800, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 771/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001198, MRE: 1.578363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.862550 \n",
      "\n",
      "Epoch 772/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 772/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 772/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 772/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 772/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 772/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 772/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 772/800, Iteration 8/12, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 772/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 772/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 772/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 772/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001200, MRE: 1.555097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.856251 \n",
      "\n",
      "Epoch 773/800, Iteration 1/12, Loss: 0.0016\n",
      "Epoch 773/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 773/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 773/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 773/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 773/800, Iteration 6/12, Loss: 0.0012\n",
      "Epoch 773/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 773/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 773/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 773/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 773/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 773/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 773/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001199, MRE: 1.589267 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.859585 \n",
      "\n",
      "Epoch 774/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 774/800, Iteration 2/12, Loss: 0.0019\n",
      "Epoch 774/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 774/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 774/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 774/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 774/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 774/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 774/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 774/800, Iteration 13/12, Loss: 0.0016\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001182, MRE: 1.554902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.853199 \n",
      "\n",
      "Epoch 775/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 775/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 775/800, Iteration 3/12, Loss: 0.0019\n",
      "Epoch 775/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 775/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 775/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 775/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 775/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 775/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 775/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 775/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 775/800, Iteration 12/12, Loss: 0.0020\n",
      "Epoch 775/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001211, MRE: 1.761808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.870309 \n",
      "\n",
      "Epoch 776/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 776/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 776/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 776/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 776/800, Iteration 5/12, Loss: 0.0019\n",
      "Epoch 776/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 776/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 776/800, Iteration 8/12, Loss: 0.0017\n",
      "Epoch 776/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 776/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 776/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 776/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 776/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001178, MRE: 1.584923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.863693 \n",
      "\n",
      "Epoch 777/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 777/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 777/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 777/800, Iteration 4/12, Loss: 0.0019\n",
      "Epoch 777/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 777/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 777/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 777/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 777/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 777/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 777/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 777/800, Iteration 12/12, Loss: 0.0016\n",
      "Epoch 777/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001185, MRE: 1.552082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.874012 \n",
      "\n",
      "Epoch 778/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 778/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 778/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 778/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 778/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 778/800, Iteration 6/12, Loss: 0.0023\n",
      "Epoch 778/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 778/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 778/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 778/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 778/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 778/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 778/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001205, MRE: 1.564164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.873018 \n",
      "\n",
      "Epoch 779/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 779/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 779/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 779/800, Iteration 4/12, Loss: 0.0009\n",
      "Epoch 779/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 779/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 779/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 779/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 779/800, Iteration 9/12, Loss: 0.0018\n",
      "Epoch 779/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 779/800, Iteration 11/12, Loss: 0.0015\n",
      "Epoch 779/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 779/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001207, MRE: 1.573353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.875237 \n",
      "\n",
      "Epoch 780/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 780/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 780/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 780/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 780/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 780/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 780/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 780/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 780/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 780/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 780/800, Iteration 11/12, Loss: 0.0019\n",
      "Epoch 780/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 780/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001204, MRE: 1.567187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.875550 \n",
      "\n",
      "Epoch 781/800, Iteration 1/12, Loss: 0.0011\n",
      "Epoch 781/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 781/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 781/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 781/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 781/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 781/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 781/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 781/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 781/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 781/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 781/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 781/800, Iteration 13/12, Loss: 0.0015\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001189, MRE: 1.558160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.869993 \n",
      "\n",
      "Epoch 782/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 782/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 782/800, Iteration 3/12, Loss: 0.0015\n",
      "Epoch 782/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 782/800, Iteration 5/12, Loss: 0.0017\n",
      "Epoch 782/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 782/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 782/800, Iteration 8/12, Loss: 0.0010\n",
      "Epoch 782/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 782/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 782/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 782/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 782/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001201, MRE: 1.564819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.875933 \n",
      "\n",
      "Epoch 783/800, Iteration 1/12, Loss: 0.0010\n",
      "Epoch 783/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 783/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 783/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 783/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 783/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 783/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 783/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 783/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 783/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 783/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 783/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001211, MRE: 1.628467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001152, MRE: 2.879223 \n",
      "\n",
      "Epoch 784/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 784/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 784/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 784/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 784/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 784/800, Iteration 8/12, Loss: 0.0020\n",
      "Epoch 784/800, Iteration 9/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 10/12, Loss: 0.0010\n",
      "Epoch 784/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 784/800, Iteration 12/12, Loss: 0.0010\n",
      "Epoch 784/800, Iteration 13/12, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 57.88%, Avg loss: 0.001195, MRE: 1.581694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001152, MRE: 2.886020 \n",
      "\n",
      "Epoch 785/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 785/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 785/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 785/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 785/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 785/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 785/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 785/800, Iteration 8/12, Loss: 0.0012\n",
      "Epoch 785/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 785/800, Iteration 10/12, Loss: 0.0017\n",
      "Epoch 785/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 785/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 785/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001186, MRE: 1.557703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001152, MRE: 2.883707 \n",
      "\n",
      "Epoch 786/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 786/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 786/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 786/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 786/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 786/800, Iteration 6/12, Loss: 0.0019\n",
      "Epoch 786/800, Iteration 7/12, Loss: 0.0019\n",
      "Epoch 786/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 786/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 786/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 786/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 786/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 786/800, Iteration 13/12, Loss: 0.0017\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001201, MRE: 1.582371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001151, MRE: 2.877846 \n",
      "\n",
      "Epoch 787/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 787/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 787/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 787/800, Iteration 4/12, Loss: 0.0016\n",
      "Epoch 787/800, Iteration 5/12, Loss: 0.0018\n",
      "Epoch 787/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 787/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 787/800, Iteration 8/12, Loss: 0.0013\n",
      "Epoch 787/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 787/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 787/800, Iteration 11/12, Loss: 0.0012\n",
      "Epoch 787/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 787/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001185, MRE: 1.562449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.001151, MRE: 2.877302 \n",
      "\n",
      "Epoch 788/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 788/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 788/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 788/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 788/800, Iteration 5/12, Loss: 0.0011\n",
      "Epoch 788/800, Iteration 6/12, Loss: 0.0011\n",
      "Epoch 788/800, Iteration 7/12, Loss: 0.0012\n",
      "Epoch 788/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 788/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 788/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 788/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 788/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 788/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001208, MRE: 1.622087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.865793 \n",
      "\n",
      "Epoch 789/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 2/12, Loss: 0.0012\n",
      "Epoch 789/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 4/12, Loss: 0.0017\n",
      "Epoch 789/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 789/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 9/12, Loss: 0.0015\n",
      "Epoch 789/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 11/12, Loss: 0.0010\n",
      "Epoch 789/800, Iteration 12/12, Loss: 0.0014\n",
      "Epoch 789/800, Iteration 13/12, Loss: 0.0020\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001198, MRE: 1.558758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.865452 \n",
      "\n",
      "Epoch 790/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 790/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 790/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 790/800, Iteration 4/12, Loss: 0.0018\n",
      "Epoch 790/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 790/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 790/800, Iteration 7/12, Loss: 0.0017\n",
      "Epoch 790/800, Iteration 8/12, Loss: 0.0018\n",
      "Epoch 790/800, Iteration 9/12, Loss: 0.0012\n",
      "Epoch 790/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 790/800, Iteration 11/12, Loss: 0.0011\n",
      "Epoch 790/800, Iteration 12/12, Loss: 0.0008\n",
      "Epoch 790/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.001198, MRE: 1.566317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.875032 \n",
      "\n",
      "Epoch 791/800, Iteration 1/12, Loss: 0.0015\n",
      "Epoch 791/800, Iteration 2/12, Loss: 0.0017\n",
      "Epoch 791/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 791/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 791/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 791/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 791/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 791/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 791/800, Iteration 9/12, Loss: 0.0010\n",
      "Epoch 791/800, Iteration 10/12, Loss: 0.0011\n",
      "Epoch 791/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 791/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 791/800, Iteration 13/12, Loss: 0.0021\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001205, MRE: 1.565457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.869856 \n",
      "\n",
      "Epoch 792/800, Iteration 1/12, Loss: 0.0017\n",
      "Epoch 792/800, Iteration 2/12, Loss: 0.0013\n",
      "Epoch 792/800, Iteration 3/12, Loss: 0.0013\n",
      "Epoch 792/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 792/800, Iteration 5/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 792/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 792/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 792/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 792/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 792/800, Iteration 13/12, Loss: 0.0010\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001202, MRE: 1.567818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001151, MRE: 2.869567 \n",
      "\n",
      "Epoch 793/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 793/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 793/800, Iteration 3/12, Loss: 0.0017\n",
      "Epoch 793/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 793/800, Iteration 5/12, Loss: 0.0013\n",
      "Epoch 793/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 793/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 793/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 793/800, Iteration 9/12, Loss: 0.0011\n",
      "Epoch 793/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 793/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 793/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 793/800, Iteration 13/12, Loss: 0.0011\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001194, MRE: 1.589081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.866745 \n",
      "\n",
      "Epoch 794/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 794/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 794/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 794/800, Iteration 4/12, Loss: 0.0014\n",
      "Epoch 794/800, Iteration 5/12, Loss: 0.0016\n",
      "Epoch 794/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 794/800, Iteration 7/12, Loss: 0.0018\n",
      "Epoch 794/800, Iteration 8/12, Loss: 0.0016\n",
      "Epoch 794/800, Iteration 9/12, Loss: 0.0021\n",
      "Epoch 794/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 794/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 794/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 794/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001187, MRE: 1.606350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.856357 \n",
      "\n",
      "Epoch 795/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 795/800, Iteration 2/12, Loss: 0.0015\n",
      "Epoch 795/800, Iteration 3/12, Loss: 0.0012\n",
      "Epoch 795/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 795/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 795/800, Iteration 6/12, Loss: 0.0016\n",
      "Epoch 795/800, Iteration 7/12, Loss: 0.0013\n",
      "Epoch 795/800, Iteration 8/12, Loss: 0.0015\n",
      "Epoch 795/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 795/800, Iteration 10/12, Loss: 0.0016\n",
      "Epoch 795/800, Iteration 11/12, Loss: 0.0013\n",
      "Epoch 795/800, Iteration 12/12, Loss: 0.0017\n",
      "Epoch 795/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001190, MRE: 1.557626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.001149, MRE: 2.847369 \n",
      "\n",
      "Epoch 796/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 796/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 796/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 796/800, Iteration 4/12, Loss: 0.0011\n",
      "Epoch 796/800, Iteration 5/12, Loss: 0.0012\n",
      "Epoch 796/800, Iteration 6/12, Loss: 0.0013\n",
      "Epoch 796/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 796/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 796/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 796/800, Iteration 10/12, Loss: 0.0014\n",
      "Epoch 796/800, Iteration 11/12, Loss: 0.0017\n",
      "Epoch 796/800, Iteration 12/12, Loss: 0.0018\n",
      "Epoch 796/800, Iteration 13/12, Loss: 0.0018\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001191, MRE: 1.575232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.859912 \n",
      "\n",
      "Epoch 797/800, Iteration 1/12, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 797/800, Iteration 2/12, Loss: 0.0011\n",
      "Epoch 797/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 797/800, Iteration 4/12, Loss: 0.0010\n",
      "Epoch 797/800, Iteration 5/12, Loss: 0.0021\n",
      "Epoch 797/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 797/800, Iteration 7/12, Loss: 0.0015\n",
      "Epoch 797/800, Iteration 8/12, Loss: 0.0021\n",
      "Epoch 797/800, Iteration 9/12, Loss: 0.0013\n",
      "Epoch 797/800, Iteration 10/12, Loss: 0.0015\n",
      "Epoch 797/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 797/800, Iteration 12/12, Loss: 0.0011\n",
      "Epoch 797/800, Iteration 13/12, Loss: 0.0014\n",
      "Train Error: \n",
      " Accuracy: 58.25%, Avg loss: 0.001193, MRE: 1.812717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.856257 \n",
      "\n",
      "Epoch 798/800, Iteration 1/12, Loss: 0.0013\n",
      "Epoch 798/800, Iteration 2/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 3/12, Loss: 0.0018\n",
      "Epoch 798/800, Iteration 4/12, Loss: 0.0013\n",
      "Epoch 798/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 798/800, Iteration 6/12, Loss: 0.0014\n",
      "Epoch 798/800, Iteration 7/12, Loss: 0.0014\n",
      "Epoch 798/800, Iteration 8/12, Loss: 0.0019\n",
      "Epoch 798/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 10/12, Loss: 0.0013\n",
      "Epoch 798/800, Iteration 11/12, Loss: 0.0016\n",
      "Epoch 798/800, Iteration 12/12, Loss: 0.0013\n",
      "Epoch 798/800, Iteration 13/12, Loss: 0.0013\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001204, MRE: 1.553012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.860049 \n",
      "\n",
      "Epoch 799/800, Iteration 1/12, Loss: 0.0014\n",
      "Epoch 799/800, Iteration 2/12, Loss: 0.0014\n",
      "Epoch 799/800, Iteration 3/12, Loss: 0.0016\n",
      "Epoch 799/800, Iteration 4/12, Loss: 0.0015\n",
      "Epoch 799/800, Iteration 5/12, Loss: 0.0014\n",
      "Epoch 799/800, Iteration 6/12, Loss: 0.0018\n",
      "Epoch 799/800, Iteration 7/12, Loss: 0.0016\n",
      "Epoch 799/800, Iteration 8/12, Loss: 0.0011\n",
      "Epoch 799/800, Iteration 9/12, Loss: 0.0016\n",
      "Epoch 799/800, Iteration 10/12, Loss: 0.0012\n",
      "Epoch 799/800, Iteration 11/12, Loss: 0.0014\n",
      "Epoch 799/800, Iteration 12/12, Loss: 0.0015\n",
      "Epoch 799/800, Iteration 13/12, Loss: 0.0019\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001211, MRE: 1.565570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.866138 \n",
      "\n",
      "Epoch 800/800, Iteration 1/12, Loss: 0.0012\n",
      "Epoch 800/800, Iteration 2/12, Loss: 0.0018\n",
      "Epoch 800/800, Iteration 3/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 4/12, Loss: 0.0012\n",
      "Epoch 800/800, Iteration 5/12, Loss: 0.0010\n",
      "Epoch 800/800, Iteration 6/12, Loss: 0.0015\n",
      "Epoch 800/800, Iteration 7/12, Loss: 0.0011\n",
      "Epoch 800/800, Iteration 8/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 9/12, Loss: 0.0014\n",
      "Epoch 800/800, Iteration 10/12, Loss: 0.0018\n",
      "Epoch 800/800, Iteration 11/12, Loss: 0.0018\n",
      "Epoch 800/800, Iteration 12/12, Loss: 0.0012\n",
      "Epoch 800/800, Iteration 13/12, Loss: 0.0012\n",
      "Train Error: \n",
      " Accuracy: 58.13%, Avg loss: 0.001199, MRE: 1.551061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.001150, MRE: 2.863185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 800 #Iterationen über Datenset\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_MRE = []\n",
    "test_MRE = []\n",
    "\n",
    "#Optimierungsloop\n",
    "for epoch in range(num_epochs):\n",
    "#     train_correct = 0\n",
    "#     train_total = 0\n",
    "        \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(X.shape)\n",
    "#         print(X.dtype)\n",
    "        \n",
    "        net.train() #Trainingmodus\n",
    "        \n",
    "        # forward\n",
    "        pred = net(X)  # Do the forward pass\n",
    "        loss = loss_fn(pred, y) # Calculate the loss\n",
    "        #loss = MRELoss(pred, y)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # Clear off the gradients from any past operation\n",
    "        loss.backward()       # Calculate the gradients with help of back propagation, updating weights and biases\n",
    "        \n",
    "        # adam step gradient descent\n",
    "        optimizer.step()      # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "#         # Record the correct predictions for training data\n",
    "#         _, predictions = torch.max(pred.data, 1)\n",
    "#         train_correct += (predictions == y.data).sum()                \n",
    "#         train_total += predictions.size(0)    \n",
    "\n",
    "        print ('Epoch %d/%d, Iteration %d/%d, Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, batch+1, len(train_dataset)//batch_size, loss.item()))\n",
    "        \n",
    "    \n",
    "    scheduler.step() # Reduzieren Learning Rate (falls step size erreicht)\n",
    "    net.eval() # Put the network into evaluation mode\n",
    "    \n",
    "    # Book keeping\n",
    "    #train_loss.append(loss.item())\n",
    "    \n",
    "    # What was our train accuracy?\n",
    "    tr_acc, tr_loss, tr_MRE = check_accuracy(train_dataloader, net)\n",
    "    \n",
    "    #Record loss and accuracy\n",
    "    train_accuracy.append(tr_acc)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_MRE.append(tr_MRE)\n",
    "    \n",
    "    # How did we do on the test set (the unseen set)\n",
    "    # Record the correct predictions for test data\n",
    "    t_acc, t_loss, t_MRE = check_accuracy(test_dataloader, net)\n",
    "    test_accuracy.append(t_acc)\n",
    "    test_loss.append(t_loss)\n",
    "    test_MRE.append(t_MRE)\n",
    "\n",
    "#     loss = criterion(outputs, Variable(test_classes))\n",
    "#     test_loss.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fb4a",
   "metadata": {},
   "source": [
    "#### Plots loss vs Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728c1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.semilogy(train_loss, label='train loss')\n",
    "ax.semilogy(test_loss, label='test loss')\n",
    "plt.title(\"Train and Test Loss\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Loss$ / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5e5454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_MRE, label='train MRE')\n",
    "ax.plot(test_MRE, label='test MRE')\n",
    "plt.title(\"Mean Relative Error\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$MRE$ / 1') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98b5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "#fig.figsize=(12, 8)\n",
    "ax.plot(train_accuracy, label='train accuracy')\n",
    "ax.plot(test_accuracy, label='test accuracy')\n",
    "plt.title(\"Train and Test Accuracy\")\n",
    "ax.set(xlabel = '$Epochs$ / 1', ylabel = '$Accuracy$ / %') #Beschriftung Achsen; Kursiv durch $$; Index durch _{}\n",
    "ax.tick_params(direction = 'in') #, length = 20, width = 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545dcb8",
   "metadata": {},
   "source": [
    "#### Debugging Hilfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b9e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8895e+00, 1.9346e-01, 3.4035e-01, 3.2695e-01, 3.3270e-01],\n",
      "        [2.9121e+00, 2.4731e-01, 1.7561e-01, 3.0300e-01, 5.2139e-01],\n",
      "        [2.8431e+00, 1.1063e-01, 1.5887e-01, 5.4630e-01, 2.9483e-01],\n",
      "        [2.9196e+00, 1.9858e-01, 3.8903e-01, 9.7260e-02, 5.1371e-01],\n",
      "        [2.8190e+00, 1.7542e-01, 5.9980e-01, 3.2291e-01, 7.7288e-02],\n",
      "        [2.9194e+00, 1.4293e-01, 1.9493e-01, 4.7480e-01, 3.3027e-01],\n",
      "        [2.8234e+00, 1.3262e-01, 1.5324e-02, 4.5766e-02, 9.3891e-01],\n",
      "        [2.9298e+00, 1.3751e-01, 1.8770e-01, 2.0795e-01, 6.0435e-01],\n",
      "        [2.9120e+00, 1.2535e-01, 3.6349e-01, 4.0062e-01, 2.3589e-01],\n",
      "        [2.9125e+00, 1.4461e-01, 2.3334e-02, 4.6445e-01, 5.1221e-01],\n",
      "        [2.8855e+00, 2.4963e-01, 8.9502e-01, 1.7578e-03, 1.0322e-01],\n",
      "        [2.8475e+00, 1.4382e-01, 6.7222e-01, 8.9779e-02, 2.3800e-01],\n",
      "        [2.9190e+00, 1.8564e-01, 2.1313e-01, 4.8301e-01, 3.0386e-01],\n",
      "        [2.8800e+00, 2.0612e-01, 1.4363e-01, 5.9676e-01, 2.5961e-01],\n",
      "        [2.8707e+00, 1.2875e-01, 2.2078e-01, 2.7603e-01, 5.0319e-01],\n",
      "        [2.9228e+00, 2.0590e-01, 4.0945e-01, 2.4549e-01, 3.4506e-01],\n",
      "        [2.8915e+00, 1.0820e-01, 4.6662e-01, 4.1164e-01, 1.2175e-01],\n",
      "        [2.8825e+00, 1.6681e-01, 8.5967e-01, 1.0198e-01, 3.8349e-02],\n",
      "        [2.8139e+00, 1.8732e-01, 5.7598e-02, 9.1067e-01, 3.1732e-02],\n",
      "        [2.8481e+00, 2.0383e-01, 3.2774e-01, 2.0543e-01, 4.6683e-01],\n",
      "        [2.8331e+00, 1.5481e-01, 3.8306e-01, 4.7608e-01, 1.4086e-01],\n",
      "        [2.8513e+00, 2.4194e-01, 1.2142e-01, 2.6620e-01, 6.1238e-01],\n",
      "        [2.8728e+00, 2.1053e-01, 3.3816e-01, 5.0637e-01, 1.5547e-01],\n",
      "        [2.9226e+00, 1.7044e-01, 5.0950e-01, 1.9647e-01, 2.9403e-01],\n",
      "        [2.8363e+00, 1.3925e-01, 5.6456e-01, 5.6131e-02, 3.7931e-01],\n",
      "        [2.8267e+00, 1.3015e-01, 1.4056e-01, 1.1610e-01, 7.4335e-01],\n",
      "        [2.8356e+00, 1.5149e-01, 2.4850e-01, 7.4799e-01, 3.5044e-03],\n",
      "        [2.8989e+00, 1.3365e-01, 2.6424e-01, 4.2288e-01, 3.1288e-01],\n",
      "        [2.8392e+00, 1.3655e-01, 2.1355e-02, 7.7339e-01, 2.0526e-01],\n",
      "        [2.8992e+00, 1.0617e-01, 3.9994e-01, 3.0736e-01, 2.9270e-01],\n",
      "        [2.9053e+00, 1.3135e-01, 7.0771e-01, 1.8693e-01, 1.0536e-01],\n",
      "        [2.8810e+00, 2.4762e-01, 1.9959e-01, 4.3750e-01, 3.6291e-01],\n",
      "        [2.8729e+00, 2.2591e-01, 7.0305e-01, 8.0035e-03, 2.8895e-01],\n",
      "        [2.9275e+00, 1.0797e-01, 6.0035e-01, 1.4486e-01, 2.5479e-01],\n",
      "        [2.8526e+00, 2.4247e-01, 2.5561e-01, 1.6800e-01, 5.7639e-01],\n",
      "        [2.9100e+00, 1.1357e-01, 1.7776e-01, 6.2174e-01, 2.0051e-01],\n",
      "        [2.8485e+00, 1.9764e-01, 1.4593e-01, 2.0771e-01, 6.4636e-01],\n",
      "        [2.8945e+00, 2.1185e-01, 1.6755e-01, 1.6275e-01, 6.6970e-01],\n",
      "        [2.8601e+00, 1.8371e-01, 7.2535e-03, 1.7312e-01, 8.1963e-01],\n",
      "        [2.9084e+00, 2.0052e-01, 7.3908e-01, 2.4551e-01, 1.5412e-02],\n",
      "        [2.8440e+00, 2.2055e-01, 7.6220e-01, 1.1302e-01, 1.2478e-01],\n",
      "        [2.9241e+00, 1.6348e-01, 2.3551e-01, 7.1525e-01, 4.9245e-02],\n",
      "        [2.9144e+00, 1.8974e-01, 4.1376e-01, 4.3796e-01, 1.4828e-01],\n",
      "        [2.8514e+00, 1.6230e-01, 3.1802e-02, 4.2659e-01, 5.4161e-01],\n",
      "        [2.8684e+00, 2.3692e-01, 2.4364e-02, 8.0967e-02, 8.9467e-01],\n",
      "        [2.8650e+00, 2.2101e-01, 5.7912e-01, 1.8778e-01, 2.3310e-01],\n",
      "        [2.8395e+00, 2.2384e-01, 3.7298e-01, 7.4688e-02, 5.5233e-01],\n",
      "        [2.8801e+00, 2.2760e-01, 5.8959e-01, 5.7785e-02, 3.5263e-01],\n",
      "        [2.8305e+00, 2.3233e-01, 3.6931e-02, 6.1911e-01, 3.4396e-01],\n",
      "        [2.8269e+00, 2.0331e-01, 4.6968e-01, 5.1900e-02, 4.7841e-01],\n",
      "        [2.8943e+00, 1.7302e-01, 6.3905e-01, 4.3015e-02, 3.1794e-01],\n",
      "        [2.8783e+00, 2.3286e-01, 5.3796e-02, 5.1268e-01, 4.3353e-01],\n",
      "        [2.8758e+00, 1.9624e-01, 3.0042e-01, 4.5820e-01, 2.4137e-01],\n",
      "        [2.9295e+00, 2.3771e-01, 2.8269e-01, 1.2773e-01, 5.8958e-01],\n",
      "        [2.8730e+00, 2.1480e-01, 1.0536e-01, 8.5303e-01, 4.1609e-02],\n",
      "        [2.8394e+00, 2.4901e-01, 2.6659e-01, 5.1477e-01, 2.1864e-01],\n",
      "        [2.8925e+00, 1.8195e-01, 1.2467e-01, 6.8346e-01, 1.9187e-01],\n",
      "        [2.9296e+00, 1.4001e-01, 7.7564e-01, 4.8499e-02, 1.7586e-01],\n",
      "        [2.9159e+00, 2.3611e-01, 8.6522e-02, 2.1716e-01, 6.9632e-01],\n",
      "        [2.8690e+00, 1.3320e-01, 4.7020e-01, 4.9106e-01, 3.8734e-02],\n",
      "        [2.8401e+00, 1.1971e-01, 1.8870e-01, 7.2026e-01, 9.1036e-02],\n",
      "        [2.8301e+00, 1.7114e-01, 3.4852e-01, 2.1015e-01, 4.4133e-01],\n",
      "        [2.8796e+00, 1.4859e-01, 4.0315e-01, 4.8545e-01, 1.1139e-01],\n",
      "        [2.8715e+00, 1.4913e-01, 5.3162e-01, 2.5448e-01, 2.1390e-01]])\n",
      "tensor([[-0.0773],\n",
      "        [-0.1696],\n",
      "        [-0.0670],\n",
      "        [-0.1805],\n",
      "        [ 0.1000],\n",
      "        [-0.1233],\n",
      "        [-0.2422],\n",
      "        [-0.2502],\n",
      "        [-0.0749],\n",
      "        [-0.2029],\n",
      "        [-0.0077],\n",
      "        [-0.0064],\n",
      "        [-0.1024],\n",
      "        [-0.0634],\n",
      "        [-0.1517],\n",
      "        [-0.1069],\n",
      "        [-0.0144],\n",
      "        [ 0.0424],\n",
      "        [ 0.0025],\n",
      "        [-0.0702],\n",
      "        [ 0.0319],\n",
      "        [-0.1277],\n",
      "        [ 0.0004],\n",
      "        [-0.0910],\n",
      "        [-0.0497],\n",
      "        [-0.1756],\n",
      "        [ 0.0377],\n",
      "        [-0.1009],\n",
      "        [-0.0550],\n",
      "        [-0.0948],\n",
      "        [-0.0031],\n",
      "        [-0.0798],\n",
      "        [-0.0458],\n",
      "        [-0.0923],\n",
      "        [-0.1060],\n",
      "        [-0.0731],\n",
      "        [-0.1460],\n",
      "        [-0.2167],\n",
      "        [-0.2398],\n",
      "        [ 0.0518],\n",
      "        [ 0.0601],\n",
      "        [-0.0066],\n",
      "        [-0.0236],\n",
      "        [-0.1456],\n",
      "        [-0.2581],\n",
      "        [ 0.0072],\n",
      "        [-0.0817],\n",
      "        [-0.0639],\n",
      "        [-0.0606],\n",
      "        [-0.0470],\n",
      "        [-0.0819],\n",
      "        [-0.1207],\n",
      "        [-0.0361],\n",
      "        [-0.2143],\n",
      "        [-0.0016],\n",
      "        [ 0.0067],\n",
      "        [-0.0556],\n",
      "        [-0.0539],\n",
      "        [-0.2506],\n",
      "        [ 0.0392],\n",
      "        [-0.0011],\n",
      "        [-0.0466],\n",
      "        [ 0.0038],\n",
      "        [-0.0160]])\n",
      "tensor([[-0.0542],\n",
      "        [-0.1229],\n",
      "        [-0.0777],\n",
      "        [-0.1337],\n",
      "        [ 0.0224],\n",
      "        [-0.0873],\n",
      "        [-0.3037],\n",
      "        [-0.1849],\n",
      "        [-0.0449],\n",
      "        [-0.1230],\n",
      "        [ 0.0444],\n",
      "        [-0.0288],\n",
      "        [-0.0619],\n",
      "        [-0.0541],\n",
      "        [-0.1441],\n",
      "        [-0.0705],\n",
      "        [-0.0244],\n",
      "        [ 0.0212],\n",
      "        [-0.0157],\n",
      "        [-0.0981],\n",
      "        [ 0.0147],\n",
      "        [-0.1737],\n",
      "        [-0.0056],\n",
      "        [-0.0526],\n",
      "        [-0.0735],\n",
      "        [-0.2338],\n",
      "        [ 0.0325],\n",
      "        [-0.0806],\n",
      "        [-0.0558],\n",
      "        [-0.0584],\n",
      "        [ 0.0458],\n",
      "        [-0.1088],\n",
      "        [-0.0349],\n",
      "        [-0.0326],\n",
      "        [-0.1522],\n",
      "        [-0.0598],\n",
      "        [-0.1787],\n",
      "        [-0.1975],\n",
      "        [-0.2631],\n",
      "        [ 0.0578],\n",
      "        [ 0.0227],\n",
      "        [ 0.0134],\n",
      "        [-0.0285],\n",
      "        [-0.1672],\n",
      "        [-0.2803],\n",
      "        [-0.0225],\n",
      "        [-0.1394],\n",
      "        [-0.0656],\n",
      "        [-0.1168],\n",
      "        [-0.1110],\n",
      "        [-0.0521],\n",
      "        [-0.1171],\n",
      "        [-0.0270],\n",
      "        [-0.1606],\n",
      "        [-0.0028],\n",
      "        [-0.0248],\n",
      "        [-0.0307],\n",
      "        [ 0.0137],\n",
      "        [-0.1985],\n",
      "        [ 0.0361],\n",
      "        [-0.0081],\n",
      "        [-0.1109],\n",
      "        [ 0.0078],\n",
      "        [-0.0027]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen aller Input X und Output y Daten\n",
    "for (X,y) in train_dataloader:\n",
    "    print(X)\n",
    "    print(y.reshape((-1,1)))\n",
    "    print(net(X))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fa554",
   "metadata": {},
   "source": [
    "#### Einblick in Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b043958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.5645e-01, -3.7037e-01, -3.9822e-02, -3.8814e-01,  1.2269e-01],\n",
       "         [-3.0394e-01, -8.7447e-02, -2.0902e-01,  3.9799e-01, -2.1697e-01],\n",
       "         [ 4.3916e-01,  3.0978e-01,  2.3668e-01, -2.1519e-01, -1.9150e-01],\n",
       "         [-4.1724e-01, -1.9061e-01, -2.2749e-01, -2.3144e-01, -1.9238e-01],\n",
       "         [-3.0372e-01,  4.5509e-02,  1.7116e-01, -6.6828e-02,  1.2777e-01],\n",
       "         [-1.5903e-02,  2.0232e-02, -6.7050e-02,  4.4466e-01,  3.2233e-01],\n",
       "         [-2.6536e-01, -3.7058e-01, -4.0500e-01,  3.3951e-01, -3.5260e-01],\n",
       "         [-1.0226e-01,  1.9307e-01, -3.0876e-01, -2.5090e-01, -3.8565e-01],\n",
       "         [ 1.7296e-01,  2.7675e-03,  2.1423e-01, -2.1113e-02, -2.3686e-01],\n",
       "         [-2.8486e-01,  2.1598e-01,  3.8766e-01,  3.3555e-01,  1.1165e-01],\n",
       "         [-1.4159e-02, -6.0634e-02,  4.2005e-02, -1.7351e-01,  4.0286e-01],\n",
       "         [-3.9587e-01, -1.7136e-01, -3.4281e-02,  3.8550e-01, -3.2436e-01],\n",
       "         [ 3.6283e-01,  4.0758e-01, -5.8121e-02, -3.1700e-01, -4.2977e-01],\n",
       "         [ 8.1643e-02,  1.1960e-01,  1.6051e-01,  3.1239e-01, -4.4066e-01],\n",
       "         [ 2.3121e-01,  1.2410e-01,  3.3446e-01, -2.2775e-01,  1.1504e-01],\n",
       "         [-4.3965e-02,  3.2819e-03,  2.9186e-01,  4.1033e-01, -4.4552e-01],\n",
       "         [ 3.4574e-01, -1.4984e-01, -3.5649e-01,  1.4266e-01,  1.9776e-01],\n",
       "         [ 2.0068e-01, -1.3909e-01, -3.8576e-01,  4.1909e-01, -5.3114e-02],\n",
       "         [-3.8450e-01,  1.1517e-01,  2.1835e-01,  1.8697e-01,  3.8717e-01],\n",
       "         [-2.0142e-01,  2.2314e-01,  2.7654e-01,  2.2456e-01,  1.8266e-01],\n",
       "         [-3.5824e-01,  3.5302e-02,  4.7512e-02,  1.7683e-01,  5.1942e-02],\n",
       "         [-4.2723e-01,  1.0004e-01, -3.3982e-01,  9.0577e-02, -1.7324e-01],\n",
       "         [ 7.1419e-02, -4.1452e-01,  9.5111e-03,  3.7135e-01,  1.6601e-01],\n",
       "         [-1.9251e-01, -2.4802e-01,  2.8575e-01, -2.9593e-01, -3.5654e-01],\n",
       "         [ 9.9286e-02,  2.8421e-02, -7.2094e-02, -1.3688e-01, -4.2676e-01],\n",
       "         [-2.8610e-01, -4.3670e-01,  2.2288e-01, -2.3578e-01, -3.3575e-01],\n",
       "         [ 1.9971e-01,  6.9988e-03, -6.7502e-02,  2.5535e-01,  8.8221e-02],\n",
       "         [ 7.1844e-02,  2.1080e-01,  6.7339e-02,  1.2032e-01, -7.2209e-02],\n",
       "         [ 3.0199e-01, -1.2073e-01,  1.3670e-02,  2.9605e-01,  6.8787e-02],\n",
       "         [ 3.4916e-01,  1.5945e-01,  2.5165e-01, -2.6944e-01, -5.3964e-02],\n",
       "         [ 2.3232e-01,  3.2471e-01,  1.8460e-01,  1.8876e-01,  4.0036e-03],\n",
       "         [ 4.0552e-03,  4.1738e-01, -1.4255e-01, -7.7355e-02,  2.5782e-01],\n",
       "         [ 3.3357e-03,  1.8350e-02,  9.3153e-02,  6.6927e-02, -2.4456e-01],\n",
       "         [-1.8919e-01, -2.3481e-01,  2.3311e-01, -9.3895e-02,  3.0003e-01],\n",
       "         [-8.5639e-02,  4.4384e-01,  2.5181e-01, -8.8825e-03, -2.3836e-01],\n",
       "         [-3.3710e-02, -3.4175e-01, -2.2724e-02, -3.8399e-01,  2.8753e-02],\n",
       "         [ 3.5077e-01, -6.8202e-02,  2.7239e-01,  4.1402e-01,  9.9761e-04],\n",
       "         [ 1.9075e-01,  3.4674e-01, -2.9306e-01,  1.8790e-01,  3.1366e-01],\n",
       "         [ 2.8416e-01,  1.2292e-01,  3.6571e-01,  1.3044e-01, -2.5685e-01],\n",
       "         [-3.1527e-01, -2.8719e-01,  1.9180e-01, -1.9725e-01, -2.5951e-02],\n",
       "         [ 1.8659e-01, -2.5020e-03, -3.5442e-01,  1.7171e-01,  2.4610e-01],\n",
       "         [-4.0556e-02,  9.9330e-02, -3.4817e-01,  2.7135e-01,  5.8783e-02],\n",
       "         [-2.4821e-01, -2.9269e-01,  1.8279e-02,  2.8115e-01, -5.3835e-02],\n",
       "         [-3.6630e-01,  2.6542e-02,  3.2270e-01,  1.8390e-01,  1.8970e-01],\n",
       "         [ 3.2591e-01,  3.8072e-01,  3.4541e-01,  4.1587e-01, -2.4433e-01],\n",
       "         [-3.3049e-01, -3.1910e-01, -2.5342e-01,  1.9930e-01, -8.4813e-02],\n",
       "         [-3.8108e-01, -3.9910e-01,  1.1103e-01, -9.2135e-02,  1.2039e-01],\n",
       "         [ 1.7067e-01, -1.1977e-01,  1.9148e-01, -8.4049e-02,  1.1000e-01],\n",
       "         [-3.6129e-01, -3.1175e-01,  9.0921e-05,  2.0928e-02,  3.8277e-01],\n",
       "         [-3.4656e-01, -4.3937e-01, -3.7203e-01,  4.2329e-01,  2.0395e-01],\n",
       "         [ 3.0295e-01, -4.1499e-01,  1.9330e-01,  4.3278e-01,  2.2270e-01],\n",
       "         [-1.7768e-01, -1.8660e-01,  1.0971e-01, -3.7760e-01,  6.5090e-02],\n",
       "         [ 2.8501e-01,  3.2293e-01, -1.5000e-01, -3.8095e-01, -1.3119e-01],\n",
       "         [ 3.2588e-01, -2.9391e-01, -4.4156e-01, -3.1722e-02,  1.1285e-01],\n",
       "         [-3.6478e-01,  1.9625e-01, -1.3067e-01, -3.7874e-01, -1.6440e-01],\n",
       "         [-1.3776e-01,  1.5285e-01,  2.9403e-01, -1.1965e-01,  3.3886e-01],\n",
       "         [-1.4855e-01, -2.2855e-01,  2.4727e-01, -4.2343e-03, -3.1910e-01],\n",
       "         [ 1.6898e-01,  6.2774e-02, -2.0746e-02,  3.0659e-01, -2.8545e-01],\n",
       "         [ 3.6577e-01, -1.6307e-01, -4.2805e-01, -8.0494e-02,  9.8664e-02],\n",
       "         [ 3.1536e-01,  7.8149e-02, -4.2471e-01, -2.9638e-01, -9.2912e-02],\n",
       "         [ 3.5518e-01, -1.9443e-01, -5.3619e-02, -1.1171e-01,  1.2468e-01],\n",
       "         [ 3.7014e-01,  2.5272e-01, -2.7552e-01, -3.1434e-01,  3.8660e-01],\n",
       "         [-2.9741e-01, -1.1092e-01,  3.9262e-01,  3.2174e-01,  1.5890e-02],\n",
       "         [-3.2924e-01, -2.4525e-01, -2.6562e-02,  2.1507e-01, -3.5450e-01],\n",
       "         [-7.3368e-02, -4.2851e-01, -3.9012e-01,  4.3671e-01,  3.3397e-01],\n",
       "         [ 4.1524e-03, -3.0880e-01,  9.8142e-03,  3.7309e-01,  2.4289e-01],\n",
       "         [ 1.8353e-01, -1.6238e-01, -2.4313e-02, -8.3386e-02, -3.8161e-01],\n",
       "         [-1.4984e-02, -2.4005e-01,  3.8579e-01,  3.6253e-01, -3.4533e-01],\n",
       "         [-2.1654e-03, -3.3709e-01,  1.5154e-01,  2.7672e-01,  7.7678e-02],\n",
       "         [-3.0457e-01, -3.9657e-01, -2.3478e-01,  1.2876e-01,  3.3192e-01],\n",
       "         [-1.6132e-01,  3.3025e-01,  3.4104e-01, -1.0357e-01,  1.9903e-01],\n",
       "         [-1.9066e-01,  3.9254e-01, -1.3354e-01,  1.0003e-01,  1.3113e-01],\n",
       "         [ 2.7904e-01, -6.8997e-02, -1.8689e-01, -2.7581e-01,  1.0785e-01],\n",
       "         [ 9.4933e-02, -2.8301e-01,  3.7986e-02, -1.2365e-01, -4.2920e-01],\n",
       "         [-2.9018e-01,  3.2460e-01,  1.3365e-01,  3.5703e-01, -1.4063e-01],\n",
       "         [-9.5329e-02, -1.1187e-01, -4.2864e-01, -1.0879e-01, -2.2129e-01],\n",
       "         [ 2.0727e-01, -8.7064e-02,  2.8759e-01,  3.6714e-02,  3.7358e-01],\n",
       "         [-2.2489e-01,  1.8215e-01, -3.9833e-01,  3.5978e-01,  2.2864e-02],\n",
       "         [ 9.5644e-02, -4.2740e-01,  4.3572e-01, -2.8957e-01,  3.6164e-01],\n",
       "         [-4.1553e-01, -1.6373e-01,  3.7423e-01, -7.2476e-02,  2.4066e-01],\n",
       "         [ 2.5746e-01, -1.7417e-01,  2.9537e-02,  2.3586e-01,  2.9919e-01],\n",
       "         [ 3.3429e-01, -4.4680e-01,  5.3762e-02, -3.9243e-01,  4.3887e-01],\n",
       "         [-2.1874e-01, -1.8325e-01,  4.8208e-02,  7.4634e-02, -1.6384e-01],\n",
       "         [-2.3684e-01,  2.8842e-01,  1.0793e-01, -2.2803e-01, -2.2336e-01],\n",
       "         [ 3.5239e-01, -1.2937e-01, -3.1382e-01,  3.1027e-02,  2.7030e-01],\n",
       "         [ 2.2125e-01, -1.9100e-01, -1.9101e-02,  3.3140e-01, -2.5748e-01],\n",
       "         [ 4.0713e-01,  1.9295e-01,  2.3761e-01, -1.0343e-01, -1.3965e-01],\n",
       "         [ 2.4056e-01,  2.6870e-01, -6.2880e-02, -2.8404e-01, -4.0217e-01],\n",
       "         [-2.3562e-01, -1.7636e-01, -3.9862e-01, -6.4629e-02,  1.6140e-01],\n",
       "         [-1.0481e-01, -1.5255e-01, -2.2955e-01,  4.3966e-01, -1.1203e-01],\n",
       "         [-9.2032e-02,  2.1639e-01,  4.4552e-01,  3.4308e-01, -4.1301e-01],\n",
       "         [-8.2728e-02,  3.9744e-01, -2.6019e-01, -4.9411e-02,  3.0375e-01],\n",
       "         [ 2.0433e-01,  1.5246e-01, -2.5179e-01, -3.5065e-01,  8.2372e-02],\n",
       "         [ 1.9346e-01,  3.8447e-01,  1.9249e-01,  4.1846e-01, -2.3069e-01],\n",
       "         [ 2.8335e-01,  2.2256e-01, -1.8220e-01,  2.7527e-01, -2.3090e-01],\n",
       "         [-4.1669e-01, -8.7587e-02, -2.6200e-01, -1.4211e-01, -4.0591e-01],\n",
       "         [-3.2604e-01, -5.5166e-02,  3.7074e-01,  1.4417e-01,  7.5855e-02],\n",
       "         [-3.6505e-01, -7.8435e-02, -3.9103e-01, -4.0904e-01, -3.8197e-01],\n",
       "         [-3.2001e-01,  7.6262e-03, -2.5344e-02,  4.1440e-01,  7.0520e-02],\n",
       "         [ 2.2286e-01,  2.4410e-01,  1.3934e-02,  2.2981e-01,  2.4614e-01],\n",
       "         [-1.0452e-01,  2.0748e-01,  4.0146e-02, -1.4141e-01, -2.3094e-01],\n",
       "         [ 7.5972e-02, -1.5063e-01,  3.5551e-02, -3.0501e-01, -2.6753e-01],\n",
       "         [-3.4116e-01, -2.4680e-01, -2.7290e-02, -3.4621e-01, -4.0947e-02],\n",
       "         [ 2.5984e-01, -3.1998e-01, -4.1175e-02, -3.4657e-01,  7.0789e-02],\n",
       "         [ 4.4990e-02, -1.4979e-01,  2.2053e-01, -2.3795e-01, -8.4683e-02],\n",
       "         [-2.5628e-01, -3.2873e-01, -4.6662e-02, -3.0478e-01, -3.3090e-01],\n",
       "         [ 4.3975e-01, -8.2926e-02, -3.8768e-01,  1.8250e-01, -4.1076e-01],\n",
       "         [-3.5473e-02,  2.1627e-01, -2.7569e-02,  6.9522e-02,  3.7830e-01],\n",
       "         [-3.3552e-01, -2.2178e-01,  1.1980e-01,  4.1874e-01,  2.6563e-01],\n",
       "         [-1.1579e-01,  5.7514e-02, -1.6442e-01, -3.9919e-01, -2.4569e-01],\n",
       "         [ 1.8904e-01, -2.8168e-01,  3.3109e-01, -2.5489e-01, -8.4036e-02],\n",
       "         [ 3.6391e-01, -2.8830e-01, -5.2083e-02, -2.2287e-01, -2.6568e-01],\n",
       "         [ 4.0763e-01, -4.0186e-01,  1.0672e-01,  5.0889e-02,  1.2137e-02],\n",
       "         [ 9.4510e-02, -6.5662e-02,  1.6675e-02, -3.5912e-01,  1.0486e-02],\n",
       "         [ 5.1172e-02,  4.4617e-01, -3.0278e-01,  2.5611e-01, -3.6110e-01],\n",
       "         [-1.5292e-01,  3.6327e-01, -3.0855e-01, -3.4028e-01, -3.9513e-01],\n",
       "         [ 1.5697e-01,  4.3509e-02, -3.7759e-01, -4.1866e-01,  3.5011e-01],\n",
       "         [-3.0473e-01, -2.0996e-01,  1.1267e-01,  1.2638e-01,  4.2581e-01],\n",
       "         [ 2.8105e-01,  3.5126e-02,  2.2711e-01, -1.6865e-01,  2.6128e-01],\n",
       "         [-1.4931e-01, -4.2898e-01,  2.8667e-01,  2.2331e-01, -3.3635e-01],\n",
       "         [ 2.8845e-01,  1.9452e-01,  4.2799e-01,  3.7746e-01,  2.4805e-01],\n",
       "         [ 4.4659e-02, -3.4788e-01,  4.4411e-01,  3.2380e-01,  3.2416e-01],\n",
       "         [-1.0356e-01, -1.7134e-01,  1.0801e-01, -4.4173e-01, -3.6439e-01],\n",
       "         [-1.7593e-01, -1.7310e-01,  4.0632e-01, -4.2933e-01,  2.4306e-01],\n",
       "         [ 1.0725e-01,  2.9009e-01,  3.3288e-01,  1.0511e-01, -2.0369e-02],\n",
       "         [-1.6225e-01,  3.7132e-01,  2.1699e-01, -1.4765e-01,  3.7260e-01],\n",
       "         [-4.1189e-01,  6.7561e-02, -2.2688e-02, -1.1344e-01,  2.5235e-01],\n",
       "         [-2.0655e-01,  3.7826e-01,  4.3540e-01, -8.7633e-02,  3.9285e-01],\n",
       "         [-2.1854e-01,  1.6057e-01, -1.3131e-01, -2.1250e-01,  8.6323e-02],\n",
       "         [ 8.8950e-02, -3.3443e-02,  7.0286e-02,  1.7253e-01,  3.1074e-01],\n",
       "         [-1.5836e-02,  2.4568e-01, -1.8909e-01,  2.4297e-02, -1.6332e-01],\n",
       "         [-7.0364e-02,  7.8555e-02, -1.5904e-02, -3.0888e-01,  1.8856e-01],\n",
       "         [-1.1546e-01,  3.4941e-01, -2.7059e-01, -7.6820e-02, -3.9063e-01],\n",
       "         [ 1.1518e-01,  3.6275e-01, -4.1713e-01, -1.0215e-01,  2.0457e-02],\n",
       "         [-2.7044e-02, -8.4447e-02, -8.7023e-02,  4.3325e-01, -2.8928e-01],\n",
       "         [ 2.5550e-01,  1.1476e-01,  3.8331e-01, -2.7103e-01,  1.2073e-01],\n",
       "         [ 3.0306e-01,  3.2132e-01, -3.5971e-01,  4.0970e-01,  4.4714e-01],\n",
       "         [-4.0890e-02, -9.4941e-02,  4.3819e-01, -8.5815e-02,  4.1841e-01],\n",
       "         [-2.0441e-01,  3.1207e-01, -1.6129e-02, -3.4003e-01,  7.9383e-02],\n",
       "         [ 2.8749e-01, -5.5918e-02,  1.8613e-01,  1.0991e-01, -2.6861e-01],\n",
       "         [-1.0732e-01, -9.7566e-03, -1.4854e-01,  9.9009e-02, -4.2286e-01],\n",
       "         [ 1.6864e-01, -2.5414e-01, -7.8535e-03,  4.0381e-01, -4.8018e-02],\n",
       "         [-2.3433e-01, -2.5593e-01,  2.8698e-01,  1.7942e-01,  4.3359e-01],\n",
       "         [-3.3217e-01,  2.5756e-01,  4.2190e-01, -4.0466e-01, -3.5926e-01],\n",
       "         [-2.7077e-01, -4.1387e-01,  2.5467e-01, -2.0582e-01,  1.0864e-01],\n",
       "         [-1.6517e-01, -3.3311e-01,  2.8854e-01, -2.9872e-01, -4.1759e-01],\n",
       "         [ 2.1975e-01, -2.0447e-01,  9.8722e-02, -1.0382e-01,  3.8305e-01],\n",
       "         [ 3.4611e-01,  1.9413e-01, -4.2485e-01,  1.3285e-01,  2.4218e-01],\n",
       "         [ 3.5886e-01, -4.4104e-01,  4.1713e-01,  1.4228e-01, -2.5896e-02],\n",
       "         [-2.7089e-01, -4.3087e-01, -2.7107e-01, -9.9131e-02, -1.9537e-01],\n",
       "         [ 1.3613e-01, -3.7701e-01,  9.2595e-02,  3.6516e-01,  4.0169e-01],\n",
       "         [ 3.5915e-01, -8.9145e-02, -3.1713e-01,  1.7644e-01, -3.1627e-01],\n",
       "         [ 2.0255e-02,  3.8020e-01,  4.1338e-01,  2.4050e-01, -9.1700e-02],\n",
       "         [ 1.1848e-01, -2.3702e-01,  4.2806e-01, -2.1245e-01, -1.0250e-01],\n",
       "         [ 2.9547e-01,  4.0408e-01, -1.6616e-01, -3.3597e-02,  3.7214e-01],\n",
       "         [ 1.5852e-01, -3.9740e-01,  1.8527e-01, -2.8033e-01, -1.0416e-01],\n",
       "         [ 1.1648e-01,  2.4580e-01,  3.8544e-01,  3.0864e-01,  3.7058e-01],\n",
       "         [ 1.8623e-02, -1.5207e-01,  1.6529e-01,  1.2612e-01,  3.3799e-01],\n",
       "         [-1.7357e-01,  1.4857e-01,  4.2270e-01, -3.7116e-01,  3.9972e-01],\n",
       "         [-4.3765e-01, -3.3613e-01, -4.0660e-01,  2.2232e-01,  2.0202e-01],\n",
       "         [ 3.5117e-01, -4.0364e-01,  2.9063e-01, -3.4816e-01,  3.5121e-01],\n",
       "         [-1.9907e-01, -2.5444e-01,  2.4300e-01, -2.2686e-01, -3.3135e-01],\n",
       "         [-8.4579e-02, -1.0721e-01,  6.4120e-02,  2.6918e-01, -4.4719e-01],\n",
       "         [ 4.0383e-01,  1.6506e-01,  3.0322e-01, -3.5570e-01,  2.9494e-01],\n",
       "         [-3.5384e-01,  2.9987e-01, -2.3103e-02, -1.0326e-01,  2.7525e-01],\n",
       "         [ 4.2057e-01,  2.8008e-02,  2.2204e-01,  2.9198e-01, -3.7568e-01],\n",
       "         [ 4.4595e-01,  4.2794e-01,  4.3551e-01,  2.0653e-01, -4.1002e-01],\n",
       "         [ 3.9909e-01,  4.2341e-01, -2.0612e-01,  9.4012e-02,  2.5243e-01],\n",
       "         [ 2.0228e-01,  2.5236e-01, -2.4520e-01, -6.7245e-02,  1.4804e-02],\n",
       "         [ 3.1578e-01,  2.1971e-01, -1.3776e-01,  3.0435e-01, -1.3016e-02],\n",
       "         [-1.4687e-01, -1.9028e-01, -3.3472e-01, -1.5369e-01, -2.7668e-01],\n",
       "         [ 1.4044e-01,  3.4813e-01,  4.2417e-01, -4.4567e-01,  2.5209e-01],\n",
       "         [ 9.1507e-02,  3.5724e-01,  3.8351e-01, -6.9862e-02, -4.1139e-01],\n",
       "         [ 2.0729e-01,  3.5923e-01, -1.4652e-01, -3.7115e-01, -3.4650e-01],\n",
       "         [-3.7787e-01,  4.2076e-01,  4.1420e-01, -1.9889e-02, -1.0738e-01],\n",
       "         [-2.1060e-01,  3.8942e-01,  5.6953e-02,  2.2132e-01,  1.9725e-02],\n",
       "         [ 3.1903e-01,  1.0211e-01, -7.0916e-02, -1.1761e-01, -2.0916e-01],\n",
       "         [-1.3896e-02,  4.3326e-01, -1.3545e-01, -2.4377e-01,  5.9601e-02],\n",
       "         [-4.3492e-01, -1.6649e-01,  7.7933e-03, -4.0012e-01, -6.3409e-02],\n",
       "         [ 3.7187e-01,  3.9654e-01, -4.2760e-01,  3.9062e-01, -1.5742e-01],\n",
       "         [ 7.7579e-02, -1.3678e-01,  1.0804e-05,  3.7662e-02,  1.4650e-02],\n",
       "         [-4.1333e-01, -4.6962e-02, -2.4202e-01, -2.3074e-01, -3.6300e-01],\n",
       "         [ 4.0564e-03, -2.2250e-01, -2.2685e-01,  2.2963e-01,  2.1200e-01],\n",
       "         [ 3.7213e-01, -3.7532e-01, -1.1953e-01, -1.6622e-01,  2.5326e-03],\n",
       "         [ 3.3683e-01,  3.0785e-01,  3.6932e-01,  3.1911e-01, -4.3918e-01],\n",
       "         [ 2.2209e-01,  3.9106e-01, -5.3454e-02,  4.2843e-01,  1.5347e-02],\n",
       "         [-6.5461e-02,  3.2470e-01, -3.3663e-02, -1.2380e-01, -3.9207e-01],\n",
       "         [ 1.4191e-01,  2.9211e-02,  2.0967e-01, -2.5036e-01, -1.5451e-01],\n",
       "         [ 3.9982e-02, -2.4105e-01,  4.1282e-01, -9.1777e-02,  3.6541e-01],\n",
       "         [ 1.9435e-01, -2.4201e-01,  2.2162e-01, -1.8798e-01, -3.9891e-01],\n",
       "         [ 1.6960e-01, -2.8680e-01,  9.8219e-02, -1.2012e-01, -1.8509e-01],\n",
       "         [-9.0662e-02,  4.2446e-01,  3.8576e-01, -7.1852e-02,  2.0815e-01],\n",
       "         [-3.0011e-01, -3.6690e-01,  1.3379e-01,  6.0807e-02, -3.8092e-01],\n",
       "         [ 1.9377e-01, -1.5070e-01,  2.3330e-01,  3.8613e-01,  3.1894e-01],\n",
       "         [ 2.0483e-01,  1.5042e-01,  3.6172e-02,  1.4121e-01, -1.2894e-01],\n",
       "         [-9.8222e-02,  6.6403e-02,  1.1339e-01,  6.1415e-02, -4.5337e-02],\n",
       "         [-1.9614e-01, -2.5253e-01,  2.4319e-01, -2.2654e-01, -4.1894e-01],\n",
       "         [ 2.4990e-01, -4.2529e-01,  5.8155e-02,  3.2988e-01,  3.0796e-01],\n",
       "         [ 3.5116e-01, -2.6319e-01,  2.8393e-01, -3.1266e-01,  3.7789e-01],\n",
       "         [ 6.5435e-02,  3.7211e-01, -2.0342e-01, -3.9904e-01,  1.3904e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3557,  0.2343,  0.3672, -0.2351,  0.3499, -0.4221, -0.3048,  0.2499,\n",
       "          0.4345, -0.3072,  0.3898, -0.2572,  0.2987,  0.1037,  0.2122, -0.1271,\n",
       "          0.0123,  0.0571,  0.2842,  0.0503,  0.3271, -0.2965, -0.3808,  0.3304,\n",
       "         -0.0289, -0.4368,  0.4020,  0.0191, -0.0284, -0.0009,  0.3366,  0.1127,\n",
       "          0.1340, -0.1286,  0.1838,  0.0355, -0.2460, -0.0912, -0.3034, -0.3632,\n",
       "          0.0412, -0.2610,  0.1269, -0.1628,  0.0597, -0.1245, -0.3036,  0.3847,\n",
       "         -0.1113,  0.0625, -0.4287, -0.1369,  0.2037,  0.3739,  0.0580,  0.1581,\n",
       "         -0.0130, -0.2023, -0.4075, -0.1705,  0.4008, -0.0918,  0.4009,  0.3950,\n",
       "          0.1178,  0.2035, -0.3161, -0.3002,  0.3059, -0.1182,  0.1179, -0.1833,\n",
       "          0.3462, -0.3564,  0.2438,  0.0402,  0.2165, -0.4092,  0.0035, -0.1516,\n",
       "         -0.1255, -0.2855,  0.3000,  0.1825,  0.3705, -0.3019, -0.3234,  0.0961,\n",
       "         -0.1357, -0.1205, -0.2714,  0.0223,  0.0059,  0.2080,  0.2911,  0.1253,\n",
       "          0.1303, -0.3756, -0.3034, -0.2236, -0.4433,  0.3469, -0.2186, -0.3301,\n",
       "         -0.3769,  0.1459,  0.0415, -0.2689, -0.0962,  0.3669, -0.1884, -0.1490,\n",
       "         -0.3652, -0.0070,  0.1474,  0.0168,  0.2240, -0.3802, -0.0120,  0.4329,\n",
       "         -0.2501, -0.0181,  0.0888,  0.2948,  0.1938, -0.3837, -0.1727,  0.2401,\n",
       "         -0.2402, -0.1122,  0.2076, -0.0702, -0.1232, -0.3214, -0.3583,  0.0598,\n",
       "         -0.3557, -0.1617,  0.0821,  0.4177,  0.2721, -0.0555,  0.1930,  0.3911,\n",
       "          0.1142, -0.2979, -0.0219,  0.3770, -0.3635,  0.1006,  0.3966, -0.3319,\n",
       "          0.4294,  0.2816,  0.0743, -0.1134, -0.1739, -0.0090,  0.3515, -0.0322,\n",
       "         -0.0919,  0.0777,  0.0096, -0.2002, -0.0194,  0.1632,  0.0964,  0.3757,\n",
       "          0.0670, -0.3982,  0.4469, -0.2892,  0.3587, -0.1248, -0.2616,  0.0118,\n",
       "         -0.2736,  0.3954,  0.2877,  0.4473,  0.0515, -0.0354, -0.1479, -0.0784,\n",
       "         -0.0754,  0.4053,  0.3316, -0.1676,  0.0850,  0.1372, -0.3470,  0.4190,\n",
       "         -0.4284,  0.3357, -0.2054,  0.0630,  0.1192, -0.1137, -0.4273, -0.0036],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0008, -0.0116, -0.0484,  ...,  0.0400,  0.0541, -0.0275],\n",
       "         [-0.0175, -0.0669, -0.0026,  ..., -0.0013, -0.0485,  0.0115],\n",
       "         [ 0.0082,  0.0588,  0.0255,  ...,  0.0235,  0.0633, -0.0648],\n",
       "         ...,\n",
       "         [-0.0065,  0.0440,  0.0064,  ..., -0.0565,  0.0621, -0.0581],\n",
       "         [-0.0545,  0.0378, -0.0441,  ...,  0.0396,  0.0514, -0.0560],\n",
       "         [-0.0516,  0.0308,  0.0421,  ...,  0.0567, -0.0412, -0.0044]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 3.0145e-02, -1.3201e-02,  2.7260e-02,  5.0998e-02, -1.7321e-02,\n",
       "         -5.5272e-02, -2.9985e-02, -4.2423e-02,  5.8073e-02,  5.4247e-02,\n",
       "          6.9174e-02, -4.5977e-03, -4.3379e-02,  4.6361e-02, -3.6574e-02,\n",
       "          1.2640e-02,  2.2672e-02, -5.4400e-02,  3.3756e-02, -2.5790e-02,\n",
       "         -7.8699e-03, -5.9386e-02, -1.3843e-02,  1.1697e-02, -1.4557e-02,\n",
       "         -6.5123e-02, -5.0068e-02,  7.5408e-03, -3.3283e-02, -3.8671e-02,\n",
       "          5.0231e-02,  3.0293e-02,  7.5656e-03,  6.1094e-02,  5.3922e-02,\n",
       "          3.7773e-04,  6.0503e-02,  3.3490e-02,  1.6478e-02,  1.8296e-02,\n",
       "         -6.1185e-02, -6.0442e-02, -5.3621e-02, -3.4914e-02, -6.7379e-02,\n",
       "          3.0866e-02,  4.0160e-02, -1.7707e-02, -1.6081e-02, -4.9914e-02,\n",
       "         -4.1672e-05, -4.9805e-02,  5.3318e-02, -7.4233e-03, -1.2395e-02,\n",
       "         -5.4330e-02,  4.1956e-02,  2.4153e-02,  6.6088e-02, -4.3092e-02,\n",
       "          8.3564e-03,  5.8343e-02,  3.6853e-02,  4.1601e-02,  5.5698e-02,\n",
       "          4.6404e-02,  1.0123e-03,  1.1875e-02,  5.8868e-02,  4.3629e-02,\n",
       "          4.3598e-03, -2.5501e-02, -6.1413e-02,  1.8829e-02,  3.6406e-02,\n",
       "         -3.2301e-03,  9.4974e-03, -6.7107e-02, -2.8909e-02,  1.3600e-02,\n",
       "          4.4842e-02,  3.5966e-02,  5.9411e-02, -3.6432e-02,  2.2365e-02,\n",
       "          6.8243e-02, -2.0041e-02, -6.2827e-03, -2.5840e-02,  4.4121e-02,\n",
       "         -7.7337e-03, -1.6103e-02,  1.8793e-02,  5.5831e-02, -3.3272e-02,\n",
       "          6.0528e-02, -3.9491e-02,  2.1768e-02,  6.9747e-02,  6.3518e-02,\n",
       "          7.0227e-02,  2.0638e-02, -5.7763e-02, -1.6184e-02, -6.4780e-02,\n",
       "         -6.6709e-02,  6.6712e-02, -2.0988e-02, -2.3933e-03, -9.3867e-03,\n",
       "          1.6861e-02,  2.8024e-02,  4.2609e-02, -3.0947e-04, -3.6342e-03,\n",
       "          7.9497e-03, -3.3480e-02, -6.1837e-03,  1.4646e-02,  4.6349e-02,\n",
       "         -4.1611e-02,  1.2051e-02, -4.3443e-02, -3.1212e-02, -2.0782e-02,\n",
       "          4.3582e-03,  2.9609e-02, -5.1187e-02,  6.3759e-02, -5.1304e-03,\n",
       "         -5.6044e-02, -6.0528e-02, -5.8659e-02,  4.8510e-02, -1.3286e-02,\n",
       "         -3.8868e-02, -5.9334e-02,  2.9505e-02,  4.4677e-02,  3.3588e-02,\n",
       "          6.1571e-03,  4.8052e-02, -1.6785e-03, -5.3426e-02,  1.5494e-02,\n",
       "         -4.2982e-02,  7.6352e-03,  4.8022e-02,  2.4096e-02, -5.6179e-03,\n",
       "          5.1965e-02,  5.7475e-02, -6.5543e-02,  6.5183e-02, -4.0183e-03,\n",
       "         -5.1867e-02, -5.2970e-02, -6.1626e-02,  3.9439e-02,  3.3035e-02,\n",
       "         -4.7768e-02,  1.1160e-02,  5.7284e-03, -6.9239e-02,  5.6325e-02,\n",
       "          2.8214e-02, -2.8422e-02, -2.6973e-02, -1.8388e-02, -4.3276e-03,\n",
       "         -6.1238e-03,  1.9947e-02, -5.1518e-02, -4.9717e-03,  2.4202e-02,\n",
       "          6.7286e-03,  6.4015e-02, -2.1770e-02,  6.2278e-02, -2.0010e-02,\n",
       "         -2.6941e-02,  2.8795e-02,  4.9113e-02,  6.1855e-02,  1.5188e-02,\n",
       "         -6.7033e-02,  1.5751e-02,  6.4894e-02, -4.1856e-02,  6.3922e-02,\n",
       "         -5.4554e-02,  5.0818e-02, -6.0224e-02, -2.2098e-02,  2.9475e-02,\n",
       "         -1.4907e-03, -2.1000e-03, -3.5487e-02, -5.9324e-02,  3.3751e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.9801e-03,  4.5650e-02, -2.3879e-02,  5.4012e-02,  2.5725e-02,\n",
       "           6.2138e-02,  2.1393e-02,  2.3824e-02, -1.0411e-02,  3.5733e-02,\n",
       "           6.5728e-03,  6.5331e-02, -4.1512e-02, -8.0698e-03,  6.1519e-03,\n",
       "          -3.6523e-02,  4.1234e-02,  3.4480e-02, -5.7902e-02, -4.8853e-02,\n",
       "           5.2193e-02, -3.7203e-02,  2.3951e-02,  5.5511e-02,  3.3125e-02,\n",
       "          -6.6961e-02, -2.2718e-02,  2.3797e-02, -2.7286e-02, -2.3477e-02,\n",
       "          -3.9444e-02, -3.1072e-02, -1.2202e-02,  3.7264e-02, -4.2882e-02,\n",
       "          -1.9486e-02, -4.2099e-02, -3.8836e-03, -1.1560e-03,  2.0165e-02,\n",
       "           7.5352e-02,  4.4027e-02,  2.3057e-03, -5.7962e-02,  1.0342e-02,\n",
       "           2.6087e-02,  5.3615e-02, -2.4337e-03, -6.9563e-02, -4.2241e-02,\n",
       "          -2.2529e-02,  2.7531e-02,  6.4753e-02, -6.7181e-02,  6.7386e-02,\n",
       "          -2.1138e-03,  6.6246e-03,  4.4176e-02,  7.0534e-02, -1.4376e-02,\n",
       "          -5.7921e-02,  1.1089e-02,  3.5762e-02,  3.7735e-02, -4.5000e-02,\n",
       "          -7.6309e-03,  6.1397e-02, -7.0522e-02, -4.3129e-02,  2.8842e-02,\n",
       "           3.0780e-02, -5.8374e-03, -5.5437e-02, -5.6446e-02,  1.6151e-02,\n",
       "           3.6925e-02,  4.8836e-02, -3.8118e-02,  6.5755e-02,  5.5761e-02,\n",
       "           2.1778e-02,  2.5374e-02,  1.7583e-02, -1.2496e-02, -3.3937e-02,\n",
       "          -3.1849e-02, -3.9169e-02, -6.6211e-02, -5.7387e-02, -5.5875e-02,\n",
       "          -5.9359e-02,  7.2518e-03,  6.2446e-02, -5.4700e-03, -6.1354e-02,\n",
       "           1.2046e-02,  5.6131e-02,  5.6672e-02, -2.2845e-02,  1.3714e-02,\n",
       "           2.8901e-02, -3.8093e-02, -3.6789e-02, -3.1399e-02, -3.7650e-02,\n",
       "           6.2114e-02, -5.9425e-02,  1.0678e-02,  6.4410e-02,  5.0275e-02,\n",
       "          -5.9094e-02, -1.5829e-02, -6.1919e-02,  6.0566e-02,  5.6647e-02,\n",
       "          -2.3336e-02, -3.8575e-02,  7.8135e-03,  1.0034e-02, -4.1018e-02,\n",
       "          -1.6043e-02, -5.9454e-02, -5.5123e-02,  5.4724e-02, -3.9975e-02,\n",
       "          -7.0654e-02,  3.0965e-02,  2.4677e-02, -6.5546e-02,  1.3214e-02,\n",
       "           9.3927e-03,  4.4056e-02,  4.6282e-02,  5.0873e-02,  7.4665e-03,\n",
       "           3.0038e-02,  3.5487e-02, -1.9792e-02,  4.1159e-02,  1.4142e-02,\n",
       "          -5.7816e-02, -4.8227e-02, -5.3340e-02, -1.7691e-02, -2.2519e-02,\n",
       "          -2.6084e-04, -2.6088e-02, -5.5605e-02,  1.8381e-02,  6.5717e-02,\n",
       "          -5.0560e-02, -3.0054e-02,  6.5390e-02,  4.5480e-02, -8.0491e-02,\n",
       "          -7.3492e-02, -1.7805e-02, -3.2353e-02,  4.2353e-02, -2.8987e-02,\n",
       "          -2.7488e-05, -7.3949e-03, -6.3837e-02,  1.6137e-02, -7.7928e-02,\n",
       "           6.3668e-02, -5.8669e-02,  6.2400e-02, -5.5853e-02,  6.9570e-02,\n",
       "          -2.0325e-02,  3.2675e-03, -4.7288e-02,  7.5841e-02, -4.3016e-02,\n",
       "           3.5297e-02, -2.0136e-02, -3.9927e-02,  7.2801e-02,  2.2258e-02,\n",
       "          -6.8225e-03,  3.5761e-02,  6.1862e-02, -4.8989e-02,  2.8300e-02,\n",
       "           3.6649e-02, -1.5006e-02,  1.5410e-02, -6.7582e-02,  2.2167e-02,\n",
       "           2.4543e-02,  5.6793e-02,  6.8819e-02, -3.2782e-02,  1.3512e-02,\n",
       "           1.5276e-02,  6.1160e-02,  6.8398e-02,  2.0177e-02,  8.1955e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0082], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) # zeigt weights, biases, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4046c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2654, 0.8665, 0.4303, 0.0127, 0.4625],\n",
      "        [0.7665, 0.4862, 0.4427, 0.5092, 0.5813]])\n",
      "tensor([[0.0626],\n",
      "        [0.0204]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2,5))\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae8dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0ea37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
